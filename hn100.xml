<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Mon, 13 May 2024 12:00:17 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Telegram has launched a pretty intense campaign to malign Signal as insecure (185 pts)]]></title>
            <link>https://twitter.com/matthew_d_green/status/1789687898863792453</link>
            <guid>40341716</guid>
            <pubDate>Mon, 13 May 2024 10:49:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/matthew_d_green/status/1789687898863792453">https://twitter.com/matthew_d_green/status/1789687898863792453</a>, See on <a href="https://news.ycombinator.com/item?id=40341716">Hacker News</a></p>
Couldn't get https://twitter.com/matthew_d_green/status/1789687898863792453: Error: Request failed with status code 400]]></description>
        </item>
        <item>
            <title><![CDATA[Ordered back to the office, top tech talent left instead, study finds (101 pts)]]></title>
            <link>https://www.washingtonpost.com/business/2024/05/12/rto-microsoft-apple-spacex/</link>
            <guid>40339852</guid>
            <pubDate>Mon, 13 May 2024 04:43:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.washingtonpost.com/business/2024/05/12/rto-microsoft-apple-spacex/">https://www.washingtonpost.com/business/2024/05/12/rto-microsoft-apple-spacex/</a>, See on <a href="https://news.ycombinator.com/item?id=40339852">Hacker News</a></p>
Couldn't get https://www.washingtonpost.com/business/2024/05/12/rto-microsoft-apple-spacex/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Open Source YouTube to MP3 Downloader (103 pts)]]></title>
            <link>https://github.com/PackJC/YoutubeToMP3</link>
            <guid>40338967</guid>
            <pubDate>Mon, 13 May 2024 01:22:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/PackJC/YoutubeToMP3">https://github.com/PackJC/YoutubeToMP3</a>, See on <a href="https://news.ycombinator.com/item?id=40338967">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">YoutubeToMP3</h2><a id="user-content-youtubetomp3" aria-label="Permalink: YoutubeToMP3" href="#youtubetomp3"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/34726562/329894214-d363050e-b42e-4c16-8edf-ab1f6574faa6.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTU1OTQ3MDQsIm5iZiI6MTcxNTU5NDQwNCwicGF0aCI6Ii8zNDcyNjU2Mi8zMjk4OTQyMTQtZDM2MzA1MGUtYjQyZS00YzE2LThlZGYtYWIxZjY1NzRmYWE2LmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MTMlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTEzVDEwMDAwNFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWRiNDA1NjliZDVkNTAyZTE2Mjc5MTkyODVmYTdkYjBmN2VjMDI2YWIwMTE3NTQ3NjhiZDRhMjdkZGI2YTYyMDEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.XibTjFXntxIYGBBi818EhXKHn-1Rsvz_K8q7GA3UM9g"><img src="https://private-user-images.githubusercontent.com/34726562/329894214-d363050e-b42e-4c16-8edf-ab1f6574faa6.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTU1OTQ3MDQsIm5iZiI6MTcxNTU5NDQwNCwicGF0aCI6Ii8zNDcyNjU2Mi8zMjk4OTQyMTQtZDM2MzA1MGUtYjQyZS00YzE2LThlZGYtYWIxZjY1NzRmYWE2LmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MTMlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTEzVDEwMDAwNFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWRiNDA1NjliZDVkNTAyZTE2Mjc5MTkyODVmYTdkYjBmN2VjMDI2YWIwMTE3NTQ3NjhiZDRhMjdkZGI2YTYyMDEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.XibTjFXntxIYGBBi818EhXKHn-1Rsvz_K8q7GA3UM9g" alt="Animation" data-animated-image=""></a></p>
<p dir="auto">This Windows Forms application in C# allows users to download YouTube videos as MP3 files. Users can enter a YouTube URL, and upon clicking the download button, the app uses YoutubeExplode to fetch and download the video. A progress bar updates in real-time, showing the download progress. After downloading, the app converts the video to MP3 using MediaToolkit. Users choose the save location for the MP3 file via a SaveFileDialog. A completion notification pops up once the process is complete. This app provides a user-friendly way to convert YouTube videos into MP3s directly from the desktop.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Star Destroyer and Imperial Military Doctrine (101 pts)]]></title>
            <link>https://acoup.blog/2024/05/10/fireside-friday-may-10-2024/</link>
            <guid>40338517</guid>
            <pubDate>Mon, 13 May 2024 00:04:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://acoup.blog/2024/05/10/fireside-friday-may-10-2024/">https://acoup.blog/2024/05/10/fireside-friday-may-10-2024/</a>, See on <a href="https://news.ycombinator.com/item?id=40338517">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		
<p>Fireside this week!  Next week, with luck, I’ll have my ‘On the Reign of Alexander III of Macedon’ up as an addendum to our discussion of Hellenistic armies.  But in the meantime, it is a fireside, and I thought, since it was just recently May the Fourth, we might talk some Star Wars (and history).  So this is going to be a bit silly this week.</p>



<figure><img loading="lazy" decoding="async" width="1024" height="768" data-attachment-id="23981" data-permalink="https://acoup.blog/2024/05/10/fireside-friday-may-10-2024/pxl_20240505_171735432-mp_/" data-orig-file="https://i0.wp.com/acoup.blog/wp-content/uploads/2024/05/PXL_20240505_171735432.MP_.jpg?fit=4032%2C3024&amp;ssl=1" data-orig-size="4032,3024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 3a&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1714915055&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.44&quot;,&quot;iso&quot;:&quot;419&quot;,&quot;shutter_speed&quot;:&quot;0.041667&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="PXL_20240505_171735432.MP_" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/acoup.blog/wp-content/uploads/2024/05/PXL_20240505_171735432.MP_.jpg?fit=300%2C225&amp;ssl=1" data-large-file="https://i0.wp.com/acoup.blog/wp-content/uploads/2024/05/PXL_20240505_171735432.MP_.jpg?fit=1024%2C768&amp;ssl=1" src="https://i0.wp.com/acoup.blog/wp-content/uploads/2024/05/PXL_20240505_171735432.MP_.jpg?resize=1024%2C768&amp;ssl=1" alt="" srcset="https://i0.wp.com/acoup.blog/wp-content/uploads/2024/05/PXL_20240505_171735432.MP_.jpg?resize=1024%2C768&amp;ssl=1 1024w, https://i0.wp.com/acoup.blog/wp-content/uploads/2024/05/PXL_20240505_171735432.MP_.jpg?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/acoup.blog/wp-content/uploads/2024/05/PXL_20240505_171735432.MP_.jpg?resize=768%2C576&amp;ssl=1 768w, https://i0.wp.com/acoup.blog/wp-content/uploads/2024/05/PXL_20240505_171735432.MP_.jpg?resize=1536%2C1152&amp;ssl=1 1536w, https://i0.wp.com/acoup.blog/wp-content/uploads/2024/05/PXL_20240505_171735432.MP_.jpg?resize=2048%2C1536&amp;ssl=1 2048w, https://i0.wp.com/acoup.blog/wp-content/uploads/2024/05/PXL_20240505_171735432.MP_.jpg?resize=1200%2C900&amp;ssl=1 1200w, https://i0.wp.com/acoup.blog/wp-content/uploads/2024/05/PXL_20240505_171735432.MP_.jpg?resize=800%2C600&amp;ssl=1 800w, https://i0.wp.com/acoup.blog/wp-content/uploads/2024/05/PXL_20240505_171735432.MP_.jpg?resize=600%2C450&amp;ssl=1 600w, https://i0.wp.com/acoup.blog/wp-content/uploads/2024/05/PXL_20240505_171735432.MP_.jpg?resize=400%2C300&amp;ssl=1 400w, https://i0.wp.com/acoup.blog/wp-content/uploads/2024/05/PXL_20240505_171735432.MP_.jpg?resize=200%2C150&amp;ssl=1 200w, https://i0.wp.com/acoup.blog/wp-content/uploads/2024/05/PXL_20240505_171735432.MP_.jpg?resize=1100%2C825&amp;ssl=1 1100w, https://i0.wp.com/acoup.blog/wp-content/uploads/2024/05/PXL_20240505_171735432.MP_.jpg?w=2200&amp;ssl=1 2200w, https://i0.wp.com/acoup.blog/wp-content/uploads/2024/05/PXL_20240505_171735432.MP_.jpg?w=3300&amp;ssl=1 3300w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1"><figcaption>The completed Lego Star Destroyer.</figcaption></figure>



<p>For this week’s <strong>musing</strong>, over the last week, as part of my May the Fourth celebration (and some enforced post-semester relaxation), I went and built the Lego Star Destroyer my better half bought for me (about a year ago – the space for building it got consumed by other things in the intervening time).  This is not the <em>very old</em> (2002) Star Destroyer kit, nor the very newest (2024) kit, but the finely aged (2019) ‘Ultimate Collector’ set, coming in at a massive 4,700 pieces.  It was fun to build and there’s actually a lot of kind of neat engineering and design that clearly went in to making it work.  With so many pieces, the set is so <em>heavy</em> that it needs a whole reinforcing frame (also made of legos) to hold it together internally.</p>



<p>But that got me thinking about Star Destroyers (<a href="https://acoup.blog/2019/12/20/collections-starships-in-silhouette/" data-type="post" data-id="1960">not the first time</a>) and Star Wars, so I figured I’d muse a bit at you both about the odd place of Star Destroyers in imperial military doctrine and also the nature of the Old Republic and the Empire as polities.</p>



<p>So let’s star with the obvious about the design of the Imperial Star Destroyer (ISD), which is that it was designed (for the screen) to <em>look</em> a certain way, rather than as a function fighting machine.  And as that sort of design, the ISD is brilliant.  The lower hull seems to have been planned out for that massive opening shot: the long, flat sections make it feel like the ship goes on <em>forever</em>, while the three breaks in the shape (the two docking hangers and the bulge over the reactor) break up the monotony.  The <em>two</em> docking bays, a smaller one first and then a much larger one, also stress the ship’s gargantuan size: the viewer see’s what they think is the primary hanger, and then, wait, no, <em>there’s another, much bigger one</em> and then the ship <em>doesn’t end</em>.  The rear of the ship, with its massive brace of engines, also manages to communicate that this behemoth might also be <em>fast</em> as well as large.  And then when we see the thing from the front, the presence of its raised superstructure immediately communicates its primary role as a battleship, because it has a similar sort of superstructure to WWII-era battleships, with that raised command tower looming over a superstructure above the main structure.  It is simultaneously different enough from any real vehicle to be immediately memorable – not merely a battleship stuck in space – but at the same time, shares enough design language for the audience to intuit its role immediately.</p>



<p>As an aside, I think this is something the ISD design does a lot better than many more recent similar efforts.  Both new Star Wars (particularly the sequel films) and new Star Trek (particularly <em>Discovery </em>and <em>Picard</em>) have a problem with villain ships which are wildly out of scale with the existing designs in the setting, but which are essentially just blown-up versions of existing visual language (<em>Discovery</em>‘s <em>Dreadnought</em> and <em>The Rise of Skywalker</em>‘s <em>Xyston</em>-class both come to mind).  Even the First Order Star Destroyers often felt like they had to be massively <em>bigger</em> than the ISD because they otherwise lacked new ideas.  But the ISD itself was pretty fresh as a concept and delivers on it extremely well (and the SSD is a better, “that, but bigger, scarier and in Vadar’s theme colors” variant than anything in the sequel trilogy).</p>



<p>Of course, the ISD initially existed without any context – it is the <em>second</em> thing we see on screen after the crawl (not counting planets) – but it eventually got one, a design lineage from the Republic-era <em>Venator</em>.  And this creates a bit of an oddity, because in the Clone Wars, the Republic fleet is essentially built around fast carriers – the <em>Venators</em> – and their fighters, whereas it is the CIS fleet which has specialized gunboats (along with the slower Lucrehulks that function as carriers), but by the time we get to the Empire, the doctrine has switched: the ISD is clearly a gun platform first and foremost, which carries its own fighter screen, but expects to win with its primary battery, not its (flimsy) TIE-Fighters, while it is the Rebellion that eventually adopts a fast-carrier kind of doctrine.</p>



<p>Now, the out-of-universe reason for this is that George Lucas thinks it is cool to have the protagonists flying fighters against big enemy battleships and so that is the doctrine he gives to the ‘good guys’ in each films.  I wonder if that is itself an influence from the Second World War (and the war films Lucas studied to block out his space battle sequences), where the early phases (particularly 1942) in the Pacific were the plucky efforts of a few American fast carriers and cruisers against fleets loaded with imposing-looking battleships.  It also, of course, makes storytelling sense: the characters we care about can be in the fighters, while the bad guys in their big Death Stars and Star Destroyers are distant, powerful and imposing.</p>



<p>But it creates a lore problem, which is, ‘why did the Galactic Empire entirely change its doctrine <em>after</em> winning the Clone Wars?’  ‘Legends’ canon – that is, the pre-Disney canon – had its answer, which is that ‘it didn’t.’  Instead, there was a longer progression of ship designs late in the Clone Wars, from the carrier-oriented <em>Venator</em> and <em>Accalamator</em> to the up-gunned version, the <em>Victory</em>-class Star Destroyer (VSD), which was supposed to be a late-Clone Wars design which serves as the bridge from to the ISD.  With the VSD in the design lineage, the ISD makes sense: the Empire deployed, late in the war, a more gun-based platform, then won the war and continued development along that ‘successful’ design lineage, producing an extreme version of the VSD in the ISD.</p>



<p>The Canon (‘Disney-Canon’) <em>technically</em> has the same narrative (the <a href="https://starwars.fandom.com/wiki/Victory-class_Star_Destroyer" data-type="link" data-id="https://starwars.fandom.com/wiki/Victory-class_Star_Destroyer">VSD is technically still canon, according to Wookiepedia</a>), but has never put the VSD on screen. In the scenes where we <em>ought</em> to see a transitional VSD, we instead see an ISD, and the new canon has also removed one of the main ‘Legends’ advantages the VSD had: in legends, the VSD was capable of atmospheric flight, but the ISD was not, but in canon, the ISD now can do that. The reason here, I have to assume is that brand new models are expensive and Disney would rather keep reusing and modifying <em>Rogue One</em>‘s very high-quality ISD-I model <em>forever</em> if necessary, even in places where it makes no sense, like for the <em>Xyston</em>-class or in games set after the Battle of Endor. If Disney can’t be bothered to make a high-detail ISD-II model, they surely can’t be bothered to work up a new VSD model.</p>



<figure><img loading="lazy" decoding="async" width="1024" height="768" data-attachment-id="23983" data-permalink="https://acoup.blog/2024/05/10/fireside-friday-may-10-2024/pxl_20240505_171251219-mp_/" data-orig-file="https://i0.wp.com/acoup.blog/wp-content/uploads/2024/05/PXL_20240505_171251219.MP_-rotated.jpg?fit=4032%2C3024&amp;ssl=1" data-orig-size="4032,3024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 3a&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1714914771&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.44&quot;,&quot;iso&quot;:&quot;825&quot;,&quot;shutter_speed&quot;:&quot;0.041667&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="PXL_20240505_171251219.MP_" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/acoup.blog/wp-content/uploads/2024/05/PXL_20240505_171251219.MP_-rotated.jpg?fit=300%2C225&amp;ssl=1" data-large-file="https://i0.wp.com/acoup.blog/wp-content/uploads/2024/05/PXL_20240505_171251219.MP_-rotated.jpg?fit=1024%2C768&amp;ssl=1" src="https://i0.wp.com/acoup.blog/wp-content/uploads/2024/05/PXL_20240505_171251219.MP_.jpg?resize=1024%2C768&amp;ssl=1" alt="" srcset="https://i0.wp.com/acoup.blog/wp-content/uploads/2024/05/PXL_20240505_171251219.MP_-rotated.jpg?resize=1024%2C768&amp;ssl=1 1024w, https://i0.wp.com/acoup.blog/wp-content/uploads/2024/05/PXL_20240505_171251219.MP_-rotated.jpg?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/acoup.blog/wp-content/uploads/2024/05/PXL_20240505_171251219.MP_-rotated.jpg?resize=768%2C576&amp;ssl=1 768w, https://i0.wp.com/acoup.blog/wp-content/uploads/2024/05/PXL_20240505_171251219.MP_-rotated.jpg?resize=1536%2C1152&amp;ssl=1 1536w, https://i0.wp.com/acoup.blog/wp-content/uploads/2024/05/PXL_20240505_171251219.MP_-rotated.jpg?resize=2048%2C1536&amp;ssl=1 2048w, https://i0.wp.com/acoup.blog/wp-content/uploads/2024/05/PXL_20240505_171251219.MP_-rotated.jpg?resize=1200%2C900&amp;ssl=1 1200w, https://i0.wp.com/acoup.blog/wp-content/uploads/2024/05/PXL_20240505_171251219.MP_-rotated.jpg?resize=800%2C600&amp;ssl=1 800w, https://i0.wp.com/acoup.blog/wp-content/uploads/2024/05/PXL_20240505_171251219.MP_-rotated.jpg?resize=600%2C450&amp;ssl=1 600w, https://i0.wp.com/acoup.blog/wp-content/uploads/2024/05/PXL_20240505_171251219.MP_-rotated.jpg?resize=400%2C300&amp;ssl=1 400w, https://i0.wp.com/acoup.blog/wp-content/uploads/2024/05/PXL_20240505_171251219.MP_-rotated.jpg?resize=200%2C150&amp;ssl=1 200w, https://i0.wp.com/acoup.blog/wp-content/uploads/2024/05/PXL_20240505_171251219.MP_-rotated.jpg?resize=1100%2C825&amp;ssl=1 1100w, https://i0.wp.com/acoup.blog/wp-content/uploads/2024/05/PXL_20240505_171251219.MP_-rotated.jpg?w=2200&amp;ssl=1 2200w, https://i0.wp.com/acoup.blog/wp-content/uploads/2024/05/PXL_20240505_171251219.MP_-rotated.jpg?w=3300&amp;ssl=1 3300w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1"><figcaption>Front view of the set, where you can see that it comes with a Tantive IV CR90 Corvette to scale (it fits neatly into the docking bay).<span id="easy-footnote-1-23926"></span><span><a href="#easy-footnote-bottom-1-23926" title="As an aside, one of the silliest things in the sequel trilogy lore was bringing back not just <em>a</em> CR90, but insisting that the Resistance&amp;#8217;s CR90 was a <a href=&quot;https://starwars.fandom.com/wiki/Tantive_IV#Return_and_destruction.&quot; data-type=&quot;link&quot; data-id=&quot;https://starwars.fandom.com/wiki/Tantive_IV#Return_and_destruction.&quot;>recovered Tantive IV</a>.  The &amp;#8216;Legends&amp;#8217; canon has Vader do the obvious thing to complete the ruse of sending a distress signal and then reporting the ship destroyed in an accident, which was, of course, <strong>to destroy the ship and kill the crew</strong>, thereby leaving no evidence behind, a thing <strong>Darth Vader</strong> is obviously ruthless enough to do."><sup>1</sup></a></span></figcaption></figure>



<p>But I think I can actually puzzle out a ‘history of the Galactic Empire’ which makes a bit of sense and into which the ISD has an understandable – if not <em>sound</em> – doctrinal place.  First, we need to understand what kind of polity the Old Republic – and thus the Empire – <em>is</em>.  And here, the phrasing I go to (somewhat imprecise) is that the Republic was a ‘Republic of Princes’ in the same sense that the Holy Roman Empire was an empire of ‘princes’ or more technically ‘imperial states.’<span id="easy-footnote-2-23926"></span><span><a href="#easy-footnote-bottom-2-23926" title="As I understand it in technical terms, a &amp;#8216;prince&amp;#8217; of the HRE was a direct vassal of the emperor; many imperial states were &amp;#8216;princes&amp;#8217; &amp;#8211; including some archbishoprics &amp;#8211; but not all were.  However, I find when explaining this to folks, the idea of a &amp;#8216;government of princes&amp;#8217; makes a lot more sense than &amp;#8216;a government of states.&amp;#8217;"><sup>2</sup></a></span>  I promise we will get back to Star Destroyers here eventually.</p>



<p>In short, the Republic was not a democracy of <em>people</em> but a republic of <em>states</em>, the ‘princes’ which in turn governed their own territory internally.  These ‘princes’ could be any form of government.  And indeed, the imperial states of the Holy Roman Empire could be noble rulers, but also bishops ruling cities (the ‘prince-archbishops’), monks running abbeys (Imperial prelates), grandmasters running holy orders, and even cities governing themselves (free and imperial cities).  So too with the Republic, which is why the Trade Federation can sit on the Senate alongside democratic Naboo and monarchic Alderaan.</p>



<p>Crucially, each of these ‘princes’ is internally self-governing, but also has its own military, some large and some small, and its own resource base with which to <em>develop</em> such a military.</p>



<p>Given that, what I think a historian of this period, looking back would conclude about the Star Wars story would be this: the Clone Wars were essentially a civil war between the princes of the Rim territories against the princes of the core regions (as the later effectively ruled the senate).  That civil war produced political momentum among some of the core princes towards centralization, which fuels the career of Palpatine.  Palpatine’s reign and the Empire in general is thus understood as a reaction to the Clone Wars primarily aimed at centralizing power at the expense of the princes.</p>



<p>That in turn produced two related reactions.  On the one hand, it produces obvious discontent among the ‘princes’ themselves – the ruling classes of these planets.  The Bail Organas and Mon Mothmas.  But the centralization also begins to disintermediate the princely governments themselves, suddenly exposing their citizens to <em>direct</em> rule by the empire (we see this quite clearly in <em>Andor</em>) and it turns out, they don’t like it.  After all, you have to imagine generations of local government means all of these planets have different assumptions about their rights and customs, and now here comes the Stormtroopers attempting to institute <em>one</em> law and <em>one</em> custom.  That creates a separate but symbiotic <em>popular</em> movement against the empire, which the princes are able to co-opt into their rebel alliance, promising that a return to princely government will mean a return to the traditional liberties and customs.</p>



<p>As this is happening, the Imperial Navy is in a state of change.  During the Clone Wars, it was fighting a peer adversary using a fast-carrier doctrine aiming to win a war that was already raging.  But now there are <em>simmering</em> tensions which the Imperial Navy is supposed to tamp down.  As a result, imperial designers reach for <strong>escalation dominance</strong> in their designs, aiming to build ships which can, on their own, <em>intimidate</em> the militaries of the princes – because remember, the ‘princes’ (planetary governments of whatever form) <em>all have their own</em> <em>small navies</em> – in order to avoid a conflict.  The ISD is the end result of that design philosophy: a gun-platform powerful enough to be effectively beyond the ability of any planetary princely navy to fight effectively.</p>



<p>Those same designers are <em>also</em>, of course, dealing with a bubbling hit-and-run insurgency, which manifests as popular insurgents whose weapons and resources clearly suggest they are being funded and supplied, in secret, by some of the princes.  Those same imperial designers respond by emphasizing <strong>force protection</strong>, to try to keep the key imperial assets well-enough armored and defended so as to limit the damage of ambush and hit-and-run.  In this sense, an ISD is a gigantic MRAP (Mine-Resistant Ambush-Protected vehicle; a kind of vehicle designed for the Global War on Terror).  Sure, it’s less <em>practical</em> than the more Humvee-like <em>Venators</em>, but its size and firepower places it beyond the capability of rebel hit-and-run attacks, allowing it to deliver its troops and firepower in safety.</p>



<p>Of course, it risks exactly the same problem that MRAPs do: troops buttoned up on their force-protection-oriented vehicles may be safe (though they may not be), but they’re not <em>accomplishing the mission</em>.  But what the ISD avoids is getting weekly reports about losing a few ships here and there as these irritatingly well-funded rebels pick off this or that small force.  Instead, imperial force is concentrated in a handful of mega-platforms that are effectively beyond attack.</p>



<p>The immediate problem, though, is that building a huge navy of brand new massive Space-MRAP-Battleships is probably really expensive, with the massive cost increasing dissatisfaction among the princes and the people, fueling the discontent already simmering in frustrations about this centralizing government.  Finally in 0BBY, the Empire makes its disastrous move: deciding that the best course of action would be to intimidate the princes by beheading one of them (Alderaan) as an example to the others, while disbanding the senate and essentially abolishing princely rule.  But like Ferdinand II marching into Bohemia and the Palatinate in 1618-9, this assertion of direct imperial power ends up triggering a more general revolt of the princes (intensified, of course, by the fact that the Empire <em>loses the Death Star</em> almost immediately, meaning the threat meant to keep the princes in line while their administrations were dismantled had vanished).</p>



<p>From that point, the Empire actually unravels quite quickly: slow, grinding centralization had taken two decades from the end of the Clone Wars to the Battle of Yavin, but from the Battle of Yavin to Endor is just five years.  The problem is a classic feature of military-tributary empires: an army can intimidate many enemies, but it can only fight one, so once the state has to turn potential force into deployed violence, the intimidation value of those armies collapses in the absence of bedrock legitimacy to keep people in line without force, <a href="https://acoup.blog/2023/07/07/collections-the-status-quo-coalition/" data-type="post" data-id="19921">as every actor in the systems’ interests suddenly recalculate against hegemony and towards balancing</a>.</p>



<p>The Rebel Alliance, constructing a navy from scratch, builds one to the doctrine of the last peer-conflict, the Clone Wars, thus a fast-carrier oriented force, while the Empire, saddled with high costs is stuck with the ships it has: giant Space-MRAPs designed to intimidation and counter-insurgency.  But with the princes broadly in revolt, what the Empire increasingly has on its hands is actually a peer, conventional conflict.  The issue comes to a head at Endor, where the Emperor tries a <a href="https://en.wikipedia.org/wiki/Battle_of_Dien_Bien_Phu" data-type="link" data-id="https://en.wikipedia.org/wiki/Battle_of_Dien_Bien_Phu">Dien Bien Phu</a>-gambit with the same historical results: thinking he can lure the rebels into a conventional battle and win, he does so but finds to his dismay that the balance of conventional forces is not so lopsided as he hoped.</p>



<p>Naturally a later historian is going to be unaware of the personal elements of the story, but “the emperor, having clearly bungled the strategy and unwilling to change course – I mean, he built a <em>second</em> Death Star – is assassinated by his close associates (Darth Vader) who remain loyal <em>to the empire, just not the emperor</em> and hope to change strategy” is a pretty standard way for dynasties to end.  And what we get after Endor is a pretty standard way that gambit often plays out, with imperial forces fragmenting instead of congealing around a new strategy.  Unable to coalesce around a new strategy or a new leader, the remains of the emperor’s half-built centralized government are dismantled by the princes who then reestablish the old Republic of Princes, albeit with some more centralized components (a central military, for instance) kept.  Restoring the intermediate layer between the Galactic government and the regular people perhaps does calm popular anger as well, as local rulers are better able to handle local issues (in a <em><a href="https://en.wikipedia.org/wiki/Cuius_regio,_eius_religio" data-type="link" data-id="https://en.wikipedia.org/wiki/Cuius_regio,_eius_religio">cuius regio, eius religio</a></em> sort of way).</p>



<p>As a coda, one of the things I liked in the old Legends canon that we haven’t seen on-screen, at least, in the new Disney-canon was that the New Republic’s centralized military – something they keep from the Clone Wars experience, evidently – ended up having lots of imperial ships, including ISDs and even SSDs.  Which makes a lot of sense: having reasserted control, one of the things the princes want both for themselves and to deliver to their newly-quite-well-armed populations is lower taxes and thus less naval spending.  But less naval spending doesn’t mean that you build smaller, cheaper ships: <em><strong>it means you keep the old ships</strong></em>.  So the New Republic isn’t going to build a new, cheaper navy, but look for ways to repurpose this pile of giant Space-MRAPs they’ve inherited from the defunct empire, alongside their Ferix-Junkyard collection of ships from the war.  I’d absolutely expect, then, to see some newly blue-trimmed Star Destroyers, employed as the flagships for Republic Navy task forces, even as New Republic officers complain about how poorly suited they are for the role and New Republic designers draw up endless new plans for high-tech, highly capable fast-carrier designs that they can never get funding to build at scale.</p>



<p>And then, of course, fortunately, the story just sort of trails off, because the notion that some insurgent power in the outer rim would conjure into existence not one but <em>two</em> fleets of Star Destroyers out of nothing with no one noticing and casually overthrow this entire system <em>off-screen</em> between movies is the daft sort of thing which would only have been excusable if paired with really good character work, <a href="https://acoup.blog/2019/12/29/miscellanea-the-latest-jedi/" data-type="post" data-id="1956">if anyone had bothered to do any</a>.</p>



<figure><img loading="lazy" decoding="async" width="768" height="1024" data-attachment-id="23985" data-permalink="https://acoup.blog/2024/05/10/fireside-friday-may-10-2024/pxl_20240509_154232603/" data-orig-file="https://i0.wp.com/acoup.blog/wp-content/uploads/2024/05/PXL_20240509_154232603.jpg?fit=3024%2C4032&amp;ssl=1" data-orig-size="3024,4032" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 3a&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1715254952&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.44&quot;,&quot;iso&quot;:&quot;443&quot;,&quot;shutter_speed&quot;:&quot;0.041667&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="PXL_20240509_154232603" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/acoup.blog/wp-content/uploads/2024/05/PXL_20240509_154232603.jpg?fit=225%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/acoup.blog/wp-content/uploads/2024/05/PXL_20240509_154232603.jpg?fit=768%2C1024&amp;ssl=1" src="https://i0.wp.com/acoup.blog/wp-content/uploads/2024/05/PXL_20240509_154232603.jpg?resize=768%2C1024&amp;ssl=1" alt="" srcset="https://i0.wp.com/acoup.blog/wp-content/uploads/2024/05/PXL_20240509_154232603.jpg?resize=768%2C1024&amp;ssl=1 768w, https://i0.wp.com/acoup.blog/wp-content/uploads/2024/05/PXL_20240509_154232603.jpg?resize=225%2C300&amp;ssl=1 225w, https://i0.wp.com/acoup.blog/wp-content/uploads/2024/05/PXL_20240509_154232603.jpg?resize=1152%2C1536&amp;ssl=1 1152w, https://i0.wp.com/acoup.blog/wp-content/uploads/2024/05/PXL_20240509_154232603.jpg?resize=1536%2C2048&amp;ssl=1 1536w, https://i0.wp.com/acoup.blog/wp-content/uploads/2024/05/PXL_20240509_154232603.jpg?resize=900%2C1200&amp;ssl=1 900w, https://i0.wp.com/acoup.blog/wp-content/uploads/2024/05/PXL_20240509_154232603.jpg?resize=600%2C800&amp;ssl=1 600w, https://i0.wp.com/acoup.blog/wp-content/uploads/2024/05/PXL_20240509_154232603.jpg?resize=450%2C600&amp;ssl=1 450w, https://i0.wp.com/acoup.blog/wp-content/uploads/2024/05/PXL_20240509_154232603.jpg?resize=300%2C400&amp;ssl=1 300w, https://i0.wp.com/acoup.blog/wp-content/uploads/2024/05/PXL_20240509_154232603.jpg?resize=150%2C200&amp;ssl=1 150w, https://i0.wp.com/acoup.blog/wp-content/uploads/2024/05/PXL_20240509_154232603.jpg?resize=1200%2C1600&amp;ssl=1 1200w, https://i0.wp.com/acoup.blog/wp-content/uploads/2024/05/PXL_20240509_154232603.jpg?resize=1100%2C1467&amp;ssl=1 1100w, https://i0.wp.com/acoup.blog/wp-content/uploads/2024/05/PXL_20240509_154232603.jpg?w=2200&amp;ssl=1 2200w" sizes="(max-width: 768px) 100vw, 768px" data-recalc-dims="1"><figcaption>Of course I can’t leave you without a cat picture, so here is Ollie helping me manage my research filing system, also known as “a giant mess in at least four languages.”</figcaption></figure>



<p>On to <strong>recommendations</strong>!</p>



<p>Excavations in Pompeii turned up some <a href="https://www.bbc.com/news/science-environment-68777741" data-type="link" data-id="https://www.bbc.com/news/science-environment-68777741">remarkable new frescoes of mythological scenes</a> earlier this month, which you can see in this BBC report.  I am always struck by the focus in domestic Greek and Roman artwork on mythological scenes which are often, at least to my mind, deeply fraught; Apollo and Cassandra (where the former is about the curse the latter for her chastity) is hardly what I would want in my dining room, but the ancients seem to have preferred scenes of high emotional and moral tension, even if it was unpleasant tension.  CUNY Professor in Classics and History Liv Yarrow offers some <a href="https://livyarrow.org/2024/04/12/new-pompeii-images/" data-type="link" data-id="https://livyarrow.org/2024/04/12/new-pompeii-images/">additional thoughts on the frescoes on her blog</a>, which I’ll also recommend generally for her musings about ancient material culture objects, their mysteries and what we can understand from them.</p>



<p>Meanwhile, Cardiff University’s Flint Dibble wrote in <em>The Guardian</em> about<a href="https://www.theguardian.com/commentisfree/2024/apr/28/lost-civilisations-make-good-tv-ancient-apocalypse-but-archaeology-real-stories-hold-far-more-wonder" data-type="link" data-id="https://www.theguardian.com/commentisfree/2024/apr/28/lost-civilisations-make-good-tv-ancient-apocalypse-but-archaeology-real-stories-hold-far-more-wonder"> his experiences as an <em>actual</em> archaeology taking on pseudo-archaeological nonsense</a>.  I agree with Dibble that the <em>actual</em> past that archaeology reveals to us is more interesting and wondrous than the wild fantasies that pseudo-archaeologists project on it, in no small part because the real past can surprise and challenge us in a way that psuedo-archaeology cannot, as it is always just a distorted mirror of our own biases and assumptions.  It is, however, profoundly frustrating how major outlets, like Netflix, continue to present nonsense peddlers as if they are asking unanswered questions, rather than asking <em>extensively</em> answered questions, the answers of which they steadfastly refuse to read.</p>



<p>Over at the <em>Partial Historians</em>, I want to pick out a really neat special guest episode from about a month ago on the <a href="https://partialhistorians.com/2024/03/28/special-episode-augustus-mausoleum-with-dr-victoria-austen/" data-type="link" data-id="https://partialhistorians.com/2024/03/28/special-episode-augustus-mausoleum-with-dr-victoria-austen/">Mausoleum of Augustus</a>, with Dr. Victoria Austen.  The mausoleum is one of those monuments in Rome that gets a bit less attention from tourists, and has been undergoing preservation work (and thus not open to the public) for quite a while now.  But the conversation between Drs. Radform, Greenfield and Austen, I think, is a really useful way to think about how the mausoleum fits in with Augustus’ building program, but also his use of space generally on the Campus Martius (the area of Rome it was in), as well as discussing the way that monuments like that get reused, repurposed and re-imagined by subsequent generations.</p>



<p>Finally, on a gaming note, I just wanted to point out game-analysis YouTuber Rosencreutz has <a href="https://youtu.be/LkCWeYsGA8g?si=ts7TcTeoAFunE7g-" data-type="link" data-id="https://youtu.be/LkCWeYsGA8g?si=ts7TcTeoAFunE7g-">a long video-essay putting the cult-classic <em>Vampire the Masquerade: Bloodlines</em> in the context of the broader genre of ‘vampire games’ </a>that I found quite interesting.  Rosencreutz videos are an interesting sort because they tend to be ruminations on a theme rather than focused deep-dives of a single game (the more common format), but they are often insightful.  I’ll also shout out his take a few months ago on “Valkyria Chronicles, Persecution, and Atrocity” for making an argument I’ve thought for some time: that it is strange and also quite interesting that one of the more <a href="https://youtu.be/Xo0uoG7FgxM?si=UEIg0_BjsV0YMjSh" data-type="link" data-id="https://youtu.be/Xo0uoG7FgxM?si=UEIg0_BjsV0YMjSh">serious takes on the holocaust in gaming is to be found in an alternate-universe anime-WWII tactics game</a>.  His channel is well worth if you are interested in thoughtful analysis of the themes and ideas in video games.</p>



<p>For this week’s <strong>book recommendation</strong>, I want to recommend J. Lyall, <em><a href="https://amzn.to/4dCRxwE" data-type="link" data-id="https://amzn.to/4dCRxwE">Divided Armies: Inequality &amp; Battlefield Performance in Modern War</a></em> (2020), a book I am legitimately surprised I have not already recommended and which is well on its way to becoming one of those modern classics of military history scholarship.  The central argument of the book is actually quite easy to state and fairly intuitive: armies with a high degree of inequality – specifically inequality of membership in the political community – suffer recognizable pathologies that cause them to perform more poorly than they might otherwise have done on the battlefield.  Alert readers will pick up from our series on Hellenistic and Roman armies that I have been noodling around my own version of this argument for those ancient armies (indeed, since before this book was published; you can see the foundations of my ideas on this back in my 2018 dissertation), so Lyall’s book came like a bolt of deliverance: here was a sustained, focused study of the modern instantiation of a phenomenon I thought I could detect in ancient armies.</p>



<p>Of course it is easy to make the observation that it <em>seems</em> like high levels of inequality negatively impact combat performance, but it is another thing to <em>prove</em> it.  Lyall comes at this problem with a political science methodology, which is to say that the foundation of the book is a quantitative approach which seeks to measure – in numbers – inequality (a ‘military inequality coefficient’) and battlefield performance (a ‘battlefield performance index’) and then compare the two.  These sorts of quantitative approaches almost invariably lead historians to cry foul and I will admit I have some <em>concerns</em> about the quite subjective foundations of these apparently objective, quantitative coefficients and indexes.   If that was all there was, I’d be concerned.  But that isn’t all there is.  Indeed, Lyall spends relatively few of his pages on the quantitative aspects of the study and instead buttresses the validity of his figures with a series of detailed, well-developed case studies running from 1800 to 1942.  That said, I also think Lyall’s definition of inequality is actually a really good one, focusing in not on economic inequality or even political representation but on inequality of membership in a political community: who is considered a full member of the polity, who <em>belongs</em> even in polities where belonging doesn’t bring a certain economic standard of living or set of political rights.  As Lyall, I think, demonstrates well, when it comes to military effectiveness, this is the question that matters.</p>



<p>Lyall makes a strong effort (noted in a forward) to try to make the book approachable and consequently confined much of the technical matter to appendices available online.  But I think for the reader looking for the <em>general</em> insight of the negative impact of inequality within armies (rather than the particular, quantitative relationship), the case studies carry the necessary weight.  These are delivered in plain language and with enough context for the reader to follow, and with a historian’s granularity in following the course of specific key moments.  The result is a book that, as long as one kind of skims the quantitative sections (or, as one of my mentors once quipped, of a different political science work’s quantitative chapter, “don’t read it, but don’t skip it”), is very readable and even quite engaging.  More to the point, its a very valuable working, taking something I think many of us kind of knew in a general sense (‘inequality damages army performance’) and providing a focused, in-depth study of the phenomenon in both particular cases and in general that puts substance behind that general sense.</p>
<ol><li><span id="easy-footnote-bottom-1-23926"></span>As an aside, one of the silliest things in the sequel trilogy lore was bringing back not just <em>a</em> CR90, but insisting that the Resistance’s CR90 was a <a href="https://starwars.fandom.com/wiki/Tantive_IV#Return_and_destruction." data-type="link" data-id="https://starwars.fandom.com/wiki/Tantive_IV#Return_and_destruction.">recovered Tantive IV</a>.  The ‘Legends’ canon has Vader do the obvious thing to complete the ruse of sending a distress signal and then reporting the ship destroyed in an accident, which was, of course, <strong>to destroy the ship and kill the crew</strong>, thereby leaving no evidence behind, a thing <strong>Darth Vader</strong> is obviously ruthless enough to do.<a href="#easy-footnote-1-23926"></a></li><li><span id="easy-footnote-bottom-2-23926"></span>As I understand it in technical terms, a ‘prince’ of the HRE was a direct vassal of the emperor; many imperial states were ‘princes’ – including some archbishoprics – but not all were.  However, I find when explaining this to folks, the idea of a ‘government of princes’ makes a lot more sense than ‘a government of states.’<a href="#easy-footnote-2-23926"></a></li></ol>	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[MacRelix – Unix-like features for classic Mac OS (109 pts)]]></title>
            <link>https://www.macrelix.org/</link>
            <guid>40338443</guid>
            <pubDate>Sun, 12 May 2024 23:47:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.macrelix.org/">https://www.macrelix.org/</a>, See on <a href="https://news.ycombinator.com/item?id=40338443">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
			<h2>MacRelix</h2>
			
			<hr>
			

<p><strong>MacRelix</strong> is a Unix-like environment that runs in classic Mac OS.</p>

<p>MacRelix natively supports classic 68K and PPC Mac OS,
as well as Mac OS X on PPC via Carbon.</p>



<div>
<p><img src="https://www.macrelix.org/screenshots/macrelix-7.1-threadmanager.png" alt="MacRelix displays a text console window with system info and a command shell prompt." title=""></p><p><strong>MacRelix</strong> running in System 7.1 in Mini vMac.</p>
</div>

<p>To get started, download the <a href="https://www.macrelix.org/pub/MacRelix-installer.mbin">MacRelix installer</a>.
It requires a classic Mac OS environment with Open Transport (and an upstream Internet connection).</p>

<p>See some more <a href="https://www.macrelix.org/screenshots/">screenshots</a>.</p>

<p>Source code: <a href="https://github.com/jjuran/metamage_1"><code>https://github.com/jjuran/metamage_1</code></a>
(Look in <code>lamp/Genie</code> and <code>relix</code>.)</p>

<p>Questions?  Comments?  <a href="https://www.metamage.com/contact.html">Contact</a> me.</p>

		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I made an open-source Loom alternative (264 pts)]]></title>
            <link>https://Cap.so</link>
            <guid>40338275</guid>
            <pubDate>Sun, 12 May 2024 23:09:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://Cap.so">https://Cap.so</a>, See on <a href="https://news.ycombinator.com/item?id=40338275">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 719 269"><path fill="#0A486B" d="M474.954 156.466c-3.122 16.278-10.217 29.23-21.286 38.856-10.927 9.484-25.118 14.226-42.572 14.226-14.333 0-26.892-3.397-37.677-10.192-10.643-6.936-18.873-16.349-24.692-28.24-5.818-11.89-8.727-25.267-8.727-40.13 0-14.863 2.838-28.31 8.514-40.342 5.819-12.032 14.12-21.445 24.905-28.24C384.204 55.468 396.763 52 411.096 52c16.603 0 30.368 4.53 41.295 13.589 10.927 9.059 18.164 21.304 21.712 36.733l-27.885 1.486c-2.129-8.776-6.244-15.641-12.346-20.596-6.102-5.096-13.765-7.644-22.989-7.644-9.65 0-17.739 2.407-24.266 7.22-6.386 4.812-11.14 11.465-14.262 19.959-3.122 8.351-4.683 17.764-4.683 28.239 0 10.475 1.561 19.818 4.683 28.028 3.122 8.21 7.876 14.792 14.262 19.746 6.527 4.813 14.616 7.219 24.266 7.219 9.65 0 17.526-2.76 23.628-8.28 6.243-5.662 10.359-13.236 12.346-22.72l28.097 1.487zM486.826 127.801c2.271-11.607 7.734-20.596 16.391-26.965 8.656-6.512 19.796-9.768 33.419-9.768 16.177 0 28.452 4.106 36.825 12.316 8.372 8.21 12.559 20.171 12.559 35.883v39.281c0 2.973.567 5.096 1.703 6.37 1.277 1.132 3.051 1.698 5.321 1.698h4.257v19.535l-6.598.212h-.852c-3.831.142-7.734-.142-11.707-.849-3.832-.708-7.237-2.336-10.217-4.884-2.981-2.548-4.683-6.441-5.109-11.678-2.838 5.804-7.45 10.546-13.836 14.226-6.386 3.68-14.191 5.521-23.415 5.521-11.636 0-21.357-2.902-29.162-8.706-7.663-5.945-11.494-13.73-11.494-23.356 0-7.078 1.631-12.811 4.895-17.199 3.406-4.388 8.089-7.856 14.049-10.404 6.102-2.548 14.049-4.742 23.841-6.582l31.716-6.37c-.142-8.635-2.058-15.004-5.747-19.109-3.69-4.247-9.366-6.37-17.029-6.37-5.96 0-10.927 1.628-14.9 4.883-3.832 3.114-6.457 7.715-7.876 13.802l-27.034-1.487zm25.331 47.987c0 4.105 1.703 7.502 5.108 10.191 3.548 2.548 8.586 3.822 15.114 3.822 5.25 0 9.933-1.274 14.048-3.822 4.258-2.547 7.522-6.369 9.792-11.465 2.413-5.238 3.619-11.537 3.619-18.898v-1.061l-21.712 3.822-3.832.637c-5.25.991-9.366 1.981-12.346 2.972-2.838.991-5.179 2.619-7.024 4.884-1.845 2.123-2.767 5.096-2.767 8.918zM611.079 93.616h24.905l.851 23.569-2.128-2.76c2.838-7.503 7.308-13.236 13.41-17.199 6.244-4.105 13.765-6.158 22.563-6.158 10.502 0 19.371 2.62 26.608 7.857 7.237 5.237 12.63 12.315 16.178 21.233 3.689 8.776 5.534 18.684 5.534 29.726 0 11.041-1.845 21.02-5.534 29.938-3.548 8.776-8.941 15.783-16.178 21.02-7.237 5.238-16.106 7.857-26.608 7.857-5.818 0-11.139-.92-15.964-2.761-4.683-1.84-8.728-4.529-12.133-8.068-3.264-3.539-5.818-7.927-7.663-13.165l2.554-2.123V238h-26.395V93.616zm24.266 56.268c0 6.794.994 13.022 2.98 18.684 2.129 5.521 5.322 9.98 9.579 13.377 4.257 3.397 9.437 5.096 15.539 5.096 9.224 0 16.178-3.539 20.861-10.616 4.824-7.078 7.237-15.925 7.237-26.541 0-10.475-2.413-19.322-7.237-26.542-4.683-7.219-11.637-10.828-20.861-10.828-6.102 0-11.282 1.769-15.539 5.308-4.257 3.397-7.45 7.927-9.579 13.589-1.986 5.521-2.98 11.678-2.98 18.473z"></path><path fill="url(#paint0_linear_0_1)" d="M218.623 0H50C22.386 0 0 22.386 0 50v168.623c0 27.614 22.386 50 50 50h168.623c27.614 0 50-22.386 50-50V50c0-27.614-22.386-50-50-50z"></path><path fill="url(#paint1_radial_0_1)" d="M134.646 240.418c58.415 0 105.77-47.355 105.77-105.77s-47.355-105.77-105.77-105.77-105.77 47.355-105.77 105.77 47.355 105.77 105.77 105.77z"></path><path fill="url(#paint2_linear_0_1)" d="M134.983 224.972c49.699 0 89.988-40.289 89.988-89.988 0-49.7-40.289-89.989-89.988-89.989-49.7 0-89.989 40.29-89.989 89.989 0 49.699 40.29 89.988 89.989 89.988z"></path><path fill="url(#paint3_radial_0_1)" d="M134.983 202.81c37.46 0 67.828-30.368 67.828-67.828 0-37.46-30.368-67.827-67.828-67.827-37.46 0-67.827 30.367-67.827 67.827 0 37.46 30.367 67.828 67.827 67.828z"></path><defs><linearGradient id="paint0_linear_0_1" x1="134.311" x2="134.311" y1="0" y2="268.623" gradientUnits="userSpaceOnUse"><stop stop-color="#A8DBF8"></stop><stop offset="1" stop-color="#BCCBFF"></stop></linearGradient><radialGradient id="paint1_radial_0_1" cx="0" cy="0" r="1" gradientTransform="rotate(107.38 31.314 98.475) scale(149.225)" gradientUnits="userSpaceOnUse"><stop offset="0.063" stop-color="#84D3FF"></stop><stop offset="0.411" stop-color="#17ABFE"></stop><stop offset="0.906" stop-color="#0770D1"></stop></radialGradient><linearGradient id="paint2_linear_0_1" x1="134.983" x2="134.983" y1="44.995" y2="224.972" gradientUnits="userSpaceOnUse"><stop stop-color="#BBE8FF"></stop><stop offset="1" stop-color="#018FEF"></stop></linearGradient><radialGradient id="paint3_radial_0_1" cx="0" cy="0" r="1" gradientTransform="rotate(98.584 14.543 129.964) scale(68.5955)" gradientUnits="userSpaceOnUse"><stop stop-color="#7EC3FF"></stop><stop offset="1" stop-color="#EAF5FF"></stop></radialGradient></defs></svg><p><span>Beta v<!-- -->0.2.3</span></p></div><p>Cap is the open source alternative to Loom. Lightweight, powerful, and stunning. Record and share in seconds.</p><p>© Cap Software, Inc. <!-- -->2024<!-- -->.</p><div><p><a href="https://cap.so/terms">Terms of Service</a><a href="https://cap.so/privacy">Privacy Policy</a></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Did GitHub Copilot increase my productivity? (152 pts)]]></title>
            <link>https://trace.yshui.dev/2024-05-copilot.html#did-github-copilot-really-increase-my-productivity</link>
            <guid>40338241</guid>
            <pubDate>Sun, 12 May 2024 23:02:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://trace.yshui.dev/2024-05-copilot.html#did-github-copilot-really-increase-my-productivity">https://trace.yshui.dev/2024-05-copilot.html#did-github-copilot-really-increase-my-productivity</a>, See on <a href="https://news.ycombinator.com/item?id=40338241">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page-wrapper">

            <div id="content" class="page">
                    <main>
                        <h2 id="did-github-copilot-really-increase-my-productivity"><a href="#did-github-copilot-really-increase-my-productivity">Did GitHub Copilot really increase my productivity?</a></h2>
<p>I had free access to GitHub Copilot for about a year, I used it, got used to it, and slowly started to take it for granted, until one day it was taken away. I had to re-adapt to a life without Copilot, but it also gave me a chance to look back at how I used Copilot, and reflect - had Copilot actually been helpful to me?</p>
<p>Copilot definitely feels a little bit magical when it works. It's like it plucked code straight from my brain and put it on the screen for me to accept. Without it, I find myself getting grumpy a lot more often when I need to write boilerplate code - "Ugh, Copilot would have done it for me!", and now I have to type it all out myself. That being said, the answer to my question above is a very definite "no, I am more productive without it". Let me explain.</p>
<p><strong>Disclaimer!</strong> This article only talks about my own personal experiences, as you will be able to see, the kind of code I ask Copilot to write is probably a little bit atypical. Still, if you are contemplating if you should pay for Copilot, I hope this article can serve as a data point. Also, I want to acknowledge that generative AI is a hot-potato topic right now - Is it morally good? Is it infringing copyright? Is it fair that companies train their model on open source code then benefit from it? Which are all very very important problems. However please allow me to put all that aside for this article, and talk about productivity only.</p>
<p>OK, let me give you some background first. For reasons you can probably guess, I do not use Copilot for my day job. I use it for my own projects only, and nowadays most of my free time is spent on a singular project - <a href="https://github.com/yshui/picom">picom</a>, a X11 compositor, which I am a maintainer of. I am not sure how many people reading this will know what a "compositor" is. It really is a dying breed after all, given the fact X11 is pretty much at its end-of-life, and everyone is slowly but surely moving to wayland. Yes, each of the major desktop environments comes with its own compositor, but if you want something that is not attached to any DE, picom is pretty much the only option left. Which is to say, it is a somewhat "one of a kind" project.</p>
<p>Of course, as is the case with any software projects, you will be able to find many commonly seen components in picom: a logging system, string manipulation functions, sorting, etc. But how they all fit together in picom is pretty unique. As a consequence, large scale reasoning of the codebase with Copilot is out of the window. Since it has not seen a project like this during training, it's going to have a really hard time understanding what it's doing. Which means my usage of Copilot is mostly limited to writing boilerplates, repetitive code, etc. To give a concrete example, say you need to <a href="https://github.com/yshui/picom/blob/311225be4d9187cbadf7388af87946d9fa62a924/src/c2.c#L1044">parse an escaped character</a>:</p>
<pre><code>if (pattern[offset] == '\\') {
	switch (pattern[offset + 1]) {
	case 't': *(output++) = '\t'; break;
	// ????
	}
}
</code></pre>
<p>If you put your cursor at the position indicated by <code>????</code>, you can pretty reliably expect Copilot to write the rest of the code for you. Other examples include <a href="https://github.com/yshui/picom/blob/311225be4d9187cbadf7388af87946d9fa62a924/src/c2.c#L238">mapping enums to strings</a>, <a href="https://github.com/yshui/picom/blob/311225be4d9187cbadf7388af87946d9fa62a924/src/dbus.c#L1421">write glue functions that have a common pattern</a>, etc. In other words, the most simple and boring stuff. Which is very good. See, I am someone who wants programming to be fun, and writing these boring, repetitive code is the least fun part of programming for me. I am more than delighted to have someone (or rather, something) take it away from me.</p>
<p>So, what is wrong then? Why did I say I am more productive without Copilot? Well, that's because Copilot has two glaring problems:</p>
<h3 id="1-copilot-is-unpredictable"><a href="#1-copilot-is-unpredictable"><strong>1. Copilot is unpredictable</strong></a></h3>
<p>Copilot can be really really helpful when it gets things right, however, it's really difficult to predict what it will get right, and what it won't. After a year of working with Copilot, I would say I am better at that than when I first started using it, but I have yet to fully grasp all the intricacies. It is easy to fall into the trap of anthropomorphising Copilot, and trying to gauge its ability like you would a human. For instance, you might think, "Hmm, it was able to write that function based on my comments, so it must be able to write this too". But you are more than likely to be proven wrong by the chunk of gibberish Copilot throws at you. This is because, Artificial Intelligence is very much unlike Human Intelligence. The intuition you've developed through a lifetime's interaction with other humans, is not going to work with an AI. Which means, short of letting Copilot actually try, there is oftentimes no surefire way to know whether it's going to work or not. And this problem is compounded by the other big problem of Copilot:</p>
<h3 id="2-copilot-is-slooooow"><a href="#2-copilot-is-slooooow"><strong>2. Copilot is <em>slooooow</em></strong></a></h3>
<p><code>clangd</code>, my C language server of choice, is very fast. It's faster than I can type, which means practically speaking, its suggestions are instant. Even when the suggestions are unhelpful, it costs me nothing. I don't have to pause, or wait, so my flow is uninterrupted. Compared to that, Copilot is much <em>much</em> slower. I would wait at least 2~3 seconds to get <em>any</em> suggestion from Copilot. If Copilot decided, for whatever reason, to write a large chunk of code, it would take a lot longer. And in many instances I would wait all those seconds only to see Copilot spit out unusable code. And I would have to decide if I need to refine the instructions in comments and try again; or partially accept the suggestion and do the rest myself. Even though this doesn't happen <em>that</em> often, (after you have gotten to know Copilot a bit better), much time is wasted in the back-and-forth.</p>
<hr>
<p>So yeah, that's pretty much all I have to say. At least at this very moment, I do not think Copilot will improve my productivity, so I definitely wouldn't be paying for it. If GitHub's plan was to give me a year's free access of Copilot to get me addicted, then their plot has conclusively failed. But that being said, if Copilot is a little bit smarter, or several times faster than it currently is, maybe the scale will tip the other way.</p>
<p>Hmm, should I be scared?</p>

                    </main>

                    <nav aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="https://trace.yshui.dev/introduction.html" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i></i>
                            </a>


                        
                    </nav>
                </div>

            <nav aria-label="Page navigation">
                    <a rel="prev" href="https://trace.yshui.dev/introduction.html" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i></i>
                    </a>

            </nav>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GPUs Go Brrr (737 pts)]]></title>
            <link>https://hazyresearch.stanford.edu/blog/2024-05-12-tk</link>
            <guid>40337936</guid>
            <pubDate>Sun, 12 May 2024 22:05:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hazyresearch.stanford.edu/blog/2024-05-12-tk">https://hazyresearch.stanford.edu/blog/2024-05-12-tk</a>, See on <a href="https://news.ycombinator.com/item?id=40337936">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>AI uses an <a href="https://www.semianalysis.com/p/gpt-4-architecture-infrastructure">awful</a> <a href="https://www.instagram.com/p/C2QARHJR1sZ">lot</a> <a href="https://www.semianalysis.com/p/google-gemini-eats-the-world-gemini">of</a> <a href="https://arxiv.org/pdf/2202.05924">compute</a>.</p>
<p>In the last few years we’ve focused a great deal of our work on making AI use less compute (e.g. <a href="https://www.together.ai/blog/based">Based</a>, <a href="https://hazyresearch.stanford.edu/blog/2023-12-11-truly-subquadratic">Monarch Mixer</a>, <a href="https://hazyresearch.stanford.edu/blog/2023-01-20-h3">H3</a>, <a href="https://hazyresearch.stanford.edu/blog/2023-06-08-hyena-safari">Hyena</a>, <a href="https://hazyresearch.stanford.edu/blog/2022-06-11-simplifying-s4">S4</a>, among others) and run more efficiently on the compute that we have (e.g. <a href="https://hazyresearch.stanford.edu/blog/2023-01-12-flashattention-long-sequences">FlashAttention</a>, <a href="https://hazyresearch.stanford.edu/blog/2023-07-17-flash2">FlashAttention-2</a>, <a href="https://hazyresearch.stanford.edu/blog/2023-11-13-flashfftconv">FlashFFTConv</a>). Lately, reflecting on these questions has prompted us to take a step back, and ask two questions:</p>
<ul>
<li>What does the hardware actually want?</li>
<li>And how can we give that to it?</li>
</ul>
<p>This post is a mixture of practice and philosophy. On the practical side, we’re going to talk about what we’ve learned about making GPUs go brr -- and release an embedded DSL, <a href="https://github.com/HazyResearch/ThunderKittens">ThunderKittens</a>, that we’ve built to help us write some particularly speedy kernels (which we are also <a href="https://github.com/HazyResearch/ThunderKittens/tree/main/examples">releasing</a>). On the philosophical side, we’ll briefly talk about how what we’ve learned has changed the way we think about AI compute.</p>
<h2>What's in an H100?</h2>
<p>For this post, we’re going to focus on the NVIDIA H100 for two reasons. First, it represents an awful lot of new compute going online. Second, we think the trends it implies are going to continue in future generations, and probably from other manufacturers, too. But bear in mind (and we will repeat in case you forget) that most of this post applies in some form to other GPUs, too.</p>
<figure><img src="https://hazyresearch.stanford.edu/static/posts/2024-05-12-tk/brr.png"><figcaption><p>Figure 1: brr</p></figcaption></figure>
<p>Advance apologies for restating the data sheet, but the details of the hardware are important for the discussion to come. An H100 SXM GPU contains, for our purposes:</p>
<ul>
<li>80 GB of HBM3 with 3 TB/s of bandwidth. (A bit less bandwidth in practice.)</li>
<li>50 MB of L2 cache with 12 TB/s of bandwidth, split across the GPU into two 25MB sections connected by a crossbar. (The crossbar sucks.)</li>
<li>132 streaming multiprocessors (SM’s), where each has:<!-- -->
<ul>
<li>up to 227 KB of shared memory within a 256 KB L1 cache. (Together, these have about 33 TB/s of bandwidth.)</li>
<li>a tensor memory accelerator (TMA) -- a new chunk of hardware in Hopper that can do asynchronous address generation and fetch memory. It also does other things like facilitate the on-chip memory network (distributed shared memory) but we’re not going to focus on this much, today.</li>
<li>4 quadrants, where each quadrant has:<!-- -->
<ul>
<li>A warp scheduler</li>
<li>512 vector registers (each containing 32 4-byte words)</li>
<li>A tensor core for matrix multiplies</li>
<li>A bunch of built-in instructions like sums, multiplies, that operate in parallel on these vector registers.</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>There’s a lot of other stuff, too (memory controllers, instruction caches, etc) but we don’t care about any of that right now.</p>
<p>All of the compute happens in the SM’s. <em>Most</em> of it happens in the registers.</p>
<p><em>Great, how do I make it go brr?</em></p>
<p>Keep the tensor core fed. That’s it.</p>
<p><em>Wait, really?</em></p>
<p>Yes. That’s the game.</p>
<p>An H100 GPU has 989 TFLOPs of half-precision matrix multiply compute, and ~60 TFLOPs of “everything else”. So, every cycle the tensor core is in use, you’re getting at least 94% utilization of the hardware. And every cycle the tensor core is not in use, you’re getting no more than 6% utilization of the hardware. Put another way:</p>
<p>% utilization H100 = % tensor cores active cycles +/- 6%.</p>
<p>Now it turns out that keeping the tensor core fed is easier said than done. We’ve discovered a number of quirks to the hardware that are important to keeping the matrix multiplies rolling. Much of this also applies to non-H100 GPUs, but the H100 is particularly tricky to keep fed so we focus on it here. (The RTX 4090, by comparison, is very easy to work with as illustrated in figure 2.)</p>
<ul>
<li>WGMMA instructions are necessary but also really irritating to use.</li>
<li>Shared memory is not actually that fast and also requires great care.</li>
<li>Address generation is expensive.</li>
<li>Occupancy remains helpful, and registers are generally the key resource.</li>
</ul>
<figure><img src="https://hazyresearch.stanford.edu/static/posts/2024-05-12-tk/spirits.png"><figcaption><p>Figure 2: NVIDIA GPUs (H100 and 4090) and their spirit animals (canadian goose and golden retriever puppy).</p></figcaption></figure>
<p>Let’s go through each of these in order.</p>
<h3>WGMMA Instructions</h3>
<p>The H100 has a new set of instructions called “warp group matrix multiply accumulate” (<code>wgmma.mma_async</code> in PTX, or <code>HGMMA</code>/<code>IGMMA</code>/<code>QGMMA</code>/<code>BGMMA</code> in SASS). To understand what makes them special, we need to look briefly at how you used to have to use tensor cores. The tensor core instructions available on previous GPUs were <code>wmma.mma.sync</code> and <code>mma.sync</code> instructions. With these instructions a warp of 32 threads on a single quadrant of an SM would synchronously feed their chunk of the data into the tensor core and await the result. Only then could they move on.</p>
<p>Not so with <code>wgmma.mma_async</code> instructions. Here, 128 consecutive threads -- split across all quadrants of the SM -- collaboratively synchronize, and asynchronously launch a matrix multiply directly from shared memory (and optionally also registers.) These warps can then go do other things with their registers while the matrix multiply happens, and await the result whenever they want.</p>
<p>In our microbenchmarks, we found that these instructions are necessary to extract the full compute of the H100. Without them, the GPU seems to top out around 63% of its peak utilization; we suspect this is because the tensor cores want a deep hardware pipeline to keep them fed, even from local resources.</p>
<p>Unfortunately, the memory layouts for these instructions <a href="https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#asynchronous-warpgroup-level-matrix-register-fragment-wgmma-64n16">are</a> <a href="https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#asynchronous-warpgroup-level-matrix-shared-memory-layout">quite</a> <a href="https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#asynchronous-warpgroup-level-matrix-shared-memory-layout-swizzling-modes">complicated</a>. The unswizzled shared memory layouts suffer from very poor coalescing, and so they require substantial additional bandwidth from L2. The swizzled memory layouts are flat-out incorrectly documented, which took considerable time for us to figure out. They’re also brittle, in that they appear to only work for specific matrix shapes and do not play well with other parts of the wgmma.mma_async instructions. For example, the hardware can transpose sub-matrices on its way to the tensor cores -- but only if the layout is not swizzled.</p>
<figure><img src="https://hazyresearch.stanford.edu/static/posts/2024-05-12-tk/lies.png"><figcaption><p>Figure 3: NVIDIA’s <span><em>lies</em></span>. This is an extraordinarily misleading representation of the actual 128b swizzled wgmma layout. This diagram cost us three weeks of life that we will not get back, hence the public shaming.</p></figcaption></figure>
<p>We’ve also found that unswizzled wgmma layouts have both poor memory coalescing as well as bank conflicts. On kernels such as flash attention, TMA and the L2 cache are both fast enough so as to hide these problems reasonably well. But to make the full use of the hardware, memory request must be coalesced and bank conflicts avoided, and then controlling layouts very carefully becomes critical.</p>
<p>Despite these pains, these instructions really are necessary to make full use of the H100. Without them, you’ve already lost 37% of the potential performance of the GPU!</p>
<h3>Shared memory</h3>
<p>Shared memory appears to have a single-access latency of around <a href="https://chipsandcheese.com/2023/07/02/nvidias-h100-funny-l2-and-tons-of-bandwidth/">30 cycles</a> (this matches our observations, too). That doesn’t sound like much, but in that time the SM’s tensor cores could have done almost two full 32x32 square matrix multiplies.</p>
<p>In previous work (like Flash Attention), we’ve focused more on the HBM-SRAM bottleneck. And indeed: this really used to be the bottleneck! But as HBM has gotten faster and the tensor cores continue to grow out of proportion with the rest of the chip, even relatively small latencies like those from shared memory have also become important to either remove or hide.</p>
<p>Shared memory can be tricky to work with because it is “banked” into 32 separate stores of memory. If one is not careful, this can lead to something called “bank conflicts”, where the same memory bank is being asked to simultaneously provide multiple different pieces of memory. This leads to requests being serialized, and in our experience this can disproportionately slow down a kernel -- and the register layouts required by wgmma and mma instructions would naively suffer from these bank conflicts. The solution is to rearrange shared memory with various “swizzling” patterns so as to avoid these conflicts, but it is an important detail to get right.</p>
<p>More generally, we have found it very valuable to avoid movement between registers and shared memory when possible, and otherwise to use the built-in hardware (wgmma and TMA instructions) to do data movement asynchronously when possible. Synchronous movement using the actual warps is a worst-case fallback with the greatest generality.</p>
<h3>Address Generation</h3>
<p>One interesting quirk of the H100 is that the tensor cores and memory are both fast enough that merely producing the memory addresses to fetch takes a substantial fraction of the resources of the chip. (This is even more the case when complicated interleaved or swizzling patterns are added in.)</p>
<p>NVIDIA appears to understand this, as they have bestowed on us the Tensor Memory Accelerator (or TMA, as it likes to be called). TMA allows you to specify a multi-dimensional tensor layout in global and shared memory, tell it to asynchronously fetch a subtile of that tensor, and trip a barrier when it’s done. This saves all of the address generation costs, and additionally makes it much easier to construct pipelines.</p>
<p>We have found TMA to be, like wgmma.mma_async, completely indispensable in achieving the full potential of the H100. (Probably moreso than wgmma, in our experience.) It saves register resources and instruction dispatches, and also has useful features such as the ability to perform reductions onto global memory asynchronously, too -- this is particularly useful in complex backwards kernels. As with wgmma, the main quirk of it is that its swizzling modes are a bit difficult to decipher without some reverse engineering, but we had substantially less pain on this point.</p>
<h3>Occupancy</h3>
<p>For those newer to CUDA, occupancy refers to the number of co-scheduled threads on the exact same execution hardware. Each cycle, the warp scheduler on that quadrant of the SM will try to issue an instruction to a warp of threads that are ready for an instruction. NVIDIA uses this model because it can enable the hardware to be more easily kept full. For example, while one warp of threads is waiting for a matrix multiply, another can receive an instruction to use the fast exponential hardware.</p>
<p>In some ways, the H100 is less reliant on occupancy than previous generations of the hardware. The asynchronous features of the chip mean that even a single instruction stream can keep many parts of the hardware busy -- fetching memory, running matrix multiplies, doing shared memory reductions, and still simultaneously running math on the registers.</p>
<p>But occupancy is very good at hiding both sins and sync’s. A perfectly designed pipeline might run reasonably fast even without any additional occupancy, but our observations suggest that NVIDIA really has designed their GPUs with occupancy in mind. And there are enough synchronizations -- and enough ways to make mistakes -- that finding ways to increase occupancy has, in our experience, usually yielded good returns at increasing the realized utilization of the hardware.</p>
<p>Finally, while occupancy is merely useful on the H100, we have found it to be increasingly important on the A100 and RTX 4090, respectively, likely because they rely increasingly on synchronous instruction dispatches, relative to the H100.</p>
<h2>ThunderKittens</h2>
<p>Based on the above, we asked ourselves how we might make it easier to write the kinds of kernels we care about while still extracting the full capabilities of the hardware. Motivated by a continuing proliferation of new architectures within the lab (and the fact that Flash Attention is like 1200 lines of code), we ended up designing a DSL embedded within CUDA -- at first for our own internal use.</p>
<p>But then we decided it was useful enough that, with love in our hearts, we cleaned it up and have released it for you. ThunderKittens is that embedded DSL. It is named ThunderKittens because we think kittens are cute, and also we think it is funny to make you type <code>kittens::</code> in your code.</p>
<figure><img src="https://hazyresearch.stanford.edu/static/posts/2024-05-12-tk/tk.png"><figcaption><p>Figure 4: A ThunderKitten. Look at her big eyes! Are you not be entranced!?!?</p></figcaption></figure>
<p>It is meant to be as simple as possible, and contains four templated types:</p>
<ul>
<li>Register tiles -- 2D tensors on the register file.</li>
<li>Register vectors -- 1D tensors on the register file.</li>
<li>Shared tiles -- 2D tensors in shared memory.</li>
<li>Shared vectors -- 1D tensors in shared memory.</li>
</ul>
<p>Tiles are parameterized by a height, width, and layout. Register vectors are parameterized by a length and a layout, and shared vectors just by a length. (They don’t generally suffer from bank conflicts.)</p>
<p>We also give operations to manipulate them, either at the warp level or at the level of a collaborative group of warps. Examples include:</p>
<ul>
<li>Initializers -- zero out a shared vector, for example.</li>
<li>Unary ops, like exp</li>
<li>Binary ops, like mul</li>
<li>Row / column ops, like a row_sum</li>
</ul>
<p>Since ThunderKittens is embedded within CUDA (contrasting libraries like Triton which we also love very much and rely on heavily), the abstractions fail gracefully. If it’s missing something, just extend it to do what you want!</p>
<p>To show an example of these primitives in action, consider Tri’s lovely flash attention -- a beautiful algorithm, but <a href="https://github.com/Dao-AILab/flash-attention/blob/main/csrc/flash_attn/src/flash_fwd_kernel.h">complicated</a> to implement in practice, even on top of NVIDIA’s wonderful Cutlass library.</p>
<p>Here's a simple forward flash attention kernel for an RTX 4090, written in ThunderKittens.</p>

<p>Altogether, this is about 60 lines of CUDA sitting at 75% hardware utilization -- and while it is fairly dense, most of the complexity is in the algorithm, rather than in swizzling patterns or register layouts. And what of all of the complexity of TMA, WGMMA, swizzling modes, and descriptors? Here’s a FlashAttention-2 forward pass for the H100, written with ThunderKittens.</p>

<p>So how does it do?</p>
<p>This kernel is just 100 lines, and it actually outperforms FlashAttention-2 on the H100 by about 30%. ThunderKittens takes care of wrapping up the layouts and instructions, and gives you a mini-pytorch to play with on the GPU.</p>
<figure><img src="https://hazyresearch.stanford.edu/static/posts/2024-05-12-tk/attn.png"><figcaption><p>Figure 5: FA2 (via Pytorch) versus TK for a wide range of configs on the H100 SXM.</p></figcaption></figure>
<p>We also release kernels for Based linear attention and other forthcoming architectures, too. Our Based linear attention kernel runs at 215 TFLOPs (or more than 300 TFLOPs when the recompute inherent in the algorithm is considered). And while linear attention is of course theoretically more efficient, historically, they have been dramatically less efficient on real hardware. So we feel this could open up a broad range of high-throughput applications -- more to come on this point later.</p>
<figure><img src="https://hazyresearch.stanford.edu/static/posts/2024-05-12-tk/based.png"><figcaption><p>Figure 6: Linear attention can be quite quick with TK!</p></figcaption></figure>
<p>If this seems up your alley, feel free to play with it!</p>
<h2>Tiles Seem Like a Good Idea</h2>
<p>In our view, what has made ThunderKittens work well for us is that it does not try to do everything. CUDA is indeed far more expressive than ThunderKittens. ThunderKittens is small and dumb and simple.</p>
<figure><img src="https://hazyresearch.stanford.edu/static/posts/2024-05-12-tk/theydontknow.png"><figcaption><p>Figure 7: the main message of this blog post.</p></figcaption></figure>
<p>But ThunderKittens has good abstractions -- small tiles -- that match where both AI and hardware are going. ThunderKittens doesn’t support any dimension less than 16. But in our view, this doesn’t really matter, since the hardware doesn’t particularly want to, either. And we ask: if your matrix multiply is smaller than 16x16, are you sure what you’re doing is AI?</p>
<p>From a philosophical point of view, we think a frame shift is in order. A “register” certainly shouldn’t be a 32-bit word like on the CPUs of old. And a 1024-bit wide vector register, as CUDA uses, is certainly a step in the right direction. But to us a “register” is a 16x16 tile of data. We think AI wants this -- after all this time, it’s still just matrix multiplies, reductions, and reshapes. And we think the hardware wants this, too -- small matrix multiplies are just begging for hardware support beyond just the systolic mma.</p>
<p>In fact, more broadly we believe we should really reorient our ideas of AI around what maps well onto the hardware. How big should a recurrent state be? As big can fit onto an SM. How dense should the compute be? No less so than what the hardware demands. An important future direction of this work for us is to use our learnings about the hardware to help us design the AI to match.</p>
<h2>Tiles Seem Pretty General</h2>
<p>Coming soon -- ThunderKittens on AMD hardware!</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I built an online PDF management platform using open-source software (149 pts)]]></title>
            <link>https://www.pdfequips.com/</link>
            <guid>40337933</guid>
            <pubDate>Sun, 12 May 2024 22:05:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.pdfequips.com/">https://www.pdfequips.com/</a>, See on <a href="https://news.ycombinator.com/item?id=40337933">Hacker News</a></p>
<div id="readability-page-1" class="page"><section><div><h2><bdi>All-In-One PDF Software &amp; Tools in one place</bdi></h2><p><bdi>All the PDF tools you can imagine are readily available at your disposal. Completely free and easy to use! You can merge, split, compress, convert, rotate, open and add watermarks to PDF files effortlessly with just a few clicks.</bdi></p></div><div><h2>How PDFEquips Can Simplify Your PDF Tasks</h2> <h6>PDFEquips simplifies PDF file management by offering All-In-One PDF Software tools for format conversion, flexible editing, and efficient file organization, along with enhanced security features. With its intuitive interface, comprehensive editing capabilities, and OCR technology, it simplifies tasks such as annotations and text extraction from scanned documents. Additionally, batch processing and automation features boost productivity, allowing professionals to unlock the full potential of PDF files.</h6></div><div><p><h3>The PDF solution you can rely on</h3><h5>PDFEquips is your ultimate web app for managing PDFs with ease. Enjoy all the features you need to work effectively with your digital documents, all in one place, while keeping your data safe and secure.</h5></p></div></section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mindfulness interventions for teens decrease mindfulness, study finds (110 pts)]]></title>
            <link>https://suchscience.net/mindfulness-interventions-for-teens-actually-decrease-mindfulness-new-study-finds/</link>
            <guid>40337815</guid>
            <pubDate>Sun, 12 May 2024 21:41:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://suchscience.net/mindfulness-interventions-for-teens-actually-decrease-mindfulness-new-study-finds/">https://suchscience.net/mindfulness-interventions-for-teens-actually-decrease-mindfulness-new-study-finds/</a>, See on <a href="https://news.ycombinator.com/item?id=40337815">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
			
<h4>A new preprint study suggests that school-based mindfulness programs, widely implemented in recent years, do not significantly benefit adolescents’ mental health or well-being.</h4>



<p>In the last two decades, mindfulness programs have become increasingly popular in schools across the United States and beyond. </p>



<p>Tens of thousands of students have learned mindfulness techniques like breath awareness, thought observation, and emotional monitoring as part of their regular curriculum.</p><p>The aim of these programs is to equip youth with skills to prevent mental disorders and enhance overall well-being.</p>



<p>But <a href="https://osf.io/preprints/psyarxiv/qnk2u" target="_blank" rel="noopener">a new preprint study casts doubt</a> on the effectiveness of universal school-based mindfulness interventions (uSBMI) for adolescents.</p>



<p>The study found no significant improvements across a range of mental health outcomes.</p>



<h2>Reanalysis Focuses on Adolescent Outcomes </h2>



<p>The preprint, written by researchers from the University of Pittsburgh and the University of Wisconsin-Madison, is a re-examination of data from <a href="https://pubmed.ncbi.nlm.nih.gov/35820989/" target="_blank" rel="noopener">a 2022 meta-analysis</a> conducted by Darren Dunning and colleagues.</p>



<p>The original meta-analysis synthesized results from randomized controlled trials of mindfulness interventions delivered to both children and adolescents in school settings.</p>



<p>But the current study’s authors noted a limitation in Dunning’s analysis — it did not separately examine the effects of uSBMI on adolescents.</p>



<p>This is a key distinction, as adolescence is a developmental period when the first symptoms of mental disorders often emerge.</p><p>Preventive interventions that work for younger children may be less effective for teens.</p><!-- wp:group {"style":{"border":{"radius":"9px","width":"3px"}},"gradient":"soft-grass","layout":{"type":"constrained"}} -->
<p><!-- wp:heading {"textAlign":"center"} -->
<h2>What would you like to know about?</h2>
<!-- /wp:heading -->

<!-- wp:html -->

<!-- /wp:html --></p>
<!-- /wp:group -->



<p>To address this gap, the researchers reanalyzed data from 22 trials that specifically evaluated uSBMI in adolescent populations.</p><p>The studies included a total of 16,558 participants with an average age of 14.2 years.</p>



<h2>No Significant Benefits Found Across Multiple Measures </h2>



<p>The reanalysis assessed uSBMI impacts on seven outcome domains: anxiety/stress, depression, executive functioning, mindfulness, negative behavior, social behavior, and well-being. </p>



<p>These outcomes were measured at two time points — immediately after the intervention and at the longest available follow-up (averaging 7 months).</p>



<p>Across 42 separate analyses examining different outcome categories, control group types, and time points, a remarkable 93% of results were statistically non-significant.</p><p>This means that adolescents who participated in uSBMI fared no better than their peers in control groups on almost all measures.</p>



<p>The few significant findings were inconsistent and hard to interpret.</p><p>Compared to passive controls, <strong>uSBMI actually reduced students’ self-reported mindfulness</strong>, with a small but statistically significant negative effect size (d = -0.10, p &lt; .001).</p>



<p>When measured against active controls, uSBMI did show show some improvements in anxiety/stress and well-being.</p><p>But when all control groups were combined, uSBMI did not significantly impact any outcome.</p>



<h2>Doubts Raised About Mindfulness as Universal Prevention Strategy</h2>



<p>The study’s results raise important questions about the value of uSBMI as a universal prevention approach for adolescents.</p><p>The authors note several potential explanations for the lack of effects, including inadequate “dosage” of mindfulness training, challenges in preparing teachers to deliver the programs, and difficulty implementing the interventions in school settings.</p>



<p>On a broader level, the study challenges the rationale behind uSBMI and similar skill-building programs as a way to prevent mental disorders in teens. </p>



<p>“It is reasonable to wonder,” the paper’s authors write, “whether solving these issues through future research is worth the opportunity cost of lost investment in other programs or policies that could more reliably enhance adolescents’ long-term prospects.”</p>



<h2>Time to Reconsider the Approach?</h2>



<p>As rates of adolescent mental disorders continue to climb, there is an urgent need for effective prevention and early intervention strategies.</p><p>While school-based programs are intuitively appealing, the current study underscores the importance of rigorously evaluating their real-world impacts.</p>



<p>The authors emphasize that their analysis does not necessarily mean mindfulness training has no value for adolescents.</p><p>Yet existing universal programs delivered in school settings do not appear to generate meaningful improvements based on the best available evidence.</p>



<p>Moving forward, researchers and policymakers will need to weigh the opportunity costs of uSBMI against other initiatives that may more reliably support teen mental health. </p>



<p>As the study’s authors conclude, “our reanalysis of meta-analytic data suggest that it is time to reconsider [uSBMI’s] value as a public health prevention strategy for youth.” </p>



<h2>Study Details:</h2>



<ul>
<li><strong>Title: </strong>“<a href="https://osf.io/preprints/psyarxiv/qnk2u" target="_blank" rel="noopener">Adolescents Do Not Benefit from Universal School-based Mindfulness Interventions: A Reanalysis of Dunning et al. (2022)</a>“</li>



<li><strong>Authors: </strong>Brian Galla, Aishwarya Karanam, Avital Pelakh, Simon Goldberg</li>



<li><strong>Preprint Publication Date:</strong> February 9, 2024</li>



<li><strong>Preprint DOI</strong>: <a href="https://doi.org/10.31234/osf.io/qnk2u" target="_blank" rel="noopener">https://doi.org/10.31234/osf.io/qnk2u</a></li>
</ul>
<!-- wp:shortcode -->


<!-- /wp:shortcode -->		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Alternative Implementation Problem (206 pts)]]></title>
            <link>https://pointersgonewild.com/2024/04/20/the-alternative-implementation-problem/</link>
            <guid>40337036</guid>
            <pubDate>Sun, 12 May 2024 19:49:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pointersgonewild.com/2024/04/20/the-alternative-implementation-problem/">https://pointersgonewild.com/2024/04/20/the-alternative-implementation-problem/</a>, See on <a href="https://news.ycombinator.com/item?id=40337036">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				<p><img width="250" height="250" src="https://pointersgonewild.files.wordpress.com/2024/04/screenshot-2024-04-20-at-11.54.09-am.png?w=250" alt="" decoding="async" srcset="https://pointersgonewild.files.wordpress.com/2024/04/screenshot-2024-04-20-at-11.54.09-am.png?w=250 250w, https://pointersgonewild.files.wordpress.com/2024/04/screenshot-2024-04-20-at-11.54.09-am.png?w=500 500w, https://pointersgonewild.files.wordpress.com/2024/04/screenshot-2024-04-20-at-11.54.09-am.png?w=150 150w, https://pointersgonewild.files.wordpress.com/2024/04/screenshot-2024-04-20-at-11.54.09-am.png?w=300 300w" sizes="(max-width: 250px) 100vw, 250px" data-attachment-id="5687" data-permalink="https://pointersgonewild.com/2024/04/20/the-alternative-implementation-problem/screenshot-2024-04-20-at-11-54-09-am/" data-orig-file="https://pointersgonewild.files.wordpress.com/2024/04/screenshot-2024-04-20-at-11.54.09-am.png" data-orig-size="1164,1164" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screenshot 2024-04-20 at 11.54.09 AM" data-image-description="" data-image-caption="" data-medium-file="https://pointersgonewild.files.wordpress.com/2024/04/screenshot-2024-04-20-at-11.54.09-am.png?w=300" data-large-file="https://pointersgonewild.files.wordpress.com/2024/04/screenshot-2024-04-20-at-11.54.09-am.png?w=497"></p><p>In this post, I want to talk about a dynamic that I’ve seen play itself over and over again in the software world. In fact, I would venture a guess that this kind of situation probably happens in the hardware world as well, but I’ll speak about software systems since this is where my experience lies. This discussion is going to touch a bit on human psychology, and outline a common trap so that you can hopefully avoid getting stuck in it.</p>



<p>Most of my career, both in academia and industry, has been spent trying to optimize dynamically-typed programming languages. During my master’s I worked on a simple optimizing <a href="https://www.sable.mcgill.ca/publications/papers/2010-3/mcvmcc2010.pdf">JIT for MATLAB</a>. For my PhD I worked on a <a href="https://drops.dagstuhl.de/storage/00lipics/lipics-vol056-ecoop2016/LIPIcs.ECOOP.2016.7/LIPIcs.ECOOP.2016.7.pdf">JIT for JavaScript</a>. Today I’m working on YJIT, an optimizing <a href="https://shopify.engineering/ruby-yjit-is-production-ready">JIT for Ruby</a> which has now been upstreamed into CRuby. </p>



<p>During my PhD, while working on my own JavaScript JIT, I read many papers and blog posts about JIT compilers for other dynamic languages. I read about the design of HotSpot, Self, LuaJIT, PyPy, TruffleJS, V8, SpiderMonkey, and JavaScriptCore among others. I also had the chance to interact with and meet face to face with many of the really smart people behind these projects.</p>



<p>One of the things that struck me is that the PyPy project was kind of stuck in a weird place. They had developed an advanced JIT compiler for Python which could produce <a href="https://speed.pypy.org/">great speedups</a> over CPython. By all accounts many people could benefit from these performance gains, but PyPy was seeing very little use in the “real world”. One of the challenges that they faced is that Python is a moving target. New versions of CPython come out regularly, always adding many new features, and PyPy struggles to keep up, is always several Python versions behind. If you want you Python software to be PyPy-compatible, you’re much more limited in terms of which Python features you use, and most Python programmers don’t want to have to think about that.</p>



<p>Reading about LuaJIT, I found that it was and still is highly regarded. Many people regard its creator, Mike Pall, as an incredible programmer. LuaJIT offers <a href="https://staff.fnwi.uva.nl/h.vandermeer/docs/lua/luajit/luajit_performance.html">great performance</a> gains over the default, interpreted Lua implementation, and has seen some decent adoption in the wild. However, I again saw that there are a number of Lua users who do not want to use LuaJIT because the Lua language keeps adding new features and LuaJIT is several versions behind. This is a bit strange considering that Lua is a language that is known for its minimalism. It seems like they could have made an effort to slow down the addition of new features and/or coordinate with Mike Pall, but this wasn’t done.</p>



<p>Almost 4 years ago, I joined Shopify to work on Ruby. For some reason, the space of Ruby JITs has been particularly competitive, and there had been a number of projects to build Ruby JITs. The TruffleRuby JIT boasted the most impressive performance numbers, but again, had seen limited deployments. There were some practical reasons for this, the warm up time of TruffleRuby is much longer than that of CRuby, but I also saw a similar dynamic to that of PyPy and LuaJIT, where CRuby kept adding features, and TruffleRuby contributors had to work hard to try and keep up. It didn’t really matter if TruffleRuby could be quite a bit faster, because Ruby users would always view CRuby as the canonical implementation, and anything that wasn’t fully compatible wasn’t seen as worthy of consideration.</p>



<p>Hopefully, at this point, you see where I’m going with this. What I’ve concluded, based on experience, is that positioning your project as an alternative implementation of something is a losing proposition. It doesn’t matter how smart you are. It doesn’t matter how hard you work. The problem is, when you build an alternative implementation, you’ve made yourself subject to the whims of the canonical implementation. They have control over the direction of the project, and all you can do is try to keep up. In the case of JITted implementations of traditionally interpreted languages, there’s a bit of a weird dynamic, because it’s much faster to implement new features in an interpreter. The implementers of the canonical implementation may see you as competition they are trying to outrun. You may be stuck trying to ice skate uphill.</p>



<p>Almost 4 years ago, with support from Shopify, two dedicated colleagues and I started a project to build YJIT, yet another Ruby JIT. The difference is that we made the key choice to build YJIT not as an alternative implementation, but directly inside CRuby itself. This came with a number of design tradeoffs, but critically, YJIT could be 100% compatible with every CRuby feature from the start. YJIT is now the “official” Ruby JIT, and is deployed at Shopify, Discourse and GitHub among others. If you’ve visited github.com today, or any Shopify store, you’ve interacted with YJIT. We’ve had more success than any other Ruby JIT compiler so far, and compatibility has been key in achieving this.</p>



<p>You may read this and think that the key lesson of this post follows the old adage that “if you can’t beat them, join them”. In some ways, I suppose it does. What I want to say is that if you start a project to try and position yourself as an alternative but better implementation of something, you are likely to find yourself stuck in a spot where you’re always playing catch up and living in the shadow of the canonical implementation. The canonical project keeps evolving, and you have no choice but to follow along with limited decisional power over where your own project is headed. That’s no fun. You may have better luck trying to join up with the canonical implementation instead. However, that’s only part of the answer.</p>



<p>In the Ruby space, there is also Crystal, a Ruby-like language that is statically compiled with type inference. This language is intentionally not Ruby-compatible, it has chosen to diverge from Ruby, but has still seen limited success. I think this is interesting because it gives us a broader perspective. Rubyists don’t like Crystal because it’s almost-Ruby-but-not-quite. It looks like Ruby, syntactically, but has many subtle differences and is very much incompatible in practice. This just confuses people, it breaks their expectations. Crystal probably would have had better luck if it had never marketed itself as being similar to Ruby in the first place.</p>



<p>Peter Thiel has a saying that <a href="https://www.youtube.com/watch?v=Z3D8Vo9hRyw">“competition is for losers”</a>. His main point is that you shouldn’t put yourself in a position where you’re forced to compete if you don’t have to. My advice to younger programmers would be, if you’re thinking of creating your own programming language, for example, then don’t go trying to create a subset of Python, or something superficially very close to an existing language. Do your own thing. That way, you can evolve your system at your own pace and in your own direction, without being chained by expectations that your language should have to match the performance, feature set, or library ecosystem of another implementation.</p>



<p>I’ll finish with some caveats. What I said above applies when you have a situation where there is a canonical implementation of a language or system. It doesn’t apply in a space where you have open standards. For example, if you want to implement your own JSON parser, there is a clearly defined specification that is relatively small and doesn’t evolve very fast. This is very much something you can achieve. You also have a situation where there are multiple browser-based implementations of JavaScript. This is possible in part because there is an external standard body that governs the JS specification, and the people working on the JS standard understand that JIT-compiled implementations are critical for performance and guide the evolution of the language accordingly. They are not in the game of adding many new features as fast as possible.</p>
											</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Professional Corner-Cutting (2016) (162 pts)]]></title>
            <link>https://blog.ometer.com/2016/05/04/professional-corner-cutting/</link>
            <guid>40336609</guid>
            <pubDate>Sun, 12 May 2024 18:55:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.ometer.com/2016/05/04/professional-corner-cutting/">https://blog.ometer.com/2016/05/04/professional-corner-cutting/</a>, See on <a href="https://news.ycombinator.com/item?id=40336609">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
              <p>Steve Jobs famously <a href="http://thenextweb.com/apple/2011/10/24/steve-jobs-obsession-with-the-quality-of-the-things-unseen/">cared about the unseen backs of cabinets</a>. Antique furniture built with hand tools isn’t like that at all. Cabinetmakers made each part to the tolerance that mattered.&nbsp;The invisible parts were left rough, with plane and saw marks, to save time. The visible parts, however, were cleaned up and polished. Some surfaces were made precisely straight and square, for structural reasons; while nonstructural surfaces were only straight enough to look good to the eye.</p>
<p>Think about an apprentice in an old cabinet shop. An apprentice painstakingly smoothing an invisible surface would be yelled at for wasting time. An apprentice failing to smooth a visible surface would be yelled at for producing crappy work. To become a professional, the apprentice learned to work <em>efficiently</em> but still <em>do a good job</em>. Crucially, a “good job” was defined in terms of customer concerns. <sup><a href="#fn1">[1]</a></sup></p>
<p>Cabinetmakers were focused on <em>what their customers cared about</em>. Customers wanted the furniture to look good, and they wanted it to be structurally sound. They didn’t care about invisible tool marks, and didn’t want to pay extra to have those removed.</p>
<p>Software remains a craft rather than a science, relying on the experience of the craftsperson. Like cabinetmakers, we proceed one step at a time, making judgments about what’s important and what isn’t at each step.</p>
<p><strong>A professional developer does thorough work when it matters, <em>and</em> cuts irrelevant corners that aren’t worth wasting time on.</strong> Extremely productive developers don’t have supernatural coding skills; their secret is to write only the code that matters.<strong><br>
</strong></p>
<p>How can we do a better job cutting corners? I think we can learn a lot from people building tables and dressers.</p>
<h2>1. Own the implementation decisions</h2>
<p>It is irresponsible to ask the customer (or manager, or other not-doing-the-work stakeholder) to tell you how to make technical tradeoffs. Cabinetmakers didn’t ask their customers how flat a tenon had to be and this is not the customer’s problem. The customer wants us to do it <em>properly</em> but not <em>wastefully</em>. It is our decision how to go about this, and if we get it wrong it’s our fault.</p>
<p>On software teams, there’s often a developer trying to push these decisions up to management or onto the customer, because they don’t want to “get in trouble” later. Perhaps they complain to management about “technical debt” and being “given time to work on it.” This is a sign that we aren’t owning our decisions. If the technical debt is a problem, 1) we shouldn’t have put it in there, and 2) we should include it in our estimates and address it. A cabinetmaker would not ask the customer to put “make tenons straight” on the sprint. Nobody cares. Technical debt is our problem; that’s the job.</p>
<p><strong>If you don’t own your technical decisions, you can never get them right, because nobody else knows how to make them.</strong> Insist on making them. And yes, that means getting them wrong is your fault. It may mean giving people bad news about how long things will take. It may mean you get yelled at sometimes.</p>
<h2>2. Understand the customer’s needs and preferences</h2>
<p>Because we must make tradeoffs and not push choices onto the customer, we have to understand what matters and what doesn’t. It’s easier to establish this in the world of furniture (“doesn’t break when you sit on it,” “looks nice”). In software, we have to know <a href="http://blog.ometer.com/2016/01/26/the-dangerous-ui-team/">what job our software will do</a> for the customer.</p>
<p>This is where we <em>should</em> be getting customer input (though watching what they do may be more valuable than asking them what they think), and reaching a consensus with our management team or client.</p>
<p>We should not ask customers for more precision than they can give us (a symptom of this is to badger customers or managers for detailed “requirements,” then complain endlessly about “changing requirements”). Our job involves converting vague needs into concrete software — if we’re lucky, we have the help of a skilled product designer, or guidance from a management team that’s able to be somewhat precise, but if not we have to do it ourselves. Accept the job and learn to do it.</p>
<p>It’s unprofessional to be the kind of developer who doesn’t care about user experience, doesn’t care about business context, or “just wants to be told the requirements.” <strong>It’s impossible to work efficiently or to do a good job without understanding the context.</strong></p>
<p>A professional developer can take a desired UX and work out the technical steps to get there as efficiently as possible. And they do get there; they don’t build something odd that doesn’t meet the need, or something slapdash that <a href="http://blog.ometer.com/2011/10/24/it-has-to-work/">doesn’t work</a>.</p>
<h2>3. Don’t be lazy</h2>
<p>Corner-cutting should be a deliberate decision; “this truly doesn’t matter.” It should not be because it’s 5pm and we’re going home. When we find ourselves asking “do I really have to redo this…” <a href="http://blog.lostartpress.com/2016/02/24/the-art-of-self-interrogation/">then we need to redo it</a>.</p>
<p><strong>Cutting corners should feel like you have a clear focus and you’re skipping tasks that don’t matter for that focus. Cutting corners should not feel like you’re doing poor-quality work.</strong></p>
<p>To push back on an unrealistic schedule, work to narrow the scope or weaken the requirements.</p>
<p>Let’s say you’re making some kitchen cabinets. You could make them all with hand tools, no metal connectors and no plywood. They would be gorgeous and cost about $150,000. When the customer says that’s too much time and too expensive, you could make them the usual modern way with machines, screws and plywood; which is a sound approach, though a little uglier. This is like offering to build a web app that’s not quite as slick and beautiful — something a little more off-the-shelf.</p>
<p>That’s all fine. What’s not fine: delivering either of those choices unfinished and broken. “Oh, I forgot the cabinet doors.” “Sorry these things aren’t painted!”</p>
<p>To cut scope, we should do something defined (such as leave out a feature or refinement), rather than something undefined (like skipping testing).</p>
<h2>Professionals are doing it for others</h2>
<p>All of this sounds hard, and it is. As in <a href="https://unicornfree.com/2012/why-blacksmiths-are-better-at-startups-than-you">Amy Hoy’s description of these students learning a craft</a>, at first we may fight it and focus on our own needs and emotions.</p>
<p>Professional software developers are <em>performing a service for others</em>. That’s the difference between a professional and a hobbyist or an artist. To perform a service for others, we have to know what others need, and apply our expertise to meet those needs.</p>

<p><a name="fn1">[1]</a> <em>Furniture made by machine doesn’t have the same ability to flex tolerances to save time. For the most part, with woodworking machines you get what you get; the machine doesn’t know whether your surface will be visible, or how flat it has to be. It makes one kind of surface and that’s it. Some parts of machine-made furniture aren’t as good as a handmade joint or surface could be, while other parts are far more precise than necessary. Check out this <a href="http://www.popularwoodworking.com/woodworking-blogs/editors-blog/dado-joints-by-hand">discussion of how to cut a dado joint by hand</a>, which mentions several ways to save time on the back, non-show side of the piece.</em></p>

          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Becoming an Amateur Polyglot (134 pts)]]></title>
            <link>https://www.lesswrong.com/posts/BPpeBH8brSCRvZajs/how-to-be-an-amateur-polyglot</link>
            <guid>40336607</guid>
            <pubDate>Sun, 12 May 2024 18:55:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.lesswrong.com/posts/BPpeBH8brSCRvZajs/how-to-be-an-amateur-polyglot">https://www.lesswrong.com/posts/BPpeBH8brSCRvZajs/how-to-be-an-amateur-polyglot</a>, See on <a href="https://news.ycombinator.com/item?id=40336607">Hacker News</a></p>
Couldn't get https://www.lesswrong.com/posts/BPpeBH8brSCRvZajs/how-to-be-an-amateur-polyglot: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Page Dewarping (2016) (145 pts)]]></title>
            <link>https://mzucker.github.io/2016/08/15/page-dewarping.html</link>
            <guid>40336095</guid>
            <pubDate>Sun, 12 May 2024 17:33:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mzucker.github.io/2016/08/15/page-dewarping.html">https://mzucker.github.io/2016/08/15/page-dewarping.html</a>, See on <a href="https://news.ycombinator.com/item?id=40336095">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Flattening images of curled pages, as an optimization problem.</p>

<h2 id="overview">Overview</h2>

<p>A while back, I wrote a script to create PDFs from
photos of hand-written text. It was nothing special – just
<a href="http://docs.opencv.org/3.0-last-rst/modules/imgproc/doc/miscellaneous_transformations.html#cv2.adaptiveThreshold">adaptive thresholding</a>
and combining multiple images into a PDF – but it came in handy
whenever a student emailed me their homework as a pile of JPEGs. After I
demoed the program to my fiancée, she ended up asking me to
run it from time to time on photos of archival documents for her
linguistics research.  This summer, she came back from the library
with a number of images where the text was significantly warped due to
curled pages.</p>

<p>So I decided to write a program that <em>automatically</em> turns pictures like the one on
the left below to the one on the right:</p>

<p><img src="https://mzucker.github.io/images/page_dewarp/linguistics_thesis_a_before_after.png" alt="before and after dewarp"></p>

<p>As with every project on this blog, the code is
<a href="https://github.com/mzucker/page_dewarp">up on github</a>. Also feel free
to <a href="#results">skip to the results section</a> if you want a sneak peek of some more before-and-after shots.</p>

<h2 id="background">Background</h2>

<p>I am by no means the first person to come up with a method for
document image dewarping – it’s even implemented in Dan Bloomberg’s open-source
image processing library
<a href="http://www.leptonica.com/dewarping.html">Leptonica</a> – but when it
comes to understanding a problem, there’s nothing quite like
implementing it yourself. Aside from browsing through the Leptonica
code, I also skimmed a few papers on the topic, including a
<a href="http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.99.7439">summary</a>
of the results of a dewarping contest, as well as an
<a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.552.8971">article</a>
about the contest-winning Coordinate Transform Model (CTM) method.</p>

<p>Both the Leptonica dewarping method and the CTM method share a similar
hierarchical problem decomposition:</p>

<ol>
  <li>
    <p>Split the text into lines.</p>
  </li>
  <li>
    <p>Find a warp or coordinate transformation that makes the lines
parallel and horizontal.</p>
  </li>
</ol>

<p>To me, Leptonica’s approach to the second subproblem seems a bit
ad-hoc compared to CTM’s 3D “cylinder” model. To be honest, I had a
bit of trouble deciphering the CTM paper, but I liked the idea of a
model-based approach. I decided to create my own parametric model
where the appearance of the page is determined by a number of
parameters:</p>

<ul>
  <li>
    <p>a rotation vector \(\mathbf{r}\) and a translation vector
\(\mathbf{t}\), both in \(\mathbb{R}^3\), that parameterize the 3D
orientation and position of the page</p>
  </li>
  <li>
    <p>two slopes \(\alpha\) and \(\beta\) that specify the curvature of
the page surface (see spline plots below)</p>
  </li>
  <li>
    <p>the vertical offsets \(y_1, \ldots, y_n\) of \(n\) horizontal
spans on the page</p>
  </li>
  <li>
    <p>for each span \(i \in \{ 1, \ldots, n \}\), the horizontal
offsets \(x_i^{(1)}, \ldots, x_i^{(m_i)}\) of \(m_i\) points in
the horizontal span (all at vertical offset \(y_i\))</p>
  </li>
</ul>

<p>The page’s 3D shape comes from sweeping a curve along the local
\(y\)-axis (top-to-bottom direction). Each \(x\) (left-to-right)
coordinate on the page maps to a displacement \(z\) of the page
surface. I model the horizontal cross-section of the page surface as a
cubic spline whose endpoints are fixed at zero. The shape of the
spline can be specified completely by its slopes \(\alpha\) and
\(\beta\) at the endpoints:</p>

<p><img src="https://mzucker.github.io/images/page_dewarp/cubic_splines.png" alt="cubic splines with varying slope"></p>

<p>As the plot shows, changing the slope parameters gives a variety of
“page-like” curves. Below, I’ve generated an animation that fixes the
page dimensions and all \((x, y)\) coordinates, while varying the
pose/shape parameters \(\mathbf{r}\), \(\mathbf{t}\), \(\alpha\), and
\(\beta\) – you can begin to appreciate that the parameter space
spans a useful variety of page appearances:</p>

<p><img src="https://mzucker.github.io/images/page_dewarp/page_warping.gif" alt="oooh dancing page"></p>

<p>Importantly, once the pose/shape parameters are fixed, each \((x,
y)\) coordinate on the page is projected to a determined location on
the image plane. Given this rich model, we can now frame the entire
dewarping puzzle as an optimization problem:</p>

<ul>
  <li>
    <p>identify a number of <em>keypoints</em> along horizontal text spans in the
original photograph</p>
  </li>
  <li>
    <p>starting from a naïve initial guess, find the parameters \(\mathbf{r}\),
 \(\mathbf{t}\), \(\alpha\), \(\beta\), \(y_1\), \(\ldots\),
 \(y_n\), \(x_1^{(1)}\), \(\ldots\), \(x_n^{(m_n)}\) 
 which minimize the <a href="https://en.wikipedia.org/wiki/Reprojection_error">reprojection error</a>
 of the keypoints</p>
  </li>
</ul>

<p>Here is an illustration of reprojection before and after optimization:</p>

<p><img src="https://mzucker.github.io/images/page_dewarp/linguistics_thesis_a_keypoints.png" alt="reprojection before and after optimization"></p>

<p>The red points in both image are detected keypoints on text spans, and
the blue ones are reprojections through the model.  Note that the left
image (initial guess) assumes no curvature at all, so all blue points
are collinear; whereas the right image (final optimization output) has
established the page pose/shape well enough to place almost all of the
blue points on top of each corresponding red point.</p>

<p>Once we have a good model, we can isolate the pose/shape parameters,
and invert the resulting page-to-image mapping to dewarp the entire
image. Of course, the devil is in the details.</p>

<h2 id="procedure">Procedure</h2>

<p>Here is a rough description of the steps I took.</p>

<ol>
  <li>
    <p><strong>Obtain page boundaries.</strong> It’s a good idea not to consider the
entire image, as borders beyond the page can contain lots of
garbage.  Instead of
<a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.81.1467">intelligently identifying page borders</a>,
I opted for a simpler approach, just carving out the middle hunk
of the image with fixed margins on the edges.</p>
  </li>
  <li>
    <p><strong>Detect text contours.</strong> Next, I look for regions that look
“text-like”. This is a multi-step process that involves an
initial adaptive threshold:</p>

    <p><img src="https://mzucker.github.io/images/page_dewarp/linguistics_thesis_a_debug_0.1_thresholded.png" alt="detect contours step 1"></p>

    <p>…<a href="https://en.wikipedia.org/wiki/Dilation_(morphology)">morphological dilation</a>
by a horizontal box to connect up horizontally adjacent mask pixels:</p>

    <p><img src="https://mzucker.github.io/images/page_dewarp/linguistics_thesis_a_debug_0.2_dilated.png" alt="detect contours step 2"></p>

    <p>…<a href="https://en.wikipedia.org/wiki/Erosion_(morphology)">erosion</a> by
a vertical box to eliminate single-pixel-high “blips”:</p>

    <p><img src="https://mzucker.github.io/images/page_dewarp/linguistics_thesis_a_debug_0.3_eroded.png" alt="detect contours step 3"></p>

    <p>and finally,
<a href="https://en.wikipedia.org/wiki/Connected-component_labeling">connected component analysis</a>
with a filtering step to eliminate any blobs which are too tall
(compared to their width) or too thick to be text. Each remaining
text contour is then approximated by its best-fitting line
segment using
<a href="https://en.wikipedia.org/wiki/Principal_component_analysis">PCA</a>,
as shown here:</p>

    <p><img src="https://mzucker.github.io/images/page_dewarp/linguistics_thesis_a_debug_1_contours.png" alt="detect contours step 4"></p>

    <p>Since some of the images that my fiancée supplied were of tables
full of vertical text, I also specialized my program to attempt
to detect horizontal lines or rules if not enough horizontal text
is found. Here’s an example image and detected contours:</p>

    <p><img src="https://mzucker.github.io/images/page_dewarp/linguistics_thesis_b_line_contours.png" alt="detect contours alt"></p>
  </li>
  <li>
    <p><strong>Assemble text into spans.</strong> Once the text contours have been
identified, we need to combine all of the contours corresponding
to a single horizontal span on the page. There is probably a
linear-time method for accomplishing this, but I settled on a
greedy quadratic method here (runtime doesn’t matter much here
since nearly 100% of program time is spent in optimization
anyways).</p>

    <p>Here is pseudocode illustrating the overall approach:</p>

    <div><pre><code>edges = []
     
for each contour a:
  for each other contour b:
     cost = get_edge_cost(a, b)
     if cost &lt; INFINITY:
        edges.append( (cost, a, b) )
             
sort edges by cost
            
for each edge (cost, a, b) in edges:
  if a and b are both unconnected:
    connect a and b with edge e
</code></pre></div>

    <p>Basically, we generate candidate edges for every pair of text
contours, and score them. The resulting cost is infinite if the
two contours overlap significantly along their lengths, if they
are too far apart, or if they diverge too much in
angle. Otherwise, the score is a linear combination of distance
and change in angle.</p>

    <p>Once the connections are made, the contours can be easily grouped
into spans; I also filter these to eliminate any that are too
small to be useful in determining the page model.</p>

    <p><img src="https://mzucker.github.io/images/page_dewarp/linguistics_thesis_a_debug_2_spans.png" alt="assemble spans"></p>

    <p>Above, you can see the span grouping has done a good job
amalgamating the text contours because each line of text has its
own color.</p>
  </li>
  <li>
    <p><strong>Sample spans.</strong> Because the parametric model needs discrete
keypoints, we need to generate a small number of representative
points on each span. I do this by choosing one keypoint per 20 or
so pixels of text contour:</p>

    <p><img src="https://mzucker.github.io/images/page_dewarp/linguistics_thesis_a_debug_3_span_points.png" alt="sample spans"></p>
  </li>
  <li>
    <p><strong>Create naïve parameter estimate.</strong> I use PCA to estimate the
mean orientation of all spans; the resulting principal components
are used to analytically establish the initial guess of the \(x\)
and \(y\) coordinates, along with the pose of a flat,
curvature-free page using
<a href="http://docs.opencv.org/3.0-last-rst/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html#cv2.solvePnP"><code>cv2.solvePnP</code></a>.
The reprojection of the keypoints will be accomplished by
sampling the cubic spline to obtain the \(z\)-offsets of the
object points and calling
<a href="http://docs.opencv.org/3.0-last-rst/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html#cv2.projectPoints"><code>cv2.projectPoints</code></a>.
to project into the image plane.</p>
  </li>
  <li>
    <p><strong>Optimize!</strong> To minimize the reprojection error, I use
<a href="http://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html"><code>scipy.optimize.minimize</code></a>
with the <code>'Powell'</code> solver as a black-box, derivative-free
optimizer. Here’s reprojection again, before and after optimization:</p>

    <p><img src="https://mzucker.github.io/images/page_dewarp/linguistics_thesis_a_keypoints.png" alt="reprojection before and after optimization"></p>

    <p>Nearly 100% of the program runtime is spent doing this
optimization. I haven’t really experimented much with other
solvers, or with using a specialized solver for
<a href="https://en.wikipedia.org/wiki/Non-linear_least_squares">nonlinear least squares</a>
problems (which is exactly what this is, by the way). It might be
possible to speed up the optimization a lot!</p>
  </li>
  <li>
    <p><strong>Remap image and threshold.</strong> Once the optimization completes, I
isolate the pose/shape parameters \(\mathbf{r}\), \(\mathbf{t}\),
\(\alpha\), and \(\beta\) to establish a coordinate
transformation. The actual dewarp is obtained by projecting a
dense mesh of 3D page points via
<a href="http://docs.opencv.org/3.0-last-rst/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html#cv2.projectPoints"><code>cv2.projectPoints</code></a>
and supplying the resulting image coordinates to
<a href="http://docs.opencv.org/3.0-last-rst/modules/imgproc/doc/geometric_transformations.html#cv2.remap"><code>cv2.remap</code></a>.
I get the final output with
<a href="http://docs.opencv.org/3.0-last-rst/modules/imgproc/doc/miscellaneous_transformations.html#cv2.adaptiveThreshold"><code>cv2.adaptiveThreshold</code></a>
and save it as a bi-level PNG using
<a href="http://python-pillow.org/">Pillow</a>. Again, before and after
shots:</p>

    <p><img src="https://mzucker.github.io/images/page_dewarp/linguistics_thesis_a_before_after.png" alt="before and after dewarp"></p>
  </li>
</ol>

<h2 id="results">Results</h2>

<p>I’ve included several
<a href="https://github.com/mzucker/page_dewarp/tree/master/example_input">example images</a>
in the github repository to illustrate how the program works on a
variety of inputs. Here are the images, along with the program output:</p>

<p><strong>boston_cooking_a.jpg</strong>:</p>

<p><img src="https://mzucker.github.io/images/page_dewarp/boston_cooking_a_before_after.png" alt="before and after dewarp"></p>

<p><strong>boston_cooking_b.jpg</strong>:</p>

<p><img src="https://mzucker.github.io/images/page_dewarp/boston_cooking_b_before_after.png" alt="before and after dewarp"></p>

<p><strong>linguistics_thesis_a.jpg</strong>:</p>

<p><img src="https://mzucker.github.io/images/page_dewarp/linguistics_thesis_a_before_after.png" alt="before and after dewarp"></p>

<p><strong>linguistics_thesis_b.jpg</strong>:</p>

<p><img src="https://mzucker.github.io/images/page_dewarp/linguistics_thesis_b_before_after.png" alt="before and after dewarp"></p>

<p>I also compiled some statistics about each program run (take the
runtimes with a grain of salt, this is for a single run on my 2012
MacBook Pro):</p>

<table>
  <thead>
    <tr>
      <th>Input</th>
      <th>Spans</th>
      <th>Keypoints</th>
      <th>Parameters</th>
      <th>Opt. time (s)</th>
      <th>Total time (s)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>boston_cooking_a.jpg</td>
      <td>38</td>
      <td>554</td>
      <td>600</td>
      <td>23.3</td>
      <td>24.8</td>
    </tr>
    <tr>
      <td>boston_cooking_b.jpg</td>
      <td>38</td>
      <td>475</td>
      <td>521</td>
      <td>18.0</td>
      <td>18.8</td>
    </tr>
    <tr>
      <td>linguistics_thesis_a.jpg</td>
      <td>20</td>
      <td>161</td>
      <td>189</td>
      <td>5.1</td>
      <td>6.1</td>
    </tr>
    <tr>
      <td>linguistics_thesis_b.jpg</td>
      <td>7</td>
      <td>89</td>
      <td>104</td>
      <td>4.2</td>
      <td>5.3</td>
    </tr>
  </tbody>
</table>

<p>You can see these are not exactly <em>small</em> optimization problems. The
smallest one has 89 parameters in the model, and the largest
has 600. Still, I’m sure the optimization speed could be improved by
trying out different methods and/or using a compiled language.</p>

<h2 id="wrapping-up">Wrapping up</h2>

<p>The way this project unfolded represents a fairly typical workflow for
me these days: do a bit of reading to collect background knowledge,
and then figure out how to formulate the entire problem as the output
of some optimization process. I find it’s a pretty effective way of
tackling a large number of technical problems. Although I didn’t think
of it at the time, the overall approach I took here is reminiscent of
both
<a href="https://people.eecs.berkeley.edu/~rbg/latent/">deformable part models</a>
and
<a href="https://www.cs.cmu.edu/~efros/courses/AP06/Papers/matthews_ijcv_2004.pdf">active appearance models</a>,
though not as sophisticated as either.</p>

<p>Both Leptonica and the CTM method go one step further than I did, and
try to model/repair horizontal distortion as well as vertical. That
would be useful for my code, too – because the cubic spline is not an
<a href="https://en.wikipedia.org/wiki/Arc_length">arc-length</a>
parameterization, the text is slightly compressed in areas where the
cubic spline has a large slope. Since this project was mostly intended
as a proof-of-concept, I decided not to pursue the issue further.</p>

<p>Before putting up the final code on github, I tried out using the
automated Python style checker <a href="https://www.pylint.org/">Pylint</a> for
the first time. For some reason, on its first run it informed me that
all of the <code>cv2</code> module members were undefined, leading to an initial
rating of -6.88/10 (yes, negative). Putting the line</p>



<p>near the top of the file made it shut up about that. After tweaking
the program for a while to make Pylint happier, I got the score up to
9.09/10, which seems good enough for now. I’m not sure I agree 100%
with all of its default settings, but it was interesting to try it out
and learn a new tool.</p>

<p>I do all of my coding these days in
<a href="https://www.gnu.org/software/emacs/">GNU Emacs</a>, which usually suits
my needs; however, messing around with Pylint led me to discover a
feature I had never used. Pylint is not fond of short variable names
like <code>h</code> (but has no problem with <code>i</code>, go figure). If I use the normal
Emacs <code>query-replace</code> function bound to <code>M-%</code> and try to replace <code>h</code>
with <code>height</code> everywhere, I have to pay close attention to make sure
that it doesn’t also try to replace the h other identifiers (like
<code>shape</code>) as well. A while back, I discovered I could sidestep this by
using <code>query-replace-regexp</code> instead, and entering
the regular expression <code>\bh\b</code> as the replacement text (the <code>\b</code>
stands for a word <em>b</em>oundary, so it will only match the entire “word”
<code>h</code>). On the other hand, it’s a bit more work, and I thought there
must be a better place to do “whole-word” replacement. A bunch of
Googling led me to
<a href="http://emacs.stackexchange.com/a/12691/12975">this Stack Exchange answer</a>,
which says that using the <code>universal-argument</code> command <code>C-u</code> in Emacs
<em>before</em> a <code>query-replace</code> will do exactly what I want. I never knew
about <code>universal-argument</code> before – always good to learn new tricks!</p>

<p>At this point, I don’t anticipate doing much more with the dewarping
code. It could definitely use a thorough round of commenting, but the
basics are pretty much spelled out in this document, so I’ll just slap
a link here on the
<a href="https://github.com/mzucker/page_dewarp">github repo</a> and call it a
day. Who knows – maybe I’ll refer back to this project again the next
time I teach
<a href="http://www.swarthmore.edu/NatSci/mzucker1/e27_s2016/">computer vision</a>…</p>

<h2>Comments</h2>














  </div>
  <!-- load mathjax -->
  
</article>


      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Homoiconic Python (204 pts)]]></title>
            <link>https://aljamal.substack.com/p/homoiconic-python</link>
            <guid>40335608</guid>
            <pubDate>Sun, 12 May 2024 16:24:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://aljamal.substack.com/p/homoiconic-python">https://aljamal.substack.com/p/homoiconic-python</a>, See on <a href="https://news.ycombinator.com/item?id=40335608">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbee1c0c5-488b-4fe9-a6ca-ced469e022dc_1032x1000.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbee1c0c5-488b-4fe9-a6ca-ced469e022dc_1032x1000.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbee1c0c5-488b-4fe9-a6ca-ced469e022dc_1032x1000.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbee1c0c5-488b-4fe9-a6ca-ced469e022dc_1032x1000.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbee1c0c5-488b-4fe9-a6ca-ced469e022dc_1032x1000.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbee1c0c5-488b-4fe9-a6ca-ced469e022dc_1032x1000.png" width="326" height="315.8914728682171" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/bee1c0c5-488b-4fe9-a6ca-ced469e022dc_1032x1000.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1000,&quot;width&quot;:1032,&quot;resizeWidth&quot;:326,&quot;bytes&quot;:436178,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbee1c0c5-488b-4fe9-a6ca-ced469e022dc_1032x1000.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbee1c0c5-488b-4fe9-a6ca-ced469e022dc_1032x1000.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbee1c0c5-488b-4fe9-a6ca-ced469e022dc_1032x1000.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbee1c0c5-488b-4fe9-a6ca-ced469e022dc_1032x1000.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p><span>The idea of a programming language being able to implement itself is fascinating. It stirs an intense feeling of curiosity: "What would that even look like?" Since its inception in the early '60s, </span><strong>Lisp</strong><span> has managed to do exactly that.</span></p><p><a href="https://en.wikipedia.org/wiki/John_McCarthy_(computer_scientist)" rel="nofollow ugc noopener">John McCarthy</a><span>, In the early '60s, unlocked a collection of remarkable ideas that work really well together and continue to be relevant decades later. First through the </span><a href="http://www-formal.stanford.edu/jmc/recursive.pdf" rel="nofollow ugc noopener">Lisp paper</a><span>, and shortly thereafter with the </span><a href="https://www.softwarepreservation.org/projects/LISP/book/LISP%201.5%20Programmers%20Manual.pdf" rel="nofollow ugc noopener">Lisp 1.5 manual</a><span>.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fac5ae3ca-7054-43fd-9cdf-2c396be4f2c0_542x506.webp" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fac5ae3ca-7054-43fd-9cdf-2c396be4f2c0_542x506.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fac5ae3ca-7054-43fd-9cdf-2c396be4f2c0_542x506.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fac5ae3ca-7054-43fd-9cdf-2c396be4f2c0_542x506.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fac5ae3ca-7054-43fd-9cdf-2c396be4f2c0_542x506.webp 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fac5ae3ca-7054-43fd-9cdf-2c396be4f2c0_542x506.webp" width="296" height="276.33948339483396" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/ac5ae3ca-7054-43fd-9cdf-2c396be4f2c0_542x506.webp&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:506,&quot;width&quot;:542,&quot;resizeWidth&quot;:296,&quot;bytes&quot;:36280,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/webp&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fac5ae3ca-7054-43fd-9cdf-2c396be4f2c0_542x506.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fac5ae3ca-7054-43fd-9cdf-2c396be4f2c0_542x506.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fac5ae3ca-7054-43fd-9cdf-2c396be4f2c0_542x506.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fac5ae3ca-7054-43fd-9cdf-2c396be4f2c0_542x506.webp 1456w" sizes="100vw"></picture></div></a><figcaption>John McCarthy</figcaption></figure></div><p><span>One such idea is </span><strong>homoiconicity</strong><span>, a trait where code and data are interchangeable. Typically, we think of code as a sequence of operations acting upon data. This understanding shapes our view of most programming languages today. However, Lisp breaks this mold by treating both code and data as the same—what's famously known as its </span><a href="https://en.wikipedia.org/wiki/Homoiconicity#:~:text=In%20computer%20programming%2C%20homoiconicity%20(from,as%20data%20using%20the%20language." rel="nofollow ugc noopener">homoiconic</a><span> nature. This distinct characteristic effectively blurs the lines between the operator (code) and the operated (data).</span></p><p>This unification of code and data in Lisp is profound, it allows a level of expression where the language can be naturally expressed in itself.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b0bdd68-04bf-4246-b3df-b0980d664c17_2222x1158.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b0bdd68-04bf-4246-b3df-b0980d664c17_2222x1158.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b0bdd68-04bf-4246-b3df-b0980d664c17_2222x1158.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b0bdd68-04bf-4246-b3df-b0980d664c17_2222x1158.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b0bdd68-04bf-4246-b3df-b0980d664c17_2222x1158.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b0bdd68-04bf-4246-b3df-b0980d664c17_2222x1158.png" width="1456" height="759" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/2b0bdd68-04bf-4246-b3df-b0980d664c17_2222x1158.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:759,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:235648,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b0bdd68-04bf-4246-b3df-b0980d664c17_2222x1158.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b0bdd68-04bf-4246-b3df-b0980d664c17_2222x1158.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b0bdd68-04bf-4246-b3df-b0980d664c17_2222x1158.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b0bdd68-04bf-4246-b3df-b0980d664c17_2222x1158.png 1456w" sizes="100vw"></picture></div></a><figcaption>Lisp in Lisp</figcaption></figure></div><p><span>This tiny card is the entire programming language of Lisp! A programming language written in itself. Here is famous quote from </span><a href="https://en.wikipedia.org/wiki/Alan_Kay" rel="nofollow ugc noopener">Alan Kay</a><span> about this piece of coding history:</span></p><p>that was the big revelation to me … when I finally understood that the half page of code on the bottom of page 13 of the Lisp 1.5 manual was Lisp in itself. These were "Maxwell's Equations of Software!" This is the whole world of programming in a few lines that I can put my hand over.</p><p>Okay, but what sort of magic did Mr. Kay see in this artifact that led him to call it the "Maxwell's Equations of Software"? How was the entire world of programming encapsulated in just a few lines of code?</p><p><span>One fun way to answer that, of course, is by applying the principle that: "</span><strong>In order to understand something, you need to code it</strong><span>".</span></p><p><span>And to keep this spiritual implementation of the original Lisp fun and fresh, I decided to pick Python as the tool of choice. Most programmers are either not familiar or not comfortable with Lisp's syntax (</span><a href="https://xkcd.com/297/" rel="nofollow ugc noopener">too many parentheses</a><span>), but probably quite familiar with Python's syntax. My idea is to rewrite the "Lisp in Lisp" code in Python and try to maintain as much of the spirit of the old code as possible.</span></p><p><span>Lisp originally, and quite brilliantly, came with two </span><strong>syntactical</strong><span> flavors. A code flavor named </span><strong>M-expression</strong><span> (short for meta) and a data flavor named </span><strong>S-expression</strong><span> (short for symbolic). They're </span><strong>semantically</strong><span> equivalent.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F405c58a5-58d4-40d2-97e8-4d6b297dd561_2080x596.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F405c58a5-58d4-40d2-97e8-4d6b297dd561_2080x596.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F405c58a5-58d4-40d2-97e8-4d6b297dd561_2080x596.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F405c58a5-58d4-40d2-97e8-4d6b297dd561_2080x596.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F405c58a5-58d4-40d2-97e8-4d6b297dd561_2080x596.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F405c58a5-58d4-40d2-97e8-4d6b297dd561_2080x596.png" width="626" height="179.2870879120879" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/405c58a5-58d4-40d2-97e8-4d6b297dd561_2080x596.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:417,&quot;width&quot;:1456,&quot;resizeWidth&quot;:626,&quot;bytes&quot;:176726,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F405c58a5-58d4-40d2-97e8-4d6b297dd561_2080x596.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F405c58a5-58d4-40d2-97e8-4d6b297dd561_2080x596.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F405c58a5-58d4-40d2-97e8-4d6b297dd561_2080x596.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F405c58a5-58d4-40d2-97e8-4d6b297dd561_2080x596.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>M-expressions side by side to their S-expressions equivalent</figcaption></figure></div><p>The "Lisp in Lisp" code presented earlier is written as an M-expression (code flavor) and implements an S-expression Lisp (data flavor).</p><p>One little trick to get us going is by translating Lisp M-expressions into Python code constructs, such as function calls and conditional statements. Additionally, we can represent Lisp S-expressions using Python lists. Lisp is short for "List Processing" because it only uses one data structure: the list. Therefore, it makes perfect sense to use Python lists to emulate Lisp S-expressions. Below, I present our mini dictionary that would act as our rosetta stone: </p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F968c725c-dec5-449e-af08-c5ec69fe8f9f_1900x390.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F968c725c-dec5-449e-af08-c5ec69fe8f9f_1900x390.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F968c725c-dec5-449e-af08-c5ec69fe8f9f_1900x390.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F968c725c-dec5-449e-af08-c5ec69fe8f9f_1900x390.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F968c725c-dec5-449e-af08-c5ec69fe8f9f_1900x390.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F968c725c-dec5-449e-af08-c5ec69fe8f9f_1900x390.png" width="496" height="101.85714285714286" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/968c725c-dec5-449e-af08-c5ec69fe8f9f_1900x390.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:299,&quot;width&quot;:1456,&quot;resizeWidth&quot;:496,&quot;bytes&quot;:70594,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F968c725c-dec5-449e-af08-c5ec69fe8f9f_1900x390.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F968c725c-dec5-449e-af08-c5ec69fe8f9f_1900x390.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F968c725c-dec5-449e-af08-c5ec69fe8f9f_1900x390.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F968c725c-dec5-449e-af08-c5ec69fe8f9f_1900x390.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>These are four ways of expressing one thing. They're all semantically</span><strong> </strong><span>equivalent.</span></p><p>An additional advantage of this mapping approach is that it eliminates the need to implement a parser for our language. This simplifies our code base and allows us to stay true to the original spirit of Lisp without getting distracted by string manipulations.</p><p>With this context and motivation in place, we can move on to the actual implementation. Lisp requires a set of basic functions to be implemented outside of its scope, they're mostly about the basic building blocks of lists.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0e85e14c-0eb9-45ce-809a-3df68ae4c11a_2682x816.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0e85e14c-0eb9-45ce-809a-3df68ae4c11a_2682x816.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0e85e14c-0eb9-45ce-809a-3df68ae4c11a_2682x816.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0e85e14c-0eb9-45ce-809a-3df68ae4c11a_2682x816.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0e85e14c-0eb9-45ce-809a-3df68ae4c11a_2682x816.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0e85e14c-0eb9-45ce-809a-3df68ae4c11a_2682x816.png" width="1456" height="443" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/0e85e14c-0eb9-45ce-809a-3df68ae4c11a_2682x816.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:443,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:141182,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0e85e14c-0eb9-45ce-809a-3df68ae4c11a_2682x816.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0e85e14c-0eb9-45ce-809a-3df68ae4c11a_2682x816.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0e85e14c-0eb9-45ce-809a-3df68ae4c11a_2682x816.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0e85e14c-0eb9-45ce-809a-3df68ae4c11a_2682x816.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Python list primitives to act like Lisp</figcaption></figure></div><ul><li><p>Equivalence</p><ul><li><p><strong>atom(x)</strong><span>: is x a list?</span></p></li><li><p><strong>eq(x,y)</strong><span>: is x equal y?</span></p></li></ul></li><li><p>Cutting</p><ul><li><p><strong>car(x)</strong><span>: first element of the list</span></p></li><li><p><strong>cdr(x)</strong><span>: the rest of the list</span></p></li></ul></li><li><p>Stitching</p><ul><li><p><strong>cons(x,y)</strong><span>: append an atom to a list</span></p></li><li><p><strong>append(x,y)</strong><span>: append two lists together</span></p></li></ul></li></ul><p><span>Ignoring a few recursive primitives, and with a little help from </span><strong><a href="https://llama.meta.com/llama3/" rel="nofollow ugc noopener">Llama3-70b</a><span> </span></strong><span>(</span><a href="https://groq.com/" rel="nofollow ugc noopener">on Groq</a><span>), we can quickly get a working interpreter for a subset of the "Lisp in Lisp" code:</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0ae0243d-7e73-421a-960a-f50b6e9ac123_1958x1572.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0ae0243d-7e73-421a-960a-f50b6e9ac123_1958x1572.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0ae0243d-7e73-421a-960a-f50b6e9ac123_1958x1572.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0ae0243d-7e73-421a-960a-f50b6e9ac123_1958x1572.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0ae0243d-7e73-421a-960a-f50b6e9ac123_1958x1572.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0ae0243d-7e73-421a-960a-f50b6e9ac123_1958x1572.png" width="1456" height="1169" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/0ae0243d-7e73-421a-960a-f50b6e9ac123_1958x1572.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1169,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:312032,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0ae0243d-7e73-421a-960a-f50b6e9ac123_1958x1572.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0ae0243d-7e73-421a-960a-f50b6e9ac123_1958x1572.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0ae0243d-7e73-421a-960a-f50b6e9ac123_1958x1572.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0ae0243d-7e73-421a-960a-f50b6e9ac123_1958x1572.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><span>A working version of the Lisp in Lisp </span><strong>M-expression</strong><span> translated to Python</span></figcaption></figure></div><p>Here are a few examples you can play with:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5dbce346-7368-48d8-85dc-37b42429ca20_1472x1512.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5dbce346-7368-48d8-85dc-37b42429ca20_1472x1512.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5dbce346-7368-48d8-85dc-37b42429ca20_1472x1512.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5dbce346-7368-48d8-85dc-37b42429ca20_1472x1512.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5dbce346-7368-48d8-85dc-37b42429ca20_1472x1512.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5dbce346-7368-48d8-85dc-37b42429ca20_1472x1512.png" width="1456" height="1496" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5dbce346-7368-48d8-85dc-37b42429ca20_1472x1512.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1496,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:220649,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5dbce346-7368-48d8-85dc-37b42429ca20_1472x1512.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5dbce346-7368-48d8-85dc-37b42429ca20_1472x1512.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5dbce346-7368-48d8-85dc-37b42429ca20_1472x1512.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5dbce346-7368-48d8-85dc-37b42429ca20_1472x1512.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><span>Python lists acting as </span><strong>S-expressions</strong></figcaption></figure></div><p><span>Full code available on </span><a href="https://gist.github.com/aburjg/1dffba5516095050089f6ea293cb782b#first" rel="nofollow ugc noopener">github gists</a></p><p><span>Our first iteration is nearly complete, except for one crucial feature: </span><a href="https://en.wikipedia.org/wiki/Anonymous_function" rel="nofollow ugc noopener">lambdas</a><span>. Lambdas are anonymous functions that serve as the primary method for defining and calling functions in Lisp. Without lambdas in Lisp, we cannot implement recursion, and without recursion, our Lisp would not be </span><a href="https://en.wikipedia.org/wiki/Church%E2%80%93Turing_thesis#:~:text=The%20thesis%20can%20be%20stated,represented%20as%20a%20Turing%20Machine%22." rel="nofollow ugc noopener">Turing complete</a><span> (the minimum threshold to compute all which can be computed). </span></p><p><span>To incorporate lambdas, we need to add a few functions we previously overlooked, specifically two primitives: </span><strong>assoc(x,y)</strong><span> and </span><strong>pairlis(x,y)</strong><span>. </span><strong>assoc(x,y)</strong><span> is a key/value dictionary style lookup but implemented with lists instead (associative lists). parlis is just the </span><strong>zip(x,y)</strong><span> in Python (ziping two lists together).</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fab54c10f-a5d7-4605-8665-f4f65cb6927f_1694x1030.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fab54c10f-a5d7-4605-8665-f4f65cb6927f_1694x1030.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fab54c10f-a5d7-4605-8665-f4f65cb6927f_1694x1030.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fab54c10f-a5d7-4605-8665-f4f65cb6927f_1694x1030.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fab54c10f-a5d7-4605-8665-f4f65cb6927f_1694x1030.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fab54c10f-a5d7-4605-8665-f4f65cb6927f_1694x1030.png" width="594" height="361.0508241758242" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/ab54c10f-a5d7-4605-8665-f4f65cb6927f_1694x1030.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:885,&quot;width&quot;:1456,&quot;resizeWidth&quot;:594,&quot;bytes&quot;:484840,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fab54c10f-a5d7-4605-8665-f4f65cb6927f_1694x1030.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fab54c10f-a5d7-4605-8665-f4f65cb6927f_1694x1030.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fab54c10f-a5d7-4605-8665-f4f65cb6927f_1694x1030.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fab54c10f-a5d7-4605-8665-f4f65cb6927f_1694x1030.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><strong>pairlis</strong><span> and </span><strong>assoc</strong><span> as they first appeared in the Lisp 1.5 manual</span></figcaption></figure></div><p>A literal translation in Python would be:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F507f7502-872f-4cc8-a950-e95d714c8caf_2576x1188.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F507f7502-872f-4cc8-a950-e95d714c8caf_2576x1188.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F507f7502-872f-4cc8-a950-e95d714c8caf_2576x1188.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F507f7502-872f-4cc8-a950-e95d714c8caf_2576x1188.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F507f7502-872f-4cc8-a950-e95d714c8caf_2576x1188.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F507f7502-872f-4cc8-a950-e95d714c8caf_2576x1188.png" width="1456" height="671" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/507f7502-872f-4cc8-a950-e95d714c8caf_2576x1188.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:671,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:234791,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F507f7502-872f-4cc8-a950-e95d714c8caf_2576x1188.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F507f7502-872f-4cc8-a950-e95d714c8caf_2576x1188.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F507f7502-872f-4cc8-a950-e95d714c8caf_2576x1188.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F507f7502-872f-4cc8-a950-e95d714c8caf_2576x1188.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><span>A literal (</span><strong>recursive</strong><span>) Lisp to Python translation of </span><strong>assoc</strong><span> and </span><strong>pairlis</strong></figcaption></figure></div><p><span>The original Lisp had to resort to </span><strong>recursion</strong><span> (function calling itself) even for simple, linear scans, since it had no </span><a href="https://en.wikipedia.org/wiki/For_loop" rel="nofollow ugc noopener">loops</a><span>. However, </span><strong>assoc</strong><span> and </span><strong>pairlis</strong><span> can be elegantly translated to Python using </span><strong>list comprehensions</strong><span>:</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe1e8befb-3b17-47c9-940d-2c7310ad7016_2184x264.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe1e8befb-3b17-47c9-940d-2c7310ad7016_2184x264.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe1e8befb-3b17-47c9-940d-2c7310ad7016_2184x264.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe1e8befb-3b17-47c9-940d-2c7310ad7016_2184x264.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe1e8befb-3b17-47c9-940d-2c7310ad7016_2184x264.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe1e8befb-3b17-47c9-940d-2c7310ad7016_2184x264.png" width="1456" height="176" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/e1e8befb-3b17-47c9-940d-2c7310ad7016_2184x264.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:176,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:64335,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe1e8befb-3b17-47c9-940d-2c7310ad7016_2184x264.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe1e8befb-3b17-47c9-940d-2c7310ad7016_2184x264.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe1e8befb-3b17-47c9-940d-2c7310ad7016_2184x264.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe1e8befb-3b17-47c9-940d-2c7310ad7016_2184x264.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><span>Python supports both </span><strong>loops</strong><span> and </span><strong>recursion</strong></figcaption></figure></div><p><span>and if you hadn't noticed already I actually cheated a bit in the COND case as this in the original lisp was a </span><strong>evcon</strong><span> which was also translated into a loop. The same trick will be done again with </span><strong>evlis</strong><span> for the LAMBDA case.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ac6b137-0f3b-417b-abb3-2a8909702103_1532x480.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ac6b137-0f3b-417b-abb3-2a8909702103_1532x480.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ac6b137-0f3b-417b-abb3-2a8909702103_1532x480.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ac6b137-0f3b-417b-abb3-2a8909702103_1532x480.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ac6b137-0f3b-417b-abb3-2a8909702103_1532x480.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ac6b137-0f3b-417b-abb3-2a8909702103_1532x480.png" width="642" height="201.06593406593407" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5ac6b137-0f3b-417b-abb3-2a8909702103_1532x480.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:456,&quot;width&quot;:1456,&quot;resizeWidth&quot;:642,&quot;bytes&quot;:102839,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ac6b137-0f3b-417b-abb3-2a8909702103_1532x480.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ac6b137-0f3b-417b-abb3-2a8909702103_1532x480.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ac6b137-0f3b-417b-abb3-2a8909702103_1532x480.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ac6b137-0f3b-417b-abb3-2a8909702103_1532x480.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><strong>evcon</strong><span>, and </span><strong>evlis</strong><span> are other examples of loops in "Lisp in Lisp" code</span></figcaption></figure></div><p><span>We're almost there! There is one last thing, and we're done. The </span><strong>eval</strong><span> function actually takes two arguments in the original Lisp. The first is the expression (s-exp) of course. The second is the environment, which is yet another list (of key/values). Environment maintains variable binding for the LAMBDA case by mapping variable names to their corresponding values. &nbsp;</span></p><p><span>For example, when you define a function with x variable then substitute that function with data, the data gets binded (with </span><strong>pairlis</strong><span>) to the x symbol and is then stored/appended to the environment list. When x is needed, it gets looked up (with </span><strong>assoc</strong><span>) and subtitued back to expression. The specific technique for this binding is known as </span><a href="https://en.wikipedia.org/wiki/Scope_(computer_science)" rel="nofollow ugc noopener">dynamic scoping</a><span>. </span></p><p>Here is the full 'Lisp in Lisp' code in Python:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb7161bbe-d80e-42b9-8b93-1a70bbab2a57_1354x1550.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb7161bbe-d80e-42b9-8b93-1a70bbab2a57_1354x1550.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb7161bbe-d80e-42b9-8b93-1a70bbab2a57_1354x1550.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb7161bbe-d80e-42b9-8b93-1a70bbab2a57_1354x1550.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb7161bbe-d80e-42b9-8b93-1a70bbab2a57_1354x1550.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb7161bbe-d80e-42b9-8b93-1a70bbab2a57_1354x1550.png" width="1354" height="1550" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b7161bbe-d80e-42b9-8b93-1a70bbab2a57_1354x1550.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1550,&quot;width&quot;:1354,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:352315,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb7161bbe-d80e-42b9-8b93-1a70bbab2a57_1354x1550.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb7161bbe-d80e-42b9-8b93-1a70bbab2a57_1354x1550.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb7161bbe-d80e-42b9-8b93-1a70bbab2a57_1354x1550.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb7161bbe-d80e-42b9-8b93-1a70bbab2a57_1354x1550.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Original 'Lisp in Lisp' in Python</figcaption></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F909b94d3-7004-4029-b03c-de794601f3f7_2174x320.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F909b94d3-7004-4029-b03c-de794601f3f7_2174x320.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F909b94d3-7004-4029-b03c-de794601f3f7_2174x320.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F909b94d3-7004-4029-b03c-de794601f3f7_2174x320.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F909b94d3-7004-4029-b03c-de794601f3f7_2174x320.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F909b94d3-7004-4029-b03c-de794601f3f7_2174x320.png" width="1456" height="214" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/909b94d3-7004-4029-b03c-de794601f3f7_2174x320.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:214,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:83226,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F909b94d3-7004-4029-b03c-de794601f3f7_2174x320.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F909b94d3-7004-4029-b03c-de794601f3f7_2174x320.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F909b94d3-7004-4029-b03c-de794601f3f7_2174x320.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F909b94d3-7004-4029-b03c-de794601f3f7_2174x320.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Lambdas at last!</figcaption></figure></div><p><span>Full code available on </span><a href="https://gist.github.com/aburjg/1dffba5516095050089f6ea293cb782b#second" rel="nofollow ugc noopener">github gists</a></p><p><strong>Helpful resources:</strong></p><ul><li><p>https://inst.eecs.berkeley.edu/~cs61a/fa14/assets/interpreter/scheme.html</p></li><li><p>http://languagelog.ldc.upenn.edu/myl/llog/jmc.pdf</p></li><li><p>https://justine.lol/sectorlisp2</p></li></ul></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Yi 1.5 (148 pts)]]></title>
            <link>https://github.com/01-ai/Yi-1.5</link>
            <guid>40335599</guid>
            <pubDate>Sun, 12 May 2024 16:23:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/01-ai/Yi-1.5">https://github.com/01-ai/Yi-1.5</a>, See on <a href="https://news.ycombinator.com/item?id=40335599">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><div dir="auto">
<themed-picture data-catalyst-inline="true"><picture> 
  <img src="https://raw.githubusercontent.com/01-ai/Yi/main/assets/img/Yi_logo_icon_light.svg" width="150px">
</picture></themed-picture>
</div>

<p dir="auto">
  <a href="https://huggingface.co/01-ai" rel="nofollow">🤗 HuggingFace</a> •
  <a href="https://www.modelscope.cn/organization/01ai/" rel="nofollow">🤖 ModelScope</a> •
  <a href="https://wisemodel.cn/organization/01.AI" rel="nofollow">✡️ WiseModel</a> 
  <br>
  <a href="https://discord.gg/hYUwWddeAu" rel="nofollow">👾 Discord</a> •
  <a href="https://twitter.com/01ai_yi" rel="nofollow">🐤 Twitter</a> •
  <a href="https://github.com/01-ai/Yi-1.5/issues/2" data-hovercard-type="issue" data-hovercard-url="/01-ai/Yi-1.5/issues/2/hovercard">💬 WeChat</a> 
  <br>
  <a href="https://arxiv.org/abs/2403.04652" rel="nofollow">📝 Paper</a> •
  <a href="https://github.com/01-ai/Yi/tree/main?tab=readme-ov-file#faq">🙌 FAQ</a> •
  <a href="https://github.com/01-ai/Yi/tree/main?tab=readme-ov-file#learning-hub">📗 Learning Hub</a>
</p>
<hr>
<ul dir="auto">
<li><a href="#intro">Intro</a></li>
<li><a href="#news">News</a></li>
<li><a href="#quick-start">Quick Start</a></li>
<li><a href="#web-demo">Web Demo</a></li>
<li><a href="#deployment">Deployment</a></li>
<li><a href="#fine-tuning">Fine-tuning</a></li>
<li><a href="#api">API</a></li>
<li><a href="#license">License</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Intro</h2><a id="user-content-intro" aria-label="Permalink: Intro" href="#intro"></a></p>
<p dir="auto">Yi-1.5 is an upgraded version of Yi. It is continuously pre-trained on Yi with a high-quality corpus of 500B tokens and fine-tuned on 3M diverse fine-tuning samples.</p>
<p dir="auto">Compared with Yi, Yi-1.5 delivers stronger performance in coding, math, reasoning, and instruction-following capability, while still maintaining excellent capabilities in language understanding, commonsense reasoning, and reading comprehension.</p>
<p dir="auto">Yi-1.5 comes in 3 model sizes: 34B, 9B, and 6B. For model details and benchmarks, see <a href="https://huggingface.co/collections/01-ai/yi-15-2024-05-663f3ecab5f815a3eaca7ca8" rel="nofollow">Model Card</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">News</h2><a id="user-content-news" aria-label="Permalink: News" href="#news"></a></p>
<ul dir="auto">
<li>2024-05-13: The Yi-1.5 series models are open-sourced, further improving coding, math, reasoning, and instruction-following abilities.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Requirements</h2><a id="user-content-requirements" aria-label="Permalink: Requirements" href="#requirements"></a></p>
<ul dir="auto">
<li>
<p dir="auto">Make sure Python 3.10 or a later version is installed.</p>
</li>
<li>
<p dir="auto">Set up the environment and install the required packages.</p>
<div dir="auto" data-snippet-clipboard-copy-content="pip install -r requirements.txt"><pre>pip install -r requirements.txt</pre></div>
</li>
<li>
<p dir="auto">Download the Yi-1.5 model from <a href="https://huggingface.co/01-ai" rel="nofollow">Hugging Face</a>, <a href="https://www.modelscope.cn/organization/01ai/" rel="nofollow">ModelScope</a>, or <a href="https://wisemodel.cn/organization/01.AI" rel="nofollow">WiseModel</a>.</p>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Quick Start</h2><a id="user-content-quick-start" aria-label="Permalink: Quick Start" href="#quick-start"></a></p>
<p dir="auto">This tutorial runs Yi-1.5-34B-Chat locally on an A800 (80G).</p>
<div dir="auto" data-snippet-clipboard-copy-content="from transformers import AutoModelForCausalLM, AutoTokenizer

model_path = '<your-model-path>'

tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=False)

# Since transformers 4.35.0, the GPT-Q/AWQ model can be loaded using AutoModelForCausalLM.
model = AutoModelForCausalLM.from_pretrained(
    model_path,
    device_map=&quot;auto&quot;,
    torch_dtype='auto'
).eval()

# Prompt content: &quot;hi&quot;
messages = [
    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;hi&quot;}
]

input_ids = tokenizer.apply_chat_template(conversation=messages, tokenize=True, add_generation_prompt=True, return_tensors='pt')
output_ids = model.generate(input_ids.to('cuda'))
response = tokenizer.decode(output_ids[0][input_ids.shape[1]:], skip_special_tokens=True)

# Model response: &quot;Hello! How can I assist you today?&quot;
print(response)"><pre><span>from</span> <span>transformers</span> <span>import</span> <span>AutoModelForCausalLM</span>, <span>AutoTokenizer</span>

<span>model_path</span> <span>=</span> <span>'&lt;your-model-path&gt;'</span>

<span>tokenizer</span> <span>=</span> <span>AutoTokenizer</span>.<span>from_pretrained</span>(<span>model_path</span>, <span>use_fast</span><span>=</span><span>False</span>)

<span># Since transformers 4.35.0, the GPT-Q/AWQ model can be loaded using AutoModelForCausalLM.</span>
<span>model</span> <span>=</span> <span>AutoModelForCausalLM</span>.<span>from_pretrained</span>(
    <span>model_path</span>,
    <span>device_map</span><span>=</span><span>"auto"</span>,
    <span>torch_dtype</span><span>=</span><span>'auto'</span>
).<span>eval</span>()

<span># Prompt content: "hi"</span>
<span>messages</span> <span>=</span> [
    {<span>"role"</span>: <span>"user"</span>, <span>"content"</span>: <span>"hi"</span>}
]

<span>input_ids</span> <span>=</span> <span>tokenizer</span>.<span>apply_chat_template</span>(<span>conversation</span><span>=</span><span>messages</span>, <span>tokenize</span><span>=</span><span>True</span>, <span>add_generation_prompt</span><span>=</span><span>True</span>, <span>return_tensors</span><span>=</span><span>'pt'</span>)
<span>output_ids</span> <span>=</span> <span>model</span>.<span>generate</span>(<span>input_ids</span>.<span>to</span>(<span>'cuda'</span>))
<span>response</span> <span>=</span> <span>tokenizer</span>.<span>decode</span>(<span>output_ids</span>[<span>0</span>][<span>input_ids</span>.<span>shape</span>[<span>1</span>]:], <span>skip_special_tokens</span><span>=</span><span>True</span>)

<span># Model response: "Hello! How can I assist you today?"</span>
<span>print</span>(<span>response</span>)</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Deployment</h2><a id="user-content-deployment" aria-label="Permalink: Deployment" href="#deployment"></a></p>
<p dir="auto">Prerequisites: Before deploying Yi-1.5 models, make sure you meet the <a href="https://github.com/01-ai/Yi/tree/main?tab=readme-ov-file#software-requirements">software and hardware requirements</a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">vLLM</h3><a id="user-content-vllm" aria-label="Permalink: vLLM" href="#vllm"></a></p>
<p dir="auto">Prerequisites: Download the lastest version of <a href="https://docs.vllm.ai/en/latest/getting_started/installation.html" rel="nofollow">vLLM</a>.</p>
<ol dir="auto">
<li>
<p dir="auto">Start the server with a chat model.</p>
<div dir="auto" data-snippet-clipboard-copy-content="python -m vllm.entrypoints.openai.api_server  --model 01-ai/Yi-1.5-9B-Chat  --served-model-name Yi-1.5-9B-Chat"><pre>python -m vllm.entrypoints.openai.api_server  --model 01-ai/Yi-1.5-9B-Chat  --served-model-name Yi-1.5-9B-Chat</pre></div>
</li>
<li>
<p dir="auto">Use the chat API.</p>
</li>
</ol>
<ul dir="auto">
<li>
<p dir="auto">HTTP</p>
<div dir="auto" data-snippet-clipboard-copy-content="curl http://localhost:8000/v1/chat/completions \
    -H &quot;Content-Type: application/json&quot; \
    -d '{
        &quot;model&quot;: &quot;Yi-1.5-9B-Chat&quot;,
        &quot;messages&quot;: [
            {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;You are a helpful assistant.&quot;},
            {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Who won the world series in 2020?&quot;}
        ]
    }'"><pre>curl http://localhost:8000/v1/chat/completions \
    -H <span><span>"</span>Content-Type: application/json<span>"</span></span> \
    -d <span><span>'</span>{</span>
<span>        "model": "Yi-1.5-9B-Chat",</span>
<span>        "messages": [</span>
<span>            {"role": "system", "content": "You are a helpful assistant."},</span>
<span>            {"role": "user", "content": "Who won the world series in 2020?"}</span>
<span>        ]</span>
<span>    }<span>'</span></span></pre></div>
</li>
<li>
<p dir="auto">Python client</p>
<div dir="auto" data-snippet-clipboard-copy-content="from openai import OpenAI
# Set OpenAI's API key and API base to use vLLM's API server.
openai_api_key = &quot;EMPTY&quot;
openai_api_base = &quot;http://localhost:8000/v1&quot;

client = OpenAI(
    api_key=openai_api_key,
    base_url=openai_api_base,
)

chat_response = client.chat.completions.create(
    model=&quot;Yi-1.5-9B-Chat&quot;,
    messages=[
        {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;You are a helpful assistant.&quot;},
        {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Tell me a joke.&quot;},
    ]
)
print(&quot;Chat response:&quot;, chat_response)"><pre><span>from</span> <span>openai</span> <span>import</span> <span>OpenAI</span>
<span># Set OpenAI's API key and API base to use vLLM's API server.</span>
<span>openai_api_key</span> <span>=</span> <span>"EMPTY"</span>
<span>openai_api_base</span> <span>=</span> <span>"http://localhost:8000/v1"</span>

<span>client</span> <span>=</span> <span>OpenAI</span>(
    <span>api_key</span><span>=</span><span>openai_api_key</span>,
    <span>base_url</span><span>=</span><span>openai_api_base</span>,
)

<span>chat_response</span> <span>=</span> <span>client</span>.<span>chat</span>.<span>completions</span>.<span>create</span>(
    <span>model</span><span>=</span><span>"Yi-1.5-9B-Chat"</span>,
    <span>messages</span><span>=</span>[
        {<span>"role"</span>: <span>"system"</span>, <span>"content"</span>: <span>"You are a helpful assistant."</span>},
        {<span>"role"</span>: <span>"user"</span>, <span>"content"</span>: <span>"Tell me a joke."</span>},
    ]
)
<span>print</span>(<span>"Chat response:"</span>, <span>chat_response</span>)</pre></div>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Web Demo</h2><a id="user-content-web-demo" aria-label="Permalink: Web Demo" href="#web-demo"></a></p>
<div data-snippet-clipboard-copy-content="python demo/web_demo.py -c <your-model-path>"><pre><code>python demo/web_demo.py -c &lt;your-model-path&gt;
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Fine-tuning</h2><a id="user-content-fine-tuning" aria-label="Permalink: Fine-tuning" href="#fine-tuning"></a></p>
<p dir="auto">You can use <a href="https://github.com/hiyouga/LLaMA-Factory">LLaMA-Factory</a>, <a href="https://github.com/modelscope/swift">Swift</a>, <a href="https://github.com/InternLM/xtuner">XTuner</a>, and <a href="https://github.com/yangjianxin1/Firefly">Firefly</a> for fine-tuning. These frameworks all support fine-tuning the Yi series models.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">API</h2><a id="user-content-api" aria-label="Permalink: API" href="#api"></a></p>
<p dir="auto">Yi APIs are OpenAI-compatible and provided at <a href="https://platform.lingyiwanwu.com/" rel="nofollow">Yi Platform</a>. Sign up to get free tokens, and you can also pay-as-you-go at a competitive price. Additionally, Yi APIs are also deployed on <a href="https://replicate.com/search?query=01+ai" rel="nofollow">Replicate</a> and <a href="https://openrouter.ai/models?q=01%20ai" rel="nofollow">OpenRouter</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">The code and weights of the Yi-1.5 series models are distributed under the <a href="https://github.com/01-ai/Yi/blob/main/LICENSE">Apache 2.0 license</a>.</p>
<p dir="auto"> [
  <a href="#top">Back to top ⬆️ </a>  ] 
</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Brain Uses Quantum Effects, New Study Finds (172 pts)]]></title>
            <link>http://backreaction.blogspot.com/2024/05/brain-really-uses-quantum-effects-new.html</link>
            <guid>40335209</guid>
            <pubDate>Sun, 12 May 2024 15:27:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://backreaction.blogspot.com/2024/05/brain-really-uses-quantum-effects-new.html">http://backreaction.blogspot.com/2024/05/brain-really-uses-quantum-effects-new.html</a>, See on <a href="https://news.ycombinator.com/item?id=40335209">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-body-7793863980395232228" itemprop="description articleBody"><p>
When Roger Penrose originally came out with the idea that the human brain uses quantum effects in microtubules and that was the origin of consciousness, many thought the idea was a little crazy. According to a new study, it turns out that Penrose was actually right… about the microtubules anyways. Let’s have a look.</p><center><iframe width="560" height="315" src="https://www.youtube.com/embed/R6G1D2UQ3gg?si=E96lZI49ezXUIa2G" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
  
</center>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Whole-body magnetic resonance imaging at 0.05 Tesla (167 pts)]]></title>
            <link>https://www.science.org/doi/10.1126/science.adm7168</link>
            <guid>40335170</guid>
            <pubDate>Sun, 12 May 2024 15:20:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.science.org/doi/10.1126/science.adm7168">https://www.science.org/doi/10.1126/science.adm7168</a>, See on <a href="https://news.ycombinator.com/item?id=40335170">Hacker News</a></p>
Couldn't get https://www.science.org/doi/10.1126/science.adm7168: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Solar Storm Knocks Out Farmers' Tractor GPS Systems During Peak Planting Season (115 pts)]]></title>
            <link>https://www.404media.co/solar-storm-knocks-out-tractor-gps-systems-during-peak-planting-season/</link>
            <guid>40334391</guid>
            <pubDate>Sun, 12 May 2024 13:42:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.404media.co/solar-storm-knocks-out-tractor-gps-systems-during-peak-planting-season/">https://www.404media.co/solar-storm-knocks-out-tractor-gps-systems-during-peak-planting-season/</a>, See on <a href="https://news.ycombinator.com/item?id=40334391">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <article>
          <div>
              
<!--kg-card-begin: html-->
  <div>
    <h5>Subscribe</h5>
    <div>
      <p>Join the newsletter to get the latest updates.</p>
      <form data-members-form="subscribe">
        
        
        <div>
          
          <p>
            Great! Check your inbox and click the link.
          </p>
        </div>
        <div>
          
          <p>
            Please enter a valid email address.
          </p>
        </div>
      </form>
    </div>
  </div>

<!--kg-card-end: html-->
<div><p>🖥️</p><p><i><em>404 Media is a journalist-owned website that is written by real people for real people. Sign up to support independent journalism.</em></i></p></div><p>The solar storm that brought the aurora borealis to large parts of the United States this weekend also broke critical GPS and precision farming functionality in tractors and agricultural equipment during a critical point of the planting season, 404 Media has learned. These outages caused many farmers to fully stop their planting operations for the moment.</p><p>One chain of John Deere dealerships warned farmers that the accuracy of some of the systems used by tractors are “extremely compromised,” and that farmers who planted crops during periods of inaccuracy are going to face problems when they go to harvest, according to text messages obtained by 404 Media and an <a href="https://landmarkimp.com/news/news/blog/geomagnetic-storm-affecting-gps-signals--may-2024/?ref=404media.co"><u>update posted by the dealership</u></a>. The outages highlight how vulnerable modern tractors are to satellite disruptions, which experts have been warning about for years. </p><p>“All the tractors are sitting at the ends of the field right now shut down because of the solar storm,” Kevin Kenney, a farmer in Nebraska, told me. “No GPS. We’re right in the middle of corn planting. I’ll bet the commodity markets spike Monday.”&nbsp;</p><p>Specifically, some GPS systems were temporarily knocked offline. This caused intermittent connections and accuracy problems with “Real-Time Kinematic” (RTK) systems, which connect to John Deere “<a href="https://www.deere.com/en/technology-products/precision-ag-technology/guidance/starfire-7500-receiver/?ref=404media.co"><u>StarFire” receivers</u></a> that are in modern tractors and agricultural equipment. RTK systems use GPS plus a stream of <a href="https://www.fullinefarm.com/fckimages/pdf/differential.pdf?ref=404media.co"><u>constantly-updating “correction” data</u></a> from a fixed point on the ground to achieve centimeter-level positional accuracy for planting crops, tilling fields, spraying fertilizer and herbicide, etc.&nbsp;</p><p>According to updates from Landmark Implement, which owns John Deere dealerships in Kansas and Nebraska, the solar storm ruined the accuracy of RTK systems for many farmers using John Deere tractors. Similar systems in other brands of tractors have also been compromised, the dealer and farmers I spoke to said.</p><p>“Due to the way the RTK network works, the base stations were sending out corrections that have been affected by the geomagnetic storm and were causing drastic shifts in the field and even some heading changes that were drastic,” the dealership told farmers Saturday morning. “When you head back into these fields to side dress, spray, cultivate, harvest, etc. over the next several months, we expect that the rows won't be where the AutoPath lines think they are. This will only affect the fields that are planted during times of reduced accuracy. It is most likely going to be difficult—if not impossible—to make AutoPath work in these fields as the inaccuracy is most likely inconsistent.”</p><div><p>🚜</p><p><b><strong>Has your farm been affected by the solar storm? I would love to hear from you. Using a non-work device, you can message me securely on Signal at +1 202 505 1702. Otherwise, send me an email at jason@404media.co.</strong></b></p></div><p>These automated systems have become critical to modern farming (often called “<a href="https://www.scientificamerican.com/article/precision-farming/?ref=404media.co"><u>precision agriculture</u></a>”), with farmers using increasingly automated tractors to plant crops in perfectly straight lines with uniform spacing. Precision agriculture has greatly increased the yield of farms, and a <a href="https://www.ers.usda.gov/webdocs/publications/105894/eib-248.pdf?v=4429.1&amp;ref=404media.co"><u>2023 report by the US Department of Agriculture</u></a> noted that more than 50 percent of corn, cotton, rice, sorghum, soybeans, and winter wheat are planted and harvested with “automated guidance.” Many modern tractors essentially steer themselves, with the oversight of a farmer in the cab. If the planting or harvesting is even slightly off, the tractors or harvesters could damage crops or plant crooked or inconsistently, which can cause problems during the growing season and ultimately reduce yield.</p><p>Landmark Implement first warned farmers about the problems Friday in a text message blast obtained by 404 Media: “Please be advised that there is a significant solar flare and space weather activity currently affecting GPS and RTK networks. This severe geomagnetic storm is the worst since 2005 and is forecasted to continue throughout the weekend.” That message advised farmers to shut down their reliance on the networks entirely.</p><p>The National Oceanic and Atmospheric Administration (NOAA) said that what’s happening is the “most extreme geomagnetic storm since 2003,” and that “there have been preliminary reports of power grid irregularities, degradation to high-frequency communications, GPS, and possibly satellite navigation.” NOAA said the storm <a href="https://www.swpc.noaa.gov/news/historic-geomagnetic-storm-continues?ref=404media.co" rel="noreferrer">will continue into Monday</a>. Geomagnetic storms happen when there is a coronal mass ejection from the sun, which is an eruption of electromagnetic radiation that can impact GPS, the electric grid, and other communications. &nbsp;</p><p>Farmers and experts I spoke to told me that GPS outages in farming are a very big deal. Landmark Implement has not given any further updates to farmers, and John Deere did not respond to a request for comment. Farmers I spoke to seem to think that the situation is getting better, but solar storms are expected to continue hitting Earth over the next day or so.&nbsp;</p><p>“In the corn belt, May 15 is a critical date to get corn planted,” Willie Cade of Repair.org, who has been working to pass legislation that would make tractors more repairable, told me. “But you don’t want to go out there with your equipment right now. Oh my God, the corn belt can’t get its corn in the ground by May 15? It’s huge. I’m thinking it’s going to go away, but if it doesn’t, shit.”</p><p>Tom Schwarz, who owns an organic farm in Nebraska, told me he had to stop planting on Friday and Saturday because of the issue, and said that the outage, combined with a bad weather forecast in the next few days, is threatening the small time window that he has to plant corn.</p><p>“When you have your window, you have to go,” Schwarz said. “We’ve just had two beautiful days from a weather perspective of being able to plant and you know, we just have to sit here. We’re not getting anything done, and it’s driving everyone nuts.”&nbsp;</p><p>Schwarz says organic farms like his rely heavily on precision farming features, because rows of crops are planted very tightly together to prevent weeds from growing in the spaces between plants. “We used to have markers that would scratch a line in the ground that you could then use to kind of drive by eye,” he said. “Now, we plant so tight in terms of how much the tractor can go side to side and how much the equipment can go side to side that if we aren't absolutely perfect, it just doesn't work. You just physically can’t drive that straight [without guidance]. If you're sitting up there in a tractor seat, you can't steer fast enough or well enough to not kill the crop because we're so tight on clearances.” &nbsp;</p><p>The fact that this happened also highlights how vulnerable modern food supplies are to GPS outages. Modern society as a whole is obviously very reliant on GPS, but experts have warned that tractors that rely on internet connections and on satellites are a particularly concerning attack vector.&nbsp;</p><p>Last year, an outage with Inmarsat satellites caused tractors in Australia and New Zealand to “<a href="https://www.smh.com.au/national/farmers-crippled-by-satellite-failure-as-gps-guided-tractors-grind-to-a-halt-20230418-p5d1de.html?ref=404media.co"><u>grind to a halt</u></a>,” and the remote bricking of <a href="https://www.csoonline.com/article/572811/remote-bricking-of-ukrainian-tractors-raises-agriculture-security-concerns.html?ref=404media.co"><u>connected tractors in Ukraine</u></a> in 2022 showed a type of vulnerability many hadn’t considered before. Experts have warned about the <a href="https://www.bbc.com/news/science-environment-61336659?ref=404media.co"><u>possibility of a cyber attack</u></a> targeting tractors or the <a href="https://www.nature.com/articles/s42256-022-00440-4?ref=404media.co"><u>satellites they rely on</u></a> as a major threat to our food supply.&nbsp;</p><p>Farmers in online communities all over the internet have been discussing the GPS outages, with some saying that they’ve been running into “very weird issues.” One <a href="https://thefarmingforum.co.uk/index.php?threads%2Fsolar-storm.409445%2F=&amp;ref=404media.co#post-9299330"><u>farmer in Manitoba posted</u></a> “Yesterday was a shit show. Going to be some stripes in the fields. Today it’s back to normal.” I also messaged with two people who work on separate farms and posted in a <a href="https://www.reddit.com/r/farming/comments/1cp2m78/anyone_else_lose_gps_right_now/?ref=404media.co"><u>Reddit thread called</u></a> “Anyone else lose GPS right now?” I agreed not to use their names because they do not own the farms and were not authorized to speak to the press.</p><p>One of them, in southern Ontario, said that they use a positioning system called TopCon, which normally offers “sub-inch accuracy,” they said. “Yesterday I saw issues I’ve never seen before. The really puzzling part was when it was actually seeing enough satellites to function from time to time it was wandering off position by 3 or even 6 feet at times! And I know that the system thought it was on target because the coverage map on the monitor in the tractor was showing that I was exactly on the row, but physically I was off by a huge amount.”&nbsp;</p><p>The other farmer from Reddit told me that they were in the middle of planting wheat when problems arose. “We didn't shut down, we just carried on and however it went in is how it went in lol,” they said. “I probably take the most pride in my work of those on this farm so the boss said I had to lower my standards of quality for the sake of getting the crop in. It wasn't the common problem of the lines just not matching up, the GPS shading thought it was spot on to where it should be but a lot of the time it either left a gap or overlapped by as much as a few feet. It wasn't even uniform enough that I could recenter the tractor.” </p>
                    <div>
    <div>
      <p>About the author</p>
      <p>Jason is a cofounder of 404 Media. He was previously the editor-in-chief of Motherboard. He loves the Freedom of Information Act and surfing.</p>
      
    </div>
      <p><img data-src="/content/images/2023/08/404-jason-01-copy.jpeg" alt="Jason Koebler" src="https://www.404media.co/content/images/2023/08/404-jason-01-copy.jpeg">  
      </p>
  </div>
          </div>
        </article>
      </div></div>]]></description>
        </item>
    </channel>
</rss>