<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 28 Dec 2024 09:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Ada's dependent types, and its types as a whole (118 pts)]]></title>
            <link>https://nytpu.com/gemlog/2024-12-27</link>
            <guid>42528302</guid>
            <pubDate>Sat, 28 Dec 2024 03:22:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nytpu.com/gemlog/2024-12-27">https://nytpu.com/gemlog/2024-12-27</a>, See on <a href="https://news.ycombinator.com/item?id=42528302">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
			
			<h3>December 27, 2024 (Updated: December 27, 2024)</h3>
			<!-- automatically generated by gemroff <https://git.sr.ht/~nytpu/gemroff/> -->
<p>So I like to joke occasionally on the Fediverse that when looking at Wikipedia's <a href="https://en.wikipedia.org/wiki/Dependent_type#Comparison_of_languages_with_dependent_types">list of programming languages supporting dependent types</a>:</p>
<blockquote>
<p>It's tons of extremely complex functional languages, formal theorem provers, and… Ada, a random Government Language dating back to 1983.</p>
<p>Also you'll note that at no point in any Ada documentation anywhere do they feel the need to bring up set theory or the λ cube when explaining how dependent types work :P</p>
</blockquote>
<p>I just love the juxtaposition of the highly formalized academic/research/for-fun languages with a very bureaucratic-feeling language whose design philosophy is very similar to COBOL's.<sup id="fnref:1"><a href="#fn:1">1</a></sup></p>
<p>But then I'll usually get one of a few functional programmers/type theory people that follow me to ask about Ada's dependent types, and this time I felt the motivation to write a big post explaining dependent types in Ada. And I really want to illustrate how how the designers were really just trying to achieve a specific goal, and coincidentally their solution meets the formal definition of dependent types.</p>
<p>Note that I'm really not knowledgeable about functional programming or type theory at all so I can't really speak much about it, although I am fairly skilled with Ada.</p>

<h2 id="adas-dependent-types">Ada's Dependent Types</h2>

<p>First-off, for context here's a very simplified summary of what I'm talking about since it is a rare feature: dependent types are just <q>types that depend on some concrete value</q>. So, for example, a structure with an array field whose length depends on another field in the struct—one of the primary applications of Ada's dependent types<sup id="fnref:2"><a href="#fn:2">2</a></sup>.</p>
<p>I also need to touch on one of Ada's design philosophies, which is to avoid dynamic allocation unless actually necessary for safety reasons, since it doesn't have a borrow checker for fully-safe allocation like Rust does<sup id="fnref:3"><a href="#fn:3">3</a></sup>. The key problem is that when you use one single call stack to both store return addresses and local variables, a called function can't return the contents of one of its stack-allocated variables <q>upwards</q> because the callee needs to be able to pop off the return address and have the stack pointer be precisely where it was before it got called. Instead, any larger-than-register returned value has to have its stack slots be allocated by the caller, <em>with a size known to the caller</em>. Ada solves this by having a second non-call stack<sup id="fnref:4"><a href="#fn:4">4</a></sup> that functions can allocate compile-time unknown space on and return that upward, without needing dynamic allocation and preserving the nice scoping and free lexical deallocation that a stack provides. The only time you really need dynamic allocation in Ada is when you're interworking with C/C++/Fortran/COBOL<sup id="fnref:5"><a href="#fn:5">5</a></sup>, or if you have an aggregate type that contains an object of unknown length, e.g. an array of strings, where you have to dynamically allocate all the strings and then the array of pointers can be handled like normal (Ada has a rich container library so it's rare you need to think about it at all). Allowing use of the second stack rather than dynamic allocation (i.e. avoiding needing a pointer elsewhere in order to encapsulate an undefined-length objects within another object) is a key motivator for one style of Ada's dependent types.</p>
<p><a href="https://nytpu.com/gemlog/2024-12-27-2">Here is an addendum detailing dynamic allocation and the secondary stack in much more detail.</a></p>

<p>And now an overview of Ada's type system because I feel them developing dependent types mostly-independently is really just a natural extension of its type system. If you're familiar with Ada already, I'm just going over basic derived types and subtypes, discriminated records, and type predicates. And tangentially things like indefinite types and how they work with subprograms and being nested in other aggregate types.</p>
<p>Firstly, Ada's type system was ahead of its time in 1983, in the sense that it's focused on modeling (and enforcing) the <em>intent</em> of the type, and letting the compiler do the work of mapping your intent to underlying machine types<sup id="fnref:6"><a href="#fn:6">6</a></sup>. So, for instance, while there is an <code>Integer</code> type that corresponds to some efficient machine integer like C's <code>int</code>, unless you need a generic integer you'd typically prefer to do something like this (this is probably not an ideal way to represent a social security number, it's just an example):</p>
<pre>type Social_Security_Number is range 0 .. 999_99_9999;
</pre>
<p>This is a completely new numeric type, but you could also make it derived type of <code>Integer</code> to allow well-defined type conversions, (although the conversions would require an explicit typecast since they're distinct but compatible types. To avoid needing explicit casts you'd use the <code>subtype</code> keyword instead of <code>type</code>).</p>
<p>As an extension of that, arrays allow using arbitrary integer types as their indices. They actually don't need to start at 0 or 1 or anything, they can use any bounds that make the most sense for your application (with the main caveat being that you have to use <code>Arr'First</code> &amp; <code>Arr'Last</code> or <code>Arr'Range,</code> rather than being able to just go from 0 to <code>Arr'Length - 1</code>). So, for instance, here's an array type:</p>
<pre>type My_Integer is range -20 .. 20;
type My_Array_Constrained is array (My_Integer) of Whatever_Type;
</pre>
<p>Or, more concisely if the integer type isn't needed anywhere outside of the array type:</p>
<pre>type My_Array_Constrained is array (-20 .. 20) of Whatever_Type;
</pre>

<p>But that's fairly limiting, because instances of <code>My_Array</code> must always be exactly 41 elements long with bounds from -20 to 20. So you can make an array with bounds determined at instantiation instead of at the type declaration:</p>
<pre>type My_Integer is range -20 .. 20;
type My_Array is array (My_Integer range &lt;&gt;) of Whatever_Type;
</pre>
<p><code>&lt;&gt;</code> is called <q>box</q> and is used all over Ada as a placeholder for some unknown thing (e.g. a placeholder type in generics). Any specific instance of <code>My_Array</code> can have arbitrary lower and upper bounds as long as they're contained within the range of <code>My_Integer</code>.</p>
<p>To use that type, you could make an instance like this:</p>
<pre>Arr_1 : My_Array(-15 .. -5);
Arr_2 : My_Array := (11 =&gt; 0, 12 =&gt; 1, 13 =&gt; 2, 14 =&gt; 3); -- implicitly determined length and bounds
</pre>
<p>It should be noted that while these instances are descendants of <code>My_Array</code>, they are still distinct types that are implicitly created on-the-fly, and are unnamed. You could declare it a new named type instead if you wanted:</p>
<pre>type My_Array_Constrained is new My_Array(-15 .. -5);
Arr_1 : My_Array_Constrained;
</pre>
<p>Both declarations of <code>Arr_1</code> are nearly equivalent, except the second one has a named type and could be easily assigned to another instance of <code>My_Array_Constrained</code> without explicitly copying slices of the same length.</p>
<p>And now we already technically have dependent types, because arrays with indefinite bounds can be created based off of a function parameter or other compile-time unknown value. For example (this is being excessively explicit about named types to prove it's true dependent typing):</p>
<pre>type My_Integer is range -20 .. 20;
type My_Array is array (My_Integer range &lt;&gt;) of Integer;
subtype My_Length is My_Integer range 0 .. My_Integer'Last; -- Technically unnecessary

function Make_Array (Len : My_Length) return My_Array is
   -- Declarative area, where all of the local variables and types and nested
   -- functions and whatever would be declared

   -- Make a subtype using the provided length.  Will raise an exception if
   -- the upper bound is outside of the range of My_Integer.
   subtype Dynamically_Created_Array is My_Array(My_Integer'First .. My_Integer'First + Len);

   -- Create an instance of that subtype with all-zero contents.
   Arr : Dynamically_Created_Array := (others =&gt; 0);
begin
   -- Function body, where the procedural stuff is done.  Presumably we
   -- would do some processing here rather than just returning the array.
   -- Returning Dynamically_Created_Array is safe because it's a compatible
   -- subtype of My_Array.
   return Arr;
end Make_Array;
</pre>

<p>But of course there's more, what if you want to use <code>My_Array</code> inside of a record (Ada's term for a structure)? You could just have one of a fixed length of course:</p>
<pre>type My_Record_Constrained is record
   Field : My_Array(-15 .. -5);
end record;
</pre>
<p>And note that that Field's length can be computed at runtime if you need, just by using a function to compute one or both bounds instead of specifying literals. But all instances of <code>My_Record_Constrained</code> in the entire program would still have the same sized field that's only calculated once, at program startup<sup id="fnref:7"><a href="#fn:7">7</a></sup>.</p>
<p>It'd be really convenient to keep the flexibility to determine the size at instantiation time like we have with standalone arrays. So there's the concept of <q>discriminants</q>, which are like standard record fields but are treated specially and can be depended on by the types of normal fields of the record. For instance:</p>
<pre>type My_Record (Top : My_Integer) is record
   Field : My_Array(My_Integer'First .. Top);
end record;
</pre>
<p><code>My_Integer'First</code> gives the lowest valid value for the integer type. <code>Top</code> can be read like any other record field but you can't modify it after the type is instantiated since that would require reallocation and moving stuff around if there were fields before and after the discriminated array. You'd declare an instance like this to make <code>Rec.Field</code> have bounds from -20 to -5:</p>
<pre>Rec : My_Record(-5);
</pre>

<p>That example could be extended with a second discriminant to allow defining both the start and end bounds, etc. And there, that's it, that's also a dependent type! There is an implicit unnamed type that's recognized by the type system, that depends on a value at runtime. There's other things you can do rather than just using the discriminant as the length of an array. And you can do things like have an embedded record whose discriminant depends on a discriminant in the outer record and such. And there's also <q>variant records</q> which are just tagged unions where the tag (any signed/unsigned integer or enumeration type) is declared in the same place as the discriminant is above.</p>
<p>But Ada 2012 introduced even more capable dependent types as part of its <a href="https://en.wikipedia.org/wiki/Design_by_contract">design by contract system</a><sup id="fnref:8"><a href="#fn:8">8</a></sup>. Say you want to allow <code>My_Record</code> to specify both the lower and upper bounds as discriminants. Well, you can just do that, even though the instantiator could specify a lower bound that's greater than the upper bound, that's fine because in Ada that's just how you make an array with a length of 0. But say, in a contrived example, that you always want at least one element. You could add a type predicate, which is I think is somewhat analogous to what theorem provers would call <q>tactics</q>? You provide an expression acting on the value of the type and will be enforced as being true either at compile-time (for static predicates) or at runtime (for dynamic predicates). For example:</p>
<pre>type My_Record (Top, Bottom : My_Integer) is record
   Field : My_Array(Bottom .. Top);
end record
   with Dynamic_Predicate =&gt; Bottom &lt;= Top;
</pre>

<p>Or you could not use discriminants at all:</p>
<pre>type Pair is record
   A, B : Integer;
end record
   with Dynamic_Predicate =&gt; B &gt; A;
</pre>

<p>Type predicates and invariants (and also function pre/postconditions) are great for non-dependent type uses too, but that's getting too off-topic for this already plodding post. Although it is neat to be able to do things like</p>
<pre>type Even is new Integer
   with Dynamic_Predicate =&gt; Even mod 2 = 0;
</pre>
<pre>type Day_Of_Week is (Sunday, Monday, Tuesday, Wednesday, Thursday, Friday, Saturday);
subtype Weekday is Day_Of_Week range Monday .. Friday;
-- Filthy Americans creating this problem for themselves
subtype Weekend is Day_Of_Week
   with Static_Predicate =&gt; Weekend in Saturday | Sunday;
</pre>


<h2 id="the-strange-interplay-between-academic-languages-and-business-languages">The Strange Interplay Between “Academic Languages” and “Business Languages”</h2>

<p>Something I find very interesting is that there's a strange interplay between a very get-things-done oriented language like SPARK (the formally verified subset of Ada) which wants to verify correctness in a program, and functional programming theory that provides ways to reason about the correctness of programs. And yet functional programming languages themselves nor the theory directly isn't suited for what SPARK does, because they prefer purity and usefulness <em>for developing the theory further</em> over things like allowing side-effects in a way that doesn't confuse imperative programmers (*cough*​monads​*cough*) or the compiled code being efficient enough for low-power embedded targets.</p>
<p>Note that I'm not implying that functional programming languages can't <q>get things done</q>, they just tend to be focused on different goals than Ada and SPARK are. Because if you're interested in the theory why would you care about the small set of high-integrity embedded developers over being able to express what you need to in the most natural way possible? And similarly, SPARK had concrete requirements for a specific set of tasks different from what academics want, and it just happened that theorem provers and FP theory can be applied to those problems to great effect.</p>
<p>I feel somewhat like this with Ada as a whole. Really, lots of its type system often stumbles across interesting concepts in type theory, but just from them reaching for some goal of correctness or flexibility rather than because of actual type theory. Although I haven't had more than a casual IRC chat with any of the standardizers so maybe they did actually get their ideas directly from type theory and just fit them into a non-academic language, rather than stumbling across the concept like I hypothesize here.</p>
<ol>
<li id="fn:1" value="1"><p>Like, Ada's entire design is basically the U.S. DoD making a <a href="https://en.wikisource.org/wiki/Steelman_language_requirements">list of requirements that they considered mandatory for a high-integrity, embedded programming language</a>, and then paying government contractors to design a language meeting those requirements, without caring if it's <q>fun</q> or <q>breaking new ground</q> or <q>mathematical purity</q>. Not that that's necessarily a good design philosophy, it just makes the language very different from many; and is what reminds me of COBOL which was made similarly: businesses designing a language to their requirements without regard for any of the things academic computer scientists of the time cared about. <a href="#fnref:1">↩︎</a></p></li>
<li id="fn:2" value="2"><p>And a natural extension of C's flexible array members if their length was enforced to match to the field in the struct storing it. <a href="#fnref:2">↩︎</a></p></li>
<li id="fn:3" value="3"><p>SPARK, the formally verified subset of Ada, does have a borrow checker though! <a href="#fnref:3">↩︎</a></p></li>
<li id="fn:4" value="4"><p><a href="https://gcc.gnu.org/git/?p=gcc.git;a=blob;f=gcc/ada/libgnat/s-secsta.adb;hb=HEAD#l39">Comments in the GCC GNAT source code</a> and some <a href="https://docs.adacore.com/gnat_ugx-docs/html/gnat_ugx/gnat_ugx/the_stacks.html#the-secondary-stack">documentation on configuring the second stack for embedded targets</a> is the only real documentation on how the second stack works in detail that I know of. Probably because while I consider it a brilliant solution, the secondary stack is actually an implementation detail and the standard just mandates <q>you have to be able to return indefinite types</q>. An implementation could in theory dynamically allocate and insert malloc and free calls appropriately in the caller and callee code. <a href="#fnref:4">↩︎</a></p></li>
<li id="fn:5" value="5"><p>The Ada specification has official, albeit optional-to-implement, APIs for interfacing with all of those languages lol <a href="#fnref:5">↩︎</a></p></li>
<li id="fn:6" value="6"><p>Not relevant to the point I'm making in this post, but if in a given application you do care about the machine types, there is a whole featureset of <q>representation clauses</q> that allow you to very precisely state the underlying size and layout of a primitive type, array, or structure/record. The compiler will generate the required bit-shifts and masks for you when reading or writing fields of an object of that type, and the specified representation is always how it's stored in memory and doesn't need a separate (de)serialization step, making it convenient for memory-mapped I/O (since Ada also lets you specify the precise address of a variable without needing pointers or poking the linker directly).</p>
<p>These features, amongst a few others similarly intended for easy low-level programming, are actually the main reason I personally use Ada since their convenience and simplicity is unmatched in any other programming language in existence AFAIK. <a href="#fnref:6">↩︎</a></p></li>
<li id="fn:7" value="7"><p>To be precise: it is calculated when the <q>elaboration code</q> for the package containing that type is called, which is typically but not always at program startup or when dlopened; but may be at any point prior to the containing package or any dependent package being used. The precise point and order in which elaboration is performed is determined by the <q>binder</q> and may be delayed from program startup if the main() is overridden to be a program in some other language rather than the entrypoint emitted by the binder. <a href="#fnref:7">↩︎</a></p></li>
<li id="fn:8" value="8"><p>The other main thing that I love about the language <a href="#fnref:8">↩︎</a></p></li>
</ol>
		</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Liberating Wi-Fi on the ESP32 [video] (179 pts)]]></title>
            <link>https://media.ccc.de/v/38c3-liberating-wi-fi-on-the-esp32</link>
            <guid>42527265</guid>
            <pubDate>Sat, 28 Dec 2024 00:03:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://media.ccc.de/v/38c3-liberating-wi-fi-on-the-esp32">https://media.ccc.de/v/38c3-liberating-wi-fi-on-the-esp32</a>, See on <a href="https://news.ycombinator.com/item?id=42527265">Hacker News</a></p>
<div id="readability-page-1" class="page">

<div>
<ol>
<li>
<a href="https://media.ccc.de/b">
browse
</a>
</li>
<li>
<span></span>
<a href="https://media.ccc.de/b/congress">
congress
</a>
</li>
<li>
<span></span>
<a href="https://media.ccc.de/b/congress/2024">
2024
</a>
</li>
<li>
<span></span>
event
</li>
</ol>
</div>

<div>

<p>
<span></span>
<a href="https://media.ccc.de/search?p=Frostie314159">Frostie314159</a> and
<a href="https://media.ccc.de/search?p=Jasper+Devreker">Jasper Devreker</a>

</p>

<p><a href="https://media.ccc.de/c/38c3/2024" rel="tag">2024</a>
<a href="https://media.ccc.de/c/38c3/Saal%201" rel="tag">Saal 1</a>
Playlists:
<a href="https://media.ccc.de/v/38c3-liberating-wi-fi-on-the-esp32/playlist">'38c3' videos starting here</a>
/
<a data-method="get" href="https://media.ccc.de/v/38c3-liberating-wi-fi-on-the-esp32/audio">audio</a></p>
<!-- %h3 About -->
<p>Reverse engineering the Wi-Fi peripheral of the ESP32 to build an open source Wi-Fi stack.</p>

<p>During the 38c3, there are probably multiple thousands of ESP32s in the CCH, all of which run a closed source Wi-Fi stack.  And while that stack works, it would be nicer to have an open source stack, which would grant us the ability to modify and audit the software, which carries potentially sensitive data.</p>

<p>So we set to work, reverse engineering the proprietary stack and building a new open source one. We soon discovered just how versatile the ESP32 can be, both as a tool for research and IoT SoC, when its capabilities are fully unlocked. This includes using it as a pentesting tool, a B.A.T.M.A.N. mesh router or an AirDrop client.</p>

<p>You'll learn something about Wi-Fi, the ESP32, reverse engineering in general and how to approach such a project.</p>

<p>Licensed to the public under http://creativecommons.org/licenses/by/4.0</p>

<h3>Download</h3>
<div>

<div>
<h4>These files contain multiple languages.</h4>
<p>
This Talk was translated into multiple languages. The files available
for download contain all languages as separate audio-tracks. Most
desktop video players allow you to choose between them.
</p>
<p>
Please look for "audio tracks" in your desktop video player.
</p>
</div>
<div>
<p>
<h4>Subtitles</h4>
</p>

</div>
<div>
<p>
<h4>Audio</h4>
</p>

</div>
</div>
<!-- %h3 Embed/Share -->

<h3>Tags</h3>

</div>





</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Spotify is full of AI music (137 pts)]]></title>
            <link>https://www.fastcompany.com/91170296/spotify-ai-music</link>
            <guid>42526803</guid>
            <pubDate>Fri, 27 Dec 2024 22:50:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.fastcompany.com/91170296/spotify-ai-music">https://www.fastcompany.com/91170296/spotify-ai-music</a>, See on <a href="https://news.ycombinator.com/item?id=42526803">Hacker News</a></p>
Couldn't get https://www.fastcompany.com/91170296/spotify-ai-music: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Plasticlist Report – Data on plastic chemicals in Bay Area foods (422 pts)]]></title>
            <link>https://www.plasticlist.org/report</link>
            <guid>42525633</guid>
            <pubDate>Fri, 27 Dec 2024 20:15:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.plasticlist.org/report">https://www.plasticlist.org/report</a>, See on <a href="https://news.ycombinator.com/item?id=42525633">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[TSMC's Arizona Plant to Start Making Advanced Chips (181 pts)]]></title>
            <link>https://spectrum.ieee.org/tsmc-arizona</link>
            <guid>42525384</guid>
            <pubDate>Fri, 27 Dec 2024 19:43:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://spectrum.ieee.org/tsmc-arizona">https://spectrum.ieee.org/tsmc-arizona</a>, See on <a href="https://news.ycombinator.com/item?id=42525384">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>TSMC’s manufacturing facility in Phoenix will produce advanced chips using 4-nanometer technology.</p><div data-headline="The U.S. Will Start Manufacturing Advanced Chips"><p><strong>After years of planning,</strong> building, geopolitical wrangling, and workforce challenges, the world’s largest semiconductor foundry, Taiwan Semiconductor Manufacturing Co. (<a href="https://www.tsmc.com/english" rel="noopener noreferrer" target="_blank">TSMC</a>) is officially starting mass production at an advanced chip-manufacturing facility in Phoenix in 2025. The fab represents the arrival of advanced chip manufacturing in the United States and a test of whether the 2022 CHIPS and Science Act can help stabilize the semiconductor-industry supply chain for the United States and its allies.
</p><p>
	In late October 2024, the company announced that 
	<a href="https://www.bloomberg.com/news/articles/2024-10-24/tsmc-s-arizona-chip-production-yields-surpass-taiwan-s-a-win-for-us-push?srnd=undefined" rel="noopener noreferrer" target="_blank">yields</a> at the Arizona plant were 4 percent higher than those at plants in Taiwan, a promising early sign of the fab’s efficiency. The current fab is capable of operating at the 4-nanometer node, the process used to make Nvidia’s most advanced <a href="https://spectrum.ieee.org/tag/gpus">GPUs</a>. A second fab, set to be operational in 2028, plans to offer 2- or 3-nm-node processes. Both 4-nm and more advanced 3-nm chips began high-volume production at other <a href="https://spectrum.ieee.org/tag/tsmc">TSMC</a> fabs in 2022, while the 2-nm node will begin volume production in Taiwan this year. In the future, the company also has plans to open a third fab in the United States that will use more advanced technology.
</p><p>
	The chip-manufacturing giant is currently set to receive US $6.6 billion in CHIPS Act funding for building the first Arizona plant. But government funding isn’t the only reason semiconductor manufacturing is coming back to the United States. TSMC makes 90 percent of the world’s advanced chips, and U.S.-based companies including Apple, <a href="https://spectrum.ieee.org/tag/nvidia">Nvidia</a>, <a href="https://spectrum.ieee.org/tag/google">Google</a>, <a href="https://spectrum.ieee.org/tag/amazon">Amazon</a>, and Qualcomm rely on them. The chip shortages during the economic shock of the early COVID years, and Chinese president Xi Jinping’s increasingly aggressive rhetoric about Taiwan, have made TSMC’s customers and international policymakers uncomfortable.
</p><p>
	TSMC announced their intention to invest in Arizona in 2020. “The CHIPS Act didn’t make it happen—companies have largely moved on their own,” says TechInsights semiconductor analyst 
	<a href="https://www.techinsights.com/our-experts/g-dan-hutcheson" rel="noopener noreferrer" target="_blank">Dan Hutcheson</a>. Big customers like Apple have been pushing TSMC to build fabs elsewhere to minimize risk, he says.
</p><p>
	Hutcheson says having TSMC fabs outside Taiwan is good for the company’s customers and good for Taiwan. The island’s “
	<a href="https://spectrum.ieee.org/taiwan-silicon-shield" target="_self">silicon shield</a>” against China has done its work—TSMC’s dominance in advanced chip manufacturing gives the United States and other countries a reason to support Taiwan. But going forward, Hutcheson says the shield could turn into a target. If the United States and its allies are increasingly dependent on chips made only in Taiwan, then China can cause major damage to the U.S. economy by targeting Taiwan. Hutcheson says TSMC’s geographical diversification will make its home country less of a target. The company has also opened a fab in Japan and is building one in Germany.
</p><h2>TSMC’s Workforce Issues</h2><p>
	Reaction to the Arizona fab in Taiwan has been mixed. An investigation published in 
	<a href="https://restofworld.org/2024/tsmc-arizona-expansion/" rel="noopener noreferrer" target="_blank"><em><em>Rest of World</em></em></a> in April 2024 featured American workers sent to Taiwan to train for a year complaining about poor working conditions and inadequate training; in the same article, Taiwanese workers complained that Americans are arrogant and don’t have the work ethic for a semiconductor fab.
</p><p>
	“TSMC is operated like a military organization. Decisions are top-down and you are not to ask questions,” says University of Chicago economics professor 
	<a href="https://faculty.chicagobooth.edu/chang-tai-hsieh" rel="noopener noreferrer" target="_blank">Chang-Tai Hsieh</a>, who once worked at the company.
</p><p>
	On the other hand, many American engineers espouse the Silicon Valley attitude of “move fast and break things,” says 
	<a href="https://www.hudson.org/experts/jason-hsu" rel="noopener noreferrer" target="_blank">Jason Hsu</a>, a former legislator in Taiwan who is now a specialist in the Indo-Pacific technology industry at the Hudson Institute, a Washington, D.C., think tank. But that’s not an easy fit with a process that can be disrupted by a single speck of dust.
</p><p>
	Hutcheson says these kinds of culture clashes are to be expected—and he says TSMC seems to have worked through them. The problem may have been that the company set unrealistic goals and timelines. TSMC saw building a fab in the United States “as a simple technology problem,” says Hutcheson. “They see it as a skill set that’s universal, but it’s not universal. It’s very culturally and legally dependent.” Each city in the United States may have different building codes and permitting processes, for instance—and that’s different from how things work in Taiwan, he says. As more fabs open, the United States is also 
	<a href="https://spectrum.ieee.org/workforce-shortage" target="_self">facing a shortage</a> of engineers and technicians.
</p><h2>Intel’s and Samsung’s Fab Plans</h2><p>
	TSMC is not the only company planning to open an advanced fab in the United States with support from the CHIPS Act. 
	<a href="https://www.samsung.com/us/" rel="noopener noreferrer" target="_blank">Samsung</a> is also set to receive $6.4 billion in potential funds to open a fab in Taylor, Texas, but the company has delayed production from the second half of 2024 to a possible opening in 2026. Hsieh says culture clash is the least of Samsung’s problems. The company doesn’t have enough customers for the chips it makes in South Korea, and there will not be demand for chips that it might make—likely at higher cost—in Texas, says Hsieh.
</p><p><a href="https://www.intel.com/content/www/us/en/homepage.html" rel="noopener noreferrer" target="_blank">Intel</a> was one of the biggest lobbyists for the CHIPS Act, and has been pursuing a revival of its foundry business since former CEO Pat Gelsinger was appointed to the position in 2021. Intel’s technology has fallen behind, and, like Samsung, the company is struggling to find enough customers. However, <a href="https://spectrum.ieee.org/tag/intel">Intel</a> is planning to open new sites in the United States. An expected $8.5 billion in direct CHIPS Act funds <a href="https://www.tomshardware.com/pc-components/cpus/us-govts-chips-act-gives-intel-dollar85-billion-in-funding-and-a-25-tax-credit-on-dollar100-billion-in-investments" rel="noopener noreferrer" target="_blank">will go toward</a> building advanced fabs in Arizona and Ohio; converting two fabs in New Mexico into packaging facilities; and purchasing the next generation of extreme-ultraviolet lithography equipment for the company’s Oregon facilities.
</p><p>
	At the time of publication, it remains unclear how the Trump administration might seek to alter implementation of the CHIPS Act. Pending any major changes, the opening of TSMC’s Arizona fab will be a test both of the ability of the CHIPS Act to stimulate domestic manufacturing and of the company’s international expansion, says Hutcheson. “What’s going on in Phoenix is quite amazing,” he says. 
	<span></span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I made a web app to bring children's drawings to life (161 pts)]]></title>
            <link>https://doodledreams.cc</link>
            <guid>42524848</guid>
            <pubDate>Fri, 27 Dec 2024 18:50:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://doodledreams.cc">https://doodledreams.cc</a>, See on <a href="https://news.ycombinator.com/item?id=42524848">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[They have not been trained for this – CCC supports train hackers (536 pts)]]></title>
            <link>https://www.ccc.de/en/updates/2024/das-ist-vollig-entgleist</link>
            <guid>42524568</guid>
            <pubDate>Fri, 27 Dec 2024 18:19:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ccc.de/en/updates/2024/das-ist-vollig-entgleist">https://www.ccc.de/en/updates/2024/das-ist-vollig-entgleist</a>, See on <a href="https://news.ycombinator.com/item?id=42524568">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>The Chaos Computer Club (CCC) supports the three hackers who explained in detail at 37C3 how the Polish rail vehicle manufacturer Newag had manipulated its trains in such a way that they could only be repaired in the company's own workshops. The manufacturer reacted to the publications with an attitude not seen since the 90s and sued the hackers under both criminal and civil law. At 38C3, the hackers are now reporting on their legal odyssey, which cost so far around 30,000 euros. The CCC is calling for donations to cover the legal and other resulting costs incurred so far.</p><div><p>In <a href="https://media.ccc.de/v/37c3-12142-breaking_drm_in_polish_trains">one of the most popular presentations at 37C3</a>, the three hackers uncovered something monstrous: Newag trains went into hibernation using a sophisticated game of hide-and-seek if they were parked for too long within the geocoordinates of competitors‘ or customers’ workshops or were left in conditions that indicated they underwent an unregistered repair. Only by calling in a Newag technician could such deactivated trains be ‘rescued’. All of this was uncovered without the potentially illegal replacement of train components which would require certifications.</p>
<p>Nevertheless, Newag's reaction was thin-skinned. We assume that the current lawsuits are aimed at preventing these - and future - publications about such ‘illegal instructions‘. But at Congress, it is not small-minded company lawyers or locomotive builders stuck in the past who decide who is allowed to speak on our stages. Only the content teams do. It is therefore a matter for us to support the three speakers that were presenting at the last congress and now - almost unfortunately - this one, too, so that they can continue researching fearlessly in the future!</p>
<p>If you would like to contribute, please make a transfer to the regular bank account of the Chaos Computer Club e.V. (<tt>DE41 2001 0020 0599 0902 01</tt> / <tt>PBNKDEFFXXX</tt>) with the reference ‘Lokomotive’.</p>
<p>If more than the € 30,000 required to date is donated, if the legal costs are lower or if court costs are repaid, all payments received in excess will be used for the statutory purposes of the Chaos Computer Club e.V.. Please note that the CCC e.V. is not formally recognised as a non-profit organisation.</p>
<p>The sequel will be presented this Friday at 38C3 in Hamburg. The presentation can be followed <a href="https://streaming.media.ccc.de/38c3/eins">in the live stream today</a> (27th Dec 2024) from 11pm and will then be made available at <a href="https://media.ccc.de/">media.ccc.de</a>.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[VW breach exposes location of 800k electric vehicles (209 pts)]]></title>
            <link>https://cyberinsider.com/vw-suffers-major-breach-exposing-location-of-800000-electric-vehicles/</link>
            <guid>42524422</guid>
            <pubDate>Fri, 27 Dec 2024 18:03:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cyberinsider.com/vw-suffers-major-breach-exposing-location-of-800000-electric-vehicles/">https://cyberinsider.com/vw-suffers-major-breach-exposing-location-of-800000-electric-vehicles/</a>, See on <a href="https://news.ycombinator.com/item?id=42524422">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<figure><img decoding="async" width="950" height="484" src="https://mnwa9ap4czgf-u1335.pressidiumcdn.com/wp-content/uploads/2024/12/IMG_0830.png" alt="VW Suffers Major Breach Exposing Location of 800,000 Electric Vehicles" srcset="https://mnwa9ap4czgf-u1335.pressidiumcdn.com/wp-content/uploads/2024/12/IMG_0830-300x153.png 300w, https://mnwa9ap4czgf-u1335.pressidiumcdn.com/wp-content/uploads/2024/12/IMG_0830-768x391.png 768w, https://mnwa9ap4czgf-u1335.pressidiumcdn.com/wp-content/uploads/2024/12/IMG_0830.png 950w" sizes="(max-width: 950px) 100vw, 950px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20950%20484'%3E%3C/svg%3E" data-lazy-srcset="https://mnwa9ap4czgf-u1335.pressidiumcdn.com/wp-content/uploads/2024/12/IMG_0830-300x153.png 300w, https://mnwa9ap4czgf-u1335.pressidiumcdn.com/wp-content/uploads/2024/12/IMG_0830-768x391.png 768w, https://mnwa9ap4czgf-u1335.pressidiumcdn.com/wp-content/uploads/2024/12/IMG_0830.png 950w" data-lazy-src="https://mnwa9ap4czgf-u1335.pressidiumcdn.com/wp-content/uploads/2024/12/IMG_0830.png"></figure>



<p>A massive data leak involving over 800,000 Volkswagen electric vehicles (EVs) has left sensitive user information, including location data and personal contact details, unprotected on the internet. Discovered by a whistleblower and reported by Der Spiegel, the breach highlights significant security shortcomings at VW’s software subsidiary Cariad, exposing vulnerabilities in modern vehicle data handling.</p>



<h3 id="h-gps-locations-exposed">GPS locations exposed</h3>



<p>The data breach, which remained unnoticed by VW for months, involved precise GPS data and personal information linked to owners of VW, Audi, Seat, and Škoda vehicles. Stored on an unprotected Amazon Cloud server, this dataset allowed anyone with basic technical skills to access:</p>



<ul>
<li>Detailed location logs showing exactly where and when cars were parked.</li>



<li>Personal information of owners, such as names, email addresses, and phone numbers.</li>



<li>Insights into users’ routines, workplaces, leisure spots, and even sensitive visits, such as government offices, hospitals, and private establishments.</li>
</ul>



<p>This exposed data posed risks for exploitation by criminals, espionage actors, or hackers, according to Linus Neumann of the Chaos Computer Club (CCC), who equated the situation to leaving “a massive keychain under a flimsy doormat.”</p>



<p>The breach impacted not only individual users but also institutional entities. <a href="https://www.spiegel.de/netzwelt/web/volkswagen-konzern-datenleck-wir-wissen-wo-dein-auto-steht-a-e12d33d0-97bc-493c-96d1-aa5892861027" target="_blank" rel="noreferrer noopener">Der Spiegel's report</a> highlights the following cases:</p>



<ol>
<li>Politician Nadja Weippert, a member of the Green Party and privacy advocate, discovered her movements were meticulously recorded and linked to identifiable personal details. She described the situation as “shocking.”</li>



<li>Markus Grübel, a CDU Bundestag member, expressed similar concerns, noting the event undermines trust in the auto industry.</li>



<li>The Hamburg Police, with 35 EVs in their fleet, were among the affected parties.</li>
</ol>



<p>Data from several countries, including Germany, Israel, and Ukraine, was accessible. In some cases, the GPS data was precise to within 10 centimeters.</p>



<h3 id="h-cariad-s-response"><strong>Cariad’s Response</strong></h3>



<p>In response to the breach, Cariad, Volkswagen’s software arm, acknowledged the issue, stating that the Chaos Computer Club (CCC) had pointed out a misconfiguration in two IT applications on November 26, 2024. The company acted promptly to close the vulnerability the same day. The misconfiguration, which had allowed access to pseudonymized vehicle data, no longer exists.</p>



<p>Cariad emphasized that the data involved was not sensitive personal information like passwords or payment details, and no vehicles or services were impacted. Only certain vehicle data from online-connected cars were affected. The company also confirmed that no unauthorized third-party access occurred, and they have reported the incident to relevant authorities.</p>



<p>Cariad clarified that the data, such as charging behavior and habits, was anonymized and used to improve future vehicle features, such as battery and charging software. No personal user profiles were created, and customers had the option to disable online services at any time.</p>



<p>VW assured customers that all data processing is conducted in compliance with legal requirements and customer consent, with strong privacy measures in place, including data separation, pseudonymization, and strict data usage limits.</p>



<p>However, this latest security lapse at Volkswagen underscores an ongoing pattern of systemic vulnerabilities in the company’s IT infrastructure and data handling practices.</p>



<h3 id="h-vw-s-security-failures">VW's security failures</h3>



<p>Similar concerns have been raised in past reports, including <a href="https://cyberinsider.com/vw-and-audi-customers-exposed-for-years-by-dealership-software-bug/" target="_blank" rel="noreferrer noopener">a 20-year flaw</a> in dealership software that exposed customer data, a five-year <a href="https://cyberinsider.com/chinese-hackers-breached-into-german-carmaker-vw-for-five-years/" target="_blank" rel="noreferrer noopener">espionage operation</a> by Chinese hackers targeting VW’s intellectual property, and critical <a href="https://cyberinsider.com/volkswagen-and-skoda-flaws-allow-engine-disruption-and-owner-data-theft/" target="_blank" rel="noreferrer noopener">vulnerabilities in vehicle systems</a> that allowed remote engine disruption and data theft. Collectively, these incidents highlight the urgent need for VW and other automakers to prioritize cybersecurity as a foundational aspect of their digital and connected services.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Parents of OpenAI Whistleblower Don't Believe He Died by Suicide, Order Autopsy (192 pts)]]></title>
            <link>https://sfist.com/2024/12/26/parents-of-openai-whistleblower-dont-believe-he-died-by-suicide-order-second-autopsy/</link>
            <guid>42524190</guid>
            <pubDate>Fri, 27 Dec 2024 17:38:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sfist.com/2024/12/26/parents-of-openai-whistleblower-dont-believe-he-died-by-suicide-order-second-autopsy/">https://sfist.com/2024/12/26/parents-of-openai-whistleblower-dont-believe-he-died-by-suicide-order-second-autopsy/</a>, See on <a href="https://news.ycombinator.com/item?id=42524190">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="site-main">

        <article>

            <figure>
                
            </figure>

            <div>
                    <p>There is a bit more intrigue around the tragic death late last month of former OpenAI researcher Suchir Balaji, who was found dead in his Lower Haight apartment of an apparent suicide.</p><p>Balaji had only recently become a whistleblower about OpenAI and its use of copyrighted material to train its ChatGPT AI model, <a href="https://www.nytimes.com/2024/10/23/technology/openai-copyright-law.html">speaking to the New York Times</a> in an interview published in October. In addition to the legal issues around consuming copyrighted material, Balaji told the Times it was also "not a sustainable model for the internet ecosystem as a whole."</p><p>On November 26, two days before Thanksgiving, Balaji was <a href="https://sfist.com/2024/12/13/openai-whistleblower-found-dead-in-his-sf-apartment/">found dead in his apartment on Buchanan Street</a>. The medical examiner deemed it a death by suicide, and the SFPD has said there is "no evidence of foul play."</p><p>Balaji's mother, Poornima Ramarao, who lives in the Bay Area, tells Bay Area News Group this week that she and her husband are "demanding a thorough investigation" into their son's death. They do not believe he would have taken his own life, and they say there had been zero indication in his mental state that this could be a possibility.</p><p>"No one believes that he could do that," Ramarao tells the news group. The mother says that she and her husband had last spoken to their son on November 22, in a 10-minute phone call in which he had not indicated anything was wrong. He said he was heading out to get dinner.</p><p>Ramarao said that when she had asked Balaji, who had quit his job at OpenAI over the summer, how he would make a living, he assured he wasn't concerned, and said "money is not important to me — I want to offer a service to humanity."</p><p>Balaji was reportedly working to establish a nonprofit that was centered on machine learning.</p><p>Balaji also reportedly reassurred his parents about his decision to go public with his concerns about OpenAI, and they say they were proud of him and that he was untroubed by his decision. Days before his death, Balaji was named in a legal filing by the New York Times as a person with significant documents to support their case. The Times is among multiple companies suing OpenAI over the use of copyrighted materials.</p><p>"He was very happy," Ramarao tells Bay Area News Group, adding that he had just turned 26 less than a week earlier, and he had spent his birthday backpacking with high school friends in the Catalina Islands. "He had a blast. He had one of the best times of his life," the mother says.</p><p>The parents have hired an attorney, Phil Kearney, and they have commissioned a second, independent autopsy.</p><p><strong>Previously:</strong> <a href="https://sfist.com/2024/12/13/openai-whistleblower-found-dead-in-his-sf-apartment/">OpenAI Whistleblower Found Dead In His SF Apartment</a></p><p><em>If you or someone you know is struggling with feelings of depression or suicidal thoughts, the 988 Suicide &amp; Crisis Lifeline offers free, round-the-clock support, information and resources for help. Call or text the lifeline at 988, or see the 988lifeline.org website, where chat is available.</em></p>
                </div>

            
            

        </article>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Cable-cutting tanker seized by Finland 'was loaded with spying equipment' (210 pts)]]></title>
            <link>https://www.lloydslist.com/LL1151955/Russia-linked-cable-cutting-tanker-seized-by-Finland-was-loaded-with-spying-equipment</link>
            <guid>42524174</guid>
            <pubDate>Fri, 27 Dec 2024 17:36:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.lloydslist.com/LL1151955/Russia-linked-cable-cutting-tanker-seized-by-Finland-was-loaded-with-spying-equipment">https://www.lloydslist.com/LL1151955/Russia-linked-cable-cutting-tanker-seized-by-Finland-was-loaded-with-spying-equipment</a>, See on <a href="https://news.ycombinator.com/item?id=42524174">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                
                <p><em>Eagle S</em>, the Russia-linked tanker suspected of damaging an underwater electricity cable on Christmas Day, was kitted out with special transmitting and receiving devices that were used to monitor naval activity, according to a source with direct involvement in the ship, which has since been detained by Finnish police
            </p></div><div>
<p>RUSSIA-LINKED dark fleet* tanker <em>Eagle S</em> (<a rel="noopener noreferrer" href="https://www.seasearcher.com/vessel/360693/overview" target="_blank">IMO: 9329760</a>), seized by Finland on December 25 for damaging an undersea cable, had transmitting and receiving devices installed that effectively allowed it to become a “spy ship” for Russia, Lloyd’s List has learnt.</p>
<p>
The hi-tech equipment on board was abnormal for a merchant ship and consumed more power from the ship’s generator, leading to repeated blackouts, a source familiar with the vessel who provided commercial maritime services to it as recently as seven months ago.</p>



<p>
As well as <em>Eagle S</em>, another related tanker from the same ownership cluster, UK-sanctioned <em>Swiftsea Rider</em> (<a rel="noopener noreferrer" href="https://www.seasearcher.com/vessel/356589/overview" target="_blank">IMO: 9318539</a>), also had similar equipment installed, Lloyd’s List was told.</p>
<p>
Cook Islands-flagged <em>Eagle S</em> and Honduras-flagged <em>Swiftsea Rider</em> are two of 26 elderly Russia-linked tankers with opaque ownership structures connected to three related shipmanagers, including two sanctioned by the UK government 12 months ago for “propping up Putin’s war machine”.</p>
<p>
The sanctions-circumventing tankers were bought between 2022 and 2023 and placed under bareboat charter arrangements with Eiger Shipping, the shipping arm of Russia oil trader Litasco.</p>
<p><em>Eagle S</em> was boarded by Finnish forces investigating sabotage of the Estlink 2 undersea cable that disrupted the supply of electricity to Estonia from Finland.</p>
<p>
The tanker slowed and dragged its anchor around the cable around midday, December 25, Finland’s police said. Another three cables were also damaged.</p>
<p>
The source, who declined to be identified to protect their safety, supplied at least 60 confidential documents about <em>Eagle S</em> to Lloyd’s List in June, including the vetting report that outlined many safety deficiencies discovered during an inspection undertaken while at anchor in Danish waters that month.</p>
<p>
These documents, and others relating to dark fleet tankers providing confidential and private information about class, insurance, and flag, and other technical and regulatory requirements, were verified as genuine at the time.</p>
<p>
In July, Lloyd’s List reported the serious deficiencies on <em>Eagle S</em> that compromised environmental and crew safety, and underscored the poor maintenance and absence of adherence to regulatory and technical standards for the wider dark fleet.</p>
<p>
The source has since provided additional information, telling Lloyd’s List that an unauthorised person, who was not a seafarer, had been identified on board <em>Eagle S</em>.&nbsp;</p>
<p>
They said listening and recording equipment was brought on to the 20-year-old tanker via “huge portable suitcases” along with “many laptops” that had keyboards for Turkish and Russian languages when calling at Türkiye&nbsp;and Russia.</p>
<p>
The equipment was kept on the bridge or in the “monkey island”, they said. The monkey island is the top-most place on the ship.</p>
<p>
The transmitting and receiving devices were used to record all radio frequencies, and upon reaching Russia were offloaded for analysis.&nbsp;</p>
<p>
“They were monitoring all Nato naval ships and aircraft,” Lloyd’s List was told.&nbsp;</p>
<p>
“They had all details on them. They were just matching their frequencies.
</p>
<p>“Russians, Turkish, Indian radio officers were operating it.”</p>
<p>
<em>Eagle S</em> also dropped “sensors-type devices” in the English Channel during a transit, they said.</p>
<p>
They said no further equipment returned to the ship after it was offloaded for analysis, to their knowledge, but other devices were placed on another related tanker, <em>Swiftsea Rider</em>.</p>
<p>
Claims that Russian-linked merchant ships are being used for spying and sabotage activities in the Baltic Sea where Russia is surrounded by Nato allies underscores the rising geopolitical tension in the region amid calls by European political leaders for increased maritime infrastructure defence.</p>



<p>
The damage to the Estlink 2 cable is the second time vital undersea cables between Nato allies have been damaged in two months, and the first time a commercial ship suspected of sabotage has been taken into custody by authorities.</p>
<p>
In November, China-flagged bulk carrier <em>Yi Peng 3</em> (<a rel="noopener noreferrer" href="https://www.seasearcher.com/vessel/307669/overview" target="_blank">IMO: 9224984</a>)&nbsp;was accused of dragging anchor to damage the C-Lion 1 communication cable connecting Finland and Germany.</p>
<p>
The bulk carrier spent more than four weeks in international waters in the Danish straits as German, Sweden, Danish and Finnish officials investigated but ended up sailing last Saturday.</p>
<p>
The crew on <em>Eagle S</em> would have been aware of its spying activities “as this could not be hidden” but were “threatened with their life, so everybody kept quiet”, the source said.</p>
<p>
“They have replaced captains when they raised this issue,” they said.</p>
<p>
The beneficial owners of <em>Eagle S</em> and <em>Swiftsea Rider</em> are hidden behind complex corporate structures. The registered owner of <em>Eagle S</em> is a single-ship structure that purports to have an office in the business centre of a luxury hotel in Dubai.</p>
<p>
The shipmanager, Mumbai-based <a rel="noopener noreferrer" href="https://www.seasearcher.com/company/515740/overview" target="_blank">Peninsular Maritime India Private Limited</a>&nbsp;cannot be contacted. One of the telephone numbers on its website did not answer. A second number hung up when asked if this was the phone number for Peninsular Maritime. Emails were not answered.</p>
<p>
The company’s website claims the company be registered in England, signalling it is likely a copy-and-paste of a template, commonly found in dark fleet shipping companies.<br>
&nbsp;</p>
<p>* Lloyd’s List defines a tanker as part of the dark fleet if it is aged 15 years or over, anonymously owned and/or has a corporate structure designed to obfuscate beneficial ownership discovery, solely deployed in sanctioned oil trades, and engaged in one or more of the deceptive shipping practices outlined in US State Department guidance issued in May 2020. The figures exclude tankers tracked to government-controlled shipping entities such as Russia’s&nbsp;<a rel="noopener noreferrer" href="https://www.seasearcher.com/company/47511/overview" target="_blank">Sovcomflot</a>, or Iran’s&nbsp;<a rel="noopener noreferrer" href="https://www.seasearcher.com/company/10753/overview" target="_blank">National Iranian Tanker Co</a>, and those already sanctioned.</p>
<p>Download our explainer on the different risk profiles of the dark fleet <a href="https://bit.ly/3Lv5sI4">here</a>&nbsp;</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Scale Model of Boeing 777-300ER, Made from Manila Folders (463 pts)]]></title>
            <link>https://www.lucaiaconistewart.com/model-777</link>
            <guid>42523745</guid>
            <pubDate>Fri, 27 Dec 2024 16:53:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.lucaiaconistewart.com/model-777">https://www.lucaiaconistewart.com/model-777</a>, See on <a href="https://news.ycombinator.com/item?id=42523745">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="site">

        
        
          
            

  


          
        

        <main id="page" role="main">

          

          <div data-type="page" data-updated-on="1561691883296" id="page-5cef0d874437940001629f3f" data-content-field="main-content"><div data-block-type="2" id="block-yui_3_17_2_1_1559268252785_9085">

<p>
  <h2><em>1:60 SCALE MODEL OF AN AIR INDIA BOEING 777-300ER, MADE ENTIRELY FROM MANILA FOLDERS</em></h2>
</p>






















</div><div data-block-type="2" id="block-yui_3_17_2_1_1559266243734_6718">
  <p>This project traces its beginnings to an <a href="https://www.lucaiaconistewart.com/architecture"><span>architecture class</span></a> in high school where we learned to use manila file folders to roughly model our building ideas. The more I worked with paper, the more I fell in love with its versatility. At some point, I got the idea to make a model of an airplane as a way of challenging myself with an unconventional shape.</p><p>Though the project began on a much smaller and simpler scale in mid-2008, it has since evolved through multiple revisions to become a highly detailed, true-to-life representation of a Boeing 777. I originally drew my plans by hand, but my desire to increase the accuracy and amount of detail led me to start using Adobe Illustrator to design and print increasingly intricate parts directly onto the folder.</p><p><em>The project has been in progress since May 2008</em></p>
</div><div data-block-type="2" id="block-yui_3_17_2_1_1559270348562_9530">

<p>
  <h2>HOW THE *#%! DO I DO IT?</h2>
</p>






















</div><div data-block-type="2" id="block-yui_3_17_2_1_1559711406501_11179">
  <h2>RESEARCH</h2><p>I start with as much source material as I can. Often that means photos and videos found on the web, but sometimes I’m lucky enough to get my hands on technical drawings as well. I study these materials to form an understanding of the intrinsic shape and function of the particular section I’m working on. Once I feel confident in my basic understanding of the part, I can begin the design process.</p>
</div><div data-block-type="2" id="block-yui_3_17_2_1_1559711406501_13965">
  <h2>DESIGN</h2><p>Much of my work consists of figuring out how to flatten 3-D shapes into 2-D slices that can be printed onto paper and assembled. I work in Adobe Illustrator to create 2-D plans for all the parts of which the final product will be comprised. I typically start the process by working out the general shape and dimensions of the piece, then I drill down, adding more detail and functionality. Once the design has been “frozen,” I work to break it down into individual pieces and arrange them for printing. Often, if a piece is complex and I’m unsure of how well it will function in reality, I build a small test section to verify my designs.</p>
</div><div data-block-type="2" id="block-yui_3_17_2_1_1559711406501_16684">
  <h2>PRINTING &amp; ASSEMBLY</h2><p>This stage is as time-consuming as the design process. I cut folders down to printer-friendly sizes and print my plans directly onto them. Then, I cut out the individual pieces using an <a href="http://www.xacto.com/products/cutting-solutions/knives/detail/X3201" target="_blank"><span>Xacto knife</span></a>, arrange them into sections, and glue them together with <a href="https://www.aleenes.com/aleenes-clear-gel-tacky-glue" target="_blank"><span>Tacky Glue</span></a>. Often, a complex piece is actually a collection of much smaller sub-sections that each needs to be assembled separately before being joined together; this is especially true of something like the wing, which contains many articulating functions and thousands of parts.</p>
</div><div data-block-type="2" id="block-yui_3_17_2_1_1561353870131_383468">
  <h2>TOOLS</h2><p>My tools of choice include the aforementioned Xacto knife, a cutting mat, straight edges, squares, and a toothpick for the precise application of glue.</p>
</div><div data-block-json="{&quot;hSize&quot;:null,&quot;floatDir&quot;:null,&quot;url&quot;:&quot;https://www.youtube.com/watch?v=77oRSCxGmYA&quot;,&quot;html&quot;:&quot;<iframe src=\&quot;//www.youtube.com/embed/77oRSCxGmYA?wmode=opaque&amp;amp;enablejsapi=1\&quot; height=\&quot;480\&quot; width=\&quot;854\&quot; scrolling=\&quot;no\&quot; frameborder=\&quot;0\&quot; allowfullscreen=\&quot;\&quot;>\n</iframe>&quot;,&quot;resolveObject&quot;:&quot;Video&quot;,&quot;resolvedBy&quot;:&quot;youtube&quot;,&quot;resolved&quot;:true,&quot;description&quot;:&quot;Many people have asked how I design and build the parts for the manila folder 777 I'm putting together, and this video is perhaps the best answer yet. This covers the design and build process for the main landing gear, and was made from almost 130 hours of raw footage.&quot;,&quot;title&quot;:&quot;Manila Folder 777 - Main Landing Gear - Design+Build Time-lapse with Info! **60FPS**&quot;,&quot;height&quot;:480,&quot;thumbnail_width&quot;:480,&quot;width&quot;:854,&quot;version&quot;:&quot;1.0&quot;,&quot;type&quot;:&quot;video&quot;,&quot;thumbnail_height&quot;:360,&quot;authorName&quot;:&quot;Luca Iaconi-Stewart&quot;,&quot;authorUrl&quot;:&quot;https://www.youtube.com/user/lucaiaconistewart&quot;,&quot;providerName&quot;:&quot;YouTube&quot;,&quot;providerUrl&quot;:&quot;https://www.youtube.com/&quot;,&quot;thumbnailUrl&quot;:&quot;https://i.ytimg.com/vi/77oRSCxGmYA/hqdefault.jpg&quot;}" data-block-type="22" id="block-yui_3_17_2_1_1559834399264_13753"><p><iframe scrolling="no" data-image-dimensions="854x480" allowfullscreen="" src="//www.youtube.com/embed/77oRSCxGmYA?wmode=opaque&amp;enablejsapi=1" width="854" data-embed="true" frameborder="0" height="480">
</iframe></p><div><p>Many people have asked how I design and build the parts for the manila folder 777 I'm putting together, and this video is perhaps the best answer yet. This covers the design and build process for the main landing gear, and was made from almost 130 hours of raw footage.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1559269142757_26027">

<p>
  <h2>EXPLORE</h2><h3>CLICK BELOW FOR MORE INFO ON EACH SECTION</h3>
</p>






















</div><div data-block-type="2" id="block-yui_3_17_2_1_1559870775542_20405">
  <h2>FOLLOW ME FOR UPDATES</h2><p>Check out an expansive catalog of photos and videos about the project, and stay tuned for further updates!</p>
</div><div data-block-type="2" id="block-yui_3_17_2_1_1559833812352_13795">

<p>
  <h2>NOTABLE PRESS</h2><h3>CLICK TO VIEW ARTICLES</h3>
</p>






















</div></div>

          

          

        </main>

        

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Notice of Service Closure (248 pts)]]></title>
            <link>https://bench.co/</link>
            <guid>42523061</guid>
            <pubDate>Fri, 27 Dec 2024 15:43:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bench.co/">https://bench.co/</a>, See on <a href="https://news.ycombinator.com/item?id=42523061">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-astro-cid-sckkx6r4="">  <p><img src="https://bench.co/images/logo.svg" alt="Bench Logo"> </p> <div> <h2>Notice of Service Closure</h2> <p>
We regret to inform you that as of December 27, 2024, the Bench platform
    will no longer be accessible. We know this news is abrupt and may cause
    disruption, so we’re committed to helping Bench customers navigate through
    the transition.
</p> <p>
From the entire team at Bench, it has been an absolute privilege to serve
    small businesses for the last 13 years. Thank you for being part of our
    journey.
</p> <p>The Bench Team</p> </div> <div> <h2>What happens next?</h2> <hr> <p>
On this website, by December 30th, customers will receive further
    information about how to access their Bench data.
</p> </div> <div> <h2>Our Recommendation</h2> <hr> <p><img src="https://bench.co/images/logo.svg" alt="arrow"> <img src="https://bench.co/images/arrow.svg" alt="arrow"> <img src="https://bench.co/images/kick-logo.svg" alt="arrow"> </p> <p>
For continued support with your bookkeeping, we recommend <a href="https://kick.co/bench?utm_source=bench&amp;utm_medium=website&amp;utm_campaign=benchreferral" target="_blank">Kick</a>, a modern accounting software, which has created an exclusive offer to
    handle your ongoing needs.
</p> <p><a href="https://kick.co/bench?utm_source=bench&amp;utm_medium=website&amp;utm_campaign=benchreferral" target="_blank">Learn more</a> </p></div> <div> <h2>Frequently asked questions</h2> <astro-island uid="12vuKB" prefix="r0" component-url="/_astro/FAQSection.DBBdZUlW.js" component-export="default" renderer-url="/_astro/client.DDQftVcU.js" props="{}" ssr="" client="load" opts="{&quot;name&quot;:&quot;FAQSection&quot;,&quot;value&quot;:true}" await-children=""><dl></dl><!--astro:end--></astro-island> </div> <p>© Bench 2011-2024</p>  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Fake Nintendo lawyer is scaring YouTubers, and its not clear YouTube can stop it (240 pts)]]></title>
            <link>https://www.theverge.com/2024/12/27/24326278/nintendo-fake-takedowns-youtube-domtendo-dmca</link>
            <guid>42521873</guid>
            <pubDate>Fri, 27 Dec 2024 13:25:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/2024/12/27/24326278/nintendo-fake-takedowns-youtube-domtendo-dmca">https://www.theverge.com/2024/12/27/24326278/nintendo-fake-takedowns-youtube-domtendo-dmca</a>, See on <a href="https://news.ycombinator.com/item?id=42521873">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>In late September, Dominik “Domtendo” Neumayer received a troubling email. He had just featured <em>The</em> <em>Legend of Zelda: Echoes of Wisdom</em> in a series of videos on his YouTube channel. Now, those videos were gone.&nbsp;</p><p>“Some of your videos have been removed,” YouTube explained matter-of-factly. The email said that Domtendo had now received a pair of copyright strikes. He was now just one copyright strike away from losing his 17-year-old channel and the over 1.5 million subscribers he’d built up.&nbsp;</p><p>At least, he would have been, if Domtendo hadn’t spotted something fishy about the takedown notice —&nbsp;something YouTube had missed.&nbsp;</p><p>Domtendo had been a little bit confused right from the start;<strong> </strong>the strikes didn’t make sense. Like countless other creators, Domtendo specializes in “Let’s Play” videos, a well-established genre where streamers play through the entirety of a game on camera.</p><div><p>“The next copyright strike will close your channel”</p></div><p>Nintendo has a complicated relationship with the fans who use its copyrighted works, infamously shutting down all sorts of unauthorized projects by sending cease-and-desists. <a href="https://www.theverge.com/games/24272743/nintendo-retro-game-corps-russ-crandall-profile-youtube-emulation-dmca-takedown-copyright-strike">It has gone after YouTubers</a>, too. But both the Japanese gaming giant and the broader gaming industry typically leave Let’s Plays alone, because they serve as free marketing for their games.</p><p>And yet, YouTube had received a legit-looking request apparently justifying these takedowns under the Digital Millennium Copyright Act (DMCA), signed “Tatsumi Masaaki, Nintendo Legal Department, Nintendo of America.”</p><p>It was in a second email from YouTube that Domtendo spotted something off. The takedown requests came from a <em>personal</em> account at an encrypted email service: “tatsumi-masaaki@protonmail.com”.</p><div><div role="button" aria-label="Zoom" tabindex="0"><figure><div><p><span><img alt="YouTube took action on Domtendo’s videos, even though the requests cited a personal email address." loading="lazy" decoding="async" data-nimg="fill" sizes="(max-width: 1023px) 100vw, 744px" srcset="https://duet-cdn.vox-cdn.com/thumbor/0x0:948x887/376x352/filters:focal(474x444:475x445):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25799995/domtendo_tatsumi_protonmail_hint.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:948x887/384x359/filters:focal(474x444:475x445):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25799995/domtendo_tatsumi_protonmail_hint.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:948x887/415x388/filters:focal(474x444:475x445):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25799995/domtendo_tatsumi_protonmail_hint.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:948x887/480x449/filters:focal(474x444:475x445):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25799995/domtendo_tatsumi_protonmail_hint.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:948x887/540x505/filters:focal(474x444:475x445):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25799995/domtendo_tatsumi_protonmail_hint.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:948x887/640x599/filters:focal(474x444:475x445):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25799995/domtendo_tatsumi_protonmail_hint.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:948x887/750x702/filters:focal(474x444:475x445):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25799995/domtendo_tatsumi_protonmail_hint.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:948x887/828x775/filters:focal(474x444:475x445):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25799995/domtendo_tatsumi_protonmail_hint.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:948x887/1080x1011/filters:focal(474x444:475x445):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25799995/domtendo_tatsumi_protonmail_hint.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:948x887/1200x1123/filters:focal(474x444:475x445):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25799995/domtendo_tatsumi_protonmail_hint.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:948x887/1440x1347/filters:focal(474x444:475x445):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25799995/domtendo_tatsumi_protonmail_hint.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:948x887/1920x1796/filters:focal(474x444:475x445):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25799995/domtendo_tatsumi_protonmail_hint.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:948x887/2048x1916/filters:focal(474x444:475x445):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25799995/domtendo_tatsumi_protonmail_hint.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:948x887/2400x2246/filters:focal(474x444:475x445):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25799995/domtendo_tatsumi_protonmail_hint.jpg 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:948x887/2400x2246/filters:focal(474x444:475x445):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25799995/domtendo_tatsumi_protonmail_hint.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p></div></figure></div><div><figcaption><em>YouTube took action on Domtendo’s videos, even though the requests cited a personal email address.</em></figcaption> <p><cite>Image: Domtendo</cite></p></div></div><p>Fake takedowns are real. <a href="https://transparencyreport.google.com/youtube-copyright/summary?hl=en">YouTube says</a> over six percent of takedown requests through its public webform are likely fake, and the company accepts requests via plain email too, meaning anyone can file them. Fighting fake takedowns can cost creators time, money, and stress. But creators can’t easily be sure that a takedown is fake — and they can lose their entire channel if they get it wrong and clash with a company that has a legitimate copyright claim.</p><p><a href="https://www.theverge.com/games/24272743/nintendo-retro-game-corps-russ-crandall-profile-youtube-emulation-dmca-takedown-copyright-strike">When the well-respected Retro Game Corps</a> received his second Nintendo copyright strike, he publicly declared he would self-censor all his future work to hopefully escape the company’s wrath. But first, he checked that Nintendo’s threat was real. He checked to see who YouTube listed as the complaining party, and that it came from a Nintendo email address. Then he checked with his YouTube Partner Manager to be extra safe.</p><div><p>Rumors of fake Nintendo takedowns have swirled in the past. Earlier this year, <em>Garry’s Mod </em>developer Garry Newman removed<a href="https://www.theverge.com/2024/4/25/24140246/garrys-mod-nintendo-copyright-takedowns-dmca"> 20 years’ worth of Nintendo-related fan content from his sandbox video game</a> over takedown threats. Fans speculated that it may actually have been someone posing as a Nintendo lawyer. But Newman eventually revealed <a href="https://garry.net/posts/aaron-peters">Nintendo was legitimately behind those takedowns</a> despite using seemingly suspicious names and emails.</p></div><p>Domtendo thought he might have an actual case of a Nintendo faker. So he decided to push back. At first, it seemed to work. He emailed YouTube, and it soon reinstated his videos. But Tatsumi was back the next day —&nbsp;this time, emailing Domtendo directly.&nbsp;</p><p>“Dear Domtendo, I represent Nintendo of America Inc. (“Nintendo”) in intellectual property matters,” the first email began. After a bunch of legalese, Tatsumi eventually explains why he’s reaching out: “I submitted a notice through YouTube’s legal copyright system, but the infringing content still appears.”</p><p>He wouldn’t let it go.&nbsp;</p><p>Domtendo wasn’t about to risk his livelihood just in case Tatsumi was real. He got spooked, and began voluntarily pulling his videos off YouTube. But his new pen pal just kept asking for more removals. Tatsumi reached out day after day, sometimes multiple times a day, according to emails shared with <em>The Verge</em>. The threats got weirder, too:</p><p><strong>October 3rd:</strong></p><div><blockquote><p>I ask for your expeditious removal of all infringing material that use Nintendo Switch game emulators by 6th October 2024. Please note that the amount of videos infringing Nintendo’s copyrights is too high to be able to list them all in this e-mail and we hope that you will conscientiously remove all infringing videos before the next week.&nbsp;</p></blockquote></div><p><strong>October 8th:&nbsp;</strong></p><div><blockquote><p>Nintendo hereby prohibits you from any future use of its intellectual and copyrighted property. Existing content may remain as long as there is no request to remove it. Nintendo of America Inc. would like to avoid further legal action and therefore hopes that their intellectual property will no longer be used by you. This cease-and-desist declaration is valid immediately and has been approved by President of Nintendo of America Doug Spencer Bowser.</p></blockquote></div><p><strong>October 12th:</strong>&nbsp;</p><div><blockquote><p>Nintendo of America Inc. (“Nintendo”) will no longer tolerate this behavior and is now on the verge of filing a lawsuit. Note that we work closely with our subsidiary Nintendo of Europe, located in Germany and therefore already have your address from the time you have been Nintendo Partner and/or will receive your new address from the residents’ registration office.”</p></blockquote></div><p>Domtendo began reaching out to friends and fellow content creators, and discovered he wasn’t alone. <a href="https://www.youtube.com/@Waikuteru">Waikuteru</a>, a streamer who develops Zelda mods, had been targeted by Tatsumi as well. Only that time, the takedown notices were filed in Japanese, and YouTube claimed they’d come from a seemingly real email address: <a href="mailto:anti-piracy3@nintendo.co.jp">anti-piracy3@nintendo.co.jp</a>. Whoever submitted those notices claimed to be a “Group Sub-Manager” in Nintendo’s “Intellectual Property Department.”&nbsp;</p><p>Could Tatsumi be legit? Was Domtendo staring down a real threat?&nbsp;</p><p><em>The Verge</em> could find no public record of a Tatsumi Masaaki working for Nintendo of America or Nintendo’s legal team, period. Nintendo did not respond to <em>The Verge</em>’s repeated requests to fact-check whether such a lawyer even exists.&nbsp;</p><p>But there <em>was </em>a person by a similar name <a href="https://patents.google.com/?inventor=Masaaki+Tatsumi);&amp;assignee=Nintendo&amp;oq=inventor:(Masaaki+Tatsumi);+assignee:(Nintendo)">working on Nintendo technology patents</a> in its home country of Japan, public records show, and Domtendo was dismayed to find a Nintendo email address for that person on the public web.&nbsp;</p><div><div role="button" aria-label="Zoom" tabindex="0"><figure><div><p><span><img alt="This is the name of a real person (真章 辰己) who worked for Nintendo out of Kyoto, Japan, but the company wouldn’t tell The Verge one word about it." loading="lazy" decoding="async" data-nimg="fill" sizes="(max-width: 1023px) 100vw, 744px" srcset="https://duet-cdn.vox-cdn.com/thumbor/0x0:2605x1288/376x186/filters:focal(1303x644:1304x645):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25800013/tatsumi_patent.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2605x1288/384x190/filters:focal(1303x644:1304x645):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25800013/tatsumi_patent.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2605x1288/415x205/filters:focal(1303x644:1304x645):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25800013/tatsumi_patent.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2605x1288/480x237/filters:focal(1303x644:1304x645):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25800013/tatsumi_patent.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2605x1288/540x267/filters:focal(1303x644:1304x645):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25800013/tatsumi_patent.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2605x1288/640x316/filters:focal(1303x644:1304x645):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25800013/tatsumi_patent.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2605x1288/750x371/filters:focal(1303x644:1304x645):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25800013/tatsumi_patent.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2605x1288/828x409/filters:focal(1303x644:1304x645):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25800013/tatsumi_patent.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2605x1288/1080x534/filters:focal(1303x644:1304x645):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25800013/tatsumi_patent.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2605x1288/1200x593/filters:focal(1303x644:1304x645):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25800013/tatsumi_patent.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2605x1288/1440x712/filters:focal(1303x644:1304x645):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25800013/tatsumi_patent.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2605x1288/1920x949/filters:focal(1303x644:1304x645):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25800013/tatsumi_patent.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2605x1288/2048x1013/filters:focal(1303x644:1304x645):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25800013/tatsumi_patent.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2605x1288/2400x1187/filters:focal(1303x644:1304x645):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25800013/tatsumi_patent.jpg 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:2605x1288/2400x1187/filters:focal(1303x644:1304x645):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25800013/tatsumi_patent.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p></div></figure></div><div><figcaption><em>This is the name of a real person (</em>真章 辰己) <em>who worked for Nintendo out of Kyoto, Japan</em>, <em>but the company wouldn’t tell The Verge one word about it.</em></figcaption> <p><cite>Image: USPTO</cite></p></div></div><p>To a trained eye, there were signs that Domtendo’s “Tatsumi” was probably a fake. What business would a Japanese game technology inventor have individually chasing down a German YouTuber and threatening them with the laws of the United States? If they were a real lawyer, wouldn’t they know that threatening Domtendo with DMCA 512 is laughable, because that’s the portion of the law that protects platforms like YouTube rather than individual creators?&nbsp;</p><p>But Domtendo didn’t want to take the risk, not without proof. His livelihood was at stake. So as Tatsumi’s email threats rolled in, he reached out to Nintendo himself.&nbsp;</p><p>To his great surprise, Nintendo replied.&nbsp;</p><p>“Please note that <a href="mailto:tatsumi-masaaki@protonmail.com">tatsumi-masaaki@protonmail.com</a> is not a legitimate Nintendo email address and the details contained within the communication do not align with Nintendo of America Inc.’s enforcement practices. We are investigating further,” the company’s legal department wrote on October 10th, according to a screenshot shared with <em>The Verge</em>.</p><div><div role="button" aria-label="Zoom" tabindex="0"><figure><div><p><span><img alt="Here’s how Nintendo replied to Domtendo." loading="lazy" decoding="async" data-nimg="fill" sizes="(max-width: 1023px) 100vw, 744px" srcset="https://duet-cdn.vox-cdn.com/thumbor/0x0:1074x726/376x254/filters:focal(537x363:538x364):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25800023/domtendo_nintendo_screenshot.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1074x726/384x260/filters:focal(537x363:538x364):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25800023/domtendo_nintendo_screenshot.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1074x726/415x281/filters:focal(537x363:538x364):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25800023/domtendo_nintendo_screenshot.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1074x726/480x324/filters:focal(537x363:538x364):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25800023/domtendo_nintendo_screenshot.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1074x726/540x365/filters:focal(537x363:538x364):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25800023/domtendo_nintendo_screenshot.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1074x726/640x433/filters:focal(537x363:538x364):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25800023/domtendo_nintendo_screenshot.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1074x726/750x507/filters:focal(537x363:538x364):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25800023/domtendo_nintendo_screenshot.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1074x726/828x560/filters:focal(537x363:538x364):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25800023/domtendo_nintendo_screenshot.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1074x726/1080x730/filters:focal(537x363:538x364):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25800023/domtendo_nintendo_screenshot.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1074x726/1200x811/filters:focal(537x363:538x364):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25800023/domtendo_nintendo_screenshot.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1074x726/1440x973/filters:focal(537x363:538x364):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25800023/domtendo_nintendo_screenshot.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1074x726/1920x1298/filters:focal(537x363:538x364):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25800023/domtendo_nintendo_screenshot.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1074x726/2048x1384/filters:focal(537x363:538x364):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25800023/domtendo_nintendo_screenshot.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1074x726/2400x1622/filters:focal(537x363:538x364):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25800023/domtendo_nintendo_screenshot.jpg 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:1074x726/2400x1622/filters:focal(537x363:538x364):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25800023/domtendo_nintendo_screenshot.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p></div></figure></div><p><figcaption><em>Here’s how Nintendo replied to Domtendo.</em></figcaption></p></div><p>Even then, Domtendo didn’t feel safe. He’d seen how Waikuteru had received a legal threat that seemingly came from a legitimate Nintendo email. Perhaps Tatsumi just wasn’t using his proper email account? Domtendo tried emailing “tasumi_masaaki@nintendo.co.jp” to find out.&nbsp;</p><p>His anxiety ratcheted even higher when Tatsumi’s next email arrived, asking him not to send email to that address. “Please understand that matters are not currently handled from there,” he wrote. Even though it seemed impossible that Tatsumi could be real, he somehow knew things that he shouldn’t.</p><p>Then, on October 18th, Tatsumi suddenly changed his tune: “Dear Domtendo, I hereby retract all of my preceding claims.”</p><div><div role="button" aria-label="Zoom" tabindex="0"><figure><div><p><span><img alt="The end?" loading="lazy" decoding="async" data-nimg="fill" sizes="(max-width: 1023px) 100vw, 744px" srcset="https://duet-cdn.vox-cdn.com/thumbor/0x0:987x810/376x309/filters:focal(494x405:495x406):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25800026/the_end_o.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:987x810/384x315/filters:focal(494x405:495x406):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25800026/the_end_o.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:987x810/415x341/filters:focal(494x405:495x406):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25800026/the_end_o.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:987x810/480x394/filters:focal(494x405:495x406):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25800026/the_end_o.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:987x810/540x443/filters:focal(494x405:495x406):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25800026/the_end_o.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:987x810/640x525/filters:focal(494x405:495x406):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25800026/the_end_o.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:987x810/750x616/filters:focal(494x405:495x406):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25800026/the_end_o.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:987x810/828x680/filters:focal(494x405:495x406):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25800026/the_end_o.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:987x810/1080x886/filters:focal(494x405:495x406):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25800026/the_end_o.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:987x810/1200x985/filters:focal(494x405:495x406):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25800026/the_end_o.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:987x810/1440x1182/filters:focal(494x405:495x406):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25800026/the_end_o.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:987x810/1920x1576/filters:focal(494x405:495x406):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25800026/the_end_o.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:987x810/2048x1681/filters:focal(494x405:495x406):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25800026/the_end_o.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:987x810/2400x1970/filters:focal(494x405:495x406):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25800026/the_end_o.jpg 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:987x810/2400x1970/filters:focal(494x405:495x406):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25800026/the_end_o.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p></div></figure></div><p><figcaption><em>The end?</em></figcaption></p></div><p>Tatsumi wasn’t done with Domtendo quite yet. Two more emails arrived the same day, explaining that while Nintendo had “suspended” him from filing copyright infringement claims, his Nintendo colleagues would now file them on his behalf. Hours later, Domtendo received what was in some ways the most legit-looking email yet, seemingly sent from anti-piracy3@nintendo.co.jp rather than a personal email address.&nbsp;</p><p>But that email turned out to be Tatsumi’s undoing, when Domtendo checked the headers and discovered they’d spoofed Nintendo’s email address using a publicly available tool on the web. I took the tool for a spin, and sure enough — <a href="https://support.google.com/mail/answer/29436?hl=en">unless you check</a>, anyone can make an email look like it was sent from Nintendo that way.&nbsp;</p><p>Domtendo still doesn’t understand how “Tatsumi” knew he’d emailed the real Tatsumi at Nintendo. He changed his passwords and reformatted his computer, just to be safe. Today, his best guess is that the troll was lurking in his personal Discord channel.&nbsp;</p><p>He’s angry at YouTube for letting this happen. “It’s their fault,” he tells me. “Every idiot can strike every YouTuber and there is nearly no problem to do so. It’s insane,” he writes. “It has to change NOW.”</p><div><p>“Every idiot can strike every YouTuber”</p></div><p>It’s true there isn’t a terribly high bar to submit a YouTube copyright claim, something that YouTube itself admits. Currently, bad actors just need to fill in a form on a website, a place where YouTube sees a “10 times higher attempted abuse rate” than tools with more limited access. Or they can just email YouTube’s copyright department directly. And while <a href="https://www.law.cornell.edu/uscode/text/17/512#:~:text=Elements%20of%20notification">the law</a> technically requires a copyright holder to provide their name and address and state “under penalty of perjury” that they’re authorized to complain on Nintendo’s behalf, there’s nothing compelling YouTube to check they aren’t lying before slapping creators with penalties.&nbsp;</p><div><div role="button" aria-label="Zoom" tabindex="0"><figure><div><p><span><img alt="Photo collage of Blue shells from Mario Kart launching at an anonymous figure." loading="lazy" decoding="async" data-nimg="fill" sizes="(max-width: 1023px) 100vw, 744px" srcset="https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/376x251/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25703633/247348_Nintendo_targeting_Youtuber_CVirginia_A.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/384x256/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25703633/247348_Nintendo_targeting_Youtuber_CVirginia_A.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/415x277/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25703633/247348_Nintendo_targeting_Youtuber_CVirginia_A.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/480x320/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25703633/247348_Nintendo_targeting_Youtuber_CVirginia_A.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/540x360/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25703633/247348_Nintendo_targeting_Youtuber_CVirginia_A.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/640x427/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25703633/247348_Nintendo_targeting_Youtuber_CVirginia_A.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/750x500/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25703633/247348_Nintendo_targeting_Youtuber_CVirginia_A.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/828x552/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25703633/247348_Nintendo_targeting_Youtuber_CVirginia_A.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/1080x720/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25703633/247348_Nintendo_targeting_Youtuber_CVirginia_A.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/1200x800/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25703633/247348_Nintendo_targeting_Youtuber_CVirginia_A.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/1440x960/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25703633/247348_Nintendo_targeting_Youtuber_CVirginia_A.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/1920x1280/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25703633/247348_Nintendo_targeting_Youtuber_CVirginia_A.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/2048x1365/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25703633/247348_Nintendo_targeting_Youtuber_CVirginia_A.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/2400x1600/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25703633/247348_Nintendo_targeting_Youtuber_CVirginia_A.jpg 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/2400x1600/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25703633/247348_Nintendo_targeting_Youtuber_CVirginia_A.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p></div></figure></div><p><h2><a href="https://www.theverge.com/games/24272743/nintendo-retro-game-corps-russ-crandall-profile-youtube-emulation-dmca-takedown-copyright-strike">Why is Nintendo targeting this YouTuber?</a></h2></p><p>Russ Crandall, aka Retro Game Corps, was actually targeted by Nintendo. <a href="https://www.theverge.com/games/24272743/nintendo-retro-game-corps-russ-crandall-profile-youtube-emulation-dmca-takedown-copyright-strike">Here’s the story</a> of  how the Japanese game company (and YouTube) are threatening his livelihood.</p><p>If you have first-hand information about Nintendo, you can reach me securely on Signal at <strong>seanhollister.01</strong>. </p></div><p>The thing to remember is the DMCA’s “Safe Harbor” isn’t here to protect creators, EFF legal director Corynne McSherry explained to me in 2022. When rightsholders realized they wouldn’t be able to sue every uploader, and internet platforms realized they wouldn’t be able to survive under an onslaught of uploader lawsuits, the law became a compromise to protect platforms from liability as long as they remove infringing content fast. </p><p>“It creates a situation where service providers have very strong incentives to respond,” said McSherry. “They don’t want to mess around and try to figure out if they might be liable or not.”</p><p>Waikuteru and Rimea, a pair of other creators harassed by Tatsumi, agree that the YouTube system is unfair. Neither know for sure whether trolls were responsible for all the takedown notices they’re received, and that’s part of the problem. “The idea that months of worries were caused by a single troll as opposed to a big untouchable company is a hard pill to swallow either way,” says Rimea.&nbsp;</p><p>But they also claim YouTube doesn’t allow smaller channels to challenge copyright strikes in the first place, arguing that it automatically and arbitrarily rejects the legal notices that would let them reinstate their videos. “YouTube decides whether someone loses his channel based on channel size,” says Waikuteru.&nbsp;</p><p>YouTube isn’t particularly interested in talking about any of this, though.&nbsp;</p><p>While YouTube spokesperson Jack Malon did confirm that “Tatsumi” made false claims, the company wouldn’t explain why the company even briefly accepted false claims from a protonmail.com email address as legitimate, and repeatedly dodged questions about whether Tatsumi made false claims on other creators’ videos, too. </p><p>YouTube wouldn’t even tell me whether Domtendo was still in danger of false copyright claims from this specific individual, or offer assurances that it would take any new action to prevent this sort of behavior in the future.&nbsp;</p><p>Malon does claim that YouTube has “dedicated teams working to detect and prevent abuse,” however, and “work to ensure that any associated strikes are reversed” when bad actors make false claims.&nbsp;</p><p>As for the troll, Tatsumi declined <em>The Verge</em>’s interview request. “Dear Sean, I am an authorized agent for Nintendo of America Inc,” they replied, staying in character to the very end.&nbsp;</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Does current AI represent a dead end? (494 pts)]]></title>
            <link>https://www.bcs.org/articles-opinion-and-research/does-current-ai-represent-a-dead-end/</link>
            <guid>42521865</guid>
            <pubDate>Fri, 27 Dec 2024 13:24:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bcs.org/articles-opinion-and-research/does-current-ai-represent-a-dead-end/">https://www.bcs.org/articles-opinion-and-research/does-current-ai-represent-a-dead-end/</a>, See on <a href="https://news.ycombinator.com/item?id=42521865">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <!--Header-->
        
        <!--header-->


        





    <main id="main-content-hub">
        


            <div>
                                <p>Eerke Boiten, Professor of Cyber Security at De Montfort University Leicester, explains his belief that current AI should not be used for serious applications.</p>
                            </div>


            <section>


<div>
                    <p>From the perspective of <a href="https://www.bcs.org/articles-opinion-and-research/how-to-become-a-software-engineer/">software engineering</a>, current AI systems are unmanageable, and as a consequence their use in serious contexts is irresponsible. For foundational reasons (rather than any temporary technology deficit), the tools we have to manage complexity and scale are just not applicable.</p>
<p>By ‘software engineering’, I mean developing software to align with the principle that impactful software systems need to be trustworthy, which implies their development needs to be managed, transparent and accountable. I don’t suggest any particular methodologies or tools (before you know it, I’d have someone explaining why ‘waterfall’ is wrong!) — but there are some principles which I believe to be both universal and unsatisfiable with current AI systems.</p>
<p>When I last gave talks about AI ethics, around 2018, my sense was that AI development was taking place alongside the abandonment of responsibility in two dimensions. Firstly, and following on from what was already happening in ‘big data’, the world stopped caring about where AI got its data — fitting in nicely with ‘<a href="https://www.amazon.co.uk/Age-Surveillance-Capitalism-Future-Frontier/dp/1781256845">surveillance capitalism</a>. And secondly, contrary to what professional organisations like BCS and ACM had been preaching for years, the outcomes of AI algorithms were no longer viewed as the responsibility of their designers — or anybody, really.</p>
<p>‘Explainable AI’ and some ideas about mitigating bias in AI were developed in response to this, and for a while this looked promising — but unfortunately, the data responsibility issue has not gone away, and the major developments in AI since then have made responsible engineering only more difficult.</p>
<h2>How neural networks work</h2>
<p>When I say ‘current AI systems’, I mean systems based on large neural networks, including most generative AI, large language models (LLMs) like ChatGPT, most of what DeepMind and OpenAI are producing and developing, and so on. An extremely optimistic view of these is what I would call ‘LLM-functionalism’: the idea that a natural language description of the required functionality fed to an LLM, possibly with some prompt engineering, establishes a meaningful implementation of the functionality.</p>
<p>The neural networks underlying these systems have millions of ‘nodes’ or ‘neurons’. Each has one output and multiple inputs, which either originate externally to the entire network or are taken from other nodes’ outputs. A node’s output is determined by the inputs, the weights put on each input, and an ‘activation function’ that decides how the weighted inputs translate into an output. The connection structure is fixed, using connected ‘layers’ or other structures such as recurrent networks or transformers, as is the activation function. The fixed structure is relevant to what type of problems the network can deal with, but the network’s functionality is almost entirely introduced by ‘training’, which means setting and modifying the weights of each input until the outputs achieve an objective satisfactorily on a set of training data.</p>
<p>The training of the huge networks that make up current AI systems has typically taken an astronomical amount of compute, measurable in the millions of dollars or kWh, and will necessarily have been mostly unsupervised or self-supervised. Put bluntly, it will have required no human input – though there may have been some human tuning afterwards (such as reinforcement learning from human feedback (RLHF) or ‘guard rails’), or when the system runs (such as context and prompt engineering).</p>
<h2>Emergence and compositionality</h2>
<p>Many of these neural network systems are stochastic, meaning that providing the same input will not always lead to the same output. The behaviour of such AI systems is ‘emergent’ — which means despite the fact that the behaviour of each neuron is given by a precise mathematical formula, neither this behaviour nor the way the nodes are connected are of much help in explaining the network’s overall behaviour.</p>
<p>My first 20 years of research were in formal methods, where <a href="https://link.springer.com/book/10.1007/978-3-319-92711-4">mathematics and logic are used to ensure systems operate according to precise formal specifications</a>, or at least to support verification of implemented systems. Software engineering, and particularly formal methods, <a href="https://www.sciencedirect.com/science/article/pii/S1571066105050966">has not been as successful in managing emergent behaviour</a> or even the aspects of ‘traditional’ systems that have emergent tendencies such as resource usage or security. This is for foundational reasons rather than for a lack of scientific effort.</p>
                </div>

<div>

                        <blockquote>

                                            <p>
                                                For you
                                            </p>
<p>Be part of something bigger,<span>&nbsp;</span><a href="https://www.bcs.org/membership-and-registrations/become-a-member/" title="Become a member">join BCS, The Chartered Institute for IT</a>.</p>

                        </blockquote>
<p><a href="https://link.springer.com/book/10.1007/3-540-49213-5">A central property in formal software engineering is compositionality</a>: the idea that composite systems can be understood in terms of the meanings of their parts and the nature of the composition, rather than by having to look at the parts themselves.</p>
<p>This idea lies at the heart of piecewise development: parts can be engineered (and verified) separately and hence in parallel, and reused in the form of modules, libraries and the like in a ‘black box’ way, with re-users being able to rely on any verification outcomes of the component and only needing to know their interfaces and their behaviour at an abstract level. Reuse of components not only provides increased confidence through multiple and diverse use, but also saves costs.</p>
<h2>Issues arising from emergent over compositional</h2>
<p>Unfortunately, my informal definitions of ‘emergent’ and ‘compositionality’ are almost exact opposites, and this raises several issues:</p>
<ul>
<li>Current AI systems have no internal structure that relates meaningfully to their functionality. They cannot be developed, or reused, as components. There can be no separation of concerns or piecewise development. A related issue is that most current AI systems do not create explicit models of knowledge — in fact, many of these systems developed from techniques in image analysis, where humans have been notably unable to create knowledge models for computers to use, and all learning is by example (‘<a href="https://www.acluohio.org/en/cases/jacobellis-v-ohio-378-us-184-1964#:~:text=TheU.S.SupremeCourtreversed,tohardcorepornography...">I know it when I see it</a>’). This has multiple consequences for development and verification.</li>
<li>There are no intermediate models at different levels of abstraction to describe the system. There is no possibility for stepwise development — using either informal or formal methods.</li>
<li>Systems are not explainable, as they have no model of knowledge and no representation of any ‘reasoning’.</li>
<li>Even a ‘human in the loop’ adds little explainability, as they can only explain system outcomes (and learn from them) by doing their own reasoning on the input data from scratch.</li>
</ul>
<h2>Verification</h2>
<p>Verification comes with a subset of issues following from the above. The only verification that is possible is of the system in its entirety; if there are no handles for generating confidence in the system during its development, we have to put all our eggs in the basket of post-hoc verification. Unfortunately, that is severely hampered, following from the issues listed above:</p>
<ul>
<li>Current AI systems have input and state spaces too large for exhaustive testing.</li>
<li>A correct output on a test of a stochastic system only evidences that the system has the capability to respond correctly to this input, but not that it will do this always or frequently enough.</li>
<li>Lacking components, current AI systems do not allow verification by parts (unit testing, integration testing, etc).</li>
<li>As the entire system is involved in every computation, there are no meaningful notions of coverage to gain confidence from non-exhaustive whole system testing.</li>
</ul>
<p>So, whole system testing is the only verification tool available, but it can never represent more than a drop in the ocean.</p>
<h2>Faults</h2>
<p>There are serious additional issues around faults and fixing. Faults may arise from unreliable input data, which certainly applies to many generative AI systems, but also from training data being sparse in parts of the input domain.</p>
<ul>
<li>Current AI systems have faults, but even their error behaviour is likely emergent, and certainly hard to predict or eradicate.</li>
<li>Given the relative efforts of unsupervised training versus human error correction and feedback learning, there can never be confidence in correctness, arguing from scale alone.</li>
<li>Fixes of errors through retraining are not localised and regression testing is not possible, so newly introduced errors are likely, but not easily discoverable.</li>
</ul>
<h2>Conclusions</h2>
<p>In my mind, all this puts even state-of-the-art current AI systems in a position where professional responsibility dictates the avoidance of them in any serious application. When all its techniques are based on testing, AI safety is an intellectually dishonest enterprise.</p>
<p>So, is there hope? I believe — though I would be happy to be proved wrong on this — that current generative AI systems represent a dead end, where exponential increases of training data and effort will give us modest increases in impressive plausibility but no foundational increase in reliability. I would love to see compositional approaches to neural networks, hard as it appears.</p>
<p>However, <a href="https://aisafety.dance/">hybrids between symbolic and intuition-based AI</a> should be possible — systems that do generate some explicit knowledge models or confidence levels, or that are coupled with more traditional data retrieval or theorem proving. Current AI systems also have a role to play as components of larger systems in limited scopes where their potentially erroneous outputs can be reliably detected and managed, or in contexts such as weather prediction where we had always expected stochastic predictions rather than certainty.</p>                </div>

            </section>



    
        <!-- topics -->
        <!-- related -->
        <div>
                        <p>
                            <h2>Related</h2>
                        </p>
                    </div>


        <!--page sharing modal-->


            
        <!--modal-->
    </main>







<!--footer-->

<!--footer-->
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The new science of controlling lucid dreams (146 pts)]]></title>
            <link>https://www.scientificamerican.com/article/engineering-lucid-dreams-could-improve-sleep-and-defuse-nightmares/</link>
            <guid>42521795</guid>
            <pubDate>Fri, 27 Dec 2024 13:11:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.scientificamerican.com/article/engineering-lucid-dreams-could-improve-sleep-and-defuse-nightmares/">https://www.scientificamerican.com/article/engineering-lucid-dreams-could-improve-sleep-and-defuse-nightmares/</a>, See on <a href="https://news.ycombinator.com/item?id=42521795">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p data-block="sciam/paragraph"><span>I</span> routinely control my own dreams. During a recent episode, in my dream laboratory, my experience went like this: I was asleep on a twin mattress in the dark lab room, wrapped in a cozy duvet and a blanket of silence. But I felt like I was awake. The sensation of being watched hung over me. Experimenters two rooms over peered at me through an infrared camera mounted on the wall. Electrodes on my scalp sent them signals about my brain waves. I opened my eyes—at least I thought I did—and sighed. Little specks of pink dust hovered in front of me. I examined them curiously. “Oh,” I then thought, realizing I was asleep, “this is a dream.”</p><p data-block="sciam/paragraph">In my dream I sat up slowly, my body feeling heavy. In reality I lay silently and moved my eyes left to right behind my closed eyelids. This signal, which I had learned to make through practice, was tracked by the electrodes and told the experimenters I was lucid: asleep yet aware I was dreaming. I remembered the task they had given me before I went to sleep: summon a dream character. I called out for my grandmother, and moments later simple black-and-white photographs of her appeared, shape-shifting and vague. I could sense her presence, a connection, a warmth rolling along my spine. It was a simple and meaningful dream that soon faded into a pleasant awakening.</p><p data-block="sciam/paragraph">Once I was awake, the scientists at the Dream Engineering Lab I direct at the University of Montreal asked me, through the intercom, about my perception of characters, any interactions with them and how they affected my mood on awakening. Even in her unusual forms, my grandmother had felt real, as if she had her own thoughts, feelings and agency. Reports from other dreamers often reflect similar sensations—the result of the brain’s striking ability in sleep to create realistic avatars we can interact with. Researchers suspect that these dreamy social scenarios help us learn how to interact with people in waking life.</p><hr><h2>On supporting science journalism</h2><p>If you're enjoying this article, consider supporting our award-winning journalism by<!-- --> <a href="https://www.scientificamerican.com/getsciam/">subscribing</a>. By purchasing a subscription you are helping to ensure the future of impactful stories about the discoveries and ideas shaping our world today.</p><hr><p data-block="sciam/paragraph">Many people have had lucid dreams. Typically you are immersed in an experience, then something seems “off,” and you realize you are actually dreaming. Often people wake up right after they become lucid, but with practice you can learn how to remain lucid and try to direct what happens. In the lab we can prime sleepers to have lucid dreams by waking them and then prompting them as they fall back asleep. At home you can try waking up and visualizing a lucid dream (most effectively in the early morning), creating a strong intention to become lucid before falling asleep again.</p><p data-block="sciam/paragraph">In the past few years scientists have discovered that while someone is having a lucid dream, they can communicate with an experimenter in a control room, and that person can communicate with the dreamer, giving them instructions to do something within the dream. In a landmark paper published in 2021 in <i>Current Biology,</i> researchers in the U.S., the Netherlands, France and Germany provided evidence of two-way, real-time communication during lucid dreams. At two locations researchers presented spoken math problems to sleeping participants, who accurately computed the correct solution. When one team asked, “What is eight minus six?” the dreamers answered with two left-right eye movements. Another team asked yes-or-no questions, and lucid dreamers frowned to indicate “no” and smiled for “yes,” with their movements recorded by electrodes around their eyebrows and mouth.</p><p data-block="sciam/paragraph">Sleep researchers are now using emerging technologies to interface directly with the dreaming mind. Meanwhile neuroimaging studies are revealing the unique patterns of brain activity that arise during lucid dreaming. This research could lead to wearable devices programmed with algorithms that detect opportune moments to induce lucidity in people as they sleep. As researchers, we are excited about this possibility because directing, or “engineering,” a dream may allow people to reduce the severity or frequency of nightmares, improve sleep quality and morning mood, and even enhance general health and well-being.</p><hr data-block="sciam/raw_html"><p data-block="sciam/paragraph">Scientists have known that lucid dreams are real since the late 1970s. In 1980 Stephen LaBerge, then a Ph.D. student at Stanford University, published a paper about the side-to-side eye-signaling method that proved lucidity’s existence. Experts went on to demonstrate that lucid dreamers could control their breathing patterns and muscle twitches, which provided ways for them to communicate with the awake world. Imaging studies revealed more wakelike activity in the brain during lucid dreams than nonlucid dreams. This momentum culminated in the first Dream x Engineering Workshop at the Massachusetts Institute of Technology Media Laboratory, which I led in 2019. LaBerge was there, along with 50 dream scientists from around the world. For two days we explored how we might engineer dreams. We focused on using new technologies to induce lucid dreams in novices and exploring the brain basis and health benefits of lucid dreaming on a larger scale.</p><p data-block="sciam/paragraph">Since then, many more researchers have become interested; progress has been quick and revealing. Investigators working in more than a dozen countries have learned how to induce and record lucid dreams with wearable devices and even use the techniques to treat nightmares, insomnia, and other sleep problems.</p><blockquote data-block="contentful/pullquote"><p>Lucid dreamers can communicate with people in the waking world by making eye movements, frowning or clenching their hands.</p></blockquote><p data-block="sciam/paragraph">Treating nightmares is an important goal because they are linked to all manner of psychiatric and sleep disorders, including addiction, psychosis, narcolepsy and insomnia, as well as higher risks for anxiety, depression and suicide. The perils are especially relevant for people with post-­traumatic stress disorder who experience nightmares, which for more than half of PTSD patients replay traumatic events again and again, potentially retraumatizing them each time. PTSD sufferers with severe nightmares have more acute symptoms and a fourfold greater risk of suicide compared with people with PTSD who don’t experience such dreams.</p><p data-block="sciam/paragraph">In a recent study, 49 PTSD patients from nine countries who had long histories of traumatic nightmares attended a week-long virtual workshop with lucid dreaming expert, trainer and author Charlie Morley. To learn how to induce lucid dreams that might heal, participants imagined positive versions of their nightmares in which they engaged curiously with the dream or with threatening dream characters. One patient reported calling out into the dreamscape, “Dreamer, heal my body!” She then experienced roaring in her ears as her body vibrated forcefully. Another patient asked to meet and befriend her anxiety, which led to the emergence of a giant, golden lozenge that evoked her amazement and gratitude. After just one week of training, all the participants had reduced their PTSD symptoms. They also recalled fewer nightmares.</p><p data-block="sciam/paragraph">Laboratory studies have yielded similar results. One person with weekly nightmares took part in a study led by one of my lab members, Remington Mallett. While sleeping in an enclosed lab bedroom with more than a dozen electrodes pasted on her scalp and face, this young woman had a nightmare. She dreamed she was in a church parking lot, and an approaching group of people with pitchforks was chanting, “Die, die, die.” She realized she was asleep and dreaming in the lab and that the experimenter was watching from the other room. She gave a left-right eye signal, knowing the experimenter would wake her up. She later said, “In the dream I was aware that you [the experimenters] were there and reachable.” She gave the signal because she knew it would get her out of the dream, and it did. Her nightmare frequency decreased after this lab visit, and four weeks later it was still lower than it had been before the experiment.</p><p data-block="sciam/paragraph">Even just the moment of becoming lucid can sometimes bring immediate relief from a nightmare because you realize you are dreaming and that there is no real danger—similar to the relief we feel when we wake up from a nightmare and realize it was just a dream. Often when people become lucid during a nightmare, they decide to simply wake up—an immediate solution. Closing and opening your eyes repeatedly is another way to intentionally wake up from a dream, which could be useful during nightmares when at home, outside a lab.</p><p data-block="sciam/paragraph">Lucid dreaming could improve sleep health more generally. For example, we now know that people with insomnia have more unpleasant dreams than sound sleepers, including dreams in which they feel like they are awake and are worrying about not sleeping. In one recent study, insomnia patients underwent two weeks of lucid-­dream training that included setting presleep intentions of becoming lucid and visualizing the kind of lucid dream they wanted to have. These practices led to less severe insomnia and less frequent anxiety and depressive symptoms in participants over time. It could be that the increased lucidity made them more aware of the fact that they were asleep, thereby improving their subjective sense of sleep quality. It’s also likely that lucid dreaming made their dreams more pleasant; my team and other researchers have shown numerous times that both lucid and positive dreams are associated with better sleep quality, mood and restfulness after waking.</p><hr data-block="sciam/raw_html"><p data-block="sciam/paragraph">To improve dream engineering, we need to have a clearer understanding of what is happening in the brain during lucid dreams. Recent work in sleep and neuro­science labs is revealing the brain patterns involved.</p><p data-block="sciam/paragraph">Our most vivid dreaming takes place during rapid-eye-movement, or REM, sleep—the light phase of sleep when the brain is most active and wakelike, especially when close to the time<b> </b>that a person would usually get up. Lucidity may enhance one of the main functions of REM sleep: to refresh connections between the prefrontal cortex, where our brains control our thoughts and decisions, and the amygdala, where they generate our emotions. Sleep helps us control our emotions every day. When REM sleep is disrupted, the prefrontal cortex becomes less effective at regulating arousal both during sleep and during the subsequent day. This creates a vicious cycle for people with nightmares and insomnia: a night of poor sleep is followed by a worse mood and decreased defenses against stress the next day, leading to another night of disturbed sleep, and so on.</p><p data-block="sciam/paragraph">In contrast, lucid dreaming is associated with increased activation in the prefrontal cortex. To have stable lucid dreams, you need to remain calm and attentive, or you will probably wake up from excitement. Maintaining self-control seems to be central to having positive lucid-dream experiences, resolving nightmares, and boosting creativity and mood. That was the conclusion of a recent study by Mallett, who surveyed 400 posts on Reddit to identify exactly when and how lucid dreams are helpful for improving mental health.</p><p data-block="sciam/paragraph">We’re learning that the real mental health benefits of lucid dreaming seem to come when dreamers can direct the content. Maintaining self-control in dreams is a bit of a learned skill. Similar to mindfulness, the dreamer must practice remaining both calm and focused while in an unpredictable and unstable dream. People can then learn to control dreams by using tricks of attention such as opening and closing their eyes and expecting, or even commanding, an object such as the Eiffel Tower to appear. This skill most likely relies on specific patterns of neural activation and on cognitive practice. To be at once an actor in and director of a lucid dream requires delicate cognitive control and flexibility, but expert lucid dreamers—people who have lucid dreams at least weekly—would probably say “control” is not the most accurate term. It’s more of an improvisation, a balancing act of guiding the dream toward desired content while allowing it to arise spontaneously—like a jazz musician suggesting a rhythm or melody but also listening and adjusting to what the other musicians are playing.</p><p data-block="sciam/paragraph">To better understand how this improvisation happens, my colleague Catherine Duclos is studying the basic brain patterns of lucid dreaming in expert lucid dreamers in our Montreal lab. The volunteers sleep normally for the first half of the night, but in the early morning experimenters awaken them to place a cap on their head that is used for electroencephalogram (EEG) tests. The cap has 128 electrodes—many more than are typically used in sleep studies. After about 30 minutes, when all the electrodes are well positioned, the subjects return to sleep, intending to have a lucid dream.</p><p data-block="sciam/paragraph">Once Duclos has identified patterns of brain-wave activity that occur only in lucid dreams, she can use that information in the lab to try to directly enhance lucidity and control by augmenting activation in the cortex with electrical brain stimulation. After decades of characterizing sleep as an “offline” brain process, scientists now view the sleeping brain as “entrainable”—it is malleable and can be controlled through external stimulation. By applying an electric current of a specific wavelength to the scalp, scientists can modulate the rhythm of the sleeping brain to make brain waves faster and more wakelike in REM sleep or slower as they are in deep sleep.</p><blockquote data-block="contentful/pullquote"><p>One woman having a nightmare produced a left-right eye signal, knowing a researcher watching her would wake her up.</p></blockquote><p data-block="sciam/paragraph">Duclos plans to use transcranial alternating-current stimulation (tACS) to shape brain rhythms so that they are more similar to those in lucid dreams, based on the patterns she finds in the dreams she is recording now. Researchers in prior studies have also attempted to use tACS to induce lucid dreams, with mixed results. We hope the increased resolution of high-density EEG will help.</p><p data-block="sciam/paragraph">Another study of expert lucid dreamers will also help clarify how cognitive control works in a lucid dream. Tobi Matzek, one of my Ph.D. students and an expert lucid dreamer, spent four nights in our lab being recorded by EEG. Each night, as early morning approached, we awakened her and presented a 20-minute instruction over speakers in the bedroom, training her to pay attention to what she was experiencing after we woke her and to maintain this awareness when sleeping. She then fell back asleep and became lucid repeatedly. She used control strategies such as calling out requests for desired characters in the dream. In one instance, Matzek said she called for “God to appear as a perceivable form,” and an emerging ball of white light brought with it feelings of euphoria. She awoke in awe.</p><p data-block="sciam/paragraph">Matzek had eight lucid dreams, in which she summoned dream figures whom she perceived as having higher levels of self-­control and independent thoughts than typical dream characters. (Her dreams described in this article were presented at a recent conference.) This study is showing us how our sleeping brain creates dream characters and just how meaningful fictional and at times otherworldly social scenarios can feel. Lucid dreamers who can conjure up characters rate these dreams as more positive and mystical than other dreams. It’s possible that lucid dreams could create opportunities to visit with lost loved ones, spiritual teachers, or family and friends, but so far we know little about how to generate such experiences or how they might impact waking life.</p><p data-block="sciam/paragraph">Matzek and other expert lucid dreamers sometimes ask big questions during their dreams. One night Matzek asked, “Can I experience the creation of the universe?” and she dreamed of being “immersed in outer space, surrounded by stars and planets and other huge celestial objects.... The darkness of space is deep and rich, and every planet and star is superbright.” At one point she felt overwhelmed by the vastness, but a spiritual presence helped her stay calm. The end result, she says, was “absolutely breathtaking.” She felt weightless and was “slowly spinning head over heels as I take in everything around me. Many [stars] are brown and red, and it’s like they’re all glowing. I know that I am actually seeing the universe uncreated, back in time.” Understanding what’s happening inside the brain during these altered states of consciousness could reveal how to induce such mystical experiences on demand.</p><p data-block="sciam/paragraph"><span>D</span>reams are ephemeral, but they feel real and impactful because the brain and body experience them as real. Brain imaging shows that our dreams are read as “real” in the sensorimotor cortex. When we dream of clenching a fist, the motor cortex becomes more active, and muscles in the forearm twitch. Dreaming is the ultimate reality simulator.</p><p data-block="sciam/paragraph">Because the body experiences physical reality in sleep, we can use visual cues, sounds, and other sensations—pressure, temperature, vibration—to sculpt the dreamworld. In my lab we use flashing lights or beeping sounds during presleep lucidity training. As we did for Matzek, we wake up participants in the early morning and pursue a 20-minute training: while they lie in bed with their eyes closed, a recorded voice instructs them to remain self-aware and to pay attention to their ongoing sensory experiences. We present the flashing lights and beeping alongside this tracking so the sensory cues will serve as reminders to remain lucid.</p><p data-block="sciam/paragraph">When participants go back to sleep, we present the cues again during REM sleep to “reactivate” the associated mind state. Fifty percent of the time, participants have a lucid dream—a higher rate than without the cues. Beeping sounds played during sleep caused one person to dream of shopping in a supermarket: “I was just putting things in my trolley, and I could hear the beeping, and it was like I was getting loads of messages on my phone telling me what to buy in Tesco ... things like, ‘Buy some biscuits.’” The cues made their way into the dream and served as reminders to become lucid.</p><p data-block="sciam/paragraph">Dream engineers around the world, such as Daniel Erlacher and Emma Peters of the Institute of Sport Science at Bern University in Switzerland, are exploring new types of sensory stimuli to more reliably induce lucid dreams. These cues include subtle vibrations that could be delivered by a wearable headband or smart ring, little electric pulses that cause muscles to twitch, or vestibular stimulation—an electric current sent behind the ears that induces sensations of falling or spinning. These sensations might be more easily detectable by dreamers than flashing lights and beeping sounds, perhaps because dreams already have so much competing visual and auditory content.</p><p data-block="sciam/paragraph">Lucid dreamers can communicate with people in the waking world by controlling their sleeping bodies. In addition to making deliberate eye movements, lucid dreamers can frown, clench their hands or control their breathing, and scientists can record all of this in the lab. They can measure respiration with a belt around the torso that detects expansion and contraction of the lungs or with a little sensor on the lip that can track the flow of air in and out of the nose. Kristoffer Appel of the Institute of Sleep and Dream Technologies in Germany has even decoded word messages from lucid dreamers. The dreamers held their thumb out in front of their face, traced letters, and followed the movement of their thumb with their eyes. Dreamers could say, with their eye movements, “Hello, dream.” We are learning to converse with lucid dreamers, getting ever more complex messages into and out of the sleeping brain and body to direct and record dreams in real time.</p><hr data-block="sciam/raw_html"><p data-block="sciam/paragraph">I expect that the mental health applications of lucid dreaming will grow. Achilleas Pavlou and Alejandra Montemayor Garcia of the University of Nicosia Medical School in Cyprus are developing wearable devices programmed with machine-learning algorithms to detect when nightmares are occurring based on bio-­signals such as brain activity, breathing and heart rate. My team, along with collaborators at the Donders Institute in the Netherlands and the IMT School for Advanced Studies in Lucca, Italy, is testing a simple EEG headband that can detect REM sleep and deliver the kinds of sensory cues I mentioned earlier to induce lucid dreams. If successful, such dream aids could be made widely available at home. Headbands and watches could help people call for help to escape nightmares—or just help them induce lucid dreams or direct the content for more satisfying dreams.</p><p data-block="sciam/paragraph">People could also use these tools simply to have exotic recreational experiences. In 2024 Adam Haar, who recently finished a postdoctoral fellowship at M.I.T., and artist Carsten Höller created an exhibit in a museum in Basel, Switzerland, that welcomed overnight visitors. A bed on six robotic legs created a rocking motion before and during sleep, while a fly agaric mushroom sculpture spun above the bed. In the liminal space before sleep onset, the dreamer was reminded to dream of flying, and rocking motions and flashing red light from the installation seeped through their body and eyelids.</p><p data-block="sciam/paragraph">These stimuli were replayed at various moments throughout the night, and the sleeper was then awakened for dream reports. One visitor noted visions of “floating on the sea ... and climbing inside the squishy stalk of a giant mushroom from the bottom and being engulfed in its gravityless squishy innards,” even of being buffeted up from the ground on the wind. In the weeks after, this woman reported “countless flight-adjacent or weightlessness dreams,” such as “gliding in the air along miles of zip line through a Swiss-looking city.”</p><p data-block="sciam/paragraph">For lucid dreamers, flying is one of the most sought-after and euphoric experiences. In a 2020 study led by Claudia Picard-Deland of the University of Montreal’s Dream and Nightmare Laboratory, participants used a virtual-reality flight simulation prior to taking a nap and then recorded their dreams for two weeks at home. Playing in the virtual-reality environment for just 15 minutes led to an eightfold increase in flying dreams. And even though the study was not designed to induce lucidity, the experimenters found that flying dreams elevated it. One participant had their first-ever lucid dream: “I succeeded to make myself float a little, then once I realized that it worked, that I had control, I put my hands just like Iron Man at my sides.... I heard a big boom and a constant noise, as if I had plane propellers at the ends of my arms, and I accelerated so fast I couldn’t believe it. I screamed with joy as loud as I could.” The participant marveled at “the quantity of detail of physical sensations that I felt from flying, the intense acceleration, the wind,” as well as seeing, from above, a beautiful city from the future.</p><p data-block="sciam/paragraph">Other gadgets may not be far off. Haar developed Dormio during his Ph.D. work at M.I.T. It is basically a glove with sensors that can measure muscle flexion, heart rate and electrical skin activity, all of which change as you drift off to sleep. When Dormio detects that you’ve just fallen asleep, it gives a spoken prompt to influence what you dream about. After a couple of minutes, it wakes you up to recall imagery, and if you follow this process several times, you can engineer brief dreams that have content you desire.</p><p data-block="sciam/paragraph">Nathan Whitmore of the M.I.T. Media Lab has developed a phone app to deliver voice training for lucid dreaming, paired with auditory cues presented again during sleep. Initial results with more than 100 participants showed that presleep training brought on lucid dreams. Ken Paller of Northwestern University and Mallett have discovered EEG signatures that seem to precede the onset of lucidity. Such measures could lead to algorithms that detect opportune moments to deliver sensory cues and induce lucid dreams. Pair these with a flying game prior to sleep, and you might be in for a fun night.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I send myself automated emails to practice Dutch (151 pts)]]></title>
            <link>https://github.com/ThReinecke/dutch_vocabulary</link>
            <guid>42521773</guid>
            <pubDate>Fri, 27 Dec 2024 13:05:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/ThReinecke/dutch_vocabulary">https://github.com/ThReinecke/dutch_vocabulary</a>, See on <a href="https://news.ycombinator.com/item?id=42521773">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Daily Dutch Vocabulary Email Automation</h2><a id="user-content-daily-dutch-vocabulary-email-automation" aria-label="Permalink: Daily Dutch Vocabulary Email Automation" href="#daily-dutch-vocabulary-email-automation"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Overview</h2><a id="user-content-overview" aria-label="Permalink: Overview" href="#overview"></a></p>
<p dir="auto">This project automates the daily delivery of an email containing three C1-level Dutch words, their English translations, and example sentences. The email looks like this:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ThReinecke/dutch_vocabulary/blob/main/images/email.png"><img src="https://github.com/ThReinecke/dutch_vocabulary/raw/main/images/email.png" alt="Screenshot of email"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Motivation</h2><a id="user-content-motivation" aria-label="Permalink: Motivation" href="#motivation"></a></p>
<p dir="auto">I created this project because I couldn't find a suitable app to help me build a C1-level Dutch vocabulary. I discovered that ChatGPT provides good word suggestions and decided to automate the process. Additionally, I know that I check emails more consistently than apps, making this method more effective for learning.</p>
<p dir="auto">This project also provided an opportunity to refresh my skills in <strong>Terraform</strong> and <strong>Python</strong>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Simplified Architecture</h2><a id="user-content-simplified-architecture" aria-label="Permalink: Simplified Architecture" href="#simplified-architecture"></a></p>
<p dir="auto">A CloudWatch Event Rule triggers a Lambda each morning at 7:00. The Lambda retrieves all previously sent Dutch words from DynamoDB. It then retrieves three new words from ChatGPT, stores them in DynamoDB, and sends them to SES. SES delivers them to the end user's email.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ThReinecke/dutch_vocabulary/blob/main/images/architecture.jpg"><img src="https://github.com/ThReinecke/dutch_vocabulary/raw/main/images/architecture.jpg" alt="Picture of architecture"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Setup</h2><a id="user-content-setup" aria-label="Permalink: Setup" href="#setup"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Prerequisites</h3><a id="user-content-prerequisites" aria-label="Permalink: Prerequisites" href="#prerequisites"></a></p>
<p dir="auto">To deploy this project, ensure the following tools and configurations are in place:</p>
<ol dir="auto">
<li>
<p dir="auto"><strong>Tools Installed:</strong></p>
<ul dir="auto">
<li>Python (Tested with Python 3.8)</li>
<li>pip (Tested with pip 19.2.3)</li>
<li>Terraform (Tested with Terraform 1.10.3)</li>
<li>AWS CLI (Tested with 2.15.58)</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Permissions:</strong>
Your AWS CLI user must have the appropriate permissions to deploy the resources. Refer to the Terraform files and apply the principle of least privilege.</p>
</li>
<li>
<p dir="auto"><strong>Amazon SES Verified Email:</strong>
You need a verified email address in Amazon SES. This email must match the one used in the project.<br>
Reference: <a href="https://docs.aws.amazon.com/ses/latest/dg/creating-identities.html#verify-email-addresses-procedure" rel="nofollow">Verifying Email Addresses in Amazon SES</a>.</p>
</li>
<li>
<p dir="auto"><strong>Optional:</strong><br>
You can zip the Lambda deployment package manually if you like:</p>
<ul dir="auto">
<li>Use the provided <code>setup.sh</code> script or follow the steps in the script manually (might need small modifications if on Mac/Linux)</li>
<li>Alternatively, use the pre-zipped package: <code>deployment_package.zip</code>.</li>
</ul>
</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">Deployment Steps</h3><a id="user-content-deployment-steps" aria-label="Permalink: Deployment Steps" href="#deployment-steps"></a></p>
<ol dir="auto">
<li>
<p dir="auto"><strong>Prepare Configuration:</strong></p>
<ul dir="auto">
<li>Copy <code>terraform.tfvars.example</code> to <code>terraform.tfvars</code>.</li>
<li>Fill out the required values in <code>terraform.tfvars</code>.</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Run the Terraform Workflow:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="terraform init
terraform plan
terraform apply"><pre>terraform init
terraform plan
terraform apply</pre></div>
</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Considerations</h2><a id="user-content-considerations" aria-label="Permalink: Considerations" href="#considerations"></a></p>
<p dir="auto">This project was intended as a <strong>weekend project</strong>, so there is room for improvement. Potential enhancements include:</p>
<ul dir="auto">
<li>Refactoring the Python code to be asynchronous for better performance and robustness.</li>
<li>Splitting the <code>lambda_function.py</code> file into smaller modules for better organization and maintainability.</li>
</ul>
<p dir="auto">However, since the project fulfills its purpose and is unlikely to grow further, I kept the implementation simple.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Instantly visualize any codebase as an interactive diagram (181 pts)]]></title>
            <link>https://gitdiagram.com/</link>
            <guid>42521769</guid>
            <pubDate>Fri, 27 Dec 2024 13:04:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gitdiagram.com/">https://gitdiagram.com/</a>, See on <a href="https://news.ycombinator.com/item?id=42521769">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Turn any GitHub repository into an interactive diagram for visualization.</p><p>This is useful for quickly visualizing projects.</p><p>You can also replace 'hub' with 'diagram' in any Github URL</p></div><div><form><div><p>Try these example repositories:</p></div></form></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why OpenAI's Structure Must Evolve to Advance Our Mission (264 pts)]]></title>
            <link>http://openai.com/index/why-our-structure-must-evolve-to-advance-our-mission</link>
            <guid>42521744</guid>
            <pubDate>Fri, 27 Dec 2024 12:57:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://openai.com/index/why-our-structure-must-evolve-to-advance-our-mission">http://openai.com/index/why-our-structure-must-evolve-to-advance-our-mission</a>, See on <a href="https://news.ycombinator.com/item?id=42521744">Hacker News</a></p>
Couldn't get http://openai.com/index/why-our-structure-must-evolve-to-advance-our-mission: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[The paper passport's days are numbered (115 pts)]]></title>
            <link>https://www.wired.com/story/the-paper-passport-is-dying/</link>
            <guid>42521629</guid>
            <pubDate>Fri, 27 Dec 2024 12:29:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wired.com/story/the-paper-passport-is-dying/">https://www.wired.com/story/the-paper-passport-is-dying/</a>, See on <a href="https://news.ycombinator.com/item?id=42521629">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-testid="ArticlePageChunks"><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>In a matter of years, no matter where you live or travel, your face will likely be your new passport.</p><p>For centuries, people have used some form of passport while moving from place to place. But the widespread standardization of passports as we know them today didn’t really begin until after <a data-offer-url="https://lucris.lub.lu.se/ws/portalfiles/portal/36018821/WP19_Kalm.pdf" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://lucris.lub.lu.se/ws/portalfiles/portal/36018821/WP19_Kalm.pdf&quot;}" href="https://lucris.lub.lu.se/ws/portalfiles/portal/36018821/WP19_Kalm.pdf" rel="nofollow noopener" target="_blank">World War 1</a>, when passports were commonly used as a security measure and to deter spies entering a country. Even then, <a data-offer-url="https://www.foreignaffairs.com/world/passport-question" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.foreignaffairs.com/world/passport-question&quot;}" href="https://www.foreignaffairs.com/world/passport-question" rel="nofollow noopener" target="_blank">some considered</a> passports to be an “anachronism in the modern world.”</p><p>But the use of paper passports—which were first <a href="https://www.wired.com/story/us-border-patrol-epassport-verification/">digitized as “e-Passports” with NFC chips in 2006</a>—is slowly undergoing one of its biggest transformations to date. The travel industry, airports, and governments are working to remove the need to show your passport while flying internationally. Eventually, you may not need to carry your passport at all.</p><p>Instead, face recognition technology and smartphones are increasingly being used to check and confirm your identity against travel details before you can fly. These systems, advocates claim, can reduce the amount of waiting time and “friction” you experience at airports. But privacy experts caution that there is little transparency about the technologies being deployed, and their proliferation could lead to data breaches and greater levels of surveillance.</p><p>The push to remove paper passports is happening worldwide. So far, airports in Finland, <a data-offer-url="https://www.klm.ca/information/travel-documents/travel-canada/dtc-pilot" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.klm.ca/information/travel-documents/travel-canada/dtc-pilot&quot;}" href="https://www.klm.ca/information/travel-documents/travel-canada/dtc-pilot" rel="nofollow noopener" target="_blank">Canada</a>, the Netherlands, the <a data-offer-url="https://www.hindustantimes.com/business/you-may-soon-be-able-to-board-flights-at-abu-dhabi-airport-without-a-passport-and-ticket-101725004066448.html" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.hindustantimes.com/business/you-may-soon-be-able-to-board-flights-at-abu-dhabi-airport-without-a-passport-and-ticket-101725004066448.html&quot;}" href="https://www.hindustantimes.com/business/you-may-soon-be-able-to-board-flights-at-abu-dhabi-airport-without-a-passport-and-ticket-101725004066448.html" rel="nofollow noopener" target="_blank">United Arab Emirates</a>, the United Kingdom, <a data-offer-url="https://www.businesstraveller.com/business-travel/2023/11/06/iata-trials-first-fully-integrated-digital-identity-travel-experience/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.businesstraveller.com/business-travel/2023/11/06/iata-trials-first-fully-integrated-digital-identity-travel-experience/&quot;}" href="https://www.businesstraveller.com/business-travel/2023/11/06/iata-trials-first-fully-integrated-digital-identity-travel-experience/" rel="nofollow noopener" target="_blank">Italy</a>, the United States, <a data-offer-url="https://www.biometricupdate.com/202410/india-to-pilot-digi-yatra-for-foreign-nationals-in-2025" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.biometricupdate.com/202410/india-to-pilot-digi-yatra-for-foreign-nationals-in-2025&quot;}" href="https://www.biometricupdate.com/202410/india-to-pilot-digi-yatra-for-foreign-nationals-in-2025" rel="nofollow noopener" target="_blank">India</a>, and elsewhere have been trialing various levels of passport-free travel or the technology needed to make it happen. In October, officials in Singapore <a data-offer-url="https://www.ica.gov.sg/news-and-publications/newsroom/media-release/passport-less-clearance-fully-rolled-out-at-changi-airport#:~:text=Since%2030%20September%202024%2C%20the,need%20to%20present%20their%20passport." data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.ica.gov.sg/news-and-publications/newsroom/media-release/passport-less-clearance-fully-rolled-out-at-changi-airport#:~:text=Since%2030%20September%202024%2C%20the,need%20to%20present%20their%20passport.&quot;}" href="https://www.ica.gov.sg/news-and-publications/newsroom/media-release/passport-less-clearance-fully-rolled-out-at-changi-airport#:~:text=Since%2030%20September%202024%2C%20the,need%20to%20present%20their%20passport." rel="nofollow noopener" target="_blank">announced</a> that its residents can fly to and from the country without using their documentation, and foreign visitors can “enjoy the convenience of passport-less clearance when they depart Singapore.” More than 1.5 million people have used the systems, officials claim.</p><p>“It’s probably going to become the mainstream way of traveling, as I understand, in the near future,” says Athina Ioannou, a lecturer in business analytics at the University of Surrey in the UK, who has researched the privacy implications that come with different types of travel. Ioannou says the Covid-19 pandemic accelerated contact-free travel, and many efforts are driven by trying to get passengers moving quickly through airports.</p><p>While trials around the world are at different stages and use different technical infrastructure, they broadly work in similar ways: Information historically stored in your passport’s NFC chip, including facial data, is instead stored digitally and linked to your phone. The EU is planning to build an <a href="https://ec.europa.eu/commission/presscorner/detail/en/ip_24_5047">official travel app</a> for this. When you are at an airport, the phone can be shown, and a face recognition camera will try to match you to the passport photo.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>One of the most commonly tested approaches is using a “digital travel credential.” A DTC, according to the United Nations’ International Civil Aviation Organization (ICAO), which is <a data-offer-url="https://www.icao.int/Security/FAL/TRIP/Documents/High%20Level%20Guidance%20explaining%20ICAO%20DTC.pdf" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.icao.int/Security/FAL/TRIP/Documents/High%20Level%20Guidance%20explaining%20ICAO%20DTC.pdf&quot;}" href="https://www.icao.int/Security/FAL/TRIP/Documents/High%20Level%20Guidance%20explaining%20ICAO%20DTC.pdf" rel="nofollow noopener" target="_blank">behind the approach</a>, is made up of two parts: a virtual element, which represents the information stored on passports, and a physical part, the bit on your phone. The two are cryptographically linked to ensure they’re not forgeries. “The key feature of the ICAO DTC is that authorities can verify a digital representation of the passport data before the traveller’s arrival and confirm the data’s integrity and authenticity,” a description of the system says.</p><p>Three different approaches to the DTC exist, with two requiring you to carry (but not necessarily use) paper passports, while the third approach, which may be some years down the line, doesn’t require a passport to even be <a data-offer-url="https://www.icao.int/Security/FAL/TRIP/Documents/High%20Level%20Guidance%20explaining%20ICAO%20DTC.pdf" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.icao.int/Security/FAL/TRIP/Documents/High%20Level%20Guidance%20explaining%20ICAO%20DTC.pdf&quot;}" href="https://www.icao.int/Security/FAL/TRIP/Documents/High%20Level%20Guidance%20explaining%20ICAO%20DTC.pdf" rel="nofollow noopener" target="_blank">issued</a>. Earlier this year, border officials in Finland held a small-scale trial of a DTC on <a data-offer-url="https://raja.fi/en/dtc" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://raja.fi/en/dtc&quot;}" href="https://raja.fi/en/dtc" rel="nofollow noopener" target="_blank">22 airline routes</a>, using a mobile app that had been developed. While passengers still had to carry passports, the country’s Border Guard concluded that checks lasted for just eight seconds, with the technical processing happening in two seconds. “Speed is really essential here if we are talking about facilitating a huge number of people,” Mikko Väisänen, the head of the DTC pilot, says.</p><p>While ending frustrating airport lines would be welcome for many, the shift to digital travel document also raises concerns about how data is protected, a normalization of problematic surveillance technology such as face recognition, plus whether digital ID systems will be further rolled out to other parts of society and who ultimately controls or builds these pieces of infrastructure.</p><p>The ICAO’s documentation around the DTC <a data-offer-url="https://www.icao.int/Security/FAL/TRIP/PublishingImages/Pages/Publications/ICAO%20GUIDING%20CORE%20PRINCIPLES%20DTC_Draft%20v4.8.pdf" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.icao.int/Security/FAL/TRIP/PublishingImages/Pages/Publications/ICAO%20GUIDING%20CORE%20PRINCIPLES%20DTC_Draft%20v4.8.pdf&quot;}" href="https://www.icao.int/Security/FAL/TRIP/PublishingImages/Pages/Publications/ICAO%20GUIDING%20CORE%20PRINCIPLES%20DTC_Draft%20v4.8.pdf" rel="nofollow noopener" target="_blank">identifies risks</a> such as “look-alike fraud,” criminals collecting DTC data and duplicating parts of it, delays to journeys if systems face outages, and people being unable to travel if there is a “false rejection” in face-recognition systems and no fallback systems in place. <a href="https://www.wired.com/tag/face-recognition/">Face-recognition</a> systems have been <a data-offer-url="https://www.biometricupdate.com/202405/facewatch-met-police-face-lawsuits-after-facial-recognition-misidentification" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.biometricupdate.com/202405/facewatch-met-police-face-lawsuits-after-facial-recognition-misidentification&quot;}" href="https://www.biometricupdate.com/202405/facewatch-met-police-face-lawsuits-after-facial-recognition-misidentification" rel="nofollow noopener" target="_blank">highly controversial for years</a>.</p><p>Multiple companies around the world are <a data-offer-url="https://www.biometricupdate.com/202408/travel-far-ahead-on-realizing-benefits-of-biometrics-and-digital-id#:~:text=Biometric%20Enabled%20Seamless%20Travel%20(BEST,digital%20identity%20issued%20by%20both" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.biometricupdate.com/202408/travel-far-ahead-on-realizing-benefits-of-biometrics-and-digital-id#:~:text=Biometric%20Enabled%20Seamless%20Travel%20(BEST,digital%20identity%20issued%20by%20both&quot;}" href="https://www.biometricupdate.com/202408/travel-far-ahead-on-realizing-benefits-of-biometrics-and-digital-id#:~:text=Biometric%20Enabled%20Seamless%20Travel%20(BEST,digital%20identity%20issued%20by%20both" rel="nofollow noopener" target="_blank">building verification systems</a> to help people prove they are who they say, which can involve linking with official government databases or systems. Udbhav Tiwari, the director of global product policy at Mozilla, says there are “privacy by design” and data minimization efforts that are taking place with the development of these products and systems, but there are still a range of other risks.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>“We don’t really know how secure these systems are,” Tiwari says, adding that there are generally concerns about the “fairness, accountability, and transparency” with AI systems that can be used. “The fact is that all of these companies develop these systems often do so in deeply proprietary manners,” Tiwari says.</p><p>On top of this, Tiwari says, countries can treat people differently. Different nations have data protection regimes of varying quality and may use different standards around how people’s information can be passed to government or law enforcement agencies or sold. “I, for example, would be much more comfortable using biometric-based travel in Germany than I would in many other countries in the world, because I trust the data-protection ecosystem and regulators in Germany and might not in other countries,” Tiwari says.</p><p>Adam Tsao, vice president of digital identity at security firm Entrust, says that people using any systems will want to know that their data is being used the way they expect it to be. For instance, he says, among other things people will want to know who has access to information, what purposes they can access it for, and what say they have in what happens to it. “You really want to get to the point where as we move in this digitized world, that you’re giving the exact right amount of information, for the exact right amount of time, for the right purpose to the right people,” Tsao says. And that may not be straightforward.</p><p>In India, the Digi Yatra face-recognition boarding system has faced multiple criticisms about how it has been introduced and how people have been signed up for the voluntary scheme, as <a data-offer-url="https://www.biometricupdate.com/202401/digi-yatra-still-ruffling-feathers-among-air-travelers-but-keeps-growing" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.biometricupdate.com/202401/digi-yatra-still-ruffling-feathers-among-air-travelers-but-keeps-growing&quot;}" href="https://www.biometricupdate.com/202401/digi-yatra-still-ruffling-feathers-among-air-travelers-but-keeps-growing" rel="nofollow noopener" target="_blank">Biometric Update</a> <a data-offer-url="https://www.biometricupdate.com/202407/digi-yatra-needs-more-individual-control-over-data-privacy-niti-aayog-argues" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.biometricupdate.com/202407/digi-yatra-needs-more-individual-control-over-data-privacy-niti-aayog-argues&quot;}" href="https://www.biometricupdate.com/202407/digi-yatra-needs-more-individual-control-over-data-privacy-niti-aayog-argues" rel="nofollow noopener" target="_blank">has</a> <a data-offer-url="https://www.biometricupdate.com/202401/digi-yatra-still-ruffling-feathers-among-air-travelers-but-keeps-growing" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.biometricupdate.com/202401/digi-yatra-still-ruffling-feathers-among-air-travelers-but-keeps-growing&quot;}" href="https://www.biometricupdate.com/202401/digi-yatra-still-ruffling-feathers-among-air-travelers-but-keeps-growing" rel="nofollow noopener" target="_blank">reported</a>. “The way that it’s happening in India is no longer voluntary, and it’s no longer something we can hold the government or anybody else accountable for,” says Disha Verma, from the Internet Freedom Foundation.</p><p>The Digi Yatra system, which has been operating in 24 airports around the country, may be opening up to <a data-offer-url="https://www.business-standard.com/finance/personal-finance/your-face-could-be-your-boarding-pass-india-plans-biometric-for-foreigners-124100200126_1.html" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.business-standard.com/finance/personal-finance/your-face-could-be-your-boarding-pass-india-plans-biometric-for-foreigners-124100200126_1.html&quot;}" href="https://www.business-standard.com/finance/personal-finance/your-face-could-be-your-boarding-pass-india-plans-biometric-for-foreigners-124100200126_1.html" rel="nofollow noopener" target="_blank">foreign citizens in 2025</a>. Meanwhile, there are plans to <a data-offer-url="https://everythingexperiential.com/article/digi-yatra-could-soon-include-hotels-rail-travel-public-areas-says-ceo-523541" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://everythingexperiential.com/article/digi-yatra-could-soon-include-hotels-rail-travel-public-areas-says-ceo-523541&quot;}" href="https://everythingexperiential.com/article/digi-yatra-could-soon-include-hotels-rail-travel-public-areas-says-ceo-523541" rel="nofollow noopener" target="_blank">roll out</a> the identity technology to hotels and historical monuments. Your face could soon be your room key as well.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Missiles Are Now the Biggest Killer of Airline Passengers (540 pts)]]></title>
            <link>https://www.wsj.com/world/flight-deaths-shot-from-sky-rising-798fd31e</link>
            <guid>42521598</guid>
            <pubDate>Fri, 27 Dec 2024 12:21:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wsj.com/world/flight-deaths-shot-from-sky-rising-798fd31e">https://www.wsj.com/world/flight-deaths-shot-from-sky-rising-798fd31e</a>, See on <a href="https://news.ycombinator.com/item?id=42521598">Hacker News</a></p>
Couldn't get https://www.wsj.com/world/flight-deaths-shot-from-sky-rising-798fd31e: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[Building AI Products–Part I: Back-End Architecture (149 pts)]]></title>
            <link>https://philcalcado.com/2024/12/14/building-ai-products-part-i.html</link>
            <guid>42521241</guid>
            <pubDate>Fri, 27 Dec 2024 10:42:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://philcalcado.com/2024/12/14/building-ai-products-part-i.html">https://philcalcado.com/2024/12/14/building-ai-products-part-i.html</a>, See on <a href="https://news.ycombinator.com/item?id=42521241">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

  

  
  <article>
      <p>In 2023, we launched an AI-powered Chief of Staff for engineering leaders—an assistant that unified information across team tools and tracked critical project developments. Within a year, we attracted 10,000 users, <a href="https://outropy.ai/blog/2024-04-19-outropy_vs_slack_ai/">outperforming even deep-pocketed incumbents such as Salesforce and Slack AI</a>. Here is an early demo:</p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/8mr5eZNXDlo?si=-IIK5uO5cTN9FFhi" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>

<p>By May 2024, we realized something interesting: while our AI assistant was gaining traction, there was overwhelming demand for the technology we built to power it. Engineering leaders using the platform were reaching out non-stop to ask not about the tool but how we made our agents work so reliably at scale and be, you know, <em>actually useful</em>. This led us to pivot to <a href="https://outropy.ai/">Outropy</a>, a developer platform that enables software engineers to build AI products.</p>

<p>Building with Generative AI at breakneck pace while the industry was finding its footing taught us invaluable lessons—lessons that now form the core of the Outropy platform. While LinkedIn overflows with thought leaders declaring every new research paper a “game changer,” few explain what the game actually is. This series aims to change that.</p>

<p>This three-part series will cover:</p>

<ul>
  <li>How we built the AI agents powering the assistant</li>
  <li>How we constructed and operate our inference pipelines</li>
  <li>The AI-specific tools and techniques that made it all work</li>
</ul>

<p>This order is intentional. So much content out there fixates on choosing the best reranker or chasing the latest shiny technology, and few discuss how to build useful AI software. This is a report from the trenches, not the ivory tower.</p>

<h3 id="structuring-an-ai-application">Structuring an AI Application</h3>

<p>Working with AI presents exciting opportunities and unique frustrations for a team like ours, with decades of experience building applications and infrastructure.</p>

<p>AI’s stochastic (probabilistic) nature fundamentally differs from traditional deterministic software development—but that’s only part of the story. With years of experience handling distributed systems and <a href="https://nighthacks.com/jag/res/Fallacies.html">their inherent uncertainties</a>, we’re no strangers to unreliable components.</p>

<p>The biggest open questions lie in structuring GenAI systems for long-term evolution and operation, moving beyond the quick-and-dirty prompt chaining that suffices for flashy demos.</p>

<p>In my experience, there are two major types of components in a GenAI system:</p>

<ul>
  <li><strong>Inference Pipelines:</strong> A deterministic sequence of operations that transforms inputs through one or more AI models to produce a specific output. Think of RAG pipelines generating answers from documents—each step follows a fixed path despite the AI’s probabilistic nature.</li>
  <li><strong>Agents:</strong> Autonomous software entities that maintain state while orchestrating AI models and tools to accomplish complex tasks. These agents can reason about their progress and adjust their approach across multiple steps, making them suitable for longer-running operations.</li>
</ul>

<p>Our journey began with <a href="https://www.youtube.com/watch?v=ePFEpU5crN0&amp;ab_channel=PhilCal%C3%A7ado">a simple Slack bot</a>. This focused approach let us explore GenAI’s possibilities and iterate quickly without getting bogged down in architectural decisions. During this period, we only used distinct inference pipelines and tied their results together manually.</p>

<p>This approach served us well until we expanded our integrations and features. As the application grew, our inference pipelines became increasingly complex and brittle, struggling to reconcile data from different sources and formats while maintaining coherent semantics.</p>

<p>This complexity drove us to adopt a <em>multi-agentic system</em>.</p>

<h3 id="what-are-agents-really">What are agents, really?</h3>

<p>The industry has poured billions into AI agents, yet most discussions focus narrowly on <a href="https://en.wikipedia.org/wiki/Robotic_process_automation">RPA</a>-style, no-code and low-code automation tools. Yes, frameworks like CrewAI, AutoGen, Microsoft Copilot Studio, and Salesforce’s Agentforce serve an important purpose—they give business users the same power that shell scripts give Linux admins. But just like you wouldn’t build a production system in Bash, these frameworks are just scratching the surface of what agents can be.</p>

<p>The broader concept of agents has a rich history in academia and AI research, offering much more interesting possibilities for product development. Still, as a tiny startup on a tight deadline, rather than get lost in theoretical debates, we distilled practical traits that guided our implementation:</p>

<ul>
  <li><strong>Semi-autonomous:</strong> Functions independently with minimal supervision, making local decisions within defined boundaries.</li>
  <li><strong>Specialized:</strong> Masters specific tasks or domains rather than attempting general-purpose intelligence.</li>
  <li><strong>Reactive:</strong> Responds intelligently to requests and environmental changes, maintaining situational awareness.</li>
  <li><strong>Memory-driven:</strong> Maintains and leverages both immediate context and historical information to inform decisions.</li>
  <li><strong>Decision-making:</strong> Analyzes situations, evaluates options, and executes actions aligned with objectives.</li>
  <li><strong>Tool-using:</strong> Effectively employs various tools, systems, and APIs to accomplish tasks.</li>
  <li><strong>Goal-oriented:</strong> Adapts behavior and strategies to achieve defined objectives while maintaining focus.</li>
</ul>

<p>While these intelligent components are powerful, we quickly learned that not everything needs to be an agent. Could we have built our Slackbot and productivity tool connectors using agents? Sure, but the traditional design patterns worked perfectly well, and our limited resources were better spent elsewhere. The same logic applied to standard business operations—user management, billing, permissions, and other commodity functions worked better with conventional architectures.</p>

<p>This meant that we had the following <a href="https://learning.oreilly.com/library/view/software-architecture-patterns/9781491971437/ch01.html#idm46407728082304">layered architecture</a> inside our application:</p>

<p><img src="https://philcalcado.com/img/building-ai-products-i/arch-mono.png" alt=""></p>

<h3 id="agents-are-not-microservices">Agents are not Microservices</h3>

<p>I’ve spent the last decade deep in microservices—from pioneering work at ThoughtWorks to helping underdogs like SoundCloud, DigitalOcean, SeatGeek, and Meetup punch above their weight. So naturally, that’s where we started with our agent architecture.</p>

<p>Initially, we implemented agents as <a href="https://martinfowler.com/eaaCatalog/serviceLayer.html">a service layer</a> with traditional request/response cycles:</p>

<p><img src="https://philcalcado.com/img/building-ai-products-i/arch-agents-service-layer.png" alt=""></p>

<p>One of the biggest appeals of this architecture was that, even if we expected our application to be a monolith for a long time, it creates an easier path to extracting services as needed and benefit from <em>horizontal scalability</em> when the time comes.</p>

<p>Unfortunately, the more we went down the path, the more obvious it became that stateless microservices and AI agents just don’t play nice together. Microservices are all about splitting a particular feature into small units of work that need minimal context to perform the task at hand. The same traits that make agents powerful create a significant impedance mismatch with these expectations:</p>

<ul>
  <li><strong>Stateful Operation</strong>: Agents must maintain rich context across interactions, including conversation history and planning states. This fundamentally conflicts with microservices’ stateless nature and complicates scaling and failover.</li>
  <li><strong>Non-deterministic Behavior</strong>: Unlike traditional services, agents are basically state machines with unbounded states. They behave completely differently depending on context and various probabilistic responses. This breaks core assumptions about caching, testing, and debugging.</li>
  <li><strong>Data-Intensive with Poor Locality</strong>: Agents process massive amounts of data through language models and embeddings, with poor data locality. This contradicts microservices’ efficiency principle.</li>
  <li><strong>Unreliable External Dependencies</strong>: Heavy reliance on external APIs such as LLMs, embedding services, and tool endpoints creates complex dependency chains with unpredictable latency, reliability, and costs.</li>
  <li><strong>Implementation Complexity</strong>: The combination of prompt engineering, planning algorithms, and tool integrations creates debugging challenges that compound with distribution.</li>
</ul>

<p>Not only did this impedance mismatch cause a lot of pain while writing and maintaining the code, but agentic systems are so far away from the ubiquitous <a href="https://12factor.net/">12-factor</a> model that attempting to leverage existing microservice tooling became an exercise in fitting square pegs into round holes.</p>

<h3 id="agents-are-more-like-objects">Agents are more like objects</h3>

<p>If microservices weren’t the right fit, another classic software engineering paradigm offered a more natural abstraction for agents: object-oriented programming.</p>

<p>Agents naturally align with OOP principles: they maintain encapsulated state (their memory), expose methods (their tools and decision-making capabilities via inference pipelines), and communicate through message passing. <a href="https://userpage.fu-berlin.de/~ram/pub/pub_jf47ht81Ht/doc_kay_oop_en">This mirrors Alan Kay’s original vision</a>:</p>

<blockquote>
  <p>OOP to me means only messaging, local retention and protection and hiding of state-process, and extreme late-binding of all things.</p>
</blockquote>

<p><img src="https://philcalcado.com/img/building-ai-products-i/uml.png" alt=""></p>

<p>We’ve been in the industry long enough to remember the nightmares of distributed objects and the fever dreams of CORBA and J2EE. Yet, objects offered us a pragmatic way to quickly iterate on our product and defer the scalability question until we actually need to solve that.</p>

<p>We evolved our agents from <a href="https://martinfowler.com/bliki/EvansClassification.html">stateless Services to Entities</a>, giving them distinct identities and lifecycles. This meant each user or organization maintained their own persistent agent instances, managed through <a href="https://philcalcado.com/2010/12/23/how_to_write_a_repository.html">Repositories</a> in our database.</p>

<p>This drastically simplified our function signatures by eliminating the need to pass extensive context as arguments on every agent call. It also lets us leverage battle-tested tools like SQLAlchemy and Pydantic to build our agents, while enabling unit tests with stubs/mocks instead of complicated integration tests.</p>

<h3 id="implementing-agentic-memory">Implementing Agentic Memory</h3>

<p>Agents’ memories can be as simple as a single value to as complicated as keeping track of historical information since the beginning of times. In our assistant, we have both types and more.</p>

<p>For simple, narrow-focused agents such as the “Today’s Priorities” agents had to remember nothing more than a list of high-priority things they were monitoring and eventually taking action, such as sending a notification if they weren’t happy with the progress. Others, like our “Org Chart Keeper” had to keep track of all interactions between everyone in the organizations and use that to infer reporting lines and teams people belonged to.</p>

<p>The agents with simpler persistence needs would usually just store their data on a dedicated table using <a href="https://docs.sqlalchemy.org/en/20/orm/">SQLAlchemy’s ORM</a>. This obviously wasn’t an option for the more complicated memory needs, so we had to apply a different model</p>

<p>After some experimentation, we adopted <a href="https://martinfowler.com/bliki/CQRS.html">CQRS</a> with <a href="https://martinfowler.com/eaaDev/EventSourcing.html">Event Sourcing</a>. In essence, every state change—whether creating a meeting or updating team members—was represented as a <em>Command</em>, a discrete event recorded chronologically—much like a database <a href="https://en.wikipedia.org/wiki/Transaction_log">transaction log</a>. The current state of any object could then be reconstructed by replaying all its associated events in sequence.</p>

<p>While this approach has clear benefits, replaying events solely to respond to a query is slow and cumbersome, especially when most queries focus on the current state rather than historical data. To address, CQRS suggests that we maintain a continuously updated, query-optimized representation of the data, similar to materialized views in a relational database. This ensured quick reads without sacrificing the advantages of event sourcing. We started off storing events and query models in Postgres, planning to move them to DynamoDB when we started having issues.</p>

<p>One big challenge in this model is that only an agent knows what matters to them. For example, if a user would change cancel a scheduled meeting, which agents should care about this event? The scheduling agent for sure, but if this meeting was about a specific project you might also want the project management agent to know about it as it might impact the roadmap.</p>

<p>Rather than building an all-knowing router to dispatch events to the right agents—risking the creation of a <a href="https://en.wikipedia.org/wiki/God_object">God object</a>—we took inspiration from <a href="https://developers.soundcloud.com/blog/building-products-at-soundcloud-part-1-dealing-with-the-monolith">my experience at SoundCloud</a>. There, we developed a semantic event bus enabling interested parties to publish and observe events for relevant entities:</p>

<blockquote>
  <p>Soon enough, we realized that there was a big problem with this model; as our microservices needed to react to user activity. The push-notifications system, for example, needed to know whenever a track had received a new comment so that it could inform the artist about it.  […] over several iterations we developed a model called Semantic Events, where changes in the domain objects result in a message being dispatched to a broker and consumed by whichever microservice finds the message interesting.</p>
</blockquote>

<p><img src="https://philcalcado.com/img/building-ai-products-i/semantic-events.png" alt=""></p>

<p>Following this model, all state-change events were posted to an event bus that agents could subscribe to. Each agent filtered out irrelevant events independently, removing the need for external systems to know what they cared about. Since we were working within a single monolith at the time, we implemented a straightforward <a href="https://en.wikipedia.org/wiki/Observer_pattern">Observer pattern</a> using <a href="https://docs.sqlalchemy.org/en/20/orm/events.html">SQLAlchemy’s native event system</a>, with plans to eventually migrate to <a href="https://aws.amazon.com/blogs/database/dynamodb-streams-use-cases-and-design-patterns/">DynamoDB Streams</a>.</p>

<p>Inside our monolith, the architecture looked like this:</p>

<p><img src="https://philcalcado.com/img/building-ai-products-i/memory1.png" alt=""></p>

<p>Managing both the ORM approach for simpler objects and CQRS for more complex needs grew increasingly cumbersome. Small refactorings or shared logic across all agents became harder than necessary. Ultimately, we decided the simplicity of ORM wasn’t worth the complexity of handling two separate persistence models. We converted all agents to the CQRS style but retained ORM for non-agentic components.</p>

<h3 id="handling-events-in-natural-language">Handling Events in Natural Language</h3>

<p>CQRS and its supporting tools excel with well-defined data structures. At SoundCloud, events like <em>UploadTrack</em> or <em>CreateTrackComment</em> were straightforward and unambiguous. AI systems, however, present a very different challenge.</p>

<p>Most AI systems deal with the uncertainty of natural language. This makes the process of consolidating the Commands into a “materialized view” hard. For example, what events correspond to someone posting a Slack message like <em>“I am feeling sick and can’t come to the office tomorrow, can we reschedule the project meeting?”</em></p>

<p>We started with the naive approach most agentic systems use: running every message through an inference pipeline to extract context, make decisions, and take actions via tool calling. This approach faced two problems: first, reliably doing all this work in a single pipeline is hard even with frontier models—more on this in part II. Second, we ran into the God object problem discussed earlier—our logic was spread across many agents, and no single pipeline could handle everything.</p>

<p>One option involved sending each piece of content—Slack messages, GitHub reviews, Google Doc comments, emails, calendar event descriptions…—to every agent for processing. While this was straightforward to implement via our event bus, each agent would need to run its inference pipeline for every piece of content. This would offer all sorts of performance and cost issues due to frequent calls to LLMs and other models, especially considering that the vast majority of content wouldn’t be relevant to a particular agent.</p>

<p>We wrestled with this problem for a while, exploring some initially promising but ultimately unsuccessful attempts at <a href="https://www.mathworks.com/discovery/feature-extraction.html">Feature Extraction</a> using simpler ML models instead of LLMs. That said, I believe this approach can work well in constrained domains—indeed, we use it in Outropy to route requests within the platform.</p>

<p>Our solution built on <a href="https://arxiv.org/pdf/2312.06648">Tong Chen’s Proposition-Based Retrieval research</a>. We already <a href="https://www.linkedin.com/posts/pcalcado_ai-vs-human-readability-the-unnecessary-activity-7275345861222535168-3fIB?utm_source=share&amp;utm_medium=member_desktop">used this approach to ingest structured content like CSV file</a>s, where instead of directly embedding it into a vector database, we first use an LLM to generate natural language factoids about the content. While these factoids add no new information, their natural language format makes vector similarity search much more effective than the original spreadsheet-like structure.</p>

<p>Our solution was to use an LLM to generate propositions for every message, structured according to a format inspired by <a href="https://github.com/amrisi/amr-guidelines/blob/master/amr.md">Abstract Meaning Representation</a>, a technique from natural language processing.</p>

<p>This way, if user <em>Bob</em> sends a message like <em>“I am feeling sick and can’t come to the office tomorrow, can we reschedule the project meeting?”</em> on the <code>#project-lavender</code> channel we would get structured propositions such as:</p>

<p><img src="https://philcalcado.com/img/building-ai-products-i/amr.jpg" alt=""></p>

<p>Naturally, we had to carefully batch messages and discussions to minimize costs and latency. This necessity became a major driver behind developing Outropy’s automated pipeline optimization using Reinforcement Learning.</p>

<h3 id="scaling-to-10000-users">Scaling to 10,000 Users</h3>

<p>As mentioned a few times, Throughout this whole process, it was very important to us to minimize the amount of time and energy invested in technical topics unrelated to learning about our users and how to use AI to build products.</p>

<p>We kept our assistant as a single component, with a single code base and a single container image that we deployed using AWS Elastic Container Service. Our agents were simple Python classes using SQLAlchemy and Pydantic, and we relied on FastAPI and asyncio’s excellent features to handle the load. Keeping things simple allowed us to make massive progress on the product side, to a point we went from 8 to 2,000 users in about two months.</p>

<p><img src="https://philcalcado.com/img/building-ai-products-i/arch-mono.png" alt=""></p>

<p>That’s when things started breaking down. Our personal daily briefings—our flagship feature—went from taking minutes to hours per user. We’d trained our assistant to learn each user’s login time and generate reports an hour before, ensuring fresh updates. But as we scaled, we had to abandon this personalization and batch process everything at midnight, hoping reports would be ready when users logged in.</p>

<p>As an early startup, growth had to continue, so we needed a quick solution. We implemented organization-based sharding with a simple configuration file: smaller organizations shared a container pool, while those with thousands of users got dedicated resources. This isolation allowed us to keep scaling while maintaining performance across our user base.</p>

<p><img src="https://philcalcado.com/img/building-ai-products-i/arch-shards.png" alt=""></p>

<p>This simple change gave us breathing room by preventing larger accounts from blocking smaller ones. We also added priority processing, deprioritizing inactive users and those we learned were away from work.</p>

<p>While sharding gave us parallelism, we quickly hit the fundamental scaling challenges of GenAI systems. Traditional microservices can scale horizontally because their external API calls are mostly for data operations. But in AI systems, these slow and unpredictable third-party API calls are your critical path. They make the core decisions, and this means everything is blocked until you get a response.</p>

<p>Python’s async features proved invaluable here. We restructured our agent-model interactions using <a href="https://refactoring.guru/design-patterns/chain-of-responsibility">Chain of Responsibility</a>, which let us properly separate CPU-bound and IO-bound work. Combined with some classic systems tuning—increasing container memory and <code>ulimit</code> for more open sockets—we saw our request backlog start to plummet.</p>

<p><a href="https://platform.openai.com/docs/guides/rate-limits">OpenAI rate limits</a> became our next bottleneck. We responded with a token budgeting system that <a href="https://dagster.io/glossary/data-backpressure">applied backpressure</a> while hardening our LLM calls with exponential backoffs, caching, and fallbacks. Moving the heaviest processing to off-peak hours gave us extra breathing room.</p>

<p>Our final optimization on the architectural: moving from OpenAI’s APIs to Azure’s GPT deployments. The key advantage was <a href="https://learn.microsoft.com/en-us/azure/ai-services/openai/quotas-limits">Azure’s per-deployment quotas</a>, unlike OpenAI’s organization-wide limits. This let us scale by load-balancing across multiple deployments. To manage the shared quota, we extracted our GPT calling code into a dedicated service rather than adding distributed locks</p>

<p><img src="https://philcalcado.com/img/building-ai-products-i/arch-gpt-proxy.png" alt=""></p>

<h3 id="the-zero-one-infinity-rule">The Zero-one-infinity rule</h3>

<p>One of my favorite adages in computer science is <a href="https://en.wikipedia.org/wiki/Zero_one_infinity_rule">“There are only three numbers: zero, one, and infinity.”</a> In software engineering, this manifests as having either zero modules, a monolith, or an arbitrary and always-growing number. As such, extracting the <code>GPTProxy</code> as our first remote service paved the way for similar changes.</p>

<p>The most obvious opportunity to simplify our monolith and squeeze more performance from the system was extracting the logic that pulled data from our users’ connected productivity tools. The extraction was straightforward, except for one challenge: our event bus needed to work across services. We kept using SQLAlchemy’s event system, but replaced our simple observer loop with a proper <a href="https://en.wikipedia.org/wiki/Publish%E2%80%93subscribe_pattern">pub/sub</a> implementation using Postgres as a queue.</p>

<p><img src="https://philcalcado.com/img/building-ai-products-i/arch-int-worker.png" alt=""></p>

<p>This change dramatically simplified things—we should have done it from the start. It isolated a whole class of errors to a single service, making debugging easier, and let developers run only the components they were working on.</p>

<p>Encouraged by this success, we took the next logical step: extracting our agents and inference pipelines into their own component.</p>

<p><img src="https://philcalcado.com/img/building-ai-products-i/arch-agents-worker.png" alt=""></p>

<p>This is where my familiar service extraction playbook stopped working. I’ll cover the details of our inference pipelines in the next article, but first, let’s talk about how we distributed our agents.</p>

<h3 id="agents-as-distributed-objects">Agents as Distributed Objects</h3>

<p>As successful as we were with modeling agents as objects, we’d always been wary of distributing them. My ex-colleague <a href="https://martinfowler.com/bliki/FirstLaw.html">Martin Fowler’s First Law of Distributed Objects</a> puts it best: <strong>don’t</strong>.</p>

<p>Still, I think that <a href="https://martinfowler.com/articles/distributed-objects-microservices.html">Martin’s “exception” for microservices</a> applies just as well for agents:</p>

<blockquote>
  <p>[My objection is that] although you can encapsulate many things behind object boundaries, you can’t encapsulate the remote/in-process distinction. An in-process function call is fast and always succeeds […] Remote calls, however, are orders of magnitude slower, and there’s always a chance that the call will fail due to a failure in the remote process or the connection.</p>
</blockquote>

<p>The problem with the distributed objects craze of the 90s was its promise that fine-grained operations—like iterating through a list of <code>user</code> objects and setting <code>is_enabled</code> to false—could work transparently across processes or servers. Microservices and agents avoid this trap by exposing coarse-grained APIs specifically designed for remote calls and error scenarios.</p>

<p>We kept modeling our agents as objects even as we distributed them, just using <a href="https://en.wikipedia.org/wiki/Data_transfer_object">Data Transfer Objects</a> for their APIs instead of domain model objects. This worked well since not everything needs to be an object. Inference pipelines, for instance, are a poor candidate for object orientation and benefit from different abstractions.</p>

<p>At this stage, our system consisted of multiple instances of a few docker images on ECS. Each container exposed FastAPI HTTP endpoints, with some continuously polling our event bus.</p>

<p>This model broke down when we added backpressure and <a href="https://learn.microsoft.com/en-us/dotnet/architecture/cloud-native/application-resiliency-patterns">resilience patterns</a> to our agents. We faced new challenges: what happens when the third of five LLM calls fails during an agent’s decision process? Should we retry everything? Save partial results and retry just the failed call? When do we give up and error out?”</p>

<p>Rather than build a custom orchestrator from scratch, we started exploring existing solutions to this problem.</p>

<p>We first looked at ETL tools like Apache Airflow. While great for data engineering, Airflow’s focus on stateless, scheduled tasks wasn’t a good fit for our agents’ stateful, event-driven operations.</p>

<p>Being in the AWS ecosystem, we looked at Lambda and other serverless options. But while serverless has evolved significantly, it’s still optimized for stateless, short-lived tasks—the opposite of what our agents need.</p>

<p>I’d heard great things about Temporal from my previous teams at DigitalOcean. It’s built for long-running, stateful workflows, offering the durability and resilience we needed out of the box. The multi-language support was a bonus, as we didn’t want to be locked into Python for every component.</p>

<p>After a quick experiment, we were sold. We migrated our agents to run all their computations through Temporal workflows.</p>

<p>Temporal’s core abstractions mapped perfectly to our object-oriented agents. It splits work between side-effect-free workflows and flexible activities. We implemented our agents’ main logic as Workflows, while tool and API interactions—like AI model calls—became Activities. This structure let Temporal’s runtime handle retries, durability, and scalability automatically.</p>

<p>The framework wasn’t perfect though. Temporal’s Python SDK felt like a second-class citizen—even using standard libraries like Pydantic was a challenge, as the framework favors data classes. We had to build quite a few converters and exception wrappers, but ultimately got everything working smoothly.</p>

<p>Temporal Cloud was so affordable we never considered self-hosting. It just works—no complaints. For local development and builds, we use their Docker image, which is equally reliable. We were so impressed that Temporal became core to both our inference pipelines and Outropy’s evolution into a developer platform!</p>

<p>Stay tuned for a deeper dive into Temporal and inference pipelines in the next installment of this series!</p>

  </article>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Homebrew Batteries (118 pts)]]></title>
            <link>http://www.hanssummers.com/homebrew/homebrewbattery.html</link>
            <guid>42521069</guid>
            <pubDate>Fri, 27 Dec 2024 09:51:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://www.hanssummers.com/homebrew/homebrewbattery.html">http://www.hanssummers.com/homebrew/homebrewbattery.html</a>, See on <a href="https://news.ycombinator.com/item?id=42521069">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<td>

<table>
<tbody>
<tr>
<td>I had lots of fun building homebrew batteries. I wanted to build a <a href="https://www.hanssummers.com/qrsslp.html">radio transmitter</a> powered by natural, homebrew power sources. The first thought, was a lemon battery (or few).<p>  All over the place on the internet, you can read about the classic school science project, sticking two dissimilar metals into a lemon and generating some small amount of power. Sometimes potatoes. You can even buy "kits" to do this in toystores. What seems to be generally lacking is any measurements on such batteries. How much power can they supply? And for how long? And what factors are involved to determine these parameters? Sure, you can power an LCD clock, until the lemon dries out. But they consume a miniscule current anyway. I found some websites which claimed that a single lemon will produce 0.5V and 1mA of current. They didn't say how long for. Several lemons in series are supposedly enough to light an LED.</p></td>
<td><!-- JW "Simple Image Gallery" Plugin (v1.2.1) starts here -->
					
					
					
					<div><p><a href="https://www.hanssummers.com/images/stories/battery/lemons/lemon.jpg" rel="lightbox[sig0]" title="Navigation tip: Hover mouse on top of the right or left side of the image to see the next or previous image respectively.<br /><br />You are browsing images from the article:<br /><b>Batteries</b>" alt="You are browsing images from the article: Batteries" target="_blank"><img src="https://www.hanssummers.com/plugins/content/plugin_jw_sig/showthumb.php?img=battery/lemons/lemon.jpg&amp;width=200&amp;height=200&amp;quality=80"></a></p></div>
<!-- JW "Simple Image Gallery" Plugin (v1.2.1) ends here --></td>
</tr>
</tbody>
</table>
<p><strong>On this page, you can click all thumbnail photographs to get bigger versions. But the graphs are already the full-size versions, so you can't click them.</strong></p>
<h2>Simple lemon cell</h2>
<p><img src="https://www.hanssummers.com/images/stories/battery/rawlemon.gif" width="400" height="224"></p>
<p>My first attempt at a lemon battery consisted of a standard lemon, fresh from the supermarket, with a copper wire (solid core household cable with the insulation stripped off) poked in one side and a normal steel bolt pushed in the other side. To test this power generation masterpiece, I rigged up a 10k variable resistor in series with a 330-ohm fixed resistor and my two DVM to measure voltages and currents.</p>
<p>Indeed, when unloaded, the lemon produced around 0.5 Volts. But what about under load? The 10K potentiometer allowed me to vary the load between 10.3k and 330 ohms. The graph to the right shows the resulting battery voltage vs load current. As soon as I connected the load, the voltage dropped to 56mV even though the load was more than 10kOhms. The current was only 5.5 microamps! At the other end of the potentiometer, by the time the load was reduced to 330-Ohms, the current increased to 8uA, but the voltage falls to only 2.6mV. This lemon battery produced only 0.3uW of power across a 10k load! To power my <a href="https://www.hanssummers.com/qrsslp.html">40m QRSS transmitter</a> I'd need about 30,000 lemons.</p>
<p>Next, I cut a strip of baked bean can tin, maybe 50 x 5mm. I inserted that into the lemon, in place of the steel bolt. The open-circuit voltage was 498mV, dropping to approx 300mV through my 10.3kOhm load. That's a current was of 29uA, for a power of 8.7uW. That's a 28-fold increase in power production! But still, nowhere near the claimed 1mA on some websites. If they lit an LED with some of these in series, then Ok, but it must have been a low-current LED. To power my <a href="https://www.hanssummers.com/qrsslp.html">40m QRSS transmitter</a>, now I'd only need 1,000 lemons. But that's still a lot of lemons.</p>
<p>In the end, I was so disappointed with the ability of a lemon to produce much current, that I even forgot to take a photograph. So all you get is the graph.</p>
<h2>Lemon juice cell</h2>
<p>Not quite ready to give up on lemons altogether, however. My next battery cell was made from baked bean tin, soldered into a small cup. The dimensions of the cup are 35 x 23 x 4mm. A small 25 x 25mm square soldered on the bottom keeps it upright. The tin cup is the negative terminal of the battery. To construct the other electrode, I used about 25cm of copper wire, wound into a flat spiral. The copper wire is household lighting cable, with the insulation stripped off. To keep the electrodes apart, I wrapped the copper spiral in a piece of kitchen tissue. Then poured in lemon juice squeezed directly from a lemon. The idea here, is to increase the surface area of the electrodes and decrease the distances involved, to reduce the internal resistance of the battery.</p>
<div><div><p><a href="https://www.hanssummers.com/images/stories/battery/smallcell/small.jpg" rel="lightbox[sig1]" title="Navigation tip: Hover mouse on top of the right or left side of the image to see the next or previous image respectively.<br /><br />You are browsing images from the article:<br /><b>Batteries</b>" alt="You are browsing images from the article: Batteries" target="_blank"><img src="https://www.hanssummers.com/plugins/content/plugin_jw_sig/showthumb.php?img=battery/smallcell/small.jpg&amp;width=200&amp;height=200&amp;quality=80"></a></p></div><div><p><a href="https://www.hanssummers.com/images/stories/battery/smallcell/small2.jpg" rel="lightbox[sig1]" title="Navigation tip: Hover mouse on top of the right or left side of the image to see the next or previous image respectively.<br /><br />You are browsing images from the article:<br /><b>Batteries</b>" alt="You are browsing images from the article: Batteries" target="_blank"><img src="https://www.hanssummers.com/plugins/content/plugin_jw_sig/showthumb.php?img=battery/smallcell/small2.jpg&amp;width=200&amp;height=200&amp;quality=80"></a></p></div>

</div>
<!-- JW "Simple Image Gallery" Plugin (v1.2.1) ends here -->
<p>The results of this experiment were a little bit more encouraging. The current at 10.3k load was 34uA, which was only a little bit more than the raw lemon alone. But it coped better with lower resistance loads, and at about 500 ohms load could support a current of 150uA and the voltage dropped to 81mV. Peak power production occured at a little lower current than this, and was 17uW. This cell is therefore about twice as good as my raw lemon (with tin strip electrode).</p>
<h2>Improved lemon juice cell</h2>
<p>I was encouraged by this result and decided to build a bigger version of the same cell, incorporating larger electrodes and keeping the electrode separation as small as possible. For this larger cell, I used a whole 400g baked bean can. I cut the wall of the can into two pieces, folded together such that I produced a cell having three compartments. A piece of tin strip from the offcuts completed this small tank. All soldered together (baked bean can tin solderes very nicely). The size of this cell was about 70 x 50 x 20mm. The flat spiral coil is in this case still made from copper wire, but a longer length of it. Three such spirals are used in this battery. Each one was wrapped in a piece of kitchen tissue to stop it touching the tin electrode. Finally, lemon juice was poured into the cell. One lemon produces enough juice to fill the cell. The three compartments weren't sealed from each other; the only reason for the three compartments was to keep as much tin and copper as close together as possible.</p>

<!-- JW "Simple Image Gallery" Plugin (v1.2.1) ends here -->
<div><p>Well, the results from this cell were much better than previous attempts, as might be expected:</p><p>  <img src="https://www.hanssummers.com/images/stories/battery/lemon1.gif" width="419" height="288"> <img src="https://www.hanssummers.com/images/stories/battery/lemon2.gif" width="503" height="260"></p><p>  The first graph (above left) shows the voltage vs current of both the small lemon juice cell (see above) and my larger cell (this section). The large cell shows a massive improvement. It can cope with a 1mA current draw, and the voltage drops only to 324mV. This is a power production of 322uW, which is 19 times better than the small lemon juice cell!</p></div>
<p>In my second graph (above right), I discharged the battery through a fixed resistance of 330 ohms, which initially takes more than 1mA of current. Note that the discharge isn't a constant current one. As the voltage declines, so does the current so the power consumption is decreasing as the experiment runs. I repeated the discharge experiment three times. The first, started at 22:38 in the evening and I left it running for 90 minutes. The following morning, I tried again at 10:30am. I found that the voltage decay was faster, and to a lower value, than the first discharge, which is not a surprising result. What WAS more surprising however, was when I tried a third discharge run at 13:30. In this case the battery seemed to substantially recover, such that the decay was less rapid and to a higher voltage. In fact even 18 hours into this 3'rd discharge run, the voltage was practically unchanged at 155mV. At that point, the power production is 73uW.</p>
<p>Whilst certainly a big improvement, the long term power production of 73uW means that if I wanted to produce say 10mW of power in order to produce a few mW of RF from a transmitter, I would require approximately 140 of these cells connected together. That's 140 baked bean cans, 140 lemons, a lot of soldering, and a whole LOT of mess. Somehow, I don't think I'll be giving Duracell much competition any time soon.</p>
<h2>Bleach cell</h2>
<p>A little bit more internet research. I read somewhere of a fellow who put bleach into an ice cube tray, with electrodes separated by kithen tissue and connecting "cells" made from each ice cube's hole, in series. So I decided to have a go with bleach. I cleaned the original "small" lemon juice cell to get rid of all the lemon juice, used a new piece of kitchen tissue to separate the electrodes, and filled it up with undiluted bleach.</p>
<div><p>Now here's a REALLY much more impressive result! Forget about lemons. Keep them for your cooking. Try bleach instead! It's cheaper than lemons, and it works MUCH better. In fact, it even SMELLS better, and less strong! You'd think not, but it's true. Too much lemon juice and the room will really start to smell. Bleach smells strong when it's been spread over a large area, but not so bad when the exposed surface area is small.</p><p>  <img src="https://www.hanssummers.com/images/stories/battery/bleach2.gif" width="432" height="246"> <img src="https://www.hanssummers.com/images/stories/battery/bleach3.gif" width="531" height="252"><br> The first graph shows the voltage vs current characteristic. The first thing to notice is that the unloaded voltage of the bleach cell is 0.8V, which is substantially more than the 0.5V produced by a lemon juice electrolyte. Even this small cell can supply 0.25mA of current whilst only dropping the voltage to 606mV. I did two separate runs. In noticed that the bleach cell seems to take a while to "warm up". The performance improves, after a little use. I noticed this several times in subsequent experiments. The power production of this cell was 152uW into 330 ohms load. At smaller loads, it would be even more (but the voltage would suffer). What this means is that roughly speaking, the identical same cell is <strong>TEN TIMES</strong> better when filled with bleach, compared to lemon juice!</p></div>
<p>The second graph shows the discharge characteristic through a fixed 330 ohm resistor. This small bleach cell sustained a current of around 1mA for over 2 hours! You will note the wild fluctuation in voltage during this time, which would make it rather unsuitable for powering many applications. This was I suspect due to bubbles in the bleach, of which there were many. Furthermore, it was noted that the bleach partially disolved the kitchen tissue, leaving a translucent gunge in its place.</p>
<p>Because of the disolved kitchen tissue, I decided NOT to try bleach in my larger improved lemon juice cell (see above). It was very difficult already to get those larger spiral coils of wire neat and flat, wrapped in tissue, and somehow squeezed into the three narrow compartments of the cell. To do that again with bleach rather than lemon juice, and the attendant problems of disolving kitchen tissue, not to mention the damage to clothing... basically it really did not appeal.</p>
<h2>LARGE bleach cell</h2>
<p>Right. Enough of the research, now I want a practical cell that I can use to power my <a href="https://www.hanssummers.com/qrsslp.html">40m QRSS transmitter</a>. The kitchen tissue dissolving problem meant it isn't suitable as a means to keep the two electrodes apart. Bleach is fierce stuff and it is difficult to think of suitable separating materials which would let the bleach through, but not be rapidly degraded. On the other hand, I wanted to get as much copper and tin as close together as possible. I thought long and hard about this and the solution I came up with is effective yet very simple to make.</p>

<!-- JW "Simple Image Gallery" Plugin (v1.2.1) ends here -->
<p>Above, the construction process. One cell uses one baked bean can. I liked baked beans, and anyway I have a collection of baked bean cans because they are great as shielding material, or as circuit substrate for "ugly" construction. Next comes the "other" electrode, for which I used copper wire again. The copper wire is from a bit of old house lighting cable, left over on a reel. I have grey and white coloured ones (on the bottom and top respectively, in the picture). I used the white wire because the copper was thicker - over 1mm diameter of copper. Stripping off the red and black insulation was a big task and I got blisters on my hands.</p>
<p><img src="https://www.hanssummers.com/images/stories/battery/bleach1.gif" width="473" height="251"> Each cell uses two 7-foot lenths of copper wire joined end-to-end. The join is brought OUT of the cell and soldered outside, so as to avoid corrosion breaking the contact if the wires were just twisted together. The wire is wound on a 250ml Johnson's orange juice bottle. I drink one of these at lunchtime so collected them over the course of a week. I filled the orange juice bottle with water, so that 1) it was less compressible than it would have been if it was air-filled and 2) so that it was heavy enough to rest firmly on the bottom of the can when the bleach was poured in, rather than trying to float. The third-from-left photo above shows three cells in various stages of construction. I like the orange juice bottle idea. The separation between the copper wire and tin walls is about 7mm, but no material is required between the two to keep them apart, as long as the cell is placed carefully on a horizontal surface. Furthermore, the orange juice core means that much less bleach is required, limiting it to about 150ml per cell.</p>
<p>The far right photo above, shows the test setup where I am characterising one bleach cell.</p>
<p>The results for this battery cell are at last good enough for it to be seriously considered for powering my <a href="https://www.hanssummers.com/qrsslp.html">40m QRSS transmitter</a>. Across my usual 330 ohm load, it produces 2mA current, dropping the cell voltage to nearly 700mV and producing 1.4mW of power.</p>
<h2>Bleach battery</h2>

<!-- JW "Simple Image Gallery" Plugin (v1.2.1) ends here -->
<table>
<tbody>
<tr>
<td>
<p>I built FOUR of these baked bean can cells, and connected them in series. One 750ml bottle of ASDA thick bleach costs 60 or 70 pence and is more than enough to fill all four cells and clean the toilet too. The voltage of the four cells is more than 3V. I connected the homebrew battery up to my <a href="https://www.hanssummers.com/qrsslp.html">40m QRSS transmitter</a> - it's the circuit in the bottom right corner of the photo, 3'rd from left. That circuit is built on a baked bean can tin substrate too!</p>
<p><strong>SUCCESS!</strong> With this battery powering the TX, it produced an output of about 3mW (into 50 ohm load) on frequency 7,000,850. On the first day of operation, the beacon received reception reports from G3VYZ, ON5SL, and GM0RZY. The report from ON5SL is shown as the rightermost image above. click that photo or <a href="https://www.hanssummers.com/qrsslp.html">Click here to read more about my 40m QRSS transmitter</a>.</p>
</td>
<td><a href="https://www.hanssummers.com/qrsslp.html"><img src="https://www.hanssummers.com/images/stories/battery/rpt.jpg" width="200" height="150"></a></td>
</tr>
</tbody>
</table>
<h2>Demise of the bleach battery</h2>
<p><img src="https://www.hanssummers.com/images/stories/battery/voltage.gif" width="670" height="214"></p>
<p>The bleach battery powered my <a href="https://www.hanssummers.com/qrsslp.html">40m QRSS transmitter</a> for over a week, at a peak RF power output of over 6mW. The last reception report was received on the 5'th day, after which the RF power output dropped to below a milliwatt so reception would have become increasingly difficult from my poor aerial.</p>
<p>The graph to the right shows the discharge of the bleach battery. The upper (blue) curve is voltage (V) and the lower (red) curve is the current (mA). One could estimate an average current of perhaps 2.2mA over this 5 day period, leading to some kind of rough estimate for the capacity of this battery of approximately 250mAh. The voltage variation during the discharge is quite harsh, and not at all even. Around day 3 the battery peaked in performance. It is interesting that the battery improved during the first few days, rather than simply discharge from its initial value.</p>
<p>The photos below show that some severe corrosion of the baked bean can tin occured during this experiment. After a couple of days, the corrosion started to eat through the tin at the seam between the wall of the tin and its base and I had to stand them on saucers. Two of the tins were much worse affected than the others. When I finally threw away the tins, the base of the tin could easily be broken with gentle pressure. However, the inside of the tin, and the copper wire, were clean and uncorroded. The corrosion all seemed to happen at the interface with the air, or at the join in the tin. (Last three photos are courtesy of Steve G0XAR while visiting).</p>

<!-- JW "Simple Image Gallery" Plugin (v1.2.1) ends here --> <br> <img src="https://www.hanssummers.com/images/stories/battery/salt.gif" width="425" height="233">
<h2>Salt cell</h2>
<p>Considering the acceptable state of the copper electrodes following the bleach battery experiment, and also encouraging reports of salt and vinegar experiments from Anders Sandstrom, I decided to try a salt cell. I dissolved a large amount of salt into boiling water, until I could dissolve no more. This ensures a saturated salt solution. I used fresh baked bean cans but the same bottle with copper wire wound around.</p>
<p>My measurements on the salt cell are shown in the graph on the right. The same standard set-up was used as for evaluation of previous cells. It seems capable of supplying a good current but the voltage is rather low, which is consistent with what Anders found.</p>
<h2>Vinegar cell</h2>
<p><img src="https://www.hanssummers.com/images/stories/battery/vinegar.gif" width="404" height="219"></p>
<p>Next comes my vinegar cell. Balsamic vinegar, to be exact, since I had no plain vinegar. I covered the bottom of a new baked bean can with a few mm of balsamic vinegar, put in the orange juice bottle with wire wound around, and filled up with water.</p>
<p>My measurements on this vinegar cell are in the graph on the right. It produces about twice the voltage of the salt solution, but half the voltage of the pure bleach. The toxicity of this weak solution of vinegar is considerably less than the bleach. The current provision ability is good, like the salt. I decided to connect four of these vinegar cells in series and try them on the <a href="https://www.hanssummers.com/qrsslp.html">40m QRSS transmitter</a>.</p>
<p>Finally - <a href="https://www.hanssummers.com/images/stories/battery/spd.ods" target="_blank">click here for the spreadsheet containing raw data</a> (Open Office format)</p>
<h2>Ideas and comments from Anders Sandstrom</h2>
<p>Anders writes: <em>After I read the page about homemade batteries on your website I decided to try to make some batteries myself.</em></p>
<p><em> I had some good results with using a steel can and copper wire, with vineager essence and caustic soda between. I could only get 600 mV and 3 mA of short circut current with only the vineager essence, but after i pored in some caustic soda I got over one volt from a single cell and over 60 milliamperes of short circut current! I tried to make another one, but the second one I only got 700 mV from, but still the same high current. There was also some salt in the first one from another experiment, but I found that poring salt into the soloution actually decreases the voltage, but increses the maxium current. I had also good results with using copper and zink, but my only source of zink were nails with zink on the outside (I don't know what they are called in English). However, I have no idea for how long the battery cells can last.</em></p>
<div><div><p><em><a href="https://www.hanssummers.com/images/stories/battery/anders/anders1.jpg" rel="lightbox[sig6]" title="Navigation tip: Hover mouse on top of the right or left side of the image to see the next or previous image respectively.<br /><br />You are browsing images from the article:<br /><b>Batteries</b>" alt="You are browsing images from the article: Batteries" target="_blank"><img src="https://www.hanssummers.com/plugins/content/plugin_jw_sig/showthumb.php?img=battery/anders/anders1.jpg&amp;width=200&amp;height=200&amp;quality=80"></a></em></p></div><div><p><em><a href="https://www.hanssummers.com/images/stories/battery/anders/anders2.jpg" rel="lightbox[sig6]" title="Navigation tip: Hover mouse on top of the right or left side of the image to see the next or previous image respectively.<br /><br />You are browsing images from the article:<br /><b>Batteries</b>" alt="You are browsing images from the article: Batteries" target="_blank"><img src="https://www.hanssummers.com/plugins/content/plugin_jw_sig/showthumb.php?img=battery/anders/anders2.jpg&amp;width=200&amp;height=200&amp;quality=80"></a></em></p></div></div><em>
<!-- JW "Simple Image Gallery" Plugin (v1.2.1) ends here --></em>
<p><em> I have now made 2 new cells, using copper pipe and sheet metal. I used water and drain opener as electrolyte. First i took a piece of copper tube, about 6-7 cm long and wrapped it in paper as insulation. I cut some sheet metal and wrapped it around it to form another tube. I put it in a small glass jar and poured in water (about 0,75 dl) and a spoon ( 15 ml) of caustic soda. The voltage was almost 1,2 volts for a new cell, but i decreases fast to about 1 volt and then stays there. I measured the current of a cell when it was places in a short circut and it was over 100 mA.</em></p>
<p><em>I tried to recharge the cells when they were almost empty, and it worked. I used a car battery charger set to 6 V and the current was about 300 mA, probably to much because bubbles started to form and after one hour the caustic soda solution was bubbling over the jar. But it worked and cell voltage was increased to 1,1 V and I could power a mp3 player for almost 3 minutes with 2 cells in series.</em></p>
<p><em>I have attached 2 photos of the cells in this email. The cells were about 1 day old when they where taken. </em></p>
<h2>Ideas and comments from John Beech G8SEQ</h2>
<p>John writes: <em> I had a look at your batteries and I'm not sure I agree with your calculations ( though they might be true for your batteries). Way back in the early 1970's ( which was probably before you were born) we had what was called the "Three Day Week" where everyone ( except me!) worked a three day week because the power workers went on strike and we had electricity cuts left, right and centre.</em></p>
<p><em>People were making oil lamps that run on smoky, smelly cooking oil and animal fat, but I thought I could do better and made a battery out of houseold materials ( People had panic-bought all the dry cells and most of them had gone flat by then). I used an aluminium 35 mm film can, some copper wire and household bleach.( I tried cooking salt first) This gave enough energy to light a 1.5 v torch bulb to full brightness for about 2 hrs. I then progressed to aluminium foil and jam jars, but these used up too much bleach, so I filled the jam jars with marbles ( later quarz pebbles) as inert displacers. Later I used aluminium drinks cans. I have made loads since as demos to school kids and at Amateur Radio Rallies. The design was published in RadComm TT many years ago. At one rally I actually used one cell to re-charge some Nicads and then had a QSO on 2m using a 2W handheld. I did a test using a Coca Cola Can and a jumbo LED ( about 40 mA) - it lit it for a fornight continuously. Then the experiment was stopped because it was end of term and the lab techs wanted to clear up!</em></p>
<p><em>These cells work better if you use a carbon rod as the positive electrode. The off load terminal voltage is about 2 v. Salt will produce this sort of voltage, but the cell quickly polarizes, reducing the current. By using chlorate bleach, the hydrogen produced is oxidized to water and current is maintained. Chorate bleaches also contain sodium hydroxide which attacks aluminium whether you are drawing current or not, but this soon gets used up. However, it has the effect of etching the aluminium surface increasing its area and increases the current generating capability. Several of these cells would definitely work a QRP TX directly in an emergency.</em></p>
<p><em>Incidentally, I wrote to Guiness in the 70's to ask them to change the design of their cans. I tried theirs and was dissapointed with the results until I found that their cans were steel with aluminium tops. I explained that this was the worst possible combination of metals from the re-cycling point of view. They did change the design and they are now all aluminium. Whether or not I had any influence on it I don't know, but I would like to think so. Conerting aluminium metal back to electricity is NOT the most efficient way of recycling aluminium, Re-melting and re-processing is the most energy efficient and therefore money efficient way.</em></p>
<div><p><em>I have been toying with the idea of making a cell which uses seawater as the electrolyte. This would be flushed with fresh seawater every time a wave came up the beach. I reckon there might be enough oxygen in the sea water to depolarize the cell. Just the job if you are stuck on a desert island with only a pile of coke cans or bits of aircraft!.</em></p></div>

</td>
</div></div>]]></description>
        </item>
    </channel>
</rss>