<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 30 Nov 2024 19:30:04 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[How honeycrisp apples went from marvel to mediocre (128 pts)]]></title>
            <link>https://www.seriouseats.com/how-honeycrisp-apples-went-from-marvel-to-mediocre-8753117</link>
            <guid>42282476</guid>
            <pubDate>Sat, 30 Nov 2024 16:44:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.seriouseats.com/how-honeycrisp-apples-went-from-marvel-to-mediocre-8753117">https://www.seriouseats.com/how-honeycrisp-apples-went-from-marvel-to-mediocre-8753117</a>, See on <a href="https://news.ycombinator.com/item?id=42282476">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="mntl-sc-page_1-0" data-sc-sticky-offset="100" data-sc-ad-label-height="11" data-sc-ad-track-spacing="100" data-sc-min-track-height="250" data-sc-max-track-height="600" data-sc-breakpoint="50em" data-sc-load-immediate="5" data-sc-content-positions="[1, 1, 1, 1250, 1, 1, 1, 1]" data-bind-scroll-on-start="true"><p id="mntl-sc-block_1-0"> It was a chilly Saturday morning in October, and at my local grocery store, shoppers were browsing the apple selection: piles of Gala, Pink Lady, Golden Delicious, Fuji, Snapdragon, and Honeycrisp beckoned. I lingered over the organic Honeycrisps, pausing to look at the $3.99-per-pound price tag, before filling my produce bag with several conventional Galas, which sold for a more reasonable $1.69 per pound. Though I had my heart set on the Honeycrisps, I’d recently had one too many bland, mealy ones with none of the fruit’s signature snap and sweet, tangy flavor, and I was unsure if I was ready to take that risk again, especially given the price.&nbsp;
</p>

<div id="mntl-sc-block_3-0"><p> It would have been an easier decision if Honeycrisps were as good today as they used to be. I first tasted one 10 years ago, standing at my mother-in-law’s kitchen counter in St. Louis on a cool September day. I grasped the rosy fruit she handed me and took a bite. The apple’s paper-thin skin produced an audible crunch, and a burst of sweet, tart juice immediately filled my mouth. I chewed carefully. I couldn’t recall the last time I ate an apple for pleasure, on its own—not in my hand as a grab-and-go breakfast as I rushed out of the house, not sliced up and slathered with <a href="https://www.seriouseats.com/creamy-peanut-butter-taste-test-8627519" data-component="link" data-source="inlineLink" data-type="internalLink" data-ordinal="1">nut butter</a>, and not peeled, cored, chopped, and baked into a <a href="https://www.seriouseats.com/pennsylvania-dutch-apple-pie-recipe-8399305" data-component="link" data-source="inlineLink" data-type="internalLink" data-ordinal="2">pie</a>. The Honeycrisp apple was revelatory for me: It was an apple that I truly enjoyed eating on its own.&nbsp;</p><p>And I did, for several years, until I noticed that the Honeycrisp apples I bought were, with increasing frequency, a miss. There were a few good ones here and there, but I often came across Honeycrisp apples that were dry and mealy. Beyond the hefty price tag, there was little to distinguish them from other standard apple varieties. <span></span>Honeycrisps from my farmers market were typically better than those I purchased from the grocery store, but even those Hudson Valley–grown apples weren’t immune. As recently as September of this year, I had several Honeycrisp apples from a local farm that were terribly mushy and flavorless, making me wonder if they had mistakenly labeled another apple variety—nothing about those apples was like the fruit I had once loved.&nbsp;</p><p>I’m not the only one who has noticed the fluctuation in quality. My colleagues <a href="https://www.seriouseats.com/daniel-gritzer-5118638" data-component="link" data-source="inlineLink" data-type="internalLink" data-ordinal="3">Daniel</a> and <a href="https://www.seriouseats.com/megan-o-steintrager-7371874" data-component="link" data-source="inlineLink" data-type="internalLink" data-ordinal="4">Megan</a> have both had their fair share of inferior Honeycrisps in the past couple of years. I also found multiple instances of people complaining about Honeycrisp quality on Reddit: Three years ago, <a href="https://www.reddit.com/r/NoStupidQuestions/comments/t16tq8/why_do_honeycrisp_apples_suck_now/" data-component="link" data-source="inlineLink" data-type="externalLink" data-ordinal="5">a user wrote</a> that the Honeycrisp apples they bought were “unrecognizable from the big sweet apples from the late 00s and 10s.” Another user, <a href="https://www.reddit.com/r/rant/comments/19bcwve/what_the_hell_happened_to_honeycrisp_apples/" data-component="link" data-source="inlineLink" data-type="externalLink" data-ordinal="6">who posted earlier this year</a>, mourned the loss of the “super sweet and crisp” apples they were able to find 10 years ago. The Honeycrisps of today, they wrote, are “bitter and barely sweet at all" and "On top of that they aren’t crisp either!”</p><p>What went wrong? <span></span>The answer is both simpler and more complex than you might think, and it’s impossible to answer that question without looking at how the Honeycrisp apple came about—and how it shot to stardom so quickly.
</p></div>

<figure id="mntl-sc-block_5-0"> 
<figcaption id="mntl-figure-caption_1-0"> <span><p>Getty Images / brizmaker</p></span>
</figcaption></figure>
<h2 id="mntl-sc-block_6-0"> <span> The Honeycrisp: Origins and Rise to Stardom </span> </h2>
<p id="mntl-sc-block_7-0"> In 1983, David Bedford, one of the seed breeders behind the Honeycrisp apple and a research scientist at the University of Minnesota, had his first taste of the fruit. Crisp and juicy with a pleasant tanginess, the apple was unlike any he’d had before. “It caused me some question,” he tells me, recalling the sensory shock he experienced. “I remember biting it and thinking, well, what’s going on here?”&nbsp;He describes picking up textural and flavor notes similar to Asian pears and watermelons, and trying to decide if the fruit was underripe or overripe. "I don't know if it was a moment or a day or a week that it took me to decide, I don't know what it is, but it's good." The tree, labeled MN1711, bore fruit that was a cross between the Keepsake apple and another experimental variety identified only as MN1627; the tree had failed a winter hardiness test, and the university’s apple breeding program had designated it for the compost heap. Bedford, however, decided to give the tree another chance. It paid off, because it yielded what has since become <a href="https://www.sos.state.mn.us/about-minnesota/state-symbols/state-fruit-honeycrisp-apple/#:~:text=The%20Honeycrisp%E2%84%A2%20apple%20%28Malus,tree%20with%20high%20quality%20fruit." data-component="link" data-source="inlineLink" data-type="externalLink" data-ordinal="1">Minnesota’s state fruit</a> and one of the most popular apple varieties today.
</p>

<p id="mntl-sc-block_9-0"> Together with Dr. Jim Luby, the former director of the University of Minnesota’s fruit breeding program, Bedford worked on improving the hardiness, texture, and flavor of the apple—placing it in the university’s evaluation program and observing it under different conditions—until they thought it was good enough to release to the public in 1991. “We had convinced ourselves on the breeding team that this is good, but we had no idea really what the rest of the world was thinking,” Bedford says. “It became clear in time that the world—the consumers—really did like this texture.”&nbsp;
</p>

<p id="mntl-sc-block_11-0"> For much of the 1960s and 1970s, Bedford tells me, there seemed to be no interest beyond the Red Delicious, the one “nice big shiny red apple that you could have year-round.” The Red Delicious was the result of the industrialization of the food system: National grocery stores and distributors wanted durable, aesthetically pleasing fruit that could be transported and stored easily, taste be damned. The skin was thick and leathery like naugahyde, with sweet, insipid flesh.
</p>

<p id="mntl-sc-block_13-0"> When Grady Auvil, the founder of Washington-based fruit company Auvil Fruit, began importing Granny Smith apples from New Zealand to the United States in the 1970s, it was a refreshing break from the Red Delicious for American consumers. The Granny Smith paved the way for the Honeycrisp: Americans welcomed the green apple’s tart flavor and crunch, signaling to growers and retailers that consumers were ready for different kinds of apples. When Bedford and Luby introduced Honeycrisp seedlings to nurseries and farmers in 1991, “there was at least some open-mindedness,” says Bedford. “Consumers had been sort of awakened to this idea that there was more to apples than Red Delicious.”&nbsp;
</p>

<p id="mntl-sc-block_15-0"> The Honeycrisp apple redefined what an apple could be. It was different from any other apple most American shoppers had encountered before, especially for consumers who frequented conventional grocery stores rather than farmers markets, where tastier heirloom varieties could be found even during the heyday of the Red Delicious. Unlike many other apple varieties, the Honeycrisp apple, journalists Deena Shanker and Lydia Mulvany noted in <a href="https://www.bloomberg.com/news/articles/2018-11-08/the-curse-of-the-honeycrisp-apple" data-component="link" data-source="inlineLink" data-type="externalLink" data-ordinal="1">Bloomberg</a> in 2008, “wasn’t bred to grow, store, or ship well," Instead, "It was bred for taste: crisp, with balanced sweetness and acidity.” Earlier this year, <a href="https://www.scientificamerican.com/article/apples-have-never-tasted-so-delicious-heres-why/" data-component="link" data-source="inlineLink" data-type="externalLink" data-ordinal="2">Bedford told <em>Scientific American</em></a> that you could separate the world of commercial apples into two phases: before Honeycrisp and after Honeycrisp. Before the variety’s debut, common grocery store apples were either soft and mealy or firm and dense. The Honeycrisp introduced the concept of a crisp apple to the public and, Bedford says, set a new bar for both customers and breeders—so much so that Bedford estimates, unofficially, that 50% of the new apple varieties coming onto the market today are Honeycrisp offspring.&nbsp;
</p>

<p id="mntl-sc-block_17-0"> This success is due to the fact that the Honeycrisp is—no exaggeration—built differently. It has a remarkably thin skin, and a crispness that is the result of the Honeycrisp having much larger cells than other apples. Apple cells contain vacuoles filled with juice; the cells are stacked on top of one another and held together by the lamella, or what Bedford describes as the “glue” that gives an apple its firm, crunchy texture. When you bite into an apple, your teeth cut through razor-thin skin and the layers of cells, fracturing the vacuoles of juice. It's these oversized cells that give the Honeycrisp its unique flavor and texture, making for a truly delicious apple with a crisp texture that people have come to crave.&nbsp;
</p>

<p id="mntl-sc-block_19-0"> Because the Honeycrisp was designed to thrive in Minnesota’s climate, Bedford and Luby made the apple available in the rest of the Midwest first, where growing conditions were fairly similar to those in the apple’s home state. Though nurseries began selling Honeycrisp cuttings in 1991, it took several years for the fruit to arrive at farmers markets and grocery stores in the Midwest. And when it did, it quickly became a word-of-mouth phenomenon.&nbsp;
</p>

<div id="mntl-sc-block_21-0"><p> People could not get enough. And unlike common apple varieties like the Red Delicious, Golden Delicious, or Granny Smith, the Honeycrisp wasn’t available to purchase year-round. Instead, it was only sold from September, when the apple was at its peak, to February. This scarcity drove up demand even more.</p><p>“People would go to their local apple orchard or to their supermarket because they had heard about [the Honeycrisp apple] in Minnesota or they tasted something,” Dr. Matthew Clark, the head of the University of Minnesota’s fruit breeding program, tells me. “Word got out, people were wanting it,” as the eating experience was “unlike any other.” Soon, growers were planting the Honeycrisp in New York and Washington.&nbsp;
</p></div>

<figure id="mntl-sc-block_23-0"> 
<figcaption id="mntl-figure-caption_2-0"> <span><p>Getty Images / Karolina Wojtasik/Bloomberg via Getty Images</p></span>
</figcaption></figure>
<h2 id="mntl-sc-block_24-0"> <span> Signs of Trouble </span> </h2>
<p id="mntl-sc-block_25-0"> The tree, however, proved difficult to grow, especially in Washington State, the heart of commercial apple production in the United States. (According to the US Apple Association, Washington is projected to produce 179 million bushels—about 63% of all the apples grown in the United States—in the 2024/2025 calendar year, making it the country’s top apple growing state.) “Really a variety cannot be successful unless it’s grown commercially in Washington,” Bedford says. “We sent trees out, they tested it, and I had more than one grower call me and say, ‘That’s the worst tree I’ve ever tried to grow here. I’m pulling all the trees out.’” Not only is the fruit a poor fit for the state’s climate, which is much warmer than Minnesota, but it’s also prone to several physiological and storage disorders, like bitter pit and soft scald, which can affect both the presentation and eating quality of the fruit when it’s stored for an extended period of time.&nbsp;
</p>

<p id="mntl-sc-block_27-0"> In order to ensure the health of the tree, it’s essential to thin or selectively remove parts of it, a labor-intensive process. “Even if you’ve done all that hand-thinning and invested a lot in the crop, you can lose a lot of it to [bitter pit],” Josh Morgenthau, the owner of Fishkill Farms in Fishkill, New York, says. “It’s very fickle.” Unfortunately, even when farmers apply all of the best practices for ensuring the quality of their Honeycrisp crop, bitter pit can continue to show up in storage, and Morgenthau estimates that about 20% of fruit that looks clean when picked is no longer sellable because bitter pit shows up after a few months.
</p>

<p id="mntl-sc-block_29-0"> The fruit’s extraordinarily thin skin may be pleasant for biting through, but it also means the apple is prone to sunburn, in which the parts of the apple that get more sun exposure experience what scientists call “<a href="https://fruit.wisc.edu/2024/08/01/understanding-sunburn-in-apples-causes-symptoms-and-management/" data-component="link" data-source="inlineLink" data-type="externalLink" data-ordinal="1">tissue collapse</a>,” causing the fruit to turn brown or black. The delicate skin also makes it time-consuming to harvest: To prevent the apple’s sharp stems from puncturing neighboring apples in storage, the stems must be clipped extra-short. “Now, if you only had to do a couple hundred of those a day, no big deal,” Bedford muses. “But when you’re picking hundreds of thousands of these things, that slows down the picking process, which increases your costs.” (Dr. Kate Evans, the breeder at Washington State University who came up with the Cosmic Crisp apple, tells me that “something like 10 billion apples a year get picked by hand in the state of Washington.”)
</p>

<p id="mntl-sc-block_31-0"> Despite the challenges, growers in Washington—enticed by the profits the Honeycrisp could potentially bring and ignoring their initial bad experiences with it—eventually ended up planting acres and acres of Honeycrisp trees. As of 2017, the apple variety made up 13% of Washington’s apple acreage, making it the state’s <a href="https://wpcdn.web.wsu.edu/cahnrs/uploads/sites/5/2020/11/TB70E.pdf" data-component="link" data-source="inlineLink" data-type="externalLink" data-ordinal="1">fourth-largest cultivar</a> after Red Delicious, Gala, and Fuji. “Farmers don’t miss out on an opportunity for something new and exciting,” Clark says. “Growing apples has tight margins and Honeycrisp and other premium apples give growers an opportunity to make some money and increase those margins.” Given the perceived quality and popularity of Honeycrisps, the variety could sell for far more than many other kinds of apples, making it possible for farmers to make a good deal more money on their crop.&nbsp;
</p>

<p id="mntl-sc-block_33-0"> Then there’s the question of storage. Honeycrisp apples can spend up to seven months in common storage (which refers to a climate at 37ºF/2.7ºC) or 10-plus months in controlled atmosphere storage, a reduced oxygen environment near freezing conditions (typically 32ºF/0ºC) that slows down the respiration rate of apples and prevents further ripening. Dr. R. Karina Gallardo, an economics professor at Washington State University, tells me that the longer the storage time, the higher the probability of disorders—which means the more likely it is that consumers purchase a poor-tasting apple.&nbsp;
</p>

<p id="mntl-sc-block_35-0"> An apple, however, doesn’t have to be stored very long to develop less-than-ideal flavors and textures. Though Honeycrisps are considered a good storage apple, a fruit that “stores well” could mean many things: It may look perfectly good, but doesn’t guarantee it will still taste good. “An apple can be pretty soft and mealy in six months,” Bedford says. “There’s no magic time for all apples.” There are numerous factors that can impact the quality of an apple in storage—especially when it’s a fickle variety like Honeycrisp, which requires careful tending to at every stage of its life.&nbsp;
</p>

<p id="mntl-sc-block_37-0"> Many farmers who invested heavily in planting Honeycrisp trees likely did not take into account just how difficult it would be to grow, harvest, and store the apples. And maybe some just decided it was worth the risk. At its most expensive, at the peak of the Honeycrisp craze in 2012 and 2013, the apple fetched a hefty price nationwide, with <a href="https://www.esquire.com/food-drink/food/a20018/honeycrisp-price-explained/" data-component="link" data-source="inlineLink" data-type="externalLink" data-ordinal="1"><em>Esquire</em></a> reporting it at of $4.50 per pound in New York City.
</p>

<p id="mntl-sc-block_39-0"> To satiate the public’s hunger for the Honeycrisp, a once highly seasonal apple available only in Minnesota, growers have made the apple variety available year-round by planting enough fruit to store for long periods of time. Planting the Honeycrisp in Washington marked not only the shift of the apple from its place of origin—Minnesota—to a growing region it wasn’t well suited to, but was also a shift from a more small-scale, local apple industry to one that was geared towards Big Apple from the start. Growers in Washington never intended to sell their tidy little Honeycrisp crop at local markets during its short season—they wanted to supply the apples year-round, and in large enough quantities to stock supermarket shelves across the country in order to make some serious money.&nbsp;
</p>

<p id="mntl-sc-block_41-0"> The move to Washington facilitated the arrival of the Honeycrisp everywhere and made it possible for consumers to purchase the apple variety wherever and whenever they wanted. All the problems with the Honeycrisp became much more common once the apple was grown and distributed on such a large scale; as Cornell University pomology professor Ian Merwin told <a href="https://www.axios.com/local/twin-cities/2024/02/25/honeycrisp-apple-prices-fall-supply-quality-questions" data-component="link" data-source="inlineLink" data-type="externalLink" data-ordinal="1">Axios</a> reporter Nick Halter, “There is no question that the quality that’s in the market is not what it was 10 years ago.” Apples are spending longer than ever in storage, and “even with advances in refrigeration in technology, that further erodes their quality.”<br>
</p>

<figure id="mntl-sc-block_43-0"> 
<figcaption id="mntl-figure-caption_3-0"> <span><p>Getty Images / Chris Ratcliffe/Bloomberg via Getty Images</p></span>
</figcaption></figure>
<h2 id="mntl-sc-block_44-0"> <span> Where the Honeycrisp Stands Today </span> </h2>
<p id="mntl-sc-block_45-0"> Apple growers very possibly over-invested in the Honeycrisp crop without truly understanding that they likely couldn’t deliver a premium product year-round on such a large scale—especially with such a capricious variety grown outside its native zone. For many consumers, the Honeycrisp crop of today has not lived up to the apple’s reputation, and for the first time ever, there is an oversupply of Honeycrisp apples. With a <a href="https://www.linkedin.com/pulse/predictions-2024-honeycrisp-pricing-continue-slide-james-williams-ampsc/" data-component="link" data-source="inlineLink" data-type="externalLink" data-ordinal="1">surplus that is 71% higher</a> than the five-year average, the national average for the cost of the apple is just $1.70 per pound. It is the cheapest the apple has ever been—and possibly the least satisfying and delicious it’s ever been.&nbsp;
</p>

<p id="mntl-sc-block_47-0"> As Bedford noted above, it is impossible for an apple variety to be “successful” unless it is grown in Washington. But what does success even mean? Turning the Honeycrisp into yet another commodity ultimately defeats the purpose of what Bedford and Luby were trying to achieve: a truly delicious apple with excellent eating quality. The Honeycrisp is a victim of its own success, and has become exactly what Bedford and Luby despised about the variety’s predecessors: a boring commodity apple.
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Rust-Query (106 pts)]]></title>
            <link>https://blog.lucasholten.com/rust-query-announcement/</link>
            <guid>42280570</guid>
            <pubDate>Sat, 30 Nov 2024 09:29:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.lucasholten.com/rust-query-announcement/">https://blog.lucasholten.com/rust-query-announcement/</a>, See on <a href="https://news.ycombinator.com/item?id=42280570">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  <article>
    
  <header>
    <p>
      <time datetime="2024-11-24">2024-11-24</time>
    
      <strong>Announcing rust-query</strong>
    </p>
      <ul role="list">
        <li role="listitem"><a href="https://blog.lucasholten.com/tags/database/">database</a></li>
      
        <li role="listitem"><a href="https://blog.lucasholten.com/tags/rust/">rust</a></li>
      </ul>
    </header>

    
  <h2 id="safe-relational-database-queries-using-the-rust-type-system">Safe relational database queries using the Rust type system</h2>
<p>Do you want to persist your data safely without migration issues and easily write complicated queries? All of this without writing a single line of SQL? If so, then <a href="https://github.com/LHolten/rust-query">I am making <code>rust-query</code></a> for you!</p>
<blockquote>
<p>This is my first blog post about <code>rust-query</code>, a project I've been working on for many months. I hope you like it!</p>
</blockquote>
<h3 id="rust-and-databases">Rust and Databases</h3>
<p>There is only one reason why I made this library and it is because I don't like the current options for interacting with a database from Rust. The existing libraries don't provide the compile time guarantees that I want and are verbose or awkward like SQL.</p>
<p>The reason I care so much is that databases are really cool. They solve a huge problem of making crash-resistant software with support for atomic transactions.</p>
<h2 id="structured-query-language-sql-is-a-protocol">Structured Query Language (SQL) is a protocol</h2>
<p>For those who don't know, SQL is <strong>the</strong> standard when it comes to interacting with databases. So much so that almost all databases only accept queries in some dialect of SQL.</p>
<p>My opinion is that SQL should be for computers to write. This would put it firmly in the same category as LLVM IR. The fact that it is human-readable is useful for debugging and testing, but I don't think it's how you want to write queries.</p>
<h2 id="introducing-rust-query">Introducing <code>rust-query</code></h2>
<p><a href="https://crates.io/crates/rust-query"><code>rust-query</code></a> is my answer to relational database queries in Rust. It's an opinionated library that deeply integrates with Rust's type system to make database operations feel Rust-native.</p>
<h2 id="key-features-and-design-decisions">Key Features and Design Decisions</h2>
<p>I could write a blog post about each one of these, but let's keep it short for now:</p>
<ul>
<li><strong>Explicit table aliasing</strong>: Joining a table gives back a dummy representing that table <code>let user = User::join(rows);</code>.</li>
<li><strong>Null safety</strong>: Optional values in queries have <code>Option</code> type, requiring special care to handle.</li>
<li><strong>Intuitive aggregates</strong>: Our aggregates are guaranteed to give a single result for every row they're joined on. After trying it, you'll see this is much more intuitive than traditional <code>GROUP BY</code> operations.</li>
<li><strong>Type-safe foreign key navigation</strong>: Database constraints are like type signatures, so you can rely on them for your queries with easy-to-use implicit joins by foreign key (e.g., <code>track.album().artist().name()</code>).</li>
<li><strong>Type-safe unique lookups</strong>: For example, you can get an <code>Option&lt;Rating&gt;</code> dummy with <code>Rating::unique(my_user, my_story)</code>.</li>
<li><strong>Multi-versioned schema</strong>: It's declarative and you can see the differences between all past versions of the schema at once!</li>
<li><strong>Type-safe migrations</strong>: Migrations have all the power of queries and can use arbitrary Rust code to process rows. Ever had to consult something outside the database for use in a migration? Now you can!</li>
<li><strong>Type-safe unique conflicts</strong>: Inserting and updating rows in tables with unique constraints results in specialized error types.</li>
<li><strong>Row references tied to transaction lifetime</strong>: Row references can only be used while the row is guaranteed to exist.</li>
<li><strong>Encapsulated typed row IDs</strong>: The actual row numbers are never exposed from the library API. Application logic should not need to know about them.</li>
</ul>
<h2 id="let-s-see-it">Let's see it!</h2>
<p>You always start by defining a schema. With <code>rust-query</code> it's easy to migrate to a different schema later.</p>
<pre data-lang="rust"><code data-lang="rust"><span>#[</span><span>schema</span><span>]
</span><span>enum </span><span>Schema {
</span><span>    User {
</span><span>        name: </span><span>String</span><span>,
</span><span>    },
</span><span>    Story {
</span><span>        author: User,
</span><span>        title: </span><span>String</span><span>,
</span><span>        content: </span><span>String
</span><span>    },
</span><span>    #[</span><span>unique</span><span>(user, story)]
</span><span>    Rating {
</span><span>        user: User,
</span><span>        story: Story,
</span><span>        stars: </span><span>i64
</span><span>    },
</span><span>}
</span><span>use </span><span>v0::</span><span>*</span><span>;
</span></code></pre>
<p>Schema defintions in <code>rust-query</code> use enum syntax, but no actual enum is defined here.
This schema defines three tables with specified columns and relationships:</p>
<ul>
<li>Using another table name as a column type creates a foreign key constraint.</li>
<li>The <code>#[unique]</code> attribute creates named unique constraints.</li>
<li>The <code>#[schema]</code> macro parses the enum syntax and generates a module <code>v0</code> that contains the database API.</li>
</ul>
<h3 id="writing-queries">Writing Queries</h3>
<p>First, let's see how to insert some data into our schema:</p>
<pre data-lang="rust"><code data-lang="rust"><span>fn </span><span>insert_data</span><span>(txn: </span><span>&amp;</span><span>mut </span><span>TransactionMut&lt;Schema&gt;) {
</span><span>    </span><span>// Insert users
</span><span>    </span><span>let</span><span> alice </span><span>=</span><span> txn.</span><span>insert</span><span>(User {
</span><span>        name: "</span><span>alice</span><span>",
</span><span>    });
</span><span>    </span><span>let</span><span> bob </span><span>=</span><span> txn.</span><span>insert</span><span>(User {
</span><span>        name: "</span><span>bob</span><span>",
</span><span>    });
</span><span>    
</span><span>    </span><span>// Insert a story
</span><span>    </span><span>let</span><span> dream </span><span>=</span><span> txn.</span><span>insert</span><span>(Story {
</span><span>        author: alice,
</span><span>        title: "</span><span>My crazy dream</span><span>",
</span><span>        content: "</span><span>A dinosaur and a bird...</span><span>",
</span><span>    });
</span><span>    
</span><span>    </span><span>// Insert a rating - note the try_insert due to the unique constraint
</span><span>    </span><span>let</span><span> rating </span><span>=</span><span> txn.</span><span>try_insert</span><span>(Rating {
</span><span>        user: bob,
</span><span>        story: dream,
</span><span>        stars: </span><span>5</span><span>,
</span><span>    }).</span><span>expect</span><span>("</span><span>no rating for this user and story exists yet</span><span>");
</span><span>}
</span></code></pre>
<p>A few important points about insertions:</p>
<ul>
<li>We need a mutable transaction (<code>TransactionMut</code>) to modify the database.</li>
<li>Insert operations return references to the newly inserted rows.</li>
<li>When inserting into tables with unique constraints, use <code>try_insert</code> to handle potential conflicts.</li>
<li>The error type of <code>try_insert</code> is based on how many unique constraints the table has.</li>
</ul>
<p>Now let's query this data:</p>
<pre data-lang="rust"><code data-lang="rust"><span>fn </span><span>query_data</span><span>(txn: </span><span>&amp;</span><span>Transaction&lt;Schema&gt;) {
</span><span>    </span><span>let</span><span> results </span><span>=</span><span> txn.</span><span>query</span><span>(|rows| {
</span><span>        </span><span>let</span><span> story </span><span>= </span><span>Story::join(rows);
</span><span>        </span><span>let</span><span> avg_rating </span><span>= aggregate</span><span>(|rows| {
</span><span>            </span><span>let</span><span> rating </span><span>= </span><span>Rating::join(rows);
</span><span>            rows.</span><span>filter_on</span><span>(rating.</span><span>story</span><span>(), </span><span>&amp;</span><span>story);
</span><span>            rows.</span><span>avg</span><span>(rating.</span><span>stars</span><span>().</span><span>as_float</span><span>())
</span><span>        });
</span><span>        rows.</span><span>into_vec</span><span>((story.</span><span>title</span><span>(), avg_rating))
</span><span>    });
</span><span>
</span><span>    </span><span>for </span><span>(title, avg_rating) </span><span>in</span><span> results {
</span><span>        println!("</span><span>story '</span><span>{title}</span><span>' has avg rating </span><span>{avg_rating:?}</span><span>");
</span><span>    }
</span><span>}
</span></code></pre>
<p>Key points about queries:</p>
<ul>
<li><code>rows</code> represents the current set of rows in the query.</li>
<li>Joins can add rows and filters can remove rows. <details>By joining a table like <code>Story</code>, the <code>rows</code> set is mutated to be the Cartesian product of itself and the rows from the joined table. The query above only has a single <code>join</code>, so we know it will give exactly one result for each row in the <code>Story</code> table.</details> </li>
<li>Using <code>aggregate</code> to calculate an aggregate, does not change the number of rows in the query.</li>
<li><code>rows.filter_on</code> can be used to filter rows in the aggregate to match a value from the outer scope.</li>
<li>The <code>rows.avg</code> method returns the average of the rows in the aggregate, if there are no rows then the average will evaluate to <code>None</code>.</li>
<li>Results can be collected into vectors of tuples or structs.</li>
</ul>
<h3 id="schema-evolution-and-migrations">Schema Evolution and Migrations</h3>
<p>Let's say you want to add an email address to each user. Here's how you'd create the new schema version:</p>
<pre data-lang="rust"><code data-lang="rust"><span>#[</span><span>schema</span><span>]
</span><span>#[</span><span>version</span><span>(0..</span><span>=</span><span>1)]
</span><span>enum </span><span>Schema {
</span><span>    User {
</span><span>        name: </span><span>String</span><span>,
</span><span>        #[</span><span>version</span><span>(1..)]
</span><span>        email: </span><span>String</span><span>,
</span><span>    },
</span><span>    </span><span>// ... rest of schema ...
</span><span>}
</span><span>use </span><span>v1::</span><span>*</span><span>;
</span></code></pre>
<p>And here's how you'd migrate the data:</p>
<pre data-lang="rust"><code data-lang="rust"><span>let</span><span> m </span><span>=</span><span> m.</span><span>migrate</span><span>(v1::update::Schema {
</span><span>    user: </span><span>Box</span><span>::new(|old_user| {
</span><span>        Alter::new(v1::update::UserMigration {
</span><span>            email: old_user
</span><span>                .</span><span>name</span><span>()
</span><span>                .</span><span>map_dummy</span><span>(|name| format!("</span><span>{name}</span><span>@example.com</span><span>")),
</span><span>        })
</span><span>    }),
</span><span>});
</span></code></pre>
<ul>
<li>The <code>v1::update</code> module contains structs defining the difference between schema <code>v0</code> and schema <code>v1</code>.</li>
<li>We use these structs to implement the migration. This way the migration is type checked against both the old and new schemas.</li>
<li>Note that inside migrations we can execute all the single-row queries we want: aggregates, unique constraint lookups etc.!</li>
<li>We can also use <code>map_dummy</code> with arbitrary Rust to process rows further.</li>
</ul>
<h2 id="conclusion">Conclusion</h2>
<p><code>rust-query</code> represents a fresh approach to database interactions in Rust, prioritizing:</p>
<ul>
<li>Checking everything possible at compile time.</li>
<li>Making it possible to compose queries with each other and arbitrary Rust.</li>
<li>Enabling schema evolution with type-checked migrations.</li>
</ul>
<p>While still in development, the library already allows building experimental database-backed applications in Rust. I encourage you to try it out and provide feedback through <a href="https://github.com/LHolten/rust-query">GitHub</a> issues!</p>
<blockquote>
<p>The library currently uses SQLite as its only backend, chosen for its embedded nature. This will not change anytime soon, as one backend is most practical while <code>rust-query</code> is in development.</p>
</blockquote>


    
  
  </article>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Engineering Sleep (296 pts)]]></title>
            <link>https://minjunes.ai/posts/sleep/index.html</link>
            <guid>42279454</guid>
            <pubDate>Sat, 30 Nov 2024 04:33:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://minjunes.ai/posts/sleep/index.html">https://minjunes.ai/posts/sleep/index.html</a>, See on <a href="https://news.ycombinator.com/item?id=42279454">Hacker News</a></p>
<div id="readability-page-1" class="page"><p><span>Engineering Sleep</span></p><p><span>Background</span><span>&nbsp;</span></p><p><span>Sleep claims a third of human life. Like water, it’s not a desire but a necessity. Sleep rules virtually every important system: brain, heart, mood, and immunity. Nature’s terms are harsh. Sleep eight hours or face mental and physical decay. Can we rewrite the terms in our favor? Can we sleep less, but still feel refreshed? I believe we can, and that now is the best time to start engineering sleep.</span></p><p><span>Rare mutations suggest a great variation in sleep efficiency between people</span><span>.</span><span>&nbsp;A small proportion of the population have Familial Natural Short Sleep (FNSS), a benign mutation that allows them to sleep 1-2 hours less than the recommended 7-9 hours, without experiencing the negative effects of sleep deprivation [</span><span><a target="_blank" rel="noopener noreferrer" href="https://my.clevelandclinic.org/health/diseases/short-sleeper-syndrome-sss&amp;sa=d&amp;source=editors&amp;ust=1732929030565618&amp;usg=aovvaw0vywxxv5vmhkrvjzmx">1</a></span><span>]</span><span>. </span></p><p><span>Contrary to symptoms of chronic sleep deprivation, people with FNSS are “healthy, energetic, optimistic, with high pain threshold, and do not seem to suffer adverse effects of chronic restricted sleep” [</span><span><a target="_blank" rel="noopener noreferrer" href="https://journals.lww.com/neurotodayonline/fulltext/2019/12050/a_genetic_mutation_for_short_sleep_prevents_memory.8.aspx">2</a></span><span>]</span><span>. This goes against everything we know about sleep. The most plausible explanation is that people with FNSS are more efficient sleepers. Whichever functions of sleep make it so crucial, they are doing it faster and better.</span></p><p><span>The Sleep Mutation</span></p><p><span>How does FNSS work? Five genes have been implicated in the FNSS phenotype, but DEC2 is the most studied. In 2009, professor Ying-Hui Fu at UCSF discovered a DEC2 point mutation from two individuals in the same family who slept 6.25 hours on average [</span><span><a target="_blank" rel="noopener noreferrer" href="https://pubmed.ncbi.nlm.nih.gov/19679812/">3</a></span><span>]. DEC2 codes for a repressive transcription factor (a protein that inhibits the expression of some gene). Normally, the gene that this transcription factor represses is responsible for expressing orexin, a neurotransmitter. In the mutation, proline is replaced by arginine at position 384 in exon 5 (DEC2P384R), disrupting its ability to repress orexin expression. Consequently, more orexin is expressed in individuals with this mutation. The UCSF group hypothesizes that this elevated level of orexin expression partially explains reduced sleep [</span><span><a target="_blank" rel="noopener noreferrer" href="https://pubmed.ncbi.nlm.nih.gov/29531056/">4</a></span><span>]. </span></p><p><span><img alt="image3" src="https://minjunes.ai/posts/sleep/images/image3.jpg" title=""></span></p><p><span>Fig 1. In normal humans, Dec2 weakens E12/Myod1’s binding affinity to the Ebox1 promoter site of prepro-orexin, which is responsible for endogenous orexin synthesis. In FNSS mutants, the DEC2P384R interaction with the E12/Myod1 complex is weaker, and there is greater orexin expression.</span></p><p><span>Two decades of sleep research supports the link between orexin and sleep [</span><span><a target="_blank" rel="noopener noreferrer" href="https://pubmed.ncbi.nlm.nih.gov/35851580/">5</a></span><span>]. In both narcolepsy and insomnia, orexin is the key neurotransmitter that modulates awakeness. A deficit of orexin producing neurons is responsible for excessive sleepiness in narcolepsy [</span><span><a target="_blank" rel="noopener noreferrer" href="https://sleep.hms.harvard.edu/education-training/public-education/sleep-and-health-education-program/sleep-health-education-4#:~:text=Research%20has%20revealed%20that%20narcolepsy,in%20the%20development%20of%20narcolepsy">6</a></span><span>]. An overexpression of orexin is responsible for hypervigilance in insomnia [</span><span><a target="_blank" rel="noopener noreferrer" href="https://pubmed.ncbi.nlm.nih.gov/37086045/">7</a></span><span>]. Throughout the day and night, we move between the wake-sleep axis defined by orexin levels, which are lowest in the middle of the day and highest during the transition from NREM to REM sleep [</span><span><a target="_blank" rel="noopener noreferrer" href="https://pubmed.ncbi.nlm.nih.gov/37686711/">8</a></span><span>].</span></p><p><span>Orexin is a commercially validated lever for controlling sleep. As of late 2024, there are eight orexin receptor agonists (promotes firing of neuron) in clinical trials for treating narcolepsy and hypersomnia, and two orexin receptor antagonists (inhibits firing of neuron) on the market for treating insomnia. To summarize orexin, too little of it makes you sleepy, and too much of it makes you unable to sleep.</span></p><p><span>But if elevated orexin levels explain reduced sleep in both FNSS carriers and insomniacs, why is one sleep deprived but not the other? We don’t know. Variation in dynamics of when, where, and how much orexin is released could explain the difference. Also, FNSS carriers might have developed compensatory mechanisms to cope with elevated orexin, leading to more efficient sleep. Experiments to reproduce FNSS will give us answers. </span></p><p><span>Reproducing FNSS</span></p><p><span>Given our current knowledge of FNSS, has anyone tried to reproduce it? A true reproduction would be safe and effective over the lifetime of the host, just like we see in the natural phenotype. The closest attempt was by the UCSF group that identified the DEC2P384R mutation. In their pioneering 2009 study, the group embryonically edited human DEC2P384R into transgenic mice and saw a 1-2 hour reduction in sleep. However, we don’t know if it was safe and effective over the lifetime of the mice. They recorded sleep architecture and sleep recovery during a 24-hour window in six to eight month old mice, tracking no other health markers [</span><span><a target="_blank" rel="noopener noreferrer" href="https://pubmed.ncbi.nlm.nih.gov/19679812/">3</a></span><span>]. </span></p><p><span>The study intervened at the embryo level of the host and saw short-term success reproducing FNSS. But what we’re really interested in is adulthood intervention and lifelong efficacy. Giving normal people the ability to sleep more efficiently is the ultimate goal. Expressing the DEC2P384R mutation in normal adult animals and conducting a lifelong study would answer this question. Two possible pathways to reproducing FNSS are reviewed below. </span></p><p><span>Path I: Orexin Agonists</span></p><p><span><img alt="" src="https://minjunes.ai/posts/sleep/images/image2.jpg" title=""></span></p><p><span>Fig 2. Pathway I success case</span></p><p><span>Approach</span></p><p><span>Orally dose orexin receptor agonists. The mechanism leverages direct receptor activation, similar to drugs currently in clinical trials for treating narcolepsy. These small molecules are designed for optimal blood-brain barrier penetration and selective binding to orexin receptors. </span></p><p><span>Unknowns</span></p><p><span>Primarily, we don’t know if elevated orexin levels explain the FNSS phenotype. Also, we don’t know the effects of chronic orexin receptor activation on sleep architecture and cognition. Pharma companies developing orexin agonists have data on short-term sleep effects, but none of them have published data on long term effects [</span><span><a target="_blank" rel="noopener noreferrer" href="https://pubmed.ncbi.nlm.nih.gov/36108771/">9</a></span><span>]. Also unknown are tolerance and withdrawal effects over time: like other receptor agonists (think nicotine), we may see diminishing effects, and withdrawal effects on return to baseline. Finally, variations in individual response are unknown. </span></p><p><span>Path II: Gene Therapy</span></p><p><span><img alt="" src="https://minjunes.ai/posts/sleep/images/image5.jpg" title=""></span></p><p><span>Fig 3. </span><span>Pathway II success case</span></p><p><span>Approach</span></p><p><span>Replicate the natural FNSS mutation through episomal expression. Episomal expression is when the gene is expressed from a piece of DNA that is outside the cell’s chromosomal DNA. Since chromosomal DNA is left alone, there is no risk of passing down the mutation to offspring. For this approach, we use Adeno-Associated Virus serotype 9 (AAV9) vectors to deliver the DEC2P384R gene to orexin-expressing neurons in adult mice. The vectors (the piece of extra chromosomal DNA) remain in the nucleus, continuously synthesizing the mutant DEC2 protein. This aims to partially mirror the mechanism seen in FNSS.</span></p><p><span>Unknowns</span></p><p><span>We are more certain that DEC2P384R explains FNSS, but we don’t know if expressing it in adulthood works. We also don’t know off-target effects on DEC2-regulated pathways beyond sleep. A specific unknown to episomal expression is the competition dynamics between DEC2P384R and native DEC2. The usual unknowns of variations between individual responses, particularly immune response, apply. </span></p><p><span>Overview of Pathways</span></p><p><span><img alt="image1" src="https://minjunes.ai/posts/sleep/images/image1.png" title=""></span></p><p><span>Too good to be true? &nbsp;</span></p><p><span>Around 90 families with FNSS have been identified to date [</span><span><a target="_blank" rel="noopener noreferrer" href="https://reporter.nih.gov/search/n0rjIH9BFE6TYwe-IE46Gw/project-details/10893516">10</a></span><span>]. If FNSS is truly benign, why is it so rare? Shouldn’t more efficient sleep confer a survival advantage? It could be that the mutation really is benign, but does not help reproductive success. But, the mutation could also have negative fitness effects that are not observed.</span></p><p><span><img alt="" src="https://minjunes.ai/posts/sleep/images/image4.jpg" title=""></span></p><p><span>Fig 4. Fisher-Wright simulation showing allele frequency dynamics with 10% fitness penalty across population sizes (N=100, 1,000, 10,000). Initial carrier frequency 1%, tracked for 20 generations over 100 simulations. Solid lines show means; shaded regions show standard deviations.</span></p><p><span>Under the Fisher-Wright model, harmful mutations can appear neutral when tracking small populations across just a few generations. If the mutation has a tiny effective population size, limited generational depth, and low carrier frequency, it would be hard to distinguish between neutral drift and negative selection.</span></p><p><span>Fortunately, there is no risk of the mutation being passed down to offsprings in either the orexin agonist pathway or the gene therapy pathway. So we can rule out the nightmare scenario of offspring effects gone wrong. Instead, the risks are concentrated in medium to long term health of individuals who undergo therapy. As of now, we simply don’t have enough data to profile risk factors. More experiments are needed to know if “FNSS for all” is too good to be true. </span></p><p><span>Where is my better sleep? </span></p><p><span>People with FNSS are living proof that we don’t need 7-9 hours of sleep to be healthy. We already don’t get enough sleep. 34% of Americans are chronically sleep deprived [</span><span><a target="_blank" rel="noopener noreferrer" href="https://news.gallup.com/poll/642704/americans-sleeping-less-stressed.aspx">11</a></span><span>]. What if they could keep sleeping less, but with no consequences? That’s possible with advanced sleep engineering. Here’s what else would be possible: falling asleep and waking at will, sleeping 4 hours but feeling like you slept 8 hours, always in perfect mental and physical condition. Considering the huge upside of engineering sleep, an unreasonably small number of experiments have studied FNSS. </span></p><p><span>Due to their relatively singular effect on sleep, FNSS mutations are a gold mine for studying sleep. But, there have been only two attempts to mimic FNSS outside of Fu et al: a study that found better memory consolidation in sleep deprived mice [</span><span><a target="_blank" rel="noopener noreferrer" href="https://pubmed.ncbi.nlm.nih.gov/31619542/">12</a></span><span>], and another that found greater longevity in flies [</span><span><a target="_blank" rel="noopener noreferrer" href="https://pubmed.ncbi.nlm.nih.gov/37163058/">13</a></span><span>]. None have been lifetime studies in mammals, which are most relevant to therapy development. </span></p><p><span>15 years after its pioneering work that identified DEC2P384R, Ying-Hui Fu’s lab is the only group that came close to reverse engineering FNSS. Perhaps this represents what J Storss Halls called a “civilizational failure of nerve”, where institutions become pathologically risk-averse, more focusing on preventing downside risks than enabling upside potential [</span><span><a target="_blank" rel="noopener noreferrer" href="https://press.stripe.com/where-is-my-flying-car#:~:text=In%20Where%20Is%20My%20Flying,that%20started%20in%20the%201970s.">14</a></span><span>]. Scientific and technological progress rests on the willingness to experiment. If existing institution’s won’t give us better sleep, we should build ones that do.</span></p><p><span>Next Steps</span></p><p><span>Contact me if you are interested in: </span></p><ul><li><span>Expanding the known FNSS database, and sequencing everyone in it</span></li><li><span>Testing pathways I and II</span></li><li><span>Funding the above</span></li></ul><p><span>Special thanks to Andy Kong, Ishan Goel, Tazik Shahjahan, and Mae Richardson for valuable feedback. </span></p><p><span>References</span></p><ol start="1"><li><span><a target="_blank" rel="noopener noreferrer" href="https://my.clevelandclinic.org/health/diseases/short-sleeper-syndrome-sss&amp;sa=d&amp;source=editors&amp;ust=1732929030565618&amp;usg=aovvaw0vywxxv5vmhkrvjzmx">Short Sleeper Syndrome</a></span></li><li><span><a target="_blank" rel="noopener noreferrer" href="https://journals.lww.com/neurotodayonline/fulltext/2019/12050/a_genetic_mutation_for_short_sleep_prevents_memory.8.aspx">A Genetic Mutation for Short Sleep Prevents Memory Deficits in a Mouse Model</a></span></li><li><span><a target="_blank" rel="noopener noreferrer" href="https://pubmed.ncbi.nlm.nih.gov/19679812/">He Y, Jones CR, Fujiki N, Xu Y, Guo B, Holder JL Jr, Rossner MJ, Nishino S, Fu YH. The transcriptional repressor DEC2 regulates sleep length in mammals. Science. 2009 Aug 14;325(5942):866-70. doi: 10.1126/science.1174443. PMID: 19679812; PMCID: PMC2884988.</a></span></li><li><span><a target="_blank" rel="noopener noreferrer" href="https://pubmed.ncbi.nlm.nih.gov/29531056/">Hirano A, Hsu PK, Zhang L, Xing L, McMahon T, Yamazaki M, Ptáček LJ, Fu YH. DEC2 modulates orexin expression and regulates sleep. Proc Natl Acad Sci U S A. 2018 Mar 27;115(13):3434-3439. doi: 10.1073/pnas.1801693115. Epub 2018 Mar 12. PMID: 29531056; PMCID: PMC5879715.</a></span></li><li><span><a target="_blank" rel="noopener noreferrer" href="https://pubmed.ncbi.nlm.nih.gov/35851580/">De Luca R, Nardone S, Grace KP, Venner A, Cristofolini M, Bandaru SS, Sohn LT, Kong D, Mochizuki T, Viberti B, Zhu L, Zito A, Scammell TE, Saper CB, Lowell BB, Fuller PM, Arrigoni E. Orexin neurons inhibit sleep to promote arousal. Nat Commun. 2022 Jul 18;13(1):4163. doi: 10.1038/s41467-022-31591-y. PMID: 35851580; PMCID: PMC9293990.</a></span></li><li><span><a target="_blank" rel="noopener noreferrer" href="https://sleep.hms.harvard.edu/education-training/public-education/sleep-and-health-education-program/sleep-health-education-4#:~:text=Research%20has%20revealed%20that%20narcolepsy,in%20the%20development%20of%20narcolepsy">https://sleep.hms.harvard.edu/education-training/public-education/sleep-and-health-education-program/sleep-health-education-4#:~:text=Research%20has%20revealed%20that%20narcolepsy,in%20the%20development%20of%20narcolepsy</a></span><span>.</span></li><li><span><a target="_blank" rel="noopener noreferrer" href="https://pubmed.ncbi.nlm.nih.gov/37086045/">Muehlan C, Roch C, Vaillant C, Dingemanse J. The orexin story and orexin receptor antagonists for the treatment of insomnia. J Sleep Res. 2023 Dec;32(6):e13902. doi: 10.1111/jsr.13902. Epub 2023 Apr 22. PMID: 37086045.</a></span></li><li><span><a target="_blank" rel="noopener noreferrer" href="https://pubmed.ncbi.nlm.nih.gov/37686711/">Mogavero, M. P., Godos, J., Grosso, G., Caraci, F., &amp; Ferri, R. (2023). Rethinking the Role of Orexin in the Regulation of REM Sleep and Appetite. Nutrients, 15(17), 3679. https://doi.org/10.3390/nu15173679</a></span></li><li><span><a target="_blank" rel="noopener noreferrer" href="https://pubmed.ncbi.nlm.nih.gov/36108771/">Ishikawa T, Hara H, Kawano A, Kimura H. Danavorexton, a selective orexin 2 receptor agonist, provides a symptomatic improvement in a narcolepsy mouse model. Pharmacol Biochem Behav. 2022 Oct;220:173464. doi: 10.1016/j.pbb.2022.173464. Epub 2022 Sep 13. PMID: 36108771.</a></span></li><li><span><a target="_blank" rel="noopener noreferrer" href="https://reporter.nih.gov/search/n0rjIH9BFE6TYwe-IE46Gw/project-details/10893516">https://reporter.nih.gov/search/n0rjIH9BFE6TYwe-IE46Gw/project-details/10893516</a></span></li><li><span><a target="_blank" rel="noopener noreferrer" href="https://news.gallup.com/poll/642704/americans-sleeping-less-stressed.aspx">https://news.gallup.com/poll/642704/americans-sleeping-less-stressed.aspx</a></span></li><li><span><a target="_blank" rel="noopener noreferrer" href="https://pubmed.ncbi.nlm.nih.gov/31619542/">Xing, L., Shi, G., Mostovoy, Y., Gentry, N. W., Fan, Z., McMahon, T. B., Kwok, P. Y., Jones, C. R., Ptáček, L. J., &amp; Fu, Y. H. (2019). Mutant neuropeptide S receptor reduces sleep duration with preserved memory consolidation. Science translational medicine, 11(514), eaax2014. https://doi.org/10.1126/scitranslmed.aax2014</a></span></li><li><span><a target="_blank" rel="noopener noreferrer" href="https://pubmed.ncbi.nlm.nih.gov/37163058/">Pandey P, Wall PK, Lopez SR, Dubuisson OS, Zunica ERM, Dantas WS, Kirwan JP, Axelrod CL, Johnson AE. A familial natural short sleep mutation promotes healthy aging and extends lifespan in Drosophila. bioRxiv [Preprint]. 2023 Apr 26:2023.04.25.538137. doi: 10.1101/2023.04.25.538137. PMID: 37163058; PMCID: PMC10168263.</a></span></li><li><span><a target="_blank" rel="noopener noreferrer" href="https://press.stripe.com/where-is-my-flying-car#:~:text=In%20Where%20Is%20My%20Flying,that%20started%20in%20the%201970s.">Hall, J. S. (2021). Where is my flying car? Stripe Press.</a></span></li></ol></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Sol-Ark manufacturer reportedly disables all Deye inverters in the US (172 pts)]]></title>
            <link>https://solarboi.com/2024/11/17/sol-ark-oem-disables-all-deye-inverters-in-the-us/</link>
            <guid>42279010</guid>
            <pubDate>Sat, 30 Nov 2024 02:51:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://solarboi.com/2024/11/17/sol-ark-oem-disables-all-deye-inverters-in-the-us/">https://solarboi.com/2024/11/17/sol-ark-oem-disables-all-deye-inverters-in-the-us/</a>, See on <a href="https://news.ycombinator.com/item?id=42279010">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[NASA's Europa Clipper: Miles Down, Instruments Deploying (137 pts)]]></title>
            <link>https://www.nasa.gov/missions/europa-clipper/nasas-europa-clipper-millions-of-miles-down-instruments-deploying/</link>
            <guid>42278148</guid>
            <pubDate>Fri, 29 Nov 2024 23:47:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nasa.gov/missions/europa-clipper/nasas-europa-clipper-millions-of-miles-down-instruments-deploying/">https://www.nasa.gov/missions/europa-clipper/nasas-europa-clipper-millions-of-miles-down-instruments-deploying/</a>, See on <a href="https://news.ycombinator.com/item?id=42278148">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p><em>Headed to Jupiter’s moon Europa, the spacecraft is operating without a hitch and will reach Mars in just three months for a gravity assist.</em></p>
<p>NASA’s Europa Clipper, which launched Oct. 14 on a journey to Jupiter’s moon Europa, is already <a href="https://eyes.nasa.gov/apps/solar-system/#/sc_europa_clipper/distance?to=earth" rel="noopener">13 million miles</a> (20 million kilometers) from Earth. Two science instruments have deployed hardware that will remain at attention, extending out from the spacecraft, for the next decade — through the cruise to Jupiter and the entire prime mission.</p>
<p>A SpaceX Falcon Heavy rocket launched it away from Earth’s gravity, and now the spacecraft is zooming along at 22 miles per second (35 kilometers per second) relative to the Sun.</p>
<p><a href="https://science.nasa.gov/mission/europa-clipper/" rel="noopener">Europa Clipper</a> is the largest spacecraft NASA has ever developed for a planetary mission. It will travel 1.8 billion miles (2.9 billion kilometers) to arrive at Jupiter in 2030 and in 2031 will begin a series of 49 flybys, using a <a href="https://europa.nasa.gov/spacecraft/instruments/" rel="noopener">suite of instruments</a> to gather data that will tell scientists if the icy moon and its internal ocean have the conditions needed to harbor life.</p>
<p>For now, the information mission teams are receiving from the spacecraft is strictly engineering data (the science will come later), telling them how the hardware is operating. Things are looking good. The team has a checklist of actions the spacecraft needs to take as it travels deeper into space. Here’s a peek:</p>

<p>Shortly after launch, the spacecraft deployed its massive <a href="https://www.jpl.nasa.gov/news/nasas-europa-clipper-gets-set-of-super-size-solar-arrays/" rel="noopener">solar arrays</a>, which extend the length of a basketball court. Next on the list was the <a href="https://europa.nasa.gov/spacecraft/instruments/ecm/" rel="noopener">magnetometer</a>’s boom, which uncoiled from a canister mounted on the spacecraft body, extending a full 28 feet (8.5 meters).</p>
<p>To confirm that all went well with the boom deployment, the team relied on data from the magnetometer’s three sensors. Once the spacecraft is at Jupiter, these sensors will measure the magnetic field around Europa, both confirming the presence of the ocean thought to be under the moon’s icy crust and telling scientists about its depth and salinity.</p>


<p>After the magnetometer, the spacecraft deployed several antennas for the radar instrument. Now extending crosswise from the solar arrays, the four high-frequency antennas form what look like two long poles, each measuring 57.7 feet (17.6 meters) long. Eight rectangular very-high-frequency antennas, each 9 feet (2.76 meters) long, were also deployed — two on the two solar arrays.</p>
<p>“It’s an exciting time on the spacecraft, getting these key deployments done,” said Europa Clipper project manager Jordan Evans of NASA’s Jet Propulsion Laboratory in Southern California. “Most of what the team is focusing on now is understanding the small, interesting things in the data that help them understand the behavior of the spacecraft on a deeper level. That’s really good to see.”</p>

<p>The remaining seven instruments will be powered on and off through December and January so that engineers can check their health. Several instruments, including the <a href="https://europa.nasa.gov/spacecraft/instruments/eis/" rel="noopener">visible imager</a> and the <a href="https://europa.nasa.gov/spacecraft/instruments/maspex/" rel="noopener">gas</a> and <a href="https://europa.nasa.gov/spacecraft/instruments/suda/" rel="noopener">dust</a> mass spectrometers, will keep their protective covers closed for the next three or so years to guard against potential damage from the Sun during Europa Clipper’s time in the inner solar system.</p>

<p>Once all the instruments and engineering subsystems have been checked out, mission teams will shift their focus to Mars. On March 1, 2025, Europa Clipper will reach Mars’ orbit and begin to loop around the Red Planet, using the planet’s gravity to gain speed. (This effect is similar to how a ball thrown at a moving train will bounce off the train in another direction at a higher speed.) Mission navigators already have completed one trajectory correction maneuver, as planned, to get the spacecraft on the precise course.</p>
<p>At Mars, scientists plan to turn on the spacecraft’s <a href="https://europa.nasa.gov/spacecraft/instruments/e-themis/" rel="noopener">thermal imager</a> to capture multicolored images of Mars as a test operation. They also plan to collect data with the radar instrument so engineers can be sure it’s operating as expected.</p>
<p>The spacecraft will perform another gravity assist in December 2026, swooping by Earth before making the remainder of the long journey to the Jupiter system. At that time, the magnetometer will measure Earth’s magnetic field, calibrating the instrument.</p>

<p>Europa Clipper’s three main science objectives are to determine the thickness of the moon’s icy shell and its interactions with the ocean below, to investigate its composition, and to characterize its geology. The mission’s detailed exploration of Europa will help scientists better understand the astrobiological potential for habitable worlds beyond our planet.</p>
<p>Managed by Caltech in Pasadena, California, JPL leads the development of the Europa Clipper mission in partnership with the Johns Hopkins Applied Physics Laboratory in Laurel, Maryland, for NASA’s Science Mission Directorate in Washington. APL designed the main spacecraft body in collaboration with JPL and NASA’s Goddard Space Flight Center in Greenbelt, Maryland, NASA’s Marshall Space Flight Center in Huntsville, Alabama, and Langley Research Center in Hampton, Virginia. The Planetary Missions Program Office at Marshall executes program management of the Europa Clipper mission. NASA’s Launch Services Program, based at Kennedy, managed the launch service for the Europa Clipper spacecraft.</p>
<p>Find more information about Europa Clipper here:</p>
<p><a href="https://science.nasa.gov/mission/europa-clipper" rel="noopener">https://science.nasa.gov/mission/europa-clipper</a></p>





<p>Gretchen McCartney<br>Jet Propulsion Laboratory, Pasadena, Calif.<br>818-287-4115<br><a href="mailto:gretchen.p.mccartney@jpl.nasa.gov%C2%A0">gretchen.p.mccartney@jpl.nasa.gov&nbsp;</a></p>
<p>Karen Fox / Molly Wasser<br>NASA Headquarters, Washington<br>202-358-1600<br><a href="mailto:karen.c.fox@nasa.gov">karen.c.fox@nasa.gov</a> / <a href="mailto:molly.l.wasser@nasa.gov">molly.l.wasser@nasa.gov</a> &nbsp;</p>
<p>2024-163</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Engagement Is Better on Bluesky (110 pts)]]></title>
            <link>https://bsky.social/about/blog/11-29-2024-engagement</link>
            <guid>42277963</guid>
            <pubDate>Fri, 29 Nov 2024 23:13:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bsky.social/about/blog/11-29-2024-engagement">https://bsky.social/about/blog/11-29-2024-engagement</a>, See on <a href="https://news.ycombinator.com/item?id=42277963">Hacker News</a></p>
<div id="readability-page-1" class="page"><section><header><section><a href="https://bsky.social/about/blog">Blog</a><svg width="8" height="12" viewBox="0 0 8 12" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M2 10L6 6L2 2" stroke="#667999" stroke-width="2" stroke-linecap="square"></path></svg><span>The Engagement Is Better on Bluesky</span></section><div><p>November 29, 2024</p><p><span>by <!-- -->The Bluesky Team</span></p></div></header><div><p>We could go on about how we welcome publishers, we don't demote links, we encourage independent developers to build apps and extensions on top of Bluesky's network.... but instead, we'll show you:</p>
<h3>The Boston Globe</h3>
<blockquote data-bluesky-uri="at://did:plc:e6zr6q76g4h7agw4tw6pnu3n/app.bsky.feed.post/3lbunm54agc2k" data-bluesky-cid="bafyreiddcne3ci43tnhmwmwdiihomvqkpliyxslsjshnnwxpryynal7udq"><p lang="en">Traffic from Bluesky to @bostonglobe.com is already 3x that of Threads, and we are seeing 4.5x the conversions to paying digital subscribers.</p>— Matt Karolian (<a href="https://bsky.app/profile/did:plc:e6zr6q76g4h7agw4tw6pnu3n?ref_src=embed">@mkarolian.bsky.social</a>) <a href="https://bsky.app/profile/did:plc:e6zr6q76g4h7agw4tw6pnu3n/post/3lbunm54agc2k?ref_src=embed">November 26, 2024 at 10:19 AM</a></blockquote>
<h3>The Guardian</h3>
<blockquote data-bluesky-uri="at://did:plc:ayz3ljwsllsn7htnmu4q3zhq/app.bsky.feed.post/3lbvwh42ipk2y" data-bluesky-cid="bafyreihfz7ezs23z7scv4vyy7xi4vacsqan5llft5v4dc56umjhr7w7cfy"><p lang="en">By which I mean, I'm pretty sure traffic from 
@bsky.app to @theguardian.com is *significantly* higher than the very obvious 2x that of Threads
</p><div><p>This post brought to you by a reply to @mkarolian.bsky.social on Threads, where it has had just 105 engagements, as opposed to the 18k+ here</p><p><a href="https://bsky.app/profile/did:plc:ayz3ljwsllsn7htnmu4q3zhq/post/3lbvwh42ipk2y?ref_src=embed">[image or embed]</a></p></div>— Dave Earley (<a href="https://bsky.app/profile/did:plc:ayz3ljwsllsn7htnmu4q3zhq?ref_src=embed">@earleyedition.bsky.social</a>) <a href="https://bsky.app/profile/did:plc:ayz3ljwsllsn7htnmu4q3zhq/post/3lbvwh42ipk2y?ref_src=embed">November 26, 2024 at 10:30 PM</a></blockquote>
<h3>The New York Times</h3>
<blockquote data-bluesky-uri="at://did:plc:ty42uz67qbam52si5yduwwaa/app.bsky.feed.post/3lbm65hi7bj2y" data-bluesky-cid="bafyreigjbemi4znbpyw52mdf77qxjlozfv6fzzds5mmn5rnkgprboclyaa"><div lang=""><p>hard to exaggerate how nuts the engagement is on Bluesky compared to 𝕏. a vastly smaller user base (at least officially), but just look at these stats for one of the biggest newspapers on Earth. Musk has absolutely trashed the platform. folks, you are not locked in on 𝕏. not even a little.</p><p><a href="https://bsky.app/profile/did:plc:ty42uz67qbam52si5yduwwaa/post/3lbm65hi7bj2y?ref_src=embed">[image or embed]</a></p></div>— Kevin Rothrock (<a href="https://bsky.app/profile/did:plc:ty42uz67qbam52si5yduwwaa?ref_src=embed">@kevinrothrock.me</a>) <a href="https://bsky.app/profile/did:plc:ty42uz67qbam52si5yduwwaa/post/3lbm65hi7bj2y?ref_src=embed">November 23, 2024 at 1:21 AM</a></blockquote>
<h3>Open-source Web Dev</h3>
<blockquote data-bluesky-uri="at://did:plc:2gkh62xvzokhlf6li4ol3b3d/app.bsky.feed.post/3lbwwdqztic2s" data-bluesky-cid="bafyreie2rhlpgr4rdrird346s7g77a2txztot2yelri5pcdzgdekzd4wuu"><div lang="en"><p>We have 6% of the followers here compared to the 100k in X. The vite 6.0 announcement in bluesky already got half the reposts and a third of the likes. And most of the comments and quotes from OSS maintainers happened here. I don't know about other communities, but OSS web dev is a bluesky game now.</p><p><a href="https://bsky.app/profile/did:plc:2gkh62xvzokhlf6li4ol3b3d/post/3lbwwdqztic2s?ref_src=embed">[image or embed]</a></p></div>— patak (<a href="https://bsky.app/profile/did:plc:2gkh62xvzokhlf6li4ol3b3d?ref_src=embed">@patak.dev</a>) <a href="https://bsky.app/profile/did:plc:2gkh62xvzokhlf6li4ol3b3d/post/3lbwwdqztic2s?ref_src=embed">November 27, 2024 at 8:01 AM</a></blockquote>
<h3>Democracy Docket</h3>
<blockquote data-bluesky-uri="at://did:plc:pjiafkey2cokiupsxpswqlk7/app.bsky.feed.post/3lbwnypsssc2s" data-bluesky-cid="bafyreigqm6acubxf6hykcdxhjscpp5yynlbr5ni6eincnewe5dutubqmfm"><p lang="en">Traffic from Bluesky to @democracydocket.com is surging while X is falling and Threads remains largely irrelevant. This is powering rapid growth of both free subscribers and paid members.</p>— Marc Elias (<a href="https://bsky.app/profile/did:plc:pjiafkey2cokiupsxpswqlk7?ref_src=embed">@marcelias.bsky.social</a>) <a href="https://bsky.app/profile/did:plc:pjiafkey2cokiupsxpswqlk7/post/3lbwnypsssc2s?ref_src=embed">November 27, 2024 at 5:31 AM</a></blockquote>
<p>Join us: <a href="https://bsky.app/download">bsky.app/download</a>. Publishers, you can find our <a href="https://bsky.social/about/blog/press-faq">press FAQ here</a>.</p></div></section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Geometric line-art of Wacław Szpakowski (2017) (302 pts)]]></title>
            <link>https://www.theparisreview.org/blog/2017/02/15/rhythmical-lines/</link>
            <guid>42277850</guid>
            <pubDate>Fri, 29 Nov 2024 22:54:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theparisreview.org/blog/2017/02/15/rhythmical-lines/">https://www.theparisreview.org/blog/2017/02/15/rhythmical-lines/</a>, See on <a href="https://news.ycombinator.com/item?id=42277850">Hacker News</a></p>
Couldn't get https://www.theparisreview.org/blog/2017/02/15/rhythmical-lines/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[The Deterioration of Google (208 pts)]]></title>
            <link>https://www.baldurbjarnason.com/2024/the-deterioration-of-google/</link>
            <guid>42277673</guid>
            <pubDate>Fri, 29 Nov 2024 22:26:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.baldurbjarnason.com/2024/the-deterioration-of-google/">https://www.baldurbjarnason.com/2024/the-deterioration-of-google/</a>, See on <a href="https://news.ycombinator.com/item?id=42277673">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="skip">
	



<p><time datetime="2024-11-07">7 November 2024</time> – <em>Baldur
		Bjarnason</em></p>
<ul>
		<li><a href="https://www.baldurbjarnason.com/tags/google/">google</a></li>
</ul>








<p>This post announcing the closure of Giant Freakin Robot set me on a bit of a journey into the state of Google.</p>
<p><a href="https://www.giantfreakinrobot.com/ent/independent-ends.html">“The End Of Independent Publishing And Giant Freakin Robot”</a></p>
<blockquote>
<p>GIANT FREAKIN ROBOT isn’t the first site to shut down. Hundreds of independent publishers have shuttered in the last two years, and thousands more are on the way. I’m in communication with dozens of other independents focused on different topics. None of them are doing well. They all expect to be out of business soon.</p>
<p>I went to Google directly, on their behalf, and told them about the problem. The message I walked away with, was that they do not care. Our industry is done.</p>
</blockquote>
<p>What I discovered was that web media companies can’t count on any of the traffic coming from Google or Facebook any more. Very few, even one that are frugally run, are capable of surviving on the traffic that remains.</p>
<p>The problem doesn’t seem limited to a few sites. What seems to have happened is that Google tried to “fix” their search engine results by using machine learning to rank sites.</p>
<p>From <a href="https://www.mariehaynes.com/what-we-can-learn-from-the-google-creators-summit-for-hcu-impacted-sites/"><em>What we can learn from the Google creators summit for HCU impacted sites</em></a>:</p>
<blockquote>
<p>We know that the helpful content system was a machine learning (AI) system.  Machine learning systems are trained by seeing good examples and bad examples. They then work to figure out the characteristics they can consider and how much weight to give them so as to predict whether an unseen example is a good one or a bad one.</p>
</blockquote>
<p>But this does not seem to be working properly. Anybody who has used Google for search over the past year knows that it lets a lot of LLM-generated spam through and blogs and small sites have basically disappeared from most results. Those sites have effectively been delisted by the machine learning model and nobody seems to know exactly why.</p>
<p>Some have been hit hard. From <a href="https://mike-hardaker.com/f/i-drank-the-kool-aid-at-the-2024-google-web-creator-summit/">“I Drank the Kool-Aid at the 2024 Google Web Creator Summit”</a>:</p>
<blockquote>
<p>I’m 44 years old, luckily I don’t have a mortgage, I barely getting by, I’m eating at the food bank now, I had grossed $250,000 last year and I just don’t know where to go from here my traffic is down 97%</p>
</blockquote>
<p>Even if your first reaction might be “good riddance” these are all people whose work Google <em>wants</em> to see in the search engine results. That’s why they were invited to the summit.</p>
<p>An exchange on Twitter, which I usually avoid but is where this crowd seems to still be congregating, describing a scene from the summit <a href="https://x.com/CharlestonCraft/status/1851643761375277103">captured the situation perfectly</a>:</p>
<blockquote>
<p>Lily Ray: I’m still stuck on “your content wasn’t the issue.” What?</p>
<p>Morgan: So, so many times they said this. Literally Danny hand picked us because we all create helpful and satisfying content. They just cannot get the algorithm to understand that. They are actively doing query debugging based on examples sent by our group.</p>
<p>Morgan: Literally Danny said he sat with an engineer team with examples of people in the room and said why aren’t they showing up and they did their “debugging process” and couldn’t figure it out.</p>
<p>Morgan: the robots are winning.</p>
</blockquote>
<p>The “algorithm” seems to have become a black box even Google engineers can’t figure out</p>
<p>The fact that over a year ago ML experts at Google (El-Mahdi El-Mhamdi at least, if I recall correctly) who have since left warned that LLMs should be avoided because they made products chaotic and hard to control seems relevant.</p>
<p>As is the fact that around the same time others also warned that one common consequence of mass layoffs is they tend to turn internal systems into black boxes because everybody with a deep understanding of them has left.</p>
<p>But, fundamentally, what lets this deterioration continue is that it does not affect business outcomes at Google in any way. They are a monopoly and monopolies are extremely effective at capturing whatever value happens in their vicinity, even if the utility of their products declines.</p>
<p>And, given the political situation in the US, the tech industry monopolies and oligopolies are only going to be strengthened and the actual productivity, performance, and effectiveness of their products will be less and less important to them.</p>
<p>Because they know that most of us will not have any real alternative.</p>

		<ul>
				<li>
					
				</li><li>
				
				</li>
		</ul>
	
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Brits are scrolling away from X and aren't that interested in AI (131 pts)]]></title>
            <link>https://www.theregister.com/2024/11/29/ofcom_online_nation/</link>
            <guid>42277089</guid>
            <pubDate>Fri, 29 Nov 2024 21:03:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2024/11/29/ofcom_online_nation/">https://www.theregister.com/2024/11/29/ofcom_online_nation/</a>, See on <a href="https://news.ycombinator.com/item?id=42277089">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>Usage of Elon Musk's X social media platform is declining in the UK, and adult Brits aren't particularly interested in generative AI tools.</p>
<p>That's according to Ofcom's <a target="_blank" rel="nofollow" href="https://www.ofcom.org.uk/media-use-and-attitudes/online-habits/online-nation/">Online Nation</a> report, an annual publication looking at what UK citizens do during their hours online and how much time they spend glued to gadgets.</p>
<p>According to the comms regulator, adults spent an average of four hours 20 minutes a day online in May 2024 across tablets, smartphones, and computers.</p>

    

<p>The report also shows that the total UK adult reach in a month of X (formerly Twitter) continues to decline. For May 2022, Ofcom measured X's adult reach at 26.8 million. In 2023, it was 24 million. By May 2024, it had fallen to 22.1 million, a year-on-year decline of 8 percent.</p>

        


        

<p>X suffered the most significant fall in total adult use of all social media sites, which also resulted in it sliding down the rankings to sixth, behind Reddit, which registered the largest year-on-year growth – 47 percent – taking May's figure to 22.9 million.</p>
<p><a target="_blank" rel="nofollow" href="https://www.theregister.com/2024/11/20/x_marks_the_spot_for/">Several changes</a> have been made at X in recent months, but the platform has continued on a downward trajectory in Britain and Northern Ireland.</p>

        

<p>Ofcom's figures align with other research on X. While still hugely popular, the service has been shedding users over the last two years. UK-based <a target="_blank" rel="nofollow" href="https://soax.com/research/twitter-active-users">SOAX reported</a> an 8.83 percent decrease in monthly active users since 2022 and 5.14 percent since 2023. This is despite global growth in social media users, according to <a target="_blank" rel="nofollow" href="https://www.statista.com/statistics/278414/number-of-worldwide-social-network-users/">Statista</a>.</p>
<p>The decline co-incides with a change of ownership after Musk bought the business for <a target="_blank" href="https://www.theregister.com/2022/10/27/musk_sink_twitter/">$44 billion in October 2022</a>, and it became a doyen of free speech - whether that includes more hateful or more honest content depends on the users' perspective.</p>
<h3>AI – huh – what is good for? Perhaps a bit of searching?</h3>
<p>Ofcom also found that Google's search engine dominance in the UK also slipped slightly over the year, with 83 percent of online adults visiting in May 2024 compared to 86 percent the year before. Microsoft's Bing fell further, down to 39 percent from 46 percent.</p>
<p>Microsoft and Google have invested heavily in AI, with generative AI content turning up in the search results from their respective services. However, ChatGPT remains the most popular GenAI tool. Microsoft's Copilot came second, with 15 percent of UK internet users aged 16 and over having used it. Despite being only recently introduced, Google's Gemini was ranked fourth, with 10 percent of users.</p>
<ul>

<li><a href="https://www.theregister.com/2024/11/21/online_safety_act/">Now Online Safety Act is law, UK has 'priorities' – but still won't explain 'spy clause'</a></li>

<li><a href="https://www.theregister.com/2024/11/13/ofcom_mmwave_spectrum_auction/">Brit telcos to clash in high-speed mmWave spectrum showdown next year</a></li>

<li><a href="https://www.theregister.com/2024/11/12/cma_vodafone_three_remedies/">Watchdog reluctantly blesses Vodafone-Three merger – with strings attached</a></li>

<li><a href="https://www.theregister.com/2024/11/11/australia_social_media_ban/">Australia tells tots: No TikTok till you're 16... or X, Instagram and Facebook</a></li>
</ul>
<p>The figures also show sluggish AI adoption. More than half of adults in the survey had yet to use GenAI, with 38 percent declaring they were "not interested" and 35 percent saying they "did not need to."</p>
<p>Forty-eight percent of adults had used the technology, but only "for fun." Forty-three percent had used one for work, and the most popular activity was finding content. However, less than one in five (18 percent) trusted the output.</p>
<p>The numbers are slightly different for the under-16s. Fifty-four percent said they had used a GenAI tool, with more than half (53 percent) of those saying they had used it for schoolwork. Sixty-three percent reported using a GenAI tool "for fun."</p>

        

<p>The distribution across age groups shows that AI is making more significant inroads into younger demographics than older. However, it appears that investors may have to wait a little longer before AI bets start paying off. ®</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Platform for senior devs to learn other programming languages? (108 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=42276995</link>
            <guid>42276995</guid>
            <pubDate>Fri, 29 Nov 2024 20:49:28 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=42276995">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="42279097"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42279097" href="https://news.ycombinator.com/vote?id=42279097&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div><p>These days my main problem when learning is coming to terms with the development environment.</p><p>Python, how do I install and work with venvs? What is poetry and why is it better?</p><p>Scala, what is sbt and how do I make it work in Intellij?</p><p>Things I have learned under way, but still more of a headache than the actual language, since most ideas there are recognizable. And problems in the dev env can make you get stuck for several hours.</p><p>Docker helps a bit as an abstraction, but not all the way to the development environment.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42280135"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42280135" href="https://news.ycombinator.com/vote?id=42280135&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div>
                  <p>I couldn’t agree more. And once you have mastered or at least come to terms with the development environment, eventually you must learn how to deploy. That’s also a minefield.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="42280534"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42280534" href="https://news.ycombinator.com/vote?id=42280534&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div><p>The worst is js development.</p><p>You need thousands of tools and there always exists 3 alternatives.</p><p>Js/ts as a language is the smallest problem.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42281500"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42281500" href="https://news.ycombinator.com/vote?id=42281500&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div>
                  <p>I think the worst is Java/Kotlin. Gradle is a nightmare and I just refuse to spend my time learning it. I just can’t.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="42280657"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42280657" href="https://news.ycombinator.com/vote?id=42280657&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div><p>It’s a newcomer confusion vs old-timer habit. You’ll feel the same in C, python, etc if you never seen these. And vice versa in any direction.</p><p>Edit: But I absolutely agree that $subj platform should focus on that, not even on the language. A language can be learned in one evening on a “fiddle” site, no platform required.</p><p>Personally, when I become interested in another language, all I want is a page of common snippets or a cheatsheet to get the feel of syntax, and then how to make and deploy a non-toy project with all the usual libs and tools attached.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42281325"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_42281325" href="https://news.ycombinator.com/vote?id=42281325&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div><p>I think the biggest problem is that js is way faster charging than almost every other language.</p><p>I was used to use vue, there was webpack now it's vite or nextjs, some tools are build on top of others like nextjs on webpack and vite on esbuild.</p><p>If you stop working 2 years in js your tools will completely change.</p><p>E.g. java has maven and more and more use graddle, but it's way slower change.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42280685"><td></td></tr>
                <tr id="42280751"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_42280751" href="https://news.ycombinator.com/vote?id=42280751&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div><p>It’s a yet another facebook shaped opportunity though. The hardest part is not to collect and systematize information, but to become distinguishable from a mountain of shitty blogspam that google agrees to promote for financial reasons.</p><p>For meta, I’d say our issue here is not the lack of platforms or manuals, but that we simply don’t have a decent search engine, because we don’t have a decent internet economy model. Our models and tools are indecent and there’s no help.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42280886"><td><table>  <tbody><tr>    <td indent="5"><img src="https://news.ycombinator.com/s.gif" height="1" width="200"></td><td>
      <center><a id="up_42280886" href="https://news.ycombinator.com/vote?id=42280886&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div><p>What you describe is exactly the challenge and opportunity to overcome.</p><p>Why should I have to rely on Google/stack overflow/chatgpt to set up my environment?</p></div></td></tr>
        </tbody></table></td></tr>
                                          <tr id="42277193"><td></td></tr>
                <tr id="42277199"><td></td></tr>
                  <tr id="42277522"><td></td></tr>
                <tr id="42278482"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42278482" href="https://news.ycombinator.com/vote?id=42278482&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div><p>Would love the equivalent of this but before applying practical problem solving. For instance in go you learn to leverage goroutines and channels. In another language it would be threads. Common design patterns etc. Gotcha’s of the language. In Python you use exception handling very commonly, in golang you’re using a special return value of an error type. JavaScript you’re using a ton of anonymous function closures. Async vs await.</p><p>I keep wanting to build this mega doc site to teach more than just “what are scalar types in this language” and more of how to apply it in idiomatic ways.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42280394"><td></td></tr>
            <tr id="42278963"><td></td></tr>
                <tr id="42280134"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_42280134" href="https://news.ycombinator.com/vote?id=42280134&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div>
                  <p>Devdocs is just a collection of official documentations. GP wants a collection of documentation that explains comparative, idiomatic problem solving in each language. How are they even remotely similar?</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42280334"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_42280334" href="https://news.ycombinator.com/vote?id=42280334&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div>
                  <p>sure but the comment two steps up mentions wanting to build a site, devdocs exists and could host that information they want to compile and build.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                              <tr id="42277724"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42277724" href="https://news.ycombinator.com/vote?id=42277724&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div>
                  <p>This is excellent. I checked Julia which is my main language and all essentials are there. Looked up to Zig, F#, Go all accessible expositions and makes it easy to get a good taste before looking into the manuals.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                  <tr id="42278939"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42278939" href="https://news.ycombinator.com/vote?id=42278939&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div>
                  <p>Alternatively rewrite some non trivial work of your own from X to Y language. You'll learn more than making frivolous programs about made up stuff.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42279727"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42279727" href="https://news.ycombinator.com/vote?id=42279727&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div><p>Any time I start using a new language I always start with "Hello world" and working a few simple example programs to get my head around the syntax, idioms, and common data structures. But yes, don't spend a ton of time on this, as soon as you have a sense that you know what to do, start tackling actual work.</p><p>If the languages are at all commonplace, having an AI convert a program from language X to language Y might speed you along as well. No guarantees it will be perfect but it will probably get you in the ballpark.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42280094"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42280094" href="https://news.ycombinator.com/vote?id=42280094&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div>
                  <p>I try not to use AI when learning a new language. I don't want to rely on premade answers to my problem. I prefer using the language's documentation and some light SO searching so I can figure it out on my own. AI is the last resort for me when learning something new.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42280407"><td></td></tr>
                              <tr id="42277920"><td></td></tr>
            <tr id="42278729"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42278729" href="https://news.ycombinator.com/vote?id=42278729&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div><p>On a related note, I found going through "The Raytracer Challenge" helped me to re-familiarise with C++ (after 20 years). Note that the book isn't language-specific.  Installing clangd (and getting it to work with my text editor) really helped too, to speed up the edit-fix loop.  Perhaps going through a book like that is a good way to challenge yourself to learn enough of a language and its tools.  The test-driven format of the book was good to make sure that my code is correct at every stage.</p><p><a href="https://pragprog.com/titles/jbtracer/the-ray-tracer-challenge/" rel="nofollow">https://pragprog.com/titles/jbtracer/the-ray-tracer-challeng...</a></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42278400"><td></td></tr>
                <tr id="42279827"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42279827" href="https://news.ycombinator.com/vote?id=42279827&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div>
                  <p>I would second this.  I have pretty extensive experience in a few python-like languages, and had written a few hundred lines of python over the years, but had never had a full-time job writing it.  I had an upcoming job working on a python codebase.  I found ExecuteProgram to be a pretty great as a way to bone up on intermediate python syntax, idioms, and standard library so I could minimize the first few weeks of "How do I do [common thing I know in 5 other languages] in python?"</p>
              </div></td></tr>
        </tbody></table></td></tr>
                  <tr id="42277603"><td></td></tr>
                <tr id="42277804"><td></td></tr>
                  <tr id="42277701"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42277701" href="https://news.ycombinator.com/vote?id=42277701&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div>
                  <p>What’s the difference between how a senior and non-senior learn that would warrant a unique platform for each?</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42278128"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42278128" href="https://news.ycombinator.com/vote?id=42278128&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div><p>I’m going to go against the flow and say nothing. I think the primary reason you see seniors looking for senior focused platforms is because almost all the learning content is terrible. Seniors will spot this sooner than juniors. I’ve worked as an external examiner for CS students for a decade and the stuff they put themselves through to avoid reading official docs is amazing. They’ll literally sit through 50 hours of video of what is essentially two a4 pages of “example how-to”.</p><p>Why a senior wouldn’t just head directly to the documentation for a programming language or the equivalent to “The C++ Programming Language” is a different question though. Learning a new language is extremely easy, it’s learning how the compiler, runtime and so on which is hard. You’ll very rarely find that outside of official docs or books written by extremely knowledgeable people.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42279582"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42279582" href="https://news.ycombinator.com/vote?id=42279582&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div><p>I 100% agree with your take and suspect most actual "seniors" do as well.</p><p>Eventually most seniors should come to the realization that expecting there to be a "senior" oriented platform is unrealistic for a variety of reasons (mostly, because the exercise based nature of platform learning in the beginner sense just isn't the sort of thing you need to learn to become senior level in a language and isn't super useful to seniors coming from other languages...).</p><p>A real senior that is really trying to learn a new language or ecosystem to a reasonable amount of competence should start with the docs and with a small (but sizeable, enough to have to learn the languages tooling and whatnot) project.</p><p>I shouldn't even comment on this, but if you expect there to be video tutorials for the kind of thing you are trying to learn, then maybe you have experienced some form of title inflation. Eventually, people need to learn to read the (f'ing) manual, and I hate to say it like that because it's infamously toxic when inappropriately told to beginners as advice, but it's the truth for somebody that calls themselves a senior.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42280322"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42280322" href="https://news.ycombinator.com/vote?id=42280322&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div><p>“50 hours of video” seems especially true for cloud certificates. Figured maybe I should finally pick up an AWS cloud cert or two and realised that video courses tend to be 40-50 hours per certificate. If you’ve already worked with AWS, or any cloud provider really, a lot of that content looks tedious.</p><p>In the end I bought a “course” that’s 6 practice exams with high quality questions and explanations of each answer. For AWS it’s been a nice approach, so far anyway, because the docs are truly vast and I probably wouldn’t have thought to read the docs for Snowmobile, which I don’t use day to day.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42280437"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42280437" href="https://news.ycombinator.com/vote?id=42280437&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div>
                  <p>I think the main issue with most documentation is that everything is treated equally, and often critical details get a passing mention, so it's helpful to have  focused course material that can give some indication of priority and a heads up for the tricky parts.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42280588"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_42280588" href="https://news.ycombinator.com/vote?id=42280588&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div><p>The challenge with this, and I agree with you, is that I don’t think you’ll find many people capable of creating such a course being in the course creation business. I suspect almost no one would be interested in doing it. The only financial motivation would be to go the consultancy route like Uncle Bob, and I’m not sure who would have any sort of motivation to do it as a hobby project. You’d be more likely to find those people contributing to the actual programming language in some way.</p><p>As I see it the programming teaching industry, or whatever you might call it, is similar to other self-help industries where people who are good at marketing sell you empty calories. Even if you created an in dept course on something, you would probably have an issue distributing it in the vast ocean of courses.</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="42278174"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42278174" href="https://news.ycombinator.com/vote?id=42278174&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div><p>All your reasoning is agreeable but I disagree with the foremost conclusion</p><p>&gt; I’m going to go against the flow and say nothing.</p><p>Whether we're talking about the actual language or the surrounding tooling and ecosystem, very few language and ecosystem experiences are actually different. As a result you're often mapping needs that you already satisfied and can explicitly state to another language. Someone who has already learned their n-th language looks at learning very differently.</p><p>This also makes a seasoned learner vastly more capable of extracting value from a friend or colleague who is willing to steer the learning experience.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42278391"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42278391" href="https://news.ycombinator.com/vote?id=42278391&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div><p>That's how I've learned Python, so far. Between that and, writing my own code, and looking at other's code, Ive picked up quite a bit (not an expert but I think I'm doing OK).</p><p>The easy part is the language, the difficult part is learning to do things the Pythonic way.</p><p>Of course, I have to allow for the Dunning-Kreuger effect.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42279619"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_42279619" href="https://news.ycombinator.com/vote?id=42279619&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div><p>This doesn't sound like Dunning-Kreuger to me.</p><p>You sound well aware of the fact that being able to put out working python code doesn't necessarily mean you fully understand all of the best practices and idioms that the particular community uses, and that's okay. You are aware of your weakness.</p><p>If you were stuck in "tutorial hell" but thought you knew the language, then maybe that would be Dunning-Kreuger. Or if you were unaware of your not writing idiomatic code due to coming from a different language and being new.</p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="42277765"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42277765" href="https://news.ycombinator.com/vote?id=42277765&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div>
                  <p>Well a senior developer would be assumed to share a certain common understanding of concepts and terms that a more junior developer might not. When teaching anything one of the most important parts is ta gauge your pupils and determine whether they need more or less information to keep the topic interesting while not making it impossible to follow along. Since written or otherwise pre-recorded teaching materials aren't afforded the luxury of interacting with their pupils they must choose ahead of time what level they are aimed at. And since a senior in any field would be able to follow along with materials meant for the junior, albeit at a slower and less interesting pace, but not the other way around they tend to err on the side of over-explanation. A platform for teaching senior developers would therefore allow a more engaging and time saving experience for those able to consume it.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="42278113"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42278113" href="https://news.ycombinator.com/vote?id=42278113&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div><p>Senior doesn't need to learn about loops, ifs and so on</p><p>For example when learning C++ while being proficient at C# I found useful this blog: <a href="https://www.jacksondunstan.com/articles/5530" rel="nofollow">https://www.jacksondunstan.com/articles/5530</a></p><p>"C++ For C# Developers: Part 1 – Introduction"</p><p>Author compares features between C# and C++ and shows what is similar, the same, different, non-existent, etc.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42281522"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42281522" href="https://news.ycombinator.com/vote?id=42281522&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div>
                  <p>These things are taught in the first semester of a CS degree and part of the interview process for an entry-level position.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                  <tr id="42277723"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42277723" href="https://news.ycombinator.com/vote?id=42277723&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div>
                  <p>Another programming language as reference. I can learn a new language really easily this way, but the first was really hard - it was so unlike anything i had ever done before.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42279192"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42279192" href="https://news.ycombinator.com/vote?id=42279192&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div><p>“Writing Fortran in Lisp” should not be disregarded. There’s a lot of value of having hands on exposure and success with common, even if not idiomatic, concepts.</p><p>Ye Olde “write once, throw it away” concept. Using prior language knowledge can make the first steps much smaller as you learn not just the new language, but environment and tools.</p><p>This can give you a quick, solid foundation with which to leverage learning newer ideas and idioms of the new system.</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="42277932"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42277932" href="https://news.ycombinator.com/vote?id=42277932&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div><p>The essence of being senior, I feel is "I have made the mistake you are about to make". This echoes in language learning. When I was learning Go I could easily pinpoint what language design decisions were made because of lessons learned from this language or that. (I do not want to suggest schismogenesis applies to programming languages but ... it kinda sorta does?) Teaching with this in mind needs a very different curriculum.</p><p>Also, basic exercises are boring because we did them ten thousand and one times already just with slightly different syntax.</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="42278844"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42278844" href="https://news.ycombinator.com/vote?id=42278844&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div>
                  <p>Learning a new syntax takes a day or two, a week or two at the most. Having a site or product that helps you with that doesn't seem important, at least to me. The hard part about learning a new language is learning <i>how</i> to use it, not its syntax. Learning how to use it requires working with it, and for a long time, somewhere in the 3 to 10 year range to really become an expert. You can't <i>learn</i> experience quickly using any product or YouTube video.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="42279806"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42279806" href="https://news.ycombinator.com/vote?id=42279806&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div><p>My old boss gave me some good pointers: find Koans. Ruby Koans, Kotlin Koans, there's probably a Koan for your language. It'll help you wrap your head around the basics of the language, and sometimes they'll even help you set up the development environment, which some people have alluded to being difficult.</p><p>From there, it's just ... using it. Making lots and lots of mistakes.</p><p>I didn't start really learning Typescript until it was a very real obligation for me, and my style of programming and the reasons for it have definitely changed over the last year as a reflection.</p><p>Accept that this sort of change is going to happen and that it's natural and even a good thing. It's okay to be new at things again and to make mistakes :)</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42279536"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42279536" href="https://news.ycombinator.com/vote?id=42279536&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div>
                  <p>As long as you know basic programming, the best way to learn a new language is to just jump into an existing project or start a new one from scratch. Classes and tutorials will get you nowhere.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="42280402"><td></td></tr>
            <tr id="42280384"><td></td></tr>
            <tr id="42278894"><td></td></tr>
            <tr id="42279530"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42279530" href="https://news.ycombinator.com/vote?id=42279530&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div><p>This is a bad question cause it comes off as judgmental and everything...</p><p>But what do you think you are getting out of a "platform" when it comes to learning a language?</p><p>I agree with keyle that you'll learn more working on a real project than doing a platform curriculum that is usually designed around beginners.</p><p>Just my personal hot take. I like exercise I suppose if that's the sort of thing you really think would be helpful.</p><p>The only reason I'm giving you this answer is cause you said explicitly "for senior devs". I don't really know any senior devs personally (that would admit to) using "platforms" or exercises to learn new languages. For me, I open up the docs and start writing a project, and I think that usually gets the job done learning a new language a bit faster.</p><p>Most platforms are way too beginner oriented, and you'll rarely get anything that requires more than a small amount of code...it's tough to learn a language very well until you have more than say 1000 lines and are seeing how the tooling and modules and whatnot really work on a realistic size of project...</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42279904"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42279904" href="https://news.ycombinator.com/vote?id=42279904&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div><p>The usefulness of beginner materials really depends on how big of a jump it is, no?</p><p>Going from writing firmware in C &amp; asm for 30 years to Haskell would likely require more than just documentation.</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="42278017"><td></td></tr>
            <tr id="42279548"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42279548" href="https://news.ycombinator.com/vote?id=42279548&amp;how=up&amp;goto=item%3Fid%3D42276995"></a></center>    </td><td><br><div><p>Honestly, I find ChatGPT excellent for this. There are two basic things I usually ask it for:</p><p>1. First, I ask it to give me a conceptual overview, going through the main features of a language I know well and then asking for the equivalent in the new language. I also ask it for specifics/features in the new language that aren't present in the language I know well.</p><p>2. If I have specific questions, I'll write a code snippet in a language I know well and ask it to translate it to the other language. I might also ask it for "library equivalents", e.g. if there is some specific library that is the "standard" for doing something in one language, I'll ask what is the standard in the other language.</p><p>Related example: I <i>suck</i> at shell scripting because there is so much esoteric shit in it, so I used to just write short scripts in JavaScript and run them in Node because I'm so much more comfortable with JS and Node. Now, though, I'll just ask ChatGPT to write the script for me. The code isn't always 100% bug free, but I understand shell scripting well enough to usually fix any bugs. Also, if there is something I don't understand (e.g. ${VAR_NAME##*/} was a new one for me today), ChatGPT explains it well.</p><p>If you haven't tried it, I strongly recommend using ChatGPT (or Claude, etc.) for learning a new programming language.</p></div></td></tr>
        </tbody></table></td></tr>
            </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Breaking the 4Chan CAPTCHA (445 pts)]]></title>
            <link>https://www.nullpt.rs/breaking-the-4chan-captcha</link>
            <guid>42276865</guid>
            <pubDate>Fri, 29 Nov 2024 20:32:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nullpt.rs/breaking-the-4chan-captcha">https://www.nullpt.rs/breaking-the-4chan-captcha</a>, See on <a href="https://news.ycombinator.com/item?id=42276865">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><span>Breaking the 4Chan CAPTCHA</span></p><h2 id="introduction">Introduction</h2>
<p>This project was entered into as a learning experience, to enhance my knowledge of machine learning, as well as TensorFlow specifically. At the end, I wanted to have a trained machine learning model that runs in the browser to reliably (at least 80% accuracy, &gt;90% preferred) solve the 4Chan CAPTCHA. These goals were achieved - let's talk about how I got there!</p>
<p>If you'd like to follow along with the code references, I have made the code public on GitHub <a href="https://github.com/AppleDash/4chan-captcha-playground">here</a>.</p>
<h2 id="terminology">Terminology</h2>
<ul>
<li><strong>CAPTCHA</strong>: A challenge-response test to determine whether or not a computer or website user is a human. The acronym stands for Completely Automated Public Turing test to tell Computers and Humans Apart.</li>
<li><strong>4Chan</strong>: A public, anonymous imageboard website with discussion boards on various topics. These boards are used for posting images and text discussions. Filling out a CAPTCHA is required before every post or reply.</li>
<li><strong>Normal CAPTCHA</strong>: The simplest form of the 4Chan CAPTCHA, that consists of an image with 5 or 6 alphanumeric characters. The user must read and correctly enter all of the characters in a field in order to make a post on 4Chan.</li>
<li><strong>Slider CAPTCHA</strong>: A more complex form of the 4Chan CAPTCHA, that consists of a background image with random-looking character fragments, and a foreground image with transparent "holes" or "windows" in it. A slider in the browser CAPTCHA form must be moved to correctly align the two images in order to see the CAPTCHA text.</li>
</ul>
<h2 id="getting-the-data">Getting the Data</h2>
<p>I've heard many times that the hardest part of any machine learning problem is getting the data to train your model. This assertion was definitely pertinent here, for several reasons. There's two parts to this problem: Getting the CAPTCHAs, and getting solutions to those CAPTCHAs.</p>
<h3 id="scraping-captchas-from-4chan">Scraping CAPTCHAs from 4Chan</h3>
<p>After looking at the HTTP requests in the browser console when requesting a new CAPTCHA, I found that it makes a request to <code>https://sys.4chan.org/captcha?framed=1&amp;board={board}</code>, where <code>{board}</code> is the name of the board we're trying to post on. The response is an HTML document that contains a script tag with a <code>window.parent.postMessage()</code> call with some JSON. On a hunch, I tried to remove the <code>framed=1</code> parameter, and found that this causes it to just spit out the raw JSON. That should be easier to work with. The JSON looks like this:</p>
<pre><code><span>{</span>
    <span>"challenge"</span><span>:</span> <span>"[some long and random string here]"</span><span>,</span>
    <span>"ttl"</span><span>:</span> <span>120</span><span>,</span>
    <span>"cd"</span><span>:</span> <span>5</span><span>,</span>
    <span>"img"</span><span>:</span> <span>"[a base64 string here]"</span><span>,</span>
    <span>"img_width"</span><span>:</span> <span>300</span><span>,</span>
    <span>"img_height"</span><span>:</span> <span>80</span><span>,</span>
    <span>"bg"</span><span>:</span> <span>"[a base64 string here]"</span><span>,</span>
    <span>"bg_width"</span><span>:</span> <span>349</span>
<span>}</span>
</code></pre>
<p>Some of these keys are pretty obvious. <code>ttl</code> and <code>cd</code> are the least obvious to me. I know from experience that the 4Chan CAPTCHA only displays for about 2 minutes before it expires and you have to request a new one, so that's what <code>ttl</code> must be. But what about <code>cd</code>? Let's make another request, shortly after the first one:</p>
<pre><code><span>{</span>
    <span>"error"</span><span>:</span> <span>"You have to wait a while before doing this again"</span><span>,</span>
    <span>"cd"</span><span>:</span> <span>23</span>
<span>}</span>
</code></pre>
<p>If I keep making the same request, the <code>cd</code> parameter steadily decreases, at a rate of about 1 per second. Alright, so this is how long you have to wait before requesting a new CAPTCHA. <code>cd</code> likely stands for "cooldown".</p>
<p>If I wait the 23 seconds, and then make another request, I get a successful response, but this time, the <code>cd</code> is 32. We have to wait longer every time. After some experimentation with a script, it looks like the first few requests can be made every 5 seconds, then it increments to 8, and then continues to roughly double until it's capped at 280 seconds, and stays there.</p>
<p>Additionally, once you've hit the 280 second timers, the CAPTCHA gets somewhat harder. It looks like this:</p>
<figure><img alt="Difficult 4Chan CAPTCHA with several horizontal lines and an oval obscuring the text, in addition to general noise all over the image" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" sizes="100vw" srcset="https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-hard.png&amp;w=640&amp;q=75 640w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-hard.png&amp;w=750&amp;q=75 750w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-hard.png&amp;w=828&amp;q=75 828w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-hard.png&amp;w=1080&amp;q=75 1080w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-hard.png&amp;w=1200&amp;q=75 1200w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-hard.png&amp;w=1920&amp;q=75 1920w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-hard.png&amp;w=2048&amp;q=75 2048w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-hard.png&amp;w=3840&amp;q=75 3840w" src="https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-hard.png&amp;w=3840&amp;q=75"><figcaption>Difficult 4Chan CAPTCHA with several horizontal lines and an oval obscuring the text, in addition to general noise all over the image</figcaption></figure>
<p>instead of this:</p>
<figure><img alt="Easier 4Chan CAPTCHA with one curved line over the text, in addition to general noise all over the image" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" sizes="100vw" srcset="https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-easy.png&amp;w=640&amp;q=75 640w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-easy.png&amp;w=750&amp;q=75 750w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-easy.png&amp;w=828&amp;q=75 828w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-easy.png&amp;w=1080&amp;q=75 1080w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-easy.png&amp;w=1200&amp;q=75 1200w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-easy.png&amp;w=1920&amp;q=75 1920w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-easy.png&amp;w=2048&amp;q=75 2048w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-easy.png&amp;w=3840&amp;q=75 3840w" src="https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-easy.png&amp;w=3840&amp;q=75"><figcaption>Easier 4Chan CAPTCHA with one curved line over the text, in addition to general noise all over the image</figcaption></figure>
<p>So, there's some throttling in place. The data also gets of lower (but still usable) quality if you make too many requests.</p>
<p>Something I will briefly touch on is that the user has to pass a Cloudflare Turnstile challenge to even request a CAPTCHA in the first place. As a result, simply using many proxies with a naive script is not realistic, without first passing the Cloudflare Turnstile and saving the relevant cookies. When I was scraping CAPTCHAs with the script I wrote for this, I simply copied the Cloudflare cookies from my browser, and manually replaced them whenever they expired.</p>
<p>I scraped several hundred CAPTCHAs in this manner - not enough to train the model, but it's at least a start. This still leaves us with a problem, though. We have all these CAPTCHAs, but we don't have the solutions. I could fill them out manually, but instead, let's try something else.</p>
<h3 id="getting-the-solutions">Getting the Solutions</h3>
<p>Or, <em>Humans are bad at solving the 4Chan CAPTCHA</em>.</p>
<p>A recurring theme in this project has been "this is easy for a computer to do, but hard for a human to do." Many users find the "slider" style CAPTCHAs incredibly frustrating, but I've had a 100% success rate in aligning them with the heuristic script I made (<code>trainer/captcha_aligner.py</code>). The 4Chan CAPTCHAs in general are widely considered by users of the site to be frustrating to solve. But, surely, for people who solve CAPTCHAs <em>for a living</em>, it shouldn't be an insurmountable challenge, right?</p>
<p>I coded a quick script (seen in the project under <code>trainer/labeler.py</code>) to send the CAPTCHAs to <a href="https://anti-captcha.com/">a commercial CAPTCHA solving service</a>, where real humans would solve the CAPTCHAs for me for a nominal fee. Writing the script was simple, but actually employing it was an exercise in frustration. I sent a couple dozen CAPTCHAs to the service, and nearly all of them came back with one or more characters incorrectly solved.</p>
<p>The service has a feature called "100% Recognition", which allowed me to specify that all my requests be first sent to <code>n</code> workers, and if <code>x</code> of those workers don't return the same solution, then send them to up to <code>y</code> more workers. It would only return an error after sending the CAPTCHAs to <code>n + y</code> workers and not getting at least <code>x</code> solutions the same. I configured my account with the values <code>n = 2</code>, <code>x = 2</code>, and <code>y = 3</code> - that is, initially send the CAPTCHA to 2 workers, and if they don't both agree, then send them to up to 3 additional workers until two of them agree, or none of them agree.</p>
<p>This improved the situation somewhat. About 80% of the CAPTCHAs were now being successfully solved, and after reviewing the results, 90% of those were correct, but about 10% had errors in them, which indicated that multiple workers were making the same mistakes. This was still less than ideal.</p>
<p><strong>A quick aside: What if I just ask someone I know to be reliable to do it for me, or even do it myself?</strong> I explored both of these approaches. I wrote a quick user script that saved the CAPTCHA image and the solution text, and just sat there requesting and solving CAPTCHAs in my free time. I also asked a good friend of mine to do the same. This yielded several hundred images, which I did add to the training set, but in the end this approach was abandoned because we still ran into the throttling problem, and the problem of the CAPTCHAs getting harder (and eventually, near-impossible) if you request too many of them.</p>
<p>I begun to wonder if there was a different way to look at this altogether. What if we didn't need to scrape CAPTCHAs and have them solved by humans?</p>
<h3 id="generating-synthetic-data">Generating Synthetic Data</h3>
<p>What if we could generate our own 4Chan CAPTCHAs? 4Chan, and the CAPTCHA it uses, are not open source, so I couldn't literally run the same code locally. But I could definitely approximate it.</p>
<p>The 4Chan CAPTCHA can be dissected into two main parts. The background, which looks like this:</p>
<figure><img alt="4Chan CAPTCHA background with the characters removed, leaving only general noise over the image" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" sizes="100vw" srcset="https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-background.png&amp;w=640&amp;q=75 640w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-background.png&amp;w=750&amp;q=75 750w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-background.png&amp;w=828&amp;q=75 828w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-background.png&amp;w=1080&amp;q=75 1080w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-background.png&amp;w=1200&amp;q=75 1200w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-background.png&amp;w=1920&amp;q=75 1920w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-background.png&amp;w=2048&amp;q=75 2048w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-background.png&amp;w=3840&amp;q=75 3840w" src="https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-background.png&amp;w=3840&amp;q=75"><figcaption>4Chan CAPTCHA background with the characters removed, leaving only general noise over the image</figcaption></figure>
<p>and the characters, which look like this:</p>
<figure><img alt="4Chan CAPTCHA character set, the characters 0, 2, 4, A, D, G, H, K, M, N, P, S, X, and Y with general noise and distortion" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" sizes="100vw" srcset="https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-letters.png&amp;w=640&amp;q=75 640w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-letters.png&amp;w=750&amp;q=75 750w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-letters.png&amp;w=828&amp;q=75 828w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-letters.png&amp;w=1080&amp;q=75 1080w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-letters.png&amp;w=1200&amp;q=75 1200w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-letters.png&amp;w=1920&amp;q=75 1920w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-letters.png&amp;w=2048&amp;q=75 2048w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-letters.png&amp;w=3840&amp;q=75 3840w" src="https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-letters.png&amp;w=3840&amp;q=75"><figcaption>4Chan CAPTCHA character set, the characters 0, 2, 4, A, D, G, H, K, M, N, P, S, X, and Y with general noise and distortion</figcaption></figure>
<p>We don't need to generate our own backgrounds from scratch. It's a relatively simple computer vision problem to take an image like the 4Chan CAPTCHA, and find all of the large <a href="https://docs.opencv.org/3.4/d4/d73/tutorial_py_contours_begin.html">contours</a> in the image, which represent the characters, and remove them. This leaves only the noisy background, as seen in the image above, which was generated using this algorithm.</p>
<p>Next, we need to isolate a decent number of characters, and label them with their values. If this was trivial to do with an algorithmic script, well, we wouldn't be here, because solving the CAPTCHA would also be trivial to do with an algorithmic script :) It's pretty easy to do this by hand, though, and that's what I settled on doing. It was annoying. I tagged the characters with <a href="https://github.com/microsoft/VoTT">VoTT</a> and then extracted them with a quick and dirty script, which also postprocessed them to make sure it was only the characters in the images. I ended up with 50-150 isolated images of each character. It was during this stage of the project that I realized the 4Chan CAPTCHA incoudes only the characters 0, 2, 4, A, D, G, H, K, M, N, P, S, X, and Y - likely done to avoid ambiguity.</p>
<p>Now we just have to put it all together. When extracting the digits, I observed a few patterns in how the characters are usually clustered or spread apart, and so I wrote my script to assemble images with backgrounds according to these formulas. And, of course, since the input character images are labelled, I can easily label the generated synthetic CAPTCHAs with their solutions.</p>
<h2 id="creating-the-model">Creating the Model</h2>
<p>Now we've got the data, it's time to train the model. I assembled a model architecture based on some research, after reading several different articles on CAPTCHA solving using neural networks.
I settled on an <abbr title="Long Short-Term Memory">LSTM</abbr> <abbr title="Convolutional Neural Network">CNN</abbr> architecture with 3 convolutional/max-pooling layers and 2 LSTM layers.
A fourth convolutional layer was also tested, but it did not improve performance.
CTC encoding of the CAPTCHA text was used, because the output was of variable length (either 5 or 6 characters).
I built the model using <a href="https://keras.io/">Keras</a> on top of <a href="https://www.tensorflow.org/">TensorFlow</a>.</p>
<h3 id="processing-the-data">Processing the data</h3>
<p>The input to the model was a mix of pre-aligned slider CAPTCHAs, normal CAPTCHAs, and synthetic CAPTCHAs.
The training script took care of ensuring they were 300x80 pixels and converted to pure black-and-white.</p>
<h4 id="always-read-the-docs">Always read the docs</h4>
<p><em>The arguments might not be in the order you expect.</em></p>
<p>One of the important steps in my data processing pipeline was making sure that all the CAPTCHA images are exactly 300x80 pixels.
Some images from the dataset, namely the older aligned "slider" CAPTCHAs, don't match this resolution / aspect ratio.
I could just fix the training data, but it's better in the end to make the training script able to cope with any data I throw at it.</p>
<p>I used <code>tf.image.resize()</code> for this. <a href="https://www.tensorflow.org/api_docs/python/tf/image/resize">The docs</a> on this are pretty simple,
for my use case I just need to pass the input image tensor, and the size, which is probably just a tuple of <code>(width, height)</code>, right?
Well, I made that assumption, and the code ran fine, so I didn't really give it a second thought.</p>
<p>Until... My model's performance was absolutely abysmal! Even after training for 32+ epochs,
the model barely performed at all on images it had seen before, and it really couldn't make anything at all of brand new CAPTCHA images,
yielding seemingly random predictions. What the heck was going on?</p>
<p>I decided to actually visualize the images I was feeding into the model, and see what they looked like
- maybe my black/white thresholding was going wrong?
I took a random image from the input data after processing, and visualized it, and I got... this:</p>
<figure><img alt="4Chan CAPTCHA that is vertically stretched to 80x300 pixels and completely unreadable" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" sizes="100vw" srcset="https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-sideways.png&amp;w=640&amp;q=75 640w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-sideways.png&amp;w=750&amp;q=75 750w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-sideways.png&amp;w=828&amp;q=75 828w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-sideways.png&amp;w=1080&amp;q=75 1080w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-sideways.png&amp;w=1200&amp;q=75 1200w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-sideways.png&amp;w=1920&amp;q=75 1920w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-sideways.png&amp;w=2048&amp;q=75 2048w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-sideways.png&amp;w=3840&amp;q=75 3840w" src="https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-sideways.png&amp;w=3840&amp;q=75"><figcaption>4Chan CAPTCHA that is vertically stretched to 80x300 pixels and completely unreadable</figcaption></figure>
<p>Yeah, you probably saw that coming as soon as I said "probably just a tuple of <code>(width, height)</code>". Turns out it's not. It is, in fact, a tuple of <code>(height, width)</code>! Had I taken the time to read the whole documentation page, I would have found this near the bottom of the page, where it provides more detail on the expected argument. This is definitely a lesson learned - read the documentation thoroughly when working with libraries you're unfamiliar with, even if you think you know how it works, and especially if things aren't working how you'd expect.</p>
<p>After fixing this bug, the training performance looked a lot more promising.</p>
<h3 id="training-the-model">Training the model</h3>
<p>The final dataset consisted of approximately 500 hand-solved images, and approximately 50,000 synthetically-generated images.
The synthetic images were generated based on random samples from approximately 2,500 background images and 50-150 images of each character.
This dataset was randomly shuffled, and then segmented 90/10 into training and evaluation sets.
Training took approximately 45 seconds per epoch on my NVIDIA RTX A4000 Laptop GPU.</p>
<p>At the end of the first epoch, the loss did not look very promising - it's still all the way up at 19. During the evaluation callback phase, predictions were nowhere near correct, yielding only 1-2 predicted characters that didn't match any of the characters in the image. This is to be expected during the early stages of training.</p>
<p>Later epochs greatly improved performance. By the end of the fourth epoch, loss decreased to 0.55, and the predictions were already looking good, with 5/5 of the random test predictions at this stage yielding correct results. Loss steadily decreased throughout the rest of the training epochs.</p>
<p>After experimenting with different numbers of epochs, 8-16 epochs was found to be a good trade-off between time and final model performance.
Loss stabilized by the 8th epoch, and increasing the epoch count beyond 16 yielded greatly diminishing returns.</p>
<figure><img alt="Graph of model loss versus epochs, showing initial large decrease followed by steady decline and levelling out" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" sizes="100vw" srcset="https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-loss.png&amp;w=640&amp;q=75 640w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-loss.png&amp;w=750&amp;q=75 750w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-loss.png&amp;w=828&amp;q=75 828w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-loss.png&amp;w=1080&amp;q=75 1080w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-loss.png&amp;w=1200&amp;q=75 1200w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-loss.png&amp;w=1920&amp;q=75 1920w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-loss.png&amp;w=2048&amp;q=75 2048w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-loss.png&amp;w=3840&amp;q=75 3840w" src="https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-loss.png&amp;w=3840&amp;q=75"><figcaption>Graph of model loss versus epochs, showing initial large decrease followed by steady decline and levelling out</figcaption></figure>
<p>I wrote a quick test script (<code>trainer/infer.py</code>) to infer CAPTCHA solutions in Python. Results were promising on images the model had not seen before, yielding correct solutions in the limited number of test cases I tried.</p>
<h2 id="using-the-model-in-tensorflowjs">Using the Model in TensorFlow.js</h2>
<p>Writing the <a href="https://www.tensorflow.org/js">TensorFlow.js</a> code for the user script was quite straightforward. I chose TypeScript for this task. I re-implemented the CAPTCHA alignment algorithm from the Python code, as well as the image preprocessing code. All of this code is located in the <code>user-scripts/</code> directory in the repository.</p>
<p>The Python TensorFlow/Keras model formats aren't compatible with the model format expected by TensorFlow.js. There's an <a href="https://www.tensorflow.org/js/guide/conversion">official conversion script</a>, with instructions on how to use it. This should be easy, right?</p>
<h3 id="the-converter-doesnt-work-on-python-312">The converter doesn't work on Python 3.12</h3>
<p>This was a pretty simple problem that took awhile to figure out. The official TensorFlow-to-TFJS model converter doesn't work on Python 3.12. This doesn't seem to really be documented, and the error messages thrown when you try to use it on Python 3.12 are non-obvious. I tried an older version of Python (3.10) on a hunch, using PyEnv, and it worked like a charm.</p>
<h3 id="tensorflowjs-doesnt-support-keras-3">TensorFlow.js doesn't support Keras 3</h3>
<p>New problem: The conversion script supports converting Keras 3 models to TensorFlow.js format. The only problem? TensorFlow.js doesn't support actually reading those converted models. I found this out from a <a href="https://discuss.ai.google.dev/t/corrupted-configuration-and-batch-input-shape-loading-pre-trained-layers-model-in-tensorflow-js/24454">forum post</a>, after I spent a bit of time puzzling out why TFJS wouldn't read the model that the official conversion script output.</p>
<p>Luckily, the solution was easy: Use Keras 2. We can do this by training the model with the environment variable <code>TF_USE_LEGACY_KERAS=1</code> set, after installing the legacy <code>tf_keras</code> package. This may require some code changes. In my case, I only had to trivially modify one line. We also have to export the model using the legacy <code>.h5</code> model format, and specify that as the input format when running the conversion script.</p>
<h2 id="real-world-performance">Real-World Performance</h2>
<p>We've seen the performance on the training dataset, which consists mainly of synthetic images. But it doesn't matter if it can solve synthetic CAPTCHAs - we care about solving the real ones.</p>
<p>Good news: It works great on the real 4Chan CAPTCHA. Solving is fast, taking about 1 second to load the model the first time, and then being imperceptibly quick on subsequent executions. In my experience over hundreds of real CAPTCHAs solved in the browser, the model exhibits a greater than 90% successful solve rate. It rarely gets characters wrong - when it is innacurate, it typically omits a single character entirely. I believe this could be improved with greater training on actual data, or possibly tweaking the CAPTCHA layouts in the synthetic dataset generator.</p>
<figure><img alt="Animation of requesting a CAPTCHA in the 4Chan post form, and it being automatically solved by the user script." loading="lazy" width="100" height="100" decoding="async" data-nimg="1" sizes="100vw" srcset="https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2Fdemo.gif&amp;w=640&amp;q=75 640w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2Fdemo.gif&amp;w=750&amp;q=75 750w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2Fdemo.gif&amp;w=828&amp;q=75 828w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2Fdemo.gif&amp;w=1080&amp;q=75 1080w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2Fdemo.gif&amp;w=1200&amp;q=75 1200w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2Fdemo.gif&amp;w=1920&amp;q=75 1920w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2Fdemo.gif&amp;w=2048&amp;q=75 2048w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2Fdemo.gif&amp;w=3840&amp;q=75 3840w" src="https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2Fdemo.gif&amp;w=3840&amp;q=75"><figcaption>Animation of requesting a CAPTCHA in the 4Chan post form, and it being automatically solved by the user script.</figcaption></figure>
<p>Small fun fact: This model has far better accuracy than the human-powered CAPTCHA solving service I described above.</p>
<h3 id="4-character-captchas">4-character CAPTCHAs</h3>
<p>While I was writing and editing this article after completing the project,
I noticed that 4Chan begun sometimes serving CAPTCHAs with only 4 characters, rather than the usual 5 and 6-character CAPTCHAs.
Despite this model only having been trained on 5 and 6-character CAPTCHAs,
performance on the 4-character CAPTCHAs is the same as for the 5 and 6-character CAPTCHAs.</p>
<h2 id="conclusion">Conclusion</h2>
<p>I enjoyed this project a lot. It had a few challenges to overcome, and I learned a ton about machine learning and computer vision in the process. There are surely improvements that can be made, but for now, I'm pleased with the results, because I achieved what I set out to do from the start.</p>
<p>I hope you enjoyed reading this write-up as much as I enjoyed writing it, and I hope you learned something too!</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What does this button do? – My new car has a mysterious and undocumented switch (537 pts)]]></title>
            <link>https://blog.koenvh.nl/what-does-this-button-do-cm42u2oi7000a09l42f54g2pr</link>
            <guid>42276620</guid>
            <pubDate>Fri, 29 Nov 2024 19:59:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.koenvh.nl/what-does-this-button-do-cm42u2oi7000a09l42f54g2pr">https://blog.koenvh.nl/what-does-this-button-do-cm42u2oi7000a09l42f54g2pr</a>, See on <a href="https://news.ycombinator.com/item?id=42276620">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><h2>My new car has a mysterious and undocumented switch</h2></p></div><div id="post-content-parent"><p>Last week I bought a car. After twelve years of service, my old trusty Peugeot 107 in blue has had its best. Expensive repairs were coming <em>at some point</em>, and I did not feel like waiting around for them to come. Plus the existing list of faults (like the high oil usage of about a litre per month, a brake that sometimes blocked without reason, or the smell of exhaust fumes that sometimes came into the car when the fan was on high) also started getting longer and longer.</p>
<p><img data-zoomable="true" loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1732888980123/91643929-8f55-468a-8568-97d1a64862da.jpeg?auto=compress,format&amp;format=webp" alt=""></p>
<p>Anyway, new car time! After a lot of research I ended up with an Opel Corsa from 2020. To be precise, it’s an Opel Corsa Edition with 101 HP, and most importantly, it’s mine.</p>
<p>Unlike the Peugeot, the Opel has gadgets - quite a few of them. Of course it being my car, I want to know what all buttons do, so I read the entire manual (which is very annoying to read, as they make one manual for every version of the car, so half of it does not apply to this car, but I digress). One of those buttons was the following below the lighting controls.</p>
<p><img data-zoomable="true" loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1732889068247/f39bda1d-77c1-4186-862b-c566cce517bb.jpeg?auto=compress,format&amp;format=webp" alt=""></p>
<p>Those do not appear in the manual, or the website, or anywhere. What could they be? Just flipping the switch does nothing, apart from turning off the light on the switch. So let’s look where the button goes. I can see that part of it is wired to the back of the OBD2 port (a port that retrieves data from the onboard computer about the car, such as pedal position, temperature, lights, rev count, speed - basically if you can see it on your dashboard it can be read using the OBD2 port), so it is getting information from the car, but apart from that the wires go to places that I can’t see without taking the car further apart.</p>
<p><img data-zoomable="true" loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1732889143592/00372c30-63b8-4807-9ae3-4b15727304e5.jpeg?auto=compress,format&amp;format=webp" alt=""></p>
<p>Something else that I noticed before is that I heard the typical inference noise coming from that area of the car when putting the ignition on. You know, <a target="_blank" href="https://youtu.be/FYjs7vsaSEw">this</a> sound. <em>Ti-ti ta, ti-ti ta, ti-ti ta, ti-ti ta, ti-ti ta, ti-ti ta, ti-ti ta, TAAAAAAAAAAA</em>. That gave me the ominous feeling there might be something sending data in there. Sure, my car does that too so I can see in the app where I parked it (seriously, it does that), but at least I gave permission for that.</p>
<p>I asked the wisdom of the crowd. A lot of ideas came up: nitrous (would have been fun), LPG switch (it’s only petrol), flame kit (I wish), front parking sensors (those are standard on the car). No avail.</p>
<p>I called my dealership and asked. They guessed it might have been an immobiliser - bit strange on a car this young and type, and also strange for it to be a switch like this. I called the dealership that previously maintained the vehicle based on the phone number in the service history. They did not install it, and guessed it might be a black box. They did tell me who it previously belonged to (a large company), so I called their headquarters. They told me they don’t do their own cars any more, but that they outsourced it, and gave me a phone number. I called them, they told me they don’t do that, but he speculated it might be a GPS tracker.</p>
<p>Some more searching, and I figured I would just drive to my dealership. More speculating with the salespeople, who told me to make an appointment with the mechanics. I did, they had a quick look at it and I now have an answer:</p>
<p>The metal part is something to hold a magnet next to. It registers who's driving to a fleet tracker via a device also mounted in the car, which sends it to a fleet manager via the internet. That way it can be tracked which employee did what (and potentially who to send the fine to). That would also explain the mobile phone interference noises I've heard from that area of the car. So it’s a black box, a GPS tracker, and maybe also an immobiliser? I am not sure about the last one (and why it has a switch).</p>
<p>I'm getting it removed because now I'm basically driving around with a foreign GPS tracker. Some lease company somewhere is getting data on wherever I go. Kind of spooky if you think of it, especially as I assume I am one of the few actually looking into what this is. Most people would have probably driven around for years with a foreign GPS tracker.</p>
<p><img data-zoomable="true" loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1732889803408/1353bcc6-c25c-482b-9a75-67686582c479.jpeg?auto=compress,format&amp;format=webp" alt=""></p>
<p>And that’s how the search comes to an end. After a bit of perseverance I figured out what it is. I now know my car is being tracked still, and that they know I did try out what the car’s acceleration is like at full throttle.</p>
<p>There are more interesting angles to this, like “can I request my data from the fleet manager thing that has been tracking my whereabouts under the GDPR?”, and “can I get free data from the SIM card embedded in the device that I now technically own?” but I will leave those for another day.</p>
</div></div>]]></description>
        </item>
    </channel>
</rss>