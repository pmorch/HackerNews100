<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 27 May 2025 03:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Owls in Towels (342 pts)]]></title>
            <link>https://owlsintowels.org/</link>
            <guid>44101349</guid>
            <pubDate>Mon, 26 May 2025 20:27:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://owlsintowels.org/">https://owlsintowels.org/</a>, See on <a href="https://news.ycombinator.com/item?id=44101349">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Wildlife rehabilitators often wrap owls in fabric so they can be weighed, treated, and fed. If not, the owls get in a flap.</p><p>The result? Loads of pictures of <mark><strong>#owlsintowels</strong></mark></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Trying to teach in the age of the AI homework machine (131 pts)]]></title>
            <link>https://www.solarshades.club/p/dispatch-from-the-trenches-of-the</link>
            <guid>44100677</guid>
            <pubDate>Mon, 26 May 2025 19:20:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.solarshades.club/p/dispatch-from-the-trenches-of-the">https://www.solarshades.club/p/dispatch-from-the-trenches-of-the</a>, See on <a href="https://news.ycombinator.com/item?id=44100677">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde63320e-16b0-4351-a920-afbca4650558_3213x3024.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde63320e-16b0-4351-a920-afbca4650558_3213x3024.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde63320e-16b0-4351-a920-afbca4650558_3213x3024.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde63320e-16b0-4351-a920-afbca4650558_3213x3024.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde63320e-16b0-4351-a920-afbca4650558_3213x3024.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde63320e-16b0-4351-a920-afbca4650558_3213x3024.jpeg" width="3213" height="3024" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/de63320e-16b0-4351-a920-afbca4650558_3213x3024.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:3024,&quot;width&quot;:3213,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:2403398,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://www.solarshades.club/i/162720948?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7991135e-3c06-47f5-8321-925a8c0b9e41_4032x3024.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde63320e-16b0-4351-a920-afbca4650558_3213x3024.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde63320e-16b0-4351-a920-afbca4650558_3213x3024.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde63320e-16b0-4351-a920-afbca4650558_3213x3024.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde63320e-16b0-4351-a920-afbca4650558_3213x3024.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a><figcaption>“Dover” (1975) by Deborah Remington, giving HAL 9000 vibes in the Phoenix Art Museum</figcaption></figure></div><p><span>Last summer I </span><a href="https://www.solarshades.club/p/the-case-for-the-butlerian-jihad" rel="">made the case</a><span> for bringing the principle of </span><em>Dune</em><span>’s Butlerian Jihad —&nbsp;“Thou shalt not make a machine in the likeness of a human mind” — to our broader discourse on AI. It seemed like a good way to bind together the various felt and thought objections to AI into a common credo. And a good way to distinguish between benign forms of so-called “AI” (spotting tumors, for instance) and the </span><a href="https://futurism.com/openai-chatgpt-sycophant" rel="">sycophantic</a><span> imitations of humanity being peddled by the various broligarchs.</span></p><p><span>Since then, this “hard no” movement against AI has started to take shape. For one the </span><a href="https://aftermath.site/buy-destroy-ai-shirt-aftermath-kim-hu" rel="">t-shirt game</a><span> keeps getting better. </span><a href="https://arstechnica.com/tech-policy/2025/01/ai-haters-build-tarpits-to-trap-and-trick-ai-scrapers-that-ignore-robots-txt/" rel="">Traps are being set</a><span> on the internet to punish AI scrapers and poison datasets. The </span><a href="https://www.independent.co.uk/news/world/europe/pope-leo-xiv-ai-challenge-humanity-b2748531.html" rel="">new Chicago pope bashed AI</a><span> in his first big speech. Just in my literary corner of the world, anti-AI clauses are becoming standard in book contracts and magazine submission forms. A recent episode of AppleTV’s </span><em>The Studio</em><span> ended with a crowd at ComicCon — and Ice Cube — chanting “fuck AI.” Last week there was a </span><a href="https://www.patreon.com/posts/genre-grapevine-128296070" rel="">WorldCon kerfuffle</a><span> (sigh) over using ChatGPT in part of the panel selection process.</span></p><p>(My WorldCon take is that, well intentioned though it was, feeding an AI a list of names and asking it to compile dossiers of their scandals and transgressions is a pretty dystopian use-case.)</p><p>It’s clear that writers, artists, and others in that orbit increasingly view any amount of engagement with LLMs as a betrayal of creative class solidarity. The sentiment (which I’ve heard all the way from Tumblr teens to Pulitzer Prize winners) seems to be something like this:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd836829f-9fbc-4a7b-8070-f93a095e6df9_346x513.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd836829f-9fbc-4a7b-8070-f93a095e6df9_346x513.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd836829f-9fbc-4a7b-8070-f93a095e6df9_346x513.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd836829f-9fbc-4a7b-8070-f93a095e6df9_346x513.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd836829f-9fbc-4a7b-8070-f93a095e6df9_346x513.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd836829f-9fbc-4a7b-8070-f93a095e6df9_346x513.png" width="346" height="513" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d836829f-9fbc-4a7b-8070-f93a095e6df9_346x513.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:513,&quot;width&quot;:346,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:394292,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.solarshades.club/i/162720948?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd836829f-9fbc-4a7b-8070-f93a095e6df9_346x513.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd836829f-9fbc-4a7b-8070-f93a095e6df9_346x513.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd836829f-9fbc-4a7b-8070-f93a095e6df9_346x513.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd836829f-9fbc-4a7b-8070-f93a095e6df9_346x513.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd836829f-9fbc-4a7b-8070-f93a095e6df9_346x513.png 1456w" sizes="100vw"></picture></div></a><figcaption><span>A famous panel from Frank Miller’s </span><em>The Dark Knight Returns</em><span>.</span></figcaption></figure></div><p><span>I’ve heard pushback about such anti-AI puritanism, the ways it’s just another case of social media mob culture. For me, this is where the Butlerian Jihad continues to be a fruitful metaphor. The </span><em>Dune</em><span> books are all about how holy wars and revolutions are not gentle or reasonable, how they can turn ugly, righteousness fueling a fire that can consume nations and worlds.</span></p><p><span>The other way the metaphor is proving apt is the deep-seated, almost spiritual nature of anti-AI sentiment. It’s not just more Luddism. Many people — though hardly all, given the popularity of AI products — sense that there is something grotesque about these simulacra, the people who push them on us, this whole affair. That aversion to the technological profane holds even when various stated objections to AI are supposedly addressed or nitpicked to death.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1-162720948" href="https://www.solarshades.club/p/dispatch-from-the-trenches-of-the#footnote-1-162720948" target="_self" rel="">1</a></span></p><p>Meanwhile, throughout all this, I have myself felt on the front lines of something like a grand struggle against these likeness machines —  not just as a creative but as a teacher. Because what’s become clear over the past year is that the killer app, the median American use case for products like ChatGPT, is cheating on your homework.</p><p><span>There’s been a lot written about this lately — a big article </span><a href="https://nymag.com/intelligencer/article/openai-chatgpt-ai-cheating-education-college-students-school.html" rel="">dropped in New York Mag</a><span> as I was sitting down to type this newsletter, and a discord mutual had a </span><a href="https://www.chronicle.com/article/is-ai-enhancing-education-or-replacing-it?sra=true" rel="">similarly thorough piece a couple weeks ago in the Chronicle of Higher Education</a><span>. Both pieces get into the increasing AI frustration among teachers and the increasing AI dependency among students.</span></p><p><span>There was a lot of hope for the value of AI in education (and still is, if university partnerships with tech companies are any measure). An infinitely patient digital tutor that can tackle any question (a la the Primer in Neal Stephenson’s </span><em>Diamond Age</em><span>, and probably a hundred other SF references) </span><em>sounds</em><span> like just what a strained education system needs — if it didn’t hallucinate constantly, that is. And I know teachers who use it. They’ll have students check with ChatGPT in class to get answers to discussion questions, or encourage its use in revision. Some are no doubt having AI write emails to students and paper feedback, too.</span></p><p><span>But these articles show that concern is mounting over a few factors. First, there’s a big difference between getting something explained to you, and actual learning. You might </span><em>feel</em><span> like you are learning when querying a chatbot, but those intellectual gains are often illusory.</span></p><p>Second, AI severs the connection between an output, like an essay, and the real learning, thinking, and practice creating that output usually requires. There’s now no way to be sure that a student who turns in a good essay actually has a grasp on the material that assignment was supposed to push them toward understanding. Thus, AI lets students skip the “desirable difficulties” that produce real learning. The temptation to skip these difficulties is powerful enough that even very engaged students, students who understand the value of “desirable difficulty,” will use AI for the sake of their GPA, their time, and their stress levels.</p><p><span>This corner cutting doesn’t seem to be confined to core classes students have to slog through on their way to their major. At AWP this spring, I attended a panel on fending off AI in the creative writing classroom. Even students who </span><em>should</em><span> be on the side of Batman (above) may turn to AI when they’ve fallen behind and have a workshop story due. Sad, because some of our best thinking and writing and storytelling often happens when racing to make a deadline! The takeaway from the panel was: less focus on the product and more on process.</span></p><p>From my own anecdotal experience teaching English over the last two years, particularly first-year composition classes, I can confirm the in-roads genAI has made with American college students. I’ve seen it happen in real time. My first semester I caught one, very tech-minded student using ChatGPT for an assignment. My second semester I caught a couple more. Last fall, I sent back rhetorical analysis papers from a full quarter of my class for obvious (and erroneous) AI usage.</p><p><span>At this point, it wasn’t just the comp-sci or business majors or the generally disengaged. That quarter last fall included one of my most engaged students, who had ChatGPT analyze, of all things, one of </span><a href="https://www.newyorker.com/culture/the-weekend-essay/why-ai-isnt-going-to-make-art" rel="">Ted Chiang’s </a><em><a href="https://www.newyorker.com/culture/the-weekend-essay/why-ai-isnt-going-to-make-art" rel="">New Yorker </a></em><a href="https://www.newyorker.com/culture/the-weekend-essay/why-ai-isnt-going-to-make-art" rel="">essays</a><span> on AI. Her mistake was forgetting to include the byline when she copy-pasted into ChatGPT, and so the bot helpfully filled in the author as Jonathan Franzen. Most of the time when I catch students using the homework machine, it’s because of “user error” like this. I’ve had students use AI to write event reports, and then turn the reports in before the event actually took place. I’ve had students submit end-of-course reflections in which they talk about projects we didn’t do or gush about how I’d become “not just a teacher but a mentor” when I’d never once seen them at office hours.</span></p><p><span>Without such user error, it’s getting hard to point to AI prose with any kind of probable cause. Sometimes I spot two assignments using the same not-quite-right phrase or characterization, or the quotes or citations are sus. Otherwise, often I sense that something isn’t quite right, but it isn’t enough to call the student out on. And I’m sure there are cases where I </span><em>don’t</em><span> pick up on the AI usage, either because students engaged with the chatbot in a more upstream fashion, or because they used various prompt tricks and prompts to make their text seem more authentic (inserting typos, etc.).</span></p><p>Students are also increasingly aware of this tension. Last fall when I emailed students with suspect papers asking if they used AI (and promising to let them resubmit), they pretty much all fessed up. This past semester I tried the same thing, but those I emailed mostly held firm and denied cheating, knowing, I think, how much of a hassle it would be for me to actually escalate the situation to the level of an academic integrity violation. And it was, so I didn’t.</p><p>So a lot of AI work gets past my bullshit filter. The result is that grading and giving feedback — always a chore for teachers since time immemorial — now feels more adversarial and less collaborative. Which I hate; we should all try to banish cop-mindset from our psyches and pedagogies. It’s not that I’m eager to catch my students cheating, but I earnestly think I’m doing them a disservice when I let them let AI do their writing and thinking for them, as though — to borrow a popular metaphor — they were using a forklift at the gym.</p><p><span>There’s a big difference between having ChatGPT compose your emails because you don’t </span><em>want</em><span> to do it yourself and having AI compose your emails because you </span><em>can’t</em><span> do it yourself.</span></p><p>Folks like Sam Altman have compared ChatGPT to a “calculator for words,” and honestly I don’t think that’s far off (except of course calculators do not make shit up). But the existence of calculators does not mean we want to live in a society where people don’t learn to do basic arithmetic. The same principle should apply here. I want my students to write unassisted because I don’t want to live in a society where people can’t compose a coherent sentence without a bot in the mix.</p><p>Plus, engaging earnestly with bot-written text is mentally deadening, and frankly I do resent when I have to read it. There’s just no there there, especially if what you’re looking for is a human you can have a conversation with. It reminds me of Neal Stephenson’s novel Anathem, in which misbehaving monks are forced to study a collection of subtly incoherent texts as a form of punishment. Sifting through a bunch of potentially bot-written likeness essays comes with a certain paranoia lurking over my shoulder. Which feels poisonous for the whole process of teaching and learning.</p><p>This past semester I tried to make it harder to use AI in my classes, and hopefully, thereby, reduce the poison. Students were asked to compose their work in Google Docs, so I could see they weren’t copy-pasting big chunks of text in. This turned out to be more trouble than it was worth, as, no matter how much I walked them through it in class, I always had to chase some students down to get access their docs, or untangle weird Canvas integrations, etc. And I’m certain some students were prompting ChatGPT in one window and then hand-typing their essay in the other.</p><p>When I first started teaching comp, we were given three options for language to include about AI on our syllabus.</p><ol><li><p>Cited Use: Students were free to query an AI tool and include that language in their assignments, so long as they cited it as one would another source.</p></li><li><p>Guided Use: Students could use AI as directed by me in the classroom.</p></li><li><p>Unauthorized Use: Students were asked not to use AI at all, (even though, the language acknowledged, these tools could “help them complete assignments more efficiently”).</p></li></ol><p><span>For the first year, I went with option #1, figuring it would help me avoid exactly the kind of paranoia described above, and that I could help students learn to avoid the pitfalls that were common in AI writing circa 2023. Exactly zero students cited AI use in their papers. Even when there are licit ways to disclose AI input on their assignments, students prefer to try to pass bot-writing off as their own. Which to my mind means that they believe AI is cheating and turn to these tools specifically </span><em>to </em><span>cheat.</span></p><p>All the while my students have been eager to write about and discuss AI, with very little prompting from me. I wrapped up this past semester with a “Writing to Future” project where students tried out futures thinking techniques and produced foresight artifacts contrasting predicted vs. preferred futures. Several of them came up with projects fretting about futures with ubiquitous AI and yearning for futures in which tech use is more moderated than today.</p><p>I’ve heard these frustrations over and over again from my students. AI is just a new layer on top of the addictive tech stack of phones and screens and social media and Zoom and online educational platforms they’ve spent their whole lives in. Many of them deeply resent that they never had a choice about all this. They get to college and find that their problems with this stuff don’t go away when they are out on their own; in fact the addictive patterns often get worse without family structure keeping them in check.</p><p>These conversations — the pleas from young people caught up by these products and unable to get out — are part of what’s pushed me toward the Butlerian Jihad line of thinking. I think there is a good case to be made for trying to restrict AI use among young people the way we try to restrict smoking, alcohol, gambling, and sex. Those policies are imperfect, but they do steer young people away from behaviors that can disproportionately harm them more than adults and that they don’t yet have the capacity to regulate the way (some) adults can.</p><p><span>There are developmental reasons for such restrictions, and pedagogical ones. But also, it seems like our tech overlords aren’t able to create an LLM “personality” that won’t </span><a href="https://www.wsj.com/tech/ai/meta-ai-chatbots-sex-a25311bf" rel="">generate CSAM or engage minors in sexual role play</a><span> (often using celebrity voices). Which highlights the problem with presenting these technologies not as simply a calculator for words but as a “likeness of the human mind.”</span></p><p><span>Not that adults are necessarily great at managing the negative cognitive impacts of these technologies. This </span><a href="https://www.rollingstone.com/culture/culture-features/ai-spiritual-delusions-destroying-human-relationships-1235330175/" rel="">harrowing article from Rolling Stone</a><span> about “ChatGPT-induced psychosis” points to a growing mental health crisis as users talking to chatbots fall into existential confusion. Which is exactly what I predicted would happen in my years-old story “</span><a href="https://web.archive.org/web/20201030125018/https://thenewaccelerator.com/the-chaperone-by-andrew-dana-hudso/" rel="">The Chaperone</a><span>”:</span></p><blockquote><p>Very rarely she’d have customers who owned up to and defended their feelings. “Who are you to say what can feel and what can’t? Trini has evolved. She’s emerged!”</p><p>“Emerged.” There was a cottage industry of books and forums that sold these lonely men vocabulary like that. They had a whole mythology. The worst charlatans pitched Jan’s customers the notion that sufficiently complex relationships — the power of love! — would make weak AI phase shift to strong. Jan felt sorry for the men who needed such prophecies. Imagine the aching ego it took to believe your chatbot crush could kick off the singularity.</p></blockquote><p><span>Meanwhile cheating with AI is not confined to homework. It’s happening in </span><a href="https://www.eweek.com/news/cluely-ai-cheating-app/" rel="">business</a><span> and </span><a href="https://www.civillitigationbrief.com/2025/05/07/when-cases-relied-upon-in-written-arguments-were-simply-false-wasted-costs-order-made-against-counsel-and-solicitors/" rel="">law</a><span> and </span><a href="https://www.scientificamerican.com/article/chatbots-have-thoroughly-infiltrated-scientific-publishing/" rel="">science</a><span>. This is not just using AI help with dull writing tasks. It’s engaging with reality based on nonexistent citations and caselaw. It’s choosing convenience over fidelity to the truth — perhaps the slipperiest slope of all.</span></p><p>All this points to a need for a new framework for thinking about and addressing the negative cognitive impacts of these products. I haven’t been able to stop thinking about this comparison I saw on discord:</p><blockquote><p>I also think we might be in a place in 20-30 years where AI is like the laudanum/heroin of the late 19th century; everybody loved it, was instantly addicted, and it was so bad we had to invent new kinds of crime and regulation</p></blockquote><p><span>For my part, I’m going to try something new in my classroom next fall: pen and paper. I’m going ask students to keep their devices put away and work their ideas onto the page by hand. Students will turn in hand-written freewrites, take notes on paper, mark up printed out readings, and receive line notes in colored ink — all that old school methodology that </span><em>did</em><span> successfully educate a number of generations before personal computers came along. I’ll have to learn how to read student handwriting (and improve my own!), but I think it’ll be worth it. Any suggestions you have on how to pull this off are most welcome.</span></p><p>This isn’t just about AI, but the way students are distracted by their screens in general. I know how hard they are to resist — as a grad student I’ve been as guilty as anyone of surfing and emailing and texting during class. This past semester was particularly bad on that front. So many were working on other homework in class, watching sports or tiktok, that the broad discussions I try to cultivate often struggled to get off the ground. (For what it’s worth, I received an award for teaching excellence this semester, so I don’t think it was just me failing to engage them effectively.)</p><p>I also I want to give grades more for completion and participation than quality of outputs. We’ll try to get more into the process, and worry less about the product. Banish the cop from my mind and teach as best I can.</p><p>It’s odd, because I was always a student who hated writing by hand. With the exception of a few periods living off the grid, I’ve always been happy to do my creative and professional work on laptops. Cut and paste is an essential tool in my writing process. But I’m excited to push myself to try out the analog methods for a while. And I’m hoping that in doing so I can cultivate a classroom that gives my students a respite from the dark patterns they are bombarded with.</p><p>AI boosters love to say that AI will change everything, and I think in education they may be right — just not in the way I suspect they hope. Beating the likeness bots and the cheating machines will require us to become more present with each other, more humble and careful in our words and choices, and, most of all, more human. But, as with all our great 21st century challenges, I’m hopeful that on the other side of that struggle, we may find a better world.</p><ul><li><p>As mentioned above, I was given a Teaching Excellence Award from ASU’s Graduate Student Government.</p></li><li><p><span>I also took first place in graduate fiction at the 63rd Glendon and Kathryn Swarthout Awards with my story “</span><a href="https://giganotosaurus.org/2023/05/01/any-percent/" rel="">Any Percent</a><span>.”</span></p></li><li><p>And I found out just yesterday that later this summer I will spent a couple weeks in DC and Louisiana as part of the Carbon Removal Justice Fellowship Program put together by the National Wildlife Federation and the Institute for Responsible Carbon Removal at American University.</p></li><li><p><span>I think I linked to this previously, before it was fully cooked, but here’s </span><a href="https://haydensferryreview.com/blog/chris-cleveland-interviews-andrew-dana-hudson" rel="">an interview</a><span> I did last fall for the blog of ASU’s literary journal Hayden’s Ferry Review.</span></p></li></ul><p data-attrs="{&quot;url&quot;:&quot;https://www.solarshades.club/p/dispatch-from-the-trenches-of-the/comments&quot;,&quot;text&quot;:&quot;Leave a comment&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://www.solarshades.club/p/dispatch-from-the-trenches-of-the/comments" rel=""><span>Leave a comment</span></a></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe082d86a-f00e-424a-ac6a-d9af3a02dd44_4032x3024.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe082d86a-f00e-424a-ac6a-d9af3a02dd44_4032x3024.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe082d86a-f00e-424a-ac6a-d9af3a02dd44_4032x3024.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe082d86a-f00e-424a-ac6a-d9af3a02dd44_4032x3024.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe082d86a-f00e-424a-ac6a-d9af3a02dd44_4032x3024.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe082d86a-f00e-424a-ac6a-d9af3a02dd44_4032x3024.jpeg" width="1456" height="1941" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/e082d86a-f00e-424a-ac6a-d9af3a02dd44_4032x3024.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1941,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:4294129,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.solarshades.club/i/162720948?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe082d86a-f00e-424a-ac6a-d9af3a02dd44_4032x3024.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe082d86a-f00e-424a-ac6a-d9af3a02dd44_4032x3024.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe082d86a-f00e-424a-ac6a-d9af3a02dd44_4032x3024.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe082d86a-f00e-424a-ac6a-d9af3a02dd44_4032x3024.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe082d86a-f00e-424a-ac6a-d9af3a02dd44_4032x3024.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>“Turbulent Mountain Waterfall” (1991) by Pat Steir</figcaption></figure></div><p>During a recent visit to the excellent Phoenix Art Museum, along with the Remington piece at the top, I enjoyed seeing this beautiful drip painting by Pat Steir. An image I’m going to hold in my mind as the Arizona heat begins to take hold.</p><p data-attrs="{&quot;url&quot;:&quot;https://www.solarshades.club/p/dispatch-from-the-trenches-of-the?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://www.solarshades.club/p/dispatch-from-the-trenches-of-the?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p></div></article></div><div id="discussion"><h4>Discussion about this post</h4></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Britain's police are restricting speech in worrying ways (127 pts)]]></title>
            <link>https://www.economist.com/britain/2025/05/15/britains-police-are-restricting-speech-in-worrying-ways</link>
            <guid>44100552</guid>
            <pubDate>Mon, 26 May 2025 19:07:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.economist.com/britain/2025/05/15/britains-police-are-restricting-speech-in-worrying-ways">https://www.economist.com/britain/2025/05/15/britains-police-are-restricting-speech-in-worrying-ways</a>, See on <a href="https://news.ycombinator.com/item?id=44100552">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p><time datetime="2025-05-15T11:13:53.772Z"> <!-- -->May 15th 2025</time></p></div><section><p data-component="paragraph"><span data-caps="initial">T</span><small>HE POLICE</small> arrived at Maxie Allen’s door at midday on January 29th. None of the six officers seemed to know much about why they were there, recalls Mr Allen. But they read out a list of charges and searched the house, before arresting him and his partner and taking them to the police station, where they were held for eight hours. The couple’s alleged crime? Disparaging emails and WhatsApp messages about their daughter’s primary school.</p></section><p><h3 id="article-tags">Explore more</h3><nav aria-labelledby="article-tags"><a href="https://www.economist.com/topics/britain" data-analytics="tags:britain"><span>Britain</span></a><a href="https://www.economist.com/topics/world" data-analytics="tags:world"><span>World</span></a><a href="https://www.economist.com/topics/jd-vance" data-analytics="tags:jd_vance"><span>J.D. Vance</span></a></nav></p><p>This article appeared in the Britain section of the print edition under the headline “Amend thyself&nbsp;”</p><div data-test-id="chapterlist" data-tracking-id="content-well-chapter-list"><div><hr data-testid="rule-accent"><div><h3><a href="https://www.economist.com/britain" text="Britain" data-analytics="chapter_list_header:Britain">Britain</a></h3><p><span>May 17th 2025</span></p></div></div><ul><li><a href="https://www.economist.com/britain/2025/05/15/britains-police-are-restricting-speech-in-worrying-ways" id="3b8e917b-6c56-4e5c-86d6-060d5fd2c9e9" data-analytics="article:reports_headline:1" data-test-id="chapterlist-link-0"><span data-testid="right-economist-red-false"><span>→</span></span><span>Britain’s police are restricting speech in worrying ways</span></a></li><li><a href="https://www.economist.com/britain/2025/05/12/britains-experiment-with-liberal-immigration-policies-is-over" id="4d8f9672-f05a-4f88-8e32-8893863eaecf" data-analytics="article:reports_headline:2" data-test-id="chapterlist-link-1"><span data-testid="right-london-5-false"><span>→</span></span><span>Britain’s experiment with liberal immigration policies is over</span></a></li><li><a href="https://www.economist.com/britain/2025/05/15/cheap-petrol-offers-a-small-respite-for-squeezed-households" id="9ebd2d27-c30a-4f4a-b2f2-b8e8aafc70ac" data-analytics="article:reports_headline:3" data-test-id="chapterlist-link-2"><span data-testid="right-london-5-false"><span>→</span></span><span>Cheap petrol offers a small respite for squeezed households</span></a></li><li><a href="https://www.economist.com/britain/2025/05/15/when-levelling-up-comes-to-town" id="dac6a737-edf9-472f-af64-e47b86c4042a" data-analytics="article:reports_headline:4" data-test-id="chapterlist-link-3"><span data-testid="right-london-5-false"><span>→</span></span><span>When levelling-up comes to town</span></a></li><li><a href="https://www.economist.com/britain/2025/05/15/how-to-prevent-drunken-punch-ups" id="56982ded-54c7-491a-a5a9-55e6c8ec19f4" data-analytics="article:reports_headline:5" data-test-id="chapterlist-link-4"><span data-testid="right-london-5-false"><span>→</span></span><span>How to prevent drunken punch-ups</span></a></li><li><a href="https://www.economist.com/britain/2025/05/15/how-to-build-tram-lines-quickly-and-cheaply" id="b84f7498-f319-46b6-9e29-6d2810538cf5" data-analytics="article:reports_headline:6" data-test-id="chapterlist-link-5"><span data-testid="right-london-5-false"><span>→</span></span><span>How to build tram lines quickly and cheaply </span></a></li><li><a href="https://www.economist.com/britain/2025/05/14/a-world-without-nigel-farage" id="57d93844-7ed5-4f52-a821-c46a307b6707" data-analytics="article:reports_headline:7" data-test-id="chapterlist-link-6"><span data-testid="right-london-5-false"><span>→</span></span><span>A world without Nigel Farage&nbsp;</span></a></li></ul></div><div orientation="vertical" data-test-id="vertical"><div orientation="vertical"><figure><img loading="lazy" width="1280" height="1709" decoding="async" data-nimg="1" sizes="300px" srcset="https://www.economist.com/cdn-cgi/image/width=16,quality=80,format=auto/content-assets/images/20250517_DE_EU.jpg 16w, https://www.economist.com/cdn-cgi/image/width=32,quality=80,format=auto/content-assets/images/20250517_DE_EU.jpg 32w, https://www.economist.com/cdn-cgi/image/width=48,quality=80,format=auto/content-assets/images/20250517_DE_EU.jpg 48w, https://www.economist.com/cdn-cgi/image/width=64,quality=80,format=auto/content-assets/images/20250517_DE_EU.jpg 64w, https://www.economist.com/cdn-cgi/image/width=96,quality=80,format=auto/content-assets/images/20250517_DE_EU.jpg 96w, https://www.economist.com/cdn-cgi/image/width=128,quality=80,format=auto/content-assets/images/20250517_DE_EU.jpg 128w, https://www.economist.com/cdn-cgi/image/width=256,quality=80,format=auto/content-assets/images/20250517_DE_EU.jpg 256w, https://www.economist.com/cdn-cgi/image/width=360,quality=80,format=auto/content-assets/images/20250517_DE_EU.jpg 360w, https://www.economist.com/cdn-cgi/image/width=384,quality=80,format=auto/content-assets/images/20250517_DE_EU.jpg 384w, https://www.economist.com/cdn-cgi/image/width=480,quality=80,format=auto/content-assets/images/20250517_DE_EU.jpg 480w, https://www.economist.com/cdn-cgi/image/width=600,quality=80,format=auto/content-assets/images/20250517_DE_EU.jpg 600w, https://www.economist.com/cdn-cgi/image/width=834,quality=80,format=auto/content-assets/images/20250517_DE_EU.jpg 834w, https://www.economist.com/cdn-cgi/image/width=960,quality=80,format=auto/content-assets/images/20250517_DE_EU.jpg 960w, https://www.economist.com/cdn-cgi/image/width=1096,quality=80,format=auto/content-assets/images/20250517_DE_EU.jpg 1096w, https://www.economist.com/cdn-cgi/image/width=1280,quality=80,format=auto/content-assets/images/20250517_DE_EU.jpg 1280w, https://www.economist.com/cdn-cgi/image/width=1424,quality=80,format=auto/content-assets/images/20250517_DE_EU.jpg 1424w" src="https://www.economist.com/cdn-cgi/image/width=1424,quality=80,format=auto/content-assets/images/20250517_DE_EU.jpg"></figure></div><div orientation="vertical"><h3 orientation="vertical">From the May 17th 2025 edition</h3><p orientation="vertical">Discover stories from this section and more in the list of contents</p><p><a href="https://www.economist.com/weeklyedition/2025-05-17" data-analytics="sidebar:weekly_edition"><span data-testid="right-economist-red-true"><span>⇒</span></span><span>Explore the edition</span></a></p></div></div><div><a href="https://s100.copyright.com/AppDispatchServlet?publisherName=economist&amp;publication=economist&amp;title=Britain%E2%80%99s%20police%20are%20restricting%20speech%20in%20worrying%20ways&amp;publicationDate=2025-05-15&amp;contentID=%2Fcontent%2Fu6hndvo01mattrcpmn5ju8d2c54aa2am&amp;type=A&amp;orderBeanReset=TRUE" target="_blank" rel="noreferrer" data-analytics="end_of_article:reuse_this_content"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" data-testid="renew-outline"><path fill="var(--mb-colour-base-chicago-45)" d="M5.1 16.05a8.25 8.25 0 0 1-.825-1.95A7.696 7.696 0 0 1 4 12.05c0-2.233.775-4.133 2.325-5.7C7.875 4.783 9.767 4 12 4h.175l-1.6-1.6 1.4-1.4 4 4-4 4-1.4-1.4 1.6-1.6H12c-1.667 0-3.083.588-4.25 1.763C6.583 8.938 6 10.367 6 12.05c0 .433.05.858.15 1.275.1.417.25.825.45 1.225l-1.5 1.5ZM12.025 23l-4-4 4-4 1.4 1.4-1.6 1.6H12c1.667 0 3.083-.587 4.25-1.762C17.417 15.063 18 13.633 18 11.95c0-.433-.05-.858-.15-1.275-.1-.417-.25-.825-.45-1.225l1.5-1.5c.367.633.642 1.283.825 1.95.183.667.275 1.35.275 2.05 0 2.233-.775 4.133-2.325 5.7C16.125 19.217 14.233 20 12 20h-.175l1.6 1.6-1.4 1.4Z"></path></svg><span>Reuse this content</span></a></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Lossless video compression using Bloom filters (201 pts)]]></title>
            <link>https://github.com/ross39/new_bloom_filter_repo/blob/main/README.md</link>
            <guid>44100179</guid>
            <pubDate>Mon, 26 May 2025 18:32:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/ross39/new_bloom_filter_repo/blob/main/README.md">https://github.com/ross39/new_bloom_filter_repo/blob/main/README.md</a>, See on <a href="https://news.ycombinator.com/item?id=44100179">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <nav aria-label="Global">
            <ul>


                <li>
      

      <div>
          <div>

                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_copilot&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_copilot_link_product_navbar&quot;}" href="https://github.com/features/copilot">
      
      <div>
          <p>
            GitHub Copilot
          </p><p>
        Write better code with AI
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_models&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_models_link_product_navbar&quot;}" href="https://github.com/features/models">
      
      <div>
          <p>
            GitHub Models
              <span>
                New
              </span>
          </p><p>
        Manage and compare prompts
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_advanced_security&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_advanced_security_link_product_navbar&quot;}" href="https://github.com/security/advanced-security">
      
      <div>
          <p>
            GitHub Advanced Security
          </p><p>
        Find and fix vulnerabilities
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;actions&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;actions_link_product_navbar&quot;}" href="https://github.com/features/actions">
      
      <div>
          <p>
            Actions
          </p><p>
        Automate any workflow
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;codespaces&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;codespaces_link_product_navbar&quot;}" href="https://github.com/features/codespaces">
      
      <div>
          <p>
            Codespaces
          </p><p>
        Instant dev environments
      </p></div>

    
</a></li>

                </ul>
              </div>
          <div>

                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;issues&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;issues_link_product_navbar&quot;}" href="https://github.com/features/issues">
      
      <div>
          <p>
            Issues
          </p><p>
        Plan and track work
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;code_review&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;code_review_link_product_navbar&quot;}" href="https://github.com/features/code-review">
      
      <div>
          <p>
            Code Review
          </p><p>
        Manage code changes
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;discussions&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;discussions_link_product_navbar&quot;}" href="https://github.com/features/discussions">
      
      <div>
          <p>
            Discussions
          </p><p>
        Collaborate outside of code
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;code_search&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;code_search_link_product_navbar&quot;}" href="https://github.com/features/code-search">
      
      <div>
          <p>
            Code Search
          </p><p>
        Find more, search less
      </p></div>

    
</a></li>

                </ul>
              </div>
          

      </div>
</li>


                <li>
      

      
</li>


                <li>
      

      <div>
                    <p><span id="resources-explore-heading">Explore</span></p><ul aria-labelledby="resources-explore-heading">
                    <li>
  <a target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;learning_pathways&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;learning_pathways_link_resources_navbar&quot;}" href="https://resources.github.com/learn/pathways">
      Learning Pathways

    
</a></li>

                    <li>
  <a target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;events_amp_webinars&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;events_amp_webinars_link_resources_navbar&quot;}" href="https://resources.github.com/">
      Events &amp; Webinars

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;ebooks_amp_whitepapers&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;ebooks_amp_whitepapers_link_resources_navbar&quot;}" href="https://github.com/resources/whitepapers">
      Ebooks &amp; Whitepapers

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;customer_stories&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;customer_stories_link_resources_navbar&quot;}" href="https://github.com/customer-stories">
      Customer Stories

    
</a></li>

                    <li>
  <a target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;partners&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;partners_link_resources_navbar&quot;}" href="https://partner.github.com/">
      Partners

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;executive_insights&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;executive_insights_link_resources_navbar&quot;}" href="https://github.com/solutions/executive-insights">
      Executive Insights

    
</a></li>

                </ul>
              </div>
</li>


                <li>
      

      <div>
              <div>

                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_sponsors&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_sponsors_link_open_source_navbar&quot;}" href="https://github.com/sponsors">
      
      <div>
          <p>
            GitHub Sponsors
          </p><p>
        Fund open source developers
      </p></div>

    
</a></li>

                </ul>
              </div>
              <div>

                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;the_readme_project&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;the_readme_project_link_open_source_navbar&quot;}" href="https://github.com/readme">
      
      <div>
          <p>
            The ReadME Project
          </p><p>
        GitHub community articles
      </p></div>

    
</a></li>

                </ul>
              </div>
              
          </div>
</li>


                <li>
      

      <div>

                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;enterprise_platform&quot;,&quot;context&quot;:&quot;enterprise&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;enterprise_platform_link_enterprise_navbar&quot;}" href="https://github.com/enterprise">
      
      <div>
          <p>
            Enterprise platform
          </p><p>
        AI-powered developer platform
      </p></div>

    
</a></li>

                </ul>
              </div>
</li>


                <li>
    <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;pricing&quot;,&quot;context&quot;:&quot;global&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;pricing_link_global_navbar&quot;}" href="https://github.com/pricing">Pricing</a>
</li>

            </ul>
          </nav>

        <div>
                


<qbsearch-input data-scope="repo:ross39/new_bloom_filter_repo" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="QLhhtg8mvk9K8AjPJqm9CZwJpLheatDZ32I4BbS9mFwJGYbVbRM2_NtrAZIVRXMVPUu4ZOUlWkJIAI5-gvGbjA" data-max-custom-scopes="10" data-header-redesign-enabled="false" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="ross39/new_bloom_filter_repo" data-current-org="" data-current-owner="ross39" data-logged-in="false" data-copilot-chat-enabled="false" data-nl-search-enabled="false" data-retain-scroll-position="true">
  <div data-modal-dialog-overlay="" data-action="click:qbsearch-input#searchInputContainerClicked">
  <modal-dialog data-action="close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose" data-target="qbsearch-input.searchSuggestionsDialog" role="dialog" id="search-suggestions-dialog" aria-modal="true" aria-labelledby="search-suggestions-dialog-header" data-view-component="true">
      <h2 id="search-suggestions-dialog-header">Search code, repositories, users, issues, pull requests...</h2>
    
</modal-dialog></div>
  
  <div>
    
<dialog-helper>
  <dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="feedback-dialog" aria-modal="true" aria-labelledby="feedback-dialog-title" aria-describedby="feedback-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="feedback-dialog-title">
        Provide feedback
      </h2>
        
    </p>
    
  </div>
      <scrollable-region data-labelled-by="feedback-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>

    <custom-scopes data-target="qbsearch-input.customScopesManager">
    
<dialog-helper>
  <dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="custom-scopes-dialog" aria-modal="true" aria-labelledby="custom-scopes-dialog-title" aria-describedby="custom-scopes-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="custom-scopes-dialog-title">
        Saved searches
      </h2>
        <h2 id="custom-scopes-dialog-description">Use saved searches to filter your results more quickly</h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="custom-scopes-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>
    </custom-scopes>
  </div>
</qbsearch-input>


            

              <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fblob%2Fshow&amp;source=header-repo&amp;source_repo=ross39%2Fnew_bloom_filter_repo" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/ross39/new_bloom_filter_repo/blob/main/README.md&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="cfbe2d70c281841f7a9367b215371ab5dad78485b9a34efd72a64d32fdf465f2" data-analytics-event="{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/<user-name>/<repo-name>/blob/show;ref_cta:Sign up;ref_loc:header logged out&quot;}">
                Sign up
              </a></p><p>
    <react-partial-anchor>
      <tool-tip id="tooltip-0f7c810a-b219-4651-ac30-d5b44288f6cd" for="icon-button-1a8335b2-fd36-49a1-948f-2c49b12b404f" popover="manual" data-direction="s" data-type="label" data-view-component="true">Appearance settings</tool-tip>

      <template data-target="react-partial-anchor.template">
        <link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/primer-react.19291721a114332ad118.module.css">
<link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/appearance-settings.22dfbc22ef0a2bf02523.module.css">

<react-partial partial-name="appearance-settings" data-ssr="false" data-attempted-ssr="false">
  
  <script type="application/json" data-target="react-partial.embeddedData">{"props":{}}</script>
  <div data-target="react-partial.reactRoot"></div>
</react-partial>

      </template>
    </react-partial-anchor>
  </p>

          </div>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[CSS Minecraft (453 pts)]]></title>
            <link>https://benjaminaster.com/css-minecraft/</link>
            <guid>44100148</guid>
            <pubDate>Mon, 26 May 2025 18:28:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://benjaminaster.com/css-minecraft/">https://benjaminaster.com/css-minecraft/</a>, See on <a href="https://news.ycombinator.com/item?id=44100148">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<p><strong>There is no JavaScript on this page.</strong> All the logic is made 100% with pure HTML &amp; CSS. For the best performance, please close other tabs and running programs.<br>
View on <a href="https://github.com/BenjaminAster/CSS-Minecraft">GitHub</a>, <a href="https://codepen.io/Benjamin_Aster/pen/gOKwpOd">CodePen</a>, <a href="https://benjaminaster.com/css-minecraft/">benjaminaster.com</a></p>
<p>⚠︎ Your browser does not support the <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/:has">CSS <code>:has()</code> pseudo-class</a>, which is needed for this site to work.
Please update it: Chromium version ≥ 105, Safari version ≥ 15.4 or Firefox version ≥ 121 is required.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Claude 4 and GitHub MCP will leak your private GitHub repositories (229 pts)]]></title>
            <link>https://twitter.com/lbeurerkellner/status/1926991491735429514</link>
            <guid>44100082</guid>
            <pubDate>Mon, 26 May 2025 18:20:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/lbeurerkellner/status/1926991491735429514">https://twitter.com/lbeurerkellner/status/1926991491735429514</a>, See on <a href="https://news.ycombinator.com/item?id=44100082">Hacker News</a></p>
Couldn't get https://twitter.com/lbeurerkellner/status/1926991491735429514: Error: Request failed with status code 400]]></description>
        </item>
        <item>
            <title><![CDATA[Duolingo CEO tries to walk back AI-first comments, fails (372 pts)]]></title>
            <link>https://htxt.co.za/2025/05/duolingo-ceo-tries-to-walk-back-ai-first-comments-fails/</link>
            <guid>44100035</guid>
            <pubDate>Mon, 26 May 2025 18:14:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://htxt.co.za/2025/05/duolingo-ceo-tries-to-walk-back-ai-first-comments-fails/">https://htxt.co.za/2025/05/duolingo-ceo-tries-to-walk-back-ai-first-comments-fails/</a>, See on <a href="https://news.ycombinator.com/item?id=44100035">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-id="117b548" data-element_type="widget" data-widget_type="theme-post-content.default">
					
<ul>
<li><strong>Following backlash to statements that Duolingo will be AI-first, threatening jobs in the process, CEO Luis von Ahn has tried to walk back his statement.</strong></li>



<li><strong>Unfortunately, the CEO doesn’t walk back any of the key points he originally outlined, choosing instead to try, and fail to placate the maddening crowd.</strong></li>



<li><strong>Unfortunately the PR team may soon be replaced by AI as this latest statement has done anything but instil confidence in the firm’s users.</strong></li>
</ul>



<p>About a month ago, <a href="https://htxt.co.za/2025/04/duolingo-kicks-contractors-out-the-door-while-chasing-the-shadow-of-ai/" target="_blank" rel="noreferrer noopener">Duolingo decided that it would gradually fire all contractors</a> and instead, use AI in a bid to become an AI-first company. Beyond firing contractors, Duolingo planned to make AI a requirement for every aspect of its business. Now Luis von Ahn is trying to do damage control, and failing.</p>



<p>The billionaire <a href="https://www.linkedin.com/posts/luis-von-ahn-duolingo_one-of-the-most-important-things-leaders-activity-7331386411670982658-jpfX?utm_source=share&amp;utm_medium=member_desktop&amp;rcm=ACoAACMhBZgBJoR2yKMoR7v1PnwsuFca7PYkms0" target="_blank" rel="noreferrer noopener">took to LinkedIn last week</a> to admit that he wasn’t clear in his AI memo, a memo that sent users into a frenzy, swearing off the app, cancelling premium subscriptions and a once-beloved brand being dragged through the mud.</p>



<p>“I don’t know exactly what’s going to happen with AI, but I do know it’s going to fundamentally change the way we work, and we have to get ahead of it,” admits the man who just a few weeks ago crowed about how vital AI was to Duolingo’s business.</p>



<p>“AI is creating uncertainty for all of us, and we can respond to this with fear or curiosity. I’ve always encouraged our team to embrace new technology (that’s why we originally built for mobile instead of desktop), and we are taking that same approach with AI. By understanding the capabilities and limitations of AI now, we can stay ahead of it and remain in control of our own product and our mission,” writes von Ahn.</p>



<p>Except that’s not at all what you said last month is it Luis? You said that AI was needed to understand your codebase and that without AI, it’d be impossible to scale the platform. In fact, you went so far as to say that despite AI not being “100 percent perfect” it was vital that Duolingo leap headfirst into the space.</p>



<p>The CEO then also says that Duolingo isn’t looking to replace employees with AI, despite explicitly saying as much about contractors. The key here is that, in the eyes of Duolingo and most Silicon Valley powerhouses (we’re looking at you Uber) hiring contractors is a way to avoid the requirements that go along with having employees. </p>



<p>“My goal is for Duos [employees] to feel empowered and prepared to use this technology. No one is expected to navigate this shift alone. We’re developing workshops and advisory councils, and carving out dedicated experimentation time to help all our teams learn and adapt,” wrote von Ahn.</p>



<p>Below his LinkedIn post you will find all the sycophantic praise you might expect from the mix of wealthy and bot users on the platform. It’s all very gross and only serves to highlight just how out of touch the wealthy are with regular people.</p>



<p>The Duolingo CEO’s latest post does nothing to reverse the statement made a month ago. The CEO didn’t backtrack the statement that AI would form part of whether a candidate is worth hiring or not. He also didn’t backtrack the statement that headcount will only increase if a team can no longer automate anymore of their work.</p>



<p>Essentially then, this was a nothing statement from von Ahn that we suspect Duolingo’s PR issued as a sort of damage control. Unfortunately, that team may soon be replaced by AI because it isn’t going well. To their credit, it didn’t help that von Ahn made a frankly stupid comment about machines being able to teach a person anything another human could. Already being dragged by the public, this backtracking just added more fuel to the fire.</p>



<figure><figcaption><em>The comments are confusing and upsetting.</em></figcaption></figure>



<figure><figcaption><em>Not von Ahn clearly.</em></figcaption></figure>



<p>Some have taken this latest sign that Duolingo is backtracking its suggestion of being AI first but there’s no language in the statement to suggest that and key statements made last month weren’t walked back at all.</p>



<p>Unfortunately, Silicon Valley isn’t listening to the masses. They are investing heavily in tech on the basis that it can replace workers and make them more money without a second thought. Unfortunately for Duolingo, its customer base is largely consumer-facing and if there is one thing consumers hate more than a scam, it’s injustice and this trend with AI seems to combine both.</p>



<p>We doubt public pressure will actually change what happens at Duolingo. We suspect that if anything, it will simply mean von Ahn stops making public statements unless that aren’t heavily sanitised by the legal and PR department.</p>
				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[TSMC bets on unorthodox optical tech (134 pts)]]></title>
            <link>https://spectrum.ieee.org/microled-optical-chiplet</link>
            <guid>44099407</guid>
            <pubDate>Mon, 26 May 2025 17:15:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://spectrum.ieee.org/microled-optical-chiplet">https://spectrum.ieee.org/microled-optical-chiplet</a>, See on <a href="https://news.ycombinator.com/item?id=44099407">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-headline="TSMC Bets On Unorthodox Optical Tech"><p>In the race to an <a href="https://spectrum.ieee.org/optics-gpu" target="_self"><span>all-optical</span></a> AI data center, a major player has now placed a bet on a different horse. <a href="https://spectrum.ieee.org/tag/semiconductor-manufacturing">Semiconductor manufacturing</a> giant <a href="https://www.businesswire.com/news/home/20250422988144/en/Avicena-Works-with-TSMC-to-Enable-PD-Arrays-for-LightBundle-MicroLED-Based-Interconnects" target="_blank"><span>TSMC announced</span></a> that it will work with Sunnyvale startup <a href="https://avicena.tech/" target="_blank"><span>Avicena</span></a> to produce microLED-based <a href="https://spectrum.ieee.org/tag/interconnects">interconnects</a>. The technology is a pragmatic twist on replacing electrical connections with optical ones to meet the high needs of communication among an increasing number of <a href="https://spectrum.ieee.org/tag/gpus">GPUs</a> in a low cost, energy efficient way. <strong></strong></p><p>Thanks to the computational demands of <a href="https://spectrum.ieee.org/tag/large-language-models">large language models</a> and their cousins, AI clusters are facing unprecedented requirements regarding amounts of data, bandwidth, latency, and speed. Sooner or later, the <a href="https://spectrum.ieee.org/tag/copper-wires">copper wires</a> that connect <a href="https://spectrum.ieee.org/tag/processors">processors</a> and memory within a single AI data center rack will have to be <a href="https://spectrum.ieee.org/optical-interconnects" target="_self"><span>replaced with optics</span></a>. “There’s a huge push to get optical connections as close to the board as possible,” says Lucas Tsai, a vice president at <a href="https://spectrum.ieee.org/tag/tsmc">TSMC</a>.</p><p>Avicena offers a unique approach, using hundreds of blue <a href="https://spectrum.ieee.org/tag/microleds">microLEDs</a> connected through imaging-type fibers to move data. The company’s modular <a href="https://avicena.tech/avicena-announces-modular-lightbundle-optical-interconnect-platform-with-1tbps-mm-i-o-density-and-1pj-bit/" target="_blank"><span>LightBundle platform</span></a> avoids problems with <a href="https://spectrum.ieee.org/tag/lasers">lasers</a> and their associated complexity that threaten the reliability, cost, and power consumption of other optical <a href="https://spectrum.ieee.org/tag/chiplets">chiplets</a>. Tsai says “it’s very unorthodox!” But it is ideal for these short distance applications, and that’s precisely what makes it interesting.</p><h2>Laser-free</h2><p>Optical connections today carry vast amounts of data tens to hundreds of meters across <a href="https://spectrum.ieee.org/tag/data-centers">data centers</a> at very high <a href="https://spectrum.ieee.org/tag/data-rates">data rates</a>. Traditionally, a pluggable module connects the <a href="https://spectrum.ieee.org/tag/optical-fiber">optical fiber</a> to the rack, where it converts between electrical and optical signals. Companies are making strides toward getting rid of these energy inefficient pluggable <a href="https://spectrum.ieee.org/tag/transceivers">transceivers</a> using co-packaged <a href="https://spectrum.ieee.org/tag/optics">optics</a> (CPO), which instead perform electrical-optical transformations adjacent to the silicon chip itself. Commercial versions exist for the <a href="https://spectrum.ieee.org/co-packaged-optics" target="_self"><span>network switch</span></a>, and prototypes are making strides <a href="https://spectrum.ieee.org/optical-interconnects" target="_self"><span>toward the GPU</span></a>. The most prominent optical chiplet designs encode electronic bits onto multiple wavelengths of light using lasers and modulators.</p><p>However, the main challenge for laser-based <a href="https://spectrum.ieee.org/tag/optical-interconnects">optical interconnects</a> is the laser itself. The laser and fiber attachments have caused the biggest problems in terms of reliability, manufacturing, and cost. Moreover, a single optical fiber that hosts dozens of GPU-to-switch links in the form of multiple wavelengths suffers from computational overhead: it’s far simpler to pipe each data lane down a separate physical channel than to electronically parse one big channel later on. <strong></strong></p><p>That’s where <a href="https://spectrum.ieee.org/photonics-and-ai" target="_self"><span>Avicena comes in</span></a>. Instead of sending a multi-wavelength laser down an optical fiber and then parsing it into individual channels, the LightBundle interconnect links hundreds of blue microLEDs to a <a href="https://spectrum.ieee.org/tag/photodetector">photodetector</a> array via multi-core imaging fibers—one for each 10 GB/s data lane. The transmitter acts like a miniature display screen and the detector like a camera. “We’re doing optical interconnects without the complexity of lasers,” says Avicena CEO Bardia Pezeshki.</p><p>A simple optical link with just 300 pixels at 10Gb/s per lane can extend over a 10m distance, carrying a net total of 3 Tb/s. Since displays and <a href="https://spectrum.ieee.org/tag/cameras">cameras</a> can scale to millions of pixels, the technology can scale to much higher data rates at much lower energy and much higher density than copper wiring. </p><h2>Mature industry</h2><p>One major advantage touted by Avicena is that their technology harnesses <a href="https://spectrum.ieee.org/tag/leds">LEDs</a>, cameras, and displays: all mature industries. “We can scale our approach to the volumes and costs required much more rapidly than if we were developing new building blocks,” says Pezeshki. Even though <a href="https://spectrum.ieee.org/tag/silicon-photonics">silicon photonics</a> has a thirty-year head start on optical interconnects, they have to develop new components like ring <a href="https://spectrum.ieee.org/tag/resonators">resonators</a> and comb lasers. “It takes a lot of time for these things to mature,” he says. In contrast, the LightBundle interconnects design requires only minor modifications to existing camera and display technologies.</p><p>That’s one main reason that TSMC signed up to produce the photodetector arrays for Avicena’s optical chiplets. “LEDs is a mature industry already, there are a lot of consumer products,” Tsai says. LEDs are of course lower power than lasers—but for, say, 10-meter distances within and across a rack, that’s enough. “There’s a potential that it will be a lot cheaper, and by nature you have a lot of redundancy,” says Tsai.</p><p>Avicena’s results are already “blowing away” what silicon <a href="https://spectrum.ieee.org/tag/photonics">photonics</a> can do, according to Pezeshki. The LightBundle prototype has already demonstrated sub-pJ/bit energy use for the whole link, where other optical approaches “are struggling to show” 5 pJ/bit energy consumption. <strong></strong></p><p>Pezeshki acknowledges that Avicena has a ways to go to build and scale the product. But “the combination of showing great results together with using mature building blocks is winning over converts,” he says.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: PgDog – Shard Postgres without extensions (185 pts)]]></title>
            <link>https://github.com/pgdogdev/pgdog</link>
            <guid>44099187</guid>
            <pubDate>Mon, 26 May 2025 16:55:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/pgdogdev/pgdog">https://github.com/pgdogdev/pgdog</a>, See on <a href="https://news.ycombinator.com/item?id=44099187">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto">
    <a target="_blank" rel="noopener noreferrer" href="https://github.com/pgdogdev/pgdog/blob/main/.github/logo2-white.png"><img src="https://github.com/pgdogdev/pgdog/raw/main/.github/logo2-white.png" height="128" width="auto"></a>
</p>
<p dir="auto"><a href="https://github.com/levkk/pgdog/actions/workflows/ci.yml"><img src="https://github.com/levkk/pgdog/actions/workflows/ci.yml/badge.svg" alt="CI"></a></p>
<p dir="auto">PgDog is a transaction pooler and logical replication manager that can shard PostgreSQL. Written in Rust, PgDog is fast, secure and can manage hundreds of databases and hundreds of thousands of connections.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Documentation</h2><a id="user-content-documentation" aria-label="Permalink: Documentation" href="#documentation"></a></p>
<p dir="auto">📘 PgDog documentation can be <strong><a href="https://docs.pgdog.dev/" rel="nofollow">found here</a></strong>. Any questions? Join our <strong><a href="https://discord.com/invite/CcBZkjSJdd" rel="nofollow">Discord</a></strong>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Quick start</h2><a id="user-content-quick-start" aria-label="Permalink: Quick start" href="#quick-start"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Kubernetes</h3><a id="user-content-kubernetes" aria-label="Permalink: Kubernetes" href="#kubernetes"></a></p>
<p dir="auto">Helm chart is <strong><a href="https://github.com/pgdogdev/helm">here</a></strong>. To install it, run:</p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/pgdogdev/helm &amp;&amp; \
cd helm &amp;&amp; \
helm install -f values.yaml pgdog ./"><pre>git clone https://github.com/pgdogdev/helm <span>&amp;&amp;</span> \
<span>cd</span> helm <span>&amp;&amp;</span> \
helm install -f values.yaml pgdog ./</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Docker</h3><a id="user-content-docker" aria-label="Permalink: Docker" href="#docker"></a></p>
<p dir="auto">You can try PgDog quickly using Docker. Install <a href="https://docs.docker.com/compose/" rel="nofollow">Docker Compose</a> and run:</p>

<p dir="auto">It will take a few minutes to build PgDog from source and launch the containers. Once started, you can connect to PgDog with psql (or any other PostgreSQL client):</p>
<div data-snippet-clipboard-copy-content="PGPASSWORD=postgres psql -h 127.0.0.1 -p 6432 -U postgres"><pre><code>PGPASSWORD=postgres psql -h 127.0.0.1 -p 6432 -U postgres
</code></pre></div>
<p dir="auto">The demo comes with 3 shards and 2 sharded tables:</p>
<div dir="auto" data-snippet-clipboard-copy-content="INSERT INTO users (id, email) VALUES (1, 'admin@acme.com');
INSERT INTO payments (id, user_id, amount) VALUES (1, 1, 100.0);

SELECT * FROM users WHERE id = 1;
SELECT * FROM payments WHERE user_id = 1;"><pre><span>INSERT INTO</span> users (id, email) <span>VALUES</span> (<span>1</span>, <span><span>'</span>admin@acme.com<span>'</span></span>);
<span>INSERT INTO</span> payments (id, user_id, amount) <span>VALUES</span> (<span>1</span>, <span>1</span>, <span>100</span>.<span>0</span>);

<span>SELECT</span> <span>*</span> <span>FROM</span> users <span>WHERE</span> id <span>=</span> <span>1</span>;
<span>SELECT</span> <span>*</span> <span>FROM</span> payments <span>WHERE</span> user_id <span>=</span> <span>1</span>;</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Monitoring</h3><a id="user-content-monitoring" aria-label="Permalink: Monitoring" href="#monitoring"></a></p>
<p dir="auto">PgDog exposes both the standard PgBouncer-style admin database and an OpenMetrics endpoint. The admin database isn't 100% compatible,
so we recommend you use OpenMetrics for monitoring. Example Datadog configuration and dashboard are <a href="https://github.com/pgdogdev/pgdog/blob/main/examples/datadog">included</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Load balancer</h3><a id="user-content-load-balancer" aria-label="Permalink: Load balancer" href="#load-balancer"></a></p>
<p dir="auto">PgDog is an application layer (OSI Level 7) load balancer for PostgreSQL. It can proxy multiple replicas (and primary) and distribute transactions evenly between databases. It supports multiple strategies, including round robin, random, least active connections, etc. PgDog can also inspect queries and send <code>SELECT</code> queries to replicas, and all others to the primary. This allows to proxy all databases behind a single PgDog deployment.</p>
<p dir="auto">📘 <strong><a href="https://docs.pgdog.dev/features/load-balancer" rel="nofollow">Load balancer</a></strong></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Healthchecks and failover</h4><a id="user-content-healthchecks-and-failover" aria-label="Permalink: Healthchecks and failover" href="#healthchecks-and-failover"></a></p>
<p dir="auto">PgDog maintains a real-time list of healthy hosts. When a host fails a healthcheck, it's removed from active rotation and queries are rerouted to other databases. This is similar to HTTP load balancing, except it's at the database layer.</p>
<p dir="auto">Failover maximizes database availability and protects against bad network connections, temporary hardware failures or misconfiguration.</p>
<p dir="auto">📘 <strong><a href="https://docs.pgdog.dev/features/healthchecks" rel="nofollow">Healthchecks</a></strong></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Transaction pooling</h3><a id="user-content-transaction-pooling" aria-label="Permalink: Transaction pooling" href="#transaction-pooling"></a></p>
<p dir="auto">Like PgBouncer, PgDog supports transaction (and session) pooling, allowing
100,000s of clients to use just a few PostgreSQL server connections.</p>
<p dir="auto">📘 <strong><a href="https://docs.pgdog.dev/features/transaction-mode" rel="nofollow">Transactions</a></strong></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Sharding</h3><a id="user-content-sharding" aria-label="Permalink: Sharding" href="#sharding"></a></p>
<p dir="auto">PgDog is able to handle databases with multiple shards by routing queries automatically to one or more shards. Using the native PostgreSQL parser, PgDog understands queries, extracts sharding keys and determines the best routing strategy. For cross-shard queries, PgDog assembles results in memory and sends them all to the client transparently.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Using <code>COPY</code></h4><a id="user-content-using-copy" aria-label="Permalink: Using COPY" href="#using-copy"></a></p>
<p dir="auto">PgDog comes with a CSV parser and can split COPY commands between all shards automatically. This allows clients to ingest data into sharded PostgreSQL without preprocessing.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Logical replication</h4><a id="user-content-logical-replication" aria-label="Permalink: Logical replication" href="#logical-replication"></a></p>
<p dir="auto">PgDog understands the PostgreSQL logical replication protocol and can split data between databases in the background and without downtime. This allows to shard existing databases and add more shards to existing clusters in production, without impacting database operations.</p>
<p dir="auto">📘 <strong><a href="https://docs.pgdog.dev/features/sharding/" rel="nofollow">Sharding</a></strong></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Configuration</h3><a id="user-content-configuration" aria-label="Permalink: Configuration" href="#configuration"></a></p>
<p dir="auto">PgDog is highly configurable and many aspects of its operation can be tweaked at runtime, without having
to restart the process and break PostgreSQL connections. If you've used PgBouncer (or PgCat) before, the options
will be familiar. If not, they are documented with examples.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">📘 <strong><a href="https://docs.pgdog.dev/configuration/" rel="nofollow">Configuration</a></strong></h2><a id="user-content--configuration" aria-label="Permalink: 📘 Configuration" href="#-configuration"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Running PgDog locally</h2><a id="user-content-running-pgdog-locally" aria-label="Permalink: Running PgDog locally" href="#running-pgdog-locally"></a></p>
<p dir="auto">Install the latest version of the Rust compiler from <a href="https://rust-lang.org/" rel="nofollow">rust-lang.org</a>.
Clone this repository and build the project in release mode:</p>

<p dir="auto">It's important to use the release profile if you're deploying to production or want to run
performance benchmarks.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Configuration</h3><a id="user-content-configuration-1" aria-label="Permalink: Configuration" href="#configuration-1"></a></p>
<p dir="auto">PgDog has two configuration files:</p>
<ul dir="auto">
<li><code>pgdog.toml</code> which contains general settings and PostgreSQL servers information</li>
<li><code>users.toml</code> for users and passwords</li>
</ul>
<p dir="auto">Most options have reasonable defaults, so a basic configuration for a single user
and database running on the same machine is pretty short:</p>
<p dir="auto"><strong><code>pgdog.toml</code></strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="[general]
host = &quot;0.0.0.0&quot;
port = 6432

[[databases]]
name = &quot;pgdog&quot;
host = &quot;127.0.0.1&quot;"><pre>[<span>general</span>]
<span>host</span> = <span><span>"</span>0.0.0.0<span>"</span></span>
<span>port</span> = <span>6432</span>

[[<span>databases</span>]]
<span>name</span> = <span><span>"</span>pgdog<span>"</span></span>
<span>host</span> = <span><span>"</span>127.0.0.1<span>"</span></span></pre></div>
<p dir="auto"><strong><code>users.toml</code></strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="[[users]]
name = &quot;pgdog&quot;
password = &quot;pgdog&quot;
database = &quot;pgdog&quot;"><pre>[[<span>users</span>]]
<span>name</span> = <span><span>"</span>pgdog<span>"</span></span>
<span>password</span> = <span><span>"</span>pgdog<span>"</span></span>
<span>database</span> = <span><span>"</span>pgdog<span>"</span></span></pre></div>
<p dir="auto">If you'd like to try this out, you can set it up like so:</p>
<div data-snippet-clipboard-copy-content="CREATE DATABASE pgdog;
CREATE USER pgdog PASSWORD 'pgdog' LOGIN;"><pre lang="postgresql"><code>CREATE DATABASE pgdog;
CREATE USER pgdog PASSWORD 'pgdog' LOGIN;
</code></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Try sharding</h4><a id="user-content-try-sharding" aria-label="Permalink: Try sharding" href="#try-sharding"></a></p>
<p dir="auto">The configuration files for a sharded database are provided in the repository. To make it work locally, create the required databases:</p>
<div data-snippet-clipboard-copy-content="CREATE DATABASE shard_0;
CREATE DATABASE shard_1;

GRANT ALL ON DATABASE shard_0 TO pgdog;
GRANT ALL ON DATABASE shard_1 TO pgdog;"><pre lang="postgresql"><code>CREATE DATABASE shard_0;
CREATE DATABASE shard_1;

GRANT ALL ON DATABASE shard_0 TO pgdog;
GRANT ALL ON DATABASE shard_1 TO pgdog;
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Start PgDog</h3><a id="user-content-start-pgdog" aria-label="Permalink: Start PgDog" href="#start-pgdog"></a></p>
<p dir="auto">Running PgDog can be done with Cargo:</p>

<p dir="auto">You can connect to PgDog with psql or any other PostgreSQL client:</p>
<div dir="auto" data-snippet-clipboard-copy-content="psql postgres://pgdog:pgdog@127.0.0.1:6432/pgdog"><pre>psql postgres://pgdog:pgdog@127.0.0.1:6432/pgdog</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">🚦 Status 🚦</h2><a id="user-content--status-" aria-label="Permalink: 🚦 Status 🚦" href="#-status-"></a></p>
<p dir="auto">This project is just getting started and early adopters are welcome to try PgDog internally. Status on features stability will be <a href="https://docs.pgdog.dev/features/" rel="nofollow">updated regularly</a>. Most features have tests and are benchmarked regularly for performance regressions.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Performance</h2><a id="user-content-performance" aria-label="Permalink: Performance" href="#performance"></a></p>
<p dir="auto">PgDog does its best to minimize its impact on overall database performance. Using Rust and Tokio is a great start for a fast network proxy, but additional care is also taken to perform as few operations as possible while moving data between client and server sockets. Some benchmarks are provided to help set a baseline.</p>
<p dir="auto">📘 <strong><a href="https://docs.pgdog.dev/architecture/" rel="nofollow">Architecture &amp; benchmarks</a></strong></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">PgDog is free and open source software, licensed under the AGPL v3. While often misunderstood, this license is very permissive
and allows the following without any additional requirements from you or your organization:</p>
<ul dir="auto">
<li>Internal use</li>
<li>Private modifications for internal use without sharing any source code</li>
</ul>
<p dir="auto">You can freely use PgDog to power your PostgreSQL databases without having to
share any source code, including proprietary work product or any PgDog modifications you make.</p>
<p dir="auto">AGPL was written specifically for organizations that offer PgDog <em>as a public service</em> (e.g. database cloud providers) and require
those organizations to share any modifications they make to PgDog, including new features and bug fixes.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributions</h2><a id="user-content-contributions" aria-label="Permalink: Contributions" href="#contributions"></a></p>
<p dir="auto">Please read our <a href="https://github.com/pgdogdev/pgdog/blob/main/CONTRIBUTING.md">Contribution Guidelines</a>.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[TeleMessage Customers Include DC Police, Andreessen Horowitz, JP Morgan,Hundreds (174 pts)]]></title>
            <link>https://micahflee.com/telemessage-customers-include-dc-police-andreesen-horowitz-jp-morgan-and-hundreds-more/</link>
            <guid>44099096</guid>
            <pubDate>Mon, 26 May 2025 16:47:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://micahflee.com/telemessage-customers-include-dc-police-andreesen-horowitz-jp-morgan-and-hundreds-more/">https://micahflee.com/telemessage-customers-include-dc-police-andreesen-horowitz-jp-morgan-and-hundreds-more/</a>, See on <a href="https://news.ycombinator.com/item?id=44099096">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <article>
                    <header>
                        
                            <figure>
        <img srcset="https://micahflee.com/content/images/size/w300/2025/05/Screenshot-2025-05-19-at-11.37.12-PM-1.png 300w,
                    https://micahflee.com/content/images/size/w720/2025/05/Screenshot-2025-05-19-at-11.37.12-PM-1.png 720w,
                    https://micahflee.com/content/images/size/w960/2025/05/Screenshot-2025-05-19-at-11.37.12-PM-1.png 960w,
                    https://micahflee.com/content/images/size/w1200/2025/05/Screenshot-2025-05-19-at-11.37.12-PM-1.png 1200w,
                    https://micahflee.com/content/images/size/w2000/2025/05/Screenshot-2025-05-19-at-11.37.12-PM-1.png 2000w,
                    https://micahflee.com/content/images/2025/05/Screenshot-2025-05-19-at-11.37.12-PM-1.png" sizes="(max-width: 1200px) 100vw, 1200px" src="https://micahflee.com/content/images/size/w1200/2025/05/Screenshot-2025-05-19-at-11.37.12-PM-1.png" alt="TeleMessage customers include DC Police, Andreessen Horowitz, JP Morgan, and hundreds more">
            <figcaption><span>"We are clean on OPSEC" sticker, with a drunk U.S. Secretary of Defense Pete Hegseth</span></figcaption>
    </figure>
                    </header>

                <section>
                    <p>I've been digging through the <a href="https://micahflee.com/ddosecrets-publishes-410-gb-of-heap-dumps-hacked-from-telemessages-archive-server/" rel="noreferrer">410 GB of Java heap dumps</a> from TeleMessage's archive server,  <a href="https://ddosecrets.com/article/telemessage" rel="noreferrer">provided</a> by DDoSecrets. Here's a description of the dataset, some of my initial findings, details about an upcoming open source research tool I'm going to release, and a huge list of potential TeleMessage customers.</p><p>First, some background. This "clean OPSEC" saga is <em>unbelievable</em>.</p><p>Mike Waltz <a href="https://web.archive.org/web/20250325174744/https://www.theatlantic.com/politics/archive/2025/03/trump-administration-accidentally-texted-me-its-war-plans/682151/" rel="noreferrer">invited</a> a journalist into a Signal group full of high-level Trumpers where they discussed and executed <a href="https://zeteo.com/p/signal-chat-war-crimes-revealed-yemen-trump-admin" rel="noreferrer">bombing</a> an apartment building full of innocent people. This led to Congressional <a href="https://www.pbs.org/newshour/politics/watch-ratcliffe-gabbard-patel-testify-to-senate-after-war-plans-revealed-to-journalist-in-chat" rel="noreferrer">hearings</a> (about using a Signal group for war, not the war crimes themselves... Congress doesn't really care about those).</p><p>Later, Waltz was photographed using TeleMessage SGNL, an Israeli-made knockoff of Signal that archives messages for its customers, and that <a href="https://micahflee.com/despite-misleading-marketing-israeli-company-telemessage-used-by-trump-officials-can-access-plaintext-chat-logs/" rel="noreferrer">lied</a> about supporting end-to-end encryption. Then TeleMessage was <a href="https://micahflee.com/despite-misleading-marketing-israeli-company-telemessage-used-by-trump-officials-can-access-plaintext-chat-logs/" rel="noreferrer">hacked</a>, <a href="https://www.nbcnews.com/tech/security/telemessage-suspends-services-hackers-say-breached-app-rcna204925" rel="noreferrer">twice</a>. The <a href="https://micahflee.com/how-the-knock-off-signal-app-used-by-trump-officials-got-hacked-in-20-minutes/" rel="noreferrer">trivial vulnerability</a> let anyone on the internet download Java heap dumps from the server. Then, DDoSecrets <a href="https://micahflee.com/ddosecrets-publishes-410-gb-of-heap-dumps-hacked-from-telemessages-archive-server/" rel="noreferrer">released</a> 410 GB of these heap dumps, all from May 4, 2025, and is distributing them to journalists and researchers.</p><p>"The trove included material from disaster responders, customs officials, several U.S. diplomatic staffers, at least one White House staffer and members of the Secret Service," <a href="https://www.reuters.com/world/us/hacker-who-breached-communications-app-used-by-trump-aide-stole-data-across-us-2025-05-21/" rel="noreferrer">according</a> to a Reuters report.</p>
<div data-layout="minimal">
                    
                        <p><span>I'm crunching data and writing these newsletters in my free time. If you want to support my work, considering becoming a paid supporter.</span></p>
                    
                    
                        <p><a href="#/portal/signup">
                            Become a paid supporter
                        </a>
                        
                    </p></div>
<h2 id="what-even-is-this-data">What even is this data?</h2><p>On May 4, a hacker loaded the URL <strong>archive.telemessage.com/management/heapdump</strong> over and over again, each time downloading a different Java heap dump from TeleMessage's server. Yes, the vulnerability was that simple, which is why it took <a href="https://micahflee.com/how-the-knock-off-signal-app-used-by-trump-officials-got-hacked-in-20-minutes/" rel="noreferrer">about 20 minutes</a> to find and exploit.</p><p>Each file is between 130 MB and 291 MB, and is in Java <a href="https://docs.oracle.com/javase/8/docs/technotes/samples/hprof.html" rel="noreferrer">HPROF format</a>. The easiest way to see what's inside is using the command line tool <code>strings</code>, which extracts all the printable strings from a binary file. If you run <code>strings</code> on one of these heap dump files, thousands of lines will scroll by, and some of them will be juicy-looking JSON objects containing plaintext chat messages, along with other interesting data.</p><p>This dataset is <em>not</em> a copy of all of the data that was stored on the TeleMessage archive server. It only includes fragments of data that happened to be in memory at a single moment on May 4. For example, I might find an interesting-looking message that's part of a group chat, but without any other messages from the same group.</p><p>The earliest message I found was from November 15, 2022, and there are messages all the way up until the hack. But about 80% of them are from May 2025. The dataset is mostly a snapshot in time from a specific Sunday earlier this month.</p><h2 id="how-juicy-are-we-talking">How juicy are we talking?</h2><p>So far, I haven't found anything from Trump cabinet officials.</p><p>While I've found plenty of things that seem interesting and warrant further investigation, so far I haven't uncovered anything that is obviously sensitive or revelatory.</p><p>I found a WhatsApp group called "MPD Command Staff" with 46 users in it. There are many messages in this group, but they're all encrypted. (As I described in my <a href="https://micahflee.com/despite-misleading-marketing-israeli-company-telemessage-used-by-trump-officials-can-access-plaintext-chat-logs/#corroborative-evidence-from-the-hack" rel="noreferrer">earlier analysis</a>, some of the individual messages are encrypted.) I looked up some of the phone numbers from this group on <a href="https://www.osint.industries/" rel="noreferrer">OSINT Industries</a> and quickly discovered that these people all work for the Metropolitan Police Department in Washington, DC.</p><p>I also found a message sent to a Signal group called "US / China AI Race." The Signal group had 100 people in it. I looked some of them up: many of the group members hold prominent positions at major universities, the defense industry, and the military, and all seem to do AI-related work. The message says, "The biggest crime was USG ignored these fabs for two years." That's it. The dataset doesn't include any other messages from this Signal group.</p><p>If you're a journalist looking for a tip: Most of the members of the group only listed names, but a few listed phone numbers. If you have access to this data and are looking for a story, why not send the phone-number people Signal messages and ask what this group is about?</p><p>As you can see, this dataset probably holds a million different leads. It's too early to tell if any of them will pan out and become something bigger.</p><h2 id="how-much-data-are-we-talking">How much data are we talking?</h2><p>The main file in the dataset that contains the compressed heap dumps is <code>telemessage.7z</code>, and it's 54 GB. After decompressing it, I end up with a folder with 2,729 heap dump files, taking a total of 384 GB of space. After running <code>strings</code> on each of these files, I end up with 83 GB of just text data.</p><p>Most of the text data is hundreds of thousands of useless lines like this:</p><pre><code>P&lt;E_IN:Ljava/lang/Object;E_OUT:Ljava/lang/Object;&gt;Ljava/util/stream/ReferencePipeline&lt;TE_IN;TE_OUT;&gt;;
(Ljava/util/function/BinaryOperator;Ljava/util/Map;Ljava/util/Map;)Ljava/util/Map;
PMethod java/util/concurrent/ConcurrentNavigableMap.floorEntry(Ljava/lang/Object;)Ljava/util/Map$Entry; is abstract</code></pre><p>However, some of the lines are more interesting, like this mildly redacted one:</p><pre><code>{"typ":"RawMessage","gatewayReceivedDate":1746332951616,"partner":"NONE","securityContent":null,"sourceService":null,"internalSecurityData":{"version":"0.0.2","internalDecryptionData":{"typ":"nothing","encryptionType":"DO_NOTHING","params":{}}},"networkType":"WHATSAPP_CLOUD_ARCHIVER","sourceType":"WHATSAPP_CLOUD_ARCHIVER","ownerExtClassId":null,"body":{"owner":{"value":"==redacted==","type":"PHONE"},"messageId":"09cfd8142e20170be8a3","messageType":"APP_MESSAGE","messageTime":1746332951000,"sender":{"value":"==redacted==","type":"PHONE"},"recipients":[{"value":"==redacted==","type":"PHONE"}],"direction":"IN","subject":"WhatsApp message from ==redacted== to ==redacted==","textField":{"extractor":{"typ":"WrapperExt","data":"Sure\nI</code></pre><p>Notice that this line ends abruptly, with <code>"data":"Sure\nI</code>, and that's it. This is a fragment of a JSON object, not the whole thing. These are all over the place. While there's potentially interesting details in broken JSON fragments, I decided to ignore them.</p><p>I've been writing software (which I plan to release as open source soon, and I talk about more below) that extracts every single intact JSON object from every single heap dump and stores anything that looks interesting in a PostgreSQL database, ignoring duplicates.</p><p>I might be missing stuff. For example, I'm only looking for JSON objects now, but I had previously found <a href="https://micahflee.com/despite-misleading-marketing-israeli-company-telemessage-used-by-trump-officials-can-access-plaintext-chat-logs/#private-key-material" rel="noreferrer">private keys</a> in the heap dumps. But with just storing interesting-looking JSON, the database ends up taking up 2.7 GB of space.</p><h2 id="statistics">Statistics</h2><p>Here are some numbers I've pulled from my database. Please take them all with a grain of salt for the following reasons:</p><ul><li>The dataset is not a representative sample of the messages passing through TeleMessage's archive server. Rather, it's what happened to be saved in heap dumps on one specific Sunday.</li><li>While I removed millions of duplicate JSON objects while building the database, there are still a lot of duplicates. Sometimes the same message is repeated multiple times, but the JSON objects are slightly different, like because two different people in the same group archived the same message.</li><li>I've made some value judgements that appear in the data. For example, some messages include metadata making it clear they're encrypted. Others look encrypted (because the text field is Base64 encoded), but are missing metadata saying one way or the other. I just mark those as encrypted, because they probably are, but I could be wrong.</li></ul><p>That said, here's what I've found:</p><ul><li>60,012 messages.<ul><li>36,388 of the messages are plaintext, and 23,624 are encrypted.</li><li>1,079 of the message include full attachments (like images, videos, PDFs, contact files, etc.) that are actually part of the dataset. But of those, only 50 of messages are in plaintext. I can, however, actually open and view those plaintext attachments.</li><li>Most messages have a <code>subject</code> field that's something like, "WhatsApp message from X to Y." Based on these subjects:<ul><li>37,753 are WhatsApp messages.</li><li>2,549 are Telegram messages.</li><li>455 are SMS messages.</li><li>141 are Signal messages.</li><li>95 are something called "App Messages."</li><li>26 are MMS messages.</li><li>26 are WeChat messages.</li><li>16 are voice calls logs.</li><li>11,254 are missing <code>subject</code> fields.</li></ul></li></ul></li><li>3,501 group chats, the vast majority of which are WhatsApp.<ul><li>At least 2,034 are WhatsApp groups.</li><li>At least 578 are SMS groups.</li><li>At least 256 are Telegram groups.</li><li>At least 26 are Signal groups.</li><li>At least 10 are WeChat groups.</li><li>I'm not sure about the other ~600 groups, though it's possible to determine by manually looking at the messages associated with them.</li><li>There are also plenty of individual messages that are clearly part of a group chat, but that didn't include JSON metadata related to it, so they're not categorized as groups, even though they are.</li></ul></li><li>44,503 users. These are either senders or recipients of messages.<ul><li>At least 25,792 of them use phone numbers as the identifier.</li><li>At least 31 of them use email addresses, and at least 391 look like they use usernames.</li><li>I'm not sure about another 18,289 of them, but I think most of them are also phone numbers.</li><li>17,377 of them include first and/or last names, too.</li></ul></li></ul><h2 id="telemessage-explorer">TeleMessage Explorer</h2><p>As I mentioned, I've been programming a tool to make researching this dataset easier. It's called TeleMessage Explore, and I'm going to release it as open source soon. <a href="#/portal/signup" rel="noreferrer">Subscribe to my newsletter</a> if you're interested in updates.</p><p>Since DDoSecrets is only distributing the TeleMessage dataset to journalists and researchers, this tool will only be useful to a small number of people, but I hope that it will make it <em>so much easier</em> for everyone who does have access to find good stories.</p><h2 id="hundreds-of-telemessage-customers">Hundreds of TeleMessage customers</h2><p>While sifting through thousands of different JSON objects, I came across what appears to be an OAuth2 validation object. This is data related to someone signing into TeleMessage using a Single Sign-On service.</p><p>Here's a validation object with info from someone at JP Morgan. I've redacted his email address and phone number, but I have them.</p><pre><code>{
    "validationData": {
        "reason": "OK",
        "validated": true
    },
    "enhancementData": {
        "data": ["==redacted=="],
        "email": "==redacted==@jpmorgan.com",
        "userName": "==redacted==",
        "shortCodes": [],
        "subUserIds": [],
        "activeIdentityProviderWithParams": {
            "activeIdentityProvider": "MICROSOFT",
            "identityProviderParams": {
                "NONCE": {"value": "", "predefined": true},
                "SCOPE": {"value": "JPMC:URI:RS-108400-153785-TMAdminConsoleSSOProd-PROD/openid", "predefined": false},
                "AUDIENCE": {"value": "JPMC:URI:RS-108400-153785-TMAdminConsoleSSOProd-PROD", "predefined": false},
                "CLIENT_ID": {"value": "PC-108400-SID-340413-PROD", "predefined": false},
                "TOKEN_ENDPOINT": {"value": "https://idag2.jpmorganchase.com/adfs/oauth2/token", "predefined": false},
                "TTL_IN_MINUTES": {"value": "30", "predefined": false},
                "VALIDATION_URL": {"value": "https://auth-service-charlie.kapi.telemessage.com/oidc/validate", "predefined": true},
                "EXPIRATION_DAYS": {"value": "0", "predefined": false},
                "METADATA_DOCUMENT": {"value": "https://idag2.jpmorganchase.com/adfs/.well-known/openid-configuration", "predefined": false},
                "TOKEN_EXCHANGE_URL": {"value": "https://auth-service-charlie.kapi.telemessage.com/oidc/exchangeAndValidateToken", "predefined": true},
                "OAUTH2_RESPONSE_TYPES": {"value": "code", "predefined": false},
                "AUTHORIZATION_ENDPOINT": {"value": "https://idag2.jpmorganchase.com/adfs/oauth2/authorize", "predefined": false}
            }
        }
    }
}</code></pre><p>When looking for more of these objects, I found that some don't include an <code>activeIdentityProvider</code>, like this one. This person works for Scotiabank:</p><pre><code>{
    "validationData": {
        "reason": "OK",
        "validated": true
    },
    "enhancementData": {
        "data": [
            "==redacted=="
        ],
        "email": "==redacted==@scotiabank.com",
        "userName": "==redacted==",
        "shortCodes": [],
        "subUserIds": [],
        "activeIdentityProviderWithParams": {
            "activeIdentityProvider": "NONE",
            "identityProviderParams": {}
        }
    }
}</code></pre><p>In all, I found 2,545 similar validation objects. I think it's likely that every email address in a validation object belongs to someone working for a TeleMessage customer.</p><p>Following is a list of domain names, along with the number of email addresses associated with those domains, in alphabetic order.</p><p>(It starts with a16z.com, which is the site for tech venture capitalist firm Andreessen Horowitz. This firm is owned by Silicon Valley billionaire and prominent reactionary Trump supporter Marc Andreessen.)</p><ul><li>a16z.com (3 emails)</li><li>abgadvisory.com (2 emails)</li><li>aipgp.com (4 emails)</li><li>alphawaveglobal.com (4 emails)</li><li>alternasecurities.com (1 email)</li><li>amcgroup.com (1 email)</li><li>amerexenergy.com (1 email)</li><li>aminagroup.com (3 emails)</li><li>amius.com (6 emails)</li><li>apg-am.com (1 email)</li><li>apg-am.hk (9 emails)</li><li>apg-am.sg (1 email)</li><li>aramcotrading.us (12 emails)</li><li>ardian.com (1 email)</li><li>aresmgmt.com (2 emails)</li><li>arringtoncapital.com (1 email)</li><li>aviorcapital.co.uk (1 email)</li><li>aviorcapital.us (1 email)</li><li>awincubation.com (2 emails)</li><li>axiuminfra.com (1 email)</li><li>b2c2.com (2 emails)</li><li>bainbridgefs.com (1 email)</li><li>ballestasgroup.com (1 email)</li><li>bbva.com (3 emails)</li><li>bgcg.com (2 emails)</li><li>biremecapital.com (1 email)</li><li>bisoncapital.com (1 email)</li><li>bitbuy.ca (1 email)</li><li>bitkraft.vc (2 emails)</li><li>blockchaincapital.com (1 email)</li><li>boltonglobal.com (5 emails)</li><li>borealcm.com (4 emails)</li><li>bradescobank.com (8 emails)</li><li>brevanhoward.com (2 emails)</li><li>br.scotiabank.com (1 email)</li><li>bulltick.com (1 email)</li><li>burlinv.com (1 email)</li><li>cantor.com (6 emails)</li><li>cantor.co.uk (1 email)</li><li>cbam.coinbase.com (1 email)</li><li>cbp.dhs.gov (26 emails)</li><li>cercano.asia (4 emails)</li><li>cibc.com (6 emails)</li><li>clarksons.com (4 emails)</li><li>cmcmarkets.com (1 email)</li><li>coinbase.com (20 emails)</li><li>consultant.kkr.com (1 email)</li><li>conti.com (1 email)</li><li>contractor101.co.uk (1 email)</li><li>contrariancapital.com (1 email)</li><li>crownagentsbank.com (5 emails)</li><li>dbank.co.il (3 emails)</li><li>dc.gov (30 emails)</li><li>dfc.gov (10 emails)</li><li>digitalbridge.com (1 email)</li><li>directhedge.com (1 email)</li><li>eastdilsecured.com (1 email)</li><li>ecor1cap.com (4 emails)</li><li>efhutton.com (1 email)</li><li>eni.com (13 emails)</li><li>exalogi.com (1 email)</li><li>falconcommoditymarkets.com (2 emails)</li><li>fibi.co.il (2 emails)</li><li>franklintempleton.com (1 email)</li><li>freightinvestor.ae (1 email)</li><li>freightinvestor.com (5 emails)</li><li>galaxydigital.io (7 emails)</li><li>gentrustwm.com (2 emails)</li><li>gfigroup.com.sg (1 email)</li><li>gmail.com (6 emails)</li><li>godspeedcm.com (1 email)</li><li>golubcapital.com (1 email)</li><li>govcapsecurities.com (1 email)</li><li>gtbankuk.com (1 email)</li><li>gunvorgroup.com (1 email)</li><li>hack-vc.com (4 emails)</li><li>hbluk.com (4 emails)</li><li>hedgepointglobal.com (1 email)</li><li>hiddenroad.com (8 emails)</li><li>hnwag.com (1 email)</li><li>hudson-trading.com (1 email)</li><li>hummerfas.com (1 email)</li><li>icap.com (3 emails)</li><li>icap.com.sg (1 email)</li><li>interactivebrokers.com (3 emails)</li><li>intercamus.com (1 email)</li><li>intercourtage.com (1 email)</li><li>investamericap.com (1 email)</li><li>itaubba.eu (1 email)</li><li>itau.ch (1 email)</li><li>jefferies.com (62 emails)</li><li>jpmchase.com (1 email)</li><li>jpmorgan.com (21 emails)</li><li>kkr.com (31 emails)</li><li>larrainvial.com (2 emails)</li><li>lasallegroupllc.com (3 emails)</li><li>lcatterton.com (8 emails)</li><li>marathonpetroleum.com (1 email)</li><li>marexfp.com (1 email)</li><li>maximcapitalgroup.com (1 email)</li><li>mbcfrance.com (1 email)</li><li>mbcl.com (2 emails)</li><li>mcquilling-energy.com (4 emails)</li><li>miraeasset.co.id (3 emails)</li><li>mitsui.com (1 email)</li><li>mlp.com (7 emails)</li><li>morganstanley.com (17 emails)</li><li>muzinich.com (1 email)</li><li>mvfp.net (1 email)</li><li>nebari.com (1 email)</li><li>nice.com (1 email)</li><li>nirbhaucorp.com (3 emails)</li><li>northisland.ventures (2 emails)</li><li>nuveen.com (1 email)</li><li>nuveenglobal.com (4 emails)</li><li>nycapmarkets.com (1 email)</li><li>opco.co.il (1 email)</li><li>p66.com (7 emails)</li><li>panteracapital.com (1 email)</li><li>paradigm.xyz (4 emails)</li><li>pa.scotiabank.com (48 emails)</li><li>petrobras.com (5 emails)</li><li>petrobras.com.br (1 email)</li><li>pimco.com (1 email)</li><li>principal.com (1 email)</li><li>privatewealthadvisorsinc.com (1 email)</li><li>psc.com (1 email)</li><li>pvm.co.uk (10 emails)</li><li>pwafamilyoffice.com (1 email)</li><li>reynoldschannel.com (1 email)</li><li>rhbgroup.com (5 emails)</li><li>ribbitcap.com (1 email)</li><li>rjobrien.com (1 email)</li><li>rmb.co.uk (2 emails)</li><li>rmbsecurities.com (1 email)</li><li>rohrpwm.com (1 email)</li><li>rsgcorp.com (1 email)</li><li>safra.com (13 emails)</li><li>scotiabank.cl (34 emails)</li><li>scotiabankcolpatria.com (71 emails)</li><li>scotiabank.com (126 emails)</li><li>scotiabank.com.mx (164 emails)</li><li>scotiabank.com.pe (45 emails)</li><li>scotiacb.com.mx (1 email)</li><li>scotiawealth.com (6 emails)</li><li>scotiawealth.com.mx (5 emails)</li><li>scsotc.com (2 emails)</li><li>seaportglobal.com (1 email)</li><li>searleco.com (1 email)</li><li>seba.swiss (1 email)</li><li>senatorlp.com (1 email)</li><li>sequencefinancialspecialists.com (1 email)</li><li>sg.pimco.com (1 email)</li><li>smarsh.com (4 emails)</li><li>smbcgroup.com (2 emails)</li><li>soteriasolutions.us (15 emails)</li><li>sperrycapital.com (1 email)</li><li>standardbank.co.za (6 emails)</li><li>statetrust.com (1 email)</li><li>steadview.com (1 email)</li><li>sunglobal.co.uk (1 email)</li><li>sunmountaincapital.com (1 email)</li><li>tcv.com (2 emails)</li><li>telemessage2020.onmicrosoft.com (9 emails)</li><li>telemessage.com (13 emails)</li><li>thestrategicfinancial.com (1 email)</li><li>tigerglobal.com (2 emails)</li><li>tm.com (4 emails)</li><li>totalenergies.com (92 emails)</li><li>tower-research.com (1 email)</li><li>tpicap.com (6 emails)</li><li>traditionasia.com (1 email)</li><li>tradition.com (4 emails)</li><li>tridentotc.com (1 email)</li><li>tullettprebon.co.jp (1 email)</li><li>tullettprebon.com (10 emails)</li><li>tyruscap.mc (1 email)</li><li>ubauk.com (3 emails)</li><li>uk.pimco.com (1 email)</li><li>united-icap.com (6 emails)</li><li>us.icap.com (1 email)</li><li>usss.dhs.gov (2 emails)</li><li>uyanapartners.com (1 email)</li><li>valley.com (8 emails)</li><li>vistaequitypartners.com (4 emails)</li><li>vitol.com (8 emails)</li><li>vlmsofts.com (1 email)</li><li>who.eop.gov (1 email)</li><li>williamblair.com (5 emails)</li><li>wonder.fi (1 email)</li><li>worldquant.com (1 email)</li></ul><p><em>If you found this interesting, </em><a href="https://micahflee.com/despite-misleading-marketing-israeli-company-telemessage-used-by-trump-officials-can-access-plaintext-chat-logs/#/portal/signup" rel="noreferrer"><em>subscribe</em></a><em> to get these posts emailed directly to your inbox. If you want to support my work, considering becoming a paid supporter.</em></p>
                    
                </section>

                    

                
            </article>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Data breach exposes 184M passwords, likely captured by malware (126 pts)]]></title>
            <link>https://www.zdnet.com/article/massive-data-breach-exposes-184-million-passwords-for-google-microsoft-facebook-and-more/</link>
            <guid>44099008</guid>
            <pubDate>Mon, 26 May 2025 16:37:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.zdnet.com/article/massive-data-breach-exposes-184-million-passwords-for-google-microsoft-facebook-and-more/">https://www.zdnet.com/article/massive-data-breach-exposes-184-million-passwords-for-google-microsoft-facebook-and-more/</a>, See on <a href="https://news.ycombinator.com/item?id=44099008">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><figure><div><picture><source media="(max-width: 767px)" srcset="https://www.zdnet.com/a/img/resize/2fcf7434c0b644d136b37849c2032ca12ba9d247/2025/05/23/e669b1a4-6612-4c2a-adbc-bf3b70a8f6f9/gettyimages-1411799666.jpg?auto=webp&amp;width=768" alt="data breach concept"><source media="(max-width: 1023px)" srcset="https://www.zdnet.com/a/img/resize/f1189ea3e1dd85500849b507ee31656c7c8b9000/2025/05/23/e669b1a4-6612-4c2a-adbc-bf3b70a8f6f9/gettyimages-1411799666.jpg?auto=webp&amp;width=1024" alt="data breach concept"><source media="(max-width: 1440px)" srcset="https://www.zdnet.com/a/img/resize/7bb565b4489f154dd822e353edf6fe5c8871d69f/2025/05/23/e669b1a4-6612-4c2a-adbc-bf3b70a8f6f9/gettyimages-1411799666.jpg?auto=webp&amp;width=1280" alt="data breach concept"> <img src="https://www.zdnet.com/a/img/resize/7bb565b4489f154dd822e353edf6fe5c8871d69f/2025/05/23/e669b1a4-6612-4c2a-adbc-bf3b70a8f6f9/gettyimages-1411799666.jpg?auto=webp&amp;width=1280" alt="data breach concept" width="1280" height="719.5495885664791" fetchpriority="low"></picture></div> <figcaption> <span>JuSun/Getty Images</span></figcaption></figure><p>Yet another data breach has exposed passwords and other sensitive information – but this one is a whopper.</p><p>Cybersecurity researcher <a href="https://www.vpnmentor.com/author/jeremiah-fowler/#link=%7B%22role%22:%22standard%22,%22href%22:%22https://www.vpnmentor.com/author/jeremiah-fowler/%22,%22target%22:%22%22,%22absolute%22:%22%22,%22linkText%22:%22Jeremiah%20Fowler%22%7D" target="_blank" rel="noopener nofollow">Jeremiah Fowler</a> revealed his discovery of a massive online database containing more than 184 million unique account credentials, in a <a href="https://www.websiteplanet.com/news/infostealer-breach-report/#link=%7B%22role%22:%22standard%22,%22href%22:%22https://www.websiteplanet.com/news/infostealer-breach-report/%22,%22target%22:%22%22,%22absolute%22:%22%22,%22linkText%22:%22report%20published%20yesterday%22%7D" target="_blank" rel="noopener nofollow">report published Thursday</a>. Usernames, passwords, emails, and URLs for a host of applications and websites, including Google, Microsoft, Apple, Facebook, Instagram, and Snapchat, among others, were stored in a file. The database also contained credentials for bank and financial accounts, health platforms, and government portals. </p><p><strong>Also:&nbsp;<a href="https://www.zdnet.com/article/best-password-manager/">The best password managers of 2025: Expert tested</a></strong></p><p>The problem? The file was unencrypted. No password protection. No security. Just a plain text file with millions of sensitive pieces of data. </p><p>Based on his analysis, Fowler determined the data was captured by some kind of infostealer malware. A popular tool used by cybercriminals, an infostealer is designed to grab usernames, passwords, and other sensitive data from breached sites and servers. Once the criminals get their hands on the data, they can use it to launch their own attacks or peddle the information on the dark web.</p><p>After finding the database, Fowler contacted the hosting provider, which removed it from public access. Since the provider would not disclose the name of the file's owner, Fowler said he didn't know if the database was created legitimately and then accidentally exposed or intentionally used for malicious reasons. </p><p>To check on the validity of the information, Fowler emailed many of the people listed in the file and told them that he was researching a data breach. Several of the individuals confirmed that the records contained valid account passwords and other data. </p><p><strong>Also:&nbsp;<a href="https://www.zdnet.com/article/oversharing-online-5-ways-it-makes-you-an-easy-target-for-cybercriminals/">Oversharing online? 5 ways it makes you an easy target for cybercriminals</a></strong></p><p>Though the person or people behind the database and exposure are obviously to blame for this incident, users also share some of the responsibility. </p><p>"Many people unknowingly treat their email accounts like free cloud storage and keep years' worth of sensitive documents, such as tax forms, medical records, contracts, and passwords, without considering how sensitive they are," Fowler said. "This could create serious security and privacy risks if criminals were to gain access to thousands or even millions of email accounts."</p><!----><p>In his report, the researcher highlighted the types of threats faced by people whose data is exposed in such breaches. </p><ul><li><p><strong>Credential stuffing attacks</strong> – People who use the same passwords on multiple accounts open themselves up to compromise. Hackers deploy automated credential stuffing scripts to try out different email and password combinations on thousands of different sites. The same password exposed on one site can then easily be exposed on others. 		</p></li><li><p><strong>Account takeovers</strong> - Cybercriminals who gain access to usernames, passwords, and other private data are able to take over an account. They can steal your identity, commit financial fraud, and run other types of scams, not just on you but on family, friends, and other contacts. 		</p></li></ul><ul><li><p><strong>Ransomware and corporate espionage</strong> – Fowler said he discovered many business credentials in the leaked data. The attackers can exploit this information to steal business records, launch ransomware attacks, and even commit corporate espionage. 		</p></li><li><p><strong>Attacks against state and government agencies </strong>– Fowler also saw several government accounts across different countries. An attacker armed with this information can target state and federal agencies. 		</p></li><li><p><strong>Phishing and social engineering</strong> – Leaked emails provide cybercriminals with a history of someone's conversations and contacts. That information can then be used in targeted phishing attacks against the account owner as well as people they know. 		</p></li></ul><p>How can you protect your own confidential data from being exposed in a breach? Though no perfect solution exists, Fowler shared the following tips in his report: </p><h2> 1. Change your passwords each year </h2><p>Many people have only one email address connected to multiple accounts, which means they can't easily change it. But you can change your password, at least periodically. Doing so is a good idea if you think your old password may have been compromised in a breach. </p><h2> 2. Use complex and unique passwords </h2><p>Beyond using <a href="https://www.zdnet.com/article/7-password-rules-security-experts-live-by-in-2025-the-last-one-might-surprise-you/">strong passwords</a>, avoid using the same one for multiple accounts. </p><h2> 3. Consider a password manager </h2><p>A <a href="https://www.zdnet.com/article/best-password-manager/">password manager</a> can take on the challenging role of creating, storing, and applying strong and unique passwords for each account. As Fowler pointed out, there is a risk in using a password manager. If your master password is ever stolen or compromised, a cybercriminal now has the key to unlock all your passwords. But that brings us to the next tip. </p><p><strong>Also: <a href="https://www.zdnet.com/article/hackers-stole-this-engineers-1password-database-could-it-happen-to-you/">Hackers stole this engineer's 1Password database. Could it happen to you?</a></strong></p><h2> 4. Use multi-factor authentication </h2><p><a href="https://www.zdnet.com/article/why-multi-factor-authentication-is-absolutely-essential-in-2025/">MFA</a> offers a second level of authentication, typically through a code, authenticator app, or <a href="https://www.zdnet.com/article/best-security-key/">security key</a>. If your password is ever breached, a cybercriminal can't access your account without that code. Make sure you use MFA on all available accounts, but especially ones for bank and financial services and password managers. </p><p><strong>Also:&nbsp;</strong><a href="https://www.zdnet.com/article/10-passkey-survival-tips-prepare-for-your-passwordless-future-now/"><strong>10 passkey survival tips: Prepare for your passwordless future now</strong></a></p><h2> 5. Check if your credentials have been leaked </h2><p>Services like <a href="https://haveibeenpwned.com/" target="_blank" rel="noopener nofollow">HaveIBeenPwned</a> will tell you if your email has popped up in any known breaches. If so, then make sure you change the password for the affected accounts. </p><h2> 6. Monitor the use of your accounts </h2><p>Some websites and services will alert you to suspicious login activity and other atypical behavior, just like your credit card company alerts you to potentially suspect transactions. Avail yourself of this feature whenever possible. </p><h2> 7. Use good security software </h2><p>The right security software can detect and eliminate infostealer malware and other known threats. Be sure to <a href="https://www.zdnet.com/article/why-delaying-software-updates-could-cost-you-more-than-you-think/">update your software</a> with the latest definitions to defend yourself against new variants. </p><p><em>Get the morning's top stories in your inbox each day with our&nbsp;</em><a href="https://www.zdnet.com/newsletters/"><em><strong>Tech Today newsletter</strong></em></a><em><strong>.</strong></em></p><div id="pinbox-656e4fed-3457-4713-94c8-e03a2db0d92d"><h4>Featured</h4> <!---->  </div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Hacker News now runs on top of Common Lisp (462 pts)]]></title>
            <link>https://lisp-journey.gitlab.io/blog/hacker-news-now-runs-on-top-of-common-lisp/</link>
            <guid>44099006</guid>
            <pubDate>Mon, 26 May 2025 16:37:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lisp-journey.gitlab.io/blog/hacker-news-now-runs-on-top-of-common-lisp/">https://lisp-journey.gitlab.io/blog/hacker-news-now-runs-on-top-of-common-lisp/</a>, See on <a href="https://news.ycombinator.com/item?id=44099006">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><a href="https://news.ycombinator.com/">Hacker News</a> was written in the
<a href="http://arclanguage.org/">Arc</a> lisp dialect, a dialect created by Paul
Graham. Arc was implemented on top of Racket, but that has now
changed. HN runs on top of SBCL since a few months.</p>

<p>But why? For performance reasons.</p>

<blockquote>
<p>I recently noticed that Hacker News no longer uses paging for long
threads. In the past, when a discussion grew large, we had to click
“More” to load the next page of comments, and dang would
occasionally post helpful tips to remind us about this feature.
Was there an announcement regarding this change? Has anyone else still seen paging recently? I’d love to know more details—especially the technical aspects or considerations that went into the decision.</p>
</blockquote>

<p>Answer:</p>

<blockquote>
<p>It’s because Clarc is finally out.</p>
</blockquote>

<p><a href="https://news.ycombinator.com/item?id=41679215">dang, Sept. 2024</a></p>

<blockquote>
<p>[Clarc] is much faster and also will easily let HN run on multiple cores. It’s been in the works for years, mainly because I rarely find time to work on it, but it’s all pretty close to done.</p>
</blockquote>

<p><a href="https://news.ycombinator.com/item?id=32597291">dang, 2022</a></p>

<p>How it’s done:</p>

<blockquote>
<p>there’s now an Arc-to-JS called Lilt, and an Arc-to-Common Lisp called Clarc. In order to make those easier to develop, we reworked the lower depths of the existing Arc implementation to build Arc up in stages. The bottom one is called arc0, then arc1 is written in arc0, and arc2 in arc1. The one at the top (arc2, I think) is full Arc. This isn’t novel, but it makes reimplementation easier since you pack as much as possible in the later stages, and only arc0 needs to be written in the underlying system (Racket, JS, or CL).</p>
</blockquote>

<p><a href="https://news.ycombinator.com/item?id=21550123">dang, 2019</a></p>

<p>But Clarc’s code isn’t released:</p>

<blockquote>
<p>Much of the HN codebase consists of anti-abuse measures that would stop working if people knew about them. Unfortunately.
separating out the secret parts would by now be a lot of work. The time to do it will be if and when we eventually release the alternative Arc implementations we’ve been working on.</p>
</blockquote>

<p><a href="https://news.ycombinator.com/item?id=21546438">https://news.ycombinator.com/item?id=21546438</a></p>

<p>Congrats for the successful “splash-free” transition though.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I think it's time to give Nix a chance (125 pts)]]></title>
            <link>https://maych.in/blog/its-time-to-give-nix-a-chance/</link>
            <guid>44098605</guid>
            <pubDate>Mon, 26 May 2025 15:56:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://maych.in/blog/its-time-to-give-nix-a-chance/">https://maych.in/blog/its-time-to-give-nix-a-chance/</a>, See on <a href="https://news.ycombinator.com/item?id=44098605">Hacker News</a></p>
<div id="readability-page-1" class="page"><article> <p>The modern developer tooling ecosystem has exploded with choices, leading to frustrating scenarios where some piece of code builds perfectly on someone’s system, runs flawlessly in production, but mysteriously fails to build for you and you have absolutely no idea why. You’re left debugging with no clear direction—perhaps it’s a missing system dependency, a subtly different library version, or some environment variable that exists somewhere in the void, and nowhere else.</p>
<p>If this sounds familiar, you too might be experiencing the fundamental problem that Nix was designed to solve: the lack of true reproducibility in software development.</p>
<p>Despite being around for about two decades, Nix has largely flown under the radar of mainstream development. Most developers have heard of it in passing—often described as “that functional package manager with a steep learning curve” or “the thing NixOS uses”—dismissing it as academic or overly complex. I believe this perception is getting increasingly outdated, Nix <em>deserves</em> a chance.</p>
<p>First, let’s get this out of the way: Nix still <em>does</em> have a steep learning curve. It requires learning a new functional programming language, understanding unfamiliar concepts like derivations and the <code>/nix/store</code>, and rethinking how package management works. The documentation can be dense, scattered, and the error messages are outright unhelpful in some cases. You’re essentially learning an entirely different approach to software deployment and environment management.</p>
<p>But here’s the thing—as of this post, the tooling around Nix has matured significantly, and the problems Nix solves have only become more pressing. If you’ve ever lost hours debugging environment differences, juggled multiple version managers, or struggled with reproducible builds, Nix addresses these pain points at the architectural level rather than through workarounds.</p>
<p>And I am here to argue that despite the quirks and learning investment, Nix’s benefits are compelling enough to warrant your time. The question isn’t whether Nix, as a tool and a language, is complex—<em>it is</em>. The question is whether the problems it solves are worth learning something genuinely different. In this post, you can expect a brief introduction to what Nix, the tool, can do for you and how it may be worth giving a try right now.</p>
<h2 id="why-traditional-package-management-breaks-down">Why Traditional Package Management Breaks Down</h2>
<p>Most package managers work by installing software into shared system locations. Install a specific version of Python, and it goes straight into <code>/usr/bin/python</code>. Need a different version of Python for another project? You either overwrite the first installation or create complex alternatives systems that are painful to manage.</p>
<p>This shared-state approach creates inevitable conflicts:</p>
<ul>
<li>Your frontend application needs the latest version of NodeJS, but a legacy service requires an older one.</li>
<li>Your applications depend on conflicting versions of OpenSSL libraries.</li>
<li>Teams use different operating systems with slightly different utilities. Heck, even same versions of tools, like <code>sed</code>, are functionally different across Linux and MacOS.</li>
</ul>
<p>In such cases, one may say that version managers help with language runtimes. But what about system libraries, databases, or compiled tools? You end up juggling multiple such tools, each with different commands and behaviors.</p>
<p>Orchestration and containerized solutions like Docker and Kubernetes help, but they introduce their own complexities and performance downgrades. More importantly, Docker containers themselves aren’t reproducible—running <code>apt-get update</code> or <code>pip install requests</code> at different times can yield different results, even with the same Dockerfile. And frankly, no one really needs Kubernetes, they just have it because everyone and their grandma has it. I digress, that’s a topic for another day.</p>
<p>This is where Nix comes in.</p>
<h2 id="and-how-nix-solves-the-problem">…And How Nix Solves the Problem</h2>
<p>Nix makes no assumptions about the global state of your system and takes a fundamentally different approach. Instead of installing packages into shared locations where they can conflict, everything goes into the immutable <code>/nix/store</code>, with each package getting a unique directory based on a cryptographic hash of its build inputs.</p>
<div><figure><pre data-language="plaintext"><code><div><p><span>/nix/store/2v66xkgfmdipzpwgl813n4mqgck6w3fd-nodejs-22.14.0/</span></p></div><div><p><span>/nix/store/2znhzcp5ran8q5mzyqgz6lxi3a56rgva-nodejs-20.18.1/</span></p></div><div><p><span>/nix/store/4rk85a5rsladhcc3ffpnx2kwglvs0i-nodejs-18.17.0/</span></p></div></code></pre></figure></div>
<p>These hashes are computed using SHA-256 over the package’s complete build dependency graph—source code, compiler version, build flags, dependencies, even the build script itself. Change any input, and you get a different hash, which means a completely separate package in the store.</p>
<h3 id="cryptographic-guarantees-and-safety">Cryptographic Guarantees and Safety</h3>
<p>Technically, you might state that hash collisions are possible with any cryptographic hash function, and you won’t be wrong here. However, the probability of a SHA-256 collision is approximately one in 2<sup>128</sup>—or roughly <strong><em>one in 340 undecillion!</em></strong>. For perspective, this is far less likely than being struck by lightning while simultaneously winning the lottery multiple times.</p>
<p>More importantly, Nix implements robust failsafe mechanisms. It uses NAR (Nix Archive) hashes, a deterministic format that canonicalizes source trees by normalizing timestamps, file permissions, and directory ordering. Unlike traditional TAR archives which include non-deterministic metadata, NAR hashes ensure identical content always produces identical hashes. Nix validates packages using both the NAR hash and additional metadata like Git revision hashes, providing multiple layers of integrity verification. This has prevented an issue in the past, where GitHub changed the hash format of their archives, causing systems and services depending on these hashes to fail.<span> <label for="sidenote-1" data-footnote-id="1" aria-label="Sidenote 1" tabindex="0" role="button" aria-expanded="false"></label>  <span role="note" aria-label="Sidenote 1"> <label for="sidenote-1" data-footnote-id="1"></label> <a href="https://flox.dev/blog/hash-collision/">Hash Collision</a> - Flox </span> </span></p>
<p>This isolation means multiple versions coexist without conflicts. Your React app gets Node.js 18, the legacy API keeps Node.js 16, and they exist in completely separate filesystem namespaces.</p>
<p>Now, I’m in no way trying to proliferate a <a href="https://xkcd.com/927/">15<sup>th</sup> competing standard</a> here that solves all package management woes for you and your grandma. Nix is far more capable at things than just that, and I’ll tell you why.</p>
<h2 id="reproducible-environments-with-flakes">Reproducible Environments with Flakes</h2>
<p>Modern Nix organizes projects using “flakes”<span> <label for="sidenote-2" data-footnote-id="2" aria-label="Sidenote 2" tabindex="0" role="button" aria-expanded="false"></label>  <span role="note" aria-label="Sidenote 2"> <label for="sidenote-2" data-footnote-id="2"></label> <a href="https://zero-to-nix.com/concepts/flakes/">Nix flakes</a> - Zero to Nix </span> </span>—standardized specifications that pin every dependency with cryptographic precision. Think of them as <code>package.json</code> or <code>Cargo.toml</code>, but with mathematical guarantees that every single build will result in the same derivation, no matter when, where, or how you build it.</p>
<p>While flakes have been “experimental” for quite a long time now, it has truly pushed Nix one step closer to complete reproducibility and shared development environments. For clarity, <a href="https://determinate.systems/posts/experimental-does-not-mean-unstable/">Experimental does not mean unstable</a>, as flakes have practically been “stable” since 2021, despite the experimental tag. Here’s what a simple flake might look like:</p>
<div><figure><pre data-language="nix"><code><div><p><span># This is a nix flake environment running</span></p></div><div><p><span># Python 3.11, with pandas and numpy installed.</span></p></div><div><p><span># The environment can be accessed by running:</span></p></div><div><p><span>#    $ nix develop</span></p></div><div><p><span>{</span></p></div><div><p><span>  </span><span>description</span><span> </span><span>=</span><span> </span><span>"Example Python Data Analysis Environment"</span><span>;</span></p></div><div><p><span>  </span><span>inputs</span><span> </span><span>=</span><span> {</span></p></div><div><p><span>    </span><span>nixpkgs</span><span>.</span><span>url</span><span> </span><span>=</span><span> </span><span>"github:nixos/nixpkgs/nixos-unstable"</span><span>;</span></p></div><div><p><span><span>  </span></span><span>};</span></p></div><div><p><span>  </span><span>outputs</span><span> </span><span>=</span><span> { self</span><span>,</span><span> nixpkgs }: {</span></p></div><div><p><span>    </span><span>devShells</span><span>.</span><span>x86_64-linux</span><span>.</span><span>default</span><span> </span><span>=</span></p></div><div><p><span>      </span><span>nixpkgs</span><span>.</span><span>legacyPackages</span><span>.</span><span>x86_64-linux</span><span>.</span><span>mkShell</span><span> {</span></p></div><div><p><span>        </span><span>buildInputs</span><span> </span><span>=</span><span> </span><span>with</span><span> </span><span>nixpkgs</span><span>.</span><span>legacyPackages</span><span>.</span><span>x86_64-linux</span><span>; [</span></p></div><div><p><span>          </span><span>python311</span></p></div><div><p><span>          </span><span>python311Packages</span><span>.</span><span>pandas</span></p></div><div><p><span>          </span><span>python311Packages</span><span>.</span><span>numpy</span></p></div><div><p><span><span>        </span></span><span>];</span></p></div><div><p><span><span>      </span></span><span>};</span></p></div><div><p><span><span>  </span></span><span>};</span></p></div><div><p><span>}</span></p></div></code></pre></figure></div>
<p>Let’s take this as an example. When you share this flake (along with the <code>flake.lock</code>) with someone and they build it, they get exactly—not approximately—the same environment as when you created the flake. The automatically generated <code>flake.lock</code><span> <label for="sidenote-3" data-footnote-id="3" aria-label="Sidenote 3" tabindex="0" role="button" aria-expanded="false"></label>  <span role="note" aria-label="Sidenote 3"> <label for="sidenote-3" data-footnote-id="3"></label> <a href="https://zero-to-nix.com/concepts/flakes/#lockfile">The <code>flake.lock</code> file</a> - Zero to Nix </span> </span> file contains cryptographic hashes for every dependency in the transitive closure. This means that building this same flake over and over again, even a few years down the line, will ideally still result in the exact same environment. Well, at least until the source of the software disappears from the face of the earth, <em>and</em> the Nix binary cache contracts bit-rot.</p>
<p>Also, these Nix flakes are backed by git and only include tracked files in builds, ensuring forgotten local files and hash changes cause immediate build failures rather than silent inconsistencies.</p>
<h2 id="running-packages-without-installing">Running Packages Without Installing</h2>
<p>Usually to run a package on any system you would need to install it, or use an AppImage, Flatpak, snap, you name it. But not with Nix. One of Nix’s most practical features is temporary tool access without system pollution:</p>
<div><figure><pre data-language="bash"><code><div><p><span># Run Node.js 20 without installing it</span></p></div><div><p><span>nix</span><span> </span><span>run</span><span> </span><span>nixpkgs#nodejs_20</span><span> </span><span>--</span><span> </span><span>--version</span></p></div><div><p><span># Get a temporary shell with multiple tools</span></p></div><div><p><span>nix</span><span> </span><span>shell</span><span> </span><span>nixpkgs#{imagemagick,ffmpeg}</span></p></div><div><p><span># Try software from any Git repository with flakes</span></p></div><div><p><span>nix</span><span> </span><span>shell</span><span> </span><span>github:DeterminateSystems/fh</span><span> </span><span>--</span><span> </span><span>fh</span><span> </span><span>--help</span></p></div></code></pre></figure></div>
<p>This eliminates tool accumulation while providing instant access to any software in the Nix ecosystem. When you exit the shell, the tools disappear from your environment (but stay in the <code>/nix/store</code> until it’s garbage collected).</p>
<h2 id="true-package-isolation">True Package Isolation</h2>
<p>Traditional package managers create a shared global namespace where conflicts are inevitable. Nix solves this architecturally by storing each package in <code>/nix/store/</code> with cryptographically unique paths. Multiple versions of the same package coexist without interference because they occupy completely separate filesystem locations.</p>
<div><figure><pre data-language="console"><code><div><p><span>$ ls /nix/store </span><span>|</span><span> </span><span>rg</span><span> </span><span>nodejs-.</span><span>\[</span><span>0</span><span>\-</span><span>9.</span><span>\]</span><span>+drv</span></p></div><div><p><span>/nix/store/2v66xkgfmdipzpwgl813n4mqgck6w3fd-nodejs-22.14.0.drv</span></p></div><div><p><span>/nix/store/2znhzcp5ran8q5mzyqgz6lxi3a56rgva-nodejs-20.18.1.drv</span></p></div><div><p><span>/nix/store/4rk85a5rsladhcc3ffpyfnx2kwglvs0i-nodejs-20.19.2.drv</span></p></div></code></pre></figure></div>
<p>This isolation extends beyond simple version conflicts. Each package includes its complete dependency tree in isolation, meaning you can run applications with entirely different versions of fundamental libraries like glibc simultaneously. The Nix store’s immutable design ensures that once built, packages never change, eliminating an entire class of “it worked yesterday” problems.</p>
<p>Simply put, each project can use a different Node.js version, present on the system, without conflicts. The hash <code>2v66xkgfmdipzpwgl813n4mqgck6w3fd</code> in this case encodes not just Node.js 22.14.0, but the exact glibc version, compiler flags, and every dependency used to build it. This can be confirmed by running a simple <code>nix-store --query</code> on both derivations:</p>
<div><figure><pre data-language="console"><code><div><p><span>$ nix-store --query --tree 2v66xkgfmdipzpwgl813n4mqgck6w3fd-nodejs-22.14.0.drv</span></p></div><div><p><span>/nix/store/2v66xkgfmdipzpwgl813n4mqgck6w3fd-nodejs-22.14.0.drv</span></p></div><div><p><span>├───/nix/store/shkw4qm9qcw5sc5n1k5jznc83ny02r39-default-builder.sh</span></p></div><div><p><span>├───/nix/store/vj1c3wf9c11a0qs6p3ymfvrnsdgsdcbq-source-stdenv.sh</span></p></div><div><p><span>├───/nix/store/cfp8jh04f3jfdcjskw2p64ri3w6njndm-bash-5.2p37.drv</span></p></div><div><p><span>│   ├───/nix/store/3jmwf7n7mdjk99lbwmznwkjvd5kwxlp4-glibc-2.40-66.drv [...]</span></p></div><div><p><span>...</span></p></div><div><p><span>$ nix-store --query --tree 2znhzcp5ran8q5mzyqgz6lxi3a56rgva-nodejs-20.18.1.drv</span></p></div><div><p><span>/nix/store/2znhzcp5ran8q5mzyqgz6lxi3a56rgva-nodejs-20.18.1.drv</span></p></div><div><p><span>├───/nix/store/v6x3cs394jgqfbi0a42pam708flxaphh-default-builder.sh</span></p></div><div><p><span>├───/nix/store/s63zivn27i8qv5cqiy8r5hf48r323qwa-bash-5.2p37.drv</span></p></div><div><p><span>│   ├───/nix/store/qhdvi3qcn60vrapyhsxxpbw0q63gmfz8-glibc-2.40-36.drv [...]</span></p></div><div><p><span>...</span></p></div></code></pre></figure></div>
<p>Package directory names correspond to cryptographic hashes that take into account all dependencies, build flags, and even compiler versions. This content-addressable storage means identical inputs always produce identical outputs, making builds truly reproducible across different machines and time periods.</p>
<h2 id="development-environment-excellence">Development Environment Excellence</h2>
<p>Beyond core benefits, Nix’s ecosystem provides sophisticated tooling for seamless workflows. With <code>nix-direnv</code><span> <label for="sidenote-4" data-footnote-id="4" aria-label="Sidenote 4" tabindex="0" role="button" aria-expanded="false"></label>  <span role="note" aria-label="Sidenote 4"> <label for="sidenote-4" data-footnote-id="4"></label> <a href="https://github.com/nix-community/nix-direnv"><code>nix-direnv</code></a> - GitHub </span> </span>, an extension to <code>direnv</code>, Nix flake environments activate automatically when changing directories:</p>

<p>Now <code>cd</code>ing into the directory automatically loads the Nix environment. The cross-platform consistency is particularly valuable—the same <code>flake.nix</code> that works on Linux works identically on macOS through <code>nix-darwin</code>, and WSL, eliminating platform-specific tooling differences.</p>
<p>And if you still don’t want to interact with or write Nix files directly, there’s tools like <a href="https://flox.dev/">Flox</a>, <a href="https://github.com/numtide/devshell">Devshell</a>, <a href="https://www.jetify.com/devbox">Devbox</a>, built on top of Nix that abstract the pain away.</p>
<h2 id="security-on-nix">Security on Nix</h2>
<p>Nix’s unique architecture provides security benefits that extend beyond reproducibility. The immutable nature of the Nix store and its departure from standard Linux filesystem conventions create inherent security advantages.</p>
<h3 id="immutable-package-store">Immutable Package Store</h3>
<p>Once built, packages in <code>/nix/store</code> cannot be modified. This prevents entire classes of attacks where malware modifies system binaries or libraries. Traditional package managers allow in-place updates that can be exploited, but Nix’s atomic model makes such attacks impossible.</p>
<h3 id="package-sandboxing-and-anti-tampering">Package Sandboxing and Anti-Tampering</h3>
<p>By design, anyone is free to contribute packages to the central Nix package repository. Although all packages there, not marked as <code>nonfree</code>, are built from source, where the source is downloaded before the build process, verified by hash, and only then processed.</p>
<p>By philosophy, Nix prevents uploading pre-built packages to <code>nixpkgs</code> and requires additional reviews before merging, thus ensuring an additional layer of safety at the expense of the latest package updates being a bit delayed—usually only by a couple of days. All built packages, on the official build infrastructure or locally, are sandboxed by default. None of the packages have internet access inside the build environment, meaning that all the dependencies must be resolved before the build runs.</p>
<p>Also, all packages are <em>required</em> to contain a hash of dependencies, ensuring that the build fails if the source or any dependencies are tampered with or poisoned.</p>
<p>In contrast, traditional package management systems rely heavily on trust. As an example, the AUR is a repository of community-contributed Arch packages where you’re trusting random maintainers. Anyone can upload a <code>PKGBUILD</code> that could download and execute arbitrary code during installation. While you can inspect the build script, many users install with <code>yay -S package</code> without review. Similarly, the Fedora RPM repositories which have pre-built binaries signed by maintainers, where you have to trust that the binary matches the claimed source code and the build environment wasn’t compromised.</p>
<h3 id="non-standard-filesystem-layout">Non-Standard Filesystem Layout</h3>
<p>Nix deliberately breaks from the Filesystem Hierarchy Standard (FHS). There’s no <code>/usr/bin</code> filled with system binaries, no <code>/lib</code> or <code>/usr/lib</code> containing shared libraries. This means malware designed for traditional Linux systems often fails because it cannot locate expected system components at standard paths.</p>
<h3 id="dynamic-linking-protection">Dynamic Linking Protection</h3>
<p>Ad-hoc binaries downloaded from the internet cannot run on NixOS without explicit configuration. Traditional Linux systems allow dynamically linked binaries to access system libraries through standard paths like <code>/lib64/ld-linux-x86-64.so.2</code>. On NixOS, these paths either don’t exist or point to controlled implementations. This prevents many categories of malicious binaries from executing.</p>
<h3 id="controlled-binary-execution">Controlled Binary Execution</h3>
<p>Although not impossible, to run external binaries, you need tools like <code>nix-ld</code><span> <label for="sidenote-5" data-footnote-id="5" aria-label="Sidenote 5" tabindex="0" role="button" aria-expanded="false"></label>  <span role="note" aria-label="Sidenote 5"> <label for="sidenote-5" data-footnote-id="5"></label> <a href="https://github.com/nix-community/nix-ld"><code>nix-ld</code></a> - GitHub </span> </span> which provides controlled access to a compatibility layer. This forced deliberation makes it much harder for malicious software to execute unnoticed.</p>
<p>While this isn’t “security through obscurity” (the design is well-documented), it does mean that common attack vectors simply don’t work in a Nix environment, providing defense-in-depth against malware targeting traditional Linux systems.</p>
<h2 id="performance-and-caching">Performance and Caching</h2>
<p>Nix provides performance advantages through sophisticated caching and deduplication. When each package is built, it is stored with its content-addressable path, meaning identical dependencies are built once and shared across all projects.</p>
<p>Binary caching eliminates most compilation time. Popular packages are pre-built and cached, so you typically download binaries rather than compiling from source. There are also services like <a href="https://cachix.org/">Cachix</a>, <a href="https://github.com/zhaofengli/attic">attic</a> that can host binary cache for you so you can push and cache the lesser known, or even your own Nix packages after building them once.</p>
<p>With cache, the first environment activation might take up to a few minutes to download dependencies, but subsequent activations are near-instantaneous. However, environment load times can be a trade-off. Directory changes that trigger environment loading through <code>nix-direnv</code> can take a few seconds depending on dependencies, as Nix maintains separate instances for each tool. But in most cases, everything will be seamless.</p>
<h2 id="when-nix-makes-sense-and-when-it-doesnt">When Nix Makes Sense (And When It Doesn’t)</h2>
<p>After reading this far, you might be wondering if Nix is right for your situation. But what I talked about in this post is barely scratching the surface of what Nix is capable of.</p>
<p>Nix provides the most value when:</p>
<ul>
<li><strong>Environment drift is costly</strong>: Financial services, healthcare, or any domain where debugging production issues has high stakes</li>
<li><strong>Onboarding takes days</strong>: Complex stacks with multiple databases, language runtimes, and system dependencies that require extensive setup documentation</li>
<li><strong>Cross-platform development</strong>: Teams mixing Linux, macOS, and WSL with different package managers and library versions</li>
<li><strong>Compliance requirements</strong>: Industries requiring reproducible builds for audit trails or regulatory compliance</li>
<li><strong>Research and experimentation</strong>: Academic computing, data science, or ML research where reproducing exact environments is critical</li>
<li><strong>Legacy system maintenance</strong>: Managing multiple versions of the same software for different clients or product versions</li>
</ul>
<p>Nix might be overkill if:</p>
<ul>
<li>You’re working on simple projects with minimal, standard dependencies</li>
<li>Your team already has smooth onboarding and deployment processes</li>
<li>Time-to-market pressure outweighs technical debt concerns</li>
<li>Your stack consists of well-containerized microservices with stable dependencies</li>
<li>Learning new tools would significantly slow current development velocity</li>
<li>You’re working solo on personal projects without collaboration needs</li>
</ul>
<h2 id="the-honest-drawbacks">The Honest Drawbacks</h2>
<p>I have been using Nix for about 8 years now. And while I would say that Nix is an indispensible part of my life at this point, I still do have some gripes with it and the occasional hurdles while explaining some concepts and philosophies to people. I still learn new things about it everyday, and yet feel like I know very little when it comes to Nix. Here’s what I think the main drawbacks are, simplified:</p>
<h3 id="learning-investment">Learning Investment</h3>
<p>The functional programming concepts and new mental models take significant time to internalize. You’ll feel less productive initially. Finding documentation or help for some issue you have might be difficult, but not impossible. Expect at least a few weeks before you become comfortable with the basic concepts. I can personally say it’s worth the effort and pain, but in the end it depends on what you want to achieve with Nix.</p>
<h3 id="debugging-difficulty">Debugging Difficulty</h3>
<p>When things go wrong, error messages often reference store paths and internal Nix mechanics rather than familiar concepts. Troubleshooting requires understanding Nix’s execution model, which adds complexity to already difficult debugging scenarios.</p>
<h3 id="ecosystem-integration">Ecosystem Integration</h3>
<p>Some software expects traditional Linux filesystem layouts. Proprietary tools that hardcode paths to <code>/usr/bin</code> or <code>/lib</code> require workarounds. Although Nix does have built-in utilities that help with this during the build process.</p>
<p>The way you look at and interact with packages and services in the system also completely changes once you adopt the “Nix way”.</p>
<h3 id="documentation-gaps">Documentation Gaps</h3>
<p>While improving, Nix documentation can be scattered. Error messages, though better than before, can still be outright unhelpful in some cases.</p>
<h3 id="storage-requirements">Storage Requirements</h3>
<p>The Nix store grows large over time, requiring periodic garbage collection to remove unused packages. Although this can be solved by enabling the periodic garbage collector on NixOS or by running it manually.</p>
<h2 id="how-do-i-get-started">How Do I Get Started?</h2>
<p>If you’re interested in trying Nix, I would suggest:</p>
<ol>
<li><strong>Install with flakes enabled</strong>: Use the <a href="https://zero-to-nix.com/start/install">Determinate Systems Installer</a> for quick setup</li>
<li><strong>Start with temporary tools</strong>: Use <code>nix shell</code> or <code>nix run</code> to try software without installing. A list of all the official packages can be found <a href="https://search.nixos.org/">here</a></li>
<li><strong>Create a simple development environment</strong>: Use <code>nix flake init</code> in a project directory and try writing a flake for it</li>
<li><strong>Add automatic activation</strong>: Uninstall some tools you depend on after setting up developer environment with flakes and set up <code>nix-direnv</code> to load environments automatically. Or use any of the other tools that abstract Nix for you</li>
<li><strong>Join the community</strong>: The <a href="https://discourse.nixos.org/">NixOS Discourse</a> is huge and welcoming to newcomers, and so is the <a href="https://github.com/NixOS/nixpkgs">Nixpkgs</a> repository</li>
</ol>
<p>And as for the documentation or general readings on Nix:</p>
<ul>
<li><a href="https://nixos.org/guides/nix-pills/">Nix Pills</a> - Explains what Nix is in brief</li>
<li><a href="https://nixos-and-flakes.thiscute.world/">NixOS &amp; Flakes Book</a> - A good starting point to understand more about Nix Flakes</li>
<li><a href="https://nix.dev/">nix.dev</a> - Official Nix Documentation</li>
<li><a href="https://wiki.nixos.org/">NixOS Wiki</a> - Wiki for Nix and NixOS-related stuff</li>
<li><a href="https://noogle.dev/">Noogle</a> - Google, but for Nix functions</li>
<li><a href="https://search.nixos.org/">NixOS Search</a> - Search packages in the official nixpkgs repository</li>
<li><a href="https://zero-to-nix.com/">Zero to Nix</a> - A general guide for Nix and Flakes</li>
</ul>
<p>There’s also <a href="https://nixos.org/">NixOS</a>, if you would like to spend more time learning and understanding Nix better.</p>
<h2 id="why-its-worth-considering">Why It’s Worth Considering</h2>
<p>The software development landscape has grown increasingly complex. We manage more dependencies, support more platforms, and deploy to more diverse environments than ever before. Traditional package management approaches that worked for simpler systems are showing their limitations.</p>
<p>Nix offers a different path—one where environment reproducibility isn’t hoped for but guaranteed, where dependency conflicts are impossible by design, and where trying new tools doesn’t risk breaking existing setups.</p>
<p>The learning investment is significant, but for teams struggling with environment management, the payoff comes through reduced debugging time, faster onboarding, and more reliable deployments.</p>
<p>The best tool isn’t always the most popular one—sometimes it’s the one that actually solves your problems.</p>
<p><em><strong>P.S.</strong>: This website runs on my <a href="https://git.deku.moe/thunderbottom/flakes">homelab</a> running NixOS.</em></p> </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Cloudflare CEO: Football Piracy Blocks Will Claim Lives; "I Pray No One Dies" (226 pts)]]></title>
            <link>https://torrentfreak.com/cloudflare-ceo-football-piracy-blocks-will-claim-lives-i-pray-no-one-dies-250526/</link>
            <guid>44098273</guid>
            <pubDate>Mon, 26 May 2025 15:15:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://torrentfreak.com/cloudflare-ceo-football-piracy-blocks-will-claim-lives-i-pray-no-one-dies-250526/">https://torrentfreak.com/cloudflare-ceo-football-piracy-blocks-will-claim-lives-i-pray-no-one-dies-250526/</a>, See on <a href="https://news.ycombinator.com/item?id=44098273">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p><picture loading="lazy" decoding="async">
<source type="image/webp" srcset="https://torrentfreak.com/images/cloudflare-spain-s2.png.webp 500w, https://torrentfreak.com/images/cloudflare-spain-s2-300x152.png.webp 300w" sizes="auto, (max-width: 300px) 100vw, 300px">
<img loading="lazy" decoding="async" src="https://torrentfreak.com/images/cloudflare-spain-s2.png" alt="cloudflare-spain-s2" width="300" height="152" srcset="https://torrentfreak.com/images/cloudflare-spain-s2.png 500w, https://torrentfreak.com/images/cloudflare-spain-s2-300x152.png 300w, https://torrentfreak.com/images/cloudflare-spain-s2-150x76.png 150w" sizes="auto, (max-width: 300px) 100vw, 300px">
</picture>
LaLiga’s 2024/2025 season is officially over. FC Barcelona were actually crowned champions on Thursday after it became mathematically impossible for Real Madrid to conjure up seven points or more from the six points available.</p>
<p>The final matches of the season were played on Sunday but with the championship settled, would LaLiga show restraint and taper down its blocking activity? Or perhaps it would continue under the authority of judge, despite the widespread collateral damage inflicted on innocent internet users since February, a scandal now known as #laligagate.</p>
<h2>In For a Penny?</h2>
<p>The early signs did little to inspire confidence. Protest website LaLigaGate.com was hit by a total blockade but whether the site was targeted deliberately or succumbed to collateral damage is unknown.</p>
<center><em>Intentional and Unintentional Blocking Look Identical</em><picture loading="lazy" decoding="async">
<source type="image/webp" srcset="https://torrentfreak.com/images/laligagate-down.png.webp 735w, https://torrentfreak.com/images/laligagate-down-300x164.png.webp 300w" sizes="auto, (max-width: 670px) 100vw, 670px">
<img loading="lazy" decoding="async" src="https://torrentfreak.com/images/laligagate-down.png" alt="laligagate-down" width="670" height="366" srcset="https://torrentfreak.com/images/laligagate-down.png 735w, https://torrentfreak.com/images/laligagate-down-300x164.png 300w, https://torrentfreak.com/images/laligagate-down-600x328.png 600w, https://torrentfreak.com/images/laligagate-down-150x82.png 150w" sizes="auto, (max-width: 670px) 100vw, 670px">
</picture>
</center>
<p>As the <a href="https://torrentfreak.com/constitutional-court-urged-to-end-piracy-blockades-now-hurting-millions-250519/">latest data</a> suggests that mass blocking of Cloudflare in pursuit of 150 piracy platforms has negatively affected millions of innocent websites, use of the term ‘collateral damage’ may be running out of scope. </p>
<p>Unintentional overblocking became inevitable overblocking some time ago, a point certainly not lost on Cloudflare CEO Matthew Prince.</p>
<p>Posting to X last week, Prince asked if anyone wanted any general feedback, declaring that he felt “in an especially truthful mood.” The first <a href="https://x.com/cisne_bayswater/status/1924962395010584847">response</a> contained direct questions about the LaLiga controversy, the blame for which LaLiga places squarely on the shoulders of Cloudflare. </p>
<p>For the first time since Cloudflare legal action <a href="https://torrentfreak.com/judge-confirms-laligas-right-to-block-cloudflare-in-pursuit-of-iptv-pirates-250328/">failed to end LaLiga’s blocking campaign</a>, Prince weighed in with his assessment of the current situation and where he believes it’s inevitably heading.</p>
<h2>“Bonkers” Blocking Strategy</h2>
<p>“A huge percentage of the Internet sits behind us, including small businesses and emergency resources in Spain,” Prince explained. </p>
<p>“The strategy of blocking broadly through ISPs based on IPs is bonkers because so much content, including emergency services content, can be behind any IP. <a href="https://x.com/eastdakota/status/1924969551478804543">The collateral damage is vast</a> and is hurting Spanish citizens from accessing critical resources,” he added.</p>
<p>Earlier this year, various comments and statements by LaLiga suggested that its relationship with Cloudflare had reached rock bottom. It transpired that LaLiga had <a href="https://torrentfreak.com/cloudflare-asks-court-to-end-laligas-illegal-blocking-response-to-encrypted-client-hello-250220/">obtained an injunction</a> which allowed it to tackle Cloudflare and <a href="https://blog.cloudflare.com/announcing-encrypted-client-hello/">Encrypted Client Hello (ECH)</a>, but had done so without Cloudflare’s knowledge, effectively denying the company a right to respond.</p>
<p>Alongside other attacks delivered via the media, LaLiga slammed Cloudflare for refusing to cooperate. What action LaLiga had demanded still isn’t clear, but the league said that if there was any overblocking as a result, Cloudflare would have to shoulder the blame.</p>
<h2>The Potential for Deadly Consequences</h2>
<p>The scale of overblocking reported in Spain is unprecedented but since LaLiga has a court order that effectively gives Cloudflare blocking a green light, it has been doing so in bulk, every single week since February.</p>
<p>Depending on who addresses the overblocking issue, with whom and when, the league claims that collateral damage a) doesn’t exist or is minimal and/or b) is Cloudflare’s responsibility. Prince appears to have grave concerns over the scale and type of blocking taking place, warning that a worst-case scenario is inevitable.</p>
<h2>Football Piracy Blocks Will Claim Lives</h2>
<p>Despite LaLiga’s unshakable claims to the contrary, Prince believes that it’s not a case of ‘if’ disaster strikes, it’s ‘when’.</p>
<p>“It’s only a matter of time before a Spanish citizen can’t access a life-saving emergency resource because the rights holder in a football match refuses to send a limited request to block one resource versus a broad request to block a whole swath of the Internet,” Prince warned.</p>
<p>“When that unfortunately and inevitably happens and harms lives, I’m confident policy makers and courts in Spain and elsewhere will make the right policy decision. Until then, it’ll be up to users to make politicians clear on the risk. I pray no one dies.”</p>
<p>The suggestion that LaLiga’s demands were too broad, doesn’t mean that Cloudflare is refusing to help, Prince suggested. On the contrary, there’s a process available, LaLiga just needs to use it.</p>
<p>“We’ve always been happy and willing to work with rights holders in conjunction with judicial bodies to protect their content. We have a clear process that works around the world to do that, Prince explained.</p>
<h2>LaLiga Targeted Cloudflare and Others During the Weekend</h2>
<p>Live blocking data provided by <a href="https://hayahora.futbol/">hayahora.futbol</a> has proven invaluable to those documenting #laligagate in recent months and this past weekend was no different. </p>
<p>As the small sample of Cloudflare IP addresses blocked on Sunday seems to show, concerns that every IP address blocked would inevitably result in collateral damage, seem to have been trumped by the authority of the now-famous court order.</p>
<center><picture loading="lazy" decoding="async">
<source type="image/webp" srcset="https://torrentfreak.com/images/laliga-top-blocked.png.webp 975w, https://torrentfreak.com/images/laliga-top-blocked-300x513.png.webp 300w" sizes="auto, (max-width: 670px) 100vw, 670px">
<img loading="lazy" decoding="async" src="https://torrentfreak.com/images/laliga-top-blocked.png" alt="laliga-top-blocked" width="670" height="1146" srcset="https://torrentfreak.com/images/laliga-top-blocked.png 975w, https://torrentfreak.com/images/laliga-top-blocked-300x513.png 300w, https://torrentfreak.com/images/laliga-top-blocked-600x1026.png 600w, https://torrentfreak.com/images/laliga-top-blocked-88x150.png 88w, https://torrentfreak.com/images/laliga-top-blocked-898x1536.png 898w" sizes="auto, (max-width: 670px) 100vw, 670px">
</picture>
</center>
<p>The importance of strict adherence to the law was underlined by LaLiga’s Global Content Protection Manager in a recent interview.</p>
<p>José Ignacio Carrillo de Albornoz told <a href="https://www.elconfidencial.com/deportes/2025-05-19/pirateria-iptv-ilegal-futbol-carrillo-albornoz-laliga-bra_4130314/">El Confidencial</a> that without the collaboration of intermediaries, piracy will be impossible to beat. Carrillo de Albornoz concluded with a “statement of responsibility” which notes that real progress will require all parties to work together and go beyond compliance with the law.</p>
<p>“It is necessary that all links in the digital chain act legally and ethically,” he said.</p>
<center><picture loading="lazy" decoding="async">
<source type="image/webp" srcset="https://torrentfreak.com/images/laliga-recordv.png.webp 726w, https://torrentfreak.com/images/laliga-recordv-300x274.png.webp 300w" sizes="auto, (max-width: 550px) 100vw, 550px">
<img loading="lazy" decoding="async" src="https://torrentfreak.com/images/laliga-recordv.png" alt="laliga-recordv" width="550" height="502" srcset="https://torrentfreak.com/images/laliga-recordv.png 726w, https://torrentfreak.com/images/laliga-recordv-300x274.png 300w, https://torrentfreak.com/images/laliga-recordv-600x548.png 600w, https://torrentfreak.com/images/laliga-recordv-150x137.png 150w" sizes="auto, (max-width: 550px) 100vw, 550px">
</picture>
</center>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[German court sends VW execs to prison over Dieselgate scandal (651 pts)]]></title>
            <link>https://www.politico.eu/article/german-court-vw-execs-prison-dieselgate-scandal-volkswagen-environment-illegal-pollution/</link>
            <guid>44098091</guid>
            <pubDate>Mon, 26 May 2025 14:59:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.politico.eu/article/german-court-vw-execs-prison-dieselgate-scandal-volkswagen-environment-illegal-pollution/">https://www.politico.eu/article/german-court-vw-execs-prison-dieselgate-scandal-volkswagen-environment-illegal-pollution/</a>, See on <a href="https://news.ycombinator.com/item?id=44098091">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
					<p>
			<h2>
						
			<span>
				Our readers read next			</span>
					</h2>
	
	
	</p>
						
		
		
		
		
			</div><div>
					<p>
			<h2>
						
			<span>
				More from Elena Giordano			</span>
					</h2>
	
	
	</p>
						<div data-count="4" data-remainder="0" data-block-attributes="[]" data-page="0">
					
<div>
			<p><img src="https://www.politico.eu/cdn-cgi/image/width=380,height=238,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/05/21/13067739-scaled.jpg" srcset="https://www.politico.eu/cdn-cgi/image/width=480,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/05/21/13067739-scaled.jpg 480w, https://www.politico.eu/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/05/21/13067739-scaled.jpg 768w, https://www.politico.eu/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/05/21/13067739-scaled.jpg 1024w, https://www.politico.eu/cdn-cgi/image/width=1280,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/05/21/13067739-scaled.jpg 1280w, https://www.politico.eu/cdn-cgi/image/width=1440,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/05/21/13067739-scaled.jpg 1440w, https://www.politico.eu/cdn-cgi/image/width=1920,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/05/21/13067739-scaled.jpg 1920w, https://www.politico.eu/cdn-cgi/image/width=2640,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/05/21/13067739-scaled.jpg 2640w" sizes="(max-width: 380px) 100vw, 380px" alt="EU outrage grows after Israel fires ‘warning shots’ at diplomatic delegation" width="380" height="238" role="" loading="lazy" decoding="async">

					</p>
	
	
		
		<div>

			
			
			
			
			
							<h2>
										<a href="https://www.politico.eu/article/israel-army-shots-fired-eu-diplomatic-delegation-jenin-west-bank-palestine-kaja-kallas/">
						EU outrage grows after Israel fires ‘warning shots’ at diplomatic delegation					</a>
				</h2>
			
			
							<p>France, Germany and Belgium have condemned the incident and demanded an explanation.</p>
			
			<p><span>
			May 21		</span>
	
	
	
<span>
	<span>3 mins read</span>
</span>
</p>

			
			
			
			
					</div>

			</div>

<div>
			<p><img src="https://www.politico.eu/cdn-cgi/image/width=380,height=253,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/05/21/Donald-Trump-Jr-scaled.jpg" srcset="https://www.politico.eu/cdn-cgi/image/width=480,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/05/21/Donald-Trump-Jr-scaled.jpg 480w, https://www.politico.eu/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/05/21/Donald-Trump-Jr-scaled.jpg 768w, https://www.politico.eu/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/05/21/Donald-Trump-Jr-scaled.jpg 1024w, https://www.politico.eu/cdn-cgi/image/width=1280,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/05/21/Donald-Trump-Jr-scaled.jpg 1280w, https://www.politico.eu/cdn-cgi/image/width=1440,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/05/21/Donald-Trump-Jr-scaled.jpg 1440w, https://www.politico.eu/cdn-cgi/image/width=1920,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/05/21/Donald-Trump-Jr-scaled.jpg 1920w, https://www.politico.eu/cdn-cgi/image/width=2640,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/05/21/Donald-Trump-Jr-scaled.jpg 2640w" sizes="(max-width: 380px) 100vw, 380px" alt="Donald Trump Jr. hints at run for US president" width="380" height="253" role="" loading="lazy" decoding="async">

					</p>
	
	
		
		<div>

			
			
			
			
			
							<h2>
										<a href="https://www.politico.eu/article/donald-trump-jr-hints-run-us-president/">
						Donald Trump Jr. hints at run for US president					</a>
				</h2>
			
			
							<p>“Maybe one day … that calling is there,” says Trump scion.</p>
			
			<p><span>
			May 21		</span>
	
	
	
<span>
	<span>2 mins read</span>
</span>
</p>

			
			
			
			
					</div>

			</div>

<div>
			<p><img src="https://www.politico.eu/cdn-cgi/image/width=380,height=253,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/05/20/12345799.jpg" srcset="https://www.politico.eu/cdn-cgi/image/width=480,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/05/20/12345799.jpg 480w, https://www.politico.eu/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/05/20/12345799.jpg 768w, https://www.politico.eu/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/05/20/12345799.jpg 1024w, https://www.politico.eu/cdn-cgi/image/width=1280,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/05/20/12345799.jpg 1280w, https://www.politico.eu/cdn-cgi/image/width=1440,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/05/20/12345799.jpg 1440w, https://www.politico.eu/cdn-cgi/image/width=1920,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/05/20/12345799.jpg 1920w, https://www.politico.eu/cdn-cgi/image/width=2640,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/05/20/12345799.jpg 2640w" sizes="(max-width: 380px) 100vw, 380px" alt="Lithuania takes Belarus to The Hague for weaponizing migration" width="380" height="253" role="" loading="lazy" decoding="async">

					</p>
	
	
		
		<div>

			
			
			
			
			
							<h2>
										<a href="https://www.politico.eu/article/belarus-lithuania-the-hague-smuggling-migrants-borders/">
						Lithuania takes Belarus to The Hague for weaponizing migration					</a>
				</h2>
			
			
							<p>Minsk authorities stand accused of facilitating illegal crossings into the EU to sow political discord.</p>
			
			<p><span>
			May 20		</span>
	
	
	
<span>
	<span>2 mins read</span>
</span>
</p>

			
			
			
			
					</div>

			</div>

<div>
			<p><img src="https://www.politico.eu/cdn-cgi/image/width=380,height=265,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/05/16/13030935-scaled.jpg" srcset="https://www.politico.eu/cdn-cgi/image/width=480,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/05/16/13030935-scaled.jpg 480w, https://www.politico.eu/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/05/16/13030935-scaled.jpg 768w, https://www.politico.eu/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/05/16/13030935-scaled.jpg 1024w, https://www.politico.eu/cdn-cgi/image/width=1280,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/05/16/13030935-scaled.jpg 1280w, https://www.politico.eu/cdn-cgi/image/width=1440,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/05/16/13030935-scaled.jpg 1440w, https://www.politico.eu/cdn-cgi/image/width=1920,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/05/16/13030935-scaled.jpg 1920w, https://www.politico.eu/cdn-cgi/image/width=2640,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/05/16/13030935-scaled.jpg 2640w" sizes="(max-width: 380px) 100vw, 380px" alt="Trump-Putin contact ‘extremely important’ for Ukraine peace effort, Kremlin says" width="380" height="265" role="" loading="lazy" decoding="async">

					</p>
	
	
		
		<div>

			
			
			
			
			
							<h2>
										<a href="https://www.politico.eu/article/kremlin-says-donald-trump-vladimir-putin-contact-extremely-important/">
						Trump-Putin contact ‘extremely important’ for Ukraine peace effort, Kremlin says					</a>
				</h2>
			
			
							<p>Comments follow Trump announcement that he is ready to meet with Putin “as soon as we can set it up.” </p>
			
			<p><span>
			May 16		</span>
	
	
	
<span>
	<span>2 mins read</span>
</span>
</p>

			
			
			
			
					</div>

			</div>
				</div>
		
		
		
		
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google is burying the web alive (177 pts)]]></title>
            <link>https://nymag.com/intelligencer/article/google-ai-mode-search-results-bury-the-web.html</link>
            <guid>44097490</guid>
            <pubDate>Mon, 26 May 2025 14:00:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nymag.com/intelligencer/article/google-ai-mode-search-results-bury-the-web.html">https://nymag.com/intelligencer/article/google-ai-mode-search-results-bury-the-web.html</a>, See on <a href="https://news.ycombinator.com/item?id=44097490">Hacker News</a></p>
<div id="readability-page-1" class="page"><section data-editable="main" data-track-zone="main">  <article role="main" data-track-type="article-detail" data-uri="nymag.com/intelligencer/_components/article/instances/cmb16qnjt000l0iismxem2er8@published" data-content-channel="Technology" data-crosspost="" data-type="News-Commentary and Analysis" data-syndication="original" data-headline="Google Is Burying the Web Alive" data-authors="John Herrman" data-publish-date="2025-05-26" data-tags="screen time, google, artificial intelligence, search engines, the internet, big tech, ai chatbots" data-issue-date="" data-components-count="16" data-canonical-url="http://nymag.com/intelligencer/article/google-ai-mode-search-results-bury-the-web.html">


  
  
  
  <header>
    <div>
          

            <p><span>
                  <a href="https://nymag.com/author/john-herrman/" rel="author">
                    <img src="https://pyxis.nymag.com/v1/imgs/6a1/1fd/b7daa97d945a1ce337bc16618022639a01-john-herrman-intel.2x.rsquare.w168.jpg" alt="Portrait of John Herrman">
                  </a>
                </span>
            <span data-editable="bylines">
            <p><span>By</span> <span>
        ,
          <span>a tech columnist at Intelligencer</span><span>&nbsp;</span>
          <span>Formerly, he was a reporter and critic at the New York Times and co-editor of The Awl.</span>
      </span></p>

              </span>
          </p>
        </div>
      
    
  </header>
  <section>
    
    <div id="intelligencer-zephr-anchor" data-editable="content">
      <div>
          <div>
            <picture> <source media="(min-resolution: 192dpi) and (min-width: 1180px), (-webkit-min-device-pixel-ratio: 2) and (min-width: 1180px)" srcset="https://pyxis.nymag.com/v1/imgs/6c0/285/4cb731bcff029a47aa644ab8d45643cf9f-google-search-.2x.rhorizontal.w700.jpg 2x" width="700" height="467"> <source media="(min-width: 1180px) " srcset="https://pyxis.nymag.com/v1/imgs/6c0/285/4cb731bcff029a47aa644ab8d45643cf9f-google-search-.rhorizontal.w700.jpg" width="700" height="467"> <source media="(min-resolution: 192dpi) and (min-width: 768px), (-webkit-min-device-pixel-ratio: 2) and (min-width: 768px)" srcset="https://pyxis.nymag.com/v1/imgs/6c0/285/4cb731bcff029a47aa644ab8d45643cf9f-google-search-.2x.rhorizontal.w700.jpg 2x" width="700" height="467"> <source media="(min-width: 768px)" srcset="https://pyxis.nymag.com/v1/imgs/6c0/285/4cb731bcff029a47aa644ab8d45643cf9f-google-search-.rhorizontal.w700.jpg" width="700" height="467"> <source media="(min-resolution: 192dpi), (-webkit-min-device-pixel-ratio: 2)" srcset="https://pyxis.nymag.com/v1/imgs/6c0/285/4cb731bcff029a47aa644ab8d45643cf9f-google-search-.2x.rsquare.w400.jpg" width="400" height="400"> <img src="https://pyxis.nymag.com/v1/imgs/6c0/285/4cb731bcff029a47aa644ab8d45643cf9f-google-search-.rsquare.w400.jpg" data-content-img="" width="400" height="400" fetchpriority="high"> </picture>
          </div>
            <div>
              <p><span>Photo-Illustration: Intelligencer</span>
              </p>
            </div>
              </div>
        <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/cmb16skyv003l3b75xennbqe3@published" data-word-count="132">By now, there’s a good chance you’ve encountered <a href="https://nymag.com/intelligencer/article/what-if-googles-biggest-problem-isnt-ai.html">Google</a>’s <a href="https://nymag.com/intelligencer/article/why-ai-search-blew-up-in-googles-face.html">AI Overviews</a>, possibly thousands of times. Appearing as blurbs at the top of search results, they attempt to settle your queries before you scroll —&nbsp;to offer answers, or relevant information, gleaned from websites that you no longer need to click on. The feature was officially rolled out at Google’s developer conference last year and had been in testing for quite some time before that; on the occasion of this year’s conference, the company characterized it as “one of the most successful launches in Search in the past decade,” a strangely narrow claim that is almost certainly true: Google put AI summaries on top of everything else, <em>for everyone,</em> as if to say, “Before you use our main product, see if this works instead.”</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/cmb16smj6003u3b752xzbw234@published" data-word-count="166">This year’s conference included another change to search, this one more profound but less aggressively deployed. “AI Mode,” which has similarly been in beta testing for a while, will appear as an option for all users. It’s not like AI Overviews; that is, it’s not an extra module taking up space on a familiar search-results page but rather a complete replacement for conventional search. It’s Google’s “most powerful AI search, with more advanced reasoning and multimodality, and the ability to go deeper through follow-up questions and helpful links to the web,” the company says, “breaking down your question into subtopics and issuing a multitude of queries simultaneously on your behalf.” It’s available to everyone. It’s a lot like using AI-first chatbots that have search functions, like those from OpenAI, Anthropic, and Perplexity, and Google says it’s destined for greater things than a small tab. “As we get feedback, we’ll graduate many features and capabilities from AI Mode right into the core Search experience,” the company says.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/cmb16smj8003v3b75lnhxrn6u@published" data-word-count="95">I’ve been testing AI Mode for a few months now, and in some ways it’s less radical than it sounds and (at first) feels. It resembles the initial demos of AI search tools, including those by Google, meaning it responds to many questions with clean, ad-free answers. Sometimes it answers in extended plain language, but it also makes a lot of lists and pulls in familiar little gridded modules — especially when you ask about things you can buy —&nbsp;resulting in a product that, despite its chatty interface, feels an awful lot like … search.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/cmb16smj9003w3b75yjto7g9i@published" data-word-count="45">Again, now you can try it yourself, and your mileage may vary; it hasn’t drawn me away from Google proper for a lot of thoughtless rote tasks, but it’s competitive with <a href="https://nymag.com/intelligencer/article/openai-chatgpt-ai-cheating-education-college-students-school.html">ChatGPT</a> for the expanding range of searchish tasks you might attempt with a chatbot.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/cmb16smj9003x3b75nlrj12el@published" data-word-count="60">From the very first use, however, AI Mode crystallized something about Google’s priorities and in particular its relationship to the web from which the company has drawn, and returned, many hundreds of billions of dollars of value. AI Overviews demoted links, quite literally pushing content from the web <em>down </em>on the page, and summarizing its contents for digestion without clicking:</p>

  <div data-uri="nymag.com/intelligencer/_components/image/instances/cmb17xauj00583b75mot5rw3s@published" data-editable="settings">
    
    <p><span>Photo-Illustration: Intelligencer; Screenshot: Google</span>
    </p>
</div>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/cmb16smj9003y3b75lx2t35qn@published" data-word-count="55">Meanwhile, AI Mode all but <em>buries</em> them, not just summarizing their content for reading within Google’s product but inviting you to explore and expand on those summaries by asking more questions, rather than clicking out. In many cases, links are retained merely to provide backup and sourcing, included as footnotes and appendices rather than destinations:</p>

  <div data-uri="nymag.com/intelligencer/_components/image/instances/cmb17xl0d005e3b75x5hvvhym@published" data-editable="settings">
    
    <p><span>Photo-Illustration: Intelligencer; Screenshot: Google</span>
    </p>
</div>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/cmb16smj9003z3b758uul90hq@published" data-word-count="117">This is typical with AI search tools and all but inevitable now that such things are possible. <a href="https://nymag.com/intelligencer/article/why-ai-search-blew-up-in-googles-face.html">In terms of automation</a>, this means companies like OpenAI and Google are mechanizing some of the “work” that goes into using tools like Google search, removing, when possible, the step where users leave their platforms and reducing, in theory, the time and effort it takes to navigate to somewhere else when necessary. In even broader terms —&nbsp;contra Google’s effort to brand this as “going beyond information to intelligence” —&nbsp;this is an example of how LLMs offer <a href="https://nymag.com/intelligencer/article/for-big-tech-the-future-is-agi-what-about-the-rest-of-us.html">different ways to interact with much of the same information</a>: summarization rather than retrieval, regeneration rather than fact-finding, and vibe-y reconstruction over deterministic reproduction.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/cmb16smja00403b750cs445ua@published" data-word-count="60">This is interesting to think about and often compelling to use but leaves unresolved one of the <a href="https://nymag.com/intelligencer/2023/02/google-and-bing-are-a-mess-will-ai-solve-their-problems.html">first questions</a> posed by chatbots-as-search: Where will they get all the data they need to <em>continue</em> to work well? When Microsoft and Google showed off their first neo-search mockups in 2023, which are pretty close to today’s AI mode, it revealed <a href="https://nymag.com/intelligencer/2023/02/google-and-bing-are-a-mess-will-ai-solve-their-problems.html">a dilemma</a>:</p>

  <blockquote data-uri="nymag.com/intelligencer/_components/blockquote/instances/cmb17xx2u005m3b75pbw04d4t@published" data-editable="text" data-word-count="66"><p>Search engines still provide the de facto gateway to the broader web, and have a deeply codependent relationship with the people and companies whose content they crawl, index, and rank; a Google that instantly but sometimes unreliably summarizes the websites to which it used to send people would destroy that relationship, and probably a lot of websites, including the ones on which its models were trained.</p></blockquote>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/cmb16smjb00423b7540uam6rd@published" data-word-count="195">And, well, yep! Now, both AI Overviews and AI Mode, when they aren’t occasionally hallucinating, produce relatively clean answers that benefit in contrast to increasingly degraded regular search results on Google, which are full of hyperoptimized and duplicative spamlike content designed <a href="https://nymag.com/intelligencer/article/how-product-recommendations-broke-google.html">first and foremost</a> with the demands of Google’s ranking algorithms and advertising in mind. AI Mode feels one step further removed from that ecosystem and once again looks good in contrast, a placid textual escape from Google’s own mountain of links that look like ads and ads that look like links (of course, Google is already working on ads for both Overviews and AI Mode). In its drive to embrace AI, Google is further concealing the raw material that fuels it, demoting links as it continues to ingest them for abstraction. Google may still retain plenty of <em>attention </em>to monetize and perhaps keep even more of it for itself, now that it doesn’t need to send people elsewhere; in the process, however, it really <em>is</em> starving the web that supplies it with data on which to train and<em> </em>from which to draw up-to-date details. (Or, one might say, putting it out of its misery.)</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/cmb16smjb00433b754e1zh54e@published" data-word-count="84">Two years later, Google has become more explicit about the extent to which it’s moving on from the “you provide us results to rank, and we send you visitors to monetize” bargain, with the head of search telling <a href="https://www.theverge.com/google-io/670439/google-ai-mode-search-io-2025">The Verge</a>, “I think the search results page was a construct.” Which is true, as far as it goes, but also a remarkable thing to hear from a company that’s communicated carefully and voluminously to website operators about small updates to its search algorithms for years.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/cmb16smjb00443b75nurt0wq2@published" data-word-count="152">I don’t doubt that Google has been thinking about this stuff for a while and that there are people at the company who deem it strategically irrelevant or at least of secondary importance to winning the AI race —&nbsp;the <em>fate of the web</em> might not sound terribly important when your bosses are talking nonstop about cashing out its accumulated data and expertise for <a href="https://nymag.com/intelligencer/article/for-big-tech-the-future-is-agi-what-about-the-rest-of-us.html">AGI</a>. I also don’t want to be precious about the web as it actually exists in 2025, nor do I suggest that websites working with or near companies like Meta and Google should have expected anything but <a href="https://nymag.com/intelligencer/2023/04/how-buzzfeed-news-went-bust.html">temporary, incidental alignment</a> with their businesses. If I had to guess, the future of Google search looks more like AI Overviews than AI mode —&nbsp;a jumble of widgets and modules including and united by AI-generated content, rather than a clean break — if only for purposes of sustaining Google’s multi-hundred-billion-dollar advertising business.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/cmb16smjb00453b75vrxcg0bj@published" data-word-count="197">But I also don’t want to assume Google knows exactly how this stuff will play out for<em> Google</em>, much less what it will actually mean for millions of websites, and their visitors, if Google stops sending as many people beyond its results pages. Google’s push into productizing generative AI is substantially fear-driven, faith-based, and informed by the actions of competitors that are far less invested in and dependent on the vast collection of behaviors —&nbsp;websites full of content authentic and inauthentic, volunteer and commercial, social and antisocial, archival and up-to-date —&nbsp;that make up what’s left of the web and have far less to lose. Maybe, in a few years, a <a href="https://stratechery.com/2025/the-agentic-web-and-original-sin/">fresh economy</a> will grow around the new behaviors produced by searchlike AI tools; perhaps companies like OpenAI and Google will sign a bunch more <a href="https://nymag.com/intelligencer/2023/12/what-do-ai-companies-want-with-the-media.html">licensing</a> deals; conceivably, this style of search automation simply collapses the marketplace supported by search, leveraging training based on years of scraped data to <a href="https://nymag.com/intelligencer/article/ai-ate-the-web-now-its-coming-back-for-seconds.html">do more with less</a>. In any case, the signals from Google —&nbsp;despite its <a href="https://searchengineland.com/google-ai-overviews-search-clicks-fell-report-455498">unconvincing suggestions</a> to the contrary — are clear: It’ll do anything to win the AI race. If that means burying the web, then so be it.</p>

  


    </div>

    


          



      <span>Google Is Burying the Web Alive</span>



  </section>
  
</article>

  

</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Engineers discover new class of materials that passively harvest water from air (325 pts)]]></title>
            <link>https://blog.seas.upenn.edu/penn-engineers-discover-a-new-class-of-materials-that-passively-harvest-water-from-air/</link>
            <guid>44097144</guid>
            <pubDate>Mon, 26 May 2025 13:14:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.seas.upenn.edu/penn-engineers-discover-a-new-class-of-materials-that-passively-harvest-water-from-air/">https://blog.seas.upenn.edu/penn-engineers-discover-a-new-class-of-materials-that-passively-harvest-water-from-air/</a>, See on <a href="https://news.ycombinator.com/item?id=44097144">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-8868">
	
		
		
		<!-- .entry-header -->
		
	<div>
		<p><span>A serendipitous observation in a Chemical Engineering lab at Penn Engineering has led to a surprising discovery: a new class of nanostructured materials that can pull water from the air, collect it in pores and release it onto surfaces without the need for any external energy. <a href="https://www.science.org/doi/10.1126/sciadv.adu8349">The research</a>, published in </span><i><span>Science Advances</span></i><span>, was conducted by an interdisciplinary team, including </span><a href="https://directory.seas.upenn.edu/daeyeon-lee/"><span>Daeyeon Lee</span></a><span>, Russell Pearce and Elizabeth Crimian Heuer Professor in Chemical and Biomolecular Engineering (CBE), </span><a href="https://directory.seas.upenn.edu/amish-j-patel/"><span>Amish Patel</span></a><span>, Professor in CBE, Baekmin Kim, a postdoctoral scholar in Lee’s lab and first author, and </span><a href="https://www.professoren.tum.de/en/guldin-stefan"><span>Stefan Guldin</span></a><span>, Professor in Complex Soft Matter at the Technical University of Munich. Their work describes a material</span> <span>that</span> <span>could open the door to new ways to collect water from the air in arid regions and devices that cool electronics or buildings using the power of evaporation.</span></p>
<figure id="attachment_8869" aria-describedby="caption-attachment-8869"><img decoding="async" src="https://blog.seas.upenn.edu/wp-content/uploads/2025/05/Daeyeon-Lee-Amish-Patel-research-PR_Amphiphilic-nanopore-team-headshots.png" alt="" width="2240" height="1260" srcset="https://blog.seas.upenn.edu/wp-content/uploads/2025/05/Daeyeon-Lee-Amish-Patel-research-PR_Amphiphilic-nanopore-team-headshots.png 2240w, https://blog.seas.upenn.edu/wp-content/uploads/2025/05/Daeyeon-Lee-Amish-Patel-research-PR_Amphiphilic-nanopore-team-headshots-300x169.png 300w, https://blog.seas.upenn.edu/wp-content/uploads/2025/05/Daeyeon-Lee-Amish-Patel-research-PR_Amphiphilic-nanopore-team-headshots-1024x576.png 1024w, https://blog.seas.upenn.edu/wp-content/uploads/2025/05/Daeyeon-Lee-Amish-Patel-research-PR_Amphiphilic-nanopore-team-headshots-768x432.png 768w, https://blog.seas.upenn.edu/wp-content/uploads/2025/05/Daeyeon-Lee-Amish-Patel-research-PR_Amphiphilic-nanopore-team-headshots-1536x864.png 1536w, https://blog.seas.upenn.edu/wp-content/uploads/2025/05/Daeyeon-Lee-Amish-Patel-research-PR_Amphiphilic-nanopore-team-headshots-2048x1152.png 2048w" sizes="(max-width: 2240px) 100vw, 2240px"><figcaption id="caption-attachment-8869">Research team including Daeyone Lee (left), Amish Patel (center) and Stefan Guldin (right).</figcaption></figure>
<p><span>“We weren’t even trying to collect water,” says Lee. “We were working on another project testing the combination of hydrophilic nanopores and hydrophobic polymers when R Bharath Venkatesh, a former Ph.D. student in our lab, noticed water droplets appearing on a material we were testing. It didn’t make sense. That’s when we started asking questions.”</span></p>
<p><span>Those questions led to an in-depth study of a new type of amphiphilic nanoporous material: one that blends water-loving (hydrophilic) and water-repelling (hydrophobic) components in a unique nanoscale structure. The result is a material that both captures moisture from air and simultaneously pushes that moisture out as droplets.</span></p>
<p><b>Water-Collecting Nanopores</b></p>
<p><span>When water condenses on surfaces, it usually requires either a drop in temperature or very high humidity levels. Conventional water harvesting methods rely on these principles, often requiring energy input to chill surfaces or a dense fog to form to collect water passively from humid environments. But Lee and Patel’s system works differently.</span></p>
<p><span>Instead of cooling, their material relies on capillary condensation, a process where water vapor condenses inside tiny pores even at lower humidity. This is not new. What </span><i><span>is</span></i><span> new is that in their system, the water doesn’t just stay trapped inside the pores, as it usually does in these types of materials.</span></p>
<p><span>“In typical nanoporous materials, once the water enters the pores, it stays there,” explains Patel. “But in our material, the water moves, first condensing inside the pores, then emerging onto the surface as droplets. That’s never been seen before in a system like this, and at first we doubted our observations.”</span></p>
<p><b>A Material That Defies Physics&nbsp;</b></p>
<p><span>Before they understood what was happening, the researchers first thought that water was simply condensing onto the surface of the material due to</span> <span>an artifact of their experimental setup, such as a temperature gradient in the lab. To rule that out, they increased the thickness of the material to see if the amount of water collected on the surface would change.&nbsp;</span></p>
<p><span>“If what we were observing was due to surface condensation alone, the thickness of the material wouldn’t change the amount of water present,” explains Lee.&nbsp;</span></p>
<p><span>But, the total amount of water collected increased as the film’s thickness increased, proving that the water droplets forming on the surface came from inside the material.</span></p>
<p><span>Even more surprising: the droplets didn’t evaporate quickly, as thermodynamics would predict.&nbsp;</span></p>
<p><span>“According to the curvature and size of the droplets, they should have been evaporating,” says Patel. “But they were not; they remained stable for extended periods.”</span></p>
<p><span>With a material that could potentially defy the laws of physics on their hands, Lee and Patel sent their design off to a collaborator to see if their results were replicable.&nbsp;</span></p>
<p><span>“We study porous films under a wide range of conditions, using subtle changes in light polarization to probe complex nanoscale phenomena,” says Guldin. “But we’ve never seen anything like this. It’s absolutely fascinating and will clearly spark new and exciting research.”</span></p>
<p><!--[if lt IE 9]><script>document.createElement('video');</script><![endif]-->
<video id="video-8868-1" width="1160" height="653" preload="metadata" controls="controls"><source type="video/mp4" src="https://blog.seas.upenn.edu/wp-content/uploads/2025/05/Daeyeon-Lee-Amish-Patel-research-PR_Amphiphilic-nanopore-video.mp4?_=1"><a href="https://blog.seas.upenn.edu/wp-content/uploads/2025/05/Daeyeon-Lee-Amish-Patel-research-PR_Amphiphilic-nanopore-video.mp4">https://blog.seas.upenn.edu/wp-content/uploads/2025/05/Daeyeon-Lee-Amish-Patel-research-PR_Amphiphilic-nanopore-video.mp4</a></video></p>
<p><span>Nanopores in action under electron microscope imagery showing water droplets forming and being replenished by stored water in the material itself.</span></p>
<p><b>A Stabilized Cycle of Condensation and Release</b></p>
<p><span>It turns out that they had created a material with just the right balance of water-attracting nanoparticles and water-repelling plastic — polyethylene — to create a nanoparticle film with this special property.</span></p>
<p><span>“We accidentally hit the sweet spot,” says Lee. “The droplets are connected to hidden reservoirs in the pores below. These reservoirs are continuously replenished from water vapor in the air, creating a feedback loop made possible by this perfect balance of water-loving and water-repelling materials.”</span></p>
<p><b>A Platform for Passive Water Harvesting and More</b></p>
<p><span>Beyond the physics-defying behavior, the materials’ simplicity is part of what makes them so promising. Made from common polymers and nanoparticles using scalable fabrication methods, these films could be integrated into passive water harvesting devices for arid regions, surfaces for cooling electronics or smart coatings that respond to ambient humidity.</span></p>
<p><span>“We’re still uncovering the mechanisms at play,” says Patel. “But the potential is exciting. We’re learning from biology — how cells and proteins manage water in complex environments — and applying that to design better materials.”</span></p>
<p><span>“This is exactly what Penn does best, bringing together expertise in chemical engineering, materials science, chemistry and biology to solve big problems,” adds Lee.</span></p>
<p><span>The next steps include studying how to optimize the balance of hydrophilic and hydrophobic components, scale the material for real-world use and investigating how to make the collected droplets roll off surfaces efficiently.</span></p>
<p><span>Ultimately, the researchers hope this discovery will lead to technologies that offer clean water in dry climates or more sustainable cooling methods using only the water vapor already in the air.</span></p>
<p><i><span>This work was supported by National Science Foundation grants NSF-2309043 and NSF-1933704, a Department of Energy grant (DE-SC0021241), a Semilab UCL Chemical Engineering Impact Ph.D. Studentship, a National Science Foundation Graduate Research Fellowships Program grant (DGE-2236662), an Alfred P. Sloan Research Foundation grant (FG-2017-9406) and a Camille &amp; Henry Dreyfus Foundation grant (TG-19-033).</span></i></p>
	</div><!-- .entry-content -->
	
	<!-- .entry-footer -->
	
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Particle Life simulation in browser using WebGPU (170 pts)]]></title>
            <link>https://lisyarus.github.io/blog/posts/particle-life-simulation-in-browser-using-webgpu.html</link>
            <guid>44096808</guid>
            <pubDate>Mon, 26 May 2025 12:28:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lisyarus.github.io/blog/posts/particle-life-simulation-in-browser-using-webgpu.html">https://lisyarus.github.io/blog/posts/particle-life-simulation-in-browser-using-webgpu.html</a>, See on <a href="https://news.ycombinator.com/item?id=44096808">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page-content">
            
            <br><center><p>Particle Life simulation in browser using WebGPU</p></center><br>
            <center><span>2025 May 15</span></center>

            <p><i>If you don't care about the explanation and want a direct link to the simulation, <a href="https://lisyarus.github.io/webgpu/particle-life.html">here you go</a>.</i></p>

            <p>You might know that I'm a <a href="https://lisyarus.github.io/blog/posts/soft-body-physics.html">sucker</a> for <a href="https://lisyarus.github.io/blog/posts/structural-mechanics-2.html">physics</a> <a href="https://lisyarus.github.io/blog/posts/simulating-water-over-terrain.html">simulations</a>, and <a href="https://lisyarus.itch.io/particle-simulator">particle simulations</a> in particular. Usually I implement something based on conventional physics, but recently I've stumbled upon a funny non-physical model that can display...well, let's call it <i>life-like</i> behavior.</p>

            <p>I've made a prototype in C++ using my pet engine, but then I decided it would be fun to try making it run in browser, using the WebGPU API. It works surprisingly well, and can produce fun simulations like this:</p>

            <center><video muted="" loop="" controls=""><source src="https://lisyarus.github.io/blog/media/particle-life/simulation-1.mp4" type="video/mp4"></video></center>

            <p>In this post I'll describe how it works under the hood.</p>

            <h2>Contents</h2>
            <ul id="contents"></ul>

            <h2 id="section-the-particle-life-model">The Particle Life Model</h2>

            <p>There are quite a number of resources (primarily, videos) online that talk about this model, for example <a href="https://www.youtube.com/watch?v=4vk7YvBYpOs">this</a>, <a href="https://www.youtube.com/watch?v=p4YirERTVF0">this</a>, and <a href="https://www.youtube.com/watch?v=Z_zmZ23grXE">this</a>, and also <a href="https://www.youtube.com/watch?v=scvuli-zcRc&amp;t=396s">this one</a> talks about the exact formulas used in the simulation. Due to a rather pretentious name composed of two overused words, googling "particle life" doesn't bring stuff of any relevance (apart from the YouTube videos), so I wasn't able to trace the origins of this model. <a href="https://www.youtube.com/watch?v=xiUpAeos168">One video</a> claims that this model was inspired by some microbiology studies, which seems believable given how organic and mobile the resulting simulations look.</p>

            <p>This model isn't in any way related to Conway's Game of Life (despite the name). It's more like <a href="https://google-research.github.io/self-organising-systems/particle-lenia">Particle Lenia</a>, if anything, though the rules are much simpler.</p>

            <p>The core idea goes like this: we run a typical physics simulation with point particles, but the forces between particles can be <i>asymmetric</i>: particle A can <i>attract</i> particle B, but particle B can <i>repel</i> particle A (or attract it with a larger/smaller force, etc). This immediately violates Newton's third law, thus it violates almost all conservation laws (specifically, energy, momentum, and angular momentum conservation).</p>

            <p>This might sound strange and unphysical, but</p>

            <ol>
                <li>We're not bound by physical laws when coding simulations,</li>
                <li>This brings an extra source of energy, which is kinda what living organisms do.</li>
            </ol>

            <p>Living creatures consume food and oxygen (and sometimes other chemicals) and turn them into energy, which they can use to move and find more consumable stuff. The asymmetric forces of Particle Life emulate that by skipping the chemicals-to-energy cycle and just adds extra energy to the system.</p>

            <p>It also allows particles to chase each other, e.g. in the scenario above particle B will constantly chase after particle A, which will in turn run away from particle B, which also kinda emulates predator-prey stuff from biology. However, in this model particles aren't created or destroyed, so particle B will never actually "eat" particle A.</p>

            <p>For simplicity and to add some coherence to the simulation, particles are usually split into several <i>types</i>, with a table specifying the interaction for each pair of particle types. Specifically, I used the model suggested by <a href="https://www.youtube.com/watch?v=xiUpAeos168">this video</a>:</p>

            <ul>
                <li>For any two particle types A and B, the force experienced by A from B consists of two parts: the <i>interaction force</i>, and the <i>collision force</i>.</li>
                <li>Interaction force can be either attractive or repulsive.</li>
                <li>Collision force is always repulsive.</li>
                <li>Both forces are specified by a radius and a strength factor. Positive strength means attraction, negative strength means repulsion. (For collision force it is always repulsion).</li>
                <li>Collision force radius is always smaller than interaction force radius (i.e. collision is close-range, interaction is far-range).</li>
                <li>Collision force strength is always larger than interaction force strength.</li>
                <li>Both forces decrease linearly with distance, upon reaching the radius value, at which they are zero.</li>
            </ul>

            <p>In formulas, the linear dependence of force on distance can be written as</p><p>

            \[ F(r) = A\cdot \max\left(0, \frac{|r-R|}{R}\right) \]

            </p><p>where \(A\) is the force strength (negative for repulsion), \(R\) is the force radius, and \(r\) is the distance between the two particles.</p>

            <p>Here's a plot of force as a function of distance, with \(A=5\) and \(R=10\):</p>

            <center><img src="https://lisyarus.github.io/blog/media/particle-life/plot-force.png"></center>

            <p>And here's the corresponding potential energy, if you're into some physics:</p>

            <center><img src="https://lisyarus.github.io/blog/media/particle-life/plot-energy.png"></center>

            <p>Here's the <a href="https://www.desmos.com/calculator/ram14bkp1r">Desmos link</a> where you can play with these values.</p>

            <p>If we add the collision force and, say, an attraction force, we get this plot of force vs distance:</p>

            <center><img src="https://lisyarus.github.io/blog/media/particle-life/plot-force-combined.png"></center>

            <p>And the potential energy:</p>

            <center><img src="https://lisyarus.github.io/blog/media/particle-life/plot-energy-combined.png"></center>

            <p>Again, here's the <a href="https://www.desmos.com/calculator/nebtb6ltme">Desmos link</a> for these.</p>

            <p>As you can see, for the collision + attraction case, there's a local minimum at some distance, where the force is equal to zero. This would be the "sweet spot" for particles, i.e. they'll tend to maintain this distance if possible.</p>

            <p>Notice that the force (and thus also the energy) doesn't go to infinity when distance is close to zero, like it does in a typical \(\frac{1}{r}\) potential from gravity or electromagnetism. This means that our collision force has finite strength, and can be overcome by sufficiently strong other forces, or if the collision radius is small enough. E.g. on this screenshot multiple particles merged into one:</p>

            <center><img src="https://lisyarus.github.io/blog/media/particle-life/merged.png"></center>

            <p>This is fine, though, since it produces interesting behaviours, and it prevents our forces from escalating too much (which typically happens with a \(\frac{1}{r}\) potential simulations).</p>

            <p>I also have a global constant friction parameter which simply decreases all velocities with time. This is to keep the simulation somewhat stable, because otherwise it constantly gains energy, and everything just accelerates to infinity.</p>

            <h2 id="section-why-webgpu">Why WebGPU?</h2>

            <p>It should be clear why I decided to move the simulation to the GPU — after all, that's a typical massively parallel task, and GPUs shine at those. But why specifically WebGPU?</p>

            <p>If you've been following me for a while, you might know that I'm in awe with WebGPU. I've been using OpenGL for more than a decade and I'm sick of it. It's a very old, stupidly inconsistent API full of legacy decisions, which stopped evolving some 8 years ago. However, Vulkan, which is the supposed alternative modern API, takes 1000 lines of setup work <i>just to show a triangle on screen</i>, without even any vertex buffers &amp; attributes. Don't get me wrong, Vulkan is pretty cool, but I just don't have <i>that</i> much spare time to use it in my pet projects.</p>

            <p>Now, WebGPU fills this niche for me. It is a modern &amp; clean API that at the same time is reasonably non-verbose. It feels just like what real-time graphics should be about, — or at least that's what I feel while using it. I already used it in a few desktop projects (via <a href="https://github.com/gfx-rs/wgpu-native">wgpu-native</a>), including a <a href="https://github.com/lisyarus/webgpu-raytracer">full Monte-Carlo raytracer</a> and a <a href="https://github.com/lisyarus/webgpu-shallow-water">shallow water simulator</a>, and I'm using it in my current main project, which is a <a href="https://www.youtube.com/playlist?list=PLSGI94QoFYJwGaieAkqw5_qfoupdppxHN">medieval village building game</a>, and I'm really happy with this API.</p>

            <p>Furthermore, being a modern API, it supports stuff like compute shaders and atomics, which are crucial for this simulation, as we'll see later. As far as I know, WebGL doesn't support these features.</p>

            <p>And, as a nice bonus, it actually runs in browser! Or, at least in some experimental versions of some browsers, under some flags, but the situation should get better with time.</p>

            <h2 id="section-simulation-loop">Simulation loop</h2>

            <p>So, how do we simulate particles with WebGPU? The simulation loop itself is rather straightforward:</p>

            <ol>
                <li>If not paused,</li>
                <ol>
                    <li>For each particle, compute the forces acting on this particle by other particles, and add the resulting acceleration to the particle's velocity</li>
                    <li>For each particle, move its position using the newly-computed velocity</li>
                    <li>Apply boundary conditions</li>
                </ol>
                <li>Render the particles</li>
            </ol>

            <p>This is essentially the <a href="https://en.wikipedia.org/wiki/Semi-implicit_Euler_method">semi-implicit Euler integrator</a>, which is easy to code and has some nice theoretical properties.</p>

            <p>I store the particles in a single large GPU buffer. A particle is just a simple struct like this:</p>

            <pre><code>struct Particle
{
    // Position
    x : f32,
    y : f32,

    // Velocity
    vx : f32,
    vy : f32,

    // Type
    species : f32,
}</code></pre>

            <p><i>I'm not storing position and velocity as <code>vec2f</code> just for alignment requirements, and I'm storing the particle type as an <code>f32</code> just to be able to load particles from JavaScript as a single large <code>Float32Array</code>.</i></p>

            <p>So, a particle is just 5 floats, i.e. 20 bytes. In theory, we could just run a single compute shader per particle, which loops over all particles, computes all the forces, and updates velocity and position. However, computing forces quickly becomes the bottleneck: it's a \(O(N^2)\) operation in total, because we need to compute all pairwise forces between all particles. This severely limits the number of particles we can process. My earlier CPU implementation only got to 4096 particles, even with multithreading.</p>

            <p>We need to be clever about computing forces, which is why this is a separate compute pass. After that, things are pretty straightforward: a single compute shader invocation for each particle moves it forward using the computed velocity, then handles collisions with simulation borders:</p>

            <pre><code>@group(0) @binding(0) var&lt;storage, read_write&gt; particles : array&lt;Particle&gt;;

@group(1) @binding(0) var&lt;uniform&gt; simulationOptions : SimulationOptions;

@compute @workgroup_size(64)
fn particleAdvance(@builtin(global_invocation_id) id : vec3u)
{
    // Protect against reading &amp; writing past array end
    if (id.x &gt;= arrayLength(&amp;particles)) {
        return;
    }

    let width = simulationOptions.right - simulationOptions.left;
    let height = simulationOptions.top - simulationOptions.bottom;

    var particle = particles[id.x];

    // Apply friction
    particle.vx *= simulationOptions.friction;
    particle.vy *= simulationOptions.friction;

    // Move particle using velocity
    particle.x += particle.vx * simulationOptions.dt;
    particle.y += particle.vy * simulationOptions.dt;

    // Collide with borders
    if (particle.x &lt; simulationOptions.left) {
        particle.x = simulationOptions.left;
        particle.vx *= -1.0;
    }

    if (particle.x &gt; simulationOptions.right) {
        particle.x = simulationOptions.right;
        particle.vx *= -1.0;
    }

    if (particle.y &lt; simulationOptions.bottom) {
        particle.y = simulationOptions.bottom;
        particle.vy *= -1.0;
    }

    if (particle.y &gt; simulationOptions.top) {
        particle.y = simulationOptions.top;
        particle.vy *= -1.0;
    }

    // Write the new state of the particle
    particles[id.x] = particle;
}</code></pre>

            <p><i>(My actual code also handles mouse interaction &amp; looping borders, but the idea is the same.)</i></p>

            <p>The <code>simulationOptions.friction</code> is actually something like \(\exp(-\text{friction}\cdot\Delta t)\), for reasons explained in <a href="https://lisyarus.github.io/blog/posts/exponential-smoothing.html">my other article</a>.</p>

            <h2 id="section-computing-interactions">Computing interactions</h2>

            <p>Before advancing the particles, though, we need to compute the inter-particle forces. The main trick is to use the fact that all forces have finite radius, and after a certain distance all forces are zero. In my implementation, I only allow forces with radius up to 32. Thus, I know that any pair of particles further than 32 units of distance apart cannot interact at all.</p>

            <p>To utilize this, we use the typical approach of spatial hashing/binning: make a square grid with cells/bins of size \(32\times 32\), sort the particles into these bins, then compute interactions only between neighbouring bins. This sounds easy, and is actually almost trivial to implement on the CPU (e.g. in C++ just make a 2D array, each storing <code>std::vector&lt;particle&gt;</code>, and you're good to go). However, building such data structures on the GPU takes a lot of effort — we can't, for example, allocate GPU memory directly from a shader!.</p>

            <p>Instead, we'll use a linearized structure to store the bins. Here's how it works: we'll have an array of particles, where particles that reside in the same bin occupy a contiguous section of this array. Then, we'll also have an array which stores the start of this section (i.e. the offset) for each bin. We don't need to store the end of it, because the end of a bin is exactly the start of the next bin! We could also store the particle IDs instead of particles themselves, but that's another indirection which could hurt memory access performance later, when we compute the forces.</p>

            <p>To do this, we use a typical three-phase approach:</p>

            <ul>
                <li>Phase 1: compute the number of particles in each bin</li>
                <li>Phase 2: run parallel prefix sum to compute the offset for each bin</li>
                <li>Phase 3: place each particle into the corresponding bin</li>
            </ul>

            <p>Phases 1 and 3 make heavy use of shader atomics. Phase 1 is fairly simple — run a compute shader for each particle, compute the (linearized) bin index for this particle, and increment the size of this bin:</p>

            <pre><code>@group(0) @binding(0) var&lt;storage, read&gt; particles : array&lt;Particle&gt;;

@group(1) @binding(0) var&lt;uniform&gt; simulationOptions : SimulationOptions;

@group(2) @binding(0) var&lt;storage, read_write&gt; binSize : array&lt;atomic&lt;u32&gt;&gt;;

@compute @workgroup_size(64)
fn fillBinSize(@builtin(global_invocation_id) id : vec3u)
{
    if (id.x &gt;= arrayLength(&amp;particles)) {
        return;
    }

    // Read the particle data
    let particle = particles[id.x];

    // Compute the linearized bin index
    let binIndex = getBinInfo(vec2f(particle.x, particle.y),
        simulationOptions).binIndex;

    // Increment the size of the bin
    atomicAdd(&amp;binSize[binIndex + 1], 1u);
}</code></pre>

            <p>Since this is done in parallel by many shader invocations, we need to use atomics here. I'm actually incrementing array at index <code>binIndex + 1</code>, and leaving the 0-th element at the value of 0, because this way <code>binOffset[i + 1] - binOffset[i]</code> always gives you the size of the i-th bin. Note that in this case the <code>binSize</code> array size is 1 plus the actual number of bins.</p>

            <p>Here, <code>getBinInfo</code> is just some helper function that computes the linearized bin index from the particle position and the size of the whole grid of bins:</p>

            <pre><code>fn getBinInfo(position : vec2f, simulationOptions : SimulationOptions) -&gt; BinInfo
{
    let binSize = simulationOptions.binSize;
    let gridSize = simulationOptions.gridSize;

    let binId = vec2i(
        clamp(i32(floor((position.x - simulationOptions.left) / binSize)), 0, gridSize.x - 1),
        clamp(i32(floor((position.y - simulationOptions.bottom) / binSize)), 0, gridSize.y - 1)
    );

    let binIndex = binId.y * gridSize.x + binId.x;

    return BinInfo(binId, binIndex);
}</code></pre>

            <p><i>(N.B.: in my actual code, <code>gridSize</code> is not passed as a uniform, but computed in-place, because I did it this way first and then never changed that.)</i></p>

            <p>In Phase 2, we need to convert the array of bin sizes into an array of bin offsets. Since the particles from the same bin go continuously in memory, a bin with some index starts when we've already put all the particles from bins with smaller indices into the array. This means that the offset \(O[i]\) of the i-th bin is simply the sum of the sizes \(S[j]\) of all preceding bins: \(O[i] = \sum\limits_{j=0}^{i-1} S[j]\). In pseudocode:</p>

            <pre><code>offset[0] = 0;
for (int i = 1; i &lt; binCount; ++i)
    binOffset[i] = binOffset[i - 1] + binSize[i];</code></pre>

            <p>This is known as computing <i>prefix sums</i>. This is, of course, not a parallel algorithm. To harness the power of the GPU, we'd want to run a parallel algorithm that does that. This is known, of course, as the <i>parallel prefix sum</i> problem, and we'll talk about it in the next section.</p>

            <p>For now, let's assume we've computed these offsets somehow. In Phase 3, we need to place ("sort") the particles into a new array, based on which bin this particle belongs to. We do this by running a per-particle compute shader once again. Because we want to put different particles into different indices in the new array, we need to use atomics again:</p>

            <pre><code>@group(0) @binding(0) var&lt;storage, read&gt; source : array&lt;Particle&gt;;
@group(0) @binding(1) var&lt;storage, read_write&gt; destination : array&lt;Particle&gt;;
@group(0) @binding(2) var&lt;storage, read&gt; binOffset : array&lt;u32&gt;;
@group(0) @binding(3) var&lt;storage, read_write&gt; binSize : array&lt;atomic&lt;u32&gt;&gt;;

@group(1) @binding(0) var&lt;uniform&gt; simulationOptions : SimulationOptions;

@compute @workgroup_size(64)
fn sortParticles(@builtin(global_invocation_id) id : vec3u)
{
    if (id.x &gt;= arrayLength(&amp;source)) {
        return;
    }

    // Read the particle data
    let particle = particles[id.x];

    // Compute the linearized bin index
    let binIndex = getBinInfo(vec2f(particle.x, particle.y),
        simulationOptions).binIndex;

    // Atomically compute the index of this particle
    // within the corresponding bin
    let indexInBin = atomicAdd(&amp;binSize[binIndex], 1);

    // Write the particle into the sorted array
    let newParticleIndex = binOffset[binIndex] + indexInBin;
    destination[newParticleIndex] = particle;
}</code></pre>

            <p>Here, we need to zero out the <code>binSize</code> array before running this shader. Again, since multiple shaders run in parallel, we use atomics to compute the index of a particle within its bin.</p>

            <p>Once we've done that, we can easily iterate over particles of a specific bin, which allows us to run the actual shader that computes per-particle forces, by only iterating over the neighbouring bins. Once again, a single shader invocation per each particle:</p>

            <pre><code>@group(0) @binding(0) var&lt;storage, read_write&gt; particles : array&lt;Particle&gt;;
@group(0) @binding(1) var&lt;storage, read&gt; binOffset : array&lt;u32&gt;;
@group(0) @binding(2) var&lt;storage, read&gt; forces : array&lt;Force&gt;;

@group(1) @binding(0) var&lt;uniform&gt; simulationOptions : SimulationOptions;

@compute @workgroup_size(64)
fn computeForces(@builtin(global_invocation_id) id : vec3u)
{
    if (id.x &gt;= arrayLength(&amp;particles)) {
        return;
    }

    // Read particle data
    var particle = particles[id.x];
    let type = u32(particle.type);

    // Compute the bin that contains this particle
    let binInfo = getBinInfo(vec2f(particle.x, particle.y), simulationOptions);

    // Compute the range of neighbouring bins for iteration
    var binXMin = binInfo.binId.x - 1;
    var binYMin = binInfo.binId.y - 1;
    var binXMax = binInfo.binId.x + 1;
    var binYMax = binInfo.binId.y + 1;

    // Guard against grid boundaries
    binXMin = max(0, binXMin);
    binYMin = max(0, binYMin);
    binXMax = min(binInfo.gridSize.x - 1, binXMax);
    binYMax = min(binInfo.gridSize.y - 1, binYMax);

    let particlePosition = vec2f(particle.x, particle.y);

    var totalForce = vec2f(0.0, 0.0);

    // Iterate over neighbouring bins
    for (var binX = binXMin; binX &lt;= binXMax; binX += 1) {
        for (var binY = binYMin; binY &lt;= binYMax; binY += 1) {
            // Compute linearized bin index
            let binIndex = binY * binInfo.gridSize.x + binX;

            // Find the range of particles from this bin
            let binStart = binOffset[binIndex];
            let binEnd = binOffset[binIndex + 1];

            // Iterate over particles from this bin
            for (var j = binStart; j &lt; binEnd; j += 1) {
                // Prevent self-interaction
                if (j == id.x) {
                    continue;
                }

                let other = particlesSource[j];
                let otherType = u32(other.type);

                // Apply the inter-particle force

                let force = forces[type * u32(simulationOptions.typeCount) + otherType];

                var r = vec2f(other.x, other.y) - particlePosition;
                let d = length(r);

                if (d &gt; 0.0) {
                    let n = r / d;

                    totalForce += force.strength * max(0.0, 1.0 - d / force.radius) * n;
                    totalForce -= force.collisionStrength * max(0.0, 1.0 - d / force.collisionRadius) * n;
                }
            }
        }
    }

    // Update velocity, assuming unit mass
    particle.vx += totalForce.x * simulationOptions.dt;
    particle.vy += totalForce.y * simulationOptions.dt;

    particles[id.x] = particle;
}</code></pre>

            <p><i>(My actual code also includes a central force &amp; handling looping boundaries. I also read particles from one buffer and write them to another buffer, but the idea is the same.)</i></p>

            <p><code>forces</code> is a \(M^2\)-sized array (where \(M\) is the number of particle types) which stores the inter-particle force parameters.</p>

            <h2 id="section-parallel-prefix-sum">Parallel prefix sum</h2>

            <p>Computing prefix sums in parallel is a well-known problem. I'm using the simplest solution, outlined as the <i>Algorithm 1</i> in the <a href="https://en.wikipedia.org/wiki/Prefix_sum#Algorithm_1:_Shorter_span,_more_parallel">wikipedia article</a>, and also called the <i>naive parallel scan</i> in this <a href="https://developer.nvidia.com/gpugems/gpugems3/part-vi-gpu-computing/chapter-39-parallel-prefix-sum-scan-cuda">GPU Gems 3 article</a>.</p>

            <p>The image from wikipedia explains everything rather nicely:</p>

            <center><img src="https://lisyarus.github.io/blog/media/particle-life/prefix-sum.png"></center>

            <p>The main idea is to run several sweeps over the whole array \(\log_2(N)\) times (where \(N\) is the array size), each time adding <code>x[i-step]</code> to <code>x[i]</code>, where <code>step</code> is a power of 2. In pseudocode, at iteration <code>k</code> we do</p>

            <pre><code>step = (1 &lt;&lt; k);
parallel for (int i = step; i &lt; array.size; ++i)
    array[i] += array[i - step];
</code></pre>

            <p>We start iteration from <code>i = step</code> because otherwise at <code>array[i - step]</code> we'd try reading at an address before the array starts. This code won't actually work because overwriting <code>array[i]</code> affects what other invocations (with different values of <code>i</code>) will read, so we have to use 2 arrays: one for reading, and one for writing. Something like this:</p>

            <pre><code>parallel for (int i = 0; i &lt; input.size; ++i) {
    if (i &lt; step)
        output[i] = input[i];
    else
        output[i] = input[i] + input[i - step];
}</code></pre>

            <p>Then, to compute the actual prefix sum, we create a temporary array, and we ping-pong the input &amp; temporary arrays \(\log_2(N)\) times with <code>step</code> taking the values of increasing powers of 2. On the first iteration (<code>k = 0, step = 1</code>), our <code>binSize</code> array is the input, and the temporary array is the output. On the next iteration (<code>k = 1, step = 2</code>), the temporary array is the input, and the <code>binSize</code> array is the output, and so on. In terms of WebGPU, this requires creating two bind groups with the same layout, one that reads from <code>binSize</code> array and writes to temporary array, and the other does the opposite.</p>

            <p>Now, with this method, the resulting prefix sum will be in the first or the second array, depending on the parity of the number of steps performed, i.e. the parity of \(\log_2(N)\). That's rather inconvenient, so I always round it up to the closest even number: this way, the result is always in the same <code>binSize</code> array, while an extra prefix sum iteration would simply copy one buffer into the other automatically (look what happens with the code when <code>step &gt;= array.size</code>).</p>

            <p>That's a lot of talking, but the implementation is rather simple:</p>

            <pre><code>@group(0) @binding(0) var&lt;storage, read&gt; input : array&lt;u32&gt;;
@group(0) @binding(1) var&lt;storage, read_write&gt; output : array&lt;u32&gt;;
@group(0) @binding(2) var&lt;uniform&gt; stepSize : u32;

@compute @workgroup_size(64)
fn prefixSumStep(@builtin(global_invocation_id) id : vec3u)
{
    if (id.x &gt;= arrayLength(&amp;input)) {
        return;
    }

    if (id.x &lt; stepSize) {
        output[id.x] = input[id.x];
    } else {
        output[id.x] = input[id.x - stepSize] + input[id.x];
    }
}</code></pre>

            <p>In order to supply different <code>stepSize</code> values while still keeping the whole thing as a single compute pass, I have a buffer with all <code>stepSize</code> values I need, and use it as the source for the uniform <code>stepSize</code> value with proper dynamic offsets in the <code>GPUComputePassEncoder.setBindGroup</code> call.</p>

            <p>So, with \(\log_2(N)\) iterations (rounded up to an even number), we run this compute shader (one invocation per bin, — or, in my case, <code>binCount + 1</code> invocations for reasons I outlined earlier), while ping-ponging two buffers. Here's what it looks like in JavaScript:</p>

<pre><code>prefixSumIterations = Math.ceil(Math.ceil(Math.log2(binCount + 1)) / 2) * 2;

...

binningComputePass.setPipeline(binPrefixSumPipeline);
for (var i = 0; i &lt; prefixSumIterations; ++i) {
    binningComputePass.setBindGroup(0, binPrefixSumBindGroup[i % 2], [i * 256]);
    binningComputePass.dispatchWorkgroups(Math.ceil((binCount + 1) / 64));
}</code></pre>

            <p><i>(The <code>i * 256</code> dynamic offset is due to requirements that dynamic offsets must be a multiple of 256 bytes. The <code>Math.ceil((binCount + 1) / 64)</code> workgroup count is because the shader uses a workgroup size of 64, and I run it on an array of size <code>binCount + 1</code>.)</i></p>

            <p>I could use a more sophisticated prefix sum algorithm, but there was no need to: even with e.g. 10000 bins, this whole particle sorting &amp; prefix sum computation takes about 0.1ms on my GeForce GTX 1060. The whole performance is <i>always</i> dominated by inter-particle forces computation, so optimizing the binning step gives little profit.</p>

            <h2 id="section-rendering">Rendering</h2>

            <p>I render particles as squares which are transformed into perfect circles in the fragment shader. For each particle, I have 2 triangles, thus 6 or 4 vertices (with or without vertex duplication), all sharing the data of the same particle. That's rather inconvenient: I'd rather not duplicate the particle data and not use instancing for that. So, instead my vertices don't have any attributes, and instead read the particles array directly as a read-only storage buffer, based on the vertex ID:</p>

            <pre><code>@group(0) @binding(0) var&lt;storage, read&gt; particles : array&lt;Particle&gt;;
@group(0) @binding(1) var&lt;storage, read&gt; species : array&lt;Species&gt;;
@group(1) @binding(0) var&lt;uniform&gt; camera : Camera;

struct VertexOut
{
    @builtin(position) position : vec4f,
    @location(0) offset : vec2f,
    @location(1) color : vec4f,
}

const offsets = array&lt;vec2f, 6&gt;(
    vec2f(-1.0, -1.0),
    vec2f( 1.0, -1.0),
    vec2f(-1.0,  1.0),
    vec2f(-1.0,  1.0),
    vec2f( 1.0, -1.0),
    vec2f( 1.0,  1.0),
);

@vertex
fn vertexCircle(@builtin(vertex_index) id : u32) -&gt; VertexOut
{
    let particle = particles[id / 6u];
    let offset = offsets[id % 6u] * 1.5;
    let position = vec2f(particle.x, particle.y) + offset;
    return VertexOut(
        vec4f((position - camera.center) / camera.extent, 0.0, 1.0),
        offset,
        species[u32(particle.species)].color
    );
}</code></pre>

            <p>Executed with a vertex count of <code>6 * particleCount</code>, this produces a square per each particle. The fragment shader computes the distance in pixels from the fragment to the center of the particle, and turns it into the alpha value to produce a perfectly anti-aliased circle:</p>

            <pre><code>@fragment
fn fragmentCircle(in : VertexOut) -&gt; @location(0) vec4f
{
    let alpha = clamp(camera.pixelsPerUnit * (1.0 - length(in.offset)) + 0.5, 0.0, 1.0);
    return in.color * vec4f(1.0, 1.0, 1.0, alpha);
}</code></pre>

            <p>And this is what it looks like:</p>

            <center><img src="https://lisyarus.github.io/blog/media/particle-life/anti-aliasing.png"></center>

            <p>I also add some glowing effect to the particles, which is rendered in a separate pass before the particles themselves. It works in pretty much the same way, but the squares are larger, and the alpha value is a gaussian:</p>

            <pre><code>@vertex
fn vertexGlow(@builtin(vertex_index) id : u32) -&gt; VertexOut
{
    let particle = particles[id / 6u];
    let offset = offsets[id % 6u];
    let position = vec2f(particle.x, particle.y) + 12.0 * offset;
    return CircleVertexOut(
        vec4f((position - camera.center) / camera.extent, 0.0, 1.0),
        offset,
        species[u32(particle.species)].color
    );
}

@fragment
fn fragmentGlow(in : VertexOut) -&gt; @location(0) vec4f
{
    let l = length(in.offset);
    let alpha = exp(- 6.0 * l * l) / 64.0;
    return in.color * vec4f(1.0, 1.0, 1.0, alpha);
}</code></pre>

            <center><img src="https://lisyarus.github.io/blog/media/particle-life/glow.png"></center>
            <center><i>Glowing effect, exaggerated for the sake of demonstration.</i></center>

            <p>All this is rendered using basic additive blending (<i>not</i> the usual over blending!) into an HDR <code>rgba16float</code> texture, then composited onto the screen (actually, onto an HTML canvas) using ACES tone-mapping and some blue-noise dithering to hide banding resulting from dark colors on the edge of the glow. I experimented with different blending methods &amp; tone-mapping curves, and this combination produced the best visuals for my taste.</p>

            <p>However, rendering perfect circles stops working when particles get too small, e.g. less than 1 pixel: the circle gets severely undersampled, the computed alpha values are pretty much random, and the whole image is just a big flickering mess. To counter that, I have a separate shader which replaces the circles when particle radius gets smaller than 1 pixel. It also renders squares, but the vertex shader makes sure the squares are exactly 2x2 pixels in size:</p>

            <pre><code>@vertex
fn vertexPoint(@builtin(vertex_index) id : u32) -&gt; VertexOut
{
    let particle = particles[id / 6u];
    let offset = 2.0 * offsets[id % 6u] / camera.pixelsPerUnit;
    let position = vec2f(particle.x, particle.y) + offset;
    return CircleVertexOut(
        vec4f((position - camera.center) / camera.extent, 0.0, 1.0),
        offset,
        species[u32(particle.species)].color
    );
}</code></pre>

            <p>Then, the fragment shader computes the area of the intersection of the circle and the current pixel. Because computing circle-square intersections is a bit non-trivial, I approximate the circle with a square, compute the intersections (which boil down to min/max along each coordinate), and multiply by \(\frac{\pi}{4}\) to compensate for the square area vs circle area:</p>

            <pre><code>@fragment
fn fragmentPoint(in : CircleVertexOut) -&gt; @location(0) vec4f
{
    let s = vec2f(camera.pixelsPerUnit);
    let d = max(vec2f(0.0), min(in.offset * s + 0.5, s) - max(in.offset * s - 0.5, - s));
    let alpha = (PI / 4.0) * d.x * d.y;
    return vec4f(in.color.rgb, in.color.a * alpha);
}</code></pre>

            <p>This feels hacky, but it works: the image almost doesn't flicker, and the transition between the two rendering modes is pretty much unnoticeable.</p>

            <h2 id="section-gallery">Gallery</h2>

            <p>I already posted the link in the beginning of the article, but if you don't feel like scolling back, <a href="https://lisyarus.github.io/webgpu/particle-life.html">here is the link to the simulation</a>. Each page reload gives a new random system, though you can also just click "Randomize". You can save the current rules as a JSON file, or upload custom rules. You can share a randomly-generated rule set by clicking "Copy link".</p>

            <p>I've noticed that less particle types leads to more large-scale coherent structures, while more particle types leads to more local &amp; busy systems. Sometimes it is a good idea to do some <a href="https://en.wikipedia.org/wiki/Simulated_annealing"><i>simulated annealing</i></a> and slowly increase or decrease the friction value, which works kind of like the inverse temperature here.</p>

            <p>But, honestly, pretty much any random system made with this simulator looks interesting in some way. Here are some of the cool-looking systems I've been able to find in about 15 minutes. Each image is a link to this particular system:</p>

            <center><a href="https://lisyarus.github.io/webgpu/particle-life.html?particleCount=65536&amp;speciesCount=1&amp;friction=10&amp;centralForce=0&amp;symmetricForces=true&amp;loopingBorders=true&amp;seed=1964178017"><img src="https://lisyarus.github.io/blog/media/particle-life/gallery-0.png"></a></center>

            <center><a href="https://lisyarus.github.io/webgpu/particle-life.html?particleCount=65536&amp;speciesCount=2&amp;friction=10&amp;centralForce=0&amp;symmetricForces=true&amp;loopingBorders=true&amp;seed=781562033"><img src="https://lisyarus.github.io/blog/media/particle-life/gallery-1.png"></a></center>

            <center><a href="https://lisyarus.github.io/webgpu/particle-life.html?particleCount=65536&amp;speciesCount=2&amp;friction=10&amp;centralForce=0&amp;symmetricForces=true&amp;loopingBorders=true&amp;seed=470127870"><img src="https://lisyarus.github.io/blog/media/particle-life/gallery-2.png"></a></center>

            <center><a href="https://lisyarus.github.io/webgpu/particle-life.html?particleCount=65536&amp;speciesCount=2&amp;friction=10&amp;centralForce=0&amp;symmetricForces=true&amp;loopingBorders=true&amp;seed=3856172604"><img src="https://lisyarus.github.io/blog/media/particle-life/gallery-3.png"></a></center>

            <center><a href="https://lisyarus.github.io/webgpu/particle-life.html?particleCount=65536&amp;speciesCount=2&amp;friction=10&amp;centralForce=0&amp;symmetricForces=true&amp;loopingBorders=true&amp;seed=4037789242"><img src="https://lisyarus.github.io/blog/media/particle-life/gallery-4.png"></a></center>

            <center><a href="https://lisyarus.github.io/webgpu/particle-life.html?particleCount=65536&amp;speciesCount=3&amp;friction=10&amp;centralForce=0&amp;symmetricForces=true&amp;loopingBorders=true&amp;seed=2609318066"><img src="https://lisyarus.github.io/blog/media/particle-life/gallery-5.png"></a></center>

            <center><a href="https://lisyarus.github.io/webgpu/particle-life.html?particleCount=65536&amp;speciesCount=3&amp;friction=10&amp;centralForce=0&amp;symmetricForces=true&amp;loopingBorders=true&amp;seed=1940662796"><img src="https://lisyarus.github.io/blog/media/particle-life/gallery-6.png"></a></center>

            <center><a href="https://lisyarus.github.io/webgpu/particle-life.html?particleCount=65536&amp;speciesCount=3&amp;friction=10&amp;centralForce=0&amp;symmetricForces=false&amp;loopingBorders=true&amp;seed=3584546700"><img src="https://lisyarus.github.io/blog/media/particle-life/gallery-7.png"></a></center>

            <center><a href="https://lisyarus.github.io/webgpu/particle-life.html?particleCount=65536&amp;speciesCount=3&amp;friction=10&amp;centralForce=0&amp;symmetricForces=false&amp;loopingBorders=true&amp;seed=1876301519"><img src="https://lisyarus.github.io/blog/media/particle-life/gallery-8.png"></a></center>

            <center><a href="https://lisyarus.github.io/webgpu/particle-life.html?particleCount=65536&amp;speciesCount=4&amp;friction=10&amp;centralForce=0&amp;symmetricForces=false&amp;loopingBorders=true&amp;seed=3588165106"><img src="https://lisyarus.github.io/blog/media/particle-life/gallery-9.png"></a></center>

            <center><a href="https://lisyarus.github.io/webgpu/particle-life.html?particleCount=65536&amp;speciesCount=4&amp;friction=10&amp;centralForce=0&amp;symmetricForces=false&amp;loopingBorders=true&amp;seed=1007650884"><img src="https://lisyarus.github.io/blog/media/particle-life/gallery-10.png"></a></center>

            <center><a href="https://lisyarus.github.io/webgpu/particle-life.html?particleCount=65536&amp;speciesCount=8&amp;friction=10&amp;centralForce=0&amp;symmetricForces=false&amp;loopingBorders=true&amp;seed=958305330"><img src="https://lisyarus.github.io/blog/media/particle-life/gallery-11.png"></a></center>

            
            
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[TIL: timeout in Bash scripts (255 pts)]]></title>
            <link>https://heitorpb.github.io/bla/timeout/</link>
            <guid>44096395</guid>
            <pubDate>Mon, 26 May 2025 11:34:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://heitorpb.github.io/bla/timeout/">https://heitorpb.github.io/bla/timeout/</a>, See on <a href="https://news.ycombinator.com/item?id=44096395">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <p>The other day at work we had a Bash script that would set up a web server and
wait for it to be up before proceeding to the next things. The script worked
fine and we had no issues, until we had an infinite loop.</p>
<center>
<a data-flickr-embed="true" data-header="false" data-footer="false" href="https://www.flickr.com/photos/heitorpb/30622866477/" title="Airplane Tracks"><img src="https://live.staticflickr.com/1908/30622866477_d147a6f3fc_z.jpg" width="640" height="426" alt="Airplane Tracks"></a>
</center>
<p>We were using the Bash built-in <code>until</code> to check if the web server was up:</p>
<pre data-lang="bash"><code data-lang="bash"><span>until </span><span>curl --silent --fail-with-body</span><span> 10.0.0.1:8080/health; </span><span>do
</span><span>	</span><span>sleep</span><span> 1
</span><span>done
</span></code></pre>
<p>This works fine. Unless our web server crashes during startup and we <code>sleep 1</code>
forever.</p>
<p>Here comes a handy utility: <code>timeout</code>. As the name suggests, this command adds
a timeout to other commands. You specify the time limit you want to wait for a
command and if that time passes, <code>timeout</code> sends a signal to terminate it and
exits with non-zero. By default, <code>timeout</code> sends <code>SIGTERM</code>, but you can change
it with the <code>--signal</code> flag, e.g. <code>timeout --signal=SIGKILL 1s foo</code>.</p>
<p>For example, <code>timeout 1s sleep 5</code> will send the <code>SIGTERM</code> signal to <code>sleep</code>
after 1 second:</p>
<pre data-lang="bash"><code data-lang="bash"><span>$</span><span> time timeout 1s sleep 4
</span><span>
</span><span>real</span><span>    0m1,004s
</span><span>user</span><span>    0m0,000s
</span><span>sys</span><span>     0m0,005s
</span><span>
</span><span>$</span><span> echo $</span><span>?
</span><span>124
</span></code></pre>
<p>The natural thing to do then is to combine <code>timeout</code> and <code>until</code>:</p>
<pre data-lang="bash"><code data-lang="bash"><span>timeout</span><span> 1m until curl</span><span> --silent --fail-with-body</span><span> 10.0.0.1:8080/health; </span><span>do
</span><span>	</span><span>sleep</span><span> 1
</span><span>done
</span></code></pre>
<p>The only issue is that this doesn’t work. <code>timeout</code> expects a killable command
and <code>until</code> is a shell keyword: you can’t <code>SIGTERM</code> <code>until</code>. We can’t use
<code>timeout</code> with any shell built-in.</p>
<p>The way forward is to wrap that <code>until</code> in a Bash process:</p>
<pre data-lang="bash"><code data-lang="bash"><span>timeout</span><span> 1m bash</span><span> -c </span><span>"</span><span>until curl --silent --fail-with-body 10.0.0.1:8080/health; do
</span><span>	sleep 1
</span><span>done</span><span>"
</span></code></pre>
<p>Another approach is to move the <code>until</code> to a separate Bash script and <code>timeout</code>
it:</p>
<pre data-lang="bash"><code data-lang="bash"><span>timeout</span><span> 1m ./until.sh
</span></code></pre>
<p>It’s a shame we can’t use <code>timeout</code> with <code>until</code> directly, that would be
amazing. But wrapping it in a Bash process/script gets the job done.</p>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The double standard of webhook security and API security (105 pts)]]></title>
            <link>https://www.speakeasy.com/blog/webhook-security</link>
            <guid>44096251</guid>
            <pubDate>Mon, 26 May 2025 11:18:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.speakeasy.com/blog/webhook-security">https://www.speakeasy.com/blog/webhook-security</a>, See on <a href="https://news.ycombinator.com/item?id=44096251">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Sleep apnea pill shows striking success in large clinical trial (212 pts)]]></title>
            <link>https://www.science.org/content/article/sleep-apnea-pill-shows-striking-success-large-clinical-trial</link>
            <guid>44095866</guid>
            <pubDate>Mon, 26 May 2025 10:15:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.science.org/content/article/sleep-apnea-pill-shows-striking-success-large-clinical-trial">https://www.science.org/content/article/sleep-apnea-pill-shows-striking-success-large-clinical-trial</a>, See on <a href="https://news.ycombinator.com/item?id=44095866">Hacker News</a></p>
Couldn't get https://www.science.org/content/article/sleep-apnea-pill-shows-striking-success-large-clinical-trial: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Lieferando.de (Takeaway) has captured 5.7% of restaurant related domain names (297 pts)]]></title>
            <link>https://mondaybits.com/lieferando-captured-6-percent-of-restaurant-related-domain-names/</link>
            <guid>44095250</guid>
            <pubDate>Mon, 26 May 2025 08:27:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mondaybits.com/lieferando-captured-6-percent-of-restaurant-related-domain-names/">https://mondaybits.com/lieferando-captured-6-percent-of-restaurant-related-domain-names/</a>, See on <a href="https://news.ycombinator.com/item?id=44095250">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
        <p>I recently decided to compile a <strong>very large list of domain names </strong>for the German country code top-level domain <strong><em>.de</em></strong>. I did this with the help of the <a href="https://commoncrawl.org/?ref=mondaybits.com" rel="noreferrer">Common Crawl project</a> which provides a free, open repository of web crawl data and web graphs for the last years.</p><p>A few command line commands and a small <em>bash shell script</em> was all it took to compile a nice list of <strong>roughly 9 million .de domain names.</strong></p><div><p>💡</p><p>If you want to know more about how exactly I compiled the domain name list, just let me know and I might write about it in another blog post.</p></div><p>The resulting list is by no means complete and also not up-to-date, but it can be a nice starting point for further analysis and investigations. One of which I am going to write about in this post.</p><h2 id="enter-the-restaurant-world">Enter the restaurant world</h2><p>I was interested in domain names that belonged to restaurants and eating places in general. A simple but quite effective way to achieve this was to filter the domain names by German words that indicate such eating places:</p><ul>
<li>Restaurant</li>
<li>Gasthaus</li>
<li>Gasthof</li>
<li>Gaststätte</li>
<li>Wirtshaus</li>
<li>Gastwirtschaft</li>
<li>Schänke</li>
<li>Speisewirtschaft</li>
<li>Speiselokal</li>
<li>Speisehaus</li>
<li>Speiserestaurant</li>
<li>Speisegaststätte</li>
<li>Gastlokal</li>
<li>Kneipe</li>
<li>Pizzaria</li>
</ul>
<p>Since I was running this analysis on my windows desktop, <em>grep </em>was not directly available. So I used the <em>findstr PowerScript command</em><strong> </strong>instead to do this filtering:</p><pre><code>findstr /I "Restaurant Gasthaus Gasthof Gaststaette Wirtshaus ..." huge-domain-list.txt
</code></pre>
<p>This yielded a still impressive list of about <strong>31.000 domain names related to German restaurants</strong>.</p><h2 id="whos-still-alive">Who's still alive?</h2><p>Since I knew that the original list is outdated by definition, I had to check which domain names were still active. My first attempt to do this was also with a PowerShell script. This worked in principle and I was somewhat impressed by the capabilities that PowerShell provided, but at the same time the unfamiliar syntax turned me off and most importantly the speed was not great. So I created a small <em>Golang </em>program to get this job done, which worked great due Golang's <em>concurrency </em>features.</p><ul>
<li><strong>63% of the domain names were still active</strong> (roughly 20.000 domains)</li>
<li><strong>49% of the domains had redirects</strong> (mostly from http:// to https://)</li>
<li><strong>14% of the domains still serve http://</strong></li>
<li><strong>37% of the domains did not exist anymore</strong> or returned other errors</li>
</ul>
<h2 id="lets-do-some-manual-spot-checks">Let's do some manual spot checks...</h2><p>I was happy to have a list of <strong>20.000 restaurant domain names</strong> to work with and started some manual spot checks. After looking at 20 randomly selected websites from the list, I made two observations:</p><ol>
<li><em><strong>Domain Parking</strong></em> <strong>was another group of domain names to filter out</strong></li>
<li><em><strong>Lieferando.de</strong></em> <strong>had captured a significant number of domain names</strong></li>
</ol>
<p>I was not surprised about the first observation, because I had noticed already quite often that many good domain names are "parked". But <strong>that lieferando.de thing caught my attention</strong>. The domains that were captured by lieferando.de did not redirect to lieferando.de, but instead showed their logo and a link to their website.</p><h2 id="how-many-of-them">How many of them?</h2><p>With just a small extension to my <em>Golang </em>program I could find all the domain names form the initial list, that were captured by lieferando.de:</p><p><strong>5.7% of the active domains from the restaurant domain list belong to lieferando.de</strong></p><p>That is 1101 domain names. Here are some random examples:</p><ul>
<li>elba-restaurant-knigstein-im-taunus.de</li>
<li>gasthauskaiser.de</li>
<li>grill-restaurantnaxos.de</li>
<li>henne-alt-berlinerwirtshaus.de</li>
<li>kulturkneipe-brotfabrik-bonn.de</li>
</ul>
<p>The numbers are of course only estimates, since the initial domain list is not complete, but it provides some impression for the size of the topic.</p><h2 id="when-did-it-start">When did it start?</h2><p>I have not yet done a systematic analysis, but it seems (based on <em>WHOIS</em> entries for some domain names) that this "capturing" of restaurant domain names has started already before the COVID-19 pandemic in 2019 and continued at least until 2022 and potentially still continues.</p><h2 id="preliminary-conclusions">(Preliminary) Conclusions</h2><ol>
<li>The number of "lost" domain names provides evidence that German restaurants have been struggling in the 2019-2023 time frame. It would be interesting to revisit this analysis in one or two years to see who many more domain names have become inactive or taken over by lieferando.</li>
<li>Lieferando is using aggressive tactics to drive traffic to their site. Maybe this can be described as <em>growth hacking</em> or a way of <em>SEO</em>. It is apparently not even new.</li>
<li>The extend to which lieferando is using this method suggest that it is at least somewhat effective and probably quite cheap to implement.</li>
</ol>
<div><p>💡</p><p>What are your thoughts on this topic? When you sign-in, you can let me know in the comments.</p></div>
    </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Anyone struggling to get value out of coding LLMs? (261 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=44095189</link>
            <guid>44095189</guid>
            <pubDate>Mon, 26 May 2025 08:17:53 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=44095189">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><td><table>
        <tbody><tr id="44095189">
      <td><span></span></td>      <td><center><a id="up_44095189" href="https://news.ycombinator.com/vote?id=44095189&amp;how=up&amp;goto=item%3Fid%3D44095189"></a></center></td><td><span><a href="https://news.ycombinator.com/item?id=44095189">Ask HN: Anyone struggling to get value out of coding LLMs?</a></span></td></tr><tr><td colspan="2"></td><td><span>
          <span id="score_44095189">103 points</span> by <a href="https://news.ycombinator.com/user?id=bjackman">bjackman</a> <span title="2025-05-26T08:17:53 1748247473"><a href="https://news.ycombinator.com/item?id=44095189">5 hours ago</a></span> <span id="unv_44095189"></span> | <a href="https://news.ycombinator.com/hide?id=44095189&amp;goto=item%3Fid%3D44095189">hide</a> | <a href="https://hn.algolia.com/?query=Ask%20HN%3A%20Anyone%20struggling%20to%20get%20value%20out%20of%20coding%20LLMs%3F&amp;type=story&amp;dateRange=all&amp;sort=byDate&amp;storyText=false&amp;prefix&amp;page=0">past</a> | <a href="https://news.ycombinator.com/fave?id=44095189&amp;auth=cfcdec8500fc3d5cbc107c7ce6bff426034e3861">favorite</a> | <a href="https://news.ycombinator.com/item?id=44095189">90&nbsp;comments</a>        </span>
              </td></tr>
    <tr><td></td></tr><tr><td colspan="2"></td><td><div><p>I use LLMs daily for stuff like:</p><p>- solving tasks that just require applying knowledge ("here's a paste of my python import structure. I don't write Python often and I'm aware I'm doing something wrong here because I get this error, tell me the proper way organise the package").</p><p>- writing self-contained throwaway pieces of code ("here's a paste of my DESCRIBE TABLE output, write an SQL query to show the median [...]").</p><p>- as a debugging partner ("I can SSH to this host directly, but Ansible fails to connect with this error, what could be causing this difference").</p><p>All these use cases work great, I save a lot of time. But with the core work of writing the code that I work on, I've almost never had any success. I've tried:</p><p>- Cursor (can't remember which model, the default)</p><p>- Google's Jules</p><p>- OpenAI Codex with o4</p><p>I found in all cases that the underlying capability is clearly there (the model can understand and write code) but the end-to-end value is not at all. It could write code that _worked_, but trying to get it to generate code that I am willing to maintain and "put my name on" took longer than writing the code would have.</p><p>I had to micromanage them infinitely ("be sure to rerun the formatter, make sure all tests pass" and "please follow the coding style of the repository". "You've added irrelevant comments remove those". "You've refactored most of the file but forgot a single function"). It would take many many iterations on trivial issues, and because these iterations are slow that just meant I had to context switch a lot, which is also exhausting.</p><p>Basically it was like having an intern who has successfully learned the core skill of programming but is not really capable of good collaboration and needs to be babysat all the time.</p><p>I asked friends who are enthusiastic vibe coders and they basically said "your standards are too high".</p><p>Is the model for success here that you just say "I don't care about code quality because I don't have to maintain it because I will use LLMs for that too?" Am I just not using the tools correctly?</p></div></td></tr>        <tr><td></td></tr><tr><td colspan="2"></td><td><form action="comment" method="post"></form></td></tr>  </tbody></table>
  </td></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GitHub issues is almost the best notebook in the world (247 pts)]]></title>
            <link>https://simonwillison.net/2025/May/26/notes/</link>
            <guid>44094980</guid>
            <pubDate>Mon, 26 May 2025 07:41:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://simonwillison.net/2025/May/26/notes/">https://simonwillison.net/2025/May/26/notes/</a>, See on <a href="https://news.ycombinator.com/item?id=44094980">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<p>GitHub issues is <em>almost</em> the best notebook in the world.</p>
<p>Free and unlimited, for both public and private notes.</p>
<p>Comprehensive Markdown support, including syntax highlighting for almost any language. Plus you can drag and drop images or videos directly onto a note.</p>
<p>It has fantastic inter-linking abilities. You can paste in URLs to other issues (in any other repository on GitHub) in a markdown list <a href="https://github.com/simonw/llm/issues/1059#issuecomment-2907515045">like this</a>:</p>
<pre><code>- https://github.com/simonw/llm/issues/1078
- https://github.com/simonw/llm/issues/1080
</code></pre>
<p>Your issue will pull in the title of the other issue, plus that other issue will get back a link to yours - taking issue visibility rules into account.</p>
<p><img alt="Screenshot of an issue showing user &quot;simonw&quot; posted yesterday containing text &quot;Current logs could do with a bit of a redesign around tools already, see:&quot; followed by two bullet points with green checkmark icons: &quot;Tools in LLM logs output should only show definition first time #1078&quot; and &quot;New design for logs involving tool calls (and maybe tool classes) #1080&quot;" src="https://static.simonwillison.net/static/2025/issue-notes.jpg"></p>
<p>It has excellent search, both within a repo, across all of your repos or even across the whole of GitHub if you've completely forgotten where you put something.</p>
<p>It has a comprehensive API, both for exporting notes and creating and editing new ones. Add GitHub Actions, triggered by issue events, and you can automate it to do almost anything.</p>
<p>The one missing feature? Synchronized offline support. I still mostly default to Apple Notes on my phone purely because it works with or without the internet and syncs up with my laptop later on.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bagel: The Open-Source Unified Multimodal Model (204 pts)]]></title>
            <link>https://bagel-ai.org/</link>
            <guid>44094362</guid>
            <pubDate>Mon, 26 May 2025 05:51:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bagel-ai.org/">https://bagel-ai.org/</a>, See on <a href="https://news.ycombinator.com/item?id=44094362">Hacker News</a></p>
Couldn't get https://bagel-ai.org/: Error: getaddrinfo ENOTFOUND bagel-ai.org]]></description>
        </item>
        <item>
            <title><![CDATA[Google Shared My Phone Number (452 pts)]]></title>
            <link>https://danq.me/2025/05/21/google-shared-my-phone-number/</link>
            <guid>44094270</guid>
            <pubDate>Mon, 26 May 2025 05:34:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://danq.me/2025/05/21/google-shared-my-phone-number/">https://danq.me/2025/05/21/google-shared-my-phone-number/</a>, See on <a href="https://news.ycombinator.com/item?id=44094270">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
        <article id="post-26608" data-post-id="26608">
          
          <div>
              <p>
                  <span>Duration</span> <time>6:06</time>
                </p>
              <div>
                <h2>
                  Podcast Version
                </h2>
                <p>
                  This post is also available as a podcast. Listen here, download for later, or subscribe wherever you consume podcasts.
                </p>
                
              </div>
            </div>
          <div>
            <p>
              Earlier this month, I received a phone call from a user of <a title="Three Rings CIC" href="https://www.threerings.org.uk/"><em>Three Rings</em></a>, the volunteer/rota management
              software system I founded<sup><a id="footnote-ref-26608-1" name="footnote-ref-26608-1" href="#footnote-26608-1" title="Way back in 2002! We’re very nearly at the point where the Three Rings system is older than the youngest member of the Three Rings team. Speaking of which, we’re seeking volunteers to help expand our support team: if you’ve got experience of using&nbsp;Three Rings and an hour or two a week to spare helping to make volunteering easier for hundreds of thousands of people around the world, you should look us up!">1</a></sup>.
            </p>
            <p>
              We don’t strictly <em>offer</em> telephone-based tech support – our distributed team of volunteers doesn’t keep any particular “core hours” so we can’t say who’s available at any given
              time – but instead we answer email/Web based queries pretty promptly at any time of the day or week.
            </p>
            <p>
              But because I’ve called-back enough users over the years, it’s pretty much inevitable that a few probably have my personal mobile number saved. And because <a title="Venn-Euler digram comparing relationship breakups to tech layoffs, based on my recent experience" href="https://danq.me/2025/04/22/breakups-vs-layoffs/">I’ve been applying for a couple of
              interesting-looking new roles</a>, I’m in the habit of answering my phone even if it’s a number I don’t recognise.
            </p>
            <figure id="attachment_26609" aria-describedby="caption-attachment-26609">
              <a href="#lightbox-p-attachment_26609" title="Zoom in on image" aria-haspopup="dialog" role="button"><img decoding="async" fetchpriority="high" src="https://danq.me/_q23u/2025/05/20240412_150500-640x360.jpg" alt="Dan sits at his laptop in front of a long conference table where a group of people are looking at a projector screen." width="640" height="360" srcset="https://danq.me/_q23u/2025/05/20240412_150500-640x360.jpg 640w, https://danq.me/_q23u/2025/05/20240412_150500-1280x720.jpg 1280w, https://danq.me/_q23u/2025/05/20240412_150500-980x551.jpg 980w, https://danq.me/_q23u/2025/05/20240412_150500-1960x1103.jpg 1960w, https://danq.me/_q23u/2025/05/20240412_150500-477x269.jpg 477w" sizes="100vw"></a>
              <figcaption id="caption-attachment-26609">
                Many of the charities that benefit from&nbsp;<em>Three Rings</em> seem to form the impression that we’re all just sat around in an office, like this. But in fact many of my fellow
                volunteers only ever see me once or twice a year!
              </figcaption>
            </figure>
            <p>
              After the first three such calls this month, I was really starting to wonder what had changed. Had we accidentally published my phone number, somewhere? So when the fourth tech support
              call came through, today (which began with a confusing exchange when I didn’t recognise the name of the caller’s charity, and he didn’t get my name right, and I initially figured it
              must be a wrong number), I had to ask: <em>where did you find this number?</em>
            </p>
            <p>
              <em>“When I Google ‘Three Rings login’, it’s right there!”</em> he said.
            </p>
            <figure id="attachment_26610" aria-describedby="caption-attachment-26610">
              <a href="#lightbox-p-attachment_26610" title="Zoom in on image" aria-haspopup="dialog" role="button"><img decoding="async" src="https://danq.me/_q23u/2025/05/3r-google-leak-dans-phone-number-1-640x397.jpg" alt="Google Search results page for 'Three Rings CIC', showing a sidebar with information about the company and including... my personal mobile number and a 'Call' button that calls it!" width="640" height="397" srcset="https://danq.me/_q23u/2025/05/3r-google-leak-dans-phone-number-1-640x397.jpg 640w, https://danq.me/_q23u/2025/05/3r-google-leak-dans-phone-number-1-1280x795.jpg 1280w, https://danq.me/_q23u/2025/05/3r-google-leak-dans-phone-number-1-980x608.jpg 980w, https://danq.me/_q23u/2025/05/3r-google-leak-dans-phone-number-1-1960x1217.jpg 1960w" sizes="100vw"></a>
              <figcaption id="caption-attachment-26610">
                I almost never use Google Search<sup><a id="footnote-ref-26608-2" name="footnote-ref-26608-2" href="#footnote-26608-2" title="Seriously: if you’re still using Google Search as your primary search engine, it’s past time you shopped around. There are great alternatives that do a better job on your choice of one or more of the metrics that might matter to you: better privacy, fewer ads (or more-relevant ads, if you want), less AI slop, etc.">2</a></sup>,
                so there’s no way I’d have noticed this change if I hadn’t been told about it.
              </figcaption>
            </figure>
            <p>
              He was right. A Google search that surfaced Three Rings CIC’s “Google Business Profile” now featured… my personal mobile number. And a convenient “Call” button that connects you
              directly to it.
            </p>
            <p id="image-26608-0">
              <a href="#lightbox-p-image-26608-0" title="Zoom in on image" aria-haspopup="dialog" role="button"><img decoding="async" src="https://danq.me/_q23u/2025/05/giphy-909268056-blink-excuse-me.gif" alt="'Excuse me' GIF reaction. A white man blinks and looks surprised." width="320" height="222"></a>
            </p>
            <p>
              Some <em>years</em> ago, I provided my phone number to Google as part of an identity verification process, but didn’t consent to it being shared publicly. And, indeed, they
              <em>didn’t</em> share it publicly, until – seemingly at random – they started doing so, presumably within the last few weeks.
            </p>
            <p>
              Concerned by this change, I logged into Google Business Profile to see if I could edit it back.
            </p>
            <figure id="attachment_26611" aria-describedby="caption-attachment-26611">
              <a href="#lightbox-p-attachment_26611" title="Zoom in on image" aria-haspopup="dialog" role="button"><img decoding="async" loading="lazy" src="https://danq.me/_q23u/2025/05/3r-google-leak-dans-phone-number-2-640x215.png" alt="Screenshot from Google Business Profile, with my phone number and the message 'Your phone number was updated by Google.'." width="640" height="215" srcset="https://danq.me/_q23u/2025/05/3r-google-leak-dans-phone-number-2-640x215.png 640w, https://danq.me/_q23u/2025/05/3r-google-leak-dans-phone-number-2-1280x430.png 1280w, https://danq.me/_q23u/2025/05/3r-google-leak-dans-phone-number-2-980x329.png 980w" sizes="100vw"></a>
              <figcaption id="caption-attachment-26611">
                Apparently Google inserted my personal mobile number into search results <em>for</em> me, randomly, without me asking them to. Delightful.
              </figcaption>
            </figure>
            <p>
              I deleted my phone number from the business listing again, and within a few minutes it seemed to have stopped being served to random strangers on the Internet. Unfortunately deleting
              the phone number also made the “Your phone number was updated by Google” message disappear, so I never got to click the “Learn more” link to maybe get a clue as to how and why this
              change happened.
            </p>
            <p>
              Last month, high-street bank <a title="My blog post about how Halifax recently leaked my personal information (by post!)" href="https://danq.me/2025/04/24/halifax-dun-goofed/">Halifax posted the
              details of a credit agreement I have with them to two people who aren’t me</a>. Twice in two months seems suspicious. Did I accidentally click the wrong button on a popup and now I’ve
              consented to <em>all</em> my PII getting leaked everywhere?
            </p>
            <figure id="attachment_26616" aria-describedby="caption-attachment-26616">
              <a href="#lightbox-p-attachment_26616" title="Zoom in on image" aria-haspopup="dialog" role="button"><img decoding="async" loading="lazy" src="https://danq.me/_q23u/2025/05/3r-google-leak-dans-phone-number-4-640x148.png" alt="Spoof privacy settings popup, such as you might find on a website, reading: We and our partners work very hard to keep your data safe and secure and to operate within the limitations of the law. It's really hard! Can you give us a break and make it easier for us by consenting for us to not have to do that? By clicking the 'I Agree' button, you consent to us and every other company you do business with to share your personal information with absolutely anybody, at any time, for any reason, forever. That's cool, right?" width="640" height="148"></a>
              <figcaption id="caption-attachment-26616">
                Don’t you hate it when you click the wrong button. Who reads these things, anyway, right?
              </figcaption>
            </figure>
            <p>
              Such feelings of rage.
            </p>
            
            <dialog id="lightbox-image-26608-0">
              <p id="lightbox-p-image-26608-0">
                <a href="https://danq.me/_q23u/2025/05/giphy-909268056-blink-excuse-me.gif"><img decoding="async" src="https://danq.me/_q23u/2025/05/giphy-909268056-blink-excuse-me.gif" alt="'Excuse me' GIF reaction. A white man blinks and looks surprised." width="320" height="222" loading="lazy"></a>
              </p><a href="#image-26608-0" title="Close image" role="button">×</a>
            </dialog>
            <dialog id="lightbox-attachment_26609">
              <p id="lightbox-p-attachment_26609">
                <a href="https://danq.me/_q23u/2025/05/20240412_150500-scaled.jpg"><img decoding="async" fetchpriority="high" src="https://danq.me/_q23u/2025/05/20240412_150500-scaled.jpg" alt="Dan sits at his laptop in front of a long conference table where a group of people are looking at a projector screen." width="640" height="360" sizes="100vw" loading="lazy"></a>
              </p><a href="#attachment_26609" title="Close image" role="button">×</a>
            </dialog>
            <dialog id="lightbox-attachment_26610">
              <p id="lightbox-p-attachment_26610">
                <a href="https://danq.me/_q23u/2025/05/3r-google-leak-dans-phone-number-1-scaled.jpg"><img decoding="async" src="https://danq.me/_q23u/2025/05/3r-google-leak-dans-phone-number-1-scaled.jpg" alt="Google Search results page for 'Three Rings CIC', showing a sidebar with information about the company and including... my personal mobile number and a 'Call' button that calls it!" width="640" height="397" sizes="100vw" loading="lazy"></a>
              </p><a href="#attachment_26610" title="Close image" role="button">×</a>
            </dialog>
            <dialog id="lightbox-attachment_26611">
              <p id="lightbox-p-attachment_26611">
                <a href="https://danq.me/_q23u/2025/05/3r-google-leak-dans-phone-number-2.png"><img decoding="async" loading="lazy" src="https://danq.me/_q23u/2025/05/3r-google-leak-dans-phone-number-2.png" alt="Screenshot from Google Business Profile, with my phone number and the message 'Your phone number was updated by Google.'." width="640" height="215" sizes="100vw"></a>
              </p><a href="#attachment_26611" title="Close image" role="button">×</a>
            </dialog>
            <dialog id="lightbox-attachment_26616">
              <p id="lightbox-p-attachment_26616">
                <a href="https://danq.me/_q23u/2025/05/3r-google-leak-dans-phone-number-4.png"><img decoding="async" loading="lazy" src="https://danq.me/_q23u/2025/05/3r-google-leak-dans-phone-number-4.png" alt="Spoof privacy settings popup, such as you might find on a website, reading: We and our partners work very hard to keep your data safe and secure and to operate within the limitations of the law. It's really hard! Can you give us a break and make it easier for us by consenting for us to not have to do that? By clicking the 'I Agree' button, you consent to us and every other company you do business with to share your personal information with absolutely anybody, at any time, for any reason, forever. That's cool, right?" width="640" height="148"></a>
              </p><a href="#attachment_26616" title="Close image" role="button">×</a>
            </dialog>
            
          </div>
          
        </article>
        
      </div></div>]]></description>
        </item>
    </channel>
</rss>