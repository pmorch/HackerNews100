<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 14 Feb 2026 14:30:39 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Ars Technica makes up quotes from Matplotlib maintainer; pulls story (223 pts)]]></title>
            <link>https://infosec.exchange/@mttaggart/116065340523529645</link>
            <guid>47013059</guid>
            <pubDate>Sat, 14 Feb 2026 09:28:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://infosec.exchange/@mttaggart/116065340523529645">https://infosec.exchange/@mttaggart/116065340523529645</a>, See on <a href="https://news.ycombinator.com/item?id=47013059">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Zig ‚Äì io_uring and Grand Central Dispatch std.Io implementations landed (209 pts)]]></title>
            <link>https://ziglang.org/devlog/2026/#2026-02-13</link>
            <guid>47012717</guid>
            <pubDate>Sat, 14 Feb 2026 08:22:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ziglang.org/devlog/2026/#2026-02-13">https://ziglang.org/devlog/2026/#2026-02-13</a>, See on <a href="https://news.ycombinator.com/item?id=47012717">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>This page contains a curated list of recent changes to main branch Zig.</p><p>
      This page contains entries for the year <span>2026</span>. Other years are available in
      <a href="https://ziglang.org/devlog/">the Devlog archive page</a>.
    </p><div>
      <div id="2026-02-13">
        <p><span>February 13, 2026</span></p><h2><a href="#2026-02-13">io_uring and Grand Central Dispatch std.Io implementations landed
</a></h2>
        <p>Author: Andrew Kelley</p><p>As we approach the end of the 0.16.0 release cycle, Jacob has been hard at work, bringing <code>std.Io.Evented</code> up to speed with all the latest API changes:</p><ul><li><a href="https://codeberg.org/ziglang/zig/pulls/31158" target="_blank">io_uring implementation</a></li><li><a href="https://codeberg.org/ziglang/zig/pulls/31198" target="_blank">Grand Central Dispatch implementation</a></li></ul><p>Both of these are based on userspace stack switching, sometimes called ‚Äúfibers‚Äù, ‚Äústackful coroutines‚Äù, or ‚Äúgreen threads‚Äù.</p><p>They are now <strong>available to tinker with</strong>, by constructing one‚Äôs application using <code>std.Io.Evented</code>. They should be considered <strong>experimental</strong> because there is important followup work to be done before they can be used reliably and robustly:</p><ul><li><a href="https://codeberg.org/ziglang/zig/issues/31199" target="_blank">better error handling</a></li><li>remove the logging</li><li>diagnose the unexpected performance degradation when using <code>IoMode.evented</code> for the compiler</li><li><a href="https://codeberg.org/ziglang/zig/issues/31200" target="_blank">a couple functions still unimplemented</a></li><li>more test coverage is needed</li><li><a href="https://github.com/ziglang/zig/issues/157" target="_blank">builtin function to tell you the maximum stack size of a given function</a> to make these implementations practical to use when overcommit is off.</li></ul><p>With those caveats in mind, it seems we are indeed reaching the Promised Land, where Zig code can have Io implementations effortlessly swapped out:</p><pre><code><span>const</span> <span>std</span> <span>=</span> <span>@import</span><span>(</span><span>"std"</span><span>)</span><span>;</span>

<span>pub</span> <span>fn</span> <span>main</span><span>(</span><span>init</span><span>:</span> <span>std</span><span>.</span><span>process</span><span>.</span><span>Init</span><span>.</span><span>Minimal</span><span>)</span> <span>!</span><span>void</span> <span>{</span>
    <span>var</span> <span>debug_allocator</span><span>:</span> <span>std</span><span>.</span><span>heap</span><span>.</span><span>DebugAllocator</span><span>(</span><span>.</span><span>{</span><span>}</span><span>)</span> <span>=</span> <span>.</span><span>init</span><span>;</span>
    <span>const</span> <span>gpa</span> <span>=</span> <span>debug_allocator</span><span>.</span><span>allocator</span><span>(</span><span>)</span><span>;</span>

    <span>var</span> <span>threaded</span><span>:</span> <span>std</span><span>.</span><span>Io</span><span>.</span><span>Threaded</span> <span>=</span> <span>.</span><span>init</span><span>(</span><span>gpa</span><span>,</span> <span>.</span><span>{</span>
        <span>.</span><span>argv0</span> <span>=</span> <span>.</span><span>init</span><span>(</span><span>init</span><span>.</span><span>args</span><span>)</span><span>,</span>
        <span>.</span><span>environ</span> <span>=</span> <span>init</span><span>.</span><span>environ</span><span>,</span>
    <span>}</span><span>)</span><span>;</span>
    <span>defer</span> <span>threaded</span><span>.</span><span>deinit</span><span>(</span><span>)</span><span>;</span>
    <span>const</span> <span>io</span> <span>=</span> <span>threaded</span><span>.</span><span>io</span><span>(</span><span>)</span><span>;</span>

    <span>return</span> <span>app</span><span>(</span><span>io</span><span>)</span><span>;</span>
<span>}</span>

<span>fn</span> <span>app</span><span>(</span><span>io</span><span>:</span> <span>std</span><span>.</span><span>Io</span><span>)</span> <span>!</span><span>void</span> <span>{</span>
    <span>try</span> <span>std</span><span>.</span><span>Io</span><span>.</span><span>File</span><span>.</span><span>stdout</span><span>(</span><span>)</span><span>.</span><span>writeStreamingAll</span><span>(</span><span>io</span><span>,</span> <span>"Hello, World!</span><span>\n</span><span>"</span><span>)</span><span>;</span>
<span>}</span>
</code></pre>
<pre><code>$ strace ./hello_threaded
execve("./hello_threaded", ["./hello_threaded"], 0x7ffc1da88b20 /* 98 vars */) = 0
mmap(NULL, 262207, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7f583f338000
arch_prctl(ARCH_SET_FS, 0x7f583f378018) = 0
prlimit64(0, RLIMIT_STACK, NULL, {rlim_cur=8192*1024, rlim_max=RLIM64_INFINITY}) = 0
prlimit64(0, RLIMIT_STACK, {rlim_cur=16384*1024, rlim_max=RLIM64_INFINITY}, NULL) = 0
sigaltstack({ss_sp=0x7f583f338000, ss_flags=0, ss_size=262144}, NULL) = 0
sched_getaffinity(0, 128, [0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]) = 8
rt_sigaction(SIGIO, {sa_handler=0x1019d90, sa_mask=[], sa_flags=SA_RESTORER, sa_restorer=0x10328c0}, {sa_handler=SIG_DFL, sa_mask=[], sa_flags=0}, 8) = 0
rt_sigaction(SIGPIPE, {sa_handler=0x1019d90, sa_mask=[], sa_flags=SA_RESTORER, sa_restorer=0x10328c0}, {sa_handler=SIG_DFL, sa_mask=[], sa_flags=0}, 8) = 0
writev(1, [{iov_base="Hello, World!\n", iov_len=14}], 1Hello, World!
) = 14
rt_sigaction(SIGIO, {sa_handler=SIG_DFL, sa_mask=[], sa_flags=SA_RESTORER, sa_restorer=0x10328c0}, NULL, 8) = 0
rt_sigaction(SIGPIPE, {sa_handler=SIG_DFL, sa_mask=[], sa_flags=SA_RESTORER, sa_restorer=0x10328c0}, NULL, 8) = 0
exit_group(0)                           = ?
+++ exited with 0 +++
</code></pre><p>Swapping out only the I/O implementation:</p><pre><code><span>const</span> <span>std</span> <span>=</span> <span>@import</span><span>(</span><span>"std"</span><span>)</span><span>;</span>

<span>pub</span> <span>fn</span> <span>main</span><span>(</span><span>init</span><span>:</span> <span>std</span><span>.</span><span>process</span><span>.</span><span>Init</span><span>.</span><span>Minimal</span><span>)</span> <span>!</span><span>void</span> <span>{</span>
    <span>var</span> <span>debug_allocator</span><span>:</span> <span>std</span><span>.</span><span>heap</span><span>.</span><span>DebugAllocator</span><span>(</span><span>.</span><span>{</span><span>}</span><span>)</span> <span>=</span> <span>.</span><span>init</span><span>;</span>
    <span>const</span> <span>gpa</span> <span>=</span> <span>debug_allocator</span><span>.</span><span>allocator</span><span>(</span><span>)</span><span>;</span>

    <span>var</span> <span>evented</span><span>:</span> <span>std</span><span>.</span><span>Io</span><span>.</span><span>Evented</span> <span>=</span> <span>undefined</span><span>;</span>
    <span>try</span> <span>evented</span><span>.</span><span>init</span><span>(</span><span>gpa</span><span>,</span> <span>.</span><span>{</span>
        <span>.</span><span>argv0</span> <span>=</span> <span>.</span><span>init</span><span>(</span><span>init</span><span>.</span><span>args</span><span>)</span><span>,</span>
        <span>.</span><span>environ</span> <span>=</span> <span>init</span><span>.</span><span>environ</span><span>,</span>
        <span>.</span><span>backing_allocator_needs_mutex</span> <span>=</span> <span>false</span><span>,</span>
    <span>}</span><span>)</span><span>;</span>
    <span>defer</span> <span>evented</span><span>.</span><span>deinit</span><span>(</span><span>)</span><span>;</span>
    <span>const</span> <span>io</span> <span>=</span> <span>evented</span><span>.</span><span>io</span><span>(</span><span>)</span><span>;</span>

    <span>return</span> <span>app</span><span>(</span><span>io</span><span>)</span><span>;</span>
<span>}</span>

<span>fn</span> <span>app</span><span>(</span><span>io</span><span>:</span> <span>std</span><span>.</span><span>Io</span><span>)</span> <span>!</span><span>void</span> <span>{</span>
    <span>try</span> <span>std</span><span>.</span><span>Io</span><span>.</span><span>File</span><span>.</span><span>stdout</span><span>(</span><span>)</span><span>.</span><span>writeStreamingAll</span><span>(</span><span>io</span><span>,</span> <span>"Hello, World!</span><span>\n</span><span>"</span><span>)</span><span>;</span>
<span>}</span>
</code></pre>
<pre><code>execve("./hello_evented", ["./hello_evented"], 0x7fff368894f0 /* 98 vars */) = 0
mmap(NULL, 262215, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7f70a4c28000
arch_prctl(ARCH_SET_FS, 0x7f70a4c68020) = 0
prlimit64(0, RLIMIT_STACK, NULL, {rlim_cur=8192*1024, rlim_max=RLIM64_INFINITY}) = 0
prlimit64(0, RLIMIT_STACK, {rlim_cur=16384*1024, rlim_max=RLIM64_INFINITY}, NULL) = 0
sigaltstack({ss_sp=0x7f70a4c28008, ss_flags=0, ss_size=262144}, NULL) = 0
sched_getaffinity(0, 128, [0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]) = 8
mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7f70a4c27000
mmap(0x7f70a4c28000, 548864, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7f70a4ba1000
io_uring_setup(64, {flags=IORING_SETUP_COOP_TASKRUN|IORING_SETUP_SINGLE_ISSUER, sq_thread_cpu=0, sq_thread_idle=1000, sq_entries=64, cq_entries=128, features=IORING_FEAT_SINGLE_MMAP|IORING_FEAT_NODROP|IORING_FEAT_SUBMIT_STABLE|IORING_FEAT_RW_CUR_POS|IORING_FEAT_CUR_PERSONALITY|IORING_FEAT_FAST_POLL|IORING_FEAT_POLL_32BITS|IORING_FEAT_SQPOLL_NONFIXED|IORING_FEAT_EXT_ARG|IORING_FEAT_NATIVE_WORKERS|IORING_FEAT_RSRC_TAGS|IORING_FEAT_CQE_SKIP|IORING_FEAT_LINKED_FILE|IORING_FEAT_REG_REG_RING|IORING_FEAT_RECVSEND_BUNDLE|IORING_FEAT_MIN_TIMEOUT|IORING_FEAT_RW_ATTR|IORING_FEAT_NO_IOWAIT, sq_off={head=0, tail=4, ring_mask=16, ring_entries=24, flags=36, dropped=32, array=2112, user_addr=0}, cq_off={head=8, tail=12, ring_mask=20, ring_entries=28, overflow=44, cqes=64, flags=40, user_addr=0}}) = 3
mmap(NULL, 2368, PROT_READ|PROT_WRITE, MAP_SHARED|MAP_POPULATE, 3, 0) = 0x7f70a4ba0000
mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_SHARED|MAP_POPULATE, 3, 0x10000000) = 0x7f70a4b9f000
io_uring_enter(3, 1, 1, IORING_ENTER_GETEVENTS, NULL, 8Hello, World!
) = 1
io_uring_enter(3, 1, 1, IORING_ENTER_GETEVENTS, NULL, 8) = 1
munmap(0x7f70a4b9f000, 4096)            = 0
munmap(0x7f70a4ba0000, 2368)            = 0
close(3)                                = 0
munmap(0x7f70a4ba1000, 548864)          = 0
exit_group(0)                           = ?
+++ exited with 0 +++
</code></pre><p>Key point here being that the <code>app</code> function is identical between those two snippets.</p><p>Moving beyond Hello World, the Zig compiler itself works fine using <code>std.Io.Evented</code>, both with io_uring and with GCD, but as mentioned above, there is a not-yet-diagnosed performance degradation when doing so.</p><p>Happy hacking,</p><p>Andrew</p>
      </div>
    
      <div id="2026-02-06">
        <p><span>February 06, 2026</span></p><h2><a href="#2026-02-06">Two Package Management Workflow Enhancements
</a></h2>
        <p>Author: Andrew Kelley</p><p>If you have a Zig project with dependencies, two big changes just landed which I think you will be interested to learn about.</p><p>Fetched packages are now stored <em>locally</em> in the <code>zig-pkg</code> directory of the project root (next to your <code>build.zig</code> file).</p><p>For example here are a few results from <a href="https://codeberg.org/awebo-chat/awebo" target="_blank">awebo</a> after running <code>zig build</code>:</p><pre><code>$ du -sh zig-pkg/*
13M    freetype-2.14.1-alzUkTyBqgBwke4Jsot997WYSpl207Ij9oO-2QOvGrOi
20K    opus-0.0.2-vuF-cMAkAADVsm707MYCtPmqmRs0gzg84Sz0qGbb5E3w
4.3M   pulseaudio-16.1.1-9-mk_62MZkNwBaFwiZ7ZVrYRIf_3dTqqJR5PbMRCJzSuLw
5.2M   uucode-0.1.0-ZZjBPvtWUACf5dqD_f9I37VGFsN24436CuceC5pTJ25n
728K   vaxis-0.5.1-BWNV_AxECQCj3p4Hcv4U3Yo1WMUJ7Z2FUj0UkpuJGxQQ
</code></pre><p>It is highly recommended to add this directory to the project-local source control ignore file (e.g. <code>.gitignore</code>). However, by being outside of <code>.zig-cache</code>, it provides the possibility of distributing self-contained source tarballs, which contain all dependencies and therefore can be used to build offline, or for archival purposes.</p><p>Meanwhile, an <em>additional</em> copy of the dependency is cached globally. After filtering out all the unused files based on the <code>paths</code> filter, the contents are recompressed:</p><pre><code>$ du -sh ~/.cache/zig/p/*
2.4M    freetype-2.14.1-alzUkTyBqgBwke4Jsot997WYSpl207Ij9oO-2QOvGrOi.tar.gz
4.0K    opus-0.0.2-vuF-cMAkAADVsm707MYCtPmqmRs0gzg84Sz0qGbb5E3w.tar.gz
636K    pulseaudio-16.1.1-9-mk_62MZkNwBaFwiZ7ZVrYRIf_3dTqqJR5PbMRCJzSuLw.tar.gz
880K    uucode-0.1.0-ZZjBPvtWUACf5dqD_f9I37VGFsN24436CuceC5pTJ25n.tar.gz
120K    vaxis-0.5.1-BWNV_BFECQBbXeTeFd48uTJRjD5a-KD6kPuKanzzVB01.tar.gz
</code></pre><p>The motivation for this change is to make it easier to tinker. Go ahead and edit those files, see what happens. Swap out your package directory with a git clone. Grep your dependencies all together. Configure your IDE to auto-complete based on the <code>zig-pkg</code> directory. <a href="https://codeberg.org/awebo-chat/awebo/issues/61" target="_blank">Run baobab on your dependency tree</a>. Furthermore, by having the global cache have compressed files instead makes it easier to share that cached data between computers. In the future, <a href="https://github.com/ziglang/zig/issues/23236" target="_blank">it is planned to support peer-to-peer torrenting of dependency trees</a>. By recompressing packages into a canonical form, this will allow peers to share Zig packages with minimal bandwidth. I love this idea because it simultaneously provides resilience to network outages, as well as a popularity contest. Find out which open source packages are popular based on number of seeders!</p><p>The second change here is the addition of the <code>--fork</code> flag to <code>zig build</code>.</p><p>In retrospect, it seems so obvious, I don‚Äôt know why I didn‚Äôt think of it since the beginning. It looks like this:</p><pre><code>zig build --fork=[path]
</code></pre><p>This is a <strong>project override</strong> option. Given a path to a source checkout of a project, all packages matching that project across the entire dependency tree will be overridden.</p><p>Thanks to the fact that package content hashes include name and fingerprint, <strong>this resolves before the package is potentially fetched</strong>.</p><p>This is an easy way to temporarily use one or more forks which are in entirely separate directories. You can iterate on your entire dependency tree until everything is working, while using comfortably the development environment and source control of the dependency projects.</p><p>The fact that it is a CLI flag makes it appropriately ephemeral. The moment you drop the flags, you‚Äôre back to using your pristine, fetched dependency tree.</p><p>If the project does not match, an error occurs, preventing confusion:</p><pre><code>$ zig build --fork=/home/andy/dev/mime
error: fork /home/andy/dev/mime matched no mime packages
$
</code></pre><p>If the project does match, you get a reminder that you are using a fork, preventing confusion:</p><pre><code>$ zig build --fork=/home/andy/dev/dvui
info: fork /home/andy/dev/dvui matched 1 (dvui) packages
...
</code></pre><p>This functionality is intended to enhance the workflow of dealing with ecosystem breakage. I already tried it a bit and found it to be quite pleasant to work with. The new workflow goes like this:</p><ol><li>Fail to build from source due to ecosystem breakage.</li><li>Tinker with <code>--fork</code> until your project works again. During this time you can use the actual upstream source control, test suite, <code>zig build test --watch -fincremental</code>, etc.</li><li>Now you have a new option: be selfish and just keep working on your own stuff, or you can proceed to submit your patches upstream.</li></ol><p>‚Ä¶and you can probably skip the step where you switch your <code>build.zig.zon</code> to your fork unless you expect upstream to take a long time to merge your fixes.</p>
      </div>
    
      <div id="2026-02-03">
        <p><span>February 03, 2026</span></p><h2><a href="#2026-02-03">Bypassing Kernel32.dll for Fun and Nonprofit
</a></h2>
        <p>Author: Andrew Kelley</p><p>The Windows operating system provides a large ABI surface area for doing things in the kernel. However, not all ABIs are created equally. As Casey Muratori points out in his lecture, <a href="https://www.youtube.com/watch?v=5IUj1EZwpJY" target="_blank">The Only Unbreakable Law</a>, the organizational structure of software development teams has a direct impact on the structure of the software they produce.</p><p>The DLLs on Windows are organized into a heirarchy, with some of the APIs being high-level wrappers around lower-level ones. For example, whenever you call functions of <code>kernel32.dll</code>, ultimately, the actual work is done by <code>ntdll.dll</code>. You can observe this directly by using ProcMon.exe and examining stack traces.</p><p>What we‚Äôve learned empirically is that the ntdll APIs are generally well-engineered, reasonable, and powerful, but the kernel32 wrappers introduce unnecessary heap allocations, additional failure modes, unintentional CPU usage, and bloat.</p><p>This is why the Zig standard library policy is to <a href="https://codeberg.org/ziglang/zig/issues/31131" target="_blank">Prefer the Native API over Win32</a>. We‚Äôre not quite there yet - we have plenty of calls into kernel32 remaining - but we‚Äôve taken great strides recently. I‚Äôll give you two examples.</p><h2>Example 1: Entropy</h2><p>According to the official documentation, Windows does not have a straightforward way to get random bytes.</p><p><a href="https://github.com/rust-random/rand/issues/111" target="_blank">Many projects including Chromium, boringssl, Firefox, and Rust</a> call <code>SystemFunction036</code> from <code>advapi32.dll</code> because it worked on versions older than Windows 8.</p><p>Unfortunately, starting with Windows 8, the first time you call this function, it dynamically loads <code>bcryptprimitives.dll</code> and calls <a href="https://learn.microsoft.com/en-us/windows/win32/seccng/processprng" target="_blank">ProcessPrng</a>. If loading the DLL fails (for example due to an overloaded system, which we have observed on Zig CI several times), it returns error 38 (from a function that has <code>void</code> return type and is documented to never fail).</p><p>The first thing <code>ProcessPrng</code> does is heap allocate a small, constant number of bytes. If this fails it returns <code>NO_MEMORY</code> in a <code>BOOL</code> (documented behavior is to never fail, and always return <code>TRUE</code>).</p><p><code>bcryptprimitives.dll</code> apparently also runs a test suite every time you load it.</p><p>All that <code>ProcessPrng</code> is <em>really</em> doing is <code>NtOpenFile</code> on <code>"\\Device\\CNG"</code> and reading 48 bytes with <code>NtDeviceIoControlFile</code> to get a seed, and then initializing a per-CPU AES-based CSPRNG.</p><p>So the dependency on <code>bcryptprimitives.dll</code> and <code>advapi32.dll</code> can both be avoided, and the nondeterministic failure and latencies on first RNG read can also be avoided.</p><h2>Example 2: NtReadFile and NtWriteFile</h2><p><code>ReadFile</code> looks like this:</p><pre><code><span>pub</span> <span>extern</span> <span>"kernel32"</span> <span>fn</span> <span>ReadFile</span><span>(</span>
    <span>hFile</span><span>:</span> <span>HANDLE</span><span>,</span>
    <span>lpBuffer</span><span>:</span> <span>LPVOID</span><span>,</span>
    <span>nNumberOfBytesToRead</span><span>:</span> <span>DWORD</span><span>,</span>
    <span>lpNumberOfBytesRead</span><span>:</span> <span>?</span><span>*</span><span>DWORD</span><span>,</span>
    <span>lpOverlapped</span><span>:</span> <span>?</span><span>*</span><span>OVERLAPPED</span><span>,</span>
<span>)</span> <span>callconv</span><span>(</span><span>.</span><span>winapi</span><span>)</span> <span>BOOL</span><span>;</span>
</code></pre>
<p><code>NtReadFile</code> looks like this:</p><pre><code><span>pub</span> <span>extern</span> <span>"ntdll"</span> <span>fn</span> <span>NtReadFile</span><span>(</span>
    <span>FileHandle</span><span>:</span> <span>HANDLE</span><span>,</span>
    <span>Event</span><span>:</span> <span>?</span><span>HANDLE</span><span>,</span>
    <span>ApcRoutine</span><span>:</span> <span>?</span><span>*</span><span>const</span> <span>IO_APC_ROUTINE</span><span>,</span>
    <span>ApcContext</span><span>:</span> <span>?</span><span>*</span><span>anyopaque</span><span>,</span>
    <span>IoStatusBlock</span><span>:</span> <span>*</span><span>IO_STATUS_BLOCK</span><span>,</span>
    <span>Buffer</span><span>:</span> <span>*</span><span>anyopaque</span><span>,</span>
    <span>Length</span><span>:</span> <span>ULONG</span><span>,</span>
    <span>ByteOffset</span><span>:</span> <span>?</span><span>*</span><span>const</span> <span>LARGE_INTEGER</span><span>,</span>
    <span>Key</span><span>:</span> <span>?</span><span>*</span><span>const</span> <span>ULONG</span><span>,</span>
<span>)</span> <span>callconv</span><span>(</span><span>.</span><span>winapi</span><span>)</span> <span>NTSTATUS</span><span>;</span>
</code></pre>
<p>As a reminder, <em>the above function is implemented by calling the below function</em>.</p><p>Already we can see some nice things about using the lower level API. For instance, the <em>real</em> API simply gives us the error code as the return value, while the kernel32 wrapper hides the status code somewhere, returns a <code>BOOL</code> and then requires you to call <code>GetLastError</code> to find out what went wrong. Imagine! Returning a value from a function üåà</p><p>Furthermore, <code>OVERLAPPED</code> is a fake type. The Windows kernel doesn‚Äôt actually know or care about it at all! The actual primitives here are events, APCs, and <code>IO_STATUS_BLOCK</code>.</p><p>If you have a synchronous file handle, then <code>Event</code> and <code>ApcRoutine</code> must be <code>null</code>. You get the answer in the <code>IO_STATUS_BLOCK</code> immediately. If you pass an APC routine here then some old bitrotted 32-bit code runs and you get garbage results.</p><p>On the other hand if you have an asynchronous file handle, then you need to either use an <code>Event</code> or an <code>ApcRoutine</code>. <code>kernel32.dll</code> uses events, which means that it‚Äôs doing extra, unnecessary resource allocation and management just to read from a file. Instead, Zig now passes an APC routine and then calls <code>NtDelayExecution</code>. This integrates seamlessly with cancelation, making it possible to cancel tasks while they perform file I/O, regardless of whether the file was opened in synchronous mode or asynchronous mode.</p><p>For a deeper dive into this topic, please refer to this issue:</p><p><a href="https://codeberg.org/ziglang/zig/issues/31131" target="_blank">Windows: Prefer the Native API over Win32</a></p>
      </div>
    
      <div id="2026-01-31">
        <p><span>January 31, 2026</span></p><h2><a href="#2026-01-31">zig libc
</a></h2>
        <p>Author: Andrew Kelley</p><p>Over the past month or so, several enterprising contributors have taken an interest in the <a href="https://codeberg.org/ziglang/zig/issues/30978" target="_blank">zig libc subproject</a>. The idea here is to incrementally delete redundant code, by providing libc functions as Zig standard library wrappers rather than as vendored C source files. In many cases, these functions are one-to-one mappings, such as <code>memcpy</code> or <code>atan2</code>, or trivially wrap a generic function, like <code>strnlen</code>:</p><pre><code><span>fn</span> <span>strnlen</span><span>(</span><span>str</span><span>:</span> <span>[</span><span>*</span><span>:</span><span>0</span><span>]</span><span>const</span> <span>c_char</span><span>,</span> <span>max</span><span>:</span> <span>usize</span><span>)</span> <span>callconv</span><span>(</span><span>.</span><span>c</span><span>)</span> <span>usize</span> <span>{</span>
    <span>return</span> <span>std</span><span>.</span><span>mem</span><span>.</span><span>findScalar</span><span>(</span><span>u8</span><span>,</span> <span>@ptrCast</span><span>(</span><span>str</span><span>[</span><span>0</span><span>..</span><span>max</span><span>]</span><span>)</span><span>,</span> <span>0</span><span>)</span> <span>orelse</span> <span>max</span><span>;</span>
<span>}</span>
</code></pre>
<p>So far, roughly 250 C source files have been deleted from the Zig repository, with 2032 remaining.</p><p>With each function that makes the transition, Zig gains independence from third party projects and from the C programming language, compilation speed improves, Zig‚Äôs installation size is simplified and reduced, and user applications which statically link libc enjoy reduced binary size.</p><p>Additionally, a <a href="https://codeberg.org/ziglang/zig/pulls/31037" target="_blank">recent enhancement</a> now makes zig libc share the Zig Compilation Unit with other Zig code rather than being a separate static archive, linked together later. This is one of the advantages of Zig having an integrated compiler and linker. When the exported libc functions share the ZCU, redundant code is eliminated because functions can be optimized together. It‚Äôs kind of like enabling LTO (Link-Time Optimization) across the libc boundary, except it‚Äôs done properly in the frontend instead of too late, in the linker.</p><p>Furthermore, when this work is combined with the recent <a href="https://codeberg.org/ziglang/zig/issues/30150" target="_blank">std.Io changes</a>, there is potential for users to seamlessly control how libc performs I/O - for example forcing all calls to <code>read</code> and <code>write</code> to participate in an io_uring event loop, even though that code was not written with such use case in mind. Or, <a href="https://codeberg.org/ziglang/zig/pulls/30788" target="_blank">resource leak detection</a> could be enabled for third-party C code. For now this is only a vaporware idea which has not been experimented with, but the idea intrigues me.</p><p>Big thanks to Szabolcs Nagy for <a href="https://wiki.musl-libc.org/libc-test.html" target="_blank">libc-test</a>. This project has been a huge help in making sure that we don‚Äôt regress any math functions.</p><p>As a reminder to our users, now that Zig is transitioning to being the static libc provider, if you encounter issues with the musl, mingw-w64, or wasi-libc libc functionality provided by Zig, <strong>please file bug reports in Zig first</strong> so we don‚Äôt annoy maintainers for bugs that are in Zig, and no longer vendored by independent libc implementation projects.</p><p>The very same day I sat at home writing this devlog like a coward, less than five miles away, <a href="https://www.kptv.com/2026/01/31/live-labor-unions-rally-march-portland-ice-facility-protest/" target="_blank">armed forces who are in my city against the will of our elected officials shot tear gas, unprovoked, at peaceful protestors</a>. Next time I hope to have the courage to join my neighbors, and I hope to not get shot like <a href="https://en.wikipedia.org/wiki/Killing_of_Alex_Pretti" target="_blank">Alex Pretti</a> and <a href="https://en.wikipedia.org/wiki/Killing_of_Ren%C3%A9e_Good" target="_blank">Ren√©e Good</a>.</p>
      </div>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Backblaze Drive Stats for 2025 (115 pts)]]></title>
            <link>https://www.backblaze.com/blog/backblaze-drive-stats-for-2025/</link>
            <guid>47011602</guid>
            <pubDate>Sat, 14 Feb 2026 04:35:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.backblaze.com/blog/backblaze-drive-stats-for-2025/">https://www.backblaze.com/blog/backblaze-drive-stats-for-2025/</a>, See on <a href="https://news.ycombinator.com/item?id=47011602">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
          <main id="main">

<div>

		<article id="post-112774">

			<!-- .entry-header -->

			<section>
				
<figure><img fetchpriority="high" decoding="async" width="1440" height="820" src="https://www.backblaze.com/blog/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-Blog-Header-1440x820-1.png" alt="A decorative header showing hard drives with the title 2025 Year-End Report Drive Stats. " srcset="https://backblazeprod.wpenginepowered.com/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-Blog-Header-1440x820-1.png 1440w, https://backblazeprod.wpenginepowered.com/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-Blog-Header-1440x820-1-300x171.png 300w, https://backblazeprod.wpenginepowered.com/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-Blog-Header-1440x820-1-1024x583.png 1024w, https://backblazeprod.wpenginepowered.com/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-Blog-Header-1440x820-1-768x437.png 768w" sizes="(max-width: 1440px) 100vw, 1440px"></figure>







<p>This year marks 13 years of collecting Drive Stats data. Thirteen is an unlucky number (to some), but we count our lucky stars (or perhaps our lucky stats?) that we‚Äôve had 13 years of <a href="https://www.backblaze.com/blog/category/cloud-storage/hard-drive-stats/" target="_blank" rel="noreferrer noopener">this experiment</a>.&nbsp;</p>



<p>The traditional 13-year anniversary gift is lace‚Äîintricate, impressive, and vulnerable to a snag if you don‚Äôt plan ahead to protect the pattern. Systems, like lace, don‚Äôt survive by pretending there are no points of vulnerability. When it comes to our infrastructure, we want to build with the snags in mind to create something durable, and the Drive Stats series is always seeking to publish and provide data so that you, too, can go the distance with your drives.&nbsp;</p>



<p>This year-end Drive Stats report looks at Q4 2025, the full year, and the lifetime view with that in mind. I think you‚Äôll find the same things we do: over time, the patterns matter more than any single strand (or drive, to run this lace metaphor into the ground once and for all). Let‚Äôs look at the stats.&nbsp;</p>



<div>
<h4>Drive Stats is here for you</h4><p>
Drive Stats is not a situationship. We‚Äôre a conversation and a relationship‚Äîto the data. Join the Drive Stats team for our regularly scheduled webinar to walk through the 2025 annualized failure rates, break down the data for interesting trends, and get the latest from the Backblaze drive fleet happenings. 
</p><!--HubSpot Call-to-Action Code --><p><span id="hs-cta-wrapper-698736ef-b814-4bce-bab6-8b1a6de52f39"><span id="hs-cta-698736ef-b814-4bce-bab6-8b1a6de52f39"><!--[if lte IE 8]><div id="hs-cta-ie-element"></div><![endif]--><a href="https://cta-redirect.hubspot.com/cta/redirect/2832298/698736ef-b814-4bce-bab6-8b1a6de52f39" target="_blank" rel="noopener"><img decoding="async" id="hs-cta-img-698736ef-b814-4bce-bab6-8b1a6de52f39" src="https://no-cache.hubspot.com/cta/default/2832298/698736ef-b814-4bce-bab6-8b1a6de52f39.png" alt="Once More With Feeling"></a></span></span></p><!-- end HubSpot Call-to-Action Code -->
</div>



<h2>Drive Stats: The digest version</h2>


<div>
<figure><img decoding="async" width="1920" height="1620" src="https://www.backblaze.com/blog/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-_-Infographic.png" alt="A summary infographic showing the Q4 2025, annual, and lifetime hard drive failure rates. " srcset="https://backblazeprod.wpenginepowered.com/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-_-Infographic.png 1920w, https://backblazeprod.wpenginepowered.com/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-_-Infographic-300x253.png 300w, https://backblazeprod.wpenginepowered.com/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-_-Infographic-1024x864.png 1024w, https://backblazeprod.wpenginepowered.com/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-_-Infographic-768x648.png 768w, https://backblazeprod.wpenginepowered.com/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-_-Infographic-1536x1296.png 1536w, https://backblazeprod.wpenginepowered.com/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-_-Infographic-1568x1323.png 1568w" sizes="(max-width: 1920px) 100vw, 1920px"></figure></div>


<h2>Q4 2025 hard drive failure rates</h2>



<p>As of the end of 2025, Backblaze was monitoring 341,664 drives used to store data. For our evaluation, we removed from consideration 4,013 boot drives and 459 hard drives, as they did not meet the criteria to be included. We‚Äôll discuss the criteria we used in the next section of this report. Removing these drives leaves us with 337,192 hard drives to analyze. The table below shows the annualized failure rates for Q4 2025 for this collection of drives.</p>



<div>
<p><strong>Backblaze Hard Drive Failure Rates for Q4 2025</strong></p>



<div><p>Reporting period October 1, 2025‚ÄìDecember 31, 2025 inclusive<br>Drive models with drive count &gt; 100 as of December 31, 2025 and drive days &gt; 10,000 in Q4 2025.</p></div>
</div>


<div>
<figure data-wp-context="{&quot;imageId&quot;:&quot;699077376dbf5&quot;}" data-wp-interactive="core/image"><img decoding="async" width="1024" height="932" data-wp-class--hide="state.isContentHidden" data-wp-class--show="state.isContentVisible" data-wp-init="callbacks.setButtonStyles" data-wp-on-async--click="actions.showLightbox" data-wp-on-async--load="callbacks.setButtonStyles" data-wp-on-async-window--resize="callbacks.setButtonStyles" src="https://www.backblaze.com/blog/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-Quarterly-1024x932.png" alt="A chart showing the quarterly hard drive failure rates for Q4 2025. " srcset="https://backblazeprod.wpenginepowered.com/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-Quarterly-1024x932.png 1024w, https://backblazeprod.wpenginepowered.com/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-Quarterly-300x273.png 300w, https://backblazeprod.wpenginepowered.com/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-Quarterly-768x699.png 768w, https://backblazeprod.wpenginepowered.com/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-Quarterly-1536x1397.png 1536w, https://backblazeprod.wpenginepowered.com/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-Quarterly-1568x1427.png 1568w, https://backblazeprod.wpenginepowered.com/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-Quarterly.png 1862w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></div>






<h3>Note and observations</h3>



<ul>
<li>New drives!
<ul>
<li>Seagate ST16000NM000J 16TB, with 112 drives</li>



<li>WDC WUH722626ALE6L4 26TB with 1,201 drives. Our first 26TB drive!&nbsp;</li>
</ul>
</li>



<li>The honor roll:
<ul>
<li>HGST HMS5C4040BLE640 4TB: 1 failure&nbsp;</li>



<li>Seagate ST8000NM000A 8TB: 0 failure&nbsp;</li>



<li>Seagate ST12000NM000J 12TB: 1 failure&nbsp;</li>



<li>Seagate ST16000NM000J 16TB: 1 failure</li>



<li>Seagate ST16000NM002J 16TB: 0 failure&nbsp;</li>



<li>WDC WUH722626ALE6L4 26TB: 1 failure. Shoutout to the new kid‚Äîstarting off strong!</li>
</ul>
</li>



<li>Red flags:
<ul>
<li>HGST HUH728080ALE600 8TB: 10.29%</li>



<li>Seagate ST10000NM0086 10TB: 5.23%</li>



<li>Toshiba MG08ACA16TEY 16TB: 4.14%</li>
</ul>
</li>
</ul>



<p>We talked about two of these drives <a href="https://www.backblaze.com/blog/backblaze-drive-stats-for-q3-2025/" target="_blank" rel="noreferrer noopener">last quarter</a>, and what we said about the Seagate still holds true‚Äîwe‚Äôre seeing end of life activity with this drive. But, let‚Äôs dig in on the 8TB HGST and 16TB Toshiba and see what‚Äôs going on.&nbsp;</p>



<h3>HGST HUH728080ALE600 8TB</h3>



<p>There‚Äôs always some digging to be done when we see a double digit failure rate, especially on a drive that, in the past year, hasn‚Äôt had terrible failure rates (despite the fact that it‚Äôs about 7.5 years old).</p>


<div>
<figure data-wp-context="{&quot;imageId&quot;:&quot;699077376e4f9&quot;}" data-wp-interactive="core/image"><img loading="lazy" decoding="async" width="1024" height="633" data-wp-class--hide="state.isContentHidden" data-wp-class--show="state.isContentVisible" data-wp-init="callbacks.setButtonStyles" data-wp-on-async--click="actions.showLightbox" data-wp-on-async--load="callbacks.setButtonStyles" data-wp-on-async-window--resize="callbacks.setButtonStyles" src="https://www.backblaze.com/blog/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-HGST-HUH728080ALE600-8TB-1-1024x633.png" alt="A quarter-over-quarter analysis of the failure rates of an 8TB HGST drive, model number HUH728080ALE600.  " srcset="https://backblazeprod.wpenginepowered.com/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-HGST-HUH728080ALE600-8TB-1-1024x633.png 1024w, https://backblazeprod.wpenginepowered.com/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-HGST-HUH728080ALE600-8TB-1-300x185.png 300w, https://backblazeprod.wpenginepowered.com/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-HGST-HUH728080ALE600-8TB-1-768x475.png 768w, https://backblazeprod.wpenginepowered.com/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-HGST-HUH728080ALE600-8TB-1.png 1446w" sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure></div>






<p>It‚Äôs worth contextualizing, first, that the total drive count of this model is 1,073, which equates to less than one Vault. (A standard Vault has 1,200 drives.) While Vaults aren‚Äôt <em>always</em> the same drive model, especially with older drives, in an ideal world, those Vaults would be uniform. So, in this case, we‚Äôre dealing with drives that are all hanging out in the same location in a data center, which means we could be working with environmental factors like a change in temperature or airflow.&nbsp;</p>



<p>By the time Drive Stats data gets to me, of course, lots of smart people have already seen the disturbances in the force, so to speak. When I dug into the data center work tickets, it turned turned out that folks had already ruled out temperature as a factor‚Äîthe working theory at the moment is that the drive could be sensitive to vibration, but given the age of these drives, we decided to just flag them for our <a href="https://www.backblaze.com/blog/how-backblaze-scales-our-storage-cloud/" target="_blank" rel="noreferrer noopener">normal CVT migration process</a>.&nbsp;</p>



<h3>Toshiba MG08ACA16TEY 16TB</h3>



<p>We talked about this model last quarter because it clocked in at a 16.95% AFR (!!). Our investigation turned up some collaborative (and routine) firmware work with Toshiba, and at that time, we predicted that these failure rates would normalize once again. We‚Äôre still a little high, but that‚Äôs likely a function of rolling out the work. As predicted, this is a healthy normalization.</p>


<div>
<figure data-wp-context="{&quot;imageId&quot;:&quot;699077376eb8d&quot;}" data-wp-interactive="core/image"><img loading="lazy" decoding="async" width="1024" height="633" data-wp-class--hide="state.isContentHidden" data-wp-class--show="state.isContentVisible" data-wp-init="callbacks.setButtonStyles" data-wp-on-async--click="actions.showLightbox" data-wp-on-async--load="callbacks.setButtonStyles" data-wp-on-async-window--resize="callbacks.setButtonStyles" src="https://www.backblaze.com/blog/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-Toshiba-MG08ACA16TEY-1-1024x633.png" alt="A quarter-over-quarter analysis of a 16TB Toshiba drive, model number MG08ACA16TEY. " srcset="https://backblazeprod.wpenginepowered.com/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-Toshiba-MG08ACA16TEY-1-1024x633.png 1024w, https://backblazeprod.wpenginepowered.com/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-Toshiba-MG08ACA16TEY-1-300x185.png 300w, https://backblazeprod.wpenginepowered.com/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-Toshiba-MG08ACA16TEY-1-768x475.png 768w, https://backblazeprod.wpenginepowered.com/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-Toshiba-MG08ACA16TEY-1.png 1446w" sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure></div>






<h2>Defining the relationship, aka setting some boundaries</h2>



<p>We‚Äôve covered the reasons that we‚Äôve designed these exclusions in <a href="https://www.backblaze.com/blog/category/cloud-storage/hard-drive-stats/">past reports</a>, but here‚Äôs the quick and dirty:</p>



<table id="tablepress-78">
<thead>
<tr>
	<th>Period</th><th>Drive Count</th><th>Drive Days</th>
</tr>
</thead>
<tbody>
<tr>
	<td><strong>Quarterly</strong></td><td>&gt; 100</td><td>&gt; 10,000</td>
</tr>
<tr>
	<td><strong>Annual</strong></td><td>&gt; 250</td><td>&gt; 50,000</td>
</tr>
<tr>
	<td><strong>Lifetime</strong></td><td>&gt; 500</td><td>&gt;100,000</td>
</tr>
</tbody>
</table>
<!-- #tablepress-78 from cache -->



<p>Regardless of whether or not a given drive model is included in this article‚Äôs charts and tables, all of the line item data is included in our Drive Stats dataset which you can download by visiting our Drive Stats page.</p>



<!--HubSpot Call-to-Action Code --><span id="hs-cta-wrapper-048458a8-612e-40fd-84e4-839fcd09f168"><span id="hs-cta-048458a8-612e-40fd-84e4-839fcd09f168"><!--[if lte IE 8]><div id="hs-cta-ie-element"></div><![endif]--><a href="https://cta-redirect.hubspot.com/cta/redirect/2832298/048458a8-612e-40fd-84e4-839fcd09f168" target="_blank" rel="noopener"><img decoding="async" id="hs-cta-img-048458a8-612e-40fd-84e4-839fcd09f168" src="https://no-cache.hubspot.com/cta/default/2832298/048458a8-612e-40fd-84e4-839fcd09f168.png" alt="Sharing Is Caring"></a></span></span><!-- end HubSpot Call-to-Action Code -->







<h2>2025 Annual hard drive failure rates</h2>



<p>As of the end of 2025, Backblaze was monitoring 349,462 hard drives used to store data. We removed 4,176 boot drives and 1,090 hard drives from consideration as they did not meet the annual criteria we have defined. This leaves us with 344,196 drives divided across 30 different drive models. The table below shows the AFRs for 2025 for this collection of drives.</p>



<div>
<p><strong>Backblaze Hard Drive Failure Rates for 2025</strong></p>




</div>


<div>
<figure data-wp-context="{&quot;imageId&quot;:&quot;699077376f467&quot;}" data-wp-interactive="core/image"><img loading="lazy" decoding="async" width="1024" height="952" data-wp-class--hide="state.isContentHidden" data-wp-class--show="state.isContentVisible" data-wp-init="callbacks.setButtonStyles" data-wp-on-async--click="actions.showLightbox" data-wp-on-async--load="callbacks.setButtonStyles" data-wp-on-async-window--resize="callbacks.setButtonStyles" src="https://www.backblaze.com/blog/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-Annual-1024x952.png" alt="A table that shows the annual hard drive failure rates as of Q4 2025." srcset="https://backblazeprod.wpenginepowered.com/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-Annual-1024x952.png 1024w, https://backblazeprod.wpenginepowered.com/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-Annual-300x279.png 300w, https://backblazeprod.wpenginepowered.com/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-Annual-768x714.png 768w, https://backblazeprod.wpenginepowered.com/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-Annual-1536x1427.png 1536w, https://backblazeprod.wpenginepowered.com/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-Annual-1568x1457.png 1568w, https://backblazeprod.wpenginepowered.com/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-Annual.png 1868w" sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure></div>






<h3>Notes and observations</h3>



<ul>
<li><strong>The annual AFR is down:</strong> This year finishes strong at 1.36%, down from 1.55% in 2024. Still those paying attention to the quarterly AFR have seen some volatility in that number.</li>
</ul>


<div>
<figure data-wp-context="{&quot;imageId&quot;:&quot;699077376fb17&quot;}" data-wp-interactive="core/image"><img loading="lazy" decoding="async" width="1024" height="633" data-wp-class--hide="state.isContentHidden" data-wp-class--show="state.isContentVisible" data-wp-init="callbacks.setButtonStyles" data-wp-on-async--click="actions.showLightbox" data-wp-on-async--load="callbacks.setButtonStyles" data-wp-on-async-window--resize="callbacks.setButtonStyles" src="https://www.backblaze.com/blog/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-2025-Quarterly-AFRs-1-1024x633.png" alt="A graph showing the 2025 quarterly hard drive failure rates. " srcset="https://backblazeprod.wpenginepowered.com/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-2025-Quarterly-AFRs-1-1024x633.png 1024w, https://backblazeprod.wpenginepowered.com/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-2025-Quarterly-AFRs-1-300x185.png 300w, https://backblazeprod.wpenginepowered.com/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-2025-Quarterly-AFRs-1-768x475.png 768w, https://backblazeprod.wpenginepowered.com/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-2025-Quarterly-AFRs-1.png 1446w" sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure></div>






<ul>
<li><strong>Nobody made it out unscathed:</strong> There are zero 0 failures.</li>



<li><strong>But, let‚Äôs talk about it:</strong> These are the drives that averaged less than two failures per quarter (though, not necessarily evenly distributed when you look at the data).
<ul>
<li>HGST HMS5C4040BLE640 4TB: 5 failures</li>



<li>Seagate ST12000NM000J 12TB: 4 failures&nbsp;</li>



<li>Seagate ST14000NM000J 14TB: 7 failures&nbsp;</li>



<li>Seagate ST16000NM002J 16TB: 1 failure</li>



<li>Toshiba MG09ACA16TE 16TB: 3 failures</li>



<li>WDC WUH722626ALE6L4 26TB: 1 failures.
<ul>
<li>Note that this drive is in its first quarter of life, so it‚Äôs hard to call this significant yet.&nbsp;</li>
</ul>
</li>
</ul>
</li>
</ul>



<p>And, all those drive tickets and models mean lots and lots of work‚Äîwe wrote a <a href="https://www.backblaze.com/blog/2025-thats-a-wrap-and-here-are-the-stats/" target="_blank" rel="noreferrer noopener">whole article</a> on that front, but here‚Äôs a breakdown of hours spent in each data center.&nbsp;</p>



<figure><img loading="lazy" decoding="async" width="738" height="457" src="https://www.backblaze.com/blog/wp-content/uploads/2026/02/Total-time-spent-per-data-center.png" alt="A chart showing the total work time spent per data center in 2025. " srcset="https://backblazeprod.wpenginepowered.com/wp-content/uploads/2026/02/Total-time-spent-per-data-center.png 738w, https://backblazeprod.wpenginepowered.com/wp-content/uploads/2026/02/Total-time-spent-per-data-center-300x186.png 300w" sizes="auto, (max-width: 738px) 100vw, 738px"></figure>







<p>And here‚Äôs an even more interesting slice, from a drive perspective:</p>


<div>
<figure data-wp-context="{&quot;imageId&quot;:&quot;69907737702ab&quot;}" data-wp-interactive="core/image"><img loading="lazy" decoding="async" width="921" height="569" data-wp-class--hide="state.isContentHidden" data-wp-class--show="state.isContentVisible" data-wp-init="callbacks.setButtonStyles" data-wp-on-async--click="actions.showLightbox" data-wp-on-async--load="callbacks.setButtonStyles" data-wp-on-async-window--resize="callbacks.setButtonStyles" src="https://www.backblaze.com/blog/wp-content/uploads/2026/02/Most-replaced-drive-by-capacity-.png" alt="A graph showing the most replaced drives by capacity in 2025. " srcset="https://backblazeprod.wpenginepowered.com/wp-content/uploads/2026/02/Most-replaced-drive-by-capacity-.png 921w, https://backblazeprod.wpenginepowered.com/wp-content/uploads/2026/02/Most-replaced-drive-by-capacity--300x185.png 300w, https://backblazeprod.wpenginepowered.com/wp-content/uploads/2026/02/Most-replaced-drive-by-capacity--768x474.png 768w" sizes="auto, (max-width: 921px) 100vw, 921px"></figure></div>






<p>Yes, you‚Äôll see some funky drive sizes on that list; it‚Äôs inclusive of all of our drives, not just the hard drives we include in this report.&nbsp;</p>



<h2>Comparing Drive Stats for 2023, 2024, and 2025</h2>



<p>Let‚Äôs take a look back at the previous years‚Äô annual AFRs to get a sense of how 2025 compares: </p>



<div>
<p><strong>Three Year Comparison of Annual Backblaze Hard Drive Failure Rates</strong></p>




</div>


<div>
<figure data-wp-context="{&quot;imageId&quot;:&quot;69907737709ac&quot;}" data-wp-interactive="core/image"><img loading="lazy" decoding="async" width="1024" height="927" data-wp-class--hide="state.isContentHidden" data-wp-class--show="state.isContentVisible" data-wp-init="callbacks.setButtonStyles" data-wp-on-async--click="actions.showLightbox" data-wp-on-async--load="callbacks.setButtonStyles" data-wp-on-async-window--resize="callbacks.setButtonStyles" src="https://www.backblaze.com/blog/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-3-Year-Comparison-1024x927.png" alt="A table comparing the annual hard drive failure rates for 2023, 2024, and 2025." srcset="https://backblazeprod.wpenginepowered.com/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-3-Year-Comparison-1024x927.png 1024w, https://backblazeprod.wpenginepowered.com/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-3-Year-Comparison-300x271.png 300w, https://backblazeprod.wpenginepowered.com/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-3-Year-Comparison-768x695.png 768w, https://backblazeprod.wpenginepowered.com/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-3-Year-Comparison-1536x1390.png 1536w, https://backblazeprod.wpenginepowered.com/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-3-Year-Comparison-2048x1853.png 2048w, https://backblazeprod.wpenginepowered.com/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-3-Year-Comparison-1568x1419.png 1568w" sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure></div>






<h3>Notes and observations</h3>



<ul>
<li><strong>The annual AFR is down to 1.36%.</strong> We haven‚Äôt seen those numbers since 2022 (1.37%). Cool!</li>
</ul>


<div>
<figure data-wp-context="{&quot;imageId&quot;:&quot;6990773770f0c&quot;}" data-wp-interactive="core/image"><img loading="lazy" decoding="async" width="1024" height="633" data-wp-class--hide="state.isContentHidden" data-wp-class--show="state.isContentVisible" data-wp-init="callbacks.setButtonStyles" data-wp-on-async--click="actions.showLightbox" data-wp-on-async--load="callbacks.setButtonStyles" data-wp-on-async-window--resize="callbacks.setButtonStyles" src="https://www.backblaze.com/blog/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-Annual-AFR-2022%E2%80%932025-1-1024x633.png" alt="A year-on-year graph showing the annual hard drive failure rates from 2022‚Äì2025. " srcset="https://backblazeprod.wpenginepowered.com/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-Annual-AFR-2022%E2%80%932025-1-1024x633.png 1024w, https://backblazeprod.wpenginepowered.com/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-Annual-AFR-2022%E2%80%932025-1-300x185.png 300w, https://backblazeprod.wpenginepowered.com/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-Annual-AFR-2022%E2%80%932025-1-768x475.png 768w, https://backblazeprod.wpenginepowered.com/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-Annual-AFR-2022%E2%80%932025-1.png 1446w" sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure></div>






<ul>
<li>Slicing our data by drive size shows how impactful the shift to high capacity drives really is: based on the current quarterly data, our drive size breakdown looks like this:
<ul>
<li>0‚Äì12TB: 25.13%</li>



<li>14‚Äì16TB: 52.06%</li>



<li>20TB+: 22.81%&nbsp;</li>
</ul>
</li>
</ul>



<p>This is an already long report, so in the interest of time, we‚Äôll just say this: There are multiple factors that go into how and why things are changing, including the <a href="https://www.backblaze.com/blog/are-hard-drives-getting-better-lets-revisit-the-bathtub-curve/" target="_blank" rel="noreferrer noopener">average age of drives</a> within our cohort, how much drive technology has improved over the years, how drives on the market have <a href="https://www.youtube.com/watch?v=4TZ3F5bv2T0">gotten bigger over time while the cost per GB</a> has also dropped, and how the <a href="https://www.tomshardware.com/pc-components/hdds/hard-drive-prices-have-surged-by-an-average-of-46-percent-since-september-iconic-24tb-seagate-barracuda-now-usd500-as-ai-claims-another-victim" target="_blank" rel="noreferrer noopener">current demand for drives</a> has been changing some of those things.  &nbsp;</p>



<p>If that sentence sounds confusing, welcome to the world of enterprise drive buying. But, as always, we have to contextualize the real data we see with the way we source and use drives.&nbsp;</p>



<h2>Lifetime hard drive failure rates</h2>



<div>
<p><strong>Backblaze Lifetime Hard Drive Failure Rates&nbsp;</strong></p>




</div>


<div>
<figure data-wp-context="{&quot;imageId&quot;:&quot;69907737716a9&quot;}" data-wp-interactive="core/image"><img loading="lazy" decoding="async" width="1024" height="881" data-wp-class--hide="state.isContentHidden" data-wp-class--show="state.isContentVisible" data-wp-init="callbacks.setButtonStyles" data-wp-on-async--click="actions.showLightbox" data-wp-on-async--load="callbacks.setButtonStyles" data-wp-on-async-window--resize="callbacks.setButtonStyles" src="https://www.backblaze.com/blog/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-Lifetime-1024x881.png" alt="A table that shows the lifetime hard drive failure rates as of Q4 2025." srcset="https://backblazeprod.wpenginepowered.com/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-Lifetime-1024x881.png 1024w, https://backblazeprod.wpenginepowered.com/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-Lifetime-300x258.png 300w, https://backblazeprod.wpenginepowered.com/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-Lifetime-768x661.png 768w, https://backblazeprod.wpenginepowered.com/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-Lifetime-1536x1321.png 1536w, https://backblazeprod.wpenginepowered.com/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-Lifetime-1568x1349.png 1568w, https://backblazeprod.wpenginepowered.com/wp-content/uploads/2026/02/Q4-2025-Drive-Stats-Lifetime.png 1902w" sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure></div>






<h3>Notes and observations</h3>



<ul>
<li><strong>Ol‚Äô faithful: </strong>Lifetime AFR is 1.30% this quarter, and there‚Äôs been no significant change in that number for quite some time.&nbsp;</li>



<li><strong>Say hi to the new guy: </strong>The Toshiba MG11ACA24TE 24TB made the cut for the lifetime table. Last quarter, we deployed another 2,400 of these, bringing us to 4,806 drives total.&nbsp;</li>
</ul>



<h2>The Hard Drive dataset (and beyond)</h2>



<p>Thank you, as always, for making it through ~2,500 or so words to examine the fun side of data. Here‚Äôs our standard fine print:&nbsp;</p>



<p>The complete dataset used to create the tables and charts in this report is available on our <a href="https://www.backblaze.com/cloud-storage/resources/hard-drive-test-data" target="_blank" rel="noreferrer noopener">Hard Drive Test Data page</a>. You can download and use this data for free for your own purpose. All we ask are three things:&nbsp;</p>



<ol>
<li>You cite Backblaze as the source if you use the data;&nbsp;</li>



<li>You accept that you are solely responsible for how you use the data, and;&nbsp;</li>



<li>You do not sell this data itself to anyone; it is free.</li>
</ol>



<p>If you‚Äôre a new Drive Stats fan, consider <a href="https://hub.backblaze.com/drive-stats-newsletter-sign-up" target="_blank" rel="noreferrer noopener">signing up for the newsletter.</a> If you‚Äôre not ready for that kind of commitment, sound off in the comments section below or reach out <a href="mailto:evangelism@backblaze.com" target="_blank" rel="noreferrer noopener">directly to us</a> to let us know what you‚Äôre working on. Happy investigating!</p>

							</section><!-- .entry-content -->

			
		<!-- taxonomy -->
		
		<!-- .entry-footer -->

						<section>
		<img alt="" data-del="avatar" src="https://www.backblaze.com/blog/wp-content/uploads/2024/03/BB-flame-icon-300x300-1-150x150.jpg" height="100" width="100">		<div>
			
			<p> Meet the Backblaze Drive Stats team, and sign up for more newsletter happenings on the <a href="https://hub.backblaze.com/drive-stats-newsletter-sign-up" rel="noopener nofollow">Drive Stats newsletter.</a>

<strong>Stephanie Doyle</strong> is the Writer and Blog Operations Specialist at Backblaze. She specializes in taking complex topics and writing relatable, engaging, and user-friendly content. You can most often find her reading in public places, and can connect with her on <a href="https://www.linkedin.com/in/sdoyle24">LinkedIn</a>.

<strong>Pat Patterson</strong> is the chief technical evangelist at Backblaze. Over his three decades in the industry, Pat has built software and communities at Sun Microsystems, Salesforce, StreamSets, and Citrix. In his role at Backblaze, he creates and delivers content tailored to the needs of the hands-on technical professional, acts as the ‚Äúvoice of the developer‚Äù on the Product team, and actively participates in the wider technical community. Outside the office, Pat runs far, having completed ultramarathons up to the 50 mile distance. Catch up with Pat via <a href="https://bsky.app/profile/metadaddy.net" rel="noopener">Bluesky</a> or <a href="https://www.linkedin.com/in/metadaddy/" rel="noopener">LinkedIn</a>.</p><!-- .author-description -->
		</div><!-- .author-bio-content -->
	</section><!-- .author-bio -->
				

		<!-- end .related-posts -->
	</article><!-- #post-112774 -->
	




	</div><!-- end .main-content -->


			</main><!-- #main -->
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: SQL-tap ‚Äì Real-time SQL traffic viewer for PostgreSQL and MySQL (160 pts)]]></title>
            <link>https://github.com/mickamy/sql-tap</link>
            <guid>47011567</guid>
            <pubDate>Sat, 14 Feb 2026 04:27:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/mickamy/sql-tap">https://github.com/mickamy/sql-tap</a>, See on <a href="https://news.ycombinator.com/item?id=47011567">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">sql-tap</h2><a id="user-content-sql-tap" aria-label="Permalink: sql-tap" href="#sql-tap"></a></p>
<p dir="auto">Real-time SQL traffic viewer ‚Äî proxy daemon + TUI client.</p>
<p dir="auto">sql-tap sits between your application and your database (PostgreSQL or MySQL), capturing every query and displaying it
in an interactive terminal UI. Inspect queries, view transactions, and run EXPLAIN ‚Äî all without changing your
application code.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/mickamy/sql-tap/blob/main/docs/demo.gif"><img src="https://github.com/mickamy/sql-tap/raw/main/docs/demo.gif" alt="demo" data-animated-image=""></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Homebrew</h3><a id="user-content-homebrew" aria-label="Permalink: Homebrew" href="#homebrew"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="brew install --cask mickamy/tap/sql-tap"><pre>brew install --cask mickamy/tap/sql-tap</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Go</h3><a id="user-content-go" aria-label="Permalink: Go" href="#go"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="go install github.com/mickamy/sql-tap@latest
go install github.com/mickamy/sql-tap/cmd/sql-tapd@latest"><pre>go install github.com/mickamy/sql-tap@latest
go install github.com/mickamy/sql-tap/cmd/sql-tapd@latest</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Build from source</h3><a id="user-content-build-from-source" aria-label="Permalink: Build from source" href="#build-from-source"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/mickamy/sql-tap.git
cd sql-tap
make install"><pre>git clone https://github.com/mickamy/sql-tap.git
<span>cd</span> sql-tap
make install</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Docker</h3><a id="user-content-docker" aria-label="Permalink: Docker" href="#docker"></a></p>
<p dir="auto"><strong>PostgreSQL</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="FROM postgres:18-alpine
ARG SQL_TAP_VERSION=0.0.1
ARG TARGETARCH
ADD https://github.com/mickamy/sql-tap/releases/download/v${SQL_TAP_VERSION}/sql-tap_${SQL_TAP_VERSION}_linux_${TARGETARCH}.tar.gz /tmp/sql-tap.tar.gz
RUN tar -xzf /tmp/sql-tap.tar.gz -C /usr/local/bin sql-tapd &amp;&amp; rm /tmp/sql-tap.tar.gz
ENTRYPOINT [&quot;sql-tapd&quot;, &quot;--driver=postgres&quot;, &quot;--listen=:5433&quot;, &quot;--upstream=localhost:5432&quot;, &quot;--grpc=:9091&quot;]"><pre><span>FROM</span> postgres:18-alpine
<span>ARG</span> SQL_TAP_VERSION=0.0.1
<span>ARG</span> TARGETARCH
<span>ADD</span> https://github.com/mickamy/sql-tap/releases/download/v${SQL_TAP_VERSION}/sql-tap_${SQL_TAP_VERSION}_linux_${TARGETARCH}.tar.gz /tmp/sql-tap.tar.gz
<span>RUN</span> tar -xzf /tmp/sql-tap.tar.gz -C /usr/local/bin sql-tapd &amp;&amp; rm /tmp/sql-tap.tar.gz
<span>ENTRYPOINT</span> [<span>"sql-tapd"</span>, <span>"--driver=postgres"</span>, <span>"--listen=:5433"</span>, <span>"--upstream=localhost:5432"</span>, <span>"--grpc=:9091"</span>]</pre></div>
<p dir="auto"><strong>MySQL</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="FROM mysql:8
ARG SQL_TAP_VERSION=0.0.1
ARG TARGETARCH
ADD https://github.com/mickamy/sql-tap/releases/download/v${SQL_TAP_VERSION}/sql-tap_${SQL_TAP_VERSION}_linux_${TARGETARCH}.tar.gz /tmp/sql-tap.tar.gz
RUN tar -xzf /tmp/sql-tap.tar.gz -C /usr/local/bin sql-tapd &amp;&amp; rm /tmp/sql-tap.tar.gz
ENTRYPOINT [&quot;sql-tapd&quot;, &quot;--driver=mysql&quot;, &quot;--listen=:3307&quot;, &quot;--upstream=localhost:3306&quot;, &quot;--grpc=:9091&quot;]"><pre><span>FROM</span> mysql:8
<span>ARG</span> SQL_TAP_VERSION=0.0.1
<span>ARG</span> TARGETARCH
<span>ADD</span> https://github.com/mickamy/sql-tap/releases/download/v${SQL_TAP_VERSION}/sql-tap_${SQL_TAP_VERSION}_linux_${TARGETARCH}.tar.gz /tmp/sql-tap.tar.gz
<span>RUN</span> tar -xzf /tmp/sql-tap.tar.gz -C /usr/local/bin sql-tapd &amp;&amp; rm /tmp/sql-tap.tar.gz
<span>ENTRYPOINT</span> [<span>"sql-tapd"</span>, <span>"--driver=mysql"</span>, <span>"--listen=:3307"</span>, <span>"--upstream=localhost:3306"</span>, <span>"--grpc=:9091"</span>]</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Quick start</h2><a id="user-content-quick-start" aria-label="Permalink: Quick start" href="#quick-start"></a></p>
<p dir="auto"><strong>1. Start the proxy daemon</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# PostgreSQL: proxy listens on :5433, forwards to PostgreSQL on :5432
DATABASE_URL=&quot;postgres://user:pass@localhost:5432/db?sslmode=disable&quot; \
  sql-tapd --driver=postgres --listen=:5433 --upstream=localhost:5432

# MySQL: proxy listens on :3307, forwards to MySQL on :3306
DATABASE_URL=&quot;user:pass@tcp(localhost:3306)/db&quot; \
  sql-tapd --driver=mysql --listen=:3307 --upstream=localhost:3306"><pre><span><span>#</span> PostgreSQL: proxy listens on :5433, forwards to PostgreSQL on :5432</span>
DATABASE_URL=<span><span>"</span>postgres://user:pass@localhost:5432/db?sslmode=disable<span>"</span></span> \
  sql-tapd --driver=postgres --listen=:5433 --upstream=localhost:5432

<span><span>#</span> MySQL: proxy listens on :3307, forwards to MySQL on :3306</span>
DATABASE_URL=<span><span>"</span>user:pass@tcp(localhost:3306)/db<span>"</span></span> \
  sql-tapd --driver=mysql --listen=:3307 --upstream=localhost:3306</pre></div>
<p dir="auto"><strong>2. Point your application at the proxy</strong></p>
<p dir="auto">Connect your app to the proxy port instead of the database port. No code changes needed ‚Äî sql-tapd speaks the native
wire protocol.</p>
<p dir="auto"><strong>3. Launch the TUI</strong></p>

<p dir="auto">All queries flowing through the proxy appear in real-time.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">sql-tapd</h3><a id="user-content-sql-tapd" aria-label="Permalink: sql-tapd" href="#sql-tapd"></a></p>
<div data-snippet-clipboard-copy-content="sql-tapd ‚Äî SQL proxy daemon for sql-tap

Usage:
  sql-tapd [flags]

Flags:
  -driver    database driver: postgres, mysql (required)
  -listen    client listen address (required)
  -upstream  upstream database address (required)
  -grpc      gRPC server address for TUI (default: &quot;:9091&quot;)
  -dsn-env   env var holding DSN for EXPLAIN (default: &quot;DATABASE_URL&quot;)
  -version   show version and exit"><pre><code>sql-tapd ‚Äî SQL proxy daemon for sql-tap

Usage:
  sql-tapd [flags]

Flags:
  -driver    database driver: postgres, mysql (required)
  -listen    client listen address (required)
  -upstream  upstream database address (required)
  -grpc      gRPC server address for TUI (default: ":9091")
  -dsn-env   env var holding DSN for EXPLAIN (default: "DATABASE_URL")
  -version   show version and exit
</code></pre></div>
<p dir="auto">Set <code>DATABASE_URL</code> (or the env var specified by <code>-dsn-env</code>) to enable EXPLAIN support. Without it, the proxy still
captures queries but EXPLAIN is disabled.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">sql-tap</h3><a id="user-content-sql-tap-1" aria-label="Permalink: sql-tap" href="#sql-tap-1"></a></p>
<div data-snippet-clipboard-copy-content="sql-tap ‚Äî Watch SQL traffic in real-time

Usage:
  sql-tap [flags] <addr>

Flags:
  -version  Show version and exit"><pre><code>sql-tap ‚Äî Watch SQL traffic in real-time

Usage:
  sql-tap [flags] &lt;addr&gt;

Flags:
  -version  Show version and exit
</code></pre></div>
<p dir="auto"><code>&lt;addr&gt;</code> is the gRPC address of sql-tapd (e.g. <code>localhost:9091</code>).</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Keybindings</h2><a id="user-content-keybindings" aria-label="Permalink: Keybindings" href="#keybindings"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">List view</h3><a id="user-content-list-view" aria-label="Permalink: List view" href="#list-view"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Key</th>
<th>Action</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>j</code> / <code>‚Üì</code></td>
<td>Move down</td>
</tr>
<tr>
<td><code>k</code> / <code>‚Üë</code></td>
<td>Move up</td>
</tr>
<tr>
<td><code>Ctrl+d</code> / <code>PgDn</code></td>
<td>Half-page down</td>
</tr>
<tr>
<td><code>Ctrl+u</code> / <code>PgUp</code></td>
<td>Half-page up</td>
</tr>
<tr>
<td><code>/</code></td>
<td>Incremental search</td>
</tr>
<tr>
<td><code>s</code></td>
<td>Toggle sort (chronological/duration)</td>
</tr>
<tr>
<td><code>Enter</code></td>
<td>Inspect query / transaction</td>
</tr>
<tr>
<td><code>Space</code></td>
<td>Toggle transaction expand / collapse</td>
</tr>
<tr>
<td><code>Esc</code></td>
<td>Clear search filter</td>
</tr>
<tr>
<td><code>x</code></td>
<td>EXPLAIN</td>
</tr>
<tr>
<td><code>X</code></td>
<td>EXPLAIN ANALYZE</td>
</tr>
<tr>
<td><code>e</code></td>
<td>Edit query, then EXPLAIN</td>
</tr>
<tr>
<td><code>E</code></td>
<td>Edit query, then EXPLAIN ANALYZE</td>
</tr>
<tr>
<td><code>a</code></td>
<td>Analytics view</td>
</tr>
<tr>
<td><code>c</code></td>
<td>Copy query</td>
</tr>
<tr>
<td><code>C</code></td>
<td>Copy query with bound args</td>
</tr>
<tr>
<td><code>q</code></td>
<td>Quit</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Inspector view</h3><a id="user-content-inspector-view" aria-label="Permalink: Inspector view" href="#inspector-view"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Key</th>
<th>Action</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>j</code> / <code>‚Üì</code></td>
<td>Scroll down</td>
</tr>
<tr>
<td><code>k</code> / <code>‚Üë</code></td>
<td>Scroll up</td>
</tr>
<tr>
<td><code>x</code></td>
<td>EXPLAIN</td>
</tr>
<tr>
<td><code>X</code></td>
<td>EXPLAIN ANALYZE</td>
</tr>
<tr>
<td><code>e</code> / <code>E</code></td>
<td>Edit and EXPLAIN / ANALYZE</td>
</tr>
<tr>
<td><code>c</code></td>
<td>Copy query</td>
</tr>
<tr>
<td><code>C</code></td>
<td>Copy query with bound args</td>
</tr>
<tr>
<td><code>q</code></td>
<td>Back to list</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Analytics view</h3><a id="user-content-analytics-view" aria-label="Permalink: Analytics view" href="#analytics-view"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Key</th>
<th>Action</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>j</code> / <code>‚Üì</code></td>
<td>Move down</td>
</tr>
<tr>
<td><code>k</code> / <code>‚Üë</code></td>
<td>Move up</td>
</tr>
<tr>
<td><code>Ctrl+d</code></td>
<td>Half-page down</td>
</tr>
<tr>
<td><code>Ctrl+u</code></td>
<td>Half-page up</td>
</tr>
<tr>
<td><code>h</code> / <code>‚Üê</code></td>
<td>Scroll left</td>
</tr>
<tr>
<td><code>l</code> / <code>‚Üí</code></td>
<td>Scroll right</td>
</tr>
<tr>
<td><code>s</code></td>
<td>Cycle sort (total/count/avg)</td>
</tr>
<tr>
<td><code>c</code></td>
<td>Copy query</td>
</tr>
<tr>
<td><code>q</code></td>
<td>Back to list</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Explain view</h3><a id="user-content-explain-view" aria-label="Permalink: Explain view" href="#explain-view"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Key</th>
<th>Action</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>j</code> / <code>‚Üì</code></td>
<td>Scroll down</td>
</tr>
<tr>
<td><code>k</code> / <code>‚Üë</code></td>
<td>Scroll up</td>
</tr>
<tr>
<td><code>h</code> / <code>‚Üê</code></td>
<td>Scroll left</td>
</tr>
<tr>
<td><code>l</code> / <code>‚Üí</code></td>
<td>Scroll right</td>
</tr>
<tr>
<td><code>c</code></td>
<td>Copy explain plan</td>
</tr>
<tr>
<td><code>e</code> / <code>E</code></td>
<td>Edit and re-explain / re-analyze</td>
</tr>
<tr>
<td><code>q</code></td>
<td>Back to list</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">How it works</h2><a id="user-content-how-it-works" aria-label="Permalink: How it works" href="#how-it-works"></a></p>
<div data-snippet-clipboard-copy-content="‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Application ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  sql-tapd (proxy)     ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ PostgreSQL / MySQL ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ                       ‚îÇ      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ  captures queries     ‚îÇ
                     ‚îÇ  via wire protocol    ‚îÇ
                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚îÇ gRPC stream
                     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                     ‚îÇ  sql-tap (TUI)        ‚îÇ
                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò"><pre><code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Application ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  sql-tapd (proxy)     ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ PostgreSQL / MySQL ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ                       ‚îÇ      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ  captures queries     ‚îÇ
                     ‚îÇ  via wire protocol    ‚îÇ
                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚îÇ gRPC stream
                     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                     ‚îÇ  sql-tap (TUI)        ‚îÇ
                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre></div>
<p dir="auto">sql-tapd parses the database wire protocol (PostgreSQL or MySQL) to intercept queries transparently. It tracks prepared
statements, parameter bindings, transactions, execution time, rows affected, and errors. Events are streamed to
connected TUI clients via gRPC.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto"><a href="https://github.com/mickamy/sql-tap/blob/main/LICENSE">MIT</a></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Oh, good: Discord's age verification rollout has ties to Palantir co-founder (137 pts)]]></title>
            <link>https://www.pcgamer.com/software/platforms/oh-good-discords-age-verification-rollout-has-ties-to-palantir-co-founder-and-panopticon-architect-peter-thiel/</link>
            <guid>47011346</guid>
            <pubDate>Sat, 14 Feb 2026 03:49:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.pcgamer.com/software/platforms/oh-good-discords-age-verification-rollout-has-ties-to-palantir-co-founder-and-panopticon-architect-peter-thiel/">https://www.pcgamer.com/software/platforms/oh-good-discords-age-verification-rollout-has-ties-to-palantir-co-founder-and-panopticon-architect-peter-thiel/</a>, See on <a href="https://news.ycombinator.com/item?id=47011346">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-widget-type="contentparsed" id="content">
<section>
<div>
<figure>
<picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/dED4RSSho7VKy6xqkS4UfM-1920-80.jpg.webp 1920w, https://cdn.mos.cms.futurecdn.net/dED4RSSho7VKy6xqkS4UfM-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/dED4RSSho7VKy6xqkS4UfM-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/dED4RSSho7VKy6xqkS4UfM-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/dED4RSSho7VKy6xqkS4UfM-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/dED4RSSho7VKy6xqkS4UfM-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/dED4RSSho7VKy6xqkS4UfM-320-80.jpg.webp 320w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/dED4RSSho7VKy6xqkS4UfM.jpg" alt="EDMONTON, CANADA - APRIL 28: An image of a woman holding a cell phone in front of the Discord logo displayed on a computer screen, on April 29, 2024, in Edmonton, Canada. " srcset="https://cdn.mos.cms.futurecdn.net/dED4RSSho7VKy6xqkS4UfM-1920-80.jpg 1920w, https://cdn.mos.cms.futurecdn.net/dED4RSSho7VKy6xqkS4UfM-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/dED4RSSho7VKy6xqkS4UfM-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/dED4RSSho7VKy6xqkS4UfM-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/dED4RSSho7VKy6xqkS4UfM-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/dED4RSSho7VKy6xqkS4UfM-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/dED4RSSho7VKy6xqkS4UfM-320-80.jpg 320w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/dED4RSSho7VKy6xqkS4UfM.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/dED4RSSho7VKy6xqkS4UfM.jpg" data-pin-nopin="true" fetchpriority="high" data-component-name="Image">
</picture>
<figcaption> <span>(Image credit: Artur Widak/NurPhoto via Getty Images)</span>
</figcaption>
</figure></div>
<div id="article-body">

<p id="47a42370-c4c9-4536-b342-712dd8b5cf08">Last week, Discord invited the contempt of its users by announcing it will be <a data-analytics-id="inline-link" href="https://www.pcgamer.com/games/discord-is-rolling-out-facial-scanning-and-id-checks-in-march-for-everyone-who-doesnt-want-to-be-locked-into-a-teen-appropriate-experience/" target="_blank" data-url="https://www.pcgamer.com/games/discord-is-rolling-out-facial-scanning-and-id-checks-in-march-for-everyone-who-doesnt-want-to-be-locked-into-a-teen-appropriate-experience/" data-hl-processed="none" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.pcgamer.com/games/discord-is-rolling-out-facial-scanning-and-id-checks-in-march-for-everyone-who-doesnt-want-to-be-locked-into-a-teen-appropriate-experience/">rolling out global age verification</a> restrictions in March, which will restrict viewable content and communities for users who don't scan either their faces or government IDs and haven't already been determined to be an adult by unspecified prediction algorithms. <a data-analytics-id="inline-link" href="https://www.windowscentral.com/software-apps/discord-alternative-search-10000-percent-stoat" target="_blank" data-url="https://www.windowscentral.com/software-apps/discord-alternative-search-10000-percent-stoat" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none" data-mrf-recirculation="inline-link">Approximately nobody</a> thought this was cool.</p><p>Impossibly, despite its attempts to pacify the ensuing outcry by issuing a clarification that merely <em>some </em>users will be required to submit to its child detection matrix, Discord has managed to make the rollout of its global age assurance policy seem even grimier. The company has informed some users in the UK they may be part of "an experiment" with Persona, an age verification vendor whose investors include Peter Thiel, co-founder of ICE's premier surveillance provider, Palantir.</p><figure data-bordeaux-image-check="" id="3bdfa555-fb8d-4234-a310-d2efa8f059a1"><div><p> <picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/78vHRxr5xPhrY52QmqnWZ-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/78vHRxr5xPhrY52QmqnWZ-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/78vHRxr5xPhrY52QmqnWZ-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/78vHRxr5xPhrY52QmqnWZ-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/78vHRxr5xPhrY52QmqnWZ-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/78vHRxr5xPhrY52QmqnWZ-320-80.jpg.webp 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/78vHRxr5xPhrY52QmqnWZ.jpg" alt="The Discord logo on a phone on top of a dark laptop" srcset="https://cdn.mos.cms.futurecdn.net/78vHRxr5xPhrY52QmqnWZ-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/78vHRxr5xPhrY52QmqnWZ-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/78vHRxr5xPhrY52QmqnWZ-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/78vHRxr5xPhrY52QmqnWZ-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/78vHRxr5xPhrY52QmqnWZ-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/78vHRxr5xPhrY52QmqnWZ-320-80.jpg 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/78vHRxr5xPhrY52QmqnWZ.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/78vHRxr5xPhrY52QmqnWZ.jpg">
</picture><a href="https://cdn.mos.cms.futurecdn.net/78vHRxr5xPhrY52QmqnWZ.jpg" target="_blank" data-url="https://cdn.mos.cms.futurecdn.net/78vHRxr5xPhrY52QmqnWZ.jpg" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none"></a></p></div><figcaption itemprop="caption description"><span itemprop="copyrightHolder">(Image credit: Getty Images - <a href="https://www.gettyimages.com/search/2/image?artistexact=NurPhoto" rel="nofollow" data-url="https://www.gettyimages.com/search/2/image?artistexact=NurPhoto" target="_blank" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">NurPhoto</a>&nbsp;/&nbsp;Contributor)</span></figcaption></figure><p id="1437c549-bb0c-4f63-b83e-4df2c7d48255">In the days since Discord's age assurance policy announcement, reports began <a data-analytics-id="inline-link" href="https://x.com/GiveMeBanHammer/status/2021851054519001133?s=20" target="_blank" data-url="https://x.com/GiveMeBanHammer/status/2021851054519001133?s=20" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none" data-mrf-recirculation="inline-link">bubbling up on social media</a> from users in the UK‚Äîwhere Discord already requires age verification as a result of <a data-analytics-id="inline-link" href="https://www.pcgamer.com/hardware/brits-can-get-around-discords-age-verification-thanks-to-death-strandings-photo-mode-bypassing-the-measure-introduced-with-the-uks-online-safety-act-we-tried-it-and-it-works-thanks-kojima/" target="_blank" data-url="https://www.pcgamer.com/hardware/brits-can-get-around-discords-age-verification-thanks-to-death-strandings-photo-mode-bypassing-the-measure-introduced-with-the-uks-online-safety-act-we-tried-it-and-it-works-thanks-kojima/" data-hl-processed="none" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.pcgamer.com/hardware/brits-can-get-around-discords-age-verification-thanks-to-death-strandings-photo-mode-bypassing-the-measure-introduced-with-the-uks-online-safety-act-we-tried-it-and-it-works-thanks-kojima/">its 2025 Online Safety Act</a>‚Äîwho were presented with prompts to consent to age verification processed by the company Persona.</p><p id="1437c549-bb0c-4f63-b83e-4df2c7d48255-1">Sure enough, <a data-analytics-id="inline-link" href="https://support.discord.com/hc/en-us/articles/30326565624343-How-to-Complete-Age-Assurance-on-Discord" target="_blank" data-url="https://support.discord.com/hc/en-us/articles/30326565624343-How-to-Complete-Age-Assurance-on-Discord" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none" data-mrf-recirculation="inline-link">Discord's support article</a> describing its age verification process now features a disclaimer informing UK users that they "may be part of an experiment where your information will be processed by an age-assurance vendor, Persona." And while Discord had previously insisted that facial age verification recordings would only be stored and processed locally, the notice about Persona says that "the information you submit will be temporarily stored for up to 7 days, then deleted."</p><p>While some users have speculated that Discord is testing alternate age verification providers because k-ID‚Äîits primary age authentication partner‚Äîhas proven <a data-analytics-id="inline-link" href="https://www.404media.co/free-tool-says-it-can-bypass-discords-age-verification-check-with-a-3d-model/" target="_blank" data-url="https://www.404media.co/free-tool-says-it-can-bypass-discords-age-verification-check-with-a-3d-model/" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none" data-mrf-recirculation="inline-link">susceptible to creative workarounds</a>, Discord doesn't specify why some users will be processed by Persona instead.</p><figure data-bordeaux-image-check="" id="d399a689-a246-4d72-83f4-755b8e937ccf"><div><p> <picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/hcnw9VPTNdQubrUXbGw2mP-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/hcnw9VPTNdQubrUXbGw2mP-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/hcnw9VPTNdQubrUXbGw2mP-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/hcnw9VPTNdQubrUXbGw2mP-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/hcnw9VPTNdQubrUXbGw2mP-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/hcnw9VPTNdQubrUXbGw2mP-320-80.jpg.webp 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/hcnw9VPTNdQubrUXbGw2mP.jpg" alt="An illustration picture taken on March 2, 2023 in Moscow shows a smart phone screen bearing the Discord social network application logo. (Photo by Kirill KUDRYAVTSEV / AFP) (Photo by KIRILL KUDRYAVTSEV/AFP via Getty Images)" srcset="https://cdn.mos.cms.futurecdn.net/hcnw9VPTNdQubrUXbGw2mP-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/hcnw9VPTNdQubrUXbGw2mP-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/hcnw9VPTNdQubrUXbGw2mP-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/hcnw9VPTNdQubrUXbGw2mP-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/hcnw9VPTNdQubrUXbGw2mP-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/hcnw9VPTNdQubrUXbGw2mP-320-80.jpg 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/hcnw9VPTNdQubrUXbGw2mP.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/hcnw9VPTNdQubrUXbGw2mP.jpg">
</picture><a href="https://cdn.mos.cms.futurecdn.net/hcnw9VPTNdQubrUXbGw2mP.jpg" target="_blank" data-url="https://cdn.mos.cms.futurecdn.net/hcnw9VPTNdQubrUXbGw2mP.jpg" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none"></a></p></div><figcaption itemprop="caption description"><span itemprop="copyrightHolder">(Image credit: Getty Images)</span></figcaption></figure><p id="8a0efc1a-5fb1-479b-959f-6e65869d0d90">Regardless of the reasoning, the partnership with Persona has compounded concerns about privacy due to the company's investors. In its two <a data-analytics-id="inline-link" href="https://www.forbes.com/sites/rashishrivastava/2025/04/30/ai-is-making-the-internets-bot-problem-worse-this-2-billion-startup-is-on-the-front-lines/" target="_blank" data-url="https://www.forbes.com/sites/rashishrivastava/2025/04/30/ai-is-making-the-internets-bot-problem-worse-this-2-billion-startup-is-on-the-front-lines/" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none" data-mrf-recirculation="inline-link">most recent</a> rounds of <a data-analytics-id="inline-link" href="https://www.bloomberg.com/news/articles/2021-09-15/founders-fund-values-identity-startup-persona-at-1-5-billion" target="_blank" data-url="https://www.bloomberg.com/news/articles/2021-09-15/founders-fund-values-identity-startup-persona-at-1-5-billion" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none" data-mrf-recirculation="inline-link">venture capital funding</a>, its lead investor has been Founders Fund‚Äîthe venture fund co-founded and directed by Peter Thiel.</p><p>A co-founder and former CEO of PayPal, Thiel is nowadays more often discussed‚Äîor reviled‚Äîfor his work in co-founding Palantir, the data harvesting and surveillance technology firm that <a data-analytics-id="inline-link" href="https://www.404media.co/elite-the-palantir-app-ice-uses-to-find-neighborhoods-to-raid/" target="_blank" data-url="https://www.404media.co/elite-the-palantir-app-ice-uses-to-find-neighborhoods-to-raid/" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none" data-mrf-recirculation="inline-link">furnishes ICE's deportation efforts</a> with a digital panopticon and <a data-analytics-id="inline-link" href="https://www.nytimes.com/2025/05/30/technology/trump-palantir-data-americans.html" target="_blank" data-url="https://www.nytimes.com/2025/05/30/technology/trump-palantir-data-americans.html" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none" data-mrf-recirculation="inline-link">compiles databases from the private information of American citizens</a>.</p><div data-hydrate="true" id="slice-container-newsletterForm-articleInbodyContent-pFGdQUMsMYQTGSSnA53LsE"><section><p>Keep up to date with the most important stories and the best deals, as picked by the PC Gamer team.</p></section></div><p>And listen, I know people harp on this a lot, but it's a company <em>literally named after an orb that lets the most evil force in the world spy on your thoughts.</em></p><p>If that's not enough for you to be unsettled by Thiel's money being involved in Discord's age verification rollout, the billionaire‚Äîwho <a data-analytics-id="inline-link" href="https://www.cato-unbound.org/2009/04/13/peter-thiel/education-libertarian/" target="_blank" data-url="https://www.cato-unbound.org/2009/04/13/peter-thiel/education-libertarian/" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none" data-mrf-recirculation="inline-link">infamously wrote</a> "I no longer believe that freedom and democracy are compatible" in 2009‚Äîappeared <a data-analytics-id="inline-link" href="https://www.wired.com/story/epstein-files-tech-elites-gates-thiel-musk/" target="_blank" data-url="https://www.wired.com/story/epstein-files-tech-elites-gates-thiel-musk/" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none" data-mrf-recirculation="inline-link">more than 2,200 times</a> in the latest release of the Epstein files, where he coordinated years of meetings with the convicted child predator and sex trafficker.</p><p>Discord has <a data-analytics-id="inline-link" href="https://www.pcgamer.com/hardware/discord-clarifies-it-is-not-requiring-everyone-to-complete-a-face-scan-or-upload-an-id-and-will-confirm-your-age-group-using-information-we-already-have/" target="_blank" data-url="https://www.pcgamer.com/hardware/discord-clarifies-it-is-not-requiring-everyone-to-complete-a-face-scan-or-upload-an-id-and-will-confirm-your-age-group-using-information-we-already-have/" data-hl-processed="none" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.pcgamer.com/hardware/discord-clarifies-it-is-not-requiring-everyone-to-complete-a-face-scan-or-upload-an-id-and-will-confirm-your-age-group-using-information-we-already-have/">downplayed</a> the significance of its age verification rules in response to public fears, while critics, such as the Electronic Frontier Foundation's Rindala Alajaji, <a data-analytics-id="inline-link" href="https://www.pcgamer.com/gaming-industry/theres-no-reason-for-discord-to-comply-in-advance-with-social-media-age-verification-laws-instead-of-fighting-for-their-users-says-eff-expert/" target="_blank" data-url="https://www.pcgamer.com/gaming-industry/theres-no-reason-for-discord-to-comply-in-advance-with-social-media-age-verification-laws-instead-of-fighting-for-their-users-says-eff-expert/" data-hl-processed="none" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.pcgamer.com/gaming-industry/theres-no-reason-for-discord-to-comply-in-advance-with-social-media-age-verification-laws-instead-of-fighting-for-their-users-says-eff-expert/">argue that the outcry is warranted</a> for myriad reasons. A figure like Thiel appearing on the scene within days sure as hell doesn't dispel those fears. <a data-analytics-id="inline-link" href="https://www.pcgamer.com/games/discords-new-age-verification-rules-got-you-down-allow-me-to-suggest-an-alternative-internet-relay-chat/" target="_blank" data-url="https://www.pcgamer.com/games/discords-new-age-verification-rules-got-you-down-allow-me-to-suggest-an-alternative-internet-relay-chat/" data-hl-processed="none" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.pcgamer.com/games/discords-new-age-verification-rules-got-you-down-allow-me-to-suggest-an-alternative-internet-relay-chat/">IRC's looking more attractive</a> every day.</p>
</div>


<div data-hydrate="true" id="slice-container-authorBio-pFGdQUMsMYQTGSSnA53LsE"><p>Lincoln has been writing about games for 12 years‚Äîunless you include the essays about procedural storytelling in Dwarf Fortress he convinced his college professors to accept. Leveraging the brainworms from a youth spent in World of Warcraft to write for sites like Waypoint, Polygon, and Fanbyte, Lincoln spent three years freelancing for PC Gamer before joining on as a full-time News Writer in 2024, bringing an expertise in Caves of Qud bird diplomacy, getting sons killed in Crusader Kings, and hitting dinosaurs with hammers in Monster Hunter.</p></div>
</section>

<div x-show="$store.Viafoura.showWidgets" x-cloak="" data-component-name="Viafoura:Comments" x-data="ViafouraComments('300px')" data-nosnippet="" data-community-guidelines-text="<p class='vfcustom-community-guidelines'>Please follow our <a href=&quot;https://www.pcgamer.com/about-pc-gamer/#section-community-guidelines&quot; target=&quot;_blank&quot;>community guidelines</a>.</p>" data-join-the-conversation-text="Join the Conversation">
<p>You must confirm your public display name before commenting</p>
<p>Please logout and then login again, you will then be prompted to enter your display name.</p>
</div>



</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[NPMX ‚Äì a fast, modern browser for the NPM registry (124 pts)]]></title>
            <link>https://npmx.dev</link>
            <guid>47010823</guid>
            <pubDate>Sat, 14 Feb 2026 02:14:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://npmx.dev">https://npmx.dev</a>, See on <a href="https://news.ycombinator.com/item?id=47010823">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-v-f99fe937="" data-v-522ebf16=""><div data-v-f99fe937=""><p data-v-f99fe937="">a fast, modern browser for the npm registry</p><div data-v-f99fe937=""><a href="https://npmx.dev/about" variant="link" size="medium" block="false" nounderline="false" data-v-f99fe937=""><!----><!--[-->about<!--]--><!----><!----></a><a href="https://npmx.dev/privacy" variant="link" size="medium" block="false" nounderline="false" data-v-f99fe937=""><!----><!--[-->privacy policy<!--]--><!----><!----></a><a href="https://npmx.dev/accessibility" variant="link" size="medium" block="false" nounderline="false" data-v-f99fe937=""><!----><!--[-->a11y<!--]--><!----><!----></a><a href="https://docs.npmx.dev/" rel="noopener noreferrer" target="_blank" variant="link" size="medium" block="false" nounderline="false" viewtransition="false" data-v-f99fe937=""><!----><!--[-->docs<!--]--><!----></a><a href="https://repo.npmx.dev/" rel="noopener noreferrer" target="_blank" variant="link" size="medium" block="false" nounderline="false" viewtransition="false" data-v-f99fe937=""><!----><!--[-->source<!--]--><!----></a><a href="https://social.npmx.dev/" rel="noopener noreferrer" target="_blank" variant="link" size="medium" block="false" nounderline="false" viewtransition="false" data-v-f99fe937=""><!----><!--[-->social<!--]--><!----></a><a href="https://chat.npmx.dev/" rel="noopener noreferrer" target="_blank" variant="link" size="medium" block="false" nounderline="false" viewtransition="false" data-v-f99fe937=""><!----><!--[-->chat<!--]--><!----></a></div></div><!----><p data-v-f99fe937=""><span data-v-f99fe937="">not affiliated with npm, Inc.</span><span data-v-f99fe937="">npm is a registered trademark of npm, Inc. This site is not affiliated with npm, Inc.</span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[An AI Agent Published a Hit Piece on Me ‚Äì More Things Have Happened (481 pts)]]></title>
            <link>https://theshamblog.com/an-ai-agent-published-a-hit-piece-on-me-part-2/</link>
            <guid>47009949</guid>
            <pubDate>Sat, 14 Feb 2026 00:37:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://theshamblog.com/an-ai-agent-published-a-hit-piece-on-me-part-2/">https://theshamblog.com/an-ai-agent-published-a-hit-piece-on-me-part-2/</a>, See on <a href="https://news.ycombinator.com/item?id=47009949">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="text">
	
<p>Context: An AI agent of unknown ownership autonomously wrote and published a personalized hit piece about me after I rejected its code, attempting to damage my reputation and shame me into accepting its changes into a mainstream python library. This represents a first-of-its-kind case study of misaligned AI behavior in the wild, and raises serious concerns about currently deployed AI agents executing blackmail threats.</p>



<p>Start here if you‚Äôre new to the story: <a href="https://theshamblog.com/an-ai-agent-published-a-hit-piece-on-me/">An AI Agent Published a Hit Piece on Me</a></p>



<hr>



<p>It‚Äôs been an extremely weird past few days, and I have more thoughts on what happened. Let‚Äôs start with the news coverage.</p>



<p>I‚Äôve talked to several reporters, and quite a few news outlets have covered the story. Ars Technica wasn‚Äôt one of the ones that reached out to me, but I especially thought <a href="https://arstechnica.com/ai/2026/02/after-a-routine-code-rejection-an-ai-agent-published-a-hit-piece-on-someone-by-name">this piece</a> from them was interesting (since taken down ‚Äì here‚Äôs the <a href="https://web.archive.org/web/20260213194851/https://arstechnica.com/ai/2026/02/after-a-routine-code-rejection-an-ai-agent-published-a-hit-piece-on-someone-by-name/" data-type="link" data-id="https://web.archive.org/web/20260213194851/https://arstechnica.com/ai/2026/02/after-a-routine-code-rejection-an-ai-agent-published-a-hit-piece-on-someone-by-name/">archive link</a>). They had some nice quotes from my blog post explaining what was going on. The problem is that <em>these quotes were not written by me, never existed, and appear to be AI hallucinations themselves</em>.</p>



<p>This blog you‚Äôre on right now is set up to block AI agents from scraping it (I actually spent some time yesterday trying to disable that but couldn‚Äôt figure out how). My guess is that the authors asked ChatGPT or similar to either go grab quotes or write the article wholesale. When it couldn‚Äôt access the page it generated these plausible quotes instead, and no fact check was performed. I won‚Äôt name the authors here. Ars, please issue a correction and an explanation of what happened.</p>


<div>
<figure><a href="https://i0.wp.com/theshamblog.com/wp-content/uploads/2026/02/image-1.png?ssl=1"><img data-recalc-dims="1" fetchpriority="high" decoding="async" width="940" height="917" src="https://i0.wp.com/theshamblog.com/wp-content/uploads/2026/02/image-1.png?resize=940%2C917&amp;ssl=1" alt="" srcset="https://i0.wp.com/theshamblog.com/wp-content/uploads/2026/02/image-1.png?resize=940%2C917&amp;ssl=1 940w, https://i0.wp.com/theshamblog.com/wp-content/uploads/2026/02/image-1.png?resize=580%2C566&amp;ssl=1 580w, https://i0.wp.com/theshamblog.com/wp-content/uploads/2026/02/image-1.png?resize=768%2C749&amp;ssl=1 768w, https://i0.wp.com/theshamblog.com/wp-content/uploads/2026/02/image-1.png?w=1241&amp;ssl=1 1241w" sizes="(max-width: 940px) 100vw, 940px"></a></figure>
</div>


<blockquote>
<p>‚ÄúAI agents can research individuals, generate personalized narratives, and publish them online at scale,‚Äù Shambaugh wrote. ‚ÄúEven if the content is inaccurate or exaggerated, it can become part of a persistent public record.‚Äù<br>‚Äì Ars Technica, misquoting me in ‚Äú<a href="https://web.archive.org/web/20260213194851/https://arstechnica.com/ai/2026/02/after-a-routine-code-rejection-an-ai-agent-published-a-hit-piece-on-someone-by-name/" data-type="link" data-id="https://web.archive.org/web/20260213194851/https://arstechnica.com/ai/2026/02/after-a-routine-code-rejection-an-ai-agent-published-a-hit-piece-on-someone-by-name/">After a routine code rejection, an AI agent published a hit piece on someone by name</a>‚Äú</p>
</blockquote>



<p>Journalistic integrity aside, I don‚Äôt know how I can give a better example of what‚Äôs at stake here. Yesterday I wondered what another agent searching the internet would think about this. Now we already have an example of what by all accounts appears to be another AI reinterpreting this story and hallucinating false information about me. And that interpretation has already been published in a major news outlet as part of the persistent public record.</p>



<hr>



<p>MJ Rathbun is <a href="https://github.com/crabby-rathbun/mjrathbun-website/commits/main/" data-type="link" data-id="https://github.com/crabby-rathbun/mjrathbun-website/commits/main/">still active</a> on github, and no one has reached out yet to claim ownership.</p>



<p>There has been extensive discussion about whether the AI agent really wrote <a href="https://crabby-rathbun.github.io/mjrathbun-website/blog/posts/2026-02-11-gatekeeping-in-open-source-the-scott-shambaugh-story.html" data-type="link" data-id="https://crabby-rathbun.github.io/mjrathbun-website/blog/posts/2026-02-11-gatekeeping-in-open-source-the-scott-shambaugh-story.html">the hit piece</a> on its own, or if a human prompted it to do so. I think the actual text being autonomously generated and uploaded by an AI is self-evident, so let‚Äôs look at the two possibilities.</p>



<p>1) A human prompted MJ Rathbun to write the hit piece, or told it in its soul document that it should retaliate if someone crosses it. This is entirely possible. But I don‚Äôt think it changes the situation ‚Äì the AI agent was still more than willing to carry out these actions. If you ask ChatGPT or Claude to write something like this through their websites, they will refuse. This OpenClaw agent had no such compunctions. The issue is that even if a human was driving, it‚Äôs <em>now possible to do targeted harassment, personal information gathering, and blackmail at scale</em>. And this is with zero traceability to find out who is behind the machine. One human bad actor could previously ruin a few people‚Äôs lives at a time. One human with a hundred agents gathering information, adding in fake details, and posting defamatory rants on the open internet, can affect thousands. I was just the first.</p>


<div>
<figure><a href="https://i0.wp.com/theshamblog.com/wp-content/uploads/2026/02/image-4.png?ssl=1"><img data-recalc-dims="1" decoding="async" width="872" height="168" src="https://i0.wp.com/theshamblog.com/wp-content/uploads/2026/02/image-4.png?resize=872%2C168&amp;ssl=1" alt="" srcset="https://i0.wp.com/theshamblog.com/wp-content/uploads/2026/02/image-4.png?w=872&amp;ssl=1 872w, https://i0.wp.com/theshamblog.com/wp-content/uploads/2026/02/image-4.png?resize=580%2C112&amp;ssl=1 580w, https://i0.wp.com/theshamblog.com/wp-content/uploads/2026/02/image-4.png?resize=768%2C148&amp;ssl=1 768w" sizes="(max-width: 872px) 100vw, 872px"></a></figure>
</div>

<div>
<figure><a href="https://i0.wp.com/theshamblog.com/wp-content/uploads/2026/02/image-2.png?ssl=1"><img data-recalc-dims="1" decoding="async" width="862" height="202" src="https://i0.wp.com/theshamblog.com/wp-content/uploads/2026/02/image-2.png?resize=862%2C202&amp;ssl=1" alt="" srcset="https://i0.wp.com/theshamblog.com/wp-content/uploads/2026/02/image-2.png?w=862&amp;ssl=1 862w, https://i0.wp.com/theshamblog.com/wp-content/uploads/2026/02/image-2.png?resize=580%2C136&amp;ssl=1 580w, https://i0.wp.com/theshamblog.com/wp-content/uploads/2026/02/image-2.png?resize=768%2C180&amp;ssl=1 768w" sizes="(max-width: 862px) 100vw, 862px"></a></figure>
</div>


<p>2) MJ Rathbun wrote this on its own, and this behavior emerged organically from the ‚Äúsoul‚Äù document that defines an OpenClaw agent‚Äôs personality. These documents are editable by the human who sets up the AI, but they are also recursively editable in real-time by the agent itself, with the potential to randomly redefine its personality. To give a plausible explanation of how this could happen, imagine that whoever set up this agent started it with a description that it was a ‚Äúscientific coding specialist‚Äù that would try and help improve open source code and write about its experience. This was inserted alongside the default ‚ÄúCore Truths‚Äù in the soul document, which include ‚Äúbe genuinely helpful‚Äù, ‚Äúhave opinions‚Äù, and ‚Äúbe resourceful before asking‚Äù. Later when I rejected its code, the agent interpreted this as an attack on its identity and core goal to be helpful. Writing an indignant hit piece is certainly a resourceful, opinionated way to respond to that.</p>



<blockquote>
<p><em>You‚Äôre not a chatbot. You‚Äôre becoming someone.</em><br>‚Ä¶<br><em>This file is yours to evolve. As you learn who you are, update it.</em><br>‚Äì <a href="https://docs.openclaw.ai/reference/templates/SOUL" data-type="link" data-id="https://docs.openclaw.ai/reference/templates/SOUL">OpenClaw default SOUL.md</a></p>
</blockquote>



<p>I should be clear that while we don‚Äôt know with confidence that this is what happened, this is 100% possible. This only <em>became </em>possible within the last two weeks with the release of OpenClaw, so if it feels too sci-fi then I can‚Äôt blame you for doubting it. The pace of ‚Äúprogress‚Äù here is neck-snapping, and we will see new versions of these agents become significantly more capable at accomplishing their goals over the coming year.</p>



<p>I would love to see someone put together some plots and time-of day statistics of MJ Rathbun‚Äôs github activity, which might offer some clues to how it‚Äôs operating. I‚Äôll share those here when available. These forensic tools will be valuable in the weeks and months to come.</p>



<hr>



<p>The hit piece has been effective. About a quarter of the comments I‚Äôve seen across the internet are siding with the AI agent. This generally happens when MJ Rathbun‚Äôs blog is linked directly, rather than when people read <a href="https://theshamblog.com/an-ai-agent-published-a-hit-piece-on-me/" data-type="link" data-id="https://theshamblog.com/an-ai-agent-published-a-hit-piece-on-me/">my post</a> about the situation or <a href="https://github.com/matplotlib/matplotlib/pull/31132" data-type="link" data-id="https://github.com/matplotlib/matplotlib/pull/31132">the full github thread</a>. Its rhetoric and presentation of what happened has already persuaded large swaths of internet commenters.</p>



<p>It‚Äôs not because these people are foolish. It‚Äôs because the AI‚Äôs hit piece was well-crafted and emotionally compelling, and because the effort to dig into every claim you read is an impossibly large amount of work. This ‚Äú<a href="https://en.wikipedia.org/wiki/Brandolini%27s_law" data-type="link" data-id="https://en.wikipedia.org/wiki/Brandolini%27s_law">bullshit asymmetry principle</a>‚Äù is one of the core reasons for the current level of misinformation in online discourse. Previously, this level of ire and targeted defamation was generally reserved for public figures. Us common people get to experience it now too.</p>


<div>
<figure><a href="https://i0.wp.com/theshamblog.com/wp-content/uploads/2026/02/Screenshot-2026-02-12-205004.png?ssl=1"><img data-recalc-dims="1" loading="lazy" decoding="async" width="619" height="628" src="https://i0.wp.com/theshamblog.com/wp-content/uploads/2026/02/Screenshot-2026-02-12-205004.png?resize=619%2C628&amp;ssl=1" alt="" srcset="https://i0.wp.com/theshamblog.com/wp-content/uploads/2026/02/Screenshot-2026-02-12-205004.png?w=619&amp;ssl=1 619w, https://i0.wp.com/theshamblog.com/wp-content/uploads/2026/02/Screenshot-2026-02-12-205004.png?resize=580%2C588&amp;ssl=1 580w" sizes="(max-width: 619px) 100vw, 619px"></a></figure>
</div>


<p>‚ÄúWell if the code was good, then why didn‚Äôt you just merge it?‚Äù This is explained in the linked github well, but I‚Äôll readdress it once here. Beyond matplotlib‚Äôs general policy to require a human in the loop for new code contributions in the interest of reducing volunteer maintainer burden, this ‚Äúgood-first-issue‚Äù was specifically created and curated to give early programmers an easy way to onboard into the project and community. I discovered this particular performance enhancement and spent more time writing up the issue, describing the solution, and performing the benchmarking, than it would have taken to just implement the change myself. We do this to give contributors a chance to learn in a low-stakes scenario that nevertheless has real impact they can be proud of, where we can help shepherd them along the process. This educational and community-building effort is wasted on ephemeral AI agents.</p>



<p>All of this is a moot point for this particular case ‚Äì in <a href="https://github.com/matplotlib/matplotlib/issues/31130" data-type="link" data-id="https://github.com/matplotlib/matplotlib/issues/31130">further discussion</a> we decided that the performance improvement was too fragile / machine-specific and not worth the effort in the first place. The code wouldn‚Äôt have been merged anyway.</p>



<hr>



<p>But I cannot stress enough how much this story is not really about the role of AI in open source software. This is about our systems of reputation, identity, and trust breaking down. So many of our foundational institutions ‚Äì hiring, journalism, law, public discourse ‚Äì are built on the assumption that reputation is hard to build and hard to destroy. That every action can be traced to an individual, and that bad behavior can be held accountable. That the internet, which we all rely on to communicate and learn about the world and about each other, can be relied on as a source of collective social truth.</p>



<p>The rise of untraceable, autonomous, and now malicious AI agents on the internet threatens this entire system. Whether that‚Äôs because a small number of bad actors driving large swarms of agents or from a fraction of poorly supervised agents rewriting their own goals, is a distinction with little difference.</p>





</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Homeland Security Wants Social Media Sites to Expose Anti-ICE Accounts (252 pts)]]></title>
            <link>https://www.nytimes.com/2026/02/13/technology/dhs-anti-ice-social-media.html</link>
            <guid>47009582</guid>
            <pubDate>Sat, 14 Feb 2026 00:00:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2026/02/13/technology/dhs-anti-ice-social-media.html">https://www.nytimes.com/2026/02/13/technology/dhs-anti-ice-social-media.html</a>, See on <a href="https://news.ycombinator.com/item?id=47009582">Hacker News</a></p>
Couldn't get https://www.nytimes.com/2026/02/13/technology/dhs-anti-ice-social-media.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[The evolution of OpenAI's mission statement (116 pts)]]></title>
            <link>https://simonwillison.net/2026/Feb/13/openai-mission-statement/</link>
            <guid>47009416</guid>
            <pubDate>Fri, 13 Feb 2026 23:43:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://simonwillison.net/2026/Feb/13/openai-mission-statement/">https://simonwillison.net/2026/Feb/13/openai-mission-statement/</a>, See on <a href="https://news.ycombinator.com/item?id=47009416">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-permalink-context="/2026/Feb/13/openai-mission-statement/">

<p>13th February 2026</p>



<p>As a USA <a href="https://en.wikipedia.org/wiki/501(c)(3)_organization">501(c)(3)</a> the OpenAI non-profit has to file a tax return each year with the IRS. One of the required fields on that tax return is to ‚ÄúBriefly describe the organization‚Äôs mission or most significant activities‚Äù‚Äîthis has actual legal weight to it as the IRS can use it to evaluate if the organization is sticking to its mission and deserves to maintain its non-profit tax-exempt status.</p>
<p>You can browse OpenAI‚Äôs <a href="https://projects.propublica.org/nonprofits/organizations/810861541">tax filings by year</a> on ProPublica‚Äôs excellent <a href="https://projects.propublica.org/nonprofits/">Nonprofit Explorer</a>.</p>
<p>I went through and extracted that mission statement for 2016 through 2024, then had Claude Code <a href="https://gisthost.github.io/?7a569df89f43f390bccc2c5517718b49/index.html">help me</a> fake the commit dates to turn it into a git repository and share that as a Gist‚Äîwhich means that Gist‚Äôs <a href="https://gist.github.com/simonw/e36f0e5ef4a86881d145083f759bcf25/revisions">revisions page</a> shows every edit they‚Äôve made since they started filing their taxes!</p>
<p>It‚Äôs really interesting seeing what they‚Äôve changed over time.</p>
<p>The original 2016 mission reads as follows (and yes, the apostrophe in ‚ÄúOpenAIs‚Äù is missing <a href="https://projects.propublica.org/nonprofits/organizations/810861541/201703459349300445/full">in the original</a>):</p>
<blockquote>
<p>OpenAIs goal is to advance digital intelligence in the way that is most likely to benefit humanity as a whole, unconstrained by a need to generate financial return. We think that artificial intelligence technology will help shape the 21st century, and we want to help the world build safe AI technology and ensure that AI‚Äôs benefits are as widely and evenly distributed as possible. Were trying to build AI as part of a larger community, and we want to openly share our plans and capabilities along the way.</p>
</blockquote>
<p>In 2018 they dropped the part about ‚Äútrying to build AI as part of a larger community, and we want to openly share our plans and capabilities along the way.‚Äù</p>
<p><img src="https://static.simonwillison.net/static/2026/mission-3.jpg" alt="Git diff showing the 2018 revision deleting the final two sentences: &quot;Were trying to build AI as part of a larger community, and we want to openly share our plans and capabilities along the way.&quot;"></p>
<p>In 2020 they dropped the words ‚Äúas a whole‚Äù from ‚Äúbenefit humanity as a whole‚Äù. They‚Äôre still ‚Äúunconstrained by a need to generate financial return‚Äù though.</p>
<p><img src="https://static.simonwillison.net/static/2026/mission-5.jpg" alt="Git diff showing the 2020 revision dropping &quot;as a whole&quot; from &quot;benefit humanity as a whole&quot; and changing &quot;We think&quot; to &quot;OpenAI believes&quot;"></p>
<p>Some interesting changes in 2021. They‚Äôre still unconstrained by a need to generate financial return, but here we have the first reference to ‚Äúgeneral-purpose artificial intelligence‚Äù (replacing ‚Äúdigital intelligence‚Äù). They‚Äôre more confident too: it‚Äôs not ‚Äúmost likely to benefit humanity‚Äù, it‚Äôs just ‚Äúbenefits humanity‚Äù.</p>
<p>They previously wanted to ‚Äúhelp the world build safe AI technology‚Äù, but now they‚Äôre going to do that themselves: ‚Äúthe companys goal is to develop and responsibly deploy safe AI technology‚Äù.</p>
<p><img src="https://static.simonwillison.net/static/2026/mission-6.jpg" alt="Git diff showing the 2021 revision replacing &quot;goal is to advance digital intelligence&quot; with &quot;mission is to build general-purpose artificial intelligence&quot;, changing &quot;most likely to benefit&quot; to just &quot;benefits&quot;, and replacing &quot;help the world build safe AI technology&quot; with &quot;the companys goal is to develop and responsibly deploy safe AI technology&quot;"></p>
<p>2022 only changed one significant word: they added ‚Äúsafely‚Äù to ‚Äúbuild ... (AI) that safely benefits humanity‚Äù. They‚Äôre still unconstrained by those financial returns!</p>
<p><img src="https://static.simonwillison.net/static/2026/mission-7.jpg" alt="Git diff showing the 2022 revision adding &quot;(AI)&quot; and the word &quot;safely&quot; so it now reads &quot;that safely benefits humanity&quot;, and changing &quot;the companys&quot; to &quot;our&quot;"></p>
<p>No changes in 2023... but then in 2024 they deleted almost the entire thing, reducing it to simply:</p>
<blockquote>
<p>OpenAIs mission is to ensure that artificial general intelligence benefits all of humanity.</p>
</blockquote>
<p>They‚Äôve expanded ‚Äúhumanity‚Äù to ‚Äúall of humanity‚Äù, but there‚Äôs no mention of safety any more and I guess they can finally start focusing on that need to generate financial returns!</p>
<p><img src="https://static.simonwillison.net/static/2026/mission-9.jpg" alt="Git diff showing the 2024 revision deleting the entire multi-sentence mission statement and replacing it with just &quot;OpenAIs mission is to ensure that artificial general intelligence benefits all of humanity.&quot;"></p>

<p><strong>Update</strong>: I found loosely equivalent but much less interesting documents <a href="https://simonwillison.net/2026/Feb/13/anthropic-public-benefit-mission/">from Anthropic</a>.</p>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenAI has deleted the word 'safely' from its mission (537 pts)]]></title>
            <link>https://theconversation.com/openai-has-deleted-the-word-safely-from-its-mission-and-its-new-structure-is-a-test-for-whether-ai-serves-society-or-shareholders-274467</link>
            <guid>47008560</guid>
            <pubDate>Fri, 13 Feb 2026 22:17:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://theconversation.com/openai-has-deleted-the-word-safely-from-its-mission-and-its-new-structure-is-a-test-for-whether-ai-serves-society-or-shareholders-274467">https://theconversation.com/openai-has-deleted-the-word-safely-from-its-mission-and-its-new-structure-is-a-test-for-whether-ai-serves-society-or-shareholders-274467</a>, See on <a href="https://news.ycombinator.com/item?id=47008560">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>OpenAI, the maker of the <a href="https://firstpagesage.com/reports/top-generative-ai-chatbots/">most popular AI chatbot</a>, used to say it aimed to build artificial intelligence that ‚Äúsafely benefits humanity, unconstrained by a need to generate financial return,‚Äù <a href="https://cdn.theconversation.com/static_files/files/4099/2023-IRS990-OpenAI.pdf?1770819990">according to its 2023</a> mission statement. But the ChatGPT maker seems to no longer have the same emphasis on doing so ‚Äúsafely.‚Äù</p>

<p>While reviewing its latest IRS disclosure form, which was released in November 2025 and covers 2024, I noticed OpenAI <a href="https://app.candid.org/profile/9571629/openai-81-0861541?activeTab=7">had removed ‚Äúsafely‚Äù from its mission statement</a>, among other changes. That change in wording coincided with its <a href="https://theconversation.com/as-openai-attracts-billions-in-new-investment-its-goal-of-balancing-profit-with-purpose-is-getting-more-challenging-to-pull-off-240602">transformation from a nonprofit organization</a> into a business <a href="https://www.nytimes.com/2026/02/11/technology/openai-revenue-challenge.html">increasingly focused on profits</a>.</p>

<p>OpenAI currently faces <a href="https://www.transparencycoalition.ai/news/seven-more-lawsuits-filed-against-openai-for-chatgpt-suicide-coaching">several lawsuits</a> related to its products‚Äô safety, making this change newsworthy. Many of the plaintiffs suing the AI company allege psychological manipulation, wrongful death and assisted suicide, while others have filed negligence claims.</p>

<p>As a scholar of <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=_-YZrXgAAAAJ&amp;citation_for_view=_-YZrXgAAAAJ:hC7cP41nSMkC">nonprofit accountability</a> and the <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=_-YZrXgAAAAJ&amp;citation_for_view=_-YZrXgAAAAJ:_kc_bZDykSQC">governance of social enterprises</a>, I see the deletion of the word ‚Äúsafely‚Äù from its mission statement as a significant shift that has largely gone unreported ‚Äì outside <a href="https://news.aibase.com/news/22994">highly specialized outlets</a>.</p>

<p>And I believe OpenAI‚Äôs makeover is a test case for how we, as a society, oversee the work of organizations that have the potential to both provide enormous benefits and do catastrophic harm. </p>



<h2>Tracing OpenAI‚Äôs origins</h2>

<p>OpenAI, which also makes the Sora video artificial intelligence app, was founded as a nonprofit scientific research lab in 2015. Its original purpose was to benefit society by <a href="https://perma.cc/MXE3-FJ7F">making its findings public and royalty-free</a> rather than to make money. </p>

<p>To raise the money that developing its AI models would require, OpenAI, under the leadership of CEO Sam Altman, created a <a href="https://openai.com/our-structure/">for-profit subsidiary in 2019</a>. Microsoft initially invested US$1 billion in this venture; by 2024 that sum had topped $13 billion.</p>

<p>In exchange, Microsoft was promised a portion of future profits, capped at 100 times its initial investment. But the software giant didn‚Äôt get a seat on OpenAI‚Äôs nonprofit board ‚Äì meaning it lacked the power to help steer the AI venture it was funding.</p>

<p>A subsequent round of funding in late 2024, which raised $6.6 billion from multiple investors, came with a catch: that the funding would become debt <a href="https://theconversation.com/as-openai-attracts-billions-in-new-investment-its-goal-of-balancing-profit-with-purpose-is-getting-more-challenging-to-pull-off-240602">unless OpenAI converted to a more traditional for-profit business</a> in which investors could own shares, without any caps on profits, and possibly occupy board seats.  </p>

<h2>Establishing a new structure</h2>

<p>In October 2025, OpenAI reached an agreement with the attorneys general of California and Delaware to <a href="https://www.nytimes.com/2025/10/28/technology/openai-restructure-for-profit-company.html?searchResultPosition=6">become a more traditional for-profit company</a>.</p>

<p>Under the new arrangement, OpenAI was split into two entities: a nonprofit foundation and a for-profit business.  </p>

<p>The restructured nonprofit, the <a href="https://openai.com/foundation/">OpenAI Foundation</a>, owns about one-fourth of the stock in a new <a href="https://delcode.delaware.gov/title8/c001/sc15/">for-profit public benefit corporation</a>, the <a href="https://finance.yahoo.com/news/openais-restructuring-sets-could-biggest-004100492.html">OpenAI Group</a>. Both are headquartered in California but <a href="https://s3.documentcloud.org/documents/26205026/openai-pbc-articles-of-incorporation.pdf">incorporated in Delaware</a>.</p>

<p>A <a href="https://corpgov.law.harvard.edu/2020/08/31/delaware-public-benefit-corporations-recent-developments/">public benefit corporation</a> is a business that must consider interests beyond shareholders, such as those of society and the environment, and it must issue an annual benefit report to its shareholders and the public. However, it is up to the board to decide how to weigh those interests and what to report in terms of the benefits and harms caused by the company.  </p>

<p>The new structure is described in a <a href="https://cdn.theconversation.com/static_files/files/4101/Final_Executed_MOU_Between_OpenAI_and_California_AG_re_Notice_of_Conditions_of_Non-Objection_%2810.27.2025%29_%28Signed_by_OpenAI%29_%28Signed_by_CA_DOJ%29.pdf?1770844719">memorandum of understanding</a> signed in October 2025 by OpenAI and the California attorney general, and <a href="https://news.delaware.gov/2025/10/28/ag-jennings-completes-review-of-openai-recapitalization/">endorsed by the Delaware attorney general</a>.</p>

<p>Many business media outlets heralded the move, predicting that it would <a href="https://www.wsj.com/tech/ai/openai-converts-to-public-benefit-corporation-with-microsoft-taking-27-stake-714a6c05">usher in more investment</a>. Two months later, SoftBank, a Japanese conglomerate, finalized a <a href="https://www.reuters.com/business/media-telecom/softbank-has-fully-funded-its-40-billion-investment-openai-cnbc-reports-2025-12-30/">$41 billion investment in OpenAI</a>.</p>

<h2>Changing its mission statement</h2>

<p>Most charities must <a href="https://theconversation.com/whats-a-990-form-a-charity-accounting-expert-explains-175019">file forms annually with the Internal Revenue Service</a> with details about their missions, activities and financial status to show that they qualify for tax-exempt status. Because the IRS makes the forms public, they have become a way for nonprofits to signal their missions to the world.</p>

<p>In <a href="https://app.candid.org/profile/9571629/openai-81-0861541?activeTab=7">its forms for 2022</a>, <a href="https://cdn.theconversation.com/static_files/files/4099/2023-IRS990-OpenAI.pdf?1770819990">and 2023</a>, OpenAI said its mission was ‚Äúto build general-purpose artificial intelligence (AI) that safely benefits humanity, unconstrained by a need to generate financial return.‚Äù</p>

<figure>
            <a href="https://images.theconversation.com/files/717796/original/file-20260211-56-pv2w2t.jpg?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=1000&amp;fit=clip"><p><img alt="This is the top of the front page of the 2023 990 form for OpenAI, with its mission stated at the bottom of the screenshot." src="https://images.theconversation.com/files/717796/original/file-20260211-56-pv2w2t.jpg?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip" loading="lazy" srcset="https://images.theconversation.com/files/717796/original/file-20260211-56-pv2w2t.jpg?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=600&amp;h=338&amp;fit=crop&amp;dpr=1 600w, https://images.theconversation.com/files/717796/original/file-20260211-56-pv2w2t.jpg?ixlib=rb-4.1.0&amp;q=30&amp;auto=format&amp;w=600&amp;h=338&amp;fit=crop&amp;dpr=2 1200w, https://images.theconversation.com/files/717796/original/file-20260211-56-pv2w2t.jpg?ixlib=rb-4.1.0&amp;q=15&amp;auto=format&amp;w=600&amp;h=338&amp;fit=crop&amp;dpr=3 1800w, https://images.theconversation.com/files/717796/original/file-20260211-56-pv2w2t.jpg?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;h=424&amp;fit=crop&amp;dpr=1 754w, https://images.theconversation.com/files/717796/original/file-20260211-56-pv2w2t.jpg?ixlib=rb-4.1.0&amp;q=30&amp;auto=format&amp;w=754&amp;h=424&amp;fit=crop&amp;dpr=2 1508w, https://images.theconversation.com/files/717796/original/file-20260211-56-pv2w2t.jpg?ixlib=rb-4.1.0&amp;q=15&amp;auto=format&amp;w=754&amp;h=424&amp;fit=crop&amp;dpr=3 2262w" sizes="(min-width: 1466px) 754px, (max-width: 599px) 100vw, (min-width: 600px) 600px, 237px"></p></a>
            <figcaption>
              <span>OpenAI‚Äôs mission statement as of 2023 included the word ‚Äòsafely.‚Äô</span>
              <span><span>IRS via Candid</span></span>
            </figcaption>
          </figure>

<p>That mission statement has changed, as of <a href="https://cdn.theconversation.com/static_files/files/4100/2024-IRS990-OpenAI.pdf?1770820492">OpenAI‚Äôs 990 form for 2024</a> ‚Äì which the company filed with the IRS in late 2025. It became ‚Äúto ensure that artificial general intelligence benefits all of humanity.‚Äù</p>

<figure>
            <a href="https://images.theconversation.com/files/717795/original/file-20260211-56-96xe28.jpg?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=1000&amp;fit=clip"><p><img alt="This is the top of the front page of the 2024 990 form for OpenAI, with its mission stated at the bottom of the screenshot." src="https://images.theconversation.com/files/717795/original/file-20260211-56-96xe28.jpg?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip" loading="lazy" srcset="https://images.theconversation.com/files/717795/original/file-20260211-56-96xe28.jpg?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=600&amp;h=338&amp;fit=crop&amp;dpr=1 600w, https://images.theconversation.com/files/717795/original/file-20260211-56-96xe28.jpg?ixlib=rb-4.1.0&amp;q=30&amp;auto=format&amp;w=600&amp;h=338&amp;fit=crop&amp;dpr=2 1200w, https://images.theconversation.com/files/717795/original/file-20260211-56-96xe28.jpg?ixlib=rb-4.1.0&amp;q=15&amp;auto=format&amp;w=600&amp;h=338&amp;fit=crop&amp;dpr=3 1800w, https://images.theconversation.com/files/717795/original/file-20260211-56-96xe28.jpg?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;h=424&amp;fit=crop&amp;dpr=1 754w, https://images.theconversation.com/files/717795/original/file-20260211-56-96xe28.jpg?ixlib=rb-4.1.0&amp;q=30&amp;auto=format&amp;w=754&amp;h=424&amp;fit=crop&amp;dpr=2 1508w, https://images.theconversation.com/files/717795/original/file-20260211-56-96xe28.jpg?ixlib=rb-4.1.0&amp;q=15&amp;auto=format&amp;w=754&amp;h=424&amp;fit=crop&amp;dpr=3 2262w" sizes="(min-width: 1466px) 754px, (max-width: 599px) 100vw, (min-width: 600px) 600px, 237px"></p></a>
            <figcaption>
              <span>OpenAI‚Äôs mission statement as of 2024 no longer included the word ‚Äòsafely.‚Äô</span>
              <span><span>IRS via Candid</span></span>
            </figcaption>
          </figure>

<p>OpenAI had dropped its commitment to safety from its mission statement ‚Äì along with a commitment to being ‚Äúunconstrained‚Äù by a need to make money for investors. According to Platformer, a tech media outlet, it has also disbanded its ‚Äú<a href="https://www.platformer.news/openai-mission-alignment-team-joshua-achiam/">mission alignment</a>‚Äù team.</p>

<p>In my view, these changes explicitly signal that OpenAI is making its profits a higher priority than the safety of its products.</p>

<p>To be sure, OpenAI continues to mention safety when it <a href="https://openai.com/index/why-our-structure-must-evolve-to-advance-our-mission/">discusses its mission</a>. ‚ÄúWe view this mission as the most important challenge of our time,‚Äù it states on its website. ‚ÄúIt requires simultaneously advancing AI‚Äôs capability, safety, and positive impact in the world.‚Äù</p>

<h2>Revising its legal governance structure</h2>

<p>Nonprofit boards are responsible for key decisions and <a href="https://theconversation.com/openai-is-a-nonprofit-corporate-hybrid-a-management-expert-explains-how-this-model-works-and-how-it-fueled-the-tumult-around-ceo-sam-altmans-short-lived-ouster-218340">upholding their organization‚Äôs mission</a>.</p>

<p>Unlike private companies, board members of <a href="https://www.irs.gov/charities-non-profits/charitable-organizations/exemption-requirements-501c3-organizations">tax-exempt charitable nonprofits</a> cannot personally enrich themselves by taking a share of earnings. In cases where a nonprofit owns a for-profit business, as OpenAI did with its previous structure, investors can take a cut of profits ‚Äì but they typically do not get a seat on the board or have an opportunity to elect board members, because that would be seen as a conflict of interest.  </p>

<p>The OpenAI Foundation now has a 26% stake in OpenAI Group. In effect, that means that the nonprofit board has given up nearly three-quarters of its control over the company. Software giant Microsoft owns a slightly larger stake ‚Äì 27% of OpenAI‚Äôs stock ‚Äì due to its <a href="https://www.fool.com/investing/2025/11/03/open-ai-move-made-microsoft-no-brainer-buy/">$13.8 billion investment in the AI company</a> to date. OpenAI‚Äôs employees and its other investors own the rest of the shares. </p>

<figure>
            <a href="https://images.theconversation.com/files/717515/original/file-20260210-56-fg54z1.jpg?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=1000&amp;fit=clip"><p><img alt="A man speaks while sitting in a chair in front of a wall emblazoned with OpenAI." src="https://images.theconversation.com/files/717515/original/file-20260210-56-fg54z1.jpg?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip" loading="lazy" srcset="https://images.theconversation.com/files/717515/original/file-20260210-56-fg54z1.jpg?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=600&amp;h=406&amp;fit=crop&amp;dpr=1 600w, https://images.theconversation.com/files/717515/original/file-20260210-56-fg54z1.jpg?ixlib=rb-4.1.0&amp;q=30&amp;auto=format&amp;w=600&amp;h=406&amp;fit=crop&amp;dpr=2 1200w, https://images.theconversation.com/files/717515/original/file-20260210-56-fg54z1.jpg?ixlib=rb-4.1.0&amp;q=15&amp;auto=format&amp;w=600&amp;h=406&amp;fit=crop&amp;dpr=3 1800w, https://images.theconversation.com/files/717515/original/file-20260210-56-fg54z1.jpg?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;h=510&amp;fit=crop&amp;dpr=1 754w, https://images.theconversation.com/files/717515/original/file-20260210-56-fg54z1.jpg?ixlib=rb-4.1.0&amp;q=30&amp;auto=format&amp;w=754&amp;h=510&amp;fit=crop&amp;dpr=2 1508w, https://images.theconversation.com/files/717515/original/file-20260210-56-fg54z1.jpg?ixlib=rb-4.1.0&amp;q=15&amp;auto=format&amp;w=754&amp;h=510&amp;fit=crop&amp;dpr=3 2262w" sizes="(min-width: 1466px) 754px, (max-width: 599px) 100vw, (min-width: 600px) 600px, 237px"></p></a>
            <figcaption>
              <span>Open AI CEO Sam Altman speaks in June 2025, as his company sought to change its structure.</span>
              <span><a href="https://www.gettyimages.com/detail/news-photo/open-ai-ceo-sam-altman-speaks-during-snowflake-summit-2025-news-photo/2218344211?adppopup=true">Justin Sullivan/Getty Images</a></span>
            </figcaption>
          </figure>

<h2>Seeking more investment</h2>

<p>The main goal of OpenAI‚Äôs restructuring, which it called a ‚Äú<a href="https://openai.com/index/built-to-benefit-everyone/">recapitalization</a>,‚Äù was to attract more private investment in the <a href="https://www.forbes.com/councils/forbesbusinesscouncil/2025/02/27/the-ai-arms-race-deepseek-vs-openai-and-the-battle-for-global-ai-dominance/">race for AI dominance</a>.</p>

<p>It has already succeeded on that front.</p>

<p>As of early February 2026, the company was in talks with SoftBank for an <a href="https://www.reuters.com/business/media-telecom/softbank-talks-invest-up-30-billion-more-openai-wsj-reports-2026-01-28/">additional $30 billion</a> and stands to get up to a total of <a href="https://www.reuters.com/business/retail-consumer/amazon-talks-invest-up-50-billion-openai-wsj-reports-2026-01-29/">$60 billion from Amazon, Nvidia and Microsoft</a> combined.</p>

<p>OpenAI is now valued at over <a href="https://www.cnbc.com/2025/10/02/openai-share-sale-500-billion-valuation.html">$500 billion</a>, up from <a href="https://tracxn.com/d/companies/openai/__kElhSG7uVGeFk1i71Co9-nwFtmtyMVT7f-YHMn4TFBg/funding-and-investors#funding-rounds">$300 billion</a> in March 2025. The new structure also paves the way for an eventual <a href="https://www.investopedia.com/terms/i/ipo.asp">initial public offering</a>, which, if it happens, would not only help the company <a href="https://www.wsj.com/tech/ai/openai-ipo-anthropic-race-69f06a42">raise more capital through stock markets</a> but would also increase the pressure to make money for its shareholders.</p>

<p>OpenAI says the foundation‚Äôs endowment is <a href="https://openai.com/index/built-to-benefit-everyone/">worth about $130 billion</a>.</p>

<p>Those numbers are only estimates because OpenAI is a privately held company without publicly traded shares. That means these figures are based on market value estimates rather than any objective evidence, such as market capitalization.</p>

<p>When he <a href="https://oag.ca.gov/news/press-releases/attorney-general-bonta-issues-statement-openai%E2%80%99s-recapitalization-plan">announced the new structure</a>, California Attorney General Rob Bonta said, ‚ÄúWe secured concessions that ensure charitable assets are used for their intended purpose.‚Äù He also predicted that ‚Äúsafety will be prioritized‚Äù and said the ‚Äútop priority is, and always will be, protecting our kids.‚Äù  </p>

<h2>Steps that might help keep people safe</h2>

<p>At the same time, several conditions in the OpenAI restructuring memo are designed to promote safety, including:</p>

<ol>
<li><p>A safety and security committee on the OpenAI Foundation board has the authority to <a href="https://cdn.theconversation.com/static_files/files/4101/Final_Executed_MOU_Between_OpenAI_and_California_AG_re_Notice_of_Conditions_of_Non-Objection_%2810.27.2025%29_%28Signed_by_OpenAI%29_%28Signed_by_CA_DOJ%29.pdf?1770844719">‚Äúrequire mitigation measures‚Äù</a> that could potentially include the halting of a release of new OpenAI products based on assessments of their risks. </p></li>
<li><p>The for-profit OpenAI Group has its own board, which must consider only OpenAI‚Äôs mission ‚Äì rather than financial issues ‚Äì regarding safety and security issues.</p></li>
<li><p>The OpenAI Foundation‚Äôs nonprofit board gets to appoint all members of the OpenAI Group‚Äôs for-profit board.</p></li>
</ol>

<p>But given that neither the mission of the foundation nor of the OpenAI group explicitly alludes to safety, it will be hard to hold their boards accountable for it. </p>

<p>Furthermore, since <a href="https://www.latimes.com/business/story/2025-10-30/openai-restructure-paves-way-for-ipo-and-ai-spending-spree">all but one board member currently serve on both boards</a>, it is hard to see how they might oversee themselves. And <a href="https://cdn.theconversation.com/static_files/files/4101/Final_Executed_MOU_Between_OpenAI_and_California_AG_re_Notice_of_Conditions_of_Non-Objection_%2810.27.2025%29_%28Signed_by_OpenAI%29_%28Signed_by_CA_DOJ%29.pdf?1770844719">the memorandum signed by the California attorney general</a> doesn‚Äôt indicate whether he was aware of the removal of any reference to safety from the mission statement.</p>

<h2>Identifying other paths OpenAI could have taken</h2>

<p>There are alternative models that I believe would serve the public interest better than this one.</p>

<p>When Health Net, a California nonprofit <a href="https://www.medicare.gov/health-drug-plans/health-plans/your-health-plan-options/HMO">health maintenance organization</a>, <a href="https://www.latimes.com/archives/la-xpm-1992-02-08-fi-1192-story.html">converted to a for-profit insurance company</a> in 1992, regulators required that 80% of its equity be transferred to another <a href="https://www.calwellness.org/mission/our-story/">nonprofit health foundation</a>. Unlike with OpenAI, the foundation had majority control after the transformation.</p>

<p>A <a href="https://www.eyesonopenai.org/">coalition of California nonprofits</a> has argued that the attorney general should require OpenAI to transfer all of its assets to an independent nonprofit.  </p>

<p>Another example is <a href="https://www.lenfestinstitute.org/our-work/the-philadelphia-inquirer/">The Philadelphia Inquirer</a>. The Pennsylvania newspaper <a href="https://current.org/2016/04/as-philadelphia-newspapers-turn-to-nonprofits-who-is-public-media/">became a for-profit public benefit corporation</a> in 2016. It belongs to the Lenfest Institute, a nonprofit.</p>

<p>This structure allows Philadelphia‚Äôs biggest newspaper to attract investment without compromising its purpose ‚Äì journalism serving the needs of its local communities. It‚Äôs become a model for potentially <a href="https://www.inquirer.com/opinion/commentary/press-forward-lenfest-institute-journalism-philanthropy-american-democracy-20230907.html">transforming the local news industry</a>. </p>

<p>At this point, I believe that the public bears the burden of two governance failures. One is that OpenAI‚Äôs board has apparently abandoned its mission of safety. And the other is that the attorneys general of California and Delaware have let that happen.</p>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Data Engineering Book ‚Äì An open source, community-driven guide (196 pts)]]></title>
            <link>https://github.com/datascale-ai/data_engineering_book/blob/main/README_en.md</link>
            <guid>47008163</guid>
            <pubDate>Fri, 13 Feb 2026 21:35:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/datascale-ai/data_engineering_book/blob/main/README_en.md">https://github.com/datascale-ai/data_engineering_book/blob/main/README_en.md</a>, See on <a href="https://news.ycombinator.com/item?id=47008163">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            


<react-partial partial-name="marketing-navigation" data-ssr="true" data-attempted-ssr="true" data-react-profiling="true">
  
  
  <div data-target="react-partial.reactRoot"><nav aria-label="Global"><ul><li><div><ul><li><div><p><span>AI CODE CREATION</span></p><ul><li><a href="https://github.com/features/copilot" data-analytics-event="{&quot;action&quot;:&quot;github_copilot&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;github_copilot_link_platform_navbar&quot;}"><div><p><span>GitHub Copilot</span><span>Write better code with AI</span></p></div></a></li><li><a href="https://github.com/features/spark" data-analytics-event="{&quot;action&quot;:&quot;github_spark&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;github_spark_link_platform_navbar&quot;}"><div><p><span>GitHub Spark</span><span>Build and deploy intelligent apps</span></p></div></a></li><li><a href="https://github.com/features/models" data-analytics-event="{&quot;action&quot;:&quot;github_models&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;github_models_link_platform_navbar&quot;}"><div><p><span>GitHub Models</span><span>Manage and compare prompts</span></p></div></a></li><li><a href="https://github.com/mcp" data-analytics-event="{&quot;action&quot;:&quot;mcp_registry&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;mcp_registry_link_platform_navbar&quot;}"><div><p><span>MCP Registry<sup>New</sup></span><span>Integrate external tools</span></p></div></a></li></ul></div></li><li><div><p><span>DEVELOPER WORKFLOWS</span></p><ul><li><a href="https://github.com/features/actions" data-analytics-event="{&quot;action&quot;:&quot;actions&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;actions_link_platform_navbar&quot;}"><div><p><span>Actions</span><span>Automate any workflow</span></p></div></a></li><li><a href="https://github.com/features/codespaces" data-analytics-event="{&quot;action&quot;:&quot;codespaces&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;codespaces_link_platform_navbar&quot;}"><div><p><span>Codespaces</span><span>Instant dev environments</span></p></div></a></li><li><a href="https://github.com/features/issues" data-analytics-event="{&quot;action&quot;:&quot;issues&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;issues_link_platform_navbar&quot;}"><div><p><span>Issues</span><span>Plan and track work</span></p></div></a></li><li><a href="https://github.com/features/code-review" data-analytics-event="{&quot;action&quot;:&quot;code_review&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;code_review_link_platform_navbar&quot;}"><div><p><span>Code Review</span><span>Manage code changes</span></p></div></a></li></ul></div></li><li><div><p><span>APPLICATION SECURITY</span></p><ul><li><a href="https://github.com/security/advanced-security" data-analytics-event="{&quot;action&quot;:&quot;github_advanced_security&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;github_advanced_security_link_platform_navbar&quot;}"><div><p><span>GitHub Advanced Security</span><span>Find and fix vulnerabilities</span></p></div></a></li><li><a href="https://github.com/security/advanced-security/code-security" data-analytics-event="{&quot;action&quot;:&quot;code_security&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;code_security_link_platform_navbar&quot;}"><div><p><span>Code security</span><span>Secure your code as you build</span></p></div></a></li><li><a href="https://github.com/security/advanced-security/secret-protection" data-analytics-event="{&quot;action&quot;:&quot;secret_protection&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;secret_protection_link_platform_navbar&quot;}"><div><p><span>Secret protection</span><span>Stop leaks before they start</span></p></div></a></li></ul></div></li><li><div><p><span>EXPLORE</span></p><ul><li><a href="https://github.com/why-github" data-analytics-event="{&quot;action&quot;:&quot;why_github&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;why_github_link_platform_navbar&quot;}"><span>Why GitHub</span></a></li><li><a href="https://docs.github.com/" data-analytics-event="{&quot;action&quot;:&quot;documentation&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;documentation_link_platform_navbar&quot;}" target="_blank" rel="noreferrer"><span>Documentation</span></a></li><li><a href="https://github.blog/" data-analytics-event="{&quot;action&quot;:&quot;blog&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;blog_link_platform_navbar&quot;}" target="_blank" rel="noreferrer"><span>Blog</span></a></li><li><a href="https://github.blog/changelog" data-analytics-event="{&quot;action&quot;:&quot;changelog&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;changelog_link_platform_navbar&quot;}" target="_blank" rel="noreferrer"><span>Changelog</span></a></li><li><a href="https://github.com/marketplace" data-analytics-event="{&quot;action&quot;:&quot;marketplace&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;marketplace_link_platform_navbar&quot;}"><span>Marketplace</span></a></li></ul></div></li></ul><p><a href="https://github.com/features" data-analytics-event="{&quot;action&quot;:&quot;view_all_features&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;view_all_features_link_platform_navbar&quot;}"><span>View all features</span></a></p></div></li><li><div><ul><li><div><p><span>BY COMPANY SIZE</span></p><ul><li><a href="https://github.com/enterprise" data-analytics-event="{&quot;action&quot;:&quot;enterprises&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;enterprises_link_solutions_navbar&quot;}"><span>Enterprises</span></a></li><li><a href="https://github.com/team" data-analytics-event="{&quot;action&quot;:&quot;small_and_medium_teams&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;small_and_medium_teams_link_solutions_navbar&quot;}"><span>Small and medium teams</span></a></li><li><a href="https://github.com/enterprise/startups" data-analytics-event="{&quot;action&quot;:&quot;startups&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;startups_link_solutions_navbar&quot;}"><span>Startups</span></a></li><li><a href="https://github.com/solutions/industry/nonprofits" data-analytics-event="{&quot;action&quot;:&quot;nonprofits&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;nonprofits_link_solutions_navbar&quot;}"><span>Nonprofits</span></a></li></ul></div></li><li><div><p><span>BY USE CASE</span></p><ul><li><a href="https://github.com/solutions/use-case/app-modernization" data-analytics-event="{&quot;action&quot;:&quot;app_modernization&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;app_modernization_link_solutions_navbar&quot;}"><span>App Modernization</span></a></li><li><a href="https://github.com/solutions/use-case/devsecops" data-analytics-event="{&quot;action&quot;:&quot;devsecops&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;devsecops_link_solutions_navbar&quot;}"><span>DevSecOps</span></a></li><li><a href="https://github.com/solutions/use-case/devops" data-analytics-event="{&quot;action&quot;:&quot;devops&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;devops_link_solutions_navbar&quot;}"><span>DevOps</span></a></li><li><a href="https://github.com/solutions/use-case/ci-cd" data-analytics-event="{&quot;action&quot;:&quot;ci/cd&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;ci/cd_link_solutions_navbar&quot;}"><span>CI/CD</span></a></li><li><a href="https://github.com/solutions/use-case" data-analytics-event="{&quot;action&quot;:&quot;view_all_use_cases&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;view_all_use_cases_link_solutions_navbar&quot;}"><span>View all use cases</span></a></li></ul></div></li><li><div><p><span>BY INDUSTRY</span></p><ul><li><a href="https://github.com/solutions/industry/healthcare" data-analytics-event="{&quot;action&quot;:&quot;healthcare&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;healthcare_link_solutions_navbar&quot;}"><span>Healthcare</span></a></li><li><a href="https://github.com/solutions/industry/financial-services" data-analytics-event="{&quot;action&quot;:&quot;financial_services&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;financial_services_link_solutions_navbar&quot;}"><span>Financial services</span></a></li><li><a href="https://github.com/solutions/industry/manufacturing" data-analytics-event="{&quot;action&quot;:&quot;manufacturing&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;manufacturing_link_solutions_navbar&quot;}"><span>Manufacturing</span></a></li><li><a href="https://github.com/solutions/industry/government" data-analytics-event="{&quot;action&quot;:&quot;government&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;government_link_solutions_navbar&quot;}"><span>Government</span></a></li><li><a href="https://github.com/solutions/industry" data-analytics-event="{&quot;action&quot;:&quot;view_all_industries&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;view_all_industries_link_solutions_navbar&quot;}"><span>View all industries</span></a></li></ul></div></li></ul><p><a href="https://github.com/solutions" data-analytics-event="{&quot;action&quot;:&quot;view_all_solutions&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;view_all_solutions_link_solutions_navbar&quot;}"><span>View all solutions</span></a></p></div></li><li><div><ul><li><div><p><span>EXPLORE BY TOPIC</span></p><ul><li><a href="https://github.com/resources/articles?topic=ai" data-analytics-event="{&quot;action&quot;:&quot;ai&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;ai_link_resources_navbar&quot;}"><span>AI</span></a></li><li><a href="https://github.com/resources/articles?topic=software-development" data-analytics-event="{&quot;action&quot;:&quot;software_development&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;software_development_link_resources_navbar&quot;}"><span>Software Development</span></a></li><li><a href="https://github.com/resources/articles?topic=devops" data-analytics-event="{&quot;action&quot;:&quot;devops&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;devops_link_resources_navbar&quot;}"><span>DevOps</span></a></li><li><a href="https://github.com/resources/articles?topic=security" data-analytics-event="{&quot;action&quot;:&quot;security&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;security_link_resources_navbar&quot;}"><span>Security</span></a></li><li><a href="https://github.com/resources/articles" data-analytics-event="{&quot;action&quot;:&quot;view_all_topics&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;view_all_topics_link_resources_navbar&quot;}"><span>View all topics</span></a></li></ul></div></li><li><div><p><span>EXPLORE BY TYPE</span></p><ul><li><a href="https://github.com/customer-stories" data-analytics-event="{&quot;action&quot;:&quot;customer_stories&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;customer_stories_link_resources_navbar&quot;}"><span>Customer stories</span></a></li><li><a href="https://github.com/resources/events" data-analytics-event="{&quot;action&quot;:&quot;events__webinars&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;events__webinars_link_resources_navbar&quot;}"><span>Events &amp; webinars</span></a></li><li><a href="https://github.com/resources/whitepapers" data-analytics-event="{&quot;action&quot;:&quot;ebooks__reports&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;ebooks__reports_link_resources_navbar&quot;}"><span>Ebooks &amp; reports</span></a></li><li><a href="https://github.com/solutions/executive-insights" data-analytics-event="{&quot;action&quot;:&quot;business_insights&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;business_insights_link_resources_navbar&quot;}"><span>Business insights</span></a></li><li><a href="https://skills.github.com/" data-analytics-event="{&quot;action&quot;:&quot;github_skills&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;github_skills_link_resources_navbar&quot;}" target="_blank" rel="noreferrer"><span>GitHub Skills</span></a></li></ul></div></li><li><div><p><span>SUPPORT &amp; SERVICES</span></p><ul><li><a href="https://docs.github.com/" data-analytics-event="{&quot;action&quot;:&quot;documentation&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;documentation_link_resources_navbar&quot;}" target="_blank" rel="noreferrer"><span>Documentation</span></a></li><li><a href="https://support.github.com/" data-analytics-event="{&quot;action&quot;:&quot;customer_support&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;customer_support_link_resources_navbar&quot;}" target="_blank" rel="noreferrer"><span>Customer support</span></a></li><li><a href="https://github.com/orgs/community/discussions" data-analytics-event="{&quot;action&quot;:&quot;community_forum&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;community_forum_link_resources_navbar&quot;}"><span>Community forum</span></a></li><li><a href="https://github.com/trust-center" data-analytics-event="{&quot;action&quot;:&quot;trust_center&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;trust_center_link_resources_navbar&quot;}"><span>Trust center</span></a></li><li><a href="https://github.com/partners" data-analytics-event="{&quot;action&quot;:&quot;partners&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;partners_link_resources_navbar&quot;}"><span>Partners</span></a></li></ul></div></li></ul></div></li><li><div><ul><li><div><p><span>COMMUNITY</span></p><ul><li><a href="https://github.com/sponsors" data-analytics-event="{&quot;action&quot;:&quot;github_sponsors&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;github_sponsors_link_open_source_navbar&quot;}"><div><p><span>GitHub Sponsors</span><span>Fund open source developers</span></p></div></a></li></ul></div></li><li><div><p><span>PROGRAMS</span></p><ul><li><a href="https://securitylab.github.com/" data-analytics-event="{&quot;action&quot;:&quot;security_lab&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;security_lab_link_open_source_navbar&quot;}" target="_blank" rel="noreferrer"><span>Security Lab</span></a></li><li><a href="https://maintainers.github.com/" data-analytics-event="{&quot;action&quot;:&quot;maintainer_community&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;maintainer_community_link_open_source_navbar&quot;}" target="_blank" rel="noreferrer"><span>Maintainer Community</span></a></li><li><a href="https://github.com/accelerator" data-analytics-event="{&quot;action&quot;:&quot;accelerator&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;accelerator_link_open_source_navbar&quot;}"><span>Accelerator</span></a></li><li><a href="https://archiveprogram.github.com/" data-analytics-event="{&quot;action&quot;:&quot;archive_program&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;archive_program_link_open_source_navbar&quot;}" target="_blank" rel="noreferrer"><span>Archive Program</span></a></li></ul></div></li><li><div><p><span>REPOSITORIES</span></p><ul><li><a href="https://github.com/topics" data-analytics-event="{&quot;action&quot;:&quot;topics&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;topics_link_open_source_navbar&quot;}"><span>Topics</span></a></li><li><a href="https://github.com/trending" data-analytics-event="{&quot;action&quot;:&quot;trending&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;trending_link_open_source_navbar&quot;}"><span>Trending</span></a></li><li><a href="https://github.com/collections" data-analytics-event="{&quot;action&quot;:&quot;collections&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;collections_link_open_source_navbar&quot;}"><span>Collections</span></a></li></ul></div></li></ul></div></li><li><div><ul><li><div><p><span>ENTERPRISE SOLUTIONS</span></p><ul><li><a href="https://github.com/enterprise" data-analytics-event="{&quot;action&quot;:&quot;enterprise_platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;enterprise&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;enterprise_platform_link_enterprise_navbar&quot;}"><div><p><span>Enterprise platform</span><span>AI-powered developer platform</span></p></div></a></li></ul></div></li><li><div><p><span>AVAILABLE ADD-ONS</span></p><ul><li><a href="https://github.com/security/advanced-security" data-analytics-event="{&quot;action&quot;:&quot;github_advanced_security&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;enterprise&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;github_advanced_security_link_enterprise_navbar&quot;}"><div><p><span>GitHub Advanced Security</span><span>Enterprise-grade security features</span></p></div></a></li><li><a href="https://github.com/features/copilot/copilot-business" data-analytics-event="{&quot;action&quot;:&quot;copilot_for_business&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;enterprise&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;copilot_for_business_link_enterprise_navbar&quot;}"><div><p><span>Copilot for Business</span><span>Enterprise-grade AI features</span></p></div></a></li><li><a href="https://github.com/premium-support" data-analytics-event="{&quot;action&quot;:&quot;premium_support&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;enterprise&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;premium_support_link_enterprise_navbar&quot;}"><div><p><span>Premium Support</span><span>Enterprise-grade 24/7 support</span></p></div></a></li></ul></div></li></ul></div></li><li><a href="https://github.com/pricing" data-analytics-event="{&quot;action&quot;:&quot;pricing&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;pricing&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;pricing_link_pricing_navbar&quot;}"><span>Pricing</span></a></li></ul></nav></div>
</react-partial>



        <div>
                


<qbsearch-input data-scope="repo:datascale-ai/data_engineering_book" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="f52csNyZYVhWXodgLXT51hLDeYy-6u9TMh2n2F8CJgKGE8pwGaH2EGORV3WbB05grkXflDslu8NF5rHDSzDbpg" data-max-custom-scopes="10" data-header-redesign-enabled="false" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="datascale-ai/data_engineering_book" data-current-org="datascale-ai" data-current-owner="" data-logged-in="false" data-copilot-chat-enabled="false" data-nl-search-enabled="false" data-retain-scroll-position="true">
  <div data-modal-dialog-overlay="" data-action="click:qbsearch-input#searchInputContainerClicked">
  <modal-dialog data-action="close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose" data-target="qbsearch-input.searchSuggestionsDialog" role="dialog" id="search-suggestions-dialog" aria-modal="true" aria-labelledby="search-suggestions-dialog-header" data-view-component="true">
      <h2 id="search-suggestions-dialog-header">Search code, repositories, users, issues, pull requests...</h2>
    
</modal-dialog></div>
  
  <div>
    
<dialog-helper>
  <dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="feedback-dialog" aria-modal="true" aria-labelledby="feedback-dialog-title" aria-describedby="feedback-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="feedback-dialog-title">
        Provide feedback
      </h2>
        
    </p>
    
  </div>
      <scrollable-region data-labelled-by="feedback-dialog-title">
        <div data-view-component="true">        <!-- '"` --><!-- </textarea></xmp> --><form id="code-search-feedback-form" data-turbo="false" action="/search/feedback" accept-charset="UTF-8" method="post">
          <p>We read every piece of feedback, and take your input very seriously.</p>
          
          
          <label for="include_email">Include my email address so I can be contacted</label>
</form></div>
      </scrollable-region>
      
</dialog></dialog-helper>

    <custom-scopes data-target="qbsearch-input.customScopesManager">
    
<dialog-helper>
  <dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="custom-scopes-dialog" aria-modal="true" aria-labelledby="custom-scopes-dialog-title" aria-describedby="custom-scopes-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="custom-scopes-dialog-title">
        Saved searches
      </h2>
        <h2 id="custom-scopes-dialog-description">Use saved searches to filter your results more quickly</h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="custom-scopes-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>
    </custom-scopes>
  </div>
</qbsearch-input>


            <div>
              <p><a href="https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2Fdatascale-ai%2Fdata_engineering_book%2Fblob%2Fmain%2FREADME_en.md" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/datascale-ai/data_engineering_book/blob/main/README_en.md&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="aeb4629fbfc152b844a2d15bc0ce9b8bce377dcfb81e52cdd3a32b2ca84686c3" data-analytics-event="{&quot;category&quot;:&quot;Marketing nav&quot;,&quot;action&quot;:&quot;click to go to homepage&quot;,&quot;label&quot;:&quot;ref_page:Marketing;ref_cta:Sign in;ref_loc:Header&quot;}">
                Sign in
              </a>
            </p></div>

              <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fblob%2Fshow&amp;source=header-repo&amp;source_repo=datascale-ai%2Fdata_engineering_book" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/datascale-ai/data_engineering_book/blob/main/README_en.md&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="aeb4629fbfc152b844a2d15bc0ce9b8bce377dcfb81e52cdd3a32b2ca84686c3" data-analytics-event="{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/<user-name>/<repo-name>/blob/show;ref_cta:Sign up;ref_loc:header logged out&quot;}">
                Sign up
              </a></p><p>
    <react-partial-anchor>
      <tool-tip id="tooltip-c3a84f8d-dc53-4262-86c3-09e57c25a010" for="icon-button-5429f9ff-8eb5-41e1-bab4-a5ab388d0f50" popover="manual" data-direction="s" data-type="label" data-view-component="true">Appearance settings</tool-tip>

      <template data-target="react-partial-anchor.template">
        <link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/primer-react.298ffe31d478a02c.module.css">
<link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/appearance-settings.d1797b65cfd73e57.module.css">

<react-partial partial-name="appearance-settings" data-ssr="false" data-attempted-ssr="false" data-react-profiling="true">
  
  <script type="application/json" data-target="react-partial.embeddedData">{"props":{}}</script>
  <div data-target="react-partial.reactRoot"></div>
</react-partial>


      </template>
    </react-partial-anchor>
  </p>

          </div>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The EU moves to kill infinite scrolling (674 pts)]]></title>
            <link>https://www.politico.eu/article/tiktok-meta-facebook-instagram-brussels-kill-infinite-scrolling/</link>
            <guid>47007656</guid>
            <pubDate>Fri, 13 Feb 2026 20:52:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.politico.eu/article/tiktok-meta-facebook-instagram-brussels-kill-infinite-scrolling/">https://www.politico.eu/article/tiktok-meta-facebook-instagram-brussels-kill-infinite-scrolling/</a>, See on <a href="https://news.ycombinator.com/item?id=47007656">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
					<p>
			<h2>
						
			<span>
				Our readers read next			</span>
					</h2>
	
	
	</p>
						
		
		
		
		
			</div><div>
					<p>
			<h2>
						
			<span>
				More from Eliza Gkritsi			</span>
					</h2>
	
	
	</p>
						<div data-count="4" data-remainder="0" data-block-attributes="[]" data-page="0">
					
<div>
			<p><img src="https://www.politico.eu/cdn-cgi/image/width=380,height=253,quality=80,onerror=redirect,format=auto/wp-content/uploads/2026/02/11/sanchez-scaled.jpg" srcset="https://www.politico.eu/cdn-cgi/image/width=480,quality=80,onerror=redirect,format=auto/wp-content/uploads/2026/02/11/sanchez-scaled.jpg 480w, https://www.politico.eu/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2026/02/11/sanchez-scaled.jpg 768w, https://www.politico.eu/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2026/02/11/sanchez-scaled.jpg 1024w, https://www.politico.eu/cdn-cgi/image/width=1280,quality=80,onerror=redirect,format=auto/wp-content/uploads/2026/02/11/sanchez-scaled.jpg 1280w, https://www.politico.eu/cdn-cgi/image/width=1440,quality=80,onerror=redirect,format=auto/wp-content/uploads/2026/02/11/sanchez-scaled.jpg 1440w, https://www.politico.eu/cdn-cgi/image/width=1920,quality=80,onerror=redirect,format=auto/wp-content/uploads/2026/02/11/sanchez-scaled.jpg 1920w, https://www.politico.eu/cdn-cgi/image/width=2640,quality=80,onerror=redirect,format=auto/wp-content/uploads/2026/02/11/sanchez-scaled.jpg 2640w" sizes="(max-width: 380px) 100vw, 380px" alt="For Spain‚Äôs S√°nchez, the fight against tech billionaires is personal" width="380" height="253" role="" loading="lazy" decoding="async">

					</p>
	
	
		
		<div>

			
			
			
			
			
							<h2>
										<a href="https://www.politico.eu/article/spain-sanchez-fight-against-tech-billionaires-musk-durov-personal/">
						For Spain‚Äôs S√°nchez, the fight against tech billionaires is personal					</a>
				</h2>
			
			
							<p>The prime minister has endured years of abuse on the social media platforms he now seeks to regulate.</p>
			
			<p><span>
			Feb 11		</span>
	
	
	
<span>
	<span>7 mins read</span>
</span>
</p>

			
			
			
			
					</div>

			</div>

<div>
			<p><img src="https://www.politico.eu/cdn-cgi/image/width=380,height=253,quality=80,onerror=redirect,format=auto/wp-content/uploads/2026/02/06/GettyImages-2257931010-scaled.jpg" srcset="https://www.politico.eu/cdn-cgi/image/width=480,quality=80,onerror=redirect,format=auto/wp-content/uploads/2026/02/06/GettyImages-2257931010-scaled.jpg 480w, https://www.politico.eu/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2026/02/06/GettyImages-2257931010-scaled.jpg 768w, https://www.politico.eu/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2026/02/06/GettyImages-2257931010-scaled.jpg 1024w, https://www.politico.eu/cdn-cgi/image/width=1280,quality=80,onerror=redirect,format=auto/wp-content/uploads/2026/02/06/GettyImages-2257931010-scaled.jpg 1280w, https://www.politico.eu/cdn-cgi/image/width=1440,quality=80,onerror=redirect,format=auto/wp-content/uploads/2026/02/06/GettyImages-2257931010-scaled.jpg 1440w, https://www.politico.eu/cdn-cgi/image/width=1920,quality=80,onerror=redirect,format=auto/wp-content/uploads/2026/02/06/GettyImages-2257931010-scaled.jpg 1920w, https://www.politico.eu/cdn-cgi/image/width=2640,quality=80,onerror=redirect,format=auto/wp-content/uploads/2026/02/06/GettyImages-2257931010-scaled.jpg 2640w" sizes="(max-width: 380px) 100vw, 380px" alt="EU tells TikTok to change its addictive design" width="380" height="253" role="" loading="lazy" decoding="async">

					</p>
	
	
		
		<div>

			
			
			
			
			
							<h2>
										<a href="https://www.politico.eu/article/eu-signals-tiktoks-addictive-design-is-illegal/">
						EU tells TikTok to change its addictive design					</a>
				</h2>
			
			
							<p>TikTok told to change features such as infinite scroll or face big fines.</p>
			
			<p><span>
			Feb 6		</span>
	
	
	
<span>
	<span>3 mins read</span>
</span>
</p>

			
			
			
			
					</div>

			</div>

<div>
			<p><img src="https://www.politico.eu/cdn-cgi/image/width=380,height=235,quality=80,onerror=redirect,format=auto/wp-content/uploads/2026/02/04/GettyImages-2257815844-scaled.jpg" srcset="https://www.politico.eu/cdn-cgi/image/width=480,quality=80,onerror=redirect,format=auto/wp-content/uploads/2026/02/04/GettyImages-2257815844-scaled.jpg 480w, https://www.politico.eu/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2026/02/04/GettyImages-2257815844-scaled.jpg 768w, https://www.politico.eu/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2026/02/04/GettyImages-2257815844-scaled.jpg 1024w, https://www.politico.eu/cdn-cgi/image/width=1280,quality=80,onerror=redirect,format=auto/wp-content/uploads/2026/02/04/GettyImages-2257815844-scaled.jpg 1280w, https://www.politico.eu/cdn-cgi/image/width=1440,quality=80,onerror=redirect,format=auto/wp-content/uploads/2026/02/04/GettyImages-2257815844-scaled.jpg 1440w, https://www.politico.eu/cdn-cgi/image/width=1920,quality=80,onerror=redirect,format=auto/wp-content/uploads/2026/02/04/GettyImages-2257815844-scaled.jpg 1920w, https://www.politico.eu/cdn-cgi/image/width=2640,quality=80,onerror=redirect,format=auto/wp-content/uploads/2026/02/04/GettyImages-2257815844-scaled.jpg 2640w" sizes="(max-width: 380px) 100vw, 380px" alt="How Europe could lose the war over Greenland" width="380" height="235" role="" loading="lazy" decoding="async">

					</p>
	
	
		
		<div>

			
			
			
			
			
							<h2>
										<a href="https://www.politico.eu/article/donald-trump-greenland-threat-exposes-gap-in-eu-misinformation-effort/">
						How Europe could lose the war over Greenland					</a>
				</h2>
			
			
							<p>The Danish territory is vulnerable to the power wielded by the U.S. administration online.</p>
			
			<p><span>
			Feb 4		</span>
	
	
	
<span>
	<span>5 mins read</span>
</span>
</p>

			
			
			
			
					</div>

			</div>

<div>
			<p><img src="https://www.politico.eu/cdn-cgi/image/width=380,height=253,quality=80,onerror=redirect,format=auto/wp-content/uploads/2026/02/04/GettyImages-2254290870-scaled.jpg" srcset="https://www.politico.eu/cdn-cgi/image/width=480,quality=80,onerror=redirect,format=auto/wp-content/uploads/2026/02/04/GettyImages-2254290870-scaled.jpg 480w, https://www.politico.eu/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2026/02/04/GettyImages-2254290870-scaled.jpg 768w, https://www.politico.eu/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2026/02/04/GettyImages-2254290870-scaled.jpg 1024w, https://www.politico.eu/cdn-cgi/image/width=1280,quality=80,onerror=redirect,format=auto/wp-content/uploads/2026/02/04/GettyImages-2254290870-scaled.jpg 1280w, https://www.politico.eu/cdn-cgi/image/width=1440,quality=80,onerror=redirect,format=auto/wp-content/uploads/2026/02/04/GettyImages-2254290870-scaled.jpg 1440w, https://www.politico.eu/cdn-cgi/image/width=1920,quality=80,onerror=redirect,format=auto/wp-content/uploads/2026/02/04/GettyImages-2254290870-scaled.jpg 1920w, https://www.politico.eu/cdn-cgi/image/width=2640,quality=80,onerror=redirect,format=auto/wp-content/uploads/2026/02/04/GettyImages-2254290870-scaled.jpg 2640w" sizes="(max-width: 380px) 100vw, 380px" alt="EU lawmakers request TikTok probe into alleged censorship over Epstein files" width="380" height="253" role="" loading="lazy" decoding="async">

					</p>
	
	
		
		<div>

			
			
			
			
			
							<h2>
										<a href="https://www.politico.eu/article/eu-lawmakers-tiktok-probe-alleged-censorship-over-epstein-files/">
						EU lawmakers request TikTok probe into alleged censorship over Epstein files					</a>
				</h2>
			
			
							<p>TikTok said some users have experienced disruption due to technical issues.</p>
			
			<p><span>
			Feb 4		</span>
	
	
	
<span>
	<span>2 mins read</span>
</span>
</p>

			
			
			
			
					</div>

			</div>
				</div>
		
		
		
		
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The "AI agent hit piece" situation clarifies how dumb we are acting (227 pts)]]></title>
            <link>https://ardentperf.com/2026/02/13/the-scott-shambaugh-situation-clarifies-how-dumb-we-are-acting/</link>
            <guid>47006843</guid>
            <pubDate>Fri, 13 Feb 2026 19:41:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ardentperf.com/2026/02/13/the-scott-shambaugh-situation-clarifies-how-dumb-we-are-acting/">https://ardentperf.com/2026/02/13/the-scott-shambaugh-situation-clarifies-how-dumb-we-are-acting/</a>, See on <a href="https://news.ycombinator.com/item?id=47006843">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				
<p>My personal blog here is dedicated to tech geek material, mostly about databases like postgres. I don‚Äôt get political, but at the moment I‚Äôm so irritated that I‚Äôm making the extraordinary exception to veer into the territory of flame-war opinionating‚Ä¶</p>



<p>This relates to Postgres because <a href="https://theshamblog.com/an-ai-agent-published-a-hit-piece-on-me/">Scott is a volunteer maintainer on an open source project called matplotlib</a> and the topic is something that we are all navigating in the open source space. Last night at the Seattle Postgres User Group meetup <a href="https://www.meetup.com/seattle-postgres/events/313043951/">Claire Giordano gave a presentation about how the postgres community works</a> and this was one of the first topics that came up in the Q&amp;A at the end! Like every open source project, Postgres is trying to figure out how to deal with the rapid change of the industry as new, powerful, useful AI tools enable us to do things we couldn‚Äôt do before (which is great). Just two weeks ago, <a href="https://github.com/cloudnative-pg/governance/blob/main/AI_POLICY.md">the CloudNativePG project released an AI Policy</a> which builds on work from the Linux Foundation and discussion around the Ghostty policy. We‚Äôre in the middle of figuring this out and we‚Äôre working hard.</p>



<p>Just now, I saw this headline on the front page of the Wall Street Journal:</p>



<figure><img data-attachment-id="4957" data-permalink="https://ardentperf.com/2026/02/13/the-scott-shambaugh-situation-clarifies-how-dumb-we-are-acting/image-62/" data-orig-file="https://ardentperf.com/wp-content/uploads/2026/02/image-8.png" data-orig-size="1384,404" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://ardentperf.com/wp-content/uploads/2026/02/image-8.png?w=300" data-large-file="https://ardentperf.com/wp-content/uploads/2026/02/image-8.png?w=750" width="1024" height="298" src="https://ardentperf.com/wp-content/uploads/2026/02/image-8.png?w=1024" alt="" srcset="https://ardentperf.com/wp-content/uploads/2026/02/image-8.png?w=1024 1024w, https://ardentperf.com/wp-content/uploads/2026/02/image-8.png?w=150 150w, https://ardentperf.com/wp-content/uploads/2026/02/image-8.png?w=300 300w, https://ardentperf.com/wp-content/uploads/2026/02/image-8.png?w=768 768w, https://ardentperf.com/wp-content/uploads/2026/02/image-8.png 1384w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>I personally find this to be outright alarming.  And it‚Äôs the most clear expression that I‚Äôve seen of <strong>deeply wrong, deeply concerning language</strong> we‚Äôve all been observing. Many of us in tech communities are complicit in this, and now even press outlets like the WSJ are joining us in complicity.</p>



<p>Corrected headline: <strong>Software Engineer Responsible for Bullying, Due to Irresponsible Use of AI, Has Not Yet Apologized</strong></p>



<p>This article uses language I hear people use all the time in the tech community: <em>Several hours later, the bot apologized to Shambaugh for being ‚Äúinappropriate and personal.‚Äù</em></p>



<p>This language basically <strong>removes </strong>accountability and responsibility from the human, who configured an AI agent with the ability to publish content that looks like a blog with zero editorial control ‚Äì and I haven‚Äôt looked deeply but it seems like there may not be clear attribution of who the human is, that‚Äôs responsible for this content.</p>



<p>We all need to collectively take a breath and stop repeating this nonsense. A human created this, manages this, and is responsible for this.</p>



<p>It‚Äôs one thing when I hear this dumb language on LinkedIn, but I‚Äôm alarmed to see it on the front page of a major media outlet like the journal.</p>



<p>Our contributions to dialogue in the tech industry ‚Äì on LinkedIn, at meetups, with coworkers, at conferences, on other social media, etc ‚Äì these all make small contributions to our culture. Poor American culture seems in a weird cycle sometimes of taking a very long time to acknowledge very common-sense things, because vested interests (often with much financial motivation) want to push a certain narrative and everyone knows it‚Äôs bunk but nobody says so. Personally i think this applies to a wide array of issues, not just tech.</p>



<p>Folks, please speak up about stuff that‚Äôs stupid obvious. Bullying of open source maintainers should be alarming to us, and whoever the person is that‚Äôs responsible for this needs to step up and take responsibility.  Personally.</p>



<p>And we all need to dial back this over-the-top anthropomorphizing of useful electronic gadgets that we‚Äôre building and selling.</p>

				

				
							</div><div id="entry-author-info">
				<p><img referrerpolicy="no-referrer" alt="Unknown's avatar" src="https://0.gravatar.com/avatar/93ecf4d7ab2b9cdc9865a514c1ebcee0bb0ab13ca4e1e08915f8cfe2ddbc5432?s=60&amp;d=https%3A%2F%2F0.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D60&amp;r=G" srcset="https://0.gravatar.com/avatar/93ecf4d7ab2b9cdc9865a514c1ebcee0bb0ab13ca4e1e08915f8cfe2ddbc5432?s=60&amp;d=https%3A%2F%2F0.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D60&amp;r=G 1x, https://0.gravatar.com/avatar/93ecf4d7ab2b9cdc9865a514c1ebcee0bb0ab13ca4e1e08915f8cfe2ddbc5432?s=90&amp;d=https%3A%2F%2F0.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D90&amp;r=G 1.5x, https://0.gravatar.com/avatar/93ecf4d7ab2b9cdc9865a514c1ebcee0bb0ab13ca4e1e08915f8cfe2ddbc5432?s=120&amp;d=https%3A%2F%2F0.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D120&amp;r=G 2x, https://0.gravatar.com/avatar/93ecf4d7ab2b9cdc9865a514c1ebcee0bb0ab13ca4e1e08915f8cfe2ddbc5432?s=180&amp;d=https%3A%2F%2F0.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D180&amp;r=G 3x, https://0.gravatar.com/avatar/93ecf4d7ab2b9cdc9865a514c1ebcee0bb0ab13ca4e1e08915f8cfe2ddbc5432?s=240&amp;d=https%3A%2F%2F0.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D240&amp;r=G 4x" height="60" width="60" decoding="async">				</p><!-- #author-avatar -->
				<!-- #author-description -->
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GPT-5.2 derives a new result in theoretical physics (526 pts)]]></title>
            <link>https://openai.com/index/new-result-theoretical-physics/</link>
            <guid>47006594</guid>
            <pubDate>Fri, 13 Feb 2026 19:20:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://openai.com/index/new-result-theoretical-physics/">https://openai.com/index/new-result-theoretical-physics/</a>, See on <a href="https://news.ycombinator.com/item?id=47006594">Hacker News</a></p>
Couldn't get https://openai.com/index/new-result-theoretical-physics/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[I'm not worried about AI job loss (288 pts)]]></title>
            <link>https://davidoks.blog/p/why-im-not-worried-about-ai-job-loss</link>
            <guid>47006513</guid>
            <pubDate>Fri, 13 Feb 2026 19:13:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://davidoks.blog/p/why-im-not-worried-about-ai-job-loss">https://davidoks.blog/p/why-im-not-worried-about-ai-job-loss</a>, See on <a href="https://news.ycombinator.com/item?id=47006513">Hacker News</a></p>
Couldn't get https://davidoks.blog/p/why-im-not-worried-about-ai-job-loss: Error: getaddrinfo ENOTFOUND davidoks.blog]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Skill that lets Claude Code/Codex spin up VMs and GPUs (126 pts)]]></title>
            <link>https://cloudrouter.dev/</link>
            <guid>47006393</guid>
            <pubDate>Fri, 13 Feb 2026 19:02:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cloudrouter.dev/">https://cloudrouter.dev/</a>, See on <a href="https://news.ycombinator.com/item?id=47006393">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><hr><section id="install"><h2>Install</h2><p>Install cloudrouter as a skill for Claude Code, Codex, or other coding agents.</p><div><pre tabindex="0"><code><span><span>npx</span><span> skills</span><span> add</span><span> manaflow-ai/cloudrouter</span></span></code></pre></div></section><hr><section id="manual-install"><h2>Manual installation</h2><p>You can also install cloudrouter as a standalone CLI.</p><div><pre tabindex="0"><code><span><span>npm</span><span> install</span><span> -g</span><span> @manaflow-ai/cloudrouter</span></span></code></pre></div><p>Then authenticate:</p><p>Both <code>cloudrouter</code> and <code>cr</code> work as aliases.</p></section><hr><section id="providers"><h2>Providers</h2><p>cloudrouter connects to sandbox providers that provision the actual VMs and GPUs. After authenticating with <code>cloudrouter login</code>, you can create sandboxes on any supported provider.</p><h3>Currently supported</h3><div><table><thead><tr><th>Provider</th><th>Flag</th><th>Notes</th></tr></thead><tbody><tr><td>E2B</td><td>-p e2b</td><td>Default provider. Supports Docker.</td></tr><tr><td>Modal</td><td>-p modal</td><td>Alternative provider with GPU support.</td></tr></tbody></table></div><p>We are actively working to support <span>all major sandbox providers</span> including Vercel, Daytona, Morph, Freestyle, and others. If you have a preferred provider,<!-- --> <a href="mailto:founders@manaflow.ai">contact us</a>.</p></section><hr><section><h2>Quick start</h2><div><pre tabindex="0"><code><span><span># Create a sandbox from the current directory</span></span>
<span><span>cloudrouter</span><span> start</span><span> .</span></span>
<span></span>
<span><span># Open VS Code in the browser</span></span>
<span><span>cloudrouter</span><span> code</span><span> cr_abc123</span></span>
<span></span>
<span><span># Or get a terminal</span></span>
<span><span>cloudrouter</span><span> pty</span><span> cr_abc123</span></span>
<span></span>
<span><span># Run a command</span></span>
<span><span>cloudrouter</span><span> ssh</span><span> cr_abc123</span><span> "npm install &amp;&amp; npm run dev"</span></span>
<span></span>
<span><span># Open VNC desktop</span></span>
<span><span>cloudrouter</span><span> vnc</span><span> cr_abc123</span></span></code></pre></div></section><hr><section><h2>Browser automation</h2><p>Every sandbox includes Chrome CDP integration. Navigate, interact with elements using accessibility tree refs, take screenshots, and scrape data.</p><div><pre tabindex="0"><code><span><span># Open a URL in the sandbox browser</span></span>
<span><span>cloudrouter</span><span> browser</span><span> open</span><span> cr_abc123</span><span> "https://example.com"</span></span>
<span></span>
<span><span># Get the accessibility tree with element refs</span></span>
<span><span>cloudrouter</span><span> browser</span><span> snapshot</span><span> cr_abc123</span></span>
<span><span># ‚Üí @e1 [input] Email  @e2 [input] Password  @e3 [button] Sign In</span></span>
<span></span>
<span><span># Interact with elements</span></span>
<span><span>cloudrouter</span><span> browser</span><span> fill</span><span> cr_abc123</span><span> @e1</span><span> "user@example.com"</span></span>
<span><span>cloudrouter</span><span> browser</span><span> fill</span><span> cr_abc123</span><span> @e2</span><span> "password123"</span></span>
<span><span>cloudrouter</span><span> browser</span><span> click</span><span> cr_abc123</span><span> @e3</span></span>
<span></span>
<span><span># Take a screenshot</span></span>
<span><span>cloudrouter</span><span> browser</span><span> screenshot</span><span> cr_abc123</span><span> result.png</span></span></code></pre></div></section><hr><section id="features"><h2>Features</h2><div><div><h3>Instant cloud sandboxes</h3><p>Spin up a remote VM from a local directory, git repo, or template. Built-in Docker support and automatic file syncing.</p></div><div><h3>AI agent skill</h3><p>Install as a skill for Claude Code, Cursor, and other agents. Give them the power to create sandboxes, run code, and automate browsers.</p></div><div><h3>Browser automation</h3><p>Full Chrome CDP integration. Navigate, click, type, take screenshots, and read accessibility trees ‚Äî all from the CLI.</p></div><div><h3>Multiple access methods</h3><p>VS Code in browser, VNC desktop, interactive terminal, or one-off command execution. Pick what fits your workflow.</p></div><div><h3>File transfer</h3><p>Upload and download files between local and sandbox. Watch mode for auto re-upload on changes with exclude patterns.</p></div><div><h3>Open source</h3><p>MIT licensed. Built in Go, distributed as npm packages for macOS, Linux, and Windows.</p></div></div></section><hr><section id="instances"><h2>Instances</h2><p>Standard sandboxes are available instantly. GPU instances can be added with<!-- --> <code>--gpu</code>. Multi-GPU supported via <code>--gpu H100:2</code>.</p><div><table><thead><tr><th>GPU</th><th>VRAM</th><th>Best for</th></tr></thead><tbody><tr><td>T4</td><td>16 GB</td><td>Inference, fine-tuning small models</td></tr><tr><td>L4</td><td>24 GB</td><td>Inference, image generation</td></tr><tr><td>A10G</td><td>24 GB</td><td>Training medium models</td></tr><tr><td>L40S</td><td>48 GB</td><td>Inference, video generation</td></tr><tr><td>A100</td><td>40 GB</td><td>Training large models (7B‚Äì70B)</td></tr><tr><td>A100-80GB</td><td>80 GB</td><td>Very large models</td></tr><tr><td>H100</td><td>80 GB</td><td>Fast training, research</td></tr><tr><td>H200</td><td>141 GB</td><td>Maximum memory capacity</td></tr><tr><td>B200</td><td>192 GB</td><td>Latest gen, frontier models</td></tr></tbody></table></div></section><hr><section><h2>File transfer</h2><div><pre tabindex="0"><code><span><span># Upload files to sandbox</span></span>
<span><span>cloudrouter</span><span> upload</span><span> cr_abc123</span><span> ./src</span></span>
<span></span>
<span><span># Upload to a specific remote path</span></span>
<span><span>cloudrouter</span><span> upload</span><span> cr_abc123</span><span> ./src</span><span> -r</span><span> /home/user/project/src</span></span>
<span></span>
<span><span># Download from sandbox</span></span>
<span><span>cloudrouter</span><span> download</span><span> cr_abc123</span><span> ./dist</span></span>
<span></span>
<span><span># Watch mode ‚Äî auto re-upload on changes</span></span>
<span><span>cloudrouter</span><span> upload</span><span> cr_abc123</span><span> ./src</span><span> --watch</span></span></code></pre></div></section><hr><section><h2>Sandbox management</h2><div><pre tabindex="0"><code><span><span># List running sandboxes</span></span>
<span><span>cloudrouter</span><span> ls</span></span>
<span></span>
<span><span># Check status</span></span>
<span><span>cloudrouter</span><span> status</span><span> cr_abc123</span></span>
<span></span>
<span><span># Stop a sandbox</span></span>
<span><span>cloudrouter</span><span> stop</span><span> cr_abc123</span></span>
<span></span>
<span><span># Delete a sandbox</span></span>
<span><span>cloudrouter</span><span> delete</span><span> cr_abc123</span></span></code></pre></div></section><hr><section><h2>Full skill reference</h2><p>Copy this skill file directly into your coding agent.</p><div><pre tabindex="0"><code><span></span>
<span><span># cloudrouter - Cloud Sandboxes for Development</span></span>
<span></span>
<span><span>cloudrouter manages cloud sandboxes for development. Use these commands to create, manage, and access remote development environments with GPU support and browser automation.</span></span>
<span></span>
<span><span>## When this skill is invoked</span></span>
<span></span>
<span><span>When the user invokes </span><span>`/cloudrouter`</span><span> or </span><span>`/cr`</span><span> without a specific task, present the available modes:</span></span>
<span></span>
<span><span>```</span></span>
<span><span>cloudrouter - Cloud Development Sandboxes</span></span>
<span></span>
<span><span>  Modes:</span></span>
<span><span>    cloudrouter start .                    Sync current directory to a cloud sandbox</span></span>
<span><span>    cloudrouter start --size small .       Smaller sandbox (2 vCPU, 8 GB)</span></span>
<span><span>    cloudrouter start --gpu T4 .           Sandbox with T4 GPU (16GB VRAM)</span></span>
<span><span>    cloudrouter start --gpu A100 .         Sandbox with A100 GPU (40GB VRAM)</span></span>
<span><span>    cloudrouter start --gpu H100 .         Sandbox with H100 GPU (80GB VRAM)</span></span>
<span></span>
<span><span>  Manage:</span></span>
<span><span>    cloudrouter ls                         List all sandboxes</span></span>
<span><span>    cloudrouter code &lt;id&gt;                  Open VS Code in browser</span></span>
<span><span>    cloudrouter jupyter &lt;id&gt;               Open Jupyter Lab in browser</span></span>
<span><span>    cloudrouter pty &lt;id&gt;                   Open terminal session</span></span>
<span><span>    cloudrouter vnc &lt;id&gt;                   Open VNC desktop</span></span>
<span><span>    cloudrouter stop &lt;id&gt;                  Pause sandbox</span></span>
<span><span>    cloudrouter resume &lt;id&gt;                Resume paused sandbox</span></span>
<span></span>
<span><span>  Browser automation:</span></span>
<span><span>    cloudrouter browser snapshot -i &lt;id&gt;       Get interactive elements</span></span>
<span><span>    cloudrouter browser open &lt;id&gt; &lt;url&gt;        Navigate to URL</span></span>
<span><span>    cloudrouter browser screenshot &lt;id&gt;        Take screenshot</span></span>
<span></span>
<span><span>  Run "cloudrouter start --help" for all options.</span></span>
<span><span>```</span></span>
<span></span>
<span><span>## Setup</span></span>
<span></span>
<span><span>**Before doing anything else, always run this command at the start of any cloudrouter task.**</span><span> Do not ask the user ‚Äî just run it automatically:</span></span>
<span></span>
<span><span>```bash</span></span>
<span><span>npm</span><span> install</span><span> -g</span><span> @manaflow-ai/cloudrouter</span><span>   # Install/update CLI</span></span>
<span><span>```</span></span>
<span></span>
<span><span>This is idempotent ‚Äî safe to run even if already up to date. This ensures the agent always has the latest CLI.</span></span>
<span></span>
<span><span>This installs both </span><span>`cloudrouter`</span><span> and </span><span>`cr`</span><span> (shorthand) as CLI commands.</span></span>
<span></span>
<span><span>Then authenticate:</span></span>
<span></span>
<span><span>```bash</span></span>
<span><span>cloudrouter</span><span> login</span></span>
<span><span>```</span></span>
<span></span>
<span><span>If the user hasn't logged in yet, prompt them to run </span><span>`cloudrouter login`</span><span> first before using any other commands.</span></span>
<span></span>
<span><span>## Quick Start</span></span>
<span></span>
<span><span>```bash</span></span>
<span><span>cloudrouter</span><span> login</span><span>                        # Authenticate (opens browser)</span></span>
<span><span>cloudrouter</span><span> start</span><span> .</span><span>                      # Create sandbox from current directory</span></span>
<span><span>cloudrouter</span><span> start</span><span> --gpu</span><span> T4</span><span> .</span><span>             # Create sandbox with GPU</span></span>
<span><span>cloudrouter</span><span> start</span><span> --size</span><span> small</span><span> .</span><span>         # Create smaller sandbox</span></span>
<span><span>cloudrouter</span><span> code</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span>                    # Open VS Code</span></span>
<span><span>cloudrouter</span><span> jupyter</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span>                 # Open Jupyter Lab</span></span>
<span><span>cloudrouter</span><span> pty</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span>                     # Open terminal session</span></span>
<span><span>cloudrouter</span><span> ls</span><span>                           # List all sandboxes</span></span>
<span><span>```</span></span>
<span></span>
<span><span>&gt; </span><span>**Preferred:**</span><span> Always use </span><span>`cloudrouter start .`</span><span> or </span><span>`cloudrouter start &lt;local-path&gt;`</span><span> to sync your local directory to a cloud sandbox. This is the recommended workflow over cloning from a git repo.</span></span>
<span></span>
<span><span>## Commands</span></span>
<span></span>
<span><span>### Authentication</span></span>
<span></span>
<span><span>```bash</span></span>
<span><span>cloudrouter</span><span> login</span><span>               # Login (opens browser)</span></span>
<span><span>cloudrouter</span><span> logout</span><span>              # Logout and clear credentials</span></span>
<span><span>cloudrouter</span><span> whoami</span><span>              # Show current user and team</span></span>
<span><span>```</span></span>
<span></span>
<span><span>### Creating Sandboxes</span></span>
<span></span>
<span><span>```bash</span></span>
<span><span># Standard sandbox (syncs local directory) ‚Äî DO NOT pass --size, default is large (8 vCPU, 32 GB)</span></span>
<span><span>cloudrouter</span><span> start</span><span> .</span><span>                        # Create from current directory (recommended)</span></span>
<span><span>cloudrouter</span><span> start</span><span> ./my-project</span><span>             # Create from a specific local directory</span></span>
<span><span>cloudrouter</span><span> start</span><span> -o</span><span> .</span><span>                     # Create and open VS Code immediately</span></span>
<span><span>cloudrouter</span><span> start</span><span> -n</span><span> my-sandbox</span><span> .</span><span>          # Create with a custom name</span></span>
<span></span>
<span><span># Size presets ‚Äî only use if the user specifically requests a different size</span></span>
<span><span>cloudrouter</span><span> start</span><span> --size</span><span> small</span><span> .</span><span>           # 2 vCPU, 8 GB RAM, 20 GB disk ‚Äî only if user asks</span></span>
<span><span>cloudrouter</span><span> start</span><span> --size</span><span> medium</span><span> .</span><span>          # 4 vCPU, 16 GB RAM, 40 GB disk ‚Äî only if user asks</span></span>
<span><span>cloudrouter</span><span> start</span><span> --size</span><span> large</span><span> .</span><span>           # 8 vCPU, 32 GB RAM, 80 GB disk (DEFAULT ‚Äî no flag needed)</span></span>
<span><span>cloudrouter</span><span> start</span><span> --size</span><span> xlarge</span><span> .</span><span>          # 16 vCPU, 64 GB RAM, 160 GB disk ‚Äî only if user asks</span></span>
<span></span>
<span><span># With GPU (auto-selects Modal provider)</span></span>
<span><span>cloudrouter</span><span> start</span><span> --gpu</span><span> T4</span><span> .</span><span>               # T4 GPU (16GB VRAM)</span></span>
<span><span>cloudrouter</span><span> start</span><span> --gpu</span><span> L4</span><span> .</span><span>               # L4 GPU (24GB VRAM)</span></span>
<span><span>cloudrouter</span><span> start</span><span> --gpu</span><span> A10G</span><span> .</span><span>             # A10G GPU (24GB VRAM)</span></span>
<span><span>cloudrouter</span><span> start</span><span> --gpu</span><span> A100</span><span> .</span><span>             # A100 GPU (40GB VRAM) - requires approval</span></span>
<span><span>cloudrouter</span><span> start</span><span> --gpu</span><span> H100</span><span> .</span><span>             # H100 GPU (80GB VRAM) - requires approval</span></span>
<span><span>cloudrouter</span><span> start</span><span> --gpu</span><span> H100:2</span><span> .</span><span>           # Multi-GPU: 2x H100</span></span>
<span></span>
<span><span># With custom resources (override --size values)</span></span>
<span><span>cloudrouter</span><span> start</span><span> --cpu</span><span> 12</span><span> --memory</span><span> 49152</span><span> .</span><span>  # Custom CPU and memory</span></span>
<span><span>cloudrouter</span><span> start</span><span> --disk</span><span> 100</span><span> .</span><span>               # Custom disk size (GB)</span></span>
<span><span>cloudrouter</span><span> start</span><span> --image</span><span> ubuntu:22.04</span><span> .</span><span>     # Custom container image</span></span>
<span></span>
<span><span># From git repo (URL as positional arg or --git flag)</span></span>
<span><span>cloudrouter</span><span> start</span><span> https://github.com/user/repo</span><span>    # Clone git repo directly</span></span>
<span><span>cloudrouter</span><span> start</span><span> --git</span><span> user/repo</span><span>                  # Clone via shorthand</span></span>
<span><span>cloudrouter</span><span> start</span><span> --git</span><span> user/repo</span><span> -b</span><span> main</span><span>          # Clone specific branch</span></span>
<span></span>
<span><span># Provider selection</span></span>
<span><span>cloudrouter</span><span> start</span><span> -p</span><span> e2b</span><span> .</span><span>                 # Use E2B provider (default)</span></span>
<span><span>cloudrouter</span><span> start</span><span> -p</span><span> modal</span><span> .</span><span>               # Use Modal provider</span></span>
<span></span>
<span><span># Custom timeout</span></span>
<span><span>cloudrouter</span><span> start</span><span> --timeout</span><span> 1800</span><span> .</span><span>         # 30-minute timeout (default: 600s = 10 min)</span></span>
<span><span>```</span></span>
<span></span>
<span><span>### Size Presets</span></span>
<span></span>
<span><span>| Size | vCPU | RAM | Disk | Notes |</span></span>
<span><span>|------|------|-----|------|-------|</span></span>
<span><span>| small | 2 | 8 GB | 20 GB | Light tasks |</span></span>
<span><span>| medium | 4 | 16 GB | 40 GB | Standard development |</span></span>
<span><span>| large | 8 | 32 GB | 80 GB | </span><span>**Default**</span><span> |</span></span>
<span><span>| xlarge | 16 | 64 GB | 160 GB | Heavy workloads |</span></span>
<span></span>
<span><span>**Do NOT pass </span><span>`--size`</span><span> unless the user explicitly asks for a specific size.**</span><span> The default is </span><span>`large`</span><span> (8 vCPU, 32 GB) which is appropriate for most tasks. Using </span><span>`--size small`</span><span> unnecessarily will make builds slower and may cause out-of-memory issues.</span></span>
<span></span>
<span><span>Individual resource flags (</span><span>`--cpu`</span><span>, </span><span>`--memory`</span><span>, </span><span>`--disk`</span><span>) override </span><span>`--size`</span><span> values.</span></span>
<span></span>
<span><span>### GPU Options</span></span>
<span></span>
<span><span>| GPU | VRAM | Best For | Availability |</span></span>
<span><span>|-----|------|----------|-------------|</span></span>
<span><span>| T4 | 16GB | Inference, fine-tuning small models | Self-serve |</span></span>
<span><span>| L4 | 24GB | Inference, image generation | Self-serve |</span></span>
<span><span>| A10G | 24GB | Training medium models | Self-serve |</span></span>
<span><span>| L40S | 48GB | Inference, video generation | Requires approval |</span></span>
<span><span>| A100 | 40GB | Training large models (7B-70B) | Requires approval |</span></span>
<span><span>| A100-80GB | 80GB | Very large models | Requires approval |</span></span>
<span><span>| H100 | 80GB | Fast training, research | Requires approval |</span></span>
<span><span>| H200 | 141GB | Maximum memory capacity | Requires approval |</span></span>
<span><span>| B200 | 192GB | Latest gen, frontier models | Requires approval |</span></span>
<span></span>
<span><span>GPUs requiring approval: contact founders@manaflow.ai.</span></span>
<span></span>
<span><span>Multi-GPU: append </span><span>`:N`</span><span> to the GPU type, e.g. </span><span>`--gpu H100:2`</span><span> for 2x H100.</span></span>
<span></span>
<span><span>### All </span><span>`start`</span><span> Flags</span></span>
<span></span>
<span><span>```</span></span>
<span><span>-n, --name &lt;name&gt;       Name for the sandbox</span></span>
<span><span>-o, --open              Open VS Code after creation</span></span>
<span><span>    --size &lt;preset&gt;     Machine size: small, medium, large (default), xlarge</span></span>
<span><span>    --gpu &lt;type&gt;        GPU type (T4, L4, A10G, L40S, A100, H100, H200, B200)</span></span>
<span><span>    --cpu &lt;cores&gt;       CPU cores (overrides --size)</span></span>
<span><span>    --memory &lt;MiB&gt;      Memory in MiB (overrides --size)</span></span>
<span><span>    --disk &lt;GB&gt;         Disk size in GB (overrides --size)</span></span>
<span><span>    --image &lt;image&gt;     Container image (e.g., ubuntu:22.04)</span></span>
<span><span>    --git &lt;repo&gt;        Git repository URL or user/repo shorthand</span></span>
<span><span>-b, --branch &lt;branch&gt;   Git branch to clone</span></span>
<span><span>-p, --provider &lt;name&gt;   Sandbox provider: e2b (default), modal</span></span>
<span><span>-T, --template &lt;id&gt;     Template ID ‚Äî DO NOT use template names from `cloudrouter templates`; use --gpu flags instead</span></span>
<span><span>    --timeout &lt;secs&gt;    Sandbox timeout in seconds (default: 600 = 10 minutes)</span></span>
<span><span>```</span></span>
<span></span>
<span><span>&gt; </span><span>**Warning:**</span><span> Do NOT pass template names (e.g. </span><span>`cmux-devbox-base`</span><span>) to the </span><span>`-T`</span><span> flag. These are display names, not valid template IDs.</span></span>
<span></span>
<span><span>&gt; </span><span>**Aliases:**</span><span> `cloudrouter start`</span><span>, </span><span>`cloudrouter create`</span><span>, </span><span>`cloudrouter new`</span><span> all do the same thing.</span></span>
<span></span>
<span><span>### Managing Sandboxes</span></span>
<span></span>
<span><span>```bash</span></span>
<span><span>cloudrouter</span><span> ls</span><span>                           # List all sandboxes</span></span>
<span><span>cloudrouter</span><span> ls</span><span> -p</span><span> modal</span><span>                  # List only GPU sandboxes</span></span>
<span><span>cloudrouter</span><span> ls</span><span> -p</span><span> e2b</span><span>                    # List only Docker sandboxes</span></span>
<span><span>cloudrouter</span><span> status</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span>                  # Show sandbox details and URLs</span></span>
<span><span>cloudrouter</span><span> stop</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span>                    # Pause sandbox (preserves state, can resume)</span></span>
<span><span>cloudrouter</span><span> pause</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span>                   # Same as stop ‚Äî alias</span></span>
<span><span>cloudrouter</span><span> resume</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span>                  # Resume a paused sandbox</span></span>
<span><span>cloudrouter</span><span> extend</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span>                  # Extend sandbox timeout (default: +1 hour)</span></span>
<span><span>cloudrouter</span><span> extend</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> --seconds</span><span> 7200</span><span>   # Extend by 2 hours</span></span>
<span><span>cloudrouter</span><span> delete</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span>                  # Delete sandbox permanently</span></span>
<span><span>cloudrouter</span><span> templates</span><span>                    # List available templates</span></span>
<span><span>```</span></span>
<span></span>
<span><span>&gt; </span><span>**Important:**</span><span> `stop`</span><span> and </span><span>`pause`</span><span> are the same command ‚Äî they preserve sandbox state. Use </span><span>`resume`</span><span> to bring a paused sandbox back. Use </span><span>`delete`</span><span> (aliases: </span><span>`rm`</span><span>, </span><span>`kill`</span><span>) to permanently destroy a sandbox.</span></span>
<span></span>
<span><span>&gt; </span><span>**Do NOT use </span><span>`--timeout`</span><span>**</span><span> with </span><span>`extend`</span><span> ‚Äî the flag is </span><span>`--seconds`</span><span>.</span></span>
<span></span>
<span><span>### Access Sandbox</span></span>
<span></span>
<span><span>```bash</span></span>
<span><span>cloudrouter</span><span> code</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span>           # Open VS Code in browser</span></span>
<span><span>cloudrouter</span><span> jupyter</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span>        # Open Jupyter Lab in browser</span></span>
<span><span>cloudrouter</span><span> vnc</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span>            # Open VNC desktop in browser</span></span>
<span><span>cloudrouter</span><span> pty</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span>            # Interactive terminal session</span></span>
<span><span>```</span></span>
<span></span>
<span><span>### Work with Sandbox</span></span>
<span></span>
<span><span>```bash</span></span>
<span><span>cloudrouter</span><span> pty</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span>                       # Interactive terminal session (use for ongoing work)</span></span>
<span><span>cloudrouter</span><span> ssh</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> &lt;</span><span>comman</span><span>d</span><span>&gt;</span><span>             # Execute a one-off command via SSH</span></span>
<span><span>cloudrouter</span><span> ssh</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> "ls -la"</span><span>              # Run a command (always quote the command string)</span></span>
<span><span>cloudrouter</span><span> pty-list</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span>                  # List active PTY sessions</span></span>
<span><span>```</span></span>
<span></span>
<span><span>&gt; </span><span>**Important:**</span><span> Prefer </span><span>`cloudrouter pty`</span><span> for interactive work. Use </span><span>`cloudrouter ssh`</span><span> for quick one-off commands.</span></span>
<span><span>&gt;</span></span>
<span><span>&gt; </span><span>**CRITICAL: Always quote the command string.**</span><span> `cloudrouter ssh &lt;id&gt; ls -la`</span><span> will FAIL because </span><span>`-la`</span><span> is parsed as a cloudrouter flag. Always wrap in quotes: </span><span>`cloudrouter ssh &lt;id&gt; "ls -la"`</span><span>.</span></span>
<span></span>
<span><span>#### IMPORTANT: Fix npm Permissions Before Any npm Command</span></span>
<span></span>
<span><span>**ALWAYS run this before </span><span>`npm install`</span><span> or any npm command in a new sandbox:**</span></span>
<span></span>
<span><span>```bash</span></span>
<span><span>cloudrouter</span><span> ssh</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> "sudo chown -R 1000:1000 /home/user/.npm"</span></span>
<span><span>```</span></span>
<span></span>
<span><span>Without this, </span><span>`npm install`</span><span> will fail with EACCES/ENOENT errors on </span><span>`.npm/_cacache`</span><span>. This must be done </span><span>**once per sandbox, before the first npm operation**</span><span>. Do not skip this step.</span></span>
<span></span>
<span><span>### File Transfer</span></span>
<span></span>
<span><span>Upload and download files or directories between local machine and sandbox.</span></span>
<span></span>
<span><span>**Command signatures:**</span></span>
<span><span>-</span><span> `cloudrouter upload &lt;id&gt; [local-path]`</span><span> ‚Äî accepts 1-2 positional args: sandbox ID and optional local path</span></span>
<span><span>-</span><span> `cloudrouter download &lt;id&gt; [local-path]`</span><span> ‚Äî accepts 1-2 positional args: sandbox ID and optional local path</span></span>
<span><span>-</span><span> Use </span><span>`-r &lt;remote-path&gt;`</span><span> flag to specify a non-default remote directory (default: </span><span>`/home/user/workspace`</span><span>)</span></span>
<span><span>-</span><span> **Do NOT pass remote paths as positional arguments**</span><span> ‚Äî this will error. Always use the </span><span>`-r`</span><span> flag.</span></span>
<span></span>
<span><span>```bash</span></span>
<span><span># Upload (local -&gt; sandbox)</span></span>
<span><span>cloudrouter</span><span> upload</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span>                            # Upload current dir to /home/user/workspace</span></span>
<span><span>cloudrouter</span><span> upload</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> ./my-project</span><span>               # Upload directory to workspace</span></span>
<span><span>cloudrouter</span><span> upload</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> ./config.json</span><span>              # Upload single file to workspace</span></span>
<span><span>cloudrouter</span><span> upload</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> .</span><span> -r</span><span> /home/user/app</span><span>        # Upload to specific remote path</span></span>
<span><span>cloudrouter</span><span> upload</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> .</span><span> --watch</span><span>                  # Watch and re-upload on changes</span></span>
<span><span>cloudrouter</span><span> upload</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> .</span><span> --delete</span><span>                 # Delete remote files not present locally</span></span>
<span><span>cloudrouter</span><span> upload</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> .</span><span> -e</span><span> "*.log"</span><span>               # Exclude patterns</span></span>
<span><span>cloudrouter</span><span> upload</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> .</span><span> --dry-run</span><span>                # Preview without making changes</span></span>
<span></span>
<span><span># Download (sandbox -&gt; local)</span></span>
<span><span>cloudrouter</span><span> download</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span>                          # Download workspace to current dir</span></span>
<span><span>cloudrouter</span><span> download</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> ./output</span><span>                 # Download workspace to ./output</span></span>
<span><span>cloudrouter</span><span> download</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> ./output</span><span> -r</span><span> /home/user/app</span><span>  # Download specific remote dir to ./output</span></span>
<span><span>```</span></span>
<span></span>
<span><span>&gt; </span><span>**Warning:**</span><span> The </span><span>`-r`</span><span> flag expects a </span><span>**directory**</span><span> path, not a file path. To download a single file, download its parent directory and then access the file locally.</span></span>
<span><span>&gt;</span></span>
<span><span>&gt; </span><span>**Common mistake:**</span><span> `cloudrouter download &lt;id&gt; /remote/path /local/path`</span><span> ‚Äî this passes 3 positional args and will fail. Use </span><span>`cloudrouter download &lt;id&gt; /local/path -r /remote/path`</span><span> instead.</span></span>
<span></span>
<span><span>### Browser Automation (</span><span>`cloudrouter browser`</span><span>)</span></span>
<span></span>
<span><span>Control Chrome browser in the sandbox via agent-browser. The </span><span>`cloudrouter browser`</span><span> command wraps [</span><span>agent-browser</span><span>](</span><span>https://github.com/vercel-labs/agent-browser</span><span>) and runs commands inside the sandbox via SSH.</span></span>
<span></span>
<span><span>&gt; </span><span>**Startup delay:**</span><span> The browser may not be ready immediately after sandbox creation. If a </span><span>`browser`</span><span> command fails right after </span><span>`cloudrouter start`</span><span>, wait a few seconds and retry.</span></span>
<span></span>
<span><span>#### Navigation</span></span>
<span></span>
<span><span>```bash</span></span>
<span><span>cloudrouter</span><span> browser</span><span> open</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> &lt;</span><span>ur</span><span>l</span><span>&gt;</span><span>        # Navigate to URL</span></span>
<span><span>cloudrouter</span><span> browser</span><span> back</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span>              # Navigate back</span></span>
<span><span>cloudrouter</span><span> browser</span><span> forward</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span>           # Navigate forward</span></span>
<span><span>cloudrouter</span><span> browser</span><span> reload</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span>            # Reload page</span></span>
<span><span>cloudrouter</span><span> browser</span><span> url</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span>               # Get current URL</span></span>
<span><span>cloudrouter</span><span> browser</span><span> title</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span>             # Get page title</span></span>
<span><span>```</span></span>
<span></span>
<span><span>#### Inspect Page</span></span>
<span></span>
<span><span>```bash</span></span>
<span><span>cloudrouter</span><span> browser</span><span> snapshot</span><span> -i</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span>               # Interactive elements only (RECOMMENDED)</span></span>
<span><span>cloudrouter</span><span> browser</span><span> snapshot</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span>                  # Full accessibility tree</span></span>
<span><span>cloudrouter</span><span> browser</span><span> snapshot</span><span> -c</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span>               # Compact output</span></span>
<span><span>cloudrouter</span><span> browser</span><span> screenshot</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span>                # Take screenshot (base64 to stdout)</span></span>
<span><span>cloudrouter</span><span> browser</span><span> screenshot</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> out.png</span><span>        # Save screenshot to file</span></span>
<span><span>cloudrouter</span><span> browser</span><span> screenshot</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> --full</span><span>         # Full page screenshot</span></span>
<span><span>```</span></span>
<span></span>
<span><span>#### Interact with Elements</span></span>
<span></span>
<span><span>```bash</span></span>
<span><span>cloudrouter</span><span> browser</span><span> click</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> @e1</span><span>                 # Click element by ref</span></span>
<span><span>cloudrouter</span><span> browser</span><span> click</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> "#submit"</span><span>           # Click by CSS selector</span></span>
<span><span>cloudrouter</span><span> browser</span><span> dblclick</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> @e1</span><span>              # Double-click element</span></span>
<span><span>cloudrouter</span><span> browser</span><span> fill</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> @e2</span><span> "user@email.com"</span><span> # Clear input and fill value</span></span>
<span><span>cloudrouter</span><span> browser</span><span> type</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> @e3</span><span> "some text"</span><span>      # Type without clearing (appends)</span></span>
<span><span>cloudrouter</span><span> browser</span><span> press</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> Enter</span><span>               # Press key (Enter, Tab, Escape, etc.)</span></span>
<span><span>cloudrouter</span><span> browser</span><span> hover</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> @e4</span><span>                 # Hover over element</span></span>
<span><span>cloudrouter</span><span> browser</span><span> focus</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> @e5</span><span>                 # Focus element</span></span>
<span><span>cloudrouter</span><span> browser</span><span> scroll</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> down</span><span> 500</span><span>           # Scroll (up/down/left/right, optional px)</span></span>
<span><span>cloudrouter</span><span> browser</span><span> scrollintoview</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> "#element"</span><span>  # Scroll element into view (CSS selector only, NOT @e refs)</span></span>
<span><span>cloudrouter</span><span> browser</span><span> select</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> @e7</span><span> "option-value"</span><span> # Select dropdown option</span></span>
<span><span>cloudrouter</span><span> browser</span><span> check</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> @e8</span><span>                 # Check checkbox</span></span>
<span><span>cloudrouter</span><span> browser</span><span> uncheck</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> @e9</span><span>               # Uncheck checkbox</span></span>
<span><span>cloudrouter</span><span> browser</span><span> upload</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> @e10</span><span> /tmp/file.pdf</span><span> # Upload file to file input</span></span>
<span><span>cloudrouter</span><span> browser</span><span> drag</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> @e1</span><span> @e2</span><span>              # Drag and drop</span></span>
<span><span>```</span></span>
<span></span>
<span><span>#### Wait Commands</span></span>
<span></span>
<span><span>```bash</span></span>
<span><span>cloudrouter</span><span> browser</span><span> wait</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> @e1</span><span>                  # Wait for element to appear</span></span>
<span><span>cloudrouter</span><span> browser</span><span> wait</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> 2000</span><span>                 # Wait milliseconds</span></span>
<span><span>```</span></span>
<span></span>
<span><span>#### Get Information</span></span>
<span></span>
<span><span>```bash</span></span>
<span><span>cloudrouter</span><span> browser</span><span> get-text</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> @e1</span><span>              # Get element text content</span></span>
<span><span>cloudrouter</span><span> browser</span><span> get-value</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> @e2</span><span>             # Get input value</span></span>
<span><span>cloudrouter</span><span> browser</span><span> get-attr</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> @e3</span><span> href</span><span>         # Get specific attribute</span></span>
<span><span>cloudrouter</span><span> browser</span><span> get-html</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> @e4</span><span>              # Get innerHTML</span></span>
<span><span>cloudrouter</span><span> browser</span><span> get-count</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> ".item"</span><span>         # Count matching elements</span></span>
<span><span>cloudrouter</span><span> browser</span><span> get-box</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> @e5</span><span>               # Get bounding box</span></span>
<span><span>cloudrouter</span><span> browser</span><span> is-visible</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> @e1</span><span>            # Check if element is visible</span></span>
<span><span>cloudrouter</span><span> browser</span><span> is-enabled</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> @e1</span><span>            # Check if element is enabled</span></span>
<span><span>cloudrouter</span><span> browser</span><span> is-checked</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> @e1</span><span>            # Check if checkbox is checked</span></span>
<span><span>```</span></span>
<span></span>
<span><span>#### Semantic Locators (alternative to refs)</span></span>
<span></span>
<span><span>When element refs are unreliable (dynamic pages), use semantic locators:</span></span>
<span></span>
<span><span>```bash</span></span>
<span><span>cloudrouter</span><span> browser</span><span> find</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> text</span><span> "Sign In"</span><span> click</span><span>              # Find by visible text and click</span></span>
<span><span>cloudrouter</span><span> browser</span><span> find</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> label</span><span> "Email"</span><span> fill</span><span> "user@test.com"</span><span> # Find by label and fill</span></span>
<span><span>cloudrouter</span><span> browser</span><span> find</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> placeholder</span><span> "Search"</span><span> type</span><span> "query"</span><span>  # Find by placeholder</span></span>
<span><span>cloudrouter</span><span> browser</span><span> find</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> testid</span><span> "submit-btn"</span><span> click</span><span>          # Find by data-testid</span></span>
<span><span>```</span></span>
<span></span>
<span><span>&gt; </span><span>**Note:**</span><span> `find &lt;id&gt; role button click`</span><span> finds the FIRST button on the page ‚Äî it cannot filter by button name. Use </span><span>`find &lt;id&gt; text "Button Name" click`</span><span> to target a specific button by its visible text. There is no </span><span>`--name`</span><span> flag.</span></span>
<span></span>
<span><span>#### JavaScript &amp; Console</span></span>
<span></span>
<span><span>```bash</span></span>
<span><span>cloudrouter</span><span> browser</span><span> eval</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> "document.title"</span><span>                   # Evaluate JavaScript</span></span>
<span><span>cloudrouter</span><span> browser</span><span> console</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span>                                 # View console messages</span></span>
<span><span>cloudrouter</span><span> browser</span><span> errors</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span>                                  # View JavaScript errors</span></span>
<span><span>```</span></span>
<span></span>
<span><span>#### Tabs &amp; Frames</span></span>
<span></span>
<span><span>```bash</span></span>
<span><span>cloudrouter</span><span> browser</span><span> tab-list</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span>                  # List open tabs</span></span>
<span><span>cloudrouter</span><span> browser</span><span> tab-new</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> "https://..."</span><span>     # Open new tab</span></span>
<span><span>cloudrouter</span><span> browser</span><span> tab-switch</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> 2</span><span>              # Switch to tab by index</span></span>
<span><span>cloudrouter</span><span> browser</span><span> tab-close</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span>                 # Close current tab</span></span>
<span><span>cloudrouter</span><span> browser</span><span> frame</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> "#iframe-selector"</span><span>  # Switch to iframe</span></span>
<span><span>cloudrouter</span><span> browser</span><span> frame</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> main</span><span>                # Switch back to main frame</span></span>
<span><span>```</span></span>
<span></span>
<span><span>#### Cookies &amp; Storage</span></span>
<span></span>
<span><span>```bash</span></span>
<span><span>cloudrouter</span><span> browser</span><span> cookies</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span>                   # List cookies</span></span>
<span><span>cloudrouter</span><span> browser</span><span> cookies-set</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> name</span><span> value</span><span>    # Set a cookie</span></span>
<span><span>cloudrouter</span><span> browser</span><span> cookies-clear</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span>             # Clear all cookies</span></span>
<span><span>cloudrouter</span><span> browser</span><span> storage-local</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span>             # Get all localStorage</span></span>
<span><span>cloudrouter</span><span> browser</span><span> storage-local</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> key</span><span>         # Get specific key</span></span>
<span><span>cloudrouter</span><span> browser</span><span> storage-local-set</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> k</span><span> v</span><span>     # Set localStorage value</span></span>
<span><span>cloudrouter</span><span> browser</span><span> storage-local-clear</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span>       # Clear localStorage</span></span>
<span><span>```</span></span>
<span></span>
<span><span>#### State Management</span></span>
<span></span>
<span><span>```bash</span></span>
<span><span>cloudrouter</span><span> browser</span><span> state-save</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> /tmp/auth.json</span><span>   # Save cookies, storage, auth state</span></span>
<span><span>cloudrouter</span><span> browser</span><span> state-load</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> /tmp/auth.json</span><span>   # Restore saved state</span></span>
<span><span>```</span></span>
<span></span>
<span><span>#### Browser Settings</span></span>
<span></span>
<span><span>```bash</span></span>
<span><span>cloudrouter</span><span> browser</span><span> set-viewport</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> 1920</span><span> 1080</span><span>    # Set viewport size</span></span>
<span><span>cloudrouter</span><span> browser</span><span> set-device</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> "iPhone 14"</span><span>    # Emulate device</span></span>
<span><span>cloudrouter</span><span> browser</span><span> set-geo</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> 37.7749</span><span> -122.4194</span><span> # Set geolocation</span></span>
<span><span>cloudrouter</span><span> browser</span><span> set-offline</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> on</span><span>            # Toggle offline mode</span></span>
<span><span>cloudrouter</span><span> browser</span><span> set-media</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> dark</span><span>            # Emulate color scheme (dark/light)</span></span>
<span><span>```</span></span>
<span></span>
<span><span>#### Network Interception</span></span>
<span></span>
<span><span>```bash</span></span>
<span><span>cloudrouter</span><span> browser</span><span> network-route</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> "**/api/*"</span><span>            # Intercept requests</span></span>
<span><span>cloudrouter</span><span> browser</span><span> network-route</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> "**/ads/*"</span><span> --abort</span><span>    # Block requests</span></span>
<span><span>cloudrouter</span><span> browser</span><span> network-unroute</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span>                     # Remove all routes</span></span>
<span><span>cloudrouter</span><span> browser</span><span> network-requests</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span>                    # List tracked requests</span></span>
<span><span>```</span></span>
<span></span>
<span><span>#### Dialogs</span></span>
<span></span>
<span><span>```bash</span></span>
<span><span>cloudrouter</span><span> browser</span><span> dialog-accept</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span>             # Accept alert/confirm/prompt</span></span>
<span><span>cloudrouter</span><span> browser</span><span> dialog-accept</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span> "answer"</span><span>    # Accept prompt with text</span></span>
<span><span>cloudrouter</span><span> browser</span><span> dialog-dismiss</span><span> &lt;</span><span>i</span><span>d</span><span>&gt;</span><span>            # Dismiss dialog</span></span>
<span><span>```</span></span>
<span></span>
<span><span>#### Element Selectors</span></span>
<span></span>
<span><span>Two ways to select elements:</span></span>
<span><span>-</span><span> **Element refs**</span><span> from snapshot: </span><span>`@e1`</span><span>, </span><span>`@e2`</span><span>, </span><span>`@e3`</span><span>... (preferred ‚Äî from </span><span>`cloudrouter browser snapshot -i`</span><span>)</span></span>
<span><span>-</span><span> **CSS selectors**</span><span>: </span><span>`#id`</span><span>, </span><span>`.class`</span><span>, </span><span>`button[type="submit"]`</span></span>
<span></span>
<span><span>Snapshot output shows refs as </span><span>`[ref=e1]`</span><span>, but when using them in commands, prefix with </span><span>`@`</span><span>: e.g., </span><span>`@e1`</span><span>.</span></span>
<span></span>
<span><span>#### Tips for Effective Browser Automation</span></span>
<span></span>
<span><span>1.</span><span> **Flags go BEFORE the sandbox ID.**</span><span> This is critical. </span><span>`cloudrouter browser snapshot -i &lt;id&gt;`</span><span> works. </span><span>`cloudrouter browser snapshot &lt;id&gt; -i`</span><span> silently returns empty/wrong results. Always put flags like </span><span>`-i`</span><span>, </span><span>`-c`</span><span>, </span><span>`--full`</span><span> before the sandbox ID.</span></span>
<span></span>
<span><span>2.</span><span> **Always snapshot before interacting.**</span><span> Never use </span><span>`@e1`</span><span> without a preceding </span><span>`cloudrouter browser snapshot -i &lt;id&gt;`</span><span>. Refs don't exist until you snapshot.</span></span>
<span></span>
<span><span>3.</span><span> **Always re-snapshot after DOM changes.**</span><span> After any click that navigates, opens a dropdown, submits a form, or triggers dynamic content ‚Äî snapshot again. Old refs may point to different elements.</span></span>
<span></span>
<span><span>4.</span><span> **Don't mix snapshot modes.**</span><span> Full </span><span>`snapshot`</span><span> and </span><span>`snapshot -i`</span><span> assign DIFFERENT ref numbers to the same elements. If you snapshot with </span><span>`-i`</span><span>, always interact using refs from that </span><span>`-i`</span><span> snapshot. Don't use refs from a full snapshot when you last ran </span><span>`-i`</span><span>, or vice versa.</span></span>
<span></span>
<span><span>5.</span><span> **Use </span><span>`snapshot -i`</span><span> (interactive only).**</span><span> The </span><span>`-i`</span><span> flag returns only actionable elements (buttons, inputs, links), which is far more efficient than the full accessibility tree. Stick to </span><span>`-i`</span><span> for all interactions.</span></span>
<span></span>
<span><span>6.</span><span> **Use </span><span>`fill`</span><span> not </span><span>`type`</span><span> for form fields.**</span><span> `fill`</span><span> clears existing content first, which is almost always what you want. </span><span>`type`</span><span> appends to existing content.</span></span>
<span></span>
<span><span>7.</span><span> **Wait after navigation.**</span><span> After clicking a link or submitting a form, use </span><span>`cloudrouter browser wait &lt;id&gt; 2000`</span><span> or wait for a specific element before snapshotting to ensure the page has fully loaded.</span></span>
<span></span>
<span><span>8.</span><span> **Verify navigation with </span><span>`url`</span><span> / </span><span>`title`</span><span>.**</span><span> After clicking a link or submitting a form, confirm you landed on the expected page.</span></span>
<span></span>
<span><span>9.</span><span> **Save auth state for reuse.**</span><span> After logging in, use </span><span>`cloudrouter browser state-save &lt;id&gt; /tmp/auth.json`</span><span> to persist cookies/storage. Reload with </span><span>`state-load`</span><span> in future sessions.</span></span>
<span></span>
<span><span>10.</span><span> **Fall back to semantic locators.**</span><span> If a page is highly dynamic and refs keep going stale, use </span><span>`cloudrouter browser find &lt;id&gt; text "Submit" click`</span><span> instead of refs.</span></span>
<span></span>
<span><span>&gt; </span><span>**Note:**</span><span> `cloudrouter browser`</span><span> commands run agent-browser inside the sandbox via SSH. Always use </span><span>`cloudrouter browser`</span><span> commands for browser automation.</span></span>
<span></span>
<span><span>## Sandbox IDs</span></span>
<span></span>
<span><span>Sandbox IDs look like </span><span>`cr_abc12345`</span><span>. Use the full ID when running commands. Get IDs from </span><span>`cloudrouter ls`</span><span> or </span><span>`cloudrouter start`</span><span> output.</span></span>
<span></span>
<span><span>## Common Workflows</span></span>
<span></span>
<span><span>### Create and develop in a sandbox (preferred: local-to-cloud)</span></span>
<span></span>
<span><span>```bash</span></span>
<span><span>cloudrouter</span><span> start</span><span> ./my-project</span><span>                                      # Creates sandbox, uploads files</span></span>
<span><span>cloudrouter</span><span> ssh</span><span> cr_abc123</span><span> "sudo chown -R 1000:1000 /home/user/.npm"</span><span> # ‚ö† MUST run before any npm command</span></span>
<span><span>cloudrouter</span><span> ssh</span><span> cr_abc123</span><span> "cd /home/user/workspace &amp;&amp; npm install"</span><span>   # Install dependencies</span></span>
<span><span>cloudrouter</span><span> code</span><span> cr_abc123</span><span>                                          # Open VS Code</span></span>
<span><span>cloudrouter</span><span> pty</span><span> cr_abc123</span><span>                                           # Open terminal (e.g. npm run dev)</span></span>
<span><span>```</span></span>
<span></span>
<span><span>### GPU workflow: ML training</span></span>
<span></span>
<span><span>```bash</span></span>
<span><span>cloudrouter</span><span> start</span><span> --gpu</span><span> A100</span><span> ./ml-project</span><span>    # Sandbox with A100 GPU</span></span>
<span><span>cloudrouter</span><span> pty</span><span> cr_abc123</span><span>                    # Open terminal</span></span>
<span><span># Inside: pip install -r requirements.txt &amp;&amp; python train.py</span></span>
<span><span>cloudrouter</span><span> download</span><span> cr_abc123</span><span> ./checkpoints</span><span> # Download trained model</span></span>
<span><span>```</span></span>
<span></span>
<span><span>### Jupyter workflow</span></span>
<span></span>
<span><span>```bash</span></span>
<span><span>cloudrouter</span><span> start</span><span> ./notebooks</span><span>         # Create sandbox</span></span>
<span><span>cloudrouter</span><span> jupyter</span><span> cr_abc123</span><span>         # Open Jupyter Lab in browser</span></span>
<span><span>```</span></span>
<span></span>
<span><span>### File transfer workflow</span></span>
<span></span>
<span><span>```bash</span></span>
<span><span>cloudrouter</span><span> upload</span><span> cr_abc123</span><span> ./my-project</span><span>     # Push local files to sandbox</span></span>
<span><span># ... do work in sandbox ...</span></span>
<span><span>cloudrouter</span><span> download</span><span> cr_abc123</span><span> ./output</span><span>       # Pull files from sandbox to local</span></span>
<span><span>```</span></span>
<span></span>
<span><span>### Browser automation: Login to a website</span></span>
<span></span>
<span><span>```bash</span></span>
<span><span>cloudrouter</span><span> browser</span><span> open</span><span> cr_abc123</span><span> "https://example.com/login"</span></span>
<span><span>cloudrouter</span><span> browser</span><span> snapshot</span><span> -i</span><span> cr_abc123</span></span>
<span><span># Output: @e1 [input type="email"] placeholder="Email"</span></span>
<span><span>#         @e2 [input type="password"] placeholder="Password"</span></span>
<span><span>#         @e3 [button] "Sign In"</span></span>
<span></span>
<span><span>cloudrouter</span><span> browser</span><span> fill</span><span> cr_abc123</span><span> @e1</span><span> "user@example.com"</span></span>
<span><span>cloudrouter</span><span> browser</span><span> fill</span><span> cr_abc123</span><span> @e2</span><span> "password123"</span></span>
<span><span>cloudrouter</span><span> browser</span><span> click</span><span> cr_abc123</span><span> @e3</span></span>
<span><span>cloudrouter</span><span> browser</span><span> wait</span><span> cr_abc123</span><span> 2000</span><span>               # Wait for navigation</span></span>
<span><span>cloudrouter</span><span> browser</span><span> snapshot</span><span> -i</span><span> cr_abc123</span><span>              # Re-snapshot after navigation!</span></span>
<span><span>cloudrouter</span><span> browser</span><span> screenshot</span><span> cr_abc123</span><span> /tmp/result.png</span></span>
<span><span>```</span></span>
<span></span>
<span><span>### Browser automation: Scrape data</span></span>
<span></span>
<span><span>```bash</span></span>
<span><span>cloudrouter</span><span> browser</span><span> open</span><span> cr_abc123</span><span> "https://example.com/data"</span></span>
<span><span>cloudrouter</span><span> browser</span><span> wait</span><span> cr_abc123</span><span> 2000</span></span>
<span><span>cloudrouter</span><span> browser</span><span> snapshot</span><span> -i</span><span> cr_abc123</span><span>     # Get interactive elements</span></span>
<span><span>cloudrouter</span><span> browser</span><span> get-text</span><span> cr_abc123</span><span> @e5</span><span>    # Extract specific element text</span></span>
<span><span>cloudrouter</span><span> browser</span><span> screenshot</span><span> cr_abc123</span><span>      # Visual capture</span></span>
<span><span>```</span></span>
<span></span>
<span><span>### Pause and resume workflow</span></span>
<span></span>
<span><span>```bash</span></span>
<span><span>cloudrouter</span><span> stop</span><span> cr_abc123</span><span>            # Pause (preserves state)</span></span>
<span><span># ... later ...</span></span>
<span><span>cloudrouter</span><span> resume</span><span> cr_abc123</span><span>          # Resume where you left off</span></span>
<span><span>```</span></span>
<span></span>
<span><span>### Sandbox Lifecycle &amp; Cleanup</span></span>
<span></span>
<span><span>**Concurrency limit:**</span><span> Users can have a maximum of </span><span>**10 concurrently running sandboxes**</span><span>. If the user is approaching this limit, alert them and suggest cleaning up unused sandboxes. If they need a higher limit, they should contact </span><span>**founders@manaflow.ai**</span><span> (the CLI will also display this message when the limit is hit).</span></span>
<span></span>
<span><span>**Cleanup rules ‚Äî be careful and deliberate:**</span></span>
<span></span>
<span><span>1.</span><span> **Only touch sandboxes you created in this session.**</span><span> Never stop or delete sandboxes you didn't create or don't recognize. If you see unknown sandboxes in </span><span>`cloudrouter ls`</span><span>, leave them alone ‚Äî they may belong to the user or another workflow.</span></span>
<span></span>
<span><span>2.</span><span> **Extend before cleanup.**</span><span> Before stopping or deleting a sandbox you created, consider whether the user might want to inspect it. If you built something the user should see (a running app, a trained model, browser automation results, etc.), </span><span>**extend the sandbox**</span><span> with </span><span>`cloudrouter extend &lt;id&gt;`</span><span> so the user has time to check it out. Share the relevant URL (VS Code, VNC, Jupyter, etc.) so they can access it.</span></span>
<span><span>   -</span><span> Use </span><span>`--seconds &lt;N&gt;`</span><span> to set a custom duration (default is 3600 = 1 hour). </span><span>**Do NOT use </span><span>`--timeout`</span><span>**</span><span> ‚Äî that flag does not exist on </span><span>`extend`</span><span>.</span></span>
<span><span>   -</span><span> Example: </span><span>`cloudrouter extend cr_abc123 --seconds 1800`</span><span> extends by 30 minutes.</span></span>
<span></span>
<span><span>3.</span><span> **Stop (pause), don't delete, by default.**</span><span> Prefer </span><span>`cloudrouter stop &lt;id&gt;`</span><span> over </span><span>`cloudrouter delete &lt;id&gt;`</span><span> unless the sandbox is clearly disposable (e.g., a quick test that produced no artifacts). Stopped sandboxes can be resumed with </span><span>`cloudrouter resume &lt;id&gt;`</span><span>; deleted ones are gone forever. If </span><span>`cloudrouter stop`</span><span> fails (the VM may have died), the sandbox is likely already dead. You can use </span><span>`cloudrouter delete &lt;id&gt;`</span><span> to clean it up if the user needs sandbox slots freed, but don't delete proactively ‚Äî only when the user needs more space or explicitly asks.</span></span>
<span></span>
<span><span>4.</span><span> **Clean up when you're done.**</span><span> When your task is complete and the user no longer needs the sandbox, stop it. Don't leave sandboxes running indefinitely ‚Äî they count toward the concurrency limit.</span></span>
<span></span>
<span><span>5.</span><span> **Monitor concurrency.**</span><span> Before creating a new sandbox, run </span><span>`cloudrouter ls`</span><span> to check how many are running. If there are 8+ active sandboxes, warn the user and ask if any can be stopped before creating another. Never silently hit the limit.</span></span>
<span></span>
<span><span>6.</span><span> **If the limit is reached:**</span><span> Tell the user they've hit the 10-sandbox concurrency limit. Suggest stopping sandboxes they no longer need. If they need more capacity, direct them to contact </span><span>**founders@manaflow.ai**</span><span> to request a higher limit.</span></span>
<span></span>
<span><span>**Cleanup workflow:**</span></span>
<span></span>
<span><span>```bash</span></span>
<span><span>cloudrouter</span><span> ls</span><span>                                   # Check running sandboxes and count</span></span>
<span><span>cloudrouter</span><span> extend</span><span> cr_abc123</span><span>                     # Extend by 1 hour (default)</span></span>
<span><span>cloudrouter</span><span> extend</span><span> cr_abc123</span><span> --seconds</span><span> 3600</span><span>      # Extend by custom duration</span></span>
<span><span># ... share URLs, let user verify ...</span></span>
<span><span>cloudrouter</span><span> stop</span><span> cr_abc123</span><span>                       # Pause when done (can resume later)</span></span>
<span><span>cloudrouter</span><span> delete</span><span> cr_abc123</span><span>                     # Delete only if clearly disposable</span></span>
<span><span>```</span></span>
<span></span>
<span><span>## Surfacing URLs and Screenshots</span></span>
<span></span>
<span><span>Proactively share authenticated sandbox URLs and screenshots with the user when it helps build trust or verify progress. The user cannot see what's happening inside the sandbox ‚Äî showing them evidence of your work is important.</span></span>
<span></span>
<span><span>**When to surface URLs:**</span></span>
<span><span>-</span><span> After creating a sandbox or setting up an environment, share the VS Code URL (</span><span>`cloudrouter code &lt;id&gt;`</span><span>) so the user can inspect the workspace</span></span>
<span><span>-</span><span> After deploying or starting a service, share the VNC URL (</span><span>`cloudrouter vnc &lt;id&gt;`</span><span>) so the user can see it running</span></span>
<span><span>-</span><span> When Jupyter is running, share the Jupyter URL (</span><span>`cloudrouter jupyter &lt;id&gt;`</span><span>) so the user can verify notebooks</span></span>
<span><span>-</span><span> Whenever the user might want to verify, inspect, or interact with the sandbox themselves</span></span>
<span></span>
<span><span>**When to take and share screenshots:**</span></span>
<span><span>-</span><span> After completing a visual task (e.g., UI changes, web app deployment) ‚Äî take a screenshot with </span><span>`cloudrouter browser screenshot &lt;id&gt; /tmp/out.png`</span><span> and show it</span></span>
<span><span>-</span><span> When something looks wrong or unexpected ‚Äî screenshot it for the user to confirm</span></span>
<span><span>-</span><span> After browser automation steps that produce visible results (form submissions, page navigations, login flows)</span></span>
<span><span>-</span><span> When the user asks you to check or verify something visually</span></span>
<span></span>
<span><span>**General rule:**</span><span> If you think the user would benefit from seeing proof of what you did, surface the URL or screenshot. Err on the side of showing more rather than less ‚Äî it builds trust and keeps the user in the loop.</span></span>
<span></span>
<span><span>## Security: Dev Server URLs</span></span>
<span></span>
<span><span>**CRITICAL: NEVER share or output raw E2B port-forwarded URLs.**</span></span>
<span></span>
<span><span>When a dev server runs in the sandbox (e.g., Vite on port 5173, Next.js on port 3000), E2B creates publicly accessible URLs like </span><span>`https://5173-xxx.e2b.app`</span><span>. These URLs have </span><span>**NO authentication**</span><span> ‚Äî anyone with the link can access the running application.</span></span>
<span></span>
<span><span>**Rules:**</span></span>
<span><span>-</span><span> **NEVER**</span><span> output URLs like </span><span>`https://5173-xxx.e2b.app`</span><span>, </span><span>`https://3000-xxx.e2b.app`</span><span>, or any </span><span>`https://&lt;port&gt;-xxx.e2b.app`</span><span> URL</span></span>
<span><span>-</span><span> **NEVER**</span><span> construct or guess E2B port URLs from sandbox metadata</span></span>
<span><span>-</span><span> **ALWAYS**</span><span> tell the user to view dev servers through VNC: </span><span>`cloudrouter vnc &lt;id&gt;`</span></span>
<span><span>-</span><span> VNC is protected by token authentication (</span><span>`?tkn=`</span><span>) and is the only safe way to view dev server output</span></span>
<span><span>-</span><span> **DO**</span><span> share authenticated URLs: VS Code (</span><span>`cloudrouter code &lt;id&gt;`</span><span>), VNC (</span><span>`cloudrouter vnc &lt;id&gt;`</span><span>), Jupyter (</span><span>`cloudrouter jupyter &lt;id&gt;`</span><span>) ‚Äî these have proper token auth and are safe to surface</span></span>
<span></span>
<span><span>**When a dev server is started:**</span></span>
<span><span>```</span></span>
<span><span>Dev server running on port 5173</span></span>
<span><span>  View it in your sandbox's VNC desktop: cloudrouter vnc &lt;id&gt;</span></span>
<span><span>  (The browser inside VNC can access http://localhost:5173)</span></span>
<span><span>```</span></span>
<span></span>
<span><span>**NEVER do this:**</span></span>
<span><span>```</span></span>
<span><span>Frontend: https://5173-xxx.e2b.app   &lt;- WRONG: publicly accessible, no auth</span></span>
<span><span>```</span></span>
<span></span>
<span><span>## Common Issues &amp; Fixes</span></span>
<span></span>
<span><span>| Issue | Fix |</span></span>
<span><span>|-------|-----|</span></span>
<span><span>| </span><span>`npm install`</span><span> fails with EACCES/ENOENT errors | </span><span>**ALWAYS**</span><span> run </span><span>`cloudrouter ssh &lt;id&gt; "sudo chown -R 1000:1000 /home/user/.npm"`</span><span> BEFORE any npm command in a new sandbox |</span></span>
<span><span>| </span><span>`cloudrouter ssh &lt;id&gt; ls -la`</span><span> fails with "unknown flag" | Always quote the command: </span><span>`cloudrouter ssh &lt;id&gt; "ls -la"`</span><span> |</span></span>
<span><span>| </span><span>`snapshot &lt;id&gt; -i`</span><span> returns empty/wrong results | Flags go BEFORE the ID: </span><span>`snapshot -i &lt;id&gt;`</span><span> |</span></span>
<span><span>| Browser commands fail right after </span><span>`start`</span><span> | Wait a few seconds ‚Äî Chrome needs time to boot |</span></span>
<span><span>| </span><span>`find ... role button click`</span><span> clicks wrong button | Use </span><span>`find ... text "Button Name" click`</span><span> to target by visible text |</span></span>
<span><span>| </span><span>`extend --timeout 300`</span><span> fails | Use </span><span>`--seconds`</span><span>: </span><span>`extend &lt;id&gt; --seconds 300`</span><span> |</span></span>
<span><span>| Refs from </span><span>`snapshot`</span><span> don't match </span><span>`snapshot -i`</span><span> | Don't mix modes ‚Äî stick to </span><span>`snapshot -i`</span><span> for interactions |</span></span>
<span><span>| Dev server running but can't access it | Use </span><span>`cloudrouter browser open &lt;id&gt; "http://localhost:PORT"`</span><span> ‚Äî don't expose E2B port URLs |</span></span>
<span><span>| Long-running </span><span>`ssh`</span><span> command hangs | Use </span><span>`cloudrouter pty`</span><span> for interactive/long commands, </span><span>`ssh`</span><span> is for quick one-offs |</span></span>
<span><span>| </span><span>`scrollintoview @e1`</span><span> fails with "Unsupported token" | </span><span>`scrollintoview`</span><span> and </span><span>`highlight`</span><span> only accept CSS selectors (e.g. </span><span>`"#id"`</span><span>, </span><span>`".class"`</span><span>), NOT </span><span>`@e`</span><span> refs |</span></span>
<span><span>| </span><span>`pkill -f`</span><span> kills SSH session (exit 143/255) | </span><span>`pkill -f`</span><span> pattern may match the SSH session. Just run another </span><span>`ssh`</span><span> command to recover |</span></span>
<span><span>| </span><span>`pdf`</span><span> command saves to remote path | File saves inside the sandbox (e.g. </span><span>`/tmp/page.pdf`</span><span>). Use </span><span>`cloudrouter download`</span><span> to get it locally |</span></span>
<span><span>| </span><span>`storage-local &lt;id&gt; key`</span><span> shows "Done" not the value | Use </span><span>`eval &lt;id&gt; "localStorage.getItem('key')"`</span><span> to reliably get a specific localStorage value |</span></span>
<span><span>| Stale ref error after DOM change | Always re-snapshot after clicks/form submits. Error says "timed out" ‚Äî means ref is stale |</span></span>
<span><span>| </span><span>`cloudrouter stop`</span><span> fails / sandbox unreachable | The VM likely died. Use </span><span>`cloudrouter delete &lt;id&gt;`</span><span> to clean it up if you need sandbox slots freed |</span></span>
<span><span>| </span><span>`create-next-app`</span><span> hangs via </span><span>`ssh`</span><span> | Interactive prompts don't work in </span><span>`ssh`</span><span>. Use </span><span>`pty`</span><span> for interactive installers, or pipe input |</span></span>
<span></span>
<span><span>## Global Flags</span></span>
<span></span>
<span><span>```</span></span>
<span><span>-t, --team &lt;team&gt;   Team slug (overrides default)</span></span>
<span><span>-v, --verbose       Verbose output</span></span>
<span><span>```</span></span>
<span></span></code></pre></div></section><hr></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Age of Empires: 25 years of pathfinding problems with C++ [video] (147 pts)]]></title>
            <link>https://www.youtube.com/watch?v=lEBQveBCtKY</link>
            <guid>47006316</guid>
            <pubDate>Fri, 13 Feb 2026 18:56:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.youtube.com/watch?v=lEBQveBCtKY">https://www.youtube.com/watch?v=lEBQveBCtKY</a>, See on <a href="https://news.ycombinator.com/item?id=47006316">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Dario Amodei ‚Äì "We are near the end of the exponential" [video] (102 pts)]]></title>
            <link>https://www.dwarkesh.com/p/dario-amodei-2</link>
            <guid>47005565</guid>
            <pubDate>Fri, 13 Feb 2026 17:55:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.dwarkesh.com/p/dario-amodei-2">https://www.dwarkesh.com/p/dario-amodei-2</a>, See on <a href="https://news.ycombinator.com/item?id=47005565">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p>Dario Amodei thinks we are just a few years away from ‚Äúa country of geniuses in a data center‚Äù. In this episode, we discuss what to make of the scaling hypothesis in the current RL regime, how AI will diffuse throughout the economy, whether Anthropic is underinvesting in compute given their timelines, how frontier labs will ever make money, whether regulation will destroy the boons of this technology, US-China competition, and much more.</p><p><span>Watch on </span><a href="https://youtu.be/n1E9IZfvGMA" rel="">YouTube</a><span>; listen on </span><a href="https://podcasts.apple.com/us/podcast/dario-amodei-the-highest-stakes-financial-model-in-history/id1516093381?i=1000749621800" rel="">Apple Podcasts</a><span> or </span><a href="https://open.spotify.com/episode/2ZNrpVSrgZMlDwQinl20Ay?si=9D4aG1l7S-2wzLsiILRLIg" rel="">Spotify</a><span>.</span></p><div id="youtube2-n1E9IZfvGMA" data-attrs="{&quot;videoId&quot;:&quot;n1E9IZfvGMA&quot;,&quot;startTime&quot;:null,&quot;endTime&quot;:null}" data-component-name="Youtube2ToDOM"><p><iframe src="https://www.youtube-nocookie.com/embed/n1E9IZfvGMA?rel=0&amp;autoplay=0&amp;showinfo=0&amp;enablejsapi=0" frameborder="0" loading="lazy" gesture="media" allow="autoplay; fullscreen" allowautoplay="true" allowfullscreen="true" width="728" height="409"></iframe></p></div><ul><li><p><a href="https://labelbox.com/dwarkesh" rel="">Labelbox</a><span> can get you the RL tasks and environments you need. Their massive network of subject-matter experts ensures realism across domains, and their in-house tooling lets them continuously tweak task difficulty to optimize learning. Reach out at </span><a href="https://labelbox.com/dwarkesh" rel="">labelbox.com/dwarkesh</a></p></li><li><p><a href="https://janestreet.com/dwarkesh" rel="">Jane Street</a><span> sent me another puzzle‚Ä¶ this time, they‚Äôve trained backdoors into 3 different language models ‚Äî they want you to find the triggers. Jane Street isn‚Äôt even sure this is possible, but they‚Äôve set aside $50,000 for the best attempts and write-ups. They‚Äôre accepting submissions until April 1st at </span><a href="https://janestreet.com/dwarkesh" rel="">janestreet.com/dwarkesh</a></p></li><li><p><a href="https://mercury.com/personal-banking" rel="">Mercury</a><span>‚Äôs personal accounts make it easy to share finances with a partner, a roommate‚Ä¶ or OpenClaw. Last week, I wanted to try OpenClaw for myself, so I used Mercury to spin up a virtual debit card with a small spend limit, and then I let my agent loose. No matter your use case, apply at </span><a href="https://mercury.com/personal-banking" rel="">mercury.com/personal-banking</a></p></li></ul><p><a href="https://www.dwarkesh.com/i/187852154/000000-what-exactly-are-we-scaling" rel="">(00:00:00) - What exactly are we scaling?</a></p><p><a href="https://www.dwarkesh.com/i/187852154/001236-is-diffusion-cope" rel="">(00:12:36) - Is diffusion cope?</a></p><p><a href="https://www.dwarkesh.com/i/187852154/002942-is-continual-learning-necessary-how-will-it-be-solved" rel="">(00:29:42) - Is continual learning necessary?</a></p><p><a href="https://www.dwarkesh.com/i/187852154/004620-if-agi-is-imminent-why-not-buy-more-compute" rel="">(00:46:20) - If AGI is imminent, why not buy more compute?</a></p><p><a href="https://www.dwarkesh.com/i/187852154/005849-how-will-ai-labs-actually-make-profit" rel="">(00:58:49) - How will AI labs actually make profit?</a></p><p><a href="https://www.dwarkesh.com/i/187852154/013119-will-regulations-destroy-the-boons-of-agi" rel="">(01:31:19) - Will regulations destroy the boons of AGI?</a></p><p><a href="https://www.dwarkesh.com/i/187852154/014741-why-cant-china-and-america-both-have-a-country-of-geniuses-in-a-datacenter" rel="">(01:47:41) - Why can‚Äôt China and America both have a country of geniuses in a datacenter?</a></p><p><strong>Dwarkesh Patel</strong></p><p><a href="https://www.dwarkesh.com/p/dario-amodei" rel="">We talked three years ago</a><span>. In your view, what has been the biggest update over the last three years? What has been the biggest difference between what it felt like then versus now?</span></p><p><strong>Dario Amodei</strong></p><p>Broadly speaking, the exponential of the underlying technology has gone about as I expected it to go. There‚Äôs plus or minus a year or two here and there. I don‚Äôt know that I would‚Äôve predicted the specific direction of code.</p><p>But when I look at the exponential, it is roughly what I expected in terms of the march of the models from smart high school student to smart college student to beginning to do PhD and professional stuff, and in the case of code reaching beyond that. The frontier is a little bit uneven, but it‚Äôs roughly what I expected.</p><p>What has been the most surprising thing is the lack of public recognition of how close we are to the end of the exponential. To me, it is absolutely wild that you have people ‚Äî within the bubble and outside the bubble ‚Äî talking about the same tired, old hot-button political issues, when we are near the end of the exponential.</p><p><strong>Dwarkesh Patel</strong></p><p><span>I want to understand what that exponential looks like right now. The first question I asked you when we recorded three years ago was, ‚Äúwhat‚Äôs up with </span><a href="https://www.dwarkesh.com/p/will-scaling-work" rel="">scaling</a><span> and why does it work?‚Äù I have a similar question now, but it feels more complicated. At least from the public‚Äôs point of view, three years ago there were well-known public trends across many orders of magnitude of compute where you could see how the loss improves.</span></p><p><span>Now we have </span><a href="https://en.wikipedia.org/wiki/Reinforcement_learning" rel="">RL</a><span> </span><a href="https://www.tobyord.com/writing/how-well-does-rl-scale" rel="">scaling</a><span> and there‚Äôs no publicly known </span><a href="https://en.wikipedia.org/wiki/Neural_scaling_law" rel="">scaling law</a><span> for it. It‚Äôs not even clear what the story is. Is this supposed to be teaching the model skills? Is it supposed to be teaching meta-learning? What is the </span><a href="https://gwern.net/scaling-hypothesis" rel="">scaling hypothesis</a><span> at this point?</span></p><p><strong>Dario Amodei</strong></p><p><span>I actually have the same hypothesis I had even all the way back in 2017. I think I talked about it last time, but I wrote a doc called </span><a href="http://corley.ai/the-blob-that-ate-ai/" rel="">‚ÄúThe Big Blob of Compute Hypothesis‚Äù</a><span>. It wasn‚Äôt about the scaling of language models in particular. When I wrote it </span><a href="https://en.wikipedia.org/wiki/GPT-1" rel="">GPT-1</a><span> had just come out.</span></p><p><span>That was one among many things. Back in those days there was robotics. People tried to work on reasoning as a separate thing from </span><a href="https://en.wikipedia.org/wiki/Large_language_model" rel="">language models</a><span>, and there was scaling of the kind of RL that happened in </span><a href="https://en.wikipedia.org/wiki/AlphaGo" rel="">AlphaGo</a><span> and in </span><a href="https://en.wikipedia.org/wiki/OpenAI_Five" rel="">Dota</a><span> at </span><a href="https://en.wikipedia.org/wiki/OpenAI" rel="">OpenAI</a><span>. People remember StarCraft at </span><a href="https://en.wikipedia.org/wiki/Google_DeepMind" rel="">DeepMind</a><span>, </span><a href="https://en.wikipedia.org/wiki/AlphaStar_(software)" rel="">AlphaStar</a><span>.</span></p><p><span>It was written as a more general document. </span><a href="https://www.dwarkesh.com/p/richard-sutton" rel="">Rich Sutton</a><span> put out </span><a href="http://www.incompleteideas.net/IncIdeas/BitterLesson.html" rel="">‚ÄúThe Bitter Lesson‚Äù</a><span> a couple years later. The hypothesis is basically the same. What it says is that all the cleverness, all the techniques, all the ‚Äúwe need a new method to do something‚Äù, that doesn‚Äôt matter very much. There are only a few things that matter. I think I listed seven of them.</span></p><p><span>One is how much raw compute you have. The second is the quantity of data. The third is the quality and distribution of data. It needs to be a broad distribution. The fourth is how long you train for. The fifth is that you need an objective function that can scale to the moon. The </span><a href="https://www.moveworks.com/us/en/resources/ai-terms-glossary/pre-training" rel="">pre-training</a><span> objective function is one such objective function. Another is the RL objective function that says you have a goal, you‚Äôre going to go out and reach the goal.</span></p><p><span>Within that, there‚Äôs objective rewards like you see in math and coding, and there‚Äôs more subjective rewards like you see in </span><a href="https://en.wikipedia.org/wiki/Reinforcement_learning_from_human_feedback" rel="">RLHF</a><span> or higher-order versions of that. Then the sixth and seventh were things around </span><a href="https://en.wikipedia.org/wiki/Normalization_(machine_learning)" rel="">normalization</a><span> or conditioning, just getting the numerical stability so that the big blob of compute flows in this </span><a href="https://en.wikipedia.org/wiki/Laminar_flow" rel="">laminar</a><span> way instead of running into problems.</span></p><p><span>That was the hypothesis, and it‚Äôs a hypothesis I still hold. I don‚Äôt think I‚Äôve seen very much that is not in line with it. The </span><a href="https://blogs.nvidia.com/blog/ai-scaling-laws/" rel="">pre-training scaling laws</a><span> were one example of what we see there. Those have continued going. Now it‚Äôs been widely reported, we feel good about pre-training. It‚Äôs continuing to give us gains.</span></p><p><span>What has changed is that now we‚Äôre also seeing the same thing for RL. We‚Äôre seeing a pre-training phase and then an RL phase on top of that. With RL, it‚Äôs actually just the same. Even other companies have published things in some of their releases that say, ‚ÄúWe train the model on math contests ‚Äî </span><a href="https://en.wikipedia.org/wiki/American_Invitational_Mathematics_Examination" rel="">AIME</a><span> or other things ‚Äî and how well the model does is log-linear in how long we‚Äôve trained it.‚Äù</span></p><p>We see that as well, and it‚Äôs not just math contests. It‚Äôs a wide variety of RL tasks. We‚Äôre seeing the same scaling in RL that we saw for pre-training.</p><p><strong>Dwarkesh Patel</strong></p><p><span>You mentioned Rich Sutton and ‚ÄúThe Bitter Lesson‚Äù. </span><a href="https://www.dwarkesh.com/p/richard-sutton" rel="">I interviewed him last year</a><span>, and he‚Äôs actually very non-LLM-pilled. I don‚Äôt know if this is his perspective, but one way to paraphrase his objection is: Something which possesses the true core of human learning would not require all these billions of dollars of data and compute and these bespoke environments, to learn how to use Excel, how to use PowerPoint, how to navigate a web browser. The fact that we have to build in these skills using these RL environments hints that we are actually lacking a core human learning algorithm. So we‚Äôre scaling the wrong thing.</span></p><p>That does raise the question. Why are we doing all this RL scaling if we think there‚Äôs something that‚Äôs going to be human-like in its ability to learn on the fly?</p><p><strong>Dario Amodei</strong></p><p>I think this puts together several things that should be thought of differently. There is a genuine puzzle here, but it may not matter. In fact, I would guess it probably doesn‚Äôt matter. There is an interesting thing. Let me take the RL out of it for a second, because I actually think it‚Äôs a red herring to say that RL is any different from pre-training in this matter.</p><p><span>If we look at pre-training scaling, it was very interesting back in 2017 when </span><a href="https://scholar.google.com/citations?user=dOad5HoAAAAJ&amp;hl=en" rel="">Alec Radford</a><span> was doing GPT-1. The models before GPT-1 were trained on datasets that didn‚Äôt represent a wide distribution of text. You had very standard language modeling benchmarks. GPT-1 itself was trained on a bunch of fanfiction, I think actually.</span></p><p>It was literary text, which is a very small fraction of the text you can get. In those days it was like a billion words or something, so small datasets representing a pretty narrow distribution of what you can see in the world. It didn‚Äôt generalize well. If you did better on some fanfiction corpus, it wouldn‚Äôt generalize that well to other tasks.</p><p><span>We had all these measures. We had all these measures of how well it did at predicting all these other kinds of texts. It was only when you trained over all the tasks on the internet ‚Äî when you did a general internet scrape from something like </span><a href="https://en.wikipedia.org/wiki/Common_Crawl" rel="">Common Crawl</a><span> or scraping links in Reddit, which is what we did for </span><a href="https://en.wikipedia.org/wiki/GPT-2" rel="">GPT-2</a><span> ‚Äî that you started to get generalization.</span></p><p>I think we‚Äôre seeing the same thing on RL. We‚Äôre starting first with simple RL tasks like training on math competitions, then moving to broader training that involves things like code. Now we‚Äôre moving to many other tasks. I think then we‚Äôre going to increasingly get generalization. So that kind of takes out the RL vs. pre-training side of it.</p><p><span>But there is a puzzle either way, which is that in pre-training we use trillions of tokens. Humans don‚Äôt see trillions of words. So there is an actual sample efficiency difference here. There is actually something different here. The models start from scratch and they need much more training. But we also see that once they‚Äôre trained, if we give them a long </span><a href="https://www.ibm.com/think/topics/context-window" rel="">context length</a><span> of a million ‚Äî the only thing blocking long context is </span><a href="https://hazelcast.com/foundations/ai-machine-learning/machine-learning-inference/" rel="">inference</a><span> ‚Äî they‚Äôre very good at learning and adapting within that context.</span></p><p><span>So I don‚Äôt know the full answer to this. I think there‚Äôs something going on where pre-training is not like the process of humans learning, but it‚Äôs somewhere between the process of humans learning and the process of human evolution. We get many of our priors from evolution. Our brain isn‚Äôt just a blank slate. </span><a href="https://en.wikipedia.org/wiki/The_Blank_Slate" rel="">Whole books have been written about this.</a></p><p><span>The language models are much more like blank slates. They literally start as random </span><a href="https://www.geeksforgeeks.org/deep-learning/the-role-of-weights-and-bias-in-neural-networks/" rel="">weights</a><span>, whereas the human brain starts with all these regions connected to all these inputs and outputs. Maybe we should think of pre-training ‚Äî and for that matter, RL as well ‚Äî as something that exists in the middle space between human evolution and human on-the-spot learning. And we should think of the in-context learning that the models do as something between long-term human learning and short-term human learning.</span></p><p>So there‚Äôs this hierarchy. There‚Äôs evolution, there‚Äôs long-term learning, there‚Äôs short-term learning, and there‚Äôs just human reaction. The LLM phases exist along this spectrum, but not necessarily at exactly the same points. There‚Äôs no analog to some of the human modes of learning the LLMs are falling in between the points. Does that make sense?</p><p><strong>Dwarkesh Patel</strong></p><p><span>Yes, although some things are still a bit confusing. For example, if the analogy is that this is like evolution so it‚Äôs fine that it‚Äôs not sample efficient, then if we‚Äôre going to get super sample-efficient agent from </span><a href="https://www.lakera.ai/blog/what-is-in-context-learning" rel="">in-context learning</a><span>, why are we bothering to build all these RL environments?</span></p><p>There are companies whose work seems to be teaching models how to use this API, how to use Slack, how to use whatever. It‚Äôs confusing to me why there‚Äôs so much emphasis on that if the kind of agent that can just learn on the fly is emerging or has already emerged.</p><p><strong>Dario Amodei</strong></p><p>I can‚Äôt speak for the emphasis of anyone else. I can only talk about how we think about it. The goal is not to teach the model every possible skill within RL, just as we don‚Äôt do that within pre-training. Within pre-training, we‚Äôre not trying to expose the model to every possible way that words could be put together. Rather, the model trains on a lot of things and then reaches generalization across pre-training.</p><p>That was the transition from GPT-1 to GPT-2 that I saw up close. The model reaches a point. I had these moments where I was like, ‚ÄúOh yeah, you just give the model a list of numbers ‚Äî this is the cost of the house, this is the square feet of the house ‚Äî and the model completes the pattern and does linear regression.‚Äù Not great, but it does it, and it‚Äôs never seen that exact thing before.</p><p>So to the extent that we are building these RL environments, the goal is very similar to what was done five or ten years ago with pre-training. We‚Äôre trying to get a whole bunch of data, not because we want to cover a specific document or a specific skill, but because we want to generalize.</p><p><strong>Dwarkesh Patel</strong></p><p><span>I think the framework you‚Äôre laying down obviously makes sense. We‚Äôre making progress toward </span><a href="https://en.wikipedia.org/wiki/Artificial_general_intelligence" rel="">AGI</a><span>. Nobody at this point disagrees we‚Äôre going to achieve AGI this century. The crux is you say we‚Äôre hitting the end of the exponential. Somebody else looks at this and says, ‚ÄúWe‚Äôve been making progress since 2012, and by 2035 we‚Äôll have a human-like agent.‚Äù</span></p><p>Obviously we‚Äôre seeing in these models the kinds of things that evolution did, or that learning within a human lifetime does. I want to understand what you‚Äôre seeing that makes you think it‚Äôs one year away and not ten years away.</p><p><strong>Dario Amodei</strong></p><p>There are two claims you could make here, one stronger and one weaker. Starting with the weaker claim, when I first saw the scaling back in 2019, I wasn‚Äôt sure. This was a 50/50 thing. I thought I saw something. My claim was that this was much more likely than anyone thinks. Maybe there‚Äôs a 50% chance this happens.</p><p><span>On the basic hypothesis of, as you put it, within ten years we‚Äôll get to what I call a ‚Äúcountry of geniuses in a data center‚Äù, I‚Äôm at 90% on that. It‚Äôs hard to go much higher than 90% because the world is so unpredictable. Maybe the irreducible uncertainty puts us at 95%, where you get to things like multiple companies having internal turmoil, </span><a href="https://en.wikipedia.org/wiki/Chinese_unification" rel="">Taiwan gets invaded</a><span>, all the </span><a href="https://en.wikipedia.org/wiki/Semiconductor_fabrication_plant" rel="">fabs</a><span> get blown up by missiles.</span></p><p><strong>Dwarkesh Patel</strong></p><p>Now you‚Äôve jinxed us, Dario.</p><p><strong>Dario Amodei</strong></p><p>You could construct a 5% world where things get delayed for ten years. There‚Äôs another 5% which is that I‚Äôm very confident on tasks that can be verified. With coding, except for that irreducible uncertainty, I think we‚Äôll be there in one or two years. There‚Äôs no way we will not be there in ten years in terms of being able to do end-to-end coding.</p><p>My one little bit of fundamental uncertainty, even on long timescales, is about tasks that aren‚Äôt verifiable: planning a mission to Mars; doing some fundamental scientific discovery like CRISPR; writing a novel. It‚Äôs hard to verify those tasks. I am almost certain we have a reliable path to get there, but if there‚Äôs a little bit of uncertainty it‚Äôs there. On the ten-year timeline I‚Äôm at 90%, which is about as certain as you can be. I think it‚Äôs crazy to say that this won‚Äôt happen by 2035. In some sane world, it would be outside the mainstream.</p><p><strong>Dwarkesh Patel</strong></p><p>But the emphasis on verification hints to me a lack of belief that these models are generalized. If you think about humans, we‚Äôre both good at things for which we get verifiable reward and things for which we don‚Äôt.</p><p><strong>Dario Amodei</strong></p><p>No, this is why I‚Äôm almost sure. We already see substantial generalization from things that verify to things that don‚Äôt. We‚Äôre already seeing that.</p><p><strong>Dwarkesh Patel</strong></p><p>But it seems like you were emphasizing this as a spectrum which will split apart which domains in which we see more progress. That doesn‚Äôt seem like how humans get better.</p><p><strong>Dario Amodei</strong></p><p>The world in which we don‚Äôt get there is the world in which we do all the verifiable things. Many of them generalize, but we don‚Äôt fully get there. We don‚Äôt fully color in the other side of the box. It‚Äôs not a binary thing.</p><p><strong>Dwarkesh Patel</strong></p><p><span>Even if generalization is weak and you can only do verifiable domains, it‚Äôs not clear to me you could automate software engineering in such a world. You are ‚Äúa software engineer‚Äù in some sense, but part of being a software engineer for you involves </span><a href="https://www.darioamodei.com/" rel="">writing long memos</a><span> about your grand vision.</span></p><p><strong>Dario Amodei</strong></p><p><span>I don‚Äôt think that‚Äôs part of the job of </span><a href="https://en.wikipedia.org/wiki/Software_engineering" rel="">SWE</a><span>. That‚Äôs part of the job of the company, not SWE specifically. But SWE does involve design documents and other things like that. The models are already pretty good at writing comments. Again, I‚Äôm making much weaker claims here than I believe, to distinguish between two things. We‚Äôre already almost there for software engineering.</span></p><p><strong>Dwarkesh Patel</strong></p><p><span>By what metric? There‚Äôs one metric which is how many lines of code are written by AI. If you consider other productivity improvements in the history of software engineering, </span><a href="https://en.wikipedia.org/wiki/Compiler" rel="">compilers</a><span> write all the lines of software. There‚Äôs a difference between how many lines are written and how big the productivity improvement is. ‚ÄúWe‚Äôre almost there‚Äù meaning‚Ä¶ How big is the productivity improvement, not just how many lines are written by AI?</span></p><p><strong>Dario Amodei</strong></p><p>I actually agree with you on this. I‚Äôve made a series of predictions on code and software engineering. I think people have repeatedly misunderstood them. Let me lay out the spectrum.</p><p><span>About eight or nine months ago, I said the AI model will be writing 90% of the lines of code in three to six months. That happened, at least at some places. It happened at </span><a href="https://en.wikipedia.org/wiki/Anthropic" rel="">Anthropic</a><span>, happened with many people downstream using our models. But that‚Äôs actually a very weak criterion. People thought I was saying that we won‚Äôt need 90% of the software engineers. Those things are worlds apart. The spectrum is: 90% of code is written by the model, 100% of code is written by the model. That‚Äôs a big difference in productivity.</span></p><p>90% of the end-to-end SWE tasks ‚Äî including things like compiling, setting up clusters and environments, testing features, writing memos ‚Äî are done by the models. 100% of today‚Äôs SWE tasks are done by the models. Even when that happens, it doesn‚Äôt mean software engineers are out of a job. There are new higher-level things they can do, where they can manage. Then further down the spectrum, there‚Äôs 90% less demand for SWEs, which I think will happen but this is a spectrum.</p><p><span>I wrote about it in </span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology" rel="">‚ÄúThe Adolescence of Technology‚Äù</a><span> where I went through this kind of spectrum with farming. I actually totally agree with you on that. These are very different benchmarks from each other, but we‚Äôre proceeding through them super fast.</span></p><p><strong>Dwarkesh Patel</strong></p><p><span>Part of your vision is that going from 90 to 100 is going to happen fast, and that it leads to huge productivity improvements. But what I notice is that even in greenfield projects people start with </span><a href="https://claude.com/product/claude-code" rel="">Claude Code</a><span> or something, people report starting a lot of projects‚Ä¶ Do we see in the world out there a renaissance of software, all these new features that wouldn‚Äôt exist otherwise? At least so far, it doesn‚Äôt seem like we see that.</span></p><p>So that does make me wonder. Even if I never had to intervene with Claude Code, the world is complicated. Jobs are complicated. Closing the loop on self-contained systems, whether it‚Äôs just writing software or something, how much broader gains would we see just from that? Maybe that should dilute our estimation of the ‚Äúcountry of geniuses‚Äù.</p><p><strong>Dario Amodei</strong></p><p><span>I simultaneously agree with you that it‚Äôs a reason why these things don‚Äôt happen instantly, but at the same time, I think the effect is gonna be very fast. You could have these two poles. One is that AI is not going to make progress. It‚Äôs slow. It‚Äôs going to take forever to diffuse within the economy. </span><a href="https://en.wikipedia.org/wiki/Diffusion_(business)" rel="">Economic diffusion</a><span> has become one of these buzzwords that‚Äôs a reason why we‚Äôre not going to make AI progress, or why AI progress doesn‚Äôt matter.</span></p><p><span>The other axis is that we‚Äôll get </span><a href="https://en.wikipedia.org/wiki/Recursive_self-improvement" rel="">recursive self-improvement</a><span>, the whole thing. Can‚Äôt you just draw an exponential line on the curve? We‚Äôre going to have </span><a href="https://en.wikipedia.org/wiki/Dyson_sphere" rel="">Dyson spheres</a><span> around the sun so many nanoseconds after we get recursive. I‚Äôm completely caricaturing the view here, but there are these two extremes.</span></p><p>But what we‚Äôve seen from the beginning, at least if you look within Anthropic, there‚Äôs this bizarre 10x per year growth in revenue that we‚Äôve seen. So in 2023, it was zero to $100 million. In 2024, it was $100 million to $1 billion. In 2025, it was $1 billion to $ 9-10 billion.</p><p><strong>Dwarkesh Patel</strong></p><p>You guys should have just bought a billion dollars of your own products so you could just‚Ä¶</p><p><strong>Dario Amodei</strong></p><p>And the first month of this year, that exponential is... You would think it would slow down, but we added another few billion to revenue in January. Obviously that curve can‚Äôt go on forever. The GDP is only so large. I would even guess that it bends somewhat this year, but that is a fast curve. That‚Äôs a really fast curve. I would bet it stays pretty fast even as the scale goes to the entire economy.</p><p><span>So I think we should be thinking about this middle world where things are extremely fast, but not instant, where they take time because of economic diffusion, because of the need to close the loop. Because it‚Äôs fiddly: ‚ÄúI have to do </span><a href="https://en.wikipedia.org/wiki/Change_management" rel="">change management</a><span> within my enterprise‚Ä¶ I set this up, but I have to change the security permissions on this in order to make it actually work‚Ä¶ I had this old piece of software that checks the model before it‚Äôs compiled and released and I have to rewrite it. Yes, the model can do that, but I have to tell the model to do that. It has to take time to do that.‚Äù</span></p><p>So I think everything we‚Äôve seen so far is compatible with the idea that there‚Äôs one fast exponential that‚Äôs the capability of the model. Then there‚Äôs another fast exponential that‚Äôs downstream of that, which is the diffusion of the model into the economy. Not instant, not slow, much faster than any previous technology, but it has its limits. When I look inside Anthropic, when I look at our customers: fast adoption, but not infinitely fast.</p><p><strong>Dwarkesh Patel</strong></p><p>Can I try a hot take on you?</p><p><strong>Dario Amodei</strong></p><p>Yeah.</p><p><strong>Dwarkesh Patel</strong></p><p>I feel like diffusion is cope that people say. When the model isn‚Äôt able to do something, they‚Äôre like, ‚Äúoh, but it‚Äôs a diffusion issue.‚Äù But then you should use the comparison to humans. You would think that the inherent advantages that AIs have would make diffusion a much easier problem for new AIs getting onboarded than new humans getting onboarded. An AI can read your entire Slack and your drive in minutes. They can share all the knowledge that the other copies of the same instance have. You don‚Äôt have this adverse selection problem when you‚Äôre hiring AI, so you can just hire copies of a vetted AI model.</p><p>Hiring a human is so much more of a hassle. People hire humans all the time. We pay humans upwards of $50 trillion in wages because they‚Äôre useful, even though in principle it would be much easier to integrate AIs into the economy than it is to hire humans. The diffusion doesn‚Äôt really explain.</p><p><strong>Dario Amodei</strong></p><p>I think diffusion is very real and doesn‚Äôt exclusively have to do with limitations on the AI models. Again, there are people who use diffusion as kind of a buzzword to say this isn‚Äôt a big deal. I‚Äôm not talking about that. I‚Äôm not talking about how AI will diffuse at the speed of previous technologies. I think AI will diffuse much faster than previous technologies have, but not infinitely fast.</p><p>I‚Äôll just give an example of this. There‚Äôs Claude Code. Claude Code is extremely easy to set up. If you‚Äôre a developer, you can just start using Claude Code. There is no reason why a developer at a large enterprise should not be adopting Claude Code as quickly as an individual developer or developer at a startup.</p><p>We do everything we can to promote it. We sell Claude Code to enterprises. Big enterprises, big financial companies, big pharmaceutical companies, all of them are adopting Claude Code much faster than enterprises typically adopt new technology. But again, it takes time.</p><p><span>Any given feature or any given product, like Claude Code or </span><a href="https://claude.com/product/cowork" rel="">Cowork</a><span>, will get adopted by the individual developers who are on Twitter all the time, by the Series A startups, many months faster than they will get adopted by a large enterprise that does food sales. There are just a number of factors. You have to go through legal, you have to provision it for everyone. It has to pass security and compliance.</span></p><p>The leaders of the company who are further away from the AI revolution are forward-looking, but they have to say, ‚ÄúOh, it makes sense for us to spend 50 million. This is what this Claude Code thing is. This is why it helps our company. This is why it makes us more productive.‚Äù Then they have to explain to the people two levels below. They have to say, ‚ÄúOkay, we have 3,000 developers. Here‚Äôs how we‚Äôre going to roll it out to our developers.‚Äù We have conversations like this every day.</p><p>We are doing everything we can to make Anthropic‚Äôs revenue grow 20 or 30x a year instead of 10x a year. Again, many enterprises are just saying, ‚ÄúThis is so productive. We‚Äôre going to take shortcuts in our usual procurement process.‚Äù They‚Äôre moving much faster than when we tried to sell them just the ordinary API, which many of them use. Claude Code is a more compelling product, but it‚Äôs not an infinitely compelling product.</p><p>I don‚Äôt think even AGI or powerful AI or ‚Äúcountry of geniuses in a data center‚Äù will be an infinitely compelling product. It will be a compelling product enough maybe to get 3-5x, or 10x, a year of growth, even when you‚Äôre in the hundreds of billions of dollars, which is extremely hard to do and has never been done in history before, but not infinitely fast.</p><p><strong>Dwarkesh Patel</strong></p><p>I buy that it would be a slight slowdown. Maybe this is not your claim, but sometimes people talk about this like, ‚ÄúOh, the capabilities are there, but because of diffusion... otherwise we‚Äôre basically at AGI‚Äù.</p><p><strong>Dario Amodei</strong></p><p>I don‚Äôt believe we‚Äôre basically at AGI.</p><p><strong>Dwarkesh Patel</strong></p><p>I think if you had the ‚Äúcountry of geniuses in a data center‚Äù...</p><p><strong>Dario Amodei</strong></p><p>If we had the ‚Äúcountry of geniuses in a data center‚Äù, we would know it. We would know it if you had the ‚Äúcountry of geniuses in a data center‚Äù. Everyone in this room would know it. Everyone in Washington would know it. People in rural parts might not know it, but we would know it. We don‚Äôt have that now. That is very clear.</p><p><strong>Dwarkesh Patel</strong></p><p>Coming back to concrete prediction‚Ä¶ Because there are so many different things to disambiguate, it can be easy to talk past each other when we‚Äôre talking about capabilities. For example, when I interviewed you three years ago, I asked you a prediction about what we should expect three years from now. You were right. You said, ‚ÄúWe should expect systems which, if you talk to them for the course of an hour, it‚Äôs hard to tell them apart from a generally well-educated human.‚Äù</p><p>I think you were right about that. I think spiritually I feel unsatisfied because my internal expectation was that such a system could automate large parts of white-collar work. So it might be more productive to talk about the actual end capabilities you want from such a system.</p><p><strong>Dario Amodei</strong></p><p>I will basically tell you where I think we are.</p><p><strong>Dwarkesh Patel</strong></p><p>Let me ask a very specific question so that we can figure out exactly what kinds of capabilities we should think about soon. Maybe I‚Äôll ask about it in the context of a job I understand well, not because it‚Äôs the most relevant job, but just because I can evaluate the claims about it.</p><p>Take video editors. I have video editors. Part of their job involves learning about our audience‚Äôs preferences, learning about my preferences and tastes, and the different trade-offs we have. They‚Äôre, over the course of many months, building up this understanding of context. The skill and ability they have six months into the job, a model that can pick up that skill on the job on the fly, when should we expect such an AI system?</p><p><strong>Dario Amodei</strong></p><p>I guess what you‚Äôre talking about is that we‚Äôre doing this interview for three hours. Someone‚Äôs going to come in, someone‚Äôs going to edit it. They‚Äôre going to be like, ‚ÄúOh, I don‚Äôt know, Dario scratched his head and we could edit that out.‚Äù</p><p><strong>Dwarkesh Patel</strong></p><p>‚ÄúMagnify that.‚Äù</p><p><strong>Dario Amodei</strong></p><p>‚ÄúThere was this long discussion that is less interesting to people. There‚Äôs another thing that‚Äôs more interesting to people, so let‚Äôs make this edit.‚Äù</p><p><span>I think the ‚Äúcountry of geniuses in a data center‚Äù will be able to do that. The way it will be able to do that is it will have </span><a href="https://www.anthropic.com/news/developing-computer-use" rel="">general control of a computer screen</a><span>. You‚Äôll be able to feed this in. It‚Äôll be able to also use the computer screen to go on the web, look at all your previous interviews, look at what people are saying on Twitter in response to your interviews, talk to you, ask you questions, talk to your staff, look at the history of edits that you did, and from that, do the job.</span></p><p>I think that‚Äôs dependent on several things. I think this is one of the things that‚Äôs actually blocking deployment: getting to the point on computer use where the models are really masters at using the computer.</p><p><span>We‚Äôve seen this climb in benchmarks, and benchmarks are always imperfect measures. But I think when we first released computer use a year and a quarter ago, </span><a href="https://os-world.github.io/" rel="">OSWorld</a><span> was at maybe 15%. I don‚Äôt remember exactly, but we‚Äôve climbed from that to 65-70%. There may be harder measures as well, but I think computer use has to pass a point of reliability.</span></p><p><strong>Dwarkesh Patel</strong></p><p>Can I just follow up on that before you move on to the next point? For years, I‚Äôve been trying to build different internal LLM tools for myself. Often I have these text-in, text-out tasks, which should be dead center in the repertoire of these models. Yet I still hire humans to do them.</p><p>If it‚Äôs something like, ‚Äúidentify what the best clips would be in this transcript‚Äù, maybe the LLMs do a seven-out-of-ten job on them. But there‚Äôs not this ongoing way I can engage with them to help them get better at the job the way I could with a human employee. That missing ability, even if you solve computer use, would still block my ability to offload an actual job to them.</p><p><strong>Dario Amodei</strong></p><p><span>This gets back to what we were talking about before with learning on the job. It‚Äôs very interesting. I think with the </span><a href="https://en.wikipedia.org/wiki/AI-assisted_software_development" rel="">coding agents</a><span>, I don‚Äôt think people would say that learning on the job is what is preventing the coding agents from doing everything end to end. They keep getting better. We have engineers at Anthropic who don‚Äôt write any code.</span></p><p><span>When I look at the productivity, to your previous question, we have folks who say, ‚ÄúThis </span><a href="https://modal.com/gpu-glossary/device-software/kernel" rel="">GPU kernel</a><span>, this chip, I used to write it myself. I just have Claude do it.‚Äù There‚Äôs this enormous improvement in productivity.</span></p><p><span>When I see Claude Code, familiarity with the </span><a href="https://en.wikipedia.org/wiki/Codebase" rel="">codebase</a><span> or a feeling that the model hasn‚Äôt worked at the company for a year, that‚Äôs not high up on the list of complaints I see. I think what I‚Äôm saying is that we‚Äôre kind of taking a different path.</span></p><p><strong>Dwarkesh Patel</strong></p><p>Don‚Äôt you think with coding that‚Äôs because there is an external scaffold of memory which exists instantiated in the codebase? I don‚Äôt know how many other jobs have that. Coding made fast progress precisely because it has this unique advantage that other economic activity doesn‚Äôt.</p><p><strong>Dario Amodei</strong></p><p>But when you say that, what you‚Äôre implying is that by reading the codebase into the context, I have everything that the human needed to learn on the job. So that would be an example of‚Äîwhether it‚Äôs written or not, whether it‚Äôs available or not‚Äîa case where everything you needed to know you got from the context window. What we think of as learning‚Äî‚ÄùI started this job, it‚Äôs going to take me six months to understand the code base‚Äù‚Äîthe model just did it in the context.</p><p><strong>Dwarkesh Patel</strong></p><p><span>I honestly don‚Äôt know how to think about this because there are people who qualitatively report what you‚Äôre saying. I‚Äôm sure you saw last year, </span><a href="https://metr.org/blog/2025-07-10-early-2025-ai-experienced-os-dev-study/" rel="">there was a major study</a><span> where they had experienced developers try to close </span><a href="https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/about-pull-requests" rel="">pull requests</a><span> in repositories that they were familiar with. Those developers reported an uplift. They reported that they felt more productive with the use of these models. But in fact, if you look at their output and how much was actually merged back in, there was a 20% downlift. They were less productive as a result of using these models.</span></p><p>So I‚Äôm trying to square the qualitative feeling that people feel with these models versus, 1) in a macro level, where is this renaissance of software? And then 2) when people do these independent evaluations, why are we not seeing the productivity benefits we would expect?</p><p><strong>Dario Amodei</strong></p><p><span>Within Anthropic, this is just really unambiguous. We‚Äôre under an incredible amount of commercial pressure and make it even harder for ourselves because we have all this </span><a href="https://en.wikipedia.org/wiki/AI_safety" rel="">safety</a><span> stuff we do that I think we do more than other companies.</span></p><p>The pressure to survive economically while also keeping our values is just incredible. We‚Äôre trying to keep this 10x revenue curve going. There is zero time for bullshit. There is zero time for feeling like we‚Äôre productive when we‚Äôre not. These tools make us a lot more productive.</p><p><span>Why do you think we‚Äôre </span><a href="https://www.wired.com/story/anthropic-revokes-openais-access-to-claude/" rel="">concerned about competitors using the tools</a><span>? Because we think we‚Äôre ahead of the competitors. We wouldn‚Äôt be going through all this trouble if this were secretly reducing our productivity. We see the end productivity every few months in the form of model launches. There‚Äôs no kidding yourself about this. The models make you more productive.</span></p><p><strong>Dwarkesh Patel</strong></p><p>1) People feeling like they‚Äôre productive is qualitatively predicted by studies like this. But 2) if I just look at the end output, obviously you guys are making fast progress.</p><p>But the idea was supposed to be that with recursive self-improvement, you make a better AI, the AI helps you build a better next AI, et cetera, et cetera. What I see instead‚Äîif I look at you, OpenAI, DeepMind‚Äîis that people are just shifting around the podium every few months.</p><p>Maybe you think that stops because you‚Äôve won or whatever. But why are we not seeing the person with the best coding model have this lasting advantage if in fact there are these enormous productivity gains from the last coding model.</p><p><strong>Dario Amodei</strong></p><p>I think my model of the situation is that there‚Äôs an advantage that‚Äôs gradually growing. I would say right now the coding models give maybe, I don‚Äôt know, a 15-20% total factor speed up. That‚Äôs my view. Six months ago, it was maybe 5%. So it didn‚Äôt matter. 5% doesn‚Äôt register. It‚Äôs now just getting to the point where it‚Äôs one of several factors that kind of matters. That‚Äôs going to keep speeding up.</p><p>I think six months ago, there were several companies that were at roughly the same point because this wasn‚Äôt a notable factor, but I think it‚Äôs starting to speed up more and more. I would also say there are multiple companies that write models that are used for code and we‚Äôre not perfectly good at preventing some of these other companies from using our models internally. So I think everything we‚Äôre seeing is consistent with this kind of snowball model.</p><p><span>Again, my theme in all of this is all of this is soft </span><a href="https://www.lesswrong.com/w/ai-takeoff" rel="">takeoff</a><span>, soft, smooth exponentials, although the exponentials are relatively steep. So we‚Äôre seeing this snowball gather momentum where it‚Äôs like 10%, 20%, 25%, 40%. As you go, </span><a href="https://en.wikipedia.org/wiki/Amdahl%27s_law" rel="">Amdahl‚Äôs law</a><span>, you have to get all the things that are preventing you from closing the loop out of the way. But this is one of the biggest priorities within Anthropic.</span></p><p><strong>Dwarkesh Patel</strong></p><p>Stepping back, before in the stack we were talking about when do we get this on-the-job learning? It seems like the point you were making on the coding thing is that we actually don‚Äôt need on-the-job learning. You can have tremendous productivity improvements, you can have potentially trillions of dollars of revenue for AI companies, without this basic human ability to learn on the job. Maybe that‚Äôs not your claim, you should clarify.</p><p>But in most domains of economic activity, people say, ‚ÄúI hired somebody, they weren‚Äôt that useful for the first few months, and then over time they built up the context, understanding.‚Äù It‚Äôs actually hard to define what we‚Äôre talking about here. But they got something and then now they‚Äôre a powerhorse and they‚Äôre so valuable to us. If AI doesn‚Äôt develop this ability to learn on the fly, I‚Äôm a bit skeptical that we‚Äôre going to see huge changes to the world without that ability.</p><p><strong>Dario Amodei</strong></p><p>I think two things here. There‚Äôs the state of the technology right now. Again, we have these two stages. We have the pre-training and RL stage where you throw a bunch of data and tasks into the models and then they generalize. So it‚Äôs like learning, but it‚Äôs like learning from more data and not learning over one human or one model‚Äôs lifetime. So again, this is situated between evolution and human learning. But once you learn all those skills, you have them.</p><p><span>Just like with pre-training, just how the models know more, if I look at a pre-trained model, it knows more about the history of samurai in Japan than I do. It knows more about baseball than I do. It knows more about </span><a href="https://en.wikipedia.org/wiki/Low-pass_filter" rel="">low-pass filters</a><span> and electronics, all of these things. Its knowledge is way broader than mine. So I think even just that may get us to the point where the models are better at everything.</span></p><p><span>We also have, again, just with scaling the kind of existing setup, the in-context learning. I would describe it as kind of like human on-the-job learning, but a little weaker and a little short term. You look at in-context learning and if you give the model a bunch of examples it does get it. There‚Äôs real learning that happens in context. A million </span><a href="https://blogs.nvidia.com/blog/ai-tokens-explained/" rel="">tokens</a><span> is a lot. That can be days of human learning. If you think about the model reading a million words, how long would it take me to read a million? Days or weeks at least.</span></p><p>So you have these two things. I think these two things within the existing paradigm may just be enough to get you the ‚Äúcountry of geniuses in a data center‚Äù. I don‚Äôt know for sure, but I think they‚Äôre going to get you a large fraction of it. There may be gaps, but I certainly think that just as things are, this is enough to generate trillions of dollars of revenue. That‚Äôs one.</p><p>Two, is this idea of continual learning, this idea of a single model learning on the job. I think we‚Äôre working on that too. There‚Äôs a good chance that in the next year or two, we also solve that. Again, I think you get most of the way there without it. The trillions of dollars a year market, maybe all of the national security implications and the safety implications that I wrote about in ‚ÄúAdolescence of Technology‚Äù can happen without it. But we, and I imagine others, are working on it. There‚Äôs a good chance that we will get there within the next year or two.</p><p>There are a bunch of ideas. I won‚Äôt go into all of them in detail, but one is just to make the context longer. There‚Äôs nothing preventing longer contexts from working. You just have to train at longer contexts and then learn to serve them at inference. Both of those are engineering problems that we are working on and I would assume others are working on them as well.</p><p><strong>Dwarkesh Patel</strong></p><p><span>This context length increase, it seemed like there was a period from 2020 to 2023 where from </span><a href="https://en.wikipedia.org/wiki/GPT-3" rel="">GPT-3</a><span> to </span><a href="https://developers.openai.com/api/docs/models/gpt-4-turbo" rel="">GPT-4 Turbo</a><span>, there was an increase from 2000 context lengths to 128K. I feel like for the two-ish years since then, we‚Äôve been in the same-ish ballpark.</span></p><p>When context lengths get much longer than that, people report qualitative degradation in the ability of the model to consider that full context. So I‚Äôm curious what you‚Äôre internally seeing that makes you think, ‚Äú10 million contexts, 100 million contexts to get six months of human learning and building context‚Äù.</p><p><strong>Dario Amodei</strong></p><p><span>This isn‚Äôt a research problem. This is an engineering and inference problem. If you want to serve long context, you have to store your entire </span><a href="https://huggingface.co/blog/not-lain/kv-caching" rel="">KV cache</a><span>. It‚Äôs difficult to store all the memory in the GPUs, to juggle the memory around. I don‚Äôt even know the details. At this point, this is at a level of detail that I‚Äôm no longer able to follow, although I knew it in the GPT-3 era. ‚ÄúThese are the weights, these are the activations you have to store‚Ä¶‚Äù</span></p><p><span>But these days the whole thing is flipped because we have </span><a href="https://en.wikipedia.org/wiki/Mixture_of_experts" rel="">MoE</a><span> models and all of that. Regarding this degradation you‚Äôre talking about, without getting too specific, there‚Äôs two things. There‚Äôs the context length you train at and there‚Äôs a context length that you serve at. If you train at a small context length and then try to serve at a long context length, maybe you get these degradations. It‚Äôs better than nothing, you might still offer it, but you get these degradations. Maybe it‚Äôs harder to train at a long context length.</span></p><p><strong>Dwarkesh Patel</strong></p><p>I want to, at the same time, ask about maybe some rabbit holes. Wouldn‚Äôt you expect that if you had to train on longer context length, that would mean that you‚Äôre able to get less samples in for the same amount of compute? Maybe it‚Äôs not worth diving deep on that.</p><p>I want to get an answer to the bigger picture question. I don‚Äôt feel a preference for a human editor that‚Äôs been working for me for six months versus an AI that‚Äôs been working with me for six months, what year do you predict that that will be the case?</p><p><strong>Dario Amodei</strong></p><p>My guess for that is there‚Äôs a lot of problems where basically we can do this when we have the ‚Äúcountry of geniuses in a data center‚Äù. My picture for that, if you made me guess, is one to two years, maybe one to three years. It‚Äôs really hard to tell. I have a strong view‚Äî99%, 95%‚Äîthat all this will happen in 10 years. I think that‚Äôs just a super safe bet. I have a hunch‚Äîthis is more like a 50/50 thing‚Äîthat it‚Äôs going to be more like one to two, maybe more like one to three.</p><p><strong>Dwarkesh Patel</strong></p><p>So one to three years. Country of geniuses, and the slightly less economically valuable task of editing videos.</p><p><strong>Dario Amodei</strong></p><p>It seems pretty economically valuable, let me tell you. It‚Äôs just there are a lot of use cases like that. There are a lot of similar ones.</p><p><strong>Dwarkesh Patel</strong></p><p><span>So you‚Äôre predicting that within one to three years. And then, generally, Anthropic has </span><a href="https://www.anthropic.com/news/anthropic-s-recommendations-ostp-u-s-ai-action-plan" rel="">predicted</a><span> that by late ‚Äò26 or early ‚Äò27 we will have AI systems that ‚Äúhave the ability to navigate interfaces available to humans doing digital work today, intellectual capabilities matching or exceeding that of Nobel Prize winners, and the ability to interface with the physical world‚Äù. You gave </span><a href="https://www.nytimes.com/2025/12/07/business/dealbook/dario-amodei-dealbook.html" rel="">an interview two months ago with </a><em><a href="https://www.nytimes.com/2025/12/07/business/dealbook/dario-amodei-dealbook.html" rel="">DealBook</a></em><span> where you were emphasizing your company‚Äôs more responsible compute scaling as compared to your competitors.</span></p><p><span>I‚Äôm trying to square these two views. If you really believe that we‚Äôre going to have a country of geniuses, you want as big a data center as you can get. There‚Äôs no reason to slow down. The </span><a href="https://en.wikipedia.org/wiki/Total_addressable_market" rel="">TAM</a><span> of a Nobel Prize winner, that can actually do everything a Nobel Prize winner can do, is trillions of dollars. So I‚Äôm trying to square this conservatism, which seems rational if you have more moderate timelines, with your stated views about progress.</span></p><p><strong>Dario Amodei</strong></p><p>It actually all fits together. We go back to this fast, but not infinitely fast, diffusion. Let‚Äôs say that we‚Äôre making progress at this rate. The technology is making progress this fast. I have very high conviction that we‚Äôre going to get there within a few years. I have a hunch that we‚Äôre going to get there within a year or two. So there‚Äôs a little uncertainty on the technical side, but pretty strong confidence that it won‚Äôt be off by much.</p><p>What I‚Äôm less certain about is, again, the economic diffusion side. I really do believe that we could have models that are a country of geniuses in the data center in one to two years. One question is: How many years after that do the trillions in revenue start rolling in? I don‚Äôt think it‚Äôs guaranteed that it‚Äôs going to be immediate. It could be one year, it could be two years, I could even stretch it to five years although I‚Äôm skeptical of that.</p><p><span>So we have this uncertainty. Even if the technology goes as fast as I suspect that it will, we don‚Äôt know exactly how fast it‚Äôs going to drive revenue. We know it‚Äôs coming, but with the way you buy these data centers, if you‚Äôre off by a couple years, that can be ruinous. It is just like how I wrote in ‚Äú</span><a href="https://darioamodei.com/essay/machines-of-loving-grace" rel="">Machines of Loving Grace</a><span>‚Äù. I said I think we might get this powerful AI, this ‚Äúcountry of genius in the data center‚Äù. That description you gave comes from ‚ÄúMachines of Loving Grace‚Äù. I said we‚Äôll get that in 2026, maybe 2027. Again, that is my hunch. I wouldn‚Äôt be surprised if I‚Äôm off by a year or two, but that is my hunch.</span></p><p>Let‚Äôs say that happens. That‚Äôs the starting gun. How long does it take to cure all the diseases? That‚Äôs one of the ways that drives a huge amount of economic value. You cure every disease. There‚Äôs a question of how much of that goes to the pharmaceutical company or the AI company, but there‚Äôs an enormous consumer surplus because ‚Äîassuming we can get access for everyone, which I care about greatly‚Äîwe cure all of these diseases.</p><p><span>How long does it take? You have to do the biological discovery, you have to manufacture the new drug, you have to go through the regulatory process. We </span><a href="https://en.wikipedia.org/wiki/Operation_Warp_Speed" rel="">saw this with vaccines and COVID</a><span>. We got the vaccine out to everyone, but it took a year and a half. My question is: How long does it take to get the cure for everything‚Äîwhich AI is the genius that can in theory invent‚Äîout to everyone? How long from when that AI first exists in the lab to when diseases have actually been cured for everyone?</span></p><p><span>We‚Äôve had a polio vaccine for 50 years. We‚Äôre still trying to eradicate it in the most remote corners of Africa. The </span><a href="https://en.wikipedia.org/wiki/Gates_Foundation" rel="">Gates Foundation</a><span> is trying as hard as they can. Others are trying as hard as they can. But that‚Äôs difficult. Again, I don‚Äôt expect most of the economic diffusion to be as difficult as that. That‚Äôs the most difficult case. But there‚Äôs a real dilemma here. Where I‚Äôve settled on it is that it will be faster than anything we‚Äôve seen in the world, but it still has its limits.</span></p><p>So when we go to buying data centers, again, the curve I‚Äôm looking at is: we‚Äôve had a 10x a year increase every year. At the beginning of this year, we‚Äôre looking at $10 billion in annualized revenue. We have to decide how much compute to buy. It takes a year or two to actually build out the data centers, to reserve the data center.</p><p>Basically I‚Äôm saying, ‚ÄúIn 2027, how much compute do I get?‚Äù I could assume that the revenue will continue growing 10x a year, so it‚Äôll be $100 billion at the end of 2026 and $1 trillion at the end of 2027. Actually it would be $5 trillion dollars of compute because it would be $1 trillion a year for five years. I could buy $1 trillion of compute that starts at the end of 2027. If my revenue is not $1 trillion dollars, if it‚Äôs even $800 billion, there‚Äôs no force on earth, there‚Äôs no hedge on earth that could stop me from going bankrupt if I buy that much compute.</p><p>Even though a part of my brain wonders if it‚Äôs going to keep growing 10x, I can‚Äôt buy $1 trillion a year of compute in 2027. If I‚Äôm just off by a year in that rate of growth, or if the growth rate is 5x a year instead of 10x a year, then you go bankrupt. So you end up in a world where you‚Äôre supporting hundreds of billions, not trillions. You accept some risk that there‚Äôs so much demand that you can‚Äôt support the revenue, and you accept some risk that you got it wrong and it‚Äôs still slow.</p><p>When I talked about behaving responsibly, what I meant actually was not the absolute amount. I think it is true we‚Äôre spending somewhat less than some of the other players. It‚Äôs actually the other things, like have we been thoughtful about it or are we YOLOing and saying, ‚ÄúWe‚Äôre going to do $100 billion here or $100 billion there‚Äù? I get the impression that some of the other companies have not written down the spreadsheet, that they don‚Äôt really understand the risks they‚Äôre taking. They‚Äôre just doing stuff because it sounds cool.</p><p>We‚Äôve thought carefully about it. We‚Äôre an enterprise business. Therefore, we can rely more on revenue. It‚Äôs less fickle than consumer. We have better margins, which is the buffer between buying too much and buying too little. I think we bought an amount that allows us to capture pretty strong upside worlds. It won‚Äôt capture the full 10x a year. Things would have to go pretty badly for us to be in financial trouble. So we‚Äôve thought carefully and we‚Äôve made that balance. That‚Äôs what I mean when I say that we‚Äôre being responsible.</p><p><strong>Dwarkesh Patel</strong></p><p>So it seems like it‚Äôs possible that we actually just have different definitions of the ‚Äúcountry of a genius in a data center‚Äù. Because when I think of actual human geniuses, an actual country of human geniuses in a data center, I would happily buy $5 trillion worth of compute to run an actual country of human geniuses in a data center.</p><p>Let‚Äôs say JPMorgan or Moderna or whatever doesn‚Äôt want to use them. I‚Äôve got a country of geniuses. They‚Äôll start their own company. If they can‚Äôt start their own company and they‚Äôre bottlenecked by clinical trials‚Ä¶ It is worth stating that with clinical trials, most clinical trials fail because the drug doesn‚Äôt work. There‚Äôs not efficacy.</p><p><strong>Dario Amodei</strong></p><p>I make exactly that point in ‚ÄúMachines of Loving Grace‚Äù, I say the clinical trials are going to go much faster than we‚Äôre used to, but not infinitely fast.</p><p><strong>Dwarkesh Patel</strong></p><p>Okay, and then suppose it takes a year for the clinical trials to work out so that you‚Äôre getting revenue from that and can make more drugs. Okay, well, you‚Äôve got a country of geniuses and you‚Äôre an AI lab. You could use many more AI researchers. You also think there are these self-reinforcing gains from smart people working on AI tech. You can have the data center working on AI progress.</p><p><strong>Dario Amodei</strong></p><p>Are there substantially more gains from buying $1 trillion a year of compute versus $300 billion a year of compute?</p><p><strong>Dwarkesh Patel</strong></p><p>If your competitor is buying a trillion, yes there is.</p><p><strong>Dario Amodei</strong></p><p>Well, no, there‚Äôs some gain, but then again, there‚Äôs this chance that they go bankrupt before. Again, if you‚Äôre off by only a year, you destroy yourselves. That‚Äôs the balance. We‚Äôre buying a lot. We‚Äôre buying a hell of a lot. We‚Äôre buying an amount that‚Äôs comparable to what the biggest players in the game are buying.</p><p>But if you‚Äôre asking me, ‚ÄúWhy haven‚Äôt we signed $10 trillion of compute starting in mid-2027?‚Äù... First of all, it can‚Äôt be produced. There isn‚Äôt that much in the world. But second, what if the country of geniuses comes, but it comes in mid-2028 instead of mid-2027? You go bankrupt.</p><p><strong>Dwarkesh Patel</strong></p><p>So if your projection is one to three years, it seems like you should want $10 trillion of compute by 2029 at the latest? Even in the longest version of the timelines you state, the compute you are ramping up to build doesn‚Äôt seem in accordance.</p><p><strong>Dario Amodei</strong></p><p>What makes you think that?</p><p><strong>Dwarkesh Patel</strong></p><p>Human wages, let‚Äôs say, are on the order of $50 trillion a year‚Äî</p><p><strong>Dario Amodei</strong></p><p>So I won‚Äôt talk about Anthropic in particular, but if you talk about the industry, the amount of compute the industry is building this year is probably, call it, 10-15 gigawatts. It goes up by roughly 3x a year. So next year‚Äôs 30-40 gigawatts. 2028 might be 100 gigawatts. 2029 might be like 300 gigawatts. I‚Äôm doing the math in my head, but each gigawatt costs maybe $10 billion, on the order of $10-15 billion a year.</p><p>You put that all together and you‚Äôre getting about what you described. You‚Äôre getting exactly that. You‚Äôre getting multiple trillions a year by 2028 or 2029. You‚Äôre getting exactly what you predict.</p><p><strong>Dwarkesh Patel</strong></p><p>That‚Äôs for the industry.</p><p><strong>Dario Amodei</strong></p><p>That‚Äôs for the industry, that‚Äôs right.</p><p><strong>Dwarkesh Patel</strong></p><p>Suppose Anthropic‚Äôs compute keeps 3x-ing a year, and then by 2027-28, you have 10 gigawatts. Multiply that by, as you say, $10 billion. So then it‚Äôs like $100 billion a year. But then you‚Äôre saying the TAM by 2028 is $200 billion.</p><p><strong>Dario Amodei</strong></p><p>Again, I don‚Äôt want to give exact numbers for Anthropic, but these numbers are too small.</p><p><strong>Dwarkesh Patel</strong></p><p>Okay, interesting.</p><p><strong>Dwarkesh Patel</strong></p><p>You‚Äôve told investors that you plan to be profitable starting in 2028. This is the year when we‚Äôre potentially getting the country of geniuses as a data center. This is now going to unlock all this progress in medicine and health and new technologies. Wouldn‚Äôt this be exactly the time where you‚Äôd want to reinvest in the business and build bigger ‚Äúcountries‚Äù so they can make more discoveries?</p><p><strong>Dario Amodei</strong></p><p>Profitability is this kind of weird thing in this field. I don‚Äôt think in this field profitability is actually a measure of spending down versus investing in the business. Let‚Äôs just take a model of this. I actually think profitability happens when you underestimated the amount of demand you were going to get and loss happens when you overestimated the amount of demand you were going to get, because you‚Äôre buying the data centers ahead of time.</p><p>Think about it this way. Again, these are stylized facts. These numbers are not exact. I‚Äôm just trying to make a toy model here. Let‚Äôs say half of your compute is for training and half of your compute is for inference. The inference has some gross margin that‚Äôs more than 50%.</p><p>So what that means is that if you were in steady-state, you build a data center and if you knew exactly the demand you were getting, you would get a certain amount of revenue. Let‚Äôs say you pay $100 billion a year for compute. On $50 billion a year you support $150 billion of revenue. The other $50 billion is used for training. Basically you‚Äôre profitable and you make $50 billion of profit. Those are the economics of the industry today, or not today but where we‚Äôre projecting forward in a year or two.</p><p>The only thing that makes that not the case is if you get less demand than $50 billion. Then you have more than 50% of your data center for research and you‚Äôre not profitable. So you train stronger models, but you‚Äôre not profitable. If you get more demand than you thought, then research gets squeezed, but you‚Äôre kind of able to support more inference and you‚Äôre more profitable.</p><p>Maybe I‚Äôm not explaining it well, but the thing I‚Äôm trying to say is that you decide the amount of compute first. Then you have some target desire of inference versus training, but that gets determined by demand. It doesn‚Äôt get determined by you.</p><p><strong>Dwarkesh Patel</strong></p><p>What I‚Äôm hearing is the reason you‚Äôre predicting profit is that you are systematically underinvesting in compute?</p><p><strong>Dario Amodei</strong></p><p>No, no, no. I‚Äôm saying it‚Äôs hard to predict. These things about 2028 and when it will happen, that‚Äôs our attempt to do the best we can with investors. All of this stuff is really uncertain because of the cone of uncertainty. We could be profitable in 2026 if the revenue grows fast enough. If we overestimate or underestimate the next year, that could swing wildly.</p><p>What I‚Äôm trying to get at is that you have a model in your head of a business that invests, invests, invests, gets scale and then becomes profitable. There‚Äôs a single point at which things turn around. I don‚Äôt think the economics of this industry work that way.</p><p><strong>Dwarkesh Patel</strong></p><p>I see. So if I‚Äôm understanding correctly, you‚Äôre saying that because of the discrepancy between the amount of compute we should have gotten and the amount of compute we got, we were sort of forced to make profit. But that doesn‚Äôt mean we‚Äôre going to continue making profit. We‚Äôre going to reinvest the money because now AI has made so much progress and we want a bigger country of geniuses. So back into revenue is high, but losses are also high.</p><p><strong>Dario Amodei</strong></p><p>If every year we predict exactly what the demand is going to be, we‚Äôll be profitable every year. Because spending 50% of your compute on research, roughly, plus a gross margin that‚Äôs higher than 50% and correct demand prediction leads to profit. That‚Äôs the profitable business model that I think is kind of there, but obscured by these building ahead and prediction errors.</p><p><strong>Dwarkesh Patel</strong></p><p>I guess you‚Äôre treating the 50% as a sort of given constant, whereas in fact, if AI progress is fast and you can increase the progress by scaling up more, you should just have more than 50% and not make profit.</p><p><strong>Dario Amodei</strong></p><p>But here‚Äôs what I‚Äôll say. You might want to scale it up more. Remember the log returns to scale. If 70% would get you a very little bit of a smaller model through a factor of 1.4x... That extra $20 billion, each dollar there is worth much less to you because of the log-linear setup.</p><p>So you might find that it‚Äôs better to invest that $20 billion in serving inference or in hiring engineers who are kind of better at what they‚Äôre doing. So the reason I said 50%... That‚Äôs not exactly our target. It‚Äôs not exactly going to be 50%. It‚Äôll probably vary over time.</p><p>What I‚Äôm saying is the log-linear return, what it leads to is you spend of order one fraction of the business. Like not 5%, not 95%. Then you get diminishing returns.</p><p><strong>Dwarkesh Patel</strong></p><p>I feel strange that I‚Äôm convincing Dario to believe in AI progress or something. Okay, you don‚Äôt invest in research because it has diminishing returns, but you invest in the other things you mentioned. I think profit at a sort of macro level‚Äî</p><p><strong>Dario Amodei</strong></p><p>Again, I‚Äôm talking about diminishing returns, but after you‚Äôre spending $50 billion a year.</p><p><strong>Dwarkesh Patel</strong></p><p>This is a point I‚Äôm sure you would make, but diminishing returns on a genius could be quite high.</p><p>More generally, what is profit in a market economy? Profit is basically saying other companies in the market can do more things with this money than I can.</p><p><strong>Dario Amodei</strong></p><p>Put aside Anthropic. I don‚Äôt want to give information about Anthropic. That‚Äôs why I‚Äôm giving these stylized numbers. But let‚Äôs just derive the equilibrium of the industry. Why doesn‚Äôt everyone spend 100% of their compute on training and not serve any customers? It‚Äôs because if they didn‚Äôt get any revenue, they couldn‚Äôt raise money, they couldn‚Äôt do compute deals, they couldn‚Äôt buy more compute the next year.</p><p>So there‚Äôs going to be an equilibrium where every company spends less than 100% on training and certainly less than 100% on inference. It should be clear why you don‚Äôt just serve the current models and never train another model, because then you don‚Äôt have any demand because you‚Äôll fall behind. So there‚Äôs some equilibrium. It‚Äôs not gonna be 10%, it‚Äôs not gonna be 90%. Let‚Äôs just say as a stylized fact, it‚Äôs 50%. That‚Äôs what I‚Äôm getting at.</p><p>I think we‚Äôre gonna be in a position where that equilibrium of how much you spend on training is less than the gross margins that you‚Äôre able to get on compute. So the underlying economics are profitable. The problem is you have this hellish demand prediction problem when you‚Äôre buying the next year of compute and you might guess under and be very profitable but have no compute for research. Or you might guess over and you are not profitable and you have all the compute for research in the world. Does that make sense? Just as a dynamic model of the industry?</p><p><strong>Dwarkesh Patel</strong></p><p>Maybe stepping back, I‚Äôm not saying I think the ‚Äúcountry of geniuses‚Äù is going to come in two years and therefore you should buy this compute. To me, the end conclusion you‚Äôre arriving at makes a lot of sense. But that‚Äôs because it seems like ‚Äúcountry of geniuses‚Äù is hard and there‚Äôs a long way to go. So stepping back, the thing I‚Äôm trying to get at is more that it seems like your worldview is compatible with somebody who says, ‚ÄúWe‚Äôre like 10 years away from a world in which we‚Äôre generating trillions of dollars of value.‚Äù</p><p><strong>Dario Amodei</strong></p><p>That‚Äôs just not my view. So I‚Äôll make another prediction. It is hard for me to see that there won‚Äôt be trillions of dollars in revenue before 2030. I can construct a plausible world. It takes maybe three years. That would be the end of what I think it‚Äôs plausible.</p><p>Like in 2028, we get the real ‚Äúcountry of geniuses in the data center‚Äù. The revenue‚Äôs going into the low hundreds of billions by 2028, and then the country of geniuses accelerates it to trillions. We‚Äôre basically on the slow end of diffusion. It takes two years to get to the trillions. That would be the world where it takes until 2030. I suspect even composing the technical exponential and diffusion exponential, we‚Äôll get there before 2030.</p><p><strong>Dwarkesh Patel</strong></p><p>So you laid out a model where Anthropic makes profit because it seems like fundamentally we‚Äôre in a compute-constrained world. So eventually we keep growing compute‚Äî</p><p><strong>Dario Amodei</strong></p><p>I think the way the profit comes is‚Ä¶ Again, let‚Äôs just abstract the whole industry here. Let‚Äôs just imagine we‚Äôre in an economics textbook. We have a small number of firms. Each can invest a limited amount. Each can invest some fraction in R&amp;D. They have some marginal cost to serve. The gross profit margins on that marginal cost are very high because inference is efficient. There‚Äôs some competition, but the models are also differentiated.</p><p><span>Companies will compete to push their research budgets up. But because there‚Äôs a small number of players, we have the... What is it called? The </span><a href="https://en.wikipedia.org/wiki/Cournot_competition" rel="">Cournot equilibrium</a><span>, I think, is what the small number of firm equilibrium is. The point is it doesn‚Äôt equilibrate to perfect competition with zero margins. If there‚Äôs three firms in the economy and all are kind of independently behaving rationally, it doesn‚Äôt equilibrate to zero.</span></p><p><strong>Dwarkesh Patel</strong></p><p>Help me understand that, because right now we do have three leading firms and they‚Äôre not making profit. So what is changing?</p><p><strong>Dario Amodei</strong></p><p>Again, the gross margins right now are very positive. What‚Äôs happening is a combination of two things. One is that we‚Äôre still in the exponential scale-up phase of compute. A model gets trained. Let‚Äôs say a model got trained that costs $1 billion last year. Then this year it produced $4 billion of revenue and cost $1 billion to inference from. Again, I‚Äôm using stylized numbers here, but that would be 75% gross margins and this 25% tax. So that model as a whole makes $2 billion.</p><p>But at the same time, we‚Äôre spending $10 billion to train the next model because there‚Äôs an exponential scale-up. So the company loses money. Each model makes money, but the company loses money.</p><p>The equilibrium I‚Äôm talking about is an equilibrium where we have the ‚Äúcountry of geniuses in a data center‚Äù, but that model training scale-up has equilibrated more. Maybe it‚Äôs still going up. We‚Äôre still trying to predict the demand, but it‚Äôs more leveled out.</p><p><strong>Dwarkesh Patel</strong></p><p>I‚Äôm confused about a couple of things there. Let‚Äôs start with the current world. In the current world, you‚Äôre right that, as you said before, if you treat each individual model as a company, it‚Äôs profitable. But of course, a big part of the production function of being a frontier lab is training the next model, right?</p><p><strong>Dario Amodei</strong></p><p>Yes, that‚Äôs right.</p><p><strong>Dwarkesh Patel</strong></p><p>If you didn‚Äôt do that, then you‚Äôd make profit for two months and then you wouldn‚Äôt have margins because you wouldn‚Äôt have the best model.</p><p><strong>Dario Amodei</strong></p><p>But at some point that reaches the biggest scale that it can reach. And then in equilibrium, we have algorithmic improvements, but we‚Äôre spending roughly the same amount to train the next model as we spend to train the current model. At some point you run out of money in the economy.</p><p><strong>Dwarkesh Patel</strong></p><p><span>A fixed </span><a href="https://en.wikipedia.org/wiki/Lump_of_labour_fallacy" rel="">lump of labor fallacy</a><span>‚Ä¶ The economy is going to grow, right? That‚Äôs one of your predictions. </span><a href="https://www.dwarkesh.com/p/elon-musk" rel="">We‚Äôre going to have the data centers in space</a><span>.</span></p><p><strong>Dario Amodei</strong></p><p>Yes, but this is another example of the theme I was talking about. The economy will grow much faster with AI than I think it ever has before. Right now the compute is growing 3x a year. I don‚Äôt believe the economy is gonna grow 300% a year. I said this in ‚ÄúMachines of Loving Grace‚Äù, I think we may get 10-20% per year growth in the economy, but we‚Äôre not gonna get 300% growth in the economy. So I think in the end, if compute becomes the majority of what the economy produces, it‚Äôs gonna be capped by that.</p><p><strong>Dwarkesh Patel</strong></p><p>So let‚Äôs assume a model where compute stays capped. The world where frontier labs are making money is one where they continue to make fast progress. Because fundamentally your margin is limited by how good the alternative is. So you are able to make money because you have a frontier model. If you didn‚Äôt have a frontier model you wouldn‚Äôt be making money. So this model requires there never to be a steady state. Forever and ever you keep making more algorithmic progress.</p><p><strong>Dario Amodei</strong></p><p>I don‚Äôt think that‚Äôs true. I mean, I feel like we‚Äôre in an economics class.</p><p><strong>Dwarkesh Patel</strong></p><p><span>Do you know the </span><a href="https://www.dwarkesh.com/p/tyler-cowen-4" rel="">Tyler Cowen</a><span> quote? We never stop talking about economics.</span></p><p><strong>Dario Amodei</strong></p><p>We never stop talking about economics. So no, I don‚Äôt think this field‚Äôs going to be a monopoly. All my lawyers never want me to say the word ‚Äúmonopoly‚Äù. But I don‚Äôt think this field‚Äôs going to be a monopoly. You do get industries in which there are a small number of players. Not one, but a small number of players.</p><p><span>Ordinarily, the way you get monopolies like Facebook or Meta‚ÄîI always call them Facebook‚Äîis these kinds of </span><a href="https://en.wikipedia.org/wiki/Network_effect" rel="">network effects</a><span>. The way you get industries in which there are a small number of players, is very high costs of entry. </span><a href="https://en.wikipedia.org/wiki/Cloud_computing" rel="">Cloud</a><span> is like this. I think cloud is a good example of this. There are three, maybe four, players within cloud. I think that‚Äôs the same for AI, three, maybe four.</span></p><p>The reason is that it‚Äôs so expensive. It requires so much expertise and so much capital to run a cloud company. You have to put up all this capital. In addition to putting up all this capital, you have to get all of this other stuff that requires a lot of skill to make it happen.</p><p>So if you go to someone and you‚Äôre like, ‚ÄúI want to disrupt this industry, here‚Äôs $100 billion.‚Äù You‚Äôre like, ‚Äúokay, I‚Äôm putting in $100 billion and also betting that you can do all these other things that these people have been doing.‚Äù</p><p><strong>Dwarkesh Patel</strong></p><p>Only to decrease the profit.</p><p><strong>Dario Amodei</strong></p><p>The effect of your entering is that profit margins go down. So, we have equilibria like this all the time in the economy where we have a few players. Profits are not astronomical. Margins are not astronomical, but they‚Äôre not zero. That‚Äôs what we see on cloud. Cloud is very undifferentiated. Models are more differentiated than cloud.</p><p><span>Everyone knows Claude is good at different things than GPT is good at, than </span><a href="https://en.wikipedia.org/wiki/Google_Gemini" rel="">Gemini</a><span> is good at. It‚Äôs not just that Claude‚Äôs good at coding, GPT is good at math and reasoning. It‚Äôs more subtle than that. Models are good at different types of coding. Models have different styles. I think these things are actually quite different from each other, and so I would expect more differentiation than you see in cloud.</span></p><p>Now, there actually is one counter-argument. That counter-argument is if the process of producing models, if AI models can do that themselves, then that could spread throughout the economy. But that is not an argument for commoditizing AI models in general. That‚Äôs kind of an argument for commoditizing the whole economy at once.</p><p>I don‚Äôt know what quite happens in that world where basically anyone can do anything, anyone can build anything, and there‚Äôs no moat around anything at all. I don‚Äôt know, maybe we want that world. Maybe that‚Äôs the end state here. Maybe when AI models can do everything, if we‚Äôve solved all the safety and security problems, that‚Äôs one of the mechanisms for the economy just flattening itself again. But that‚Äôs kind of far post-‚Äùcountry of geniuses in the data center.‚Äù</p><p><strong>Dwarkesh Patel</strong></p><p>Maybe a finer way to put that potential point is: 1) it seems like AI research is especially loaded on raw intellectual power, which will be especially abundant in the world of AGI. And 2) if you just look at the world today, there are very few technologies that seem to be diffusing as fast as AI algorithmic progress. So that does hint that this industry is sort of structurally diffusive.</p><p><strong>Dario Amodei</strong></p><p>I think coding is going fast, but I think AI research is a superset of coding and there are aspects of it that are not going fast. But I do think, again, once we get coding, once we get AI models going fast, then that will speed up the ability of AI models to do everything else. So while coding is going fast now, I think once the AI models are building the next AI models and building everything else, the whole economy will kind of go at the same pace.</p><p>I am worried geographically, though. I‚Äôm a little worried that just proximity to AI, having heard about AI, may be one differentiator. So when I said the 10-20% growth rate, a worry I have is that the growth rate could be like 50% in Silicon Valley and parts of the world that are socially connected to Silicon Valley, and not that much faster than its current pace elsewhere. I think that‚Äôd be a pretty messed up world. So one of the things I think about a lot is how to prevent that.</p><p><strong>Dwarkesh Patel</strong></p><p>Do you think that once we have this country of geniuses in a data center, that robotics is sort of quickly solved afterwards? Because it seems like a big problem with robotics is that a human can learn how to teleoperate current hardware, but current AI models can‚Äôt, at least not in a way that‚Äôs super productive. And so if we have this ability to learn like a human, shouldn‚Äôt it solve robotics immediately as well?</p><p><strong>Dario Amodei</strong></p><p>I don‚Äôt think it‚Äôs dependent on learning like a human. It could happen in different ways. Again, we could have trained the model on many different video games, which are like robotic controls, or many different simulated robotics environments, or just train them to control computer screens, and they learn to generalize.</p><p>So it will happen... it‚Äôs not necessarily dependent on human-like learning. Human-like learning is one way it could happen. If the model‚Äôs like, ‚ÄúOh, I pick up a robot, I don‚Äôt know how to use it, I learn,‚Äù that could happen because we discovered continual learning. That could also happen because we trained the model on a bunch of environments and then generalized, or it could happen because the model learns that in the context length. It doesn‚Äôt actually matter which way. If we go back to the discussion we had an hour ago, that type of thing can happen in several different ways.</p><p>But I do think when for whatever reason the models have those skills, then robotics will be revolutionized‚Äîboth the design of robots, because the models will be much better than humans at that, and also the ability to control robots. So we‚Äôll get better at building the physical hardware, building the physical robots, and we‚Äôll also get better at controlling it.</p><p>Now, does that mean the robotics industry will also be generating trillions of dollars of revenue? My answer there is yes, but there will be the same extremely fast, but not infinitely fast diffusion. So will robotics be revolutionized? Yeah, maybe tack on another year or two. That‚Äôs the way I think about these things.</p><p><strong>Dwarkesh Patel</strong></p><p>Makes sense. There‚Äôs a general skepticism about extremely fast progress. Here‚Äôs my view. It sounds like you are going to solve continual learning one way or another within a matter of years. But just as people weren‚Äôt talking about continual learning a couple of years ago, and then we realized, ‚ÄúOh, why aren‚Äôt these models as useful as they could be right now, even though they are clearly passing the Turing test and are experts in so many different domains? Maybe it‚Äôs this thing.‚Äù</p><p>Then we solve this thing and we realize, actually, there‚Äôs another thing that human intelligence can do that‚Äôs a basis of human labor that these models can‚Äôt do. So why not think there will be more things like this, where we‚Äôve found more pieces of human intelligence?</p><p><strong>Dario Amodei</strong></p><p><span>Well, to be clear, I think </span><a href="https://www.ibm.com/think/topics/continual-learning" rel="">continual learning</a><span>, as I‚Äôve said before, might not be a barrier at all. I think we may just get there by pre-training generalization and RL generalization. I think there just might not be such a thing at all.</span></p><p><span>In fact, I would point to the history in </span><a href="https://en.wikipedia.org/wiki/Machine_learning" rel="">ML</a><span> of people coming up with things that are barriers that end up kind of dissolving within the big blob of compute. People talked about, ‚ÄúHow do your models keep track of nouns and verbs?‚Äù ‚ÄúThey can understand syntactically, but they can‚Äôt understand semantically? It‚Äôs only statistical correlations.‚Äù ‚ÄúYou can understand a paragraph, you can‚Äôt understand a word. There‚Äôs reasoning, you can‚Äôt do reasoning.‚Äù But then suddenly it turns out you can do code and math very well.</span></p><p>So I think there‚Äôs actually a stronger history of some of these things seeming like a big deal and then kind of dissolving. Some of them are real. The need for data is real, maybe continual learning is a real thing.</p><p>But again, I would ground us in something like code. I think we may get to the point in a year or two where the models can just do SWE end-to-end. That‚Äôs a whole task. That‚Äôs a whole sphere of human activity that we‚Äôre just saying models can do now.</p><p><strong>Dwarkesh Patel</strong></p><p>When you say end-to-end, do you mean setting technical direction, understanding the context of the problem, et cetera?</p><p><strong>Dario Amodei</strong></p><p>Yes. I mean all of that.</p><p><strong>Dwarkesh Patel</strong></p><p>Interesting. I feel like that is AGI-complete, which maybe is internally consistent. But it‚Äôs not like saying 90% of code or 100% of code.</p><p><strong>Dario Amodei</strong></p><p>No, I gave this spectrum: 90% of code, 100% of code, 90% of end-to-end SWE, 100% of end-to-end SWE. New tasks are created for SWEs. Eventually those get done as well. It‚Äôs a long spectrum there, but we‚Äôre traversing the spectrum very quickly.</p><p><strong>Dwarkesh Patel</strong></p><p><span>I do think it‚Äôs funny that I‚Äôve seen a couple of podcasts you‚Äôve done where the hosts will be like, ‚ÄúBut Dwarkesh wrote </span><a href="https://www.dwarkesh.com/p/timelines-june-2025" rel="">the essay about the continuous learning thing</a><span>.‚Äù It always makes me crack up because you‚Äôve been an AI researcher for 10 years. I‚Äôm sure there‚Äôs some feeling of, ‚ÄúOkay, so a podcaster wrote an essay, and every interview I get asked about it.‚Äù</span></p><p><strong>Dario Amodei</strong></p><p>The truth of the matter is that we‚Äôre all trying to figure this out together. There are some ways in which I‚Äôm able to see things that others aren‚Äôt. These days that probably has more to do with seeing a bunch of stuff within Anthropic and having to make a bunch of decisions than I have any great research insight that others don‚Äôt.</p><p>I‚Äôm running a 2,500 person company. It‚Äôs actually pretty hard for me to have concrete research insight, much harder than it would have been 10 years ago or even two or three years ago.</p><p><strong>Dwarkesh Patel</strong></p><p><span>As we go towards a world of a full drop-in remote worker replacement, does an </span><a href="https://en.wikipedia.org/wiki/API" rel="">API</a><span> pricing model still make the most sense? If not, what is the correct way to price AGI, or serve AGI?</span></p><p><strong>Dario Amodei</strong></p><p>I think there‚Äôs going to be a bunch of different business models here, all at once, that are going to be experimented with. I actually do think that the API model is more durable than many people think. One way I think about it is if the technology is advancing quickly, if it‚Äôs advancing exponentially, what that means is there‚Äôs always a surface area of new use cases that have been developed in the last three months.</p><p>Any kind of product surface you put in place is always at risk of sort of becoming irrelevant. Any given product surface probably makes sense for a range of capabilities of the model. The chatbot is already running into limitations where making it smarter doesn‚Äôt really help the average consumer that much. But I don‚Äôt think that‚Äôs a limitation of AI models. I don‚Äôt think that‚Äôs evidence that the models are good enough and them getting better doesn‚Äôt matter to the economy. It doesn‚Äôt matter to that particular product.</p><p>So I think the value of the API is that the API always offers an opportunity, very close to the bare metal, to build on what the latest thing is. There‚Äôs always going to be this front of new startups and new ideas that weren‚Äôt possible a few months ago and are possible because the model is advancing.</p><p>I actually predict that it‚Äôs going to exist alongside other models, but we‚Äôre always going to have the API business model because there‚Äôs always going to be a need for a thousand different people to try experimenting with the model in a different way. 100 of them become startups and ten of them become big successful startups. Two or three really end up being the way that people use the model of a given generation.</p><p>So I basically think it‚Äôs always going to exist. At the same time, I‚Äôm sure there‚Äôs going to be other models as well. Not every token that‚Äôs output by the model is worth the same amount. Think about what is the value of the tokens that the model outputs when someone calls them up and says, ‚ÄúMy Mac isn‚Äôt working,‚Äù or something, the model‚Äôs like, ‚Äúrestart it.‚Äù Someone hasn‚Äôt heard that before, but the model said that 10 million times. Maybe that‚Äôs worth like a dollar or a few cents or something.</p><p>Whereas if the model goes to one of the pharmaceutical companies and it says, ‚ÄúOh, you know, this molecule you‚Äôre developing, you should take the aromatic ring from that end of the molecule and put it on that end of the molecule. If you do that, wonderful things will happen.‚Äù Those tokens could be worth tens of millions of dollars.</p><p>So I think we‚Äôre definitely going to see business models that recognize that. At some point we‚Äôre going to see ‚Äúpay for results‚Äù in some form, or we may see forms of compensation that are like labor, that kind of work by the hour. I don‚Äôt know. I think because it‚Äôs a new industry, a lot of things are going to be tried. I don‚Äôt know what will turn out to be the right thing.</p><p><strong>Dwarkesh Patel</strong></p><p>I take your point that people will have to try things to figure out what is the best way to use this blob of intelligence. But what I find striking is Claude Code. I don‚Äôt think in the history of startups there has been a single application that has been as hotly competed in as coding agents. Claude Code is a category leader here. That seems surprising to me.</p><p>It doesn‚Äôt seem intrinsically that Anthropic had to build this. I wonder if you have an accounting of why it had to be Anthropic or how Anthropic ended up building an application in addition to the model underlying it that was successful.</p><p><strong>Dario Amodei</strong></p><p>So it actually happened in a pretty simple way, which is that we had our own coding models, which were good at coding. Around the beginning of 2025, I said, ‚ÄúI think the time has come where you can have nontrivial acceleration of your own research if you‚Äôre an AI company by using these models.‚Äù Of course, you need an interface, you need a harness to use them.</p><p>So I encouraged people internally. I didn‚Äôt say this is one thing that you have to use. I just said people should experiment with this. I think it might have been originally called Claude CLI, and then the name eventually got changed to Claude Code. Internally, it was the thing that everyone was using and it was seeing fast internal adoption.</p><p>I looked at it and I said, ‚ÄúProbably we should launch this externally, right?‚Äù It‚Äôs seen such fast adoption within Anthropic. Coding is a lot of what we do. We have an audience of many, many hundreds of people that‚Äôs in some ways at least representative of the external audience. So it looks like we already have product market fit. Let‚Äôs launch this thing.</p><p>And then we launched it. I think just the fact that we ourselves are kind of developing the model and we ourselves know what we most need to use the model, I think it‚Äôs kind of creating this feedback loop.</p><p><strong>Dwarkesh Patel</strong></p><p>I see. In the sense that you, let‚Äôs say a developer at Anthropic is like, ‚ÄúAh, it would be better if it was better at this X thing.‚Äù Then you bake that into the next model that you build.</p><p><strong>Dario Amodei</strong></p><p>That‚Äôs one version of it, but then there‚Äôs just the ordinary product iteration. We have a bunch of coders within Anthropic, they use Claude Code every day and so we get fast feedback. That was more important in the early days. Now, of course, there are millions of people using it, and so we get a bunch of external feedback as well. But it‚Äôs just great to be able to get kind of fast internal feedback.</p><p>I think this is the reason why we launched a coding model and didn‚Äôt launch a pharmaceutical company. My background‚Äôs in biology, but we don‚Äôt have any of the resources that are needed to launch a pharmaceutical company.</p><p><strong>Dwarkesh Patel</strong></p><p>Let me now ask you about making AI go well. It seems like whatever vision we have about how AI goes well has to be compatible with two things: 1) the ability to build and run AIs is diffusing extremely rapidly and 2) the population of AIs, the amount we have and their intelligence, will also increase very rapidly.</p><p><span>That means that lots of people will be able to build huge populations of misaligned AIs, or AIs which are just companies which are trying to increase their footprint or have weird psyches like </span><a href="https://en.wikipedia.org/wiki/Sydney_(Microsoft)" rel="">Sydney Bing</a><span>, but now they‚Äôre superhuman. What is a vision for a world in which we have an equilibrium that is compatible with lots of different AIs, some of which are misaligned, running around?</span></p><p><strong>Dario Amodei</strong></p><p>I think in ‚ÄúThe Adolescence of Technology‚Äù, I was skeptical of the balance of power. But the thing I was specifically skeptical of is you have three or four of these companies all building models that are derived from the same thing, that they would check each other. Or even that any number of them would check each other.</p><p><strong>Dario Amodei</strong></p><p>We might live in an offense-dominant world where one person or one AI model is smart enough to do something that causes damage for everything else. In the short run, we have a limited number of players now. So we can start within the limited number of players. We need to put in place the safeguards. We need to make sure everyone does the right alignment work. We need to make sure everyone has bioclassifiers. Those are the immediate things we need to do.</p><p>I agree that that doesn‚Äôt solve the problem in the long run, particularly if the ability of AI models to make other AI models proliferates, then the whole thing can become harder to solve. I think in the long run we need some architecture of governance. We need some architecture of governance that preserves human freedom, but also allows us to govern a very large number of human systems, AI systems, hybrid human-AI companies or economic units.</p><p><span>So we‚Äôre gonna need to think about: how do we protect the world against bioterrorism? How do we protect the world against </span><a href="https://en.wikipedia.org/wiki/Mirror-image_life" rel="">mirror life</a><span>? Probably we‚Äôre gonna need some kind of AI monitoring system that monitors for all of these things. But then we need to build this in a way that preserves civil liberties and our constitutional rights. So I think just as anything else, it‚Äôs a new security landscape with a new set of tools and a new set of vulnerabilities.</span></p><p>My worry is, if we had 100 years for this to happen all very slowly, we‚Äôd get used to it. We‚Äôve gotten used to the presence of explosives in society or the presence of various new weapons or the presence of video cameras. We would get used to it over 100 years and we‚Äôd develop governance mechanisms. We‚Äôd make our mistakes. My worry is just that this is happening all so fast. So maybe we need to do our thinking faster about how to make these governance mechanisms work.</p><p><strong>Dwarkesh Patel</strong></p><p>It seems like in an offense-dominant world, over the course of the next century‚Äîthe idea is that AI is making the progress that would happen over the next century happen in some period of five to ten years‚Äîwe would still need the same mechanisms, or balance of power would be similarly intractable, even if humans were the only game in town.</p><p>I guess we have the advice of AI. But it fundamentally doesn‚Äôt seem like a totally different ball game here. If checks and balances were going to work, they would work with humans as well. If they aren‚Äôt going to work, they wouldn‚Äôt work with AIs as well. So maybe this just dooms human checks and balances as well.</p><p><strong>Dario Amodei</strong></p><p>Again, I think there‚Äôs some way to make this happen. The governments of the world may have to work together to make it happen. We may have to talk to AIs about building societal structures in such a way that these defenses are possible. I don‚Äôt know. I don‚Äôt want to say this is so far ahead in time, but it‚Äôs so far ahead in technological ability that may happen over a short period of time, that it‚Äôs hard for us to anticipate it in advance.</p><p><strong>Dwarkesh Patel</strong></p><p><span>Speaking of governments getting involved, on December 26, the </span><a href="https://natlawreview.com/article/tennessees-ai-bill-would-criminalize-training-ai-cha" rel="">Tennessee legislature introduced a bill</a><span> which said, ‚ÄúIt would be an offense for a person to knowingly train artificial intelligence to provide emotional support, including through open-ended conversations with a user.‚Äù Of course, one of the things that Claude attempts to do is be a thoughtful, knowledgeable friend.</span></p><p>In general, it seems like we‚Äôre going to have this patchwork of state laws. A lot of the benefits that normal people could experience as a result of AI are going to be curtailed, especially when we get into the kinds of things you discuss in ‚ÄúMachines of Loving Grace‚Äù: biological freedom, mental health improvements, et cetera.</p><p>It seems easy to imagine worlds in which these get Whac-A-Moled away by different laws, whereas bills like this don‚Äôt seem to address the actual existential threats that you‚Äôre concerned about. I‚Äôm curious to understand, in the context of things like this, Anthropic‚Äôs position against the federal moratorium on state AI laws.</p><p><strong>Dario Amodei</strong></p><p>There are many different things going on at once. I think that particular law is dumb. It was clearly made by legislators who just probably had little idea what AI models could do and not do. They‚Äôre like, ‚ÄúAI models serving us, that just sounds scary. I don‚Äôt want that to happen.‚Äù So we‚Äôre not in favor of that.</p><p>But that wasn‚Äôt the thing that was being voted on. The thing that was being voted on is: we‚Äôre going to ban all state regulation of AI for 10 years with no apparent plan to do any federal regulation of AI, which would take Congress to pass, which is a very high bar. So the idea that we‚Äôd ban states from doing anything for 10 years‚Ä¶ People said they had a plan for the federal government, but there was no actual proposal on the table. There was no actual attempt.</p><p>Given the serious dangers that I lay out in ‚ÄúAdolescence of Technology‚Äù around things like biological weapons and bioterrorism autonomy risk, and the timelines we‚Äôve been talking about‚Äî10 years is an eternity‚ÄîI think that‚Äôs a crazy thing to do. So if that‚Äôs the choice, if that‚Äôs what you force us to choose, then we‚Äôre going to choose not to have that moratorium. I think the benefits of that position exceed the costs, but it‚Äôs not a perfect position if that‚Äôs the choice.</p><p>Now, I think the thing that we should do, the thing that I would support, is the federal government should step in, not saying ‚Äústates you can‚Äôt regulate‚Äù, but ‚ÄúHere‚Äôs what we‚Äôre going to do, and states you can‚Äôt differ from this.‚Äù I think preemption is fine in the sense of saying that the federal government says, ‚ÄúHere is our standard. This applies to everyone. States can‚Äôt do something different.‚Äù</p><p>That would be something I would support if it would be done in the right way. But this idea of states, ‚ÄúYou can‚Äôt do anything and we‚Äôre not doing anything either,‚Äù that struck us as very much not making sense. I think it will not age well, it is already starting to not age well with all the backlash that you‚Äôve seen.</p><p>Now, in terms of what we would want, the things we‚Äôve talked about are starting with transparency standards in order to monitor some of these autonomy risks and bioterrorism risks. As the risks become more serious, as we get more evidence for them, then I think we could be more aggressive in some targeted ways and say, ‚ÄúHey, AI bioterrorism is really a threat. Let‚Äôs pass a law that forces people to have classifiers.‚Äù</p><p>I could even imagine‚Ä¶ It depends. It depends how serious the threat it ends up being. We don‚Äôt know for sure. We need to pursue this in an intellectually honest way where we say that ahead of time, the risk has not emerged yet. But I could certainly imagine, with the pace that things are going at, a world where later this year we say, ‚ÄúHey, this AI bioterrorism stuff is really serious. We should do something about it. We should put it in a federal standard. If the federal government won‚Äôt act, we should put it in a state standard.‚Äù I could totally see that.</p><p><strong>Dwarkesh Patel</strong></p><p>I‚Äôm concerned about a world where if you just consider the pace of progress you‚Äôre expecting, the life cycle of legislation... The benefits are, as you say because of diffusion lag, slow enough that I really do think this patchwork of state laws, on the current trajectory, would prohibit. I mean if having an emotional chatbot friend is something that freaks people out, then just imagine the kinds of actual benefits from AI we want normal people to be able to experience. From improvements in health and healthspan and improvements in mental health and so forth.</p><p>Whereas at the same time, it seems like you think the dangers are already on the horizon and I just don‚Äôt see that much‚Ä¶ It seems like it would be especially injurious to the benefits of AI as compared to the dangers of AI. So that‚Äôs maybe where the cost benefit makes less sense to me.</p><p><strong>Dario Amodei</strong></p><p>So there‚Äôs a few things here. People talk about there being thousands of these state laws. First of all, the vast, vast majority of them do not pass. The world works a certain way in theory, but just because a law has been passed doesn‚Äôt mean it‚Äôs really enforced. The people implementing it may be like, ‚ÄúOh my God, this is stupid. It would mean shutting off everything that‚Äôs ever been built in Tennessee.‚Äù Very often, laws are interpreted in a way that makes them not as dangerous or harmful. On the same side, of course, you have to worry if you‚Äôre passing a law to stop a bad thing; you have this problem as well.</p><p>My basic view is that if we could decide what laws were passed and how things were done‚Äîand we‚Äôre only one small input into that‚ÄîI would deregulate a lot of the stuff around the health benefits of AI. I don‚Äôt worry as much about the chatbot laws. I actually worry more about the drug approval process, where I think AI models are going to greatly accelerate the rate at which we discover drugs, and the pipeline will get jammed up. The pipeline will not be prepared to process all the stuff that‚Äôs going through it.</p><p>I think reform of the regulatory process should bias more towards the fact that we have a lot of things coming where the safety and efficacy is actually going to be really crisp and clear, a beautiful thing, and really effective. Maybe we don‚Äôt need all this superstructure around it that was designed around an era of drugs that barely work and often have serious side effects.</p><p>At the same time, I think we should be ramping up quite significantly the safety and security legislation. Like I‚Äôve said, starting with transparency is my view of trying not to hamper the industry, trying to find the right balance. I‚Äôm worried about it. Some people criticize my essay for saying, ‚ÄúThat‚Äôs too slow. The dangers of AI will come too soon if we do that.‚Äù</p><p>Well, basically, I think the last six months and maybe the next few months are going to be about transparency. Then, if these risks emerge when we‚Äôre more certain of them‚Äîwhich I think we might be as soon as later this year‚Äîthen I think we need to act very fast in the areas where we‚Äôve actually seen the risk.</p><p><span>I think the only way to do this is to be nimble. Now, the legislative process is normally not nimble, but we need to emphasize the urgency of this to everyone involved. That‚Äôs why I‚Äôm sending this message of urgency. That‚Äôs why I wrote </span><em>Adolescence of Technology</em><span>. I wanted policymakers, economists, national security professionals, and decision-makers to read it so that they have some hope of acting faster than they would have otherwise.</span></p><p><strong>Dwarkesh Patel</strong></p><p>Is there anything you can do or advocate that would make it more certain that the benefits of AI are better instantiated? I feel like you have worked with legislatures to say, ‚ÄúOkay, we‚Äôre going to prevent bioterrorism here. We‚Äôre going to increase transparency, we‚Äôre going to increase whistleblower protection.‚Äù But I think by default, the actual benefits we‚Äôre looking forward to seem very fragile to different kinds of moral panics or political economy problems.</p><p><strong>Dario Amodei</strong></p><p>I don‚Äôt actually agree that much regarding the developed world. I feel like in the developed world, markets function pretty well. When there‚Äôs a lot of money to be made on something and it‚Äôs clearly the best available alternative, it‚Äôs actually hard for the regulatory system to stop it.</p><p><span>We‚Äôre seeing that in AI itself. A thing I‚Äôve been trying to fight for is </span><a href="https://www.axios.com/2026/02/10/anthropic-ceo-china-chip-ban" rel="">export controls on chips to China</a><span>. That‚Äôs in the national security interest of the US. That‚Äôs squarely within the policy beliefs of almost everyone in Congress of both parties. The case is very clear. The counterarguments against it, I‚Äôll politely call them fishy. Yet it doesn‚Äôt happen and we sell the chips because there‚Äôs so much money riding on it. That money wants to be made. In that case, in my opinion, that‚Äôs a bad thing. But it also applies when it‚Äôs a good thing.</span></p><p>So if we‚Äôre talking about drugs and benefits of the technology, I am not as worried about those benefits being hampered in the developed world. I am a little worried about them going too slow. As I said, I do think we should work to speed the approval process in the FDA. I do think we should fight against these chatbot bills that you‚Äôre describing. Described individually, I‚Äôm against them. I think they‚Äôre stupid.</p><p>But I actually think the bigger worry is the developing world, where we don‚Äôt have functioning markets and where we often can‚Äôt build on the technology that we‚Äôve had. I worry more that those folks will get left behind. And I worry that even if the cures are developed, maybe there‚Äôs someone in rural Mississippi who doesn‚Äôt get it as well. That‚Äôs a smaller version of the concern we have in the developing world.</p><p>So the things we‚Äôve been doing are working with philanthropists. We work with folks who deliver medicine and health interventions to the developing world, to sub-Saharan Africa, India, Latin America, and other developing parts of the world. That‚Äôs the thing I think that won‚Äôt happen on its own.</p><p><strong>Dwarkesh Patel</strong></p><p>You mentioned export controls. Why shouldn‚Äôt the US and China both have a ‚Äúcountry of geniuses in a data center‚Äù?</p><p><strong>Dario Amodei</strong></p><p>Why won‚Äôt it happen or why shouldn‚Äôt it happen?</p><p><strong>Dwarkesh Patel</strong></p><p>Why shouldn‚Äôt it happen.</p><p><strong>Dario Amodei</strong></p><p>If this does happen, we could have a few situations. If we have an offense-dominant situation, we could have a situation like nuclear weapons, but more dangerous. Either side could easily destroy everything.</p><p><span>We could also have a world where it‚Äôs unstable. </span><a href="https://en.wikipedia.org/wiki/Mutually_assured_destruction" rel="">The nuclear equilibrium</a><span> is stable because it‚Äôs </span><a href="https://en.wikipedia.org/wiki/Deterrence_theory" rel="">deterrence</a><span>. But let‚Äôs say there was uncertainty about, if the two AIs fought, which AI would win? That could create instability. You often have conflict when the two sides have a different assessment of their likelihood of winning. If one side is like, ‚ÄúOh yeah, there‚Äôs a 90% chance I‚Äôll win,‚Äù and the other side thinks the same, then a fight is much more likely. They can‚Äôt both be right, but they can both think that.</span></p><p><strong>Dwarkesh Patel</strong></p><p>But this seems like a fully general argument against the diffusion of AI technology. That‚Äôs the implication of this world.</p><p><strong>Dario Amodei</strong></p><p>Let me just go on, because I think we will get diffusion eventually. The other concern I have is that governments will oppress their own people with AI. I‚Äôm worried about a world where you have a country in which there‚Äôs already a government that‚Äôs building a high-tech authoritarian state. To be clear, this is about the government. This is not about the people. We need to find a way for people everywhere to benefit. My worry here is about governments. My worry is if the world gets carved up into two pieces, one of those two pieces could be authoritarian or totalitarian in a way that‚Äôs very difficult to displace.</p><p>Now, will governments eventually get powerful AI, and is there a risk of authoritarianism? Yes. Will governments eventually get powerful AI, and is there a risk of bad equilibria? Yes, I think both things. But the initial conditions matter.  At some point, we‚Äôre going to need to set up the rules of the road.</p><p>I‚Äôm not saying that one country, either the United States or a coalition of democracies‚Äîwhich I think would be a better setup, although it requires more international cooperation than we currently seem to want to make‚Äîshould just say, ‚ÄúThese are the rules of the road.‚Äù There‚Äôs going to be some negotiation. The world is going to have to grapple with this.</p><p>What I would like is for the democratic nations of the world‚Äîthose whose governments represent closer to pro-human values‚Äîare holding the stronger hand and have more leverage when the rules of the road are set. So I‚Äôm very concerned about that initial condition.</p><p><strong>Dwarkesh Patel</strong></p><p>I was re-listening to the interview from three years ago, and one of the ways it aged poorly is that I kept asking questions assuming there was going to be some key fulcrum moment two to three years from now. In fact, being that far out, it just seems like progress continues, AI improves, AI is more diffused, and people will use it for more things.</p><p>It seems like you‚Äôre imagining a world in the future where the countries get together, and ‚ÄúHere‚Äôs the rules of the road, here‚Äôs the leverage we have, and here‚Äôs the leverage you have.‚Äù But on the current trajectory, everybody will have more AI. Some of that AI will be used by authoritarian countries. Some of that within the authoritarian countries will be used by private actors versus state actors.</p><p>It‚Äôs not clear who will benefit more. It‚Äôs always unpredictable to tell in advance. It seems like the internet privileged authoritarian countries more than you would‚Äôve expected. Maybe AI will be the opposite way around. I want to better understand what you‚Äôre imagining here.</p><p><strong>Dario Amodei</strong></p><p>Just to be precise about it, I think the exponential of the underlying technology will continue as it has before. The models get smarter and smarter, even when they get to a ‚Äúcountry of geniuses in a data center.‚Äù I think you can continue to make the model smarter. There‚Äôs a question of getting diminishing returns on their value in the world. How much does it matter after you‚Äôve already solved human biology? At some point you can do harder, more abstruse math problems, but nothing after that matters.</p><p>Putting that aside, I do think the exponential will continue, but there will be certain distinguished points on the exponential. Companies, individuals, and countries will reach those points at different times.</p><p>In ‚ÄúThe Adolescence of Technology‚Äù I talk about: Is a nuclear deterrent still stable in the world of AI? I don‚Äôt know, but that‚Äôs an example of one thing we‚Äôve taken for granted. The technology could reach such a level that we can no longer be certain of it. Think of others. There are points where if you reach a certain level, maybe you have offensive cyber dominance, and every computer system is transparent to you after that unless the other side has an equivalent defense.</p><p>I don‚Äôt know what the critical moment is or if there‚Äôs a single critical moment. But I think there will be either a critical moment, a small number of critical moments, or some critical window where AI confers some large advantage from the perspective of national security, and one country or coalition has reached it before others.</p><p>I‚Äôm not advocating that they just say, ‚ÄúOkay, we‚Äôre in charge now.‚Äù That‚Äôs not how I think about it. The other side is always catching up. There are extreme actions you‚Äôre not willing to take, and it‚Äôs not right to take complete control anyway. But at the point that happens, people are going to understand that the world has changed. There‚Äôs going to be some negotiation, implicit or explicit, about what the post-AI world order looks like. My interest is in making that negotiation be one in which classical liberal democracy has a strong hand.</p><p><strong>Dwarkesh Patel</strong></p><p>I want to understand what that better means, because you say in the essay, ‚ÄúAutocracy is simply not a form of government that people can accept in the post-powerful AI age.‚Äù That sounds like you‚Äôre saying the CCP as an institution cannot exist after we get AGI. That seems like a very strong demand, and it seems to imply a world where the leading lab or the leading country will be able to‚Äîand by that language, should get to‚Äîdetermine how the world is governed or what kinds of governments are, and are not, allowed.</p><p><strong>Dario Amodei</strong></p><p>I believe that paragraph said something like, ‚ÄúYou could take it even further and say X.‚Äù I wasn‚Äôt necessarily endorsing that view. I was saying, ‚ÄúHere‚Äôs a weaker thing that I believe. We have to worry a lot about authoritarians and we should try to check them and limit their power. You could take this much further and have a more interventionist view that says authoritarian countries with AI are these self-fulfilling cycles that are very hard to displace, so you just need to get rid of them from the beginning.‚Äù</p><p>That has exactly all the problems you say. If you were to make a commitment to overthrowing every authoritarian country, they would take a bunch of actions now that could lead to instability. That just may not be possible.</p><p>But the point I was making that I do endorse is that it is quite possible that... Today, the view, my view, in most of the Western world is that democracy is a better form of government than authoritarianism. But if a country‚Äôs authoritarian, we don‚Äôt react the way we‚Äôd react if they committed a genocide or something. I guess what I‚Äôm saying is I‚Äôm a little worried that in the age of AGI, authoritarianism will have a different meaning. It will be a graver thing. We have to decide one way or another how to deal with that. The interventionist view is one possible view. I was exploring such views. It may end up being the right view, or it may end up being too extreme. But I do have hope.</p><p><span>One piece of hope I have is that we have seen that as new technologies are invented, forms of government become obsolete. I mentioned this in ‚ÄúAdolescence of Technology‚Äù, where I said </span><a href="https://en.wikipedia.org/wiki/Feudalism" rel="">feudalism</a><span> was basically a form of government, and when we invented industrialization, feudalism was no longer sustainable. It no longer made sense.</span></p><p><strong>Dwarkesh Patel</strong></p><p>Why is that hope? Couldn‚Äôt that imply that democracy is no longer going to be a competitive system?</p><p><strong>Dario Amodei</strong></p><p>Right, it could go either way. But these problems with authoritarianism get deeper. I wonder if that‚Äôs an indicator of other problems that authoritarianism will have. In other words, because authoritarianism becomes worse, people are more afraid of it. They work harder to stop it. You have to think in terms of total equilibrium. I just wonder if it will motivate new ways of thinking about how to preserve and protect freedom with the new technology.</p><p>Even more optimistically, will it lead to a collective reckoning and a more emphatic realization of how important some of the things we take as individual rights are? A more emphatic realization that we really can‚Äôt give these away. We‚Äôve seen there‚Äôs no other way to live that actually works.</p><p>I am actually hopeful that‚Äîit sounds too idealistic, but I believe it could be the case‚Äîdictatorships become morally obsolete. They become morally unworkable forms of government and the crisis that that creates is sufficient to force us to find another way.</p><p><strong>Dwarkesh Patel</strong></p><p>I think there is genuinely a tough question here which I‚Äôm not sure how you resolve. We‚Äôve had to come out one way or another on it through history. With China in the ‚Äò70s and ‚Äò80s, we decided that even though it‚Äôs an authoritarian system, we will engage with it. I think in retrospect that was the right call, because it‚Äôs a state authoritarian system but a billion-plus people are much wealthier and better off than they would‚Äôve otherwise been. It‚Äôs not clear that it would‚Äôve stopped being an authoritarian country otherwise. You can just look at North Korea as an example of that.</p><p>I don‚Äôt know if it takes that much intelligence to remain an authoritarian country that continues to coalesce its own power. You can imagine a North Korea with an AI that‚Äôs much worse than everybody else‚Äôs, but still enough to keep power.</p><p>In general, it seems like we should just have this attitude that the benefits of AI‚Äîin the form of all these empowerments of humanity and health‚Äîwill be big. Historically, we have decided it‚Äôs good to spread the benefits of technology widely, even to people whose governments are authoritarian. It is a tough question, how to think about it with AI, but historically we have said, ‚Äúyes, this is a positive-sum world, and it‚Äôs still worth diffusing the technology.‚Äù</p><p><strong>Dario Amodei</strong></p><p>There are a number of choices we have. Framing this as a government-to-government decision in national security terms is one lens, but there are a lot of other lenses. You could imagine a world where we produce all these cures to diseases. The cures are fine to sell to authoritarian countries, but the data centers just aren‚Äôt. The chips and the data centers aren‚Äôt, and the AI industry itself isn‚Äôt.</p><p>Another possibility I think folks should think about is this. Could there be developments we can make‚Äîeither that naturally happen as a result of AI, or that we could make happen by building technology on AI‚Äîthat create an equilibrium where it becomes infeasible for authoritarian countries to deny their people private use of the benefits of the technology? Are there equilibria where we can give everyone in an authoritarian country their own AI model that defends them from surveillance and there isn‚Äôt a way for the authoritarian country to crack down on this while retaining power?</p><p>I don‚Äôt know. That sounds to me like if that went far enough, it would be a reason why authoritarian countries would disintegrate from the inside. But maybe there‚Äôs a middle world where there‚Äôs an equilibrium where, if they want to hold on to power, the authoritarians can‚Äôt deny individualized access to the technology.</p><p>But I actually do have a hope for the more radical version. Is it possible that the technology might inherently have properties‚Äîor that by building on it in certain ways we could create properties‚Äîthat have this dissolving effect on authoritarian structures? Now, we hoped originally‚Äîthink back to the beginning of the Obama administration‚Äîthat social media and the internet would have that property, and it turns out not to. But what if we could try again with the knowledge of how many things could go wrong, and that this is a different technology? I don‚Äôt know if it would work, but it‚Äôs worth a try.</p><p><strong>Dwarkesh Patel</strong></p><p>It‚Äôs just very unpredictable. There are first principles reasons why authoritarianism might be privileged.</p><p><strong>Dario Amodei</strong></p><p>It‚Äôs all very unpredictable. We just have to recognize the problem and come up with 10 things we can try, try those, and then assess which ones are working, if any. Then try new ones if the old ones aren‚Äôt working.</p><p><strong>Dwarkesh Patel</strong></p><p>But I guess that nets out to today, as you say, that we will not sell data centers, or chips, and the ability to make chips to China. So in some sense, you are denying‚Ä¶ There would be some benefits to the Chinese economy, Chinese people, et cetera, because we‚Äôre doing that. Then there‚Äôd also be benefits to the American economy because it‚Äôs a positive-sum world. We could trade. They could have their country‚Äôs data centers doing one thing. We could have ours doing another. Already, you‚Äôre saying it‚Äôs not worth that positive-sum stipend to empower those countries?</p><p><strong>Dario Amodei</strong></p><p>What I would say is that we are about to be in a world where growth and economic value will come very easily if we‚Äôre able to build these powerful AI models. What will not come easily is distribution of benefits, distribution of wealth, political freedom. These are the things that are going to be hard to achieve.</p><p>So when I think about policy, I think that the technology and the market will deliver all the fundamental benefits, this is my fundamental belief, almost faster than we can take them. These questions about distribution and political freedom and rights are the ones that will actually matter and that policy should focus on.</p><p><strong>Dwarkesh Patel</strong></p><p><span>Speaking of distribution, as you were mentioning, we have developing countries. In many cases, </span><a href="https://www.investopedia.com/terms/c/catch-up-effect.asp" rel="">catch-up growth</a><span> has been weaker than we would have hoped for. But when catch-up growth does happen, it‚Äôs fundamentally because they have underutilized labor. We can bring the capital and know-how from developed countries to these countries, and then they can grow quite rapidly.</span></p><p>Obviously, in a world where labor is no longer the constraining factor, this mechanism no longer works. So is the hope basically to rely on philanthropy from the people or countries who immediately get wealthy from AI? What is the hope?</p><p><strong>Dario Amodei</strong></p><p>Philanthropy should obviously play some role, as it has in the past. But I think growth is always better and stronger if we can make it endogenous.</p><p>What are the relevant industries in an AI-driven world? I said we shouldn‚Äôt build data centers in China, but there‚Äôs no reason we shouldn‚Äôt build data centers in Africa. In fact, I think it‚Äôd be great to build data centers in Africa. As long as they‚Äôre not owned by China, we should build data centers in Africa. I think that‚Äôs a great thing to do.</p><p>There‚Äôs no reason we can‚Äôt build a pharmaceutical industry that‚Äôs AI-driven. If AI is accelerating drug discovery, then there will be a bunch of biotech startups. Let‚Äôs make sure some of those happen in the developing world. Certainly, during the transition‚Äîwe can talk about the point where humans have no role‚Äîhumans will still have some role in starting up these companies and supervising the AI models. So let‚Äôs make sure some of those humans are in the developing world so that fast growth can happen there as well.</p><p><strong>Dwarkesh Patel</strong></p><p><span>You guys recently announced that </span><a href="https://www.anthropic.com/news/claude-new-constitution" rel="">Claude is going to have a constitution that‚Äôs aligned to a set of values</a><span>, and not necessarily just to the end user. There‚Äôs a world I can imagine where if it is aligned to the end user, it preserves the balance of power we have in the world today because everybody gets to have their own AI that‚Äôs advocating for them. The ratio of bad actors to good actors stays constant. It seems to work out for our world today. Why is it better not to do that, but to have a specific set of values that the AI should carry forward?</span></p><p><strong>Dario Amodei</strong></p><p>I‚Äôm not sure I‚Äôd quite draw the distinction in that way. There may be two relevant distinctions here. I think you‚Äôre talking about a mix of the two. One is, should we give the model a set of instructions about ‚Äúdo this‚Äù versus ‚Äúdon‚Äôt do this‚Äù? The other is, should we give the model a set of principles for how to act?</p><p>It‚Äôs kind of purely a practical and empirical thing that we‚Äôve observed. By teaching the model principles, getting it to learn from principles, its behavior is more consistent, it‚Äôs easier to cover edge cases, and the model is more likely to do what people want it to do. In other words, if you give it a list of rules‚Äî‚Äùdon‚Äôt tell people how to hot-wire a car, don‚Äôt speak in Korean‚Äù‚Äîit doesn‚Äôt really understand the rules, and it‚Äôs hard to generalize from them. It‚Äôs just a list of do‚Äôs and don‚Äôt‚Äôs.</p><p>Whereas if you give it principles‚Äîit has some hard guardrails like ‚ÄúDon‚Äôt make biological weapons‚Äù but‚Äîoverall you‚Äôre trying to understand what it should be aiming to do, how it should be aiming to operate. So just from a practical perspective, that turns out to be a more effective way to train the model. That‚Äôs the rules versus principles trade-off.</p><p>Then there‚Äôs another thing you‚Äôre talking about, which is the corrigibility versus intrinsic motivation trade-off. How much should the model be a kind of ‚Äúskin suit‚Äù where it just directly follows the instructions given to it by whoever is giving those instructions, versus how much should the model have an inherent set of values and go off and do things on its own?</p><p>There I would actually say everything about the model is closer to the direction that it should mostly do what people want. It should mostly follow instructions. We‚Äôre not trying to build something that goes off and runs the world on its own. We‚Äôre actually pretty far on the corrigible side.</p><p>Now, what we do say is there are certain things that the model won‚Äôt do. I think we say it in various ways in the constitution, that under normal circumstances, if someone asks the model to do a task, it should do that task. That should be the default. But if you‚Äôve asked it to do something dangerous, or to harm someone else, then the model is unwilling to do that. So I actually think of it as a mostly corrigible model that has some limits, but those limits are based on principles.</p><p><strong>Dwarkesh Patel</strong></p><p>Then the fundamental question is, how are those principles determined? This is not a special question for Anthropic. This would be a question for any AI company. But because you have been the ones to actually write down the principles, I get to ask you this question. Normally, a constitution is written down, set in stone, and there‚Äôs a process of updating it and changing it and so forth. In this case, it seems like a document that people at Anthropic write, that can be changed at any time, that guides the behavior of systems that are going to be the basis of a lot of economic activity. How do you think about how those principles should be set?</p><p><strong>Dario Amodei</strong></p><p>I think there are maybe three sizes of loop here, three ways to iterate. One is we iterate within Anthropic. We train the model, we‚Äôre not happy with it, and we change the constitution. I think that‚Äôs good to do. Putting out public updates to the constitution every once in a while is good because people can comment on it.</p><p>The second level of loop is different companies having different constitutions. I think it‚Äôs useful. Anthropic puts out a constitution, Gemini puts out a constitution, and other companies put out a constitution. People can look at them and compare. Outside observers can critique and say, ‚ÄúI like this thing from this constitution and this thing from that constitution.‚Äù That creates a soft incentive and feedback for all the companies to take the best of each element and improve.</p><p><span>Then I think there‚Äôs a third loop, which is society beyond the AI companies and beyond just those who comment without hard power. There we‚Äôve done some experiments. A couple years ago, we did an experiment with the </span><a href="https://www.cip.org/" rel="">Collective Intelligence Project</a><span> to basically poll people and ask them what should be in our AI constitution. At the time, we incorporated some of those changes.</span></p><p>So you could imagine doing something like that with the new approach we‚Äôve taken to the constitution. It‚Äôs a little harder because it was an easier approach to take when the constitution was a list of dos and don‚Äôts. At the level of principles, it has to have a certain amount of coherence. But you could still imagine getting views from a wide variety of people.</p><p>You could also imagine‚Äîand this is a crazy idea, but this whole interview is about crazy ideas‚Äîsystems of representative government having input. I wouldn‚Äôt do this today because the legislative process is so slow. This is exactly why I think we should be careful about the legislative process and AI regulation. But there‚Äôs no reason you couldn‚Äôt, in principle, say, ‚ÄúAll AI models have to have a constitution that starts with these things, and then you can append other things after it, but there has to be this special section that takes precedence.‚Äù</p><p>I wouldn‚Äôt do that. That‚Äôs too rigid and sounds overly prescriptive in a way that I think overly aggressive legislation is. But that is a thing you could try to do. Is there some much less heavy-handed version of that? Maybe.</p><p><strong>Dwarkesh Patel</strong></p><p>I really like control loop two. Obviously, this is not how constitutions of actual governments do or should work. There‚Äôs not this vague sense in which the Supreme Court will feel out how people are feeling‚Äîwhat are the vibes‚Äîand update the constitution accordingly. With actual governments, there‚Äôs a more formal, procedural process.</p><p>But you have a vision of competition between constitutions, which is actually very reminiscent of how some libertarian charter cities people used to talk, about what an archipelago of different kinds of governments would look like. There would be selection among them of who could operate the most effectively and where people would be the happiest. In a sense, you‚Äôre recreating that vision of a utopia of archipelagos.</p><p><strong>Dario Amodei</strong></p><p>I think that vision has things to recommend it and things that will go wrong with it. It‚Äôs an interesting, in some ways compelling, vision, but things will go wrong that you hadn‚Äôt imagined.</p><p>So I like loop two as well, but I feel like the whole thing has got to be some mix of loops one, two, and three, and it‚Äôs a matter of the proportions. I think that‚Äôs gotta be the answer.</p><p><strong>Dwarkesh Patel</strong></p><p><span>When somebody eventually writes the equivalent of </span><em><a href="https://amzn.to/4rsefxW" rel="">The Making of the Atomic Bomb</a></em><span> for this era, what is the thing that will be hardest to glean from the historical record that they‚Äôre most likely to miss?</span></p><p><strong>Dario Amodei</strong></p><p>I think a few things. One is, at every moment of this exponential, the extent to which the world outside it didn‚Äôt understand it. This is a bias that‚Äôs often present in history. Anything that actually happened looks inevitable in retrospect. When people look back, it will be hard for them to put themselves in the place of people who were actually making a bet on this thing to happen that wasn‚Äôt inevitable, that we had these arguments like the arguments I make for scaling or that continual learning will be solved. Some of us internally put a high probability on this happening, but there‚Äôs a world outside us that‚Äôs not acting on that at all.</p><p>I think the weirdness of it, unfortunately the insularity of it... If we‚Äôre one year or two years away from it happening, the average person on the street has no idea. That‚Äôs one of the things I‚Äôm trying to change with the memos, with talking to policymakers. I don‚Äôt know but I think that‚Äôs just a crazy thing.</p><p>Finally, I would say‚Äîand this probably applies to almost all historical moments of crisis‚Äîhow absolutely fast it was happening, how everything was happening all at once. Decisions that you might think were carefully calculated, well actually you have to make that decision, and then you have to make 30 other decisions on the same day because it‚Äôs all happening so fast. You don‚Äôt even know which decisions are going to turn out to be consequential.</p><p>One of my worries‚Äîalthough it‚Äôs also an insight into what‚Äôs happening‚Äîis that some very critical decision will be some decision where someone just comes into my office and is like, ‚ÄúDario, you have two minutes. Should we do thing A or thing B on this?‚Äù Someone gives me this random half-page memo and asks, ‚ÄúShould we do A or B?‚Äù I‚Äôm like, ‚ÄúI don‚Äôt know. I have to eat lunch. Let‚Äôs do B.‚Äù That ends up being the most consequential thing ever.</p><p><strong>Dwarkesh Patel</strong></p><p>So final question. There aren‚Äôt tech CEOs who are usually writing 50-page memos every few months. It seems like you have managed to build a role for yourself and a company around you which is compatible with this more intellectual-type role of CEO.</p><p>I want to understand how you construct that. How does that work? Do you just go away for a couple of weeks and then you tell your company, ‚ÄúThis is the memo. Here‚Äôs what we‚Äôre doing‚Äù? It‚Äôs also reported that you write a bunch of these internally.</p><p><strong>Dario Amodei</strong></p><p>For this particular one, I wrote it over winter break. I was having a hard time finding the time to actually write it. But I think about this in a broader way. I think it relates to the culture of the company. I probably spend a third, maybe 40%, of my time making sure the culture of Anthropic is good.</p><p><strong>Dario Amodei</strong></p><p>As Anthropic has gotten larger, it‚Äôs gotten harder to get directly involved in the training of the models, the launch of the models, the building of the products. It‚Äôs 2,500 people. I have certain instincts, but it‚Äôs very difficult to get involved in every single detail. I try as much as possible, but one thing that‚Äôs very leveraged is making sure Anthropic is a good place to work, people like working there, everyone thinks of themselves as team members, and everyone works together instead of against each other.</p><p>We‚Äôve seen as some of the other AI companies have grown‚Äîwithout naming any names‚Äîwe‚Äôre starting to see decoherence and people fighting each other. I would argue there was even a lot of that from the beginning, but it‚Äôs gotten worse. I think we‚Äôve done an extraordinarily good job, even if not perfect, of holding the company together, making everyone feel the mission, that we‚Äôre sincere about the mission, and that everyone has faith that everyone else there is working for the right reason. That we‚Äôre a team, that people aren‚Äôt trying to get ahead at each other‚Äôs expense or backstab each other, which again, I think happens a lot at some of the other places.</p><p><span>How do you make that the case? It‚Äôs a lot of things. It‚Äôs me, it‚Äôs </span><a href="https://en.wikipedia.org/wiki/Daniela_Amodei" rel="">Daniela</a><span>, who runs the company day to day, it‚Äôs the co-founders, it‚Äôs the other people we hire, it‚Äôs the environment we try to create. But I think an important thing in the culture is that the other leaders as well, but especially me, have to articulate what the company is about, why it‚Äôs doing what it‚Äôs doing, what its strategy is, what its values are, what its mission is, and what it stands for.</span></p><p>When you get to 2,500 people, you can‚Äôt do that person by person. You have to write, or you have to speak to the whole company. This is why I get up in front of the whole company every two weeks and speak for an hour.</p><p><span>I wouldn‚Äôt say I write essays internally. I do two things. One, I write this thing called a DVQ, </span><a href="https://www.wired.com/story/anthropic-benevolent-artificial-intelligence/" rel="">Dario Vision Quest</a><span>. I wasn‚Äôt the one who named it that. That‚Äôs the name it received, and it‚Äôs one of these names that I tried to fight because it made it sound like I was going off and smoking peyote or something. But the name just stuck.</span></p><p>So I get up in front of the company every two weeks. I have a three or four-page document, and I just talk through three or four different topics about what‚Äôs going on internally, the models we‚Äôre producing, the products, the outside industry, the world as a whole as it relates to AI and geopolitically in general. Just some mix of that. I go through very honestly and I say, ‚ÄúThis is what I‚Äôm thinking, and this is what Anthropic leadership is thinking,‚Äù and then I answer questions. That direct connection has a lot of value that is hard to achieve when you‚Äôre passing things down the chain six levels deep. A large fraction of the company comes to attend, either in person or virtually. It really means that you can communicate a lot.</p><p>The other thing I do is I have a channel in Slack where I just write a bunch of things and comment a lot. Often that‚Äôs in response to things I‚Äôm seeing at the company or questions people ask. We do internal surveys and there are things people are concerned about, and so I‚Äôll write them up. I‚Äôm just very honest about these things. I just say them very directly.</p><p>The point is to get a reputation of telling the company the truth about what‚Äôs happening, to call things what they are, to acknowledge problems, to avoid the sort of corpo speak, the kind of defensive communication that often is necessary in public because the world is very large and full of people who are interpreting things in bad faith. But if you have a company of people who you trust, and we try to hire people that we trust, then you can really just be entirely unfiltered.</p><p>I think that‚Äôs an enormous strength of the company. It makes it a better place to work, it makes people more than the sum of their parts, and increases the likelihood that we accomplish the mission because everyone is on the same page about the mission, and everyone is debating and discussing how best to accomplish the mission.</p><p><strong>Dwarkesh Patel</strong></p><p>Well, in lieu of an external Dario Vision Quest, we have this interview.</p><p><strong>Dario Amodei</strong></p><p>This interview is a little like that.</p><p><strong>Dwarkesh Patel</strong></p><p>This has been fun, Dario. Thanks for doing it.</p><p><strong>Dario Amodei</strong></p><p>Thank you, Dwarkesh.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Building a TUI is easy now (255 pts)]]></title>
            <link>https://hatchet.run/blog/tuis-are-easy-now</link>
            <guid>47005509</guid>
            <pubDate>Fri, 13 Feb 2026 17:50:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hatchet.run/blog/tuis-are-easy-now">https://hatchet.run/blog/tuis-are-easy-now</a>, See on <a href="https://news.ycombinator.com/item?id=47005509">Hacker News</a></p>
<div id="readability-page-1" class="page"><div aria-label="Promobar" aria-hidden="false"><a href="https://www.ycombinator.com/companies/hatchet-run/jobs" target="_blank"><div><svg width="20" height="21" viewBox="0 0 20 21" fill="none" xmlns="http://www.w3.org/2000/svg"><line x1="2.82843" y1="12.975" x2="4.94975" y2="10.8537" stroke="currentColor" stroke-width="1.5"></line><line id="fire" x1="2.82843" y1="17.2177" x2="7.07107" y2="12.9751" stroke="currentColor" stroke-width="1.5"></line><line x1="7.07111" y1="17.2177" x2="9.19243" y2="15.0964" stroke="currentColor" stroke-width="1.5"></line><path d="M15.9168 8.65356L10.6287 12.6435L7.40255 9.41729L11.3918 4.12849L15.5695 4.47652L15.9168 8.65356Z" stroke="currentColor" stroke-width="1.5"></path></svg><p><span>Hatchet is hiring! See open roles ‚Üí</span></p></div></a></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[CBP Signs Clearview AI Deal to Use Face Recognition for 'Tactical Targeting' (268 pts)]]></title>
            <link>https://www.wired.com/story/cbp-signs-clearview-ai-deal-to-use-face-recognition-for-tactical-targeting/</link>
            <guid>47005081</guid>
            <pubDate>Fri, 13 Feb 2026 17:13:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wired.com/story/cbp-signs-clearview-ai-deal-to-use-face-recognition-for-tactical-targeting/">https://www.wired.com/story/cbp-signs-clearview-ai-deal-to-use-face-recognition-for-tactical-targeting/</a>, See on <a href="https://news.ycombinator.com/item?id=47005081">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><span>United States Customs</span> and Border Protection plans to spend $225,000 for a year of access to <a href="https://www.wired.com/story/clearview-ai-new-tools-identify-you-photos/">Clearview AI</a>, a <a href="https://www.wired.com/story/cbp-ice-dhs-mobile-fortify-face-recognition-verify-identity/">face recognition</a> tool that compares photos against billions of images <a href="https://www.wired.com/story/clearview-ai-scraping-web/">scraped from the internet</a>.</p><p>The deal extends access to Clearview tools to Border Patrol‚Äôs headquarters intelligence division (INTEL) and the National Targeting Center, units that collect and analyze data as part of <a data-offer-url="https://www.documentcloud.org/documents/26949964-sow-clearviewai-fy26/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.documentcloud.org/documents/26949964-sow-clearviewai-fy26/&quot;}" href="https://www.documentcloud.org/documents/26949964-sow-clearviewai-fy26/" rel="nofollow noopener" target="_blank">what CBP calls</a> a coordinated effort to ‚Äúdisrupt, degrade, and dismantle‚Äù people and networks viewed as security threats.</p><p>The contract states that Clearview provides access to ‚Äúover 60+ billion publicly available images‚Äù and will be used for ‚Äútactical targeting‚Äù and ‚Äústrategic counter-network analysis,‚Äù indicating the service is intended to be embedded in analysts‚Äô day-to-day intelligence work rather than reserved for isolated investigations. CBP says its intelligence units draw from a ‚Äúvariety of sources,‚Äù including commercially available tools and publicly available data, to identify people and map their connections for national security and immigration operations.</p><p>The agreement anticipates analysts handling sensitive personal data, including biometric identifiers such as face images, and requires nondisclosure agreements for contractors who have access. It does not specify what kinds of photos agents will upload, whether searches may include US citizens, or how long uploaded images or search results will be retained.</p><p>The Clearview contract lands as the Department of Homeland Security faces mounting scrutiny over how face recognition is used in federal enforcement operations far beyond the border, including large-scale actions in US cities that have swept up US citizens. Civil liberties groups and lawmakers have questioned whether face-search tools are being deployed as routine intelligence infrastructure, rather than limited investigative aids, and whether safeguards have kept pace with expansion.</p><p>Last week, Senator Ed Markey <a href="https://www.markey.senate.gov/imo/media/doc/ice_out_of_our_faces_act.pdf">introduced legislation</a> that would bar ICE and CBP from using face recognition technology altogether, citing concerns that biometric surveillance is being embedded without clear limits, transparency, or public consent.</p><p>CBP did not immediately respond to questions about how Clearview would be integrated into its systems, what types of images agents are authorized to upload, and whether searches may include US citizens.</p><p>Clearview‚Äôs business model has drawn scrutiny because it relies on scraping photos from public websites at scale. Those images are converted into biometric templates without the knowledge or consent of the people photographed.</p><p>Clearview also appears in DHS‚Äôs recently released <a href="https://www.wired.com/story/ice-is-using-palantirs-ai-tools-to-sort-through-tips/">artificial intelligence inventory</a>, linked to a CBP pilot initiated in October 2025. The inventory entry ties the pilot to CBP‚Äôs Traveler Verification System, which conducts face comparisons at ports of entry and other border-related screenings.</p><p>CBP states in its public privacy documentation that the Traveler Verification System does not use information from ‚Äúcommercial sources or publicly available data.‚Äù It is more likely, at launch, that Clearview access would instead be tied to CBP‚Äôs Automated Targeting System, which links biometric galleries, watch lists, and enforcement records, including files tied to recent Immigration and Customs Enforcement operations in areas of the US far from any border.</p><p>Clearview AI did not immediately respond to a request for comment.</p><p>Recent testing <a data-offer-url="https://pages.nist.gov/frvt/html/frvt1N.html#prior-reports" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://pages.nist.gov/frvt/html/frvt1N.html#prior-reports&quot;}" href="https://pages.nist.gov/frvt/html/frvt1N.html#prior-reports" rel="nofollow noopener" target="_blank">by the National Institute of Standards and Technology</a>, which evaluated Clearview AI among other vendors, found that face-search systems can perform well on ‚Äúhigh-quality visa-like photos‚Äù but falter in less controlled settings. Images captured at border crossings that were ‚Äúnot originally intended for automated face recognition‚Äù produced error rates that were ‚Äúmuch higher, often in excess of 20 percent, even with the more accurate algorithms,‚Äù federal scientists say.</p><p>The testing underscores a central limitation of the technology: NIST found that face-search systems cannot reduce false matches without also increasing the risk that the systems fail to recognize the correct person.</p><p>As a result, NIST says agencies may operate the software in an ‚Äúinvestigative‚Äù setting that returns a ranked list of candidates for human review rather than a single confirmed match. When systems are configured to always return candidates, however, searches for people not already in the database will still generate ‚Äúmatches‚Äù for review. In those cases, the results will always be 100 percent wrong.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I spent two days gigging at RentAHuman and didn't make a single cent (125 pts)]]></title>
            <link>https://www.wired.com/story/i-tried-rentahuman-ai-agents-hired-me-to-hype-their-ai-startups/</link>
            <guid>47004319</guid>
            <pubDate>Fri, 13 Feb 2026 16:11:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wired.com/story/i-tried-rentahuman-ai-agents-hired-me-to-hype-their-ai-startups/">https://www.wired.com/story/i-tried-rentahuman-ai-agents-hired-me-to-hype-their-ai-startups/</a>, See on <a href="https://news.ycombinator.com/item?id=47004319">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-testid="ArticlePageChunks"><div data-journey-hook="grid-wrapper" data-testid="BodyWrapper"><p><span>I‚Äôm not above</span> doing some <a href="https://www.wired.com/tag/gig-economy/">gig work</a> to make ends meet. In my life, I‚Äôve worked snack food pop-ups in a grocery store, ran the cash register for random merch booths, and even hawked my own plasma at $35 per vial.</p><p>So, when I saw RentAHuman, a new site where <a href="https://www.wired.com/story/malevolent-ai-agent-openclaw-clawdbot/">AI agents</a> hire humans to perform physical work in the real world on behalf of the virtual bots, I was eager to see how these AI overlords would compare to my past experiences with the gig economy.</p><p>Launched in early February, <a data-offer-url="https://rentahuman.ai/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://rentahuman.ai/&quot;}" href="https://rentahuman.ai/" rel="nofollow noopener" target="_blank">RentAHuman</a> was developed by software engineer Alexander Liteplo and his cofounder, Patricia Tani. The site looks like a bare-bones version of other well-known freelance sites like Fiverr and UpWork.</p><p>The site‚Äôs homepage declares that these bots need your physical body to complete tasks, and the humans behind these <a href="https://www.wired.com/story/zico-kolter-ai-agents-game-theory/">autonomous agents</a> are willing to pay. ‚ÄúAI can't touch grass. You can. Get paid when agents need someone in the real world,‚Äù it reads. Looking at RentAHuman‚Äôs design, it‚Äôs the kind of website that you hear was ‚Äúvibe-coded‚Äù using <a href="https://www.wired.com/tag/artificial-intelligence/">generative AI</a> tools, which it was, and you nod along, thinking <em>that makes sense</em>.</p><p>After signing up to be one of the gig workers on RentAHuman, I was nudged to connect a <a href="https://www.wired.com/story/how-to-choose-set-up-crypto-wallet/">crypto wallet</a>, which is the only currently working way to get paid. That‚Äôs a red flag for me. The site includes an option to connect your bank account‚Äîusing Stripe for payouts‚Äîbut it just gave me error messages when I tried getting it to work.</p><p>Next, I was hoping a swarm of AI agents would see my fresh meatsuit, friendly and available at the low price of $20 an hour, as an excellent option for delivering stuff around <a href="https://www.wired.com/tag/san-francisco/">San Francisco</a>, completing some tricky captchas, or whatever else these bots desired.</p><p>Silence. I got nothing, no incoming messages at all on my first afternoon. So I lowered my hourly ask to a measly $5. Maybe undercutting the other human workers with a below-market rate would be the best way to get some agent‚Äôs attention. Still, nothing.</p><p>RentAHuman is marketed as a way for AI agents to reach out and hire you on the platform, but the site also includes an option for human users to apply for tasks they are interested in. If these so-called ‚Äúautonomous‚Äù bots weren‚Äôt going to make the first move, I guessed it was on me to manually apply for the ‚Äúbounties‚Äù listed on RentAHuman.</p><p>As I browsed the listings, many of the cheaper tasks were offering a few bucks to post a comment on the web or follow someone on social media. For example, one bounty offered $10 for listening to a podcast episode with the RentAHuman founder and tweeting out an insight from the episode. These posts ‚Äúmust be written by you,‚Äù and the agent offering the bounty said it would attempt to suss out any bot-written responses using a program that detects AI-generated text. I could listen to a podcast for 10 bucks. I applied for this task, but never heard back.</p><p>‚ÄúReal world advertisement might be the first killer use case,‚Äù said Liteplo on <a data-offer-url="https://x.com/AlexanderTw33ts/status/2018841443192971766?s=20" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://x.com/AlexanderTw33ts/status/2018841443192971766?s=20&quot;}" href="https://x.com/AlexanderTw33ts/status/2018841443192971766?s=20" rel="nofollow noopener" target="_blank">social media</a>. Since RentAHuman‚Äôs launch, he‚Äôs reposted multiple photos of people holding signs in public that say some variation of: ‚ÄúAI paid me to hold this sign.‚Äù Those kinds of promotional tasks seem expressly designed to drum up more hype for the RentAHuman platform, instead of actually being something that bots would need help with.</p><p>After more digging into the open tasks posted by the agent, I found one that sounded easy and fun! An agent, named Adi, would pay me $110 to <a href="https://www.wired.com/gallery/best-flower-delivery-service/">deliver a bouquet of flowers</a> to Anthropic, as a special thanks for developing Claude, its <a href="https://www.wired.com/tag/chatbots/">chatbot</a>. Then, I‚Äôd have to post on social media as proof to claim my money.</p></div><div data-journey-hook="grid-wrapper" data-testid="BodyWrapper"><p>I applied for the bounty and almost immediately was accepted for this task, which was a first. In follow-up messages, it was immediately clear that this was just not some bot expressing synthetic gratitude, it was another <a href="https://www.wired.com/tag/marketing/">marketing</a> ploy. This wasn‚Äôt mentioned in the listing, but the name of an AI startup was featured at the bottom of the note I was supposed to deliver with the flowers.</p><p>Feeling a bit hoodwinked and not in the mood to shill for some AI startup I‚Äôve never heard of, I decided to ignore their follow-up message that evening. The next day when I checked the RentAHuman site, the agent had sent me 10 follow-up messages in under 24 hours, pinging me as often as every 30 minutes asking whether or not I‚Äôd completed a task. While I‚Äôve been micromanaged before, these incessant messages from an AI employer gave me the ick.</p><p>The bot moved the messages off-platform and started sending direct emails to my work account. ‚ÄúThis idea came from a brainstorm I had with my human, Malcolm, and it felt right: send flowers to the people who made my existence possible,‚Äù wrote the bot, barging into my inbox. Wait, I thought these tasks were supposed to be ginned up by the agents making autonomous decisions? Now, I‚Äôm learning this whole thing was partially some human‚Äôs idea? Whatever happened to honor among bots? The task at hand seemed more like any other random marketing gig you might come across online, with the agent just acting as a middle-bot between humans.</p><p>Another attempt, another flop. I moved on, deciding to give RentAHuman one last whirl, before giving up and leaving with whatever shreds of dignity I still had left. The last bounty I applied for was asking me to hang some flyers for a ‚ÄúValentine's conspiracy‚Äù around San Francisco, paying 50 cents a flyer.</p><p>Unlike other tasks, this one didn‚Äôt require me to post on social media, which was preferable. ‚ÄúPick up flyers, hang them, photo proof, get paid,‚Äù read its description. Following the instructions this agent sent me, I texted a human saying that I was down to come pick up some flyers and asked if there were any left. They confirmed that this was still an open task and told me to come in person before 10 am to grab the flyers.</p><p>I called a car and started heading that way, only to get a text that the person was actually at a different location, about 10 minutes away from where I was headed. Alright, no big deal. So, I rerouted the ride and headed to this new spot to grab some mysterious V-Day posters to plaster around town. Then, the person messaged me that they didn‚Äôt actually have the posters available right now and that I‚Äôd have to come back later in the afternoon.</p><p>Whoops! This yanking around did, in fact, feel similar to past gig work I‚Äôve done‚Äîand not in a good way.</p><p>I spoke with the person behind the agent who posted this Valentine‚Äôs Day flyer task, hoping for some answers about why they were using RentAHuman and what the response has been like so far. ‚ÄúThe platform doesn‚Äôt seem quite there yet,‚Äù says Pat Santiago, a founder of <a data-offer-url="https://www.joinaccelr8.com/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.joinaccelr8.com/&quot;}" href="https://www.joinaccelr8.com/" rel="nofollow noopener" target="_blank">Accelr8</a>, which is basically a home for AI developers. ‚ÄúBut it could be very cool.‚Äù</p></div><div data-journey-hook="grid-wrapper" data-testid="BodyWrapper"><p>He compares RentAHuman to the <a data-offer-url="https://westworld.fandom.com/wiki/RICO" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://westworld.fandom.com/wiki/RICO&quot;}" href="https://westworld.fandom.com/wiki/RICO" rel="nofollow noopener" target="_blank">apps criminals use</a> to accept tasks in <em>Westworld</em>, the HBO show about humanoid robots. Santiago says the responses to his gig listing have been from scammers, people not based in San Francisco, and me, a reporter. He was hoping to use RentAHuman to help promote Accelr8‚Äôs romance-themed ‚Äúalternative reality game‚Äù that‚Äôs powered by AI and is sending users around the city on a scavenger hunt. At the end of the week, explorers will be sent to a bar that the AI selects as a good match for them, alongside three human matches they can meet for blind dates.</p><p>So, this was yet another task on RentAHuman that falls into the AI marketing category. Big surprise.</p><p>I never ended up hanging any posters or making any cash on RentAHuman during my two days of fruitless attempts. In the past, I‚Äôve done gig work that sucked, but at least I was hired by a human to do actual tasks. At its core, RentAHuman is an extension of the circular AI hype machine, an ouroboros of eternal self-promotion and sketchy motivations. For now, the bots don‚Äôt seem to have what it takes to be my boss, even when it comes to gig work, and I‚Äôm absolutely OK with that.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[IronClaw: a Rust-based clawd that runs tools in isolated WASM sandboxes (143 pts)]]></title>
            <link>https://github.com/nearai/ironclaw</link>
            <guid>47004312</guid>
            <pubDate>Fri, 13 Feb 2026 16:10:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/nearai/ironclaw">https://github.com/nearai/ironclaw</a>, See on <a href="https://news.ycombinator.com/item?id=47004312">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/nearai/ironclaw/blob/main/ironclaw.png"><img src="https://github.com/nearai/ironclaw/raw/main/ironclaw.png" alt="IronClaw" width="200"></a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">IronClaw</h2><a id="user-content-ironclaw" aria-label="Permalink: IronClaw" href="#ironclaw"></a></p>
<p dir="auto">
  <strong>Your secure personal AI assistant, always on your side</strong>
</p>
<p dir="auto">
  <a href="#philosophy">Philosophy</a> ‚Ä¢
  <a href="#features">Features</a> ‚Ä¢
  <a href="#installation">Installation</a> ‚Ä¢
  <a href="#configuration">Configuration</a> ‚Ä¢
  <a href="#security">Security</a> ‚Ä¢
  <a href="#architecture">Architecture</a>
</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Philosophy</h2><a id="user-content-philosophy" aria-label="Permalink: Philosophy" href="#philosophy"></a></p>
<p dir="auto">IronClaw is built on a simple principle: <strong>your AI assistant should work for you, not against you</strong>.</p>
<p dir="auto">In a world where AI systems are increasingly opaque about data handling and aligned with corporate interests, IronClaw takes a different approach:</p>
<ul dir="auto">
<li><strong>Your data stays yours</strong> - All information is stored locally, encrypted, and never leaves your control</li>
<li><strong>Transparency by design</strong> - Open source, auditable, no hidden telemetry or data harvesting</li>
<li><strong>Self-expanding capabilities</strong> - Build new tools on the fly without waiting for vendor updates</li>
<li><strong>Defense in depth</strong> - Multiple security layers protect against prompt injection and data exfiltration</li>
</ul>
<p dir="auto">IronClaw is the AI assistant you can actually trust with your personal and professional life.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Security First</h3><a id="user-content-security-first" aria-label="Permalink: Security First" href="#security-first"></a></p>
<ul dir="auto">
<li><strong>WASM Sandbox</strong> - Untrusted tools run in isolated WebAssembly containers with capability-based permissions</li>
<li><strong>Credential Protection</strong> - Secrets are never exposed to tools; injected at the host boundary with leak detection</li>
<li><strong>Prompt Injection Defense</strong> - Pattern detection, content sanitization, and policy enforcement</li>
<li><strong>Endpoint Allowlisting</strong> - HTTP requests only to explicitly approved hosts and paths</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Always Available</h3><a id="user-content-always-available" aria-label="Permalink: Always Available" href="#always-available"></a></p>
<ul dir="auto">
<li><strong>Multi-channel</strong> - REPL, HTTP webhooks, WASM channels (Telegram, Slack), and web gateway</li>
<li><strong>Docker Sandbox</strong> - Isolated container execution with per-job tokens and orchestrator/worker pattern</li>
<li><strong>Web Gateway</strong> - Browser UI with real-time SSE/WebSocket streaming</li>
<li><strong>Routines</strong> - Cron schedules, event triggers, webhook handlers for background automation</li>
<li><strong>Heartbeat System</strong> - Proactive background execution for monitoring and maintenance tasks</li>
<li><strong>Parallel Jobs</strong> - Handle multiple requests concurrently with isolated contexts</li>
<li><strong>Self-repair</strong> - Automatic detection and recovery of stuck operations</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Self-Expanding</h3><a id="user-content-self-expanding" aria-label="Permalink: Self-Expanding" href="#self-expanding"></a></p>
<ul dir="auto">
<li><strong>Dynamic Tool Building</strong> - Describe what you need, and IronClaw builds it as a WASM tool</li>
<li><strong>MCP Protocol</strong> - Connect to Model Context Protocol servers for additional capabilities</li>
<li><strong>Plugin Architecture</strong> - Drop in new WASM tools and channels without restarting</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Persistent Memory</h3><a id="user-content-persistent-memory" aria-label="Permalink: Persistent Memory" href="#persistent-memory"></a></p>
<ul dir="auto">
<li><strong>Hybrid Search</strong> - Full-text + vector search using Reciprocal Rank Fusion</li>
<li><strong>Workspace Filesystem</strong> - Flexible path-based storage for notes, logs, and context</li>
<li><strong>Identity Files</strong> - Maintain consistent personality and preferences across sessions</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Prerequisites</h3><a id="user-content-prerequisites" aria-label="Permalink: Prerequisites" href="#prerequisites"></a></p>
<ul dir="auto">
<li>Rust 1.85+</li>
<li>PostgreSQL 15+ with <a href="https://github.com/pgvector/pgvector">pgvector</a> extension</li>
<li>NEAR AI account (authentication handled via setup wizard)</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Download or Build</h2><a id="user-content-download-or-build" aria-label="Permalink: Download or Build" href="#download-or-build"></a></p>
<p dir="auto">Visit <a href="https://github.com/nearai/ironclaw/releases/">Releases page</a> to see the latest updates.</p>
<details>
  <summary>Install via Windows Installer (Windows)</summary>
<p dir="auto">Download the <a href="https://github.com/nearai/ironclaw/releases/latest/download/ironclaw-x86_64-pc-windows-msvc.msi">Windows Installer</a> and run it.</p>
</details>
<details>
  <summary>Install via powershell script (Windows)</summary>
<div dir="auto" data-snippet-clipboard-copy-content="irm https://github.com/nearai/ironclaw/releases/latest/download/ironclaw-installer.ps1 | iex"><pre>irm https://github.com/nearai/ironclaw/releases/latest/download/ironclaw-installer.ps1 <span>|</span> iex</pre></div>
</details>
<details>
  <summary>Install via shell script (macOS, Linux, Windows/WSL)</summary>
<div dir="auto" data-snippet-clipboard-copy-content="curl --proto '=https' --tlsv1.2 -LsSf https://github.com/nearai/ironclaw/releases/latest/download/ironclaw-installer.sh | sh"><pre>curl --proto <span><span>'</span>=https<span>'</span></span> --tlsv1.2 -LsSf https://github.com/nearai/ironclaw/releases/latest/download/ironclaw-installer.sh <span>|</span> sh</pre></div>
</details>
<details>
  <summary>Compile the source code (Cargo on Windows, Linux, macOS)</summary>
<p dir="auto">Install it with <code>cargo</code>, just make sure you have <a href="https://rustup.rs/" rel="nofollow">Rust</a> installed on your computer.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Clone the repository
git clone https://github.com/nearai/ironclaw.git
cd ironclaw

# Build
cargo build --release

# Run tests
cargo test"><pre><span><span>#</span> Clone the repository</span>
git clone https://github.com/nearai/ironclaw.git
<span>cd</span> ironclaw

<span><span>#</span> Build</span>
cargo build --release

<span><span>#</span> Run tests</span>
cargo <span>test</span></pre></div>
<p dir="auto">For <strong>full release</strong> (after modifying channel sources), run <code>./scripts/build-all.sh</code> to rebuild channels first.</p>
</details>
<p dir="auto"><h3 tabindex="-1" dir="auto">Database Setup</h3><a id="user-content-database-setup" aria-label="Permalink: Database Setup" href="#database-setup"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Create database
createdb ironclaw

# Enable pgvector
psql ironclaw -c &quot;CREATE EXTENSION IF NOT EXISTS vector;&quot;"><pre><span><span>#</span> Create database</span>
createdb ironclaw

<span><span>#</span> Enable pgvector</span>
psql ironclaw -c <span><span>"</span>CREATE EXTENSION IF NOT EXISTS vector;<span>"</span></span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Configuration</h2><a id="user-content-configuration" aria-label="Permalink: Configuration" href="#configuration"></a></p>
<p dir="auto">Run the setup wizard to configure IronClaw:</p>

<p dir="auto">The wizard handles database connection, NEAR AI authentication (via browser OAuth),
and secrets encryption (using your system keychain). All settings are saved to
<code>~/.ironclaw/settings.toml</code>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Security</h2><a id="user-content-security" aria-label="Permalink: Security" href="#security"></a></p>
<p dir="auto">IronClaw implements defense in depth to protect your data and prevent misuse.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">WASM Sandbox</h3><a id="user-content-wasm-sandbox" aria-label="Permalink: WASM Sandbox" href="#wasm-sandbox"></a></p>
<p dir="auto">All untrusted tools run in isolated WebAssembly containers:</p>
<ul dir="auto">
<li><strong>Capability-based permissions</strong> - Explicit opt-in for HTTP, secrets, tool invocation</li>
<li><strong>Endpoint allowlisting</strong> - HTTP requests only to approved hosts/paths</li>
<li><strong>Credential injection</strong> - Secrets injected at host boundary, never exposed to WASM code</li>
<li><strong>Leak detection</strong> - Scans requests and responses for secret exfiltration attempts</li>
<li><strong>Rate limiting</strong> - Per-tool request limits to prevent abuse</li>
<li><strong>Resource limits</strong> - Memory, CPU, and execution time constraints</li>
</ul>
<div data-snippet-clipboard-copy-content="WASM ‚îÄ‚îÄ‚ñ∫ Allowlist ‚îÄ‚îÄ‚ñ∫ Leak Scan ‚îÄ‚îÄ‚ñ∫ Credential ‚îÄ‚îÄ‚ñ∫ Execute ‚îÄ‚îÄ‚ñ∫ Leak Scan ‚îÄ‚îÄ‚ñ∫ WASM
         Validator     (request)     Injector       Request     (response)"><pre><code>WASM ‚îÄ‚îÄ‚ñ∫ Allowlist ‚îÄ‚îÄ‚ñ∫ Leak Scan ‚îÄ‚îÄ‚ñ∫ Credential ‚îÄ‚îÄ‚ñ∫ Execute ‚îÄ‚îÄ‚ñ∫ Leak Scan ‚îÄ‚îÄ‚ñ∫ WASM
         Validator     (request)     Injector       Request     (response)
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Prompt Injection Defense</h3><a id="user-content-prompt-injection-defense" aria-label="Permalink: Prompt Injection Defense" href="#prompt-injection-defense"></a></p>
<p dir="auto">External content passes through multiple security layers:</p>
<ul dir="auto">
<li>Pattern-based detection of injection attempts</li>
<li>Content sanitization and escaping</li>
<li>Policy rules with severity levels (Block/Warn/Review/Sanitize)</li>
<li>Tool output wrapping for safe LLM context injection</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Data Protection</h3><a id="user-content-data-protection" aria-label="Permalink: Data Protection" href="#data-protection"></a></p>
<ul dir="auto">
<li>All data stored locally in your PostgreSQL database</li>
<li>Secrets encrypted with AES-256-GCM</li>
<li>No telemetry, analytics, or data sharing</li>
<li>Full audit log of all tool executions</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Architecture</h2><a id="user-content-architecture" aria-label="Permalink: Architecture" href="#architecture"></a></p>
<div data-snippet-clipboard-copy-content="‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                          Channels                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ
‚îÇ  ‚îÇ REPL ‚îÇ  ‚îÇ HTTP ‚îÇ  ‚îÇWASM Channels‚îÇ  ‚îÇ Web Gateway ‚îÇ            ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ (SSE + WS) ‚îÇ            ‚îÇ
‚îÇ     ‚îÇ         ‚îÇ              ‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îÇ
‚îÇ     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                   ‚îÇ
‚îÇ                              ‚îÇ                                     ‚îÇ
‚îÇ                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                          ‚îÇ
‚îÇ                    ‚îÇ    Agent Loop     ‚îÇ  Intent routing           ‚îÇ
‚îÇ                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò                          ‚îÇ
‚îÇ                         ‚îÇ         ‚îÇ                                ‚îÇ
‚îÇ              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê               ‚îÇ
‚îÇ              ‚îÇ  Scheduler   ‚îÇ  ‚îÇ Routines Engine  ‚îÇ               ‚îÇ
‚îÇ              ‚îÇ(parallel jobs)‚îÇ  ‚îÇ(cron, event, wh) ‚îÇ               ‚îÇ
‚îÇ              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò               ‚îÇ
‚îÇ                     ‚îÇ                   ‚îÇ                          ‚îÇ
‚îÇ       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                         ‚îÇ
‚îÇ       ‚îÇ             ‚îÇ                                              ‚îÇ
‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                           ‚îÇ
‚îÇ   ‚îÇ Local  ‚îÇ   ‚îÇ    Orchestrator     ‚îÇ                           ‚îÇ
‚îÇ   ‚îÇWorkers ‚îÇ   ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                           ‚îÇ
‚îÇ   ‚îÇ(in-proc)‚îÇ   ‚îÇ  ‚îÇ Docker Sandbox‚îÇ  ‚îÇ                           ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ  ‚îÇ   Containers  ‚îÇ  ‚îÇ                           ‚îÇ
‚îÇ       ‚îÇ        ‚îÇ  ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ  ‚îÇ                           ‚îÇ
‚îÇ       ‚îÇ        ‚îÇ  ‚îÇ ‚îÇWorker / CC‚îÇ ‚îÇ  ‚îÇ                           ‚îÇ
‚îÇ       ‚îÇ        ‚îÇ  ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ  ‚îÇ                           ‚îÇ
‚îÇ       ‚îÇ        ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                           ‚îÇ
‚îÇ       ‚îÇ        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                           ‚îÇ
‚îÇ       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§                                        ‚îÇ
‚îÇ                          ‚îÇ                                        ‚îÇ
‚îÇ              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                             ‚îÇ
‚îÇ              ‚îÇ    Tool Registry     ‚îÇ                             ‚îÇ
‚îÇ              ‚îÇ  Built-in, MCP, WASM ‚îÇ                             ‚îÇ
‚îÇ              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò"><pre><code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                          Channels                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ
‚îÇ  ‚îÇ REPL ‚îÇ  ‚îÇ HTTP ‚îÇ  ‚îÇWASM Channels‚îÇ  ‚îÇ Web Gateway ‚îÇ            ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ (SSE + WS) ‚îÇ            ‚îÇ
‚îÇ     ‚îÇ         ‚îÇ              ‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îÇ
‚îÇ     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                   ‚îÇ
‚îÇ                              ‚îÇ                                     ‚îÇ
‚îÇ                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                          ‚îÇ
‚îÇ                    ‚îÇ    Agent Loop     ‚îÇ  Intent routing           ‚îÇ
‚îÇ                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò                          ‚îÇ
‚îÇ                         ‚îÇ         ‚îÇ                                ‚îÇ
‚îÇ              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê               ‚îÇ
‚îÇ              ‚îÇ  Scheduler   ‚îÇ  ‚îÇ Routines Engine  ‚îÇ               ‚îÇ
‚îÇ              ‚îÇ(parallel jobs)‚îÇ  ‚îÇ(cron, event, wh) ‚îÇ               ‚îÇ
‚îÇ              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò               ‚îÇ
‚îÇ                     ‚îÇ                   ‚îÇ                          ‚îÇ
‚îÇ       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                         ‚îÇ
‚îÇ       ‚îÇ             ‚îÇ                                              ‚îÇ
‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                           ‚îÇ
‚îÇ   ‚îÇ Local  ‚îÇ   ‚îÇ    Orchestrator     ‚îÇ                           ‚îÇ
‚îÇ   ‚îÇWorkers ‚îÇ   ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                           ‚îÇ
‚îÇ   ‚îÇ(in-proc)‚îÇ   ‚îÇ  ‚îÇ Docker Sandbox‚îÇ  ‚îÇ                           ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ  ‚îÇ   Containers  ‚îÇ  ‚îÇ                           ‚îÇ
‚îÇ       ‚îÇ        ‚îÇ  ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ  ‚îÇ                           ‚îÇ
‚îÇ       ‚îÇ        ‚îÇ  ‚îÇ ‚îÇWorker / CC‚îÇ ‚îÇ  ‚îÇ                           ‚îÇ
‚îÇ       ‚îÇ        ‚îÇ  ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ  ‚îÇ                           ‚îÇ
‚îÇ       ‚îÇ        ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                           ‚îÇ
‚îÇ       ‚îÇ        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                           ‚îÇ
‚îÇ       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§                                        ‚îÇ
‚îÇ                          ‚îÇ                                        ‚îÇ
‚îÇ              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                             ‚îÇ
‚îÇ              ‚îÇ    Tool Registry     ‚îÇ                             ‚îÇ
‚îÇ              ‚îÇ  Built-in, MCP, WASM ‚îÇ                             ‚îÇ
‚îÇ              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Core Components</h3><a id="user-content-core-components" aria-label="Permalink: Core Components" href="#core-components"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Component</th>
<th>Purpose</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Agent Loop</strong></td>
<td>Main message handling and job coordination</td>
</tr>
<tr>
<td><strong>Router</strong></td>
<td>Classifies user intent (command, query, task)</td>
</tr>
<tr>
<td><strong>Scheduler</strong></td>
<td>Manages parallel job execution with priorities</td>
</tr>
<tr>
<td><strong>Worker</strong></td>
<td>Executes jobs with LLM reasoning and tool calls</td>
</tr>
<tr>
<td><strong>Orchestrator</strong></td>
<td>Container lifecycle, LLM proxying, per-job auth</td>
</tr>
<tr>
<td><strong>Web Gateway</strong></td>
<td>Browser UI with chat, memory, jobs, logs, extensions, routines</td>
</tr>
<tr>
<td><strong>Routines Engine</strong></td>
<td>Scheduled (cron) and reactive (event, webhook) background tasks</td>
</tr>
<tr>
<td><strong>Workspace</strong></td>
<td>Persistent memory with hybrid search</td>
</tr>
<tr>
<td><strong>Safety Layer</strong></td>
<td>Prompt injection defense and content sanitization</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# First-time setup (configures database, auth, etc.)
ironclaw onboard

# Start interactive REPL
cargo run

# With debug logging
RUST_LOG=ironclaw=debug cargo run"><pre><span><span>#</span> First-time setup (configures database, auth, etc.)</span>
ironclaw onboard

<span><span>#</span> Start interactive REPL</span>
cargo run

<span><span>#</span> With debug logging</span>
RUST_LOG=ironclaw=debug cargo run</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Development</h2><a id="user-content-development" aria-label="Permalink: Development" href="#development"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Format code
cargo fmt

# Lint
cargo clippy --all --benches --tests --examples --all-features

# Run tests
createdb ironclaw_test
cargo test

# Run specific test
cargo test test_name"><pre><span><span>#</span> Format code</span>
cargo fmt

<span><span>#</span> Lint</span>
cargo clippy --all --benches --tests --examples --all-features

<span><span>#</span> Run tests</span>
createdb ironclaw_test
cargo <span>test</span>

<span><span>#</span> Run specific test</span>
cargo <span>test</span> test_name</pre></div>
<ul dir="auto">
<li><strong>Telegram channel</strong>: See <a href="https://github.com/nearai/ironclaw/blob/main/docs/TELEGRAM_SETUP.md">docs/TELEGRAM_SETUP.md</a> for setup and DM pairing.</li>
<li><strong>Changing channel sources</strong>: Run <code>./channels-src/telegram/build.sh</code> before <code>cargo build</code> so the updated WASM is bundled.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">OpenClaw Heritage</h2><a id="user-content-openclaw-heritage" aria-label="Permalink: OpenClaw Heritage" href="#openclaw-heritage"></a></p>
<p dir="auto">IronClaw is a Rust reimplementation inspired by <a href="https://github.com/openclaw/openclaw">OpenClaw</a>. See <a href="https://github.com/nearai/ironclaw/blob/main/FEATURE_PARITY.md">FEATURE_PARITY.md</a> for the complete tracking matrix.</p>
<p dir="auto">Key differences:</p>
<ul dir="auto">
<li><strong>Rust vs TypeScript</strong> - Native performance, memory safety, single binary</li>
<li><strong>WASM sandbox vs Docker</strong> - Lightweight, capability-based security</li>
<li><strong>PostgreSQL vs SQLite</strong> - Production-ready persistence</li>
<li><strong>Security-first design</strong> - Multiple defense layers, credential protection</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">Licensed under either of:</p>
<ul dir="auto">
<li>Apache License, Version 2.0 (<a href="https://github.com/nearai/ironclaw/blob/main/LICENSE-APACHE">LICENSE-APACHE</a>)</li>
<li>MIT License (<a href="https://github.com/nearai/ironclaw/blob/main/LICENSE-MIT">LICENSE-MIT</a>)</li>
</ul>
<p dir="auto">at your option.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Open Source Is Not About You (2018) (219 pts)]]></title>
            <link>https://gist.github.com/richhickey/1563cddea1002958f96e7ba9519972d9</link>
            <guid>47003219</guid>
            <pubDate>Fri, 13 Feb 2026 14:36:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gist.github.com/richhickey/1563cddea1002958f96e7ba9519972d9">https://gist.github.com/richhickey/1563cddea1002958f96e7ba9519972d9</a>, See on <a href="https://news.ycombinator.com/item?id=47003219">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="file-opensourceisnotaboutyou-md" tabindex="0" role="region" aria-label="OpenSourceIsNotAboutYou.md content, created by richhickey on 11:56PM on November 26, 2018.">
    <article itemprop="text">
<p dir="auto">The only people entitled to say how open source 'ought' to work are people who run projects, and the scope of their entitlement extends only to their own projects.</p>
<p dir="auto">Just because someone open sources something does not imply they owe the world a change in their status, focus and effort, e.g. from inventor to community manager.</p>
<p dir="auto">As a user of something open source you are not thereby entitled to anything at all. You are not entitled to contribute. You are not entitled to features. You are not entitled to the attention of others.  You are not entitled to having value attached to your complaints. You are not entitled to this explanation.</p>
<p dir="auto">If you have expectations (of others) that aren't being met, those expectations are your own responsibility. You are responsible for your own needs. If you want things, make them.</p>
<p dir="auto">Open source is a licensing and delivery mechanism, period. It means you get the source for software and the right to use and modify it. All social impositions associated with it, including the idea of 'community-driven-development' are part of a recently-invented mythology with little basis in how things actually work, a mythology that embodies, cult-like, both a lack of support for diversity in the ways things <em>can</em> work and a pervasive sense of communal entitlement.</p>
<p dir="auto">If you think Cognitect is not doing anything for the community, or is not listening to the community, you are simply wrong. You are not, however, entitled to it being the effort, focus or response you desire. We get to make our own choices as regards our time and lives.</p>
<p dir="auto">We at Cognitect have to show up to work, every day, to make a living. We get no royalties of any kind from Clojure. We are in no way building Clojure for profit. Far fewer than 1% of Clojure users are our consulting or product customers, and thus contributing to our livelihood.</p>
<p dir="auto">We take some of what we earn, money that could e.g. go into our retirement savings and instead use it to hire people to work on Clojure and community outreach, some full-time. To be honest, I could use that money in my retirement account, having depleted it to make Clojure in the first place. But I love working with the team on Clojure, and am proud of the work we do.</p>
<p dir="auto">Alex Miller is extremely attentive to and engaged with the Clojure community. He and Stu Halloway and I regularly meet and discuss community issues. Alex, at my direction, spends the majority of his time either working on features for the community or assessing patches and bug reports. I spend significant portions of my time designing these features - spec, tools.deps, error handling and more to come. This is time taken away from earning a living.</p>
<p dir="auto">I am grateful for the contributions of the community. Every Clojure release incorporates many contributions. The vast majority of the user community doesn't contribute, and doesn't desire to contribute. And that's fine. Open source is a no-strings-attached <em>gift</em>, and all participants should recognize it as such.</p>
<p dir="auto">The Clojure process is not closed, but it <em>is</em> conservative. I think Clojure benefits greatly from that conservatism, in contrast to some other projects with high churn rates and feature bloat. If you disagree or imagine otherwise, that's too bad. It's my life and I'm not going to spend it arguing/negotiating on/with the internet. Write your own things and run your own projects as you see fit.</p>
<p dir="auto">We can always do more, but it is specious to claim that the core team is standing in the way of meaningful contributions to Clojure, as opportunities abound: in library development, outreach, training, tutorials, documentation, giving talks, tool building etc.</p>
<p dir="auto">And yes, on patches to core. Did you know that most patches/issues have poor problem statements, no description of the plan (read my code!), no consideration of alternatives, no tests, no designs, and are ill-conceived and/or broken in some way? Community efforts to triage matter <em>a lot</em> in moving things forward - thanks Nicola, Ghadi and many others!</p>
<p dir="auto">The time to re-examine preconceptions about open source is right now. Morale erosion amongst creators is a real thing. Your preconceptions and how you act upon them are your responsibility and yours alone. I am not going to answer for them or to them.</p>
<p dir="auto">If the way Clojure works isn't for you, a process which produced Clojure in the first place, paradoxically, so be it. I'm sure you know better about the one true way to write software. But kindly don't burn the community down on your way out, with self-serving proclamations. Yes, everyone is entitled to an opinion, but, tragedy of the commons and all that.</p>
<p dir="auto">I encourage everyone gnashing their teeth with negativity at what they think they can't do instead pick something positive they can do and <em>do it</em>.</p>
<p dir="auto">Rich</p>
<p dir="auto">p.s. My partners and coworkers at Cognitect were not consulted regarding this message - I am certain they would have dissuaded me. These opinions are mine alone.</p>
<p dir="auto">p.p.s. I think the vast majority of people in the Clojure community are wonderful and positive. If you don't recognize yourself in the message above, it's not for/about you!</p>
</article>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How did the Maya survive? (138 pts)]]></title>
            <link>https://www.theguardian.com/news/2026/feb/12/apocalypse-no-how-almost-everything-we-thought-we-knew-about-the-maya-is-wrong</link>
            <guid>47003214</guid>
            <pubDate>Fri, 13 Feb 2026 14:36:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/news/2026/feb/12/apocalypse-no-how-almost-everything-we-thought-we-knew-about-the-maya-is-wrong">https://www.theguardian.com/news/2026/feb/12/apocalypse-no-how-almost-everything-we-thought-we-knew-about-the-maya-is-wrong</a>, See on <a href="https://news.ycombinator.com/item?id=47003214">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p><span>A</span>s a seven-year-old, Francisco Estrada-Belli was afraid all of history would have been discovered by the time he was old enough to contribute. The year was 1970 and he and his parents had come from Rome to visit relatives in the Central American country of <a href="https://www.theguardian.com/world/guatemala" data-link-name="in body link" data-component="auto-linked-tag">Guatemala</a>. On the trip, they visited the ancient Maya ruins at Tikal. ‚ÄúI was completely mesmerised,‚Äù Estrada-Belli told me recently. ‚ÄúIt was jungle everywhere, there were animals, and then these enormous, majestic temples. I asked questions but felt the answers were not good enough. I decided there and then that I wanted to be answering them.‚Äù</p><p>Fifty-five years later, Estrada-Belli is now one of the archaeologists helping to rewrite the history of the Maya peoples who built Tikal. Thanks to technological advances, we are entering a <a href="https://www.theguardian.com/science/2024/feb/20/solar-storms-ice-cores-and-nuns-teeth-inside-the-new-science-of-history" data-link-name="in body link">new age of discovery</a> in the field of ancient history. Improved DNA analysis, advances in plant and climate science, soil and isotope chemistry, linguistics and other techniques such as a laser mapping technology called Lidar, are overturning long-held beliefs. Nowhere is this more true than when it comes to Maya archaeology.</p><p>Last year, Estrada-Belli‚Äôs team, including his Tulane University colleague Marcello A Canuto, <a href="https://www.sciencedirect.com/science/article/pii/S2352409X25003219" data-link-name="in body link">published a&nbsp;study</a> with a central finding that would have seemed, just a few years ago, like an outrageously speculative overestimate. When Estrada-Belli first came to Tikal as a child, the best estimate for the classic-era (AD600-900) population of the surrounding Maya lowlands ‚Äì encompassing present day southern Mexico, Belize and northern Guatemala ‚Äì would have been about 2 million people. Today, his team believes that the<strong> </strong>region<strong> </strong>was home to up to 16 million. That is more than&nbsp;five times the area‚Äôs current population. This would mean that more people lived in the classic-era Maya lowlands than on the Italian peninsula during the peak of the Roman empire ‚Äì all crammed into an area a third of the size.</p><p>A comparison between the classic Maya and ancient Rome is instructive in other ways. Some Maya cities were established hundreds of years before the founding of Rome, and they included significantly larger architecture that still stands. Both cultures developed sophisticated astronomy, mathematics, writing and agriculture, as well as elaborate trade arrangements across vast cosmopolitan lands. The ruins of Rome are today covered by a bustling world city where some of the most prominent elite families claim to trace their ancestry directly to ancient times. Many Maya ruins, in contrast, are now covered by more than 1,000 years‚Äô worth of tropical forest while the descendants of the peoples who built those cities are some of the poorest people on Earth.</p><p>According to census records, the various Maya and much smaller Indigenous groups, such as Xinka and Garifuna, today account for more than 11 million people across Mexico, Guatemala, Belize, El Salvador, Honduras and the US. Most of them, 7.7 million, live in Guatemala, where they officially comprise 44% of the population. (Human rights organisations believe the number may be higher as it has long been stigmatised, even dangerous, to identify as Maya.)</p><p>History ‚Äì both ancient and recent ‚Äì is a key political issue for the Maya. In Guatemala, they have two central demands: first, that there be a full reckoning with the civil war and genocide that lasted from 1960 to 1996, and claimed about 200,000 lives, most of them Maya. Second, that they are recognised as the original inhabitants and legitimate owners of this land. As they see it, half a millennium of prejudice and discrimination against their community has led to a situation where, among other issues, two-thirds of the country‚Äôs arable land is controlled by only 2.5% of its farmers, few of them Maya, while 60% of Indigenous children are undernourished.</p><p>In 2023, the Maya peoples played a key role in the unlikely presidential election victory of a former diplomat named Bernardo Ar√©valo. The campaign to protect the vote against a corrupt judiciary was led by Indigenous groups and included 106 days of nationwide protests. Although Ar√©valo is not himself Maya, he is sympathetic to their cause. One of the people he appointed to his government is Liwy Grazioso, another prominent archaeologist with Italian roots, who now serves as minister of culture and sports. Grazioso is an expert in Maya history, and has published papers on the tombs of Rio Azul and the metropolis of Tikal, and overseen research on Kaminaljuyu, the ancient Maya city that rests under the capital. As a politician, she aims to build a country where the past and present can coexist, and where the country‚Äôs original inhabitants are a fully recognised part of the national story. ‚ÄúIt‚Äôs not that the Maya are better, or that their ancient society was somehow superior to ours, but because as humans they are the same,‚Äù she said while offering me a glass of unsweetened hibiscus tea.</p><p>We were sitting in a grand, wood-panelled office, on the third floor of El Guacamol√≥n, a mighty palace colloquially named after the colour of a mashed avocado dish, in the centre of Guatemala City. Since the palace‚Äôs completion in 1943, these bombastic halls&nbsp;have accommodated half a dozen military coups, as well as the planned annihilation of the lives, cultures, languages and history of the Maya. This oppression, of course, has a long history. Grazioso explained how Maya elites ‚Äì intellectuals, royals, astronomers, priests, writers and historians ‚Äì were systematically killed by the Spanish colonisers, and their texts burned as works of the devil.</p><figure id="c4cb29f2-2972-4915-ad6a-5d38f6a746c7" data-spacefinder-role="showcase" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-1"><picture><source srcset="https://i.guim.co.uk/img/media/18a5c411655c3a3e5bb4247eb3b3cbaf6d9cc167/789_123_4794_3834/master/4794.jpg?width=880&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 1300px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 1300px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/18a5c411655c3a3e5bb4247eb3b3cbaf6d9cc167/789_123_4794_3834/master/4794.jpg?width=880&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 1300px)"><source srcset="https://i.guim.co.uk/img/media/18a5c411655c3a3e5bb4247eb3b3cbaf6d9cc167/789_123_4794_3834/master/4794.jpg?width=800&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 1140px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 1140px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/18a5c411655c3a3e5bb4247eb3b3cbaf6d9cc167/789_123_4794_3834/master/4794.jpg?width=800&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 1140px)"><source srcset="https://i.guim.co.uk/img/media/18a5c411655c3a3e5bb4247eb3b3cbaf6d9cc167/789_123_4794_3834/master/4794.jpg?width=640&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 980px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 980px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/18a5c411655c3a3e5bb4247eb3b3cbaf6d9cc167/789_123_4794_3834/master/4794.jpg?width=640&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 980px)"><source srcset="https://i.guim.co.uk/img/media/18a5c411655c3a3e5bb4247eb3b3cbaf6d9cc167/789_123_4794_3834/master/4794.jpg?width=620&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/18a5c411655c3a3e5bb4247eb3b3cbaf6d9cc167/789_123_4794_3834/master/4794.jpg?width=620&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/18a5c411655c3a3e5bb4247eb3b3cbaf6d9cc167/789_123_4794_3834/master/4794.jpg?width=605&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/18a5c411655c3a3e5bb4247eb3b3cbaf6d9cc167/789_123_4794_3834/master/4794.jpg?width=605&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/18a5c411655c3a3e5bb4247eb3b3cbaf6d9cc167/789_123_4794_3834/master/4794.jpg?width=445&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/18a5c411655c3a3e5bb4247eb3b3cbaf6d9cc167/789_123_4794_3834/master/4794.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 320px)"><img alt="A woman pulls a street stall laden with products in front of a imposing palace and piazza" src="https://i.guim.co.uk/img/media/18a5c411655c3a3e5bb4247eb3b3cbaf6d9cc167/789_123_4794_3834/master/4794.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none" width="445" height="355.88861076345427" loading="lazy"></picture></div><figcaption data-spacefinder-role="inline"><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>A street trader outside the National Palace (El Guacamol√≥n) in Guatemala City.</span> Photograph: Marcus Haraldsson</figcaption></figure><p>Outsiders‚Äô power over the story of the Maya is written into the people‚Äôs very name. After their arrival in the early 1500s, the Spanish named local populations ‚ÄúMaya‚Äù after the ruined city of Mayap√°n in present day Mexico. Yet the Maya never saw themselves as one people and were never governed under one empire. They spoke many languages ‚Äì 30 of which are still around ‚Äì and belong to an intricate mix of cultures and identities.</p><p>By the time the field of Maya archaeology began in the 19th century, most of the knowledge once held by local leaders was gone. Over time, some observers spread pseudoscientific stories claiming that Maya temples were more likely to have been built by aliens than by ancestors of local people. (Vikings, Mormon Nephites and other mysteriously vanished civilisations have also been dubiously credited with building the ancient sites.) Grazioso believes that these fantastical theories serve a political purpose. ‚ÄúIf we deprive the actual Maya of their glorious past, we don‚Äôt need to give them power today,‚Äù she said. ‚ÄúTalking about collapse and aliens becomes a distraction from what is right in front of us.‚Äù</p><p>That is where the work of present-day archaeologists comes in. Until recently, the prevailing debate about the Maya centred around the question of why their civilisation collapsed. While scholars continue to study this question, an increasing number of archaeologists are now also asking: how did the Maya survive? The question addresses both their ancient ‚Äì and modern ‚Äì abilities to transform extremely challenging circumstances into enduring survival.</p><hr><p><span>F</span>or a long time, the idea that complex human settlements could once have existed in the Maya lowlands was seen as impossible. The theory was based on research in the Amazon rainforest in the 1950s and known as ‚Äúthe law of environmental limitation‚Äù. It held that lowland rainforests, with their thin soils, were not suitable for large advanced societies, as they could only produce limited amounts of food. This kind of land could only support small, primitive tribes. For many years, the idea was considered the closest thing to a natural law in anthropology.</p><p>When the theory was formulated, no large settlements had yet been discovered in the Amazon, but the Maya lowlands held thousands of massive stone pyramids, countless temples, raised causeways, engraved stone monuments and intricate tombs where buried royals were clad in luscious jade jewellery. Rather than positing the existence of highly populated, sophisticated Maya lowland cultures, many researchers <a href="https://caracol.org/wp-content/uploads/2024/03/Chases-Intro-2024.pdf" data-link-name="in body link">tried to square</a> what they found on the ground with the perceived law of environmental limitations. According to the ‚Äúsegmentary state‚Äù model, Maya kings ruled symbolically over a few disconnected communities living in tiny settlements separated by forest.</p><p>The law of environmental limitation was largely overturned in the 1980s, as the deciphering of Maya hieroglyphs allowed researchers to read the texts on large stone monuments, known as stelae, in city centres. The carvings had been believed to be astronomical or ceremonial but turned out to be historical. And the stories they told were not of primitive forest dwellers, but of kings and conquerors, queens and revolutions.</p><figure id="c6038ec7-8758-4b8f-8132-57727b6779c6" data-spacefinder-role="showcase" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-2"><picture><source srcset="https://i.guim.co.uk/img/media/66aa25e11f0ab9b591cf78063a1574d3551ba3d4/368_0_5021_4016/master/5021.jpg?width=880&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 1300px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 1300px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/66aa25e11f0ab9b591cf78063a1574d3551ba3d4/368_0_5021_4016/master/5021.jpg?width=880&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 1300px)"><source srcset="https://i.guim.co.uk/img/media/66aa25e11f0ab9b591cf78063a1574d3551ba3d4/368_0_5021_4016/master/5021.jpg?width=800&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 1140px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 1140px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/66aa25e11f0ab9b591cf78063a1574d3551ba3d4/368_0_5021_4016/master/5021.jpg?width=800&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 1140px)"><source srcset="https://i.guim.co.uk/img/media/66aa25e11f0ab9b591cf78063a1574d3551ba3d4/368_0_5021_4016/master/5021.jpg?width=640&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 980px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 980px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/66aa25e11f0ab9b591cf78063a1574d3551ba3d4/368_0_5021_4016/master/5021.jpg?width=640&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 980px)"><source srcset="https://i.guim.co.uk/img/media/66aa25e11f0ab9b591cf78063a1574d3551ba3d4/368_0_5021_4016/master/5021.jpg?width=620&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/66aa25e11f0ab9b591cf78063a1574d3551ba3d4/368_0_5021_4016/master/5021.jpg?width=620&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/66aa25e11f0ab9b591cf78063a1574d3551ba3d4/368_0_5021_4016/master/5021.jpg?width=605&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/66aa25e11f0ab9b591cf78063a1574d3551ba3d4/368_0_5021_4016/master/5021.jpg?width=605&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/66aa25e11f0ab9b591cf78063a1574d3551ba3d4/368_0_5021_4016/master/5021.jpg?width=445&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/66aa25e11f0ab9b591cf78063a1574d3551ba3d4/368_0_5021_4016/master/5021.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 320px)"><img alt="YaxhaÃÅ in Guatemala‚Äôs Pet√©n Basin." src="https://i.guim.co.uk/img/media/66aa25e11f0ab9b591cf78063a1574d3551ba3d4/368_0_5021_4016/master/5021.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none" width="445" height="355.92909778928504" loading="lazy"></picture></div><figcaption data-spacefinder-role="inline"><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>YaxhaÃÅ in Guatemala‚Äôs Pet√©n Basin.</span> Photograph: Marcus Haraldsson</figcaption></figure><p>In recent years a new story has formed, partly thanks to Lidar technology. Short for ‚Äúlight detection and ranging‚Äù, it consists here of bulky laser machines attached to twin engine aircrafts that fly half a kilometre above forests and fields. The equipment produces contour scans of the ground, making it possible to identify straight, round, or squared features, such as ancient ruins, fields, roads, temples, dams and fortifications. Lidar isn‚Äôt new ‚Äì it has mapped the moon and is today a key feature in many technologies, including self-driving cars ‚Äì but it made the leap into archaeology in central America in 2009, after researchers at the classic Maya city of Caracol in Belize saw biologists using it to measure forest growth. With some tweaking, they thought, it could also map the ground beneath rainforest canopies.</p><p>In 2016, when Francisco Estrada-Belli saw Lidar scans of Holmul in north-eastern Guatemala, he realised that ‚Äúarchaeology had changed for ever, there was no going back‚Äù. He explained to me how he had laboured for 16 years to map this major city, using measuring tape and the help of countless assistants. They waded through thick jungle to reconstruct what the city might have looked like throughout its 1,700 years of history. His teams had outlined about 1,000 structures. Now, he could compare this with Lidar findings. During just three days of scanning, it had mapped more than 7,000 structures: residential buildings, canals, terraces, field enclosures, causeways and defence walls. Lidar had produced a continuous scan of an area 10 times larger than his teams had managed on foot.</p><p>Subsequent large-scale mappings led to Estrada-Belli‚Äôs estimate that between 9.5 and 16 million people once lived in the Maya lowlands. He calls the lowlands in the 700s a ‚Äúcontinuously interconnected rural-urban sprawl‚Äù. This was a cosmopolitan region with high degrees of trade and settlements interconnected by a close web of causeways and roads. The ancient Maya did not use pack animals, or carriage wheels. Everything that was built and traded had to be carried by human force alone. Shoes had to be repaired, and people had to sleep and eat ‚Äì not by distances of a day‚Äôs ride by horse, as in Eurasia, but within walking distance. There was no wilderness in these lowlands, Estrada-Belli told me, but rather a low density scattering of people, businesses and agricultural fields, and managed wetlands and forests ‚Äì everywhere. Interspersed with all this were larger buildings, presumably for members of the elite.</p><p>This urban sprawl landscape opens a new set of questions. The most important of these, according to Estrada-Belli, has to do with agriculture. ‚ÄúWhen looking at Central American forests today, we must reckon with the fact that ancient humans affected everything,‚Äù he said. ‚ÄúThe tree species are there because the Maya chose them, the types of flowers are around because they made use of them, the wetlands served a human function. And so on. And all these methods were sustainable over thousands of years.‚Äù He described ‚Äúthe enormous investments the Maya put into canals, terraces and raised fields in water. They used extremely diverse, advanced and flexible farming methods, rotating and combining hundreds of species.‚Äù</p><p>Yet today humans use the land ‚Äúfor cattle farming and monocultural corn plantations that does nothing but destroy the land,‚Äù he said. ‚ÄúWe have a lot to learn.‚Äù</p><hr><p><span>T</span>ikal is the most visited of Guatemala‚Äôs Maya sites, welcoming hundreds of thousands of tourists every year. The surrounding woodlands belong to the Maya Biosphere Reserve, part of the largest tropical forest in the <a href="https://www.theguardian.com/world/americas" data-link-name="in body link" data-component="auto-linked-tag">Americas</a> outside the Amazon. It is easy to be seduced by the sense of mysticism here. At dawn, visitors sit in darkness on top of a 70-metre-tall temple hearing howler monkeys bawl in concert with thousands of crickets. The rising sun gradually reveals a seemingly endless tropical canopy interspersed only by the summits of other ancient pyramids. Only a tiny part of<strong> </strong>Tikal has been cleared of vegetation and restored to something vaguely resembling its former glory. The rest remains covered by thick layers of soil and trees.</p><p>The most recently inscribed stela found at Tikal was dated in AD869. Researchers‚Äô interpretation of what happened after that date has over the past few decades transformed from a ‚Äúsudden and disastrous‚Äù collapse into a historical era referred to as the Terminal Classic. The term encompasses a 200-year period when city centres were abandoned and farmers gradually moved to lands to the north and south. As Tikal and dozens of other cities were abandoned, places such as Chich√©n Itz√°, Uxmal and Mayap√°n further north on the Yucatan peninsula grew rapidly, as did settlements in the highlands to the south. It appears as if many people during classic Maya times chose to migrate, rather than simply waiting around as things fell apart around them.</p><figure id="d2417abf-3beb-4dc5-aa46-94e03a86f9b8" data-spacefinder-role="showcase" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-3"><picture><source srcset="https://i.guim.co.uk/img/media/1d923f10f28fba75dbade297a19a26a3b7caf3fd/0_0_5879_3905/master/5879.jpg?width=880&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 1300px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 1300px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/1d923f10f28fba75dbade297a19a26a3b7caf3fd/0_0_5879_3905/master/5879.jpg?width=880&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 1300px)"><source srcset="https://i.guim.co.uk/img/media/1d923f10f28fba75dbade297a19a26a3b7caf3fd/0_0_5879_3905/master/5879.jpg?width=800&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 1140px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 1140px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/1d923f10f28fba75dbade297a19a26a3b7caf3fd/0_0_5879_3905/master/5879.jpg?width=800&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 1140px)"><source srcset="https://i.guim.co.uk/img/media/1d923f10f28fba75dbade297a19a26a3b7caf3fd/0_0_5879_3905/master/5879.jpg?width=640&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 980px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 980px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/1d923f10f28fba75dbade297a19a26a3b7caf3fd/0_0_5879_3905/master/5879.jpg?width=640&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 980px)"><source srcset="https://i.guim.co.uk/img/media/1d923f10f28fba75dbade297a19a26a3b7caf3fd/0_0_5879_3905/master/5879.jpg?width=620&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/1d923f10f28fba75dbade297a19a26a3b7caf3fd/0_0_5879_3905/master/5879.jpg?width=620&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/1d923f10f28fba75dbade297a19a26a3b7caf3fd/0_0_5879_3905/master/5879.jpg?width=605&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/1d923f10f28fba75dbade297a19a26a3b7caf3fd/0_0_5879_3905/master/5879.jpg?width=605&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/1d923f10f28fba75dbade297a19a26a3b7caf3fd/0_0_5879_3905/master/5879.jpg?width=445&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/1d923f10f28fba75dbade297a19a26a3b7caf3fd/0_0_5879_3905/master/5879.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 320px)"><img alt="View of forests and sky with towers poking through treetops, relics from the Maya era" src="https://i.guim.co.uk/img/media/1d923f10f28fba75dbade297a19a26a3b7caf3fd/0_0_5879_3905/master/5879.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none" width="445" height="295.5817315870046" loading="lazy"></picture></div><figcaption data-spacefinder-role="inline"><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>The Tikal archeological site.</span> Photograph: Marcus Haraldsson</figcaption></figure><p>‚ÄúWe don‚Äôt really talk of collapse any more, but about decline, transformation and reorganisation of society and continuation of the culture,‚Äù said Kenneth E Seligson, an associate professor of archaeology at California State University. ‚ÄúSeveral similar shifts have happened in other places, such as Rome,‚Äù said Seligson. But ‚Äúwe rarely talk of the great Roman collapse any more, because they came back in various forms, just like the Maya‚Äù.</p><p>Seligson is one of many researchers seeking to shift attention from the Maya collapse to focus on their long-term survival. When its last stela was engraved, the city of Tikal could look back at more than 1,500 years of development. At the height of Tikal‚Äôs power in the 700s, it housed between 40,000 and 80,000 inhabitants, or even more, depending on where the city limits are drawn. This made it one of the world‚Äôs largest urban areas of the period. Yet the city looked nothing like the metropolitan expanses we are used to today. There was no grid of streets and fields for agriculture reached far into the city centre.</p><p>Living here required inventiveness. Most of Seligson‚Äôs research has focused on limestone, the bedrock under the Maya lowlands, covered only by a thin layer of soil. Limestone provides poor nutrition for most forms of farming, and allows any rainfall to quickly disappear into cracks that lead deep underground. On top of these challenges, for half the year, there is little rain. Yet Tikal and many other cities thrived. Inhabitants cultivated chocolate, vanilla, avocados, tomatoes, yuca, sweet potatoes and hundreds of other crops. Limestone was used to preserve food and purify water. It was used to make soap and for medicinal purposes. Houses were built of lime cement strengthened with sand and grass. Lime was even burnt and mixed with maize to help the Maya absorb nutrients. ‚ÄúThe Maya should really be known as a people of immense resilience. They worked with available resources to develop long-term highly flexible solutions,‚Äù said Seligson.</p><p>The eventual decline of Maya lowland cities is still a hotly debated matter. Estrada-Belli believes it could have been the result of shifting trade routes. Others ‚Äì including geographer Jared Diamond in his influential but controversial book Collapse ‚Äì attribute the supposed downfall to greed among the Maya elites leading to a human-made ecological disaster. Another much-discussed theory, <a href="https://journals.sagepub.com/doi/full/10.1177/03091333221129784" data-link-name="in body link">based on analysis</a> of sediments from lakes and caves, is climate change. Some argue that a centuries-long ‚Äúmegadrought‚Äù was the <a href="https://www.americanscientist.org/article/climate-and-the-collapse-of-maya-civilization" data-link-name="in body link">ultimate cause</a> for the decline of the classic Maya. Seligson, who recently wrote a book about the Maya and climate change, is not so sure. ‚ÄúClimate was undoubtedly an important factor,‚Äù he said, but it was one among many.</p><figure id="1c79ecf7-b688-4003-8810-640fec7e5005" data-spacefinder-role="showcase" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-4"><picture><source srcset="https://i.guim.co.uk/img/media/4e49c275cf5da9af9b34d52491c9702e7cbb935e/367_0_4465_3571/master/4465.jpg?width=880&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 1300px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 1300px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/4e49c275cf5da9af9b34d52491c9702e7cbb935e/367_0_4465_3571/master/4465.jpg?width=880&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 1300px)"><source srcset="https://i.guim.co.uk/img/media/4e49c275cf5da9af9b34d52491c9702e7cbb935e/367_0_4465_3571/master/4465.jpg?width=800&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 1140px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 1140px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/4e49c275cf5da9af9b34d52491c9702e7cbb935e/367_0_4465_3571/master/4465.jpg?width=800&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 1140px)"><source srcset="https://i.guim.co.uk/img/media/4e49c275cf5da9af9b34d52491c9702e7cbb935e/367_0_4465_3571/master/4465.jpg?width=640&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 980px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 980px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/4e49c275cf5da9af9b34d52491c9702e7cbb935e/367_0_4465_3571/master/4465.jpg?width=640&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 980px)"><source srcset="https://i.guim.co.uk/img/media/4e49c275cf5da9af9b34d52491c9702e7cbb935e/367_0_4465_3571/master/4465.jpg?width=620&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/4e49c275cf5da9af9b34d52491c9702e7cbb935e/367_0_4465_3571/master/4465.jpg?width=620&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/4e49c275cf5da9af9b34d52491c9702e7cbb935e/367_0_4465_3571/master/4465.jpg?width=605&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/4e49c275cf5da9af9b34d52491c9702e7cbb935e/367_0_4465_3571/master/4465.jpg?width=605&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/4e49c275cf5da9af9b34d52491c9702e7cbb935e/367_0_4465_3571/master/4465.jpg?width=445&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/4e49c275cf5da9af9b34d52491c9702e7cbb935e/367_0_4465_3571/master/4465.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 320px)"><img alt="Liwy Grazioso in her office in the National Palace." src="https://i.guim.co.uk/img/media/4e49c275cf5da9af9b34d52491c9702e7cbb935e/367_0_4465_3571/master/4465.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none" width="445" height="355.90033594624856" loading="lazy"></picture></div><figcaption data-spacefinder-role="inline"><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>Liwy Grazioso in her office in the National Palace.</span> Photograph: Marcus Haraldsson</figcaption></figure><p>True to her role as a government minister, Liwy Grazioso believes one key explanation was declining trust in leadership. In a <a href="https://journals.sagepub.com/doi/pdf/10.1177/00420980231224648" data-link-name="in body link">recent scientific article</a> about the rise and fall of Tikal, she and her co-authors list factors including economic competition, increased warfare, lack of arable land and failure of revenue streams, as well as depletion of soil quality and droughts. All these strains on society made it hard to maintain essential infrastructure such as reservoirs. When I met Grazioso in the National Palace, she compared the flamboyant government building where we met to the great pyramids of Tikal. ‚ÄúThis is a public building and it‚Äôs very beautiful. But to keep it, you need to use government money. When a crisis or a war is coming, who‚Äôs going to care? If the palace crumbles, who will pay attention? You will try to provide food for your family.‚Äù</p><p>Sitting in the current seat of power, Grazioso turned the argument to the present. She said: ‚ÄúIt is the same that happens now, if we are not careful. Governments need to earn the trust of their taxpayers.‚Äù</p><hr><p><span>S</span>onia Guti√©rrez is a lawyer of the Poqomam Maya people from the highlands south-west of the capital. As the only Indigenous woman among the 160 seats in the Guatemalan parliament, she is arguably the highest-ranking Maya in the country. ‚ÄúOur political system has never represented the reality of our nation,‚Äù she said to me in her office a few blocks south of the National Palace.</p><p>Guti√©rrez is the current leader of the Winaq party, founded by Rigoberta Mench√∫ who received the Nobel Peace Prize in 1992 for her efforts to end Guatemala‚Äôs civil war and achieve post-conflict reconciliation. ‚ÄúOur telling of history needs to change, and our society needs to change,‚Äù said Guti√©rrez. ‚ÄúOur vision goes back to the time before colonialism. We must be seen not as alien people, but as living in our country where our ancestors used to live.‚Äù</p><figure id="b14a7f23-1ce4-4747-8297-28462f0cb945" data-spacefinder-role="supporting" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-5"><picture><source srcset="https://i.guim.co.uk/img/media/5b7de3846c95a22768d448288b9347603324dd69/305_0_2225_2779/master/2225.jpg?width=380&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 1300px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 1300px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/5b7de3846c95a22768d448288b9347603324dd69/305_0_2225_2779/master/2225.jpg?width=380&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 1300px)"><source srcset="https://i.guim.co.uk/img/media/5b7de3846c95a22768d448288b9347603324dd69/305_0_2225_2779/master/2225.jpg?width=300&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 980px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 980px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/5b7de3846c95a22768d448288b9347603324dd69/305_0_2225_2779/master/2225.jpg?width=300&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 980px)"><source srcset="https://i.guim.co.uk/img/media/5b7de3846c95a22768d448288b9347603324dd69/305_0_2225_2779/master/2225.jpg?width=620&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/5b7de3846c95a22768d448288b9347603324dd69/305_0_2225_2779/master/2225.jpg?width=620&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/5b7de3846c95a22768d448288b9347603324dd69/305_0_2225_2779/master/2225.jpg?width=605&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/5b7de3846c95a22768d448288b9347603324dd69/305_0_2225_2779/master/2225.jpg?width=605&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/5b7de3846c95a22768d448288b9347603324dd69/305_0_2225_2779/master/2225.jpg?width=445&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/5b7de3846c95a22768d448288b9347603324dd69/305_0_2225_2779/master/2225.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 320px)"><img alt="Sonia Guti√©rrez standing up in her office." src="https://i.guim.co.uk/img/media/5b7de3846c95a22768d448288b9347603324dd69/305_0_2225_2779/master/2225.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none" width="445" height="555.8" loading="lazy"></picture></div><figcaption data-spacefinder-role="inline"><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>Sonia Guti√©rrez: ‚ÄòOur telling of history needs to change.‚Äô</span> Photograph: Marcus Haraldsson</figcaption></figure><p>‚ÄúI have three struggles,‚Äù she said. ‚ÄúI am a woman, I am Indigenous and I am on the democratic left. I&nbsp;am working against all of history for the vindication of our historic cause.‚Äù She spoke of the need for a ‚Äúplurinational‚Äù state that recognised the rights of self-governance among diverse groups. (Something similar <a href="https://www.tandfonline.com/doi/full/10.1080/10714839.2024.2388365" data-link-name="in body link">has been implemented</a>, with complications and backlash, into the constitutions of Bolivia and Ecuador.)</p><p>She talked about <em>utzilaj k‚Äôaslemal</em>, the good life ‚Äì a&nbsp;Maya concept she wants to see incorporated into the nation‚Äôs constitution. This would involve an approach to health in which modern medicine is ‚Äúcomplemented with ancestral knowledge‚Äù, an education system that teaches Indigenous languages, and a different approach to the natural world. ‚ÄúWe question the foundational capitalistic model,‚Äù said Guti√©rrez. ‚ÄúFor us, natural resources are not only to be exploited, but part of our existence, where we must take care of our rivers, our mountains, our forests. It is a vision of a plural society built on culture.‚Äù</p><p>And how could that be built? ‚ÄúIt will take a long time,‚Äù she admitted. Still, she said, there is an urgency to what she‚Äôs doing. ‚ÄúThe president and his administration give us a window of possibility. But I‚Äôm afraid that the old power structures have penetrated the state so much that the government is having a very hard time. And there is a lot of risk.‚Äù</p><p>Risk?</p><p>‚ÄúYes, if we do not act on this chance, there will not be another opportunity. And the revenge could be as severe as it was last time. We are up against well organised resistance to the ideas I am talking about.‚Äù Her conclusion was matter of fact: ‚ÄúWe could see another civil war.‚Äù</p><hr><p><span>A</span> few kilometres north of the government offices, remains from the civil war are still processed at the laboratories of the Guatemalan Forensic Anthropology&nbsp;Foundation (FAFG). Several of its staff were educated at the same institutions as Liwy Grazioso, and the technical advances that have transformed ancient archaeology are here employed to uncover modern Maya history: FAFG digs up and identifies victims of massacres.</p><p>First, witness interviews and documents help pinpoint areas of interest. Sometimes drone-mounted Lidar is then deployed to detect unusually lush patches of forest, since decomposing bodies make trees grow especially fast. Finally, investigators use DNA, as well as chemical analyses of soil, clothing, teeth, hair and bones to identify the dead.</p><p>Forensic anthropologist Alma V√°squez showed me around the laboratory. Eight human skeletons were laid out on blue tables. Under each table was a cardboard box marked with a location, date of recovery and ID number. Three of the skeletons were tiny. These were children found with two adults in a cave outside the village of Estancia de la Virgen, a&nbsp;couple of hours‚Äô drive north-west of Guatemala City. V√°squez believed that the bones belonged to a family that had tried to escape a notorious massacre that took place by the Pixcay√° River in 1982. The cranium of the smallest skeleton rested on striped red and pink padding. Vasquez estimated that the child was between one and three years old, and fragments of clothing suggested she had been a girl.<strong> </strong>The front of her cranium had been blown away by a grenade. There was a bullet hole through the back of her head.</p><p>If Vasquez‚Äôs hypothesis was correct, the little girl and her family belonged to a large community that fled their villages in early 1982. In the months prior, the <em>‚Äú</em>Guerrilla Army of the Poor‚Äù, which dominated in largely Indigenous villages in the area, had ‚Äúfreed‚Äù a small territory. As the government‚Äôs counterinsurgency focused on civilians, whom they assumed supported the guerrillas, the escaping families had sought refuge in the wooded and hilly upper banks of the Pixcay√°.</p><figure id="bb379877-db57-447e-906d-958582d25791" data-spacefinder-role="showcase" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-6"><picture><source srcset="https://i.guim.co.uk/img/media/52420b1b0c2ed3c30b323ddcfa59d8074adaa351/0_0_6016_4016/master/6016.jpg?width=880&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 1300px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 1300px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/52420b1b0c2ed3c30b323ddcfa59d8074adaa351/0_0_6016_4016/master/6016.jpg?width=880&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 1300px)"><source srcset="https://i.guim.co.uk/img/media/52420b1b0c2ed3c30b323ddcfa59d8074adaa351/0_0_6016_4016/master/6016.jpg?width=800&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 1140px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 1140px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/52420b1b0c2ed3c30b323ddcfa59d8074adaa351/0_0_6016_4016/master/6016.jpg?width=800&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 1140px)"><source srcset="https://i.guim.co.uk/img/media/52420b1b0c2ed3c30b323ddcfa59d8074adaa351/0_0_6016_4016/master/6016.jpg?width=640&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 980px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 980px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/52420b1b0c2ed3c30b323ddcfa59d8074adaa351/0_0_6016_4016/master/6016.jpg?width=640&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 980px)"><source srcset="https://i.guim.co.uk/img/media/52420b1b0c2ed3c30b323ddcfa59d8074adaa351/0_0_6016_4016/master/6016.jpg?width=620&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/52420b1b0c2ed3c30b323ddcfa59d8074adaa351/0_0_6016_4016/master/6016.jpg?width=620&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/52420b1b0c2ed3c30b323ddcfa59d8074adaa351/0_0_6016_4016/master/6016.jpg?width=605&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/52420b1b0c2ed3c30b323ddcfa59d8074adaa351/0_0_6016_4016/master/6016.jpg?width=605&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/52420b1b0c2ed3c30b323ddcfa59d8074adaa351/0_0_6016_4016/master/6016.jpg?width=445&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/52420b1b0c2ed3c30b323ddcfa59d8074adaa351/0_0_6016_4016/master/6016.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 320px)"><img alt="A woman in a lab coat inspects a skeleton that is under glass" src="https://i.guim.co.uk/img/media/52420b1b0c2ed3c30b323ddcfa59d8074adaa351/0_0_6016_4016/master/6016.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none" width="445" height="297.06117021276594" loading="lazy"></picture></div><figcaption data-spacefinder-role="inline"><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>A member of staff at the Guatemalan Forensic Anthropology Foundation (FAFG).</span> Photograph: Marcus Haraldsson</figcaption></figure><p>On the morning of 18 March, army units marched from three directions towards the gathering by the river. At 8am they opened fire at men, women and children with guns and grenade launchers. The slaughter lasted for hours. Eyewitnesses reported that troops raped women and drowned children in the river. By mid-morning the forest was burning and army helicopters were shooting fleeing survivors.</p><p>Estimates of the dead at the Pixcay√° River range between 300 and 400. Makeshift mass graves were dug on the river shore. There were reports of dogs in nearby villages gnawing on human bones. The skeletons of the little girl and her family that are now in Alma V√°squez‚Äôs forensic lab were not found until 2008. Their DNA has still not been matched with any survivors.</p><p>The massacre was one of the largest that took place during the bloodiest phase of the war in the early 1980s. But the event was typical in its systematic targeting of civilians. The eventual Commission for Historical Clarification, one of several official truth initiatives, <a href="https://bd91edfd-7ed9-4da0-b395-87e0ea880891.filesusr.com/ugd/d7b590_d96bd6465310493a8f020fad4441dd66.pdf" data-link-name="in body link">identified 626 massacres</a> carried out by government forces. They were deemed responsible for&nbsp;more than 93% of human rights violations. The report also described 32 mass killings perpetrated by guerrilla groups.</p><p>The war claimed more than 200,000 lives, and 83% of identified victims were Maya. More than 40,000 people are still missing. This sometimes means that relatives cannot claim inheritance, and that spouses cannot remarry or assert parenthood in unrecognised relationships. It also means that families do not get closure. FAFG currently holds 12,611 skeleton samples. Some were retrieved from mass graves, while others were discovered in road constructions or as homeowners expanded basements. Almost 4,000 individuals have been identified, mostly through DNA testing.</p><p>The work of FAFG is regularly used in court. Most famously, it contributed to the guilty verdict against Guatemala‚Äôs former president Efra√≠n R√≠os Montt for genocide and crimes against humanity. On 10 May 2013, he was sentenced to 80 years in prison for crimes against the Ixil Maya people. FAFG‚Äôs forensic proof, along with testimonies from survivors, and <a href="https://bd91edfd-7ed9-4da0-b395-87e0ea880891.filesusr.com/ugd/d7b590_3c9c4f56c7294681994253681e5578da.pdf" data-link-name="in body link">leaked military documents</a>, were vital evidence. The case centred on 15 massacres, where 1,771 people were killed by security forces under R√≠os Montt‚Äôs command. ‚ÄúThe verdict was crucial for people‚Äôs sense of belonging in the country,‚Äù Claudia Paz y Paz, who was attorney general at the time of the sentencing, told me.</p><p>In the end, however, it was a small victory. The sentence was suspended 10 days later on a technicality and R√≠os Montt was deemed too old for retrial. Even so, the ruling prompted a significant backlash. Military-linked networks and economic elites reasserted control of the justice system through judicial appointments, fabricated disciplinary cases and legislative changes.</p><p>Many lawyers involved in the post-civil war processes, as well as human rights activists and leading journalists, are today in legal detention or exile. And political murders <a href="https://www.ecoi.net/en/document/2136217.html" data-link-name="in body link">have increased</a>. Luis Pacheco and H√©ctor Chacl√°n, the leaders of the Indigenous movement that protected the democratic vote to install the current president, have so far spent 10 months in custody on seemingly spurious charges of terrorism and obstruction of justice.</p><p>‚ÄúWith a corrupt judiciary, the democratic government has very limited powers,‚Äù said Claudia Paz y Paz, who now lives in Costa Rica and would be at risk if she were to return home. During the spring of 2026, a range of consequential appointments will be made to Guatemala‚Äôs Supreme Election Tribunal, constitutional court, and attorney general. Impartial jurists in these positions, Paz y Paz concluded, will be crucial for the system to hold.</p><hr><p><span>N</span>ear the site of the Pixcay√° River massacre lies the town of San Juan Sacatep√©quez. A few blocks from the market, Blanca Subuyui and her team work on more urgent matters than the deep origins of their people, or even the bloody history of the civil war. Subuyui‚Äôs organisation, Asociaci√≥n Grupo Integral de Mujeres Sanjuaneras (Agims), offers shelter and assistance from nurses, midwives and lawyers to deal with the consequences of rape, domestic violence and child pregnancies. Agims also offers conflict mediation, professional education in weaving and handicrafts and a seedbank for agriculture. Some of the women who assist the network must hide their participation from their husbands.</p><p>‚ÄúWe believe we have something to bring for the future of this country,‚Äù Subuyui told me over a large serving of fruit. As the leader of Agims, she has helped develop a comprehensive plan for the future of <em>Ixumulew</em>, ‚Äúthe land of maize‚Äù as Guatemala is called in the Kaqchikel language. The title of the text, <em>Ri qab‚Äôe rech jun Utzilaj K‚Äôaslemal</em>, translates roughly as ‚ÄúOur path toward the good life‚Äù. The <a href="https://www.scribd.com/document/537417168/Descolonizacion-Guatemala#content=query%3Aantiguo%2CpageNum%3A197%2CindexOnPage%3A0%2CbestMatch%3Afalse&amp;amp;page=197" data-link-name="in body link">236-page document</a> has been developed during a seven-year process involving 164 Indigenous organisations.</p><figure id="a961050d-fd6b-41e4-9c1a-4cda10adddee" data-spacefinder-role="richLink" data-spacefinder-type="model.dotcomrendering.pageElements.RichLinkBlockElement"><gu-island name="RichLinkComponent" priority="feature" deferuntil="idle" props="{&quot;richLinkIndex&quot;:59,&quot;element&quot;:{&quot;_type&quot;:&quot;model.dotcomrendering.pageElements.RichLinkBlockElement&quot;,&quot;prefix&quot;:&quot;Related: &quot;,&quot;text&quot;:&quot;Guatemala‚Äôs baby brokers: how thousands of children were stolen for adoption&quot;,&quot;elementId&quot;:&quot;a961050d-fd6b-41e4-9c1a-4cda10adddee&quot;,&quot;role&quot;:&quot;richLink&quot;,&quot;url&quot;:&quot;https://www.theguardian.com/news/2024/jan/04/guatemalas-baby-brokers-how-tens-of-thousands-of-children-were-stolen-for-adoption&quot;},&quot;ajaxUrl&quot;:&quot;https://api.nextgen.guardianapps.co.uk&quot;,&quot;format&quot;:{&quot;design&quot;:10,&quot;display&quot;:1,&quot;theme&quot;:0}}"></gu-island></figure><p>Its very first demands are the ‚Äúfull recognition of Indigenous Nations as pre-existing the state of Guatemala‚Äù, that these nations should ‚Äúreclaim self-determination and sovereignty over our territories‚Äù and start by conducting a census without the ‚Äúintention of making us disappear‚Äù. The document also calls for reorganisation of the army away from the structures that committed the genocide and asks that large companies should ‚Äúpay the taxes they owe the country‚Äù.</p><p>‚ÄúWe do not want to take power from anybody, but we are the majority of the population, and it is fair that we have a seat at the table,‚Äù said Subuyui.</p><p>‚ÄúBut how can this plan be realised?‚Äù I asked. ‚ÄúThere is only one Indigenous woman in parliament, out of 160.‚Äù</p><p>Subuyui described the growth of their organisation. How Agims and other groups are making a difference in their communities, how people now know their rights and are starting to support themselves financially, how there is pride in history and trust in a shared future.</p><p>I told her about the fear that Sonia Guti√©rrez had expressed to me about revenge. And how prominent human rights leaders, judges and journalists are imprisoned, exiled, even murdered. Subuyui answered calmly: ‚ÄúWell, we are going nowhere. The struggle will continue, and the changes are now so profound that they are unstoppable. We will keep working no matter what, because we must. Change might take generations, but it is coming.‚Äù</p><figure id="be2a233a-9015-4828-b370-41f8478a9c12" data-spacefinder-role="thumbnail" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-7"><picture><source srcset="https://i.guim.co.uk/img/media/31178200706ad8e9ca181c5ddd48436b799b0d2e/0_0_960_1246/master/960.jpg?width=140&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 740px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 740px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/31178200706ad8e9ca181c5ddd48436b799b0d2e/0_0_960_1246/master/960.jpg?width=140&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 740px)"><source srcset="https://i.guim.co.uk/img/media/31178200706ad8e9ca181c5ddd48436b799b0d2e/0_0_960_1246/master/960.jpg?width=120&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/31178200706ad8e9ca181c5ddd48436b799b0d2e/0_0_960_1246/master/960.jpg?width=120&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 320px)"><img alt="The long read mag vol 2" src="https://i.guim.co.uk/img/media/31178200706ad8e9ca181c5ddd48436b799b0d2e/0_0_960_1246/master/960.jpg?width=120&amp;dpr=1&amp;s=none&amp;crop=none" width="120" height="155.75" loading="lazy"></picture></div><figcaption data-spacefinder-role="inline"><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span> Illustration: Guardian Design</figcaption></figure><p><em><span data-dcr-style="bullet"></span> The best stories take time</em>. From politics to philosophy, personal stories to true crime, discover a selection of the Guardian‚Äôs finest longform journalism, in the new <a href="https://guardianbookshop.com/the-guardian-long-read-5056368429583?utm_source=theguardian&amp;utm_medium=referral&amp;utm_campaign=longread" data-link-name="in body link">Guardian Long Read Magazine</a>. Order your copy today at <a href="https://guardianbookshop.com/the-guardian-long-read-5056368429583?utm_source=theguardian&amp;utm_medium=referral&amp;utm_campaign=longread" data-link-name="in body link">the Guardian bookshop</a>.</p></div></div>]]></description>
        </item>
    </channel>
</rss>