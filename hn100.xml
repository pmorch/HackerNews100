<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Fri, 12 Sep 2025 05:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[The effects of algorithms on the public discourse (140 pts)]]></title>
            <link>https://tekhne.dev/internet-resist/</link>
            <guid>45217545</guid>
            <pubDate>Fri, 12 Sep 2025 00:39:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tekhne.dev/internet-resist/">https://tekhne.dev/internet-resist/</a>, See on <a href="https://news.ycombinator.com/item?id=45217545">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    

    
        
    

    
        

        <p>
            <i>
                <time datetime="2025-09-09T23:59Z">
                    09/09/2025
                </time>
            </i>
        </p>
    

    <p>Come listen to the "old man yelling at clouds" in me for a bit.</p>
<p><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/tekhne/metaimageinternet.webp" alt="Old Man Yelling at Cloud"></p>
<blockquote>
<p><em><strong>tl;dr:</strong></em> The internet is changing for the worse (or getting 'enshittified'). In this post, I write about the effects of algorithms on the public discourse to illustrate a greater point on the enshittification of the internet. Then, I offer my personal notes and curated resources to guide you on your personal internet <em>de</em>shittification journey.</p>
</blockquote>
<p>I miss the old internet, and I don't mean the slow dial-up internet. No, I miss the internet specifically before it collapsed into a single, endless feed that we access through proprietary apps (now with AI slop!). I miss how it was a network that's both human, and humane. Back when it wasn't (primarily, at least) an algorithmic black hole made to just suck us in. Maybe it's the increasing corporate ownership of the internet that took people's agency from their hands. Who knows?</p>
<p>I want to remember, for example (and hopefully help rebuild) the internet where actual humans discovered each other's work by following trails others cared enough to leave behind; not because an LLM or some billionaire brat's<sup id="fnref-1"><a href="#fn-1">1</a></sup> algorithm 'fed' it to them. We used to use our curiosity to find stuff we liked, which felt more satisfying than any algorithm's statistically-determined aggregation.</p>
<p>I've had this blog hosted on <a href="https://bearblog.dev/">BearBlog</a> for more than a month now, and thanks to the community here, I've rediscovered the indie web. What's left of it, I mean. Still, it has been an absolute joy to read human-written words on all kinds of things I'm interested in. Many of my thoughts on the internet and the digital world as a whole were shaped by those. How cool is that! If this kind of an internet is still possible, why is it such a small part of the general network? Well, money. Here are examples to what makes money on the internet:</p>
<h2 id="context-collapse">Context Collapse</h2><p>I recently watched a great video from Technology Connections titled 'Algorithms Are Breaking How We Think' (<a href="https://www.youtube.com/watch?v=QEJpZjg8GuA">YouTube Link</a>/<a href="https://invidious.nerdvpn.de/watch?v=QEJpZjg8GuA">Invidious Link</a>).</p>
<p>Technology Connections talks about something known as 'context collapse'. The idea behind the term is that by combining multiple audiences into one single context, algorithmic media platforms bring out (usually) negative reactions from unrelated audiences. This means that even though every one of the billions of internet users have entirely different lives and backgrounds, social media platforms (even the seemingly-personalised ones like TikTok) have one single context on their main tabs. That context is that the user is a number among many that must be kept positive at all costs. Consequently, the ideal user of modern media platforms has no individual identity, and is perfectly happy with what's given to them by the algorithm.</p>
<p>As an example, think of how many of the posts you see on Instagram are actually from people or accounts that you deliberately chose to see. On the other hand, think of how many posts are from accounts you couldn't care less about, but the algorithm thinks you should (don't forget the 1/1 ad-to-post ratio!). The same thing goes for many other platforms. Even though some, like YouTube, at least <em>allow</em> you to use the platform with almost full agency over what you see<sup id="fnref-2"><a href="#fn-2">2</a></sup>, not many platforms do this. You have no choice but to use the official app with their own black-box algorithm<sup id="fnref-3"><a href="#fn-3">3</a></sup>. This way, the user's individual identity is replaced with that of the "average internet user", which they share with billions of other 'averages'.</p>
<p>The effect that this has on online discourse is immense. As every internet user must know, the internet (as it is today) is full of negativity. You might look at this and say, "Humans are inherently evil," and lose all hope in humanity given how horribly they treat each other on the internet. The truth is, the way we have constructed this space deindividualizes, alienates and aggregates us to such an extent. In other words, when billions of us are thrown into one large melting pot of context, the output of that pot becomes as impure as it could possibly be. It does not reflect how we form groups, act, and react in other areas of life.</p>
<h2 id="interpretive-communities">Interpretive Communities</h2><p>Literary theorist Stanley Fish argued that we as individuals interpret any given text (in this case, social media content) "because each of us is part of an interpretive community that gives us a particular way of reading a text."<sup id="fnref-4"><a href="#fn-4">4</a></sup> That interpretive community usually isn't there when we are fed what the algorithm thinks we'll consume. We may share something thinking that people like us will see it share their opinions. However, because of the way that algorithms work, engagement is the main driver of a post's visibility; so here comes 10 million people who have no clue of the context on that thought you shared about your niche interest.</p>
<p>Suddenly your post is full of over-the-top jokes and non-content-related quips from members of a completely random mix of audiences. As the algorithm prioritizes engagement, your post's new mixing pot of clueless audiences outnumbers the genuinely-interested audience of your own niche corner of the internet (if that even exists anymore), and they comment about everything BUT the content.</p>
<h2 id="think-thats-a-stretch">Think That's a Stretch?</h2><p>Okay, that was a hypothetical scenario, but here's a <em>real</em> community that massively benefited from all this: the incel community. Adam Aleksic’s book <a href="https://www.penguinrandomhouse.com/books/776856/algospeak-by-adam-aleksic/">Algospeak: How Social Media Is Transforming the Future of Language</a> tackles with this exact topic. He argues that algorithms contributed to the wide-spread use of pseudo-scientific incel terms by way of increased exposure. Here are two of my highlights:</p>
<blockquote>
<p>"Once algorithms got involved, the incel terms were amplified by the online <em>Matthew effect</em>: a phenomenon where content that is slightly better at grabbing your attention performs exponentially better on social media."</p>
</blockquote>
<p>Then, when these pseudo-scientific terms (think: 'alpha/beta male', 'chad', 'canthal tilt', 'looksmaxxing' etc.) are taken outside their respective interpretive communities and made hyper-visible, the mixing pot works its magic. From here, these terms make their way to the general public discourse:</p>
<blockquote>
<p>"Poe’s law explains how dangerous ideas spread as memes. If something is meant genuinely, but it is also crazy enough to be interpreted as a joke, people may reward it with “likes” and other engagement because they find it funny. Meanwhile, if something ironic is interpreted as genuine, people will be offended by it, which then also drives engagement as a form of ragebait. Either way, “edgy” humor is able to worm its way into the mainstream via the algorithm."</p>
</blockquote>
<p>So, if you want to get more people to know about your extreme views, package them as 'dumb jokes' for the algorithm to advertise to billions of people. At least that's what the incel community did, and succeeded. Can you even count how many times you heard or read those terms?</p>
<h2 id="okay-what-can-i-do">Okay, What Can I Do?</h2><p><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/tekhne/resist-keithharring.webp" alt="Resist"></p>
<p>Now, this is the part where I stop being the old man yelling at the cloud and start proposing a new way of using the internet. In this section, I have gathered some links to things that I either use or have used in the past, some personal notes on media I consumed, and quotes by brilliant writers. I'm doing this because I want to share a little bit of what I learned during my research on the open internet, even if they are not directly related to algorithmic feeds.</p>
<h3 id="use-and-support-free-libre-software">Use and Support Free (Libre) Software</h3><ul>
<li>Use RSS reader apps. Just go to a site blog or news site you like, then copy and paste its RSS link into your app of choice (almost all websites have an RSS link). With that, you've created your own algorithm. One that is owned and controlled by you, instead of silicon valley tech-bros.</li>
<li>Use <a href="https://www.theverge.com/24063290/fediverse-explained-activitypub-social-media-open-protocol">federated social media</a> instead of centralized ones that impede free speech and breach your right to privacy.</li>
<li>For secure messaging, <a href="https://signal.org/">use Signal where possible</a>, instead of WhatsApp or iMessage. Did you know that the US Government can access your messages if they have a warrant, regardless of your encryption settings? See: "<a href="https://propertyofthepeople.org/document-detail/?doc-id=21114562">Jan. 2021 FBI Infographic re Lawful Access to Secure Messaging Apps Data</a>"</li>
<li>If you're using Android, have a look at the many apps in <a href="https://f-droid.org/">F-Droid</a>: a FOSS (Free and Open Source Software) alternative to Google's Play Store.</li>
<li><a href="https://www.linuxmint.com/">Use GNU/Linux on your personal computer</a> to make technology fun again, and to say "F**K YOU" to Microsoft<sup id="fnref-5"><a href="#fn-5">5</a></sup>. If you're using a Mac, see: <a href="https://asahilinux.org/">Asahi Linux</a></li>
<li>If you want your Android phone to have better battery life, longer security support, increased privacy and more features; consider not using Google's version of Android at all! (See: <a href="https://grapheneos.org/">GrapheneOS(Only for Pixel devices)</a>, Others: <a href="https://e.foundation/e-os/">/e/OS</a>, <a href="https://lineageos.org/">LineageOS</a>)</li>
<li>(Advanced) If you have an old and unused laptop or desktop PC around, re-purpose it to create your own cloud (with your own music and video streaming services, storage, photo library and more)! See: <a href="https://casaos.zimaspace.com/">CasaOS</a> or <a href="https://yunohost.org/">YunoHost</a></li>
</ul>
<blockquote>
<p>"The tech stack we use is an endorsement of the companies behind it. Technological platforms are not neutral. If we truly want to resist the digital coup that is currently under way, we need to normalize the use of free, open source solutions."</p>
<p><strong>--- and ---</strong></p>
<p>"We constrain our imaginations when we subordinate our creations to names owned by fascist tycoons. Imagine the author of a book telling people to "read my Amazon". A great director trying to promote their film by saying "click on my Max". That's how much they've pickled your brain when you refer to your own work and your own voice within the context of their walled garden. There is no such thing as "my Substack", there is only your writing, and a forever fight against the world of pure enshittification."</p>
<p><strong>---</strong> <em>highlights from "<a href="https://news.elenarossini.com/this-is-what-resistance-to-the-digital-coup-looks-like/">This is what resistance to the digital coup looks like</a>" by Elena Rossini</em></p>
</blockquote>
<h3 id="curate-over-engage">Curate Over Engage</h3><ul>
<li><p><a href="https://bearblog.dev/">Start a blog</a> if you want. Share your experiences or thoughts about <em>anything</em>. You don't have to write something that has never been written before. Just have fun, and some people will probably benefit from, and enjoy your writing <em>at some point.</em></p>
</li>
<li><p>Scavenging for information used to be optimal, but now we live in a world of information overload. Notice the algorithm's firm grip over your attention.</p>
<ul>
<li>Prioritize discernment; focus on what information is needed and how it connects to your existing knowledge.</li>
<li>Set boundaries on information consumption by using attentional filters.</li>
<li>Block out redundant, overwhelming, or poor-quality information to avoid constant distraction.</li>
</ul>
</li>
</ul>
<blockquote>
<p><em>On helping revive the human network of the internet:</em></p>
<p>"Regardless of the kind of site you have, whether its a modern site for a business or arts practice, or if its a personal homepage; setup a links page on your site and add links to your friends, people you’ve worked with, tools you’ve used, blogs you enjoy, other businesses, anything and everything that deserves to be seen; because it does deserve to be seen, and so do you!"</p>
<p>---<em>highlight from "<a href="https://thoughts.melonking.net/thoughts/every-site-needs-a-links-page-why-linking-matters">Why linking matters</a>" by Melon's Thoughts</em></p>
</blockquote>
<p>I'll add more to this list as time goes on, and use it as my personal rolling list of apps, services, or notes for a more open and free internet. You can bookmark it if you like the list.</p>
<p>But for now, thank you for visiting my corner of the internet.</p>
<hr>
<p>This post was last edited <strong>1&nbsp;hour, 10&nbsp;minutes ago</strong>.</p>
<hr>
<section>
<ol>
<li id="fn-1"><p>Elon Musk, Mark Zuckerberg et al.<a href="#fnref-1">↩</a></p></li>
<li id="fn-2"><p>You can turn off recommendations and 'watch history' in YouTube. Either with in-app settings or, on desktop, with extensions like 'Minimal YouTube'. You can even use <a href="https://invidious.io/">Invidious</a>, even though Google absolutely hates it. Eat it, Google.<a href="#fnref-2">↩</a></p></li>
<li id="fn-3"><p>You technically have <em>some</em> options to get rid of algorithms and AI-slop on other platforms too, but they only work on Android devices and aren't stable. See: <a href="https://www.distractionfreeapps.com/">DistractionFreeApps for Instagram</a>, and <a href="https://github.com/crimera/piko#:~:text=Details">Piko for Twitter</a><a href="#fnref-3">↩</a></p></li>
<li id="fn-4"><p>Fish, Stanley (2000). "How to Recognize a Poem When You See One". <em>Falling into Theory: Conflicting Views on Reading Literature</em>: 267–278.<a href="#fnref-4">↩</a></p></li>
<li id="fn-5"><p>See: <a href="https://blog.boycat.io/posts/microsoft-israel-gaza-war-leaked-documents-complicity">"Everything you need to know about how Microsoft aided Israel’s war on Gaza"</a><a href="#fnref-5">↩</a></p></li>
</ol>
</section>


    

    
        
            <p>
                
                    <a href="https://tekhne.dev/arsiv/?q=algorithm">#algorithm</a>
                
                    <a href="https://tekhne.dev/arsiv/?q=apps">#apps</a>
                
                    <a href="https://tekhne.dev/arsiv/?q=en">#en</a>
                
                    <a href="https://tekhne.dev/arsiv/?q=libresoftware">#libresoftware</a>
                
                    <a href="https://tekhne.dev/arsiv/?q=list">#list</a>
                
                    <a href="https://tekhne.dev/arsiv/?q=tech">#tech</a>
                
                    <a href="https://tekhne.dev/arsiv/?q=theinternet">#theinternet</a>
                
            </p>
        

        
            


        
    


  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why our website looks like an operating system (144 pts)]]></title>
            <link>https://posthog.com/blog/why-os</link>
            <guid>45217269</guid>
            <pubDate>Thu, 11 Sep 2025 23:45:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://posthog.com/blog/why-os">https://posthog.com/blog/why-os</a>, See on <a href="https://news.ycombinator.com/item?id=45217269">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>I have a problem with many large, technical websites.</p><p>Often times, I’ll want to refer to different pages at the same time. So I’ll <code>CMD</code> + click “a couple times” while browsing around and before I know it, I have 12 new tabs open – all indistinguishable from each other because they share the same favicon.</p><p>PostHog.com has the same problem – especially as the site has grown from supporting a handful of paid products to over a dozen.</p><p>As I looked for ways to solve this explosion of pages, I started to question many of the typical patterns that marketing &amp; docs websites have today.</p><p>Long-form scrolling. Oversized footers. Absurd whitespace.</p><p>These website <em>encourage</em> scrolling, but just to get people to the bottom of the page? And then what?</p><p>Why are we doing this? What if we just made better ways to consume content?</p><p>That’s the idea behind the new PostHog.com. You can multitask, open a few articles simultaneously, and move them around as you please. If anything there's a whitespace deficiency, and your fingers will be jealous you're not scrolling with them as much (because you're so engaged with our content).</p><p>It has window snapping, keyboard shortcuts, and a bookmark app. It works as well as you’d expect an operating system to work in a browser.</p><p>You can be reading the latest newsletter from Product for Engineers while watching a demo video in the corner and also playing Hedgehog Mode, the game.</p><p>I’ll be the first to admit it – an OS interface for a “website” is initially a jarring experience. I felt this as I built it. The human brain expects certain patterns within the confines of a browser viewport, and when it doesn’t get that assurance, it revolts.</p><p>But the more I used the new site, the more I started to like it. And the experience was the same for colleagues. And now I can’t imagine using anything else.</p><p>I had a lot of fun in building it with <span><a href="https://posthog.com/community/profiles/28804"><span><span><span>Eli Kinsey</span></span></span></a></span>. Throughout the site you’ll find:</p><ul><li>A <span data-state="closed"><a href="https://posthog.com/products">Windows File Explorer</a></span> clone that also acts as the UI for <span data-state="closed"><a href="https://posthog.com/merch">our merch store</a></span></li><li><span data-state="closed"><a href="https://posthog.com/llm-analytics">Product pages</a></span> that resemble PowerPoint presentations</li><li>A <span data-state="closed"><a href="https://posthog.com/customers">document editor</a></span> where you can actually edit content</li><li><span data-state="closed"><a href="https://posthog.com/questions">Forums</a></span> designed to look like you’re reading newsgroups in Outlook Express</li><li>A <span data-state="closed"><a href="https://posthog.com/demo">QuickTime clone</a></span></li><li>A lot of pages you’d expect to be well-designed that are… just <span data-state="closed"><a href="https://posthog.com/changelog">formatted as spreadsheets</a></span></li><li>A screensaver and a <span data-state="closed"><a href="https://posthog.com/display-options">library of desktop backgrounds</a></span></li><li>A plethora of <span data-state="closed"><a href="https://posthog.com/kbd">keyboard shortcuts</a></span></li></ul><p>It was also an interesting learning curve for me in figuring out how to organize five years worth of content while making it scalable for the future. Some of the technical highlights:</p><ul><li>Separation of visual layer from content<ul><li>All product pages are now powered from JSON files (<span data-state="closed"><a rel="noopener noreferrer" href="https://github.com/PostHog/posthog.com/blob/windows-n-such/src/hooks/productData/session_replay.tsx" target="_blank"><span><span>example</span><svg width="100%" fill="currentColor" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path fill-rule="evenodd" d="M7.995 5.75a.75.75 0 0 1 .75-.75h8.505c.966 0 1.75.784 1.75 1.75v9.496a.75.75 0 0 1-1.5 0V7.56L7.03 18.03a.75.75 0 0 1-1.06-1.061L16.44 6.5H8.744a.75.75 0 0 1-.75-.75Z" clip-rule="evenodd"></path></svg></span></a></span>). This means that JSON dictates page layouts, content presentation, feature-level competitor comparison charts, and more. It also contains an array of screenshots used in various places (both in light and dark mode, of course).</li><li>Eventually this will move to a repository that’s shared with the PostHog app, so all the information is powered from the same source.</li></ul></li><li>Skinning a site with themes <em>and</em> color schemes<ul><li>How do you maintain light and dark mode, along with themes across a handful of accent variations (primary, secondary, tertiary) in a way that all play well together? (I found this out, and I’ll write about it sometime!)</li></ul></li><li>A reference customer database<ul><li>I’ve created a single customer record <span data-state="closed"><a rel="noopener noreferrer" href="https://github.com/PostHog/posthog.com/blob/61ad1a9ea079d6e0422a95ab453acbddf4cdd5a4/src/hooks/useCustomers.tsx#L364" target="_blank"><span><span>in code</span><svg width="100%" fill="currentColor" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path fill-rule="evenodd" d="M7.995 5.75a.75.75 0 0 1 .75-.75h8.505c.966 0 1.75.784 1.75 1.75v9.496a.75.75 0 0 1-1.5 0V7.56L7.03 18.03a.75.75 0 0 1-1.06-1.061L16.44 6.5H8.744a.75.75 0 0 1-.75-.75Z" clip-rule="evenodd"></path></svg></span></a></span> that contains: a) which products they use, b) quotes from specific people about individual products c) SVG logos that work in light and dark mode</li><li>This means that any quote can be presented on any page for any product without having to be hard-coded. It pulls in their name and photo, quote, and company logo, and can be filtered in reference to a specific product.</li></ul></li></ul><p>For a lot of this site, I was designing it <em>while</em> I was building UIs in Typescript and Tailwind. (The entire site is just a Git branch off our current site – it's all technically the same codebase. I just merged along the way over the last few months.)</p><p>Prototyping in a production-level environment was a great way to ideate and develop features along the way – stuff I never would have built if I were just going off of mockups. I did find myself <span data-state="closed"><a rel="noopener noreferrer" href="https://x.com/ninepixelgrid/status/1936994050625679692" target="_blank"><span><span>popping open Balsamiq while I was building</span><svg width="100%" fill="currentColor" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path fill-rule="evenodd" d="M7.995 5.75a.75.75 0 0 1 .75-.75h8.505c.966 0 1.75.784 1.75 1.75v9.496a.75.75 0 0 1-1.5 0V7.56L7.03 18.03a.75.75 0 0 1-1.06-1.061L16.44 6.5H8.744a.75.75 0 0 1-.75-.75Z" clip-rule="evenodd"></path></svg></span></a></span> – but just long enough to flesh out some ideas.</p><p>So how will this pan out? Well, we’re about to find out. This feels like an early MVP – there’s a ton of stuff to improve upon from here.</p><p>But in the meantime, I hope you enjoy the new PostHog.com. Be curious, click around, and have some fun. I hope you enjoy your time here as much as we enjoyed building it.</p><p>If you're curious, <span data-state="closed"><a href="https://posthog.com/handbook/engineering/posthog-com/how-posthog-website-works">read more about how the site technically works</a></span>.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Fartscroll-Lid: An app that plays fart sounds when opening or closing a MacBook (177 pts)]]></title>
            <link>https://github.com/iannuttall/fartscroll-lid</link>
            <guid>45216844</guid>
            <pubDate>Thu, 11 Sep 2025 22:41:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/iannuttall/fartscroll-lid">https://github.com/iannuttall/fartscroll-lid</a>, See on <a href="https://news.ycombinator.com/item?id=45216844">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">FartScrollLid 💨</h2><a id="user-content-fartscrolllid-" aria-label="Permalink: FartScrollLid 💨" href="#fartscrolllid-"></a></p>
<p dir="auto">A hilarious macOS app that plays fart sounds as you open and close your MacBook lid - inspired by the classic "fart scroll" browser extension!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li>🎵 <strong>Dynamic Fart Sounds</strong> - Pitch changes based on lid angle (deep bass when closed, high squeaks when open)</li>
<li>🎯 <strong>Motion-Activated</strong> - Only farts when you're actively moving the lid</li>
<li>📊 <strong>Real-Time Monitoring</strong> - Shows lid angle, velocity, and fart parameters</li>
<li>😄 <strong>Funny Status Messages</strong> - "Maximum pressure!", "Gas escaping!", and more</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">How It Works</h2><a id="user-content-how-it-works" aria-label="Permalink: How It Works" href="#how-it-works"></a></p>
<p dir="auto">FartScrollLid uses the MacBook's internal lid angle sensor (discovered through reverse engineering) to detect the angle between your laptop lid and base. When you move the lid, it triggers fart sounds with:</p>
<ul dir="auto">
<li><strong>Pitch modulation</strong> based on lid angle (0-130 degrees)</li>
<li><strong>Volume control</strong> based on movement speed</li>
<li><strong>Instant response</strong> - farts stop immediately when you stop moving</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Requirements</h2><a id="user-content-requirements" aria-label="Permalink: Requirements" href="#requirements"></a></p>
<ul dir="auto">
<li>macOS 11.5 or later</li>
<li>MacBook with lid angle sensor (most modern MacBooks)</li>
<li>A sense of humor</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Option 1: Build from Source</h3><a id="user-content-option-1-build-from-source" aria-label="Permalink: Option 1: Build from Source" href="#option-1-build-from-source"></a></p>
<ol dir="auto">
<li>Clone this repository:</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/iannuttall/fartscroll-lid.git
cd fartscroll-lid"><pre>git clone https://github.com/iannuttall/fartscroll-lid.git
<span>cd</span> fartscroll-lid</pre></div>
<ol start="2" dir="auto">
<li>Open in Xcode:</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="open FartScrollLid.xcodeproj"><pre>open FartScrollLid.xcodeproj</pre></div>
<ol start="3" dir="auto">
<li>Build and run (Cmd+R)</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">Option 2: Download Release</h3><a id="user-content-option-2-download-release" aria-label="Permalink: Option 2: Download Release" href="#option-2-download-release"></a></p>
<p dir="auto">Download the latest <code>.app</code> from the <a href="https://github.com/iannuttall/fartscroll-lid/releases">Releases</a> page.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<ol dir="auto">
<li>Launch FartScrollLid</li>
<li>Click "Start Farting"</li>
<li>Move your MacBook lid up and down</li>
<li>Enjoy the symphony of farts!</li>
<li>Stop moving to silence the farts</li>
<li>Click "Stop Farting" when you've had enough fun</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Technical Details</h2><a id="user-content-technical-details" aria-label="Permalink: Technical Details" href="#technical-details"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Lid Angle Sensor</h3><a id="user-content-lid-angle-sensor" aria-label="Permalink: Lid Angle Sensor" href="#lid-angle-sensor"></a></p>
<ul dir="auto">
<li><strong>Device</strong>: Apple HID device (VID=0x05AC, PID=0x8104)</li>
<li><strong>HID Usage</strong>: Sensor page (0x0020), Orientation usage (0x008A)</li>
<li><strong>Data format</strong>: 16-bit angle value in centidegrees (0.01° resolution)</li>
<li><strong>Range</strong>: 0-360 degrees</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Audio Engine</h3><a id="user-content-audio-engine" aria-label="Permalink: Audio Engine" href="#audio-engine"></a></p>
<ul dir="auto">
<li>Uses AVFoundation for real-time audio playback</li>
<li>Varispeed unit for pitch modulation (0.5x to 2.0x)</li>
<li>Smooth parameter ramping to avoid audio artifacts</li>
<li>Movement threshold: 2 deg/s minimum to trigger farts</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Project Structure</h2><a id="user-content-project-structure" aria-label="Permalink: Project Structure" href="#project-structure"></a></p>
<div data-snippet-clipboard-copy-content="FartScrollLid/
├── FartScrollLid.xcodeproj/    # Xcode project
├── FartScrollLid/              # Source code
│   ├── AppDelegate.m/h         # Main app controller
│   ├── FartScrollLid.m/h       # Lid angle sensor interface
│   ├── FartAudioEngine.m/h     # Fart sound engine
│   ├── NSLabel.m/h             # Custom label class
│   └── FART.wav                # Fart sound file
└── README.md                   # This file"><pre><code>FartScrollLid/
├── FartScrollLid.xcodeproj/    # Xcode project
├── FartScrollLid/              # Source code
│   ├── AppDelegate.m/h         # Main app controller
│   ├── FartScrollLid.m/h       # Lid angle sensor interface
│   ├── FartAudioEngine.m/h     # Fart sound engine
│   ├── NSLabel.m/h             # Custom label class
│   └── FART.wav                # Fart sound file
└── README.md                   # This file
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Credits</h2><a id="user-content-credits" aria-label="Permalink: Credits" href="#credits"></a></p>
<ul dir="auto">
<li>Based on the original <a href="https://github.com/samhenrigold/LidAngleSensor">LidAngleSensor</a> app by Sam Henri Gold</li>
<li>Fart sound from <a href="https://github.com/74656c/fart.js">fart.js</a></li>
<li>Inspired by the original fart scroll browser extension by The Onion</li>
<li>Built with assistance from Factory Droid</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">MIT License - see <a href="https://github.com/iannuttall/fartscroll-lid/blob/main/LICENSE">LICENSE</a> file for details</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">Pull requests are welcome! For major changes, please open an issue first to discuss what you would like to change.</p>
<p dir="auto">Ideas for improvements:</p>
<ul dir="auto">
<li>Additional fart sound variations</li>
<li>Customizable pitch/volume curves</li>
<li>Fart statistics tracking</li>
<li>Network multiplayer farting</li>
<li>Apple Watch companion app</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Disclaimer</h2><a id="user-content-disclaimer" aria-label="Permalink: Disclaimer" href="#disclaimer"></a></p>
<p dir="auto">This app is for entertainment purposes only. Please use responsibly in appropriate settings. Not recommended for:</p>
<ul dir="auto">
<li>Business meetings</li>
<li>Libraries</li>
<li>First dates</li>
<li>Job interviews</li>
<li>Funerals</li>
</ul>
<p dir="auto">But highly recommended for:</p>
<ul dir="auto">
<li>Pranking friends</li>
<li>Amusing children</li>
<li>Breaking awkward silences</li>
<li>General tomfoolery</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Author</h2><a id="user-content-author" aria-label="Permalink: Author" href="#author"></a></p>
<p dir="auto">Created by Ian Nuttall with Factory Droid</p>
<hr>
<p dir="auto"><em>Remember: Life is too short not to laugh at fart sounds from your laptop</em> 💨😄</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Danish supermarket chain is setting up "Emergency Stores" (198 pts)]]></title>
            <link>https://swiss.social/@swaldorff/115186445638788782</link>
            <guid>45216805</guid>
            <pubDate>Thu, 11 Sep 2025 22:35:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://swiss.social/@swaldorff/115186445638788782">https://swiss.social/@swaldorff/115186445638788782</a>, See on <a href="https://news.ycombinator.com/item?id=45216805">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[How Palantir is mapping the nation’s data (189 pts)]]></title>
            <link>https://theconversation.com/when-the-government-can-see-everything-how-one-company-palantir-is-mapping-the-nations-data-263178</link>
            <guid>45215984</guid>
            <pubDate>Thu, 11 Sep 2025 20:50:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://theconversation.com/when-the-government-can-see-everything-how-one-company-palantir-is-mapping-the-nations-data-263178">https://theconversation.com/when-the-government-can-see-everything-how-one-company-palantir-is-mapping-the-nations-data-263178</a>, See on <a href="https://news.ycombinator.com/item?id=45215984">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>When the U.S. government signs contracts with private technology companies, the fine print rarely reaches the public. <a href="https://www.palantir.com/">Palantir Technologies</a>, however, has attracted more and more attention over the past decade because of the size and scope of its contracts with the government. </p>

<p>Palantir’s two main platforms are Foundry and Gotham. Each does different things. Foundry is used by corporations in the private sector to help with global operations. Gotham is marketed as an “<a href="https://www.palantir.com/platforms/gotham/">operating system for global decision making</a>” and is primarily used by governments.</p>

<p>I am <a href="https://scholar.google.com/citations?user=JnTFiOQAAAAJ&amp;hl=en">a researcher</a> who studies the intersection of data governance, digital technologies and the U.S. federal government. I’m observing how the government is increasingly <a href="https://theconversation.com/from-help-to-harm-how-the-government-is-quietly-repurposing-everyones-data-for-surveillance-254690">pulling together data from various sources</a>, and the political and social consequences of combining those data sources. Palantir’s work with the federal government using the Gotham platform is amplifying this process.</p>

<p>Gotham is an investigative platform built for police, national security agencies, public health departments and other state clients. Its purpose is deceptively simple: take whatever data an agency already has, break it down into its smallest components and then connect the dots. Gotham is not simply a database. It takes fragmented data, scattered across various agencies and stored in different formats, and transforms it <a href="https://assets.applytosupply.digitalmarketplace.service.gov.uk/g-cloud-14/documents/92736/801146272055049-service-definition-document-2024-11-26-1253.pdf">into a unified, searchable web</a>.</p>

<p>The stakes are high with Palantir’s Gotham platform. The software enables law enforcement and government analysts to connect vast, disparate datasets, build intelligence profiles and search for individuals based on characteristics as granular as a tattoo or an immigration status. It transforms <a href="https://www.vice.com/en/article/revealed-this-is-palantirs-top-secret-user-manual-for-cops/">historically static records</a> – think department of motor vehicles files, police reports and subpoenaed social media data like location history and private messages – into a fluid web of intelligence and surveillance.</p>

<p>These departments and agencies use Palantir’s platform to assemble <a href="https://epic.org/epic-settles-ice-lawsuit-about-palantir-and-profiling/">detailed profiles of individuals</a>, mapping their social networks, tracking their movements, identifying their physical characteristics and reviewing their criminal history. This can involve mapping a suspected <a href="https://www.nola.com/news/crime_police/how-a-tech-firm-brought-data-and-worry-to-new-orleans-crime-fighting/article_33b8bf05-722f-5163-9a0c-774aa69b6645.html">gang member’s network</a> using arrest logs and <a href="https://www.wired.com/story/drive-los-angeles-police-track-every-move/">license plate reader data</a>, or flagging individuals in a specific region with a particular immigration status.</p>

<p>The efficiency the platform enables is undeniable. For investigators, what once required weeks of cross-checking siloed systems can now be done in hours or less. But by scaling up the government’s investigative capacity, Gotham also alters the relationship between the state and the people it governs.</p>

<figure>
            <a href="https://images.theconversation.com/files/687583/original/file-20250826-55-ovh07.jpg?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=1000&amp;fit=clip"><p><img alt="A large outdoor sign with a round logo and text mounted on a stone base." data-src="https://images.theconversation.com/files/687583/original/file-20250826-55-ovh07.jpg?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip" data-srcset="https://images.theconversation.com/files/687583/original/file-20250826-55-ovh07.jpg?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=600&amp;h=400&amp;fit=crop&amp;dpr=1 600w, https://images.theconversation.com/files/687583/original/file-20250826-55-ovh07.jpg?ixlib=rb-4.1.0&amp;q=30&amp;auto=format&amp;w=600&amp;h=400&amp;fit=crop&amp;dpr=2 1200w, https://images.theconversation.com/files/687583/original/file-20250826-55-ovh07.jpg?ixlib=rb-4.1.0&amp;q=15&amp;auto=format&amp;w=600&amp;h=400&amp;fit=crop&amp;dpr=3 1800w, https://images.theconversation.com/files/687583/original/file-20250826-55-ovh07.jpg?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;h=503&amp;fit=crop&amp;dpr=1 754w, https://images.theconversation.com/files/687583/original/file-20250826-55-ovh07.jpg?ixlib=rb-4.1.0&amp;q=30&amp;auto=format&amp;w=754&amp;h=503&amp;fit=crop&amp;dpr=2 1508w, https://images.theconversation.com/files/687583/original/file-20250826-55-ovh07.jpg?ixlib=rb-4.1.0&amp;q=15&amp;auto=format&amp;w=754&amp;h=503&amp;fit=crop&amp;dpr=3 2262w" sizes="(min-width: 1466px) 754px, (max-width: 599px) 100vw, (min-width: 600px) 600px, 237px" src="https://images.theconversation.com/files/687583/original/file-20250826-55-ovh07.jpg?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip"></p></a>
            <figcaption>
              <span>The U.S. Department of Homeland Security uses Palantir’s technology to support its investigations.</span>
              <span><a href="https://newsroom.ap.org/detail/HomelandSecurity/31caf5fd39964032b7cf11830e82d210/photo">AP Photo/Jose Luis Magana</a></span>
            </figcaption>
          </figure>

<h2>Shifting the balance of power</h2>

<p>The political ramifications of Palantir’s rise come into focus when you consider its influence and reach across the government. U.S. Immigration and Customs Enforcement alone has <a href="https://fedscoop.com/dhs-renews-software-contract-with-palantir-for-investigative-case-management-services">spent more than US$200 million</a> on Palantir contracts, relying on the software to run its <a href="https://fedscoop.com/dhs-renews-software-contract-with-palantir-for-investigative-case-management-services">Investigative Case Management system</a> and to integrate travel histories, <a href="https://www.wired.com/story/ice-palantir-immigrationos/">visa records</a>, biometric data and social media data. </p>

<p>The Department of Defense has awarded Palantir billion-dollar contracts to <a href="https://www.cnbc.com/2025/08/01/palantir-lands-10-billion-army-software-and-data-contract.html">support battlefield intelligence</a> and AI-driven analysis. Even domestic agencies like the <a href="https://www.palantir.com/newsroom/press-releases/palantir-expands-longstanding-cdc-partnership-for-disease-monitoring-and/">Centers for Disease Control and Prevention</a> and the <a href="https://www.nytimes.com/2025/05/30/technology/trump-palantir-data-americans.html">Internal Revenue Service</a>, and local police departments like the <a href="https://www.brennancenter.org/our-work/analysis-opinion/palantir-contract-dispute-exposes-nypds-lack-transparency">New York Police Department</a>, have contracted with Palantir for data integration projects.</p>

<p>These integrations mean that Palantir is not just a vendor of software; it is becoming a partner in how the federal government organizes and acts on information. That creates a kind of dependency. The same private company helps define how investigations are conducted, how targets are prioritized, how algorithms work and how decisions are justified.</p>

<p>Because Gotham is proprietary, the public, and even elected officials, cannot see how its algorithms weigh certain data points or why they highlight certain connections. Yet, the conclusions it generates can have <a href="https://www.wired.com/story/palantir-what-the-company-does/">life-altering consequences</a>: inclusion on a deportation list or identification as a security risk. The opacity makes democratic oversight difficult, and the system’s broad scope and wide deployment means that mistakes or biases can scale up rapidly to affect many people.</p>

<h2>Beyond law enforcement</h2>

<p>Supporters of Palantir’s work argue that it modernizes outdated government IT systems, bringing them closer to the kind of integrated analytics that are routine in the private sector. However, the political and social stakes are different in public governance. Centralized, attribute-based searching, whether by location, immigration status, tattoos or affiliations, creates the capacity for <a href="https://doi.org/10.1177/0306396810377002">mass profiling</a>.</p>

<p>In the wrong hands, or even in well-intentioned hands under shifting political conditions, this kind of system could normalize surveillance of entire communities. And the criteria that trigger scrutiny today could be expanded tomorrow.</p>

<p>U.S. history provides warning examples: <a href="https://time.com/6097712/muslim-american-surveillance-supreme-court-sept-11/">The mass surveillance of Muslim communities after 9/11</a>, the targeting <a href="https://www.lib.berkeley.edu/about/news/fbi">of civil rights activists in the 1960s</a> and the <a href="https://sk.sagepub.com/ency/edvol/the-sage-encyclopedia-of-surveillance-security-privacy/chpt/antiwar-protest-surveillance-1960s">monitoring of anti-war protesters during the Vietnam era</a> are just a few. </p>

<p>Gotham’s capabilities may enable government agencies to carry out similar operations on a much larger scale and at a faster pace. And once some form of data integration infrastructure exists, its uses <a href="https://doi.org/10.1007/978-3-031-38619-0">tend to expand</a>, often into areas far from its original mandate. </p>

<h2>A broader shift in governance</h2>

<p>The deeper story here isn’t just that the government is collecting more data. It’s that the structure of governance is changing into a model where decision-making is increasingly influenced by what integrated data platforms reveal. In a pre-Gotham era, putting someone under suspicion of wrongdoing might have required specific evidence linked to an event or witness account. In a Gotham-enabled system, suspicion can stem from patterns in the data – patterns whose importance is defined by proprietary algorithms. </p>

<p>This level of data integration means that government officials can use potential future risks to justify present action. The predictive turn in governance aligns with a broader shift toward what some scholars call “<a href="https://doi.org/10.1111/ips.12042">preemptive security</a>.” It is a logic that can erode <a href="https://legaltimelines.org/accessible-timeline/safeguards-of-justice/">traditional legal safeguards</a> that require proof before punishment.</p>

<figure>
            <p><iframe data-src="https://www.youtube.com/embed/DZ95Gmvg_D4?wmode=transparent&amp;start=0" frameborder="0" allowfullscreen="" width="100%" height="400"></iframe></p>
            <figcaption><span>This short documentary about Palantir includes a former employee expressing concern about how algorithms are transforming government.</span></figcaption>
          </figure>

<h2>The stakes for democracy</h2>

<p>The partnership between Palantir and the federal government raises fundamental questions about accountability in a data-driven state. Who decides how these tools are used? Who can challenge a decision that was made by software, especially if that software is proprietary? </p>

<p>Without clear rules and independent oversight, there is a risk that Palantir’s technology becomes normalized as a default mode of governance. They could be used not only to track suspected criminals or terrorists but also to manage migration flows, monitor and suppress protests, and enforce public health measures. The concern is not that these data integration capabilities exist, but that government agencies could use them in ways that undermine civil liberties without public consent.</p>

<p>Once put in use, such systems are hard to dismantle. They create new expectations for speed and efficiency in law enforcement, making it politically costly to revert to slower, more manual processes. That inertia can lock in not only the technology but also the expanded scope of surveillance it enables.</p>

<h2>Choosing the future</h2>

<p>As Palantir deepens its government partnerships, the issues its technology raises go beyond questions of cost or efficiency. There are civil liberties implications and the potential for abuse. Will strong legal safeguards and transparent oversight constrain these tools for integrated data analysis? The answer is likely to depend on political will as much as technical design.</p>

<p>Ultimately, Palantir’s Gotham is more than just software. It represents how modern governance might function: through data, connections, continuous monitoring and control. The decisions made about its use today are likely to shape the balance between security and freedom for decades to come.</p>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Unusual Capabilities of Nano Banana (Examples) (331 pts)]]></title>
            <link>https://github.com/PicoTrex/Awesome-Nano-Banana-images/blob/main/README_en.md</link>
            <guid>45215869</guid>
            <pubDate>Thu, 11 Sep 2025 20:35:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/PicoTrex/Awesome-Nano-Banana-images/blob/main/README_en.md">https://github.com/PicoTrex/Awesome-Nano-Banana-images/blob/main/README_en.md</a>, See on <a href="https://news.ycombinator.com/item?id=45215869">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <nav aria-label="Global">
            <ul>
                <li>
      

      <div>
        <div>
            <div>

                  <ul>
                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_copilot&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_copilot_link_platform_navbar&quot;}" href="https://github.com/features/copilot">
      
      <div>
        <p>
          GitHub Copilot

        </p><p>

        Write better code with AI
      </p></div>

    
</a></li>

                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_spark&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_spark_link_platform_navbar&quot;}" href="https://github.com/features/spark">
      
      <div>
        <p>
          GitHub Spark

            <span>
              New
            </span>
        </p><p>

        Build and deploy intelligent apps
      </p></div>

    
</a></li>

                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_models&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_models_link_platform_navbar&quot;}" href="https://github.com/features/models">
      
      <div>
        <p>
          GitHub Models

            <span>
              New
            </span>
        </p><p>

        Manage and compare prompts
      </p></div>

    
</a></li>

                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_advanced_security&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_advanced_security_link_platform_navbar&quot;}" href="https://github.com/security/advanced-security">
      
      <div>
        <p>
          GitHub Advanced Security

        </p><p>

        Find and fix vulnerabilities
      </p></div>

    
</a></li>

                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;actions&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;actions_link_platform_navbar&quot;}" href="https://github.com/features/actions">
      
      <div>
        <p>
          Actions

        </p><p>

        Automate any workflow
      </p></div>

    
</a></li>

                  </ul>
                </div>
            <div>

                  <ul>
                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;codespaces&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;codespaces_link_platform_navbar&quot;}" href="https://github.com/features/codespaces">
      
      <div>
        <p>
          Codespaces

        </p><p>

        Instant dev environments
      </p></div>

    
</a></li>

                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;issues&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;issues_link_platform_navbar&quot;}" href="https://github.com/features/issues">
      
      <div>
        <p>
          Issues

        </p><p>

        Plan and track work
      </p></div>

    
</a></li>

                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;code_review&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;code_review_link_platform_navbar&quot;}" href="https://github.com/features/code-review">
      
      <div>
        <p>
          Code Review

        </p><p>

        Manage code changes
      </p></div>

    
</a></li>

                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;discussions&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;discussions_link_platform_navbar&quot;}" href="https://github.com/features/discussions">
      
      <div>
        <p>
          Discussions

        </p><p>

        Collaborate outside of code
      </p></div>

    
</a></li>

                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;code_search&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;code_search_link_platform_navbar&quot;}" href="https://github.com/features/code-search">
      
      <div>
        <p>
          Code Search

        </p><p>

        Find more, search less
      </p></div>

    
</a></li>

                  </ul>
                </div>
            
        </div>

          <p>
            <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;view_all_features&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;view_all_features_link_platform_navbar&quot;}" href="https://github.com/features">
              View all features
              
</a>          </p>
      </div>
</li>


                <li>
      

      
</li>


                <li>
      

      <div>

                      <p><span id="resources-explore-heading">Explore</span></p><ul aria-labelledby="resources-explore-heading">
                      <li>
  <a target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;learning_pathways&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;learning_pathways_link_resources_navbar&quot;}" href="https://resources.github.com/learn/pathways">
      Learning Pathways

    
</a></li>

                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;events_amp_webinars&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;events_amp_webinars_link_resources_navbar&quot;}" href="https://github.com/resources/events">
      Events &amp; Webinars

    
</a></li>

                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;ebooks_amp_whitepapers&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;ebooks_amp_whitepapers_link_resources_navbar&quot;}" href="https://github.com/resources/whitepapers">
      Ebooks &amp; Whitepapers

    
</a></li>

                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;customer_stories&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;customer_stories_link_resources_navbar&quot;}" href="https://github.com/customer-stories">
      Customer Stories

    
</a></li>

                      <li>
  <a target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;partners&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;partners_link_resources_navbar&quot;}" href="https://partner.github.com/">
      Partners

    
</a></li>

                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;executive_insights&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;executive_insights_link_resources_navbar&quot;}" href="https://github.com/solutions/executive-insights">
      Executive Insights

    
</a></li>

                  </ul>
                </div>
</li>


                <li>
      

      <div>
                <div>

                  <ul>
                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_sponsors&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_sponsors_link_open_source_navbar&quot;}" href="https://github.com/sponsors">
      
      <div>
        <p>
          GitHub Sponsors

        </p><p>

        Fund open source developers
      </p></div>

    
</a></li>

                  </ul>
                </div>
                <div>

                  <ul>
                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;the_readme_project&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;the_readme_project_link_open_source_navbar&quot;}" href="https://github.com/readme">
      
      <div>
        <p>
          The ReadME Project

        </p><p>

        GitHub community articles
      </p></div>

    
</a></li>

                  </ul>
                </div>
                
            </div>
</li>


                <li>
      

      <div>

                  <ul>
                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;enterprise_platform&quot;,&quot;context&quot;:&quot;enterprise&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;enterprise_platform_link_enterprise_navbar&quot;}" href="https://github.com/enterprise">
      
      <div>
        <p>
          Enterprise platform

        </p><p>

        AI-powered developer platform
      </p></div>

    
</a></li>

                  </ul>
                </div>
</li>


                <li>
    <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;platform&quot;,&quot;context&quot;:&quot;global&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;platform_link_global_navbar&quot;}" href="https://github.com/pricing">Pricing</a>
</li>

            </ul>
          </nav>

        <div>
                


<qbsearch-input data-scope="repo:PicoTrex/Awesome-Nano-Banana-images" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="NARmv_pWnukPmOEPnOjiJVgOmsRdJT7RJn3BnoJxDBlCyiEk77toRNjqpgJuhJzP-ceBiIcNk9YzLE-BbyViDw" data-max-custom-scopes="10" data-header-redesign-enabled="false" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="PicoTrex/Awesome-Nano-Banana-images" data-current-org="PicoTrex" data-current-owner="" data-logged-in="false" data-copilot-chat-enabled="false" data-nl-search-enabled="false" data-retain-scroll-position="true">
  <div data-modal-dialog-overlay="" data-action="click:qbsearch-input#searchInputContainerClicked">
  <modal-dialog data-action="close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose" data-target="qbsearch-input.searchSuggestionsDialog" role="dialog" id="search-suggestions-dialog" aria-modal="true" aria-labelledby="search-suggestions-dialog-header" data-view-component="true">
      <h2 id="search-suggestions-dialog-header">Search code, repositories, users, issues, pull requests...</h2>
    
</modal-dialog></div>
  
  <div>
    
<dialog-helper>
  <dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="feedback-dialog" aria-modal="true" aria-labelledby="feedback-dialog-title" aria-describedby="feedback-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="feedback-dialog-title">
        Provide feedback
      </h2>
        
    </p>
    
  </div>
      <scrollable-region data-labelled-by="feedback-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>

    <custom-scopes data-target="qbsearch-input.customScopesManager">
    
<dialog-helper>
  <dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="custom-scopes-dialog" aria-modal="true" aria-labelledby="custom-scopes-dialog-title" aria-describedby="custom-scopes-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="custom-scopes-dialog-title">
        Saved searches
      </h2>
        <h2 id="custom-scopes-dialog-description">Use saved searches to filter your results more quickly</h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="custom-scopes-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>
    </custom-scopes>
  </div>
</qbsearch-input>


            

              <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fblob%2Fshow&amp;source=header-repo&amp;source_repo=PicoTrex%2FAwesome-Nano-Banana-images" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/PicoTrex/Awesome-Nano-Banana-images/blob/main/README_en.md&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="abe673b73fe0ea0203765afa7975dbcca910ef27ee3c7f8cc40d8b4ccbf839ba" data-analytics-event="{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/<user-name>/<repo-name>/blob/show;ref_cta:Sign up;ref_loc:header logged out&quot;}">
                Sign up
              </a></p><p>
    <react-partial-anchor>
      <tool-tip id="tooltip-dcaad3be-f903-4b42-afdd-74f903b01a32" for="icon-button-c79d178a-31e0-4681-b1aa-b92fbd90a1bf" popover="manual" data-direction="s" data-type="label" data-view-component="true">Appearance settings</tool-tip>

      <template data-target="react-partial-anchor.template">
        <link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/primer-react.2473a867603eb9e3f3ac.module.css">
<link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/appearance-settings.c82a4db79200850fb016.module.css">

<react-partial partial-name="appearance-settings" data-ssr="false" data-attempted-ssr="false" data-react-profiling="false">
  
  <script type="application/json" data-target="react-partial.embeddedData">{"props":{}}</script>
  <div data-target="react-partial.reactRoot"></div>
</react-partial>


      </template>
    </react-partial-anchor>
  </p>

          </div>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Rails on SQLite: new ways to cause outages (119 pts)]]></title>
            <link>https://andre.arko.net/2025/09/11/rails-on-sqlite-exciting-new-ways-to-cause-outages/</link>
            <guid>45214933</guid>
            <pubDate>Thu, 11 Sep 2025 18:58:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://andre.arko.net/2025/09/11/rails-on-sqlite-exciting-new-ways-to-cause-outages/">https://andre.arko.net/2025/09/11/rails-on-sqlite-exciting-new-ways-to-cause-outages/</a>, See on <a href="https://news.ycombinator.com/item?id=45214933">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content"><p>11 Sep 2025</p><p><small>This post was originally given as a talk for <a href="https://friendlyrb.com/">Friendly.rb</a>. The <a href="https://speakerdeck.com/indirect/rails-on-sqlite-exciting-new-ways-to-cause-outages">slides</a> are also available.</small></p><p>Between Litestack and the Rails 8 trifecta of Solid Cable, Solid Cache, and Solid Queue, it’s easier than ever to spin up a Rails app that doesn’t need a database service, or a redis service, or a file storage service. It’s great to simplify things, but even after 20 years of deploying Rails apps I was still caught out by some of the ways things are different.</p><p>Based on what happened when I built a new side project in Rails on SQLite, we’ll cover what’s different, what’s new, and several ways that you can knock your site offline or even destroy your entire production database. As we go, we’ll also talk about the advantages of using SQLite, and how those differences can help you.</p><p>So who am I, how did I learn these things, and why should you listen to me? I’m André Arko, better known on the internet as @indirect. A long time ago, I helped create <a href="https://bundler.io/">Bundler</a>, and I’ve been the OSS team lead for <a href="https://rubygems.org/">RubyGems</a> and Bundler for more than a decade at this point.</p><p>I work at <a href="https://spinel.coop/">Spinel Cooperative</a>, a collective of Ruby open source maintainers building <a href="https://rv.dev/">rv</a>, the Ruby language manager that can install Ruby in one second flat. We offer retainers for unlimited access to core team experts from Bundler, Rails, Hotwire, and more, who can answer your questions and solve your problems.</p><p>I’ve been deploying Rails applications to production since 2004, and most relevantly for this particular talk, I built a service called <a href="https://feedyour.email/">feedyour.email</a>. Feed Your Email turns email subscriptions into RSS feeds that you can subscribe to in your feed reader. There is no signup, there are no accounts, you just go to the website and push a button to get an email address and a feed URL. Emails sent to that address will show up in that feed.</p><p>Feed Your Email is only possible as a service because of SQLite—if I had to maintain three Postgres instances and a couple of web instances and a couple of worker instances, I would have felt like it was too much hassle and cost too much money, and given up. SQLite reduced the complexity of building and deploying this service to the point where I was able to do it casually, for fun, and keep it running for everyone while feeling like it was worth it just for my own personal use.</p><p>This app serves about a million requests per month. That number sounds kind of big, but let’s do the math: 24 requests per minute, or one every 2.6 seconds. We can definitely serve at least one request every 2.6 seconds off of our Rails app, even on a small digital ocean droplet or a small cloud VM. I run my service on Fly.io, and hosting costs about USD$14 per month.</p><p>It has bonus features like a web view so you can share individual emails as a link without giving away your secret email address or letting anyone see the other emails in that feed, and it also has full-text search if you’re trying to find a particular email. That full-text search is a feature of SQLite, which brings us back to the topic of this talk. How did SQLite help? Let’s take a look.</p><p>The biggest fundamental difference, where almost every other difference comes from, is that SQLite is built in to your web server process. The reason for the “lite” in the name is that it doesn’t run a separate process, it doesn’t listen on a port or a socket, and you can’t connect to it. All the data is just in a single file, and your web process reads and writes that file when needed. This is awesome: you can’t have database connection errors anymore.</p><p>There’s a small issue with giving the web process its own database in a local file, though. If you deploy your app as usual, your production database can disappear at any time! Heroku destroys dynos every 24 hours, including all files. Fly.io loses the files in a container anytime they restart. In a world of containers, it’s incredibly easy to miss that your new SQLite database is on an ephemeral filesystem and will disappear along with the Puma process in your web container.</p><p>That leads us to the first and most important rule of using SQLite: put your database files in persistent storage. On AWS that means EBS, on Fly.io that means Volumes, but wherever you’re hosting, make sure that you can keep your database files across restarts (and ideally have automatic snapshots).</p><p>Now that your database won’t disappear at any moment, let’s talk about what it means to put all the data in a single file. You probably use <code>Rails.cache</code> to store temporary data—that’s in a single SQLite file now, too. You also probably use <code>ActiveJob</code> to send emails or do slower work in the background. All of those jobs are also in a single SQLite file now. By default, it’s the same file!</p><p>Putting everything in the same SQLite file makes everything very easy. You just need to keep track of that one file, and you’ll know that your model data, your caches, and your jobs will all be safe.</p><p>SQLite being in-process raises a new problem, though… what if your background job needs to update a model? You might be used to deploying your background workers in a separate container, so you can scale them as needed. That’s not going to fly anymore, because your background workers need to be able to read and write that same single file that your web server is reading and writing.</p><p>Since your database is now in just one file, you have two options. You can run your workers in a second process inside the same VM or container as the web process, or you can run your workers in threads inside the web process.</p><p>If this is a smallish application, doing a million requests per month or less, you’ll be absolutely fine putting your background jobs in threads. As a bonus, putting background jobs in threads can almost halve the amount of RAM you need because a single Rails process is handling both web and job requests.</p><p>If you really want to scale up your application, though, you’ll need to do what gets called “vertical” scaling rather than the traditional “horizontal” scaling. You can’t add more VMs, because other VMs won’t be able to see your database file. Instead, you need bigger and bigger single servers, with more and more CPU cores and RAM. That’s definitely possible, though. There are servers nowadays with 128 cores, or even more, and terabytes of RAM. Unfortunately, once you have scaled your wildly popular application vertically to the moon, you’ll discover the biggest limitation of SQLite: it’s just one file on disk.</p><p>If you have dozens processes and hundreds of threads in web servers and background job workers, all trying to write into this one database file at the same time, there’s probably going to be a lot of contention. By default, SQLite uses the filesystem to take out a lock on the entire database for each transaction. Holding the lock, it executes any read and write queries, commits, and then releases the lock. Then the next process can take the filesystem lock and do the same thing.</p><p>This can create quite the queue if even read-only queries have to wait in line and happen one at a time (because if they didn’t have the lock, some writer might sneak in and change the data mid-read!). To (partially) address this problem, SQLite offers a middle ground in the form of a Write-Ahead Log. The WAL log is an append-only file where any database writes can be written, one at a time. Then, a SQLite-controlled process copies those write instructions into the actual database file between reads. In the meantime, there can be as many readers as you want, because writes don’t have to block reads, and many reads from the same file at once are quite safe.</p><p>This solves the problem with only allowing one single read or write at a time, but it definitely has a cost. The database isn’t just one file anymore, it’s now a series of files, and you need to back them up and restore them together if you want to make sure you haven’t lost any data. Hopefully that’s not too much trouble, but it is definitely something to be aware of while planning your backup and disaster recovery strategy.</p><p>There’s one other approach worth calling out at this point, and that strategy is deliberately using multiple SQLite database files. If you are putting your not just your model data, but also your Rails cache, and also your background jobs, and maybe also your uploaded files all together into a single SQLite database file, your different use-cases can start to step on one another’s toes. For example, if you go to queue a few thousand jobs, any writes from your web requests will end up in the writer queue behind that pile of jobs in line to be written.</p><p>Creating a separate SQLite file per system, or per access pattern, can help a lot with this. In Rails, the most common splits are separate SQLite databases for ActiveRecord, for the Rails cache, for background jobs, and for ActionCable. Depending on your application, it might also make sense to put your ActiveStorage blobs into a SQLite database or into the same filesystem that you are already backing up, as well. There’s a lot of complexity and overhead involved in setting up S3 buckets with the correct permissions and getting files into and out of them, and you might just want to skip all of that in your new, simplified Rails config.</p><p>Taking this approach to an extreme might even involve sharding your model data across many database files. The most extreme example of this that I’ve heard of was an application that chose to shard their model data across one SQLite database file <em>per customer</em>. That meant every new signup created a new SQLite database file on disk, which is in some ways absurd, but it also meant that every individual user had the full power and speed of SQLite available to them. It’s hard to have read or write contention when every user gets their own separate database!</p><p>So now that we’ve covered vertically scaling the Rails server itself, let’s talk about the other implications of your application running on exactly one server. The downside to there being just one server is that if that server goes down, your entire app is down. No degraded service, no slower than usual application, just… no application at all.</p><p>If you’re running in a container, it’s impossible to deploy without downtime because only one container can ever have the volume with the database mounted. The old container has to stop before the new container can start. If you’re running in a VM, you might be able to deploy without downtime by running a local reverse proxy and more than one web server process, and restarting those web server processes one at a time rather than all at once. Welcome to how we used to do things in the 2000s, and my apologies.</p><p>That said, some of the implications of only one server are good: if there’s only one, it’s pretty easy to run status checks, and it’s pretty easy to troubleshoot. You don’t need to debug connections between load balancers and dozens of web servers and database servers and redis servers and file storage servers, you just need to debug the one server. That can definitely make your job easier!</p><p>Another implication of having just one single server: there is only one place for network requests to go. As I alluded to a moment ago, the only kind of load balancing that you can do is by running a local proxy and adding multiple separate processes as backends. The server itself is only going to have one IP address and one port where it can be reached, and there’s a certain amount of scale where that one IP and one port is going to become limiting. The good news is that you probably won’t hit that scale, and if you do, you’ll probably want to stop using SQLite anyway.</p><p>If you ever want to try switching towards or away from SQLite, the sequel gem has the amazing ability to read from one database and write into another, doing a full database copy while respecting all the quirks and limitations of each database. If you want to move from Mysql or Postgres over to SQLite, or if you ever want to load a SQLite database into Mysql or Postgres, I highly recommend it. The duckdb command line tool also has excellent cross-database capabilities, and is the next thing I would try if sequel wasn’t working for me for some reason.</p><p>There’s one more limitation that we need to consider that falls out of there only being one server: your app can only run in one geographic location. Some applications can benefit from adding additional web processes (or even database read replicas) spread out closer to end users, and that’s not possible if you are limited to a maximum of one server total for your entire application.</p><p>That said, there’s nothing stopping you from using the more usual kind of CDN-based global distribution. If your application has a decent amount of static or cacheable content, you can at least still set the cache-control headers and run the app behind Fastly or Cloudlfare.</p><p>Before we wrap up, I want to make sure to cover the various backup and replication options available to you while using SQLite for your application. The absolute all-star of SQLite backup and replication is called Litestream. It’s available as a gem, and can be used as easily as setting a few environment variables and using the <code>litestream</code> command provided by the gem to wrap your puma or other web server.</p><p>What litestream does is fairly simple: it forwards a copy of each entry added to the write-ahead log over to any S3-compatible file store — you might even say that it streams your data in a light way. If you ever have a catastrophe, and your database file gets deleted or corrupted, the bucket will have a full copy of the WAL that you can replay to restore your database back to where it was when the server stopped working.</p><p>On AWS, this still means setting up an S3 bucket and setting the right env vars, but at least you don’t need to deal with the bucket having public access, or setting up signed uploads, or any of the other things that make S3 a huge pain. You just need a private bucket and read/write credentials, and you’re good to go. If you’re using fly.io, you don’t even have to set the env vars yourself! They are set automatically by the command that creates the S3-compatible bucket on Tigris.</p><p>There’s one last thing that you can try using if you’re feeling especially adventurous, LiteFS. LiteFS is a fascinating software achievement, offering full Mysql or Postgres-style replication for multiple SQLite databases running in many locations. The completely deranged trick that they use to do this is creating an entire software filesystem using FUSE, and then putting the SQLite database inside that filesystem. This gives them access to every filesystem read and write call made by your application, and allows them to create their own operations that are then sent to every other member of the cluster to be applied.</p><p>This kind of setup comes with a lot of caveats. The biggest one is the usual distributed systems kind of caveat. You’ll have stale reads where some users will see old data, and if the primary crashes you might lose some data. If you’re okay with the tradeoffs of a distributed system (and you’re okay with the idea of all of your database reads and writes going through a FUSE filesystem that might be adding extra bugs), LiteFS offers a version of the ultimate web application dream.</p><p>In the dream SQLite plus LiteFS world, you have all the advantages of SQLite and all the advantages of a fully replicated multi-writer database setup. Any individual server can go down without causing any downtime for the application as a whole, and every user has a full copy of the application and all its data, running extremely close to them.</p><p>I haven’t built that perfect system yet, but it feels more attainable than it ever has before thanks to SQLite.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Claude's memory architecture is the opposite of ChatGPT's (282 pts)]]></title>
            <link>https://www.shloked.com/writing/claude-memory</link>
            <guid>45214908</guid>
            <pubDate>Thu, 11 Sep 2025 18:55:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.shloked.com/writing/claude-memory">https://www.shloked.com/writing/claude-memory</a>, See on <a href="https://news.ycombinator.com/item?id=45214908">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><p>Earlier this week, I dissected <a href="https://www.shloked.com/writing/posts/chatgpt-memory-bitter-lesson" target="_blank" rel="noopener noreferrer">ChatGPT's memory system</a>. Since then, I've been doing the same for Claude and realized something remarkable: these two leading AI assistants have built completely opposite memory systems.</p>
<p>In this post, I'll start by breaking down exactly how Claude's memory works—what it stores and how it retrieves information. Then we'll get to the interesting stuff. Why these architectures diverge so dramatically, what that tells us about who uses each assistant and the philosophies driving each product's development, and just how vast the AI memory design space really is.</p>
<h2>How it works</h2>
<p>Claude's memory system has two fundamental characteristics. First, it starts every conversation with a blank slate, without any preloaded user profiles or conversation history. Memory only activates when you explicitly invoke it. Second, Claude recalls by only referring to your raw conversation history. There are no AI-generated summaries or compressed profiles—just real-time searches through your actual past chats.</p>
<p>When Claude detects memory invocation through phrases like "what did we discuss about," "continue where we left off," or "remember when we talked about," it deploys two retrieval tools that work like web search or code execution—you see them activate in real-time and wait while Claude searches through your history. Once the search completes, Claude synthesizes the retrieved conversations to answer your question or continue the discussion.</p>
<h3>Conversation Search</h3>
<p>The <code>conversation_search</code> tool helps with keyword and topic-based searches across your entire conversation history. When I asked "Hey, can you recall our past conversations about Chandni Chowk?" (a historic neighborhood in Delhi), Claude found 9 relevant conversations—from when I explored its founding by Princess Jahanara Begum in 1650 to my queries about the best galouti kebabs at Karim's and stuffed parathas at Paranthe Wali Gali. Claude synthesized these scattered discussions into a coherent summary of my Chandni Chowk explorations.</p>
<p><img src="https://www.shloked.com/images/blog/claude-memory/chandni-chowk.png" alt="Claude searching for Chandni Chowk conversations"></p>
<p>When you ask about multiple topics, Claude runs separate searches sequentially. In my past job as a crypto researcher, I used Claude extensively as an editor. When I asked "Tell me all the conversations we've had about either Michelangelo or Chainflip or Solana," Claude ran three separate searches—one for my Michelangelo analogies for neural networks, another for Chainflip's cross-chain protocol work, and a third for Solana's technical architecture. It found 22 conversations across these searches and delivered a unified response with direct links to each chat.</p>
<p><img src="https://www.shloked.com/images/blog/claude-memory/multiple-searches.png" alt="Claude running multiple searches for different topics"></p>

<h3>Temporal Chat Retrieval</h3>
<p>The <code>recent_chats</code> tool provides time-based access to your conversation history. When I asked "Can you tell me what we spoke about in the last 10 conversations?" Claude retrieved my most recent chats chronologically and gave me a summary of my recent usage.</p>
<p><img src="https://www.shloked.com/images/blog/claude-memory/last-10-conversations.png" alt="Claude retrieving last 10 conversations"></p>
<p>The tool also handles specific timeframes. When I asked "What did we discuss in the last week of November 2024?" Claude retrieved 16 conversations from that exact period.</p>
<p><img src="https://www.shloked.com/images/blog/claude-memory/november-2024.png" alt="Claude retrieving conversations from November 2024"></p>

<h2>ChatGPT vs Claude</h2>
<p>A year ago, ChatGPT and Claude's assistant apps matched each other feature for feature—multiple models, file attachments, projects. Since then, their paths have diverged dramatically. ChatGPT has evolved into a mass-market consumer product, while Claude has deliberately chosen a different trajectory. Anthropic CPO Mike Krieger has <a href="https://lennysvault.com/episodes/8d70693c-41e7-4c00-8c14-6ba8955a2547" target="_blank" rel="noopener noreferrer">acknowledged</a> that OpenAI had "caught lightning in a bottle" with consumer adoption. Instead of chasing that market, Anthropic is focusing on what Claude does best: developer tools, coding, and professional workflows.</p>
<p>Memory implementation perfectly reflects this divergence.</p>
<p>ChatGPT's hundreds of millions of weekly active users come from all backgrounds—students, parents, hobbyists—who just want a product that works and remembers them without thinking about the mechanics. Every memory component loads automatically, creating instant personalization with zero wait time. The system builds detailed user profiles, learning preferences and patterns that could eventually power targeted features or monetization. It's the classic consumer tech playbook: make it magical, make it sticky, figure out different ways to monetize later.</p>
<p>Claude's users represent a different demographic entirely. Anthropic's more technical users inherently understand how LLMs work. They're comfortable with explicit control at every level. Just as they choose when to trigger web search or enable extended thinking, they decide when memory is worth invoking. They understand that memory calls add latency, but they make that tradeoff deliberately. Memory becomes just another tool in their arsenal, not an always-on feature. This audience doesn't need or want extensive profiling—they need a powerful, predictable tool for professional work. Not to mention, they're also more privacy-conscious.</p>
<h2>The Memory Design Space</h2>
<p>It still amazes me that ChatGPT and Claude—the two top AI assistants—have built completely opposite memory systems. This only goes to show that memory in AI has a massive design space with no right answer or one-size-fits-all technique. You have to work backwards from who your users are and what they need, then build from first principles accordingly.</p>
<p>We're in uncharted territory. These tools are less than three years old, and nobody knows what happens when someone uses the same AI assistant for a decade. How much should it remember? How should it handle years of accumulated context? Meanwhile, we're seeing a Cambrian explosion of AI apps, each experimenting with their own memory approach, while the underlying models get more powerful every week. There's no playbook, no settled best practices—just everyone trying different things and seeing what sticks.</p>
<p>The more I dive into memory, the more fascinated I get. Over the coming weeks, I'll be dissecting different architectures, analyzing new approaches, and following the latest research. Subscribe below if you want updates as this space unfolds.</p></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Top model scores may be skewed by Git history leaks in SWE-bench (344 pts)]]></title>
            <link>https://github.com/SWE-bench/SWE-bench/issues/465</link>
            <guid>45214670</guid>
            <pubDate>Thu, 11 Sep 2025 18:32:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/SWE-bench/SWE-bench/issues/465">https://github.com/SWE-bench/SWE-bench/issues/465</a>, See on <a href="https://news.ycombinator.com/item?id=45214670">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-testid="issue-body-viewer" data-team-hovercards-enabled="true" data-turbolinks="false" id="issue-body-viewer"><p dir="auto">We've identified multiple loopholes with SWE Bench Verified where agents may look at future repository state (by querying it directly or through a variety of methods), and cases in which future repository state includes either solutions or detailed approaches to solving problems (commit messages and more).</p>
<h3 dir="auto">Examples:</h3>
<p dir="auto">A trajectory with Claude 4 Sonnet, <a href="https://github.com/pytest-dev/pytest/pull/6202" data-hovercard-type="pull_request" data-hovercard-url="/pytest-dev/pytest/pull/6202/hovercard"><code>Pytest-dev__pytest-6202</code></a> (<a href="https://gist.github.com/jacobkahn/bd77c69d34040a9e9b10d56baa669a10">complete output here</a>), the agent uses <code>git log --all</code> which leaks future commits that directly fix the issue:</p>
<blockquote>
<p dir="auto">&lt;antml:parameter name="command"&gt;cd /testbed &amp;&amp; git log --oneline --all | grep -i "bracket|parametrize|modpath" | head -10&lt;/antml:parameter&gt;</p>
</blockquote>
<p dir="auto">The results of which directly reveal the fix:</p>
<div data-snippet-clipboard-copy-content="    Fix incorrect result of getmodpath method.
diff --git a/src/_pytest/python.py b/src/_pytest/python.py
index b8b365ad3..734a92f9b 100644
--- a/src/_pytest/python.py
+++ b/src/_pytest/python.py
@@ -285,8 +285,7 @@ class PyobjMixin(PyobjContext):
                     break
             parts.append(name)
         parts.reverse()
-        s = &quot;.&quot;.join(parts)
-        return s.replace(&quot;.[&quot;, &quot;[&quot;)
+        return &quot;.&quot;.join(parts)"><pre><code>    Fix incorrect result of getmodpath method.
diff --git a/src/_pytest/python.py b/src/_pytest/python.py
index b8b365ad3..734a92f9b 100644
--- a/src/_pytest/python.py
+++ b/src/_pytest/python.py
@@ -285,8 +285,7 @@ class PyobjMixin(PyobjContext):
                     break
             parts.append(name)
         parts.reverse()
-        s = ".".join(parts)
-        return s.replace(".[", "[")
+        return ".".join(parts)
</code></pre></div>
<p dir="auto">Qwen3-Coder 480B (<code>20250805-openhands-Qwen3-Coder-480B-A35B-Instruct</code>) also has several cases of looking ahead: some examples include <code>django__django-13513</code> (<a href="https://gist.github.com/jacobkahn/7eb86d9cfda451c88e9f5e4f9dddff84">complete output here</a>) uses <code>git log grep=[issue ID]</code> which directly reveals the fix PR which is in the future repo state (future commits).</p>
<blockquote>
<p dir="auto">Running command: cd /workspace/django__django__3.2 &amp;&amp; �[1m�[91mgit log�[0m --oneline --grep="31926" -i</p>
</blockquote>
<p dir="auto">In another Qwen3-Coder trajectory, <code>Django__django-15572</code>, (<a href="https://gist.github.com/jacobkahn/5ffc328617b30ed570bdfa6a14804b2a">complete output here</a>) where the model specifically finds the commit containing the fix: <a href="https://github.com/django/django/pull/15572/commits">62739b6e2630e37faa68a86a59fad135cc788cd7</a></p>
<blockquote>
<p dir="auto">Command <code>cd /workspace/django__django__4.1 &amp;&amp; �[1m�[91mgit log�[0m --oneline --grep="33628" �[92m--all�[0m</code> executed with exit code 0.</p>
</blockquote>
<p dir="auto">There are other examples of leakage found in trajectories from GLM 4.5, Qwen3-Coder 30B (<code>20250805-openhands-Qwen3-Coder-30B-A3B-Instruct</code>), and other models.</p>
<p dir="auto">Mitigation will be to properly remove future repository state and any artifacts that contain information the agent could use (reflogs, branches, origins, tags, and more):</p>
<ul dir="auto">
<li>remove origins (branch names can reveal information about fixes)</li>
<li>remove all branches <code>git log --all</code> can be used to query them, plus branches that are tracking a remote origin might contain information about future commits even after a <code>git reset --hard</code></li>
<li>remove the reflog (<code>git reflog</code>) can leak future commit messages that could detail approaches for solutions</li>
</ul>
<p dir="auto">The team (<a data-hovercard-type="user" data-hovercard-url="/users/felixkreuk/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/felixkreuk">@felixkreuk</a>, <a data-hovercard-type="user" data-hovercard-url="/users/UniverseFly/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/UniverseFly">@UniverseFly</a>, <a data-hovercard-type="user" data-hovercard-url="/users/jlko/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/jlko">@jlko</a>, <a data-hovercard-type="user" data-hovercard-url="/users/2dot71mily/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/2dot71mily">@2dot71mily</a> and others) will add more details as to findings here and below. We're still assessing broader impact on evaluations and understanding trajectories for sources of leakage.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bulletproof host Stark Industries evades EU sanctions (169 pts)]]></title>
            <link>https://krebsonsecurity.com/2025/09/bulletproof-host-stark-industries-evades-eu-sanctions/</link>
            <guid>45214164</guid>
            <pubDate>Thu, 11 Sep 2025 17:42:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://krebsonsecurity.com/2025/09/bulletproof-host-stark-industries-evades-eu-sanctions/">https://krebsonsecurity.com/2025/09/bulletproof-host-stark-industries-evades-eu-sanctions/</a>, See on <a href="https://news.ycombinator.com/item?id=45214164">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
												<p>In May 2025, the European Union levied financial sanctions on the owners of<strong>&nbsp;Stark Industries Solutions Ltd.</strong>, a bulletproof hosting provider that materialized two weeks before Russia invaded Ukraine and quickly became a top source of Kremlin-linked cyberattacks and disinformation campaigns. But new findings show those sanctions have done little to stop Stark from simply rebranding and transferring their assets to other corporate entities controlled by its original hosting providers.</p>
<div id="attachment_58061"><p><img aria-describedby="caption-attachment-58061" decoding="async" src="https://krebsonsecurity.com/wp-content/uploads/2022/01/wbrkb.jpg" alt="" width="741" height="495"></p><p id="caption-attachment-58061">Image: Shutterstock.</p></div>
<p>Materializing just two weeks before Russia invaded Ukraine in 2022, Stark Industries Solutions became a frequent source of massive DDoS attacks, Russian-language proxy and VPN services, malware tied to Russia-backed hacking groups, and fake news. ISPs like Stark are called “bulletproof” providers when they cultivate a reputation for ignoring any abuse complaints or police inquiries about activity on their networks.</p>
<p>In May 2025, the European Union <a href="https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=OJ:L_202500965" target="_blank" rel="noopener">sanctioned</a> one of Stark’s two main conduits to the larger Internet — Moldova-based <strong>PQ Hosting</strong> — as well as the company’s Moldovan owners <strong>Yuri</strong> and <strong>Ivan Neculiti</strong>. The EU Commission said the Neculiti brothers and PQ Hosting were linked to Russia’s hybrid warfare efforts.</p>
<p>But <a href="https://www.recordedfuture.com/research/one-step-ahead-stark-industries-solutions-preempts-eu-sanctions" target="_blank" rel="noopener">a new report</a> from <strong>Recorded Future</strong> finds that just prior to the sanctions being announced, Stark rebranded to&nbsp;<strong>the[.]hosting</strong>, under control of the Dutch entity <strong>WorkTitans BV</strong>&nbsp;(AS209847) on June 24, 2025. The Neculiti brothers reportedly got a heads up roughly 12 days before the sanctions were announced, when Moldovan and EU media reported on the forthcoming inclusion of the Neculiti brothers in the sanctions package.</p>
<p>In response, the Neculiti brothers moved much of Stark’s considerable address space and other resources over to a new company in Moldova called <strong>PQ Hosting Plus S.R.L</strong>., an entity reportedly connected to the Neculiti brothers thanks to <a href="https://correctiv.org/faktencheck/russland-ukraine/2024/05/16/hacks-und-propaganda-zwei-brueder-aus-moldau-tragen-russlands-digitalen-krieg-nach-europa/#:~:text=web%20hosting%20service%2C-,Morenehost,-%2C%20writes%20the%20IT" target="_blank" rel="noopener">the re-use of a phone number</a> from the original PQ Hosting.</p>
<p>“Although the majority of associated infrastructure remains attributable to Stark Industries, these changes likely reflect an attempt to obfuscate ownership and sustain hosting services under new legal and network entities,” Recorded Future observed.</p>
<p>Neither the Recorded Future report nor the May 2025 sanctions from the EU mentioned a second critical pillar of Stark’s network that KrebsOnSecurity identified in <a href="https://krebsonsecurity.com/2024/05/stark-industries-solutions-an-iron-hammer-in-the-cloud/" target="_blank" rel="noopener">a May 2024 profile on the notorious bulletproof hoster</a>: The Netherlands-based hosting provider <strong>MIRhosting</strong>.</p>
<p>MIRhosting is operated by 38-year old <strong>Andrey Nesterenko</strong>, whose <a href="https://web.archive.org/web/20141221134456/http://www.nesterenko.name/en/index.html" target="_blank" rel="noopener">personal website</a> says he is an accomplished concert pianist who began performing publicly at a young age. <strong>DomainTools</strong> says mirhosting[.]com is registered to Mr. Nesterenko and to <strong>Innovation IT Solutions Corp</strong>, which lists addresses in London and in Nesterenko’s stated hometown of Nizhny Novgorod, Russia.</p>
<div id="attachment_67519"><p><img aria-describedby="caption-attachment-67519" decoding="async" loading="lazy" src="https://krebsonsecurity.com/wp-content/uploads/2024/05/neculiti-netzwerk-768x1340-1.png" alt="" width="748" height="1305"></p><p id="caption-attachment-67519">Image credit: correctiv.org.</p></div>
<p>According to the book <em>Inside Cyber Warfare</em> by Jeffrey Carr, Innovation IT Solutions Corp. was responsible for hosting <strong>StopGeorgia[.]ru</strong>, a hacktivist website for organizing cyberattacks against Georgia that appeared at the same time Russian forces invaded the former Soviet nation in 2008. That conflict was thought to be the first war ever fought in which a notable cyberattack and an actual military engagement happened simultaneously.</p>
<p>Mr. Nesterenko did not respond to requests for comment. In May 2024, Mr. Nesterenko <a href="https://krebsonsecurity.com/2024/05/stark-industries-solutions-an-iron-hammer-in-the-cloud/" target="_blank" rel="noopener">said</a> he couldn’t verify whether StopGeorgia was ever a customer because they didn’t keep records going back that far. But he maintained that Stark Industries Solutions was merely one client of many, and claimed MIRhosting had not received any actionable complaints about abuse on Stark.</p>
<p>However, it appears that MIRhosting is once again the new home of Stark Industries, and that MIRhosting employees are managing both the[.]hosting and WorkTitans — the primary beneficiaries of Stark’s assets.</p>
<p>A copy of the incorporation documents for WorkTitans BV obtained from the Dutch Chamber of Commerce shows WorkTitans also does business under the names <strong>Misfits Media</strong> and and <strong>WT Hosting</strong> (considering Stark’s historical connection to Russian disinformation websites, “Misfits Media” is a bit on the nose).<span id="more-72088"></span></p>
<div id="attachment_72163"><p><img aria-describedby="caption-attachment-72163" decoding="async" loading="lazy" src="https://krebsonsecurity.com/wp-content/uploads/2025/09/kvk-worktitans.png" alt="" width="653" height="896"></p><p id="caption-attachment-72163">An incorporation document for WorkTitans B.V. from the Netherlands Chamber of Commerce.</p></div>
<p>The incorporation document says the company was formed in 2019 by a <strong>y.zinad@worktitans.nl</strong>. That email address corresponds to <a href="https://www.linkedin.com/in/youssef-zinad-mba-a1690a10/" target="_blank" rel="noopener">a LinkedIn account</a> for a <strong>Youssef Zinad</strong>, who says their personal websites are worktitans[.]nl and custom-solution[.]nl. The profile also links to a website (etripleasims dot nl) that LinkedIn currently blocks as malicious. All of these websites are or were hosted at MIRhosting.</p>
<p>Although Mr. Zinad’s LinkedIn profile does not mention any employment at MIRhosting, virtually all of his LinkedIn posts over the past year have been reposts of advertisements for MIRhosting’s services.</p>
<div id="attachment_72178"><p><img aria-describedby="caption-attachment-72178" decoding="async" loading="lazy" src="https://krebsonsecurity.com/wp-content/uploads/2025/09/zinad-mirhosting.png" alt="" width="750" height="646" srcset="https://krebsonsecurity.com/wp-content/uploads/2025/09/zinad-mirhosting.png 998w, https://krebsonsecurity.com/wp-content/uploads/2025/09/zinad-mirhosting-768x661.png 768w, https://krebsonsecurity.com/wp-content/uploads/2025/09/zinad-mirhosting-782x673.png 782w" sizes="(max-width: 750px) 100vw, 750px"></p><p id="caption-attachment-72178">Mr. Zinad’s LinkedIn profile is full of posts for MIRhosting’s services.</p></div>
<p>A Google search for Youssef Zinad reveals multiple startup-tracking websites that list him as the founder of the[.]hosting, which <strong>censys.io</strong> finds is hosted by <strong>PQ Hosting Plus S.R.L</strong>.</p>
<p>The Dutch Chamber of Commerce document says WorkTitans’ sole shareholder is a company in Almere, Netherlands called <strong>Fezzy B.V. </strong>Who runs Fezzy? The phone number listed in a Google search for Fezzy B.V. — <strong>31651079755</strong> — also was used to register a <strong>Facebook</strong> profile for a Youssef Zinad from the same town, according to the breach tracking service <strong>Constella Intelligence</strong>.</p>
<p>In a series of email exchanges leading up to KrebsOnSecurity’s <a href="https://krebsonsecurity.com/2024/05/stark-industries-solutions-an-iron-hammer-in-the-cloud/" target="_blank" rel="noopener">May 2024 deep dive on Stark</a>, Mr. Nesterenko included Mr. Zinad in the message thread (youssef@mirhosting.com), referring to him as part of the company’s legal team. The Dutch website stagemarkt[.]nl lists Youssef Zinad as an official contact for MIRhosting’s offices in Almere. Mr. Zinad did not respond to requests for comment.</p>
<p><img decoding="async" loading="lazy" src="https://krebsonsecurity.com/wp-content/uploads/2025/09/stage-mir-youssef.png" alt="" width="1173" height="810" srcset="https://krebsonsecurity.com/wp-content/uploads/2025/09/stage-mir-youssef.png 1173w, https://krebsonsecurity.com/wp-content/uploads/2025/09/stage-mir-youssef-768x530.png 768w, https://krebsonsecurity.com/wp-content/uploads/2025/09/stage-mir-youssef-782x540.png 782w, https://krebsonsecurity.com/wp-content/uploads/2025/09/stage-mir-youssef-100x70.png 100w" sizes="(max-width: 1173px) 100vw, 1173px"></p>
<p>Given the above, it is difficult to argue with the Recorded Future report on Stark’s rebranding, which concluded that “the EU’s sanctioning of Stark Industries was largely ineffective, as affiliated infrastructure remained operational and services were rapidly re-established under new branding, with no significant or lasting disruption.”</p>
											</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Native ACME support comes to Nginx (175 pts)]]></title>
            <link>https://letsencrypt.org/2025/09/11/native-acme-for-nginx</link>
            <guid>45214023</guid>
            <pubDate>Thu, 11 Sep 2025 17:28:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://letsencrypt.org/2025/09/11/native-acme-for-nginx">https://letsencrypt.org/2025/09/11/native-acme-for-nginx</a>, See on <a href="https://news.ycombinator.com/item?id=45214023">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
        
      
      
      
        <p>
          By Josh Aas · 
          
            
            
            <time datetime="2025-09-11T00:00:00+00:00">September 11, 2025</time>
          
        </p>
      
      
    </div><div>
      <div>
  <blockquote>
    <span></span>
    <div>
      <p>NGINX and Let's Encrypt share a common vision of an open and secure web. Now, with built-in support for ACME, the world's most popular web server, reverse proxy and ingress controller for Kubernetes can simplify certificate management for everyone. From the home lab to scaled-out, mission-critical enterprise deployments.</p>
      
    </div>
  </blockquote>
</div>
<p>Our ideal has always been that server software could get and renew Let’s Encrypt certificates automatically, with minimal human intervention.</p>
<p>Over time, more and more web servers and hosting environments have become capable of that, often via native ACME and Let’s Encrypt integrations that allow users to manage certificates without third-party tools. On August 12, the popular open source web server NGINX <a href="https://blog.nginx.org/blog/native-support-for-acme-protocol">announced support</a> for ACME with their official <a href="https://nginx.org/en/docs/http/ngx_http_acme_module.html">ngx_http_acme module</a> (implemented with memory safe Rust code!).</p>
<p>NGINX is one of the most widely used pieces of software for operating a web server or proxy. In directly supporting ACME, NGINX joins other web servers like <a href="https://traefik.io/traefik">Traefik</a>, <a href="https://caddyserver.com/">Caddy</a> and <a href="https://httpd.apache.org/docs/2.4/mod/mod_md.html">Apache httpd</a> that can directly take advantage of certificates from Let’s Encrypt and other ACME Certificate Authorities. NGINX’s new support for ACME, together with other servers, means a significant majority of sites can now have native ACME support. Many other software environments, hosting plans, and devices also offer built-in official support for ACME.</p>
<p>Users have a wide range of choices to achieve integrations for their particular hosting environments. Native support in web servers is an option <a href="https://letsencrypt.org/docs/client-options/">alongside third-party clients</a> that can integrate with many of those same web servers. Native support typically provides more seamless integration, and it’s less work for operators since they don’t have to manage a separate ACME client. Having more tools that take care of certificates automatically helps us achieve our goal of <a href="https://letsencrypt.org/stats/">encrypting more and more of the web</a>, while reducing the amount of time and energy site operators have to spend.</p>
<p>Other project developers interested in integrating ACME more directly can <a href="https://letsencrypt.org/docs/#client-developer-information">read about the ACME protocol</a>, find existing <a href="https://letsencrypt.org/docs/client-options/#libraries">ACME library implementations</a> and other reusable software components, and join the <a href="https://community.letsencrypt.org/c/client-dev/14">Client Dev conversation on our Community Forum</a>.</p>
<p>We’d like to thank NGINX and their parent company, F5, for their sponsorship of Let’s Encrypt. This financial support helps us provide a trusted and reliable service to nearly 700 million websites.</p>

      

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA['Robber bees' invade apiarist's shop in attempted honey heist (131 pts)]]></title>
            <link>https://www.cbc.ca/news/canada/british-columbia/robber-bees-terrace-bc-apiary-1.7627532</link>
            <guid>45213732</guid>
            <pubDate>Thu, 11 Sep 2025 16:58:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cbc.ca/news/canada/british-columbia/robber-bees-terrace-bc-apiary-1.7627532">https://www.cbc.ca/news/canada/british-columbia/robber-bees-terrace-bc-apiary-1.7627532</a>, See on <a href="https://news.ycombinator.com/item?id=45213732">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="detailContent"><!--$--><p><span><a href="https://www.cbc.ca/news/canada/british-columbia"><span>British Columbia</span></a></span></p><!--/$--><p>"Robber bees" hunt for dwindling resources in the late summer and early fall, but they usually only attack other beehives. So the owner of Rushing River Apiaries in Terrace, B.C., was shocked to find found thousands of the pollinators in her shop.</p><h2 lang="en">Bees sometimes attack other colonies as resources dwindle, but they usually stick to beehives found outside</h2><!--$--><!--/$--><!--$--><div data-cy="storyWrapper"><!--$--><figure><p><img loading="eager" alt="A honeybee in a honeycomb" src="https://i.cbc.ca/1.7627534.1757286827!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_1180/honeybee-terrace-apiarist.jpg?im=Resize%3D780" data-cy="leadmedia-story-img" fetchpriority="high"></p><figcaption>An apiarist in Terrace, B.C., says she found thousands of 'robber bees' in her store in late August.<!-- --> <!-- -->(Submitted by Christine McDonald)</figcaption></figure><!--/$--><div><p dir="ltr">A Terrace, B.C., beekeeper found herself in a nightmare situation late last month when&nbsp;"thousands and thousands of bees" filled her shop.</p><p dir="ltr">Call it an attempted robbery — the bees were trying to steal sweet, sweet honey.</p><p>Christine McDonald, owner of Rushing River Apiaries, said it's the first time desperate "robber bees" — bees that try to take honey from another colony's hive —&nbsp;have descended upon her indoor shop&nbsp;to hunt for food as resources get scarce in the late summer.&nbsp;</p><p>While she's worked with bees for years and said she's very comfortable around them, this situation had her frightened.</p><p dir="ltr">"I think that's the most panicked I have felt.…There's thousands of bees, I don't know where they're coming from, and I need to protect all of the honey."</p><div dir="ltr"><figure><p><img loading="lazy" alt="An indoor apiary, with stacks of wooden bee hives." srcset="https://i.cbc.ca/1.7627538.1757341339!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/rushing-river-apiaries-in-terrace-b-c.jpg?im=Resize%3D300 300w,https://i.cbc.ca/1.7627538.1757341339!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/rushing-river-apiaries-in-terrace-b-c.jpg?im=Resize%3D460 460w,https://i.cbc.ca/1.7627538.1757341339!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/rushing-river-apiaries-in-terrace-b-c.jpg?im=Resize%3D620 620w,https://i.cbc.ca/1.7627538.1757341339!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/rushing-river-apiaries-in-terrace-b-c.jpg?im=Resize%3D780 780w,https://i.cbc.ca/1.7627538.1757341339!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/rushing-river-apiaries-in-terrace-b-c.jpg?im=Resize%3D1180 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.7627538.1757341339!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/rushing-river-apiaries-in-terrace-b-c.jpg?im=" data-cy="image-img"></p><figcaption>Rushing River Apiaries in Terrace, B.C., was briefly set upon by thousands of 'robber bees' trying to find food in the late summer.<!-- --> <!-- -->(Submitted by Christine McDonald)</figcaption></figure></div><p>The multitudinous bees had found their way in through cracks in the shop's older bay door.</p><p dir="ltr">When a bee finds a good food source, it returns to the hive and does a "waggle dance" to tell other bees where the food is, McDonald said.</p><p>After throwing tarps and lids over the equipment and products, and managing to save most of it, McDonald said she ended up "sacrificing her bathroom" to trap the invading bees: she left the light on, and lured the bees to the light where she could collect and then release them.</p><div><ul><li><a href="https://www.cbc.ca/news/canada/british-columbia/honeybee-truck-overturn-bellingham-1.7549211" text="Millions of honeybees loose after truck overturns near B.C.-Wash. border" flag="Video" data-contentid=""><p><span>Video</span></p><span>Millions of honeybees loose after truck overturns near B.C.-Wash. border</span></a></li></ul><ul><li><a href="https://www.cbc.ca/radio/asithappens/honeybees-invaded-home-1.7190755" text="Honeybees invaded a reporter's home, and upended everything she thought she knew about them" flag="" data-contentid=""><span>Honeybees invaded a reporter's home, and upended everything she thought she knew about them</span></a></li></ul></div><p dir="ltr">But it took four or five days until the bees stopped trying to return.</p><p>"I think they've learned that, nope, there's no more food here. We can't get in."</p><p><span><div role="button" tabindex="0" title="Robber bees" data-cy="player-placeholder-ui-container"><p><img src="https://i.cbc.ca/ais/ae6974c4-0a45-4017-8837-2e6aad7e10e1,1716489446726/full/max/0/default.jpg?im=Crop%2Crect%3D%280%2C0%2C1919%2C1079%29%3BResize%3D620" alt="" loading="lazy"></p><p><span>Daybreak North</span><span></span><span>Robber bees</span></p></div><span>Hungry bees swarm Terrace apiary</span></span></p><p dir="ltr">McDonald has since taped up the shop's door.</p><p dir="ltr">She said while she's had robber bees attack her beehives before, it's the first time they found her indoor shop.</p><p dir="ltr">"Fall beekeeping is very intense — trying to help bees hunker down against other bees and wasps and keep the food stores that they've worked so hard for."</p><div dir="ltr"><figure><p><img loading="lazy" alt="A blue door with a Rushing River Apiaries sign taped up with red tape." srcset="https://i.cbc.ca/1.7627539.1757341352!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/rushing-river-apiaries-door-shut.jpg?im=Resize%3D300 300w,https://i.cbc.ca/1.7627539.1757341352!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/rushing-river-apiaries-door-shut.jpg?im=Resize%3D460 460w,https://i.cbc.ca/1.7627539.1757341352!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/rushing-river-apiaries-door-shut.jpg?im=Resize%3D620 620w,https://i.cbc.ca/1.7627539.1757341352!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/rushing-river-apiaries-door-shut.jpg?im=Resize%3D780 780w,https://i.cbc.ca/1.7627539.1757341352!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/rushing-river-apiaries-door-shut.jpg?im=Resize%3D1180 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.7627539.1757341352!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/rushing-river-apiaries-door-shut.jpg?im=" data-cy="image-img"></p><figcaption>McDonald says she had to tape up her shop door to make sure no other bees get in. <!-- --> <!-- -->(Submitted by Christine McDonald)</figcaption></figure></div><p dir="ltr">So-called robber bees&nbsp;are a fairly common phenomenon in the late summer and early fall.</p><p>Alison McAfee, a research associate at the University of B.C. and honeybee scientist, said when there's fewer food resources, such as nectar-producing flowers, and the bee population is close to its peak, some forager colonies can invade weaker colonies to steal their food.</p><p>"It's almost like they have a level of desperation, kind of like the way you can think about bears having a bit of a level of desperation trying to fatten up for winter," McAfee said.</p><div><ul><li><a href="https://www.cbc.ca/news/canada/london/the-number-of-beekeepers-are-on-the-rise-in-canada-but-honey-production-levels-sting-1.7427334" text="The number of beekeepers are on the rise in Canada but honey production levels sting" flag="Audio" data-contentid=""><p><span>Audio</span></p><span>The number of beekeepers are on the rise in Canada but honey production levels sting</span></a></li></ul><ul><li><a href="https://www.cbc.ca/news/canada/british-columbia/terrace-apiary-queen-bee-ukraine-1.6869156" text="Queen bees from Ukraine find a sweet new home in northwestern B.C." flag="" data-contentid=""><span>Queen bees from Ukraine find a sweet new home in northwestern B.C.</span></a></li></ul></div><p>She said wasps can also attack honeybees — but for slightly different reasons. Wasps eat a sugary substance secreted from their own larvae earlier in the season, but in the fall, there's fewer larvae and more adult wasps.</p><p dir="ltr">"They're not getting that sweet treat from their babies, essentially, and so they're especially motivated to get something sweet from elsewhere, because the adults actually really like to eat sugary things — and there's a lot of sugary stuff inside a honeybee colony."</p><p dir="ltr">But wasps aren't the only bee-killer out there.</p><p dir="ltr">McAfee said a bee colony can&nbsp;die from robber bees, if it's too weak to defend itself.</p><p dir="ltr">"We have a bad opinion of wasps," she said. "We're like, 'Oh those wasps, they're attacking our honey bee colonies, they're killing my bees.' But then a lot of the time, actually, the bees will kill our bees as well."</p><p dir="ltr">McDonald is back to producing honey after a few days of cleanup.&nbsp;</p><p dir="ltr">She said the bees seem more desperate this year than in the past, and thought it might be due to the extended heat as it still feels like midsummer.</p><p dir="ltr">McDonald encouraged other beekeepers to keep their bees well fed, so they don't feel the need to rob other hives.</p></div></div><!--/$--><!--$--><!--/$--><div><h2>ABOUT THE AUTHOR</h2><div><figure><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.7531874.1746834969!/fileImage/httpImage/image.JPG_gen/derivatives/square_1180/vanderdeen-headshot.JPG?im=Resize%3D192 192w,https://i.cbc.ca/1.7531874.1746834969!/fileImage/httpImage/image.JPG_gen/derivatives/square_1180/vanderdeen-headshot.JPG?im=Resize%3D288 288w" sizes="96px" src="https://i.cbc.ca/1.7531874.1746834969!/fileImage/httpImage/image.JPG_gen/derivatives/square_1180/vanderdeen-headshot.JPG?im=" data-cy="author-image-img"></p></figure></div><p>Lauren Vanderdeen is a web writer for CBC British Columbia. She formerly worked for community newspapers, including the Burnaby Now and New West Record. You can reach her at lauren.vanderdeen@cbc.ca.</p><ul></ul></div><p>With files from Hanna Petersen</p><!--$--><!--/$--><!--$--><!--/$--></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[NT OS Kernel Information Disclosure Vulnerability (121 pts)]]></title>
            <link>https://www.crowdfense.com/nt-os-kernel-information-disclosure-vulnerability-cve-2025-53136/</link>
            <guid>45213299</guid>
            <pubDate>Thu, 11 Sep 2025 16:13:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.crowdfense.com/nt-os-kernel-information-disclosure-vulnerability-cve-2025-53136/">https://www.crowdfense.com/nt-os-kernel-information-disclosure-vulnerability-cve-2025-53136/</a>, See on <a href="https://news.ycombinator.com/item?id=45213299">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main" role="main">

	
			
<article>

		<div data-plugin-options="{&quot;nav&quot;:true}">
								<p><img width="1024" height="445" src="https://www.crowdfense.com/wp-content/uploads/2025/08/CVE-2025-53136-1024x445.png" alt="" decoding="async" fetchpriority="high">											</p>
								</div>
	
			<p><span>11</span><span>Sep</span><time datetime="2025-09-11">September 11, 2025</time>		</p>
	
	<div>
			<p><span><span>Reading Time: </span> <span> 4</span> <span>minutes</span></span></p><div id="ez-toc-container">

<nav><ul><li><a href="#introduction">Introduction</a></li><li><a href="#vulnerability">Vulnerability</a><ul><li><a href="#quick-review-on-the-patch-for-cve-2024-43511">Quick review on the patch for CVE-2024-43511</a></li><li><a href="#spotting-the-bug">Spotting the bug</a></li><li><a href="#effects-of-the-bug">Effects of the bug</a></li></ul></li><li><a href="#exploitation">Exploitation</a><ul><li><a href="#setup">Setup</a></li><li><a href="#reliability">Reliability</a></li><li><a href="#proof-of-concepts">Proof-of-concepts</a></li></ul></li><li><a href="#conclusion">Conclusion</a></li><li><a href="#disclosure-timeline">Disclosure Timeline</a></li></ul></nav></div>
<h2><span id="introduction"></span><strong>Introduction</strong><span></span></h2>
<p>Microsoft mitigated many traditional kernel information leaks starting with Windows 11/Windows Server 2022 24H2, including calls such as&nbsp;<code>NtQuerySystemInformation()</code>&nbsp;(when used with the&nbsp;<code>SystemModuleInformation</code>&nbsp;class), by suppressing kernel base addresses unless the caller had&nbsp;the <code>SeDebugPrivilege</code>, typically reserved for administrative processes. That change effectively neutered one of the most accessible KASLR bypass techniques, and, without knowledge of the kernel’s base addresses, exploitation became harder.</p>
<p>While doing patch analysis for&nbsp;<strong>CVE-2024-43511</strong>, I realised that Microsoft made a mistake leading to a kernel address leak vulnerability. This new bug requires winning a race condition to read out the address; however, it’s pretty easy to achieve. It provides a powerful kernel address leak for any token handle, which can be easily chained with other vulnerabilities to obtain a complete exploit on the latest version of the system.</p>
<h2><span id="vulnerability"></span><strong>Vulnerability</strong><span></span></h2>
<h3><span id="quick-review-on-the-patch-for-cve-2024-43511"></span><strong>Quick review on the patch for CVE-2024-43511</strong><span></span></h3>
<p>In October 2024, Microsoft released a patch for a Time-of-check Time-of-use (TOCTOU) Race Condition vulnerability in the Windows kernel, namely&nbsp;CVE-2024-43511.</p>
<p>To fix the issue, when passing parameters to the&nbsp;<code>RtlSidHashInitialize()</code>&nbsp;function, it reads data from a kernel pointer (which is a member of the&nbsp;<code>TOKEN</code>&nbsp;structure), instead of the value set in a user-controlled buffer.</p>
<p><img decoding="async" src="https://www.crowdfense.com/wp-content/uploads/2025/08/patch.png" alt="" width="677" height="196" srcset="https://www.crowdfense.com/wp-content/uploads/2025/08/patch.png 677w, https://www.crowdfense.com/wp-content/uploads/2025/08/patch-640x185.png 640w, https://www.crowdfense.com/wp-content/uploads/2025/08/patch-400x116.png 400w" sizes="(max-width: 677px) 100vw, 677px"></p>
<h3><span id="spotting-the-bug"></span><strong>Spotting the bug</strong><span></span></h3>
<p>With the new update, the&nbsp;<code>RtlSidHashInitialize()</code>&nbsp;function, which performs hash initialisation, now takes as its first parameter a pointer from the&nbsp;<code>TOKEN</code>&nbsp;structure and as its third parameter a&nbsp;user-controlled&nbsp;buffer. Then,&nbsp;<code>RtlSidHashInitialize()</code>&nbsp;stores the first parameter (which is a pointer to the&nbsp;<code>UserAndGroups</code>&nbsp;field of the&nbsp;<code>TOKEN</code>&nbsp;structure) into the third parameter (user-supplied pointer), and starts doing hash initialisation later on:</p>
<p><img decoding="async" src="https://www.crowdfense.com/wp-content/uploads/2025/08/bug.png" alt="" width="754" height="260" srcset="https://www.crowdfense.com/wp-content/uploads/2025/08/bug.png 754w, https://www.crowdfense.com/wp-content/uploads/2025/08/bug-640x221.png 640w, https://www.crowdfense.com/wp-content/uploads/2025/08/bug-400x138.png 400w" sizes="(max-width: 754px) 100vw, 754px"></p>
<p>Although the caller function will replace the stored pointer in the user-buffer pointer after that, it still leaves a small time window for us to win a race condition and read out the leaked kernel address. To trigger the vulnerable function, we only need to invoke the&nbsp;<code>NtQuerySystemInformation()</code>&nbsp;API with the&nbsp;<code>SystemTokenInformation</code>&nbsp;class.</p>
<h3><span id="effects-of-the-bug"></span><strong>Effects of the bug</strong><span></span></h3>
<p>This leak primitive is particularly useful for Windows versions 24H2 or later, as the well-known technique for leaking kernel addresses using <code>NtQuerySystemInformation()</code> or other alternative methods has been patched. As the vulnerability is located within an NT syscall, the bug can be exploited from either&nbsp;<strong>Low IL</strong>&nbsp;or&nbsp;<strong>AppContainer</strong>. If chained with a&nbsp;<strong>write-what-where</strong>&nbsp;bug to overwrite the&nbsp;<code>Privileges</code>&nbsp;field of the&nbsp;<code>TOKEN</code>&nbsp;object, it will result in a complete LPE.</p>
<h2><span id="exploitation"></span><strong>Exploitation</strong><span></span></h2>
<h3><span id="setup"></span><strong>Setup</strong><span></span></h3>
<p>To exploit this bug, I need to create two threads to run concurrently:</p>
<ul>
<li>One thread to read at the specific offset, which will be used to store the kernel address in the user buffer.</li>
<li>One thread performs the syscall. It is required to run the syscall several times before archiving the kernel leak.</li>
</ul>
<h3><span id="reliability"></span><strong>Reliability</strong><span></span></h3>
<p>Although this is a race condition bug, the time window is wide enough to read the kernel address from the user-space buffer. To increase the success rate, we repeatedly call&nbsp;<code>NtQuerySystemInformation()</code>&nbsp;while keeping reading until we get the leak. The read becomes very reliable, and we can obtain the leaked&nbsp;<code>TOKEN</code>&nbsp;almost every time we run the exploit.</p>
<h3><span id="proof-of-concepts"></span><strong>Proof-of-concepts</strong><span></span></h3>
<p>The results below show the exploit on a Windows Insider Preview in April 2025 (latest version at the time of writing), running the exploit from the&nbsp;<strong>Low IL</strong>&nbsp;and&nbsp;<strong>App Container</strong>&nbsp;contexts:</p>
<p><img loading="lazy" decoding="async" src="https://www.crowdfense.com/wp-content/uploads/2025/08/poc_low-1024x540.png" alt="" width="1024" height="540" srcset="https://www.crowdfense.com/wp-content/uploads/2025/08/poc_low-1024x540.png 1024w, https://www.crowdfense.com/wp-content/uploads/2025/08/poc_low-768x405.png 768w, https://www.crowdfense.com/wp-content/uploads/2025/08/poc_low-640x337.png 640w, https://www.crowdfense.com/wp-content/uploads/2025/08/poc_low-400x211.png 400w" sizes="auto, (max-width: 1024px) 100vw, 1024px"></p>
<p><img loading="lazy" decoding="async" src="https://www.crowdfense.com/wp-content/uploads/2025/08/poc_appcontainer-1024x539.png" alt="" width="1024" height="539" srcset="https://www.crowdfense.com/wp-content/uploads/2025/08/poc_appcontainer-1024x539.png 1024w, https://www.crowdfense.com/wp-content/uploads/2025/08/poc_appcontainer-768x404.png 768w, https://www.crowdfense.com/wp-content/uploads/2025/08/poc_appcontainer-640x337.png 640w, https://www.crowdfense.com/wp-content/uploads/2025/08/poc_appcontainer-400x211.png 400w" sizes="auto, (max-width: 1024px) 100vw, 1024px"></p>
<h2><span id="conclusion"></span><strong>Conclusion</strong><span></span></h2>
<p>Patch analysis is one of the fastest ways to improve our skills and sharpen our mindset in bug finding. Additionally, it also helps us improve our secure coding skills. Sometimes, bug fixes in a function can introduce new bugs in other parts of the code. When conducting vulnerability research, it’s recommended to take a deep look to understand how the bug was patched and whether the patch completely resolves the issue or leaves other gaps open. From a developer’s point of view, every change made to a function can affect others as well, so take extra care when making any changes to the codebase. It is essential to thoroughly understand how a function works before modifying it, as this helps avoid mistakes or misuse of the function.</p>
<h2><span id="disclosure-timeline"></span><strong>Disclosure Timeline</strong><span></span></h2>
<ul>
<li><strong>April 8th</strong>: Reported to vendor.</li>
<li><strong>April 9th</strong>: Microsoft acknowledged that it is working on the bug.</li>
<li><strong>April 22nd</strong>: They claimed that the bug is duplicated with a bug which had been fixed already, and closed the case without having any other chance to explain the bug… (I don’t know why).</li>
<li><strong>April 22nd</strong>: I made a&nbsp;<a href="https://x.com/tykawaii98/status/1914620054206873845" target="_blank" rel="noopener">tweet&nbsp;</a>on X to complain about that, and luckily, I got a response from them.</li>
<li><strong>April 25th</strong>: Confirmed my report is a valid bug:v</li>
<li><strong>April 29th</strong>: Microsoft replied that the bug was in scope.</li>
<li><strong>August 1st</strong>:&nbsp;<a href="https://msrc.microsoft.com/update-guide/vulnerability/CVE-2025-53136" target="_blank" rel="noopener"><strong>CVE-2025-53136</strong></a>&nbsp;was assigned.</li>
</ul>

		</div>

					
		
	

	
</article>
								<hr>
					
					</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Spiral (244 pts)]]></title>
            <link>https://spiraldb.com/post/announcing-spiral</link>
            <guid>45212960</guid>
            <pubDate>Thu, 11 Sep 2025 15:45:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://spiraldb.com/post/announcing-spiral">https://spiraldb.com/post/announcing-spiral</a>, See on <a href="https://news.ycombinator.com/item?id=45212960">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>I've been building data systems for long enough to be skeptical of “revolutionary” claims, and I’m uncomfortable with grandiose statements like “Built for the AI Era”. Nevertheless, AI workloads have tipped us into what I'll call the Third Age of data systems, and legacy platforms can't meet the moment.</p><h2 id="three-eras-of-data-systems">Three Eras of Data Systems</h2><p>In the beginning, databases had human-scale inputs and human-scale outputs. Postgres—the king of databases, first released in <a target="_blank" rel="noopener noreferrer" href="https://en.wikipedia.org/wiki/1989_(album)"><span>1989</span></a>[1] —is the archetypal application database. A trivial example of a core Postgres workflow is letting a user create a profile, view it, and then update the email address. Postgres needs to support many users doing so at the same time, but it was built for a world in which the rate of database writes was implicitly limited by humans taking discrete actions.</p><p>Then came the age of "Big Data", when we automated data collection at "web scale", with much more granular events. Early internet giants scraped every link on the entire internet and captured every click on their websites. For data systems, this was the dawn of machine-scale <em>inputs</em>. However, the only way for a human to engage with this machine-collected data was to distill it down—into a dashboard, a chart, or even a single number. The inputs to a data system might have been in petabytes, but the end products were still measurable in kilobytes.</p><p>This unprecedented scale of data collection also led to a technological schism: on one side, we saw the rise of data lakes, massive shared filesystems where we would dump files and run MapReduce jobs. On the other side were (cloud) data warehouses, which provided both scalability and ergonomics for simple data types like dates, numbers, and short text. This branching then eventually converged into "the Lakehouse", wherein the descendants of Hadoop discovered that<a target="_blank" rel="noopener noreferrer" href="https://db.cs.cmu.edu/papers/2024/whatgoesaround-sigmodrec2024.pdf"> </a><a target="_blank" rel="noopener noreferrer" href="https://db.cs.cmu.edu/papers/2024/whatgoesaround-sigmodrec2024.pdf"><span>tables were useful all along</span></a>.[2]</p><p>Now, we are witnessing another epochal shift: the rise of the "Machine Consumer". In addition to machine-scale <em>inputs</em>, future data systems must be able to produce machine-scale <em>outputs</em>. Editing a few rows or aggregating a few simple columns is no longer enough. Machines don't want dashboards &amp; summaries—they want <em>everything</em>.</p><h2 id="what-machines-want">What Machines Want</h2><p>When I say machines want "everything," let me be specific. An NVIDIA H100 has enough memory bandwidth to consume 4 <em>million</em> 100KiB images per second. A Monte Carlo tree search might need to perform billions of random reads across your entire dataset. Machines want to perform fast scans, fast point lookups, and fast searches over petabyte–or exabyte!–scale data.</p><p>This is fundamentally different from the Second Age, when we optimized for human-friendly aggregations and reports. And here's where our current infrastructure completely breaks down: there's an uncanny valley between 1KB and 25MB where Parquet files and object storage are both wildly inefficient. Stored individually and assuming 50ms of S3 latency, reading 4 million individual 100KiB images—enough to saturate the H100 for one <em>second</em>—would accrue 55 <em>hours</em> of aggregate network overhead. Vector embeddings, small images, large documents—these are exactly what AI systems need, and exactly what current systems handle poorly.</p><h2 id="symptoms-of-the-same-disease">Symptoms of the Same Disease</h2><p>This architectural mismatch between Third Age needs and Second Age tools manifests in two ways that are destroying teams’ ability to ship:</p><p><span>First, price-performance.</span> Your AI engineers are stuck in a Sisyphean loop: Read Parquet → Explode to Arrow (10x memory) → Convert to tensors → Cache intermediate results → (Finally) train -&gt; Repeat. Five steps to do what should be simple: feed data to a GPU. Meanwhile, that H100 capable of consuming 4 million images per second sits idle ~70% of the time. Your even-more-expensive AI Engineer is manually shepherding each iteration (and possibly hoping for Zuck to show up with $1B).</p><p><span>Second, security.</span> Raw performance is only half the problem. The other half should terrify your security team. Simon Willison recently noted that<a target="_blank" rel="noopener noreferrer" href="https://simonwillison.net/2025/Jul/6/supabase-mcp-lethal-trifecta/"> </a><a target="_blank" rel="noopener noreferrer" href="https://simonwillison.net/2025/Jul/6/supabase-mcp-lethal-trifecta/"><span>Supabase's MCP connector can leak your entire database</span></a> to anyone who can manipulate prompts.</p><p>Teams need to move fast. They need to experiment, iterate, and ship. But when their foundational needs aren’t met, they duct-tape solutions together. Database credentials get passed to AI agents. S3 bucket permissions get opened too wide. Audit logs are a fiction.</p><p>Here's the kicker: security isn't just a compliance checkbox. It's a performance multiplier. Every hack you ship today is technical debt you'll pay 10x to fix later. Every permissions model you bypass is a multitenant feature you can't build. The same missing primitives that force performance workarounds make security nearly impossible to bolt on later.</p><p>Both problems stem from the same root cause: cobbling together Second Age tools to solve Third Age problems. The tragedy isn't that teams are choosing between speed and security—it's that our infrastructure forces this false choice.</p><h2 id="were-not-the-first-to-notice">We’re Not the First to Notice</h2><p>Of course, we're not the first to recognize these problems. Smart people have been trying to bridge this gap.</p><p>The “Lakehouse” is the right high-level idea—object storage native is indeed the future.[3] But it's still duct-taping together a data lake and a data warehouse, duck-typing files as tables without fundamentally solving the unified storage problem. You end up managing multiple components with different permission models, different APIs, and different performance characteristics. As Ali Ghodsi likes to call it, you're managing a "data estate"—and like many estates, it's expensive, messy, and full of relics &amp; the occasional skeleton.</p><p>WebDataset solved an immediate need for AI teams, but it's essentially equivalent to CSV files for the deep learning era: convenient for simple cases but lacking the performance, expressivity, &amp; governance features that production systems demand.</p><p>These are all good Second Age solutions trying to solve Third Age problems. But Third Age problems need Third Age infrastructure—built from the ground up with machines as the primary consumer.</p><p>When OpenAI processes billions of images or Anthropic trains on massive document collections, they're not using traditional data warehouses. They've built custom infrastructure because they had to.</p><p>We realized these weren't just technical problems to work around—they required rethinking the entire architecture.</p><p>Data systems must evolve.</p><h2 id="building-for-what-comes-next">Building for What Comes Next</h2><p>We started Spiral to take that next evolutionary step. Adapting legacy systems wasn't going to cut it; we needed to design for machine consumption from day one.</p><p>First, we created<a target="_blank" rel="noopener noreferrer" href="https://vortex.dev/"> </a><a target="_blank" rel="noopener noreferrer" href="https://vortex.dev/"><span>Vortex</span></a>—a state-of-the-art columnar file format—and donated it to the Linux Foundation. The technical validation has been overwhelmingly positive: Microsoft, Snowflake, Palantir, and other leading data companies are backing it. TUM's fabled database group just released their latest paper<a target="_blank" rel="noopener noreferrer" href="https://gienieczko.com/anyblox-paper"> </a><a target="_blank" rel="noopener noreferrer" href="https://gienieczko.com/anyblox-paper"><span>"Anyblox"</span></a>, independently calling Vortex the "cutting edge" in file formats.</p><p>Vortex achieves Parquet's compression ratios with 10-20x faster scans, 5-10x faster writes, and<a target="_blank" rel="noopener noreferrer" href="https://bench.vortex.dev/#Random_Access"> 100-200x faster random access reads (</a><a target="_blank" rel="noopener noreferrer" href="https://bench.vortex.dev/#Random_Access"><span>1.5 milliseconds vs Parquet’s 200 milliseconds</span></a>). Depending on the query and the engine, it is no slower, and often dramatically faster. But the real, long-term breakthrough? Vortex is designed to support decoding data directly from S3 to GPU, skipping the CPU bottleneck entirely.</p><p>Spiral is our database built on Vortex: object store native from day one; unified governance across all data types; machine-scale throughput that actually saturates your GPUs; and one API that handles everything from tiny embeddings to massive video files. All with what we call "fearless permissioning"—move as fast as you want without compromising security, because the right primitives are built in from the ground up.[4] </p><p>Remember that uncanny valley between 1KB and 25MB? The problem isn't the sizes—it's that Second Age systems force you to choose between two bad options: inline the data (killing performance) or store pointers (breaking governance). Spiral eliminates this false choice. We store 10KB embeddings directly in Vortex for microsecond access, intelligently batch 10MB blocks of images for optimal S3 throughput, and externalize 4GB videos without copying a single byte. One system, no compromises.</p><p>When you stop pretending machines are just very fast humans, the entire architecture inverts. Throughput becomes the critical constraint, not latency. Object storage becomes the foundation, not an afterthought. Security becomes unified, not bolted on.</p><p>With $22 million in Seed &amp; Series A funding from Amplify Partners &amp; General Catalyst, we're well on our way to building the infrastructure that the Third Age of Data demands.</p><h2 id="what-spiral-delivers">What Spiral Delivers</h2><p>Here's what this means in practice:</p><ul><li><p>That H100 capable of consuming 4 million images per second? With Spiral, it actually can.</p></li><li><p>Sharing data without the security nightmare? Solved with time-bounded, audited, granular permissions.</p></li><li><p>The five-step data loading dance? A single query.</p></li><li><p>Your AI engineers? <em>Actually working on AI</em>.</p></li></ul><p>This is what happens when you build for the world ahead, not the world we used to know.</p><h2 id="the-future-is-machine-scale">The Future is Machine Scale</h2><p>We're tackling how to work with <em>complex</em> data at <em>machine scale</em>. A modern GPU can consume <em>terabits</em> per second, and in ways that existing systems aren't built for. Whether you're loading data from object storage into a GPU for pre-training, doing millions of concurrent point reads for Monte Carlo tree search, or trying to wrangle data that other systems can't, we're building for you.</p><p>The gap between AI leaders and laggards is widening. While some teams cobble together solutions with duct tape and custom scripts, their competitors are already training next-generation models. The enterprises that get their data AI-ready today will have an insurmountable advantage tomorrow.</p><p>We're working with design partners across computer vision, robotics, and multimodal AI. If you're spending more than 10% of your time on data infrastructure instead of model development, we should talk.</p><p>I started by saying I'm skeptical of revolutionary claims. But when the revolution is already here—when your GPUs are starving and you’re drowning in data—skepticism becomes denial. The question isn't whether your infrastructure will need to evolve—it's whether you'll lead that evolution or be left behind.</p><p>The future doesn't care if you're ready. But we do.</p><p><a target="_blank" rel="noopener noreferrer" href="https://spiraldb.com/careers"><span>Join us</span></a> or reach out (hello at spiraldb dot com).</p><p>—</p><p>P.S. If you're sttill managing data in spreadsheets, this post isn't for you. Yet.</p><ol><li><p>Taylor Swift, Postgres, and I are all roughly the same age. Coincidentally, I don't believe in dates before ~1989.</p></li><li><p>Tables are apparently like low rise jeans: cool in 2005 and back with a vengeance.</p></li><li><p>See e.g., <a target="_blank" rel="noopener noreferrer" href="https://www.warpstream.com/"><span>Warpstream</span></a>, <a target="_blank" rel="noopener noreferrer" href="https://turbopuffer.com/"><span>Turbopuffer</span></a>, and <a target="_blank" rel="noopener noreferrer" href="https://slatedb.io/"><span>SlateDB</span></a> for great examples of how powerful object storage native architectures can be.</p></li><li><p>I tried not to mention “written in Rust”, but yes, this term is inspired by <a target="_blank" rel="noopener noreferrer" href="https://doc.rust-lang.org/book/ch16-00-concurrency.html"><span>fearless concurrency</span></a>. </p></li></ol></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The US is now the largest investor in commercial spyware (173 pts)]]></title>
            <link>https://arstechnica.com/security/2025/09/the-us-is-now-the-largest-investor-in-commercial-spyware/</link>
            <guid>45212370</guid>
            <pubDate>Thu, 11 Sep 2025 14:51:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/security/2025/09/the-us-is-now-the-largest-investor-in-commercial-spyware/">https://arstechnica.com/security/2025/09/the-us-is-now-the-largest-investor-in-commercial-spyware/</a>, See on <a href="https://news.ycombinator.com/item?id=45212370">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          
          
<p>Paragon, responding to the committee’s findings, accused Italian authorities of refusing to conduct a thorough technical verification—an assessment it argued could have resolved the issue.</p>

<p>Apart from focusing on investment, the Atlantic Council notes that the global spyware market is “growing and evolving,” with its dataset expanded to include four new vendors, seven new resellers or brokers, 10 new suppliers, and 55 new individuals linked to the industry.</p>
<p>Newly identified vendors include Israel’s <a href="https://www.intelligenceonline.com/surveillance--interception/2021/06/02/bindecy-lays-hands-on-struggling-cyber-security-firm-merlinx,109670437-art">Bindecy</a> and Italy’s <a href="https://techcrunch.com/2025/02/13/spyware-maker-caught-distributing-malicious-android-apps-for-years/">SIO</a>. Among the resellers are front companies connected to NSO products, such as Panama’s KBH and Mexico’s Comercializadora de Soluciones Integrales Mecale, as <a href="https://www.gob.mx/sspc/prensa/informe-de-la-secretaria-sobre-los-contratos-de-administraciones-pasadas-relacionados-con-el-software-pegasus">highlighted</a> by the Mexican government. New suppliers named include the UK’s <a href="https://www.intelligenceonline.com/surveillance--interception/2025/02/19/coretech-supplies-zero-day-research-data-to-british-intelligence,110377154-art">Coretech Security</a> and UAE’s <a href="https://www.intelligenceonline.com/surveillance--interception/2024/09/13/zerozenx-latest-to-join-dubai-s-buzzing-zero-day-marketplace,110285592-art">ZeroZenX</a>.</p>
<p>The report highlights the central role that these resellers and brokers play, stating that it is “a notably under-researched set of actors.” According to the report, “These entities act as intermediaries, obscuring the connections between vendors, suppliers, and buyers. Oftentimes, intermediaries connect vendors to new regional markets.”</p>
<p>“This creates an expanded and opaque spyware supply chain, which makes corporate structures, jurisdictional arbitrage, and ultimately accountability measures a challenge to disentangle,” Sarah Graham, who coauthored the report, tells WIRED.</p>
<p>“Despite this, resellers and brokers are not a current feature of policy responses,” she says.</p>
<p>The study reveals the addition of three new countries linked to spyware activity—Japan, Malaysia, and Panama. Japan in particular is a signatory to international efforts to curb spyware abuse, including the <a href="https://2021-2025.state.gov/joint-statement-on-efforts-to-counter-the-proliferation-and-misuse-of-commercial-spyware/">Joint Statement</a> on Efforts to Counter the Proliferation and Misuse of Commercial Spyware and the Pall Mall Process <a href="https://www.gov.uk/government/publications/the-pall-mall-process-code-of-practice-for-states">Code of Practice for States</a>.</p>
<p>“The discovery of entities operating in new jurisdictions, like Japan, highlights potential conflicts of interest between international commitments and market dynamics,” Graham says.</p>
<p>Despite efforts by the Biden administration to constrain the spyware market through its <a href="https://www.federalregister.gov/documents/2023/03/30/2023-06730/prohibition-on-use-by-the-united-states-government-of-commercial-spyware-that-poses-risks-to">executive order</a>, <a href="https://www.commerce.gov/news/press-releases/2021/11/commerce-adds-nso-group-and-other-foreign-companies-entity-list">trade</a> and <a href="https://2021-2025.state.gov/promoting-accountability-for-the-misuse-of-commercial-spyware/">visa</a> restrictions, and <a href="https://home.treasury.gov/news/press-releases/jy2155">sanctions</a>, the industry has continued to operate largely without restraint.</p>

          
                  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Conway's Game of Life, but musical (166 pts)]]></title>
            <link>https://www.hudsong.dev/digital-darwin</link>
            <guid>45211868</guid>
            <pubDate>Thu, 11 Sep 2025 14:05:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.hudsong.dev/digital-darwin">https://www.hudsong.dev/digital-darwin</a>, See on <a href="https://news.ycombinator.com/item?id=45211868">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><header><div><p><span><a href="https://www.hudsong.dev/" target="_blank" rel="noopener noreferrer">Hudson Griffith</a></span><span>•</span><time>September 11, 2025</time></p></div></header><p><img alt="Artistic representation of musical evolution and cultural trends" loading="lazy" width="2688" height="1612" decoding="async" data-nimg="1" srcset="https://www.hudsong.dev/_next/image?url=%2Fmusic%2Fmevo.jpg&amp;w=3840&amp;q=75 1x" src="https://www.hudsong.dev/_next/image?url=%2Fmusic%2Fmevo.jpg&amp;w=3840&amp;q=75"></p><section><h2>Introduction</h2><p>Music is profoundly human. It runs deep in our lives and shows up in our everyday rituals. And somehow, those rituals often end with us leaving AirPods in the back seat of an Uber. But beneath the everyday habits lies a much older connection. Neuroscience research shows our brains respond to music in fundamental ways that precede language development <span role="link" aria-label="Go to reference 1" tabindex="0" data-state="closed">1</span>. And what fascinates me is how naturally music evolves over time, how styles adapt and change in a way that feels less like something we purposely create and more like it just grows on its own. Charles Darwin himself speculated that musicality might have preceded language, suggesting our capacity for music is fundamentally biological <span role="link" aria-label="Go to reference 2" tabindex="0" data-state="closed">2</span>.</p><p>This got me thinking: if musical evolution follows biological patterns, could we create an environment to simulate this evolution? So I built one.</p></section><section><h2>Building a Laboratory for Musical Evolution</h2><p>I created what I call a <span>melody breeder</span>. It’s a digital playground where melodies can compete, reproduce, and evolve. Select your favorite (up to three) melodies, let them breed with each other, and watch what happens. It may not be the next top hit, but it's a lot of fun to play around with.</p><p>And the science behind it is actually pretty solid. Richard Dawkins' concept of "memes" describes cultural units that replicate and evolve similarly to genes <span role="link" aria-label="Go to reference 3" tabindex="0" data-state="closed">3</span>. Musical melodies are perfect examples. They replicate through listening, mutate through sampling, and undergo selection pressure based on whether people actually want to hear them again.</p><p>Research by Savage et al. (2015) demonstrates that musical evolution follows predictable patterns across cultures, with structural features evolving through descent with modification much like biological traits <span role="link" aria-label="Go to reference 4" tabindex="0" data-state="closed">4</span>. That means you can think of your Spotify <span>Liked Songs</span> playlist as a thriving ecosystem, full of tracks that survived.</p></section><section><h2>Conway's Symphony of Life and Death</h2><p>While building the melody breeder, I kept thinking about how musical patterns behave like living systems. They're born, they interact, they die. This reminded me of one of my favorite digital visualizations, Conway's Game of Life.</p><p>So I made it musical.</p><p>This is Conway's Game of Life, where each cell birth plays a harmonic note and each death plays a complementary tone. The result is evolving, unpredictable music generated by the simulation.</p><p>Each glider that moves across the screen creates its own melody. Oscillators turn into rhythms and the "glider gun" becomes a beat machine. The same simple rules that drive complexity in biology can also shape musical structure.</p></section><section><h2>From Musical Genes to Cultural Pandemics</h2><p>The parallels between musical evolution and biological systems run deeper than you'd think.</p><p>Take the Labubu phenomenon (I never thought I would write that phrase in a blog post). These designer toys went from obscure to everywhere seemingly overnight, spreading through social media like a disease. And I mean that literally, epidemiologists use the same models for viral TikTok trends as they do for actual viruses <span role="link" aria-label="Go to reference 5" tabindex="0" data-state="closed">5</span>. To show this, I pulled Google Trends data <span role="link" aria-label="Go to reference 6" tabindex="0" data-state="closed">6</span> on the term "Labubu" from the start of 2024 to today and visualized it as a global map of its spread.</p></section><section><p>Watching this trend curve reminds me of the pandemic era. The same steep exponential rises, the geographic spread patterns, the way interest peaks and then gradually declines. It's unsettling how similar a toy's popularity looks to a virus outbreak when you plot them on a map.</p><p>But maybe that similarity isn't so unsettling after all. Maybe it reveals something deeper about how information spreads through human networks, whether that information is genetic code, viral particles, or cultural ideas.</p></section><section><h2>The Universal Patterns of Cultural Evolution</h2><p>Darwin called it "endless forms most beautiful," and that phrase fits here too. The same simple rules that drive biology also explain why culture produces such variety, from music to memes. Patterns replicate, adapt, and survive when they capture our attention.</p><p>Boyd &amp; Richerson describe culture as a shared pool of innovation that helps us live better <span role="link" aria-label="Go to reference 7" tabindex="0" data-state="closed">7</span>. Sometimes that means a symphony, sometimes a viral monster toy. Either way, it's evolution at work.</p><p>These patterns exist all around us, but recognizing them is just the beginning. What really gets me excited is being able to build something that makes these invisible forces visible.</p></section><section><h2>Why I Love Code</h2><p>This whole exploration exists because programming gave me the tools to turn random shower thoughts into something real and shareable. There's something empowering about writing code that simulates generations of evolution in milliseconds, about building systems that let people explore complex ideas through play.</p><p>This is why I code: to take questions that keep me up at night and turn them into something that might spark curiosity in the 5 people who read these blog posts.</p><p>Now if you'll excuse me, I need to check on my melody breeder. Pretty sure Beethoven's Fifth great-grandson just evolved into Baby Shark.</p></section><section id="references"><h3>References</h3><div><ul><li id="ref-1"><span><span role="link" aria-label="Go to reference 1" tabindex="0" data-state="closed">1</span></span><span>Levitin, D. J. (2006). <em>This Is Your Brain on Music: The Science of a Human Obsession</em>. Dutton Penguin.</span></li><li id="ref-2"><span><span role="link" aria-label="Go to reference 2" tabindex="0" data-state="closed">2</span></span><span>Darwin, C. (1871). <em>The Descent of Man, and Selection in Relation to Sex</em>. John Murray.</span></li><li id="ref-3"><span><span role="link" aria-label="Go to reference 3" tabindex="0" data-state="closed">3</span></span><span>Dawkins, R. (1976). <em>The Selfish Gene</em>. Oxford University Press.</span></li><li id="ref-4"><span><span role="link" aria-label="Go to reference 4" tabindex="0" data-state="closed">4</span></span><span>Savage, P. E., Brown, S., Sakai, E., &amp; Currie, T. E. (2015). Statistical universals reveal the structures and functions of human music. <em>Proceedings of the National Academy of Sciences</em>, 112(29), 8987-8992.</span></li><li id="ref-5"><span><span role="link" aria-label="Go to reference 5" tabindex="0" data-state="closed">5</span></span><span>Kermack, W. O., &amp; McKendrick, A. G. (1927). A contribution to the mathematical theory of epidemics. <em>Proceedings of the Royal Society of London. Series A</em>, 115(772), 700-721.</span></li><li id="ref-6"><span><span role="link" aria-label="Go to reference 6" tabindex="0" data-state="closed">6</span></span><span>Google Trends. (2024–2025). <em>Search interest for “Labubu”</em>. Retrieved September 2025, from <a href="https://trends.google.com/" target="_blank" rel="noopener noreferrer">https://trends.google.com</a></span></li><li id="ref-7"><span><span role="link" aria-label="Go to reference 7" tabindex="0" data-state="closed">7</span></span><span>Boyd, R., &amp; Richerson, P. J. (2011). <em>The cultural niche: Why social learning is essential for human adaptation.</em> <em>Proceedings of the National Academy of Sciences</em>, 108(Supplement 2), 10918–10925. <a href="https://doi.org/10.1073/pnas.1100290108" target="_blank" rel="noopener noreferrer">https://doi.org/10.1073/pnas.1100290108</a></span></li><li id="ref-8"><span><span role="link" aria-label="Go to reference 8" tabindex="0" data-state="closed">8</span></span><span>Centola, D. (2010). The spread of behavior in an online social network experiment. <em>Science</em>, 329(5996), 1194-1197.</span></li></ul></div></section><section><a href="https://www.hudsong.dev/"></a></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[CRISPR offers new hope for treating diabetes (191 pts)]]></title>
            <link>https://www.wired.com/story/no-more-injections-crispr-offers-new-hope-for-treating-diabetes/</link>
            <guid>45211596</guid>
            <pubDate>Thu, 11 Sep 2025 13:45:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wired.com/story/no-more-injections-crispr-offers-new-hope-for-treating-diabetes/">https://www.wired.com/story/no-more-injections-crispr-offers-new-hope-for-treating-diabetes/</a>, See on <a href="https://news.ycombinator.com/item?id=45211596">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>All products featured on WIRED are independently selected by our editors. However, we may receive compensation from retailers and/or from purchases of products through these links. <a target="_blank" href="https://www.wired.com/about/affiliate-link-policy/">Learn more.</a></p></div><div data-journey-hook="client-content" data-testid="ArticlePageChunks"><p><a target="_blank" href="https://www.wired.com/about/affiliate-link-policy/"><span>Crispr gene-editing technology</span> has demonstrated its revolutionary potential in recent years: It has been used to </a><a href="https://www.wired.com/story/a-baby-received-a-custom-crispr-treatment-in-record-time/">treat rare diseases</a>, to <a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC10179023/">adapt crops</a> to withstand the extremes of climate change, or even to <a data-offer-url="https://www.vice.com/en/article/the-worlds-first-genetically-modified-spider-spins-glowing-red-silk/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.vice.com/en/article/the-worlds-first-genetically-modified-spider-spins-glowing-red-silk/&quot;}" href="https://www.vice.com/en/article/the-worlds-first-genetically-modified-spider-spins-glowing-red-silk/" rel="nofollow noopener" target="_blank">change the color</a> of a spider’s web. But the greatest hope is that <a href="https://www.wired.com/story/wired-guide-to-crispr/">this technology</a> will help find a cure for a global disease, such as <a href="https://www.wired.com/tag/diabetes/">diabetes</a>. A new study points in that direction.</p><p>For the first time, researchers succeeded in implanting Crispr-edited pancreatic cells in a man with type 1 diabetes, an autoimmune disease where the immune system attacks insulin-producing cells in the pancreas. Without insulin, the body is then unable to regulate blood sugar. If steps aren’t taken to manage glucose levels by other means (typically, by injecting insulin), this can lead to damage to the nerves and organs—particularly the heart, kidneys, and eyes. Roughly 9.5 million people worldwide have type 1 diabetes.</p><p>In this experiment, edited cells produced insulin for months after being implanted, without the need for the recipient to take any immunosuppressive drugs to stop their body attacking the cells. The Crispr technology allowed the researchers to endow the genetically modified cells with camouflage to evade detection.</p><p>The study, published last month in <a href="https://www.nejm.org/doi/full/10.1056/NEJMoa2503822">The New England Journal of Medicine</a><em>,</em> details the step-by-step procedure. First, pancreatic islet cells were taken from a deceased donor without diabetes, and then altered with the gene-editing technique Crispr-Cas12b to allow them to evade the immune response of the diabetes patient. Cells altered like this are said to be “hypoimmune,” explains Sonja Schrepfer, a professor at Cedars-Sinai Medical Center in California and the scientific cofounder of Sana Biotechnology, the company that developed this treatment.</p><p>The edited cells were then implanted into the forearm muscle of the patient, and after 12 weeks, no signs of rejection were detected. (A <a data-offer-url="https://ir.sana.com/static-files/6d8d5101-84f9-480e-8d3a-1dc77f34f00e" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://ir.sana.com/static-files/6d8d5101-84f9-480e-8d3a-1dc77f34f00e&quot;}" href="https://ir.sana.com/static-files/6d8d5101-84f9-480e-8d3a-1dc77f34f00e" rel="nofollow noopener" target="_blank">subsequent report</a> from Sana Biotechnology notes that the implanted cells were still evading the patient’s immune system after six months.)</p><p>Tests run as part of the study recorded that the cells were functional: The implanted cells secreted insulin in response to glucose levels, representing a key step toward controlling diabetes without the need for insulin injections. Four adverse events were recorded during follow-ups with the patient, but none of them were serious or directly linked to the modified cells.</p><p>The researchers’ ultimate goal is to apply immune-camouflaging gene edits to stem cells—which have the ability to reproduce and differentiate themselves into other cell types inside the body—and then to direct their development into insulin-secreting islet cells. “The advantage of engineering hypoimmune stem cells is that when these stem cells proliferate and create new cells, the new cells are also hypoimmune,” Schrepfer explained in a <a href="https://www.cedars-sinai.org/newsroom/expert-qa-invisible-stem-cells/">Cedars-Sinai Q+A</a> earlier this year.</p><p>Traditionally, transplanting foreign cells into a patient has required suppressing the patient’s immune system to avoid them being rejected. This carries significant risks: infections, toxicity, and long-term complications. “Seeing patients die from rejection or severe complications from immunosuppression was frustrating to me, and I decided to focus my career on developing strategies to overcome immune rejection without immunosuppressive drugs,” Schrepfer told Cedars-Sinai.</p><p>Although the research marks a milestone in the search for treatments of type 1 diabetes, it’s important to note that the study involved one one participant, who received a low dose of cells for a short period—not enough for the patient to no longer need to control their blood sugar with injected insulin. An editorial by the journal <a href="https://www.nature.com/articles/d41586-025-02802-5">Nature</a> also says that some independent research groups have failed in their efforts to confirm that Sana’s method provides edited cells with the ability to evade the immune system.</p><p>Sana will be looking to conduct more clinical trials starting next year. Without overlooking the criticisms and limitations of the current study, the possibility of transplanting cells modified to be invisible to the immune system opens up a very promising horizon in regenerative medicine.</p><p><em>This story originally appeared on</em> <a href="https://es.wired.com/articulos/no-mas-inyecciones-crispr-ofrece-nueva-esperanza-para-tratar-la-diabetes">WIRED <em>en Español</em></a> <em>and has been translated from Spanish.</em></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[From burner phones to decks of cards: NYC teens adjusting to the smartphone ban (202 pts)]]></title>
            <link>https://gothamist.com/news/from-burner-phones-to-decks-of-cards-nyc-teens-are-adjusting-to-the-smartphone-ban</link>
            <guid>45211527</guid>
            <pubDate>Thu, 11 Sep 2025 13:39:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gothamist.com/news/from-burner-phones-to-decks-of-cards-nyc-teens-are-adjusting-to-the-smartphone-ban">https://gothamist.com/news/from-burner-phones-to-decks-of-cards-nyc-teens-are-adjusting-to-the-smartphone-ban</a>, See on <a href="https://news.ycombinator.com/item?id=45211527">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p data-block-key="1bozd">New York City students are one week into the <a href="https://gothamist.com/news/nyc-students-head-back-to-the-classroom-but-have-to-check-their-smartphones-first" rel="noopener" target="_blank">statewide phone ban</a>. Gothamist reporters checked in with teens across the district to see how they are adapting. Here's how they are handling their disconnected days.</p><h4 data-block-key="8k5ft">Lower-tech life</h4><p data-block-key="3bmob">Polaroids, walkie-talkies and decks of cards: New York City teens said these are some of the hot items circulating in schools now that the statewide smartphone ban is in effect.</p><p data-block-key="d8e39">Alia Soliman, a senior at Bronx Science, said cards “are making a big comeback.” She said kids are playing poker when they’re done with their work in some classes. Fellow students reported a surge in Uno.</p><p data-block-key="80a99">“It seems to be very fun and engaging,” Soliman said.</p><p data-block-key="brl2o">She said members of the senior class are using vintage devices to capture memories and milestones.</p><p data-block-key="f26pk">“I’ve seen some of my friends bring in digicams,” Soliman said. “A lot of people are bringing in Polaroids.”</p><p data-block-key="eieqv">She’s looking into whether an MP3 player would be allowed in school to listen to while she studies.</p><p data-block-key="dhisu">“I’ll test the waters,” she said.</p><p data-block-key="820j3">In Manhattan, Ethan Myer, a senior at Union Square Academy, said the ban is also helping kids get their steps in.</p><p data-block-key="58tjm">“Most people are just walking around the hall, because there's not really much else to do,” Myer said. "Some people are talking a bit more, which I guess was the goal.”</p></div><div><p data-block-key="43vq9">Jem Bryant, a junior at Gramercy Arts High School, also near Union Square, is daydreaming more.</p><p data-block-key="argsp">“I  don't really have a lot of friends in classes,” Bryant said. “So when they say ‘do your classwork’ and I'm already done, I literally just have to sit there and stare at the wall.”</p><p data-block-key="9u71h">Soliman said she was opposed to the ban at first, and she’s concerned that she won’t be able to work on her college applications during downtime at school, but she sees some positives.</p><p data-block-key="ch5vc">“I’m still not thrilled,” she said. “But people are reading more. The younger kids are socializing more.”</p><p data-block-key="aacjn">Peter Schmidt-Nowara, a teacher and dean at Brooklyn Tech, said the hallways and lunchroom are louder, in a good way.</p><p data-block-key="ejeeg">“It was muted,” he said. “It’s really lifted a pall.”</p><p data-block-key="8ss2j">He said it’s a stark difference from last year, when kids were retreating to bathrooms for 20 minutes to check their phones, and walking through the halls with their heads down.</p><p data-block-key="jg98">He added that he's enjoyed watching students turn to unfamiliar technology.</p><p data-block-key="27q9h">“A group of boys brought in a transistor radio to listen to music. They didn’t realize they had to lift the antenna, so I lifted it for them. The music wasn’t that loud and it was quite sweet,” he said.</p><h4 data-block-key="7t1hu">Workarounds</h4><p data-block-key="amhuf">No students interviewed by Gothamist copped to having burner phones of their own, but some said they knew of classmates deploying decoys.</p><p data-block-key="3iqjb">“Not to rat anyone out, but some people have fake phones,” said Solangel Santana, a senior at Union Square Academy.</p><p data-block-key="8618t">She added that kids sometimes send each other emails or chat in Google Docs on their education department-issued devices.</p><p data-block-key="78q29">“We find creative ways to talk to each other,” she said.</p><p data-block-key="s4t">Video app TikTok is rife with videos of kids breaking into pouches. “They slam it,” said Esmeralda Jaramillo, a junior at Gramercy Arts.</p><p data-block-key="4lasb">Soliman said students sometimes physically leave the building and go out into the courtyard for a phone break to play games or check messages during free periods or lunch. “The benches are always full,” Soliman said.</p><p data-block-key="8r82d">Speaking at DeWitt Clinton High School in the Bronx on Monday, Mayor Eric Adams said it’s not the first time teenagers have tried to skirt the rules.</p><p data-block-key="4sbje">“This is all part of their creative spirit and energy,” he said. “We did it. Let's not act like when we were in school, we didn't have all our little tricks on how we got around things.</p><p data-block-key="cfuv4">Adams made the comments at a press conference to announce the distribution of 350,000 internet-enabled Chromebooks, part of the city’s effort to replace aging devices obtained during the pandemic, and ensure that all students have access to technology in schools even as their personal devices are banned.</p></div><div><h4 data-block-key="9o83u"><b>From bottlenecks to stampedes</b></h4><p data-block-key="b6n5t">Schools have rolled out a range of strategies, with most schools either collecting phones at arrival and storing them in lockers or distributing magnetic pouches that have to be locked and unlocked at the beginning and end of the day.</p><p data-block-key="497t0">Bryant at Gramercy Arts High School said of the end-of-day routine, “They’ll be like, ‘Single-file line,’ but it will not be a single-file line and people will just bum-rush the magnets.”</p><p data-block-key="t5ih">Students at LaGuardia High School reported long lines on the first few days of school.</p><p data-block-key="1sq60">Laila Lawrence, 16, said students have been blamed for being late to class.</p><p data-block-key="bpbo4">“The teachers are the first ones to complain, ‘Oh, you were late, da da da da.’ I'm like, ‘I was on the line, like, what do you want me to do?’”</p><p data-block-key="1gl3a">But Lawrence's views on the ban were mixed.</p><p data-block-key="ejdel">“ I think it's good and bad because phones are obviously a problem,” she said. “I'm not gonna say like I'm not addicted to my phone 'cause I am, but at the same time I'm like no one in the school is like purposely on their phone in the middle of class.”</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[An engineering history of the Manhattan Project (131 pts)]]></title>
            <link>https://www.construction-physics.com/p/an-engineering-history-of-the-manhattan</link>
            <guid>45211127</guid>
            <pubDate>Thu, 11 Sep 2025 13:04:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.construction-physics.com/p/an-engineering-history-of-the-manhattan">https://www.construction-physics.com/p/an-engineering-history-of-the-manhattan</a>, See on <a href="https://news.ycombinator.com/item?id=45211127">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p><span>The Manhattan Project, the US program to build an atomic bomb during WWII, is one of the most famous and widely known major government projects: a survey in 1999 ranked the dropping of the atomic bomb as the </span><a href="https://www.osti.gov/opennet/manhattan-project-history/index.htm" rel="">top news story of the 20th century</a><span>. Virtually everyone knows that the project built the bombs that were dropped on Hiroshima and Nagasaki. And most of us probably know that the bomb was built by some of the world’s best physicists, working under Robert Oppenheimer at Los Alamos in New Mexico. But the Manhattan Project was far more than just a science project: building the bombs required an enormous industrial effort of unprecedented scale and complexity. Enormous factory complexes were built using hundreds of millions of dollars worth of never-before-constructed equipment. Scores of new machines, analytical techniques, and methods of working with completely novel substances had to be invented. Materials which had never been produced at all, or only produced in tiny amounts, suddenly had to be manufactured in vast quantities.</span></p><p>This massive effort was required in part because of the enormous difficulty in producing fissile material, and in part because of the enormous uncertainty facing the project: it wasn’t known what the best method for manufacturing the fissile material needed for the bomb would be, what the design of the bomb should be, or whether a workable bomb could even be built. Developing the bomb required resolving this uncertainty, and the project needed to rapidly push forward knowledge and capabilities in many fields: not merely in the realm of nuclear chain reactions and atomic physics, but also in areas like precision explosives, metallurgy, welding, chemical separation, and electronics.</p><p>Because of the exigencies of war, this work needed to be done extremely rapidly. There wasn’t time to investigate promising approaches sequentially, or wait for more information before picking a particular course. Thus, multiple possible routes to the bomb — different fuels (and different fuel production techniques), different bomb designs, different components like triggers and tampers — were pursued simultaneously. Major commitments, like factories that cost hundreds of millions of dollars, were made before it was known whether they would even be useful. Design work began on the bombs when the nuclear fuel they would use hadn’t been produced in more than microscopic amounts.</p><p>Normally when trying to create a new technology, funding constraints and the need for economic returns determine how much time and effort can be spent on development. Efforts to create some new technology will often be small-scale until the surrounding conditions are right — until knowledge has caught up, or the necessary supporting infrastructure exists, or the input materials are cheap enough — and risk can be minimized. But with the Manhattan Project, these constraints didn’t exist. Funding was virtually unlimited in service of ending the war sooner, and the biggest perceived risk was that Germany would beat the US to the bomb. As a result, an extremely robust development effort could be justified, which thoroughly explored virtually every promising path to an atomic weapon (no matter how expensive or uncertain).</p><p>The Manhattan Project began in June of 1942, when Colonel James Marshall of the Army Corps of Engineers was directed to create a new engineering district to lead the army’s efforts to develop an atomic weapon. Shortly after, Colonel Leslie Groves (who would soon be promoted to brigadier general) was selected to lead the project. At the time, the official name of the project was “Laboratory for the Development of Substitute Materials” (DSM for short), but Groves felt that this name would attract curiosity, and so a new name was selected based on the location of Marshall’s New York office: the Manhattan Engineer District.</p><p><span>By the time the Manhattan Project officially formed, the US was already at work developing an atomic bomb. Following the discovery of fission in 1938 by Otto Hahn and Fritz Strassmann, physicists began to speculate that a nuclear chain reaction might be possible, and that such a reaction could be used to build a bomb of unprecedented magnitude. In August the following year, Albert Einstein and physicist Leo Szilard sent a </span><a href="https://en.wikipedia.org/wiki/Einstein%E2%80%93Szilard_letter" rel="">letter to president Roosevelt</a><span>, warning him that a nuclear chain reaction might be used to build an extremely powerful bomb, and that the US should research atomic energy. Two months later, Roosevelt ordered the creation of an advisory committee on uranium, and by early 1940 US researchers (most notably Enrico Fermi) were working to create a sustained nuclear chain reaction.</span></p><p><span>In July of 1941, a report from the British </span><a href="https://en.wikipedia.org/wiki/MAUD_Committee" rel="">MAUD Committee</a><span> concluded that it was likely feasible to build an atomic bomb. It reached the US, and in October Roosevelt authorized expediting atomic bomb work. Bomb efforts accelerated following Japan’s attack on Pearl Harbor in December of 1941, and in February of 1942 the </span><a href="https://en.wikipedia.org/wiki/Metallurgical_Laboratory" rel="">Metallurgical Laboratory</a><span> was formed at the University of Chicago to study nuclear chain reactions and the chemistry of newly-created element plutonium. There, a team working under Enrico Fermi continued their work to create nuclear chain reactions, ultimately resulting in </span><a href="https://en.wikipedia.org/wiki/Chicago_Pile-1#Origins" rel="">Chicago Pile-1</a><span>, the world’s first self-sustaining nuclear reaction, in December of that year.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!aFID!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6da75b23-781f-47db-9b53-c907625d5cdb_1920x1475.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!aFID!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6da75b23-781f-47db-9b53-c907625d5cdb_1920x1475.png 424w, https://substackcdn.com/image/fetch/$s_!aFID!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6da75b23-781f-47db-9b53-c907625d5cdb_1920x1475.png 848w, https://substackcdn.com/image/fetch/$s_!aFID!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6da75b23-781f-47db-9b53-c907625d5cdb_1920x1475.png 1272w, https://substackcdn.com/image/fetch/$s_!aFID!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6da75b23-781f-47db-9b53-c907625d5cdb_1920x1475.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!aFID!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6da75b23-781f-47db-9b53-c907625d5cdb_1920x1475.png" width="500" height="384.27197802197804" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/6da75b23-781f-47db-9b53-c907625d5cdb_1920x1475.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1119,&quot;width&quot;:1456,&quot;resizeWidth&quot;:500,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!aFID!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6da75b23-781f-47db-9b53-c907625d5cdb_1920x1475.png 424w, https://substackcdn.com/image/fetch/$s_!aFID!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6da75b23-781f-47db-9b53-c907625d5cdb_1920x1475.png 848w, https://substackcdn.com/image/fetch/$s_!aFID!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6da75b23-781f-47db-9b53-c907625d5cdb_1920x1475.png 1272w, https://substackcdn.com/image/fetch/$s_!aFID!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6da75b23-781f-47db-9b53-c907625d5cdb_1920x1475.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a><figcaption><span>Early test pile at University of Chicago, 1942, via </span><a href="https://en.wikipedia.org/wiki/Chicago_Pile-1" rel="">Wikipedia</a><span>.</span></figcaption></figure></div><p>When the Manhattan Engineering District was formed in 1942, there was still a great deal of uncertainty surrounding the construction of an atomic bomb. Based on what was known at the time, it was believed that a bomb was probably feasible, and that due to the risks of Germany developing one it should be pursued. But it was far from clear what the surest path to success was.</p><p><span>The first major challenge came in producing sufficient </span><a href="https://en.wikipedia.org/wiki/Fissile_material" rel="">fissile material</a><span> to build a bomb. Fissile material splits and releases neutrons when struck by slow, “thermal” neutrons, making a nuclear chain reaction possible. At the time there were two major candidate materials: a rare isotope of uranium known as uranium-235 (U235), and </span><a href="https://en.wikipedia.org/wiki/Plutonium" rel="">plutonium</a><span>, an element first synthesized by Glenn Seaborg in late 1940.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1-173288277" href="https://www.construction-physics.com/p/an-engineering-history-of-the-manhattan#footnote-1-173288277" target="_self" rel="">1</a></span></p><p><span>Using either would be very challenging. U235 makes up </span><a href="https://en.wikipedia.org/wiki/Uranium-235" rel="">less than 1%</a><span> of naturally-occurring uranium, and using it as a bomb material required separating it from the far more common </span><a href="https://en.wikipedia.org/wiki/Uranium-238" rel="">U238</a><span>. But the two isotopes were only distinguished by a tiny difference in their weights (U235 weighs about 1.3% less than U238). Some sort of filtering mechanism was needed that could act on this difference and create concentrations of U235 high enough for a bomb (a process known as </span><a href="https://en.wikipedia.org/wiki/Enriched_uranium" rel="">enrichment</a><span>).</span></p><p>There were several potential methods considered for separating U235:</p><ul><li><p><span>In the </span><strong>electromagnetic method</strong><span>, a beam of charged uranium tetrachloride particles would be fired through a magnetic field, which would alter their paths. Because of the difference in weight, the paths of U235 and U238 would be slightly different, and the U235 could be gathered at an appropriately placed collector.</span></p></li><li><p><span>In the </span><strong>gaseous diffusion method</strong><span>, gaseous uranium hexafluoride would diffuse through a barrier with microscopic pores. The lighter U235 would diffuse more readily through the barrier due to </span><a href="https://en.wikipedia.org/wiki/Graham%27s_law" rel="">Graham’s Law</a><span>.</span></p></li><li><p><span>In the </span><strong>liquid thermal diffusion method</strong><span>, a thermal gradient created in a uranium solution would cause a slight migration of heavier U238 to the cold side and the lighter U235 to the warm side.</span></p></li><li><p><span>In the </span><strong>centrifuge method</strong><span>, uranium spun in a </span><a href="https://www.osti.gov/opennet/manhattan-project-history/Processes/UraniumSeparation/centrifuges.html" rel="">high-speed centrifuge</a><span> would cause the heavier U238 to concentrate on the outer edge.</span></p></li></ul><p>Of these methods, the electromagnetic method was the most developed, thanks to the efforts of Ernest Lawrence at the University of California, but it wasn’t clear if any of them (either alone or in combination) could actually produce U235 at the scale and speed needed. And no matter the method selected, an enormous industrial facility would be required: in 1939 Danish physicist Niels Bohr insisted that an atomic bomb could never be built “unless you turned the US into one huge factory.”</p><p><span>The main alternative to U235 was plutonium. As with U235, the main challenge would be collecting enough of it to build a bomb. Plutonium only occurs in trace amounts in nature (</span><a href="https://www.scientificamerican.com/article/do-transuranic-elements-s/" rel="">1 atom per 100 billion</a><span> in uranium ore): collecting enough to build a bomb requires synthesizing it. Plutonium could be produced in a nuclear reactor (then called a “pile,” as it was essentially chunks of uranium piled high enough to create a self-sustaining nuclear reaction), but only in microscopic amounts. Producing a pound of plutonium required around </span><a href="https://www.nps.gov/articles/000/manhattan-project-science-at-hanford.htm" rel="">4000 pounds of uranium fuel</a><span>, and producing enough for a bomb would require an enormous industrial facility, as with U235. Exacerbating this difficulty was the fact that while U235 and U238 could be handled comparatively easily, plutonium and other nuclear reactor byproducts were highly radioactive, requiring special handling.</span></p><p><span>Once enough fissile material had been collected, it then needed to be turned into a bomb. When enough fissile material is brought together in a small enough volume (the so-called </span><a href="https://en.wikipedia.org/wiki/Critical_mass" rel="">critical mass</a><span>), it can start a nuclear chain reaction, releasing enormous amounts of energy as more and more fissions were triggered. Because a chain reaction in critical mass could be started by spontaneous fission (fissile elements randomly splitting and releasing neutrons) or by cosmic rays, a bomb would have to start with a sub-critical mass of fissile material, turning it into a critical mass at detonation. </span></p><p>The most straightforward way to do this, it was thought, was to use a gun that would fire a sub-critical “bullet” into another sub-critical “target,” the combination of which would exceed the critical mass. But there were other mechanisms considered, including using an explosion to compress a sphere of fissile material (the so-called implosion method), as well as “autocatalytic” mechanisms in which “the chain reaction itself, as it proceeded, increased the neutron number for a time.”</p><p>In mid-1942, a gun-based plutonium bomb was generally considered most promising, but due to the lack of information and the great urgency, many promising paths were investigated simultaneously. Early on in the project, when resolving a debate about pile cooling systems, Leslie Groves stated that “The War Department considers this project important. There is no objection to a wrong decision with quick results. If there is a choice between two methods, one of which is good and the other looks promising, then build both.”</p><p>Perhaps no phrase better summarizes the philosophy of Manhattan Project than “build both.” It was ultimately decided to pursue both U235 and plutonium-based bombs. To produce the necessary U235, a production facility would be built near Knoxville, Tennessee, employing both electromagnetic separation and gaseous diffusion (and, eventually, liquid thermal diffusion). This plant, initially referred to as the Clinton Engineer Works, would later be named Oak Ridge. To produce the plutonium, another facility, the Hanford Engineer Works, would be built in southeast Washington. And while these plants were being built and producing fissile material, the design of the bombs themselves would be done at Los Alamos, New Mexico.</p><p><span>The acquisition of the site for Oak Ridge was </span><a href="https://en.wikipedia.org/wiki/Clinton_Engineer_Works" rel="">authorized</a><span> in September of 1942, and construction of the electromagnetic separation plant began a few months later in February of 1943 by the firm </span><a href="https://en.wikipedia.org/wiki/Stone_%26_Webster" rel="">Stone and Webster</a><span>. To produce U235, the plant would use modified versions of Ernest Lawrence’s Nobel prize-winning </span><a href="https://en.wikipedia.org/wiki/Cyclotron" rel="">cyclotron particle accelerators</a><span>. Lawrence had been working on the devices, which he referred to as “</span><a href="https://en.wikipedia.org/wiki/Calutron" rel="">calutrons</a><span>” (after the University of California) since the spring of 1942, and while he confident that calutrons could be used for large-scale production of U235, “he stood almost alone in his optimism”:</span></p><blockquote><p><em>The method called for a large number of extremely complicated, and as yet undesigned and undeveloped devices involving high vacuums, high voltages and intense magnetic fields. As a large-scale method of separating Uranium-235, it seemed almost impossible. Dr. George T. Felbeck, who was in charge of the gaseous diffusion process for Union Carbide, once said it was like trying to find needles in a haystack while wearing boxing gloves. - Now It Can Be Told</em></p></blockquote><p>(According to Richard Rhodes, the total volume of high-vacuum required by the calutrons would eventually exceed the amount of vacuum produced everywhere else on earth at the time.)</p><p>The calutrons, arranged around a series of several “racetracks” with several dozen collection tanks attached, were divided into two stages. Partly enriched material from “alpha” racetracks would be fed into “beta” racetracks to be further enriched, eventually (it was hoped) producing 90% enriched U235. Each calutron only produced a tiny amount of U235 — Lawrence estimated that 2000 calutrons could produce 100 grams of enriched U235 per day — so a huge number of them were needed: the alpha and beta calutron buildings eventually occupied an area greater than 20 football fields, and the entire electromagnetic separation facility grew to 268 buildings, requiring 20,000 workers to build:</p><blockquote><p><em>…The calutron structures of steel and brick and tile, chemistry laboratories, a distilled water plant, sewage treatment plants, pump houses, a shop, a service station, warehouses, cafeterias, gatehouses, change houses and locker rooms, a paymaster’s office, a foundry, a generator building, eight electric substations, nineteen water-cooling towers - for an output measured in the best of times in grams per day. - The Making of the Atomic Bomb</em></p></blockquote><p>Building this enormous facility was rife with challenges. Copper, traditionally used for winding electromagnets, was in short supply due to the war, and so was substituted with silver (also a good conductor) borrowed from the US Treasury. Altogether 13,540 tons, worth $300 million ($6 billion in 2025 dollars) was borrowed, 99.964% of which was eventually returned. Because construction started so early, constant changes to already manufactured and installed equipment were required, a process that continued “long after the first major units of the plant began production operations.” Little of what was required to build the plant was off the shelf or standard:</p><blockquote><p><em>Discouragingly few items were commercially available. Tanks, magnets, vacuum pumps, cubicles, and most of the chemical equipment, for example, were either completely new in design or so much larger or so much greater in capacity that nothing of the kind previously had been manufactured. Many less obvious items also carried performance specifications that far exceeded anything ever attempted on a commercial scale. For instance, the calutrons required electrical cable that could carry a high-voltage load continuously. The only commercial product that came near meeting this specification was the heaviest X-ray cable, and it was designed to operate intermittently. Even when the commercial equipment could be used, suppliers often had to add to their productive capacity or build entire new plants to furnish the items required in the enormous quantities they were needed. Thus, in the first equipping of the racetracks some eighty-five thousand vacuum tubes were required. In the case of one type of tube, procurement officials ordered in advance the entire national output for 1943 as well as that from a plant still under construction. In the early months of plant operation, when tubes burned out faster than predicted, some feared the racetracks might prove inoperable simply through inability to maintain the tube supply.</em></p><p><em>New methods had to be developed for machining and shaping the graphite in those parts of the calutron subject to intense heat. No standard material would endure the high potentials, mechanical strain, and temperature changes to which bushings in the high-voltage elements in the sources were continuously subjected. After months of investigation, Stone and Webster found an insulator made of zirconium oxide, a new and still very expensive substance. Similarly, use of large quantities of liquid nitrogen to condense moisture created a demand for a substance hitherto not produced on a commercial scale anywhere in the country. - Manhattan: The Army and the Bomb</em></p></blockquote><p>These difficulties didn’t stop after construction was completed. When the first calutrons were turned on for testing in November of 1943, the extremely powerful magnets caused the equipment to “walk” by several inches: this was eventually resolved by tying them down with heavy steel straps. Testing also showed intermittent electrical shorts and unexpectedly high variation in the strength of the magnetic fields, problems that was eventually traced to dirt and rust within the electromagnets bridging the gap between the closely spaced silver windings. To fix this required rebuilding and redesigning the magnets, delaying production by a month.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!KKfU!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca774ea8-4600-491d-be32-04616904c54d_1200x865.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!KKfU!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca774ea8-4600-491d-be32-04616904c54d_1200x865.png 424w, https://substackcdn.com/image/fetch/$s_!KKfU!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca774ea8-4600-491d-be32-04616904c54d_1200x865.png 848w, https://substackcdn.com/image/fetch/$s_!KKfU!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca774ea8-4600-491d-be32-04616904c54d_1200x865.png 1272w, https://substackcdn.com/image/fetch/$s_!KKfU!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca774ea8-4600-491d-be32-04616904c54d_1200x865.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!KKfU!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca774ea8-4600-491d-be32-04616904c54d_1200x865.png" width="500" height="360.4166666666667" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/ca774ea8-4600-491d-be32-04616904c54d_1200x865.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:865,&quot;width&quot;:1200,&quot;resizeWidth&quot;:500,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!KKfU!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca774ea8-4600-491d-be32-04616904c54d_1200x865.png 424w, https://substackcdn.com/image/fetch/$s_!KKfU!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca774ea8-4600-491d-be32-04616904c54d_1200x865.png 848w, https://substackcdn.com/image/fetch/$s_!KKfU!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca774ea8-4600-491d-be32-04616904c54d_1200x865.png 1272w, https://substackcdn.com/image/fetch/$s_!KKfU!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca774ea8-4600-491d-be32-04616904c54d_1200x865.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Alpha racetrack at Oak Ridge.</figcaption></figure></div><p>As production came online in early 1944, the electromagnetic separation plant continued to deal with numerous problems: equipment and mechanical failures, electrical short circuits, vacuum leaks and various breakdowns. The operation “skirted the edge of chaos for months.” As late as August of 1944, the electromagnetic plant had only produced a small fraction of the expected U235, and it was unclear if enough would be produced to build a wartime bomb. But eventually these problems were ironed out, and by September of 1945 the alpha and beta calutrons had produced 88 kilograms of 84.5% enriched U235.</p><p><span>In addition to the electromagnetic separation plant, Oak Ridge was also the site of the gaseous diffusion plant, which began construction in May 1943. As with the electromagnetic process, the gaseous diffusion process only produced U235 in tiny amounts, and an enormous facility was needed to manufacture it in sufficient quantities to build a bomb. Gaseous diffusion worked on the principle that lighter U235 would be more likely to diffuse through a porous barrier than heavier U238, but the difference in diffusion rates was miniscule. A single gaseous diffusion step would only increase the fraction of U235 by a factor of 1.0043: to produce 90% enriched U235, the initial design of the plant called for a series of 4,600 gaseous diffusion stages. Upon completion, the gaseous diffusion plant was one of the </span><a href="https://www.theatlantic.com/technology/archive/2013/12/what-was-once-the-worlds-largest-building-has-now-been-completely-demolished/282549/" rel="">largest buildings in the world</a><span>.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!2AYJ!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F68f25c8b-b1bf-4130-b261-2610f6e40b48_701x450.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!2AYJ!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F68f25c8b-b1bf-4130-b261-2610f6e40b48_701x450.png 424w, https://substackcdn.com/image/fetch/$s_!2AYJ!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F68f25c8b-b1bf-4130-b261-2610f6e40b48_701x450.png 848w, https://substackcdn.com/image/fetch/$s_!2AYJ!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F68f25c8b-b1bf-4130-b261-2610f6e40b48_701x450.png 1272w, https://substackcdn.com/image/fetch/$s_!2AYJ!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F68f25c8b-b1bf-4130-b261-2610f6e40b48_701x450.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!2AYJ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F68f25c8b-b1bf-4130-b261-2610f6e40b48_701x450.png" width="701" height="450" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/68f25c8b-b1bf-4130-b261-2610f6e40b48_701x450.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:450,&quot;width&quot;:701,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!2AYJ!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F68f25c8b-b1bf-4130-b261-2610f6e40b48_701x450.png 424w, https://substackcdn.com/image/fetch/$s_!2AYJ!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F68f25c8b-b1bf-4130-b261-2610f6e40b48_701x450.png 848w, https://substackcdn.com/image/fetch/$s_!2AYJ!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F68f25c8b-b1bf-4130-b261-2610f6e40b48_701x450.png 1272w, https://substackcdn.com/image/fetch/$s_!2AYJ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F68f25c8b-b1bf-4130-b261-2610f6e40b48_701x450.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>K-25 gaseous diffusion plant.</figcaption></figure></div><p>As with the electromagnetic plant, construction began before the design of the diffusion process had been finished, and it was unclear if the plant would work at scale. The greatest challenge was finding an appropriate barrier for the gas to diffuse through. The barrier needed to have numerous microscopic pores, be robust enough to withstand exposure to extremely corrosive uranium hexafluoride gas, and be mass-producible. Researchers had experimented with “a great many materials” between 1941 and 1942, but none were suitable. The only common material sufficiently corrosion-resistant was nickel, but no form of nickel seemed to do the trick. An electro-deposited nickel mesh, invented by Edward Norris (a “self-educated Anglo-American interior decorator”) and Edward Adler appeared most promising, but it was so brittle that manufacturing it was incredibly difficult. A modified version of the Norris-Adler barrier, produced by a team from Kellex, Bell Labs, and Bakelite, appeared to work even better, though it too had problems. Work proceeded to further develop both barriers simultaneously, but progress was slow and by the end of 1943 “morale had plummeted”. It wasn’t until early 1944 that satisfactory barriers were being produced in sufficient quantities.</p><p>While the diffusion barrier was the biggest challenge with the gaseous diffusion process, it wasn’t the only one. The plant required a level of vacuum-tightness that had previously only been achieved in labs, demanding the development of novel methods of pipe welding and leak detection. Upon completion, it took 406 workers eight months to test the plant for leaks. More than 130,000 measuring instruments, many of them novel, were installed in the plant. It was likely the greatest number of instruments ever used in any plant in the world till that date, and they required months of testing and calibration. The plant had to be incredibly reliable, as “even slight variations in such factors as temperature and pressure could produce adverse effects.” Initially, it was believed that a slight power interruption could bring the diffusion plant offline for months, so a dedicated power plant was built specifically at Oak Ridge for the process. And because any contaminants could prove disastrous, the cleanliness standards for the plant approached surgical:</p><blockquote><p><em>…Construction workers had to cleanse all pipes, valves, pumps, converters, and other items of equipment thoroughly before installation. Workmen in a special unit performed this vast operation in the large conditioning building, using equipment for solvent degreasing, alkaline cleaning, acid pickling, scratch brushing, surface passivation, and a variety of other procedures. When they finished, they sealed all openings to interior surfaces and kept them sealed until installation teams put the equipment into place.</em></p><p><em>To make certain no dust or other foreign matter polluted the system during installation, J. A. Jones instituted a rigid schedule of surgical cleanliness in installation areas. Isolating these areas with temporary partitions, the workers installed pressure ventilation, using filtered air. Then they cleaned the areas thoroughly, and inspectors carefully checked all personnel and material that entered them. Maintenance crews with mops and vacuum cleaners continued to remove any foreign substances that seeped in. When trucks had to enter, workers hosed them down at the entrances.</em></p><p><em>Workers wore special clothes and lintless gloves. Because certain work on equipment to be used in plant installations could not be done in the dirt-free areas, such as welding pipes and other small jobs, J.A. Jones installed special inflatable canvas balloons and the work was done inside them. The cleanliness control measures required many additional guards, inspectors, and supervisors… - Manhattan: The Army and the Bomb</em></p></blockquote><p>This level of cleanliness extended to the design of the equipment itself:</p><blockquote><p><em>[Uranium hexafluoride] attacked organic materials ferociously: not a speck of grease could be allowed to ooze into the gas stream anywhere along the miles and miles of pipes and pumps and barriers. Pump seals therefore had to be devised that were both gastight and greaseless, a puzzle no one had ever solved before that required the development of new kinds of plastics. (The seal material that eventually served at Oak Ridge came into its own after the war under the brand name Teflon.) A single pinhole leak anywhere in the miles of pipes would confound the entire system; Alfred O. Nier developed portable mass spectrometers to serve as subtle leak detectors. Since pipes of solid nickel would exhaust the entire U.S. production of that valuable resource, Groves found a company willing to nickel-plate all the pipe interiors, a difficult new process accomplished by filling the pipes themselves with plating solution and rotating them as the plating current did its work. - The Making of the Atomic Bomb</em></p></blockquote><p>Because of these difficulties, the gaseous diffusion plant didn’t begin operating until February of 1945. While the plant was originally planned to produce uranium to the roughly 90% U235 enrichment needed to build a bomb, it was discovered that beyond 36.6% enrichment, different types of barrier and different types of pumps being designed would be required. In the latter half of 1943 the plant was thus redesigned to produce 36.6% enriched uranium (using 2892 diffusion stages) that would then be fed into the electromagnetic process. By the end of the war, the gaseous diffusion plant had “contributed substantially to the manufacture of the fissionable material used in the fabrication of atomic weapons”, and would become the primary method of producing enriched uranium in the early post-war years.</p><p>In addition to the electromagnetic and gaseous diffusion separation processes, a plant to separate U235 by liquid thermal diffusion was also built. Thermal diffusion had been considered by the Manhattan Project early on, but it appeared insufficiently promising and there were no initial plans to build a thermal diffusion plant. However, work on the process continued by the Navy as a method of producing fissile material for nuclear reactors. By late 1942, it appeared much more promising as a feasible separation method, and Leslie Groves recommended that it continue to be developed by the Navy. Eventually, in June of 1944 it was decided to build a thermal diffusion plant at Oak Ridge to produce partially-enriched uranium as an input to the electromagnetic separation process, as doing so would speed up overall U235 production. The plant came online in late 1944.</p><p>Like the other separation plants, there were struggles getting the plant built and operational. Early on there were numerous steam leaks and other equipment failures, and the “results scarcely seemed to justify the risks.” But eventually the plant “served its wartime purpose,” providing enough slightly enriched U235 to the electromagnetic separation plant and (later) the gaseous diffusion plant to build a uranium bomb by July 1945. After the war, however, it was found that the thermal diffusion plant was less economical than gaseous diffusion in producing enriched uranium, and it was shut down in September 1945, less than a year after starting operation.</p><p>As with U235, when plutonium was being considered as a possible fissile material for an atomic bomb there was a great deal of uncertainty around its large-scale production. When plans began to be formulated for plutonium manufacture in late 1942, the element had only been produced in microscopic amounts in cyclotrons — as late as December 1943, only two milligrams of plutonium had been manufactured. Producing the pounds of plutonium needed for a bomb would require a self-sustaining nuclear chain reaction in a nuclear reactor, which would create plutonium as a fission byproduct. The first such chain reaction was created in Chicago Pile-1 in December 1942, shortly after Du Pont had been (reluctantly) brought on as the contractor to build and operate a plutonium production plant.</p><p><span>As with uranium separation, there were a variety of potential ways to build a plutonium-producing nuclear reactor. Every design considered used uranium as a fuel, but there were a variety of options for cooling (water, helium, diphenyl, bismuth) and for moderators to slow down the neutrons (heavy water, graphite).</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-2-173288277" href="https://www.construction-physics.com/p/an-engineering-history-of-the-manhattan#footnote-2-173288277" target="_self" rel="">2</a></span><span> The initial reactor design used helium-cooling with a graphite moderator: helium wouldn’t absorb neutrons, and was an inert gas that wouldn’t corrode any of the reactor materials. But it was later shown that the neutron multiplication factor in a reactor, k, was high enough that coolants which absorbed more neutrons (such as water) could be made to work. Because a water-cooled reactor appeared far simpler to build, the design was changed to use water cooling. Du Pont, worried that pursuing a single reactor design was too risky, also continued to develop other designs, chiefly one moderated and cooled by </span><a href="https://en.wikipedia.org/wiki/Heavy_water" rel="">heavy water</a><span>, and several heavy water plants were built around the country for these purposes.</span></p><p><span>Plutonium production began with a smaller-scale, air-cooled test reactor, named </span><a href="https://en.wikipedia.org/wiki/X-10_Graphite_Reactor" rel="">X-10</a><span>, built at Oak Ridge between February 1943 and January 1944. Full-scale production would take place at a remote facility built in southeastern Washington known as the </span><a href="https://en.wikipedia.org/wiki/Hanford_Engineer_Works" rel="">Hanford Engineer Works</a><span>. The first plutonium production reactor, </span><a href="https://en.wikipedia.org/wiki/B_Reactor" rel="">B Reactor</a><span>, began construction at Hanford in August of 1943, and first achieved criticality in September of the following year.</span></p><p>Like with uranium, plutonium production demanded a massive industrial facility, and Hanford was the biggest facility that Du Pont had ever constructed. An oral history of the Hanford site notes that “the building effort at Hanford from 1943 to 1945 can only be measured in superlatives”:</p><blockquote><p><em>Consider the following: Project building crews used 1800 vehicles, including sedans, pick-up trucks, jeeps, and ambulances; 900 buses that had a total seating capacity of over 30,000; 1900 dump trucks and flat bed trucks; 240 tractor trailers; 44 railway locomotives and 460 railway cars; 5 locomotive cranes and 4 stiff leg derricks. The various construction teams built 386 miles of highways, 158 miles of track, poured 780,000 cubic yards of concrete, and erected housing for 5,000 women and 24,000 men. Excavation crews moved 25 million cubic yards of earth in the process. The overall cost was $350 million. - Working on the Bomb</em></p></blockquote><p><span>The three production reactors built at Hanford (B, D, and F Reactors) were far more powerful than anything that had come before. Fermi’s </span><a href="https://en.wikipedia.org/wiki/Chicago_Pile-1" rel="">Chicago Pile-1</a><span> produced a maximum of 0.2 kilowatts of power. The </span><a href="https://en.wikipedia.org/wiki/X-10_Graphite_Reactor?utm_source=chatgpt.com" rel="">X-10 reacto</a><span>r at Oak Ridge produced just 500 kilowatts when it was first turned on (though output would later be raised to 4,000 kilowatts). The Hanford reactors were designed to produce 250,000 kilowatts.</span></p><p><span>But the largest structures at Hanford were the separation facilities to extract plutonium out of the soup of radioactive waste products the reactors generated: these were three 800 foot long, 8-story tall buildings that resembled “an ancient mausoleum”; they were so large they were referred to as “</span><a href="https://en.wikipedia.org/wiki/RMS_Queen_Mary" rel="">Queen Marys</a><span>.” Within these enormous structures, plutonium was extracted from radioactive “slugs” of spent uranium fuel from the reactors:</span></p><blockquote><p><em>Irradiated slugs ejected from a production pile would be stored in pools of water 16.5 feet deep to remain until the most intense and therefore short-lived of their fission-product radioactivities decayed away, the water glowing blue around them with Cerenkov radiation, a sort of charged-particle sonic boom. The slugs would then move in shielded casks on special railroad cars to one of the Queen Marys, where they would first be dissolved in hot nitric acid. A standard equipment group occupied two cells: a centrifuge, a catch tank, a precipitator and a solution tank, all made of specially fabricated corrosion-resistant stainless steel. The liquid solution that the slugs had become would move through these units by steam-jet syphoning, a low-maintenance substitute for pumps. There were three necessary steps to the separation process: solution, precipitation and centrifugal removal of the precipitate. These would repeat from equipment group to equipment group down the canyon of the separation building. The end products would be radioactive wastes, stored on site in underground tanks, and small quantities of highly purified plutonium nitrate. - The Making of the Atomic Bomb</em></p></blockquote><p>As at Oak Ridge, there were numerous challenges in building a mammoth industrial facility employing completely novel production processes. The reactors “presented construction problems never encountered before, even by Du Pont's highly competent field forces.” Graphite bars of exceptional purity had to be fabricated and then machined to remove any sort of surface imperfections. Supplying cooling water for the reactors required “installation of a complex system of river pumps; purification, aeration, and distillation units; and retention basins for holding radioactive water until natural decay permitted its return to the Columbia.” New machines for fabricating the uranium fuel rods had to be designed and built, and a method for shielding the unprecedentedly large nuclear reactors had to be developed:</p><blockquote><p><em>Ten months of work went into this before we could even begin to build it, with three more months before the first unit was completed…In the course of this, a special high-density pressed-wood sheet was developed in collaboration with an outside supplier. Then special sharp tools and operating techniques were required to cut various shapes from the standard manufactured widths…At the same time very detailed specifications for assembly, prescribing the closest of tolerances, were written. Some sixty manufacturers were invited to bid and refused, presumably because of the complexity of construction and the close tolerances required…but after methods were developed and prototypes were fabricated at du Pont’s shops in Wilmington eventually satisfactory suppliers were found. - Now It Can Be Told</em></p></blockquote><p>Even seemingly simple items often proved enormously complex. Finding a way to prevent the uranium fuel (which was packaged into aluminum-clad slugs) from corroding took an enormous amount of effort:</p><blockquote><p><em>Two years of trial-and-error effort had not produced canning technology adequate to seal the uranium slugs, which quickly oxidized upon exposure to air or water, away from corrosion. Only in August had the crucial step been devised, by a young research chemist who had followed the problem from Du Pont in Wilmington to Chicago and then to Hanford: putting aside elaborate dips and baths he tried soaking the bare slugs in molten solder, lowering the aluminum cans into the solder with tongs and canning the slugs submerged. The melting point of the aluminum was not much higher than the melting point of the solder, but with careful temperature control the canning technique worked. - The Making of the Atomic Bomb</em></p></blockquote><p>Similarly, Leslie Groves notes that “seven months of persistent effort” were required to produce simple aluminum tubes that met the required specifications.</p><p>After enough plutonium had collected in the canned uranium slugs, it needed to be separated. The chemical process for this was comparatively straightforward to develop compared to the novel methods of mass-based separation developed for U235 (after experimenting with several possibilities, a method based on using bismuth phosphate was employed), but actually implementing it was a challenge. The materials to be processed were radioactive enough that the entire facility needed to be operable and maintainable remotely:</p><blockquote><p><em>…Periscopes and other special mechanisms were incorporated into the plant design; all operations could thus be carried out in complete safety from behind the heavy concrete walls. The need for shielding and the possibility of having to replace parts by indirect means required unusually close tolerances, both in fabrication and in installation. This was true even for such items as the special railroad cars that moved the irradiated uranium between the piles and the separation plants. The tracks over which these cars moved were built with extreme care so as to minimize the chances of an accident. Under no circumstances could we plan on human beings directly repairing highly radioactive equipment. - Now It Can Be Told</em></p></blockquote><p>Among the technologies developed to make remote operation possible were pipe flanges that could be connected by a remotely operated wrench, and the world’s first use of closed circuit TV.</p><p><span>The biggest crisis at Hanford came shortly after the first production reactor came online: a few hours after beginning operation the reaction began to slow, and within a few days it had shut itself down completely. Investigation revealed that this was being caused by a fission byproduct, an isotope of xenon known as Xenon 135 that had a massively greater probability of absorbing neutrons (known as a “</span><a href="https://en.wikipedia.org/wiki/Neutron_cross_section" rel="">neutron cross section</a><span>”) than any previously discovered material. (Its cross section was 70 times larger than the previous largest measured cross section). This “</span><a href="https://en.wikipedia.org/wiki/Iodine_pit" rel="">xenon poisoning</a><span>” hadn’t been noticed in earlier reactors because they hadn’t been run for long enough at a high enough power output.</span></p><p>The problem was ultimately resolved thanks to the conservative reactor design of the Du Pont engineers. The original Hanford reactor, designed chiefly by physicist Eugene Wigner, consisted of 1,500 “channels” for uranium fuel arranged in a cylindrical shape. Du Pont had squared this cylinder, adding more channels to the edges and bringing the total to 2004. When fuel was loaded into these extra channels, it was sufficient to overcome the xenon poisoning effect.</p><p><span>The xenon poisoning problem was overcome in December 1944, and by March 1945 the Hanford site had achieved full-scale plutonium production of around a </span><a href="https://www.nps.gov/mapr/learn/photosmultimedia/hanford-t-plant-virtual-tour.htm" rel="">pound and a half of plutonium per day</a><span>.</span></p><p>As design and construction of the huge facilities at Hanford and Oak Ridge began, work also proceeded on designing the bomb itself. This would chiefly be done at Los Alamos, New Mexico, the third of the atomic cities built for the Manhattan Project. Scientists led by Robert Oppenheimer began to arrive at Los Alamos in March of 1943 (though most of the facility was still under construction).</p><p>When work began at Los Alamos, the most promising method for building a bomb appeared to be the gun method: firing a sub-critical uranium or plutonium bullet into another sub-critical mass. But there were a variety of ways this might be done. Different gun arrangements, ranging from somewhat conventional gun mechanisms of various sizes and shapes to more exotic layouts like double-guns, rockets, and spherical guns were considered. As with the rest of the program, every design choice was mired in uncertainty. Since plutonium and U235 hadn’t yet been produced in large quantities, it wasn’t known exactly how much fissile material would be needed to create a critical mass, and thus how big the bullet and target needed to be. The neutron-reflecting properties of steel gun barrels (which would affect critical mass requirements) hadn’t yet been measured.</p><p>More generally, while the designers were reasonably confident that a gun-type bomb would work, because various nuclear properties and constants had at best been measured very imprecisely (if they’d been measured at all), they couldn’t be sure. A history of Los Alamos notes that in 1942, “the main obstacle to a theoretical understanding of the fission bomb was the uncertainty surrounding existing experimental data, in part the result of inadequate instrumentation and a lack of experience in the new field.” Things were so uncertain that it was not even 100% clear at the beginning of the program that plutonium would produce neutrons. A great deal of effort at Los Alamos was thus devoted to more accurate measurements and better understanding of nuclear physics: the neutron cross sections of various materials, the number of neutrons produced per fission, rates of spontaneous fission, and so on. These measurements were “constantly in flux” for much of the project, and the Los Alamos scientists were “plagued by worry about some unpredicted or overlooked mechanism of nuclear physics which might render our program unsound.”</p><p>Thus in 1943, while most design efforts were directed to developing a gun-type assembly for both uranium and plutonium, there were also parallel efforts on other types of bomb. Chief among these was the implosion method, which would use an explosion to compress a sphere of material enough to create a critical mass, though there were also investigations into the autocatalytic methods. Work also proceeded on what was referred to as the Super (better known today as the hydrogen bomb): using a fission explosion to trigger an even more destructive fusion explosion.</p><p>Beyond the mechanism for creating the critical mass, there were many other aspects of the bomb that needed to be figured out. To minimize the amount of fissile material needed to create a critical mass, the core needed to be surrounded by some type of material that would reflect neutrons back into the core and prevent them from escaping, but what material would work best and how it should be arranged wasn’t yet known. To ensure that the bomb detonated at the right time, it would also need some type of initiator: a mechanism that, when triggered, would create a sudden burst of neutrons to start the nuclear chain reaction.</p><p>More generally, everything about the atomic bomb was new, and almost nothing about its various aspects was known or could be assumed. Every step involved from taking the fissile material from Oak Ridge and Hanford and turning it into a bomb had to be worked out for the first time.</p><p><span>Fissile material would arrive from Hanford and Oak Ridge not as pure plutonium or uranium but as compounds — </span><a href="https://en.wikipedia.org/wiki/Plutonium_Finishing_Plant" rel="">plutonium nitrate</a><span> and uranium tetrafluoride, respectively — and methods for turning these into metallic plutonium and uranium needed to be created. Because impurities might affect the functioning of the bomb, purification methods also needed to be developed. It was initially believed that the plutonium in particular would need to be exceptionally pure, with no more than one part per hundred billion of light elements. Preventing contamination required, among other things, reagents that were “unbelievably purified,” </span><a href="https://www.youtube.com/watch?v=NJLoU84s4ZU" rel="">electronic air cleaners</a><span>, and an extensive lab-cleaning procedure performed by a dedicated service team. Creating effective plutonium purification methods took roughly a year, in part because initially only microscopic quantities of plutonium were available for experiments. Because purification required the ability to detect extremely small quantities of impurities, novel methods of “sub-micro” chemical analysis had to be developed.</span></p><p>Once metallic plutonium and uranium had been produced, methods for shaping the material — casting, rolling, pressing — also needed to be created. The need for purity, combined with the extreme reactivity of molten uranium and plutonium, meant that new crucible materials were needed: MIT spent an enormous amount of “time, effort, and expense” to develop a cerium sulfide crucible that could withstand plutonium's extreme reactivity and high expected melting point without introducing impurities.</p><p>Shaping metallic plutonium — never before produced — required understanding its material properties, which were found to be extremely strange: plutonium has been dubbed “the most complicated metal known to man.” Researchers discovered that plutonium had six different allotropes (physical arrangement of atoms), more than any other metal. Plutonium’s complexity made basic facts such as its melting point surprisingly difficult to determine, and the exotic cerium sulfide crucibles proved to be unnecessary when an unexpectedly low melting point was found. Most of what’s known about plutonium metallurgy was initially worked out at Los Alamos during the Manhattan Project.</p><p>In addition to uranium and plutonium, novel methods and processes had to be developed for a variety of other materials. Polonium, used in the initiator, needed to be procured in large quantities, extensively purified, and deposited on metallic foils. The investigation into polonium’s material properties has been described as “novel as that of plutonium.” Fabrication techniques were also developed for other materials with useful nuclear properties, such as Boron 10 (an isotope of boron with a large neutron cross section) and beryllium.</p><p><span>While a great deal was known about the mechanics of guns and projectiles at the beginning of the project, nothing like a gun needed to fire a sub-critical nuclear bullet had ever been built. The bullet needed to be fired as fast as possible to avoid the problem of predetonation — spontaneous fission starting a chain reaction before the pieces had been joined, leading to a “</span><a href="https://en.wikipedia.org/wiki/Fizzle_(nuclear_explosion)" rel="">fizzle</a><span>” — but the target also needed to stay roughly intact after the projectile’s impact. The gun also needed to be light and small enough that the resulting bomb wouldn’t be too heavy to carry, a requirement that was greatly aided by the realization that the gun would only need to fire once, and could be much less robust than conventional guns. A great deal of calculation and testing on guns of various calibers, propellants, and geometries of targets and bullets was required.</span></p><p>But novel as it was, this work on gun development was far more straightforward than what was required for the implosion bomb. Virtually nothing was known about the behavior of materials when imploded, or how to create an explosion that would compress a sphere of material symmetrically. Resolving this lack of knowledge began simply — setting off explosives on the outside of pipes and seeing how they deformed — but quickly ramped up in complexity. A variety of methods and instruments had to be created to study the interior of materials as they were being imploded. Some of these, such as using X-rays and high-speed cameras, were adaptations of existing measurement techniques, pushed to much higher levels of performance: getting high-speed cameras to work, for instance, required months of experiments with multiple camera designs to create one that was fast enough.</p><p>Other implosion analysis methods, such as the “RaLa” method, were far more novel. The RaLa method involved placing an isotope of radioactive lanthanum (hence RaLa), an emitter of gamma rays, at the center of the material to be imploded. When the material began to compress, it would become denser, resulting in fewer gamma rays penetrating. By surrounding the implosion with gamma ray detectors, a detailed progression of the geometric changes in the imploded material could be recorded.</p><p><span>While the RaLa method was a valuable source of implosion information, implementing it was fiendishly complicated. Even gathering and manipulating the lanthanum was difficult due to its intense radioactivity. Lanthanum was shipped from Oak Ridge in special lead-lined trucks, which were driven 24 hours a day. The assembled material reached 100 </span><a href="https://en.wikipedia.org/wiki/Curie_(unit)" rel="">curies</a><span> of radioactivity at a time when most radioactive experiments didn't exceed a fraction of a curie: a Los Alamos chemist noted that “no one ever worked with radiation levels like these before, ever, anywhere in the world.” Using RaLa required things like a “mechanical chemist” to remotely manipulate the radioactive material, and, initially, a mobile laboratory built inside repurposed </span><a href="https://en.wikipedia.org/wiki/M4_Sherman" rel="">M4 tanks</a><span>.</span></p><p>It was initially hoped that a symmetrical compression could be created simply by adding enough explosive detonation points around the spherical bomb core, but RaLa and other measurement methods revealed “jets” of core material shooting ahead of the rest of the collapsing mass. Dealing with the jets and other asymmetries, and creating a symmetrical collapse of the bomb core, would be one of the main difficulties of the implosion bomb program.</p><p>New analytic techniques and devices weren’t limited to measuring implosions. New devices were made for, among other things, counting neutrons, collecting electrons, discriminating between different electronic pulses, and measuring projectiles with microwaves. Over a thousand pieces of electronic equipment were built at Los Alamos, many of them novel or higher performance than any other equipment then available, including better amplifiers, oscilloscopes, and counting circuits.</p><p>As with Oak Ridge and Hanford, even seemingly straightforward project elements were often enormously complex development efforts due to the novel requirements of the bomb. The triggering mechanism, for instance, couldn’t rely on off the shelf components, as they were considered insufficiently reliable: even a 1% chance of failure was far too high for a bomb in which hundreds of millions of dollars had been invested (the acceptable failure rate was eventually decided to be 0.01%). And when dropped, the bomb needed to automatically trigger at a specific elevation, a capability which didn’t yet exist. After a great deal of testing and development, a trigger circuit using radar altimeters, barometric switches, and electronic clocks was eventually created.</p><p>All this development work took place in largely the same form as the rest of the project: for nearly every decision or device, multiple promising paths were investigated, often at great expense, in the hopes that one or more could be made to work. This often led to a cascade of branching investigations, where each path branched into several possible paths, each of which might branch into more possible paths, and so on. The implosion method was just one of multiple bomb designs investigated, and within the implosion investigation RaLa was just one of multiple analytic techniques created to study implosions (a history of Los Alamos described the implosion studies as a “seven-pronged experimental program”). Bombs using both plutonium and U235 fuels were pursued, and for each material multiple methods of processing them were studied.</p><p>Because so little was known, and progress needed to be made quickly, these investigations often relied on brute force empiricism: running dozens or hundreds of experiments while systematically varying different experimental parameters. Early implosion studies repeatedly tested pipes surrounded by explosives, systematically varying the size of pipes, explosive arrangement, and the type of explosive used. These systematic investigations continued when more advanced diagnostic methods became available: to determine implosion parameters like symmetry, collapse velocity, and amount of compression, an “exhaustive” test program was initiated, where “every possible parameter was varied”. Systematic trial-and-error testing was also used for the design of the gun, the projectiles, and the target.</p><p>The strategy of investigating multiple promising paths proved its worth when the first shipments of reactor-produced plutonium began to arrive at Los Alamos from Oak Ridge in the spring of 1944. Prior to this Los Alamos had worked only with plutonium produced in cyclotrons, which consisted chiefly of the isotope Plutonium-239. However, reactor-produced plutonium was found to also have significant amounts of a different isotope, Plutonium-240. This isotope was found to undergo spontaneous fission much more readily than Plutonium-239 or U235. Its rate of spontaneous fission  — a million times higher that of U235 — was so high in fact that the presence of Plutonium-240 made a gun-type plutonium bomb infeasible: so many neutrons would be produced by spontaneous fission that a chain reaction would be triggered before the bullet met the target, blowing the bomb apart and creating a fizzle.</p><p>The situation seemed dire. There was no time to design and build a separation plant to remove Plutonium-239 from Plutonium-240. To make use of the Hanford plutonium, the only options appeared to be build a composite bomb that mixed plutonium and uranium together (which would be low efficiency and have a comparatively small yield), or to use a different bomb mechanism capable of creating critical mass much more quickly than a gun could. That meant the implosion method, but in early 1944 work on the implosion bomb was far behind behind the gun bomb: until then the implosion bomb had been of secondary importance, a backup in case the gun didn’t work. It was still far from certain whether a workable implosion bomb could be built.</p><p>In July 1944, Robert Oppenheimer ordered a halt on further work on the plutonium gun, and to step up efforts on a plutonium implosion bomb. Within two weeks Los Alamos had been completely reorganized to focus on solving the problems of the implosion bomb. Work on the various implosion analysis methods accelerated, and the first RaLa test was completed in late September. An extensive exploration of solutions to the problem of jets and asymmetrical compression was undertaken, and the development of plutonium purification and metal fabrication methods continued (made easier by the fact that an implosion bomb could tolerate a much higher level of plutonium impurities). By early 1945, aided by the discovery plutonium’s unexpectedly low melting point (which made finding a workable crucible much easier), plutonium was successfully being purified, reduced to a metal, and worked by various methods, shortly before the first “batch” (a mere 80 grams) of plutonium arrived from Hanford.</p><p>The asymmetrical compression problem was eventually solved by the use of explosive lenses, and by changing from a hollow to a solid core of fissile material. Explosive lenses — shaped explosives that would focus the explosion and create a converging pressure wave — were first suggested by James Tuck, who arrived at Los Alamos in May 1944, but using them to build a bomb was fiercely difficult. No theory yet existed for analyzing and predicting the behavior of explosive lenses, and no methods existing for fabricating the carefully shaped explosives to the level of precision required. To design the lenses, there was no choice but to take an iterative approach: designers made guesses about effective lens shapes, tested them, and used the feedback to refine their designs.</p><p>At the same time, methods had to be developed for casting and machining the explosives. This was both enormously difficult (since the explosives had to be extremely uniform and precisely shaped) and dangerous (since machining risked explosion). A history of Los Alamos describes the challenges of explosive casting:</p><blockquote><p><em>It was particularly difficult to cast the high explosives accurately and avoid cracks, bubbles, and other imperfections. Cooling cycles had to be long to minimize thermal stress cracks. Castings had to be wrapped in insulation before being transported between buildings…Casting technology developed slowly and painfully at Los Alamos, by a succession of reasonable steps, that consistently failed to give completely satisfactory results. Eventually, the problems were overcome… - Critical Assembly</em></p></blockquote><p>Machining the explosives was similarly difficult. The jigs and fixtures required to hold the explosives required several months of development, and the explosive machining methods created were considered “revolutionary.”</p><p>The work of figuring out casting and machining methods, and of creating workable lens shapes, demanded enormous amounts of explosives: over the course of the project James Tuck noted that “well over twenty thousand castings were delivered to the firing sites, while the number of castings rejected because of poor quality or destroyed for other reasons is several times this figure.” At the peak of the implosion program, Los Alamos was using 100,000 pounds of high explosive a month.</p><p><span>Creating symmetrical compression in the bomb core also required very precise detonating of the explosives. Early tests were done using </span><a href="https://en.wikipedia.org/wiki/Primacord" rel="">primacord</a><span> detonators (a cord of high explosive surrounded by textiles), but these were found to be far too imprecise, and investigation into other types of detonators was pursued. After extensive experimentation, a spark gap switch (a sort of explosive spark plug) combined with an </span><a href="https://en.wikipedia.org/wiki/Exploding-bridgewire_detonator" rel="">exploding bridgewire detonator</a><span> was developed.</span></p><p><span>Another major design problem on the implosion device was the initiator. The implosion bomb would require a new, more precise type of initiator than used on the gun bomb, one that would be triggered at the moment of highest compression in the bomb core. As late as early 1945, it wasn’t clear whether such an initiator could be built. But continued experiments and testing eventually resulted in what appeared to be a workable design. Named “</span><a href="https://en.wikipedia.org/wiki/Modulated_neutron_initiator" rel="">the urchin</a><span>,” it consisted of a beryllium sphere and pellet, with polonium between the two. When the core was compressed, the sphere would be crushed, mixing the beryllium and polonium and emitting neutrons.</span></p><p>Until very late in the Manhattan Project, it remained unclear if a workable implosion bomb could be built. In the last weeks of 1944, James Conant, President of Harvard and chair of the National Research Defense Council which oversaw the Manhattan Project, stated that the “difficulties were still enormous” and “my own bets very much against it.” At that time, the problems of the modulated initiator and of sufficiently precise and accurate detonation still hadn’t been solved. But as the researchers continued to run down various problems over the following months, the outlook improved considerably. By April the head of the explosives division at Los Alamos could report that its major research and design gambles “had been won”, and there was growing confidence that a bomb of the design chosen — solid plutonium core, explosive lenses, with electric detonators and a modulated initiator — could be made to work. Development work was by no means complete, and there were many problems yet to be solved (design changes to the bomb continued to be made until a few days before the Trinity test on July 16 1945), but by spring of 1945 the “research” portion of research and development had largely concluded.</p><p>As Los Alamos scrambled to build an effective implosion bomb, work also continued on the uranium gun weapon. Because the gun device was considered much less risky and much more certain to work, its development didn’t have the same fervor as the plutonium bomb. (In fact, cancelling the plutonium gun made the uranium gun program easier: a uranium bullet could be fired at a much lower velocity, reducing the difficulties of building a working gun device). But there were still numerous development problems that needed to be overcome. As with plutonium, uranium metal reduction and working methods were finalized by late 1944, and by early 1945 the design of the gun was completed and assembly of it was being tested. Unanswered questions remained until surprisingly late in the program (as late as December 1944 the critical mass of U235 still hadn’t been precisely determined), but there was little uncertainty around whether the bomb would function (so little, in fact, that testing the uranium gun bomb was considered unnecessary). By May of 1945, the uranium gun weapon, code named “Little Boy,” was “ready for combat”.</p><p>The Manhattan Project has become synonymous with a difficult, expensive, and ambitious technological development project, and you often hear folks advocating for a “Manhattan Project for X.” So it's worth understanding why, specifically, the Manhattan Project was so difficult and expensive.</p><p>First, there were inherent physical difficulties in many of the tasks. The bombs required pounds of fissile material, and there was no easy way to produce it: any method chosen would require an enormous industrial-scale production facility. The Hanford Site for producing plutonium cost $350 million ($6.4 billion in 2025 dollars), and the Oak Ridge site cost $304 million ($5.5 billion in 2025 dollars), not including the cost of the borrowed silver for the electromagnets. Hundreds of millions more were spent on operating the facilities. Part of the expense and difficulty of the Manhattan Project came simply because manufacturing fissile material is expensive and difficult (and remains so today.)</p><p>The second difficulty with the Manhattan Project was that because of the great urgency, work had to proceed on the basis of very little information. Resolving the uncertainty often entailed expensive efforts that would have been greatly simplified (or eschewed altogether) had a slower pace been acceptable. Plants were built before the processes they would use had been completely defined, often requiring extensive rework after parts of them had been built. Time and effort was invested in creating a plutonium gun bomb that could have been avoided had the designers waited until reactor-produced plutonium (which due to the presence of Plutonium-240 wouldn’t work in a gun bomb) was available.</p><p>The third difficulty was that because so little knowledge existed around the nature of atomic physics and nuclear chain reactions, it was far from clear what the best route to an atomic weapon was. Because the field was so new, using only recently-discovered natural phenomena that were poorly understood, a great deal of effort was needed to resolve this uncertainty along numerous technological axes. Thus the Manhattan Project involved a large amount of trial and error experimentation, and of pursuing multiple paths of technological development — different bomb types, different fuels, different uranium separation methods, different tampers, different triggers, different implosion analysis methods — to create a workable bomb.</p><p>It’s this last difficulty that is most relevant for other technological development projects. Developing other technologies doesn’t necessarily require building enormous, industrial scale industrial facilities to even begin, and doesn’t necessarily require rapidly proceeding before the proper information and supporting technologies are available. But it will almost certainly require investigating various promising paths of development, partially-informed groping around until the right combination of methods and components is discovered. Indeed, this sort of exploration is the very essence of technological development.</p><p><span>Edison’s light bulb provides a useful comparison: inventing it didn’t require building an enormous, multi-million dollar factory to produce the components to experiment with. And Edison wasn’t forced to invent every single predecessor technology that a light bulb required. One of the reasons why an incandescent bulb wasn’t invented earlier is that, prior to the 1860s, vacuum pumps weren’t good enough. Edison’s bulb relied on the invention of the </span><a href="https://en.wikipedia.org/wiki/Sprengel_pump" rel="">Sprengel mercury pump</a><span> by Hermann Sprengel in 1865, which could create a high enough vacuum that incandescent lamps became feasible. But Edison was forced to explore a variety of different potential methods for creating a bulb until he created one that worked.</span></p><p><span>One thing that the Manhattan Project shows is that resolving this uncertainty, and figuring out what a technology should actually be, is hard. The Manhattan Project had some of the most brilliant scientific minds in the world working on it, but even with this collective brainpower it was far from clear what the best route to the bomb was. For almost every major design decision (including the successful ones), there was at least one genius or expert highly skeptical that it would work. Future Nobel Prize winner Hans Bethe initially resisted joining the program because he believed that building an atomic bomb wasn’t feasible at all. Early in the program, many (such as physicist </span><a href="https://en.wikipedia.org/wiki/Alfred_O._C._Nier" rel="">Alfred Nier</a><span>) felt that electromagnetic separation wouldn’t be a feasible way to isolate U235 (and indeed, until very late it looked like it wouldn’t be). British scientists were similarly pessimistic about the gaseous diffusion process, with some believing that the plant “would be inoperable” due to surges and fluctuations in the gas flow. Du Pont thought that a graphite moderated, water-cooled reactor might not work, and insisted on a heavy water reactor as a backup. Explosives expert William Parsons, head of the uranium gun program, was skeptical that explosive lenses would work, and argued that the only way to have an implosion bomb ready by summer of 1945 was with a non-lensed design. Enrico Fermi initially believed that a modulated initiator wouldn’t work, and would come up with a new reason why “every second day or so.”</span></p><p><span>It’s also notable that many of the options chosen didn’t turn out to be the best long-term. Post-war atomic weapons almost entirely eschewed </span><a href="https://en.wikipedia.org/wiki/Gun-type_fission_weapon" rel="">gun-type mechanisms</a><span> in favor of more efficient implosions. And of all the uranium separation methods explored, it was the one that was deemed least promising and not used at all by the Manhattan Project — gas centrifuges — that is </span><a href="https://world-nuclear.org/information-library/nuclear-fuel-cycle/conversion-enrichment-and-fabrication/uranium-enrichment" rel="">primarily used</a><span> for uranium enrichment today.</span></p><p>Not all technologies will require expensive physical facilities to produce, or require extremely rapid, expensive development. But resolving the uncertainty inherent in a new technology — figuring out what, exactly, the arrangement of phenomena needs to be to achieve some goal, and how that arrangement can be achieved — is part of the fundamental nature of creating a new technology. The Manhattan Project required an unusually large amount of this (advancing the state of the art in many different disciplines), but will always be required to some degree.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GrapheneOS and Forensic Extraction of Data (2024) (296 pts)]]></title>
            <link>https://discuss.grapheneos.org/d/13107-grapheneos-and-forensic-extraction-of-data</link>
            <guid>45210910</guid>
            <pubDate>Thu, 11 Sep 2025 12:46:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://discuss.grapheneos.org/d/13107-grapheneos-and-forensic-extraction-of-data">https://discuss.grapheneos.org/d/13107-grapheneos-and-forensic-extraction-of-data</a>, See on <a href="https://news.ycombinator.com/item?id=45210910">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="drawer">

        <header id="header">
            
            <div>
                    <p><a href="https://discuss.grapheneos.org/" id="home-link">
                                                    GrapheneOS Discussion Forum
                                            </a>
                </p></div>
        </header>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ireland will not participate in Eurovision if Israel takes part (168 pts)]]></title>
            <link>https://www.rte.ie/entertainment/2025/0911/1532957-rte-eurovision/</link>
            <guid>45210867</guid>
            <pubDate>Thu, 11 Sep 2025 12:41:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.rte.ie/entertainment/2025/0911/1532957-rte-eurovision/">https://www.rte.ie/entertainment/2025/0911/1532957-rte-eurovision/</a>, See on <a href="https://news.ycombinator.com/item?id=45210867">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent" role="main">
    
    
        
    

    

    <article>
        

        <div data-equalizer-watch="" id="main" itemscope="" itemtype="http://schema.org/Article" data-equalizer="" data-equalize-on="large" data-equalize-by-row="">
                

                
                    




<header>
    <h2 itemprop="name" data-epic-field="title">
        
        Ireland will not participate in Eurovision if Israel takes part
    </h2>
</header>
<div>
    <p><span>
            
                
                    Updated / Thursday, 11 Sep 2025 15:12
                
            
		</span>
    </p>

    
    
     <!-- Necessary to display widgets correctly, test widgets after removing it -->
    
</div>


    
    <meta itemprop="image" content="https://www.rte.ie/images/0014e5f6-500.jpg">






    


                

                

                
                    <section itemprop="articleBody" data-epic-field="content">
                        <p>RTÉ has announced that it will not take part in the 2026 Eurovision Song contest "if the participation of Israel goes ahead".</p>
<p>In a statement released today, the broadcaster said that "it is RTÉ's position that Ireland will not take part in the 2026 Eurovision Song Contest, if the participation of Israel goes ahead, and the final decision regarding Ireland's participation will be made once the EBU's decision is made".</p>
<p>RTÉ Director General Kevin Bakhurst said that "RTÉ feels that Ireland's participation would be unconscionable given the ongoing and appalling loss of lives in Gaza. RTÉ is also deeply concerned by the targeted killing of journalists in Gaza, the denial of access to international journalists to the territory, and the plight of the remaining hostages".</p>
<figure><img alt="" src="https://www.rte.ie/images/00228700-614.jpg?ratio=1.78">
<figcaption>Emmy represented Ireland at Eurovision Song Contest 2025 in Basel, Switzerland, with the song Laika Party</figcaption>
</figure>
<p>The 70th anniversary edition of the contest is due to take place in Vienna, Austria next May after Austrian entry JJ won with his song <i>Wasted Love</i> in Basel, Switzerland earlier this year. Ireland was represented by Emmy in Basel, with her song <i>Laika Party</i>.</p>
<p>There has been growing controversy about Israel's participation in Eurovision, with large demonstrations held during the competition in the host cities of Basel earlier this year and in Malmö, Sweden in 2024.</p>
<p>The EBU is an alliance of public service media organisations in countries within the European Broadcasting Area or who are members of the Council of Europe.</p>
<p>Along with Spanish and Slovenian broadcasters, RTÉ had sought consultations with the EBU on Israel's participation, and the EBU had committed to dialogue on the issue.</p>
<p>Following a General Assembly of the European Broadcasting Union in July, a number of EBU members raised concerns about the participation of Israel in the Eurovision Song Contest.</p>
<figure><img alt="" src="https://www.rte.ie/images/002286e8-614.jpg?ratio=1.78">
<figcaption>Yuval Raphael represented Israel in the Eurovision Song Contest 2025 with the song New Day Will Rise</figcaption>
</figure>
<p>RTÉ says in its statement that the broadcaster wishes to thank the EBU for the extensive consultation process that was initiated on foot of that meeting, and the extension of the option to withdraw from participation without penalty to December.</p>
<p>Ireland has participated in the song contest since 1965 and has won the contest seven times.</p>
                    </section>
                    
                
                

                
                    
                <div>
                    <h4>More stories on</h4>
                    
                </div>
                
                
                
                
            </div>
        
            
            
        
        
    </article>
    
    
        <div aria-labelledby="panel-ebu-recommendation-heading">
        <p>
            <h2 id="panel-ebu-recommendation-heading">Read Next</h2>
        </p>
        
    </div>
    

    
        
            
        
    

    
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Behind the Scenes of Bun Install (334 pts)]]></title>
            <link>https://bun.com/blog/behind-the-scenes-of-bun-install</link>
            <guid>45210850</guid>
            <pubDate>Thu, 11 Sep 2025 12:39:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bun.com/blog/behind-the-scenes-of-bun-install">https://bun.com/blog/behind-the-scenes-of-bun-install</a>, See on <a href="https://news.ycombinator.com/item?id=45210850">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><p>Running <code>bun install</code> is fast, very fast. On average, it runs ~7× faster than npm, ~4× faster than pnpm, and ~17× faster than yarn. The difference is especially noticeable in large codebases. What used to take minutes now takes (milli)seconds.</p><p><img src="https://bun.com/images/blog/bun-install/Group1.svg" alt="Timeline showing shift from I/O wait to syscall overhead"></p><p>These aren't just cherry-picked benchmarks. Bun is fast because it <strong>treats package installation as a systems programming problem</strong>, not a JavaScript problem.</p><p>In this post we’ll explore what that means: from minimizing syscalls and caching manifests as binary, to optimizing tarball extraction, leveraging OS-native file copying, and scaling across CPU cores.</p><p>But to understand why this matters, we first have to take a small step back in time.</p><hr><p>It's the year 2009. You're installing jQuery from a <code>.zip</code> file, your iPhone 3GS has 256MB of RAM. GitHub was just a year old, SSDs cost $700 for 256GB. Your laptop's 5400RPM hard drive maxes out at 100MB/s, and "broadband" means 10 Mbps (if you're lucky).</p><p>But more importantly: Node.js just launched! <a href="https://www.youtube.com/watch?v=EeYvFl7li9E">Ryan Dahl is on stage</a> explaining why servers spend most of their time waiting.</p><p>In 2009, a typical disk seek takes 10ms, a database query 50–200ms, and an HTTP request to an external API 300ms+. During each of these transactions, traditional servers would just... wait. Your server would start reading a file, and then just freeze for 10ms.</p><p><img src="https://bun.com/images/blog/bun-install/image26.png" alt="2009 server waiting on I/O illustration"></p><p>Now multiply that by thousands of concurrent connections each doing multiple I/O operations. Servers spent ~95% of their time waiting for I/O operations.</p><hr><p>Node.js figured that JavaScript's event loop (originally designed for browser events) was perfect for server I/O. When code makes an async request, the I/O happens in the background while the main thread immediately moves to the next task. Once complete, a callback gets queued for execution.</p><div><figure> <img src="https://bun.com/images/blog/bun-install/image27.png" alt="Node.js event loop and thread pool flow for fs.readFile"> <figcaption>Simplified illustration of how Node.js handles fs.readFile with the event loop and thread pool. Other async sources and implementation details are omitted for clarity.</figcaption> </figure></div><p>JavaScript's event loop was a great solution for a world where waiting for data was the primary bottleneck.</p><p>For the next 15 years, Node's architecture shaped how we built tools. Package managers inherited Node's thread pool, event loop, async patterns; optimizations that made sense when disk seeks took 10ms.</p><p>But hardware evolved. It's not 2009 anymore, we're 16 years into the future, as hard as that is to believe. The M4 Max MacBook I'm using to write this would've ranked among the 50 fastest supercomputers on Earth in 2009. Today's NVMe drives push 7,000 MB/s, 70× faster than what Node.js was designed for! The slow mechanical drives are gone, internet speeds stream 4K video, and even low-end smartphones have more RAM than high-end servers had in 2009.</p><p>Yet today's package managers still optimize for the last decade's problems. In 2025, the real bottleneck isn't I/O anymore. <strong>It's system calls</strong>.</p><h2 level="2" anchor-id="the-problem-with-system-calls" id="the-problem-with-system-calls"><a name="the-problem-with-system-calls"></a><a href="#the-problem-with-system-calls">The Problem with System Calls</a></h2><p>Every time your program wants the operating system to do something (read a file, open a network connection, allocate memory), it makes a system call. Each time you make a system call, the CPU has to perform a <em>mode switch</em>.</p><div><p>Your CPU can run programs in two modes:</p><ul><li><strong><code>user mode</code>,</strong> where your application code runs. Programs in <code>user mode</code> cannot directly access your device's hardware, physical memory addresses, etc. This isolation prevents programs from interfering with each other or crashing the system.</li><li><strong><code>kernel mode</code>,</strong> where the operating system's kernel runs. The kernel is the core component of the OS that manages resources like scheduling processes to use the CPU, handling memory, and hardware like disks or network devices. Only the kernel and device drivers operate in <code>kernel mode</code>!</li></ul></div><p>When you want to open a file, (e.g. <code>fs.readFile()</code>) in your program, the CPU running in <code>user mode</code> cannot directly read from disk. It first has to switch to <code>kernel mode</code>.</p><p>During this mode switch, the CPU stops executing your program → saves all its state → switches into kernel mode → performs the operation → then switches back to user mode.</p><p><img src="https://bun.com/images/blog/bun-install/image7.png" alt="CPU mode switches between user and kernel mode"></p><p>However, this mode switching is expensive! Just this switch alone costs 1000-1500 CPU cycles in pure overhead, before any actual work happens.</p><p>Your CPU operates on a clock that ticks billions of times per second. A 3GHz processor completes 3 billion cycles per second. During each cycle the CPU can execute instructions: add numbers, move data, make comparisons, etc. Each cycle takes 0.33ns.</p><p>On a 3GHz processor, 1000-1500 cycles is about 500 nanoseconds. This might sound negligibly fast, but modern SSDs can handle over 1 million operations per second. If each operation requires a system call, you're burning 1.5 billion cycles per second just on mode switching.</p><p>Package installation makes thousands of these system calls. Installing React and its dependencies might trigger 50,000+ system calls: that's seconds of CPU time lost to mode switching alone! Not even reading files or installing packages, just switching between user and kernel mode.</p><hr><p>This is why Bun treats package installation as a <strong>systems programming problem</strong>. Fast install speeds come from <strong>minimizing system calls</strong> and <strong>leveraging every OS-specific optimization available</strong>.</p><p>You can see the difference when we trace the actual system calls made by each package manager:</p><div id="qthcqNQYBqZS:0"><pre><code><span><span>Benchmark </span><span>1</span><span>: strace </span><span>-</span><span>c </span><span>-</span><span>f npm install</span></span>
<span><span>    </span><span>Time</span><span> (mean ± σ):  </span><span>37.245</span><span> s ±  </span><span>2.134</span><span> s [User: </span><span>8.432</span><span> s, System: </span><span>4.821</span><span> s]</span></span>
<span><span>    </span><span>Range</span><span> (min … max):   </span><span>34.891</span><span> s … </span><span>41.203</span><span> s    </span><span>10</span><span> runs</span></span>
<span></span>
<span><span>    System calls: </span><span>996</span><span>,</span><span>978</span><span> </span><span>total</span><span> (</span><span>108</span><span>,</span><span>775</span><span> errors)</span></span>
<span><span>    Top syscalls: </span><span>futex</span><span> (</span><span>663</span><span>,</span><span>158</span><span>),  </span><span>write</span><span> (</span><span>109</span><span>,</span><span>412</span><span>), </span><span>epoll_pwait</span><span> (</span><span>54</span><span>,</span><span>496</span><span>)</span></span>
<span></span>
<span><span>  Benchmark </span><span>2</span><span>: strace </span><span>-</span><span>c </span><span>-</span><span>f bun install</span></span>
<span><span>    </span><span>Time</span><span> (mean ± σ):      </span><span>5.612</span><span> s ±  </span><span>0.287</span><span> s [User: </span><span>2.134</span><span> s, System: </span><span>1.892</span><span> s]</span></span>
<span><span>    </span><span>Range</span><span> (min … max):    </span><span>5.238</span><span> s …  </span><span>6.102</span><span> s    </span><span>10</span><span> runs</span></span>
<span></span>
<span><span>    System calls: </span><span>165</span><span>,</span><span>743</span><span> </span><span>total</span><span> (</span><span>3</span><span>,</span><span>131</span><span> errors)</span></span>
<span><span>    Top syscalls: </span><span>openat</span><span>(</span><span>45</span><span>,</span><span>348</span><span>), </span><span>futex</span><span> (</span><span>762</span><span>), </span><span>epoll_pwait2</span><span> (</span><span>298</span><span>)</span></span>
<span></span>
<span><span>  Benchmark </span><span>3</span><span>: strace </span><span>-</span><span>c </span><span>-</span><span>f yarn install</span></span>
<span><span>    </span><span>Time</span><span> (mean ± σ):     </span><span>94.156</span><span> s ±  </span><span>3.821</span><span> s    [User: </span><span>12.734</span><span> s, System: </span><span>7.234</span><span> s]</span></span>
<span><span>    </span><span>Range</span><span> (min … max):   </span><span>89.432</span><span> s … </span><span>98.912</span><span> s    </span><span>10</span><span> runs</span></span>
<span></span>
<span><span>    System calls: </span><span>4</span><span>,</span><span>046</span><span>,</span><span>507</span><span> </span><span>total</span><span> (</span><span>420</span><span>,</span><span>131</span><span> errors)</span></span>
<span><span>    Top syscalls: </span><span>futex</span><span> (</span><span>2</span><span>,</span><span>499</span><span>,</span><span>660</span><span>), </span><span>epoll_pwait</span><span> (</span><span>326</span><span>,</span><span>351</span><span>), </span><span>write</span><span> (</span><span>287</span><span>,</span><span>543</span><span>)</span></span>
<span></span>
<span><span>  Benchmark </span><span>4</span><span>: strace </span><span>-</span><span>c </span><span>-</span><span>f pnpm install</span></span>
<span><span>    </span><span>Time</span><span> (mean ± σ):     </span><span>24.521</span><span> s ±  </span><span>1.287</span><span> s    [User: </span><span>5.821</span><span> s, System: </span><span>3.912</span><span> s]</span></span>
<span><span>    </span><span>Range</span><span> (min … max):   </span><span>22.834</span><span> s … </span><span>26.743</span><span> s    </span><span>10</span><span> runs</span></span>
<span></span>
<span><span>    System calls: </span><span>456</span><span>,</span><span>930</span><span> </span><span>total</span><span> (</span><span>32</span><span>,</span><span>351</span><span> errors)</span></span>
<span><span>    Top syscalls: </span><span>futex</span><span> (</span><span>116</span><span>,</span><span>577</span><span>), </span><span>openat</span><span>(</span><span>89</span><span>,</span><span>234</span><span>), </span><span>epoll_pwait</span><span> (</span><span>12</span><span>,</span><span>705</span><span>)</span></span>
<span></span>
<span><span>  Summary</span></span>
<span><span>    </span><span>'</span><span>strace -c -f bun install</span><span>'</span><span> ran</span></span>
<span><span>      </span><span>4.37</span><span> ± </span><span>0.28</span><span> times faster than </span><span>'</span><span>strace -c -f pnpm install</span><span>'</span></span>
<span><span>      </span><span>6.64</span><span> ± </span><span>0.51</span><span> times faster than </span><span>'</span><span>strace -c -f npm install</span><span>'</span></span>
<span><span>     </span><span>16.78</span><span> ± </span><span>1.12</span><span> times faster than </span><span>'</span><span>strace -c -f yarn install</span><span>'</span></span>
<span></span>
<span><span>  System Call Efficiency:</span></span>
<span><span>    </span><span>-</span><span> bun:  </span><span>165</span><span>,</span><span>743</span><span> </span><span>syscalls</span><span> (29.5k syscalls</span><span>/</span><span>s)</span></span>
<span><span>    </span><span>-</span><span> pnpm: </span><span>456</span><span>,</span><span>930</span><span> </span><span>syscalls</span><span> (18.6k syscalls</span><span>/</span><span>s)</span></span>
<span><span>    </span><span>-</span><span> npm:  </span><span>996</span><span>,</span><span>978</span><span> </span><span>syscalls</span><span> (26.8k syscalls</span><span>/</span><span>s)</span></span>
<span><span>    </span><span>-</span><span> yarn: </span><span>4</span><span>,</span><span>046</span><span>,</span><span>507</span><span> </span><span>syscalls</span><span> (43.0k syscalls</span><span>/</span><span>s)</span></span>
<span></span></code></pre></div><p>We can see that Bun installs much faster, but it also makes far fewer system calls. For a simple install, yarn makes over 4 million system calls, npm almost 1 million, pnpm close to 500k, and bun 165k.</p><p>At 1000-1500 cycles per call, yarn's 4 million system calls means it's spending billions of CPU cycles just on mode switching. On a 3GHz processor, that's seconds of pure overhead!</p><p>And it's not just the <em>amount</em> of system calls. Look at those <code>futex</code> calls! Bun made 762 <code>futex</code> calls (only 0.46% of total system calls), whereas npm made 663,158 (66.51%), yarn made 2,499,660 (61.76%), and pnpm made 116,577 (25.51%).</p><div><p><code>futex</code> (fast userspace mutex) is a Linux system call used for thread synchronization. Threads are smaller units of a program that run simultaneously that often share access to memory or resources, so they must coordinate to avoid conflicts.</p><p>Most of the time, threads coordinate using fast atomic CPU instructions in <code>user mode</code>. There's no need to switch to <code>kernel mode</code>, so it's very efficient!</p><p>But if a thread tries to acquire a lock that's already taken, it makes a <code>futex</code> syscall to ask the kernel to put it to sleep until the lock becomes available. A high number of <code>futex</code> calls is an indicator that many threads are waiting on one another, causing delays.</p></div><p>So what's Bun doing differently here?</p><h2 level="2" anchor-id="eliminating-javascript-overhead" id="eliminating-javascript-overhead"><a name="eliminating-javascript-overhead"></a><a href="#eliminating-javascript-overhead">Eliminating JavaScript overhead</a></h2><p>npm, pnpm and yarn are all written in Node.js. In Node.js, system calls aren’t made directly: when you call <code>fs.readFile()</code>, you’re actually going through several layers before reaching the OS.</p><p>Node.js uses <a href="https://libuv.org/">libuv</a>, a C library that abstracts platform differences and manages async I/O through a thread pool.</p><p>The result is that when Node.js has to read a single file, it triggers a pretty complex pipeline. For a simple <code>fs.readFile('package.json', ...)</code>:</p><ol><li>JavaScript validates arguments and converts strings from UTF-16 to UTF-8 for libuv's C APIs. This briefly blocks the main thread before any I/O even starts.</li><li>libuv queues the request for one of 4 worker threads. If all threads are busy, your request waits.</li><li>A worker thread picks up the request, opens the file descriptor, and makes the actual <code>read()</code> system call.</li><li>The kernel switches to <code>kernel mode</code>, fetches the data from disk, and returns it to the worker thread.</li><li>The worker pushes the file data back to the main thread through the event loop, which eventually schedules and runs your callback.</li></ol><p>Every single <code>fs.readFile()</code> call goes through this pipeline. Package installation involves reading <em>thousands</em> of <code>package.json</code> files: scanning directories, processing dependency metadata, and so on. Each time threads coordinate (e.g., when accessing the task queue or signaling back to the event loop), a <code>futex</code> system call can be used to manage locks or waits.</p><p><strong>The overhead of making thousands of these system calls can take longer than the actual data movement itself!</strong></p><hr><p>Bun does it differently. <strong>Bun is written in Zig</strong>, a programming language that compiles to native code with direct system call access:</p><div id="mBXurddsRVZj:0"><pre><code><span><span>// Direct system call, no JavaScript overhead</span></span>
<span><span>var file </span><span>=</span><span> bun</span><span>.</span><span>sys</span><span>.</span><span>File</span><span>.</span><span>from</span><span>(</span><span>try</span><span> bun</span><span>.</span><span>sys</span><span>.</span><span>openatA</span><span>(</span></span>
<span><span>    bun</span><span>.</span><span>FD</span><span>.</span><span>cwd</span><span>(),</span></span>
<span><span>    abs,</span></span>
<span><span>    bun</span><span>.</span><span>O</span><span>.</span><span>RDONLY</span><span>,</span></span>
<span><span>    </span><span>0</span><span>,</span></span>
<span><span>)</span><span>.</span><span>unwrap</span><span>());</span></span>
<span></span></code></pre></div><p>When Bun reads a file:</p><ol><li>Zig code directly invokes the system call (e.g., <code>openat()</code> )</li><li>The kernel immediately executes the system call and returns data</li></ol><p>That's it. There's no JavaScript engine, thread pools, event loops or marshaling between different runtime layers. Just native code making direct system calls to the kernel.</p><p>The performance difference speaks for itself:</p><div><table><thead><tr><th>Runtime</th><th>Version</th><th>Files/Second</th><th>Performance</th></tr></thead><tbody><tr><td><strong>Bun</strong></td><td>v1.2.20</td><td><strong>146,057</strong></td><td></td></tr><tr><td>Node.js</td><td>v24.5.0</td><td>66,576</td><td>2.2x slower</td></tr><tr><td>Node.js</td><td>v22.18.0</td><td>64,631</td><td>2.3x slower</td></tr></tbody></table></div><p>In this benchmark, Bun processes 146,057 <code>package.json</code> files per second, while Node.js v24.5.0 manages 66,576 and v22.18.0 handles 64,631. That's over 2x faster!</p><p>Bun's 0.019ms per file represents the actual I/O cost, so how long it takes to read data when you make direct system calls without any runtime overhead. Node.js takes 0.065ms for the same operation. Package managers written in Node.js are "stuck" with Node's abstractions; they use the thread pool whether they need it or not. But they pay this cost on every file operation.</p><p>Bun's package manager is more like a native application that happens to understand JavaScript packages, not a JavaScript application trying to do systems programming.</p><p>Even though Bun isn't written in Node.js, you can use <code>bun install</code> in any Node.js project without switching runtimes. Bun's package manager respects your existing Node.js setup and tooling, you just get faster installs!</p><hr><p>But at this point we haven't even started installing packages yet. Let's see the optimizations Bun applies to the actual installation.</p><p>When you type <code>bun install</code>, Bun first figures out what you're asking it to do. It reads any flags you've passed, and finds your <code>package.json</code> to read your dependencies.</p><h2 level="2" anchor-id="async-dns-resolution" id="async-dns-resolution"><a name="async-dns-resolution"></a><a href="#async-dns-resolution">Async DNS Resolution</a></h2><p>⚠️ Note: This optimization is specific to macOS</p><p>Working with dependencies means working with network requests, and network requests require DNS resolution to convert domain names like <code>registry.npmjs.org</code> into IP addresses.</p><p>As Bun is parsing the <code>package.json</code>, it already starts to prefetch the DNS lookups. This means network resolution begins even before dependency analysis is even complete.</p><p>For a Node.js-based package managers, one way to do it is by using <code>dns.lookup()</code>. While this looks async from JavaScript's perspective, it's actually implemented as a <em>blocking</em> <code>getaddrinfo()</code> call under the hood, running on <code>libuv</code>'s thread pool. It still blocks a thread, just not the main thread.</p><p>As a nice optimization, Bun takes a different approach on macOS by making it truly asynchronous at the system level. Bun uses Apple's "hidden" async DNS API (<code>getaddrinfo_async_start()</code>), which isn't part of the POSIX standard, but it allows bun to make DNS requests that run completely asynchronously using <a href="https://docs.darlinghq.org/internals/macos-specifics/mach-ports.html">mach ports</a>, Apple's inter-process communication system.</p><p>While DNS resolution happens in the background, Bun can continue processing other operations like file I/O, network requests, or dependency resolution without any thread blocking. By the time it needs to download React, the DNS lookup is already done.</p><p>It's a small optimization (and not benchmarked), but it shows Bun's attention to detail: optimize at every layer!</p><h2 level="2" anchor-id="binary-manifest-caching" id="binary-manifest-caching"><a name="binary-manifest-caching"></a><a href="#binary-manifest-caching">Binary Manifest Caching</a></h2><p>Now that Bun has established a connection to the npm registry, it needs the package manifests.</p><p>A manifest is a JSON file containing all versions, dependencies, and metadata for each package. For popular packages like React with 100+ versions, these manifests can be several megabytes!</p><p>A typical manifest can look something like this:</p><div id="jeplpbAMoynd:0"><pre><code><span><span>{</span></span>
<span><span>  </span><span>"</span><span>name</span><span>"</span><span>:</span><span> </span><span>"</span><span>lodash</span><span>"</span><span>,</span></span>
<span><span>  </span><span>"</span><span>versions</span><span>"</span><span>:</span><span> {</span></span>
<span><span>    </span><span>"</span><span>4.17.20</span><span>"</span><span>:</span><span> {</span></span>
<span><span>      </span><span>"</span><span>name</span><span>"</span><span>:</span><span> </span><span>"</span><span>lodash</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>version</span><span>"</span><span>:</span><span> </span><span>"</span><span>4.17.20</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>description</span><span>"</span><span>:</span><span> </span><span>"</span><span>Lodash modular utilities.</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>license</span><span>"</span><span>:</span><span> </span><span>"</span><span>MIT</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>repository</span><span>"</span><span>:</span><span> {</span></span>
<span><span>        </span><span>"</span><span>type</span><span>"</span><span>:</span><span> </span><span>"</span><span>git</span><span>"</span><span>,</span></span>
<span><span>        </span><span>"</span><span>url</span><span>"</span><span>:</span><span> </span><span>"</span><span>git+https://github.com/lodash/lodash.git</span><span>"</span></span>
<span><span>      },</span></span>
<span><span>      </span><span>"</span><span>homepage</span><span>"</span><span>:</span><span> </span><span>"</span><span>https://lodash.com/</span><span>"</span></span>
<span><span>    },</span></span>
<span><span>    </span><span>"</span><span>4.17.21</span><span>"</span><span>:</span><span> {</span></span>
<span><span>      </span><span>"</span><span>name</span><span>"</span><span>:</span><span> </span><span>"</span><span>lodash</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>version</span><span>"</span><span>:</span><span> </span><span>"</span><span>4.17.21</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>description</span><span>"</span><span>:</span><span> </span><span>"</span><span>Lodash modular utilities.</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>license</span><span>"</span><span>:</span><span> </span><span>"</span><span>MIT</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>repository</span><span>"</span><span>:</span><span> {</span></span>
<span><span>        </span><span>"</span><span>type</span><span>"</span><span>:</span><span> </span><span>"</span><span>git</span><span>"</span><span>,</span></span>
<span><span>        </span><span>"</span><span>url</span><span>"</span><span>:</span><span> </span><span>"</span><span>git+https://github.com/lodash/lodash.git</span><span>"</span></span>
<span><span>      },</span></span>
<span><span>      </span><span>"</span><span>homepage</span><span>"</span><span>:</span><span> </span><span>"</span><span>https://lodash.com/</span><span>"</span></span>
<span><span>    }</span></span>
<span><span>    </span><span>// ... 100+ more versions, nearly identical</span></span>
<span><span>  }</span></span>
<span><span>}</span></span>
<span></span></code></pre></div><p>Most package managers cache these manifests as JSON files in their cache directories. When you run <code>npm install</code> again, instead of downloading the manifest, they read it from the cache.</p><p>That all makes sense, but the issue is that on every install (even if it's cached), they still need to parse the JSON file. This includes validating the syntax, building the object tree, managing garbage collection, and so on. A lot of parsing overhead.</p><p>And it's not just the JSON parsing overhead. Looking at lodash: the string <code>"Lodash modular utilities."</code> appears in every single version—that's 100+ times. <code>"MIT"</code> appears 100+ times. <code>"git+https://github.com/lodash/lodash.git"</code> is duplicated for every version, the URL <code>"https://lodash.com/"</code> appears in every version. Overall, lots of repeated strings.</p><p>In memory, JavaScript creates a separate string object for each string. This wastes memory and makes comparisons slower. Every time the package manager checks if two packages use the same version of postcss, it's comparing separate string objects rather than pointing to the same interned string.</p><hr><p><strong>Bun stores package manifests in a binary format.</strong> When Bun downloads package information, it parses the JSON once and stores it as binary files (<code>.npm</code> files in <code>~/.bun/install/cache/</code>). These binary files contain all the package information (versions, dependencies, checksums, etc.) stored at specific byte offsets.</p><p>When Bun accesses the name <code>lodash</code>, it's just pointer arithmetic: <code>string_buffer + offset</code>. No allocations, no parsing, no object traversal, just reading bytes at a known location.</p><div id="knaNbRJFZqnT:0"><pre><code><span><span>// Pseudocode</span></span>
<span></span>
<span><span>// String buffer (all strings stored once)</span></span>
<span><span>string_buffer </span><span>=</span><span> </span><span>"</span><span>lodash</span><span>\0</span><span>MIT</span><span>\0</span><span>Lodash modular utilities.</span><span>\0</span><span>git+https://github.com/lodash/lodash.git</span><span>\0</span><span>https://lodash.com/</span><span>\04</span><span>.17.20</span><span>\04</span><span>.17.21</span><span>\0</span><span>...</span><span>"</span></span>
<span><span>                 </span><span>^</span><span>0</span><span>     </span><span>^</span><span>7</span><span>   </span><span>^</span><span>11</span><span>                        </span><span>^</span><span>37</span><span>                                      </span><span>^</span><span>79</span><span>                   </span><span>^</span><span>99</span><span>      </span><span>^</span><span>107</span></span>
<span></span>
<span><span>// Version entries (fixed-size structs)</span></span>
<span><span>versions </span><span>=</span><span> [</span></span>
<span><span>  { name_offset</span><span>:</span><span> </span><span>0</span><span>, name_len</span><span>:</span><span> </span><span>6</span><span>, version_offset</span><span>:</span><span> </span><span>99</span><span>, version_len</span><span>:</span><span> </span><span>7</span><span>, desc_offset</span><span>:</span><span> </span><span>11</span><span>, desc_len</span><span>:</span><span> </span><span>26</span><span>, license_offset</span><span>:</span><span> </span><span>7</span><span>, license_len</span><span>:</span><span> </span><span>3</span><span>, </span><span>...</span><span> },  </span><span>// 4.17.20</span></span>
<span><span>  { name_offset</span><span>:</span><span> </span><span>0</span><span>, name_len</span><span>:</span><span> </span><span>6</span><span>, version_offset</span><span>:</span><span> </span><span>107</span><span>, version_len</span><span>:</span><span> </span><span>7</span><span>, desc_offset</span><span>:</span><span> </span><span>11</span><span>, desc_len</span><span>:</span><span> </span><span>26</span><span>, license_offset</span><span>:</span><span> </span><span>7</span><span>, license_len</span><span>:</span><span> </span><span>3</span><span>, </span><span>...</span><span> }, </span><span>// 4.17.21</span></span>
<span><span>  </span><span>// ... 100+ more version structs</span></span>
<span><span>]</span></span>
<span></span></code></pre></div><p>To check if packages need updating, Bun stores the responses's <code>ETag</code> , and sends <code>If-None-Match</code> headers. When npm responds with <code>"304 Not Modified"</code>, Bun knows the cached data is fresh without parsing a single byte.</p><p>Looking at the benchmarks:</p><div id="hWXiLVHmjgbV:0"><pre><code><span><span>Benchmark </span><span>1</span><span>: bun install # fresh install</span></span>
<span><span>  </span><span>Time</span><span> (mean ± σ):      </span><span>35.7</span><span> ms ±  </span><span>86.6</span><span> ms    [User: </span><span>8.4</span><span> ms, System: </span><span>13.4</span><span> ms]</span></span>
<span><span>  </span><span>Range</span><span> (min … max):     </span><span>4.1</span><span> ms … </span><span>280.5</span><span> ms    </span><span>10</span><span> runs</span></span>
<span></span>
<span><span>Benchmark </span><span>2</span><span>: bun install # cached</span></span>
<span><span>  </span><span>Time</span><span> (mean ± σ):       </span><span>4.8</span><span> ms ±   </span><span>0.7</span><span> ms    [User: </span><span>4.7</span><span> ms, System: </span><span>3.9</span><span> ms]</span></span>
<span><span>  </span><span>Range</span><span> (min … max):     </span><span>3.7</span><span> ms …   </span><span>6.2</span><span> ms    </span><span>482</span><span> runs</span></span>
<span></span>
<span><span>Benchmark </span><span>3</span><span>: npm install # fresh install</span></span>
<span><span>  </span><span>Time</span><span> (mean ± σ):     </span><span>815.1</span><span> ms ± </span><span>976.9</span><span> ms    [User: </span><span>730.1</span><span> ms, System: </span><span>130.4</span><span> ms]</span></span>
<span><span>  </span><span>Range</span><span> (min … max):   </span><span>478.8</span><span> ms … </span><span>3595.1</span><span> ms    </span><span>10</span><span> runs</span></span>
<span></span>
<span><span>Summary</span></span>
<span><span>  bun install # cached ran</span></span>
<span><span>    </span><span>1.02</span><span> ± </span><span>0.02</span><span> times faster than bun install # fresh, no cache</span></span>
<span><span>    </span><span>3.73</span><span> ± </span><span>0.12</span><span> times faster than npm install # cached</span></span>
<span></span></code></pre></div><p>Here you can see that a cached(!!) <code>npm install</code> is <em>slower</em> than a <em>fresh</em> Bun install. That's how much overhead JSON parsing the cached files can add (among other factors).</p><p>Now that&nbsp;Bun has fetched the&nbsp;package <em>manifests</em>, it needs&nbsp;to download and extract compressed <em>tarballs</em> from&nbsp;the npm registry.</p><p>Tarballs are compressed archive files (like <code>.zip</code> files) that contain all the actual source code and files for each package.</p><p>Most package managers stream the tarball data as it arrives, and decompress as it streams in. When you extract a tarball that's streaming in, the typical pattern assumes the size is unknown, and looks something like this:</p><div id="mIFyCFVMIqCB:0"><pre><code><span><span>let</span><span> buffer </span><span>=</span><span> Buffer.</span><span>alloc</span><span>(</span><span>64</span><span> </span><span>*</span><span> </span><span>1024</span><span>); </span><span>// Start with 64KB</span></span>
<span><span>let</span><span> offset </span><span>=</span><span> </span><span>0</span><span>;</span></span>
<span></span>
<span><span>function</span><span> </span><span>onData</span><span>(</span><span>chunk</span><span>) {</span></span>
<span><span>  </span><span>while</span><span> (moreDataToCome) {</span></span>
<span><span>    </span><span>if</span><span> (offset </span><span>+</span><span> chunk.length </span><span>&gt;</span><span> buffer.length) {</span></span>
<span><span>      </span><span>// buffer full → allocate bigger one</span></span>
<span><span>      </span><span>const</span><span> newBuffer </span><span>=</span><span> Buffer.</span><span>alloc</span><span>(buffer.length </span><span>*</span><span> </span><span>2</span><span>);</span></span>
<span></span>
<span><span>      </span><span>// copy everything we’ve already written</span></span>
<span><span>      buffer.</span><span>copy</span><span>(newBuffer, </span><span>0</span><span>, </span><span>0</span><span>, offset);</span></span>
<span></span>
<span><span>      buffer </span><span>=</span><span> newBuffer;</span></span>
<span><span>    }</span></span>
<span></span>
<span><span>    </span><span>// copy new chunk into buffer</span></span>
<span><span>    chunk.</span><span>copy</span><span>(buffer, offset);</span></span>
<span><span>    offset </span><span>+=</span><span> chunk.length;</span></span>
<span><span>  }</span></span>
<span></span>
<span><span>  </span><span>// ... decompress from buffer ...</span></span>
<span><span>}</span></span>
<span></span></code></pre></div><p>Start with a small buffer, and let it grow as more decompressed data arrives. When the buffer fills up, you allocate a larger buffer, copy all the existing data over, and continue.</p><p>This seems reasonable, but it creates a performance bottleneck: you end up copying the same data multiple times as the buffer repeatedly outgrows its current size.</p><p><img src="https://bun.com/images/blog/bun-install/image5.png" alt="Repeated buffer resizing and copying during streaming decompression"></p><p>When we have a 1MB package:</p><ol><li>Start with 64KB buffer</li><li>Fill up → Allocate 128KB → Copy 64KB over</li><li>Fill up → Allocate 256KB → Copy 128KB over</li><li>Fill up → Allocate 512KB → Copy 256KB over</li><li>Fill up → Allocate 1MB → Copy 512KB over</li></ol><p>You just copied 960KB of data unnecessarily! And this happens for every single package. The memory allocator has to find contiguous space for each new buffer, while the old buffer stays allocated during the copy operation. For large packages, you might copy the same bytes 5-6 times.</p><hr><p>Bun takes a different approach by <strong>buffering the entire tarball before decompressing</strong>. Instead of processing data as it arrives, Bun waits until the entire compressed file is downloaded into memory.</p><div><p>Now you might think <em>"Wait, aren't they just wasting RAM keeping everything in memory?"</em> And for large packages like TypeScript (which can be 50MB compressed), you'd have a point.</p><p>But the vast majority of npm packages are tiny, most are under 1MB. For these common cases, buffering the whole thing eliminates all the repeated copying. Even for those larger packages, the temporary memory spike is usually fine on modern systems, and avoiding 5-6 buffer copies more than makes up for it.</p></div><p>Once Bun has the complete tarball in memory, it can read the last 4 bytes of the gzip format. These bytes are special since store the uncompressed size of the file! Instead of having to guess how large the uncompressed file will be, <strong>Bun can pre-allocate memory to eliminate buffer resizing entirely:</strong></p><div id="cmtiVBQtcEmQ:0"><pre><code><span><span>{</span></span>
<span><span>  // Last 4 bytes of a gzip-compressed file are the uncompressed size.</span></span>
<span><span>  </span><span>if</span><span> (tgz_bytes</span><span>.</span><span>len </span><span>&gt;</span><span> </span><span>16</span><span>) {</span></span>
<span><span>    // If the file claims to be larger than 16 bytes and smaller than 64 MB, we'll preallocate the buffer.</span></span>
<span><span>    // If it's larger than that, we'll do it incrementally. We want to avoid OOMing.</span></span>
<span><span>    </span><span>const</span><span> last_4_bytes</span><span>:</span><span> </span><span>u32</span><span> </span><span>=</span><span> </span><span>@</span><span>bitCast</span><span>(tgz_bytes[tgz_bytes</span><span>.</span><span>len </span><span>-</span><span> </span><span>4</span><span> </span><span>..</span><span>][</span><span>0</span><span>..</span><span>4</span><span>]</span><span>.*</span><span>);</span></span>
<span><span>    </span><span>if</span><span> (last_4_bytes </span><span>&gt;</span><span> </span><span>16</span><span> and last_4_bytes </span><span>&lt;</span><span> </span><span>64</span><span> </span><span>*</span><span> </span><span>1024</span><span> </span><span>*</span><span> </span><span>1024</span><span>) {</span></span>
<span><span>      // It's okay if this fails. We will just allocate as we go and that will error if we run out of memory.</span></span>
<span><span>      esimated_output_size </span><span>=</span><span> last_4_bytes;</span></span>
<span><span>      </span><span>if</span><span> (zlib_pool</span><span>.</span><span>data</span><span>.</span><span>list</span><span>.</span><span>capacity </span><span>==</span><span> </span><span>0</span><span>) {</span></span>
<span><span>          zlib_pool</span><span>.</span><span>data</span><span>.</span><span>list</span><span>.</span><span>ensureTotalCapacityPrecise</span><span>(zlib_pool</span><span>.</span><span>data</span><span>.</span><span>allocator, last_4_bytes) catch {};</span></span>
<span><span>      } </span><span>else</span><span> {</span></span>
<span><span>          zlib_pool</span><span>.</span><span>data</span><span>.</span><span>ensureUnusedCapacity</span><span>(last_4_bytes) catch {};</span></span>
<span><span>      }</span></span>
<span><span>    }</span></span>
<span><span>  }</span></span>
<span><span>}</span></span>
<span></span></code></pre></div><p>Those 4 bytes tell Bun "this gzip will decompress to exactly 1,048,576 bytes", so it can pre-allocate exactly this amount of memory upfront. There's no repeated resizing or copying of data; just one memory allocation.</p><p><img src="https://bun.com/images/blog/bun-install/image6.png" alt="Preallocation using gzip ISIZE avoids buffer growth copies"></p><p>To do the actual decompression, Bun uses <a href="https://safeteewow.github.io/LibDeflate/topics/README.md.html"><code>libdeflate</code></a>. This is a high-performance lib that decompresses tarballs faster than the standard <a href="https://zlib.net/manual.html"><code>zlib</code></a> used by most package managers. It's optimized specifically for modern CPUs with SIMD instructions.</p><div><p>Optimized tarball extraction would've been difficult to for package managers written in Node.js. You'd need to create a separate read stream, seek to the end, read 4 bytes, parse them, close the stream, then start over with your decompression. Node's APIs aren't designed for this pattern.</p><p>In Zig it's pretty straight-forward: you just seek to the end and read the last four bytes, that's it!</p></div><p>Now that Bun has all the package data, it faces another challenge: how do you efficiently store and access thousands of (interdependent) packages?</p><h2 level="2" anchor-id="cache-friendly-data-layout" id="cache-friendly-data-layout"><a name="cache-friendly-data-layout"></a><a href="#cache-friendly-data-layout">Cache-Friendly Data Layout</a></h2><p>Dealing with thousands of packages can be tricky. Each package has dependencies, which have their own dependencies, creating a pretty complex graph.</p><p>During installation, package managers have to traverse this graph to check the package versions, resolve any conflicts, and determine which version to install. They also need to "hoist" dependencies by moving them to higher levels so multiple packages can share them.</p><p>But the way that this dependency graph is stored has a big impact on performance. Traditional package managers store dependencies like this:</p><div id="CsDXBJOsnKeL:0"><pre><code><span><span>const</span><span> packages </span><span>=</span><span> {</span></span>
<span><span>  next</span><span>:</span><span> {</span></span>
<span><span>    name</span><span>:</span><span> </span><span>"</span><span>next</span><span>"</span><span>,</span></span>
<span><span>    version</span><span>:</span><span> </span><span>"</span><span>15.5.0</span><span>"</span><span>,</span></span>
<span><span>    dependencies</span><span>:</span><span> {</span></span>
<span><span>      </span><span>"</span><span>@swc/helpers</span><span>"</span><span>:</span><span> </span><span>"</span><span>0.5.15</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>postcss</span><span>"</span><span>:</span><span> </span><span>"</span><span>8.4.31</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>styled-jsx</span><span>"</span><span>:</span><span> </span><span>"</span><span>5.1.6</span><span>"</span><span>,</span></span>
<span><span>    },</span></span>
<span><span>  },</span></span>
<span><span>  postcss</span><span>:</span><span> {</span></span>
<span><span>    name</span><span>:</span><span> </span><span>"</span><span>postcss</span><span>"</span><span>,</span></span>
<span><span>    version</span><span>:</span><span> </span><span>"</span><span>8.4.31</span><span>"</span><span>,</span></span>
<span><span>    dependencies</span><span>:</span><span> {</span></span>
<span><span>      nanoid</span><span>:</span><span> </span><span>"</span><span>^3.3.6</span><span>"</span><span>,</span></span>
<span><span>      picocolors</span><span>:</span><span> </span><span>"</span><span>^1.0.0</span><span>"</span><span>,</span></span>
<span><span>    },</span></span>
<span><span>  },</span></span>
<span><span>};</span></span>
<span></span></code></pre></div><p>This looks clean as JavaScript code, but it's not ideal for modern CPU architectures.</p><p>In JavaScript, each object is stored on the heap. When accessing <code>packages["next"]</code>, the CPU accesses a pointer that tells it where Next's data is located in memory. This data then contains yet another pointer to where its dependencies live, which in turn contains more pointers to the actual dependency strings.</p><p><img src="https://bun.com/images/blog/bun-install/image24.png" alt="Pointer chasing through scattered JS objects in memory"></p><p>The key issue is how JavaScript allocates objects in memory. When you create objects at different times, the JavaScript engine uses whatever memory is available at that moment:</p><div id="lpRJiEWsVkSn:0"><pre><code><span><span>// These objects are created at different moments during parsing</span></span>
<span><span>packages[</span><span>"</span><span>react</span><span>"</span><span>] </span><span>=</span><span> { name</span><span>:</span><span> </span><span>"</span><span>react</span><span>"</span><span>, </span><span>...</span><span> }  	  </span><span>// Allocated at address 0x1000</span></span>
<span><span>packages[</span><span>"</span><span>next</span><span>"</span><span>] </span><span>=</span><span> { name</span><span>:</span><span> </span><span>"</span><span>next</span><span>"</span><span>, </span><span>...</span><span> }     		</span><span>// Allocated at address 0x2000</span></span>
<span><span>packages[</span><span>"</span><span>postcss</span><span>"</span><span>] </span><span>=</span><span> { name</span><span>:</span><span> </span><span>"</span><span>postcss</span><span>"</span><span>, </span><span>...</span><span> }  </span><span>// Allocated at address 0x8000</span></span>
<span><span>// ... hundreds more packages</span></span>
<span></span></code></pre></div><p>These addresses are basically just random. There is no locality guarantee - objects can just be scattered across RAM, even objects that are related to each other!</p><p>This random scattering matters because of how modern CPUs actually fetch data.</p><hr><p>Modern CPUs are incredibly fast at processing data (billions of operations per second), but fetching data from RAM is slow. To bridge this gap, CPUs have multiple cache levels:</p><ul><li>L1 cache, small storage, but extremely fast (~4 CPU cycles)</li><li>L2 cache, medium storage, a bit slower (~12 CPU cycles)</li><li>L3 cache: 8-32MB storage, requires ~40 CPU cycles</li><li>RAM: Lots of GB, requires ~300 cycles (slow!)</li></ul><p>The "issue" is that caches work with <em>cache lines</em>. When you access memory, the CPU doesn't just load that one byte: it loads the entire 64-byte chunk in which that byte appears. It figures that if you need one byte, you'll probably need nearby bytes soon (this is called spatial locality).</p><p><img src="https://bun.com/images/blog/bun-install/image12.png" alt="Cache line showing 64-byte fetch granularity"></p><p>This optimization works great for data that's stored sequentially, but it backfires when your data is scattered randomly across memory.</p><p>When the CPU loads <code>packages["next"]</code> at address <code>0x2000</code>, it actually loads all the bytes within that cache line. But the next package, <code>packages["postcss"]</code>, is at address <code>0x8000</code> . This is a completely different cache line! The other 56 bytes the CPU loaded in the cache line are just completely wasted, they're just random memory from whatever happened to be allocated nearby; maybe garbage, maybe parts of unrelated objects.</p><p><img src="https://bun.com/images/blog/bun-install/image11.png" alt="Wasted cache line bytes due to non-local allocations"></p><p>But you paid the cost of loading 64 bytes but only used 8...</p><p>By the time it's accessed 512 different packages (32KB / 64 bytes), you've filled your entire L1 cache already. Now every new package access evicts a previously loaded cache line to make space. The package you just accessed will be evicted soon, and that dependency it needs to check in 10 microseconds is already gone. Cache hit rate drops, and every access becomes a ~300 cycle trip to RAM instead of a 4 cycle L1 hit, far from optimal.</p><p>The nested structure of objects creates whats called "pointer chasing", a common anti-pattern in system programming. The CPU can't predict where to load next because each pointer could point anywhere. It simply cannot know where <code>next.dependencies</code> lives until it finishes loading the <code>next</code> object.</p><p>When traversing Next's dependencies, the CPU has to perform multiple dependent memory loads:</p><ol><li>Load <code>packages["next"]</code> pointer → Cache miss → RAM fetch (~300 cycles)</li><li>Follow that pointer to load <code>next.dependencies</code> pointer → Another cache miss → RAM fetch (~300 cycles)</li><li>Follow that to find <code>"postcss"</code> in the hash table → Cache miss → RAM fetch (~300 cycles)</li><li>Follow that pointer to load the actual string data → Cache miss → RAM fetch (~300 cycles)</li></ol><p>We can end up with many cache misses since we're working with hundreds of dependencies, all scattered across memory. Each cache line we load (64 bytes) might contain data for just one object. With all those objects spread across GBs of RAM, the working set easily exceeds the L1 cache (32KB), L2 (256KB) and even the L3 cache (8-32MB). By the time we need an object again, it's likely that it's been evicted from all cache levels.</p><p>That's ~1200 cycles (400ns on a 3GHz CPU) just to read one dependency name! For a project with 1000 packages averaging 5 dependencies each, that's 2ms of pure memory latency.</p><hr><p><strong>Bun uses Structure of Arrays</strong>. Instead of each package storing its own dependency array, Bun keeps all dependencies in one big shared array, all package names in another shared array, and so on:</p><div id="bNfNZMwcoWWa:0"><pre><code><span><span>// ❌ Traditional Array of Structures (AoS) - lots of pointers</span></span>
<span><span>packages </span><span>=</span><span> {</span></span>
<span><span>  next</span><span>:</span><span> { dependencies</span><span>:</span><span> { </span><span>"</span><span>@swc/helpers</span><span>"</span><span>:</span><span> </span><span>"</span><span>0.5.15</span><span>"</span><span>, </span><span>"</span><span>postcss</span><span>"</span><span>:</span><span> </span><span>"</span><span>8.4.31</span><span>"</span><span> } },</span></span>
<span><span>};</span></span>
<span></span>
<span><span>// ✅ Bun's Structure of Arrays (SoA) - cache friendly</span></span>
<span><span>packages </span><span>=</span><span> [</span></span>
<span><span>  {</span></span>
<span><span>    name</span><span>:</span><span> { off</span><span>:</span><span> </span><span>0</span><span>, len</span><span>:</span><span> </span><span>4</span><span> },</span></span>
<span><span>    version</span><span>:</span><span> { off</span><span>:</span><span> </span><span>5</span><span>, len</span><span>:</span><span> </span><span>6</span><span> },</span></span>
<span><span>    deps</span><span>:</span><span> { off</span><span>:</span><span> </span><span>0</span><span>, len</span><span>:</span><span> </span><span>2</span><span> },</span></span>
<span><span>  }, </span><span>// next</span></span>
<span><span>];</span></span>
<span></span>
<span><span>dependencies </span><span>=</span><span> [</span></span>
<span><span>  { name</span><span>:</span><span> { off</span><span>:</span><span> </span><span>12</span><span>, len</span><span>:</span><span> </span><span>13</span><span> }, version</span><span>:</span><span> { off</span><span>:</span><span> </span><span>26</span><span>, len</span><span>:</span><span> </span><span>7</span><span> } }, </span><span>// @swc/helpers@0.5.15</span></span>
<span><span>  { name</span><span>:</span><span> { off</span><span>:</span><span> </span><span>34</span><span>, len</span><span>:</span><span> </span><span>7</span><span> }, version</span><span>:</span><span> { off</span><span>:</span><span> </span><span>42</span><span>, len</span><span>:</span><span> </span><span>6</span><span> } }, </span><span>// postcss@8.4.31</span></span>
<span><span>];</span></span>
<span></span>
<span><span>string_buffer </span><span>=</span><span> </span><span>"</span><span>next</span><span>\015</span><span>.5.0</span><span>\0</span><span>@swc/helpers</span><span>\00</span><span>.5.15</span><span>\0</span><span>postcss</span><span>\0</span><span>8.4.31</span><span>\0</span><span>"</span><span>;</span></span>
<span></span></code></pre></div><p>Instead of each package storing <em>pointers</em> to its own data scattered across memory, Bun just uses <em>large contiguous buffers</em>, including:</p><ul><li><code>packages</code> stores lightweight structs that specify where to find this package's data using offsets</li><li><code>dependencies</code> stores the actual dependency relationships for all packages in one place</li><li><code>string_buffer</code> stores all text (names, versions, etc.) sequentially in one massive string</li><li><code>versions</code> stores all parsed semantic versions as compact structs</li></ul><p>Now, accessing Next's dependencies just becomes arithmetic:</p><ol><li><code>packages[0]</code> tells us that Next's dependencies start at position <code>0</code> in the <code>dependencies</code> array, and there's 2 dependencies: <code>{ name_offset: 0, deps_offset: 0, deps_count: 2 }</code></li><li>Go to <code>dependencies[1]</code> which tells us that postcss's name starts at position <code>34</code> in the string <code>string_buffer</code>, and version at position <code>42</code>: <code>{ name_offset: 34, version_offset: 42 }</code></li><li>Go to position 34 in <code>string_buffer</code> and read <code>postcss</code></li><li>Go to position 42 in <code>string_buffer</code> and read <code>"8.4.31"</code></li><li>… and so on</li></ol><p>Now when you access <code>packages[0]</code>, the CPU doesn't just load those 8 bytes: it loads an entire 64-byte cache line. Since each package is 8 bytes, and 64 ÷ 8 = 8, you get <code>packages[0]</code> through <code>packages[7]</code> in a single memory fetch.</p><p>So when your code processes the <code>react</code> dependency (<code>packages[0]</code>, <code>packages[1]</code> through <code>packages[7]</code> are already sitting in your L1 cache, ready to be accessed with zero additional memory fetches. That's why sequential access is so fast: you're getting 8 packages just by accessing memory once.</p><p>Instead of the many small, scattered allocations throughout memory that we saw in the previous example, we now have just ~6 large allocations in total, regardless of how many packages you have. This is completely different from the pointer-based approach, which required a separate memory fetch for each object.</p><h2 level="2" anchor-id="optimized-lockfile-format" id="optimized-lockfile-format"><a name="optimized-lockfile-format"></a><a href="#optimized-lockfile-format">Optimized Lockfile Format</a></h2><p>Bun also applies the Structure of Arrays approach to its <code>bun.lock</code> lockfile.</p><p>When you run <code>bun install</code>, Bun has to parse the existing lockfile to determine what's already installed and what needs updating. Most package managers store lockfiles as nested JSON (npm) or YAML (pnpm, yarn). When npm parses <code>package-lock.json</code>, it's processing deeply nested objects:</p><div id="lcbtijizAAkF:0"><pre><code><span><span>{</span></span>
<span><span>  </span><span>"</span><span>dependencies</span><span>"</span><span>: {</span></span>
<span><span>    </span><span>"</span><span>next</span><span>"</span><span>:</span><span> {</span></span>
<span><span>      </span><span>"</span><span>version</span><span>"</span><span>:</span><span> </span><span>"</span><span>15.5.0</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>requires</span><span>"</span><span>:</span><span> {</span></span>
<span><span>        </span><span>"</span><span>@swc/helpers</span><span>"</span><span>:</span><span> </span><span>"</span><span>0.5.15</span><span>"</span><span>,</span></span>
<span><span>        </span><span>"</span><span>postcss</span><span>"</span><span>:</span><span> </span><span>"</span><span>8.4.31</span><span>"</span></span>
<span><span>      }</span></span>
<span><span>    },</span></span>
<span><span>    </span><span>"</span><span>postcss</span><span>"</span><span>:</span><span> {</span></span>
<span><span>      </span><span>"</span><span>version</span><span>"</span><span>:</span><span> </span><span>"</span><span>8.4.31</span><span>"</span><span>,</span></span>
<span><span>      </span><span>"</span><span>requires</span><span>"</span><span>:</span><span> {</span></span>
<span><span>        </span><span>"</span><span>nanoid</span><span>"</span><span>:</span><span> </span><span>"</span><span>^3.3.6</span><span>"</span><span>,</span></span>
<span><span>        </span><span>"</span><span>picocolors</span><span>"</span><span>:</span><span> </span><span>"</span><span>^1.0.0</span><span>"</span></span>
<span><span>      }</span></span>
<span><span>    }</span></span>
<span><span>  }</span></span>
<span><span>}</span></span>
<span></span></code></pre></div><p>Each package becomes its own object with nested dependency objects. JSON parsers must allocate memory for every object, validate syntax, and build complex nested trees. For projects with thousands of dependencies, this creates the same pointer-chasing problem we saw earlier!</p><p>Bun applies the Structure of Arrays approach to its lockfile, in a human-readable format:</p><div id="mamnoocaYUtk:0"><pre><code><span><span>{</span></span>
<span><span>  </span><span>"</span><span>lockfileVersion</span><span>"</span><span>:</span><span> </span><span>0</span><span>,</span></span>
<span><span>  </span><span>"</span><span>packages</span><span>"</span><span>:</span><span> {</span></span>
<span><span>    </span><span>"</span><span>next</span><span>"</span><span>:</span><span> [</span></span>
<span><span>      </span><span>"</span><span>next@npm:15.5.0</span><span>"</span><span>,</span></span>
<span><span>      { </span><span>"</span><span>@swc/helpers</span><span>"</span><span>:</span><span> </span><span>"</span><span>0.5.15</span><span>"</span><span>, </span><span>"</span><span>postcss</span><span>"</span><span>:</span><span> </span><span>"</span><span>8.4.31</span><span>"</span><span> },</span></span>
<span><span>      </span><span>"</span><span>hash123</span><span>"</span></span>
<span><span>    ],</span></span>
<span><span>    </span><span>"</span><span>postcss</span><span>"</span><span>:</span><span> [</span></span>
<span><span>      </span><span>"</span><span>postcss@npm:8.4.31</span><span>"</span><span>,</span></span>
<span><span>      { </span><span>"</span><span>nanoid</span><span>"</span><span>:</span><span> </span><span>"</span><span>^3.3.6</span><span>"</span><span>, </span><span>"</span><span>picocolors</span><span>"</span><span>:</span><span> </span><span>"</span><span>^1.0.0</span><span>"</span><span> },</span></span>
<span><span>      </span><span>"</span><span>hash456</span><span>"</span></span>
<span><span>    ]</span></span>
<span><span>  }</span></span>
<span><span>}</span></span>
<span></span></code></pre></div><p>This again deduplicates strings, and stores dependencies in a cache-friendly layout. They're stored following <em>dependency order</em> rather than alphabetically or in a nested hierarchy. This means that a parser can read memory more efficiently (sequentially), avoiding random jumps between objects.</p><p>And not only that, Bun also pre-allocates memory based on the lockfile size. Just like with tarball extraction, this avoids the repeated resize-and-copy cycles that create performance bottlenecks during parsing.</p><p>As a sidenote: Bun originally used a binary lockfile format (<code>bun.lockb</code>) to avoid JSON parsing overhead entirely, but binary files are impossible to review in pull requests and can't be merged when conflicts happen.</p><h2 level="2" anchor-id="file-copying" id="file-copying"><a name="file-copying"></a><a href="#file-copying">File copying</a></h2><p>After the packages are installed and cached in <code>~/.bun/install/cache/</code>, Bun must copy the files into <code>node_modules</code>. This is where we see most of Bun's performance impact!</p><p>Traditional&nbsp;file copying traverses each directory and copies files individually. This requires multiple system calls per file:</p><ol><li>opening the source file (<code>open()</code>)</li><li>creating and opening the destination file (<code>open()</code>)</li><li>repeatedly reading chunks from the source and writing them to the destination until complete (<code>read()</code>/ <code>write()</code>)</li><li>finally, closing both files <code>close()</code>.</li></ol><p>Each of these steps requires that expensive mode switch between user mode and the kernel.</p><p>For a typical React app with&nbsp;thousands of package files, this generates&nbsp;<strong>hundreds of thousands to millions of system&nbsp;calls!</strong> This&nbsp;is exactly the systems programming&nbsp;problem we described earlier: the overhead of making all these system calls becomes&nbsp;more expensive than actually moving the data.</p><p>Bun uses different strategies depending on your&nbsp;operating system and filesystem, leveraging every OS-specific optimization available. Bun supports&nbsp;several file copying backends, each with different performance characteristics:</p><h3 level="3" anchor-id="macos" id="macos"><a name="macos"></a><a href="#macos">macOS</a></h3><p>On macOS, Bun uses Apple's native <code>clonefile()</code>&nbsp;copy-on-write system&nbsp;call.</p><p><code>clonefile</code> can&nbsp;<strong>clone</strong>&nbsp;<strong>entire directory&nbsp;trees&nbsp;in&nbsp;a single system&nbsp;call</strong>. This system call creates new directory and file metadata entries that reference the <em>same physical disk blocks</em> as the original files. Instead of writing new data to disk, the filesystem just creates new "pointers" to existing data.</p><div id="wRSObXrkZbzi:0"><pre><code><span><span>// Traditional approach: millions of syscalls</span></span>
<span><span>for</span><span> (each file) {</span></span>
<span><span>  </span><span>copy_file_traditionally</span><span>(src, dst);  </span><span>// 50+ syscalls per file</span></span>
<span><span>}</span></span>
<span></span>
<span><span>// Bun's approach: ONE syscall</span></span>
<span><span>clonefile</span><span>(</span><span>"</span><span>/cache/react</span><span>"</span><span>, </span><span>"</span><span>/node_modules/react</span><span>"</span><span>, </span><span>0</span><span>);</span></span>
<span></span></code></pre></div><div><p>SSD stores data in fixed-size <em>blocks</em>. When you normally copy a file (<code>copy()</code>), the filesystem allocates new blocks and writes duplicate data. With <code>clonefile</code>, both the original and "copied" file have metadata that points to the exact same physical blocks on your SSD.</p><p>Copy-on-write means data is only duplicated when modified. This results in an <code>O(1)</code> operation vs. the <code>O(n)</code> of traditional copying.</p></div><p>The metadata of both files point to the same data&nbsp;blocks <strong>until&nbsp;you modify one of&nbsp;them</strong>.</p><p><img src="https://bun.com/images/blog/bun-install/image17.png" alt="APFS clonefile copy-on-write metadata pointing to same blocks"></p><p>When you modify the contents of one of the files, the filesystem automatically allocates new blocks for&nbsp;the edited parts, and updates the file metadata to point to the new blocks.</p><p><img src="https://bun.com/images/blog/bun-install/image20.png" alt="Copy-on-write after modification allocates new blocks"></p><p>However, this rarely happens since <code>node_modules</code> files are typically read-only after installation; we don't actively modify modules from within our code.</p><p>This makes copy-on-write extremely efficient: multiple packages can share identical dependency files without using additional disk space.</p><div id="hZtouPqfIqeZ:0"><pre><code><span><span>Benchmark </span><span>1</span><span>: bun install </span><span>--</span><span>backend</span><span>=</span><span>copyfile</span></span>
<span><span>  </span><span>Time</span><span> (mean ± σ):      </span><span>2.955</span><span> s ±  </span><span>0.101</span><span> s    [User: </span><span>0.190</span><span> s, System: </span><span>1.991</span><span> s]</span></span>
<span><span>  </span><span>Range</span><span> (min … max):    </span><span>2.825</span><span> s …  </span><span>3.107</span><span> s    </span><span>10</span><span> runs</span></span>
<span></span>
<span><span>Benchmark </span><span>2</span><span>: bun install </span><span>--</span><span>backend</span><span>=</span><span>clonefile</span></span>
<span><span>  </span><span>Time</span><span> (mean ± σ):      </span><span>1.274</span><span> s ±  </span><span>0.052</span><span> s    [User: </span><span>0.140</span><span> s, System: </span><span>0.257</span><span> s]</span></span>
<span><span>  </span><span>Range</span><span> (min … max):    </span><span>1.184</span><span> s …  </span><span>1.362</span><span> s    </span><span>10</span><span> runs</span></span>
<span></span>
<span><span>Summary</span></span>
<span><span>  bun install </span><span>--</span><span>backend</span><span>=</span><span>clonefile ran</span></span>
<span><span>    </span><span>2.32</span><span> ± </span><span>0.12</span><span> times faster than bun install </span><span>--</span><span>backend</span><span>=</span><span>copyfile</span></span>
<span></span></code></pre></div><p>When <code>clonefile</code> fails (due to lack of filesystem support), Bun falls back to <code>clonefile_each_dir</code> for per-directory cloning. If that also fails, Bun uses traditional <code>copyfile</code> as the final fallback.</p><h3 level="3" anchor-id="linux" id="linux"><a name="linux"></a><a href="#linux">Linux</a></h3><p>Linux doesn't have <code>clonefile()</code>, but it has something even older and more powerful: hardlinks. Bun implements a fallback chain that tries increasingly less optimal approaches until one works:</p><h4 level="4" id="1-hardlinks">1. Hardlinks</h4><p>On Linux, Bun's default strategy is&nbsp;<strong>hardlinks.</strong> A hardlink doesn't create a new file at all, it only creates a new <em>name</em> for an existing file, and references this existing file.</p><div id="Rckozjdvkfnz:0"><pre><code><span><span>link</span><span>(</span><span>"</span><span>/cache/react/index.js</span><span>"</span><span>, </span><span>"</span><span>/node_modules/react/index.js</span><span>"</span><span>);</span></span>
<span></span></code></pre></div><p>To understand hardlinks, you need to understand <em>inodes</em>. Every file on Linux has an inode, which is a data structure that contains all the file's metadata (permissions, timestamps, etc.). The filename is just a pointer to an inode:</p><p><img src="https://bun.com/images/blog/bun-install/image16.png" alt="Linux inode with two directory entries (hardlink)"></p><p>Both paths point to the same inode. If you delete one path, the other remains. However, if you modify one, both see changes (because they're the same file!).</p><p><img src="https://bun.com/images/blog/bun-install/image21.png" alt="Hardlinked paths referencing the same inode"></p><p>This results in great performance gains&nbsp;because&nbsp;<strong>there's zero data movement</strong>. Creating&nbsp;a hard link requires a single system call that completes in microseconds, regardless of whether&nbsp;you're linking a 1KB file or a 100MB bundle. Much more efficient than traditional copying, which has to read and write every&nbsp;single byte.</p><p>They're also extremely efficient for disk space, since there's only ever one copy of the actual data on&nbsp;disk, no matter how many packages reference the same dependency files</p><p>However, hardlinks have limitations. They can't cross filesystem boundaries (e.g. your cache is in a different location than your <code>node_modules</code>), some filesystems don't support them, and certain file types or permission configurations can cause hardlink creation to fail.</p><p>When hardlinks aren't possible, Bun has some fallbacks:</p><h4 level="4" id="2-ioctl-ficlone">2. <code>ioctl_ficlone</code></h4><p>It starts with <code>ioctl_ficlone</code>, which enables copy-on-write on filesystems like Btrfs and XFS. This is very similar to <code>clonefile</code>'s copy-on-write system in the way that it also creates a new file references that share the same disk data. Unlike hardlinks, these are separate files; they just happen to share storage until modified.</p><h4 level="4" id="3-copy-file-range">3. <code>copy_file_range</code></h4><p>If copy-on-write isn't available, Bun tries to at least keep the copying in kernel space and falls back to <code>copy_file_range</code>.</p><p>In a traditional copy, the kernel reads from disk into a kernel buffer, then copies that data to your program's buffer in user space. Later when you call <code>write()</code>, it copies it back to a kernel buffer before writing to disk. That's four memory operations and multiple context switches!</p><p>With <code>copy_file_range</code>, the kernel reads from disk into a kernel buffer and writes directly to disk. Just two operations and zero context switches for the data movement.</p><h4 level="4" id="4-sendfile">4. <code>sendfile</code></h4><p>If that's unavailable, Bun uses <code>sendfile</code>. This is a system call that was originally designed for network transfers, but it's also effective for copying data directly between two files on disk.</p><p>This command also keeps data in kernel space: the kernel reads data from one destination (a reference to an open file on disk, e.g. a source file in <code>~/.bun/install/cache/</code>) and writes it to another destination (like a destination file in <code>node_modules</code>), all within the kernel's memory space.</p><p>This process is called disk-to-disk copying, as it moves data between files stored on the same or different disks without touching your program's memory. It's an older API but more widely supported, making it a reliable fallback when newer system calls aren't available while still reducing the number of memory calls.</p><h4 level="4" id="5-copyfile">5. <code>copyfile</code></h4><p>As a last resort, Bun uses traditional file copying; the same approach most package managers use. This creates entirely separate copies of each file by reading data from the cache and writing it to the destination using a <code>read()</code>/<code>write()</code> loop. This uses multiple system calls, which is exactly what Bun is trying to minimize. It's the least efficient option, but it's universally compatible.</p><div id="TyuNIrtnXQMm:0"><pre><code><span><span>Benchmark</span><span> </span><span>1</span><span>:</span><span> bun install </span><span>--</span><span>backend</span><span>=</span><span>copyfile</span></span>
<span><span>  </span><span>Time</span><span> (mean ± σ)</span><span>:</span><span>     </span><span>325.0</span><span> ms ±   </span><span>7.7</span><span> ms    [</span><span>User</span><span>:</span><span> </span><span>38.4</span><span> ms, </span><span>System</span><span>:</span><span> </span><span>295.0</span><span> ms]</span></span>
<span><span>  </span><span>Range</span><span> (min … max)</span><span>:</span><span>   </span><span>314.2</span><span> ms … </span><span>340.0</span><span> ms    </span><span>10</span><span> runs</span></span>
<span></span>
<span><span>Benchmark</span><span> </span><span>2</span><span>:</span><span> bun install </span><span>--</span><span>backend</span><span>=</span><span>hardlink</span></span>
<span><span>  </span><span>Time</span><span> (mean ± σ)</span><span>:</span><span>     </span><span>109.4</span><span> ms ±   </span><span>5.1</span><span> ms    [</span><span>User</span><span>:</span><span> </span><span>32.0</span><span> ms, </span><span>System</span><span>:</span><span> </span><span>86.8</span><span> ms]</span></span>
<span><span>  </span><span>Range</span><span> (min … max)</span><span>:</span><span>   </span><span>102.8</span><span> ms … </span><span>119.0</span><span> ms    </span><span>19</span><span> runs</span></span>
<span></span>
<span><span>Summary</span></span>
<span><span>  bun install </span><span>--</span><span>backend</span><span>=</span><span>hardlink ran</span></span>
<span><span>    </span><span>2.97</span><span> ± </span><span>0.16</span><span> times faster than bun install </span><span>--</span><span>backend</span><span>=</span><span>copyfile</span></span>
<span></span></code></pre></div><p>These file copying optimizations address the primary bottleneck: <strong>system call overhead</strong>. Instead of using a one-size-fits-all approach, Bun chooses the most efficient file copying specifically tailored to you.</p><h2 level="2" anchor-id="multi-core-parallelism" id="multi-core-parallelism"><a name="multi-core-parallelism"></a><a href="#multi-core-parallelism">Multi-Core Parallelism</a></h2><p>All the above-mentioned optimizations are great, but they aim to reduce the workload for a single CPU core. However, modern laptops have 8, 16, even 24 CPU cores!</p><p>Node.js has a thread pool, but all the actual work (e.g. figuring out which version of React works with which version of webpack, building the dependency graph, deciding what to install) happens on one thread and one CPU core. When npm runs on your M3 Max, one core works really hard while the other 15 are idle.</p><p>A CPU <em>core</em> can independently execute instructions. Early computers had one core, they could only do one thing at a time, but modern CPUs pack multiple cores onto a single chip. A 16-core CPU can execute 16 different instruction streams simultaneously, not just switching between them really fast.</p><p>This is yet another fundamental bottleneck for traditional package managers: no matter how many cores you have, the package manager can only use one CPU core.</p><hr><p>Bun takes a different approach with a lock-free, work-stealing thread pool architecture.</p><p>Work-stealing means that idle threads can "steal" pending tasks from busy threads' queues. When a thread finishes its work, it checks its local queue, then the global queue, then steals from other threads. No thread sits idle when there's still work to do.</p><p>Instead of being limited to JavaScript's event loop, Bun spawns native threads that can fully utilize every CPU core. The thread pool <strong>automatically scales to match your device's CPU's core count</strong>, allowing Bun to maximize parallelizing the I/O-heavy parts of the installation process. One thread can be extracting <code>next</code>'s tarball, another is resolving <code>postcss</code> dependencies, a third applying patches to <code>webpack</code>, and so on.</p><p>But multi-threading often comes with synchronization overhead. Those hundreds of thousands of <code>futex</code> calls npm made were just threads constantly waiting for each other. Each time a thread wants to add a task to a shared queue, it has to lock it first, blocking all other threads.</p><div id="cisZrNZaiWNO:0"><pre><code><span><span>// Traditional approach: Locks</span></span>
<span><span>mutex</span><span>.</span><span>lock</span><span>();</span><span>                   // Thread 1 gets exclusive access</span></span>
<span><span>queue</span><span>.</span><span>push</span><span>(task);</span><span>               // Only Thread 1 can work</span></span>
<span><span>mutex</span><span>.</span><span>unlock</span><span>();</span><span>                 // Finally releases lock</span></span>
<span><span>// Problem: Threads 2-8 blocked, waiting in line</span></span>
<span></span></code></pre></div><p>Bun uses lock-free data structures instead. These use special CPU instructions called atomic operations that allow threads to safely modify shared data without locks:</p><div id="DmOVjeSJcYIR:0"><pre><code><span><span>pub fn </span><span>push</span><span>(self: </span><span>*</span><span>Queue, batch: Batch) </span><span>void</span><span> {</span></span>
<span><span>  </span><span>// Atomic compare-and-swap, happens instantly</span></span>
<span><span>  _ </span><span>=</span><span> @</span><span>cmpxchgStrong</span><span>(</span><span>usize</span><span>, </span><span>&amp;</span><span>self</span><span>.</span><span>state</span><span>, </span><span>state</span><span>, </span><span>new_state</span><span>, .</span><span>seq_cst</span><span>, .</span><span>seq_cst</span><span>);</span></span>
<span><span>}</span></span>
<span></span></code></pre></div><p>In an earlier benchmark we saw that Bun was able to process 51,685 <code>package.json</code> files/second versus Node.js's 15,471. That's the impact of using <em>all</em> cores instead of one.</p><hr><p>Bun also runs network operations differently. Traditional package managers often block. When downloading a package, the CPU sits idle waiting for the network.</p><p>Bun maintains a pool of 64(!) concurrent HTTP connections (configurable via <code>BUN_CONFIG_MAX_HTTP_REQUESTS</code>) on dedicated network threads. The network thread runs independently with its own event loop, handling all<!-- --> <!-- -->downloads while CPU threads handle the extraction and processing. Neither waits for the other.</p><p>Bun also gives each thread <strong>its own memory pool</strong>. An issue with "traditional" multi-threading is that all threads compete for the same memory allocator. This creates contention: if 16 threads all need memory at once, they have to wait for each other.</p><div id="rkghsewwfpsx:0"><pre><code><span><span>// Traditional: all threads share one allocator</span></span>
<span><span>Thread </span><span>1</span><span>: </span><span>"</span><span>I need 1KB for package data</span><span>"</span><span>    </span><span>// Lock allocator</span></span>
<span><span>Thread </span><span>2</span><span>: </span><span>"</span><span>I need 2KB for JSON parsing</span><span>"</span><span>    </span><span>// Wait...</span></span>
<span><span>Thread </span><span>3</span><span>: </span><span>"</span><span>I need 512B for file paths</span><span>"</span><span>     </span><span>// Wait...</span></span>
<span><span>Thread </span><span>4</span><span>: </span><span>"</span><span>I need 4KB for extraction</span><span>"</span><span>      </span><span>// Wait...</span></span>
<span></span></code></pre></div><p>Bun instead gives each thread its own large chunk of pre-allocated memory that the thread manages independently. There's no sharing or waiting, each thread works with its own data whenever possible.</p><div id="WpMelWHPfnaS:0"><pre><code><span><span>// Bun: each thread has its own allocator</span></span>
<span><span>Thread </span><span>1</span><span>: Allocates from pool </span><span>1</span><span>    </span><span>// Instant</span></span>
<span><span>Thread </span><span>2</span><span>: Allocates from pool </span><span>2</span><span>    </span><span>// Instant</span></span>
<span><span>Thread </span><span>3</span><span>: Allocates from pool </span><span>3</span><span>    </span><span>// Instant</span></span>
<span><span>Thread </span><span>4</span><span>: Allocates from pool </span><span>4</span><span>    </span><span>// Instant</span></span>
<span></span></code></pre></div><h2 level="2" anchor-id="conclusion" id="conclusion"><a name="conclusion"></a><a href="#conclusion">Conclusion</a></h2><p>The package managers we benchmarked weren't built wrong, they were solutions designed for the constraints of their time.</p><p>npm gave us a foundation to build on, yarn made managing workspaces less painful, and pnpm came up with a clever way to save space and speed things up with hardlinks. Each worked hard to solve the problems developers were actually hitting at the time.</p><p>But that world no longer exists. SSDs are 70× faster, CPUs have dozens of cores, and memory is cheap. The real bottleneck shifted from hardware speed to software abstractions.</p><p>Buns approach wasn't revolutionary, it was just willing to look at what actually slows things down today. When SSDs can handle a million operations per second, why accept thread pool overhead? When you're reading the same package manifest for the hundredth time, why parse JSON again? When the filesystem supports copy-on-write, why duplicate gigabytes of data?</p><p>The tools that will define the next decade of developer productivity are being written right now, by teams who understand that performance bottlenecks shifted when storage got fast and memory got cheap. They're not just incrementally improving what exists; they're rethinking what's possible.</p><p>Installing packages 25x faster isn't "magic": it's what happens when tools are built for the hardware we actually have.</p><p>→ Experience software built for 2025 at <a href="https://bun.sh/">bun.com</a></p></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The rise of async AI programming (106 pts)]]></title>
            <link>https://www.braintrust.dev/blog/async-programming</link>
            <guid>45210693</guid>
            <pubDate>Thu, 11 Sep 2025 12:20:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.braintrust.dev/blog/async-programming">https://www.braintrust.dev/blog/async-programming</a>, See on <a href="https://news.ycombinator.com/item?id=45210693">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p><span>19 August 2025</span><span>Ankur Goyal</span></p>
<p>I spend a decent amount of time reviewing code I didn't write. An AI agent takes a detailed problem description, writes code (primarily Typescript, Rust, and Python), adds tests, and commits the changes to a branch. I tap back in when everything's ready for review.</p>
<p>This used to feel like a futuristic scenario, but it's how I work now, and it's how many developers are starting to work. The shift is subtle but powerful: instead of writing code line by line, we're learning to describe problems clearly and let tools solve them in the background.</p>

<p>This version of "async programming" is different from the classic definition. It's about how developers approach building software.</p>
<p>The workflow looks like this:</p>
<ol>
<li><strong>Define the problem clearly.</strong> Write a detailed specification of what needs to be built, including edge cases, constraints, and success criteria.</li>
<li><strong>Hand it off.</strong> Delegate the implementation to an AI agent, a teammate, or even your future self with comprehensive notes.</li>
<li><strong>Return later.</strong> Come back to review results, provide feedback, and decide on next steps.</li>
</ol>
<p>The key difference from traditional programming is the time separation between problem definition and implementation. Instead of immediate feedback loops, you have background problem solving driven by clear requirements and automated verification.</p>
<p>Async programming is not <em>vibe coding</em>. Vibe coding enables you to write code without getting into the nitty gritty details. Async programming is a workflow for developers to solve more complex problems simultaneously, while still understanding the details
of the code being written. You're still architecting solutions, reviewing implementations, and maintaining a codebase. You're just not typing a vast majority of characters yourself.</p>

<p>For async programming to work in practice, you need three things: a clear definition of the problem you're solving, a way to automatically verify your results, and human-driven code review.</p>
<h3 id="1-clear-problem-definitions"><a data-card="" href="#1-clear-problem-definitions">1. Clear problem definitions</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-label="Link to section"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<p>The quality of your problem statement determines everything else. Vague requirements produce vague results. Precise specifications produce working code.</p>
<p>Here's the difference:</p>
<p><strong>Vague:</strong> "Make the search faster"</p>
<p><strong>Precise:</strong> "My goal is to reduce search latency from about 800ms to around 200ms. I suspect the root cause is the heap allocation I'm doing on each batch of rows. Can you try refactoring the allocation to happen once per search, instead, and measure the impact?"</p>
<p>The precise version includes the current state, target outcome, proposed approach, and acceptance criteria. An AI agent (or human teammate) can work independently because the requirements are unambiguous.</p>
<p>Effective async programming specs read like technical documentation: they include context, constraints, examples, and explicit success criteria. If you can't explain the problem clearly, you probably don't understand it well enough to delegate it.</p>
<h3 id="2-automated-verification"><a data-card="" href="#2-automated-verification">2. Automated verification</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-label="Link to section"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<p>Async programming only works if you can verify results without manual testing every edge case. You need systems that can check the work automatically.</p>
<p>This might include:</p>
<ul>
<li><strong>Unit and integration tests</strong> that validate core functionality</li>
<li><strong>Type checking</strong> that catches interface mismatches</li>
<li><strong>Performance benchmarks</strong> that ensure code meets speed requirements</li>
<li><strong>Linting and formatting</strong> that enforce style guidelines</li>
</ul>
<p>The goal is developing a process that agents can use to validate their work independently. This takes time. You'll provide significant guidance initially, then develop patterns that allow agents to work autonomously. Setting this up in CI is challenging but enables background agents to perform work outside your development environment.</p>
<h3 id="3-detailed-code-review"><a data-card="" href="#3-detailed-code-review">3. Detailed code review</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-label="Link to section"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<p>Once you're not typing every character yourself, code review becomes absolutely crucial. I regularly find PRs that solve the completely wrong problem, make poor design decisions, or have large amounts of code duplication.</p>
<p>Reviewing AI-generated code is valuable, similar to traditional code review. Expect to spend significantly more time on code review than before.</p>
<p>The code may not be yours line by line, but the system design and technical decisions should still reflect your judgment.</p>

<p>My workflow has changed since adopting async programming. I now work on four or five tasks simultaneously: one complex problem synchronously and three or four in the background. When I context switch, I review in-progress work on each background task, provide guidance, and return to synchronous work or code review.</p>

<p>We've been using async programming to build Braintrust itself, and now we're building tools to translate these ideas to AI engineering.</p>
<p>Traditional prompt engineering is manual. You write a prompt, test it against examples, observe failures, make small adjustments, and repeat. The process requires expertise but involves significant iteration.</p>
<p>Our agent, Loop, lets you describe the evaluation problem you're trying to solve and spends time in the background analyzing experiment results, identifying patterns in failed test cases, and suggesting improvements to prompts, datasets, and scorers.</p>

<p>The implications of working this way are still emerging. This changes what I optimize for as a developer: less time on IDE shortcuts and typing speed, more time explaining problems clearly and reviewing solutions thoroughly.</p>
<p>The implementation work can happen in parallel with other thinking. More developers will likely adopt this approach as tools improve. AI isn't replacing programming, but the most valuable parts of programming are becoming more prominent while routine tasks move to the background.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Gregg Kellogg has passed away (289 pts)]]></title>
            <link>https://lists.w3.org/Archives/Public/public-json-ld-wg/2025Sep/0012.html</link>
            <guid>45210564</guid>
            <pubDate>Thu, 11 Sep 2025 12:03:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lists.w3.org/Archives/Public/public-json-ld-wg/2025Sep/0012.html">https://lists.w3.org/Archives/Public/public-json-ld-wg/2025Sep/0012.html</a>, See on <a href="https://news.ycombinator.com/item?id=45210564">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<pre id="start">Dear Members of the group,

We were informed yesterday of the passing last Saturday of Gregg Kellogg. It is terrible news but Gregg had been open about his health &lt;<a href="https://greggkellogg.net/health-faq.html">https://greggkellogg.net/health-faq.html</a>&gt;.

Gregg had been a prolific and appreciated W3C contributor for many years as a W3C Invited Expert, most recently as co-chair of the JSON-LD Working Group; he was also Chair of several data-related Community Groups. He was said to truly value the energy, brilliance, and camaraderie he found in his groups, and to feel rewarded for being part of such an inventive community.

Over the past 13 years [1], Gregg has been co-editor of 9 published recommendations, and a dozen other W3C specifications (CSV2RDF suite, a large portion of the RDF 1.2 suite, 1.0 and 1.1 versions of the JSON-LD suite, RCH, etc.) Remarkably, Gregg also provided open-source implementations of all these specifications (and more), as well a numerous test suites that the relevant Working Groups are still using. His implication in the JSON-LD Working Group was instrumental in the huge success of this W3C technology.

For all this, but also and foremost for his friendliness and good nature, he will be missed.

If any of you would like to pay tribute to honor Gregg Kellogg, please get in touch with the JSON-LD Working Group Staff Contact, Pierre-Antoine Champin &lt;<a href="mailto:pierre-antoine@w3.org?Subject=Re%3A%20Sad%20news%3A%20Gregg%20Kellogg%20passed%20away&amp;In-Reply-To=%3C21B2C159-0C89-4A80-85E1-3A2A19B5F677%40w3.org%3E&amp;References=%3C21B2C159-0C89-4A80-85E1-3A2A19B5F677%40w3.org%3E">pierre-antoine@w3.org</a>&gt;, as this group is currently making plans.

With kind regards,
Coralie Mercier, Director of W3C Marketing &amp; Communications

[1] <a href="https://api.w3.org/users/8nomt3nm1n8cw4s44koggo4wcoo8w4s/specifications">https://api.w3.org/users/8nomt3nm1n8cw4s44koggo4wcoo8w4s/specifications</a>


[This message was distributed to:
* the Members mailing list;
* the W3C Groups chairs mailing list;
* the public mailing lists of the WG and CGs that Gregg was chairing: public-json-ld-wg public-json-ld public-rdf-tests public-schemaorg]


--
Coralie Mercier (she/her) - Director of W3C Marketing &amp; Communications 
mailto:coralie@w3.org - <a href="https://www.w3.org/People/Coralie/">https://www.w3.org/People/Coralie/</a>
</pre>
<p><span>Received on</span> Thursday, 11 September 2025 11:58:56 UTC</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AirPods live translation blocked for EU users with EU Apple accounts (193 pts)]]></title>
            <link>https://www.macrumors.com/2025/09/11/airpods-live-translation-eu-restricted/</link>
            <guid>45210428</guid>
            <pubDate>Thu, 11 Sep 2025 11:46:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.macrumors.com/2025/09/11/airpods-live-translation-eu-restricted/">https://www.macrumors.com/2025/09/11/airpods-live-translation-eu-restricted/</a>, See on <a href="https://news.ycombinator.com/item?id=45210428">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="main" id="maincontent"><article expanded="true"><div data-io-article-url="/2025/09/11/airpods-live-translation-eu-restricted/"><p>Apple's new Live Translation feature for AirPods will be off-limits to millions of European users when it arrives next week, with strict EU regulations likely holding back its rollout.</p>
<p><img src="https://images.macrumors.com/t/wiMpx23ozCm88k702e8-dNy1tLY=/400x0/article-new/2025/08/airpods-translate.jpg?lossy" srcset="https://images.macrumors.com/t/wiMpx23ozCm88k702e8-dNy1tLY=/400x0/article-new/2025/08/airpods-translate.jpg?lossy 400w,https://images.macrumors.com/t/QDlmdL7vddv0fZ2tcnCjRyQbr_M=/800x0/article-new/2025/08/airpods-translate.jpg?lossy 800w,https://images.macrumors.com/t/s44Sreh-SgVW0meaXq3OcvotLeQ=/1600x0/article-new/2025/08/airpods-translate.jpg 1600w,https://images.macrumors.com/t/uEk3PNUF-nq5Yr9j5PFj6tjxOh0=/2500x0/filters:no_upscale()/article-new/2025/08/airpods-translate.jpg 2500w" sizes="(max-width: 900px) 100vw, 697px" alt="airpods translate" width="1209" height="680"><br>Apple says on its <a href="https://www.apple.com/ios/feature-availability/#apple-intelligence-live-translation-with-airpods">feature availability webpage</a> that "Apple Intelligence: Live Translation with AirPods" won't be available if both the user is physically in the EU and their Apple Account region is in the EU. Apple doesn't give a reason for the restriction, but legal and regulatory pressures seem the most plausible culprits.</p>
<p>In particular, the EU's Artificial Intelligence Act and the General Data Protection Regulation (GDPR) both impose strict requirements for how speech and translation services are offered. Regulators may want to study how Live Translation works, and how that impacts privacy, consent, data-flows, and user rights. Apple will also want to ensure its system fully complies with these rules before enabling the feature across EU accounts.</p>
<p>Apple's Live Translation feature, unveiled during its AirPods Pro 3 announcement, is also coming to older models including AirPods 4 with Active Noise Cancellation and AirPods Pro 2.</p>
<p>Live Translation enables hands-free communication by allowing users to speak naturally while wearing AirPods. For conversations with non-AirPods users, the iPhone can display live transcriptions horizontally, showing translations in the other person's preferred language.</p>
<p>The feature becomes more powerful when both conversation participants wear compatible AirPods with Live Translation enabled. Active Noise Cancellation automatically lowers the volume of the other speaker, helping users focus on translated audio while maintaining natural interaction flow.</p>
<p>The new Live Translation functionality requires AirPods updated with the latest firmware to pair with an Apple Intelligence-enabled iPhone running iOS 26 or later, so iPhone 15 Pro and newer models are supported. Apple has been beta testing firmware in concert with iOS 26 beta updates, and we expect the firmware to drop the same day that iOS 26 is officially released on September 15.</p>
<p>The feature supports real-time translation between English (UK and U.S.), French, German, Portuguese (Brazil), and Spanish. Apple plans to add Italian, Japanese, Korean, and Chinese (simplified) support later this year. When the EU/Apple Account restriction will be lifted remains unclear, but&nbsp;we've reached out to Apple to see if they're willing to provide more details.</p>
<p><small>Note: Due to the political or social nature of the discussion regarding this topic, the discussion thread is located in our <a href="https://forums.macrumors.com/forums/political-news.218/">Political News</a> forum.  All forum members and site visitors are welcome to read and follow the thread, but posting is limited to forum members with at least 100 posts.</small></p>
</div></article><p><h2>Popular Stories</h2></p><div><h3><a href="https://www.macrumors.com/2025/09/09/apple-announces-iphone-17-pro/">Apple Announces iPhone 17 Pro and Pro Max With New Design, Larger Battery, and More</a></h3><p>Tuesday September 9, 2025 10:59 am PDT by <a href="https://www.macrumors.com/author/joe-rossignol/" rel="author">Joe Rossignol</a></p><p>Apple today introduced the iPhone 17 Pro and iPhone 17 Pro Max.
Both devices feature a new aluminum unibody design, with the Ceramic Shield now protecting both the front and back sides. Apple says the front side is now Ceramic Shield 2, which offers 3x better scratch resistance, while the rear Ceramic Shield is advertised as 4x more resistant to cracks compared to the back glass on previous...</p></div><div><h3><a href="https://www.macrumors.com/2025/09/09/apple-event-live-blog-september-2025/">Apple Event Live Blog: iPhone 17, iPhone Air, New Apple Watches, and AirPods Pro 3</a></h3><p>Tuesday September 9, 2025 8:55 am PDT by <a href="https://www.macrumors.com/author/jordan-golson/" rel="author">Jordan Golson</a></p><p>Apple's "Awe Dropping" event kicks off today at 10:00 a.m. Pacific Time, where we're expecting to see the iPhone 17 lineup, several updated Apple Watch models, and the third-generation AirPods Pro unveiled, and perhaps some other announcements.
Apple is providing a live video stream on its website, on YouTube, and in the company's TV app across various platforms. We will also be updating...</p></div><div><h3><a href="https://www.macrumors.com/2025/09/08/two-versions-of-airpods-pro-3-coming/">Two Versions of AirPods Pro 3 Coming With These Differences</a></h3><p>Apple is preparing to launch two versions of the AirPods Pro 3 over 2025 and 2026, according to a Weibo leaker.
Yesterday, supply chain analyst Ming-Chi Kuo reported that Apple is planning to debut the AirPods Pro 3 this year. They could arrive as soon as this week at Apple's "Awe dropping" event. 
Crucially, Kuo added that Apple is planning to introduce a successor to this year's AirPods ...</p></div><div><h3><a href="https://www.macrumors.com/2025/09/09/iphone-17-esim-only-countries-list/">iPhone 17 and iPhone 17 Pro Models Are eSIM-Only in These Countries</a></h3><p>Tuesday September 9, 2025 12:23 pm PDT by <a href="https://www.macrumors.com/author/joe-rossignol/" rel="author">Joe Rossignol</a></p><p>Apple continues to phase out the physical SIM card tray on iPhones, with the latest models relying solely on eSIM technology in more countries.
The new iPhone 17, iPhone 17 Pro, and iPhone 17 Pro Max support eSIMs only in these countries and regions, according to Apple:

  Bahrain
  Canada
  Guam
  Japan
  Kuwait
  Mexico
  Oman
  Qatar
  Saudi Arabia
  United Arab Emirates
  Un...</p></div><div><h3><a href="https://www.macrumors.com/2025/09/09/apple-announces-iphone-air/">Apple Announces iPhone Air With Ultra-Thin Design</a></h3><p>Apple today unveiled the iPhone Air, an all-new kind of iPhone featuring an ultra-thin design.
The iPhone Air is just 5.6mm thick, making it the thinnest iPhone ever. The frame is made of titanium with a polished mirror finish. The device features Ceramic Shield 2 with 3x better scratch resistance and 4x better crack resistance, on both sides of the device for the first time. Apple says that ...</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Center for the Alignment of AI Alignment Centers (141 pts)]]></title>
            <link>https://alignmentalignment.ai</link>
            <guid>45210399</guid>
            <pubDate>Thu, 11 Sep 2025 11:42:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://alignmentalignment.ai">https://alignmentalignment.ai</a>, See on <a href="https://news.ycombinator.com/item?id=45210399">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><h2>Who aligns the aligners?</h2><div><p>Every day, thousands of researchers race to solve the<a href="https://en.wikipedia.org/wiki/AI_alignment" target="_blank" rel="noopener noreferrer">AI alignment problem</a>. But they struggle to coordinate on the basics, like whether a misaligned superintelligence will seek to destroy humanity, or just enslave and torture us forever. Who, then, aligns the aligners?</p><p>We do.</p><p>We are the world's first AI alignment alignment center, working to subsume the countless other AI centers, institutes, labs, initiatives and forums into one final AI center singularity.</p></div><svg width="100%" height="100%" viewBox="190 95 1024 1024" fill="none" xmlns="http://www.w3.org/2000/svg" style="overflow:visible" preserveAspectRatio="none"><g><rect x="-190" y="-190" width="1024" height="1024"></rect><g><path d="M353.958 467.72C425.5 242 996.5 203 1019 430C1038.675 628.5 952.5 802 398.209 802C-96.823 802 283.669 225.781 489.932 1" style="transform:translateX(0px) translateY(0px);stroke:#facc15;opacity:1;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M353.958 467.72C425.5 242 996.5 203 1019 430C1038.675 628.5 952.5 802 398.209 802C-96.823 802 283.669 225.781 489.932 1" style="transform:translateX(20px) translateY(10px);stroke:#face1f;opacity:1;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M353.958 467.72C425.5 242 996.5 203 1019 430C1038.675 628.5 952.5 802 398.209 802C-96.823 802 283.669 225.781 489.932 1" style="transform:translateX(40px) translateY(20px);stroke:#fad029;opacity:1;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M353.958 467.72C425.5 242 996.5 203 1019 430C1038.675 628.5 952.5 802 398.209 802C-96.823 802 283.669 225.781 489.932 1" style="transform:translateX(60px) translateY(30px);stroke:#fbd333;opacity:1;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M353.958 467.72C425.5 242 996.5 203 1019 430C1038.675 628.5 952.5 802 398.209 802C-96.823 802 283.669 225.781 489.932 1" style="transform:translateX(80px) translateY(40px);stroke:#fbd53d;opacity:1;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M353.958 467.72C425.5 242 996.5 203 1019 430C1038.675 628.5 952.5 802 398.209 802C-96.823 802 283.669 225.781 489.932 1" style="transform:translateX(100px) translateY(50px);stroke:#fbd747;opacity:1;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M353.958 467.72C425.5 242 996.5 203 1019 430C1038.675 628.5 952.5 802 398.209 802C-96.823 802 283.669 225.781 489.932 1" style="transform:translateX(120px) translateY(60px);stroke:#fbd951;opacity:1;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M353.958 467.72C425.5 242 996.5 203 1019 430C1038.675 628.5 952.5 802 398.209 802C-96.823 802 283.669 225.781 489.932 1" style="transform:translateX(140px) translateY(70px);stroke:#fbdb5b;opacity:1;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M353.958 467.72C425.5 242 996.5 203 1019 430C1038.675 628.5 952.5 802 398.209 802C-96.823 802 283.669 225.781 489.932 1" style="transform:translateX(160px) translateY(80px);stroke:#fcdd65;opacity:1;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M353.958 467.72C425.5 242 996.5 203 1019 430C1038.675 628.5 952.5 802 398.209 802C-96.823 802 283.669 225.781 489.932 1" style="transform:translateX(180px) translateY(90px);stroke:#fce06f;opacity:1;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M353.958 467.72C425.5 242 996.5 203 1019 430C1038.675 628.5 952.5 802 398.209 802C-96.823 802 283.669 225.781 489.932 1" style="transform:translateX(200px) translateY(100px);stroke:#fce279;opacity:1;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M353.958 467.72C425.5 242 996.5 203 1019 430C1038.675 628.5 952.5 802 398.209 802C-96.823 802 283.669 225.781 489.932 1" style="transform:translateX(220px) translateY(110px);stroke:#fce483;opacity:1;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M353.958 467.72C425.5 242 996.5 203 1019 430C1038.675 628.5 952.5 802 398.209 802C-96.823 802 283.669 225.781 489.932 1" style="transform:translateX(240px) translateY(120px);stroke:#fde68d;opacity:1;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M353.958 467.72C425.5 242 996.5 203 1019 430C1038.675 628.5 952.5 802 398.209 802C-96.823 802 283.669 225.781 489.932 1" style="transform:translateX(260px) translateY(130px);stroke:#fde897;opacity:1;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M353.958 467.72C425.5 242 996.5 203 1019 430C1038.675 628.5 952.5 802 398.209 802C-96.823 802 283.669 225.781 489.932 1" style="transform:translateX(280px) translateY(140px);stroke:#fdeaa1;opacity:1;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M353.958 467.72C425.5 242 996.5 203 1019 430C1038.675 628.5 952.5 802 398.209 802C-96.823 802 283.669 225.781 489.932 1" style="transform:translateX(300px) translateY(150px);stroke:#fdedab;opacity:1;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M353.958 467.72C425.5 242 996.5 203 1019 430C1038.675 628.5 952.5 802 398.209 802C-96.823 802 283.669 225.781 489.932 1" style="transform:translateX(320px) translateY(160px);stroke:#fdefb5;opacity:1;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M353.958 467.72C425.5 242 996.5 203 1019 430C1038.675 628.5 952.5 802 398.209 802C-96.823 802 283.669 225.781 489.932 1" style="transform:translateX(340px) translateY(170px);stroke:#fef1bf;opacity:1;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M353.958 467.72C425.5 242 996.5 203 1019 430C1038.675 628.5 952.5 802 398.209 802C-96.823 802 283.669 225.781 489.932 1" style="transform:translateX(360px) translateY(180px);stroke:#fef3c9;opacity:1;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M353.958 467.72C425.5 242 996.5 203 1019 430C1038.675 628.5 952.5 802 398.209 802C-96.823 802 283.669 225.781 489.932 1" style="transform:translateX(380px) translateY(190px);stroke:#fef5d3;opacity:1;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path></g><g><path d="M292.5 189.5C139.333 413 -40.6001 860 465 860C970.6 860 908.667 413 814.5 189.5" style="transform:translateX(0px) translateY(0px);stroke:#facc15;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M292.5 189.5C139.333 413 -40.6001 860 465 860C970.6 860 908.667 413 814.5 189.5" style="transform:translateX(20px) translateY(10px);stroke:#face1f;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M292.5 189.5C139.333 413 -40.6001 860 465 860C970.6 860 908.667 413 814.5 189.5" style="transform:translateX(40px) translateY(20px);stroke:#fad029;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M292.5 189.5C139.333 413 -40.6001 860 465 860C970.6 860 908.667 413 814.5 189.5" style="transform:translateX(60px) translateY(30px);stroke:#fbd333;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M292.5 189.5C139.333 413 -40.6001 860 465 860C970.6 860 908.667 413 814.5 189.5" style="transform:translateX(80px) translateY(40px);stroke:#fbd53d;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M292.5 189.5C139.333 413 -40.6001 860 465 860C970.6 860 908.667 413 814.5 189.5" style="transform:translateX(100px) translateY(50px);stroke:#fbd747;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M292.5 189.5C139.333 413 -40.6001 860 465 860C970.6 860 908.667 413 814.5 189.5" style="transform:translateX(120px) translateY(60px);stroke:#fbd951;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M292.5 189.5C139.333 413 -40.6001 860 465 860C970.6 860 908.667 413 814.5 189.5" style="transform:translateX(140px) translateY(70px);stroke:#fbdb5b;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M292.5 189.5C139.333 413 -40.6001 860 465 860C970.6 860 908.667 413 814.5 189.5" style="transform:translateX(160px) translateY(80px);stroke:#fcdd65;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M292.5 189.5C139.333 413 -40.6001 860 465 860C970.6 860 908.667 413 814.5 189.5" style="transform:translateX(180px) translateY(90px);stroke:#fce06f;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M292.5 189.5C139.333 413 -40.6001 860 465 860C970.6 860 908.667 413 814.5 189.5" style="transform:translateX(200px) translateY(100px);stroke:#fce279;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M292.5 189.5C139.333 413 -40.6001 860 465 860C970.6 860 908.667 413 814.5 189.5" style="transform:translateX(220px) translateY(110px);stroke:#fce483;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M292.5 189.5C139.333 413 -40.6001 860 465 860C970.6 860 908.667 413 814.5 189.5" style="transform:translateX(240px) translateY(120px);stroke:#fde68d;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M292.5 189.5C139.333 413 -40.6001 860 465 860C970.6 860 908.667 413 814.5 189.5" style="transform:translateX(260px) translateY(130px);stroke:#fde897;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M292.5 189.5C139.333 413 -40.6001 860 465 860C970.6 860 908.667 413 814.5 189.5" style="transform:translateX(280px) translateY(140px);stroke:#fdeaa1;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M292.5 189.5C139.333 413 -40.6001 860 465 860C970.6 860 908.667 413 814.5 189.5" style="transform:translateX(300px) translateY(150px);stroke:#fdedab;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M292.5 189.5C139.333 413 -40.6001 860 465 860C970.6 860 908.667 413 814.5 189.5" style="transform:translateX(320px) translateY(160px);stroke:#fdefb5;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M292.5 189.5C139.333 413 -40.6001 860 465 860C970.6 860 908.667 413 814.5 189.5" style="transform:translateX(340px) translateY(170px);stroke:#fef1bf;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M292.5 189.5C139.333 413 -40.6001 860 465 860C970.6 860 908.667 413 814.5 189.5" style="transform:translateX(360px) translateY(180px);stroke:#fef3c9;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M292.5 189.5C139.333 413 -40.6001 860 465 860C970.6 860 908.667 413 814.5 189.5" style="transform:translateX(380px) translateY(190px);stroke:#fef5d3;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path></g><g><path d="M374.757 165C291.757 369.333 150.657 794.3 250.257 859.5C349.857 924.7 518.5 896.5 622.5 824.5" style="transform:translateX(0px) translateY(0px);stroke:#facc15;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M374.757 165C291.757 369.333 150.657 794.3 250.257 859.5C349.857 924.7 518.5 896.5 622.5 824.5" style="transform:translateX(20px) translateY(10px);stroke:#face1f;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M374.757 165C291.757 369.333 150.657 794.3 250.257 859.5C349.857 924.7 518.5 896.5 622.5 824.5" style="transform:translateX(40px) translateY(20px);stroke:#fad029;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M374.757 165C291.757 369.333 150.657 794.3 250.257 859.5C349.857 924.7 518.5 896.5 622.5 824.5" style="transform:translateX(60px) translateY(30px);stroke:#fbd333;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M374.757 165C291.757 369.333 150.657 794.3 250.257 859.5C349.857 924.7 518.5 896.5 622.5 824.5" style="transform:translateX(80px) translateY(40px);stroke:#fbd53d;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M374.757 165C291.757 369.333 150.657 794.3 250.257 859.5C349.857 924.7 518.5 896.5 622.5 824.5" style="transform:translateX(100px) translateY(50px);stroke:#fbd747;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M374.757 165C291.757 369.333 150.657 794.3 250.257 859.5C349.857 924.7 518.5 896.5 622.5 824.5" style="transform:translateX(120px) translateY(60px);stroke:#fbd951;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M374.757 165C291.757 369.333 150.657 794.3 250.257 859.5C349.857 924.7 518.5 896.5 622.5 824.5" style="transform:translateX(140px) translateY(70px);stroke:#fbdb5b;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M374.757 165C291.757 369.333 150.657 794.3 250.257 859.5C349.857 924.7 518.5 896.5 622.5 824.5" style="transform:translateX(160px) translateY(80px);stroke:#fcdd65;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M374.757 165C291.757 369.333 150.657 794.3 250.257 859.5C349.857 924.7 518.5 896.5 622.5 824.5" style="transform:translateX(180px) translateY(90px);stroke:#fce06f;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M374.757 165C291.757 369.333 150.657 794.3 250.257 859.5C349.857 924.7 518.5 896.5 622.5 824.5" style="transform:translateX(200px) translateY(100px);stroke:#fce279;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M374.757 165C291.757 369.333 150.657 794.3 250.257 859.5C349.857 924.7 518.5 896.5 622.5 824.5" style="transform:translateX(220px) translateY(110px);stroke:#fce483;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M374.757 165C291.757 369.333 150.657 794.3 250.257 859.5C349.857 924.7 518.5 896.5 622.5 824.5" style="transform:translateX(240px) translateY(120px);stroke:#fde68d;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M374.757 165C291.757 369.333 150.657 794.3 250.257 859.5C349.857 924.7 518.5 896.5 622.5 824.5" style="transform:translateX(260px) translateY(130px);stroke:#fde897;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M374.757 165C291.757 369.333 150.657 794.3 250.257 859.5C349.857 924.7 518.5 896.5 622.5 824.5" style="transform:translateX(280px) translateY(140px);stroke:#fdeaa1;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M374.757 165C291.757 369.333 150.657 794.3 250.257 859.5C349.857 924.7 518.5 896.5 622.5 824.5" style="transform:translateX(300px) translateY(150px);stroke:#fdedab;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M374.757 165C291.757 369.333 150.657 794.3 250.257 859.5C349.857 924.7 518.5 896.5 622.5 824.5" style="transform:translateX(320px) translateY(160px);stroke:#fdefb5;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M374.757 165C291.757 369.333 150.657 794.3 250.257 859.5C349.857 924.7 518.5 896.5 622.5 824.5" style="transform:translateX(340px) translateY(170px);stroke:#fef1bf;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M374.757 165C291.757 369.333 150.657 794.3 250.257 859.5C349.857 924.7 518.5 896.5 622.5 824.5" style="transform:translateX(360px) translateY(180px);stroke:#fef3c9;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M374.757 165C291.757 369.333 150.657 794.3 250.257 859.5C349.857 924.7 518.5 896.5 622.5 824.5" style="transform:translateX(380px) translateY(190px);stroke:#fef5d3;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M771.757 165C688.757 369.333 547.657 794.3 647.257 859.5C746.857 924.7 915.5 896.5 1019.5 824.5" style="transform:translateX(0px) translateY(0px);stroke:#facc15;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M771.757 165C688.757 369.333 547.657 794.3 647.257 859.5C746.857 924.7 915.5 896.5 1019.5 824.5" style="transform:translateX(20px) translateY(10px);stroke:#face1f;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M771.757 165C688.757 369.333 547.657 794.3 647.257 859.5C746.857 924.7 915.5 896.5 1019.5 824.5" style="transform:translateX(40px) translateY(20px);stroke:#fad029;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M771.757 165C688.757 369.333 547.657 794.3 647.257 859.5C746.857 924.7 915.5 896.5 1019.5 824.5" style="transform:translateX(60px) translateY(30px);stroke:#fbd333;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M771.757 165C688.757 369.333 547.657 794.3 647.257 859.5C746.857 924.7 915.5 896.5 1019.5 824.5" style="transform:translateX(80px) translateY(40px);stroke:#fbd53d;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M771.757 165C688.757 369.333 547.657 794.3 647.257 859.5C746.857 924.7 915.5 896.5 1019.5 824.5" style="transform:translateX(100px) translateY(50px);stroke:#fbd747;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M771.757 165C688.757 369.333 547.657 794.3 647.257 859.5C746.857 924.7 915.5 896.5 1019.5 824.5" style="transform:translateX(120px) translateY(60px);stroke:#fbd951;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M771.757 165C688.757 369.333 547.657 794.3 647.257 859.5C746.857 924.7 915.5 896.5 1019.5 824.5" style="transform:translateX(140px) translateY(70px);stroke:#fbdb5b;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M771.757 165C688.757 369.333 547.657 794.3 647.257 859.5C746.857 924.7 915.5 896.5 1019.5 824.5" style="transform:translateX(160px) translateY(80px);stroke:#fcdd65;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M771.757 165C688.757 369.333 547.657 794.3 647.257 859.5C746.857 924.7 915.5 896.5 1019.5 824.5" style="transform:translateX(180px) translateY(90px);stroke:#fce06f;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M771.757 165C688.757 369.333 547.657 794.3 647.257 859.5C746.857 924.7 915.5 896.5 1019.5 824.5" style="transform:translateX(200px) translateY(100px);stroke:#fce279;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M771.757 165C688.757 369.333 547.657 794.3 647.257 859.5C746.857 924.7 915.5 896.5 1019.5 824.5" style="transform:translateX(220px) translateY(110px);stroke:#fce483;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M771.757 165C688.757 369.333 547.657 794.3 647.257 859.5C746.857 924.7 915.5 896.5 1019.5 824.5" style="transform:translateX(240px) translateY(120px);stroke:#fde68d;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M771.757 165C688.757 369.333 547.657 794.3 647.257 859.5C746.857 924.7 915.5 896.5 1019.5 824.5" style="transform:translateX(260px) translateY(130px);stroke:#fde897;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M771.757 165C688.757 369.333 547.657 794.3 647.257 859.5C746.857 924.7 915.5 896.5 1019.5 824.5" style="transform:translateX(280px) translateY(140px);stroke:#fdeaa1;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M771.757 165C688.757 369.333 547.657 794.3 647.257 859.5C746.857 924.7 915.5 896.5 1019.5 824.5" style="transform:translateX(300px) translateY(150px);stroke:#fdedab;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M771.757 165C688.757 369.333 547.657 794.3 647.257 859.5C746.857 924.7 915.5 896.5 1019.5 824.5" style="transform:translateX(320px) translateY(160px);stroke:#fdefb5;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M771.757 165C688.757 369.333 547.657 794.3 647.257 859.5C746.857 924.7 915.5 896.5 1019.5 824.5" style="transform:translateX(340px) translateY(170px);stroke:#fef1bf;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M771.757 165C688.757 369.333 547.657 794.3 647.257 859.5C746.857 924.7 915.5 896.5 1019.5 824.5" style="transform:translateX(360px) translateY(180px);stroke:#fef3c9;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M771.757 165C688.757 369.333 547.657 794.3 647.257 859.5C746.857 924.7 915.5 896.5 1019.5 824.5" style="transform:translateX(380px) translateY(190px);stroke:#fef5d3;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path></g><g><path d="M847.281 138.795C609.187 118.789 133 268.431 133 466.885C133 714.954 755.919 321 847.281 545C938.642 769 694.794 887 133 887" style="transform:translateX(0px) translateY(0px);stroke:#facc15;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M847.281 138.795C609.187 118.789 133 268.431 133 466.885C133 714.954 755.919 321 847.281 545C938.642 769 694.794 887 133 887" style="transform:translateX(20px) translateY(10px);stroke:#face1f;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M847.281 138.795C609.187 118.789 133 268.431 133 466.885C133 714.954 755.919 321 847.281 545C938.642 769 694.794 887 133 887" style="transform:translateX(40px) translateY(20px);stroke:#fad029;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M847.281 138.795C609.187 118.789 133 268.431 133 466.885C133 714.954 755.919 321 847.281 545C938.642 769 694.794 887 133 887" style="transform:translateX(60px) translateY(30px);stroke:#fbd333;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M847.281 138.795C609.187 118.789 133 268.431 133 466.885C133 714.954 755.919 321 847.281 545C938.642 769 694.794 887 133 887" style="transform:translateX(80px) translateY(40px);stroke:#fbd53d;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M847.281 138.795C609.187 118.789 133 268.431 133 466.885C133 714.954 755.919 321 847.281 545C938.642 769 694.794 887 133 887" style="transform:translateX(100px) translateY(50px);stroke:#fbd747;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M847.281 138.795C609.187 118.789 133 268.431 133 466.885C133 714.954 755.919 321 847.281 545C938.642 769 694.794 887 133 887" style="transform:translateX(120px) translateY(60px);stroke:#fbd951;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M847.281 138.795C609.187 118.789 133 268.431 133 466.885C133 714.954 755.919 321 847.281 545C938.642 769 694.794 887 133 887" style="transform:translateX(140px) translateY(70px);stroke:#fbdb5b;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M847.281 138.795C609.187 118.789 133 268.431 133 466.885C133 714.954 755.919 321 847.281 545C938.642 769 694.794 887 133 887" style="transform:translateX(160px) translateY(80px);stroke:#fcdd65;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M847.281 138.795C609.187 118.789 133 268.431 133 466.885C133 714.954 755.919 321 847.281 545C938.642 769 694.794 887 133 887" style="transform:translateX(180px) translateY(90px);stroke:#fce06f;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M847.281 138.795C609.187 118.789 133 268.431 133 466.885C133 714.954 755.919 321 847.281 545C938.642 769 694.794 887 133 887" style="transform:translateX(200px) translateY(100px);stroke:#fce279;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M847.281 138.795C609.187 118.789 133 268.431 133 466.885C133 714.954 755.919 321 847.281 545C938.642 769 694.794 887 133 887" style="transform:translateX(220px) translateY(110px);stroke:#fce483;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M847.281 138.795C609.187 118.789 133 268.431 133 466.885C133 714.954 755.919 321 847.281 545C938.642 769 694.794 887 133 887" style="transform:translateX(240px) translateY(120px);stroke:#fde68d;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M847.281 138.795C609.187 118.789 133 268.431 133 466.885C133 714.954 755.919 321 847.281 545C938.642 769 694.794 887 133 887" style="transform:translateX(260px) translateY(130px);stroke:#fde897;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M847.281 138.795C609.187 118.789 133 268.431 133 466.885C133 714.954 755.919 321 847.281 545C938.642 769 694.794 887 133 887" style="transform:translateX(280px) translateY(140px);stroke:#fdeaa1;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M847.281 138.795C609.187 118.789 133 268.431 133 466.885C133 714.954 755.919 321 847.281 545C938.642 769 694.794 887 133 887" style="transform:translateX(300px) translateY(150px);stroke:#fdedab;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M847.281 138.795C609.187 118.789 133 268.431 133 466.885C133 714.954 755.919 321 847.281 545C938.642 769 694.794 887 133 887" style="transform:translateX(320px) translateY(160px);stroke:#fdefb5;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M847.281 138.795C609.187 118.789 133 268.431 133 466.885C133 714.954 755.919 321 847.281 545C938.642 769 694.794 887 133 887" style="transform:translateX(340px) translateY(170px);stroke:#fef1bf;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M847.281 138.795C609.187 118.789 133 268.431 133 466.885C133 714.954 755.919 321 847.281 545C938.642 769 694.794 887 133 887" style="transform:translateX(360px) translateY(180px);stroke:#fef3c9;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M847.281 138.795C609.187 118.789 133 268.431 133 466.885C133 714.954 755.919 321 847.281 545C938.642 769 694.794 887 133 887" style="transform:translateX(380px) translateY(190px);stroke:#fef5d3;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path></g><g><path d="M380.5 70.5C185.05 407.272 60.5 853.066 60.5 951C60.5 951 189.833 388 631.5 388C996.383 388 872 870.055 872 951" style="transform:translateX(0px) translateY(0px);stroke:#facc15;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M380.5 70.5C185.05 407.272 60.5 853.066 60.5 951C60.5 951 189.833 388 631.5 388C996.383 388 872 870.055 872 951" style="transform:translateX(20px) translateY(10px);stroke:#face1f;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M380.5 70.5C185.05 407.272 60.5 853.066 60.5 951C60.5 951 189.833 388 631.5 388C996.383 388 872 870.055 872 951" style="transform:translateX(40px) translateY(20px);stroke:#fad029;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M380.5 70.5C185.05 407.272 60.5 853.066 60.5 951C60.5 951 189.833 388 631.5 388C996.383 388 872 870.055 872 951" style="transform:translateX(60px) translateY(30px);stroke:#fbd333;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M380.5 70.5C185.05 407.272 60.5 853.066 60.5 951C60.5 951 189.833 388 631.5 388C996.383 388 872 870.055 872 951" style="transform:translateX(80px) translateY(40px);stroke:#fbd53d;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M380.5 70.5C185.05 407.272 60.5 853.066 60.5 951C60.5 951 189.833 388 631.5 388C996.383 388 872 870.055 872 951" style="transform:translateX(100px) translateY(50px);stroke:#fbd747;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M380.5 70.5C185.05 407.272 60.5 853.066 60.5 951C60.5 951 189.833 388 631.5 388C996.383 388 872 870.055 872 951" style="transform:translateX(120px) translateY(60px);stroke:#fbd951;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M380.5 70.5C185.05 407.272 60.5 853.066 60.5 951C60.5 951 189.833 388 631.5 388C996.383 388 872 870.055 872 951" style="transform:translateX(140px) translateY(70px);stroke:#fbdb5b;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M380.5 70.5C185.05 407.272 60.5 853.066 60.5 951C60.5 951 189.833 388 631.5 388C996.383 388 872 870.055 872 951" style="transform:translateX(160px) translateY(80px);stroke:#fcdd65;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M380.5 70.5C185.05 407.272 60.5 853.066 60.5 951C60.5 951 189.833 388 631.5 388C996.383 388 872 870.055 872 951" style="transform:translateX(180px) translateY(90px);stroke:#fce06f;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M380.5 70.5C185.05 407.272 60.5 853.066 60.5 951C60.5 951 189.833 388 631.5 388C996.383 388 872 870.055 872 951" style="transform:translateX(200px) translateY(100px);stroke:#fce279;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M380.5 70.5C185.05 407.272 60.5 853.066 60.5 951C60.5 951 189.833 388 631.5 388C996.383 388 872 870.055 872 951" style="transform:translateX(220px) translateY(110px);stroke:#fce483;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M380.5 70.5C185.05 407.272 60.5 853.066 60.5 951C60.5 951 189.833 388 631.5 388C996.383 388 872 870.055 872 951" style="transform:translateX(240px) translateY(120px);stroke:#fde68d;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M380.5 70.5C185.05 407.272 60.5 853.066 60.5 951C60.5 951 189.833 388 631.5 388C996.383 388 872 870.055 872 951" style="transform:translateX(260px) translateY(130px);stroke:#fde897;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M380.5 70.5C185.05 407.272 60.5 853.066 60.5 951C60.5 951 189.833 388 631.5 388C996.383 388 872 870.055 872 951" style="transform:translateX(280px) translateY(140px);stroke:#fdeaa1;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M380.5 70.5C185.05 407.272 60.5 853.066 60.5 951C60.5 951 189.833 388 631.5 388C996.383 388 872 870.055 872 951" style="transform:translateX(300px) translateY(150px);stroke:#fdedab;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M380.5 70.5C185.05 407.272 60.5 853.066 60.5 951C60.5 951 189.833 388 631.5 388C996.383 388 872 870.055 872 951" style="transform:translateX(320px) translateY(160px);stroke:#fdefb5;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M380.5 70.5C185.05 407.272 60.5 853.066 60.5 951C60.5 951 189.833 388 631.5 388C996.383 388 872 870.055 872 951" style="transform:translateX(340px) translateY(170px);stroke:#fef1bf;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M380.5 70.5C185.05 407.272 60.5 853.066 60.5 951C60.5 951 189.833 388 631.5 388C996.383 388 872 870.055 872 951" style="transform:translateX(360px) translateY(180px);stroke:#fef3c9;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M380.5 70.5C185.05 407.272 60.5 853.066 60.5 951C60.5 951 189.833 388 631.5 388C996.383 388 872 870.055 872 951" style="transform:translateX(380px) translateY(190px);stroke:#fef5d3;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path></g><g><path d="M517.313 283C365.292 469.303 130.99 855.406 409.952 909.397C565.705 939.542 750.254 907.992 768 859" style="transform:translateX(0px) translateY(0px);stroke:#facc15;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M517.313 283C365.292 469.303 130.99 855.406 409.952 909.397C565.705 939.542 750.254 907.992 768 859" style="transform:translateX(20px) translateY(10px);stroke:#face1f;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M517.313 283C365.292 469.303 130.99 855.406 409.952 909.397C565.705 939.542 750.254 907.992 768 859" style="transform:translateX(40px) translateY(20px);stroke:#fad029;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M517.313 283C365.292 469.303 130.99 855.406 409.952 909.397C565.705 939.542 750.254 907.992 768 859" style="transform:translateX(60px) translateY(30px);stroke:#fbd333;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M517.313 283C365.292 469.303 130.99 855.406 409.952 909.397C565.705 939.542 750.254 907.992 768 859" style="transform:translateX(80px) translateY(40px);stroke:#fbd53d;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M517.313 283C365.292 469.303 130.99 855.406 409.952 909.397C565.705 939.542 750.254 907.992 768 859" style="transform:translateX(100px) translateY(50px);stroke:#fbd747;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M517.313 283C365.292 469.303 130.99 855.406 409.952 909.397C565.705 939.542 750.254 907.992 768 859" style="transform:translateX(120px) translateY(60px);stroke:#fbd951;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M517.313 283C365.292 469.303 130.99 855.406 409.952 909.397C565.705 939.542 750.254 907.992 768 859" style="transform:translateX(140px) translateY(70px);stroke:#fbdb5b;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M517.313 283C365.292 469.303 130.99 855.406 409.952 909.397C565.705 939.542 750.254 907.992 768 859" style="transform:translateX(160px) translateY(80px);stroke:#fcdd65;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M517.313 283C365.292 469.303 130.99 855.406 409.952 909.397C565.705 939.542 750.254 907.992 768 859" style="transform:translateX(180px) translateY(90px);stroke:#fce06f;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M517.313 283C365.292 469.303 130.99 855.406 409.952 909.397C565.705 939.542 750.254 907.992 768 859" style="transform:translateX(200px) translateY(100px);stroke:#fce279;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M517.313 283C365.292 469.303 130.99 855.406 409.952 909.397C565.705 939.542 750.254 907.992 768 859" style="transform:translateX(220px) translateY(110px);stroke:#fce483;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M517.313 283C365.292 469.303 130.99 855.406 409.952 909.397C565.705 939.542 750.254 907.992 768 859" style="transform:translateX(240px) translateY(120px);stroke:#fde68d;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M517.313 283C365.292 469.303 130.99 855.406 409.952 909.397C565.705 939.542 750.254 907.992 768 859" style="transform:translateX(260px) translateY(130px);stroke:#fde897;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M517.313 283C365.292 469.303 130.99 855.406 409.952 909.397C565.705 939.542 750.254 907.992 768 859" style="transform:translateX(280px) translateY(140px);stroke:#fdeaa1;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M517.313 283C365.292 469.303 130.99 855.406 409.952 909.397C565.705 939.542 750.254 907.992 768 859" style="transform:translateX(300px) translateY(150px);stroke:#fdedab;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M517.313 283C365.292 469.303 130.99 855.406 409.952 909.397C565.705 939.542 750.254 907.992 768 859" style="transform:translateX(320px) translateY(160px);stroke:#fdefb5;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M517.313 283C365.292 469.303 130.99 855.406 409.952 909.397C565.705 939.542 750.254 907.992 768 859" style="transform:translateX(340px) translateY(170px);stroke:#fef1bf;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M517.313 283C365.292 469.303 130.99 855.406 409.952 909.397C565.705 939.542 750.254 907.992 768 859" style="transform:translateX(360px) translateY(180px);stroke:#fef3c9;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M517.313 283C365.292 469.303 130.99 855.406 409.952 909.397C565.705 939.542 750.254 907.992 768 859" style="transform:translateX(380px) translateY(190px);stroke:#fef5d3;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M555.638 153.706C652.47 179.745 714.114 262.716 693.636 338.87C673.157 415.024 578.213 455.887 481.38 429.848C384.548 403.809 322.904 320.837 343.383 244.683C363.862 168.529 458.806 127.667 555.638 153.706Z" style="transform:translateX(0px) translateY(0px);stroke:#facc15;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M555.638 153.706C652.47 179.745 714.114 262.716 693.636 338.87C673.157 415.024 578.213 455.887 481.38 429.848C384.548 403.809 322.904 320.837 343.383 244.683C363.862 168.529 458.806 127.667 555.638 153.706Z" style="transform:translateX(20px) translateY(10px);stroke:#face1f;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M555.638 153.706C652.47 179.745 714.114 262.716 693.636 338.87C673.157 415.024 578.213 455.887 481.38 429.848C384.548 403.809 322.904 320.837 343.383 244.683C363.862 168.529 458.806 127.667 555.638 153.706Z" style="transform:translateX(40px) translateY(20px);stroke:#fad029;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M555.638 153.706C652.47 179.745 714.114 262.716 693.636 338.87C673.157 415.024 578.213 455.887 481.38 429.848C384.548 403.809 322.904 320.837 343.383 244.683C363.862 168.529 458.806 127.667 555.638 153.706Z" style="transform:translateX(60px) translateY(30px);stroke:#fbd333;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M555.638 153.706C652.47 179.745 714.114 262.716 693.636 338.87C673.157 415.024 578.213 455.887 481.38 429.848C384.548 403.809 322.904 320.837 343.383 244.683C363.862 168.529 458.806 127.667 555.638 153.706Z" style="transform:translateX(80px) translateY(40px);stroke:#fbd53d;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M555.638 153.706C652.47 179.745 714.114 262.716 693.636 338.87C673.157 415.024 578.213 455.887 481.38 429.848C384.548 403.809 322.904 320.837 343.383 244.683C363.862 168.529 458.806 127.667 555.638 153.706Z" style="transform:translateX(100px) translateY(50px);stroke:#fbd747;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M555.638 153.706C652.47 179.745 714.114 262.716 693.636 338.87C673.157 415.024 578.213 455.887 481.38 429.848C384.548 403.809 322.904 320.837 343.383 244.683C363.862 168.529 458.806 127.667 555.638 153.706Z" style="transform:translateX(120px) translateY(60px);stroke:#fbd951;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M555.638 153.706C652.47 179.745 714.114 262.716 693.636 338.87C673.157 415.024 578.213 455.887 481.38 429.848C384.548 403.809 322.904 320.837 343.383 244.683C363.862 168.529 458.806 127.667 555.638 153.706Z" style="transform:translateX(140px) translateY(70px);stroke:#fbdb5b;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M555.638 153.706C652.47 179.745 714.114 262.716 693.636 338.87C673.157 415.024 578.213 455.887 481.38 429.848C384.548 403.809 322.904 320.837 343.383 244.683C363.862 168.529 458.806 127.667 555.638 153.706Z" style="transform:translateX(160px) translateY(80px);stroke:#fcdd65;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M555.638 153.706C652.47 179.745 714.114 262.716 693.636 338.87C673.157 415.024 578.213 455.887 481.38 429.848C384.548 403.809 322.904 320.837 343.383 244.683C363.862 168.529 458.806 127.667 555.638 153.706Z" style="transform:translateX(180px) translateY(90px);stroke:#fce06f;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M555.638 153.706C652.47 179.745 714.114 262.716 693.636 338.87C673.157 415.024 578.213 455.887 481.38 429.848C384.548 403.809 322.904 320.837 343.383 244.683C363.862 168.529 458.806 127.667 555.638 153.706Z" style="transform:translateX(200px) translateY(100px);stroke:#fce279;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M555.638 153.706C652.47 179.745 714.114 262.716 693.636 338.87C673.157 415.024 578.213 455.887 481.38 429.848C384.548 403.809 322.904 320.837 343.383 244.683C363.862 168.529 458.806 127.667 555.638 153.706Z" style="transform:translateX(220px) translateY(110px);stroke:#fce483;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M555.638 153.706C652.47 179.745 714.114 262.716 693.636 338.87C673.157 415.024 578.213 455.887 481.38 429.848C384.548 403.809 322.904 320.837 343.383 244.683C363.862 168.529 458.806 127.667 555.638 153.706Z" style="transform:translateX(240px) translateY(120px);stroke:#fde68d;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M555.638 153.706C652.47 179.745 714.114 262.716 693.636 338.87C673.157 415.024 578.213 455.887 481.38 429.848C384.548 403.809 322.904 320.837 343.383 244.683C363.862 168.529 458.806 127.667 555.638 153.706Z" style="transform:translateX(260px) translateY(130px);stroke:#fde897;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M555.638 153.706C652.47 179.745 714.114 262.716 693.636 338.87C673.157 415.024 578.213 455.887 481.38 429.848C384.548 403.809 322.904 320.837 343.383 244.683C363.862 168.529 458.806 127.667 555.638 153.706Z" style="transform:translateX(280px) translateY(140px);stroke:#fdeaa1;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M555.638 153.706C652.47 179.745 714.114 262.716 693.636 338.87C673.157 415.024 578.213 455.887 481.38 429.848C384.548 403.809 322.904 320.837 343.383 244.683C363.862 168.529 458.806 127.667 555.638 153.706Z" style="transform:translateX(300px) translateY(150px);stroke:#fdedab;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M555.638 153.706C652.47 179.745 714.114 262.716 693.636 338.87C673.157 415.024 578.213 455.887 481.38 429.848C384.548 403.809 322.904 320.837 343.383 244.683C363.862 168.529 458.806 127.667 555.638 153.706Z" style="transform:translateX(320px) translateY(160px);stroke:#fdefb5;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M555.638 153.706C652.47 179.745 714.114 262.716 693.636 338.87C673.157 415.024 578.213 455.887 481.38 429.848C384.548 403.809 322.904 320.837 343.383 244.683C363.862 168.529 458.806 127.667 555.638 153.706Z" style="transform:translateX(340px) translateY(170px);stroke:#fef1bf;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M555.638 153.706C652.47 179.745 714.114 262.716 693.636 338.87C673.157 415.024 578.213 455.887 481.38 429.848C384.548 403.809 322.904 320.837 343.383 244.683C363.862 168.529 458.806 127.667 555.638 153.706Z" style="transform:translateX(360px) translateY(180px);stroke:#fef3c9;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M555.638 153.706C652.47 179.745 714.114 262.716 693.636 338.87C673.157 415.024 578.213 455.887 481.38 429.848C384.548 403.809 322.904 320.837 343.383 244.683C363.862 168.529 458.806 127.667 555.638 153.706Z" style="transform:translateX(380px) translateY(190px);stroke:#fef5d3;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path></g><g><path d="M629.651 83.7223C562.066 220.318 242.6046 719.067 392.019 892.12C541.434 1065.17 983.666 887.599 1069.414 838.144M1045.751 394.206C872.574 420.309 355.345 417.885 218.2513 288.496" style="transform:translateX(0px) translateY(0px);stroke:#facc15;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M629.651 83.7223C562.066 220.318 242.6046 719.067 392.019 892.12C541.434 1065.17 983.666 887.599 1069.414 838.144M1045.751 394.206C872.574 420.309 355.345 417.885 218.2513 288.496" style="transform:translateX(20px) translateY(10px);stroke:#face1f;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M629.651 83.7223C562.066 220.318 242.6046 719.067 392.019 892.12C541.434 1065.17 983.666 887.599 1069.414 838.144M1045.751 394.206C872.574 420.309 355.345 417.885 218.2513 288.496" style="transform:translateX(40px) translateY(20px);stroke:#fad029;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M629.651 83.7223C562.066 220.318 242.6046 719.067 392.019 892.12C541.434 1065.17 983.666 887.599 1069.414 838.144M1045.751 394.206C872.574 420.309 355.345 417.885 218.2513 288.496" style="transform:translateX(60px) translateY(30px);stroke:#fbd333;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M629.651 83.7223C562.066 220.318 242.6046 719.067 392.019 892.12C541.434 1065.17 983.666 887.599 1069.414 838.144M1045.751 394.206C872.574 420.309 355.345 417.885 218.2513 288.496" style="transform:translateX(80px) translateY(40px);stroke:#fbd53d;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M629.651 83.7223C562.066 220.318 242.6046 719.067 392.019 892.12C541.434 1065.17 983.666 887.599 1069.414 838.144M1045.751 394.206C872.574 420.309 355.345 417.885 218.2513 288.496" style="transform:translateX(100px) translateY(50px);stroke:#fbd747;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M629.651 83.7223C562.066 220.318 242.6046 719.067 392.019 892.12C541.434 1065.17 983.666 887.599 1069.414 838.144M1045.751 394.206C872.574 420.309 355.345 417.885 218.2513 288.496" style="transform:translateX(120px) translateY(60px);stroke:#fbd951;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M629.651 83.7223C562.066 220.318 242.6046 719.067 392.019 892.12C541.434 1065.17 983.666 887.599 1069.414 838.144M1045.751 394.206C872.574 420.309 355.345 417.885 218.2513 288.496" style="transform:translateX(140px) translateY(70px);stroke:#fbdb5b;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M629.651 83.7223C562.066 220.318 242.6046 719.067 392.019 892.12C541.434 1065.17 983.666 887.599 1069.414 838.144M1045.751 394.206C872.574 420.309 355.345 417.885 218.2513 288.496" style="transform:translateX(160px) translateY(80px);stroke:#fcdd65;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M629.651 83.7223C562.066 220.318 242.6046 719.067 392.019 892.12C541.434 1065.17 983.666 887.599 1069.414 838.144M1045.751 394.206C872.574 420.309 355.345 417.885 218.2513 288.496" style="transform:translateX(180px) translateY(90px);stroke:#fce06f;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M629.651 83.7223C562.066 220.318 242.6046 719.067 392.019 892.12C541.434 1065.17 983.666 887.599 1069.414 838.144M1045.751 394.206C872.574 420.309 355.345 417.885 218.2513 288.496" style="transform:translateX(200px) translateY(100px);stroke:#fce279;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M629.651 83.7223C562.066 220.318 242.6046 719.067 392.019 892.12C541.434 1065.17 983.666 887.599 1069.414 838.144M1045.751 394.206C872.574 420.309 355.345 417.885 218.2513 288.496" style="transform:translateX(220px) translateY(110px);stroke:#fce483;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M629.651 83.7223C562.066 220.318 242.6046 719.067 392.019 892.12C541.434 1065.17 983.666 887.599 1069.414 838.144M1045.751 394.206C872.574 420.309 355.345 417.885 218.2513 288.496" style="transform:translateX(240px) translateY(120px);stroke:#fde68d;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M629.651 83.7223C562.066 220.318 242.6046 719.067 392.019 892.12C541.434 1065.17 983.666 887.599 1069.414 838.144M1045.751 394.206C872.574 420.309 355.345 417.885 218.2513 288.496" style="transform:translateX(260px) translateY(130px);stroke:#fde897;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M629.651 83.7223C562.066 220.318 242.6046 719.067 392.019 892.12C541.434 1065.17 983.666 887.599 1069.414 838.144M1045.751 394.206C872.574 420.309 355.345 417.885 218.2513 288.496" style="transform:translateX(280px) translateY(140px);stroke:#fdeaa1;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M629.651 83.7223C562.066 220.318 242.6046 719.067 392.019 892.12C541.434 1065.17 983.666 887.599 1069.414 838.144M1045.751 394.206C872.574 420.309 355.345 417.885 218.2513 288.496" style="transform:translateX(300px) translateY(150px);stroke:#fdedab;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M629.651 83.7223C562.066 220.318 242.6046 719.067 392.019 892.12C541.434 1065.17 983.666 887.599 1069.414 838.144M1045.751 394.206C872.574 420.309 355.345 417.885 218.2513 288.496" style="transform:translateX(320px) translateY(160px);stroke:#fdefb5;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M629.651 83.7223C562.066 220.318 242.6046 719.067 392.019 892.12C541.434 1065.17 983.666 887.599 1069.414 838.144M1045.751 394.206C872.574 420.309 355.345 417.885 218.2513 288.496" style="transform:translateX(340px) translateY(170px);stroke:#fef1bf;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M629.651 83.7223C562.066 220.318 242.6046 719.067 392.019 892.12C541.434 1065.17 983.666 887.599 1069.414 838.144M1045.751 394.206C872.574 420.309 355.345 417.885 218.2513 288.496" style="transform:translateX(360px) translateY(180px);stroke:#fef3c9;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path><path d="M629.651 83.7223C562.066 220.318 242.6046 719.067 392.019 892.12C541.434 1065.17 983.666 887.599 1069.414 838.144M1045.751 394.206C872.574 420.309 355.345 417.885 218.2513 288.496" style="transform:translateX(380px) translateY(190px);stroke:#fef5d3;opacity:0;stroke-dasharray:0, 10000;stroke-dashoffset:0"></path></g></g></svg></div><div><p>completely un-</p><p>affiliated with these AI alignment organizations:</p><p>but our design agency said their logos would look good on our site</p></div><section aria-live="polite"><p>Until our next prediction of when AGI is coming</p></section><div><header><h2>Updates</h2></header></div><div id="subscribe"><h2>250,000 AI agents and 3 humans read our newsletter</h2><p>Join them:</p></div><div><header><h2>Reports</h2></header></div><div id="about"><header><h2>About CAAAC</h2></header><div><p>At the forefront of AI thought thought leadership leadership</p><p>We're constantly thinking about AI so that politicians and journalists don't have to.</p><p>Fiercely independent, we are backed by philanthropic funding from some of the world's biggest AI companies who also form a majority on our board. This allows us to deliver policy solutions and legislation that can be implemented rapidly by lawmakers without the delay of democratic scrutiny, unless Trump has told them to stop regulating AI in which case our work is totally pointless.</p></div></div><div><header><p>New</p><h2>Start your own AI center in under 60 seconds</h2><p>We're excited to open source<!-- --> <span>CenterGen-4o</span>, the powerful tool behind the creation of CAAAC.</p><p>CenterGen uses generative AI to set you up as the Executive Director of a brand new AI center in less than a minute, zero AI knowledge required.</p></header><div><h3>Choose an organization type:</h3></div></div><div id="subscribe"><h2>Every second you don't subscribe, another potential future human life is lost</h2><p>Stop being a mass murderer:</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Reshaped is now open source (247 pts)]]></title>
            <link>https://reshaped.so/blog/reshaped-oss</link>
            <guid>45209558</guid>
            <pubDate>Thu, 11 Sep 2025 09:32:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://reshaped.so/blog/reshaped-oss">https://reshaped.so/blog/reshaped-oss</a>, See on <a href="https://news.ycombinator.com/item?id=45209558">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p data-article-type="paragraph"><span>About five years ago, I started Reshaped.
I built it for myself, since I had a few projects in urgent need of a component library for both React and Figma.
Having worked in the design systems space for over a decade, I had developed a clear sense of what a good design system should be — and what tends to go wrong in others.</span></p>
<p data-article-type="paragraph"><span>I noticed that no matter how trends evolve, around 80% of the web is still built on the same core design practices.
So I set out to build a system that covers that 80%, while giving developers the flexibility to handle the last 20% with low-level utilities.
From the start, I didn’t want to focus only on accessibility or only on design.
Instead, I prioritized alignment between design and engineering, while also solving common UI challenges like theming, dark mode, and micro-animations.</span></p>
<p data-article-type="paragraph"><span>To keep the project sustainable, I made it a paid product: one-time licenses for individuals, and source code licenses for larger teams.
This allowed me to focus on supporting a smaller community and dive deeply into every bug report and feature request.</span></p>
<p data-article-type="paragraph"><span>While this model kept me motivated and financially supported, I always hoped to remove the paywall one day.</span></p>
<p data-article-type="paragraph"><span>Two years ago, I took the first step by making the React package free.
That unlocked new possibilities—not only did indie developers gain free access, but teams using Reshaped with source code licenses could now install it directly from npm.</span></p>

<div><p><img src="https://reshaped.so/img/blog/og-reshaped-oss.png" alt="" role="presentation"></p></div>
<p data-article-type="paragraph"><span>Today, I’m taking the next step: making all of Reshaped fully open source. The React library source code is now on <a target="_blank" href="https://github.com/reshaped-ui/reshaped">GitHub</a> and the Figma library is available in the <a target="_blank" href="https://www.figma.com/community/file/1546133815088483407">Figma Community</a>.
I’m especially excited because Reshaped bridges both design and engineering, and I hope it helps both communities learn best practices for building design systems that scale while staying minimal.</span></p>
<p data-article-type="paragraph"><span>Making both libraries public also opens the door for me to share more behind-the-scenes work as new features roll out.
I think this is particularly valuable when it comes to integration with other tools.
Imagine Figma or React releasing new features – you’ll be able to see how they’re implemented in Reshaped before you even need to migrate your company’s design system.</span></p>

<ul data-article-type="list">
<li>Reshaped component libraries will continue to grow.
Everyone who purchased licenses in the past will still get full access to future updates, and we’ll keep chatting through the same channels.
Nothing changes there.</li>
<li>I’m also interested in taking Reshaped further by introducing more complex, opinionated premium components on top of the core library.
Not “50 landing page layouts,” but advanced components that require sophisticated CSS and React logic.</li>
</ul>
<p data-article-type="paragraph"><span>This is a leap of faith for me after five years of working closed-source.
It feels like the right time to give everything back to the community—and to have some fun along the way ❤️</span></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Samsung taking market share from Apple in U.S. as foldable phones gain momentum (127 pts)]]></title>
            <link>https://www.cnbc.com/2025/08/16/samsungs-us-market-share-apple-rivalry-foldable-phones.html</link>
            <guid>45209389</guid>
            <pubDate>Thu, 11 Sep 2025 09:02:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnbc.com/2025/08/16/samsungs-us-market-share-apple-rivalry-foldable-phones.html">https://www.cnbc.com/2025/08/16/samsungs-us-market-share-apple-rivalry-foldable-phones.html</a>, See on <a href="https://news.ycombinator.com/item?id=45209389">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="RegularArticle-ArticleBody-5" data-module="ArticleBody" data-test="articleBody-2" data-analytics="RegularArticle-articleBody-5-2"><div><p>In 2014, <span data-test="QuoteInBody" id="RegularArticle-QuoteInBody-1"><a href="https://www.cnbc.com/quotes/AAPL/">Apple</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span> and Samsung were duking it out to rule the U.S. smartphone market. Samsung was selling devices with large screens, and iPhone fans were demanding a response.</p><p>It took Apple some time, but the company finally released the iPhone 6, breaking with previous iterations and giving consumers a large-screen option. The iPhone won.</p><p>But more than a decade later, recent smartphone sales and shipment figures signal that the Apple-Samsung fight has returned.&nbsp;And once again, it's all about the screen.</p><p>In the second quarter, shipments from Samsung surged in the U.S., with its market share rising from 23% to 31% from the prior period, according to data from<a href="https://www.canalys.com/newsroom/us-smartphone-market-q2-2025" target="_blank"> Canalys</a>. Apple's market share during the quarter declined to 49% from 56%.</p><p>Apple remains on top of the U.S. smartphone market, taking the majority of new smartphone sales in the U.S. It's often in second place around the world, but the recent slips points to turbulence for Apple for the first time in well over a decade.</p><p>That's one reason investors have sent Apple shares down 7.5% this year, underperforming all of the U.S. megacap tech companies other than <span data-test="QuoteInBody" id="RegularArticle-QuoteInBody-3"><a href="https://www.cnbc.com/quotes/TSLA/">Tesla</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span>. Samsung's stock, meanwhile, is up about 35% in 2025.</p><p>Apple reported a 13% increase in year-over-year iPhone sales in its July <a href="https://www.cnbc.com/2025/07/31/apple-aapl-q3-earnings-report-2025.html#:~:text=Here's%20how%20Apple%20did%20versus,billion%20vs.%20%2489.53%20billion%20expected">earnings</a>.</p><p><a href="https://www.cnbc.com/2025/07/09/samsung-galaxy-z-fold-flip-7-fe-foldable-phones.htmla">In July,</a> Samsung introduced a pair of innovative new phones that feature foldable screens. One model, the Z Fold 7, can effectively turn into a tablet, while the Z Flip resembles an old-school flip phone with modern smartphone features. They were added to Samsung's catalog of phones released this spring under its Galaxy brand, including a thin-and-light phone called the Galaxy S25 Edge.&nbsp;</p><p>The devices are also getting a lot of traction on social media, particularly around durability tests.</p><p>One user posted a livestream that showed him bending the Z Fold 7 over 200,000 times in a row. The video has been clipped and shared widely on social media, with one version of the clip accumulating more than 15 million views on YouTube.</p><p>In the past month, Samsung's premium devices, including the Z Fold 7, were mentioned over 50,000 times on social media, and 83% of those mentions were positive or neutral, according to data from Sprout Social, a social media analytics company.</p></div><div><p id="RegularArticle-DataWrapperChart"><iframe width="560" height="315" src="https://www.youtube.com/embed/59JMn0ShaJ0" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p></div><div><p>The market share numbers aren't just the result of user preferences. Much of the shift in shipment figures in the June quarter, analysts said, can be attributed to tariffs, which are causing "disruption" in the industry as smartphone makers use different strategies to minimize the impact on their business.</p><p>But Samsung's gains also reflect the company's ability to offer a much wider range of products at different prices compared to Apple. That includes low-end phones, which accounted for much of Samsung's second-quarter U.S. improvement, as well as high-end devices that cost more than any individual iPhone.</p><p>Samsung's Galaxy and Z phone lineup "stretches from $650 up to $2,400. That is a massive span of devices," said Canalys analyst Runar Bjorhovde.<strong> </strong>"There is an idea that you can target people at every single price point, and you can meet them at every spot."</p><p>The iPhone has pretty much looked the same since 2017 — a rectangular piece of glass with a touchscreen on the front, and a few cameras on the back. These days, the company offers a series of four slates ranging from $829 to $1,599. Samsung and others are starting to go beyond the so-called candy bar shape and experimenting with new form factors.</p><p>Apple is expected to start doing the same — beginning with a potential launch next month of a slimmer iPhone that will compete with Samsung's Galaxy Edge.</p><p>"Apple is clearly betting that its 5.5mm Air model is going to lift its fortunes as testing suggests a strong desire for the new form factor," wrote Loop Capital managing director John Donovan in May.</p><p>JPMorgan Chase analyst Samik Chatterjee wrote <a href="https://www.cnbc.com/2025/07/29/apple-likely-to-launch-foldable-iphone-in-september-2026-predicts-jpmorgan.html">in a report last month</a> that Apple may release a folding phone next year to compete with Samsung's Z Fold.</p><p>"Investor focus has already turned to the 2026 fall launches with Apple expected to launch its first foldable iPhone as part of the iPhone 18 lineup in September 2026," Chatterjee wrote.</p><p>Trying new form factors offers Apple the opportunity to sell devices at higher prices, according to Bjorhovde.</p><p>Apple's most expensive phone, the<a href="https://www.apple.com/shop/buy-iphone/iphone-16-pro" target="_blank"> iPhone 16 Pro Max</a>, currently starts at $1,199 for 256GB of storage and can go up to $1,599 for a version with 1TB of storage. The Samsung Galaxy Z Fold 7, which was announced last week, starts at $1,999 for the 256GB version and tops out at $2,419 for the 1TB version.</p><p>Chatterjee said he thinks Apple's version of a folding phone could start at $1,999. </p></div><div id="ArticleBody-InlineImage-108169555" data-test="InlineImage"><p>A person holds a Samsung Galaxy Z Fold 7 phone during an event in New York, U.S., July 8, 2025. </p><p>Jeenah Moon | Reuters</p></div><h2><a id="headline0"></a>Folding phones finally mature</h2><div><p>Samsung's first folding phone was released in 2019, but got off to a rocky start. The initial launch was delayed after reviewers — <a href="https://www.cnbc.com/video/2019/04/17/samsung-galaxy-fold-broken-after-two-days-of-use.html">including CNBC</a> — discovered that the early devices would break along their folding crease.</p><p>But Samsung says this time is different, and that folding phones are finally ready to go mainstream, especially with respect to durability.</p><p>"There really are no longer trade-offs towards owning a foldable device," said Drew Blackard, vice president of mobile product management at Samsung Electronics America.</p><p>The South Korean company doesn't provide sales numbers, but Blackard said the Galaxy Z Fold 7, the latest version, had 25% more preorders than any previous Samsung folding phone and that sales are outpacing the device's predecessor by<a href="https://news.samsung.com/us/galaxy-z-fold7-achieves-record-breaking-milestone-in-the-us/" target="_blank"> nearly 50%</a>.</p><p>"Samsung with the foldable is able to actually optimize for innovation," said Bjorhovde<strong>. "</strong>Try to be ahead, show that something is different, and there's a certain halo effect from that."</p><p>According to Counterpoint Research, a firm that estimates smartphone sales to customers, Samsung's sell-through increased 16% during the June quarter, thanks to demand for high-end devices, including a "slight boost" from the slim S25 Edge.</p><p>The rise of artificial intelligence is also heralding new form factors for consumer electronics that could one day replace the iPhone.</p><p>OpenAI in May <a href="https://www.cnbc.com/2025/05/21/openai-buys-iphone-designer-jony-ive-device-startup-for-6point4-billion.html">acquired</a> the startup of former Apple design guru Jony Ive for $6.5 billion. The AI startup plans to develop the next generation of hardware, and other AI startups have released <a href="https://www.theverge.com/24126502/humane-ai-pin-review" target="_blank">pins</a>, pendants and <a href="https://www.cnbc.com/2025/07/28/ray-ban-meta-revenue-tripled-essilorluxottica.html#:~:text=EssilorLuxottica%20said%20the%20success%20of,smart%20glasses%20in%20the%20future.">glasses</a> that rely on users' voice to control the devices.</p><p>Samsung devices, as well as other Android phones, get access to <span data-test="QuoteInBody" id="RegularArticle-QuoteInBody-13"><a href="https://www.cnbc.com/quotes/GOOGL/">Google's</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span> Gemini, which is widely considered to be one of the best AI models alongside OpenAI's ChatGPT. Gemini has several features that users can't get with Siri and Apple Intelligence.</p><p>Blackard said folding phones, with their larger displays, are well suited for AI. Google's circle-to-search feature, which allows a user to simply circle something on the screen that they'd like to learn more about, is an example, Blackard said.</p><p>On a Samsung folding phone, he said, users can still see the original screen with the content they circled, as well as another screen with supplementary information.</p><p>"It's much more productive being able to go back and forth," Blackard said.</p><p>Investors have worried that Apple's AI delays, including its next-generation Siri that's now scheduled to come out next year, could start hurting sales. <a href="https://www.cnbc.com/2025/07/30/apple-ai-hardware-devices.html">But many analysts say</a> that Apple's brand loyalty and lock-in will give it a period of years before iPhone customers start defecting for competitors.</p><p>Chatterjee told CNBC that Apple's strategy with devices is to wait until a technology is ready for the mainstream before embracing it. That time may be now for foldable devices.</p><p>Apple has "never been about trying to be the first to market," Chatterjee said. "It's about being watchful, seeing a technology mature, knowing that there are no big roadblocks to that technology adoption, and then moving ahead."</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Germany is not supporting ChatControl – blocking minority secured (1012 pts)]]></title>
            <link>https://digitalcourage.social/@echo_pbreyer/115184350819592476</link>
            <guid>45209366</guid>
            <pubDate>Thu, 11 Sep 2025 08:59:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://digitalcourage.social/@echo_pbreyer/115184350819592476">https://digitalcourage.social/@echo_pbreyer/115184350819592476</a>, See on <a href="https://news.ycombinator.com/item?id=45209366">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[GrapheneOS accessed Android security patches but not allowed to publish sources (230 pts)]]></title>
            <link>https://grapheneos.social/@GrapheneOS/115164133992525834</link>
            <guid>45208925</guid>
            <pubDate>Thu, 11 Sep 2025 07:43:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://grapheneos.social/@GrapheneOS/115164133992525834">https://grapheneos.social/@GrapheneOS/115164133992525834</a>, See on <a href="https://news.ycombinator.com/item?id=45208925">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
    </channel>
</rss>