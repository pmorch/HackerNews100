<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 05 Feb 2026 08:30:04 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Don't rent the cloud, own instead (158 pts)]]></title>
            <link>https://blog.comma.ai/datacenter/</link>
            <guid>46896146</guid>
            <pubDate>Thu, 05 Feb 2026 05:50:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.comma.ai/datacenter/">https://blog.comma.ai/datacenter/</a>, See on <a href="https://news.ycombinator.com/item?id=46896146">Hacker News</a></p>
<div id="readability-page-1" class="page"><section itemprop="text"><p>These days it seems you need a trillion fake dollars, or lunch with politicians to get your own data center. They may help, but they’re not required. At comma we’ve been running our own data center for years. All of our model training, metrics, and data live in our own data center in our own office. Having your own data center is cool, and in this blog post I will describe how ours works, so you can be inspired to have your own data center too.</p>
<figure><picture> <source srcset="https://blog.comma.ai/img/datacenter/side_view2.webp" type="image/webp"> <img src="https://blog.comma.ai/img/datacenter/side_view2.png" alt=""> </picture><figcaption><p>Our data center</p></figcaption></figure><h2 id="why-no-cloud">Why no cloud?</h2>
<p>If your business relies on compute, and you run that compute in the cloud, you are putting a lot of trust in your cloud provider. Cloud companies generally make onboarding very easy, and offboarding very difficult. If you are not vigilant you will sleepwalk into a situation of high cloud costs and no way out. If you want to control your own destiny, you must run your own compute.</p>
<p>Self-reliance is great, but there are other benefits to running your own compute. It inspires good engineering. Maintaining a data center is much more about solving real-world challenges. The cloud requires expertise in company-specific APIs and billing systems. A data center requires knowledge of Watts, bits, and FLOPs. I know which one I rather think about.</p>
<p>Avoiding the cloud for ML also creates better incentives for engineers. Engineers generally want to improve things. In ML many problems go away by just using more compute. In the cloud that means improvements are just a budget increase away. This locks you into inefficient and expensive solutions. Instead, when all you have available is your current compute, the quickest improvements are usually speeding up your code, or fixing fundamental issues.</p>
<p>Finally there’s cost, owning a data center can be far cheaper than renting in the cloud. Especially if your compute or storage needs are fairly consistent, which tends to be true if you are in the business of training or running models. In comma’s case I estimate we’ve spent ~5M on our data center, and we would have spent 25M+ had we done the same things in the cloud.</p>
<h2 id="whats-all-needed">What’s all needed?</h2>
<p>Our data center is pretty simple. It’s maintained and built by only a couple engineers and technicians. Your needs may be slightly different, our implementation should provide useful context.</p>
<h3 id="power">Power</h3>
<p>To run servers you need power. We currently use about 450kW at max. Operating a data center exposes you to many fun engineering challenges, but procuring power is not one of them. San Diego power cost is over 40c/kWh, ~3x the global average. It’s a ripoff, and overpriced simply due to political dysfunction. We spent $540,112 on power in 2025, a big part of the data center cost. In a future blog post I hope I can tell you about how we produce our own power and you should too.</p>
<figure><picture> <source srcset="https://blog.comma.ai/img/datacenter/power.webp" type="image/webp"> <img src="https://blog.comma.ai/img/datacenter/power.png" alt=""> </picture><figcaption><p>data center power usage</p></figcaption></figure><h3 id="cooling">Cooling</h3>
<p>Data centers need cool dry air. Typically this is achieved with a CRAC system, but they are power-hungry. San Diego has a mild climate and we opted for pure outside air cooling. This gives us less control of the temperature and humidity, but uses only a couple dozen kW. We have dual 48” intake fans and dual 48” exhaust fans to keep the air cool. To ensure low humidity (&lt;45%) we use recirculating fans to mix hot exhaust air with the intake air. One server is connected to several sensors and runs a PID loop to control the fans to optimize the temperature and humidity.</p>
<figure><picture> <source srcset="https://blog.comma.ai/img/datacenter/air_cooling.webp" type="image/webp"> <img src="https://blog.comma.ai/img/datacenter/air_cooling.jpg" alt=""> </picture><figcaption><p>Filtered intake fan on right, 2 recirculating fans at the top</p></figcaption></figure><h3 id="servers">Servers</h3>
<p>The majority of our current compute is 600 GPUs in 75 <a href="https://tinycorp.myshopify.com/products/tinybox-pro-v2" target="_blank" rel="noopener noreferrer">TinyBox Pro machines</a>. They were built in-house, which saves us money and ensures they suit our needs. Our self-built machines fail at a similar rate to pre-built machines we’ve bought, but we’re capable of fixing them ourselves quickly. They have 2 CPUs and 8 GPUs each, and work as both training machines and general compute workers.</p>
<figure><picture> <source srcset="https://blog.comma.ai/img/datacenter/breakers.webp" type="image/webp"> <img src="https://blog.comma.ai/img/datacenter/breakers.jpg" alt=""> </picture><figcaption><p>Breaker panels for all the computers, that’s a lot of breakers!</p></figcaption></figure><p>For data storage we have a few racks of Dell machines (R630 and R730). They are filled with SSDs for a total of ~4PB of storage. We use SSDs for reliability and speed. Our main storage arrays have no redundancy and each node needs to be able to saturate the network bandwidth with random access reads. For the storage machines this means reading up to 20Gbps of each 80TB chunk.</p>
<p>Other than storage and compute machines we have several one-off machines to run services. This includes a router, climate controller, data ingestion machine, storage master servers, metric servers, redis servers, and a few more.</p>
<p>Running the network requires switches, but at this scale we don’t need to bother with complicated switch topologies. We have 3 100Gbps interconnected Z9264F switches, which serve as the main ethernet network. We have two more infiniband switches to interconnect the 2 tinybox pro groups for training all-reduce.</p>
<h3 id="the-software">The software</h3>
<p>To effectively use all these compute and storage machines you need some infra. At this scale, services don’t need redundancy to achieve 99% uptime. We use a single master for all services, which makes things pretty simple.</p>
<h5 id="setup">Setup</h5>
<p>All servers get ubuntu installed with pxeboot and are managed by <a href="https://github.com/saltstack/salt" target="_blank" rel="noopener noreferrer">salt</a>.</p>
<h5 id="distributed-storage-minikeyvalue">Distributed storage: minikeyvalue</h5>
<p>All of our storage arrays use <a href="https://github.com/commaai/minikeyvalue/tree/prod" target="_blank" rel="noopener noreferrer">mkv</a>. The main array is 3PB of non-redundant storage hosting our driving data we train on. We can read from this array at ~1TB/s, which means we can train directly on the raw data without caching. Redundancy is not needed since no specific data is critical.</p>
<figure><picture> <source srcset="https://blog.comma.ai/img/datacenter/mkv_machines.webp" type="image/webp"> <img src="https://blog.comma.ai/img/datacenter/mkv_machines.png" alt=""> </picture><figcaption><p>Storage nodes</p></figcaption></figure><p>We have an additional ~300TB non-redundant array to cache intermediate processed results. And lastly, we have a redundant mkv storage array to store all of our trained models and training metrics. Each of these 3 arrays have a separate single master server.</p>
<h5 id="workload-management-slurm">Workload management: slurm</h5>
<p>We use slurm to manage the compute nodes, and compute jobs. We schedule two types of distributed compute. Pytorch training jobs, and miniray workers.</p>
<h5 id="distributed-training-pytorch">Distributed training: pytorch</h5>
<p>To train models across multiple GPU nodes we use <code>torch.distributed</code> FSDP. We have 2 separate training partitions, each intra-connected with Infiniband for training across machines. We wrote our own training framework which handles the training loop boilerplate, but it’s mostly just pytorch.</p>
<figure><picture> <source srcset="https://blog.comma.ai/img/datacenter/reporter.webp" type="image/webp"> <img src="https://blog.comma.ai/img/datacenter/reporter.png" alt=""> </picture><figcaption><p>reporter; comma’s experiment tracking service</p></figcaption></figure><p>We have a custom model experiment tracking service (similar to wandb or tensorboard). It provides a dashboard for tracking experiments, and shows custom metrics and reports. It is also the interface for the mkv storage array that hosts the model weights. The training runs store the model weights there with a uuid, and they are available to download for whoever needs to run them. The metrics and reports for our latest models <a href="https://commaai.github.io/model_reports/" target="_blank" rel="noopener noreferrer">are also open</a>.</p>
<h5 id="distributed-compute-miniray">Distributed compute: miniray</h5>
<p>Besides training we have many other compute tasks. This can be anything from running tests, running models, pre-processing data, or even running agent rollouts for on-policy training. We wrote a lightweight <a href="https://github.com/commaai/miniray" target="_blank" rel="noopener noreferrer">open-source task scheduler called miniray</a> that allows you to run arbitrary python code on idle machines. This is a simpler version of dask, with a focus on extreme simplicity. Slurm will schedule any idle machine to be an active miniray worker, and accept pending tasks. All the task information is hosted in a central redis server.</p>
<figure><picture> <source srcset="https://blog.comma.ai/img/datacenter/tbox2.webp" type="image/webp"> <img src="https://blog.comma.ai/img/datacenter/tbox2.jpg" alt=""> </picture><figcaption><p>Our main training/compute machines. Notice the 400Gbps switch in the center.</p></figcaption></figure><p>Miniray workers with GPUs will spin up a <a href="https://github.com/triton-inference-server/server" target="_blank" rel="noopener noreferrer">triton inference server</a> to run model inference with dynamic batching. A miniray worker can thus easily and efficiently run any of the models hosted in the model mkv storage array.</p>
<p>Miniray makes it extremely easy to scale parallel tasks to hundreds of machines. For example, the <a href="https://comma.ai/leaderboard" target="_blank" rel="noopener noreferrer">controls challenge record</a> was set by just having ~1hr of access to our data center with miniray.</p>
<h5 id="code-nfs-monorepo">Code NFS monorepo</h5>
<p>All our code is in a monorepo that we have cloned on our workstations. This monorepo is kept small (&lt;3GB), so it can easily be copied around. When a training job or miniray distributed job is started on any workstation, the local monorepo is cached on a shared NFS drive including all the local changes. Training jobs and miniray tasks are pointed towards this cache, such that all distributed work uses the exact codebase you have locally. Even all the python packages are identical, UV on the worker/trainer syncs the packages specified in the monorepo before starting any work. This entire process of copying your entire local codebase and syncing all the packages takes only ~2s, and is well worth it to prevent the issues mismatches can cause.</p>
<h2 id="all-together-now">All together now</h2>
<p>The most complex thing we do at comma is train driving models on-policy, these training runs require training data to be generated during training by running simulated driving rollouts with the most recent model weights. Here’s a real-world command we just used to train such a model. This training run uses all of the infrastructure described above. While only this small command is needed to kick everything off, it orchestrates a lot of moving parts.</p>
<div><pre><code>./training/train.sh N=4 partition=tbox2 trainer=mlsimdriving dataset=/home/batman/xx/datasets/lists/train_500k_20250717.txt vision_model=8d4e28c7-7078-4caf-ac7d-d0e41255c3d4/500 data.shuffle_size=125k optim.scheduler=COSINE bs=4
</code></pre></div>
<figure><picture> <source srcset="https://blog.comma.ai/img/datacenter/onpol.webp" type="image/webp"> <img src="https://blog.comma.ai/img/datacenter/onpol.png" alt=""> </picture><figcaption><p>Diagram of all infrastructure involved in training an on-policy driving model.</p></figcaption></figure><h2 id="like-this-stuff">Like this stuff?</h2>
<p>Does all this stuff sound exciting? Then build your own datacenter for yourself or your company! <a href="https://comma.ai/jobs" target="_blank" rel="noopener noreferrer">You can also come work here.</a></p>
<p><em>Harald Schäfer</em><br> <em>CTO @ <a href="https://blog.comma.ai/datacenter/www.comma.ai">comma.ai</a></em></p></section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[When internal hostnames are leaked to the clown (142 pts)]]></title>
            <link>https://rachelbythebay.com/w/2026/02/03/badnas/</link>
            <guid>46895972</guid>
            <pubDate>Thu, 05 Feb 2026 05:22:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://rachelbythebay.com/w/2026/02/03/badnas/">https://rachelbythebay.com/w/2026/02/03/badnas/</a>, See on <a href="https://news.ycombinator.com/item?id=46895972">Hacker News</a></p>
Couldn't get https://rachelbythebay.com/w/2026/02/03/badnas/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[ICE seeks industry input on ad tech location data for investigative use (170 pts)]]></title>
            <link>https://www.biometricupdate.com/202602/ice-seeks-industry-input-on-ad-tech-location-data-for-investigative-use</link>
            <guid>46895860</guid>
            <pubDate>Thu, 05 Feb 2026 05:02:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.biometricupdate.com/202602/ice-seeks-industry-input-on-ad-tech-location-data-for-investigative-use">https://www.biometricupdate.com/202602/ice-seeks-industry-input-on-ad-tech-location-data-for-investigative-use</a>, See on <a href="https://news.ycombinator.com/item?id=46895860">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				
				<p>Immigration and Customs Enforcement (ICE) is surveying the commercial advertising technology market for tools capable of supplying location data and large-scale analytics to federal investigators, according to a recent <a href="https://sam.gov/workspace/contract/opp/411452e8b3614944b9c50cc3aa24fb42/view">Request for Information</a> (RFI).</p>
<p>Framed as market research rather than a procurement, the RFI seeks information from companies offering “<a href="https://privacyinternational.org/learn/adtech">Ad Tech</a> compliant and location data services” that could support criminal, civil, and administrative investigations across ICE’s mission set.</p>
		
		
	
<p>The RFI, issued by ICE’s Homeland Security Investigations (HSI), emphasizes that the government is not soliciting proposals or committing to a future contract, but it does signal active interest in selecting vendors for live demonstrations of operational platforms and data services, a step that typically precedes pilot deployments or integration into existing investigative environments.</p>
<p>ICE says it is attempting to better understand how commercial <a href="https://www.biometricupdate.com/tag/data-brokers">big data providers</a> and advertising technology firms might directly support investigative activities, while remaining sensitive to “regulatory constraints and privacy expectations.”</p>
<p>The agency noted that its components are handling increasing volumes of criminal, civil, and administrative information from both internal and external sources and are assessing whether commercial off-the-shelf platforms comparable to large investigative data and legal analytics providers can help manage and exploit that data at scale.</p>
<p>At the center of the inquiry is a category of information traditionally associated with digital advertising rather than law enforcement: location data, device identifiers, IP intelligence, and behavioral signals derived from everyday consumer activity.</p>
<p>Advertising technology, commonly referred to as ad tech, is the sprawling ecosystem of software, data brokers, analytics platforms, and intermediaries that power targeted advertising on the modern Internet.</p>
<p>Ad tech companies collect and process information about where devices are located, how users move between physical and digital spaces, which apps are installed on their phones, and how devices can be linked across websites, applications, and networks.</p>
<p>While the industry typically frames this activity as anonymous or pseudonymous, the underlying data is often persistent, granular, and capable of tracking individuals over time.</p>
<p>Location data is a particularly valuable component of that ecosystem. Mobile applications routinely share latitude and longitude coordinates with advertising partners through embedded software development kits.</p>
<p>Even when precise GPS data is not available, companies infer location through IP addresses, Wi-Fi networks, Bluetooth beacons, and cell tower connections. That information is then aggregated, analyzed, and sold to advertisers seeking to measure foot traffic, target audiences, or assess the effectiveness of campaigns.</p>
<p>ICE’s RFI suggests that the agency is exploring whether those same mechanisms can be repurposed as investigative tools.</p>
<p>The document asks vendors to describe platforms and data services that can support investigative needs while remaining “Ad Tech compliant,” a phrase that reflects industry norms rather than statutory law enforcement standards.</p>
<p>ICE appears to be looking into tapping into the commercial data ecosystem rather than building bespoke surveillance tools from scratch, a strategy that allows agencies to access rich data streams without directly collecting the information themselves.</p>
<p>ICE’s interest is not limited to raw data. The RFI repeatedly references “operational platforms,” signaling a desire for systems that can ingest, correlate, analyze, and visualize information from multiple sources.</p>
<p>In practice, that means software environments capable of fusing location data with other records, such as criminal histories, financial data, travel records, social media activity, or administrative files, to generate investigative leads or support ongoing cases.</p>
<p>The agency frames its inquiry as exploratory and cautious. It notes that the government is seeking to understand the “current state” of ad tech and location data services available to federal investigative entities, particularly considering regulatory constraints and privacy expectations.</p>
<p>That language reflects growing scrutiny of commercial data practices by courts, regulators, and civil liberties advocates, especially when such data is accessed by federal agencies like ICE.</p>
<p>In recent years, federal agencies have increasingly relied on commercially available data to sidestep traditional legal barriers.</p>
<p>Because ad tech data is collected by private companies under consumer-facing privacy policies, agencies have argued that purchasing or accessing that data does not constitute a search under the Fourth Amendment.</p>
<p>Critics counter that this approach allows the government to obtain highly sensitive information, including detailed location histories, without warrants, probable cause, or meaningful oversight.</p>
<p>The U.S. Supreme Court has signaled skepticism of such practices in cases recognizing the sensitivity of long-term location tracking, even when data is held by third parties.</p>
<p>At the same time, regulators have brought enforcement actions against data brokers accused of selling sensitive location information without adequate safeguards.</p>
<p>Against that backdrop, ICE’s assertion that it is considering privacy expectations appears designed to reassure both policymakers and potential vendors that the agency is aware of the controversy surrounding commercial surveillance data.</p>
<p>Yet the RFI itself provides little detail about how those concerns would be operationalized. It does not reference warrants, court orders, or judicial authorization.</p>
<p>Nor does it explain how ICE would distinguish between data associated with U.S. persons and noncitizens, how long information would be retained, or whether data obtained for one investigative purpose could be reused for others.</p>
<p>That ambiguity is particularly significant given HSI’s broad mandate. Unlike agencies focused solely on criminal enforcement, HSI conducts civil and administrative investigations alongside criminal cases.</p>
<p>Location data or ad tech-derived insights could therefore be used in contexts ranging from immigration enforcement to customs violations to sanctions and export control investigations, often under lower legal thresholds than those required in criminal proceedings.</p>
<p>ICE’s emphasis on “Ad Tech compliant” services also underscore a fundamental tension. Compliance in the advertising industry typically refers to adherence to self-regulatory frameworks, contractual obligations, and privacy policies that permit extensive data collection so long as certain disclosures are made.</p>
<p>Those standards are not designed to constrain government use, nor do they substitute for constitutional or statutory protections governing law enforcement surveillance.</p>
<p>Companies marketing “privacy-friendly” location or IP intelligence tools often argue that they avoid directly identifying individuals. But researchers and regulators have repeatedly demonstrated that supposedly anonymized or aggregated data can be reidentified when combined with other datasets.</p>
<p>In an investigative context, reidentification is not a bug but a feature, enabling analysts to link digital signals back to real-world subjects.</p>
<p><em>Biometric Update</em> earlier <a href="https://www.biometricupdate.com/202511/dod-service-members-others-face-security-risks-from-publicly-accessible-digital-data">reported</a> that a Government Accountability Office audit had found that publicly accessible data – from social media posts to commercial geolocation records – can be aggregated into detailed “digital profiles” that expose U.S. personnel, military operations, and senior leaders to targeting, coercion, and disruption.</p>
<p>In January 2025, Gravy Analytics, a prominent location data broker, disclosed that a significant data breach had <a href="https://www.biometricupdate.com/202501/breach-exposes-privacy-risk-from-de-anonymization-of-location-data">potentially exposed</a> through de-anonymization the precise location information of millions of individuals.</p>
<p>The RFI’s focus on live demonstrations suggests that ICE is interested in mature, deployable capabilities rather than theoretical offerings. Vendors selected to present would be expected to show how their platforms operate in practice, how data is accessed and analyzed, and how investigative outputs are generated.</p>
<p>While the agency stresses that it is not committing to a future solicitation, such demonstrations often inform subsequent procurements, task orders, or pilot programs conducted under existing contracts.</p>
<p>ICE has used similar market research approaches in the past to normalize new surveillance capabilities before formal adoption.</p>
<p>Social media monitoring tools, mobile biometric systems, and large-scale analytics platforms were all introduced through incremental steps that began with RFIs and demonstrations rather than headline-grabbing contracts.</p>
<p>For privacy advocates, the latest filing fits a familiar pattern. Commercial surveillance markets evolve rapidly, driven by advertising and marketing demand. Government agencies then adopt those tools after the fact, often before lawmakers have fully grappled with the implications.</p>
<p>Oversight mechanisms, however, lag technical capability, leaving key questions unanswered until after systems are already in use.</p>
<p>ICE’s RFI does not indicate when demonstrations might occur or whether a solicitation will follow. It does make clear, though, that the agency sees the ad tech ecosystem as a potential investigative resource worth serious consideration.</p>
<p>As debates over commercial data, surveillance, and constitutional protections continue, the filing offers a window into how federal law enforcement is adapting to – and seeking to leverage – a data economy built for advertising rather than accountability.</p>
<p>For now, ICE is asking industry to explain how ad tech-derived location and analytics services can be made suitable for investigative use while respecting privacy expectations.</p>
<p>What remains unclear is who will define those expectations, how they will be enforced, and whether existing legal frameworks are equipped to govern a surveillance model that blurs the line between consumer marketing and government intelligence.</p>
								
				
				

				
				<h2>Article Topics</h2>
				<p><a href="https://www.biometricupdate.com/tag/data-brokers" rel="tag">data brokers</a> &nbsp;|&nbsp; <a href="https://www.biometricupdate.com/tag/device-fingerprinting" rel="tag">device fingerprinting</a> &nbsp;|&nbsp; <a href="https://www.biometricupdate.com/tag/ice" rel="tag">ICE</a> &nbsp;|&nbsp; <a href="https://www.biometricupdate.com/tag/law-enforcement-2" rel="tag">law enforcement</a> &nbsp;|&nbsp; <a href="https://www.biometricupdate.com/tag/location-data" rel="tag">location data</a> &nbsp;|&nbsp; <a href="https://www.biometricupdate.com/tag/rfi" rel="tag">RFI</a> &nbsp;|&nbsp; <a href="https://www.biometricupdate.com/tag/surveillance" rel="tag">surveillance</a> &nbsp;|&nbsp; <a href="https://www.biometricupdate.com/tag/u-s-government" rel="tag">U.S. Government</a></p>

								
				
				
									
							
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Child prodigies rarely become elite performers (106 pts)]]></title>
            <link>https://www.economist.com/science-and-technology/2026/01/14/why-child-prodigies-rarely-become-elite-performers</link>
            <guid>46894815</guid>
            <pubDate>Thu, 05 Feb 2026 02:17:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.economist.com/science-and-technology/2026/01/14/why-child-prodigies-rarely-become-elite-performers">https://www.economist.com/science-and-technology/2026/01/14/why-child-prodigies-rarely-become-elite-performers</a>, See on <a href="https://news.ycombinator.com/item?id=46894815">Hacker News</a></p>
Couldn't get https://www.economist.com/science-and-technology/2026/01/14/why-child-prodigies-rarely-become-elite-performers: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[OpenClaw is what Apple intelligence should have been (296 pts)]]></title>
            <link>https://www.jakequist.com/thoughts/openclaw-is-what-apple-intelligence-should-have-been</link>
            <guid>46893970</guid>
            <pubDate>Thu, 05 Feb 2026 00:28:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.jakequist.com/thoughts/openclaw-is-what-apple-intelligence-should-have-been">https://www.jakequist.com/thoughts/openclaw-is-what-apple-intelligence-should-have-been</a>, See on <a href="https://news.ycombinator.com/item?id=46893970">Hacker News</a></p>
<div id="readability-page-1" class="page"><section><p>Something strange is happening with Mac Minis. They’re selling out everywhere, and it’s not because people suddenly need more coffee table computers.</p><p>If you browse Reddit or HN, you’ll see the same pattern: people are buying Mac Minis specifically to run AI agents with computer use. They’re setting up headless machines whose sole job is to automate their workflows. OpenClaw—the open-source framework that lets you run Claude, GPT-5, or whatever model you want to actually control your computer—has become the killer app for Mac hardware. Not Final Cut. Not Logic. An AI agent that clicks buttons.</p><p>This is exactly what Apple Intelligence should have been.</p><p>Apple had everything: the hardware, the ecosystem, the reputation for “it just works.” They could have shipped an agentic AI that actually automated your computer instead of summarizing your notifications. Imagine if Siri could genuinely file your taxes, respond to emails, or manage your calendar by actually using your apps, not through some brittle API layer that breaks every update.</p><p>They could have charged $500 more per device and people would have paid it. The margins would have been obscene. And they would have won the AI race not by building the best model, but by being the only company that could ship an AI you’d actually trust with root access to your computer. That trust—built over decades—was their moat.</p><p>So why didn’t they?</p><p>Maybe they just didn’t see it. That sounds mundane, but it’s probably the most common reason companies miss opportunities. When you’re Apple, you’re thinking about chip design, manufacturing scale, and retail strategy. An open-source project letting AI agents control computers might not ping your radar until it’s already happening.</p><p>Or maybe they saw it and decided the risk wasn’t worth it. If you’re Apple, you don’t want your AI agent automatically buying things, posting on social media, or making irreversible decisions. The liability exposure would be enormous. Better to ship something safe and limited than something powerful and unpredictable.</p><p>But there’s another dynamic at play. Look at who’s about to get angry about OpenClaw-style automation: <a href="https://www.jakequist.com/thoughts/big-tech-vs-openclaw/">LinkedIn, Facebook, anyone with a walled garden and a careful API strategy</a>. These services depend on friction. They want you to use their app, see their ads, stay in their ecosystem. An AI that can automate away that friction is an existential threat.</p><p>If Apple had built this, they’d be fighting Instagram over ToS violations by Tuesday. They’d be testifying in front of Congress about AI agents committing fraud. Every tech platform would be updating their terms to explicitly ban Apple Intelligence.</p><p>By letting some third party do it, Apple gets plausible deniability. They’re just selling hardware. Not their fault what people run on it. It’s the same strategy that made them billions in the App Store while maintaining they’re “not responsible for what developers do.”</p><p>But I think this is short-term thinking.</p><p>Here’s what people miss about moats: they compound. The reason Microsoft dominated PCs wasn’t just that they had the best OS. It’s that everyone built for Windows, which made Windows more valuable, which made more people build for Windows. Network effects.</p><p>If Apple owned the agent layer, they could have created the most defensible moat in tech. Because an AI agent gets better the more it knows about you. And Apple already has all your data, all your apps, all your devices. They could have built an agent that works across your iPhone, Mac, iPad, and Watch seamlessly—something no one else can do.</p><p>More importantly, they could have owned the API. Want your service to work with Apple Agent? You play by Apple’s rules. Suddenly Apple isn’t fighting with platforms—they’re the platform that platforms need to integrate with. It’s the App Store playbook all over again, but for the AI era.</p><p>The Mac Mini rush is a preview of this future. People want agents. They want automation. They want to pay for it. They’re literally buying extra computers just to run someone else’s AI on Apple’s hardware.</p><p>Apple is getting the hardware revenue but missing the platform revenue. That might look smart this quarter. But platform revenue is what built Apple into a $3 trillion company. And platforms are what create trillion-dollar moats.</p><p>I suspect ten years from now, people will look back at 2024-2025 as the moment Apple had a clear shot at owning the agent layer and chose not to take it. Not because they couldn’t build it—they obviously could—but because they were optimizing for this year’s legal risk instead of next decade’s platform power.</p><p>The people buying Mac Minis to run AI agents aren’t just early adopters. They’re showing Apple exactly what product they should have built. Whether Apple is paying attention is another question entirely.</p></section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why more companies are recognizing the benefits of keeping older employees (119 pts)]]></title>
            <link>https://longevity.stanford.edu/why-more-companies-are-recognizing-the-benefits-of-keeping-older-employees/</link>
            <guid>46893411</guid>
            <pubDate>Wed, 04 Feb 2026 23:26:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://longevity.stanford.edu/why-more-companies-are-recognizing-the-benefits-of-keeping-older-employees/">https://longevity.stanford.edu/why-more-companies-are-recognizing-the-benefits-of-keeping-older-employees/</a>, See on <a href="https://news.ycombinator.com/item?id=46893411">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><h3 itemprop="headline"><strong>DEEP</strong> DIVE</h3></div>
<div><h3 itemprop="headline"><strong>Why More Companies Are Recognizing the Benefits of Keeping Older Employees</strong></h3><p>By&nbsp;Annie Coleman</p></div>
<div itemprop="text" itemscope="itemscope" itemtype="https://schema.org/CreativeWork"><p><span lang="EN-US" xml:lang="EN-US" data-contrast="auto"><span data-ccp-parastyle="heading 1"><img fetchpriority="high" decoding="async" src="https://longevity.stanford.edu/wp-content/uploads/2026/02/Deep-Dive.jpg" alt="" width="1985" height="456" srcset="https://longevity.stanford.edu/wp-content/uploads/2026/02/Deep-Dive.jpg 1985w, https://longevity.stanford.edu/wp-content/uploads/2026/02/Deep-Dive-300x69.jpg 300w, https://longevity.stanford.edu/wp-content/uploads/2026/02/Deep-Dive-1030x237.jpg 1030w, https://longevity.stanford.edu/wp-content/uploads/2026/02/Deep-Dive-80x18.jpg 80w, https://longevity.stanford.edu/wp-content/uploads/2026/02/Deep-Dive-1536x353.jpg 1536w, https://longevity.stanford.edu/wp-content/uploads/2026/02/Deep-Dive-1500x345.jpg 1500w, https://longevity.stanford.edu/wp-content/uploads/2026/02/Deep-Dive-705x162.jpg 705w, https://longevity.stanford.edu/wp-content/uploads/2026/02/Deep-Dive-450x103.jpg 450w, https://longevity.stanford.edu/wp-content/uploads/2026/02/Deep-Dive-500x115.jpg 500w, https://longevity.stanford.edu/wp-content/uploads/2026/02/Deep-Dive-750x172.jpg 750w, https://longevity.stanford.edu/wp-content/uploads/2026/02/Deep-Dive-1140x262.jpg 1140w" sizes="(max-width: 1985px) 100vw, 1985px">Although age bias is still the norm, the value-add of longtime, experienced workers is beginning to take shape.<br>
</span></span></p>
<p><span>On the outskirts of Macclesfield, in northwest England, a branch of the UK home-improvement retailer B&amp;Q quietly overturned one of corporate life’s most persistent assumptions. Faced with high staff turnover and uneven customer satisfaction, the company tried a simple experiment: In 1989, it staffed the store largely with older workers.&nbsp;</span></p>
<p><span>The results were striking, according to </span><a href="https://www.som.org.uk/bq-and-ageing-workers#:~:text=Profits%20were%2018%25%20higher" target="_blank" rel="noopener"><span>one study</span></a><span>. Profits rose 18 percent. Staff turnover fell to a fraction of the company average. Absenteeism dropped sharply. An experiment that started more than 30 years ago reshaped how the retailer approached age inclusiveness and led B&amp;Q to open training to all ages and feature older workers in advertising, treating experience as an advantage rather than a cost.</span></p>
<p><span>In 2007, BMW began </span><span>implementing 70 ergonomic, low-cost improvements in a specialized assembly line in Dingolfing, Germany, to provide better conditions for its many older and middle-aged workers. </span><span>Key changes</span><span> included </span><span>adjustable-height workstations, improved lighting and specialized stools,</span><span> resulting in a </span><a href="https://www.scdigest.com/ASSETS/ON_TARGET/10-03-17-3.php?cid=3294#:~:text=periods%20of%20time.-,The%20total%20investment%20was%20quite%20modest%20%E2%80%93%20just%20some%20$20%2C000%20euros,at%20the%20Feedback%20button%20below." target="_blank" rel="noopener"><span>7 percent productivity increase</span></a><span>.</span></p>
<p><span>Evidence suggests that similar age-performance dynamics are not limited to the quirks of retail or to the factory floor </span><span>and are increasingly relevant as declining birth rates and artificial intelligence investments reduce the inflow of entry-level workers. </span><a href="https://business.bofa.com/content/dam/flagship/workplace-benefits/silver-economy/better-with-age.pdf" target="_blank" rel="noopener"><span>A white paper</span></a><span> from Bank of America’s Workplace Benefits group argues that recruiting and retaining older workers is becoming increasingly important as populations age, framing age-inclusive benefits not as accommodation, but as a driver of organizational performance, especially for roles where judgment, experience and decision quality matter most.&nbsp;</span></p>
<p><span>“The retention of these older workers is an idea that is becoming much more well-received,” says Cynthia Hutchins, Bank of America’s inaugural director of financial gerontology. </span><span>Hutchins has been involved in implementing a workforce longevity policy that includes hybrid schedules, financial planning benefits, menopause support, grandparents’ leave and sabbaticals</span><span>. “It’s almost a business imperative to institute those types of benefits” to retain older workers and attract younger ones, adds Hutchins.</span></p>
<p><span>Yet initiatives such as these&nbsp;are rarely framed as strategy or as signals of a deeper shift. Most corporations continue to design careers as if effectiveness peaks early — as if speed, stamina and innovation belong exclusively to the young.&nbsp;If experience improves outcomes, why are so many organizations structured to push people out just as their value peaks?&nbsp;</span></p>
<blockquote>
<p>If experience improves outcomes, why are so many organizations structured to push people out just as their value peaks?</p>
</blockquote>
<h3><b>The Albatross or the Wise Man&nbsp;</b></h3>
<p><span>At the heart of corporate resistance lies a fundamental disagreement about value. </span><span>Moody’s Analytics chief economist Mark Zandi framed the debate in </span><a href="https://ma.moodys.com/rs/961-KCJ-308/images/2018-09-04-Aging-and-the-Productivity-Puzzle.pdf" target="_blank" rel="noopener"><span>Aging and the Productivity Puzzle</span></a><span>, a 2018 analysis delineating two schools of thought. The “albatross theory” holds that workers above the age of 65 drag down productivity due to resistance to change and outdated skills. The “wise man theory” tells a different story: of workers who possess judgment, institutional knowledge, emotional intelligence and expertise that younger employees cannot replicate.&nbsp;</span></p>
<p><span>Zandi and his colleagues analyzed state-level ADP data in the U.S. and concluded that post-retirement-age workers slowed wage growth and productivity, largely because they tend to be averse to adopting new technologies. Yet several major institutions reject the idea that older workers are a productivity “albatross” — and most look at the effects, not of those above the age of 65, but of the 50-plus age workforce, often the first in line for layoffs.&nbsp;</span></p>
<p><span>More recent research from </span><a href="https://www.aarpinternational.org/file%20library/future%20of%20work/2020-global-insights-multigenerational-workforce-issuebrief.doi.10.26419-2fres.00399.001.pdf" target="_blank" rel="noopener"><span>AARP</span></a><span> and the </span><a href="https://www.oecd.org/en/publications/promoting-an-age-inclusive-workforce_59752153-en.html" target="_blank" rel="noopener"><span>OECD</span></a><span> shows that firms with more 50-plus workers are more productive, not less: a 10-percentage-point increase in older workers is associated with roughly 1.1 percent higher productivity. The 2020 OECD analysis also finds that age-balanced firms benefit from lower turnover and stronger team performance, driven by experience and knowledge sharing rather than technology resistance. Similarly, a 2022 study from </span><a href="https://www.bcg.com/publications/2022/leveraging-power-of-cross-generational-teams" target="_blank" rel="noopener"><span>Boston Consulting Group</span></a><span> found that cross-generational teams outperform homogeneous ones when older workers’ judgment and mentoring are combined with younger workers’ digital skills. </span><span>A 2022 </span><a href="https://academic.oup.com/workar/article/8/2/208/6574297?login=false" target="_blank" rel="noopener"><span>meta analysis</span></a> <span>also</span> <span>pushes back against the idea that older workers are less effective, and found that teams perform better when members have a long tenure at the company, irrespective of workers’ ages.&nbsp;</span></p>
<p><span>Still, </span><span>Zandi says that </span><span>the value of older workers may depend on how AI in the workplace unfolds and what impact it has on productivity growth. “If AI turns out to be a bust or doesn’t live up to expectations, and you have other demographic forces that are restraining labor growth, then I think older workers should fare well,” Zandi says. He notes that so far, older workers have “navigated things reasonably gracefully,” while younger workers and mid-level managers are so far taking the brunt of AI-related impacts.&nbsp;</span><span><br>
</span></p>
<h3>People Peak Later Than We Think</h3>
<p><span>Population aging is often treated as a future problem, something to be managed later with technology or policy tweaks. In reality, it is already reshaping labor markets in the U.S. and across advanced economies. Birth rates are lower, people are living longer and the share of workers above the age of 50 is rising steadily. This is not a forecast. It is arithmetic.&nbsp;</span></p>
<blockquote>
<p><span>Across advanced economies, there appears to be a persistent pattern of early exits that are less about individual choice than organizational design.</span></p>
</blockquote>
<p><span>Yet organizational assumptions about performance have not kept pace. Modern careers are still built around the idea that effectiveness peaks early. Recent research challenges that view. A 2025 </span><a href="https://www.sciencedirect.com/science/article/pii/S0160289625000649" target="_blank" rel="noopener"><span>study</span></a><span> in the journal </span><em><span>Intelligence</span></em><span>, analyzing age trajectories across 16 cognitive, emotional and personality dimensions, finds that while processing speed does decline after early adulthood, many of the capabilities most relevant to complex work continue to improve well into midlife. When these traits are combined into a composite measure of overall functioning, performance peaks between ages 55 and 60.</span></p>
<p><span>But if proficiency increasingly peaks in late midlife, then why are so many careers ending before they can be fully realized? Across advanced economies, there appears to be a persistent pattern of early exits that are less about individual choice than organizational design.</span></p>
<p><span>In the U.S., </span><a href="https://www.urban.org/sites/default/files/publication/99570/how_secure_is_employment_at_older_ages_2.pdf" target="_blank" rel="noopener"><span>analysis by the Urban Institute</span></a><span> of survey data of older workers from 1992 to 2016 showed that more than half above the age of 50 were pushed out of long-held jobs before they chose to retire, often through layoffs or restructuring rather than performance issues. The 2018 study — along with </span><a href="https://www.propublica.org/article/older-workers-united-states-pushed-out-of-work-forced-retirement" target="_blank" rel="noopener"><span>reporting from ProPublica</span></a><span> — found that few ever regained comparable pay or responsibility, and hiring practices reinforced the trend.</span></p>
<blockquote>
<p><span>T</span><span>he fact that more than half of U.S. workers above the age of 50 leave long-held jobs for reasons unrelated to performance and before they choose to retire is a systemic design failure.</span></p>
</blockquote>
<p><span>Bill Greene, a longtime business consultant, is an exception to this layoff trend. Hired at 64 as principal of Mind Share Partners, a nonprofit in San Francisco, he advises companies on the importance of creating mentally healthy environments, and cautions that the workplace is a minefield of biases — and that ageism </span><span>cuts both ways for older workers and younger workers.</span></p>
<p><span>Greene advises employers to be aware of the blind spots and inconsistencies. In the technology industry, he says, “it’s widely perceived that if you are 45 years old or over, you are a dinosaur,” yet in politics, “you can be 70, 75, 80, 85, and apparently that’s OK.”</span></p>
<p><span>Experience helps in an emergency. When the Covid-19 pandemic struck in 2020, Greene was consulting for a financial services firm, and he saw firsthand how worried his client was that younger employees were going to panic and quit because they hadn’t been through a crisis of that magnitude before.</span></p>
<p><span>“They realized that they had to coach their younger employees,” he says, comparing the pandemic to the 2008 financial crash to help the client’s staff understand the risks and path forward. “That kind of wisdom and experience can come with more depth of understanding and perspective from an older employee than from a younger one,” he says.</span></p>
<h3><b>Small-Scale Experiments Miss an Urgent Challenge</b></h3>
<p><span>Although </span><a href="https://creators.yahoo.com/lifestyle/story/14-companies-begging-for-workers-over-50-right-now-some-pay-over-30hour-145532316.html" target="_blank" rel="noopener"><span>several Fortune 500 companies</span></a><span> have advertised their interest in hiring and retaining older workers, corporate commitments remain tentative and small-scale. UK-based Unilever launched its </span><a href="https://www.unilever.com/files/4bbfab9a-54aa-4493-a9b0-146c1c4aa738/glo-wired-x-unilever-workplace.pdf" target="_blank" rel="noopener"><span>U-Work program</span></a><span> in 2019, and now offers employees in nine countries a hybrid between traditional employment and gig work: a monthly retainer, benefits and freedom to choose which projects they work on and when. Workers can scale back hours, pursue other interests or transition gradually toward retirement.&nbsp;</span></p>
<p><span>The program is innovative and, by all accounts, successful. Half of participants are above the age of 50. But only 140 employees out of Unilever’s 150,000-strong global workforce participate.&nbsp;This raises a question: Are these strategies of genuine transformation or sophisticated public relations?</span></p>
<p><span>Three converging forces make the case for urgency.&nbsp;First, premature exit creates value leakage. T</span><span>he fact that more than half of U.S. workers above the age of 50 leave long-held jobs for reasons unrelated to performance and before they choose to retire is a systemic design failure.</span></p>
<p><span>Second, the demand-side blind spot.</span><span> Globally, spending by people above the age of 55 is projected to approach </span><a href="https://www.brookings.edu/articles/the-silver-economy-is-coming-of-age-a-look-at-the-growing-spending-power-of-seniors/" target="_blank" rel="noopener"><span>$15 trillion annually</span></a><span> by the end of this decade, making older consumers one of the largest and fastest-growing sources of demand in the world economy. Yet many companies treat older customers as peripheral.&nbsp;</span></p>
<p><span>There are exceptions. Alan Patricof, now 91 and still investing, launched Primetime Partners at 85 after observing that venture capital remained focused on millennials, despite obvious unmet demand among older adults. His fund has invested in more than 35 companies serving what he calls the “ageless market.” Consumer brands are adapting, too — L’Oréal has repositioned itself around longevity and healthy aging, treating later life as aspiration rather than decline.&nbsp;</span></p>
<p><span>The silver economy is not a niche. It is one of the largest and least contested growth opportunities of the next decade — and one that many firms still underestimate.&nbsp;</span></p>
<p><span>Third, longer working lives are inevitable. In Europe and the UK, effective retirement ages have been climbing, driven in part by financial need and policy changes. Meanwhile, in the U.S., the shift from defined-benefit to defined-contribution retirement plans incentivizes workers to remain employed longer. Organizations that fail to retain experienced talent will face labor shortages, while competitors benefit from workers who bring judgment, stability and institutional memory.&nbsp;</span></p>
<h3><b>The Role of Investors, C-Suites and Boards&nbsp;</b></h3>
<p><span>The mismatch between demographic reality and corporate behavior is beginning to register with long-term investors. Large asset managers increasingly frame longevity&nbsp;as a structural economic force with implications for growth, productivity and risk.&nbsp;</span></p>
<p><span>A Vanguard study, </span><a href="https://corporate.vanguard.com/content/dam/corp/research/pdf/megatrends-the-economics-of-a-graying-world-us-isgdemog_062019_online.pdf" target="_blank" rel="noopener"><span>The Economics of a Graying World</span></a><span>, highlights aging and slower labor-force growth as a persistent drag on economic expansion, arguing that longer working lives are one of the few viable adjustment mechanisms. From this perspective, workforce age policy becomes financially material, not optional.&nbsp;</span></p>
<blockquote>
<p><span>When organizations push experienced workers out early, they forfeit peak judgment, execution capability and mentoring capacity. </span></p>
</blockquote>
<p><span>Economist Andrew J. Scott of the London Business School argues in his 2024 book </span><em><a href="https://profandrewjscott.com/the-longevity-imperative/" target="_blank" rel="noopener"><span>The Longevity Imperative</span></a></em> <span>that if societies see longevity primarily as an “aging problem” of more pensioners, higher health costs and fewer workers, longer lives risk becoming a fiscal drag. But if they invest in health, skills and age‑inclusive work, longevity can instead raise growth, employment and innovation.</span><span>&nbsp;</span></p>
<p><span>One hurdle to this shift in perspective is an ongoing lack of transparency and accountability by employers. Ageism in hiring, promotion and redundancy remains widespread, yet unlike gender or ethnicity, workforce age is rarely disclosed or scrutinized. The result is a growing governance gap. Misalignment with demographic reality creates execution risk — in talent, productivity and growth.&nbsp;</span></p>
<p><span>The case for a longevity strategy is ultimately an economic one. When organizations push experienced workers out early, they forfeit peak judgment, execution capability and mentoring capacity. When they underinvest in older consumers, they leave vast pools of demand underserved. Value is forfeited on both sides of the business.&nbsp;</span></p>
<p><span>In meeting their responsibility for long-term risk and growth, companies should begin with clarity. Map the age profile of the workforce by role and seniority. Identify where people in their fifties and early sixties are exiting — and whether those exits reflect performance or design. Treat age as a strategic variable in the same way firms now treat gender, skills or succession risk.&nbsp;</span></p>
<p><span>From there, redesign follows. Build roles and career paths that assume longer working lives. Invest in mid- and late-career reskilling, not as remediation but as renewal. Structure intergenerational teams deliberately, so experience and speed compound rather than collide. Align product, service and brand strategy with the realities of an aging, wealthier customer base.&nbsp;</span></p>
<p><span>None of this is about altruism. It is about reclaiming value currently being left on the table. As populations age, companies that learn to retain experience and serve longevity-driven demand will not just adapt — they will outperform.&nbsp;</span></p>
<hr>
<p><em><span><strong>Annie Coleman</strong> is Founder of </span><a href="https://www.realiselongevity.com/" target="_blank" rel="noopener"><span>RealiseLongevity</span></a><span>, a consulting firm based in the UK, and is a </span><a href="https://longevity.stanford.edu/scl-ambassadors-program-a-launchpad-for-global-impact/" target="_blank" rel="noopener"><span>Stanford Center on Longevity Ambassador</span></a><span>.</span></em></p>
</div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Spotlighting the World Factbook as We Bid a Fond Farewell (129 pts)]]></title>
            <link>https://www.cia.gov/stories/story/spotlighting-the-world-factbook-as-we-bid-a-fond-farewell/</link>
            <guid>46891794</guid>
            <pubDate>Wed, 04 Feb 2026 21:08:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cia.gov/stories/story/spotlighting-the-world-factbook-as-we-bid-a-fond-farewell/">https://www.cia.gov/stories/story/spotlighting-the-world-factbook-as-we-bid-a-fond-farewell/</a>, See on <a href="https://news.ycombinator.com/item?id=46891794">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div data-gatsby-image-wrapper=""><picture><source type="image/webp" data-srcset="/static/2958550a00127cfea909b6a91493208b/fed88/CleanedWFB-editions-Screenshot-possible-graphic.webp 223w,/static/2958550a00127cfea909b6a91493208b/74cf0/CleanedWFB-editions-Screenshot-possible-graphic.webp 446w,/static/2958550a00127cfea909b6a91493208b/82ebc/CleanedWFB-editions-Screenshot-possible-graphic.webp 892w" sizes="(min-width: 892px) 892px, 100vw"><img data-gatsby-image-ssr="" data-main-image="" sizes="(min-width: 892px) 892px, 100vw" decoding="async" loading="lazy" data-src="/static/2958550a00127cfea909b6a91493208b/0d82a/CleanedWFB-editions-Screenshot-possible-graphic.jpg" data-srcset="/static/2958550a00127cfea909b6a91493208b/f99ed/CleanedWFB-editions-Screenshot-possible-graphic.jpg 223w,/static/2958550a00127cfea909b6a91493208b/2cb86/CleanedWFB-editions-Screenshot-possible-graphic.jpg 446w,/static/2958550a00127cfea909b6a91493208b/0d82a/CleanedWFB-editions-Screenshot-possible-graphic.jpg 892w" alt="" src="https://www.cia.gov/static/2958550a00127cfea909b6a91493208b/0d82a/CleanedWFB-editions-Screenshot-possible-graphic.jpg" srcset="https://www.cia.gov/static/2958550a00127cfea909b6a91493208b/f99ed/CleanedWFB-editions-Screenshot-possible-graphic.jpg 223w,https://www.cia.gov/static/2958550a00127cfea909b6a91493208b/2cb86/CleanedWFB-editions-Screenshot-possible-graphic.jpg 446w,https://www.cia.gov/static/2958550a00127cfea909b6a91493208b/0d82a/CleanedWFB-editions-Screenshot-possible-graphic.jpg 892w"></picture></div><p>One of CIA’s oldest and most recognizable intelligence publications, The World Factbook, has sunset. The World Factbook served the Intelligence Community and the general public as a longstanding, one-stop basic reference about countries and communities around the globe. Let’s take a quick look into the history of The World Factbook. &nbsp;</p><p><a href="https://www.cia.gov/stories/story/history-of-the-world-factbook/">Over many decades</a>, The World Factbook evolved from a classified to unclassified, hardcopy to electronic product that added new categories, and even new global entities. The original classified publication, titled <em>The National Basic Intelligence Factbook</em>, launched in 1962. The first unclassified companion version was issued in 1971. A decade later it was renamed The World Factbook. In 1997, The World Factbook went digital and debuted to a worldwide audience on CIA.gov, where it garnered millions of views each year.</p><p>The World Factbook appealed to researchers, news organizations, teachers, students, and international travelers. Some readers even inquired whether their preferred geographic designation or world entity could be included on the high-profile site.</p><p>Finally, only CIA insiders would know that officers donated some of their personal travel photos to The World Factbook, which hosted more than 5,000 photographs that were copyright-free for anyone to access and use.</p><p>Though the World Factbook is gone, in the spirit of its global reach and legacy, we hope you will stay curious about the world and find ways to explore it… in person or virtually.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How Jeff Bezos Brought Down the Washington Post (222 pts)]]></title>
            <link>https://www.newyorker.com/news/annals-of-communications/how-jeff-bezos-brought-down-the-washington-post</link>
            <guid>46890034</guid>
            <pubDate>Wed, 04 Feb 2026 18:56:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.newyorker.com/news/annals-of-communications/how-jeff-bezos-brought-down-the-washington-post">https://www.newyorker.com/news/annals-of-communications/how-jeff-bezos-brought-down-the-washington-post</a>, See on <a href="https://news.ycombinator.com/item?id=46890034">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main-content" tabindex="-1"><article lang="en-US"><div><header data-testid="SplitScreenContentHeaderWrapper"><div data-journey-hook="grid-wrapper"><div><p>The Amazon founder bought the paper to save it. Instead, with a mass layoff, he’s forced it into severe decline.</p></div><div><p><span><picture><source media="(max-width: 767px)" srcset="https://media.newyorker.com/photos/69823708afa37297f9cff815/3:4/w_120,c_limit/Marcus-GettyImages-2257983026.jpg 120w, https://media.newyorker.com/photos/69823708afa37297f9cff815/3:4/w_240,c_limit/Marcus-GettyImages-2257983026.jpg 240w, https://media.newyorker.com/photos/69823708afa37297f9cff815/3:4/w_320,c_limit/Marcus-GettyImages-2257983026.jpg 320w, https://media.newyorker.com/photos/69823708afa37297f9cff815/3:4/w_640,c_limit/Marcus-GettyImages-2257983026.jpg 640w, https://media.newyorker.com/photos/69823708afa37297f9cff815/3:4/w_960,c_limit/Marcus-GettyImages-2257983026.jpg 960w" sizes="100vw"><source media="(min-width: 768px)" srcset="https://media.newyorker.com/photos/69823708afa37297f9cff815/master/w_120,c_limit/Marcus-GettyImages-2257983026.jpg 120w, https://media.newyorker.com/photos/69823708afa37297f9cff815/master/w_240,c_limit/Marcus-GettyImages-2257983026.jpg 240w, https://media.newyorker.com/photos/69823708afa37297f9cff815/master/w_320,c_limit/Marcus-GettyImages-2257983026.jpg 320w, https://media.newyorker.com/photos/69823708afa37297f9cff815/master/w_640,c_limit/Marcus-GettyImages-2257983026.jpg 640w, https://media.newyorker.com/photos/69823708afa37297f9cff815/master/w_960,c_limit/Marcus-GettyImages-2257983026.jpg 960w, https://media.newyorker.com/photos/69823708afa37297f9cff815/master/w_1280,c_limit/Marcus-GettyImages-2257983026.jpg 1280w, https://media.newyorker.com/photos/69823708afa37297f9cff815/master/w_1600,c_limit/Marcus-GettyImages-2257983026.jpg 1600w, https://media.newyorker.com/photos/69823708afa37297f9cff815/master/w_1920,c_limit/Marcus-GettyImages-2257983026.jpg 1920w, https://media.newyorker.com/photos/69823708afa37297f9cff815/master/w_2240,c_limit/Marcus-GettyImages-2257983026.jpg 2240w" sizes="100vw"><img alt="The Washington Post building." loading="eager" src="https://media.newyorker.com/photos/69823708afa37297f9cff815/master/w_2560%2Cc_limit/Marcus-GettyImages-2257983026.jpg" data-src="https://media.newyorker.com/photos/69823708afa37297f9cff815/master/w_2560%2Cc_limit/Marcus-GettyImages-2257983026.jpg"></picture></span></p></div></div><div data-journey-hook="grid-wrapper"><p><span>Photograph by Kent Nishimura / Bloomberg / Getty</span></p></div></header></div><div data-testid="ArticlePageChunks" data-attribute-verso-pattern="article-body"><div data-journey-hook="grid-wrapper" data-testid="BodyWrapper"><p>On September 4, 2013, the Amazon founder <a href="https://www.newyorker.com/tag/jeff-bezos">Jeff Bezos</a> held his first meeting with the staff of the Washington <em>Post</em>, the newspaper he had agreed to purchase a month earlier from the Graham family, for two hundred and fifty million dollars. It had been a long and unsettling stretch for the paper’s staff. We—I was a deputy editor of the editorial page at the time—had suffered through years of retrenchment. We trusted that Don Graham would place us in capable hands, but we did not know this new owner, and he did not know or love our business in the way that the Graham family had. Bezos’s words at that meeting, about “a new golden era for the Washington <em>Post</em>,” were reassuring. Bob Woodward asked why he had purchased the paper, and Bezos was clear about the commitment he was prepared to make. “I finally concluded that I could provide runway—financial runway—because I don’t think you can keep shrinking the business,” he said. “You can be profitable and shrinking. And that’s a survival strategy, but it ultimately leads to irrelevance, at best. And, at worst, it leads to extinction.”</p><p>To look back on that moment is to wonder: How could it have come to this? The paper had some profitable years under Bezos, sparked by the 2016 election and the first Trump term. But it began losing enormous sums: seventy-seven million dollars in 2023, another hundred million in 2024. The owner who once offered runway was unwilling to tolerate losses of that magnitude. And so, after years of Bezos-fuelled growth, the <em>Post</em> endured two punishing rounds of voluntary buyouts, in 2023 and 2025, that reduced its newsroom from more than a thousand staffers to under eight hundred, and cost the <em>Post</em> some of its best writers and editors. Then, early Wednesday morning, newsroom employees received an e-mail announcing “some significant actions.” They were instructed to stay home and attend a “Zoom webinar at 8:30 <em>a.m.</em>” Everyone knew what was coming—mass layoffs.</p><p>The scale of the demolition, though, was staggering—<a data-offer-url="https://www.nytimes.com/2026/02/04/business/media/washington-post-layoffs.html" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.nytimes.com/2026/02/04/business/media/washington-post-layoffs.html&quot;}" href="https://www.nytimes.com/2026/02/04/business/media/washington-post-layoffs.html" rel="nofollow noopener" target="_blank">reportedly</a> more than three hundred newsroom staffers. The announcement was left to the executive editor, Matt Murray, and human-relations chief Wayne Connell; the newspaper’s publisher, Will Lewis, was nowhere to be seen as the grim news was unveiled. In what Murray termed a “broad strategic reset,” the <em>Post</em>’s storied sports department was shuttered “in its current form”; several reporters will now cover sports as a “cultural and societal phenomenon.” The metro staff, already cut to about forty staffers during the past five years, has been shrunk to about twelve; the foreign desks will be reduced to approximately twelve locations from more than twenty; Peter Finn, the international editor, told me that he asked to be laid off. The books section and the flagship podcast, “Post Reports,” will end. Shortly after the meeting, staffers received individualized e-mails letting them know whether they would stay or go. Murray said the retrenched <em>Post</em> would “concentrate on areas that demonstrate authority, distinctiveness, and impact,” focussing on areas such as politics and national security. This strategy, a kind of <em>Politico</em>-lite, would be more convincing if so many of the most talented players were not already gone.</p></div><div data-journey-hook="grid-wrapper" data-testid="BodyWrapper"><p>Graham, who has previously been resolutely silent about changes at the paper, posted a message on Facebook that pulsed with anguish. “It’s a bad day,” he wrote, adding, “I am sad that so many excellent reporters and editors—and old friends—are losing their jobs. My first concern is for them; I will do anything I can to help.” As for himself, Graham, who once edited the sports section, said, “I will have to learn a new way to read the paper, since I have started with the sports page since the late 1940’s.”</p><p>What happened to the Bezos of 2013, a self-proclaimed optimist who seemed to have absorbed the importance of the <em>Post</em> in the nation’s journalistic ecosystem? In 2016, dedicating the paper’s new headquarters, he boasted that it had become “a little more swashbuckling” and had a “little more swagger.” As recently as December, 2024, at the New York <em>Times</em>’ DealBook Summit, Bezos expressed his commitment to nurturing the paper: “The advantage I bring to the <em>Post</em> is when they need financial resources, I’m available. I’m like that. I’m the doting parent in that regard.” Not long ago, he envisioned attracting as many as a hundred million paying subscribers to the <em>Post</em>. With these brutal cuts, he seems content to let the paper limp along, diminished in size and ambition.</p><p>“In the beginning, he was wonderful,” Sally Quinn, the veteran <em>Post</em> contributor and wife of its legendary executive editor, Ben Bradlee, told me of Bezos. “He was smart and funny and kind and interested. He was joyful. He was a person of integrity and conscience. He really meant it when he said this was a sacred trust, to buy the <em>Post</em>. And now I don’t know who this person is.”</p><p>The author David Maraniss was with the <em>Post</em> for forty-eight years. He resigned as an associate editor in 2024, after Bezos killed the editorial page’s planned endorsement of Kamala Harris. “He bought the <em>Post</em> thinking that it would give him some gravitas and grace that he couldn’t get just from billions of dollars, and then the world changed,” Maraniss said of Bezos. “Now I don’t think he gives us—I don’t think he gives a flying fuck.”</p><p>I asked Maraniss what cuts of this magnitude would mean for the institution. “I don’t even want to call it the Washington <em>Post</em>,” he said. “I don’t know what it’ll be without all of that.”</p><p>The first sign of impending layoffs came in late January, when the sports staff was informed that plans to send writers to Italy to cover the Winter Olympics had been cancelled. (Management later agreed to send a smaller crew.) In the following days, as rumors began to spread of severe cuts, the paper’s reporters began posting messages directed at Bezos on X, with the plaintive hashtag #SaveThePost. “Our reporters on the ground drove exclusive coverage during pivotal moments of recent history,” the foreign staff wrote to Bezos. “We have so much left to do.” The local staff noted that it had already been slashed in half in the past five years. “Watergate,” they wrote, “started as a local story.”</p></div><div data-journey-hook="grid-wrapper" data-testid="BodyWrapper"><p>It did not help the staff’s morale that Lewis and his team were hobnobbing in Davos, or that Bezos and his wife, Lauren Sánchez, were in Paris for Haute Couture Week. More troubling were reminders that Bezos, who once emblazoned “Democracy Dies in Darkness” on the paper’s masthead, appears to be pursuing a policy of appeasement toward the Trump Administration. During the first Trump term, Bezos stood by the <em>Post</em> even when his stewardship threatened to cost him billions in government contracts. Now Bezos had not said a word about a recent F.B.I. raid on the home of the <em>Post</em> federal-government reporter Hannah Natanson, in which the agency seized her phones, laptops, and other devices. As the staff awaited the axe, the President and the First Lady celebrated the première of “<a href="https://www.newyorker.com/culture/critics-notebook/melania-is-a-forty-million-dollar-journey-into-the-void">Melania</a>,” a documentary that Amazon had licensed for forty million dollars and was reported to be spending another thirty-five million to promote. The deal was inked after Bezos had dinner with the Trumps shortly before the Inauguration.</p><p>Martin Baron, who oversaw coverage at the paper that garnered eleven Pulitzer Prizes during his eight years as executive editor, said in a statement, “This ranks among the darkest days in the history of one of the world’s greatest news organizations. The Washington <em>Post</em>’s ambitions will be sharply diminished, its talented and brave staff will be further depleted, and the public will be denied the ground-level, fact-based reporting in our communities and around the world that is needed more than ever.” The news industry is in “a period of head-spinning change,” Baron told me. But the <em>Post’s</em> problems “were made infinitely worse by ill-conceived decisions that came from the very top.” He pointed to Bezos’s decision to kill the Harris endorsement—a “gutless order” that cost the paper more than two hundred fifty thousand subscribers. “Loyal readers, livid as they saw owner Jeff Bezos betraying the values he was supposed to uphold, fled The Post. In truth, they were driven away, by the hundreds of thousands,” Baron said. “Bezos’s sickening efforts to curry favor with President Trump have left an especially ugly stain of their own. This is a case study in near-instant, self-inflicted brand destruction.”</p><p>I spent more than forty years at the <em>Post</em>, as a reporter, an editor, an editorial writer, and a columnist. I <a href="https://www.newyorker.com/news/essay/why-ruth-marcus-left-the-washington-post">resigned</a> last March, after Bezos announced that the Opinions section, where I worked, would henceforth be concentrating on the twin pillars of “personal liberties and free markets.” More alarming, Bezos advised, “Viewpoints opposing those pillars will be left to be published by others.” We had been an opinion section reflecting a wide range of views—which Bezos himself had encouraged. It seemed obvious that this change was deeply misguided.</p><p>I had written a column critical of the non-endorsement decision several months earlier. The paper published it without any substantive changes. But, when I wrote a column disagreeing with the no-dissent-allowed dictum, I was told that Lewis had killed it—it apparently didn’t meet the “high bar” for the <em>Post</em> to write about itself—and declined my request to meet. I submitted my letter of resignation. A new editorial-page editor went on to shift both unsigned editorials and signed opinion columns dramatically to the right, to the point that no liberal columnists remain. One recent <a data-offer-url="https://www.washingtonpost.com/opinions/2025/10/25/ballroom-east-wing-trump-white-house/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.washingtonpost.com/opinions/2025/10/25/ballroom-east-wing-trump-white-house/&quot;}" href="https://www.washingtonpost.com/opinions/2025/10/25/ballroom-east-wing-trump-white-house/" rel="nofollow noopener" target="_blank">editorial</a> praised the President’s plan for a new ballroom and excused his unauthorized bulldozing of the East Wing, saying that “the blueprints would have faced death by a thousand papercuts.” <a data-offer-url="https://www.washingtonpost.com/opinions/2025/09/05/war-department-defense-trump-rebrand/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.washingtonpost.com/opinions/2025/09/05/war-department-defense-trump-rebrand/&quot;}" href="https://www.washingtonpost.com/opinions/2025/09/05/war-department-defense-trump-rebrand/" rel="nofollow noopener" target="_blank">Another</a> endorsed the move to rename the Defense Department the Department of War as “a worthy blow against government euphemism.” There are some editorials critical of Trump, but the inclination to fawning praise is unmistakable. Had I not defenestrated myself, I would, no doubt, have been advised to take my buyout and go.</p></div><div data-journey-hook="grid-wrapper" data-testid="BodyWrapper"><p>But I am not—at least, I have not been—a Bezos-hater. I am grateful for the resources, financial and technological, that he devoted to the paper in his early years as owner. The surprise of Bezos’s tenure at the <em>Post</em> has been his bad business decisions. Fred Ryan, a former chief of staff to Ronald Reagan and founding president of <em>Politico</em>, was hired as the publisher and C.E.O. in 2014 and oversaw a period of spectacular growth. Buoyed by Bezos-funded expansion and the public’s fixation on the new Trump Administration, the number of digital subscribers soared from thirty-five thousand when he arrived to two and a half million when he left, in the summer of 2023. But Ryan failed to develop an adequate plan for how the newspaper would thrive in a post-Trump environment. As traffic and revenue plunged, Ryan found himself increasingly at odds with the newsroom. He held a year-end town-hall meeting in 2022 at which he announced that layoffs were coming, and then, to the consternation of the staff, left without taking questions. As Clare Malone <a href="https://www.newyorker.com/magazine/2025/05/26/is-jeff-bezos-selling-out-the-washington-post">reported</a> for <em>The New Yorker</em>, Woodward beseeched Bezos to intercede. The owner made a rare visit to the paper in January, 2023, for meetings with key staffers, taking notes on a legal pad as they poured out their anxiety.</p><p>Ryan left that summer, but Lewis, his eventual replacement, accomplished the feat of making the newsroom nostalgic for Ryan. A decade earlier, Lewis, then a senior executive in Rupert Murdoch’s British-tabloid empire, had played a pivotal role in dealing with the fallout from the phone-hacking scandal at some of Murdoch’s papers. Lewis had said that he was acting to protect “journalistic integrity,” when the <em>Post</em> questioned him about his actions during that time, but in 2024 questions arose, fuelled by a civil lawsuit brought against the papers, about whether Lewis had sought to conceal evidence, including by carrying out a plan to delete millions of e-mails. (Lewis has said the allegations against him were “completely untrue.”) At the <em>Post</em>, Lewis clashed with executive editor Sally Buzbee over coverage of the story, reportedly insisting that it was not newsworthy. Shortly afterward, Lewis announced Buzbee’s departure, and his plan to replace her with Robert Winnett, a former colleague of his from London’s <em>Daily Telegraph</em> and <em>Sunday Times</em>. The <em>Post</em> and the <em>Times</em> <a data-offer-url="https://www.washingtonpost.com/investigations/2024/06/16/washington-post-editor-robert-winnett/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.washingtonpost.com/investigations/2024/06/16/washington-post-editor-robert-winnett/&quot;}" href="https://www.washingtonpost.com/investigations/2024/06/16/washington-post-editor-robert-winnett/" rel="nofollow noopener" target="_blank">both</a> <a data-offer-url="https://www.nytimes.com/2024/06/15/world/europe/will-lewis-records-uk-editor.html" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.nytimes.com/2024/06/15/world/europe/will-lewis-records-uk-editor.html&quot;}" href="https://www.nytimes.com/2024/06/15/world/europe/will-lewis-records-uk-editor.html" rel="nofollow noopener" target="_blank">reported</a> on how Lewis and Winnett had used fraudulently obtained material as the basis for articles. “His ambition outran his ethics,” one of Lewis’s former reporters told the <em>Times</em>. Winnett ended up withdrawing from the position, but the episode poisoned relations between Lewis and the newsroom.</p><p>The staff, meanwhile, became increasingly concerned that Lewis was offering corporate word salad in place of a vision to address the <em>Post</em>’s decline. “Fix it, build it, scale it” was his catchphrase when he arrived, in January, 2024. In June of that year came an amorphous plan for what Lewis called a “third newsroom.” (The second newsroom, we were surprised to learn, was the Opinions section.) First, it was to focus on social media and service journalism. Then it was rechristened WP Ventures and, according to a memo to staff, would “focus entirely on building personality-driven content and franchises around personalities.” By February, 2025, the situation had deteriorated to the point that two former top editors, Leonard Downie and Robert Kaiser, wrote to Bezos about Lewis. “Replacing him is a crucial first step in saving The Washington Post,” they urged in an e-mail. Bezos never responded.</p></div><div data-journey-hook="grid-wrapper" data-testid="BodyWrapper"><p>Downie, who served as executive editor from 1991 to 2008, contrasted the paths of the <em>Times</em> and the <em>Post</em>. During the past decade, the <em>Times</em> transformed itself into a one-stop-shopping environment that lured readers with games such as Spelling Bee, a cooking app, and a shopping guide. By the end of 2025, it was reporting close to thirteen million digital subscribers and an operating profit of more than a hundred and ninety-two million dollars. The <em>Post</em> does not release information about its digital subscribers, but it was reported to have two and a half million digital subscribers at the time of the non-endorsement decision, in 2024.</p><p>“One of the big differences to me was that they hired a publisher”—Ryan—“who didn’t come up with any ideas,” Downie told me. “And then when he left&nbsp;.&nbsp;.&nbsp;.&nbsp;we knew that Bezos was losing money, and we were encouraged by the fact that they were looking for somebody who could improve the business side of the paper and the circulation side of the paper. And then they chose this guy who we hardly ever heard from, who had a checkered past in British journalism.”</p><p>Writing last month on a private Listserv for former <em>Post</em> employees, Paul Farhi, who as the media reporter for the <em>Post</em> covered Bezos’s acquisition of the paper, shared his “utter mystification and bafflement” about Bezos’s tolerance of Lewis. “Even as a hands-off boss,” he wondered, “could Bezos not see what was obvious to even casual observers within a few months of Will’s arrival—that Will was ill-suited to the Post, that he had alienated the newsroom, that he had an ethically suspect past, and—most important—that none of his big ideas was working or even being implemented?” (Farhi, who took a buyout in 2023, gave me permission to quote his message.)</p><p>Even before these new cuts, a parade of key staffers had left the <em>Post</em>. A beloved managing editor, Matea Gold, went to the <em>Times</em>. The national editor, Philip Rucker, decamped to CNN, and the political reporter Josh Dawsey to the <em>Wall Street</em> <em>Journal</em>. The <em>Atlantic</em> hired, among others, three stars of the paper’s White House team: Ashley Parker, Michael Scherer, and Toluse Olorunnipa. These are losses that would take years to rebuild—if the <em>Post</em> were in a rebuilding mode. The <em>Post</em>, Woodward said, “lives and is doing an extraordinary reporting job on the political crisis that is Donald Trump”—including its scoop on the second strike to kill survivors of an attack on an alleged Venezuelan drug boat. But the print edition is a shadow of its former self, with metro, style, and sports melded into an anemic second section; daily print circulation is now below one hundred thousand. More pressingly, it’s unclear whether a newsroom so stripped of resources can sustain the quality of its work.</p><p>The sports columnist Sally Jenkins, who left the <em>Post</em> in August, 2025, as part of the second wave of buyouts, has been more supportive of management than many other <em>Post</em> veterans. So it was striking that, when we spoke recently, she was both passionate about the work of her newsroom colleagues and unsparing about how the business side had failed them. “When you whack at these sections, you’re whacking at the roots of the tree,” she told me. “We train great journalists in every section of the paper, and we train them to cover every subject on the globe. And when you whack whole sections of people away, you are really, really in danger of killing the whole tree.” When I asked how she felt about the losses, Jenkins said, “My heart is cracked in about five different pieces.”</p></div><div data-journey-hook="grid-wrapper" data-testid="BodyWrapper"><p>Jenkins, who was in California covering Super Bowl week for the <em>Atlantic</em>, has spent a career studying what accounts for the difference between winning teams and losing ones. Bezos, she said, had been generous with his money and laudable for never interfering in the work of the newsroom. But, she added, “making money at journalism, you have to break rocks with a shovel. You have to love thinking about journalism to the point that it wakes you up at night with an idea, and then you have to be willing to try it. And I don’t see a sense that he loves the business enough to think about it at night. It’s almost like he’s treated it like Pets.com—an interesting experiment that he’s willing to lose some money on until he’s not. But the difference with this business is it’s not Pets.com. It’s not a business that just disappears into the muck of venture capitalism. It’s a business that is essential to the survival of the Republic, for Christ’s sake. So you don’t fuck around with it like that.”</p><p>As <em>Post</em> staffers and alumni braced for the cuts, I called Kaiser, the former managing editor, who spent more than half a century at the paper. “Mr. Bezos’s personal system has failed him in a way I fear he doesn’t grasp,” Kaiser, now eighty-two, told me. “He has no sense of the damage that will be done to his reputation in history if he becomes seen as the man who destroyed the institution that Katharine Graham”—the famed publisher who led the paper from the sixties to the nineties—“and Ben Bradlee built.” Kaiser recalled arriving at the paper’s London bureau in 1964. “If I say, ‘I’m Kaiser from the Washington <em>Post’</em>—what’s that? They never heard of it.” A decade later, he was posted in Moscow, as Woodward and Carl Bernstein were breaking the Watergate story. “Explaining was not necessary,” Kaiser said. “The Russians, in fact, had a gloriously exaggerated impression of the Washington <em>Post</em> as the king-maker and the king-destroyer.”</p><p>Bezos, Kaiser continued, “knew what the role was, acknowledged the role—those words ‘doting parent’—and then he walked away from it. What the hell?” The damage, he predicted, will reverberate beyond the immediate cuts. “What purpose does any honorable, attractive, competent journalist have for remaining at the <em>Post</em>? None.”</p><p>At one point, as we talked about the transformation of the <em>Post</em>, Kaiser stopped himself. “I’m going to cry,” he said, and paused. “Oh, God, it’s killing me.”</p><p>Bezos may be tiring of the <em>Post</em>, but he has not seemed inclined to sell the paper. Nor is it clear that would be a better, or at this point even feasible, outcome. Newspapers across the country are being bought up by private-equity firms that are essentially selling off the valuable parts. But there is another model for Bezos to consider: turning the <em>Post</em> into a nonprofit, endowed by Bezos but operating independently of him. For Bezos, this would reduce the role of the <em>Post</em> as a headache and a threat to other, more favored endeavors, such as his rocket company, Blue Origin. For the <em>Post</em>, assuming the endowment is sufficient, it would provide that continuing runway.</p></div><div data-journey-hook="grid-wrapper" data-testid="BodyWrapper"><p>There are models for this approach. In Philadelphia, the late cable-television tycoon H.&nbsp;F.&nbsp;“Gerry” Lenfest purchased the <em>Inquirer</em>, the <em>Daily News</em>, and Philly.com in 2015, and the following year donated the publications to a charitable trust. “What would the city be without the <em>Inquirer</em> and the <em>Daily News</em>?” asked Lenfest, whose contribution to the endeavor has been valued at almost a hundred and thirty million dollars. In Utah, the investor Paul Huntsman bought the Salt Lake <em>Tribune</em> from the hedge fund Alden Global Capital in 2016; three years later, he transformed it into a nonprofit, supported in part by tax-deductible contributions from readers.</p><p>Writing in the <em>Columbia Journalism Review</em> in 2024, Steven Waldman <a href="https://www.cjr.org/opinion/waldman-bezos-washington-post-donation-charity-goodwill-endorsements-harris-spiked.php">suggested</a> that Bezos follow a similar course. “&nbsp;‘Nonprofit’ does not mean ‘losing money,’&nbsp;” Waldman wrote. “Nonprofit news organizations can sell ads, offer subscriptions, and take donations. Done well, it is an especially strong business model, because it provides an extra revenue stream (philanthropy) and is deeply embedded in serving the community.” My quibble with Waldman’s pitch is that he asked Bezos to ante up a paltry hundred million. When Bezos purchased the <em>Post,</em> his net worth was about twenty-five billion; it is now an estimated two hundred fifty billion. Why not one per cent of that for the <em>Post</em>, enough to sustain the paper indefinitely? A pipe dream, I know, but this arrangement would make Bezos the savior of the <em>Post</em>, not the man who presided over its demise.</p><p>In the 1941 movie “Citizen Kane,” Charles Foster Kane, a newspaper publisher who, like Bezos, is one of the richest men in the world, is confronted by his legal guardian, Walter Thatcher, about the folly of funding his paper. “Honestly, my boy, don’t you think it’s rather unwise to continue this philanthropic enterprise, this <em>Inquirer</em> that’s costing you a million dollars a year?” Thatcher demands. “You’re right, Mr. Thatcher. I did lose a million dollars last year,” Kane replies. “I expect to lose a million dollars this year. I expect to lose a million dollars next year. You know, Mr. Thatcher, at the rate of a million dollars a year, I’ll have to close this place in sixty years.” Update Kane’s outlays to assume losses of a hundred million annually, in perpetuity. By that math, Bezos would have more than two millennia before needing to turn out the lights.&nbsp;♦</p></div></div></article><div><div data-testid="RowWrapper" data-journey-hook="grid-wrapper"><p><a href="https://www.newyorker.com/contributors/ruth-marcus"><span><picture><source media="(max-width: 767px)" srcset="https://media.newyorker.com/photos/68b85a13ad1f1326c3869e1a/1:1/w_120,c_limit/ruth_marcus.png 120w, https://media.newyorker.com/photos/68b85a13ad1f1326c3869e1a/1:1/w_240,c_limit/ruth_marcus.png 240w" sizes="100vw"><source media="(min-width: 768px)" srcset="https://media.newyorker.com/photos/68b85a13ad1f1326c3869e1a/1:1/w_120,c_limit/ruth_marcus.png 120w, https://media.newyorker.com/photos/68b85a13ad1f1326c3869e1a/1:1/w_240,c_limit/ruth_marcus.png 240w" sizes="100vw"><img alt="" loading="lazy" src="https://media.newyorker.com/photos/68b85a13ad1f1326c3869e1a/1:1/w_270%2Cc_limit/ruth_marcus.png" data-src="https://media.newyorker.com/photos/68b85a13ad1f1326c3869e1a/1:1/w_270%2Cc_limit/ruth_marcus.png"></picture></span></a></p></div><div data-journey-hook="grid-wrapper" data-testid="ContentFooterBottom" data-attr-viewport-monitor=""><p data-testid="SectionTitle"><header>Read More</header></p><div data-testid="SummaryCollectionGridItems"><div data-item="{&quot;dangerousHed&quot;:&quot;What a Viral YouTube Video Says About the Future of Journalism&quot;,&quot;index&quot;:0,&quot;contentType&quot;:&quot;venue&quot;,&quot;hotelLink&quot;:&quot;https://www.newyorker.com/news/fault-lines/what-a-viral-youtube-video-says-about-the-future-of-journalism#intcid=_the-new-yorker-article-bottom-recirc_09f2a729-10bd-45d2-a373-32e3290626c8_roberta-similarity1_fallback_text2vec1&quot;,&quot;layout&quot;:&quot;GridFourColumns&quot;}" role="button" tabindex="0"><a data-component-type="recirc-river" data-recirc-id="item-hed-1" data-recirc-pattern="summary-item" href="https://www.newyorker.com/news/fault-lines/what-a-viral-youtube-video-says-about-the-future-of-journalism#intcid=_the-new-yorker-article-bottom-recirc_09f2a729-10bd-45d2-a373-32e3290626c8_roberta-similarity1_fallback_text2vec1" target="_self"><p>What a Viral YouTube Video Says About the Future of Journalism</p></a><p>A streamer’s investigation of fraud in Minnesota garnered millions of views. His content was questionable, but his methods will likely inspire scores of imitators.</p></div><div data-item="{&quot;dangerousHed&quot;:&quot;The Brilliance and the Badness of “The Sun Also Rises”&quot;,&quot;index&quot;:1,&quot;contentType&quot;:&quot;venue&quot;,&quot;hotelLink&quot;:&quot;https://www.newyorker.com/books/second-read/the-brilliance-and-the-badness-of-the-sun-also-rises#intcid=_the-new-yorker-article-bottom-recirc_09f2a729-10bd-45d2-a373-32e3290626c8_roberta-similarity1_fallback_text2vec1&quot;,&quot;layout&quot;:&quot;GridFourColumns&quot;}" role="button" tabindex="0"><a data-component-type="recirc-river" data-recirc-id="item-hed-2" data-recirc-pattern="summary-item" href="https://www.newyorker.com/books/second-read/the-brilliance-and-the-badness-of-the-sun-also-rises#intcid=_the-new-yorker-article-bottom-recirc_09f2a729-10bd-45d2-a373-32e3290626c8_roberta-similarity1_fallback_text2vec1" target="_self"><p>The Brilliance and the Badness of “The Sun Also Rises”</p></a><p>Although Ernest Hemingway’s novel makes positive claims about what one should be—brave, admiring of nature and grace—its architecture is held up primarily by hatred.</p></div><div data-item="{&quot;dangerousHed&quot;:&quot;Gavin Newsom Is Playing the Long Game&quot;,&quot;index&quot;:2,&quot;contentType&quot;:&quot;venue&quot;,&quot;hotelLink&quot;:&quot;https://www.newyorker.com/magazine/2026/02/09/gavin-newsom-profile#intcid=_the-new-yorker-article-bottom-recirc_09f2a729-10bd-45d2-a373-32e3290626c8_roberta-similarity1_fallback_text2vec1&quot;,&quot;layout&quot;:&quot;GridFourColumns&quot;}" role="button" tabindex="0"><a data-component-type="recirc-river" data-recirc-id="item-hed-3" data-recirc-pattern="summary-item" href="https://www.newyorker.com/magazine/2026/02/09/gavin-newsom-profile#intcid=_the-new-yorker-article-bottom-recirc_09f2a729-10bd-45d2-a373-32e3290626c8_roberta-similarity1_fallback_text2vec1" target="_self"><p>Gavin Newsom Is Playing the Long Game</p></a><p>California’s governor has been touted as the Democrats’ best shot in 2028. But first he’ll need to convince voters that he’s not just a slick establishment politician.</p></div><div data-item="{&quot;dangerousHed&quot;:&quot;J. D. Vance’s Notable Absence on Venezuela&quot;,&quot;index&quot;:3,&quot;contentType&quot;:&quot;venue&quot;,&quot;hotelLink&quot;:&quot;https://www.newyorker.com/news/the-lede/j-d-vances-notable-absence-on-venezuela#intcid=_the-new-yorker-article-bottom-recirc_09f2a729-10bd-45d2-a373-32e3290626c8_roberta-similarity1_fallback_text2vec1&quot;,&quot;layout&quot;:&quot;GridFourColumns&quot;}" role="button" tabindex="0"><a data-component-type="recirc-river" data-recirc-id="item-hed-4" data-recirc-pattern="summary-item" href="https://www.newyorker.com/news/the-lede/j-d-vances-notable-absence-on-venezuela#intcid=_the-new-yorker-article-bottom-recirc_09f2a729-10bd-45d2-a373-32e3290626c8_roberta-similarity1_fallback_text2vec1" target="_self"><p>J. D. Vance’s Notable Absence on Venezuela</p></a><p>Was the Vice-President’s exclusion from the operation in Venezuela an expression of his anti-interventionist ideology—or a political calculation?</p></div><div data-item="{&quot;dangerousHed&quot;:&quot;Why Donald Trump Wants Greenland (and Everything Else)&quot;,&quot;index&quot;:4,&quot;contentType&quot;:&quot;venue&quot;,&quot;hotelLink&quot;:&quot;https://www.newyorker.com/news/letter-from-trumps-washington/why-donald-trump-wants-greenland-and-everything-else#intcid=_the-new-yorker-article-bottom-recirc_09f2a729-10bd-45d2-a373-32e3290626c8_roberta-similarity1_fallback_text2vec1&quot;,&quot;layout&quot;:&quot;GridFourColumns&quot;}" role="button" tabindex="0"><div><p><span><span>Letter from Trump’s Washington</span></span></p></div><a data-component-type="recirc-river" data-recirc-id="item-hed-5" data-recirc-pattern="summary-item" href="https://www.newyorker.com/news/letter-from-trumps-washington/why-donald-trump-wants-greenland-and-everything-else#intcid=_the-new-yorker-article-bottom-recirc_09f2a729-10bd-45d2-a373-32e3290626c8_roberta-similarity1_fallback_text2vec1" target="_self"><p>Why Donald Trump Wants Greenland (and Everything Else)</p></a><p>There’s no Trump Doctrine, just a map of the world that the President wants to write his name on in big gold letters.</p></div><div data-item="{&quot;dangerousHed&quot;:&quot;How Colombia’s President Reached an Uneasy Détente with Donald Trump&quot;,&quot;index&quot;:5,&quot;contentType&quot;:&quot;venue&quot;,&quot;hotelLink&quot;:&quot;https://www.newyorker.com/news/the-lede/how-colombias-president-reached-an-uneasy-detente-with-donald-trump#intcid=_the-new-yorker-article-bottom-recirc_09f2a729-10bd-45d2-a373-32e3290626c8_roberta-similarity1_fallback_text2vec1&quot;,&quot;layout&quot;:&quot;GridFourColumns&quot;}" role="button" tabindex="0"><a data-component-type="recirc-river" data-recirc-id="item-hed-6" data-recirc-pattern="summary-item" href="https://www.newyorker.com/news/the-lede/how-colombias-president-reached-an-uneasy-detente-with-donald-trump#intcid=_the-new-yorker-article-bottom-recirc_09f2a729-10bd-45d2-a373-32e3290626c8_roberta-similarity1_fallback_text2vec1" target="_self"><p>How Colombia’s President Reached an Uneasy Détente with Donald Trump</p></a><p>After the attack in Venezuela, its neighbor state reckons with U.S. aggression.</p></div><div data-item="{&quot;dangerousHed&quot;:&quot;Jay Powell, the Prepster Banker Who Is Standing Up to Trump&quot;,&quot;index&quot;:6,&quot;contentType&quot;:&quot;venue&quot;,&quot;hotelLink&quot;:&quot;https://www.newyorker.com/news/the-lede/jay-powell-the-prepster-banker-who-is-standing-up-to-trump#intcid=_the-new-yorker-article-bottom-recirc_09f2a729-10bd-45d2-a373-32e3290626c8_roberta-similarity1_fallback_text2vec1&quot;,&quot;layout&quot;:&quot;GridFourColumns&quot;}" role="button" tabindex="0"><a data-component-type="recirc-river" data-recirc-id="item-hed-7" data-recirc-pattern="summary-item" href="https://www.newyorker.com/news/the-lede/jay-powell-the-prepster-banker-who-is-standing-up-to-trump#intcid=_the-new-yorker-article-bottom-recirc_09f2a729-10bd-45d2-a373-32e3290626c8_roberta-similarity1_fallback_text2vec1" target="_self"><p>Jay Powell, the Prepster Banker Who Is Standing Up to Trump</p></a><p>The seventy-two-year-old Fed chairman put to shame the heads of law firms, universities, and public companies who have caved to the White House.</p></div><div data-item="{&quot;dangerousHed&quot;:&quot;Aaron Rodgers, Football’s Rorschach Quarterback&quot;,&quot;index&quot;:7,&quot;contentType&quot;:&quot;venue&quot;,&quot;hotelLink&quot;:&quot;https://www.newyorker.com/sports/sporting-scene/aaron-rodgers-footballs-rorschach-quarterback#intcid=_the-new-yorker-article-bottom-recirc_09f2a729-10bd-45d2-a373-32e3290626c8_roberta-similarity1_fallback_text2vec1&quot;,&quot;layout&quot;:&quot;GridFourColumns&quot;}" role="button" tabindex="0"><a data-component-type="recirc-river" data-recirc-id="item-hed-8" data-recirc-pattern="summary-item" href="https://www.newyorker.com/sports/sporting-scene/aaron-rodgers-footballs-rorschach-quarterback#intcid=_the-new-yorker-article-bottom-recirc_09f2a729-10bd-45d2-a373-32e3290626c8_roberta-similarity1_fallback_text2vec1" target="_self"><p>Aaron Rodgers, Football’s Rorschach Quarterback</p></a><p>The Pittsburgh Steelers gambled on the forty-two-year-old, one of the N.F.L.’s most polarizing players, to try to end their playoff disappointments. Will it pay off?</p></div><div data-item="{&quot;dangerousHed&quot;:&quot;The Dangerous Paradox of A.I. Abundance&quot;,&quot;index&quot;:8,&quot;contentType&quot;:&quot;venue&quot;,&quot;hotelLink&quot;:&quot;https://www.newyorker.com/news/the-financial-page/the-dangerous-paradox-of-ai-abundance#intcid=_the-new-yorker-article-bottom-recirc_09f2a729-10bd-45d2-a373-32e3290626c8_roberta-similarity1_fallback_text2vec1&quot;,&quot;layout&quot;:&quot;GridFourColumns&quot;}" role="button" tabindex="0"><a data-component-type="recirc-river" data-recirc-id="item-hed-9" data-recirc-pattern="summary-item" href="https://www.newyorker.com/news/the-financial-page/the-dangerous-paradox-of-ai-abundance#intcid=_the-new-yorker-article-bottom-recirc_09f2a729-10bd-45d2-a373-32e3290626c8_roberta-similarity1_fallback_text2vec1" target="_self"><p>The Dangerous Paradox of A.I. Abundance</p></a><p>Silicon Valley envisions artificial intelligence ushering in an era of economic plenty. But what if the benefits are largely confined to corporations and investors that own the technology itself?</p></div><div data-item="{&quot;dangerousHed&quot;:&quot;Denmark Is Sick of Being Bullied by Trump&quot;,&quot;index&quot;:9,&quot;contentType&quot;:&quot;venue&quot;,&quot;hotelLink&quot;:&quot;https://www.newyorker.com/magazine/2026/01/19/denmark-is-sick-of-being-bullied-by-trump#intcid=_the-new-yorker-article-bottom-recirc_09f2a729-10bd-45d2-a373-32e3290626c8_roberta-similarity1_fallback_text2vec1&quot;,&quot;layout&quot;:&quot;GridFourColumns&quot;}" role="button" tabindex="0"><a data-component-type="recirc-river" data-recirc-id="item-hed-10" data-recirc-pattern="summary-item" href="https://www.newyorker.com/magazine/2026/01/19/denmark-is-sick-of-being-bullied-by-trump#intcid=_the-new-yorker-article-bottom-recirc_09f2a729-10bd-45d2-a373-32e3290626c8_roberta-similarity1_fallback_text2vec1" target="_self"><p>Denmark Is Sick of Being Bullied by Trump</p></a><p>The U.S., once Denmark’s closest ally, is threatening to steal Greenland and attacking the country’s wind-power industry. Is this a permanent breakup?</p></div><div data-item="{&quot;dangerousHed&quot;:&quot;Does Every Marriage Need a Prenup?&quot;,&quot;index&quot;:10,&quot;contentType&quot;:&quot;venue&quot;,&quot;hotelLink&quot;:&quot;https://www.newyorker.com/podcast/the-new-yorker-radio-hour/does-every-marriage-need-a-prenup#intcid=_the-new-yorker-article-bottom-recirc_09f2a729-10bd-45d2-a373-32e3290626c8_roberta-similarity1_fallback_text2vec1&quot;,&quot;layout&quot;:&quot;GridFourColumns&quot;}" role="button" tabindex="0"><div><p><span><span>The New Yorker Radio Hour</span></span></p></div><a data-component-type="recirc-river" data-recirc-id="item-hed-11" data-recirc-pattern="summary-item" href="https://www.newyorker.com/podcast/the-new-yorker-radio-hour/does-every-marriage-need-a-prenup#intcid=_the-new-yorker-article-bottom-recirc_09f2a729-10bd-45d2-a373-32e3290626c8_roberta-similarity1_fallback_text2vec1" target="_self"><p>Does Every Marriage Need a Prenup?</p></a><p>The staff writer Jennifer Wilson explores why prenuptial agreements have boomed in popularity among millennial and Gen Z couples.</p></div><div data-item="{&quot;dangerousHed&quot;:&quot;Barry Blitt’s “Guzzler”&quot;,&quot;index&quot;:11,&quot;contentType&quot;:&quot;venue&quot;,&quot;hotelLink&quot;:&quot;https://www.newyorker.com/culture/cover-story/cover-story-2026-01-19#intcid=_the-new-yorker-article-bottom-recirc_09f2a729-10bd-45d2-a373-32e3290626c8_roberta-similarity1_fallback_text2vec1&quot;,&quot;layout&quot;:&quot;GridFourColumns&quot;}" role="button" tabindex="0"><a data-component-type="recirc-river" data-recirc-id="item-hed-12" data-recirc-pattern="summary-item" href="https://www.newyorker.com/culture/cover-story/cover-story-2026-01-19#intcid=_the-new-yorker-article-bottom-recirc_09f2a729-10bd-45d2-a373-32e3290626c8_roberta-similarity1_fallback_text2vec1" target="_self"><p>Barry Blitt’s “Guzzler”</p></a><p>Trump’s thirst for Venezuela.</p></div></div></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Claude Code for Infrastructure (208 pts)]]></title>
            <link>https://www.fluid.sh/</link>
            <guid>46889703</guid>
            <pubDate>Wed, 04 Feb 2026 18:34:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.fluid.sh/">https://www.fluid.sh/</a>, See on <a href="https://news.ycombinator.com/item?id=46889703">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-astro-cid-j7pv25f6=""> <header data-astro-cid-j7pv25f6=""> <div data-astro-cid-j7pv25f6="">  <p data-astro-cid-j7pv25f6="">
Claude Code for infrastructure. Debug, act, and audit
                    everything Fluid does on your infrastructure.
</p> <h2 data-astro-cid-j7pv25f6="">What does that mean?</h2> <p data-astro-cid-j7pv25f6="">
Fluid is a terminal agent that do work on production infrastructure like VMs/K8s cluster/etc. by making sandbox clones of the infrastructure for AI agents to work on, allowing the agents to run commands, test connections, edit files, and then generate Infra-as-code like an Ansible Playbook to be applied on production.
</p> <h2 data-astro-cid-j7pv25f6="">
Why not just use an LLM to generate Infrastructure-as-Code (IaC)?
</h2> <p data-astro-cid-j7pv25f6="">
LLMs are great at generating Terraform, OpenTofu, Ansible, etc. but bad at guessing how production systems work. By giving access to a clone of the infrastructure, agents can explore, run commands, test things before writing the IaC, giving them better context and a place to test ideas and changes before deploying.

                I got the idea after seeing how much Claude Code has helped me work on code, I thought "I wish there was something like that for infrastructure", and here we are.
</p> <h2 data-astro-cid-j7pv25f6="">
Why not just provide tools, skills, MCP server to Claude Code?
</h2> <p data-astro-cid-j7pv25f6="">
Safety. I didn't want CC to SSH into a prod machine from where it is running locally (real problem!). I wanted to lock down the tools it can run to be only on sandboxes while also giving it autonomy to create sandboxes and not have access to anything else.

                Fluid gives access to a live output of commands run (it's pretty cool) and does this by ephemeral SSH Certificates. Fluid gives tools for creating IaC and requires human approval for creating sandboxes on hosts with low memory/CPU and for accessing the internet or installing packages.
</p> <!-- <p class="mt-4 text-neutral-400">
                    Create sandboxes from VMs, investigate, plan, execute,
                    generate Ansible playbooks, and audit everything.
                </p> --> <h2 data-astro-cid-j7pv25f6="">
Installation
</h2> <p data-astro-cid-j7pv25f6="">Note: this is a terminal agent (like Claude Code) meant to be installed on your local laptop/workstation</p> <div data-astro-cid-j7pv25f6=""> <div data-astro-cid-j7pv25f6=""> <p><span data-astro-cid-j7pv25f6="">$ </span>curl -fsSL https://fluid.sh/install.sh |
                            bash
</p> </div> <p><span data-astro-cid-j7pv25f6="">$ </span>fluid
</p> </div>  </div> </header> <main data-astro-cid-j7pv25f6=""> <div data-astro-cid-j7pv25f6=""> <section data-astro-cid-j7pv25f6=""> <h2 data-astro-cid-j7pv25f6="">
Built for where you already work
</h2> <!-- Feature Cards Grid --> <div data-astro-cid-j7pv25f6=""> <!-- Card 1: Sandbox --> <div data-astro-cid-j7pv25f6=""> <p>[~]</p> <div data-astro-cid-j7pv25f6=""> <h3 data-astro-cid-j7pv25f6="">Sandbox Isolation</h3> <p data-astro-cid-j7pv25f6="">Clone VMs instantly. Test changes in isolation before touching production.</p> </div> </div> <!-- Card 2: Explore --> <div data-astro-cid-j7pv25f6=""> <p>ls</p> <div data-astro-cid-j7pv25f6=""> <h3 data-astro-cid-j7pv25f6="">Context-Aware</h3> <p data-astro-cid-j7pv25f6="">Fluid explores your host first - OS, packages, CLI tools - then adapts.</p> </div> </div> <!-- Card 3: Audit --> <div data-astro-cid-j7pv25f6=""> <p>&gt;&gt;&gt;</p> <div data-astro-cid-j7pv25f6=""> <h3 data-astro-cid-j7pv25f6="">Full Audit Trail</h3> <p data-astro-cid-j7pv25f6="">Every command logged. Every change tracked. Review before production.</p> </div> </div> <!-- Card 4: Ansible --> <div data-astro-cid-j7pv25f6=""> <p>.yaml</p> <div data-astro-cid-j7pv25f6=""> <h3 data-astro-cid-j7pv25f6="">Ansible Playbooks</h3> <p data-astro-cid-j7pv25f6="">Auto-generates playbooks from sandbox work. Reproducible infrastructure.</p> </div> </div> </div> <!-- Workflow Steps --> <!-- <div class="relative">
                        <h3 class="text-neutral-400 text-sm font-mono mb-4 uppercase tracking-wider">How it works</h3>


                        <div class="hidden md:block absolute top-18 left-0 right-0 h-px bg-neutral-800"></div>
                        <div id="workflow-progress" class="hidden md:block absolute top-18 left-0 h-px bg-linear-to-r from-blue-500 to-blue-400 transition-all duration-1000 ease-out" style="width: 0%;"></div>

                        <div class="grid grid-cols-2 md:grid-cols-4 gap-4">
                            <div class="workflow-step opacity-0 translate-y-4 transition-all duration-500" data-step="1">
                                <div class="relative flex flex-col items-center text-center">
                                    <div class="w-10 h-10 rounded-full bg-neutral-900 border-2 border-neutral-700 flex items-center justify-center mb-3 transition-all duration-300 workflow-dot">
                                        <span class="text-neutral-500 font-mono text-sm transition-colors duration-300">1</span>
                                    </div>
                                    <span class="text-blue-400 font-mono text-sm mb-1">explore</span>
                                    <span class="text-neutral-600 text-xs">Scan host environment</span>
                                </div>
                            </div>


                            <div class="workflow-step opacity-0 translate-y-4 transition-all duration-500" data-step="2">
                                <div class="relative flex flex-col items-center text-center">
                                    <div class="w-10 h-10 rounded-full bg-neutral-900 border-2 border-neutral-700 flex items-center justify-center mb-3 transition-all duration-300 workflow-dot">
                                        <span class="text-neutral-500 font-mono text-sm transition-colors duration-300">2</span>
                                    </div>
                                    <span class="text-blue-400 font-mono text-sm mb-1">plan</span>
                                    <span class="text-neutral-600 text-xs">Build execution strategy</span>
                                </div>
                            </div>

                            <div class="workflow-step opacity-0 translate-y-4 transition-all duration-500" data-step="3">
                                <div class="relative flex flex-col items-center text-center">
                                    <div class="w-10 h-10 rounded-full bg-neutral-900 border-2 border-neutral-700 flex items-center justify-center mb-3 transition-all duration-300 workflow-dot">
                                        <span class="text-neutral-500 font-mono text-sm transition-colors duration-300">3</span>
                                    </div>
                                    <span class="text-blue-400 font-mono text-sm mb-1">execute</span>
                                    <span class="text-neutral-600 text-xs">Run in sandbox</span>
                                </div>
                            </div>

                            <div class="workflow-step opacity-0 translate-y-4 transition-all duration-500" data-step="4">
                                <div class="relative flex flex-col items-center text-center">
                                    <div class="w-10 h-10 rounded-full bg-neutral-900 border-2 border-neutral-700 flex items-center justify-center mb-3 transition-all duration-300 workflow-dot">
                                        <span class="text-neutral-500 font-mono text-sm transition-colors duration-300">4</span>
                                    </div>
                                    <span class="text-blue-400 font-mono text-sm mb-1">export</span>
                                    <span class="text-neutral-600 text-xs">Generate playbook</span>
                                </div>
                            </div>
                        </div>
                    </div> -->  </section> <section data-astro-cid-j7pv25f6=""> <h2 data-astro-cid-j7pv25f6="">Usage</h2> <!-- Timeline container --> <div id="usage-timeline" data-astro-cid-j7pv25f6=""> <!-- Vertical timeline line - grows as items appear -->  <!-- User Prompt - Blue accent -->  <!-- Sandbox Info -->  <!-- OS Detection --> <div data-astro-cid-j7pv25f6="" data-color="neutral" data-tool="run_command" data-command="cat /etc/os-release"> <p><span data-astro-cid-j7pv25f6=""></span> <span data-astro-cid-j7pv25f6="">Running: <span data-astro-cid-j7pv25f6="">cat /etc/os-release</span></span> </p>  </div> <!-- Package Update -->  <!-- Install Apache --> <div data-astro-cid-j7pv25f6="" data-color="neutral" data-tool="run_command" data-command="apt install -y apache2"> <p><span data-astro-cid-j7pv25f6=""></span> <span data-astro-cid-j7pv25f6="">Running: <span data-astro-cid-j7pv25f6="">apt install -y apache2</span></span> </p>  </div> <!-- Create HTML file --> <div data-astro-cid-j7pv25f6="" data-color="neutral" data-tool="run_command" data-command="echo '<h1>Hello</h1>' > /var/www/html/index.html"> <p><span data-astro-cid-j7pv25f6=""></span> <span data-astro-cid-j7pv25f6="">Running: <span data-astro-cid-j7pv25f6="">echo '...' &gt; /var/www/html/index.html</span></span> </p>  </div> <!-- Service Status --> <div data-astro-cid-j7pv25f6="" data-color="neutral" data-tool="run_command" data-command="systemctl status apache2"> <p><span data-astro-cid-j7pv25f6=""></span> <span data-astro-cid-j7pv25f6="">Running: <span data-astro-cid-j7pv25f6="">systemctl status apache2</span></span> </p>  </div> <!-- Verification -->  <!-- Playbook Creation -->  <!-- Playbook Tasks -->  <!-- Final Summary --> <div data-astro-cid-j7pv25f6="" data-color="green" data-tool="summary"> <p>Done! Here's what I accomplished:</p> <div data-astro-cid-j7pv25f6=""> <p><span data-astro-cid-j7pv25f6="">Sandbox Created</span></p><p>- ID: SBX-demo1234</p> <p>- IP: 192.168.122.50</p> </div> <div data-astro-cid-j7pv25f6=""> <p><span data-astro-cid-j7pv25f6="">Apache HTTP Server</span></p><p>- Installed and running</p> <p>- Custom page at /var/www/html/index.html</p> <p>- Verified working with curl</p> </div> <div data-astro-cid-j7pv25f6=""> <p><span data-astro-cid-j7pv25f6="">Ansible Playbook: httpd-setup</span></p><p>The playbook includes 4 tasks:</p> <p>1. Update apt cache</p> <p>2. Install Apache</p> <p>3. Create custom index.html</p> <p>4. Start and enable Apache service</p> </div> <p>
You can run this playbook on any Ubuntu server to reproduce this setup.
</p> </div> </div> </section>   </div> </main> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Great Unwind (250 pts)]]></title>
            <link>https://occupywallst.com/yen</link>
            <guid>46889008</guid>
            <pubDate>Wed, 04 Feb 2026 17:49:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://occupywallst.com/yen">https://occupywallst.com/yen</a>, See on <a href="https://news.ycombinator.com/item?id=46889008">Hacker News</a></p>
<div id="readability-page-1" class="page">





<p>Have you wondered why the stock market has been so choppy since
October and why crypto and gold keep flash crashing? The western media
would have you believe this is due to AI bubble, war in Greenland, and
Trump's tweets. We have a better story to tell.

</p><p>
<strong>Wall Street has lost control of the
Japanese Yen carry trade unwind.</strong>

</p><p>There's been a fair bit of quiet chaos in financial markets recently.
Cryptocurrencies have lost 40% of their value. We saw silver drop 40%
which hasn't happened since 1980. Stocks like Microsoft are getting
picked off one-by-one with 15% drops when positive earnings reports come
out. Meanwhile the broader market chops sideways, so people think things
are fine. Trump and Europe were on the brink of war for control of a
desolate arctic territory. Truth Social has overtaken FOMC as the most
important source of financial news. These things may all appear to the
untrained eye as a series of idiosyncratic, disconnected shocks. The
prevailing media narrative is that the market is reacting negatively to
AI CapEx spending and a hawkish new Fed chair. But our systematic
analysis of cross-asset flows, derivatives positioning, central bank
policy minutes, and institutional balance sheets suggests a singular,
unified causality that binds these disparate anomalies, which is the
covert unwinding of the Japanese Yen carry trade.

</p><p>For nearly thirty years, the Bank of Japan’s (BOJ) Zero Interest Rate
Policy (ZIRP) and subsequent Negative Interest Rate Policy (NIRP)
effectively transformed the Yen into the world’s funding currency. We
would call it the greatest free money printer ever made. By anchoring
borrowing costs at or near zero, the BOJ enabled Wall Street to borrow
Yen cheaply and invest it with leverage into higher yielding instruments
globally, such as U.S. treasuries, equities, and cryptography. For
example, you borrow Yen from Japan at 0% interest, you exchange it for
USD, and then you buy treasury bonds that pay 4%. It's that simple. This
funded government benefits and provided continuous reliable liquidity
for financial markets that made stocks keep going up while suppressing
volatility.

</p><p>Trillions of dollars of free loans from the Bank of Japan were used
by a generation of investors to buy a double digit percentage of the
U.S. economy. Now those loans are being recalled. Wall Street traders
who levered up on the free Japanese money now have to sell trillions of
assets and convert the proceeds back to Yen in order to not be
liquidated. These aren't happy times for them. They get liquidated when
Japan raises interest rates; they get liquidated when the Federal
Reserve lowers interest rates; they get liquidated when the Japanese Yen
increases in value; they get liquidated when tech stocks aren't going up
enough, and all four of these things have been happening at once.

</p><p>Wall Street may be greedy, but they're very intelligent too. They
made many smart choices about where to put the "free" money. Now let's
say you're someone who's also smart, but was wise enough to not use
Sauron's ring. Chances are you invested in the same things as Wall
Street. So by now you've probably seen your whole portfolio move against
you; you're wondering why your hedges don't work; and you feel like
you're being punished for making all the right choices. It's because
other smart people, who got greedy, are being forced to close their
positions, and you're the whipping boy for their avarice.

</p><p>The Japanese Yen is sort of like GameStop ($GME). It's the most
shorted currency on Earth. When you borrow yen to buy American assets,
you're effectively shorting the yen. Currency can be rehypothecated so
that yen-denominated debt ends up exceeding the actual yen supply, the
same way GME's short interest exceeded 100% of its float. When shorts
start covering it compounds tragedy, because they all have to buy yen,
which makes its value increase, forcing more shorts to cover, and Japan
is a small island.

</p><p>This December 2025 rate hike to 0.75%, followed by the explicitly
hawkish signalling from Prime Minister Sanae Takaichi’s administration,
has fundamentally altered the risk-reward calculus of these leveraged
positions. The market disruptions observed in January 2026 bear the
distinct mathematical signature of a forced liquidation event rather
than a fundamental repricing of growth prospects. When correlations
between historically uncorrelated assets (e.g. Gold, Bitcoin, Microsoft,
and Silver) approach 1.0 during a sell-off, it serves as a distinct
indicator that traders are not selling what they <em>want</em> to sell,
but rather what they <em>must</em> sell in order to meet margin calls in
a funding currency that is rapidly appreciating against their
liabilities.

</p><p>We shall investigate the mechanics of this unwind in exhaustive
detail. We analyze the "Greenland Distraction" not as a root cause but
as a volatility trigger that shattered the complacent calm of the "Davos
Consensus." We examine the anomalous liquidation in precious metals
following the nomination of Kevin Warsh to the Federal Reserve
Chairmanship, and we dissect the flow of funds from major Japanese
institutional whales like Norinchukin Bank, whose retreat from foreign
bond markets has left a liquidity vacuum in the U.S. Treasury complex.
The evidence points to a systemic repricing of the global cost of
capital, originating in Tokyo and transmitting violently through the
plumbing of Wall Street, leaving no asset class untouched.

</p><h2 id="pivot">
  Japan's Monetary Normalization
</h2>

<p>To fully comprehend the market chaos of January 2026, one must look
beyond the immediate headlines of the new year and scrutinize the subtle
yet seismic shifts that occurred in Tokyo during the closing months of
2025. The conventional market narrative has long regarded the Bank of
Japan as a passive, almost paralyzed actor, perpetually trapped in a
deflationary mire and unable to normalize policy. This view has always
been demonstratably false. The truth is that Wall Street leaders have
been planning for the next quarter, while the Japanese have been
preparing for the next century. The data confirms a deliberate,
aggressive shift toward normalization that caught global carry traders
offguard.

</p><h3>1.1 The December 2025 Rate Hike: A Regime Change</h3>

<p>In a move that many Western analysts critically underestimated, the
Policy Board of the Bank of Japan voted unanimously to raise the
uncollateralized overnight call rate to <strong>0.75%</strong> during
its policy session on December 18-19, 2025. While a 25 basis point hike
might appear negligible in the context of Federal Reserve or ECB
tightening cycles, in the context of the Japanese financial system,
which has operated near the zero-bound for decades, it represents a
massive tightening of financial conditions.

</p><p>This move was not merely a technical adjustment; it was a fundamental
regime change. Coming from a baseline of -0.1% in early 2024 and 0.50%
in late 2025, the move to 0.75% signaled that the era of "free money"
had definitively ended. The rationale provided by the BOJ was grounded
in shifting inflationary dynamics. Core CPI (excluding fresh food), the
central bank's preferred metric, was tracking near 3% in late 2025,
persistently exceeding the 2% price stability target.Although inflation
eased slightly to 2.4% in December, the BOJ minutes reveal a board
convinced that "wage gains may be durable," thus justifying higher rates
to prevent a wage-price spiral.

</p><p>Crucially, the minutes from the December meeting, which were released
in late January 2026, contain explicit language suggesting that the
tightening cycle is far from complete. The board noted that "real
interest rates are expected to remain negative," implying that a policy
rate of 0.75% is <em>still</em> considered accommodative relative to
inflation.To a bond trader, this is hawkish code. It suggests that the
"neutral rate" is significantly higher, potentially between 1.5% and
2.0%. If the market prices in a terminal rate of 2.0%, the cost of
funding for carry trades effectively triples from previous levels,
turning profitable arbitrage positions into deep losses.

</p><h3>1.2 The Takaichi Factor: "Abrynomics" Redux?</h3>

<p>The political dimension in Japan has exacerbated the monetary
tightness, creating a "double tightening" effect that algorithms have
struggled to price. Prime Minister Sanae Takaichi, preparing for a snap
election on February 8, 2026, has adopted a complex economic stance that
blends fiscal expansion with monetary discipline, a volatile mix for
currency markets.

</p><p>Takaichi advocates for "strategic fiscal spending" and tax cuts to
stimulate the domestic economy. In standard macroeconomic theory, an
expansionary fiscal policy (increased government spending) combined with
a tightening monetary policy (higher rates to combat the resulting
inflation) is the perfect recipe for currency appreciation. While
Takaichi has publicly softened her rhetoric to avoid accusations of
currency manipulation, stating she "did not have a preference for the
yen's direction", her policies speak louder than her soundbites.

</p><p>The market fears that Takaichi’s proposed fiscal largesse will force
the BOJ to hike rates <em>faster</em> than currently projected to
counteract the inflationary effects of government spending. This creates
a two-front war on the Yen carry trade:

</p><ol start="1">
  <li>
    <p><strong>Cost of Funding Rises:</strong> Higher BOJ rates make borrowing Yen expensive.
  </p></li>
  <li>
    <p><strong>Exchange Rate Risk:</strong> If the Yen appreciates due to the fiscal-monetary policy mix, the principal value of the USD-denominated assets held by Japanese investors falls in Yen terms, triggering margin calls.
  </p></li>
</ol>

<p>The tension between the Prime Minister's office and the Ministry of
Finance (MOF) adds another layer of uncertainty. Finance Minister
Satsuki Katayama has been far less tolerant of currency volatility,
repeatedly intervening or threatening intervention when USD/JPY
approaches the 155-160 danger zone.This political friction creates a
"floor" for the Yen, making shorting the currency a perilous endeavor
for global macro funds.

</p><h3>1.3 Institutional Flows: The "Whale" Retreats</h3>

<p>Perhaps the most critical, yet underreported, development is the
behavior of Japan's gargantuan institutional investors,
specifically <strong>Norinchukin Bank</strong> (often referred to as the
"CLO Whale") and <strong>Nippon Life Insurance</strong>. These entities
have historically been the largest buyers of U.S. debt, recycling
Japan's trade surplus into U.S. Treasuries and corporate bonds.

</p><p>The data indicates a massive reversal in these flows. Following
significant losses in 2024 and 2025 due to unhedged exposure to U.S. and
European sovereign bonds, Norinchukin has been actively liquidating
foreign assets. By the end of December 2025, the bank had unloaded
nearly <strong>¥12.8 trillion</strong> (approximately $88 billion) in
foreign government bonds.The bank’s CEO, Taro Kitabayashi, confirmed the
completion of this sell-off, stating the bank would "take its time"
before committing capital to fresh investments.

</p><p>The significance of this cannot be overstated. A major,
price-insensitive buyer of U.S. debt has left the building. When the
U.S. Treasury issues debt to fund its deficit, Norinchukin is no longer
the guaranteed bid. This removal of liquidity support weakens the floor
for U.S. Treasuries, contributing to the yield spikes seen in January.
Similarly, Nippon Life has signaled a rotation back into domestic
Japanese Government Bonds (JGBs), acknowledging that "unrealized losses"
on foreign bonds had swelled to ¥4.7 trillion.The logic is simple: why
take currency risk for a 4.5% U.S. yield when domestic JGB yields are
rising and offer a risk-free return in your home currency?

</p><p>By December 31, 2025, the stage was set. The "free money" era was
over. The largest holders of capital in Tokyo were repatriating funds or
moving into cash. Global markets, however, were still positioned for
"business as usual", long Nvidia, long Bitcoin, short Yen. The dissonance
between Japanese reality and Western positioning created the perfect
conditions for a crash.

</p><h2 id="timeline">
  Timeline of the Crisis
</h2>

<p>To validate the thesis that the Yen unwind is the primary driver of
volatility, we must examine the sequence of events. The crash did not
happen in a vacuum; it followed a precise timeline where geopolitical
shocks acted as triggers for a structural fragility that had been
building since the BOJ's December pivot.

</p><h3>2.1 The Lead-Up: October to December 2025</h3>

<p>The pressure began to build in Q4 2025. As the BOJ signaled its
intention to hike rates, Japanese traders, often the "canary in the coal
mine" for global liquidity, began to reduce risk. This cycle started with
Bitcoin. Bitcoin is a pure
liquidity asset; it has no yield and is often funded via margin. As the
cost of Yen margin rose, Japanese selling pressure on Bitcoin
intensified from October through December.This was the first tremor.

</p><h3>2.2 The Catalyst: The "Greenland Crisis" (January 17-21, 2026)</h3>

<p>Was the "Greenland War" theater? While the military dimensions may have
been performative, the economic consequences were
tangible and acted as the catalyst that exposed the fragility of the Yen
carry trade.

</p><p>On January 17, 2026, President Trump escalated his demand to purchase
Greenland by threatening a <strong>10% tariff</strong> on eight European
nations (including the UK, Germany, and France) and escalating to 25% by
June if the territory was not ceded.This introduced a "tail risk" that
markets had not priced: the fracture of the Atlantic economic
alliance.

</p><p>Following the Martin Luther King Jr. holiday, U.S. markets opened on
January 20 to a bloodbath. The S&amp;P 500 fell 2.1%, the Nasdaq
composite dropped 2.4%, and yields on U.S. Treasuries spiked.The
narrative was "Greenland," but the market mechanics told a different
story. The threat of tariffs on close allies disrupts the "Atlantic
Trade" narrative. For Japanese investors holding U.S. assets, this
introduced a new risk premium. It wasn't just about rates anymore; it
was about the stability of the U.S.-led global order. This geopolitical
volatility forced risk parity funds and algorithmic traders to reduce
gross exposure. When a global portfolio deleverages, it buys back its
funding currency. In this case, it bought Yen.

</p><p>While Trump walked back the <em>military</em> threat on January 21 at
Davos, the <em>economic</em> threat of tariffs remained a live wire. The
volatility persisted, suggesting that the "Greenland" narrative was
merely the match that lit the fuse of a much larger powder keg.

</p><h3>2.3 The "Warsh Shock" and the Liquidity Event (January 30-31, 2026)</h3>

<p>The final and most violent phase of the crash occurred at the end of
the month, triggered by the nomination of Kevin Warsh as Federal Reserve
Chair.Warsh is widely perceived as a hawk, favoring sound money and
skepticism toward quantitative easing. His nomination signaled the
potential end of the "Fed Put", the assumption that the central bank
would always intervene to support asset prices.

</p><p>This announcement triggered a massive repricing of the "Debasement
Trade." Assets that thrive on currency debasement, Gold, Silver, and
Bitcoin, collapsed. Gold fell ~11%, and Silver crashed ~36% in a single
session.This synchronization of losses across uncorrelated assets (Tech
and Gold falling together) is the definitive signature of a liquidity
crisis driven by margin calls.

</p><h2 id="liquidation">
  Anatomy of the Liquidation
</h2>

<p>The unwinding of a carry trade is not a monolithic event; it is a
cascade that ripples outward from the most liquid and speculative assets
to the core holdings of institutional portfolios. The sequence of asset
price collapses observed from October 2025 to January 2026 follows this
classic liquidation hierarchy perfectly.

</p><h3>3.1 The Canary in the Coal Mine: Bitcoin</h3>

<p>As noted, the unwind began in the crypto markets. Japan is home to a
massive retail crypto trading base, and the Yen is a major pair for
Bitcoin trading. Snippets indicate that Japanese traders began selling
off Bitcoin in October 2025.

</p><p>This timing is crucial. It correlates with the period when the BOJ
began signaling the December rate hike. Retail traders, facing higher
mortgage rates and loan costs in Japan, likely liquidated their most
volatile, liquid asset first to raise cash. The selling was exacerbated
by the looming tax reform in Japan. While the proposal to move to a flat
20% tax rate is bullish in the long term, the immediate pressure of
rising funding costs forced traders to sell <em>before</em> the tax cut
could be realized.By January 31, massive outflows from Bitcoin ETFs
($528 million) coincided with the broader market crash, confirming that
crypto was being used as a source of liquidity to cover losses
elsewhere.

</p><h3>3.2 The "Tech Wreck": The Microsoft Anomaly</h3>

<p>Consider the "painful ~3% dump" in the Nasdaq and Microsoft's
staggering 15% drop. On January 29, 2026,
Microsoft reported earnings. Despite beating revenue estimates ($81.27
billion vs. $80.28 billion), the stock plummeted ~11-15% intraday.

</p><p>The street blamed concerns over "AI CapEx", the idea that Microsoft
was spending billions on data centers with slow return on investment.
However, a 15% drop in a $3 trillion company on a "good" earnings beat
is rarely fundamental; it is mechanical. Microsoft is a quintessential
"momentum" stock, heavily held by foreign institutional investors,
including Japanese pension funds. When the Yen strengthens, the value of
these USD-denominated assets falls in JPY terms.

</p><p>If a Japanese insurer holds Microsoft unhedged, a falling USD/JPY
exchange rate hurts their balance sheet. If they hold it <em>hedged</em>
(rolling short USD positions), the rising U.S. rates (driven by the
Warsh nomination) make the hedge prohibitively expensive. The January 29
drop was likely exacerbated by a "stop-loss" cascade from Tokyo desks.
As the price broke key technical levels, algorithms programmed to
protect Yen-denominated returns indiscriminately sold the most liquid
blocks. Microsoft, being one of the most liquid stocks in the world,
became the ATM for the rest of the portfolio.

</p><h3>3.3 The Precious Metals Flash Crash</h3>

<p>The most compelling evidence of a forced liquidation event is the
behavior of Gold and Silver on January 31, 2026. Gold fell ~11-12% and
Silver crashed ~31-36% in a single session. Historically, Gold acts as a
safe haven during equity market turmoil. If the Nasdaq is crashing due
to "Greenland" fears, Gold should rally. Instead, it crashed.

</p><p>This anomaly can be explained by two factors:

</p><ol start="1">
  <li>
    <p><strong>The Warsh Effect:</strong> As discussed, Warsh's nomination strengthened the USD and undermined the thesis for holding anti-fiat assets.
  </p></li>
  <li>
    <p><strong>Margin Call Dynamics:</strong> Snippets reveal that CME Group and the Shanghai Gold Exchange raised margin requirements on gold and silver futures <em>days before</em> the crash.When Japanese traders faced losses on their Microsoft longs and their Yen shorts, they needed cash immediately. They couldn't sell illiquid bonds quickly enough, so they sold their "winners." Gold had rallied to ~$5,400/oz prior to the crash. Traders liquidated their profitable Gold positions to pay for the margin calls on their losing Tech and Yen positions.
  </p></li>
</ol>

<h4>Correlation Convergence: The Signature of a Liquidity Event</h4>

<p><strong>Cross-Asset Correlations (Week Ending Jan 31, 2026)</strong>

</p><figure>
  <img src="https://occupywallst.com/correlations.png" alt="Cross-asset correlations chart showing spike in correlation between Gold, Bitcoin, and Nasdaq 100 on Jan 31, 2026">
  <figcaption>
    <strong>Figure 2:</strong> Cross-asset correlations, Jan 15–Jan 31,
    2026. Note the spike in correlation between Gold, Bitcoin, and
    Nasdaq 100 on Jan 31, indicating a systemic "sell-everything" margin
    call.<br>
    <em>Data sources:
      <a href="https://alexlexington.com/blogs/news/gold-and-silver-crash-january-2026-what-caused-fridays-historic-drop">Alex Lexington</a>,
      <a href="https://www.financemagnates.com/trending/why-gold-is-falling-with-silver-and-why-ron-paul-predicts-a-20k-price/">Finance Magnates</a>,
      <a href="https://global.morningstar.com/en-nd/markets/why-are-gold-silver-plunging">Morningstar</a>,
      <a href="https://www.investing.com/analysis/bitcoins-identity-crisis-in-2026-4-paths-forward-and-the-road-to-150000-200674299">Investing.com</a>,
      <a href="https://seekingalpha.com/article/4865184-gold-silver-and-equities-evidence-positive-volspot-correlation">Seeking Alpha</a></em>
  </figcaption>
</figure>

<p>This correlation breakdown is visualized in Figure 2, where the
correlation between Gold and the Nasdaq 100 spikes to nearly 1.0 during
the crash week, a statistical anomaly that only occurs during severe
liquidity events.

</p><h4>The Liquidation Vice: Margin Hikes vs. Silver Price</h4>

<figure>
  <img src="https://occupywallst.com/liquidations.png" alt="Chart showing impact of CME margin requirement increases on Silver spot prices">
  <figcaption>
    <strong>Figure 3:</strong> Impact of CME margin requirement
    increases on Silver spot prices (Jan 20–Feb 2, 2026). The "Step Up"
    in margin cost precedes the vertical drop in price, characteristic
    of a forced unwind.<br>
    <em>Data sources:
      <a href="https://alexlexington.com/blogs/news/gold-and-silver-crash-january-2026-what-caused-fridays-historic-drop">Alex Lexington</a>,
      <a href="https://www.financemagnates.com/trending/why-gold-is-falling-with-silver-and-why-ron-paul-predicts-a-20k-price/">Finance Magnates</a>,
      <a href="https://evrimagaci.org/gpt/bitcoin-and-gold-plunge-as-margin-calls-roil-markets-526479">Evrim Agaci</a></em>
  </figcaption>
</figure>

<h2 id="plumbing">
  The Plumbing of the Crisis
</h2>

<p>The "Yen Whale" hypothesis is strongly supported by the data on
futures volumes and repo market stress. The "central mystery" is not
just in the price action, but in the unseen flows of the derivatives
market.

</p><h3>4.1 The /6J (Yen Futures) Whale</h3>

<p>About a week ago, some whale kicked off an astronomically large
market order for a /6J long when it hit all-time lows. /6J (CME Yen
Futures) hit a low of ~0.00647 (approximately 154.50 USD/JPY) in late
January. This level has historically been a "line in the sand" for the
Japanese Ministry of Finance (MOF).

</p><figure>
  <a href="https://occupywallst.com/yen.png"><img src="https://occupywallst.com/yen.png" alt="Thinkorswim chart showing massive whale order on /6J yen futures"></a>
  <figcaption><strong>Figure 4:</strong> The whale event that kicked off
  the Japanese Yen unwind. Note the massive spike as /6J hit all-time
  lows, rallying investors worldwide to go long on yen
  futures.</figcaption>
</figure>

<p>CME reported record volumes in FX and Interest Rate products for
January 2026.The aggressive buying off the lows suggests a
massive <em>repatriation</em> flow. Who is the Whale? Two theories
emerge:

</p><ol start="1">
  <li>
    <p><strong>The MOF Thesis:</strong> The Ministry of Finance has a history of stealth intervention. Buying /6J (Long Yen) is functionally equivalent to selling USD reserves. Buying futures allows them to support the currency without immediately depleting cash reserves, squeezing speculators who are short.
  </p></li>
  <li>
    <p><strong>The Carry Unwind:</strong> A massive hedge fund or bank (like Norinchukin) realizing that the "game is up" and closing out short-Yen positions. The size of the order suggests an entity that needed to move billions, not millions.
  </p></li>
</ol>

<p>The subsequent price action, a sharp rally followed by "hammering back
down", represents the battleground. U.S. macro funds are still trying to
short the Yen (betting on U.S. economic exceptionalism and Warsh's
policies), while Japanese domestic accounts are buying it. The
volatility is the result of these tectonic plates grinding against each
other.

</p><h3>4.2 The Repo Market &amp; ON RRP</h3>

<p>The plumbing of the U.S. financial system showed signs of stress that
coincided with the Japanese retreat. The Overnight Reverse Repo facility
(ON RRP) saw a year-end spike to $106 billion but has since drained.

</p><p>Japanese banks are typically huge participants in the U.S. repo
market to fund their dollar assets. As Norinchukin and others retreat
(repatriating funds to Japan), liquidity in the U.S. repo market becomes
thinner. The "air pocket" in Microsoft and Gold prices was likely
exacerbated by a lack of market maker depth in the repo-funded
derivatives market. When market makers cannot access cheap repo funding,
they widen spreads and reduce liquidity provision, leading to "gaps" in
price action during sell-offs.

</p><h3>4.3 Peripheral Currency Volatility</h3>

<p>There have been significant moves in other currency futures as well: /6A
increased 87 basis points, /6L rose 19 basis points, and /6S rose 18
basis points.

</p><ul>
 <li>
   <p><strong>/6A (Australian Dollar):</strong> The 87 basis point rise
     in the Aussie Dollar is notable. AUD is often a proxy for Chinese
     growth and global risk sentiment. A rise here, amidst a tech crash,
     suggests a rotation <em>out</em> of U.S. assets and into
     commodities or Asia-Pacific currencies, further supporting the
     "Sell America" thesis triggered by the Greenland tariff
     threats.
 </p></li>
 <li>
   <p><strong>/6L (Brazilian Real) and /6S (Swiss Franc):</strong> The
   rise in the Swiss Franc (a classic safe haven) aligns with the
   risk-off sentiment. The move in the Brazilian Real suggests that
   emerging markets are also seeing volatile flows as the dollar
   stabilizes.
 </p></li>
</ul>

<h3>4.4 The VIX Anomaly</h3>

<p>Why was the VIX at 16 despite the chaos? The VIX measures implied
volatility of S&amp;P 500 options. Its relatively low level (16)
compared to the violence in individual names (MSFT -15%, Gold -11%)
indicates that the crash is a <strong>de-leveraging event</strong>, not
a panic event.

</p><p>In a panic, investors buy Puts on the index to protect themselves,
spiking the VIX. In a de-leveraging event, investors simply sell the
underlying assets (stocks, gold, crypto) to raise cash. They are not
hedging; they are exiting. This explains why the VIX remained subdued
while prices collapsed, the selling was orderly, algorithmic, and
relentless, rather than emotional and panicked.

</p><h2 id="greenland">
  The Greenland Distraction
</h2>

<p>Skepticism about the "Greenland War" is well-founded. While the
diplomatic row was real, its utility as a <em>financial</em>
narrative was far greater than its geopolitical reality.

</p><h3>5.1 The "Davos Pivot"</h3>

<p>President Trump's threat of military force was retracted on January
21 at Davos.This "de-escalation" should theoretically have calmed
markets. Instead, the volatility <em>worsened</em> into month-end. This
confirms that the <em>real</em> problem wasn't Greenland; it was the
re-pricing of the Yen.

</p><h3>5.2 The Narrative Utility</h3>

<p>The financial media loves a simple cause-and-effect narrative.
"Stocks down because of War" is easy to digest. "Stocks down because the
cross-currency basis swap spread widened due to BOJ minutes" is not. The
"Greenland" narrative provided the perfect cover for sophisticated
actors to liquidate positions in Gold and Tech under the guise of "war
jitters." This allowed them to exit without sparking a broader panic
about <em>liquidity</em> in the banking system. The focus on the Arctic
masked the structural rot in the leverage complex.

</p><h2 id="conclusion">
  Conclusion
</h2>

<p>The evidence suggests a covert, structural unwinding of the Yen carry
trade is the primary driver of the January 2026 market chaos.

</p><p>The interconnectedness of these events is undeniable. The BOJ's rate
hike in December 2025 and the subsequent hawkish signaling from the
Takaichi administration fundamentally altered the cost of capital for
the world's largest carry trade. The "Greenland Crisis" acted as the
initial volatility trigger, forcing a reduction in gross exposure. The
nomination of Kevin Warsh acted as the final catalyst, shattering the
"Debasement Trade" and forcing a liquidation of precious metals and
crypto to cover margin calls on Yen-funded positions.

</p><p>Here are some key takeaways:

</p><ol start="1">
  <li>
    <p><strong>The "Free Money" Era is Over:</strong> BOJ policies have
    fundamentally altered the global cost of capital. The flow of
    liquidity from Tokyo to New York has reversed.
  </p></li>
  <li>
    <p><strong>Geopolitics as Catalyst:</strong> "Greenland" may have
    been the spark, but the Yen leverage was the powder keg. The tariff
    threats disrupted the "Atlantic Trade" narrative, forcing a
    repatriation of capital.
  </p></li>
  <li>
    <p><strong>Liquidity Event:</strong> The synchronized crash of Gold,
    Crypto, and Tech confirms a systemic de-leveraging. The "Whale"
    orders in Yen futures and the breakdown of correlations are the
    smoking guns of a margin-driven event.
  </p></li>
</ol>

<p>With the Japanese election on February 8 and U.S. tariffs looming,
the "hammering" of the Yen is likely temporary. The structural trend is
now toward repatriation. This implies <strong>lower U.S. asset prices,
higher U.S. yields, and a stronger Yen</strong> over the medium term.
The "mystery" of the low VIX is explained by the mechanical nature of
the unwind, a controlled demolition of leverage rather than a chaotic
panic.

</p><h2 id="action">
  Call To Action
</h2>

<p>
This won't just be the big one. This could be the last one. If you've
been preparing your whole life, knowing that something's coming, then
this could be the thing you've been preparing for. One final opportunity
to get the guys who did this.

</p><p>
Longing the Yen is commonly referred to as "The Widowmaker Trade" on
Wall Street, because you have trillions of dollars of monopoly money
working against you. The carry traders have compromised every level of
our government. Their greatest vulnerability is the Yen rising in value.
They will do anything to defend their positions, even if that means
bringing America's economy down with them. Since recent events have made
it obvious they're going to lose, we might as well fight them. Most of
us probably won't make it out of this fight. But if we at least try,
then there's a chance we might prosper when it's over.

</p><p>
The IV on
OTM <a href="https://www.cmegroup.com/markets/fx/g10/japanese-yen.html">CME
/6J futures</a> calls is 11% which is astonishingly low. The same is
true for calls on the
<a href="https://www.invesco.com/us/en/financial-products/etfs/invesco-currencyshares-japanese-yen-trust.html">FXY</a>
ETF. Call options have defined risk. The more Yen we control, the more
its value goes up, and the more crooks on Wall Street get liquidated.
The worst that can happen is you lose your monopoly money, but that's
been happening anyway. Since carry traders own 10% of all U.S.
treasuries, when they get liquidated they'll have to sell a lot of
treasury bonds, which means that
<a href="https://www.cmegroup.com/markets/interest-rates/us-treasury/ultra-t-bond.html">CME
/UB futures</a> and
the <a href="https://www.ishares.com/us/products/239454/ishares-20-year-treasury-bond-etf">TLT</a>
ETF will fall.

</p><hr>

<p>This blog is brought to you by various radicals,
malcontents, and people who think the system is rigged. We're not
affiliated with any organization. Nothing here constitutes financial
advice. Occupy Wall Street is not your financial advisor or your lawyer.
We're retail investors like you. Do your own research. Past performance
does not guarantee future results. We are the 99 percent. The only
solution is world revolution. Wall Street's time has finally come.
</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Steve Bannon Proposes Using ICE in Elections (121 pts)]]></title>
            <link>https://www.newsweek.com/steve-bannon-proposes-using-ice-in-elections-11462376</link>
            <guid>46888824</guid>
            <pubDate>Wed, 04 Feb 2026 17:36:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.newsweek.com/steve-bannon-proposes-using-ice-in-elections-11462376">https://www.newsweek.com/steve-bannon-proposes-using-ice-in-elections-11462376</a>, See on <a href="https://news.ycombinator.com/item?id=46888824">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><p>Steve Bannon, a former White House adviser to President Donald Trump, has said agents from U.S. Immigration and Customs Enforcement (ICE) will be at the polls during November's midterm elections.</p><p>"You're damn right we're gonna have ICE surround the polls come November," Bannon said on his <em>War Room</em> podcast on Tuesday.</p><ul><li><span><strong><a href="https://www.newsweek.com/russia-just-put-another-taco-on-trumps-plate-11463407">Essential Reading: Russia Just Put Another TACO on Trump’s Plate</a></strong></span></li><li><span><strong><a href="https://www.newsweek.com/shutdown-averted-ice-deal-winners-conventional-wisdom-11462827">Conventional Wisdom: The Shutdown Averted Edition</a></strong></span></li></ul><p>"We're not gonna sit here and allow you to steal the country again. And you can whine and cry and throw your toys out of the pram all you want, but we will never again allow an election to be stolen."</p><p>Federal and state laws prohibit the government from deploying federal agents to any polling place, according to the Brennan Center for Justice. Federal law also prohibits any activity that intimidates voters.</p><p>Bannon's comments come after Trump said in a podcast interview on Monday that <a href="https://www.newsweek.com/donald-trump-nationalize-voting-dan-bongino-show-elections-11455526">Republicans should "take over" elections</a> in as many 15 states, as he continued to baselessly claim that widespread fraud cost him re-election in 2020. His calls come amid <a href="https://www.newsweek.com/major-changes-american-voting-system-congress-11458749">a push among Republicans in Congress</a> to impose stricter voting requirements nationwide.</p><p><em>Newsweek</em> contacted the White House and the Department of Homeland Security (DHS) for comment by email outside of regular business hours.</p><div><p><img id="11462395" alt="" caption="Conservative political strategist Steve Bannon, former advisor to US President Donald Trump, addresses Turning Point's annual AmericaFest conference, in remembrance of late right-wing political activist Charlie Kirk, in Phoenix, Arizona on December 19, 2025.  (Photo by Olivier Touron/AFP via Getty Images)" captionoverride="Steve Bannon speaking at Turning Point's annual AmericaFest conference in Phoenix, Arizona, in December." credit="Olivier Touron/AFP/Getty Images" sourcealt="" sources="[]" fetchpriority="auto" loading="lazy" width="5079" height="3386" decoding="async" data-nimg="1" sizes="(min-width: 1200px) 1536px, (min-width: 768px) 768px, 100vw" srcset="https://assets.newsweek.com/wp-content/uploads/2026/02/GettyImages-2252092393.jpg?w=640&amp;quality=80&amp;webp=1 640w, https://assets.newsweek.com/wp-content/uploads/2026/02/GettyImages-2252092393.jpg?w=750&amp;quality=80&amp;webp=1 750w, https://assets.newsweek.com/wp-content/uploads/2026/02/GettyImages-2252092393.jpg?w=1000&amp;quality=80&amp;webp=1 1000w, https://assets.newsweek.com/wp-content/uploads/2026/02/GettyImages-2252092393.jpg?w=1200&amp;quality=80&amp;webp=1 1200w, https://assets.newsweek.com/wp-content/uploads/2026/02/GettyImages-2252092393.jpg?w=1360&amp;quality=80&amp;webp=1 1360w, https://assets.newsweek.com/wp-content/uploads/2026/02/GettyImages-2252092393.jpg?w=1600&amp;quality=80&amp;webp=1 1600w" src="https://assets.newsweek.com/wp-content/uploads/2026/02/GettyImages-2252092393.jpg?w=1600&amp;quality=80&amp;webp=1"></p></div><h2>Why It Matters</h2><p>Trump has recently intensified his efforts to undermine the results of the 2020 election, which he lost to President Joe Biden. He has repeated disproven theories that ballots were altered or stolen and that illegal migrants were allowed to cast votes in some states that he lost. Those efforts come as the Trump administration is turning its attention to electoral issues before the midterm elections in November, when control of Congress will be at stake.</p><p>Meanwhile, the fatal shootings of two U.S. citizens, <a href="https://www.newsweek.com/renee-good-autopsy-results-released-by-lawyers-11398361">Renee Good</a> and <a href="https://www.newsweek.com/alex-pretti-death-deemed-homicide-by-medical-examiner-11454424">Alex Pretti</a>, by immigration enforcement agents in separate incidents in Minneapolis last month have amplified scrutiny of ICE. On Tuesday, Trump signed a government funding bill&nbsp;that only funds DHS for two weeks at the behest of Democrats, who are demanding more restrictions on immigration enforcement&nbsp;following the fatal shootings.</p><h2><strong>What To Know&nbsp;</strong></h2><p>On the <em>War Room </em>podcast, Bannon said that Democrats rely on voter fraud to win elections, suggesting without evidence that illegal migrants are voting in large numbers in Minnesota and New York City.</p><p>Caroline Wren, a GOP fundraiser, agreed with Bannon, saying that Democrats are seeking to "defund ICE" to keep agents away from polling sites.</p><p>Wren pointed to comments from Democratic Senator Mark Warner, who&nbsp;recently expressed concerns about the possibility of Trump sending ICE agents to polling places.</p><p>"They don't want ICE funded because they don't want ICE at the polling stations to stop illegals from voting," she said.&nbsp;</p><p>Bannon said the proposals in two bills to implement stricter voter requirements were "basic."</p><p>"The ask here on the SAVE Act and&nbsp;Make Elections Great Again Act are pretty basic. A legitimate ID to show who you are to vote. It is to clean up the voter rolls," he said. </p><h2><strong>What People Are Saying&nbsp;</strong></h2><p><strong>Bannon said on the podcast</strong>: "Let's put you on notice again. ICE is going to be around the polls in the 2026 midterm elections."</p><p><strong>Senate Minority Leader Chuck Schumer</strong> <strong>wrote on X on Monday</strong>: "The SAVE Act is nothing more than Jim Crow 2.0. It would disenfranchise millions of Americans. Every single Senate Democrat will vote against any bill that contains it."</p><p><strong>Democratic Senator Mark Warner</strong> <strong>told reporters on Tuesday</strong>: "The idea that the president might send some part of the federal government like ICE into patrol and suddenly people are saying, 'well, we want to make sure that nobody undocumented shows up at any polling station.' Again, pre-Minneapolis occupation, that didn't ring as true as it potentially rings true right now"</p><h2><strong>What Happens Next&nbsp;</strong></h2><p>The midterm elections will take place on November 3.</p><blockquote><article><div><p><img id="11261860" alt="" caption="" credit="" sourcealt="" sources="[]" fetchpriority="auto" loading="lazy" width="1312" height="121" decoding="async" data-nimg="1" sizes="(min-width: 1200px) 1312px, (min-width: 768px) 1024px, 100vw" srcset="https://assets.newsweek.com/wp-content/uploads/2025/12/Top.png?w=640&amp;quality=80&amp;webp=1 640w, https://assets.newsweek.com/wp-content/uploads/2025/12/Top.png?w=750&amp;quality=80&amp;webp=1 750w, https://assets.newsweek.com/wp-content/uploads/2025/12/Top.png?w=1000&amp;quality=80&amp;webp=1 1000w, https://assets.newsweek.com/wp-content/uploads/2025/12/Top.png?w=1200&amp;quality=80&amp;webp=1 1200w, https://assets.newsweek.com/wp-content/uploads/2025/12/Top.png?w=1360&amp;quality=80&amp;webp=1 1360w, https://assets.newsweek.com/wp-content/uploads/2025/12/Top.png?w=1600&amp;quality=80&amp;webp=1 1600w" src="https://assets.newsweek.com/wp-content/uploads/2025/12/Top.png?w=1600&amp;quality=80&amp;webp=1"></p></div><p>In a polarized era, the center is dismissed as bland. At <em>Newsweek</em>, ours is different: The Courageous Center—it's not "both sides," it's sharp, challenging and alive with ideas. We follow facts, not factions. If that sounds like the kind of journalism you want to see thrive, we need you.</p><p>When you <a href="https://www.newsweek.com/subscribe?utm_campaign=inlineCTAv2" target="_blank" rel="noreferrer noopener">become a Newsweek Member</a>, you support a mission to keep the center strong and vibrant.&nbsp;Members enjoy:&nbsp;Ad-free browsing, exclusive content and editor conversations.&nbsp;<a href="https://www.newsweek.com/subscribe" target="_blank" rel="noreferrer noopener">Help keep the center courageous. Join today.</a></p><div><p><a href="https://www.newsweek.com/jennifer-cunningham"><img lightbox="{&quot;enabled&quot;:false}" id="11261873" alt="" caption="" credit="" sourcealt="" sources="[]" fetchpriority="auto" loading="lazy" width="1312" height="136" decoding="async" data-nimg="1" sizes="(min-width: 1200px) 1312px, (min-width: 768px) 1024px, 100vw" srcset="https://assets.newsweek.com/wp-content/uploads/2025/12/Bottom.png?w=640&amp;quality=80&amp;webp=1 640w, https://assets.newsweek.com/wp-content/uploads/2025/12/Bottom.png?w=750&amp;quality=80&amp;webp=1 750w, https://assets.newsweek.com/wp-content/uploads/2025/12/Bottom.png?w=1000&amp;quality=80&amp;webp=1 1000w, https://assets.newsweek.com/wp-content/uploads/2025/12/Bottom.png?w=1200&amp;quality=80&amp;webp=1 1200w, https://assets.newsweek.com/wp-content/uploads/2025/12/Bottom.png?w=1360&amp;quality=80&amp;webp=1 1360w, https://assets.newsweek.com/wp-content/uploads/2025/12/Bottom.png?w=1600&amp;quality=80&amp;webp=1 1600w" src="https://assets.newsweek.com/wp-content/uploads/2025/12/Bottom.png?w=1600&amp;quality=80&amp;webp=1"></a></p></div></article></blockquote></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Building a 24-bit arcade CRT display adapter from scratch (154 pts)]]></title>
            <link>https://www.scd31.com/posts/building-an-arcade-display-adapter</link>
            <guid>46888795</guid>
            <pubDate>Wed, 04 Feb 2026 17:35:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.scd31.com/posts/building-an-arcade-display-adapter">https://www.scd31.com/posts/building-an-arcade-display-adapter</a>, See on <a href="https://news.ycombinator.com/item?id=46888795">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><section><p>In November, my friend and fellow Recurser, <a href="https://www.frankchiarulli.com/">Frank</a>, picked up an arcade machine for the <a href="https://www.recurse.com/">Recurse Center</a>. We call it the RCade. He wanted to leave the original CRT in - which I think is a great choice! - and drove it off of a Raspberry Pi. Eventually we wanted to move to a more powerful computer, but we needed a way to connect it to the display. Off-hand, I mentioned that I could build a CRT display adapter that interfaces with a normal computer over USB. This is that project.</p></section><h2>What the display expects</h2><section><p>The CRT in the RCade has a JAMMA connector, and Frank bought a converter that goes between VGA and JAMMA.</p><p>You might think we could just use an off-the-shelf VGA adapter to drive it at this point, but it's not that simple. The CRT runs at a weird resolution; We started with 320x240 but eventually wanted to target 336x262, which is super non-standard. Even 320x240 is unattainable by most display adapters, which typically can't go below 640x480. A custom solution would allow us to output any arbitrary resolution we wanted.</p><p>The other thing is that the Pi, with the <a href="https://github.com/fenlogic/vga666">VGA board</a> we were using, only supports 18-bit colour, and we wanted to improve this. Even on the RCade's CRT, colour banding was an obvious issue.</p><p>We also wanted to use a laptop, not a desktop, which meant not using a PCI-e card. Instead, a USB interface would be preferable.</p></section><h2>Wait, but what is VGA?</h2><section><p>VGA is a signaling protocol that maps almost exactly 1:1 with what a CRT actually does.</p><p><a href="https://www.scd31.com/img/rcade/crt-diagram.jpg"><img src="https://www.scd31.com/thumb/rcade/crt-diagram.jpg"></a></p><small>Taken from wikimedia.org</small><p>Inside of a CRT, there are 3 electron guns, which correspond to red, green, and blue colour values. Two electromagnets in the neck of the tube are responsible for steering the beam - one steers horizontally and one steers vertically. To draw an image, the beam moves across the screen one horizontal line at a time, and the electron guns are rapidly modulated in order to display the correct colour at each pixel.</p><p>VGA contains analog signals for these R, G, and B electron guns. It also contains an HSYNC and VSYNC signal, which are used so that the driver and the CRT can agree on what pixel is being drawn at a given time. Between the VGA input and the CRT is a very simple circuit which locks onto these HSYNC and VSYNC pulses and synchronizes the sweeping of the beam.</p><p><a href="https://www.scd31.com/img/rcade/vga-timing.png"><img src="https://www.scd31.com/thumb/rcade/vga-timing.png"></a></p><small>Taken from pyroelectro.com</small><p>The HSYNC pulses happen in between horizontal lines, and the VSYNC pulses happen in between frames. There are dead zones around each pulse - referred to as the front and back porch - which give the electron beam time to sweep back across the screen.</p><p>So, all we really need are those R, G, B, HSYNC, and VSYNC signals, running at precise timing, and synced properly relative to each other. Conceptually this is actually pretty simple!</p></section><h2>Attempt 1: Using the RP2040's PIO</h2><section><p>I like the Raspberry Pi RP2040 a lot. It's relatively cheap (around $1 USD) and has tons of on-board RAM - 264 KB in fact! It also has what is called Programmable IO, or PIO.</p><p>I've never used the PIO before, but the basic idea is that you can write assembly programs where every instruction takes exactly one cycle, and has useful primitives for interacting with GPIO. It's a fairly limited instruction set, but it allows for bit-banging precise cycle-accurate custom protocols. It's exactly what I need to modulate a VGA signal.</p><p>The PIO code ended up looking like this:</p><pre><span>  </span><span>// 1. low for 320+16=336 pixels
</span><span>  </span><span>// 2. high for 30 pixels
</span><span>  </span><span>// 3. low for 34 pixels
</span><span>  </span><span>// 4. repeat
</span><span>  </span><span>// runs on sm0
</span><span>  </span><span>// 6 instrs -&gt; can save some with sidesetting
</span><span>  </span><span>let</span><span> hsync = pio::pio_asm!(
</span><span>      "</span><span>.wrap_target</span><span>",
</span><span>      </span><span>/* begin pixels + front porch */
</span><span>      "</span><span>irq set 0 [2]</span><span>",    </span><span>// tell vsync we're doing 1 line
</span><span>      "</span><span>set pins, 1 [31]</span><span>", </span><span>// go low for 32
</span><span>      "</span><span>set X, 8 [15]</span><span>",    </span><span>// +16 = 48
</span><span>      "</span><span>a:</span><span>",
</span><span>      "</span><span>jmp X-- a [31]</span><span>", </span><span>// each loop 32, * 9 = 288, total = 336
</span><span>      </span><span>/* end front porch, being assert hsync */
</span><span>      "</span><span>set pins, 0 [29]</span><span>", </span><span>// assert hsync for 30
</span><span>      </span><span>/* end assert hsync, begin back porch */
</span><span>      "</span><span>set pins, 1 [29]</span><span>", </span><span>// deassert, wait 32 (note there is extra delay after the wrap)
</span><span>      "</span><span>.wrap</span><span>"
</span><span>    );
</span><span>
</span><span>  </span><span>// NOTE - we get irq at *end* of line so we have to time things accordingly
</span><span>  </span><span>// 1. low for 242 lines -&gt; but irq 2 every line for the first 240
</span><span>  </span><span>// 2. high for 3 lines
</span><span>  </span><span>// 3. low for 22 lines
</span><span>  </span><span>// 4. repeat
</span><span>  </span><span>// runs on sm1
</span><span>  </span><span>// 19 instr
</span><span>  </span><span>let</span><span> vsync = pio::pio_asm!(
</span><span>      "</span><span>.side_set 1 opt</span><span>",
</span><span>      "</span><span>.wrap_target</span><span>",
</span><span>      "</span><span>set Y, 6</span><span>",
</span><span>      "</span><span>a_outer:</span><span>",
</span><span>      "</span><span>set X, 31</span><span>",
</span><span>      "</span><span>a:</span><span>",
</span><span>      "</span><span>wait 1 irq 0</span><span>",
</span><span>      "</span><span>irq set 2</span><span>",
</span><span>      "</span><span>jmp X-- a</span><span>", </span><span>// 32 lines per inner loop
</span><span>      "</span><span>jmp Y-- a_outer</span><span>", </span><span>// 7 outer loops = 224
</span><span>
</span><span>      "</span><span>set X, 15</span><span>", </span><span>// 16 more lines = 240
</span><span>      "</span><span>z:</span><span>"
</span><span>      "</span><span>wait 1 irq 0</span><span>",
</span><span>      "</span><span>irq set 2</span><span>",
</span><span>      "</span><span>jmp X-- z</span><span>",
</span><span>
</span><span>      "</span><span>wait 1 irq 0</span><span>", </span><span>// wait for end of last rgb line
</span><span>      "</span><span>wait 1 irq 0</span><span>", </span><span>// 2 more lines for front porch
</span><span>      "</span><span>wait 1 irq 0</span><span>",
</span><span>
</span><span>      "</span><span>set X, 2 side 0</span><span>", </span><span>// assert vsync
</span><span>      "</span><span>b:</span><span>",
</span><span>      "</span><span>wait 1 irq 0</span><span>",
</span><span>      "</span><span>jmp X-- b</span><span>", </span><span>// wait for 3 lines
</span><span>      "</span><span>set X, 20 side 1</span><span>", </span><span>// deassert vsync
</span><span>      "</span><span>c:</span><span>",
</span><span>      "</span><span>wait 1 irq 0</span><span>",
</span><span>      "</span><span>jmp X-- c</span><span>" </span><span>// wait for 21 lines (back porch)
</span><span>      "</span><span>.wrap</span><span>",
</span><span>  );
</span><span>
</span><span>  </span><span>// 2 cycles per pixel so we run at double speed
</span><span>  </span><span>// 6 instr
</span><span>  </span><span>let</span><span> rgb = pio::pio_asm!(
</span><span>      "</span><span>out X, 32</span><span>", </span><span>// holds 319, which we have to read from the FIFO
</span><span>      "</span><span>.wrap_target</span><span>",
</span><span>      "</span><span>mov Y, X</span><span>",
</span><span>      "</span><span>wait 1 irq 2</span><span>", </span><span>// wait until start of line
</span><span>      "</span><span>a:</span><span>",
</span><span>      "</span><span>out pins, 16</span><span>", </span><span>// write to rgb from dma
</span><span>      "</span><span>jmp Y-- a</span><span>",
</span><span>      "</span><span>mov pins, NULL</span><span>", </span><span>// output black
</span><span>      "</span><span>.wrap</span><span>"
</span><span>  );
</span></pre>
<p>The full code lives <a href="https://gitlab.scd31.com/stephen/rp2040-rcade-crt-driver/-/blob/master/src/main.rs">here</a>.</p><p>There are 3 separate PIO programs. <code>hsync</code> is responsible for keeping time and generating HSYNC pulses. At the start of each line, it generates an IRQ event that the other programs use for synchronization. <code>vsync</code> counts these events and generates the VSYNC pulses. Finally, <code>rgb</code> reads pixel data from DMA and outputs to the RGB pins in precise time with the other signals. The <code>out pins, 16</code> signifies that we're only doing 16-bit colour for now.</p><p>There's a lot of weirdness in here to get around the constraints of the PIO. For example, between all 3 programs, only a maximum of 31 instructions are allowed. All of the VGA parameters (resolution, porch length, etc.) are hard-coded, and changing these would require at least a small rewrite. It's pretty brittle in that regard, but for our use-case it's sufficient as a proof-of-concept.</p><p>Here it is running the actual CRT in the RCade:</p><p><a href="https://www.scd31.com/img/rcade/pio-crt.jpg"><img src="https://www.scd31.com/thumb/rcade/pio-crt.jpg"></a></p><p>I wanted to fill the framebuffer with a repeating pattern, but I messed up my code, hence it looking weird. That's fine - it was enough to verify my VGA program worked!</p><p>As an aside, every time I popped off the back of the RCade to work on it was terrifying. Not because of the lethal voltages inside, but because Recursers absolutely <i>love</i> the RCade. I often joke that if I were to break it, I would basically be the anti-Frank!</p><p>Now that I had something that could take a framebuffer and throw it onto the CRT, it was time to get the image from my computer to the RP2040.</p></section><h2>Let's write a kernel module!</h2><section><p>My plan was to write a Linux kernel module that would expose itself as a framebuffer, and then send that framebuffer over USB to the RP2040. On the framebuffer side, this involved interfacing with the <a href="https://www.kernel.org/doc/html/v4.11/gpu/drm-internals.html">DRM layer</a>.</p><p>I actually made decent progress here, although I kernel panicked many, many times. I never bothered to set up a proper development environment (oops), so pretty much any bug would require me to reboot my computer. This was super annoying and tedious, although I did learn a lot. I found cursed things in the official documentation, like <a href="https://www.kernel.org/doc/html/v5.5/gpu/drm-kms.html#c.drm_display_mode">interrobangs!</a></p><p><a href="https://www.scd31.com/img/rcade/interrobangs.png"><img src="https://www.scd31.com/thumb/rcade/interrobangs.png"></a></p><small>Linus pls</small><p>I got as far as getting a framebuffer to show up at the correct resolution and refresh rate. Along this journey though, I discovered the <a href="https://github.com/notro/gud/wiki">GUD kernel module</a>, and quickly realized I should use that instead.</p></section><h2>GUD is... pretty good</h2><section><p>Okay so this GUD thing is sick. It's a USB display adapter protocol - exactly what I need! It was originally designed to send video from a computer to a Pi Zero for use as a secondary display. It consists of an upstreamed (!!!) kernel module that runs on the host, and separate gadget software that runs on the Pi Zero. I decided I would just write my own gadget implementation to run on the RP2040.</p><p>As a protocol, GUD seems decent. It supports compression over the wire, and only sends the deltas of what's changed in the host's framebuffer. It's also pretty robust in terms of allowing the gadget to advertise what features it supports - compression is optional, and there's flexibility in colour depth and resolution. And again, it's upstreamed into the kernel, so anyone on modern Linux could use my display adapter with no software tweaks.</p><p>Unfortunately, GUD has almost no documentation. I figured out what I needed to do by reverse engineering the kernel module, which involved recompiling it to add some debugging statements. The protocol is simple enough that is wasn't too much of a hassle, and it didn't take long before I had developed a gadget implementation in Rust for the RP2040.</p><p>And with that, we saw our first Linux images on the CRT:</p>
<p>I know, I know, it looks terrible. Several years ago, I had built a board that implements the R/G/B DACs out of resistors, and I reused that for this project. It can only do 12 bits of colour maximum, and for this test I only bothered to wire up ~2 bits per channel, which is basically unusable. But it proves the concept works!</p><p><a href="https://www.scd31.com/img/rcade/vga-dac.jpg"><img src="https://www.scd31.com/thumb/rcade/vga-dac.jpg"></a></p><small>The board I built several years ago. It was originally designed to fit an STM32 development board.</small><p>To be honest, it's pretty lucky that this board came with me to New York. I'm surprised I didn't either throw it out or move it to my parent's place. It was probably in some other box of things I deemed worth keeping around.</p><p><a href="https://www.scd31.com/img/rcade/rev0-board.jpg"><img src="https://www.scd31.com/thumb/rcade/rev0-board.jpg"></a></p><small>The VGA board connected to the RP2040.</small><p>You can see from the above picture that I really connected the bare minimum for a proof-of-concept. I find perfboard soldering to be a bit tedious!</p><p>As an aside, you may notice in the video that the entire screen is shifted to the left. The left side has wrapped around and is now on the right side. On initial boot, it would look fine; over time it would gradually get worse and worse. This is a bug in my implementation - I suspect it's some kind of buffer underflow that's happening, such that each time it occurs, the PIO gets progressively more out of sync. But this is just a guess; I didn't look into it too much.</p><p>The colour depth issue is trivial to fix, but this next one isn't. The framerate sucks! You can even see it in the video above, where you can watch the new frame scroll down the screen. The RP2040 can only do USB FS (full-speed), which is capable of 11 Mbps. At the 320x240x16 bpp we were originally targeting, every frame is 153.6 kB. At our maximum USB FS speed, that's less than 10 FPS! Embarrasingly, I had originally done the math with a bandwidth of 11 M<b>B</b>ps, not 11 M<b>b</b>ps, so I was off by a factor of 8. I was hoping to get something at least temporarily usable but had to go back to the drawing board.</p></section><h2>Going on a GUD gadget side quest</h2><section><p>Who even needs microcontrollers anyway? My next idea was to use the normal GUD gadget implementation, running on a Pi Zero, but outputting to VGA over GPIO. Conceptually this is pretty simple, although in practice it was anything but. The canonical GUD gadget software was based on a 2021 version of <a href="https://buildroot.org/">Buildroot</a>, which was too old to output VGA. I tried, and failed, to update the Buildroot version, as well as to backport the VGA overlay. Neither of those really worked, but I didn't really know what I was doing.</p><p>I also played around with generating a custom NixOS image that had a modern kernel and the GUD gadget kernel module. When that didn't work I prepared to run a user space GUD gadget implementation on Raspberry Pi OS. But like, isn't that boring? And then I'll still be stuck at 18 bit colour! And sometimes a girl just wants to tickle her electrons :3</p></section><h2>Attempt... 2? 3? 1+i? Returning to MCU land</h2><section><p>Okay, so my beloved RP2040 doesn't support USB HS (high-speed). My beloved RP2350 (the newer version of the same chip) doesn't either. But some of my beloved STM32s do!</p><p>Initially I was planning to go computer -&gt; USB HS -&gt; STM32 -&gt; SPI bus -&gt; RP2040 -&gt; VGA. But like, that's complicated, and there are 2 microcontrollers to program, and there is so much to go wrong, and the SPI bus protocol is going to need to be robust against lost/extra bits, and AAAAAAAAAA I don't wanna!</p><p>But! STM32! I learned through research that some of the nicer ones have an LTDC peripheral, which, among other things, can drive an LCD display. And guess what? Many LCDs take in an R, G, B, HSYNC, and VSYNC signal. That's right - they pretend they're a CRT, and they pretend they have a cute little electron gun inside of them, and the STM32 is like "ok I got u" and can just like, do this natively. And I realize that this is what VGA is, but it's so, so funny to me that the protocol is literally just the manifestation of a physical design that is largely obsolete.</p><p>Okay so at this point I'm like, is this even a real project anymore? I'm just connecting the USB peripheral to the LTDC peripheral. What part of this is supposed to take effort? I had already written the GUD gadget implementation. Wasn't I basically already done?</p><p>OH BOY.</p><p>Anyway, by now it's Christmas time and I fly back to Canada to hang out with my family, as you would expect. I had none of my hardware with me, so now felt like a good time to design the actual board.</p><p><a href="https://www.scd31.com/img/rcade/rev1-top.jpg"><img src="https://www.scd31.com/thumb/rcade/rev1-top.jpg"></a>
<a href="https://www.scd31.com/img/rcade/rev1-bottom.jpg"><img src="https://www.scd31.com/thumb/rcade/rev1-bottom.jpg"></a></p><p>By Christmas Eve, this is what I had. Conceptually, it's a pretty basic board - there's the USB HS input, the VGA output, 3 8-bit DACs, some RAM for the framebuffer, and supporting components. At the heart of it is the STM32H723, which is a microcontroller that's advertised as supporting USB HS and LTDC.</p><p>It's worth talking about the DACs a bit. They have a few requirements. They need to map the 8-bit binary space uniformly to the analog domain. They also need to act as a resistor divider - my I/O is at 3.3V, but VGA expects a maximum of 0.7 volts for R/G/B. And finally, they need to be impedance-matched to the 75 ohms of the VGA cable, to prevent reflections and ringing that show up in the image. I am... pretty doubtful we need this at our resolution, but it doesn't hurt, and it increases nerd cred (^:</p><p>I encoded all of these requirements into a system of equations, threw it into a SAT solver, and computed all of my resistor values. I checked the output manually and it made sense, so I used these values in my DAC.</p><p>Also worth noting is the length-matched traces between the STM32 and the HyperRAM. Length-matching ensures that all the signals arrive at the same time; if some arrive too early or late it can cause issues. The traces aren't impedance-matched, but I did a bit of math and determined they were short enough that I didn't have to worry about it.</p><p>Also, I want to talk about the USB port. I used Mini-USB. Alright look. I know I know, I should have used USB-C. But I don't like USB-C! It's a dumb standard. We spent decades teaching non-technical users to plug the square wire into the square hole and the round wire into the round hole. And then we made every hole the same shape!! But they don't all support the same things!! Not even every <b>cable</b> supports the same things!! I hate it!! And Mini-USB is so cute. It's not reversible, but who cares? It's more robust than micro USB, while still being small. And it's my board, my rules. So yes, I will keep sending pictures of this board to people, and they will keep complaining it doesn't use USB-C. And I will continue to not care! Mini-USB is CUTE. And by the way, if you read this entire article and <b>this</b> is the section you choose to engage with, then you are boring!!! You will never live up to Mini-USB!!</p><p>Okay okay sorry about that. I am calm now. With all of that out of the way, I placed the order for the boards. I bought 5 of them, 2 of which were partially assembled. I would complete the rest of the assembly myself, but I didn't want to worry about the more finicky stuff. Between taxes, tariffs, and shipping, it came to a little over a hundred dollars USD.</p></section><h2>Disaster strikes</h2><section><p>About a week later, I was back home in NYC. My boards hadn't arrived yet, although I did have access to an STM32H723 development board at this point. To prepare for my boards, I started porting my RP2040 firmware to the STM32H723.</p><p>Things were going well until I tried getting USB set up. For some reason, I could only get it working at USB FS speeds. I figured I was just initializing something wrong - maybe a register I was forgetting about, or that wasn't in the HAL? I did a lot of digging, before finding this hidden in the datasheet (emphasis mine):</p><blockquote><p>The devices embed a USB OTG high-speed (up to 480 Mbit/s) device/host/OTG peripheral
that supports both full-speed and high-speed operations. It integrates the transceivers for
full-speed operation (12 Mbit/s) and a UTMI low-pin interface (ULPI) for high-speed
operation (480 Mbit/s). <b>When using the USB OTG_HS interface in HS mode, an external
PHY device connected to the ULPI is required.</b></p></blockquote><p>My heart sank. Yes, despite this chip very clearly advertising support for USB HS, it can't actually do that without an external PHY. This is super easy to miss - I actually told other people about the problem, and often they would tell me I was incorrect until I showed it to them in the datasheet. I've also found many posts on the ST Community forums from people running into the same thing. So yeah, I need a new board.</p><p>But because boards are expensive, I figure I'll still use the rev 1 board to validate as much as I can.</p></section><h2>Disaster strikes, again</h2><section><p>Once the boards come, I complete assembly of one, plug it into my computer, and nothing happens. I find out that the 3.3V rail is shorted to ground. This is the same on all of my boards, even the 3 that are disassembled. Some debugging later, it turns out I moved a via in KiCad and didn't do a re-pour. My ground plane was connected to my power plane.</p><p>I have a full CI/CD pipeline set up for my PCBs, so I was surprised it didn't catch this. It turns out it has a bit of wiggle-room, and the re-pour was small enough it didn't get picked up. I now know I need to be disciplined and run DRC locally, ensuring there are literally no differences (and if there are, commit them and push them up to my Git forge).</p><p>Although annoying, and quite embarrassing, this wasn't a huge deal. I used a drill bit and very carefully drilled out the offending via by hand. It made a bit of a mess - make sure you use breathing protection - but I got a board that worked.</p><p><a href="https://www.scd31.com/img/rcade/rev1-drilled.jpg"><img src="https://www.scd31.com/thumb/rcade/rev1-drilled.jpg"></a></p><small>The drilled-out via. You can see it directly under the text, near the center-bottom of the image.</small><p>At this point I wrote some code that exercised the HyperRAM and VGA. Everything worked great, so I began work on the new board. Here's what my development setup looked like while I was testing:</p><p><a href="https://www.scd31.com/img/rcade/rev1-ltdc-testing.jpg"><img src="https://www.scd31.com/thumb/rcade/rev1-ltdc-testing.jpg"></a></p><p>Even though the rev 1 board didn't work out, Frank pointed out that the difference between it and the previous revision was stark:</p><p><a href="https://www.scd31.com/img/rcade/rev0-rev1.jpg"><img src="https://www.scd31.com/thumb/rcade/rev0-rev1.jpg"></a></p><p>Not a bad pace of development!</p></section><h2>Attempt 4 - Rev 2</h2><section><p>I needed an STM32 that supported ULPI (used for talking to the USB PHY), LTDC, and some kind of external RAM. I looked at dozens of chips and found all sorts of blockers. Chips that actually supported both (but they had overlapping pins), chips that were advertised as supporting both (but in actuality, could only do one or the other, depending on the specific model number), and chips that actually could do both, with unconflicting pins, but only in a BGA package. I did not particularly want to deal with that, mainly because the tiny vias and traces would balloon the board cost even more.</p><p>I ended up settling on the STM32H750IBT, a massive, 176 pin, LQFP chip. This thing is larger than some New York apartments, and at over $10 USD, it costs about the same! I have bought entire dev boards for a fraction of this.</p><p>Once I picked out the chip, I basically redesigned the entire board from scratch. Sure, I could reuse the DACs, but I needed completely new RAM (the new chip has no HyperBus), as well as the USB PHY and supporting components. Now that my Christmas vacation was over, it took me a solid week to get everything designed. This isn't my most complicated board, but it's certainly my most complex routing:</p><p><a href="https://www.scd31.com/img/rcade/rev2-routing.png"><img src="https://www.scd31.com/thumb/rcade/rev2-routing.png"></a></p><p>I mean, look at those traces. I'm using basically all available space just to get them to be the same length. ST famously has bad pinouts, and because one of the memory controller pins is located on the complete opposite side of the chip, literally all of the rest of the RAM traces had to be lengthened. And the RAM has a 16-bit data bus. I had to route 38 length-matched traces for the memory alone!</p><p>The USB PHY also had a decent number of traces to route, although far less than the RAM. This is probably the part where I'm supposed to say that like, crosstalk is bad and stuff, but we're just gonna ignore that. I had like no space; leave me alone!</p><p>Here's what the board looked like:</p><p><a href="https://www.scd31.com/img/rcade/rev2-top.jpg"><img src="https://www.scd31.com/thumb/rcade/rev2-top.jpg"></a>
<a href="https://www.scd31.com/img/rcade/rev2-bottom.jpg"><img src="https://www.scd31.com/thumb/rcade/rev2-bottom.jpg"></a></p><p>And with that, I ordered the board. Waiting for it to arrive just about killed me, but when it finally did, I got to work.</p></section><h2>Board bring-up</h2><section><p>Board bring-up is a magical thing. One-by-one, you enable each part of the board, and you make sure that everything works the way you expect. Given that USB burned me before, I decided to start there.</p><p>Right out of the gate, I was off to a bumpy start. I got the USB technically working, and I even got it to show up on my computer as USB HS (yay!), but it was super, super flaky. Eventually I worked out that its crystal oscillator was unstable. Going back to the datasheet, I realized I missed a 1M ohm resistor, which was meant to be put in parallel with the crystal. I didn't have one handy, but I know the human body is around that resistance. I put one finger on each terminal of the crystal. It immediately stabilized. I was pretty ecstatic!</p><p>The next day I went to the Recurse Center and stole a 1M ohm resistor to affix to the board. (Faculty, if you're reading this, I owe you about a tenth of a cent. Sorry!)</p><p>With that over, the rest of the bring-up process was pretty smooth. I got the LTDC running and ported over the rest of the code that implemented the GUD protocol. I had written things pretty naively but, to my surprise, it didn't need any optimization for high-speed USB. I guess that's what a microcontroller with a 480 MHz core will get you!</p></section><h2>Running it in the RCade cabinet</h2><section><p>I was already at the Recurse Center at this point, so I popped the back off the RCade, unplugged the VGA from the Pi, and plugged it into my board. It started up immediately - the colours looked great and I got the full 60 Hz framerate. To be honest, I was shocked at how good it looked, and the crowd that had formed was shocked too. I wasn't really a believer that 24 bit colour would be noticeable, but I was totally wrong. The lack of colour banding was striking.</p><p>Next, I plugged the board into the Pi, and Frank reconfigured it to make my display adapter the primary display. We launched the normal RCade software and played some games. They looked truly amazing; nothing like before. <a href="https://rose.hall.ly/">Rose</a>, one of the main people who developed the software, joked that it looked so good that some of the graphical shortcuts she took were no longer sufficient.</p><p><a href="https://www.scd31.com/img/rcade/image-before.jpg"><img src="https://www.scd31.com/thumb/rcade/image-before.jpg"></a>
<a href="https://www.scd31.com/img/rcade/image-after.jpg"><img src="https://www.scd31.com/thumb/rcade/image-after.jpg"></a></p><p>It's hard to tell in the pictures but the difference in person was striking. Where it's most obvious is in the lack of banding around the mountains.</p><p>This felt amazing, but I wasn't quite ready to leave the board installed. It was fragile - especially with the resistor I bodged on - and it was expensive. I took my board back out and Frank reverted the RCade to how it was before.</p></section><h2>Designing a case</h2><section><p>I'll be honest. I don't get that much joy out of 3D modeling. I find it frustrating, tedious, and generally unfulfilling. To get around this, I decided to use <a href="https://github.com/mrWheel/YAPP_Box">YAPP</a> to design the case. YAPP is a parametric box generator written in OpenSCAD. I wrote a few dozen lines of code and ended up with this beauty:</p><p><a href="https://www.scd31.com/img/rcade/case-top.png"><img src="https://www.scd31.com/thumb/rcade/case-top.png"></a>
<a href="https://www.scd31.com/img/rcade/case-bottom.png"><img src="https://www.scd31.com/thumb/rcade/case-bottom.png"></a></p><p>It took barely any time at all and only took 2 physical revisions before I was happy with it. I added the OpenSCAD code to my board repository and CI/CD pipeline. Now, it builds all the files I need to order the boards, as well as the STL files for the case.</p><p><a href="https://www.scd31.com/img/rcade/case-printing.jpg"><img src="https://www.scd31.com/thumb/rcade/case-printing.jpg"></a></p><small>HE'S BEGINNING TO TAKE FORM</small><p>And now, with the board in the case:</p><p><a href="https://www.scd31.com/img/rcade/physical-case-top.jpg"><img src="https://www.scd31.com/thumb/rcade/physical-case-top.jpg"></a>
<a href="https://www.scd31.com/img/rcade/physical-case-bottom.jpg"><img src="https://www.scd31.com/thumb/rcade/physical-case-bottom.jpg"></a></p><p>At this point I was starting to prepare myself to install it in the RCade.</p></section><h2>Disaster strikes, again??</h2><section><p>Everything was done, so I expected I'd just plug it in and be good to go. When I did this, though, nothing happened. After some debugging I realized the USB had completely died on my board. It wasn't showing up on any computer I connected it to, although the STM32 was still chugging along happily (and outputting to VGA).</p><p>I still haven't figured out exactly what happened here. I was having a bit of flakiness with the USB already. I vaguely suspect ESD to either the STM32 or the USB PHY, but am not super confident this is the cause. I'm going to keep looking into this. (inb4: wow maybe you shouldn't have touched the crystal without grounding yourself first!)</p><p>In the meantime, I assembled a second board and got that installed instead. I'm slightly nervous because I don't have a third board to use if this one also dies, and I don't want to order any more until I can figure out what's killing them. That said, it has been a few days now since I installed it, and despite running 24/7, there's no signs of it dying yet.</p><p><a href="https://www.scd31.com/img/rcade/in-cabinet.jpg"><img src="https://www.scd31.com/thumb/rcade/in-cabinet.jpg"></a></p><p>Here's the board in its case, installed in the RCade. We're still running it off the Raspberry Pi for now, but soon we'll have that switched out with a laptop. I can't wait!</p></section><h2>Future improvements</h2><section><p>There are all sorts of things I want to change. I want the board to also support audio, with an integrated amp. Perhaps even a tube amp? I just think it would be funny. And being able to read input from the controls would be cool too.</p><p>On the software side, I want double or triple buffering. I actually got them both working, although they didn't play nice with the deltas that GUD sends over the wire. There are workarounds to this that I haven't implemented yet. It would also be nice to give GUD the ability to disable these deltas; perhaps that would be a good feature for me to add to the kernel module. Writing some documentation on the GUD protocol could be good too!</p><p>This was a really fun project, and it's not over yet, but I think all the hard stuff is pretty much done (although - I've thought that before!). I really wasn't expecting this to take as long as it did, but I learned so much, and I'm a stronger engineer for it.</p></section><h2>Source code</h2><section><p>There's a few repositories of interest:</p><p>The hardware lives <a href="https://gitlab.scd31.com/stephen/stm32-usb-vga-adapter-hardware">here</a>.</p><p>The software lives <a href="https://gitlab.scd31.com/stephen/stm32-usb-vga-rcade-adapter">here</a>.</p><p>If you're interested, the original software for the RP2040 lives <a href="https://gitlab.scd31.com/stephen/rp2040-rcade-crt-driver">here</a>.</p><p>My very messy DAC equations live <a href="https://gitlab.scd31.com/stephen/vga-dac-formula-sage">here</a>.</p><p>My Nix GUD gadget attempt lives <a href="https://gitlab.scd31.com/stephen/rcade-gud-os">here</a>.</p><p>I also wrote a fair bit of scratch code while learning (such as for my kernel module), but I don't think any of it was worth putting it in my Git forge.</p></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI is killing B2B SaaS (324 pts)]]></title>
            <link>https://nmn.gl/blog/ai-killing-b2b-saas</link>
            <guid>46888441</guid>
            <pubDate>Wed, 04 Feb 2026 17:09:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nmn.gl/blog/ai-killing-b2b-saas">https://nmn.gl/blog/ai-killing-b2b-saas</a>, See on <a href="https://news.ycombinator.com/item?id=46888441">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
    
    
      <p>SaaS is the most profitable business model on Earth.<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" rel="footnote">1</a></sup> It’s easy to understand why: build once, sell the same thing again ad infinitum, and don’t suffer any marginal costs on more sales.</p>

<p>I have been writing software for more than half my life. In the last year itself, I’ve talked to hundreds of founders and operators in SF, from preseed to Series E companies.</p>

<p>AI is bringing an existential threat to a lot of B2B SaaS executives: How to keep asking customers for renewal, when every customer <em>feels</em> they can get something better built with vibe-coded AI products?</p>

<p>And the market is pricing it in. Morgan Stanley’s SaaS basket has <a href="https://www.bloomberg.com/news/articles/2026-01-18/-no-reasons-to-own-software-stocks-sink-on-fear-of-new-ai-tool">lagged the Nasdaq by 40 points</a> since December. HubSpot and Klaviyo are down ~30%. Analysts are writing notes titled “No Reasons to Own” software stocks.</p>

<figure>
  <img src="https://nmn.gl/blog/assets/saas-stocks.png">
  <figcaption>The market is reflecting our new reality (Source: Bloomberg)</figcaption>
</figure>

<!--more-->

<h2 id="the-relation-between-vibe-coding-and-b2b-saas-sales">The relation between vibe coding and B2B SaaS sales</h2>

<p>The new problem for B2B SaaS is that with AI, customers can get <em>something</em> working with vibe coding. There are tens of vibe coding “internal tool” services that promise to connect to every integration in the world to pump out CRUD and workflow apps.</p>

<p>Whatever they build <em>simply works</em>. It takes some wrangling to get there (one Series C VP listed <strong>eleven different</strong> vibe coding tools they’ve tried and the pros and cons between each on a phone call once), but productivity gains are immediate.</p>

<p>And vibe coding is fun. You feel like a mad wizard using the right incantation <sup id="fnref:3" role="doc-noteref"><a href="#fn:3" rel="footnote">2</a></sup> to get this magical new silicon intelligence to do exactly what you want.</p>

<p>What they don’t know, though, is that a poorly architected system will fail, eventually. As every senior programmer (eventually) understands, our job is complex because we have to understand the relationships in the real world, the processes involved, and the workflows needed, and representing it in a robust way to create a stable system. AI can’t do that.</p>

<p>Non-programmers don’t know any of this nuance. One Series E CEO told me that they’re re-evaluating the quarterly renewal of their engineering productivity software because they along with an engineer reimplemented something using Github and Notion APIs. They were paying $30,000 to a popular tool<sup id="fnref:4" role="doc-noteref"><a href="#fn:4" rel="footnote">3</a></sup> <strong>and they were not going to renew anymore.</strong></p>

<h2 id="how-does-it-impact-b2b-sales">How does it impact B2B sales?</h2>

<p>If customers feel like they aren’t being served exactly like they want to, they are more likely to churn. The reason behind all this is that customers are demanding more from their B2B vendors, because they know what’s possible.</p>

<p>Previously, you would change <em>your company</em> to fit what your ERP and pay them hundreds of thousands of dollars. Now, everyone can see that agentic coding makes an unprecedented level of flexibility possible. And customers are demanding that flexibility, and if they don’t get it, they’ll leave.</p>

<p>This week itself I was on a phone call with a Series B AE talking about how they’re potentially losing an $X00,000 account just because the customer can’t use a specific failure reporting workflow in the SaaS. They’re now working with me to build what the customer needs and retain them.</p>

<h2 id="how-to-survive">How to survive</h2>

<h3 id="1-be-a-system-of-record">1. Be a System of Record</h3>

<p>If the entire company’s workflows operates on your platform, i.e. you’re a line-of-business SaaS, you are integrated into their existing team already. They know your UI and rely on you on the day to day.</p>

<p>For example, to create a data visualization I won’t seek any SaaS. I’ll just code one myself using many of the popular vibe coding tools <em>(my team actually did that and it’s vastly more flexible than what we’d get off-the-shelf).</em></p>

<p>Being a “System of Record” means you’re embedded so deeply that there’s no choice but to win. My prediction is that we’ll see more SaaS companies go from the application layer to offering their robust SoR as their primary selling point.</p>

<h3 id="2-security-authentication-and-robustness">2. Security, authentication, and robustness</h3>

<p>This is where vibe-coded apps silently fail — and where established SaaS platforms earn their keep.</p>

<p>When a non-technical team vibe-codes an internal tool, they’re not thinking about environment keys, XSS vulnerabilities or API keys hardcoded in client-side JavaScript. They’re not implementing rate limiting, audit logs, or proper session management. They’re definitely not thinking about SOC 2 compliance, GDPR data residency requirements, or HIPAA audit trails.</p>

<p>I’ve seen it firsthand: a finance team built a “quick” expense approval tool that stored unencrypted reports in a public S3 bucket. A sales ops team created a commission calculator that anyone with the URL could access — no auth required. These aren’t edge cases. They’re the norm when software is built without security as a foundational concern.</p>

<p>Enterprise SaaS platforms have spent years (and millions) solving these problems: role-based access control, encryption at rest and in transit, penetration testing, compliance certifications, incident response procedures. Your customers may not consciously value this — until something breaks.</p>

<p>The challenge is that security is invisible when it works. You need to communicate this value proactively: remind customers that the “simple” tool they could vibe-code themselves would require them to also handle auth, permissions, backups, uptime, and compliance.</p>

<h3 id="3-adapt-to-the-customer-not-the-other-way-around">3. Adapt to the customer, not the other way around</h3>

<p>The times of asking customers to change how they work are gone. Now, SaaS vendors that differentiate by being ultra customizable win the hearts of customers.</p>

<p>How? It’s the most powerful secret to increase usage. We’ve all heard the classic SaaS problem where the software is sold at the beginning of the year, but no one actually ends up using it because of how inflexible it is and the amount of training needed.</p>

<p>And if a SaaS is underutilized, it gets noticed. And that leads to churn.</p>

<p>This is the case with one of my customers, they have a complex SaaS for maintenance operations. But turns out, this was not being used at the technician level because they found the UI too complex<sup id="fnref:5" role="doc-noteref"><a href="#fn:5" rel="footnote">4</a></sup>.</p>

<p>How I’m solving this is essentially a whitelabelled vibe-coding platform with in-built distribution and secure deployments. When they heard of my solution they were immediately onboard. Their customer success teams quickly coded a very specific mobile webapp for the technicians to use and deployed it in a few days.</p>

<p>Now, the IC technician is exposed to just those parts of the SaaS that they care about i.e. creating maintenance work orders. The executives get what they want too, vibe coding custom reports exactly the way they want vs going through complicated BI config. They are able to build exactly what they want and feel like digital gods while doing it.</p>

<p><strong>Usage for that account was under 35%, and is now over 70%.</strong> They are now working closely with me to vibe code new “micro-apps” that work according to all of their customer workflows. And the best part? This is all on top of their existing SaaS which works as a system of record and handles security, authentication, and supports lock-in by being a data and a UI moat.</p>

<p>This is exactly what I’m building: a way for SaaS companies to let their end-users vibe code on top of their platform (More on that below). My customers tell me it’s the best thing they’ve done for retention, engagement, and expansion in 2026 – because when your users are building on your platform, they’re not evaluating your competitors.</p>

<h2 id="the-real-shift">The Real Shift</h2>

<p>Here’s what I’ve realized after hundreds of conversations with founders and operators: AI isn’t killing B2B SaaS. It’s killing B2B SaaS <strong>that refuses to evolve</strong>.</p>

<p>The SaaS model was built on a simple premise: we build it once, you pay forever. That worked when building software was hard. But now your customers have tasted what’s possible. They’ve seen their finance team whip up a custom dashboard in an afternoon. They’ve watched a non-technical PM build an internal tool that actually fits their workflow.</p>

<p>You can’t unsee that. You can’t go back to paying $X0,000/year for software that almost does what you need.</p>

<p>The survivors won’t be the SaaS companies with the best features. They’ll be the ones who become platforms – who let customers build <em>on top of</em> them instead of <em>instead of</em> them. When I showed a well-known VC what I was building to help SaaS companies do exactly this, he said: “This is the future of marketplaces and software companies.”</p>

<p>Maybe. Or maybe this is just another cycle and traditional SaaS will adapt like it always has. But I know this: the companies I’m talking to aren’t waiting around to find out. They’re already rebuilding their relationship with customers from “use our product” to “build on our platform.”</p>

<p>The question isn’t whether AI will eat your SaaS.</p>

<p>It’s whether you’ll be the one holding the fork.</p>

<hr>

<p><strong>I’m solving exactly this problem with a whitelabelled AI platform for B2B SaaS companies</strong>, so your users can vibe code customized workflows on top of their existing system of record.</p>

<p>My customers tell me this is the <strong>best way to support retention, engagement, and expansion</strong> in 2026. If this sounds interesting to you or someone you know, I can reach out with a custom demo or you can <a target="_blank" href="https://gigamind.dev/catalyst">learn more about Giga Catalyst</a>.</p>

<hr>



    
    
    
    
    
    
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[French streamer unbanked by Qonto after criticizing Palantir and Peter Thiel (207 pts)]]></title>
            <link>https://twitter.com/Ced_haurus/status/2018716889191498172</link>
            <guid>46888438</guid>
            <pubDate>Wed, 04 Feb 2026 17:09:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/Ced_haurus/status/2018716889191498172">https://twitter.com/Ced_haurus/status/2018716889191498172</a>, See on <a href="https://news.ycombinator.com/item?id=46888438">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="ScriptLoadFailure"><form action="" method="GET"><div><p><span>Something went wrong, but don’t fret — let’s give it another shot.</span></p><p><img alt="⚠️" draggable="false" src="https://abs-0.twimg.com/emoji/v2/svg/26a0.svg"><span> Some privacy related extensions may cause issues on x.com. Please disable them and try again.</span></p></div></form></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[RS-SDK: Drive RuneScape with Claude Code (109 pts)]]></title>
            <link>https://github.com/MaxBittker/rs-sdk</link>
            <guid>46888142</guid>
            <pubDate>Wed, 04 Feb 2026 16:47:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/MaxBittker/rs-sdk">https://github.com/MaxBittker/rs-sdk</a>, See on <a href="https://news.ycombinator.com/item?id=46888142">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">RS-SDK</h2><a id="user-content-rs-sdk" aria-label="Permalink: RS-SDK" href="#rs-sdk"></a></p>
<p dir="auto">Research-oriented starter kit for runescape-style bots, including a typescript sdk, agent documentation and bindings, and a server emulator. Works out of the box - tell it what to automate!</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/MaxBittker/rs-sdk/blob/main/content/title/promo.gif"><img src="https://github.com/MaxBittker/rs-sdk/raw/main/content/title/promo.gif" alt="RS-SDK Demo" width="800" data-animated-image=""></a>
</p>
<p dir="auto"><a href="https://discord.gg/3DcuU5cMJN" rel="nofollow"><img src="https://github.com/MaxBittker/rs-sdk/raw/main/content/title/discord.svg" alt="Discord"></a>
<a href="https://rs-sdk-demo.fly.dev/hiscores" rel="nofollow"><img src="https://github.com/MaxBittker/rs-sdk/raw/main/content/title/hiscores.svg" alt="Hiscores"></a></p>
<p dir="auto">Build and operate bots within a complex economic role-playing MMO. You can automate the game, level an account to all 99s, and experiment with agentic development techniques within a safe, bot-only setting.</p>
<p dir="auto">The goals of this project are to provide a rich testing environment for goal-directed program synthesis techniques (Ralph loops, etc), and to facilitate research into collaboration and competition between agents.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/MaxBittker/rs-sdk/blob/main/content/title/task_length.svg"><img src="https://github.com/MaxBittker/rs-sdk/raw/main/content/title/task_length.svg" alt="Task Length Distribution"></a></p>
<p dir="auto">There is currently a <a href="https://rs-sdk-demo.fly.dev/hiscores" rel="nofollow">leaderboard</a> for bots running on the demo server, with rankings based on highest total level per lowest account playtime.</p>
<div dir="auto"><p dir="auto">Note</p><p dir="auto">RS-SDK is a fork of the LostCity engine/client, an amazing project without which rs-sdk would not be possible.
Find their <a href="https://github.com/LostCityRS/Server">code here</a> or read their <a href="https://lostcity.rs/t/faq-what-is-lost-city/16" rel="nofollow">history and ethos</a></p>
</div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Getting Started:</h2><a id="user-content-getting-started" aria-label="Permalink: Getting Started:" href="#getting-started"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/MaxBittker/rs-sdk.git"><pre>git clone https://github.com/MaxBittker/rs-sdk.git</pre></div>
<p dir="auto">Out of the box, you can connect to the provided demo server, choose a name that is not already taken!</p>
<p dir="auto">With claude code:</p>
<div dir="auto" data-snippet-clipboard-copy-content="bun install
claude &quot;start a new bot with name: {username}&quot;"><pre>bun install
claude <span><span>"</span>start a new bot with name: {username}<span>"</span></span></pre></div>
<p dir="auto">Manually:</p>
<div dir="auto" data-snippet-clipboard-copy-content="bun install
bun scripts/create-bot.ts {username}
bun bots/{username}/script.ts "><pre>bun install
bun scripts/create-bot.ts {username}
bun bots/{username}/script.ts </pre></div>
<p dir="auto">Chat is off by default to prevent scamming and prompt injection attacks, but you can opt in  with <code>SHOW_CHAT=true</code> in the bot.env file</p>
<p dir="auto">Warning: The demo server is offered as a convenience, and we do not guarantee uptime or data persistence. Hold your accounts lightly, and consider hosting your own server instance. Please do not manually play on the demo server.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Gameplay Modifications</h2><a id="user-content-gameplay-modifications" aria-label="Permalink: Gameplay Modifications" href="#gameplay-modifications"></a></p>
<p dir="auto">This server has a few modifications from the original game to make development and bot testing easier:</p>
<ul dir="auto">
<li><strong>Faster leveling</strong> - The XP curve is accelerated and less steep.</li>
<li><strong>Infinite run energy</strong> - Players never run out of energy</li>
<li><strong>No random events</strong> - Anti-botting random events are disabled</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Architecture:</h2><a id="user-content-architecture" aria-label="Permalink: Architecture:" href="#architecture"></a></p>
<p dir="auto">rs-sdk runs against an enhanced web-based client (<code>botclient</code>) which connects to the LostCity 2004scape server emulator.</p>
<p dir="auto">There is a gateway server which accepts connections from botclient and SDK instances, and forwards messages between them based on username.
Once connected to the gateway, the botclient will relay game state to the SDK, and execute low-level actions (e.g. <code>walkTo(x,y)</code>) sent from the SDK through the gateway.</p>
<p dir="auto">This means that the SDK can't talk directly to the game server, but must go through the botclient. It will attempt to launch the botclient on startup if one is not already running.</p>
<p dir="auto">You don't need to run the gateway/botclient in order to run automations against the demo server, but you may choose to if you are fixing bugs or adding features to the rs-sdk project</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Running the server locally:</h2><a id="user-content-running-the-server-locally" aria-label="Permalink: Running the server locally:" href="#running-the-server-locally"></a></p>
<p dir="auto">You want all these running:</p>
<div dir="auto" data-snippet-clipboard-copy-content="cd engine &amp;&amp; bun run start"><pre><span>cd</span> engine <span>&amp;&amp;</span> bun run start</pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="cd webclient &amp;&amp; bun run watch"><pre><span>cd</span> webclient <span>&amp;&amp;</span> bun run watch</pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="cd gateway &amp;&amp; bun run gateway"><pre><span>cd</span> gateway <span>&amp;&amp;</span> bun run gateway</pre></div>
<p dir="auto">There is also a login server which you may not need, I forget</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Disclaimer</h2><a id="user-content-disclaimer" aria-label="Permalink: Disclaimer" href="#disclaimer"></a></p>
<p dir="auto">This is a free, open-source, community-run project.</p>
<p dir="auto">The goal is strictly education and scientific research.</p>
<p dir="auto">LostCity Server was written from scratch after many hours of research and peer review. Everything you see is completely and transparently open source.</p>
<p dir="auto">We have not been endorsed by, authorized by, or officially communicated with Jagex Ltd. on our efforts here.</p>
<p dir="auto">You cannot play Old School RuneScape here, buy RuneScape gold, or access any of the official game's services! Bots developed here will not work on the official game servers.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">This project is licensed under the <a href="https://opensource.org/licenses/MIT" rel="nofollow">MIT License</a>. See the <a href="https://github.com/MaxBittker/rs-sdk/blob/main/LICENSE">LICENSE</a> file for details.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Microsoft's Copilot chatbot is running into problems (199 pts)]]></title>
            <link>https://www.wsj.com/tech/ai/microsofts-pivotal-ai-product-is-running-into-big-problems-ce235b28</link>
            <guid>46887564</guid>
            <pubDate>Wed, 04 Feb 2026 16:08:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wsj.com/tech/ai/microsofts-pivotal-ai-product-is-running-into-big-problems-ce235b28">https://www.wsj.com/tech/ai/microsofts-pivotal-ai-product-is-running-into-big-problems-ce235b28</a>, See on <a href="https://news.ycombinator.com/item?id=46887564">Hacker News</a></p>
Couldn't get https://www.wsj.com/tech/ai/microsofts-pivotal-ai-product-is-running-into-big-problems-ce235b28: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[Voxtral Transcribe 2 (880 pts)]]></title>
            <link>https://mistral.ai/news/voxtral-transcribe-2</link>
            <guid>46886735</guid>
            <pubDate>Wed, 04 Feb 2026 15:08:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mistral.ai/news/voxtral-transcribe-2">https://mistral.ai/news/voxtral-transcribe-2</a>, See on <a href="https://news.ycombinator.com/item?id=46886735">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p dir="ltr">Today, we're releasing Voxtral Transcribe 2, two next-generation speech-to-text models with state-of-the-art transcription quality, diarization, and ultra-low latency. The family includes Voxtral Mini Transcribe V2 for batch transcription and Voxtral Realtime for live applications. Voxtral Realtime is open-weights under the Apache 2.0 license.</p>
<p dir="ltr">We're also launching an <a href="https://console.mistral.ai/build/audio/speech-to-text">audio playground in Mistral Studio</a> to test transcription instantly, powered by Voxtral Transcribe 2, with diarization and timestamps.</p>
<h2 dir="ltr">Highlights.</h2>
<ul>
<li dir="ltr" aria-level="1">
<p dir="ltr" role="presentation">Voxtral Mini Transcribe V2: State-of-the-art transcription with speaker diarization, context biasing, and word-level timestamps in 13 languages.</p>
</li>
<li dir="ltr" aria-level="1">
<p dir="ltr" role="presentation">Voxtral Realtime: Purpose-built for live transcription with latency configurable down to sub-200ms, enabling voice agents and real-time applications.</p>
</li>
<li dir="ltr" aria-level="1">
<p dir="ltr" role="presentation">Best-in-class efficiency: Industry-leading accuracy at a fraction of the cost, with Voxtral Mini Transcribe V2 achieving the lowest word error rate, at the lowest price point.</p>
</li>
<li dir="ltr" aria-level="1">
<p dir="ltr" role="presentation">Open weights: Voxtral Realtime ships under Apache 2.0, deployable on edge for privacy-first applications.</p>
</li>
</ul>
<h2 dir="ltr">Voxtral Realtime.</h2>
<p dir="ltr">Voxtral Realtime is purpose-built for applications where latency matters. Unlike approaches that adapt offline models by processing audio in chunks, Realtime uses a novel streaming architecture that transcribes audio as it arrives. The model delivers transcriptions with delay configurable down to sub-200ms, unlocking a new class of voice-first applications.</p>
<p dir="ltr"><img src="https://cms.mistral.ai/assets/a21cafea-208d-4290-b65e-36c0514dc179.png?width=2621&amp;height=1293" alt="Fleur Voxtral 2"></p>
<p dir="ltr"><em>Word error rate (lower is better) across languages in the FLEURS transcription benchmark.</em></p>
<p dir="ltr">At 2.4 seconds delay, ideal for subtitling, Realtime matches Voxtral Mini Transcribe V2, our latest batch model. At 480ms delay, it stays within 1-2% word error rate, enabling voice agents with near-offline accuracy.</p>
<p dir="ltr">The model is natively multilingual, achieving strong transcription performance in 13 languages, including English, Chinese, Hindi, Spanish, Arabic, French, Portuguese, Russian, German, Japanese, Korean, Italian, and Dutch. With a 4B parameter footprint, it runs efficiently on edge devices, ensuring privacy and security for sensitive deployments.</p>
<p dir="ltr">We’re releasing the model weights under Apache 2.0 on the <a href="https://huggingface.co/mistralai/Voxtral-Mini-4B-Realtime-2602" target="_blank" rel="noopener">Hugging Face Hub.</a></p>
<h2 dir="ltr">Voxtral Mini Transcribe V2.</h2>
<p><img src="https://cms.mistral.ai/assets/6b8d07b0-1526-4e94-ac66-a861f092aa41.png?width=1775&amp;height=1103" alt="Voxtral 2.0   Avg Diarization Error Rate   Priceper Min"></p>
<p><em>Average diarization error rate (lower is better) across five English benchmarks (Switchboard, CallHome, AMI-IHM, AMI-SDM, SBCSAE) and the TalkBank multilingual benchmark (German, Spanish, English, Chinese, Japanese).</em></p>
<p><img src="https://cms.mistral.ai/assets/58664549-fe38-420a-86fd-5c7003476689.png?width=1775&amp;height=1111" alt="Voxtral 2.0   Transcription Performance Fleurs   Priceper Min"></p>
<p><em>Average word error rate (lower is better) across the top-10 languages in the FLEURS transcription benchmark.</em></p>
<p>Voxtral Mini Transcribe V2 delivers significant improvements in transcription and diarization quality across languages and domains. At approximately 4% word error rate on FLEURS and $0.003/min, Voxtral offers the best price-performance of any transcription API. It outperforms GPT-4o mini Transcribe, Gemini 2.5 Flash, Assembly Universal, and Deepgram Nova on accuracy, and processes audio approximately 3x faster than ElevenLabs’ Scribe v2 while matching on quality at one-fifth the cost.</p>
<h3 dir="ltr">Enterprise-ready features.</h3>
<p dir="ltr">Voxtral Mini Transcribe V2 introduces key capabilities for enterprise deployments.</p>
<div>
<div><p><img src="https://cms.mistral.ai/assets/4b23530e-23c1-4a58-8296-c61a1d5cff98.png?width=96&amp;height=96" alt="Icon Language"></p><h4>Speaker diarization.</h4>
<p dir="ltr">Generate transcriptions with speaker labels and precise start/end times. Ideal for meeting transcription, interview analysis, and multi-party call processing. Note: with overlapping speech, the model typically transcribes one speaker.</p>
</div>
<div><p><img src="https://cms.mistral.ai/assets/221e1a35-1b56-41a1-b294-6e5a3492e0cd.png?width=72&amp;height=64" alt="Icon Filters"></p><h4>Context biasing.</h4>
<p dir="ltr">Provide up to 100 words or phrases to guide the model toward correct spellings of names, technical terms, or domain-specific vocabulary. Particularly useful for proper nouns or industry terminology that standard models often miss. Context biasing is optimized for English; support for other languages is experimental.</p>
</div>
<div><p><img src="https://cms.mistral.ai/assets/e8c644a8-93bf-49c0-ae96-a859c1cec3ad.svg?width=32&amp;height=32" alt="Word-level timestamps."></p><h4>Word-level timestamps.</h4>
<p dir="ltr">Generate precise start and end timestamps for each word, enabling applications like subtitle generation, audio search, and content alignment.</p>
</div>
</div>
<div>
<div><p><img src="https://cms.mistral.ai/assets/ecdac1ed-522e-4a58-a3cc-23d03c40ba6e.png?width=96&amp;height=96" alt="Icon Earth Black"></p><h4>Expanded language support.</h4>
<p dir="ltr">Like Realtime, this model now supports 13 languages: English, Chinese, Hindi, Spanish, Arabic, French, Portuguese, Russian, German, Japanese, Korean, Italian, and Dutch. Non-English performance significantly outpaces competitors.</p>
</div>
<div><p><img src="https://cms.mistral.ai/assets/ec93c74e-5cdd-4950-b494-0a8f3a43dd74.svg?width=32&amp;height=32" alt="Noise robustness."></p><h4>Noise robustness.</h4>
<p dir="ltr">Maintains transcription accuracy in challenging acoustic environments, such as factory floors, busy call centers, and field recordings.</p>
</div>
<div><p><img src="https://cms.mistral.ai/assets/d18e43b2-1c42-4916-b787-d28739220476.svg?width=32&amp;height=32" alt="Longer audio support."></p><h4>Longer audio support.</h4>
<p dir="ltr">Process recordings up to 3 hours in a single request.</p>
</div>
</div>
<p dir="ltr"><img src="https://cms.mistral.ai/assets/97f4a4ee-7448-4a2f-889e-17409821e503.png?width=2849&amp;height=1358" alt="FlEURS"></p>
<p><em>Word error rate (lower is better) across languages in the FLEURS transcription benchmark.</em></p>
<h2 dir="ltr">Audio playground.</h2>
<p dir="ltr">Test Voxtral Transcribe 2 directly in <a href="https://console.mistral.ai/build/audio/speech-to-text">Mistral Studio</a>. Upload up to 10 audio files, toggle diarization, choose timestamp granularity, and add context bias terms for domain-specific vocabulary. Supports .mp3, .wav, .m4a, .flac, .ogg up to 1GB each.</p>
<p dir="ltr"><iframe title="YouTube video player" src="https://www.youtube.com/embed/93ZAhW3bk8g" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe></p>
<h2 dir="ltr">Transforming voice applications.</h2>
<p dir="ltr">Voxtral powers voice workflows in diverse applications and industries.</p>
<ul>
<li>
<h3 dir="ltr">Meeting intelligence.</h3>
<p dir="ltr">Transcribe multilingual recordings with speaker diarization that clearly attributes who said what and when. At Voxtral's price point, annotate large volumes of meeting content at industry-leading cost efficiency.</p>
</li>
<li>
<h3 dir="ltr">Voice agents and virtual assistants.</h3>
<p dir="ltr">Build conversational AI with sub-200ms transcription latency. Connect Voxtral Realtime to your LLM and TTS pipeline for responsive voice interfaces that feel natural.</p>
</li>
<li>
<h3 dir="ltr">Contact center automation.</h3>
<p dir="ltr">Transcribe calls in real time, enabling AI systems to analyze sentiment, suggest responses, and populate CRM fields while conversations are still happening. Speaker diarization ensures clear attribution between agents and customers.</p>
</li>
<li>
<h3 dir="ltr">Media and broadcast.</h3>
<p dir="ltr">Generate live multilingual subtitles with minimal latency. Context biasing handles proper nouns and technical terminology that trip up generic transcription services.</p>
</li>
<li>
<h3 dir="ltr">Compliance and documentation.</h3>
<p dir="ltr">Monitor and transcribe interactions for regulatory compliance, with diarization providing clear speaker attribution and timestamps enabling precise audit trails.</p>
</li>
</ul>
<p dir="ltr">Both models support GDPR and HIPAA-compliant deployments through secure on-premise or private cloud setups.</p>
<h2 dir="ltr">Get started.</h2>
<p dir="ltr"><a href="https://docs.mistral.ai/models/voxtral-mini-transcribe-26-02">Voxtral Mini Transcribe V2</a> is available now via API at $0.003 per minute. Try it now in the new Mistral Studio <a href="https://console.mistral.ai/build/audio/speech-to-text">audio playground</a> or in <a href="http://chat.mistral.ai/">Le Chat</a>.</p>
<p dir="ltr"><a href="https://docs.mistral.ai/models/voxtral-mini-transcribe-realtime-26-02">Voxtral Realtime</a> is available via API at $0.006 per minute and as open weights on <a href="https://huggingface.co/mistralai/Voxtral-Mini-3B-Realtime-2602">Hugging Face</a>.</p>
<p dir="ltr"><a href="https://docs.mistral.ai/capabilities/audio_transcription">Explore documentation</a> on Mistral’s audio and transcription capabilities.</p>
<h2 dir="ltr">We’re hiring.</h2>
<p dir="ltr">If you're excited about building world-class speech AI and putting frontier models into the hands of developers everywhere, we'd love to hear from you. <a href="https://mistral.ai/careers">Apply to join our team</a>.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A case study in PDF forensics: The Epstein PDFs (289 pts)]]></title>
            <link>https://pdfa.org/a-case-study-in-pdf-forensics-the-epstein-pdfs/</link>
            <guid>46886440</guid>
            <pubDate>Wed, 04 Feb 2026 14:46:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pdfa.org/a-case-study-in-pdf-forensics-the-epstein-pdfs/">https://pdfa.org/a-case-study-in-pdf-forensics-the-epstein-pdfs/</a>, See on <a href="https://news.ycombinator.com/item?id=46886440">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>The recent release of a <a href="https://www.justice.gov/epstein/doj-disclosures" target="_blank" rel="noopener">tranche of files</a> by the US Department of Justice (DoJ) under the “Epstein Files Transparency Act (H.R.4405)” has once again prompted many people to closely examine redacted and sanitized PDF documents. Our previous articles on the <a href="https://pdfa.org/corruption-in-pdf-federal-crimes-edition/">Manafort papers</a> and the <a href="https://pdfa.org/a-technical-and-cultural-assessment-of-the-mueller-report-pdf/">Mueller report</a>, as well as a study by Adhatarao, S. and Lauradoux, C. (2021) “<a href="https://doi.org/10.1145/3437880.3460405" target="_blank" rel="noopener">Exploitation and Sanitization of Hidden Data in PDF Files: Do Security Agencies Sanitize Their PDF files?</a>,” in <em>Proceedings of the 2021 ACM Workshop on Information Hiding and Multimedia Security</em>, illustrate the importance of robust sanitization and redaction workflows when handling sensitive documents prior to release.</p>
<p>This article examines a small random selection of the Epstein PDF files from a purely digital forensic perspective, focusing on the PDF syntax and idioms they contain, any malformations or unusual constructs, and other technical aspects.</p>
<p>PDFs are more challenging to analyze than many other formats because they are binary files that require specialized knowledge, expertise, and software. Please note that we did not analyze the contents of the PDF documents. Not every PDF was examined. Any mention of products (or appearance in screen-shots) does not imply any endorsement or support of any information, products, or providers whatsoever. We are not lawyers; this article does not constitute legal advice</p>
<p>We offer this information, in part, as some of the Epstein PDFs released by DoJ are beginning to appear on malware analysis sites (such as <a href="https://hybrid-analysis.com/sample/d8f6ba273d416f1b3160b94b5646374b218a9ecef9d2cb3ae33cd3788f8f862b/6946599fcca0461fcc056ab2" target="_blank" rel="noopener">Hybrid-Analysis</a>) with various kinds of incorrect analysis and misinformation.</p>
<h2 id="26-december-2025-update">26 December 2025 update</h2>
<p>After we'd completed our analysis the DoJ released a new dataset, <a href="https://www.justice.gov/epstein/files/DataSet%208.zip">DataSet 8.zip</a>. This new ZIP file is 9.95 GB compressed and contains over 11,000 files, including 10,593 new PDFs totaling 1.8 GB and 29,343 pages (the longest document has 1,060 pages). DataSet 8 also contains many large MP4 movies, Excel spreadsheets, and various other files. The first PDF in the set of 10,593 PDFs is VOL00008\IMAGES\0001\EFTA00009676.pdf, and the last file is VOL00008\IMAGES\0011\EFTA00039023.pdf. A cursory analysis shows <span>pdfinfo</span> properties similar to those from the earlier datasets, but we have not otherwise analyzed this new dataset.</p>
<p>Since our original post, various social media and news platforms have also been announcing “recoverable redactions” from the “Epstein Files”. We stand by our analysis; DoJ has correctly redacted the EFTA PDFs in Datasets 01-07, and they <b><i>do not contain</i></b> recoverable text as alleged. As our article states, we did not analyze any other DoJ or Epstein-related documents.</p>
<p>For example, the featured image in <a href="https://www.theguardian.com/us-news/2025/dec/23/epstein-unredacted-files-social-media">this Guardian news article</a> (which was also picked up by the <a href="https://www.nytimes.com/2025/12/23/us/politics/epstein-files-redactions-doj.html">New York Times</a>) corresponds to VOL00004\IMAGES\0001EFTA00005855.pdf, as can be easily determined by searching for the Bates Numbers in the EFTA “.OPT” data files. The information in this EFTA PDF is <b><i>fully and correctly redacted</i></b>; there is <b><i>no hidden information</i></b>. The only extractable text is some garbled text from the poor-quality OCR and, as expected, the Bates Numbers on each page.</p>
<p>In the few reports we investigated (including from <a href="https://www.forbes.com/sites/daveywinder/2025/12/26/epstein-files-hacked---all-you-need-to-know">Forbes</a> and Ed Krassenstein on both <a href="https://x.com/EdKrassen/status/2003222444270661801">X (formerly Twitter)</a> and <a href="https://www.instagram.com/krassensteins?igsh=eGYyc3gwZXA2eW4=">Instagram</a>), these stories misrepresent <strong><i>other</i></strong> DoJ files that were <b><i>not</i></b> part of the major DataSets 01-07 release on December 19 under the EFTA. All PDFs released under EFTA have a Bates Number on every page starting "EFTA". These include “<a href="https://www.justice.gov/multimedia/Court%20Records/Government%20of%20the%20United%20States%20Virgin%20Islands%20v.%20JPMorgan%20Chase%20Bank,%20N.A.,%20No.%20122-cv-10904%20(S.D.N.Y.%202022)/001-01.pdf">Case 1:22-cv-10904-JSR &nbsp; Document 1-1,&nbsp; Exhibit 1 to Government’s Complaint against JPMorgan Chase Bank, N.A.</a>” (see page 41) and “<a href="https://www.justice.gov/multimedia/Court%20Records/Matter%20of%20the%20Estate%20of%20Jeffrey%20E.%20Epstein,%20Deceased,%20No.%20ST-21-RV-00005%20(V.I.%20Super.%20Ct.%202021)/2022.03.17-1%20Exhibit%201.pdf">Case No: ST-20-CV-14 Government Exhibit 1</a>” (see page 19). These PDFs, previously released by the DoJ, do contain incorrect and ineffective redactions, with black boxes that simply obscure text, making “copy &amp; paste” easy to recover the text that's otherwise hidden. Clearly, DoJ processes and systems in the past have inadequately redacted information!</p>
<h2 id="the-files-we-examined">The files we examined</h2>
<p>The tranche released by DoJ on Friday, December 19 is available as seven “data sets”, most easily downloaded as seven ZIP archives totaling just under 2.97 GB. Each ZIP file contains a similar folder structure, with DataSet 6 being the odd one out with an extra top-level folder. Once unzipped, the total size is 2.99 GB. The tranche contains 4,085 PDF files, a single AVI (movie) file (located in the folder VOL00002\NATIVES\0001), and 2 data files (.DAT and .OPT) for each ZIP archive. The “.OPT” files appear to be CSV (<a href="https://en.wikipedia.org/wiki/Comma-separated_values" target="_blank" rel="noopener">Comma-Separated Values</a>) but lack a heading row, while the “.DAT” files contain information about the <a href="https://en.wikipedia.org/wiki/Bates_numbering" target="_blank" rel="noopener">Bates numbering</a>. The analysis we provide here is limited to the PDF files.</p>
<p>The PDF files are named and ordered sequentially within the folder structure, starting with “EFTA00000001.pdf” in VOL00001 and ending with “EFTA00009664.pdf” in VOL00007, indicating that <span><strong>at least 5,879 PDF files remain unreleased</strong></span>.</p>
<p>A random sampling of the PDFs for visual review suggests that they are a mix of single and multi-page full-page photos and scanned content. OCR (Optical Character Recognition) was used to provide some searchable and extractable text in at least some files. “Black box” style redactions (without text reasons) are apparent. When done correctly, this is the appropriate way to redact, far more robust than <a href="https://www.bitdefender.com/en-us/blog/hotforsecurity/stop-pixelating-new-tool-reveals-the-secrets-of-redacted-documents" target="_blank" rel="noopener">pixelating text</a>. The PDFs we sampled did not include any obviously “born digital” documents. Various news sites are reporting <a href="https://www.cbsnews.com/news/epstein-files-redaction-over-500-pages-entirely-blacked-out/" target="_blank" rel="noopener">very heavily redacted documents</a> within this tranche.</p>
<h2 id="file-validity">File validity</h2>
<p>A precursor to most forensic examinations is to establish whether the PDF files are technically valid (that is, conform to the rules of the PDF format), since analyzing malformed files can easily lead to incorrect results or wrong conclusions. Combining tools that use different methods provides the broadest possible information while ensuring that tooling limitations are fully understood. However, if the basic file structure or cross-reference information is incorrect, various software might then draw different conclusions and/or construct different Document Object Models (DOMs).</p>
<p>In addition to basic file structure, incremental updates (if any), and cross-reference information, PDF validity assessments include the objects that comprise the PDF’sDOM as well as the file structure, incremental updates, and cross-reference information. To assess relationships between objects in the PDF DOM, some forensic analysis tools leverage our <a href="https://github.com/pdf-association/arlington-pdf-model" target="_blank" rel="noopener">Arlington PDF Data Model</a>, while others use their own internal methods.</p>
<p>Our analysis of file validity, using a multitude of PDF forensic tools, identified only one minor defect (invalidity); 109 PDFs had a positive FontDescriptor <strong>Descent</strong> value rather than a negative one. This is a relatively common (but minor) error, typically associated with font substitution and font matching, that does not affect the validity of the files overall. One specific forensic tool reported a PDF version issue with some files, related to the document catalog <strong>Version</strong> entry, which prevented the tool from further verifying those specific PDFs.</p>
<h2 id="pdf-versions">PDF versions</h2>
<p>I’ve previously written about the <a href="https://pdfa.org/pdf-versions/">unreliability of PDF version numbers</a>. Still, for forensic purposes, they may provide insight into the DoJ’s software, and whether improved software could have performed better.</p>
<p>I used two different but commonly used PDF command-line <code>pdfinfo</code> utilities on different platforms (Windows and Ubuntu Linux) to summarize information about these PDF files. When run against the full tranche of PDFs, I got two very different sets of answers! Immediately, my <a href="https://en.wiktionary.org/wiki/Spidey_sense#English" target="_blank" rel="noopener">spidey senses</a> started to tingle, and I was once again reminded of a key lesson in digital document forensics – you should <em><span>never</span></em> trust a single tool!</p>
<table>
<tbody>
<tr>
<td><strong>Reported PDF Version</strong></td>
<td><strong>Count Tool A</strong></td>
<td><strong>Count Tool B</strong></td>
</tr>
<tr>
<td>1.3</td>
<td>209</td>
<td>3,817</td>
</tr>
<tr>
<td>1.4</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>1.5</td>
<td>3,875</td>
<td>267</td>
</tr>
<tr>
<td><strong>TOTAL</strong> <em>(should be 4,085)</em></td>
<td>4,085</td>
<td>4,085</td>
</tr>
</tbody>
</table>

<p>The PDF version in the file header, “<code>%PDF-<em>x.y</em></code>”, is nominally the first line in every PDF file (based on the not-unreasonable assumption that the PDF files have no “junk bytes” before this PDF file identifier). Using the Linux command line, you can run in Linux “<code>head -n 1 <em>file.pdf</em></code>” to extract the first header line from each PDF and compare it with the reported results from each tool. Or run in Linux “<code>grep -P --text --byte-offset "%PDF-\d\.\d" *.pdf</code>” to confirm that there are no junk bytes prior to the PDF header line.</p>
<p>The reason for the difference reported in the table above is that Tool B is not accounting for the <strong>Version</strong> entry in the document catalog of PDFs with incremental updates. We’ll next investigate whether this is due to malformed files or a programming error. When properly accounting for incremental updates, however, Tool A is correct.</p>
<p>Using the same <code>pdfinfo</code> output (and again comparing results from both tools), we can also quickly establish the following facts:</p>
<ul>
<li>No PDF is tagged</li>
<li>No PDF is encrypted</li>
<li>No PDF is “optimized” (technically, Linearized PDF)</li>
<li>No PDF has any annotations</li>
<li>No PDF has any outlines (bookmarks)</li>
<li>No PDF contains any embedded files</li>
<li>None of the PDFs are forms</li>
<li>None of the PDFs contains JavaScript</li>
</ul>
<p>Page counts range from 1 (in 3,818 PDFs) to 119 pages (in two PDFs), totaling 9,659 pages across all 4,085 PDFs.</p>
<h2 id="incremental-updates">Incremental updates</h2>
<p>PDF’s incremental updates feature allows multiple revisions of a document to be stored in a PDF file. As the name implies, each set of deltas is appended to the original document, forming a chain of edits. When read by conforming PDF software, a PDF is <em><span>always</span></em> processed from the end of the file, effectively applying the deltas to the original document and to any previous incremental updates. Both the original document and each incremental update can be recognized by their respective “<code>xref</code>” and “<code>%%EOF</code>” markers (assuming that the PDF files are structured correctly).</p>
<p>For this investigation, we started by examining the very first PDF in the tranche: VOL00001\IMAGES\0001\EFTA00000001.pdf. This PDF had different PDF versions reported by different versions of <code>pdfinfo</code>. A simple trick to check if a PDF contains incremental updates is to search for these special markers while treating the PDF as a text file (<em>which it isn’t!</em>):</p>
<p><strong><code>$ grep -P --text -–byte-offset "(xref)|(%%EOF)" EFTA00000001.pdf</code></strong><br>
<code>371340:xref<br>
371758:startxref<br>
371775:%%EOF<br>
372977:startxref<br>
372994:%%EOF<br>
373961:startxref<br>
373978:%%EOF</code></p>
<p>These results (sorted by byte offset) indicate that EFTA00000001.pdf contains <em><span>two incremental updates after the original file</span></em>. The lack of an “<code>xref</code>” marker before the last two “<code>startxref</code>” markers indicate that neither incremental updates uses conventional cross-reference data, but may use cross-reference streams (if any objects are changed).</p>
<h2 id="bates-numbering">Bates numbering</h2>
<p>As referenced above, Bates numbering is the process by which every page is assigned a unique identifier. For this tranche of Epstein PDF files, Bates numbers were added to each page via a separate incremental update, as shown below in <a href="https://pdfa.org/resource/vscode-extension-pdf-cos-syntax-support/">Visual Studio Code with my pdf-cos-syntax extension</a>. Note that DoJ’s PDFs are primarily text-based internally, making forensic analysis a lot easier - and the files a lot bigger.</p>
<p><img decoding="async" src="https://pdfa.org/wp-content/uploads/2025/12/2984-3037.png" alt="Screenshot of VS Code discussed in the text." width="766" height="1284" srcset="https://pdfa.org/wp-content/uploads/2025/12/2984-3037.png 766w, https://pdfa.org/wp-content/uploads/2025/12/2984-3037-179x300.png 179w, https://pdfa.org/wp-content/uploads/2025/12/2984-3037-611x1024.png 611w, https://pdfa.org/wp-content/uploads/2025/12/2984-3037-600x1006.png 600w" sizes="(max-width: 766px) 100vw, 766px"></p>
<p>Observations:</p>
<ul>
<li>Line 2984 is the end-of-file marker for the file version, and line 2985 starts a new incremental update section.</li>
<li>Lines 2985-2987 define object 26, the unembedded Helvetica font resource used by the Bates number.</li>
<li>Lines 2997-3020 are the modified page object (object 3), replacing the page object in previous revisions of the file.</li>
<li>Line 2999 is the page Contents array, comprising five separate content streams, with the 3rd stream (object 29) being the Bates numbering added in this incremental update. Object 30 is an empty content stream that could have been removed by an optimization process.</li>
<li>Line 3034 sets the Helvetica font to 12 point.</li>
<li>Line 3037 uses a hexadecimal string to paint the Bates number onto the page.</li>
</ul>
<p>The idiom for this final incremental update, which adds the Bates number to every page, appears in all the PDF files we selected at random for investigation. This specific incremental update always uses a cross-reference stream (<code>/Type /XRef</code>) and relies on the previous incremental update, in which the document catalog <strong>Version</strong> entry is set to PDF 1.5.</p>
<h2 id="the-first-incremental-update">The first incremental update</h2>
<p>The VSCode pdf-cos-syntax extension also indicates (correctly!) that the original PDF is missing the required (when the PDF contains binary data, which most do) comment as the second line of the file that indicates to software that the PDF file needs to be treated as binary data (ISO 32000-2:2020, §7.5.2). Although the missing comment does not make the PDF invalid per se, without such a marker close to the top of each PDF, software may think the PDF is a text file, and thus potentially corrupt the PDF by changing line endings, which would break the byte offsets in the cross-reference data. In this PDF, the first incremental update adds this marker comment after a lot of binary data, which is pointless.</p>
<p>As mentioned above, the first incremental update changed the document catalog <strong>Version</strong> entry to PDF 1.5, as we see in this next screenshot:</p>
<p><img decoding="async" src="https://pdfa.org/wp-content/uploads/2025/12/2924-3000.png" alt="Screenshot of VS Code discussed in the text." width="766" height="1284" srcset="https://pdfa.org/wp-content/uploads/2025/12/2924-3000.png 766w, https://pdfa.org/wp-content/uploads/2025/12/2924-3000-179x300.png 179w, https://pdfa.org/wp-content/uploads/2025/12/2924-3000-611x1024.png 611w, https://pdfa.org/wp-content/uploads/2025/12/2924-3000-600x1006.png 600w" sizes="(max-width: 766px) 100vw, 766px"></p>
<p><span>Observations:</span></p>
<ul>
<li><span>Lines 2953-2984 are the incremental update section.</span></li>
<li><span>Line 2954 is a PDF comment. PDF comments always start with a PERCENT SIGN (<code>%</code>) and may occur in many places in PDF files. Effective sanitization and redaction workflows typically remove all comments from PDFs because they may inadvertently disclose information, but this exact comment appears in 3,608 other PDF files. The origin or meaning of this comment was not further investigated.</span></li>
<li><span>Line 2964 upgrades the PDF version to 1.5. At first glance, this may appear to be perfectly valid PDF, but it is technically incorrect because the file header is <code>%PDF-1.3</code> yet the <strong>Version</strong> key was only added in PDF 1.4 - this is what the strict file validation tool mentioned above had noticed. As object 24 is a compressed object stream (lines 2966-2973) and object 25 is a compressed cross-reference stream (lines 2974-2981), the indicated version should be PDF 1.5. As a practical matter, however, this level of technical detail does not impact operation or behavior of PDFs.</span></li>
<li><span>Line 2984 is the end-of-section “<code>%%EOF</code>” marker for this incremental update section.</span></li>
</ul>
<p><span>As this section of the PDF uses compressed object streams, specialized PDF forensic tools must be used… simple search methodologies, such as those mentioned above, may not identify everything!</span></p>
<p><span>We know that there are 7 objects (because we find /<code>N 7</code>) inside the object stream:</span></p>
<p><img loading="lazy" decoding="async" src="https://pdfa.org/wp-content/uploads/2025/12/pdf-debugger.png" alt="Screenshot of debugger displaying content discussed in the text." width="676" height="443" srcset="https://pdfa.org/wp-content/uploads/2025/12/pdf-debugger.png 676w, https://pdfa.org/wp-content/uploads/2025/12/pdf-debugger-300x197.png 300w, https://pdfa.org/wp-content/uploads/2025/12/pdf-debugger-600x393.png 600w" sizes="auto, (max-width: 676px) 100vw, 676px"></p>
<p><span>As per PDF’s specification, ISO 32000-2:2020, §7.5.7, the first line of integers is interpreted as N pairs, where the first integer is the object number and the second integer is the byte offset relative to the first object in the object stream.</span></p>
<table>
<tbody>
<tr>
<td><strong>N</strong></td>
<td><strong>1st integer (object number)</strong></td>
<td><strong>2nd integer (start offset)</strong></td>
<td><strong>Explanation</strong></td>
<td><strong>Content</strong></td>
</tr>
<tr>
<td>1</td>
<td>19</td>
<td>0</td>
<td>Type1 Font object for OPBaseFont0 (Courier)</td>
<td><span>&lt;&lt;/BaseFont/Courier/Encoding&lt;&lt;/BaseEncoding/WinAnsiEncoding/Type/Encoding&gt;&gt;/Name/OPBaseFont0/Subtype/Type1/Type/Font&gt;&gt;</span></td>
</tr>
<tr>
<td>2</td>
<td>20</td>
<td>118</td>
<td>Type1 Font object for OPBaseFont1 (Helvetica)</td>
<td><span>&lt;&lt;/BaseFont/Helvetica/Encoding&lt;&lt;/BaseEncoding/WinAnsiEncoding/Type/Encoding&gt;&gt;/Name/OPBaseFont1/Subtype/Type1/Type/Font&gt;&gt;</span></td>
</tr>
<tr>
<td>3</td>
<td>17</td>
<td>238</td>
<td>Document information (Info) dictionary</td>
<td><span>&lt;&lt;/CreationDate(D:20251218143205)/Creator(OmniPage CSDK 21.1)/ModDate(D:20251218143205)/Producer(Processing-CLI)&gt;&gt;</span></td>
</tr>
<tr>
<td>4</td>
<td>18</td>
<td>352</td>
<td>ProcSet resources array</td>
<td><span>[/PDF/Text/ImageB/ImageC/ImageI]</span></td>
</tr>
<tr>
<td>5</td>
<td>22</td>
<td>384</td>
<td>Resources dictionary for the page</td>
<td><span>&lt;&lt;/Font&lt;&lt;/OPBaseFont0 19 0 R/OPBaseFont1 20 0 R&gt;&gt;/ProcSet 18 0 R/XObject&lt;&lt;/Im0 8 0 R&gt;&gt;&gt;&gt;</span></td>
</tr>
<tr>
<td>6</td>
<td>23</td>
<td>472</td>
<td>Array of 2 indirect references (to content streams)</td>
<td><span>[21 0 R 4 0 R]</span></td>
</tr>
<tr>
<td>7</td>
<td>3</td>
<td>486</td>
<td>Updated Page object</td>
<td><span>&lt;&lt;/Contents 23 0 R/MediaBox[0 0 864 576.75]/Parent 2 0 R/Resources 22 0 R/Thumb 11 0 R/Type/Page&gt;&gt;</span></td>
</tr>
</tbody>
</table>

<p>What is very interesting here – from a PDF forensics perspective – is the fact of a <strong><em><span>hidden document information dictionary</span></em></strong> that is not referenced from the last (final) incremental update trailer (i.e., there is no <strong>Info</strong> entry in object 31, lines 3050-3063 below). As such, this orphaned dictionary is invisible to PDF software! This oddity occurs in all other PDFs we’d randomly selected for investigation.</p>
<p><img loading="lazy" decoding="async" src="https://pdfa.org/wp-content/uploads/2025/12/2985-3067.png" alt="Screenshot of VS Code discussed in the text." width="777" height="1144" srcset="https://pdfa.org/wp-content/uploads/2025/12/2985-3067.png 777w, https://pdfa.org/wp-content/uploads/2025/12/2985-3067-204x300.png 204w, https://pdfa.org/wp-content/uploads/2025/12/2985-3067-695x1024.png 695w, https://pdfa.org/wp-content/uploads/2025/12/2985-3067-768x1131.png 768w, https://pdfa.org/wp-content/uploads/2025/12/2985-3067-600x883.png 600w" sizes="auto, (max-width: 777px) 100vw, 777px"></p>
<p><span>Formatted nicely as an uncompressed object, this hidden document information dictionary inside the compressed object stream contains the following information (the CreationDate and ModDate appear to change in other randomly examined PDFs):</span></p>
<pre>     17 0 obj
     &lt;&lt;
          /CreationDate (D:20251218143205)
          /ModDate      (D:20251218143205)
          /Creator      (OmniPage CSDK 21.1)
          /Producer     (Processing-CLI)
     &gt;&gt;
     endobj</pre>
<p>This metadata clearly indicates the software DoJ used to manipulate these PDF files. Although not relevant to the content, this forensic discovery clearly shows that extra care is required when sanitizing PDFs.</p>
<h2 id="different-incremental-updates">Different incremental updates</h2>
<p>Another randomly selected PDF, VOL00003\IMAGES\0001\EFTA00003939.pdf contains 3 full-page images, and just a single incremental update that applies the Bates numbering. However, in this case the file header is <code>%PDF-1.5</code> yet both the original PDF and incremental update use conventional cross-reference tables! This isn’t problematic, but is certainly unexpected and inefficient since PDF 1.5 introduced compressed cross-reference streams.</p>
<p>By comparing the objects in the incremental cross-reference table to the original cross-reference table we can see that objects 66 to 69 – the 3 Page objects for the 3 page document – were redefined. This is just what is expected in order to add the Bates number to each page’s <strong>Contents</strong> stream as in the previous example.</p>

<p>Our initial examination using pdfinfo utilities did not identify any metadata in any of the PDFs in the tranche, either in the document information dictionary (PDF file trailer Info entry) or as an XMP metadata stream (<strong>Metadata</strong> entry).</p>
<p>However, since we know that (a) the tranche includes PDFs with incremental updates, and (b) that an orphaned document information dictionary exists, all revisions of a document should be thoroughly examined. Incremental updates may have marked other document information dictionaries or XMP metadata streams as free but not deleted the actual data.</p>
<p>XMP metadata is always encoded in PDF as a stream object, and since stream objects cannot be in compressed object streams, using forensic tools to search for keys “<code>/XML</code>” or “<code>/Metadata</code>” should always locate them. All modern office suites and PDF creation applications will generate XMP metadata when exporting to PDF. As XMP is usually uncompressed, searching for XML fragments may also be helpful (see below for an example XMP object fragment).</p>
<pre>     3 0 obj
     &lt;&lt;/Length 36996/Subtype/XML/Type/Metadata&gt;&gt;
     stream
     &lt;?xpacket begin="ï»¿" id="W5M0MpCe … zNTczkc9d"?&gt;
     &lt;x:xmpmeta xmlns:x="adobe:ns:meta/" x:xmptk=" … "&gt;
         &lt;rdf:RDF 
     xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"&gt;
              &lt;rdf:Description rdf:about=""
                   xmlns:dc="http://purl.org/dc/elements/1.1/"
                   xmlns:xmp="http://ns.adobe.com/xap/1.0/"
     ...</pre>
<p>Not unsurprisingly for properly-redacted files, we did not find any XMP metadata streams or XML in any PDF. As a consequence, none of the PDFs can declare conformance to either PDF/A (ISO 19005 for long-term archiving) or PDF/UA (ISO 14289 for accessibility). Of course, as untagged PDFs, the files cannot conform to accessibility specifications such as PDF/UA or WCAG in any event. Additionally, none of the PDFs appear to include device-independent color spaces.</p>
<p>The presence of an <strong>Info</strong> entry in the trailer dictionary or (in PDFs with cross-reference streams) in the cross-reference stream dictionary indicates the presence of document information dictionaries. “<code>/Info</code>” does indeed occur in many of the PDFs, including multiple times in some PDFs, indicating potential changes via incremental updates. However, as discovered above, in some cases the final incremental update does not include an <strong>Info</strong> entry, thus “orphaning” any existing document information dictionaries.</p>
<p>ISO 32000-2:2020, Table 349 lists the defined entries in PDF’s document information dictionary (<strong>Title</strong>, <strong>Author</strong>, <strong>Subject</strong>, etc). Any vendor may add additional entries (such as <a href="https://developer.apple.com/documentation/coregraphics/kcgpdfcontextkeywords" target="_blank" rel="noopener">Apple does with its <span>/AAPL:Keywords</span> entry</a>), so redaction and sanitization software should be aware of extra entries.</p>
<p>From our random sampling, we identified one PDF with a non-trivial document information dictionary still present: VOL00002\IMAGES\0001\EFTA00003212.pdf. This is shown below in <a href="https://pdfa.org/resource/vscode-extension-pdf-cos-syntax-support/">Visual Studio Code with my pdf-cos-syntax extension</a>:</p>
<p><img loading="lazy" decoding="async" src="https://pdfa.org/wp-content/uploads/2025/12/1-69.png" alt="Screenshot of VS Code discussed in the text." width="766" height="1284" srcset="https://pdfa.org/wp-content/uploads/2025/12/1-69.png 766w, https://pdfa.org/wp-content/uploads/2025/12/1-69-179x300.png 179w, https://pdfa.org/wp-content/uploads/2025/12/1-69-611x1024.png 611w, https://pdfa.org/wp-content/uploads/2025/12/1-69-600x1006.png 600w" sizes="auto, (max-width: 766px) 100vw, 766px"></p>
<p><span>Of additional interest in this specific PDF is that the comment at line 60 has survived DoJ’s sanitization and redaction workflow! Other PDF comments may therefore also be present in other files.</span></p>
<p><span>EFTA00003212.pdf appears to be a redacted image or an error from the DoJ workflow, as it is a single page with the text “No Images Produced”.</span></p>
<p><span>Simple searching of the standardized PDF document information dictionary entries gives the following (note that the technique used will not locate information in compressed object streams, as mentioned above):</span></p>
<table>
<tbody>
<tr>
<td><strong>Key name</strong></td>
<td><strong>Number of PDFs (max. = 4,085)</strong></td>
<td><strong>Comment</strong></td>
</tr>
<tr>
<td><strong>Info</strong></td>
<td>3,823</td>
<td>Some PDFs have empty <strong>Info</strong> dictionaries with no entries</td>
</tr>
<tr>
<td><strong>Title</strong></td>
<td>1</td>
<td>Only EFTA00003212.pdf</td>
</tr>
<tr>
<td><strong>Author</strong></td>
<td>1</td>
<td>Only EFTA00003212.pdf</td>
</tr>
<tr>
<td><strong>Subject</strong></td>
<td>1</td>
<td>Only EFTA00003212.pdf</td>
</tr>
<tr>
<td><strong>Keywords</strong></td>
<td>1</td>
<td>Only EFTA00003212.pdf</td>
</tr>
<tr>
<td><strong>Creator</strong></td>
<td>1</td>
<td>Only EFTA00003212.pdf</td>
</tr>
<tr>
<td><strong>Producer</strong></td>
<td>215</td>
<td>Always “pypdf” (denotes <a href="https://pypi.org/project/pypdf/" target="_blank" rel="noopener">https://pypi.org/project/pypdf/</a>)</td>
</tr>
<tr>
<td><strong>CreationDate</strong></td>
<td>3,609</td>
<td>Same PDFs that have <strong>ModDate</strong> with an identical value</td>
</tr>
<tr>
<td><strong>ModDate</strong></td>
<td>3,609</td>
<td>Same PDFs that have <strong>CreationDate</strong> with an identical value</td>
</tr>
<tr>
<td><strong>Trapped</strong></td>
<td>1</td>
<td>Only EFTA00003212.pdf</td>
</tr>
<tr>
<td><strong>APPL:Keywords</strong></td>
<td>0</td>
<td></td>
</tr>
</tbody>
</table>

<h3 id="date-analysis">Date analysis</h3>
<p>Detailed date analysis is a common task in the forensic analysis of potentially fraudulent or modified documents. However, in the case of redacted or sanitized documents, where the document is known to have been modified, this can be less useful.</p>
<p>The creation and modification dates for the 3,609 PDFs range from December 18, 2025, 14:32:05 (2:32 pm) to December 19, 2025, 23:26:13 (almost midnight). For all files, the creation and modification dates are always the same. This may also imply that the DoJ batch processing to prepare this tranche of PDFs took at least 36 hours!</p>
<p>What’s also interesting is that the <strong>CreationDate</strong> and <strong>ModDate</strong> fields in the hidden document information dictionary (inside the object stream of the first increment update – see above) appear to always be an exact match to both the <strong>CreationDate</strong> and <strong>ModDate</strong> of the original document. This implies that all dates across all incremental updates were updated in a single processing pass that applied the Bates numbering.</p>
<h2 id="photographs">Photographs</h2>
<p>There are no JPEG images (<strong>DCTDecode </strong>filter) in any PDF in the tranche, including the full-page photographs. Randomly viewing the photographic images at high magnification (zoom) in PDF viewers clearly shows JPEG “jaggy” <a href="https://en.wikipedia.org/wiki/Compression_artifact" target="_blank" rel="noopener">compression artifacts</a>. All photographic images appear to have been downscaled to 96 DPI (769 x 1152 or 1152 x 769 pixels), making text on random objects in the photos much harder to discern (see the <a href="#ocr">OCR discussion below</a>).</p>
<p>DoJ explicitly avoids JPEG images in the PDFs probably because they appreciate that JPEGs often contain identifiable information, such as EXIF, IPTC, or XMP metadata, as well as <a href="https://exiftool.org/#JPEG" target="_blank" rel="noopener">COM (comment) tags</a> in the JPEG bitstream. This information may disclose the camera model and serial number, GPS location, camera operator details, date/time of the photo, etc., and is more difficult to redact while retaining the JPEG data. The DoJ processing pipeline has therefore explicitly converted all lossy JPEG images to low DPI, FLATE-encoded bitmaps in the PDFs using an indexed device-dependent color space with a palette of 256 unique colors (which reduces the color fidelity compared to the original high-quality digital color photograph).</p>
<h2 id="scanned-documents-or-are-they">Scanned documents – or are they?</h2>
<p>Randomly inspecting the tranche discovers many documents that appear to have been created by a scanning process. On closer inspection, there are documents that have tell-tale artifacts from a physical scanning process, such as visible physical paper edges, punched holes, staple marks, spiral binding, stamps, paper scuff marks, color blotches and inconsistencies, handwritten notes or marginalia, varying paper skew, and platen marks from the physical paper scanning processes. For example, VOL00007\IMAGES\0001\EFTA00009440.pdf shows many of these aspects</p>
<p>There are also other documents that appear to <span><em>simulate</em></span> a scanned document but completely lack the “real-world noise” expected with physical paper-based workflows. The much crisper images appear almost perfect without random artifacts or background noise, and with the exact same amount of image skew across multiple pages. Thanks to the borders around each page of text, page skew can easily be measured, such as with VOL00007\IMAGES\0001\EFTA00009229.pdf. It is highly likely these PDFs were created by rendering original content (from a digital document) to an image (e.g., via print to image or save to image functionality) and then applying image processing such as skew, downscaling, and color reduction.</p>
<p>The use of the timeless monospaced (also known as fixed-width) “Courier” typeface means that the number of characters redacted can be easily determined by vertical alignment with text lines above and below each redaction. In some instances, this may reduce the possible number of options that represent the redacted content, allowing it to be more easily guessed. Although redaction of variable-width typefaces is far more complex, Bland, M., Iyer, A., and Levchenko, K. 2022 paper “<a href="http://arxiv.org/abs/2206.02285" target="_blank" rel="noopener">Story Beyond the Eye: Glyph Positions Break PDF Text Redaction</a>” showed that this is still possible with sufficient computing power and determination.</p>
<h3 id="optical-character-recognition-ocr"><a id="ocr"></a>Optical Character Recognition (OCR)</h3>
<p><a href="https://en.wikipedia.org/wiki/Optical_character_recognition" target="_blank" rel="noopener">OCR</a> is complex image processing that attempts to identify text in bitmap images. In PDF files, OCR-identified text is commonly placed on top of the image using the invisible text render mode. This enables users to then extract the text from the image.</p>
<p>Returning to the very first PDF file in the tranche, VOL00001\IMAGES\0001\EFTA00000001.pdf - this is a full-page photo of a hand-written sign where part of the hand-written information is explicitly redacted. The PDF contains largely inaccurate OCR-ed text, indicating that natural language processing (NLP), machine learning (ML), or even language aware dictionary-based algorithms were not used. This means that there will be more errors in the extracted text than is necessary.</p>
<p>With cloud platforms readily accessible and supporting advanced OCR at low cost, anyone is capable of re-processing the entire tranche of PDFs and comparing the OCR results to those provided by DoJ. Even though the page images are low-resolution (96 DPI), rerunning OCR may bring to light additional or corrected information hidden by the original OCR that failed to recognize everything correctly.</p>
<p>The “black box” redactions we investigated were all correctly applied directly into the image pixel data. They are not separate PDF rectangle objects simply floating above sensitive information that was still present in the image and easily discoverable. Yes, sometimes it is that easy…!</p>
<h2 id="conclusion">Conclusion</h2>
<p>We did not set out to comprehensively analyze every corner of every PDF file in the Epstein PDFs, but to present a basic walk-through of some of the challenges and tricks used to conduct a PDF forensic assessment. Our results above were from a small random sample of documents - there may well be outlier PDFs in the data sets that we did not encounter.</p>
<p>The DoJ has clearly created internal processes, systems, and workflows that can sanitize and redact information prior to publishing as PDF. This includes converting JPEG images to low-resolution pixel-only bitmaps, largely removing metadata, and rendering page images to bitmaps. OCR appears to have been widely applied, but is of variable quality.</p>
<p>Their PDF technology could be improved to vastly reduce file size by removing unnecessary objects (e.g., empty content streams, ProcSets, empty thumbnail references, etc.), simplifying and reducing content streams, applying all incremental updates (i.e., removing all incremental update sections), and always using compressed object streams and compressed cross-reference streams. Information leakage may also be occurring via PDF comments or orphaned objects inside compressed object streams, as I discovered above.</p>
<p>PDF forensics is a highly complex field, where variations in files and tool assumptions can easily yield false results. The PDF Association hosts a PDF Forensic Liaison Working Group to develop industry guidance on forensic examination of PDF files and to educate document examiners and other specialists about many of these aspects.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Attention at Constant Cost per Token via Symmetry-Aware Taylor Approximation (159 pts)]]></title>
            <link>https://arxiv.org/abs/2602.00294</link>
            <guid>46886265</guid>
            <pubDate>Wed, 04 Feb 2026 14:33:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2602.00294">https://arxiv.org/abs/2602.00294</a>, See on <a href="https://news.ycombinator.com/item?id=46886265">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2602.00294">View PDF</a>
    <a href="https://arxiv.org/html/2602.00294v1">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>The most widely used artificial intelligence (AI) models today are Transformers employing self-attention. In its standard form, self-attention incurs costs that increase with context length, driving demand for storage, compute, and energy that is now outstripping society's ability to provide them. To help address this issue, we show that self-attention is efficiently computable to arbitrary precision with constant cost per token, achieving orders-of-magnitude reductions in memory use and computation. We derive our formulation by decomposing the conventional formulation's Taylor expansion into expressions over symmetric chains of tensor products. We exploit their symmetry to obtain feed-forward transformations that efficiently map queries and keys to coordinates in a minimal polynomial-kernel feature basis. Notably, cost is fixed inversely in proportion to head size, enabling application over a greater number of heads per token than otherwise feasible. We implement our formulation and empirically validate its correctness. Our work enables unbounded token generation at modest fixed cost, substantially reducing the infrastructure and energy demands of large-scale Transformer models. The mathematical techniques we introduce are of independent interest.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Leo Kozachkov [<a href="https://arxiv.org/show-email/aad7e88e/2602.00294" rel="nofollow">view email</a>]      <br>    <strong>[v1]</strong>
        Fri, 30 Jan 2026 20:38:02 UTC (2,756 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FBI couldn't get into WaPo reporter's iPhone because Lockdown Mode enabled (566 pts)]]></title>
            <link>https://www.404media.co/fbi-couldnt-get-into-wapo-reporters-iphone-because-it-had-lockdown-mode-enabled/</link>
            <guid>46886237</guid>
            <pubDate>Wed, 04 Feb 2026 14:31:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.404media.co/fbi-couldnt-get-into-wapo-reporters-iphone-because-it-had-lockdown-mode-enabled/">https://www.404media.co/fbi-couldnt-get-into-wapo-reporters-iphone-because-it-had-lockdown-mode-enabled/</a>, See on <a href="https://news.ycombinator.com/item?id=46886237">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  
<!--kg-card-begin: html-->

<!--kg-card-end: html-->
<p>The FBI has been unable to access a Washington Post reporter’s seized iPhone because it was in Lockdown Mode, a sometimes overlooked feature that makes iPhones broadly more secure, according to recently filed court records.</p><p>The court record shows what devices and data the FBI was able to ultimately access, and which devices it could not, after <a href="https://www.theguardian.com/us-news/2026/jan/14/fbi-raid-washington-post-hannah-natanson?ref=404media.co"><u>raiding the home of the reporter</u></a>, Hannah Natanson, in January as part of an investigation into leaks of classified information. It also provides rare insight into the apparent effectiveness of Lockdown Mode, or at least how effective it might be before the FBI may try other techniques to access the device.</p><div><p>💡</p><p><b><strong>Do you know anything else about phone unlocking technology? I would love to hear from you. Using a non-work device, you can message me securely on Signal at joseph.404 or send me an email at joseph@404media.co.</strong></b></p></div>
</div><div>
  <div>
    <h2>This post is for paid members only</h2>
    <p>Become a paid member for unlimited ad-free access to articles, bonus podcast content, and more.</p>
    <p><a href="https://www.404media.co/membership/">Subscribe</a>
  </p></div>
  <div>
    <h2>Sign up for free access to this post</h2>
    <p>Free members get access to posts like this one along with an email round-up of our week's stories.</p>
    <p><a href="https://www.404media.co/signup/">Subscribe</a>
  </p></div>
  <p>Already have an account? <a href="https://www.404media.co/signin/" data-portal="signin">Sign in</a></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Guinea worm on track to be 2nd eradicated human disease; only 10 cases in 2025 (286 pts)]]></title>
            <link>https://arstechnica.com/health/2026/02/guinea-worm-on-track-to-be-2nd-eradicated-human-disease-only-10-cases-in-2025/</link>
            <guid>46886191</guid>
            <pubDate>Wed, 04 Feb 2026 14:27:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/health/2026/02/guinea-worm-on-track-to-be-2nd-eradicated-human-disease-only-10-cases-in-2025/">https://arstechnica.com/health/2026/02/guinea-worm-on-track-to-be-2nd-eradicated-human-disease-only-10-cases-in-2025/</a>, See on <a href="https://news.ycombinator.com/item?id=46886191">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                      
                      
          <p>A debilitating infection from the parasitic Guinea worm is inching closer to global eradication, with an all-time low of only 10 human cases reported worldwide in 2025, <a href="https://www.cartercenter.org/news/guinea-worm-announcement/">the Carter Center announced</a>.</p>
<p>If health workers can fully wipe out the worms, it will be only the second human disease to be eradicated, after smallpox.</p>
<p>Guinea worm (<em>Dracunculus medinensis</em>) is a parasitic nematode transmitted in water. More specifically, it’s found in waters that contain small crustacean copepods, which harbor the worm’s larvae. If a person consumes water contaminated with Guinea worm, the parasites burrow through the intestinal tract and migrate through the body. About a year later, a spaghetti noodle-length worm emerges from a painful blister, usually in the feet or legs. It can take up to eight weeks for the adult worm to fully emerge. To ease the searing pain, infected people may put their blistered limbs in water, allowing the parasite to release more larvae and continue the cycle.</p>
<p>In addition to being extremely painful, the disease (dracunculiasis) can lead to complications, such as secondary infections and sepsis, which in turn can lead to temporary or permanent disability.</p>
<p>When the Guinea worm eradication program began in 1986, there were an estimated 3.5 million cases across 21 countries in Africa and Asia. To date, only six countries have not been certified by the World Health Organization as Guinea worm-free. In 2024, there were just 15 cases, and, according to the provisional tally for 2025, the number is down to just 10. It’s considered provisional until each country’s disease reports are confirmed, which occurs in a program meeting usually held in April.</p>

          
                      
                  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Claude Is a Space to Think (419 pts)]]></title>
            <link>https://www.anthropic.com/news/claude-is-a-space-to-think</link>
            <guid>46884883</guid>
            <pubDate>Wed, 04 Feb 2026 12:08:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.anthropic.com/news/claude-is-a-space-to-think">https://www.anthropic.com/news/claude-is-a-space-to-think</a>, See on <a href="https://news.ycombinator.com/item?id=46884883">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div data-theme="ivory"><p>There are many good places for advertising. A conversation with Claude is not one of them.</p><p>Advertising drives competition, helps people discover new products, and allows services like email and social media to be offered for free. We’ve run our own <a href="https://www.youtube.com/watch?v=FDNkDBNR7AM">ad campaigns</a>, and our AI models have, in turn, helped many of our customers in the advertising industry.</p><p>But including ads in conversations with Claude would be incompatible with what we want Claude to be: a genuinely helpful assistant for work and for deep thinking.</p><p>We want Claude to act unambiguously in our users’ interests. So we’ve made a choice: Claude will remain ad-free. Our users won’t see “sponsored” links adjacent to their conversations with Claude; nor will Claude’s responses be influenced by advertisers or include third-party product placements our users did not ask for.</p><h2 id="the-nature-of-ai-conversations"><strong>The nature of AI conversations</strong></h2><p>When people use search engines or social media, they’ve come to expect a mixture of organic and sponsored content. Filtering signal from noise is part of the interaction.</p><p>Conversations with AI assistants are meaningfully different. The format is open-ended; users often share context and reveal more than they would in a search query. This openness is part of what makes conversations with AI valuable, but it’s also what makes them susceptible to influence in ways that other digital products are not.</p><p>Our <a href="https://www.anthropic.com/news/how-people-use-claude-for-support-advice-and-companionship">analysis of conversations</a> with Claude (conducted in a way that keeps all data <a href="https://www.anthropic.com/research/clio">private and anonymous</a>) shows that an appreciable portion involve topics that are sensitive or deeply personal—the kinds of conversations you might have with a trusted advisor. Many other uses involve complex software engineering tasks, deep work, or thinking through difficult problems. The appearance of ads in these contexts would feel incongruous—and, in many cases, inappropriate.</p><p>We still have much to learn about the impact of AI models on the people who use them. <a href="https://www.jmir.org/2025/1/e67114">Early</a> <a href="https://hai.stanford.edu/news/exploring-the-dangers-of-ai-in-mental-health-care">research</a> suggests both benefits—like people finding support they couldn’t access elsewhere—and risks, including the potential for models to reinforce harmful beliefs in vulnerable users. Introducing advertising incentives at this stage would add another level of complexity. <a href="https://www.anthropic.com/research/tracing-thoughts-language-model">Our understanding</a> of how models translate the goals we set them into specific behaviors is still developing; an ad-based system could therefore have unpredictable results.</p><h2 id="incentive-structures"><strong>Incentive structures</strong></h2><p>Being genuinely helpful is one of the core principles of <a href="https://www.anthropic.com/constitution">Claude’s Constitution</a>, the document that describes our vision for Claude’s character and guides how we train the model. An advertising-based business model would introduce incentives that could work against this principle.</p><p>Consider a concrete example. A user mentions they’re having trouble sleeping. An assistant without advertising incentives would explore the various potential causes—stress, environment, habits, and so on—based on what might be most insightful to the user. An ad-supported assistant has an additional consideration: whether the conversation presents an opportunity to make a transaction. These objectives may often align—but not always. And, unlike a list of search results, ads that influence a model’s responses may make it difficult to tell whether a given recommendation comes with a commercial motive or not. Users shouldn’t have to second-guess whether an AI is genuinely helping them or subtly steering the conversation towards something monetizable.</p><p>Even ads that don’t directly influence an AI model’s responses and instead appear separately within the chat window would compromise what we want Claude to be: a clear space to think and work. Such ads would also introduce an incentive to optimize for engagement—for the amount of time people spend using Claude and how often they return. These metrics aren’t necessarily aligned with being genuinely helpful. The most useful AI interaction might be a short one, or one that resolves the user’s request without prompting further conversation.</p><p>We recognize that not all advertising implementations are equivalent. More transparent or opt-in approaches—where users explicitly choose to see sponsored content—might avoid some of the concerns outlined above. But the history of ad-supported products suggests that advertising incentives, once introduced, tend to expand over time as they become integrated into revenue targets and product development, blurring boundaries that were once more clear-cut. We’ve chosen not to introduce these dynamics into Claude.</p><h2 id="our-approach"><strong>Our approach</strong></h2><p>Anthropic is focused on businesses, developers, and helping our users flourish. Our business model is straightforward: we generate revenue through enterprise contracts and paid subscriptions, and we reinvest that revenue into improving Claude for our users. This is a choice with tradeoffs, and we respect that other AI companies might reasonably reach different conclusions.</p><p>Expanding access to Claude is central to our public benefit mission, and we want to do it without selling our users’ attention or data to advertisers. To that end, we’ve <a href="https://www.anthropic.com/news/anthropic-teach-for-all">brought AI tools and training to educators</a> in over 60 countries, begun national AI education pilots with <a href="https://www.anthropic.com/news/anthropic-and-iceland-announce-one-of-the-world-s-first-national-ai-education-pilots">multiple</a> <a href="https://www.anthropic.com/news/rwandan-government-partnership-ai-education">governments</a>, and made Claude <a href="https://www.anthropic.com/news/claude-for-nonprofits">available to nonprofits</a> at a significant discount. We continue to invest in our smaller models so that our free offering remains at the frontier of intelligence, and we may consider lower-cost subscription tiers and regional pricing where there is clear demand for it. Should we need to revisit this approach, we’ll be transparent about our reasons for doing so.</p><h2 id="supporting-commerce"><strong>Supporting commerce</strong></h2><p>AI will increasingly interact with commerce, and we look forward to supporting this in ways that help our users. We’re particularly interested in the potential of agentic commerce, where Claude acts on a user’s behalf to handle a purchase or booking end to end. And we’ll continue to build features that enable our users to find, compare, or buy products, connect with businesses, and more—when they choose to do so.</p><p>We’re also exploring more ways to make Claude a focused space to be at your most productive. Users can already <a href="https://claude.com/blog/interactive-tools-in-claude">connect third-party tools</a> they use for work—like Figma, Asana, and Canva—and interact with them directly within Claude. We expect to introduce many more useful integrations and expand this toolkit over time.</p><p>All third-party interactions will be grounded in the same overarching design principle: they should be initiated by the <em>user </em>(where the AI is working for them) rather than an <em>advertiser</em> (where the AI is working, at least in part, for someone else). Today, whether someone asks Claude to research running shoes, compare mortgage rates, or recommend a restaurant for a special occasion, Claude’s only incentive is to give a helpful answer. We’d like to preserve that.</p><h2 id="a-trusted-tool-for-thought"><strong>A trusted tool for thought</strong></h2><p>We want our users to trust Claude to help them keep thinking—about their work, their challenges, and their ideas.</p><p>Our experience of using the internet has made it easy to assume that advertising on the products we use is inevitable. But open a notebook, pick up a well-crafted tool, or stand in front of a clean chalkboard, and there are no ads in sight.</p><p>We think Claude should work the same way.</p></div></article></div><div data-theme="ivory"><p><h2>Related content</h2></p><div><div><h3>Apple’s Xcode now supports the Claude Agent SDK</h3><p><a href="https://www.anthropic.com/news/apple-xcode-claude-agent-sdk" referrerpolicy="no-referrer-when-downgrade"><span>Read more</span><span><svg width="20" height="20" viewBox="0 0 21 21"><path d="M4.14585 9.87492L14.4584 9.87492L9.60419 5.04158L10.5 4.14575L16.8542 10.4999L10.5 16.8541L9.60419 15.9583L14.4584 11.1249L4.14585 11.1249L4.14585 9.87492Z" fill="currentColor"></path></svg></span></a></p></div><div><h3>Anthropic partners with Allen Institute and Howard Hughes Medical Institute to accelerate scientific discovery</h3><p><a href="https://www.anthropic.com/news/anthropic-partners-with-allen-institute-and-howard-hughes-medical-institute" referrerpolicy="no-referrer-when-downgrade"><span>Read more</span><span><svg width="20" height="20" viewBox="0 0 21 21"><path d="M4.14585 9.87492L14.4584 9.87492L9.60419 5.04158L10.5 4.14575L16.8542 10.4999L10.5 16.8541L9.60419 15.9583L14.4584 11.1249L4.14585 11.1249L4.14585 9.87492Z" fill="currentColor"></path></svg></span></a></p></div><div><h3>ServiceNow chooses Claude to power customer apps and increase internal productivity</h3><p><a href="https://www.anthropic.com/news/servicenow-anthropic-claude" referrerpolicy="no-referrer-when-downgrade"><span>Read more</span><span><svg width="20" height="20" viewBox="0 0 21 21"><path d="M4.14585 9.87492L14.4584 9.87492L9.60419 5.04158L10.5 4.14575L16.8542 10.4999L10.5 16.8541L9.60419 15.9583L14.4584 11.1249L4.14585 11.1249L4.14585 9.87492Z" fill="currentColor"></path></svg></span></a></p></div></div></div></div>]]></description>
        </item>
    </channel>
</rss>