<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Mon, 09 Oct 2023 07:00:10 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Bill to Ban Hidden Fees in California Signed into Law (105 pts)]]></title>
            <link>https://oag.ca.gov/news/press-releases/attorney-general-bonta%E2%80%99s-sponsored-bill-ban-hidden-fees-california-signed-law</link>
            <guid>37817112</guid>
            <pubDate>Mon, 09 Oct 2023 05:17:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://oag.ca.gov/news/press-releases/attorney-general-bonta%E2%80%99s-sponsored-bill-ban-hidden-fees-california-signed-law">https://oag.ca.gov/news/press-releases/attorney-general-bonta%E2%80%99s-sponsored-bill-ban-hidden-fees-california-signed-law</a>, See on <a href="https://news.ycombinator.com/item?id=37817112">Hacker News</a></p>
<div id="readability-page-1" class="page"><div property="content:encoded"><p><b>OAKLAND&nbsp;</b>— California Attorney General Rob Bonta today issued a statement in response to Senate Bill 478 (SB 478), a bill that&nbsp;he&nbsp;<a href="https://oag.ca.gov/news/press-releases/attorney-general-bonta-senator-dodd-senator-skinner-introduce-bill-prohibiting" target="_blank">sponsored</a>,&nbsp;being signed into law by Governor Gavin Newsom. Coauthored by Senator Bill Dodd (D-Napa) and Senator Nancy Skinner (D-Berkeley), the legislation will prohibit hidden fees (also called ‘junk fees’) in California beginning on July 1, 2024. Hidden fees are fees in which a seller uses an artificially low headline price to attract a customer and usually either discloses additional required fees in smaller print, or reveals additional unavoidable charges later in the buying process.</p>
<p>“Today, California is eliminating hidden fees,”&nbsp;<b>said Attorney General Rob Bonta</b>. “These deceptive fees prevent us from knowing how much we will be charged at the outset.&nbsp;They&nbsp;are bad for consumers and bad for competition. They cost Americans tens of billions of dollars each year. They hit families who are just trying to make ends meet the hardest. And, because a growing list of websites, apps, and brick-and-mortar businesses are using them, they penalize companies that are upfront and transparent with their prices. With the signing of SB 478, California now has the most effective piece of legislation in the nation to tackle this problem. The price Californians see will be the price they pay. I am deeply grateful to Senators Dodd and Skinner, the authors of SB 478, for their commitment to protecting consumers.”</p>
<p>“With the governor’s signing of this historic bill, we can finally take aim at dishonest junk fees that are tacked onto seemingly everything – from online concert tickets to hotel reservations,”&nbsp;<b>said Senator&nbsp;Bill Dodd</b>. “Now we can put the consumer first and create a level playing field for those businesses that advertise the real price, up front. I appreciate everyone who worked to end these dishonest charges that boost corporate profits at the expense of those who can least afford it.”</p>
<p>“California sent a clear message today: The days of bait-and-switch pricing practices are over,”&nbsp;<b>said Senator&nbsp;Nancy Skinner</b>. “With Gov. Newsom’s signing of SB 478, Californians will know up front how much they’re being asked to pay, and no longer be surprised by hidden junk fees when buying a concert or sports ticket or booking hotel rooms for their family vacation.”&nbsp;</p>
<p>After announcing that he was sponsoring SB 478 in February 2023, Attorney General Bonta&nbsp;<a href="https://oag.ca.gov/news/press-releases/attorney-general-bonta-california-heeding-president-biden%E2%80%99s-call-end-hidden-fees" target="_blank">urged</a>&nbsp;the California Legislature to approve the legislation in March 2023, heeding the call from the Biden-Harris Administration and the Consumer Financial Protection Bureau for states to better address the nationwide concern of hidden fees. In May 2023, he&nbsp;<a href="https://www.youtube.com/watch?v=CB3vvw2sbF0" target="_blank">held a press conference</a>&nbsp;in San Diego to highlight the bill’s importance.&nbsp;</p>
<p>Deceptive price advertising&nbsp;is a significant problem facing consumers that appears to be proliferating in more and more sectors of the economy.&nbsp;Hidden&nbsp;required fees are&nbsp;now charged for a variety of goods and services, such as lodging, tickets for live events, and&nbsp;restaurants and food delivery.&nbsp;These fees, when mandatory, are&nbsp;a deceptive way of hiding the true price of a good or service.&nbsp;</p>
<p>The text of the legislation is available&nbsp;<a href="https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=202320240SB478" target="_blank">here</a>.&nbsp;</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Impacts of Lack of Sleep (133 pts)]]></title>
            <link>https://belkarx.github.io/posts/finished/Impacts%20Of%20Lack%20Of%20Sleep.html</link>
            <guid>37815945</guid>
            <pubDate>Mon, 09 Oct 2023 01:20:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://belkarx.github.io/posts/finished/Impacts%20Of%20Lack%20Of%20Sleep.html">https://belkarx.github.io/posts/finished/Impacts%20Of%20Lack%20Of%20Sleep.html</a>, See on <a href="https://news.ycombinator.com/item?id=37815945">Hacker News</a></p>
<div id="readability-page-1" class="page"><header><p><a href="https://belkarx.github.io/index.html">home/about-me</a> | <a href="https://belkarx.github.io/posts/posts_main.html">posts</a></p></header>


<h6 id="rather-bluntly-listed-for-those-that-need-to-hear-them--">- rather bluntly listed for those that need to hear them -</h6>
<p>Sleep is important. People vastly underestimate the extent to which not sleeping is harmful, viewing it as a valid trade off for productivity and overlooking all of the longterm negative effects.</p>
<h2 id="said-effects-being">Said Effects Being</h2>
<ul>
<li>Metabolism slows down, appetite goes up</li>
<li>Depression, anxiety, irritability, distress</li>
<li>Increased risk of diabetes</li>
<li>More substance abuse/addiction (alcohol and caffiene, specifically) [ironically both depressants and stimulents]</li>
<li>Lower life expectancy</li>
<li>Lower cognitive performance (specifically in reasoning/logic)</li>
<li>Long and short term memory issues</li>
<li>Increased (+33%) risk of dementia which is something you should be terrified of</li>
<li>Fatigued and demotivated</li>
<li>Lower libido</li>
</ul>
<h2 id="impact-of-those-being">Impact of Those Being</h2>
<ul>
<li>You get fat</li>
<li>You might enter a state where consumption of sugar has to be stringently regulated and have to do annoying blood checks which is expensive if you’re in country with a questionable private healthcare system</li>
<li>No one likes talking to you or being around you in general because you become asshole-ish and/or a loner</li>
<li>You have to deal with expensive and unhealthy addictions</li>
<li>More likely to die early!</li>
<li>more stupid - can’t unlock your full intelligence and cognitive prowess, so you’re stifling potential</li>
<li>Memory also worsens, see above</li>
<li>Ooh that decreased cognitive state has a higher chance of being permanent and getting much much worse, making your life miserable</li>
<li>You lose all ambition so start following others. you also feel dead inside all the time and just want to sleeeep</li>
<li>to top it all off</li>
<li>can’t sexually pleasure your parter to their level of desire, leading to strained relations (even more strained, since the aforementioned negative effects on personality likely contribute as well) so they are less useful in helping you deal with all of the above issues.</li>
</ul>
<p>Discussion on Hacker News <a href="https://news.ycombinator.com/item?id=30184796">here</a></p>
<h4 id="sources">Sources</h4>
<ul>
<li><a href="https://healthysleep.med.harvard.edu/healthy/matters/consequences/sleep-performance-and-public-safety">harvard study[p1]</a></li>
<li><a href="https://healthysleep.med.harvard.edu/healthy/matters/consequences/sleep-and-disease-risk">harvard[p2]</a></li>
<li><a href="https://www.nichd.nih.gov/health/topics/sleep/conditioninfo/inadequate-sleep">nih</a></li>
<li><a href="https://onlinelibrary.wiley.com/doi/full/10.1111/jsm.12858">journal of medical health</a></li>
</ul>
</div>]]></description>
        </item>
        <item>
            <title><![CDATA[My personal C coding style as of late 2023 (228 pts)]]></title>
            <link>https://nullprogram.com/blog/2023/10/08/</link>
            <guid>37815674</guid>
            <pubDate>Mon, 09 Oct 2023 00:30:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nullprogram.com/blog/2023/10/08/">https://nullprogram.com/blog/2023/10/08/</a>, See on <a href="https://news.ycombinator.com/item?id=37815674">Hacker News</a></p>
<div id="readability-page-1" class="page"><div lang="en">
<article>
  
  <time datetime="2023-10-08">
    October 08, 2023
  </time>
  <p>
    nullprogram.com/blog/2023/10/08/
  </p>

  <p>This has been a ground-breaking year for my C skills, and paradigm shifts
in my technique has provoked me to reconsider my habits and coding style.
It’s been my largest personal style change in years, so I’ve decided to
take a snapshot of its current state and my reasoning. These changes have
produced significant productive and organizational benefits, so while most
is certainly subjective, it likely includes a few objective improvements.
I’m not saying everyone should write C this way, and when I contribute
code to a project I follow their local style. This is about what works
well for me.</p>

<h3 id="primitive-types">Primitive types</h3>

<p>Starting with the fundamentals, I’ve been using short names for primitive
types. The resulting clarity was more than I had expected, and it’s made
my code more enjoyable to review. These names appear frequently throughout
a program, so conciseness pays. Also, now that I’ve gone without, <code>_t</code>
suffixes are more visually distracting than I had realized.</p>

<div><pre><code><span>typedef</span> <span>uint8_t</span>   <span>u8</span><span>;</span>
<span>typedef</span> <span>char16_t</span>  <span>c16</span><span>;</span>
<span>typedef</span> <span>int32_t</span>   <span>b32</span><span>;</span>
<span>typedef</span> <span>int32_t</span>   <span>i32</span><span>;</span>
<span>typedef</span> <span>uint32_t</span>  <span>u32</span><span>;</span>
<span>typedef</span> <span>uint64_t</span>  <span>u64</span><span>;</span>
<span>typedef</span> <span>float</span>     <span>f32</span><span>;</span>
<span>typedef</span> <span>double</span>    <span>f64</span><span>;</span>
<span>typedef</span> <span>uintptr_t</span> <span>uptr</span><span>;</span>
<span>typedef</span> <span>char</span>      <span>byte</span><span>;</span>
<span>typedef</span> <span>ptrdiff_t</span> <span>size</span><span>;</span>
<span>typedef</span> <span>size_t</span>    <span>usize</span><span>;</span>
</code></pre></div>

<p>Some people prefer an <code>s</code> prefix for signed types. I prefer <code>i</code>, plus as
you’ll see, I have other designs for <code>s</code>. For sizes, <code>isize</code> would be more
consistent, and wouldn’t hog the identifier, but <a href="https://nullprogram.com/blog/2023/09/27/">signed sizes are the
way</a> and so I want them in a place of privilege. <code>usize</code> is niche,
mainly for interacting with external interfaces where it might matter.</p>

<p><code>b32</code> is a “32-bit boolean” and communicates intent. I could use <code>_Bool</code>,
but I’d rather stick to a natural word size and stay away from its weird
semantics. To beginners it might seem like “wasting memory” by using a
32-bit boolean, but in practice that’s never the case. It’s either in a
register (return value, local variable) or would be padded anyway (struct
field). When it actually matters, I pack booleans into a <code>flags</code> variable,
and a 1-byte boolean rarely important.</p>

<p>While UTF-16 might seem niche, it’s a necessary evil when dealing with
Win32, so <code>c16</code> (“16-bit character”) has made a frequent appearance. I
could have based it on <code>uint16_t</code>, but putting the name <code>char16_t</code> in its
“type hierarchy” communicates to debuggers, particularly GDB, that for
display purposes these variables hold character data. Officially Win32
uses a type named <code>wchar_t</code>, but I like being explicit about UTF-16.</p>

<p><code>u8</code> is for octets, usually UTF-8 data. It’s distinct from <code>byte</code>, which
represents raw memory and is a special <em>aliasing</em> type. In theory these
can be distinct types with differing semantics, though I’m not aware of
any implementation that does so (yet?). For now it’s about intent.</p>

<p>What about systems that don’t support fixed width types? That’s academic,
and far too much time has been wasted worrying about it. That includes
time wasted on typing out <code>int_fast32_t</code> and similar nonsense. Virtually
no existing software would actually work correctly on such systems — I’m
certain nobody’s <em>testing</em> it after all — so it seems nobody else cares
either.</p>

<p>I don’t intend to use these names in isolation, such as in code snippets
(outside of this article). If I did, examples would require the <code>typedefs</code>
to give readers the complete context. That’s not worth extra explanation.
Even in the most recent articles I’ve used <code>ptrdiff_t</code> instead of <code>size</code>.</p>

<h3 id="macros">Macros</h3>

<p>Next, my “standard” set of macros:</p>

<div><pre><code><span>#define sizeof(x)    (size)sizeof(x)
#define alignof(x)   (size)_Alignof(x)
#define countof(a)   (sizeof(a) / sizeof(*(a)))
#define lengthof(s)  (countof(s) - 1)
</span></code></pre></div>

<p>While I still prefer <code>ALL_CAPS</code> for constants, I’ve adopted lowercase for
function-like macros because it’s nicer to read. They don’t have the same
namespace problems as other macro definitions: I can have a macro named
<code>new()</code> and also variables and fields named <code>new</code> because they don’t look
like function calls.</p>

<p>For GCC and Clang, my favorite <code>assert</code> macro now looks like this:</p>

<div><pre><code><span>#define assert(c)  while (!(c)) __builtin_unreachable()
</span></code></pre></div>

<p>It has useful properties beyond <a href="https://nullprogram.com/blog/2022/06/26/">the usual benefits</a>:</p>

<ul>
  <li>
    <p>It does not require separate definitions for debug and release builds.
Instead it’s controlled by the presence of Undefined Behavior Sanitizer
(UBSan), which is already present/absent in these circumstances. That
includes <a href="https://nullprogram.com/blog/2019/01/25/">fuzz testing</a>.</p>
  </li>
  <li>
    <p><code>libubsan</code> provides a diagnostic printout with a file and line number.</p>
  </li>
  <li>
    <p>In release builds it turns into a practical optimization hint.</p>
  </li>
</ul>

<p>To enable assertions in release builds, put UBSan in trap mode with
<code>-fsanitize-trap</code> and then enable at least <code>-fsanitize=unreachable</code>. In
theory this can also be done with <code>-funreachable-traps</code>, but as of this
writing it’s been broken for the past few GCC releases.</p>

<h3 id="parameters-and-functions">Parameters and functions</h3>

<p>No <code>const</code>. It serves no practical role in optimization, and <strong>I cannot
recall an instance where it caught, or would have caught, a mistake</strong>. I
held out for awhile as prototype documentation, but on reflection I found
that good parameter names were sufficient. Dropping <code>const</code> has made me
noticeably more productive by reducing cognitive load and eliminating
visual clutter. I now believe its inclusion in C was a costly mistake.</p>

<p>(One small exception: I still like it as a hint to place static tables in
read-only memory closer to the code. I’ll cast away the <code>const</code> if needed.
This is only of minor importance.)</p>

<p>Literal <code>0</code> for null pointers. Short and sweet. This is not new, but a
style I’ve used for about 7 years now, and has appeared all over my
writing since. There are some theoretical edge cases where it may cause
defects, and lots of <a href="https://ljabl.com/nullptr.xhtml">ink has been spilled</a> on the subject, but
after a couple 100K lines of code I’ve yet to see it happen.</p>

<p><code>restrict</code> when necessary, but better to organize code so that it’s not,
e.g. don’t write to “out” parameters in loops, or don’t use out parameters
at all (more on that momentarily). I don’t bother with <code>inline</code> because I
compile everything as one translation unit anyway.</p>

<p><code>typedef</code> all structures. I used to shy away from it, but eliminating the
<code>struct</code> keyword makes code easier to read. If it’s a recursive structure,
use a forward declaration immediately above so that such fields can use
the short name:</p>

<div><pre><code><span>typedef</span> <span>struct</span> <span>map</span> <span>map</span><span>;</span>
<span>struct</span> <span>map</span> <span>{</span>
    <span>map</span> <span>*</span><span>child</span><span>[</span><span>4</span><span>];</span>
    <span>// ...</span>
<span>};</span>
</code></pre></div>

<p>Declare all functions <code>static</code> except for entry points. Again, with
everything compiled as a single translation unit there’s no reason to do
otherwise. It was probably a mistake for C not to default to <code>static</code>,
though I don’t have a strong opinion on the matter. With the clutter
eliminated through short types, no <code>const</code>, no <code>struct</code>, etc. <strong>functions
fit comfortably on the same line as their return type</strong>. I used to break
them apart so that the function name began on its own line, but that’s no
longer necessary.</p>

<p>In my writing I sometimes omit <code>static</code> to simplify, and because outside
the context of a complete program it’s mostly irrelevant. However, I will
use it below to emphasize this style.</p>

<p>For awhile I capitalized type names as that effectively put them in a kind
of namespace apart from variables and functions, but I eventually stopped.
I may try this idea in different way in the future.</p>

<h3 id="strings">Strings</h3>

<p>One of my most productive changes this year has been the total rejection
of null terminated strings — another of those terrible mistakes — and the
embrace of <a href="https://nullprogram.com/blog/2023/01/18/#implementation-highlights">this basic string type</a>:</p>

<div><pre><code><span>#define s8(s) (s8){(u8 *)s, lengthof(s)}
</span><span>typedef</span> <span>struct</span> <span>{</span>
    <span>u8</span>  <span>*</span><span>data</span><span>;</span>
    <span>size</span> <span>len</span><span>;</span>
<span>}</span> <span>s8</span><span>;</span>
</code></pre></div>

<p>I’ve used a few names for it, but this is my favorite. The <code>s</code> is for
string, and the <code>8</code> is for UTF-8 or <code>u8</code>. The <code>s8</code> macro (sometimes just
spelled <code>S</code>) wraps a C string literal, making a <code>s8</code> string out of it. A
<code>s8</code> is handled like a <a href="https://nullprogram.com/blog/2019/06/30/">fat pointer</a>, passed and returned by copy.
<code>s8</code> makes for a great function prefix, unlike <code>str</code>, all of which are
reserved. Some examples:</p>

<div><pre><code><span>static</span> <span>s8</span>   <span>s8span</span><span>(</span><span>u8</span> <span>*</span><span>,</span> <span>u8</span> <span>*</span><span>);</span>
<span>static</span> <span>b32</span>  <span>s8equals</span><span>(</span><span>s8</span><span>,</span> <span>s8</span><span>);</span>
<span>static</span> <span>size</span> <span>s8compare</span><span>(</span><span>s8</span><span>,</span> <span>s8</span><span>);</span>
<span>static</span> <span>u64</span>  <span>s8hash</span><span>(</span><span>s8</span><span>);</span>
<span>static</span> <span>s8</span>   <span>s8trim</span><span>(</span><span>s8</span><span>);</span>
<span>static</span> <span>s8</span>   <span>s8clone</span><span>(</span><span>s8</span><span>,</span> <span>arena</span> <span>*</span><span>);</span>
</code></pre></div>

<p>Then when combined with the macro:</p>

<div><pre><code>    <span>if</span> <span>(</span><span>s8equals</span><span>(</span><span>tagname</span><span>,</span> <span>s8</span><span>(</span><span>"body"</span><span>)))</span> <span>{</span>
        <span>// ...</span>
    <span>}</span>
</code></pre></div>

<p>You might be tempted to use a flexible array member to pack the size and
array together as one allocation. Tried it. Its inflexibility is totally
not worth whatever benefits it might have. Consider, for instance, how
you’d create such a string out of a literal, and how it would be used.</p>

<p>A few times I’ve thought, “This program is simple enough that I don’t need
a string type for this data.” That thought is nearly always wrong. Having
it available helps me think more clearly, and makes for simpler programs.
(C++ got it only a few years ago with <code>std::string_view</code> and <code>std::span</code>.)</p>

<p>It has a natural UTF-16 counterpart, <code>s16</code>:</p>

<div><pre><code><span>#define s16(s) (s16){u##s, lengthof(u##s)}
</span><span>typedef</span> <span>struct</span> <span>{</span>
    <span>c16</span> <span>*</span><span>data</span><span>;</span>
    <span>size</span> <span>len</span><span>;</span>
<span>}</span> <span>s16</span><span>;</span>
</code></pre></div>

<p>I’m not entirely sold on gluing <code>u</code> to the literal in the macro, versus
writing it out on the string literal.</p>

<h3 id="more-structures">More structures</h3>

<p>Another change has been preferring structure returns instead of out
parameters. It’s effectively a multiple value return, though without
destructuring. A great organizational change. For example, this function
returns two values, a parse result and a status:</p>

<div><pre><code><span>typedef</span> <span>struct</span> <span>{</span>
    <span>i32</span> <span>value</span><span>;</span>
    <span>b32</span> <span>ok</span><span>;</span>
<span>}</span> <span>i32parsed</span><span>;</span>

<span>static</span> <span>i32parsed</span> <span>i32parse</span><span>(</span><span>s8</span><span>);</span>
</code></pre></div>

<p>Worried about the “extra copying?” Have no fear, because in practice
calling conventions turn this into a hidden, <code>restrict</code>-qualified out
parameter — if it’s not inlined such that any return value overhead would
be irrelevant anyway. With this return style I’m less tempted to use
in-band signals like special null returns to indicate errors, which is
less clear.</p>

<p>It’s also led to a style of defining a zero-initialized return value at
the top of the function, i.e. <code>ok</code> is false, and then use it for all
<code>return</code> statements. On error, it can bail out with an immediate return.
The success path sets <code>ok</code> to true before the return.</p>

<div><pre><code><span>static</span> <span>i32parsed</span> <span>i32parse</span><span>(</span><span>s8</span> <span>s</span><span>)</span>
<span>{</span>
    <span>i32parsed</span> <span>r</span> <span>=</span> <span>{</span><span>0</span><span>};</span>
    <span>for</span> <span>(</span><span>size</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>s</span><span>.</span><span>len</span><span>;</span> <span>i</span><span>++</span><span>)</span> <span>{</span>
        <span>u8</span> <span>digit</span> <span>=</span> <span>s</span><span>.</span><span>data</span><span>[</span><span>i</span><span>]</span> <span>-</span> <span>'0'</span><span>;</span>
        <span>// ...</span>
        <span>if</span> <span>(</span><span>overflow</span><span>)</span> <span>{</span>
            <span>return</span> <span>r</span><span>;</span>
        <span>}</span>
        <span>r</span><span>.</span><span>value</span> <span>=</span> <span>r</span><span>.</span><span>value</span><span>*</span><span>10</span> <span>+</span> <span>digit</span><span>;</span>
    <span>}</span>
    <span>r</span><span>.</span><span>ok</span> <span>=</span> <span>1</span><span>;</span>
    <span>return</span> <span>r</span><span>;</span>
<span>}</span>
</code></pre></div>

<p>Aside from static data, I’ve also moved away from initializers except the
conventional zero initializer. (Notable exception: <code>s8</code> and <code>s16</code> macros.)
This includes designated initializers. Instead I’ve been initializing with
assignments. For example, this <a href="https://nullprogram.com/blog/2023/02/13/">buffered output</a> “constructor”:</p>

<div><pre><code><span>typedef</span> <span>struct</span> <span>{</span>
    <span>u8</span> <span>*</span><span>buf</span><span>;</span>
    <span>i32</span> <span>len</span><span>;</span>
    <span>i32</span> <span>cap</span><span>;</span>
    <span>i32</span> <span>fd</span><span>;</span>
    <span>b32</span> <span>err</span><span>;</span>
<span>}</span> <span>u8buf</span><span>;</span>

<span>static</span> <span>u8buf</span> <span>newu8buf</span><span>(</span><span>arena</span> <span>*</span><span>perm</span><span>,</span> <span>i32</span> <span>cap</span><span>,</span> <span>i32</span> <span>fd</span><span>)</span>
<span>{</span>
    <span>u8buf</span> <span>r</span> <span>=</span> <span>{</span><span>0</span><span>};</span>
    <span>r</span><span>.</span><span>buf</span> <span>=</span> <span>new</span><span>(</span><span>perm</span><span>,</span> <span>u8</span><span>,</span> <span>cap</span><span>);</span>
    <span>r</span><span>.</span><span>cap</span> <span>=</span> <span>cap</span><span>;</span>
    <span>r</span><span>.</span><span>fd</span>  <span>=</span> <span>fd</span><span>;</span>
    <span>return</span> <span>r</span><span>;</span>
<span>}</span>
</code></pre></div>

<p>I like how this reads, but it also eliminates a cognitive burden: The
assignments are separated by sequence points, giving them an explicit
order. It doesn’t matter here, but in other cases it does:</p>

<div><pre><code>    <span>example</span> <span>e</span> <span>=</span> <span>{</span>
        <span>.</span><span>name</span> <span>=</span> <span>randname</span><span>(</span><span>&amp;</span><span>rng</span><span>),</span>
        <span>.</span><span>age</span>  <span>=</span> <span>randage</span><span>(</span><span>&amp;</span><span>rng</span><span>),</span>
        <span>.</span><span>seat</span> <span>=</span> <span>randseat</span><span>(</span><span>&amp;</span><span>rng</span><span>),</span>
    <span>};</span>
</code></pre></div>

<p>There are 6 possible values for <code>e</code> from the same seed. I like no longer
thinking about these possibilities.</p>

<h3 id="odds-and-ends">Odds and ends</h3>

<p>Prefer <code>__attribute</code> to <code>__attribute__</code>. The <code>__</code> suffix is excessive and
unnecessary.</p>

<div><pre><code><span>__attribute</span><span>((</span><span>malloc</span><span>,</span> <span>alloc_size</span><span>(</span><span>2</span><span>,</span> <span>4</span><span>)))</span>
</code></pre></div>

<p>For Win32 systems programming, which typically only requires a modest
number of declarations and definitions, rather than include <code>windows.h</code>,
<a href="https://nullprogram.com/blog/2023/05/31/">write the prototypes out by hand</a> using custom types. It reduces
build times, declutters namespaces, and interfaces more cleanly with the
program (no more <code>DWORD</code>/<code>BOOL</code>/<code>ULONG_PTR</code>, but <code>u32</code>/<code>b32</code>/<code>uptr</code>).</p>

<div><pre><code><span>#define W32(r) __declspec(dllimport) r __stdcall
</span><span>W32</span><span>(</span><span>void</span><span>)</span>   <span>ExitProcess</span><span>(</span><span>u32</span><span>);</span>
<span>W32</span><span>(</span><span>i32</span><span>)</span>    <span>GetStdHandle</span><span>(</span><span>u32</span><span>);</span>
<span>W32</span><span>(</span><span>byte</span> <span>*</span><span>)</span> <span>VirtualAlloc</span><span>(</span><span>byte</span> <span>*</span><span>,</span> <span>usize</span><span>,</span> <span>u32</span><span>,</span> <span>u32</span><span>);</span>
<span>W32</span><span>(</span><span>b32</span><span>)</span>    <span>WriteConsoleA</span><span>(</span><span>uptr</span><span>,</span> <span>u8</span> <span>*</span><span>,</span> <span>u32</span><span>,</span> <span>u32</span> <span>*</span><span>,</span> <span>void</span> <span>*</span><span>);</span>
<span>W32</span><span>(</span><span>b32</span><span>)</span>    <span>WriteConsoleW</span><span>(</span><span>uptr</span><span>,</span> <span>c16</span> <span>*</span><span>,</span> <span>u32</span><span>,</span> <span>u32</span> <span>*</span><span>,</span> <span>void</span> <span>*</span><span>);</span>
</code></pre></div>

<p>For inline assembly, treat the outer parentheses like braces, put a space
before the opening parenthesis, just like <code>if</code>, and start each constraint
line with its colon.</p>

<div><pre><code><span>static</span> <span>u64</span> <span>rdtscp</span><span>(</span><span>void</span><span>)</span>
<span>{</span>
    <span>u32</span> <span>hi</span><span>,</span> <span>lo</span><span>;</span>
    <span>asm</span> <span>volatile</span> <span>(</span>
        <span>"rdtscp"</span>
        <span>:</span> <span>"=d"</span><span>(</span><span>hi</span><span>),</span> <span>"=a"</span><span>(</span><span>lo</span><span>)</span>
        <span>:</span>
        <span>:</span> <span>"cx"</span><span>,</span> <span>"memory"</span>
    <span>);</span>
    <span>return</span> <span>(</span><span>u64</span><span>)</span><span>hi</span><span>&lt;&lt;</span><span>32</span> <span>|</span> <span>lo</span><span>;</span>
<span>}</span>
</code></pre></div>

<p>There’s surely a lot more to my style than this, but unlike the above,
those details haven’t changed this year. To see most of the mentioned
items in action in a small program, see <a href="https://github.com/skeeto/scratch/blob/master/misc/wordhist.c"><code>wordhist.c</code></a>, one of my
testing grounds for <a href="https://nullprogram.com/blog/2023/09/30/">hash-tries</a>, or for a slightly larger program,
<a href="https://github.com/skeeto/scratch/blob/master/misc/asmint.c"><code>asmint.c</code></a>, a mini programming language implementation.</p>



  
  <ol></ol>

  

  <nav>
  
    
  
  
  </nav>
</article>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Forty years of programming (200 pts)]]></title>
            <link>https://fabiensanglard.net/40/index.html</link>
            <guid>37814748</guid>
            <pubDate>Sun, 08 Oct 2023 21:55:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fabiensanglard.net/40/index.html">https://fabiensanglard.net/40/index.html</a>, See on <a href="https://news.ycombinator.com/item?id=37814748">Hacker News</a></p>
<div id="readability-page-1" class="page"><br><center>
    
</center><p>
Oct 8, 2023</p>
<p>Forty years of programming</p><hr>


<p>I am about to turn forty-six. This means I have been programming for forty years, half of them professionally. During most of that time, I used a "standard" setup with 104 keyboard, a flat mouse, and a sitting desk.</p>

<img loading="lazy" src="https://fabiensanglard.net/40/macpro.webp" width="1932" height="1152"><span><i><small>My home workstation circa 2011 (porting Doom III to mac)</small></i></span>
 
<p>Things evolved ten years ago when I started to experience pain in my forearms and shoulders when I programmed. Here is what I did to solve my problem, it may work for someone else.</p>


<p>Mouse</p><hr>
<p>
Using a vertical mouse improved things a lot. My favorite is the Evoluent VerticalMouse 4.
</p>

<img loading="lazy" src="https://fabiensanglard.net/40/vertical_mouse.webp" width="2650" height="1665"><span><i><small>My work workstation circa 2015</small></i></span>

<p>Eventually, I opted for the Magic Trackpad from Apple. It is great to switch workspace with three fingers, zoom, and more. Having it in the center allows me to use it alternatively with my left and right hand.</p>

<img loading="lazy" src="https://fabiensanglard.net/40/magic.webp" width="2955" height="1368"><span><i><small>My home workstation circa 2015</small></i></span>

<p> It used to be annoying to get the drivers for Linux/Windows but now it is all sorted out.</p>

<p>Keyboard</p><hr><p>The first ergonomic keyboard I tried was the <a href="https://kinesis-ergo.com/shop/freestyle2-for-pc-us/">KINESIS Freestyle2</a>. It allowed me to spread each half as needed, resulting in horizontally straight wrist . However, the standard <code>Control</code>, <code>Shift</code>, and <code>Alt</code> still required wrist gymnastics. Same thing for <code>Esc</code> (I talk about VIM later) which required a left wrist twist. Also the tenting angle was too low.</p>

<p>I tried the <a href="https://kinesis-ergo.com/shop/advantage2/">KINESIS Advantage2</a>. I liked the concept of having so many thumb options. But the fixed width was a step backward compared to the KINESIS Freestyle2.</p>

<p>The keyboard which has it all for me is the  <a href="https://ergodox-ez.com/">Ergodox EZ</a>. It can be as wide or narrow as I need. And the custom firmware is a highly customizable gem. Among many features, it can switch all keys into a different layer with a single keystroke. The silver bullet for me is the ability to have a key function change if you keep it pressed.</p>

<p> If you look at <a href="https://configure.zsa.io/ergodox-ez/layouts/9qw4W/latest/0">my layout</a> you can see how capitalization (<code>Shift</code>) can be done by maintaining pressed either <code>D</code> or <code>K</code>.  All my symbols <code>{</code>, <code>[</code>, <code>(</code>, ... are on another layer available from a single key maintained pressed.</p> 


<img loading="lazy" src="https://fabiensanglard.net/40/ergodox_ez.webp" width="2622" height="1569"><span><i><small>My work keyboard in 2023</small></i></span>

<p>With the Ergodox EZ, my wrists never move. They are always in a rest position, on all three axes. Zero pain and I can program all day.</p>


<p>Additionally, the Ergodox accepts hardware tuning, like <a href="https://drop.com/buy/carbon">DROP Carbon keycaps</a>, custom cables by <a href="https://www.pexonpcs.co.uk/">pexonpcs.co.uk</a>, and <a href="https://www.keychron.com/products/gateron-switch-set">Brown Gateron G Pro.</a></p>


<blockquote><b>Trivia:</b> As a fan of IBM's Model M clicky keyboard, I tried to build my first Ergo using Cherry MX Blue. That was fine for home but made some coworkers upset. I recommend going for Cherry MX Red which are the most silent, or the Cherry MX Brown which are a good middle ground between Blue and Red.</blockquote>


<p>VIM</p><hr><img loading="lazy" src="https://fabiensanglard.net/40/vim.svg" width="544.16998" height="544.8642"><p>As you will have guessed my goal is to move my hands and twist my wrists as little as possible. That would be a problem to navigate a program since most IDEs require clicking via the mouse. Thankfully, most editors have a VIM mode which allows you to move across a file, goto definition, go back, all that without using the mouse.</p>


<p>Desk</p><hr><p>Standing up improves my posture. I don't slouch when I stand. So I built a motorized standing desk with <a href="https://amzn.to/48xIGKc">Topsky legs</a> and a Home Depot <a href="https://www.homedepot.com/p/Hampton-Bay-4-ft-L-x-25-in-D-Unfinished-Birch-Butcher-Block-Countertop-in-With-Standard-Edge-birch-4ft-x-25in/319222041">butcher counter top</a>.</p>



<img loading="lazy" src="https://fabiensanglard.net/40/desk.webp" width="2640" height="1988"><span><i><small>My home desk, at the time used for amazing Diablo 2 Resurrected adventures</small></i></span>

<p>The three position memory allow to switch from standing to seating within a few seconds. And I try to alternate during the day.</p>



<p>Stretching</p><hr><p>I take a break every once in a while and do a bunch of Wall Angel.</p>

<p>Meditation in motion</p><hr><p>I manage my stress level by disconnecting from work when I leave it. Rock climbing works well for me. You can't think of anything else when you climb. It is a great way to turn off a brain that keeps on having great optimization ideas when it is not the time anymore.</p>

<img loading="lazy" src="https://fabiensanglard.net/40/scalade.webp" width="707" height="462"> <hr>
 <center>*</center></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Metals Fuse Together in Space (121 pts)]]></title>
            <link>https://www.spacecentre.nz/resources/facts/physics/metals-fuse.html</link>
            <guid>37814667</guid>
            <pubDate>Sun, 08 Oct 2023 21:42:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.spacecentre.nz/resources/facts/physics/metals-fuse.html">https://www.spacecentre.nz/resources/facts/physics/metals-fuse.html</a>, See on <a href="https://news.ycombinator.com/item?id=37814667">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">


<p>You may have heard that two pieces of similar metal will bond together if they touch each other in space. In theory this is correct, although in real life we wouldn't expect it to happen quite that easily.</p>
<p>If two pieces of similar metals touch in a vacuum, and if both pieces are perfectly flat and polished, they will indeed fuse to effectively make one new piece. Atoms in the metals share electrons and bond permanently. This is called <em>cold welding</em>.</p>
<p>The reason this doesn't happen in everyday life is that there is always some kind of barrier between the pure metals. In particular, most metals form an oxide layer on any surface that is exposed to air. This acts as a shield to prevent bonding.</p>
<p>In the vacuum of space, there is no air so metals wouldn't form the protective layer. In practice, however, any metals that astronauts use should still have their oxidation layer from when they were exposed to air. In addition, astronauts' tools are coated with plastic.</p>
<p>Although it's not a common problem in space, it has happened<sup>1</sup> and space engineers need to be aware of the issue<sup>2</sup>.</p>
<p>Note that there are numerous variations of cold welding. Some types of cold welding can be done on Earth without a vacuum. A particular type of alignment or friction may be required for the bonding to take place. </p>

<div>
<h4>Page information</h4>
<p>Author: <a href="https://www.spacecentre.nz/about/space-dave.html">Dave Owen</a></p>
</div>








</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: This is what social media could be (117 pts)]]></title>
            <link>https://bloom.tendtoyourgarden.xyz/</link>
            <guid>37814182</guid>
            <pubDate>Sun, 08 Oct 2023 20:34:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bloom.tendtoyourgarden.xyz/">https://bloom.tendtoyourgarden.xyz/</a>, See on <a href="https://news.ycombinator.com/item?id=37814182">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><nav><p><a href="https://bloom.tendtoyourgarden.xyz/"><img alt="Bloom Logo" draggable="false" loading="lazy" width="40" height="40" decoding="async" data-nimg="1" src="https://bloom.tendtoyourgarden.xyz/Bloom_Logo.svg"></a></p></nav><div><p><span>let conversation&nbsp;</span><span>bloom</span><img alt="Bloom Logo" loading="lazy" width="40" height="40" decoding="async" data-nimg="1" src="https://bloom.tendtoyourgarden.xyz/Bloom_Logo.svg"></p><p>community gardens that you tend to together.</p><a href="https://bloom.tendtoyourgarden.xyz/you">enter<!-- --> <span>BLOOM</span>-&gt;</a></div><div><div><p><img alt="Bloom Red Flower" loading="lazy" width="160" height="160" decoding="async" data-nimg="1" srcset="https://bloom.tendtoyourgarden.xyz/_next/image?url=%2FBloom_Desktop_Red_Flower_1_LARGE.png&amp;w=256&amp;q=75 1x, https://bloom.tendtoyourgarden.xyz/_next/image?url=%2FBloom_Desktop_Red_Flower_1_LARGE.png&amp;w=384&amp;q=75 2x" src="https://bloom.tendtoyourgarden.xyz/_next/image?url=%2FBloom_Desktop_Red_Flower_1_LARGE.png&amp;w=384&amp;q=75"></p><p>Share a thought with your community by planting a seed.</p></div><div><p>Others can water your seed by responding.</p><p><img alt="Bloom Red Flower" loading="lazy" width="160" height="160" decoding="async" data-nimg="1" srcset="https://bloom.tendtoyourgarden.xyz/_next/image?url=%2FBloom_Desktop_Red_Flower_2_LARGE.png&amp;w=256&amp;q=75 1x, https://bloom.tendtoyourgarden.xyz/_next/image?url=%2FBloom_Desktop_Red_Flower_2_LARGE.png&amp;w=384&amp;q=75 2x" src="https://bloom.tendtoyourgarden.xyz/_next/image?url=%2FBloom_Desktop_Red_Flower_2_LARGE.png&amp;w=384&amp;q=75"></p></div><div><p><img alt="Bloom Red Flower" loading="lazy" width="160" height="160" decoding="async" data-nimg="1" srcset="https://bloom.tendtoyourgarden.xyz/_next/image?url=%2FBloom_Desktop_Red_Flower_3_LARGE.png&amp;w=256&amp;q=75 1x, https://bloom.tendtoyourgarden.xyz/_next/image?url=%2FBloom_Desktop_Red_Flower_3_LARGE.png&amp;w=384&amp;q=75 2x" src="https://bloom.tendtoyourgarden.xyz/_next/image?url=%2FBloom_Desktop_Red_Flower_3_LARGE.png&amp;w=384&amp;q=75"></p><p>With every response your flower grows - or else it withers away.</p></div><div><p>Flowers bloom when people come together.</p><p><img alt="Bloom Red Flower" loading="lazy" width="160" height="160" decoding="async" data-nimg="1" srcset="https://bloom.tendtoyourgarden.xyz/_next/image?url=%2FBloom_Desktop_Red_Flower_4_LARGE.png&amp;w=256&amp;q=75 1x, https://bloom.tendtoyourgarden.xyz/_next/image?url=%2FBloom_Desktop_Red_Flower_4_LARGE.png&amp;w=384&amp;q=75 2x" src="https://bloom.tendtoyourgarden.xyz/_next/image?url=%2FBloom_Desktop_Red_Flower_4_LARGE.png&amp;w=384&amp;q=75"></p></div><div><p><img alt="Bloom Red Flower" loading="lazy" width="160" height="160" decoding="async" data-nimg="1" srcset="https://bloom.tendtoyourgarden.xyz/_next/image?url=%2FBloom_Desktop_Red_Flower_5_LARGE.png&amp;w=256&amp;q=75 1x, https://bloom.tendtoyourgarden.xyz/_next/image?url=%2FBloom_Desktop_Red_Flower_5_LARGE.png&amp;w=384&amp;q=75 2x" src="https://bloom.tendtoyourgarden.xyz/_next/image?url=%2FBloom_Desktop_Red_Flower_5_LARGE.png&amp;w=384&amp;q=75"></p><p>Tend to your community garden by sharing and caring.</p></div></div><div><div><p><img alt="Bloom Red Flower" loading="lazy" width="160" height="160" decoding="async" data-nimg="1" srcset="https://bloom.tendtoyourgarden.xyz/_next/image?url=%2FBloom_Desktop_Red_Flower_1_LARGE.png&amp;w=256&amp;q=75 1x, https://bloom.tendtoyourgarden.xyz/_next/image?url=%2FBloom_Desktop_Red_Flower_1_LARGE.png&amp;w=384&amp;q=75 2x" src="https://bloom.tendtoyourgarden.xyz/_next/image?url=%2FBloom_Desktop_Red_Flower_1_LARGE.png&amp;w=384&amp;q=75"></p><p>Share a thought with your community by planting a seed.</p></div><div><p><img alt="Bloom Red Flower" loading="lazy" width="160" height="160" decoding="async" data-nimg="1" srcset="https://bloom.tendtoyourgarden.xyz/_next/image?url=%2FBloom_Desktop_Red_Flower_2_LARGE.png&amp;w=256&amp;q=75 1x, https://bloom.tendtoyourgarden.xyz/_next/image?url=%2FBloom_Desktop_Red_Flower_2_LARGE.png&amp;w=384&amp;q=75 2x" src="https://bloom.tendtoyourgarden.xyz/_next/image?url=%2FBloom_Desktop_Red_Flower_2_LARGE.png&amp;w=384&amp;q=75"></p><p>Others can water your seed by responding.</p></div><div><p><img alt="Bloom Red Flower" loading="lazy" width="160" height="160" decoding="async" data-nimg="1" srcset="https://bloom.tendtoyourgarden.xyz/_next/image?url=%2FBloom_Desktop_Red_Flower_3_LARGE.png&amp;w=256&amp;q=75 1x, https://bloom.tendtoyourgarden.xyz/_next/image?url=%2FBloom_Desktop_Red_Flower_3_LARGE.png&amp;w=384&amp;q=75 2x" src="https://bloom.tendtoyourgarden.xyz/_next/image?url=%2FBloom_Desktop_Red_Flower_3_LARGE.png&amp;w=384&amp;q=75"></p><p>With every response your flower grows - or else it withers away.</p></div><div><p><img alt="Bloom Red Flower" loading="lazy" width="160" height="160" decoding="async" data-nimg="1" srcset="https://bloom.tendtoyourgarden.xyz/_next/image?url=%2FBloom_Desktop_Red_Flower_4_LARGE.png&amp;w=256&amp;q=75 1x, https://bloom.tendtoyourgarden.xyz/_next/image?url=%2FBloom_Desktop_Red_Flower_4_LARGE.png&amp;w=384&amp;q=75 2x" src="https://bloom.tendtoyourgarden.xyz/_next/image?url=%2FBloom_Desktop_Red_Flower_4_LARGE.png&amp;w=384&amp;q=75"></p><p>Flowers bloom when people come together.</p></div><div><p><img alt="Bloom Red Flower" loading="lazy" width="160" height="160" decoding="async" data-nimg="1" srcset="https://bloom.tendtoyourgarden.xyz/_next/image?url=%2FBloom_Desktop_Red_Flower_5_LARGE.png&amp;w=256&amp;q=75 1x, https://bloom.tendtoyourgarden.xyz/_next/image?url=%2FBloom_Desktop_Red_Flower_5_LARGE.png&amp;w=384&amp;q=75 2x" src="https://bloom.tendtoyourgarden.xyz/_next/image?url=%2FBloom_Desktop_Red_Flower_5_LARGE.png&amp;w=384&amp;q=75"></p><p>Tend to your community garden by sharing and caring.</p></div></div><div><p>It is their reimagining of social media; beyond bottomless feeds and chat archives.</p><p>A platform where communities may find beauty in lurking and meaning in contributing.</p><p>It is their hope that the world may find joy in tending to their gardens.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why I can no longer recommend a Mac to fellow blind computer users (297 pts)]]></title>
            <link>https://www.applevis.com/blog/we-deserve-better-apple-why-i-can-no-longer-recommend-mac-fellow-blind-computer-users</link>
            <guid>37813895</guid>
            <pubDate>Sun, 08 Oct 2023 19:59:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.applevis.com/blog/we-deserve-better-apple-why-i-can-no-longer-recommend-mac-fellow-blind-computer-users">https://www.applevis.com/blog/we-deserve-better-apple-why-i-can-no-longer-recommend-mac-fellow-blind-computer-users</a>, See on <a href="https://news.ycombinator.com/item?id=37813895">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
      

<article data-history-node-id="35728">
  <header>
    
          
          </header>
  <div>
        
            <div><p>As many of you will know from personal experience, there is a longstanding issue with VoiceOver on Mac where Safari will frequently become unresponsive with VoiceOver repeatedly announcing the message “Safari not responding.” When this issue occurs, the user's Mac may become unusable for up to several minutes at a time. Sometimes it can be resolved by switching away from Safari. Sometimes restarting VoiceOver can resolve the issue. However, far too often, the user is unable to switch away from Safari or turn VoiceOver off, instead having to simply wait for their Mac to become responsive again.</p>

<p>This “Safari not responding” behaviour when using VoiceOver dramatically impacts productivity and overall usability of Macs for blind and low vision users. Furthermore, it appears that the issue extends beyond just Safari - many other common applications that utilise Apple's WebKit browser engine can also be affected by the “not responding” problem.</p>

<p>It is also important to point out this issue occurs regardless of the specification level of the Mac - it has been widely experienced on the latest Apple silicon-equipped Macs with 16GB or more of RAM, so even owners of top-tier new Mac hardware still face this crippling VoiceOver bug.</p>

<p>This critical problem has persisted for years across multiple MacOS versions without a permanent fix from Apple. Given the longevity and level of disruption caused by this bug across Safari and other applications, I can unfortunately no longer in good faith recommend Macs to anyone who relies on using VoiceOver. The impact of this bug when performing routine, and often critical, tasks in Safari and other applications simply makes macOS an unreliable and frustrating platform.</p>

<p>Macs have traditionally been popular within the blind community, and they offer some great accessibility features. However, frankly, Apple should be utterly ashamed that they have let this issue persist for so long without a permanent fix. It's a failing that raises serious questions about the company's frequently stated commitment to accessibility. There can be no doubt that if sighted users were to experience something similar, that it would receive significant media coverage and that Apple's response would be fast.</p>

<p>I want to note that I am sympathetic to the difficulties Apple's engineering team likely faces in resolving this issue. Based on user reports, there appears to be no consistent way to reproduce the “Safari not responding” behaviour - it can occur randomly and sporadically. The same web page may work fine multiple times before suddenly triggering a freeze. There are also inconsistencies across different users, machines, and configurations. I imagine these factors make it very challenging to isolate and fix the underlying problem. However, given the engineering talent and resources available to Apple, the challenge should not be insurmountable.</p>

<p>I believe we need to escalate out urging of Apple to prioritise and permanently solve the “Safari not responding” bug that has plagued VoiceOver users for far too long. To this end, I encourage those of you who use VoiceOver on Mac to directly contact Apple's accessibility team at <a href="mailto:accessibility@apple.com">accessibility@apple.com</a> to share your own personal experiences with and frustrations about the “Safari not responding” issue. It is important we continue putting direct, polite pressure on Apple to prioritise resolving this problem. Please be constructive in expressing your concerns. Consider also copying Apple CEO Tim Cook on your email by using his publicly shared email address <a href="mailto:tcook@apple.com">tcook@apple.com</a> to ensure he sees the direct impact this ongoing bug is having on Apple's blind and low vision customers.</p>

<p>I want to emphasise that the “Safari not responding” bug is far from the only issue effecting VoiceOver users on Mac. As <a href="https://www.applevis.com/blog/macos-sonoma-new-features-changes-improvements-bugs-blind-low-vision-users">our recent post on problems in macOS Sonoma and the replies outline,</a> there are numerous other VoiceOver frustrations and failures impacting users. However, it has become a yardstick by which Apple's overall performance on and commitment to accessibility is being judged. It is a yardstick against which Apple has failed for some considerable time.</p>

<p>I know many of you share my frustration. I welcome your perspectives and discussion in the comments. Collectively, we need to apply consumer pressure by being vocal about this issue and not purchasing new Macs until the “Safari not responding” issue is fixed once and for all. Apple simply must do better and restore our trust that Macs provide a stable and fully accessible experience for its blind and low vision customers.</p></div>
      
  <div>
    <h3>Tags</h3>
          
      </div>




<section data-drupal-selector="comments">

      
    
    
  
  
<article data-comment-user-id="30010" id="comment-155583" role="article" data-drupal-selector="comment">
     <p>
               
        <h3><a href="https://www.applevis.com/comment/155583#comment-155583" rel="bookmark" hreflang="en">My opinion</a></h3>
        
          </p>
  <span data-comment-timestamp="1696794983"></span>

  <div>
      
            <p>The only matter I had the supplier not responded she is on the MacBook Pro 2012. I’ve also had it happen either 2017 MacBook Air, but not with my Apple Silicon MacBook Air. The only reason I use my Mac is for music creation and even Matts becoming a hassle</p>
      
    </div>
</article>

<article data-comment-user-id="1178" id="comment-155584" role="article" data-drupal-selector="comment">
     <p>
               
        <h3><a href="https://www.applevis.com/comment/155584#comment-155584" rel="bookmark" hreflang="en">Shared to HackerNews</a></h3>
        
          </p>
  <span data-comment-timestamp="1696796293"></span>

  
</article>

<article data-comment-user-id="23639" id="comment-155585" role="article" data-drupal-selector="comment">
     <p>
               
        <h3><a href="https://www.applevis.com/comment/155585#comment-155585" rel="bookmark" hreflang="en">I agree.</a></h3>
        
          </p>
  <span data-comment-timestamp="1696797839"></span>

  <div><p>I've been a windows user for most of my life and don't plan on switching to a mac at all.</p>
<p>I tried it once, never again.</p>
</div>
</article>

<article data-comment-user-id="26568" id="comment-155587" role="article" data-drupal-selector="comment">
     <p>
               
        <h3><a href="https://www.applevis.com/comment/155587#comment-155587" rel="bookmark" hreflang="en">This major problum is just not ok</a></h3>
        
          </p>
  <span data-comment-timestamp="1696798322"></span>

  <div>
      
            <p>I use windows and never used a mac nor do i want to<br>
If i am understanding this correctly vo will say safari not responding and then the keyboard doesnt work, is this correct? If so thats unacceptable</p>
      
    </div>
</article>

<article data-comment-user-id="1445" id="comment-155589" role="article" data-drupal-selector="comment">
     <p>
               
        <h3><a href="https://www.applevis.com/comment/155589#comment-155589" rel="bookmark" hreflang="en">Safari Not Responding</a></h3>
        
          </p>
  <span data-comment-timestamp="1696798858"></span>

  <div>
      
            <p>Maybe I have been very lucky, but I have not experienced the same level of frustration with my Mac. I have been using a MacBook Air since 2013, and my current Mac is a 2020 M1 MacBook Air with 8 GB of RAM. While I have occasionally encountered the  "Safari not responding" issue, I could easily work around this by turning VO off and on. I use my Mac for creating documents, working with spreadsheets, using the Internet, managing my music library, handling emails, among other things. Based on my experience, I would have no problem recommending a Mac to a blind user. Of course, each person must determine their own use case.<br>
Over the past ten years, I have encountered numerous bugs but none of them were show stoppers for me. I imagine that Windows with JAWS or NVDA also has its share of bugs.<br>
Given that this bug seems to not affect all Mac users with the same severity, this may make it a more difficult issue for Apple to address. However, given the comments that I have read on Applevis, I agree that this should be a priority for their Accessibility team.</p>
      
    </div>
</article>

<article data-comment-user-id="8869" id="comment-155591" role="article" data-drupal-selector="comment">
     <p>
               
        <h3><a href="https://www.applevis.com/comment/155591#comment-155591" rel="bookmark" hreflang="en">Upgrade to latest Mac Mini on hold</a></h3>
        
          </p>
  <span data-comment-timestamp="1696799187"></span>

  <div>
      
            <p>I was looking forward to upgrading my 2018 Mac Mini - just waiting for the M3 to be released. But that's now tabled. I stand in solidarity with David. No more new Apple hardware until this long-standing and unacceptable issue is resolved.</p>
      
    </div>
</article>

<article data-comment-user-id="26568" id="comment-155596" role="article" data-drupal-selector="comment">
     <p>
               
        <h3><a href="https://www.applevis.com/comment/155596#comment-155596" rel="bookmark" hreflang="en">My experience with jaws</a></h3>
        
          </p>
  <span data-comment-timestamp="1696800662"></span>

  <div>
      
            <p>Hi<br>
I used jaws for 5 years and dont remember any major bugs with it<br>
I am having a problem with the computer i use at work where jaws sometimes crashes, HP laptop running windows 10 and jaws 2021 but that doesnt happen offten</p>
      
    </div>
</article>

<article data-comment-user-id="8869" id="comment-155597" role="article" data-drupal-selector="comment">
     <p>
               
        <h3><a href="https://www.applevis.com/comment/155597#comment-155597" rel="bookmark" hreflang="en">For those of you not experiencing this issue</a></h3>
        
          </p>
  <span data-comment-timestamp="1696801768"></span>

  <div><p>I can't speak for David, but I personally feel this post will have more impact if those of you not experiencing this issue please <a href="https://www.applevis.com/forum/macos-mac-apps/safari-v15-mac-busy-busy-busy">discuss</a> your <a href="https://www.applevis.com/forum/macos-mac-apps/safari-busy-busy-busy-busy-busy">system config</a> in <a href="https://www.applevis.com/forum/macos-mac-apps/safari-not-responding">any</a> of the <a href="https://www.applevis.com/forum/macos-mac-apps/fixing-safari-not-responding-problem">numerous</a> posts devoted to <a href="https://www.applevis.com/forum/apple-beta-releases/i-dispair-safari-not-responding-just-bad-latest-beta-until-fixed-i-cannot">trying</a> to <a href="https://www.applevis.com/forum/apple-beta-releases/safari-still-not-responding">find</a> a <a href="https://www.applevis.com/forum/macos-mac-apps/please-apple-make-safari-respond">solution.</a> And I'll warn you in advance, lots of suggestions have been made over the years, and there is no silver bullet.</p>

<p>Most of us have been experiencing this issue for years. Please don't pretend this issue doesn't exist.</p></div>
</article>


  
</section>

  </div>
  </article>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mitigations=off considered harmful or spurious SIGILL on AMD Zen4 (114 pts)]]></title>
            <link>https://forum.level1techs.com/t/mitigations-off-considered-harmful-or-spurious-sigill-on-amd-zen4/202049</link>
            <guid>37812556</guid>
            <pubDate>Sun, 08 Oct 2023 17:31:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://forum.level1techs.com/t/mitigations-off-considered-harmful-or-spurious-sigill-on-amd-zen4/202049">https://forum.level1techs.com/t/mitigations-off-considered-harmful-or-spurious-sigill-on-amd-zen4/202049</a>, See on <a href="https://news.ycombinator.com/item?id=37812556">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main-outlet" role="main">
        

  


      <div id="post_1" itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        <div>
          
          


          <p><span>
              <time itemprop="datePublished" datetime="2023-10-02T22:05:57Z">
                October 2, 2023, 10:05pm
              </time>
              <meta itemprop="dateModified" content="2023-10-02T22:07:55Z">
          <span itemprop="position">#1</span>
          </span>
        </p></div>
        <p>Hunting spurious illegal instructions where there were none on AMD Ryzen 7950x for months compiling OpenSource packages with GCC (for <a href="https://t2sde.org/" rel="noopener nofollow ugc">https://t2sde.org</a>), I finally found this regular user-land code causing some pseudo random speculative execution state corruption on Zen 4! The good news: actually running with mitigations=on (I had it =off for performance) or disabling SMT works around it for now. <a href="https://www.youtube.com/watch?v=1UnoBfw6soI" rel="noopener nofollow ugc">https://www.youtube.com/watch?v=1UnoBfw6soI</a> I guess one of the first documented cases of regular user programs causing speculative execution marginalities! So much for running with mitigations=off for performance even with your “own” trusted code, … not anymore. I’ll continue to further reduce the test case and hope to eventually reach AMD and linux-kernel to further find the root cause of this, … :-/</p>

        <meta itemprop="headline" content="Mitigations=off considered harmful or spurious SIGILL on AMD Zen4">
          <meta itemprop="keywords" content="kernel">

        

         

      </div>
      <div id="post_2" itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        
        <div itemprop="articleBody">
          <p>Wow, that is crazy. I wonder how many others have run into similar issues and did not attribute it to Speculative Execution bugs.</p>
<p><a href="https://forum.level1techs.com/u/rener">@rener</a> Is there a significant hit in performance between mitigations on and mitigations off? I am still running the heavy machinery architecture on my desktop. My laptop is Zen3.5 (6800U) but I have to run MS Windows for school and I have not been able to get T2 or any GNU/Linux to run properly on the laptop just yet (I think TPM 2.0 issues). BSD seems to work fine, if not slow on  the laptop though. haha.</p>
        </div>

        <meta itemprop="headline" content="Mitigations=off considered harmful or spurious SIGILL on AMD Zen4">

        

         

      </div>
      <div id="post_3" itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        <div>
          
          <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            <a itemprop="url" href="https://forum.level1techs.com/u/rener"><span itemprop="name">rener</span></a>
            
          </span></p>


          <p><span>
              <time itemprop="datePublished" datetime="2023-10-03T10:21:49Z">
                October 3, 2023, 10:21am
              </time>
              <meta itemprop="dateModified" content="2023-10-03T10:21:49Z">
          <span itemprop="position">#3</span>
          </span>
        </p></div>
        <p>thankfully currently on Zen4 the performance impact for my usecase with mitigations=on is barely meassurable. For Zen3 and Zen2 it was quite some % in the meantime with years of mitigations. A kernel dev commented in the meantime it could also be generic TLB bugs in the linux kernel. So the research will continue, …</p>

        <meta itemprop="headline" content="Mitigations=off considered harmful or spurious SIGILL on AMD Zen4">

        

         

      </div>
      <div id="post_4" itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        
        <p>I will give it a try on my Ryzen 7 6800U and my FX-6300 and see what happens.</p>

        <meta itemprop="headline" content="Mitigations=off considered harmful or spurious SIGILL on AMD Zen4">

        

         

      </div>






    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Email Steve Jobs sent to himself 1 year before his passing (106 pts)]]></title>
            <link>https://officechai.com/stories/steve-jobs-email-to-self/</link>
            <guid>37812342</guid>
            <pubDate>Sun, 08 Oct 2023 17:08:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://officechai.com/stories/steve-jobs-email-to-self/">https://officechai.com/stories/steve-jobs-email-to-self/</a>, See on <a href="https://news.ycombinator.com/item?id=37812342">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page">
<main id="main" role="main">
<article id="post-43561">

<p><img width="1920" height="1080" src="https://officechai.com/wp-content/uploads/2022/10/getty_96211011_2000134813806405780_414357.jpg" alt="" srcset="https://officechai.com/wp-content/uploads/2022/10/getty_96211011_2000134813806405780_414357.jpg 1920w, https://officechai.com/wp-content/uploads/2022/10/getty_96211011_2000134813806405780_414357-300x169.jpg 300w, https://officechai.com/wp-content/uploads/2022/10/getty_96211011_2000134813806405780_414357-1024x576.jpg 1024w, https://officechai.com/wp-content/uploads/2022/10/getty_96211011_2000134813806405780_414357-768x432.jpg 768w, https://officechai.com/wp-content/uploads/2022/10/getty_96211011_2000134813806405780_414357-1536x864.jpg 1536w" sizes="(max-width: 1920px) 100vw, 1920px" data-srcset="https://officechai.com/wp-content/uploads/2022/10/getty_96211011_2000134813806405780_414357.jpg 1920w, https://officechai.com/wp-content/uploads/2022/10/getty_96211011_2000134813806405780_414357-300x169.jpg 300w, https://officechai.com/wp-content/uploads/2022/10/getty_96211011_2000134813806405780_414357-1024x576.jpg 1024w, https://officechai.com/wp-content/uploads/2022/10/getty_96211011_2000134813806405780_414357-768x432.jpg 768w, https://officechai.com/wp-content/uploads/2022/10/getty_96211011_2000134813806405780_414357-1536x864.jpg 1536w" data-src="https://officechai.com/wp-content/uploads/2022/10/getty_96211011_2000134813806405780_414357.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="> </p>
<div>



<p>People at the top of their professional games are thought to be quite self centered and sure of themselves. But one of the best-known tech figures of all time had a remarkably poignant take on life an humanity a year before he passed away.</p>
<figure><img width="1024" height="576" src="https://officechai.com/wp-content/uploads/2022/10/getty_96211011_2000134813806405780_414357-1024x576.jpg" alt="Steve Jobs email to self humanity" srcset="https://officechai.com/wp-content/uploads/2022/10/getty_96211011_2000134813806405780_414357-1024x576.jpg 1024w, https://officechai.com/wp-content/uploads/2022/10/getty_96211011_2000134813806405780_414357-300x169.jpg 300w, https://officechai.com/wp-content/uploads/2022/10/getty_96211011_2000134813806405780_414357-768x432.jpg 768w, https://officechai.com/wp-content/uploads/2022/10/getty_96211011_2000134813806405780_414357-1536x864.jpg 1536w, https://officechai.com/wp-content/uploads/2022/10/getty_96211011_2000134813806405780_414357.jpg 1920w" sizes="(max-width: 1024px) 100vw, 1024px" data-srcset="https://officechai.com/wp-content/uploads/2022/10/getty_96211011_2000134813806405780_414357-1024x576.jpg 1024w, https://officechai.com/wp-content/uploads/2022/10/getty_96211011_2000134813806405780_414357-300x169.jpg 300w, https://officechai.com/wp-content/uploads/2022/10/getty_96211011_2000134813806405780_414357-768x432.jpg 768w, https://officechai.com/wp-content/uploads/2022/10/getty_96211011_2000134813806405780_414357-1536x864.jpg 1536w, https://officechai.com/wp-content/uploads/2022/10/getty_96211011_2000134813806405780_414357.jpg 1920w" data-src="https://officechai.com/wp-content/uploads/2022/10/getty_96211011_2000134813806405780_414357-1024x576.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure>
<p>In 2010, Steve Jobs had been diagnosed with cancer, and had cut down on his work comittments. At that point, he had written an email to himself, and sent it via what else, but his iPad. The email ruminated on the fact that most things in Jobs’ life weren’t controlled by him. He said that he didn’t grow most of the food he ate, used a language he didn’t develop, listened to music which he didn’t write, was governed by laws which he didn’t come up with. </p>
<p>This led Jobs to a beautiful conclusion, which was the closing line of his email: I love and admire my species, living and dead, and am totally dependent on them for my life and well being..</p>
<p>One of the greatest entrepreneurs of all time, who’d created what is now the world’s most valuable company, and whose products had touched millions of lives, was putting things in perspective, and saying that most of his life had been built by other members of his species. Sure, he might’ve created beautiful products and tremendous amounts of shareholder value, but Jobs was acknowledging that he had stood on shoulders of giants. And if Steve Jobs felt that the outcome of his life had been largely determined by the human species as a whole, it does put a lot off pressure off ordinary folks like you and me.</p>
<figure><img src="https://pbs.twimg.com/media/FcV8SqoacAMj9gD?format=png&amp;name=large" alt="Steve Jobs email to self"></figure>
<p>Here’s the full text of the letter:</p>
<p>From: Steve Jobs, <a href="https://officechai.com/cdn-cgi/l/email-protection" data-cfemail="ed9e87828f9ead8c9d9d8188c38e8280">[email&nbsp;protected]</a> To: Steve Jobs, <a href="https://officechai.com/cdn-cgi/l/email-protection" data-cfemail="82f1e8ede0f1c2e3f2f2eee7ace1edef">[email&nbsp;protected]</a> Date: Thursday, September 2, 2010 at 11:08PM</p>
<p><br>I grow little of the food I eat, and of the little I do grow I did not breed or perfect the seeds. </p>
<p>I do not make any of my own clothing. </p>
<p>I speak a language I did not invent or refine. I did not discover the mathematics I use. </p>
<p>I am protected by freedoms and laws I did not conceive of or legislate, and do not enforce or adjudicate.</p>
<p> I am moved by music I did not create myself.</p>
<p> When I needed medical attention, I was helpless to help myself survive.</p>
<p><br>I did not invent the transistor, the microprocessor, object oriented programming, or most of the technology I work with.<br></p>
<p>I love and admire my species, living and dead, and am totally dependent on them for my life and well being.</p>
<p><br>Sent from my iPad</p>



 </div>

</article>
</main>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Writing down unfiltered thoughts enhances self-knowledge (154 pts)]]></title>
            <link>https://www.scientificamerican.com/article/know-yourself-better-by-writing-what-pops-into-your-head/</link>
            <guid>37812332</guid>
            <pubDate>Sun, 08 Oct 2023 17:08:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.scientificamerican.com/article/know-yourself-better-by-writing-what-pops-into-your-head/">https://www.scientificamerican.com/article/know-yourself-better-by-writing-what-pops-into-your-head/</a>, See on <a href="https://news.ycombinator.com/item?id=37812332">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-behavior="newsletter_promo dfp_article_rendering" data-dfp-adword="Advertisement" data-newsletterpromo_article-text="<p>Sign up for <em>Scientific American</em>&amp;rsquo;s free newsletters.</p>" data-newsletterpromo_article-image="https://static.scientificamerican.com/sciam/cache/file/4641809D-B8F1-41A3-9E5A87C21ADB2FD8_source.png" data-newsletterpromo_article-button-text="Sign Up" data-newsletterpromo_article-button-link="https://www.scientificamerican.com/page/newsletter-sign-up/?origincode=2018_sciam_ArticlePromo_NewsletterSignUp" name="articleBody" itemprop="articleBody"><p>For decades, physician and author Silke Heimes has been leading groups in therapeutic exercises to put thoughts and feelings down on paper. Heimes, a professor of journalism at Darmstadt University of Applied Sciences,&nbsp; points to abundant evidence that <a href="https://www.munich-business-school.de/insights/en/2021/the-power-of-writing-interactive-guest-lecture-from-prof-silke-heimes/">writing for five to 20 minutes a day</a> can improve health, diminish stress, increase self-confidence and even kindle the imagination. A writing routine, she argues, is a form of mental hygiene that almost anyone can benefit from.</p>

<p>So how do you start? What happens if—as every writer fears—the page remains blank? And how do you get rid of an overcritical inner censor? Heimes, director of the Institute for Creative and Therapeutic Writing in Darmstadt, explains how to overcome inhibitions and open up your inner world.</p>

<p>[<em>An edited transcript of the interview follows</em>.]</p>

<p><strong>If you want to write in order to understand yourself better, what's the best way to start?</strong></p>

<p>There are writing exercises, for example in so-called fill-in journals, where you directly answer a question. But if I just want to get started without any aids, the best way is to use the method of automatic writing. That means I set myself a short time window, maybe five minutes, in which I write continuously without thinking, without putting down the pen or rereading what I’ve written. The goal is to get thoughts down on paper as unfiltered as possible so that an inner censor can't switch on—or at least doesn't get too loud. It helps not to set the goal too high—not to expect too much—but to understand this writing as a time-out, so to speak, or as a kind of warm-up exercise.</p>

<p><strong>Wouldn’t it be</strong> <strong>helpful to ask yourself specific questions?</strong></p>

<p>If you want to, you can follow programs that, for example, organize specific questions into topics. But that can also be inhibiting at times because such questions primarily get your head working to produce rational answers. Questions often steer thoughts along preconceived paths. Sometimes it is almost easier without them to let the gut lead the way.</p>

<p><strong>W</strong><strong>hat if you just can't think of anything?</strong></p>

<p>The half-sentence method can help. With this approach, you complete a given half-sentence such as "When I woke up this morning” or “What happened to me today.” If you write in the morning, the [first example] is a good choice. Because everyone wakes up in the morning, everyone can think of something to say about it. The same applies to [the second example] if you write in the evening because you inevitably experienced something during the day by then. To start, you can also write down words that begin with the letters of your name and then create a text using those words.</p>

<p><strong>Can anything go wrong using these methods?</strong></p>

<p>Not really. Just as with thinking, you can of course get tangled up in your own thoughts or get stuck in brooding loops when writing. But that’s not the fault of the writing itself; it’s just something that becomes obvious on paper. Writing often deals with emotional issues, so you also might temporarily feel bad because something is stirred up or triggered. In that case, you should take a break and do something else or talk to someone about it. If the feeling persists, it is best to seek professional help.</p>

<p><strong>Does it make a difference whether you write by hand or on a keyboard?</strong></p>

<p>Writing by hand is a very complex movement that activates more areas in the brain, which leads to being more creative. It also usually means slowing down, which invites you to pause and take a breath. In addition, there is something sensual and unique about writing by hand. because, for one thing, our handwriting is very individual. And for another thing, it tells us something about our state of mind. In fact, handwriting usually becomes rounder and livelier when we are in a good mood and smaller or tighter when we are not feeling so well. Typing on the keyboard, on the other hand has a soothing quality because it is very rhythmic. Further, it has the advantage of allowing you to share your writing more quickly. I think it’s always good to have both skills and to use them.</p>

<p><strong>You have guided many groups in this type of writing. How does that typically work?</strong></p>

<p>We first do little writing exercises to warm up. Many people come with the expectation that they’ll sit down, and the writing will flow right away—that they’ll perform brilliantly almost off the cuff. But no athlete, no musician would expect that of themselves. Professional writers know better.</p>

<p>And there are other common misconceptions. The biggest one is “I can't write.” A lot of people come to my seminars with this attitude. But we can all write. Rather the problem is the often exaggerated demands we place on ourselves. I like to quote French writer André Breton, who invented automatic writing. He said, mutatis mutandis, that if you want to write, find a nice place, sit down in peace and quiet and forget about seeking out brilliant thoughts.</p>

<p><strong>Is there anything else that people particularly struggle with when it comes to writing?</strong></p>

<p>We’ve already talked about your own performance expectations. But what can also lead to inhibitions is the fear of emotions or of your personal history—fear of confronting possibly painful topics. And further problems usually arise when people want to put their thoughts into a literary form in order to publish them.</p>

<p><strong>What if someone only produces platitudes? What if they sound banal or superficial?</strong></p>

<p>Who decides that? That is a judgment that should be unacceptable in creative and therapeutic writing. Everyone expresses what is important, right and possible for them at that moment, and I think that is precisely what deserves appreciation.</p>

<p><strong>What do people in your groups write about most often?</strong></p>

<p>They write about the topic of self-worth—that is, the fear of not being good enough—about not being heard or seen and about the topic of freedom versus security, especially at work.</p>

<p><strong>And what insights do they go home with?</strong></p>

<p>That varies greatly. But they often take home a lot of pieces of paper, and that’s how they recognize that they can definitely write. They have produced something and are justifiably proud of it. This increases their self-esteem, and they develop more confidence. Writing also sharpens perception and promotes mindfulness. People notice more quickly when something is not good for them and find better ways to deal with those problems. And when thoughts go round in circles, putting them down on paper clears the mind. After that you have more capacity for other things in your life.</p>

<p><strong>Can these benefits be probed empirically?</strong></p>

<p>There are [hundreds] of studies on the effect of expressive or therapeutic writing. Many of them come from the psychologist James Pennebaker, who did research on this primarily with students.</p>

<p><strong>Do you write a lot yourself?</strong></p>

<p>Yes, every day. I work on a novel or nonfiction book every day, and I also jot down my thoughts for three minutes in the morning. These few minutes of mental hygiene are as important and natural to me as brushing my teeth every day.</p>

<p><em>This article originally appeared in</em> Spektrum der Wissenschaft <em>and was reproduced with permission</em>.</p></div><section><h3>ABOUT THE AUTHOR(S)</h3><div><ul></ul><p><strong>Christiane Gelitz</strong> is a psychologist and an editor at <em>Spektrum der Wissenschaft</em>.</p></div></section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenIPC: Alternative open firmware for your IP camera (305 pts)]]></title>
            <link>https://github.com/OpenIPC</link>
            <guid>37812217</guid>
            <pubDate>Sun, 08 Oct 2023 16:57:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/OpenIPC">https://github.com/OpenIPC</a>, See on <a href="https://news.ycombinator.com/item?id=37812217">Hacker News</a></p>
<div id="readability-page-1" class="page"><article itemprop="text"><h2 id="user-content-alternative-open-firmware-for-your-ip-camera--" dir="auto"><a href="#alternative-open-firmware-for-your-ip-camera--">Alternative open firmware for your IP camera  </a><a href="https://t.me/OpenIPC" rel="nofollow"><img src="https://camo.githubusercontent.com/69edb3d30ff26af89903ca32db2a30f33fdf404eafdc5bd7a993d4a69e8daa7e/68747470733a2f2f6f70656e6970632e6f72672f696d616765732f74656c656772616d5f627574746f6e2e737667" alt="Telegram" data-canonical-src="https://openipc.org/images/telegram_button.svg"></a></h2>
<p dir="auto"><em>(based on Buildroot)</em></p>
<p dir="auto">OpenIPC is an open source operating system from the <a href="https://github.com/OpenIPC/.github/blob/main/opencollective">open community</a>
targeting for IP cameras with ARM and MIPS processors from several manufacturers in
order to replace that closed, opaque, insecure, often abandoned and unsupported
firmware pre-installed by a vendor.</p>
<p dir="auto">OpenIPC <a href="https://github.com/openipc/firmware/">firmware</a> comes as binary pre-compiled files for easy
installation by end-user. Also, we provide full access to the source files for
further development and improvement by any capable programmer willing to
contribute to the project. OpenIPC source code is released under one of the most
simple open source license agreements, <a href="https://opensource.org/license/mit/" rel="nofollow">MIT License</a>, giving users express
permission to reuse code for any purpose, even as part of a proprietary software.
We only ask you politely to contribute your improvements back to us. We would
be grateful for any feedback and suggestions.</p>
<p dir="auto">Historically, OpenIPC <a href="https://github.com/openipc/firmware/">firmware</a> only supported SoC manufactured by
HiSilicon, but as the development continues, the list of supported processors
expands. Today, it also includes chips from <em>Ambarella</em>, <em>Anyka</em>, <em>Fullhan</em>, <em>Goke</em>,
<em>GrainMedia</em>, <em>Ingenic</em>, <em>MStar</em>, <em>Novatek</em>, <em>SigmaStar</em>, <em>XiongMai</em>, and is
expected to grow further.</p>
<p dir="auto">More information about the <a href="https://github.com/openipc/">project</a> is available in our <a href="https://openipc.org/" rel="nofollow">website</a>
and on the <a href="https://github.com/OpenIPC/wiki">wiki</a>.</p>
<p dir="auto">
<a href="https://opencollective.com/openipc/contribute/backer-14335/checkout" rel="nofollow"><img src="https://camo.githubusercontent.com/440363e6c94395b51235765a32ea883666f3c6460067200c06353499e6539bf6/68747470733a2f2f6f70656e636f6c6c6563746976652e636f6d2f7765627061636b2f646f6e6174652f627574746f6e4032782e706e673f636f6c6f723d626c7565" width="250" alt="Open Collective donate button" data-canonical-src="https://opencollective.com/webpack/donate/button@2x.png?color=blue"></a>
</p>
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Tailscale Universal Docker Mod (195 pts)]]></title>
            <link>https://tailscale.dev/blog/docker-mod-tailscale</link>
            <guid>37812142</guid>
            <pubDate>Sun, 08 Oct 2023 16:51:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tailscale.dev/blog/docker-mod-tailscale">https://tailscale.dev/blog/docker-mod-tailscale</a>, See on <a href="https://news.ycombinator.com/item?id=37812142">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><p>Imagine a world where you could add applications to your tailnet the same way you add machines to it. This would mean that <code>http://wiki</code> would go to your internal wiki, <code>http://code</code> would take you to an IDE, and <code>http://chat</code> would take you to your internal chat server. This is the world that Tailscale lets you create, but historically the details on how you would actually do this are left as an exercise for the reader.</p><p>Today, we're introducing a new way to add Tailscale to your Docker containers: our brand new <a href="https://github.com/linuxserver/docker-mods/blob/master/README.md" target="_blank" rel="noreferrer">universal Docker mod</a>. This lets you add Tailscale to any Docker container based on <a href="https://linuxserver.io/" target="_blank" rel="noreferrer">linuxserver.io</a> images. This lets you have applications join your tailnet just as easily as machines can. You can set up a wiki on <code>http://wiki</code>, an IDE at <code>http://code</code>, and a chat server at <code>http://chat</code> and have them all be accessible over your tailnet. You can even use this to expose your internal applications to the public internet with <a href="https://tailscale.com/kb/1112/funnel/" target="_blank" rel="noreferrer">Funnel</a>.</p><div><p><img alt="the avatar for Xe Iaso" srcset="https://tailscale.dev/_next/image?url=%2Favatars%2Fxe.png&amp;w=64&amp;q=75 1x, https://tailscale.dev/_next/image?url=%2Favatars%2Fxe.png&amp;w=128&amp;q=75 2x" src="https://tailscale.dev/_next/image?url=%2Favatars%2Fxe.png&amp;w=128&amp;q=75" width="64" height="64" decoding="async" data-nimg="1" loading="lazy"></p><div><p>&lt;<b>Xe</b>&gt; </p><p>You can even use this to SSH into containers!</p></div></div><div><p><img alt="A picture of the character Aoi in a coffee mood.}" srcset="https://tailscale.dev/_next/image?url=%2Fimages%2Fxe%2Fstickers%2Faoi%2Fcoffee.png&amp;w=64&amp;q=75 1x, https://tailscale.dev/_next/image?url=%2Fimages%2Fxe%2Fstickers%2Faoi%2Fcoffee.png&amp;w=128&amp;q=75 2x" src="https://tailscale.dev/_next/image?url=%2Fimages%2Fxe%2Fstickers%2Faoi%2Fcoffee.png&amp;w=128&amp;q=75" width="64" height="64" decoding="async" data-nimg="1" loading="lazy"><br></p><div><p>&lt;<b>Aoi</b>&gt; </p><p>You can <em>what</em> into a container?</p></div></div><div><p><img alt="the avatar for Xe Iaso" srcset="https://tailscale.dev/_next/image?url=%2Favatars%2Fxe.png&amp;w=64&amp;q=75 1x, https://tailscale.dev/_next/image?url=%2Favatars%2Fxe.png&amp;w=128&amp;q=75 2x" src="https://tailscale.dev/_next/image?url=%2Favatars%2Fxe.png&amp;w=128&amp;q=75" width="64" height="64" decoding="async" data-nimg="1" loading="lazy"></p><div><p>&lt;<b>Xe</b>&gt; </p><p>Yep! <a href="https://tailscale.com/kb/1193/ssh/" target="_blank" rel="noreferrer">Tailscale SSH</a> lets you SSH into containers when you enable the <code>TAILSCALE_USE_SSH</code> setting and <a href="https://tailscale.com/kb/1193/tailscale-ssh/#ensure-tailscale-ssh-is-permitted-in-acls" target="_blank" rel="noreferrer">permit access in the ACLs</a>. This is a great way to get into a container without having to SSH into the docker host and run <code>docker exec -it &lt;container&gt; bash</code>.</p></div></div><p>To add this to your existing Docker containers with linuxserver.io images, add the following environment variables to your docker-compose.yml file:</p><div><p><code><br><div><p><span>- DOCKER_MODS=ghcr.io/tailscale-dev/docker-mod:main</span></p></div><div><p><span># tailscale configuration</span></p></div><div><p><span># make sure this is persisted in a volume</span></p></div><div><p><span>- TAILSCALE_STATE_DIR=/var/lib/tailscale</span></p></div><div><p><span>- TAILSCALE_SERVE_MODE=https</span></p></div><div><p><span>- TAILSCALE_SERVE_PORT=80</span></p></div><div><p><span>- TAILSCALE_USE_SSH=1</span></p></div><div><p><span>- TAILSCALE_HOSTNAME=wiki</span></p></div><div><p><span>## uncomment to enable funnel</span></p></div><div><p><span>## remember that if you do, it's exposed to the internet, so be careful!</span></p></div><div><p><span>#- TAILSCALE_FUNNEL=on</span></p></div><div><p><span># replace this with your authkey from the admin panel</span></p></div><div><p><span>- TAILSCALE_AUTHKEY=tskey-auth-hunter2CNTRL-hunter2hunter2</span></p></div><br></code></p></div><p>This will add Tailscale to your container so that you can access it over your tailnet. If you run <code>docker compose up -d</code> with the authkey changed out for <a href="https://login.tailscale.com/admin/settings/keys" target="_blank" rel="noreferrer">a valid authkey</a>, you'll be able to access your apps over Tailscale.</p><figure><img alt="flat color, shipyard, containers, mountains, no humans, space needle" srcset="https://tailscale.dev/_next/image?url=%2Fimages%2Fhero%2Fshipyard-vibes.png&amp;w=1920&amp;q=75 1x, https://tailscale.dev/_next/image?url=%2Fimages%2Fhero%2Fshipyard-vibes.png&amp;w=3840&amp;q=75 2x" src="https://tailscale.dev/_next/image?url=%2Fimages%2Fhero%2Fshipyard-vibes.png&amp;w=3840&amp;q=75" width="1280" height="512" decoding="async" data-nimg="1" loading="lazy"><figcaption>Image generated by <!-- -->Ligne Claire v1.5<!-- -->, prompt: <!-- -->flat color, shipyard, containers, mountains, no humans, space needle</figcaption><meta property="og:image" content="/images/hero/shipyard-vibes.png"></figure><h2 id="docker-and-docker-mods">Docker and Docker mods</h2><p>Docker allows you to create snapshots of operating system installs with a given state, such as "having the <a href="https://go.dev/" target="_blank" rel="noreferrer">Go</a> compiler available" or "install this program and all its dependencies" and distribute those preconfigured images on the Internet. When you consume the same Docker image at two time intervals T0 and T1, you get the same image with the same code, just as you expect.</p><p>When a Docker container is run, it usually runs on top of an ephemeral filesystem that gets destroyed when the container is stopped. This means that restarting the container will reset it back to the state that was there when the image was created. This is normally convenient when working on applications that make temporary changes to the filesystem, such as an image converter that uses temporary files to do the conversion logic.</p><p>This is less convenient when you want to run things like database servers in Docker. However, most of the time when you do things that need persistent state, that persistent state is usually limited to a single file or directory. Docker provides external persistent state with <a href="https://docs.docker.com/storage/volumes/" target="_blank" rel="noreferrer">volumes</a>. They're basically directories that are plunked into the container at runtime, but it maintains the state between container runs. This is great for things like databases because you wouldn't want to lose all your data when you restart the container.</p><p><img alt="The expected hierarchies of Docker containers and their statefulness" src="https://tailscale.dev/images/universal-docker-mod/docker-normal.svg" width="623" height="490" decoding="async" data-nimg="1" loading="lazy"></p><p>So, from here we can create a hierarchy for docker and statefulness. You expect docker containers to have state for <em>data</em>, and you also expect the docker container to be running the same code every time you run the same image. You don't expect anything else to be running, everything is deterministic at T0, T1, or TN.</p><div><p><img alt="the avatar for Xe Iaso" srcset="https://tailscale.dev/_next/image?url=%2Favatars%2Fxe.png&amp;w=64&amp;q=75 1x, https://tailscale.dev/_next/image?url=%2Favatars%2Fxe.png&amp;w=128&amp;q=75 2x" src="https://tailscale.dev/_next/image?url=%2Favatars%2Fxe.png&amp;w=128&amp;q=75" width="64" height="64" decoding="async" data-nimg="1" loading="lazy"></p><div><p>&lt;<b>Xe</b>&gt; </p><p>This is a valid hierarchy because it's what you expect from docker. You expect the same code to run every time you run the same image.</p></div></div><h3 id="what-is-humor">What is humor?</h3><p>Humor is a complicated concept that is almost universal throughout human cultures. It's a way of conveying concepts like absurdity, irony, the absurdity of irony, and normally frustrating things in ways that aren't quite as much of a downer. It's really about being able to communicate subtle things like common errors that everyone makes when learning things (such as English and its rule of all the rules having exceptions, even for the exceptions). It's also a tool that you can use to help describe the abstract and nonphysical things like emotions, feelings, ideas, the human condition, and how Kubernetes works.</p><div><p><img alt="the avatar for Xe Iaso" srcset="https://tailscale.dev/_next/image?url=%2Favatars%2Fxe.png&amp;w=64&amp;q=75 1x, https://tailscale.dev/_next/image?url=%2Favatars%2Fxe.png&amp;w=128&amp;q=75 2x" src="https://tailscale.dev/_next/image?url=%2Favatars%2Fxe.png&amp;w=128&amp;q=75" width="64" height="64" decoding="async" data-nimg="1" loading="lazy"></p><div><p>&lt;<b>Xe</b>&gt; </p><p>Humor is also really hard to convey properly in a written medium. This is even more difficult when the humor is about technology, which is usually hard to understand in the first place. I'm going to try to explain the humor in this article with these asides so that y'all can follow along, but if you already get why this is funny it may ruin the joke for you. Sorry!</p></div></div><p>In his famous presentation <a href="https://youtu.be/ar9WRwCiSr0" target="_blank" rel="noreferrer">Reverse emulating the NES</a>, fellow philosopher in arms <a href="http://tom7.org/" target="_blank" rel="noreferrer">tom7</a> introduced the idea of a type of humor called "invalid hierarchies". In this he does rather abusrd things to an NES using a custom circuit board and a raspbery pi to allow him to (among other things) run an SNES emulator on the NES. This video is quite possibly one of my favorite technical communication videos and is a huge influence to how I write humorous things for this blog.</p><div><p><img alt="the avatar for Xe Iaso" srcset="https://tailscale.dev/_next/image?url=%2Favatars%2Fxe.png&amp;w=64&amp;q=75 1x, https://tailscale.dev/_next/image?url=%2Favatars%2Fxe.png&amp;w=128&amp;q=75 2x" src="https://tailscale.dev/_next/image?url=%2Favatars%2Fxe.png&amp;w=128&amp;q=75" width="64" height="64" decoding="async" data-nimg="1" loading="lazy"></p><div><p>&lt;<b>Xe</b>&gt; </p><p>This creates an invalid hierarchy because you expect the NES to only run 8-bit NES games, but not 16-bit SNES games. This is funny. If you've never seen that video before, it's well worth a watch.</p><p>Another example of an invalid hierarchy is my April Fool's Day post <a href="https://tailscale.dev/blog/headscale-funnel" target="_blank" rel="noreferrer">Using Tailscale without using Tailscale</a>. You'd expect to have to use Tailscale if you want to use Tailscale, but "using Tailscale without using Tailscale" creates an invalid hierarchy in the mind of the reader. This is also funny.</p></div></div><p><img alt="The expected hierarchies of NES and SNES consoles and their games" src="https://tailscale.dev/images/universal-docker-mod/nes-snes.svg" width="359" height="490" decoding="async" data-nimg="1" loading="lazy"></p><h3 id="docker-mods">Docker mods</h3><p>Docker mods let you install extra packages and services into containers at runtime. If the <code>ONBUILD</code> hook lets you run a series of commands when an image is built, you can think of docker mods as a missing <code>ONRUN</code> hook that lets you customize an image at runtime.</p><p><img alt="How Docker mods change the statefulness of a container" src="https://tailscale.dev/images/universal-docker-mod/docker-mod.svg" width="703" height="716" decoding="async" data-nimg="1" loading="lazy"></p><div><p><img alt="the avatar for Xe Iaso" srcset="https://tailscale.dev/_next/image?url=%2Favatars%2Fxe.png&amp;w=64&amp;q=75 1x, https://tailscale.dev/_next/image?url=%2Favatars%2Fxe.png&amp;w=128&amp;q=75 2x" src="https://tailscale.dev/_next/image?url=%2Favatars%2Fxe.png&amp;w=128&amp;q=75" width="64" height="64" decoding="async" data-nimg="1" loading="lazy"></p><div><p>&lt;<b>Xe</b>&gt; </p><p>This creates an invalid hierarchy because we think about the code in a container being deterministic between invocations and this allows you to make something <em>nondeterministic</em>. This is funny.</p></div></div><h3 id="docker-mods-and-s6">Docker mods and s6</h3><p>At a high level, a docker mod is a series of files that add additional instructions to the start phase of a docker container. It works because the <a href="https://www.linuxserver.io/" target="_blank" rel="noreferrer">linuxserver.io</a> containers preinstall <a href="https://skarnet.org/software/s6/" target="_blank" rel="noreferrer">s6</a> via <a href="https://github.com/just-containers/s6-overlay" target="_blank" rel="noreferrer">s6-overlay</a> and then start it in the background to manage the lifecycle of services in the container.</p><div><p><img alt="the avatar for Xe Iaso" srcset="https://tailscale.dev/_next/image?url=%2Favatars%2Fxe.png&amp;w=64&amp;q=75 1x, https://tailscale.dev/_next/image?url=%2Favatars%2Fxe.png&amp;w=128&amp;q=75 2x" src="https://tailscale.dev/_next/image?url=%2Favatars%2Fxe.png&amp;w=128&amp;q=75" width="64" height="64" decoding="async" data-nimg="1" loading="lazy"></p><div><p>&lt;<b>Xe</b>&gt; </p><p>This is also funny because usually Docker containers aren't supposed to have multiple processes running in them for simplicity, but it turns out that when you want to do things like put your wiki seamlessly on your tailnet, you want to have multiple processes running. This is another invalid hierarchy because you expect the container to only have one process running, but it has multiple with a service manager, just like the host OS.</p></div></div><p>When I made the docker mod, I had to create a few s6 services to help it run:</p><ul><li>One to set a list of packages that Tailscale needs to run (<a href="https://stedolan.github.io/jq/" target="_blank" rel="noreferrer">jq</a> to process some data from the packages server, and <a href="https://linux.die.net/man/8/iptables" target="_blank" rel="noreferrer">iptables</a> to configure the firewall inside the container for Tailscale to run in a <a href="https://en.wikipedia.org/wiki/TUN/TAP" target="_blank" rel="noreferrer">TUN</a> device).</li><li>One to download Tailscale to the container.</li><li>One to start the Tailscale node agent <code>tailscaled</code>.</li><li>One to authenticate you to the tailnet with <a href="https://tailscale.com/kb/1241/tailscale-up/" target="_blank" rel="noreferrer"><code>tailscale up</code></a> and set other settings like <a href="https://tailscale.com/kb/1242/tailscale-serve/" target="_blank" rel="noreferrer"><code>tailscale serve</code></a>.</li></ul><div><p><img alt="the avatar for Xe Iaso" srcset="https://tailscale.dev/_next/image?url=%2Favatars%2Fxe.png&amp;w=64&amp;q=75 1x, https://tailscale.dev/_next/image?url=%2Favatars%2Fxe.png&amp;w=128&amp;q=75 2x" src="https://tailscale.dev/_next/image?url=%2Favatars%2Fxe.png&amp;w=128&amp;q=75" width="64" height="64" decoding="async" data-nimg="1" loading="lazy"></p><div><p>&lt;<b>Xe</b>&gt; </p><p>This is also hilarious because this roughly mirrors the process that you have to do on your host OS to get Tailscale running. This is another layer of invalid hierarchy because you expect containers to ship with all the software they need, but here is this container that needs to download software at runtime. This is funny because it's like a container that needs to download software at runtime, just like your host OS. As above, so below, eh?</p></div></div><p>Each of these is connected together like this (arrows indicate dependencies):</p><p><img alt="The s6 dependency web" src="https://tailscale.dev/images/universal-docker-mod/s6.svg" width="318" height="550" decoding="async" data-nimg="1" loading="lazy"></p><div><p><img alt="the avatar for Xe Iaso" srcset="https://tailscale.dev/_next/image?url=%2Favatars%2Fxe.png&amp;w=64&amp;q=75 1x, https://tailscale.dev/_next/image?url=%2Favatars%2Fxe.png&amp;w=128&amp;q=75 2x" src="https://tailscale.dev/_next/image?url=%2Favatars%2Fxe.png&amp;w=128&amp;q=75" width="64" height="64" decoding="async" data-nimg="1" loading="lazy"></p><div><p>&lt;<b>Xe</b>&gt; </p><p>If you've ever worked deeply with the Heroku ecosystem, you can think about Docker mods as akin to all of the hilarous hacks you can do with buildpacks at dyno boot time.</p></div></div><h2 id="configuration">Configuration</h2><p>The Docker mod exposes a bunch of environment variables that you can use to configure it. You can see the full list of environment variables in the <a href="https://github.com/tailscale-dev/docker-mod" target="_blank" rel="noreferrer">documentation</a>, but here are the important ones:</p><table><thead><tr><th>Environment Variable</th><th>Description</th><th>Example</th></tr></thead><tbody><tr><td><code>DOCKER_MODS</code></td><td>The list of additional mods to layer on top of the running container, separated by pipes.</td><td><code>ghcr.io/tailscale-dev/docker-mod:main</code></td></tr><tr><td><code>TAILSCALE_STATE_DIR</code></td><td>The directory where the Tailscale state will be stored, this should be pointed to a Docker volume. If it is not, then the node will set itself as ephemeral, making the node disappear from your tailnet when the container exits.</td><td><code>/var/lib/tailscale</code></td></tr><tr><td><code>TAILSCALE_AUTHKEY</code></td><td>The authkey for your tailnet. You can create one in the <a href="https://login.tailscale.com/admin/settings/keys" target="_blank" rel="noreferrer">admin panel</a>. See <a href="https://tailscale.com/kb/1085/auth-keys/" target="_blank" rel="noreferrer">here</a> for more information about authkeys and what you can do with them.</td><td><code>tskey-auth-hunter2CNTRL-hunter2hunter2</code></td></tr><tr><td><code>TAILSCALE_HOSTNAME</code></td><td>The hostname that you want to set for the container. If you don't set this, the hostname of the node on your tailnet will be a bunch of random hexadecimal numbers, which many humans find hard to remember.</td><td><code>wiki</code></td></tr><tr><td><code>TAILSCALE_USE_SSH</code></td><td>Set this to <code>1</code> to enable SSH access to the container.</td><td><code>1</code></td></tr><tr><td><code>TAILSCALE_SERVE_PORT</code></td><td>The port number that you want to expose on your tailnet. This will be the port of your DokuWiki, Transmission, or other container.</td><td><code>80</code></td></tr><tr><td><code>TAILSCALE_SERVE_MODE</code></td><td>The mode you want to run Tailscale serving in. This should be <code>https</code> in most cases, but there may be times when you need to enable <code>tls-terminated-tcp</code> to deal with some weird edge cases like HTTP long-poll connections. See <a href="https://tailscale.com/kb/1242/tailscale-serve/" target="_blank" rel="noreferrer">here</a> for more information.</td><td><code>https</code></td></tr><tr><td><code>TAILSCALE_FUNNEL</code></td><td>Set this to <code>true</code>, <code>1</code>, or <code>t</code> to enable <a href="https://tailscale.com/kb/1243/funnel/" target="_blank" rel="noreferrer">funnel</a>. For more information about the accepted syntax, please read the <a href="https://pkg.go.dev/strconv#ParseBool" target="_blank" rel="noreferrer">strconv.ParseBool documentation</a> in the Go standard library.</td><td><code>on</code></td></tr></tbody></table><p>Something important to keep in mind is that you really should set up a separate volume for Tailscale state. Here is how to do that with the docker commandline:</p><div><p><code><br><div><p><span>docker volume create dokuwiki-tailscale</span></p></div><br></code></p></div><p>Then you can mount it into a container by using the volume name instead of a host path:</p><div><p><code><br><div><p><span>docker run \</span></p></div><div><p><span>  ... \</span></p></div><div><p><span>  -v dokuwiki-tailscale:/var/lib/tailscale \</span></p></div><div><p><span>  ...</span></p></div><br></code></p></div><p>If you want to use kernel networking mode, you will need to add the <code>NET_ADMIN</code> and <code>NET_RAW</code> capabilities to the container, as well as pass the <a href="https://www.kernel.org/doc/Documentation/networking/tuntap.txt" target="_blank" rel="noreferrer"><code>/dev/net/tun</code></a> device into the container. Here is an example of how to do that with the docker commandline:</p><div><p><code><br><div><p><span>docker run \</span></p></div><div><p><span>  ... \</span></p></div><div><p><span>  --cap-add=NET_ADMIN \</span></p></div><div><p><span>  --cap-add=NET_RAW \</span></p></div><div><p><span>  --device=/dev/net/tun \</span></p></div><div><p><span>  ...</span></p></div><br></code></p></div><p>In a <code>compose.yaml</code> file, it will look like this:</p><div><p><code><br><div><p><span>version: '2.1'</span></p></div><div><p><span>services:</span></p></div><div><p><span>  dokuwiki:</span></p></div><div><p><span>    image: lscr.io/linuxserver/dokuwiki:latest</span></p></div><div><p><span>    volumes:</span></p></div><div><p><span>      - /dev/net/tun:/dev/net/tun</span></p></div><div><p><span>    cap_add:</span></p></div><div><p><span>      - NET_ADMIN</span></p></div><div><p><span>      - NET_RAW</span></p></div><div><p><span>    # ...</span></p></div><br></code></p></div><p>This can be useful when you are running applications on your tailnet <em>without</em> <a href="https://tailscale.com/kb/1242/tailscale-serve/" target="_blank" rel="noreferrer">tailscale serve</a>, and you want the underlying service to know the exact remote IP address (such as when running a Minecraft server).</p><h2 id="fun-things-you-can-do">Fun things you can do</h2><p>Normally when I write these articles, I tend to give you one functional example so that you can fill in the blanks here. This time, I want to give you a few functional and genuninely useful examples so that you can get started with our Docker mod right away.</p><p>If you want to test this with a simple command-line shell, you can run this docker command to create a volume for Tailscale state, and then run a container with the Docker mod installed:</p><div><p><code><br><div><p><span>docker volume create trap-sun-state</span></p></div><br></code></p></div> <div><p><img alt="the avatar for Xe Iaso" srcset="https://tailscale.dev/_next/image?url=%2Favatars%2Fxe.png&amp;w=64&amp;q=75 1x, https://tailscale.dev/_next/image?url=%2Favatars%2Fxe.png&amp;w=128&amp;q=75 2x" src="https://tailscale.dev/_next/image?url=%2Favatars%2Fxe.png&amp;w=128&amp;q=75" width="64" height="64" decoding="async" data-nimg="1" loading="lazy"></p><div><p>&lt;<b>Xe</b>&gt; </p><p><code>trap-sun</code> is the name of the container that we will be running. You can name it whatever you want, but you should use the same name in both your volume and your container. I'm setting the name here in case you get stuck and need to arbitrarily kill the container with <code>docker kill trap-sun</code>.</p></div></div><div><p><code><br><div><p><span>docker run \</span></p></div><div><p><span>  --rm \</span></p></div><div><p><span>  -v trap-sun-state:/var/lib/tailscale \</span></p></div><div><p><span>  -e TAILSCALE_STATE_DIR=/var/lib/tailscale \</span></p></div><div><p><span>  -e TAILSCALE_SERVE_PORT=3000 \</span></p></div><div><p><span>  -e TAILSCALE_SERVE_MODE=https \</span></p></div><div><p><span>  -e TAILSCALE_FUNNEL=on \</span></p></div><div><p><span>  -e TAILSCALE_USE_SSH=1 \</span></p></div><div><p><span>  -e TAILSCALE_HOSTNAME=trap-sun \</span></p></div><div><p><span>  -e TAILSCALE_AUTHKEY=tskey-auth-hunter2CNTRL-hunter2hunter2 \</span></p></div><div><p><span>  -e DOCKER_MODS=ghcr.io/tailscale-dev/docker-mod:main \</span></p></div><div><p><span>  --name trap-sun \</span></p></div><div><p><span>  -it \</span></p></div><div><p><span>  --cap-add=NET_ADMIN \</span></p></div><div><p><span>  --cap-add=NET_RAW \</span></p></div><div><p><span>  -v /dev/net/tun:/dev/net/tun \</span></p></div><div><p><span>  lsiobase/alpine:3.17 \</span></p></div><div><p><span>  sh</span></p></div><br></code></p></div> <div><p><img alt="the avatar for Xe Iaso" srcset="https://tailscale.dev/_next/image?url=%2Favatars%2Fxe.png&amp;w=64&amp;q=75 1x, https://tailscale.dev/_next/image?url=%2Favatars%2Fxe.png&amp;w=128&amp;q=75 2x" src="https://tailscale.dev/_next/image?url=%2Favatars%2Fxe.png&amp;w=128&amp;q=75" width="64" height="64" decoding="async" data-nimg="1" loading="lazy"></p><div><p>&lt;<b>Xe</b>&gt; </p><p>You can also base your Docker images on the <code>lscr.io/linuxserver/baseimage-alpine:3.17</code> image, which is a minimal <a href="https://alpinelinux.org/" target="_blank" rel="noreferrer">Alpine Linux</a> with Docker mod support. This can be used to adapt your existing containers into nodes on your tailnet. You can also use <a href="https://ubuntu.com/" target="_blank" rel="noreferrer">Ubuntu</a> with <code>lscr.io/linuxserver/baseimage-ubuntu:jammy</code> as the base image. The cloud's the limit!</p></div></div><h3 id="dokuwiki">DokuWiki</h3><p>If you want to set up a wiki for your tailnet with <a href="https://www.dokuwiki.org/dokuwiki" target="_blank" rel="noreferrer">DokuWiki</a>, you can use this Docker compose file:</p><div><p><code><br><div><p><span># docker-compose.yaml</span></p></div><div><p><span>version: '2.1'</span></p></div><div><p><span>services:</span></p></div><div><p><span>  dokuwiki:</span></p></div><div><p><span>    image: lscr.io/linuxserver/dokuwiki:latest</span></p></div><div><p><span>    container_name: dokuwiki</span></p></div><div><p><span>    environment:</span></p></div><div><p><span>      - PUID=1000</span></p></div><div><p><span>      - PGID=1000</span></p></div><div><p><span>      - TZ=Etc/UTC</span></p></div><div><p><span>      - DOCKER_MODS=ghcr.io/tailscale-dev/docker-mod:main</span></p></div><div><p><span>      # tailscale information</span></p></div><div><p><span>      - TAILSCALE_STATE_DIR=/var/lib/tailscale</span></p></div><div><p><span>      - TAILSCALE_SERVE_PORT=80</span></p></div><div><p><span>      - TAILSCALE_SERVE_MODE=https</span></p></div><div><p><span>      ## uncomment to enable funnel, may be a bad idea for some use cases</span></p></div><div><p><span>      #- TAILSCALE_FUNNEL=on</span></p></div><div><p><span>      - TAILSCALE_USE_SSH=1</span></p></div><div><p><span>      - TAILSCALE_HOSTNAME=wiki</span></p></div><div><p><span>      - TAILSCALE_AUTHKEY=tskey-auth-hunter2CNTRL-hunter2hunter2</span></p></div><div><p><span>    volumes:</span></p></div><div><p><span>      - dokuwiki-data:/config</span></p></div><div><p><span>      - dokuwiki-tailscale:/var/lib/tailscale</span></p></div><div><p><span>    restart: unless-stopped</span></p></div><div><p><span>volumes:</span></p></div><div><p><span>  dokuwiki-data:</span></p></div><div><p><span>  dokuwiki-tailscale:</span></p></div><br></code></p></div><p>Then use <code>docker compose up -d</code> to start the DokuWiki container with Tailscale grafted in. You can then access your DokuWiki instance at <code>https://wiki.yourtailnet.ts.net</code>. You will want to do the setup wizard, and then you can start using your own private wiki!</p><h3 id="your-private-cloud-development-environment-with-code-server">Your private cloud development environment with code-server</h3><p>Want to have all the fun of <a href="https://docs.github.com/en/codespaces/overview" target="_blank" rel="noreferrer">GitHub Codespaces</a> without having to use GitHub's servers for development? Set up your own private cloud with <a href="https://github.com/coder/code-server" target="_blank" rel="noreferrer">code-server</a> and Tailscale!</p><div><p><code><br><div><p><span>version: '2.1'</span></p></div><div><p><span>services:</span></p></div><div><p><span>  code-server:</span></p></div><div><p><span>    image: lscr.io/linuxserver/code-server:latest</span></p></div><div><p><span>    container_name: code-server</span></p></div><div><p><span>    environment:</span></p></div><div><p><span>      - PUID=1000</span></p></div><div><p><span>      - PGID=1000</span></p></div><div><p><span>      - TZ=Etc/UTC</span></p></div><div><p><span>      - PASSWORD=hunter2</span></p></div><div><p><span>      - PROXY_DOMAIN=code.shark-harmonic.ts.net</span></p></div><div><p><span>      - DOCKER_MODS=ghcr.io/tailscale-dev/docker-mod:main|ghcr.io/linuxserver/mods:code-server-nodejs|ghcr.io/linuxserver/mods:code-server-npmglobal</span></p></div><div><p><span>      # tailscale information</span></p></div><div><p><span>      - TAILSCALE_STATE_DIR=/var/lib/tailscale</span></p></div><div><p><span>      - TAILSCALE_SERVE_PORT=8443</span></p></div><div><p><span>      - TAILSCALE_SERVE_MODE=tls-terminated-tcp</span></p></div><div><p><span>      - TAILSCALE_USE_SSH=1</span></p></div><div><p><span>      - TAILSCALE_HOSTNAME=code</span></p></div><div><p><span>      - TAILSCALE_AUTHKEY=tskey-auth-hunter2CNTRL-hunter2hunter2</span></p></div><div><p><span>    volumes:</span></p></div><div><p><span>      - code-server-data:/config</span></p></div><div><p><span>      - code-server-tailscale:/var/lib/tailscale</span></p></div><div><p><span>    restart: unless-stopped</span></p></div><div><p><span>volumes:</span></p></div><div><p><span>  code-server-data:</span></p></div><div><p><span>  code-server-tailscale:</span></p></div><br></code></p></div><p>Then use <code>docker compose up -d</code> to start the code-server container with Tailscale grafted in. You can then access your code-server instance at <code>https://code.shark-harmonic.ts.net</code>. You may want to change the password from <a href="http://bash.org/?244321" target="_blank" rel="noreferrer"><code>hunter2</code></a> to something more secure.</p><p>code-server also has support for cloning repositories from GitHub directly, so with this you can get started hacking on a project on one machine, then seamlessly pick up where you left off on another! You can start hacking at something in your office and then walk over to the local Tim Horton's to finish it up!</p><hr><p>There's a bunch of other containers in the <a href="https://fleet.linuxserver.io/" target="_blank" rel="noreferrer">linuxserver.io fleet</a>, you can use Tailscale with those as well. You can also check out <a href="https://docs.linuxserver.io/general/awesome-lsio" target="_blank" rel="noreferrer">Awesome-LSIO</a> for more ideas!</p><p>At Tailscale, we want to recreate the Internet around the idea of small, trusted networks with your friends, family, and coworkers. When you set up applications on your tailnet like this, you can slowly start to use your own private infrastructure instead of relying on the public Internet. This is a great way to start using Tailscale, and we hope that you will find this Docker mod useful.</p><p>If you have any questions, feel free to reach out to us on <a href="https://twitter.com/tailscale" target="_blank" rel="noreferrer">Twitter</a> or <a href="https://hachyderm.io/@tailscale" target="_blank" rel="noreferrer">the Fediverse</a>. We are always happy to help!</p></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Zen 5's Leaked Slides (199 pts)]]></title>
            <link>https://chipsandcheese.com/2023/10/08/zen-5s-leaked-slides/</link>
            <guid>37812113</guid>
            <pubDate>Sun, 08 Oct 2023 16:49:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://chipsandcheese.com/2023/10/08/zen-5s-leaked-slides/">https://chipsandcheese.com/2023/10/08/zen-5s-leaked-slides/</a>, See on <a href="https://news.ycombinator.com/item?id=37812113">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>A YouTuber called Moore’s Law is Dead recently leaked a couple AMD slides about Zen 5. I typically find leaks uninteresting as they are impossible to verify and often don’t correspond to reality. One example is leakers expecting RDNA 3 to one-up Nvidia’s Ada architecture. AMD is fighting two larger competitors on two fronts and has not managed a decisive lead over Nvidia for more than a decade. AMD is expected to pull a miracle in the next generation, every generation (or two), and to everyone’s surprise it doesn’t happen.</p>
<div>
<figure><a href="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/09/zen5_mlid_slide.jpg?ssl=1"><img data-attachment-id="22284" data-permalink="https://chipsandcheese.com/2023/10/08/zen-5s-leaked-slides/zen5_mlid_slide/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/09/zen5_mlid_slide.jpg?fit=1265%2C698&amp;ssl=1" data-orig-size="1265,698" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="zen5_mlid_slide" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/09/zen5_mlid_slide.jpg?fit=1265%2C698&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/09/zen5_mlid_slide.jpg?fit=688%2C380&amp;ssl=1" decoding="async" width="688" height="380" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/09/zen5_mlid_slide.jpg?resize=688%2C380&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/09/zen5_mlid_slide.jpg?w=1265&amp;ssl=1 1265w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/09/zen5_mlid_slide.jpg?resize=768%2C424&amp;ssl=1 768w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/09/zen5_mlid_slide.jpg?resize=1200%2C662&amp;ssl=1 1200w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a></figure></div>
<p>However, this leak is worth a mention because it includes a slide with architecture information. I don’t know whether the leaked slides are genuine, however building a coherent picture with a lot of details is far more difficult than fabricating a few performance numbers. With that in mind, let’s dig a bit into the slides point by point. Instead of trying to validate or disprove the rumors, I’ll try to provide context for each point so you can reach your own conclusions.</p>
<h2>Branch Prediction</h2>
<p>Branch predictors steer a CPU’s pipeline, making them vital to both power efficiency and performance. If a branch predictor takes too long to guess where a branch is going, it could hold up the rest of the CPU pipeline. If it guesses wrong, the core will waste time and power doing useless work. The leaked slide brings up three points under the branch predictor, namely zero bubble conditional branches, high accuracy, and a larger BTB.</p>
<h3>Zero Bubble Conditional Branches</h3>
<p>“Zero bubble” branching refers to handling a branch without delaying subsequent instructions in the pipeline. If later instructions were delayed, it would be analogous to a gas bubble in a pipe carrying liquid. Too many bubbles reduce how much liquid the pipe is delivering, and can be a problem if your production is constrained by how much liquid that pipe can deliver.</p>
<div>
<figure><a href="https://chipsandcheese.com/a64fx_predictor/"><img data-attachment-id="22359" data-permalink="https://chipsandcheese.com/a64fx_predictor/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/a64fx_predictor.png?fit=822%2C634&amp;ssl=1" data-orig-size="822,634" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="a64fx_predictor" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/a64fx_predictor.png?fit=822%2C634&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/a64fx_predictor.png?fit=688%2C531&amp;ssl=1" decoding="async" width="688" height="531" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/a64fx_predictor.png?resize=688%2C531&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/a64fx_predictor.png?w=822&amp;ssl=1 822w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/a64fx_predictor.png?resize=768%2C592&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a><figcaption>A64FX branch prediction and fetch pipeline from the microarchitecture manual. Annotations added in red and green by Clam</figcaption></figure></div>
<p>AMD could already do zero bubble branching since Zen 1, even though few branches could be tracked by the zero bubble predictor. Zen 3 expanded the zero bubble BTB (cache of branch targets) to cover 1024 branches, making zero bubble branches the typical case. Zen 4 carries this forward and expands zero bubble BTB capacity to 1536 branch targets. Therefore, zero bubble branching is nothing new. Zero bubble conditional branches aren’t new either. On all Zen generations, zero bubble branching can happen regardless of whether the branch is conditional or unconditional.</p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=22279"><img data-attachment-id="22279" data-permalink="https://chipsandcheese.com/2023/10/08/zen-5s-leaked-slides/zen4_btb_latency_cond/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/09/zen4_btb_latency_cond.png?fit=944%2C487&amp;ssl=1" data-orig-size="944,487" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="zen4_btb_latency_cond" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/09/zen4_btb_latency_cond.png?fit=944%2C487&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/09/zen4_btb_latency_cond.png?fit=688%2C355&amp;ssl=1" decoding="async" width="688" height="355" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/09/zen4_btb_latency_cond.png?resize=688%2C355&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/09/zen4_btb_latency_cond.png?w=944&amp;ssl=1 944w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/09/zen4_btb_latency_cond.png?resize=768%2C396&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a><figcaption>Not a lot of difference between unconditional and conditional always-taken branches</figcaption></figure></div>
<p>AMD isn’t alone either. Intel’s Haswell could track 128 branches and handle them with no bubbles. Intel thus made zero bubble branch handling a common case well before AMD did. Since Zen 3, AMD has been able handle more branches with zero bubble speed, but Intel is still very respectable in this area.</p>
<p>Therefore “zero bubble conditional branches” is not an exciting point. Existing CPUs from Intel, Arm, and AMD themselves can already handle conditional branches with zero bubbles. Maybe Zen 5 increases zero bubble predictor capacity, but the slide did not say so.</p>
<h3>High Accuracy and Larger BTB</h3>
<p>AMD has improved branch predictor accuracy with every generation. Zen 2, 3, and 4 could often achieve<a href="https://chipsandcheese.com/2021/02/22/analyzing-zen-2s-cinebench-r15-lead/"> better branch prediction accuracy </a>than their Intel competitors. Zen 5 certainly looks to maintain that lead. But saying a desktop CPU has “high accuracy” branch prediction is like saying an airliner has a pressurized cabin. You expect it to, and it’s news if it doesn’t. Even older, simpler branch predictors like the ones on AMD’s Phenom CPUs could correctly predict the vast majority of branches.</p>
<p>BTB stands for “branch target buffer”, which is a cache of branch targets. If a branch’s target is cached, the predictor can tell the CPU where to fetch instructions from next without waiting for the branch instruction to reach the core. That reduces frontend latency especially if the branch instruction has to be fetched from L2 or beyond. AMD has tweaked BTB size with every generation, but is a step behind Intel’s best.</p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=11110"><img data-attachment-id="11110" data-permalink="https://chipsandcheese.com/2022/11/05/amds-zen-4-part-1-frontend-and-execution-engine/zen4_btb_compared/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2022/10/zen4_btb_compared.png?fit=1097%2C524&amp;ssl=1" data-orig-size="1097,524" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="zen4_btb_compared" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2022/10/zen4_btb_compared.png?fit=1097%2C524&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2022/10/zen4_btb_compared.png?fit=688%2C329&amp;ssl=1" decoding="async" loading="lazy" width="688" height="329" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2022/10/zen4_btb_compared.png?resize=688%2C329&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2022/10/zen4_btb_compared.png?w=1097&amp;ssl=1 1097w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2022/10/zen4_btb_compared.png?resize=768%2C367&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a></figure></div>
<p>Golden Cove’s L3 BTB has 50% more capacity than AMD’s last level L2 BTB, and <a href="https://chipsandcheese.com/2023/09/06/hot-chips-2023-characterizing-gaming-workloads-on-zen-4/">frontend latency is a problem</a> for Zen 4 in games. It’s likely a problem for Intel as well, and both companies will try to expand branch target caching capacity as transistor budget allows.</p>
<h3>2 Basic Block Fetch</h3>
<p>A basic block is a block of code with exactly one entry point and one exit point. A branch will terminate a basic block even if it’s conditional and not always taken. Existing AMD (and Intel) CPUs could already fetch across basic blocks because they could fetch across not-taken branches. The point on AMD’s slide could mean several things.</p>
<div>
<figure><img data-attachment-id="22384" data-permalink="https://chipsandcheese.com/2023/10/08/zen-5s-leaked-slides/basicblock_example/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/basicblock_example.png?fit=248%2C284&amp;ssl=1" data-orig-size="248,284" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="basicblock_example" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/basicblock_example.png?fit=248%2C284&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/basicblock_example.png?fit=248%2C284&amp;ssl=1" decoding="async" loading="lazy" width="248" height="284" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/basicblock_example.png?resize=248%2C284&amp;ssl=1" alt="" data-recalc-dims="1"><figcaption>Hypothetical basic block example. Assume nothing can jump into the middle of block1, and that the blocks are laid out consecutively in memory</figcaption></figure></div>
<p>The simplest and most likely explanation is that Zen 5 can fetch across basic blocks just as any high performance CPU made in the last 20 years could. Usually the most boring interpretation of a marketing statement is the correct one.</p>
<div>
<figure><a href="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/basicblock_fetch_across_not_taken.png?ssl=1"><img data-attachment-id="22386" data-permalink="https://chipsandcheese.com/2023/10/08/zen-5s-leaked-slides/basicblock_fetch_across_not_taken/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/basicblock_fetch_across_not_taken.png?fit=680%2C303&amp;ssl=1" data-orig-size="680,303" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="basicblock_fetch_across_not_taken" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/basicblock_fetch_across_not_taken.png?fit=680%2C303&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/basicblock_fetch_across_not_taken.png?fit=680%2C303&amp;ssl=1" decoding="async" loading="lazy" width="680" height="303" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/basicblock_fetch_across_not_taken.png?resize=680%2C303&amp;ssl=1" alt="" data-recalc-dims="1"></a><figcaption>CPUs can generally fetch across not-taken branch boundaries, thus fetching two basic blocks in a single cycle</figcaption></figure></div>
<p>Maybe Zen 5 can fetch across taken branches. Recent CPUs from Intel and Arm have done this. Rocket Lake could unroll small loops within its loop buffer, turning taken branches into not-taken ones from the fetch perspective. Arm’s Neoverse N2 and Cortex X2 can also sustain two taken branches per cycle by using a 64 entry nano-BTB. This capability can help improve frontend bandwidth for high IPC but branchy code. If an architectural feature has been around long enough to be implemented by multiple manufacturers, it has a better chance of showing up in a new core. Without being completely crazy, you could hope that Zen 5 can sustain more than one taken branch per cycle based on the leaked slide.</p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=22388"><img data-attachment-id="22388" data-permalink="https://chipsandcheese.com/2023/10/08/zen-5s-leaked-slides/basicblock_complicated_fetch/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/basicblock_complicated_fetch.png?fit=679%2C285&amp;ssl=1" data-orig-size="679,285" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="basicblock_complicated_fetch" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/basicblock_complicated_fetch.png?fit=679%2C285&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/basicblock_complicated_fetch.png?fit=679%2C285&amp;ssl=1" decoding="async" loading="lazy" width="679" height="285" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/basicblock_complicated_fetch.png?resize=679%2C285&amp;ssl=1" alt="" data-recalc-dims="1"></a><figcaption>Fetching across taken branches is harder and requires </figcaption></figure></div>
<p>Finally, there’s the daydream category. AMD previously advertised zero-bubble branch handling when it became the common case with Zen 3. They didn’t mention zero-bubble branch handling with Zen 1 or Zen 2, even though both had limited ability to do zero-bubble branches. Maybe Zen 5 can fetch across basic blocks in the common case instead of using a loop buffer or micro-BTB as Intel and Arm did. That likely requires a dual-ported instruction cache or micro-op cache alongside a large BTB capable of delivering two branch targets per cycle. Zen 5 would also need circuitry to merge two fetch blocks into a buffer that downstream stages can consume. I think implementing such a strategy makes little sense. It’d only help in high IPC code bound by frontend throughput. Frontend latency due to instruction cache misses is a bigger issue.</p>
<h2>Load/Store</h2>
<p>Every CPU generation tends to see memory subsystem changes to reduce and hide latency.</p>
<h3>Increased L1D Capacity</h3>
<p>The leaked slide says Zen 5 has a 48 KB 12-way set associative L1 data cache, giving it increased capacity and associativity compared to Zen 4’s 32 KB, 8-way L1D. Impressively, the slide claims latency stays at 4 cycles. Intel did the same with their L1 data cache in Sunny Cove, but increased latency from 4 to 5 cycles.</p>
<p>Zen 5’s larger L1D will enjoy increased hitrate. Higher capacity helps reduce cases where a code sequence’s working set exceeds cache capacity. Higher associativity helps prevent conflict misses where cache capacity is sufficient but too many “hot” addresses clash into the same set.</p>
<p>I’m surprised AMD was able to pull this off because 12-way associativity means a cache access involves 12 tag comparisons. Zen uses a micro-tagging scheme where partial tags are compared to predict which cache way (if any) will have a hit, but comparing 12 micro-tags is still no joke. The slide also says Zen 5 can do 4 loads per cycle. That would require 48 tag comparisons.</p>
<h3>Larger DTLB</h3>
<p>All modern CPUs use virtual memory. Program memory addresses don’t directly address locations on DRAM chips. Instead, the operating system sets up a map of virtual addresses to physical addresses (page tables) for each process. A misbehaving process therefore won’t run over everything else and force you to reboot the computer because it has limited access to system memory.</p>
<p>However, virtual memory addresses have to be translated to physical addresses. If the CPU checked the page tables for each memory access, latency would skyrocket as each program memory access turns into several dependent ones. Therefore, CPUs use TLBs (translation lookaside buffers) to cache frequently used translations.</p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=22360"><img data-attachment-id="22360" data-permalink="https://chipsandcheese.com/2023/10/08/zen-5s-leaked-slides/64bit_page_walk/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/64bit_page_walk.png?fit=1648%2C724&amp;ssl=1" data-orig-size="1648,724" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="64bit_page_walk" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/64bit_page_walk.png?fit=1648%2C724&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/64bit_page_walk.png?fit=688%2C302&amp;ssl=1" decoding="async" loading="lazy" width="688" height="302" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/64bit_page_walk.png?resize=688%2C302&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/64bit_page_walk.png?w=1648&amp;ssl=1 1648w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/64bit_page_walk.png?resize=768%2C337&amp;ssl=1 768w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/64bit_page_walk.png?resize=1536%2C675&amp;ssl=1 1536w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/64bit_page_walk.png?resize=1200%2C527&amp;ssl=1 1200w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/64bit_page_walk.png?resize=1600%2C703&amp;ssl=1 1600w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/64bit_page_walk.png?resize=1320%2C580&amp;ssl=1 1320w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/64bit_page_walk.png?w=1376&amp;ssl=1 1376w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a><figcaption>x86-64 4-level paging as described in Intel’s Developer Manual. Plain English comments added by Clam in red.</figcaption></figure></div>
<p>Zen 4 already enjoyed a first level data TLB size increase from 64 to 72 entries. Because of their small size, the first level TLB is fully associative. That eliminates conflict misses, but means any TLB entry could contain the desired translation. Four data cache accesses per cycle could require more than 72 * 4 = 288 TLB tag comparisons every cycle. I’m not sure how Zen 5 would increase the DTLB size without impacting latency unless AMD dropped the fully associative scheme.</p>
<p>I could see Zen 5 using a 16-way set associative DTLB with 128 entries or something along those lines. Checking it would be easier than with a 64 entry fully associative TLB, and the larger capacity could be enough to minimize conflict misses. Alternatively, Zen 5 could leave the first level DTLB untouched and increase L2 DTLB capacity. Zen 4 already brought L2 DTLB size up to 3072 entries compared to 2048 entries in Zen 3. Increasing L2 DTLB size would help programs with hot memory footprints in the multi-megabyte range.</p>
<h3>Larger PWC (Page Walk Cache)</h3>
<p>An address translation doesn’t have to be an all-or-nothing scenario where you either hit in the TLBs or do a full page walk. CPUs can cache upper level paging structures to reduce page walk latency when the TLBs can’t contain a program’s working set.</p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=22365"><img data-attachment-id="22365" data-permalink="https://chipsandcheese.com/2023/10/08/zen-5s-leaked-slides/64bit_page_walk_with_pwc/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/64bit_page_walk_with_pwc.png?fit=1694%2C684&amp;ssl=1" data-orig-size="1694,684" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="64bit_page_walk_with_pwc" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/64bit_page_walk_with_pwc.png?fit=1694%2C684&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/64bit_page_walk_with_pwc.png?fit=688%2C278&amp;ssl=1" decoding="async" loading="lazy" width="688" height="278" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/64bit_page_walk_with_pwc.png?resize=688%2C278&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/64bit_page_walk_with_pwc.png?w=1694&amp;ssl=1 1694w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/64bit_page_walk_with_pwc.png?resize=768%2C310&amp;ssl=1 768w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/64bit_page_walk_with_pwc.png?resize=1536%2C620&amp;ssl=1 1536w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/64bit_page_walk_with_pwc.png?resize=1200%2C485&amp;ssl=1 1200w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/64bit_page_walk_with_pwc.png?resize=1600%2C646&amp;ssl=1 1600w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/64bit_page_walk_with_pwc.png?resize=1320%2C533&amp;ssl=1 1320w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/64bit_page_walk_with_pwc.png?w=1376&amp;ssl=1 1376w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a><figcaption>Page walk cache implementations can vary. You can cache higher levels and cover more address space, or cache lower levels and shorten the page walk more.</figcaption></figure></div>
<p>That lets the page walker start at a lower level, letting a page walk complete with fewer memory accesses. Each page walk cache entry covers a larger region in memory than a TLB entry, making it ideal for handling programs with a larger memory footprint than the L2 DTLB can reasonably cover. For example, a cached page directory pointer table entry would cover 1 GB of address space.</p>
<p>I’ve seen a lot of Reddit comments where people said they didn’t understand my articles, so I can explain this in plain English with a real life analogy. Imagine you need to walk your dog down four blocks. You want it done faster. An obvious answer is to build a trebuchet that can throw you and your dog down two blocks. Then, you can start the walk closer to your destination. Because different destinations exist, you build 64 trebuchets facing in different directions. Now, you have a real life walk cache.</p>
<p>If you build more powerful trebuchets, you can start your walk closer to the destination. But less powerful ones can throw you places that are a short walk away to many destinations. You can build a lot of more powerful trebuchets but that would consume more area (and trees). CPU architects have to make the same tradeoff.</p>
<p>Since Zen 1, AMD has used a 64 entry page directory cache (PDC) that holds page directory pointer table and page map level 4 entries. L2 TLB entries can cache page directory entries. Perhaps Zen 5 finally increases PDC size. Or maybe, AMD gave the load/store unit a stronger preference for caching page directory entries in the L2 TLB compared to direct translations.</p>
<h2>High Throughput</h2>
<p>Zen generations have seen modest improvements in core throughput, because core throughput is typically not a limiting factor. Zen 1 and 2 could sustain 5 instructions per cycle, while Zen 3 and 4 could sustain 6 per cycle. AMD made double digit IPC gains every generation thanks to large improvements to instruction and data side memory access performance.</p>
<div>
<figure><a href="https://chipsandcheese.com/zen3_ipc_gain/"><img data-attachment-id="22523" data-permalink="https://chipsandcheese.com/zen3_ipc_gain/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/zen3_ipc_gain.png?fit=1276%2C713&amp;ssl=1" data-orig-size="1276,713" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="zen3_ipc_gain" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/zen3_ipc_gain.png?fit=1276%2C713&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/zen3_ipc_gain.png?fit=688%2C384&amp;ssl=1" decoding="async" loading="lazy" width="688" height="384" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/zen3_ipc_gain.png?resize=688%2C384&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/zen3_ipc_gain.png?w=1276&amp;ssl=1 1276w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/zen3_ipc_gain.png?resize=768%2C429&amp;ssl=1 768w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/zen3_ipc_gain.png?resize=1200%2C671&amp;ssl=1 1200w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a><figcaption>Slide from AMD’s Zen 3 Hot Chips presentation showing IPC gains largely coming from memory access improvements from both the data and instruction side</figcaption></figure></div>
<p>But a small minority of high IPC applications might benefit.</p>
<h3>8-Wide Dispatch/Rename</h3>
<p>Every Zen generation had at least an 8-wide frontend and 8-wide retire. However, the dispatch/rename stage was only 6 micro-ops wide. If Zen 5 makes rename/dispatch 8-wide, it would be able to sustain 8 micro-ops per cycle.</p>
<div>
<figure><img data-attachment-id="22526" data-permalink="https://chipsandcheese.com/samsung_mongoose_paper_ipc/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/samsung_mongoose_paper_ipc.png?fit=1233%2C511&amp;ssl=1" data-orig-size="1233,511" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="samsung_mongoose_paper_ipc" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/samsung_mongoose_paper_ipc.png?fit=1233%2C511&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/samsung_mongoose_paper_ipc.png?fit=688%2C285&amp;ssl=1" decoding="async" loading="lazy" width="688" height="285" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/samsung_mongoose_paper_ipc.png?resize=688%2C285&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/samsung_mongoose_paper_ipc.png?w=1233&amp;ssl=1 1233w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/samsung_mongoose_paper_ipc.png?resize=768%2C318&amp;ssl=1 768w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/samsung_mongoose_paper_ipc.png?resize=1200%2C497&amp;ssl=1 1200w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"><figcaption>From Samsung’s paper “Evolution of the Samsung Exynos CPU Microarchitecture”</figcaption></figure></div>
<p>This change will benefit a small minority of high IPC applications capped by core width. Lower IPC applications like games will see little benefit from this change because they’re primarily bound by cache and memory latency.</p>
<h3>Op Fusion</h3>
<p>CPUs can achieve higher throughput and make better use of internal buffers by fusing adjacent instructions into single micro-ops. Branch fusion is the most common example. Conditional branching on x86 involves using an instruction that sets flags, and then a branch that jumps (or not) depending on flags. Intel and AMD have been fusing such ALU + conditional branch pairs for many generations. Arm’s recent cores do the same for equivalent ARM64 sequences.</p>
<p>Zen 3 improved AMD’s fusion capabilities by allowing simple ALU instructions like ADD, AND, and XOR to be fused with a subsequent branch as well as CMP and TEST. Therefore one micro-op on Zen 3 can perform a math operation, check the result for a condition and branch on it, and write the result back to a register. Zen 4 added NOP fusion and XOR+DIV/CDQ+IDIV fusion. The latter handles common use patterns for x86’s division instructions.</p>
<p>Maybe Zen 5 expanded fusion cases, but the slide did not say so. For all we know, the slide could be reiterating the features already present on Zen 4. Prior Zen generations already covered the most common fusion cases (branches). Zen 4’s improvements chase diminishing returns. NOPs are used to align code and should account for a very small percentage of executed instruction. Division is known to be very expensive and avoided by most compilers. If Zen 5 adds fusion cases, it’ll probably pursue further diminishing returns.</p>
<h2>Larger, More Unified Scheduler</h2>
<p>Schedulers sit at the heart of an out-of-order CPU and let them achieve high instruction level parallelism. Every cycle, a scheduler has to watch what registers are written to and see if pending instructions need those inputs. It also has to select instructions that have all their inputs ready and send them to execution units. Failing to accomplish all that in a single cycle <a href="https://www.stuffedcow.net/files/henry-thesis-phd.pdf">incurs a ~10% IPC penalty</a>, so large, fast schedulers are very difficult to design. Small schedulers are easy to make fast but can fill quickly and prevent the core from hiding latency. Fortunately, engineers have a lot of scheduler layout options available.</p>
<p>In a distributed scheduler, each execution port gets its own private scheduler. That simplifies scheduler design because each scheduler only has to select one instruction for execution each cycle, and only needs enough entries to hold the fraction of pending instructions that are expected to be waiting for that port. However, tuning is difficult because one scheduler can fill and block the renamer even if scheduler entries are available elsewhere.</p>

<p>A unified scheduler avoids that problem by having one scheduler serve multiple ports. Each scheduler entry can hold an instruction destined for any port, so a sudden spike in demand for one execution port can be better tolerated. However, a unified scheduler has to select enough instructions per cycle to feed all the execution ports it’s attached to. There’s no free lunch.</p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=22399"><img data-attachment-id="22399" data-permalink="https://chipsandcheese.com/2023/10/08/zen-5s-leaked-slides/zen_sched-drawio/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/zen_sched.drawio.png?fit=622%2C546&amp;ssl=1" data-orig-size="622,546" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="zen_sched.drawio" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/zen_sched.drawio.png?fit=622%2C546&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/zen_sched.drawio.png?fit=622%2C546&amp;ssl=1" decoding="async" loading="lazy" width="622" height="546" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/zen_sched.drawio.png?resize=622%2C546&amp;ssl=1" alt="" data-recalc-dims="1"></a><figcaption>AMD’s Zen cores have used a mix of distributed and unified schedulers. There are multiple schedulers like with a distributed scheduler, but some schedulers serve multiple ports as in unified designs</figcaption></figure></div>
<p>AMD, Intel, and Arm’s recent CPUs use a hybrid of the two approaches. Zen 5’s scheduler is both larger and more unified, meaning it has more total entries and can use some of them more efficiently.</p>
<div>
<figure><a href="https://chipsandcheese.com/brp_dispatch_stall/"><img data-attachment-id="20619" data-permalink="https://chipsandcheese.com/brp_dispatch_stall/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/08/brp_dispatch_stall.png?fit=664%2C694&amp;ssl=1" data-orig-size="664,694" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="brp_dispatch_stall" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/08/brp_dispatch_stall.png?fit=664%2C694&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/08/brp_dispatch_stall.png?fit=664%2C694&amp;ssl=1" decoding="async" loading="lazy" width="664" height="694" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/08/brp_dispatch_stall.png?resize=664%2C694&amp;ssl=1" alt="" data-recalc-dims="1"></a><figcaption>What filled up and caused a renamer/dispatch stall in a couple of games</figcaption></figure></div>
<p>From a look at a <a href="https://chipsandcheese.com/2023/09/06/hot-chips-2023-characterizing-gaming-workloads-on-zen-4/">couple of gaming workloads</a>, integer scheduler 0 fills a bit more often than the others. Cinebench 2024 sees similar behavior on the integer side.</p>
<div>
<figure><a href="https://chipsandcheese.com/cb2024_sched_stall/"><img data-attachment-id="22419" data-permalink="https://chipsandcheese.com/cb2024_sched_stall/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/cb2024_sched_stall.png?fit=730%2C384&amp;ssl=1" data-orig-size="730,384" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="cb2024_sched_stall" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/cb2024_sched_stall.png?fit=730%2C384&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/cb2024_sched_stall.png?fit=688%2C362&amp;ssl=1" decoding="async" loading="lazy" width="688" height="362" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/cb2024_sched_stall.png?resize=688%2C362&amp;ssl=1" alt="" data-recalc-dims="1"></a></figure></div>
<p>Scheduler 0 feeds an AGU pipe and an ALU/branch pipe. AMD could chose to make this scheduler bigger or unify it with another scheduler. They could combine both approaches as well. However, scope for improvement may be limited. Integer scheduler related dispatch stalls account for single digit percentages, indicating Zen 4’s distributed scheduler is already well tuned.</p>
<h3>6 ALUs, 4 loads, 2 stores</h3>
<p>The slide says Zen 5 has 6 ALUs, and the ability to do 4 loads/2stores per cycle. ALUs, or arithmetic logic units, are execution units capable of handling the most common integer instructions like adds and bitwise operations. All prior Zen generations had four ALUs, so Zen 5 would increase per-cycle scalar integer throughput by 50%.</p>
<p>This change will have minimal effect. I put this section right after the scheduler one because schedulers will fill if the execution units can’t keep up with incoming operations. Schedulers can fill for reasons other than lack of execution ports as well. For example, a sequence of latency-bound instructions will also fill the schedulers. Scheduler-bound dispatch stalls are therefore an upper bound on how often the core is execution unit bound. From above, it doesn’t happen often.</p>
<p>Increased load/store throughput might help specific scenarios like memory copies, where the core can sustain 2 loads and 2 stores per cycle but how much this will effect general cases, I don’t know.</p>
<p>ALUs and AGUs themselves are tiny, but feeding them is more difficult. Each new execution port needs inputs from the register file, and increasing register file port count will increase area. More execution ports mean schedulers will have to pick more instructions per cycle, requiring more power and area as well. </p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=22482"><img data-attachment-id="22482" data-permalink="https://chipsandcheese.com/2023/10/08/zen-5s-leaked-slides/zen_alu_agu-drawio/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/zen_alu_agu.drawio.png?fit=593%2C172&amp;ssl=1" data-orig-size="593,172" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="zen_alu_agu.drawio" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/zen_alu_agu.drawio.png?fit=593%2C172&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/zen_alu_agu.drawio.png?fit=593%2C172&amp;ssl=1" decoding="async" loading="lazy" width="593" height="172" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/zen_alu_agu.drawio.png?resize=593%2C172&amp;ssl=1" alt="" data-recalc-dims="1"></a><figcaption>A not insanely expensive way to get to 6 ALUs and 4 loads/2 stores</figcaption></figure></div>
<p>If I were AMD and had to implement 6 ALUs and 4 AGUs, I would do so with the absolute minimum of extra ports. AGU ports can do double duty as ALU ports because AGUs already have to do simple math on register inputs anyway. The branch port can also be upgraded to an ALU, again reusing existing register file ports.</p>
<p>Increasing execution unit throughput will result in minimal gains, but minimal gains can be worthwhile if they are achieved at low cost. I suspect AMD is going after that route.</p>
<h2>Larger Structure Sizes</h2>
<p>An out-of-order CPU has structures to track instruction state until their results can be made final. Structure sizes tend to increase with every CPU generation. The leaked slide suggests Zen 5 will do so too, but did not go into specifics.</p>
<div>
<figure><img data-attachment-id="22423" data-permalink="https://chipsandcheese.com/cb2024_dispatch_stall/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/cb2024_dispatch_stall.png?fit=840%2C460&amp;ssl=1" data-orig-size="840,460" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="cb2024_dispatch_stall" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/cb2024_dispatch_stall.png?fit=840%2C460&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/cb2024_dispatch_stall.png?fit=688%2C377&amp;ssl=1" decoding="async" loading="lazy" width="688" height="377" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/cb2024_dispatch_stall.png?resize=688%2C377&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/cb2024_dispatch_stall.png?w=840&amp;ssl=1 840w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/cb2024_dispatch_stall.png?resize=768%2C421&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></figure></div>
<p>In Cinebench 2024 and the tested games, Zen 4’s reorder buffer is responsible for most stalls. The reorder buffer tracks all instructions in the backend until they are committed in-order. It’s a cap on how far ahead the CPU can move ahead of a stalled instruction. Filling the reorder buffer isn’t a bad thing because it means other queues for specific instruction categories are large enough to not become limitations themselves.</p>
<div>
<figure><a href="https://chipsandcheese.com/amd_rob_capacity/"><img data-attachment-id="22432" data-permalink="https://chipsandcheese.com/amd_rob_capacity/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/amd_rob_capacity.png?fit=705%2C379&amp;ssl=1" data-orig-size="705,379" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="amd_rob_capacity" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/amd_rob_capacity.png?fit=705%2C379&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/amd_rob_capacity.png?fit=688%2C370&amp;ssl=1" decoding="async" loading="lazy" width="688" height="370" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/amd_rob_capacity.png?resize=688%2C370&amp;ssl=1" alt="" data-recalc-dims="1"></a></figure></div>
<p>AMD has increased reorder buffer capacity with every CPU generation. Zen 5 will almost certainly see an increase as well, but we don’t know to what extent. Along with a reorder buffer capacity increase, AMD will have to augment other structures to prevent them from filling before the ROB does. The store queue could already use more entries and is a prime candidate for optimization. However, increasing store buffer size will be difficult because it has to hold pending store data. For Zen 4, that’s up to 32 bytes per store.</p>
<h3>64 Byte Fills/Victim</h3>
<p>This line on the slide talks about caching. “Fills” refers to cache fills, and “victim” refers to lines kicked out of a cache to make room for data being filled in. I’m confused because every CPU in recent history uses 64 byte cache lines, which means caches manage data at 64 byte granularity. Thus, data is evicted 64 bytes at a time, and brought in 64 bytes at a time. It’s not a point worth mentioning.</p>
<h2>Data Prefetching Improvements</h2>
<p>Better caching and higher reordering capacity help attack the memory latency problem by reducing latency and allowing execution to proceed past a latency-bound instruction, respectively. Prefetching counters memory latency by trying to get data that the program will need before an instruction asks for it. Again, the slide didn’t go into specifics, so I’ll provide context on what Zen 4 does.</p>
<div>
<figure><a href="https://chipsandcheese.com/zen4_pf-drawio/"><img data-attachment-id="22460" data-permalink="https://chipsandcheese.com/zen4_pf-drawio/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/zen4_pf.drawio.png?fit=747%2C185&amp;ssl=1" data-orig-size="747,185" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="zen4_pf.drawio" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/zen4_pf.drawio.png?fit=747%2C185&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/zen4_pf.drawio.png?fit=688%2C170&amp;ssl=1" decoding="async" loading="lazy" width="688" height="170" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/zen4_pf.drawio.png?resize=688%2C170&amp;ssl=1" alt="" data-recalc-dims="1"></a></figure></div>
<p>In Zen 4, AMD has prefetchers at the L1 and L2 level. Zen 5 may keep the same prefetch methods but allow them to prefetch further, taking advantage of any bandwidth increases offered by more mature DDR5 implementations. AMD may also tune the prefetchers to ensure demand requests get priority when there’s high bandwidth demand, such as during multi-core workloads.</p>
<h2>Better AVX-512</h2>
<p>Zen 4 featured AMD’s first AVX-512 implementation. Unlike AMD’s first SSE and AVX implementations, Zen 4 did not break instructions that operated on 512-bit vectors into two micro-ops. It had full width 512-bit vector registers, and kept AVX-512 math instructions as one micro-op until they were executed 256 bits at a time.</p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=22484"><img data-attachment-id="22484" data-permalink="https://chipsandcheese.com/2023/10/08/zen-5s-leaked-slides/zen4_avx512/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/zen4_avx512.png?fit=1271%2C713&amp;ssl=1" data-orig-size="1271,713" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="zen4_avx512" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/zen4_avx512.png?fit=1271%2C713&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/zen4_avx512.png?fit=688%2C386&amp;ssl=1" decoding="async" loading="lazy" width="688" height="386" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/zen4_avx512.png?resize=688%2C386&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/zen4_avx512.png?w=1271&amp;ssl=1 1271w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/zen4_avx512.png?resize=768%2C431&amp;ssl=1 768w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/zen4_avx512.png?resize=1200%2C673&amp;ssl=1 1200w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a><figcaption>From AMD’s presentation at ISSCC</figcaption></figure></div>
<p>Keeping the same FP execution throughput as Zen 2 and Zen 3 helped AMD get the most important AVX-512 benefits (more efficient use of backend resources) without a massive increase in die area and power.</p>
<p>The slide says “FP Pipes/Units at 512b”. The most optimistic interpretation is that Zen 5 has 2×512-bit FP vector execution. Even on TSMC’s newer 4 nm process, I feel that’ll cost too much area and power when most consumer applications don’t use 512-bit vectors. Perhaps AMD will create Zen 5 variants with different FP configurations as Intel has done, with client SKUs spending less area and power on vector FP throughput.</p>
<p>512-bit stores are handled less efficiently on Zen 4 because the store queue can only hold 256-bit pending store data with each entry. At Hot Chips 2023, AMD stated that the area overhead of buffering 512-bit store data was not acceptable. The leaked Zen 5 slide says “Load/Store Queues (512 bit)”, so AMD may have changed their stance. </p>
<p>Applications that heavily leverage 512-bit vectors should see more performance uplift on Zen 5 thanks to these changes.</p>
<h2>Final Words</h2>
<p>From the leaked slides, AMD is pursuing diminishing returns after getting most of the low hanging fruit with prior Zen generations. Zen 2 greatly improved branch prediction accuracy, vector throughput, and cache capacity compared to Zen 1. Zen 3’s improved BTB setup mitigated Zen 2’s frontend latency problem, and a reorganized scheduler avoids situations where Zen 2’s AGU scheduler fills up. Zen 4 brought a bigger micro-op cache, improved L2 capacity, a substantially increased out-of-order execution window, and AVX-512 support. Zen 5 appears to be going after more limited gains by increasing core throughput and providing a stronger AVX-512 implementation. </p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=22548"><img data-attachment-id="22548" data-permalink="https://chipsandcheese.com/2023/10/08/zen-5s-leaked-slides/zen4_ipc_uplift_breakdown/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/zen4_ipc_uplift_breakdown.png?fit=1278%2C718&amp;ssl=1" data-orig-size="1278,718" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="zen4_ipc_uplift_breakdown" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/zen4_ipc_uplift_breakdown.png?fit=1278%2C718&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/zen4_ipc_uplift_breakdown.png?fit=688%2C387&amp;ssl=1" decoding="async" loading="lazy" width="688" height="387" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/zen4_ipc_uplift_breakdown.png?resize=688%2C387&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/zen4_ipc_uplift_breakdown.png?w=1278&amp;ssl=1 1278w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/zen4_ipc_uplift_breakdown.png?resize=768%2C431&amp;ssl=1 768w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/zen4_ipc_uplift_breakdown.png?resize=1200%2C674&amp;ssl=1 1200w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a></figure></div>
<p>That said I would caution against looking too far into the current leaks. Specific details are rare, leaving plenty of wiggle room. Assuming Zen 5 is set in stone at this point is also perilous. Core behavior can be tuned via microcode updates. A core can be configurable as well, giving AMD the potential to make large changes even when the architecture is “complete”. We’ve seen AMD roll out Zen 2 variants with different FPU configurations. In the same video, MLiD showed another slide that suggests different FP-512 variants exist as well. </p>
<figure><img data-attachment-id="22466" data-permalink="https://chipsandcheese.com/zen5_mlid_slide1/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/zen5_mlid_slide1.jpg?fit=1259%2C693&amp;ssl=1" data-orig-size="1259,693" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="zen5_mlid_slide1" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/zen5_mlid_slide1.jpg?fit=1259%2C693&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/zen5_mlid_slide1.jpg?fit=688%2C379&amp;ssl=1" decoding="async" loading="lazy" width="688" height="379" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/zen5_mlid_slide1.jpg?resize=688%2C379&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/zen5_mlid_slide1.jpg?w=1259&amp;ssl=1 1259w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/zen5_mlid_slide1.jpg?resize=768%2C423&amp;ssl=1 768w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/zen5_mlid_slide1.jpg?resize=1200%2C661&amp;ssl=1 1200w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"><figcaption>Second slide shown by MLiD</figcaption></figure>
<p>Any performance numbers should be taken with a giant grain of salt too. It’s better to assume they are all guesses at this point. Even if a leaker has a “source”, estimating performance is inherently difficult because different applications will behave differently. An engineer might see a 30% IPC instruction uplift in simulation with a specific instruction trace, but that doesn’t mean other applications will enjoy the same improvement. </p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=22544"><img data-attachment-id="22544" data-permalink="https://chipsandcheese.com/2023/10/08/zen-5s-leaked-slides/zen4_ipc_uplift/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/zen4_ipc_uplift.jpg?fit=1975%2C549&amp;ssl=1" data-orig-size="1975,549" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="zen4_ipc_uplift" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/zen4_ipc_uplift.jpg?fit=1975%2C549&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/zen4_ipc_uplift.jpg?fit=688%2C191&amp;ssl=1" decoding="async" loading="lazy" width="688" height="191" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/zen4_ipc_uplift.jpg?resize=688%2C191&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/zen4_ipc_uplift.jpg?w=1975&amp;ssl=1 1975w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/zen4_ipc_uplift.jpg?resize=768%2C213&amp;ssl=1 768w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/zen4_ipc_uplift.jpg?resize=1536%2C427&amp;ssl=1 1536w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/zen4_ipc_uplift.jpg?resize=1200%2C334&amp;ssl=1 1200w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/zen4_ipc_uplift.jpg?resize=1600%2C445&amp;ssl=1 1600w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/zen4_ipc_uplift.jpg?resize=1320%2C367&amp;ssl=1 1320w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/zen4_ipc_uplift.jpg?w=1376&amp;ssl=1 1376w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a><figcaption>AMD’s slide</figcaption></figure></div>
<p>That could be mentioned to a leaker, who doesn’t understand that the trace may not be representative of most applications.</p>
<div>
<figure><a href="https://chipsandcheese.com/rgt_zen5_speculation/"><img data-attachment-id="22468" data-permalink="https://chipsandcheese.com/rgt_zen5_speculation/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/rgt_zen5_speculation.jpg?fit=1274%2C706&amp;ssl=1" data-orig-size="1274,706" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="rgt_zen5_speculation" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/rgt_zen5_speculation.jpg?fit=1274%2C706&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/rgt_zen5_speculation.jpg?fit=688%2C381&amp;ssl=1" decoding="async" loading="lazy" width="688" height="381" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/rgt_zen5_speculation.jpg?resize=688%2C381&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/rgt_zen5_speculation.jpg?w=1274&amp;ssl=1 1274w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/rgt_zen5_speculation.jpg?resize=768%2C426&amp;ssl=1 768w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/rgt_zen5_speculation.jpg?resize=1200%2C665&amp;ssl=1 1200w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a><figcaption>From a Red Gaming Tech video. 20-30% IPC gains sound very high considering AMD has managed 10-20% with Zen 2, Zen 3, and Zen 4. Certainly not impossible, but I would be skeptical after seeing the wild RDNA 3 rumored performance numbers.</figcaption></figure></div>
<p>Finally, engineers at Intel, AMD, Arm, and other companies put a lot of hard work into their products. It’s only fair to let them get their say when a product is released. If the engineers release a solid product that delivers a typical 10-20% generation on generation gain but everyone’s perception is set based on fabricated or misinterpreted early performance numbers, I think that’s disrespectful to the engineers. It’s also nonsensical when <a href="https://www.anandtech.com/show/9483/intel-skylake-review-6700k-6600k-ddr4-ddr3-ipc-6th-generation/9">Intel delivered lower generation on generation gains</a> at the top of their game in the early 2010s.</p>
<p>AMD is prone to this because they’re an underdog that people expect to one-up its bigger competitors, so fanciful rumors get a lot of attention. Whenever Zen 5 comes out, I would encourage everyone to look at its performance with respect to how Intel and other CPU manufacturers are progressing, and not based on rumors.</p>
<p>If you like our articles and journalism, and you want to support us in our endeavors, then consider heading over to our&nbsp;<a href="https://www.patreon.com/ChipsandCheese">Patreon</a>&nbsp;or our&nbsp;<a href="https://www.paypal.com/donate/?hosted_button_id=4EMPH66SBGVSQ">PayPal</a>&nbsp;if you want to toss a few bucks our way. If you would like to talk with the Chips and Cheese staff and the people behind the scenes, then consider joining our&nbsp;<a href="https://discord.gg/TwVnRhxgY2">Discord</a>.</p>

<div data-post_id="10949" data-instance_id="1" data-additional_class="pp-multiple-authors-layout-boxed.multiple-authors-target-the-content" data-original_class="pp-multiple-authors-boxes-wrapper pp-multiple-authors-wrapper box-post-id-10949 box-instance-id-1">

<ul>
<li>
<p><img alt="clamchowder" src="https://secure.gravatar.com/avatar/7c39d2e6d35e77c8fd15c4b2d9ce4e64?s=80&amp;d=identicon&amp;r=g" srcset="https://secure.gravatar.com/avatar/7c39d2e6d35e77c8fd15c4b2d9ce4e64?s=160&amp;d=identicon&amp;r=g 2x" height="80" width="80" loading="lazy" decoding="async"> </p>

</li>
</ul>
</div>





</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Scaling Knative to 100K+ Webapps (121 pts)]]></title>
            <link>https://render.com/blog/knative</link>
            <guid>37811814</guid>
            <pubDate>Sun, 08 Oct 2023 16:21:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://render.com/blog/knative">https://render.com/blog/knative</a>, See on <a href="https://news.ycombinator.com/item?id=37811814">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>Render takes your infrastructure problems away and gives you a battle-tested, powerful, and cost-effective cloud with an outstanding developer experience. Focus on building your apps, shipping fast, and delighting your customers, and leave your cloud infrastructure to us.</p><div><p>In November 2021, Render introduced a <a href="https://render.com/docs/free">free tier</a> for hobbyist developers and teams who want to kick the tires. Adoption grew at a steady, predictable rate—until Heroku announced the end of <em>their</em> free offering ten months later:</p>
<p><span>
<p><span>
      <span></span>
  <picture>
          <source srcset="https://render.com/static/0a7dee25a43efba6f5a5706350024c60/3122e/free-adoption-growth.webp 245w,
https://render.com/static/0a7dee25a43efba6f5a5706350024c60/eeaca/free-adoption-growth.webp 490w,
https://render.com/static/0a7dee25a43efba6f5a5706350024c60/285d6/free-adoption-growth.webp 980w,
https://render.com/static/0a7dee25a43efba6f5a5706350024c60/90fc6/free-adoption-growth.webp 1211w" sizes="(max-width: 980px) 100vw, 980px" type="image/webp">
          <source srcset="https://render.com/static/0a7dee25a43efba6f5a5706350024c60/232f7/free-adoption-growth.png 245w,
https://render.com/static/0a7dee25a43efba6f5a5706350024c60/9319d/free-adoption-growth.png 490w,
https://render.com/static/0a7dee25a43efba6f5a5706350024c60/2b72d/free-adoption-growth.png 980w,
https://render.com/static/0a7dee25a43efba6f5a5706350024c60/44079/free-adoption-growth.png 1211w" sizes="(max-width: 980px) 100vw, 980px" type="image/png">
          <img src="https://render.com/static/0a7dee25a43efba6f5a5706350024c60/2b72d/free-adoption-growth.png" alt="Graph of free-tier app creation" title="" loading="lazy" decoding="async">
        </picture>
    </span></p>
<p><sup><i>Comparison of Render free-tier apps <b>created</b> each week, late 2022</i></sup></p>
</span></p><p><strong>Render’s free-tier adoption rate doubled immediately and grew from there</strong> (awesome), causing our infrastructure to creak under the load (less awesome). In the span of a month, we experienced four incidents related to this surge. We knew that if Free usage continued to grow (and it very much has—as of this writing, <strong>tens of thousands</strong> of free-tier apps are created each week), we needed to make it much more scalable. This post describes the first step we took along that path.</p>
<h2 id="how-we-initially-built-free"><a href="#how-we-initially-built-free" aria-label="how we initially built free permalink"></a>How we initially built Free</h2>
<p>Some background: unlike other services on Render, free-tier web services “scale to zero” (as in, they stop running) if they go 15 minutes without receiving traffic. They start up again whenever they next receive an incoming request. This hibernation behavior helps us provide a no-cost offering without breaking the bank.</p>
<p>However, this desired behavior presented an immediate development challenge. Render uses Kubernetes (K8s) behind the scenes, and K8s didn’t natively support scale-to-zero (<a href="https://github.com/kubernetes/enhancements/pull/2022" target="_blank" rel="nofollow">it still doesn’t, as of September 2023</a>). In looking for a solution that did, we found and settled on <a href="https://knative.dev/docs/" target="_blank" rel="nofollow">Knative</a> (kay-NAY-tiv). Knative extended Kubernetes with serverless support—a natural fit for services that would regularly spin up and down.</p>
<p>In the interest of shipping quickly, we deployed Knative with its default configuration. And, until our growth spurt nearly a year later, those defaults worked without issue.</p>
<h2 id="where-we-hit-a-wall"><a href="#where-we-hit-a-wall" aria-label="where we hit a wall permalink"></a>Where we hit a wall</h2>
<p>With the free-tier surge, the total number of apps on Render effectively quadrupled. This put significant strain on the networking layer of each of our Kubernetes clusters. To understand the nature of that strain, let’s look at how this layer operates.</p>
<p>Two networking components run on every node in every cluster: <a href="https://github.com/projectcalico/calico" target="_blank" rel="nofollow">Calico</a> and <a href="https://kubernetes.io/docs/reference/command-line-tools-reference/kube-proxy/" target="_blank" rel="nofollow">kube-proxy</a>.</p>
<p><strong>Calico</strong> mainly takes care of IP address management, or IPAM: assigning IP addresses to Pods and Services (we’re using capital-S <strong>Service</strong> to refer to a <a href="https://kubernetes.io/docs/concepts/services-networking/service/" target="_blank" rel="nofollow">Kubernetes Service</a>, to distinguish from the services that customers create on Render.). It also enforces <a href="https://kubernetes.io/docs/concepts/services-networking/network-policies/" target="_blank" rel="nofollow">Network Policies</a> by managing iptables rules on the node.</p>
<p><strong>kube-proxy</strong> configures a different set of routing rules on the node to ensure traffic destined for a Service is load-balanced across all backing Pods.</p>
<p>Both of these components do their jobs by listening for creates, updates, and deletes to all Pods and Services in the cluster. As you can imagine, having <em>more</em> Pods and Services that changed <em>more</em> frequently resulted in <em>more</em> work:</p>
<ul>
<li>
<p><strong>More work meant more CPU consumption.</strong> Remember, both Calico and kube-proxy run on <em>every</em> node. The more CPU these components used, the less we had left to run our customers’ apps.</p>
</li>
<li>
<p><strong>More work meant higher update latency.</strong> As the work queue grew, each networking change took longer to propagate due to increased time spent waiting in the queue. This delay is defined as the <strong>network programming latency</strong>, or NPL (read more about NPL <a href="https://github.com/kubernetes/community/blob/master/sig-scalability/slos/network_programming_latency.md" target="_blank" rel="nofollow">here</a>). When there was high NPL, traffic could be routed using stale rules that led nowhere (the Pod had already been destroyed), causing connections to fail intermittently.</p>
</li>
</ul>
<p>To mitigate these issues, we needed to reduce the overhead each free-tier app added to our networking machinery.</p>
<h2 id="serviceless-knative"><a href="#serviceless-knative" aria-label="serviceless knative permalink"></a>“Serviceless” Knative</h2>
<p>As mentioned, we’d deployed out-of-the-box Knative to handle free-tier resource provisioning. We took a closer look at exactly <em>what</em> K8s primitives were being provisioned for each free-tier app:</p>
<ul>
<li>One Pod (for running the application code). Expected.</li>
<li><code>2N + 1</code> Services, where <code>N</code> is the number of times the app was deployed. This is because Knative manages changes with <a href="https://knative.dev/docs/concepts/serving-resources/revisions/" target="_blank" rel="nofollow">Revisions</a>, and retained resources belonging to historical Revisions. <i>Un</i>expected.</li>
</ul>
<p>We figured the Pod needed to stay, but did we really need all those Kubernetes Services? What if we could get away with fewer—or even zero?</p>
<p>We dove deeper into how those resources interacted in a cluster:</p>
<p><span>
<p><span>
      <span></span>
  <picture>
          <source srcset="https://render.com/static/7275f4971a15f8642a7380a8c9b15dfb/3122e/knative-free-before.webp 245w,
https://render.com/static/7275f4971a15f8642a7380a8c9b15dfb/eeaca/knative-free-before.webp 490w,
https://render.com/static/7275f4971a15f8642a7380a8c9b15dfb/285d6/knative-free-before.webp 980w,
https://render.com/static/7275f4971a15f8642a7380a8c9b15dfb/6fd4b/knative-free-before.webp 985w" sizes="(max-width: 980px) 100vw, 980px" type="image/webp">
          <source srcset="https://render.com/static/7275f4971a15f8642a7380a8c9b15dfb/232f7/knative-free-before.png 245w,
https://render.com/static/7275f4971a15f8642a7380a8c9b15dfb/9319d/knative-free-before.png 490w,
https://render.com/static/7275f4971a15f8642a7380a8c9b15dfb/2b72d/knative-free-before.png 980w,
https://render.com/static/7275f4971a15f8642a7380a8c9b15dfb/cdfe7/knative-free-before.png 985w" sizes="(max-width: 980px) 100vw, 980px" type="image/png">
          <img src="https://render.com/static/7275f4971a15f8642a7380a8c9b15dfb/2b72d/knative-free-before.png" alt="Knative defaults in Render K8s clusters" title="" loading="lazy" decoding="async">
        </picture>
    </span></p>
</span></p><p>And learned what each of the Knative-provisioned Services (in purple above) was for:</p>
<ul>
<li>The <strong>Placeholder Service</strong> was a dummy service that existed to prevent naming collisions among resources for Knative-managed apps. There was one for every free-tier app.</li>
<li>The <strong>Public Service</strong> routed incoming traffic to the app from the <em>public internet</em>.</li>
<li>The <strong>Private Service</strong> routed incoming <em>cluster-local</em> traffic based on whether the app was scaled up.
<ul>
<li><strong>If scaled up</strong>, traffic was routed to the Pod.</li>
<li><strong>If scaled down</strong>, traffic was routed to the cluster’s Knative proxy (called the <a href="https://knative.dev/docs/serving/knative-kubernetes-services/#service-activator" target="_blank" rel="nofollow">activator</a>), which handled scaling up the app by creating a Pod.</li>
</ul>
</li>
</ul>
<p>Armed with this newfound knowledge, we devised a path to remove all of these Services.</p>
<h3 id="step-by-step"><a href="#step-by-step" aria-label="step by step permalink"></a>Step by step</h3>
<p>We started simple with the dummy <strong>Placeholder Service</strong>, which did <em>literally nothing</em>. There was no risk of naming collisions among our Knative-managed resources, so we updated the Knative Route controller to stop creating the Placeholder Service. ❌</p>
<p>Next! While the <strong>Public Service</strong> (for public internet routing) is needed for plenty of Knative use cases out there, in Render-land, all requests from the public Internet must pass through our load-balancing layer. This means requests are guaranteed to be <em>cluster-local</em> by the time they reach Pods, so the <strong>Public Service</strong> <em>also</em> had nothing to do! We patched Knative to stop reconciling it and its related Endpoint resources. ❌</p>
<p>Finally, the <strong>Private Service</strong> (for cluster-local routing). We put together the concepts that Services are used to balance load across backing Pods, and that a free-tier app can have at most only one Pod receiving traffic at a time, making load balancing <em>slightly</em> unnecessary. There were two changes we needed to make:</p>
<ul>
<li>
<p>Streamline traffic to flow exclusively through the activator, as we no longer had a Service to split traffic to when the app is scaled up. With a little experimentation, we discovered that the activator could both wake Pods <em>and</em> reverse-proxy to a woke Pod, even though that behavior wasn’t documented! We just needed to set the right headers.</p>
</li>
<li>
<p>Patch the activator to listen for changes to Pod readiness states, and route directly to Pod IP addresses (thanks, Calico!). By default, the activator listens for changes to EndpointSlices, but those are tied to the Services we were hoping to delete. See the code additions in the diff:</p>
</li>
</ul>
<details>
<summary><strong>+ Click to show diff</strong></summary>
<div data-language="diff"><pre><code>diff --git a/pkg/activator/net/helpers.go b/pkg/activator/net/helpers.go
index 3a8e5ef49..0e7d5c3d0 100644
<span>--- a/pkg/activator/net/helpers.go</span>
<span>+++ b/pkg/activator/net/helpers.go</span>
@@ -92,6 +92,47 @@ func endpointsToDests(endpoints *corev1.Endpoints, portName string) (ready, notR
<span><span> </span>	return ready, notReady
<span> </span>}
</span>
<span><span>+</span>// podsToDests returns the pod's IP as the ready set if the pod is Ready,
<span>+</span>// and as the notReady set if not.
<span>+</span>func podsToDests(pods []*corev1.Pod) (_ready, _notReady sets.String) {
<span>+</span>	ready := sets.String{}
<span>+</span>	notReady := sets.String{}
<span>+</span>	// 8012 is the port of the queue-proxy container that runs alongside
<span>+</span>	// the user-server container.
<span>+</span>	port := "8012"
<span>+</span>	for _, pod := range pods {
<span>+</span>		if podIsReady(pod) {
<span>+</span>			for _, ip := range pod.Status.PodIPs {
<span>+</span>				ready.Insert(net.JoinHostPort(ip.IP, port))
<span>+</span>			}
<span>+</span>		} else {
<span>+</span>			for _, ip := range pod.Status.PodIPs {
<span>+</span>				notReady.Insert(net.JoinHostPort(ip.IP, port))
<span>+</span>			}
<span>+</span>		}
<span>+</span>
<span>+</span>	}
<span>+</span>	return ready, notReady
<span>+</span>}
<span>+</span>
<span>+</span>func podIsReady(pod *corev1.Pod) bool {
<span>+</span>	// This is the same logic that the K8s endpoints controller uses to list
<span>+</span>	// the Pod's IP under the Endpoint's `Addresses` (as opposed to `NotReadyAddresses`).
<span>+</span>	//
<span>+</span>	// https://github.com/kubernetes/kubernetes/blob/8a3f72074e6390f8f14a89a7b78cef4379737216/pkg/controller/endpoint/endpoints_controller.go#L624
<span>+</span>	//
<span>+</span>	// If we "mistime" it by interpreting the pod as ready before it is indeed
<span>+</span>	// ready, then the request that triggers scale-from-zero will always return
<span>+</span>	// some connection error, as the activator will try to reach the user-server
<span>+</span>	// container before it can serve requests.
<span>+</span>	for _, cond := range pod.Status.Conditions {
<span>+</span>		if cond.Type == corev1.PodReady &amp;&amp; cond.Status == corev1.ConditionTrue {
<span>+</span>			return true
<span>+</span>		}
<span>+</span>	}
<span>+</span>	return false
<span>+</span>}
<span>+</span>
</span><span><span> </span>// getServicePort takes a service and a protocol and returns the port number of
<span> </span>// the port named for that protocol. If the port is not found then ok is false.
<span> </span>func getServicePort(protocol networking.ProtocolType, svc *corev1.Service) (int, bool) {
</span>
diff --git a/pkg/activator/net/revision_backends.go b/pkg/activator/net/revision_backends.go
index 3d1524925..94758eae1 100644
<span>--- a/pkg/activator/net/revision_backends.go</span>
<span>+++ b/pkg/activator/net/revision_backends.go</span>
@@ -31,6 +31,8 @@ import (
<span><span> </span>	"go.uber.org/zap"
<span> </span>	"go.uber.org/zap/zapcore"
<span> </span>	"golang.org/x/sync/errgroup"
</span><span><span>+</span>	"k8s.io/apimachinery/pkg/labels"
<span>+</span>	podsinformer "knative.dev/pkg/client/injection/kube/informers/core/v1/pod"
</span>
<span><span> </span>	corev1 "k8s.io/api/core/v1"
<span> </span>	"k8s.io/apimachinery/pkg/types"
</span>@@ -47,6 +49,7 @@ import (
<span><span> </span>	"knative.dev/pkg/logging"
<span> </span>	"knative.dev/pkg/logging/logkey"
<span> </span>	"knative.dev/pkg/reconciler"
</span><span><span>+</span>
</span><span><span> </span>	"knative.dev/serving/pkg/apis/serving"
<span> </span>	revisioninformer "knative.dev/serving/pkg/client/injection/informers/serving/v1/revision"
<span> </span>	servinglisters "knative.dev/serving/pkg/client/listers/serving/v1"
</span>@@ -441,6 +444,7 @@ type revisionBackendsManager struct {
<span><span> </span>	ctx            context.Context
<span> </span>	revisionLister servinglisters.RevisionLister
<span> </span>	serviceLister  corev1listers.ServiceLister
</span><span><span>+</span>	podLister      corev1listers.PodLister
</span>
<span><span> </span>	revisionWatchers    map[types.NamespacedName]*revisionWatcher
<span> </span>	revisionWatchersMux sync.RWMutex
</span>@@ -466,6 +470,7 @@ func newRevisionBackendsManagerWithProbeFrequency(ctx context.Context, tr http.R
<span><span> </span>		ctx:              ctx,
<span> </span>		revisionLister:   revisioninformer.Get(ctx).Lister(),
<span> </span>		serviceLister:    serviceinformer.Get(ctx).Lister(),
</span><span><span>+</span>		podLister:        podsinformer.Get(ctx).Lister(),
</span><span><span> </span>		revisionWatchers: make(map[types.NamespacedName]*revisionWatcher),
<span> </span>		updateCh:         make(chan revisionDestsUpdate),
<span> </span>		transport:        tr,
</span>@@ -478,6 +483,7 @@ func newRevisionBackendsManagerWithProbeFrequency(ctx context.Context, tr http.R
<span><span> </span>	endpointsInformer.Informer().AddEventHandler(cache.FilteringResourceEventHandler{
<span> </span>		FilterFunc: reconciler.ChainFilterFuncs(
<span> </span>			reconciler.LabelExistsFilterFunc(serving.RevisionUID),
</span><span><span>+</span>			reconciler.Not(reconciler.LabelExistsFilterFunc(serving.RenderServicelessKey)),
</span><span><span> </span>			// We are only interested in the private services, since that is
<span> </span>			// what is populated by the actual revision backends.
<span> </span>			reconciler.LabelFilterFunc(networking.ServiceTypeKey, string(networking.ServiceTypePrivate), false),
</span>@@ -488,6 +494,18 @@ func newRevisionBackendsManagerWithProbeFrequency(ctx context.Context, tr http.R
<span><span> </span>			DeleteFunc: rbm.endpointsDeleted,
<span> </span>		},
<span> </span>	})
</span><span><span>+</span>	podsInformer := podsinformer.Get(ctx)
<span>+</span>	podsInformer.Informer().AddEventHandler(cache.FilteringResourceEventHandler{
<span>+</span>		FilterFunc: reconciler.ChainFilterFuncs(
<span>+</span>			reconciler.LabelExistsFilterFunc(serving.RevisionUID),
<span>+</span>			reconciler.LabelExistsFilterFunc(serving.RenderServicelessKey),
<span>+</span>		),
<span>+</span>		Handler: cache.ResourceEventHandlerFuncs{
<span>+</span>			AddFunc:    rbm.podUpdated,
<span>+</span>			UpdateFunc: controller.PassNew(rbm.podUpdated),
<span>+</span>			DeleteFunc: rbm.podDeleted,
<span>+</span>		},
<span>+</span>	})
</span>
<span><span> </span>	go func() {
<span> </span>		// updateCh can only be closed after revisionWatchers are done running
</span>@@ -566,6 +584,40 @@ func (rbm *revisionBackendsManager) endpointsUpdated(newObj interface{}) {
<span><span> </span>	}
<span> </span>}
</span>
<span><span>+</span>// podUpdated is a handler function to be used by the Endpoints informer.
<span>+</span>// It updates the endpoints in the RevisionBackendsManager if the hosts changed
<span>+</span>func (rbm *revisionBackendsManager) podUpdated(newObj interface{}) {
<span>+</span>	// Ignore the updates when we've terminated.
<span>+</span>	select {
<span>+</span>	case &lt;-rbm.ctx.Done():
<span>+</span>		return
<span>+</span>	default:
<span>+</span>	}
<span>+</span>	pod := newObj.(*corev1.Pod)
<span>+</span>	revID := types.NamespacedName{Namespace: pod.Namespace, Name: pod.Labels[serving.RevisionLabelKey]}
<span>+</span>
<span>+</span>	rw, err := rbm.getOrCreateRevisionWatcher(revID)
<span>+</span>	if err != nil {
<span>+</span>		rbm.logger.Errorw("Failed to get revision watcher", zap.Error(err), zap.String(logkey.Key, revID.String()))
<span>+</span>		return
<span>+</span>	}
<span>+</span>	selector, _ := labels.Parse(fmt.Sprintf("%s=%s", serving.RevisionLabelKey, pod.Labels[serving.RevisionLabelKey]))
<span>+</span>	allPods, err := rbm.podLister.Pods(pod.Namespace).List(selector)
<span>+</span>	if err != nil {
<span>+</span>		rbm.logger.Errorw("Failed to list pods belonging to revision", zap.Error(err), zap.String(logkey.Key, revID.String()))
<span>+</span>		return
<span>+</span>	}
<span>+</span>	ready, notReady := podsToDests(allPods)
<span>+</span>	select {
<span>+</span>	case &lt;-rbm.ctx.Done():
<span>+</span>		return
<span>+</span>	case rw.destsCh &lt;- dests{ready: ready, notReady: notReady}:
<span>+</span>	}
<span>+</span>}
<span>+</span>
</span><span><span> </span>// deleteRevisionWatcher deletes the revision watcher for rev if it exists. It expects
<span> </span>// a write lock is held on revisionWatchersMux when calling.
<span> </span>func (rbm *revisionBackendsManager) deleteRevisionWatcher(rev types.NamespacedName) {
</span>@@ -590,3 +642,7 @@ func (rbm *revisionBackendsManager) endpointsDeleted(obj interface{}) {
<span><span> </span>	defer rbm.revisionWatchersMux.Unlock()
<span> </span>	rbm.deleteRevisionWatcher(revID)
<span> </span>}
</span><span><span>+</span>
<span>+</span>func (rbm *revisionBackendsManager) podDeleted(obj interface{}) {
<span>+</span>	rbm.podUpdated(obj)
<span>+</span>}
</span>
diff --git a/pkg/apis/serving/register.go b/pkg/apis/serving/register.go
index 61a2e8b4a..c067f962b 100644
<span>--- a/pkg/apis/serving/register.go</span>
<span>+++ b/pkg/apis/serving/register.go</span>
@@ -25,6 +25,8 @@ const (
<span><span> </span>	// GroupNamePrefix is the prefix for label key and annotation key
<span> </span>	GroupNamePrefix = GroupName + "/"
</span>
<span><span>+</span>	RenderServicelessKey = "render.com/knative-serviceless"
<span>+</span>
</span><span><span> </span>	// ConfigurationLabelKey is the label key attached to a Revision indicating by
<span> </span>	// which Configuration it is created.
<span> </span>	ConfigurationLabelKey = GroupName + "/configuration"
</span></code></pre></div>
</details>
<p>And just like that, the <strong>Private Service</strong> was no more. ❌</p>
<p><span data-block="help">
<p>Want to go deeper under the hood? Check out an abridged version of <a href="https://render.com/blog/knative-design-doc">the design doc</a> for removing the <strong>Private Service</strong>.</p>
</span></p><p>At the end of this entire optimization pass, the networking architecture for a free-tier app had been simplified to the following:</p>
<p><span>
<p><span>
      <span></span>
  <picture>
          <source srcset="https://render.com/static/03fcde75139f0b9aa07c4fe09e551fa9/3122e/knative-free-after.webp 245w,
https://render.com/static/03fcde75139f0b9aa07c4fe09e551fa9/eeaca/knative-free-after.webp 490w,
https://render.com/static/03fcde75139f0b9aa07c4fe09e551fa9/a3fe1/knative-free-after.webp 656w" sizes="(max-width: 656px) 100vw, 656px" type="image/webp">
          <source srcset="https://render.com/static/03fcde75139f0b9aa07c4fe09e551fa9/232f7/knative-free-after.png 245w,
https://render.com/static/03fcde75139f0b9aa07c4fe09e551fa9/9319d/knative-free-after.png 490w,
https://render.com/static/03fcde75139f0b9aa07c4fe09e551fa9/abbf1/knative-free-after.png 656w" sizes="(max-width: 656px) 100vw, 656px" type="image/png">
          <img src="https://render.com/static/03fcde75139f0b9aa07c4fe09e551fa9/abbf1/knative-free-after.png" alt="Free-tier architecture after Knative Service removal" title="" loading="lazy" decoding="async">
        </picture>
    </span></p>
</span></p><p><em>Zero</em> Kubernetes Services per free-tier app! Predictably, K8s Service counts plummeted across our clusters:</p>
<p><span>
<p><span>
      <span></span>
  <picture>
          <source srcset="https://render.com/static/078632874886cd166c047c04eff4ac84/3122e/service-metrics-change.webp 245w,
https://render.com/static/078632874886cd166c047c04eff4ac84/eeaca/service-metrics-change.webp 490w,
https://render.com/static/078632874886cd166c047c04eff4ac84/285d6/service-metrics-change.webp 980w,
https://render.com/static/078632874886cd166c047c04eff4ac84/0c953/service-metrics-change.webp 1253w" sizes="(max-width: 980px) 100vw, 980px" type="image/webp">
          <source srcset="https://render.com/static/078632874886cd166c047c04eff4ac84/232f7/service-metrics-change.png 245w,
https://render.com/static/078632874886cd166c047c04eff4ac84/9319d/service-metrics-change.png 490w,
https://render.com/static/078632874886cd166c047c04eff4ac84/2b72d/service-metrics-change.png 980w,
https://render.com/static/078632874886cd166c047c04eff4ac84/c40ef/service-metrics-change.png 1253w" sizes="(max-width: 980px) 100vw, 980px" type="image/png">
          <img src="https://render.com/static/078632874886cd166c047c04eff4ac84/2b72d/service-metrics-change.png" alt="Chart of Service count by cluster over time" title="" loading="lazy" decoding="async">
        </picture>
    </span></p>
<p><sup><i>Change in K8s Service count in each Render cluster, November 2022</i></sup></p>
</span></p><p>With these improvements, Calico and kube-proxy’s combined usage fell by <strong>hundreds of CPU seconds</strong> in our largest cluster.</p>
<p><span>
<p><span>
      <span></span>
  <picture>
          <source srcset="https://render.com/static/3f257270780f098f95e4a7d3410d2dda/3122e/cpu-usage-change.webp 245w,
https://render.com/static/3f257270780f098f95e4a7d3410d2dda/eeaca/cpu-usage-change.webp 490w,
https://render.com/static/3f257270780f098f95e4a7d3410d2dda/b6870/cpu-usage-change.webp 570w" sizes="(max-width: 570px) 100vw, 570px" type="image/webp">
          <source srcset="https://render.com/static/3f257270780f098f95e4a7d3410d2dda/232f7/cpu-usage-change.png 245w,
https://render.com/static/3f257270780f098f95e4a7d3410d2dda/9319d/cpu-usage-change.png 490w,
https://render.com/static/3f257270780f098f95e4a7d3410d2dda/2cee3/cpu-usage-change.png 570w" sizes="(max-width: 570px) 100vw, 570px" type="image/png">
          <img src="https://render.com/static/3f257270780f098f95e4a7d3410d2dda/2cee3/cpu-usage-change.png" alt="Chart of CPU usage over time" title="" loading="lazy" decoding="async">
        </picture>
    </span></p>
<p><sup><i>CPU usage for Calico and kube-proxy in one Render cluster, November 2022</i></sup></p>
</span></p><p>With compute resources freed up, free-tier network latency and stability improved dramatically. But even so, we knew we had more work to do.</p>
<h2 id="a-moving-target"><a href="#a-moving-target" aria-label="a moving target permalink"></a>A moving target</h2>
<p>Our Knative tweaks bought us some much-needed breathing room, but ultimately, free-tier usage began to put a strain even on this optimized architecture. The time was quickly approaching for us to rip out Knative entirely, in favor of a home-grown solution that was tailor-made for Render’s needs.</p>
<p>But that’s a story for another post!</p>
<p>—</p>

<ul>
<li><a href="https://render.com/blog/knative-design-doc">Design doc for removing the <strong>Private Service</strong></a> (abridged)</li>
<li><a href="https://knative.dev/docs/concepts/" target="_blank" rel="nofollow">Knative documentation</a></li>
<li><a href="https://render.com/careers">Careers at Render</a> 😉</li>
</ul></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Flappy Dird: Flappy Bird Implemented in MacOS Finder (385 pts)]]></title>
            <link>https://eieio.games/nonsense/game-11-flappy-bird-finder/</link>
            <guid>37810144</guid>
            <pubDate>Sun, 08 Oct 2023 13:10:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://eieio.games/nonsense/game-11-flappy-bird-finder/">https://eieio.games/nonsense/game-11-flappy-bird-finder/</a>, See on <a href="https://news.ycombinator.com/item?id=37810144">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>I made a game. It’s called Flappy Dird. It’s Flappy Bird inside MacOS Finder.</p>

<div>
    <video playsinline="" controls="" muted="">
        <source src="https://eieio.games/assets/images/flappy-dird/vidlong.mp4">
    </video>
    <p>ad placements start at $2,000</p>
</div>

<p>It has instructions, high score tracking, and marquee banner ads. You double-click to start a game and select any file in the window to jump. It runs at 4 frames a second and can’t run much faster. It occasionally drops inputs for reasons that you’ll understand if you finish this blog.</p>

<p>I’m going to lay out how Flappy Dird works and how it got there. <a href="https://github.com/nolenroyalty/flappy-dird">Head to the github repo</a> if you want to check out the code or play the game yourself.
<!-- excerpt-end --></p>

<h2 id="idea-to-prototype">Idea to Prototype</h2>
<p>The original idea for Flappy Dird came when I noticed that Finder had a “Date Last Opened” field for directories. I knew that the <code>atime</code> (file access time) field was controversial (updating an inode on every file read is expensive!) and wanted to learn how similar date last opened was. I found a few things:</p>
<ol>
  <li>The field only updated when opened via Finder; <code>cd</code>ing didn’t update the timestamp.</li>
  <li>The field <em>did</em> update if you made a symlink to a directory and then double-clicked that symlink within Finder.</li>
  <li>The field was accessible (with second-level precision) via <code>mdls</code></li>
</ol>

<p>This got me pretty excited! I like <a href="https://eieio.games/nonsense/implementing-wordle-in-the-firefox-address-bar/">putting games in weird places</a>, and I realized I could combine those three facts to make a button! The basic idea:</p>
<ul>
  <li>Create a directory <code>dir</code>. Inside <code>dir</code> make a directory <code>button</code> that symlinks back to <code>dir</code>.</li>
  <li>On startup, read the ‘last opened’ timestamp of <code>dir</code>.</li>
  <li>Repeatedly poll the ‘last opened’ timestamp and do something when it changes.</li>
  <li>Open <code>button</code> (inside <code>dir</code>) to change the ‘last opened’ timestamp without changing your location in Finder.</li>
</ul>

<p>I brainstormed some ideas for iconic games that could be played with a single button and came up with Flappy Bird<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" rel="footnote">1</a></sup> pretty quickly. And then I started trying to figure out how I’d draw something like Flappy Bird in Finder.</p>

<p>I spent a while looking into making Finder’s font monospaced (to make ascii art easier) and measuring out the width of various ascii characters in Finder’s default font before realizing that I had a much better option: <em>emojis have a constant width and if you put them in filenames Finder will display them.</em></p>

<p><img src="https://eieio.games/assets/images/flappy-dird/emoji-names.png">
</p>
<p>emojis in filenames. the future is here.</p>

<p>So I had a way to accept clicks and a way to draw to the screen - enough for a prototype!</p>

<div>
    
    
    <video playsinline="" controls="" poster="https://eieio.games/assets/images/flappy-dird/flap-novsync-firstframe.png">
    
        <source src="https://eieio.games/assets/images/flappy-dird/flap-novsync.mp4" type="video/mp4">
    </video>
    
    <p> vsync does NOT work for emojis in Finder </p>
    
</div>

<p>The basic idea:</p>
<ul>
  <li>Set up <code>dir</code> so that it has 15 subdirectories that symlink back to <code>dir</code></li>
  <li>Wait until the player double-clicks a directory to start the game. Treat all future double clicks as flaps.</li>
  <li>Write a function from <code>bird_y_pos,pipe_locations,frame</code> to a 15x15 grid of emojis</li>
  <li>Every frame, rename every symlink in the directory to a row from our emoji grid.</li>
  <li>Do some hackery to rename the symlinks in the right order so that we can tell Finder to sort by ‘Date Modified’</li>
</ul>

<p>This works! But it’s really slow and the screen tears a lot. We can do better.</p>

<h2 id="vsync-at-home-applescript-and-double-buffering">Vsync at home: AppleScript and double buffering</h2>

<p>The biggest problem with the prototype was that the screen tearing was <em>bad</em>. I figured I’d try to get Finder to “refresh” the file listing in case the tearing was because it wasn’t updating frequently enough. I stumbled upon <a href="https://apple.stackexchange.com/questions/49543/is-there-a-way-to-refresh-a-finder-file-listing">this Stack Exchange question</a> which pointed me to the AppleScript invocation <code>tell application "Finder" to tell front window to update every item</code>.</p>

<p>This line helped a little bit (I still saw tearing), but more importantly it planted the seed of using AppleScript. It also delighted me - I find AppleScript totally bizarre. <a href="https://twitter.com/slomobo/status/1707521508308816148">slomobo made this joke on twitter</a> and it feels pretty correct:</p>

<p><img src="https://eieio.games/assets/images/flappy-dird/tweet.png">
</p>
<p>this is an image; i have no idea how to embed a tweet anymore</p>

<p>I shopped the tearing problem around to some smart friends and a bunch suggested that I find a way to do double buffering. The basic idea of double buffering<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" rel="footnote">2</a></sup> is:</p>
<ul>
  <li>Have two buffers, buf1 and buf2</li>
  <li>On frame 1, display buf1 and start writing your data for frame 2 to buf2.</li>
  <li>On frame 2, display buf2 all at once! And start writing your data for frame 3 to buf1.</li>
  <li>Etc.</li>
</ul>

<p>Or something like that. The point is that you avoid the jitter that comes from writing some but not all of the pixels of a new frame to the screen.</p>

<p>We came up with several ideas for how to do double buffering. The big ones were:</p>
<ul>
  <li>Use symlinks to atomically swap out the directory’s contents. This doesn’t work because you can’t expand the contents of a symlinked dir in Finder (you have to double-click on it, at which point Finder dereferences the symlink and won’t follow renames).</li>
  <li>Make two directories whose inner symlinks <em>point at each other</em>. This would solve the tearing problem but would mean that we could only advance a frame when the user clicked, which wouldn’t really work for this game.</li>
  <li>Magically find a way to make Finder display a different directory without changing the “last opened” timestamp.</li>
</ul>

<p>The winning solution came from my friend <a href="https://jakelazaroff.com/">Jake</a>, who suggested that AppleScript might have a way to control Finder. And it does! <code>tell application "Finder" to set target of front Finder window to ("PATH" POSIX file)</code> does exactly what you’d think.</p>



<p>I hacked together a double buffering implementation and got the game running smoothly at 1 frame per second! But 1 FPS is slow. We can do better.</p>

<h2 id="tapplescript-to-flapplescript">Tap(pleScript) to Flap(pleScript)</h2>

<p>The game couldn’t reasonably run above 1 FPS because our input mechanism (double-clicking a file) only had second-level precision - if Flappy Dird ran at 2 FPS you’d only be able to jump every other frame. So I needed a new way to accept input. At this point I figured that AppleScript was all-powerful and could tell me whether an item in Finder was selected. I checked and it totally could! I reworked the code to accept <em>selection</em> of any file in the window as a jump.</p>

<p>This worked well and even matched the original game better than double clicking. The game logic became something like:</p>
<ul>
  <li>Wait until the user double clicks</li>
  <li>On every frame, shell out to AppleScript and check whether the user has selected a file in the current window.</li>
  <li>If they have (or if the “last opened” timestamp has changed), make the bird jump.</li>
  <li>Shell out to AppleScript to change the directory displayed in Finder.</li>
  <li>Sleep so that we maintain a constant framerate (e.g. if the above steps took 0.1 seconds and we want to run at 2 FPS, sleep for 0.4 seconds).</li>
</ul>



<p>This could…kind of get us to 2 FPS. Except for one problem: AppleScript startup was <em>really really slow.</em> Like 0.2 seconds slow. Which meant:</p>
<ul>
  <li>There was no hope of going above 2 FPS, since we had fixed AppleScript costs of 0.4 seconds.</li>
  <li>When running at 2 FPS there was only a tiny window where you could actually tap a file - if you tapped the file after we shelled out to AppleScript to check whether you had tapped a file we’d miss the tap!</li>
</ul>

<p>So the game wasn’t super playable at 2 FPS. And 2 FPS still felt too slow. We can do better.</p>

<h2 id="rewrite-in-rust-applescript">Rewrite in <del>Rust</del> AppleScript</h2>

<p>I searched for ways to improve AppleScript’s startup speed. I compiled my AppleScripts (basically useless), entertained ideas like “writing an AppleScript RPC server,” and repeatedly googled “AppleScript improve startup speed” and “AppleScript preload script.”</p>

<p>Eventually I posted in the <a href="https://recurse.com/">Recurse Center</a> chat and my friend <a href="https://iangrunert.com/">Ian</a> pitched a few suggestions. One of his first suggestions, <em>“can you write the whole game in AppleScript?”</em>, went a little far<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" rel="footnote">3</a></sup> - but he also pitched inverting the control flow between my Python and AppleScript code: I could move my main loop to AppleScript while still shelling out to Python for most of the game logic, allowing me to only pay AppleScript’s startup cost once.</p>

<p>I was reluctant to do this because adding any amount of control flow to an AppleScript seemed hard - but I was also pretty excited to get to say “I rewrote it in AppleScript for speed.” Coming up with a way to communicate back from Python to AppleScript was tricky but I landed on something like:</p>
<div><pre><code><span>do shell script</span><span> </span><span>"game.py await"</span><span>

</span><span>set</span><span> </span><span>shouldContinue</span><span> </span><span>to</span><span> </span><span>"continue"</span><span>
</span><span>repeat</span><span> </span><span>while</span><span> </span><span>shouldContinue</span><span> </span><span>=</span><span> </span><span>"continue"</span><span>
    </span><span>do shell script</span><span> </span><span>"game.py start-frame"</span><span>
    </span><span>tell</span><span> </span><span>application</span><span> </span><span>"Finder"</span><span> </span><span>to</span><span> </span><span>set</span><span> </span><span>sel</span><span> </span><span>to</span><span> </span><span>selection</span><span>
    </span><span>set</span><span> </span><span>curBuf</span><span> </span><span>to</span><span> </span><span>do shell script</span><span> </span><span>"game.py tick "</span><span> </span><span>&amp;</span><span> </span><span>(</span><span>number</span><span> </span><span>of</span><span> </span><span>sel</span><span>)</span><span>
    </span><span>tell</span><span> </span><span>application</span><span> </span><span>"Finder"</span><span> </span><span>to</span><span> </span><span>set</span><span> </span><span>target</span><span> </span><span>of</span><span> </span><span>front</span><span> </span><span>¬
</span><span>        </span><span>Finder</span><span> </span><span>window</span><span> </span><span>to</span><span> </span><span>(</span><span>"DIR"</span><span> </span><span>&amp;</span><span> </span><span>curBuf</span><span> </span><span>as</span><span> </span><span>POSIX</span><span> </span><span>file</span><span>)</span><span>
    </span><span>set</span><span> </span><span>shouldContinue</span><span> </span><span>to</span><span> </span><span>do shell script</span><span> </span><span>"game.py sleep"</span><span>
</span><span>end</span><span> </span><span>repeat</span><span>
</span></code></pre></div>

<p>That is:</p>
<ul>
  <li>Wait for the user to double-click to start the game (<code>await</code>)</li>
  <li>Record the time at which we’re starting the frame (<code>start-frame</code>)</li>
  <li>Pass the number of files selected to <code>tick</code> to render the frame.</li>
  <li>Save the response from <code>tick</code> (which is the name of the directory we just prepared) and navigate to it in Finder.</li>
  <li>Sleep to achieve our target framerate and emit <code>continue</code> if the player hasn’t lost yet (so that we keep looping).</li>
</ul>

<p>This worked really well! Ian pointed out to me that <code>start-frame</code> and <code>sleep</code> can be easily combined, and I ended up adding <em>another</em> layer of looping to add a way to restart after you die, but this is the basic structure that the game still uses.</p>

<h2 id="adding-some-flavor">Adding some flavor</h2>

<p>The rest of the game was more straightforward - not necessarily easy, but it was just writing Python code to make the emojis on screen look right given some game state. A few notes about that process:</p>
<ul>
  <li>To store state during and between runs I made a little <code>state.json</code> file that I read/wrote every frame</li>
  <li>Adding text was hard because the text I chose was narrower than the emojis I was using. I used a lot of hardcoded spacing to make sure that things lined up correctly.</li>
  <li>Getting scrolling text across the top was particularly annoying because of the spacing - I ended up writing a function <code>read_n_ad_chars</code> to handle the guesswork around how many characters to show at a given time.</li>
  <li>I didn’t want to mess with relaying the working directory to AppleScript, so the script has a bunch of template variables that get swapped out by the <code>first-time-setup</code> Python invocation.</li>
  <li>AppleScript eats anything the python script outputs so I handled logging by appending to a file and catting it afterwards.</li>
  <li>You jump up an extra row if you tap on two successive frames, which I think makes the game feel a lot better.</li>
</ul>

<p>The hardest bit here was the scrolling banner text. It was particularly tricky because I couldn’t use a debugger since the script was being invoked via AppleScript<sup id="fnref:4" role="doc-noteref"><a href="#fn:4" rel="footnote">4</a></sup>.</p>

<h2 id="wrapping-up">Wrapping up</h2>

<p>I loved making this. One thing I found particularly delightful was how simple writing the Python for this game was. The prototype was ~90 lines of code (it’s now ~550 lines but like a third of it is boilerplate or constants)! I did it all in vim! No clicking at all! It was great to work without an engine and keep all of my frame state in tiny 2D array. It was easy to keep the whole game in my head from start to finish (even as the control flow got wonkier). The experience made me excited to try making something bigger without an engine.</p>

<p>I presented an early iteration of Flappy Dird at <a href="https://recurse.com/">Recurse Center</a> and spent a whole lot more time on it because of the response it got during that presentation. Thanks so much to the folks at Recurse for the encouragement, especially since I was presenting 2 weeks after I “never graduated” (Recurse’s word for finishing a batch). If being encouraged to make nonsense like this sounds fun to you you should consider <a href="https://www.recurse.com/apply">applying!</a> And a special thank you to <a href="https://twitter.com/kelin_online">Kelin</a> for telling me that the banner ads should be pulled by a little plane emoji.</p>

<p>4 frames a second and limited input is a pretty big constraint but I think that it’d be feasible to build some other games this way. Some <a href="https://mastodon.gamedev.place/@eieio/111190521120302217">folks on mastodon</a> suggested building Tetris in Finder and I think that’s hard but feasible. If you want to chat about this please <a href="https://eieio.games/whats-my-deal">get in touch!</a> I’ve been particularly enjoying <a href="https://cohost.org/eieio">cohost</a> for gamedev chatting but I’m all over.</p>

<p>I’m currently on vacation (I wrote this on a train from Busan to Seoul) but I’ll be back with some more nonsense in November :)</p>



  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Fastest sailboat: Two wild designs (165 pts)]]></title>
            <link>https://newatlas.com/marine/syroco-sp80-testing/</link>
            <guid>37810068</guid>
            <pubDate>Sun, 08 Oct 2023 13:00:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://newatlas.com/marine/syroco-sp80-testing/">https://newatlas.com/marine/syroco-sp80-testing/</a>, See on <a href="https://news.ycombinator.com/item?id=37810068">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>The SP80 and Syroco teams have both got their remarkable boats on the water. Looking like a pair of alien spaceships, and pulled by ultra-fast kites instead of sails on masts, both these machines are built to reach terrifying, unprecedented speeds.</p><p>The current world sailing speed record has stood for a little over a decade at 65.37 knots (75.23 mph/121.06 km/h), set by Paul Larsen in the <a href="https://newatlas.com/new-world-speed-sailing-record-6537kts-75mph-121kmh/25065/" data-cms-ai="0">Vestas Sailrocket II</a> back in 2012. </p><p>There's a reason nobody's gone faster – rigid masts provide excellent leverage, so when you attempt to harness serious wind power, they want to roll the boat over. So if those record speed figures seem a bit 'meh,' take a look at the video below.</p><div data-video-disable-history="" data-align-center="">
    
        <p><ps-youtubeplayer data-video-player="" data-player-id="f710207866bda444591398cf870ae7e27" data-video-id="wnjyusAgk8I" data-video-title="VESTAS Sailrocket 2  Outright world speed sailing record holder. (subject to WSSRC ratification)">

    <iframe id="YouTubeVideoPlayer-f710207866bda444591398cf870ae7e27" role="application" title="YouTube embedded video player" allowfullscreen="" loading="lazy" src="https://www.youtube.com/embed/wnjyusAgk8I?enablejsapi=1"></iframe>
</ps-youtubeplayer>
</p>
    
    
        <p>VESTAS Sailrocket 2  Outright world speed sailing record holder. (subject to WSSRC ratification)</p>
    
</div><p>But records are made to be broken, and both the SP80 and Syroco teams are taking radically different approaches to Larsen's. Both teams have set a target speed of 81 knots (93 mph/150 km/h), hoping to absolutely smash the record, both are using huge kites, attached to the boats on strong lines, to avoid capsizing, and both have come a long way since <a href="https://newatlas.com/marine/sp80-syroco-speed-sailing-record/" data-cms-ai="0">we first examined these designs in 2021</a>.</p><p>If this was a beauty contest, it'd go to the SP80 hands down. You could 3D-model this sleek, elegant trimaran, reskin it in silver, stick Naboo in the background and get Natalie Portman to pop out of the cabin for a Star Wars flick. </p><div data-align-center="">
                
                    <figure>
    
    
    
    


<p><img alt="The SP80 is lowered into the smooth waters of Lake Geneva" width="1440" height="960" data-image-size="articleImage" loading="lazy" data-srcset="https://assets.newatlas.com/dims4/default/841db33/2147483647/strip/true/crop/2000x1333+0+0/resize/440x293!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2Fc1%2F22%2F929b5c604bf687ee5aa4d394e481%2Fbqsp80-31juillet-stills-40.jpg 440w,https://assets.newatlas.com/dims4/default/d2bee51/2147483647/strip/true/crop/2000x1333+0+0/resize/800x533!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2Fc1%2F22%2F929b5c604bf687ee5aa4d394e481%2Fbqsp80-31juillet-stills-40.jpg 800w,https://assets.newatlas.com/dims4/default/dc984d7/2147483647/strip/true/crop/2000x1333+0+0/resize/1200x800!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2Fc1%2F22%2F929b5c604bf687ee5aa4d394e481%2Fbqsp80-31juillet-stills-40.jpg 1200w,https://assets.newatlas.com/dims4/default/524a36d/2147483647/strip/true/crop/2000x1333+0+0/resize/1920x1280!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2Fc1%2F22%2F929b5c604bf687ee5aa4d394e481%2Fbqsp80-31juillet-stills-40.jpg 1920w" data-src="https://assets.newatlas.com/dims4/default/39f18e4/2147483647/strip/true/crop/2000x1333+0+0/resize/1440x960!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2Fc1%2F22%2F929b5c604bf687ee5aa4d394e481%2Fbqsp80-31juillet-stills-40.jpg" sizes="(min-width: 1240px) 800px, (min-width: 1024px) 95vw, 100vw" srcset="https://assets.newatlas.com/dims4/default/841db33/2147483647/strip/true/crop/2000x1333+0+0/resize/440x293!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2Fc1%2F22%2F929b5c604bf687ee5aa4d394e481%2Fbqsp80-31juillet-stills-40.jpg 440w,https://assets.newatlas.com/dims4/default/d2bee51/2147483647/strip/true/crop/2000x1333+0+0/resize/800x533!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2Fc1%2F22%2F929b5c604bf687ee5aa4d394e481%2Fbqsp80-31juillet-stills-40.jpg 800w,https://assets.newatlas.com/dims4/default/dc984d7/2147483647/strip/true/crop/2000x1333+0+0/resize/1200x800!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2Fc1%2F22%2F929b5c604bf687ee5aa4d394e481%2Fbqsp80-31juillet-stills-40.jpg 1200w,https://assets.newatlas.com/dims4/default/524a36d/2147483647/strip/true/crop/2000x1333+0+0/resize/1920x1280!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2Fc1%2F22%2F929b5c604bf687ee5aa4d394e481%2Fbqsp80-31juillet-stills-40.jpg 1920w" src="https://assets.newatlas.com/dims4/default/39f18e4/2147483647/strip/true/crop/2000x1333+0+0/resize/1440x960!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2Fc1%2F22%2F929b5c604bf687ee5aa4d394e481%2Fbqsp80-31juillet-stills-40.jpg">
</p>



    
    

    
        <div><figcaption itemprop="caption">The SP80 is lowered into the smooth waters of Lake Geneva</figcaption><p>SP80</p></div>
    
</figure>

                
            </div><p>This 10.5-m (34.4-ft) design seats two in tandem – one in the back seat to work the kite attached to a control arm behind the cabin, and one to steer the thing. The design is focused around keeping the three hulls in contact with the water, so the high-speed airflow doesn't flip it over.</p><p>In August, the SP80 team took it out on Lake Geneva, where it did 30 knots being pulled behind a boat, to check drag measurements against the team's computer-modeled predictions. Check it out:</p><div data-video-disable-history="" data-align-center="">
    
        <p><ps-youtubeplayer data-video-player="" data-player-id="f214d2aca14514d6e839be155251e8356" data-video-id="39q23l1Hmgc" data-video-title="Le bateau a touché l'eau sur le Léman&nbsp;!">

    <iframe id="YouTubeVideoPlayer-f214d2aca14514d6e839be155251e8356" role="application" title="YouTube embedded video player" allowfullscreen="" loading="lazy" src="https://www.youtube.com/embed/39q23l1Hmgc?enablejsapi=1"></iframe>
</ps-youtubeplayer>
</p>
    
    
        <p>Le bateau a touché l'eau sur le Léman&nbsp;!</p>
    
</div><p>The team is now working on getting the sail part happening, starting small, and then increasing the size, power and speed incrementally over time.</p><p>As for Syroco, well, it almost feels silly calling this thing a boat at all. The team calls it a "weightless yacht," but effectively it's a kite on a line running more or less straight down into the water, where it attaches to a hydrofoil wing. As the foil and the kite pull against each other, the line is pulled taut.</p><div data-align-center="">
                
                    <figure>
    
    
    
    


<p><img alt="Syroco's #1 challenge is to design a supercavitating hydrofoil that won't produce shuddering instability" width="1280" height="640" data-image-size="articleImage" loading="lazy" data-srcset="https://assets.newatlas.com/dims4/default/3499590/2147483647/strip/true/crop/1280x640+0+0/resize/440x220!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2F6c%2Fb5%2Fa853939d439f8900ab8abb7a28bd%2F123334930-373768407409261-2390544981432492216-n.jpg 440w,https://assets.newatlas.com/dims4/default/f5b7878/2147483647/strip/true/crop/1280x640+0+0/resize/800x400!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2F6c%2Fb5%2Fa853939d439f8900ab8abb7a28bd%2F123334930-373768407409261-2390544981432492216-n.jpg 800w,https://assets.newatlas.com/dims4/default/4dd7e27/2147483647/strip/true/crop/1280x640+0+0/resize/1200x600!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2F6c%2Fb5%2Fa853939d439f8900ab8abb7a28bd%2F123334930-373768407409261-2390544981432492216-n.jpg 1200w,https://assets.newatlas.com/dims4/default/b105e34/2147483647/strip/true/crop/1280x640+0+0/resize/1920x960!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2F6c%2Fb5%2Fa853939d439f8900ab8abb7a28bd%2F123334930-373768407409261-2390544981432492216-n.jpg 1920w" data-src="https://assets.newatlas.com/dims4/default/94bf3c4/2147483647/strip/true/crop/1280x640+0+0/resize/1280x640!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2F6c%2Fb5%2Fa853939d439f8900ab8abb7a28bd%2F123334930-373768407409261-2390544981432492216-n.jpg" sizes="(min-width: 1240px) 800px, (min-width: 1024px) 95vw, 100vw" srcset="https://assets.newatlas.com/dims4/default/3499590/2147483647/strip/true/crop/1280x640+0+0/resize/440x220!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2F6c%2Fb5%2Fa853939d439f8900ab8abb7a28bd%2F123334930-373768407409261-2390544981432492216-n.jpg 440w,https://assets.newatlas.com/dims4/default/f5b7878/2147483647/strip/true/crop/1280x640+0+0/resize/800x400!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2F6c%2Fb5%2Fa853939d439f8900ab8abb7a28bd%2F123334930-373768407409261-2390544981432492216-n.jpg 800w,https://assets.newatlas.com/dims4/default/4dd7e27/2147483647/strip/true/crop/1280x640+0+0/resize/1200x600!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2F6c%2Fb5%2Fa853939d439f8900ab8abb7a28bd%2F123334930-373768407409261-2390544981432492216-n.jpg 1200w,https://assets.newatlas.com/dims4/default/b105e34/2147483647/strip/true/crop/1280x640+0+0/resize/1920x960!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2F6c%2Fb5%2Fa853939d439f8900ab8abb7a28bd%2F123334930-373768407409261-2390544981432492216-n.jpg 1920w" src="https://assets.newatlas.com/dims4/default/94bf3c4/2147483647/strip/true/crop/1280x640+0+0/resize/1280x640!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2F6c%2Fb5%2Fa853939d439f8900ab8abb7a28bd%2F123334930-373768407409261-2390544981432492216-n.jpg">
</p>



    
    

    
        <div><figcaption itemprop="caption">Syroco's #1 challenge is to design a supercavitating hydrofoil that won't produce shuddering instability</figcaption><p>Syroco</p></div>
    
</figure>

                
            </div><p>Somewhere in the middle of that line is a sort of roughly shark-shaped hull and cabin, which is hoisted right out of the water, such that it dangles a few meters up in the air as the boat sails. This has to be the first hydrofoiling boat design I've seen where the hull and the foil are connected by a flexible high-tension line and not a solid support.</p><p><a href="https://newatlas.com/tag/hydrofoil/" data-cms-ai="0">Hydrofoils</a> are naturally speed-limited to around 100 km/h (62 mph) by a process called cavitation, in which the hydrofoil wing creates a high-pressure zone on one side, and a low-pressure zone on the other, and the low-pressure zone gets so low that water starts to vaporize, creating enormous drag. You can <a href="https://newatlas.com/marine/sp80-syroco-speed-sailing-record/" data-cms-ai="0">check out our earlier piece</a> to learn more about how Syroco plans to get past this speed limit, it's pretty out there.</p><p>This team has actually had prototypes flying since the end of 2021. At first, the kite was replaced by a crane arm attached to a support boat, but now it's up and flying solely on wind power, with a small kite attached. And it's possibly just the low wind speeds they're testing in, but my dear god, this thing looks sketchy as hell. Take a look:</p><div data-video-disable-history="" data-align-center="">
    
        <p><ps-youtubeplayer data-video-player="" data-player-id="f782404d013b2415280f82019e3aa283d" data-video-id="WpmgVO5uSs8" data-video-title="On the Road to the Sailing World Speed Record | Syroco - Footage from the Journey!">

    <iframe id="YouTubeVideoPlayer-f782404d013b2415280f82019e3aa283d" role="application" title="YouTube embedded video player" allowfullscreen="" loading="lazy" src="https://www.youtube.com/embed/WpmgVO5uSs8?enablejsapi=1"></iframe>
</ps-youtubeplayer>
</p>
    
    
        <p>On the Road to the Sailing World Speed Record | Syroco - Footage from the Journey!</p>
    
</div><p>I suspect the Air Syroco folks might need to stock up on barf bags when they start putting human meat sacks on board. </p><p>Both teams will continue tuning, tweaking, testing and accelerating, and we look forward to seeing just how far these bizarre, left-field designs can be pushed. It's certainly fun having two well-resourced, innovative teams chasing the record at once!</p><p>Sources: <a href="https://sp80.ch/launching-on-lake-geneva-for-the-sp80-boat/" target="_blank" data-cms-ai="0">SP80</a>, <a href="https://syro.co/en/news/releasing-video-prototype-flight/" target="_blank" data-cms-ai="0">Syroco</a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Indoor wood burning raises women’s lung cancer risk by 43% (180 pts)]]></title>
            <link>https://www.sciencedirect.com/science/article/pii/S0160412023004014</link>
            <guid>37810052</guid>
            <pubDate>Sun, 08 Oct 2023 12:58:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.sciencedirect.com/science/article/pii/S0160412023004014">https://www.sciencedirect.com/science/article/pii/S0160412023004014</a>, See on <a href="https://news.ycombinator.com/item?id=37810052">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="app" data-aa-name="root" data-reactroot="" data-iso-key="_0"><header id="gh-cnt"><div id="gh-main-cnt"><a id="gh-branding" href="https://www.sciencedirect.com/" aria-label="ScienceDirect home page" data-aa-region="header" data-aa-name="ScienceDirect"><img src="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/shared-assets/24/images/elsevier-non-solus-new-grey.svg" alt="Elsevier logo" height="48" width="54"></a></div></header><div id="mathjax-container" role="main"><div role="region" aria-label="Download options and search"><ul aria-label="PDF Options"><li><a aria-label="View PDF. Opens in a new window."><svg focusable="false" viewBox="0 0 32 32" height="24" width="24"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke="#000" stroke-width=".703" fill="#fff"></path><path d="M.167 2.592H22.39V9.72H.166z" fill="#da0000"></path><path fill="#fff9f9" d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill="#f91d0a"></path></svg><span>View&nbsp;<strong>PDF</strong></span></a></li><li></li></ul></div><div><article lang="en"><div id="publication"><p><a href="https://www.sciencedirect.com/journal/environment-international" title="Go to Environment International on ScienceDirect"><span><img src="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/prod/bebed1cf7f0e52b8a74e313925b021091693422e/image/elsevier-non-solus.png" alt="Elsevier"></span></a></p><p><a href="https://www.sciencedirect.com/journal/environment-international/vol/178/suppl/C"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0160412023X00063-cov150h.gif" alt="Environment International"></span></a></p></div><p id="article-identifier-links"><a href="https://doi.org/10.1016/j.envint.2023.108128" target="_blank" rel="noreferrer noopener" aria-label="Persistent link using digital object identifier" title="Persistent link using digital object identifier"><span>https://doi.org/10.1016/j.envint.2023.108128</span><svg focusable="false" viewBox="0 0 78 128" aria-label="Opens in new window" width="1em" height="1em"><path d="m4 36h57.07l-59.5 59.5 7.07 7.08 59.36-59.36v56.78h1e1v-74h-74z"></path></svg></a><a href="https://s100.copyright.com/AppDispatchServlet?publisherName=ELS&amp;contentID=S0160412023004014&amp;orderBeanReset=true" target="_blank" rel="noreferrer noopener"><span>Get rights and content</span><svg focusable="false" viewBox="0 0 78 128" aria-label="Opens in new window" width="1em" height="1em"><path d="m4 36h57.07l-59.5 59.5 7.07 7.08 59.36-59.36v56.78h1e1v-74h-74z"></path></svg></a></p><div id="abstracts"><div id="ab005" lang="en"><h2>Highlights</h2><div id="as005"><ul><li><span>•</span><span><p id="p0005">First prospective study of wood burning and lung cancer incidence among U.S. women.</p></span></li><li><span>•</span><span><p id="p0010">Higher wood stove/fireplace usage associated with 70&nbsp;% higher incidence of lung cancer.</p></span></li><li><span>•</span><span><p id="p0015">Associations were also elevated when analysis was restricted to never smokers.</p></span></li><li><span>•</span><span><p id="p0020">Suggest even occasional indoor wood burning can contribute to lung cancer.</p></span></li></ul></div></div><div id="ab010"><h2>Abstract</h2><div id="as010"><h3 id="st015">Background and aim</h3><p id="sp0010">Epidemiological studies conducted mostly in low- and middle-income countries have found a positive association between household combustion of wood and lung cancer. However, most studies have been retrospective, and few have been conducted in the United States where indoor wood-burning usage patterns differ. We examined the association of exposure to indoor wood smoke from fireplaces and stoves with incident lung cancer in a U.S.-wide cohort of women.</p></div><div id="as015"><h3 id="st020">Methods</h3><p id="sp0015">We included 50,226 women without prior lung cancer participating in the U.S.-based prospective Sister Study. At enrollment (2003–2009), women reported frequency of use of wood-burning stoves and/or fireplaces in their longest-lived adult residence. Cox regression was used to estimate adjusted hazard ratios (HR<sub>adj</sub>) and 95&nbsp;% confidence intervals (CI) for the association between indoor wood-burning fireplace/stove use and incident lung cancer. Lung cancer was self-reported and confirmed with medical records.</p></div><div id="as020"><h3 id="st025">Results</h3><p id="sp0020">During an average 11.3&nbsp;years of follow-up, 347 medically confirmed lung cancer cases accrued. Overall, 62.3&nbsp;% of the study population reported the presence of an indoor wood-burning fireplace/stove at their longest-lived adult residence and 20.6&nbsp;% reported annual usage of ≥30&nbsp;days/year. Compared to those without a wood-burning fireplace/stove, women who used their wood-burning fireplace/stove ≥30&nbsp;days/year had an elevated rate of lung cancer (HR<sub>adj</sub>&nbsp;=&nbsp;1.68; 95&nbsp;% CI&nbsp;=&nbsp;1.27, 2.20). In never smokers, positive associations were seen for use 1–29&nbsp;days/year (HR<sub>adj</sub>&nbsp;=&nbsp;1.64; 95&nbsp;% CI&nbsp;=&nbsp;0.87, 3.10) and ≥30&nbsp;days/year (HR<sub>adj</sub>&nbsp;=&nbsp;1.99; 95&nbsp;% CI&nbsp;=&nbsp;1.02, 3.89). Associations were also elevated across all income groups, in Northeastern, Western or Midwestern U.S. regions, and among those who lived in urban or rural/small town settings.</p></div><div id="as025"><h3 id="st030">Conclusions</h3><p id="sp0025">Our prospective analysis of a cohort of U.S. women found that increasing frequency of wood-burning indoor fireplace/stove usage was associated with incident lung cancer, even among never smokers.</p></div></div></div><ul id="issue-navigation"><li></li><li></li></ul><div id="kg005"><h2>Keywords</h2><p><span>Wood smoke</span></p><p><span>Heating</span></p><p><span>Cooking</span></p><p><span>Lung cancer</span></p><p><span>Women</span></p></div><section id="da005"><h2 id="st040">Data availability</h2><p id="p0025">Data will be made available on request.</p></section><section aria-label="Cited by" id="section-cited-by"><header id="citing-articles-header"><h2>Cited by (0)</h2></header></section><p><span>Published by Elsevier Ltd.</span></p></article></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Contour: Modern and Fast Terminal Emulator (174 pts)]]></title>
            <link>https://github.com/contour-terminal/contour</link>
            <guid>37809834</guid>
            <pubDate>Sun, 08 Oct 2023 12:20:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/contour-terminal/contour">https://github.com/contour-terminal/contour</a>, See on <a href="https://news.ycombinator.com/item?id=37809834">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" id="user-content-contour---a-modern--actually-fast-terminal-emulator" dir="auto"><a href="#contour---a-modern--actually-fast-terminal-emulator">Contour - a modern &amp; actually fast Terminal Emulator</a></h2>
<p dir="auto"><a href="https://github.com/contour-terminal/contour/actions?query=workflow%3ABuild"><img src="https://github.com/contour-terminal/contour/workflows/Build/badge.svg" alt="CI Build"></a>
<a href="https://codecov.io/gh/contour-terminal/contour" rel="nofollow"><img src="https://camo.githubusercontent.com/a13b212c030b23482c3335fd0147847c24bd76109e1d06ddb1e345e24c21a098/68747470733a2f2f636f6465636f762e696f2f67682f636f6e746f75722d7465726d696e616c2f636f6e746f75722f6272616e63682f6d61737465722f67726170682f62616467652e737667" alt="codecov" data-canonical-src="https://codecov.io/gh/contour-terminal/contour/branch/master/graph/badge.svg"></a>
<a href="https://isocpp.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/3cf63accce4ccab78694605dce8b3a5fdce4797907333bcb6ee65513280c47a2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7374616e646172642d4325324225324225323032302d626c75652e7376673f6c6f676f3d43253242253242" alt="C++20" data-canonical-src="https://img.shields.io/badge/standard-C%2B%2B%2020-blue.svg?logo=C%2B%2B"></a>
<a href="https://discord.gg/ncv4pG9" rel="nofollow"><img src="https://camo.githubusercontent.com/7dc86b70f31d81db1a03bbc7a4fbf91eb66e17148258418e733bdd6ebd08611a/68747470733a2f2f696d672e736869656c64732e696f2f646973636f72642f3437393330313331373333373238343630382e7376673f6c6162656c3d266c6f676f3d646973636f7264266c6f676f436f6c6f723d66666666666626636f6c6f723d373338394438266c6162656c436f6c6f723d364137454332" alt="Discord" data-canonical-src="https://img.shields.io/discord/479301317337284608.svg?label=&amp;logo=discord&amp;logoColor=ffffff&amp;color=7389D8&amp;labelColor=6A7EC2"></a>
<a href="https://twitch.tv/christianparpart" rel="nofollow"><img src="https://camo.githubusercontent.com/102469cd0266a890b0dd4d80a0149d07e88f0645bcdcd7c8ebf779390e8070fc/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f5477697463682d4c69766525323053747265616d2d626c75653f7374796c653d666c61742d737175617265" alt="Twitch Live Stream" data-canonical-src="https://img.shields.io/badge/Twitch-Live%20Stream-blue?style=flat-square"></a>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/22a3940995b55ad540162b8f2656ce4b3f9ed4b65f96610f2cf2fc20512e8227/68747470733a2f2f6f70656e636f6c6c6563746976652e636f6d2f636f6e746f75722d7465726d696e616c2d656d756c61746f722f74696572732f6261636b65722f62616467652e7376673f6c6162656c3d6261636b657226636f6c6f723d627269676874677265656e"><img alt="open collective badge" src="https://camo.githubusercontent.com/22a3940995b55ad540162b8f2656ce4b3f9ed4b65f96610f2cf2fc20512e8227/68747470733a2f2f6f70656e636f6c6c6563746976652e636f6d2f636f6e746f75722d7465726d696e616c2d656d756c61746f722f74696572732f6261636b65722f62616467652e7376673f6c6162656c3d6261636b657226636f6c6f723d627269676874677265656e" data-canonical-src="https://opencollective.com/contour-terminal-emulator/tiers/backer/badge.svg?label=backer&amp;color=brightgreen"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/contour-terminal/contour/blob/master/docs/screenshots/contour-notcurses-ncneofetch.png"><img src="https://github.com/contour-terminal/contour/raw/master/docs/screenshots/contour-notcurses-ncneofetch.png" alt="screenshot showcasing notcurses ncneofetch on KDE/Fedora" title="Screenshot"></a></p>
<p dir="auto"><code>contour</code> is a modern and actually fast, modal, virtual terminal emulator,
for everyday use. It is aiming for power users with a modern feature mindset.</p>
<h2 tabindex="-1" id="user-content-features" dir="auto"><a href="#features">Features</a></h2>
<ul dir="auto">
<li>✅ Available on all 4 major platforms, Linux, OS/X, FreeBSD, Windows.</li>
<li>✅ GPU-accelerated rendering.</li>
<li>✅ Font ligatures support (such as in Fira Code).</li>
<li>✅ Unicode: Emoji support (-: 🌈 💝 😛 👪 - including ZWJ, VS15, VS16 emoji :-)</li>
<li>✅ Unicode: Grapheme cluster support</li>
<li>✅ Bold and italic fonts</li>
<li>✅ High-DPI support.</li>
<li>✅ Vertical Line Markers (quickly jump to markers in your history!)</li>
<li>✅ Vi-like input modes for improved selection and copy'n'paste experience and Vi-like <code>scrolloff</code> feature.</li>
<li>✅ Blurred behind transparent background when using Windows 10 or KDE window manager on Linux.</li>
<li>✅ Blurrable Background image support.</li>
<li>✅ Runtime configuration reload</li>
<li>✅ 256-color and Truecolor support</li>
<li>✅ Key binding customization</li>
<li>✅ Color Schemes</li>
<li>✅ Profiles (grouped customization of: color scheme, login shell, and related behaviours)</li>
<li>✅ <a href="https://github.com/contour-terminal/contour/wiki/VTExtensions#synchronized-output">Synchronized rendering</a> (via <code>SM ? 2026</code> / <code>RM ? 2026</code>)</li>
<li>✅ Text reflow (configurable via <code>SM ? 2028</code> / <code>RM ? 2028</code>)</li>
<li>✅ Clickable hyperlinks via <a href="https://gist.github.com/egmontkob/eb114294efbcd5adb1944c9f3cb5feda">OSC 8</a></li>
<li>✅ Clipboard setting via OSC 52</li>
<li>✅ Sixel inline images</li>
<li>✅ Terminal page <a href="https://github.com/contour-terminal/contour/wiki/VTExtensions#buffer-capture">buffer capture VT extension</a> to quickly extract contents.</li>
<li>✅ Builtin <a href="https://github.com/contour-terminal/contour/issues/521" data-hovercard-type="issue" data-hovercard-url="/contour-terminal/contour/issues/521/hovercard">Fira Code inspired progress bar</a> support.</li>
<li>✅ Read-only mode, protecting against accidental user-input to the running application, such as <kbd>Ctrl</kbd>+<kbd>C</kbd>.</li>
<li>✅ VT320 Host-programmable and Indicator status line support.</li>
<li>✅ and much more ...</li>
</ul>
<h2 tabindex="-1" id="user-content-installation" dir="auto"><a href="#installation">Installation</a></h2>
<p dir="auto"><code>contour</code> is packaged and available for installation on multiple distributions.</p>
<ul dir="auto">
<li><code>Fedora</code> use official <a href="https://packages.fedoraproject.org/pkgs/contour-terminal/contour-terminal/" rel="nofollow">package</a></li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="sudo dnf install contour-terminal"><pre>sudo dnf install contour-terminal</pre></div>
<ul dir="auto">
<li><code>Arch</code> use AUR <a href="https://aur.archlinux.org/packages/contour" rel="nofollow">package</a></li>
</ul>
<h3 tabindex="-1" id="user-content-installing-via-flatpak" dir="auto"><a href="#installing-via-flatpak">Installing via Flatpak</a></h3>
<h4 tabindex="-1" id="user-content-install-from-flathub" dir="auto"><a href="#install-from-flathub">Install from Flathub</a></h4>
<p dir="auto">Click the following button install Contour from the Flathub store.</p>
<p dir="auto"><a href="https://flathub.org/apps/details/org.contourterminal.Contour" rel="nofollow"><img src="https://raw.githubusercontent.com/flatpak-design-team/flathub-mockups/master/assets/download-button/download.svg?sanitize=true" alt="Get it on Flathub"></a></p>
<h4 tabindex="-1" id="user-content-prerequisites" dir="auto"><a href="#prerequisites">Prerequisites</a></h4>
<ul dir="auto">
<li>Make sure you have flatpak installed in your system (<a href="https://flatpak.org/getting.html" rel="nofollow">here is a tutorial on how to install it</a>), and make sure that the version is &gt;= 0.10 (check it using this command: <code>flatpak --version</code>)</li>
<li>Add the <a href="https://flathub.org/" rel="nofollow">flathub</a> repository using the following command: <code>flatpak remote-add --if-not-exists flathub https://dl.flathub.org/repo/flathub.flatpakrepo</code>.</li>
<li>Proceed with one of the following options:
<ul dir="auto">
<li><a href="#install-from-flathub">Install from Flathub</a></li>
<li><a href="https://github.com/contour-terminal/contour/releases">Install from GitHub release</a></li>
</ul>
</li>
</ul>
<h2 tabindex="-1" id="user-content-requirements" dir="auto"><a href="#requirements">Requirements</a></h2>
<ul dir="auto">
<li><strong>operating system</strong>: A <em>recent</em> operating system (OS/X 12, Windows 10+, an up-to-date Linux, or FreeBSD)</li>
<li><strong>GPU</strong>: driver must support at least OpenGL 3.3 hardware accelerated or as software rasterizer.</li>
<li><strong>CPU</strong>: x86-64 AMD or Intel with AES-NI instruction set or ARMv8 with crypto extensions.</li>
</ul>
<h2 tabindex="-1" id="user-content-configuration" dir="auto"><a href="#configuration">Configuration</a></h2>
<p dir="auto">In order to set up Contour, it is necessary to modify the configuration file
<code>contour.yml</code>, which is initially generated in the <code>$HOME/.config/contour</code>
directory. Some features also require shell integration. These can be generated
via the CLI (see below), these currently exist for zsh, fish and tcsh.</p>
<h2 tabindex="-1" id="user-content-installing-from-source" dir="auto"><a href="#installing-from-source">Installing from source</a></h2>
<p dir="auto">Contour is best installed from supported package managers, but you can build
from source by following the instruction below. You can Qt 5 or Qt 6,
by default contour will be compiler with Qt 6, to change Qt version use <code>QTVER=5 ./scripts/install-deps.sh</code> to fetch dependencies and cmake flag <code>-D CONTOUR_QT_VERSION=5</code>.</p>
<h3 tabindex="-1" id="user-content-unix-like-systems-linux-freebsd-osx" dir="auto"><a href="#unix-like-systems-linux-freebsd-osx">UNIX-like systems (Linux, FreeBSD, OS/X)</a></h3>
<h4 tabindex="-1" id="user-content-prerequisites-1" dir="auto"><a href="#prerequisites-1">Prerequisites</a></h4>
<div dir="auto" data-snippet-clipboard-copy-content="./scripts/install-deps.sh"><pre>./scripts/install-deps.sh</pre></div>
<p dir="auto">This script <em>might</em> ask you for the administrator password if a package dependency
can be insalled via the system package manager.</p>
<h4 tabindex="-1" id="user-content-compile" dir="auto"><a href="#compile">Compile</a></h4>
<div dir="auto" data-snippet-clipboard-copy-content="cmake -S . -B build -G Ninja
cmake --build build/

# Optionally, if you want to install from source
cmake --build build/ --target install"><pre>cmake -S <span>.</span> -B build -G Ninja
cmake --build build/

<span><span>#</span> Optionally, if you want to install from source</span>
cmake --build build/ --target install</pre></div>
<h4 tabindex="-1" id="user-content-windows-10-or-newer" dir="auto"><a href="#windows-10-or-newer">Windows 10 or newer</a></h4>
<h4 tabindex="-1" id="user-content-prerequisites-2" dir="auto"><a href="#prerequisites-2">Prerequisites</a></h4>
<p dir="auto">For Windows, you must have Windows 10, 2018 Fall Creators Update, and Visual Studio 2019, installed.
It will neither build nor run on any prior Windows OS, due to libterminal making use of <a href="https://devblogs.microsoft.com/commandline/windows-command-line-introducing-the-windows-pseudo-console-conpty/" rel="nofollow">ConPTY API</a>.</p>
<ol dir="auto">
<li>Set up <a href="https://vcpkg.io/en/getting-started.html" rel="nofollow">vcpkg</a>, preferably somewhere high up in the folder hierarchy, and add the folder to your <code>PATH</code>.</li>
</ol>
<div data-snippet-clipboard-copy-content="cd C:\
git clone git clone https://github.com/Microsoft/vcpkg.git
.\vcpkg\bootstrap-vcpkg.bat"><pre><code>cd C:\
git clone git clone https://github.com/Microsoft/vcpkg.git
.\vcpkg\bootstrap-vcpkg.bat
</code></pre></div>
<ol start="2" dir="auto">
<li>Install Visual Studio Build Tools (make sure to select the CLI tools for
C++, which you might need to do in the separate components tab).</li>
<li>Install Qt6 (i.e. to C:\Qt)</li>
<li>Open the <em>developer</em> version of Powershell.</li>
<li>In the <code>contour</code> source folder execute <code>.\scripts\install-deps.ps1</code>. This step may take a <em>very</em> long time.</li>
</ol>
<h4 tabindex="-1" id="user-content-compile-1" dir="auto"><a href="#compile-1">Compile</a></h4>
<p dir="auto">In the <em>developer</em> version of Powershell:</p>
<div data-snippet-clipboard-copy-content="# change paths accordingly if you installed QT and vcpkg to somewhere else
cmake -S . -B build -DCMAKE_TOOLCHAIN_FILE=C:\vcpkg\scripts\buildsystems\vcpkg.cmake -DCMAKE_PREFIX_PATH=C:\Qt\6.5.0\msvc2019_64\lib\cmake
cmake --build build/

# Optionally, if you want to install from source
cmake --build build/ --target install"><pre lang="psh"><code># change paths accordingly if you installed QT and vcpkg to somewhere else
cmake -S . -B build -DCMAKE_TOOLCHAIN_FILE=C:\vcpkg\scripts\buildsystems\vcpkg.cmake -DCMAKE_PREFIX_PATH=C:\Qt\6.5.0\msvc2019_64\lib\cmake
cmake --build build/

# Optionally, if you want to install from source
cmake --build build/ --target install
</code></pre></div>
<h4 tabindex="-1" id="user-content-distribution-packages" dir="auto"><a href="#distribution-packages">Distribution Packages</a></h4>
<p dir="auto"><a href="https://repology.org/project/contour-terminal/versions" rel="nofollow"><img src="https://camo.githubusercontent.com/528c06fea3754750cf8c5983333a124cf2a70fd857d33d46a97c6725982967f2/68747470733a2f2f7265706f6c6f67792e6f72672f62616467652f766572746963616c2d616c6c7265706f732f636f6e746f75722d7465726d696e616c2e737667" alt="Packaging status" data-canonical-src="https://repology.org/badge/vertical-allrepos/contour-terminal.svg"></a></p>
<h2 tabindex="-1" id="user-content-cli---command-line-interface" dir="auto"><a href="#cli---command-line-interface">CLI - Command Line Interface</a></h2>
<div dir="auto" data-snippet-clipboard-copy-content="  Usage:

    contour [terminal] [config FILE] [profile NAME] [debug TAGS] [live-config] [dump-state-at-exit PATH]
                       [early-exit-threshold UINT] [working-directory DIRECTORY] [class WM_CLASS]
                       [platform PLATFORM[:OPTIONS]] [session SESSION_ID] [PROGRAM ARGS...]
    contour font-locator [config FILE] [profile NAME] [debug TAGS]
    contour info vt
    contour help
    contour version
    contour license
    contour parser-table
    contour list-debug-tags
    contour generate terminfo to FILE
    contour generate config to FILE
    contour generate integration shell SHELL to FILE
    contour capture [logical] [words] [timeout SECONDS] [lines COUNT] to FILE
    contour set profile [to NAME]
"><pre>  Usage:

    contour [terminal] [config FILE] [profile NAME] [debug TAGS] [live-config] [dump-state-at-exit PATH]
                       [early-exit-threshold UINT] [working-directory DIRECTORY] [class WM_CLASS]
                       [platform PLATFORM[:OPTIONS]] [session SESSION_ID] [PROGRAM ARGS...]
    contour font-locator [config FILE] [profile NAME] [debug TAGS]
    contour info vt
    contour help
    contour version
    contour license
    contour parser-table
    contour list-debug-tags
    contour generate terminfo to FILE
    contour generate config to FILE
    contour generate integration shell SHELL to FILE
    contour capture [logical] [words] [timeout SECONDS] [lines COUNT] to FILE
    contour set profile [to NAME]
</pre></div>
<h2 tabindex="-1" id="user-content-references" dir="auto"><a href="#references">References</a></h2>
<ul dir="auto">
<li><a href="https://vt100.net/docs/vt510-rm/" rel="nofollow">VT510</a>: VT510 Manual, see Chapter 5.</li>
<li><a href="http://www.ecma-international.org/publications/standards/Ecma-035.htm" rel="nofollow">ECMA-35</a>:
Character Code Structure and Extension Techniques</li>
<li><a href="http://www.ecma-international.org/publications/standards/Ecma-043.htm" rel="nofollow">ECMA-43</a>:
8-bit Coded Character Set Structure and Rules</li>
<li><a href="http://www.ecma-international.org/publications/standards/Ecma-048.htm" rel="nofollow">ECMA-48</a>:
Control Functions for Coded Character Sets</li>
<li><a href="https://www.iso.org/standard/22943.html" rel="nofollow">ISO/IEC 8613-6</a>:
Character content architectures</li>
<li><a href="https://invisible-island.net/xterm/ctlseqs/ctlseqs.html" rel="nofollow">xterm</a>: xterm control sequences</li>
<li><a href="http://man.he.net/man4/console_codes" rel="nofollow">console_codes</a> Linux console codes</li>
<li><a href="http://www.inwap.com/pdp10/ansicode.txt" rel="nofollow">Summary of ANSI standards for ASCII terminals</a></li>
<li><a href="http://tldp.org/HOWTO/Text-Terminal-HOWTO-7.html#ss7.2" rel="nofollow">Text Terminal HOWTO (Chapter 7.2, PTY)</a></li>
<li><a href="https://en.wikipedia.org/wiki/ANSI_escape_code" rel="nofollow">ANSI escape code</a> in Wikipedia</li>
</ul>
<h3 tabindex="-1" id="user-content-license" dir="auto"><a href="#license">License</a></h3>
<div data-snippet-clipboard-copy-content="Contour - A modern C++ Terminal Emulator
-------------------------------------------

Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
you may not use this file except in compliance with the License.

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License."><pre><code>Contour - A modern C++ Terminal Emulator
-------------------------------------------

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
</code></pre></div>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Homebrew to deprecate and add caveat for HashiCorp (247 pts)]]></title>
            <link>https://github.com/Homebrew/homebrew-core/pull/139538</link>
            <guid>37809721</guid>
            <pubDate>Sun, 08 Oct 2023 12:00:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/Homebrew/homebrew-core/pull/139538">https://github.com/Homebrew/homebrew-core/pull/139538</a>, See on <a href="https://news.ycombinator.com/item?id=37809721">Hacker News</a></p>
<div id="readability-page-1" class="page"><div disabled="" sortable="">
          <p dir="auto">I've re-run the tap_syntax to show the failure so we don't try and fail to auto-merge this for a 5th time.</p>
<p dir="auto">(It previously wasn't showing because we had removed <code>brew audit</code> from PR checks for a little while while keeping it for merge checks - but I restored it fully as of yesterday.)</p>
<p dir="auto">Might be worth splitting consul and terraform to their own PRs. We'll need to make a decision on the former, and for the latter it looks like we'll wait for a little bit until OpenTofu make their first release - we already are blocking version bumps so no rush.</p>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[500 Lines or Less (166 pts)]]></title>
            <link>https://aosabook.org/en/index.html#500lines</link>
            <guid>37809529</guid>
            <pubDate>Sun, 08 Oct 2023 11:14:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://aosabook.org/en/index.html#500lines">https://aosabook.org/en/index.html#500lines</a>, See on <a href="https://news.ycombinator.com/item?id=37809529">Hacker News</a></p>
<div id="readability-page-1" class="page">
    



<p>
  Architects look at thousands of buildings during their
  training, and study critiques of those buildings written
  by masters.  In contrast, most software developers only
  ever get to know a handful of large programs
  well—usually programs they wrote
  themselves—and never study the great programs of
  history.  As a result, they repeat one another's mistakes
  rather than building on one another's successes.
</p>
      
<p>
  Our goal is to change that.  In these two books, the authors of
  four dozen open source applications explain how their software
  is structured, and why.  What are each program's major
  components?  How do they interact?  And what did their builders
  learn during their development?  In answering these questions,
  the contributors to these books provide unique insights into how
  they think.
</p>
      
<p>
  If you are a junior developer, and want to learn how your
  more experienced colleagues think, these books are the place
  to start.  If you are an intermediate or senior developer,
  and want to see how your peers have solved hard design
  problems, these books can help you too.
</p>

<div>
  <p>
    <h2 id="500lines">500 Lines or Less</h2>
  </p>
</div>


<div>
  <p>
    <h2 id="posa">The Performance of Open Source Applications</h2>
  </p>
</div>


<div>
  <p>
    <h2 id="aosa2">AOSA Volume 2</h2>
  </p>
</div>


<div>
  <p>
    <h2 id="aosa1">AOSA Volume 1</h2>
  </p>
</div>
<div>
    <table>
      <tbody><tr>
        <td></td>
        <td><a href="https://aosabook.org/en/v1/intro1.html">Introduction</a></td>
        <td><a href="https://aosabook.org/en/v1/intro1.html#brown-amy">Amy Brown</a> and <a href="https://aosabook.org/en/v1/intro1.html#wilson-greg">Greg Wilson</a></td>
      </tr>
      <tr>
        <td>1.</td>
        <td><a href="https://aosabook.org/en/v1/asterisk.html">Asterisk</a></td>
        <td><a href="https://aosabook.org/en/v1/intro1.html#bryant-russell">Russell Bryant</a></td>
      </tr>
      <tr>
        <td>2.</td>
        <td><a href="https://aosabook.org/en/v1/audacity.html">Audacity</a></td>
        <td><a href="https://aosabook.org/en/v1/intro1.html#crook-james">James Crook</a></td>
      </tr>
      <tr>
        <td>3.</td>
        <td><a href="https://aosabook.org/en/v1/bash.html">The Bourne-Again Shell</a></td>
        <td><a href="https://aosabook.org/en/v1/intro1.html#ramey-chet">Chet Ramey</a></td>
      </tr>
      <tr>
        <td>4.</td>
        <td><a href="https://aosabook.org/en/v1/bdb.html">Berkeley DB</a></td>
        <td><a href="https://aosabook.org/en/v1/intro1.html#seltzer-margo">Margo Seltzer</a> and <a href="https://aosabook.org/en/v1/intro1.html#bostic-keith">Keith Bostic</a></td>
      </tr>
      <tr>
        <td>5.</td>
        <td><a href="https://aosabook.org/en/v1/cmake.html">CMake</a></td>
        <td><a href="https://aosabook.org/en/v1/intro1.html#hoffman-bill">Bill Hoffman</a> and <a href="https://aosabook.org/en/v1/intro1.html#martin-kenneth">Kenneth Martin</a></td>
      </tr>
      <tr>
        <td>6.</td>
        <td><a href="https://aosabook.org/en/v1/eclipse.html">Eclipse</a></td>
        <td><a href="https://aosabook.org/en/v1/intro1.html#moir-kim">Kim Moir</a></td>
      </tr>
      <tr>
        <td>7.</td>
        <td><a href="https://aosabook.org/en/v1/graphite.html">Graphite</a></td>
        <td><a href="https://aosabook.org/en/v1/intro1.html#davis-chris">Chris Davis</a></td>
      </tr>
      <tr>
        <td>8.</td>
        <td><a href="https://aosabook.org/en/v1/hdfs.html">The Hadoop Distributed File System</a></td>
        <td><a href="https://aosabook.org/en/v1/intro1.html#chansler-robert">Robert Chansler</a>, <a href="https://aosabook.org/en/v1/intro1.html#kuang-hairong">Hairong Kuang</a>, <a href="https://aosabook.org/en/v1/intro1.html#radia-sanjay">Sanjay Radia</a>, <a href="https://aosabook.org/en/v1/intro1.html#shvachko-konstantin">Konstantin Shvachko</a>, and <a href="https://aosabook.org/en/v1/intro1.html#srinivas-suresh">Suresh Srinivas</a></td>
      </tr>
      <tr>
        <td>9.</td>
        <td><a href="https://aosabook.org/en/v1/integration.html">Continuous Integration</a></td>
        <td><a href="https://aosabook.org/en/v1/intro1.html#brown-titus">C. Titus Brown</a> and <a href="https://aosabook.org/en/v1/intro1.html#canino-koning-rosangela">Rosangela Canino-Koning</a></td>
      </tr>
      <tr>
        <td>10.</td>
        <td><a href="https://aosabook.org/en/v1/jitsi.html">Jitsi</a></td>
        <td><a href="https://aosabook.org/en/v1/intro1.html#ivov-emil">Emil Ivov</a></td>
      </tr>
      <tr>
        <td>11.</td>
        <td><a href="https://aosabook.org/en/v1/llvm.html">LLVM</a></td>
        <td><a href="https://aosabook.org/en/v1/intro1.html#lattner-chris">Chris Lattner</a></td>
      </tr>
      <tr>
        <td>12.</td>
        <td><a href="https://aosabook.org/en/v1/mercurial.html">Mercurial</a></td>
        <td><a href="https://aosabook.org/en/v1/intro1.html#ochtman-dirkjan">Dirkjan Ochtman</a></td>
      </tr>
      <tr>
        <td>13.</td>
        <td><a href="https://aosabook.org/en/v1/nosql.html">The NoSQL Ecosystem</a></td>
        <td><a href="https://aosabook.org/en/v1/intro1.html#marcus-adam">Adam Marcus</a></td>
      </tr>
      <tr>
        <td>14.</td>
        <td><a href="https://aosabook.org/en/v1/packaging.html">Python Packaging</a></td>
        <td><a href="https://aosabook.org/en/v1/intro1.html#ziade-tarek">Tarek Ziadé</a></td>
      </tr>
      <tr>
        <td>15.</td>
        <td><a href="https://aosabook.org/en/v1/riak.html">Riak and Erlang/OTP</a></td>
        <td><a href="https://aosabook.org/en/v1/intro1.html#cesarini-francesco">Francesco Cesarini</a>, <a href="https://aosabook.org/en/v1/intro1.html#gross-andy">Andy Gross</a>, and <a href="https://aosabook.org/en/v1/intro1.html#sheehy-justin">Justin Sheehy</a></td>
      </tr>
      <tr>
        <td>16.</td>
        <td><a href="https://aosabook.org/en/v1/selenium.html">Selenium WebDriver</a></td>
        <td><a href="https://aosabook.org/en/v1/intro1.html#stewart-simon">Simon Stewart</a></td>
      </tr>
      <tr>
        <td>17.</td>
        <td><a href="https://aosabook.org/en/v1/sendmail.html">Sendmail</a></td>
        <td><a href="https://aosabook.org/en/v1/intro1.html#allman-eric">Eric Allman</a></td>
      </tr>
      <tr>
        <td>18.</td>
        <td><a href="https://aosabook.org/en/v1/snowflock.html">SnowFlock</a></td>
        <td><a href="https://aosabook.org/en/v1/intro1.html#bryant-roy">Roy Bryant</a> and <a href="https://aosabook.org/en/v1/intro1.html#lagar-cavilla-andres">Andrés Lagar-Cavilla</a></td>
      </tr>
      <tr>
        <td>19.</td>
        <td><a href="https://aosabook.org/en/v1/socialcalc.html">SocialCalc</a></td>
        <td><a href="https://aosabook.org/en/v1/intro1.html#tang-audrey">Audrey Tang</a></td>
      </tr>
      <tr>
        <td>20.</td>
        <td><a href="https://aosabook.org/en/v1/telepathy.html">Telepathy</a></td>
        <td><a href="https://aosabook.org/en/v1/intro1.html#madeley-danielle">Danielle Madeley</a></td>
      </tr>
      <tr>
        <td>21.</td>
        <td><a href="https://aosabook.org/en/v1/thousandparsec.html">Thousand Parsec</a></td>
        <td><a href="https://aosabook.org/en/v1/intro1.html#laudicina-alan">Alan Laudicina</a> and <a href="https://aosabook.org/en/v1/intro1.html#mavrinac-aaron">Aaron Mavrinac</a></td>
      </tr>
      <tr>
        <td>22.</td>
        <td><a href="https://aosabook.org/en/v1/violet.html">Violet</a></td>
        <td><a href="https://aosabook.org/en/v1/intro1.html#horstmann-cay">Cay Horstmann</a></td>
      </tr>
      <tr>
        <td>23.</td>
        <td><a href="https://aosabook.org/en/v1/vistrails.html">VisTrails</a></td>
        <td><a href="https://aosabook.org/en/v1/intro1.html#freire-juliana">Juliana Freire</a>, <a href="https://aosabook.org/en/v1/intro1.html#koop-david">David Koop</a>, <a href="https://aosabook.org/en/v1/intro1.html#santos-emanuele">Emanuele Santos</a>, <a href="https://aosabook.org/en/v1/intro1.html#scheidegger-carlos">Carlos Scheidegger</a>, <a href="https://aosabook.org/en/v1/intro1.html#silva-claudio">Claudio Silva</a>, and <a href="https://aosabook.org/en/v1/intro1.html#vo-huy">Huy T. Vo</a></td>
      </tr>
      <tr>
        <td>24.</td>
        <td><a href="https://aosabook.org/en/v1/vtk.html">VTK</a></td>
        <td><a href="https://aosabook.org/en/v1/intro1.html#geveci-berk">Berk Geveci</a> and <a href="https://aosabook.org/en/v1/intro1.html#schroeder-will">Will Schroeder</a></td>
      </tr>
      <tr>
        <td>25.</td>
        <td><a href="https://aosabook.org/en/v1/wesnoth.html">Battle For Wesnoth</a></td>
        <td><a href="https://aosabook.org/en/v1/intro1.html#shimooka-richard">Richard Shimooka</a> and <a href="https://aosabook.org/en/v1/intro1.html#white-david">David White</a></td>
      </tr>
      <tr>
        <td></td>
        <td><a href="https://aosabook.org/en/v1/bib1.html">Bibliography</a></td>
        <td></td>
      </tr>
    </tbody></table>
  </div>

<h2>License and Royalties</h2>
<p>
  This work is made available under
  the <a href="http://creativecommons.org/licenses/by/3.0/legalcode">Creative Commons Attribution 3.0 Unported</a> license.
  Please see
  the <a href="https://aosabook.org/en/license.html">full description of the license</a> for details.
  All royalties from sales of these books will be donated to
  <a href="http://amnesty.org/">Amnesty International</a>.
</p>

<h2>Contributing</h2>
<p>
  Dozens of volunteers worked hard to create this book,
  but there is still lots to do.
  You can help by reporting errors,
  by helping to translate the content into other languages and formats,
  or by describing the architecture of other open source projects.
  Please contact us the coordinators for various translations listed below,
  or mail us directly at <a href="mailto:gvwilson@third-bit.com">gvwilson@third-bit.com</a>
  if you would like to start a new translation or write a chapter yourself.
</p>

  

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[A Raspberry Pi 5 is better than two Pi 4S (239 pts)]]></title>
            <link>https://hackaday.com/2023/09/28/a-raspberry-pi-5-is-better-than-two-pi-4s/</link>
            <guid>37809516</guid>
            <pubDate>Sun, 08 Oct 2023 11:12:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hackaday.com/2023/09/28/a-raspberry-pi-5-is-better-than-two-pi-4s/">https://hackaday.com/2023/09/28/a-raspberry-pi-5-is-better-than-two-pi-4s/</a>, See on <a href="https://news.ycombinator.com/item?id=37809516">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
        <p>What’s as fast as two Raspberry Pi 4s? <a href="https://www.raspberrypi.com/news/introducing-raspberry-pi-5/" target="_blank">The brand-new Raspberry Pi 5</a>, that’s what. And for only a $5 upcharge (with an asterisk), it’s going to the new go-to board from the British House of Fruity Single-Board Computers. But aside from the brute speed, it also has a number of cool features that will make using the board easier for a number of projects, and it’s going to be on sale in October. Raspberry Pi sent us one for review, and if you were just about to pick up a Pi 4 for a project that needs the speed, we’d say that you might wait a couple weeks until the Raspberry Pi 5 goes on sale.</p>
<h2 id="twice-as-nice">Twice as Nice</h2>
<p>On essentially every benchmark, the Raspberry Pi 5 comes in two to three times faster than the Pi 4. This is thanks to the new Broadcom BCM2712 system-on-chip (SOC) that runs four ARM A76s at 2.4 GHz instead of the Pi 4’s ARM A72s at 1.8 GHz. This gives the CPUs a roughly 2x – 3x advantage over the Pi 4. (Although the Pi 4 was <a href="https://hackaday.com/2020/11/11/adventures-in-overclocking-which-raspberry-pi-4-flavor-is-fastest/">eminently overclockable</a> in the CM4 package.)<a href="https://hackaday.com/wp-content/uploads/2023/09/ch01-raspberrypi5-soc_thumbnail.png" target="_blank"><img data-attachment-id="623884" data-permalink="https://hackaday.com/2023/09/28/a-raspberry-pi-5-is-better-than-two-pi-4s/ch01-raspberrypi5-soc_thumbnail/" data-orig-file="https://hackaday.com/wp-content/uploads/2023/09/ch01-raspberrypi5-soc_thumbnail.png" data-orig-size="1200,1200" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="ch01-raspberrypi5-soc_thumbnail" data-image-description="" data-image-caption="" data-medium-file="https://hackaday.com/wp-content/uploads/2023/09/ch01-raspberrypi5-soc_thumbnail.png?w=400" data-large-file="https://hackaday.com/wp-content/uploads/2023/09/ch01-raspberrypi5-soc_thumbnail.png?w=625" decoding="async" src="https://hackaday.com/wp-content/uploads/2023/09/ch01-raspberrypi5-soc_thumbnail.png?w=400" alt="" width="400" height="400" srcset="https://hackaday.com/wp-content/uploads/2023/09/ch01-raspberrypi5-soc_thumbnail.png 1200w, https://hackaday.com/wp-content/uploads/2023/09/ch01-raspberrypi5-soc_thumbnail.png?resize=250,250 250w, https://hackaday.com/wp-content/uploads/2023/09/ch01-raspberrypi5-soc_thumbnail.png?resize=400,400 400w, https://hackaday.com/wp-content/uploads/2023/09/ch01-raspberrypi5-soc_thumbnail.png?resize=625,625 625w" sizes="(max-width: 400px) 100vw, 400px"></a></p>
<p>The DRAM runs at double the clock speed. The video core is more efficient and pushes pixels about twice as fast. The new WiFi controller in the SOC allows about twice as much throughput to the same radio. Even the SD card interface is capable of running twice as fast, speeding up boot times to easily under 10 sec – maybe closer to 8 sec, but who’s counting?</p>
<p>Heck, while we’re on factors of two, there are now two MIPI camera/display lines, so you can do stereo imaging straight off the board, or run a camera and external display simultaneously. And it’s capable of driving <em>two</em> 4k HDMI displays at 60 Hz.</p>
<p>There are only two exceptions to the overall factor-of-two improvements. First, the Gigabyte Ethernet remains Gigabyte Ethernet, so that’s a one-ex. (We’re not sure who is running up against that constraint, but if it’s you, you’ll want an external network adapter.) But second, the new Broadcom SOC finally supports the ARM cryptography extensions, which make it 45x faster at AES, for instance. With TLS almost everywhere, this keeps crypto performance from becoming the bottleneck. Nice.</p>
<p>All in all, most everything performance-related has been doubled or halved appropriately, and completely in line with <a href="https://www.jeffgeerling.com/blog/2023/testing-pcie-on-raspberry-pi-5" target="_blank">the only formal benchmarks we’ve seen so far</a>, it <em>feels</em> about twice as fast all around in our informal tests. Compared with a Pi 400 that I use frequently in the basement workshop, the Pi 5 is a lot snappier.</p>

<h2 id="more-powah">More Powah!</h2>
<p>Nothing comes for free. While the Raspberry Pi 5 is more efficient for the same workload than the Pi 4, you can push it still harder. And when you do, it draws a peak 12 W versus the Pi 4’s peak 8 W. And this is where we get to that price asterisk we mentioned in the opening. You might need to fork out for more power coming into the board, and figure out how to handle the heat coming off of it, if you’re computering hard.</p>
<p><a href="https://hackaday.com/wp-content/uploads/2023/09/ch01-raspberrypi5-usb-c_thumbnail.png" target="_blank"><img data-attachment-id="623887" data-permalink="https://hackaday.com/2023/09/28/a-raspberry-pi-5-is-better-than-two-pi-4s/ch01-raspberrypi5-usb-c_thumbnail/" data-orig-file="https://hackaday.com/wp-content/uploads/2023/09/ch01-raspberrypi5-usb-c_thumbnail.png" data-orig-size="1200,1200" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="ch01-raspberrypi5-usb-c_thumbnail" data-image-description="" data-image-caption="" data-medium-file="https://hackaday.com/wp-content/uploads/2023/09/ch01-raspberrypi5-usb-c_thumbnail.png?w=400" data-large-file="https://hackaday.com/wp-content/uploads/2023/09/ch01-raspberrypi5-usb-c_thumbnail.png?w=625" decoding="async" src="https://hackaday.com/wp-content/uploads/2023/09/ch01-raspberrypi5-usb-c_thumbnail.png?w=400" alt="" width="400" height="400" srcset="https://hackaday.com/wp-content/uploads/2023/09/ch01-raspberrypi5-usb-c_thumbnail.png 1200w, https://hackaday.com/wp-content/uploads/2023/09/ch01-raspberrypi5-usb-c_thumbnail.png?resize=250,250 250w, https://hackaday.com/wp-content/uploads/2023/09/ch01-raspberrypi5-usb-c_thumbnail.png?resize=400,400 400w, https://hackaday.com/wp-content/uploads/2023/09/ch01-raspberrypi5-usb-c_thumbnail.png?resize=625,625 625w" sizes="(max-width: 400px) 100vw, 400px"></a>But first the good news. The Raspberry Pi 5 has an all-new power subsystem, featuring the DA9091 power-management IC, generating eight separate voltages and capable of supplying 20 A to the BCM2712 SoC. Apparently, this chip was co-developed between Raspberry Pi and Renesas, and it includes a real-time clock unit just because they could squeeze it in. It also supports <a href="https://hackaday.com/2023/01/09/all-about-usb-c-power-delivery/">USB-C Power Delivery</a>, so finding a power supply that’s capable of supplying all that juice to the Pi 5 is a lot easier, something that has been a pain point in the past. Will we never see a brownout warning again? We can dream.</p>
<p>The star of the new power management system, hands-down, is the power button. How many <a href="https://hackaday.com/2022/04/04/a-power-button-for-raspberry-pi-courtesy-of-device-tree-overlays/">power button hacks</a> have we seen over the years? We’re happy to bid them adieu.</p>
<p>Now the bad news, in the immortal words of Stan Lee: with great power comes great cooling requirements. The Pi 5 runs hot enough that you might require a heatsink, or even an active cooling solution with a fan. Raspberry Pi shipped us an active cooling package to test out, and it plugs into a fan header on the board, so you know they mean business.</p>
<p>Raspberry Pi has also re-worked their case for the Pi 5, adding a fan with a removable cover, and vents on the underside. And they haven’t forgotten the power button here either – a small piece of acrylic serves as both a button cap and a power status light. Nice.</p>
<h2 id="pcie-for-real-this-time">PCIe, For Real This Time</h2>
<p>The most exciting new feature for people who wish to use the Pi 5 on the desktop is probably the official support for a real PCIe lane. When the Pi 4 came out, it was discovered that it spoke PCIe between the USB controller and the SOC, and of course <a href="https://hackaday.com/2020/07/01/adding-pcie-to-your-raspberry-pi-4-the-easier-way/">intercepting those lines was one of the first hacks</a> that we saw on the then-new Pi 4. Then came the CM4, which forced you to design your own board anyway, so you could choose between USB and PCIe. With the Pi 5, you don’t have to choose, and you won’t have to hack on it either.</p>
<p><a href="https://hackaday.com/wp-content/uploads/2023/09/PI_5_TOP_pcie.png" target="_blank"><img data-attachment-id="623901" data-permalink="https://hackaday.com/2023/09/28/a-raspberry-pi-5-is-better-than-two-pi-4s/pi_5_top_pcie/" data-orig-file="https://hackaday.com/wp-content/uploads/2023/09/PI_5_TOP_pcie.png" data-orig-size="1226,1218" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="PI_5_TOP_pcie" data-image-description="" data-image-caption="" data-medium-file="https://hackaday.com/wp-content/uploads/2023/09/PI_5_TOP_pcie.png?w=400" data-large-file="https://hackaday.com/wp-content/uploads/2023/09/PI_5_TOP_pcie.png?w=629" decoding="async" loading="lazy" src="https://hackaday.com/wp-content/uploads/2023/09/PI_5_TOP_pcie.png?w=400" alt="" width="400" height="397" srcset="https://hackaday.com/wp-content/uploads/2023/09/PI_5_TOP_pcie.png 1226w, https://hackaday.com/wp-content/uploads/2023/09/PI_5_TOP_pcie.png?resize=250,248 250w, https://hackaday.com/wp-content/uploads/2023/09/PI_5_TOP_pcie.png?resize=400,397 400w, https://hackaday.com/wp-content/uploads/2023/09/PI_5_TOP_pcie.png?resize=629,625 629w" sizes="(max-width: 400px) 100vw, 400px"></a>But you will need an adapter. A single PCIe 2.0 lane is broken out to a flat-flex connector, and from there you’ll need an adapter board to connect it up to whichever peripherals you’ve got in mind. Adapters will doubtless come on the market soon, but if you just can’t wait, we’ve got a <a href="https://hackaday.com/2023/03/14/pcie-for-hackers-the-diffpair-prelude/">tutorial series on making your own PCIe devices</a> to help.</p>
<p>Once you get the connections sorted out, you might also try pushing it up to PCIe 3.0 speeds. [Jeff Geerling] got a preview hardware adapter from Raspberry Pi, and <a href="https://www.jeffgeerling.com/blog/2023/testing-pcie-on-raspberry-pi-5" target="_blank">found that although it’s not certified for PCIe 3.0, it works most of the time at those speeds</a>. With an NVMe hard drive attached, he found that he could get 450 MB/sec using the sanctioned PCIe 2.0, and almost 900 MB/sec by changing a line in <code>/boot/config.txt</code>, enabling the unsupported PCIe 3.0 mode, and crossing his fingers. That was easy.</p>
<h2 id="under-the-hood-the-rp1-custom-controller">Under the Hood: The RP1 Custom Controller</h2>
<p>Power supply tweaks, including the power button, are down to Raspberry Pi’s cooperation with Renesas. More computational grunt comes from Broadcom’s new SOC. But features like the dual MIPI connectors or the dual USB 3.0 <em>and</em> USB 2.0 ports with enough bandwidth that they don’t crowd out each other or any of the other peripherals, are all due to Raspberry Pi’s in-house innovation here: the custom RP1 interface / southbridge chip.</p>
<p><a href="https://hackaday.com/wp-content/uploads/2023/09/ch01-raspberrypi5-rp1_thumbnail.png" target="_blank"><img data-attachment-id="623886" data-permalink="https://hackaday.com/2023/09/28/a-raspberry-pi-5-is-better-than-two-pi-4s/ch01-raspberrypi5-rp1_thumbnail/" data-orig-file="https://hackaday.com/wp-content/uploads/2023/09/ch01-raspberrypi5-rp1_thumbnail.png" data-orig-size="1200,1200" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="ch01-raspberrypi5-rp1_thumbnail" data-image-description="" data-image-caption="" data-medium-file="https://hackaday.com/wp-content/uploads/2023/09/ch01-raspberrypi5-rp1_thumbnail.png?w=400" data-large-file="https://hackaday.com/wp-content/uploads/2023/09/ch01-raspberrypi5-rp1_thumbnail.png?w=625" decoding="async" loading="lazy" src="https://hackaday.com/wp-content/uploads/2023/09/ch01-raspberrypi5-rp1_thumbnail.png?w=400" alt="" width="400" height="400" srcset="https://hackaday.com/wp-content/uploads/2023/09/ch01-raspberrypi5-rp1_thumbnail.png 1200w, https://hackaday.com/wp-content/uploads/2023/09/ch01-raspberrypi5-rp1_thumbnail.png?resize=250,250 250w, https://hackaday.com/wp-content/uploads/2023/09/ch01-raspberrypi5-rp1_thumbnail.png?resize=400,400 400w, https://hackaday.com/wp-content/uploads/2023/09/ch01-raspberrypi5-rp1_thumbnail.png?resize=625,625 625w" sizes="(max-width: 400px) 100vw, 400px"></a>According to Eben Upton, Raspberry Pi’s CEO, “It’s basically a chiplet architecture: all the rage now, but very forward-thinking when we started the RP1 development program back in 2016.” Broadcom makes the SOC at a very fine feature scale, while Raspberry Pi can use larger and cheaper processes to handle the rest: Ethernet, USB, MIPI, analog video out, USART, I2C, I2S, PWM, and GPIO – everything but SDRAM, the SD card, and HDMI.</p>
<p>The Raspberry Pi 5 uses PCIe for the backbone between the SOC and their RP1 chip. Four lanes of PCIe, to be exact, providing a 16 Gb/s link between the body and the brains. This is interesting because most chiplet designs are entirely proprietary, and both chips need to speak a common secret language. Here, Raspberry Pi and Broadcom can collaborate, but almost at arm’s length, because there’s nothing proprietary about PCIe. And because they had a spare PCIe channel on the SOC, they were able to break it out for the end user.</p>
<p>Desoldering the RP1 and doing without all the peripherals it provides, patching the kernel appropriately, and turning the Pi 5 into an all-PCIe, five-channel monstrosity is left as an exercise to the motivated reader.</p>
<h2 id="odds-and-ends">Odds and Ends</h2>
<p><a href="https://hackaday.com/wp-content/uploads/2023/09/ch01-raspberrypi5-csidsi_thumbnail.png" target="_blank"><img data-attachment-id="623885" data-permalink="https://hackaday.com/2023/09/28/a-raspberry-pi-5-is-better-than-two-pi-4s/ch01-raspberrypi5-csidsi_thumbnail/" data-orig-file="https://hackaday.com/wp-content/uploads/2023/09/ch01-raspberrypi5-csidsi_thumbnail.png" data-orig-size="1200,1200" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="ch01-raspberrypi5-csidsi_thumbnail" data-image-description="" data-image-caption="" data-medium-file="https://hackaday.com/wp-content/uploads/2023/09/ch01-raspberrypi5-csidsi_thumbnail.png?w=400" data-large-file="https://hackaday.com/wp-content/uploads/2023/09/ch01-raspberrypi5-csidsi_thumbnail.png?w=625" decoding="async" loading="lazy" src="https://hackaday.com/wp-content/uploads/2023/09/ch01-raspberrypi5-csidsi_thumbnail.png?w=400" alt="" width="400" height="400" srcset="https://hackaday.com/wp-content/uploads/2023/09/ch01-raspberrypi5-csidsi_thumbnail.png 1200w, https://hackaday.com/wp-content/uploads/2023/09/ch01-raspberrypi5-csidsi_thumbnail.png?resize=250,250 250w, https://hackaday.com/wp-content/uploads/2023/09/ch01-raspberrypi5-csidsi_thumbnail.png?resize=400,400 400w, https://hackaday.com/wp-content/uploads/2023/09/ch01-raspberrypi5-csidsi_thumbnail.png?resize=625,625 625w" sizes="(max-width: 400px) 100vw, 400px"></a>The big yellow composite video-out is gone from the Raspberry Pi 5, but they broke out the lines for you to solder to if you want to hook it up to something other than HDMI. The old audio output jack has been removed entirely, so you’re probably going to have to rely on HDMI audio out or a HAT if you want hi-fi audio. Other connections include PoE on a four-pin header, an ARM debug / UART on a three pin header, and a JST battery connector to keep the real-time clock module ticking.</p>
<p>Since you might want a heatsink, with fan or without, they’ve added mounting holes spaced around the processor. For space reasons, the MIPI camera/display flat-flex connectors use the thinner form factor that we’ve seen on the Pi Zero, rather than the wider one on the Pi 4.</p>
<h2 id="raspberry-pi-evolution">Raspberry Pi Evolution</h2>
<p>The Raspberry Pi 5 is, in some ways, a modest step forward. A two-times speedup isn’t anything to sneeze at, and the various quality-of-life improvements scattered throughout are great, but none of this is revolutionary when you look at the state of play in the SBC market. Still, the Pi 5 is at least twice as nice as the Pi 4, and at only a small upcharge. If you think back six months ago, where people were paying absurd markups for Pi 4s, the Raspberry Pi 5 is positively a bargain. And while there are faster Linux SBCs on the market these days, they also cost a lot more, so the value proposition of the Pi 5 is still solid. Add in Raspberry Pi’s documentation and software support, and there’s a lot here to like.</p>
<p>They’re not available in stores just yet, but Raspberry Pi plans to have “just under a million” Pi 5s produced and in stores over the course of the rest of 2023, so they’re not going to be scarce — we hope! If you need the speed, and can handle the heat, there’s no reason not to get a Raspberry Pi 5.</p>
	            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why is Debian the way it is? (274 pts)]]></title>
            <link>https://blog.liw.fi/posts/2023/debian-reasons/</link>
            <guid>37809276</guid>
            <pubDate>Sun, 08 Oct 2023 10:21:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.liw.fi/posts/2023/debian-reasons/">https://blog.liw.fi/posts/2023/debian-reasons/</a>, See on <a href="https://news.ycombinator.com/item?id=37809276">Hacker News</a></p>
<div id="readability-page-1" class="page"><article class="page">
    

    

    <section id="pagebody">
	<div>
<ol>
	<li><a href="#what-debian-wants-to-be">What Debian wants to be</a>
	</li>
	<li><a href="#the-constitution-power-structure-governance">The constitution, power structure, governance</a>
	</li>
	<li><a href="#social-contract-and-debian-free-software-guidelines">Social contract and Debian free software guidelines</a>
	</li>
	<li><a href="#self-contained">Self-contained</a>
	</li>
	<li><a href="#no-bundled-libraries">No bundled libraries</a>
	</li>
	<li><a href="#membership-process">Membership process</a>
	</li>
	<li><a href="#release-code-names">Release code names</a>
	</li>
	<li><a href="#changing-slowly">Changing slowly</a>
	</li>
</ol>


</div>
<p>Debian is a large, complex operating system, and a huge open source project. It’s thirty years old now. To many people, some of its aspects are weird. Most such things have a good reason, but it can be hard to find out what it is. This is an attempt to answer some such questions, without being a detailed history of the project.</p>
<h2 id="what-debian-wants-to-be"><a name="index1h1"></a>What Debian wants to be</h2>
<p>Debian wants to be a high-quality, secure general purpose operating system that consists only of free and open source software that runs on most kinds of computers that are in active use in the world.</p>
<p>By general purpose I mean Debian should be suitable for most people for most purposes. There will always be situations where it’s not suitable, for whatever reason, but it’s a good goal to aim for. Some other distributions aim for specific purposes: a desktop, a server, playing games, doing scientific research, etc. It’s fine to aim to be general purpose, or specific purpose, but the choice of goal leads to different decisions along the way.</p>
<p>For Debian, aiming to be general purpose means that Debian doesn’t choose what to package based on the purpose of the software. The only real choice Debian makes here is on whether the software is free and whether it’s plausible for Debian to maintain a high quality package.</p>
<h2 id="the-constitution-power-structure-governance"><a name="index2h1"></a>The constitution, power structure, governance</h2>
<p>Debian is one of the more explicitly democratic open source organizations. It has well-defined processes for making decisions, and elects a project leader every year. Further, the powers of the project leader are strictly constrained, and most powers usually associated with leadership are explicitly delegated to other people.</p>
<p>The historic background for this is that the first Debian project leaders were implicitly all-powerful dictators until they chose to step down. Then one project leader went too far, and a revolt threw them out, and democracy was introduced. As part of this, the project got a formal <a href="https://www.debian.org/devel/constitution">constitution</a>, which defines rules for the project.</p>
<p>The reason Debian has the rules it has, is because less rules, and less bureaucracy, didn’t work for Debian earlier in its history.</p>
<h2 id="social-contract-and-debian-free-software-guidelines"><a name="index3h1"></a>Social contract and Debian free software guidelines</h2>
<p>In the mid-1990s, before the term open source had been introduced, what was “free software” was defined by the Free Software Foundation, but in a way that left much to be interpreted. Debian wanted to have clearer rules, and came up with the Debian Free Software Guidelines, and made them part of its <a href="https://www.debian.org/social_contract">Social Contract</a>.</p>
<p>The social contract is Debian’s promise to itself and to the world at large about what Debian is and does. The DFSG is part of that. This is a foundation document for Debian, and changing it is intentionally made difficult in the Debian constitution.</p>
<p>The more detailed rules have made it clearer what Debian will accept, and have simplified discussions about this. There is still a lot to discuss, of course.</p>
<p>The DFSG was later the basis of the <a href="https://opensource.org/osd/">Open Source Definition</a>.</p>
<h2 id="self-contained"><a name="index4h1"></a>Self-contained</h2>
<p>Debian insists on being self-contained. Anything that is packaged in Debian, by Debian, must be built (compiled) using only dependencies in Debian. Also, everything in Debian must be built by Debian. This can cause a lot of extra work. For example, current programming language tooling often assumes it can download dependencies from online repositories at build time, and that is not acceptable to Debian.</p>
<p>The main reason for this is that a dependency might not be available later. Debian has no control over third party package repositories, and if a package, or entire repository, goes away, it might be impossible for Debian to rebuild the package. Debian needs to rebuild to upgrade to a new compiler, to fix a security problem, to port to a new architecture, or just to make some change to the packaged software, including bug fixes.</p>
<p>If Debian weren’t self-contained, it would be at the mercy of any of the tens of thousands of packages it has, and all their dependencies, being available when an urgent security fix needs to be released. This is not acceptable to Debian, and so Debian chooses to do the work of packaging all dependencies.</p>
<p>That means, of course, that for Debian to package something can be a lot of work.</p>
<h2 id="no-bundled-libraries"><a name="index5h1"></a>No bundled libraries</h2>
<p>Debian avoids using copies of libraries, or other dependencies, that are bundled with the software it packages. Many upstream projects find it easier to bundle or “vendor” dependencies, but for Debian, this means that there can be many copies of some popular libraries. When there is a need to fix a security or other severe problem in such a library, Debian would have to find all copies to fix them. This can be a lot of work, and if the security problem is urgent, it wastes valuable time to have to do that.</p>
<p>As an example: the zlib is used by a very large number of projects. By its nature, it needs to process data that may be constructed to exploit a vulnerability in the library. This has happened. At one point, Debian found dozens of bundled copies of zlib in its archive, and spent considerable effort making sure only the packaged version of zlib is used by packages in Debian.</p>
<p>Thus, Debian chooses to do the work up front, before it’s urgent, while packaging the software, and make sure the package in Debian uses the version of the library packaged in Debian.</p>
<p>This is not always appreciated by upstream developers, who would prefer to only have to deal with the version of the library they bundle. That’s the version they’ve verified their own software with. This sometimes leads to friction with Debian.</p>
<h2 id="membership-process"><a name="index6h1"></a>Membership process</h2>
<p>Given the size and complexity of Debian as an operating system, and its popularity, the project needs to trust its members. This especially means trusting those who upload new packages. Because of technical limitations in Linux in the 1990s, every Debian package has full root access during its installation. In other words, every Debian developer can potentially become the root user on any machine running Debian. With tens of millions of machines running Debian, that is potentially a lot of power.</p>
<p>Debian vets its new members in various ways. Ideally, every new member has been part of the Debian development community sufficiently long that they are known to others, and they’ve built trust within the community.</p>
<p>The process can be quite frustrating to those wanting to join Debian, especially to someone used to a smaller open source project.</p>
<h2 id="release-code-names"><a name="index7h1"></a>Release code names</h2>
<p>Debian assigns a code name for its each major release. This was originally done to make mirroring the Debian package archive less costly.</p>
<p>In the mid-1990s, when Debian was getting close to making its 1.0 release, code names weren’t used. Instead, the archive had a directory for each release, named after its version. Developing a new release takes a while, so the directory “1.0” was created well ahead of time. Unfortunately, a publisher of CD-ROMs, prematurely mass-produced a disc they labeled 1.0, before Debian had actually finished making 1.0. This meant that people who got the Debian 1.0 CD-ROM got something that wasn’t actually 1.0.</p>
<p>An obvious solution to prevent this from happening again would have been to prepare the release in a directory called “1.0-not-released”, and rename the directory to “1.0” after the release was finished. However, this would’ve meant that all the mirrors would’ve had to re-download the release when the name of the directory changed. That would’ve been costly, given the massive size of Debian (hundreds of packages! tens of megabytes!). Thus, Debian chose to use code names instead.</p>
<p>Later, the “pool” structure was added to the Debian archive. With this, the files for all releases are in the same directory tree, and metadata files specify what files belong to each release. This makes mirroring easier. It might be possible to drop the code names and stick to versions, now, but I don’t know if Debian would be interested in that.</p>
<h2 id="changing-slowly"><a name="index8h1"></a>Changing slowly</h2>
<p>As implied above, Debian is huge. It’s massive. It’s enormous, It’s really not very small at all, any more.</p>
<p>Large ships stop slowly. Large projects change slowly. Any change in Debian that affects large portion of its packages may require hundreds of volunteers to do work. That is not going to happen quickly.</p>
<p>Sometimes the work can be done with just a small number of people, and Debian has processes to enable that. As an example, if a new version of the GNU C compiler is uploaded, the work of finding out what fixes in other packages need to be made can usually be done by a handful of people.</p>
<p>Often a change takes time because there’s a need to build consensus, and that requires extensive discussion, which takes time and can only rarely be short-circuited.</p>
<p>This all also means Debian developers tend to be conservative in technical decisions. They often prefer solutions that don’t require large scale changes.</p>
<hr>
<p>To comment publicly, please use <a href="https://toot.liw.fi/@liw/111198682212279688">this fediverse thread</a>.</p>

      </section>

  </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Pg_bm25: Elastic-Quality Full Text Search Inside Postgres (179 pts)]]></title>
            <link>https://docs.paradedb.com/blog/introducing_bm25</link>
            <guid>37809126</guid>
            <pubDate>Sun, 08 Oct 2023 09:43:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://docs.paradedb.com/blog/introducing_bm25">https://docs.paradedb.com/blog/introducing_bm25</a>, See on <a href="https://news.ycombinator.com/item?id=37809126">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><img src="https://mintlify.s3-us-west-1.amazonaws.com/paradedb/blog/images/bm25.png"></p><p>We’re unveiling <code>pg_bm25</code>: a Rust-based Postgres extension that significantly improves Postgres’ full text
search capabilities. <code>pg_bm25</code> is named after BM25, the algorithm used by modern search engines to calculate the
relevance scores of search results.</p>
<p>Today, Postgres’ native full text search, which uses the <code>tsvector</code> type, has two main problems:</p>
<ol role="list">
<li><strong>Performance</strong>: Searching and ranking over large tables is sluggish. When tables grow to millions of rows, a single full text search can take several minutes.</li>
<li><strong>Functionality</strong>: Postgres has no support for operations like fuzzy search, relevance tuning, or
BM25 relevance scoring, which are the bread and butter of modern search engines.</li>
</ol>
<p><code>pg_bm25</code> aims to bridge the gap between the native capabilities of Postgres’ full text search and those of a specialized search engine like ElasticSearch.
The goal is to eliminate the need to bring a cumbersome service like ElasticSearch into the data stack.</p>
<p>Some features of <code>pg_bm25</code> include:</p>
<ul role="list">
<li>100% Postgres native, with zero dependencies on an external search engine</li>
<li>Built on top of Tantivy, a Rust-based alternative to the Apache Lucene search library</li>
<li>Query times over 1M rows are 20x faster compared to <code>tsquery</code> and <code>ts_rank</code>, Postgres’ built-in full text search and sort functions</li>
<li>Support for fuzzy search, aggregations, highlighting, and relevance tuning</li>
<li>Relevance scoring uses BM25, the same algorithm used by ElasticSearch</li>
<li>Real-time search — new data is immediately searchable without manual reindexing</li>
</ul>
<p><code>pg_bm25</code> stands on the shoulders of several open-source giants. The goal of this blog post is to recognize these projects
and to share how <code>pg_bm25</code> was built.</p>
<h2 id="the-shoulders-of-giants"><span>The Shoulders of Giants</span></h2>
<p>Putting a search engine inside of Postgres is hard. A few projects have attempted it, but with one caveat: every
single one has relied on an external ElasticSearch instance. This means introducing a
complex and expensive piece of infrastructure into the data stack. Perhaps the best-known example of this kind of design
is a Postgres extension called <a href="https://github.com/zombodb/zombodb" target="_blank" rel="noreferrer">ZomboDB</a>.</p>
<p>In 2016, an open source search library called <a href="https://github.com/quickwit-oss/tantivy" target="_blank" rel="noreferrer">Tantivy</a> emerged. Tantivy
was designed as a Rust-based alternative to Apache Lucene, the search library that powers ElasticSearch.
Three years later, a library called <a href="https://github.com/pgcentralfoundation/pgrx" target="_blank" rel="noreferrer">pgrx</a> — built by the same
author of ZomboDB — made it possible to build Postgres extensions in Rust.
Combined, these projects laid the groundwork for a Postgres extension that could create Elastic-quality
search experiences within Postgres.</p>
<h2 id="creating-the-inverted-index"><span>Creating the Inverted Index</span></h2>
<p>Like ElasticSearch, the backbone of Tantivy’s search engine is a data structure called the inverted index,
which stores a mapping from words to their locations in a set of documents. An inverted index
is like the table of contents of a book — without it, you might have to examine every page to find
a specific chapter.</p>
<p>Rather than creating this inverted index externally, <code>pg_bm25</code> stores the
index inside Postgres as a new, Postgres-native index type, which we call the BM25 index. This is made possible
through Postgres’ <a href="https://www.postgresql.org/docs/current/indexam.html" target="_blank" rel="noreferrer">index access method</a> API.</p>
<p>When a BM25 index is created, Postgres automatically updates it as new data arrives
or is deleted in the underlying SQL table. In this way, <code>pg_bm25</code> enables real-time search without any
additional reindexing logic.</p>
<h2 id="building-the-sql-interface"><span>Building the SQL Interface</span></h2>
<p>Following index creation, the next step was to expose an intuitive SQL interface for users to write search queries.
This was accomplished through the Postgres <a href="https://www.postgresql.org/docs/current/sql-createoperator.html" target="_blank" rel="noreferrer">operator API</a>,
which enables the creation of custom Postgres operators. We chose the <code>@@@</code> operator to signify the beginning
of a query to the BM25 index in homage to the <code>@@</code> operator used by Postgres’ native full text search.</p>
<p>The end result is the ability to search any table with a single SQL query.</p>
<div><pre><code><span>SELECT</span> <span>*</span>
<span>FROM</span> my_table
<span>WHERE</span> my_table @@@ <span>'"my query string"'</span>
</code></pre></div>
<p>Wherever possible, we designed the SQL interface to transparently mirror Tantivy’s API. For instance,
the right-hand side of the <code>@@@</code> operator accepts Tantivy’s mini query language and configuration options.</p>
<div><pre><code><span>SELECT</span> <span>*</span>
<span>FROM</span> my_table
<span>WHERE</span> my_table @@@ <span>'description:keyboard^2 OR electronics:::fuzzy_fields=description&amp;distance=2'</span>
</code></pre></div>
<h2 id="performance-benchmarks"><span>Performance Benchmarks</span></h2>
<p>On a table with one million rows, <code>pg_bm25</code> indexes 50 seconds faster than <code>tsvector</code> and ranks results
20x faster. Indexing and search times are nearly identical to those of a dedicated ElasticSearch instance.
With further optimizations, we’re aiming to reduce the query times compared to ElasticSearch
by an additional 2x.</p>
<p>More detailed benchmark results can be found in the extension <a href="https://github.com/paradedb/paradedb/tree/dev/pg_bm25#benchmarks" target="_blank" rel="noreferrer">README</a>.</p>
<h2 id="wrapping-up"><span>Wrapping Up</span></h2>
<p><code>pg_bm25</code> is ready for use today. There are two ways to try it: <a href="https://github.com/paradedb/paradedb/tree/dev/pg_bm25#installation" target="_blank" rel="noreferrer">installing it</a> inside an existing, self-hosted Postgres instance,
or <a href="https://github.com/paradedb/paradedb#from-self-hosted-postgres" target="_blank" rel="noreferrer">running the Postgres Docker image</a>.</p>
<p><code>pg_bm25</code> is open-source and licensed under AGPL. If you’d like to contribute, the best place to start is our
<a href="https://join.slack.com/t/paradedbcommunity/shared_invite/zt-217mordsh-ielS6BiZf7VW3rqKBFgAlQ" target="_blank" rel="noreferrer">Slack community</a>. And please don’t hesitate to show your support by
<a href="https://github.com/paradedb/paradedb" target="_blank" rel="noreferrer">giving us a star</a>!</p></div></div>]]></description>
        </item>
    </channel>
</rss>