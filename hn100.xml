<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 07 Oct 2023 14:00:06 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Shell Using Fortnite, TikTok, etc. to Convince Kids Fossil Fuels Are Cool (177 pts)]]></title>
            <link>https://kotaku.com/shell-big-oil-roadtrips-fortnite-map-collab-tiktok-ign-1850907435</link>
            <guid>37800507</guid>
            <pubDate>Sat, 07 Oct 2023 10:17:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://kotaku.com/shell-big-oil-roadtrips-fortnite-map-collab-tiktok-ign-1850907435">https://kotaku.com/shell-big-oil-roadtrips-fortnite-map-collab-tiktok-ign-1850907435</a>, See on <a href="https://news.ycombinator.com/item?id=37800507">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Kids today only care about online free-to-play shooter <em>Fortnite</em>. They don’t even talk about how great gasoline is! Luckily for us, one large oil company wants to change that using <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;Internal link&quot;,&quot;https://kotaku.com/fortnite-2022-quests-zero-build-fun-indiana-jones-1849327938&quot;,{&quot;metric25&quot;:1}]]" href="https://kotaku.com/fortnite-2022-quests-zero-build-fun-indiana-jones-1849327938"><em>Fortnite</em></a></span>, TikTok stars, and Twitch streamers. Welcome to Hell. </p><div data-video-id="191683" data-monetizable="true" data-position="sidebar" data-video-title="Dead By Daylight Devs’ New Game Is Fortnite Meets Doom" data-video-blog-id="9" data-video-network="kotaku" data-video-duration="87" data-playlist="191683,194440,190618" data-current="191683"><div><p>Dead By Daylight Devs’ New Game Is Fortnite Meets Doom</p></div><video disablepictureinpicture="" muted="" playsinline="" width="100%" height="100%" crossorigin="anonymous" preload="none"><source data-src="https://vid.kinja.com/prod/191683/191683_240p.mp4" label="240p" type="video/mp4"><source data-src="https://vid.kinja.com/prod/191683/191683_480p.mp4" label="480p" type="video/mp4"><source data-src="https://vid.kinja.com/prod/191683/191683_720p.mp4" label="720p" type="video/mp4"><source data-src="https://vid.kinja.com/prod/191683/191683_1080p.mp4" label="1080p" type="video/mp4"><track kind="captions" label="English" src="https://kinja.com/api/videoupload/caption/17452.vtt" srclang="en"></video><div><ul><li data-label="">Off</li><li data-label="English">English</li></ul></div></div><p>Climate change is bad. I think we can all agree on that. But for kids, who have long lives and futures ahead of them, the prospect of the planet turning into a nightmare sphere of extreme weather and chaos is particularly scary. But don’t worry about all that, kids. Instead, Shell—a massive oil company and one of the many entities directly responsible for destroying our planet—wants you all to know just how rad its fossil fuel products are, and even made a whole <em>Fortnite </em>world for you to enjoy! But to truly enjoy it, you’ll need to use Shell’s V-Power® NiTRO+ Premium Gasoline, of course.<br></p><p><span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.mediamatters.org/climate-deniers/after-decades-climate-deception-shell-uses-fortnite-court-demographic-most&quot;,{&quot;metric25&quot;:1}]]" href="https://www.mediamatters.org/climate-deniers/after-decades-climate-deception-shell-uses-fortnite-court-demographic-most" target="_blank" rel="noopener noreferrer">As reported by <em>Media Matters</em> earlier this week</a></span>, Shell has partnered with map creators to develop “<span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.shell.us/motorist/shell-ultimate-road-trips-sweepstakes.html#&quot;,{&quot;metric25&quot;:1}]]" href="https://www.shell.us/motorist/shell-ultimate-road-trips-sweepstakes.html#" target="_blank" rel="noopener noreferrer">Shell Ultimate Road Trips</a></span>”, a <em>Fortnite </em>world featuring six different areas to explore in the car of your choice. In the middle of these worlds, players will find a lonely, sad-looking Shell gas station acting as the map’s hub.<br></p><p>The campaign—part of <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.bloomberg.com/news/articles/2023-06-14/shell-boosts-dividend-15-as-it-pivots-back-toward-oil-and-gas#xj4y7vzkg&quot;,{&quot;metric25&quot;:1}]]" href="https://www.bloomberg.com/news/articles/2023-06-14/shell-boosts-dividend-15-as-it-pivots-back-toward-oil-and-gas#xj4y7vzkg" target="_blank" rel="noopener noreferrer">Shell’s pivot back to focusing on gasoline</a></span> over cleaner energy sources— is designed to promote the company’s “new and improved” premium gasoline. The idea is that in the map, players will need to occasionally fill up at the central Shell gas station and use its new V-Power NiTRO+ fuel to successfully navigate obstacles and courses.<br></p><h2 id="h165683"><a id=""></a><strong>Content creators are being enlisted to create big oil propaganda</strong></h2><p>To help promote this terrible collaboration, Shell has enlisted various TikTok creators and Twitch streamers in an effort to connect with their large audiences made up of mostly younger individuals.<br></p><p><em>Media Matters</em> reportedly identified at least a half dozen streamers—including folks like <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.mediamatters.org/media/4011824&quot;,{&quot;metric25&quot;:1}]]" href="https://www.mediamatters.org/media/4011824" target="_blank" rel="noopener noreferrer">Punisher</a></span>, <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.mediamatters.org/media/4011828&quot;,{&quot;metric25&quot;:1}]]" href="https://www.mediamatters.org/media/4011828" target="_blank" rel="noopener noreferrer">NateHill</a></span>, <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.mediamatters.org/media/4011823&quot;,{&quot;metric25&quot;:1}]]" href="https://www.mediamatters.org/media/4011823" target="_blank" rel="noopener noreferrer">Chica</a></span>, and <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.mediamatters.org/media/4011825&quot;,{&quot;metric25&quot;:1}]]" href="https://www.mediamatters.org/media/4011825" target="_blank" rel="noopener noreferrer">brookeab</a></span>—with a combined Twitch following of over 5.5 million subscribers—who helped promote Shell’s <em>Fortnite</em> map and fossil fuel products during sponsored streams that racked up over a million views. Some of these creators also promoted the sponsored streams on Instagram, Twitter, and TikTok to their millions of followers. <em>Media Matters</em> also identified three content creators who advertised the ShellxFortnite map in several videos posted on the gas company’s official YouTube, TikTok, and Instagram accounts.</p><p>The creators directly promoting Shell’s gasoline propaganda have a combined audience of 8.5 million TikTok followers, 1.5 million Instagram followers, and over 11 million YouTube subscribers. </p><p>In August, Shell even paid out for <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.ign.com/articles/shell-ultimate-road-trips-brings-you-to-a-new-fortnite-creative-map&quot;,{&quot;metric25&quot;:1}]]" href="https://www.ign.com/articles/shell-ultimate-road-trips-brings-you-to-a-new-fortnite-creative-map" target="_blank" rel="noopener noreferrer">a sponsored post on <em>IGN</em></a></span><em> </em>as well as a three-part series featuring <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://youtu.be/_EGuZmdRiR8&quot;,{&quot;metric25&quot;:1}]]" href="https://youtu.be/_EGuZmdRiR8" target="_blank" rel="noopener noreferrer"><em>IGN </em>staff playing <em>Fortnite</em></a></span><em> </em>and exploring the Shell-sponsored map. The videos are covered in Shell logos and featured on <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.ign.com/special/shell/&quot;,{&quot;metric25&quot;:1}]]" href="https://www.ign.com/special/shell/" target="_blank" rel="noopener noreferrer">a fancy <em>IGN</em>-hosted website</a></span> dedicated to the oil company’s <em>Fortnite</em> map.<br></p><h2 id="h165684"><a id=""></a><strong>Kids aren’t buying this crap</strong></h2><p>So how’s all this money and effort paying off? As far as I can tell, not great. For example, looking at that <em>IGN </em>article, it’s got only two comments and both are negative. On YouTube, the <em>IGN </em>videos have mostly received negative comments from viewers, with many calling out the outlet for sponsoring an oil company. Elsewhere, <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://youtu.be/1_UuXnHvsIQ&quot;,{&quot;metric25&quot;:1}]]" href="https://youtu.be/1_UuXnHvsIQ" target="_blank" rel="noopener noreferrer">the official trailers put out by Shell</a></span> for their <em>Fortnite </em>creation are similarly receiving negative comments.<br></p><p>“Drop in this season and complete the objective: ‘Do irreparable damage to the environment with Shell!” is the top-rated comment on <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://youtu.be/1_UuXnHvsIQ&quot;,{&quot;metric25&quot;:1}]]" href="https://youtu.be/1_UuXnHvsIQ" target="_blank" rel="noopener noreferrer">this trailer for the map</a></span>.<br></p><p>This is all part of an ongoing campaign by big oil companies, like Shell, to connect with younger people via online influencers and content creators. In 2021, <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;Internal link&quot;,&quot;https://gizmodo.com/the-big-oil-instagram-influencers-are-here-1847091004&quot;,{&quot;metric25&quot;:1}]]" href="https://gizmodo.com/the-big-oil-instagram-influencers-are-here-1847091004"><em>Earther </em>reported that Shell and Phillips 66</a></span> had started campaigns with Instagram influencers. These sponsored deals and ads aren’t just about promoting oil companies and their products. These large corporations know that as climate change gets worse, it’s getting harder to convince young people to keep buying gas-powered cars and supporting the fossil fuel industry.<br></p><p>As <em>Media Matters</em> pointed out, in a <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.thelancet.com/journals/lanplh/article/PIIS2542-5196(21)00278-3/fulltext&quot;,{&quot;metric25&quot;:1}]]" href="https://www.thelancet.com/journals/lanplh/article/PIIS2542-5196(21)00278-3/fulltext" target="_blank" rel="noopener noreferrer">2021 survey</a></span> of young people between the ages of 16-25, about 75% said the future is frightening because of climate change. It’s hard to sell gasoline and diesel to teens who know it’s destroying the planet and their futures. And it doesn’t look like some Instagram models and <em>Fortnite </em>videos on <em>IGN </em>promoting Shell are going to be enough to change their minds. <br></p><p>&nbsp; <!-- -->.<br></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Cloudflare is free of CAPTCHAs; Turnstile is free for everyone (146 pts)]]></title>
            <link>https://blog.cloudflare.com/turnstile-ga/</link>
            <guid>37799413</guid>
            <pubDate>Sat, 07 Oct 2023 06:13:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.cloudflare.com/turnstile-ga/">https://blog.cloudflare.com/turnstile-ga/</a>, See on <a href="https://news.ycombinator.com/item?id=37799413">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post">
    <article>
        


        <p localize="" datetime="2023-09-29T14:00:00+01:00">Loading...</p>
        

        <ul>
            <li>
                <a href="https://blog.cloudflare.com/author/benedikt/">
                    <img src="https://blog.cloudflare.com/cdn-cgi/image/format=auto,dpr=3,width=62,height=62/http://blog.cloudflare.com/content/images/2022/04/Screenshot-2020-10-27-165713.png" alt="Benedikt Wolters" width="62" height="62">
                </a>
                
            </li>
            <li>
                <a href="https://blog.cloudflare.com/author/maxime/">
                    <img src="https://blog.cloudflare.com/cdn-cgi/image/format=auto,dpr=3,width=62,height=62/http://blog.cloudflare.com/content/images/2019/06/unnamed.jpg" alt="Maxime Guerreiro" width="62" height="62">
                </a>
                
            </li>
            <li>
                <a href="https://blog.cloudflare.com/author/adam-martinetti/">
                    <img src="https://blog.cloudflare.com/cdn-cgi/image/format=auto,dpr=3,width=62,height=62/http://blog.cloudflare.com/content/images/2022/12/_tmp_uploaded20220909-4-1lugsmy.jpg" alt="Adam Martinetti" width="62" height="62">
                </a>
                
            </li>
        </ul>

        <section>
            <p>7 min read</p>
            <div>
                <figure><img src="https://blog.cloudflare.com/content/images/2023/09/image3-37.png" alt="" loading="lazy" width="1200" height="676"></figure><p>For years, we’ve <a href="https://blog.cloudflare.com/moving-from-recaptcha-to-hcaptcha/">written</a> that CAPTCHAs drive us crazy. Humans give up on CAPTCHA puzzles <a href="https://www.math.unipd.it/~gaggi/doc/ads20.pdf">approximately 15% of the time</a> and, maddeningly,<a href="https://www.usenix.org/conference/usenixsecurity23/presentation/searles"> CAPTCHAs are significantly easier for bots</a> to solve than they are for humans. We’ve spent the past three and a half years working to build a better experience for humans that’s just as effective at stopping bots. As of this month, we’ve finished replacing every CAPTCHA issued by Cloudflare with<strong> </strong>Turnstile, our new CAPTCHA replacement (pictured below). Cloudflare will never issue another visual puzzle to anyone, for any reason.</p><figure><img src="https://blog.cloudflare.com/content/images/2023/09/image2.gif" alt="" loading="lazy" width="878" height="300"></figure><p>Now that we’ve eliminated CAPTCHAs at Cloudflare, we want to make it easy for anyone to do the same, even if they don’t use other Cloudflare services. We’ve decoupled Turnstile from our platform so that any website operator on any platform can use it just by adding <a href="https://github.com/cloudflare/turnstile-demo-workers/blob/main/src/explicit.html#L74-L85">a few lines of code</a>. We’re thrilled to announce that Turnstile is now generally available, and <strong>Turnstile’s ‘Managed’ mode is now completely free to everyone for unlimited use</strong>. </p><h3 id="easy-on-humans-hard-on-bots-private-for-everyone">Easy on humans, hard on bots, private for everyone</h3><figure><img src="https://blog.cloudflare.com/content/images/2023/09/image6-5.png" alt="" loading="lazy" width="1999" height="607"></figure><p>There’s a lot that goes into Turnstile’s simple checkbox to ensure that it’s easy for everyone, preserves user privacy, and does its job stopping bots. Part of making challenges better for everyone means that everyone gets the same great experience, no matter what browser you’re using. Because we do not employ a visual puzzle, users with low vision or blindness get the same easy to use challenge flow as everyone else. </p><p>It was particularly important for us to avoid falling back to audio CAPTCHAs to offer an experience accessible to everyone. Audio CAPTCHAs are often much worse than even visual CAPTCHAs for humans to solve, with only<a href="https://web.stanford.edu/~jurafsky/burszstein_2010_captcha.pdf"> 31.2% of audio challenges</a> resulting in a three-person agreement on what the correct solution actually is. The prevalence of free speech-to-text services has made it easy for bots to solve audio CAPTCHAs as well, with <a href="https://uncaptcha.cs.umd.edu/papers/uncaptcha_woot17.pdf">a recent study</a> showing bots can accurately solve audio CAPTCHAs in over 85% of attempts. We’re proud to state that Turnstile is WCAG 2.1 Level AA compliant, while eliminating the need for audio CAPTCHAs as well as visual ones.</p><p>We also created Turnstile to be privacy focused. Turnstile meets <a href="https://www.cloudflare.com/learning/privacy/what-is-eprivacy-directive/">ePrivacy Directive</a>, <a href="https://www.cloudflare.com/learning/privacy/what-is-the-gdpr/">GDPR</a> and <a href="https://www.cloudflare.com/learning/privacy/what-is-the-ccpa/">CCPA</a> compliance requirements, as well as the strict requirements of our own privacy commitments. In addition, Cloudflare's <a href="https://marketplace.fedramp.gov/products/FR2000863987">FedRAMP Moderate authorized package</a>, "Cloudflare for Government" now includes Turnstile. We don’t rely on tracking user data, like what other websites someone has visited, to determine if a user is a human or robot. Our business is protecting websites, not selling ads, so operators can deploy Turnstile knowing that their users’ data is safe.</p><p>With all of our emphasis on how <em>easy</em> it is to pass a Turnstile challenge, you would be right to ask how it can stop a bot. If a bot can find <a href="https://www.vox.com/22436832/captchas-getting-harder-ai-artificial-intelligence">all images with crosswalks</a> in grainy photos faster than we can, surely it can check a box as well. Bots definitely can check a box, and they can even<a href="https://arxiv.org/abs/1903.01003"> mimic the erratic path of human mouse movement</a> while doing so. For Turnstile, the actual act of checking a box isn’t important, it’s the background data we’re analyzing while the box is checked that matters. We find and stop bots by running a series of in-browser tests, checking browser characteristics, native browser APIs, and asking the browser to pass lightweight tests (ex: proof-of-work tests, proof-of-space tests) to prove that it’s an actual browser. The current deployment of Turnstile checks billions of visitors every day, and we are able to identify browser abnormalities that bots exhibit while attempting to pass those tests.</p><p>For over one year, <a href="https://blog.cloudflare.com/end-cloudflare-captcha/">we used our Managed Challenge</a> to rotate between CAPTCHAs and our own Turnstile challenge to compare our effectiveness. We found that <strong>even without asking users for any interactivity at all</strong>, Turnstile was just as effective as a CAPTCHA. Once we were sure that the results were effective at coping with the response from bot makers, we replaced the CAPTCHA challenge with our own checkbox solution. We present this extra test when we see potentially suspicious signals, and it helps us provide an even greater layer of security.</p><h3 id="turnstile-is-great-for-fighting-fraud">Turnstile is great for fighting fraud</h3><p>Like all sites that offer services for free, Cloudflare sees our fair share of automated account signups, which can include “new account fraud,” where bad actors automate the creation of many different accounts to abuse our platform. To help combat this abuse, we’ve rolled out Turnstile’s invisible mode to protect our own signup page. This month, we’ve blocked <strong>over</strong> <strong>1 million automated signup attempts </strong>using Turnstile, without a reported false positive or any change in our self-service billings that rely on this signup flow. &nbsp;</p><h3 id="lessons-from-the-turnstile-beta">Lessons from the Turnstile beta</h3><figure><img src="https://blog.cloudflare.com/content/images/2023/09/image5-11.png" alt="" loading="lazy" title="Chart" width="1200" height="742"></figure><p>Over the past twelve months, we’ve been grateful to see how many people are eager to try, then rely on, and integrate Turnstile into their web applications. It’s been rewarding to see the developer community embrace Turnstile as well. We list some of the community created Turnstile integrations <a href="https://developers.cloudflare.com/turnstile/community-resources/">here</a>, including integrations with WordPress, Angular, Vue, and a Cloudflare recommended <a href="https://www.npmjs.com/package/@marsidev/react-turnstile">React library</a>. We’ve listened to customer feedback, and added support for <a href="https://developers.cloudflare.com/turnstile/reference/supported-languages/">17 new languages</a>, <a href="https://developers.cloudflare.com/turnstile/get-started/client-side-rendering/">new callbacks</a>, and <a href="https://developers.cloudflare.com/turnstile/reference/client-side-errors/">new error codes</a>. </p><p>76,000+ users have signed up, but our biggest single test by far was the <a href="https://blog.cloudflare.com/how-cloudflare-scaled-and-protected-eurovision-2023-voting/">Eurovision final vote</a>. Turnstile runs on challenge pages on over 25 million Cloudflare websites. Usually, that makes Cloudflare the far and away biggest Turnstile consumer, until the final Eurovision vote. During that one hour, challenge traffic from the Eurovision voting site outpaced the use of challenge pages on those 25 million sites combined! Turnstile handled the enormous spike in traffic without a hitch. </p><p>While a lot went well during the Turnstile beta, we also encountered some opportunities for us to learn. We were initially resistant to disclosing why a Turnstile challenge failed. After all, if bad actors know what we’re looking for, it becomes easier for bots to fool our challenges until we introduce new detections. However, during the Turnstile beta, we saw a few scenarios where legitimate users could not pass a challenge. These scenarios made it clear to us that we need to be transparent about why a challenge failed to help aid any individual who might modify their browser in a way that causes them to get caught by Turnstile. We now publish detailed client-side error codes to surface the reason why a challenge has failed. Two scenarios came up on several occasions that we didn’t expect: </p><p>First, we saw that desktop computers at least 10 years old frequently had expired motherboard batteries, and computers with bad motherboard batteries very often keep inaccurate time. This is because without the motherboard battery, a desktop computer’s clock will stop operating when the computer is off. Turnstile checks your computer’s system time to detect when a website operator has accidentally configured a challenge page to be cached, as caching a challenge page will cause it to become impassable. Unfortunately, this same check was unintentionally catching humans who just needed to update the time. When we see this issue, we now surface a clear error message to the end user to update their system time. We’d prefer to never have to surface an error in the first place, so we’re working to develop new ways to check for cached content that won’t impact real people. </p><p>Second, we find that a few privacy-focused users often ask their browsers to go beyond standard practices to preserve their anonymity. This includes changing their user-agent (something bots will do to evade detection as well), and preventing third-party scripts from executing entirely. Issues caused by this behavior can now be displayed clearly in a Turnstile widget, so those users can immediately understand the issue and make a conscientious choice about whether they want to allow their browser to pass a challenge.</p><p>Although we have some of the most sensitive, thoroughly built monitoring systems at Cloudflare, we did not catch either of these issues on our own. We needed to talk to users affected by the issue to help us understand what the problem was. Going forward, we want to make sure we always have that direct line of communication open. We’re rolling out a new feedback form in the Turnstile widget, to ensure any future corner cases are addressed quickly and with urgency.</p><figure><img src="https://blog.cloudflare.com/content/images/2023/09/Screenshot-2023-09-29-at-11.37.58.png" alt="" loading="lazy" width="1608" height="464"></figure><h3 id="turnstile-ga-and-free-for-everyone">Turnstile: GA and Free for Everyone </h3><p>Announcing Turnstile’s General Availability means that Turnstile is now completely production ready, available for free for unlimited use via our visible widget in Managed mode. Turnstile Enterprise includes SaaS platform support and a visible mode without the Cloudflare logo. Self-serve customers can expect a pay-as-you-go option for advanced features to be available in early 2024. Users can continue to access Turnstile’s advanced features below our 1 million siteverify request limit, as has been the case during the beta. If you’ve been waiting to try Turnstile, head over to our <a href="https://www.cloudflare.com/products/turnstile/">signup page</a> and create an account!</p>
            </div>
        </section>
    
        









    <div>
            <p>We protect
                <a target="_blank" href="https://www.cloudflare.com/network-services/">entire corporate networks</a>,
                    help customers build
                    <a target="_blank" href="https://workers.cloudflare.com/">Internet-scale applications efficiently</a>,
                    accelerate any
                    <a target="_blank" href="https://www.cloudflare.com/performance/accelerate-internet-applications/">website
                    or Internet application</a>,
                    <a target="_blank" href="https://www.cloudflare.com/ddos/">ward off DDoS
                    attacks</a>, keep
                    <a target="_blank" href="https://www.cloudflare.com/application-security/">hackers at
                    bay</a>,
                    and can help you on
                    <a target="_blank" href="https://www.cloudflare.com/products/zero-trust/">your journey to Zero Trust</a>.</p>
            <p>Visit <a target="_blank" href="https://1.1.1.1/">1.1.1.1</a> from any device to get started with
                our free app that makes your Internet faster and safer.</p>
            <p>To learn more about our mission to help build a better Internet, <a target="_blank" href="https://www.cloudflare.com/learning/what-is-cloudflare/">start here</a>. If you're looking for a
                new career direction, check out <a target="_blank" href="https://cloudflare.com/careers">our open
                    positions</a>.</p>
        </div>

        

        
        

        <a href="https://blog.cloudflare.com/tag/birthday-week/">Birthday Week</a>
        <a href="https://blog.cloudflare.com/tag/product-news/">Product News</a>
        <a href="https://blog.cloudflare.com/tag/turnstile/">Turnstile</a>
        <a href="https://blog.cloudflare.com/tag/captcha/">CAPTCHA</a>
        <a href="https://blog.cloudflare.com/tag/speed-and-reliability/">Speed &amp; Reliability</a>
    </article>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Documented source code for Elite on the NES (161 pts)]]></title>
            <link>https://github.com/markmoxon/nes-elite-beebasm</link>
            <guid>37798914</guid>
            <pubDate>Sat, 07 Oct 2023 04:03:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/markmoxon/nes-elite-beebasm">https://github.com/markmoxon/nes-elite-beebasm</a>, See on <a href="https://news.ycombinator.com/item?id=37798914">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" id="user-content-fully-documented-source-code-for-elite-on-the-nes" dir="auto"><a href="#fully-documented-source-code-for-elite-on-the-nes">Fully documented source code for Elite on the NES</a></h2>
<p dir="auto"><a href="https://github.com/markmoxon/cassette-elite-beebasm">BBC Micro (cassette)</a> | <a href="https://github.com/markmoxon/disc-elite-beebasm">BBC Micro (disc)</a> | <a href="https://github.com/markmoxon/6502sp-elite-beebasm">6502 Second Processor</a> | <a href="https://github.com/markmoxon/master-elite-beebasm">BBC Master</a> | <a href="https://github.com/markmoxon/electron-elite-beebasm">Acorn Electron</a> | <a href="https://github.com/markmoxon/elite-a-beebasm">Elite-A</a> | <strong>NES</strong></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/94fa2714bfdbcffcfc5c917f6f2751344020c5f2cc4f0582fdbc87117dfce6f1/68747470733a2f2f7777772e626263656c6974652e636f6d2f696d616765732f6769746875622f6e65732d73746174696f6e2e706e67"><img src="https://camo.githubusercontent.com/94fa2714bfdbcffcfc5c917f6f2751344020c5f2cc4f0582fdbc87117dfce6f1/68747470733a2f2f7777772e626263656c6974652e636f6d2f696d616765732f6769746875622f6e65732d73746174696f6e2e706e67" alt="Screenshot of Elite on the NES" data-canonical-src="https://www.bbcelite.com/images/github/nes-station.png"></a></p>
<p dir="auto">This repository contains source code for Elite on the Nintendo Entertainment System (NES), with every single line documented and (for the most part) explained.</p>
<p dir="auto">It is a companion to the <a href="https://www.bbcelite.com/" rel="nofollow">bbcelite.com website</a>.</p>
<p dir="auto">See the <a href="#introduction">introduction</a> for more information, or jump straight into the <a href="https://github.com/markmoxon/nes-elite-beebasm/blob/main/1-source-files/main-sources">documented source code</a>.</p>
<h2 tabindex="-1" id="user-content-contents" dir="auto"><a href="#contents">Contents</a></h2>
<ul dir="auto">
<li>
<p dir="auto"><a href="#introduction">Introduction</a></p>
</li>
<li>
<p dir="auto"><a href="#acknowledgements">Acknowledgements</a></p>
<ul dir="auto">
<li><a href="#user-content-a-note-on-licences-copyright-etc">A note on licences, copyright etc.</a></li>
</ul>
</li>
<li>
<p dir="auto"><a href="#browsing-the-source-in-an-ide">Browsing the source in an IDE</a></p>
</li>
<li>
<p dir="auto"><a href="#folder-structure">Folder structure</a></p>
</li>
<li>
<p dir="auto"><a href="#building-elite-from-the-source">Building Elite from the source</a></p>
<ul dir="auto">
<li><a href="#requirements">Requirements</a></li>
<li><a href="#build-targets">Build targets</a></li>
<li><a href="#windows">Windows</a></li>
<li><a href="#mac-and-linux">Mac and Linux</a></li>
<li><a href="#verifying-the-output">Verifying the output</a></li>
<li><a href="#log-files">Log files</a></li>
</ul>
</li>
<li>
<p dir="auto"><a href="#building-different-variants-of-nes-elite">Building different variants of NES Elite</a></p>
<ul dir="auto">
<li><a href="#building-the-ntsc-release">Building the NTSC release</a></li>
<li><a href="#building-the-pal-release">Building the PAL release</a></li>
<li><a href="#differences-between-the-variants">Differences between the variants</a></li>
</ul>
</li>
</ul>
<h2 tabindex="-1" id="user-content-introduction" dir="auto"><a href="#introduction">Introduction</a></h2>
<p dir="auto">This repository contains source code for Elite on the NES, with every single line documented and (for the most part) explained.</p>
<p dir="auto">You can build the fully functioning game from this source. <a href="#building-different-variants-of-nes-elite">Two variants</a> are currently supported: the NTSC version from Ian Bell's personal website, and the Imagineer PAL release.</p>

<ul dir="auto">
<li>
<p dir="auto">If you want to explore the source code, then the <a href="https://github.com/markmoxon/nes-elite-beebasm/blob/main/1-source-files/main-sources">annotated source</a> is what you're looking for. You might also like to read the section on <a href="#browsing-the-source-in-an-ide">Browsing the source in an IDE</a> for some tips.</p>
</li>
<li>
<p dir="auto">If you want to build Elite from the source on a modern computer, to produce a working ROM image that can be loaded into a real NES or an emulator, then you want the section on <a href="#building-elite-from-the-source">Building Elite from the source</a>.</p>
</li>
</ul>
<p dir="auto">My hope is that this repository and the <a href="https://www.bbcelite.com/" rel="nofollow">accompanying website</a> will be useful for those who want to learn more about Elite and what makes it tick. It is provided on an educational and non-profit basis, with the aim of helping people appreciate one of the most iconic games of the 8-bit era.</p>
<h2 tabindex="-1" id="user-content-acknowledgements" dir="auto"><a href="#acknowledgements">Acknowledgements</a></h2>
<p dir="auto">NES Elite was written by Ian Bell and David Braben and is copyright © D. Braben and I. Bell 1991/1992.</p>
<p dir="auto">The code on this site has been reconstructed from a disassembly of the version released on <a href="http://www.elitehomepage.org/" rel="nofollow">Ian Bell's personal website</a>.</p>
<p dir="auto">The commentary is copyright © Mark Moxon. Any misunderstandings or mistakes in the documentation are entirely my fault.</p>
<p dir="auto">Huge thanks are due to the original authors for not only creating such an important piece of my childhood, but also for releasing the source code for us to play with; to Paul Brink for his annotated disassembly; and to Kieran Connell for his <a href="https://github.com/kieranhj/elite-beebasm">BeebAsm version</a>, which I forked as the original basis for this project. You can find more information about this project in the <a href="https://www.bbcelite.com/about_site/about_this_project.html" rel="nofollow">accompanying website's project page</a>.</p>
<p dir="auto">The following archive from Ian Bell's personal website forms the basis for this project:</p>
<ul dir="auto">
<li><a href="http://www.elitehomepage.org/archive/a/b7120500.zip" rel="nofollow">NES Elite, NTSC version</a></li>
</ul>
<h3 tabindex="-1" id="user-content-a-note-on-licences-copyright-etc" dir="auto"><a href="#a-note-on-licences-copyright-etc">A note on licences, copyright etc.</a></h3>
<p dir="auto">This repository is <em>not</em> provided with a licence, and there is intentionally no <code>LICENSE</code> file provided.</p>
<p dir="auto">According to <a href="https://docs.github.com/en/free-pro-team@latest/github/creating-cloning-and-archiving-repositories/licensing-a-repository">GitHub's licensing documentation</a>, this means that "the default copyright laws apply, meaning that you retain all rights to your source code and no one may reproduce, distribute, or create derivative works from your work".</p>
<p dir="auto">The reason for this is that my commentary is intertwined with the original Elite source code, and the original source code is copyright. The whole site is therefore covered by default copyright law, to ensure that this copyright is respected.</p>
<p dir="auto">Under GitHub's rules, you have the right to read and fork this repository... but that's it. No other use is permitted, I'm afraid.</p>
<p dir="auto">My hope is that the educational and non-profit intentions of this repository will enable it to stay hosted and available, but the original copyright holders do have the right to ask for it to be taken down, in which case I will comply without hesitation. I do hope, though, that along with the various other disassemblies and commentaries of this source, it will remain viable.</p>
<h2 tabindex="-1" id="user-content-browsing-the-source-in-an-ide" dir="auto"><a href="#browsing-the-source-in-an-ide">Browsing the source in an IDE</a></h2>
<p dir="auto">If you want to browse the source in an IDE, you might find the following useful.</p>
<ul dir="auto">
<li>
<p dir="auto">The main game's source code is split across eight different ROM banks, which you can find in the <a href="https://github.com/markmoxon/nes-elite-beebasm/blob/main/1-source-files/main-sources">main-sources</a> folder. This is the motherlode and probably contains all the stuff you're interested in.</p>
</li>
<li>
<p dir="auto">It's probably worth skimming through the <a href="https://www.bbcelite.com/about_site/terminology_used_in_this_commentary.html" rel="nofollow">notes on terminology and notations</a> on the accompanying website, as this explains a number of terms used in the commentary, without which it might be a bit tricky to follow at times (in particular, you should understand the terminology I use for multi-byte numbers).</p>
</li>
<li>
<p dir="auto">The accompanying website contains <a href="https://www.bbcelite.com/deep_dives/" rel="nofollow">a number of "deep dive" articles</a>, each of which goes into an aspect of the game in detail. Routines that are explained further in these articles are tagged with the label <code>Deep dive:</code> and the relevant article name.</p>
</li>
<li>
<p dir="auto">There are loads of routines and variables in Elite - literally hundreds. You can find them in the source files by searching for the following: <code>Type: Subroutine</code>, <code>Type: Variable</code>, <code>Type: Workspace</code> and <code>Type: Macro</code>.</p>
</li>
<li>
<p dir="auto">If you know the name of a routine, you can find it by searching for <code>Name: &lt;name&gt;</code>, as in <code>Name: SCAN</code> (for the 3D scanner routine) or <code>Name: LL9</code> (for the ship-drawing routine).</p>
</li>
<li>
<p dir="auto">The entry point for the main game code is the <code>BEGIN</code> routine in <a href="https://github.com/markmoxon/nes-elite-beebasm/blob/main/1-source-files/main-sources/elite-source-bank-7.asm">bank 7</a>, which you can find by searching for <code>Name: BEGIN</code>. If you want to follow the program flow all the way from the title screen around the main game loop, then you can find a number of <a href="https://www.bbcelite.com/deep_dives/" rel="nofollow">deep dives on program flow</a> on the accompanying website.</p>
</li>
<li>
<p dir="auto">The source code is designed to be read at an 80-column width and with a monospaced font, just like in the good old days.</p>
</li>
</ul>
<p dir="auto">I hope you enjoy exploring the inner workings of NES Elite as much as I have.</p>
<h2 tabindex="-1" id="user-content-folder-structure" dir="auto"><a href="#folder-structure">Folder structure</a></h2>
<p dir="auto">There are five main folders in this repository, which reflect the order of the build process.</p>
<ul dir="auto">
<li>
<p dir="auto"><a href="https://github.com/markmoxon/nes-elite-beebasm/blob/main/1-source-files">1-source-files</a> contains all the different source files, such as the main assembler source files, image binaries, fonts and so on.</p>
</li>
<li>
<p dir="auto"><a href="https://github.com/markmoxon/nes-elite-beebasm/blob/main/2-build-files">2-build-files</a> contains build-related scripts, such as the crc32 verification scripts.</p>
</li>
<li>
<p dir="auto"><a href="https://github.com/markmoxon/nes-elite-beebasm/blob/main/3-assembled-output">3-assembled-output</a> contains the output from the assembly process, when the source files are assembled and the results processed by the build files.</p>
</li>
<li>
<p dir="auto"><a href="https://github.com/markmoxon/nes-elite-beebasm/blob/main/4-reference-binaries">4-reference-binaries</a> contains the correct binaries for each variant, so we can verify that our assembled output matches the reference.</p>
</li>
<li>
<p dir="auto"><a href="https://github.com/markmoxon/nes-elite-beebasm/blob/main/5-compiled-game-discs">5-compiled-game-discs</a> contains the final output of the build process: an iNES ROM image that contains the compiled game and which can be run on real hardware or in an emulator.</p>
</li>
</ul>
<h2 tabindex="-1" id="user-content-building-elite-from-the-source" dir="auto"><a href="#building-elite-from-the-source">Building Elite from the source</a></h2>
<h3 tabindex="-1" id="user-content-requirements" dir="auto"><a href="#requirements">Requirements</a></h3>
<p dir="auto">You will need the following to build Elite from the source:</p>
<ul dir="auto">
<li>
<p dir="auto">BeebAsm, which can be downloaded from the <a href="https://github.com/stardot/beebasm">BeebAsm repository</a>. Mac and Linux users will have to build their own executable with <code>make code</code>, while Windows users can just download the <code>beebasm.exe</code> file.</p>
</li>
<li>
<p dir="auto">Python. Both versions 2.7 and 3.x should work.</p>
</li>
<li>
<p dir="auto">Mac and Linux users may need to install <code>make</code> if it isn't already present (for Windows users, <code>make.exe</code> is included in this repository).</p>
</li>
</ul>
<p dir="auto">For details of how the build process works, see the <a href="https://www.bbcelite.com/about_site/building_elite.html" rel="nofollow">build documentation on bbcelite.com</a>.</p>
<p dir="auto">Let's look at how to build Elite from the source.</p>
<h3 tabindex="-1" id="user-content-build-targets" dir="auto"><a href="#build-targets">Build targets</a></h3>
<p dir="auto">There are two main build targets available. They are:</p>
<ul dir="auto">
<li><code>build</code> - A version with a maxed-out commander</li>
<li><code>encrypt</code> - A version that exactly matches the released version of the game</li>
</ul>
<p dir="auto">Unlike the Acornsoft versions of Elite on which it is based, the NES version is not encrypted, so there is no difference in encryption between the two targets. I have used the same target names for consistency, but the only difference is in the commander file.</p>
<p dir="auto">Builds are supported for both Windows and Mac/Linux systems. In all cases the build process is defined in the <code>Makefile</code> provided.</p>
<h3 tabindex="-1" id="user-content-windows" dir="auto"><a href="#windows">Windows</a></h3>
<p dir="auto">For Windows users, there is a batch file called <code>make.bat</code> to which you can pass one of the build targets above. Before this will work, you should edit the batch file and change the values of the <code>BEEBASM</code> and <code>PYTHON</code> variables to point to the locations of your <code>beebasm.exe</code> and <code>python.exe</code> executables. You also need to change directory to the repository folder (i.e. the same folder as <code>make.bat</code>).</p>
<p dir="auto">All being well, doing one of the following:</p>


<p dir="auto">will produce a file called <code>elite-ntsc.NES</code> in the <code>5-compiled-game-discs</code> folder that contains the NTSC release, which you can then load into an emulator, or into a real NES using a flash cart.</p>
<h3 tabindex="-1" id="user-content-mac-and-linux" dir="auto"><a href="#mac-and-linux">Mac and Linux</a></h3>
<p dir="auto">The build process uses a standard GNU <code>Makefile</code>, so you just need to install <code>make</code> if your system doesn't already have it. If BeebAsm or Python are not on your path, then you can either fix this, or you can edit the <code>Makefile</code> and change the <code>BEEBASM</code> and <code>PYTHON</code> variables in the first two lines to point to their locations. You also need to change directory to the repository folder (i.e. the same folder as <code>Makefile</code>).</p>
<p dir="auto">All being well, doing one of the following:</p>


<p dir="auto">will produce a file called <code>elite-ntsc.NES</code> in the <code>5-compiled-game-discs</code> folder that contains the NTSC release, which you can then load into an emulator, or into a real NES using a flash cart.</p>
<h3 tabindex="-1" id="user-content-verifying-the-output" dir="auto"><a href="#verifying-the-output">Verifying the output</a></h3>
<p dir="auto">The build process also supports a verification target that prints out checksums of all the generated files, along with the checksums of the files from the original sources.</p>
<p dir="auto">You can run this verification step on its own, or you can run it once a build has finished. To run it on its own, use the following command on Windows:</p>

<p dir="auto">or on Mac/Linux:</p>

<p dir="auto">To run a build and then verify the results, you can add two targets, like this on Windows:</p>

<p dir="auto">or this on Mac/Linux:</p>

<p dir="auto">The Python script <code>crc32.py</code> in the <code>2-build-files</code> folder does the actual verification, and shows the checksums and file sizes of both sets of files, alongside each other, and with a Match column that flags any discrepancies. If you are building an unencrypted set of files then there will be lots of differences, while the encrypted files should mostly match (see the Differences section below for more on this).</p>
<p dir="auto">The binaries in the <code>4-reference-binaries</code> folder are those extracted from the released version of the game, while those in the <code>3-assembled-output</code> folder are produced by the build process. For example, if you don't make any changes to the code and build the project with <code>make encrypt verify</code>, then this is the output of the verification process:</p>
<div data-snippet-clipboard-copy-content="Results for variant: pal
[--originals--]  [---output----]
Checksum    Size  Checksum    Size  Match  Filename
-----------------------------------------------------
6a32bd20   16384  6a32bd20   16384   Yes   bank0.bin
1840f774   16384  1840f774   16384   Yes   bank1.bin
e08fa78a   16384  e08fa78a   16384   Yes   bank2.bin
e07c0f21   16384  e07c0f21   16384   Yes   bank3.bin
731cd900   16384  731cd900   16384   Yes   bank4.bin
fee7480c   16384  fee7480c   16384   Yes   bank5.bin
500f28cd   16384  500f28cd   16384   Yes   bank6.bin
8e1162f8   16384  8e1162f8   16384   Yes   bank7.bin
4cf12d39  131088  4cf12d39  131088   Yes   elite.bin
eb5e8763      16  eb5e8763      16   Yes   header.bin"><pre><code>Results for variant: pal
[--originals--]  [---output----]
Checksum    Size  Checksum    Size  Match  Filename
-----------------------------------------------------
6a32bd20   16384  6a32bd20   16384   Yes   bank0.bin
1840f774   16384  1840f774   16384   Yes   bank1.bin
e08fa78a   16384  e08fa78a   16384   Yes   bank2.bin
e07c0f21   16384  e07c0f21   16384   Yes   bank3.bin
731cd900   16384  731cd900   16384   Yes   bank4.bin
fee7480c   16384  fee7480c   16384   Yes   bank5.bin
500f28cd   16384  500f28cd   16384   Yes   bank6.bin
8e1162f8   16384  8e1162f8   16384   Yes   bank7.bin
4cf12d39  131088  4cf12d39  131088   Yes   elite.bin
eb5e8763      16  eb5e8763      16   Yes   header.bin
</code></pre></div>
<p dir="auto">All the compiled binaries match the originals, so we know we are producing the same final game as the release version.</p>
<h3 tabindex="-1" id="user-content-log-files" dir="auto"><a href="#log-files">Log files</a></h3>
<p dir="auto">During compilation, details of every step are output in nine files called <code>compile.txt</code> (for the header) or <code>compile0.txt</code> through <code>compile7.txt</code> (for banks 0 to 7) in the <code>3-assembled-output</code> folder. If you have problems, these might come in handy, and they're a great reference if you need to know the addresses of labels and variables for debugging (or just snooping around).</p>
<h2 tabindex="-1" id="user-content-building-different-variants-of-nes-elite" dir="auto"><a href="#building-different-variants-of-nes-elite">Building different variants of NES Elite</a></h2>
<p dir="auto">This repository contains the source code for two different variants of NES Elite:</p>
<ul dir="auto">
<li>
<p dir="auto">The NTSC version from Ian Bell's personal website</p>
</li>
<li>
<p dir="auto">The Imagineer PAL release, which is the only official release of NES Elite</p>
</li>
</ul>
<p dir="auto">By default the build process builds the NTSC release, but you can build a specified variant using the <code>variant=</code> build parameter.</p>
<h3 tabindex="-1" id="user-content-building-the-ntsc-release" dir="auto"><a href="#building-the-ntsc-release">Building the NTSC release</a></h3>
<p dir="auto">You can add <code>variant=ntsc</code> to produce the <code>elite-ntsc.NES</code> file that contains the NTSC release, though that's the default value so it isn't necessary. In other words, you can build it like this:</p>
<div data-snippet-clipboard-copy-content="make.bat encrypt verify variant=ntsc"><pre><code>make.bat encrypt verify variant=ntsc
</code></pre></div>
<p dir="auto">or this on a Mac or Linux:</p>
<div data-snippet-clipboard-copy-content="make encrypt verify variant=ntsc"><pre><code>make encrypt verify variant=ntsc
</code></pre></div>
<p dir="auto">This will produce a file called <code>elite-ntsc.NES</code> in the <code>5-compiled-game-discs</code> folder that contains the NTSC release.</p>
<p dir="auto">The verification checksums for this version are as follows:</p>
<div data-snippet-clipboard-copy-content="Results for variant: ntsc
[--originals--]  [---output----]
Checksum    Size  Checksum    Size  Match  Filename
-----------------------------------------------------
0560a52b   16384  0560a52b   16384   Yes   bank0.bin
c1239b33   16384  c1239b33   16384   Yes   bank1.bin
5e6c3bfb   16384  5e6c3bfb   16384   Yes   bank2.bin
54df916d   16384  54df916d   16384   Yes   bank3.bin
5953c5d4   16384  5953c5d4   16384   Yes   bank4.bin
0dd49e0c   16384  0dd49e0c   16384   Yes   bank5.bin
39255d4f   16384  39255d4f   16384   Yes   bank6.bin
26f0c7de   16384  26f0c7de   16384   Yes   bank7.bin
54386491  131088  54386491  131088   Yes   elite.bin
eb5e8763      16  eb5e8763      16   Yes   header.bin"><pre><code>Results for variant: ntsc
[--originals--]  [---output----]
Checksum    Size  Checksum    Size  Match  Filename
-----------------------------------------------------
0560a52b   16384  0560a52b   16384   Yes   bank0.bin
c1239b33   16384  c1239b33   16384   Yes   bank1.bin
5e6c3bfb   16384  5e6c3bfb   16384   Yes   bank2.bin
54df916d   16384  54df916d   16384   Yes   bank3.bin
5953c5d4   16384  5953c5d4   16384   Yes   bank4.bin
0dd49e0c   16384  0dd49e0c   16384   Yes   bank5.bin
39255d4f   16384  39255d4f   16384   Yes   bank6.bin
26f0c7de   16384  26f0c7de   16384   Yes   bank7.bin
54386491  131088  54386491  131088   Yes   elite.bin
eb5e8763      16  eb5e8763      16   Yes   header.bin
</code></pre></div>
<h3 tabindex="-1" id="user-content-building-the-pal-release" dir="auto"><a href="#building-the-pal-release">Building the PAL release</a></h3>
<p dir="auto">You can build the PAL release by appending <code>variant=ntsc</code> to the <code>make</code> command, like this on Windows:</p>
<div data-snippet-clipboard-copy-content="make.bat encrypt verify variant=pal"><pre><code>make.bat encrypt verify variant=pal
</code></pre></div>
<p dir="auto">or this on a Mac or Linux:</p>
<div data-snippet-clipboard-copy-content="make encrypt verify variant=pal"><pre><code>make encrypt verify variant=pal
</code></pre></div>
<p dir="auto">This will produce a file called <code>elite-pal.NES</code> in the <code>5-compiled-game-discs</code> folder that contains the PAL release.</p>
<p dir="auto">The verification checksums for this version are as follows:</p>
<div data-snippet-clipboard-copy-content="Results for variant: pal
[--originals--]  [---output----]
Checksum    Size  Checksum    Size  Match  Filename
-----------------------------------------------------
6a32bd20   16384  6a32bd20   16384   Yes   bank0.bin
1840f774   16384  1840f774   16384   Yes   bank1.bin
e08fa78a   16384  e08fa78a   16384   Yes   bank2.bin
e07c0f21   16384  e07c0f21   16384   Yes   bank3.bin
731cd900   16384  731cd900   16384   Yes   bank4.bin
fee7480c   16384  fee7480c   16384   Yes   bank5.bin
500f28cd   16384  500f28cd   16384   Yes   bank6.bin
8e1162f8   16384  8e1162f8   16384   Yes   bank7.bin
4cf12d39  131088  4cf12d39  131088   Yes   elite.bin
eb5e8763      16  eb5e8763      16   Yes   header.bin"><pre><code>Results for variant: pal
[--originals--]  [---output----]
Checksum    Size  Checksum    Size  Match  Filename
-----------------------------------------------------
6a32bd20   16384  6a32bd20   16384   Yes   bank0.bin
1840f774   16384  1840f774   16384   Yes   bank1.bin
e08fa78a   16384  e08fa78a   16384   Yes   bank2.bin
e07c0f21   16384  e07c0f21   16384   Yes   bank3.bin
731cd900   16384  731cd900   16384   Yes   bank4.bin
fee7480c   16384  fee7480c   16384   Yes   bank5.bin
500f28cd   16384  500f28cd   16384   Yes   bank6.bin
8e1162f8   16384  8e1162f8   16384   Yes   bank7.bin
4cf12d39  131088  4cf12d39  131088   Yes   elite.bin
eb5e8763      16  eb5e8763      16   Yes   header.bin
</code></pre></div>
<h3 tabindex="-1" id="user-content-differences-between-the-variants" dir="auto"><a href="#differences-between-the-variants">Differences between the variants</a></h3>
<p dir="auto">You can see the differences between the variants by searching the source code for <code>_PAL</code> (for features in the PAL release) or <code>_NTSC</code> (for features in the NTSC release). The main differences in the NTSC release compared to the PAL release are:</p>
<ul dir="auto">
<li>
<p dir="auto">The two versions count a different number of cycles in the NMI handler (7433 in the PAL version, 6797 in the NTSC version).</p>
</li>
<li>
<p dir="auto">The NTSC version is missing the Imagineer and Nintendo headings from the Start screen.</p>
</li>
<li>
<p dir="auto">The PAL version waits for longer before starting auto-play on the combat demo.</p>
</li>
<li>
<p dir="auto">Each version has its own unique checksum algorithm for the save slots.</p>
</li>
<li>
<p dir="auto">The internal version number is different (the PAL version is "&lt;2.8&gt;" while the NTSC version is "5.0")</p>
</li>
<li>
<p dir="auto">The copyright message hidden in bank 3 is different (the PAL message is "NES ELITE IMAGE 2.8 - 04 MAR 1992" while the NTSC message is "NES ELITE IMAGE 5.2 - 24 APR 1992"</p>
</li>
<li>
<p dir="auto">The first title in the combat demo scroll text is different (the PAL title is "IMAGINEER PRESENTS --- E L I T E --- (C)BRABEN &amp; BELL 1991" while the NTSC title is "NTSC EMULATION --- E L I T E ---  (C)BELL &amp; BRABEN 1991")</p>
</li>
<li>
<p dir="auto">A number of pixel y-coordinate constants in the PAL version are six pixels bigger than in the NTSC version, to cater for the taller screen height.</p>
</li>
<li>
<p dir="auto">The interrupt vectors in banks 0 to 6 that are used during initialisation are subtly different.</p>
</li>
<li>
<p dir="auto">The code for detecting double-taps of the B button when choosing buttons from the icon bar is a bit simpler in the NTSC version.</p>
</li>
</ul>
<p dir="auto">It's worth noting that the NTSC variant doesn't actually work on an NTSC machine. The NMI timings have been changed to work with some (but not all) emulators in NTSC mode, but it isn't a full NTSC conversion, it's an NTSC emulation (as per the scroll text).</p>

<hr>
<p dir="auto">Right on, Commanders!</p>
<p dir="auto"><em>Mark Moxon</em></p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[RISC-V chip technology emerges as new battleground in US-China tech war (127 pts)]]></title>
            <link>https://www.reuters.com/technology/us-china-tech-war-risc-v-chip-technology-emerges-new-battleground-2023-10-06/</link>
            <guid>37798178</guid>
            <pubDate>Sat, 07 Oct 2023 01:09:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/technology/us-china-tech-war-risc-v-chip-technology-emerges-new-battleground-2023-10-06/">https://www.reuters.com/technology/us-china-tech-war-risc-v-chip-technology-emerges-new-battleground-2023-10-06/</a>, See on <a href="https://news.ycombinator.com/item?id=37798178">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p data-testid="paragraph-0">Oct 6 (Reuters) - In a new front in the U.S.-China tech war, President Joe Biden's administration is facing pressure from some lawmakers to restrict American companies from working on a freely available chip technology widely used in China - a move that could upend how the global technology industry collaborates across borders.</p><p data-testid="paragraph-1">At issue is RISC-V, pronounced "risk five," an open-source technology that competes with costly proprietary technology from British semiconductor and software design company Arm Holdings <a data-testid="Link" href="https://www.reuters.com/markets/companies/O9Ty.F" target="_blank" referrerpolicy="no-referrer-when-downgrade">(O9Ty.F)</a>. RISC-V can be used as a key ingredient for anything from a smartphone chip to advanced processors for artificial intelligence.</p><p data-testid="paragraph-2">Some lawmakers - including two Republican House of Representatives committee chairmen, Republican Senator Marco Rubio and Democratic Senator Mark Warner - are urging Biden's administration to take action regarding RISC-V, citing national security grounds.</p><p data-testid="paragraph-3">The lawmakers expressed concerns that Beijing is exploiting a culture of open collaboration among American companies to advance its own semiconductor industry, which could erode the current U.S. lead in the chip field and help China modernize its military. Their comments represent the first major effort to put constraints on work by U.S. companies on RISC-V.</p><p data-testid="paragraph-4">Representative Mike Gallagher, chairman of the House select committee on China, said in a statement to Reuters that the Commerce Department needs to "require any American person or company to receive an export license prior to engaging with PRC (People's Republic of China) entities on RISC-V technology."</p><p data-testid="paragraph-5">Such calls to regulate RISC-V are the latest in the U.S.-China battle over chip technology that escalated last year with sweeping export restrictions that the Biden administration <a data-testid="Link" href="https://www.reuters.com/technology/us-warned-china-expect-updated-export-curbs-october-us-official-2023-10-02/" referrerpolicy="no-referrer-when-downgrade">has told China</a> it will update this month.</p><p data-testid="paragraph-6">"The CCP (Chinese Communist Party) is abusing RISC-V to get around U.S. dominance of the intellectual property needed to design chips. U.S. persons should not be supporting a PRC tech transfer strategy that serves to degrade U.S. export control laws," Representative Michael McCaul, chairman of the House Foreign Affairs Committee, said in a statement to Reuters.</p><p data-testid="paragraph-7">McCaul said he wants action from the Bureau of Industry and Security, the part of the Commerce Department that oversees export-control regulations, and would pursue legislation if that does not materialize.</p><p data-testid="paragraph-8">The bureau "is constantly reviewing the technology landscape and threat environment, and continually assessing how best to apply our export control policies to protect national security and safeguard core technologies," a Commerce Department spokesperson said in a statement.</p><p data-testid="paragraph-9">"Communist China is developing open-source chip architecture to dodge our sanctions and grow its chip industry," Rubio said in a statement to Reuters. "If we don't broaden our export controls to include this threat, China will one day surpass us as the global leader in chip design."</p><p data-testid="paragraph-10">"I fear that our export-control laws are not equipped to deal with the challenge of open-source software - whether in advanced semiconductor designs like RISC-V or in the area of AI - and a dramatic paradigm shift is needed," Warner said in a statement to Reuters.</p><p data-testid="paragraph-11">RISC-V is overseen by a Swiss-based nonprofit foundation that coordinates efforts among for-profit companies to develop the technology.</p><p data-testid="paragraph-12">The RISC-V technology came from labs at the University of California, Berkeley, and later benefited from funding by the Pentagon's Defense Advanced Research Projects Agency (DARPA). Its creators have compared it to Ethernet, USB and even the internet, which are freely available and draw on contributions from around the world to make innovation faster and cheaper.</p><h2 data-testid="Heading">HUAWEI TECHNOLOGIES</h2><p data-testid="paragraph-13">Executives from China's Huawei Technologies have embraced RISC-V as a pillar of that nation's progress in developing its own chips. But the United States and its allies also have jumped on the technology, with chip giant Qualcomm <a data-testid="Link" href="https://www.reuters.com/markets/companies/QCOM.O" target="_blank" referrerpolicy="no-referrer-when-downgrade">(QCOM.O)</a> working with a group of European automotive firms on RISC-V chips and Alphabet's Google saying it will make Android, the world's most popular mobile operating system, work on RISC-V chips.</p><p data-testid="paragraph-14">Qualcomm declined to comment. Its executives said in August they believe RISC-V will speed up chip innovation and transform the tech industry.</p><p data-testid="paragraph-15">Google did not respond to a request for comment.</p><p data-testid="paragraph-16">If Biden's administration were to regulate U.S. companies' participation in the Swiss-based foundation in the manner lawmakers are seeking, the move could complicate how American and Chinese companies work together on open technical standards. It also could create hurdles for China's pursuit of chip self-sufficiency, as well as for U.S. and European efforts to create cheaper and more versatile chips.</p><p data-testid="paragraph-17">Jack Kang, vice president of business development at SiFive, a Santa Clara, California-based startup using RISC-V, said potential U.S. government restrictions on American companies regarding RISC-V would be a "tremendous tragedy."</p><p data-testid="paragraph-18">"It would be like banning us from working on the internet," Kang said. "It would be a huge mistake in terms of technology, leadership, innovation and companies and jobs that are being created."</p><p data-testid="paragraph-19">Regulating the open discussion of technologies is rarer than regulating physical products, but not impossible, said Kevin Wolf, an export-control attorney at law firm Akin Gump who served in the Commerce Department under former President Barack Obama. Existing rules on chip exports could help provide a legal framework for such a proposal, Wolf said.</p><p data-testid="Body">Reporting by Max A. Cherney and Stephen Nellis in San Francisco; Editing by Will Dunham and Kenneth Li</p><p data-testid="Body">Our Standards: <a data-testid="Link" href="https://www.thomsonreuters.com/en/about-us/trust-principles.html" target="_blank" referrerpolicy="no-referrer-when-downgrade">The Thomson Reuters Trust Principles.</a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Half a million kinksters can't be wrong (101 pts)]]></title>
            <link>https://asteriskmag.com/issues/04/half-a-million-kinksters-can-t-be-wrong</link>
            <guid>37797789</guid>
            <pubDate>Fri, 06 Oct 2023 23:51:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://asteriskmag.com/issues/04/half-a-million-kinksters-can-t-be-wrong">https://asteriskmag.com/issues/04/half-a-million-kinksters-can-t-be-wrong</a>, See on <a href="https://news.ycombinator.com/item?id=37797789">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    
    <div data-mode="add-marker">
        <p><img id="marker" src="https://asteriskmag.com/assets/img/asterisk_mark.png" title="save highlight"></p><!-- <a href="https://asteriskmag.com/about/#highlights"><img id="help" src="https://asteriskmag.com/assets/img/asterisk_help.png" title="about highlights"></a> -->
        
    </div>

    <section>
                
                   <h2>
                   
                    <span>Aella</span>
                            </h2>
            </section>
    <section id="rangyscope">
                    <p>The story of how one independent researcher conducted the largest-ever survey on fetishes, and what it has to teach us about sex, pleasure, and social science methodology.</p>
                <div>
                                            <div><p>At a conference recently, someone pulled me aside and told me they’d be down to offer me funding for my research. I was like, awesome, because for years people have been yelling at me for doing surveys on the internet.</p><p>If you’re new to my work, I’m a self-taught researcher, driven to learn through fortunate access to high sample sizes and sheer curiosity. As of this writing, over 700,000 people have responded to my <a href="https://www.guidedtrack.com/programs/u4m797m/run" rel="noopener noreferrer">Big Kink Survey</a> on fetishes and sex — likely one of the largest surveys on the topic ever done. It grew out of my desire to answer two questions: <em>How weird is my own sexuality, exactly?</em> and <em>Why are there way more women interested in submission than men interested in dominance?</em></p><p>I originally started doing surveys via porn (I also do porn), which is a <em>super</em> easy way to get a lot of horny social media followers willing to do anything you ask them to. I’d ask them to help answer random questions I had, and quickly realized the data was terrible because my questions were terrible.</p><p>This started years of rapidly iterated survey learning. I’d pump out tons of questions, look at the resulting data on Google Sheets, and then rock back and forth with agony that I hadn’t thoroughly thought through how people might interpret question five and now all my correlations were useless. I’d often practice with questions in polls on X (formerly known as Twitter), which got lots of people in the comments reliably misinterpreting my phrasing in the most ingenious ways. I became a calloused, precise, question-asking machine. My phrasing could split any hair, and I started failing less and less frequently. Now, my crying-in-corner-agony per question rate is probably less than 1%.</p><p>It turns out that, when you get data, you have to figure out how to interpret it. Since I’m a homeschooler without a college degree, I started wrangling smart people to tell me how the hell a correlation worked, what p-hacking was, and how to do factor analysis. I’m a slow but thorough learner, and eventually got to the point where I was pretty solid with simple statistics.</p><p>But my datasets were getting huge, because my survey design was getting better at seducing people into taking them. My surveys, originally getting 10,000 responses, recently started to explode into the hundreds of thousands. You can’t process huge data in Google Sheets, so starting in 2021 I begrudgingly learned how to program in Python.</p><p>My audience expanded past just porn users into other, usually nerd-adjacent, platforms. Often my surveys would go viral elsewhere, bringing in novel audiences — recently, mostly young, female social media users, primarily on TikTok. I started buying randomized samples from the study recruiting site <a href="https://www.positly.com/" target="_blank" rel="noopener noreferrer">Positly</a> to compare against my own, to try to understand the degree to which the respondents I drew from social media might be unrepresentative.</p><p>I’ve been saturated in the world of rationalists — an intellectual community formed around the group blog LessWrong — for eight years or so, and from watching them viciously tear apart other studies, I’d gained a sense of mistakes not to make: Don’t control for too many or too few things, do <em>not</em> trust your intuitions on how stats should work, don’t avoid reporting things that contradict your results, don’t check for new ways to investigate data just because it didn’t match your expectations, and report the null findings. I got odds-ratio-pilled and used those over p-values when I could; I published raw data; I shared my code; and I tried to keep my analysis and interpretation separate.</p></div>
                                            <div><figure>
      <p><img src="https://asteriskmag.com/media/pages/issues/04/half-a-million-kinksters-can-t-be-wrong/d00565a012-1696000753/final_rgb_small.jpg" alt="">
  </p>
    <p>
    Ana Galvañ  </p>
  </figure>
</div>
                                            <div><p>Finally, I’d write up my findings and post them online. I’m not an expert — there’s a <em>ton</em> of stats stuff I don’t know — but I tried to keep it simple and just say what I found.</p><p>It turns out that a lot of people <em>really hate this. </em>People say I’m not trustworthy because I’m a sex worker and thus biased, because I don’t have a representative sample, because I don’t have credentials. My work isn’t peer reviewed, I haven’t weighted the data to ensure it’s representative, and I’m an “OnlyFans girl just polling her horny audience.”</p><p>So when the guy at the conference offered funding, I was excited to do <em>official, real work</em>. I’d dreamed that one day, if I had money, I’d do a formal, grown-up study, with verified participants. It’d be reliable and like the way professors do it and make all the angry internet people embarrassed for ever doubting me. I fantasized about repentant emails drizzling into my inbox. “You were right all along,” they would say. “The silly online correlations you found do in fact match the official serious business ones too! You’re a real scientist and we trust you."</p><p>But as I went about the rest of the conference, trying to plan how I would do my research respectably, it slowly dawned on me that … there actually wasn’t a clearly better option to recruit people to talk about kinks. Each potential study concept I worked through suffered from equal, if not greater, vulnerabilities than mine did.</p><p>For example, let’s say you want to study people who are really into vore, a fetish around swallowing someone whole or being swallowed whole, typically by a much larger creature. Maybe you want to find out if it correlates with things like childhood abuse or mental illness — common theories people have about the origin of fetishes. Let’s say you want around 300 people to check.</p><p>Firstly, how do you find these people? Vore, like most fetishes, is rare. If you wanted to do a survey where you randomly ask people about their childhood, and also if they’re into vore, you’d have to ask <em>thousands</em> to get the 300 people who mark “yes.” So how do you find your 300 body-swallowing enthusiasts? You probably need to look at some forums for vore lovers.</p><p>Already, we’re introducing a nonrandom sample — we’re picking from people <em>active on a vore forum.</em> Maybe these people are less ashamed about their fetish, maybe they’re lonelier in real life, maybe they’re much more into vore than the actual population of people into vore. These people are probably unusual in much more specific ways than the category of “people just browsing TikTok,” for example.</p><p>This issue plagues most existing sexual fetish research. Pedophilia is the most extreme example. In a society with such massive penalties for even suspected pedophiles, it’s obvious that any pedophile-heavy source you go to is going to be hugely affected by selection bias — e.g. sex offender registries. One <a href="https://pubmed.ncbi.nlm.nih.gov/11893991/" rel="noopener noreferrer">study</a> recruited pedophiles from an “outpatient facility for sexual offenders” and — shockingly — found that they had compulsive behaviors and anti-social personality traits.</p></div>
                                            <div><p>But back to our comparatively innocent vore enthusiasts. However we find them, we need to incentivize them to participate. You can pay participants in money or gift cards or, if you’re a professor, with grades. This might work. On paid survey-taking sites, you can try to improve the quality of your sample by looking at things like how fast it takes them to do the survey, are their answers consistent, do they have high quality ratings by previous researchers, etc., But you <em>can’t</em> filter by “Do they like vore?” — that’s not a default demographic that most services provide.&nbsp;</p><p>Let’s say you have a survey that takes a half-hour, which means you might be paying $4 a survey. If you want 300 people who are into vore, and let’s say ~4% of the population likes vore, this means you’re going to need to pay roughly 7,500 people, which makes this a $30,000 study. And keep in mind you don’t know the vore prevalence beforehand, because this data isn’t available in traditional journals, because nobody has done a high-powered general fetish prevalence study before. Except me, which is why I know that number.</p><p>So let’s limit ourselves to confirmed vore fetishists. In that case, what’s to stop people from filling out the survey dishonestly in order to get the money? Maybe they wouldn’t, but “studies done on people trying to get $20” is a commonly mourned problem in research, and it seems reasonable that niche fetish enthusiasts are even <em>more</em> inclined to be dishonest than usual if they believe researchers are going to be scrutinizing the results.</p><p>And we want this to be a <em>real-life</em> survey anyway. To do this, we need to get our vore friends <em>into an office</em>, <em>verify their identity, and then have them fill out a survey in exchange for payment.</em></p><p>Uh, this is <em>terrible</em>. How could we possibly trust any results we get from this?&nbsp;</p><p>Problems like “How do you find a not-super-selected source, verify nontrolls are taking the survey, and get them to be honest?” exist in a lot of fields, but they’re <em>especially</em> difficult in sexual fetish research. The entire thing is studying rare traits that people are incentivized to lie about!</p><p>I recently looked at the the ratio between the frequency of fetishes in my sample and the degree to which people were aware of those fetishes in others. The least visible item I measured was BDSM. And <a href="https://aella.substack.com/p/fetish-tabooness-and-popularity-v3" rel="noopener noreferrer">the more uncommon the fetish, the more taboo</a>, and the greater the pressure against sharing it.</p><p>Genital response measuring is an option — but we’d <em>really</em> be selecting for people who are okay with an invasive measuring process, where your genitals are showing exactly how turned on you are by, e.g., an anime of a young boy screaming as he slides down the vast gullet of a half-lizard woman in a microkini. There are benefits to this — it might be good for checking correlations across lots of fetishes — but there’s no way this sample can be random.</p><p>So, given all this difficulty, it makes sense that most fetish research involves the scenario I described above — going to various fetish communities to ask them questions, usually in the form of visiting a forum or club dedicated to this fetish and posting a survey there. Consider the following sample of studies published between 1980 and 2020:</p><p><a href="https://www.jstor.org/stable/3813093" rel="noopener noreferrer">If the Shoe Fits: Exploring Male Homosexual Foot Fetishism</a> (262 respondents from an organization for foot fetishists)</p><p>To be clear, I still think these studies are respectable! I don’t mean to say a study is bunk just because the researchers behind it have limited access to populations - but the method seems ripe for accidental correlations.</p><p>Lots of existing research (maybe due to the necessity of using active community groups to get your sample) also focuses on action as opposed to fantasy, which conceivably biases the sample. A lot of things unrelated to a fetish probably affect whether someone acts on it. Are they in a liberal culture that celebrates their love of sitting on cakes? Are active cake sitters more disagreeable than those who wistfully dream about one day icing their own buttocks? Less afraid? Then we’d expect any studies done on cake sitting to find the cake-sitter community to be more liberal, disagreeable, and bold than the true population of people aroused by cake sitting.</p><p>Given all this difficulty, the ideal form here is probably an anonymous survey where people are properly incentivized to be honest — and what does this better than giving them information back about themselves? You need to give people a reason, and that reason should be as closely aligned with reporting the truth as you can make it. Telling people what you’ve found out about them based on that survey seemed like an obvious answer.</p><p>Basically: an elevated take on the classic BuzzFeed quiz, “What Princess Are You?” Of course this isn’t perfect — one can easily imagine someone deliberately putting in odd answers to see what this does to the results — but I think this still beats out other methods of research for most purposes.</p><p>Plus, it’s easy to disincentivize people spamming funny answers into your form for fun — just make your survey <em>really friggin’ long</em>.</p></div>
                                            <p><h2><strong>The Really Friggin’ Long Survey</strong></h2>
</p>
                                            <div><p>I’d gotten a year’s worth of funding from the wonderful <a href="https://invisible.college/" rel="noopener noreferrer">Invisible College</a> in 2021, and so I cracked my knuckles, quit OnlyFans, and settled down to work.</p><p>I wanted to make a survey about the origin of sexual fetishes because we know almost nothing about it, which is probably because this is really hard to do, for the reasons I’ve outlined above. Luckily I didn’t fully appreciate the difficulty when I started on this problem, or I might never have tried.</p><p>My goal was simple — I’d pick a fetish, ask if people were into it, and then ask them a bunch of questions about childhood. This would allow me to determine, for example, if you got spanked in childhood, did that correlate with interest in being spanked as an adult? This was pretty easy for a narrow fetish like this, but I wanted a big sample for the reasons I explained above — searching <em>specifically</em> for people interested in spanking seemed like it would do the whole “skewing results ’cause you’re drawing from the spank-specific community” thing, so I needed to get a bunch of people to answer for some other reason and then <em>happen to ask them</em> about spanking. This meant a really big sample.</p><p>And my access to big samples was limited. My audience — the most active of which was around 150,000 followers on X, though my total was around a million distributed across various platforms — would only take so many surveys, and I didn’t want to ask the same background questions over and over for each new fetish survey. It would be so much more efficient to combine <em>all</em> the fetishes into one big survey!</p><p>And while we were there, we should throw in more questions — what about porn use, sex rate, BMI, IQ, Big Five personality traits? You can check correlations for each additional question with everything else, so the more questions you add, the more valuable the data becomes. As my list of questions increased, the more compelling it became to add on yet another question, and this turned into a nightmare snowball.</p><p>In the end, I included 61 demographic, childhood, and other questions; 35 “general sex and porn” questions, and 206 fetish questions, for a total of 302 questions. But many of these were checkbox lists, where I asked people to “mark all that applied.” If you count those, the total amount of items I measured climbed to around 1,000.</p><p>I don’t know if you know how survey-taking norms work, but trying to get someone to answer 1,000 items is absolutely unhinged. It’s like asking someone to meet for coffee and then forcing them to stay for 12 hours of small talk. And the final cherry on the top of this sundae of horror was that the size of sample you need to make findings significant in the traditional sense increases with the number of questions you’re asking (or, more specifically, correlations you’re checking). So I needed a big sample size — many thousands, at least. But how do you get many thousands of people to sit down and answer a thousand questions?</p><p>It depends on the type of question, but on average I’ve found people take around two to six seconds to answer a survey question, which meant it would take roughly between 30 and 90 minutes to complete my survey.</p><p>I could pay people to take the survey, but that would get <em>really</em> expensive. If I were paying people $8 per hour to do this, and the survey <em>optimistically</em> took 30 minutes to do, then 10,000 responses would cost me $40,000.</p><p>I had to get creative.</p><p>First off was shortening the amount of time to take the survey, which sounds simple but was <em>agonizing.</em> I couldn’t let go of any of my precious questions. Each question I considered cutting meant I was releasing all of the other correlations I asked about into the wind. I felt like a hoarder on a TV show, wailing as I watched Marie Kondo slowly approach my front lawn.</p><p>But I <em>could</em> condense them. After lots of experimentation, building and testing out various survey versions, I settled upon a gated method. I’d ask people the first two categories — personal stuff and general sex stuff — like a normal survey, but the <em>fetish</em> part would be gated. I’d list a bunch of vaguely described fetish categories, like “Humiliation (defilement, impotence, cuckoldry, ridicule, etc.)” or “Transformations (growth/shrinking, bodyswapping, furries, etc.),” ask them to check off the ones they thought might apply, and then I’d feed them relevant questions from the categories that they checked.</p><p>But this meant I needed to define fetish categories, and there is <em>no</em> good research on this anywhere. I had to invent them. So I went and scraped the internet for all the fetish lists I could find, compiled them into a spreadsheet, and painstakingly tagged them all. There were nearly 900 fetishes, and I had to individually research most of them by wading into enthusiast boards in order to know how to tag them. I as a person really lack willpower (or discipline in general), and so here the only thing that kept me going was deliberately, frothily fantasizing about getting all the data in the end.</p><p>This still wasn’t ideal. My personal categorization of these fetishes was going to artificially cluster the data. If you clicked on, say, the “clothing” category, you would be exposed to more clothing-specific questions, which might make you more likely to mark “yes” to things you’re only mildly interested in, while someone who didn’t click that category wouldn’t see those questions at all.</p><p>And I wasn’t that confident in my fetish clustering. What if I put “cake sitting” into the “humiliation” category instead of the “sensory” one, but it turned out cake sitters didn’t care at all about humiliation? Despite my rigorous research, there’s no way I was going to have a 0% error rate.</p><p>To help compensate for this, I picked a few of the gated fetish questions and repeated them outside the gate, so I could compare the answers between the whole survey population and people who expressed an interest in a specific cluster to see just how much my survey design was affecting responses. This still wasn’t perfect, though!</p><p>The ideal question format was a Likert scale — “I find light bondage to be:” on a “not erotic” to “extremely erotic” zero-to-five scale. With this information, I could help differentiate between responses like “meh I guess” and “this is essential to my sexual function.” But scales take a while to complete, and so this ended up as a sacrifice on the altar of time sensitivity. I reserved&nbsp;Likert scale questions for <em>general categories</em>, like “clothes,” and then condensed many of the subcategories into increasingly nested checkboxes. I get to see <em>how much</em> you like the general category, and then binary responses to items within that category. If you like clothes, does that mean specific clothing textures, states, or items? If textures, is it latex? Leather?</p></div>
                                            <div><p>The entire process was a series of tiny, painstaking tradeoffs. Each time I decided to make a question into a scale, this boosted the total time it took to complete the survey by a few seconds. And I <em>had to care</em> about those few seconds.</p><p>In the end, the average time it took users to complete the survey was 40 minutes. This is <em>really</em> long for a survey! You really have to get people to care about it in order to finish.</p><p>So: How do I get them to care?</p><p>I decided to give users a score at the end — <em>How freaky are you compared to others?</em>&nbsp;</p><p>This turned into watery-eyed frustration all on its own, because how do you measure freakiness? Sure, you could do a survey to get people to rate how taboo various sexual things were — and this is precisely what I did — but this still leaves the problem of weighting. Necrophilia is really freaky, sure, but what if someone is only <em>slightly</em> into it? Is that freakier than someone who’s <em>extremely</em> into voyeurism? And then there’s the fact that freakiness is also a function of gender norms. If you’re a really submissive man, that’s certainly culturally freakier than being a dominant man, so I had to calculate different scores independently for men and women.</p><p>Scoring the survey took almost as much time as actually building it did.</p><p>The last part was easy. I assembled a list of fictional and well-known characters — like SpongeBob, Hitler, and Bambi — and asked people to rank them on how taboo they assumed their sexuality was. I then matched them up, based on these rankings, to the scores that people got in the Big Kink Survey. I personally got House, from that TV show some years back, or roughly 85th-percentile kinky. The character that people assigned the highest kinkiness score was Willy Wonka.</p><p>As of my writing this, the survey has around 550,000-700,000 respondents, depending on how aggressively I’m cleaning the data. Most respondents are in their early 20s, and around 70% of respondents are women — a reflection of the demographics that most love taking internet surveys (as verified by my friend who runs one of the oldest, biggest personality-testing websites on the internet).</p><p>One great thing about my sample is that I asked about hundreds of niche fetishes without having to go into a single niche-specific community and ask its members to take my survey. The survey results for the fetishes I’m asking about are as close to an unbiased sample as we can reasonably get given you’re trying to get a big sample with low cost.</p><p>I think <em>information about your personality</em> is one of the best possible incentives to complete a survey. Yes, your answers are probably warped a bit by your self-perception, but at least it’s an incentive directly related to <em>you</em>, as opposed to trying to get paid.</p><p>And the length of the survey probably indirectly helped accuracy here too — when I was younger and took personality tests for fun, I would retake them to see what changing little answers did to my score — but this is really annoying to do if the survey is 40 minutes long! This also made it resilient to intentional brigading or trolling — it’s simply difficult to sink that much time into warping the results, especially to the degree where it would show up on my final analyses, and especially with enough cleverness to get around all the survey checks I included to catch unserious responses. And when looking at survey results, I only include data from people who’d completed a majority of the survey.</p><p>The data I’ve gathered so far seems to match up quite well with existing data, at least for well-studied variables. For instance, my height and weight numbers correlate at around the standard 0.5, the rate of pedophilia in men is 3%, and the gap in interest between women and men in BDSM is clearly represented.</p><p>I don’t know why academia hasn’t tried to come up with more innovative solutions for gathering large amounts of survey data. Researchers are already doing internet surveys, so why not sink some effort into marketing? Hire some influencers? Get on podcasts? I don’t know. I treat my surveys not only as a vehicle to gather data, but also as products in themselves — to sell your survey, you have to make respondents enjoy it. You have to make them <em>like</em> giving you their time. It seems like current academia — or at least the sex part — views taking surveys as something like a chore, or like school. I’m not sure they’ve thought about making it fun.</p><p>I don’t mean sacrifice the quality of the survey itself. I was painstakingly dry with the wording of the questions, because I <em>didn’t</em> want a cheeky tone to prime respondents to give cheeky answers — but results at the end are a clean way to make it fun. I didn’t <em>have</em> to tell people they were the sexual equivalent of SpongeBob or whatever at the end of this survey, but I did — and this caused them to share it with friends and on TikTok.</p><p>I come from a background of marketing sex work, where I had to claw my way up the internet flesh by sheer “how do I make people want to send this thing to their friends.” And this is the eye with which I’m approaching research. I have done most of this without funding, yet have gotten samples that, if you paid test takers to do, would cost upwards of $4 million.</p><p>I also make my research a community effort — not only do I share my raw data and code, I regularly crowdsource questions from the public about what to study next. What hypotheses do people have that they want tested? I do drafts of survey questions in X polls, to see how commenters will inevitably misinterpret my wording and thus inform me on how to write the question more clearly in the future. I hope this process helps vanquish the sacredness of research.</p><p>And more specifically, I hope it normalizes people with fetishes. I feel such care and compassion for people walking around with these strange arousal patterns in their head that often cause such alienation. They’re shunned or ignored socially, but also by researchers — because of the logistical difficulty, because institutional review boards make approval hard, because sexuality is a subject rife with potential triggers, or because people simply don’t want to investigate things that aren’t trendy or socially sympathetic. I’ve got half a million data points, with an individual behind each one, and I’ll keep trying to understand all of them. &nbsp;</p></div>
                                    </div>
        
    </section>

 
               
       


    <section>            
        <p>
            Published October 2023        </p>
        
        <p>Have something to say? Email us at <a href="mailto:letters@asteriskmag.com">letters@asteriskmag.com</a>.</p>                                
    </section>
      
    
    

    <!--tags-->
     

    
    
                
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Braid is dead, long live Braid (121 pts)]]></title>
            <link>https://amandapeyton.com/blog/2023/10/braid-is-dead-long-live-braid/</link>
            <guid>37797696</guid>
            <pubDate>Fri, 06 Oct 2023 23:38:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://amandapeyton.com/blog/2023/10/braid-is-dead-long-live-braid/">https://amandapeyton.com/blog/2023/10/braid-is-dead-long-live-braid/</a>, See on <a href="https://news.ycombinator.com/item?id=37797696">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<h2>October 6th, 2023</h2><h2><a href="https://amandapeyton.com/blog/2023/10/braid-is-dead-long-live-braid/">Braid Is Dead, Long Live Braid</a></h2>


		
			<h3>A dispatch from the wild, vicious world of consumer payments</h3>
<hr>
<p>On the day I chose to start writing this, I went to an afternoon showing of <a href="https://en.wikipedia.org/wiki/Oldboy_(2003_film)">Oldboy</a> at Alamo. There’s a quote that’s repeated at least three times:</p>
<blockquote><p>Laugh, and the world laughs with you;<br>
Weep, and you weep alone;</p></blockquote>
<p>I’d been trying to write a pithy summary of my last four years in consumer payments, and here it was, served up on a giant screen. Luck is critical for startups, even in death.</p>
<p><a href="https://medium.com/@braidapp/sharing-money-shouldnt-be-hard-introducing-braid-e86d0ffdc52a">Braid</a> was a consumer payments company that was around from 2019-2023. We designed and shipped a brand-new multi-user financial account called a money pool, and raised ~$10mm in venture capital from investors that I’d looked up to for years. It took us ~2.5 years to find product-market fit, and after that we grew sustainably and quickly. We’d made software that people seemed to want.</p>
<p>A few months later, we were dead.</p>
<p>The thrash happened fast, and left a sea of heartbroken customers, employees, investors, and partners. The thing that broke us wasn’t a stronger blow than any of the others, it was simply the last one we could tolerate. The company shut down in September 2023.</p>
<p>That’s not the end of it, though. We ran an auction for our IP and there was a single bidder: me. You see, fintech is far from over.</p>
<p>Tolstoy was right: <em>successful companies are all alike; every failed company fails in its own way.</em> Failure is a cocktail of loneliness, grief and shame, which is why these stories are not told often. But every failure is also a playbook for the next obvious, effortless success, so it’s critical to share.</p>
<p>I hope our story is helpful.</p>
<p><a href="https://amandapeyton.com/blog/wp-content/uploads/2023/10/IMG_08901.jpg"><img title="Harrison Street" src="https://amandapeyton.com/blog/wp-content/uploads/2023/10/IMG_08901-825x1024.jpg" alt="" width="495" height="614"></a><small>Braid’s empty office on Harrison St. in SF</small></p>
<p><strong>What’s Below</strong><br>
I’ve included a timeline of the company’s life, along with one lesson/myth from that time period.</p>
<p><strong>1. Road to Product-Market Fit</strong>, 2019, 2020 and most of 2021.<br>
<em> Myth: Your Early Adopters Are Your Best Customers</em></p>
<p><strong>2. Then, It Worked</strong>, Late 2021 to Summer 2022.<br>
<em>Myth: With Great Metrics You Can Always Raise</em></p>
<p><strong>3. The Ice Bath,</strong> Summer 2022.<br>
<em>Myth: Ruthless Dedication to Compliance Will Save You </em></p>
<p><strong>4. We’re So Done, We’re So Back, We’re So Done</strong>, Summer 2022 to Spring 2023. <em><br>
Myth: The Answer is AWS for Fintech</em></p>
<p><strong>5. Shutting Down, </strong>Summer 2023.<strong> </strong><br>
<em> Myth:Failure is a Learning Experience for Everyone</em></p>
<p>This post is for those who still dare to dream and build in fintech. We do not do this work because it is easy. We do not spend our days trying to make origami out of tissue paper to simply quit and go home. Consumers deserve a financial system that is no less than excellent, and someone needs to do the work to make that happen.</p>
<p>I still blame myself wholly and completely for Braid’s demise, but this post isn’t about me. It’s about what happened.</p>
<hr>
<p><strong>Road to Product-Market Fit, </strong>2019-2021<br>
<em>Myth: Your Early Adopters Are Your Best Customers</em></p>
<p>We had an initial concept for the money pool right away, though it had many different names over time. A multi-user bank account was painful to build and difficult to operationalize for a bunch of reasons, which meant we had very few competitors. But for most of these years our metrics were flat. With consumer products it either works or it doesn’t. We iterated constantly for ~2.5 years.</p>
<p><a href="https://amandapeyton.com/blog/wp-content/uploads/2023/10/Screen-Shot-2023-10-03-at-11.50.34-AM1.png"><img title="Multiplayer Wisdom" src="https://amandapeyton.com/blog/wp-content/uploads/2023/10/Screen-Shot-2023-10-03-at-11.50.34-AM1-1024x541.png" alt="" width="600" height="300"></a></p>
<p>But there’s nothing like a hot market. In early 2019, the <a href="https://www.revolut.com/news/revolut_reports_continued_rapid_growth_in_2019_after_350_increase_in_revenues_for_2018/">neobanks</a> were <a href="https://techcrunch.com/2019/07/17/banking-startup-n26-raises-another-170-million-at-3-5-billion-valuation/?guccounter=1&amp;guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&amp;guce_referrer_sig=AQAAACfMfxnnaMdvHSOMRA71QTMjcNdGYOh4ymHj92t9cE3PFWVWEnasRdu4laaDH2IaNfkt5MafKV0RZ7Y8S-skUVce5A-kPNWNh6XxT4Ll2ciaj9LcEBX2gvdQAmxl3KaU6xpWps7cVlAUjdk4xrDiDXwoelTeEhbc2WcDnw445uqt">taking over</a> <a href="https://www.pymnts.com/news/international/2019/transferwise-reports-66-pct-profit-growth-yoy/">Europe</a>, and in the U.S. <a href="https://www.bloomberg.com/news/articles/2019-09-19/stripe-becomes-third-most-valuable-startup-in-the-u-s">Stripe</a>, <a href="https://www.coindesk.com/markets/2019/04/18/coinbase-generated-520-million-in-revenue-last-year-reuters-estimates/">Coinbase</a>, <a href="https://www.cnbc.com/2019/07/22/robinhood-lands-a-7point6-billion-valuation-after-recent-funding-round.html">Robinhood</a>, and <a href="https://www.forbes.com/sites/jeffkauflin/2019/11/18/digital-bank-chime-will-quadruple-its-revenue-in-2019-reeling-in-direct-deposits/?sh=71788d3a6487">Chime</a> were ripping.</p>
<p>We heard “yes” a lot in those years.</p>
<p>We built the software that we’d wanted to use ourselves, and eventually others started to use it and love it, too. We rode the roller-coaster all the way up, and got high enough to kiss the clouds. But this took a long time.</p>
<p>There are two types of product-market fit for a fintech company: fake PMF and real PMF. Many fintechs, including us, dupe themselves into thinking their PMF is real when it’s not. All the signs are there: enviable early traction, organic growth, and real payment volume. It’s easy to look at the numbers and say, wow, there’s such demand for what we’ve built. We’ve found our cohort of wildly passionate early adopters.</p>
<p>Unfortunately, these people are criminals. They were there to steal our money. They’re early adopters because they’re fraud sharks patrolling coastal waters for fresh meat. And our little payments app? Well, you can guess.</p>
<p>You know who doesn’t move $500 into a brand-new app they’ve never heard of, within 10 minutes of signing up? Real consumers. They need time to learn about the product, build up trust, move $1 or $10 in and out, and make sure everything works.</p>
<p>For the first few months, or few years, fraud can feel all-consuming because it is. I’m thankful that there are many great companies working on this problem (<a href="https://www.sardine.ai/">Sardine</a>, <a href="https://www.sentilink.com/">Sentilink</a>, <a href="https://www.alloy.com/">Alloy</a>, <a href="https://www.unit21.ai/">Unit21</a>, <a href="https://www.socure.com/">Socure</a>, and more). But in the beginning, it was crushing and time-consuming to handle.</p>
<p>The bright side is there are a lot more real consumers than there are fraudsters. If a product resonates, eventually it all flips. I drew the following graph the day we figured this out, and it’s still up on my wall.</p>
<p><a href="https://amandapeyton.com/blog/wp-content/uploads/2023/10/IMG_3570.jpg"><img title="IMG_3570" src="https://amandapeyton.com/blog/wp-content/uploads/2023/10/IMG_3570-1024x768.jpg" alt="" width="600" height="450"></a></p>
<hr>
<p><strong>Then, It Worked</strong><br>
<em>October 2021-July 2022</em><br>
<em>Myth: With Great Metrics You Can Always Raise</em></p>
<p>When we finally found our groove, our payment volume grew ~5% a week, most weeks, for nearly 22 straight weeks in H1 2022. We went from processing less than $10K a day to having multiple $100K+ days, in the span of around five months. We were on track to pass $10mm in monthly volume by Q4 2022. We’d figured out who our customer was, why people wanted what we’d built, and how to find more of them for very little money.</p>
<p>We’d get asked a lot about use-cases – who was using it, and for what?</p>
<p>The most concise explanation of the multi-user opportunity was this: there are financial accounts for 1 and 2 consumers, and there are financial accounts for businesses. But there is no financial account for <em>n</em> consumers. Joint accounts are insufficient, outdated, often (but not always) capped at two, and not a product priority for most banks. A money pool could serve a customer base for which there was no existing product, only clunky workarounds.</p>
<p>There were myriad buckets of <em>n </em>users who loved having a financial account designed just for them. A few examples from our own data: coparents, houses, art collectives, extended families who get along, teams, people who share livestock, churches, punk bands, weekend hustles, extended families who don’t get along, wiccans, and our team’s personal favorite, firehouses.</p>
<p>The use-cases that didn’t work well for us were short-duration social events: group travel, bachelor parties, etc. The <em>“split payments with friends”</em> meme, we found, was a red herring and a fallacy. Opening a standalone financial account for a one-off event makes no sense. These use-cases had massive churn, low relative volume and created little sustainable long-term value. Use Venmo!</p>
<p>Instead of the usual hockey stick graph, here’s a video of a fireman from Alabama talking about how they used Braid:</p>
<p><iframe width="560" height="315" src="https://www.youtube.com/embed/8qIWe3M1Rng?si=XrOBFJzFKSdNbWzi" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe></p>
<p>I called one of our investors in early October 2021 to report that we’d figured it out, that it was going to work. He said, <em>“great, raise money immediately, the time is now.” </em>This advice was excellent, prescient, and correct.</p>
<p>I fought him. I said, <em>“if our numbers are great and consistent, we can always raise, let’s wait it out a few more months.”</em> I believed this, too. But this was the moment I got greedy. I’d like to blame it on anything else – companies raising huge rounds off zero traction, ZIRP, whatever. I’d been building software since I was in my early 20s, and felt that, finally, the rest of the world now understood the magic of software business models. <em>Of course these multiples are warranted</em>, I thought to myself – this growth has no ceiling, the TAM is “unlimited” and this is our new reality. The revenge of the nerds is happening in real-time, and gosh,<em> it fucking rules.</em></p>
<p>But if I really take a hard look at that moment, it was about me, and my ego. We’d processed eight-figures of payments at that point, and over the next few months, we grew consistently and fast. But venture capital is not for companies that are good, or even companies that are great. It’s for companies that are so excellent that they produce outsized returns at the right time, in the right market. We timed this completely wrong and it hurt us.</p>
<p>Every dollar a startup can raise is a gift. For a time I lost sight of this, and I won’t make that mistake again.</p>
<hr>
<p><strong>The Ice Bath</strong><br>
<em>July 2022<br>
Myth: Ruthless Dedication to Compliance Will Save You</em></p>
<p>We’d finally found a delicate equilibrium balancing the many mouths we had to feed: consumers, banks, networks, regulators, employees, investors, vendors and fraudsters.</p>
<p>But that balance got ripped apart fast. Our sponsor bank’s behavior changed suddenly. They stopped replying to emails and became noticeably cagey on phone calls. When they did reply, it was usually with an urgent demand for something they hadn’t asked us about in years. We’ve never heard the full story, but this bank isn’t in the fintech sponsorship business anymore, with us or with anyone. Eventually, we had to move to a new bank. We had to offboard and cash-out all our customers in the summer of 2022.</p>
<p>It felt like a bucket of ice got dumped over our heads. Here is a highly realistic AI-generated image of me in that moment:</p>
<p><a href="https://amandapeyton.com/blog/wp-content/uploads/2023/10/IMG_3898.jpg"><img title="IMG_3898" src="https://amandapeyton.com/blog/wp-content/uploads/2023/10/IMG_3898.jpg" alt="" width="500" height="500"></a></p>
<p>In fintech, it’s easy to pit the technologists and the regulators against one another: <em>fuck around</em> on one side, <em>find out</em> on the other. But we knew better than that. Our product was not in any sort of legal gray area (e.g. crypto) and fit within the bounds of existing law. From the day we started until the day we shut down, we’d spend millions of dollars to build a best-in-class compliance program to sit alongside our offering. For every hour that we spent on engineering for a consumer-facing feature, we spent another hour on compliance, and a third hour on fraud. That meant everything took 3X as long, but there wasn’t another way.</p>
<p>What we didn’t understand at any level of depth, is that even the most robust compliance program would only get us so far. We were taking on indirect risk from every fintech in the bank’s portfolio, as well as the bank’s relationship with its regulators, which is highly protected and confidential. Fintechs sit adjacent to regulators, not directly under them, so mission-critical information affecting multi-million-dollar companies is often delivered via backchannel whispers and a messy game of telephone.</p>
<p>Yet, one observation about sponsor banks is how much they care about supporting new products. The community-oriented mindset is pervasive among bankers. Many see their bank as a place to help their community members live the lives they want. I continue to go back to this quote from a Credit Union executive <a href="https://www.americanbanker.com/creditunions/news/sketching-out-the-future-for-a-bigger-better-credit-union-movement">from February 2018</a>:</p>
<blockquote>
<p>People don’t want a mortgage, they want a house…They don’t want an auto loan, they want a car to get to work. They don’t want a savings account, they want a way to buy the things they want.</p>
</blockquote>
<p>This is encouraging, but banks do not answer to their fintech customers, they answer to their regulators. If the regulators come down on the bank, as the fintech there’s nothing you can do about it. A regulatory rug pull can and will outstrip any early traction or compliance gold stars that you think might save you.</p>
<p>Put another way, as a startup we were a tiny rivulet downstream of the ocean that is the U.S. financial system. When the dam broke, we learned very quickly that no one cared about our perfect, squeaky clean BSA audit.</p>
<hr>
<p><strong>We’re So Done, We’re So Back, We’re So Done</strong><br>
<em>July 2022 – April 2023<br>
Myth: The Answer is AWS for Fintech</em></p>
<p>The company was effectively in a coma from July 2022 to January 2023. It was bleak – we were a payments company processing $0 in payment volume. Eventually, we found a new bank that wanted to work with us, and we were eager to get the product back online. We worked for ~six months on the migration, and Braid came roaring back to life in January 2023.</p>
<p>We started from zero and processed over $1mm in the first ~30 days of our relaunch. It felt like we’d get back to where we left off quickly, as if no time had passed. In the spring of 2023, we signed a term sheet for a new round of funding. It looked like we might make it through, after all.</p>
<p>The euphoria didn’t last.</p>
<p>Six weeks after our relaunch, <a href="https://www.reuters.com/business/finance/global-markets-banks-wrapup-1-2023-03-10/">SVB imploded</a>, and right after, <a href="https://hindenburgresearch.com/block/">Hindenburg Research’s Cash App report</a> dropped. The market kept getting worse. Rates kept going up.</p>
<p>The nail in the coffin came soon after. A critical third-party informed us that they’d changed their mind on a key technical decision. All the players in our ecosystem had not fit together perfectly post-migration, and we’d been dealing with a long list of technical problems.This change was going to break all our software. We had two decisions: rebuild over from zero or shut it all down. It didn’t feel right to take additional capital knowing that we’d have to rebuild, again, so we called off the round.</p>
<p>This should be a separate post, but I wanted to note how much my feelings about fintech software changed over my four-plus years at Braid. Initially, we thought leveraging third-party software would help us move faster and focus on our core offering.</p>
<p>What we found, instead, was every additional partner had the potential to break big, important parts of our stack. Building a multiplayer offering meant we had to be as close to the metal as possible, because a lot of our UX didn’t really exist off-the-shelf. After several painful migrations, our distaste for contractual and technical lock-in grew dramatically. By the end, if there was something we could build ourselves in Retool, we did.</p>
<p>In addition, building mostly in-house was the only way our unit economics worked. There’s a lot of great fintech software out there, but if that software eats your entire margin, you’ll end up dead regardless.</p>
<p>Once we decided it was over, I spent the morning sitting in my Herman Miller chair that would soon be sold, zooming from one end of the office to the other. Could I put it off, just one more hour? The dread and loneliness in that moment is hard to overstate – sending out a final email to customers, laying people off, selling everything, telling the investors.</p>
<p>I’ve been lucky to have started four software companies. Every time they end, whether it’s “a good outcome” or “a bad outcome”, it’s universally devastating.</p>
<p>Finally, we told everyone it was over, and cashed-out our customers for the second time.</p>
<hr>
<p><strong>Shutting Down, IP Sale</strong><br>
<em>June-September 2023<br>
Myth: Failure is a Learning Experience for Everyone</em></p>
<p>The team was gone by June, and I spent the summer winding everything down. The first note I wrote down after we shut down was: <em>when you win, you win together, and when you fail you fail alone.</em> Our failure felt like a lesson, a “case study”, for everyone but me. For me, it was a punch in the gut. In my experience, the best quote on failure is from <a href="https://www.theinformation.com/articles/parker-conrad-takes-the-pain">Parker Conrad</a>:</p>
<blockquote>
<p>‘Failure is really, really, really awful,’ he told me. ‘People describe it as, ‘Oh, you learn so much from failure.’ I don’t think that’s true. I think the only thing I learned was how much failure sucks and how soul destroying it is.’</p>
</blockquote>
<p>It was important to write up these lessons for everyone else. But for me, the biggest takeaway was that I never, ever wanted to fail again.</p>
<p>Braid shut down almost exactly three years after we wrote the <a href="https://medium.com/@braidapp/on-multiplayer-fintech-cb4fffbfe455">Multiplayer Fintech</a> essay. To this day I still believe everything written there – the soul of the product didn’t change much over all the years we worked on it. We swapped features, changed banks, processed thousands, then millions, then tens of millions of dollars.</p>
<p>We ran an auction for the IP, and in the end, there was only one bid: from me. This happens more often than people realize. Payments software has enormous overhead (compliance, fraud, regulatory, etc.) so the software on its own has little inherent value. All our major investors approved the sale, and I’m extremely thankful and grateful they did. Braid’s second act is currently <a href="https://braid.substack.com/">a Substack email list </a>(sign up!), a Github repo and a blinking cursor in a brand-new Google Doc.</p>
<p>Will it be different next time? Yes. Absolutely. So much has changed about the product, market conditions, and business model over the years. Every startup is an amalgamation of thousands of data points that are changing in real-time, and no two are the exact same. The through line is making something people want. This is the most sacred thing of all, and one thing that will never be a myth.</p>
<p>Braid’s second act will be just as tumultuous, I’m sure. Consumer financial needs change faster than our financial system can evolve to meet them. This is a fact. There’s an enormous opportunity here to build excellent software that solves a tangible problem, and that’s what makes it worth it to keep going.</p>
<p>And, I hate to lose.</p>
<hr>
<p><strong>Special Thanks</strong><br>
I want to thank all our customers for taking a chance on us, even the ones who churned, Braid team members past and present who worked hard and shipped, even when our numbers were flat, and every investor who wrote us a check of any amount, even when the market was ice cold.</p>
<p>Finally, thank you to Rajiv Ayyangar for your thoughtful essay about <a href="https://blog.rajivayyangar.com/what-happened-to-tandem-virtual-office/">Tandem</a>, which provided the inspiration for this post.</p>
<p><strong>Solitude</strong><br>
<a href="https://www.poetryfoundation.org/poems/45937/solitude-56d225aad9924">By Ella Wheeler Wilcox</a></p>
<p>Laugh, and the world laughs with you;<br>
Weep, and you weep alone;<br>
For the sad old earth must borrow its mirth,<br>
But has trouble enough of its own.<br>
Sing, and the hills will answer;<br>
Sigh, it is lost on the air;<br>
The echoes bound to a joyful sound,<br>
But shrink from voicing care.</p>
<p>Rejoice, and men will seek you;<br>
Grieve, and they turn and go;<br>
They want full measure of all your pleasure,<br>
But they do not need your woe.<br>
Be glad, and your friends are many;<br>
Be sad, and you lose them all,—<br>
There are none to decline your nectared wine,<br>
But alone you must drink life’s gall.</p>
<p>Feast, and your halls are crowded;<br>
Fast, and the world goes by.<br>
Succeed and give, and it helps you live,<br>
But no man can help you die.<br>
There is room in the halls of pleasure<br>
For a large and lordly train,<br>
But one by one we must all file on<br>
Through the narrow aisles of pain.</p>



<p><small><span>Comments Off</span></small>
</p>
			 <hr>

         



		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Android devices with backdoored firmware found in US schools (139 pts)]]></title>
            <link>https://www.securityweek.com/android-devices-with-backdoored-firmware-found-in-us-schools/</link>
            <guid>37797679</guid>
            <pubDate>Fri, 06 Oct 2023 23:35:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.securityweek.com/android-devices-with-backdoored-firmware-found-in-us-schools/">https://www.securityweek.com/android-devices-with-backdoored-firmware-found-in-us-schools/</a>, See on <a href="https://news.ycombinator.com/item?id=37797679">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="tps_slideContainer_35233">
<p><strong>Tens of thousands of Android devices have been shipped to end-users with backdoored firmware, according to a warning from cybersecurity vendor Human Security.</strong>
</p><p>As part of the global cybercriminal operation called <a href="https://www.humansecurity.com/hubfs/HUMAN_Report_BADBOX-and-PEACHPIT.pdf">BadBox</a> (PDF), Human Security found a threat actor relied on supply chain compromise to infect the firmware of more than 70,000 Android smartphones, CTV boxes, and tablet devices with the Triada malware.
</p><p>The infected devices come from at least one Chinese manufacturer but, before they are delivered to resellers, physical retail stores, and e-commerce warehouses, a backdoor was injected into their firmware.
</p><p>“Products known to contain the backdoor have been found on public school networks throughout the United States,” Human says.
</p><p>Discovered in 2016, <a href="https://www.securityweek.com/triada-trojan-most-advanced-mobile-malware-yet-kaspersky/">Triada is a modular trojan</a> residing in a device’s RAM, relying on the Zygote process to hook all applications on Android, actively using root privileges to substitute system files. Over time, <a href="https://www.securityweek.com/android-trojan-uses-sandbox-evade-detection/">the malware went through various iterations</a> and was found<a href="https://www.securityweek.com/triada-trojan-preinstalled-low-cost-android-devices/"> pre-installed on low-cost Android devices</a> on<a href="https://www.securityweek.com/triada-trojan-pre-installed-low-cost-android-smartphones/"> at least two occasions</a>.
</p><p>As part of the BadBox operation that Human Security discovered, the infected low-cost Android devices allow threat actors to carry out various ad-fraud schemes, including one named PeachPit, which at its peak relied on 121,000 Android and 159,000 iOS devices infected with malware, and on 39 Android, iOS, and CTV-centric apps designed to connect to a fake supply-side platform (SSP).
</p><p>One of the modules delivered to the infected devices from the command-and-control (C&amp;C) server allows the creation of WebViews that are fully hidden from the user, but which “are used to request, render, and click on ads, spoofing the ad requests to look like they’re coming from certain apps, referred by certain websites, and rendered” on specific devices.</p>
<p>BadBox, Human Security notes, also includes a residential proxy module that allows the threat actors to sell access to the victim’s network. Furthermore, they can create WhatsApp messaging accounts and Gmail accounts they can then use for other malicious activities.
</p><p>“Finally, because of the backdoor’s connection to C2 servers on BadBox-infected smartphones, tablets, and CTV boxes, new apps or code can be remotely installed by the threat actors without the device owner’s permission. The threat actors behind BadBox could develop entirely new schemes and deploy them on BadBox-infected devices without any interaction from the devices’ owners,” Human notes.
</p><p>The cybersecurity firm says that it has managed to disrupt the PeachPit ad fraud scheme and that the BadBox operators have taken down their C&amp;C servers, likely to adapt and circumvent the deployed defensive measures.
</p><p>Human also warns that BadBox-infected devices cannot be cleaned by the end-users, since the backdoor resides in the firmware partition and that almost all infected devices are lower-price-point, recommending that users choose familiar brands when purchasing new products.
</p><p><strong>Related:</strong> <a href="https://www.securityweek.com/xenomorph-android-banking-trojan-targeting-users-in-us-canada/">Xenomorph Android Banking Trojan Targeting Users in US, Canada</a>
</p><p><strong>Related:</strong> <a href="https://www.securityweek.com/predator-spyware-delivered-to-ios-android-devices-via-zero-days-mitm-attacks/">Predator Spyware Hitting iOS, Android Devices via Zero-Days</a>
</p><p><strong>Related:</strong> <a href="https://www.securityweek.com/anatsa-banking-trojan-delivered-via-google-play-targets-android-users-in-us-europe/">Banking Trojan Delivered via Google Play Targets Users in US, Europe</a>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Multiplayer game engine with 120fps and 2 second load time on the web (207 pts)]]></title>
            <link>https://dotbigbang.com/game/1af877e9bfdb47088611f55982b7570f/prestons-diamond-wars?mp=playdw</link>
            <guid>37797606</guid>
            <pubDate>Fri, 06 Oct 2023 23:26:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dotbigbang.com/game/1af877e9bfdb47088611f55982b7570f/prestons-diamond-wars?mp=playdw">https://dotbigbang.com/game/1af877e9bfdb47088611f55982b7570f/prestons-diamond-wars?mp=playdw</a>, See on <a href="https://news.ycombinator.com/item?id=37797606">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Looking back on SaaS product strategy (111 pts)]]></title>
            <link>https://ghiculescu.substack.com/p/11-years-of-saas-product-strategy</link>
            <guid>37797503</guid>
            <pubDate>Fri, 06 Oct 2023 23:12:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ghiculescu.substack.com/p/11-years-of-saas-product-strategy">https://ghiculescu.substack.com/p/11-years-of-saas-product-strategy</a>, See on <a href="https://news.ycombinator.com/item?id=37797503">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p><span>In the last year at </span><a href="https://www.tanda.co/" rel="">Tanda</a><span>, we’ve gone from being a single-product company, to launching a bunch of new products that all work together really well.</span></p><p><span> This has got me reflecting on the different phases of product strategy over the last decade, as we went from no product to a market leader.</span></p><p><span>If you find this interesting you might also enjoy </span><em><a href="https://ghiculescu.substack.com/p/11-years-of-hosting-a-saas" rel="">11 years of hosting a SaaS</a></em><span>. </span></p><p>This is the phase that all products, projects, and companies start at. There is nothing built, there is only an idea. In this phase all you should do is build enough of the idea that you can present it to people who’d use or buy it and see what they think. Startup people call that an MVP.</p><p>Planning at this stage is actually quite useful, but it looks very different to planning later on. Anyone experienced with product planning at a mature company will need to unlearn a lot to succeed here. That’s because “planning” here is writing 2 sentence summaries of what needs to get built.</p><blockquote><p>We are going to make an employee time clock that runs on an Android device. It will connect to a website in the cloud so you don’t need any dedicated IT support.</p></blockquote><p>Some people say you should start with a market, and then tailor your product to that. Go out and interview 100 similar potential buyers, figure out something they want, and build exactly that. In my experience, this advice is often given and (correctly) never followed. If you don’t already know about something that people want that you can explain in 2 sentences, then you shouldn’t be starting a business.</p><p>If you insist on the customer research approach, at least work on your script. When wannabe founders ask me if they can do “a customer development interview to identify potential pain points and riff on product ideas”, all I hear is that the call will be a waste of my time.</p><p>You’ve built the first two sentences of your product, and managed to get some people to use it (hopefully to pay for it too). At this stage it can seem pretty obvious what to build next, because you have way less features than what customers expect. You’re on the way to product market fit.</p><p><span>For Tanda, this was the case for award interpretation, rosters, the early, simple, versions of timesheets and leave, and payroll exports.</span></p><p><span>Why were they obvious? Obvious to who? Here’s how I think about it. When talking to a customer or prospect, if instead of asking “does it do X?”, they ask “how do you do X?”, and you can’t confidently answer “oh, you </span><em>don’t</em><span> do X, and here’s why”, then that is an obvious gap. 1) The customer assumed the functionality is there, so it’s an obvious requirement to them. 2) You don’t have a justification for it not being there</span></p><p><span>, so implicitly it’s obvious to you.</span></p><p>When it’s obvious what to build next, product planning is easy. Pick one obvious thing, build the simplest version of it that you can, and repeat. Steer clear of “prioritising”; if you need to prioritise things then implicitly admitting that it’s not obvious what needs to get built, and during this phase you should only build truly obvious things. Pick whichever obvious thing you got asked about most recently, build it, and repeat.</p><p>Seasoned product managers will warn you that if you do this too much you will end up building all sorts of random disparate features that don’t work well together and are not consistent. They’re not wrong, but they miss the part where if you don’t do that you’ll go broke. During this phase, you should build lots of things, accept some of them will suck and attract bad customers, and use this intel to identify who your ideal customers are. Then gradually remove the features, and customers, you don’t want.</p><p><span>While prioritisation is a bad thing during this phase, scoping is not. It’s tempting to get carried away by making a really sophisticated version of your obvious need. Either one that does too many niche things, or one that is too polished. This is where the saying “</span><a href="https://twitter.com/reidhoffman/status/847142924240379904?lang=en" rel="">if you’re not embarrassed by your v1, you shipped too late</a><span>” comes from; the first version of every obvious feature should look a bit ugly, and should only have functionality that 100% of customers will use exactly the same way. All the other stuff, you can come back to later. It’s tempting to plan ahead because you’re “sure” you’ll need some functionality soon. Resist this temptation; even if “soon” actually comes soon (it often doesn’t!) it’s still better to aggressively restrict your scope and add the extra bits later.</span></p><p><span>During this phase you will get asked for lots of things that are not actually obvious needs. For us, a mobile app for employees was the most classic example. We didn’t have one on the app store for the first 4 years of Tanda. We got asked “how do employees install the app?” all the time. Our answer: there’s a mobile website</span></p><p><span>, and everything important also happens over email and SMS</span></p><p><span>. So you see - we’d explain to customers - you don’t </span><em>need</em><span> an app, but what you do need is a really accurate award interpreter, and only we have that.</span></p><p>We didn’t say this because we were fundamentally opposed to native apps. Eventually we built one. But for a long time, it just wasn’t as important as other things we could have built with our really small team.</p><p>All of a sudden you’ll find that all the really obvious stuff has been built. Suddenly prioritisation goes from being really easy, to really hard. You’re drowning in feature requests, bug reports, suggestions (that are phrased as requests), complaints about technical debt, and a million other inputs. And while most of them don’t seem like bad ideas, none of them seem critical either.</p><p>Now you have to actually prioritise.</p><p>I found this transition really difficult. I’d spent years building whatever felt like a good idea and being right more often than not. Now everyone was saying we couldn’t keep doing that and we needed to create a lot of new process to protect ourselves from us building the wrong thing. In hindsight, I should have been more skeptical of the sudden need for drastic change. But I wasn’t, and so we lent into transforming how we did product strategy.</p><p>We got a lot of things wrong over many years while trying to find the right of balancing our intrinsic scrappiness with the new and constantly growing number of customers that relied on us. Here’s some things that didn’t work:</p><p><strong>Succumbing to pressure from big customers</strong></p><p>Big customers will always ask you to build something that everyone knows only they will use. A million people have written the advice that if 1 customer dictates your roadmap then you need to say no. It’s still hard to resist, the first time you have that opportunity.</p><p><span>I thought the reason you aren’t meant to do this is because then you’ll never get off the treadmill of building whatever that customer wants. We were on that treadmill for years with our first enterprise customer, but it actually wasn’t that hard to step off once we really committed to do it. We got very firm about explaining how we’d like to work (citing </span><a href="https://basecamp.com/shapeup" rel="">a book</a><span> helped make it more official), and they respected that and let us work our way.</span></p><p><span>The real problem is that when you are building something a single customer is pressuring you for, it’s incredibly hard to build it in a way that different customers will be able to use.</span></p><p><span> Before we learned this, we built a few features for big important customers, and those features work really well if you’re the same size, and in the same industry, as those customers. For anyone else, they’re too confusing to bother. It took a long time to internalise this and properly try to make them work for all customers. We still haven’t perfected that but it’s a lot better than when we started.</span></p><p>Scarred by getting this wrong a few times, we made a big decision: we won’t build features if only a single customer wants them. This sounded good on paper. In practice it resulted in…</p><p><strong>“Prioritisation” by sorting by MRR</strong></p><p>This is a phenomenon when any internal proposal for a feature (sometimes bug reports too!) includes a list of prospects or customers that have suggested the feature, and their corresponding revenue. Prioritisation becomes picking whichever item has the biggest revenue associated with it.</p><p>The implication is “if we build this feature we’ll win all these new customers” or “if we don’t build this feature we’ll lose all these customers”. It’s never true. It’s very rare to see someone buy or churn off a business software product exclusively because of one feature’s existence. If that’s happening often, and you want those customers, you don’t need prioritisation!</p><p>This methodology is one of those things where there’s enough merit to it that it sounds reasonable in theory, but actually is a total mess in practice. Salespeople and account managers can be very convincing, and it’s really hard to resist the allure of just building what they ask. At the same time, it’s bad to not listen to them at all. To make good product decisions when it’s not obvious what to build next, you need to walk the tightrope between those extremes.</p><p><strong>Forced innovation</strong></p><p><span>Worn down by MRR-based-development, a few teams drew a line in the sand. “From now on, we’re only going to bet on big, chunky, innovative things.” This was very popular internally. Developers love working on “big” projects.</span></p><p><span> Everyone loves innovative new things. What’s not to like?</span></p><p><span>The problem with forcing innovation is that it assumes there is an endless supply of game changing ideas floating around your company, and the only reason you haven’t built them yet is because the product team didn’t want to. If this is true for your company, you’re on the verge of being obscenely rich. But for most companies this isn’t the case. </span><a href="https://stratechery.com/2017/amazons-operating-system/" rel="">You don’t make good products because you really want to, you make good products by fostering the conditions in which great products can be made</a><span>. An environment where every 6 weeks teams pick which big new innovation they’ll be launching is not one that invents anything new.</span></p><p>That’s what we learned, from trying to force this. We saw lots of complex features with fancy names come from this, but nothing that substantially changed the lives or fortunes of our customers.</p><p><strong>Data-driven development</strong></p><p><span>Like most product teams, we spent a lot of time buying and setting up product analytics tools like </span><a href="https://amplitude.com/" rel="">Amplitude</a><span>. Like most product teams, we spent virtually no time using the data inside Amplitude to make good decisions.</span></p><p>Amplitude is a cool tool and it’s well built. I’m sure there are some kinds of product, and some kinds of company, where it’s really useful for finding diamonds of insight. But in our B2B SaaS world, it only uncovered really obvious things we already knew (“lots of people log in every day”, “everyone uses user profiles regularly”).</p><p><span>Same goes for recording tools like </span><a href="https://www.fullstory.com/" rel="">FullStory</a><span>. We were able to uncover a few bugs that were hard to replicate otherwise - and I’m glad we did - but we did not discover brilliant untapped product insights from watching screen recordings of our settings pages.</span></p><p><span>All these tools are a bad proxy for talking to customers.</span></p><p>This is where we’re at today. As we’ve grown as a company, we’ve found that the biggest impact we get when building features comes when the rest of the company can also align its work with that feature.</p><p>This sounds obvious, but it’s a pretty big change from the early days of having the feature idea over breakfast, shipping it after dinner, and hoping your customers discover it.</p><p><span>For example, a few years ago, we added a bunch of improvements to how we handle different kinds of lunch breaks in the shifts people work. To market this, we sent all our prospects a </span><a href="https://www.creativemoment.co/creative-classic-how-and-why-have-a-break-have-a-kit-kat-has-lasted-60-years" rel="">Kit Kat</a><span> in the mail, as well as a flyer about what we’d built. Mailing people stuff is a surprisingly big logistical challenge, but it worked really well to draw attention to what we were doing and get people talking about it. It also got the whole company talking about the same thing. Between designing and building the features and putting Kit Kats in boxes, everyone was aware of what was going on and could make sure they understood the new features well so they could explain them to customers.</span></p><p>I’ve found there’s two cadences that really matter, and if you can get product happening on those cadences then things will work well.</p><ul><li><p>If you do your product thinking on the same cadence as that every other team prioritises work on, you can work together better.</p></li><li><p>If you do your product thinking on a cadence that matches how customers will deploy new features, they’ll be more comfortable with your pace of deployment.</p></li></ul><p><span>In our case it turned out the answer to both of these was every 3 months. We use </span><a href="https://en.wikipedia.org/wiki/Objectives_and_key_results" rel="">OKR</a><span>s across the entire company. Every 3 months the OKRs get refreshed. About a month before that, we pick what the product theme for the next quarter will be. OKRs flow down from that, and the individual pieces of work get shaped from that.</span></p><p>This means every team knows broadly what areas we are thinking about, where to expect improvement, and is able to align it with their work.</p><p>This is where we are at today, I’m sure in the future I’ll write an update about all the stuff that we got wrong here.</p><p>We’re building and launching new products at the moment, which has got me reflecting on this, because those new products are still in Phase 1 (or 0!). It’s so obvious what to build next because there’s still lots of stuff missing! But as a result, we’re getting it done really quickly, knowing we’ll get some things wrong and have to rebuild some stuff along the way.</p><p><span>I wish I’d thought more about </span><em>when</em><span> to add a second product a long time ago. It’s a bit like having kids: most people assume they’ll do it one day, but want to wait until they’re ready. If you wait for an email telling you you’re ready, you’ll never do it. So it is with many things, and I found that once we started building a second product it was not as hard as expected, and much more rewarding. I was most surprised by how much happier customers who buy more products seem to be, which I think has really energised everyone.</span></p><p>Should we have done it earlier? I think so. It would have been harder, we would have been less ready, we’d have gotten more things wrong, and we’d have been more stretched between products - but there’s a lot of sunk cost fallacy to that line of thinking.</p><p>More usefully: should someone who’s just moving from Phase 1 to Phase 2 consider adding a second product as an alternative on going deeper on the existing one? Absolutely you should at least consider it, even if you decide not to after weighing it up.</p><p>If I had a time machine to go back to 2012 and give myself a few pointers, what would I say? 3 big tips:</p><p><strong>Be less afraid of adding new products/markets</strong><span>. I was always really reluctant to consider new products, or new countries (which is basically a new product in our world). It seemed like a lot of hard work that would distract from focusing on the core product. I underestimated how much it would energise the team and increase focus.</span></p><p><strong>Change/remove features if they aren’t working</strong><span>. There’s a lot of product management advice that boils down to “say no to feature ideas”. This is easy to prescribe, and hard to do. But I wish I’d gotten better at changing features, or scrapping them, if they weren’t working well for the majority of customers or were clearly too confusing.</span></p><p><strong>The best product strategy is to build what your customers say they’ll buy</strong><span>. As cliche as it is, there is always temptation to come up with other sources of inspiration for the right thing to build. These should be resisted. If you build what your customers are asking for you’ll build too much stuff, it won’t work together properly, and it’ll be confusing in your UI. But if you build stuff your customers aren’t asking for, you won’t be troubled by having customers for much longer.</span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[SlowLlama: Finetune llama2-70B and codellama on MacBook Air without quantization (147 pts)]]></title>
            <link>https://github.com/okuvshynov/slowllama</link>
            <guid>37796863</guid>
            <pubDate>Fri, 06 Oct 2023 21:46:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/okuvshynov/slowllama">https://github.com/okuvshynov/slowllama</a>, See on <a href="https://news.ycombinator.com/item?id=37796863">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" id="user-content-slowllama" dir="auto"><a href="#slowllama">slowllama</a></h2>
<p dir="auto">Fine-tune Llama2 and CodeLLama models, including 70B/35B on Apple M1/M2 devices (for example, Macbook Air or Mac Mini) or consumer nVidia GPUs.</p>
<p dir="auto">slowllama is not using any quantization. Instead, it offloads parts of model to SSD or main memory on both forward/backward passes. In contrast with training large models from scratch (unattainable) or inference, where we are likely to care about interactivity, we can still get something finetuned if you let it run for a while.</p>
<p dir="auto">Current version is using LoRA to limit the updates to a smaller set of parameters. First version supported full finetuning as well, but I decided to remove it for now, more on that below.</p>
<p dir="auto">Finetuning is the only focus, there's nothing special done for inference, consider <a href="https://github.com/ggerganov/llama.cpp">llama.cpp</a>.</p>
<p dir="auto">For CUDA-specific experiments, see <a href="https://github.com/okuvshynov/slowllama/blob/main/docs/a10.md">report on a10</a>.</p>
<p dir="auto">It is all very experimental, but even more so for CUDA.</p>
<h3 tabindex="-1" id="user-content-example" dir="auto"><a href="#example">Example</a></h3>
<p dir="auto">Tests were done on Apple M1 with 16Gb memory and Apple M2 with 24Gb memory.</p>
<p dir="auto">In order to fine-tune llama2 model we need to:</p>
<ol dir="auto">
<li>Install dependencies: <code>pip install torch sentencepiece numpy</code>. Optional: install <code>pip install fewlines</code> for <a href="https://github.com/okuvshynov/slowllama/blob/main/docs/lora_weights.md">weight/gradient distribution logging</a>.</li>
<li>Clone <a href="https://github.com/facebookresearch/llama">llama2</a> and follow instructions to download the models. The script will download tokenizer as well. <code>tokenizer.model</code> should be put into the same directory as llama model itself. Use <a href="https://github.com/facebookresearch/codellama">codellama</a> for CodeLLama models. Example folder structure could look like:</li>
</ol>
<div data-snippet-clipboard-copy-content="/parent/
    /slowllama/...   # <- this repo
    /codellama/...   # <-- this is Meta's codellama repository.
    /llama-2-7b/...  # <- put tokenizer.model here
    /llama-2-13b/... # <- and here
    /llama-2-70b/... # <- and here as well
    /CodeLlama-34b-Python/... # and here"><pre><code>/parent/
    /slowllama/...   # &lt;- this repo
    /codellama/...   # &lt;-- this is Meta's codellama repository.
    /llama-2-7b/...  # &lt;- put tokenizer.model here
    /llama-2-13b/... # &lt;- and here
    /llama-2-70b/... # &lt;- and here as well
    /CodeLlama-34b-Python/... # and here
</code></pre></div>
<p dir="auto">Let's start with a <a href="https://github.com/okuvshynov/slowllama/blob/main/test_data/cubestat.txt">tiny example</a>. It is an intro to the description of another open-source project - <a href="https://github.com/okuvshynov/cubestat">cubestat</a>. Text is short enough to just be included as part of the prompt, but it's ok as an illustration and you can read it in seconds youself. As I just published that project recently, there's no way original llama would know anything about it.</p>
<p dir="auto">Asking base llama2-7b to complete the prompt <em>"Cubestat reports the following metrics: "</em> results in <em>"1) the number of cubes in the system, 2) the number of cubes that are in the process of being created"</em>.</p>
<p dir="auto">First step is to transform the model to the sequential format more suitable for loading to/from storage block-by-block.</p>

<p dir="auto">Modify the input/output paths in the script itself.</p>
<p dir="auto">Now we can try not-finetuned llama2:</p>
<div data-snippet-clipboard-copy-content="python test_gen.py ../llama7b mps # use path to transformed model here"><pre><code>python test_gen.py ../llama7b mps # use path to transformed model here
</code></pre></div>
<p dir="auto">Now let's finetune the 7b model. <a href="https://github.com/okuvshynov/slowllama/blob/main/finetune.py">finetune.py</a> is a very simple script which trains LoRA weights based on the plaintext data. There are some settings you could change here, like sequence length, batch size, learning rate, dropout rate, number of iterations. Current settings are pretty much a guess, change this if desired. Adjust accordingly. Currently it uses AdamW optimizer.</p>

<p dir="auto">Here's train dataset loss:</p>
<div data-snippet-clipboard-copy-content="2023-09-10 22:05:35,569 backprop done, loss after forward pass = 2.9539270401000977
2023-09-10 22:06:08,022 backprop done, loss after forward pass = 2.9073102474212646
2023-09-10 22:06:40,223 backprop done, loss after forward pass = 2.7192320823669434
2023-09-10 22:07:12,468 backprop done, loss after forward pass = 2.7223477363586426
2023-09-10 22:07:44,626 backprop done, loss after forward pass = 2.5889995098114014
2023-09-10 22:08:16,899 backprop done, loss after forward pass = 2.4459967613220215
2023-09-10 22:08:49,072 backprop done, loss after forward pass = 2.3632657527923584
2023-09-10 22:09:21,335 backprop done, loss after forward pass = 2.250361442565918
2023-09-10 22:09:53,511 backprop done, loss after forward pass = 2.165428638458252
2023-09-10 22:10:25,738 backprop done, loss after forward pass = 2.031874656677246
2023-09-10 22:13:45,794 backprop done, loss after forward pass = 1.8926434516906738
2023-09-10 22:14:18,049 backprop done, loss after forward pass = 1.7222942113876343
2023-09-10 22:14:50,243 backprop done, loss after forward pass = 1.58726966381073
2023-09-10 22:15:22,405 backprop done, loss after forward pass = 1.4983913898468018
2023-09-10 22:15:54,598 backprop done, loss after forward pass = 1.296463131904602
2023-09-10 22:16:26,909 backprop done, loss after forward pass = 1.3328818082809448
2023-09-10 22:16:59,031 backprop done, loss after forward pass = 1.0978631973266602
2023-09-10 22:17:31,200 backprop done, loss after forward pass = 1.018444538116455
2023-09-10 22:18:03,406 backprop done, loss after forward pass = 0.8421685099601746
2023-09-10 22:18:35,673 backprop done, loss after forward pass = 0.7168515920639038
2023-09-10 22:21:55,482 backprop done, loss after forward pass = 0.7870235443115234"><pre><code>2023-09-10 22:05:35,569 backprop done, loss after forward pass = 2.9539270401000977
2023-09-10 22:06:08,022 backprop done, loss after forward pass = 2.9073102474212646
2023-09-10 22:06:40,223 backprop done, loss after forward pass = 2.7192320823669434
2023-09-10 22:07:12,468 backprop done, loss after forward pass = 2.7223477363586426
2023-09-10 22:07:44,626 backprop done, loss after forward pass = 2.5889995098114014
2023-09-10 22:08:16,899 backprop done, loss after forward pass = 2.4459967613220215
2023-09-10 22:08:49,072 backprop done, loss after forward pass = 2.3632657527923584
2023-09-10 22:09:21,335 backprop done, loss after forward pass = 2.250361442565918
2023-09-10 22:09:53,511 backprop done, loss after forward pass = 2.165428638458252
2023-09-10 22:10:25,738 backprop done, loss after forward pass = 2.031874656677246
2023-09-10 22:13:45,794 backprop done, loss after forward pass = 1.8926434516906738
2023-09-10 22:14:18,049 backprop done, loss after forward pass = 1.7222942113876343
2023-09-10 22:14:50,243 backprop done, loss after forward pass = 1.58726966381073
2023-09-10 22:15:22,405 backprop done, loss after forward pass = 1.4983913898468018
2023-09-10 22:15:54,598 backprop done, loss after forward pass = 1.296463131904602
2023-09-10 22:16:26,909 backprop done, loss after forward pass = 1.3328818082809448
2023-09-10 22:16:59,031 backprop done, loss after forward pass = 1.0978631973266602
2023-09-10 22:17:31,200 backprop done, loss after forward pass = 1.018444538116455
2023-09-10 22:18:03,406 backprop done, loss after forward pass = 0.8421685099601746
2023-09-10 22:18:35,673 backprop done, loss after forward pass = 0.7168515920639038
2023-09-10 22:21:55,482 backprop done, loss after forward pass = 0.7870235443115234
</code></pre></div>
<p dir="auto">I didn't add a validation set for this data, instead I just checked what would the fine-tuned model produce for the same prompt.</p>
<p dir="auto">At ~10 iteration we get the following reasonable output:  <em>Cubestat reports the following metrics: 1. CPU usage, 2. Memory usage, 3. Disk usage</em></p>
<p dir="auto">At ~20 iteration another output is produced:</p>
<p dir="auto"><em>0 - Cubestat reports the following metrics: CPU utilization: Efficiency and Performance cores. Shows as percentage.</em></p>
<p dir="auto">Maybe we were overfitting already at this point.</p>
<p dir="auto">Running completion with newly produced lora checkpoint can be done like this:</p>
<div data-snippet-clipboard-copy-content="python test_gen.py ../llama7b mps ./out/state_dict_19.pth"><pre><code>python test_gen.py ../llama7b mps ./out/state_dict_19.pth
</code></pre></div>
<h3 tabindex="-1" id="user-content-how-does-it-work" dir="auto"><a href="#how-does-it-work">How does it work?</a></h3>
<p dir="auto">For all versions the process is roughly the same.</p>
<p dir="auto">First, we need to be able to load a model which requires more RAM than we have and save it back in sequential format. We create model instance with all large modules' weights offloaded to SSD - all of the transformer blocks, token embeddings and output linear layer. After that we <a href="https://github.com/okuvshynov/slowllama/blob/main/loader.py#L69">load model shards one by one</a>, for each shard iterate over all modules, update corresponding subset of its weights and save it back.</p>
<p dir="auto">Doing forward path is easy - we just load modules when we need and pass the output forward.</p>
<p dir="auto">Backward pass is a little more tricky, in a way we have to run forward pass twice. The way it's <a href="https://github.com/okuvshynov/slowllama/blob/main/blackbox_model.py#L351">currently implemented</a> is:</p>
<ol dir="auto">
<li>Do a forward pass while also saving inputs to each offloaded block to the SSD. The goal of the first forward pass is to compute the final loss and cache inputs to each offloaded block.</li>
<li>Then, do a manual backward gradient propagation. We start from the last block, re-run each block once again (forward, to build autograd graph) with the same input we cached on step (1). After that we run backward pass within that block only, and pass the gradient for the input to the next (previous?) block. As we use LoRA, only LoRA gradients are being saved. LoRA weights are not offloaded to disk, always staying on RAM/GPU. Important: we also need to save and restore random number generation state before evaluating each offloaded module. During training we use dropout, and randomly switched off neurons should be the same on both forward passes.</li>
<li>After that we run optimizer step on LoRA weights and save them separately if needed.</li>
</ol>
<p dir="auto">Original llama2 weights are in bfloat16, but mps backend doesn't support that type natively, so we do computation in float32 instead.</p>
<p dir="auto">Experimental version of slowllama which can be still found <a href="https://github.com/okuvshynov/experiments/tree/5cf944cb1274e577d1e755e6ad1957190d286d9d/split_model">here</a> was capable of doing full finetuning and update all weights pretty much the same way. I've temporarily removed that feature to preserve the lifespan of SSDs, as frequent write operations can degrade performance over time. Reading from SSDs isn't an issue, but they do have a write limit. Limit is typically high enough for normal usage, but in the case of full finetunining we'll have to write ~150Gb per one iteration/weight update of 70B variant, assuming stateless optimizer and no gradient accumulation. With AdamW we'll have to save/update another 150Gb more of optimizer state per iteration. If, for example, we assume 1Pb of writes before SSD will start having issues, even 100 iterations of finetuning would incur significant cost/risk. For machines with GPUs and large amount of RAM we can skip the disk entirely and offload to RAM only. It should be possible to bring full finetuning back for main-memory-only offload. On the other hand, if everything fits into memory, there's no need to do whole 'evaluate twice' thing, might just use <a href="https://fairscale.readthedocs.io/en/stable/deep_dive/offload.html" rel="nofollow">fairscale</a> instead and only move tensors between GPU/CPU.</p>
<h3 tabindex="-1" id="user-content-experiments" dir="auto"><a href="#experiments">Experiments</a></h3>
<h4 tabindex="-1" id="user-content-llama2-7b-finetune-on-m1-mini-16gb-memory" dir="auto"><a href="#llama2-7b-finetune-on-m1-mini-16gb-memory">Llama2 7B finetune on M1 Mini (16Gb memory):</a></h4>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/okuvshynov/slowllama/blob/main/static/finetune_m1_7b.png"><img src="https://github.com/okuvshynov/slowllama/raw/main/static/finetune_m1_7b.png" alt="finetune on mac mini"></a></p>
<p dir="auto">Here we can see resource utilization for 1 full iteration on 7B model - forward and manual backward passes. Each column == 1 second. A few notes:</p>
<ol dir="auto">
<li>GPU is reasonably well utilized;</li>
<li>First forward pass has lower GPU utilization and spends more time on IO as we need to both read weights and write cached inputs/outputs</li>
<li>Backward (combined?) pass achieves very high GPU utilization, close to 100%</li>
<li>As we move along layers back and forth, right after each 'direction switch' we process layers in LIFO order. Thus in the beginning of both forward and backward pass we don't have to access disk, weights are being cached and we don't see disk reads.</li>
</ol>
<p dir="auto">batch_size/seq_len - works ok with, say, 2048 seq_len and batch_size = 2.</p>
<h4 tabindex="-1" id="user-content-llama2-70b-finetune-on-m1-mini-16gb-memory" dir="auto"><a href="#llama2-70b-finetune-on-m1-mini-16gb-memory">Llama2 70B finetune on M1 Mini (16Gb memory)</a></h4>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/okuvshynov/slowllama/blob/main/static/llama2_70b_m1.png"><img src="https://github.com/okuvshynov/slowllama/raw/main/static/llama2_70b_m1.png" alt="finetune 70b model"></a></p>
<p dir="auto">The chart here has different granularity - each column is 30 seconds. Input data was also different - it is the readme file you are reading now.
I didn't have enough free space on disk to store both original weights (140Gb) + weights in sequential format we use (another 140Gb). In order to still be able to finetune this model, I stored original weights on much slower external SD card, as we need to read them only once. Weights in sequential format on fast internal SSD.
With batch size = 16 and sequence length = 128 it was taking ~25-30 min per iteration.</p>
<p dir="auto">As we can see, GPU utilization doesn't look that great - we might be able to benefit from prefetching next transformer block, assuming we have enough memory for storing 2 layers. Memory utilization peaked at around 80% of 16Gb.</p>
<p dir="auto">Loss over time:</p>
<div data-snippet-clipboard-copy-content="2023-09-13 17:30:28,731 backprop done, loss after forward pass = 2.431253433227539
2023-09-13 18:00:00,133 backprop done, loss after forward pass = 2.604712963104248
2023-09-13 18:29:36,473 backprop done, loss after forward pass = 2.6277880668640137
2023-09-13 19:00:40,463 backprop done, loss after forward pass = 2.408756971359253
2023-09-13 19:29:55,974 backprop done, loss after forward pass = 2.6121537685394287
2023-09-13 19:59:04,849 backprop done, loss after forward pass = 2.428431987762451
2023-09-13 20:27:03,760 backprop done, loss after forward pass = 2.4040215015411377
2023-09-13 20:55:56,969 backprop done, loss after forward pass = 2.158071279525757
2023-09-13 21:25:04,615 backprop done, loss after forward pass = 2.3459620475769043
2023-09-13 21:54:07,128 backprop done, loss after forward pass = 2.2933709621429443
2023-09-13 23:18:57,588 backprop done, loss after forward pass = 2.273494243621826
2023-09-13 23:48:05,310 backprop done, loss after forward pass = 2.4055371284484863
2023-09-14 00:17:19,113 backprop done, loss after forward pass = 2.2604546546936035
2023-09-14 00:46:31,872 backprop done, loss after forward pass = 2.552386522293091
2023-09-14 01:15:45,731 backprop done, loss after forward pass = 2.297588586807251
2023-09-14 01:44:51,640 backprop done, loss after forward pass = 2.1217401027679443
2023-09-14 02:14:09,033 backprop done, loss after forward pass = 1.9815442562103271
2023-09-14 02:43:09,114 backprop done, loss after forward pass = 2.020181179046631
2023-09-14 03:12:17,966 backprop done, loss after forward pass = 2.0041542053222656
2023-09-14 03:41:20,649 backprop done, loss after forward pass = 1.9396495819091797
2023-09-14 05:06:31,414 backprop done, loss after forward pass = 2.1592249870300293
2023-09-14 05:35:39,080 backprop done, loss after forward pass = 1.976989984512329
2023-09-14 06:04:57,859 backprop done, loss after forward pass = 1.7638890743255615
2023-09-14 06:34:06,953 backprop done, loss after forward pass = 1.9829202890396118
2023-09-14 07:03:18,661 backprop done, loss after forward pass = 1.754631519317627
2023-09-14 07:32:26,179 backprop done, loss after forward pass = 2.027863025665283
2023-09-14 08:01:37,546 backprop done, loss after forward pass = 1.8579339981079102
2023-09-14 08:30:41,689 backprop done, loss after forward pass = 1.7934837341308594
2023-09-14 08:59:55,921 backprop done, loss after forward pass = 1.794022798538208
2023-09-14 09:28:59,690 backprop done, loss after forward pass = 1.750269889831543
2023-09-14 10:56:19,282 backprop done, loss after forward pass = 1.4310824871063232
2023-09-14 11:25:28,462 backprop done, loss after forward pass = 1.6895856857299805
2023-09-14 11:54:39,973 backprop done, loss after forward pass = 1.5074403285980225
2023-09-14 12:23:42,604 backprop done, loss after forward pass = 1.6695624589920044
2023-09-14 12:53:00,535 backprop done, loss after forward pass = 1.4220315217971802
2023-09-14 13:22:15,685 backprop done, loss after forward pass = 1.5720497369766235
2023-09-14 13:51:30,744 backprop done, loss after forward pass = 1.544579267501831
2023-09-14 14:20:44,482 backprop done, loss after forward pass = 1.2813694477081299
2023-09-14 14:50:03,384 backprop done, loss after forward pass = 1.2990479469299316
2023-09-14 15:19:09,620 backprop done, loss after forward pass = 1.0500637292861938"><pre><code>2023-09-13 17:30:28,731 backprop done, loss after forward pass = 2.431253433227539
2023-09-13 18:00:00,133 backprop done, loss after forward pass = 2.604712963104248
2023-09-13 18:29:36,473 backprop done, loss after forward pass = 2.6277880668640137
2023-09-13 19:00:40,463 backprop done, loss after forward pass = 2.408756971359253
2023-09-13 19:29:55,974 backprop done, loss after forward pass = 2.6121537685394287
2023-09-13 19:59:04,849 backprop done, loss after forward pass = 2.428431987762451
2023-09-13 20:27:03,760 backprop done, loss after forward pass = 2.4040215015411377
2023-09-13 20:55:56,969 backprop done, loss after forward pass = 2.158071279525757
2023-09-13 21:25:04,615 backprop done, loss after forward pass = 2.3459620475769043
2023-09-13 21:54:07,128 backprop done, loss after forward pass = 2.2933709621429443
2023-09-13 23:18:57,588 backprop done, loss after forward pass = 2.273494243621826
2023-09-13 23:48:05,310 backprop done, loss after forward pass = 2.4055371284484863
2023-09-14 00:17:19,113 backprop done, loss after forward pass = 2.2604546546936035
2023-09-14 00:46:31,872 backprop done, loss after forward pass = 2.552386522293091
2023-09-14 01:15:45,731 backprop done, loss after forward pass = 2.297588586807251
2023-09-14 01:44:51,640 backprop done, loss after forward pass = 2.1217401027679443
2023-09-14 02:14:09,033 backprop done, loss after forward pass = 1.9815442562103271
2023-09-14 02:43:09,114 backprop done, loss after forward pass = 2.020181179046631
2023-09-14 03:12:17,966 backprop done, loss after forward pass = 2.0041542053222656
2023-09-14 03:41:20,649 backprop done, loss after forward pass = 1.9396495819091797
2023-09-14 05:06:31,414 backprop done, loss after forward pass = 2.1592249870300293
2023-09-14 05:35:39,080 backprop done, loss after forward pass = 1.976989984512329
2023-09-14 06:04:57,859 backprop done, loss after forward pass = 1.7638890743255615
2023-09-14 06:34:06,953 backprop done, loss after forward pass = 1.9829202890396118
2023-09-14 07:03:18,661 backprop done, loss after forward pass = 1.754631519317627
2023-09-14 07:32:26,179 backprop done, loss after forward pass = 2.027863025665283
2023-09-14 08:01:37,546 backprop done, loss after forward pass = 1.8579339981079102
2023-09-14 08:30:41,689 backprop done, loss after forward pass = 1.7934837341308594
2023-09-14 08:59:55,921 backprop done, loss after forward pass = 1.794022798538208
2023-09-14 09:28:59,690 backprop done, loss after forward pass = 1.750269889831543
2023-09-14 10:56:19,282 backprop done, loss after forward pass = 1.4310824871063232
2023-09-14 11:25:28,462 backprop done, loss after forward pass = 1.6895856857299805
2023-09-14 11:54:39,973 backprop done, loss after forward pass = 1.5074403285980225
2023-09-14 12:23:42,604 backprop done, loss after forward pass = 1.6695624589920044
2023-09-14 12:53:00,535 backprop done, loss after forward pass = 1.4220315217971802
2023-09-14 13:22:15,685 backprop done, loss after forward pass = 1.5720497369766235
2023-09-14 13:51:30,744 backprop done, loss after forward pass = 1.544579267501831
2023-09-14 14:20:44,482 backprop done, loss after forward pass = 1.2813694477081299
2023-09-14 14:50:03,384 backprop done, loss after forward pass = 1.2990479469299316
2023-09-14 15:19:09,620 backprop done, loss after forward pass = 1.0500637292861938
</code></pre></div>
<p dir="auto">We used prompt 'slowllama is a ', and here you can see the completions:</p>
<ul dir="auto">
<li>before any weight update: <em>slowllama is a 24 year old (DOB: December 25, 1994) pure-blood witch</em></li>
<li>after 10 iterations: <em>slowllama is a 24 year old (DOB: December 25, 1994) pure-blood witch</em></li>
<li>after 20 iterations: <em>slowllama is a 70B model trained on the same data as llama.70b, but with a different training setup.</em></li>
<li>after 30 iterations: <em>slowllama is a 2022 fork of llama2, which is a 2021 fork of llama, which is a 2020 fork</em></li>
<li>after 40 iterations: <em>slowllama is a 2-stage finetuning implementation for llama2.</em></li>
</ul>
<p dir="auto">Current setup is probably too slow for 70B model finetuning on old mac mini M1. It would be interesting to try it on more recent hardware (say, M2 Max / M2 Pro), implement prefetch/async save and see how it's going to work.</p>
<h3 tabindex="-1" id="user-content-merging-lora-weights-back" dir="auto"><a href="#merging-lora-weights-back">merging LoRA weights back</a></h3>
<p dir="auto">In order to merge LoRA checkpoint back to the model in original format, we can do the following:</p>
<div data-snippet-clipboard-copy-content="# confirm that old model is producing wrong output
python test_gen.py ../llama-2-7b mps

# ...
# 0 - slowllama is a 24 year old (DOB: May 1, 1997) pure-blood witch 

# check what would be the output for finetuned model by passing path to checkpoint
python test_gen.py ../llama-2-7b mps ./data/state_dict_29.pth

# ...
# 0 - slowllama is a 100% static, 100% offline, 100% open source, 100% free,

# now run merge. we need to pass: 
#   - original model path
#   - new path for new model
#   - lora checkpoint path 
#   - optionally number of model shards (default = 1)
python merge_lora.py ../llama-2-7b ./data/state_dict_29.pth ../llama-2-7b-out

# copy tokenizer model over:
cp ../llama-2-7b/tokenizer.model ../llama-2-7b-out/

# now run new model with no extra checkpoint, observe new output, same as in combined model: 
python test_gen.py ../llama-2-7b-out mps

# ...
# 0 - slowllama is a 100% static, 100% offline, 100% open source, 100% free,
"><pre><code># confirm that old model is producing wrong output
python test_gen.py ../llama-2-7b mps

# ...
# 0 - slowllama is a 24 year old (DOB: May 1, 1997) pure-blood witch 

# check what would be the output for finetuned model by passing path to checkpoint
python test_gen.py ../llama-2-7b mps ./data/state_dict_29.pth

# ...
# 0 - slowllama is a 100% static, 100% offline, 100% open source, 100% free,

# now run merge. we need to pass: 
#   - original model path
#   - new path for new model
#   - lora checkpoint path 
#   - optionally number of model shards (default = 1)
python merge_lora.py ../llama-2-7b ./data/state_dict_29.pth ../llama-2-7b-out

# copy tokenizer model over:
cp ../llama-2-7b/tokenizer.model ../llama-2-7b-out/

# now run new model with no extra checkpoint, observe new output, same as in combined model: 
python test_gen.py ../llama-2-7b-out mps

# ...
# 0 - slowllama is a 100% static, 100% offline, 100% open source, 100% free,

</code></pre></div>
<p dir="auto">Now the <code>../llama-2-7b-out</code> can be used in exactly same way as original llama2 for further quantization, inference, etc.</p>
<h3 tabindex="-1" id="user-content-project-structure" dir="auto"><a href="#project-structure">Project structure</a></h3>
<p dir="auto">Just a few files with no dependencies other than torch, numpy and sentencepiece for tokenizer.</p>
<ol dir="auto">
<li><a href="https://github.com/okuvshynov/slowllama/blob/main/blackbox_model.py">blackbox_model.py</a> -- model definition and manual backprop implementation. It's based on model.py from <a href="https://github.com/karpathy/llama2.c">llama2.c</a>, also MIT licenced.</li>
<li><a href="https://github.com/okuvshynov/slowllama/blob/main/finetune.py">finetune.py</a> - script which does the training</li>
<li><a href="https://github.com/okuvshynov/slowllama/blob/main/loader.py">loader.py</a> - manual loading/saving of large llama2 models</li>
<li><a href="https://github.com/okuvshynov/slowllama/blob/main/utils.py">utils.py</a> - small utility functions, including saving/loading random generator state for different devices.</li>
<li><a href="https://github.com/okuvshynov/slowllama/blob/main/test_gen.py">test_gen.py</a> - greedily complete the prompt. Takes base weights + trained LoRA weights as input. Useful for sanity checks.</li>
<li><a href="https://github.com/okuvshynov/slowllama/blob/main/blackbox.py">blackbox.py</a> - module wrapper which offloads the module to disk or main memory.</li>
<li><a href="https://github.com/okuvshynov/slowllama/blob/main/plot_lora.py">plot_lora.py</a> - logging utility, writes LoRA weights and gradient distribution to <a href="https://github.com/okuvshynov/slowllama/blob/main/docs/lora_weights.md">logfile</a>. Requires <a href="https://github.com/okuvshynov/fewlines">fewlines</a>. If fewlines is not installed, does nothing.</li>
<li><a href="https://github.com/okuvshynov/slowllama/blob/main/merge_lora.py">merge_lora.py</a> - merge original weights + lora weights in the original format which can then be used directly.</li>
<li><a href="https://github.com/okuvshynov/slowllama/blob/main/prepare_model.py">prepare_model.py</a> - script to transform sharded model to sequentially split model.</li>
</ol>
<h3 tabindex="-1" id="user-content-todo" dir="auto"><a href="#todo">TODO:</a></h3>
<div data-snippet-clipboard-copy-content="[ ] masking
[ ] more generic train routine
    [ ] pause/resume from LoRA snapshot
    [ ] do not create LoRA layers on prepare, only on finetune?
[ ] how to make it work with fp16 on Apple?
[ ] optimizations - prefetch the next layer/input, save asyncronously, etc;
[ ] gradient accumulation
[ ] plot something like memory requirement for (batch_size , seq_len)
[ ] combined RAM/disk offload - 200Gb RAM is rarity.
[ ] tests, cleanup and comments;
[ ] progress tracking for everything;
[ ] quantization beyond 16 bit?
[ ] configurable weight tying;
[ ] double check RNG state correctness."><pre><code>[ ] masking
[ ] more generic train routine
    [ ] pause/resume from LoRA snapshot
    [ ] do not create LoRA layers on prepare, only on finetune?
[ ] how to make it work with fp16 on Apple?
[ ] optimizations - prefetch the next layer/input, save asyncronously, etc;
[ ] gradient accumulation
[ ] plot something like memory requirement for (batch_size , seq_len)
[ ] combined RAM/disk offload - 200Gb RAM is rarity.
[ ] tests, cleanup and comments;
[ ] progress tracking for everything;
[ ] quantization beyond 16 bit?
[ ] configurable weight tying;
[ ] double check RNG state correctness.
</code></pre></div>
<h3 tabindex="-1" id="user-content-references" dir="auto"><a href="#references">References</a></h3>
<ul dir="auto">
<li><a href="https://github.com/facebookresearch/llama">llama2</a></li>
<li><a href="https://github.com/ggerganov/llama.cpp">llama.cpp</a></li>
<li><a href="https://github.com/karpathy/llama2.c">llama2.c</a></li>
<li><a href="https://github.com/okuvshynov/cubestat">cubestat</a></li>
<li><a href="https://arxiv.org/abs/2106.09685" rel="nofollow">LoRA</a></li>
</ul>
<h3 tabindex="-1" id="user-content-contact" dir="auto"><a href="#contact">Contact</a></h3>
<p dir="auto">{github handle} @ gmail.com</p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Lasers deflected using air (148 pts)]]></title>
            <link>https://www.desy.de/news/news_search/index_eng.html?openDirectAnchor=2951&amp;two_columns=0</link>
            <guid>37796428</guid>
            <pubDate>Fri, 06 Oct 2023 21:06:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.desy.de/news/news_search/index_eng.html?openDirectAnchor=2951&#x26;two_columns=0">https://www.desy.de/news/news_search/index_eng.html?openDirectAnchor=2951&#x26;two_columns=0</a>, See on <a href="https://news.ycombinator.com/item?id=37796428">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>Innovative concept changes the direction of laser light with the help of sound waves</p><div><p>Using a novel method, beams of laser light can be deflected using air alone. An invisible grating made only of air is not only immune to damage from the laser light, but it also preserves the original quality of the beam, reports the interdisciplinary research team in the journal <em>Nature Photonics</em>. The researchers have applied for a patent for their method.</p><div><video controls="controls"><source src="https://www.desy.de/e409/e116959/e119238/media/13764/Szene_01.mp4.mp4" type="video/mp4">Your browser does not support the video tag. Please try to <a href="https://www.desy.de/e409/e116959/e119238/media/13764/Szene_01.mp4.mp4" target="_blank">download</a> the video file.</video><p>In this animation, a laser light beam passes between a loudspeaker-reflector array that creates a grating of air. The laser beam interacts with this grating and is deflected without contact. Animation: Science Communication Lab for DESY</p></div><p>The innovative technique uses sound waves in order to modulate the air in the region where the laser beam is passing. “We’ve generated an optical grating with the help of acoustic density waves,” explains first author Yannick Schrödel, a Ph.D. student at DESY and Helmholtz Institute Jena. With the help of special loudspeakers, the researchers shape a pattern of dense and less dense areas in the air, forming a striped grating. In a way that is similar to how differential air densities bend the light in the Earth’s atmosphere, the density pattern takes on the role of an optical grating that changes the direction of the laser light beam. “However, deflecting light by diffraction grating allows much more precise control of the laser light compared to deflection in the Earth's atmosphere,” says Schrödel. “The properties of the optical grating are influenced by the frequency and intensity – in other words, the volume – of the sound waves.”</p><p>In the first laboratory tests, a strong infrared laser pulse could be redirected in this way with an efficiency of 50 percent. Significantly higher efficiencies should be possible in the future, according to numerical models. For the first test, the scientists had to turn their special loudspeakers way up. “We are moving at a sound level of about 140 decibels, which corresponds to a jet engine a few metres away,” explains scientist Christoph Heyl from DESY and the Helmholtz Institute Jena, who is leading the research project. “Fortunately, we are in the ultrasound range, which our ears don’t pick up.”</p><p>Here you can try out the deflection of the laser light by sound waves by sliding the slider:</p><p>The team sees great potential in the technique for high-performance optics. In their experiments, the researchers used an infrared laser pulse with a peak power of 20 gigawatts, which corresponds to the power of around two billion LED bulbs. Lasers of this and even higher power classes are used, for example, for material processing, in fusion research, or for the latest particle accelerators. “In this power range, the material properties of mirrors, lenses, and prisms significantly limit their use, and such optical elements are easily damaged by strong laser beams in practice,” explains Heyl. “In addition, the quality of the laser beam suffers. In contrast, we’ve managed to deflect laser beams in a quality-preserving way without contact.”</p><p>The principle of acoustic control of laser light in gases is not limited to the generation of optical gratings, the scientists emphasise. It can probably also be transferred to other optical elements such as lenses and waveguides. “We’ve been thinking about this method for a long time and quickly realised that extreme sound levels are necessary. At first, these seemed technically unfeasible,” explains Heyl. “However, we did not give up and finally found a solution with the support of researchers at the Technical University of Darmstadt as well as the company Inoson. First, we tried out our technique with ordinary air. Next, for example, we will also use other gases in order to tap into other wavelengths and other optical properties and geometries.”</p><p>The deflection of light directly into ambient air, which has already been demonstrated, opens up promising applications, especially as a fast switch for high-power lasers. “The potential of contactless control of light and its extension to other applications can currently only be imagined,” explains Heyl. “Modern optics is based almost exclusively on the interaction of light with solid matter. Our approach opens up a completely new direction.”</p><p>Researchers from the Technical University of Darmstadt, Aalen University of Applied Sciences, Universität Hamburg, Inoson GmbH in St. Ingbert, the Helmholtz Institute Jena, and DESY were involved in the work.</p><p><strong>Reference:<br></strong>Acousto-optic modulation of gigawatt-scale laser pulses in ambient air; Yannick Schrödel, Claas Hartmann, Tino Lang, Jiaan Zheng, Max Steudel, Matthias Rutsch, Sarper H. Salman, Martin Kellert, Mikhail Pergament, Thomas Hahn-Jose, Sven Suppelt, Jan Helge Dörsam, Anne Harth, Wim P. Leemans, Franz X. Kärtner, Ingmar Hartl, Mario Kupnik, Christoph M. Heyl; <em>Nature Photonics</em>, 2023; DOI: <a href="https://dx.doi.org/10.1038/s41566-023-01304-y">10.1038/s41566-023-01304-y</a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why did the Motorola 68000 processor family fall out of use in PCs? (120 pts)]]></title>
            <link>https://retrocomputing.stackexchange.com/questions/27722/why-did-the-motorola-68000-processor-family-fall-out-of-use-in-personal-computer</link>
            <guid>37796292</guid>
            <pubDate>Fri, 06 Oct 2023 20:54:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://retrocomputing.stackexchange.com/questions/27722/why-did-the-motorola-68000-processor-family-fall-out-of-use-in-personal-computer">https://retrocomputing.stackexchange.com/questions/27722/why-did-the-motorola-68000-processor-family-fall-out-of-use-in-personal-computer</a>, See on <a href="https://news.ycombinator.com/item?id=37796292">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="mainbar" role="main" aria-label="question and answers">

                
<div data-questionid="27722" data-position-on-page="0" data-score="41" id="question">
        

        

<div>
    
    <div itemprop="text">
                
<p>In the '80s and '90s the Intel x86 and Motorola 68000 families were the two leading microcomputer architectures in the 16-bit/32-bit personal computer scene. The 68000s were even preferred by the purists because of its orthogonal instruction set. The Intel x86 family, although always the market leader, has been criticized for its non-orthogonal instruction set and segmented addressing.</p>
<p>When the Macintosh line switched to PowerPC, the Motorola 68000 family began to disappear as a contender for newly designed personal computers outside the “Wintel” ecosystem. New contenders, such as the PowerPC, ARM and MIPS, take the 68000 family’s place.</p>
<p>I cannot find on the internet the reason why the 68000 family fell out of favor in the personal computer market.</p>
<p>Can someone explain this or point me in the direction of the answer?</p>
    </div>

        

    <div>
            

                <div>
        <a href="https://retrocomputing.stackexchange.com/users/7946/toby-speight"><p><img src="https://i.stack.imgur.com/acYd0.png?s=64&amp;g=1" alt="Toby Speight's user avatar" width="32" height="32"></p></a>
    </div>
            <div>
    <p>
        asked <span title="2023-09-25 02:30:51Z">Sep 25 at 2:30</span>
    </p>
    <div>
        <a href="https://retrocomputing.stackexchange.com/users/8047/biff-iam"><p><img src="https://graph.facebook.com/10153952907388852/picture?type=large" alt="Biff Iam's user avatar" width="32" height="32"></p></a>
    </div>
    
</div>
        </div>
    
</div>




            <p><span itemprop="commentCount">19</span></p>
    </div>



                
                
                <div id="answers">
                    


                                    
<div id="answer-27724" data-answerid="27724" data-parentid="27722" data-score="35" data-position-on-page="1" data-highest-scored="0" data-question-has-accepted-highest-score="0" itemprop="acceptedAnswer" itemscope="" itemtype="https://schema.org/Answer">
        

        

<div>
    
    <div itemprop="text">
<p>The <a href="https://en.wikipedia.org/wiki/AIM_alliance" rel="noreferrer">Apple-IBM-Motorola alliance</a> was created in 1991 to compete with the Windows/Intel market. Its main successes were the creation of the PowerPC instruction set, derived from IBM's POWER architecture, and Apple's Power Macintosh line of computers.</p>
<p>IBM originated the idea, having seen that Windows on Intel was out-competing OS/2, and wanting to avoid being dependent on Intel. Apple joined it, seeing the chance to grow out of their existing markets, and Motorola presumably saw it as a successor to 68000, having failed comprehensively with the <a href="https://en.wikipedia.org/wiki/Motorola_88000" rel="noreferrer">MC88000</a>.</p>
<p>While the 68000 was used in the Macintosh series, Atari STs and Amigas, all the operating systems involved were quite different, so there was no unified software base. That meant there wasn't the sustained demand for 68000 that could have paid for chip development on the scale required to keep it competitive with x86. The engineering workstation market had started with the 68000, but had already switched to RISC before AIM was created.</p>
    </div>
    <div>
    <p>
        answered <span title="2023-09-25 06:36:35Z">Sep 25 at 6:36</span>
    </p>
    <div>
        <a href="https://retrocomputing.stackexchange.com/users/3481/john-dallman"><p><img src="https://www.gravatar.com/avatar/fa5764b5ee7afe97b5a925b24c4fa229?s=64&amp;d=identicon&amp;r=PG&amp;f=y&amp;so-version=2" alt="John Dallman's user avatar" width="32" height="32"></p></a>
    </div>
    <div itemprop="author" itemscope="" itemtype="http://schema.org/Person">
        <p><a href="https://retrocomputing.stackexchange.com/users/3481/john-dallman">John Dallman</a><span itemprop="name">John Dallman</span></p><p><span title="reputation score 11,427" dir="ltr">11.4k</span><span>2 gold badges</span><span>38 silver badges</span><span>52 bronze badges</span>
        </p>
    </div>
</div>
    
</div>




            <p><span itemprop="commentCount">4</span></p>
    </div>


                                    
<div id="answer-27727" data-answerid="27727" data-parentid="27722" data-score="47" data-position-on-page="2" data-highest-scored="1" data-question-has-accepted-highest-score="0" itemprop="suggestedAnswer" itemscope="" itemtype="https://schema.org/Answer">
        

        

<div>
    
    <div itemprop="text">
<p>The 68k family instruction set, as elegant as it appeared to the casual assembler programmer (been there), had several flaws that made it very difficult to get fast in hardware. Out of order or superscalar execution were very, very difficult to implement.</p>
<ul>
<li>Over-complex addressing modes, especially the indirect one introduced with 68020: when combined with virtual memory made it theoretical possible to get up to 16 page faults in 1 instruction (move long indirect with displacement and shifted index from an odd address touching 2 pages etc.). These indirect addressing modes were the first to be removed when defining the Coldfire ISA.</li>
<li>Exposure of the pipeline internals on traps and exceptions: the idea was that on a trap, the instruction could be resumed after fixing the error cause. This made it very difficult to get performance out of the kernel as it wrote more and more data to the stack at each generation, and it also limited the internal state that could be saved. x86 was much more pragmatic and just restarted the cancelled instruction from start.</li>
<li>Compatibility between successive family members was not as good as in intel CPUs. If you want to compile a program that runs on 68000 and on any of 680[2346]0 you will lose a lot of features on the side.</li>
</ul>
<p>There is the famous <a href="https://userpages.umbc.edu/%7Evijay/mashey.on.risc.html" rel="noreferrer">newsgroup post from John Mashey</a> explaining the fundamental issue with the 68k ISA in comparison to other ISAs of that time.</p>
    </div>
    <div>
    <p>
        answered <span title="2023-09-25 08:25:00Z">Sep 25 at 8:25</span>
    </p>
    <div>
        <a href="https://retrocomputing.stackexchange.com/users/7095/patrick-schl%c3%bcter"><p><img src="https://www.gravatar.com/avatar/5b36bf29056af38269b2147d5c36b94e?s=64&amp;d=identicon&amp;r=PG" alt="Patrick Schlüter's user avatar" width="32" height="32"></p></a>
    </div>
    <div itemprop="author" itemscope="" itemtype="http://schema.org/Person">
        <p><a href="https://retrocomputing.stackexchange.com/users/7095/patrick-schl%c3%bcter">Patrick Schlüter</a><span itemprop="name">Patrick Schlüter</span></p><p><span title="reputation score " dir="ltr">3,319</span><span>1 gold badge</span><span>12 silver badges</span><span>17 bronze badges</span>
        </p>
    </div>
</div>
    
</div>




            <p><span itemprop="commentCount">8</span></p>
    </div>

                                    
<div id="answer-27726" data-answerid="27726" data-parentid="27722" data-score="16" data-position-on-page="3" data-highest-scored="0" data-question-has-accepted-highest-score="0" itemprop="suggestedAnswer" itemscope="" itemtype="https://schema.org/Answer">
        

        

<div>
    
    <div itemprop="text">
<p>Motorola stopped investing in MC68000 family when everyone thought that RISC was the future and that CISC CPUs would be soon non competitive. So it switched to PowerPCs.</p>
<p>Even Intel thought this and developed RISC CPUs (i860, i960...). Intel reluctantly continued investing in x86.</p>
<p>For Motorola, it was probably true, the last version, MC68060 was competitive with Pentium but it was quickly surpassed because of Intel manufacturing superiority allowing lower dissipation, higher frequencies. Switching to simpler RISC CPUs could allow to stay in the race.</p>
<p>Now, the difference between RISC and CISC (eg x86) is less relevant performance-wise due to the possibility of putting 100 times more transistors on a die.</p>
    </div>
    <div>
            
            <div>
        <a href="https://retrocomputing.stackexchange.com/users/7095/patrick-schl%c3%bcter"><p><img src="https://www.gravatar.com/avatar/5b36bf29056af38269b2147d5c36b94e?s=64&amp;d=identicon&amp;r=PG" alt="Patrick Schlüter's user avatar" width="32" height="32"></p></a>
    </div>


            <div>
    <p>
        answered <span title="2023-09-25 07:22:32Z">Sep 25 at 7:22</span>
    </p>
    <div>
        <a href="https://retrocomputing.stackexchange.com/users/1958/temlib"><p><img src="https://i.stack.imgur.com/JeK6w.png?s=64&amp;g=1" alt="TEMLIB's user avatar" width="32" height="32"></p></a>
    </div>
    <div itemprop="author" itemscope="" itemtype="http://schema.org/Person">
        <p><a href="https://retrocomputing.stackexchange.com/users/1958/temlib">TEMLIB</a><span itemprop="name">TEMLIB</span></p><p><span title="reputation score " dir="ltr">3,417</span><span>16 silver badges</span><span>18 bronze badges</span>
        </p>
    </div>
</div>
        </div>
    
</div>




            <p><span itemprop="commentCount">4</span></p>
    </div>


                                    
<div id="answer-27725" data-answerid="27725" data-parentid="27722" data-score="10" data-position-on-page="4" data-highest-scored="0" data-question-has-accepted-highest-score="0" itemprop="suggestedAnswer" itemscope="" itemtype="https://schema.org/Answer">
        

        

<div>
    
    <div itemprop="text">
<blockquote>
<p>When the Macintosh line switched to Power PC, the Motorola 68000 family begun to disappear</p>
</blockquote>
<p>It's been rather the other way around. Apple switching was a result of Motorola losing the race.</p>
<blockquote>
<p>New contenders, such as the Power PC, ARM and MIPS take the 68000 family’s place.</p>
</blockquote>
<p>Not really - also you forget the NS32k family going away at the same time, being maybe less visible but at least as successful as the 68k.</p>
<blockquote>
<p>I cannot find in the internet the reason why the 68000 family fell out of favor in the personal computer market.</p>
</blockquote>
<p>Cost on either side:</p>
<ul>
<li>Motorola wasn't able to keep up investment to improve their CPUs the same way that Intel did</li>
<li>Resulting CPUs were considerably more expensive than Intel's offering.</li>
</ul>
<p>This is not only true at upper end offerings with '060 vs. Pentium but even more for embedded. Basic 80(1)88 based systems could be delivered at considerable lower development and production cost.</p>
    </div>
    <div>
            
            <div>
    
    <div>
        <a href="https://retrocomputing.stackexchange.com/users/576/lorraine"><p><img src="https://i.stack.imgur.com/RZLo7.png?s=64&amp;g=1" alt="Lorraine's user avatar" width="32" height="32"></p></a>
    </div>
    <div>
        <p><a href="https://retrocomputing.stackexchange.com/users/576/lorraine">Lorraine</a></p><p><span title="reputation score 38,038" dir="ltr">38k</span><span>11 gold badges</span><span>131 silver badges</span><span>270 bronze badges</span>
        </p>
    </div>
</div>


            <div>
    <p>
        answered <span title="2023-09-25 06:45:20Z">Sep 25 at 6:45</span>
    </p>
    <div>
        <a href="https://retrocomputing.stackexchange.com/users/6659/raffzahn"><p><img src="https://lh3.googleusercontent.com/-yspgfz81fFw/AAAAAAAAAAI/AAAAAAAAD5o/7CFgAMaSHSE/photo.jpg?sz=64" alt="Raffzahn's user avatar" width="32" height="32"></p></a>
    </div>
    <div itemprop="author" itemscope="" itemtype="http://schema.org/Person">
        <p><a href="https://retrocomputing.stackexchange.com/users/6659/raffzahn">Raffzahn</a><span itemprop="name">Raffzahn</span></p><p><span title="reputation score 208,875" dir="ltr">209k</span><span>21 gold badges</span><span>586 silver badges</span><span>862 bronze badges</span>
        </p>
    </div>
</div>
        </div>
    
</div>




            <p><span itemprop="commentCount">5</span></p>
    </div>

                                    
<div id="answer-27737" data-answerid="27737" data-parentid="27722" data-score="8" data-position-on-page="5" data-highest-scored="0" data-question-has-accepted-highest-score="0" itemprop="suggestedAnswer" itemscope="" itemtype="https://schema.org/Answer">
    
    <p>Motorola lost the race to 32 bit computing from a simple engineering mistake.
In the era when the 68k and x86 were very popular, the shift to 32 bit CPUs was a race to mass production. No question the 68020 was a cleaner design and almost destined to be the no. 1 choice for new machines. Friends of mine paid around $400 at the time for early 68020 chips to build test boards. X86 at the time was hopelessly behind. BUT, the first iteration of the 68020 had pushed the design parameters of the chip process to the point that yields were appalling. Every chip sold at a loss. Motorola then had to redesign all the masks which was an 18 month engineering exercise. 18 months was the window that let x86 get ahead in the market and that was the end of the 68k family's dominance. Shame</p>
    <div>
    <p>
        answered <span title="2023-09-26 11:29:50Z">Sep 26 at 11:29</span>
    </p>
    <div>
        <a href="https://retrocomputing.stackexchange.com/users/28249/alex-danilo"><p><img src="https://www.gravatar.com/avatar/a0a488cb658854d129ec3c2e9c27bb1e?s=64&amp;d=identicon&amp;r=PG" alt="Alex Danilo's user avatar" width="32" height="32"></p></a>
    </div>
    
</div>
    
</div>

                                    
<div id="answer-27723" data-answerid="27723" data-parentid="27722" data-score="6" data-position-on-page="6" data-highest-scored="0" data-question-has-accepted-highest-score="0" itemprop="suggestedAnswer" itemscope="" itemtype="https://schema.org/Answer">
    
    <p>The 68000 was a joy to program (compared to the segmented memory Intel x86), but it simply didn't keep up in the clocking race.</p>
    <div>
    <p>
        answered <span title="2023-09-25 02:50:05Z">Sep 25 at 2:50</span>
    </p>
    <div>
        <a href="https://retrocomputing.stackexchange.com/users/27579/ubfan1"><p><img src="https://www.gravatar.com/avatar/499ad6b4324afc463ebfcff47450a85e?s=64&amp;d=identicon&amp;r=PG" alt="ubfan1's user avatar" width="32" height="32"></p></a>
    </div>
    
</div>
    
</div>

                                    
<div id="answer-27753" data-answerid="27753" data-parentid="27722" data-score="3" data-position-on-page="7" data-highest-scored="0" data-question-has-accepted-highest-score="0" itemprop="suggestedAnswer" itemscope="" itemtype="https://schema.org/Answer">
        

        

<div>
    
    <div itemprop="text">
<p>This was purely economics. By about 1988 the ready availability of IBM AT clones had the effect of pushing the price of support hardware- including cases, discs etc.- down enormously, and even on the '286 there were UNIX variants that demonstrated that such things were possible. The '386, when introduced, exploited that, and from that point onwards it became a race between what Intel- with a growing income- and Motorola et al.- with static incomes- could do with the available semiconductor technology.</p>
<p>By about 1995 Intel's price/performance ratio was unassailable, and graphics accelerators which could operate in conjunction with PC hardware were starting to erode the market for specialist workstations.</p>
    </div>
    <div>
    <p>
        answered <span title="2023-09-27 10:39:16Z">Sep 27 at 10:39</span>
    </p>
    <div>
        <a href="https://retrocomputing.stackexchange.com/users/18835/mark-morgan-lloyd"><p><img src="https://www.gravatar.com/avatar/4d46055b400959f30cdfae3541924714?s=64&amp;d=identicon&amp;r=PG&amp;f=y&amp;so-version=2" alt="Mark Morgan Lloyd's user avatar" width="32" height="32"></p></a>
    </div>
    
</div>
    
</div>




            <p><span itemprop="commentCount">1</span></p>
    </div>

                                <h2>
                                    You must <a href="https://retrocomputing.stackexchange.com/users/login?ssrc=question_page&amp;returnurl=https%3a%2f%2fretrocomputing.stackexchange.com%2fquestions%2f27722">log in</a> to answer this question.
                                </h2>



                            <h2 data-loc="1">
                                <div><p>
Not the answer you're looking for? Browse other questions tagged </p><p>.                                </p></div>
                            </h2>
                </div>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[23andMe scraping incident leaked data on 1.3M users (154 pts)]]></title>
            <link>https://therecord.media/scraping-incident-genetic-testing-site</link>
            <guid>37795652</guid>
            <pubDate>Fri, 06 Oct 2023 20:08:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://therecord.media/scraping-incident-genetic-testing-site">https://therecord.media/scraping-incident-genetic-testing-site</a>, See on <a href="https://news.ycombinator.com/item?id=37795652">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Genetic testing giant 23andMe confirmed that a data scraping incident resulted in hackers gaining access to sensitive user information and selling it on the dark web.</p>
<p>The information of nearly 7 million 23andMe users was <a href="https://twitter.com/DarkWebInformer/status/1709348139793068069">offered</a> for sale on a cybercriminal forum this week. The information included origin estimation, phenotype, health information, photos, identification data and more. 23andMe processes saliva samples submitted by customers to determine their ancestry.</p>
<p>When asked about the post, the company initially denied that the information was legitimate, calling it a “misleading claim” in a statement to Recorded Future News.</p>
<p>The company later said it was aware that certain 23andMe customer profile information was compiled through unauthorized access to individual accounts that were signed up for the DNA Relative feature — which allows users to opt in for the company to show them potential matches for relatives.</p>
<p>“We do not have any indication at this time that there has been a data security incident within our systems. Rather, the preliminary results of this investigation suggest that the login credentials used in these access attempts may have been gathered by a threat actor from data leaked during incidents involving other online platforms where users have recycled login credentials,” they said.</p>
<p>“We believe that the threat actor may have then, in violation of our terms of service, accessed 23andme.com accounts without authorization and obtained information from those accounts. We are taking this issue seriously and will continue our investigation to confirm these preliminary results.”</p>
<p><img src="https://cms.therecord.media/uploads/Breach_Forums_ace4be7d97.jpg" alt="BreachForums.jpg">
<em>A screenshot from the posting of 23andMe data on the BreachForums site.</em></p>
<p>When pressed on how compromising a handful of user accounts would give someone access to millions of users, the spokesperson said the company does not believe the threat actor had access to all of the accounts but rather gained unauthorized entry to a much smaller number of 23andMe accounts and scraped data from their DNA Relative matches.</p>
<p>The spokesperson declined to confirm the specific number of customer accounts affected.</p>
<p>Anyone who has opted into DNA Relatives can view basic profile information of others who make their profiles visible to DNA Relative participants, a spokesperson said.</p>
<p>Users who are genetically related can access ancestry information, which is made clear to users when they create their DNA Relatives profile, the spokesperson added.</p>
<p>Once the company has more information from the investigation, they said, it will determine the best approach to notifying any impacted customers.</p>
<h2>‘A botch job’</h2>
<p>The incident shows how a company's customer data can be vulnerable even if intruders don't get deep into its network.</p>
<p>A researcher approached Recorded Future News after examining the leaked database and found that much of it looked real. The researcher spoke on condition of anonymity because he found the information of his wife and several of her family members in the leaked data set. He also found other acquaintances and verified that their information was accurate.</p>
<p>The researcher downloaded two files from the BreachForums post and found that one had information on 1 million 23andMe users of Ashkenazi heritage. The other file included data on more than 300,000 users of Chinese heritage.</p>
<p>The data included profile and account ID numbers, names, gender, birth year, maternal and paternal genetic markers, ancestral heritage results, and data on whether or not each user has opted into 23andme’s health data.</p>
<p>“It appears the information has been scraped from user profiles which are only supposed to be shared between DNA Matches. So although this particular leak does not contain genomic sequencing data, it’s still data that should not be available to the public,” the researcher said.</p>
<p>“23andme seems to think this isn’t a big deal. They keep telling me that if I don’t want this info to be shared, I should not opt into the DNA relatives feature. But that’s dismissing the importance of this data which should only be viewable to DNA relatives, not the public. And the fact that someone was able to scrape this data from 1.3 million users is concerning. The hacker allegedly has more data that they have not released yet.”</p>
<p>The researcher added that he discovered another issue where someone could enter a 23andme profile ID, like the ones included in the leaked data set, into their URL and see someone’s profile.</p>
<p>The data available through this only includes profile photos, names, birth years and location but does not include test results.</p>
<p>“It’s very concerning that 23andme has such a big loophole in their website design and security where they are just freely exposing peoples info just by typing a profile ID into the URL. Especially for a website that deals with people's genetic data and personal information. What a botch job by the company,” the researcher said.</p>
<p>“I’ve tried contacting 23andme however they keep denying that there is anything wrong and are replying with cookie cutter responses. I don’t know how to prove this without doxing myself. But this is pretty serious and no one is taking it seriously.”</p>
<p>The security policies of genetic testing companies like 23andMe have faced scrutiny from regulators in recent weeks. Three weeks ago, genetic testing firm 1Health.io <a href="https://therecord.media/genetic-testing-firm-fined-ftc-privacy">agreed to pay the Federal Trade Commission (FTC) a $75,000 fine</a> to resolve allegations that it failed to secure sensitive genetic and health data, retroactively overhauled its privacy policy without notifying and obtaining consent from customers whose data it had obtained, and tricked customers about their ability to delete their data.</p><div><div><p>Get more insights with the </p><p>Recorded Future</p><p>Intelligence Cloud.</p></div><p><a target="_blank" rel="noopener noreferrer" href="https://www.recordedfuture.com/platform?mtm_campaign=ad-unit-record">Learn more.</a></p></div><div><p><span>Tags</span></p><ul><li><a href="https://therecord.media/tag/genetic-testing">genetic testing</a></li><li><a href="https://therecord.media/tag/privacy">Privacy</a></li><li><a href="https://therecord.media/tag/data-breach">Data breach</a></li><li><a href="https://therecord.media/tag/dark-web">dark web</a></li><li><a href="https://therecord.media/tag/scraping">scraping</a></li></ul></div><div><p><span>No previous article</span></p><p><span>No new articles</span></p></div><div><a href="https://therecord.media/author/jonathan-greig"><h2>Jonathan Greig</h2></a><p><a href="https://therecord.media/author/jonathan-greig"><span><img sizes="100vw" srcset="https://cms.therecord.media/uploads/DSC_0283_1_a6f4e4e315.jpg?w=640 640w, https://cms.therecord.media/uploads/DSC_0283_1_a6f4e4e315.jpg?w=750 750w, https://cms.therecord.media/uploads/DSC_0283_1_a6f4e4e315.jpg?w=828 828w, https://cms.therecord.media/uploads/DSC_0283_1_a6f4e4e315.jpg?w=1080 1080w, https://cms.therecord.media/uploads/DSC_0283_1_a6f4e4e315.jpg?w=1200 1200w, https://cms.therecord.media/uploads/DSC_0283_1_a6f4e4e315.jpg?w=1920 1920w, https://cms.therecord.media/uploads/DSC_0283_1_a6f4e4e315.jpg?w=2048 2048w, https://cms.therecord.media/uploads/DSC_0283_1_a6f4e4e315.jpg?w=3840 3840w" src="https://cms.therecord.media/uploads/DSC_0283_1_a6f4e4e315.jpg?w=3840" decoding="async" data-nimg="fill"></span></a></p><p>Jonathan Greig is a Breaking News Reporter at Recorded Future News. Jonathan has worked across the globe as a journalist since 2014. Before moving back to New York City, he worked for news outlets in South Africa, Jordan and Cambodia. He previously covered cybersecurity at ZDNet and TechRepublic.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A 20MP Sensor in a Film Canister Reinvigorates Vintage Analog Cameras (104 pts)]]></title>
            <link>https://petapixel.com/2023/10/06/a-20mp-sensor-in-a-film-canister-reinvigorates-vintage-analog-cameras/</link>
            <guid>37795278</guid>
            <pubDate>Fri, 06 Oct 2023 19:40:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://petapixel.com/2023/10/06/a-20mp-sensor-in-a-film-canister-reinvigorates-vintage-analog-cameras/">https://petapixel.com/2023/10/06/a-20mp-sensor-in-a-film-canister-reinvigorates-vintage-analog-cameras/</a>, See on <a href="https://news.ycombinator.com/item?id=37795278">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p><img data-perfmatters-preload="" decoding="async" fetchpriority="high" src="https://petapixel.com/assets/uploads/2023/10/Screenshot-2023-10-06-at-13.45.56-800x420.jpg" alt="I'm Back Film" width="800" height="420" srcset="https://petapixel.com/assets/uploads/2023/10/Screenshot-2023-10-06-at-13.45.56-800x420.jpg 800w, https://petapixel.com/assets/uploads/2023/10/Screenshot-2023-10-06-at-13.45.56-320x168.jpg 320w, https://petapixel.com/assets/uploads/2023/10/Screenshot-2023-10-06-at-13.45.56-1536x806.jpg 1536w, https://petapixel.com/assets/uploads/2023/10/Screenshot-2023-10-06-at-13.45.56-150x79.jpg 150w, https://petapixel.com/assets/uploads/2023/10/Screenshot-2023-10-06-at-13.45.56-300x157.jpg 300w, https://petapixel.com/assets/uploads/2023/10/Screenshot-2023-10-06-at-13.45.56-400x209.jpg 400w, https://petapixel.com/assets/uploads/2023/10/Screenshot-2023-10-06-at-13.45.56-550x288.jpg 550w, https://petapixel.com/assets/uploads/2023/10/Screenshot-2023-10-06-at-13.45.56.jpg 1600w" sizes="(max-width: 800px) 100vw, 800px"></p> <p><a href="https://imback.eu/home/" data-wpel-link="external" target="_blank" rel="follow external noopener">I’m Back Film</a> is a fascinating product that makes the dream of “digital film” a reality. I’m Back is the first digital film roll and relies upon a 20-megapixel Sony Micro Four Thirds image sensor tucked away inside a film roll canister. </p>  <p>“‘I’m Back’ represents a second chance for old analog cameras that were relegated to obscurity (I’m referring to the millions that went unused, not the ones still cherished by analog enthusiasts). With our incredible ability to transform these relics into modern digital devices, we’re writing a new chapter in the history of photography,” writes I’m Back. </p> <div><p><iframe src="https://www.youtube.com/embed/ZrKFGIRYUsg?si=FfYGPdpEkFO9hlwS" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe></p></div> <p>The I’m Back Film’s 20-megapixel Four-Thirds sensor can work alongside a wide-angle adapter to ensure the smaller-than-full-frame sensor covers a whole 35mm-format image area. Or users can take advantage of the crop factor enabled by a Micro Four Thirds sensor (2x crop factor compared to a full-frame image sensor). </p> <p>As for why I’m Back Film uses a Micro Four Thirds sensor instead of a full-frame sensor, the team behind the product says it comes down to cost. A Four-Thirds sensor offers “excellent image quality at a more affordable cost compared to a full-frame sensor.” Further, as mentioned, when combined with a wide-angle lens filter, users can achieve the same field of view on their lens as they would have when using a 35mm camera sensor. </p> <p><img decoding="async" src="https://petapixel.com/assets/uploads/2023/10/Screenshot-2023-10-06-at-13.46.11-800x536.jpg" alt="I'm Back Film" width="800" height="536" srcset="https://petapixel.com/assets/uploads/2023/10/Screenshot-2023-10-06-at-13.46.11-800x536.jpg 800w, https://petapixel.com/assets/uploads/2023/10/Screenshot-2023-10-06-at-13.46.11-320x214.jpg 320w, https://petapixel.com/assets/uploads/2023/10/Screenshot-2023-10-06-at-13.46.11-1536x1028.jpg 1536w, https://petapixel.com/assets/uploads/2023/10/Screenshot-2023-10-06-at-13.46.11-300x200.jpg 300w, https://petapixel.com/assets/uploads/2023/10/Screenshot-2023-10-06-at-13.46.11-120x80.jpg 120w, https://petapixel.com/assets/uploads/2023/10/Screenshot-2023-10-06-at-13.46.11.jpg 1600w" sizes="(max-width: 800px) 100vw, 800px"></p>
<p>The device captures digital images to an SD memory card. It also includes Wi-Fi connectivity, allowing photographers to connect their smartphone to I’m Back Film and instantly grab photos to post on social media. </p> <p><img decoding="async" loading="lazy" src="https://petapixel.com/assets/uploads/2023/10/Screenshot-2023-10-06-at-13.46.02-800x453.jpg" alt="I'm Back Film" width="800" height="453" srcset="https://petapixel.com/assets/uploads/2023/10/Screenshot-2023-10-06-at-13.46.02-800x453.jpg 800w, https://petapixel.com/assets/uploads/2023/10/Screenshot-2023-10-06-at-13.46.02-320x181.jpg 320w, https://petapixel.com/assets/uploads/2023/10/Screenshot-2023-10-06-at-13.46.02-1536x870.jpg 1536w, https://petapixel.com/assets/uploads/2023/10/Screenshot-2023-10-06-at-13.46.02.jpg 1600w" sizes="(max-width: 800px) 100vw, 800px"></p> <p>It is fair to wonder, the ingenuity of the product aside, what it offers to photographers. “Currently, the world of photography has mainly seen new lens releases and improvements to existing digital cameras. However, ‘I’m Back Film’ offers something truly unique. It allows photographers to revisit their old analog cameras, many of which are gathering dust on shelves. This not only opens up new creative possibilities but also helps preserve the history of photography,” writes I’m Back. </p> <p>The company also thinks photography is experiencing a “creativity crisis,” wherein photographers often repeat the same techniques and styles. I’m Back Film aims to reinvigorate photographers and inspire fresh approaches and creative imagery. It also hopes to encourage more experimentation. </p> <p><img decoding="async" loading="lazy" src="https://petapixel.com/assets/uploads/2023/10/Screenshot-2023-10-06-at-13.45.39-800x213.jpg" alt="I'm Back Film" width="800" height="213" srcset="https://petapixel.com/assets/uploads/2023/10/Screenshot-2023-10-06-at-13.45.39-800x213.jpg 800w, https://petapixel.com/assets/uploads/2023/10/Screenshot-2023-10-06-at-13.45.39-320x85.jpg 320w, https://petapixel.com/assets/uploads/2023/10/Screenshot-2023-10-06-at-13.45.39-1536x408.jpg 1536w, https://petapixel.com/assets/uploads/2023/10/Screenshot-2023-10-06-at-13.45.39.jpg 1600w" sizes="(max-width: 800px) 100vw, 800px"></p> <p>The Sony IMX 269 sensor is paired with an NT9853 processor and a 1.5-inch LCD. The sensor can also record 4K UHD video at up to 60 frames per second. The device includes RAW and JPEG image capture and features various black-and-white and color presets, including ones inspired by Kodachrome and Fujifilm. </p> <p><img decoding="async" loading="lazy" src="https://petapixel.com/assets/uploads/2023/10/Screenshot-2023-10-06-at-13.46.45-800x516.jpg" alt="I'm Back Film" width="800" height="516" srcset="https://petapixel.com/assets/uploads/2023/10/Screenshot-2023-10-06-at-13.46.45-800x516.jpg 800w, https://petapixel.com/assets/uploads/2023/10/Screenshot-2023-10-06-at-13.46.45-320x206.jpg 320w, https://petapixel.com/assets/uploads/2023/10/Screenshot-2023-10-06-at-13.46.45-1536x991.jpg 1536w, https://petapixel.com/assets/uploads/2023/10/Screenshot-2023-10-06-at-13.46.45.jpg 1600w" sizes="(max-width: 800px) 100vw, 800px"></p>
<p>With I’m Back Film, users no longer need to choose between analog or digital. Using I’m Back Film does not require modifying existing analog cameras, ensuring that vintage gear is preserved. The product has been created by I’m Back CEO Samuel Mello Medeiros, and the team includes co-founder Filippo Nishino, shipping manager Monique Medeiros, and administrative manager Yasmin Nishino. </p> <p><img decoding="async" loading="lazy" src="https://petapixel.com/assets/uploads/2023/10/Screenshot-2023-10-06-at-13.45.21-800x479.jpg" alt="I'm Back Film" width="800" height="479" srcset="https://petapixel.com/assets/uploads/2023/10/Screenshot-2023-10-06-at-13.45.21-800x479.jpg 800w, https://petapixel.com/assets/uploads/2023/10/Screenshot-2023-10-06-at-13.45.21-320x191.jpg 320w, https://petapixel.com/assets/uploads/2023/10/Screenshot-2023-10-06-at-13.45.21-1536x919.jpg 1536w, https://petapixel.com/assets/uploads/2023/10/Screenshot-2023-10-06-at-13.45.21.jpg 1600w" sizes="(max-width: 800px) 100vw, 800px"></p> <p>I’m Back Film will be launching soon on Kickstarter. Photographers can <a href="https://www.kickstarter.com/projects/samellos/im-back-film?ref=6vto0i" data-wpel-link="external" target="_blank" rel="follow external noopener">sign up to be notified</a> when the campaign goes live, which is expected to commence next week. </p> <p><img decoding="async" loading="lazy" src="https://petapixel.com/assets/uploads/2023/10/Screenshot-2023-10-06-at-13.46.22-800x171.jpg" alt="I'm Back Film" width="800" height="171" srcset="https://petapixel.com/assets/uploads/2023/10/Screenshot-2023-10-06-at-13.46.22-800x171.jpg 800w, https://petapixel.com/assets/uploads/2023/10/Screenshot-2023-10-06-at-13.46.22-320x68.jpg 320w, https://petapixel.com/assets/uploads/2023/10/Screenshot-2023-10-06-at-13.46.22-1536x327.jpg 1536w, https://petapixel.com/assets/uploads/2023/10/Screenshot-2023-10-06-at-13.46.22.jpg 1600w" sizes="(max-width: 800px) 100vw, 800px"></p> <p>If the “I’m Back” name sounds familiar, it is because it is not the company’s first foray onto Kickstarter. The name “I’m Back” makes sense in multiple ways. The company was last on the crowdfunding platform with a <a href="https://petapixel.com/2020/04/13/the-im-back-35-lets-you-add-a-digital-sensor-to-your-old-film-camera/" data-wpel-link="internal">similar product</a> for 35mm cameras, although that version was significantly larger and utilized a smaller 14-megapixel image sensor. It also required photographers to remove the back of a film camera and did not include a canister-style attachment. The spirit of previous I’m Back devices lives on in the upcoming I’m Back Film, but the new iteration capitalizes on the way that analog cameras work in a wholly different and cleverer way. </p> <hr> <p><em><strong>Image credits:</strong> I’m Back</em></p>  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Fail2Ban (145 pts)]]></title>
            <link>https://github.com/fail2ban/fail2ban</link>
            <guid>37795100</guid>
            <pubDate>Fri, 06 Oct 2023 19:26:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/fail2ban/fail2ban">https://github.com/fail2ban/fail2ban</a>, See on <a href="https://news.ycombinator.com/item?id=37795100">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><div data-snippet-clipboard-copy-content="                     __      _ _ ___ _               
                    / _|__ _(_) |_  ) |__  __ _ _ _  
                   |  _/ _` | | |/ /| '_ \/ _` | ' \ 
                   |_| \__,_|_|_/___|_.__/\__,_|_||_|
                   v1.1.0.dev1            20??/??/??"><pre><code>                     __      _ _ ___ _               
                    / _|__ _(_) |_  ) |__  __ _ _ _  
                   |  _/ _` | | |/ /| '_ \/ _` | ' \ 
                   |_| \__,_|_|_/___|_.__/\__,_|_||_|
                   v1.1.0.dev1            20??/??/??
</code></pre></div>
<h2 tabindex="-1" id="user-content-fail2ban-ban-hosts-that-cause-multiple-authentication-errors" dir="auto"><a href="#fail2ban-ban-hosts-that-cause-multiple-authentication-errors">Fail2Ban: ban hosts that cause multiple authentication errors</a></h2>
<p dir="auto">Fail2Ban scans log files like <code>/var/log/auth.log</code> and bans IP addresses conducting
too many failed login attempts. It does this by updating system firewall rules
to reject new connections from those IP addresses, for a configurable amount
of time. Fail2Ban comes out-of-the-box ready to read many standard log files,
such as those for sshd and Apache, and is easily configured to read any log
file of your choosing, for any error you wish.</p>
<p dir="auto">Though Fail2Ban is able to reduce the rate of incorrect authentication
attempts, it cannot eliminate the risk presented by weak authentication.
Set up services to use only two factor, or public/private authentication
mechanisms if you really want to protect services.</p>
<table>
<thead>
<tr>
<th><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/270c686a79697f1292054865b13732166001452000e7a02fc69081963a9c2166/687474703a2f2f7777772e776f726c64697076366c61756e63682e6f72672f77702d636f6e74656e742f7468656d65732f697076362f646f776e6c6f6164732f576f726c645f495076365f6c61756e63685f6c6f676f2e737667"><img src="https://camo.githubusercontent.com/270c686a79697f1292054865b13732166001452000e7a02fc69081963a9c2166/687474703a2f2f7777772e776f726c64697076366c61756e63682e6f72672f77702d636f6e74656e742f7468656d65732f697076362f646f776e6c6f6164732f576f726c645f495076365f6c61756e63685f6c6f676f2e737667" height="52pt" data-canonical-src="http://www.worldipv6launch.org/wp-content/themes/ipv6/downloads/World_IPv6_launch_logo.svg"></a></th>
<th>Since v0.10 fail2ban supports the matching of IPv6 addresses.</th>
</tr>
</thead>
</table>
<p dir="auto">This README is a quick introduction to Fail2Ban. More documentation, FAQ, and HOWTOs
to be found on fail2ban(1) manpage, <a href="https://github.com/fail2ban/fail2ban/wiki">Wiki</a>,
<a href="https://fail2ban.readthedocs.io/" rel="nofollow">Developers documentation</a>
and the website: <a href="https://www.fail2ban.org/" rel="nofollow">https://www.fail2ban.org</a></p>
<h2 tabindex="-1" id="user-content-installation" dir="auto"><a href="#installation">Installation:</a></h2>
<p dir="auto">Fail2Ban is likely already packaged for your Linux distribution and <a href="https://github.com/fail2ban/fail2ban/wiki/How-to-install-fail2ban-packages">can installed with a simple command</a>.</p>
<p dir="auto">If your distribution is not listed, you can install from GitHub:</p>
<p dir="auto">Required:</p>
<ul dir="auto">
<li><a href="https://www.python.org/" rel="nofollow">Python &gt;= 3.5</a> or <a href="https://pypy.org/" rel="nofollow">PyPy3</a></li>
<li>python-setuptools, python-distutils (or python3-setuptools) for installation from source</li>
</ul>
<p dir="auto">Optional:</p>
<ul dir="auto">
<li><a href="https://github.com/seb-m/pyinotify">pyinotify &gt;= 0.8.3</a>, may require:
<ul dir="auto">
<li>Linux &gt;= 2.6.13</li>
</ul>
</li>
<li><a href="http://www.freedesktop.org/wiki/Software/systemd" rel="nofollow">systemd &gt;= 204</a> and python bindings:
<ul dir="auto">
<li><a href="https://www.freedesktop.org/software/systemd/python-systemd/index.html" rel="nofollow">python-systemd package</a></li>
</ul>
</li>
<li><a href="http://www.dnspython.org/" rel="nofollow">dnspython</a></li>
</ul>
<p dir="auto">To install:</p>
<div data-snippet-clipboard-copy-content="tar xvfj fail2ban-master.tar.bz2
cd fail2ban-master
sudo python setup.py install"><pre><code>tar xvfj fail2ban-master.tar.bz2
cd fail2ban-master
sudo python setup.py install
</code></pre></div>
<p dir="auto">Alternatively, you can clone the source from GitHub to a directory of Your choice, and do the install from there. Pick the correct branch, for example, master or 0.11</p>
<div data-snippet-clipboard-copy-content="git clone https://github.com/fail2ban/fail2ban.git
cd fail2ban
sudo python setup.py install "><pre><code>git clone https://github.com/fail2ban/fail2ban.git
cd fail2ban
sudo python setup.py install 
</code></pre></div>
<p dir="auto">This will install Fail2Ban into the python library directory. The executable
scripts are placed into <code>/usr/bin</code>, and configuration in <code>/etc/fail2ban</code>.</p>
<p dir="auto">Fail2Ban should be correctly installed now. Just type:</p>

<p dir="auto">to see if everything is alright. You should always use fail2ban-client and
never call fail2ban-server directly.
You can verify that you have the correct version installed with</p>

<p dir="auto">Please note that the system init/service script is not automatically installed.
To enable fail2ban as an automatic service, simply copy the script for your
distro from the <code>files</code> directory to <code>/etc/init.d</code>. Example (on a Debian-based
system):</p>
<div data-snippet-clipboard-copy-content="cp files/debian-initd /etc/init.d/fail2ban
update-rc.d fail2ban defaults
service fail2ban start"><pre><code>cp files/debian-initd /etc/init.d/fail2ban
update-rc.d fail2ban defaults
service fail2ban start
</code></pre></div>
<h2 tabindex="-1" id="user-content-configuration" dir="auto"><a href="#configuration">Configuration:</a></h2>
<p dir="auto">You can configure Fail2Ban using the files in <code>/etc/fail2ban</code>. It is possible to
configure the server using commands sent to it by <code>fail2ban-client</code>. The
available commands are described in the fail2ban-client(1) manpage.  Also see
fail2ban(1) and jail.conf(5)  manpages for further references.</p>
<h2 tabindex="-1" id="user-content-code-status" dir="auto"><a href="#code-status">Code status:</a></h2>
<ul dir="auto">
<li><a href="https://github.com/fail2ban/fail2ban/actions/workflows/main.yml"><img src="https://github.com/fail2ban/fail2ban/actions/workflows/main.yml/badge.svg" alt="CI"></a></li>
</ul>
<h2 tabindex="-1" id="user-content-contact" dir="auto"><a href="#contact">Contact:</a></h2>
<h3 tabindex="-1" id="user-content-bugs-feature-requests-discussions" dir="auto"><a href="#bugs-feature-requests-discussions">Bugs, feature requests, discussions?</a></h3>
<p dir="auto">See <a href="https://github.com/fail2ban/fail2ban/blob/master/CONTRIBUTING.md">CONTRIBUTING.md</a></p>
<h3 tabindex="-1" id="user-content-you-just-appreciate-this-program" dir="auto"><a href="#you-just-appreciate-this-program">You just appreciate this program:</a></h3>
<p dir="auto">Send kudos to the original author (<a href="mailto:cyril.jaquier@fail2ban.org">Cyril Jaquier</a>)
or <em>better</em> to the <a href="https://lists.sourceforge.net/lists/listinfo/fail2ban-users" rel="nofollow">mailing list</a>
since Fail2Ban is "community-driven" for years now.</p>
<h2 tabindex="-1" id="user-content-thanks" dir="auto"><a href="#thanks">Thanks:</a></h2>
<p dir="auto">See <a href="https://github.com/fail2ban/fail2ban/blob/master/THANKS">THANKS</a> file.</p>
<h2 tabindex="-1" id="user-content-license" dir="auto"><a href="#license">License:</a></h2>
<p dir="auto">Fail2Ban is free software; you can redistribute it and/or modify it under the
terms of the GNU General Public License as published by the Free Software
Foundation; either version 2 of the License, or (at your option) any later
version.</p>
<p dir="auto">Fail2Ban is distributed in the hope that it will be useful, but WITHOUT ANY
WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
PARTICULAR PURPOSE. See the GNU General Public License for more details.</p>
<p dir="auto">You should have received a copy of the GNU General Public License along with
Fail2Ban; if not, write to the Free Software Foundation, Inc., 51 Franklin
Street, Fifth Floor, Boston, MA 02110, USA</p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Chicago independently abolishes subminimum wage for tipped workers (120 pts)]]></title>
            <link>https://www.chicagotribune.com/politics/ct-chicago-council-votes-eliminate-lower-tipped-minimum-wage-20231006-xg5vpkqcxnfqhe5fqogxrpbcua-story.html</link>
            <guid>37794874</guid>
            <pubDate>Fri, 06 Oct 2023 19:08:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.chicagotribune.com/politics/ct-chicago-council-votes-eliminate-lower-tipped-minimum-wage-20231006-xg5vpkqcxnfqhe5fqogxrpbcua-story.html">https://www.chicagotribune.com/politics/ct-chicago-council-votes-eliminate-lower-tipped-minimum-wage-20231006-xg5vpkqcxnfqhe5fqogxrpbcua-story.html</a>, See on <a href="https://news.ycombinator.com/item?id=37794874">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><p>Chicago on Friday became the largest American city to independently<i> </i>require that tipped employees make a full minimum wage, following a relatively easy City Council vote that delivered one of Mayor Brandon Johnson’s biggest political wins for his progressive agenda.</p><p>In a 36-10 vote, aldermen approved the measure that advocates said was direly needed for the lowest-paid service workers and that opponents countered would backfire, causing some employees in the service industry to be paid less and lead<b> </b>to higher menu prices and staff cuts. The ordinance becomes law immediately but the full impact won’t take effect for five years.</p><p><span>[&nbsp;</span><a href="https://www.chicagotribune.com/politics/ct-tipped-worker-wage-increase-committee-vote-chicago-20230920-fc5sonq365cntibvuzwkbfeinm-story.html#nt=interstitial-manual" aria-label="Open related story">Proposal to raise Chicago’s minimum wage for tipped workers advances in City Council</a><span>&nbsp;]</span></p><p>The Friday vote was originally supposed to take place Wednesday, but a clerical error delayed the meeting. Starting next July, the gap between tipped and minimum wages will shrink from 60% to 40%. Each year after, that gap will shrink by 8% until parity is reached by July 1, 2028.</p><p>Los Angeles, which has a larger population than Chicago, already bans a subminimum wage for tipped workers but that’s under a California state law that requires employers to pay those employees the full minimum wage. Besides California, Alaska, Minnesota, Montana, Nevada, Oregon and Washington also have abolished the lower tipped wage, <a href="https://www.dol.gov/agencies/whd/state/minimum-wage/tipped">according</a> to the U.S. Department of Labor.</p><p>In a celebratory post-council news conference, Johnson said the vote made Friday an “incredible historic day.”</p><p>”The ordinance embodies Chicago’s values of uplifting working people and addressing systemic inequities in the restaurant and hospitality industry, which, in turn, will create a better economic future for tipped workers and our city,” the mayor said. “Many of the people who are standing in support with us today, these are heads of households and anchors of communities who are finally receiving a bit more of the respect and dignity that they deserve.”</p><p>Ahead of the vote, progressive aldermen stood up and shared anecdotes that fueled their decision to favor the new law on what they described as a poignant day.<b> </b>Ald. Jessie Fuentes, 26th, one of the measure’s lead sponsors, said the subminimum wage for tipped employees has long been a driver of income inequality.</p><p>She pointed to the sea of pink-clad service workers behind her who were recruited by the national One Fair Wage campaign to cheer on the ordinance.</p><p>“Today, our tipped workers will win,” Fuentes said. “Look at the room. Look at the room. Those are Black and brown faces that are asking for a raise.”</p><p>Some aldermen also lamented that the moment did not come sooner, such as when the City Council <a href="https://www.chicagotribune.com/business/ct-biz-chicago-minimum-wage-approved-20191126-esp6g6do6nhzjfl7i7yphbfmrm-story.html">raised</a> the minimum wage to $15 under former Mayor Lori Lightfoot but did not alter the pay floor for tipped workers.</p><p>Ald. Rossana Rodriguez Sanchez, 33rd, said when that vote passed four years ago a man sitting in the back of the public gallery in the council chambers yelled, “You left out tipped wage!”</p><p>“He yelled that so many times, and I felt that in my heart. I knew that that moment was an opportunity for us to do that, and we didn’t do that,” Rodriguez Sanchez said. “It took us four more years and a progressive movement to push for this and be able to pass it now. … Wherever he is, this vote is dedicated to you today.”</p><p>But Ald. Nicole Lee, 11th, said the small business owners in her ward that encompasses Chinatown — where family restaurants have served as a time-honored engine for economic mobility — implored her to oppose the measure even though they knew it likely would pass.</p><p>“My constituents there feel this is going to hurt more than it is going to help our local economy,” Lee said. “Because of that, I’m going to be a no.”</p><p>A man in the public section then cried out, “Thank you for saving my job.”</p><p>Other opponents have argued evening out the minimum wage across all industries will cause people to tip less, hurting servers’ bottom lines.</p><p>Ald. Nicholas Sposato, 38th, said instead of raising the minimum wage for tipped workers customers should be “educated” on how to tip better because, “I believe we are going to get destroyed with this.”</p><p>Ald. Daniel La Spata, 1st, who represents the neighborhoods of Wicker Park and Bucktown that are hubs for restaurants, rejected the business community’s anxieties by declaring to any servers listening in: “I don’t need to balance my bill on the backs of your poverty.”</p><p>“The sky maybe is going to fall in when we pass this ordinance, but the sky didn’t fall in when we fought for and won a $15 minimum wage,” La Spata said, before listing other pro-labor ordinances passed in Chicago. “The sky keeps on not falling. … Somehow I have a feeling that the sky is not going to fall today either.”</p><p>Johnson campaigned on the issue and this summer donned a One Fair Wage apron at a progressive conference, serving appetizers in solidarity with the conference’s catering staff.</p><p><span>[&nbsp;</span><a href="https://www.chicagotribune.com/politics/ct-tipped-minimum-wage-abolish-ordinance-deal-20230919-7g2afmgi55donobgsrzaqosoca-story.html#nt=interstitial-manual" aria-label="Open related story">Chicago could become largest US city to independently abolish tipped wage under Mayor Brandon Johnson compromise</a><span>&nbsp;]</span></p><p>The restaurant lobby, a longtime foe of the effort and similar attempts to do away with the lower tipped wage, <a href="https://www.chicagotribune.com/politics/ct-tipped-minimum-wage-abolish-ordinance-deal-20230919-7g2afmgi55donobgsrzaqosoca-story.html" target="_blank">begrudgingly accepted a deal</a> from the mayor’s administration that increased the phase-in from two years to five. That was after the head of the Illinois Restaurant Association, Sam Toia, floated a counterproposal to raise subminimum wages only at restaurants earning more than $3 million in annual revenue. That offer failed to gain traction.</p><p>“Obviously, a lot of restaurant owners, operators will tell you, the last couple of years have been really rough coming out of the pandemic, especially with double-digit inflation,” Toia said last month. “There’s only two things you can control in the restaurant industry: your product costs and your labor costs. … There could definitely be people cutting back on labor.”</p><p>However, the mayor’s floor leader, Ald. Carlos Ramirez-Rosa, 35th, has argued raising minimum pay for tipped workers is good for business.</p><p>“We have decades of research: Los Angeles, Minneapolis, cities across this nation with economies very similar to ours have already instituted One Fair Wage with tips on top,” he said during a council committee meeting<b> </b>last month. “Restaurants are opening up, restaurants are growing, restaurants are employing more workers and workers are making the same — or more — in tips.”</p><p><span>[&nbsp;</span><a href="https://www.chicagotribune.com/politics/ct-one-fair-wage-forward-city-council-1004-20231004-h2li44wyhjdixn67o27bqg5mgi-story.html#nt=interstitial-manual" aria-label="Open related story">Mayor Brandon Johnson beats back opposition, moves forward with plans to end lower minimum wage and for homeless services</a><span>&nbsp;]</span></p><p>The ordinance was originally supposed <a href="https://www.chicagotribune.com/politics/ct-one-fair-wage-forward-city-council-1004-20231004-h2li44wyhjdixn67o27bqg5mgi-story.html" target="_blank">to get a final vote on Wednesday</a>, but the city clerk’s office failed to post the item on the council’s agenda with enough advance notice, as legally mandated. A group of moderate and more conservative members tried to stall an attempt to reschedule the vote during the Wednesday council meeting but were squashed by Johnson allies.</p><p>The city’s minimum wage rate is $15.80 per hour for businesses with 21 or more workers and $15.00 per hour for those with four to 20 workers. Under the old law, tipped workers were paid 60% of the minimum wage rate and if a tipped worker’s wages with the addition of tips did<b> </b>not equal at least the full minimum wage, the employer had to make up the difference.</p><p><a href="mailto:ayin@chicagotribune.com" target="_blank"><i>ayin@chicagotribune.com</i></a></p></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[X rolls out new ad format that can't be reported, blocked (116 pts)]]></title>
            <link>https://mashable.com/article/twitter-x-new-clickbait-ad-format</link>
            <guid>37794809</guid>
            <pubDate>Fri, 06 Oct 2023 19:02:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mashable.com/article/twitter-x-new-clickbait-ad-format">https://mashable.com/article/twitter-x-new-clickbait-ad-format</a>, See on <a href="https://news.ycombinator.com/item?id=37794809">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>


<p>The new ads also don't disclose who the advertiser is or that they are even ads.</p>


</div><section data-ga-module="content_body">
<div>
<p><img src="https://helios-i.mashable.com/imagery/articles/07dSJUT5Ii2rhdYhDH6UoKO/hero-image.fill.size_1248x702.v1696612480.jpg" alt="X logo on mobile device" width="1248" height="702" srcset="https://helios-i.mashable.com/imagery/articles/07dSJUT5Ii2rhdYhDH6UoKO/hero-image.fill.size_400x225.v1696612480.jpg 400w, https://helios-i.mashable.com/imagery/articles/07dSJUT5Ii2rhdYhDH6UoKO/hero-image.fill.size_800x450.v1696612480.jpg 800w, https://helios-i.mashable.com/imagery/articles/07dSJUT5Ii2rhdYhDH6UoKO/hero-image.fill.size_1248x702.v1696612480.jpg 1600w" sizes="(max-width: 1280px) 100vw, 1280px"></p><p><span>Elon Musk's X is now serving users clickbait advertisements that can't be blocked or reported.</span>
<span>Credit: Thomas Trutschel/Photothek via Getty Images</span>
</p>
</div>
<article id="article" data-autopogo="">
<p><a href="https://mashable.com/article/elon-musk-removes-headlines-links-twitter-x" target="_self">X</a>, the Elon Musk-owned platform formerly known as <a href="https://mashable.com/article/twitter-x-trademark-infringement-lawsuit-x-social-media" target="_self">Twitter</a>, has begun serving its users with a weird new ad format and it's one of the company's least transparent products yet.</p><p>The rollout of these ads also provides the public with a hint regarding just how much the company is struggling to attract advertisers.</p><p>Multiple X users have reached out to Mashable over the past few days to report seeing a new type of ad in their For You feed that they had not previously come across on the platform. These new X ads don't allow users to like or retweet the ad posts. In fact, the new ad format also doesn't disclose who is behind the ad or that it is even an advertisement at all.</p><div>
<p><img src="https://helios-i.mashable.com/imagery/articles/07dSJUT5Ii2rhdYhDH6UoKO/images-1.fill.size_2000x1432.v1696612481.jpg" alt="X ad" width="2000" height="1432" loading="lazy" srcset="https://helios-i.mashable.com/imagery/articles/07dSJUT5Ii2rhdYhDH6UoKO/images-1.fill.size_800x573.v1696612481.jpg 800w, https://helios-i.mashable.com/imagery/articles/07dSJUT5Ii2rhdYhDH6UoKO/images-1.fill.size_1400x1002.v1696612481.jpg 1400w, https://helios-i.mashable.com/imagery/articles/07dSJUT5Ii2rhdYhDH6UoKO/images-1.fill.size_2000x1432.v1696612481.jpg 2000w" sizes="(max-width: 1408px) 100vw, 1408px">
</p>
<p><span>Here's X's new clickbait ads featuring chumbox content. Notice the lack of display name and handle.</span>
<span>Credit: X screenshot</span>
</p>
</div>
<p>Mashable has confirmed this ad format with numerous users from across X and have seen a variety of different ads running this bizarre new format that just consists of written copy text, a photo, and a fake avatar that's sole purpose is to make the ad look like an organically posted tweet.&nbsp;</p><p>The type of content being promoted in the ads that Mashable has viewed appear to be consistent with ads found in spammy, low quality "<a href="https://www.theawl.com/2015/06/a-complete-taxonomy-of-internet-chum/" target="_blank" title="(opens in a new window)"><u>chumbox</u></a>" advertising – typically defined as those clickbait ads found at the bottom of posts on content farm sites – made popular by native ad networks like <a href="https://www.wired.co.uk/article/fake-news-outbrain-taboola-hillary-clinton" target="_blank" title="(opens in a new window)"><u>Taboola</u></a>.&nbsp;</p><p>"This Seems Unbelievable, But Happens in Dubai Everyday" reads one ad that takes users to a third-party content mill website, overloaded with ads of its own. "These Incredibly Cool Gadgets That Are Going To Sell Out This Year. Action Now!" and "If you suffer from ringing ears (Tinnitus) you're going to love this recent breakthrough" are other examples of some of the content found in these X ads.</p><div>
<p><img src="https://helios-i.mashable.com/imagery/articles/07dSJUT5Ii2rhdYhDH6UoKO/images-2.fill.size_2000x1374.v1696612481.jpg" alt="X ad" width="2000" height="1374" loading="lazy" srcset="https://helios-i.mashable.com/imagery/articles/07dSJUT5Ii2rhdYhDH6UoKO/images-2.fill.size_800x550.v1696612481.jpg 800w, https://helios-i.mashable.com/imagery/articles/07dSJUT5Ii2rhdYhDH6UoKO/images-2.fill.size_1400x962.v1696612481.jpg 1400w, https://helios-i.mashable.com/imagery/articles/07dSJUT5Ii2rhdYhDH6UoKO/images-2.fill.size_2000x1374.v1696612481.jpg 2000w" sizes="(max-width: 1408px) 100vw, 1408px">
</p>
<p><span>Here's another example of X's shady chumbox-esque advertising.</span>
<span>Credit: X screenshot</span>
</p>
</div>
<p>Users who have seen these X ads report being taken to a third-party website in a new window upon clicking anywhere within the ad, including when they try to click on the fake avatar. There is no X post to open nor is there a user profile attached to the ad to visit. So far, Mashable has seen these ads served to users within X's mobile apps. Its unclear if the ads are also running on the web version of the platform.&nbsp;</p><p>Mashable was able to find advertisements similar to the aforementioned X ads using the same exact text copy running through ad networks on Yahoo and Taboola competitors like RevContent. Mashable could not locate this X ad format in the platform's ad campaign manager so it appears these ads are actually being served by a third-party ad provider.&nbsp;</p><p>The presence of these ads is actually quite telling about the state of advertising on Musk's social media platform.</p><blockquote>
<a href="https://twitter.com/aMarkzzz/status/1708964978315718735" target="_blank" rel="noopener" title="(opens in a new window)">
Tweet may have been deleted
</a>
</blockquote>
<h2>X turns to the chumbox amid direct ad sale decline</h2><p>Since Musk's acquisition of the company, X has <a href="https://mashable.com/article/twitter-advertisers-leaving-app-elon-musk" target="_self"><u>struggled</u></a> to <a href="https://mashable.com/article/x-twitter-brands-suspend-ads-showing-beside-nazi-content" target="_self"><u>attract</u></a> advertisers to the <a href="https://www.nytimes.com/2023/06/05/technology/twitter-ad-sales-musk.html" target="_blank" title="(opens in a new window)"><u>platform</u></a>. Half of the platform's biggest advertisers stopped running ads shortly after Musk's takeover. Furthermore, according to a <a href="https://www.mediamatters.org/twitter/linda-yaccarino-again-claims-advertisers-are-returning-x-here-are-facts" target="_blank" title="(opens in a new window)"><u>new report</u></a> from Media Matters For America, the advertisers who have returned are spending up to 90 percent less on advertising on X than they did prior to Musk acquiring the company. Another <a href="https://www.reuters.com/technology/us-ad-revenue-musks-x-declined-each-month-since-takeover-data-2023-10-04/" target="_blank" title="(opens in a new window)"><u>recent report</u></a> from Reuters found that Musk's X has faced declining revenue each and every month since he became the owner of the company.</p><p>In order to help with declining ad revenue, X has turned to partnering with third-parties within the adtech industry to sell available advertising inventory. Just last month, Google <a href="https://adage.com/article/digital-marketing-ad-tech-news/x-turns-google-programmatic-ads-timeline/2515981" target="_blank" title="(opens in a new window)"><u>announced</u></a> it would be partnering with X to sell programmatic advertising. Earlier this year, X also partnered with InMobi, a mobile-focused programmatic ad sales company.</p><div>
<p><img src="https://helios-i.mashable.com/imagery/articles/07dSJUT5Ii2rhdYhDH6UoKO/images-4.fill.size_553x750.v1696612481.png" alt="X ad in feed" width="553" height="750" loading="lazy" srcset="https://helios-i.mashable.com/imagery/articles/07dSJUT5Ii2rhdYhDH6UoKO/images-4.fill.size_800x1085.v1696612481.png 800w, https://helios-i.mashable.com/imagery/articles/07dSJUT5Ii2rhdYhDH6UoKO/images-4.fill.size_1400x1899.v1696612481.png 1400w, https://helios-i.mashable.com/imagery/articles/07dSJUT5Ii2rhdYhDH6UoKO/images-4.fill.size_2000x2713.v1696612481.png 2000w" sizes="(max-width: 1408px) 100vw, 1408px">
</p>
<p><span>This is how the new X ads look among real, organic posts in the For You feed.</span>
<span>Credit: X screenshot</span>
</p>
</div>
<p>So, what does that mean? Users are likely seeing these ads because X no longer has any direct ad inventory to serve them. This could mean that these particular users seeing these ads are not being targeted by any brands that are running ads at the moment. Or brands that are advertising on X and targeting these users have exhausted their ad spend for the moment. It's also possible that these users have blocked brand accounts that would've targeted them with ads otherwise.&nbsp;</p><p>Whatever the reason these users aren't being served ads directly from the platform, the point is that they aren't seeing them. And that means that X hasn't been able to sell enough ad space directly to brands and need to instead serve advertisements from ad networks. In turn, X makes less money as direct ad sales typically generate much more revenue for a company.</p><h2>These new clickbait X ads</h2><p>Typically, how it worked on Twitter and then on X until now, ads on the platform were just normal posts that an advertiser paid to show users in their feeds, replies, or profiles.&nbsp;</p><p>However, this new ad format completely breaks that as these ads are technically not posts, even if they somewhat look the part. All the engagement buttons on these new X ads are completely grayed out. For example, users are unable to click like, retweet, or reply. These ads cannot be clicked to open in full tweet view like every other X ad format.&nbsp;</p>
<blockquote>
<a href="https://twitter.com/lynxnoirs/status/1707947210732650682" target="_blank" rel="noopener" title="(opens in a new window)">
Tweet may have been deleted
</a>
</blockquote>
<blockquote>
<a href="https://twitter.com/flipnotemachine/status/1706550158043869572" target="_blank" rel="noopener" title="(opens in a new window)">
Tweet may have been deleted
</a>
</blockquote>
<p>This new X ad format completely lacks the three dotted icon button usually present in the upper right hand side of X posts and ads. On a normal post, that button provides users with a slew of options to report a post and mute or block an account. Without it, there are no ways for a user to report or block these types of ads that are being served to them.&nbsp;</p><p>In addition, users cannot add Community Notes to these ads either. Over the past few months, users have been utilizing Community Notes, the popular feature on the platform that allows users to add context to disinformation and other factually incorrect posts, to <a href="https://www.vice.com/en/article/7kxepa/twitter-users-are-warning-each-other-about-its-junk-ads-with-community-notes" target="_blank" title="(opens in a new window)">warn</a> others of scam ads on X.</p><p>Perhaps the biggest deviation from the regular ads on X is that these new ads have no X account attached to them at all. At least, not one that's visible to the user. There is no username or handle present on these ads. While an avatar is displayed in order to make the ad blend in with other posts on a user's feed, the image isn't a profile picture. The avatar appears to just be a cropped version of the photo included within the ad itself.&nbsp;</p><p>Without a display name or handle, it's also unclear to the user exactly who is behind the ad. The new ad format also doesn't disclose that it is an advertisement at all. There is no "promoted" or "ad" label on any of these types of ads that Mashable has seen.&nbsp;And, unlike most other websites that run chumbox clickbait advertising, X doesn't even disclose the ad network associated with these ads.</p><div>
<p><img src="https://helios-i.mashable.com/imagery/articles/07dSJUT5Ii2rhdYhDH6UoKO/images-3.fill.size_644x750.v1696612481.png" alt="X ad in feed" width="644" height="750" loading="lazy" srcset="https://helios-i.mashable.com/imagery/articles/07dSJUT5Ii2rhdYhDH6UoKO/images-3.fill.size_800x932.v1696612481.png 800w, https://helios-i.mashable.com/imagery/articles/07dSJUT5Ii2rhdYhDH6UoKO/images-3.fill.size_1400x1632.v1696612481.png 1400w, https://helios-i.mashable.com/imagery/articles/07dSJUT5Ii2rhdYhDH6UoKO/images-3.fill.size_2000x2331.v1696612481.png 2000w" sizes="(max-width: 1408px) 100vw, 1408px">
</p>
<p><span>Another example of how these new X ads look like next to real posts in the feed.</span>
<span>Credit: X screenshot</span>
</p>
</div>
<p>Mashable <a href="https://mashable.com/article/twitter-x-removes-ad-labels-for-some-users" target="_self"><u>previously reported</u></a> earlier this month how these important advertisement disclosure labels were also missing from the traditional X ad formats for some users. However, even in those cases, a user could click the options button to report the post and the platform would inform the user it was an advertisement by providing the option to tell X it was "not interested" in the ad. There is no such option on this new ad format as the three dotted button is missing from these ads. One other way to tell an X ad from a regular post is that ads don't include a timestamp on the posts. The new ad format also excludes a timestamp.</p><p>As previously mentioned, Mashable confirmed this ad format with numerous users from across X and have seen a variety of different ads running this new format. Mashable has also found <a href="https://twitter.com/aMarkzzz/status/1708964978315718735" target="_blank" title="(opens in a new window)">other users</a> who have <a href="https://twitter.com/lynxnoirs/status/1707947210732650682" target="_blank" title="(opens in a new window)">shared</a> via their <a href="https://twitter.com/flipnotemachine/status/1706550158043869572" target="_blank" title="(opens in a new window)">own</a> social media accounts that they have <a href="https://twitter.com/nonfatdairy/status/1706631902365446549" target="_blank" title="(opens in a new window)">also seen </a>these ads in <a href="https://twitter.com/cgsakurapink/status/1706751390008459548" target="_blank" title="(opens in a new window)">their feed</a>. It's unclear if X is just testing this format at this time.</p><p>The new ad format arrives to X around the same time the company made another decision that makes the platform less transparent. Earlier this week, under a directive from Musk himself, <a href="https://mashable.com/article/elon-musk-removes-headlines-links-twitter-x" target="_self"><u>X removed headlines</u></a> and other context from links shared to the platform. Instead of seeing the title of an article or other link posted to X, users now simply see an embed of the header image with the corresponding domain name displayed like a watermark-like overlay in the corner of the photo. Musk said he made the change to how links were displayed because he didn't like the way it previously looked. </p>

</article>
</section><div x-data="window.newsletter()" x-init="init()" data-ga-impression="" data-ga-category="newsletters" data-ga-module="footer_nl_signup" data-ga-label="Top Stories">

<p>
This newsletter may contain advertising, deals, or affiliate links. Subscribing to a newsletter indicates your consent to our <a href="https://www.ziffdavis.com/terms-of-use" target="_blank" rel="noopener" title="(opens in a new window)">Terms of Use</a> and <a href="https://www.ziffdavis.com/ztg-privacy-policy" target="_blank" rel="noopener" title="(opens in a new window)">Privacy Policy</a>. You may unsubscribe from the newsletters at any time.
</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Genetics firm 23andMe says user data stolen in credential stuffing attack (308 pts)]]></title>
            <link>https://www.bleepingcomputer.com/news/security/genetics-firm-23andme-says-user-data-stolen-in-credential-stuffing-attack/</link>
            <guid>37794379</guid>
            <pubDate>Fri, 06 Oct 2023 18:29:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bleepingcomputer.com/news/security/genetics-firm-23andme-says-user-data-stolen-in-credential-stuffing-attack/">https://www.bleepingcomputer.com/news/security/genetics-firm-23andme-says-user-data-stolen-in-credential-stuffing-attack/</a>, See on <a href="https://news.ycombinator.com/item?id=37794379">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p><img alt="DNA" height="900" src="https://www.bleepstatic.com/content/hl-images/2021/11/30/dna.jpg" width="1600"></p>
<p>23andMe has confirmed to BleepingComputer that it is aware of user data from its platform circulating&nbsp;on hacker forums and attributes the leak to a credential-stuffing attack.</p>
<p>23andMe is a U.S. biotechnology and genomics firm offering genetic testing services to customers who send a saliva sample to its labs and get back an ancestry and genetic predispositions report.</p>
<p>Recently, a threat actor leaked samples of data&nbsp;that was allegedly stolen from a genetics firm and, a few days later, offered to sell data packs belonging to 23andMe customers.</p>
<div>
<figure><img alt="Initial leak of genetic data" height="600" src="https://www.bleepstatic.com/images/news/u/1220909/2023/Databases/11/leak.png" width="836"><figcaption><strong>Initial leak of genetic data</strong><br><em>Source: BleepingComputer</em></figcaption></figure></div>
<p>The initial data leak was limited, with the threat actor releasing 1 million lines of data for Ashkenazi people. However, on October 4, the threat actor offered to sell data profiles in bulk for $1-$10 per 23andMe account, depending on how many were purchased.</p>
<div>
<figure><img alt="Selling stolen genetic data profiles in bulk" height="477" src="https://www.bleepstatic.com/images/news/u/1220909/2023/Databases/11/sale.png" width="1023"><figcaption><strong>Selling stolen genetic data profiles in bulk</strong><br><em>Source:&nbsp;BleepingComputer</em></figcaption></figure></div>
<p>A 23andMe spokesperson confirmed the data is legitimate&nbsp;and told BleepingComputer that the threat actors used exposed credentials from other breaches to access 23andMe accounts and steal the sensitive data.</p>
<p>"We were made aware that certain 23andMe customer profile information was compiled through access to individual 23andMe.com accounts," stated 23andMe's spokesperson</p>
<p>"We do not have any indication at this time that there has been a data security incident within our systems."</p>
<p>"Rather, the preliminary results of this investigation suggest that the login credentials used in these access attempts may have been gathered by a threat actor from data leaked during incidents involving other online platforms where users have recycled login credentials."</p>
<p>The information that has been exposed from this incident includes full names, usernames, profile photos, sex, date of birth, genetic ancestry results, and geographical location.</p>
<p>BleepingComputer has also learned that the number of accounts sold by the cybercriminal does not reflect the number of 23andMe accounts breached using exposed credentials.</p>
<p>The compromised accounts had opted into the platform's 'DNA Relatives' feature, which allows users to find genetic relatives and connect with them.</p>
<p>The threat actor accessed a small number of 23andMe accounts and then scraped the data of their DNA Relative matches, which shows how opting into a feature can have unexpected privacy consequences.</p>
<p>23andMe told BleepingComputer that the platform offers two-factor authentication as an additional account protection measure and <a href="https://customercare.23andme.com/hc/en-us/articles/360034119874-Adding-2-Step-Verification-to-Your-23andMe-Account" target="_blank" rel="nofollow noopener">encourages</a> all users to enable it.</p>
<p>Users should refrain from reusing passwords and consistently employ strong, distinct credentials for every online account they have.</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The ozone hole above Antarctica has grown to three times the size of Brazil (111 pts)]]></title>
            <link>https://www.space.com/ozone-hole-antarctica-three-times-size-of-brazil</link>
            <guid>37793941</guid>
            <pubDate>Fri, 06 Oct 2023 18:00:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.space.com/ozone-hole-antarctica-three-times-size-of-brazil">https://www.space.com/ozone-hole-antarctica-three-times-size-of-brazil</a>, See on <a href="https://news.ycombinator.com/item?id=37793941">Hacker News</a></p>
<div id="readability-page-1" class="page"><article aria-label="article" data-id="MwoBrj6xSd3LoxbyTS4zzW">
<header>
<nav aria-label="Breadcrumbs">
<ol>
<li>
<a href="https://www.space.com/news" aria-label="Return to News">News</a>
</li>
<li>
<a href="https://www.space.com/science-astronomy" aria-label="Return to Science &amp; Astronomy">Science &amp; Astronomy</a>
</li>
</ol>
</nav>


</header>
<section>
<div itemprop="image" itemscope="" itemtype="https://schema.org/ImageObject">
<div>
<picture><source type="image/webp" alt="A map of the ozone hole on Sept. 16, 2023." onerror="if(this.src &amp;&amp; this.src.indexOf('missing-image.svg') !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" srcset="https://cdn.mos.cms.futurecdn.net/FHSnfv6hdmdcFgnBrwuzHE-320-80.jpg.webp 320w, https://cdn.mos.cms.futurecdn.net/FHSnfv6hdmdcFgnBrwuzHE-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/FHSnfv6hdmdcFgnBrwuzHE-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/FHSnfv6hdmdcFgnBrwuzHE-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/FHSnfv6hdmdcFgnBrwuzHE-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/FHSnfv6hdmdcFgnBrwuzHE-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/FHSnfv6hdmdcFgnBrwuzHE-1920-80.jpg.webp 1920w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/FHSnfv6hdmdcFgnBrwuzHE.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/FHSnfv6hdmdcFgnBrwuzHE.jpg"><source type="image/jpeg" alt="A map of the ozone hole on Sept. 16, 2023." onerror="if(this.src &amp;&amp; this.src.indexOf('missing-image.svg') !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" srcset="https://cdn.mos.cms.futurecdn.net/FHSnfv6hdmdcFgnBrwuzHE-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/FHSnfv6hdmdcFgnBrwuzHE-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/FHSnfv6hdmdcFgnBrwuzHE-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/FHSnfv6hdmdcFgnBrwuzHE-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/FHSnfv6hdmdcFgnBrwuzHE-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/FHSnfv6hdmdcFgnBrwuzHE-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/FHSnfv6hdmdcFgnBrwuzHE-1920-80.jpg 1920w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/FHSnfv6hdmdcFgnBrwuzHE.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/FHSnfv6hdmdcFgnBrwuzHE.jpg"><img src="https://cdn.mos.cms.futurecdn.net/FHSnfv6hdmdcFgnBrwuzHE-320-80.jpg" alt="A map of the ozone hole on Sept. 16, 2023." onerror="if(this.src &amp;&amp; this.src.indexOf('missing-image.svg') !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" srcset="https://cdn.mos.cms.futurecdn.net/FHSnfv6hdmdcFgnBrwuzHE-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/FHSnfv6hdmdcFgnBrwuzHE-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/FHSnfv6hdmdcFgnBrwuzHE-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/FHSnfv6hdmdcFgnBrwuzHE-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/FHSnfv6hdmdcFgnBrwuzHE-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/FHSnfv6hdmdcFgnBrwuzHE-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/FHSnfv6hdmdcFgnBrwuzHE-1920-80.jpg 1920w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/FHSnfv6hdmdcFgnBrwuzHE.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/FHSnfv6hdmdcFgnBrwuzHE.jpg"></picture>
</div>
<meta itemprop="url" content="https://cdn.mos.cms.futurecdn.net/FHSnfv6hdmdcFgnBrwuzHE.jpg">
<meta itemprop="height" content="600">
<meta itemprop="width" content="338">
<figcaption itemprop="caption description">
<span>A map of the ozone hole on Sept. 16, 2023.</span>
<span itemprop="copyrightHolder">(Image credit: NASA Ozone Watch)</span>
</figcaption>
</div>

<div id="article-body">
<p>Just as the <a href="https://www.space.com/sea-ice-antarctica-hits-record-low-2023-satellite-data"><u>sea ice around Antarctica</u></a> grows and retreats each year, so does the ozone hole above the continent. And this year, that hole has grown a lot.&nbsp;</p><p>Observations from the European Space Agency's (ESA) <a href="https://www.space.com/copernicus-program"><u>Copernicus Sentinel-5P satellite </u></a>indicate the ozone hole reached approximately 10 million square miles (26 million square kilometers) in area on Sept. 16, 2023 —&nbsp;making it one of the largest seasonal holes ever observed. The true largest ozone hole maximum occurred in 2000, when the chasm reached nearly 11 million square miles (28.4 million square kilometers) in area.</p><p>Ozone is a naturally occurring gas, and there's a layer of it in the stratosphere that protects us from the <a href="https://www.space.com/58-the-sun-formation-facts-and-characteristics.html"><u>sun's</u></a> ultraviolet, or UV, rays. In 1985, a hole in the ozone layer was discovered above Antarctica&nbsp;— and later connected to human use of carbon-depleting substances. Since then, we've banned the use of those substances and have been monitoring the hole's size.</p><p><strong>Related: </strong><a href="https://www.space.com/antarctic-ozone-hole-early-hunga-tonga">The ozone hole above Antarctica opened early this year. Huge Tonga undersea volcano eruption may be to blame</a></p><p>The ozone hole still grows and shrinks seasonally, however, due to temperature changes and wind conditions in the stratosphere, reaching a maximum between mid-September and mid-October. "Our operational ozone monitoring and forecasting service shows that the 2023 ozone hole got off to an early start and has grown rapidly since mid-August," Antje Inness, Copernicus Atmosphere Monitoring Service senior scientist, said in a <a href="https://www.esa.int/Applications/Observing_the_Earth/Copernicus/Sentinel-5P/Ozone_hole_goes_large_again" target="_blank" data-url="https://www.esa.int/Applications/Observing_the_Earth/Copernicus/Sentinel-5P/Ozone_hole_goes_large_again"><u>statement</u></a>.&nbsp;</p><p>One possible reason for the higher-than-normal growth is the <a href="https://www.space.com/hunga-tonga-will-make-ozone-hole-larger"><u>Hunga Tonga volcanic eruption</u></a> in January 2022, which introduced massive quantities of water vapor into the air. “The water vapor could have led to the heightened formation of polar stratospheric clouds, where chlorofluorocarbons (CFCs) can react and accelerate ozone depletion," said Inness.</p><p>Yet despite experiencing large seasonal growth this year, the ozone hole is still decreasing in size overall. "Based on the Montreal Protocol and the decrease of anthropogenic ozone-depleting substances, scientists currently predict that the global ozone layer will reach its normal state again by around 2050," said Claus Zehner, ESA's mission manager for Copernicus Sentinel-5P.</p>
</div>
<p><em><a href="https://forums.space.com/">Join our Space Forums</a> to keep talking space on the latest missions, night sky and more! And if you have a news tip, correction or comment, let us know at: <a href="mailto:community@space.com">community@space.com.</a></em></p>
<div data-hydrate="true" id="slice-container-newsletterForm-articleInbodyContent"><section><p>Breaking space news, the latest updates on rocket launches, skywatching events and more!</p></section></div>
<div id="slice-container-authorBio"><p>Space.com contributing writer Stefanie Waldek is a self-taught space nerd and aviation geek who is passionate about all things spaceflight and astronomy. With a background in travel and design journalism, as well as a Bachelor of Arts degree from New York University, she specializes in the budding space tourism industry and Earth-based astrotourism. In her free time, you can find her watching rocket launches or looking up at the stars, wondering what is out there. Learn more about her work at <a href="https://mailtrack.io/trace/link/841a96809cf8444a85db7a2b318410433580a8f6?url=https%3A%2F%2Fwww.stefaniewaldek.com&amp;userId=2756587&amp;signature=ba54abdc159873b3" target="_blank">www.stefaniewaldek.com</a>.</p></div>


</section>




<div id="slice-container-relatedArticles"><p><h5>Most Popular</h5></p></div>

</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AMD may get across the CUDA moat (467 pts)]]></title>
            <link>https://www.hpcwire.com/2023/10/05/how-amd-may-get-across-the-cuda-moat/</link>
            <guid>37793635</guid>
            <pubDate>Fri, 06 Oct 2023 17:35:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.hpcwire.com/2023/10/05/how-amd-may-get-across-the-cuda-moat/">https://www.hpcwire.com/2023/10/05/how-amd-may-get-across-the-cuda-moat/</a>, See on <a href="https://news.ycombinator.com/item?id=37793635">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		<p><span data-preserver-spaces="true">When discussing GenAI, the term “GPU” almost always enters the conversation and the topic often moves toward performance and <a href="https://www.hpcwire.com/2023/07/13/the-great-gpu-squeeze-is-upon-us/">access</a>. Interestingly, the word “GPU” is assumed to mean “Nvidia” products. (As an aside, the popular Nvidia hardware used in GenAI are not technically Graphical Processing Units. I prefer SIMD units.)</span></p>
<p><span data-preserver-spaces="true">The association of GenAI and GPUs with Nvidia is no accident. Nvidia has always recognized the need for tools and applications to help grow its market. They have created a very low barrier to getting software tools (e.g., CUDA) and optimized libraries (e.g., cuDNN) for Nvidia hardware. Indeed, Nvidia is known as a hardware company, but as Bryan Catanzaro, VP of Applied Deep Learning Research, Nvidia has<a href="https://www.deeplearning.ai/blog/working-ai-at-the-office-with-vp-of-applied-deep-learning-research-bryan-catanzaro"> stated</a> ” Many people don’t know this, but Nvidia has more software engineers than hardware engineers.”</span></p>
<p><span data-preserver-spaces="true">As a result, Nvidia has built a powerful software “moat” around their hardware. While CUDA is not open source, it is freely available and under the firm control of Nvidia. While this situation has benefited Nvidia (As it should. They invested time and money into CUDA), it has created difficulties for those companies and users that want to grab some of the HPC and GenAI market with alternate hardware.</span></p>
<h3><span data-preserver-spaces="true">Building on the Castle Foundation</span></h3>
<p><span data-preserver-spaces="true">The number of foundational models developed for GenAI continues to grow. Many of these are “open source” because they can be used and shared freely. (For example, the <a href="https://ai.meta.com/llama">Llama foundational model</a> from Meta) In addition, they require a large number of resources (both people and machines) to create and are limited mainly to the hyperscalers (AWS, Microsoft Azure, Google Cloud, Meta Platforms, and Apple) that have huge amounts of GPUs available, In addition to the hyperscalers, other companies have invested in hardware (i.e. purchased a massive amount of GPUs) to create their own foundational models.</span></p>
<p><span data-preserver-spaces="true">From a research perspective, the models are interesting and can be used for a variety of tasks; however, the expected use and need for even more GenAI computing resources is two fold;</span></p>
<ol>
<li><span data-preserver-spaces="true">Fine-tuning — Adding domain-specific data to foundational models to make it work for your use case.</span></li>
<li><span data-preserver-spaces="true">Inference – Once the model is fine-tuned, it will require resources when used (i.e., asked questions).</span></li>
</ol>
<p><span data-preserver-spaces="true">These tasks are not restricted to hyperscalers and will need accelerated computing, that is, GPUs. The obvious solution is to buy more “unavailable” Nvidia GPUs, and AMD is ready and waiting now that the demand has far outstripped the supply. To be fair, Intel and some other companies are also ready and waiting to sell into this market. The point is that GenAI will continue to squeeze GPU availability as fine-tuning and inference become more pervasive, and any GPU (or accelerator) is better than no GPU.</span></p>
<p><span data-preserver-spaces="true">Moving away from Nvidia hardware suggests that other vendor GPUs and accelerators must support CUDA to run many of the models and tools. AMD has made this possible with <a href="https://www.amd.com/system/files/documents/porting-cuda-to-hip.pdf">HIP CUDA conversion tool</a>; however, the best results often seem to use the native tools surrounding the Nvidia castle.</span></p>
<h3><span data-preserver-spaces="true">The PyTorch Drawbridge</span></h3>
<p><span data-preserver-spaces="true">In the HPC sector, CUDA-enabled applications rule the GPU-accelerated world. Porting codes can often realize a speed-up of 5-6x when using a GPU and CUDA. (Note: Not all codes can achieve this speed up, and some may not be able to use the GPU hardware.) However, in GenAI, the story is quite different.</span></p>
<p><span data-preserver-spaces="true">Initially, TensorFlow was the tool of choice for creating AI applications using GPUs. It works both with CPUs and was accelerated with CUDA for GPUs. This situation is changing rapidly.</span></p>
<p><span data-preserver-spaces="true">An alternative to TensorFlow is PyTorch, an open-source machine learning library for developing and training neural network-based deep learning models. Facebook’s AI research group primarily develops it.</span></p>
<p><span data-preserver-spaces="true">In a recent <a href="https://www.assemblyai.com/blog/pytorch-vs-tensorflow-in-2023/">blog post</a> by Ryan O’Connor, a Developer Educator at <a href="https://www.assemblyai.com/">AssemblyAI</a> notes that the popular site </span><a href="https://huggingface.co/?ref=assemblyai.com" target="_blank" rel="noopener"><span data-preserver-spaces="true">HuggingFace</span></a><span data-preserver-spaces="true">, (that allows users to download and incorporate trained and tuned state of the art models into application pipelines with just a few lines of code), 92% of models available are PyTorch exclusive.</span></p>
<p><span data-preserver-spaces="true">In addition, as shown in Figure One, a comparison of Machine Learning papers shows a significant trend toward PyTorch and away from TensorFlow.</span></p>
<figure id="attachment_165049" aria-describedby="caption-attachment-165049"><img decoding="async" loading="lazy" src="https://www.hpcwire.com/wp-content/uploads/2023/10/PyTorch-TF-trends-300x178.png" alt="" width="556" height="330" srcset="https://www.hpcwire.com/wp-content/uploads/2023/10/PyTorch-TF-trends-300x178.png 300w, https://www.hpcwire.com/wp-content/uploads/2023/10/PyTorch-TF-trends-150x89.png 150w, https://www.hpcwire.com/wp-content/uploads/2023/10/PyTorch-TF-trends-600x355.png 600w, https://www.hpcwire.com/wp-content/uploads/2023/10/PyTorch-TF-trends.png 709w" sizes="(max-width: 556px) 100vw, 556px"><figcaption id="caption-attachment-165049">Figure One: Percentage of papers that utilize PyTorch, TensorFlow, or another framework over time, with data aggregated quarterly, from late 2017, Source: assemblyai.com.</figcaption></figure>
<p><span data-preserver-spaces="true">Of course, underneath PyTorch are calls to CUDA, but that is not required because PyTorch insulates the user from the underlying GPU architecture. There is also a version of <a href="https://rocm.docs.amd.com/en/latest/how_to/pytorch_install/pytorch_install.html">PyTorch</a> that uses AMD <a href="https://en.wikipedia.org/wiki/ROCm">ROCm</a>, an open-source software stack for AMD GPU programming. Crossing the CUDA moat for AMD GPUs may be as easy as using PyTorch.<br>
</span></p>
<h3><span data-preserver-spaces="true">Instinct for Inference</span></h3>
<p><span data-preserver-spaces="true">In both HPC and GenAI, the Nvidia 72-core ARM-based <a href="https://www.hpcwire.com/2023/09/28/nvidia-delivering-new-options-for-mlperf-and-hpc-performance/">Grace-Hopper superchip</a> with a shared memory H100 GPU (and also the 144-core Grace-Grace version) is highly anticipated. All Nvidia released benchmarks thus far indicate much better performance than the traditional server where the GPU is attached and accessed over the PCIe bus. Grace-Hopper represents an optimized hardware for both HPC and GenAI. It also is expected to find wide use in both fine-tuning and inference. Demand is expected to be high.</span></p>
<p><span data-preserver-spaces="true">AMD has had shared memory CPU-GPU designs since 2006 (AMD acquired graphics card company ATI in 2006). Beginning as the “Fusion” brand many AMD x86_64 processors are now implemented as a combined CPU/GPU called an Accelerated Processing Unit (<a href="https://en.wikipedia.org/wiki/AMD_APU">APU</a>).</span></p>
<p><span data-preserver-spaces="true">The upcoming Instinct MI300A processor (APU) from AMD will offer competition for Grace-Hopper superchip. It will also power the forthcoming <a href="https://www.hpcwire.com/2022/06/21/amds-mi300-apus-to-power-exascale-el-capitan-supercomputer/">El Capitan at Lawrence Livermore National Laboratory</a>. The Integrated MI300A will provide up to 24 Zen4 cores in combination with a CDNA 3 GPU Architecture </span><span data-preserver-spaces="true">and up to 192 GB of HBM3 memory, providing uniform access memory for all the CPU and GPU cores. The chip-wide cache-coherent memory reduces data movement between the CPU and GPU, eliminating the PCIe bus bottleneck and improving performance and power efficiency.</span></p>
<p><span data-preserver-spaces="true">AMD is readying the Instinct MI300A for the upcoming inference market. As stated by AMD CEO Lisa Su in a <a href="https://finance.yahoo.com/news/amd-lisa-su-ready-crash-150000172.html">recent article on Yahoo!Finance</a>. “We actually think we will be the industry leader for inference solutions because of some of the choices that we’ve made in our architecture.”</span></p>
<p><span data-preserver-spaces="true">For AMD and many other hardware vendors, PyTorch has dropped the drawbridge on the CUDA moat around the foundational models. AMD has the Instinct MI3000A battle wagon ready to go. The hardware battles for the GenAI market will be won by performance, portability, and availability. The AI day is young.</span></p>
							<div>
						<p><span>Sectors:</span>
						<a href="https://www.hpcwire.com/sector/academia-research/" rel="tag">Academia &amp; Research</a>, <a href="https://www.hpcwire.com/sector/community/" rel="tag">Community</a>, <a href="https://www.hpcwire.com/sector/entertainment/" rel="tag">Entertainment</a>, <a href="https://www.hpcwire.com/sector/financial-services/" rel="tag">Financial Services</a>, <a href="https://www.hpcwire.com/sector/government/" rel="tag">Government</a>, <a href="https://www.hpcwire.com/sector/life-sciences/" rel="tag">Life Sciences</a>, <a href="https://www.hpcwire.com/sector/manufacturing/" rel="tag">Manufacturing</a>, <a href="https://www.hpcwire.com/sector/oil-gas/" rel="tag">Oil &amp; Gas</a>, <a href="https://www.hpcwire.com/sector/retail/" rel="tag">Retail</a>, <a href="https://www.hpcwire.com/sector/semiconductor/" rel="tag">semiconductor</a>, <a href="https://www.hpcwire.com/sector/space-physics/" rel="tag">Space &amp; Physics</a>, <a href="https://www.hpcwire.com/sector/weather-climate/" rel="tag">Weather &amp; Climate</a>					</p></div><!-- .entry-utility -->
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Exploratory data analysis for humanities data (146 pts)]]></title>
            <link>https://awk.dev/eda.html</link>
            <guid>37792916</guid>
            <pubDate>Fri, 06 Oct 2023 16:31:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://awk.dev/eda.html">https://awk.dev/eda.html</a>, See on <a href="https://news.ycombinator.com/item?id=37792916">Hacker News</a></p>
<div id="readability-page-1" class="page">

<h2>Exploratory Data Analysis for Humanities Data</h2>

<h5>by Brian Kernighan</h5>

<p> <span size="-1"> Updated
Sun Sep 10 13:58:41 EDT 2023
 </span>

</p><h4>Introduction</h4>

In the spring of 2023, I co-taught a course called
 <a href="https://humstudies.princeton.edu/courses/literature-as-data/">
 <i>Literature as Data</i></a> with my friend and colleague
 <a href="https://english.princeton.edu/people/meredith-martin">Meredith Martin</a>,
professor of English at Princeton, and director of the
 <a href="https://cdh.princeton.edu/">Center for Digital Humanities</a>.

<p> The course was very much an experiment, an attempt to combine
literary study with computing.  The 17 surviving students were largely sophomores.
About two thirds of them were hard-core humanities majors; the rest were
potential or actual CS majors or other STEM concentrators.  The class
met once a week for three hours, 12 weeks in all.

</p><p> One of the goals of the course was to try to teach enough computing 
to a mostly non-technical and definitely not computer-experienced
population that they could use computers to do an interesting and new
(to them) exploration of some dataset that they found intriguing.

</p><p> After much discussion, Meredith and I decided that for the
programming aspects, we would devote half of each class meeting to a
"studio" where I would lead the students through hands-on computing
exercises on some small dataset, followed by having the students do
similar exercises on larger datasets outside the class.

</p><p> We planned to spend one week on Unix file system and command-line
basics, a week on grep and similar tools (including a real text editor),
a week on Awk, and a couple of weeks on Python.  Not surprisingly,
everything took longer than expected, and a fair number of students
struggled mightily in spite of help from their peers, Meredith and
myself, and two exceptional colleagues from the CDH, Sierra Eckert and Ryan Heuser.

</p><p> More about the course can be found elsewhere (at least when we get
around to writing it).  The course had a web site at
 <a href="http://www.hum307.com/">hum307.com</a>, though after a
while we stopped using that in favor of Google Docs -- information
was spread out over too many sites, and in addition we had to limit
access since some of our datasets were not public.

</p><h4> Awk vs Pandas </h4>

Arguably, most humanities computing uses Python and
the Pandas library to analyze structured data that often began life
as a CSV file.  If you're looking for a single language solution,
this is an excellent way to go.  But in my experience, admittedly
biased, Unix command-line tools and Awk can be especially
useful in the initial stages of exploring a new dataset.  They are
better at counting things, looking for anomalies and outliers,
and coping with data that isn't quite in the right format.
And, again a biased view, looping over a set of input lines seems
more natural than the dataframe selectors that Pandas favors.

<h4> Awk for EDA </h4>

<p> The purpose of this essay is to talk about how we used Awk in a
different EDA setting from the examples in the book.  In keeping with
the "literature" theme of the course, in the first few weeks we asked
students to look at poetry, specifically the <i>Sonnets from the
Portuguese</i> by Elizabeth Barrett Browning, and Shakespeare's sonnets.
We used grep and wc to count things like the number of times specific
words appeared, and also to observe something unexpected: even though
sonnets always have 14 lines, Shakespeare's Sonnet 126 has only 12
lines, and Sonnet 99 has 15 lines.  This was a good lesson about
literature but also about how real data does not always behave as
expected.

</p><p> This essay parallels the EDA discussion in Chapter 3 of the new Awk
book, but using different data, a metadata file about 18-th century
sonnets originally curated by Professor
 <a href="https://english.stanford.edu/people/mark-algee-hewitt"> Mark Algee-Hewitt</a>
of the Stanford Literary Lab.  We are very grateful to Mark for
kindly allowing us to use this metadata for the class and for this
page.

</p><p>
 <a href="https://www.hum307.com/studio3.html">What we did in class</a>
and the outside class exercises
can be found at <tt>hum307.com</tt>.


</p><p> The metadata file is <a href="https://awk.dev/18.csv">18.csv</a>.  The name is
not strictly accurate: we converted the original CSV into a file
with fields separated by slashes so that it would work with any version
of Awk.  We also removed some attributes from Mark's original dataset,
leaving us with 7 columns.

</p><pre>$ wc 18.csv
     508    3499   36876 18.csv
$ sed 1q 18.csv
author_dob/author_dod/author_fname/author_lname/num_lines/title_main/title_sub
$
</pre>

<p> Using the head-tail code of Section 2.2 of the book, we can look at the start
and end of the contents:

</p><pre>$ headtail 18.csv
author_dob/author_dod/author_fname/author_lname/num_lines/title_main/title_sub
1771/1798/E. H. (Elihu Hubbard)/Smith/8/SONNET I./Sent to Miss  , with a Braid of Hair.
1771/1798/E. H. (Elihu Hubbard)/Smith/8/SONNET II./Sent to Mrs.  , with a Song.
...
1740/1809/Hugh/Downman/14/SONNET II./[Though here almost eternal Winter reigns]
1740/1809/Hugh/Downman/14/SONNET III./[When Recollection stirs up in the mind]
1740/1809/Hugh/Downman/14/SONNET IV./[Now is the feudal vassalage destroy'd]
$
</pre>

Notice that the first sonnets only have 8 lines, echoing the observation above.


<h4> Validation </h4>

The first step is data validation: does the data satisfy basic
criteria like the right number of fields in each record.
In a separate command, we can look at the distribution of
number of lines in each sonnet:

<pre>$ awk -F/ '{print NF}' 18.csv | sort -u
7
$ awk -F/ '{print $5}' 18.csv | sort | uniq -c | sort -nr
 483 14
  11 8
   3 15
   2 12
   1 num_lines
   1 68
   1 66
   1 55
   1 54
   1 40
   1 28
   1 24
   1 123
$
</pre>

<p> This is a bit surprising: although 95% of the sonnets have the
standard 14 lines, 8 lines is not uncommon and some are remarkably long.
I'm no scholar, so I don't know what makes these "sonnets" as opposed to
some other poetic form.

</p><p> Maybe printing something about the longer ones might provide more
insight?  We'll exclude the header line too.

</p><pre>$ awk -F/ 'NF &gt; 1 &amp;&amp; $5 &gt; 14' 18.csv
1729/1777/William/Dodd/15/SONNET./OCCASIONED BY HEARING A YOUNG LADY SING SPENSER'S AMORETTI, &amp;c. SET TO MUSIC BY DR. GREENE.
1749/1806/Charlotte Turner/Smith/40/ODE TO DESPAIR./FROM THE NOVEL OF EMMELINE.
1749/1806/Charlotte Turner/Smith/68/ELEGY./[‘Dark gathering clouds involve the threatening skies]
1749/1806/Charlotte Turner/Smith/24/SONG./FROM THE FRENCH OF CARDINAL BERNIS.
1749/1806/Charlotte Turner/Smith/123/THE ORIGIN OF FLATTERY./
1749/1806/Charlotte Turner/Smith/54/THE PEASANT OF THE ALPS./FROM THE NOVEL OF CELESTINA.
1749/1806/Charlotte Turner/Smith/55/THIRTY-EIGHT./ADDRESSED TO MRS. HY.
1749/1806/Charlotte Turner/Smith/28/VERSES/INTENDED TO HAVE BEEN PREFIXED TO THE NOVEL OF EMMELINE, BUT THEN SUPPRESSED.
_/_/G./Bent/66/To the SAME,/On receiving his Poems to Thespia with a Sonnet prefixed.
1735/1779/John/Langhorne/15/SONNET CLXXIX./
1735/1788/William Julius/Mickle/15/SONNET TO VASCO DE GAMA: FROM TASSO./
</pre>

<p> This output suggests a variety of other questions and potential issues.
Charlotte Turner Smith wrote the majority of the long sonnets,
including the extreme outlier with 123 lines.
How many did she write overall?

</p><pre>$ grep Charlotte.Turner 18.csv | wc
     101     941    8955
$
</pre>

<p> She certainly was prolific, representing nearly 20% of the data.  
This raises some other questions for scholars, in particular, how
were these sonnets selected and how representative are they?  

</p><p> Here are some commands
to investigate the authors further.  For example, if we do a straightforward
display of unique author names:

</p><pre>$ awk -F/ '{print $3, $4}' 18.csv | uniq | sed 10q  # display the first 10 lines
author_fname author_lname
E. H. (Elihu Hubbard) Smith
M. F. Cogswell
E. H. (Elihu Hubbard) Smith
M. F. Cogswell
John Bampfylde
Thomas Edwards
William Cowper
William Dodd
Thomas Edwards
</pre>

we see that records for at least three authors are not contiguous, as we
might naively have expected.

This raises a new question: what is the order of the records?

<p> How many unique authors are there, and how much did they write?

</p><pre>$ awk -F/ '{print $4 ", " $3}' 18.csv | sort | uniq -c | sort -n
   1 Anon., _
   1 Anstey, Christopher
   1 Bent, G.
   1 Bishop, Samuel
   1 Bradford, A. M.
     ...
  23 Russell, Thomas
  38 Downman, Hugh
  50 Edwards, Thomas
 101 Smith, Charlotte Turner
 103 Seward, Anna
</pre>

<p> There are 42 distinct authors; the display above shows a few of the 14
singletons, and the five most prolific.  Interestingly, the top two are
women.  Guessing from names, there are only a handful of other female
authors.  One might wonder why over 40% of the sonnets are by two women.

How the data was created is a very important consideration for any
dataset, and particularly for data in the humanities.  As Meredith puts
it, <b>there is no such thing as raw data</b>; all datasets are the result of a
selection and curation process.  Historically, this has often been to
the detriment of some classes of authors.

</p><p> As a peripheral question, how many lines did Anna Seward and
Charlotte Turner Smith write?

</p><pre>awk -F/ '/Anna/ { anna += $5 }; /Charlotte/ { char += $5 }; END {print anna, char}' 18.csv
1456 1706
</pre>

Seward wrote fewer lines because all her sonnets were 14 lines long.

<h4>When did they live and die?</h4>

The first two fields are the birth and death dates for each author,
so we can explore questions about the ages of the authors.

The age is just <tt>$2-$1</tt>:

<pre>$ awk -F/ '{age[$3 " " $4] = $2 - $1}
    END {for (i in age) print age[i], i}' 18.csv | sort -n
-1807 M. F. Cogswell
0 A. M. Bradford
0 G. Bent
0 J. Cole
0 R. Hole
0 _ Anon.
0 author_fname author_lname
23 Henry Headley
...
79 John, Mrs. Hunter
81 Christopher Anstey
81 Thomas James Mathias
83 Anne MacVicar Grant
84 William Crowe
88 William Lisle Bowles
</pre>

<p> This tells us pretty clearly that the dates need to be studied further,
most easily by looking for the ages that are zero or negative:

</p><pre>$ awk -F/ '$2-$1 &lt;= 0' 18.csv
1807fl.//M. F./Cogswell/8/SONNET,/Written after hearing a SONG sung by several SISTERS.
1807fl.//M. F./Cogswell/8/THE SMILE./SONNET TO CAROLINE.
_/_/_/Anon./14/SONNET./
_/_/A. M./Bradford/14/To the SAME./
_/_/J./Cole/14/To the SAME./
_/_/G./Bent/66/To the SAME,/On receiving his Poems to Thespia with a Sonnet prefixed.
_/_/R./Hole/14/To the SAME,/On his Poems addressed to Thespia.
</pre>

<p> What do we do about entries like R. Hole and the often prolific
Anon, whose date fields are marked with <tt>_</tt>?

</p><p> What's with M. F. Cogswell?  He flourished around 1807, with two
8-line sonnets.  Actually, this entry shows one way in which Awk differs
from Python, often usefully.  When converting an arbitrary string to a
number, Awk uses the longest prefix that looks like a number, so
<tt>1807fl.</tt> has numeric value 1807; Awk processes that and
carries on.  Python, by contrast, will
throw an exception that, unless explicitly caught, will terminate execution.

</p><p> Neither of these deals with the real issue, which is that the data
is incomplete so an age computation isn't possible.

One simple solution, appropriate when unknown dates are
a small fraction of the data, is to ignore those records.
Regular expressions are the easiest way to select the good bits
or reject the bad ones:

</p><pre>$ awk -F/ '$1 ~ /^[0-9]+$/ &amp;&amp; $2 ~ /^[0-9]+$/ {print $2-$1, $3, $4}' 18.csv | uniq | sort -n | uniq
23 Henry Headley
25 Richard Gall
26 Thomas Russell
27 E. H. (Elihu Hubbard) Smith
37 Robert Burns
...
79 John, Mrs. Hunter
81 Christopher Anstey
83 Anne MacVicar Grant
84 William Crowe
88 William Lisle Bowles
</pre>

Rather than repeating the test over and over again,
we could collect all the lines that have valid dates in a new
temporary file, then do some further computations on that.

<pre>$ awk -F/ '$1 ~ /^[0-9]+$/ &amp;&amp; $2 ~ /^[0-9]+$/' 18.csv &gt;temp
$ wc temp
     486    3350   35265 temp
</pre>

<p> After that, we can compute the average age, and determine
the youngest and oldest.

</p><pre>$ awk -F/ '{ ages = ages + $2 - $1 } # add up all the ages
       END { print "average age =", ages / NR }' temp
average age = 60.2942
$ awk -F/ '$2-$1 &gt; max { max = $2 - $1; fname = $3; lname = $4 }
       END { print "oldest:", fname, lname, " age", max }' temp
oldest: William Lisle Bowles  age 88
</pre>

<p> As noted above, the author names are not contiguous, and the dates
are not in any obvious order either, which makes one wonder what order
the data has been sorted into.

How would you detect such anomalies mechanically in a larger dataset, in
particular if it were not related to dates)?

</p><h4> Associative Arrays </h4>

None of the examples so far have used associative arrays, which are Awk's
only data structure.  We didn't spend much if any time on associative
arrays in the class, since it felt like a slightly too-advanced topic
for our population.

<p> An associative array, equivalent to a hash in Java or a dictionary
in Python, is an array whose subscripts are not integers but arbitrary strings.

Several of the examples above that used <tt>sort|uniq -c</tt> can be
written equivalently with associative arrays to bring together
identical items.  For example, to see the distribution of sonnet lengths,
we can write:

</p><pre># awk -F/ '{print $5}' 18.csv | sort | uniq -c | sort -nr

$ awk -F/ '{ len[$5]++ }; END { for (i in len) print len[i], i }' 18.csv | sort -nr
</pre>

This produces the same result as the previous version.  We could even
embed the sort command in the Awk program:

<pre>$ awk -F/ '{ len[$5]++ }; END { for (i in len) print len[i], i | "sort -nr" }' 18.csv
</pre>

This computation is essentially the same as the Pandas <tt>unique_id</tt>
dataframe function.



<h4> Wrap-up </h4>

Awk is good for the kind of preliminary analysis we've
shown here, particularly when coupled with basic Unix
tools like <tt>sort</tt>, <tt>uniq</tt>, and <tt>wc</tt>.

At some point it's time to switch to Python and some
of its libraries, especially for plotting, but that
can be deferred until you really understand what's in the
data and where it might be flaky.



</div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Tell HN: Postman update removes all your stuff if you refuse to create account (316 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=37792690</link>
            <guid>37792690</guid>
            <pubDate>Fri, 06 Oct 2023 16:14:54 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=37792690">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="37794463"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37794463" href="https://news.ycombinator.com/vote?id=37794463&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>There are some extensions for VSCode that let you define your requests in a text file and has ways to run the file and show the data.<p>Here's one I just found:
<a href="https://marketplace.visualstudio.com/items?itemName=humao.rest-client" rel="nofollow noreferrer">https://marketplace.visualstudio.com/items?itemName=humao.re...</a></p><p>Syntax looks like:</p><pre><code>    GET https://example.com/comments/1 HTTP/1.1

    ###

    GET https://example.com/topics/1 HTTP/1.1

    ###

    POST https://example.com/comments HTTP/1.1
    content-type: application/json

    {
        "name": "sample",
        "time": "Wed, 21 Oct 2015 18:27:50 GMT"
    }</code></pre></span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37794702"><td></td></tr>
            <tr id="37794787"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37794787" href="https://news.ycombinator.com/vote?id=37794787&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>I use the VS Code REST extension a lot but it does lack some of the aspects that make Postman easier for teams and larger projects. It's super easy to define a "collection" as an .http page for smaller and one-off needs though.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37794727"><td></td></tr>
                <tr id="37794906"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37794906" href="https://news.ycombinator.com/vote?id=37794906&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>Yep, me to. Since it's just textfiles I can have them checked into git and share them. Credentials stays in a separate environments file (not checked in). I'm pretty happy with this setup.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37794919"><td></td></tr>
            <tr id="37795224"><td></td></tr>
                <tr id="37795299"><td></td></tr>
                        <tr id="37794371"><td></td></tr>
                <tr id="37795031"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37795031" href="https://news.ycombinator.com/vote?id=37795031&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><p><span>I almost ignored HTTPie as a Postman alternative because I thought it was CLI only but learned that it has a GUI now. Unfortunately the GUI seems to be proprietary.<p>Also we were looking for HTTP/2 support which neither Postman not HTTPie have and found xh which is a HTTPie clone in Rust.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37794715"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37794715" href="https://news.ycombinator.com/vote?id=37794715&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>On windows I even got to enjoy using Invoke-WebRequest directly. Extremely useful since powershell has structured output and input.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37795002"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37795002" href="https://news.ycombinator.com/vote?id=37795002&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>I also found it surprisingly how pleasant this was. For all Powershell’s quirks, this is one of those features that just makes sense to me.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37795033"><td></td></tr>
                <tr id="37795257"><td></td></tr>
                        <tr id="37792914"><td></td></tr>
                <tr id="37794762"><td></td></tr>
                <tr id="37795114"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37795114" href="https://news.ycombinator.com/vote?id=37795114&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><p><span>If you updated to v8 and missed the one small text link to export your data before creating an account, then all of your data was gone. Fortunately you could go to Github and download an old version.<p>If you created an account all of the data was still there. By default the "scratchpad" that did not require an account would not show anything.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37794921"><td></td></tr>
            <tr id="37794839"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37794839" href="https://news.ycombinator.com/vote?id=37794839&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>Plenty of users reported that updating, being prompted to create an account, and then refusing denied them access to their requests.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37794557"><td></td></tr>
                <tr id="37795018"><td></td></tr>
            <tr id="37794798"><td></td></tr>
                        <tr id="37794246"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37794246" href="https://news.ycombinator.com/vote?id=37794246&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><p><span>Yes, it happened to me as well.<p>Fortunately I regularly export the collections that still matter.</p><p>Now I am no longer a Postman user, as due to NDA's we aren't allowed to store project data on them.</p><p>Paying was never an issue, not having a secure alternative is what killed it for us.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37795475"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37795475" href="https://news.ycombinator.com/vote?id=37795475&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>Not very surprised, Postman has continued to get more bloated and pushy with accounts, I ended up just moving to Insomnia after using Postman for many many years.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37793874"><td></td></tr>
                <tr id="37794739"><td></td></tr>
                <tr id="37794851"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37794851" href="https://news.ycombinator.com/vote?id=37794851&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>The one thing I'm afraid of is that it's a single maintainer project, and while they are active now, I'm not sure how this is going to fare in a few months or so.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37793918"><td></td></tr>
                  <tr id="37794357"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37794357" href="https://news.ycombinator.com/vote?id=37794357&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><p><span>As one of the creators, I can recommmend <a href="https://kreya.app/" rel="nofollow noreferrer">https://kreya.app</a>. It is not open source (like Postman), but has a strong focus on privacy and also stores the data locally.<p>As it has more powerful features (IMO) than most alternatives listed here, I am a little disappointed that it isn't mentioned more often.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37794704"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37794704" href="https://news.ycombinator.com/vote?id=37794704&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>Kreya is the only alternative I've used that prioritizes gRPC support (along with REST). Regardless of source availability, thank you for creating this!</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37795038"><td></td></tr>
                        <tr id="37794712"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37794712" href="https://news.ycombinator.com/vote?id=37794712&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>Highly recommend the HTTP client in the JetBrains IDEs. I looked carefully at the standalones in this category and IMHO it’s the best. Text based so you can seamlessly manage everything with your repo, with automatic features built in from parsing the text.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37795078"><td></td></tr>
                  <tr id="37794902"><td></td></tr>
            <tr id="37794774"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37794774" href="https://news.ycombinator.com/vote?id=37794774&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>Am I crazy for using curl and editing the shell cmdline with vim when I need to work with lots of headers?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37795180"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37795180" href="https://news.ycombinator.com/vote?id=37795180&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>No, I use curl similarly and a lot. Where I find Postman convenient is when using it against services that use OAuth2. You authenticate once, it fetches the token and you are good to go. Could I script this with curl? Sure. Do I want to? Nah.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37794878"><td></td></tr>
                <tr id="37795042"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37795042" href="https://news.ycombinator.com/vote?id=37795042&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><p><span>I’m not a curl pro but devtools ‘copy as curl’ gets me 95% there most of the time.<p>That said, thanks! Didn’t know about this. Definitely adding to the toolbox.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="37794374"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37794374" href="https://news.ycombinator.com/vote?id=37794374&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>After the whiffs of enshittification caught my nose I did some research and switched over to Insomnia. I don’t make use of any advanced features, just a pre request authentication call that was a little bit of a pain to set up. But it’s working exactly how I was using postman so it’s a suitable replacement for me</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37794413"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37794413" href="https://news.ycombinator.com/vote?id=37794413&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>Didn't they just push a similar update where they require an account? And pushed all data into their cloud sync without asking?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37794550"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37794550" href="https://news.ycombinator.com/vote?id=37794550&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>When I switched over they made it clear they were getting rid of offline mode. So I said whiffs but at that point there was a turd halfway up my nose</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="37794462"><td></td></tr>
                <tr id="37795261"><td></td></tr>
            <tr id="37794520"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37794520" href="https://news.ycombinator.com/vote?id=37794520&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>I really like restclient - also really makes sense for persisting tests in this manner to source control.  Not that anybody else on your team will know how to use it...</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37794238"><td></td></tr>
            <tr id="37795066"><td></td></tr>
                <tr id="37795431"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37795431" href="https://news.ycombinator.com/vote?id=37795431&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>yeah, this one is the only thing that i'm missing after migration to linux box. the extensions and ability to write own extensions is very powerful, the speed and native UI were very welcomed, as postman and other electron based tools are just way too heavy for me.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37794862"><td></td></tr>
            <tr id="37794976"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37794976" href="https://news.ycombinator.com/vote?id=37794976&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><p><span>Is that what happened? I DO have an account (begrudgingly made because it doesn't just let you do a JSON export of your collections, you have to send it to the cloud and then download it for some baffling reason) and last time I opened it all of my environment variable values were wiped.<p>I've been wanting to get off Postman for a while. It's so clunky these days, and they're shoving way too much shit in it that I don't care about.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37794640"><td></td></tr>
            <tr id="37794847"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37794847" href="https://news.ycombinator.com/vote?id=37794847&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><p><span>Is this all stuff that you had kept in your Scratchpad? I think Postman had been warning users for months that Scratchpad would be going away, and that you should migrate everything to a workspace.<p>I'm not saying the decision is <i>right</i>; personally I much preferred the scratch, because it didn't require a freaking network request every time I want to look at my API collections. I'm just saying, this didn't come out of nowhere.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37794942"><td></td></tr>
                <tr id="37794970"><td></td></tr>
                  <tr id="37794286"><td></td></tr>
                <tr id="37794824"><td></td></tr>
                  <tr id="37794956"><td></td></tr>
            <tr id="37794365"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37794365" href="https://news.ycombinator.com/vote?id=37794365&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><p><span>another alternative: RapidAPI <a href="https://rapidapi.com/" rel="nofollow noreferrer">https://rapidapi.com/</a><p>it's a good api client, and it's free for individual use and they have some sort of nifty marketplace integration catalog...thing with remote API servers that makes it easy to find and try API services that offer data / functionality you want to connect to.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37794920"><td></td></tr>
            <tr id="37794936"><td></td></tr>
                  <tr id="37794697"><td></td></tr>
                <tr id="37794721"><td></td></tr>
                <tr id="37794757"><td></td></tr>
                  <tr id="37794722"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37794722" href="https://news.ycombinator.com/vote?id=37794722&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>I lost everything in a update with them too. And not a create-account update. Just a regular update one day, and <i>poof</i> gone.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37794529"><td></td></tr>
                <tr id="37795464"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37795464" href="https://news.ycombinator.com/vote?id=37795464&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>the mac client probably wont, as they were already bought by rapidapi.com and made web-based client that looks like PAW but has the same issues as other web-based solution</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37794636"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37794636" href="https://news.ycombinator.com/vote?id=37794636&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>I'm not sure why you're downvoted. I still use paw/rapidapi and I think it's great. Maybe downvoters can explain.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37794961"><td></td></tr>
            <tr id="37792871"><td></td></tr>
            <tr id="37794097"><td></td></tr>
            <tr id="37794130"><td></td></tr>
            <tr id="37794047"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37794047" href="https://news.ycombinator.com/vote?id=37794047&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><p><span>Learn and use curl, then you won’t have any issues like this. You can make some scripts in Python or something, too.<p>I say this because the last three tools I used for this all got shitty (postman, insomnia, and thunder client).
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37794177"><td></td></tr>
                <tr id="37795000"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37795000" href="https://news.ycombinator.com/vote?id=37795000&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>Seriously, python with the requests lib in a jupyter notebook is always a nicer user experience than any REST API GUI, most importantly once it's grown a bit.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37794352"><td></td></tr>
            <tr id="37794223"><td></td></tr>
                <tr id="37794420"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37794420" href="https://news.ycombinator.com/vote?id=37794420&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>Depends how comfortable you are with curl and your workflow. I'm much more productive using curl vs any GUI you give me. Still have OpenAPI specs in my projects but curl is much faster initially.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37794765"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_37794765" href="https://news.ycombinator.com/vote?id=37794765&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>It falls apart instantly when you need to pass data from one endpoint to another or add any sort of logic like filtering through data - so any time you have non-trivial workloads where you don't want to spend half your time fighting against jq or shell.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37795230"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_37795230" href="https://news.ycombinator.com/vote?id=37795230&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>You don’t have to fight tools if you learn them, but I understand— as a fellow programmer— that you don’t always have time to learn them. However, it’s pretty easy to use pipes and tools like jq to do complex stuff.</span></p></div></td></tr>
        </tbody></table></td></tr>
                              <tr id="37794570"><td></td></tr>
                <tr id="37794751"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37794751" href="https://news.ycombinator.com/vote?id=37794751&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>I think you're joking, but I actually want to know these things when adopting tools now to the extent that it's applicable.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37794254"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37794254" href="https://news.ycombinator.com/vote?id=37794254&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><p><span>for individual users, i've not quite got the appeal of postman.<p>in larger teams, I did see groups of people collaboratively creating various urls/scripts/tests, and putting some docs with them, to help with the dev and testing (mostly qa/test folks).  that was, imo, a relatively legitimate use for a full tool like postman.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37794242"><td></td></tr>
                  <tr id="37794348"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37794348" href="https://news.ycombinator.com/vote?id=37794348&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>Same. Quite a surprise. I switched to IntelliJ http requests and am seeing how that does for me.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37794318"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37794318" href="https://news.ycombinator.com/vote?id=37794318&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><p><span>I'm sure it's a bug, they have nothing to gain from it, especially if there's no warning about this.<p>It's also a good reminder for everyone to back up everything!
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37794747"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37794747" href="https://news.ycombinator.com/vote?id=37794747&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>It's not a bug to release a version which removed a massive chunk of functionality. It's intentionally fucking over their users who are not willing to create an account.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37794650"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37794650" href="https://news.ycombinator.com/vote?id=37794650&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><p><span>&gt; Any alternatives that I can migrate to?<p>If it works for your use case: writing integration tests.</p><p>I used Postman in the past but I never really got the point of "storing" queries beyond the history.</p><p>I think if you have that need it means it's time to write a frontend to call your endpoints, or use integration tests.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37795014"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37795014" href="https://news.ycombinator.com/vote?id=37795014&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><p><span>I’ve used alternatives to explore under-documented APIs interactively and suss out their behavior. Then I could use the app’s codegen to turn the query I’d manually crafted into my chosen language’s code.<p>You can do all that directly in the language, of course, but by the time you go through the trouble of pretty printing the output, parametrizing the input, etc, you’ve reimplemented a less ergonomic version of Postman-and-similar.</p><p>(Not saying you’re wrong for doing it your way, but explaining why others might choose a different approach.)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="37794857"><td></td></tr>
                <tr id="37794950"><td></td></tr>
                  <tr id="37794189"><td></td></tr>
                <tr id="37794553"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37794553" href="https://news.ycombinator.com/vote?id=37794553&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>Disappointing that there isn't a standalone program like Postman. I don't want to install an extension in my browser to handle CORS.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37794953"><td></td></tr>
            <tr id="37794792"><td></td></tr>
                <tr id="37794887"><td></td></tr>
                <tr id="37794992"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_37794992" href="https://news.ycombinator.com/vote?id=37794992&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>Having a dedicated browser profile is a good solution to this if you’re ever uncomfortable with a particular extension.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37794979"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_37794979" href="https://news.ycombinator.com/vote?id=37794979&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><p><span>Running standalone binaries by a VC-fueled project on your host is even worse.<p>I guess a separate quarantine browser profile is the best of both worlds?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37794974"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_37794974" href="https://news.ycombinator.com/vote?id=37794974&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><p><span>Ah, I follow. I was confused because a small, open-source extension should be sufficient to handle sending test requests. Sounds like they're doing something much bigger than that.<p>POSTman started as an extension; hence my confusion. I was wondering if there was a technical issue I was unaware of.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                              <tr id="37794646"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37794646" href="https://news.ycombinator.com/vote?id=37794646&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>It's a non-starter for me if it requires an extension. I also think it's a matter of time before it goes the Insomnia/Postman route. I'd love to be proven wrong though.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37794848"><td></td></tr>
                  <tr id="37794544"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37794544" href="https://news.ycombinator.com/vote?id=37794544&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><p><span>But you raised VC funding right?<p>Insomnia was an alternative to Postman, raised VC funds, eventually needed to justify that, and suddenly accounts mattered more. They're currently on the same trajectory.</p><p>Insomnia is open source but just like OP experienced, a single update can do damage and it takes time for the community to react.</p><p>Is this the same company that raised? If so, are you exempt from that? Have you figured out some monetization scheme for what is essentially a glorified curl UI that doesn't incentivize account sign ups?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37794926"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37794926" href="https://news.ycombinator.com/vote?id=37794926&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>I wish tech product managers could get it through their skulls: creating and maintaining yet-another-account for yet-another-app is high friction and undesirable. If you're going to give me an ultimatum where I need to either create an account or stop using the app. 99% of the time I'm just going to stop using your app.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37794772"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37794772" href="https://news.ycombinator.com/vote?id=37794772&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><p><span>If it's just a "glorified curl UI" what's the problem? Just use curl, or build your own, if it's so trivial.<p>You are kicking the tires awfully hard for a solution to a problem you claim is easy.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37794990"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_37794990" href="https://news.ycombinator.com/vote?id=37794990&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><p><span>That’s actually what I do and did. I have a whole bunch of scripts that allow me to replicate a lot of what Postman did for me.<p>The problem with these VC companies is that they enter the market with a whole bunch of lies and I was convinced that building on my ad hoc scripts wasn’t very useful since there were multiple alternatives including open source ones.</p><p>It’s taken me a decade however to learn that if these projects are VC backed as opposed to having some sort of govt or heck, even a benevolent dictator, they will screw you.</p><p>And while I might have learnt this lesson, which so much of the knowledge ecosystem also being filled with VC backed individuals (including this very forum) a whole another generation of potential OS developers will learn the lesson also too late.</p><p>And that’s how Silicon Valley has built a massive eco system to suck money out of everything across the globe, especially open source, but not limited to it (taxis, restaurants, hoteling, everything…).
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37794995"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_37794995" href="https://news.ycombinator.com/vote?id=37794995&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>I think it's fair to criticize them given a fair number of alternatives in this thread (with their own shortcomings). It's kind of silly to post something to hackernews and not expect criticism.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37794562"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37794562" href="https://news.ycombinator.com/vote?id=37794562&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>Postman is also open source lol. Unless its donation driven without funding its all going to be the same.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37794700"><td></td></tr>
            <tr id="37794632"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_37794632" href="https://news.ycombinator.com/vote?id=37794632&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>Can't someone just locally fork one of these apps and use it forever without updating it?  What's actually different about manually poking APIs from one week to the next?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37794883"><td></td></tr>
                  <tr id="37794687"><td></td></tr>
                              <tr id="37794998"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37794998" href="https://news.ycombinator.com/vote?id=37794998&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><p><span>I would really like to see Chrome offering an alternative to Postman. For me, it feels natural, to have everything in one place.<p>What do others think?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37795037"><td></td></tr>
                <tr id="37795053"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37795053" href="https://news.ycombinator.com/vote?id=37795053&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>I checked out of postman for a few years. Color me confused in this thread until I figured that part out.</span></p></div></td></tr>
        </tbody></table></td></tr>
                        </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: A job application tracker with company reviews, recruiter autoresponder (218 pts)]]></title>
            <link>https://rolepad.com</link>
            <guid>37792507</guid>
            <pubDate>Fri, 06 Oct 2023 16:01:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://rolepad.com">https://rolepad.com</a>, See on <a href="https://news.ycombinator.com/item?id=37792507">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p><span>Whether you are actively looking for a job or not, Rolepad gives you the tools to stay organized and informed when opportunity knocks. It's free, easy, and convenient.</span></p></div><div><div><div><p><span>Track all the data</span></p><p><span>Capture every job application</span> and incoming opportunity. Record company facts, role details, interview stages, contact information, freeform notes, follow-up actions and more - <span>all in one place</span>.</p></div><p><img src="https://rolepad.com/assets/static/track.0735e958.png" alt="Details of an opportunity selected from a list"></p></div><div><div><p><span>Streamline your correspondence</span></p><p><span>Organize your conversations</span> with recruiters, interviewers, and hiring managers by sending the emails to <a href="mailto:save@rolepad.com">save@rolepad.com</a>.</p><p>Or forward them to <a href="mailto:no@rolepad.com">no@rolepad.com</a> to <span>decline with an automated response.</span></p></div><p><img src="https://rolepad.com/assets/static/email-no.fd9f58d9.png" alt="Automated decline message"><img src="https://rolepad.com/assets/static/email-save.b9655f16.png" alt="Assign email to opportunity"></p></div><div><div><p><span>Visualize your progress</span></p><p><span>Generate a diagram</span> highlighting your job search journey over time.<span> Share your progress</span> with others without revealing sensitive information.</p></div><p><img src="https://rolepad.com/assets/static/sankey.7ad37b65.jpg" alt="Sankey chart"></p></div><div><div><p><span>Share feedback and reviews</span></p><p>Were the interviews difficult? How quickly did the company respond? What was your offer like?</p><p><span>Share private feedback</span> with the company or <span>submit an anonymous review</span>. Explore the <a href="https://rolepad.com/companies">Reviews</a> to <span>gain insight</span> into company hiring processes.</p></div><p><img src="https://rolepad.com/assets/static/reviews.8ff0022f.png" alt="Company stats and reviews"></p></div></div><div><blockquote><span>“This has been the most straightforward, easiest, lowest friction tracker I've encountered, <span>ever :)”</span></span><p>Chris H., Software Engineer</p></blockquote></div><div><h3>Fast. Flexible. Free.</h3><h2>Still relying on emails and spreadsheets?</h2><h2>There is a better way!</h2><p>Track every job opportunity, capture the key details, visualize your progress, and gain critical insight from other applicants. Rolepad gives you <span>job search superpowers</span>.</p><p><a href="https://app.rolepad.com/">Get started now</a></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Shortbread – Create AI comics in minutes (201 pts)]]></title>
            <link>https://shortbread.ai/</link>
            <guid>37792444</guid>
            <pubDate>Fri, 06 Oct 2023 15:56:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://shortbread.ai/">https://shortbread.ai/</a>, See on <a href="https://news.ycombinator.com/item?id=37792444">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main" data-framer-hydrate-v2="{&quot;routeId&quot;:&quot;augiA20Il&quot;,&quot;localizationId&quot;:&quot;default&quot;,&quot;localeId&quot;:&quot;default&quot;}" data-framer-ssr-released-at="2023-09-27T07:53:51.711Z" data-framer-page-optimized-at="2023-10-03T01:23:55.661Z"><header data-framer-name="Landing" name="Landing"></header><div data-framer-name="Grid 1" name="Grid 1"><div data-framer-name="Content" name="Content"><p data-framer-component-type="RichTextContainer"><h2>Idea to Page in Seconds</h2></p><p data-styles-preset="GOagwD4oe">Begin with a spark—whether it's a storyline, a unique character, or a specific mood you want to capture. Just describe it, and let Shortbread transform your idea into a page, setting the stage for your artistry.</p></div><div data-framer-name="Content" name="Content"><p data-framer-component-type="RichTextContainer"><h2>Fine-Tune like a Pro</h2></p><p data-styles-preset="GOagwD4oe">Create with unparalleled control over each panel. Manipulate scenes, character poses, fine-tune facial expressions, and adjust camera angles to create your perfect shot.</p></div><div data-framer-name="Content" name="Content"><p data-framer-component-type="RichTextContainer"><h2>Pixel-Perfect Design</h2></p><p data-styles-preset="GOagwD4oe">Elevate the look of your comics with a rich selection of design elements. From speech bubbles to fonts, every pixel can be customized to enhance the flow your story.</p></div></div><section><p data-framer-component-type="RichTextContainer"><h2 data-styles-preset="stylesPresetHeading2">Frequently Asked Questions</h2></p></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Java 21 VirtualThreads vs. Clojure Lazy Seqs (from Clojure Deref 2023-10-06) (195 pts)]]></title>
            <link>https://clojure.org/news/2023/10/06/deref</link>
            <guid>37792294</guid>
            <pubDate>Fri, 06 Oct 2023 15:44:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://clojure.org/news/2023/10/06/deref">https://clojure.org/news/2023/10/06/deref</a>, See on <a href="https://news.ycombinator.com/item?id=37792294">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
      <p><em>06 October 2023</em><br>
         <em>Alex Miller</em></p>

      <div id="preamble">
<p>Welcome to the Clojure Deref! This is a weekly link/news roundup for the Clojure ecosystem (feed: <a href="https://clojure.org/feed.xml">RSS</a>). Thanks to Anton Fonarev for link aggregation.</p>
</div>
<div>
<h2 id="_from_the_core"><a href="#_from_the_core"></a>From the core</h2>
<div>
<p>Recently Java 21 was released (congrats!) and this has driven a lot of interest and experimentation with the new virtual threads feature. Virtual threads have the ability to park and resume a virtual thread (particularly one blocked on I/O) and this cooperates transparently with many blocking constructs in Java - I/O, sockets, java.util.concurrent.lock, etc. However, one thing it does not (yet) cooperate with is object monitors (synchronized) and thus doing a blocking call while holding a synchronized monitor prevents a virtual thread from parking (ie, "pins" the virtual thread). Note that synchronization itself is not inherently bad - normal use of synchronized to serialize reads and writes to fields is fine (as there is no blocking I/O that can pin a thread).</p>
<p>Several people doing new things with virtual threads have detected cases where user code is doing I/O blocking while Clojure is in a synchronization block, thus pinning threads. The two most important cases are lazy seqs and <code>delay</code> - both hold some suspended computation in a thunk and invoke the thunk under synchronization, thus allowing for the possibility of user I/O under a lock in the language level. As people have raised this as an issue, we have spent the last week taking a hard look at this area.</p>
<p>At a meta level, there are a bunch of options here and we have still not decided on our approach or timeframe. From a user level, it is possible to simply not do (or tolerate) I/O under delay or lazy seqs. Delay is a one-time thing, so it may not generally be an issue to pin a thread that is reading a config file as that is a one-time thing. Pulling I/O over a lazy seq is not uncommon and can definitely present this kind of issue, but there are a lot of other options - controlling via loop/recur, using transducers and <code>sequence</code>, etc. If you are experiencing this problem now, these are probably worth exploring.</p>
<p>We’ve spent a ton of time over the last week looking at the internals of LazySeq and options for avoiding synchronization. The general guidance from Java is to replace synchronized with ReentrantLock (which has virtual thread coordination), but this advice leaves out the inherent tradeoffs in that change. synchronized relies on object monitors which are built into every Java object at the JVM level, whereas ReentrantLocks are additional Java objects (which hold a reference to an internal Sync object). Clojure makes a lot of lazy seqs and allocating two objects (plus adding an additional field to LazySeq) for every lazy seq is a real cost in allocation, heap size, and GC. Additionally, while ReentrantLock seems to be a bit faster than synchronized in Java 21, LazySeq makes one reentrant call, and reentrant calls seems to be noticeably slower than synchronized. There are lots of options though. We think it’s relatively easy to make lazy seq walking faster, but a lot harder to keep realization costs under control (as making locks takes non-zero time). One interesting branch we have explored is making one lock per seq and passing it through the seq as we go - lots of tradeoffs in that.</p>
<p>Additionally, we continue to work on functional interface adapters and method thunks. With FI adapters, we continue to refine when implicit coercion and conversion occur and I think that draws asymptotically closer to completion. With method thunks, we have taken a bit of a detour to examine array class representation.</p>
<p>Generally, classes are represented by symbols that name the class, but this does not work for array classes as they cannot be represented as a valid symbol. The fallback right now is using a String that holds the internal class name, like <code>^"[Ljava.lang.String;"</code> which I think we can all agree is no fun. Our plan going forward is to support a new array class syntax which is a symbol of the class with a <code>*</code> suffix. Imported classes can use their short name, so <code>String*</code> will represent a Java <code>String[]</code> (or a <code>String…​</code> vararg). Multiple <code>**</code> will represent multidimensional arrays. This will work with both classes and with primitives, so <code>long*</code> will be a synonym for the existing <code>longs</code>. Rich also wishes you to notice the C pointer punnery. :)</p>
<p>That was a bit of a diversion, but I think it is a big win to fix a long-time representational gap. It also helps create some new "columns" in the varargs decision matrix, which is not going to be addressed in 1.12, but I think we have teed up to work on immediately after.</p>
</div>
</div>
<div>
<h2 id="_podcasts_and_videos"><a href="#_podcasts_and_videos"></a>Podcasts and videos</h2>

</div>
<div>
<h2 id="_blogs_articles_and_projects"><a href="#_blogs_articles_and_projects"></a>Blogs, articles, and projects</h2>

</div>
<div>
<p>New releases and tools this week:</p>
<div>
<ul>
<li>
<p><a href="https://github.com/holyjak/fulcro-troubleshooting">fulcro-troubleshooting</a> v7 - A development-time library for Fulcro that helps to detect problems earlier and find and fix their root cause faster</p>
</li>
<li>
<p><a href="https://github.com/holyjak/minimalist-fulcro-template-backendless">minimalist-fulcro-template-backendless</a>  - A minimal template for browser-only Fulcro apps for learning</p>
</li>
<li>
<p><a href="https://github.com/clojure-expectations/clojure-test">clojure-test</a> <a href="https://github.com/clojure-expectations/clojure-test/releases/tag/v2.1.182">2.1.182</a> - A clojure.test-compatible version of the classic Expectations testing library</p>
</li>
<li>
<p><a href="https://github.com/nextjournal/clerk">clerk</a> <a href="https://github.com/nextjournal/clerk/blob/9c38ff3ef240c9bd21e596792adb2ebdbb5a738d/CHANGELOG.md#015957-2023-09-28">0.15.957</a> - Moldable Live Programming for Clojure</p>
</li>
<li>
<p><a href="https://github.com/namenu/deps-diff">deps-diff</a> 1.1 - A tool for comparing transitive dependencies in two deps.edn files</p>
</li>
<li>
<p><a href="https://github.com/juji-io/datalevin">datalevin</a> <a href="https://github.com/juji-io/datalevin/blob/master/CHANGELOG.md">0.8.20</a> - A simple, fast and versatile Datalog database</p>
</li>
<li>
<p><a href="https://github.com/liquidz/antq">antq</a> <a href="https://github.com/liquidz/antq/releases/tag/2.7.1133">2.7.1133</a> - Point out your outdated dependencies</p>
</li>
<li>
<p><a href="https://github.com/eerohele/tab">tab</a> <a href="https://github.com/eerohele/tab/blob/main/CHANGELOG.md#2023-10-03">2023-10-03.333</a> - A tool for tabulating Clojure collections</p>
</li>
<li>
<p><a href="https://github.com/eerohele/pp">pp</a> 2023-10-05.5 - Pretty-print Clojure data structures, fast</p>
</li>
<li>
<p><a href="https://github.com/quoll/raphael">raphael</a> 0.3.0 - A Clojure library for parsing strings containing the Terse Triples Language: Turtle</p>
</li>
<li>
<p><a href="https://github.com/steffan-westcott/clj-otel">clj-otel</a> <a href="https://github.com/steffan-westcott/clj-otel/blob/master/CHANGELOG.adoc">0.2.4.1</a> - An idiomatic Clojure API for adding telemetry to your libraries and applications using OpenTelemetry</p>
</li>
<li>
<p><a href="https://github.com/babashka/neil">neil</a> <a href="https://github.com/babashka/neil/blob/main/CHANGELOG.md#0262">0.2.61</a> - A CLI to add common aliases and features to deps.edn-based projects</p>
</li>
<li>
<p><a href="https://github.com/squint-cljs/squint">squint</a> <a href="https://github.com/squint-cljs/squint/blob/main/CHANGELOG.md">0.2.30</a> - ClojureScript syntax to JavaScript compiler</p>
</li>
<li>
<p><a href="https://github.com/eerohele/Tutkain">Tutkain</a> <a href="https://github.com/eerohele/Tutkain/blob/master/CHANGELOG.md#0190-alpha---2023-10-03">0.19.0 (alpha)</a> - A Sublime Text package for interactive Clojure development</p>
</li>
<li>
<p><a href="https://github.com/squint-cljs/cherry">cherry</a> <a href="https://github.com/squint-cljs/cherry/blob/main/CHANGELOG.md">0.1.9</a> - Experimental ClojureScript to ES6 module compiler</p>
</li>
<li>
<p><a href="https://github.com/PEZ/taplet">taplet</a> <a href="https://github.com/PEZ/taplet/blob/master/CHANGELOG.md">1.0.58</a> - A Clojure/ClojureScript macro, let&gt; that works like a let, and also tap&gt;s the binding vector</p>
</li>
<li>
<p><a href="https://github.com/babashka/nbb">nbb</a> <a href="https://github.com/babashka/nbb/blob/main/CHANGELOG.md">1.2.179</a> - Scripting in Clojure on Node.js using SCI</p>
</li>
</ul>
</div>
</div>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Petscii Side-Scrolling Platformer by Jimbo (101 pts)]]></title>
            <link>https://jimbo.itch.io/petscii-side-scrolling-platformer</link>
            <guid>37792129</guid>
            <pubDate>Fri, 06 Oct 2023 15:31:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jimbo.itch.io/petscii-side-scrolling-platformer">https://jimbo.itch.io/petscii-side-scrolling-platformer</a>, See on <a href="https://news.ycombinator.com/item?id=37792129">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="wrapper"><div><p>The Commodore PET now has a multi-level side-scrolling platformer. Inspired by other side-scrolling platform games like Mario and Sonic. Run, jump, collect coins, crush henchmen, battle the bosses, rescue friends.</p><div><h2 id="download">Download</h2></div><div><h2 id="instructions">Install instructions</h2><p>For PET/CBM 2001 (32K required), 3032, 4032 and 8032.</p></div><div id="game_comments_2824560"><h2 id="comments">Comments</h2><p><a href="https://itch.io/login?return_to=https%3A%2F%2Fjimbo.itch.io%2Fpetscii-side-scrolling-platformer" data-register_action="comment">Log in with itch.io</a> to leave a comment.</p><div id="community_topic_posts_8124343"><div id="post-8695938" data-post="{&quot;id&quot;:8695938,&quot;user_id&quot;:971499}"><a href="https://itch.io/profile/cghijinks"></a><div><p>Front page HN 👌 Congrats 👏&nbsp;</p></div></div><div id="post-8676119" data-post="{&quot;id&quot;:8676119,&quot;user_id&quot;:1757640}"><a href="https://itch.io/profile/naggynaggerson"></a><div><p>Love this to bits! Made a PET-style cover for it :) <img src="https://img.itch.zone/aW1nLzEzNTk4MDIyLmpwZw==/original/veuWt5.jpg" loading="lazy"></p></div></div><div id="post-8667807" data-post="{&quot;id&quot;:8667807,&quot;user_id&quot;:4598661}"><a href="https://itch.io/profile/retroshaun"></a><div><p>This is a spectacular version of the classic! So much fun, great attention to detail and very very playable!</p></div></div><div id="post-8664137" data-post="{&quot;id&quot;:8664137,&quot;user_id&quot;:4937575}"><a href="https://itch.io/profile/koko74"></a><div><p>Hey Jim! I must say it's a true piece of art. I love the details in every aspect of the gameplay. Well done on creating such an incredible game!<br>Kornel</p></div></div><div id="post-8663767" data-post="{&quot;id&quot;:8663767,&quot;user_id&quot;:648359}"><a href="https://itch.io/profile/fuzzybad"></a><div><p>Love it! Super PETSCII Bros :D</p></div></div></div></div></div><div><div><p id="video_embed_884428"><iframe frameborder="0" allowfullscreen="" src="//www.youtube.com/embed/lApSXRx2Z90"></iframe></p></div><p><a data-image_lightbox="true" target="_blank" href="https://img.itch.zone/aW1hZ2UvMjI4OTQ5OS8xMzU2NjkyMS5wbmc=/original/B62TXm.png"><img src="https://img.itch.zone/aW1hZ2UvMjI4OTQ5OS8xMzU2NjkyMS5wbmc=/347x500/%2BBScX%2B.png" data-screenshot_id="13566921" srcset="https://img.itch.zone/aW1hZ2UvMjI4OTQ5OS8xMzU2NjkyMS5wbmc=/347x500/%2BBScX%2B.png 1x, https://img.itch.zone/aW1hZ2UvMjI4OTQ5OS8xMzU2NjkyMS5wbmc=/794x1000/TP2zmB.png 2x"></a><a data-image_lightbox="true" target="_blank" href="https://img.itch.zone/aW1hZ2UvMjI4OTQ5OS8xMzU2NjkyMy5wbmc=/original/7P44S2.png"><img src="https://img.itch.zone/aW1hZ2UvMjI4OTQ5OS8xMzU2NjkyMy5wbmc=/347x500/rqk32I.png" data-screenshot_id="13566923" srcset="https://img.itch.zone/aW1hZ2UvMjI4OTQ5OS8xMzU2NjkyMy5wbmc=/347x500/rqk32I.png 1x, https://img.itch.zone/aW1hZ2UvMjI4OTQ5OS8xMzU2NjkyMy5wbmc=/794x1000/Xcy9dA.png 2x"></a><a data-image_lightbox="true" target="_blank" href="https://img.itch.zone/aW1hZ2UvMjI4OTQ5OS8xMzU2NjkyMi5wbmc=/original/sCoQ1O.png"><img src="https://img.itch.zone/aW1hZ2UvMjI4OTQ5OS8xMzU2NjkyMi5wbmc=/347x500/NSWmXZ.png" data-screenshot_id="13566922" srcset="https://img.itch.zone/aW1hZ2UvMjI4OTQ5OS8xMzU2NjkyMi5wbmc=/347x500/NSWmXZ.png 1x, https://img.itch.zone/aW1hZ2UvMjI4OTQ5OS8xMzU2NjkyMi5wbmc=/794x1000/Xo5zvZ.png 2x"></a><a data-image_lightbox="true" target="_blank" href="https://img.itch.zone/aW1hZ2UvMjI4OTQ5OS8xMzU2NzAyNy5wbmc=/original/D8B8WN.png"><img src="https://img.itch.zone/aW1hZ2UvMjI4OTQ5OS8xMzU2NzAyNy5wbmc=/347x500/Bh6Rqj.png" data-screenshot_id="13567027" srcset="https://img.itch.zone/aW1hZ2UvMjI4OTQ5OS8xMzU2NzAyNy5wbmc=/347x500/Bh6Rqj.png 1x, https://img.itch.zone/aW1hZ2UvMjI4OTQ5OS8xMzU2NzAyNy5wbmc=/794x1000/UcgoBj.png 2x"></a></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What is in that .git directory? (108 pts)]]></title>
            <link>https://blog.meain.io/2023/what-is-in-dot-git/</link>
            <guid>37792097</guid>
            <pubDate>Fri, 06 Oct 2023 15:29:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.meain.io/2023/what-is-in-dot-git/">https://blog.meain.io/2023/what-is-in-dot-git/</a>, See on <a href="https://news.ycombinator.com/item?id=37792097">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      

<p> Oct 06, 2023 . 8 min </p>



<p>Well, I think most of you reading this blog use <code>git</code> more or less on a daily basis, but have you ever looked into what is in the <code>.git</code> folder that git creates? Let's explore it together and understand what is going on in there.</p>
<p><em>This is a blog version of a talk that I recently gave. Unfortunately I can't link to the recording :(.</em></p>
<blockquote>
<p><code>git</code> at a basic level is just a bunch of text files linked to each other by filenames.</p>
</blockquote>
<h2 id="lets-start-init" tabindex="-1">Lets <s>start</s> init <a href="#lets-start-init">#</a></h2>
<p>As you all know, we start our git journey with a <code>git init</code>. This gives the message that we all are probably used to by now, especially if you start and abandon a lot of side projects.</p>
<pre><code>Initialized empty Git repository in /home/meain/dev/src/git-talk/.git/
</code></pre>
<p>Let's look at what is in the <code>.git</code> repo as of now.</p>
<pre><code>$ tree .git

.git
├── config
├── HEAD
├── hooks
│&nbsp;&nbsp; └── prepare-commit-msg.msample
├── objects
│&nbsp;&nbsp; ├── info
│&nbsp;&nbsp; └── pack
└── refs
    ├── heads
    └── tags
</code></pre>
<p>It seems to create a bunch of files and folders. What are all these? Let's go over them one by one.</p>
<ul>
<li><code>config</code> is a text file that contains your git configuration for the current repo. If you look into it, you would see some basic settings for you repo like the author, filemode etc.</li>
<li><code>HEAD</code> contains the current head of the repo. Depending on what you have set your "default" branch to be, it will be <code>refs/heads/master</code> or <code>refs/heads/main</code> or whatever else you had set to. As you might have guessed, this is pointing to <code>refs/heads</code> folder that you can see below, and into a file called <code>master</code> which does not exist as of now. This file <code>master</code> will only show up after you make your first commit.</li>
<li><code>hooks</code> contain any scripts that can be run before/after git does anything. I have written another blog <a href="https://blog.meain.io/2019/making-sure-you-wont-commit-conflict-markers/">here</a> which goes a bit more into how git hooks work.</li>
<li><code>objects</code> contains the git objects, ie the data about the files, commits etc in your repo. We will go in depth into this in this blog.</li>
<li><code>refs</code> as we previously mentioned, stores references(pointers). <code>refs/heads</code> contains pointers to branches and <code>refs/tags</code> contains pointers to tags. We will go into what these files look like soon.</li>
</ul>
<h2 id="now-we-add-a-file" tabindex="-1">Now we add a file <a href="#now-we-add-a-file">#</a></h2>
<p>Now that you have an idea of what the initial set of files in <code>.git</code> is, let's perform the first action that adds something into the <code>.git</code> directory. Let's create a file and add it(we are not committing it yet).</p>
<pre><code><span>echo</span> <span>'meain.io'</span> <span>&gt;</span> <span>file</span><br><span>git</span> <span>add</span> <span>file</span></code></pre>
<p>This does the following:</p>
<pre><code><span>--- init       2024-07-02 15:14:00.584674816 +0530</span><br><span>+++ add        2023-07-02 15:13:53.869525054 +0530</span><br><span>@@ -3,7 +3,10 @@</span><br><span><span> </span><span>├── HEAD<br></span><span> </span><span>├── hooks<br></span><span> </span><span>│   └── prepare-commit-msg.msample<br></span></span><span><span>+</span><span>├── index<br></span></span><span><span> </span><span>├── objects<br></span></span><span><span>+</span><span>│   ├── 4c<br></span><span>+</span><span>│   │   └── 5b58f323d7b459664b5d3fb9587048bb0296de<br></span></span><span><span> </span><span>│   ├── info<br></span><span> </span><span>│   └── pack<br></span><span> </span><span>└── refs</span></span></code></pre>
<p>This causes two main changes as you can see. The first thing it modifies is the <code>index</code> file. The <a href="https://git-scm.com/docs/index-format">index</a> is what stores the information about what is currently staged. This is used to signify that the file named <code>file</code> has been added to the index.</p>
<p>The second and more important change is the addition of a new folder <code>objects/4c</code> and a file <code>5b58f323d7b459664b5d3fb9587048bb0296de</code> inside it.</p>
<h2 id="but-what-is-in-that-file%3F" tabindex="-1">But what is in that file? <a href="#but-what-is-in-that-file%3F">#</a></h2>
<p>Here is where we get into the details of how <code>git</code> stores things. Let's start with looking at what kind of data is present in that.</p>
<pre><code>$ <span>file</span> .git/objects/5c/5b58f323d7b459664b5d3fb9587048bb0296de<br>.git/objects/4c/5b58f323d7b459664b5d3fb9587048bb0296de: zlib compressed data</code></pre>
<p>Hmm, but what is the zlib compressed data?</p>
<pre><code>$ zlib-flate <span>-uncompress</span> <span>&lt;</span>.git/objects/4c/5b58f323d7b459664b5d3fb9587048bb0296de<br>blob <span>9</span><span>\</span>0meain.io</code></pre>
<p>Looks like it contains the type, size and data of the file named <code>file</code> that we did a <code>git add</code> on. In this case, the data says that it is a <code>blob</code> of size <code>9</code> and the content is <code>meain.io</code>.</p>
<h2 id="ok%2C-but-what-is-with-that-filename%3F" tabindex="-1">OK, but what is with that filename? <a href="#ok%2C-but-what-is-with-that-filename%3F">#</a></h2>
<p>Well, good question. It comes from the sha1 of the content. If you take the zlib compressed data and pipe it through <code>sha1sum</code>, you get the filename.</p>
<pre><code>$ zlib-flate <span>-uncompress</span> <span>&lt;</span>.git/objects/4c/5b58f323d7b459664b5d3fb9587048bb0296de<span>|</span>sha1sum<br>4c5b58f323d7b459664b5d3fb9587048bb0296de</code></pre>
<p><code>git</code> takes the sha1 of the content to be written, takes the first two characters, in this case <code>4c</code>, creates a folder and then uses the rest of it as the filename. <code>git</code> creates folders from the first two chars to make sure we don't have too many files under the single <code>objects</code> folder.</p>
<h2 id="say-hello-to-git-cat-file" tabindex="-1">Say hello to <code>git cat-file</code> <a href="#say-hello-to-git-cat-file">#</a></h2>
<p>In fact, since this is one of the more important parts of git, git also has a plumbing command to view the content of an object. You can use <code>git cat-file</code> with <code>-t</code> for type, <code>-s</code> for size and <code>-p</code> for content.</p>
<pre><code>$ <span>git</span> cat-file <span>-t</span> 4c5b58f323d7b459664b5d3fb9587048bb0296de<br>blob<p>$ <span>git</span> cat-file <span>-s</span> 4c5b58f323d7b459664b5d3fb9587048bb0296de<br><span>9</span></p><p>$ <span>git</span> cat-file <span>-p</span> 4c5b58f323d7b459664b5d3fb9587048bb0296de<br>meain.io</p></code></pre>
<h2 id="let's-commit" tabindex="-1">Let's commit <a href="#let's-commit">#</a></h2>
<p>Now that we know what changes when we add a file, let's take this to the next level by committing.</p>
<pre><code>$ <span>git</span> commit <span>-m</span> <span>'Initial commit'</span><br><span>[</span>master <span>(</span>root-commit<span>)</span> 4c201df<span>]</span> Initial commit<br> <span>1</span> <span>file</span> changed, <span>1</span> insertion<span>(</span>+<span>)</span><br> create mode <span>100644</span> <span>file</span></code></pre>
<p>Here is what changed:</p>
<pre><code><span>--- init        2024-07-02 15:14:00.584674816 +0530</span><br><span>+++ commit      2023-07-02 15:33:28.536144046 +0530</span><br><span>@@ -1,11 +1,25 @@</span><br><span><span> </span><span>.git<br></span></span><span><span>+</span><span>├── COMMIT_EDITMSG<br></span></span><span><span> </span><span>├── config<br></span><span> </span><span>├── HEAD<br></span><span> </span><span>├── hooks<br></span><span> </span><span>│   └── prepare-commit-msg.msample<br></span><span> </span><span>├── index<br></span></span><span><span>+</span><span>├── logs<br></span><span>+</span><span>│   ├── HEAD<br></span><span>+</span><span>│   └── refs<br></span><span>+</span><span>│       └── heads<br></span><span>+</span><span>│           └── master<br></span></span><span><span> </span><span>├── objects<br></span></span><span><span>+</span><span>│   ├── 3c<br></span><span>+</span><span>│   │   └── 201df6a1c4d4c87177e30e93be1df8bfe2fe19<br></span></span><span><span> </span><span>│   ├── 4c<br></span><span> </span><span>│   │   └── 5b58f323d7b459664b5d3fb9587048bb0296de<br></span></span><span><span>+</span><span>│   ├── 62<br></span><span>+</span><span>│   │   └── 901ec0eca9faceb8fe0a9870b9b6cde75a9545<br></span></span><span><span> </span><span>│   ├── info<br></span><span> </span><span>│   └── pack<br></span><span> </span><span>└── refs<br></span><span> </span><span>    ├── heads<br></span></span><span><span>+</span><span>    │   └── master<br></span></span><span><span> </span><span>    └── tags</span></span></code></pre>
<p>Woah, looks like there are a bunch of changes. Let's walk through them one by one. The first one is a new file <code>COMMIT_EDITMSG</code>. As the name might suggest, it contains the (last) commit message.</p>
<p><em>If you where to run the <code>git commit</code> command without the <code>-m</code> flag, the way <code>git</code> gets a commit message is to open an editor with the <code>COMMIT_EDITMSG</code> file to let the user edit the commit message and once the user has updated it and exited the editor, <code>git</code> uses the contents of the file as the commit message.</em></p>
<p>It also added a whole new folder <code>logs</code>. This is a way for git to log all the commits changes in a repo. You will be able to see the changes in commits for all refs and <code>HEAD</code> here.</p>
<p>The <code>object</code> dir also got some changes, but I want you to first look into the <code>refs/heads</code> directory where we now have the file <code>master</code>. This as you might have guessed is the reference to the <code>master</code> branch. Let's see what is in it.</p>
<pre><code>$ <span>cat</span> refs/heads/master<br>3c201df6a1c4d4c87177e30e93be1df8bfe2fe19</code></pre>
<p>Looks like it is pointing to one of the new objects. We know how to look at objects, let's do that.</p>
<pre><code>$ <span>git</span> cat-file <span>-t</span> 3c201df6a1c4d4c87177e30e93be1df8bfe2fe19<br>commit<p>$ <span>git</span> cat-file <span>-p</span> 3c201df6a1c4d4c87177e30e93be1df8bfe2fe19<br>tree 62902ec0eca9faceb8fe0a9870b9b6cde75a9545<br>author Abin Simon <span>&lt;</span>mail@meain.io<span>&gt;</span> <span>1688292123</span> +0530<br>committer Abin Simon <span>&lt;</span>mail@meain.io<span>&gt;</span> <span>1688292123</span> +0530</p><p>Initial commit</p></code></pre>
<blockquote>
<p>You could have also done <code>git cat-file -t refs/heads/master</code></p>
</blockquote>
<p>Well, looks like that is new kind of object. This seems to be a <code>commit</code> object. The contents of the <code>commit</code> object tells us that it contains a <code>tree</code> object with the hash <code>62902ec0eca9faceb8fe0a9870b9b6cde75a9545</code>, which looks like the other object that got added when we did the commit. The <code>commit</code> object also has the information about who the author and committer is, which in this case is both me. Lastly is also shows what the commit message for this commit was.</p>
<p>Now let's look at what the <code>tree</code> object contains.</p>
<pre><code>$ <span>git</span> cat-file <span>-t</span> 62902ec0eca9faceb8fe0a9870b9b6cde75a9545<br>tree<p>$ <span>git</span> cat-file <span>-p</span> 62901ec0eca9faceb8fe0a9870b9b6cde75a9545<br><span>100644</span> blob 4c5b58f323d7b459664b5d3fb9587048bb0296de    <span>file</span></p></code></pre>
<p>A <code>tree</code> object will contain the state of working directory in the form of other tree and blob objects. In this case, since we just have a single file named <code>file</code>, you will just see a single object. If you see, the file is pointing to the original object that got added when we did a <code>git add file</code>.</p>
<p>Here is what a tree for a more mature repo look like. More <code>tree</code> objects are used inside <code>tree</code> object linked from the <code>commit</code> object to denote folders.</p>
<pre><code>$ git cat-file -p 2e5e84c3ee1f7e4cb3f709ff5ca0ddfc259a8d04
100644 blob 3cf56579491f151d82b384c211cf1971c300fbf8    .dockerignore
100644 blob 02c348c202dd41f90e66cfeb36ebbd928677cff6    .gitattributes
040000 tree ab2ba080c4c3e4f2bc643ae29d5040f85aca2551    .github
100644 blob bdda0724b18c16e69b800e5e887ed2a8a210c936    .gitignore
100644 blob 3a592bc0200af2fd5e3e9d2790038845f3a5cf9b    CHANGELOG.md
100644 blob 71a7a8c5aacbcaccf56740ce16a6c5544783d095    CODE_OF_CONDUCT.md
100644 blob f433b1a53f5b830a205fd2df78e2b34974656c7b    LICENSE
100644 blob 413072d502db332006536e1af3fad0dce570e727    README.md
100644 blob 1dd7ed99019efd6d872d5f6764115a86b5121ae9    SECURITY.md
040000 tree 918756f1a4e5d648ae273801359c440c951555f9    build
040000 tree 219a6e58af53f2e53b14b710a2dd8cbe9fea15f5    design
040000 tree 5810c119dd4d9a1c033c38c12fae781aeffeafc1    docker
040000 tree f09c5708676cdca6562f10e1f36c9cfd7ee45e07    src
040000 tree e6e1595f412599d0627a9e634007fcb2e32b62e5    website
</code></pre>
<h2 id="making-a-change" tabindex="-1">Making a change <a href="#making-a-change">#</a></h2>
<p>Let's make a change to the file and see how that works.</p>
<pre><code>$ <span>echo</span> <span>'blog.meain.io'</span> <span>&gt;</span> <span>file</span><br>$ <span>git</span> commit <span>-am</span> <span>'Use blog link'</span><br><span>[</span>master 68ed5aa<span>]</span> Use blog <span>link</span><br> <span>1</span> <span>file</span> changed, <span>1</span> insertion<span>(</span>+<span>)</span>, <span>1</span> deletion<span>(</span>-<span>)</span></code></pre>
<p>Here is what it does:</p>
<pre><code><span>--- commit      2024-07-02 15:33:28.536144046 +0530</span><br><span>+++ update      2023-07-02 15:47:20.841154907 +0530</span><br><span>@@ -17,6 +17,12 @@</span><br><span><span> </span><span>│   │   └── 5b58f323d7b459664b5d3fb9587048bb0296de<br></span><span> </span><span>│   ├── 62<br></span><span> </span><span>│   │   └── 901ec0eca9faceb8fe0a9870b9b6cde75a9545<br></span></span><span><span>+</span><span>│   ├── 67<br></span><span>+</span><span>│   │   └── ed5aa2372445cf2249d85573ade1c0cbb312b1<br></span><span>+</span><span>│   ├── 8a<br></span><span>+</span><span>│   │   └── b377e2f9acd9eaca12e750a7d3cb345065049e<br></span><span>+</span><span>│   ├── e5<br></span><span>+</span><span>│   │   └── ec63cd761e6ab9d11e7dc2c4c2752d682b36e2<br></span></span><span><span> </span><span>│   ├── info<br></span><span> </span><span>│   └── pack<br></span><span> </span><span>└── refs</span></span></code></pre>
<p>Well, we added 3 new objects. One of them would be a <code>blob</code> object with the new contents of the file, one would be a <code>tree</code> object and the last one will be a <code>commit</code> object.</p>
<p>Let's trace them again from the <code>HEAD</code> or <code>refs/heads/master</code>.</p>
<pre><code>$ <span>git</span> cat-file <span>-p</span> refs/heads/master<br>tree 9ab377e2f9acd9eaca12e750a7d3cb345065049e<br>parent 3c201df6a1c4d4c87177e30e93be1df8bfe2fe19<br>author Abin Simon <span>&lt;</span>mail@meain.io<span>&gt;</span> <span>1688292975</span> +0530<br>committer Abin Simon <span>&lt;</span>mail@meain.io<span>&gt;</span> <span>1688292975</span> +0530<p>Use blog <span>link</span></p><p>$ <span>git</span> cat-file <span>-p</span> 9ab377e2f9acd9eaca12e750a7d3cb345065049e<br><span>100644</span> blob e5ec63cd761e6ab9d11e7dc2c4c2752d682b36e2    <span>file</span></p><p>$ <span>git</span> cat-file <span>-p</span> e6ec63cd761e6ab9d11e7dc2c4c2752d682b36e2<br>blog.meain.io</p></code></pre>
<p>Those paying attention might have noticed that the <code>commit</code> object now has an additional key called <code>parent</code> which links to the previous commit as this commit is created on top of the previous commit.</p>
<h2 id="creating-a-branch" tabindex="-1">Creating a branch <a href="#creating-a-branch">#</a></h2>
<p>About time we created a branch. Let's do that with <code>git branch fix-url</code>.</p>
<pre><code><span>--- update      2024-07-02 15:47:20.841154907 +0530</span><br><span>+++ branch      2023-07-02 15:55:25.165204941 +0530</span><br><span>@@ -27,5 +28,6 @@</span><br><span><span> </span><span>│   └── pack<br></span><span> </span><span>└── refs<br></span><span> </span><span>    ├── heads<br></span></span><span><span>+</span><span>    │   ├── fix-url<br></span></span><span><span> </span><span>    │   └── master<br></span><span> </span><span>    └── tags</span></span></code></pre>
<p>This adds a new file under the folder <code>refs/heads</code> with a file as the branch name and the content as the id of the latest commit.</p>
<pre><code>$ <span>cat</span> .git/refs/heads/fix-url<br>68ed5aa2372445cf2249d85573ade1c0cbb312b1</code></pre>
<p>This is pretty much all there is to creating a branch. Branches in <code>git</code> are really cheap. Tags also behave the same way, except that they are created under <code>refs/tags</code>.</p>
<p>A file is also added under the <code>logs</code> directory to store the commit history data similar to <code>master</code> branch.</p>
<h2 id="checking-out-a-branch" tabindex="-1">Checking out a branch <a href="#checking-out-a-branch">#</a></h2>
<p>Checking out in <code>git</code> is git getting the <code>tree</code> object of a commit and updating the files in your worktree to match the state recorded in it. In this case, since we are switching from <code>master</code> to <code>fix-url</code>, both of which point to the same <code>commit</code> and underlying <code>tree</code> object, <code>git</code> does not have anything to do in the working tree.</p>
<pre><code><span>git</span> checkout fix-url</code></pre>
<p>The only change that happens when you do a checkout inside <code>.git</code> is that the <code>.git/HEAD</code> file will now point to <code>fix-url</code>.</p>
<pre><code>$ <span>cat</span> .git/HEAD<br>ref: refs/heads/fix-url</code></pre>
<p>Wile we are here, let me make a commit. I'm gonna need this to show what merging does later.</p>
<pre><code>$ <span>echo</span> <span>'https://blog.meain.io'</span><span>&gt;</span>file<br>$ <span>git</span> commit <span>-am</span> <span>'Fix url'</span></code></pre>
<h2 id="merging" tabindex="-1">Merging <a href="#merging">#</a></h2>
<p>There are primarily 3 ways of merging.</p>
<ol>
<li>The simplest and the most easiest is a fast forward merge. In this case you just update the commit a branch is pointing to a commit another branch is pointing to. This pretty much involves copying the hash in <code>refs/heads/fix-url</code> to <code>refs/heads/master</code>.</li>
<li>The second one is rebase merge. In this case we first apply our changes on top of what main is currently pointing to one commit at a time and then perform something similar to a fast forward merge.</li>
<li>The last one would be to just merge two branches using a separate merge commit. This is a bit different in that it will have two <code>parent</code> entries in its commit object. We will go a bit more into this towards the end.</li>
</ol>
<p>First let's see what the graph looks like before a merge.</p>
<pre><code><span>git</span> log <span>--graph</span> <span>--oneline</span> <span>--all</span><br>* 42c6318 <span>(</span>fix-url<span>)</span> Fix url<br>* 67ed5aa <span>(</span>HEAD -<span>&gt;</span> master<span>)</span> Use blog <span>link</span><br>* 3c201df Initial commit</code></pre>
<p>Now to perform the merge:</p>
<pre><code>$ <span>git</span> merge fix-url <span># updates refs/heads/master to the hash in refs/heads/fix-url</span></code></pre>
<pre><code>$ <span>git</span> log <span>--graph</span> <span>--oneline</span> <span>--all</span><br>* 42c6318 <span>(</span>HEAD -<span>&gt;</span> master<span>)</span> <span>(</span>fix-url<span>)</span> Fix url<br>* 67ed5aa Use blog <span>link</span><br>* 3c201df Initial commit</code></pre>
<h2 id="pushing" tabindex="-1">Pushing <a href="#pushing">#</a></h2>
<p>Now that we have been playing around with our local <code>git</code> repo for some time, let's see what happen when we push it. What is being sent to the git repo on the other side?</p>
<p>To show this, first let me create another git repo which can be used as remote for this  repo.</p>
<pre><code>$ <span>mkdir</span> git-talk-2<br>$ <span>cd</span> git-talk-2 <span>&amp;&amp;</span> <span>git</span> init <span>--bare</span><p>$ <span>cd</span> <span>..</span>/git-talk <span>&amp;&amp;</span> <span>git</span> remote <span>add</span> origin <span>..</span>/git-talk-2</p></code></pre>
<p>Btw, this change of adding a new remote is a config change and you can see that change in <code>.git/config</code> file. I'm gonna let you go look what the change was on your own.</p>
<p>Now let's <a href="https://www.youtube.com/watch?v=OuhFTX6yLXQ">push</a>.</p>
<pre><code>$ <span>git</span> push origin master</code></pre>
<p>Let's see what changed in our repo.</p>
<pre><code><span>--- branch	2023-07-02 15:55:25.165204941 +0530</span><br><span>+++ remote	2023-07-02 17:41:05.170923141 +0530</span><br><span>@@ -22,12 +29,18 @@</span><br><span><span> </span><span>│   ├── e5<br></span><span> </span><span>│   │   └── ec63cd761e6ab9d11e7dc2c4c2752d682b36e2<br></span><span> </span><span>│   ├── info<br></span><span> </span><span>│   └── pack<br></span><span> </span><span>├── ORIG_HEAD<br></span><span> </span><span>└── refs<br></span><span> </span><span>    ├── heads<br></span><span> </span><span>    │   ├── fix-url<br></span><span> </span><span>    │   └── master<br></span></span><span><span>+</span><span>    ├── remotes<br></span><span>+</span><span>    │   └── origin<br></span><span>+</span><span>    │       └── master<br></span></span><span><span> </span><span>    └── tags</span></span></code></pre>
<p>It added a new <code>refs/remotes</code> to store the information on what all is available in different remotes.</p>
<p>But what gets sent to the other git repo? It is everything that is in <code>objects</code> and under <code>refs</code>. That is all the other git instance needs to get your entire git history.</p>
<h2 id="references" tabindex="-1">References <a href="#references">#</a></h2>
<ul>
<li><a href="https://git-scm.com/book/en/v3/Git-Internals-Git-Objects">https://git-scm.com/book/en/v3/Git-Internals-Git-Objects</a></li>
<li><a href="https://matthew-brett.github.io/curious-git/reading_git_objects.html">https://matthew-brett.github.io/curious-git/reading_git_objects.html</a></li>
<li><a href="https://blog.meain.io/2020/bunch-of-git-stuff/">https://blog.meain.io/2020/bunch-of-git-stuff/</a></li>
</ul>


<p><a href="https://blog.meain.io/">← Home</a></p>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Unreal Engine will no longer be free for all (157 pts)]]></title>
            <link>https://www.creativebloq.com/news/epic-games-unreal-engine-charge</link>
            <guid>37792030</guid>
            <pubDate>Fri, 06 Oct 2023 15:24:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.creativebloq.com/news/epic-games-unreal-engine-charge">https://www.creativebloq.com/news/epic-games-unreal-engine-charge</a>, See on <a href="https://news.ycombinator.com/item?id=37792030">Hacker News</a></p>
<div id="readability-page-1" class="page"><article aria-label="article" data-id="3SQ7DLX5NJZCHBGUGzFPtk">
<header>
<nav aria-label="Breadcrumbs">
<ol>
<li>
<a href="https://www.creativebloq.com/news" aria-label="Return to News">News</a>
</li>
<li>
<a href="https://www.creativebloq.com/tag/digital-art" aria-label="Return to Digital Art">Digital Art</a>
</li>
</ol>
</nav>



</header>
<section>
<div itemprop="image" itemscope="" itemtype="https://schema.org/ImageObject">
<div>
<picture><source type="image/webp" alt="Unreal Engine and Unity learn a game engine; a 3d render of a cityscape" onerror="if(this.src &amp;&amp; this.src.indexOf('missing-image.svg') !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" srcset="https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-320-80.jpg.webp 320w, https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-1920-80.jpg.webp 1920w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode.jpg"><source type="image/jpeg" alt="Unreal Engine and Unity learn a game engine; a 3d render of a cityscape" onerror="if(this.src &amp;&amp; this.src.indexOf('missing-image.svg') !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" srcset="https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-1920-80.jpg 1920w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode.jpg"><img src="https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-320-80.jpg" alt="Unreal Engine and Unity learn a game engine; a 3d render of a cityscape" onerror="if(this.src &amp;&amp; this.src.indexOf('missing-image.svg') !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" srcset="https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-1920-80.jpg 1920w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode.jpg"></picture>
</div>
<meta itemprop="url" content="https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode.jpg">
<meta itemprop="height" content="600">
<meta itemprop="width" content="338">
<figcaption itemprop="caption description">
<span itemprop="copyrightHolder">(Image credit: Epic Games)</span>
</figcaption>
</div>

<div id="article-body">
<p>Bad news for those using <a href="https://www.creativebloq.com/tag/unreal-engine" data-auto-tag-linker="true">Unreal Engine</a> for VFX or animation this week – or at least for some. Epic Games has confirmed that it will begin charging industries outside gaming to use the 3D graphics engine next year.&nbsp;</p><p>Until now the company has not charged directly for use of Unreal Engine. Instead it charges royalties for projects that surpass $1m in revenue – and only those that use code from the engine. That means that while the developers of big-selling games pay royalties, those who use Unreal Engine for film making and other uses pay nothing. Epic Games now plans to start charging subscription fees on a per-seat basis, but it has clarified that not everyone will be affected (also see our pick of the <a href="https://www.creativebloq.com/features/best-free-3d-apps">best 3D apps</a>).</p><div><blockquote data-lang="en"><p lang="en" dir="ltr">Tim Sweeney addresses Epic Games Layoffs... #UnrealFest pic.twitter.com/49t4Tf20SA<a href="https://twitter.com/ImmatureGamerX/status/1709216675730542972" data-url="https://twitter.com/ImmatureGamerX/status/1709216675730542972">October 3, 2023</a></p></blockquote><p><span role="button" tabindex="0" aria-label="See more">See more</span></p></div><p>Speaking at Unreal Fest 2023, Epic Games CEO Tim Sweeney said Unreal Engine would become “a licensable piece of software like Maya or <a href="https://www.creativebloq.com/tag/photoshop" data-auto-tag-linker="true">Photoshop</a>” with a subscription-based pricing model. Studios using it for non-gaming work like animation, VFX and visualization will be charged through a “seat-based enterprise software licensing model”</p><p>The video above, shared from the event by the creative developer <a href="https://twitter.com/ImmatureGamerX" target="_blank" data-url="https://twitter.com/ImmatureGamerX">Immature on Twitter</a>, shows Sweeney outlining the company’s sources of income, which will include licensing Unreal Engine, in the context of Epic's recent decision to lay off 16% of its staff.</p><div><blockquote data-lang="en"><p lang="en" dir="ltr">Won’t affect. There will be minimum revenue thresholds for commercial projecrs, and student/educator use will remain free.<a href="https://twitter.com/TimSweeneyEpic/status/1709731335147831316" data-url="https://twitter.com/TimSweeneyEpic/status/1709731335147831316">October 5, 2023</a></p></blockquote><p><span role="button" tabindex="0" aria-label="See more">See more</span></p></div><p>Understandably, the news has caused concern among creatives, especially independent filmmakers and non-professionals. Unreal Engine was developed as a graphics engine for gaming, but is now routinely used for real-time rendering and virtual production in everything from animation, to commercials, including by aspiring filmmakers who may not be able to pay for a subscription.</p><p>Replying to <a href="https://twitter.com/TimSweeneyEpic/status/1709731335147831316" target="_blank" data-url="https://twitter.com/TimSweeneyEpic/status/1709731335147831316">a question raised on X</a>, Sweeney has now clarified that there will be minimum revenue thresholds for commercial projects that have to pay for a subscription and that student and educator use of Unreal Engine will remain free.</p><p>There is no detail as yet on what the threshold will be, but the idea seems to be to charge larger studios and developers. It's also unknown what the Unreal Engine price or terms will look like – Sweeney said pricing would not be "unusually expensive, or unusually inexpensive”. The move will not affect game developers who will continue to pay a 5 per cent royalty rate after revenue passes $1m.</p><p>Sweeney said he was announcing the change ahead of time to ensure transparency. Some have suggested that the move was inevitable, noting that it was unusual that access has remained free. However, others have raised concerns that a subscription model could means some creatives cannot afford to use the tool. "Can you imagine that there are some really good unreal engine users that cannot afford subscription in some countries? Please keep it free to use and monetize results for movie and nongame usage," the producer Mihai Ogasanu wrote.</p><p>In our <a href="https://www.creativebloq.com/reviews/unreal-engine-53">Unreal Engine 5.3 review</a>, we note that Unreal Engine continues to redefine the game engine industry with a new skeletal mesh editor, cloth editor and volumetric capabilities.</p>
</div>
<div>
<p><img src="https://cdn.mos.cms.futurecdn.net/flexiimages/mcasa08ogs1651144853.svg"></p>
<div>
<p><strong><span>Thank you for reading 5 articles this month* Join now for unlimited access</span></strong></p><p><strong><span>Enjoy your first month for just £1 / $1 / €1</span></strong></p>
</div>

<p><span>*Read 5 free articles per month without a subscription</span></p>
</div>


<div>
<p><img src="https://cdn.mos.cms.futurecdn.net/flexiimages/mcasa08ogs1651144853.svg">
</p>
<div>
<p><strong><span>Join now for unlimited access</span></strong></p><p>Try first month for just <strong>£1 / $1 / €1</strong></p>
</div>

</div>



<div data-hydrate="true" id="slice-container-newsletterForm-articleInbodyContent"><section><p>Daily design news, reviews, how-tos and more, as picked by the editors.</p></section></div>
<div id="slice-container-authorBio"><p>Joe is a regular freelance journalist and editor at Creative Bloq. He writes news and features, updates buying guides and keeps track of the best equipment for creatives, from monitors to accessories and office supplies. A writer and translator, he also works as a project manager at London and Buenos Aires-based design and branding agency Hermana Creatives, where he manages a team of designers, photographers and video editors who specialise in producing photography, video content, graphic design and collaterals for the hospitality sector. He enjoys photography, particularly nature photography, wellness and he dances Argentine tango.</p></div>


<div>
<h4>Related articles</h4>

</div>
</section>



</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[EU Grabs ARM for First ExaFLOP Supercomputer, x86 Misses Out (146 pts)]]></title>
            <link>https://www.hpcwire.com/2023/10/04/eu-grabs-arm-for-first-exaflop-supercomputer-x86-misses-out/</link>
            <guid>37791116</guid>
            <pubDate>Fri, 06 Oct 2023 14:18:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.hpcwire.com/2023/10/04/eu-grabs-arm-for-first-exaflop-supercomputer-x86-misses-out/">https://www.hpcwire.com/2023/10/04/eu-grabs-arm-for-first-exaflop-supercomputer-x86-misses-out/</a>, See on <a href="https://news.ycombinator.com/item?id=37791116">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		<p>The configuration of Europe’s first exascale supercomputer, Jupiter, has been finalized, and it is a win for Nvidia and a disappointment for x86 chip vendors Intel and AMD. The Jupiter supercomputer, which will cost €273 million to build, will pair SiPearl’s Rhea processor, which is based on ARM architecture, with accelerator technology from Nvidia.</p>
<p>The supercomputer is being built by the European High-Performance Computing Joint Undertaking (EuroHPC JU) and a consortium including Eviden and ParTec. Eviden is an Atos business focusing on advanced computing initiatives that include HPC and AI.</p>
<p>The Jülich Supercomputing Centre, which is near Munich, will host the system. The installation will begin in early 2024.</p>
<p>Specifically, the supercomputer’s main compute cluster will be based on ARM CPUs, and the initial configuration does not include x86. Six of the top 10 supercomputers in the world are based on x86 chips, and only one is based on ARM.</p>
<p>That is a big disappointment for Intel, which last year announced it would invest €33 billion to build a new chip factory and fund research and development initiatives in Europe. Intel’s CEO Pat Gelsinger also met with EU leaders in a bid to get more business in the region.</p>
<p>Jülich’s fastest system, JUWELS, was last featured in the Top500 list in November 2021 and is currently ranked 13. The fastest supercomputers in Europe are the third-ranked Lumi in Finland, which delivers a peak performance of 309 petaflops, and the fourth-ranked Leonardo in Italy, which peaks at 239 petaflops.</p>
<p>Jupiter was first announced last year and is designed to be a modular system in which multiple types of accelerators can be plugged into the core system.</p>
<p>The supercomputer is being built by almost the same cast of characters, including Atos (now Eviden) and system integrator Partec, responsible for the 44-petaflop JUWELS supercomputer, which was installed in 2020 with AMD’s Epyc 7402 chip.</p>
<p>The Jupiter will instead have SiPearl’s ARM processor based on ARM’s Neoverse V1 CPU design. SiPearl has designed the Rhea chip to be universally compliant with many accelerators, and it supports high-bandwidth memory and DDR5 memory channels.</p>
<figure id="attachment_165009" aria-describedby="caption-attachment-165009"><img decoding="async" loading="lazy" src="https://www.hpcwire.com/wp-content/uploads/2023/10/SciPearl-Rhea-300x145.png" alt="SciPearl Rhea" width="277" height="134" srcset="https://www.hpcwire.com/wp-content/uploads/2023/10/SciPearl-Rhea-300x145.png 300w, https://www.hpcwire.com/wp-content/uploads/2023/10/SciPearl-Rhea-150x72.png 150w, https://www.hpcwire.com/wp-content/uploads/2023/10/SciPearl-Rhea.png 460w" sizes="(max-width: 277px) 100vw, 277px"><figcaption id="caption-attachment-165009">European Rhea processor designed to deliver fast real compute performance and efficiency with an unmatched Bytes/Flops ratio. Source: SiPearl</figcaption></figure>
<p>Jupiter will have Nvidia’s Booster Module, an integrated system that includes the company’s GPUs and Mellanox interconnects. SiPearl has been working with Nvidia to connect its CPUs with Nvidia GPUs.<br>
The current JUWELS Booster Module uses Nvidia’s A100 GPUs, and Jupiter could be upgraded to Nvidia’s H100 GPUs. Nvidia has not shared details of successors to H100, and Jupiter’s installation is due to begin in three months.</p>
<p>While Intel and AMD may be losers in the Jupiter deal, it does not preclude their chips from being used in the supercomputer. Jupiter’s modular design means that Jülich may opt to add GPUs, and less likely, CPUs, from those companies into modules that plug into the core compute system.</p>
<p>Intel worked extensively with SiPearl to bring OneAPI support for its Ponte Vecchio supercomputing GPUs to Rhea. SiPearl last year partnered with AMD to make Instinct GPUs compatible with Rhea chips.<br>
Jülich is also building out its machine-learning and quantum computing infrastructure, which the supercomputing center hopes to plug in as accelerator modules hosted at its facility.</p>
<p>ARM, which recently became a publicly listed company, will get a feather on its cap as it looks to break the dominance of x86 in supercomputing. The world’s second fastest supercomputer, Fugaku, installed at the Riken Center for Computational Science, is based on an ARM processor from Fujitsu.</p>
<p>Europe is striving for hardware independence with homegrown CPU designs, so the selection of Rhea CPUs for Jupiter shouldn’t come as a surprise.</p>
<p>SiPearl, based in France, started developing Rhea with seed funding from the European Processor Initiative, which wants to develop open-chip designs that cut reliance on foreign chip technologies. The EPI is focused heavily on chip design based on the open-source RISC-V architecture.<br>
SiPearl is a relatively new chip design company compared to the well-established Intel and AMD and is now under pressure to prove its chip will support the exaflop performance.</p>
<p>SiPearl chose ARM as it is well-established and ready for high-performance applications. Experts say RISC-V is many years away from mainstream server adoption. EuroHPC JU requested Jupiter suppliers to meet energy efficiency, performance, system stability, and programmability requirements.</p>
<p>Jupiter will run classic computing applications and is also designed for AI technologies such as large-language models. AI applications could involve creating simulations that hasten drug discovery or simulating weather problems to make predictions or solve problems related to climate change.</p>
<p>The exaflop performance is expected to be based on the LINPACK benchmark. Nvidia, Google, and others have released debatable supercomputing AI benchmarks, often reporting performance in excess of one exaflop.</p>
<p>Top500 in 2021 tested the mixed-precision HPL-AI (High-Performance LINPACK for Accelerator Introspection) benchmark, which propelled the total performance of ARM-based RIKEN to 2.0 exaflops, compared to 442 exaflops on conventional LINPACK measurements.</p>
<p>Jupiter is also a big step forward in the EU’s effort to achieve computing independence and reduce its reliance on proprietary tech.</p>
<p>The European Commission last month passed the European Chips Act, which opened €43 billion in public funding for manufacturing, next-generation semiconductor technology, and research.</p>
<p>The regulation specifically opens up €2 billion for HPC and €1.67 billion for artificial intelligence. The HPC allotment is related to procuring and building out the supercomputing and quantum infrastructure within the EU.</p>
<p>However, Europe is still behind the US, China, and Japan in the race to build the world’s fastest supercomputers.</p>
<p>The US is expected to host two exaflop supercomputers — Aurora at ORNL and El Capitan at the Lawrence Livermore National Laboratory — in the coming years, which will again put Europe behind. China has hinted that multiple exaflop supercomputers are already or expected to go online.</p>
<p>Europe’s second exascale supercomputer will be up and running in France by the end of 2025. EuroHPC JU announced in June that the supercomputer will be hosted and operated by the Jules Verne consortium, which includes French institutions GENCI (Grand Equipement National de Calcul Intensif), the CEA (the Alternative Energies and Atomic Energy Commission), and Dutch national supercomputing center SURF.</p>
<p>Jupiter’s total cost is €273 million, over half that of the original €500 million budget. About half of the cost of standing up Jupiter is funded by the EuroHPC JU, and the remaining amount is funded by the German Federal Ministry of Education and Research and the Ministry of Culture and Science of the State of North Rhine-Westphalia.</p>
							<div>
						<p><span>Tags:</span>
						<a href="https://www.hpcwire.com/tag/a100/" rel="tag">A100</a>, <a href="https://www.hpcwire.com/tag/arm/" rel="tag">ARM</a>, <a href="https://www.hpcwire.com/tag/aurora/" rel="tag">Aurora</a>, <a href="https://www.hpcwire.com/tag/cea/" rel="tag">CEA</a>, <a href="https://www.hpcwire.com/tag/el-capitan/" rel="tag">El Capitan</a>, <a href="https://www.hpcwire.com/tag/eu/" rel="tag">EU</a>, <a href="https://www.hpcwire.com/tag/eurohpc-ju/" rel="tag">EuroHPC JU</a>, <a href="https://www.hpcwire.com/tag/genci/" rel="tag">GENCI</a>, <a href="https://www.hpcwire.com/tag/h100/" rel="tag">H100</a>, <a href="https://www.hpcwire.com/tag/juwels/" rel="tag">JUWELS</a>, <a href="https://www.hpcwire.com/tag/lawrence-livermore-national-laboratory/" rel="tag">Lawrence Livermore National Laboratory</a>, <a href="https://www.hpcwire.com/tag/linpack/" rel="tag">LINPACK</a>, <a href="https://www.hpcwire.com/tag/neoverse/" rel="tag">Neoverse</a>, <a href="https://www.hpcwire.com/tag/oneapi/" rel="tag">OneAPI</a>, <a href="https://www.hpcwire.com/tag/ornl/" rel="tag">ORNL</a>, <a href="https://www.hpcwire.com/tag/ponte-vecchio/" rel="tag">Ponte Vecchio</a>, <a href="https://www.hpcwire.com/tag/rhea/" rel="tag">Rhea</a>, <a href="https://www.hpcwire.com/tag/riken/" rel="tag">RIKEN</a>, <a href="https://www.hpcwire.com/tag/risc-v/" rel="tag">RISC-V</a>, <a href="https://www.hpcwire.com/tag/surf/" rel="tag">SURF</a>, <a href="https://www.hpcwire.com/tag/top500/" rel="tag">TOP500</a>, <a href="https://www.hpcwire.com/tag/x86/" rel="tag">X86</a>					</p></div><!-- .entry-utility -->
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Making Hard Things Easy (813 pts)]]></title>
            <link>https://jvns.ca/blog/2023/10/06/new-talk--making-hard-things-easy/</link>
            <guid>37791002</guid>
            <pubDate>Fri, 06 Oct 2023 14:09:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jvns.ca/blog/2023/10/06/new-talk--making-hard-things-easy/">https://jvns.ca/blog/2023/10/06/new-talk--making-hard-things-easy/</a>, See on <a href="https://news.ycombinator.com/item?id=37791002">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
     

<p>A few weeks ago I gave a keynote at <a href="https://www.thestrangeloop.com/">Strange Loop</a>
called Making Hard Things Easy. It’s about why I think some things are hard
to learn and ideas for how we can make them easier.</p>

<p>Here’s the video, as well as the slides and a transcript of (roughly) what I
said in the talk.</p>

<h3 id="the-video">the video</h3>

<iframe width="560" height="315" src="https://www.youtube.com/embed/30YWsGDr8mA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>

<h3 id="the-transcript">the transcript</h3>



<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-0.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-0.png"></a>
</p>
<p>


Hello, Strange Loop! Strange Loop is one of the first places I
spoke almost 10 years ago and I'm so honored to be back here today for the
last one. Can we have one more round of applause for the organizers?


</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-1.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-1.png"></a>
</p>
<div>

<p>
I often give talks about things that I'm excited about,
or that I think are really fun.
</p>

<p>
But today, I want to talk about something that I'm a little bit mad about,
which is that sometimes things that seem like they should be basic take me 10
years or 20 years to learn, way longer than it seems like they should. 
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-2.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-2.png"></a>
</p>
<p>

One thing that took me a long time to learn was DNS, which is this question
of -- what's the IP address for a domain name like example.com?
This feels like it should be a straightforward thing.


</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-3.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-3.png"></a>
</p>
<p>

But seven years into learning DNS, I'd be setting up a website. And I'd feel
like things should be working. I thought I understood DNS. But then I'd run
into problems, like my domain name wouldn't work. And I'd wonder -- why not?
What's happening?

</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-4.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-4.png"></a>
</p>
<div>

<p>
And sometimes this would feel kind of personal! This shouldn't be so hard
for me! I should understand this already. It's been seven years!
</p>


<p>
And this "it's just me" attitude is often encouraged -- when I write about
finding things hard to learn on the Internet, Internet strangers will sometimes
tell me: "yeah, this is easy! You should get it already! Maybe you're just not
very smart!"
</p>

<p>
But luckily I have a pretty big ego so I don't take the internet strangers too
seriously. And I have a lot of patience so I'm willing to keep coming back to a
topic I'm confused about. There were maybe four different things that were
going wrong with DNS in my life and eventually I figured them all out.
</p>


</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-5.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-5.png"></a>
</p>
<div>

<p>
So, hooray! I understood DNS! I win! But then I see some of my friends struggling with
the exact same things.
</p>

<p>
They're wondering, hey, my DNS isn't working. Why not? 
</p>




</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-6.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-6.png"></a>
</p>
<div>
<p>
And it doesn't end. We're still having the same problems over and over and over
again. And it's frustrating! It feels redundant! It makes
me mad. Especially when friends take it personally, and they feel like "hey I
should really understand this already".
</p>

<p>
Because everyone is going through this. From the sounds of recognition I hear,
I think a lot of you have been through some of these same problems with DNS.
</p>
</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-7.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-7.png"></a>
</p>
<p>

I got so mad about this that I decided to make it my job. 
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-8.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-8.png"></a>
</p>
<div>

   <p>
   I started a little publishing company called Wizard Zines where --
   </p>
   
 <p>
 (applause)
 </p>
 
   <p>
   Wow. Where I write about some of these topics and try to demystify them.
   </p>
     
</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-9.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-9.png"></a>
</p>
<p>
     Here are a few of the zines I've published. I want to talk today about a
     few of these topics and what makes them so hard and how we can make them
     easier.
     
    
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-10.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-10.png"></a>
</p>
<p>
 We're going to talk about bash, HTTP, SQL, and DNS.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-11.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-11.png"></a>
</p>
<div>


<p>
 For each of them, we're
 going to talk a little bit about:
 </p>
   
 <p>
 a.  what's so hard about it? 
 </p>
   
 <p>
 b. what are some things we can do to make it a little bit easier for each other?
 </p>


</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-12.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-12.png"></a>
</p>
<p>
   Let's start with Bash. 

</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-13.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-13.png"></a>
</p>
<p>
What's so hard about it?
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-14.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-14.png"></a>
</p>
<p>
So, bash is a programming language, right?
But it's one of the weirdest programming languages that I work
with.


</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-15.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-15.png"></a>
</p>
<p>

To understand why it's weird, let's do a little small demo
of bash.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-16.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-16.png"></a>
</p>
<div>


<p>
First, let's run this script, <code>bad.sh</code>:
</p>

<pre>mv ./*.txt /tmmpp
echo "success!"
</pre>

   <p>
   This moves a file and prints "success!". And with most of the programming languages that I use, if there's a problem, the program will stop.
   </p>
   
 <p>
 [laughter from audience]
 </p>
 
 <p>
 
     But I think a lot of you know from maybe sad experience that bash does not
     stop, right? It keeps going. And going... and sometimes very bad things
     happen to your computer in the process. 
   </p>
   
 <p>
 When I run this program, here's the output:
 </p>
   
   <pre>mv: cannot stat './*.txt': No such file or directory
success!
</pre>

<p>
It didn't stop after the failed <code>mv</code>.
</p>
     
</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-17.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-17.png"></a>
</p>
<div>

<p>
Eventually I learned that you can write <code>set
-e</code> at the top of your program, and that will make bash stop if
there's a problem. 
</p>

<p>
When we run this new program with <code>set -e</code> at the top, here's the output:
</p>

<pre>mv: cannot stat './*.txt': No such file or directory
</pre>


</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-18.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-18.png"></a>
</p>
<p>
Great. We're happy. Everything is good. But every time I think I've learned
everything that go wrong with bash, I'll find out -- surprise! There are more
bad things that can happen! Let's look at another program as an example.
     
    </p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-19.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-19.png"></a>
</p>
<div>

<p>
Here we've put our code in a function. And if the function
fails, we want to echo "failed". 

</p>

<p>
So use <code>set -e</code> at the beginning, and you might think everything should be okay. 
</p>

<p>
But if we run it... this is the output we get
</p>

<pre>mv: cannot stat './*.txt': No such file or directory
success
</pre>

<p>
We get the "success" message again! It didn't stop, it just kept going. This is
because the "or" (<code>|| echo "failed"</code>) globally disables <code>set -e</code> in the
function.
</p>

<p>
Which is certainly not what I wanted, and not what I would expect. But this is
not a bug in bash, it's is the documented behavior.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-20.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-20.png"></a>
</p>
<div>

<p>
And I think one reason this is tricky is a lot of us don't use bash very often.
Maybe you write a bash script every six months and don't look at it again.
</p>

<p>
When you use a system very infrequently and it's full of a lot of weird trivia
and gotchas, it's hard to use the system correctly.
</p>


</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-21.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-21.png"></a>
</p>
<p>

So how can we make this easier? What can we do about it?
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-22.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-22.png"></a>
</p>
<p>
One thing that I sometimes hear is -- a newcomer will say "this is hard",
and someone more experienced will say "Oh, yeah, it's impossible to use bash.
Nobody knows how to use it."



</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-23.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-23.png"></a>
</p>
<div>

<p>
But I would say this is factually untrue. How many of you are using bash?
</p>

<p>
A lot of us ARE using it! And it doesn't always work perfectly, but often
it gets the job done.
</p>


</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-24.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-24.png"></a>
</p>
<p>

We have a lot of bash programs that are mostly working, and there's a big
community of us who are using bash mostly successfully despite all the
problems.

</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-25.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-25.png"></a>
</p>
<div>

<p>
The way I think this is --  you have some people on the left in this
diagram who are confused about bash, who think it seems awful and
incomprehensible.
</p>

<p>
And some people on the right who know how to make the bash work for them,
mostly.
</p>

<p>
So how do we move people from the left to the right, from being overwhelmed by
a pile of impossible gotchas to being able to mostly use the system correctly?
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-26.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-26.png"></a>
</p>
<p>

Well, bash has a giant pile of trivia to remember. But who's good at remembering
giant piles of trivia?
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-27.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-27.png"></a>
</p>
<p>

Not me! I can't memorize all of the weird things about bash. But computers!
Computers are great at memorizing trivia!

</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-28.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-28.png"></a>
</p>
<div>

<p>
And for bash, we have this incredible tool called
shellcheck.
</p>

<p>
[ Applause ]
</p>

<p>
Yes! Shellcheck is amazing! And shellcheck knows a lot of things that can go
wrong and can tell you "oh no, you don't want to do that. You're going to have
a bad time."
</p>

<p>
I'm very grateful for shellcheck, it makes it much easier for me to write
tiny bash scripts from time to time. 
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-29.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-29.png"></a>
</p>
<div>

<p>
Now let's do a shellcheck demo! 
</p>

<pre>$ shellcheck -o all bad-again.sh
In bad-again.sh line 7:
f || echo "failed!"
^-- SC2310 (info): This function is invoked in an || condition so set -e will be disabled. Invoke separately if failures should cause the script to exit.
</pre>

<p>
Shellcheck gives us this
lovely error message. The message isn't completely obvious on its own (and this
check is only run if you invoke shellcheck with <code>-o all</code>). But
shellcheck tells you "hey, there's this problem, maybe you should be worried
about that".
</p>

<p>
And I think it's wonderful that all these tips live in this linter. 
</p>


</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-30.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-30.png"></a>
</p>
<div>

<p>
I'm not trying to tell you to write linters, though I think that some of you
probably will write linters because this is that kind of crowd.
</p>

<p>
I've personally never written a linter, and I'm definitely not going to create
something as cool as shellcheck!
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-31.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-31.png"></a>
</p>
<div>

<p>
But instead, the way I write linters is I tell people about shellcheck from
time to time and then I feel a little like I invented shellcheck for those
people. Because some people didn't know about the tool until I told them about
it!
</p>

<p>
I didn't find out about shellcheck for a long time and I was kind of mad about
it when I found out. I felt like -- excuse me? I could have been using
shellcheck this whole time? I didn't need to remember all of this stuff in
my brain?
</p>

<p>
So I think an incredible thing we can do is to reflect on the tools that we're
using to reduce our cognitive load and all the things that we can't fit into
our minds, and make sure our friends or coworkers know about them.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-32.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-32.png"></a>
</p>
<p>
I also like to warn people about gotchas and some of the terrible things
computers have done to me.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-33.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-33.png"></a>
</p>
<div>

<p>
I think this is an incredibly valuable community service. The example I shared
about how <code>set -e</code> got disabled is something I learned from my
friend Jesse a few weeks ago. 
</p>

<p>
They told me how this thing happened to them, and now I know and I don't have
to go through it personally.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-34.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-34.png"></a>
</p>
<div>

<p>
One way I see people kind of trying to share terrible things that their
computers have done to them is by sharing "best practices".
</p>

<p>
But I really love to hear the stories behind the best practices!
</p>


</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-35.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-35.png"></a>
</p>
<div>


<p>
If someone has
a strong opinion like "nobody should ever use bash", I want to hear about the
story! What did bash do to you? I need to know.
</p>

<p>
The reason I prefer stories to best practices is if I know the story about how
the bash hurt you, I can take that information and decide for myself how I want
to proceed.
</p>

<p>
Maybe I feel like -- the computer did that to you? That's okay, I can deal with
that problem, I don't mind.
</p>

<p>
Or I might instead feel like "oh no, I'm going to do the best practice you
recommended, because I do not want that thing to happen to me". 
</p>

<p>
These bash stories are a great example of that: my reaction to them is "okay,
I'm going to keep using bash, I'll just use shellcheck and keep my bash scripts
pretty simple". But other people see them and decide "wow, I never want to use
bash for anything, that's awful, I hate it".
</p>

<p>
Different people have different reactions to the same stories and that's okay.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-36.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-36.png"></a>
</p>
<p>
That's all for bash. Next up we're gonna talk about HTTP. 
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-37.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-37.png"></a>
</p>

</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-38.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-38.png"></a>
</p>
<div>

<p>
I was talking to Marco Rogers at some point, many years ago, and he mentioned
some new developers he was working with were struggling with HTTP.
</p>

<p>
And at first, I was a little confused about this -- I didn't understand what
was hard about HTTP.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-39.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-39.png"></a>
</p>
<div>

<p>
The way I was thinking about it
at the time was that if you have an HTTP response, it has a few parts: a response
code, some headers, and a body.
</p>


<p>
I felt like -- that's a pretty simple structure, what's the problem? But of
course there was a problem, I just couldn't see what it was at first.
</p>


</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-40.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-40.png"></a>
</p>
<div>

<p>
So, I talked to a friend who was newer to HTTP. And they asked "why does it
matter what headers you set?"
</p>

<p>
And I said: "well, the browser..."
</p>


</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-41.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-41.png"></a>
</p>
<p>
But then I thought... the browser?
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-42.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-42.png"></a>
</p>
<p>
the browser?
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-43.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-43.png"></a>
</p>
<div>

<p>
The browser!
</p>

<p>
Firefox is 20 million lines of code! It's been
evolving since the '90s. There have been as I understand it, 1 million
changes to the browser security model as people have discovered new and
exciting exploits and the web has become a scarier and scarier place.
</p>

<p>
The browser is really a lot to understand.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-44.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-44.png"></a>
</p>
<div>



<p>
One trick for understanding why a topic is hard is -- if the implementation if the
thing involves 20 million lines of code, maybe that's why people are confused!
</p>

<p>
Though that 20 million lines of code also involves CSS and JS and many other
things that aren't HTTP, but still.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-45.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-45.png"></a>
</p>
<div>

<p>
Once I thought of it in terms of how complex a modern web browser is, it
made so much more sense! Of course newcomers are confused about HTTP if you
have to understand what the browser is doing!
</p>

<p>
Then my problem changed from "why is this hard?" to "how do I explain this at all?"
</p>

<p>
So how do we make it easier? How do we wrap our minds around this 20 million lines
of code?
</p>



</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-46.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-46.png"></a>
</p>
<p>
One way I think about this for HTTP is: here are some of the HTTP request
headers. That's kind of a big list there are 43 headers there.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-47.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-47.png"></a>
</p>
<p>
There are more unofficial headers too.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-48.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-48.png"></a>
</p>
<div>

<p>
My brain does not contain all of those headers, I have no idea what most of
them are.
</p>

<p>
When I think about trying to explain big topics, I think about -- what is
actually in my brain, which only contains a normal human number of things?
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-49.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-49.png"></a>
</p>
<div>


<p>
This is <a href="https://wizardzines.com/comics/request-headers/">a comic I drew about HTTP request headers</a>.
You don't have to read the whole thing. This has 15
request headers.
</p>

<p>
I wrote that these are "the most important headers", but what I mean by "most
important" here is that these are the ones that I know about and use. It's a
subjective list.
</p>

<p>
I wrote about 12 words about each one, which I think is approximately the
amount of information about each header that lives in my mind.
</p>

<p>
For example I know that you can set <code>Accept-Encoding</code> to <code>gzip</code>
and then you might get back a compressed response. That's all I know,
and that's usually all I need to know!
</p>

<p>
This very small set of information is working pretty well for me.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-50.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-50.png"></a>
</p>
<div>


<p>
The general way I think about this trick is "turn a big list into a small list".
</p>

<p>
Turn the set of EVERY SINGLE THING into just the things I've personally used. I
find it helps a lot.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-51.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-51.png"></a>
</p>
<div>


<p>
Another example of this "turn a big list into a small list" trick is command line arguments.
</p>

<p>
I use a lot of command line tools, the number of arguments they have can be
overwhelming, and I've written about them <a href="https://wizardzines.com/zines/bite-size-command-line/">a fair amount</a> over
the years.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-52.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-52.png"></a>
</p>
<p>
Here are all the flags for grep, from its man page. That's too much! I've been
using grep for 20 years but I don't know what all that stuff is.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-53.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-53.png"></a>
</p>
<div>

<p>
But when I look at the grep man page, this is what I see.
</p>


<p>
I think it's very helpful to newcomers when a more experienced person says
"look, I've been using this system for a while, I know about 7 things about it,
and here's what they are".
</p>

<p>
We're just pruning those lists down to a more human scale. And it can even help
other more experienced people -- often someone else will know a slightly
different set of 7 things from me.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-54.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-54.png"></a>
</p>
<div>

<p>
But what about the stuff that doesn't fit in my brain?
</p>

<p>
Because I have a few things about HTTP stored in my brain. But sometimes I need
other information which is hard to remember, like maybe the exact details of
how CORS works.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-55.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-55.png"></a>
</p>
<p>

And so, that's where we come to references. Where do we find the information
that we can't remember?

</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-56.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-56.png"></a>
</p>
<div>

<p>
I often have trouble finding the right references.
</p>

<p>
For example I've been trying to learn CSS off and on for 20 years. I've made a
lot of progress -- it's going well!
</p>

<p>
But only in the last 2 years or so I learned about this wonderful website called 
<a href="https://css-tricks.com/">CSS Tricks</a>.
</p>

<p>
And I felt kind of mad when I learned about CSS Tricks! Why didn't I know about
this before? It would have helped me!
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-57.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-57.png"></a>
</p>
<div>


<p>
But anyway, I'm happy to know about CSS Tricks now. (though sadly they seem to
have stopped publishing in April after the acquisition, I'm still happy the older posts are there)
</p>

<p>
For HTTP, I think a lot of us use the Mozilla Developer Network. 
</p>


</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-58.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-58.png"></a>
</p>
<div>


<p>
Another HTTP reference I love is the official RFC, <a href="https://www.rfc-editor.org/rfc/rfc9110">RFC 9110</a> (also
<a href="https://www.rfc-editor.org/rfc/rfc9111">9111</a>,
<a href="https://www.rfc-editor.org/rfc/rfc9112">9112</a>,
<a href="https://www.rfc-editor.org/rfc/rfc9113">9113</a>,
<a href="https://www.rfc-editor.org/rfc/rfc9114">9114</a>)
</p>

<p>
It's a new authoritative reference for HTTP and it was written just last
year, in 2022! They decided to organize all the information really nicely. So if you
want to know exactly what the <code>Connection</code> header does, you can look
it up. 
</p>

<p>
This is not really my top reference. I'm usually on MDN. But I really
appreciate that it's available.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-59.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-59.png"></a>
</p>
<p>
So I love to share my favorite references.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-60.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-60.png"></a>
</p>
<div>

<p>
I do sometimes find it tempting to kind of lie about references. Not on
purpose.
But I'll see something on the internet, and I'll think it's kind of cool, and
tell a friend about. But then my friend might ask me -- "when have you used this?"
And I'll have to admit "oh, never, I just thought it seemed cool".
</p>

<p>
I think it's important to be honest about what the references that I'm actually
using in real life are. Even if maybe the real references I use are a little
"embarrassing", like maybe w3schools or something.
</p>


</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-61.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-61.png"></a>
</p>
<p>

So that's HTTP! Next we're going to talk about SQL.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-62.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-62.png"></a>
</p>
<p>
The case of the mysterious execution order.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-63.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-63.png"></a>
</p>
<div>

<p>
I started thinking about SQL because someone mentioned they're trying to learn
SQL. I get most of my zine ideas that way, one person will make an offhand
comment and I'll decide "ok, I'm going to spend 4 months writing about
that". It's a weird process.
</p>

<p>
So I was wondering -- what's hard about SQL? What gets in the way of trying
to learn that?
</p>

<p>
I want to say that when I'm confused about what's hard about something, that's
a fact about me. It's not usually that the thing is easy, it's that I need to
work on understanding what's hard about it. It's easy to forget when you've
been using something for a while.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-64.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-64.png"></a>
</p>
<p>
So, I was used to reading SQL queries. For example this made up query that tries to
find people who own exactly two cats. It felt straightforward
to me, SELECT,
FROM, WHERE, GROUP BY.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-65.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-65.png"></a>
</p>
<div>

<p>
But then I was talking to a friend about these queries who was new to SQL. And
my friend asked -- what is this doing?
</p>

<p>
I thought, hmm, fair point.
</p>



</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-66.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-66.png"></a>
</p>
<p>
And I think the point my friend was making was that the order that this SQL
query is written in, is not the order that it actually happens in. It happens
in a different order, and it's not immediately obvious what that is.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-67.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-67.png"></a>
</p>
<p>

So how do we make this easier?
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-68.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-68.png"></a>
</p>
<div>


<p>
I like to think about: what does the computer do first?
What actually happens first chronologically?
</p>

<p>
Computers actually do live in the same timeline as us. Things happen. Things
happen in an order. So what happens first?
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-69.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-69.png"></a>
</p>

</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-70.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-70.png"></a>
</p>
<p>

The way I think about an SQL query is: is you start with a table like
<code>cats</code>.

</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-71.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-71.png"></a>
</p>
<p>

Then maybe you filter it, you remove some stuff. 
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-72.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-72.png"></a>
</p>
<p>

Then you make some groups.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-73.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-73.png"></a>
</p>
<p>

Then you filter the groups, remove some of them.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-74.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-74.png"></a>
</p>
<p>

Then you do some
aggregation. There's two things in each group.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-75.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-75.png"></a>
</p>
<p>

And you sort it.

And you
can also limit the results.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-76.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-76.png"></a>
</p>
<div>


<p>
So, that's how I think about SQL. The way a query runs is first
FROM, then WHERE, GROUP BY, HAVING, SELECT, ORDER BY, LIMIT.
</p>

<p>
At least conceptually. Real life databases have optimizations and it's more
complicated than that. But this is the mental model that I use most of the time
and it works for me. Everything is in the same order as you write it,
except SELECT is fifth. 
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-77.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-77.png"></a>
</p>
<p>

I've really gotten a lot out of this trick where you try to tell the
chronological story of what the computer is doing. I want to talk about a
couple other examples.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-78.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-78.png"></a>
</p>
<div>


<p>
One is CORS, in HTTP. 
</p>

<p>
This <a href="https://wizardzines.com/comics/cors/">comic</a> is way too small to read on the slide.
But the idea is if you're making a cross-origin request in your
browser, you can write down every communication that's happening between your
browser and the server, in chronological order.
</p>

<p>
And I think writing down everything in chronological order makes it a lot easier to understand and more concrete.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-79.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-79.png"></a>
</p>
<div>


<p>
"What happens in chronological order?" is a very
straightforward structure, which is what I like about it. "What happens first?"
feels like it should be easy to answer. But it's not!
</p>

<p>
I've found that it's actually very hard to know what our computers is
doing, and it's a really fun question to explore.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-80.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-80.png"></a>
</p>
<div>


<p>
As an example of how this is hard: I wrote a blog post recently called 
<a href="https://jvns.ca/blog/2023/08/03/behind--hello-world/">"Behind Hello World on Linux"</a>. It's about what happens when you run "hello world" on a
Linux computer. I wrote a bunch about it, and I was really happy with it.
</p>

<p>
But after I wrote the post, I thought -- haven't I written about this before? Maybe 10 years ago?
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-81.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-81.png"></a>
</p>
<div>

<p>
And sure enough, I'd tried to write <a href="https://jvns.ca/blog/2013/11/29/what-happens-when-you-run-a-unix-program/">
a similar post</a> 10 years before.
</p>

<p>
I think this is really cool. Because the 2013 version of this post was about 6
times shorter. This isn't because Linux is more complicated than it was 10
years ago -- I think everything in the 2023 post was probably also true in
2013. The 2013 post just has a lot less information in it.
</p>

<p>
The reason the 2023 post is longer is that I didn't know what was happening
chronologically on my computer in 2013 very well, and in 2023 I know a lot
more. Maybe in 2033 I'll know even more!
</p>

<p>
I think a lot of us -- like me in 2013 and honestly me now, often don't know
the facts of what's happening on our computers. It's very hard, which is what
makes it such a fun question to try and discuss.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-82.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-82.png"></a>
</p>
<div>



<p>
I think it's cool that all of us
have different knowledge about what is happening chronologically on our
computers and we can all chip in to this conversation.
</p>

<p>
For example when I posted this blog post about Hello World on Linux, some people
mentioned that they had a lot of thoughts about what happens exactly in your
terminal, or more details about the filesystem, or about what's happening
internally in the Python interpreter, or any number of things. You can go
really deep.
</p>

<p>
I think it's just a really fun collaborative question. 
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-83.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-83.png"></a>
</p>
<div>

<p>
I've seen "what happens chronologically?" work really well as an activity with
coworkers, where you're ask: "when a request comes into this API endpoint we
run, how does that work? What happens?"
</p>

<p>
What I've seen is that someone will understand some part of the system, like "X
happens, then Y happens, then it goes over to the database and I have no idea
how that works".  And then someone else can chime in and say "ah, yes, with the
database A B C happens, but then there's a queue and I don't know about that".
</p>

<p>
I think it's really fun to get together with people who have different
specializations and try to make these little timelines of what the
computers are doing. I've learned a lot from doing that with people.
</p>


</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-84.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-84.png"></a>
</p>
<p>
That's all for SQL.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-85.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-85.png"></a>
</p>
<p>

So, now we've arrived at DNS which is
where we started the talk.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-86.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-86.png"></a>
</p>
<div>



<p>
Even though I struggled with DNS. Once I got figured it out, I felt like "dude,
this is easy!". Even though it just took me 10 years to learn how it
works.
</p>

<p>
But of course, DNS was pretty hard for me to learn. So -- why is that? Why did
it take me so long?
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-87.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-87.png"></a>
</p>
<div>


<p>
So, I have a little <a href="https://wizardzines.com/comics/cast-of-characters/">chart</a> here of how I think about DNS.
</p>

<p>
You have your browser on the left. And over on the right there's the authoritative
nameservers, the source of truth of where the DNS records for a domain live. 
</p>

<p>
In the middle, there's a function that you call and a cache.
So you have browser, function, cache, source of truth.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-88.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-88.png"></a>
</p>
<div>

<p>
One problem is that there are a lot of things in this diagram that are
totally hidden from you.
</p>

<p>
The library code that you're using where you make a DNS request -- there are a
lot of different libraries you could be using, and it's not straightforward to figure out which one is being used.
That was the source of some of my confusion.
</p>

<p>
There's a cache which has a bunch of cached data. That's invisible to you, you
can't inspect it easily and you have no control over it. that
</p>

<p>
And there's a conversation between the cache and the source of
truth, these two red arrows which also you can't see at all.
</p>

<p>
So this is kind of tough! How are you supposed to develop an intuition for a
system when it's mostly things that are completely hidden from you? Feels like
a lot to expect.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-89.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-89.png"></a>
</p>
<p>

So, what do we do about this?
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-90.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-90.png"></a>
</p>
<div>


<p>
So: let's talk about these red arrows
on the right.
</p>

<p>
We have our cache and then we have the source of truth. This conversation
is normally hidden from you because you often don't control either of these
servers. Usually they're too busy doing high-performance computing to report to
you what they're doing.
</p>

<p>
But I thought: anyone can write an authoritative nameserver!
In particular, I could write one that reports back every single message that it receives to its users.
So, with my friend <a href="https://marieflanagan.com/">Marie</a>, we wrote a little DNS server.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-91.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-91.png"></a>
</p>
<div>

<p>
(demo of <a href="https://messwithdns.net/">messwithdns.net</a>)
</p>

<p>
This is called Mess With DNS. The idea is I have a domain name and you
can do whatever you want with it. We're going to make a DNS record called
<code>strangeloop</code>, and we're going to make a CNAME record pointing at
<code>orange.jvns.ca</code>, which is just a picture of an orange. Because I
like oranges.
</p>

<p>
And then over here, every time a request comes in from a resolver, this will --
this will report back what happened. So, if we click on this link, we can see
-- a Canadian DNS resolver, which is apparently what my browser is configured
to use, is requesting an IPv4 record and an IPv6 record, A and AAAA.
</p><p>


(at this point in the demo everyone in the audience starts visiting the link
and it gets a bit chaotic, it's very funny)

</p></div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-93.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-93.png"></a>
</p>
<p>
So the trick here is to find ways to show people parts of what the computer is
doing that are normally hidden.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-94.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-94.png"></a>
</p>
<div>

<p>
Another great example of showing things that are hidden is this website called <a href="https://float.exposed/0x4d000006">float.exposed</a>
by <a href="https://ciechanow.ski/">Bartosz Ciechanowski</a> who makes a lot of incredible visualizations.
</p>

<p>
So if you look at <a href="https://float.exposed/0x4b800000">this 32-bit
floating point number</a> and click the "up" button on the significand, it'll
show you the next floating point number, which is 2 more. And then as you make
the number bigger and bigger (by increasing the exponent), you can see that the
floating point numbers get further and further apart.
</p>

<p>
Anyway, this is not a talk about floating point. I could do an entire talk
about this site and how we can use it to see how floating point works, but
that's not this talk.
</p>


</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-95.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-95.png"></a>
</p>
<div>

<p>
Another thing that makes DNS confusing is that it's a giant distributed system
-- maybe you're confused because there are 5 million computers involved (really, more!).
Most of which you have no control over, and some
are doing not what they're supposed to do. 
</p>

<p>
So that's another trick for understanding why things are hard, check to see if
there are actually 5 million computers involved.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-96.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-96.png"></a>
</p>
<div>

<p>
So what else is hard about DNS?
</p>

<p>
We've talked about how most of the system is hidden from you, and about how
it's a big distributed system.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-97.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-97.png"></a>
</p>
<p>

One problem I've run into is that the tools are confusing.

</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-98.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-98.png"></a>
</p>
<div>

<p>
One of the hidden things I talked about was: the resolver has cached data,
right? And you might be curious about whether a certain domain name is cached
or not by your resolver right now.
</p>

<p>
Just to understand what's happening:  am I getting this result because it was
cached? What's the deal?
</p>

<p>

I said this was hidden, but there are a couple of ways to query a resolver to
see what it has cached, and I want to show you one of them.

</p>


</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-99.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-99.png"></a>
</p>
<div><p>

The tool I usually use for making DNS queries is called <code>dig</code>, and
it has a flag called <code>+norecurse</code>. You can use it to query a
resolver and ask it to only return results it already has cached.

</p><p>
With <code>dig +norecurse jvns.ca</code>, I'm kind of asking -- how popular is my website? Is it popular enough that someone has visited it in the last 5 minutes?
Because my records are not cached for that long, only for 5 minutes.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-100.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-100.png"></a>
</p>
<div>


<p>
But when I look at this
response, I feel like "please! What is all this?"
</p>

<p>
And when I show newcomers this output, they often respond by saying "wow,
that's complicated, this DNS thing must be really complicated". But really this
is just not a great output format, I think someone just made some relatively
arbitrary choices about how to print this stuff out in the 90s and it's stayed
that way ever since.
</p>

<p>
So a bad output format can mislead newcomers into thinking that something is more complicated than it actually is.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-101.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-101.png"></a>
</p>
<p>

What can we do about confusing output like this?

</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-102.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-102.png"></a>
</p>
<div>

<p>
One of my favorite tricks, I call eraser eyes.
</p>

<p>
Because when I look at that output, I'm not looking at all of it, I'm just
looking at a few things. My eyes are ignoring the rest of it.
</p>
</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-103.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-103.png"></a>
</p>
<div>

<p>
When I look at the output, this is what I see: it says <code>SERVFAIL</code>.
That's the DNS response code.
</p>


<p>
Which as I understand it is a very unintuitive way of it saying, "I do not have
that in my cache". So nobody has asked that resolver about my domain name in
the last 5 minutes, which isn't very surprising.
</p>

<p>
I've learned so much from people doing a little demo of a tool, and showing how
they use it and which parts of the output or UI they pay attention to, and which parts they ignore.
</p>

<p>
Becuase usually we ignore most of what's on our screens!
</p>

<p>
I really love to use <code>dig</code> even though it's a little hairy because
it has a lot of features (I don't know of another DNS debugging that supports this
<code>+norecurse</code> trick), it's everywhere, and it hasn't changed in a
long time. And I know if I learn its weird output format once I can know that
forever. Stability is really valuable to me.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-104.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-104.png"></a>
</p>
<p>

So we've talked about these four technologies. Let's talk a little more about
how we can make things easier for each other.

</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-105.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-105.png"></a>
</p>
<p>



What can we do to move folks from "I really don't get it" to "okay, I can
mostly deal with this, at least 90% of the time, it's fine"? For bash or HTTP or DNS or anything else.

</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-106.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-106.png"></a>
</p>
<div>


<p>
We've talked about some tricks I use to bring people over, like:
</p>

<ul>
<li> sharing useful tools </li>
<li> sharing references</li>
<li>telling a chronological story of what happens on your computer</li>
<li>turning a big list into a small list of the things you actually use</li>
<li>showing the hidden things</li>
<li>demoing a confusing tool and telling folks which parts I pay attention to</li>
</ul>


</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-107.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-107.png"></a>
</p>
<div>

<p>

When I practiced this talk, I got some feedback from people saying "julia! I don't
do those things! I don't have a blog, and I'm not going to start one!"

</p>

<p>
And it's true that most people are probably not going to start programming blogs.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-108.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-108.png"></a>
</p>
<p>
But I really don't think you need to have a public presence on the internet to
tell the people around you a little bit about how you use computers and how you
understand them.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-109.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-109.png"></a>
</p>
<div>


<p>
My experience is that a lot of people (who do not have blogs!) have helped me
understand how computers work and have
shared little pieces of their experience with computers with me.
</p>

<p>
I've learned a lot from my friends and my coworkers and honestly a lot of
random strangers on the Internet too. I'm pretty sure some of you here today
have helped me over the years, maybe on Twitter or Mastodon.
</p>

<p>
So I want to talk about some archetypes of helpful people
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-110.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-110.png"></a>
</p>
<div>

<p>
One kind of person who has really helped me is the
grumpy old-timer. I'll say "this is so cool". And they'll reply yes,
however, let me tell you some stories of how this has gone wrong in my life.
</p>


<p>
And those stories have sometimes helped spare me some suffering.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-111.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-111.png"></a>
</p>
<div>

<p>
We have the loud newbie, who asks questions like "wait, how does that work?"
And then everyone else feels relieved -- "oh, thank god. It's not just me."
</p>

<p>
I think it's especially valuable when the person who takes the "loud newbie"
role is actually a pretty senior developer. Because when you're more secure in
your position, it's easier to put yourself out there and say "uh, I don't get
this" because nobody is going to judge you for that and think you're
incompetent.
</p>

<p>
And then other people who feel more like they might be judged for not knowing
something can ride along on your coattails.
</p>


</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-112.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-112.png"></a>
</p>
<div>

<p>
Then we have the bug chronicler. Who decides "ok, that bug. This can never happen again".
</p>

<p>
"I'm gonna make sure we understand what happened. Because I want this to end
now."
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-113.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-113.png"></a>
</p>
<p>

We have the tool builder, whose attitude is more like "I see people struggling
with something, and I don't feel like explaining it. But I can write code to
just make it easier permanently for everyone."

</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-114.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-114.png"></a>
</p>
<p>

There's this "today I learned" person who's into sharing cool new tools they
learned about, a bug that they ran into, or a great new-to-them library feature.

</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-115.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-115.png"></a>
</p>
<p>

There's the person who has read the entire Internet and has 700 tabs open. If you
want to know where to find something, there's a good chance they already have
it open in their browser.


</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-116.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-116.png"></a>
</p>
<p>

We have the person who is just willing to answer questions! "Yeah, I can tell
you how that works!"
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-117.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-117.png"></a>
</p>
<p>

And at the end of all this, sometimes you have someone who likes to write some
things down so that other people can read it and can find it later.


</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-118.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-118.png"></a>
</p>
<p>

But all of us have different roles and we need to work together. I'm into
writing but a lof of the stuff I've written about, I only know about because
someone told me about it or explained it to me.

</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-119.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-119.png"></a>
</p>
<p>

To end: the one thing I would like to convince you of is: if you're struggling
with something that feels basic, it's not just you! You're not alone. We're all struggling with a
lot of these things that feel like they should be "basic".


</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-120.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-120.png"></a>
</p>
<p>

And we're struggling with these things for a lot of
the same reasons as each other. 


</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-123.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-123.png"></a>
</p>
<div>

<p>
And much like when debugging a computer program, when you have a bug, you
want to understand why the bug is happening if you're gonna fix it.
</p>

<p>
If we're all struggling with the same things together for the same reasons, if
we can figure out what those reasons are, we can do a better job of fixing
them.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-121.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-121.png"></a>
</p>
<div><p>

Some of the reasons we've talked about were:

</p><ul>
<li>
a giant pile of trivia and gotchas.
</li>
<li>
or maybe there's 20 million lines of code somewhere.
</li>
<li>
Maybe a big part of the system is being hidden from you.
</li>
<li>
Maybe the tool's output is extremely confusing and no UI designer has ever worked on improving it
</li>
</ul><p>

And there are a lot more reasons.

</p></div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-124.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-124.png"></a>
</p>
<p>

I don't have all the answers for why things are hard. For example I don't really understand why Git is hard, that's something I've been thinking about recently.

</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-125.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-125.png"></a>
</p>
<p>

But that's something I'm excited to keep
working on and keep trying to figure out.


</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-126.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-126.png"></a>
</p>
<div>

<p>
And that's all I have for you. Thank you.
</p>

<p>
I brought some zines to the conference, if you come to the signing later on you can get one.
</p>

</div>
</div>

<h3 id="some-thanks">some thanks</h3>

<p>This was the last ever Strange Loop and I’m really grateful to Alex Miller and the
whole organizing team for making such an incredible conference for so many years. Strange Loop
accepted one of my first talks (<a href="https://www.youtube.com/watch?v=0IQlpFWTFbM">you can be a kernel hacker</a>) 9 years ago when I had
almost no track record as a speaker so I owe a lot to them.</p>

<p>Thanks to Sumana for coming up with the idea for this talk, and to Marie,
Danie, Kamal, Alyssa, and Maya for listening to rough drafts of it and helping
make it better, and to Dolly, Jesse, and Marco for some of the conversations I
mentioned.</p>

<p>Also after the conference Nick Fagerland wrote a nice post with thoughts on <a href="https://roadrunnertwice.dreamwidth.org/596185.html">why git is hard</a> in response to my “I
don’t know why git is hard” comment and I really appreciated it. It had some
new-to-me ideas and I’d love to read more analyses like that.</p>

</div></div>]]></description>
        </item>
    </channel>
</rss>