<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 14 Feb 2024 22:00:09 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[I Fucking Hate Jira (2022) (158 pts)]]></title>
            <link>https://ifuckinghatejira.com</link>
            <guid>39374797</guid>
            <pubDate>Wed, 14 Feb 2024 20:23:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ifuckinghatejira.com">https://ifuckinghatejira.com</a>, See on <a href="https://news.ycombinator.com/item?id=39374797">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="index">
    <p><a id="randomiser" href="https://ifuckinghatejira.com/posts/57">
      <img src="https://ifuckinghatejira.com/static/img/no-dinosaurs.jpg">
    </a></p><p>Click on the dinosaur for an honest opinion.</p>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Inside the proton, the ‘most complicated thing you could possibly imagine’ (123 pts)]]></title>
            <link>https://www.quantamagazine.org/inside-the-proton-the-most-complicated-thing-imaginable-20221019/</link>
            <guid>39374020</guid>
            <pubDate>Wed, 14 Feb 2024 19:26:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.quantamagazine.org/inside-the-proton-the-most-complicated-thing-imaginable-20221019/">https://www.quantamagazine.org/inside-the-proton-the-most-complicated-thing-imaginable-20221019/</a>, See on <a href="https://news.ycombinator.com/item?id=39374020">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="postBody"><div><h2>Inside the Proton, the ‘Most Complicated Thing You Could Possibly Imagine’</h2><div><p>The positively charged particle at the heart of the atom is an object of unspeakable complexity, one that changes its appearance depending on how it is probed. We’ve attempted to connect the proton’s many faces to form the most complete picture yet.  </p></div></div><figure><div><p><img alt="" src="https://d2r55xnwy6nx47.cloudfront.net/uploads/2022/10/PROTON_2880x1620_Lede-scaled.webp"></p></div><figcaption><div><p>Researchers recently discovered that the proton sometimes includes a charm quark and charm antiquark, colossal particles that are each heavier than the proton itself.</p><p data-pm-slice="1 1 []">Samuel Velasco/Quanta Magazine</p></div></figcaption></figure><div><h2>Introduction</h2><div><p>More than a century after Ernest Rutherford discovered the positively charged particle at the heart of every atom, physicists are still struggling to fully understand the proton.</p>
<p>High school physics teachers describe them as featureless balls with one unit each of positive electric charge — the perfect foils for the negatively charged electrons that buzz around them. College students learn that the ball is actually a bundle of three elementary particles called quarks. But decades of research have revealed a deeper truth, one that’s too bizarre to fully capture with words or images.</p>
<p>“This is the most complicated thing that you could possibly imagine,” said <a href="https://physics.mit.edu/faculty/michael-williams/">Mike Williams</a>, a physicist at the Massachusetts Institute of Technology. “In fact, you can’t even imagine how complicated it is.”</p>
<p>The proton is a quantum mechanical object that exists as a haze of probabilities until an experiment forces it to take a concrete form. And its forms differ drastically depending on how researchers set up their experiment. Connecting the particle’s many faces has been the work of generations. “We’re kind of just starting to understand this system in a complete way,” said <a href="https://physics.mit.edu/faculty/richard-milner/">Richard Milner</a>, a nuclear physicist at MIT.</p>

<p>As the pursuit continues, the proton’s secrets keep tumbling out. Most recently, a <a href="https://www.nature.com/articles/s41586-022-04998-2">monumental data analysis</a> published in August found that the proton contains traces of particles called charm quarks that are heavier than the proton itself.</p>
<p>The proton “has been humbling to humans,” Williams said. “Every time you think you kind of have a handle on it, it throws you some curveballs.”</p>
<p>Recently, Milner, together with Rolf Ent at Jefferson Lab, MIT filmmakers Chris Boebel and Joe McMaster, and animator James LaPlante, set out to transform a set of arcane plots that compile the results of hundreds of experiments into a series of animations of the shape-shifting proton. We’ve incorporated their animations into our own attempt to unveil its secrets.</p>
<h2><strong>Cracking Open the Proton</strong></h2>
<p>Proof that the proton contains multitudes came from the Stanford Linear Accelerator Center (SLAC) in 1967. In earlier experiments, researchers had pelted it with electrons and watched them ricochet off like billiard balls. But SLAC could hurl electrons more forcefully, and researchers saw that they bounced back differently. The electrons were hitting the proton hard enough to shatter it — a process called deep inelastic scattering — and were rebounding from point-like shards of the proton called quarks. “That was the first evidence that quarks actually exist,” said <a href="https://www.phys.virginia.edu/People/personal.asp?UID=xz5y">Xiaochao Zheng</a>, a physicist at the University of Virginia.</p>
<p>After SLAC’s discovery, which won the Nobel Prize in Physics in 1990, scrutiny of the proton intensified. Physicists have carried out hundreds of scattering experiments to date. They infer various aspects of the object’s interior by adjusting how forcefully they bombard it and by choosing which scattered particles they collect in the aftermath.</p>
</div></div><figure><div><p><img alt="" src="https://d2r55xnwy6nx47.cloudfront.net/uploads/2022/10/Proton_gun_fix_920-Desktop.svg"></p></div></figure><figure></figure><div><h2>Introduction</h2><div><p>By using higher-energy electrons, physicists can ferret out finer features of the target proton. In this way, the electron energy sets the maximum resolving power of a deep inelastic scattering experiment. More powerful particle colliders offer a sharper view of the proton.</p>
<p>Higher-energy colliders also produce a wider array of collision outcomes, letting researchers choose different subsets of the outgoing electrons to analyze. This flexibility has proved key to understanding quarks, which careen about inside the proton with different amounts of momentum.</p>
<p>By measuring the energy and trajectory of each scattered electron, researchers can tell if it has glanced off a quark carrying a large chunk of the proton’s total momentum or just a smidgen. Through repeated collisions, they can take something like a census — determining whether the proton’s momentum is mostly bound up in a few quarks, or distributed over many.</p>

<p>Even SLAC’s proton-splitting collisions were gentle by today’s standards. In those scattering events, electrons often shot out in ways suggesting that they had crashed into quarks carrying a third of the proton’s total momentum. The finding matched a theory from Murray Gell-Mann and George Zweig, who in 1964 posited that a proton consists of three quarks.</p>
<p>Gell-Mann and Zweig’s “quark model” remains an elegant way to imagine the proton. It has two “up” quarks with electric charges of +2/3 each and one “down” quark with a charge of −1/3, for a total proton charge of +1.</p>
</div></div><figure></figure><div><h2>Introduction</h2><div><p>But the quark model is an oversimplification that has serious shortcomings.</p>
<p>It fails, for instance, when it comes to a proton’s spin, a quantum property analogous to angular momentum. The proton has half a unit of spin, as do each of its up and down quarks. Physicists initially supposed that — in a calculation echoing the simple charge arithmetic — the half-units of the two up quarks minus that of the down quark must equal half a unit for the proton as a whole. But in 1988, the European Muon Collaboration <a href="https://www.sciencedirect.com/science/article/abs/pii/0370269388915237?via%3Dihub">reported</a> that the quark spins add up to far less than one-half. Similarly, the masses of two up quarks and one down quark only comprise about 1% of the proton’s total mass. These deficits drove home a point physicists were already coming to appreciate: The proton is much more than three quarks.</p>
<h2><strong>Much More Than Three Quarks</strong></h2>
<p>The Hadron-Electron&nbsp;Ring&nbsp;Accelerator (HERA), which operated in Hamburg, Germany, from 1992 to 2007, slammed electrons into protons roughly a thousand times more forcefully than SLAC had. In HERA experiments, physicists could select electrons that had bounced off of extremely low-momentum quarks, including ones carrying as little as 0.005% of the proton’s total momentum. And detect them they did: HERA’s electrons rebounded from a maelstrom of low-momentum quarks and their antimatter counterparts, antiquarks.</p>
</div></div><figure></figure><div><h2>Introduction</h2><div><p>The results confirmed a sophisticated and outlandish theory that had by then replaced Gell-Mann and Zweig’s quark model. Developed in the 1970s, it was a quantum theory of the “strong force” that acts between quarks. The theory describes quarks as being roped together by force-carrying particles called gluons. Each quark and each gluon has one of three types of “color” charge, labeled red, green and blue; these color-charged particles naturally tug on each other and form a group — such as a proton — whose colors add up to a neutral white. The colorful theory became known as quantum chromodynamics, or QCD.</p>
<p>According to QCD, gluons can pick up momentary spikes of energy. With this energy, a gluon splits into a quark and an antiquark — each carrying just a tiny bit of momentum — before the pair annihilates and disappears. It’s this “sea” of transient gluons, quarks and antiquarks that HERA, with its greater sensitivity to lower-momentum particles, detected firsthand.</p>
<p>HERA also picked up hints of what the proton would look like in more powerful colliders. As physicists adjusted HERA to look for lower-momentum quarks, these quarks — which come from gluons — showed up in greater and greater numbers. The results suggested that in even higher-energy collisions, the proton would appear as a cloud made up almost entirely of gluons.</p>
</div></div><figure></figure><div><h2>Introduction</h2><div><p>The gluon dandelion is exactly what QCD predicts. “The HERA data are direct experimental proof that QCD describes nature,” Milner said.</p>
<p>But the young theory’s victory came with a bitter pill: While QCD beautifully described the dance of short-lived quarks and gluons revealed by HERA’s extreme collisions, the theory is useless for understanding the three long-lasting quarks seen in SLAC’s gentle bombardment.</p>
<p>QCD’s predictions are easy to understand only when the strong force is relatively weak. And the strong force weakens only when quarks are extremely close together, as they are in short-lived quark-antiquark pairs. Frank Wilczek, David Gross and David Politzer identified this defining feature of QCD in 1973, winning the Nobel Prize for it 31 years later.</p>
<p>But for gentler collisions like SLAC’s, where the proton acts like three quarks that mutually keep their distance, these quarks pull on each other strongly enough that QCD calculations become impossible. Thus, the task of further demystifying the three-quark view of the proton has fallen largely to experimentalists. (Researchers who run “digital experiments,” in which QCD predictions are simulated on supercomputers, have also made <a href="https://www.quantamagazine.org/impossible-particle-discovery-adds-key-piece-to-the-strong-force-puzzle-20210927/">key contributions</a>.) And it’s in this low-resolution picture that physicists keep finding surprises.</p>
<h2><strong>A Charming New View</strong></h2>
<p>Recently, a team led by <a href="https://research.vu.nl/en/persons/juan-rojo">Juan Rojo</a> of the National Institute for Subatomic Physics in the Netherlands and VU University Amsterdam analyzed more than 5,000 proton snapshots taken over the last 50 years, using machine learning to infer the motions of quarks and gluons inside the proton in a way that sidesteps theoretical guesswork.</p>
<p><strong><em>&nbsp;</em></strong>The new scrutiny picked up a background blur in the images that had escaped past researchers. In relatively soft collisions just barely breaking the proton open, most of the momentum was locked up in the usual three quarks: two ups and a down. But a small amount of momentum appeared to come from a “charm” quark and charm antiquark — colossal elementary particles that each outweigh the entire proton by more than one-third.</p>
</div></div><figure><div></div></figure><div><h2>Introduction</h2><div><p>Short-lived charms frequently show up in the “quark sea” view of the proton (gluons can split into any of six different quark types if they have enough energy). But the results from Rojo and colleagues suggest that the charms have a more permanent presence, making them detectable in gentler collisions. In these collisions, the proton appears as a quantum mixture, or superposition, of multiple states: An electron usually encounters the three lightweight quarks. But it will occasionally encounter a rarer “molecule” of five quarks, such as an up, down and charm quark grouped on one side and an up quark and charm antiquark on the other.</p>
<p>Such subtle details about the proton’s makeup could prove consequential. At the Large Hadron Collider, physicists search for new elementary particles by bashing high-speed protons together and seeing what pops out; to understand the results, researchers need to know what’s in a proton to begin with. The occasional apparition of giant charm quarks would <a href="https://arxiv.org/abs/1512.06666">throw off the odds</a> of making more exotic particles.</p>
<p>And when protons called cosmic rays hurtle here from outer space and slam into protons in Earth’s atmosphere, charm quarks popping up at the right moments would shower Earth with <a href="https://arxiv.org/abs/2107.13852">extra-energetic neutrinos</a>, researchers calculated in 2021. These could confound observers <a href="https://www.quantamagazine.org/cosmic-map-of-ultrahigh-energy-particles-points-to-long-hidden-treasures-20210427/">searching</a> for high-energy neutrinos coming from across the cosmos.</p>
<p>Rojo’s collaboration plans to continue exploring the proton by searching for an imbalance between charm quarks and antiquarks. And heavier constituents, such as the top quark, could make even rarer and harder-to-detect appearances.</p>
<p>Next-generation experiments will seek still more unknown features. Physicists at Brookhaven National Laboratory hope to fire up the Electron-Ion Collider in the 2030s and pick up where HERA left off, taking higher-resolution snapshots that will enable the first 3D reconstructions of the proton. The EIC will also use spinning electrons to create detailed maps of the spins of the internal quarks and gluons, just as SLAC and HERA mapped out their momentums. This should help researchers to finally pin down the origin of the proton’s spin, and to address other fundamental questions about the baffling particle that makes up most of our everyday world.</p>

<p><em><strong>Correction:</strong> October 20, 2022</em><br>
<em>A previous version of the article erroneously implied that lower-momentum quarks live shorter lives than higher-momentum quarks in the quark sea. The text has been updated to clarify that all these quarks are lower-momentum and shorter-lived than those in the three quark-picture.</em></p>
</div></div></div><div><h2>Next article</h2><p>The Computer Scientist Who’s Boosting Privacy on the Internet</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Duolingo Sucks, Now What? (109 pts)]]></title>
            <link>https://ruhua-langblr.tumblr.com/post/739086003139149824/duolingo-sucks-now-what-a-guide</link>
            <guid>39373921</guid>
            <pubDate>Wed, 14 Feb 2024 19:17:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ruhua-langblr.tumblr.com/post/739086003139149824/duolingo-sucks-now-what-a-guide">https://ruhua-langblr.tumblr.com/post/739086003139149824/duolingo-sucks-now-what-a-guide</a>, See on <a href="https://news.ycombinator.com/item?id=39373921">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Freenginx: Core Nginx developer announces fork (437 pts)]]></title>
            <link>https://mailman.nginx.org/pipermail/nginx-devel/2024-February/K5IC6VYO2PB7N4HRP2FUQIBIBCGP4WAU.html</link>
            <guid>39373327</guid>
            <pubDate>Wed, 14 Feb 2024 18:29:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mailman.nginx.org/pipermail/nginx-devel/2024-February/K5IC6VYO2PB7N4HRP2FUQIBIBCGP4WAU.html">https://mailman.nginx.org/pipermail/nginx-devel/2024-February/K5IC6VYO2PB7N4HRP2FUQIBIBCGP4WAU.html</a>, See on <a href="https://news.ycombinator.com/item?id=39373327">Hacker News</a></p>
<div id="readability-page-1" class="page">
   
    <b>Maxim Dounin</b> 
    <a href="mailto:nginx-devel%40nginx.org?Subject=Re%3A%20announcing%20freenginx.org&amp;In-Reply-To=%3CZc0AXy1XQ5KBPY5Y%40mdounin.ru%3E" title="announcing freenginx.org">mdounin at mdounin.ru
       </a><br>
    <i>Wed Feb 14 18:03:11 UTC 2024</i>
    <ul>
        <li>Previous message (by thread): <a href="https://mailman.nginx.org/pipermail/nginx-devel/2024-February/RP7ZPCPM7W3E6X53FDCJIK6ZRMWMHGOF.html">[nginx] release-1.25.4 tag
</a></li>
        
         <li> <b>Messages sorted by:</b> 
              <a href="https://mailman.nginx.org/pipermail/nginx-devel/2024-February/date.html#17640">[ date ]</a>
              <a href="https://mailman.nginx.org/pipermail/nginx-devel/2024-February/thread.html#17640">[ thread ]</a>
              <a href="https://mailman.nginx.org/pipermail/nginx-devel/2024-February/subject.html#17640">[ subject ]</a>
              <a href="https://mailman.nginx.org/pipermail/nginx-devel/2024-February/author.html#17640">[ author ]</a>
         </li>
       </ul>
    <hr>  
<!--beginarticle-->
<pre>Hello!

As you probably know, F5 closed Moscow office in 2022, and I no
longer work for F5 since then.  Still, we’ve reached an agreement
that I will maintain my role in nginx development as a volunteer.
And for almost two years I was working on improving nginx and
making it better for everyone, for free.

Unfortunately, some new non-technical management at F5 recently
decided that they know better how to run open source projects.  In
particular, they decided to interfere with security policy nginx
uses for years, ignoring both the policy and developers’ position.

That’s quite understandable: they own the project, and can do
anything with it, including doing marketing-motivated actions,
ignoring developers position and community.  Still, this
contradicts our agreement.  And, more importantly, I no longer able
to control which changes are made in nginx within F5, and no longer
see nginx as a free and open source project developed and
maintained for the public good.

As such, starting from today, I will no longer participate in nginx
development as run by F5.  Instead, I’m starting an alternative
project, which is going to be run by developers, and not corporate
entities:

<a href="http://freenginx.org/">http://freenginx.org/</a>

The goal is to keep nginx development free from arbitrary corporate
actions.  Help and contributions are welcome.  Hope it will be
beneficial for everyone.


-- 
Maxim Dounin
<a href="http://freenginx.org/">http://freenginx.org/</a>
</pre>

<!--endarticle-->
    <hr>
    <ul>
        <!--threads-->
	<li>Previous message (by thread): <a href="https://mailman.nginx.org/pipermail/nginx-devel/2024-February/RP7ZPCPM7W3E6X53FDCJIK6ZRMWMHGOF.html">[nginx] release-1.25.4 tag
</a></li>
	
         <li> <b>Messages sorted by:</b> 
              <a href="https://mailman.nginx.org/pipermail/nginx-devel/2024-February/date.html#17640">[ date ]</a>
              <a href="https://mailman.nginx.org/pipermail/nginx-devel/2024-February/thread.html#17640">[ thread ]</a>
              <a href="https://mailman.nginx.org/pipermail/nginx-devel/2024-February/subject.html#17640">[ subject ]</a>
              <a href="https://mailman.nginx.org/pipermail/nginx-devel/2024-February/author.html#17640">[ author ]</a>
         </li>
       </ul>

<hr>
<a href="https://mailman.nginx.org/mailman/listinfo/nginx-devel">More information about the nginx-devel
mailing list</a><br>

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Reor – An AI note-taking app that runs models locally (172 pts)]]></title>
            <link>https://github.com/reorproject/reor</link>
            <guid>39372159</guid>
            <pubDate>Wed, 14 Feb 2024 17:00:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/reorproject/reor">https://github.com/reorproject/reor</a>, See on <a href="https://news.ycombinator.com/item?id=39372159">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <nav aria-label="Global">
            <ul>
                <li>
      
      <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Actions&quot;,&quot;label&quot;:&quot;ref_cta:Actions;&quot;}" href="https://github.com/features/actions">
      
      <div>
        <p>Actions</p><p>
        Automate any workflow
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Packages&quot;,&quot;label&quot;:&quot;ref_cta:Packages;&quot;}" href="https://github.com/features/packages">
      
      <div>
        <p>Packages</p><p>
        Host and manage packages
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Security&quot;,&quot;label&quot;:&quot;ref_cta:Security;&quot;}" href="https://github.com/features/security">
      
      <div>
        <p>Security</p><p>
        Find and fix vulnerabilities
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Codespaces&quot;,&quot;label&quot;:&quot;ref_cta:Codespaces;&quot;}" href="https://github.com/features/codespaces">
      
      <div>
        <p>Codespaces</p><p>
        Instant dev environments
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Copilot&quot;,&quot;label&quot;:&quot;ref_cta:Copilot;&quot;}" href="https://github.com/features/copilot">
      
      <div>
        <p>Copilot</p><p>
        Write better code with AI
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Code review&quot;,&quot;label&quot;:&quot;ref_cta:Code review;&quot;}" href="https://github.com/features/code-review">
      
      <div>
        <p>Code review</p><p>
        Manage code changes
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Issues&quot;,&quot;label&quot;:&quot;ref_cta:Issues;&quot;}" href="https://github.com/features/issues">
      
      <div>
        <p>Issues</p><p>
        Plan and track work
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Discussions&quot;,&quot;label&quot;:&quot;ref_cta:Discussions;&quot;}" href="https://github.com/features/discussions">
      
      <div>
        <p>Discussions</p><p>
        Collaborate outside of code
      </p></div>

    
</a></li>

            </ul>
          </div>
</li>


                <li>
      
      
</li>


                <li>
      
      <div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to GitHub Sponsors&quot;,&quot;label&quot;:&quot;ref_cta:GitHub Sponsors;&quot;}" href="https://github.com/sponsors">
      
      <div>
        <p>GitHub Sponsors</p><p>
        Fund open source developers
      </p></div>

    
</a></li>

            </ul>
          </div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to The ReadME Project&quot;,&quot;label&quot;:&quot;ref_cta:The ReadME Project;&quot;}" href="https://github.com/readme">
      
      <div>
        <p>The ReadME Project</p><p>
        GitHub community articles
      </p></div>

    
</a></li>

            </ul>
          </div>
          
      </div>
</li>


                <li>
    <a data-analytics-event="{&quot;category&quot;:&quot;Header menu top item (logged out)&quot;,&quot;action&quot;:&quot;click to go to Pricing&quot;,&quot;label&quot;:&quot;ref_cta:Pricing;&quot;}" href="https://github.com/pricing">Pricing</a>
</li>

            </ul>
          </nav>

        <div>
                


<qbsearch-input data-scope="repo:reorproject/reor" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="1pFIvS9qltJN5xbIkiyLsEKvhTRzHUQvGxtHxZYymLZxJgYU1ASVJdfLg3jfeRk6V7dUGPaONFDg9ps70XFsfQ" data-max-custom-scopes="10" data-header-redesign-enabled="false" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="reorproject/reor" data-current-org="reorproject" data-current-owner="" data-logged-in="false" data-copilot-chat-enabled="false" data-blackbird-indexed-repo-csrf="<esi:include src=&quot;/_esi/rails_csrf_token_form_hidden?r=whnierytwwpNrZyWlpXVJbdZaxP3OvcXAmt6FZxqZrxRmFVe4pVReNVHf3ateIboAq3v2DMsc5fARElb6pulAvqMpOH2fuPNDS%2BuGOQWNQA%2Bu72fQDCpkmpKiYPe4OkO2%2BcOuJYq4htyaoUGaKirQXD67PGrfUvYiBDD7TJxIOl3B8KJ2P7pQzwgySgf2L%2BMiaKDefaGsLqKXsMrQn1Yen4n8LAm0cW5GV6m1ehBwpug%2FP%2BJ7b4%2BMRZoTthm8XlAGTLBSLYReeLZ%2BLhWpgItz22uztnTqSMcLcI7HRYYms6fWd6kQnMrC%2F32eP6UGrK7xcKmDfeg%2FsYaRJx%2FWt7sQoJyw60jroYhlZ5x%2Fso%2FhZG%2F1x5m4w%2Fv7EhGnBpAEgoGg4kCI0b7ceL77us5cMVbnH1snOPhI7eQ%2Fv6Bh%2BRnVtNxUDcxDW3Ir4PS%2FavnmO76UvUWAXFuclKqb1dHCb%2F4wl9v4wC7LQ8OvsKWk1SxazMg%2BQPCXsS%2BE7UPwX3OLkaqZUp8MMAb%2B9eEcs2MqSY%3D--DcEd0vYrGV59tPgE--RDpJg83Vh2TV7lKRaBtX0w%3D%3D&quot; />">
  <div data-modal-dialog-overlay="" data-action="click:qbsearch-input#searchInputContainerClicked">
  <modal-dialog data-action="close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose" data-target="qbsearch-input.searchSuggestionsDialog" role="dialog" id="search-suggestions-dialog" aria-modal="true" aria-labelledby="search-suggestions-dialog-header" data-view-component="true">
      <h2 id="search-suggestions-dialog-header">Search code, repositories, users, issues, pull requests...</h2>
    
</modal-dialog></div>
  
  <div>
    
<dialog-helper>
  <dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="feedback-dialog" aria-modal="true" aria-labelledby="feedback-dialog-title" aria-describedby="feedback-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="feedback-dialog-title">
        Provide feedback
      </h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="feedback-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>

    <custom-scopes data-target="qbsearch-input.customScopesManager">
    
<dialog-helper>
  <dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="custom-scopes-dialog" aria-modal="true" aria-labelledby="custom-scopes-dialog-title" aria-describedby="custom-scopes-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="custom-scopes-dialog-title">
        Saved searches
      </h2>
        <h2 id="custom-scopes-dialog-description">Use saved searches to filter your results more quickly</h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="custom-scopes-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>
    </custom-scopes>
  </div>
</qbsearch-input>

            <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&amp;source=header-repo&amp;source_repo=reorproject%2Freor" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/reorproject/reor&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="24663a2c0ccc1737a33d07871b3a272a8ede998237283f3ae99204de7b4b1cff" data-analytics-event="{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/<user-name>/<repo-name>;ref_cta:Sign up;ref_loc:header logged out&quot;}">
              Sign up
            </a>
        </p></div>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Reverse-engineering an encrypted IoT protocol (115 pts)]]></title>
            <link>https://smlx.dev/posts/goodwe-sems-protocol-teardown/</link>
            <guid>39371831</guid>
            <pubDate>Wed, 14 Feb 2024 16:34:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://smlx.dev/posts/goodwe-sems-protocol-teardown/">https://smlx.dev/posts/goodwe-sems-protocol-teardown/</a>, See on <a href="https://news.ycombinator.com/item?id=39371831">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2 id="tldr"><a href="#tldr">##</a>
TL;DR</h2><ul><li>I reverse-engineered the encrypted protocol <a href="https://www.goodwe.com.au/">GoodWe</a> smart meters and solar inverters use to send metrics to the cloud.</li><li>I used this research to build a <a href="https://github.com/smlx/goodwe-exporters">prometheus exporter</a>.</li></ul><h2 id="the-sun-so-hot-right-now"><a href="#the-sun-so-hot-right-now">##</a>
The Sun: so hot right now</h2><p>I got a solar <abbr title="Photovoltaic">PV</abbr> system installed in my house in mid 2023.
I did the bare minimum of research beforehand - just talked to a couple of different installers about pricing, sizing and the economics of a battery.</p><p>One thing I certainly did <em>not</em> do is any research into brands and their relative hackability or security merits.
I just specified that I wanted to monitor the devices and see some metrics.
The installer told me that this required a smart meter and a mobile app.
Honestly I assumed that all brands would be equally horrific <abbr title="Internet of Things">IoT</abbr> junk, so I just went with the recommendation of the installer.
At least that way the <em>electrical</em> functionality had to be reasonable, right?</p><p>The result of my lucky dip was a <a href="https://www.goodwe.com.au/dns-g3-au">GoodWe DNS G3 Inverter</a> and a <a href="https://www.goodwe.com.au/single-phase-homekit">GoodWe HomeKit 1000 Smart Meter</a>.
These devices look quite slick, and so does the website.
They are also popular here in Australia, so my hopes were high that it would be easy to set up local monitoring, because surely someone else had figured out how to do it.</p><h2 id="post-install-setup"><a href="#post-install-setup">##</a>
Post-install setup</h2><h3 id="metrics-you-need-to-be-online"><a href="#metrics-you-need-to-be-online">###</a>
Metrics? You need to be online.</h3><p>Right after physical installation the system is producing power, but the metrics aren’t visible anywhere.
The documented way to see metrics is to connect the device to GoodWe’s cloud, and then use their web <abbr title="User Interface">UI</abbr> or mobile app.</p><p>The devices act in simultaneous wireless <abbr title="Access Point">AP</abbr> and <abbr title="Station (client)">STA</abbr> modes, and setup works like so:</p><ol><li>Connect to the device’s <abbr title="Wireless Local Area Network">WLAN</abbr>, which will be named <code>Solar-WiFiXXXXXXXX</code>, where the <code>X</code>s are the serial number of the device. The password is, naturally, <code>admin</code>.</li><li>Visit the device’s web <abbr title="User Interface">UI</abbr> on <code>10.10.100.253</code>.</li><li>Log in (using credentials <code>admin</code> / <code>admin</code>, of course!).</li><li>In the web <abbr title="User Interface">UI</abbr>, select the <abbr title="Wireless Local Area Network">WLAN</abbr> that you want the device to use to connect to the Internet.</li></ol><p>Now the devices are connected to GoodWe’s cloud.
But you still can’t see any metrics.</p><h3 id="sems-portal-account-required"><a href="#sems-portal-account-required">###</a>
SEMS Portal account required</h3><p>The next step is to go to GoodWe’s <a href="https://www.semsportal.com/"><abbr title="Smart Energy Management System">SEMS</abbr> Portal</a> and create an account.
Then let the installer know that the devices are connected, and the email you used to create an account on the <abbr title="Smart Energy Management System">SEMS</abbr> Portal.
Then the installer will <em>email</em> GoodWe (!?) to tell them to assocate your account with the serial number of the devices, and at some point GoodWe will action that request (I was assured they checked their inbox regularly).</p><p>Finally after a day or so the device’s metrics are visible in the <abbr title="Smart Energy Management System">SEMS</abbr> Portal.</p><p><img src="https://smlx.dev/posts/goodwe-sems-protocol-teardown/sems.png" alt="Screenshot of SEMS portal showing power usage over a day" title="" width="867" height="270"></p><p>According to <a href="https://en.goodwe.com/Ftp/EN/Downloads/Datasheet/GW_SEMS_Flyer-EN.pdf">this flyer</a>, it seems that the installer would have a portfolio of “power plants”, and they can use the <abbr title="Smart Energy Management System">SEMS</abbr> Portal to perform “Fault self-analysis &amp; troubleshooting”.</p><blockquote><p>SEMS includes a range of functions and features to ensure reliable operation and to deliver precise information to operators at the press of a button. It is accessible by multiple accounts with different levels of access for owners, installers and EPC companies</p></blockquote><h2 id="post-setup-state-of-play"><a href="#post-setup-state-of-play">##</a>
Post-setup state of play</h2><p>So now these two devices were physically installed, and connected to GoodWe’s cloud over the internet via my isolated <abbr title="Internet of Things">IoT</abbr> <abbr title="Virtual Local Area Network">VLAN</abbr>.
But I had questions:</p><ol><li>I wanted to scrape metrics locally, dammit! Why should I have to use the crappy cloud <abbr title="User Interface">UI</abbr> or equally bad mobile app?</li><li>What else can GoodWe do with this connection? E.g. can they remotely administer the devices? If so, can I disable this “feature”?</li></ol><p>It turns out that the inverter is powered by the solar panels, not by the grid.
So it loses power and goes offline as soon as the sun goes down.
And since I mostly have time to hack on this stuff after dark, I concentrated on the smart meter.</p><p>There is quite a cottage industry online documenting how to extract data from GoodWe <em>inverters</em>.
They respond to <a href="https://en.wikipedia.org/wiki/Modbus">Modbus</a> queries, an <a href="https://en.wikipedia.org/wiki/Operational_technology">Operational Technology</a> standard.
There are many Github repositories with useful information about the GoodWe Modbus protocol, such as:</p><ul><li>a <a href="https://github.com/marcelblijleven/goodwe">python library for extracting metrics</a>;</li><li>a <a href="https://github.com/mletenay/home-assistant-goodwe-inverter">Home Assistant integration</a>, built on that library; and</li><li>some <a href="https://github.com/tkubec/GoodWe/wiki">GoodWe-specific</a> <a href="https://github.com/MiG-41/Modbus-GoodWe-DT">field documentation</a>.</li></ul><p>Unfortunately, my Homekit 1000 smart meter is not supported by any of these libraries.</p><h2 id="hacking-the-homekit-1000"><a href="#hacking-the-homekit-1000">##</a>
Hacking the Homekit 1000</h2><p>I’m presenting the process I followed in chronological order.
So if you want to find out what actually worked, skip to the end.</p><h3 id="nmap"><a href="#nmap">###</a>
nmap</h3><p>The first thing I did was fire up <code>nmap</code>, and point it at the <abbr title="Homekit 1000">HK1000</abbr>.
It showed listening <abbr title="Transmission Control Protocol">TCP</abbr> port <code>23</code> - good old <a href="https://en.wikipedia.org/wiki/Telnet">Telnet</a>!
Connecting to this port and trying Username: <code>admin</code>, Password: <code>admin</code> gave me a command prompt!</p><pre tabindex="0"><code>$ nc 192.168.18.17 23
Login as:admin
Password:admin
CMD&gt;?
cfg         net         os          mft         
CMD&gt;
</code></pre><p>Poking around this prompt soon showed that it was pretty limited<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>, and it seemed to be a development interface that was left enabled.
I couldn’t get any metrics out of it.</p><p>I also ran <code>nmap</code> in aggressive mode and was rewarded with a hard crash in the web server, and the device resetting back to factory settings.</p><h3 id="packet-capture"><a href="#packet-capture">###</a>
Packet capture</h3><p>Sniffing the traffic from the device showed that it was connecting out to <code>tcp.goodwe-power.com:200001</code>, and sending packets at regular intervals.
However a quick look at the traffic revealed that while the serial number of my inverter was visible, the main body of the payload was a high-entropy blob.
So the metrics data I was after seemed to be encrypted.</p><p>I also found <a href="https://github.com/mletenay/home-assistant-goodwe-inverter/issues/3#issuecomment-1523697494">a Github comment</a> which came to the same conclusion.</p><h3 id="modbus"><a href="#modbus">###</a>
Modbus</h3><p>There is a <a href="https://github.com/jantenhove/GoodWeLogger/files/6024769/Goodwe_Modbus_PROTOCOL_Grid_English-ningzenkun20200527.1.pdf">GoodWe Modbus protocol</a> spec sheet and register map floating around the internet which was invaluable in understanding how GoodWe encodes metrics from their inverters.
From this documentation I built a Modbus scanner that simply queried every register.
The address is only 2 bytes wide, so there are ~65k possible addresses.</p><p>Unfortunately the <abbr title="Homekit 1000">HK1000</abbr> only returns a value for a single register address.
I forget which register it was, but it was something useless like Firmware Version.</p><h3 id="aa55-protocol"><a href="#aa55-protocol">###</a>
AA55 protocol</h3><p>GoodWe devices also support another (older?) protocol known as the AA55 protocol.
I couldn’t find much info about it except for <a href="https://yamasun.com.tw/upload/F_20170313191367UrC8jo.PDF">another old spec sheet</a>.</p><p>I built a scanner for this too, but the <abbr title="Homekit 1000">HK1000</abbr> didn’t respond to any queries.</p><h3 id="zz5a5a-protocol-mobile-app"><a href="#zz5a5a-protocol-mobile-app">###</a>
ZZ/5A5A protocol (mobile app)</h3><p>The <abbr title="Smart Energy Management System">SEMS</abbr> portal mobile app has an interesting function where you can connect to the <code>SOLAR-Wifixxxx</code> network, and configure the device using the app but <em>without</em> any authentication.</p><p>Sniffing this traffic (thanks to <a href="https://aircrack-ng.org/doku.php?id=airodump-ng">airodump-ng</a> and <a href="https://wiki.wireshark.org/HowToDecrypt802.11">Wireshark’s WPA2 decrypt support</a>) shows that the device can be configured without authentication by sending plaintext <abbr title="User Datagram Protocol">UDP</abbr> packets to the right port.
Of course, this port is listening on all interfaces so it also probably works via whichever local wifi network you connect the device to.
Gross.</p><p><img src="https://smlx.dev/posts/goodwe-sems-protocol-teardown/zz-protocol.png" alt="Screenshot of UDP dump showing the ZZ protocol" title="" width="552" height="91"></p><p>However, this protocol appeared to <em>only</em> be used for network configuration.
I didn’t find any way of extracting data from the device using this protocol.</p><h3 id="firmware-reverse-engineering"><a href="#firmware-reverse-engineering">###</a>
Firmware Reverse Engineering</h3><p>After no success with the query protocols, I decided that maybe the network was the wrong approach and I should try firmware instead.
I managed to dump the firmware of the device using the command prompt and a command similar to this<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>echo -e <span>'admin\nadmin\nspi rd 0 2097152\n'</span> | nc 192.168.18.17 <span>23</span> | tee ~/download/hk1000.spi2.img
</span></span></code></pre></div><p>This hexdump is interspersed with log lines, and the bytes are transposed.
So I dumped it twice, diffed the two dumps to eliminate the log lines, and fixed the transposition manually using vim.</p><p>Then I <a href="https://docs.python.org/3/library/binascii.html#binascii.unhexlify">unhexlified</a> the binary with <a href="https://manpages.debian.org/testing/xxd/xxd.1.en.html">xxd</a>:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>xxd -r -p hk1000.spi.img &gt; hk1000.spi.bin.img
</span></span></code></pre></div><p>And ran <a href="">binwalk</a> over it:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>binwalk -eM hk1000.spi.bin.img
</span></span></code></pre></div><p>This revealed that the OS was <a href="https://www.ecoscentric.com/ecos/index.shtml">eCos RTOS</a> on a <a href="https://en.wikipedia.org/wiki/MIPS_architecture">MIPS architecture</a>.
I spent some time trying to reverse this binary using <a href="https://ghidra-sre.org/">Ghidra</a>, but honestly I just don’t know what I’m doing when it comes to binary reverse engineering.</p><p>Finally, while staring at the binwalk output, these lines caught my eye:</p><pre tabindex="0"><code>1976456       0x1E2888        AES Inverse S-Box
1977752       0x1E2D98        AES S-Box
</code></pre><h3 id="packet-capture-redux"><a href="#packet-capture-redux">###</a>
Packet Capture redux</h3><p>Going back to the packet capture I finally noticed that the length of the encrypted blob section was always a multiple of 16, plus 2.</p><p>Wait a second… <a href="https://en.wikipedia.org/wiki/Advanced_Encryption_Standard"><abbr title="Advanced Encryption Standard">AES</abbr></a> block size is 16 bytes!</p><h2 id="analysis-of-the-goodwe-metrics-protocol"><a href="#analysis-of-the-goodwe-metrics-protocol">##</a>
Analysis of the GoodWe metrics protocol</h2><p>Since this is was a black-box analysis, I had to rely on probing via the <abbr title="Input / Output">I/O</abbr> I controlled: network and power.</p><h3 id="network-glitching3"><a href="#network-glitching3">###</a>
Network “glitching”<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup></h3><p>It was at this point that I found what would be the key to cracking the encryption scheme.</p><p>Back in October 2021, someone else did basically all the same work I did, and presented it at the <a href="https://www.mlug-au.org/">Melbourne Linux User’s Group</a>.
Not only that, but they put their presentation <a href="https://www.mlug-au.org/lib/exe/fetch.php?media=20210726-goodwe.pdf">online</a>!
Thank you Danny!</p><p>Anyway, Danny made a very interesting observation: if the internet connection went down, the device would buffer messages, and send them all at once when the connection came back up.
Crucially, for buffered frames sent in the same second, the first few 16-byte blocks of ciphertext were identical!</p><p>I was able to replicate this locally!</p><h3 id="empathy-a-powerful-reverse-engineering-tool"><a href="#empathy-a-powerful-reverse-engineering-tool">###</a>
Empathy: a powerful reverse-engineering tool</h3><p>When I’m looking at a problem like this, I like to put myself in the shoes of the developer.
What kind of person are they?
What are their motivations?</p><p>In this case, we can observe:</p><ul><li>Telnet left on in a production firmware image, with credentials <code>admin:admin</code>.</li><li><code>nmap</code> can crash the device hard enough to factory reset.</li><li>Packets sent over <abbr title="Transmission Control Protocol">TCP</abbr> with identifying data (serial number) in the clear.</li><li>The metrics seem to be poorly encrypted (identical section of ciphertext in consecutive frames).</li><li>Unauthenticated configuration protocol.</li><li>A web <abbr title="User Interface">UI</abbr> that looks like it was hacked together in an afternoon. Inspecting the source shows lots of commented out HTML blocks.</li></ul><p>In Danny’s presentation, he used this slide after discovering the Telnet port password:</p><p><img src="https://smlx.dev/posts/goodwe-sems-protocol-teardown/telnet-password.png" alt="Picard facepalm meme" title="" width="631" height="460"></p><p>However I think this is more appropriate:</p><p><video title="Michael Scott wow meme" autoplay="" loop="" muted="" playsinline="">
<source src="https://smlx.dev/posts/goodwe-sems-protocol-teardown/michael-scott-wow.mp4" type="video/mp4">There should have been an animation here but your browser doesn't seem to
support it.</video></p><p>What these observations tell me is that GoodWe doesn’t put a great deal of effort into securing their devices, and therefore the developers working on this device didn’t have much incentive to create a secure protocol.
So there’s a chance I can hack around their encryption.</p><p>Putting myself into the shoes of these developers, what would I need to implement a metric protocol?</p><ul><li>Framing: this is <abbr title="Transmission Control Protocol">TCP</abbr>; it’s a byte stream. So we need a header of some kind to know where frames start.</li><li>Length: how many bytes after the header do we need to read to get the full frame?</li><li>Detecting data corruption: not anything malicious, just bitflips.</li></ul><p>Looking at the packet captures, it is easy to see <code>POSTGW</code> is the frame header, and the very next field looks like a big-endian encoded int32 with a value consistently three bytes shy of the length of the data before the next <code>POSTGW</code>.
That must be the length!</p><p>And finally: detecting data corruption.
In the GoodWe Modbus document linked above, there is a description of the <abbr title="Cyclic Redundancy Check">CRC</abbr> used to detect data corruption.
It is a standard <a href="https://en.wikipedia.org/wiki/Cyclic_redundancy_check#Polynomial_representations">Modbus CRC-16</a> (two bytes), designed to effectively detect bitflips.
Again, assuming I am a software developer who is familiar with Modbus but who has been tasked with sending data over the internet (and didn’t really care much for security), why wouldn’t I use an algorithm or library I am already familiar with?</p><p>A quick check proves that running the data between the length field and the last two bytes through the Modbus <abbr title="Cyclic Redundancy Check">CRC</abbr> algorithm returns a value matching the last two bytes of the frame.</p><figure><img src="https://smlx.dev/posts/goodwe-sems-protocol-teardown/postgw.png" alt="Annotated hexdump of protocol frame showing the components"><figcaption><h4>An annotated frame, with length in red, device type and serial in green, timestamp in blue and purple, and encrypted blob in yellow.</h4></figcaption></figure><p>My best guess for the length field being <em>three</em> bytes shy of the length of data rather than two is that it is just a sloppy implementation with an off-by-one error, which matches my profile of the developers.</p><p>Another data point to paint a picture of the engineering quality: the <abbr title="Cyclic Redundancy Check">CRC</abbr> of frames from the client are encoded in big-endian byte order (same as all the other integers encoded in the protocol).
However the <em>server</em> sends the <abbr title="Cyclic Redundancy Check">CRC</abbr> in little-endian byte order.
Why?
Maybe the server is <code>x86</code> and the developer forgot to call <a href="https://pubs.opengroup.org/onlinepubs/9699919799/functions/htonl.html"><code>htons()</code></a>?</p><p>Now I just had the encrypted blob to decipher.</p><h3 id="encryption-scheme"><a href="#encryption-scheme">###</a>
Encryption scheme</h3><p>I guessed that they must be using <abbr title="Advanced Encryption Standard">AES</abbr> in <a href="https://en.wikipedia.org/wiki/Block_cipher_mode_of_operation#Cipher_block_chaining_(CBC)"><abbr title="Cipher Block Chaining">CBC</abbr></a> mode because:</p><ul><li>The identical section of ciphertext in consecutive frames is a <a href="https://cwe.mitre.org/data/definitions/329.html">classic <abbr title="Cipher Block Chaining">CBC</abbr> failure mode</a> when reusing <abbr title="Initialization Vector">IV</abbr>s.</li><li>This is an old mode and widely supported in libraries, making it easy to use.</li><li>Since they don’t care about security they are hardly likely to be using <abbr title="Authenticated Encryption with Additional Data">AEAD</abbr> modes.</li></ul><p>When implementing a scheme using <abbr title="Cipher Block Chaining">CBC</abbr>, it is critically important that initialization vectors are not reused.
Otherwise identical plaintext will give you identical ciphertext.
Metrics from a smart meter are highly likely to be the same minute-to-minute, which is probably why we see identical sections of ciphertext in successive frames with the same <abbr title="Initialization Vector">IV</abbr>!</p><p>A common practice is to prefix the <abbr title="Initialization Vector">IV</abbr> to the ciphertext.
This is known as an explicit initialization vector, and it doesn’t need to be secret - just randomly generated in a cryptographically secure manner.
However what if you are running on a microcontroller without a <a href="https://en.wikipedia.org/wiki/Hardware_random_number_generator"><abbr title="Non-deterministic Random Bit Generator">NRBG</abbr></a>? Or maybe you just don’t know or care about <abbr title="Cipher Block Chaining">CBC</abbr> footguns?
Then you have to use some other “unique-ish” value!</p><p>The device is designed to only send metrics every minute.
Therefore the developers may have assumed that time based <abbr title="Initialization Vector">IV</abbr>s will be unique enough, without taking into account buffering on network outage.</p><h3 id="power-glitching"><a href="#power-glitching">###</a>
Power “glitching”</h3><p>The final and most difficult question: what is the encryption key?</p><p>The first thing I checked was what happened when the device rebooted: was there any key exchange or handshake?
Fortunately the web <abbr title="User Interface">UI</abbr> has a reboot button, so it was easy to confirm that no, there is no key exchange on startup.</p><p>So because we are assuming <abbr title="Advanced Encryption Standard">AES</abbr> (symmetric encryption), that probably means… fixed keys!</p><p>Since the keys are fixed, they are likely hard-coded.
<abbr title="Advanced Encryption Standard">AES</abbr> can use 16, 24, or 32 byte keys, so I started by assuming a 16-byte key.
I suspected they’d use some string like <code>GoodWeSolarPower</code>, and store it as a static string or byte array.
I poked around in the firmware a bit with Ghidra, but didn’t find any promising strings.</p><p>But in any case, there was another problem.
One of the properties of <abbr title="Advanced Encryption Standard">AES</abbr>-<abbr title="Cipher Block Chaining">CBC</abbr> is that you can plug <em>any</em> <abbr title="Initialization Vector">IV</abbr> and secret key into it and it will “decrypt”.
But unless the <abbr title="Initialization Vector">IV</abbr> and key are correct, the output will be garbage.
So how to know if I manage to correctly guess the <abbr title="Initialization Vector">IV</abbr> and key?</p><p>At this point I made another educated guess.
The frame header and length field use <a href="https://en.wikipedia.org/wiki/ASCII"><abbr title="American Standard Code for Information Interchange">ASCII</abbr></a> characters and leading null bytes respectively.
Assuming the plaintext metric data is similarly structured, it will have relatively low <a href="https://en.wikipedia.org/wiki/Entropy_(information_theory)">Shannon entropy</a>.
Another property of <abbr title="Advanced Encryption Standard">AES</abbr> is that it is a <a href="https://crypto.stackexchange.com/a/1651">secure block cipher</a>.
That is, the ciphertext should be indistinguishable from random bytes.
Therefore, using the incorrect key or <abbr title="Initialization Vector">IV</abbr> should result in <em>high entropy</em> garbage.</p><p>Assuming the timestamp in the frame (which is null-padded to 16 bytes) is the <abbr title="Initialization Vector">IV</abbr>, I wrote a really dumb tool to:</p><ol><li>step through the firmware one byte at a time, taking the next 16 bytes as a key.</li><li>“decrypt” the encrypted blob using that key, and the timestamp prefix as the <abbr title="Initialization Vector">IV</abbr>.</li><li>calculate the entropy of the decrypted blob. If it is below a given threshold, print the plaintext and key.</li></ol><p>Fortunately although this was a very naïve brute force algorithm, one great thing about 2024 is that computers are fast.</p><p>Running this tool over the firmware dump from my device only took a few seconds and yielded… nothing.
Huh.</p><p>Fortunately my previous googling efforts had discovered a <a href="https://drive.google.com/drive/folders/110hBxoNVC4M9F_GK5sKP7uq_aDNxwstZ">public Google drive</a> with relatively recent updates (early 2023) containing firmware for (all?) GoodWe inverters<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup>.
Running the tool over a firmware image for another device yielded… nothing again!</p><p>Finally on the third attempt, I got a single hit:</p><p><img src="https://smlx.dev/posts/goodwe-sems-protocol-teardown/key.png" alt="Screenshot of the firmware scan tool showing plaintext, the key used for decryption, and an entropy calculation of 2.862" title="" width="818" height="280"></p><p>Of course!
The key was just all bits set.
Why not!?</p><p>I doubt this was actually hard-coded as a key anywhere in the binary blob.
I think I just got lucky that this firmware had a run of <code>0xff</code> bytes.</p><p>Finally I had a plaintext with obvious structure, but nothing mapping fields to metrics values.
However I did have an <a href="https://en.wikipedia.org/wiki/Oracle_machine#Oracles">oracle</a>: the <abbr title="Smart Energy Management System">SEMS</abbr> Portal API!
I was able to dump metric values for my smart meter using <a href="https://curl.se/">curl</a> on the <abbr title="Smart Energy Management System">SEMS</abbr> Portal API, and observe the metrics changing every time a packet was sent from the smart meter.</p><p>Then by eyeballing the packets and the values (assuming standard <a href="https://en.wikipedia.org/wiki/Two%27s_complement">two’s complement</a> signed integer encoding) it was relatively straightforward, though a little time consuming, to map offsets to metrics values.</p><p>This wiring diagram was helpful to understand that there were really only two <abbr title="Current Transformer">CT</abbr> sensors and every other metric was calculated from those two numbers:</p><p><img src="https://smlx.dev/posts/goodwe-sems-protocol-teardown/hk-wiring.png" alt="High-level Homekit 1000 wiring diagram" title="" width="924" height="358"></p><h2 id="prometheus--grafana"><a href="#prometheus--grafana">##</a>
Prometheus &amp; Grafana</h2><p>I like <a href="https://prometheus.io/">Prometheus</a> for gathering metrics.
So I built an <a href="https://github.com/smlx/goodwe-exporters">exporter</a> based on the research described above.
It works by conducting a <a href="https://en.wikipedia.org/wiki/Man-in-the-middle_attack">man-in-the-middle attack</a> on the protocol.
Pointing the <abbr title="Homekit 1000">HK1000</abbr> at the <abbr title="Internet Protocol">IP</abbr> address of the exporter when it requests <code>tcp.goodwe-power.com</code> will cause the <abbr title="Homekit 1000">HK1000</abbr> to connect to the exporter instead of the GoodWe cloud.
Then the exporter will sniff the metrics out of the frames and forward them to the real <code>tcp.goodwe-power.com</code>.</p><p>The nice thing about this design is that you still get metrics in <abbr title="Smart Energy Management System">SEMS</abbr> Portal.
These metrics are visible to your installer, so if you have problems it is easy for them to troubleshoot.
I also added support for my inverter, which uses approximately the same protocol.</p><p>In addition, the Prometheus exporter will reject any packets from the server that it doesn’t understand.
So <em>hopefully</em> unsolicited firmware updates will be blocked.</p><p>Finally, I created a <a href="https://grafana.com/grafana/dashboards/20479-household-power/">dashboard</a> in <a href="https://grafana.com/">Grafana</a>:</p><p><img src="https://smlx.dev/posts/goodwe-sems-protocol-teardown/grafana.png" alt="Household Power Grafana dashboard, showing a summary of power usage over a single day" title="" width="1007" height="396"></p><h2 id="conclusions"><a href="#conclusions">##</a>
Conclusions</h2><ul><li>This exercise has reinforced my prejudice that <abbr title="Internet of Things">IoT</abbr> devices are horribly insecure. In the case of GoodWe, where they even <em>have</em> authentication, they use fixed default passwords such as <code>admin</code>, and leave Telnet debug interfaces listening on their production devices.</li><li>Although the metrics protocol and encryption scheme are insecure, I didn’t find anything that could really be described as a security vulnerability as opposed to a design decision.</li><li>Only the metrics were encrypted in the data sent to <abbr title="Smart Energy Management System">SEMS</abbr> Portal over the internet.
Not the model or serial number.
So even with (bad) encryption, they have left the most sensitive data unprotected.
I guess they are just obfuscating the metrics?
Or maybe the boss asked for encryption?
<a href="https://youtu.be/_k7U55anSW8?t=132">“He said encryption! Give him encryption!”</a>.</li><li>Conversely the <em>hardware</em> seems pretty good, functions well, and looks great!</li><li>I spent months tinkering on this on-and-off.
I was motivated by equal parts indignant anger at not being able to scrape metrics locally from a device so intimately integrated into <em>my</em> house and running on <em>my</em> network, and morbid curiosity about what security flaw I was going to uncover next.
Now I understand what jwz means when he talks about <a href="https://www.jwz.org/hacks/">writing software in self-defence</a>.</li></ul><h2 id="how-to-secure-goodwe-devices"><a href="#how-to-secure-goodwe-devices">##</a>
How to secure GoodWe devices</h2><p>Finally, here’s my advice if you have a GoodWe device:</p><ul><li>Whatever else you do, keep these things off the public internet!
Preferably in your private, firewalled <abbr title="Internet of Things">IoT</abbr> <abbr title="Virtual Local Area Network">VLAN</abbr>.</li><li>There doesn’t seem to be a simple way to disable the <code>Solar-Wifixxxx</code> <abbr title="Wireless Local Area Network">WLAN</abbr> after the devices are set up.
So set a strong password, because the default is <code>admin</code>.
You can do this via the web <abbr title="User Interface">UI</abbr>.</li><li>The web server is listening on all interfaces, so it is accessible from your <abbr title="Virtual Local Area Network">VLAN</abbr>.
Change the password for the web UI from <code>admin</code> to something a bit more secure.
Note: not all devices have this option easily accessible.
For example the <abbr title="Homekit 1000">HK1000</abbr> only allows changing this password via the Telnet interface.</li></ul><p>For the paranoid:</p><ul><li>My prometheus exporter drops incoming packets it doesn’t recognize. Only metrics will flow, not e.g. firmware updates (I hope - I haven’t seen any come through yet). So in theory it will block remote administration of the devices.</li></ul><h2 id="miscellaneous-notes"><a href="#miscellaneous-notes">##</a>
Miscellaneous notes</h2><p>This section contains a few notes I made that didn’t fit into the narrative of the blog post, but are interesting nonetheless.</p><h3 id="goodwes-cyber-security-claims"><a href="#goodwes-cyber-security-claims">###</a>
GoodWe’s Cyber Security claims</h3><p>GoodWe has a page on Cyber Security on their website with a nice infographic, basically confirming everything I have just discovered:</p><blockquote><p>In order to prevent cyber-attacks on photovoltaic systems to the greatest extent, inverter manufacturers usually deploy various security policies on the equipment side and server side. Taking GoodWe as an example, to ensure the security of data transmission between the inverter and the server, we use the transmission protocols of CRC+AES and TLS respectively for communication with servers with different functions.</p></blockquote><p><img src="https://smlx.dev/posts/goodwe-sems-protocol-teardown/goodwe-cyber.png" alt="Infographic diagram of an inverter and a laptop connecting to the cloud. The inverter connection has a lock icon and is labelled AES 128. The laptop connection also has a lock icon and is labelled HTTPS." title="" width="909" height="548"></p><p>This is a great demonstration of how you can use secure cryptographic primitives such as <abbr title="Advanced Encryption Standard">AES</abbr>-<abbr title="Cipher Block Chaining">CBC</abbr>, and still come up with an insecure encryption scheme.</p><h3 id="hi-flying-and-xinwu"><a href="#hi-flying-and-xinwu">###</a>
Hi-Flying and Xinwu</h3><p>The GoodWe devices seem to use an <abbr title="Internet of Things">IoT</abbr> platform common to several Chinese manufacturers, for example <a href="https://github.com/StephanJoubert/home_assistant_solarman/blob/03470164fcad6b57d528f8c5b72dbc5603b0b2df/custom_components/solarman/scanner.py#L12">Solarman</a>.
It has a unique discovery protocol where you broadcast a special packet to a given port, and the device replies with its <abbr title="Internet Protocol">IP</abbr>, <abbr title="Medium Access Control">MAC</abbr>, and <abbr title="Service Set IDentifier">SSID</abbr> (which includes the device serial).</p><p>For example (in separate terminals):</p><div><pre tabindex="0"><code data-lang="bash"><span><span>nc -u -l -p <span>50123</span>
</span></span><span><span>192.168.18.17,907856FECDAB,Solar-WiFi12345678
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="bash"><span><span>echo -n WIFIKIT-214028-READ | nc -u -b -p <span>50123</span> 192.168.18.255 <span>48899</span>
</span></span></code></pre></div><p>According to the config dumped from the Telnet command prompt, the chip in the <abbr title="Homekit 1000">HK1000</abbr> is the <a href="http://www.hi-flying.com/hf-a21">HF-A21</a>, from a company called Hi-Flying, <a href="http://www.hi-flying.com/index.php?route=information/contact">based in Shanghai</a>.
You can build your <abbr title="Internet of Things">IoT</abbr> device on top of this platform by loading your own application onto it, while the included <abbr title="Operating System">OS</abbr> takes care of the hardware, network etc.</p><p>An interesting part of the discovery protocol is the string <code>214028</code>.
Where does this come from?
Well approximately 150km from the Hi-Flying office is <a href="https://en.wikipedia.org/wiki/Xinwu,_Wuxi">Xinwu district, Wuxi</a>.
According to Wikipedia:</p><blockquote><p>In 2013, the output value of Internet of Things (IoT) core industry in Wuxi New District exceeded 70 billion yuan, accounting for 38.4 percent of the output value of the whole high-tech industry in the district. Wuxi New District has formed a cloud computing industrial distribution, featuring hardware, platform and application.</p></blockquote><p>Xinwu’s postcode is 214028.</p><h3 id="remote-administration"><a href="#remote-administration">###</a>
Remote administration</h3><p>According to market researchers, GoodWe was the <a href="https://www.woodmac.com/press-releases/top-10-solar-pv-inverter-vendors-account-for-86-of-global-market-share/">fifth largest supplier of solar inverters worldwide in 2022</a>.
GoodWe have full remote administration capability on the devices, including the capability to <a href="https://www.4x4community.co.za/forum/showthread.php/329200-Goodwe-Remote-firmware-update">push firmware updates</a>.
This seems like a lot of power for any company, let alone a company headquartered in a totalitarian dictatorship, to have over national power grids.</p><h3 id="batman-mode"><a href="#batman-mode">###</a>
Batman mode</h3><p><del>To validate the <abbr title="Man-In-The-Middle">MITM</abbr> functionality</del> For fun, I implemented Batman mode in the prometheus exporter.
In this mode, rather than forwarding metrics to the <abbr title="Smart Energy Management System">SEMS</abbr> Portal, the exporter replaces them with the <a href="https://math.stackexchange.com/q/54506">batman equation</a>.</p><p><img src="https://smlx.dev/posts/goodwe-sems-protocol-teardown/batman.png" alt="Screenshot of SEMS Portal showing batman logo plotted on the power graph" title="" width="648" height="766"></p><h3 id="dns-updates"><a href="#dns-updates">###</a>
DNS updates</h3><p>The GoodWe devices send their metrics to <code>tcp.goodwe-power.com:200001</code>.
When I first started investigating the protocol in mid 2023, this resolved to an <abbr title="Internet Protocol">IP</abbr> address in Alibaba Cloud.
However late last year this was updated to now resolve to a pair of <abbr title="Elastic Load Balancer">ELB</abbr>s in <abbr title="Amazon Web Services">AWS</abbr>.</p><p><img src="https://smlx.dev/posts/goodwe-sems-protocol-teardown/dns.goodwe-power.png" alt="Screenshot of SecurityTrails showing the historical DNS records for tcp.goodwe-power.com" title="" width="992" height="318">
<img src="https://smlx.dev/posts/goodwe-sems-protocol-teardown/dns.semsportal.png" alt="Screenshot of SecurityTrails showing the historical DNS records for www.semsportal.com" title="" width="986" height="366"></p><p>In both Alibaba Cloud and in <abbr title="Amazon Web Services">AWS</abbr> they seem to be doing <abbr title="Domain Name System">DNS</abbr> load balancing, because while the <a href="https://securitytrails.com/">SecurityTrails</a> screenshots above show <abbr title="United States">US</abbr> <abbr title="Internet Protocol">IP</abbr>s, from here in Australia both those domains resolved to <abbr title="Internet Protocol">IP</abbr>s in Alibaba Cloud China (previously), and now to <abbr title="Amazon Web Services">AWS</abbr> Sydney.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[YC: Requests for Startups (218 pts)]]></title>
            <link>https://www.ycombinator.com/rfs</link>
            <guid>39371805</guid>
            <pubDate>Wed, 14 Feb 2024 16:31:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ycombinator.com/rfs">https://www.ycombinator.com/rfs</a>, See on <a href="https://news.ycombinator.com/item?id=39371805">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<h3 id="introduction"><strong id="introduction"><strong id="introduction">INTRODUCTION</strong></strong></h3>
<p id="at-yc-we-often-find-ourselves-discussing-the-ideas-and-categories-wed-like-to-see-more-people-working-on-">At YC we often find ourselves discussing the ideas and categories we’d like to see more people working on. </p>


<h3 id="applying-machine-learning-to-robotics"><strong id="applying-machine-learning-to-robotics">Applying Machine Learning to robotics</strong></h3>
<p id="-diana-hu-and-jared-friedman"><em id="-diana-hu-and-jared-friedman">- <a href="https://www.ycombinator.com/people/diana-hu" id="diana-hu">Diana Hu</a> and <a href="https://www.ycombinator.com/people/jared-friedman" id="jared-friedman">Jared Friedman</a></em></p>
<p id="robotics-hasnt-yet-had-its-gpt-moment-but-we-think-its-close">Robotics hasn't yet had its GPT moment, but we think it’s close.</p>
<p id="yc-has-followed-robotics-closely-for-two-decades-in-fact-one-of-ycs-founders-trevor-blackwell-is-a-pioneering-roboticist-who-built-the-first-dynamically-balancing-bipedal-robot">YC has followed robotics closely for two decades. In fact, one of YC’s founders, <a href="https://en.wikipedia.org/wiki/Trevor_Blackwell" id="trevor-blackwell">Trevor Blackwell</a>, is a pioneering roboticist who built the first dynamically balancing bipedal robot.</p>
<p id="for-decades-everyone-has-known-that-robots-are-the-future-as-any-science-fiction-novel-will-show-but-that-future-proved-elusive-because-previous-generations-of-robots-were-expensive-and-brittle-requiring-controlled-conditions-with-the-rapid-improvements-in-foundation-models-its-finally-possible-to-make-robots-that-have-humanlevel-perception-and-judgment-thats-been-the-missing-piece">For decades, everyone has known that robots are the future, as any science fiction novel will show. But that future proved elusive because previous generations of robots were expensive and brittle, requiring controlled conditions. &nbsp;With the rapid improvements in foundation models, it's finally possible to make robots that have human-level perception and judgment. That’s been the missing piece.</p>
<p id="while-consumer-usecases-feature-heavily-in-science-fiction-some-of-the-overlooked-and-most-immediately-addressable-applications-for-robots-are-b2b-specifically-we-think-promising-areas-are-industrial-usecases-like-gecko-robotics-w16-which-builds-inspection-robots-and-farm-usecases-like-bear-flag-robotics-w18-which-builds-autonomous-tractors-and-was-acquired-by-john-deere">While consumer use-cases feature heavily in science fiction, some of the overlooked and most immediately addressable applications for robots are B2B. Specifically, we think promising areas are industrial use-cases like Gecko Robotics (W16), which builds inspection robots, and farm use-cases like Bear Flag Robotics (W18), which builds autonomous tractors and was acquired by John Deere.</p>
<p id="were-interested-in-funding-people-building-software-tools-to-help-other-people-to-make-robots-along-with-people-building-the-robots-themselves">We're interested in funding people building software tools to help other people to make robots, along with people building the robots themselves.</p>
<h3 id="using-machine-learning-to-simulate-the-physical-world"><strong id="using-machine-learning-to-simulate-the-physical-world">Using Machine Learning to simulate the physical world</strong></h3>
<p id="-diana-hu-and-jared-friedman"><em id="-diana-hu-and-jared-friedman">- <a href="https://www.ycombinator.com/people/diana-hu" id="diana-hu">Diana Hu</a> and <a href="https://www.ycombinator.com/people/jared-friedman" id="jared-friedman">Jared Friedman</a></em></p>
<p id="many-essential-software-tools-work-by-simulating-the-world-using-known-principles-of-physics-and-chemistry-weather-prediction-computational-fluid-dynamics-for-designing-rockets-and-airplanes-and-tools-for-drug-discovery-that-predict-the-interactions-of-molecules--today-many-of-these-are-based-on-running-a-full-physics-simulation-of-the-world-these-are-very-computationally-heavy-since-they-are-solving-complex-multivariate-mathematical-equations">Many essential software tools work by simulating the world using known principles of physics and chemistry. Weather prediction, computational fluid dynamics for designing rockets and airplanes, and tools for drug discovery that predict the interactions of molecules — today many of these are based on running a full physics simulation of the world. These are very computationally heavy since they are solving complex multivariate mathematical equations.</p>
<p id="it-turns-out-that-ai-models-are-general-functional-approximators-that-can-also-solve-and-predict-problems-like-these-without-needing-to-explicitly-know-about-physics-this-results-in-predictions-that-are-much-less-computationally-expensive-and-can-be-completed-in-minutes-or-seconds-on-much-smaller-computers-rather-than-taking-daysweeks-and-super-computers">It turns out that AI models are general functional approximators that can also solve and predict problems like these without needing to explicitly know about physics. This results in predictions that are much less computationally expensive and can be completed in minutes or seconds on much smaller computers rather than taking days/weeks and super computers.</p>
<p id="were-interested-in-companies-replacing-existing-simulations-with-mlbased-ones-along-with-companies-using-mlbased-simulations-to-open-new-markets-currently-unaddressable">We're interested in companies replacing existing simulations with ML-based ones, along with companies using ML-based simulations to open new markets currently unaddressable.</p>
<h3 id="new-defense-technology"><strong id="new-defense-technology">New defense technology</strong></h3>
<p id="-jared-friedman-and-gustaf-alstrmer"><em id="-jared-friedman-and-">- <a href="https://www.ycombinator.com/people/jared-friedman" id="jared-friedman">Jared Friedman</a> and </em><a href="https://www.ycombinator.com/people/gustaf-alstromer" id="gustaf-alstrmer"><em id="gustaf-alstr">Gustaf Alstr</em>ö<em id="mer">mer</em></a></p>
<p id="the-us-is-now-engaged-in-largescale-conflicts-in-several-regions-that-threaten-to-change-our-world-while-the-us-has-historically-led-the-world-in-defense-technology-the-defense-contractors-it-depends-on-have-grown-slow-and-inefficient-bloated-by-decades-of-costplus-contracts-">The US is now engaged in large-scale conflicts in several regions that threaten to change our world. &nbsp;While the US has historically led the world in defense technology, the defense contractors it depends on have grown slow and inefficient, bloated by decades of cost-plus contracts. </p>
<p id="spacex-showed-the-world-that-a-private-space-company-could-be-vastly-more-effective-than-the-publiclyfunded-united-launch-alliance-new-companies-that-sell-to-the-dod-like-palantir-and-anduril-are-showing-that-the-same-thing-is-true-for-defense-tech">SpaceX showed the world that a private space company could be vastly more effective than the publicly-funded United Launch Alliance. New companies that sell to the DoD like Palantir and Anduril are showing that the same thing is true for defense tech.</p>
<p id="silicon-valley-was-born-in-the-early-20th-century-as-an-rd-area-for-the-us-military-early-silicon-valley-companies-were-largely-funded-by-the-dod-and-played-a-key-role-in-wwii-by-building-military-radar-codebreaking-equipment-and-components-for-the-atomic-bomb">Silicon Valley was born in the early 20th century as an R&amp;D area for the US military. Early Silicon Valley companies were largely funded by the DoD and <a href="https://steveblank.com/secret-history/#Secret%20History%20Backstory" id="played-a-key-role-in-wwii">played a key role in WWII</a> by building military radar, code-breaking equipment, and components for the atomic bomb.</p>
<p id="this-decade-is-the-time-to-return-silicon-valley-to-these-roots">This decade is the time to return Silicon Valley to these roots.</p>
<h3 id="bring-manufacturing-back-to-america"><strong id="bring-manufacturing-back-to-america">Bring manufacturing back to America</strong></h3>
<p id="-jared-friedman"><em id="-jared-friedman">- <a href="https://www.ycombinator.com/people/jared-friedman" id="jared-friedman">Jared Friedman</a></em></p>
<p id="the-uk-became-the-worlds-richest-country-in-the-19th-century-by-being-the-workshop-of-the-world-the-us-did-the-same-in-the-20th-century-but-in-recent-decades-weve-given-up-this-role-the-hollowing-out-of-us-manufacturing-has-led-to-social-and-political-division-and-left-us-in-a-precarious-place-geopolitically">The UK became the world's richest country in the 19th century by being the workshop of the world. The US did the same in the 20th century. But in recent decades, we've given up this role. The hollowing out of US manufacturing has led to social and political division and left us in a precarious place geopolitically.</p>
<p id="bringing-manufacturing-back-to-america-is-one-of-the-biggest-areas-of-bipartisan-agreement-and-the-chips-act-which-was-passed-in-2022-proves-that-the-us-government-will-put-serious-money-behind-this-objective">Bringing manufacturing back to America is one of the biggest areas of bipartisan agreement, and the CHIPS act which was passed in 2022 proves that the US government will put serious money behind this objective.</p>
<p id="other-changes-in-the-world-have-set-the-stage-for-a-resurgence-of-us-manufacturing-new-mlbased-robotics-systems-will-make-it-possible-to-automate-far-more-which-will-reduce-the-costoflabor-arbitrage-that-pushed-manufacturing-to-other-countries-in-the-first-place-companies-like-spacex-and-tesla-have-trained-an-entire-generation-of-engineers-in-how-to-build-an-american-company-that-makes-physical-products-but-operates-like-a-startup">Other changes in the world have set the stage for a resurgence of US manufacturing. &nbsp;New ML-based robotics systems will make it possible to automate far more, which will reduce the cost-of-labor arbitrage that pushed manufacturing to other countries in the first place. &nbsp;Companies like SpaceX and Tesla have trained an entire generation of engineers in how to build an American company that makes physical products but operates like a startup.</p>
<p id="we-know-this-works-because-weve-had-experience-working-with-some-of-the-leading-companies-in-this-space-astranis-w16-is-building-telecommunications-satellites-in-the-heart-of-san-francisco-in-a-building-that-used-to-build-warships-for-the-us-navy-during-wwii-gecko-robotics-w16-based-in-americas-old-industrial-heartland-of-pittsburgh-builds-robots-that-do-industrial-inspections-solugen-w17-makes-industrial-chemicals-from-a-largescale-plant-in-houston">We know this works because we've had experience working with some of the leading companies in this space. <a href="https://www.ycombinator.com/companies/astranis" id="astranis">Astranis</a> (W16) is building telecommunications satellites in the heart of San Francisco, in a building that used to build warships for the US Navy during WWII. <a href="https://www.ycombinator.com/companies/gecko-robotics" id="gecko-robotics">Gecko Robotics</a> (W16), based in America's old industrial heartland of Pittsburgh, builds robots that do industrial inspections. <a href="https://www.ycombinator.com/companies/solugen" id="solugen">Solugen</a> (W17) makes industrial chemicals from a large-scale plant in Houston.</p>
<h3 id="new-space-companies"><strong id="new-space-companies">New space companies</strong></h3>
<p id="-jared-friedman-and-dalton-caldwell-"><em id="-jared-friedman-and-dalton-caldwell-">- <a href="https://www.ycombinator.com/people/jared-friedman" id="jared-friedman">Jared Friedman</a> and <a href="https://www.ycombinator.com/people/dalton-caldwell" id="dalton-caldwell">Dalton Caldwell</a> </em></p>
<p id="the-cost-to-reach-orbit-is-falling-fast-having-fallen-over-10x-since-spacexs-first-launch-in-2006-a-startup-can-now-build-and-launch-a-satellite-on-just-a-seed-round">The cost to reach orbit is falling<strong id="-fast"> fast</strong>, having fallen over 10x since SpaceX’s first launch in 2006. A startup can now build and launch a satellite on just a seed round.</p>
<p id="if-you-think-about-how-many-kilograms-of-payload-get-launched-into-space-today-imagine-how-many-will-be-sent-up-in-one-year-in-five-years-in-ten-years-and-so-on-">If you think about how many kilograms of payload get launched into space today, imagine how many will be sent up in one year, in five years, in ten years, and so on. </p>
<p id="if-we-are-entering-a-future-with-access-to-space-being-as-routine-and-inexpensive-as-commercial-air-travel-shipping-or-trucking-what-new-businesses-does-that-unlock">If we are entering a future with access to space being as routine and inexpensive as commercial air travel, shipping or trucking… what new businesses does that unlock?</p>
<p id="building-a-space-company-might-scare-founders-by-seeming-too-ambitious-but-surprisingly-it-is-not-necessarily-harder-than-building-a-software-company-yc-has-funded-many-space-companies--astranis-relativity-space-stoke-and-many-others--and-their-success-rate-has-been-no-lower-and-maybe-higher-than-our-other-companies">Building a space company might scare founders by seeming too ambitious, but surprisingly, <a href="https://blog.samaltman.com/hard-startups" id="it-is-not-necessarily-harder">it is not necessarily harder</a> than building a software company. YC has funded many space companies — Astranis, Relativity Space, Stoke, and <a href="https://www.ycombinator.com/companies?industry=Aviation%20and%20Space" id="many-others">many others</a> &nbsp;— and their success rate has been no lower, and maybe higher, than our other companies.</p>
<h3 id="climate-tech"><strong id="climate-tech">Climate Tech</strong></h3>
<p id="-gustaf-alstrmer"><em id="-">- </em><a href="https://www.ycombinator.com/people/gustaf-alstromer" id="gustaf-alstrmer"><em id="gustaf-alstr">Gustaf Alstr</em>ö<em id="mer">mer</em></a></p>
<p id="we-have-a-fair-chance-of-avoiding-catastrophic-climate-change-if-startups-offer-commercial-solutions-to-decarbonize-society-or-remove-carbon-from-the-atmosphere">We have a fair chance of avoiding catastrophic climate change if startups offer commercial solutions to decarbonize society or remove carbon from the atmosphere.</p>
<p id="were-interested-in-funding-people-building-in-these-five-toplevel-buckets-energy-related-science-required-climate-adaptation-green-fintech-and-carbon-accounting--offsets-">We're interested in funding people building in these five top-level buckets: <a href="https://www.ycombinator.com/blog/rfs-climatetech/#energy-related" id="energy-related">Energy Related</a>, <a href="https://www.ycombinator.com/blog/rfs-climatetech/#science-required" id="science-required">Science Required</a>, <a href="https://www.ycombinator.com/blog/rfs-climatetech/#climate-adaptation" id="climate-adaptation">Climate Adaptation</a>, <a href="https://www.ycombinator.com/blog/rfs-climatetech/#green-fintech" id="green-fintech">Green Fintech</a>, and <a href="https://www.ycombinator.com/blog/rfs-climatetech/#carbon-accounting-offsets" id="carbon-accounting--offsets">Carbon Accounting &amp; Offsets</a>. </p>
<p id="the-financial-opportunity-of-building-in-this-space-is-massive-an-estimated-310-trillion-in-ebitda-will-be-up-for-grabs-recent-legislation-will-also-significantly-accelerate-the-existing-market-trends-the-inflation-reduction-act-will-spend-an-estimated-800b-in-the-us-alone-over-10-years-to-put-that-into-perspective-it-is-almost-10x-the-90b-2008-bill-that-catalyzed-the-us-solar-battery-and-ev-industries-into-existence">The financial opportunity of building in this space is massive: an estimated <a href="https://www.morganstanley.com/ideas/investing-in-decarbonization" id="310-trillion-in-ebitda">$3-10 trillion in EBITDA</a> will be up for grabs. Recent legislation will also significantly accelerate the existing market trends. The Inflation Reduction Act will spend an estimated <a href="https://www.theatlantic.com/science/archive/2022/10/inflation-reduction-act-climate-economy/671659/" id="800b">$800B</a> in the US alone over 10 years. To put that into perspective, it is almost 10x the <a href="https://obamawhitehouse.archives.gov/the-press-office/2016/02/25/fact-sheet-recovery-act-made-largest-single-investment-clean-energy" id="90b-2008-bill">$90B 2008 bill</a> that catalyzed the US solar, battery, and EV industries into existence.</p>
<p id="y-combinator-has-funded-well-over-100-climate-tech-startups-and-together-they-are-worth-over-10b-building-in-climate-tech-is-a-onceinageneration-opportunity">Y Combinator has funded well over 100 <a href="https://www.ycombinator.com/companies/?query=Climate%20" id="climate-tech-startups">climate tech startups</a>, and together they are worth over $10B. Building in climate tech is a once-in-a-generation opportunity.</p>
<h3 id="commercial-open-source-companies"><strong id="commercial-open-source-companies">Commercial Open Source companies</strong></h3>
<p id="-nicolas-dessaigne-and-diana-hu"><em id="-">- </em><a href="https://www.ycombinator.com/people/nicolas-dessaigne" id="nicolas-dessaigne"><em id="nicolas-dessaigne">Nicolas Dessaigne</em></a><em id="-and-diana-hu"> and <a href="https://www.ycombinator.com/people/diana-hu" id="diana-hu">Diana Hu</a></em></p>
<p id="open-source-companies-move-more-quickly-than-closed-source-companies-for-developer-tools-being-open-source-is-a-powerful-way-to-gain-developer-adoption-but-its-also-a-great-way-for-startups-to-become-mature-and-sell-to-enterprises-a-lot-sooner-ultimately-open-source-companies-succeed-when-they-become-the-standard-choice-for-software-engineers-">Open source companies move more quickly than closed source companies. For developer tools, being open source is a powerful way to gain developer adoption. But it’s also a great way for startups to become mature and sell to enterprises a lot sooner. Ultimately, open source companies succeed when they become the standard choice for software engineers. </p>
<p id="very-technical-founders-are-at-a-strong-advantage-here-as-the-sales-motion-relies-more-on-the-technical-merits-of-the-project-rather-than-strong-sales-tactics-its-more-natural-for-technical-founders-to-talk-to-users-who-are-engineers-just-like-them-and-they-can-iterate-faster-since-theyll-get-feedback-from-the-open-source-community">Very technical founders are at a strong advantage here, as the sales motion relies more on the technical merits of the project rather than strong sales tactics. It’s more natural for technical founders to talk to users who are engineers just like them, and they can iterate faster since they’ll get feedback from the open source community.</p>
<p id="yc-has-funded-over-150-open-source-companies-including-gitlab-w15-docker-s10-apollo-s11-supabase-s20-to-name-a-few-and-we-want-to-fund-more">YC has funded over 150 open source companies including <a href="https://www.ycombinator.com/companies/gitlab" id="gitlab-w15">Gitlab (W15)</a>, <a href="https://www.ycombinator.com/companies/docker" id="docker-s10">Docker (S10)</a>, <a href="https://www.ycombinator.com/companies/apollo" id="apollo-s11">Apollo (S11)</a>, <a href="https://www.ycombinator.com/companies/supabase" id="supabase-s20">Supabase (S20)</a> to name a few, and we want to fund more.</p>
<h3 id="spatial-computing"><strong id="spatial-computing">Spatial Computing</strong></h3>
<p id="-diana-hu"><em id="-diana-hu">- <a href="https://www.ycombinator.com/people/diana-hu" id="diana-hu">Diana Hu</a></em></p>
<p id="arvr-as-the-new-personal-computing-platform-has-been-in-the-works-for-over-a-decade-but-its-only-recently-with-the-launches-of-the-apple-vision-pro-and-the-meta-quest-3-that-we-are-getting-close-the-user-experience-is-getting-better-rendering-power-is-increasing-and-handeye-tracking-has-improved-dramatically--but-theres-still-work-to-be-done">AR/VR as the new personal computing platform has been in the works for over a decade. But it’s only recently, with the launches of the Apple Vision Pro and the Meta Quest 3, that we are getting close. The user experience is getting better, rendering power is increasing, and hand/eye tracking has improved dramatically — but there’s still work to be done.</p>
<p id="we-would-like-to-see-a-new-set-of-startups-building-software-on-these-devices-solving-practical-use-cases-that-go-beyond-gaming-there-are-so-many-challenges-still-to-solve-with-discovering-best-use-cases-best-uxui-practices-and-more--we-are-excited-to-work-with-founders-that-are-at-the-frontier-of-this-tech">We would like to see a new set of startups building software on these devices, solving practical use cases that go beyond gaming. There are so many challenges still to solve with discovering best use cases, best UX/UI practices, and more — we are excited to work with founders that are at the frontier of this tech.</p>
<h3 id="new-enterprise-resource-planning-software">New <strong id="enterprise-resource-planning-software">Enterprise Resource Planning Software</strong>
</h3>
<p id="-dalton-caldwell"><em id="-dalton-caldwell">- <a href="https://www.ycombinator.com/people/dalton-caldwell" id="dalton-caldwell">Dalton Caldwell</a></em></p>
<p id="as-companies-get-larger-they-end-up-adopting-some-software-suite-to-help-run-their-business-this-piece-of-software-is-widely-known-as-an-erp-or-enterprise-resource-planning-software-you-can-think-of-this-software-as-the-operating-system-that-a-business-runs-on-">As companies get larger they end up adopting some software suite to help run their business. This piece of software is widely known as an “ERP”, or Enterprise Resource Planning software. You can think of this software as the operating system that a business runs on. </p>
<p id="erps-are-usually-known-to-be-expensive-painful-to-implement-and-disliked-by-users-yet-are-absolutely-necessary-and-the-very-definition-of-business-critical-to-its-customers">ERPs are usually known to be expensive, painful to implement, and disliked by users, yet are absolutely necessary and the very definition of business critical to its customers.</p>
<p id="we-would-like-to-see-new-startups-that-build-software-that-helps-businesses-run-ideally-that-software-would-be-loved-by-its-customers-for-its-flexibility-and-ease-of-use-this-type-of-software-is-so-valuable-and-important-that-we-can-imagine-that-there-is-the-opportunity-for-dozens-of-new-massively-successful-vendors">We would like to see new startups that build software that helps businesses run. Ideally that software would be loved by its customers for its flexibility and ease of use. This type of software is so valuable and important that we can imagine that there is the opportunity for dozens of new massively successful vendors.</p>
<h3 id="developer-tools-inspired-by-existing-internal-tools">
<strong id="developer">Developer</strong> tools inspired by existing internal tools</h3>
<p id="-dalton-caldwell"><em id="-dalton-caldwell">- <a href="https://www.ycombinator.com/people/dalton-caldwell" id="dalton-caldwell">Dalton Caldwell</a></em></p>
<p id="if-a-developer-has-worked-at-a-company-with-some-amount-of-success-they-have-likely-encountered-tools-or-frameworks-that-were-built-by-programmers-at-the-company-to-help-solve-their-own-particularly-painful-or-repetitive-problems-these-tools-tend-to-have-funny-internal-nicknames-and-for-the-most-part-never-see-the-light-of-day-">If a developer has worked at a company with some amount of success, they have likely encountered tools or frameworks that were built by programmers at the company to help solve their own particularly painful or repetitive problems. These tools tend to have funny internal nicknames and for the most part never see the light of day. </p>
<p id="when-aspiring-founders-try-to-come-up-with-new-startup-ideas-they-often-dont-realize-that-the-internal-tools-they-had-at-prior-jobs-are-a-great-place-to-get-inspiration-from">When aspiring founders try to come up with new startup ideas they often don’t realize that the internal tools they had at prior jobs are a <strong id="great-">great </strong>place to get inspiration from.</p>
<p id="we-would-like-to-see-more-startups-created-that-are-inspired-by-these-types-of-homegrown-tools-because-its-likely-that-if-its-very-useful-at-one-company-its-very-useful-at-others-the-lineage-of-all-software-tools-can-often-be-traced-back-to-something-a-programmer-built-to-get-their-job-done-and-there-is-no-reason-to-doubt-this-wont-continue-to-be-true">We would like to see more startups created that are inspired by these types of homegrown tools, because it’s likely that if it's very useful at one company, it's very useful at others. The lineage of all software tools can often be traced back to something a programmer built to get their job done, and there is no reason to doubt this won't continue to be true.</p>
<h3 id="explainable-ai">Explainable A.I.</h3>
<p id="-diana-hu-and-nicolas-dessaigne"><em id="-diana-hu-and-">- <a href="https://www.ycombinator.com/people/diana-hu" id="diana-hu">Diana Hu</a> and </em><a href="https://www.ycombinator.com/people/nicolas-dessaigne" id="nicolas-dessaigne"><em id="nicolas-dessaigne">Nicolas Dessaigne</em></a></p>
<p id="would-you-trust-an-ai-to-diagnose-you-would-you-swear-that-a-model-is-unbiased-or-more-simply-how-can-we-be-sure-that-a-model-doesnt-hallucinate-an-answer">Would you trust an AI to diagnose you? Would you swear that a model is unbiased? Or more simply, how can we be sure that a model doesn’t hallucinate an answer?</p>
<p id="understanding-model-behavior-is-very-challenging-but-we-believe-that-in-contexts-where-trust-is-paramount-it-is-essential-for-an-ai-model-to-be-interpretable-its-responses-need-to-be-explainable">Understanding model behavior is very challenging, but we believe that in contexts where trust is paramount it is essential for an AI model to be interpretable. Its responses need to be explainable.</p>
<p id="for-society-to-reap-the-full-benefits-of-ai-more-work-needs-to-be-done-on-explainable-ai-we-are-interested-in-funding-people-building-new-interpretable-models-or-tools-to-explain-the-output-of-existing-models">For society to reap the full benefits of AI, more work needs to be done on explainable AI. We are interested in funding people building new interpretable models or tools to explain the output of existing models.</p>
<h3 id="llms-for-manual-back-office-processes-in-legacy-enterprises">L.L.Ms for manual back office processes in legacy enterprises</h3>
<p id="-tom-blomfield"><em id="-tom-blomfield">- <a href="https://www.ycombinator.com/people/tom-blomfield" id="tom-blomfield">Tom Blomfield</a></em></p>
<p id="in-pretty-much-every-old-large-company-there-are-huge-teams-of-people-running-manual-processes-theyre-hidden-away-from-the-end-customer-hence-back-office-rather-than-front-office-so-we-dont-tend-to-encounter-them-very-often-in-our-daytoday-lives-">In pretty much every old, large company, there are huge teams of people running manual processes. They’re hidden away from the end customer (hence “back office” rather than “front office”), so we don’t tend to encounter them very often in our day-to-day lives. </p>
<p id="often-there-was-just-enough-ambiguity-in-these-tasks-that-they-were-very-difficult-to-automate-before-the-existence-of-llms-in-other-cases-software-engineers-had-simply-never-even-come-into-contact-with-these-processes-so-automation-had-never-seriously-been-considered-people-continue-to-do-this-repetitive-work-in-the-same-way-they-have-for-decades">Often there was just enough ambiguity in these tasks that they were very difficult to automate before the existence of LLMs. In other cases, software engineers had simply never even come into contact with these processes, so automation had never seriously been considered. People continue to do this repetitive work in the same way they have for decades.</p>
<p id="llms-allow-whole-categories-of-manual-processes-to-be-automated-in-ways-that-werent-possible-until-recently-where-theres-linguistic-ambiguity-or-some-amount-of-subjective-evaluation-needed-llms-come-into-their-own-">LLMs allow whole categories of manual processes to be automated in ways that weren’t possible until recently. Where there’s linguistic ambiguity or some amount of subjective evaluation needed, LLMs come into their own. </p>
<p id="examples-might-be">Examples might be:</p>
<ul id="qa-and-compliance-reviews-of-customers-service-chatsfiguring-out-medical-billing-codes-and-insurance-reimbursement-at-a-hospitalassessing-applications-for-a-mortgage-or-a-business-loantransaction-monitoring-sanctions-screening-and-anti-moneylaundering-investigationsfiling-paperwork-with-the-state-authorities-after-a-dealership-sells-a-car">
<li id="qa-and-compliance-reviews-of-customers-service-chats">QA and compliance reviews of customers service chats</li>
<li id="figuring-out-medical-billing-codes-and-insurance-reimbursement-at-a-hospital">Figuring out medical billing codes and insurance reimbursement at a hospital</li>
<li id="assessing-applications-for-a-mortgage-or-a-business-loan">Assessing applications for a mortgage or a business loan</li>
<li id="transaction-monitoring-sanctions-screening-and-anti-moneylaundering-investigations">Transaction monitoring, sanctions screening and anti money-laundering investigations</li>

</ul>
<p id="the-problem-for-most-software-engineers-is-that-theyve-never-encountered-these-kinds-of-back-office-processes-before-the-biggest-hurdle-is-often-uncovering-one-of-these-processes-to-tackle">The problem for most software engineers is that they’ve never encountered these kinds of back office processes before. The biggest hurdle is often uncovering one of these processes to tackle.</p>
<h3 id="ai-to-build-enterprise-software">A.I. to build Enterprise Software</h3>
<p id="-harj-taggar"><em id="-harj-taggar">- <a href="https://www.ycombinator.com/people/harj-taggar" id="harj-taggar">Harj Taggar</a></em></p>
<p id="enterprise-software-has-a-reputation-among-smart-programmers-as-being-boring-to-work-on-you-have-to-do-sales-and-because-each-potential-customer-wants-something-slightly-different-you-end-up-writing-bloated-software-to-try-and-please-them-all">Enterprise software has a reputation among smart programmers as being boring to work on. You have to do sales and because each potential customer wants something slightly different, you end up writing bloated software to try and please them all.</p>
<p id="but-what-if-ai-could-change-how-enterprise-software-gets-built-and-sold-the-core-of-what-every-customer-wants-is-the-same--they-just-want-it-customized-around-the-edges-">But what if AI could change how enterprise software gets built and sold? The core of what every customer wants is the same — they just want it customized around the edges. </p>
<p id="ai-is-good-at-writing-code--especially-when-you-give-it-an-existing-codebase-to-learn-from-so-what-if-instead-of-long-enterprise-sales-cycles-you-just-give-customers-a-simple-starter-product-and-have-them-tell-your-ai-how-they-want-it-customized-in-the-future-every-enterprise-could-have-their-own-custom-erp-crm-or-hris-that-is-continually-updating-itself-as-the-company-itself-is-changing-">AI is good at writing code — especially when you give it an existing codebase to learn from. So what if instead of long enterprise sales cycles you just give customers a simple starter product and have them tell your AI how they want it customized? In the future, every enterprise could have their own custom ERP, CRM or HRIS that is continually updating itself as the company itself is changing. &nbsp;</p>
<p id="a-product-based-on-this-premise-would-be-highly-disruptive-to-large-incumbents-because-now-they-cant-win-by-just-copying-you-and-adding-another-feature-to-their-bloated-software-now-they-would-have-to-completely-change-their-whole-conceptual-approach-to-building-software">A product based on this premise would be highly disruptive to large incumbents, because now they can’t win by just copying you and adding another feature to their bloated software. Now they would have to completely change their whole conceptual approach to building software.</p>
<p id="maybe-the-ai-will-get-so-good-at-this-that-it-can-think-up-new-types-of-enterprise-software-that-dont-even-exist-yet-building-this-ai-would-be-an-interesting-technical-challenge-and-if-youre-excited-about-building-ai-that-can-code-enterprise-software-is-the-most-profitable-software-to-build">Maybe the AI will get so good at this that it can think up new types of enterprise software that don’t even exist yet. Building this AI would be an interesting technical challenge and if you’re excited about building AI that can code, enterprise software is the most profitable software to build.</p>
<h3 id="stablecoin-finance"><strong id="stablecoin-finance">Stablecoin finance</strong></h3>
<p id="-brad-flora"><em id="-brad-flora">- <a href="https://www.ycombinator.com/people/brad-flora" id="brad-flora">Brad Flora</a></em></p>
<p id="stablecoins-are-digital-currencies-that-peg-their-value-to-some-external-reference-this-is-typically-the-us-dollar-but-it-can-be-other-fiat-currencies-assets-or-even-other-digital-currencies-their-transactions-are-recorded-on-a-digital-ledger-usually-a-blockchain-this-means-they-can-be-traded-at-any-time-of-day-between-any-two-wallets-on-the-same-network-transactions-settle-in-seconds-and-fees-are-a-fraction-of-what-you-see-in-traditional-finance">Stablecoins are digital currencies that peg their value to some external reference. This is typically the U.S. dollar, but it can be other fiat currencies, assets, or even other digital currencies. Their transactions are recorded on a digital ledger, usually a blockchain. This means they can be traded at any time of day between any two wallets on the same network, transactions settle in seconds, and fees are a fraction of what you see in traditional finance.</p>
<p id="theres-been-much-debate-about-the-utility-of-blockchain-technology-but-it-seems-clear-that-stablecoins-will-be-a-big-part-of-the-future-of-money-we-know-this-because-yc-companies-have-been-effectively-incorporating-stablecoins-into-their-operations-for-years-now--for-crossborder-payments-to-reduce-transaction-fees-and-fraud-to-help-users-protect-savings-from-hyperinflation-this-utility-is-so-straightforward-it-seems-inevitable-traditional-finance-will-follow-suit-">There’s been much debate about the utility of blockchain technology, but it seems clear that stablecoins will be a big part of the future of money. We know this because YC companies have been effectively incorporating stablecoins into their operations for years now – for cross-border payments, to reduce transaction fees and fraud, to help users protect savings from hyperinflation. This utility is so straightforward it seems inevitable traditional finance will follow suit. &nbsp;</p>
<p id="in-fact-were-seeing-signs-of-this-paypal-recently-issued-its-own-stablecoin-major-banks-have-started-offering-custody-services-and-making-noise-about-issuing-their-own-">In fact we’re seeing signs of this. PayPal recently issued its own stablecoin. Major banks have started offering custody services and making noise about issuing their own. </p>
<p id="it-all-looks-a-bit-like-digital-musics-transition-from-the-realm-of-outlaw-file-sharing-in-the-early-2000s-to-becoming-the-norm-as-players-like-apple-entered-the-market-importantly-those-major-players-were-all-outmatched-in-the-end-by-spotify-a-startup-founded-during-that-same-transition-moment">It all looks a bit like digital music’s transition from the realm of outlaw file sharing in the early 2000s to becoming the norm as players like Apple entered the market. Importantly, those major players were all outmatched in the end by Spotify, a startup founded during that same transition moment.</p>
<p id="136b-worth-of-stablecoins-have-been-issued-to-date-but-the-opportunity-seems-much-more-immense-still-only-about-seven-million-people-have-transacted-with-stablecoins-to-date-while-more-than-half-a-billion-live-in-countries-with-30-inflation-us-banks-hold-17b-in-customer-deposits-which-are-all-up-for-grabs-as-well-and-yet-the-major-stablecoin-issuers-can-be-counted-on-one-hand-and-the-major-liquidity-providers-with-just-a-few-fingers">$136b worth of stablecoins have been issued to date but the opportunity seems much more immense still. Only about seven million people have transacted with stablecoins to date, while more than half a billion live in countries with 30%+ inflation. U.S. banks hold $17b in customer deposits which are all up for grabs as well. &nbsp;And yet the major stablecoin issuers can be counted on one hand and the major liquidity providers with just a few fingers.</p>
<p id="we-would-like-to-fund-great-teams-building-b2b-and-consumer-products-on-top-of-stablecoins-tools-and-platforms-that-enable-stablecoin-finance-and-more-stablecoin-protocols-themselves">We would like to fund great teams building B2B and consumer products on top of stablecoins, tools and platforms that enable stablecoin finance and more stablecoin protocols themselves.</p>
<h3 id="a-way-to-end-cancer"><strong id="a-way-to-end-cancer">A way to end cancer</strong></h3>
<p id="-surbhi-sarna"><em id="-surbhi-sarna">- <a href="https://www.ycombinator.com/people/surbhi-sarna" id="surbhi-sarna">Surbhi Sarna</a></em></p>
<p id="the-technology-to-diagnose-cancer-at-an-early-stage-already-exists-since-most-cancers-are-now-treatable-if-caught-early-enough-this-technology-would-dramatically-reduce-cancer-deaths-if-rolled-out-widely-and-affordably-">The technology to diagnose cancer at an early stage already exists. Since most cancers are now treatable if caught early enough, this technology would dramatically reduce cancer deaths if rolled out widely and affordably. </p>
<p id="the-technology-were-talking-about-is-an-mri-modern-mris-are-sensitive-enough-to-detect-cancer-masses-as-small-as-a-millimeter">The technology we’re talking about is an MRI. Modern MRIs are sensitive enough to detect cancer masses as small as a millimeter.</p>
<p id="some-companies-are-already-having-success-on-a-small-scale-offering-mris-to-patients-for-a-high-cash-price-however-there-is-backlash-from-the-medical-community-as-mris-also-create-incidental-findings-or-false-positives-that-cost-our-healthcare-system-valuable-time-and-money-to-investigate-">Some companies are already having success on a small scale offering MRIs to patients for a high cash price. However, there is backlash from the medical community as MRIs also create incidental findings (or false positives), that cost our healthcare system valuable time and money to investigate. </p>
<p id="for-this-to-work-the-world-would-need-to-scale-up-the-number-of-mri-scans-it-does-by-at-least-100x-doing-that-will-require-innovations-in-the-mri-hardware-the-ai-algorithms-to-interpret-scans-and-reduce-false-positives-and-the-business-models-and-consumer-marketing-to-make-it-a-viable-business-were-interested-in-funding-companies-looking-to-tackle-this-multifaceted-problem">For this to work, the world would need to scale up the number of MRI scans it does by at least 100x. Doing that will require innovations in the MRI hardware, the AI algorithms to interpret scans and reduce false positives, and the business models and consumer marketing to make it a viable business. &nbsp;We’re interested in funding companies looking to tackle this multifaceted problem.</p>
<p id="while-much-exciting-progress-is-being-made-on-cancer-therapeutics-finding-cancer-early-enough-for-our-existing-therapeutics-to-be-curative-might-be-the-opportunity-with-the-greatest-potential-impact">While much exciting progress is being made on cancer therapeutics, finding cancer early enough for our existing therapeutics to be curative might be the opportunity with the greatest potential impact.</p>
<h3 id="foundation-models-for-biological-systems"><strong id="foundation-models-for-biological-systems">Foundation Models for biological systems</strong></h3>
<p id="-surbhi-sarna"><em id="-surbhi-sarna">- <a href="https://www.ycombinator.com/people/surbhi-sarna" id="surbhi-sarna">Surbhi Sarna</a></em></p>
<p id="the-vast-majority-of-scientific-innovation-fails--either-on-the-bench-during-early-experimentation-or-while-in-clinical-trials-">The vast majority of scientific innovation fails – either on the bench during early experimentation or while in clinical trials. </p>
<p id="foundation-models-built-around-the-vast-amount-of-data-we-now-have-will-not-only-enable-scientists-to-know-what-path-to-pursue-much-quicker-than-before-but-have-the-potential-to-unlock-new-scientific-approaches-to-disease-foundation-models-built-around-text-and-images-are-enabling-the-nextgeneration-of-consumer-products-we-believe-foundation-models-built-around-biological-systems-will-do-the-same-for-healthcare">Foundation models built around the vast amount of data we now have will not only enable scientists to know what path to pursue much quicker than before, but have the potential to unlock new scientific approaches to disease. Foundation models built around text and images are enabling the next-generation of consumer products; we believe foundation models built around biological systems will do the same for healthcare.</p>
<p id="we-are-interested-in-funding-highly-technical-founders-building-foundational-models-from-scratch-in-any-part-of-biology-or-medicine">We are interested in funding highly technical founders building foundational models from scratch in any part of biology or medicine.</p>
<h3 id="the-managed-service-organization-model-for-healthcare"><strong id="the-managed-service-organization-model-for-healthcare">The Managed Service Organization model for healthcare</strong></h3>
<p id="-surbhi-sarna"><em id="-surbhi-sarna">- <a href="https://www.ycombinator.com/people/surbhi-sarna" id="surbhi-sarna">Surbhi Sarna</a></em></p>
<p id="private-equity-is-consuming-small-and-large-private-clinics-all-over-the-country-by-the-time-more-junior-healthcare-workers-are-paid-they-only-make-a-fraction-of-what-they-are-billing-this-causes-them-to-be-overworked-but-underpaid-as-much-of-the-revenue-goes-to-overhead-and-the-private-equity-owner-of-the-clinic-">Private equity is consuming small and large private clinics all over the country. By the time more junior healthcare workers are paid, they only make a fraction of what they are billing. This causes them to be overworked but underpaid, as much of the revenue goes to overhead and the private equity owner of the clinic. </p>
<p id="a-new-startup-model-has-emerged-as-an-alternative-to-pe-ownership-the-mso-managed-service-organizations-model-">A new startup model has emerged as an alternative to PE ownership: the MSO (Managed Service Organizations) model. &nbsp;</p>
<p id="the-mso-model-enables-doctors-to-run-their-own-clinics-by-1-providing-them-software-that-can-handle-back-office-tasks-such-as-billing-and-scheduling-and-2-channeling-patients-to-them--">The MSO model enables doctors to run their own clinics by (1) providing them software that can handle back office tasks such as billing and scheduling and (2) channeling patients to them. &nbsp; </p>
<p id="these-functions-are-largely-what-pe-ownership-provides-doctors-who-are-part-of-an-mso-model-can-continue-to-run-small-physicianowned-practices-while-competing-successfully-with-large-peowned-conglomerates">These functions are largely what PE ownership provides. Doctors who are part of an MSO model can continue to run small, physician-owned practices while competing successfully with large, PE-owned conglomerates.</p>
<p id="yc-has-funded-several-companies-doing-this-in-different-verticals-nourish-nutritionists-lunajoy-mental-health-for-women-finni-health-autism-care-for-children-and-others-">YC has funded several companies doing this in different verticals: <a href="https://www.ycombinator.com/companies/nourish" id="nourish">Nourish</a> (nutritionists), <a href="https://www.ycombinator.com/companies/lunajoy" id="lunajoy">LunaJoy</a> (mental health for women), <a href="https://www.ycombinator.com/companies/finni-health" id="finni-health">Finni Health</a> (autism care for children), and others. </p>
<p id="we-are-interested-in-investing-in-this-mso-managed-service-organizations-model-across-every-vertical-in-healthcare">We are interested in investing in this MSO (Managed Service Organizations) model across every vertical in healthcare.</p>
<h3 id="eliminating-middlemen-in-healthcare">Eliminating middlemen in healthcare</h3>
<p id="-surbhi-sarna"><em id="-surbhi-sarna">- <a href="https://www.ycombinator.com/people/surbhi-sarna" id="surbhi-sarna">Surbhi Sarna</a></em></p>
<p id="the-us-spends-more-money-per-person-on-healthcare-than-any-other-developed-nation-yet-our-patient-outcomes-are-no-better-much-of-our-spend-goes-to-paying-middlemen--which-in-our-view-includes-everyone-not-directly-providing-care-to-patients">The US spends more money per person on healthcare than any other developed nation, yet our patient outcomes are no better. &nbsp;Much of our spend goes to paying middlemen — which in our view includes everyone not directly providing care to patients.</p>
<p id="a-recent-report-on-medicare-spending-on-drugs-found-that-70-of-spend-went-to-middlemen-primarily-pbms-wholesalers-and-pharmacies-and-only-30-to-the-pharmaceutical-companies-who-make-the-drugs-similar-dynamics-exist-in-every-other-vertical--hospital-care-medical-equipment-insurance-etc">A recent report on medicare spending on drugs found that 70% of spend went to middlemen (primarily PBMs, wholesalers, and pharmacies) and only 30% to the pharmaceutical companies who make the drugs. &nbsp;Similar dynamics exist in every other vertical — hospital care, medical equipment, insurance, etc.</p>
<p id="there-are-many-ways-startups-could-attack-these-inefficiencies-from-using-ai-to-automate-repetitive-human-jobs-to-exploring-new-and-better-business-models-for-providing-care-in-the-spirit-of-jeff-bezos-your-margin-is-my-opportunity-we-believe-its-possible-to-build-a-highly-profitable-business-and-make-the-system-more-efficient-at-the-same-time">There are many ways startups could attack these inefficiencies, from using AI to automate repetitive human jobs to exploring new and better business models for providing care. &nbsp;In the spirit of Jeff Bezos’ “your margin is my opportunity”, we believe it’s possible to build a highly profitable business <em id="and">and</em> make the system more efficient at the same time.</p>
<h3 id="better-enterprise-glue"><strong id="better-enterprise-glue">Better enterprise glue</strong></h3>
<p id="-pete-koomen"><em id="-pete-koomen">- <a href="https://www.ycombinator.com/people/pete-koomen" id="pete-koomen">Pete Koomen</a></em></p>
<p id="most-enterprise-software-requires-customers-to-write-a-lot-of-custom-code-large-vendors-like-oracle-salesforce-and-netsuite-each-support-multibillion-dollar-ecosystems-of-consultants-and-independent-software-vendors-isvs-who-help-customize-these-products-and-connect-them-to-other-software-on-behalf-of-their-clients">Most enterprise software requires customers to write a lot of custom code. Large vendors like Oracle, Salesforce, and Netsuite each support multibillion dollar ecosystems of consultants and independent software vendors ("ISVs") who help customize these products and connect them to other software on behalf of their clients.</p>
<p id="this-glue-code--etl-pipelines-integrations-and-custom-workflows--is-the-dark-matter-of-the-enterprise-software-universe">This "glue code" — ETL pipelines, integrations, and custom workflows — is the dark matter of the enterprise software universe.</p>
<p id="yc-has-funded-successful-companies-in-this-space-including-zapier-s12-fivetran-w13-and-airbyte-w20-these-products-help-companies-build-glue-code-for-common-use-cases">YC has funded successful companies in this space, including <a href="https://www.ycombinator.com/companies/zapier" id="zapier">Zapier</a> (S12), <a href="https://www.ycombinator.com/companies/fivetran" id="fivetran">Fivetran</a> (W13) and <a href="https://www.ycombinator.com/companies/airbyte" id="airbyte">Airbyte</a> (W20). These products help companies build glue code for common use cases.</p>
<p id="by-generating-custom-code-for-uncommon-companyspecific-use-cases-large-language-models-have-the-potential-to-eliminate-the-need-for-glue-code-altogether-we-would-like-to-see-more-startups-working-on-solving-this-problem">By generating custom code for <em id="un">un</em>common, company-specific use cases, large language models have the potential to eliminate the need for glue code altogether. We would like to see more startups working on solving this problem.</p>
<h3 id="small-finetuned-models-as-an-alternative-to-giant-generic-ones"><strong id="small-finetuned-models-as-an-alternative-to-giant-generic-ones">Small fine-tuned models as an alternative to giant generic ones</strong></h3>
<p id="-nicolas-dessaigne"><em id="-">- </em><a href="https://www.ycombinator.com/people/nicolas-dessaigne" id="nicolas-dessaigne"><em id="nicolas-dessaigne">Nicolas Dessaigne</em></a></p>
<p id="giant-generic-models-with-a-lot-of-parameters-are-very-impressive-but-they-are-also-very-costly-and-often-come-with-latency-and-privacy-challenges-fortunately-smaller-opensource-models-like-llama2-and-mistral-have-already-demonstrated-that-when-finely-tuned-with-appropriate-data-they-can-yield-comparable-results-at-a-fraction-of-the-cost">Giant generic models with a lot of parameters are very impressive. But they are also very costly and often come with latency and privacy challenges. Fortunately, smaller open-source models like Llama2 and Mistral have already demonstrated that, when finely tuned with appropriate data, they can yield comparable results at a fraction of the cost.</p>
<p id="moreover-as-new-hardware-continues-to-be-integrated-into-our-phones-and-laptops-the-prospect-of-running-these-models-at-the-edge-becomes-increasingly-feasible-unlocking-a-multitude-of-new-use-cases">Moreover, as new hardware continues to be integrated into our phones and laptops, the prospect of running these models at the edge becomes increasingly feasible, unlocking a multitude of new use cases.</p>
<p id="we-are-eager-to-support-companies-engaged-in-developing-or-finetuning-such-specialized-models-or-creating-tools-to-facilitate-their-construction">We are eager to support companies engaged in developing or fine-tuning such specialized models or creating tools to facilitate their construction.</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Conformant OpenGL 4.6 on the M1 (223 pts)]]></title>
            <link>https://rosenzweig.io/blog/conformant-gl46-on-the-m1.html</link>
            <guid>39371669</guid>
            <pubDate>Wed, 14 Feb 2024 16:18:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://rosenzweig.io/blog/conformant-gl46-on-the-m1.html">https://rosenzweig.io/blog/conformant-gl46-on-the-m1.html</a>, See on <a href="https://news.ycombinator.com/item?id=39371669">Hacker News</a></p>
<div id="readability-page-1" class="page"> <header><p>14 Feb 2024</p></header><p>For years, the M1 has only supported OpenGL 4.1. That changes today – with our release of full OpenGL® 4.6 and OpenGL® ES 3.2! <a href="https://fedora-asahi-remix.org/">Install Fedora</a> for the latest M1/M2-series drivers.</p> <p>Already installed? Just <code>dnf upgrade --refresh</code>.</p> <p>Unlike the vendor’s non-conformant 4.1 drivers, our <a href="https://gitlab.freedesktop.org/asahi/mesa">open source</a> Linux drivers are <strong>conformant</strong> to the latest OpenGL versions, finally promising broad compatibility with modern OpenGL workloads, like <a href="https://www.blender.org/">Blender</a>, <a href="https://ryujinx.org/">Ryujinx</a>, and <a href="https://citra-emu.org/">Citra</a>.</p> <p><a href="https://rosenzweig.io/Blender-Wanderer-high.avif"><img title="Screenshot of Blender running on Apple M1 on Fedora Linux 39. The scene is 'Wanderer', depicting a humanoid in a space suit on a rocky terrain, beside a rover with solar panels." src="https://rosenzweig.io/Blender-Wanderer.avif" width="1465" height="993"></a></p> <p>Conformant 4.6/3.2 drivers must pass over 100,000 tests to ensure correctness. The official list of conformant drivers now includes <a href="https://www.khronos.org/conformance/adopters/conformant-products/opengl#submission_347">our OpenGL 4.6</a> and <a href="https://www.khronos.org/conformance/adopters/conformant-products/opengles#submission_1045">ES 3.2</a>.</p> <p>While the vendor doesn’t yet support graphics standards like modern OpenGL, we do. For this Valentine’s Day, we want to profess our love for interoperable open standards. We want to free users and developers from lock-in, enabling applications to run anywhere the heart wants without special ports. For that, we need standards conformance. Six months ago, we became the <a href="https://rosenzweig.io/blog/first-conformant-m1-gpu-driver.html">first conformant driver for any standard graphics API for the M1</a> with the release of OpenGL ES 3.1 drivers. Today, we’ve finished OpenGL with the full 4.6… and we’re well on the road to Vulkan.</p> <hr> <p>Compared to 4.1, OpenGL 4.6 adds dozens of required features, including:</p> <ul> <li>Robustness</li> <li>SPIR-V</li> <li><a href="https://rosenzweig.io/blog/asahi-gpu-part-6.html">Clip control</a></li> <li>Cull distance</li> <li><a href="https://rosenzweig.io/blog/first-conformant-m1-gpu-driver.html">Compute shaders</a></li> <li>Upgraded transform feedback</li> </ul> <p>Regrettably, the M1 doesn’t map well to any graphics standard newer than OpenGL ES 3.1. While Vulkan makes some of these features optional, the missing features are required to layer DirectX and OpenGL on top. No existing solution on M1 gets past the OpenGL 4.1 feature set.</p> <p>How do we break the 4.1 barrier? Without hardware support, new features need new tricks. Geometry shaders, tessellation, and transform feedback become compute shaders. Cull distance becomes a transformed interpolated value. Clip control becomes a vertex shader epilogue. The list goes on.</p> <p>For a taste of the challenges we overcame, let’s look at <strong>robustness</strong>.</p> <p>Built for gaming, GPUs traditionally prioritize raw performance over safety. Invalid application code, like a shader that reads a buffer out-of-bounds, can trigger undefined behaviour. Drivers exploit that to maximize performance.</p> <p>For applications like web browsers, that trade-off is undesirable. Browsers handle untrusted shaders, which they must sanitize to ensure stability and security. Clicking a malicious link should not crash the browser. While some sanitization is necessary as graphics APIs are not security barriers, reducing undefined behaviour in the API can assist “defence in depth”.</p> <p>“Robustness” features can help. Without robustness, out-of-bounds buffer access in a shader can crash. With robustness, the application can opt for defined out-of-bounds behaviour, trading some performance for less attack surface.</p> <p>All modern cross-vendor APIs include robustness. Many games even (accidentally?) rely on robustness. Strangely, the vendor’s proprietary API omits buffer robustness. We must do better for conformance, correctness, and compatibility.</p> <p>Let’s first define the problem. Different APIs have different definitions of what an out-of-bounds load returns when robustness is enabled:</p> <ul> <li>Zero (Direct3D, Vulkan with <code>robustBufferAccess2</code>)</li> <li>Either zero or some data in the buffer (OpenGL, Vulkan with <code>robustBufferAccess</code>)</li> <li>Arbitrary values, but can’t crash (OpenGL ES)</li> </ul> <p>OpenGL uses the second definition: return zero or data from the buffer. One approach is to return the <em>last</em> element of the buffer for out-of-bounds access. Given the buffer size, we can calculate the last index. Now consider the <em>minimum</em> of the index being accessed and the last index. That equals the index being accessed if it is valid, and some other valid index otherwise. Loading the minimum index is safe and gives a spec-compliant result.</p> <p>As an example, a uniform buffer load without robustness might look like:</p> <div><pre><code><span><span>load</span>.i32 result, buffer, index</span></code></pre></div> <p>Robustness adds a single unsigned minimum (<code>umin</code>) instruction:</p> <div><pre><code><span><span>umin</span> idx, index, last</span>
<span><span>load</span>.i32 result, buffer, idx</span></code></pre></div> <p>Is the robust version slower? It can be. The difference should be small percentage-wise, as arithmetic is faster than memory. With thousands of threads running in parallel, the arithmetic cost may even be hidden by the load’s latency.</p> <p>There’s another trick that speeds up robust uniform buffers. Like other GPUs, the M1 supports “preambles”. The idea is simple: instead of calculating the same value in every thread, it’s faster to calculate once and reuse the result. The compiler identifies eligible calculations and moves them to a preamble executed before the main shader. These redundancies are common, so preambles provide a nice speed-up.</p> <p>We usually move uniform buffer loads to the preamble when every thread loads the same index. Since the size of a uniform buffer is fixed, extra robustness arithmetic is <em>also</em> moved to the preamble. The robustness is “free” for the main shader. For robust storage buffers, the clamping might move to the preamble even if the load or store cannot.</p> <p>Armed with robust uniform and storage buffers, let’s consider robust “vertex buffers”. In graphics APIs, the application can set vertex buffers with a base GPU address and a chosen layout of “attributes” within each buffer. Each attribute has an offset and a format, and the buffer has a “stride” indicating the number of bytes per vertex. The vertex shader can then read attributes, implicitly indexing by the vertex. To do so, the shader loads the address:</p> <p><img alt="Base plus stride times vertex plus offset" src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' style='width:31.875ex;height:2.5ex;vertical-align:-.75ex;margin:1px 0' viewBox='0 -778.581 13744.556 1057.161'%3E%3Cg stroke='%23000' stroke-width='0' transform='scale(1 -1)'%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23a'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23b' x='713'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23c' x='1218'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23d' x='1617'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23e' x='2288'/%3E%3Cg transform='translate(3293)'%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23f'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23g' x='561'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23h' x='955'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23i' x='1352'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23j' x='1635'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23d' x='2196'/%3E%3C/g%3E%3Cg transform='translate(6105)'%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23k'/%3E%3Cg transform='translate(394)'%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23l'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23d' x='755'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23h' x='1204'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23g' x='1601'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23d' x='1995'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23m' x='2444'/%3E%3C/g%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23n' x='3371'/%3E%3C/g%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23e' x='10092'/%3E%3Cg transform='translate(11097)'%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23o'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23p' x='783'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23p' x='1094'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23c' x='1405'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23d' x='1804'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23g' x='2253'/%3E%3C/g%3E%3C/g%3E%3Cdefs%3E%3Cpath id='k' stroke-width='10' d='M94 250q0 69 10 131t23 107 37 88 38 67 42 52 33 34 25 21h17q14 0 14-9 0-3-17-21t-41-53-49-86-42-138-17-193 17-192 41-139 49-86 42-53 17-21q0-9-15-9h-16l-28 24q-94 85-137 212T94 250Z'/%3E%3Cpath id='e' stroke-width='10' d='M56 237v13l14 20h299v150l1 150q10 13 19 13 13 0 20-15V270h298q15-8 15-20t-15-20H409V-68q-8-14-18-14h-4q-12 0-18 14v298H70q-14 7-14 20Z'/%3E%3Cpath id='n' stroke-width='10' d='m60 749 4 1h22l28-24q94-85 137-212t43-264q0-68-10-131T261 12t-37-88-38-67-41-51-32-33-23-19l-4-4H63q-3 0-5 3t-3 9q1 1 11 13Q221-64 221 250T66 725q-10 12-11 13 0 8 5 11Z'/%3E%3Cpath id='a' stroke-width='10' d='M131 622q-7 7-11 9t-16 3-43 3H28v46h318q77 0 113-5t72-27q43-24 68-61t25-78q0-51-41-93t-107-59l-10-3q73-9 129-55t56-115q0-68-51-120T469 3q-13-2-227-3H28v46h33q42 1 51 3t19 12v561Zm380-109q0 47-26 81t-69 42h-45q-20 0-38 1-67 0-82-1t-19-8q-3-4-3-129V374h83l84 1 10 2q4 1 11 3t25 13 32 24 25 39 12 57Zm26-325q0 51-28 94t-79 54l-101 1H229V116q0-59 5-64 6-5 100-5h49q42 0 60 6 43 14 68 51t26 84Z'/%3E%3Cpath id='b' stroke-width='10' d='M137 305h-22l-37 15-15 39q0 35 34 62t121 27q73 0 118-32t60-76q5-14 5-31t1-115v-70q0-48 5-66t21-18q15 0 20 16t5 53v36h40v-39q-1-40-3-47-9-30-35-47T400-6t-47 18-24 42v4l-2-3q-2-3-5-6t-8-9-12-11-15-12-18-11-22-8-26-6-31-3q-60 0-108 31t-48 87q0 21 7 40t27 41 48 37 78 28 110 15h14v22q0 34-6 50-22 71-97 71-18 0-34-1t-25-4-8-3q22-15 22-44 0-25-16-39Zm-11-199q0-31 24-55t59-25q38 0 67 23t39 60q2 7 3 66 0 58-1 58-8 0-21-1t-45-9-58-20-46-37-21-60Z'/%3E%3Cpath id='c' stroke-width='10' d='M295 316q0 40-27 69t-78 29q-36 0-62-13-30-19-30-52-1-5 0-13t16-24 43-25q18-5 44-9t44-9 32-13q17-8 33-20t32-41 17-62q0-62-38-102T198-10h-8q-52 0-96 36l-8-7-9-9Q71 4 65-1L54-11H42q-3 0-9 6v137q0 21 2 25t10 5h9q12 0 16-4t5-12 7-27 19-42q35-51 97-51 97 0 97 78 0 29-18 47-20 24-83 36t-83 23q-36 17-57 46t-21 62q0 39 17 66t43 40 50 18 44 5h11q40 0 70-15l15-8 9 7q10 9 22 17h12q3 0 9-6V310l-6-6h-28q-6 6-6 12Z'/%3E%3Cpath id='d' stroke-width='10' d='M28 218q0 55 20 100t50 73 65 42 66 15q53 0 91-18t58-50 28-64 9-71q0-7-7-14H126v-15q0-148 100-180 20-6 44-6 42 0 72 32 17 17 27 42l10 24q3 3 16 3h3q17 0 17-10 0-4-3-13-19-55-63-87t-99-32q-95 0-158 69T28 218Zm305 57q-11 128-95 136h-2q-8 0-16-1t-25-8-29-21-23-41-16-66v-7h206v8Z'/%3E%3Cpath id='l' stroke-width='10' d='m114 620-4 4-3 3-4 3q-4 3-5 2t-7 2-11 1-13 1-19 1H19v46h9q18-3 124-3 121 0 142 3h11v-46h-21q-61-3-61-17 0-2 90-248t91-246l86 232q85 230 85 239 0 19-21 29t-46 11h-5v46h9q15-3 115-3 91 0 97 3h6v-46h-7q-75 0-96-41 0-1-112-305T401-14q-5-8-19-8h-15q-14 0-19 8-2 2-117 317-117 314-117 317Z'/%3E%3Cpath id='h' stroke-width='10' d='M36 46h14q39 0 47 14v31q0 14 1 31t0 39 0 42v125l-1 23q-3 19-14 25t-45 9H20v23q0 23 2 23l10 1q10 1 28 2t36 2q16 1 35 2t29 3 11 1h3v-69q39 68 97 68h6q45 0 66-22t21-46q0-21-13-36t-38-15q-25 0-37 16t-13 34q0 9 2 16t5 12 3 5q-2 2-23-4-16-8-24-15-47-45-47-179V101q0-12 1-20t0-15v-5q1-2 3-4t5-3 5-3 7-2 7-1 9-1 9 0 10-1 10 0h31V0h-9q-18 3-127 3Q37 3 28 0h-8v46h16Z'/%3E%3Cpath id='g' stroke-width='10' d='M27 422q53 4 82 56t32 122v15h40V431h135v-46H181V241q1-125 1-141t7-32q14-39 49-39 44 0 54 71 1 8 1 46v35h40v-47q0-77-42-117-27-27-70-27-34 0-59 12t-38 31-19 35-7 32q-1 7-1 148v137H18v37h9Z'/%3E%3Cpath id='m' stroke-width='10' d='M201 0q-12 3-99 3-76 0-85-3h-6v46h14q23 1 42 6t29 9 25 17 18 18 21 26 20 28l46 60-58 78q-9 13-19 27t-16 21-11 15-9 12-6 7-7 6-6 3-6 2-8 2q-6 0-36 2H16v46h7q36-2 103-2 93 0 103 2h8v-46q-36-4-36-16 0-2 10-16t28-38 29-41l4-4 25 34q32 41 32 54 0 6-2 11t-5 7-5 4-7 4l-3 1h-5v46h7q15-3 99-3 79 0 85 3h6v-46h-7q-49 0-81-17-17-8-34-27t-65-84l-16-21 62-85q66-90 71-94t17-7q18-4 53-4h17V0h-14q-8 1-20 1t-25 1-25 0-18 1h-37q-26 0-50-2l-23-1h-9v46h3q11 0 22 5t11 12q0 2-40 57l-41 55q-1-1-31-42t-34-45q-4-5-4-14 0-11 7-19t18-9q2 0 2-23V0h-7Z'/%3E%3Cpath id='f' stroke-width='10' d='M55 507q0 83 57 140t131 57h14q85 0 148-63l21 31q5 7 10 15t10 13l3 4h4q3 0 6 1h4q3 0 9-6V462l-6-6h-18q-11 0-13 3t-5 20q-17 126-101 167-37 16-75 16-53 0-86-36t-33-84q0-34 17-62t48-45q10-4 86-23t84-23q57-22 93-75t37-123q0-81-52-146T301-21q-56 0-100 17t-61 31l-18 14q-4-5-15-20T87-7t-9-14q-2-1-10-1h-4q-3 0-9 6v117q0 119 1 121 2 5 20 5h13q6-6 6-13 0-32 10-63t34-61 66-48 100-18q47 0 81 38t34 93q0 43-22 78t-58 48q-56 14-74 19-5 1-27 6t-33 8-32 11-33 18-29 24-27 35q-30 49-30 105Z'/%3E%3Cpath id='i' stroke-width='10' d='M69 609q0 28 18 44t44 16q23-2 40-17t17-43q0-30-17-45t-42-15q-25 0-42 15t-18 45ZM247 0q-15 3-104 3h-37Q80 3 56 1L34 0h-8v46h16q28 0 49 3 9 4 11 11t2 42v191q0 52-2 66t-14 19q-14 7-47 7H30v23q0 23 2 23l10 1q10 1 28 2t36 2 36 2 29 3 11 1h3V62q5-10 12-12t35-4h23V0h-8Z'/%3E%3Cpath id='j' stroke-width='10' d='M376 495v40q0 24 1 33 0 45-10 56t-51 13h-18v23q0 23 2 23l10 1q10 1 29 2t37 2 37 2 30 3 11 1h3V390q0-306 1-309 3-20 14-26t45-9h18V0q-2 0-76-5t-79-6h-7v55l-8-7q-58-48-130-48-77 0-139 61T34 215q0 100 63 163t147 64q75 0 132-49v102Zm-3-153q-45 63-113 63-49 0-87-36-27-28-34-64t-8-94q0-56 7-91t35-61q30-33 78-33 71 0 122 77v239Z'/%3E%3Cpath id='o' stroke-width='10' d='M56 340q0 83 30 154t78 116 106 70 118 25q133 0 233-104t101-260q0-81-29-150T617 75 510 4 388-22 267 3 160 74 85 189 56 340Zm411 307q-41 18-79 18-28 0-57-11t-62-34-56-71-34-110q-5-28-5-85 0-210 103-293 50-41 108-41h6q83 0 146 79 66 89 66 255 0 57-5 85-21 153-131 208Z'/%3E%3Cpath id='p' stroke-width='10' d='M273 0q-18 3-127 3Q43 3 34 0h-8v46h16q28 0 49 3 8 3 12 11 1 2 1 164v161H33v46h71v66l1 67 2 10q19 65 64 94t95 36h9q8 0 14 1 41-3 62-26t21-52q0-23-14-37t-37-14-37 14-14 37q0 20 18 40h-4q-4 1-11 1-28 0-50-21t-34-55q-6-20-7-95v-66h111v-46H185V225q0-162 1-164t3-4 5-3 5-3 7-2 7-1 9-1 9 0 10-1 10 0h31V0h-9Z'/%3E%3C/defs%3E%3C/svg%3E"></p> <p>Some hardware implements robust vertex fetch natively. Other hardware has bounds-checked buffers to accelerate robust software vertex fetch. Unfortunately, the M1 has neither. We need to implement vertex fetch with raw memory loads.</p> <p>One instruction set feature helps. In addition to a 64-bit base address, the M1 GPU’s memory loads also take an offset in <em>elements</em>. The hardware shifts the offset and adds to the 64-bit base to determine the address to fetch. Additionally, the M1 has a combined integer multiply-add instruction <code>imad</code>. Together, these features let us implement vertex loads in two instructions. For example, a 32-bit attribute load looks like:</p> <div><pre><code><span><span>imad</span> idx, stride/<span>4</span>, vertex, offset/<span>4</span></span>
<span><span>load</span>.i32 result, base, idx</span></code></pre></div> <p>The hardware load can perform an additional small shift. Suppose our attribute is a vector of 4 32-bit values, densely packed into a buffer with no offset. We can load that attribute in one instruction:</p> <div><pre><code><span><span>load</span>.v4i32 result, base, vertex <span>&lt;&lt;</span> <span>2</span></span></code></pre></div> <p>…with the hardware calculating the address:</p> <p><img alt="Base plus 4 times vertex left shifted 2, which equals Base plus 16 times vertex" src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' style='width:25.375ex;height:5.75ex;vertical-align:-2.375ex;margin:1px 0' viewBox='0 -1478.581 10898.731 2457.161'%3E%3Cg stroke='%23000' stroke-width='0'%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23a' y='-700' transform='matrix(1 0 0 -1 153 0)'/%3E%3Cg transform='matrix(1 0 0 -1 936 -660)'%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23b'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23c' x='713'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23d' x='1218'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23e' x='1617'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23f' x='2288'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23g' x='3293'/%3E%3Cg transform='translate(3965)'%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23h'/%3E%3Cg transform='translate(394)'%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23i'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23e' x='755'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23j' x='1204'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23k' x='1601'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23e' x='1995'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23l' x='2444'/%3E%3C/g%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23m' x='3648'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23n' x='4931'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23o' x='5436'/%3E%3C/g%3E%3C/g%3E%3Cg transform='matrix(1 0 0 -1 936 700)'%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23b'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23c' x='713'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23d' x='1218'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23e' x='1617'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23f' x='2288'/%3E%3Cg transform='translate(3293)'%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23p'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23q' x='505'/%3E%3C/g%3E%3Cg transform='translate(4470)'%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23h'/%3E%3Cg transform='translate(394)'%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23i'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23e' x='755'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23j' x='1204'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23k' x='1601'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23e' x='1995'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23l' x='2444'/%3E%3C/g%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23o' x='3371'/%3E%3C/g%3E%3C/g%3E%3C/g%3E%3Cdefs%3E%3Cpath id='a' stroke-width='10' d='M56 347q0 13 14 20h637q15-8 15-20 0-11-14-19l-318-1H72q-16 5-16 20Zm0-194q0 15 16 20h636q14-10 14-20 0-13-15-20H70q-14 7-14 20Z'/%3E%3Cpath id='h' stroke-width='10' d='M94 250q0 69 10 131t23 107 37 88 38 67 42 52 33 34 25 21h17q14 0 14-9 0-3-17-21t-41-53-49-86-42-138-17-193 17-192 41-139 49-86 42-53 17-21q0-9-15-9h-16l-28 24q-94 85-137 212T94 250Z'/%3E%3Cpath id='f' stroke-width='10' d='M56 237v13l14 20h299v150l1 150q10 13 19 13 13 0 20-15V270h298q15-8 15-20t-15-20H409V-68q-8-14-18-14h-4q-12 0-18 14v298H70q-14 7-14 20Z'/%3E%3Cpath id='p' stroke-width='10' d='m213 578-13-5q-14-5-40-10t-58-7H83v46h19q47 2 87 15t56 24 28 22q2 3 12 3 9 0 17-6V361l1-300q7-7 12-9t24-4 62-2h26V0h-11q-21 3-159 3-136 0-157-3H88v46h64q16 0 25 1t16 3 8 2 6 5 6 4v517Z'/%3E%3Cpath id='o' stroke-width='10' d='m60 749 4 1h22l28-24q94-85 137-212t43-264q0-68-10-131T261 12t-37-88-38-67-41-51-32-33-23-19l-4-4H63q-3 0-5 3t-3 9q1 1 11 13Q221-64 221 250T66 725q-10 12-11 13 0 8 5 11Z'/%3E%3Cpath id='n' stroke-width='10' d='M109 429q-27 0-43 18t-16 44q0 71 53 123t132 52q91 0 152-56t62-145q0-43-20-82t-48-68-80-74q-36-31-100-92l-59-56 76-1q157 0 167 5 7 2 24 89v3h40v-3q-1-3-13-91T421 3V0H50v31q0 7 6 15t30 35q29 32 50 56 9 10 34 37t34 37 29 33 28 34 23 30 21 32 15 29 13 32 7 30 3 33q0 63-34 109t-97 46q-33 0-58-17t-35-33-10-19q0-1 5-1 18 0 37-14t19-46q0-25-16-42t-45-18Z'/%3E%3Cpath id='b' stroke-width='10' d='M131 622q-7 7-11 9t-16 3-43 3H28v46h318q77 0 113-5t72-27q43-24 68-61t25-78q0-51-41-93t-107-59l-10-3q73-9 129-55t56-115q0-68-51-120T469 3q-13-2-227-3H28v46h33q42 1 51 3t19 12v561Zm380-109q0 47-26 81t-69 42h-45q-20 0-38 1-67 0-82-1t-19-8q-3-4-3-129V374h83l84 1 10 2q4 1 11 3t25 13 32 24 25 39 12 57Zm26-325q0 51-28 94t-79 54l-101 1H229V116q0-59 5-64 6-5 100-5h49q42 0 60 6 43 14 68 51t26 84Z'/%3E%3Cpath id='c' stroke-width='10' d='M137 305h-22l-37 15-15 39q0 35 34 62t121 27q73 0 118-32t60-76q5-14 5-31t1-115v-70q0-48 5-66t21-18q15 0 20 16t5 53v36h40v-39q-1-40-3-47-9-30-35-47T400-6t-47 18-24 42v4l-2-3q-2-3-5-6t-8-9-12-11-15-12-18-11-22-8-26-6-31-3q-60 0-108 31t-48 87q0 21 7 40t27 41 48 37 78 28 110 15h14v22q0 34-6 50-22 71-97 71-18 0-34-1t-25-4-8-3q22-15 22-44 0-25-16-39Zm-11-199q0-31 24-55t59-25q38 0 67 23t39 60q2 7 3 66 0 58-1 58-8 0-21-1t-45-9-58-20-46-37-21-60Z'/%3E%3Cpath id='d' stroke-width='10' d='M295 316q0 40-27 69t-78 29q-36 0-62-13-30-19-30-52-1-5 0-13t16-24 43-25q18-5 44-9t44-9 32-13q17-8 33-20t32-41 17-62q0-62-38-102T198-10h-8q-52 0-96 36l-8-7-9-9Q71 4 65-1L54-11H42q-3 0-9 6v137q0 21 2 25t10 5h9q12 0 16-4t5-12 7-27 19-42q35-51 97-51 97 0 97 78 0 29-18 47-20 24-83 36t-83 23q-36 17-57 46t-21 62q0 39 17 66t43 40 50 18 44 5h11q40 0 70-15l15-8 9 7q10 9 22 17h12q3 0 9-6V310l-6-6h-28q-6 6-6 12Z'/%3E%3Cpath id='e' stroke-width='10' d='M28 218q0 55 20 100t50 73 65 42 66 15q53 0 91-18t58-50 28-64 9-71q0-7-7-14H126v-15q0-148 100-180 20-6 44-6 42 0 72 32 17 17 27 42l10 24q3 3 16 3h3q17 0 17-10 0-4-3-13-19-55-63-87t-99-32q-95 0-158 69T28 218Zm305 57q-11 128-95 136h-2q-8 0-16-1t-25-8-29-21-23-41-16-66v-7h206v8Z'/%3E%3Cpath id='g' stroke-width='10' d='M462 0q-18 3-129 3-116 0-134-3h-9v46h58q7 0 17 2t14 5 7 8q1 2 1 54v50H28v46l151 231q153 232 155 233 2 2 21 2h18l6-6V211h92v-46h-92V66q0-7 6-12 8-7 57-8h29V0h-9ZM293 211v334L74 212l109-1h110Z'/%3E%3Cpath id='i' stroke-width='10' d='m114 620-4 4-3 3-4 3q-4 3-5 2t-7 2-11 1-13 1-19 1H19v46h9q18-3 124-3 121 0 142 3h11v-46h-21q-61-3-61-17 0-2 90-248t91-246l86 232q85 230 85 239 0 19-21 29t-46 11h-5v46h9q15-3 115-3 91 0 97 3h6v-46h-7q-75 0-96-41 0-1-112-305T401-14q-5-8-19-8h-15q-14 0-19 8-2 2-117 317-117 314-117 317Z'/%3E%3Cpath id='j' stroke-width='10' d='M36 46h14q39 0 47 14v31q0 14 1 31t0 39 0 42v125l-1 23q-3 19-14 25t-45 9H20v23q0 23 2 23l10 1q10 1 28 2t36 2q16 1 35 2t29 3 11 1h3v-69q39 68 97 68h6q45 0 66-22t21-46q0-21-13-36t-38-15q-25 0-37 16t-13 34q0 9 2 16t5 12 3 5q-2 2-23-4-16-8-24-15-47-45-47-179V101q0-12 1-20t0-15v-5q1-2 3-4t5-3 5-3 7-2 7-1 9-1 9 0 10-1 10 0h31V0h-9q-18 3-127 3Q37 3 28 0h-8v46h16Z'/%3E%3Cpath id='k' stroke-width='10' d='M27 422q53 4 82 56t32 122v15h40V431h135v-46H181V241q1-125 1-141t7-32q14-39 49-39 44 0 54 71 1 8 1 46v35h40v-47q0-77-42-117-27-27-70-27-34 0-59 12t-38 31-19 35-7 32q-1 7-1 148v137H18v37h9Z'/%3E%3Cpath id='l' stroke-width='10' d='M201 0q-12 3-99 3-76 0-85-3h-6v46h14q23 1 42 6t29 9 25 17 18 18 21 26 20 28l46 60-58 78q-9 13-19 27t-16 21-11 15-9 12-6 7-7 6-6 3-6 2-8 2q-6 0-36 2H16v46h7q36-2 103-2 93 0 103 2h8v-46q-36-4-36-16 0-2 10-16t28-38 29-41l4-4 25 34q32 41 32 54 0 6-2 11t-5 7-5 4-7 4l-3 1h-5v46h7q15-3 99-3 79 0 85 3h6v-46h-7q-49 0-81-17-17-8-34-27t-65-84l-16-21 62-85q66-90 71-94t17-7q18-4 53-4h17V0h-14q-8 1-20 1t-25 1-25 0-18 1h-37q-26 0-50-2l-23-1h-9v46h3q11 0 22 5t11 12q0 2-40 57l-41 55q-1-1-31-42t-34-45q-4-5-4-14 0-11 7-19t18-9q2 0 2-23V0h-7Z'/%3E%3Cpath id='m' stroke-width='10' d='M639-48q0-6-5-12t-15-7h-1q-6 0-82 41Q430 33 329 88 61 235 59 239q-3 4-3 11t3 11q3 5 277 154t279 152l4 1q3-1 6-1 14-5 14-19 0-8-6-14-1-2-259-143L117 250l257-141Q632-32 633-34q6-6 6-14Zm305 0q0-6-5-12t-15-7h-1q-6 0-82 41Q735 33 634 88 366 235 364 239q-3 4-3 11t3 11q3 5 277 154t279 152l4 1q3-1 6-1 14-5 14-19 0-8-6-14-1-2-259-143L422 250l257-141Q937-32 938-34q6-6 6-14Z'/%3E%3Cpath id='q' stroke-width='10' d='M42 313q0 163 81 258t180 95q69 0 99-36t30-80q0-25-14-40t-39-15q-23 0-38 14t-15 39q0 44 47 53-22 22-62 25-71 0-117-60-47-66-47-202l1-4q5 6 8 13 41 60 107 60h4q46 0 81-19 24-14 48-40t39-57q21-49 21-107v-18q0-23-5-43-11-59-64-115T253-22q-28 0-54 8t-56 30-51 59-36 97-14 141Zm215 84q-30 0-52-17t-34-45-17-57-6-62q0-83 12-119t38-58q24-18 53-18 51 0 78 38 13 18 18 45t5 105q0 80-5 107t-18 45q-27 36-72 36Z'/%3E%3C/defs%3E%3C/svg%3E"></p> <p>What about robustness?</p> <p>We want to implement robustness with a clamp, like we did for uniform buffers. The problem is that the vertex buffer size is given in bytes, while our optimized load takes an index in “vertices”. A single vertex buffer can contain multiple attributes with different formats and offsets, so we can’t convert the size in bytes to a size in “vertices”.</p> <p>Let’s handle the latter problem. We can rewrite the addressing equation as:</p> <p><img alt="Base plus offset, which is the attribute base, plus stride times vertex" src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' style='width:33.75ex;height:6ex;vertical-align:-4.25ex;margin:1px 0' viewBox='0 -778.581 14532.556 2598.036'%3E%3Cg stroke='%23000' stroke-width='0' transform='scale(1 -1)'%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23a'/%3E%3Cg transform='translate(394)'%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23b'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23c' x='713'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23d' x='1218'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23e' x='1617'/%3E%3C/g%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23f' x='2682'/%3E%3Cg transform='translate(3687)'%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23g'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23h' x='783'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23h' x='1094'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23d' x='1405'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23e' x='1804'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23i' x='2253'/%3E%3C/g%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23j' x='6334'/%3E%3Cg transform='translate(12 -783)'%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23k' x='19'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23l' transform='matrix(5.77434 0 0 1 512.872 0)'/%3E%3Cg transform='translate(2909)'%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23m'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23n' x='455'/%3E%3C/g%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23l' transform='matrix(5.77434 0 0 1 3848.094 0)'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23o' x='6249'/%3E%3C/g%3E%3Cg transform='matrix(.7071 0 0 .7071 1116 -1687)'%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23p'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23i' x='754'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23i' x='1149'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23q' x='1543'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23r' x='1940'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23s' x='2223'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23t' x='2784'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23i' x='3345'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23e' x='3739'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23u' x='4188'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23s' x='4443'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23c' x='5004'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23d' x='5509'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23e' x='5908'/%3E%3C/g%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23f' x='6950'/%3E%3Cg transform='translate(7955)'%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23v'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23i' x='561'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23q' x='955'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23r' x='1352'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23w' x='1635'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23e' x='2196'/%3E%3C/g%3E%3Cg transform='translate(10767)'%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23a'/%3E%3Cg transform='translate(394)'%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23x'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23e' x='755'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23q' x='1204'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23i' x='1601'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23e' x='1995'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23y' x='2444'/%3E%3C/g%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23j' x='3371'/%3E%3C/g%3E%3C/g%3E%3Cdefs%3E%3Cpath id='a' stroke-width='10' d='M94 250q0 69 10 131t23 107 37 88 38 67 42 52 33 34 25 21h17q14 0 14-9 0-3-17-21t-41-53-49-86-42-138-17-193 17-192 41-139 49-86 42-53 17-21q0-9-15-9h-16l-28 24q-94 85-137 212T94 250Z'/%3E%3Cpath id='f' stroke-width='10' d='M56 237v13l14 20h299v150l1 150q10 13 19 13 13 0 20-15V270h298q15-8 15-20t-15-20H409V-68q-8-14-18-14h-4q-12 0-18 14v298H70q-14 7-14 20Z'/%3E%3Cpath id='j' stroke-width='10' d='m60 749 4 1h22l28-24q94-85 137-212t43-264q0-68-10-131T261 12t-37-88-38-67-41-51-32-33-23-19l-4-4H63q-3 0-5 3t-3 9q1 1 11 13Q221-64 221 250T66 725q-10 12-11 13 0 8 5 11Z'/%3E%3Cpath id='b' stroke-width='10' d='M131 622q-7 7-11 9t-16 3-43 3H28v46h318q77 0 113-5t72-27q43-24 68-61t25-78q0-51-41-93t-107-59l-10-3q73-9 129-55t56-115q0-68-51-120T469 3q-13-2-227-3H28v46h33q42 1 51 3t19 12v561Zm380-109q0 47-26 81t-69 42h-45q-20 0-38 1-67 0-82-1t-19-8q-3-4-3-129V374h83l84 1 10 2q4 1 11 3t25 13 32 24 25 39 12 57Zm26-325q0 51-28 94t-79 54l-101 1H229V116q0-59 5-64 6-5 100-5h49q42 0 60 6 43 14 68 51t26 84Z'/%3E%3Cpath id='c' stroke-width='10' d='M137 305h-22l-37 15-15 39q0 35 34 62t121 27q73 0 118-32t60-76q5-14 5-31t1-115v-70q0-48 5-66t21-18q15 0 20 16t5 53v36h40v-39q-1-40-3-47-9-30-35-47T400-6t-47 18-24 42v4l-2-3q-2-3-5-6t-8-9-12-11-15-12-18-11-22-8-26-6-31-3q-60 0-108 31t-48 87q0 21 7 40t27 41 48 37 78 28 110 15h14v22q0 34-6 50-22 71-97 71-18 0-34-1t-25-4-8-3q22-15 22-44 0-25-16-39Zm-11-199q0-31 24-55t59-25q38 0 67 23t39 60q2 7 3 66 0 58-1 58-8 0-21-1t-45-9-58-20-46-37-21-60Z'/%3E%3Cpath id='d' stroke-width='10' d='M295 316q0 40-27 69t-78 29q-36 0-62-13-30-19-30-52-1-5 0-13t16-24 43-25q18-5 44-9t44-9 32-13q17-8 33-20t32-41 17-62q0-62-38-102T198-10h-8q-52 0-96 36l-8-7-9-9Q71 4 65-1L54-11H42q-3 0-9 6v137q0 21 2 25t10 5h9q12 0 16-4t5-12 7-27 19-42q35-51 97-51 97 0 97 78 0 29-18 47-20 24-83 36t-83 23q-36 17-57 46t-21 62q0 39 17 66t43 40 50 18 44 5h11q40 0 70-15l15-8 9 7q10 9 22 17h12q3 0 9-6V310l-6-6h-28q-6 6-6 12Z'/%3E%3Cpath id='e' stroke-width='10' d='M28 218q0 55 20 100t50 73 65 42 66 15q53 0 91-18t58-50 28-64 9-71q0-7-7-14H126v-15q0-148 100-180 20-6 44-6 42 0 72 32 17 17 27 42l10 24q3 3 16 3h3q17 0 17-10 0-4-3-13-19-55-63-87t-99-32q-95 0-158 69T28 218Zm305 57q-11 128-95 136h-2q-8 0-16-1t-25-8-29-21-23-41-16-66v-7h206v8Z'/%3E%3Cpath id='x' stroke-width='10' d='m114 620-4 4-3 3-4 3q-4 3-5 2t-7 2-11 1-13 1-19 1H19v46h9q18-3 124-3 121 0 142 3h11v-46h-21q-61-3-61-17 0-2 90-248t91-246l86 232q85 230 85 239 0 19-21 29t-46 11h-5v46h9q15-3 115-3 91 0 97 3h6v-46h-7q-75 0-96-41 0-1-112-305T401-14q-5-8-19-8h-15q-14 0-19 8-2 2-117 317-117 314-117 317Z'/%3E%3Cpath id='q' stroke-width='10' d='M36 46h14q39 0 47 14v31q0 14 1 31t0 39 0 42v125l-1 23q-3 19-14 25t-45 9H20v23q0 23 2 23l10 1q10 1 28 2t36 2q16 1 35 2t29 3 11 1h3v-69q39 68 97 68h6q45 0 66-22t21-46q0-21-13-36t-38-15q-25 0-37 16t-13 34q0 9 2 16t5 12 3 5q-2 2-23-4-16-8-24-15-47-45-47-179V101q0-12 1-20t0-15v-5q1-2 3-4t5-3 5-3 7-2 7-1 9-1 9 0 10-1 10 0h31V0h-9q-18 3-127 3Q37 3 28 0h-8v46h16Z'/%3E%3Cpath id='i' stroke-width='10' d='M27 422q53 4 82 56t32 122v15h40V431h135v-46H181V241q1-125 1-141t7-32q14-39 49-39 44 0 54 71 1 8 1 46v35h40v-47q0-77-42-117-27-27-70-27-34 0-59 12t-38 31-19 35-7 32q-1 7-1 148v137H18v37h9Z'/%3E%3Cpath id='y' stroke-width='10' d='M201 0q-12 3-99 3-76 0-85-3h-6v46h14q23 1 42 6t29 9 25 17 18 18 21 26 20 28l46 60-58 78q-9 13-19 27t-16 21-11 15-9 12-6 7-7 6-6 3-6 2-8 2q-6 0-36 2H16v46h7q36-2 103-2 93 0 103 2h8v-46q-36-4-36-16 0-2 10-16t28-38 29-41l4-4 25 34q32 41 32 54 0 6-2 11t-5 7-5 4-7 4l-3 1h-5v46h7q15-3 99-3 79 0 85 3h6v-46h-7q-49 0-81-17-17-8-34-27t-65-84l-16-21 62-85q66-90 71-94t17-7q18-4 53-4h17V0h-14q-8 1-20 1t-25 1-25 0-18 1h-37q-26 0-50-2l-23-1h-9v46h3q11 0 22 5t11 12q0 2-40 57l-41 55q-1-1-31-42t-34-45q-4-5-4-14 0-11 7-19t18-9q2 0 2-23V0h-7Z'/%3E%3Cpath id='v' stroke-width='10' d='M55 507q0 83 57 140t131 57h14q85 0 148-63l21 31q5 7 10 15t10 13l3 4h4q3 0 6 1h4q3 0 9-6V462l-6-6h-18q-11 0-13 3t-5 20q-17 126-101 167-37 16-75 16-53 0-86-36t-33-84q0-34 17-62t48-45q10-4 86-23t84-23q57-22 93-75t37-123q0-81-52-146T301-21q-56 0-100 17t-61 31l-18 14q-4-5-15-20T87-7t-9-14q-2-1-10-1h-4q-3 0-9 6v117q0 119 1 121 2 5 20 5h13q6-6 6-13 0-32 10-63t34-61 66-48 100-18q47 0 81 38t34 93q0 43-22 78t-58 48q-56 14-74 19-5 1-27 6t-33 8-32 11-33 18-29 24-27 35q-30 49-30 105Z'/%3E%3Cpath id='r' stroke-width='10' d='M69 609q0 28 18 44t44 16q23-2 40-17t17-43q0-30-17-45t-42-15q-25 0-42 15t-18 45ZM247 0q-15 3-104 3h-37Q80 3 56 1L34 0h-8v46h16q28 0 49 3 9 4 11 11t2 42v191q0 52-2 66t-14 19q-14 7-47 7H30v23q0 23 2 23l10 1q10 1 28 2t36 2 36 2 29 3 11 1h3V62q5-10 12-12t35-4h23V0h-8Z'/%3E%3Cpath id='w' stroke-width='10' d='M376 495v40q0 24 1 33 0 45-10 56t-51 13h-18v23q0 23 2 23l10 1q10 1 29 2t37 2 37 2 30 3 11 1h3V390q0-306 1-309 3-20 14-26t45-9h18V0q-2 0-76-5t-79-6h-7v55l-8-7q-58-48-130-48-77 0-139 61T34 215q0 100 63 163t147 64q75 0 132-49v102Zm-3-153q-45 63-113 63-49 0-87-36-27-28-34-64t-8-94q0-56 7-91t35-61q30-33 78-33 71 0 122 77v239Z'/%3E%3Cpath id='g' stroke-width='10' d='M56 340q0 83 30 154t78 116 106 70 118 25q133 0 233-104t101-260q0-81-29-150T617 75 510 4 388-22 267 3 160 74 85 189 56 340Zm411 307q-41 18-79 18-28 0-57-11t-62-34-56-71-34-110q-5-28-5-85 0-210 103-293 50-41 108-41h6q83 0 146 79 66 89 66 255 0 57-5 85-21 153-131 208Z'/%3E%3Cpath id='h' stroke-width='10' d='M273 0q-18 3-127 3Q43 3 34 0h-8v46h16q28 0 49 3 8 3 12 11 1 2 1 164v161H33v46h71v66l1 67 2 10q19 65 64 94t95 36h9q8 0 14 1 41-3 62-26t21-52q0-23-14-37t-37-14-37 14-14 37q0 20 18 40h-4q-4 1-11 1-28 0-50-21t-34-55q-6-20-7-95v-66h111v-46H185V225q0-162 1-164t3-4 5-3 5-3 7-2 7-1 9-1 9 0 10-1 10 0h31V0h-9Z'/%3E%3Cpath id='k' stroke-width='10' d='m-24 327 6 6h33q4 0 7-4t5-7 8-14 19-24q61-81 171-122t216-42q13 0 16-3t3-22V28q0-20-3-24t-15-4q-87 0-182 36Q75 118-16 278l-8 14v35Z'/%3E%3Cpath id='o' stroke-width='10' d='M-10 60v35q0 18 3 21t16 4q142 0 241 51t146 113q8 9 16 21t12 19 7 7q2 2 20 2h17l6-6v-35l-8-14Q375 118 190 36 95 0 8 0-5 0-7 3t-3 21v36Z'/%3E%3Cpath id='m' stroke-width='10' d='M-10 60v51q0 7 5 7 4 2 15 2 86 0 180-36Q375 2 466-158l8-14v-35l-6-6h-34q-3 0-6 4t-5 7-9 15-18 24Q331-82 224-41T9 0Q-4 0-7 3t-3 22v35Z'/%3E%3Cpath id='n' stroke-width='10' d='m-18-213-6 6v35l8 14Q75 2 260 84q74 29 155 35h12q9 0 13 1 14 0 17-3t3-19V25q0-18-3-21t-16-4Q308 0 193-55T25-205q-4-6-7-7t-19-1h-17Z'/%3E%3Cpath id='l' stroke-width='10' d='M-10 0v120h420V0H-10Z'/%3E%3Cpath id='p' stroke-width='10' d='M255 0q-15 3-115 3Q48 3 39 0h-7v46h15q72 3 92 42 1 3 53 157t103 308 53 155q3 8 18 8h10q20-1 24-7 2-2 108-319L617 67q7-13 19-16t51-5h30V0h-9q-9 3-127 3-123 0-144-3h-10v46h13q70 0 70 18 0 2-24 74l-24 71H229l-20-59q-20-59-20-65 0-13 20-26t50-13h5V0h-9Zm192 255L345 557 244 256q0-1 101-1h102Z'/%3E%3Cpath id='s' stroke-width='10' d='M307-11q-73 0-139 66l-10-18q-2-3-5-9t-6-11-4-7l-5-9-20-1H98v298q0 301-1 305-3 19-14 25t-45 9H20v23q0 23 2 23l10 1q10 1 29 2t37 2 37 2 30 3 11 1h3V543q0-152 1-152l3 3q3 3 9 7t15 10 21 10 26 10 32 8 37 3q78 0 138-63t61-163q0-101-64-164T307-11ZM182 98q0-1 5-8t9-11 10-12 12-12 15-11 17-9 21-6 24-3q35 0 68 20t49 67q12 35 12 99 0 75-12 111-27 82-112 82-30 0-61-15t-51-43l-6-8V98Z'/%3E%3Cpath id='t' stroke-width='10' d='M383 58q-56-68-127-68h-7q-125 0-144 99-1 7-2 137-1 109-1 122t-6 21q-10 16-60 16H25v23q0 23 2 23l11 1q10 1 29 2t38 2q17 1 37 2t30 3 12 1h3V261q1-184 3-197 3-15 14-24 20-14 60-14 26 0 47 9t32 23 20 32 12 30 4 24v17q0 16 1 40t0 47v67q0 46-10 57t-50 13h-18v46q2 0 76 5t79 6h7V264q0-180 1-183 3-20 14-26t45-9h18V0q-2 0-75-5t-77-6h-7v69Z'/%3E%3C/defs%3E%3C/svg%3E"></p> <p>That is: one buffer with many attributes at different offsets is equivalent to many buffers with one attribute and no offset. This gives an alternate perspective on the same data layout. Is this an improvement? It avoids an addition in the shader, at the cost of passing more data – addresses are 64-bit while attribute offsets are <a href="https://vulkan.gpuinfo.org/listreports.php?limit=maxVertexInputAttributeOffset&amp;value=4294967295&amp;platform=all0">16-bit</a>. More importantly, it lets us translate the vertex buffer size in bytes into a size in “vertices” for <em>each</em> vertex attribute. Instead of clamping the offset, we clamp the vertex index. We still make full use of the hardware addressing modes, now with robustness:</p> <div><pre><code><span><span>umin</span> idx, vertex, last valid</span>
<span><span>load</span>.v4i32 result, base, idx <span>&lt;&lt;</span> <span>2</span></span></code></pre></div> <p>We need to calculate the last valid vertex index ahead-of-time for each attribute. Each attribute has a format with a particular size. Manipulating the addressing equation, we can calculate the last <em>byte</em> accessed in the buffer (plus 1) relative to the base:</p> <p><img alt="Offset plus stride times vertex plus format" src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' style='width:31.5ex;height:2.5ex;vertical-align:-.75ex;margin:1px 0' viewBox='0 -778.581 13568.556 1057.161'%3E%3Cg stroke='%23000' stroke-width='0' transform='scale(1 -1)'%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23a'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23b' x='783'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23b' x='1094'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23c' x='1405'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23d' x='1804'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23e' x='2253'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23f' x='2869'/%3E%3Cg transform='translate(3874)'%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23g'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23e' x='561'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23h' x='955'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23i' x='1352'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23j' x='1635'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23d' x='2196'/%3E%3C/g%3E%3Cg transform='translate(6686)'%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23k'/%3E%3Cg transform='translate(394)'%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23l'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23d' x='755'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23h' x='1204'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23e' x='1601'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23d' x='1995'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23m' x='2444'/%3E%3C/g%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23n' x='3371'/%3E%3C/g%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23f' x='10673'/%3E%3Cg transform='translate(11678)'%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23o'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23p' x='658'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23e' x='1496'/%3E%3C/g%3E%3C/g%3E%3Cdefs%3E%3Cpath id='k' stroke-width='10' d='M94 250q0 69 10 131t23 107 37 88 38 67 42 52 33 34 25 21h17q14 0 14-9 0-3-17-21t-41-53-49-86-42-138-17-193 17-192 41-139 49-86 42-53 17-21q0-9-15-9h-16l-28 24q-94 85-137 212T94 250Z'/%3E%3Cpath id='f' stroke-width='10' d='M56 237v13l14 20h299v150l1 150q10 13 19 13 13 0 20-15V270h298q15-8 15-20t-15-20H409V-68q-8-14-18-14h-4q-12 0-18 14v298H70q-14 7-14 20Z'/%3E%3Cpath id='n' stroke-width='10' d='m60 749 4 1h22l28-24q94-85 137-212t43-264q0-68-10-131T261 12t-37-88-38-67-41-51-32-33-23-19l-4-4H63q-3 0-5 3t-3 9q1 1 11 13Q221-64 221 250T66 725q-10 12-11 13 0 8 5 11Z'/%3E%3Cpath id='c' stroke-width='10' d='M295 316q0 40-27 69t-78 29q-36 0-62-13-30-19-30-52-1-5 0-13t16-24 43-25q18-5 44-9t44-9 32-13q17-8 33-20t32-41 17-62q0-62-38-102T198-10h-8q-52 0-96 36l-8-7-9-9Q71 4 65-1L54-11H42q-3 0-9 6v137q0 21 2 25t10 5h9q12 0 16-4t5-12 7-27 19-42q35-51 97-51 97 0 97 78 0 29-18 47-20 24-83 36t-83 23q-36 17-57 46t-21 62q0 39 17 66t43 40 50 18 44 5h11q40 0 70-15l15-8 9 7q10 9 22 17h12q3 0 9-6V310l-6-6h-28q-6 6-6 12Z'/%3E%3Cpath id='d' stroke-width='10' d='M28 218q0 55 20 100t50 73 65 42 66 15q53 0 91-18t58-50 28-64 9-71q0-7-7-14H126v-15q0-148 100-180 20-6 44-6 42 0 72 32 17 17 27 42l10 24q3 3 16 3h3q17 0 17-10 0-4-3-13-19-55-63-87t-99-32q-95 0-158 69T28 218Zm305 57q-11 128-95 136h-2q-8 0-16-1t-25-8-29-21-23-41-16-66v-7h206v8Z'/%3E%3Cpath id='l' stroke-width='10' d='m114 620-4 4-3 3-4 3q-4 3-5 2t-7 2-11 1-13 1-19 1H19v46h9q18-3 124-3 121 0 142 3h11v-46h-21q-61-3-61-17 0-2 90-248t91-246l86 232q85 230 85 239 0 19-21 29t-46 11h-5v46h9q15-3 115-3 91 0 97 3h6v-46h-7q-75 0-96-41 0-1-112-305T401-14q-5-8-19-8h-15q-14 0-19 8-2 2-117 317-117 314-117 317Z'/%3E%3Cpath id='h' stroke-width='10' d='M36 46h14q39 0 47 14v31q0 14 1 31t0 39 0 42v125l-1 23q-3 19-14 25t-45 9H20v23q0 23 2 23l10 1q10 1 28 2t36 2q16 1 35 2t29 3 11 1h3v-69q39 68 97 68h6q45 0 66-22t21-46q0-21-13-36t-38-15q-25 0-37 16t-13 34q0 9 2 16t5 12 3 5q-2 2-23-4-16-8-24-15-47-45-47-179V101q0-12 1-20t0-15v-5q1-2 3-4t5-3 5-3 7-2 7-1 9-1 9 0 10-1 10 0h31V0h-9q-18 3-127 3Q37 3 28 0h-8v46h16Z'/%3E%3Cpath id='e' stroke-width='10' d='M27 422q53 4 82 56t32 122v15h40V431h135v-46H181V241q1-125 1-141t7-32q14-39 49-39 44 0 54 71 1 8 1 46v35h40v-47q0-77-42-117-27-27-70-27-34 0-59 12t-38 31-19 35-7 32q-1 7-1 148v137H18v37h9Z'/%3E%3Cpath id='m' stroke-width='10' d='M201 0q-12 3-99 3-76 0-85-3h-6v46h14q23 1 42 6t29 9 25 17 18 18 21 26 20 28l46 60-58 78q-9 13-19 27t-16 21-11 15-9 12-6 7-7 6-6 3-6 2-8 2q-6 0-36 2H16v46h7q36-2 103-2 93 0 103 2h8v-46q-36-4-36-16 0-2 10-16t28-38 29-41l4-4 25 34q32 41 32 54 0 6-2 11t-5 7-5 4-7 4l-3 1h-5v46h7q15-3 99-3 79 0 85 3h6v-46h-7q-49 0-81-17-17-8-34-27t-65-84l-16-21 62-85q66-90 71-94t17-7q18-4 53-4h17V0h-14q-8 1-20 1t-25 1-25 0-18 1h-37q-26 0-50-2l-23-1h-9v46h3q11 0 22 5t11 12q0 2-40 57l-41 55q-1-1-31-42t-34-45q-4-5-4-14 0-11 7-19t18-9q2 0 2-23V0h-7Z'/%3E%3Cpath id='g' stroke-width='10' d='M55 507q0 83 57 140t131 57h14q85 0 148-63l21 31q5 7 10 15t10 13l3 4h4q3 0 6 1h4q3 0 9-6V462l-6-6h-18q-11 0-13 3t-5 20q-17 126-101 167-37 16-75 16-53 0-86-36t-33-84q0-34 17-62t48-45q10-4 86-23t84-23q57-22 93-75t37-123q0-81-52-146T301-21q-56 0-100 17t-61 31l-18 14q-4-5-15-20T87-7t-9-14q-2-1-10-1h-4q-3 0-9 6v117q0 119 1 121 2 5 20 5h13q6-6 6-13 0-32 10-63t34-61 66-48 100-18q47 0 81 38t34 93q0 43-22 78t-58 48q-56 14-74 19-5 1-27 6t-33 8-32 11-33 18-29 24-27 35q-30 49-30 105Z'/%3E%3Cpath id='i' stroke-width='10' d='M69 609q0 28 18 44t44 16q23-2 40-17t17-43q0-30-17-45t-42-15q-25 0-42 15t-18 45ZM247 0q-15 3-104 3h-37Q80 3 56 1L34 0h-8v46h16q28 0 49 3 9 4 11 11t2 42v191q0 52-2 66t-14 19q-14 7-47 7H30v23q0 23 2 23l10 1q10 1 28 2t36 2 36 2 29 3 11 1h3V62q5-10 12-12t35-4h23V0h-8Z'/%3E%3Cpath id='j' stroke-width='10' d='M376 495v40q0 24 1 33 0 45-10 56t-51 13h-18v23q0 23 2 23l10 1q10 1 29 2t37 2 37 2 30 3 11 1h3V390q0-306 1-309 3-20 14-26t45-9h18V0q-2 0-76-5t-79-6h-7v55l-8-7q-58-48-130-48-77 0-139 61T34 215q0 100 63 163t147 64q75 0 132-49v102Zm-3-153q-45 63-113 63-49 0-87-36-27-28-34-64t-8-94q0-56 7-91t35-61q30-33 78-33 71 0 122 77v239Z'/%3E%3Cpath id='a' stroke-width='10' d='M56 340q0 83 30 154t78 116 106 70 118 25q133 0 233-104t101-260q0-81-29-150T617 75 510 4 388-22 267 3 160 74 85 189 56 340Zm411 307q-41 18-79 18-28 0-57-11t-62-34-56-71-34-110q-5-28-5-85 0-210 103-293 50-41 108-41h6q83 0 146 79 66 89 66 255 0 57-5 85-21 153-131 208Z'/%3E%3Cpath id='b' stroke-width='10' d='M273 0q-18 3-127 3Q43 3 34 0h-8v46h16q28 0 49 3 8 3 12 11 1 2 1 164v161H33v46h71v66l1 67 2 10q19 65 64 94t95 36h9q8 0 14 1 41-3 62-26t21-52q0-23-14-37t-37-14-37 14-14 37q0 20 18 40h-4q-4 1-11 1-28 0-50-21t-34-55q-6-20-7-95v-66h111v-46H185V225q0-162 1-164t3-4 5-3 5-3 7-2 7-1 9-1 9 0 10-1 10 0h31V0h-9Z'/%3E%3Cpath id='o' stroke-width='10' d='M128 619q-7 7-11 9t-16 3-43 3H25v46h557v-4q2-6 14-116t14-116v-4h-40v4q-7 49-9 57-6 37-18 62t-27 38-39 21-46 9-57 2h-88q-34 0-42-2t-11-10q-1-2-1-131V363h71q16 0 24 1t22 3 23 6 17 12q18 18 21 74v21h40V200h-40v21q-3 55-21 75-8 7-18 11t-23 6-21 3-24 1-19 0h-52V189l1-128q7-7 12-9t25-4 63-2h27V0h-12q-24 3-166 3Q51 3 36 0H25v46h33q42 1 51 3t19 12v558Z'/%3E%3Cpath id='p' stroke-width='10' d='M41 46h14q39 0 47 14v62q0 17 1 39t0 42v66q0 35-1 59v23q-3 19-14 25t-45 9H25v23q0 23 2 23l10 1q10 1 28 2t37 2q17 1 36 2t29 3 11 1h3v-40q0-38 1-38t5 5 12 15 19 18 29 19 38 16q20 5 51 5 15 0 28-2t23-6 19-8 15-9 11-11 9-11 7-11 4-10 3-8l2-5 3 4 6 8q3 4 9 11t13 13 15 13 20 12 23 10 26 7 31 3q126 0 137-113 1-7 1-139v-86q0-38 2-45t11-10q21-3 49-3h16V0h-8l-23 1q-24 1-51 1t-38 1Q596 3 587 0h-8v46h16q61 0 61 16 1 2 1 138-1 135-2 143-6 28-20 42t-24 17-26 2q-45 0-79-34-27-27-34-55t-8-83V108q0-30 1-40t3-13 9-6q21-3 49-3h16V0h-8l-24 1q-23 1-50 1t-38 1Q319 3 310 0h-8v46h16q61 0 61 16 1 2 1 138-1 135-2 143-6 28-20 42t-24 17-26 2q-45 0-79-34-27-27-34-55t-8-83V108q0-30 1-40t3-13 9-6q21-3 49-3h16V0h-8l-23 1q-24 1-51 1t-38 1Q42 3 33 0h-8v46h16Z'/%3E%3C/defs%3E%3C/svg%3E"></p> <p>The load is valid when that value is bounded by the buffer size in bytes. We solve the integer inequality as:</p> <p><img alt="Vertex less than or equal to the floor of size minus offset minus format divided by stride" src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' style='width:34.5ex;height:5.75ex;vertical-align:-2.375ex;margin:1px 0' viewBox='0 -1478.081 14863.222 2456.161'%3E%3Cg stroke='%23000' stroke-width='0' transform='scale(1 -1)'%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23a'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23b' x='755'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23c' x='1204'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23d' x='1601'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23b' x='1995'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23e' x='2444'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23f' x='3254'/%3E%3Cg transform='translate(4315)'%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23g' x='277' y='-1'/%3E%3Cpath stroke='none' d='M985 220h8853v60H985z'/%3E%3Cg transform='translate(1045 676)'%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23h'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23i' x='561'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23j' x='844'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23b' x='1293'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23k' x='1964'/%3E%3Cg transform='translate(2969)'%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23l'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23m' x='783'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23m' x='1094'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23n' x='1405'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23b' x='1804'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23d' x='2253'/%3E%3C/g%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23k' x='5838'/%3E%3Cg transform='translate(6843)'%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23o'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23p' x='658'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23d' x='1496'/%3E%3C/g%3E%3C/g%3E%3Cg transform='translate(4089 -690)'%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23h'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23d' x='561'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23c' x='955'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23i' x='1352'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23q' x='1635'/%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23b' x='2196'/%3E%3C/g%3E%3Cuse xmlns:xlink='http://www.w3.org/1999/xlink' xlink:href='%23r' x='9959' y='-1'/%3E%3C/g%3E%3C/g%3E%3Cdefs%3E%3Cpath id='n' stroke-width='10' d='M295 316q0 40-27 69t-78 29q-36 0-62-13-30-19-30-52-1-5 0-13t16-24 43-25q18-5 44-9t44-9 32-13q17-8 33-20t32-41 17-62q0-62-38-102T198-10h-8q-52 0-96 36l-8-7-9-9Q71 4 65-1L54-11H42q-3 0-9 6v137q0 21 2 25t10 5h9q12 0 16-4t5-12 7-27 19-42q35-51 97-51 97 0 97 78 0 29-18 47-20 24-83 36t-83 23q-36 17-57 46t-21 62q0 39 17 66t43 40 50 18 44 5h11q40 0 70-15l15-8 9 7q10 9 22 17h12q3 0 9-6V310l-6-6h-28q-6 6-6 12Z'/%3E%3Cpath id='b' stroke-width='10' d='M28 218q0 55 20 100t50 73 65 42 66 15q53 0 91-18t58-50 28-64 9-71q0-7-7-14H126v-15q0-148 100-180 20-6 44-6 42 0 72 32 17 17 27 42l10 24q3 3 16 3h3q17 0 17-10 0-4-3-13-19-55-63-87t-99-32q-95 0-158 69T28 218Zm305 57q-11 128-95 136h-2q-8 0-16-1t-25-8-29-21-23-41-16-66v-7h206v8Z'/%3E%3Cpath id='a' stroke-width='10' d='m114 620-4 4-3 3-4 3q-4 3-5 2t-7 2-11 1-13 1-19 1H19v46h9q18-3 124-3 121 0 142 3h11v-46h-21q-61-3-61-17 0-2 90-248t91-246l86 232q85 230 85 239 0 19-21 29t-46 11h-5v46h9q15-3 115-3 91 0 97 3h6v-46h-7q-75 0-96-41 0-1-112-305T401-14q-5-8-19-8h-15q-14 0-19 8-2 2-117 317-117 314-117 317Z'/%3E%3Cpath id='c' stroke-width='10' d='M36 46h14q39 0 47 14v31q0 14 1 31t0 39 0 42v125l-1 23q-3 19-14 25t-45 9H20v23q0 23 2 23l10 1q10 1 28 2t36 2q16 1 35 2t29 3 11 1h3v-69q39 68 97 68h6q45 0 66-22t21-46q0-21-13-36t-38-15q-25 0-37 16t-13 34q0 9 2 16t5 12 3 5q-2 2-23-4-16-8-24-15-47-45-47-179V101q0-12 1-20t0-15v-5q1-2 3-4t5-3 5-3 7-2 7-1 9-1 9 0 10-1 10 0h31V0h-9q-18 3-127 3Q37 3 28 0h-8v46h16Z'/%3E%3Cpath id='d' stroke-width='10' d='M27 422q53 4 82 56t32 122v15h40V431h135v-46H181V241q1-125 1-141t7-32q14-39 49-39 44 0 54 71 1 8 1 46v35h40v-47q0-77-42-117-27-27-70-27-34 0-59 12t-38 31-19 35-7 32q-1 7-1 148v137H18v37h9Z'/%3E%3Cpath id='e' stroke-width='10' d='M201 0q-12 3-99 3-76 0-85-3h-6v46h14q23 1 42 6t29 9 25 17 18 18 21 26 20 28l46 60-58 78q-9 13-19 27t-16 21-11 15-9 12-6 7-7 6-6 3-6 2-8 2q-6 0-36 2H16v46h7q36-2 103-2 93 0 103 2h8v-46q-36-4-36-16 0-2 10-16t28-38 29-41l4-4 25 34q32 41 32 54 0 6-2 11t-5 7-5 4-7 4l-3 1h-5v46h7q15-3 99-3 79 0 85 3h6v-46h-7q-49 0-81-17-17-8-34-27t-65-84l-16-21 62-85q66-90 71-94t17-7q18-4 53-4h17V0h-14q-8 1-20 1t-25 1-25 0-18 1h-37q-26 0-50-2l-23-1h-9v46h3q11 0 22 5t11 12q0 2-40 57l-41 55q-1-1-31-42t-34-45q-4-5-4-14 0-11 7-19t18-9q2 0 2-23V0h-7Z'/%3E%3Cpath id='h' stroke-width='10' d='M55 507q0 83 57 140t131 57h14q85 0 148-63l21 31q5 7 10 15t10 13l3 4h4q3 0 6 1h4q3 0 9-6V462l-6-6h-18q-11 0-13 3t-5 20q-17 126-101 167-37 16-75 16-53 0-86-36t-33-84q0-34 17-62t48-45q10-4 86-23t84-23q57-22 93-75t37-123q0-81-52-146T301-21q-56 0-100 17t-61 31l-18 14q-4-5-15-20T87-7t-9-14q-2-1-10-1h-4q-3 0-9 6v117q0 119 1 121 2 5 20 5h13q6-6 6-13 0-32 10-63t34-61 66-48 100-18q47 0 81 38t34 93q0 43-22 78t-58 48q-56 14-74 19-5 1-27 6t-33 8-32 11-33 18-29 24-27 35q-30 49-30 105Z'/%3E%3Cpath id='i' stroke-width='10' d='M69 609q0 28 18 44t44 16q23-2 40-17t17-43q0-30-17-45t-42-15q-25 0-42 15t-18 45ZM247 0q-15 3-104 3h-37Q80 3 56 1L34 0h-8v46h16q28 0 49 3 9 4 11 11t2 42v191q0 52-2 66t-14 19q-14 7-47 7H30v23q0 23 2 23l10 1q10 1 28 2t36 2 36 2 29 3 11 1h3V62q5-10 12-12t35-4h23V0h-8Z'/%3E%3Cpath id='q' stroke-width='10' d='M376 495v40q0 24 1 33 0 45-10 56t-51 13h-18v23q0 23 2 23l10 1q10 1 29 2t37 2 37 2 30 3 11 1h3V390q0-306 1-309 3-20 14-26t45-9h18V0q-2 0-76-5t-79-6h-7v55l-8-7q-58-48-130-48-77 0-139 61T34 215q0 100 63 163t147 64q75 0 132-49v102Zm-3-153q-45 63-113 63-49 0-87-36-27-28-34-64t-8-94q0-56 7-91t35-61q30-33 78-33 71 0 122 77v239Z'/%3E%3Cpath id='l' stroke-width='10' d='M56 340q0 83 30 154t78 116 106 70 118 25q133 0 233-104t101-260q0-81-29-150T617 75 510 4 388-22 267 3 160 74 85 189 56 340Zm411 307q-41 18-79 18-28 0-57-11t-62-34-56-71-34-110q-5-28-5-85 0-210 103-293 50-41 108-41h6q83 0 146 79 66 89 66 255 0 57-5 85-21 153-131 208Z'/%3E%3Cpath id='m' stroke-width='10' d='M273 0q-18 3-127 3Q43 3 34 0h-8v46h16q28 0 49 3 8 3 12 11 1 2 1 164v161H33v46h71v66l1 67 2 10q19 65 64 94t95 36h9q8 0 14 1 41-3 62-26t21-52q0-23-14-37t-37-14-37 14-14 37q0 20 18 40h-4q-4 1-11 1-28 0-50-21t-34-55q-6-20-7-95v-66h111v-46H185V225q0-162 1-164t3-4 5-3 5-3 7-2 7-1 9-1 9 0 10-1 10 0h31V0h-9Z'/%3E%3Cpath id='o' stroke-width='10' d='M128 619q-7 7-11 9t-16 3-43 3H25v46h557v-4q2-6 14-116t14-116v-4h-40v4q-7 49-9 57-6 37-18 62t-27 38-39 21-46 9-57 2h-88q-34 0-42-2t-11-10q-1-2-1-131V363h71q16 0 24 1t22 3 23 6 17 12q18 18 21 74v21h40V200h-40v21q-3 55-21 75-8 7-18 11t-23 6-21 3-24 1-19 0h-52V189l1-128q7-7 12-9t25-4 63-2h27V0h-12q-24 3-166 3Q51 3 36 0H25v46h33q42 1 51 3t19 12v558Z'/%3E%3Cpath id='p' stroke-width='10' d='M41 46h14q39 0 47 14v62q0 17 1 39t0 42v66q0 35-1 59v23q-3 19-14 25t-45 9H25v23q0 23 2 23l10 1q10 1 28 2t37 2q17 1 36 2t29 3 11 1h3v-40q0-38 1-38t5 5 12 15 19 18 29 19 38 16q20 5 51 5 15 0 28-2t23-6 19-8 15-9 11-11 9-11 7-11 4-10 3-8l2-5 3 4 6 8q3 4 9 11t13 13 15 13 20 12 23 10 26 7 31 3q126 0 137-113 1-7 1-139v-86q0-38 2-45t11-10q21-3 49-3h16V0h-8l-23 1q-24 1-51 1t-38 1Q596 3 587 0h-8v46h16q61 0 61 16 1 2 1 138-1 135-2 143-6 28-20 42t-24 17-26 2q-45 0-79-34-27-27-34-55t-8-83V108q0-30 1-40t3-13 9-6q21-3 49-3h16V0h-8l-24 1q-23 1-50 1t-38 1Q319 3 310 0h-8v46h16q61 0 61 16 1 2 1 138-1 135-2 143-6 28-20 42t-24 17-26 2q-45 0-79-34-27-27-34-55t-8-83V108q0-30 1-40t3-13 9-6q21-3 49-3h16V0h-8l-23 1q-24 1-51 1t-38 1Q42 3 33 0h-8v46h16Z'/%3E%3Cpath id='f' stroke-width='10' d='M674 636q8 0 14-6t6-15-7-14q-1-1-270-129L151 346l248-118Q687 92 691 87q3-6 3-11 0-18-18-20h-6L382 192Q92 329 90 331q-7 5-7 17 1 11 13 17 8 4 286 135t283 134q4 2 9 2ZM84-118q0 10 15 20h579q16-6 16-20 0-12-15-20H98q-14 7-14 20Z'/%3E%3Cpath id='j' stroke-width='10' d='M42 263q2 7 6 82t5 78v8h340q6-6 6-16 0-12-1-13l-17-24q-17-23-50-69t-66-89L134 41l48-1h24q48 0 77 6t48 31q21 28 28 108l2 16q0 1 20 1h20v-6q0-1-8-93t-9-97V0H209L34 1l-3 2q-3 5-3 14 0 13 1 14t131 179 134 184h-58q-67-1-84-6-25-6-39-21-24-23-31-103v-9H42v8Z'/%3E%3Cpath id='k' stroke-width='10' d='M84 237v13l14 20h581q15-8 15-20t-15-20H98q-14 7-14 20Z'/%3E%3Cpath id='g' stroke-width='10' d='M246-949v2399h62V-887h263v-62H246Z'/%3E%3Cpath id='r' stroke-width='10' d='M274-887v2337h62V-949H11v62h263Z'/%3E%3C/defs%3E%3C/svg%3E"></p> <p>The driver calculates the right-hand side and passes it into the shader.</p> <p>One last problem: what if a buffer is too small to load <em>anything</em>? Clamping won’t save us – the code would clamp to a negative index. In that case, the attribute is entirely invalid, so we swap the application’s buffer for a small buffer of zeroes. Since we gave each attribute its own base address, this determination is per-attribute. Then clamping the index to zero correctly loads zeroes.</p> <p>Putting it together, a little driver math gives us robust buffers at the cost of one <code>umin</code> instruction.</p> <hr> <p>In addition to buffer robustness, we need image robustness. Like its buffer counterpart, image robustness requires that out-of-bounds image loads return zero. That formalizes a guarantee that reasonable hardware already makes.</p> <p>…But it would be no fun if our hardware was reasonable.</p> <p>Running the conformance tests for image robustness, there is a single test failure affecting “mipmapping”.</p> <p>For background, mipmapped images contain multiple “levels of detail”. The base level is the original image; each successive level is the previous level downscaled. When rendering, the hardware selects the level closest to matching the on-screen size, improving efficiency and visual quality.</p> <p>With robustness, the specifications all agree that image loads return…</p> <ul> <li>Zero if the X- or Y-coordinate is out-of-bounds</li> <li>Zero if the level is out-of-bounds</li> </ul> <p>Meanwhile, image loads on the M1 GPU return…</p> <ul> <li>Zero if the X- or Y-coordinate is out-of-bounds</li> <li>Values from the last level if the level is out-of-bounds</li> </ul> <p>Uh-oh. Rather than returning zero for out-of-bounds levels, the hardware clamps the level and returns nonzero values. It’s a mystery why. The vendor does not document their hardware publicly, forcing us to rely on reverse engineering to build drivers. Without documentation, we don’t know if this behaviour is intentional or a hardware bug. Either way, we need a workaround to pass conformance.</p> <p>The obvious workaround is to never load from an invalid level:</p> <div><pre><code><span><span>if</span> <span>(</span>level <span>&lt;=</span> levels<span>)</span> <span>{</span></span>
<span>    <span>return</span> <span>imageLoad</span><span>(</span>x, y, level<span>);</span></span>
<span><span>}</span> <span>else</span> <span>{</span></span>
<span>    <span>return</span> <span>0</span><span>;</span></span>
<span><span>}</span></span></code></pre></div> <p>That involves branching, which is inefficient. Loading an out-of-bounds level doesn’t crash, so we can speculatively load and then use a compare-and-select operation instead of branching:</p> <div><pre><code><span><span>vec4</span> data <span>=</span> <span>imageLoad</span><span>(</span>x, y, level<span>);</span></span>
<span></span>
<span><span>return</span> <span>(</span>level <span>&lt;=</span> levels<span>)</span> <span>?</span> data <span>:</span> <span>0</span><span>;</span></span></code></pre></div> <p>This workaround is okay, but it could be improved. While the M1 GPU has combined compare-and-select instructions, the instruction set is <em>scalar</em>. Each thread processes one value at a time, not a vector of multiple values. However, image loads return a vector of four components (red, green, blue, alpha). While the pseudo-code looks efficient, the resulting assembly is not:</p> <div><pre><code><span><span>image_load</span> R, x, y, level</span>
<span><span>ulesel</span> R[<span>0</span>], level, levels, R[<span>0</span>], <span>0</span></span>
<span><span>ulesel</span> R[<span>1</span>], level, levels, R[<span>1</span>], <span>0</span></span>
<span><span>ulesel</span> R[<span>2</span>], level, levels, R[<span>2</span>], <span>0</span></span>
<span><span>ulesel</span> R[<span>3</span>], level, levels, R[<span>3</span>], <span>0</span></span></code></pre></div> <p>Fortunately, the vendor driver has a trick. We know the hardware returns zero if either X or Y is out-of-bounds, so we can <em>force</em> a zero output by <em>setting</em> X or Y out-of-bounds. As the maximum image size is 16384 pixels wide, any X greater than 16384 is out-of-bounds. That justifies an alternate workaround:</p> <div><pre><code><span><span>bool</span> valid <span>=</span> <span>(</span>level <span>&lt;=</span> levels<span>);</span></span>
<span><span>int</span> x_ <span>=</span> valid <span>?</span> x <span>:</span> <span>20000</span><span>;</span></span>
<span></span>
<span><span>return</span> <span>imageLoad</span><span>(</span>x_, y, level<span>);</span></span></code></pre></div> <p>Why is this better? We only change a single scalar, not a whole vector, compiling to compact scalar assembly:</p> <div><pre><code><span><span>ulesel</span> x_, level, levels, x, <span>#</span><span>20000</span></span>
<span><span>image_load</span> R, x_, y, level</span></code></pre></div> <p>If we preload the constant to a uniform register, the workaround is a single instruction. That’s optimal – and it passes conformance.</p> <hr> <p><em>Blender <a href="https://download.blender.org/demo/eevee/wanderer/wanderer.blend">“Wanderer”</a> demo by <a href="https://www.artstation.com/dbystedt">Daniel Bystedt</a>, licensed CC BY-SA.</em></p> <p><a href="https://rosenzweig.io/">Back to home</a></p> </div>]]></description>
        </item>
        <item>
            <title><![CDATA[Only real people can patent inventions – not AI – US Government says (178 pts)]]></title>
            <link>https://www.cnn.com/2024/02/14/tech/billions-in-ai-patents-get-new-regulations/index.html</link>
            <guid>39370681</guid>
            <pubDate>Wed, 14 Feb 2024 15:14:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnn.com/2024/02/14/tech/billions-in-ai-patents-get-new-regulations/index.html">https://www.cnn.com/2024/02/14/tech/billions-in-ai-patents-get-new-regulations/index.html</a>, See on <a href="https://news.ycombinator.com/item?id=39370681">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-editable="content" itemprop="articleBody" data-reorderable="content">
                    <p><cite>
      <span data-editable="location"></span>
      <span data-editable="source">CNN</span>
        &nbsp;—&nbsp;
    </cite>
</p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clskox92m0027knpc3sdueh25@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Artificial intelligence promises to supercharge scientific research and entrepreneurial innovation, helping researchers and inventors make new discoveries and creations.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clskoyej6000n3b5wrwmlm496@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            But how will patent protections apply to inventions made with the help of AI tools, particularly generative AI?
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clskoxkz800023b5wx4p50iy7@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            For the first time, the US government has provided an answer, one that will shape how everyone from large businesses to home tinkerers alike can apply for intellectual property protections.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clskoxkz800033b5waf0szdj8@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            The decision could influence the future of billions of dollars in investments and subtly guide how artificial intelligence is marketed and used.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clskoxkz800043b5wmn1q8cqy@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            On Tuesday, the US Patent and Trademark Office (USPTO) said that to obtain a patent, a real person must have made a “significant contribution” to the invention and that only a human being can be named as an inventor on a patent.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clskoxkz800053b5wgvqshzfh@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            The official guidance <a href="https://www.federalregister.gov/documents/2024/02/13/2024-02623/inventorship-guidance-for-ai-assisted-inventions" target="_blank">published this week</a> provides a boost to innovators by reassuring them that their inventions involving AI can be patented, while continuing to enshrine human creativity and ingenuity by establishing basic expectations about how AI could make or break a patent application.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clskoxkz800063b5wm5cclk70@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            The guidelines reflect the Biden administration’s swift moves to get ahead of artificial intelligence issues. In a sweeping <a href="https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/" target="_blank">executive order</a> last fall, the White House had directed the USPTO to issue its inventorship guidelines by the end of February.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clskoxkz800073b5wmfnc8avm@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Precisely what constitutes a “significant contribution” is a little bit fuzzy and case-specific, and much of how the guidelines work will necessarily be figured out in real-time as they are applied and, perhaps in some situations, debated in court.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clskoxkz800083b5wkfpk9739@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            “The challenge will be in implementing the guidance,” said Jamie Nafziger, an attorney at the law firm Dorsey &amp; Whitney. “How sophisticated of a prompt will be required for a given invention? In connection with training an AI system, what level of planning will be required?&nbsp;Patent examiners will surely have some interesting challenges ahead.”
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clskoxkz800093b5wol3fcbps@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Still, the overall picture the USPTO has painted is one where real people continue to sit at the center of the US patent system, in what experts describe as a logical extension of the status quo.
    </p>

  

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clskoxkz8000a3b5wwzruw5al@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            The USPTO has <a href="https://www.uspto.gov/sites/default/files/documents/ai-inventorship-guidance-mechanical.pdf" target="_blank">provided</a> some hypothetical <a href="https://www.uspto.gov/sites/default/files/documents/ai-inventorship-guidance-chemical.pdf" target="_blank">examples</a> of ways that its guidelines could work. For instance, an inventor who simply asks an AI chatbot to design a critical part for a remote-control car would not be eligible for a patent on the car, because he or she didn’t make enough of a contribution to the car’s invention. It was the AI that did the hard part, not the human.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clskoxkz8000b3b5wc1l0l7tp@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            “A natural person who only presents a problem to an AI system may not be a proper inventor” of something, the USPTO <a href="https://www.uspto.gov/sites/default/files/documents/ai-inventorship-guidance-mechanical.pdf" target="_blank">said</a>. “However, a significant contribution could be shown by the way the person constructs the prompt in view of a specific problem to elicit a particular solution from the AI system.”
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clskoxkz9000c3b5wq6habudr@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            If an inventor could show the work he or she did to get the AI chatbot to produce a specific design that enabled the remote-control car to function, then that could open the door to a patent, according to the USPTO.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clskoxkz9000d3b5w5t4mrvnb@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            The USPTO guidance builds on existing case law. A federal appeals court already held last year, in a case known as <a href="https://cafc.uscourts.gov/opinions-orders/21-2347.OPINION.8-5-2022_1988142.pdf" target="_blank"><em>Thaler v. Vidal</em></a>,  that only actual people can be listed as inventors on US patents, effectively ruling out the possibility for AI to be named as an inventor or co-inventor.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clskoxkz9000e3b5wbrvmlw67@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            In that case, the USPTO had rejected the patent applications of an inventor who had given his AI system sole credit for the inventions.
    </p>

<div data-image-variation="image" data-breakpoints="{&quot;image--eq-extra-small&quot;: 115, &quot;image--eq-small&quot;: 300}" data-uri="cms.cnn.com/_components/image/instances/clslxupqq00003b6hkbrvot1l@published" data-name="GettyImages-483223701.jpg" data-component-name="image" data-observe-resizes="" data-original-ratio="0.6665" data-original-height="1333" data-original-width="2000" data-url="https://media.cnn.com/api/v1/images/stellar/prod/gettyimages-483223701.jpg?c=original" data-editable="settings">
       <picture><source height="1333" width="2000" media="(min-width: 1280px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/gettyimages-483223701.jpg?q=w_1110,c_fill/f_webp" type="image/webp"><source height="1333" width="2000" media="(min-width: 960px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/gettyimages-483223701.jpg?q=w_1015,c_fill/f_webp" type="image/webp"><source height="1333" width="2000" media="(min-width: 480px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/gettyimages-483223701.jpg?q=w_1160,c_fill/f_webp" type="image/webp"><source height="1333" width="2000" media="(max-width: 479px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/gettyimages-483223701.jpg?q=w_680,c_fill/f_webp" type="image/webp"><img src="https://media.cnn.com/api/v1/images/stellar/prod/gettyimages-483223701.jpg?q=w_1110,c_fill" alt="A man walks through the public search facility at the U.S. Patent and Trademark Office (USPTO) headquarters in Alexandria, Virginia, U.S., on Friday, April 4, 2014." onload="this.classList.remove('image__dam-img--loading')" onerror="imageLoadError(this)" height="1333" width="2000" loading="lazy"></picture>
    </div>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clskoxkz9000f3b5w8578l5bg@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            The&nbsp;inventorship guidelines will help everyone understand the boundaries of patent protections as AI is increasingly used in the inventive process. That may resolve some of the uncertainties that could otherwise slow the development and use of AI, said Randy McCarthy, an attorney at the law firm Hall Estill.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clskoxkz9000g3b5wubu01697@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            It’s also consistent with how the US Copyright Office is approaching copyright protections in relation to AI, McCarthy added.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clskoxkz9000h3b5wbhu8qavp@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            “Some sort of human agency is required, or no protection is available,” he said. “A practical result is that, when creating a new design, artwork, invention, novel, or even computer code, a human can use an AI-based system to assist in the creation of this content, but must make sure that they are sufficiently involved in the process.”
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clskoxkz9000i3b5wdzn1fceo@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            At the same time, the USPTO guidelines don’t require inventors to disclose the use of AI, and some worry it could encourage so-called patent trolls to apply for broad patents that don’t lead to any actual creations but serve as the&nbsp;foundation for bogus patent lawsuits.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clskoxkz9000j3b5wjp1711md@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            “The economy already is harmed by a surplus of low-quality patents which leads to unproductive litigation, rent-seeking and transfers of wealth from productive businesses to those who are experts at navigating the legal system,” said John Bergmayer, legal director at the consumer advocacy group Public Knowledge.&nbsp;“My worry would be that AI-assisted “inventions” [where the involvement of AI might be concealed] or just AI-assisted patent applications supercharges this.”
    </p>

                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Your AI Girlfriend Is a Data-Harvesting Horror Show (131 pts)]]></title>
            <link>https://gizmodo.com/your-ai-girlfriend-is-a-data-harvesting-horror-show-1851253284</link>
            <guid>39370235</guid>
            <pubDate>Wed, 14 Feb 2024 14:38:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gizmodo.com/your-ai-girlfriend-is-a-data-harvesting-horror-show-1851253284">https://gizmodo.com/your-ai-girlfriend-is-a-data-harvesting-horror-show-1851253284</a>, See on <a href="https://news.ycombinator.com/item?id=39370235">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Lonely on Valentine’s Day? AI can help. At least, that’s what a number of companies hawking “romantic” chatbots will tell you. But as your robot love story unfolds, there’s a tradeoff you may not realize you’re making. According to a new study from Mozilla’s *Privacy Not Included project, <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;Internal link&quot;,&quot;https://gizmodo.com/sam-altman-says-chatgpt-can-t-be-your-girlfriend-1851181240&quot;,{&quot;metric25&quot;:1}]]" href="https://gizmodo.com/sam-altman-says-chatgpt-can-t-be-your-girlfriend-1851181240">AI girlfriends and boyfriends</a></span> harvest shockingly personal information, and almost all of them sell or share the data they collect. </p><div data-video-id="196019" data-monetizable="true" data-position="sidebar" data-video-title="Like It or Not, Your Doctor Will Use AI | AI Unlocked" data-video-blog-id="4" data-video-network="gizmodo" data-video-duration="209" data-playlist="196019,196111,195635" data-current="196019"><div><p>Like It or Not, Your Doctor Will Use AI | AI Unlocked</p></div><video disablepictureinpicture="" muted="" playsinline="" width="100%" height="100%" crossorigin="anonymous" preload="none"><source data-src="https://vid.kinja.com/prod/196019/196019_240p.mp4" label="240p" type="video/mp4"><source data-src="https://vid.kinja.com/prod/196019/196019_480p.mp4" label="480p" type="video/mp4"><source data-src="https://vid.kinja.com/prod/196019/196019_720p.mp4" label="720p" type="video/mp4"><source data-src="https://vid.kinja.com/prod/196019/196019_1080p.mp4" label="1080p" type="video/mp4"><track kind="captions" label="English" src="https://kinja.com/api/videoupload/caption/21541.vtt" srclang="en"></video><div><ul><li data-label="">Off</li><li data-label="English">English</li></ul></div></div><p>“To be perfectly blunt, AI girlfriends and boyfriends are not your friends,” said Misha Rykov, a Mozilla Researcher, in a press statement. “Although they are marketed as something that will enhance your mental health and well-being, they specialize in delivering dependency, loneliness, and toxicity, all while prying as much data as possible from you.”</p><p>Mozilla dug into <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://foundation.mozilla.org/en/privacynotincluded/eva-ai-chat-bot-soulmate/&quot;,{&quot;metric25&quot;:1}]]" href="https://foundation.mozilla.org/en/privacynotincluded/eva-ai-chat-bot-soulmate/" target="_blank" rel="noopener noreferrer">11 different AI romance chatbots</a></span>, including popular apps such as Replika, Chai, Romantic AI, EVA AI Chat Bot &amp; Soulmate, and CrushOn.AI. Every single one earned the Privacy Not Included label, putting these chatbots among the worst categories of products Mozilla has ever reviewed. The apps mentioned in this story didn’t immediately respond to requests for comment.</p><p>You’ve heard stories about data problems before, but according to Mozilla, AI girlfriends violate your privacy in “disturbing new ways.” For example, CrushOn.AI collects details including information about sexual health, use of medication, and gender-affirming care. 90% of the apps may sell or share user data for targeted ads and other purposes, and more than half won’t let you delete the data they collect. Security was also a problem. Only one app, Genesia AI Friend &amp; Partner, met Mozilla’s minimum security standards. </p><p>One of the more striking findings came when Mozilla counted the trackers in these apps, little bits of code that collect data and share them with other companies for advertising and other purposes. Mozilla found the AI girlfriend apps used an average of 2,663 trackers per minute, though that number was driven up by Romantic AI, which called a whopping 24,354 trackers in just one minute of using the app.</p><p>The privacy mess is even more troubling because the apps actively encourage you to share details that are far more personal than the kind of thing you might enter into a typical app. EVA AI Chat Bot &amp; Soulmate pushes users to “share all your secrets and desires,” and specifically asks for photos and voice recordings. It’s worth noting that EVA was the only chatbot that didn’t get dinged for how it uses that data, though the app did have security issues. </p><p>Data issues aside, the apps also made some questionable claims about what they’re good for. EVA AI Chat Bot &amp; Soulmate bills itself as “a provider of software and content developed to improve your mood and well-being.” Romantic AI says it’s “here to maintain your MENTAL HEALTH.” When you read the company’s terms and services though, they go out of their way to distance themselves from their own claims. Romantic AI’s policies, for example, say it is “neither a provider of healthcare or medical Service nor providing medical care, mental health Service, or other professional Service.”</p><p>That’s probably important legal ground to cover, given these app’s history. Replika reportedly encouraged a man’s attempt to <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;Internal link&quot;,&quot;https://gizmodo.com/man-sentenced-ai-girlfriend-assassinate-queen-1850904625&quot;,{&quot;metric25&quot;:1}]]" href="https://gizmodo.com/man-sentenced-ai-girlfriend-assassinate-queen-1850904625">assassinate the Queen of England</a></span>. A Chai chatbot allegedly <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.vice.com/en/article/pkadgm/man-dies-by-suicide-after-talking-with-ai-chatbot-widow-says&quot;,{&quot;metric25&quot;:1}]]" href="https://www.vice.com/en/article/pkadgm/man-dies-by-suicide-after-talking-with-ai-chatbot-widow-says" target="_blank" rel="noopener noreferrer">encouraged a user to commit suicide</a></span>.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tai chi reduces blood pressure better than aerobic exercise (124 pts)]]></title>
            <link>https://www.npr.org/sections/health-shots/2024/02/14/1231232197/tai-chi-aerobics-exercise-blood-pressure-hypertension-mindfulness</link>
            <guid>39370173</guid>
            <pubDate>Wed, 14 Feb 2024 14:32:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.npr.org/sections/health-shots/2024/02/14/1231232197/tai-chi-aerobics-exercise-blood-pressure-hypertension-mindfulness">https://www.npr.org/sections/health-shots/2024/02/14/1231232197/tai-chi-aerobics-exercise-blood-pressure-hypertension-mindfulness</a>, See on <a href="https://news.ycombinator.com/item?id=39370173">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="primaryaudio">
      <article id="res1231438499" aria-label="audio-module"><div>
      <h4>Tai chi reduces blood pressure better than aerobic exercise, study finds</h4>
   

   
    
</div>
</article>
</div><div id="storytext">
      <div id="res1231265260">
            <div data-crop-type="">
        <picture>
            <source srcset="https://media.npr.org/assets/img/2024/02/13/gettyimages-603710743_custom-cfb8d7460f79fc25589ec91e0037febfac2c87c9-s400-c85.webp 400w,
https://media.npr.org/assets/img/2024/02/13/gettyimages-603710743_custom-cfb8d7460f79fc25589ec91e0037febfac2c87c9-s600-c85.webp 600w,
https://media.npr.org/assets/img/2024/02/13/gettyimages-603710743_custom-cfb8d7460f79fc25589ec91e0037febfac2c87c9-s800-c85.webp 800w,
https://media.npr.org/assets/img/2024/02/13/gettyimages-603710743_custom-cfb8d7460f79fc25589ec91e0037febfac2c87c9-s900-c85.webp 900w,
https://media.npr.org/assets/img/2024/02/13/gettyimages-603710743_custom-cfb8d7460f79fc25589ec91e0037febfac2c87c9-s1200-c85.webp 1200w,
https://media.npr.org/assets/img/2024/02/13/gettyimages-603710743_custom-cfb8d7460f79fc25589ec91e0037febfac2c87c9-s1600-c85.webp 1600w,
https://media.npr.org/assets/img/2024/02/13/gettyimages-603710743_custom-cfb8d7460f79fc25589ec91e0037febfac2c87c9-s1800-c85.webp 1800w" sizes="(min-width: 1300px) 763px, (min-width: 1025px) calc(100vw - 496px), (min-width: 768px) calc(100vw - 171px), calc(100vw - 30px)" type="image/webp">
            <source srcset="https://media.npr.org/assets/img/2024/02/13/gettyimages-603710743_custom-cfb8d7460f79fc25589ec91e0037febfac2c87c9-s400-c85.jpg 400w,
https://media.npr.org/assets/img/2024/02/13/gettyimages-603710743_custom-cfb8d7460f79fc25589ec91e0037febfac2c87c9-s600-c85.jpg 600w,
https://media.npr.org/assets/img/2024/02/13/gettyimages-603710743_custom-cfb8d7460f79fc25589ec91e0037febfac2c87c9-s800-c85.jpg 800w,
https://media.npr.org/assets/img/2024/02/13/gettyimages-603710743_custom-cfb8d7460f79fc25589ec91e0037febfac2c87c9-s900-c85.jpg 900w,
https://media.npr.org/assets/img/2024/02/13/gettyimages-603710743_custom-cfb8d7460f79fc25589ec91e0037febfac2c87c9-s1200-c85.jpg 1200w,
https://media.npr.org/assets/img/2024/02/13/gettyimages-603710743_custom-cfb8d7460f79fc25589ec91e0037febfac2c87c9-s1600-c85.jpg 1600w,
https://media.npr.org/assets/img/2024/02/13/gettyimages-603710743_custom-cfb8d7460f79fc25589ec91e0037febfac2c87c9-s1800-c85.jpg 1800w" sizes="(min-width: 1300px) 763px, (min-width: 1025px) calc(100vw - 496px), (min-width: 768px) calc(100vw - 171px), calc(100vw - 30px)" type="image/jpeg">
            <img src="https://media.npr.org/assets/img/2024/02/13/gettyimages-603710743_custom-cfb8d7460f79fc25589ec91e0037febfac2c87c9-s1100-c50.jpg" alt="" loading="lazy">
        </picture>
        
</div>
<div>
    <div>
        <p>
                Tai chi has many health benefits. It improves flexibility, reduces stress and can help lower blood pressure.
                <b aria-label="Image credit">
                    
                    Ruth Jenkinson/Getty Images/Science Photo Library
                    
                </b>
                <b><b>hide caption</b></b>
            </p>


            <p><b><b>toggle caption</b></b>
    </p></div>

    <p><span aria-label="Image credit">
        
        Ruth Jenkinson/Getty Images/Science Photo Library
        
    </span>
</p></div>
<div>
        <picture>
            <source data-original="https://media.npr.org/assets/img/2024/02/13/gettyimages-603710743_custom-cfb8d7460f79fc25589ec91e0037febfac2c87c9-s1200.webp" type="image/webp">
            <source data-original="https://media.npr.org/assets/img/2024/02/13/gettyimages-603710743_custom-cfb8d7460f79fc25589ec91e0037febfac2c87c9-s1200.jpg" type="image/jpeg">
            <img data-original="https://media.npr.org/assets/img/2024/02/13/gettyimages-603710743_custom-cfb8d7460f79fc25589ec91e0037febfac2c87c9-s1200.jpg" alt="" src="https://media.npr.org/assets/img/2024/02/13/gettyimages-603710743_custom-cfb8d7460f79fc25589ec91e0037febfac2c87c9-s1200.jpg">
        </picture>
    </div>
<div>
        <p>Tai chi has many health benefits. It improves flexibility, reduces stress and can help lower blood pressure.</p>
        <p><span aria-label="Image credit">
            
            Ruth Jenkinson/Getty Images/Science Photo Library
            
        </span>
    </p></div>
   </div>
   <p>Tai chi, a traditional, slow-moving form of Chinese martial art, is known to increase flexibility and improve balance. Now, new research suggests it's better than more vigorous aerobic exercises for lowering blood pressure in people with prehypertension.</p>   <p>Prehypertension is blood pressure that's higher than normal but doesn't quite reach the level of high blood pressure, or hypertension. It's considered a warning sign that heart disease may be ahead, and it raises the risk of having a heart attack.</p>   <p>The new findings,<a href="https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2814872"> published in the journal <em>JAMA Network Open</em></a>, add to a large body of research pointing to health benefits from tai chi, a wellness practice that combines slow, gentle movements and postures with mindfulness. It's often called meditation in motion.</p>   
   
   
<!-- END ID="RES1231265664" CLASS="BUCKETWRAP INTERNALLINK INSETTWOCOLUMN INSET2COL " -->
   <p>In the study, researchers in China randomly assigned 342 adults with prehypertension to one of two interventions. The average age of participants was 49. Roughly half the people participated in supervised aerobic exercise, including jogging, climbing stairs, brisk walking and cycling. The other half was trained to practice tai chi. Both groups got hourlong sessions four times a week.</p>   <p>After 12 months, those in the tai chi group saw bigger drops in their blood pressure than those in the aerobic exercise group. What's more, nearly 22% of the people who practiced tai chi saw their blood pressure fall to within normal range, compared with nearly 16% of people in the aerobic exercise group. And fewer patients in the tai chi group went on to develop hypertension than in the aerobic exercise group.</p>   <p>Previous research has found that<a href="https://pubmed.ncbi.nlm.nih.gov/30195124/"> tai chi is more effective than brisk walking</a> at lowering blood pressure, fasting blood sugar levels and perceived stress in people who have hypertension.</p>   <p>So what is it about tai chi that helps lower blood pressure? The practice tends to elicit more of a response from the parasympathetic nervous system, says<a href="https://www.nursing.arizona.edu/rpiliae"> Ruth Taylor-Piliae</a>, a professor at the University of Arizona's College of Nursing, who was not involved in the study. The <a href="https://my.clevelandclinic.org/health/body/23266-parasympathetic-nervous-system-psns">parasympathetic nervous system</a> is the network of nerves that relaxes your body after periods of stress or danger.</p>   
   <p>"It [tai chi] kind of helps to just relax everything, and I think it's that response that's working towards lowering blood pressure," says Taylor-Piliae, whose research focuses on how mind-body interventions such as tai chi can benefit older adults with cardiovascular disease. "I think it's the meditative quality of it."</p>   <p>She notes a large body of evidence has now shown the benefits of tai chi on blood pressure. The practice is appealing as a form of exercise because it is low impact and requires little space or equipment.</p>   <p>"I think the beauty of tai chi is that you don't have to have a special gym membership, you don't have to have special clothing," Taylor-Piliae says. "Once you learn tai chi, you can do it anytime, anyplace, anywhere. And it does kind of provide that calming, relaxing" effect.</p>   <p>Studies have also shown that practicing tai chi can help reduce the risk of<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10509476/"> falls, improve balance</a> and walking speed in older adults, and <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9957102/#:~:text=Several%20trials%20have%20reported%20the,24%2C25%2C26%5D.">reduce depression and anxiety</a>. </p>   <p>Evidence suggests it can also help protect against cognitive decline and even <a href="https://www.npr.org/sections/health-shots/2023/11/06/1210507968/thai-chi-word-games-cognition-mentally-sharp-meditation-motion">boost memory</a>. But you have to practice it consistently to reap the most benefit.</p>   <p>"You have to have enough 'dose' of  tai chi," Taylor-Piliae says. "You can't just do it one hour, one time<em>."</em></p>   <p><em>This story was edited by Jane Greenhalgh.</em></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[We sped up time series by 20-30x (133 pts)]]></title>
            <link>https://www.rerun.io/blog/primary-query-caching</link>
            <guid>39369853</guid>
            <pubDate>Wed, 14 Feb 2024 14:03:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.rerun.io/blog/primary-query-caching">https://www.rerun.io/blog/primary-query-caching</a>, See on <a href="https://news.ycombinator.com/item?id=39369853">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="__next"><p>This is a follow up post to the post <a href="https://www.rerun.io/blog/fast-plots">Real-time kHz time series in a multimodal visualizer</a> that dives into how we managed to achieve such huge performance gains for time series (among other things), and why it was so hard in the first place.</p>
<p><img src="https://www.rerun.io/blog/1M_series_before_v_after.png" alt="Before and after graph of time taken to draw a 1M point time series in Rerun"></p>
<p><em>Comparison of time taken to draw a time series plot in Rerun with 1M points between version 0.12 and 0.13. The numbers come from profiling on a 2021 M1 MacBook Pro.</em></p>
<h2 id="flexible-multimodal-data-is-hard-to-combine-with-fast-plots">Flexible multimodal data is hard to combine with fast plots<!-- --> <a href="#flexible-multimodal-data-is-hard-to-combine-with-fast-plots"></a></h2>
<p>Ever since the first release of Rerun, plotting larger time series has been painfully slow.
<a href="https://github.com/rerun-io/rerun/releases/tag/0.13.0">0.13</a> is the first release where we think they're actually usable.
It’s worth taking a step back to explain why making plots fast in Rerun was hard, before getting into what we did about it.
To do that, we need some more background on how Rerun, the in-memory database, works.</p>
<h3 id="rerun-as-a-multimodal-time-series-database">Rerun as a multimodal time series database<!-- --> <a href="#rerun-as-a-multimodal-time-series-database"></a></h3>
<p>One way of looking at Rerun is as an in-memory multimodal time series database with visualization on top.</p>
<ul>
<li>You can throw many kinds of data at it, from simple metrics to big multi dimensional tensors, point clouds, and text documents.</li>
<li>Data is indexed along multiple user defined timelines, and can come in out of order.</li>
<li>The Rerun data model is a temporal Entity Component System (ECS) that allows updating single components at a time.</li>
</ul>
<p>Let's look at a small example of updating a colored point cloud in parts and out of order:</p>
<p><img src="https://www.rerun.io/blog/data-model-example.png" alt="Overview of Rerun's ECS updated out of order"></p>
<p>For any given time point, the datastore needs to be able to collect the latest components of any entity, and join them against the primary component (3D positions in this case). Queries run every time Rerun renders a frame, which should be 60 times per second.</p>
<p>Getting all this to be both correct and fast took considerable effort during the first year of Rerun. The combination of all these features is what makes Rerun so versatile and easy to use.</p>
<p><iframe src="https://player.vimeo.com/video/910960113?autoplay=1&amp;loop=1&amp;autopause=0&amp;background=1&amp;muted=1&amp;ratio=1920:1080&amp;transparent=false&amp;dnt=1" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen=""></iframe></p>
<h3 id="overhead-from-flexibility-make-simple-time-series-the-worst-case">Overhead from flexibility make simple time series the worst case<!-- --> <a href="#overhead-from-flexibility-make-simple-time-series-the-worst-case"></a></h3>
<p>Flexibility comes at the cost of added overhead. That matters less for larger data, but dominates performance for small data like scalars. In Rerun, time series are created by querying the datastore for all scalars on an entity for a range of time.
Before 0.13, the worst case was therefore simple time series plots, since you'd have to pay all that overhead many times for very little data.</p>
<h2 id="speeding-up-time-series-by-a-factor-of-2030">Speeding up time series by a factor of 20-30<!-- --> <a href="#speeding-up-time-series-by-a-factor-of-2030"></a></h2>
<p>On Rerun 0.12, rendering a single frame of a 1M point time series plot takes ~600ms on a 2021 M1 MacBook Pro. On 0.13 it takes ~20ms, a 30x speedup. For smaller series the speedup tends to come closer to 20x, which is still huge. How did we get there?</p>
<h3 id="sources-of-overhead-in-time-series-plots">Sources of overhead in time series plots<!-- --> <a href="#sources-of-overhead-in-time-series-plots"></a></h3>
<p>Let’s sum up the main sources of overhead in producing data for and rendering a time series plot:</p>
<ol>
<li><strong>Bookkeeping</strong>: Keeping track of which components exist at each timestamp is relatively costly for small data.</li>
<li><strong>Data locality</strong>: For small data, the flexible data model (both in time and data type) bottoms out in a lack of data locality, which is bad for CPU cache efficiency.</li>
<li><strong>Redundant work</strong>: When plotting a moving time window, data is usually only changing at the edges of the window. Repeatedly running the full range query creates lots of redundant work.</li>
<li><strong>Rendering</strong>: For large time series, there may be more points than pixels to draw them on along the time dimension (x-axis). This leads to redundant tessellation and overdraw in the rendering pipeline.</li>
</ol>
<h3 id="why-we-didnt-just-special-case-metrics">Why we didn't just special case metrics<!-- --> <a href="#why-we-didnt-just-special-case-metrics"></a></h3>
<p>The easiest solution for speeding up time series plots would be to special case the path for metrics. A specialized code path for simple metrics would make huge gains relatively easy.</p>
<p>Unfortunately this isn’t good enough because our users need good performance for more kinds of range queries. Here is an example using time ranges to show an aggregate point cloud in a structure from motion setting:</p>
<p><iframe src="https://player.vimeo.com/video/910977084?autoplay=1&amp;loop=1&amp;autopause=0&amp;background=1&amp;muted=1&amp;ratio=1920:1080&amp;transparent=false&amp;dnt=1" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen=""></iframe></p>
<p>In addition, our motivating example for kHz plots was <a href="https://en.wikipedia.org/wiki/Inertial_measurement_unit">IMU</a> samples, which usually come as messages containing multiple values to plot. That makes special casing the single metrics less useful. For example:</p>
<pre><p><code><span>typedef</span> <span>struct</span> <span>{</span>
    <span>float</span> acc<span>[</span><span>3</span><span>]</span><span>;</span>

    <span>float</span> gyro<span>[</span><span>3</span><span>]</span><span>;</span>  <span>// &lt;- Want to plot these as time series</span>
    
    <span>unsigned</span> <span>long</span> timestamp<span>;</span>
<span>}</span> IMUSample<span>;</span>
</code></p></pre>
<p>Rerun doesn’t yet support visualizing time series from single fields of larger structs directly, but we will soon and our approach needs to support this as a first class use-case.</p>
<h3 id="caching-is-difficult-but-necessary">Caching is difficult but necessary<!-- --> <a href="#caching-is-difficult-but-necessary"></a></h3>
<blockquote>
<p>There are only two hard things in Computer Science: cache invalidation and naming things.</p>
<p>Phil Karlton</p>
</blockquote>
<p>The non-rendering sources of overhead just scream caching, but as usual the devil is in the details, in particular the details of cache invalidation. In our case, out of order insertions combined with composing multiple components over time make invalidation particularly gnarly.</p>
<h3 id="datastore-changelogs-make-invalidation-manageable">Datastore changelogs make invalidation manageable<!-- --> <a href="#datastore-changelogs-make-invalidation-manageable"></a></h3>
<p>Except for garbage collection (dropping old data to free up memory), the Rerun datastore is immutable. Data is always dropped through snapshotting so that query semantics are left unchanged. Every single change results in adding or removing rows to the store.</p>
<p>The first step we took after deciding it was time for caching was a refactor that turned every system that maintains a derived dataset in Rerun (timeline widget, view heuristics engine, etc) into a store subscriber, which listens to changelogs of added or removed rows in the datastore.</p>
<p>Cache invalidation is yet another store subscriber, and having this protocol in place is what made it manageable to deal with all the complexity.</p>
<h3 id="caches-are-built-lazily-at-query-time">Caches are built lazily at query time<!-- --> <a href="#caches-are-built-lazily-at-query-time"></a></h3>
<p>Cache invalidation only sets a dirty flag. Actually building the cache happens lazily at query time. Since Rerun uses an end to end immediate mode architecture, we query the datastore on every frame, ideally 60 times per second.</p>
<p>This acts as a natural micro-batching mechanism where we first accumulate changes while we render the current frame and then handle all these changes at the start of the next frame. Batching updates like this is great for performance.</p>
<p>Visible views query the datastore right before rendering. Building caches lazily therefore means we never spend time updating a cache that isn’t used.</p>
<h3 id="multitenancy-requires-fine-grained-locking">Multi-tenancy requires fine grained locking<!-- --> <a href="#multitenancy-requires-fine-grained-locking"></a></h3>
<p>When not on the web, each space view (draggable visualization panel) runs and queries the datastore in parallel. Many of these queries might overlap so we need to make sure to share data and cache resources appropriately.</p>
<p>Supporting this multi-tenancy requires fine grained locking on the combination of store (there are multiple), entity, set of components, and the component “point of view” (the component we join against).</p>
<h3 id="aggregating-subpixel-points-speeds-up-rendering">Aggregating sub-pixel points speeds up rendering<!-- --> <a href="#aggregating-subpixel-points-speeds-up-rendering"></a></h3>
<p>There are only so many pixels available to draw on along the x-axis. For large time series, that means you need to aggregate points that would show up on the same x-axis tick to avoid overdraw and redundant tessellation in the render pipeline.</p>
<p><iframe src="https://player.vimeo.com/video/910983296?autoplay=1&amp;loop=1&amp;autopause=0&amp;background=1&amp;muted=1&amp;ratio=1920:1080&amp;transparent=false&amp;dnt=1" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen=""></iframe></p>
<p>We compute these aggregations on every frame and let users choose between a set of basic options.</p>
<h3 id="a-caveat-on-performance-for-out-of-order-logs">A caveat on performance for out of order logs<!-- --> <a href="#a-caveat-on-performance-for-out-of-order-logs"></a></h3>
<p>The speedups added in 0.13 slow down ingestion speed for out of order logs.
In practice this only matters for scalars logged out of order at high frequency,
but it does mean that live time series plots are slow in this case.
An update that fixes this is planned for 0.13.1.
Follow the progress <a href="https://github.com/rerun-io/rerun/issues/4810">here</a>.</p>
<h2 id="huge-wins-already-but-there-is-more-to-be-had">Huge wins already but there is more to be had<!-- --> <a href="#huge-wins-already-but-there-is-more-to-be-had"></a></h2>
<p>Adding a caching layer to the Rerun datastore has taken lots of effort over the last months, but the performance gains are clearly worth the added complexity.</p>
<p>There are still lots of gains to be had by adding secondary caches on top, for scalars and other data. For example, slowly changing 3D geometry could be cached on the GPU to avoid redundant CPU -&gt; GPU transfers, which are currently the performance bottleneck for point clouds.</p>
<p>Join us on <a href="https://github.com/rerun-io/rerun">Github</a> or <a href="https://discord.gg/PXtCgFBSmH">Discord</a>
and let us know what if these performance improvement made a difference for you,
and what areas you'd love to see us speed up next.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[European Court of Human Rights bans weakening of secure end-to-endencryption (1274 pts)]]></title>
            <link>https://www.eureporter.co/world/human-rights-category/european-court-of-human-rights-echr/2024/02/14/european-court-of-human-rights-bans-weakening-of-secure-end-to-endencryption-the-end-of-eus-chat-control-csar-mass-surveillance-plans/</link>
            <guid>39369653</guid>
            <pubDate>Wed, 14 Feb 2024 13:44:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.eureporter.co/world/human-rights-category/european-court-of-human-rights-echr/2024/02/14/european-court-of-human-rights-bans-weakening-of-secure-end-to-endencryption-the-end-of-eus-chat-control-csar-mass-surveillance-plans/">https://www.eureporter.co/world/human-rights-category/european-court-of-human-rights-echr/2024/02/14/european-court-of-human-rights-bans-weakening-of-secure-end-to-endencryption-the-end-of-eus-chat-control-csar-mass-surveillance-plans/</a>, See on <a href="https://news.ycombinator.com/item?id=39369653">Hacker News</a></p>
Couldn't get https://www.eureporter.co/world/human-rights-category/european-court-of-human-rights-echr/2024/02/14/european-court-of-human-rights-bans-weakening-of-secure-end-to-endencryption-the-end-of-eus-chat-control-csar-mass-surveillance-plans/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[What made Earth a giant snowball 700M years ago? Scientists have an answer (142 pts)]]></title>
            <link>https://www.sydney.edu.au/news-opinion/news/2024/02/08/geoscientists-discover-what-turned-snowball-earth-sturtian-ice-age-earthbyte.html</link>
            <guid>39369040</guid>
            <pubDate>Wed, 14 Feb 2024 12:24:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.sydney.edu.au/news-opinion/news/2024/02/08/geoscientists-discover-what-turned-snowball-earth-sturtian-ice-age-earthbyte.html">https://www.sydney.edu.au/news-opinion/news/2024/02/08/geoscientists-discover-what-turned-snowball-earth-sturtian-ice-age-earthbyte.html</a>, See on <a href="https://news.ycombinator.com/item?id=39369040">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		<div><figure>

	
		

			<img src="https://www.sydney.edu.au/content/dam/corporate/images/news-and-opinion/news/2024/february/dr-adriana-dutkiewicz-geosciences-in-the-flinders-ranges,-south-australia.jpg/_jcr_content/renditions/cq5dam.web.1280.1280.jpeg" alt="Research lead author Dr Adriana Dutkiewicz pointing to a thick bed of glacial deposits.  ">

			
			
		
	

	<figcaption>
		<p> Deposits from the Sturtian Glaciation 717­–664 million years ago in the northern Flinders Ranges, Australia. Research lead author Dr Adriana Dutkiewicz pointing to a thick bed of glacial deposits. &nbsp;<em>Photo: Professor Dietmar Müller/University of Sydney</em></p>

	</figcaption>
</figure>
</div>
		
			<p>Australian geologists have used plate tectonic modelling to determine what most likely caused an extreme ice-age climate in Earth’s history, more than 700 million years ago.</p>
<p>The study, published in<em> </em><a href="https://pubs.geoscienceworld.org/geology"><em>Geology</em></a>, helps our understanding of the functioning of the Earth's built-in thermostat that prevents the Earth from getting stuck in overheating mode. It also shows how sensitive global climate is to atmospheric carbon concentration.</p>
<p>“Imagine the Earth almost completely frozen over,” said the study’s lead author, ARC Future Fellow <a href="https://sydney.edu.au/science/people/adriana.dutkiewicz.php">Dr Adriana Dutkiewicz</a>. “That’s just what happened about 700 million years ago; the planet was blanketed in ice from poles to equator and temperatures plunged. However, just what caused this has been an open question.</p>
<p>“We now think we have cracked the mystery: historically low volcanic carbon dioxide emissions, aided by weathering of a large pile of volcanic rocks in what is now Canada; a process that absorbs atmospheric carbon dioxide.”</p>
<p>The project was inspired by the glacial debris left by the ancient glaciation from this period that can be spectacularly observed in the Flinders Ranges in South Australia.</p>
<p>A recent geological field trip to the Ranges, led by co-author <a href="https://www.adelaide.edu.au/directory/alan.collins">Professor Alan Collins</a> from the University of Adelaide, prompted the team to use the University of Sydney <a href="https://www.earthbyte.org/">EarthByte</a> computer models to investigate the cause and the exceptionally long duration of this ice age.</p>
<p>The extended ice age, also called the Sturtian glaciation after the 19th century European colonial explorer of central Australia, Charles Sturt, stretched from 717 to 660 million years ago, a period well before the dinosaurs and complex plant life on land existed.</p>

		
		
	</div><div>
		
		
			<p>Dr Dutkiewicz said: “Various causes have been proposed for the trigger and the end of this extreme ice age, but the most mysterious aspect is why it lasted for 57 million years – a time span hard for us humans to imagine.”</p>
<p>The team went back to a plate tectonic model that shows the evolution of continents and ocean basins at a time after the breakup of the ancient supercontinent Rodina. They connected it to a computer model that calculates CO2&nbsp;degassing of underwater volcanoes along mid-ocean ridges – the sites where plates diverge and new ocean crust is born.</p>
<p>They soon realised that the start of the Sturtian ice age precisely correlates with an all-time low in volcanic CO2&nbsp;emissions. In addition, the CO2&nbsp;outflux remained relatively low for the entire duration of the ice age.</p>
<p>Dr Dutkiewicz said: “At this time, there were no multicellular animals or land&nbsp;plants on Earth. The greenhouse gas concentration of the atmosphere was almost entirely dictated by CO2&nbsp;outgassing from volcanoes and by silicate rock weathering processes, which consume CO2.”</p>

		
		
	</div><div>
		<div><figure>

	
		

			<img src="https://www.sydney.edu.au/content/dam/corporate/images/news-and-opinion/news/2024/february/dietmar-m%C3%BCller-pointing-to-carbonates-overlying-sturt-formation-flinders-ranges-photo-by-adriana-dutkiewicz.jpg/_jcr_content/renditions/cq5dam.web.1280.1280.jpeg" alt="Professor Dietmar Müller points to carbonates overlying glacial deposits in the Flinders Ranges.">

			
			
		
	

	<figcaption>
		<p>Professor Dietmar Müller points to carbonates overlying glacial deposits in the Flinders Ranges. <em>Photo: Dr Adriana Dutkiewicz</em></p>

	</figcaption>
</figure>
</div>
		
			<p>Co-author&nbsp;<a href="https://www.sydney.edu.au/science/about/our-people/academic-staff/dietmar-muller.html">Professor Dietmar Müller</a>&nbsp;from the University of Sydney said: "Geology ruled climate at this time. We think the Sturtian ice age kicked in due to a double whammy: a plate tectonic reorganisation brought volcanic degassing to a minimum, while simultaneously a continental volcanic province in Canada started eroding away, consuming atmospheric CO2.</p>
<p>“The result was that atmospheric CO2&nbsp;fell to a level where glaciation kicks in – which we estimate to be below 200 parts per million, less than half today’s level.”</p>
<p>The team's work raises intriguing questions about Earth's long-term future.&nbsp; A&nbsp;<a href="https://www.nature.com/articles/s41561-023-01259-3">recent theory proposed</a>&nbsp;that over the next 250 million years, Earth would evolve towards Pangea Ultima, a supercontinent so hot that mammals might become extinct.</p>
<p>However, the Earth is also currently on a trajectory of lower volcanic CO2&nbsp;emissions, as continental collisions increase and the plates slow down. So, perhaps Pangea Ultima will turn into a snowball again.</p>
<p>Dr Dutkiewicz said: “Whatever the future holds, it is important to note that geological climate change, of the type studied here, happens extremely slowly.&nbsp;<a href="https://climate.nasa.gov/evidence/">According to NASA</a>, human-induced climate change is happening at a pace 10 times faster than we have seen before.”</p>
<h2>Research</h2>
<p>‘Duration of Sturtian “Snowball Earth” glaciation linked to exceptionally low mid-ocean ridge outgassing’, Dutkiewicz, A. et al (<em>Geology</em>, 2024). DOI: 10.1130/G51669.1</p>
<h2>EarthByte Group<br>
</h2>
<p>This work was enabled by the&nbsp;<a href="https://www.gplates.org/">GPlates</a>&nbsp;plate tectonic software, developed by the&nbsp;<a href="https://www.earthbyte.org/">EarthByte Group</a>&nbsp;at the University of Sydney, which has been the basis of a slew of discoveries over the past decade, contributing significant knowledge to how geology is a central long-term driver of climate and biodiversity. GPlates development is supported by the AuScope National Collaborative Research Infrastructure System (NCRIS) program.</p>
<h2>Declaration</h2>
<p>The authors declare no competing interests. Research was in part funded by the Australian Research Council.</p>

		
		
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Xonsh: Python-powered, cross-platform, Unix-gazing shell (116 pts)]]></title>
            <link>https://github.com/xonsh/xonsh</link>
            <guid>39368586</guid>
            <pubDate>Wed, 14 Feb 2024 11:14:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/xonsh/xonsh">https://github.com/xonsh/xonsh</a>, See on <a href="https://news.ycombinator.com/item?id=39368586">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><h2 tabindex="-1" dir="auto">xonsh</h2>
<p dir="auto"><strong>xonsh</strong> is a Python-powered, cross-platform, Unix-gazing shell language and command prompt.</p>
<p dir="auto">The language is a superset of Python 3.6+ with additional shell primitives.
xonsh (pronounced <em>conch</em>) is meant for the daily use of experts and novices alike.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/xonsh/xonsh/main/docs/_static/what_is_xonsh.png"><img alt="What is xonsh?" src="https://raw.githubusercontent.com/xonsh/xonsh/main/docs/_static/what_is_xonsh.png"></a></p>
<p dir="auto">If you like xonsh, ⭐ the repo, <a href="https://twitter.com/intent/tweet?text=xonsh%20is%20a%20Python-powered,%20cross-platform,%20Unix-gazing%20shell%20language%20and%20command%20prompt.&amp;url=https://github.com/xonsh/xonsh" rel="nofollow">write a tweet</a> and stay tuned by watching releases.</p>
<a href="https://gitter.im/xonsh/xonsh?utm_source=badge&amp;utm_medium=badge&amp;utm_campaign=pr-badge&amp;utm_content=badge" rel="nofollow"><img alt="Join the chat at https://gitter.im/xonsh/xonsh" src="https://camo.githubusercontent.com/b8ab3219443241e4c23062a442187e5bb3ca34f1d071237e1aeb45ffcba8713b/68747470733a2f2f6261646765732e6769747465722e696d2f786f6e73682f786f6e73682e737667" data-canonical-src="https://badges.gitter.im/xonsh/xonsh.svg">
</a>
<a href="https://travis-ci.org/xonsh/xonsh" rel="nofollow"><img alt="Travis" src="https://camo.githubusercontent.com/35732d8d096fd79dc3363946e8b4ed88f327057db06d804da2744e5f3e9e419e/68747470733a2f2f7472617669732d63692e6f72672f786f6e73682f786f6e73682e7376673f6272616e63683d6d61696e" data-canonical-src="https://travis-ci.org/xonsh/xonsh.svg?branch=main"></a>
<a href="https://ci.appveyor.com/project/xonsh/xonsh" rel="nofollow"><img alt="Appveyor" src="https://camo.githubusercontent.com/f412619487e5e015776325b40e2d063a7dbcceb5724bd73dfc9eb2d64dbb89ed/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f6769746875622f786f6e73682f786f6e73683f7376673d74727565" data-canonical-src="https://ci.appveyor.com/api/projects/status/github/xonsh/xonsh?svg=true"></a>
<a href="https://ssh.cloud.google.com/cloudshell/editor?cloudshell_git_repo=https://github.com/xonsh/xonsh.git" rel="nofollow"><img alt="Open in Google Cloud Shell" src="https://camo.githubusercontent.com/0c0c5d76144ebcd95e5a4da68c8481c98000486e066f4bf3d03eee6958863c1a/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f476f6f676c65253230436c6f75642532305368656c6c2d786f6e73682d677265656e" data-canonical-src="https://img.shields.io/badge/Google%20Cloud%20Shell-xonsh-green"></a>
<a href="https://codecov.io/github/xonsh/xonsh?branch=main" rel="nofollow"><img alt="codecov.io" src="https://camo.githubusercontent.com/09365076d9337b6df7b2cf868efa2f4069e57273962b7d90073e94743cfab142/68747470733a2f2f636f6465636f762e696f2f67682f786f6e73682f786f6e73682f6272616e63682f6d61737465722f6772617068732f62616467652e7376673f6272616e63683d6d61696e" data-canonical-src="https://codecov.io/gh/xonsh/xonsh/branch/master/graphs/badge.svg?branch=main"></a>
<a href="https://repology.org/project/xonsh/versions" rel="nofollow"><img alt="repology.org" src="https://camo.githubusercontent.com/a90f19dfec618ffe152d6678e79d0c6046d00d8a78f632d5a0c153df9a5731f1/68747470733a2f2f7265706f6c6f67792e6f72672f62616467652f74696e792d7265706f732f786f6e73682e737667" data-canonical-src="https://repology.org/badge/tiny-repos/xonsh.svg">
</a>
<a name="user-content-first-steps"></a>
<h2 tabindex="-1" dir="auto">First steps</h2>
<p dir="auto">Install xonsh from pip:</p>
<pre lang="xonshcon">python -m pip install 'xonsh[full]'
</pre>
<p dir="auto">And visit <a href="https://xon.sh/" rel="nofollow">https://xon.sh</a> for more information:</p>
<ul dir="auto">
<li><a href="https://xon.sh/contents.html#installation" rel="nofollow">Installation</a> - using packages, docker or AppImage.</li>
<li><a href="https://xon.sh/tutorial.html" rel="nofollow">Tutorial</a> - step by step introduction in xonsh.</li>
</ul>
<a name="user-content-extensions"></a>
<h2 tabindex="-1" dir="auto">Extensions</h2>
<p dir="auto">Xonsh has the certain term for extensions and additional materials - xontrib - the short version of "contribution" word.</p>
<ul dir="auto">
<li><a href="https://github.com/topics/xontrib">Xontribs on Github</a></li>
<li><a href="https://github.com/xonsh/awesome-xontribs">Awesome xontribs</a></li>
<li><a href="https://xon.sh/api/_autosummary/xontribs/xontrib.html" rel="nofollow">Core xontribs</a></li>
<li><a href="https://github.com/xonsh/xontrib-template">Create a xontrib step by step from template</a></li>
</ul>
<a name="user-content-projects-that-use-xonsh-or-compatible"></a>
<h2 tabindex="-1" dir="auto">Projects that use xonsh or compatible</h2>
<ul dir="auto">
<li><a href="https://github.com/donnemartin/gitsome">gitsome</a>: Supercharged Git/shell autocompleter with GitHub integration.</li>
<li><a href="https://github.com/xxh/xxh">xxh</a>: Using xonsh wherever you go through the SSH.</li>
<li><a href="https://regro.github.io/rever-docs/" rel="nofollow">rever</a>: Cross-platform software release tool.</li>
<li><a href="https://github.com/regro/cf-scripts">Regro autotick bot</a>: Regro Conda-Forge autoticker.</li>
</ul>
<p dir="auto">Jupyter-based interactive notebooks via <a href="https://github.com/xonsh/xontrib-jupyter">xontrib-jupyter</a>:</p>
<ul dir="auto">
<li><a href="https://jupyter.org/" rel="nofollow">jupyter and jupyterlab</a>: Interactive notebook platform.</li>
<li><a href="https://github.com/joouha/euporie">euporie</a>: Terminal based interactive computing environment.</li>
</ul>
<a name="user-content-the-xonsh-shell-community"></a>
<h2 tabindex="-1" dir="auto">The xonsh shell community</h2>
<p dir="auto">The xonsh shell is developed by a community of volunteers. There are few ways to help the xonsh shell:</p>
<ul dir="auto">
<li><a href="https://github.com/sponsors/xonsh">Become a sponsor to xonsh</a>.</li>
<li><a href="https://twitter.com/intent/tweet?text=xonsh%20is%20a%20Python-powered,%20cross-platform,%20Unix-gazing%20shell%20language%20and%20command%20prompt.&amp;url=https://github.com/xonsh/xonsh" rel="nofollow">Write a tweet</a>, post or an article to spread the good word about xonsh in the world.</li>
<li>Solve a <a href="https://github.com/xonsh/xonsh/issues?q=is%3Aissue+is%3Aopen+sort%3Areactions-%2B1-desc">popular issue</a>.</li>
<li>Solve a <a href="https://github.com/xonsh/xonsh/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22+sort%3Areactions-%2B1-desc">good first issue</a>.</li>
<li>Get the <a href="https://github.com/xonsh/xontrib-template/issues?q=is%3Aopen+is%3Aissue+label%3Aidea+sort%3Areactions-%2B1-desc">idea</a> and <a href="https://github.com/xonsh/xontrib-template#why-use-this-template">create new xontrib</a>.</li>
<li>Become xonsh core by deep diving into xonsh and improve the threading and subprocess logic.</li>
<li>Give a star to xonsh repository and to <a href="https://github.com/topics/xontrib">xontribs</a> you like.</li>
</ul>
<p dir="auto">We welcome new contributors!</p>

</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Matrix Trashfire (275 pts)]]></title>
            <link>https://blog.koehntopp.info/2024/02/13/the-matrix-trashfire.html</link>
            <guid>39368561</guid>
            <pubDate>Wed, 14 Feb 2024 11:07:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.koehntopp.info/2024/02/13/the-matrix-trashfire.html">https://blog.koehntopp.info/2024/02/13/the-matrix-trashfire.html</a>, See on <a href="https://news.ycombinator.com/item?id=39368561">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				<p>For reasons, I tried to evaluate the distributed Matrix chat and their clients.
That did not work out very well.</p>
<h2 id="onboarding-experience">
    <a href="#onboarding-experience">
	Onboarding experience
    </a>
</h2>
<p>I was told that the default Matrix chat client is called Elements, so I looked it up on the iOS App store.
Unfortunately, there are two, “Element” and “Element X.”
No explanation is given, and no preference is stated.
“Element” is categorized business, “Element X” is in “Social Networking.”
Are they not the same?
They seem to be from the same company, though.</p>
<p>
  <img src="https://blog.koehntopp.info/uploads/2024/02/element-01.jpg" alt="">
</p>


<p><em>Element and Element X in the app store. Which one to use?</em></p>
<p>Ok, let’s open the descriptions.
They are identical, except for one sentence at the start:
“Element X is the future Element.”
So it’s a beta?
Why is it not labeled as a Beta?</p>
<p>On the desktop, going to <a href="https://matrix.org/" target="_blank" rel="noopener">Matrix.org</a>

 plus two additional clicks take you to
<a href="https://matrix.org/ecosystem/clients/" target="_blank" rel="noopener">the client page</a>

, which offers</p>
<p>
  <img src="https://blog.koehntopp.info/uploads/2024/02/element-02.jpg" alt="">
</p>


<p><em>The client page offers you, among others, both clients and also states which is available on what platform.</em></p>
<p>So apparently “Element X” is beta and not yet available on all platforms. I open the macOS App Store and…</p>
<p>
  <img src="https://blog.koehntopp.info/uploads/2024/02/element-03.jpg" alt="">
</p>


<p><em>macOS does not offer Element, only Element X.</em></p>
<p>Apparently matrix.org lied to me.
Element X is available on iOS and macOS, Element is not.</p>
<p>Ok, let’s install Element X and try:</p>
<p>
  <img src="https://blog.koehntopp.info/uploads/2024/02/element-04.jpg" alt="">
</p>


<p><em>Element X wants me to sign in to matrix.org. There is no ‘sign up’ Button. There is no sign-up menu.</em></p>
<p>The client wants me to log in to matrix.org. There is no button to make an account. There is no menu to make an account.
There is zero onboarding for new users.</p>
<p>Ok, let’s go to matrix.org again, and see.</p>
<p>
  <img src="https://blog.koehntopp.info/uploads/2024/02/element-05.jpg" alt="">
</p>


<p><em>The matrix.org Website is not very helpful. But when you notice the burger menu, there is actually a “Try Matrix” button.</em></p>
<p>The matrix.org website is a very empty clean screen that is not very helpful. There is a burger menu, though,
and if you open it, you get a “Try Matrix” button.
This leads to another screen that tells you to use your organizations server instance (What organization? I’m alone!),
or install a server,
or choose a public server.
If you opt for Public Servers, you land here:</p>
<p>
  <img src="https://blog.koehntopp.info/uploads/2024/02/element-06.jpg" alt="">
</p>


<p><em>matrix.org server instances, alphabetically sorted, with little additional information.</em></p>
<p>Matrix.org is conspicuously absent from this list.
The rest I do not know anything about.</p>
<p>I can now research what server instance I want to join.
Unfortunately, I do not get information about what their country is.
I can’t see if they are subject to GDPR rules.
I don’t know if they are owned by a company or run by a single private person.
There is no indication how many users they have.</p>
<p>I can dig through their privacy policies and rules, except that some don’t provide any.</p>
<p>Scrolling down, I end up with the option to onboard to this:</p>
<p>
  <img src="https://blog.koehntopp.info/uploads/2024/02/element-07.jpg" alt="">
</p>


<p><em>Servers marked as vulnerable, unavailable and with profanity in their name.</em></p>
<p>Why in heaven or earth would anybody put unavailable or vulnerable servers into an onboarding listing?
Isn’t this supposed a “secure” messenger?</p>
<h2 id="trying-to-use-it-nontheless">
    <a href="#trying-to-use-it-nontheless">
	Trying to use it, nontheless
    </a>
</h2>
<p>I made an “isotopp” account at <a href="https://chat.tchncs.de/#/login" target="_blank" rel="noopener">tchncs.de</a>

.
The password is generated and stored in Bitwarden.
A validation mail is sent to a unique address at koehntopp.de and arrives.</p>
<p>I try to login not being validated, using Bitwarden.
The login is rejected.</p>
<p>I validate the email.
The server says I am validated.</p>
<p>I try to login, using Bitwarden.
The login is rejected.</p>
<p>
  <img src="https://blog.koehntopp.info/uploads/2024/02/element-09.jpg" alt="">
</p>


<p><em>I am trying to recover the password for the account which I just validated, using the email from the verification mail.
The account is unknown.</em></p>
<p>I click on “forgotten password”, and supply the mail adress the validation mail was sent to.
“This email address was not found.”</p>
<p>Okay, since my account does not exist, I create it again:</p>
<p>
  <img src="https://blog.koehntopp.info/uploads/2024/02/element-10.jpg" alt="">
</p>


<p><em>I recreate my account, using the same mail address. As you can see, the first registration mail still is in the account.
I take the validation URL, which is longer than 80 characters, and use it to successfully validate, again.</em></p>
<p>I create the account again, using the same parameters.
The account validation mail is sent to my address.
The old account validation mail is also still in the account.
I take the new URL, which is longer than 80 characters, and use it to successfully validate my account, again.</p>
<p>This time I accidentally left the “create account” window open.
This window is now suddenly logged in.
Turns out, you MUST NOT, UNDER ANY CIRCUMSTANCES, close the “create account” window until the account is validated,
or it is simply not created.
This is not stated anywhere.</p>
<p>To confirm the account works and the password in Bitwarden is stored successfully,
I log out and log in again.</p>
<p>I get this:</p>
<p>
  <img src="https://blog.koehntopp.info/uploads/2024/02/element-11.jpg" alt="">
</p>


<ul>
<li><strong>Unable to verify this device</strong>
It looks like you don’t have a Security Key or any other devices you can verify against.
This device will not be able to access old encrypted messages.
In order to verify your identity on this device, you’ll need to reset your verification keys.*</li>
</ul>
<p>What does that even mean?</p>
<h2 id="trying-element-x-with-my-account">
    <a href="#trying-element-x-with-my-account">
	Trying Element X with my account
    </a>
</h2>
<p>Starting Element X, it tries to onboard me to Matrix.org.
I select “Change Server”, and get a form field where it says “matrix.org”.
I am overwriting it with “chat.tchncs.de”, which supposedly is my server.
At least that is what it says in the web client.</p>
<p>
  <img src="https://blog.koehntopp.info/uploads/2024/02/element-12.jpg" alt="">
</p>


<p>That is not accepted.</p>
<p>I take the URL from the browser and paste that instead.</p>
<p>
  <img src="https://blog.koehntopp.info/uploads/2024/02/element-13.jpg" alt="">
</p>


<p>That is also not accepted, but I can learn more.
I click.</p>
<p>
  <img src="https://blog.koehntopp.info/uploads/2024/02/element-14.jpg" alt="">
</p>


<p>The what?</p>
<p>Turns out, while the Chat is running on “chat.tchncs.de”, this is not the “Identity Provider.”
That one is called “tchncs.de”.
You only learn this when you open your config menu in the web chat and look at Identifer shown there.</p>
<p>
  <img src="https://blog.koehntopp.info/uploads/2024/02/element-15.jpg" alt="">
</p>


<p>Once you enter this, Element X and the web chat get hectic.
There is a new client, and both clients want to authenticate that the new device is legit.</p>
<p>
  <img src="https://blog.koehntopp.info/uploads/2024/02/element-16.jpg" alt="">
</p>


<p>For that purpose, they display a set of Emojis, which look differently in the web client and the application,
and ask me if they are the same.
Helpful Emoji names are shown under the Emoji, and they are identical.
I simply click yes.</p>
<p>After that, both clients can see my Chat, but the Element X Client still has no access to any chat history.
That is, because the client is unverified (so is the web client).</p>
<p>When I close any client, I have to re-login, re-compare the Emojis, and all chat history is gone.</p>
<h2 id="after-onboarding">
    <a href="#after-onboarding">
	After onboarding
    </a>
</h2>
<p>Why have I been trying this?</p>
<p>
  <img src="https://blog.koehntopp.info/uploads/2024/02/element-08.jpg" alt="">
</p>


<p><em>A friend was trying to use a Matrix messenger on their phone, and waited 9 hours for this to complete.</em></p>
<p>A friend of mine was trying to re-install a Matrix messenger on their phone, and landed on the screen above.
This hung for 9 hours without any message or failure indication.
The application cannot detect if somebody is using the wrong recovery key for a different account.</p>
<p>The friend tried to use an Android application, but the application was complaining about the account not being verified.
That is, the mail address in use was not confirmed, and for that reason the client would not be showing any chats.
At the same time, these chats were being sent to the unconfirmed mail address,
unencrypted,
as a reminder that he was missing out.</p>
<p>According to him, you can’t delete a half-made unconfirmed account.
You also can’t rename an account.</p>
<p>Apparently, you cannot create invite links for private chat rooms,
only invite people.
To do that, vector.im uses the very same dark patterns that LinkedIn uses to convince you to share your address book.</p>
<p>With the unique mail-address used to sign up to Matrix, I am unfindable because only Matrix uses this specific mail address.</p>
<p>Outside of Element, there are very few clients, most of them very old and not being updated within the last few years.</p>
<p>All in all, this is a mess, and my recommendation is to avoid Matrix for at least two years.
It is not secure, it is actively user-hostile, and looks not well managed.</p>
<p>This is a project in severe need of management changes, a thorough UX evaluation.
The design needs changes that make onboarding and usage smoother, encourage secure workflows,
keep accounts available, and encourage secure practice.
It also needs careful curation of servers and clients.
At the moment it is a trash fire.</p>
<h2 id="matrix-responds">
    <a href="#matrix-responds">
	Matrix responds
    </a>
</h2>
<p>Added on 14-Feb-2024:
People at Matrix.org and Matrix developers have picked this up and responded in a very constructive way.
They cannot address all things because they are not in the realm of Matrix, but part of Element.
So far, no responses from Element.</p>
<p><a href="https://mastodon.matrix.org/@matrix/111924190165706931" target="_blank" rel="noopener">Matrix writes</a>

:</p>
<p>
  <img src="https://blog.koehntopp.info/uploads/2024/02/element-17.jpg" alt="">
</p>


<blockquote>
<p>well, this is a trashfire indeed.
Thanks for writing this up.
You’ve caught Element in the middle of their migration to Element X, and there’s a lot of legit feedback here:</p>
<ul>
<li>Both E &amp; EX should be in the macOS app store.</li>
<li>EX should clearly be labelled WIP in appstores.
-It’s a mistake that matrix.org hurls people to servers.joinmatrix.org (which is not run by us);
until recently it defaulted to matrix.org for convenience.</li>
<li>Keeping the “create account” window open is a pure bug.</li>
</ul>
</blockquote>
<p><a href="https://mastodon.matrix.org/@matrix/111924227099676114" target="_blank" rel="noopener">The continue</a>

</p>
<p>
  <img src="https://blog.koehntopp.info/uploads/2024/02/element-18.jpg" alt="">
</p>


<blockquote>
<ul>
<li>Verification UX in Element is a disaster, and being reworked in EX:
<a href="https://github.com/element-hq/element-meta/blob/develop/docs/FTUE.md" target="_blank" rel="noopener">Github link</a>

</li>
<li>Element Android failing to compute a recovery key is clearly a bug too.</li>
</ul>
<p>Your other complaints about Element UX (e.g. user discovery by email;
specifying the server URL) are also very familiar.</p>
<p>It’s not true to say vector.im uses “the very same dark patterns as LinkedIn” for contact discovery though;
<a href="https://github.com/matrix-org/matrix-spec-proposals/blob/hs/hash-identity/proposals/2134-identity-hash-lookup.md" target="_blank" rel="noopener">Github link</a>


explains how it works (and is strictly opt-in).</p>
</blockquote>
<p>Matrix Director of Program Development <a href="https://mamot.fr/@thibaultamartin/111924256997285624" target="_blank" rel="noopener">Thibault A. Martin responds</a>

</p>
<p>
  <img src="https://blog.koehntopp.info/uploads/2024/02/element-19.jpg" alt="">
</p>


<blockquote>
<p>Hej @isotopp I’m one of the maintainers of the matrix.org website.</p>
<p>Your post provides a very valuable perspective.
I gathered the following gripes that we can address on the website itself in this issue:
<a href="https://github.com/matrix-org/matrix.org/issues/2178" target="_blank" rel="noopener">Matrix.Org Issue 2178</a>

</p>
<p>If you have the time to let me know if I got things right,
that would be very useful!</p>
</blockquote>
<p>Thanks for picking this up, people!
I very much hope that Matrix and Element eventually turn into something useful.</p>

			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I grew my Substack from 439 to 451 free subscribers in just 11 months (213 pts)]]></title>
            <link>https://shadesofgreaves.substack.com/p/how-i-grew-my-substack-from-439-to</link>
            <guid>39368370</guid>
            <pubDate>Wed, 14 Feb 2024 10:27:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://shadesofgreaves.substack.com/p/how-i-grew-my-substack-from-439-to">https://shadesofgreaves.substack.com/p/how-i-grew-my-substack-from-439-to</a>, See on <a href="https://news.ycombinator.com/item?id=39368370">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p>A lot of people have been talking recently about how to grow their platform on Substack. And since I’m something of an expert on Substack growth, I figured I’d chime in. Because I’ve grown my Substack from 439 free subscribers to 451 free subscribers in just 11 months.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5db5bea-4916-4cd3-a36a-3f88a088fd66_766x591.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5db5bea-4916-4cd3-a36a-3f88a088fd66_766x591.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5db5bea-4916-4cd3-a36a-3f88a088fd66_766x591.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5db5bea-4916-4cd3-a36a-3f88a088fd66_766x591.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5db5bea-4916-4cd3-a36a-3f88a088fd66_766x591.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5db5bea-4916-4cd3-a36a-3f88a088fd66_766x591.png" width="766" height="591" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/c5db5bea-4916-4cd3-a36a-3f88a088fd66_766x591.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:591,&quot;width&quot;:766,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:48735,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5db5bea-4916-4cd3-a36a-3f88a088fd66_766x591.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5db5bea-4916-4cd3-a36a-3f88a088fd66_766x591.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5db5bea-4916-4cd3-a36a-3f88a088fd66_766x591.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5db5bea-4916-4cd3-a36a-3f88a088fd66_766x591.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p><span>I know what you’re thinking: no fiddle-dee-freaking way, hombre. But it’s true. I gained 11 new subscribers in less than a year and I have the stats to prove it. You, too, can hit numbers like mine (1 new subscriber </span><em>per month</em><span>!) if you just follow these simple steps. </span><em>And</em><span> are in a financial situation that allows the kind of free time you’ll need to grow this bad boy. </span><em>And</em><span> are willing to put in a butt ton of hours on a project that, statistically speaking, won’t succeed. Okay, let’s dive in!</span></p><p><span>I personally don’t know a single writer who works hard enough, and it shows. Writers come to me for advice all the time saying things like “Carlos, I just don’t get it. I wrote four Substack posts during my 9-month-long vacation in Turks &amp; Caicos and yet I’ve only gained 3 new subscribers.” And I have to tell them, “Listen, buddy boy, you’re never going anywhere with those kinds of numbers. You have to post at least </span><em>twice</em><span> that often!” And then they look at me, crestfallen, their dreams of writerly success fading before their eyes.&nbsp;</span></p><p>But, sure enough, the writers that do heed my advice see the kinds of double digit growth I’ve achieved. It’s possible, but you have to PUT. IN. THE. WORK. I’ve published 19 POSTS in just under a year. That’s over 1.5 times PER MONTH.&nbsp;</p><p><span>Side note: I never take vacations, but even if I did, Turks &amp; Caicos is </span><em>so over</em><span>, baby. Anyone who’s anyone is going to St. Kitts &amp; Nevis now. That’s the Caribbean ampersand island nation du jour.&nbsp;&nbsp;&nbsp;</span></p><p>When I launched Shades of Greaves in January, I had a clear mission:&nbsp;</p><p><em>Start a Substack, I guess, because that’s what other writers I know are doing.&nbsp;</em></p><p>I thought long and hard about what I should focus on, and ultimately landed on a concise concept for what my Substack would be about:&nbsp;</p><p><em>Shades of Greaves will feature topical satire, evergreen humor pieces, craft essays, self-publishing advice, occasional life updates, and any pieces that The New Yorker and McSweeney’s passed on.</em></p><p><span>Sure, the focus was a bit singular, but if I were to wander into, say, gardening advice, or home buying tips, or marketing strategy, then the focus would start to be too broad. Actually, come to think of it, there’s a bit of all of those things in the Substack, too. So I take back what I said earlier about having a clear vision. The key to Substack growth is the exact opposite: </span><em>spray and pray!</em></p><p>As you can see, I put a ton of hours into crafting the Shades of Greaves logo:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39e52742-6b5c-45fa-955e-f5293d7e0d91_500x500.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39e52742-6b5c-45fa-955e-f5293d7e0d91_500x500.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39e52742-6b5c-45fa-955e-f5293d7e0d91_500x500.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39e52742-6b5c-45fa-955e-f5293d7e0d91_500x500.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39e52742-6b5c-45fa-955e-f5293d7e0d91_500x500.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39e52742-6b5c-45fa-955e-f5293d7e0d91_500x500.jpeg" width="500" height="500" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/39e52742-6b5c-45fa-955e-f5293d7e0d91_500x500.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:500,&quot;width&quot;:500,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:22099,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39e52742-6b5c-45fa-955e-f5293d7e0d91_500x500.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39e52742-6b5c-45fa-955e-f5293d7e0d91_500x500.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39e52742-6b5c-45fa-955e-f5293d7e0d91_500x500.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39e52742-6b5c-45fa-955e-f5293d7e0d91_500x500.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Whether you like it or not, Notes is here to stay. And, sure, like any social-media-style feed, it’s time consuming, mentally exhausting, and a great place to get harassed by the most heinous people on planet Earth. But that’s a small price to pay for occasionally meeting someone cool. So, in addition to my prolific newsletter posts (1.5x a month, need I remind you) I also frequently write, comment on, and restack Notes. AT LEAST once every two months (sometimes three months if I forget).</p><p>I have no idea if this is true, but everyone else says it is, so I’m guessing it’s true.</p><p><span>At the end of the day, it’s important to remember that the most successful people all put tons and tons of hours worth of work into their projects. It’s also important to remember that plenty of non-successful people </span><em>also</em><span> put tons and tons of hours worth of work into their projects and failed anyway! Most people never make a living wage from creative pursuits because we live in a chaotic world governed by probability. So any success on this topsy-turvy stochastic planet is, in part, due to being at the right place at the right time, appealing to humanity’s notoriously fickle, ever-changing tastes at just the right moment, being born with Lebron James-like preternatural abilities, and the alignment of Mercury relative to Earth. And even if you have all of those things, working your whole entire ass off is (DUH) also a prerequisite.&nbsp;</span></p><p>So, considering that you’re likely going to fail, at least pick something you’re going to enjoy failing at! It’s the only way to overcome the psychological carpet bombing that is putting your heart and soul into your creative work only for it to FALL INTO THE VOID TIME AND TIME AGAIN! Or maybe it won’t this time! You’ll never know until you put WAY TOO MUCH FUCKING ENERGY into it! Good luck!&nbsp;&nbsp;</p><p>I hope all of the advice above helps you achieve the kind of stellar growth I’ve achieved on Substack these past 11 months. I don’t know about you, but I’m feeling energized to put in even more work into my Substack in 2024. I daresay, I may even hit 468 or even 479 subscribers by this same time next year!</p><p><span>And, if all else fails, you can always become an alt-right Nazi troll. They seem to be </span><a href="https://www.theatlantic.com/ideas/archive/2023/11/substack-extremism-nazi-white-supremacy-newsletters/676156/" rel="">thriving</a><span> on Substack.</span></p><p>Okay, was that fun? I hope you found it as cathartic to read as it was to write. Now, I just want to be super, super, super clear – this post isn’t intended to bash any writers who have written about growing their platforms recently. If you’ve perused Substack over the past few weeks, you’ve likely come across a few of the pieces I poked fun at above. But I assure you, my intent is not to put other writers on blast. This was just a silly way for those of us who are on the other side of the growth equation to have a laugh and let off a little steam. For the record, I’ve actually found those posts about Substack growth to be both informative and inspiring, and I appreciate those writers sharing their insights.</p><p>My only pet peeve I have about these kinds of advice posts is when writers (or any successful person, for that matter) tells other people that they need to “work harder.” You mean I have to work hard? If only I’d thought of that! Here I was being a lazy sack of shit this whole time thinking that was the key to success.&nbsp;</p><p><span>I don’t know about you, but I personally don’t know a single writer who </span><em>isn’t</em><span> working their absolute, wordsmithing ass off. The only difference is that what they’re working their asses off on might be anything from writing books, to teaching, to raising children, to working a non-writing day job that pays the bills. Not everyone has the time or resources to devote to growing a platform — that’s just the reality of the world we live in — so attributing one’s own success to working hard, though undoubtedly true, never sits right with me. It’s like saying that to be a writer you need to drink water and remember to keep breathing oxygen. True, yes, but it hardly bears repeating.&nbsp;</span></p><p>So that’s the only bit of advice I take issue with, which is a common thread I saw in many of the posts I came across. And I know that wasn’t their intent, but the satirist in me tends to interpret people’s words in the least generous way possible if it means getting to make a little joke out of it.</p><p><span>What I </span><em>do</em><span> think is spot on is that, to grow your platform, you have to deliver something of value to readers. And developing the writing skills to do that can take years. Many of the Substacks I see growing quickly are from authors with multiple books under their belts and decades of experience. And that does, of course, take </span><em>work</em><span>. So that I wholeheartedly agree with.</span></p><p>Also, I want to be clear, I don’t think you need Lebron James-like natural ability to succeed. But I do think that embracing the randomness of life is freeing. You really do have to love the work for the sake of the work, and that’s one of the hardest things to do as a writer when you also want to, you know, make enough money to eat. But putting constant pressure on yourself doesn’t do a bit of good.&nbsp;</p><p><span>Most importantly, I hope this piece serves as a self-deprecating look at my own failures (okay, “failures” is too harsh. “Non-successes,” maybe?) when it comes to growing my Substack over the past year. A what </span><em>not</em><span> to do, if you will. The blame for why my Substack hasn’t grown as much as I might’ve liked it to lies squarely with me. Life got in the way. I got busy with </span><a href="https://www.amazon.com/dp/B0CF47Z8JG?maas=maas_adg_7C9BAC2EFA2585AA6123C15055227C59_afap_abs&amp;ref_=aa_maas&amp;tag=maas" rel="">my book</a><span>, and starting a new job, and thus my Substack went by the wayside for parts of the year.&nbsp;</span></p><p>Even so, I managed to grow my Substack from 320 to 451 subscribers (yes, I exaggerated earlier for comedic effect) in less than a year and I'm grateful for that! I do intend to post more regularly and make a concerted effort to build community here in 2024, so hopefully I can stick to that (feel free to slide into my chats to hound me if you feel I’m not delivering on that).</p><p><span>As for why someone might consider subscribing, if there's anything I offer on Substack that you can’t get elsewhere it's that A) I’m a satirist and therefore my writing is (hopefully) relatively funny and entertaining to read, and B) I’m sharing what I’m learning as I’m learning it. So, in that sense, this Substack is a journey we’re going on </span><em>together</em><span> as opposed to me just passing on advice. So if that sounds like your jam, come say hi! And if you’re already a subscriber, come say hi more often! I love discussing all things humor and writing and my chats, notes, and comments are always open.&nbsp;</span></p><p>Until the right-wing trolls find me, of course, then I may have to lay low for a bit.</p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Popular XMPP App "Conversations" Removed from PlayStore by Google (289 pts)]]></title>
            <link>https://gultsch.social/@daniel/111929074071688694</link>
            <guid>39368233</guid>
            <pubDate>Wed, 14 Feb 2024 09:54:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gultsch.social/@daniel/111929074071688694">https://gultsch.social/@daniel/111929074071688694</a>, See on <a href="https://news.ycombinator.com/item?id=39368233">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Not all TLDs are Created Equal (200 pts)]]></title>
            <link>https://www.hezmatt.org/~mpalmer/blog/2024/02/13/not-all-tlds-are-created-equal.html</link>
            <guid>39367540</guid>
            <pubDate>Wed, 14 Feb 2024 07:51:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.hezmatt.org/~mpalmer/blog/2024/02/13/not-all-tlds-are-created-equal.html">https://www.hezmatt.org/~mpalmer/blog/2024/02/13/not-all-tlds-are-created-equal.html</a>, See on <a href="https://news.ycombinator.com/item?id=39367540">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">

				
				<p>
					Posted: Tue, 13 February 2024
					| <a href="https://www.hezmatt.org/~mpalmer/blog/2024/02/13/not-all-tlds-are-created-equal.html">permalink</a>
					| <a href="https://www.hezmatt.org/~mpalmer/blog/2024/02/13/not-all-tlds-are-created-equal.html#comments">
						
							No comments
						
					</a>
				</p>
<p>In light of the recent <a href="https://akko.erincandescent.net/notice/AenvYJ0yiHfspKM8uW">cancellation of the <code>queer.af</code> domain registration by the Taliban</a>, the fragile and difficult nature of country-code top-level domains (ccTLDs) has once again been comprehensively demonstrated.
Since many people may not be aware of the risks, I thought I’d give a solid explainer of the whole situation, and explain why you should, in general, not have anything to do with domains which are registered under ccTLDs.</p>

<h2 id="top-level-what-now">Top-level What-Now?</h2>

<p>A top-level domain (TLD) is the last part of a domain name (the collection of words, separated by periods, after the <code>https://</code> in your web browser’s location bar).
It’s the “com” in <code>example.com</code>, or the “af” in <code>queer.af</code>.</p>

<p>There are two kinds of TLDs: country-code TLDs (ccTLDs) and generic TLDs (gTLDs).
Despite all being TLDs, they’re very different beasts under the hood.</p>

<h2 id="whats-the-difference">What’s the Difference?</h2>

<p>Generic TLDs are what most organisations and individuals register their domains under: old-school technobabble like “com”, “net”, or “org”, historical oddities like “gov”, and the new-fangled world of words like “tech”, “social”, and “bank”.
These gTLDs are all regulated under a set of rules created and administered by ICANN (the “Internet Corporation for Assigned Names and Numbers”), which try to ensure that things aren’t a complete wild-west, limiting things like price hikes (well, sometimes, anyway), and providing means for disputes over names<sup id="fnref:1"><a href="https://www.hezmatt.org/~mpalmer/blog/#fn:1">1</a></sup>.</p>

<p>Country-code TLDs, in contrast, are all two letters long<sup id="fnref:2"><a href="https://www.hezmatt.org/~mpalmer/blog/#fn:2">2</a></sup>, and are given out to countries to do with as they please.
While ICANN kinda-sorta has something to do with ccTLDs (in the sense that it makes them exist on the Internet), it has no authority to control how a ccTLD is managed.
If a country decides to raise prices by 100x, or cancel all registrations that were made on the 12th of the month, there’s nothing anyone can do about it.</p>

<p>If that sounds bad, that’s because it is.
Also, it’s not a theoretical problem – the Taliban deciding to asssert its bigotry over the little corner of the Internet namespace it has taken control of is far from the first time that ccTLDs have caused grief.</p>

<h2 id="shifting-sands">Shifting Sands</h2>

<p>The <code>queer.af</code> cancellation is interesting because, at the time the domain was reportedly registered, 2018, Afghanistan had what one might describe as, at least, a <em>different</em> political climate.
Since then, of course, things have changed, and the new bosses have decided to get a bit more active.</p>

<p>Those running <code>queer.af</code> seem to have seen the writing on the wall, and were planning on moving to another, less fraught, domain, but hadn’t completed that move when the Taliban came knocking.</p>

<h2 id="the-curious-case-of-brexit">The Curious Case of Brexit</h2>

<p>When the United Kingdom decided to leave the European Union, it fell foul of the EU’s rules for the registration of domains under the “eu” ccTLD<sup id="fnref:3"><a href="https://www.hezmatt.org/~mpalmer/blog/#fn:3">3</a></sup>.
To register (and maintain) a domain name ending in <code>.eu</code>, you have to be a resident of the EU.
When the UK ceased to be part of the EU, residents of the UK were no longer EU residents.</p>

<p>Cue much unhappiness, wailing, and gnashing of teeth when this was pointed out to Britons.
Some decided to give up their domains, and move to other parts of the Internet, while others managed to hold onto them by various legal sleight-of-hand (like having an EU company maintain the registration on their behalf).</p>

<p>In any event, all very unpleasant for everyone involved.</p>

<h2 id="geopolitics-on-the-internet">Geopolitics… on the Internet?!?</h2>

<p>After Russia invaded Ukraine in February 2022, the Ukranian Vice Prime Minister <a href="https://eump.org/media/2022/Goran-Marby.pdf">asked ICANN to suspend ccTLDs associated with Russia</a>.
While ICANN said that it wasn’t going to do that, because it wouldn’t do anything useful, some domain registrars (the companies you pay to register domain names) ceased to deal in Russian ccTLDs, and some websites restricted links to domains with Russian ccTLDs.</p>

<p>Whether or not you agree with the sort of activism implied by these actions, the fact remains that even the actions of a government that <em>aren’t</em> directly related to the Internet can have grave consequences for your domain name if it’s registered under a ccTLD.
I don’t <em>think</em> any gTLD operator will be invading a neighbouring country any time soon.</p>

<h2 id="money-money-money-must-be-funny">Money, Money, Money, Must Be Funny</h2>

<p>When you register a domain name, you pay a registration fee to a registrar, who does administrative gubbins and causes you to be able to control the domain name in the DNS.
However, you don’t “own” that domain name<sup id="fnref:4"><a href="https://www.hezmatt.org/~mpalmer/blog/#fn:4">4</a></sup> – you’re only <em>renting</em> it.
When the registration period comes to an end, you have to renew the domain name, or you’ll cease to be able to control it.</p>

<p>Given that a domain name is typically your “brand” or “identity” online, the chances are you’d prefer to keep it over time, because moving to a new domain name is a <em>massive</em> pain, having to tell all your customers or users that now you’re somewhere else, plus having to accept the risk of someone registering the domain name you used to have and capturing your traffic… it’s all a gigantic hassle.</p>

<p>For gTLDs, ICANN has various rules around price increases and bait-and-switch pricing that tries to keep a lid on the worst excesses of registries.
While there are any number of reasonable criticisms of the rules, and the Internet community has to stay on their toes to keep ICANN from <a href="https://domainnamewire.com/2019/03/18/icann-proposes-lifting-price-controls-on-org-info-domains/">totally succumbing to regulatory capture</a>, at least in the gTLD space there’s some degree of control over price gouging.</p>

<p>On the other hand, ccTLDs have no effective controls over their pricing.
For example, in 2008 the Seychelles increased the price of <code>.sc</code> domain names from <a href="https://web.archive.org/web/20071113061947/http://www.afilias-grs.info:80/public/policies/sc">US$25</a> to <a href="https://web.archive.org/web/20080308114828/http://www.afilias-grs.info:80/public/policies/sc">US$75</a>.  No reason, no warning, just “pay up”.</p>

<h2 id="who-is-even-getting-that-money">Who Is Even Getting That Money?</h2>

<p>A closely related concern about ccTLDs is that some of the “cool” ones are assigned to countries that are… not great.</p>

<p>The poster child for this is almost certainly Libya, which has the ccTLD “ly”.
While Libya was being run by a <a href="https://en.wikipedia.org/wiki/Muammar_Gaddafi">terrorist-supporting extremist</a>, companies thought it was a great idea to have domain names that ended in <code>.ly</code>.
These domain registrations weren’t (and aren’t) cheap, and it’s hard to imagine that at least some of that money wasn’t going to benefit the Gaddafi regime.</p>

<p>Similarly, the British Indian Ocean Territory, which has the “io” ccTLD, was created in a <a href="https://theconversation.com/how-the-us-and-uk-worked-together-to-recolonise-the-chagos-islands-and-evict-chagossians-177636">colonialist piece of chicanery that expelled thousands of native Chagossians from Diego Garcia</a>.
Money from the registration of <code>.io</code> domains doesn’t go to the (former) residents of the Chagos islands, instead <a href="https://web.archive.org/web/20200314085443/gigaom.com/2014/06/30/the-dark-side-of-io-how-the-u-k-is-making-web-domain-profits-from-a-shady-cold-war-land-deal/">it gets paid to the UK government</a>.</p>

<p>Again, I’m not trying to suggest that all gTLD operators are wonderful people, but it’s not particularly likely that the direct beneficiaries of the operation of a gTLD stole an island chain and evicted the residents.</p>

<h2 id="are-cctlds-ever-useful">Are ccTLDs Ever Useful?</h2>

<p>The answer to that question is an unqualified “maybe”.
I certainly don’t think it’s a good idea to register a domain under a ccTLD for “vanity” purposes: because it makes a word, is the same as a file extension you like, or because it looks cool.</p>

<p>Those ccTLDs that clearly represent and are associated with a particular country are more likely to be OK, because there is less impetus for the registry to try a naked cash grab.
Unfortunately, ccTLD registries have a disconcerting habit of changing their minds on whether they serve their geographic locality, such as when auDA decided to declare an open season in the <code>.au</code> namespace some years ago.
Essentially, while a ccTLD may have geographic connotations <em>now</em>, there’s not a lot of guarantee that they won’t fall victim to scope creep in the future.</p>

<p>Finally, it <em>might</em> be somewhat safer to register under a ccTLD if you live in the location involved.
At least then you might have a better idea of whether your domain is likely to get pulled out from underneath you.
Unfortunately, as the <code>.eu</code> example shows, living somewhere today is no guarantee you’ll still be living there tomorrow, even if you don’t move house.</p>

<p>In short, I’d suggest sticking to gTLDs.
They’re at least <em>lower</em> risk than ccTLDs.</p>

<h2 id="helpful">“+1, Helpful”</h2>

<p>If you’ve found this post informative, why not <a href="https://ko-fi.com/tobermorytech">buy me a refreshing beverage</a>?
My typing fingers (both of them) thank you in advance for your generosity.</p>

<hr>





<hr>
			
			

			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apple has not fixed the macOS audio left/right balance bug for nearly 10 years (271 pts)]]></title>
            <link>https://twitter.com/ffaebi/status/1757669861377949930</link>
            <guid>39367460</guid>
            <pubDate>Wed, 14 Feb 2024 07:37:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/ffaebi/status/1757669861377949930">https://twitter.com/ffaebi/status/1757669861377949930</a>, See on <a href="https://news.ycombinator.com/item?id=39367460">Hacker News</a></p>
Couldn't get https://twitter.com/ffaebi/status/1757669861377949930: Error: Request failed with status code 400]]></description>
        </item>
        <item>
            <title><![CDATA[UC Berkley: World Model on Million-Length Video and Language with RingAttention (176 pts)]]></title>
            <link>https://largeworldmodel.github.io/</link>
            <guid>39367141</guid>
            <pubDate>Wed, 14 Feb 2024 06:34:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://largeworldmodel.github.io/">https://largeworldmodel.github.io/</a>, See on <a href="https://news.ycombinator.com/item?id=39367141">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  <div>
      <h2>Abstract</h2>
      <div><p>
          Current language models fall short in understanding aspects of the world not easily described in words, and struggle with complex, long-form tasks. Video sequences offer valuable temporal information absent in language and static images, making them attractive for joint modeling with language. Such models could develop a understanding of both human textual knowledge and the physical world, enabling broader AI capabilities for assisting humans. However, learning from millions of tokens of video and language sequences poses challenges due to memory constraints, computational complexity, and limited datasets. To address these challenges, we curate a large dataset of diverse videos and books, utilize the RingAttention technique to scalably train on long sequences, and gradually increase context size from 4K to 1M tokens. This paper makes the following contributions: (a) Largest context size neural network: We train one of the largest context size transformers on long video and language sequences, setting new benchmarks in difficult retrieval tasks and long video understanding. (b) Solutions for overcoming vision-language training challenges, including using masked sequence packing for mixing different sequence lengths, loss weighting to balance language and vision, and model-generated QA dataset for long sequence chat. (c) A highly-optimized implementation with RingAttention, masked sequence packing, and other key features for training on millions-length multimodal sequences. (d) Fully open-sourced a family of 7B parameter models capable of processing long text documents (LWM-Text, LWM-Text-Chat) and videos (LWM, LWM-Chat) of over 1M tokens.
          This work paves the way for training on massive datasets of long video and language to develop understanding of both human knowledge and the multimodal world, and broader capabilities.
          </p></div>
    </div>
<!-- End paper abstract -->


<!-- 1M Vision-Language figure -->
<div>
    <h2>Question Answering Over 1 Hour Video.</h2>
    <div>
      <p><img src="https://largeworldmodel.github.io/materials/long_video_chat_main.png" alt="1M video chat" width="820"></p><p><b>Figure 1. Long video understanding.</b> LWM can answer questions about over 1 hour YouTube video.</p>
      </div>
    </div>
<!-- End 1M Vision-Language figure -->

<!-- 1M Language figure -->
<div>
    <h2>Fact Retrieval Over 1M Context.</h2>
    <div>
      <div>
        <p><img src="https://largeworldmodel.github.io/materials/needle_comparison_baselines_log_linear_mix_rot.png" alt="1M fact retrieval" width="850"></p><p><b>Figure 2. Needle retrieval task.</b> LWM achieves high accuracy across 1M context window and outperforms GPT-4V and Gemini Pro.</p>
      </div>
      <br>
      <div>
        <p><img src="https://largeworldmodel.github.io/materials/single_needle_1M.png" alt="1M fact retrieval" width="900"></p><p><b>Figure 3. Needle retrieval task.</b> LWM achieves high accuracy for varying context sizes and positions in the context window.</p>
      </div>
      <!-- <div class="image-container" style="display: flex; justify-content: center; gap: 5px;">
        <div class="image">
          <img src="./materials/single_needle_1M.png" alt="Image 1" width="200" height="100">
        </div>
        <div class="image">
          <img src="./materials/multi_needle.png" alt="Image 2" width="200" height="100">
        </div>
      </div> -->
    </div>
    </div>

<!-- End 1M Language figure -->


<!-- Model figure -->
<div>
    <h2>Long Sequence Any-to-Any AR Prediction.</h2>
    <div>
      <p><img src="https://largeworldmodel.github.io/materials/model.png" alt="Model" width="700"></p><p><b>Figure 4. Any-to-Any Long Sequence Prediction.</b> RingAttention enables the use of a very large context window for training across diverse formats such as video-text, text-video, image-text, text-image, pure video, pure image, and pure text. See <a href="https://arxiv.org/abs/2402.08268" target="_blank">the LWM paper</a> for key features, including masked sequence packing and loss weighting, which allow effective video-language training.</p>
      </div>
    </div>
<!-- End model figure -->

<!-- Data figure. -->
<div>
    <h2>Modeling Diverse Videos and Books With RingAttention.</h2>
    <div>
      <p><img src="https://largeworldmodel.github.io/materials/data.png" alt="Data Mixture" width="900"></p><p><b>Figure 5. Context Extension and Vision-Language Training.</b> Expanding context size from 4K to 1M on books using RingAttention, followed by vision-language training on diverse forms of visual contents of lengths 32K to 1M. The lower panel shows interactive capabilities in understanding and responding to queries about complex multimodal world.</p>
    </div>
    </div>
<!-- End data figure -->


<!-- Image Generation figure -->
<div>
    <h2>Text-Image Generation.</h2>
    <div>
      <p><img src="https://largeworldmodel.github.io/materials/image_gen/set_1.png" alt="Fact retrieval" width="800">
      </p>
    </div>
    <div>
      <p><img src="https://largeworldmodel.github.io/materials/image_gen/set_2.png" alt="Fact retrieval" width="800"></p><p><b>Figure 6. Text to Image.</b> LWM generates images based on text prompts, autoregressively.</p>
      </div>
    </div>
<!-- End Image Generation figure -->


<!-- Text-Video figure -->
<div>
    <h2>Text-Video Generation.</h2>
    <div>
        <div>
          <div>
              <video width="100%" onloadstart="this.playbackRate = 0.75" autoplay="" loop="" playsinline="" muted="">
                <source src="https://largeworldmodel.github.io/materials/video_gen/fireworks.mp4" type="video/mp4">
                </video>
              <center>
                <p>Fireworks exploding in the sky</p>
              </center>
          </div>
          
          <div>
              <video width="100%" onloadstart="this.playbackRate = 0.75" autoplay="" loop="" playsinline="" muted="">
              <source src="https://largeworldmodel.github.io/materials/video_gen/waves.mp4" type="video/mp4">
              </video>
              <center>
                <p>Waves crashing against the shore</p>
              </center>
          </div>
          
          <div>
              <video width="100%" onloadstart="this.playbackRate = 0.75" autoplay="" loop="" playsinline="" muted="">
              <source src="https://largeworldmodel.github.io/materials/video_gen/street.mp4" type="video/mp4">
              </video>
              <center>
                <p>A bustling street in London with red telephone booths and Big Ben in the background</p>
              </center>
          </div>
          
          <div>
              <video width="100%" onloadstart="this.playbackRate = 0.75" autoplay="" loop="" playsinline="" muted="">
              <source src="https://largeworldmodel.github.io/materials/video_gen/mangoes.mp4" type="video/mp4">
              </video>
              <center>
                <p>Camera pans left to right on mago slices sitting on a table</p>
                </center>
          </div>
        </div>
        <div>
          
          
          <div>
              <video width="100%" onloadstart="this.playbackRate = 0.75" autoplay="" loop="" playsinline="" muted="">
              <source src="https://largeworldmodel.github.io/materials/video_gen/flowers.mp4" type="video/mp4">
              </video>
              <center>
                <p>Slow motion flower petals falling on the ground</p>
              </center>
          </div>
          
          <div>
              <video width="100%" onloadstart="this.playbackRate = 0.75" autoplay="" loop="" playsinline="" muted="">
              <source src="https://largeworldmodel.github.io/materials/video_gen/campfire.mp4" type="video/mp4">
              </video>
              <center>
                <p>A burning campire in a forest</p>
              </center>
          </div>
          
          <div>
              <video width="100%" onloadstart="this.playbackRate = 0.75" autoplay="" loop="" playsinline="" muted="">
              <source src="https://largeworldmodel.github.io/materials/video_gen/boat_storm.mp4" type="video/mp4">
              </video>
              <center>
              <p>A boat sailing on a stormy ocean</p>
              </center>
          </div>
        </div>
        <p><b>Figure 5. Text to Video.</b> LWM generates videos based on text prompts, autoregressively.</p>
      </div>
    </div>
<!-- Text-Video figure -->


<!-- Short Video Chat figure -->
<!-- <div class="columns is-centered has-text-centered">
  <div class="column is-four-fifths">
    <h2 class="title is-3" style="white-space: nowrap;">Video-Based Conversation (30s - 5min).</h2>
    <div class="content has-text-justified">
      <div style="text-align: center;">
        <div style="width: 100%; overflow: hidden;">
          <div style="width: 35%; float: left;">
              <iframe src="https://www.youtube.com/embed/hkbJ75oei18?start=0&end=120" frameborder="0" allowfullscreen></iframe>
          </div>
          <div style="width: 2%;"> </div>
          <div style="width: 60%; float: right;">
            <img src="./materials/video_chat_comparison_1.png" width="100%">
          </div>
        </div>
        <br>
        <div style="width: 100%; overflow: hidden;">
          <div style="width: 35%; float: left;">
              <iframe src="https://www.youtube.com/embed/hkbJ75oei18?start=0&end=120" frameborder="0" allowfullscreen></iframe>
          </div>
          <div style="width: 2%;"> </div>
          <div style="width: 60%; float: right;">
            <img src="./materials/video_chat_comparison_2.png" width="100%">
          </div>
        </div>
        <p class="caption" style="width: 100%; text-align: center;"><b>Figure 7. Short Video Chat.</b> LWM answers questions about short videos and performs similarly to GPT-4V and Gemini Pro.</p>
      </div>
    </div>
    <br><br>
  </div>
</div> -->
<!-- End Short Video Chat figure -->

<!-- Image chat figure -->
<div>
    <h2>Image Based Conversation.</h2>
    <div>
      <p><img src="https://largeworldmodel.github.io/materials/image_chat.png" alt="1M video chat" width="820"></p><p><b>Figure 6. Image understanding.</b> LWM can answer questions about images.</p>
      </div>
    </div>
<!-- End image chat figure -->

<!-- Long Video Chat figure -->
<div>
    <h2>Video Chat Over 1 Hour YouTube Video.</h2>
    <div>
        <div>
          <p>
              <iframe src="https://www.youtube.com/embed/NgTV5bxK8Cs" frameborder="0" allowfullscreen=""></iframe>
          </p>
          
          <p><img src="https://largeworldmodel.github.io/materials/long_video_chat_1.png" width="100%">
          </p>
        </div>
        <br>
        <div>
          <p>
              <iframe src="https://www.youtube.com/embed/ZrRMYgws-s4" frameborder="0" allowfullscreen=""></iframe>
          </p>
          
          <p><img src="https://largeworldmodel.github.io/materials/long_video_chat_2.png" width="100%">
          </p>
        </div>
        <p><b>Figure 7. Long Video Chat.</b> LWM answers questions about 1 hour long YouTube video even if state-of-the-art commercial models GPT-4V and Gemini Pro both fail. The relevant clips for each example are at timestamps 9:56 (top) and 6:49 (bottom).</p>
      </div>
    </div>
<!-- End Short Video Chat figure -->

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Quarto (174 pts)]]></title>
            <link>https://quarto.org/</link>
            <guid>39367103</guid>
            <pubDate>Wed, 14 Feb 2024 06:27:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://quarto.org/">https://quarto.org/</a>, See on <a href="https://news.ycombinator.com/item?id=39367103">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="hello-quarto-tabcontent">
<div id="python" role="tabpanel" aria-labelledby="python-tab">
<p>Combine Jupyter notebooks with flexible options to produce production quality output in a wide variety of formats. Author using traditional notebook UIs or with a plain text markdown representation of notebooks.</p>
<div>
<p><img src="https://quarto.org/images/demo-jupyter-plain.png" alt="Example Jupyter notebook entitled Palmer Penguins with code cells, text, and a scatterplot." height="605"></p>
<p><img src="https://quarto.org/images/demo-jupyter-output.png" alt="Output of example Jupyter notebook, Palmer Penguins, in HTML showing title, metadata, text, code, and scatterplot. At the top there is a dropdown option to show or hide the code."></p>
</div>
</div>
<div id="knitr" role="tabpanel" aria-labelledby="knitr-tab">
<p>Quarto is a multi-language, next generation version of R Markdown from Posit, with many new new features and capabilities. Like R Markdown, Quarto uses <a href="https://yihui.org/knitr/">knitr</a> to execute R code, and is therefore able to render most existing Rmd files without modification.</p>
<div>
<div id="cb1"><pre><code><span id="cb1-1"><span>---</span></span>
<span id="cb1-2"><span>title:</span><span> "ggplot2 demo"</span></span>
<span id="cb1-3"><span>author:</span><span> "Norah Jones"</span></span>
<span id="cb1-4"><span>date:</span><span> "5/22/2021"</span></span>
<span id="cb1-5"><span>format:</span><span> </span></span>
<span id="cb1-6"><span>  html:</span></span>
<span id="cb1-7"><span>    fig-width: 8</span></span>
<span id="cb1-8"><span>    fig-height: 4</span></span>
<span id="cb1-9"><span>    code-fold: true</span></span>
<span id="cb1-10"><span>---</span></span>
<span id="cb1-11"></span>
<span id="cb1-12"><span>## Air Quality</span></span>
<span id="cb1-13"></span>
<span id="cb1-14">@fig-airquality further explores the impact of temperature on ozone level.</span>
<span id="cb1-15"></span>
<span id="cb1-16"><span>```{r}</span></span>
<span id="cb1-17"><span>#| label: fig-airquality</span></span>
<span id="cb1-18"><span>#| fig-cap: "Temperature and ozone level."</span></span>
<span id="cb1-19"><span>#| warning: false</span></span>
<span id="cb1-20"></span>
<span id="cb1-21"><span>library(ggplot2)</span></span>
<span id="cb1-22"><span>ggplot(airquality, aes(Temp, Ozone)) + </span></span>
<span id="cb1-23"><span>  geom_point() + </span></span>
<span id="cb1-24"><span>  geom_smooth(method = "loess")</span></span>
<span id="cb1-25"><span>```</span></span>
<span id="cb1-26"></span></code></pre></div>
<p><img src="https://quarto.org/images/hello-knitr.png" alt="Example output with title (ggplot2 demo), author (Norah Jones), and date (5/22/2021). Below is a header reading Air Quality followed by body text (Figure 1 further explores the impact of temperature on ozone level.) with a toggleable code field, and figure with caption Figure 1 Temperature and ozone level."></p>
</div>
</div>
<div id="julia" role="tabpanel" aria-labelledby="julia-tab">
<p>Combine markdown and Julia code to create dynamic documents that are fully reproducible. Quarto executes Julia code via the <a href="https://github.com/JuliaLang/IJulia.jl">IJulia</a> Jupyter kernel, enabling you to author in plain text (as shown below) or render existing Jupyter notebooks.</p>
<div>
<div id="cb2"><pre><code><span id="cb2-1"><span>---</span></span>
<span id="cb2-2"><span>title:</span><span> "Plots Demo"</span></span>
<span id="cb2-3"><span>author:</span><span> "Norah Jones"</span></span>
<span id="cb2-4"><span>date:</span><span> "5/22/2021"</span></span>
<span id="cb2-5"><span>format:</span></span>
<span id="cb2-6"><span>  html:</span></span>
<span id="cb2-7"><span>    code-fold: true</span></span>
<span id="cb2-8"><span>jupyter:</span><span> julia-1.8</span></span>
<span id="cb2-9"><span>---</span></span>
<span id="cb2-10"></span>
<span id="cb2-11"><span>## Parametric Plots</span></span>
<span id="cb2-12"></span>
<span id="cb2-13">Plot function pair (x(u), y(u)). </span>
<span id="cb2-14">See @fig-parametric for an example.</span>
<span id="cb2-15"></span>
<span id="cb2-16"><span>```{julia}</span></span>
<span id="cb2-17"><span>#| label: fig-parametric</span></span>
<span id="cb2-18"><span>#| fig-cap: "Parametric Plots"</span></span>
<span id="cb2-19"></span>
<span id="cb2-20"><span>using Plots</span></span>
<span id="cb2-21"></span>
<span id="cb2-22"><span>plot(sin, </span></span>
<span id="cb2-23"><span>     x-&gt;sin(2x), </span></span>
<span id="cb2-24"><span>     0, </span></span>
<span id="cb2-25"><span>     2π, </span></span>
<span id="cb2-26"><span>     leg=false, </span></span>
<span id="cb2-27"><span>     fill=(0,:lavender))</span></span>
<span id="cb2-28"><span>```</span></span>
<span id="cb2-29"></span></code></pre></div>
<p><img src="https://quarto.org/images/hello-julia.png" alt="Example Plots Demo output with title, author, date published and main section on Parametric plots which contains text, a toggleable code field, and the output of the plot, with the caption Figure 1 Parametric Plots."></p>
</div>
</div>
<div id="observable" role="tabpanel" aria-labelledby="observable-tab">
<p>Quarto includes native support for Observable JS, a set of JavaScript enhancements created by Mike Bostock (the author of D3). Observable JS uses a reactive execution model, and is especially well suited for interactive data exploration and analysis.</p>
<div>
<div id="cb3"><pre><code><span id="cb3-1"><span>---</span></span>
<span id="cb3-2"><span>title:</span><span> "observable plot"</span></span>
<span id="cb3-3"><span>author:</span><span> "Norah Jones"</span></span>
<span id="cb3-4"><span>format:</span><span> </span></span>
<span id="cb3-5"><span>  html: </span></span>
<span id="cb3-6"><span>    code-fold: true</span></span>
<span id="cb3-7"><span>---</span></span>
<span id="cb3-8"></span>
<span id="cb3-9"><span>## Seattle Precipitation by Day (2012 to 2016)</span></span>
<span id="cb3-10"></span>
<span id="cb3-11"><span>```{ojs}</span></span>
<span id="cb3-12"><span>data = FileAttachment("seattle-weather.csv")</span></span>
<span id="cb3-13"><span>  .csv({typed: true})</span></span>
<span id="cb3-14"><span>  </span></span>
<span id="cb3-15"><span>Plot.plot({</span></span>
<span id="cb3-16"><span>  width: 800, height: 500, padding: 0,</span></span>
<span id="cb3-17"><span>  color: { scheme: "blues", type: "sqrt"},</span></span>
<span id="cb3-18"><span>  y: { tickFormat: i =&gt; "JFMAMJJASOND"[i] },</span></span>
<span id="cb3-19"><span>  marks: [</span></span>
<span id="cb3-20"><span>    Plot.cell(data, Plot.group({fill: "mean"}, {</span></span>
<span id="cb3-21"><span>      x: d =&gt; new Date(d.date).getDate(),</span></span>
<span id="cb3-22"><span>      y: d =&gt; new Date(d.date).getMonth(),</span></span>
<span id="cb3-23"><span>      fill: "precipitation", </span></span>
<span id="cb3-24"><span>      inset: 0.5</span></span>
<span id="cb3-25"><span>    }))</span></span>
<span id="cb3-26"><span>  ]</span></span>
<span id="cb3-27"><span>})</span></span>
<span id="cb3-28"><span>```</span></span></code></pre></div>
<p><img src="https://quarto.org/images/hello-observable.png" alt="Example output with title, author, and date. Below, the main section reads Seattle Precipitation by Day (2012 to 2016) with a toggleable section to show code and a heatmap of the precipitation by day."></p>
</div>
</div>
</div><div>
<section id="dynamic-documents">
<h3>Dynamic Documents</h3>
<p>Generate dynamic output using Python, R, Julia, and Observable. Create reproducible documents that can be regenerated when underlying assumptions or data change.</p>

</section>
<section id="beautiful-publications">
<h3>Beautiful Publications</h3>
<p>Publish high-quality articles, reports, presentations, websites, and books in HTML, PDF, MS Word, ePub, and more. Use a single source document to target multiple formats.</p>

</section>
<section id="scientific-markdown">
<h3>Scientific Markdown</h3>
<p>Pandoc markdown has excellent support for LaTeX equations and citations. Quarto adds extensions for cross-references, figure panels, callouts, advanced page layout, and more.</p>

</section>
<section id="authoring-tools">
<h3>Authoring Tools</h3>
<p>Use your favorite tools including VS Code, RStudio, Jupyter Lab, or any text editor. Use the Quarto visual markdown editor for long-form documents.</p>

</section>
<section id="interactivity">
<h3>Interactivity</h3>
<p>Engage readers by adding interactive data exploration to your documents using Jupyter Widgets, htmlwidgets for R, Observable JS, and Shiny.</p>

</section>
<section id="websites-and-books">
<h3>Websites and Books</h3>
<p>Publish collections of documents as a blog or full website. Create books and manuscripts in both print formats (PDF and MS Word) and online formats (HTML and ePub).</p>

</section>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bob Moore, who founded Bob's Red Mill, has died (169 pts)]]></title>
            <link>https://www.nytimes.com/2024/02/13/business/bob-moore-dead.html</link>
            <guid>39366542</guid>
            <pubDate>Wed, 14 Feb 2024 04:38:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2024/02/13/business/bob-moore-dead.html">https://www.nytimes.com/2024/02/13/business/bob-moore-dead.html</a>, See on <a href="https://news.ycombinator.com/item?id=39366542">Hacker News</a></p>
Couldn't get https://www.nytimes.com/2024/02/13/business/bob-moore-dead.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Hi everyone yes, I left OpenAI yesterday (701 pts)]]></title>
            <link>https://twitter.com/karpathy/status/1757600075281547344</link>
            <guid>39365935</guid>
            <pubDate>Wed, 14 Feb 2024 03:08:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/karpathy/status/1757600075281547344">https://twitter.com/karpathy/status/1757600075281547344</a>, See on <a href="https://news.ycombinator.com/item?id=39365935">Hacker News</a></p>
Couldn't get https://twitter.com/karpathy/status/1757600075281547344: Error: Request failed with status code 400]]></description>
        </item>
        <item>
            <title><![CDATA[Andrej Karpathy Departs OpenAI (175 pts)]]></title>
            <link>https://www.theinformation.com/articles/openai-researcher-andrej-karpathy-departs</link>
            <guid>39365288</guid>
            <pubDate>Wed, 14 Feb 2024 01:35:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theinformation.com/articles/openai-researcher-andrej-karpathy-departs">https://www.theinformation.com/articles/openai-researcher-andrej-karpathy-departs</a>, See on <a href="https://news.ycombinator.com/item?id=39365288">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-testid="fade-wrapper"><p><span>Andrej Karpathy, one</span> of the founding members of OpenAI, has left the company, a spokesperson confirmed.</p><p>Karpathy, a prominent artificial intelligence researcher, was developing a product he has described as an AI assistant and worked closely with the company’s research chief, Bob McGrew. While ChatGPT has been a hit with consumers, <a href="https://www.theinformation.com/org-charts/openai?rc=c48ukx">OpenAI</a> wants to launch software that can automate complex computer-based tasks, like filling out expense reports and entering them in accounting software, The Information <a href="https://www.theinformation.com/articles/openai-shifts-ai-battleground-to-software-that-operates-devices-automates-tasks?rc=1tesbi">reported</a> last week.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[100 Years Ago, IBM Was Born (304 pts)]]></title>
            <link>https://spectrum.ieee.org/ibm-history</link>
            <guid>39365187</guid>
            <pubDate>Wed, 14 Feb 2024 01:20:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://spectrum.ieee.org/ibm-history">https://spectrum.ieee.org/ibm-history</a>, See on <a href="https://news.ycombinator.com/item?id=39365187">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-headline="100 Years Ago, IBM Was Born" data-elid="2667228583" data-post-url="https://spectrum.ieee.org/ibm-history" data-authors="James W. Cortada" data-page-title="100 Years Ago, IBM Was Born - IEEE Spectrum"><p>Happy birthday, IBM! You’re 100 years old! Or are you?</p><p>It’s true that the businesses that formed IBM began in the late 1800s. But it’s also true that a birth occurred in February 1924, with the renaming of the Computing-Tabulating-Recording Co. as the International Business Machines Corp. And a hundred years after that event, it serves as an important reminder that the world of computing and IT that IBM played a pivotal role in building has a longer history than we are likely to think. “Data processing” was coined over a century ago, while “office appliance” was in use in the 1880s. From the 19th century, through the 20th, and into the 21st, IBM was there, making HP, <a href="https://spectrum.ieee.org/tag/microsoft">Microsoft</a>, and Apple appear more like children or grandchildren of the IT world; <a href="https://spectrum.ieee.org/tag/facebook">Facebook</a>, <a href="https://spectrum.ieee.org/tag/google">Google</a>, and Twitter/X more like great-grandchildren. So let’s take a moment to contemplate the origins of an iconic corporation.</p><h2>The Assembling of IBM’s Parts</h2><p>Back in the late 19th century, as the U.S. economy gave birth to important large enterprises—telecommunications, railroads, manufacturing—the need to coordinate the work of individuals and dispersed locations led to the mechanization of information. Hence the emergence of typewriters, adding machines, and cash registers. Time-recording devices tracked when workers arrived and left, while scales weighed everything from meat at a butcher shop to industrial machine parts. For the 1890 U.S. census, Herman Hollerith’s punch-card tabulators calculated the nation’s population.</p><p><img alt="Black and white photo of women standing in line and watching as one woman turns the handle on a large dial. " data-rm-shortcode-id="0835b05aed29e173cfa4351a5613b076" data-rm-shortcode-name="rebelmouse-image" data-runner-src="https://spectrum.ieee.org/media-library/black-and-white-photo-of-women-standing-in-line-and-watching-as-one-woman-turns-the-handle-on-a-large-dial.jpg?id=51435036&amp;width=980" height="749" id="f344b" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/black-and-white-photo-of-women-standing-in-line-and-watching-as-one-woman-turns-the-handle-on-a-large-dial.jpg?id=51435036&amp;width=980" width="1200"><small placeholder="Add Photo Caption...">Workers punched in and out on a dial recorder, sold by C-T-R’s International Time Recording Co.</small><small placeholder="Add Photo Credit...">IBM Corp.</small></p><p>To provide these various products, countless little companies popped up, most of them lost to history. But at least three survived. One came into being in 1900 as the <a href="https://www.ibm.com/history/international-time-recording" rel="noopener noreferrer" target="_blank">International Time Recording Co.</a>, in Endicott, N.Y. ITR soon became known as <em>the</em> company for time-recording products in the United States and Canada. It had been formed and shaped by <a href="https://en.wikipedia.org/wiki/Charles_Ranlett_Flint" rel="noopener noreferrer" target="_blank">Charles Flint</a>, a dynamic character known for consolidating several companies into U.S. Rubber and several other companies into the American Chicle Co.—a.k.a the Chewing Gum Trust—and for his love of sailing and airplanes. </p><p>In 1901, Flint acquired the Computing Scale Co., which made tabletop scales popular with grocers in the Midwest. Over time, the company added cheese slicers and office furniture.</p><p><img alt="Black and white photo of a shop window displaying various scales and clocks. Across the top, it reads International Business Machines. " data-rm-shortcode-id="5e27d79acb17c77005289c2728254ea1" data-rm-shortcode-name="rebelmouse-image" data-runner-src="https://spectrum.ieee.org/media-library/black-and-white-photo-of-a-shop-window-displaying-various-scales-and-clocks-across-the-top-it-reads-international-business-mac.jpg?id=51435037&amp;width=980" height="832" id="aa273" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/black-and-white-photo-of-a-shop-window-displaying-various-scales-and-clocks-across-the-top-it-reads-international-business-mac.jpg?id=51435037&amp;width=980" width="1332"><small placeholder="Add Photo Caption...">This showroom in Melbourne, Australia, displayed products from all three of IBM’s founding companies: scales, time recorders, and tabulating machines.</small><small placeholder="Add Photo Credit...">IBM Corp.</small></p><p>In 1911, the Washington, D.C.–based Tabulating Machine Co. came into Flint’s orbit. Created in the 1880s and widely successful almost from its birth, TMC—maker of Hollerith’s punch-card tabulating equipment—produced the kind of breakthrough technology that large enterprises and government agencies desperately needed, to support massive undertakings like the census as well as inventory control and logistics. </p><p><img alt="Black and white photo of a wooden apparatus that looks like an upright piano and has rows of round dials across the top." data-rm-shortcode-id="5cba1a5a7ce6a5e71a65e08cbf5c55ae" data-rm-shortcode-name="rebelmouse-image" data-runner-src="https://spectrum.ieee.org/media-library/black-and-white-photo-of-a-wooden-apparatus-that-looks-like-an-upright-piano-and-has-rows-of-round-dials-across-the-top.jpg?id=51435038&amp;width=980" height="956" id="f9679" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/black-and-white-photo-of-a-wooden-apparatus-that-looks-like-an-upright-piano-and-has-rows-of-round-dials-across-the-top.jpg?id=51435038&amp;width=980" width="1280"><small placeholder="Add Photo Caption...">Herman Hollerith’s punch-card tabulators were used in the 1890 U.S. Census.</small><small placeholder="Add Photo Credit...">IBM Corp.</small></p><p>That same year, Flint smashed the three pieces together to form an entity that he unimaginatively called the Computing-Tabulating-Recording Co., or C-T-R. The scales business was okay, the time-recording business was booming, and the tabulating business had enormous potential but had yet to demonstrate it could keep up with demand. The creation of C-T-R yielded a company with promise, but the three entities didn’t coordinate or leverage each other’s assets and talents.</p><p><img alt="On the left, a black and white photo of a serious looking white man with an enormous mustache and wearing a suit. On the right a round logo with decorative letters that say CTR Co." data-rm-shortcode-id="b930b05cd23214821e4ec8f21fa51c31" data-rm-shortcode-name="rebelmouse-image" data-runner-src="https://spectrum.ieee.org/media-library/on-the-left-a-black-and-white-photo-of-a-serious-looking-white-man-with-an-enormous-mustache-and-wearing-a-suit-on-the-right-a.jpg?id=51435040&amp;width=980" height="979" id="ea878" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/on-the-left-a-black-and-white-photo-of-a-serious-looking-white-man-with-an-enormous-mustache-and-wearing-a-suit-on-the-right-a.jpg?id=51435040&amp;width=980" width="1386"><small placeholder="Add Photo Caption...">Charles Flint [left] acquired the three companies that became the Computing-Tabulating-Recording Co., or C-T-R, and he hired Thomas J. Watson Sr. to build the business. </small><small placeholder="Add Photo Credit...">IBM Corp.</small></p><p>Flint convinced his board of directors to hire a professional manager to see what could be done to grow the entire business. Enter <a href="https://www.ibm.com/history/thomas-watson-sr" rel="noopener noreferrer" target="_blank">Thomas Watson Sr.</a> in 1914. A highly successful sales executive who had recently spent two decades working at the <a href="https://www.ncr.com/about/history" rel="noopener noreferrer" target="_blank">National Cash Register Co.</a>—considered one of the best-run “cool” companies of the early 20th century. He was 42 when he arrived at C-T-R. Hollywood handsome, smart, mature, and confident in his skills as an executive working in the high-tech end of the economy, he quickly sized up the situation and went to work.</p><p><img alt="Black and white photo of a middle-aged white man in a suit sitting at his desk and looking at papers." data-rm-shortcode-id="7d79ff70f5089d086c604c34d1a4b168" data-rm-shortcode-name="rebelmouse-image" data-runner-src="https://spectrum.ieee.org/media-library/black-and-white-photo-of-a-middle-aged-white-man-in-a-suit-sitting-at-his-desk-and-looking-at-papers.jpg?id=51435043&amp;width=980" height="1010" id="ddf7c" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/black-and-white-photo-of-a-middle-aged-white-man-in-a-suit-sitting-at-his-desk-and-looking-at-papers.jpg?id=51435043&amp;width=980" width="1447"><small placeholder="Add Photo Caption...">Thomas J. Watson Sr., hired in 1914, propelled C-T-R into a high-tech data-processing enterprise.</small><small placeholder="Add Photo Credit...">IBM Corp.</small></p><p>Watson brought in technical and sales colleagues from NCR, figured out who in C-T-R to take seriously, dismissed dissidents and incompetents, and sought ways to integrate all three pieces of the company. He concluded that the greatest potential for growth lay with Hollerith’s tabulators, so he focused on growing that market. Meanwhile, ITR had a popular product and, almost as important, a presence in Europe. The scales business, though, was a ho-hum opportunity as far as Watson was concerned, so he paid far less attention to it.</p><p>Watson integrated sales—his strong suit—across all three businesses, and trained the team to become a highly skilled, professional staff. His newly hired engineers, meanwhile, improved manufacturing operations.</p><p>The start of World War I blocked sales in Europe, but not in the United States. When the United States entered the war in 1917, government and private sector demand for C-T-R’s products grew rapidly. The end of the war opened up Europe’s huge market, and smaller ones in South America and parts of Asia.</p><h2>Birth of a Corporate Culture</h2><p>Slowly and steadily, Watson was creating a new corporate culture of ethics, paired with competent sales, solid technology, and a growing international perspective. The previously disjointed three-legged operation increasingly embraced his notion of “speed, accuracy, and flexibility,” in which the customer always came first. Despite a short recession at the start of the 1920s, C-T-R was emerging as a serious and well-run high-tech data-processing enterprise.</p><p><img alt="Image of an old-fashioned stock certificate for the Computing-Tabulating-Recording Co." data-rm-shortcode-id="d874d48aee7a120930a8773b8d49467b" data-rm-shortcode-name="rebelmouse-image" data-runner-src="https://spectrum.ieee.org/media-library/image-of-an-old-fashioned-stock-certificate-for-the-computing-tabulating-recording-co.jpg?id=51435044&amp;width=980" height="973" id="ad240" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/image-of-an-old-fashioned-stock-certificate-for-the-computing-tabulating-recording-co.jpg?id=51435044&amp;width=980" width="1440"><small placeholder="Add Photo Caption...">Under Watson’s leadership, C-T-R’s revenue, staff, and product lines continued to grow. </small><small placeholder="Add Photo Credit...">IBM Corp.</small></p><p>In 1914, the company had generated US $4 million in revenues (about $120 million today) with 1,346 employees; in 1920, revenues were $14 million, with 2,731 employees. In 1922, a recession year, C-T-R brought in only $9 million, but its staff had climbed to 3,043—solid evidence that Watson considered the recession a mere bump in the road. And for the next six decades, the company continued to grow. Not until the late 1980s did the company again face declining revenues (then measured in the billions of dollars) and a shrinking labor force (then in excess of 400,000).</p><p>In 1923, Watson, his executives, and employees collectively looked toward a future without immediate threats of war, where large organizations had embraced the concept of data processing powered by mechanical devices. Watson oversaw a rapidly expanding company that was grabbing market share away from competitors. He concluded that C-T-R’s future lay in pursuing a worldwide strategy, one for which he now had enough factories, sales offices, and trained employees. To be sure—and this is an important lesson for today’s startups—it had taken him a decade to reach the point where he could sit comfortably in his office in New York and imagine the next phase of C-T-R. </p><p>As a preamble to that future, he decided that the company’s image and reputation required some burnishing. He considered what the public knew about the firm, what the company stood for, what its brand would be, and how its reputation should be shaped. It was time, Watson decided, for a name upgrade.</p><h2>IBM Gets Its Name</h2><p>On 15 February 1924, <em>The</em><em>Wall Street Journal</em> published a short article on page 3, announcing that the “International Business Machines Corp. has been incorporated under the laws of New York to take over business and assets of Computing-Tabulating-Recording Co.” That’s how the world learned about the existence of IBM (that is, unless they worked in Canada, where employees had known their employer as <a href="https://www.ibm.com/ibm/ca/en/ibmcanada100/" rel="noopener noreferrer" target="_blank">IBM since 1917</a>).</p><p><img alt="Black and white logo with the words &quot;International Business Machines&quot; shaped into a globe" data-rm-shortcode-id="229adf65709226d31ff502b363f94bbd" data-rm-shortcode-name="rebelmouse-image" data-runner-src="https://spectrum.ieee.org/media-library/black-and-white-logo-with-the-words-international-business-machines-shaped-into-a-globe.jpg?id=51435046&amp;width=980" height="755" id="3f643" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/black-and-white-logo-with-the-words-international-business-machines-shaped-into-a-globe.jpg?id=51435046&amp;width=980" width="1208"><small placeholder="Add Photo Caption...">In a 13 February 1924 letter to employees, Thomas Watson unveiled IBM’s new name.</small><small placeholder="Add Photo Credit...">IBM Corp.</small></p><p>When Watson had been remaking C-T-R, he already thought the company’s name was awkward and uninspiring, but too many other issues required his urgent attention. In early 1924, though, he decided it was time. On 13 February 1924, Watson published a letter addressed to all employees to announce the change, explaining: “Our new name is particularly adaptable and suitable to our business, in view of the fact of our increasing growth, the consistent development of additions to our line, and our products covering such a wide range in the field of business machinery.” He concluded, “We are confident that this change in name will be beneficial to the business, and that the members of our field organization will find it of direct value in introducing our company and the products which we manufacture and distribute.”</p><p>The name change was also significant to C-T-R’s customers and vendors, and IBM salesmen rushed to explain how wonderful it would be. Then there was this little story in the <em>Wall Street Journal</em> three months after IBM’s incorporation. It may not have been true, but it suggests that everything comes down to execution. The article began by stating that some people were confused by the name, which it called “unwieldy,” and maybe this episode really did happen:</p><blockquote>The other day an uptown merchant called up a friend in Wall Street and inquired if he had ever heard of a new concern called the International Business Machines Corp.<p>“We have a big order from them,” he said, “and I am trying to check up on their credit rating. My partner has just gone downtown to demand a balance sheet from them.”</p><p>“Well,” said the broker, “in their last balance sheet they showed $800,000 cash and about $8,000,000 current assets. Their position seems pretty good. How big was the order?”</p><p>“About $100,” said the merchant. “Wait a minute, I want to head off my partner.”</p></blockquote><p>Implicit in that story was the real business problem of retaining the positive reputation of C-T-R while leveraging its new name to build business momentum. Watson and his colleagues spent the rest of the 1920s and 1930s creating a brand image that reflected their positive view and plans for the future but that also translated into transactions, profits, growth, and prestige. They battled ignorance of what their products could do, invented new products, hired people, expanded operations, overcame the worldwide tragedy of the Great Depression, and endured an antitrust challenge in the 1930s, the first of several.</p><p>The name change ultimately signaled a larger transformation under way. Whether the firm should have had a different name than IBM was less important than that Thomas Watson felt it was time to declare a grander purpose for the company. The tone of his comments, the nature of the company’s communications, and the way its staff interacted with the media and with customers evolved almost as a step change after the adoption of the new name. Watson was declaring that IBM wanted to become a major player in its industry and a leading international corporation. And so it did.<br></p><p><em>This article is adapted from excerpts of the author’s award-winning book, </em><a href="https://mitpress.mit.edu/9780262547826/ibm/" target="_blank">IBM: The Rise and Fall and Reinvention of a Global Icon</a><em>(MIT Press, 2019).</em></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bioluminescent petunias now available for U.S. market (247 pts)]]></title>
            <link>https://lgrmag.com/news/light-bio-to-introduce-bioluminescent-petunias-into-u-s-market/</link>
            <guid>39365142</guid>
            <pubDate>Wed, 14 Feb 2024 01:14:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lgrmag.com/news/light-bio-to-introduce-bioluminescent-petunias-into-u-s-market/">https://lgrmag.com/news/light-bio-to-introduce-bioluminescent-petunias-into-u-s-market/</a>, See on <a href="https://news.ycombinator.com/item?id=39365142">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>


			
<p><img width="800" height="450" src="https://lgrmag.com/wp-content/uploads/2024/02/Light-Bio-to-introduce-bioluminescent-petunias-into-U.S.-market-800.png" alt="Light Bio to introduce bioluminescent petunias into U.S. market" decoding="async" fetchpriority="high" srcset="https://lgrmag.com/wp-content/uploads/2024/02/Light-Bio-to-introduce-bioluminescent-petunias-into-U.S.-market-800.png 800w, https://lgrmag.com/wp-content/uploads/2024/02/Light-Bio-to-introduce-bioluminescent-petunias-into-U.S.-market-800-300x169.png 300w" sizes="(max-width: 800px) 100vw, 800px"></p>








<div>
<p><span>Light Bio, a synthetic biology startup, announced that it is now selling its bioluminescent petunias in the U.S.</span></p>
<p><span>With support from biotech leaders such as NFX and Ginkgo Bioworks, </span><span>Light Bio is reimagining the horticultural industry by introducing a new category of plants that emit an ethereal glow.&nbsp;</span></p>
<p><span>People are fascinated with glowing plants, and scientists have now revealed how to make these much brighter. This significant achievement, </span><a href="https://www.nature.com/articles/s41592-023-02152-y" target="_blank" rel="noopener"><span>documented in Nature Methods</span></a><span>, details genetic modifications that enhance bioluminescence in a variety of plants by up to 100 times. The team of 26 scientists created the brighter plants by optimizing genes isolated from multiple species of luminous mushrooms.</span></p>
<p><span>The new research builds on </span><span>an earlier discovery </span><span>for creating continuously glowing plants by inserting DNA obtained from the mushrooms. Those researchers had revealed a surprising similarity between mushroom bioluminescence and plant metabolism, allowing for more visible light than was previously possible. In this new report, the scientists have adapted the inserted genes to further boost luminescence.</span></p>
<p><span>Beginning in April, glowing petunias will be available under the brand Firefly Petunia, so named because the bright buds resemble fireflies. Last September, the </span><span>USDA reportedly determined</span> <span>through its independent evaluation that Light Bio’s genetically engineered Firefly Petunia may be safely grown and bred in the U.S.</span></p>
<p><span>Light Bio is taking orders at </span><a href="http://www.light.bio/" target="_blank" rel="noopener"><span>light.bio</span></a><span>.</span></p>

<br clear="all">

</div>
<br clear="all">


<br clear="all">


		
							

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Play the game I'm developing directly on its website (257 pts)]]></title>
            <link>https://athenacrisis.com</link>
            <guid>39365135</guid>
            <pubDate>Wed, 14 Feb 2024 01:13:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://athenacrisis.com">https://athenacrisis.com</a>, See on <a href="https://news.ycombinator.com/item?id=39365135">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Protein biomarkers predict dementia 15 years before diagnosis in new study (214 pts)]]></title>
            <link>https://warwick.ac.uk/newsandevents/pressreleases/?newsItem=8a17841a8d79730b018d9e2bbb0e054b</link>
            <guid>39365104</guid>
            <pubDate>Wed, 14 Feb 2024 01:09:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://warwick.ac.uk/newsandevents/pressreleases/?newsItem=8a17841a8d79730b018d9e2bbb0e054b">https://warwick.ac.uk/newsandevents/pressreleases/?newsItem=8a17841a8d79730b018d9e2bbb0e054b</a>, See on <a href="https://news.ycombinator.com/item?id=39365104">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="news_8a17841a8d79730b018d9e2bbb0e054b">

                <div><p>In the largest study of its kind, scientists have shown how protein “biomarkers” predict dementia 15 years before diagnosis.</p></div>
<div><p>The research, published today in Nature Aging, shows how profiles of proteins in the blood accurately predict dementia up to 15 years prior to clinical diagnosis. These are known as biomarkers, which are molecules found in blood, other body fluids, or tissues that is a sign of a normal or abnormal process, or of a condition or disease.</p></div>
<div><p>In the study, scientists from The University of Warwick and Fudan University, Shanghai used the largest cohort of blood proteomics and dementia to date, including blood samples from 52,645 healthy participants recruited from UK Biobank – a population-based study cohort.</p></div>
<div><p>Blood samples collected between 2006 and 2010 were frozen and then analysed 10-15 years later by the research team who analysed them between April 2021 and February 2022. Until March 2023, a total of 1,417 participants went on to develop dementia – and these people’s blood showed dysregulation of protein biomarkers.</p></div>
<div><p>Of 1,463 proteins analysed, aided by with a type of artificial intelligence known as machine learning, 11 proteins were identified and combined as a protein panel, which the researchers have shown to be highly accurate at predicting future dementia. Further incorporation of conventional risk factors of age, sex, education level and genetics, showed for the first time the high accuracy of the predictive model, measured at over 90%*, indicating its potential future use in community-based dementia screening programs.</p></div>
<div><p>Proteins (for example Glial Fibrillary acidic protein, GFAP) had previously been identified as potential biomarkers for dementia in smaller studies, but this new research was much larger and conducted over several years. Known as a longitudinal analysis (a study conducted on a sample of participants over a number of years), the researchers were able to show the differences and trajectories between those with dementia and controls across 15 years.</p></div>
<div><p>An early diagnosis is critical for those with dementia. New drug technology can slow, or even reverse the progress of Alzheimer’s, but only if the disease is detected early enough. The drug lecanemab is one of two new treatments for the disease.</p></div>
<div><p>Lead author Professor Jianfeng Feng, from the Department of Computer Science, University of Warwick, hopes future drugs may be developed to interact with the proteins identified in the study.</p></div>
<div><p>Professor Feng emphasised that the combination of artificial intelligence and protein analysis offers a promising avenue for precision medicine. This is highly important for screening mid-aged to older individuals within the community who are at high risk of dementia. “This model could be seamlessly integrated into the NHS and used as a screening tool by GPs”, said Professor Feng.</p></div>
<div><p>Professor Wei Cheng, a co-corresponding author from Fudan University, explained that this research builds on the team’s previously developed dementia prediction model which used variables, such as age, presence of a certain gene and mother’s age at death. “Compared to our previous work, the newly developed protein-based model is obviously a breakthrough”, he said.</p></div>
<div><p>Another corresponding author Professor Jintai Yu, a neurovegetative disease specialist from Fudan University, added: “The proteomic biomarkers are more easily to access and non-invasive, and they can substantially facilitate the application of large-scale population screening”.</p></div>
<div><p>He also pointed drawbacks of previous risk models, which were primarily depended on intricate and difficult-to-obtain biomarkers using procedures such as lumbar puncture or complex imaging methods meaning their widespread use is hindered because of the invasive procedures and the high cost of carrying them out.</p></div>

<p><b>Notes to Editors</b></p>
<div><p>The University of Warwick signed a Memorandum of Understanding with Fudan University in 2022 and the two Universities work together designing and developing new research projects and run staff and student exchanges. </p></div>
<div><p>*The Area Under the Curve (AUC) figure is used to measure how good a model performs. A model whose predictions are 100% wrong has an AUC of 0.0; one whose predictions are 100% correct has an AUC of 1.0. this study had an AUC of over 0.9.</p></div>
<p><b>Case studies</b></p>
<div><p>The University works closely with people with dementia and their families at a Dementia Café, set up by Warwick Medical School. Should you wish to speak to a case study, please get in touch.</p></div>
<p><span><b>Media contact</b></span><span>&nbsp;</span></p>
<p><span>University of Warwick press office contact:</span><span>&nbsp;</span></p>
<p><span>Annie Slinn 07876876934</span><span>&nbsp;</span></p>
<p><span>Communications Officer | Press &amp; Media Relations | University of Warwick Email: </span><a href="mailto:annie.slinn@warwick.ac.uk" target="_blank" rel="noopener"><span>annie.slinn@warwick.ac.uk</span><span>Link opens in a new window</span></a><span>&nbsp;<p><strong>12 February 2024</strong></p></span></p>



            
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Handwriting but not typewriting leads to widespread brain connectivity (283 pts)]]></title>
            <link>https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2023.1219945/full</link>
            <guid>39364576</guid>
            <pubDate>Wed, 14 Feb 2024 00:00:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2023.1219945/full">https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2023.1219945/full</a>, See on <a href="https://news.ycombinator.com/item?id=39364576">Hacker News</a></p>
<div id="readability-page-1" class="page"><div> <h2>Introduction</h2>
<p>Digital devices are more and more replacing traditional handwriting (<a href="#ref32">Longcamp et al., 2006</a>; <a href="#ref25">Kiefer et al., 2015</a>), and as both writing and reading are becoming increasingly digitized in the classroom, we need to examine the implications of this practice (<a href="#ref35">Mangen and Balsvik, 2016</a>; <a href="#ref39">Patterson and Patterson, 2017</a>). Using a keyboard is now often recommended for young children as it is less demanding and frustrating (<a href="#ref15">Cunningham and Stanovich, 1990</a>; <a href="#ref17">Fears and Lockman, 2018</a>), allowing them to express themselves in written form earlier (<a href="#ref22">Hultin and Westman, 2013</a>). Be that as it may, handwriting training has not only been found to improve spelling accuracy (<a href="#ref15">Cunningham and Stanovich, 1990</a>) and better memory and recall (<a href="#ref32">Longcamp et al., 2006</a>; <a href="#ref53">Smoker et al., 2009</a>; <a href="#ref36">Mueller and Oppenheimer, 2014</a>), but also to facilitate letter recognition and understanding (<a href="#ref33">Longcamp et al., 2005</a>, <a href="#ref31">2008</a>; <a href="#ref30">Li and James, 2016</a>). Such benefits for learning have been reported irrespective of when writing by hand using a traditional pen or pencil or using a digital pen (<a href="#ref38">Osugi et al., 2019</a>). Also, brain research shows that it is not just any motor activity that facilitates learning, but that accurately coordinating the complex hand movements while carefully shaping each letter when using a pen, is crucial (<a href="#ref40">Pei et al., 2021</a>). Apparently, the pen causes different underlying neurological processes that provide the brain with optimal conditions for learning and remembering (<a href="#ref4">Askvik et al., 2020</a>).</p>
<p>Recent findings in neuroscience reveal that neural processes are not as localized and static as is commonly believed, but that the brain is organized in a highly dynamic functional manner (<a href="#ref34">Lopes da Silva, 1991</a>; <a href="#ref52">Singer, 1993</a>). Under normal circumstances, several brain systems are continually working together (<a href="#ref12">Buzsáki, 2006</a>), showing an extremely flexible organization with structurally different neural tissue being involved in neural circuits that are only temporarily assembled so as to enable a given task (<a href="#ref16">Edelman and Gally, 2013</a>; <a href="#ref57">Van der Weel et al., 2019</a>). In such a view, neurons can change function entirely when incorporated in different systems (<a href="#ref2">Anderson, 2014</a>). <a href="#ref10">Bullmore and Sporns (2009)</a> refer to this type of flexible organization of the brain as functional connectivity as against structural connectivity.</p>
<p>Electroencephalography is well suited to studying brain electrical activity as a function of handwriting and typewriting in the millisecond scale. It permits the investigation of changes in the status of the underlying active networks (<a href="#ref34">Lopes da Silva, 1991</a>) and can reveal the everchanging spatial patterns of activations that are specific to any given task (<a href="#ref45">Pfurtscheller et al., 1996</a>). In particular, studies of cortical oscillations detected with high-density EEG are now considered an indispensable aspect of contemporary systems neuroscience (<a href="#ref18">Fröhlich, 2016</a>).</p>
<p>Brain oscillations can be considered as the interplay between the cortex and the thalamus and are generated by changes involved in the control of oscillations in neural networks (<a href="#ref43">Pfurtscheller and Lopes da Silva, 1999</a>). The complex interactions and the resulting particular frequencies are thought to reflect distinct cognitive processes (<a href="#ref29">Klimesch et al., 1994</a>; <a href="#ref6">Berens and Horner, 2017</a>). The temporal organization of neuronal firing is crucial as it is assumed to be fundamental when forming long-term memories in the hippocampus (<a href="#ref6">Berens and Horner, 2017</a>).</p>
<p>Frequency-specific changes in EEG recordings can be observed as event-related synchronization (ERS) or event-related desynchronization (ERD; <a href="#ref42">Pfurtscheller and Aranibar, 1977</a>; <a href="#ref43">Pfurtscheller and Lopes da Silva, 1999</a>). Spectral analyses are used to detect differences in a given frequency band (<a href="#ref44">Pfurtscheller et al., 1994</a>; <a href="#ref49">Salmelin and Hari, 1994</a>; <a href="#ref28">Klimesch et al., 1996</a>), by calculating the temporal dynamics of EEG oscillations and quantifying event-related amplifications and/or suppressions of rhythms.</p>
<p>A recent EEG-study from our lab showed that drawing by hand causes more activity and involves larger areas in the brain as opposed to typing on a keyboard (<a href="#ref56">Van der Meer and Van der Weel, 2017</a>). We concluded that the involvement of fine and intricate hand movements in notetaking, in contrast with pressing keys on a keyboard that all require the same simple finger movement, may be more advantageous for learning (<a href="#ref56">Van der Meer and Van der Weel, 2017</a>). A follow-up study observed event-related synchronized activity in the theta range in both children and students in parietal and central brain regions, but only when writing by hand (<a href="#ref4">Askvik et al., 2020</a>). As these studies have found evidence that writing by hand facilitates learning, the present study further investigated the neurobiological differences related to cursive writing and typewriting in the young adult brain. Specifically, we investigated how the various brain regions interconnect via neural networks when writing by hand as opposed to typing on a keyboard using frequency modulation and the latest in brain connectivity analysis (c.f., <a href="#ref54">Solomon et al., 2017</a>).</p> <h2>Methods</h2>
<h3>Participants</h3>
<p>Forty university students in their early twenties took part in the study at the Developmental Neuroscience Laboratory, Norwegian University of Science and Technology (NTNU). HD EEG data from 36 students were of good enough quality and sufficiently artifact-free to be included in the analyses. The data from 12 adult participants were already used in analyses in the time-frequency domain (<a href="#ref4">Askvik et al., 2020</a>). The present study performed a brain connectivity analysis to investigate the underlying neural networks involved in tasks of handwriting and typewriting. Participants were mostly students and were recruited at the university campus. They received a $15 cinema ticket for taking part. To avoid crossover effects between the two hemispheres, only right-handed participants were included, as determined by the Edinburgh Handedness Inventory (<a href="#ref37">Oldfield, 1971</a>). Allowing the use of (the fingers of) both hands would cause many unforeseen effects on the brain, which would make it hard to interpret the results. Participants gave their informed written consent, and it was made clear that they could withdraw from the experiment at any time without consequences. The Regional Committee for Medical and Health Ethics (Central Norway) approved the study.</p>
<h3>Experimental stimuli and EEG data acquisition</h3>
<p>E-prime 2.0 was used to individually display 15 different Pictionary words on a Microsoft Surface Studio. The participants used a digital pen to write in cursive by hand directly on the touchscreen, and a keyboard to typewrite the presented words.</p>
<p>The experiment comprised a total of 30 trials, where each word appeared in two different conditions, presented in a randomized order. For each trial, participants were instructed to either (a) <i>write in cursive</i> with their right hand the presented word with a digital pen directly on the screen, or (b) <i>type</i> the presented word using the right index finger on the keyboard. Before each trial, the instruction <i>write</i> or <i>type</i> appeared before one of the target words appeared, and the participants were given 25 s to either write by hand or type the word multiple times, separated by a space. EEG data were recorded only during the first 5 s of each trial. To prevent artifacts produced by head and eye movements caused by shifting gaze between the screen and the keyboard, typed words did not appear on the screen while the participant was typewriting. The writings produced by the participants (see <a href="#fig1">Figure 1</a> for example) were stored for offline analyses.</p>
  <div><a href="https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g001.jpg" name="figure1" target="_blank">
  <picture>
    <source type="image/webp" srcset="https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g001.jpg 410w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g001.jpg 290w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g001.jpg 370w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g001.jpg 480w" sizes="(max-width: 563px) 480px, (max-width: 1024px) 370px, (max-width: 1441px) 290px, 410px">
    <img src="https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g001.jpg" srcset="https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g001.jpg 410w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g001.jpg 290w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g001.jpg 370w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g001.jpg 480w" sizes="(max-width: 563px) 480px, (max-width: 1024px) 370px, (max-width: 1441px) 290px, 410px" alt="www.frontiersin.org" id="fig1" loading="lazy" onerror="this.onerror=null;this.src='https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g001.jpg';this.srcset='https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g001.jpg';this.previousElementSibling.remove();">
  </picture>
</a>
<p><b>Figure 1</b>. Task design, behavioral performance, and sequence of the connectivity analyses. Visually presented words were either written by hand with a digital pen or typed on a keyboard while participants were wearing a 256-channel sensor array. EEG recordings were analyzed in terms of their functional connectivity, resulting in detailed network measures.</p></div>  
<p>A Geodesic Sensor Net (GSN; <a href="#ref55">Tucker et al., 1994</a>) with 256 evenly distributed electrodes was used to record EEG activity from the participant’s scalp at 500 Hz. The signals were amplified using a high-input EGI amplifier (<a href="#ref46">Picton et al., 2000</a>).</p>
<h3>Procedure</h3>
<p>On arrival in the lab, a consent form with all necessary information was given to the participants to sign. While the participant completed the handedness test, an appropriately sized net was soaked in a saline electrolyte for 15 min to optimize electrical conductivity. The participant was sitting comfortably in an adjustable chair in front of a table. The screen was placed on the table as closely as possible to the participant. A keyboard was also placed in a preferred position for the participant, and a digital pen was used for writing on the touchscreen. A pre-test was completed before the experiment started, where one of the experimenters was present in the room with the participant.</p>
<h3>Brain data pre-analyses</h3>
<p>Brain Electrical Source Analysis (BESA version 7.0) research software and BESA Connectivity (version 1.0) were used to analyze the EEG data. Epoch and filter settings were the same as in <a href="#ref4">Askvik et al. (2020)</a>.</p>
<p>Channels contaminated by movement artifacts were either removed or interpolated using spherical spline interpolation (<a href="#ref41">Perrin et al., 1989</a>; <a href="#ref46">Picton et al., 2000</a>). Up to 10% of channels could be defined as bad. Artifact correction was applied using manual and semi-automatic artifact correction with fitting spatial filters (<a href="#ref7">Berg and Scherg, 1994</a>; <a href="#ref23">Ille et al., 2002</a>; <a href="#ref19">Fujioka et al., 2011</a>).</p>
<p>The mean number of accepted trials out of 15 was 14.1 (<i>SD</i> = 1.1) for handwriting and 13.3 (<i>SD</i> = 1.3) for typewriting. To analyze oscillatory brain activity, a time-frequency analysis in brain space was then performed on accepted trials, see <a href="#ref4">Askvik et al. (2020)</a> for details. Optimal separation of brain activity was achieved using source montages derived from a multiple source model where waveforms separated different brain activities (<a href="#ref50">Scherg and Berg, 1991</a>). Using this procedure, the time-frequency content of different brain regions can be separated even if their activities severely overlap at the surface of the scalp (<a href="#ref21">Hoechstetter et al., 2004</a>). Then, the connectivity measure of Coherence was applied, resulting in a symmetric connectivity matrix with the upper and lower triangular matrix showing pairwise clusters symmetrical to the diagonal.</p>
<h3>Statistical analyses</h3>
<p>Probability of significance in connectivity values was tested with BESA Statistics 2.0, where connectivity measures for all participants were computed and the significant connectivity regions were used as guides in finding the extent of connectivity between the two experimental conditions of writing and typing. A combination of permutation tests and data clustering was employed. Permutation tests were applied to each set of time samples belonging to one frequency bin (<a href="#ref51">Simes, 1986</a>). Data clusters that showed a significant effect between conditions were assigned initial cluster values. Using within-group ANOVA’s, these initial cluster values were passed through permutation and assigned new clusters so that the significance of the initial cluster could be determined. A Bonferroni correction was used for multiple comparisons. As in <a href="#ref4">Askvik et al. (2020)</a>, cluster alpha, the significance level for building clusters in time and/or frequency, was set at 0.01 and the number of permutations was set at 10.000. Low- and high cut-offs for frequency were kept at 2 Hz and 60 Hz respectively, and epochs were set from −250 to 4,500 ms.</p> <h2>Results</h2>
<p>High-density EEGs were recorded during the experimental handwriting and typing conditions. Artifacts were removed from the raw EEG recordings, then the inverse problem was solved by using a 4-shell ellipsoidal head model to analyze the brain regions of interest. The time series of the reconstructed sources were obtained and transformed into the frequency domain using complex demodulation. The functional connectivity between the reconstructed sources was computed using the coherence method. A high-resolution functional connectivity matrix was obtained, and the corresponding functional brain network was visualized. Network measures were then extracted from the network (<a href="#fig1">Figure 1</a>).</p>
<p>A time-frequency display is shown for three important brain regions in <a href="#fig2">Figure 2</a> where the power/amplitude for each time is normalized to the mean power/amplitude of the baseline epoch for that frequency. The x-axis shows the time relative to the event, the y-axis shows the frequencies. The intensities are displayed as a color-coded plot.</p>
  <div><a href="https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g002.jpg" name="figure2" target="_blank">
  <picture>
    <source type="image/webp" srcset="https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g002.jpg 410w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g002.jpg 290w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g002.jpg 370w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g002.jpg 480w" sizes="(max-width: 563px) 480px, (max-width: 1024px) 370px, (max-width: 1441px) 290px, 410px">
    <img src="https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g002.jpg" srcset="https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g002.jpg 410w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g002.jpg 290w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g002.jpg 370w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g002.jpg 480w" sizes="(max-width: 563px) 480px, (max-width: 1024px) 370px, (max-width: 1441px) 290px, 410px" alt="www.frontiersin.org" id="fig2" loading="lazy" onerror="this.onerror=null;this.src='https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g002.jpg';this.srcset='https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g002.jpg';this.previousElementSibling.remove();">
  </picture>
</a>
<p><b>Figure 2</b>. Grand average coherence results. Displayed are only three selected connectivity areas of interest for the two experimental conditions handwriting and typewriting (left panels), together with the difference in coherence between writing and typing and their permutation results (right panels). Connectivity areas of large significant difference between handwriting and typewriting included brain regions CR-PM (central right-parietal midline, top two panels on the left) and CL-PM (central left-parietal midline, middle two panels on the left), as well as CM-CR (central midline-central right, bottom two panels on the left), in frequencies ranging from theta (2 Hz) and up to gamma (60 Hz). The x-axes display the time interval from baseline to 4,500 ms of recordings of the trial. The signal magnitude reflects the estimated neural connectivity strength between the various brain areas during the experimental conditions compared to baseline activity (−250 to 0 ms). Positive connectivity is shown as (shades of) red-colored contours in handwriting/typewriting plots (panels on the left) and difference plots between handwriting and typewriting/permutation results (panels on the right). Positive connectivity is significantly more prominent in lower frequencies (theta 3.5–7.5 Hz and alpha 8–12.5) for handwriting (0 ≤ <i>p</i> &lt; 0.05, see also <a href="#fig4">Figure 4</a>).</p></div>  
<p><a href="#fig2">Figure 2</a> displays the results of grand average coherence results from just three selected connectivity areas of interest for clarity, for the two experimental conditions handwriting and typewriting (left panels), together with the difference in coherence between writing and typing and their permutation results (right panels). Connectivity areas of large significant difference between writing and typing included central and parietal brain regions in frequencies ranging from theta (2 Hz) and up to gamma (60 Hz). The signal magnitude reflects estimated connectivity strength between brain areas compared to baseline (−250 to 0 ms) activity. Positive connectivity patterns are shown in (shades of) red. In the central and parietal areas, positive coherence patterns were more prominent in the lower frequencies (theta 3.5–7.5 Hz and alpha 7.5–12.5 Hz) for handwriting as opposed to typewriting. For handwriting, this activity appeared between 1,000 to 2000 ms and lasted throughout the trial.</p>
<h3>The connectivity matrix of writing over typing</h3>
<p>Comparisons between the two conditions handwriting and typewriting were computed for each participant with time-frequency displays (changes in amplitude over time). TSE displays were limited between frequency cut-offs of 2–60 Hz, while frequency and time were sampled at 1 Hz and 50 ms, respectively. Symmetric connectivity measures were then obtained from BESA Connectivity and a high-resolution functional connectivity matrix between the reconstructed sources was computed using the coherence method (<a href="#ref48">Rosenberg et al., 1989</a>). Here, the number of in-phase components of two brain source signals at a specific frequency were described, and the corresponding functional brain network was visualized in <a href="#fig3">Figure 3</a>. Finally, network measures were extracted from the network and presented in <a href="#fig4">Figure 4</a>.</p>
  <div><a href="https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g003.jpg" name="figure3" target="_blank">
  <picture>
    <source type="image/webp" srcset="https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g003.jpg 410w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g003.jpg 290w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g003.jpg 370w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g003.jpg 480w" sizes="(max-width: 563px) 480px, (max-width: 1024px) 370px, (max-width: 1441px) 290px, 410px">
    <img src="https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g003.jpg" srcset="https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g003.jpg 410w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g003.jpg 290w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g003.jpg 370w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g003.jpg 480w" sizes="(max-width: 563px) 480px, (max-width: 1024px) 370px, (max-width: 1441px) 290px, 410px" alt="www.frontiersin.org" id="fig3" loading="lazy" onerror="this.onerror=null;this.src='https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g003.jpg';this.srcset='https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g003.jpg';this.previousElementSibling.remove();">
  </picture>
</a>
<p><b>Figure 3</b>. Connectivity results of writing over typing. <b>(A)</b> Grand average connectivity matrix results show widespread theta/alpha coherence results (in red) between PL, PM, PR and CL, CM, CR brain regions when writing by hand, but not when typing. The y-axes display frequencies from 2 to 60 Hz. The x-axes display the time interval from baseline to 4,500 ms of recordings of the trial for all involved brain regions. The signal magnitude (coherence) reflects the estimated neural connectivity between the various brain regions during the writing condition compared to baseline activity (−250 to 0 ms). <b>(B)</b> Further illustration of connectivity patterns revealing a concentration of 16 significant connections for handwriting compared to typewriting. Connection lines in red indicate connectivity in the theta range whereas lines in blue indicate connectivity in the alpha range. Levels of significance in connectivity strength for handwriting, but not for typewriting are further indicated by solid (&lt;0.0001), dashed (&lt;0.005), and dotted (&lt;0.05) connection lines.</p></div>  
 <div><a href="https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g004.jpg" name="figure4" target="_blank">
  <picture>
    <source type="image/webp" srcset="https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g004.jpg 410w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g004.jpg 290w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g004.jpg 370w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g004.jpg 480w" sizes="(max-width: 563px) 480px, (max-width: 1024px) 370px, (max-width: 1441px) 290px, 410px">
    <img src="https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g004.jpg" srcset="https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g004.jpg 410w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g004.jpg 290w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g004.jpg 370w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g004.jpg 480w" sizes="(max-width: 563px) 480px, (max-width: 1024px) 370px, (max-width: 1441px) 290px, 410px" alt="www.frontiersin.org" id="fig4" loading="lazy" onerror="this.onerror=null;this.src='https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g004.jpg';this.srcset='https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g004.jpg';this.previousElementSibling.remove();">
  </picture>
</a>
<p><b>Figure 4</b>. Symmetric connectivity matrix with <i>t</i>-values <b>(A)</b> and significance Table <b>(B)</b> with significant data clusters in the various sources of interest when handwriting is compared to typewriting in all participants. Thirty-two significant cluster differences marked in orange in <b>(A)</b> and fully described in <b>(B)</b> were found in the matrix and came out particularly significant in the parietal left (PL), parietal midline (PM), and parietal right (PR) areas.</p></div>  
<p><a href="#fig3">Figure 3A</a> displays the grand average connectivity matrix for writing compared to typing. The matrix offers a compact description of the pairwise connectivity between all separate regions of the brain. Throughout the matrix there is evidence for widespread theta/alpha coherence results (in red) particularly between areas parietal-right, parietal-mid, and parietal-left and between areas central-right and central-left. These connectivity patterns are further illustrated in <a href="#fig3">Figure 3B</a> revealing a concentration of no less than 32 significant clusters (see <a href="#fig4">Figure 4</a> for details) for handwriting, but not for typewriting. A pair of clusters will represent a single link between the corresponding pair of sources. The 32 significant clusters thus represent 16 significant connections.</p>
<h3>Main statistical effects</h3>
<p>Analyses were run to test for statistical differences in brain activity between handwriting and typewriting. <a href="#fig4">Figure 4</a> displays the detailed effects (<i>t</i>-tests) of the permutation results. These results showed 32 significant cluster differences between the two experimental conditions. The <i>t</i>-tests revealed significant differences in connectivity primarily in the theta (3.5–7.5 Hz) and alpha (8–12.5 Hz) range within three positive clusters (in orange), namely in the parietal left (PL), parietal midline (PM), and parietal right (PR) areas (see also <a href="#fig3">Figure 3</a>). These positive clusters suggest separate processes (differences in band power) between handwriting and typewriting mainly in the parietal but also in the central regions.</p>
<p>As can be seen in <a href="#fig4">Figure 4</a>, significant clusters of differences in band power were found mainly in parietal and central brain regions.</p>
<h3>Network measures</h3>
<p><a href="#fig5">Figure 5</a> shows the adjacency matrix for handwriting in the form of a hub, nodes, and edges of a simplified theoretical network (<a href="#fig5">Figure 5A</a>). Hubs have a higher degree of involvement in the network than nodes as expressed through their functional connectivity values (edges). <a href="#fig5">Figure 5B</a> shows the brain connectivity network results of handwriting compared to typewriting in this experiment. Proposed hubs (in red, ≥ 4 departures/arrivals) and nodes (in black, ≤ 3 departures/arrivals) interacting between brain regions PL, PM, PR and CL, CM, CR show widespread theta/alpha coherence patterns indicating stronger connectivity when writing as opposed to typing (<a href="#fig5">Figure 5C</a>).</p>
  <div><a href="https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g005.jpg" name="figure5" target="_blank">
  <picture>
    <source type="image/webp" srcset="https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g005.jpg 410w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g005.jpg 290w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g005.jpg 370w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g005.jpg 480w" sizes="(max-width: 563px) 480px, (max-width: 1024px) 370px, (max-width: 1441px) 290px, 410px">
    <img src="https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g005.jpg" srcset="https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g005.jpg 410w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g005.jpg 290w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g005.jpg 370w, https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g005.jpg 480w" sizes="(max-width: 563px) 480px, (max-width: 1024px) 370px, (max-width: 1441px) 290px, 410px" alt="www.frontiersin.org" id="fig5" loading="lazy" onerror="this.onerror=null;this.src='https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g005.jpg';this.srcset='https://www.frontiersin.org/files/Articles/1219945/fpsyg-14-1219945-HTML-r2/image_m/fpsyg-14-1219945-g005.jpg';this.previousElementSibling.remove();">
  </picture>
</a>
<p><b>Figure 5</b>. The adjacency matrix for handwriting. <b>(A)</b> Hub, nodes, and edges of a simplified theoretical network. <b>(B)</b> Brain connectivity network of handwriting compared to typewriting in this experiment. <b>(C)</b> Hubs (in red, ≥ 4 departures/arrivals) and nodes (in black, ≤ 3 departures/arrivals) interacting between brain regions PL, PM, PR and CL, CM, CR show widespread theta/alpha connectivity patterns when writing by hand, but not when typing.</p></div>   <h2>General discussion</h2>
<p>This study investigated brain electrical connectivity as a function of handwriting and typewriting using high-density EEG in young adults. Participants used a digital pen to write visually presented words directly on a touchscreen and used a keyboard to type the words. Going beyond our previous study where we reported synchronized theta oscillations in parietal and central brain regions when children and students wrote by hand (<a href="#ref4">Askvik et al., 2020</a>), the present study performed connectivity analyses on the brain data of 36 students to explore underlying differences in coherence patterns when participants were typing versus writing by hand.</p>
<p>Focusing on brain connectivity that has shown to facilitate learning and memory (<a href="#ref43">Pfurtscheller and Lopes da Silva, 1999</a>), we investigated parietal and central areas in specific frequency bands. These brain areas have been associated with attentional mechanisms and cognitive processes in visual perception (<a href="#ref44">Pfurtscheller et al., 1994</a>; <a href="#ref59">Vilhelmsen et al., 2019</a>) and language (<a href="#ref9">Brownsett and Wise, 2010</a>; <a href="#ref5">Benedek et al., 2014</a>), and have strong links to sensorimotor cortex (<a href="#ref58">Velasques et al., 2007</a>). We set out to investigate whether it is actually the act of forming the letters by hand itself that brings about larger connectivity in the brain, since perceptual, motor, and higher cognitive areas are more involved during handwriting as opposed to typewriting.</p>
<h3>Increased connectivity in theta/alpha range for handwriting</h3>
<p>The present findings revealed increased connectivity for handwriting over typewriting, suggesting that different underlying cognitive processes are involved in the two tasks. Increased connectivity within the theta (3.5–7.5 Hz) and alpha (8–12.5 Hz) frequency bands has been linked to mechanisms underlying sensorimotor integration (<a href="#ref8">Bland and Oddie, 2001</a>). As increased connectivity in the brain was observed only when writing by hand and not when simply pressing keys on the keyboard, our findings can be taken as evidence that handwriting promotes learning. Interestingly, the increased connectivity between the various brain regions seems to be linked to the specific sensorimotor processes that are so typical in handwriting.</p>
<p>The theta/alpha connectivity patterns found in the present study may indicate that different neural networks are involved in handwriting and typewriting. Interestingly, whereas connectivity in the alpha band is considered highly task-specific and is said to correspond to long-term memory performance, theta connectivity seems to be related to working memory and the ability to apprehend novel information (<a href="#ref29">Klimesch et al., 1994</a>, <a href="#ref28">1996</a>, <a href="#ref27">2001</a>; <a href="#ref26">Klimesch, 1999</a>; <a href="#ref47">Raghavachari et al., 2001</a>; <a href="#ref14">Clouter et al., 2017</a>). Thus, the enhanced brain connectivity for handwriting appears not to be related to differences in muscular involvement. It has also been proposed that hippocampal activity is reflected within the theta band (<a href="#ref29">Klimesch et al., 1994</a>), adding further support for the benefits of handwriting in terms of learning and memory formation.</p>
<p>Lower frequencies are considered especially suited for facilitating communication over longer distances in the brain, and are often reported to “gate” the occurrence of faster oscillations, for example when theta oscillations in humans are proposed to gate gamma (&gt; 30 Hz) oscillations (<a href="#ref13">Canolty et al., 2006</a>; <a href="#ref20">Halgren et al., 2018</a>). In general, this theta-to-gamma cross-frequency coupling can be linked to gamma networks desynchronizing and theta networks synchronizing during encoding, retrieval, and episodic memory formation (<a href="#ref11">Burke et al., 2013</a>). Others have suggested that theta connectivity activity (see <a href="#fig3">Figure 3</a>) is positively correlated with a brain region’s gamma power, suggesting a potent low-frequency mechanism for communication between brain regions (<a href="#ref54">Solomon et al., 2017</a>). Exploring these interactions may disclose the relationship between a brain region’s functional connectivity and local processing. Our results reflect such a low-frequency mechanism for interregional communication. Present findings of theta synchrony for handwriting suggest that low-frequency connections support the integration of information during memory formation, and follow from earlier studies that have reported low-frequency entrainment to be essential to cognition (<a href="#ref54">Solomon et al., 2017</a>).</p>
<h3>The importance of handwriting practice in a learning environment</h3>
<p>Handwriting requires fine motor control over the fingers, and it forces students to pay attention to what they are doing. Typing, on the other hand, requires mechanical and repetitive movements that trade awareness for speed. Our results reveal that whenever handwriting movements are included as a learning strategy, more of the brain gets stimulated, resulting in the formation of more complex neural network connectivity. It appears that the movements related to typewriting do not activate these connectivity networks the same way that handwriting does. The concurrent spatiotemporal pattern from vision, motor commands, and proprioceptive feedback provided through fine hand and finger movements, is lacking in typewriting, where only a simple key press is required to produce the entire wanted form (<a href="#ref32">Longcamp et al., 2006</a>; <a href="#ref24">James, 2010</a>; <a href="#ref60">Vinci-Booher et al., 2016</a>, <a href="#ref61">2021</a>). In the present study, participants only used their right index finger for typing to prevent undesired crossover effects between the two hemispheres.</p>
<p>Thus, the ongoing substitution of handwriting by typewriting in almost every educational setting may seem somewhat misguided as it could affect the learning process in a negative way (<a href="#ref1">Alonso, 2015</a>; <a href="#ref35">Mangen and Balsvik, 2016</a>; <a href="#ref3">Arnold et al., 2017</a>). The present findings suggest that the intricate and precisely controlled handwriting movements have a beneficial impact on the brain’s connectivity patterns related to learning and remembering. The present study did not find evidence of such positive activation patterns when using a keyboard.</p>
<p>Even though maintaining handwriting practice in school is crucial, it is also important to keep up in the ever-developing digital world. Children should receive handwriting training at school to learn to write by hand successfully, and, at the same time learn to use a keyboard, depending on the task at hand. The present study shows that the neural connectivity patterns underlying handwriting and typewriting are distinctly different. Hence, being aware of when to write by hand or use a digital device is crucial, whether it is to take lecture notes to learn new concepts or to write longer essays.</p> <h2>Data availability statement</h2>
<p>The raw data supporting the conclusions of this article will be made available by the authors, without undue reservation.</p> <h2>Ethics statement</h2>
<p>The studies involving human participants were reviewed and approved by the Norwegian Data Protection Services for Research and by the Regional Committee for Medical and Health Ethics (Central Norway). The participants gave their written informed consent. Written informed consent was obtained from the individual(s) for the publication of any identifiable images or data included in this article.</p> <h2>Author contributions</h2>
<p>FW and AM contributed equally to all aspects of the study. All authors contributed to the article and approved the submitted version.</p> <h2>Funding</h2>
<p>The APC for this article was covered under one of NTNU's open publication agreements.</p> <h2>Conflict of interest</h2>
<p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p> <h2>Publisher’s note</h2>
<p>All claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. Any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher.</p> <h2>References</h2>
<div>
<p><a name="ref1" id="ref1"></a>Alonso, M. A. P. (2015). Metacognition and sensorimotor components underlying the process of handwriting and keyboarding and their impact on learning: an analysis from the perspective of embodied psychology. <i>Procedia Soc. Behav. Sci.</i> 176, 263–269. doi: 10.1016/j.sbspro.2015.01.470</p>
<p><a href="https://doi.org/10.1016/j.sbspro.2015.01.470" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=M.+A.+P.+Alonso&amp;publication_year=2015&amp;title=Metacognition+and+sensorimotor+components+underlying+the+process+of+handwriting+and+keyboarding+and+their+impact+on+learning:+an+analysis+from+the+perspective+of+embodied+psychology&amp;journal=Procedia+Soc.+Behav.+Sci.&amp;volume=176&amp;pages=263-269" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref2" id="ref2"></a>Anderson, M. L. (2014). <i>After phrenology: Neural reuse and the interactive brain</i>. Cambridge, MA: MIT Press.</p>
<p><a href="http://scholar.google.com/scholar_lookup?author=M.+L.+Anderson&amp;publication_year=2014&amp;journal=After+phrenology:+Neural+reuse+and+the+interactive+brain&amp;" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref3" id="ref3"></a>Arnold, K. M., Umanath, S., Thio, K., Reilly, W. B., McDaniel, M. A., and Marsch, E. J. (2017). Understanding the cognitive processes involved in writing to learn. <i>J. Exp. Psychol. Appl.</i> 23, 115–127. doi: 10.1037/xap0000119</p>
<p><a href="https://doi.org/10.1037/xap0000119" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=K.+M.+Arnold&amp;author=S.+Umanath&amp;author=K.+Thio&amp;author=W.+B.+Reilly&amp;author=M.+A.+McDaniel&amp;author=E.+J.+Marsch&amp;publication_year=2017&amp;title=Understanding+the+cognitive+processes+involved+in+writing+to+learn&amp;journal=J.+Exp.+Psychol.+Appl.&amp;volume=23&amp;pages=115-127" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref4" id="ref4"></a>Askvik, E. O., Van der Weel, F. R., and Van der Meer, A. L. H. (2020). The importance of cursive handwriting over typewriting for learning in the classroom. <i>Front. Psychol.</i> 11:1810. doi: 10.3389/fp-syg.2020.01810</p>
<p><a href="https://doi.org/10.3389/fp-syg.2020.01810" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=E.+O.+Askvik&amp;author=F.+R.+Van+der+Weel&amp;author=A.+L.+H.+Van+der+Meer&amp;publication_year=2020&amp;title=The+importance+of+cursive+handwriting+over+typewriting+for+learning+in+the+classroom&amp;journal=Front.+Psychol.&amp;volume=11&amp;pages=1810" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref5" id="ref5"></a>Benedek, M., Schickel, R. J., Jauk, E., Fink, A., and Neubauer, A. C. (2014). Alpha power increases in right parietal cortex reflects focused internal attention. <i>Neuropsychologia</i> 56, 393–400. doi: 10.1016/j.neuropsychologia.2014.02.010 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/24561034" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1016/j.neuropsychologia.2014.02.010" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=M.+Benedek&amp;author=R.+J.+Schickel&amp;author=E.+Jauk&amp;author=A.+Fink&amp;author=A.+C.+Neubauer&amp;publication_year=2014&amp;title=Alpha+power+increases+in+right+parietal+cortex+reflects+focused+internal+attention&amp;journal=Neuropsychologia&amp;volume=56&amp;pages=393-400" target="_blank">Google Scholar</a></p></div>

<div>
<p><a name="ref7" id="ref7"></a>Berg, P., and Scherg, M. (1994). A multiple source approach to the correction of eye artifacts. <i>Electroencephalogr. Clin. Neurophysiol.</i> 90, 229–241. doi: 10.1016/0013-4694(94)90094-9 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/7511504" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1016/0013-4694(94)90094-9" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=P.+Berg&amp;author=M.+Scherg&amp;publication_year=1994&amp;title=A+multiple+source+approach+to+the+correction+of+eye+artifacts&amp;journal=Electroencephalogr.+Clin.+Neurophysiol.&amp;volume=90&amp;pages=229-241" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref8" id="ref8"></a>Bland, B. H., and Oddie, S. D. (2001). Theta band oscillations and synchrony in the hippocampal formation and associated structures: the case for its role in sensorimotor integration. <i>Behav. Brain Res.</i> 127, 119–136. doi: 10.1016/S0166-4328(01)00358-8</p>
<p><a href="https://doi.org/10.1016/S0166-4328(01)00358-8" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=B.+H.+Bland&amp;author=S.+D.+Oddie&amp;publication_year=2001&amp;title=Theta+band+oscillations+and+synchrony+in+the+hippocampal+formation+and+associated+structures:+the+case+for+its+role+in+sensorimotor+integration&amp;journal=Behav.+Brain+Res.&amp;volume=127&amp;pages=119-136" target="_blank">Google Scholar</a></p></div>

<div>
<p><a name="ref10" id="ref10"></a>Bullmore, E., and Sporns, O. (2009). Complex brain networks: graph theoretical analysis of structural and functional systems. <i>Nat. Rev. Neurosci.</i> 10, 186–198. doi: 10.1038/nrn2575</p>
<p><a href="https://doi.org/10.1038/nrn2575" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=E.+Bullmore&amp;author=O.+Sporns&amp;publication_year=2009&amp;title=Complex+brain+networks:+graph+theoretical+analysis+of+structural+and+functional+systems&amp;journal=Nat.+Rev.+Neurosci.&amp;volume=10&amp;pages=186-198" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref11" id="ref11"></a>Burke, J. F., Zaghloul, K. A., Jacobs, J., Williams, R. B., Sperling, M. R., Sharan, A. D., et al. (2013). Synchronous and asynchronous theta and gamma activity during episodic memory formation. <i>J. Neurosci.</i> 33, 292–304. doi: 10.1523/JNEUROSCI.2057-12.2013</p>
<p><a href="https://doi.org/10.1523/JNEUROSCI.2057-12.2013" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=J.+F.+Burke&amp;author=K.+A.+Zaghloul&amp;author=J.+Jacobs&amp;author=R.+B.+Williams&amp;author=M.+R.+Sperling&amp;author=A.+D.+Sharan&amp;publication_year=2013&amp;title=Synchronous+and+asynchronous+theta+and+gamma+activity+during+episodic+memory+formation&amp;journal=J.+Neurosci.&amp;volume=33&amp;pages=292-304" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref12" id="ref12"></a>Buzsáki, G. (2006). <i>Rhythms of the brain</i>. New York, NY: Oxford University Press.</p>
<p><a href="http://scholar.google.com/scholar_lookup?author=G.+Buzs%C3%A1ki&amp;publication_year=2006&amp;journal=Rhythms+of+the+brain&amp;" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref13" id="ref13"></a>Canolty, R. T., Edwards, E., Dalal, S. S., Soltani, M., Nagarajan, S. S., Kirsch, H. E., et al. (2006). High gamma power is phase-locked to theta oscillations in human neocortex. <i>Science</i> 313, 1626–1628. doi: 10.1126/science.1128115 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/16973878" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1126/science.1128115" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=R.+T.+Canolty&amp;author=E.+Edwards&amp;author=S.+S.+Dalal&amp;author=M.+Soltani&amp;author=S.+S.+Nagarajan&amp;author=H.+E.+Kirsch&amp;publication_year=2006&amp;title=High+gamma+power+is+phase-locked+to+theta+oscillations+in+human+neocortex&amp;journal=Science&amp;volume=313&amp;pages=1626-1628" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref14" id="ref14"></a>Clouter, A., Shapiro, K. L., and Hanslmayr, S. (2017). Theta phase synchronization is the glue that binds human associative memory. <i>Curr. Biol.</i> 27, 3143–3148.e6. doi: 10.1016/j.cub.2017.09.001 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/28988860" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1016/j.cub.2017.09.001" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=A.+Clouter&amp;author=K.+L.+Shapiro&amp;author=S.+Hanslmayr&amp;publication_year=2017&amp;title=Theta+phase+synchronization+is+the+glue+that+binds+human+associative+memory&amp;journal=Curr.+Biol.&amp;volume=27&amp;pages=3143-3148.e6" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref15" id="ref15"></a>Cunningham, A. E., and Stanovich, K. E. (1990). Early spelling acquisition: writing beats the computer. <i>J. Educ. Psychol.</i> 82, 159–162. doi: 10.1037/0022-0663.82.1.159</p>
<p><a href="https://doi.org/10.1037/0022-0663.82.1.159" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=A.+E.+Cunningham&amp;author=K.+E.+Stanovich&amp;publication_year=1990&amp;title=Early+spelling+acquisition:+writing+beats+the+computer&amp;journal=J.+Educ.+Psychol.&amp;volume=82&amp;pages=159-162" target="_blank">Google Scholar</a></p></div>

<div>
<p><a name="ref17" id="ref17"></a>Fears, N. E., and Lockman, J. J. (2018). How beginning handwriting is influenced by letter knowledge: visual-motor coordination during children’s form copying. <i>J. Exp. Child Psychol.</i> 171, 55–70. doi: 10.1016/j.jecp.2018.01.017</p>
<p><a href="https://doi.org/10.1016/j.jecp.2018.01.017" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=N.+E.+Fears&amp;author=J.+J.+Lockman&amp;publication_year=2018&amp;title=How+beginning+handwriting+is+influenced+by+letter+knowledge:+visual-motor+coordination+during+children%E2%80%99s+form+copying&amp;journal=J.+Exp.+Child+Psychol.&amp;volume=171&amp;pages=55-70" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref18" id="ref18"></a>Fröhlich, F. (2016). <i>Network neuroscience</i>. London, UK: Academic Press.</p>
<p><a href="http://scholar.google.com/scholar_lookup?author=F.+Fr%C3%B6hlich&amp;publication_year=2016&amp;journal=Network+neuroscience&amp;" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref19" id="ref19"></a>Fujioka, T., Mourad, N., He, C., and Trainor, L. J. (2011). Comparison of artifact correction methods for infant EEG applied to extraction of event-related potential signals. <i>Clin. Neurophysiol.</i> 122, 43–51. doi: 10.1016/j.clinph.2010.04.036 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/20580601" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1016/j.clinph.2010.04.036" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=T.+Fujioka&amp;author=N.+Mourad&amp;author=C.+He&amp;author=L.+J.+Trainor&amp;publication_year=2011&amp;title=Comparison+of+artifact+correction+methods+for+infant+EEG+applied+to+extraction+of+event-related+potential+signals&amp;journal=Clin.+Neurophysiol.&amp;volume=122&amp;pages=43-51" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref20" id="ref20"></a>Halgren, M., Fabó, D., Ulbert, I., Madsen, J. R., Eröss, L., Doyle, W. K., et al. (2018). Superficial slow rhythms integrate cortical processing in humans. <i>Sci. Rep.</i> 8:2055. doi: 10.1038/s41598-018-20662-0 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/29391596" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1038/s41598-018-20662-0" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=M.+Halgren&amp;author=D.+Fab%C3%B3&amp;author=I.+Ulbert&amp;author=J.+R.+Madsen&amp;author=L.+Er%C3%B6ss&amp;author=W.+K.+Doyle&amp;publication_year=2018&amp;title=Superficial+slow+rhythms+integrate+cortical+processing+in+humans&amp;journal=Sci.+Rep.&amp;volume=8&amp;pages=2055" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref21" id="ref21"></a>Hoechstetter, K., Bornfleth, H., Weckesser, D., Ille, N., Berg, P., and Scherg, M. (2004). BESA source coherence: a new method to study cortical oscillatory coupling. <i>Brain Topogr.</i> 16, 233–238. doi: 10.1023/B:BRAT.0000032857.55223.5d </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/15379219" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1023/B:BRAT.0000032857.55223.5d" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=K.+Hoechstetter&amp;author=H.+Bornfleth&amp;author=D.+Weckesser&amp;author=N.+Ille&amp;author=P.+Berg&amp;author=M.+Scherg&amp;publication_year=2004&amp;title=BESA+source+coherence:+a+new+method+to+study+cortical+oscillatory+coupling&amp;journal=Brain+Topogr.&amp;volume=16&amp;pages=233-238" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref22" id="ref22"></a>Hultin, E., and Westman, M. (2013). Early literacy practices go digital. <i>Lit. Inf. Comput. Educ. J.</i> 4, 1096–1104. doi: 10.20533/licej.2040.2589.2013.0145</p>
<p><a href="https://doi.org/10.20533/licej.2040.2589.2013.0145" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=E.+Hultin&amp;author=M.+Westman&amp;publication_year=2013&amp;title=Early+literacy+practices+go+digital&amp;journal=Lit.+Inf.+Comput.+Educ.+J.&amp;volume=4&amp;pages=1096-1104" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref23" id="ref23"></a>Ille, N., Berg, P., and Scherg, M. (2002). Artifact correction of the ongoing EEG using spatial filters based on artifact and brain signal topographies. <i>J. Clin. Neurophysiol.</i> 19, 113–124. doi: 10.1097/00004691-200203000-00002 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/11997722" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1097/00004691-200203000-00002" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=N.+Ille&amp;author=P.+Berg&amp;author=M.+Scherg&amp;publication_year=2002&amp;title=Artifact+correction+of+the+ongoing+EEG+using+spatial+filters+based+on+artifact+and+brain+signal+topographies&amp;journal=J.+Clin.+Neurophysiol.&amp;volume=19&amp;pages=113-124" target="_blank">Google Scholar</a></p></div>

<div>
<p><a name="ref25" id="ref25"></a>Kiefer, M., Schuler, S., Mayer, C., Trumpp, N. M., Hille, K., and Sachse, S. (2015). Handwriting or typewriting? The influence of pen- or keyboard-based writing training on reading and writing performance in preschool children. <i>Adv.Cogn. Psychol.</i> 11, 136–146. doi: 10.5709/acp-0178-7 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/26770286" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.5709/acp-0178-7" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=M.+Kiefer&amp;author=S.+Schuler&amp;author=C.+Mayer&amp;author=N.+M.+Trumpp&amp;author=K.+Hille&amp;author=S.+Sachse&amp;publication_year=2015&amp;title=Handwriting+or+typewriting?+The+influence+of+pen-+or+keyboard-based+writing+training+on+reading+and+writing+performance+in+preschool+children&amp;journal=Adv.Cogn.+Psychol.&amp;volume=11&amp;pages=136-146" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref26" id="ref26"></a>Klimesch, W. (1999). EEG alpha and theta oscillations reflect cognitive and memory performance: a review and analysis. <i>Brain Res. Rev.</i> 29, 169–195. doi: 10.1016/S0165-0173(98)00056-3 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/10209231" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1016/S0165-0173(98)00056-3" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=W.+Klimesch&amp;publication_year=1999&amp;title=EEG+alpha+and+theta+oscillations+reflect+cognitive+and+memory+performance:+a+review+and+analysis&amp;journal=Brain+Res.+Rev.&amp;volume=29&amp;pages=169-195" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref27" id="ref27"></a>Klimesch, W., Doppelmayr, M., Yonelinas, A., Kroll, N. E., Lazzara, M., Röhm, D., et al. (2001). Theta synchronization during episodic retrieval: neural correlates of conscious awareness. <i>Cogn. Brain Res.</i> 12, 33–38. doi: 10.1016/S0926-6410(01)00024-6 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/11489606" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1016/S0926-6410(01)00024-6" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=W.+Klimesch&amp;author=M.+Doppelmayr&amp;author=A.+Yonelinas&amp;author=N.+E.+Kroll&amp;author=M.+Lazzara&amp;author=D.+R%C3%B6hm&amp;publication_year=2001&amp;title=Theta+synchronization+during+episodic+retrieval:+neural+correlates+of+conscious+awareness&amp;journal=Cogn.+Brain+Res.&amp;volume=12&amp;pages=33-38" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref28" id="ref28"></a>Klimesch, W., Schimke, H., Doppelmayr, M., Ripper, B., Schwaiger, J., and Pfurtscheller, G. (1996). Event-related desynchronization (ERD) and the Dm-effect: does alpha desynchronization during encoding predict later recall performance? <i>Int. J. Psychophysiol.</i> 24, 47–60. doi: 10.1016/S0167-8760(96)00054-2 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/8978435" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1016/S0167-8760(96)00054-2" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=W.+Klimesch&amp;author=H.+Schimke&amp;author=M.+Doppelmayr&amp;author=B.+Ripper&amp;author=J.+Schwaiger&amp;author=G.+Pfurtscheller&amp;publication_year=1996&amp;title=Event-related+desynchronization+(ERD)+and+the+Dm-effect:+does+alpha+desynchronization+during+encoding+predict+later+recall+performance?&amp;journal=Int.+J.+Psychophysiol.&amp;volume=24&amp;pages=47-60" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref29" id="ref29"></a>Klimesch, W., Schimke, H., and Schwaiger, J. (1994). Episodic and semantic memory: an analysis in the EEG theta and alpha band. <i>Electroencephalogr. Clin. Neurophysiol.</i> 91, 428–441. doi: 10.1016/0013-4694(94)90164-3 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/7529682" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1016/0013-4694(94)90164-3" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=W.+Klimesch&amp;author=H.+Schimke&amp;author=J.+Schwaiger&amp;publication_year=1994&amp;title=Episodic+and+semantic+memory:+an+analysis+in+the+EEG+theta+and+alpha+band&amp;journal=Electroencephalogr.+Clin.+Neurophysiol.&amp;volume=91&amp;pages=428-441" target="_blank">Google Scholar</a></p></div>

<div>
<p><a name="ref31" id="ref31"></a>Longcamp, M., Boucard, C., Gilhodes, J. C., and Anton, J. L. (2008). Learning through hand- or typewriting influences visual recognition of new graphic shapes: behavioral and functional imaging evidence. <i>J. Cogn. Neurosci.</i> 20, 802–815. doi: 10.1162/jocn.2008.20504</p>
<p><a href="https://doi.org/10.1162/jocn.2008.20504" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=M.+Longcamp&amp;author=C.+Boucard&amp;author=J.+C.+Gilhodes&amp;author=J.+L.+Anton&amp;publication_year=2008&amp;title=Learning+through+hand-+or+typewriting+influences+visual+recognition+of+new+graphic+shapes:+behavioral+and+functional+imaging+evidence&amp;journal=J.+Cogn.+Neurosci.&amp;volume=20&amp;pages=802-815" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref32" id="ref32"></a>Longcamp, M., Boucard, C., Gilhodes, J. C., and Velay, J. L. (2006). Remembering the orientation of newly learned characters depends on the associated writing knowledge: a comparison between handwriting and typing. <i>Hum. Mov. Sci.</i> 25, 646–656. doi: 10.1016/j.humov.2006.07.007 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/17011660" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1016/j.humov.2006.07.007" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=M.+Longcamp&amp;author=C.+Boucard&amp;author=J.+C.+Gilhodes&amp;author=J.+L.+Velay&amp;publication_year=2006&amp;title=Remembering+the+orientation+of+newly+learned+characters+depends+on+the+associated+writing+knowledge:+a+comparison+between+handwriting+and+typing&amp;journal=Hum.+Mov.+Sci.&amp;volume=25&amp;pages=646-656" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref33" id="ref33"></a>Longcamp, M., Zerbato-Poudou, M. T., and Velay, J. L. (2005). The influence of writing practice on letter recognition in preschool children: a comparison between handwriting and typing. <i>Acta Psychol.</i> 119, 67–79. doi: 10.1016/j.actpsy.2004.10.019 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/15823243" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1016/j.actpsy.2004.10.019" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=M.+Longcamp&amp;author=M.+T.+Zerbato-Poudou&amp;author=J.+L.+Velay&amp;publication_year=2005&amp;title=The+influence+of+writing+practice+on+letter+recognition+in+preschool+children:+a+comparison+between+handwriting+and+typing&amp;journal=Acta+Psychol.&amp;volume=119&amp;pages=67-79" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref34" id="ref34"></a>Lopes da Silva, F. H. (1991). Neural mechanisms underlying brain waves: from neural membranes to networks. <i>Electroencephalogr. Clin. Neurophysiol.</i> 79, 81–93. doi: 10.1016/0013-4694(91)90044-5 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/1713832" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1016/0013-4694(91)90044-5" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=F.+H.+Lopes+da+Silva&amp;publication_year=1991&amp;title=Neural+mechanisms+underlying+brain+waves:+from+neural+membranes+to+networks&amp;journal=Electroencephalogr.+Clin.+Neurophysiol.&amp;volume=79&amp;pages=81-93" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref35" id="ref35"></a>Mangen, A., and Balsvik, L. (2016). Pen or keyboard in beginning writing instruction? Some perspectives from embodied cognition. <i>Trends Neurosci. Educ.</i> 5, 99–106. doi: 10.1016/j.tine.2016.06.003</p>
<p><a href="https://doi.org/10.1016/j.tine.2016.06.003" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=A.+Mangen&amp;author=L.+Balsvik&amp;publication_year=2016&amp;title=Pen+or+keyboard+in+beginning+writing+instruction?+Some+perspectives+from+embodied+cognition&amp;journal=Trends+Neurosci.+Educ.&amp;volume=5&amp;pages=99-106" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref36" id="ref36"></a>Mueller, P. A., and Oppenheimer, D. M. (2014). The pen is mightier than the keyboard: advantages of longhand over laptop note taking. <i>Psychol. Sci.</i> 25, 1159–1168. doi: 10.1177/0956797614524581 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/24760141" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1177/0956797614524581" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=P.+A.+Mueller&amp;author=D.+M.+Oppenheimer&amp;publication_year=2014&amp;title=The+pen+is+mightier+than+the+keyboard:+advantages+of+longhand+over+laptop+note+taking&amp;journal=Psychol.+Sci.&amp;volume=25&amp;pages=1159-1168" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref37" id="ref37"></a>Oldfield, R. C. (1971). The assessment and analysis of handedness: the Edinburgh inventory. <i>Neuropsychologia</i> 9, 97–113. doi: 10.1016/0028-3932(71)90067-4</p>
<p><a href="https://doi.org/10.1016/0028-3932(71)90067-4" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=R.+C.+Oldfield&amp;publication_year=1971&amp;title=The+assessment+and+analysis+of+handedness:+the+Edinburgh+inventory&amp;journal=Neuropsychologia&amp;volume=9&amp;pages=97-113" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref38" id="ref38"></a>Osugi, K., Ihara, A. S., Nakajima, K., Kake, A., Ishimaru, K., Yokota, Y., et al. (2019). Differences in brain activity after learning with the use of a digital pen vs. an ink pen: an electroencephalography study. <i>Front. Hum. Neurosci.</i> 13:275. doi: 10.3389/fnhum.2019.00275 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/31447662" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.3389/fnhum.2019.00275" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=K.+Osugi&amp;author=A.+S.+Ihara&amp;author=K.+Nakajima&amp;author=A.+Kake&amp;author=K.+Ishimaru&amp;author=Y.+Yokota&amp;publication_year=2019&amp;title=Differences+in+brain+activity+after+learning+with+the+use+of+a+digital+pen+vs.+an+ink+pen:+an+electroencephalography+study&amp;journal=Front.+Hum.+Neurosci.&amp;volume=13&amp;pages=275" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref39" id="ref39"></a>Patterson, R. W., and Patterson, R. M. (2017). Computers and productivity: evidence from laptop use in the college classroom. <i>Econ. Educ. Rev.</i> 57, 66–79. doi: 10.1016/j.econedurev.2017.02.004</p>
<p><a href="https://doi.org/10.1016/j.econedurev.2017.02.004" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=R.+W.+Patterson&amp;author=R.+M.+Patterson&amp;publication_year=2017&amp;title=Computers+and+productivity:+evidence+from+laptop+use+in+the+college+classroom&amp;journal=Econ.+Educ.+Rev.&amp;volume=57&amp;pages=66-79" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref40" id="ref40"></a>Pei, L., Longcamp, M., Leung, F. K.-S., and Ouyang, G. (2021). Temporally resolved neural dynamics underlying handwriting. <i>NeuroImage</i> 244:118578. doi: 10.1016/j.neuroimage.2021.118578 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/34534659" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1016/j.neuroimage.2021.118578" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=L.+Pei&amp;author=M.+Longcamp&amp;author=F.+K.-S.+Leung&amp;author=G.+Ouyang&amp;publication_year=2021&amp;title=Temporally+resolved+neural+dynamics+underlying+handwriting&amp;journal=NeuroImage&amp;volume=244&amp;pages=118578" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref41" id="ref41"></a>Perrin, F., Pernier, J., Bertrand, O., and Echallier, J. F. (1989). Spherical splines for scalp potential and current density mapping. <i>Electroencephalogr. Clin. Neurophysiol.</i> 72, 184–187. doi: 10.1016/0013-4694(89)90180-6 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/2464490" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1016/0013-4694(89)90180-6" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=F.+Perrin&amp;author=J.+Pernier&amp;author=O.+Bertrand&amp;author=J.+F.+Echallier&amp;publication_year=1989&amp;title=Spherical+splines+for+scalp+potential+and+current+density+mapping&amp;journal=Electroencephalogr.+Clin.+Neurophysiol.&amp;volume=72&amp;pages=184-187" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref42" id="ref42"></a>Pfurtscheller, G., and Aranibar, A. (1977). Event-related cortical desynchronization detected by power measurements of scalp EEG. <i>Electroencephalogr. Clin. Neurophysiol.</i> 42, 817–826. doi: 10.1016/0013-4694(77)90235-8 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/67933" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1016/0013-4694(77)90235-8" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=G.+Pfurtscheller&amp;author=A.+Aranibar&amp;publication_year=1977&amp;title=Event-related+cortical+desynchronization+detected+by+power+measurements+of+scalp+EEG&amp;journal=Electroencephalogr.+Clin.+Neurophysiol.&amp;volume=42&amp;pages=817-826" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref43" id="ref43"></a>Pfurtscheller, G., and Lopes da Silva, F. H. (1999). Event-related EEG/MEG synchronization and desynchronization: basic principles. <i>Clin. Neurophysiol.</i> 110, 1842–1857. doi: 10.1016/S1388-2457(99)00141-8 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/10576479" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1016/S1388-2457(99)00141-8" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=G.+Pfurtscheller&amp;author=F.+H.+Lopes+da+Silva&amp;publication_year=1999&amp;title=Event-related+EEG/MEG+synchronization+and+desynchronization:+basic+principles&amp;journal=Clin.+Neurophysiol.&amp;volume=110&amp;pages=1842-1857" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref44" id="ref44"></a>Pfurtscheller, G., Neuper, C., and Mohl, W. (1994). Event-related desynchronization (ERD) during visual processing. <i>Int. J. Psychophysiol.</i> 16, 147–153. doi: 10.1016/0167-8760(89)90041-x</p>
<p><a href="https://doi.org/10.1016/0167-8760(89)90041-x" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=G.+Pfurtscheller&amp;author=C.+Neuper&amp;author=W.+Mohl&amp;publication_year=1994&amp;title=Event-related+desynchronization+(ERD)+during+visual+processing&amp;journal=Int.+J.+Psychophysiol.&amp;volume=16&amp;pages=147-153" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref45" id="ref45"></a>Pfurtscheller, G., Stancak, A. J., and Neuper, C. (1996). Event-related synchronization (ERS) in the alpha band - an electrophysiological correlate of cortical idling: a review. <i>Int. J. Psychophysiol.</i> 24, 39–46. doi: 10.1016/S0167-8760(96)00066-9 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/8978434" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1016/S0167-8760(96)00066-9" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=G.+Pfurtscheller&amp;author=A.+J.+Stancak&amp;author=C.+Neuper&amp;publication_year=1996&amp;title=Event-related+synchronization+(ERS)+in+the+alpha+band+-+an+electrophysiological+correlate+of+cortical+idling:+a+review&amp;journal=Int.+J.+Psychophysiol.&amp;volume=24&amp;pages=39-46" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref46" id="ref46"></a>Picton, T. W., Bentin, S., Berg, P., Donchin, E., Hillyard, S. A., Johnson, R. J., et al. (2000). Guidelines for using human event-related potentials to study cognition: recording standards and publication criteria. <i>Psychophysiology</i> 37, 127–152. doi: 10.1111/1469-8986.3720127</p>
<p><a href="https://doi.org/10.1111/1469-8986.3720127" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=T.+W.+Picton&amp;author=S.+Bentin&amp;author=P.+Berg&amp;author=E.+Donchin&amp;author=S.+A.+Hillyard&amp;author=R.+J.+Johnson&amp;publication_year=2000&amp;title=Guidelines+for+using+human+event-related+potentials+to+study+cognition:+recording+standards+and+publication+criteria&amp;journal=Psychophysiology&amp;volume=37&amp;pages=127-152" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref47" id="ref47"></a>Raghavachari, S., Kahana, M. J., Rizzuto, D. S., Caplan, J. B., Kirschen, M. P., Bourgeois, B., et al. (2001). Gating of human theta oscillations by a working memory task. <i>J. Neurosci.</i> 21, 3175–3183. doi: 10.1523/jneurosci.21-09-03175.2001 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/11312302" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1523/jneurosci.21-09-03175.2001" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=S.+Raghavachari&amp;author=M.+J.+Kahana&amp;author=D.+S.+Rizzuto&amp;author=J.+B.+Caplan&amp;author=M.+P.+Kirschen&amp;author=B.+Bourgeois&amp;publication_year=2001&amp;title=Gating+of+human+theta+oscillations+by+a+working+memory+task&amp;journal=J.+Neurosci.&amp;volume=21&amp;pages=3175-3183" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref48" id="ref48"></a>Rosenberg, J. R., Amjad, A. M., Breeze, P., Brillinger, D. R., and Halliday, D. M. (1989). The fourier approach to the identification of functional coupling between neuronal spike trains. <i>Prog. Biophys. Mol. Biol.</i> 53, 1–31. doi: 10.1016/0079-6107(89)90004-7</p>
<p><a href="https://doi.org/10.1016/0079-6107(89)90004-7" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=J.+R.+Rosenberg&amp;author=A.+M.+Amjad&amp;author=P.+Breeze&amp;author=D.+R.+Brillinger&amp;author=D.+M.+Halliday&amp;publication_year=1989&amp;title=The+fourier+approach+to+the+identification+of+functional+coupling+between+neuronal+spike+trains&amp;journal=Prog.+Biophys.+Mol.+Biol.&amp;volume=53&amp;pages=1-31" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref49" id="ref49"></a>Salmelin, R., and Hari, R. (1994). Spatiotemporal characteristics of sensorimotor neuromagnetic rhythms related to thumb movement. <i>Neuroscience</i> 60, 537–550. doi: 10.1016/0306-4522(94)90263-1 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/8072694" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1016/0306-4522(94)90263-1" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=R.+Salmelin&amp;author=R.+Hari&amp;publication_year=1994&amp;title=Spatiotemporal+characteristics+of+sensorimotor+neuromagnetic+rhythms+related+to+thumb+movement&amp;journal=Neuroscience&amp;volume=60&amp;pages=537-550" target="_blank">Google Scholar</a></p></div>

<div>
<p><a name="ref51" id="ref51"></a>Simes, R. J. (1986). An improved Bonferroni procedure for multiple tests of significance. <i>Biometrica</i> 73, 751–754. doi: 10.1093/biomet/73.3.751</p>
<p><a href="https://doi.org/10.1093/biomet/73.3.751" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=R.+J.+Simes&amp;publication_year=1986&amp;title=An+improved+Bonferroni+procedure+for+multiple+tests+of+significance&amp;journal=Biometrica&amp;volume=73&amp;pages=751-754" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref52" id="ref52"></a>Singer, W. (1993). Synchronization of cortical activity and its putative role in information processing and learning. <i>Annu. Rev. Physiol.</i> 55, 349–374. doi: 10.1146/annurev.ph.55.030193.002025 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/8466179" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1146/annurev.ph.55.030193.002025" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=W.+Singer&amp;publication_year=1993&amp;title=Synchronization+of+cortical+activity+and+its+putative+role+in+information+processing+and+learning&amp;journal=Annu.+Rev.+Physiol.&amp;volume=55&amp;pages=349-374" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref53" id="ref53"></a>Smoker, T. J., Murphy, C. E., and Rockwell, A. K. (2009). Comparing memory for handwriting versus typing. <i>Proc. Hum. Factors Ergon. Soc. Annu. Meet.</i> 53, 1744–1747. doi: 10.1518/107118109X12524444081755</p>
<p><a href="https://doi.org/10.1518/107118109X12524444081755" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=T.+J.+Smoker&amp;author=C.+E.+Murphy&amp;author=A.+K.+Rockwell&amp;publication_year=2009&amp;title=Comparing+memory+for+handwriting+versus+typing&amp;journal=Proc.+Hum.+Factors+Ergon.+Soc.+Annu.+Meet.&amp;volume=53&amp;pages=1744-1747" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref54" id="ref54"></a>Solomon, E. A., Kragel, J. E., Sperling, M. R., Sharan, A., Worrell, G., Kucewicz, M., et al. (2017). Widespread theta synchrony and high-frequency desynchronization underlies enhanced cognition. <i>Nat. Commun.</i> 8:1704. doi: 10.1038/s41467-017-01763-2 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/29167419" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1038/s41467-017-01763-2" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=E.+A.+Solomon&amp;author=J.+E.+Kragel&amp;author=M.+R.+Sperling&amp;author=A.+Sharan&amp;author=G.+Worrell&amp;author=M.+Kucewicz&amp;publication_year=2017&amp;title=Widespread+theta+synchrony+and+high-frequency+desynchronization+underlies+enhanced+cognition&amp;journal=Nat.+Commun.&amp;volume=8&amp;pages=1704" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref55" id="ref55"></a>Tucker, D. M., Liotti, M., Potts, G. F., Russell, G. S., and Posner, M. I. (1994). Spatiotemporal analysis of brain electrical fields. <i>Hum. Brain Mapp.</i> 1, 134–152. doi: 10.1002/hbm.460010206</p>
<p><a href="https://doi.org/10.1002/hbm.460010206" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=D.+M.+Tucker&amp;author=M.+Liotti&amp;author=G.+F.+Potts&amp;author=G.+S.+Russell&amp;author=M.+I.+Posner&amp;publication_year=1994&amp;title=Spatiotemporal+analysis+of+brain+electrical+fields&amp;journal=Hum.+Brain+Mapp.&amp;volume=1&amp;pages=134-152" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref56" id="ref56"></a>Van der Meer, A. L. H., and Van der Weel, F. R. (2017). Only three fingers write, but the whole brain works: a high-density EEG study showing advantages of drawing over typing for learning. <i>Front. Psychol.</i> 8:706. doi: 10.3389/fpsyg.2017.00706 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/28536546" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.3389/fpsyg.2017.00706" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=A.+L.+H.+Van+der+Meer&amp;author=F.+R.+Van+der+Weel&amp;publication_year=2017&amp;title=Only+three+fingers+write+but+the+whole+brain+works:+a+high-density+EEG+study+showing+advantages+of+drawing+over+typing+for+learning&amp;journal=Front.+Psychol.&amp;volume=8&amp;pages=706" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref57" id="ref57"></a>Van der Weel, F. R., Agyei, S. B., and Van der Meer, A. L. H. (2019). Infants’ brain responses to looming danger: degeneracy of neural connectivity patterns. <i>Ecol. Psychol.</i> 31, 182–197. doi: 10.1080/10407413.2019.1615210</p>
<p><a href="https://doi.org/10.1080/10407413.2019.1615210" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=F.+R.+Van+der+Weel&amp;author=S.+B.+Agyei&amp;author=A.+L.+H.+Van+der+Meer&amp;publication_year=2019&amp;title=Infants%E2%80%99+brain+responses+to+looming+danger:+degeneracy+of+neural+connectivity+patterns&amp;journal=Ecol.+Psychol.&amp;volume=31&amp;pages=182-197" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref58" id="ref58"></a>Velasques, B., Machado, S., Portella, C. E., Silva, J. G., Basile, L. F. H., Cagy, M., et al. (2007). Electrophysiological analysis of a sensorimotor integration task. <i>Neurosci. Lett.</i> 426, 155–159. doi: 10.1016/j.neulet.2007.08.061 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/17900806" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1016/j.neulet.2007.08.061" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=B.+Velasques&amp;author=S.+Machado&amp;author=C.+E.+Portella&amp;author=J.+G.+Silva&amp;author=L.+F.+H.+Basile&amp;author=M.+Cagy&amp;publication_year=2007&amp;title=Electrophysiological+analysis+of+a+sensorimotor+integration+task&amp;journal=Neurosci.+Lett.&amp;volume=426&amp;pages=155-159" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref59" id="ref59"></a>Vilhelmsen, K., Agyei, S. B., Van der Weel, F. R., and Van der Meer, A. L. H. (2019). A high-density EEG study of differentiation between two speeds and directions of simulated optic flow in adults and infants. <i>Psychophysiology</i> 56:e13281. doi: 10.1111/psyp.13281 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/30175487" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1111/psyp.13281" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=K.+Vilhelmsen&amp;author=S.+B.+Agyei&amp;author=F.+R.+Van+der+Weel&amp;author=A.+L.+H.+Van+der+Meer&amp;publication_year=2019&amp;title=A+high-density+EEG+study+of+differentiation+between+two+speeds+and+directions+of+simulated+optic+flow+in+adults+and+infants&amp;journal=Psychophysiology&amp;volume=56&amp;pages=e13281" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref60" id="ref60"></a>Vinci-Booher, S., James, T. W., and James, K. H. (2016). Visual-motor functional connectivity in preschool children emerges after handwriting experience. <i>Trends Neurosci. Educ.</i> 5, 107–120. doi: 10.1016/j.tine.2016.07.006</p>
<p><a href="https://doi.org/10.1016/j.tine.2016.07.006" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=S.+Vinci-Booher&amp;author=T.+W.+James&amp;author=K.+H.+James&amp;publication_year=2016&amp;title=Visual-motor+functional+connectivity+in+preschool+children+emerges+after+handwriting+experience&amp;journal=Trends+Neurosci.+Educ.&amp;volume=5&amp;pages=107-120" target="_blank">Google Scholar</a></p></div>
<div>
<p><a name="ref61" id="ref61"></a>Vinci-Booher, S., James, T. W., and James, K. H. (2021). Visual-motor contingency during symbol production contributes to short term changes in the functional connectivity during symbol perception and long-term gains in symbol recognition. <i>NeuroImage</i> 227, 1–14. doi: 10.1016/j.neuroimage.2020.117554 </p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/33359354" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1016/j.neuroimage.2020.117554" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?author=S.+Vinci-Booher&amp;author=T.+W.+James&amp;author=K.+H.+James&amp;publication_year=2021&amp;title=Visual-motor+contingency+during+symbol+production+contributes+to+short+term+changes+in+the+functional+connectivity+during+symbol+perception+and+long-term+gains+in+symbol+recognition&amp;journal=NeuroImage&amp;volume=227&amp;pages=1-14" target="_blank">Google Scholar</a></p></div>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A bird's eye view of Polars (188 pts)]]></title>
            <link>https://pola.rs/posts/polars_birds_eye_view/</link>
            <guid>39363675</guid>
            <pubDate>Tue, 13 Feb 2024 22:25:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pola.rs/posts/polars_birds_eye_view/">https://pola.rs/posts/polars_birds_eye_view/</a>, See on <a href="https://news.ycombinator.com/item?id=39363675">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>A good library abstracts away many complexities for its user. Polars is no different in this regard, as it maintains a philosophy that queries you write should be performant by default without knowing any of the internals. However, many users are interested in what happens under the hood either as a learning experience or to squeeze that last bit of performance out of their queries. In this blog post, we will provide a bird’s eye view of how Polars works and in future posts we will deep dive into each of its components.</p>
<h2 id="high-level-overview">High level overview</h2>
<p>So, what is Polars? A short description would be “a query engine with a DataFrame frontend”. This is too high level even for a bird’s eye view. So let’s dive into the two elements, DataFrame and query engine, a bit more by looking at how a query gets executed. By taking a step-by-step journey through the execution of a query, we can observe each component in action and understand its role and purpose.</p>
<p>From a bird’s eye view, the execution of a query goes as follows. First we parse the query and validate it into a logical plan. The plan describes what the user intends to do, but not the how. Then our query optimizer traverses this plan (several times) to optimize any unnecessary work and produces an optimized logical plan. Following this optimization phase, the query planner transforms this logical plan into a physical plan, which outlines how the query is to be executed. This finalized physical plan serves as the ultimate input for the actual execution of the query and runs our compute kernels.</p>
<p><img alt="" src="https://pola.rs/_astro/birds-eye-overview.6f8aa92d_ZVHkQh.webp" width="3074" height="209" loading="lazy" decoding="async"></p>
<h2 id="query">Query</h2>
<p>When you interact with Polars, you use our DataFrame API. This API is specifically designed to allow for parallel execution and with performance in mind. Writing a Polars query in that sense is writing a small program (or this case query) in a domain-specific language (<a href="https://en.wikipedia.org/wiki/Domain-specific_language">DSL</a>) designed by Polars. This DSL has its own set of rules governing which queries are valid and which ones are not.</p>
<p>For this post, let’s use the famous NYE taxi dataset with taxi trips<sup><a href="#user-content-fn-1" id="user-content-fnref-1" data-footnote-ref="" aria-describedby="footnote-label">1</a></sup>. In the example below we calculate the average cost per minute for a trip over 25 dollars by zone. This case is simple enough to be easily understood while containing enough depth to showcase the purpose of the query engine.</p>
<pre tabindex="0"><code><span><span>import</span><span> polars </span><span>as</span><span> pl</span></span>
<span></span>
<span><span>query </span><span>=</span><span> (</span></span>
<span><span>    pl</span><span>.</span><span>scan_parquet</span><span>(</span><span>"yellow_tripdata_2023-01.parquet"</span><span>)</span></span>
<span><span>    .</span><span>join</span><span>(pl.</span><span>scan_csv</span><span>(</span><span>"taxi_zones.csv"</span><span>), left_on</span><span>=</span><span>"PULocationID"</span><span>, right_on</span><span>=</span><span>"LocationID"</span><span>)</span></span>
<span><span>    .</span><span>filter</span><span>(pl.</span><span>col</span><span>(</span><span>"total_amount"</span><span>) </span><span>&gt;</span><span> 25</span><span>)</span></span>
<span><span>    .</span><span>group_by</span><span>(</span><span>"Zone"</span><span>)</span></span>
<span><span>    .</span><span>agg</span><span>(</span></span>
<span><span>        (pl.</span><span>col</span><span>(</span><span>"total_amount"</span><span>) </span><span>/</span></span>
<span><span>        (pl.</span><span>col</span><span>(</span><span>"tpep_dropoff_datetime"</span><span>) </span><span>-</span><span> pl.</span><span>col</span><span>(</span><span>"tpep_pickup_datetime"</span><span>)).dt.</span><span>total_minutes</span><span>()</span></span>
<span><span>        ).</span><span>mean</span><span>().</span><span>alias</span><span>(</span><span>"cost_per_minute"</span><span>)</span></span>
<span><span>    ).</span><span>sort</span><span>(</span><span>"cost_per_minute"</span><span>,descending</span><span>=</span><span>True</span><span>)</span></span>
<span><span>)</span></span></code></pre>
<p>The query above is of type <code>LazyFrame</code>. It returns instantly while the NY taxi trips dataset is over 3 million rows, so what has happened? The statement defines the query, but does not yet execute it. This concept is known as lazy evaluation and is one of the key strengths of Polars. If you look into the data structure on the Rust side, you will see it contains two elements: a <code>logical_plan</code> and configuration flags for the optimizer <code>opt_state</code>.</p>
<pre tabindex="0"><code><span><span>pub</span><span> struct</span><span> LazyFrame</span><span> {</span></span>
<span><span>    pub</span><span> logical_plan</span><span>:</span><span> LogicalPlan</span><span>,</span></span>
<span><span>    pub</span><span>(</span><span>crate</span><span>) opt_state</span><span>:</span><span> OptState</span><span>,</span></span>
<span><span>}</span></span></code></pre>
<p>The logical plan is a tree with the data sources as leaves of the tree and the transformations as nodes. The plan describes the structure of a query and the expressions it contains.</p>
<pre tabindex="0"><code><span><span>pub</span><span> enum</span><span> LogicalPlan</span><span> {</span></span>
<span><span>    /// Filter on a boolean mask</span></span>
<span><span>    Selection</span><span> {</span></span>
<span><span>        input</span><span>:</span><span> Box</span><span>&lt;</span><span>LogicalPlan</span><span>&gt;,</span></span>
<span><span>        predicate</span><span>:</span><span> Expr</span><span>,</span></span>
<span><span>    },</span></span>
<span><span>    /// Column selection</span></span>
<span><span>    Projection</span><span> {</span></span>
<span><span>        expr</span><span>:</span><span> Vec</span><span>&lt;</span><span>Expr</span><span>&gt;,</span></span>
<span><span>        input</span><span>:</span><span> Box</span><span>&lt;</span><span>LogicalPlan</span><span>&gt;,</span></span>
<span><span>        schema</span><span>:</span><span> SchemaRef</span><span>,</span></span>
<span><span>        options</span><span>:</span><span> ProjectionOptions</span><span>,</span></span>
<span><span>    },</span></span>
<span><span>    /// Join operation</span></span>
<span><span>    Join</span><span> {</span></span>
<span><span>        input_left</span><span>:</span><span> Box</span><span>&lt;</span><span>LogicalPlan</span><span>&gt;,</span></span>
<span><span>        input_right</span><span>:</span><span> Box</span><span>&lt;</span><span>LogicalPlan</span><span>&gt;,</span></span>
<span><span>        schema</span><span>:</span><span> SchemaRef</span><span>,</span></span>
<span><span>        left_on</span><span>:</span><span> Vec</span><span>&lt;</span><span>Expr</span><span>&gt;,</span></span>
<span><span>        right_on</span><span>:</span><span> Vec</span><span>&lt;</span><span>Expr</span><span>&gt;,</span></span>
<span><span>        options</span><span>:</span><span> Arc</span><span>&lt;</span><span>JoinOptions</span><span>&gt;,</span></span>
<span><span>    },</span></span>
<span><span>    ...</span></span>
<span><span>}</span></span></code></pre>
<p>One important step when converting your query into a logical plan is validation. Polars knows the schema of the data upfront and can validate if the transformations are correct. This ensures you don’t run into any errors halfway through executing a query. For instance, defining a query where you select a column that does not exist returns an error before execution</p>
<pre tabindex="0"><code><span><span>pl</span><span>.</span><span>LazyFrame</span><span>([]).</span><span>select</span><span>(pl.</span><span>col</span><span>(</span><span>"does_not_exist"</span><span>))</span></span></code></pre>
<pre tabindex="0"><code><span><span>polars.exceptions.ColumnNotFoundError: column_does_not_exist</span></span>
<span><span></span></span>
<span><span>Error originated just after this operation:</span></span>
<span><span>DF []; PROJECT */0 COLUMNS; SELECTION: "None"</span></span></code></pre>
<p>We can view the logical plan by calling <code>show_graph</code> on a <code>LazyFrame</code>:</p>
<pre tabindex="0"><code><span><span>query</span><span>.</span><span>show_graph</span><span>(optimized</span><span>=</span><span>False</span><span>)</span></span></code></pre>
<p><img alt="non optimized query plan" src="https://pola.rs/_astro/non-optimized.82896225_ZbNItr.svg" width="984" height="383" loading="lazy" decoding="async"></p>
<h2 id="query-optimization">Query Optimization</h2>
<p>The goal of the query optimizer is to optimize the <code>LogicalPlan</code> for performance. It does this by traversing the tree structure and modifying/adding/removing nodes.There are many types of optimizations that will lead to faster execution, for instance changing the order of operations. Generally, you want <code>filter</code> operations to occur as early as possible as it allows you to throw away any unused data and avoid unnessary work. In the example we can show our optimized logical plan with the same <code>show_graph</code> function:</p>
<pre tabindex="0"><code><span><span>query</span><span>.</span><span>show_graph</span><span>()</span></span></code></pre>
<p><img alt="optimized query plan" src="https://pola.rs/_astro/optimized.e46e3f3c_ZSiab5.svg" width="1083" height="383" loading="lazy" decoding="async"></p>
<p>At first glance, it might look like both plans (optimized vs non optimized) are the same. However, two important optimizations have occured <strong>Projection pushdown</strong> and <strong>Predicate pushdown</strong>.</p>
<p>Polars has analyzed the query and noted that only use a small set of columns is used. For the trip data there are four columns. For the zone data there are two columns. Reading in the entire dataset would be wasteful as there is no need for the other columns. Therefore, by analyzing your query, <strong>Projection Pushdown</strong> will speed up reading in the data significantly. You can see the optimization in the leaf nodes under $\pi$  4/19 and $\pi$ 2/4.</p>
<p>With <strong>Predicate pushdown</strong> Polars filters data as close to the source as possible. This avoids reading in data that a later stage in the query will be discarded. The filter node has been moved to the parquet reader under $\sigma$ which indicates our reader will immediately remove rows which do not match our filter. The next join operation will a lot faster as there is less data coming in.</p>
<p>Polars supports a range of optimizations which can be viewed <a href="https://docs.pola.rs/user-guide/lazy/optimizations/">here</a>.</p>
<h2 id="query-execution">Query Execution</h2>
<p>Once the logical plan has been optimized, it is time for execution. The logical plan is a blueprint for what the user wants to execute, not the how. This is where the physical plan comes into play. A naive solution would be to have one join algorithm and one sort algorithm; that way, you could execute the logical plan directly. However, this comes at a huge performance cost, because knowing the characteristics of your data and the environment you run in allows Polars to select more specialized algorithms. Thus there is not one join algorithm, but multiple, each with their own unique style and performance. The query planner converts the LogicalPlan into a PhysicalPlan and picks the best algorithms for the query. Then our compute engine performs the operations. This post will not go into much detail about the execution model of our engines or how it is able to work so fast. That is left for another time.</p>
<p>When we look the performance difference of both plans (optimized vs non-optimized), we can see a 4x improvement. This is the power of lazy execution and using a query engine instead of eagerly evaluating every expression in order. It allows the engine to optimize and avoid unnecessary work. This whole improvement comes at zero cost for the user as all they have to do is write the query. All the complexity is hidden inside the query engine.</p>
<pre tabindex="0"><code><span><span>%%</span><span>time</span></span>
<span><span>query</span><span>.</span><span>collect</span><span>(no_optimization</span><span>=</span><span>True</span><span>)</span><span>;</span></span></code></pre>
<pre tabindex="0"><code><span><span>CPU times: user 2.45 s, sys: 1.18 s, total: 3.62 s</span></span>
<span><span>Wall time: 544 ms</span></span></code></pre>
<pre tabindex="0"><code><span><span>%%</span><span>time</span></span>
<span><span>query</span><span>.</span><span>collect</span><span>()</span><span>;</span></span></code></pre>
<pre tabindex="0"><code><span><span>CPU times: user 616 ms, sys: 54.2 ms, total: 670 ms</span></span>
<span><span>Wall time: 135 ms</span></span></code></pre>
<h2 id="conclusion">Conclusion</h2>
<p>During this post we covered the main components of Polars. Hopefully by now you will have a better understanding of how Polars works from its API down to execution. The next posts will dive deeper into every component, so stay tuned!</p>
<section data-footnotes="">
<ol>
<li id="user-content-fn-1">
<p>The NYE taxi trip dataset is available at <a href="https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page">nyc.gov</a>. <a href="#user-content-fnref-1" data-footnote-backref="" aria-label="Back to content">↩</a></p>
</li>
</ol>
</section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Fly.io Has GPUs Now (532 pts)]]></title>
            <link>https://fly.io/blog/fly-io-has-gpus-now/</link>
            <guid>39363499</guid>
            <pubDate>Tue, 13 Feb 2024 22:06:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fly.io/blog/fly-io-has-gpus-now/">https://fly.io/blog/fly-io-has-gpus-now/</a>, See on <a href="https://news.ycombinator.com/item?id=39363499">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
         <dl>
             <dt>Author</dt>
             <dd>
                 <img alt="Xe Iaso" src="https://fly.io/static/images/xe.webp">
               <dl>
                 <dt>Name</dt>
                 <dd>
                   Xe Iaso
                 </dd>
                  <dt>pony.social/@cadey</dt>
                  <dd>
                    <a href="https://pony.social/@cadey" target="_blank">
                      pony.social/@cadey
                    </a>
                  </dd>
               </dl>
             </dd>
         </dl>

        <section>
            <figure>
                <img src="https://fly.io/blog/fly-io-has-gpus-now/assets/llama-portal-cover.webp" alt="A cartoon illustration of a green haired woman with a ponytail looks into a portal in a datacentre to see a graceful llama.">
                <figcaption>
                  <span>Image by</span>
                  
<svg role="img" style="pointer-events: none; width: 17px; height: 17px;" viewBox="0 0 20 20" fill="currentColor" fill-rule="evenodd">
  <g buffered-rendering="static">
    <path fill-rule="evenodd" d="M1 8a2 2 0 012-2h.93a2 2 0 001.664-.89l.812-1.22A2 2 0 018.07 3h3.86a2 2 0 011.664.89l.812 1.22A2 2 0 0016.07 6H17a2 2 0 012 2v7a2 2 0 01-2 2H3a2 2 0 01-2-2V8zm13.5 3a4.5 4.5 0 11-9 0 4.5 4.5 0 019 0zM10 14a3 3 0 100-6 3 3 0 000 6z" clip-rule="evenodd"></path>
  </g>
</svg>

                    <a href="https://annieruygtillustration.com/" target="_blank">
                      Annie Ruygt
                    </a>
                </figcaption>
            </figure>
          <p>We’re Fly.io, we’re a new public cloud that lets you put your compute where it matters: near your users. Today we’re announcing that you can do this with GPUs too, allowing you to do AI workloads on the edge. Want to find out more? Keep reading.</p><h2 id="ai-is-pretty-fly"><a href="#ai-is-pretty-fly" aria-label="Anchor"></a>AI is pretty fly</h2>
<p>AI is apparently a bit of a <em>thing</em> (maybe even <em>an thing</em> come to think about it). We’ve seen entire industries get transformed in the wake of ChatGPT existing (somehow it’s only been around for a year, I can’t believe it either). It’s likely to leave a huge impact on society as a whole in the same way that the Internet did once we got search engines. Like any good venture-capital funded infrastructure provider, we want to enable you to do hilarious things with AI using industrial-grade muscle.</p>

<p>Fly.io lets you run a full-stack app - or an entire dev platform based on the <a href="https://fly.io/docs/machines/">Fly Machines API</a> - close to your users. Fly.io GPUs let you attach an <a href="https://www.nvidia.com/en-us/data-center/a100/">Nvidia A100</a> to whatever you’re building, harnessing the full power of CUDA with more VRAM than your local 4090 can shake a ray-traced stick at. With these cards (or whatever you call a GPU attached to SXM fabric), AI/ML workloads are at your fingertips. You can <a href="https://fly.io/blog/transcribing-on-fly-gpu-machines/">recognize speech</a>, segment text, summarize articles, synthesize images, and more at speeds that would make your homelab blush. You can even set one up as your programming companion with <a href="https://github.com/deepseek-ai/DeepSeek-Coder">your model of choice</a> in case you’ve just not been feeling it with the output of <em>other</em> models changing over time.</p>

<p>If you want to find out more about what these cards are and what using them is like, check out <a href="https://fly.io/blog/what-are-these-gpus-really/">What are these “GPUs” really?</a> It covers the history of GPUs and why it’s ironic that the cards we offer are called “Graphics Processing Units” in the first place.</p>
<h2 id="fly-io-gpus-in-action"><a href="#fly-io-gpus-in-action" aria-label="Anchor"></a>Fly.io GPUs in Action</h2>
<p>We want you to deploy your own code with your favorite models on top of Fly.io’s cloud backbone. Fly.io GPUs make this really easy.</p>

<p>You can get a GPU app running <a href="https://ollama.ai/">Ollama</a> (our friends in text generation) in two steps:</p>

<ol>
<li>Put this in your <code>fly.toml</code>:
</li></ol>
<div>
  <pre><code><span>app</span> <span>=</span> <span>"sandwich_ai"</span>
<span>primary_region</span> <span>=</span> <span>"ord"</span>
<span>vm.size</span> <span>=</span> <span>"a100-40gb"</span>

<span>[build]</span>
  <span>image</span> <span>=</span> <span>"ollama/ollama"</span>

<span>[mounts]</span>
  <span>source</span> <span>=</span> <span>"models"</span>
  <span>destination</span> <span>=</span> <span>"/root/.ollama"</span>
  <span>initial_size</span> <span>=</span> <span>"100gb"</span>
</code></pre>
</div>

<ol>
<li>Run <code>fly apps create sandwich_ai &amp;&amp; fly deploy</code>.
</li></ol>

<p>If you want to read more about how to start your new sandwich empire, check out <a href="https://fly.io/blog/scaling-llm-ollama/">Scaling Large Language Models to zero with Ollama</a>, it explains how to set up Ollama so that it <em>automatically scales itself down</em> when it’s not in use.</p>
<h2 id="the-speed-of-light-is-only-so-fast"><a href="#the-speed-of-light-is-only-so-fast" aria-label="Anchor"></a>The speed of light is only so fast</h2>
<p>Being able to spin up GPUs is great, but where Fly.io really shines is inference at the edge.</p>

<p>Let’s say you have an app that lets users enter ingredients they have in their kitchen and receive a sandwich recipe. Your users expect their recipes <em>instantly</em> (or at least as fast as the other leading apps). Seconds count when you need an emergency sandwich.</p>
<div><p>


It’s depressingly customary in the AI industry to cherry-pick outputs. This was not cherry-picked. I used <a href="https://ollama.ai/library/yi:34b">yi:34b</a> to generate this recipe. I’m not sure what a taco salad sandwich is, but I might be willing to try it.</p>
</div>
<p><img alt="A conversation between a user and an artificial intelligence. The user asks: &quot;What kind of sandwich can I make with an egg, a taco shell, and a pound of ground beef?&quot; The AI responds: &quot; You can make a breakfast taco or a taco salad sandwich with the ingredients you have. Here's how to prepare each: for the breakfast taco. Cook the pound of ground beef in a pan until browned. Season with salt, pepper, and any other desired spices like chili powder or taco seasoning. While the beef is cooking, fry an egg (or scramble it if you prefer) in another pan. Warm up the taco shell in the oven or microwave according to the package instructions. Assemble the taco by placing the ground cooked beef in the taco shell followed by the fried egg. You can also add any additional toppings like diced onions avocados, avocado, salsa or cheese if you have them. Serve with a side of hot sauce or sour cream if desired. For the taco salad sandwich: Prepare the ground beef as in the breakfast taco recipe above. Instead of frying an egg, you can cook it sunny side up or over easy depending on your preference. Crumble the taco shell into small pieces and mix them with the cooked ground beef. Assemble the sandwich by layering the crumbled taco shell mixture and ground beef in two slices of bread. Top with the fried egg and any additional toppings you like such as shredded lettuce, diced tomatoes, or sliced olives. Serve with a side of salsa or ranch dressing if desired. Both options are hardy and can be easily customized based on your taste preferences. Enjoy!&quot;" src="https://fly.io/blog/fly-io-has-gpus-now/assets/sandwich-recipes.webp"></p>

<p>In the previous snippet, we deployed our app to ord (<code>primary_region = "ord"</code>). The good news is that our model returns a result really quickly and users in Chicago get instant sandwich recipes. It’s a good experience for users near your datacentre, and you can do this on any half decent cloud provider.</p>

<p>But surely people outside of Chicago need sandwiches too. Amsterdam has sandwich fiends as well. And sometimes it takes too long to have their requests leap across the pond. The speed of light is only so fast after all. Don’t worry, we’ve got your back. Fly.io has GPUs in datacentres all over the world. Even more, we’ll let you run <em>the same program</em> with the same public IP address and the same TLS certificates in any regions with GPU support.</p>

<p>Don’t believe us? See how you can scale your app up in Amsterdam with one command:</p>
<div>
  <pre><code>fly scale count 2 --region ams
</code></pre>
</div>

<p>It’s that easy.</p>
<h2 id="actually-on-demand"><a href="#actually-on-demand" aria-label="Anchor"></a>Actually On-Demand</h2>
<p>GPUs are powerful parallel processing packages, but they’re not cheap! Once we have enough people wanting to turn their fridge contents into tasty sandwiches, keeping a GPU or two running makes sense. But we’re just a small app still growing our user base while also funding the latest large sandwich model research. We want to only pay for GPUs when a user makes a request.</p>

<p>Let’s open up that <code>fly.toml</code> again, and add a section called <code>services</code>, and we’ll include instructions on how we want our app to scale up and down:</p>
<div>
  <pre><code><span>[[services]]</span>
  <span>internal_port</span> <span>=</span> <span>8080</span>
  <span>protocol</span> <span>=</span> <span>"tcp"</span>
  <span>auto_stop_machines</span> <span>=</span> <span>true</span>
  <span>auto_start_machines</span> <span>=</span> <span>true</span>
  <span>min_machines_running</span> <span>=</span> <span>0</span>
</code></pre>
</div>

<p>Now when no one needs sandwich recipes, you don’t pay for GPU time.</p>
<h2 id="the-deets"><a href="#the-deets" aria-label="Anchor"></a>The Deets</h2>
<p>We have GPUs ready to use in several US and EU regions and Sydney. You can deploy your sandwich, music generation, or AI illustration apps to:</p>

<ul>
<li><a href="https://www.nvidia.com/en-us/data-center/a100/">Ampere A100s</a> with 40gb of RAM for $2.50/hr
</li><li><a href="https://www.nvidia.com/en-us/data-center/a100/">Ampere A100s</a> with 80gb of RAM for $3.50/hr
</li><li><a href="https://www.nvidia.com/en-us/data-center/l40/">Lovelace L40s</a> are coming soon (pricing TBD)
</li></ul>

<p>By default, anything you deploy to GPUs will use eight heckin’ <a href="https://www.amd.com/en/processors/epyc-server-cpu-family">AMD EPYC</a> CPU cores, and you can attach volumes up to 500 gigabytes. We’ll even give you discounts for reserved instances and dedicated hosts if you ask nicely.</p>

<p>We hope you have fun with these new cards and we’d love to see what you can do with them! Reach out to us on X (formerly Twitter) or <a href="https://community.fly.io/">the community forum</a> and share what you’ve been up to. We’d love to see what we can make easier!</p>

          
        </section>
        <dl>
            <dt>
              Next post  ↑
            </dt>
            <dd>
              <a href="https://fly.io/blog/fks/">
                Introducing Fly Kubernetes
              </a>
            </dd>
            <dt>
              Previous post  ↓
            </dt>
            <dd>
              <a href="https://fly.io/blog/what-are-these-gpus-really/">
                What are these "GPUs" really?
              </a>
            </dd>
        </dl>
      </article></div>]]></description>
        </item>
    </channel>
</rss>