<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Fri, 11 Oct 2024 16:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Manifest v2 is now removed from Chrome canary (144 pts)]]></title>
            <link>https://developer.chrome.com/docs/extensions/develop/migrate/mv2-deprecation-timeline</link>
            <guid>41809698</guid>
            <pubDate>Fri, 11 Oct 2024 14:20:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://developer.chrome.com/docs/extensions/develop/migrate/mv2-deprecation-timeline">https://developer.chrome.com/docs/extensions/develop/migrate/mv2-deprecation-timeline</a>, See on <a href="https://news.ycombinator.com/item?id=41809698">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

  
    




<p>Understand when Manifest V2 will stop working for extensions</p>

<h2 id="latest" data-text="Latest" tabindex="-1">Latest</h2>

<h3 id="october_9th_2024_an_update_on_manifest_v2_phase-out" data-text="October 9th 2024: an update on Manifest V2 phase-out." tabindex="-1">October 9th 2024: an update on Manifest V2 phase-out.</h3>

<p>Over the last few months, we have continued with the Manifest V2 phase-out.
Currently the chrome://extensions page displays a warning banner for all users
of Manifest V2 extensions. Additionally, we have started disabling Manifest V2
extensions on pre-stable channels.</p>

<p>We will now begin disabling installed extensions still using Manifest V2 in
Chrome stable. This change will be slowly rolled out over the following weeks.
Users will be directed to the Chrome Web Store, where they will be recommended
Manifest V3 alternatives for their disabled extension. For a short time, users
will still be able to turn their Manifest V2 extensions back on. Enterprises
using the
<a href="https://chromeenterprise.google/policies/#ExtensionManifestV2Availability">ExtensionManifestV2Availability</a>
policy will be exempt from any browser changes until June 2025. See our <a href="https://blog.chromium.org/2024/05/manifest-v2-phase-out-begins.html">May
2024 blog</a>
for more context.</p>

<h3 id="june_3rd_2024_the_manifest_v2_phase-out_begins" data-text="June 3rd 2024: the Manifest V2 phase-out begins." tabindex="-1">June 3rd 2024: the Manifest V2 phase-out begins.</h3>

<p>Starting on June 3rd on the Chrome Beta, Dev and Canary channels, if users still
have Manifest V2 extensions installed, some will start to see a warning banner
when visiting their extension management page - chrome://extensions - informing
them that some (Manifest V2) extensions they have installed will soon no longer
be supported. At the same time, extensions with the Featured badge that are
still using Manifest V2 will lose their badge.</p>

<h2 id="upcoming" data-text="Upcoming" tabindex="-1">Upcoming</h2>

<h3 id="june_2025_chrome_mv2_deprecation_enterprise_rollout" data-text="June 2025: Chrome MV2 deprecation enterprise rollout" tabindex="-1">June 2025: Chrome MV2 deprecation enterprise rollout</h3>

<p>Enterprises using the
<a href="https://chromeenterprise.google/policies/#ExtensionManifestV2Availability">ExtensionManifestV2Availability</a>
policy to ensure the continued functioning of Manifest V2 extensions in their
organization will have one additional year - until June 2025 - to migrate the
Manifest V2 extensions in their organization. Browsers with the policy enabled
won't be impacted by the rollout of the deprecation until that time.</p>

<h2 id="past" data-text="Past" tabindex="-1">Past</h2>

<h3 id="june_2022_chrome_web_store_-_no_new_private_extensions" data-text="June 2022: Chrome Web Store -  no new private extensions" tabindex="-1">June 2022: Chrome Web Store -  no new private extensions</h3>

<p>Chrome Web Store stopped accepting new Manifest V2 extensions with visibility
set to "Private".</p>

<h3 id="january_2022_chrome_web_store_-_no_new_public_unlisted_extensions" data-text="January 2022: Chrome Web Store - no new public / unlisted extensions" tabindex="-1">January 2022: Chrome Web Store - no new public / unlisted extensions</h3>

<p>Chrome Web Store stopped accepting new Manifest V2 extensions with visibility
set to "Public" or "Unlisted". The ability to change Manifest V2 extensions from
"Private" to "Public" or "Unlisted" was removed.</p>

  

  
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google Play killed my game and won't tell me why (114 pts)]]></title>
            <link>https://antiidlereborn.com/news/</link>
            <guid>41808917</guid>
            <pubDate>Fri, 11 Oct 2024 12:34:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://antiidlereborn.com/news/">https://antiidlereborn.com/news/</a>, See on <a href="https://news.ycombinator.com/item?id=41808917">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Hello everyone – this is Tukkun (of course) and this is my first real post on this website! I know you guys are all excited for the release of my upcoming game “Anti-Idle: Reborn” and it is my intention to keep this website updated with contents related to the game – its development, gameplay sneak peeks, and so on. But before that, today I’d like to write this post to explain the current situation.</p>







<h2>In short…</h2>



<ul>
<li>I have submitted the game “Anti-Idle: Reborn” to both Google and Apple for review. Both Google and Apple have reviewed the game and approved it for production.</li>



<li>Closed Beta of the game has been ongoing for about a month. People have found lots of weird bugs, and I have fixed many of them.</li>



<li>However, on October 7, 2024, without any prior warnings, Google decided to terminate my account due to “prior violations” and “High Risk Behavior”. I’ve re-read the policies, I’ve checked everything I can think of, and I still can’t figure out why.</li>



<li>I sent an appeal but it seems like they haven’t looked into it yet (as of October 11, 2024). I have gathered any information I can think of and sent it to the Google Play Team, but I only receive the same (possibly automated) response.</li>



<li>I have developed games for many years, and “Anti-Idle: Reborn” is more than just my passion. It’s over one year of full time work and dedication, and it is my future source of income. With the Google Play Developer account terminated, I can no longer continue work.</li>



<li>A quick search showed me that I am not the only one in this situation. Lots of other developers have had their account terminated for vague reasons, possibly by bots and automated algorithms, and received nothing other than automated messages when appealing.</li>



<li>I would like to emphasize that I understand the need for thorough app reviews and termination of accounts that violate the rules. However, this shouldn’t come at a cost of many good faith developers’ accounts being wrongly terminated.</li>
</ul>







<h2>The full story</h2>



<p>While I think most of you are familiar with my works and are just here to check for new information about my game <strong>Anti-Idle: Reborn</strong>, I understand that some of you might have gotten here from other pages and have no idea who I am. In that case, or in the rare case that a Google employee is somehow reading this, let me introduce myself.</p>



<p>I am <strong>Tukkun</strong>, an indie game developer making games since 2008. My most significant work is a PC Flash game I made back in 2009 called <a href="http://www.kongregate.com/games/tukkun/anti-idle-the-game" data-type="link" data-id="http://www.kongregate.com/games/tukkun/anti-idle-the-game"><strong>Anti-Idle: The Game</strong></a>, uploaded to the website Kongregate. As of the writing of this post, the game has been played 16,392,188 times (and this is not counting plays of the offline version). I know I shouldn’t say too much good stuff about my own projects (just like anything, my game had imperfections), but <strong>Anti-Idle: The Game</strong> is often said to have pioneered the idle game genre. It is one of the first games to popularize many mechanics often seen in modern idle games and is a source of inspiration for the development of many popular idle games, including several games on the Play Store (Android) and App Store (iOS). It is even mentioned in the <a href="https://en.wikipedia.org/wiki/Incremental_game">Wikipedia page for Incremental game</a>: </p>



<p><em>The early pioneers of idle games also saw some games parodying the genre, such as Anti-Idle (2009, by tukkun) which has elements of both active and idle games. The game was extremely complicated, content-rich, and constantly updated, and it helped popularize the genre.</em></p>


<div>
<figure><img decoding="async" loading="lazy" width="646" height="646" src="https://antiidlereborn.com/wp-content/uploads/2024/10/image.png" alt="" srcset="https://antiidlereborn.com/wp-content/uploads/2024/10/image.png 646w, https://antiidlereborn.com/wp-content/uploads/2024/10/image-300x300.png 300w, https://antiidlereborn.com/wp-content/uploads/2024/10/image-150x150.png 150w" sizes="(max-width: 646px) 100vw, 646px"></figure></div>


<p><em>A screenshot of “Anti-Idle: The Game”</em> </p>



<p>Following the success of <strong>Anti-Idle: The Game</strong>, I decided to develop the mobile sequel <strong>Anti-Idle: Reborn</strong>. I started doing serious design works on the game since 2023, and started programming it in Unity since the beginning of 2024, with the target of releasing it to Android and iOS late 2024.</p>



<p>The idea of developing a mobile sequel started as early as around 2020, with Flash no longer being supported by browsers, and lots of people in the community asked for a “mobile version” of the game. However, like many grown up adults, I had a day job and didn’t have enough free time to develop a mobile game. Despite that, I’ve released a few updates for the original Anti-Idle: The Game – 13 years after its initial release, the game still has a nice active community.</p>



<p><strong>That’s why I decided to follow my passion</strong> – I went as far as quitting my day job some time ago to fully dedicate myself to game development, and to make Anti-Idle live on. I’ve decided to announce and work on <strong>Anti-Idle: Reborn</strong> as my first mobile game. Creating a game from scratch feels great – when I managed to get the game design work on paper, when I opened Unity and created a simple loading screen that worked, when I got a prototype running… everything felt like a huge milestone.</p>


<div>
<figure><img decoding="async" loading="lazy" width="188" height="300" src="https://antiidlereborn.com/wp-content/uploads/2024/10/image-1-188x300.png" alt="" srcset="https://antiidlereborn.com/wp-content/uploads/2024/10/image-1-188x300.png 188w, https://antiidlereborn.com/wp-content/uploads/2024/10/image-1-640x1024.png 640w, https://antiidlereborn.com/wp-content/uploads/2024/10/image-1-768x1229.png 768w, https://antiidlereborn.com/wp-content/uploads/2024/10/image-1-960x1536.png 960w, https://antiidlereborn.com/wp-content/uploads/2024/10/image-1-1280x2048.png 1280w, https://antiidlereborn.com/wp-content/uploads/2024/10/image-1.png 1440w" sizes="(max-width: 188px) 100vw, 188px"></figure></div>


<p><em>A screenshot of “Anti-Idle: Reborn” (under development)</em></p>



<p>The day eventually came when I created enough features to launch the first version of the game and decided that <strong>Closed Beta</strong> can finally begin. I made a Google Forms so people can voluntarily register for Closed Beta and shared it with the community that still played my original game after over 14 years. To my surprise, they shared it to many other communities, including <a href="https://www.reddit.com/r/incremental_games/comments/1etrj2e/antiidles_mobile_sequel_closed_beta_opening_and/">this post on Reddit r/incremental_games</a>, and in total <strong>over 1000 people have applied</strong>!</p>



<p>Then, of course, in order to start Closed Beta, I would have to upload my game to the stores: Play Store (Android) and App Store (iOS). Little did I know, this is only the beginning of the story.</p>







<h3>Uploading the game to iOS</h3>



<p>I’ve always been under the impression that it is really difficult to upload a game to the App Store of iOS. They have always set high quality standards and from what I’ve heard, they seem to review apps really thoroughly.</p>



<p>And I guess I was right. Within a few hours of uploading my game to the App Store for review, it got rejected.</p>


<div>
<figure><img decoding="async" loading="lazy" width="1024" height="626" src="https://antiidlereborn.com/wp-content/uploads/2024/10/image-2-1024x626.png" alt="" srcset="https://antiidlereborn.com/wp-content/uploads/2024/10/image-2-1024x626.png 1024w, https://antiidlereborn.com/wp-content/uploads/2024/10/image-2-300x183.png 300w, https://antiidlereborn.com/wp-content/uploads/2024/10/image-2-768x470.png 768w, https://antiidlereborn.com/wp-content/uploads/2024/10/image-2.png 1248w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></div>


<p><em>Apple’s initial rejection</em></p>



<p>Oh, great, I knew it. Of course “Anti-Idle” is a world-renowned intellectual property and it is natural for Apple to think I have no permission to use it (sigh).</p>



<p>I attempted to convince Apple that I am the real Tukkun (because that’s who I am), and I submitted some proof to the Apple review team, including a screenshot of the source code of the original <strong>Anti-Idle: The Game</strong> and a link from my profile on Kongregate to this website of <strong>Anti-Idle: Reborn</strong>. I told Apple that I would provide any other information if necessary. A few hours later, they reviewed the game again, pointed out a bug and even sent screenshots as evidence. I fixed it, and they approved the game. All of the subsequent updates also passed through Apple’s review just fine. All good.</p>


<div>
<figure><img decoding="async" loading="lazy" width="836" height="279" src="https://antiidlereborn.com/wp-content/uploads/2024/10/image-5.png" alt="" srcset="https://antiidlereborn.com/wp-content/uploads/2024/10/image-5.png 836w, https://antiidlereborn.com/wp-content/uploads/2024/10/image-5-300x100.png 300w, https://antiidlereborn.com/wp-content/uploads/2024/10/image-5-768x256.png 768w" sizes="(max-width: 836px) 100vw, 836px"></figure></div>


<p><em>iOS version has been approved! Hooray!</em></p>







<h3>Uploading the game to Android</h3>



<p>Onto the next fun part – I entered the necessary information and uploaded the game to the Play Store. It seemed to get through review pretty quickly. I was able to get the Closed Beta up and running in no time. I think initial review for my first closed testing version took around half a day. My first impressions with the Google Play Console were pretty good, it’s easy and intuitive to use.</p>



<p>However, for the Play Store, there is a policy that before applying for production (which is required to start open testing and put the game on pre-registration) you need to run closed testing for at least 14 days with at least 20 testers (this seems like a new policy since 2023). All good, that sounds like it will increase the quality of apps uploaded to the store. And I didn’t have problem finding testers at all – as I said, I had over 1000 people applying so I just randomly picked 40 of them for the first phase of testing.</p>



<p>During testing, the testers have found a lot of bugs, ranging from minor ones to game-breaking ones, like microtransactions not working correctly, user data sometimes being rolled back and every action within the game causing serious lag. I fixed the game-breaking ones pretty quickly (as a result though, I didn’t have much time creating new features or writing progress updates). And with the game-breaking bugs gone, I have also fulfilled the requirements of “20 testers in 14 days” so I figured I should apply for production. So I did.</p>



<p>There was a questionnaire about how I found testers, what the testers did, how I incorporated the testers’ feedback, what makes the game stand out, and why I think the game is ready for production. I just answered the questions truthfully. And after Google’s review, on October 4, they approved my request for production! Look, I even received a congratulations email.</p>


<div>
<figure><img decoding="async" loading="lazy" width="631" height="386" src="https://antiidlereborn.com/wp-content/uploads/2024/10/image-3.png" alt="" srcset="https://antiidlereborn.com/wp-content/uploads/2024/10/image-3.png 631w, https://antiidlereborn.com/wp-content/uploads/2024/10/image-3-300x184.png 300w" sizes="(max-width: 631px) 100vw, 631px"></figure></div>


<p><em>My game has been granted Google Play production access!</em></p>



<p>Great! Now all that’s left is testing some more, improving the game quality and then publishing to production, right? That’s Google’s recommendation as well.</p>



<p>Unfortunately, before I could do that, three days after the above email, on October 7, testers started reporting that in-app purchases suddenly stopped working and the URL to download the game doesn’t work anymore. In a hurry, I checked and was shocked to find out that <strong>my account has been terminated</strong>.</p>


<div>
<figure><img decoding="async" loading="lazy" width="998" height="870" src="https://antiidlereborn.com/wp-content/uploads/2024/10/image-4.png" alt="" srcset="https://antiidlereborn.com/wp-content/uploads/2024/10/image-4.png 998w, https://antiidlereborn.com/wp-content/uploads/2024/10/image-4-300x262.png 300w, https://antiidlereborn.com/wp-content/uploads/2024/10/image-4-768x669.png 768w" sizes="(max-width: 998px) 100vw, 998px"></figure></div>


<p><em>My account has been terminated… Wait, what?</em></p>



<p>I did a quick search for the issue and learned that a termination for this reason is most likely related to <strong>prior violations, possibly prior violations of associated accounts</strong>. Which is weird. My app got two policy warnings from Google Play before, but both times I fixed it promptly, and according to Google’s <a href="https://support.google.com/googleplay/android-developer/answer/9899234?hl=en" data-type="link" data-id="https://support.google.com/googleplay/android-developer/answer/9899234?hl=en">Enforcement Process</a>, app rejections or violations of this level shouldn’t affect the standing of my account. And my game was even approved for production. Which leads me think of prior violations of associated accounts. But what’s an associated account exactly? I am an indie developer and this is my first and only account. Well, I did add some trusted developers and testers into the internal testing track, but I’ve checked with them and they insist that their accounts are in good standing. Do the 40 testers I added for closed testing count? And why should I be responsible for their prior violations (how do I even know whether they made any violations in the first place)?</p>



<p>I even took extra precaution steps: I used my Google Play Console account on only one device that I use for releasing the game, I didn’t use VPN, I didn’t use the same network with other people, and ensured I didn’t accidentally connect to some public Wi-Fi. And yet Google still decided that my account has a “high risk of abuse” and terminated it.</p>



<p>I have heard a lot of stories about other Android developers having their accounts terminated, but I never thought it would happen to me. I re-read their policies once again just to be sure (by now, I think I’ve read through Google’s policies at least five times). Believing that I did nothing wrong, I sent an appeal.</p>







<h3>Appealing</h3>



<p>The appeal form only allowed me to enter 1000 characters, so this is what I wrote.</p>



<hr>



<p><em>After thoroughly checking the Developer Program Policies and Developer Distribution Agreement, as well as the Policy Coverage policy, I don’t believe I have made any violations that could have led to account termination. I have promptly resolved violations in the past, and my app was even approved for production a few days ago. I am also working closely with my testers in Closed Testing to fix bugs, improve app performance, and ensure that my game “Anti-Idle: Reborn” meets all of Google’s standards and meets user expectations prior to production. I am new to the Developer Program, this is my first account and my first app. I don’t know about “associated accounts” but if this includes the testers’ emails I have added, they are users who volunteered to test my game and I’m not associated with any of their violations (if any). I am always thriving to improve app quality and would greatly appreciate it if you could tell me what is wrong with my app or account so that I could resolve it.</em></p>



<hr>







<p>In hindsight, that was probably not the most useful information that could have fit into 1000 characters, but that’s all I could think of at the time.</p>



<p>I received a system email saying that my appeal would be reviewed by a specialist, subsequently followed by an email with the name of a person at Google (presumably the “specialist”).</p>



<hr>



<p><em>Hi developers at Tukkun,</em></p>



<p><em>Thanks for contacting the Google Play team.</em></p>



<p><em>I’ve received your appeal and I appreciate your patience while I look into it.</em></p>



<p><em>I’ll let you know as soon as I have any additional information to share. Please let me know if you have any questions in the meantime.</em></p>



<p><em>[…]</em></p>



<p><em>Regards,<br>[Name of Google specialist]</em></p>



<hr>







<p>I subsequently sent some additional information in relatively lengthy emails, basically everything that I can think of.</p>



<ul>
<li>Any information I know about my prior violations (I’ve promptly resolved them anyway)</li>



<li>How I am “the real Tukkun” and have rights to the things I’m using within the game (basically the same things I’ve sent Apple)</li>



<li>How I’ve put my heart and soul into the development of Anti-Idle: Reborn and that it is a very anticipated release. I’ve even sent screenshots of the game’s design files</li>



<li>Anything I know about what’s possibly considered “associated accounts”</li>



<li>Anything else that I think might be the problem</li>
</ul>



<p>I just said everything I can know of with all of my honesty, and said that whatever the problem is I am committed to resolving it. I still have no idea what the exact problem is though. Of course, in my emails, I tried asking for more information too.</p>



<p>However, both times I contacted them, they responded with the exact same email:</p>



<hr>



<p><em>Hi developers at Tukkun,</em></p>



<p><em>Thanks again for contacting the Google Play team.</em></p>



<p><em>I’ve received your appeal and I appreciate your patience while I look into it.</em></p>



<p><em>I’ll let you know as soon as I have any additional information to share.</em></p>



<p><em>Regards,<br>[Name of Google specialist]</em></p>



<hr>







<p>They didn’t respond instantly, but several hours after I sent the information. And to be fair they did say “thanks <span>again</span>” (they know it’s not the first time I contacted them), but there’s no other useful information in the email. At this point I’m not even sure if that’s an actual human or just an automated email delayed to feel human. I wouldn’t even be surprised if Google started giving AI unique “names” to make them sound like human specialists.</p>



<p>According to Google, it can take up to 7 days for them to make a decision. As of the writing of this post, it is the 4th day. There’s still time and I guess “I appreciate your patience” is still better than a rejection, but I am beginning to get impatient and this is affecting my future plans for the development of Anti-Idle: Reborn. And the Closed Beta testers are just as impatient as I am.</p>



<p>I still believe that I have done nothing wrong, and I hoped it would be easy to show my good faith (just like how Apple immediately re-reviewed my app after I sent the evidence that I am indeed Tukkun), but I’m starting to get more and more worried as each day passes without any new information. And from what I’ve read about these appeals, most of the time they just get rejected for vague reasons.</p>



<p>And that’s it. Over 15 years of game development, first app on Android with over 1 year of development, and my career as an Android game developer is at stake for no reason, even before the game is released.</p>



<p>Dear everyone who is looking forward to the release of Anti-Idle: Reborn on Android, thank you for your continued support and your interest in the game. While I can’t make any promises under the current situation, I will keep you updated with any new information.</p>



<p>Dear Google, thank you for providing a trustworthy place for app developers to provide apps to billions of users. Once again, I would like to emphasize that I understand the need for thorough app reviews and termination of accounts that violate the rules. It is what allows users to trust the Google Play Store to download and use apps. However, it also needs trust from developers so they can confidently develop great apps without the fear of everything being erased without prior warning and for no reason.</p>



<p>Please, tell me what I am doing wrong and what I can do to have my account and my game restored. Anti-Idle: Reborn is my hopes and dreams, and a large community is waiting for it to become a reality.</p>



<hr>



<p><em>In case anyone at Google is reading this, my appeal ticket number is <strong>6-1733000037134</strong>, and my game’s package ID (before it was removed from Google Play) is <strong>com.tukkun.anti.idle.reborn</strong></em></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A Lisp compiler to RISC-V written in Lisp (157 pts)]]></title>
            <link>http://www.ulisp.com/show?4Y20</link>
            <guid>41808696</guid>
            <pubDate>Fri, 11 Oct 2024 11:56:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://www.ulisp.com/show?4Y20">http://www.ulisp.com/show?4Y20</a>, See on <a href="https://news.ycombinator.com/item?id=41808696">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">

<p>11th October 2024</p>
<p>This is a simple experimental Lisp compiler, written in uLisp, that will compile a Lisp function into RISC-V machine code. You can run the compiler on the RISC-V core of a Raspberry Pi Pico 2 (or another RP2350-based board):</p>
<p><img src="http://www.ulisp.com/pictures/3j/raspberrypipico2.jpg" alt="RaspberryPiPico2.jpg" width="600" height="275"></p>
<p>It's based on my earlier project&nbsp;<a href="http://www.ulisp.com/show?4W2I">A Lisp compiler to ARM written in Lisp</a>.</p>
<h4><span>Introduction</span></h4>
<p>When I added the facility of executing machine code to uLisp I had in mind the eventual goal of being able to compile uLisp functions into machine code, and this is a first step in that direction.</p>
<p>The nice thing about compiling Lisp is that you don't have to write a tokeniser or parser, because Lisp programs are already in a consistent structure that can be processed by another Lisp program.</p>
<p>The compiler program is written in the subset of Common Lisp supported by uLisp, and will run on the RISC-V core of a RP2350-based board; I used a Raspberry Pi Pico 2. You can also run it using Common Lisp on a laptop or desktop computer, and display the code it generates, but of course you won't be able to run the RISC-V machine code because Common Lisp doesn't have uLisp's <strong>defcode</strong> command.</p>
<p>I got my initial inspiration for this compiler from Peter Norvig's book "Paradigms of Artificial Intelligence Programming" <sup id="cite_ref1"><a href="#cite_note1">[1]</a></sup>.</p>
<h4>Resources</h4>
<p>To use the compiler you first need to load the RISC-V assembler from:&nbsp;<a href="http://www.ulisp.com/list?31OE">RISC-V assembler in uLisp</a>.</p>
<p>Get the full source of the compiler here:&nbsp;<a href="http://www.ulisp.com/list?4Y4Q">Lisp compiler for RISC-V</a>.</p>
<p>Or from GitHub here:&nbsp;<a href="https://github.com/technoblogy/lisp-arm-compiler" target="_blank">https://github.com/technoblogy/lisp-arm-compiler</a>.</p>
<p>For information about setting up uLisp on a Raspberry Pi Pico 2 see:&nbsp;<a href="http://www.ulisp.com/show?4X21">Raspberry Pi Pico 2</a>.</p>
<h4>Using the compiler</h4>
<p>To run the compiler you simply call <strong>compile</strong> on a Lisp function; for example:</p>
<pre>(compile 'fibonacci)</pre>
<p>The function will be compiled into a machine code function, replacing the original Lisp code, so that calling <strong>fibonacci</strong> will now execute the RISC-V machine-code version.</p>
<p>You can also display the code generated for an expression by calling <strong>comp</strong> on the expression; for example:</p>
<pre>(pprint (comp '(* 13 17)))

(:integer
  ($li 'a0 13)
  ($addi 'sp 'sp -4)
  ($sw 'a0 0 '(sp))
  ($li 'a0 17)
  ($lw 'a1 0 '(sp))
  ($addi 'sp 'sp 4)
  ($mul 'a0 'a1 'a0))</pre>
<p>The <strong>:integer</strong> prefix shows that the result is an integer; see below.</p>
<p>For examples of several simple Lisp programs that it will successfully compile see <a href="#examples">Examples</a> below. These also give a comparison of the speed of the Lisp and machine-code versions.</p>
<h4>Specification</h4>
<p>The compiler understands the following Lisp objects:</p>
<p><strong>Defining variables and functions:</strong> defun, setq</p>
<p><strong>Symbols:</strong> nil, t</p>
<p><strong>List functions:</strong> car, cdr</p>
<p><strong>Arithmetic functions:</strong> +, -, *, /, mod, 1+, 1-</p>
<p><strong>Arithmetic comparisons:</strong> =, &lt;, &lt;=, &gt;, &gt;=, /=</p>
<p><strong>Conditionals:</strong> if, and, or</p>
<h4>Tail-call optimisation</h4>
<p>Although the compiler doesn't include any iteration constructs, it does provide tail-call optimisation which can make recursive programs as efficient as iterative ones. Consider this recursive program to add two positive numbers:</p>
<pre>(defun add (a b)
  (if (= b 0) a
    (add (+ a 1) (- b 1))))</pre>
<p>On a system without tail-call optimisation, evaluating:</p>
<pre>(add 10000 10000)</pre>
<p>will probably fail, because it requires 10000 stack frames to store the intermediate results. This compiler recognises that the recursive call to <strong>add</strong> can be replaced by a jump to the start of the program, and so it has no problem evaluating it. For a more sensible example see <strong><a href="#factor">factor</a></strong> below.</p>
<h3>How the compiler works</h3>
<h4>Register usage</h4>
<p>To avoid needing to keep track of register usage the compiler makes use of the stack to pass values to an expression, and store the value returned by an expression.</p>
<p>The following table shows how the RISC-V registers are used within the compiler:</p>
<table>
<thead>
<tr>
<td><strong>Registers</strong></td>
<td><strong>Use</strong></td>
</tr>
</thead>
<tbody>
<tr>
<td>a0 a1 a2 a3</td>
<td>Used to pass the parameters to the main function's arguments.</td>
</tr>
<tr>
<td>a0</td>
<td>Contains the value returned by the main function.</td>
</tr>
<tr>
<td>a4 a5 a6 a7</td>
<td>Contain copies of the function arguments within the function.</td>
</tr>
<tr>
<td>a0 a1</td>
<td>Used to pass the arguments to each operator.</td>
</tr>
<tr>
<td>a0</td>
<td>Used to return the value from each operator.</td>
</tr>
<tr>
<td>s0 to s11</td>
<td>Local variables.</td>
</tr>
</tbody>
</table>
<h4>Compiling an expression</h4>
<p>The following steps show the sequence of compiling an expression, such as:</p>
<pre>(* x 13)</pre>
<ul>
<li>Code is generated to evaluate each of the arguments, in this case <strong>x</strong> and 13, and each result is pushed onto the stack, apart from the last which is left in <strong>a0</strong>.</li>
<li>The first value is popped from the stack into register&nbsp;<strong>a1.</strong></li>
<li>The function, in this case *, is then evaluated for <strong>a1</strong> and <strong>a0</strong>, with the result in <strong>a0</strong>.</li>
</ul>
<p>This stack-based approach ensures that a more complex expression, such as:</p>
<pre>(* (- x 1) (+ x 13))</pre>
<p>will also compile into correct code, without conflicts between registers.</p>
<h4>Calling the function recursively</h4>
<p>The compiler supports calling a function recursively from within the function itself. Because the registers corresponding to the parameters and local variables would be overwritten by the recursive call they are stored on the stack around the function call.</p>
<p>There are several recursive functions in the examples below.</p>
<h4>Types</h4>
<p>For boolean operations I decided to represent <strong>nil</strong> as 0, and <strong>t</strong> as 1. A problem I hadn't anticipated was that I would need to keep track of what type of object each function returned, integer or boolean. For example, consider the problem of compiling the statement:</p>
<pre>(and x y)</pre>
<p>If <strong>x</strong> has the value 0 and <strong>y</strong> has the value 7 this should return 7. However, if <strong>x</strong> has the value <strong>nil</strong>&nbsp;and&nbsp;<strong>y</strong>&nbsp;has the value 7 this should return <strong>nil</strong>. Representing <strong>nil</strong> as zero leads to an ambiguity.</p>
<p>I solved this by returning a type, <strong>:integer</strong> or <strong>:boolean</strong>, with each compiled expression, according to the following rules:</p>
<ul>
<li>Predicates, and <strong>t</strong> or <strong>nil</strong>, always return a <strong>:boolean</strong>.</li>
<li>Arithmetic operations always return an <strong>:integer</strong>.</li>
<li>An <strong>if</strong> form requires a <strong>:boolean</strong> test form and returns an <strong>:integer</strong>.</li>
<li>A <strong>progn</strong>&nbsp;or <strong>let</strong> block returns the type of its last expression.</li>
</ul>
<p>An item with an ambiguous type returns the type <strong>nil</strong>.</p>
<h4>Running the examples</h4>
<p>I used the following simple examples to test the compiler. Before compiling a new function you might want to remove the previous one from memory using&nbsp;<strong>makunbound</strong>&nbsp;to free up the code memory before compiling the next function; for example:</p>
<pre>(makunbound 'fibonacci)</pre>
<p>Alternatively you could increase the amount of memory available for machine code by editing the directive such as:</p>
<pre>#define CODESIZE 256&nbsp;</pre>
<p>before uploading uLisp to your board.</p>
<h3 id="examples">Examples</h3>
<p>The following examples take integer arguments and return an integer result.</p>
<h4 id="factor">Factor</h4>
<p>This function takes a simple approach to finding the least prime factor of a number:</p>
<pre>(defun factor (n d)
  (if (&gt; (* d d) n) n
   (if (= 0 (mod n d)) d
     (factor n (1+ d)))))</pre>
<p>It should be called with n equal to the number to be factorized, and d=2. It takes advantage of the compiler's tail-call optimisation, which makes it as efficient as an iterative solution. If the number is prime,&nbsp;factor&nbsp;will print the number itself.</p>
<p>To find the least prime factor of&nbsp;2146654199 (46327 x 46337):</p>
<p>Lisp version:</p>
<pre>&gt; (time (factor 2146654199 2))
46327
Time: 5.4 s</pre>
<p>Compiled version:</p>
<pre>&gt; (time (factor 2146654199 2))
46327
Time: 19 ms</pre>
<p>You can use the above&nbsp;function as the basis for a simple recursive routine to factorize a number into a list of its prime factors:</p>
<pre>(defun factorize (n)
  (let ((f (factor n 2)))
    (if (= n f) (list n) (cons f (factorize (/ n f))))))</pre>
<p>For example:</p>
<pre>&gt; (factorize 731731731)
(3 17 43 333667)</pre>
<h4>Takeuchi function</h4>
<p>This is a version of the highly-recursive benchmark I use for comparing versions of Lisp <sup id="cite_ref2"><a href="#cite_note2">[2]</a></sup>:</p>
<pre>(defun tak (x y z)
  (if (&gt;= y x) z
    (tak
     (tak (1- x) y z)
     (tak (1- y) z x)
     (tak (1- z) x y))))</pre>
<p>Lisp version:</p>
<pre>&gt; (time (tak 18 12 6))
7
Time: 4.1 s
</pre>
<p>Compiled version</p>
<pre>&gt; (time (tak 18 12 6))
7
Time: 16 ms</pre>
<h4>Factorial</h4>
<p>This is a recursive implementation of the factorial function:</p>
<pre>(defun fact (n)
  (if (&lt;= n 1) 1
    (* n (fact (- n 1)))))</pre>
<p>Lisp version:</p>
<pre>&gt; (time (fact 12))
479001600
Time: 1 ms
</pre>
<p>Compiled version</p>
<pre>&gt; (time (fact 12))
479001600
Time: 0 ms</pre>
<h4>Fibonacci</h4>
<p>This is a recursive implementation of the Fibonacci series:</p>
<pre>(defun fibonacci (n)
  (if (&lt; n 3) 1
    (+ (fibonacci (- n 1)) (fibonacci (- n 2)))))</pre>
<p>Lisp version:</p>
<pre>&gt; (time (fibonacci 27))<br>196418
Time: 50.5 s
</pre>
<p>Compiled version</p>
<pre>&gt; (time (fibonacci 27))
196418
Time: 80 ms</pre>
<h4>Greatest Common Divisor</h4>
<p>A recursive algorithm to calculate the greatest common divisor of two integers.</p>
<pre>(defun gcd (a b)
  (if (= b 0) a
   (gcd b (mod a b))))</pre>
<p>Lisp version:</p>
<pre>&gt; (time (gcd 2032460032 2056252672))
256
Time: 1 ms
</pre>
<p>Compiled version</p>
<pre>&gt; (time (gcd 2032460032 2056252672))
256
Time: 0 ms</pre>
<h4>Hofstadter Q sequence</h4>
<p>This is one of several recursive sequences described in Douglas Hofstadter's book "Gödel, Escher, Bach: an Eternal Golden Braid". It is defined as follows:</p>
<pre>(defun q (n)
  (if (&lt;= n 2) 1
    (+
     (q (- n (q (- n 1))))
     (q (- n (q (- n 2)))))))</pre>
<p>It is related to the Fibonacci sequence, except that in this case&nbsp;the two preceding terms specify how far to go back in the sequence to find the two terms to be summed.</p>
<p>Lisp version:</p>
<pre>&gt; (time (q 21))
12
Time: 8.6 s
</pre>
<p>Compiled version</p>
<pre>&gt; (time (q 21))
12
Time: 25 ms</pre>
<h4>Two-dimensional recursive function Q2</h4>
<p>This function Q2 is my two-dimensional extension of the Hofstadter Q sequence <sup id="cite_ref3"><a href="#cite_note3">[3]</a></sup>:</p>
<pre>(defun q2 (x y)
  (if (or (&lt; x 1) (&lt; y 1)) 1
    (+ (q2 (- x (q2 (1- x) y)) y)
       (q2 x (- y (q2 x (1- y)))))))</pre>
<p>Lisp version:</p>
<pre>&gt; (time (q2 7 8))
31
Time: 13.8 s
</pre>
<p>Compiled version</p>
<pre>&gt; (time (q2 7 8))
31
Time: 50 ms</pre>
<h4>Number of combinations - nCr</h4>
<p>This is a simple but very inefficient way of recursively calculating nCr, based on Pascal's Triangle:</p>
<pre>(defun ncr (n r)
  (if (or (= r 0) (= r n)) 1
    (+ (ncr (1- n) (1- r)) (ncr (1- n) r))))</pre>
<p>For example, to calculate the number of possible poker hands from a pack of cards:</p>
<p>Lisp version:</p>
<pre>&gt; (time (ncr 52 5))
2598960
Time: 615.5 s
</pre>
<p>Compiled version</p>
<pre>&gt; (time (ncr 52 5))
2598960
Time: 1.7 s</pre>
<h3 id="listexamples">List examples</h3>
<p>Any of the arguments to a machine-code function can be a list, in which case the address of the list is passed to the routine in the corresponding parameter. You can then use the functions <strong>car</strong> and <strong>cdr</strong> to process the elements in the list.</p>
<h4>Dot product</h4>
<p>This recursive function calculates the dot product of two vectors:</p>
<pre>(defun dot-product (a b)
  (if (and a b)
      (+ (* (car a) (car b)) (dot-product (cdr a) (cdr b)))<br>    0))</pre>
<p>It can handle two vectors of arbitrary length provided they are the same length.</p>
<p>For example, to calculate the following dot product:</p>
<p>(987 654 321)&nbsp;•&nbsp;(963 852 741) = 987&nbsp;×&nbsp;963 + 654&nbsp;×&nbsp;852 + 321&nbsp;×&nbsp;741 = 1745550</p>
<p>Lisp version:</p>
<pre>&gt; (time (dot-product '(987 654 321) '(963 852 741)))
1745550
Time: 0 ms
</pre>
<p>Compiled version</p>
<pre>&gt; (time (dot-product '(987 654 321) '(963 852 741)))
1745550
Time: 0 ms</pre>
<h3>Compiler source</h3>
<p>Here's a description of the source of the compiler.</p>
<h4>Invoking the compiler</h4>
<p>To compile a Lisp function you simply give the command compile followed by the name of the function; for example, to compile the <strong>fibonacci</strong> function:</p>
<pre>(compile 'fibonacci)</pre>
<p>Here's the definition of the command <strong>compile</strong>:</p>
<pre>(defun compile (name)
  (if (eq (car (eval name)) 'lambda)
    (eval (comp (cons 'defun (cons name (cdr (eval name))))))
 "Not a Lisp function"))</pre>
<h4>Main compiler function</h4>
<p>The main function&nbsp;<strong>comp</strong> returns the compiled code for an expression or form, as a list of assembler instructions prefixed by the type, <strong>:integer</strong> or <strong>:boolean</strong>:</p>
<pre>(defun comp (x &amp;optional env tail)
  (cond
   ((null x) (type-code :boolean '(($li 'a0 0))))
   ((eq x t) (type-code :boolean '(($li 'a0 1))))
   ((symbolp x) (comp-symbol x env tail))
   ((atom x) (type-code :integer (list (list '$li ''a0 x))))
   (t (let ((fn (first x)) (args (rest x)))
        (case fn
          (defun (setq *label-num* 0)
                 (setq env (mapcar #'(lambda (x y) (cons x y)) (second args) *locals*))
                 (comp-defun (first args) (second args) (cddr args) env))
          (progn (comp-progn args env tail))
          (if    (comp-if (first args) (second args) (third args) env tail))
          (setq  (comp-setq args env tail))
          (t     (comp-funcall fn args env tail)))))))</pre>
<p>The function <strong>comp</strong> takes the item <strong>x</strong> to be compiled,&nbsp;the current environment <strong>env</strong> associating each local variable with a register, and a flag <strong>tail</strong>&nbsp;which is true if the item has no successors.</p>
<p>Each of the different types of form are handled by separate functions such as <strong>comp-defun</strong>, <strong>comp-if</strong>, and <strong>comp-progn</strong>.</p>
<h4>Utilities</h4>
<p>The compiler uses the following utility functions:</p>
<p>The functions <strong>push-regs</strong> and <strong>pop-regs</strong> generate instructions to push a list of registers to the stack, and pop a list of registers from the stack:</p>
<pre>(defun push-regs (&amp;rest regs)
  (let ((n -4))
  (append
   (list (list '$addi ''sp ''sp (* -4 (length regs))))
   (mapcar #'(lambda (reg) (list '$sw (list 'quote reg) (incf n 4) ''(sp))) regs))))

(defun pop-regs (&amp;rest regs)
  (let ((n (* 4 (length regs))))
  (append
   (mapcar #'(lambda (reg) (list '$lw (list 'quote reg) (decf n 4) ''(sp))) regs)
   (list (list '$addi ''sp ''sp (* 4 (length regs)))))))</pre>
<p>The function <strong>mappend</strong> applies a function to the elements of a list, and the results, which should be lists, are appended together:</p>
<pre>(defun mappend (fn lst)
  (apply #'append (mapcar fn lst)))</pre>
<p>The function <strong>type-code</strong> adds a code type label to the front of a list of assembler instructions, and the functions code-type and code return the code type label, and the code list, respectively:</p>
<pre>(defun type-code (type code) (cons type code))

(defun code-type (type-code) (car type-code))

(defun code (type-code) (cdr type-code))</pre>
<p>The function <strong>checktype</strong> gives an error if the value returned is not the correct type:</p>
<pre>(defun checktype (fn type check)
  (unless (or (null type) (null check) (eq type check))
    (error "Argument to '~a' must be ~a not ~a~%" fn check type)))</pre>
<p>The lists <strong>*params*</strong> and <strong>*locals*</strong> list the registers available for use in the compiler:</p>
<pre>(defvar *params* '(a0 a1 a2 a3))

(defvar *locals* '(a4 a5 s0 s1 a6 a7 s2 s3 s4 s5 s6 s7 s8 s9 s10 s11))</pre>
<p>Finally, <strong>gen-label</strong> generates a new label for use in branches and jumps:</p>
<pre>(defvar *label-num* 0)

(defun gen-label ()
  (read-from-string (format nil "lab~d" (incf *label-num*))))</pre>
<p>The remaining functions handle the compiling of specific types of Lisp form:</p>
<h4>Symbols</h4>
<p>The environment is represented by an association list giving the register associated with each variable, such as:</p>
<pre>((y . r5) (x . r4))</pre>
<p>The function <strong>comp-symbol</strong> looks up a symbol in the association list and returns the appropriate register:</p>
<pre>(defun comp-symbol (x env)
  (let ((reg (cdr (assoc x env))))
    (type-code nil (list (list '$mv ''a0 (list 'quote reg))))))</pre>
<h4>Assignment</h4>
<p>The function <strong>comp-setq</strong> handles assignment to a variable:</p>
<pre>(defun comp-setq (args env tail)
  (let ((value (comp (second args) env tail))
        (reg (cdr (assoc (first args) env))))
    (type-code 
     (code-type value) 
     (append (code value) (list (list '$mv (list 'quote reg) ''a0))))))</pre>
<h4>Function definition</h4>
<p>The definition of the function being compiled is handled by <strong>comp-defun</strong>:</p>
<pre>(defun comp-defun (name args body env)
  (setq *used-params* (subseq *locals* 0 (length args)))
  (append 
   (list 'defcode name args)
   (list name)
   (apply #'append 
          (mapcar #'(lambda (x y) (list (list '$mv (list 'quote x) (list 'quote y))))
                  *used-params* *params*))
   (code (comp-progn body env t))))</pre>
<h4>Progn special form</h4>
<p>The function <strong>comp-progn</strong> compiles a <strong>progn</strong> form:</p>
<pre>(defun comp-progn (exps env tail)
  (let* ((len (1- (length exps)))
         (nlast (subseq exps 0 len))
         (last1 (nth len exps))
         (start (mappend #'(lambda (x) (append (code (comp x env t)))) nlast))
         (end (comp last1 env tail)))
    (type-code (code-type end) (append start (code end)))))</pre>
<p>It compiles code to evaluate each expression in the body of the <strong>progn</strong>, discarding all but the last results, and returns the type of the last form as the type of the whole block.</p>
<h4>If special form</h4>
<p>The function <strong>comp-if</strong> compiles the code for an <strong>if</strong> special form:</p>
<pre>(defun comp-if (pred then else env tail)
  (let ((lab1 (gen-label))
        (lab2 (gen-label))
        (test (comp pred env nil)))
    (checktype 'if (car test) :boolean)
    (type-code :integer
               (append
                (code test) (list (list '$beqz ''a0 lab1))
                (code (comp then env t)) (list (list '$j lab2) lab1)
                (code (comp else env tail)) (list lab2)
                (when tail '(($ret)))))))</pre>
<h4>Function calls</h4>
<p>Finally, <strong>comp-funcall</strong> compiles code for function calls to the built-in functions, or a recursive call to the main function:</p>
<pre>(defun comp-funcall (f args env tail)
  (let ((test (assoc f '((&lt; . $slt) (&gt; . $sgt))))
        (teste (assoc f '((= . $seqz) (/= . $snez))))
        (testn (assoc f '((&gt;= . $slt) (&lt;= . $sgt))))
        (logical (assoc f '((and . $and) (or . $or))))
        (arith1 (assoc f '((1+ . 1) (1- . -1))))
        (arith (assoc f '((+ . $add) (- . $sub) (* . $mul) (/ . $div) (mod . $rem)))))
    (cond
     ((or test teste testn)
      (type-code :boolean
                   (append
                    (comp-args f args 2 :integer env)
                    (pop-regs 'a1)
                    (cond
                     (test (list (list (cdr test) ''a0 ''a1 ''a0)))
                     (teste (list '($sub 'a0 'a1 'a0) (list (cdr teste) ''a0 ''a0)))
                     (testn (list (list (cdr testn) ''a0 ''a1 ''a0) '($xori 'a0 'a0 1))))
                    (when tail '(($ret))))))
     (logical 
      (type-code :boolean
                 (append
                  (comp-args f args 2 :boolean env)
                  (pop-regs 'a1)
                  (list (list (cdr logical) ''a0 ''a0 ''a1))
                  (when tail '(($ret))))))
     (arith1
      (type-code :integer
                 (append
                  (comp-args f args 1 :integer env)
                  (list (list '$addi ''a0 ''a0 (cdr arith1)))
                  (when tail '(($ret))))))
     (arith
      (type-code :integer 
                 (append
                  (comp-args f args 2 :integer env)
                  (pop-regs 'a1)
                  (list (list (cdr arith) ''a0 ''a1 ''a0))
                  (when tail '(($ret))))))
     ((member f '(car cdr))
      (type-code :integer
                 (append
                  (comp-args f args 1 :integer env)
                  (if (eq f 'cdr) (list '($lw 'a0 4 '(a0)))
                    (list '($lw 'a0 0 '(a0)) '($lw 'a0 4 '(a0))))
                  (when tail '(($ret))))))
     (t ; function call
      (type-code :integer 
                 (append
                  (comp-args f args nil :integer env)
                  (when (&gt; (length args) 1)
                    (append
                     (list (list '$mv (list 'quote (nth (1- (length args)) *params*)) ''a0))
                     (apply #'pop-regs (subseq *params* 0 (1- (length args))))))
                  (cond
                   (tail (list (list '$j f)))
                   (t (append
                       (apply #'push-regs (cons 'ra (reverse *used-params*)))
                       (list (list '$jal f))
                       (apply 'pop-regs (append *used-params* (list 'ra))))))))))))</pre>
<p>The arithmetic comparisons take advantage of the RISC-V instructions such as <strong>slt</strong>&nbsp;(Set if less than), which set the destination register to 0 if the comparison is false, and to 1 if it's true; this provides the required boolean result without needing a branch.</p>
<p>The function <strong>comp-funcall</strong> uses the routine&nbsp;<strong>comp-args</strong>&nbsp;to generate code to compile each of the arguments to a function:</p>
<pre>(defun comp-args (fn args n type env)
  (unless (or (null n) (= (length args) n))
    (error "Incorrect number of arguments to '~a'" fn))
  (let ((n (length args)))
    (mappend #'(lambda (y)
                 (let ((c (comp y env nil)))
                   (decf n)
                   (checktype fn type (code-type c))
                   (if (zerop n) (code c) (append (code c) (push-regs 'a0)))))
             args)))</pre>
<h3>Appendix</h3>
<p>The following example shows the code generated by a simple function,&nbsp;<strong>rec</strong>, a recursive function related to the factorial function:</p>
<pre>(defun rec (n)
  (1+ (* n (if (= n 0) 0 (rec (1- n))))))</pre>
<p>Compiling this gives the following RISC-V machine code:</p>
<pre>&gt; (compiler 'rec)
0000      rec
0000 872a ($mv 'a4 'a0)
0002 853a ($mv 'a0 'a4)
0004 1171 ($addi 'sp 'sp -4)
0006 c02a ($sw 'a0 0 '(sp))
0008 853a ($mv 'a0 'a4)
000a 1171 ($addi 'sp 'sp -4)
000c c02a ($sw 'a0 0 '(sp))
000e 4501 ($li 'a0 0)
0010 4582 ($lw 'a1 0 '(sp))
0012 0111 ($addi 'sp 'sp 4)
0014 8533 ($sub 'a0 'a1 'a0)
0016 40a5 
0018 3513 ($seqz 'a0 'a0)
001a 0015 
001c c119 ($beqz 'a0 lab1)
001e 4501 ($li 'a0 0)
0020 a819 ($j lab2)
0022      lab1
0022 853a ($mv 'a0 'a4)
0024 157d ($addi 'a0 'a0 -1)
0026 1161 ($addi 'sp 'sp -8)
0028 c006 ($sw 'ra 0 '(sp))
002a c23a ($sw 'a4 4 '(sp))
002c f0ef ($jal rec)
002e fd5f 
0030 4712 ($lw 'a4 4 '(sp))
0032 4082 ($lw 'ra 0 '(sp))
0034 0121 ($addi 'sp 'sp 8)
0036      lab2
0036 4582 ($lw 'a1 0 '(sp))
0038 0111 ($addi 'sp 'sp 4)
003a 8533 ($mul 'a0 'a1 'a0)
003c 02a5 
003e 0505 ($addi 'a0 'a0 1)
0040 8082 ($ret)</pre>
<p>Trying it out:</p>
<pre>&gt; (rec 12)
1302061345</pre>
<p>This example demonstrates how the RISC-V Lisp assembler takes advantage of 16-bit compressed instructions where possible, instead of the equivalent full 32-bit instructions.</p><hr>
<ol>
<li id="cite_note1"><a href="#cite_ref1">^</a> Norvig, Peter "Paradigms of Artificial Intelligence Programming" Morgan Kaufmann Publishers, Inc, San Francisco, 1992, pp 784-833, available as a PDF <a href="https://github.com/norvig/paip-lisp" target="_blank">paip-lisp</a> on GitHub.</li>
<li id="cite_note2"><a href="#cite_ref2">^</a> <a href="http://www.ulisp.com/show?1EO1#tak">Benchmarks - Takeuchi function</a>.</li>
<li id="cite_note3"><a href="#cite_ref3">^</a> <a href="http://www.ulisp.com/show?1EO1#q2">Benchmarks - Two-dimensional recursive function Q2</a>.</li>
</ol>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nobel Peace Prize for 2024 awarded to Nihon Hidankyo (140 pts)]]></title>
            <link>https://www.nobelprize.org/press-release-peace-2024/</link>
            <guid>41807681</guid>
            <pubDate>Fri, 11 Oct 2024 09:01:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nobelprize.org/press-release-peace-2024/">https://www.nobelprize.org/press-release-peace-2024/</a>, See on <a href="https://news.ycombinator.com/item?id=41807681">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content" role="main">
<section>

<article>
<header>
<h2>
Press release </h2>
</header>

<h5><b>English</b><br><a href="https://www.nobelprize.org/prizes/peace/2024/222035-press-release-norwegian/">Norwegian</a></h5>
<figure><img decoding="async" width="226" height="121" src="https://www.nobelprize.org/uploads/2022/10/nobel-peace-prize-logo.jpg" alt="The Nobel Peace Prize logo"></figure>
<h2>Announcement</h2>
<p><a href="https://www.nobelpeaceprize.org/" target="_blank" rel="noreferrer noopener">The Norwegian Nobel Committee</a> has decided to award the Nobel Peace Prize for 2024 to the Japanese organisation Nihon Hidankyo. This grassroots movement of atomic bomb survivors from Hiroshima and Nagasaki, also known as Hibakusha, is receiving the Peace Prize for its efforts to achieve a world free of nuclear weapons and for demonstrating through witness testimony that nuclear weapons must never be used again.</p>
<p>In response to the atomic bomb attacks of August 1945, a global movement arose whose members have worked tirelessly to raise awareness about the catastrophic humanitarian consequences of using nuclear weapons. Gradually, a powerful international norm developed, stigmatising the use of nuclear weapons as morally unacceptable. This norm has become known as “the nuclear taboo”.</p>
<p>The testimony of the Hibakusha – the survivors of Hiroshima and Nagasaki – is unique in this larger context.</p>
<p>These historical witnesses have helped to generate and consolidate widespread opposition to nuclear weapons around the world by drawing on personal stories, creating educational campaigns based on their own experience, and issuing urgent warnings against the spread and use of nuclear weapons. The Hibakusha help us to describe the indescribable, to think the unthinkable, and to somehow grasp the incomprehensible pain and suffering caused by nuclear weapons.</p>
<p>The Norwegian Nobel Committee wishes nevertheless to acknowledge one encouraging fact: No nuclear weapon has been used in war in nearly 80 years. The extraordinary efforts of Nihon Hidankyo and other representatives of the Hibakusha have contributed greatly to the establishment of the nuclear taboo. It is therefore alarming that today this taboo against the use of nuclear weapons is under pressure.</p>
<p>The nuclear powers are modernising and upgrading their arsenals; new countries appear to be preparing to acquire nuclear weapons; and threats are being made to use nuclear weapons in ongoing warfare. At this moment in human history, it is worth reminding ourselves what nuclear weapons are: the most destructive weapons the world has ever seen.</p>
<p>Next year will mark 80 years since two American atomic bombs killed an estimated 120&nbsp;000 inhabitants of Hiroshima and Nagasaki. A comparable number died of burn and radiation injuries in the months and years that followed. Today’s nuclear weapons have far greater destructive power. They can kill millions and would impact the climate catastrophically. A nuclear war could destroy our civilisation.</p>
<p>The fates of those who survived the infernos of Hiroshima and Nagasaki were long concealed and neglected. In 1956, local Hibakusha associations along with victims of nuclear weapons tests in the Pacific formed the Japan Confederation of A- and H-Bomb Sufferers Organisations. This name was shortened in Japanese to Nihon Hidankyo. It would become the largest and most influential Hibakusha organisation in Japan.</p>
<p>The core of Alfred Nobel’s vision was the belief that committed individuals can make a difference. In awarding this year’s Nobel Peace Prize to Nihon Hidankyo, the Norwegian Nobel Committee wishes to honour all survivors who, despite physical suffering and painful memories, have chosen to use their costly experience to cultivate hope and engagement for peace.</p>
<p>Nihon Hidankyo has provided thousands of witness accounts, issued resolutions and public appeals, and sent annual delegations to the United Nations and a variety of peace conferences to remind the world of the pressing need for nuclear disarmament.</p>
<p>One day, the Hibakusha will no longer be among us as witnesses to history. But with a strong culture of remembrance and continued commitment, new generations in Japan are carrying forward the experience and the message of the witnesses. They are inspiring and educating people around the world. In this way they are helping to maintain the nuclear taboo – a precondition of a peaceful future for humanity.</p>
<p>The decision to award the Nobel Peace Prize for 2024 to Nihon Hidankyo is securely anchored in Alfred Nobel’s will. This year’s prize joins a distinguished list of Peace Prizes that the Committee has previously awarded to champions of nuclear disarmament and arms control.</p>
<p>The Nobel Peace Prize for 2024 fulfils Alfred Nobel’s desire to recognise efforts of the greatest benefit to humankind.</p>
<p>Oslo, 11 October 2024</p>

<div>
<p><a href="#content">
Back to top </a></p><svg width="18px" height="15px" viewBox="0 0 20 17" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" role="image" aria-labelledby="back-to-top-title  back-to-top-desc">
<title id="back-to-top-title">Back To Top</title>
<desc id="back-to-top-desc">Takes users back to the top of the page</desc>
<g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
<g transform="translate(-474.000000, -9998.000000)" fill="#2E2A25">
<g transform="translate(474.000000, 9998.000000)">
<g transform="translate(10.000000, 10.000000) rotate(45.000000) translate(-10.000000, -10.000000) translate(3.000000, 3.000000)">
<rect x="0" y="0" width="2" height="14"></rect>
<rect x="0" y="0" width="14" height="2"></rect>
</g>
<rect x="9" y="3" width="2" height="14"></rect>
</g>
</g>
</g>
</svg>
</div>
</article>

</section>
<section>

<article>
<div>
<header>
<p>
<h2>
<a href="https://www.nobelprize.org/">
Coming up </a>
</h2>
</p>
</header>
<div><p>
Don't miss the Nobel Prize announcements 7-14 October!</p><p>Watch the live stream of the announcements. </p></div>
</div>
<figure>
<a href="https://www.nobelprize.org/"><picture><source data-srcset="https://www.nobelprize.org/uploads/2023/09/2024_Announcement_Recommended_Live-992x656.jpg" media="(min-width: 220px)"><source data-srcset="https://www.nobelprize.org/uploads/2023/09/2024_Announcement_Recommended_Live-1520x1008.jpg" media="(min-width: 900px)"><source data-srcset="https://www.nobelprize.org/uploads/2023/09/2024_Announcement_Recommended_Live.jpg" media="(min-width: 1400px)"><img src="https://www.nobelprize.org/uploads/2023/09/2024_Announcement_Recommended_Live-1024x676.jpg" alt="Illustration" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></picture></a> </figure>
</article>
</section>
<section>

<form id="67090ae8419c5" method="GET" action="">
<p><label for="mobile-dropdown">
Select the category or categories you would like to filter by </label>

</p>
<div>
<p><label>Select the category or categories you would like to filter by</label></p><p><label for="physics">

<span>
Physics </span>
</label>
</p>
<p><label for="chemistry">

<span>
Chemistry </span>
</label>
</p>
<p><label for="medicine">

<span>
Medicine </span>
</label>
</p>
<p><label for="literature">

<span>
Literature </span>
</label>
</p>
<p><label for="peace">

<span>
Peace </span>
</label>
</p>
<p><label for="economic-sciences">

<span>
Economic Sciences </span>
</label>
</p>
</div>
<p><label for="increment-down">
Decrease the year by one </label>

<label for="increment-input">
Choose a year you would like to search in </label>

<label for="increment-up">
Increase the year by one </label>

</p>

</form>
</section>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nurdle Patrol (101 pts)]]></title>
            <link>https://www.nurdlepatrol.org/app/</link>
            <guid>41806629</guid>
            <pubDate>Fri, 11 Oct 2024 06:00:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nurdlepatrol.org/app/">https://www.nurdlepatrol.org/app/</a>, See on <a href="https://news.ycombinator.com/item?id=41806629">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Tesla Robotaxi (241 pts)]]></title>
            <link>https://www.tesla.com/we-robot</link>
            <guid>41805706</guid>
            <pubDate>Fri, 11 Oct 2024 03:24:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tesla.com/we-robot">https://www.tesla.com/we-robot</a>, See on <a href="https://news.ycombinator.com/item?id=41805706">Hacker News</a></p>
Couldn't get https://www.tesla.com/we-robot: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[$2 H100s: How the GPU Rental Bubble Burst (343 pts)]]></title>
            <link>https://www.latent.space/p/gpu-bubble</link>
            <guid>41805446</guid>
            <pubDate>Fri, 11 Oct 2024 02:19:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.latent.space/p/gpu-bubble">https://www.latent.space/p/gpu-bubble</a>, See on <a href="https://news.ycombinator.com/item?id=41805446">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p><em><strong>Swyx’s note:</strong><span> we’re on a roll catching up with former guests! Apart from our recent guest spot on </span><a href="https://www.listennotes.com/podcasts/high-agency-the/why-your-ai-product-needs-ALy02ewNtDC/" rel="">Raza Habib’s chat with Hamel Husain</a><span> (see </span><a href="https://www.latent.space/p/humanloop" rel="">Raza’s first pod here</a><span>). </span></em></p><p><em><span>We’re delighted to welcome Eugene Cheah (see </span><a href="https://www.latent.space/p/rwkv" rel="">his first pod on RWKV last year</a><span>) as a rare guest </span><strong>writer </strong><span>for our newsletter</span><strong>.</strong><span> Eugene has now cofounded </span><a href="https://featherless.ai/" rel="">Featherless.AI</a><span>, an inference platform with the world’s largest collection of open source models (~2,000) instantly accessible via a single API for a </span><strong>flat rate</strong><span> ($10-$75+ a month).</span></em></p><p><em><span>Recently there has been a lot of excitement with NVIDIA’s new Blackwell series rolling out to OpenAI, with the company saying it is </span><a href="https://x.com/firstadopter/status/1844417947277852925" rel="">sold out for the next year</a><span> and Jensen noting that it could be the “</span><a href="https://x.com/The_AI_Investor/status/1844080690046058843" rel="">most successful product in the history of the industry</a><span>”. With cousin Lisa hot on his heels </span><a href="https://www.cnbc.com/2024/10/10/amd-launches-mi325x-ai-chip-to-rival-nvidias-blackwell-.html" rel="">announcing the MI3 25 X</a><span> and </span><a href="https://news.ycombinator.com/item?id=41702789" rel="">Cerebras filing for IPO</a><span>, it is time to dive deep on the GPU market again (see also </span><a href="https://www.latent.space/p/semianalysis" rel="">former guest</a><span> </span><a href="https://www.dwarkeshpatel.com/p/dylan-jon" rel="">Dylan Patel’s pod</a><span> for his trademark candid take on the industry of course): </span></em></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8f05a21e-05b3-4691-a2bb-44547e0acd7e_1074x1268.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8f05a21e-05b3-4691-a2bb-44547e0acd7e_1074x1268.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8f05a21e-05b3-4691-a2bb-44547e0acd7e_1074x1268.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8f05a21e-05b3-4691-a2bb-44547e0acd7e_1074x1268.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8f05a21e-05b3-4691-a2bb-44547e0acd7e_1074x1268.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8f05a21e-05b3-4691-a2bb-44547e0acd7e_1074x1268.png" width="421" height="497.04655493482306" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/8f05a21e-05b3-4691-a2bb-44547e0acd7e_1074x1268.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1268,&quot;width&quot;:1074,&quot;resizeWidth&quot;:421,&quot;bytes&quot;:1493562,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8f05a21e-05b3-4691-a2bb-44547e0acd7e_1074x1268.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8f05a21e-05b3-4691-a2bb-44547e0acd7e_1074x1268.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8f05a21e-05b3-4691-a2bb-44547e0acd7e_1074x1268.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8f05a21e-05b3-4691-a2bb-44547e0acd7e_1074x1268.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p><em><span>Do we yet have an answer to </span><a href="https://www.latent.space/p/mar-jun-2024" rel="">the $600bn question</a><span>? It is now consensus that the capex on foundation model training is the “</span><a href="https://x.com/GavinSBaker/status/1720819375517716610" rel="">fastest depreciating asset in history</a><span>”, but the jury on GPU infra spend is still out and </span><a href="https://www.latent.space/i/140396949/mixtral-sparks-a-gpuinference-race-to-the-bottom" rel="">the GPU Rich Wars are raging</a><span>.</span></em></p><p><em><span>What follows is Eugene’s take on GPU economics as he is now an inference provider, diving deep on the H100 market, as a possible read for what is to come for the Blackwell generation. Not financial advice! We also recommend </span><a href="https://blog.lepton.ai/the-missing-guide-to-the-h100-gpu-market-91ebfed34516" rel="">Yangqing Jia’s guide</a><span>.</span></em></p><p><em><strong>TLDR: Don’t buy H100s. The market has flipped from shortage ($8/hr) to oversupplied ($2/hr), because of reserved compute resales, open model finetuning, and decline in new foundation model co’s. Rent instead.</strong><p><span>(Unless you have some combination of discounted H100s, discounted electricity, or a Sovereign AI angle where the location of your GPU is critical to your customers, or you have billions and need a super large cluster for frontier model training)</span></p><p><span>For the general market, it makes little sense to be investing in new H100s today, when </span><strong>you can rent it at near cost, when you need it</strong><span>, with the current oversupply.</span></p></em></p><p><span>ChatGPT was launched in November 2022, built on the A100 series. The H100s arrived in March 2023. </span><strong>The pitch to investors and founders was simple: </strong><span>Compared to A100s, </span><strong>the new H100s were 3x more powerful, but only 2x the sticker price</strong><span>.</span></p><p>If you were faster to ramp up on H100s, you too, can build a bigger, better model, and maybe even leapfrog OpenAI to Artificial General Intelligence - If you have the capital to match their wallet! </p><p>With this desire, $10-100’s billions of dollars were invested into GPU-rich AI startups to build this next revolution. Which lead to ….</p><p><strong>The sudden surge in H100 demand</strong></p><p><span>Market prices shot through the roof, the original rental rates of H100 started at approximately </span><em><strong>$4.70 an hour</strong></em><span> but were going for </span><em><strong>over $8</strong></em><span>. For all the desperate founders rushing to train their models to convince their investors for their next $100 million round.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F10d1b8c6-8c88-4579-a65d-3ce677c98d88_2798x1576.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F10d1b8c6-8c88-4579-a65d-3ce677c98d88_2798x1576.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F10d1b8c6-8c88-4579-a65d-3ce677c98d88_2798x1576.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F10d1b8c6-8c88-4579-a65d-3ce677c98d88_2798x1576.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F10d1b8c6-8c88-4579-a65d-3ce677c98d88_2798x1576.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_2400,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F10d1b8c6-8c88-4579-a65d-3ce677c98d88_2798x1576.png" width="404" height="227.52747252747253" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/10d1b8c6-8c88-4579-a65d-3ce677c98d88_2798x1576.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:false,&quot;imageSize&quot;:&quot;large&quot;,&quot;height&quot;:820,&quot;width&quot;:1456,&quot;resizeWidth&quot;:404,&quot;bytes&quot;:265694,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F10d1b8c6-8c88-4579-a65d-3ce677c98d88_2798x1576.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F10d1b8c6-8c88-4579-a65d-3ce677c98d88_2798x1576.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F10d1b8c6-8c88-4579-a65d-3ce677c98d88_2798x1576.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F10d1b8c6-8c88-4579-a65d-3ce677c98d88_2798x1576.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Nvidia, literally pitched to their investors &amp; datacenter customers, in their 2023 investor presentation - the “market opportunity” on renting H100s at $4/hr</figcaption></figure></div><p><span>For GPU farms, it felt like free money - if you can get these founders to rent your H100 SXMGPUs at $4.70 an hour or more, or even get them to pay it upfront, </span><strong>the payback period was &lt;1.5 years</strong><span>. From then on, it was free-flowing cash of over $100k per GPU, per year.</span></p><p>With no end to the GPU demand in sight, their investors agreed, with even larger investments…</p><p><span>Physical goods, unlike digital goods, suffer from lag time. Especially when there are </span><a href="https://www.ft.com/content/c7e9cfa9-3f68-47d3-92fc-7cf85bcb73b3" rel="">multiple shipment delays</a><span>.</span></p><p>For most of 2023, the H100 prices felt like they would forever be above $4.70 (unless you were willing to do a huge upfront downpayment)</p><p>At the start of 2024, the H100 prices reached approximately $2.85 across multiple providers.</p><p>As more providers come online, however… I started to get emails like this:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F14ef9576-25d7-4b63-b70b-57c442789fe3_2202x1248.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F14ef9576-25d7-4b63-b70b-57c442789fe3_2202x1248.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F14ef9576-25d7-4b63-b70b-57c442789fe3_2202x1248.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F14ef9576-25d7-4b63-b70b-57c442789fe3_2202x1248.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F14ef9576-25d7-4b63-b70b-57c442789fe3_2202x1248.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F14ef9576-25d7-4b63-b70b-57c442789fe3_2202x1248.png" width="1456" height="825" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/14ef9576-25d7-4b63-b70b-57c442789fe3_2202x1248.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:825,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:413942,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F14ef9576-25d7-4b63-b70b-57c442789fe3_2202x1248.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F14ef9576-25d7-4b63-b70b-57c442789fe3_2202x1248.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F14ef9576-25d7-4b63-b70b-57c442789fe3_2202x1248.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F14ef9576-25d7-4b63-b70b-57c442789fe3_2202x1248.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>While I have not been successful with acquiring H100 nodes (8xH100) at $4/hour, I have confirmed multiple times, that you can do so at $8 - $16/hour</figcaption></figure></div><p>In Aug 2024, if you're willing to auction for a small slice of H100 time (days to weeks), you can start finding H100 GPUs for $1 to $2 an hour.</p><p><strong>We are looking at a &gt;= 40% price drop per year</strong><span>, especially for small clusters. NVIDIA’s marketing projection of $4 per GPU hour across 4 years, has evaporated away in under 1.5 years.</span></p><p><span>And that is horrifying because it means someone out there is potentially </span><a href="https://en.wikipedia.org/wiki/Bagholder" rel="">left holding the bag</a><span> - especially so if they just bought it as a new GPUs. So what is going on?</span></p><blockquote><p><em>This will be focusing on the economical cost, and the ROI on leasing, against various market rates. Not the opportunity cost, or buisness value.</em></p></blockquote><p>The average H100 SXM GPU in a data center costs $50k or more to set up, maintain, and operate (aka most of the CAPEX). Excluding electricity and cooling OPEX cost. More details on the calculation are provided later in this article.</p><p><span>But what does that mean for unit economics today, as an investment?</span><br><span>Especially if we assume a 5-year lifespan on the GPUs itself today.</span></p><p>Generally, there are two business models for leasing H100, which we would cover.</p><ul><li><p>Short on-demand leases (by the hour - by the week - or the month)</p></li><li><p>Longterm reservation (3-5 years)</p></li></ul><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7815afb5-d4f8-4444-804d-5fc96fa094c6_1884x990.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7815afb5-d4f8-4444-804d-5fc96fa094c6_1884x990.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7815afb5-d4f8-4444-804d-5fc96fa094c6_1884x990.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7815afb5-d4f8-4444-804d-5fc96fa094c6_1884x990.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7815afb5-d4f8-4444-804d-5fc96fa094c6_1884x990.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7815afb5-d4f8-4444-804d-5fc96fa094c6_1884x990.png" width="1456" height="765" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7815afb5-d4f8-4444-804d-5fc96fa094c6_1884x990.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:765,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:618581,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7815afb5-d4f8-4444-804d-5fc96fa094c6_1884x990.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7815afb5-d4f8-4444-804d-5fc96fa094c6_1884x990.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7815afb5-d4f8-4444-804d-5fc96fa094c6_1884x990.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7815afb5-d4f8-4444-804d-5fc96fa094c6_1884x990.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><strong>In summary, for an on-demand workload</strong></p><ul><li><p><strong>&gt;$2.85</strong><span> : Beat stock market IRR</span></p></li><li><p><strong>&lt;$2.85</strong><span> : Loses to stock market IRR</span></p></li><li><p><strong>&lt;$1.65</strong><span> : Expect loss in investment</span></p></li></ul><p>For the above ROI and revenue forecast projection, we introduced “blended price”, where we assume a gradual drop to 50% in the rental price across 5 years.</p><p>This is arguably a conservative/optimistic estimate given the &gt;= 40% price drop per year we see now. But it’s a means of projecting an ROI while taking into account a certain % of price drop.</p><p>At $4.50/hour, even when blended, we get to see the original pitch for data center providers from NVIDIA, where they practically print money after 2 years. Giving an IRR (Internal rate of return) of 20+%.</p><p>However, at $2.85/hour, this is where it starts to be barely above 10% IRR.</p><p>Meaning, if you are buying a new H100 server today, and if the market price is less than $2.85/hour, you can barely beat the market, assuming 100% allocation (which is an unreasonable assumption). Anything, below that price, and you're better off with the stock market, instead of a H100 infrastructure company, as an investment.</p><p><strong>And if the price falls below $1.65/hour, you are doomed to make losses on the H100 over the 5 years, as an infra provider</strong><span>. Especially, if you just bought the nodes and cluster this year.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb3453721-463c-4de2-9bda-cd2fa3133ada_1884x984.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb3453721-463c-4de2-9bda-cd2fa3133ada_1884x984.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb3453721-463c-4de2-9bda-cd2fa3133ada_1884x984.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb3453721-463c-4de2-9bda-cd2fa3133ada_1884x984.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb3453721-463c-4de2-9bda-cd2fa3133ada_1884x984.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb3453721-463c-4de2-9bda-cd2fa3133ada_1884x984.png" width="1456" height="760" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b3453721-463c-4de2-9bda-cd2fa3133ada_1884x984.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:760,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:642212,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb3453721-463c-4de2-9bda-cd2fa3133ada_1884x984.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb3453721-463c-4de2-9bda-cd2fa3133ada_1884x984.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb3453721-463c-4de2-9bda-cd2fa3133ada_1884x984.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb3453721-463c-4de2-9bda-cd2fa3133ada_1884x984.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Many infrastructure providers, especially the older ones - were not naive about this - Because they had been burnt firsthand by GPU massive rental price drops, after a major price pump, from the crypto days - they had seen this cycle before.</p><p><strong>So for this cycle, last year, they pushed heavily for a 3-5 year upfront commitment and/or payment at the $4+ price range. </strong><span>(typically with 50% to 100% upfront)</span><strong>. </strong><span>Today, they push the $2.85+ price range - locking in their profits.</span></p><p>This happened aggressively during the 2023 AI peak with various foundation model companies, especially in the image generation space, indirectly forced into high-priced 3-5 year contracts, just so to get to the front-of-the-line of a new cluster, and be first to make their target model, to help close the next round.</p><p>It may not be the most economical move, but it lets them move faster than the competition.</p><p>This, however, has led to some interesting market dynamics - if you are paying $3 or $4 per hour for your H100, for the next 3 years, locked into a contract.</p><p><span>When a model creator is done training a model, you have no more use for the cluster. </span><strong>What would they do? - they resell and start recouping some of the costs.</strong></p><p>From hardware to AI inference / finetune, it can be broadly viewed as the following</p><ul><li><p>Hardware vendors partnered with Nvidia (one-time purchase cost)</p></li><li><p>Datacenter Infrastructure providers &amp; partners (selling long-term reservations, on facility space and/or H100 nodes)</p></li><li><p><span>VC Funds, Large Companies, and Startups: that plann</span><em>ed</em><span> to build foundation models (or have already finished building their models)</span></p></li><li><p><strong>Resellers of capacity: Runpod, SFCompute, Together.ai, Vast.ai, GPUlist.ai</strong></p></li><li><p>Managed AI Inference / Finetune providers: who use a combination of the above</p></li></ul><p><span>While any layer down the stack may be vertically integrated (skipping the infra players for example), the key drivers here are the </span><strong>“Resellers of unused capacity” </strong><span>and the rise of “good enough” open weights models like </span><a href="https://www.latent.space/p/llama-3" rel="">Llama 3</a><span>, as they are all major influencing factors in the current H100 economical pressures.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F333cc1d8-8e8b-47dc-b9f5-1a02e0eefd7b_2140x1280.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F333cc1d8-8e8b-47dc-b9f5-1a02e0eefd7b_2140x1280.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F333cc1d8-8e8b-47dc-b9f5-1a02e0eefd7b_2140x1280.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F333cc1d8-8e8b-47dc-b9f5-1a02e0eefd7b_2140x1280.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F333cc1d8-8e8b-47dc-b9f5-1a02e0eefd7b_2140x1280.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F333cc1d8-8e8b-47dc-b9f5-1a02e0eefd7b_2140x1280.png" width="1456" height="871" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/333cc1d8-8e8b-47dc-b9f5-1a02e0eefd7b_2140x1280.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:871,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:932212,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F333cc1d8-8e8b-47dc-b9f5-1a02e0eefd7b_2140x1280.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F333cc1d8-8e8b-47dc-b9f5-1a02e0eefd7b_2140x1280.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F333cc1d8-8e8b-47dc-b9f5-1a02e0eefd7b_2140x1280.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F333cc1d8-8e8b-47dc-b9f5-1a02e0eefd7b_2140x1280.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><em><strong><span>The rise of open weights models, on-par with closed-source models.</span><br><span>Is resulting in a fundamental shift in the market</span></strong></em></p><blockquote><p><em><strong>↑↑ Increased demand for AI inference &amp; fine-tuning</strong><p><span>Because many “open” models, lack proper “open source” licenses, but are being distributed freely, and used widely, even commercially. We will refer to them collectively as “open-weights” or “open” models instead here.</span></p></em></p></blockquote><p>In general, with multiple open-weights models of various sizes being built, so has the growth in demand for inference and fine-tuning them. This is largely driven by two major events</p><ul><li><p>The arrival of GPT4 class open models (eg. 405B LLaMA3, DeepSeek-v2)</p></li><li><p>The maturity and adoption of small (~8B) and medium (~70B) fine-tuned models</p></li></ul><p>Today, for the vast majority of use cases, enterprises may need, there are already off-the-shelf open-weights models. Which might be a small step behind proprietary models in certain benchmarks.</p><p>Provides an advantage with the following</p><ul><li><p><strong>Flexibility</strong><span>: Domain / Task specific finetunes</span></p></li><li><p><strong>Reliability</strong><span>: No more minor model updates, breaking use case (there is currently low community trust that model weights are not quietly changed without notification in public API endpoints, causing inexplicable regressions)</span></p></li><li><p><strong>Security &amp; Privacy</strong><span>: Assurance that their prompts and customer data are safe.</span></p></li></ul><p>All of this leads to the current continuous growth and adoption of open models, with the growth in demand for inference and finetunes.</p><p>But it does cause another problem…</p><blockquote><p><em><strong>↓↓ Shrinking foundation model creator market (Small &amp; Medium)</strong><p><span>We used “model creators” to collectively refer to organization that create models from scratch. For fine-tuners, we refer to them as “model finetuners”</span></p></em></p></blockquote><p>Many enterprises, and multiple small &amp; medium foundation model creator startups - especially those who raised on the pitch of “smaller, specialized domain-specific models”, are groups who had no long-term plans / goals for training large foundation models from scratch ( &gt;= 70B ).</p><p>For both groups, they both came to the realization that it is more economical and effective to fine-tune existing Open Weights models, instead of “training on their own”.</p><p><strong>This ended up creating a triple whammy in reducing the demand for H100s!</strong></p><ol><li><p><strong>Finetuning is significantly cheaper than training from scratch.</strong></p><ol><li><p>Because the demands for fine-tuning are significantly less in compute requirements (typically 4 nodes or less, usually a single node), compared to training from scratch (from 16 nodes, usually more, for 7B and up models).</p></li><li><p>This industry-wide switch essentially killed a large part of smaller cluster demands.</p></li></ol></li><li><p><strong>Scaling back on foundation model investment (at small/mid-tier)</strong></p><ol><li><p>In 2023, there was a huge wave of small and medium foundation models, within the text and image space.</p></li><li><p>Today, however, unless you are absolutely confident you can surpass llama3, or you are bringing something new to the table (eg. new architecture, 100x lower inference, 100+ languages, etc), there are ~no more foundation model cos being founded from scratch.</p></li><li><p>In general, the small &amp; medium, open models created by the bigger players (Facebook, etc), make it hard for smaller players to justify training foundation models - unless they have a strong differentiator to do so (tech or data) - or have plans to scale to larger models.</p></li><li><p>And this has been reflected lately with investors as well, as there has been a sharp decline in new foundation model creators’ funding. With the vast majority of smaller groups having switched over to finetuning. (this sentiment is combined with the recent less than desired exits for multiple companies).</p></li><li><p>Presently today, there is approximately worldwide by my estimate:</p><ul><li><p>&lt;20 Large model creator teams (aka 70B++, may create small models as well)</p></li><li><p>&lt;30 Small / Medium model creator teams (7B - 70B)</p></li></ul></li><li><p>Collectively there are less than &lt;50 teams worldwide who would be in the market for 16 nodes of H100s (or much more), at any point in time, to do foundation model training.</p></li><li><p>There are more than 50 clusters of H100 worldwide with more than 16 nodes.</p></li></ol></li><li><p><strong>Excess capacity from reserved nodes is coming online</strong></p><ol><li><p>For the cluster owners, especially the various foundation model startups and VCs, who made long reservations, in the initial “land grab” of the year 2023.</p></li><li><p><span>With the switch to finetuning, and the very long wait times of the H100’s</span><br><span>(it peaked at &gt;= 6 months), it is very well possible that many of these groups had already made the upfront payment before they made the change, essentially making their prepaid hardware “obsolete on arrival”.</span></p></li><li><p>Alternatively, those who had the hardware arrive on time, to train their first few models, had come to the same realization it would be better to fine-tune their next iteration of models. Instead of building on their own.</p></li><li><p><span>In both cases, they would have unused capacity, which comes online via </span><strong>“Compute Resellers”</strong><span> joining the market supply….</span></p></li></ol></li></ol><p>Another major factor, is how all the major Model Creators, such as Facebook, X.AI, and arguably OpenAI (if you count them as part of Microsoft) are moving away from an existing public provider, and building their own billion-dollar clusters, removing the demand that the existing clusters depend on.</p><p>The move is happening mostly for the following reasons:</p><ul><li><p>Existing ~1k node clusters (which costs &gt;$50M to build), is no longer big enough for them, to train bigger models</p></li><li><p>At a billion-dollar scale, it is better for accounting to purchase assets (of servers, land, etc), which has booked value (part of company valuation and assets), instead of pure expenses leasing.</p></li><li><p>If you do not have the people (they do), you could straight up buy small datacenters companies, who have the expertise to build this for you.</p></li></ul><p>With the demand gradually weaning away in stages. These clusters are coming online to the public cloud market instead.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F23dbc794-e567-4b34-a6e7-761fafef2ccc_2710x1812.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F23dbc794-e567-4b34-a6e7-761fafef2ccc_2710x1812.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F23dbc794-e567-4b34-a6e7-761fafef2ccc_2710x1812.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F23dbc794-e567-4b34-a6e7-761fafef2ccc_2710x1812.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F23dbc794-e567-4b34-a6e7-761fafef2ccc_2710x1812.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F23dbc794-e567-4b34-a6e7-761fafef2ccc_2710x1812.png" width="1456" height="974" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/23dbc794-e567-4b34-a6e7-761fafef2ccc_2710x1812.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:974,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1268863,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F23dbc794-e567-4b34-a6e7-761fafef2ccc_2710x1812.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F23dbc794-e567-4b34-a6e7-761fafef2ccc_2710x1812.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F23dbc794-e567-4b34-a6e7-761fafef2ccc_2710x1812.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F23dbc794-e567-4b34-a6e7-761fafef2ccc_2710x1812.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Vast.ai essentially does a free market system, where providers from all over the world, are forced to compete with each other</figcaption></figure></div><p>Recall all the H100 large shipment delays in 2023, or 6 months or more? They are coming online, now - along with the H200, B200, etc.</p><p>This is alongside, the various unused compute, coming online (from existing startups, enterprises or VCs as covered earlier).</p><p><span>The bulk of this is done via </span><strong>Compute Resellers</strong><span>, such as : together.ai, sfcompute, runpod, vast.ai, etc</span></p><p>In most cases, cluster owners have a small or medium cluster, (typically 8-64 nodes), that is underutilized. With the money already “spent” for the cluster.</p><p>With the primary goal is to recoup as much of the cost as possible, they rather undercut the market and guarantee an allocation, instead of competing with the main providers, and possibly have no allocation.</p><p>This is typically done either via a fixed rate, an auction system, or just a free market listing, etc. With the later 2 driving the market price downwards.</p><p>Another major factor, is once your outside of the training / fine-tune space. The inference space is filled with alternatives, especially if your running smaller models.</p><p>One do not need to pay for the premium invoked by H100’s Infiniband and/or nvidia.</p><p>H100 premium for training is priced into the hardware. For example nvidia themselves recommend the L40S, which is the more price competitive alternative for inference.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdf705375-9942-4ea5-86b9-b41d3661096b_1842x556.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdf705375-9942-4ea5-86b9-b41d3661096b_1842x556.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdf705375-9942-4ea5-86b9-b41d3661096b_1842x556.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdf705375-9942-4ea5-86b9-b41d3661096b_1842x556.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdf705375-9942-4ea5-86b9-b41d3661096b_1842x556.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdf705375-9942-4ea5-86b9-b41d3661096b_1842x556.png" width="1456" height="439" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/df705375-9942-4ea5-86b9-b41d3661096b_1842x556.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:439,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:414838,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdf705375-9942-4ea5-86b9-b41d3661096b_1842x556.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdf705375-9942-4ea5-86b9-b41d3661096b_1842x556.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdf705375-9942-4ea5-86b9-b41d3661096b_1842x556.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdf705375-9942-4ea5-86b9-b41d3661096b_1842x556.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Which Is 1/3rd the performance, at 1/5th the price. But does not work well with multi-node training. Undercutting their very own H100 for this segment.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F55aee33d-e501-4923-9fd2-39740f781ed5_2610x826.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F55aee33d-e501-4923-9fd2-39740f781ed5_2610x826.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F55aee33d-e501-4923-9fd2-39740f781ed5_2610x826.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F55aee33d-e501-4923-9fd2-39740f781ed5_2610x826.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F55aee33d-e501-4923-9fd2-39740f781ed5_2610x826.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F55aee33d-e501-4923-9fd2-39740f781ed5_2610x826.png" width="1456" height="461" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/55aee33d-e501-4923-9fd2-39740f781ed5_2610x826.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:461,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:2982780,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F55aee33d-e501-4923-9fd2-39740f781ed5_2610x826.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F55aee33d-e501-4923-9fd2-39740f781ed5_2610x826.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F55aee33d-e501-4923-9fd2-39740f781ed5_2610x826.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F55aee33d-e501-4923-9fd2-39740f781ed5_2610x826.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Both AMD and Intel may be late into the game with their MX300, and Gaudi 3 respectively.</p><p>This has been tested and verified by us, having used these systems. They are generally:</p><ul><li><p>Cheaper than a H100 in purchase cost</p></li><li><p>Have more memory and compute than a H100, and outperforms on a single node.</p></li><li><p>Overall, they are great hardware!</p></li></ul><p>The catch? They have minor driver issues in training and are entirely unproven in large multi-node cluster training.</p><p>Which as we covered is largely irrelevant to the current landscape. To anyone but &lt;50 teams. The market for H100 has been moving towards inference and single or small cluster fine-tuning.</p><p>All of which these GPUs have been proven to work at. For the use cases, the vast majority of the market is asking for.</p><p>These 2 competitors are full drop-in replacements. With working off-the-shelf inference code (eg. VLLM) or finetuning code for most common model architectures (primarily LLaMA3, followed by others).</p><p>So, if you have compatibility sorted out. Its highly recommended to have a look.</p><p>With Ethereum moving towards proof of stake, ASIC dominating the bitcoin mining race, and the general crypto market condition.</p><p>GPU usage in mining for crypto has been a downward trend, and in several cases unprofitable. And has since been flooding the GPU public cloud market.</p><p>And while the vast majority of these GPUs are unusable for training, or even for inference, due to hardware constraints (low PCIe bandwidth, network, etc). The hardware has been flooding the market and has been repurposed for AI inference workloads.</p><p>In most cases if you are under &lt;10B, you can get decent performance with these GPUs, out of the box, for really low prices.</p><p>If you optimize it further (though various tricks), you can even get large 405B models to run on a small cluster of this hardware, cheaper then an H100 node (which is what is typically used)</p><p><em><span>H100 Prices are becoming commodity-prices cheap.</span><br><span>Or even being rented at a loss - if so, what now?</span></em></p><p>On a high level, it is expected that big clusters still get to charge a premium (&gt;=$2.90 / hour) because there is no other option. For those who truly need it.</p><p>We are starting to see this trend for example with Voltage Park:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc1dd60f1-1e51-4ec7-ac64-d5a2b506f2f0_2118x1078.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc1dd60f1-1e51-4ec7-ac64-d5a2b506f2f0_2118x1078.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc1dd60f1-1e51-4ec7-ac64-d5a2b506f2f0_2118x1078.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc1dd60f1-1e51-4ec7-ac64-d5a2b506f2f0_2118x1078.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc1dd60f1-1e51-4ec7-ac64-d5a2b506f2f0_2118x1078.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc1dd60f1-1e51-4ec7-ac64-d5a2b506f2f0_2118x1078.png" width="1456" height="741" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/c1dd60f1-1e51-4ec7-ac64-d5a2b506f2f0_2118x1078.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:741,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:647709,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc1dd60f1-1e51-4ec7-ac64-d5a2b506f2f0_2118x1078.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc1dd60f1-1e51-4ec7-ac64-d5a2b506f2f0_2118x1078.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc1dd60f1-1e51-4ec7-ac64-d5a2b506f2f0_2118x1078.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc1dd60f1-1e51-4ec7-ac64-d5a2b506f2f0_2118x1078.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Where clusters with Infiniband are charged at a premium.</p><p>While the Ethernet-based instances, which are perfectly fine for inference are priced at a lower rate. Adjusting the prices for the respective use case/availability.</p><p>While there’s been a general decline in foundation model creator teams, it is hard to predict if there will be a resurgence, with the growth in open weights, and/or alternative architectures.</p><p>It is also, expected that in the future, we will see further segmentation by cluster sizes. Where a large 512-node cluster with Infiniband may be billed higher per GPU than a 16-node cluster.</p><p>There is a lot against you, if you price it below $2.25, depending on your OPEX, you risk potentially being unprofitable.</p><p>If you price it too high &gt;= $3, you might not be able to get sufficient buyers to fill capacity.</p><p>If you're late, you could not recoup the cost in the early $4/hour days.</p><p>Overall, these cluster investments will be rough for the key stakeholders and investors.</p><p>While I doubt it’s the case, if new clusters, make a large segment of the AI portfolio investments. We may see additional rippling effects in the funding ecosystem from burnt investors.</p><p>Instead of a negative outlook, a neutral outlook would be some of the unused compute foundation model creators, coming online, are already paid for.</p><p>The funding market has already priced in and paid for this cluster and its model training. And “extracted its value” which they used for their current and next funding round.</p><p><span>Most of these purchases were made before the popularity of </span><strong>Compute Resellers</strong><span>, the cost was already priced in.</span></p><p>If anything, the current revenue they get from their excess H100 compute, and the lowered prices we get, are beneficial to both parties</p><p>If so the negative market impact is minimal, while overall it’s a net positive win for the ecosystem.</p><p>Given that the open-weights model has entered the GPT-4 class arena. Falling H100 prices will be the multiplier unlock for open-weights AI adoption.</p><p>It will be more affordable, for hobbyists, AI developers, and engineers, to run, fine-tune, and tinker with these open models.</p><p><span>Especially if there is no major leap for GPT5++,</span><strong> </strong><span>because it will mean that the gap between open-weights and closed-source models will blur.</span></p><p>This is strongly needed, as the market is currently not sustainable. As there lacks the value capture on the application layer for paying users (which trickles down the platform, models, and infra layers)</p><p>In a way, if everyone is building shovels (including us), and applications with paying users are not being built (and collecting revenue and value).</p><p>But when AI inference and fine-tuning becomes cheaper than ever.</p><p>It can potentially kick off the AI application wave. If it has not already slowly started so.</p><p><em><strong>Spending on new H100’s hardware is likely a loss-maker</strong><p><span>Unless you have some combination of discounted H100s, discounted electricity, or a Sovereign AI angle where the location of your GPU is critical to your customers. Or you have billions and need a super large cluster.</span></p><p><span>If you're investing, consider investing elsewhere.</span><br><span>Or the stock market index itself for a better rate of returns. IMO</span></p></em></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3e858927-de4c-499b-9ba0-261dd470a88b_1948x1088.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3e858927-de4c-499b-9ba0-261dd470a88b_1948x1088.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3e858927-de4c-499b-9ba0-261dd470a88b_1948x1088.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3e858927-de4c-499b-9ba0-261dd470a88b_1948x1088.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3e858927-de4c-499b-9ba0-261dd470a88b_1948x1088.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3e858927-de4c-499b-9ba0-261dd470a88b_1948x1088.png" width="1456" height="813" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/3e858927-de4c-499b-9ba0-261dd470a88b_1948x1088.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:813,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:664297,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:&quot;&quot;,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3e858927-de4c-499b-9ba0-261dd470a88b_1948x1088.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3e858927-de4c-499b-9ba0-261dd470a88b_1948x1088.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3e858927-de4c-499b-9ba0-261dd470a88b_1948x1088.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3e858927-de4c-499b-9ba0-261dd470a88b_1948x1088.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>At Featherless.AI - We currently host the world’s largest collection of OpenSource AI models, instantly accessible, serverlessly, with unlimited requests from $10 a month, at a fixed price.</p><p><span>We have indexed and made over 2,000 models ready for inference today. This is 10x the catalog of openrouter.ai, the largest model provider </span><em>aggregator</em><span>, </span><em>and </em><span>is the world’s largest collection of Open Weights models available serverlessly for instant inference. Without the need for any expensive dedicated GPUs</span></p><p>And our platform makes this possible, as it’s able to dynamically hot-swap between models in seconds.</p><p>It’s designed to be easy to use, with full OpenAI API compatibility, so you can just plug our platform in as a replacement to your existing AI API for your AI agents. Running in the background</p><p>And we do all of this; As we believe that AI should be easily accessible to everyone, regardless of language or social status.</p><p>On the technical side of things, related to this article.</p><p>It is a challenge having PetaBytes’s worth of AI models, and growing, running 24/7 - while being hardware profitable (we are), because we needed to optimize every layer of our platform, down to how we choose the GPU hardware.</p><p>In an industry, where the typical inference provider pitch is typically along the lines of winning with their, special data center advantages, and CUDA optimization that they perform on their own hardware. Hardware is CAPEX intensive. (Which is being pitched and funded even today)</p><p>We were saying the opposite, which defied most investors’ sensibilities - we were saying we would be avoiding buying new hardware like the plague.</p><p>We came to a realization, that most investors, their analysts, and founders failed to realize, thanks to the billions in hardware investments to date. GPUs are commodity hardware. Faster than all of us expected.</p><p>Few investors have even realized we have reached commodity-level prices at $2.85 in certain places, let alone loss-making prices of a dollar. Because most providers (ignoring certain exceptions), only show their full prices after quotation or after login.</p><p>And that was the trigger, which got me to write this article.</p><p>While we do optimize our inference CUDA and kernels as well. On the hardware side; We’ve bet on hardware commoditizing and have focussed instead on the orchestration layer above.</p><p>So for us, this is a mix of sources from, AWS spot (preferred), to various data center grade providers (eg. Tensordock, Runpod) with security and networking compliances that meet our standards.</p><p>Leveraging them with our own proprietary model hot swapping, which boots new models up in under a second. Keeping our fleet of GPUs right-sized to our workload, while using a custom version of our RWKV foundation model as a low-cost speculative decoder. All of which allows us to take full advantage of this market trend, and future GPU price drops, as newer (and older) GPUs come online to replace the H100s. And scale aggressively.</p><p><em>PS: If you are looking at building the world's largest inference platform, and are aligned with our goals - to make AI accessible to everyone, regardless of language or status. Reach out to us at: hello@featherless.ai</em></p><p><em><span>Head over to Eugene’s Blog </span></em></p><p><em><span> for </span><a href="https://substack.tech-talk-cto.com/p/d4ffab7a-3f0d-4e6e-ade0-e74409770196?postPreview=paid&amp;updated=2024-08-25T03%3A36%3A59.886Z&amp;audience=everyone&amp;free_preview=false&amp;freemail=true" rel="">more footnotes on xAI’s H100 cluster</a><span> we cut from this piece.</span></em><span> </span></p><p><strong>Additional Sources:</strong></p><ul><li><p><span>GPU data: </span><a href="https://www.techpowerup.com/gpu-specs/h100-sxm5-80-gb.c3900" rel="">Tech Power Up Database</a><span>. The A100 SXM had 624 bf16 TFlops, the H100 SXM was 1,979 bf16 TFlops</span></p></li><li><p><span>Microsoft &amp; AWS allocated over $40 billion in AI infra alone: </span><a href="https://www.wsj.com/tech/ai/big-tech-moves-more-ai-spending-abroad-088988de" rel="">Wall Street Journal</a></p></li><li><p><span>“600 Billion Dollars “ is about: </span><a href="https://www.sequoiacap.com/article/ais-600b-question/" rel="">Sequoia’s AI article</a></p></li><li><p><span>Nvidia investor slides for Oct 2014: </span><a href="https://s201.q4cdn.com/141608511/files/doc_presentations/2023/Oct/01/ndr_presentation_oct_2023_final.pdf" rel="">page 14 has the pitch for “data centers”</a></p></li><li><p><span>Semi Analysis: </span><a href="https://www.semianalysis.com/p/100000-h100-clusters-power-network" rel="">deepdive for H100 clusters, w/ 5 year lifespan approx for components</a></p></li><li><p><span>Spreadsheet for : </span><a href="https://docs.google.com/spreadsheets/d/1kZosZmvaecG6P4-yCPzMN7Ha3ubMcTmF9AeJNDKeo98/edit?usp=sharing" rel="">new H100 ROI (Aug 2024)</a></p></li><li><p><span>Spreadsheet for: </span><a href="https://docs.google.com/spreadsheets/d/1Ft3RbeZ-w43kYSiLfYc1vxO41mK5lmJpcPC9GOYHAWc/edit?usp=sharing" rel="">H100 Infiniband Cluster math (Aug 2024)</a></p></li></ul></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[WordPress Alternatives (141 pts)]]></title>
            <link>https://darn.es/wordpress-alternatives/</link>
            <guid>41805391</guid>
            <pubDate>Fri, 11 Oct 2024 02:03:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://darn.es/wordpress-alternatives/">https://darn.es/wordpress-alternatives/</a>, See on <a href="https://news.ycombinator.com/item?id=41805391">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
      <heading-anchors>
        <div><p>📝</p><p>Editor note: Due to this article's unexpected attention, I've included a few more alternatives that people suggested. I've also added some contextual notes you should know before diving into these options.</p></div><p>Due to <em>gestures vaguely, </em>everything going on <a href="https://css-tricks.com/catching-up-on-the-wordpress-wp-engine-sitch/" rel="noreferrer">right now with WordPress</a>, I thought I'd put together a list of alternative CMSs that better fit the criteria someone might have for their website. The modern CMS landscape is super broad, with the very definition of "Content Management System" being stretched. Some see it as a full-package website platform, and some see it as just UI for their content stored elsewhere.</p><p>The criteria for this list are "Can it be downloaded, dropped onto a server, and you'll have a website?" This eliminates API and git-based CMSs, which I enjoy using; however, wiring a daisy chain of tools is just not viable for many.</p><figure><a href="https://ghost.org/"><div><p>Ghost: The best open source blog &amp; newsletter platform</p><p>Beautiful, modern publishing with email newsletters and paid subscriptions built-in. Used by Platformer, 404Media, Lever News, Tangle, The Browser, and thousands more.</p><p><img src="https://darn.es/img/Z24D4b6-favicon-1.ico" alt=""></p></div><p><img src="https://darn.es/img/Z1hjw9Q-ghost.png" alt="" onerror="this.style.display = 'none'"></p></a></figure><p>People will already know I have a soft spot for Ghost. But what you might not know is what I'd recommend for hosting.</p><figure><a href="https://www.magicpages.co/"><div><p>Magic Pages</p><p>Get your Ghost CMS publication up and running in no time with Magic Pages’ Ghost CMS web hosting – starting at $4/month!</p><p><img src="https://darn.es/img/iczFH-favicon-196x196-1.jpg" alt=""><span>Magic Pages</span></p></div><p><img src="https://darn.es/img/Z1EYPIA-MagicPages.co-3.png" alt="" onerror="this.style.display = 'none'"></p></a></figure><p>Magic Pages is what I'm using for <a href="https://designsystems.wtf/" rel="noreferrer">Design Systems WTF</a>, and it's been great! The uptime is good, the price is very reasonable, and <a href="https://www.jannis.io/" rel="noreferrer">Jannis</a> provides a personal touch with support. In addition, this sidesteps Ghost's own hosting option (Ghost Pro), which I would be wary of due to <a href="https://x.com/amyhoy/status/1449482190224384000">past experiences with other customers</a>.</p><figure><a href="https://getkirby.com/"><div><p>Kirby is the CMS that adapts to you</p><p>Kirby is the content management system that adapts to any project. Made for developers, designers, creators and clients.</p><p><img src="https://darn.es/img/1CTUoB-favicon.1704303350.svg" alt=""><span>Kirby CMS</span></p></div><p><img src="https://darn.es/img/1RRwiG-opengraph.png" alt="" onerror="this.style.display = 'none'"></p></a></figure><p>I have not used Kirby in client work, but I hear only good things. It's file-based, which seems super appealing to someone like myself who gets cold sweats when opening a database.</p><figure><a href="https://getindiekit.com/"><div><p>Indiekit</p><p>The little server that connects your website to the independent web.</p><p><img src="https://darn.es/img/1Py0ge-icon.svg" alt=""><span>Get Started</span></p></div><p><img src="https://darn.es/img/Z1QWsfN-opengraph-image.png" alt="" onerror="this.style.display = 'none'"></p></a></figure><p>Indiekit seems like an interesting option; it's also file-based but needs a database to manage existing content.</p><figure><a href="https://craftcms.com/"><div><p>Craft CMS</p><p>Craft is a flexible, user-friendly CMS for creating custom digital experiences on the web and beyond.</p><p><img src="https://darn.es/img/1o1WvD-apple-touch-icon.png" alt=""><span>Craft CMS</span></p></div><p><img src="https://darn.es/img/ZXh3Gs-social-craft-cms.png" alt="" onerror="this.style.display = 'none'"></p></a></figure><p>It's a bit more of a commercial option with Craft CMS, but it does offer a free option for solo creators. Warning, though, as you'll need to spend time architecting your content structure by the looks of it.</p><figure><a href="https://www.classicpress.net/"><div><p>ClassicPress | Stable. Lightweight. Instantly Familiar.</p><p>ClassicPress is a community-led open source content management system. A fork of WordPress 4.9, it retains the WordPress classic editor as the default option.</p><p><img src="https://darn.es/img/1MLpdH-cropped-icon-gradient-500x500.png" alt=""><span>ClassicPress</span></p></div><p><img src="https://darn.es/img/1lFgeF-classicpress-cms-for-creators.jpg" alt="" onerror="this.style.display = 'none'"></p></a></figure><p>ClassicPress appears to be a direct fork of WordPress but at version 6.2.3. It seems perfect for anyone looking for "the good old days." However, it uses the official WordPress plugin API, so it's not a 100% clean break if that's what you're going for.  Thanks to <a href="https://voxpelli.com/" rel="noreferrer">Pelle Wessman</a> for this suggestion.</p><figure><a href="https://statamic.com/"><div><p>Statamic is a powerful, highly scalable CMS built on Laravel.</p><p>The open source, flat-first, Laravel + Git powered CMS designed for building easy to manage websites.</p><p><img src="https://darn.es/img/Z2ddyQl-favicon-196x196.png" alt=""><span>Statamic</span></p></div><p><img src="https://darn.es/img/Z1MKo0C-card-2023.jpg" alt="" onerror="this.style.display = 'none'"></p></a></figure><p>I've had several people suggest Statamic. It does look pretty good, plus they have a free solo plan (similar to Craft CMS). I think if the cofounder hadn't brazenly <a href="https://jaygeorge.co.uk/blog/intolerance">endorsed a horrendously damaging politician</a>, I'd have tried it.</p><p>I was going to suggest <a href="https://grabaperch.com/" rel="noreferrer">Perch</a> and <a href="http://buckets.io/" rel="noreferrer">Buckets</a> on this list, but public activity seems low for both. The Perch website even has SSL certificate issues, which isn't a good sign. Check them out if you're interested, but you have been warned.</p><h3 id="honourable-mention">Honourable mention</h3><figure><a href="http://anchorcms.com/"><div><p>Lifting Anchor</p><p>Help on how to use Anchor</p><p><img src="https://darn.es/img/p9SGH-1433533.png" alt=""><span>Anchor CMS</span></p></div><p><img src="https://darn.es/img/Z2kqVUC-screenshot.png" alt="" onerror="this.style.display = 'none'"></p></a></figure><p>Many years ago, I contributed to Anchor, a humble PHP-based CMS that grew a little community around itself. Sadly, the creator, Charlotte, passed away in 2020, and the remaining core team couldn't keep the project going while juggling other responsibilities. I think of it fondly and wish we could give it the time it deserves. </p><p>The theming and custom types aspects were wonderfully simple; heck, I even made a whole site dedicated to themes and sites built with it:</p><figure><a href="https://anchorthemes.com/"><div><p>Welcome - Anchor Themes</p><p>Themes and sites built for &lt;a href=“https://anchorcms.com”&gt;Anchor&lt;/a&gt;, obviously</p><p><img src="https://darn.es/img/xtffw-link-icon.svg" alt=""><span>Anchor Themes</span><span>David Darnes</span></p></div><p><img src="https://darn.es/img/Z1nRKSm-facebook.png" alt="" onerror="this.style.display = 'none'"></p></a></figure><p>I'll try to keep this list up to date if I recall any others I've used in the past. Hopefully, you find this useful if you're seeking alternative CMSs.</p>
      </heading-anchors>
    </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The FBI created a coin to investigate crypto pump-and-dump schemes (109 pts)]]></title>
            <link>https://www.theverge.com/2024/10/10/24267098/fbi-coin-crypto-token-nexgenai-sec-doj-fraud-investigation</link>
            <guid>41802823</guid>
            <pubDate>Thu, 10 Oct 2024 19:52:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/2024/10/10/24267098/fbi-coin-crypto-token-nexgenai-sec-doj-fraud-investigation">https://www.theverge.com/2024/10/10/24267098/fbi-coin-crypto-token-nexgenai-sec-doj-fraud-investigation</a>, See on <a href="https://news.ycombinator.com/item?id=41802823">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>The FBI created a cryptocurrency as part of an investigation into price manipulation in crypto markets, the <a href="https://www.justice.gov/usao-ma/pr/eighteen-individuals-and-entities-charged-international-operation-targeting-widespread">government revealed</a> on Wednesday. The FBI’s Ethereum-based token, NexFundAI, was created with the help of “cooperating witnesses.”</p><p>As a result of the investigation, the Securities and Exchange Commission <a href="https://www.sec.gov/newsroom/press-releases/2024-166">charged</a> three “market makers” and nine people for allegedly engaging in schemes to boost the prices of certain crypto assets. The Department of Justice charged 18 people and entities for “widespread fraud and manipulation” in crypto markets.</p><p>The defendants allegedly made false claims about their tokens and executed so-called “wash trades” to create the impression of an active trading market, prosecutors claim. The three market makers — ZMQuant, CLS Global, and MyTrade — allegedly wash traded or conspired to wash trade on behalf of NexFundAI, an Ethereum-based token they didn’t realize was created by the FBI.&nbsp;</p><p>“What the FBI uncovered in this case is essentially a new twist to old-school financial crime,” Jodi Cohen, the special agent in charge of the FBI’s Boston division, said in a statement. “What we uncovered has resulted in charges against the leadership of four cryptocurrency companies, and four crypto ‘market makers’ and their employees who are accused of spearheading a sophisticated trading scheme that allegedly bilked honest investors out of millions of dollars.”</p><p>Liu Zhou, a “market maker” working with MyTrade MM, allegedly told promoters of NexFundAI that MyTrade MM was better than its competitors because they “control the pump and dump” allowing them to “do inside trading easily.”</p><p>An FBI spokesperson <a href="https://www.coindesk.com/policy/2024/10/09/prosecutors-charge-two-crypto-market-makers-employees-with-market-manipulation-fraud/">told <em>CoinDesk</em></a> that there was limited trading activity on the coin but didn’t share additional information. On a Wednesday press call, Joshua Levy, the acting US attorney for the District of Massachusetts, said trading on the token was disabled, according to <em>CoinDesk</em>.</p><p>The DOJ has reportedly secured $25 million from “fraudulent proceeds” that will be returned to investors.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Copenhagen Book: general guideline on implementing auth in web applications (650 pts)]]></title>
            <link>https://thecopenhagenbook.com/</link>
            <guid>41801883</guid>
            <pubDate>Thu, 10 Oct 2024 18:37:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thecopenhagenbook.com/">https://thecopenhagenbook.com/</a>, See on <a href="https://news.ycombinator.com/item?id=41801883">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
      
      <main>
<p>The Copenhagen Book provides a general guideline on implementing auth in web applications. It is free, open-source, and community-maintained. It may be opinionated or incomplete at times but we hope this fills a certain void in online resources. We recommend using this alongside the <a href="https://cheatsheetseries.owasp.org/index.html">OWASP Cheat Sheet Series</a>.</p>
<p>If you have any suggestions or concerns, consider opening a new issue.</p>
<p><em>Created by <a href="https://github.com/pilcrowOnPaper">Pilcrow</a></em></p>
</main>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[TypedDicts are better than you think (126 pts)]]></title>
            <link>https://blog.changs.co.uk/typeddicts-are-better-than-you-think.html</link>
            <guid>41801415</guid>
            <pubDate>Thu, 10 Oct 2024 17:56:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.changs.co.uk/typeddicts-are-better-than-you-think.html">https://blog.changs.co.uk/typeddicts-are-better-than-you-think.html</a>, See on <a href="https://news.ycombinator.com/item?id=41801415">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="content">
    <article>
      <header>
        
      </header>

      <div>
<!-- /.post-info -->        <p><code>TypedDict</code> was introduced in <a href="https://peps.python.org/pep-0589/">PEP-589</a> which landed in Python 3.8.</p>
<p>The primary use case was to create type annotations for dictionaries. For example,</p>
<div><pre><span></span><code><span>class</span> <span>Movie</span><span>(</span><span>TypedDict</span><span>):</span>
    <span>title</span><span>:</span> <span>str</span>


<span>movie</span><span>:</span> <span>Movie</span> <span>=</span> <span>{</span><span>"title"</span><span>:</span> <span>"Avatar"</span><span>}</span>
</code></pre></div>

<p>I remember thinking at the time that this was pretty neat, but I tend to use <code>dataclass</code> or <code>pydantic</code> to represent 'record' type data. Instead I use dictionaries more as a collection, so the standard <code>dict[KT, VT]</code> annotation is enough.</p>
<h3>Non-totality</h3>
<p>I revisited typeddicts when I looked at implementing a HTTP patch endpoint.</p>
<p>Let's suppose I have a data structure represented by the following dataclass:</p>
<div><pre><span></span><code><span>@dataclass</span>
<span>class</span> <span>User</span><span>:</span>
    <span>id</span><span>:</span> <span>UUID</span>
    <span>name</span><span>:</span> <span>str</span>
    <span>subscription</span><span>:</span> <span>str</span> <span>|</span> <span>None</span> <span>=</span> <span>None</span>
</code></pre></div>

<p>Where <code>subscription = None</code> means no subscription.</p>
<p>Let's say we want to option to patch name, subscription. You might define the patch body using dataclass:</p>
<div><pre><span></span><code><span>@dataclass</span>
<span>class</span> <span>PatchUser</span><span>:</span>
    <span>name</span><span>:</span> <span>str</span> <span>|</span> <span>None</span> <span>=</span> <span>None</span>
    <span>subscription</span><span>:</span> <span>str</span> <span>|</span> <span>None</span> <span>=</span> <span>None</span>
</code></pre></div>

<p>Here we have a problem, for subscription does <code>None</code> mean don't change or remove subscription. </p>
<p>We can fix this a number of ways, for example, we can take the string <code>'none'</code> to mean no subscription instead, or make a new sentinel value called <code>NoChange</code> to indicate no changes.</p>
<p>These solutions all feel a little awkward, this is because dataclasses don't have a concept of a field being missing. But this is where dictionaries shine. Dictionaries are not general expected to have all the fields available. We get a <code>KeyError</code> if a field is missing and there are convenience methods such as <code>.get(key, [default])</code> to fetch a key that is not guaranteed to be present.</p>
<p>This makes <code>TypedDict</code> the ideal data structure in this scenario:</p>
<div><pre><span></span><code><span>class</span> <span>PatchUser</span><span>(</span><span>TypedDict</span><span>,</span> <span>total</span><span>=</span><span>False</span><span>):</span>
    <span>name</span><span>:</span> <span>str</span> <span>|</span> <span>None</span>
    <span>subscription</span><span>:</span> <span>str</span> <span>|</span> <span>None</span> <span>=</span> <span>None</span>
</code></pre></div>

<p>Since <code>total</code> is False here (by default it is set to True), <code>name</code> or <code>subscription</code> can be absent from the dictionary. Which represents the PATCH operation much better than a <code>dataclass</code> or Pydantic model.</p>
<p>Further additions in <a href="https://peps.python.org/pep-0655/">PEP-655</a> allows us to mark individual fields as <code>Required</code> or <code>NotRequired</code> which further increases its flexibility.</p>
<blockquote>
<p>If you're wondering about FastAPI support for TypedDict, <a href="https://docs.pydantic.dev/2.3/usage/types/dicts_mapping/#typeddict">Pydantic supports it out of the box</a>. So your TypedDict can be used in a FastAPI endpoint.</p>
</blockquote>
<h3>Using <code>TypedDict</code> as <code>**kwargs</code></h3>
<p><a href="https://peps.python.org/pep-0692/">PEP-692</a> introduced the ability to type variadic keyword arguments using <code>TypedDict</code>.</p>
<p>So the following two snippets are equivalent.
Without <code>TypedDict</code>:</p>
<div><pre><span></span><code><span>def</span> <span>my_function</span><span>(</span><span>*</span><span>,</span> <span>option1</span><span>:</span> <span>int</span><span>,</span> <span>option2</span><span>:</span> <span>str</span><span>)</span> <span>-&gt;</span> <span>None</span><span>:</span>
    <span>...</span>
</code></pre></div>

<p>Using <code>TypedDict</code>:</p>
<div><pre><span></span><code><span>from</span> <span>typing</span> <span>import</span> <span>TypedDict</span><span>,</span> <span>Unpack</span>


<span>class</span> <span>Options</span><span>(</span><span>TypedDict</span><span>):</span>
    <span>option1</span><span>:</span> <span>int</span>
    <span>option2</span><span>:</span> <span>str</span>


<span>def</span> <span>my_function</span><span>(</span><span>**</span><span>options</span><span>:</span> <span>Unpack</span><span>[</span><span>Options</span><span>])</span> <span>-&gt;</span> <span>None</span><span>:</span>
    <span>...</span>
</code></pre></div>

<p>At a glance I can say that the TypedDict option is rather verbose. Though it does become more useful if Options were used in multiple function definitions.</p>
<div><pre><span></span><code><span>def</span> <span>my_function2</span><span>(</span><span>**</span><span>options</span><span>)</span> <span>-&gt;</span> <span>None</span><span>:</span>
    <span>...</span>


<span>def</span> <span>my_function3</span><span>(</span><span>*</span><span>,</span> <span>other_option</span><span>:</span> <span>str</span><span>,</span> <span>**</span><span>options</span><span>)</span> <span>-&gt;</span> <span>None</span><span>:</span>
    <span>...</span>
</code></pre></div>

<p>Where it truely shines is once again with non-totality.</p>
<p>Suppose we have the following scenario, where we want to create a custom version of pytest.fixture, but still pass through some arguments.</p>
<div><pre><span></span><code><span>def</span> <span>fixture</span><span>(</span><span>scope</span><span>:</span> <span>str</span> <span>=</span> <span>"module"</span><span>,</span> <span>autouse</span><span>:</span> <span>bool</span> <span>=</span> <span>False</span><span>):</span>
    <span>return</span> <span>pytest</span><span>.</span><span>fixture</span><span>(</span><span>scope</span><span>,</span> <span>autouse</span><span>)</span>
</code></pre></div>

<p>Here to get the typing right I not only have to find the type of each argument but also the default value. It would be better if we use <code>**kwargs</code> so we can just avoid passing the arguments through. And to keep type information we just need to use our trusty <code>TypedDict</code> once more:</p>
<div><pre><span></span><code><span>class</span> <span>FixtureOptions</span><span>(</span><span>TypedDict</span><span>,</span> <span>total</span><span>=</span><span>False</span><span>):</span>
    <span>scope</span><span>:</span> <span>str</span>
    <span>autouse</span><span>:</span> <span>bool</span>


<span>def</span> <span>fixture</span><span>(</span><span>**</span><span>options</span><span>:</span> <span>Unpack</span><span>[</span><span>FixtureOptions</span><span>]):</span>
    <span># Some custom implementations</span>
    <span>...</span>
    <span>return</span> <span>pytest</span><span>.</span><span>fixture</span><span>(</span><span>**</span><span>options</span><span>)</span>
</code></pre></div>

<p>Non-totallity means that we don't have to pass in scope and autouse. We can just have the default.</p>
<h4>Sentinels</h4>
<p>We can achieve similar behaviour with sentinels:</p>
<div><pre><span></span><code><span>UNSPECIFIED</span><span>:</span> <span>Any</span> <span>=</span> <span>object</span><span>()</span>  <span># Has to be Any type so it could be set as default for other types.</span>

<span>def</span> <span>my_func</span><span>(</span><span>option1</span><span>:</span> <span>bool</span> <span>=</span> <span>UNSPECIFIED</span><span>,</span> <span>...</span><span>)</span> <span>-&gt;</span> <span>...</span><span>:</span>
    <span>if</span> <span>option1</span> <span>is</span> <span>UNSPECIFIED</span><span>:</span>
        <span>...</span>
    <span>...</span>
</code></pre></div>

<p>Sentinels work well enough here, but we have to remember to handle them. Additionally type annotations for sentinels can be a bit awkward, here we made <code>UNSPECIFIED</code> an <code>Any</code> type, but it means that inside the function <code>option1</code> is only typed as <code>bool</code>. There are options to expose the sentinel type but they may add even more confusion.</p>
<h3>Using <code>TypedDict</code> to pass in dependencies</h3>
<p>We can do even more with <a href="https://peps.python.org/pep-0692/">PEP-692</a>! When I first learned about the PEP, I thought it was only about function signature. But reading through it more thoroughly, I discovered that another consequence of the PEP is that type checkers can now check for function invocation when using TypedDicts:</p>
<div><pre><span></span><code><span>def</span> <span>purge</span><span>(</span><span>queue</span><span>:</span> <span>str</span><span>,</span> <span>timeout</span><span>:</span> <span>float</span><span>)</span> <span>-&gt;</span> <span>...</span><span>:</span>
    <span>...</span>


<span>class</span> <span>Options</span><span>(</span><span>TypedDict</span><span>):</span>
    <span>queue</span><span>:</span> <span>str</span>
    <span>timeout</span><span>:</span> <span>float</span>


<span>class</span> <span>WrongOptions</span><span>(</span><span>TypedDict</span><span>):</span>
    <span>queue</span><span>:</span> <span>str</span>
    <span>timeout</span><span>:</span> <span>timedelta</span>


<span>options</span><span>:</span> <span>Options</span> <span>=</span> <span>...</span>
<span>purge</span><span>(</span><span>**</span><span>options</span><span>)</span>  <span># ✅</span>

<span>wrong_options</span><span>:</span> <span>WrongOptions</span> <span>=</span> <span>...</span>
<span>purge</span><span>(</span><span>**</span><span>wrong_options</span><span>)</span>  <span># ❌</span>
</code></pre></div>

<p>This feature is necessary in many situations such as cases where we pass through the kwargs. For example, in the <code>fixture</code> example, when we invoke <code>pytest.fixture(**options)</code> the type checker will perform proper type checking.</p>
<p>But we can use it in more creative ways.</p>
<h4>Dependency Injection</h4>
<p>Let's consider a situation where we have many resources that share some dependencies. </p>
<div><pre><span></span><code><span>class</span> <span>UserClient</span><span>:</span>
    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>db</span><span>:</span> <span>Engine</span><span>,</span> <span>user_service</span><span>:</span> <span>APIClient</span><span>)</span> <span>-&gt;</span> <span>None</span><span>:</span>
        <span>...</span>


<span>class</span> <span>ProjectClient</span><span>:</span>
    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>db</span><span>:</span> <span>Engine</span><span>,</span> <span>user_service</span><span>:</span> <span>APIClient</span><span>,</span> <span>project_service</span><span>:</span> <span>APIClient</span><span>)</span> <span>-&gt;</span> <span>None</span><span>:</span>
        <span>...</span>
</code></pre></div>

<p>We want a way to create all the dependencies in one place and pass in the dependencies.</p>
<p>Essentially we need something that is the union of all kwargs of the resources. That suddernly sounds a lot like a TypedDict:</p>
<div><pre><span></span><code><span>class</span> <span>Dependencies</span><span>(</span><span>TypedDict</span><span>):</span>
    <span>db</span><span>:</span> <span>Engine</span>
    <span>user_service</span><span>:</span> <span>APIClient</span>
    <span>project_service</span><span>:</span> <span>APIClient</span>


<span>def</span> <span>create_deps</span><span>(</span><span>...</span><span>)</span> <span>-&gt;</span> <span>Dependencies</span><span>:</span>
    <span>...</span>
</code></pre></div>

<p>Unfortunately this won't work since <code>UserClient</code> can't take <code>project_service</code> as a kwarg.</p>
<p>To fix this, we need to rewrite the resources such that we accept arbitrary arguments.</p>
<div><pre><span></span><code><span>class</span> <span>UserClient</span><span>:</span>
    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>...</span><span>,</span> <span>**</span><span>_</span><span>)</span> <span>-&gt;</span> <span>None</span><span>:</span>
        <span>...</span>
<span>...</span>
</code></pre></div>

<p>And then we can do the injection like this:</p>
<div><pre><span></span><code><span>class</span> <span>ResourceWithMissing</span><span>:</span>
    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>other</span><span>:</span> <span>Any</span><span>,</span> <span>**</span><span>_</span><span>)</span> <span>-&gt;</span> <span>None</span><span>:</span>
        <span>...</span>


<span>def</span> <span>inject</span><span>(</span><span>deps</span><span>:</span> <span>Dependencies</span><span>):</span>
    <span>UserClient</span><span>(</span><span>**</span><span>deps</span><span>)</span>  <span># ✅</span>
    <span>ProjectClient</span><span>(</span><span>**</span><span>deps</span><span>)</span>  <span># ✅</span>
    <span>ResourceWithMissing</span><span>(</span><span>**</span><span>deps</span><span>)</span>  <span># ❌</span>
    <span>...</span>


<span>inject</span><span>(</span><span>create_deps</span><span>(</span><span>...</span><span>))</span>
</code></pre></div>

<p>With the solution complete, we can now rely on the type system to check the dependency injection to see if any arguments are incorrect or missing. </p>
<p>I will admit that changing resource signature with <code>**_</code> is not ideal, but this is a smaller change than most dependency injection frameworks. And we get static type checking which a lot of the frameworks won't support.</p>
<h3>Upcoming Features</h3>
<p><a href="https://peps.python.org/pep-0728/">PEP-728</a> will allow types of extra items to be defined, and a typed dict to be closed meaning no extra items can be defined.</p>
<p>This new change looks like it'll help us define record types more precisely.</p>
<p>I personally haven't thought of many other use cases for it, but as I've demonstrated above it's always worth reading through the PEP and experimenting with the new change. </p>
<p><a href="https://peps.python.org/pep-0705/">PEP-705</a> might already be out by the time you read this. This will allow for read only items to be specified.</p>
<p>This is primarily intended for situations where different typed dicts intuitively should be compatible but potential mutations (deletions) can create problems.</p>
      </div><!-- /.entry-content -->

    </article>
  </section><div id="contentinfo">
                        <address id="about">
                                Proudly powered by <a rel="nofollow" href="https://getpelican.com/">Pelican</a>, which takes great advantage of <a rel="nofollow" href="https://www.python.org/">Python</a>.
                        </address><!-- /#about -->

                        <p>The theme is by <a rel="nofollow" href="https://www.smashingmagazine.com/2009/08/designing-a-html-5-layout-from-scratch/">Smashing Magazine</a>, thanks!</p>
                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: HTML for People (527 pts)]]></title>
            <link>https://htmlforpeople.com</link>
            <guid>41801334</guid>
            <pubDate>Thu, 10 Oct 2024 17:47:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://htmlforpeople.com">https://htmlforpeople.com</a>, See on <a href="https://news.ycombinator.com/item?id=41801334">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main-content">
      
  
<p>HTML isn’t only for people working in the tech field. It’s for anybody, the way documents are for anybody. HTML is just another type of document. A very special one—the one the web is built on.</p>
<p>I’m <a href="https://blakewatson.com/">Blake Watson</a>. I’ve been building websites since the early 2000s. Though I work professionally in the field, I feel strongly that <em>anyone</em> should be able to make a website with HTML if they want. This book will teach you how to do just that. It doesn’t require any previous experience making websites or coding. I will cover everything you need to know to get started in an approachable and friendly way.</p>
<p>Ready? Let’s do it!</p>


  <p>
    <a href="https://htmlforpeople.com/intro">Read the introduction</a>
    <a href="https://htmlforpeople.com/zero-to-internet-your-first-website">Start coding already!</a>
  </p>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Microsoft Recall is now an explorer.exe dependency (205 pts)]]></title>
            <link>https://github.com/ChrisTitusTech/winutil/issues/2697</link>
            <guid>41801331</guid>
            <pubDate>Thu, 10 Oct 2024 17:47:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/ChrisTitusTech/winutil/issues/2697">https://github.com/ChrisTitusTech/winutil/issues/2697</a>, See on <a href="https://news.ycombinator.com/item?id=41801331">Hacker News</a></p>
<div id="readability-page-1" class="page"><div disabled="" sortable="">
          <p dir="auto">There are 3 settings you can use to practically disable copilot/recall completely. These will do the following things<br>
1: Remove the package so it doesn't even appear in search or app lists<br>
2: Remove the package so it doesn't activate if you hit the new copilot key on keyboards<br>
3: Remove the package so it doesn't even show up as an app that was installed in apps and features</p>
<p dir="auto">In group policy there are 2 settings</p>
<p dir="auto">"turn off windows copilot"<br>
(UserConfig\AdministrativeTemplates\WindowsComponents\Windows Copilot)</p>
<p dir="auto">"turn off saving snapshots to windows"<br>
(UserConfig\AdministrativeTemplates\WindowsComponents\Windows Ai)</p>
<p dir="auto">These 2 group policy options enter 2 registry keys located here</p>
<p dir="auto">HKEY_LOCAL_MACHINE\SOFTWARE\Policies\Microsoft\Windows\WindowsCopilot<br>
HKEY_CURRENT_USER\Software\Policies\Microsoft\Windows\WindowsCopilot<br>
"TurnOffWindowsCopilot"<br>
Dword (1)</p>
<p dir="auto">HKEY_CURRENT_USER\Software\Policies\Microsoft\Windows\WindowsAI<br>
HKEY_LOCAL_MACHINE\SOFTWARE\Policies\Microsoft\Windows\WindowsCopilot<br>
"DisableAIDataAnalysis"<br>
Dword (1)</p>
<p dir="auto">If you also use an app called "AppXPackagesManager"<br>
<a href="https://github.com/Savitarax/File-Resources">https://github.com/Savitarax/File-Resources</a><br>
(I am NOT the original creator of said app, I am merely providing the software to use)</p>
<p dir="auto">Copilot is an option that you can remove listed in user packages</p>
<p dir="auto">After doing these steps.<br>
I can't get copilot to activate in any way, nor can I find recall.</p>
<p dir="auto">Figured i'd list this to anyone that was looking for a pretty solid solution if they were looking for the template to do so.</p>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Studios: Please Don't Spoil the Movie We Are Seated to See (229 pts)]]></title>
            <link>http://fxrant.blogspot.com/2024/06/studios-dont-spoil-movie-we-are-seated.html</link>
            <guid>41801300</guid>
            <pubDate>Thu, 10 Oct 2024 17:44:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://fxrant.blogspot.com/2024/06/studios-dont-spoil-movie-we-are-seated.html">http://fxrant.blogspot.com/2024/06/studios-dont-spoil-movie-we-are-seated.html</a>, See on <a href="https://news.ycombinator.com/item?id=41801300">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-body-8595952586617710821" itemprop="description articleBody">
<p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhXlFhEI0V8S6K4imrSag-M5PNYBCJIV-ze_r-r6R06QUqdyY49YhxiO79peJKdwjV8mH06lM5R-JFgSU57mfctbt1eyM52NbW9L0F95gZqMaq8RIsQInxb7Jrkf8wi5V3Zw7TRod8OsP3I72jsP5ZgwGzaNAWfdjERvIgFLBtSSPvfvP9Aq5U/s720/alien-1979.jpg.webp" imageanchor="1"><img data-original-height="480" data-original-width="720" height="265" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhXlFhEI0V8S6K4imrSag-M5PNYBCJIV-ze_r-r6R06QUqdyY49YhxiO79peJKdwjV8mH06lM5R-JFgSU57mfctbt1eyM52NbW9L0F95gZqMaq8RIsQInxb7Jrkf8wi5V3Zw7TRod8OsP3I72jsP5ZgwGzaNAWfdjERvIgFLBtSSPvfvP9Aq5U/w400-h265/alien-1979.jpg.webp" width="400"></a></p><p>I tweeted this incredibly non-controversial take and it got a huge reaction, so I thought I'd recycle the content for a blog post. Enjoy.</p><p>We took our kid to see "Alien" (1979) on the big screen during its one-week-only theatrical run. We told him there was a good chance of a pre-show featurette that would spoil the movie, so he needed to be ready to cover his eyes.</p><p>Well, that's exactly what happened.</p><p>My kid threw his hoodie over his eyes while a pre-show interview between Fede Alvarez and Ridley Scott appeared, featuring tons of behind-the-scenes photos of the alien, the chestburster scene, and discussion of the legacy of the classic film.</p><p>Why do this before the movie!??!</p><p>If even one person in that theater hadn't seen the film yet, it puts a huge damper on the surprise and delight that the movie would bring them, which is sad. We WANT to bring first-timers to theaters to see classic movies. Don't ruin it for them.</p><p><b>Play that shit AFTER the movie.</b></p><p>This has happened with several re-releases for me. Fathom did this to "Star Trek II: The Wrath of Khan" (pre-show highlighted a main character's death!) and "Close Encounters" (pre-show showed the effing aliens!). And now "Alien" (Disney/Fox).</p><p>The solution is simple: preserve the wonder for first-timers by putting these featurettes AFTER the movie. Tease it before the feature.</p><p>Anyway, <a href="https://www.fathomevents.com/events/close-encounters-of-the-third-kind-2024-re-release/">"Close Encounters of the Third Kind" is coming to theaters again this summer </a>(Fathom), so get ready to cover the eyes of first-timers before the show.</p><p><a href="https://x.com/tvaziri/status/1796955123337372032">Original tweet thread.</a></p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Game Programming in Prolog (245 pts)]]></title>
            <link>https://thingspool.net/morsels/page-10.html</link>
            <guid>41800764</guid>
            <pubDate>Thu, 10 Oct 2024 16:50:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thingspool.net/morsels/page-10.html">https://thingspool.net/morsels/page-10.html</a>, See on <a href="https://news.ycombinator.com/item?id=41800764">Hacker News</a></p>
<div id="readability-page-1" class="page">

<a href="https://thingspool.net/morsels/list.html">Back to List</a>

<h3>Author: Youngjin Kang</h3>
<h3>Date: August 25, 2024</h3>

<hr>

<h3><b>Introduction</b></h3>
<p>As a fan of unconventional programming paradigms, I enjoy learning new programming languages which are drastically different from the typical object-oriented ones such as C#, Java, and the like. The most iconic of them are LISP (which is a powerful language for both functional programming as well as metalinguistic patterns in software development) and Prolog (which is one of the most popular languages in logic programming). Learning these languages is quite hard, compared to being acquainted with usual C-style imperative languages such as Ruby and Python, yet it has turned out to be one of the most effective ways of exercising one's brain.</p>
<p>By the time I started learning LISP via MIT's 1986 lecture series called "SICP (Structure and Interpretation of Computer Programs)" back in 2018, I was already quite familiar with some of its core concepts (such as lambda expressions, higher-order functions, etc) because they were already integrated as some of the main features of C#, which was the language I was using all the time as a Unity game developer. Also, my academic background in electrical engineering (signal processing in particular) helped me easily grasp the idea of "stream processing" which appeared in the latter half of the lecture series. Thus, learning LISP and its functional design patterns was not as difficult as I imagined it to be.</p>
<p>A major intellectual challenge, however, struck me when I began to study Prolog - the famous logic programming language which is notorious for its esoteric syntax. The grammar itself did not appear to be complicated at all; it was just as minimal as that of LISP. The way in which programming had to be done in Prolog, though, was stressful enough to fry the engine of my brain. The way it approached data structures (such as lists) and algorithms based upon mathematical relations was something so revolutionarily novel to me, that it seriously opened up a new horizon in my faculty of computational reasoning.</p>
<p>While Prolog's approach in software development was quite alien to me, I managed to notice a number of familiar associations between Prolog and many useful topics in engineering. I discovered, for example, that the so-called "relational databases" (e.g. MySQL) are named so not because they comprise data tables which are related to each other via references, but because each row of a data table can be considered an n-ary predicate (where 'n' is the number of columns in the table) in Prolog's syntax. Besides, I found out that the input/output behavior of each digital circuit component (e.g. logic gate) could be implemented as an n-ary relation (where 'n' is the total number of the input/output ports combined), implying that an "object", whether it be a piece of hardware or a piece of pure data in memory, may as well be defined as a relation in logic programming (just like an object may as well be defined as a function in functional programming). Furthermore, the declarative nature of Prolog strongly convinced me that it must be optimal for data-driven design.</p>
<p>These realizations soon led me to contemplate upon the notion that, maybe, logic programming has a great deal of potential in the design and implementation of highly complex systems, such as a video game's core gameplay mechanics. I began to ask myself, "Will it be possible to develop an entire game using the grammar of logic programming?"</p>
<p>Indeed, there are reasons why most game developers just stick to general-purpose programming languages (such as C#) for making games, aside from purely experimental purposes. Implementing an entire game based on Prolog, for instance, is perhaps too much of a challenge for those who are not hardcore mathematicians. Also, Prolog may not be the best language to use for parts of the project which are not necessarily made of a complex web of relations, such as simple I/O modules, graphics modules, audio modules, physics modules, and the like.</p>
<p>However, I believe that at least the core mechanics of a game can definitely be implemented using the language of Prolog, and that we will be able to solve a plethora of complex design problems by doing so. It is because a gameplay system which is structured in terms of a set of declarative statements will be far more robust, modular, and free of confusing edge cases (e.g. race conditions) than an imperative system.</p>
<p>For this alternative methodology to be successful, one must start by designing the system in terms of logical relations/predicates only, and nothing else (That is, no functions, no structs, no classes, no interfaces, no state variables, etc). This will allow us to construct a gameplay system which is purely driven by the soul of Prolog.</p>
<hr>

<h3><b>World and Actors</b></h3>
<p>The core idea in Prolog-based game programming is to utilize relations as the most primitive building blocks of the system, just like basic circuit components (e.g. resistors, transistors, capacitors, inductors, etc) are the most primitive building blocks of an electric circuit. It is sensible, therefore, to start this journey by considering the most rudimentary relations (e.g. unary and binary) first, and see if these elements can serve as the most essential nuts and bolts of the game.</p>
<img src="https://thingspool.net/morsels/e01.jpg" alt="Game Programming in Prolog - Part 1 (Figure 1)">
<p>Suppose that we are designing a game, and that the game consists of two major parts - world and actors (see the image above). The world is a scene in which everything is supposed to happen, and actors are objects which belong to the world. Examples of actors include "players", "enemies", "obstacles", "items", and pretty much any discrete entities which have their own names and attributes. Actors are able to interact with each other (as well as with themselves), from which various events occur. What we refer to as "gameplay" is a chain of such events.</p>
<p>We will begin formulating a gameplay system based off of this conceptual backbone. All you need to remember is that there is a world, and that the world contains a number of actors, each of which possesses its own state and behavior.</p>
<hr>

<h3><b>Tags</b></h3>
<p>First of all, let us identify each individual actor with a unique name. If there are two actors in the world, for instance, we will simply assume that the name "actor1" and "actor2" will be used to indicate the first and second actors, respectively.</p>
<img src="https://thingspool.net/morsels/e02.jpg" alt="Game Programming in Prolog - Part 1 (Figure 2)">
<p>The first piece of logic I will illustrate is the idea of tags. A tag is a keyword which, when attached to an actor, describes what the actor stands for. When an actor has the tag "bread" attached to it, for example, we should be able to tell that the actor is a piece of bread.</p>
<p>The Prolog code below assigns the tag "bread" to both actor1 and actor2, in the form of unary predicates (The tag "bread" itself is an unary relation, and "bread(actor1)" &amp; "bread(actor2)" are two separate instances of it). This implies that both actor1 and actor2 are pieces of bread.</p>
<div><pre><code>bread(actor1).
bread(actor2).</code></pre></div>
<img src="https://thingspool.net/morsels/e03.jpg" alt="Game Programming in Prolog - Part 1 (Figure 3)">
<p>An actor can have multiple tags as well. However, one may feel that it is a bit too tedious to manually assign a bunch of tags to each individual actor. For example, let us say that every piece of bread must also be labeled as flammable and decomposable. This means that, whenever an actor is associated with the tag "bread", we are obliged to always ensure that it is also associated with the tag "flammable" and "decomposable". Manually attaching these two additional tags to every "bread" actor is way too cumbersome and error-prone. Fortunately, the following pair of horn clauses neatly solve this problem. They enforce the following two rules:</p>
<p>(1) Whenever tag "bread" is assigned to actor X, tag "flammable" will automatically be assigned to actor X.<br>(2) Whenever tag "bread" is assigned to actor X, tag "decomposable" will automatically be assigned to actor X.</p>
<div><pre><code>flammable(X) :- bread(X).
decomposable(X) :- bread(X).</code></pre></div>
<img src="https://thingspool.net/morsels/e04.jpg" alt="Game Programming in Prolog - Part 1 (Figure 4)">
<p>These horn clauses, therefore, serve as part of the game's "config data" - a list of data entries in the game's technical design document (like the ones you would see on a spreadsheet) telling us the characteristics of each individual character type, skill type, mission type, and so forth. The tags called "flammable" and "decomposable" in our case, for instance, are characteristics which belong to the type-specifier called "bread", meaning that any actor which can be identified as "bread" is a composition of two properties called "flammable" and "decomposable".</p>
<p>A decent analogy can be found in Unity game engine, where we may create a prefab called "Bread" with two components in it - "Flammable" and "Decomposable". Or, in a general object-oriented programming environment, "Bread" may stand for the name of a class which implements two interfaces called "IFlammable" and "IDecomposable".</p>
<p>In a way, therefore, horn clauses in Prolog play the role of data type definitions.</p>
<img src="https://thingspool.net/morsels/e05.jpg" alt="Game Programming in Prolog - Part 1 (Figure 5)">
<p>Aside from these pre-configured tags (which all rely on the presence of the tag "bread"), one may as well attach a custom tag to an actor as needed. For example, imagine that a wizard happened to enchant actor2 (i.e. the second piece of bread). This means that, unlike actor1 which is an ordinary piece of bread, actor2 must be an "enchanted" piece of bread which is required to have the tag "enchanted" attached to it for the purpose of showing us that it has been enchanted. The code below ensures that this is the case.</p>

<img src="https://thingspool.net/morsels/e06.jpg" alt="Game Programming in Prolog - Part 1 (Figure 6)">
<p>The tags "flammable" and "decomposable" are characteristics of all pieces of bread, whereas the tag "enchanted" is a characteristic of only special pieces of bread which have been enchanted by a wizard.</p>
<hr>

<h3><b>Relationships</b></h3>
<p>So far, we have been using tags for specifying the characteristics of each individual actor. In a gameplay system, however, we also need to specify relationships between actors, such as ways in which they interact, etc.</p>
<p>In an ecosystem, predators chase preys and preys run from predators. In a dating simulator, a guy tries to flirt with girls and girls reject him. In a social simulator (such as The Sims), people are either friends or enemies of each other, or somewhere in between. In the game of chess, a bishop devours a rook diagonally and a rook devours a bishop orthogonally. These are all relationships out of which the game's dynamics emerge.</p>
<p>Defining actor-to-actor relationships in Prolog is pretty straightforward. Just like an unary predicate can be used to characterize a single actor, a binary predicate can be used to characterize a relationship between a pair of actors. And by means of a horn clause, such a relationship can be dynamically deduced from a set of requisite conditions.</p>
<p>The following code is an example of a relationship. Suppose that there is a third actor called "actor3", and that we have declared it as a human (by attaching the tag "human" to it). Since a human is able to eat a piece of bread, we can confidently assert that "X can eat Y if X is a human and Y is a piece of bread". Here, "X can eat Y" is a relationship which holds whenever X is associated with tag "human" and Y is associated with tag "bread".</p>
<div><pre><code>human(actor3).
canEat(X, Y) :- human(X), bread(Y).</code></pre></div>
<img src="https://thingspool.net/morsels/e07.jpg" alt="Game Programming in Prolog - Part 1 (Figure 7)">
<p>Here is another example. Since a piece of bread is decomposable (because anything which is identified as "bread" must also be identified as "decomposable"), we know that microbes such as fungi are capable of spoiling it. If there is an actor with the tag "fungus" attached to it, therefore, we will be able to tell that it must be able to spoil any other actor which is "decomposable". This is yet another case of a relationship between two types of actors; it is a relationship which says, "X can spoil Y if X is a fungus and Y is decomposable". The following code shows its definition.</p>
<div><pre><code>fungus(actor4).
canSpoil(X, Y) :- fungus(X), decomposable(Y).</code></pre></div>
<img src="https://thingspool.net/morsels/e08.jpg" alt="Game Programming in Prolog - Part 1 (Figure 8)">
<p>There is something still missing here, though. While I have demonstrated that it is possible to assign characteristics to individual actors as well as their mutual connections (i.e. relationships), I have not shown yet how to make these characteristics change over time. They all have been static so far, and the declarative nature of Prolog does not seem to offer an easy solution to make things dynamic.</p>
<p>If we want to create a game rather than a fixed landscape of how things are shaped permanently, we better let them move and interact as time goes by. In the next part of the series, I will explain how the game loop shall be conceptualized in Prolog.</p>
<p>(Will be continued in <a href="https://thingspool.net/morsels/page-11.html">Part 2</a>)</p>


</div>]]></description>
        </item>
        <item>
            <title><![CDATA[DeskPad – A virtual monitor for screen sharing (1000 pts)]]></title>
            <link>https://github.com/Stengo/DeskPad</link>
            <guid>41800602</guid>
            <pubDate>Thu, 10 Oct 2024 16:36:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/Stengo/DeskPad">https://github.com/Stengo/DeskPad</a>, See on <a href="https://news.ycombinator.com/item?id=41800602">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><div dir="auto"><h3 tabindex="-1" dir="auto">
  <a href="https://github.com/Stengo/DeskPad/blob/main/DeskPad/Assets.xcassets/AppIcon.appiconset/Icon-256.png">
  <img src="https://github.com/Stengo/DeskPad/raw/main/DeskPad/Assets.xcassets/AppIcon.appiconset/Icon-256.png?raw=true" alt="DeskPad Icon" width="128">
  </a>
</h3><a id="user-content-------" aria-label="Permalink: " href="#------"></a></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">DeskPad</h2><a id="user-content-deskpad" aria-label="Permalink: DeskPad" href="#deskpad"></a></p>
<p dir="auto">A virtual monitor for screen sharing</p>
<div dir="auto"><h3 tabindex="-1" dir="auto">
  <a href="https://github.com/Stengo/DeskPad/blob/main/screenshot.jpg">
  <img src="https://github.com/Stengo/DeskPad/raw/main/screenshot.jpg?raw=true" alt="DeskPad Screenshot">
  </a>
</h3><a id="user-content--------1" aria-label="Permalink: " href="#-------1"></a></div>
<p dir="auto">Certain workflows require sharing the entire screen (usually due to switching through multiple applications), but if the presenter has a much larger display than the audience it can be hard to see what is happening.</p>
<p dir="auto">DeskPad creates a virtual display that is mirrored within its application window so that you can create a dedicated, easily shareable workspace.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto">You can either download the <a href="https://github.com/Stengo/DeskPad/releases">latest release binary</a> or install via <a href="https://brew.sh/" rel="nofollow">Homebrew</a> by calling <code>brew install deskpad</code>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto">DeskPad behaves like any other display. Launching the app is equivalent to plugging in a monitor, so macOS will take care of properly arranging your windows to their previous configuration.</p>
<p dir="auto">You can change the display resolution through the system preferences and the application window will adjust accordingly.</p>
<p dir="auto">Whenever you move your mouse cursor to the virtual display, DeskPad will highlight its title bar in blue and move the application window to the front to let you know where you are.</p>
<div dir="auto"><h3 tabindex="-1" dir="auto">
  <a href="https://github.com/Stengo/DeskPad/blob/main/demonstration.gif">
  <img src="https://github.com/Stengo/DeskPad/raw/main/demonstration.gif?raw=true" alt="DeskPad Demonstration" data-animated-image="">
  </a>
</h3><a id="user-content--------2" aria-label="Permalink: " href="#-------2"></a></div>
</article></div></div>]]></description>
        </item>
    </channel>
</rss>