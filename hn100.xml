(ignoring known css parsing error)
<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Fri, 06 Dec 2024 00:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[McKinsey unit will pay $123M to settle claims it bribed South African officials (110 pts)]]></title>
            <link>https://www.cnbc.com/2024/12/05/mckinsey-bribery-settlement-south-africa.html</link>
            <guid>42332352</guid>
            <pubDate>Thu, 05 Dec 2024 20:24:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnbc.com/2024/12/05/mckinsey-bribery-settlement-south-africa.html">https://www.cnbc.com/2024/12/05/mckinsey-bribery-settlement-south-africa.html</a>, See on <a href="https://news.ycombinator.com/item?id=42332352">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="RegularArticle-ArticleBody-5" data-module="ArticleBody" data-test="articleBody-2" data-analytics="RegularArticle-articleBody-5-2"><div id="ArticleBody-InlineImage-108048622" data-test="InlineImage"><p>This photograph shows a logo of American multinational corporation McKinsey &amp; Company on the first day of the Mobile World Congress (MWC), the telecom industry's biggest annual gathering, in Barcelona on February 26, 2024.&nbsp;</p><p>Pau Barrena | Afp | Getty Images</p></div><div><p>A subsidiary of top global consulting firm McKinsey &amp; Company agreed to pay nearly $123 million to settle claims that it bribed government officials in South Africa, the <a href="https://www.justice.gov/opa/pr/mckinsey-company-africa-pay-over-122m-connection-bribery-south-african-government-officials" target="_blank">U.S. Department of Justice said</a> Thursday.</p><p>Federal prosecutors also unsealed a 2022 guilty plea by Vikas Sagar, a former senior partner at McKinsey who worked in the subsidiary's South Africa office. </p><p>Sagar, 56, of Johannesburg, <a href="https://www.justice.gov/opa/pr/mckinsey-company-africa-pay-over-122m-connection-bribery-south-african-government-officials" target="_blank">pleaded guilty in</a> U.S. District Court for the&nbsp;Southern District&nbsp;of&nbsp;New York, to one count of conspiracy to violate the Foreign Corrupt Practices Act.</p><p>The subsidiary, McKinsey Africa, paid bribes to officials at two state-controlled utility companies in South Africa between 2012 and 2016 in order to secure lucrative consulting contracts, the DOJ said in a press release.</p><p>Prosecutors said McKinsey Africa obtained confidential information from the two companies, Transnet SOC Ltd. and Eskom Holdings SOC Ltd., about the contracts during the bidding process.</p><p>Then it submitted multimillion-dollar consulting engagement proposals, knowing that other South African consulting firms it had partnered with would pay part of their fees as bribes to Transnet and Eskom officials, the DOJ said.</p><p>The bribery scheme helped McKinsey and McKinsey Africa net approximately $85 million in profits, according to prosecutors.</p><p>McKinsey Africa has entered into a three-year deferred prosecution agreement with the DOJ related to a criminal charging document, called an information, charging McKinsey Africa with one count of conspiracy to violate the anti-bribery provisions of the FCPA, prosecutors said.</p><p>The deferred prosecution agreement requires McKinsey Africa to accept responsibility for the allegations.</p><p>"McKinsey Africa engaged in a serious and long-running bribery scheme to secure contracts by corrupting government officials," Chad Yarbrough, assistant director of the FBI Criminal Investigative Division, said in the press release.</p><p>"This misconduct is a blatant violation of law and a breach of public trust. No matter what country the crime occurs in, the FBI will always work closely with our international partners to root out corruption," said Yarbough.</p><p>"McKinsey welcomes the resolution of these matters and the closure of this regretful situation," McKinsey Africa said in a statement Thursday.</p><p>"McKinsey is a very different firm today than when these matters first took place," the subsidiary said, adding, "We fired Mr. Sagar soon after learning of these issues, returned our fees with interest, cooperated with the authorities, and made significant upgrades to our risk, legal, and compliance controls to ensure McKinsey sets the standard across our profession."</p></div><div id="RegularArticle-RelatedContent-1"><h2>Read more CNBC politics coverage</h2><div><ul><li><a href="https://www.cnbc.com/2024/12/03/florida-prison-sentence-ponzi-scheme-business.html">Florida woman who led a nearly $200 million Ponzi scheme sentenced to 20 years in prison</a></li><li><a href="https://www.cnbc.com/2024/12/04/trump-picks-peter-navarro-as-top-trade-advisor.html">Trump picks Peter Navarro as top trade advisor</a></li><li><a href="https://www.cnbc.com/2024/12/04/trump-georgia-election-interference-case-dismissal-court-.html">Trump asks Georgia court to end criminal election interference case, cites White House win</a></li><li><a href="https://www.cnbc.com/2024/12/04/french-government-toppled-in-no-confidence-vote-brought-by-opposition.html">French government toppled in no-confidence vote brought by opposition</a></li><li><a href="https://www.cnbc.com/2024/12/05/trump-picks-adam-boehler-to-be-presidential-envoy-for-hostage-affairs.html">Trump picks former Development Finance Corp. CEO Adam Boehler as special envoy for hostage affairs</a></li></ul></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Congo gov. says it's 'on alert' over mystery flu-like disease that killed dozens (116 pts)]]></title>
            <link>https://www.ctvnews.ca/health/congo-government-says-it-s-on-alert-over-mystery-flu-like-disease-that-killed-dozens-1.7134550</link>
            <guid>42332129</guid>
            <pubDate>Thu, 05 Dec 2024 20:06:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ctvnews.ca/health/congo-government-says-it-s-on-alert-over-mystery-flu-like-disease-that-killed-dozens-1.7134550">https://www.ctvnews.ca/health/congo-government-says-it-s-on-alert-over-mystery-flu-like-disease-that-killed-dozens-1.7134550</a>, See on <a href="https://news.ycombinator.com/item?id=42332129">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    
      <p><span>KINSHASHA, Congo - </span></p><p>
	Public health officials in Africa urged caution Thursday as Congo's health minister said the government was on alert over a mystery flu-like disease that in recent weeks killed dozens of people.</p>
<p>
	Jean Kaseya, the head of Africa Centers for Disease Control and Prevention, told reporters that more details about the disease should be known in the next 48 hours as experts receive results from laboratory samples of infected people.</p>
<ul>
	<li>
		<a href="https://www.ctvnews.ca/app" target="_blank"><strong>Download the CTV News App for breaking news alerts and video on all the top stories</strong></a></li>
</ul>
<p>
	"First diagnostics are leading us to think it is a respiratory disease," Kaseya said. "But we need to wait for the laboratory results." He added that there are many things that are still unknown about the disease -- including whether it is infectious and how it is transmitted.</p>
<p>
	Authorities in Congo have so far confirmed 71 deaths, including 27 people who died in hospitals and 44 in the community in the southern Kwango province, health minister Roger Kamba said.</p>
<p>
	"The Congolese government is on general alert regarding this disease," Kamba said, without providing more details.</p>
<p>
	Of the victims at the hospitals, 10 died due to lack of blood transfusion and 17 as a result of respiratory problems, he said.</p>
<p>
	The deaths were recorded between Nov. 10 and Nov. 25 in the Panzi health zone of Kwango province. There were around 380 cases, almost half of which were children under the age of five, according to the minister.</p>
<p>
	The Africa CDC recorded slightly different numbers, with 376 cases and 79 deaths. The discrepancy was caused by problems with surveillance and case definition, Kaseya said.</p>
<p>
	Authorities have said that symptoms include fever, headache, cough and anemia. Epidemiological experts are in the region to take samples and investigate the disease, the minister said.</p>
<ul>
	<li>
		<strong><a href="https://whatsapp.com/channel/0029VaHOKHN3rZZbOPG8Kz2H" target="_blank">Follow the CTV News channel on WhatsApp</a></strong></li>
</ul>
<p>
	The Panzi health zone, located around 435 miles (700 kilometres) from the capital Kinshasa, is a remote area of the Kwango province, making it hard to access.</p>
<p>
	The epidemiological experts took two days to arrive there, the minister said. Because of the lack of testing capacity, samples had to be taken to Kikwit, more than 500 km away, said Dieudonne Mwamba, the head of the National Institute for Public Health.</p>
<p>
	"The health system is quite weak in our rural areas, but for certain types of care, the ministry has all the provisions, and we are waiting for the first results of the sample analysis to properly calibrate things," Kaseya said.</p>
<p>
	Mwamba said that Panzi was already a "fragile" zone, with 40 per cent of its residents experiencing malnutrition. It was also hit by an epidemic of typhoid fever two years ago, and there is currently a resurgence of seasonal flu across the country.</p>
<p>
	"We need to take into account all this as context," Mwamba said.</p>
<p>
	A Panzi resident, Claude Niongo, said his wife and seven-year-old daughter died from the disease.</p>
<p>
	"We do not know the cause but I only noticed high fevers, vomiting... and then death," Niongo told The Associated Press over the phone. "Now, the authorities are talking to us about an epidemic but in the meantime, there is a problem of care (and) people are dying," he added.</p>
<ul>
	<li>
		<a href="https://www.ctvnews.ca/newsletters" target="_blank"><strong>Sign up for breaking news alerts from CTV News, right at your fingertips</strong></a></li>
</ul>
<p>
	Lucien Lufutu, president of the civil society consultation framework of Kwango province, who is in Panzi, said the local hospital where patients are treated is underequipped.</p>
<p>
	"There is a lack of medicines and medical supplies, since the disease is not yet known, most of the population is treated by traditional practitioners," Lufutu told the AP.</p>
<p>
	He also said the disease affected Katenda, another nearby health zone.</p>
<p>
	When asked about a potential outbreak in other health zones, the minister said he could not tell if that was the case but that nothing was reported.</p>
<p>
	Congo is already plagued by the mpox epidemic, with more than 47,000 suspected cases and over 1,000 suspected deaths from the disease in the Central African country, according to the World Health Organization.</p>
<p>
	-----</p>
<p>
	<em>The Associated Press receives financial support for global health and development coverage in Africa from the Gates Foundation. The AP is solely responsible for all content. Find AP's standards for working with philanthropies, a list of supporters and funded coverage areas at AP.org.</em></p>

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tsunami Warning for Northern California (281 pts)]]></title>
            <link>https://www.tsunami.gov/?p=PAAQ/2024/12/05/so1aq0/1/WEAK51</link>
            <guid>42331326</guid>
            <pubDate>Thu, 05 Dec 2024 18:58:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tsunami.gov/?p=PAAQ/2024/12/05/so1aq0/1/WEAK51">https://www.tsunami.gov/?p=PAAQ/2024/12/05/so1aq0/1/WEAK51</a>, See on <a href="https://news.ycombinator.com/item?id=42331326">Hacker News</a></p>
Couldn't get https://www.tsunami.gov/?p=PAAQ/2024/12/05/so1aq0/1/WEAK51: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Banan-OS, an Unix-like operating system written from scratch (150 pts)]]></title>
            <link>https://github.com/Bananymous/banan-os</link>
            <guid>42331270</guid>
            <pubDate>Thu, 05 Dec 2024 18:54:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/Bananymous/banan-os">https://github.com/Bananymous/banan-os</a>, See on <a href="https://news.ycombinator.com/item?id=42331270">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><a href="https://git.bananymous.com/Bananymous/banan-os" rel="nofollow"><img src="https://camo.githubusercontent.com/138af8e93904d20476c6f4d19e8dc6c1853136292bf7edb4c1891becb40f989c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f64796e616d69632f6a736f6e3f75726c3d687474707325334125324625324662616e616e796d6f75732e636f6d25324662616e616e2d6f73253246746f6b65692e6a736f6e2671756572793d2532342e6c696e6573266c6162656c3d746f74616c2532306c696e6573" alt="" data-canonical-src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fbananymous.com%2Fbanan-os%2Ftokei.json&amp;query=%24.lines&amp;label=total%20lines"></a>
<a href="https://git.bananymous.com/Bananymous/banan-os" rel="nofollow"><img src="https://camo.githubusercontent.com/0ef8861bdf681dce6369983306d9016d2266097865fec0e84154b0b1b761de2c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f636f6d6d69742d61637469766974792f6d2f42616e616e796d6f75732f62616e616e2d6f73" alt="" data-canonical-src="https://img.shields.io/github/commit-activity/m/Bananymous/banan-os"></a>
<a href="https://git.bananymous.com/Bananymous/banan-os/src/branch/main/LICENSE" rel="nofollow"><img src="https://camo.githubusercontent.com/97044798f55906a525e307077719e27834cdce087477e7ea135f608aae965cc4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f62616e616e796d6f75732f62616e616e2d6f73" alt="" data-canonical-src="https://img.shields.io/github/license/bananymous/banan-os"></a>
<a href="https://discord.gg/ehjGySwYdK" rel="nofollow"><img src="https://camo.githubusercontent.com/aa668f05a2cb56d9412d0a73a8da516ce2e840af413a0f74647636afc7dd5acb/68747470733a2f2f696d672e736869656c64732e696f2f646973636f72642f313234323136353137363033323239373034303f6c6f676f3d646973636f7264266c6162656c3d646973636f7264" alt="" data-canonical-src="https://img.shields.io/discord/1242165176032297040?logo=discord&amp;label=discord"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">banan-os</h2><a id="user-content-banan-os" aria-label="Permalink: banan-os" href="#banan-os"></a></p>
<p dir="auto">This is my hobby operating system written in C++. Currently supports x86_64 and i686 architectures.</p>
<p dir="auto">You can find a live demo <a href="https://bananymous.com/banan-os" rel="nofollow">here</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Features</h3><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">General</h4><a id="user-content-general" aria-label="Permalink: General" href="#general"></a></p>
<ul>
<li> Ring3 userspace</li>
<li> SMP (multiprocessing)</li>
<li> Linear framebuffer (VESA and GOP)</li>
<li> Network stack</li>
<li> ELF executable loading</li>
<li> AML interpreter (partial)</li>
<li> Basic graphical environment
<ul>
<li> Terminal emulator</li>
<li> Status bar</li>
<li> Program launcher</li>
<li> Some nice apps</li>
</ul>
</li>
<li> ELF dynamic linking</li>
<li> copy-on-write memory
<ul>
<li> file mappings</li>
<li> anonymous mappings</li>
</ul>
</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Drivers</h4><a id="user-content-drivers" aria-label="Permalink: Drivers" href="#drivers"></a></p>
<ul>
<li> NVMe disks</li>
<li> ATA (IDE, SATA) disks</li>
<li> E1000 and E1000E NICs</li>
<li> RTL8111/8168/8211/8411 NICs</li>
<li> PS2 keyboard (all scancode sets)</li>
<li> PS2 mouse</li>
<li> USB
<ul>
<li> Keyboard</li>
<li> Mouse</li>
<li> Mass storage</li>
<li> Hubs</li>
<li> ...</li>
</ul>
</li>
<li> virtio devices (network, storage)</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Network</h4><a id="user-content-network" aria-label="Permalink: Network" href="#network"></a></p>
<ul>
<li> ARP</li>
<li> ICMP</li>
<li> IPv4</li>
<li> UDP</li>
<li> TCP (partial and buggy)</li>
<li> Unix domain sockets</li>
<li> SSL</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Filesystems</h4><a id="user-content-filesystems" aria-label="Permalink: Filesystems" href="#filesystems"></a></p>
<ul>
<li> Virtual filesystem</li>
<li> Ext2</li>
<li> FAT12/16/32</li>
<li> Dev</li>
<li> Ram</li>
<li> Proc</li>
<li> Sys</li>
<li> 9P</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Bootloader support</h4><a id="user-content-bootloader-support" aria-label="Permalink: Bootloader support" href="#bootloader-support"></a></p>
<ul>
<li> GRUB</li>
<li> Custom BIOS bootloader</li>
<li> Custom UEFI bootloader</li>
</ul>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/Bananymous/banan-os/blob/main/assets/banan-os.png"><img src="https://github.com/Bananymous/banan-os/raw/main/assets/banan-os.png" alt="screenshot from qemu running banan-os"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Code structure</h2><a id="user-content-code-structure" aria-label="Permalink: Code structure" href="#code-structure"></a></p>
<p dir="auto">Each major component and library has its own subdirectory (kernel, userspace, libc, ...). Each directory contains directory <em>include</em>, which has <strong>all</strong> of the header files of the component. Every header is included by its absolute path.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Building</h2><a id="user-content-building" aria-label="Permalink: Building" href="#building"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Needed packages</h3><a id="user-content-needed-packages" aria-label="Permalink: Needed packages" href="#needed-packages"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">apt (tested on ubuntu 22.04)</h4><a id="user-content-apt-tested-on-ubuntu-2204" aria-label="Permalink: apt (tested on ubuntu 22.04)" href="#apt-tested-on-ubuntu-2204"></a></p>
<p dir="auto"><code># apt install build-essential git ninja-build texinfo bison flex libgmp-dev libmpfr-dev libmpc-dev parted qemu-system-x86 cpu-checker</code></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">pacman</h4><a id="user-content-pacman" aria-label="Permalink: pacman" href="#pacman"></a></p>
<p dir="auto"><code># pacman -S --needed base-devel git wget cmake ninja parted qemu-system-x86</code></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Compilation</h3><a id="user-content-compilation" aria-label="Permalink: Compilation" href="#compilation"></a></p>
<p dir="auto">To build the toolchain for this os. You can run the following command.</p>
<blockquote>
<p dir="auto"><em><strong>NOTE:</strong></em> The following step has to be done only once. This might take a long time since we are compiling binutils and gcc.</p>
</blockquote>

<p dir="auto">To build the os itself you can run one of the following commands. You will need root access for disk image creation/modification.</p>
<div dir="auto" data-snippet-clipboard-copy-content="./bos qemu
./bos qemu-nographic
./bos qemu-debug
./bos bochs"><pre>./bos qemu
./bos qemu-nographic
./bos qemu-debug
./bos bochs</pre></div>
<p dir="auto">You can also build the kernel or disk image without running it:</p>

<p dir="auto">To build for other architectures set environment variable BANAN_ARCH=<em>arch</em> (e.g. BANAN_ARCH=i686).</p>
<p dir="auto">To change the bootloader you can set environment variable BANAN_BOOTLOADER; supported values are BANAN (my custom bootloader) and GRUB.</p>
<p dir="auto">To run with UEFI set environment variable BANAN_UEFI_BOOT=1. You will also have to set OVMF_PATH to the correct OVMF (default <em>/usr/share/ovmf/x64/OVMF.fd</em>).</p>
<p dir="auto">If you have corrupted your disk image or want to create new one, you can either manually delete <em>build/banan-os.img</em> and build system will automatically create you a new one or you can run the following command.</p>

<p dir="auto">I have also created shell completion script for zsh. You can either copy the file in <em>script/shell-completion/zsh/_bos</em> to <em>/usr/share/zsh/site-functions/</em> or add the <em>script/shell-completion/zsh</em> to your fpath in <em>.zshrc</em>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">As the upstream is hosted on my server <a href="https://git.bananymous.com/Bananymous/banan-os" rel="nofollow">https://git.bananymous.com/Bananymous/banan-os</a>, merging contributions is not as trivial as it would be on GitHub. You can still send PRs in GitHub in which case I should be able to download the diff and apply it manually. If you want, I can also provide you an account to my git server. In this case please contact me (<a href="mailto:oskari.alaranta@bananymous.com">email</a>, <a href="https://discord.gg/ehjGySwYdK" rel="nofollow">discord</a>).</p>
<p dir="auto">As this is mostly a learning experience for me, I would appreciate if you first contacted me about adding new features (email, discord, issue, ...). If you send a PR about something I was planning on doing myself and you didn't ask me, I will probably just close it. Bug fixes are always welcome!</p>
<p dir="auto">Commit message should be formatted followingly</p>
<ol dir="auto">
<li>First line is of the form "<em>Subject: Description</em>", where <em>Subject</em> tells the area touched (Kernel, Shell, BuildSystem, ...) and <em>Description</em> is brief description of the change done. First line should fit fully in 72 characters.</li>
<li>Body of the message should further describe the change and reasoning behind the change.</li>
</ol>
<p dir="auto">All commits should pass the pre-commit hook defined in <em>.pre-commit-config.yaml</em>. For instructions on how to setup pre-commit, please see <a href="https://pre-commit.com/#install" rel="nofollow">https://pre-commit.com/#install</a>.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[React 19 (205 pts)]]></title>
            <link>https://github.com/facebook/react/blob/main/CHANGELOG.md</link>
            <guid>42331207</guid>
            <pubDate>Thu, 05 Dec 2024 18:50:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/facebook/react/blob/main/CHANGELOG.md">https://github.com/facebook/react/blob/main/CHANGELOG.md</a>, See on <a href="https://news.ycombinator.com/item?id=42331207">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <nav aria-label="Global">
            <ul>
                <li>
      
      <div>
                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_copilot&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_copilot_link_product_navbar&quot;}" href="https://github.com/features/copilot">
      
      <div>
        <p>GitHub Copilot</p><p>
        Write better code with AI
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;security&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;security_link_product_navbar&quot;}" href="https://github.com/features/security">
      
      <div>
        <p>Security</p><p>
        Find and fix vulnerabilities
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;actions&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;actions_link_product_navbar&quot;}" href="https://github.com/features/actions">
      
      <div>
        <p>Actions</p><p>
        Automate any workflow
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;codespaces&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;codespaces_link_product_navbar&quot;}" href="https://github.com/features/codespaces">
      
      <div>
        <p>Codespaces</p><p>
        Instant dev environments
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;issues&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;issues_link_product_navbar&quot;}" href="https://github.com/features/issues">
      
      <div>
        <p>Issues</p><p>
        Plan and track work
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;code_review&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;code_review_link_product_navbar&quot;}" href="https://github.com/features/code-review">
      
      <div>
        <p>Code Review</p><p>
        Manage code changes
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;discussions&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;discussions_link_product_navbar&quot;}" href="https://github.com/features/discussions">
      
      <div>
        <p>Discussions</p><p>
        Collaborate outside of code
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;code_search&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;code_search_link_product_navbar&quot;}" href="https://github.com/features/code-search">
      
      <div>
        <p>Code Search</p><p>
        Find more, search less
      </p></div>

    
</a></li>

                </ul>
              </div>
</li>

                  <li>
      
      
</li>

                  <li>
      
      <div>
                    <p><span id="resources-explore-heading">Explore</span></p><ul aria-labelledby="resources-explore-heading">
                    <li>
  <a target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;learning_pathways&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;learning_pathways_link_resources_navbar&quot;}" href="https://resources.github.com/learn/pathways">
      Learning Pathways

    
</a></li>

                    <li>
  <a target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;white_papers_ebooks_webinars&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;white_papers_ebooks_webinars_link_resources_navbar&quot;}" href="https://resources.github.com/">
      White papers, Ebooks, Webinars

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;customer_stories&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;customer_stories_link_resources_navbar&quot;}" href="https://github.com/customer-stories">
      Customer Stories

    
</a></li>

                    <li>
  <a target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;partners&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;partners_link_resources_navbar&quot;}" href="https://partner.github.com/">
      Partners

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;executive_insights&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;executive_insights_link_resources_navbar&quot;}" href="https://github.com/solutions/executive-insights">
      Executive Insights

    
</a></li>

                </ul>
              </div>
</li>


                <li>
      
      <div>
              <div>
                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_sponsors&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_sponsors_link_open_source_navbar&quot;}" href="https://github.com/sponsors">
      
      <div>
        <p>GitHub Sponsors</p><p>
        Fund open source developers
      </p></div>

    
</a></li>

                </ul>
              </div>
              <div>
                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;the_readme_project&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;the_readme_project_link_open_source_navbar&quot;}" href="https://github.com/readme">
      
      <div>
        <p>The ReadME Project</p><p>
        GitHub community articles
      </p></div>

    
</a></li>

                </ul>
              </div>
              
          </div>
</li>


                <li>
      
      <div>
                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;enterprise_platform&quot;,&quot;context&quot;:&quot;enterprise&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;enterprise_platform_link_enterprise_navbar&quot;}" href="https://github.com/enterprise">
      
      <div>
        <p>Enterprise platform</p><p>
        AI-powered developer platform
      </p></div>

    
</a></li>

                </ul>
              </div>
</li>


                <li>
    <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;pricing&quot;,&quot;context&quot;:&quot;global&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;pricing_link_global_navbar&quot;}" href="https://github.com/pricing">Pricing</a>
</li>

            </ul>
          </nav>

        <div>
                


<qbsearch-input data-scope="repo:facebook/react" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="BonVFaG1dEZGYfWO9secTE3x_2uJRZVgY3gSA-PvcrRT5NuWVstBtTuHoALM5FeXvvYCI1bJaOF0y39O3Pwx5A" data-max-custom-scopes="10" data-header-redesign-enabled="false" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="facebook/react" data-current-org="facebook" data-current-owner="" data-logged-in="false" data-copilot-chat-enabled="false" data-nl-search-enabled="false" data-retain-scroll-position="true">
  <div data-modal-dialog-overlay="" data-action="click:qbsearch-input#searchInputContainerClicked">
  <modal-dialog data-action="close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose" data-target="qbsearch-input.searchSuggestionsDialog" role="dialog" id="search-suggestions-dialog" aria-modal="true" aria-labelledby="search-suggestions-dialog-header" data-view-component="true">
      <h2 id="search-suggestions-dialog-header">Search code, repositories, users, issues, pull requests...</h2>
    
</modal-dialog></div>
  
  <div>
    
<dialog-helper>
  <dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="feedback-dialog" aria-modal="true" aria-labelledby="feedback-dialog-title" aria-describedby="feedback-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="feedback-dialog-title">
        Provide feedback
      </h2>
        
    </p>
    
  </div>
      <scrollable-region data-labelled-by="feedback-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>

    <custom-scopes data-target="qbsearch-input.customScopesManager">
    
<dialog-helper>
  <dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="custom-scopes-dialog" aria-modal="true" aria-labelledby="custom-scopes-dialog-title" aria-describedby="custom-scopes-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="custom-scopes-dialog-title">
        Saved searches
      </h2>
        <h2 id="custom-scopes-dialog-description">Use saved searches to filter your results more quickly</h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="custom-scopes-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>
    </custom-scopes>
  </div>
</qbsearch-input>

            

              <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fblob%2Fshow&amp;source=header-repo&amp;source_repo=facebook%2Freact" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/facebook/react/blob/main/CHANGELOG.md&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="b4e1dc55364ac120a10f382cc1ccb131c0ef823b772b57cf4d1e41e25196d6a2" data-analytics-event="{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/<user-name>/<repo-name>/blob/show;ref_cta:Sign up;ref_loc:header logged out&quot;}">
                Sign up
              </a>
          
        </p></div>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ChatGPT Pro (463 pts)]]></title>
            <link>https://openai.com/index/introducing-chatgpt-pro/</link>
            <guid>42330732</guid>
            <pubDate>Thu, 05 Dec 2024 18:09:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://openai.com/index/introducing-chatgpt-pro/">https://openai.com/index/introducing-chatgpt-pro/</a>, See on <a href="https://news.ycombinator.com/item?id=42330732">Hacker News</a></p>
Couldn't get https://openai.com/index/introducing-chatgpt-pro/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[OpenAI o1 system card (320 pts)]]></title>
            <link>https://openai.com/index/openai-o1-system-card/</link>
            <guid>42330666</guid>
            <pubDate>Thu, 05 Dec 2024 18:03:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://openai.com/index/openai-o1-system-card/">https://openai.com/index/openai-o1-system-card/</a>, See on <a href="https://news.ycombinator.com/item?id=42330666">Hacker News</a></p>
Couldn't get https://openai.com/index/openai-o1-system-card/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[PaliGemma 2: Powerful Vision-Language Models, Simple Fine-Tuning (132 pts)]]></title>
            <link>https://developers.googleblog.com/en/introducing-paligemma-2-powerful-vision-language-models-simple-fine-tuning/</link>
            <guid>42330491</guid>
            <pubDate>Thu, 05 Dec 2024 17:46:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://developers.googleblog.com/en/introducing-paligemma-2-powerful-vision-language-models-simple-fine-tuning/">https://developers.googleblog.com/en/introducing-paligemma-2-powerful-vision-language-models-simple-fine-tuning/</a>, See on <a href="https://news.ycombinator.com/item?id=42330491">Hacker News</a></p>
Couldn't get https://developers.googleblog.com/en/introducing-paligemma-2-powerful-vision-language-models-simple-fine-tuning/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Boeing plea deal over fatal 737 MAX crashes rejected by judge (120 pts)]]></title>
            <link>https://www.bloomberg.com/news/articles/2024-12-05/boeing-plea-deal-over-fatal-737-max-crashes-rejected-by-judge</link>
            <guid>42330454</guid>
            <pubDate>Thu, 05 Dec 2024 17:43:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bloomberg.com/news/articles/2024-12-05/boeing-plea-deal-over-fatal-737-max-crashes-rejected-by-judge">https://www.bloomberg.com/news/articles/2024-12-05/boeing-plea-deal-over-fatal-737-max-crashes-rejected-by-judge</a>, See on <a href="https://news.ycombinator.com/item?id=42330454">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
    <section>
        <h3>Why did this happen?</h3>
        <p>Please make sure your browser supports JavaScript and cookies and that you are not
            blocking them from loading.
            For more information you can review our <a href="https://www.bloomberg.com/notices/tos">Terms of
                Service</a> and <a href="https://www.bloomberg.com/notices/tos">Cookie Policy</a>.</p>
    </section>
    <section>
        <h3>Need Help?</h3>
        <p>For inquiries related to this message please <a href="https://www.bloomberg.com/feedback">contact
            our support team</a> and provide the reference ID below.</p>
        <p>Block reference ID:</p>
    </section>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[An Interview with Bill Watterson (1987) (103 pts)]]></title>
            <link>http://timhulsizer.com/cwords/chonk.html</link>
            <guid>42330086</guid>
            <pubDate>Thu, 05 Dec 2024 17:05:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://timhulsizer.com/cwords/chonk.html">http://timhulsizer.com/cwords/chonk.html</a>, See on <a href="https://news.ycombinator.com/item?id=42330086">Hacker News</a></p>
<div id="readability-page-1" class="page">

<b>
</b><center><b>

<hr></b>


<h3>The creator of <i>Calvin and Hobbes</i>
<p>on cartooning, syndicates, <i>Garfield</i>, Charles Schulz, and 
 editors.<br></p></h3>
</center>

<i>When</i> Calvin and Hobbes <i>hit the nation's funny pages in 
 late 1985, it took everybody by surprise. A literate comic 
 strip? By a guy who can draw? About a kid who acts like a real 
 kid? And it's funny? And it's from a major syndicate!? The 
 cognoscenti of the graphic narrative form thought they'd died 
 and gone to comic strip heaven.

</i><p><i>But its true. Against heavy odds, one man with a lot of 
 determination and a fierce sense of his craft may have 
 single-handedly given the strips a new lease on their artistic 
 life. It's been a struggle, but Bill Watterson, like his 
 creation, is the real thing at last.</i>

</p><p>
<b>Andrew Christie:</b> Let's start with the basics: when, where, 
 why, and how?

</p><p>
<b>Bill Watterson:</b> Well, I don't know how far back you want 
 to go; I've been interested in cartooning all my life. I read 
 the comics as a kid, and I did cartoons for high school 
 publications -- the newspaper and yearbook and such. In college, 
 I got interested in political cartooning and did political 
 cartoons every week for four years at Kenyon College in Gambier, 
 Ohio, and majored in political science there.

</p><p>
<b>Christie:</b> All in Ohio?

</p><p>
<b>Watterson:</b> Yes. I grew up in Chagrin Falls, Ohio.

</p><p>
<b>Christie:</b> What kind of time frame are we talking about?

</p><p>
<b>Watterson:</b> I was born in 1958; we moved to Chagrin when I 
 was 6, so from the first grade on, really. My whole childhood was 
 in Chagrin Falls. Right after I graduated from Kenyon, I was 
 offered a job at the <i>Cincinnati Post</i> as their editorial 
 cartoonist in a trial six month arrangement. The agreement was 
 that they could fire me or I could quit with no questions asked 
 if things didn't work out during the first few months. Sure 
 enough, things didn't work out, and they fired me, no questions 
 asked.

</p><p>
<b>Christie:</b> What was the problem?

</p><p>
<b>Watterson:</b> To this day, I'm not completely sure. My guess 
 is that the editor wanted his own Jeff MacNelly (a Pulitzer 
 winner at 24), and I didn't live up to his expectations. My 
 Cincinnati days were pretty Kafkaesque. I had lived there all 
 of two weeks, and the editor insisted that most of my work be 
 about local, as opposed to national, issues. Cincinnati has a 
 weird, three-party, city manager-government, and by the time I 
 figured it out, I was standing in the unemployment lines. I didn't 
 hit the ground running. Cincinnati at that time was also beginning 
 to realize it had major cartooning talent in Jim Borgman, at the 
 city's other paper, and I didn't benefit from the comparison.

</p><p>
<b>Christie:</b> I'm not familiar...

</p><p>
<b>Watterson:</b> He's syndicated through King Features, and had 
 been for a couple years by the time I arrived in Cincinnati. This 
 is an odd story. Borgman graduated from Kenyon College the year 
 before I went there, and it was his example that inspired me to 
 pursue political cartooning. He had drawn cartoons at Kenyon, and 
 landed his job at the <i>Cincinnati Enquirer</i> right after 
 graduation. His footsteps seemed like good ones to follow, so I 
 cultivated an interest in politics, and Borgman helped me a lot in 
 learning how to construct an editorial cartoon. Neither of us 
 dreamed I'd end up in the same town on the opposite paper. I don't 
 know to what extent the comparison played a role in my editor's 
 not liking my work, but I was very intimidated by working on a 
 major city paper and I didn't feel free to experiment, really, or 
 to travel down my own path. I very early caught on that the editor 
 had something specific in mind that he was looking for, and I tried 
 to accommodate him in order to get published. His idea was that he 
 was going to publish only my very best work so that I wouldn't 
 embarress the newspaper while I learned the ropes. As sound as 
 that idea may be from the management standpoint, it was 
 disastrous for me because I was only getting a couple cartoons 
 a week printed.  I would turn out rough idea after rough idea, and 
 he would veto eighty percent of them. As a result I lost all 
 my self-confidence, and his intervention was really unhealthy, I 
 think, as far as letting me experiment and make mistakes, and 
 become a stronger cartoonist for it. Obviously, if he wanted a 
 more experienced cartoonist, he shouldn't have hired a kid just 
 out of college. I pretty much prostituted myself for six months 
 but I couldn't please him, so he sent me packing.

</p><p>
<b>Christie:</b> Well, it was mercifully brief, then.

</p><p>
<b>Watterson:</b> Yeah, in a way it was; and actually, I think the 
 experience-- now, in hindsight -- was probably a good thing. It 
 forced me to consider how interested I was in political cartooning. 
 After I was fired, I applied to other papers but political 
 cartooning, like all cartooning, is a very tough field to break 
 into. Newspapers are very reluctant to hire their own cartoonists 
 when they can get Oliphant or MacNelly through syndication for a 
 twentieth of the price.

</p><p>
So I wasn't having any luck getting accepted anyway and it forced 
 me to re-examine what it was that I really wanted to do. In my 
 experience in political cartooning, I was never one of those 
 people who reads the headlines and foams at the mouth with rabid 
 opinion that I've just got to get down on paper. I'm interested 
 in the issues but...I don't know...I guess I just don't have the 
 killer instinct that I think makes a great political cartoonist. 
 I'd always enjoyed the comics more, and felt that as long as I 
 was unemployed it would be a good chance to pursue that and see 
 what response I could get from a syndicate, as I didn't have 
 anything to lose at that point. So I drew up a comic strip -- this 
 was in 1980 -- and sent it off and got rejected. I continued that 
 for five years with different comic strip examples 'til 
 finally <i>Calvin and Hobbes</i> came together. But it's been a 
 long road.

</p><p>
<b>Christie:</b> Were you submitting different strips to different 
 syndicates, or did you go after one syndicate?

</p><p>
<b>Watterson:</b> I didn't know a lot then -- and don't know a lot 
 now -- as to what the best way to do this is, but my procedure 
 was I would draw up the submission -- a month's worth of strips, 
 made to look as professional as I could, and send copies to the 
 five major syndicates, and then just sit around and wait for 
 their rejection letters. I would then try to see if I could 
 second guess them or imagine what they were looking for that 
 I could put in my next submission and gradually get a more 
 marketable comic strip. In hindsight, as I say, I'm not convinced 
 that that's the best way to go about it. Trying to please the 
 syndicates was pretty much the same as what I had ended up doing 
 at the <i>Cincinnati Post</i>, and I don't think that's the way 
 to draw your best material. You should stick with what you enjoy, 
 what you find funny -- that's the humor that will be the strongest, 
 and that will transmit itself. Rather then trying to find out what 
 the latest trend is, you should draw what is personally interesting.

</p><p>
<b>Christie:</b> So after five years you just quit doing what you'd 
 been doing and did what you wanted to do?

</p><p>
<b>Watterson:</b> It was a slow process, and actually what happened 
 is another odd coincidence. One of the strips I'd sent had 
 Calvin and Hobbes as minor characters. Calvin was the little 
 brother of the strip's main character, and Hobbes was like he is 
 now, a stuffed tiger that came to life in Calvin's imagination. 
 One of the syndicates suggested that these two characters were the 
 strongest and why didn't I develop a strip around them? I had 
 thought they were the funniest characters myself, but I was 
 unsure as to whether they could hold their own strip. I was afraid 
 that maybe the key to their wackiness was the contrast between 
 them and the more normal characters in the rest of the strip. I 
 wasn't sure Calvin and Hobbes would be able to maintain that 
 intensity on their own. But I tried it, and almost immediately it 
 clicked in my mind; it became much easier to write material. Their 
 personalities expanded easily, and that takes a good 75 percent of 
 the work out of it. If you have the personalities down, you 
 understand them and identify with them; you can stick them in any 
 situation and have a pretty good idea of how they're going to 
 respond. Then it's just a matter of sanding and polishing up the 
 jokes. But if you've got more ambiguous characters or stock 
 stereotypes, the plastic comes through and they don't work as 
 well. These two characters clicked for me almost immediately and 
 I feel very comfortable working with them. That syndicate, oddly 
 enough, declined my strip, so I started sending it around. 
 Universal expressed an interest in it and wanted to see more work, 
 so I drew another month's worth of art, sent that to them, and 
 they decided to take it.

</p><p>
<b>Christie:</b>That's rather ironic: The syndicate that suggested 
 you bring out those two characters rejected the strip?

</p><p>
<b>Watterson:</b> Yeah.

</p><p>
<b>Christie:</b> Who was this?

</p><p>
<b>Watterson:</b> Well, if you want to rub their noses in it, it 
 was United Features. I was sort of mystified when they rejected 
 the strip. They had given me a development contract, which meant 
 I was to work exclusively with them and rather than completing 
 everything on my own and turning it in to them and having it 
 rejected or accepted, I was working much more directly with the 
 syndicate, turning in smaller batches much more frequently, and 
 getting comments on them. The idea was that they would help me 
 develop the strip and then, assuming that they liked it, it would 
 flow into a normal contract for syndication. I'm not sure exactly 
 what happened; I gather that the sales staff didn't have much 
 enthusiasm for it, I don't know--but apparently they couldn't 
 convince enough people there in high places.

</p><p>
<b>Christie:</b> I would guess, and I don't know if you share this 
 opinion, but there is probably considerable resistance to a strip 
 that doesn't have a lot of immediate, apparent marketing 
 potential.

</p><p>
<b>Watterson:</b> I think United really looks for the marketing 
 more than some of the other syndicates, and they saw Hobbes as 
 having marketing potential, so I don't think that was it. I was 
 later offered the chance to incorporate Robotman into my strip. 
 There they had envisioned a character as a product--toylines, 
 television show, everything--and they wanted a strip written 
 around the character. They thought that maybe I could stick it 
 in my strip, working with Calvin's imagination or something. They 
 didn't really care too how much I did it, just so long as the 
 character remained intact and would be a very major character...And 
 I turned them down. It really went against my idea of what a comic 
 strip should be. I'm not interested in slamming United Features 
 here. Keep in mind that at the time, it was the only syndicate 
 that had expressed any interest in my work. I remain grateful 
 for their early attention. But there's a professional issue here. 
 They told me that if I was to insert Robotman into my strip, they 
 would reconsider it, and because the licensing was already in 
 production, my strip would stand a better chance of being 
 accepted. Not knowing if <i>Calvin and Hobbes</i> would ever go 
 anywhere, it was difficult to turn down another chance at 
 syndication. But I really recoiled at the idea of drawing 
 somebody else's character. It's cartooning by committee, and I 
 have a moral problem with that. It's not art then.

</p><p>
<b>Christie:</b> I've never heard of anything like that before.

</p><p>
<b>Watterson:</b> Yea, well, I think it's really a crass way to 
 go about it--the Saturday morning cartoons do that now, where they 
 develop the toy and then draw the cartoon around it, and the 
 result is the cartoon is a commercial for the toy and the toy is 
 a commercial for the cartoon. The same thing's happening now in 
 comic strips; it's just another way to get the competitive edge. 
 You saturate all the different markets and allow each other to 
 advertise the other, and it's the best of all possible worlds. 
 You can see the financial incentive to work that way. I just think 
 it's to the detriment of integrity in comic strip art.

</p><p>
<b>Christie:</b> It may be good business but it would be unfortunate 
 to see that catch on.

</p><p>
<b>Watterson:</b> Yeah, I don't have a lot of respect for that.

</p><p>
<b>Christie:</b> Well, enough of this depressing stuff; let's talk 
 about <i>Calvin and Hobbes</i>.

</p><p>
<b>Watterson:</b> Okay.

</p><p>
<b>Christie:</b> Is there a Calvin?

</p><p>
<b>Watterson:</b> A real one? No.

</p><p>
<b>Christie:</b> Is he in some way autobiographical?

</p><p>
<b>Watterson:</b> Not really. Hobbes might be a little closer to 
 me in terms of personality, with Calvin being more energetic, 
 brash, always looking for life on the edge. He lives entirely 
 in the present, and whatever he can do to make that moment more 
 exciting he'll just let fly...and I'm really not like that at all.

</p><p>
<b>Christie:</b> You manage a lot of complex shifts between fantasy 
 and reality; between Hobbes as a stuffed tiger and a real-life 
 playmate. He's frequently involved in what is apparently the real 
 world, doing real things together with Calvin that he couldn't 
 possibly be doing. Do you think that kind of thing out in advance 
 or does it just come to you when the gag calls for it?

</p><p>
<b>Watterson:</b> Could you name something specifically? I'm not 
 sure I follow.

</p><p>
<b>Christie:</b> Well, when they're driving down the mountain in 
 their wagon and flying all over the place. You think, after 
 reading the first few strips, that you've got the idea; that this 
 is a stuffed tiger and when he and Calvin are alone he becomes 
 real--to Calvin--but then, obviously, when they're doing things 
 like that in the real world, he has to be more than fantasy.

</p><p>
<b>Watterson:</b> Yeah, it's a strange metamorphosis. I hate to 
 subject it to too much analysis, but one thing I have fun with is 
 the rarity of things being shown from an adult's perspective. When 
 Hobbes is a stuffed toy in one panel and alive in the next, I'm 
 juxtaposing the "grown-up" version of reality with Calvin's 
 version, and inviting the reader to decide which is truer. Most 
 of the time, the strip is drawn simply from Calvin's perspective, 
 and Hobbes is as real as anyone. So when Calvin is careening down 
 the hillside, I don't feel compelled to insert reminders that 
 Hobbes is a stuffed toy. I try to get the reader completely swept 
 up into Calvin's world by ignoring adult perspective. Hobbes, 
 therefore, isn't just a cute gimmick. I'm not making the strip 
 revolve around the transformation. The viewpoint of the strip 
 fluctuates, and this allows Hobbes to be a "real" character.

</p><p>
<b>Christie:</b> It has a lunatic internal consistency.

</p><p>
<b>Watterson:</b> Yeah, I guess that's the best way of putting it.

</p><p>
<b>Christie:</b> Are you familiar with <i>Krazy Kat</i>?

</p><p>
<b>Watterson:</b> Yes! I love it; I wish I thought that that kind 
 of work were possible today.

</p><p>
<b>Christie:</b> Well, it sounds like it is. George Herriman didn't 
 need to justify his reality, either.

</p><p>
<b>Watterson:</b> Yeah, I agree on that point. I mean the bizarre 
 dialect, the constantly changing backgrounds...In the first place, 
 I don't know who would put enough energy into their work anymore 
 to do something like that; secondly, and probably more 
 importantly, comic strips are being printed at such a ridiculous 
 size that elimination of dialogue and linework is almost a 
 necessity and you just can't get that kind of depth. I think 
 of <i>Pogo</i>, another strip that had tremendous dialogue and 
 fantastic backgrounds...Those strips were just complete worlds 
 that the reader would be sucked into. For a few moments a day we 
 could live in Coconino County; the whole thing was entirely there. 
 The dialogue was part of it, the backgrounds were part of it, the 
 characters were off-beat...and you need a little space and time 
 to develop that sort of thing. I know for a fact that nobody's 
 doing it now and I don't know that anybody will do it. Garry 
 Trudeau is the only cartoonist with the clout to get his strip 
 published large enough to accomodate extended dialogue. It's a 
 shame.

</p><p>
<b>Christie:</b> Well, let's talk about your peers for a bit.

</p><p>
<b>Watterson:</b> You're gonna get me in trouble.

</p><p>
<b>Christie:</b> No, no; you can say anything you want.

</p><p>
<b>Watterson:</b> Yeah, that's what's going to get me into trouble.

</p><p>
<b>Christie:</b> What about Gary Larson?

</p><p>
<b>Watterson:</b> I really like the lunacy of <i>The Far Side</i>. 
 It's a one-panel strip so it's a slightly different animal than a 
 four-panel strip like mine. I don't really compare one-panel 
 strips to four-panels strips because there are different 
 opportunities with each. Larson's working with one picture and a 
 handful of words, and given that, I think he's one of the most 
 inventive guys in comics. The four-panel strip has more potential 
 for storyline and character involvement than just a single panel. 
 But I do enjoy his stuff alot.

</p><p>
<b>Christie:</b> What about Jim Davis?

</p><p>
<b>Watterson:</b> Uh...<i>Garfield</i> 
 is...(long pause)...consistent.

</p><p>
<b>Christie:</b> Ooo-kay...

</p><p>
<b>Watterson:</b> <i>U.S. Acres</i> I think is an abomination.

</p><p>
<b>Christie:</b> Never seen it.

</p><p>
<b>Watterson:</b> Lucky you. Jim Davis has his factory in Indiana 
 cranking out this strip about a pig on a farm. I find it an insult 
 to the intelligence, though it's very successful.

</p><p>
<b>Christie:</b> Most insults to the intelligence are. Well, how 
 about the old school, are they holding up their end at all? Johnny 
 Hart? Charles Schulz...?

</p><p>
<b>Watterson:</b> That's an interesting question. I have a 
 tremendous amount of respect for <i>Peanuts</i>. Every now and 
 then I hear that <i>Peanuts</i> isn't as funny as it was or it's 
 gotten old or something like that. I think what's really happened 
 is that Schulz, in <i>Peanuts</i>, changed the entire face of 
 comic strips, and everybody has now caught up to him. I don't 
 think he's five years ahead of everybody else like he used to 
 be, so that's taken some of the edge off it. I think it's still 
 a wonderful strip in terms of solid construction, character 
 development, the fantasy element...Things that we now take for 
 granted--reading the thoughts of an animal for example--there's 
 not a cartoonist who's done anything since 1960 who doesn't owe 
 Schulz a tremendous debt. Johnny Hart; I admire the simplicity, 
 the way he's gotten that strip down to the bare essentials; there's 
 nothing extraneous in the drawing, and the humor is very spartan. 
 It doesn't grab me, though, because I look for real involvement 
 with characters, and the characters in <i>B.C.</i> are pretty much 
 interchangeable; they're props for humor. I think his style of 
 humor is mostly in words, not in the characters. I look to strips 
 like <i>Peanuts</i>, where you're really involved with the 
 characters, you feel that you know them. Iguess that's why I don't 
 enjoy <i>B.C.</i> quite as much. It's better than many, though.

</p><p>
<b>Christie:</b> A lot of golf jokes.

</p><p>
<b>Watterson:</b> Yeah, yeah. I don't know, it's hard to knock a 
 strip that bangs out a solid joke every day, but I'd like to think 
 more comic strips could be pushing the boundaries. A lot of comic 
 characters are flat and predictable, and a lot of jokes are no 
 more than stupid puns. For most readers, sure, that passes the 
 mustard, but it certainly doesn't take full advantage of a 
 remarkably versatile medium. I'd like to see cartoonists measuring 
 their work by higher standards than how many papers their strips 
 are in and how much money they make. With four panels, the 
 cartoonist has the opportunity to develop characters and 
 storylines. It can be like writing a novel in daily installments. 
 That's where the potential of the medium is, and I see very few 
 cartoonists taking advantage of it. <i>Peanuts</i> does it. 
 <i>Bloom County</i>, <i>Doonesbury</i>, and <i>For Better Or For 
 Worse</i> and others, and that's more or less it. These strips 
 have heart, and an involvement with the characters, so that they're 
 more than just props to relate a gag. We read about them and sort 
 of go through their life with them. I think that's taking the 
 strip to a deeper and more significant level. The strips I admire 
 go farther than a gag a day, and take us into a special world.

</p><p>
<b>Christie:</b> Would it be the accurate to call Charles Schulz the 
 major influence on you?

</p><p>
<b>Watterson:</b> Oh yeah. As a child, especially, 
 <i>Peanuts</i> and <i>Pogo</i> were my two biggest influences.

</p><p>
<b>Christie:</b> Did you ever see any of Percy Crosby's 
 <i>Skippy</i>?

</p><p>
<b>Watterson:</b> No, never did.

</p><p>
<b>Christie:</b> There are some interesting similarities.

</p><p>
<b>Watterson:</b> I've had a couple of people write in comparing 
 my work to <i>Barnaby</i> by Crockett Johnson, and that's another 
 strip I've never seen. Or rather, with both of those I think I've 
 seen one or two strips in anthologies, but I've never seen the 
 work at any length.

</p><p>
<b>Christie:</b> I believe Dover is reprinting two books worth of 
 <i>Barnaby</i> in the next few months. That would be worth your 
 picking up. Also <i>Harold and the Magic Crayon</i>.

</p><p>
<b>Watterson:</b> I remember that. The drawings don't interest 
 me a great deal, but I should look it up just to see what the 
 fuss is about.

</p><p>
<b>Christie:</b> Do you see yourself doing this forever?

</p><p>
<b>Watterson:</b> I'd like to, yeah, if the market will bear it.

</p><p>
<b>Christie:</b> <i>Calvin and Hobbes</i> exclusively?

</p><p>
<b>Watterson:</b> Yeah, I'm really enjoying the work. I feel that 
 the characters have a lot of potential. I'd like to have the 
 opportunity to draw this strip for years and see where it goes. 
 It's sort of a scary thing now to imagine; these cartoonists who've 
 been drawing a strip for twenty years. I can't imagine coming up 
 with that much material. If I just take it day by day, though, 
 it's a lot of fun, and I do think I have a long way to go before 
 I've exhausted the possibilities.

</p><p>
<b>Christie:</b> Do you think you'll ever need a ghost?

</p><p>
<b>Watterson:</b> No, that's against what I believe about comic 
 strips. In fact, I'd go even further and say I don't think a strip 
 should ever be continued after the death or retirement of a 
 cartoonist.

</p><p>
<b>Christie:</b> Well, you know, a lot of the very good ones used 
 assistants.

</p><p>
<b>Watterson:</b> Yeah, <i>Pogo</i> did. Schulz has a good comment 
 on that: "It's like Arnold Palmer having someone to hit his chip 
 shots." I spent five years trying to get this stupid job and now 
 that I have it I'm not going to hire it out to somebody else. The 
 whole pleasure for me is having the opportunity to do a comic 
 strip for a living, and now that I've finally got that I'm not 
 going to give it away. It also gives me complete creative control. 
 Any time somebody else has their hand in the ink it's changing 
 the product, and I enjoy the responsibility for this product. I'm 
 willing to take the blame if the strip goes down the drain, and I 
 want the credit if it succeeds. So long as it has my name on it, 
 I want it to be mine. I don't know, if you don't have that kind 
 of investment in it...I guess that's the difference between looking 
 at it as an art and looking at it as a job. I'm not interested in 
 setting up an assembly line to produce this thing more efficiently. 
 There are certainly people who could letter the strip better than 
 I do; I don't enjoy lettering very much, but that's the way I write 
 and that belongs in the strip because the strip is a reflection 
 of me. If cartoonists would look at this more as an art than as 
 a part time job or a get-rich-quick scheme, I think comics overall 
 would be better. I think there's a tremendous potential to be 
 tapped.

</p><p>
<b>Christie:</b> Speaking of creative control, do you ever have 
 a problem with an editor or the syndicate sending a strip back 
 and saying you're using big words, or you're getting political...?

</p><p>
<b>Watterson:</b> Universal is really good about that. I send in 
 roughs to the syndicate, which they okay or veto. If the rough is 
 okayed, I ink it up. I understand this arrangement will continue 
 for the first year or two while I get on my feet. Unlike the other 
 places I've worked, though, Universal seems to have some basic 
 respect for what I'm trying to do. Sometimes they'll axe a strip 
 idea I kind of liked--that's inevitable when you judge something 
 as subjective as humor--but they're not altering things, or telling 
 me what to do instead. Either a joke is okay as I have it, or it's 
 rejected, and I've never argued about a decision yet. At the other 
 syndicate, I'd hear, "this is funny, but it's too wordy," or 
 "simplify the drawings." That's interfering with the craft. And 
 if you give a little credit to the concept of the artist, I think 
 you ought to indulge excesses a bit, because that reflects the 
 personality of the writer. Now if a joke is in bad taste or it's 
 not funny, okay, that's a whole different thing, but how you craft 
 a joke is really what the writer's job is, and I don't think that 
 technique should be subject to any editorial constraints, and 
 Universal has been tremendous about that.

</p><p>
<b>Christie:</b> So you actually have to draw up more than seven 
 strips a week?

</p><p>
<b>Watterson:</b> Yeah...unless they're all really great.

</p><p>
<b>Christie:</b> How much time do you put in?

</p><p>
<b>Watterson:</b> I've never really measured it out. Obviously the 
 great thing about this job is the complete freedom of the schedule.
 So long as I meet the deadline, they don't care when I work or 
 how I work. Sometimes I work all day if I'm under a crunch; I 
 take a day off here and there if I have something else pressing 
 or if I'm just tired of what I'm doing...so I don't know, I've 
 never sat down to quantify how many hours I actually spend on 
 the strip. I use the deadlines to estimate my progress; each 
 month I know that I have to produce so many strips, and by the 
 end of the month I'll make sure that I have.

</p><p>
<b>Christie:</b> When you sit down at the drawing table, though, 
 do you do one at a time or just keep going?

</p><p>
<b>Watterson:</b> I write separately from the inking up. I'm sure 
 this varies from cartoonist to cartoonist; I find that the writing 
 is the hard part and the drawing is the fun part. I like to 
 separate the two so I can give my full attention to one or the 
 other. Writing it, I'll sit down and stare into space for an hour 
 and sometimes not come up with a single decent idea, or sometimes 
 no idea at all, and it's very tempting to go do something else or 
 just draw up a strip, but I find that if I make myself stick to 
 it for another hour I can sometimes come up with several good 
 ideas. And when I get to the drawing, I really enjoy taking a 
 big chunk of time and working on the drawing and nothing else. 
 That allows me to make sure that I'm really challenging the art, 
 making each picture as interesting as I can...stick in a close-up 
 or an odd perspective. This way, the writing doesn't distract me 
 while I'm drawing and vice versa. I can devote my full attention 
 to each.

</p><p>
<b>Christie:</b> Is that original artwork available to your 
 admirers? Say, people who interview you for prestigious national 
 magazines?

</p><p>
<b>Watterson:</b> No, I've decided not to sell or give any of it 
 out. Don't feel slighted.

</p><p>
<b>Christie:</b> No, no. I would only make such a request because 
 in my opinion, and in the opinion of just about everybody I know, 
 what you're doing is the best stuff in the papers.

</p><p>
<b>Watterson:</b> Thank you very much; it's gratifying to hear 
 that from people who care about comic art. I never know what to 
 make of it when someone writes to say, "<i>Calvin and Hobbes</i> 
 is the best strip in the paper. I like it even more than 
 <i>Nancy</i>." Ugh.

</p><p>
<b>Christie:</b> That's Andy Warhol's favorite strip.

</p><p>
<b>Watterson:</b> Oh, well, that would figure. Maybe he's the 
 nut writing me.

</p><hr>
<b>
</b><center><b>

<hr></b>


</center></div>]]></description>
        </item>
        <item>
            <title><![CDATA[7 Databases in 7 Weeks for 2025 (228 pts)]]></title>
            <link>https://matt.blwt.io/post/7-databases-in-7-weeks-for-2025/</link>
            <guid>42330055</guid>
            <pubDate>Thu, 05 Dec 2024 17:02:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://matt.blwt.io/post/7-databases-in-7-weeks-for-2025/">https://matt.blwt.io/post/7-databases-in-7-weeks-for-2025/</a>, See on <a href="https://news.ycombinator.com/item?id=42330055">Hacker News</a></p>
Couldn't get https://matt.blwt.io/post/7-databases-in-7-weeks-for-2025/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Replace "hub" by "ingest" in GitHub URLs for a prompt-friendly extract (150 pts)]]></title>
            <link>https://gitingest.com/</link>
            <guid>42329071</guid>
            <pubDate>Thu, 05 Dec 2024 15:24:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gitingest.com/">https://gitingest.com/</a>, See on <a href="https://news.ycombinator.com/item?id=42329071">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <div>
                <p>
                    <svg viewBox="0 0 91 98" fill="none" xmlns="http://www.w3.org/2000/svg">
                        <path d="m35.878 14.162 1.333-5.369 1.933 5.183c4.47 11.982 14.036 21.085 25.828 24.467l5.42 1.555-5.209 2.16c-11.332 4.697-19.806 14.826-22.888 27.237l-1.333 5.369-1.933-5.183C34.56 57.599 24.993 48.496 13.201 45.114l-5.42-1.555 5.21-2.16c11.331-4.697 19.805-14.826 22.887-27.237Z" fill="#FE4A60" stroke="#000" stroke-width="3.445"></path>
                        <path d="M79.653 5.729c-2.436 5.323-9.515 15.25-18.341 12.374m9.197 16.336c2.6-5.851 10.008-16.834 18.842-13.956m-9.738-15.07c-.374 3.787 1.076 12.078 9.869 14.943M70.61 34.6c.503-4.21-.69-13.346-9.49-16.214M14.922 65.967c1.338 5.677 6.372 16.756 15.808 15.659M18.21 95.832c-1.392-6.226-6.54-18.404-15.984-17.305m12.85-12.892c-.41 3.771-3.576 11.588-12.968 12.681M18.025 96c.367-4.21 3.453-12.905 12.854-14" stroke="#000" stroke-width="2.548" stroke-linecap="round"></path>
                    </svg>
                    <h2>
                        Prompt-friendly <br>codebase&nbsp;
                    </h2>
                    <svg viewBox="0 0 92 80" fill="none" xmlns="http://www.w3.org/2000/svg">
                        <path d="m35.213 16.953.595-5.261 2.644 4.587a35.056 35.056 0 0 0 26.432 17.33l5.261.594-4.587 2.644A35.056 35.056 0 0 0 48.23 63.28l-.595 5.26-2.644-4.587a35.056 35.056 0 0 0-26.432-17.328l-5.261-.595 4.587-2.644a35.056 35.056 0 0 0 17.329-26.433Z" fill="#5CF1A4" stroke="#000" stroke-width="2.868"></path>
                        <path d="M75.062 40.108c1.07 5.255 1.072 16.52-7.472 19.54m7.422-19.682c1.836 2.965 7.643 8.14 16.187 5.121-8.544 3.02-8.207 15.23-6.971 20.957-1.97-3.343-8.044-9.274-16.588-6.254M12.054 28.012c1.34-5.22 6.126-15.4 14.554-14.369M12.035 28.162c-.274-3.487-2.93-10.719-11.358-11.75C9.104 17.443 14.013 6.262 15.414.542c.226 3.888 2.784 11.92 11.212 12.95" stroke="#000" stroke-width="2.319" stroke-linecap="round"></path>
                    </svg>
                </p>
                <p>
                    Turn any GitHub repository into a simple text ingest of its codebase.
                    This is useful for feeding a codebase into any LLM.
                </p>
            </div>

            

            <div>
                    <p><img src="https://cdn.devdojo.com/images/january2023/shape-1.png"></p>

                    <!-- Example repositories section -->
                    <div>
                        <p>Try these example repositories:</p>
                        
                    </div>
                </div>

            
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Federal Court Says Dismantling a Phone to Install Firmware Isn't a 'Search' (243 pts)]]></title>
            <link>https://www.techdirt.com/2024/12/04/federal-court-says-dismantling-a-phone-to-install-firmware-isnt-a-search-even-if-was-done-to-facilitate-a-search/</link>
            <guid>42329005</guid>
            <pubDate>Thu, 05 Dec 2024 15:18:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.techdirt.com/2024/12/04/federal-court-says-dismantling-a-phone-to-install-firmware-isnt-a-search-even-if-was-done-to-facilitate-a-search/">https://www.techdirt.com/2024/12/04/federal-court-says-dismantling-a-phone-to-install-firmware-isnt-a-search-even-if-was-done-to-facilitate-a-search/</a>, See on <a href="https://news.ycombinator.com/item?id=42329005">Hacker News</a></p>
Couldn't get https://www.techdirt.com/2024/12/04/federal-court-says-dismantling-a-phone-to-install-firmware-isnt-a-search-even-if-was-done-to-facilitate-a-search/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Waymo announces Miami as its next ride hailing city (209 pts)]]></title>
            <link>https://waymo.com/blog/2024/12/next-stop-miami/</link>
            <guid>42328971</guid>
            <pubDate>Thu, 05 Dec 2024 15:14:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://waymo.com/blog/2024/12/next-stop-miami/">https://waymo.com/blog/2024/12/next-stop-miami/</a>, See on <a href="https://news.ycombinator.com/item?id=42328971">Hacker News</a></p>
Couldn't get https://waymo.com/blog/2024/12/next-stop-miami/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Americans React to UnitedHealthcare CEO's Murder: 'My Empathy Is Out of Network' (148 pts)]]></title>
            <link>https://gizmodo.com/bitter-americans-react-to-unitedhealthcare-ceos-murder-my-empathy-is-out-of-network-2000534520</link>
            <guid>42327272</guid>
            <pubDate>Thu, 05 Dec 2024 11:52:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gizmodo.com/bitter-americans-react-to-unitedhealthcare-ceos-murder-my-empathy-is-out-of-network-2000534520">https://gizmodo.com/bitter-americans-react-to-unitedhealthcare-ceos-murder-my-empathy-is-out-of-network-2000534520</a>, See on <a href="https://news.ycombinator.com/item?id=42327272">Hacker News</a></p>
Couldn't get https://gizmodo.com/bitter-americans-react-to-unitedhealthcare-ceos-murder-my-empathy-is-out-of-network-2000534520: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Diátaxis – A systematic approach to technical documentation authoring (463 pts)]]></title>
            <link>https://diataxis.fr/</link>
            <guid>42325011</guid>
            <pubDate>Thu, 05 Dec 2024 04:35:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://diataxis.fr/">https://diataxis.fr/</a>, See on <a href="https://news.ycombinator.com/item?id=42325011">Hacker News</a></p>
<div id="readability-page-1" class="page"><div class="page">
        <a href="#">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div>
          

          <p><label for="__toc">
            <p>Toggle table of contents sidebar</p>
            <i><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </p></div>
        <article role="main">
          <section id="diataxis">
<span id="id1"></span>

<p>A systematic approach to technical documentation authoring.</p>
<hr>
<p>Diátaxis is a way of thinking about and doing documentation.</p>
<p>It prescribes approaches to content, architecture and form that emerge from a systematic approach to understanding the needs of documentation users.</p>

<p>Diátaxis identifies four distinct needs, and four corresponding forms of documentation - <em>tutorials</em>, <em>how-to guides</em>, <em>technical reference</em> and <em>explanation</em>. It places them in a systematic relationship, and proposes that documentation should itself be organised around the structures of those needs.</p>
<img alt="Diátaxis" src="https://diataxis.fr/_images/diataxis.png">
<p>Diátaxis solves problems related to documentation <em>content</em> (what to write), <em>style</em> (how to write it) and <em>architecture</em> (how to organise it).</p>
<p>As well as serving the users of documentation, Diátaxis has value for documentation creators and maintainers. It is light-weight, easy to grasp and straightforward to apply. It doesn’t impose implementation constraints. It brings an active principle of quality to documentation that helps maintainers think effectively about their own work.</p>
<hr>
<section id="contents">
<h2>Contents<a href="#contents" title="Link to this heading">¶</a></h2>
<p>This website is divided into two main sections, to help apply and understand Diátaxis.</p>
<div>
<p><em>Start here.</em> These pages will help make immediate, concrete sense of the approach.</p>

<p>This section explores the theory and principles of Diátaxis more deeply, and sets forth the understanding of needs that underpin it.</p>

</div>
<hr>
<p>Diátaxis is proven in practice. Its principles have been adopted successfully in hundreds of documentation projects.</p>
<blockquote>
<div><p>At Gatsby we recently reorganized our open-source documentation, and the Diátaxis framework was our go-to resource
throughout the project. The four quadrants helped us prioritize the user’s goal for each type of documentation. By
restructuring our documentation around the Diátaxis framework, we made it easier for users to discover the
resources that they need when they need them.</p>
<p>—<a href="https://hachyderm.io/@meganesulli">Megan Sullivan</a></p>
</div></blockquote>
<blockquote>
<div><p>While redesigning the <a href="https://developers.cloudflare.com/">Cloudflare developer docs</a>, Diátaxis became our north star for information architecture. When we weren’t sure where a new piece of content should fit in, we’d consult the framework. Our documentation is now clearer than it’s ever been, both for readers and contributors.</p>
<p>—<a href="https://github.com/adamschwartz">Adam Schwartz</a></p>
</div></blockquote>

</section>
</section>

        </article>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bitcoin is over $100k (136 pts)]]></title>
            <link>https://www.tradingview.com/symbols/BTCUSD/</link>
            <guid>42324263</guid>
            <pubDate>Thu, 05 Dec 2024 02:41:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tradingview.com/symbols/BTCUSD/">https://www.tradingview.com/symbols/BTCUSD/</a>, See on <a href="https://news.ycombinator.com/item?id=42324263">Hacker News</a></p>
<div id="readability-page-1" class="page"><section data-query-type="media" data-props-id="fuP9Tl" id="tv-content" aria-label="Main content" tabindex="-1"><div><p><span><div><p><span><p>On December 5, Bitcoin reached $100,000, up from $90,000 on November 12. The U.S. experienced over $31 billion in net inflows from Bitcoin ETFs, raising its market cap to $2 trillion.</p></span><span><p>Bitcoin crossed the $100,000 mark, recording a 5.5% gain over a 24-hour period, with its current price at $101,345.</p></span><span><p>Bitcoin's price is influenced by short-term demand and long-term supply, with profit-taking affecting it. Analysts indicate that inflows from Bitcoin spot ETFs may drive the price closer to $100,000.</p></span></p></div></span><a href="https://www.tradingview.com/chart/?symbol=BITSTAMP%3ABTCUSD"><span>Analyze the impact</span></a><a href="https://www.tradingview.com/chart/?symbol=BITSTAMP%3ABTCUSD"><span>Analyze the impact</span></a></p></div><div data-container-name="company-info-id"><p><span>Bitcoin is the world’s most traded cryptocurrency, and represents the largest piece of the crypto market pie. It was the first digital coin and as such, remains the most famous and widely-adopted cryptocurrency in the world. It's the original gangster in whose footsteps all other coins follow. The birth of Bitcoin was the genesis of an entirely new asset class, and a huge step away from traditional, centrally controlled money. Today, many advocates believe Bitcoin will facilitate the next stage for the global financial system, although this — of course — remains to be seen.</span></p></div><div data-container-name="symbol-faq-widget-id"><div><div id="Accordion-details::Rmr:" inert=""><p>The current price of </p><!-- --><p>Bitcoin</p><!-- --><p> (</p><!-- --><p>BTC</p><!-- --><p>) is </p><!-- --><p>103,282</p><!-- -->&nbsp;<!-- --><p>USD</p><!-- --><p> — it has fallen </p><!-- --><p>−0.79</p><!-- --><p>% in the past 24 hours. Try placing this info into the context by checking out what coins are also <a href="https://www.tradingview.com/markets/cryptocurrencies/prices-gainers/">gaining</a> and <a href="https://www.tradingview.com/markets/cryptocurrencies/prices-losers/">losing</a> at the moment and seeing </p><a href="https://www.tradingview.com/chart/?symbol=BITSTAMP:BTCUSD">BTC<!-- --> price chart</a><p>.</p></div><div id="Accordion-details::R1mr:" inert=""><p>Bitcoin</p><!-- --><p> (</p><!-- --><p>BTC</p><!-- --><p>) trading volume in 24 hours is </p><!-- --><p>‪61.06 B‬</p><!-- -->&nbsp;<!-- --><p>USD</p><!-- --><p>. See how often other coins are traded in <a href="https://www.tradingview.com/markets/cryptocurrencies/prices-most-traded/">this list</a>.</p></div><div id="Accordion-details::R26r:" inert=""><p>Bitcoin</p><!-- --><p> price has risen by </p><!-- --><p>3.53</p><!-- --><p>% over the last week, its month performance shows a </p><!-- --><p>38.46</p><!-- --><p>% increase, and as for the last year, </p><!-- --><p>Bitcoin</p><!-- --><p> has increased by </p><!-- --><p>134.27</p><!-- --><p>%. See more dynamics on </p><a href="https://www.tradingview.com/chart/?symbol=BITSTAMP:BTCUSD">BTC<!-- --> price chart</a><p>. <br>Keep track of coins' changes with our <a href="https://www.tradingview.com/heatmap/crypto/?color=change&amp;dataset=Crypto&amp;group=no_group&amp;size=market_cap_calc">Crypto Coins Heatmap</a>.</p></div><div id="Accordion-details::R2mr:" inert=""><p>Bitcoin</p><!-- --><p> (</p><!-- --><p>BTC</p><!-- --><p>) reached its highest price on </p><!-- --><p>Nov 22, 2024</p><!-- --><p> — it amounted to </p><!-- --><p>99,800</p><!-- -->&nbsp;<!-- --><p>USD</p><!-- --><p>. Find more insights on the </p><a href="https://www.tradingview.com/chart/?symbol=BITSTAMP:BTCUSD">BTC<!-- --> price chart</a><p>. <br>See the list of <a href="https://www.tradingview.com/markets/cryptocurrencies/prices-gainers/">crypto gainers</a> and choose what best fits your strategy.</p></div><div id="Accordion-details::R36r:" inert=""><p>Bitcoin</p><!-- --><p> (</p><!-- --><p>BTC</p><!-- --><p>) reached the lowest price of </p><!-- --><p>2</p><!-- -->&nbsp;<!-- --><p>USD</p><!-- --><p> on </p><!-- --><p>Oct 20, 2011</p><!-- --><p>. View more </p><!-- --><p>Bitcoin</p><!-- --><p> dynamics on the <a href="https://www.tradingview.com/chart/?symbol=BITSTAMP:BTCUSD">price chart</a>. <br>See the list of <a href="https://www.tradingview.com/markets/cryptocurrencies/prices-losers/">crypto losers</a> to find unexpected opportunities.</p></div></div><div><div id="Accordion-details::R1ar:" inert=""><p>Bitcoin</p><!-- --><p> has the limit of </p><!-- --><p>‪21.00 M‬</p><!-- --><p> coins. No matter how the currency evolves, no new coins will be released after this number is reached.</p></div><div id="Accordion-details::R1qr:" inert=""><p>The safest choice when buying </p><!-- --><p>BTC</p><!-- --><p> is to go to a well-known crypto exchange. Some of the popular names are Binance, Coinbase, Kraken. But you'll have to find a reliable broker and create an account first. You can trade </p><!-- --><p>BTC</p><!-- --><p> right from TradingView charts — just <a href="https://www.tradingview.com/brokers/">choose a broker</a> and connect to your account.</p></div><div id="Accordion-details::R2ar:" inert=""><p>Crypto markets are famous for their volatility, so one should study all the available stats before adding crypto assets to their portfolio. Very often it's technical analysis that comes in handy. We prepared <a href="https://www.tradingview.com/symbols/BTCUSD/technicals/?exchange=BITSTAMP">technical ratings</a> for </p><!-- --><p>Bitcoin</p><!-- --><p> (</p><!-- --><p>BTC</p><!-- --><p>): today its technical analysis shows the buy signal, and according to the 1 week rating </p><!-- --><p>BTC</p><!-- --><p> shows the buy signal. And you'd better dig deeper and study 1 month rating too — it's strong buy. Find inspiration in </p><a href="https://www.tradingview.com/symbols/BTCUSD/ideas/?exchange=BITSTAMP">Bitcoin<!-- --> trading ideas</a><p> and keep track of what's moving crypto markets with our <a href="https://www.tradingview.com/markets/cryptocurrencies/news/">crypto news feed</a>.</p></div><div id="Accordion-details::R2qr:" inert=""><p>Bitcoin</p><!-- --><p> (</p><!-- --><p>BTC</p><!-- --><p>) is just as reliable as any other crypto asset — this corner of the world market is highly volatile. Today, for instance, </p><!-- --><p>Bitcoin</p><!-- --><p> is estimated as </p><!-- --><p>5.66</p><!-- --><p>% volatile. The only thing it means is that you must prepare and examine all available information before making a decision. And if you're not sure about </p><!-- --><p>Bitcoin</p><!-- --><p>, you can find more inspiration in our <a href="https://www.tradingview.com/sparks/crypto/">curated watchlists</a>.</p></div><div id="Accordion-details::R3ar:" inert=""><p>You can discuss </p><!-- --><p>Bitcoin</p><!-- --><p> (</p><!-- --><p>BTC</p><!-- --><p>) with other users in our public chats, Minds or in the comments to <a href="https://www.tradingview.com/symbols/BTCUSD/ideas/?exchange=BITSTAMP">Ideas</a>.</p></div></div></div></section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[VectorChord: Store 400k Vectors for $1 in PostgreSQL (152 pts)]]></title>
            <link>https://blog.pgvecto.rs/vectorchord-store-400k-vectors-for-1-in-postgresql</link>
            <guid>42324059</guid>
            <pubDate>Thu, 05 Dec 2024 02:01:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.pgvecto.rs/vectorchord-store-400k-vectors-for-1-in-postgresql">https://blog.pgvecto.rs/vectorchord-store-400k-vectors-for-1-in-postgresql</a>, See on <a href="https://news.ycombinator.com/item?id=42324059">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-content-parent"><p>We’re pleased to announce our new vector search extension for PostgreSQL, providing a highly cost-effective way to manage large vectors. Using <a target="_blank" href="https://github.com/tensorchord/VectorChord">VectorChord</a>, you can achieve a QPS of 131 with 0.95 precision on 100 million 768-dimensional vectors for the top 10 queries. This setup costs only $250 monthly and can be hosted on a single machine.</p>
<p>This means you can <strong>store 400k vectors for only $1</strong>, allowing you to save significantly: 6x more vectors compared to Pinecone (storage optimized instance) and 26x more than pgvector/<a href="http://pgvecto.rs/" target="_blank">pgvecto.rs</a> for the same price.</p>
<p><img data-zoomable="true" loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1733194327962/8b0f2610-af64-4104-98db-7f94416f354e.png?auto=compress,format&amp;format=webp" alt=""></p>
<p>In the monthly cost comparison for storing vectors, based on <a target="_blank" href="https://myscale.github.io/benchmark/#/">MyScale benchmark data</a>, the chart highlights how <a target="_blank" href="https://github.com/tensorchord/VectorChord">VectorChord</a> emerges as an affordable option, priced at just $247 for storing 100 million vectors. In contrast, Pinecone, despite its optimized storage, costs $1,600 per month, while Qdrant is priced at $4,374. pgvector/<a target="_blank" href="http://pgvecto.rs/">pgvecto.rs</a> has a considerably higher cost of $6,580.</p>
<p><img data-zoomable="true" loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1733194599461/eb1cf21d-4eb0-4427-8b39-bbb96d125182.png?auto=compress,format&amp;format=webp" alt=""></p>


<h2 id="heading-hnsws-problem">HNSW’s problem</h2>
<p>As the successor to <a href="http://pgvecto.rs/" target="_blank">pgvecto.rs</a>, VectorChord has gained valuable insights from its predecessor. While many vector databases or extensions (including <a href="http://pgvecto.rs/" target="_blank">pgvecto.rs</a>) perform well with datasets of around 1 million, they often struggle when scaling up to larger sizes, such as from 10 million to 100 million. Traditional HNSW-based vector databases face specific challenges with larger datasets:</p>
<ul>
<li><p><strong>Long index build time:</strong> It typically takes over 2 hours to build an index for 5 million records.</p>
</li>
<li><p><strong>High memory requirements:</strong> Storing a dataset of 10 million vectors can require as much as 40GB of memory.</p>
</li>
</ul>
<h2 id="heading-vectorchords-solution-disk-friendly-ivfrabitq">VectorChord’s solution: Disk-friendly IVF+RabitQ</h2>
<p>VectorChord employs IVF (Inverted File Index) along with <a target="_blank" href="https://arxiv.org/pdf/2405.12497">RaBitQ</a>[1] quantization to provide fast, scalable, and accurate vector search capabilities. This method <strong>compresses 32-bit vectors into compact bit representations</strong>, significantly reducing computation demands. Most comparisons are conducted using these compressed vectors, while full-precision calculations are reserved for an adaptive reranking phase applied to a smaller subset, ensuring both speed and recall are preserved.</p>
<p>Many people think that IVF has a less favorable recall/speed tradeoff than HNSW and involves many configurations for optimization. However, it's a complex issue, and we’ll explain it briefly now, with a detailed post on the topic coming later.</p>
<h3 id="heading-ivf-vs-hnsw">IVF vs HNSW</h3>
<p>A significant portion of the time taken by vector search algorithms is dedicated to distance computation. To enhance speed, it's essential to minimize distance comparisons as much as possible. The original IVF struggles in this area, usually necessitating a scan of 1% to 5% of the total vectors, which is considerably higher than what HNSW requires.</p>
<p>However, RabitQ presents an innovative approach that allows for the compression of a 32-bit vector into just 1 bit. While this compression results in some loss of precision, it greatly reduces computational requirements. With the fast scan optimization, we can achieve calculations that are <strong>over 100 times faster than traditional vector distance computations</strong>.</p>
<p>You might wonder about the recall. We can rerank additional vectors to enhance the recall rate, and full precision distance computation is only necessary during the reranking phase. RaBitQ guarantees a sharp theoretical error bound and provides good empirical accuracy at the same time. This is why IVF can be faster than HNSW.</p>
<p>Here are some initial benchmark results for the GIST dataset, which consists of 1 million vectors in 960 dimensions. With equivalent recall, VectorChord's QPS could be twice that of pgvector. More details will be provided in the Benchmark section.</p>
<p><img data-zoomable="true" loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1733288263095/3f2dcc75-a3e9-4d86-9515-7ab120f73c0c.png?auto=compress,format&amp;format=webp" alt=""></p>
<h3 id="heading-external-index-build">External Index build</h3>
<p>The original IVF method typically needs to scan 1–5% of the dataset, which can be slow. By using RaBitQ and fast scan optimization, VectorChord aims to speed up calculations by cutting down the number of full precision vectors that need to be fully compared. This approach helps create a stable and scalable vector search system that works well with the PostgreSQL storage system. As a result, users can use <strong>physical replication and other PostgreSQL features</strong> along with VectorChord.</p>
<p>Built on IVF, VectorChord <strong>allows KMeans clustering to be conducted externally</strong> (such, as on a GPU) and easily imported into the database. We performed tests to measure indexing and insert time on an AWS i4i.large instance, which has 2 vCPUs, and 16 GB of RAM. The dataset used for this test was GIST 1M. We inserted 700,000 vectors, built the index, and then added another 300,000 vectors. After warming up the system, we performed queries using a single thread. During this process, we evaluated both the index build time and the insert time. Here are the results:</p>
<p><img data-zoomable="true" loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1733302602422/57f0e7d6-5f48-484f-ac2a-5e999b7cd0fe.png?auto=compress,format&amp;format=webp" alt=""></p>
<p>VectorChord takes 186 seconds to build the index by utilizing a separate machine for KMeans clustering, making it <strong>16 times faster than pgvector</strong>. Additionally, the insert time is also 14 times faster than that of pgvector. As we know, indexing is the most resource-intensive part of vector databases, requiring significant computation and increasing the demand for CPUs and memory. By utilizing a more capable machine to build the index and then importing it to a smaller machine for querying, it becomes possible to support billions of vectors on a single machine.</p>
<h2 id="heading-benchmark">Benchmark</h2>
<p>We conducted additional experiments to assess performance and costs more thoroughly using the LAION 5M and 100M datasets.</p>
<h3 id="heading-laion-5m">LAION 5M</h3>
<p>We had an experiment using the LAION 5M dataset, and the results were encouraging for Vectorchord. It consistently achieved higher queries per second (RPS) compared to other platforms. While many databases struggle to maintain a balance between speed and accuracy as recall increases, Vectorchord managed to remain efficient even at higher recall levels. This characteristic could make it a suitable option for applications needing both quick responses and precision.</p>
<p><img data-zoomable="true" loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1733288538606/7f7ae3ef-5bda-4b3c-ace7-cf269511472f.png?auto=compress,format&amp;format=webp" alt=""></p>
<p>The experiment utilizes the <a target="_blank" href="https://myscale.github.io/benchmark/#/">Myscale single thread benchmark</a>, and we conducted it on an r6a.xlarge machine, which features 4 vCPUs, 32GB of memory, and 200GB of EBS storage. The parameters set for the experiment include an nlist of 8192, a shared buffer of 28GB, JIT disabled, and an effective I/O concurrency of 200. We ran the experiment twice without prewarming.</p>
<p><img data-zoomable="true" loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1733288473788/e47f3d44-84fc-4dc7-900b-a6b0cbe4db92.png?auto=compress,format&amp;format=webp" alt=""></p>
<p>The machine we used, an <code>r6a.xlarge</code>, costs around $165.56 per month, while the Zilliz Performance 4CU is priced at approximately $460 per month. Notably, we achieved comparable performance in the Top 100 on the LAION 5M dataset.</p>
<h3 id="heading-laion-100m-on-a-single-machine">LAION 100M, on a single machine</h3>
<p>Furthermore, due to its disk-friendly indexing, increasing a single machine's disk capacity can proportionally enhance the maximum number of vectors VectorChord can hold, potentially allowing for storage of 1 billion or more.</p>
<p>To assess scalability, we performed experiments on the LAION 100M dataset (768 dimensions) using an AWS <code>i4i.xlarge</code> instance, which is an economical configuration priced at $250 per month.</p>
<p><a target="_blank" href="https://instances.vantage.sh/aws/ec2/i4i.xlarge?region=us-east-1&amp;os=linux&amp;cost_duration=monthly&amp;reserved_term=Standard.noUpfront"><img data-zoomable="true" loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1733213906554/5021cb87-7337-4fe3-b29f-7b0fd5f28a08.png?auto=compress,format&amp;format=webp" alt=""></a></p>
<p>It features just 4 CPUs and 32 GB of memory, with 937 GB of SSD used to store the 100 million vectors. In this setup, we achieved a QPS of 16.2 @ recall 0.95 for the top 10 results and 4.3 @ recall 0.95 for the top 100 results with a single-thread query. Here are the impressive results:</p>
<p><img data-zoomable="true" loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1733215378789/abdae62d-0085-4b38-97d3-43409d3d3f7b.png?auto=compress,format&amp;format=webp" alt=""></p>
<p>While maintaining a recall greater than 0.95, we also assessed the multi-thread QPS on this 4-vCPU machine. In this scenario, as the number of requested threads rises from 1 to 8, the QPS for vector queries can increase linearly. This indicates that VectorChord demonstrates excellent scalability.</p>
<p><img data-zoomable="true" loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1733288585680/c6de7df3-facd-456c-8268-b6799586bc6c.png?auto=compress,format&amp;format=webp" alt=""></p>
<h2 id="heading-summary">Summary</h2>
<p>VectorChord is a new PostgreSQL extension designed for efficient vector search. It allows users to store 400,000 vectors for just $1, significantly cheaper than competitors. By utilizing IVF and RaBitQ quantization, VectorChord optimizes search speed and memory usage, making it suitable for large datasets.</p>
<p>We offer cloud-managed services for VectorChord at <a target="_blank" href="https://cloud.pgvecto.rs/">PGVecto.rs Cloud</a>. Our platform simplifies deployment and management, enabling you to scale your vector database solutions with ease and efficiency. If you have any questions about VectorChord, please feel free to reach out. We're here to assist you! You can either open an issue in our repository or email us at <a target="_blank" href="mailto:vectorchord-inquiry@tensorchord.ai">vectorchord-inquiry@tensorchord.ai</a>.</p>


<h2 id="heading-references">References</h2>
<p>[1] Gao, Jianyang, and Cheng Long. "RaBitQ: Quantizing High-Dimensional Vectors with a Theoretical Error Bound for Approximate Nearest Neighbor Search." <em>Proceedings of the ACM on Management of Data</em> 2.3 (2024): 1-27.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bringing K/V context quantisation to Ollama (214 pts)]]></title>
            <link>https://smcleod.net/2024/12/bringing-k/v-context-quantisation-to-ollama/</link>
            <guid>42323953</guid>
            <pubDate>Thu, 05 Dec 2024 01:40:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://smcleod.net/2024/12/bringing-k/v-context-quantisation-to-ollama/">https://smcleod.net/2024/12/bringing-k/v-context-quantisation-to-ollama/</a>, See on <a href="https://news.ycombinator.com/item?id=42323953">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Explaining the concept of K/V context cache quantisation, why it matters and the journey to <a href="https://github.com/ollama/ollama/pull/6279">integrate it into Ollama</a>.</p><p><a href="https://github.com/ollama/ollama/pull/6279"><img loading="lazy" src="https://smcleod.net/2024/12/bringing-k/v-context-quantisation-to-ollama/ollama-release.png" alt="Release the Ollamas"></a></p><hr><h2 id="why-kv-context-cache-quantisation-matters">Why K/V Context Cache Quantisation Matters</h2><p>The <a href="https://github.com/ollama/ollama/pull/6279">introduction</a> of K/V context cache quantisation in Ollama is significant, offering users a range of benefits:</p><ul><li>• <strong>Run Larger Models</strong>: With reduced VRAM demands, users can now run larger, more powerful models on their existing hardware.</li><li>• <strong>Expand Context Sizes</strong>: Larger context sizes allow LLMs to consider more information, leading to potentially more comprehensive and nuanced responses. For tasks like coding, where longer context windows are beneficial, K/V quantisation can be a game-changer.</li><li>• <strong>Reduce Hardware Utilisation</strong>: Freeing up memory or allowing users to run LLMs closer to the limits of their hardware.</li></ul><p>Running the K/V context cache at Q8_0 quantisation effectively halves the VRAM required for the context compared to the default F16 with minimal quality impact on the generated outputs, while Q4_0 cuts it down to just one third (at the cost of some noticeable quality reduction).</p><p><img loading="lazy" src="https://smcleod.net/2024/12/bringing-k/v-context-quantisation-to-ollama/llm-vram-components.svg" alt="What makes up a LLMs memory usage?"></p><p>Consider running a 8b parameter model with a 32K context size, the vRAM required for the context could be as follows:</p><ul><li>• <strong>F16</strong> K/V: Around <strong>6GB</strong>.</li><li>• <strong>Q8_0</strong> K/V: Around <strong>3GB</strong>, (50%~ saving).</li><li>• <strong>Q4_0</strong> K/V: Around <strong>2GB</strong>, (66%~ saving).</li></ul><p>Saving that 3GB of vRAM by using Q8_0 could be enough to either allow you to double the context size to 64K, or perhaps to run a larger parameter model (e.g. 14B instead of 8B).</p><hr><h2 id="interactive-vram-estimator">Interactive VRAM Estimator</h2><p>I’ve built an interactive VRAM estimator to help you understand the impact of K/V context cache quantisation on your VRAM usage. You can adjust the model size, context size and quantisation level to see how it affects the memory requirements.</p><hr><h2 id="enabling-kv-context-cache-quantisation-in-ollama">Enabling K/V Context Cache Quantisation in Ollama</h2><p>This is covered in the <a href="https://github.com/ollama/ollama/blob/main/docs/faq.md#how-can-i-set-the-quantization-type-for-the-kv-cache">Ollama FAQ</a>, but here’s a quick guide:</p><ul><li>• Build the latest version of Ollama from the main branch or download the pre-release binaries from Ollama’s <a href="https://github.com/ollama/ollama/releases">releases page</a>).</li><li>• Make sure you’re running Ollama with <a href="https://github.com/ollama/ollama/blob/main/docs/faq.md#how-can-i-enable-flash-attention">Flash Attention enabled</a> (<code>OLLAMA_FLASH_ATTENTION=1</code>), <em>Note: This should become the default behaviour in the near future as there’s no reason not to use it.</em></li><li>• Set the K/V cache quantisation to Q8_0 by adding <code>OLLAMA_KV_CACHE_TYPE="q8_0"</code> to the environment variables you run Ollama with.</li></ul><p>Start Ollama and Q8_0 quantisation will be used for the K/V context cache by default.</p><h3 id="implementation-limitations">Implementation Limitations</h3><p>See <a href="#what-wasnt-included-in-the-pr">what wasn’t included in the PR</a> for more information on these limitations.</p><ul><li>You cannot set the quantisation level in a model’s Modelfile (this would be really good to add back in).</li><li>You cannot set the K and V caches to different quantisation levels.</li><li>You cannot request a quantisation level via the Ollama API, or on the command line.</li></ul><hr><h2 id="understanding-kv-context-cache-quantisation">Understanding K/V Context Cache Quantisation</h2><p>K/V context quantisation is completely separate from model quantisation, which is the process of reducing the precision of the model’s weights and biases to save memory and improve performance. Instead of compressing the model itself, K/V context cache quantisation focuses on reducing the memory footprint of the context cache used during text generation.</p><blockquote><p><em>Matt Williams kindly featured the PR on his YouTube channel, which generated a lot of interest and feedback from the community.</em>
<a href="https://www.youtube.com/watch?v=RFaMiQ97EoE"><img loading="lazy" src="https://img.youtube.com/vi/RFaMiQ97EoE/0.jpg" alt="Matt William’s YouTube video on the PR"></a></p></blockquote><h3 id="kv-context-cache">K/V Context Cache</h3><p>You can think of the K/V (key-value) context as the ‘working memory’ of an LLM. It’s it needs to keep at front of mind as you interact with it. This cache can get <em>very</em> large - in the order of many gigabytes.</p><p>In simple terms, the K/V context cache acts as the memory of an LLM during text generation. It stores the essential information from the preceding text, allowing the model to maintain context and generate coherent responses.</p><h3 id="quantisation">Quantisation</h3><p>Quantisation <em>(or ‘quantization’ to our American friends)</em> can be thought of as <em>compression</em>, it works by reducing the precision of the numerical values stored within it. Think of it like rounding numbers - you lose a tiny bit of detail, but you save a lot of space.</p><p>When quantisation is applied to the K/V context cache it greatly reduces the memory requirements, allowing users to run larger models or use larger context sizes on their existing hardware.</p><p>The most commonly used quantisation levels for the K/V are Q8_0 and Q4_0, unquantised is referred to as F16 (or F32 although for inference you would not run F32).</p><h3 id="performance">Performance</h3><p>Quantisation of the K/V context cache has minimal impact on performance, with quantising the K cache slightly improving performance while quantising the V cache may have a slight negative impact. The overall performance impact is negligible, especially when weighed against the significant reductions in VRAM usage.</p><h3 id="quality">Quality</h3><p>• Q8_0 - Minimal quality impact for normal text generation models, suitable for most users to be enabled by default.
Perplexity measurements on an early implementation showed it added around 0.002~ perplexity to the model.</p><p>• Q4_0 - Some noticeable quality reduction, but still usable for those without much vRAM or working on creative tasks where quality is less critical.
In early testing, Q4_0 added around 0.206~ perplexity to the model.</p><p>As stated in the FAQ, it is not recommended to use K/V cache quantisation for embedding models as these are more sensitive to quantisation. The same may apply to vision/multi-modal models although I have not looked into this.</p><p>If you run into issues with quality however - you can simply disable K/V context cache quantisation by setting <code>OLLAMA_KV_CACHE_TYPE</code> environment variable to <code>f16</code> or not setting it at all. This is even easier if you run Ollama in a container as you can simply run two containers with different configurations (as there’s practically no overhead to running multiple containers).</p><p>Note that the ability to set the K/V cache quantisation level in a model’s Modelfile was <a href="#what-wasnt-included-in-the-pr">removed from the PR</a>, but I hope that Ollama will reconsider this in the future.</p><hr><h2 id="compatibility">Compatibility</h2><p>K/V context cache quantisation requires <a href="https://github.com/ollama/ollama/blob/main/docs/faq.md#how-can-i-enable-flash-attention">Flash Attention</a> to be enabled. Enabling Flash Attention has no negative impacts and is something I expect to become the default behaviour in the near future with Ollama.</p><p>While practically all modern models support Flash Attention, if a model is loaded that - or if your hardware doesn’t support Flash Attention, Ollama will automatically fall back to the default F16 quantisation. You’ll see a warning in the logs if this happens.</p><p>Supported Hardware:</p><ul><li>• Apple Silicon (Metal): Works on Apple Silicon devices.</li><li>• NVIDIA GPUs: Works on all NVIDIA GPUs with CUDA support, Pascal and newer.</li><li>• AMD: Works on most AMD GPUs with ROCm support, although ROCm in general is not as well supported as CUDA or Metal and performance may vary.</li></ul><hr><h2 id="the-journey-to-integration">The Journey to Integration</h2><p>The journey to integrate K/V context cache quantisation into Ollama took around 5 months.</p><p>The hard work was done up front by <a href="https://github.com/ggerganov/">ggerganov</a> in the underlying <a href="https://github.com/ggerganov/llama.cpp">llama.cpp</a>, which Ollama uses as it’s primary inference engine.</p><p>My PR integrated that functionality into Ollama which involved not just supporting the required configuration, but implementing memory estimations for layer placement, error and condition handling, ensuring compatibility with the existing codebase and a lot of testing.</p><h3 id="successes">Successes</h3><ul><li>• It’s merged!</li><li>• Extensive testing and feedback from the community.</li><li>• Once the PR gained traction with the Ollama team, <a href="https://github.com/jmorganca">jmorganca</a> and <a href="https://github.com/jessegross">jessegross</a> were both incredibly helpful in providing feedback and guidance, especially as I am not a Golang developer.</li><li>• The PR became so popular I knew of <em>many</em> people running Ollama from the feature branch, this is not something I wanted to see in the long term, but it was a good sign that people were interested in the feature.</li><li>• I have been building Ollama successfully at least twice, often much more every day for 5 months without major issues.</li></ul><h3 id="challenges">Challenges</h3><ul><li>• Explaining the concept and benefits of K/V context cache quantisation to the community.</li><li>• Addressing merge conflicts due to updates in the Ollama main branch as time passed.</li><li>• Adapting to the new CGO server implementation and refactoring the code to accommodate new runners.</li><li>• Ensuring compatibility with the existing codebase as it changed over time.</li><li>• Finding the right balance between allowing users to configure Ollama to meet their needs while maintaining simplicity and ease of use.</li><li>• The noise in the PR from folks either piling on or trying to help, which made it hard to keep track of the actual changes.</li><li>• Github’s PR interface which can be a bit clunky when dealing with large PRs.</li><li>• Daily battles with my (International / British English) spell checker to keep the Americanised spelling of words consistent with the rest of the codebase.</li></ul><p><em>It took 5 months, but we got there in the end.</em></p><hr><h2 id="definitions">Definitions</h2><table><thead><tr><th>Term</th><th>Definition</th></tr></thead><tbody><tr><td>LLM</td><td>Large Language Model, a type of AI model capable of understanding and generating human-like text.</td></tr><tr><td>vRAM</td><td>Video RAM, the memory used by your graphics card. LLMs require significant vRAM, especially for larger models and context sizes.</td></tr><tr><td>Context Size</td><td>The amount of text the LLM can “remember” and consider when generating a response including both the user’s inputs and the models own outputs. Larger context sizes allow for more nuanced and relevant output.</td></tr><tr><td>Quantisation</td><td>A technique for reducing the precision of numerical values, resulting in smaller data sizes.</td></tr><tr><td>Q8_0 &amp; Q4_0</td><td>Different levels of quantisation, with Q8_0 halving the VRAM usage of the context and Q4_0 reducing it to one third compared to F16 (unquantised).</td></tr><tr><td>llama.cpp</td><td>The primary underlying inference engine used by Ollama.</td></tr><tr><td>Flash Attention</td><td>A technique used to reduce the memory requirements of LLMs by only <a href="https://huggingface.co/docs/text-generation-inference/en/conceptual/flash_attention">attending</a> to a subset of the context at a time.</td></tr><tr><td>ROCm</td><td>The AMD Radeon Open Compute platform, an open-source platform for GPU computing</td></tr><tr><td>CUDA</td><td>A parallel computing platform and application programming interface model created by Nvidia</td></tr><tr><td>Metal</td><td>A low-level, low-overhead hardware-accelerated graphics and compute application programming interface developed by Apple.</td></tr></tbody></table><hr><h2 id="what-wasnt-included-in-the-pr">What wasn’t included in the PR</h2><p>Originally I had several features which in the PR that were not included in the final version as Ollama wanted to minimise the configuration exposed to users and not introduce API changes.</p><ul><li>• All the K/V quantisation types supported by llama.cpp (Q4_1, IQ4_NL, Q5_0, Q5_1).</li><li>• Ability to set the quantisation level in a models Modelfile (I’m hoping this will be added back in the future).</li><li>• API parameters that allowed setting the quantisation level when making requests.</li><li>• CMD line parameters that allowed setting the quantisation level when running Ollama.</li></ul><p>Additionally the ability to set different quantisation levels for the K and V caches was not included, this might be nice to add back in the future, as to quote <a href="https://github.com/JohannesGaessler">JohannesGaessler</a> [<a href="https://github.com/ggerganov/llama.cpp/pull/7412#issuecomment-2120427347">May 2024</a>] while measuring the quality impact of K/V context cache quantisation using an older implementation:</p><blockquote><p><em>• The K cache seems to be much more sensitive to quantization than the V cache. However, the weights seem to still be the most sensitive.</em></p><p><em>• Using q4_0 for the V cache and FP16 for everything else is more precise than using q6_K with FP16 KV cache.</em></p><p><em>• A 6.5 bit per value KV cache with q8_0 for the K cache and q4_0 for the V cache also seems to be more precise than q6_K weights. There seems to be no significant quality loss from using q8_0 instead of FP16 for the KV cache.</em></p></blockquote><hr><h2 id="reporting-issues">Reporting Issues</h2><p>If you find a bug with K/V context cache quantisation it could be either in Ollama or, perhaps more likely - in the underlying llama.cpp project.</p><p>Remember to test using the latest Ollama release or main branch build and to test with the feature disabled to ensure it’s actually related to K/V context cache quantisation.</p><p>It’s likely to be Ollama if it’s related to:</p><ul><li>• Enabling/disabling the feature.</li><li>• Memory estimations (e.g. how many layers are offloaded to each GPU).</li></ul><p>It’s more likely to a bug in llama.cpp if it’s related to:</p><ul><li>• Performance.</li><li>• ROCm support.</li><li>• Model compatibility.</li><li>• Quality issues.</li></ul><p>When logging a bug:</p><ul><li>• You should first <a href="https://github.com/ggerganov/llama.cpp/issues?q=sort%3Aupdated-desc+is%3Aissue+k%2Fv+quantization">search for existing issues in the llama.cpp project</a>.</li><li>• Reach out to the community to see if others have experienced the issue.<ul><li>• Ollama has a <a href="https://discord.gg/ollama">Discord server</a> where you can discuss issues, although be mindful that <strong>Discord is an information black hole and is not well suited to knowledge discovery or issue tracking</strong>.</li><li>• If you find an issue do not add a comment such as “+1” or “I have this issue too” - instead use an emoji reaction to indicate your support and only comment if you have valuable information to add.</li></ul></li></ul><p>Finally, if you can’t find an existing issue, you can create an issue (in the relevant project), ensuring you include your hardware configuration, software versions, environmental settings, the model you’re using, the context size, the quantisation level and any other relevant information.</p><div><p>Remember: You’re <em>logging a bug</em> to a free and open source project, not requesting <em>support</em> from a paid service.</p><p>Be patient, respectful and provide as much information as you can to help the developers diagnose and fix the issue if they have the time and resources to do so.</p></div><hr><h2 id="further-reading">Further Reading</h2><ul><li>• <a href="https://github.com/ollama/ollama/pull/6279">The PR to add K/V context cache quantisation to Ollama.</a></li><li>• <a href="https://www.youtube.com/watch?v=RFaMiQ97EoE">Matt William’s YouTube video on the PR</a></li><li>• <a href="https://smcleod.net/2024/07/understanding-ai/llm-quantisation-through-interactive-visualisations/">Understanding Quantisation</a></li><li>• Ollama<ul><li>• <a href="https://github.com/ollama/ollama/blob/main/docs/faq.md#how-can-i-set-the-quantization-type-for-the-kv-cache">Ollama FAQ</a></li><li>• <a href="https://ollama.com/blog">Ollama Blog</a></li><li>• <a href="https://github.com/ollama/ollama/releases">Ollama Releases</a></li></ul></li><li>• <a href="https://huggingface.co/blog/kv-cache-quantization">HuggingFace’s blog post on K/V cache quantisation</a>, which provides a more technical deep dive into the topic in the context of Transformers</li><li>• Related llama.cpp PRs and performance measurements (note: these are now quite old and things have likely improved since):<ul><li>• <a href="https://github.com/ggerganov/llama.cpp/pull/7412#issuecomment-2120427347">ggerganov/llama.cpp#7412</a></li><li>• <a href="https://github.com/ggerganov/llama.cpp/pull/7527#issuecomment-2132341565">ggerganov/llama.cpp#7527</a></li></ul></li></ul><hr><p>Discuss this post on:</p><ul><li>• <a href="https://news.ycombinator.com/item?id=42323953">HackerNews</a></li><li>• <a href="https://x.com/ollama/status/1864487185443115378">Twitter</a></li><li>• <a href="https://www.linkedin.com/feed/update/urn:li:activity:7270248388057542656/">LinkedIn</a></li><li>• <a href="https://aus.social/@s_mcleod/113597789410718453">Mastodon</a></li><li>• <a href="https://www.reddit.com/r/LocalLLaMA/comments/1h62u1p/ollama_has_merged_in_kv_cache_quantisation/">Reddit</a></li></ul></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HowStuffWorks founder Marshall Brain sent final email before sudden death (136 pts)]]></title>
            <link>https://arstechnica.com/ai/2024/12/web-pioneer-marshall-brain-dies-suddenly-at-63-amid-ethics-battle/</link>
            <guid>42323599</guid>
            <pubDate>Thu, 05 Dec 2024 00:36:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/ai/2024/12/web-pioneer-marshall-brain-dies-suddenly-at-63-amid-ethics-battle/">https://arstechnica.com/ai/2024/12/web-pioneer-marshall-brain-dies-suddenly-at-63-amid-ethics-battle/</a>, See on <a href="https://news.ycombinator.com/item?id=42323599">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          
          
<p>Brandon Kashani, a former student of Brain's and startup mentor at NC State's entrepreneurship clinic, recalled to the Technician about how he met with Brain on November 15. "He felt like his reputation was tarnished, like everything he worked for was ruined, and the root of all that was he didn't get any support from the University," Kashani <a href="https://www.technicianonline.com/news/popular-nc-state-professor-marshall-brain-dies-alleges-retaliation-for-ethics-complaints/article_152e5c80-ac2e-11ef-8b3f-036ac3c8d9bf.html">told</a> the newspaper.</p>
<p>In his email, Brain wrote that the school's head of the Department of Mechanical and Aerospace Engineering later informed him the department would stop recommending students for Brain's Engineering Entrepreneurs Program. According to Brain's account, this led to disciplinary action against Brain for "unacceptable behavior."</p>
<p>"My career has been destroyed by multiple administrators at NCSU who united together and completely ignored the EthicsPoint System and its promises to employees," Brain wrote. "I did what the University told me to do, and then these administrators ruined my life for it."</p>
<h2>Unanswered questions remain</h2>
<p>In recent years, Brain <a href="https://ece.ncsu.edu/people/mdbrain/">directed</a> NC State's <a href="https://entrepreneurship.ncsu.edu/engineering-entrepreneurs-program/">Engineering Entrepreneurs Program</a>, where he mentored students and supported innovation in Research Triangle Park.</p>
<p>So far, Brain's death on campus has come as a shock to students and colleagues. Dror Baron, an NCSU professor of Electrical and Computer Engineering, <a href="https://x.com/BaronDror/status/1861985286873375165">wrote</a> on X, "A professor I know died following various investigations. I know the people mentioned here, and call for a transparent and independent investigation."</p>
<p>So far, that investigation has not been forthcoming. University spokesperson Mick Kulikowski declined to comment to The Technician about Brain's death or the allegations. To date, the university has not issued a public statement about Brain's death.</p>
<p>Barry and Kashani expressed disappointment in the university's lack of public response. "It's been six days now," Kashani said at the time to the school newspaper. "There hasn't been any acknowledgment of mistakes that were made, systems that failed, no resignations, not even a call to celebrate Marshall's achievements."</p>
<p>Brain’s friends and family plan to celebrate his achievements. His wife, Leigh Ann, their four children—David, Irena, Johnny, and Ian—and family dog Summer survive him. The family will host a <a href="https://www.dignitymemorial.com/obituaries/cary-nc/marshall-brain-12105251">Celebration of Life</a> on December 8, 2024, at Brown-Wynne Funeral Home in Cary, North Carolina.</p>
<p><em>If you or someone you know is feeling suicidal or in distress, please call the Suicide Prevention Lifeline number, 1-800-273-TALK (8255), which will put you in touch with a local crisis center.</em></p>


          
                  </div></div>]]></description>
        </item>
    </channel>
</rss>