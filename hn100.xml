<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 22 Jul 2023 11:00:06 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Bun v0.7.0 (102 pts)]]></title>
            <link>https://bun.sh/blog/bun-v0.7.0</link>
            <guid>36823723</guid>
            <pubDate>Sat, 22 Jul 2023 06:04:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bun.sh/blog/bun-v0.7.0">https://bun.sh/blog/bun-v0.7.0</a>, See on <a href="https://news.ycombinator.com/item?id=36823723">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><p>We're pleased to announce Bun v0.7.0, a big leap forward in terms of Node.js compatibility.</p><p>We're hiring C/C++ and Zig engineers to build the future of JavaScript! <a href="https://bun.sh/careers">Join our team →</a></p><p>Bun is an incredibly fast JavaScript runtime, bundler, transpiler, and package manager — all in one. Over the past couple months, we've been releasing a lot of changes to Bun recently, here's a recap in case you missed it:</p><ul><li><a href="https://bun.sh/blog/bun-v0.6.10"><code>v0.6.10</code></a> - <code>fs.watch()</code>, <code>bun install</code> bug fixes, <code>bun test</code> features, and improved CommonJS support</li><li><a href="https://bun.sh/blog/bun-v0.6.10"><code>v0.6.11</code></a> - Addressed a release build issue from <code>v0.6.10</code>.</li><li><a href="https://bun.sh/blog/bun-v0.6.12"><code>v0.6.12</code></a> - Sourcemap support in <code>Error.stack</code>, <code>Bun.file().exists()</code>, and Node.js bug fixes.</li><li><a href="https://bun.sh/blog/bun-v0.6.13"><code>v0.6.13</code></a> - Implemented mock <code>Date</code>, faster base64 encoding, and fixes for <code>WebSocket</code> and <code>node:tls</code>.</li><li><a href="https://bun.sh/blog/bun-v0.6.14"><code>v0.6.14</code></a> - <code>process.memoryUsage()</code>, <code>process.cpuUsage()</code>, <code>process.on('beforeExit', cb)</code>, <code>process.on('exit', cb)</code> and crash fixes</li></ul><p>To install Bun:</p><div id="RWUelGtIHM"><div><p>curl</p><div><pre><code><span><span>curl -fsSL https://bun.sh/install </span><span>|</span><span> bash</span></span></code></pre></div></div><div><p>docker</p><div><pre><code><span><span>docker run --rm --init --ulimit memlock=-1:-1 oven/bun</span></span></code></pre></div></div></div><p>To upgrade Bun:</p><h2 level="2" anchor-id="vite-support"><a name="vite-support"></a><a href="#vite-support">Vite support</a></h2><p><em>Support is still experimental and non-optimized.</em> Vite does not use Bun's bundler, module resolver, or transpiler, even when run with Bun.</p><p>With the recent strides towards Node.js API compatibilty, Bun can now run <a href="https://vitejs.dev/"><code>vite dev</code></a>, thanks to <a href="https://github.com/paperdave">@paperdave</a>! This is one of Bun's <a href="https://github.com/oven-sh/bun/issues/250">most upvoted issues</a>.</p><p>To try this with one of Vite's starter projects, use <code>bunx</code>:</p><p>Then start the dev server.</p><p><strong>Why <code>--bun</code>?</strong> The <code>--bun</code> flag tells Bun to override the <code>#! /usr/bin/env node</code> shebang in the <code>vite</code> CLI and execute the file with Bun instead of Node.js. In a future release this will be the default behavior.</p><figure><a href="https://user-images.githubusercontent.com/709451/254804727-725bf67c-c60f-4eec-b472-07d52b650a93.gif"><img src="https://user-images.githubusercontent.com/709451/254804727-725bf67c-c60f-4eec-b472-07d52b650a93.gif" caption="Hot module reloading with Vite"></a><figcaption>Hot module reloading with Vite</figcaption></figure><p>This is a great way to develop frontend code with Bun's APIs on the server when building frontend apps.</p><p>Note: if you run <code>bun vite dev</code> without <code>-b</code> or <code>--bun</code>, it will still run in Node.js as <code>vite</code>'s CLI specifies <code>#!/usr/bin/env node</code> at the top which tells Bun (and other software on your computer) to run it in Node.js.</p><h2 level="2" anchor-id="concurrency-with-worker"><a name="concurrency-with-worker"></a><a href="#concurrency-with-worker">Concurrency with <code>Worker</code></a></h2><p>Bun now supports <a href="https://developer.mozilla.org/en-US/docs/Web/API/Worker"><code>Worker</code></a> which allows you to run another JavaScript instance in a separate thread. In Bun, workers support ES Modules, CommonJS, TypeScript, JSX, and the rest of Bun's features with no extra configuration.</p><p>As in browsers, <code>Worker</code> is a global class. To create a worker from the main thread:</p><div><p>main.ts</p><div><pre><code><span><span>const</span><span> worker </span><span>=</span><span> </span><span>new</span><span> </span><span>Worker</span><span>(</span><span>"</span><span>./worker.ts</span><span>"</span><span>);</span></span>
<span><span>worker.</span><span>addEventListener</span><span>(</span><span>"</span><span>message</span><span>"</span><span>, (</span><span>event</span><span>:</span><span> </span><span>MessageEvent</span><span>) </span><span>=&gt;</span><span> {</span></span>
<span><span>  console.</span><span>log</span><span>(</span><span>"</span><span>Message from worker:</span><span>"</span><span>, event.data);</span></span>
<span><span>});</span></span>
<span><span>worker.</span><span>postMessage</span><span>(</span><span>"</span><span>Hello from main thread!</span><span>"</span><span>);</span></span>
<span></span></code></pre></div></div><p>On the worker thread:</p><div><p>worker.ts</p><div><pre><code><span><span>addEventListener</span><span>(</span><span>"</span><span>message</span><span>"</span><span>, (</span><span>event</span><span>:</span><span> </span><span>MessageEvent</span><span>) </span><span>=&gt;</span><span> {</span></span>
<span><span>  console.</span><span>log</span><span>(</span><span>"</span><span>Message from main thread:</span><span>"</span><span>, event.data);</span></span>
<span><span>  </span><span>postMessage</span><span>(</span><span>"</span><span>Hello from worker thread!</span><span>"</span><span>);</span></span>
<span><span>});</span></span>
<span></span>
<span></span></code></pre></div></div><p>This release <em>does not</em> include support for the <code>node:worker_threads</code> module, but this unblocks the work necessary for us to implement it in Bun.</p><p>The following globals have been added to Bun:</p><ul><li><code>postMessage</code></li><li><code>addEventListener</code></li><li><code>removeEventListener</code></li><li><code>onmessage</code> (getter/setter)</li></ul><p>Refer to <a href="https://bun.sh/docs/api/workers">Docs &gt; API &gt; Workers</a> to learn more about using <code>Worker</code> in Bun.</p><h3 level="3" anchor-id="using-comlink-with-bun"><a name="using-comlink-with-bun"></a><a href="#using-comlink-with-bun">Using <code>comlink</code> with Bun</a></h3><p>The popular <a href="https://github.com/GoogleChromeLabs/comlink"><code>comlink</code></a> package works in Bun without changes. This library makes it easier to share functions and state between main and worker threads.</p><h3 level="3" anchor-id="structuredclone-support"><a name="structuredclone-support"></a><a href="#structuredclone-support"><code>structuredClone()</code> support</a></h3><p>As in browsers, <code>postMessage</code> serializes messages using the <em>structured clone algorithm</em>. Bun now exposes this via the Web-standard<a href="https://developer.mozilla.org/en-US/docs/Web/API/structuredClone"><code>structuredClone()</code></a> function, which provides a mechanism for deep-cloning objects. It is similar to <code>JSON.parse(JSON.stringify(obj))</code>, but it supports more types.</p><div><pre><code><span><span>const</span><span> obj </span><span>=</span><span> { a</span><span>:</span><span> </span><span>1</span><span>, b</span><span>:</span><span> </span><span>2</span><span> };</span></span>
<span><span>const</span><span> clone </span><span>=</span><span> </span><span>structuredClone</span><span>(obj);</span></span>
<span></span></code></pre></div><h2 level="2" anchor-id="asynclocalstorage-support"><a name="asynclocalstorage-support"></a><a href="#asynclocalstorage-support"><code>AsyncLocalStorage</code> support</a></h2><p>Bun now implements <code>AsyncLocalStorage</code> from the <code>node:async_hooks</code> module. This provides a mechanism for passing contextual data through a chain of asynchronous code. This is a big step towards supporting Next.js and other frameworks that rely on this module.</p><div><pre><code><span><span>import</span><span> { AsyncLocalStorage } </span><span>from</span><span> </span><span>"</span><span>node:async_hooks</span><span>"</span><span>;</span></span>
<span></span>
<span><span>const</span><span> requestId </span><span>=</span><span> </span><span>new</span><span> </span><span>AsyncLocalStorage</span><span>();</span></span>
<span><span>let</span><span> lastId </span><span>=</span><span> </span><span>0</span><span>;</span></span>
<span></span>
<span><span>Bun.</span><span>serve</span><span>({</span></span>
<span><span>  </span><span>fetch</span><span>(</span><span>request</span><span>) {</span></span>
<span><span>    lastId</span><span>++</span><span>;</span></span>
<span><span>    </span><span>// Run the callback with 'requestId' set. async_hooks will preserve</span></span>
<span><span>    </span><span>// this value through any chain of asynchronous code.</span></span>
<span><span>    </span><span>return</span><span> requestId.</span><span>run</span><span>(lastId, </span><span>async</span><span> () </span><span>=&gt;</span><span> {</span></span>
<span><span>      console.</span><span>log</span><span>(</span><span>"</span><span>Request ID: ${requestId getStore ()}</span><span>"</span><span>);</span></span>
<span><span>      </span><span>await</span><span> Bun.</span><span>sleep</span><span>(</span><span>500</span><span>);</span></span>
<span><span>      </span><span>// Even if new requests mutate 'lastId', 'requestId' is still preserved.</span></span>
<span><span>      </span><span>return</span><span> </span><span>new</span><span> </span><span>Response</span><span>(</span><span>"</span><span>Request ID: ${requestId. getStore ()}</span><span>"</span><span>);</span></span>
<span><span>    });</span></span>
<span><span>  },</span></span>
<span><span>});</span></span>
<span></span></code></pre></div><h2 level="2" anchor-id="reduce-memory-usage-with-bun-smol"><a name="reduce-memory-usage-with-bun-smol"></a><a href="#reduce-memory-usage-with-bun-smol">Reduce memory usage with <code>bun --smol</code></a></h2><p><code>bun --smol</code> is a new CLI flag which configures the JavaScriptCore heap size to be smaller and grow slower, at a cost to runtime performance. This is useful for running Bun in memory-constrained environments.</p><p>To avoid setting the flag manually, you can set this as a default in <code>bunfig.toml</code>.</p><div><p>bunfig.toml</p><div><pre><code><span><span>smol</span><span> </span><span>=</span><span> </span><span>true</span></span>
<span></span>
<span><span>[</span><span>test</span><span>]</span></span>
<span><span># set it only for tests, if you want</span></span>
<span><span>smol</span><span> </span><span>=</span><span> </span><span>true</span></span>
<span></span></code></pre></div></div><h2 level="2" anchor-id="bail-in-bun-test"><a name="bail-in-bun-test"></a><a href="#bail-in-bun-test"><code>--bail</code> in <code>bun test</code></a></h2><p>Running <code>bun test</code> with <code>--bail=1</code> will exit after the first test failure.</p><div><pre><code><span><span>bun test v0.7.0</span></span>
<span><span></span></span>
<span><span>✓ test1 [0.02ms]</span></span>
<span><span>test2.test.js:</span></span>
<span><span>1 | import {test, expect} from 'bun:test';</span></span>
<span><span>2 |</span></span>
<span><span>3 | test('test2', () =&gt; {</span></span>
<span><span>4 |   expect(2).toEqual(3);</span></span>
<span><span>      ^</span></span>
<span><span>error: expect(received).toEqual(expected)</span></span>
<span><span>Expected: 3</span></span>
<span><span>Received: 2</span></span>
<span><span>      at /Users/colinmcd94/Documents/bun/fun/test/test2.test.js:13:8</span></span>
<span><span>✗ test2 [0.18ms]</span></span>
<span><span>Ran 2 tests across 2 files. [8.00ms]</span></span>
<span><span>Bailed out after 1 failures</span></span></code></pre></div><p>This is useful for CI environments or when you want to stop running tests after the first failure. Thanks to <a href="https://github.com/TiranexDev">@TiranexDev</a> for landing this improvement!</p><h2 level="2" anchor-id="bun-readablestreamtoformdata"><a name="bun-readablestreamtoformdata"></a><a href="#bun-readablestreamtoformdata"><code>Bun.readableStreamToFormData()</code></a></h2><p>Bun now exposes a helper for converting a <a href="https://developer.mozilla.org/en-US/docs/Web/API/ReadableStream">ReadableStream</a> into <a href="https://developer.mozilla.org/en-US/docs/Web/API/FormData">FormData</a>.</p><p>It supports multipart form data.</p><div><pre><code><span><span>import</span><span> { readableStreamToFormData } </span><span>from</span><span> </span><span>"</span><span>bun</span><span>"</span><span>;</span></span>
<span></span>
<span><span>// without dashes</span></span>
<span><span>const</span><span> boundary </span><span>=</span><span> </span><span>"</span><span>WebKitFormBoundary</span><span>"</span><span> </span><span>+</span><span> </span><span>Math</span><span>.</span><span>random</span><span>().</span><span>toString</span><span>(</span><span>16</span><span>).</span><span>slice</span><span>(</span><span>2</span><span>);</span></span>
<span></span>
<span><span>const</span><span> myStream </span><span>=</span><span> </span><span>getStreamFromSomewhere</span><span>(); </span><span>// ...</span></span>
<span><span>const</span><span> formData </span><span>=</span><span> </span><span>await</span><span> Bun.</span><span>readableStreamToFormData</span><span>(stream, boundary);</span></span>
<span><span>formData.</span><span>get</span><span>(</span><span>"</span><span>foo</span><span>"</span><span>); </span><span>// "bar"</span></span>
<span></span></code></pre></div><p>It also supports URL-encoded form data:</p><div><pre><code><span><span>import</span><span> { readableStreamToFormData } </span><span>from</span><span> </span><span>"</span><span>bun</span><span>"</span><span>;</span></span>
<span></span>
<span><span>const</span><span> stream </span><span>=</span><span> </span><span>new</span><span> </span><span>Response</span><span>(</span><span>"</span><span>hello=123</span><span>"</span><span>).body;</span></span>
<span><span>const</span><span> formData </span><span>=</span><span> </span><span>await</span><span> </span><span>readableStreamToFormData</span><span>(stream);</span></span>
<span><span>formData.</span><span>get</span><span>(</span><span>"</span><span>hello</span><span>"</span><span>); </span><span>// "123"</span></span>
<span></span></code></pre></div><p>We added this to help fix a bug causing <code>request.formData()</code> and <code>response.formData()</code> to hang when the body was a <code>ReadableStream</code> from JavaScript.</p><h2 level="2" anchor-id="serialize-and-deserialize-in-bun-jsc"><a name="serialize-and-deserialize-in-bun-jsc"></a><a href="#serialize-and-deserialize-in-bun-jsc"><code>serialize</code> and <code>deserialize</code> in <code>bun:jsc</code></a></h2><p>The <code>bun:jsc</code> module now exports <code>serialize()</code> and <code>deserialize()</code>, which convert JavaScript objects to <code>ArrayBuffer</code> and back.</p><div><pre><code><span><span>import</span><span> { serialize, deserialize } </span><span>from</span><span> </span><span>"</span><span>bun:jsc</span><span>"</span><span>;</span></span>
<span><span>import</span><span> { deepEquals } </span><span>from</span><span> </span><span>"</span><span>bun</span><span>"</span><span>;</span></span>
<span></span>
<span><span>const</span><span> obj </span><span>=</span><span> { a</span><span>:</span><span> </span><span>1</span><span>, b</span><span>:</span><span> </span><span>2</span><span> };</span></span>
<span><span>const</span><span> buffer </span><span>=</span><span> </span><span>serialize</span><span>(obj);</span></span>
<span><span>const</span><span> clone </span><span>=</span><span> </span><span>deserialize</span><span>(buffer);</span></span>
<span></span>
<span><span>if</span><span> (</span><span>deepEquals</span><span>(obj, clone)) {</span></span>
<span><span>  console.</span><span>log</span><span>(</span><span>"</span><span>They are equal!</span><span>"</span><span>);</span></span>
<span><span>}</span></span>
<span></span></code></pre></div><p>The <code>node:v8</code> module exports these same functions, for compatibility with existing libraries that serialize/deserialize data between processes.</p><h2 level="2" anchor-id="websocket-improvements"><a name="websocket-improvements"></a><a href="#websocket-improvements"><code>WebSocket</code> improvements</a></h2><p>You can now manually send &amp; receive WebSocket <code>ping</code> and <code>pong</code> frames.</p><div><pre><code><span><span>const</span><span> ws </span><span>=</span><span> </span><span>new</span><span> </span><span>WebSocket</span><span>(</span><span>"</span><span>wss://echo.websocket.org</span><span>"</span><span>);</span></span>
<span><span>ws.</span><span>addEventListener</span><span>(</span><span>"</span><span>pong</span><span>"</span><span>, () </span><span>=&gt;</span><span> {</span></span>
<span><span>  console.</span><span>log</span><span>(</span><span>"</span><span>Received pong</span><span>"</span><span>);</span></span>
<span><span>});</span></span>
<span><span>ws.</span><span>ping</span><span>();</span></span>
<span></span></code></pre></div><p>This applies to both <code>ServerWebSocket</code> and <code>WebSocket</code>.</p><h3 level="3" anchor-id="nodebuffer-is-now-the-default-binarytype"><a name="nodebuffer-is-now-the-default-binarytype"></a><a href="#nodebuffer-is-now-the-default-binarytype"><code>nodebuffer</code> is now the default <code>binaryType</code></a></h3><p>By default, the <code>binaryType</code> for <code>WebSocket</code> and <code>ServerWebSocket</code> in Bun is now <code>nodebuffer</code> This means that binary data frames in <code>WebSocket</code> will be <code>Buffer</code> instances, instead of <code>ArrayBuffer</code> (as before). This is to match the bahavior of the <code>ws</code> package.</p><div><pre><code><span><span>const</span><span> ws </span><span>=</span><span> </span><span>new</span><span> </span><span>WebSocket</span><span>(</span><span>"</span><span>wss://echo.websocket.org</span><span>"</span><span>);</span></span>
<span></span>
<span><span>ws.</span><span>addEventListener</span><span>(</span><span>"</span><span>message</span><span>"</span><span>, (</span><span>event</span><span>:</span><span> </span><span>MessageEvent</span><span>) </span><span>=&gt;</span><span> {</span></span>
<span><span>  console.</span><span>log</span><span>(event.data </span><span>instanceof</span><span> </span><span>Buffer</span><span>); </span><span>// true</span></span>
<span><span>});</span></span>
<span></span></code></pre></div><p>To change it back to <code>ArrayBuffer</code>, set <code>ws.binaryType = "arraybuffer"</code>.</p><div><pre><code><span><span>const</span><span> ws </span><span>=</span><span> </span><span>new</span><span> </span><span>WebSocket</span><span>(</span><span>"</span><span>wss://echo.websocket.org</span><span>"</span><span>);</span></span>
<span><span>ws.binaryType </span><span>=</span><span> </span><span>"</span><span>arraybuffer</span><span>"</span><span>;</span></span>
<span></span>
<span><span>ws.</span><span>addEventListener</span><span>(</span><span>"</span><span>message</span><span>"</span><span>, (</span><span>event</span><span>:</span><span> </span><span>MessageEvent</span><span>) </span><span>=&gt;</span><span> {</span></span>
<span><span>  event.data; </span><span>// ArrayBuffer</span></span>
<span><span>});</span></span>
<span></span></code></pre></div><p>(Note that in browsers it is <code>Blob</code> by default.)</p><h3 level="3" anchor-id="close-reasons-propagate-correctly-now"><a name="close-reasons-propagate-correctly-now"></a><a href="#close-reasons-propagate-correctly-now">Close reasons propagate correctly now</a></h3><p>A bug was fixed where <code>WebSocket</code> would not propagate close reasons from third-party servers correctly. Thanks to <a href="https://github.com/electroid">@Electroid</a> for landing these improvements!</p><h2 level="2" anchor-id="node-js-compatibility-improvements"><a name="node-js-compatibility-improvements"></a><a href="#node-js-compatibility-improvements">Node.js compatibility improvements</a></h2><p>This release adds several additional improvements to Node.js compatibility.</p><h3 level="3" anchor-id="improvements-to-tlssocket-from-node-tls"><a name="improvements-to-tlssocket-from-node-tls"></a><a href="#improvements-to-tlssocket-from-node-tls">Improvements to <code>TLSSocket</code> from <code>node:tls</code></a></h3><p>The following methods were implemented on the <code>TLSSocket</code> class. Thanks to <a href="https://github.com/cirospaciari">@cirospaciari</a> for landing these improvements in <a href="https://github.com/oven-sh/bun/pull/3596"><code>#3596</code></a>.</p><ul><li><code>.getPeerFinished()</code></li><li><code>.getFinished()</code></li><li><code>.getProtocol()</code></li><li><code>.getSharedSigalgs()</code></li><li><code>.isSessionReused()</code></li><li><code>.exportKeyingMaterial()</code></li><li><code>.setMaxSendFragment()</code></li><li><code>.getPeerCertificate()</code></li><li><code>.getCertificate()</code></li><li><code>.enableTrace()</code></li><li><code>.disableRenegotiation()</code></li><li><code>.getCipher()</code></li><li><code>.getEphemeralKeyInfo()</code></li><li><code>.getTLSTicket()</code></li><li><code>.getSession()</code></li><li><code>.setSession()</code></li></ul><h3 level="3" anchor-id="base64url-hashes-are-no-longer-data-urls"><a name="base64url-hashes-are-no-longer-data-urls"></a><a href="#base64url-hashes-are-no-longer-data-urls"><code>base64url</code> hashes are no longer <code>data:</code> urls</a></h3><p>Previously, Bun would prepend <code>data:base64,</code> to the output of <code>crypto.createHash("sha256").digest("base64url")</code>. This is not what Node.js does, and it was causing issues with libraries that expected the output to be the same string as Node.js.</p><div><pre><code><span><span>crypto.</span><span>createHash</span><span>(</span><span>"</span><span>sha256</span><span>"</span><span>).</span><span>update</span><span>(</span><span>"</span><span>abc</span><span>"</span><span>).</span><span>digest</span><span>(</span><span>"</span><span>base64url</span><span>"</span><span>);</span></span>
<span></span>
<span><span>//        Node.js:  "ungWv48Bz-pBQUDeXa4iI7ADYaOWF3qctBD_YfIAFa0"</span></span>
<span><span>//     Bun v0.7.0:  "ungWv48Bz-pBQUDeXa4iI7ADYaOWF3qctBD_YfIAFa0"</span></span>
<span><span>// &lt;= Bun v0.6.14:  "data:base64,ungWv48Bz-pBQUDeXa4iI7ADYaOWF3qctBD_YfIAFa0="</span></span>
<span></span></code></pre></div><h3 level="3" anchor-id="terminal-dimensions-with-process-stdout-columns-and-process-stdout-rows"><a name="terminal-dimensions-with-process-stdout-columns-and-process-stdout-rows"></a><a href="#terminal-dimensions-with-process-stdout-columns-and-process-stdout-rows">Terminal dimensions with <code>process.stdout.columns</code> and <code>process.stdout.rows</code></a></h3><p><code>process.stdout</code> and <code>process.stderr</code> now support reading the terminal window's dimensions.</p><div><pre><code><span><span>const</span><span> { columns, rows } </span><span>=</span><span> process.stdout;</span></span>
<span><span>const</span><span> [columns, rows] </span><span>=</span><span> process.stdout.</span><span>getWindowSize</span><span>();</span></span>
<span><span>const</span><span> { columns, rows } </span><span>=</span><span> process.stderr;</span></span>
<span><span>const</span><span> [columns, rows] </span><span>=</span><span> process.stderr.</span><span>getWindowSize</span><span>();</span></span>
<span></span></code></pre></div><p>You can also use <code>process.stdout.getWindowSize()</code> if you want both dimensions at once.</p><h2 level="2" anchor-id="bugfixes"><a name="bugfixes"></a><a href="#bugfixes">Bugfixes</a></h2><p><a href="https://github.com/oven-sh/bun/pull/3656"><code>#3656</code></a> <strong>A memory leak</strong> in await <code>new Response(latin1String).arrayBuffer()</code> and <code>await Response.json(obj).json()</code> has been fixed.</p><p>After:</p><div><pre><code><span><span>cpu: Apple M1 Max</span></span>
<span><span>runtime: bun </span><span>0.7</span><span>.</span><span>0</span><span> (arm64</span><span>-</span><span>darwin)</span></span>
<span></span>
<span><span>benchmark                                                        </span><span>time</span><span> (avg)             (min … max)       p75       p99      p995</span></span>
<span><span>---------------------------------------------------------------------------------------------------</span><span> </span><span>-----------------------------</span></span>
<span><span>new</span><span> </span><span>Response</span><span>().</span><span>arrayBuffer</span><span>() (</span><span>new</span><span> string each call, latin1)    </span><span>12.9</span><span> µs</span><span>/</span><span>iter</span><span>      (</span><span>625</span><span> ns … </span><span>4.18</span><span> ms)      </span><span>1</span><span> µs </span><span>567.17</span><span> µs </span><span>711.79</span><span> µs</span></span>
<span><span>new</span><span> </span><span>Response</span><span>().</span><span>arrayBuffer</span><span>() (</span><span>new</span><span> string each call, utf16)    </span><span>12.85</span><span> µs</span><span>/</span><span>iter</span><span>     (</span><span>1.67</span><span> µs … </span><span>1.56</span><span> ms)   </span><span>2.17</span><span> µs </span><span>462.75</span><span> µs </span><span>621.13</span><span> µs</span></span>
<span><span>new</span><span> </span><span>Response</span><span>().</span><span>arrayBuffer</span><span>() (existing string, latin1)         </span><span>6.53</span><span> µs</span><span>/</span><span>iter</span><span>     (</span><span>6.21</span><span> µs … </span><span>7.07</span><span> µs)   </span><span>6.64</span><span> µs   </span><span>7.07</span><span> µs   </span><span>7.07</span><span> µs</span></span>
<span></span>
<span><span>Peak memory usage: </span><span>49</span><span> MB</span></span>
<span></span></code></pre></div><p>Before:</p><div><pre><code><span><span>cpu: Apple M1 Max</span></span>
<span><span>runtime: bun </span><span>0.7</span><span>.</span><span>0</span><span> (arm64</span><span>-</span><span>darwin)</span></span>
<span></span>
<span><span>benchmark                                                        </span><span>time</span><span> (avg)             (min … max)       p75       p99      p995</span></span>
<span><span>---------------------------------------------------------------------------------------------------</span><span> </span><span>-----------------------------</span></span>
<span><span>new</span><span> </span><span>Response</span><span>().</span><span>arrayBuffer</span><span>() (</span><span>new</span><span> string each call, latin1)   </span><span>13.51</span><span> µs</span><span>/</span><span>iter</span><span>       (</span><span>541</span><span> ns … </span><span>3.2</span><span> ms)   </span><span>1.92</span><span> µs </span><span>553.42</span><span> µs </span><span>709.92</span><span> µs</span></span>
<span><span>new</span><span> </span><span>Response</span><span>().</span><span>arrayBuffer</span><span>() (</span><span>new</span><span> string each call, utf16)    </span><span>13.07</span><span> µs</span><span>/</span><span>iter</span><span>     (</span><span>1.71</span><span> µs … </span><span>3.43</span><span> ms)   </span><span>2.13</span><span> µs </span><span>451.21</span><span> µs </span><span>651.67</span><span> µs</span></span>
<span><span>new</span><span> </span><span>Response</span><span>().</span><span>arrayBuffer</span><span>() (existing string, latin1)         </span><span>6.25</span><span> µs</span><span>/</span><span>iter</span><span>     (</span><span>5.79</span><span> µs … </span><span>6.81</span><span> µs)    </span><span>6.4</span><span> µs   </span><span>6.81</span><span> µs   </span><span>6.81</span><span> µs</span></span>
<span></span>
<span><span>Peak memory usage: </span><span>292</span><span> MB</span></span>
<span></span></code></pre></div><p><a href="https://github.com/oven-sh/bun/issues/3659"><code>#3659</code></a> A <strong>module resolution bug</strong> causing the <code>graphql</code> package to import both CommonJS and ESM versions of the same modules has been fixed. This was fixed by aligning the package.json main field order closer to what Node.js does.</p><div><pre><code><span><span>error: Cannot use GraphQLScalarType "String" from another module or realm.</span></span>
<span><span></span></span>
<span><span>Ensure that there is only one instance of "graphql" in the node_modules</span></span>
<span><span>directory. If different versions of "graphql" are the dependencies of other</span></span>
<span><span>relied on modules, use "resolutions" to ensure only one version is installed.</span></span>
<span><span></span></span>
<span><span>https://yarnpkg.com/en/docs/selective-version-resolutions</span></span>
<span><span></span></span>
<span><span>Duplicate "graphql" modules cannot be used at the same time since different</span></span>
<span><span>versions may have different capabilities and behavior. The data from one</span></span>
<span><span>version used in the function from another could produce confusing and</span></span>
<span><span>spurious results.</span></span>
<span><span></span></span></code></pre></div><p><a href="https://github.com/oven-sh/bun/pull/3663"><code>#3663</code></a> A <strong>bug in bun:test lifecycle hooks</strong> caused <code>beforeAll</code> and <code>afterAll</code> to not run when no tests were defined in a scope. This has been fixed.</p><p><a href="https://github.com/oven-sh/bun/issues/3670"><code>#3670</code></a> A <strong>bug when .env pointed to a directory</strong> caused Bun to crash. This has been fixed.</p><p><a href="https://github.com/oven-sh/bun/issues/3682"><code>#3682</code></a> A <strong>TypeScript parser bug related to ternaries with spread operators</strong> has been fixed</p><h3 level="3" anchor-id="changelog"><a name="changelog"></a><a href="#changelog">Changelog</a></h3><div><table><thead></thead><tbody><tr><td><a href="https://github.com/oven-sh/bun/pull/3253">#3253</a></td><td>feat(bun/test): Implement "bail" option for "bun test" by @TiranexDev</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3608">#3608</a></td><td>Improve our internal typedefs by @paperdave</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3257">#3257</a></td><td>Improvements to <code>WebSocket</code> and <code>ServerWebSocket</code> by @Electroid</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3630">#3630</a></td><td>$npm_lifecycle_event should have the value of the last call by @TiranexDev</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3631">#3631</a></td><td>Update docs/types for process by @colinhacks</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3637">#3637</a></td><td>structured clone by @dylan-conway</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3650">#3650</a></td><td>docs: add one missing line in typescript.md by @capaj</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3643">#3643</a></td><td>Fixes #3641 by @Jarred-Sumner</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3614">#3614</a></td><td>Support <code>napi_wrap</code> in constructors by @Jarred-Sumner</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3645">#3645</a></td><td>Implement Workers by @Jarred-Sumner</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3654">#3654</a></td><td>Fixes base64url encoding for crypto by @Jarred-Sumner</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3655">#3655</a></td><td>20% faster <code>deserialize</code> for structuredClone / postMessage with objects by @Jarred-Sumner</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3626">#3626</a></td><td>workaround <code>readable-stream</code> compatibility by @alexlamsl</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3662">#3662</a></td><td>[install] handle duplicated workspace declarations gracefully by @alexlamsl</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3664">#3664</a></td><td>package json <code>main</code> field extension order by @dylan-conway</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3596">#3596</a></td><td>[tls] General compatibility improvements by @cirospaciari</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3667">#3667</a></td><td>zig upgrade by @dylan-conway</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3671">#3671</a></td><td>fix(tls) patch checkServerIdentity by @cirospaciari</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3672">#3672</a></td><td>feature(constants) add constants/node:constants module and tests(prisma) use prima 5.0.0 + use same connection for postgres, add prisma mssql (disabled for now) by @cirospaciari</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3678">#3678</a></td><td>Better error for workspace dependency not found by @Jarred-Sumner</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3683">#3683</a></td><td>move constants module to cpp by @cirospaciari</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3687">#3687</a></td><td>fix #3682 by @dylan-conway</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3680">#3680</a></td><td>fix createDecipheriv by @cirospaciari</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3688">#3688</a></td><td>update root certificates and add tls.rootCertificates by @cirospaciari</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3089">#3089</a></td><td>Implement <code>AsyncLocalStorage</code> by @paperdave</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3693">#3693</a></td><td>Fix browser bundled string_decoder by @paperdave</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3694">#3694</a></td><td>Fix vite by @paperdave</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3698">#3698</a></td><td>Fixes #3670 by @Jarred-Sumner</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3697">#3697</a></td><td>Support streams in response.formData() &amp; request.formData, introduce Bun.readableStreamToFormData() by @Jarred-Sumner</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3706">#3706</a></td><td>Improve types for FFI number types by @colinhacks</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3707">#3707</a></td><td>fix start delay on Worker by @cirospaciari</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3709">#3709</a></td><td>set <code>_preload_modules</code> to empty array by @dylan-conway</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3708">#3708</a></td><td>fix 3702 by @dylan-conway</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3692">#3692</a></td><td>Pass constructor arguments to TextDecoder by @Parzival-3141</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3711">#3711</a></td><td>Fix builtins generator <code>$lazy</code> by @paperdave</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3710">#3710</a></td><td>fix directory caching with workaround by @paperdave</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3713">#3713</a></td><td>Fix builtins again by @paperdave</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3714">#3714</a></td><td>fix process.exit status code handling by @paperdave</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3715">#3715</a></td><td>fix <code>isFIFO</code> by @dylan-conway</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3717">#3717</a></td><td>string escape edgecase by @dylan-conway</td></tr></tbody></table></div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ElKaWe – Electrocaloric heat pumps (105 pts)]]></title>
            <link>https://www.fraunhofer.de/en/research/lighthouse-projects-fraunhofer-initiatives/fraunhofer-lighthouse-projects/elkawe.html</link>
            <guid>36823524</guid>
            <pubDate>Sat, 22 Jul 2023 05:20:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.fraunhofer.de/en/research/lighthouse-projects-fraunhofer-initiatives/fraunhofer-lighthouse-projects/elkawe.html">https://www.fraunhofer.de/en/research/lighthouse-projects-fraunhofer-initiatives/fraunhofer-lighthouse-projects/elkawe.html</a>, See on <a href="https://news.ycombinator.com/item?id=36823524">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		<p>In the ElKaWe lighthouse project, six Fraunhofer Institutes under the leadership of the Fraunhofer IPM are working on the development of electrocaloric heat pumps for heating and cooling. Today, heat pumps work almost exclusively on the basis of compressor technology. Electrocaloric heat pumps promise a significantly higher efficiency and do not require harmful refrigerants. As part of the project, scientists are developing ceramic and polymer-based electrocaloric materials and are working on an innovative system approach that enables particularly efficient heat dissipation. The work in the project is intended to demonstrate that electrocaloric heat pumps have the potential to replace compressors in the long term. Heat pumps are an important module in the heat revolution. Powered by regeneratively generated power, they form the missing link between power and heat generation. However, the increase in heat pumps for building air conditioning is slow, due to the poor economic efficiency of compressor-based heat pumps. In cooling technology, the gradual ban on refrigerants under the European F-Gas Regulations makes alternative, refrigerant-free technologies more desirable.</p> 
<h4>How does an electrocaloric heat pump work?</h4> 
<p>When an electrical field is applied to electrocaloric materials, the electrical dipole moments in the field are aligned – this additional order is accompanied by heating of the material according to thermodynamics laws. The resulting heat is dissipated via a heat sink, meaning the material cools down again to its initial temperature.&nbsp;If the electric field is now removed, order is reduced and the material cools, also in accordance with the laws of thermodynamics. Now it can absorb thermal energy from a heat source. The effect is reversible. This allows a cycle to be established that functions as an efficient heat pump for cooling or heating.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Compromised Microsoft Key: More Impactful Than We Thought (189 pts)]]></title>
            <link>https://www.wiz.io/blog/storm-0558-compromised-microsoft-key-enables-authentication-of-countless-micr</link>
            <guid>36823007</guid>
            <pubDate>Sat, 22 Jul 2023 03:40:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wiz.io/blog/storm-0558-compromised-microsoft-key-enables-authentication-of-countless-micr">https://www.wiz.io/blog/storm-0558-compromised-microsoft-key-enables-authentication-of-countless-micr</a>, See on <a href="https://news.ycombinator.com/item?id=36823007">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><a href="https://www.microsoft.com/en-us/security/blog/2023/07/14/analysis-of-storm-0558-techniques-for-unauthorized-email-access/">Microsoft</a> and <a href="https://www.cisa.gov/news-events/cybersecurity-advisories/aa23-193a">CISA</a> recently disclosed a security incident impacting multiple customers of Exchange Online and Outlook.com. According to Microsoft, this incident stemmed from a threat actor attributed to China, Storm-0558, acquiring a private encryption key (MSA key) and using it to forge access tokens for Outlook Web Access (OWA) and Outlook.com. Additionally, the threat actor reportedly exploited two security issues in Microsoft’s token verification process. </p><p>Microsoft have said that Outlook.com and Exchange Online were the only applications known to have been affected via the token forging technique, but Wiz Research has found that the compromised signing key was more powerful than it may have seemed, and was not limited to just those two services. Our researchers concluded that the compromised MSA key could have allowed the threat actor to forge access tokens for multiple types of Azure Active Directory applications, including every application that supports personal account authentication, such as SharePoint, Teams, OneDrive, customers’ applications that support the “login with Microsoft” functionality, and multi-tenant applications in certain conditions.</p><p>In addition, while Microsoft mitigated this risk by revoking the impacted encryption key and publishing <a href="https://www.microsoft.com/en-us/security/blog/2023/07/14/analysis-of-storm-0558-techniques-for-unauthorized-email-access/">attacker IOCs,</a> we discovered that it may be difficult for customers to detect the use of forged tokens against their applications due to lack of logs on crucial fields related to the token verification process.</p><p>Why is it so impactful?&nbsp; Identity provider’s signing keys are probably the most powerful secrets in the modern world.&nbsp; For example, they are much more powerful than TLS keys. Even if an attacker got access to the google.com TLS key, they would still need to somehow impersonate a google.com server to gain significant impact. With identity provider keys, one can gain immediate single hop access to everything, any email box, file service or cloud account. This isn’t a Microsoft specific issue, if a signing key for Google, Facebook, Okta or any other major identity provider leaks, the implications are hard to comprehend. Our industry – and especially cloud service providers – must commit to a greater level of security and transparency concerning how they protect critical keys such as this one, to prevent future incidents and limit their potential impact.&nbsp;</p><p>In this post, we will share how we were able to confirm which private key was acquired by the threat actor and how we determined its permissions. We will also unpack some of the technical aspects of this incident and help detect potential use of this compromised key within your environments.</p><h2><span></span><a id="compromised-consumer-signing-key--who-are-you-5"></a>Compromised consumer signing key – who are you?&nbsp;</h2><p>On July 11th, 2023, Microsoft revealed that a malicious actor had obtained an MSA consumer signing key, allowing them to forge access tokens for Exchange Online and Outlook.com accounts.</p><p>Determined to learn more about the incident, we launched an investigation.</p><p>First, we checked which keys could sign OpenID tokens for Microsoft accounts and Azure Active Directory applications. We therefore examined Microsoft’s <a href="https://learn.microsoft.com/en-us/azure/active-directory/develop/access-tokens#validating-tokens">official documentation for OpenID token verification</a>. Interestingly, we discovered that all Azure personal account v2.0 applications depend on a list of <a href="https://login.microsoftonline.com/consumers/discovery/v2.0/keys">8 public keys</a>, and all Azure multi-tenant v2.0 applications with Microsoft account enabled depend on a list of <a href="https://login.microsoftonline.com/common/discovery/v2.0/keys">7 public keys</a> (at the time of writing).</p><p>Using the Internet Archive’s Wayback Machine, we noticed that one of the listed public keys that had been present <a href="http://web.archive.org/web/20160801114452/https:/login.microsoftonline.com/common/discovery/v2.0/keys">since at least 2016</a> was replaced sometime between <a href="http://web.archive.org/web/20230627150747/https:/login.microsoftonline.com/common/discovery/v2.0/keys">June 27th</a> and <a href="http://web.archive.org/web/20230705095601/https:/login.microsoftonline.com/common/discovery/v2.0/keys">July 5th</a>, 2023, matching the time frame in which Microsoft replaced the acquired key according to their blog post.</p><p><em>Metadata of the public key replaced between June 27th and July 5th</em>&nbsp;</p><p>The old public key’s certificate revealed it was issued on April 5th, 2016, and expired on April 4th, 2021, and its thumbprint matched the thumbprint of the key Microsoft <a href="https://www.microsoft.com/en-us/security/blog/2023/07/14/analysis-of-storm-0558-techniques-for-unauthorized-email-access/#:~:text=d4b4cccda9228624656bff33d8110955779632aa">listed in their latest blog post</a>, named “Thumbprint of acquired signing key”:</p><div><p>The decoded certificate of the old key (1LTMzakihiRla_8z2BEJVXeWMqo). Obtained from the list intended June 27th, 2023 version of the certificate list for Azure common (mixed audience) applications.</p></div><p>This led us to believe that although the compromised key acquired by Storm-0558 was a private key designed for Microsoft's MSA tenant in Azure, it was also able to sign OpenID v2.0 tokens for multiple types of Azure Active Directory applications.</p><h2><span></span><a id="what-is-the-significance-of-a-compromised-openid-signing-key-16"></a>What is the significance of a compromised OpenID signing key?&nbsp;</h2><p>The Azure identity platform publishes multiple lists of trusted keys scoped to different application types. These serve to validate the integrity of tokens which are issued by Azure Active Directory (AAD). During the authentication process for an AAD application, the application must confirm the token's authenticity by verifying its signature against the correct trusted public key list. This verification determines whether the token should be trusted.</p><p># Azure Active Directory multi-tenant applications:&nbsp;<br></p><p><em>Azure Active Directory public certificates’ lists</em>&nbsp;</p><p>If any of the keys from one of these lists are compromised, there is a significant risk for applications using that list for validation. Such a compromise could enable unauthorized parties to forge valid access tokens for consumption by any application that depends on the Azure identity platform under certain conditions (see below).</p><div><p>The risks of compromised OpenID signing key </p></div><p>Based on what we can deduce from Microsoft’s blog post, Storm-0558 seemingly managed to obtain access to one of <a href="https://login.microsoftonline.com/common/discovery/v2.0/keys">several keys</a> that were intended for signing and verifying AAD access tokens. The compromised key was trusted to sign any OpenID v2.0 access token for personal accounts and mixed-audience (multi-tenant or personal account) AAD applications.</p><div><p>The types of applications that could trust the key acquired by Storm-0558</p></div><p>In other words, Storm-0558 could have theoretically used the private key it acquired to forge tokens to authenticate as any user to any affected application that trusts Microsoft OpenID v2.0 mixed audience and personal-accounts certificates.</p><h2><span></span><a id="which-applications-are-affected-27"></a>Which applications are affected?&nbsp;</h2><p>Based on our analysis, only Azure Active Directory applications that work with Microsoft’s OpenID v2.0 were affected. Version 1.0 applications were not using the compromised key for token validation and therefore were not affected.</p><h3><span></span><a id="applications-supporting-personal-microsoft-accounts-only-29"></a><strong>Applications supporting Personal Microsoft accounts only</strong></h3><p>Any Azure Active Directory application that supports “Personal Microsoft accounts only” and works against Microsoft’s v2.0 protocol was affected<strong>. This includes </strong>managed Microsoft applications, such as Outlook, SharePoint, OneDrive, and Teams, as well as customers’ applications that support Microsoft Account authentication, including those who allow the “Login with Microsoft” functionality.</p><h3><span></span><a id="applications-supporting-accounts-in-any-organizational-directory-any-azure-ad-directory--multi-tenant-and-personal-microsoft-accounts-eg-skype-xbox-31"></a><strong>Applications supporting accounts in any organizational directory (Any Azure AD directory – Multi-tenant) and personal Microsoft accounts (e.g. Skype, Xbox)</strong></h3><p>Any Azure Active Directory application that supported “mixed audience” and works against Microsoft’s v2.0 protocol was affected as well. The threat actor could forge valid access tokens and impersonate application users who signed in with their Personal Microsoft account.</p><p>To restrict the power of MSA keys in impersonating organizational accounts, Microsoft introduced an extension to the OpenID protocol. This extension advises developers to validate the issuer claim by comparing it with the issuer field in the list of the OpenID public keys. By doing this, it aims to prevent an MSA key from signing access tokens with an issuer different than the MSA tenant (9188040d-6c67-4c5b-b112-36a304b66dad). This extension is specific to Microsoft and the responsibility of its implementation rests with the application owner. Therefore, there is a concern that many applications lack this procedure and as a result, the threat actor could potentially impersonate organizational accounts as well (according to Microsoft’s blogpost, OWA was affected by a similar issue).</p><p>To assist Azure developers with adopting this validation functionality, Microsoft added it to their <a href="https://github.com/AzureAD/azure-activedirectory-identitymodel-extensions-for-dotnet/issues/2134">official Azure SDK</a> on July 12.</p><h3><span></span><a id="applications-supporting-accounts-in-any-organizational-directory-any-azure-ad-directory--multi-tenant-35"></a><strong>Applications supporting accounts in any organizational directory (Any Azure AD directory – Multi-tenant)</strong></h3><p>IIf the multi-tenant application is configured to rely on the “<a href="https://login.microsoftonline.com/common/discovery/v2.0/keys">common</a>” v2.0 keys endpoint (instead of “Organizations”), then it is affected but also should be considered misconfigured. The official Microsoft <a href="https://learn.microsoft.com/en-us/azure/active-directory/develop/access-tokens#validating-tokens">documentation</a> is not clear on when the “common” endpoint should be used, and therefore, some multi-tenant applications could be affected as well.</p><h3><span></span><a id="applications-supporting-accounts-in-this-organizational-directory-only-singletenant-37"></a><strong>Applications supporting accounts in this organizational directory only (Singletenant)</strong></h3><p>Single tenant applications were not affected.&nbsp;</p><div><p>How different types of users may have been affected depending on the application type and whether it was properly validating access tokens</p></div><h2><span></span><a id="how-does-key-forging-work-40"></a>How does key forging work?&nbsp;</h2><p>OpenID keys are fundamentally JWTs signed by an authorized private key. As part of the Azure Active Directory token validation procedure, the app developer must confirm that the key is indeed signed by the relevant authority for the intended scope, and that the token's <code>aud</code> field matches the targeted application’s scope.</p><p>To confirm whether the token was truly signed by a trusted Azure authority, the application developer queries a metadata endpoint (named <code>jwks_uri</code>) to pull the permitted certificates for signature verification and verify the token against it.</p><p>To forge a valid access token, the threat actor could have crafted a JWT token, populated it with a victim’s data (e.g. email address), and finally signed it with the trusted compromised key that is listed under the Azure Active Directory public certificates’ endpoint. By submitting the signed token to a targeted application, the malicious actor could have then impersonated the victim.</p><p>Here is a fictitious example of such a forged OpenID token signed by the compromised encryption key, <code>1LTMzakihiRla_8z2BEJVXeWMqo</code>:</p><p>According to Microsoft's guidelines, in order for the token to be considered valid, the issuer claim (<code>iss</code>) must be set to https: //sts.windows.net/9188040d-6c67-4c5b-b112-36a304b66dad/v2.0 since it was specified in the issuer field within the <code>jwks_uri</code> endpoint. As for the tenant ID claim (<code>tid</code>), it must accordingly be set to <code>9188040d-6c67-4c5b-b112-36a304b66dad</code>, the MSA tenant’s ID.</p><p>For AAD mixed-audience applications (multi-tenant and personal-account), any token signed by the MSA tenant for an Azure AD account could be deemed valid, as long as it impersonates a personal account.</p><p>For additional details, check out Microsoft's <a href="https://learn.microsoft.com/en-us/azure/active-directory/develop/access-tokens#validating-tokens">official guidelines</a> on how to verify ID Tokens.</p><h2><span></span><a id="are-azure-customers-still-at-risk-49"></a>Are Azure customers still at risk?&nbsp;</h2><p>Due to Microsoft's revocation of the compromised key, Azure Active Directory applications will no longer accept forged tokens as valid tokens. Tokens with extended expiration dates will also be rejected by these applications.</p><p>However, during previously established sessions with customer applications prior to the revocation, the malicious actor could have leveraged its access to establish persistence. This could have occurred by leveraging the obtained application permissions to issue application-specific access keys or setting up application-specific backdoors. A notable example of this is how, prior to Microsoft’s mitigation, Storm-0558 issued valid Exchange Online access tokens by forging access tokens for Outlook Web Access (OWA).</p><p>There is another potential risk to applications that retained copies of the AAD public keys prior to Microsoft's certificate revocation. Applications that rely on local certificate stores or cached keys and still trust the compromised key remain susceptible to token forgery. It is imperative for these applications to immediately refresh the list of trusted certificates. Microsoft advises refreshing the cache of local stores and certificates at least once a day.</p><h2><span></span><a id="recommendations-for-azure-users-53"></a>Recommendations for Azure users&nbsp;</h2><p>To identify whether a compromised key was used in your environment, identify all potentially affected applications in your environment, search for forged tokens usage (as explained in the next section) and leverage the Indicators of Compromise (IoCs) <a href="https://www.microsoft.com/en-us/security/blog/2023/07/14/analysis-of-storm-0558-techniques-for-unauthorized-email-access/#:~:text=Indicators%20of%20compromise">published by Microsoft</a> on their blog to look for any activity that originates from the IP addresses provided by Microsoft.</p><p>In addition, make sure that none of the applications use a cached version of the Microsoft OpenID public certificates, and if so, refresh the cache.</p><p>Microsoft has added additional verifications to the official Azure SDK, which are designed to prevent the use of MSA keys to authenticate to organization accounts. Users of the package are advised to update it to the <a href="https://github.com/AzureAD/azure-activedirectory-identitymodel-extensions-for-dotnet">latest version</a>.</p><h2><span></span><a id="how-to-detect-the-compromised-key-in-your-environment-57"></a>How to detect the compromised key in your environment&nbsp;</h2><p>Since the threat actor can forge access tokens offline, there is no trail in the Azure portal for token issuance. The only way for cloud customers to identify whether the key was used to target their apps or users is by reviewing application-specific logs for potentially affected AAD apps. Therefore, application owners who want to protect their systems will have to check whether a forged token has been used against their applications.</p><p>To the best of our knowledge, the only affected applications were those that utilized Microsoft v2.0 access token verification using the endpoints ”<a href="https://login.microsoftonline.com/common/discovery/v2.0/keyshttps:/login.microsoftonline.com/common/discovery/v2.0/keys%20common">https://login.microsoftonline.com/common/discovery/v2.0/keyscommon</a>“ and “<a href="https://login.microsoftonline.com/consumers/discovery/v2.0/keys">https://login.microsoftonline.com/consumers/discovery/v2.0/keys</a>“. These parameters make it feasible to filter out applications that were not exposed to this issue.&nbsp;</p><p>First, to identify which AAD applications in your environment might be affected, you can run the following Azure CLI command:&nbsp;</p><p>Additionally, your AAD applications might also be associated with Azure WebApps. To identify which AAD apps are redirecting to any of your WebApps, you can run the following CLI command:&nbsp;</p><p>Next, to identify potentially malicious activities in applications, it is necessary to examine suspicious authentication attempts via OpenID tokens signed by the compromised key. This can be done by unpacking the access tokens used against the application and searching for the string <code>1LTMzakihiRla_8z2BEJVXeWMqo</code> within the <code>kid</code> field of the JOSE Header.&nbsp;</p><p><a href="https://www.microsoft.com/en-us/security/blog/2023/07/14/analysis-of-storm-0558-techniques-for-unauthorized-email-access/#:~:text=inactive%20MSA">According to Microsoft</a>, the compromised key was inactive and therefore any access token signed by this key must be considered suspicious.</p><p>Unfortunately, there is a lack of standardized practices when it comes to application-specific logging. Therefore, in most cases, application owners do not have detailed logs containing the raw access token or its signing key. As a result, identifying and investigating such events can prove exceedingly challenging for app owners.</p><p>When examining an AAD application configured solely for multi-tenant authentication (without support for Microsoft personal accounts), it is possible to detect forged tokens by filtering for `iss` and `tid` claims within the access token. Applications commonly use these fields and they are more likely to be present in application logs. Moreover, any attempt to connect with an access token signed by the MSA tenant ID <code>9188040d-6c67-4c5b-b112-36a304b66dad</code> may indicate the use of a compromised key.</p><p>Finally, if you’ve enabled <a href="https://learn.microsoft.com/en-us/azure/azure-monitor/reference/tables/appservicehttplogs">HTTP Logs</a> in your WebApp, you might be able to see which IP addresses have accessed your application. Based on Microsoft’s blogpost, the following IP addresses are associated with the threat actor, so you should validate if your WebApp might have been impacted by running the following query in Log Analytics for each of your potentially affected Web Apps:&nbsp;</p><p>For additional guidance on searching for signs of persistence in your environment, see our <a href="https://www.wiz.io/blog/hunting-for-signs-of-persistence-in-the-cloud-an-ir-guide#hunting-for-signs-of-persistence-in-azure-24">“CircleCI Incident Sign of Persistence” blog</a>.&nbsp;</p><h2><span></span><a id="key-takeaways-72"></a>Key Takeaways&nbsp;</h2><p>The full impact of this incident is much larger than we Initially understood it to be. We believe this event will have long lasting implications on our trust of the cloud and the core components that support it, above all, the identity layer which is the basic fabric of everything we do in cloud. We must learn from it and improve.</p><p>At this stage, it is hard to determine the full extent of the incident as there were millions of applications that were potentially vulnerable, both Microsoft apps and customer apps, and the majority of them lack the sufficient logs to determine if they were compromised or not. However there are some critical actions items that application owners should perform. The first and foremost is to update their Azure SDK to the latest version and ensure their application cache is updated, otherwise their apps may still be vulnerable to a threat actor using the compromised key.</p><p>We will continue to closely monitor this incident and provide updates; this is still an ongoing investigation and there are many unanswered questions (how did the threat actor acquire the key? When exactly did it happen? Were other keys compromised as well?). Finally, we want to thank the Microsoft team for working closely with us on this blog and helping us ensure it is technically accurate.</p><div><div><p><span>See for yourself...</span></p><p>Learn what makes Wiz the platform to enable your cloud security operation</p></div><svg viewBox="0 0 162 177" fill="none" xmlns="http://www.w3.org/2000/svg"><g clip-path="url(#request-demo-block_svg__a)"><rect x="1" y="1.074" width="160" height="174" rx="2.5" fill="#fff"></rect><path fill="#0254EC" d="M1 1h160v22H1z"></path><g clip-path="url(#request-demo-block_svg__b)"><path d="M23.151 7.883c.202.21.593.315.825.36a.03.03 0 0 1 .017.011.032.032 0 0 1 .007.02.032.032 0 0 1-.007.02.03.03 0 0 1-.017.01c-.232.047-.623.152-.825.361-.19.197-.29.57-.337.815a.03.03 0 0 1-.011.018.029.029 0 0 1-.038-.001.031.031 0 0 1-.01-.019c-.034-.228-.123-.572-.354-.813-.202-.21-.593-.314-.825-.36a.03.03 0 0 1-.017-.01.032.032 0 0 1 0-.04.03.03 0 0 1 .017-.011c.233-.046.624-.15.825-.36.2-.21.302-.617.346-.859a.031.031 0 0 1 .01-.018.029.029 0 0 1 .038 0c.005.005.009.011.01.018.044.242.145.649.346.858Zm-8.61 1.626v6.395c0 .025.01.05.027.068a.09.09 0 0 0 .065.028h1.365a.09.09 0 0 0 .065-.028.098.098 0 0 0 .027-.068V9.509c0-.025-.01-.05-.027-.067a.09.09 0 0 0-.065-.028h-1.365a.089.089 0 0 0-.065.028.096.096 0 0 0-.027.067Zm2.132 6.367a.087.087 0 0 0 .034.113c.012.007.026.01.04.01h4.957a.09.09 0 0 0 .066-.027.098.098 0 0 0 .027-.068v-1.252a.098.098 0 0 0-.027-.068.093.093 0 0 0-.066-.028h-2.5a.08.08 0 0 1-.041-.01.087.087 0 0 1-.032-.115l2.6-4.892a.087.087 0 0 0-.002-.084.083.083 0 0 0-.03-.03.08.08 0 0 0-.04-.011h-4.91a.089.089 0 0 0-.066.027.099.099 0 0 0-.028.068v1.387a.1.1 0 0 0 .028.068.09.09 0 0 0 .066.028h2.18c.015 0 .029.003.041.01a.087.087 0 0 1 .034.113l-2.331 4.761Zm-2.706-6.463h-1.435a.09.09 0 0 0-.052.017.095.095 0 0 0-.033.045l-1.01 2.755a.034.034 0 0 1-.012.015.031.031 0 0 1-.037.002.033.033 0 0 1-.012-.015L10.17 9.494a.166.166 0 0 0-.056-.069.157.157 0 0 0-.081-.03h-.002a.157.157 0 0 0-.084.03.166.166 0 0 0-.057.07l-1.207 2.737a.033.033 0 0 1-.012.015.032.032 0 0 1-.036-.001.033.033 0 0 1-.012-.016l-1.01-2.755a.095.095 0 0 0-.034-.045.09.09 0 0 0-.052-.017H6.092a.09.09 0 0 0-.043.011.094.094 0 0 0-.033.031.099.099 0 0 0-.01.09l2.373 6.431a.032.032 0 0 0 .029.022.031.031 0 0 0 .019-.005.034.034 0 0 0 .012-.014l1.446-3.013a.166.166 0 0 1 .06-.069.157.157 0 0 1 .17 0c.027.017.047.04.06.069l1.446 3.013c.003.006.008.011.013.014a.032.032 0 0 0 .036-.001.035.035 0 0 0 .011-.016l2.372-6.432a.1.1 0 0 0-.01-.089.09.09 0 0 0-.076-.042Z" fill="#fff"></path></g><path fill="#fff" d="M-22 34h192v136H-22z"></path><path d="M111 45.416h21.6" stroke="url(#request-demo-block_svg__c)" stroke-linecap="round"></path><path d="M76.2 45.416h31.2" stroke="#FFAB31" stroke-linecap="round"></path><ellipse cx="142.2" cy="46.631" rx="9.6" ry="9.715" fill="#0073CF"></ellipse><path d="M145.674 37.96c-.022-.123-.043-.243 0-.363a.854.854 0 0 0-.059-.048 9.412 9.412 0 0 0-1.286-.393c-.402-.085-.801-.15-1.195-.195a9.608 9.608 0 0 0-.934-.045c-3.792 0-7.071 2.225-8.631 5.456.172.289.231.631.283.927.012.072.024.14.037.205.16.79.418 1.501.988 2.107.19.2.339.436.489.672.198.31.396.622.689.86.358.293.738.546 1.195.606 1.473.196 2.378 2.156 1.608 3.373-.244.386-.187.732.14 1.09a6.8 6.8 0 0 1 .546.712c.228.327.457.654.757.924.181.164.205.4.201.635a11.3 11.3 0 0 1-.16 1.68 9.534 9.534 0 0 0 2.264.174c-.011-.45.139-.77.627-.87a.993.993 0 0 0 .617-.462c.378-.611.917-1.05 1.466-1.483.443-.351.736-.789.8-1.37.07-.637 0-.737-.614-.808-.183-.021-.366-.038-.549-.054l-.28-.026c-.024-.003-.05-.004-.076-.006-.145-.01-.308-.02-.341-.152-.122-.488-.486-.64-.85-.793-.14-.059-.28-.117-.407-.195-.614-.375-1.249-.65-1.982-.733-.629-.07-1.387-.304-1.59-.86-.101-.276-.299-.47-.494-.662-.252-.249-.499-.491-.516-.895-.004-.131-.164-.291-.341-.28-.154.009-.163.127-.172.24a.797.797 0 0 1-.009.089c-.031.164-.077.324-.258.355-.21.033-.308-.133-.393-.289-.247-.455-.193-1.234.098-1.492.505-.444 1.246-.47 1.75-.055l.047.04c.077.07.155.14.268.1.164-.06.166-.22.153-.358-.033-.38.092-.683.36-.948.287-.282.429-.628.392-1.048-.022-.24.032-.504.332-.495.386.011.685-.164.989-.342.067-.04.135-.08.204-.117.273-.151.391-.276.251-.613-.151-.36.081-.642.485-.657.075-.002.15.008.225.018.081.011.161.022.241.017.225-.013.419-.144.483-.348.058-.193-.06-.21-.18-.228-.06-.009-.12-.017-.159-.047a2.994 2.994 0 0 0-.21-.144c-.12-.077-.24-.154-.336-.256-.319-.338-.697-.573-1.104-.782-.872-.448-1.536-.026-1.523.975.002.14.002.282-.004.422-.007.13-.048.25-.175.302-.153.062-.306-.002-.361-.131-.186-.437-.549-.652-.914-.868a7.05 7.05 0 0 1-.239-.145c-.387-.246-.387-.548-.081-.872.29-.306.601-.586.948-.824.175-.117.345-.237.402-.464.07-.268.188-.517.496-.537.238-.015.322.158.405.33.025.052.051.105.08.152.284.453.63.87 1.11 1.085.179.08.333-.028.493-.14.111-.078.224-.158.351-.18.142-.024.345-.064.332-.27-.013-.211-.208-.26-.38-.3a1.786 1.786 0 0 0-.09-.017.844.844 0 0 1-.164-.04c-.19-.078-.347-.207-.295-.436.051-.217.236-.293.444-.293.264-.002.461.14.631.324.122.133.241.27.359.405.25.287.501.574.778.83.544.504 1.234.357 1.521-.26.066-.142.041-.28.017-.417ZM150.261 41.353a9.749 9.749 0 0 1 1.539 5.278c0 .436-.028.866-.084 1.288a.311.311 0 0 1-.176.088 5.561 5.561 0 0 1-.115-.102c-.092-.082-.184-.165-.283-.236-.142-.1-.304-.128-.389.074l-.044.115c-.073.202-.149.412-.399.397l-.082-.004c-.343-.017-.693-.034-1.004-.273-1.036-.8-1.198-2.298-.483-3.188.096-.12.185-.278.199-.426.052-.666.526-.902 1.04-1.11.031-.013.062-.025.094-.036.082-.03.164-.061.24-.104.094-.054.162-.147.131-.265-.033-.12-.138-.148-.249-.14-.035.003-.07.009-.105.015a.905.905 0 0 1-.1.014c-.046.003-.093.008-.141.013-.221.024-.453.049-.563-.19-.093-.202.041-.27.179-.34.076-.038.154-.077.195-.14a7.55 7.55 0 0 1 .499-.61l.101-.118Z" fill="#71D96A"></path><path d="M139.704 46.19a.398.398 0 0 1 .112.014l.081.026h.001c.283.088.624.195.539.527-.05.194-.272.125-.481.06a1.659 1.659 0 0 0-.207-.056.56.56 0 0 1-.195-.073 1.113 1.113 0 0 0-.135-.061c-.144-.057-.294-.117-.256-.29.035-.165.18-.156.32-.148.06.004.118.007.167-.003l-.002.002.056.003ZM141.204 46.935a1.417 1.417 0 0 1-.142-.025l-.002-.002c-.029.004-.06.006-.091.008-.149.01-.307.02-.289.223.022.24.266.246.452.237.034-.001.073.002.114.005.157.012.336.025.319-.205-.014-.19-.192-.216-.361-.24Z" fill="#71D96A"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M105 39.344c-3.314 0-6 2.718-6 6.072 0 3.353 2.686 6.071 6 6.071s6-2.718 6-6.072c0-3.353-2.687-6.071-6-6.071ZM75 39.344c-3.314 0-6 2.718-6 6.072 0 3.353 2.686 6.071 6 6.071s6-2.718 6-6.072c0-3.353-2.687-6.071-6-6.071ZM136.2 113.42c-3.314 0-6 2.718-6 6.072 0 3.353 2.686 6.071 6 6.071s6-2.718 6-6.071c0-3.354-2.687-6.072-6-6.072Z" fill="#FFAB31"></path><path d="M45 87.919v25.501" stroke="url(#request-demo-block_svg__d)" stroke-linecap="round"></path><path d="M75 51.488c0 21.251-30 7.286-30 25.502" stroke="url(#request-demo-block_svg__e)" stroke-linecap="round"></path><path d="M45 87.918c0 21.251-30 7.286-30 25.501" stroke="url(#request-demo-block_svg__f)" stroke-linecap="round"></path><path d="M75 51.488c0 21.251 30 7.286 30 25.502" stroke="#FFAB31" stroke-linecap="round"></path><path d="M45 87.918c0 21.251 30 7.286 30 25.501" stroke="url(#request-demo-block_svg__g)" stroke-linecap="round"></path><path d="M105 87.918c0 21.251 31.2 7.286 31.2 25.501" stroke="#FFAB31" stroke-linecap="round"></path><path d="M136 126c0 21.667-30 7.429-30 26" stroke="url(#request-demo-block_svg__h)" stroke-linecap="round"></path><path d="M75 126c0 21.251 31.2 7.286 31.2 25.501" stroke="url(#request-demo-block_svg__i)" stroke-linecap="round"></path><path d="M79.8 81.846h20.4" stroke="url(#request-demo-block_svg__j)" stroke-linecap="round"></path><path d="M111 81.846h19.2" stroke="url(#request-demo-block_svg__k)" stroke-linecap="round"></path><path d="M70.2 81.846H51" stroke="url(#request-demo-block_svg__l)" stroke-linecap="round"></path><path d="M81 156h19.2" stroke="url(#request-demo-block_svg__m)" stroke-linecap="round"></path><path d="M69.2 156H50" stroke="url(#request-demo-block_svg__n)" stroke-linecap="round"></path><path d="M39 81.846H21" stroke="url(#request-demo-block_svg__o)" stroke-linecap="round"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M15 75.775c-3.314 0-6 2.718-6 6.072s2.686 6.072 6 6.072 6-2.718 6-6.072c0-3.353-2.687-6.072-6-6.072Z" fill="#FF1721"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M45 75.775c-3.314 0-6 2.718-6 6.072s2.686 6.072 6 6.072 6-2.718 6-6.072c0-3.353-2.687-6.072-6-6.072Z" fill="#3679DB"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M105 75.775c-3.314 0-6 2.718-6 6.072s2.686 6.072 6 6.072 6-2.718 6-6.072c0-3.353-2.687-6.072-6-6.072ZM75 150c-3.314 0-6 2.718-6 6.072 0 3.353 2.686 6.071 6 6.071s6-2.718 6-6.071c0-3.354-2.687-6.072-6-6.072ZM75 75.775c-3.314 0-6 2.718-6 6.072s2.686 6.072 6 6.072 6-2.718 6-6.072c0-3.353-2.687-6.072-6-6.072ZM45 150c-3.314 0-6 2.718-6 6.072 0 3.353 2.686 6.071 6 6.071s6-2.718 6-6.071c0-3.354-2.687-6.072-6-6.072ZM135 75.775c-3.314 0-6 2.718-6 6.072s2.686 6.072 6 6.072 6-2.718 6-6.072c0-3.353-2.687-6.072-6-6.072Z" fill="#FFAB31"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M105 150c-3.314 0-6 2.718-6 6.072 0 3.353 2.686 6.071 6 6.071s6-2.718 6-6.071c0-3.354-2.687-6.072-6-6.072ZM15 113.42c-3.314 0-6 2.718-6 6.072 0 3.353 2.686 6.071 6 6.071s6-2.718 6-6.071c0-3.354-2.687-6.072-6-6.072Z" fill="#71D96A"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M45 113.42c-3.314 0-6 2.718-6 6.072 0 3.353 2.686 6.071 6 6.071s6-2.718 6-6.071c0-3.354-2.687-6.072-6-6.072ZM75 113.42c-3.314 0-6 2.718-6 6.072 0 3.353 2.686 6.071 6 6.071s6-2.718 6-6.071c0-3.354-2.687-6.072-6-6.072Z" fill="#36AD82"></path></g><rect x="0.5" y="0.574" width="161" height="175" rx="3" stroke="#fff"></rect><defs><linearGradient id="request-demo-block_svg__c" x1="134.657" y1="45.416" x2="111.514" y2="45.416" gradientUnits="userSpaceOnUse"><stop stop-color="#0073CF"></stop><stop offset="1" stop-color="#FFAB31"></stop></linearGradient><linearGradient id="request-demo-block_svg__d" x1="0" y1="113.42" x2="0" y2="95.569" gradientUnits="userSpaceOnUse"><stop stop-color="#36AD82"></stop><stop offset="1" stop-color="#3679DB"></stop></linearGradient><linearGradient id="request-demo-block_svg__e" x1="45.001" y1="77.168" x2="60.065" y2="84.104" gradientUnits="userSpaceOnUse"><stop stop-color="#3679DB"></stop><stop offset="1" stop-color="#FFAB31"></stop></linearGradient><linearGradient id="request-demo-block_svg__f" x1="15.001" y1="113.598" x2="30.065" y2="120.534" gradientUnits="userSpaceOnUse"><stop stop-color="#71D96A"></stop><stop offset="1" stop-color="#3679DB"></stop></linearGradient><linearGradient id="request-demo-block_svg__g" x1="45" y1="87.918" x2="75.294" y2="113.065" gradientUnits="userSpaceOnUse"><stop stop-color="#3679DB"></stop><stop offset="1" stop-color="#36AD82"></stop></linearGradient><linearGradient id="request-demo-block_svg__h" x1="121" y1="134" x2="121" y2="144.5" gradientUnits="userSpaceOnUse"><stop stop-color="#FFAB31"></stop><stop offset="1" stop-color="#71D96A"></stop></linearGradient><linearGradient id="request-demo-block_svg__i" x1="90.6" y1="126" x2="90.6" y2="151.501" gradientUnits="userSpaceOnUse"><stop stop-color="#36AD82"></stop><stop offset="1" stop-color="#71D96A"></stop></linearGradient><linearGradient id="request-demo-block_svg__j" x1="79.8" y1="81.846" x2="103.037" y2="81.846" gradientUnits="userSpaceOnUse"><stop stop-color="#FFAB31"></stop><stop offset="1" stop-color="#FFAB31"></stop></linearGradient><linearGradient id="request-demo-block_svg__k" x1="111" y1="81.846" x2="130.2" y2="81.846" gradientUnits="userSpaceOnUse"><stop stop-color="#FFAB31"></stop><stop offset="1" stop-color="#FFAB31"></stop></linearGradient><linearGradient id="request-demo-block_svg__l" x1="70.327" y1="81.846" x2="48.457" y2="81.846" gradientUnits="userSpaceOnUse"><stop stop-color="#FFAB31"></stop><stop offset="1" stop-color="#3679DB"></stop></linearGradient><linearGradient id="request-demo-block_svg__m" x1="80.873" y1="156" x2="102.743" y2="156" gradientUnits="userSpaceOnUse"><stop stop-color="#FFAB31"></stop><stop offset="1" stop-color="#71D96A"></stop></linearGradient><linearGradient id="request-demo-block_svg__n" x1="69.327" y1="156" x2="47.457" y2="156" gradientUnits="userSpaceOnUse"><stop stop-color="#FFAB31"></stop><stop offset="1" stop-color="#FFAB31"></stop></linearGradient><linearGradient id="request-demo-block_svg__o" x1="37.925" y1="81.719" x2="21" y2="81.719" gradientUnits="userSpaceOnUse"><stop stop-color="#3679DB"></stop><stop offset="1" stop-color="#FF1721"></stop></linearGradient><clipPath id="request-demo-block_svg__a"><rect x="1" y="1.074" width="160" height="174" rx="2.5" fill="#fff"></rect></clipPath><clipPath id="request-demo-block_svg__b"><path fill="#fff" transform="translate(6 7)" d="M0 0h18v9H0z"></path></clipPath></defs></svg></div><h2><span></span><a id="references-77"></a>References&nbsp;</h2><ul><li><p><a href="https://msrc.microsoft.com/blog/2023/07/microsoft-mitigates-china-based-threat-actor-storm-0558-targeting-of-customer-email/">https://msrc.microsoft.com/blog/2023/07/microsoft-mitigates-china-based-threat-actor-storm-0558-targeting-of-customer-email/</a>&nbsp;</p></li><li><p><a href="https://www.cisa.gov/news-events/cybersecurity-advisories/aa23-193a">https://www.cisa.gov/news-events/cybersecurity-advisories/aa23-193a</a>&nbsp;</p></li><li><p><a href="https://blogs.microsoft.com/on-the-issues/2023/07/11/mitigation-china-based-threat-actor/">https://blogs.microsoft.com/on-the-issues/2023/07/11/mitigation-china-based-threat-actor/</a>&nbsp;</p></li><li><p><a href="https://www.microsoft.com/en-us/security/blog/2023/07/14/analysis-of-storm-0558-techniques-for-unauthorized-email-access/">https://www.microsoft.com/en-us/security/blog/2023/07/14/analysis-of-storm-0558-techniques-for-unauthorized-email-access/</a>&nbsp;</p></li><li><p><a href="https://github.com/AzureAD/azure-activedirectory-identitymodel-extensions-for-dotnet/pull/2136/files">https://github.com/AzureAD/azure-activedirectory-identitymodel-extensions-for-dotnet/pull/2136/files</a>&nbsp;</p></li><li><p><a href="https://github.com/MicrosoftDocs/azure-docs/commit/f17445bb9202a89964ea7311c4374806adfcb28c">https://github.com/MicrosoftDocs/azure-docs/commit/f17445bb9202a89964ea7311c4374806adfcb28c</a>&nbsp;</p></li></ul></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Internet search tips (105 pts)]]></title>
            <link>https://gwern.net/search</link>
            <guid>36822880</guid>
            <pubDate>Sat, 22 Jul 2023 03:22:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gwern.net/search">https://gwern.net/search</a>, See on <a href="https://news.ycombinator.com/item?id=36822880">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page-metadata">
        <p>A description of advanced tips and tricks for effective Internet research of papers/​books, with real-world examples.</p>
        
        
      </div><div id="markdownBody">
        <div>
          <blockquote>
            <p>Over time, I developed a certain google-fu and expertise in finding references, papers, and books online. Some of these tricks are not well-known, like checking the Internet Archive (IA) for books.</p>
            <p>I try to write down my search workflow, and give general advice about finding and hosting documents, with <a href="#case-studies">demonstration case studies</a>⁠.</p>
          </blockquote>
        </div>
        <p>Google-fu search skill is something I’ve prided myself ever since elementary school, when the librarian challenged the class to find things in the almanac; not infrequently, I’d win. And I can still remember the exact moment it dawned on me in high school that much of the rest of my life would be spent dealing with searches, paywalls, and broken links. The Internet is the greatest almanac of all, and to the curious, a never-ending cornucopia, so I am sad to see many fail to find things after a cursory search—or not look at all. For most people, if it’s not the first hit in Google/​Google Scholar, it doesn’t exist. Below, I reveal my best Internet search tricks and try to provide a rough flowchart of how to go about an online search, explaining the subtle tricks and <a href="https://en.wikipedia.org/wiki/Tacit_knowledge" data-link-icon="wikipedia" data-link-icon-type="svg">tacit knowledge</a> of search-fu.</p>
        <p>Roughly, we need to have proper tools to create an occasion for a search: we cannot search well if we avoid searching at all. Then each search will differ by which search engine &amp; type of medium we are searching—they all have their own quirks, blind spots, and ways to modify a failed search. Often, we will run into walls, each of which has its own circumvention methods. But once we have <em>found</em> something, we are not done: we would often be foolish &amp; short-sighted if we did not then make sure it <em>stayed</em> found. Finally, we might be interested in advanced topics like ensuring in advance resources can be found in the future if need be, or learning about new things we might want to then go find. To illustrate the overall workflow &amp; provide examples of tacit knowledge, I include many Internet case studies of finding hard-to-find things.</p>
        <section id="papers">
          <h2><a href="#papers" title="Link to section: § 'Papers'">Papers</a></h2>
          <section id="search">
            <h2><a href="#search" title="Link to section: § 'Search'">Search</a></h2>
            <section id="preparation">
              <h3><a href="#preparation" title="Link to section: § 'Preparation'">Preparation</a></h3>
              <p><span>Do or do not; there is no try.</span> The first thing you must do is develop a habit of searching when you have a question: “Google is your friend.” Your only search guaranteed to fail is the one you never run. ( <a href="https://www.lesswrong.com/posts/reitXJgJXFzKpdKyd/beware-trivial-inconveniences" id="alexander-2009-trivial-inconveniences" data-link-icon="LW" data-link-icon-type="text" title="'Beware Trivial Inconveniences', Alexander 2009">Beware trivial inconveniences!</a>)</p>
              <ol>
                <li>
                  <p><strong>Query Syntax Knowledge</strong></p>
                  <p>Know your basic <a href="https://en.wikipedia.org/wiki/Logical_connective" data-link-icon="wikipedia" data-link-icon-type="svg">Boolean operators</a> &amp; the <a href="https://support.google.com/websearch/answer/2466433" data-link-icon="alphabet" data-link-icon-type="svg">key G search operators</a>: double quotes for exact matches, hyphens for negation/​exclusion, and <code>site:</code> for search a specific website or specific directory of that website (eg. <code>foo site:gwern.net/docs/genetics/</code>, or to exclude folders, <code>foo site:gwern.net -site:gwern.net/docs/</code>). You may also want to play with <a href="https://gwern.net/doc/www/www.google.com/ad76c5678e80cfed004ec8c7d6704944cee44b28.html" data-link-icon="alphabet" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://www.google.com/advanced_search" title="(Original URL: https://www.google.com/advanced_search )">Advanced Search</a> to understand what is possible. (There are <a href="https://gwern.net/doc/www/ahrefs.com/dc5e68b27bd732a5613f29f62ee9596826aaafc8.html" data-link-icon="alphabet" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://ahrefs.com/blog/google-advanced-search-operators/" title="(Original URL: https://ahrefs.com/blog/google-advanced-search-operators/ )">many more G search operators</a> ( <a href="https://docs.google.com/document/d/1ydVaJJeL1EYbWtlfj9TPfBTE5IBADkQfZrQaBZxqXGs/mobilebasic" data-link-icon="worddoc" data-link-icon-type="svg" title="Google's Advanced Search Operators">Russell description</a>) but they aren’t necessarily worth learning, because they implement esoteric functionality and most seem to be buggy<a href="#fn1" id="fnref1" role="doc-noteref"><sup>1</sup></a>⁠.)</p>
                </li>
                <li>
                  <p><strong>Hotkey Shortcuts</strong> (<em>strongly recommended</em>)</p>
                  <p>Enable some kind of hotkey search with both prompt and copy-paste selection buffer, to turn searching Google (G)/​Google Scholar (GS)/​Wikipedia (WP) into a reflex.<a href="#fn2" id="fnref2" role="doc-noteref"><sup>2</sup></a> You should be able to search instinctively within a split second of becoming curious, with a few keystrokes. (If you can’t use it while IRCing without the other person noting your pauses, it’s not fast enough.)</p>
                  <p>Example tools: <a href="https://en.wikipedia.org/wiki/AutoHotkey#Examples" data-link-icon="wikipedia" data-link-icon-type="svg">AutoHotkey</a> (Windows), <a href="https://en.wikipedia.org/wiki/Quicksilver_(software)" data-link-icon="wikipedia" data-link-icon-type="svg">Quicksilver</a> (Mac), <a href="https://github.com/astrand/xclip" data-link-icon="github" data-link-icon-type="svg">xclip</a>+<a href="https://web.archive.org/web/20220427164018/https://en.wikipedia.org/wiki/Surfraw" data-link-icon="internetarchive" data-link-icon-type="svg">Surfraw</a>⁠/ ​<a href="https://en.wikipedia.org/wiki/StumpWM" data-link-icon="wikipedia" data-link-icon-type="svg">StumpWM’s</a> <a href="https://github.com/stumpwm/stumpwm-contrib/blob/master/util/searchengines/README.org" data-link-icon="github" data-link-icon-type="svg"><code>search-engines</code></a>⁠/ ​<a href="https://en.wikipedia.org/wiki/Xmonad" data-link-icon="wikipedia" data-link-icon-type="svg">XMonad’s</a> <a href="https://hackage.haskell.org/package/xmonad-contrib-0.15/docs/XMonad-Actions-Search.html" data-link-icon="𝛌" data-link-icon-type="text"><code>Actions.Search</code></a>⁠/ ​<a href="https://hackage.haskell.org/package/xmonad-contrib-0.15/docs/XMonad-Prompt-Shell.html" data-link-icon="𝛌" data-link-icon-type="text"><code>Prompt.Shell</code></a> (Linux). <a href="https://duckduckgo.com/bangs#bangs-list">DuckDuckGo</a> offers <a href="https://duckduckgo.com/bang_lite.html">‘bangs’</a>⁠, within-engine special searches (most are equivalent to a kind of Google <code>site:</code> search), which can be used similarly or combined with prompts/​macros/​hotkeys.</p>
                  <p><a href="https://wiki.haskell.org/Xmonad/Config_archive/Gwern's_xmonad.hs" data-link-icon="code" data-link-icon-type="svg">I make</a> heavy use of the XMonad hotkeys, which I wrote, and which gives me window manager shortcuts: while using any program, I can highlight a title string, and press <code>Super-shift-y</code> to open the current selection as a GS search in a new Firefox tab within an instant; if I want to edit the title (perhaps to add an author surname, year, or keyword), I can instead open a prompt, <code>Super-y</code>, paste with <code>C-y</code>, and edit it before a <code>\n</code> launches the search. As can be imagined, this is extremely helpful for searching for many papers or for searching. (There are in-browser equivalents to these shortcuts but I disfavor them because they only work if you are in the browser, typically require more keystrokes or mouse use, and don’t usually support hotkeys or searching the copy-paste selection buffer: <a href="https://support.mozilla.org/en-US/kb/keyboard-shortcuts-perform-firefox-tasks-quickly" data-link-icon="FF" data-link-icon-type="text,sans">Firefox</a>⁠, <a href="https://support.google.com/chrome/answer/157179" data-link-icon="alphabet" data-link-icon-type="svg" title="Chrome keyboard shortcuts: Learn keyboard shortcuts and become a pro at using Chrome">Chrome</a>)</p>
                </li>
                <li>
                  <p><strong>Web Browser Hotkeys</strong></p>
                  <p>For navigating between sets of results and entries, you should have good command of your tabbed web browser. You should be able to go to the address bar, move left/​right in tabs, close tabs, open new blank tabs, unclose tabs, go to the <em>n</em><sup>th</sup> tab, etc. (In <a href="https://support.mozilla.org/en-US/kb/keyboard-shortcuts-perform-firefox-tasks-quickly" data-link-icon="FF" data-link-icon-type="text,sans">Firefox</a>⁠/ ​<a href="https://support.google.com/chrome/answer/157179" data-link-icon="alphabet" data-link-icon-type="svg" title="Chrome keyboard shortcuts: Learn keyboard shortcuts and become a pro at using Chrome">Chrome</a> Win/​Linux, those are, respectively: <code>C-l</code>, <code>C-PgUp</code>/​<code>C-PgDwn</code>, <code>C-w</code>, <code>C-t</code>/​<code>C-T</code>, <code>M-[1–9]</code>.)</p>
                </li>
              </ol>
            </section>
            <section id="searching">
              <h3><a href="#searching" title="Link to section: § 'Searching'">Searching</a></h3>
              <p>Having launched your search in, presumably, Google Scholar, you must navigate the GS results. For GS, it is often as simple as clicking on the <code>[PDF]</code> or <code>[HTML]</code> link in the top right which denotes (what GS believes to be) a fulltext link, eg:</p>
              <figure>
                <img alt="An example of a hit in Google Scholar: note the [HTML] link indicating there is a fulltext Pubmed version of this paper (often overlooked by newbies)." decoding="async" height="387" loading="lazy" src="https://gwern.net/doc/technology/google/gwern-googlescholar-search-highlightfulltextlink.png" width="1400">
                
              </figure>
              <p><span>GS: if no fulltext in upper right, look for soft walls.</span> In GS, remember that a fulltext link is <em>not</em> always denoted by a “[PDF]” link! Check the top hits by hand: there are often ‘soft walls’ which block web spiders but still let you download fulltext (perhaps after substantial hassle, like SSRN).</p>
              <p>Note that GS supports other useful features like alerts for search queries, alerts for anything citing a specific paper, and reverse citation searches (to followup on a paper to look for failures-to-replicate or criticisms of it).</p>
              <section id="drilling-down">
                <h4><a href="#drilling-down" title="Link to section: § 'Drilling Down'">Drilling Down</a></h4>
                <p>A useful hit may not turn up immediately. Life is like that.<a href="#fn3" id="fnref3" role="doc-noteref"><sup>3</sup></a> You may have to get creative:</p>
                <ul>
                  <li>
                    <p><strong>Title searches</strong>: if a paper fulltext doesn’t turn up on the first page, start tweaking (hard rules cannot be given for this, it requires development of <a href="https://en.wikipedia.org/wiki/Tacit_knowledge" data-link-icon="wikipedia" data-link-icon-type="svg">“mechanical sympathy”</a> and asking a mixture of “how would a machine think to classify this” and “how would other people think to write this”):</p>
                  </li>
                  <li>
                    <p><strong>The Golden Mean</strong>: Keep mind when searching, you want some but not too many or too few results. A few hundred hits in GS is around the sweet spot. If you have less than a page of hits, you have made your search too specific.</p>
                    <p>If nothing is turning up, try trimming the title. Titles tend to have more errors towards the end than the beginning, and people often drop So start cutting words off the end of the title to broaden the search. Think about what kinds of errors you make when you recall titles: you drop punctuation or subtitles, substitute in more familiar synonyms, or otherwise simplify it. (How might OCR software screw up a title?)</p>
                    <p>Pay attention to technical terms that pop up in association with your own query terms, particularly in the snippets or full abstracts. Which ones look like they might be more popular than yours, or indicate yours are usually used slightly different from you think they mean? You may need to switch terms.</p>
                    <p>If deleting a few terms then yields way too many hits, try to filter out large classes of hits with a negation <code>foo -bar</code>, adding as many as necessary; also useful is using OR clauses to open up the search in a more restricted way by adding in possible synonyms, with parentheses for group. This can get quite elaborate, and border on <a href="https://en.wikipedia.org/wiki/Google_hacking" data-link-icon="wikipedia" data-link-icon-type="svg">hacking</a>—I have on occasion resorted to search queries as baroque as <code>(foo OR baz) AND (qux OR quux) -bar -garply -waldo -fred</code> to the point where I hit search query length limits and CAPTCHA barriers.<a href="#fn4" id="fnref4" role="doc-noteref"><sup>4</sup></a> (By that point, it is time to consider alternate attacks.)</p>
                  </li>
                  <li>
                    <p><strong>Tweak The Title</strong>: quote the title; delete any subtitle; try the subtitle instead; be suspicious of any character which is not alphanumeric and if there are colons, split it into two title quotes (instead of searching <code>Foo bar: baz quux</code>, or <code>"Foo bar: baz quux"</code>, search <code>"Foo bar" "baz quux"</code>); swap their order.</p>
                  </li>
                  <li>
                    <p><strong>Tweak The Metadata</strong>:</p>
                    <ul>
                      <li>Add/​remove the year.</li>
                      <li>Add/​remove the first author’s surname. Try searching GS for <em>just</em> the author (<code>author:foo</code>).</li>
                    </ul>
                  </li>
                  <li>
                    <p><strong>Delete Odd Characters/​Punctuation</strong>:</p>
                    <p>Libgen had trouble with colons for a long time, and many websites still do (eg. <a href="https://en.wikipedia.org/wiki/Goodreads" data-link-icon="wikipedia" data-link-icon-type="svg">GoodReads</a>); I don’t know why colons in particular are such trouble, although hyphens/​em-dashes and any kind of quote or apostrophe or period are problematic too. Watch out for words which may be space-separated—if you want to find <a href="https://en.wikipedia.org/wiki/Arpad_Elo" data-link-icon="wikipedia" data-link-icon-type="svg">Arpad Elo’s</a> epochal <a href="https://gwern.net/doc/statistics/order/comparison/1978-elo-theratingofchessplayerspastandpresent.pdf" id="elo-1978" data-link-icon="pdf" data-link-icon-type="svg" title="'<em>The Rating of Chessplayers, Past and Present (Second Edition)</em>', Elo 1978"><em>The Rating of Chessplayers</em></a> in Libgen, you need to search “The Rating of Chess Players” instead! (This is also an example of why falling back to search by author is a good idea.)</p>
                  </li>
                  <li>
                    <p><strong>Tweak Spelling</strong>: Try alternate spellings of British/​American terms. This shouldn’t be necessary, but then, deleting colons or punctuation shouldn’t be necessary either.</p>
                  </li>
                  <li>
                    <p><strong>Check For Book Publication</strong>: many papers are published in the form of <em>book anthologies</em>, not journal articles. So look for the book if the paper is mysteriously abent.</p>
                    <p>A book will not necessarily turn up in GS and thus its constituent papers may not either; similarly, while SH does a good job of linking article paywalls to their respective book compilation in LG, it is far from infallible. If a paper was published in any kind of ‘proceeding’ or ‘conference’ or ‘series’ or anything with an ISBN, the paper may be absent from the usual places but the book readily available. It can be quite frustrating to be searching hard for a paper and realize the book was there in plain sight all along. (My suggestion in such cases for <a href="#post-finding">post-finding</a> is to cut out the relevant page range &amp; upload the paper for others to more easily find.)</p>
                  </li>
                  <li>
                    <p><strong>Use URLs</strong>: if you have a URL, try searching chunks of it, typically towards the end, stripping out dates and domain names.</p>
                  </li>
                  <li>
                    <p><strong>Date Search</strong>:</p>
                    <p>Use a search engine (eg. G/​GS) date range feature (in “Tools”) to search ±4 years: metadata can be wrong, publishing conventions can be odd (eg. a magazine published in ‘June’ may actually be published several months before or after), publishers can be <em>extremely</em> slow. This is particularly useful if you add a date constraint &amp; simultaneously loosen the search query to turn up the most temporally-relevant of what would otherwise be far too many hits. If this doesn’t turn up the relevant target, it might turn up related discussions or fixed citations, since most things are cited most shortly after publication and then vanish into obscurity.</p>
                    <figure>
                      <img alt="Click “Tools” on the far right to access date-range &amp; “verbatim” search modes in Google Search." decoding="async" height="842" loading="lazy" src="https://gwern.net/doc/technology/google/gwern-googlesearch-tools-daterange.png" width="1283">
                      
                    </figure>
                    <figure>
                      <img alt="The “verbatim” mode is useful for forcing more literal matching: without it, a search for “foobar” will insist on hits about music players, hiring contests, etc rather than the programming term itself." decoding="async" height="548" loading="lazy" src="https://gwern.net/doc/technology/google/gwern-googlesearch-tools-verbatim.png" width="1333">
                      
                    </figure>
                    <p>If a year is not specified, try to guess from the medium: popular media has heavy recentist bias &amp; prefers only contemporary research which is ‘news’, while academic publications go back a few more years; the style of the reference can give a hint as to how relatively old some mentioned research or writings is. Frequently, given the author surname and a reasonable guess at some research being a year or two old, the name + date-range + keyword in GS will be enough to find the paper.</p>
                    <ul>
                      <li>
                        <span>Consider errors</span>: typos are common. If nothing is showing up in the date-range despite a specific date, perhaps there was a typographic error. Even a diligent typist will occasionally copy metadata from a previous entry or type the same character twice or 2 characters in the wrong order, and for numbers, there is no spellcheck to help catch such errors. Authors <a href="https://gwern.net/leprechaun#citogenesis-how-often-do-researchers-not-read-the-papers-they-cite" id="gwern-leprechaun-citogenesis-how-often-do-researchers-not-read-the-papers-they-cite" title="'Leprechaun Hunting &amp; Citogenesis § Citogenesis: How Often Do Researchers Not Read The Papers They Cite?', Branwen 2014">frequently propagate bibliographic errors</a> without correcting them (demonstrating, incidentally, that they probably did not read the original and so any summaries should be taken with a grain of salt). Think about transpositions &amp; neighboring keys on a QWERTY keyboard: eg. a year like “1976” may actually be 1966, 1967, 1975, 1977, or 1986.
                      </li>
                    </ul>
                  </li>
                  <li>
                    <p><strong>Add Jargon</strong>: Add technical terminology which <em>might</em> be used by relevant papers; for example, if you are looking for an article on college admissions statistics, any such analysis would probably be using <a href="https://en.wikipedia.org/wiki/Logistic_regression" data-link-icon="wikipedia" data-link-icon-type="svg">logistic regression</a> and, even if they do not say “logistic regression” (in favor of some more precise yet unguessable term) would express their effects in terms of “odds”.</p>
                    <p>If you don’t know what jargon might be used, you may need to back off and look for a review article or textbook or WP page and spend some quality time reading. If you’re using the wrong term, period, nothing will help you; you can spend hours going through countless pages, but that won’t make the wrong term work. You may need to read through overviews until you finally recognize the skeleton of what you want under a completely different (and often rather obtuse) name. Nothing is more frustrating that <em>knowing</em> there must be a large literature on a topic (“Cowen’s Law”) but being unable to <em>find</em> it because it’s named something completely different from expected—and many fields have different names for the same concept or tool. (Occasionally people compile “Rosetta stones” to translate between fields: eg. <a href="https://gwern.net/doc/www/arxiv.org/999c2f28682d1581b2fa3d939a54c2c9bc05cad6.pdf" id="baez-stay-2009" data-link-icon="𝛘" data-link-icon-type="text" rel="archived alternate nofollow" data-url-original="https://ar5iv.labs.arxiv.org/html/0903.0340?fallback=original" title="Physics, Topology, Logic and Computation: A Rosetta Stone (Original URL: https://arxiv.org/abs/0903.0340 )"><span><span>Baez &amp; Stay</span><span>2009</span></span></a>⁠, <a href="https://gwern.net/doc/www/arxiv.org/e43cd8342289fecff435e5142a48f10bbdf8e849.pdf" id="bertsekas-2018" data-link-icon="𝛘" data-link-icon-type="text" rel="archived alternate nofollow" data-url-original="https://ar5iv.labs.arxiv.org/html/1804.04577?fallback=original" title="Feature-Based Aggregation and Deep Reinforcement Learning: A Survey and Some New Implementations (Original URL: https://arxiv.org/abs/1804.04577 )"><span><span>Bertsekas</span><span>2018</span></span></a>⁠, <a href="https://gwern.net/backstop#meta-learning-paradigms" id="gwern-backstop-meta-learning-paradigms"><span><span><span title="et al">Metz</span> <span>et al</span> <span>2018</span></span>’s Table 1</span></a>⁠. These are invaluable.)</p>
                  </li>
                  <li>
                    <p><strong>Even The Humble Have A Tale To Tell</strong>: Beware hastily dismissing ‘bibliographic’ websites as useless—they may have more than you think.</p>
                    <p>While a bibliographic-focused library site like <code>elibrary.ru</code> is (almost) always useless &amp; clutters up search results by hosting only the citation metadata but not fulltext, every so often I run into a peculiar foreign website (often Indian or Chinese) which happens to have a scan of a book or paper. (eg. <a href="https://gwern.net/doc/genetics/heritable/1954-darlington.pdf" id="darlington-1954" data-link-icon="pdf" data-link-icon-type="svg" title="Heredity and Environment"><span><span>Darlington</span><span>1954</span></span></a>⁠, which eluded me for well over half an hour until, taking the alternate approach of hunting its volume, I out of desperation clicked on an <a href="https://gwern.net/doc/www/krishikosh.egranth.ac.in/3df4adaed8ad670bbe2efc9d5ebbb928d4b073b2.html" rel="archived alternate nofollow" data-url-original="http://krishikosh.egranth.ac.in/handle/1/21169" title="(Original URL: http://krishikosh.egranth.ac.in/handle/1/21169 )">Indian index / ​library website</a> which… had it. Go figure.) Sometimes you have to check every hit, just in case.</p>
                  </li>
                  <li>
                    <p><strong>Search The Internet Archive</strong>:</p>
                    <p>The Internet Archive (IA) deserves special mention as a target because it has a remarkable assortment of scans &amp; uploads from all sorts of sources, including the aforementioned Indian/​Chinese libraries with more laissez-faire approaches. It also exposes OCR of them all. So not infrequently, a book may be available, or a paper exists in the middle of a scan of an entire journal volume, but the IA will be ranked very low in search queries and the snippet will be misleading due to bad OCR. A good search strategy is to drop the quotes around titles or excerpts and focus down to <code>site:archive.org</code> and check the first few hits by hand.</p>
                  </li>
                </ul>
                <section id="hard-cases">
                  <h5><a href="#hard-cases" title="Link to section: § 'Hard Cases'">Hard Cases</a></h5>
                  <p>If the basic tricks aren’t giving any hints of working, you will have to get serious. The title may be completely wrong, or it may be indexed under a different author, or not directly indexed at all, or hidden inside a database. Here are some indirect approaches to finding articles:</p>
                  <ul>
                    <li>
                      <p><strong>Reverse Citations</strong>: Take a look in GS’s “related articles” or “cited by” to find similar articles such as later versions of a paper which may be useful. (These are also good features to know about if you want to check things like “has this ever been replicated?” or are still figuring out the right jargon to search.)</p>
                    </li>
                    <li>
                      <p><strong>Anomalous Hits</strong>: Look for hints of hidden bibliographic connections and anomalous hits.</p>
                      <p>Does a paper pop up high in the search results which doesn’t <em>seem</em> to make sense, such as not containing your keywords in the displayed snippet? GS generally penalizes items which exist as simply bibliographic entries, so if one is ranked high in a sea of fulltexts, that should make you wonder why it is being prioritized. Similarly, for Google Books (GB): a book might be forbidden from displaying even snippets but rank high; that might be for a good reason—it may actually contain the fulltext hidden inside it, or something else relevant.</p>
                      <p>Likewise, you cannot trust metadata too much. The inferred or claimed title may be wrong, and a hit may be your desired target lurking in disguise.</p>
                    </li>
                    <li>
                      <p><strong>Compilation Files</strong>: Some papers can be found by searching for the volume or book title to find it indirectly, especially conference proceedings or anthologies; many papers <em>appear</em> to not be available online but are merely buried deep inside a 500-page PDF, and the G snippet listing is misleading.</p>
                      <p>Conferences are particularly complex bibliographically, so you may need to apply the same tricks as for page titles: drop parts, don’t fixate on the numbers, know that the authors or ISBN or ordering of “title:subtitle” can differ between sources, etc.</p>
                      
                    </li>
                    <li>
                      <p><strong>Search By Issue</strong>: Another approach is to look up the listing for a journal issue, and find the paper by hand; sometimes papers are listed in the journal issue’s online Table of Contents, but just don’t appear in search engines (‽). In particularly insidious cases, a paper may be digitized &amp; available—but lumped in with another paper due to error, or only as part of a catch-all file which contains the last 20 miscellaneous pages of an issue. Page range citations are particularly helpful here because they show where the overlap is, so you can download the suspicious overlapping ‘papers’ to see what they <em>really</em> contain.</p>
                      <p>Esoteric as this may sound, this has been a problem on multiple occasions. (I searched in vain for any hint of <a href="https://gwern.net/doc/psychology/animal/maze/1929-shepard.pdf" id="shepard-1929" data-link-icon="pdf" data-link-icon-type="svg" title="An Unexpected Cue in Maze Learning"><span><span>Shepard</span><span>1929</span></span></a>’s existence, half-convinced it was a typo for his 19<em>5</em>9 publication, until I turned to the raw journal scans. A particularly epic example was <a href="https://gwern.net/doc/genetics/heritable/1966-shockley.pdf" id="shockley-1966" data-link-icon="pdf" data-link-icon-type="svg" title="'Possible Transfer of Metallurgical and Astronomical Approaches to Problem of Environment versus Ethnic Heredity', Shockley 1966"><span><span>Shockley</span><span>1966</span></span></a> where after an hour of hunting, all I had was bibliographic echoes despite apparently being published in a high-profile, easily obtained, &amp; definitely digitized journal, <em>Science</em>—leaving me thoroughly baffled. I eventually looked up the ToC and inferred it had been hidden in a set of abstracts!<a href="#fn5" id="fnref5" role="doc-noteref"><sup>5</sup></a> Or a number of <a href="https://gwern.net/smpy" id="gwern-smpy" title="'SMPY Bibliography', Branwen 2018">SMPY</a> papers turned out to be split or merged with neighboring items in journal issues, and I had to fix them by hand.)</p>
                    </li>
                    <li>
                      <p><strong>Masters/​PhD Theses</strong>: sorry. It may be hopeless if it’s pre-2000. You may well find the citation and even an abstract, but actual fulltext…?</p>
                      <p>If you have a university proxy, you may be able to get a copy off <a href="https://en.wikipedia.org/wiki/ProQuest" data-link-icon="wikipedia" data-link-icon-type="svg">ProQuest</a> (specializing in US theses). If ProQuest does not allow a download but indexes it, that usually means it has a copy archived on microfilm/​microfiche, but no one has yet paid for a scan to be made; you can sign up without any special permission, and then purchase ProQuest scans for ~$43 (as of 2023), and that gives you a downloadable PDF. (They apparently scan non-digital works from their vast backlog only on request, so it’s almost like ransoming papers; which means that buying a scan makes it available to academic subscribers as part of the ProQuest database.)</p>
                      <p>Otherwise, you need full university ILL services<a href="#fn6" id="fnref6" role="doc-noteref"><sup>6</sup></a>⁠, and even that might not be enough (a surprising number of universities appear to restrict access only to the university students/​faculty, with the complicating factor of most theses being stored on microfilm).</p>
                    </li>
                    <li>
                      <p><strong><a href="https://en.wikipedia.org/wiki/Reverse_image_search" data-link-icon="wikipedia" data-link-icon-type="svg">Reverse Image Search</a></strong>: If images are involved, a reverse image search in Google Images or <a href="https://tineye.com/">TinEye</a> or <a href="https://en.wikipedia.org/wiki/Yandex_Search" data-link-icon="wikipedia" data-link-icon-type="svg">Yandex Search</a> can turn up important leads.</p>
                      <p><a href="https://en.wikipedia.org/wiki/Bellingcat" data-link-icon="wikipedia" data-link-icon-type="svg">Bellingcat</a> has a good guide by Aric Toller: <a href="https://gwern.net/doc/www/www.bellingcat.com/bd9929bbe1245e2647608c98c34b3ca746cdc0d7.html" id="toller-2019" rel="archived alternate nofollow" data-url-original="https://www.bellingcat.com/resources/how-tos/2019/12/26/guide-to-using-reverse-image-search-for-investigations/" title="'Guide To Using Reverse Image Search For Investigations', Toller 2019 (Original URL: https://www.bellingcat.com/resources/how-tos/2019/12/26/guide-to-using-reverse-image-search-for-investigations/ )">“Guide To Using Reverse Image Search For Investigations”</a>⁠. (Yandex image search appears to exploit face recognition, text OCR, and other capabilities Google Images will not, and bows less to copyright concerns.)</p>
                      <div>
                        <p>
                          Use Browser <strong>Page Info</strong> to Bypass Image Restrictions
                        </p><p>If you are having trouble downloading an image from a web page which is badly/​maliciously designed to stop you, use <a href="https://support.mozilla.org/en-US/kb/firefox-page-info-window" data-link-icon="FF" data-link-icon-type="text,sans">“View Page Info”’s</a> (<code>C-I</code>) “Media” tab ( <a href="https://gwern.net/doc/cs/2021-04-18-gwern-firefox-viewpageinfo-mediatab.png" data-link-icon="image" data-link-icon-type="svg" data-image-height="1421" data-image-width="1600" title="Screenshot of Firefox's 'View Page Info: Media' dialogue, showing all the images used on a web page for easy review &amp; download, bypassing any restrictions or obstacles the website may try to impose on the reader.">eg</a>), which will list the images in a page and let one download them directly.
                      </p></div>
                    </li>
                    <li>
                      <p><strong>Enemy Action</strong>: Is a page or topic not turning up in Google/​IA that you <em>know</em> ought to be there? Check the website’s <a href="https://en.wikipedia.org/wiki/Robots.txt" data-link-icon="wikipedia" data-link-icon-type="svg"><code>robots.txt</code></a> &amp; <a href="https://en.wikipedia.org/wiki/Sitemaps" data-link-icon="wikipedia" data-link-icon-type="svg">sitemap</a>⁠. While not as relevant as they used to be (due to increasing use of dynamic pages &amp; entities ignoring it), <code>robots.txt</code> can sometimes be relevant: key URLs may be excluded from search results, and overly-restrictive <code>robots.txt</code> can cause enormous holes in IA coverage, which may be impossible to fix (but at least you’ll know why).</p>
                    </li>
                    <li>
                      <p><strong>Patience</strong>: not every paywall can be bypassed immediately, and papers may be embargoed or proxies not immediately available.</p>
                      <p>If something is not available at the moment, it may become available in a few months. Use calendar reminders to check back in to see if an embargoed paper is available or if LG/​SH have obtained it, and whether to proceed to additional search steps like manual requests.</p>
                    </li>
                    <li>
                      <p><strong>Domain Knowledge-Specific Tips</strong>:</p>
                      <ul>
                        <li>
                          <p><span>Twitter</span>: Twitter is indexed in Google so web searches <em>may</em> turn up hits, but if you know any metadata, Twitter’s native search functions are still relatively powerful (although Twitter limits searches in many ways in order to drive business to its staggeringly-expensive ‘firehose’ &amp; historical analytics). Use of <a href="https://twitter.com/search-advanced?lang=en" data-link-icon="twitter" data-link-icon-type="svg">Twitter’s “advanced search”</a> interface, particularly the <code>from:</code> &amp; <code>to:</code> <a href="https://developer.twitter.com/en/docs/twitter-api/v1/rules-and-filtering/search-operators" data-link-icon="twitter" data-link-icon-type="svg">search query operators</a>⁠, can vastly cut down the search space. (Also of note: <code>list:</code>, <code>-filter:retweets</code>, <code>near:</code>, <code>url:</code>, &amp; <code>since:</code>/​<code>until:</code>.)</p>
                        </li>
                        <li>
                          <p><span>US federal courts</span>: US federal court documents can be downloaded off <a href="https://en.wikipedia.org/wiki/PACER_(law)" data-link-icon="wikipedia" data-link-icon-type="svg">PACER</a> after registration; it is pay-per-page ($0.10/​page) but users under a certain level each quarter (currently $15) have their fees waived, so if you are careful, you may not need to pay anything at all. There is a public mirror, called <a href="https://www.courtlistener.com/recap/" data-link-icon="PACR" data-link-icon-type="text,quad">RECAP</a>⁠, which can be searched &amp; downloaded from for free. If you fail to find a case in RECAP and must use PACER (as often happens for obscure cases), please install the <a href="https://en.wikipedia.org/wiki/Free_Law_Project#RECAP" data-link-icon="wikipedia" data-link-icon-type="svg">Firefox /  Chrome RECAP browser extension</a>⁠, which will copy anything you download into RECAP. (This can be handy if you realize later that you should’ve kept a long PDF you downloaded or want to double-check a docket.)</p>
                          <p>Navigating PACER can be difficult because it is an old &amp; highly specialized computer system which assumes you are a lawyer, or at least very familiar with PACER &amp; the American federal court system. As a rule of thumb, if you are looking up a particular case, what you want to do is to search for the first name &amp; surname (even if you have the case ID) for either criminal or civil cases as relevant, and pull up all cases which might pertain to an individual; there can be multiple cases, cases can hibernate for years, be closed, reopened as a different case number, etc. Once you have found the most active or relevant case, you want to look at the “docket”, and check the options to see <em>all</em> documents in the case. This will pull up a list of many documents as the case unfolds over time; most of these documents are legal bureaucracy, like rescheduling hearings or notifications of changed lawyers. You want the <em>longest</em> documents, as those are most likely to be useful. In particular, you want the “indictment”, the “criminal complaint”<a href="#fn7" id="fnref7" role="doc-noteref"><sup>7</sup></a>⁠, and any transcripts of trial testimony.<a href="#fn8" id="fnref8" role="doc-noteref"><sup>8</sup></a> Shorter documents, like 1–2pg entries in the docket, <em>can</em> be useful, but are much less likely to be useful unless you are interested in the exact details of how things like pre-trial negotiations unfold. So carelessly choosing the ‘download all’ option on PACER may blow through your quarterly budget without getting you anything interesting (and also may interfere with RECAP uploading documents).</p>
                          <p>There is no equivalent for state or county court systems, which are balkanized and use a thousand different systems (often privatized &amp; charging far more than PACER); those must be handled on a case by case basis. (Interesting trivia point: according to Nick Bilton’s account of the Silk Road 1 case, the FBI and other federal agencies in the SR1 investigation would deliberately steer cases into state rather than federal courts in order to hide them from the relative transparency of the PACER system. The use of multiple court systems can backfire on them, however, as in the case of SR2’s DoctorClu (see <a href="https://gwern.net/dnm-arrest" id="gwern-dnm-arrest" title="'DNM-related arrests, 2011–2015', Branwen 2012">the DNM arrest census</a> for details), where the local police filings revealed the use of hacking techniques to deanonymize SR2 <a href="https://en.wikipedia.org/wiki/Tor_(network)" data-link-icon="wikipedia" data-link-icon-type="svg">Tor</a> users, implicating CMU’s CERT center—details which were belatedly scrubbed from the PACER filings.)</p>
                        </li>
                        <li>
                          <p><span>charity financials</span>: for USA charity financial filings, do <code>Form 990 site:charity.com</code> and then check <a href="https://en.wikipedia.org/wiki/Candid_(organization)" data-link-icon="wikipedia" data-link-icon-type="svg">GuideStar</a> (eg. looking at <a href="https://gwern.net/girl-scouts" id="gwern-girl-scouts" title="'Girl Scouts &amp; Good Corporate Governance', Branwen 2011">Girl Scouts filings</a> or <a href="https://www.lesswrong.com/posts/PmrD2T6F82RkRkhQv/case-study-reading-edge-s-financial-filings" data-link-icon="LW" data-link-icon-type="text">“Case Study: Reading Edge’s financial filings”</a>). For UK charities, the <a href="https://en.wikipedia.org/wiki/Charity_Commission_for_England_and_Wales" data-link-icon="wikipedia" data-link-icon-type="svg">Charity Commission for England and Wales</a> may be helpful.</p>
                        </li>
                        <li>
                          <p><span>education research</span>: for anything related to education, do a site search of <a href="https://en.wikipedia.org/wiki/Education_Resources_Information_Center" data-link-icon="wikipedia" data-link-icon-type="svg">ERIC</a>⁠, which is similar to IA in that it will often have fulltext which is buried in the usual search results</p>
                        </li>
                        <li>
                          <p><span>Wellcome Library</span>: the <a href="https://wellcomecollection.org/">Wellcome Library</a> has many old journals or books digitized which are impossible to find elsewhere; unfortunately, their SEO is awful &amp; their PDFs are unnecessarily hidden behind click-through EULAs, so they will not show up normally in Google Scholar or elsewhere. If you see the Wellcome Library in your Google hits, check it out carefully.</p>
                        </li>
                        <li>
                          <p><span>magazines</span> (as opposed to scholarly or trade journals) are hard to get.</p>
                          <p>They are not covered in Libgen/​Sci-Hub, which outsource that to MagzDB; coverage is poor, however. An alternative is <a href="https://pdf-giant.top/" data-link-icon="pdf" data-link-icon-type="svg">pdf-giant</a>⁠. Particularly for pre-2000 magazines, one may have to resort to looking for old used copies on eBay. Some magazines are easier than others—I generally give up if I run into a <em>New Scientist</em> citation because it’s never worth the trouble.</p>
                        </li>
                      </ul>
                    </li>
                    <li>
                      <p><strong>Newspapers</strong>: like theses, tricky. I don’t know of any general solutions short of a LexisNexis subscription.<a href="#fn9" id="fnref9" role="doc-noteref"><sup>9</sup></a> An interesting resource for American papers is <a href="https://gwern.net/doc/www/chroniclingamerica.loc.gov/973fc0451da75b2330531f477d417fcc1328ad3f.html" rel="archived alternate nofollow" data-url-original="https://chroniclingamerica.loc.gov/newspapers/" title="(Original URL: https://chroniclingamerica.loc.gov/newspapers/ )">Chronicling America’s “Historic American Newspaper”</a> scans.</p>
                    </li>
                  </ul>
                </section>
              </section>
              <section id="by-quote-or-description">
                <h4><a href="#by-quote-or-description" title="Link to section: § 'By Quote or Description'">By Quote or Description</a></h4>
                <p>For quote/​description searches: if you don’t have a title and are falling back on searching quotes, try varying your search similarly to titles:</p>
                <ul>
                  <li>
                    <p><strong>Novel sentences</strong>: Try the easy search first—whatever looks most memorable or unique.</p>
                  </li>
                  <li>
                    <p><strong>Short quotes are unique</strong>: Don’t search too long a quote, a sentence or two is usually enough to be near-unique, and can be helpful in turning up other sources quoting different chunks which may have better citations.</p>
                    <ul>
                      <li><span>Break up quotes</span>: Because even phrases can be unique, try multiple sub-quotes from a big quote, especially from the beginning and end, which are likely to overlap with quotes which have prior or subsequent passages.</li>
                      <li><span>Odd idiosyncratic wording</span>: Search for oddly-specific phrases or words, especially numbers. 3 or 4 keywords is usually enough.</li>
                      <li><span>Paraphrasing</span>: Look for passages in the original text which seem like they might be based on the same source, particularly if they are simply dropped in without any hint at sourcing and don’t sound like the author; authors typically don’t cite every time they draw on a source, usually only the first time, and during editing the ‘first’ appearance of a source could easily have been moved to later in the text. All of these additional uses are something to add to your searches.</li>
                    </ul>
                  </li>
                  <li>
                    <p><strong>Robust Quotes</strong>: You are fighting a game of Chinese whispers, so look for unique-sounding sentences and terms which can survive garbling in the repeated transmissions.</p>
                    <p>Memories are urban legends told by one neuron to another over the years. Pay attention to how you mis-remember things: you distort them by simplifying them, rounding them to the nearest easiest version, and by adding in details which <em>should</em> have been there. Avoid phrases which could be easily reworded in multiple equivalent ways, as people usually will reword them when quoting from memory, screwing up literal searches. Remember the fallibility of memory and the basic principles of <a href="https://en.wikipedia.org/wiki/Textual_criticism" data-link-icon="wikipedia" data-link-icon-type="svg">textual criticism</a>: people substitute easy-to-remember versions for the <a href="https://en.wikipedia.org/wiki/Lectio_difficilior_potior" data-link-icon="wikipedia" data-link-icon-type="svg">hard</a>⁠, long<a href="#fn10" id="fnref10" role="doc-noteref"><sup>10</sup></a>⁠, or unusual original.</p>
                  </li>
                  <li>
                    <p><strong>Tweak Spelling</strong>: Watch out for punctuation and spelling differences hiding hits.</p>
                  </li>
                  <li>
                    <p><strong>Gradient Ascent</strong>: Longer, less witty versions are usually closer to the original and a sign you are on the right trail. The worse, the better. Sniff in the direction of worse versions. (Authors all too often fail to write what they were supposed to write—as Yogi Berra remarked, <a href="https://gwern.net/doc/www/quoteinvestigator.com/9901447988c3e611b2ff9a241679b89bcb56adad.html" rel="archived alternate nofollow" data-url-original="https://quoteinvestigator.com/2012/12/30/yogi-didnt-say/" title="(Original URL: https://quoteinvestigator.com/2012/12/30/yogi-didnt-say/ )">“I really didn’t say everything I said.”</a>)</p>
                  </li>
                  <li>
                    <p><strong>Search Books</strong>: Switch to GB and hope someone paraphrases or quotes it, and includes a real citation; if you can’t see the full passage or the reference section, look up the <em>book</em> in Libgen.</p>
                  </li>
                </ul>
                <section id="dealing-with-paywalls">
                  <h5><a href="#dealing-with-paywalls" title="Link to section: § 'Dealing With Paywalls'">Dealing With Paywalls</a></h5>
                  <div>
                    <blockquote>
                      <p>Gold once out of the earth is no more due unto it; What was unreasonably committed to the ground is reasonably resumed from it: Let Monuments and rich Fabricks, not Riches adorn mens ashes. The commerce of the living is not to be transferred unto the dead: It is not injustice to take that which none complains to lose, and no man is wronged where no man is possessor.</p>
                      <p><a href="https://en.wikipedia.org/wiki/Hydriotaphia,_Urn_Burial" data-link-icon="wikipedia" data-link-icon-type="svg"><em>Hydriotaphia, Urn Burial</em></a>⁠, Sir <a href="https://en.wikipedia.org/wiki/Thomas_Browne" data-link-icon="wikipedia" data-link-icon-type="svg">Thomas Browne</a></p>
                    </blockquote>
                  </div>
                  <p><span>Use Sci-Hub/​Libgen for books/​papers.</span> A paywall can usually be bypassed by using Libgen (LG)/​Sci-Hub (SH): <a href="http://libgen.rs/scimag/" data-link-icon="raven" data-link-icon-type="svg">papers</a> can be searched directly (ideally with the <a href="https://en.wikipedia.org/wiki/Digital_object_identifier" data-link-icon="wikipedia" data-link-icon-type="svg">DOI</a><a href="#fn11" id="fnref11" role="doc-noteref"><sup>11</sup></a>⁠, but title+author with no quotes will usually work), or an easier way may be to prepend<a href="#fn12" id="fnref12" role="doc-noteref"><sup>12</sup></a> <code>sci-hub.st</code> (or whatever SH mirror you prefer) to the URL of a paywall. Occasionally Sci-Hub will not have a paper or will persistently error out with some HTTP or proxy error, but searching the DOI in Libgen directly will work. Finally, there is a <a href="https://z-lib.is/fulltext">LibGen / Sci-Hub fulltext search engine</a> on the Z-Library mirror, which is a useful alternative to Google Books (despite the poor OCR).</p>
                  <p><span>Use university Internet.</span> If those don’t work and you do not have a university proxy or alumni access, many university libraries have IP-based access rules and also open WiFi or Internet-capable computers with public logins inside the library, which can be used, if you are willing to take the time to visit a university in person, for using their databases (probably a good idea to keep a list of needed items before paying a visit).</p>
                  <p><span>Public libraries too.</span> Public libraries often subscribe to commercial newspapers or magazine databases; they are inconvenient to get to, but you can usually at least check what’s available on their website. Public &amp; school libraries also have a useful trick for getting common schooling-related resources, such as the OED, or the archives of the <em>New York Times</em> or <em>New Yorker</em>: because of their usually unsophisticated &amp; transient userbase, some public &amp; school libraries will post lists of usernames/​passwords on their website (sometimes as a PDF). They shouldn’t, but they do. Googling phrases like “public library <a href="https://en.wikipedia.org/wiki/The_New_Yorker" data-link-icon="wikipedia" data-link-icon-type="svg">New Yorker</a> username password” can turn up examples of these. Used discreetly to fetch an article or two, it will do them no harm. (This trick works less well with passwords to anything else.)</p>
                  <p>If that doesn’t work, there is a more opaque ecosystem of filesharing services: booksc/​bookfi/​bookzz, private torrent trackers like Bibliotik, <a href="https://gwern.net/doc/www/old.reddit.com/f0d2bc439c217ff55bc7659a1ba27eb72ddd68e7.html" data-link-icon="reddit" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://old.reddit.com/r/Piracy/comments/2oftbu/guide_the_idiot_proof_guide_to_downloading_ebooks/" title="(Original URL: https://www.reddit.com/r/Piracy/comments/2oftbu/guide_the_idiot_proof_guide_to_downloading_ebooks/ )">IRC</a> channels with <a href="https://en.wikipedia.org/wiki/XDCC" data-link-icon="wikipedia" data-link-icon-type="svg">XDCC</a> bots like <code>#bookz</code>/​<a href="https://gwern.net/doc/www/ebooks.byethost6.com/49a1f20ea30a50b5e73e590542a13d11e7a1278f.html" rel="archived alternate nofollow" data-url-original="http://ebooks.byethost6.com/?i=1" title="(Original URL: http://ebooks.byethost6.com/?i=1 )"><code>#ebooks</code></a>⁠, old P2P networks like <a href="https://en.wikipedia.org/wiki/EMule" data-link-icon="wikipedia" data-link-icon-type="svg">eMule</a>⁠, private <a href="https://en.wikipedia.org/wiki/DC%2B%2B" data-link-icon="wikipedia" data-link-icon-type="svg">DC++</a> hubs…</p>
                  <p>Site-specific notes:</p>
                  <ul>
                    <li>
                      <p><strong>PubMed</strong>: most papers with a <a href="https://en.wikipedia.org/wiki/PubMed" data-link-icon="wikipedia" data-link-icon-type="svg">PMC</a> ID can be purchased through the Chinese scanning service <a href="https://eurekamag.com/">Eureka Mag</a>⁠; scans are $30 &amp; electronic papers are $20.</p>
                    </li>
                    <li>
                      <p><strong>Elsevier/​<code>sciencedirect.com</code></strong>: easy, always available via SH/​LG</p>
                      <p>Note that many Elsevier journal websites do not work with the SH proxy, although their <code>sciencedirect.com</code> version <em>does</em> and/​or the paper is already in LG. If you see a link to <code>sciencedirect.com</code> on a paywall, try it if SH fails on the journal website itself.</p>
                    </li>
                    <li>
                      <p><a href="https://en.wikipedia.org/wiki/PsycINFO" data-link-icon="wikipedia" data-link-icon-type="svg"><strong>PsycNET</strong></a>: one of the worst sites; SH/​LG never work with the URL method, rarely work with paper titles/​DOIs, and with my university library proxy, loaded pages ‘expire’ and redirect while breaking the browser back button (‽‽‽), combined searches don’t usually work (frequently failing to pull up even bibliographic entries), and only DOI or manual title searches in the EBSCOhost database have a chance of fulltext. (EBSCOhost itself is a fragile search engine which is difficult to query reliably in the absence of a DOI.)</p>
                      <p>Try to find the paper anywhere else besides PsycNET!</p>
                    </li>
                    <li>
                      <p><strong>ProQuest/​JSTOR</strong>: ProQuest/​JSTOR are not standard academic publishers, but have access to or mirrors of a surprisingly large number of publications.</p>
                      <p>I have been surprised how often I have hit deadends, and then discovered a copy sitting in ProQuest/​JSTOR, poorly-indexed by search engines.</p>
                    </li>
                    <li>
                      <p><strong>Custom journal websites</strong>: sometimes a journal will have its own website (eg. <em>Cell</em> or <em>Florida Tax Review</em>), but will still be ultimately run by one of the giants like Elsevier or HeinOnline. (You can often see hints of this in the site design, such as the footer, the URL structure, direct links to the publisher version, etc.)</p>
                      <p>When this is the case, it is usually a waste of time to try to use the journal website: it won’t whitelist university IPs, SH/​LG won’t know how to handle it, etc. Instead, look for the alternative version.</p>
                    </li>
                  </ul>
                </section>
              </section>
            </section>
          </section>
          <section id="request">
            <h2><a href="#request" title="Link to section: § 'Request'">Request</a></h2>
            <p><span>Human flesh search engine.</span> Last resort: if none of this works, there are a few places online you can request a copy (however, they will usually fail if you have exhausted all previous avenues):</p>
            <ul>
              <li>
                <a href="https://gwern.net/doc/www/old.reddit.com/53e945ba27eb68f361a04735673fcab833c8d5b6.html" data-link-icon="reddit" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://old.reddit.com/r/Scholar/" title="(Original URL: https://www.reddit.com/r/Scholar/ )"> / ​r / ​scholar</a>
              </li>
              <li>
                <a href="https://twitter.com/search?f=tweets&amp;vertical=default&amp;q=%23icanhazpdf&amp;src=typd" data-link-icon="twitter" data-link-icon-type="svg"><code>#icanhazpdf</code></a>
              </li>
              <li>
                <a href="https://en.wikipedia.org/wiki/Wikipedia:WikiProject_Resource_Exchange/Resource_Request" data-link-icon="wikipedia" data-link-icon-type="svg">Wikipedia Resource Request</a>
              </li>
              <li>
                <a href="https://www.lesswrong.com/posts/4sAsygakd4oCpbEKs/lesswrong-help-desk-free-paper-downloads-and-more-2014" data-link-icon="LW" data-link-icon-type="text" title="Free research help, editing and article downloads for LessWrong">LW help desk</a>
              </li>
            </ul>
            <p>Finally, you can always try to contact the author. This only occasionally works for the papers I have the hardest time with, since they tend to be old ones where the author is dead or unreachable—any author publishing a paper since 1990 will usually have been digitized <em>somewhere</em>—but it’s easy to try.</p>
          </section>
          <section id="post-finding">
            <h2><a href="#post-finding" title="Link to section: § 'Post-finding'">Post-finding</a></h2>
            <p>After finding a fulltext copy, you should find a reliable long-term link/​place to store it and make it more findable (remember—if it’s not in Google/​Google Scholar, it doesn’t exist!):</p>
            <ul>
              <li>
                <p><strong>Never Link Unreliable Hosts</strong>:</p>
                <ul>
                  <li>
                    <p><span>LG/​SH</span>: Always operate under the assumption they could be gone tomorrow. (As my uncle found out with Library.nu shortly after paying for a lifetime membership!) There are no guarantees either one will be around for long under their legal assaults or the behind-the-scenes dramas, and no guarantee that they are being properly mirrored or will be restored elsewhere.</p>
                    <p>When in doubt, make a copy. Disk space is cheaper every day. Download anything you need and keep a copy of it yourself and, ideally, host it publicly.</p>
                  </li>
                  <li>
                    <p><span>NBER</span>: never rely on a <code>papers.nber.org/tmp/</code> or <code>psycnet.apa.org</code> URL, as they are temporary. (SSRN is also undesirable due to making it increasingly difficult to download, but it is at least reliable.)</p>
                  </li>
                  <li>
                    <p><span>Scribd</span>: never link Scribd—they are a scummy website which impede downloads, and anything on Scribd usually first appeared elsewhere anyway. (In fact, if you run into anything vaguely useful-looking which exists only on Scribd, you’ll do humanity a service if you copy it elsewhere just in case.)</p>
                  </li>
                  <li>
                    <p><span>RG</span>: avoid linking to <a href="https://en.wikipedia.org/wiki/ResearchGate" data-link-icon="wikipedia" data-link-icon-type="svg">ResearchGate</a> (compromised by new ownership &amp; PDFs get deleted routinely, apparently often by authors) or <code>Academia.edu</code> (the URLs are one-time and break)</p>
                  </li>
                  <li>
                    <p><span>high-impact journals</span>: be careful linking to Nature.com or <a href="https://en.wikipedia.org/wiki/Cell_(journal)" data-link-icon="wikipedia" data-link-icon-type="svg"><em>Cell</em></a> (if a paper is not <em>explicitly</em> marked as Open Access, even if it’s available, it may disappear in a few months!<a href="#fn13" id="fnref13" role="doc-noteref"><sup>13</sup></a>); similarly, watch out for <code>wiley.com</code>, <code>tandfonline.com</code>, <code>jstor.org</code>, <code>springer.com</code>, <code>springerlink.com</code>, &amp; <code>mendeley.com</code>, who pull similar shenanigans.</p>
                  </li>
                  <li>
                    <p><code>~/</code>: be careful linking to academic personal directories on university websites (often noticeable by the <a href="https://en.wikipedia.org/wiki/Unix" data-link-icon="wikipedia" data-link-icon-type="svg">Unix</a> convention <code>.edu/~user/</code> or by directories suggestive of ephemeral hosting, like <code>.edu/cs/course112/readings/foo.pdf</code>); they have short half-lives.</p>
                  </li>
                  <li>
                    <p><code>?token=</code>: beware any PDF URL with a lot of trailing garbage in the URL such as query strings like <code>?casa_token</code> or <code>?cookie</code> or <code>?X</code> (or hosted on S3/​AWS); such links may or may not work for other people but will surely stop working soon. (Academia.edu, Nature, and Elsevier are particularly egregious offenders here.)</p>
                  </li>
                </ul>
              </li>
              <li>
                <p><strong>PDF Editing</strong>: if a scan, it may be worth editing the PDF to crop the edges, threshold to binarize it (which, for a bad grayscale or color scan, can drastically reduce filesize while increasing readability), and OCR it.</p>
                <p>I use <a href="https://gscan2pdf.sourceforge.net/" id="ratcliffe-2019" title="'gscan2pdf: A GUI to produce PDFs or DjVus from scanned documents', Ratcliffe 2019">gscan2pdf</a> but there are alternatives worth checking out.</p>
              </li>
              <li>
                <p><strong>Check &amp; Improve Metadata</strong>.</p>
                <p>Adding metadata to papers/​books is a good idea because it makes the file findable in G/​GS (if it’s not online, does it really exist?) and helps you if you decide to use bibliographic software like <a href="https://en.wikipedia.org/wiki/Zotero" data-link-icon="wikipedia" data-link-icon-type="svg">Zotero</a> in the future. Many academic publishers &amp; LG are terrible about metadata, and will not include even title/​author/​DOI/​year.</p>
                <p>PDFs can be easily annotated with metadata using <a href="https://en.wikipedia.org/wiki/ExifTool" data-link-icon="wikipedia" data-link-icon-type="svg">ExifTool</a>:: <code>exiftool -All</code> prints all metadata, and the metadata can be set individually using similar fields.</p>
                <p>For papers hidden inside volumes or other files, you should extract the relevant page range to create a single relevant file. (For extraction of PDF page-ranges, I use <a href="https://en.wikipedia.org/wiki/PDFtk" data-link-icon="wikipedia" data-link-icon-type="svg"><code>pdftk</code></a>⁠, eg: <code>pdftk 2010-davidson-wellplayed10-videogamesvaluemeaning.pdf cat 180-196 output 2009-fortugno.pdf</code>. Many publishers insert a spam page as the first page. You can drop that easily with <code>pdftk INPUT.pdf cat 2-end output OUTPUT.pdf</code>, but note that PDFtk may drop all metadata, so do that before adding any metadata. To delete pseudo-encryption or ‘passworded’ PDFs, do <code>pdftk INPUT.pdf input_pw output OUTPUT.pdf</code>; PDFs using actual encryption are trickier but <a href="#astronomy">can often be beaten</a> by off-the-shelf password-cracking utilities.)</p>
                <p>I try to set at least title/​author/​DOI/​year/​subject, and stuff any additional topics &amp; bibliographic information into the “Keywords” field. Example of setting metadata:</p>
                <div id="cb1">
                  <pre><code><span id="cb1-1"><span>exiftool</span> <span>-Author</span><span>=</span><span>"Frank P. Ramsey"</span> <span>-Date</span><span>=</span>1930 <span>-Title</span><span>=</span><span>"On a Problem of Formal Logic"</span> <span>-DOI</span><span>=</span><span>"10.1112/plms/s2-30.1.264"</span> <span>\</span></span>
<span id="cb1-2">    <span>-Subject</span><span>=</span><span>"mathematics"</span> <span>-Keywords</span><span>=</span><span>"Ramsey theory, Ramsey's theorem, combinatorics, mathematical logic, decidability, </span><span>\</span></span>
<span id="cb1-3"><span>    first-order logic,  Bernays-Schönfinkel-Ramsey class of first-order logic, _Proceedings of the London Mathematical </span><span>\</span></span>
<span id="cb1-4"><span>    Society_, Volume s2-30, Issue 1, 1930-01-01, pg264-286"</span> 1930-ramsey.pdf</span></code></pre>
                </div>
                <div>
                  <p>
                    “PDF Plus” is better than “PDF”.
                  </p><p>If two versions are provided, the “PDF” one may be intended (if there is any real difference) for printing and exclude features like hyperlinks .
                </p></div>
              </li>
              <li>
                <p><strong>Public Hosting</strong>: if possible, host a public copy; especially if it was very difficult to find, even if it was useless, it should be hosted. The life you save may be your own.</p>
              </li>
              <li>
                <p><strong>Link On WP/​Social Media</strong>: for bonus points, link it in appropriate places on Wikipedia or Reddit or Twitter; this makes people aware of the copy being available, and also supercharges visibility in search engines.</p>
              </li>
              <li>
                <p><strong>Link Specific Pages</strong>: as noted before, you can link a specific page by adding <code>#page=N</code> to the URL. Linking the relevant page is helpful to readers. (I recommend against doing this if this is done to link an <em>entire article</em> inside a book, because that article will still have bad SEO and it will be hard to find; in such cases, it’s better to crop out the relevant page range as a standalone article, eg. using <code>pdftk</code> again for <code>pdftk 1900-BOOK.pdf cat 123-456 output 1900-PAPER.pdf</code>.)</p>
              </li>
            </ul>
          </section>
          <section id="advanced">
            <h2><a href="#advanced" title="Link to section: § 'Advanced'">Advanced</a></h2>
            <p>Aside from the (highly-recommended) use of hotkeys and Booleans for searches, there are a few useful tools for the researcher, which while expensive initially, can pay off in the long-term:</p>
            <ul>
              <li>
                <p><a href="https://gwern.net/archiving#remote-caching" id="gwern-archiver-bot"><code>archiver-bot</code></a>: automatically archive your web browsing and/​or links from arbitrary websites to forestall linkrot; particularly useful for detecting &amp; recovering from dead PDF links</p>
              </li>
              <li>
                <p><strong>Subscriptions</strong> like <a href="https://pubmed.ncbi.nlm.nih.gov/" data-link-icon="nlm-ncbi" data-link-icon-type="svg">PubMed</a> &amp; GS search alerts: set up alerts for a specific search query, or for new citations of a specific paper. ( <a href="https://en.wikipedia.org/wiki/Google_Alerts" data-link-icon="wikipedia" data-link-icon-type="svg">Google Alerts</a> is not as useful as it seems.)</p>
                <ol>
                  <li><span>PubMed</span> has straightforward conversion of search queries into alerts: “Create alert” below the search bar. (Given the volume of PubMed indexing, I recommend carefully tailoring your search to be as narrow as possible, or else your alerts may overwhelm you.)</li>
                  <li>To create generic <span>GS</span> search query alert, simply use the “Create alert” on the sidebar for any search. To follow citations of a key paper, you must: 1. bring up the paper in GS; 2. click on “Cited by X”; 3. <em>then</em> use “Create alert” on the sidebar.</li>
                </ol>
              </li>
              <li>
                <p><strong>GCSE</strong>: a <a href="https://programmablesearchengine.google.com/about/" data-link-icon="alphabet" data-link-icon-type="svg">Google Custom Search Engines</a> is a specialized search queries limited to whitelisted pages/​domains etc (eg. my <a href="https://cse.google.com/cse?cx=009114923999563836576%3A1eorkzz2gp4" data-link-icon="alphabet" data-link-icon-type="svg">Wikipedia-focused anime / ​manga CSE</a>).</p>
                <p>A GCSE can be thought of as a saved search query on steroids. If you find yourself regularly including scores of the same domains in multiple searches search, or constantly blacklisting domains with <code>-site:</code> or using many negations to filter out common false positives, it may be time to set up a GCSE which does all that by default.</p>
              </li>
              <li>
                <p><strong>Clippings</strong>: <a href="https://en.wikipedia.org/wiki/Comparison_of_note-taking_software" data-link-icon="wikipedia" data-link-icon-type="svg">note-taking services</a> like <a href="https://en.wikipedia.org/wiki/Evernote" data-link-icon="wikipedia" data-link-icon-type="svg">Evernote</a>⁠/ ​<a href="https://en.wikipedia.org/wiki/Microsoft_OneNote" data-link-icon="wikipedia" data-link-icon-type="svg">Microsoft OneNote</a>: regularly making and keeping excerpts creates a personalized search engine, in effect.</p>
                <p>This can be vital for refinding old things you read where the search terms are hopelessly generic or you can’t remember an <em>exact</em> quote or reference; it is one thing to search a keyword like “autism” in a few score thousand clippings, and another thing to search that in the entire Internet! (One can also reorganize or edit the notes to add in the keywords one is thinking of, to help with refinding.) I make heavy use of Evernote clipping and it is key to refinding my references.</p>
              </li>
              <li>
                <p><strong>Crawling Websites</strong>: sometimes having copies of whole websites might be useful, either for more flexible searching or for ensuring you have anything you might need in the future. (example: <a href="https://gwern.net/dnm-archive" id="gwern-dnm-archive" title="'Darknet Market Archives (2013–2015)', Gwern 2013">“Darknet Market Archives (2013–2015)”</a>).</p>
                <p>Useful tools to know about: <a href="https://en.wikipedia.org/wiki/Wget" data-link-icon="wikipedia" data-link-icon-type="svg">wget</a>⁠, <a href="https://en.wikipedia.org/wiki/CURL" data-link-icon="wikipedia" data-link-icon-type="svg">cURL</a>⁠, <a href="https://en.wikipedia.org/wiki/HTTrack" data-link-icon="wikipedia" data-link-icon-type="svg">HTTrack</a>⁠; Firefox plugins: <a href="https://gwern.net/doc/www/noscript.net/aa40da7a98a144ecc776d63453662c8e00469bb8.html" rel="archived alternate nofollow" data-url-original="https://noscript.net/" title="(Original URL: https://noscript.net/ )">NoScript</a>⁠, <a href="https://github.com/gorhill/uBlock" data-link-icon="github" data-link-icon-type="svg">uBlock origin</a>⁠, <a href="https://addons.mozilla.org/en-US/firefox/addon/http-header-live/" data-link-icon="FF" data-link-icon-type="text,sans">Live HTTP Headers</a>⁠, <a href="https://github.com/iamadamdev/bypass-paywalls-chrome" data-link-icon="github" data-link-icon-type="svg">Bypass Paywalls</a>⁠, cookie exporting.</p>
                <p>Short of downloading a website, it might also be useful to pre-emptively archive it by using <code>linkchecker</code> to crawl it, compile a list of all external &amp; internal links, and store them for processing by another archival program (see <a href="https://gwern.net/archiving" id="gwern-archiving" title="'Archiving URLs', Gwern 2011">Archiving URLs</a> for examples). In certain rare circumstances, security tools like <a href="https://en.wikipedia.org/wiki/Nmap" data-link-icon="wikipedia" data-link-icon-type="svg"><code>nmap</code></a> can be useful to examine a mysterious server in more detail: what web server and services does it run, what else might be on it (sometimes interesting things like old anonymous FTP servers turn up), has a website moved between IPs or servers, etc.</p>
              </li>
            </ul>
          </section>
        </section>
        <section id="web-pages">
          <h2><a href="#web-pages" title="Link to section: § 'Web pages'">Web Pages</a></h2>
          <p>With proper use of pre-emptive archiving tools like <code>archiver-bot</code>, fixing linkrot in one’s own pages is much easier, but that leaves other references. Searching for lost web pages is similar to searching for papers:</p>
          <ul>
            <li>
              <p><strong>Just Search The Title</strong>: if the page title is given, search for the title.</p>
              <p>It is a good idea to include page titles in one’s own pages, as well as the URL, to help with future searches, since the URL may be meaningless gibberish on its own, and pre-emptive archiving can fail. HTML supports both <code>alt</code> and <code>title</code> parameters in link tags, and, in cases where displaying a title is not desirable (because the link is being used inline as part of normal hypertextual writing), titles can be included cleanly in <a href="https://en.wikipedia.org/wiki/Markdown" data-link-icon="wikipedia" data-link-icon-type="svg">Markdown</a> documents like this: <code>[inline text description](URL "Title")</code>.</p>
            </li>
            <li>
              <p><strong>Clean URLs</strong>: check the URL for weirdness or trailing garbage like `<code>or</code>?utm_source = feedburner&amp;utm_medium = feed&amp;utm_campaign = Feed%3A+blogspot%2FgJZg+%28Google+AI+Blog%29<code>? Or a variant domain, like a</code>mobile.foo.com<code>/</code>m.foo.com<code>/</code>foo.com/​amp/​` URL? Those are all less likely to be findable or archived than the canonical version.</p>
            </li>
            <li>
              <p><strong>Domain Site Search</strong>: restrict G search to the original domain with <code>site:</code>, or to related domains</p>
            </li>
            <li>
              <p><strong>Time-Limited Search</strong>: restrict G search to the original date-range/​years</p>
            </li>
            <li>
              <p><strong>Switch Engines</strong>: try a different search engine: corpuses can vary, and in some cases G tries to be too smart for its own good when you need a literal search; <a href="https://en.wikipedia.org/wiki/DuckDuckGo" data-link-icon="wikipedia" data-link-icon-type="svg">DuckDuckGo</a> (especially for ‘bang’ special searches), <a href="https://en.wikipedia.org/wiki/Microsoft_Bing" data-link-icon="wikipedia" data-link-icon-type="svg">Bing</a>⁠, and Yandex are usable alternatives</p>
            </li>
            <li>
              <p><strong>Check Archives</strong>: if nowhere on the clearnet, try the Internet Archive (IA) or the <a href="http://timetravel.mementoweb.org/" data-link-icon="internetarchive" data-link-icon-type="svg">Memento meta-archive search engine</a>:</p>
              <p>IA is the default backup for a dead URL. If IA doesn’t Just Work, there may be other versions in it:</p>
              <ul>
                <li>
                  <p><span>misleading redirects</span>: did the IA ‘helpfully’ redirect you to a much-later-in-time error page? Kill the redirect and check the earliest stored version for the exact URL rather than the redirect. Did the page initially load but then error out/​redirect? Disable JS with NoScript and reload.</p>
                </li>
                <li>
                  <p><span>Within-Domain Archives</span>: IA lets you list all URLs with any archived versions, by searching for <code>URL/*</code>; the list of available URLs may reveal an alternate newer/​older URL. It can also be useful to filter by filetype or substring.</p>
                  <p>For example, one might list all URLs in a domain, and if the list is too long and filled with garbage URLs, then using the “Filter results” incremental-search widget to search for “uploads/​” on a WordPress blog.<a href="#fn14" id="fnref14" role="doc-noteref"><sup>14</sup></a></p>
                  <figure>
                    <img alt="Screenshot of an oft-overlooked feature of the Internet Archive: displaying all available/​archived URLs for a specific domain, filtered down to a subset matching a string like *uploads/*." decoding="async" height="1360" loading="lazy" src="https://gwern.net/doc/cs/2019-gwern-internetarchive-domainsearch-screenshot.png" width="1036">
                    
                  </figure>
                  <ul>
                    <li>
                      <a href="https://github.com/hartator/wayback-machine-downloader" data-link-icon="github" data-link-icon-type="svg"><code>wayback_machine_downloader</code></a> (not to be confused with the <a href="https://github.com/jjjake/internetarchive" data-link-icon="github" data-link-icon-type="svg"><code>internetarchive</code> Python package</a> which provides a CLI interface to uploading files) is a Ruby tool which lets you download whole domains from IA, which can be useful for running a local fulltext search using regexps (a good <code>grep</code> query is often enough), in cases where just looking at the URLs via <code>URL/*</code> is not helpful. (An alternative which might work is <a href="https://websitedownloader.io/" title="Wayback Machine Downloader: Download the source code and assets from Wayback Machine"><code>websitedownloader.io</code></a>⁠.)
                    </li>
                  </ul>
                  <p>Example:</p>
                  <div id="cb2">
                    <pre><code><span id="cb2-1"><span>gem</span> install <span>--user-install</span> wayback_machine_downloader</span>
<span id="cb2-2"><span>~/.gem/ruby/2.7.0/bin/wayback_machine_downloader</span> wayback_machine_downloader <span>--all-timestamps</span> <span>'https://blog.okcupid.com'</span></span></code></pre>
                  </div>
                </li>
                <li>
                  <p>did <span>the domain change</span>, eg. from <code>www.foo.com</code> to <code>foo.com</code> or <code>www.foo.org</code>? Entirely different as far as IA is concerned.</p>
                </li>
                <li>
                  <p>does the <span>internal evidence of the URL</span> provide any hints? You can learn a lot from URLs just by paying attention and thinking about what each directory and argument means.</p>
                </li>
                <li>
                  <p>is this a <span>Blogspot blog</span>? Blogspot is uniquely horrible in that it has versions of each blog for every country domain: a <code>foo.blogspot.com</code> blog could be under any of <code>foo.blogspot.de</code>, <code>foo.blogspot.au</code>, <code>foo.blogspot.hk</code>, <code>foo.blogspot.jp</code>…<a href="#fn15" id="fnref15" role="doc-noteref"><sup>15</sup></a></p>
                </li>
                <li>
                  <p>did the website provide <span>RSS feeds</span>?</p>
                  <p>A little known fact is that <a href="https://en.wikipedia.org/wiki/Google_Reader" data-link-icon="wikipedia" data-link-icon-type="svg">Google Reader</a> (GR; October 2005–July 2013) stored all RSS items it crawled, so if a website’s RSS feed was configured to include full items, the RSS feed history was an alternate mirror of the whole website, and since GR never removed RSS items, it was possible to retrieve pages or whole websites from it. GR has since closed down, sadly, but before it closed, <a href="https://en.wikipedia.org/wiki/Archive_Team" data-link-icon="wikipedia" data-link-icon-type="svg">Archive Team</a> <a href="https://wiki.archiveteam.org/index.php/Google_Reader" data-link-icon="internetarchive" data-link-icon-type="svg">downloaded</a> a large fraction of GR’s historical RSS feeds, and <em>those</em> archives are <a href="https://archive.org/details/archiveteam_greader" data-link-icon="internetarchive" data-link-icon-type="svg">now hosted on IA</a>⁠. The catch is that they are stored in mega-<a href="https://en.wikipedia.org/wiki/Web_ARChive" data-link-icon="wikipedia" data-link-icon-type="svg">WARCs</a>⁠, which, for all their archival virtues, are not the most user-friendly format. The raw GR mega-WARCs are difficult enough to work with that I <a href="#searching-the-google-reader-archives" data-link-icon="alphabet" data-link-icon-type="svg">defer an example to the appendix</a>⁠.</p>
                </li>
                <li>
                  <p><a href="https://archive.is/" data-link-icon="internetarchive" data-link-icon-type="svg"><code>archive.today</code></a>: an IA-like mirror. (Sometimes bypasses paywalls or has snapshots other services do not; I strongly recommend against treating archive.today/​archive.is/​etc as anything but a temporary mirror to grab snapshots from, as <a href="https://blog.archive.today/post/660719734341386240/is-there-any-structure-in-place-to-assure-the" data-link-icon="internetarchive" data-link-icon-type="svg">it has no long-term plans</a>⁠.)</p>
                </li>
                <li>
                  <p>any <span>local archives</span>, such as those made with my <a href="#gwern-archiver-bot"><code>archiver-bot</code></a></p>
                </li>
                <li>
                  <p><span>Google Cache</span> ( <a href="https://en.wikipedia.org/wiki/Garbage_collection_%28computer_science%29" data-link-icon="wikipedia" data-link-icon-type="svg">GC</a>): GC works, sometimes, but the copies are usually the worst around, ephemeral &amp; cannot be relied upon. Google also appears to have been steadily deprecating GC over the years, as GC shows up less &amp; less in search results. A last resort.</p>
                </li>
              </ul>
            </li>
          </ul>
        </section>
        <section id="books">
          <h2><a href="#books" title="Link to section: § 'Books'">Books</a></h2>
          <section id="digital">
            <h2><a href="#digital" title="Link to section: § 'Digital'">Digital</a></h2>
            <p>E-books are rarer and harder to get than papers, although the situation has improved vastly since the early 2000s. To search for books online:</p>
            <ul>
              <li>
                <p><strong>More Straightforward</strong>: book searches tend to be faster and simpler than paper searches, and to require less cleverness in search query formulation, perhaps because they are rarer online, much larger, and have simpler titles, making it easier for search engines.</p>
                <p>Search G, not GS, for books:</p>
                <div>
                  <p>
                    No Books in Google Scholar
                  </p><p>Book fulltexts usually don’t show up in G<em>S</em> (for unknown reasons). You need to check G when searching for books.
                </p></div>
                <p>To double-check, you can try a <code>filetype:pdf</code> search; then check LG. Typically, if the main title + author doesn’t turn it up, it’s not online. (In some cases, the author order is reversed, or the title:subtitle are reversed, and you can find a copy by tweaking your search, but these are rare.).</p>
              </li>
              <li>
                <p><strong>IA</strong>: the Internet Archive has many books scanned which do not appear easily in search results (poor SEO?).</p>
                <ul>
                  <li>
                    <p>If an IA hit pops up in a search, <em>always check it</em>; the OCR may offer hints as to where to find it. If you don’t find anything or the provided, try doing an IA site search in G (<em>not</em> the IA built-in search engine), eg. <code>book title site:archive.org</code>.</p>
                  </li>
                  <li>
                    <p><span>DRM workarounds</span>: if it <em>is</em> on IA but the IA version is DRMed and is only available for “checkout”, you can jailbreak it.</p>
                    <p>Check the book out for the full period, 14 days. Download the PDF (not EPUB) version to Adobe Digital Elements version ≤4.0 (which can be run in Wine on Linux), and then import it to <a href="https://en.wikipedia.org/wiki/Calibre_(software)" data-link-icon="wikipedia" data-link-icon-type="svg">Calibre</a> with <a href="https://gwern.net/doc/www/apprenticealf.wordpress.com/f294474f6b56273006d0c67c61ffbbaed6438408.html" rel="archived alternate nofollow" data-url-original="https://apprenticealf.wordpress.com/" title="(Original URL: https://apprenticealf.wordpress.com/ )">the De-DRM plugin</a>⁠, which will produce a DRM-free PDF inside Calibre’s library. (Getting De-DRM running can be tricky, especially under Linux. I wound up having to edit some of the paths in the Python files to make them work with Wine. It also appears to fail on the most recent Google Play ebooks, ~2021.) You can then add metadata to the PDF &amp; upload it to LG<a href="#fn16" id="fnref16" role="doc-noteref"><sup>16</sup></a>⁠. (LG’s versions of books are usually better than the IA scans, but if they don’t exist, IA’s is better than nothing.)</p>
                  </li>
                </ul>
              </li>
              <li>
                <p><strong><a href="https://en.wikipedia.org/wiki/Google_Play" data-link-icon="wikipedia" data-link-icon-type="svg">Google Play</a></strong>: use the same PDF DRM as IA, can be broken same way</p>
              </li>
              <li>
                <p><strong><a href="https://en.wikipedia.org/wiki/HathiTrust" data-link-icon="wikipedia" data-link-icon-type="svg">HathiTrust</a></strong> also hosts many book scans, which can be searched for clues or hints or jailbroken.</p>
                <p>HathiTrust blocks whole-book downloads but it’s easy to download each page in a loop and stitch them together, for example:</p>
                <div id="cb3">
                  <pre><code><span id="cb3-1"><span>for</span> i <span>in</span> <span>{</span><span>1</span><span>..</span><span>151</span><span>}</span></span>
<span id="cb3-2"><span>do</span> <span>if</span> <span>[[</span> <span>!</span> <span>-s</span> <span>"</span><span>$i</span><span>.pdf"</span> <span>]];</span> <span>then</span></span>
<span id="cb3-3">    <span>wget</span> <span>"https://babel.hathitrust.org/cgi/imgsrv/download/pdf?id=mdp.39015050609067;orient=0;size=100;seq=</span><span>$i</span><span>;attachment=0"</span> <span>\</span></span>
<span id="cb3-4">          <span>-O</span> <span>"</span><span>$i</span><span>.pdf"</span></span>
<span id="cb3-5">    <span>sleep</span> 20s</span>
<span id="cb3-6"> <span>fi</span></span>
<span id="cb3-7">done</span>
<span id="cb3-8"></span>
<span id="cb3-9"><span>pdftk</span> <span>*</span>.pdf cat output 1957-super-scientificcareersandvocationaldevelopmenttheory.pdf</span>
<span id="cb3-10"></span>
<span id="cb3-11"><span>exiftool</span> <span>-Title</span><span>=</span><span>"Scientific Careers and Vocational Development Theory: A review, a critique and some recommendations"</span> <span>\</span></span>
<span id="cb3-12">    <span>-Date</span><span>=</span>1957 <span>-Author</span><span>=</span><span>"Donald E. Super, Paul B. Bachrach"</span> <span>-Subject</span><span>=</span><span>"psychology"</span> <span>\</span></span>
<span id="cb3-13">    <span>-Keywords</span><span>=</span><span>"Bureau Of Publications (Teachers College Columbia University), LCCCN: 57-12336, National Science Foundation, public domain, </span><span>\</span></span>
<span id="cb3-14"><span>    https://babel.hathitrust.org/cgi/pt?id=mdp.39015050609067;view=1up;seq=1 https://psycnet.apa.org/record/1959-04098-000"</span> <span>\</span></span>
<span id="cb3-15">    1957-super-scientificcareersandvocationaldevelopmenttheory.pdf</span></code></pre>
                </div>
                <p>Another example of this would be the Wellcome Library; while looking for <a href="https://wellcomecollection.org/works/d63gy9b7"><em>An Investigation Into The Relation Between Intelligence And Inheritance</em><span>, <span><span>Lawrence</span><span>1931</span></span></span></a>⁠, I came up dry until I checked one of the last search results, a “Wellcome Digital Library” hit, on the slim off-chance that, like the occasional Chinese/​Indian library website, it just might have fulltext. As it happens, it did—good news? Yes, but with a caveat: it provides <em>no</em> way to download the book! It provides OCR, metadata, and individual page-image downloads all under CC-BY-NC-SA (so no legal problems), but… not the book. (The OCR is also unnecessarily zipped, so that is why Google ranked the page so low and did not show any revealing excerpts from the OCR transcript: because it’s hidden in an opaque archive to save a few kilobytes while destroying SEO.) Examining the download URLs for the highest-resolution images, they follow an unfortunate schema:</p>
                <ol>
                  <li><code>https://dlcs.io/iiif-img/wellcome/1/5c27d7de-6d55-473c-b3b2-6c74ac7a04c6/full/2212,/0/default.jpg</code></li>
                  <li><code>https://dlcs.io/iiif-img/wellcome/1/d514271c-b290-4ae8-bed7-fd30fb14d59e/full/2212,/0/default.jpg</code></li>
                  <li>etc</li>
                </ol>
                <p>Instead of being sequentially numbered 1–90 or whatever, they all live under a unique hash or ID. Fortunately, one of the metadata files, the ‘manifest’ file, provides all of the hashes/​IDs (but not the high-quality download URLs). Extracting the IDs from the manifest can be done with some quick <code>sed</code> &amp; <code>tr</code> string processing, and fed into another short <code>wget</code> loop for download</p>
                <div id="cb4">
                  <pre><code><span id="cb4-1"><span>grep</span> <span>-F</span> <span>'@id'</span> manifest<span>\?</span>manifest<span>\=</span>https<span>\:</span>%2F%2Fwellcomelibrary.org%2Fiiif%2Fb18032217%2Fmanifest <span>|</span> <span>\</span></span>
<span id="cb4-2">   <span>sed</span> <span>-e</span> <span>'s/.*imageanno\/\(.*\)/\1/'</span> <span>|</span> <span>grep</span> <span>-E</span> <span>-v</span> <span>'^ .*'</span> <span>|</span> <span>tr</span> <span>-d</span> <span>','</span> <span>|</span> <span>tr</span> <span>-d</span> <span>'"'</span> <span># "</span></span>
<span id="cb4-3"># bf23642e-e89b-43a0-8736-f5c6c77c03c3</span>
<span id="cb4-4"># 334faf27-3ee1-4a63-92d9-b40d55ab72ad</span>
<span id="cb4-5"># 5c27d7de-6d55-473c-b3b2-6c74ac7a04c6</span>
<span id="cb4-6"># d514271c-b290-4ae8-bed7-fd30fb14d59e</span>
<span id="cb4-7"># f85ef645-ec96-4d5a-be4e-0a781f87b5e2</span>
<span id="cb4-8"># a2e1af25-5576-4101-abee-96bd7c237a4d</span>
<span id="cb4-9"># 6580e767-0d03-40a1-ab8b-e6a37abe849c</span>
<span id="cb4-10"># ca178578-81c9-4829-b912-97c957b668a3</span>
<span id="cb4-11"># 2bd8959d-5540-4f36-82d9-49658f67cff6</span>
<span id="cb4-12"># ...etc</span>
<span id="cb4-13"><span>I</span><span>=</span>1</span>
<span id="cb4-14"><span>for</span> HASH <span>in</span> <span>$HASHES</span><span>;</span> <span>do</span></span>
<span id="cb4-15">    <span>wget</span> <span>"https://dlcs.io/iiif-img/wellcome/1/</span><span>$HASH</span><span>/full/2212,/0/default.jpg"</span> <span>-O</span> <span>$I</span>.jpg</span>
<span id="cb4-16">    <span>I</span><span>=</span><span>$((I</span><span>+</span><span>1</span><span>))</span></span>
<span id="cb4-17">done</span></code></pre>
                </div>
                <p>And then the 59MB of JPGs can be cleaned up as usual with <code>gscan2pdf</code> (empty pages deleted, tables rotated, cover page cropped, all other pages binarized), compressed/​OCRed with <code>ocrmypdf</code>, and metadata set with <code>exiftool</code>, producing a readable, downloadable, highly-search-engine-friendly 1.8MB PDF.</p>
              </li>
              <li>
                <p>remember the <a href="https://en.wikipedia.org/wiki/Analog_hole" data-link-icon="wikipedia" data-link-icon-type="svg"><strong>Analog Hole</strong></a> works for papers/​books too:</p>
                <p>if you can find a copy to <em>read</em>, but cannot figure out how to <em>download</em> it directly because the site uses JS or complicated cookie authentication or other tricks, you can always exploit the ‘analogue hole’—fullscreen the book in high resolution &amp; take screenshots of every page; then crop, OCR etc. This is tedious but it works. And if you take screenshots at sufficiently high resolution, there will be relatively little quality loss. (This works better for books that are scans than ones born-digital.)</p>
              </li>
            </ul>
          </section>
          <section id="physical">
            <h2><a href="#physical" title="Link to section: § 'Physical'">Physical</a></h2>
            <p><span>Expensive but feasible.</span> Books are something of a double-edged sword compared to papers/​theses. On the one hand, books are much more often unavailable online, and must be bought offline, but at least you almost always <em>can</em> buy used books offline without much trouble (and often for &lt;$10 total); on the other hand, while paper/​theses are often available online, when one is not unavailable, it’s usually <em>very</em> unavailable, and you’re stuck (unless you have a university ILL department backing you up or are willing to travel to the few or only universities with paper or microfilm copies).</p><!-- TODO: outsourcing to the IA? https://openlibrary.org/sponsorship -->
            <p>Purchasing from used book sellers:</p>
            <ul>
              <li>
                <p><strong>Sellers</strong>:</p>
                <ul>
                  <li>
                    <p><span>used book search engines</span>: Google Books/​<a href="https://www.find-more-books.com/">find-more-books.com</a>: a good starting point for seller links; if buying from a marketplace like AbeBooks/​Amazon/​Barnes &amp; Noble, it’s worth searching the seller to see if they have their own website, which is potentially much cheaper. They may also have multiple editions in stock.</p>
                  </li>
                  <li>
                    <p><span>bad</span>: eBay &amp; Amazon are often bad, due to high-minimum-order+S&amp;H and sellers on Amazon seem to assume Amazon buyers are easily rooked; but can be useful in providing metadata like page count or ISBN or variations on the title</p>
                  </li>
                  <li>
                    <p><span>good</span>: <a href="https://www.abebooks.com/">AbeBooks</a>⁠, <a href="https://www.thriftbooks.com/">Thrift Books</a>⁠, <a href="https://www.betterworldbooks.com/">Better World Books</a>⁠, <a href="https://www.barnesandnoble.com/">B&amp;N</a>⁠, <a href="https://www.discoverbooks.com/">Discover Books</a>⁠.</p>
                    <p>Note: on AbeBooks, international orders can be useful (especially for behavioral genetics or psychology books) but be careful of international orders with your credit card—many debit/​credit cards will fail on international orders and trigger a fraud alert, and <a href="https://en.wikipedia.org/wiki/PayPal" data-link-icon="wikipedia" data-link-icon-type="svg">PayPal</a> is not accepted.</p>
                  </li>
                </ul>
              </li>
              <li>
                <p><strong>Price Alerts</strong>: if a book is not available or too expensive, set price watches: AbeBooks supports email alerts on stored searches, and Amazon can be monitored via <a href="https://camelcamelcamel.com/">CamelCamelCamel</a> (remember the CCC price alert you want is on the <em>used third-party</em> category, as new books are more expensive, less available, and unnecessary).</p>
              </li>
            </ul>
            <p>Scanning:</p>
            <ul>
              <li>
                <p><strong>Destructive Vs Non-Destructive</strong>: the fundamental dilemma of book scanning—destructively debinding books with a razor or guillotine cutter works much better &amp; is much less time-consuming than spreading them on a flatbed scanner to scan one-by-one<a href="#fn17" id="fnref17" role="doc-noteref"><sup>17</sup></a>⁠, because it allows use of a sheet-fed scanner instead, which is easily 5x faster and will give higher-quality scans (because the sheets will be flat, scanned edge-to-edge, and much more closely aligned), but does, of course, require effectively destroying the book.</p>
              </li>
              <li>
                <p><strong>Tools</strong>:</p>
                <ul>
                  <li>
                    <p><span>cutting</span>: For simple debinding of a few books a year, an X-acto knife/​razor is good (avoid the ‘triangle’ blades, get curved blades intended for large cuts instead of detail work).</p>
                    <p>Once you start doing more than one a month, it’s time to upgrade to a guillotine blade paper cutter (a fancier swinging-arm paper cutter, which uses a two-joint system to clamp down and cut uniformly).</p>
                    <p>A guillotine blade can cut chunks of 200 pages easily without much slippage, so for books with more pages, I use both: an X-acto to cut along the spine and turn it into several 200-page chunks for the guillotine cutter.</p>
                  </li>
                  <li>
                    <p><span>scanning</span>: at some point, it may make sense to switch to a scanning service like <a href="https://1dollarscan.com/">1DollarScan</a> (1DS has acceptable quality for the black-white scans I have used them for thus far, but watch out for their nickel-and-diming fees for OCR or “setting the PDF title”; these can be done in no time yourself using <code>gscan2pdf</code>/​<code>exiftool</code>/​<code>ocrmypdf</code> and will save a <em>lot</em> of money as they, amazingly, bill by 100-page units). Books can be sent directly to 1DS, reducing logistical hassles.</p>
                  </li>
                </ul>
              </li>
              <li>
                <p><strong>Clean Up</strong>: after scanning, crop/​threshold/​OCR/​add metadata</p>
                <ul>
                  <li><span>Adding metadata</span>: same principles as papers. While more elaborate metadata can be added, like bookmarks, I have not experimented with those yet.</li>
                </ul>
              </li>
              <li>
                <p><strong>File format</strong>: PDF, <a href="https://gwern.net/design-graveyard#djvu-files" id="gwern-design-graveyard-djvu-files">not DjVu</a></p>
                <p>Despite being a worse format in many respects, I now recommend PDF and have stopped using DjVu for new scans<a href="#fn18" id="fnref18" role="doc-noteref"><sup>18</sup></a> and have converted my old DjVu files to PDF.</p>
              </li>
              <li>
                <p><strong>Uploading</strong>: to LibGen, usually, and Gwern.net sometimes. For backups, filelockers like Dropbox, Mega, MediaFire, or Google Drive are good. I usually upload 3 copies including LG. I rotate accounts once a year, to avoid putting too many files into a single account. [I discourage <a href="https://gwern.net/archiving#why-not-internet-archive" id="gwern-archiving-why-not-internet-archive" title="‘Archiving URLs § Why Not Internet Archive?’, Branwen 2011">reliance on IA links.</a>)</p>
                <div>
                  <p>
                    Do Not Use Google Docs/​Scribd/​Dropbox/​IA/​etc for Long-Term Documents
                  </p>
                  <p>‘Document’ websites like Google Docs (GD) should be strictly avoided as primary hosting. GD does <em>not</em> appear in G/​GS, dooming a document to obscurity, and Scribd is ludicrously user-hostile with changing <a href="https://en.wikipedia.org/wiki/Dark_pattern" data-link-icon="wikipedia" data-link-icon-type="svg">dark patterns</a>⁠. Such sites cannot be searched, scraped, downloaded reliably, clipped, used on many devices, archived<a href="#fn19" id="fnref19" role="doc-noteref"><sup>19</sup></a>⁠, or counted on for the long haul. (For example, Google Docs has made many documents ‘private’, breaking public links, to the surprise of even the authors when I contact them about it, for unclear reasons.)</p><p>Such sites may be useful for collaboration or surveys, but should be regarded as strictly temporary <em>working files</em>, and moved to clean static HTML/​PDF/​XLSX hosted elsewhere as soon as possible.
                </p></div>
              </li>
              <li>
                <p><strong>Hosting</strong>: hosting papers is easy but books come with risk:</p>
                <p>Books can be dangerous; in deciding whether to host a book, my rule of thumb is host only books pre-2000 and which do not have Kindle editions or other signs of active exploitation and is effectively an ‘<a href="https://en.wikipedia.org/wiki/Orphan_work" data-link-icon="wikipedia" data-link-icon-type="svg">orphan work</a>’.</p>
                <p>As of 2019-10-23, hosting 4090 files over 9 years (very roughly, assuming linear growth, &lt;6.7 million document-days of hosting: 3763 × 0.5 × 8 × 365.25 = 6722426), I’ve received 4 takedown orders: a behavioral genetics textbook (2013), <em>The Handbook of Psychopathy</em> (2005), a recent <a href="https://en.wikipedia.org/wiki/Meta-analysis" data-link-icon="wikipedia" data-link-icon-type="svg">meta-analysis</a> <span>paper (<span><span title="et al">Roberts</span> <span>et al</span> <span>2016</span></span>), and a CUP DMCA takedown order for 27 files. I broke my rule of thumb to host the 2 books (my mistake), which leaves only the 1 paper, which I think was a fluke. So, as long as one avoids relatively recent books, the risk should be minimal.</span> <!-- Sep 2020 update: +2: IEEE, and newspaper over mirrored page; Oct 2020: CUP, 1 book --></p>
              </li>
            </ul>
          </section>
        </section>
        <section id="case-studies">
          <h2><a href="#case-studies" title="Link to section: § 'Case Studies'">Case Studies</a></h2>
          <p>Followup section to the article covering how to search the Internet effectively: &gt;14 case studies of challenging Internet searches drawn from the past 10 years. I present the problem, and step through the process of finding it, and describe my tacit knowledge and implicit strategies. These case studies make the prior tips more understandable by showing them off in practice.</p>
          <section id="missing-appendix">
            <h2><a href="#missing-appendix" title="Link to section: § 'Missing Appendix'">Missing Appendix</a></h2>
            <p><a href="https://en.wikipedia.org/wiki/Anders_Sandberg" data-link-icon="wikipedia" data-link-icon-type="svg">Anders Sandberg</a> <a href="https://twitter.com/anderssandberg/status/1176040327679029249" data-link-icon="twitter" data-link-icon-type="svg">asked</a>:</p>
            <blockquote>
              <p>Does anybody know where the online appendix to Nordhaus’ <a href="https://pdfs.semanticscholar.org/f60f/e757587be15c29ad6ee5695bc48a44df3e8a.pdf" data-link-icon="pdf" data-link-icon-type="svg" title="Nordhaus 2007">“Two Centuries of Productivity Growth in Computing”</a> is hiding?</p>
            </blockquote>
            <p>I look up the title in Google Scholar; seeing a friendly <code>psu.edu</code> PDF link (CiteSeerx), I click. The paper says “The data used in this study are provided in a background spreadsheet available at <code>http://www.econ.yale.edu/~nordhaus/Computers/Appendix.xls</code>”. Sadly, this is a lie. (Sandberg would, of course, have tried that already.)</p>
            <p>I immediately check the URL in the IA—nothing. The IA didn’t catch it at all. Maybe the <a href="https://www.cambridge.org/core/journals/journal-of-economic-history/article/two-centuries-of-productivity-growth-in-computing/856EC5947A5857296D3328FA154BA3A3" id="nordhaus-2007" data-link-icon="⛨" data-link-icon-type="text" title="'Two Centuries of Productivity Growth in Computing', Nordhaus 2007">official published paper website</a> has it? Nope, it references the same URL, and doesn’t provide a copy as an appendix or supplement. (What do we pay these publishers such enormous sums of money for, exactly?) So I back off to checking <code>http://www.econ.yale.edu/~nordhaus/</code>, to check Nordhaus’s personal website for a newer link. The Yale personal website is empty and appears to’ve been replaced by a Google Sites personal page. It links nothing useful, so I check a more thorough index, Google, by searching <code>site:sites.google.com/site/williamdnordhaus/</code>. Nothing there either (and it appears almost empty, so Nordhaus has allowed most of his stuff to be deleted and bitrot). I try a broader Google: <code>nordhaus appendix.xls</code>. This turns up some spreadsheets, but still nothing.</p>
            <p>Easier approaches having been exhausted, I return to the IA and I pull up <em>all</em> URLs archived for his original personal website: <code>https://web.archive.org/web/*/http://www.econ.yale.edu/~nordhaus/*</code> This pulls up way too many URLs to manually review, so I filter results for <code>xls</code>, which reduces to a more manageable 60 hits; reading through the hits, I spot <code>http://www.econ.yale.edu/~nordhaus/homepage/documents/Appendix_Nordhaus_computation_update_121410.xlsx</code> from 2014-10-10; this sounds right, albeit substantially later in time than expected (either 2010 or 2012, judging from the filename).</p>
            <p><a href="https://gwern.net/doc/cs/2010-nordhaus-nordhaus2007twocenturiesofproductivitygrowthincomputing-appendix.xlsx" data-link-icon="spreadsheet" data-link-icon-type="svg">Downloading it</a>⁠, opening it up and cross-referencing with the paper, it has the same spreadsheet ‘sheets’ as mentioned, like “Manual” or “Capital_Deep”, and seems to be either the original file in question or an updated version thereof (which may be even better). The spreadsheet metadata indicates it was created “04/​09/​2001, 23:20:43, <a href="https://en.wikipedia.org/wiki/Incompatible_Timesharing_System" data-link-icon="wikipedia" data-link-icon-type="svg">ITS</a> Academic Media &amp; Technology”, and modified “12/​22/​2010, 02:40:20”, so it seems to be the latter—it’s the original spreadsheet Nordhaus created when he began work several years prior to the formal 2007 publication (6 years seems reasonable given all the delays in such a process), and then was updated 3 years afterwards. Close enough.</p>
          </section>
          <section id="misremembered-book">
            <h2><a href="#misremembered-book" title="Link to section: § 'Misremembered Book'">Misremembered Book</a></h2>
            <p><a href="https://gwern.net/doc/www/old.reddit.com/e4be352758223ce0ec474b7824e48ef8e469dd6c.html" data-link-icon="reddit" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://old.reddit.com/r/science/comments/d8dcm0/todays_obesity_epidemic_may_have_been_caused_by/f1ac2sy/" title="(Original URL: https://www.reddit.com/r/science/comments/d8dcm0/todays_obesity_epidemic_may_have_been_caused_by/f1ac2sy/ )">A Redditor asked</a>:</p>
            <blockquote>
              <p>I was in a consignment type store once and picked up a book called “Eat fat, get thin”. Giving it a quick scan through, it was basically the same stuff as Atkins but this book was from the 50s or 60s. I wish I’d have bought it. I think I found a reference to it once online but it’s been drowned out since someone else released a book with the same name (and it wasn’t Barry Groves either).</p>
            </blockquote>
            <p>The easiest way to find a book given a corrupted title, a date range, and the information there are many similar titles drowning out a naive search engine query, is to skip to a specialized search engine with clean metadata (ie. a library database).</p>
            <p>Searching in WorldCat for 1950s–1970s, “Eat fat, get thin” turns up nothing relevant. This is unsurprising, as he was unlikely to’ve remembered the title <em>exactly</em>, and this title doesn’t quite sound right for the era anyway (a little too punchy and ungrammatical, and ‘thin’ wasn’t a desirable word back then compared to words like ‘slim’ or ‘sleek’ or ‘svelte’). People often oversimplify titles, so I dropped back to just “Eat fat”.</p>
            <p>This immediately turned up the book: <a href="https://en.wikipedia.org/wiki/Richard_Mackarness" data-link-icon="wikipedia" data-link-icon-type="svg">Richard Mackarness’s</a> 1958 <em>Eat Fat and Grow Slim</em>—note that it is <em>almost</em> the same title, with a comma serving as conjunction and ‘slim’ rather than the more contemporary ‘thin’, but just different enough to screw up an overly-literal search.</p>
            <p>With the same trick in mind, we could also have found it in a regular Google search query by adding additional terms to hint to Google that we want old books, not recent ones: both <code>"Eat Fat" 1950s</code> or <code>"Eat Fat" 1960s</code> would have turned it up in the first 5 search results. If we didn’t use quotes, the searches get harder because broader hits get pulled in. For example, <code>Eat fat, get thin 1950s -Hyman</code> excludes the recent book mentioned, but you still have to go down 15 hits before finding Mackarness, and <code>Eat fat, get thin -Hyman</code> requires going down 18 hits.</p>
          </section>
          <section id="missing-website">
            <h2><a href="#missing-website" title="Link to section: § 'Missing Website'">Missing Website</a></h2>
            <p><a href="https://onlinelibrary.wiley.com/doi/full/10.1002/anie.201410356" id="bučar-et-al-2015" data-link-icon="W" data-link-icon-type="text,sans" title="Disappearing Polymorphs Revisited"><span><span title="et al">Bučar</span> <span>et al</span> <span>2015</span></span></a>⁠, on the phenomenon of <a href="https://en.wikipedia.org/w/index.php?title=Polymorphism_(materials_science)&amp;oldid=999770848#Disappearing_polymorphs" data-link-icon="wikipedia" data-link-icon-type="svg">disappearing polymorphs</a> quotes striking transcripts from a major example of a disappearing crystal, when ~1998 Abbott suddenly became unable to manufacture the anti-retroviral drug <a href="https://en.wikipedia.org/wiki/Ritonavir" data-link-icon="wikipedia" data-link-icon-type="svg">ritonavir</a> (Norvir™) due to a rival (and less effective) crystal form spontaneously infecting all its plants, threatening many AIDS patients, but notes:</p>
            <blockquote>
              <p>The transcripts were originally published on the website<sup>42</sup> of the International Association of Physicians in AIDS Care [IAPAC], but no longer appear there.</p>
            </blockquote>
            <p>A search using the quotes confirms that the originals have long since vanished from the open Internet, turning up only quotes of the quotations. Unfortunately, no URL is given. The Internet Archive has comprehensive mirrors of the IAPAC, but too many to easily search through. Using the filter feature, I keyword-searched for “ritonavir”, but while this turned up a number of pages from roughly the right time period, they do not mention it and none of the quotes appear. The key turned out to be to use the trademark name instead which pulls up many more pages, and after checking a few, the IAPAC turned out to have organized all the Norvir material into a single subdirectory with a convenient <a href="https://gwern.net/doc/biology/2000-iapac-norvir/index.html"><code>index.html</code></a>⁠; the articles/​transcripts, in turn, were indexed under the linked <a href="https://gwern.net/doc/biology/2000-iapac-norvir/description.html" id="care-2000" title="'Norvir Advisory', Care 2000">“Description of the Problem” index page</a>⁠.</p>
            <p>I then pulled the Norvir subdirectory with a <code>~/.gem/ruby/2.5.0/bin/wayback_machine_downloader wayback_machine_downloader 'http://www.iapac.org/norvir/'</code> command and hosted a mirror to make it visible in Google.</p>
          </section>
          <section id="speech-book">
            <h2><a href="#speech-book" title="Link to section: § 'Speech → Book'">Speech → Book</a></h2>
            <p><a href="https://www.lesswrong.com/posts/cHEQSEPz4eipGHFy9/differential-reproduction-for-men-and-women#comment-TZQqzYPDv6vsWqfut" data-link-icon="LW" data-link-icon-type="text">Nancy Lebovitz</a> asked about a citation in a <a href="https://web.archive.org/web/20071011022938/https://psy.fsu.edu/~baumeistertice/goodaboutmen.htm" id="baumeister-2007" data-link-icon="internetarchive" data-link-icon-type="svg" title="'Is There Anything Good About Men?', Roy F. Baumeister 2007">Roy Baumeister speech about sex differences</a>:</p>
            <blockquote>
              <p>There’s an idea I’ve seen a number of times that 80% of women have had descendants, but only 40% of men. A little research tracked it back to <a href="https://web.archive.org/web/20071011022938/https://psy.fsu.edu/~baumeistertice/goodaboutmen.htm" id="baumeister-2007" data-link-icon="internetarchive" data-link-icon-type="svg" title="‘Is There Anything Good About Men?’, Baumeister 2007">this</a>⁠, but the speech doesn’t have a cite and I haven’t found a source.</p>
            </blockquote>
            <p>This could be solved by guessing that the formal citation is given in the book, and doing keyword search to find a similar passage. The second line of the speech says:</p>
            <blockquote>
              <blockquote>
                <p>For more information on this topic, read Dr.&nbsp;Baumeister’s book <em>Is There Anything Good About Men?</em> available in bookstores everywhere, including here.</p>
              </blockquote>
            </blockquote>
            <p>A search of <em>Is There Anything Good About Men</em> in Libgen turns up a copy. Download. What are we looking for? A reminder, the key lines in the speech are:</p>
            <blockquote>
              <blockquote>
                <p>…It’s not a trick question, and it’s not 50%. True, about half the people who ever lived were women, but that’s not the question. We’re asking about all the people who ever lived who have a descendant living today. Or, put another way, yes, every baby has both a mother and a father, but some of those parents had multiple children. Recent research using DNA analysis answered this question about two years ago. Today’s human population is descended from twice as many women as men. I think this difference is the single most under-appreciated fact about gender. To get that kind of difference, you had to have something like, throughout the entire history of the human race, maybe 80% of women but only 40% of men reproduced.</p>
              </blockquote>
            </blockquote>
            <p>We could search for various words or phrase from this passage which seem to be relatively unique; as it happens, I chose the rhetorical “50%” (but “80%”, “40%”, “underappreciated”, etc. all would’ve worked with varying levels of efficiency since the speech is heavily based on the book), and thus jumped straight to chapter 4, “The Most Underappreciated Fact About Men”. (If these had not worked, we could have started searching for years, based on the quote “about two years ago”.) A glance tells us that Baumeister is discussing exactly this topic of reproductive differentials, so we read on and a few pages later, on page 63, we hit the jackpot:</p>
            <blockquote>
              <p>The correct answer has recently begun to emerge from DNA studies, notably those by Jason Wilder and his colleagues. They concluded that among the ancestors of today’s human population, women outnumbered men about two to one. Two to one! In percentage terms, then, humanity’s ancestors were about 67% female and 33% male.</p>
            </blockquote>
            <p>Who’s Wilder? A C-f for “Wilder” takes us to pg286, where we immediately read:</p>
            <blockquote>
              <p>…The DNA studies on how today’s human population is descended from twice as many women as men have been the most requested sources from my earlier talks on this. The work is by Jason Wilder and his colleagues. I list here some sources in the mass media, which may be more accessible to laypersons than the highly technical journal articles, but for the specialists I list those also. For a highly readable introduction, you can Google the article <a href="https://web.archive.org/web/20040922020546/http://www.scienceagogo.com/news/20040819224859data_trunc_sys.shtml" data-link-icon="internetarchive" data-link-icon-type="svg">“Ancient Man Spread the Love Around,”</a> which was published September, 20, 2004 and is still available (last I checked) online. There were plenty of other stories in the media at about this time, when the research findings first came out. In <a href="https://www.medicalnewstoday.com/">“Medical News Today,”</a>⁠, on the same date in 2004, a story under “Genes expose secrets of sex on the side” covered much the same material.</p>
              <p>If you want the original sources, read Wilder, J. A., Mobasher, Z., &amp; Hammer, M. F. (2004). <a href="https://academic.oup.com/mbe/article/21/11/2047/1147770" data-link-icon="OUP" data-link-icon-type="text,tri">“Genetic evidence for unequal effective population sizes of human females and males”</a>⁠. <em>Molecular Biology and Evolution</em>, 21, 2047–2057. If that went down well, you might try Wilder, J. A., Kingan, S. B., Mobasher, Z., Pilkington, M. M., &amp; Hammer, M. F. (2004). <a href="https://www.nature.com/articles/ng1428" data-link-icon="n" data-link-icon-type="text">“Global patterns of human mitochondrial DNA and Y-chromosome structure are not influenced by higher migration rates of females versus males”</a>⁠. <em>Nature Genetics</em>, 36, 1122–1125. That one was over my head, I admit. A more readable source on these is Shriver, M. D. (2005), <a href="https://www.nature.com/articles/5201329" data-link-icon="n" data-link-icon-type="text">“Female migration rate might not be greater than male rate”</a>⁠. <em>European Journal of Human Genetics</em>, 13, 131–132. Shriver raises another intriguing hypothesis that could have contributed to the greater preponderance of females in our ancestors: Because couples mate such that the man is older, the generational intervals are smaller for females (ie. baby’s age is closer to mother’s than to father’s). As for the 90% to 20% differential in other species, that I believe is standard information in biology, which I first heard in one of the lectures on testosterone by the late James Dabbs, whose book <em>Heroes, Rogues, and Lovers</em> remains an authoritative source on the topic.</p>
            </blockquote>
            <p><span><span><span title="et al">Wilder</span> <span>et al</span> <span>2004</span></span>, incidentally, fits well with Baumeister remarking in 2007 that the research was done 2 or so years ago. And of course you could’ve done the same thing using Google Books: search</span> <a href="https://books.google.com/books?id=qqprY-YiWY8C&amp;printsec=frontcover&amp;dq=Baumeister+anything+good+about+men&amp;sa=X&amp;ei=4vNaUZffIoe9igLB74DQBA&amp;ved=0CDAQ6AEwAA" data-link-icon="alphabet" data-link-icon-type="svg">“Baumeister anything good about men”</a> to get to the book, then search-within-the-book for “50%”, jump to page 53, read to page 63, do a second search-within-the-book for “Wilder” and the second hit of page 287 even luckily gives you the snippet:</p>
            <blockquote>
              <p><em>Sources and References</em> 287</p>
              <p>…If you want the original sources, read Wilder, J. A., Mobasher, Z., &amp; Hammer, M. F. (2004). “Genetic evidence for unequal effective population sizes of human females and males”. <em>Molecular Biology and Evolution</em>…</p>
            </blockquote>
          </section>
          <section id="rowling-quote-on-death">
            <h2><a href="#rowling-quote-on-death" title="Link to section: § 'Rowling Quote On Death'">Rowling Quote On Death</a></h2>
            <p>Did <a href="https://en.wikipedia.org/wiki/J._K._Rowling" data-link-icon="wikipedia" data-link-icon-type="svg">J.K. Rowling</a> say the <em>Harry Potter</em> books were about ‘death’? There are a lot of Rowling statements, but checking WP and opening up each interview links (under the theory that the key interviews are linked there) and searching for ‘death’ soon turns up a relevant quote from <a href="https://gwern.net/doc/www/www.accio-quote.org/763e66fc7f7ae146fdfa894b9d224c297e0fae9d.html" rel="archived alternate nofollow" data-url-original="http://www.accio-quote.org/articles/2001/1201-bbc-hpandme.htm" title="'Harry Potter and Me' (BBC Christmas Special, British version), BBC, 2001-12-28 (Original URL: http://www.accio-quote.org/articles/2001/1201-bbc-hpandme.htm )">2001</a>:</p>
            <blockquote>
              <p>Death is an extremely important theme throughout all seven books. I would say possibly the most important theme. If you are writing about Evil, which I am, and if you are writing about someone who is essentially a <a href="https://en.wikipedia.org/wiki/Psychopathy" data-link-icon="wikipedia" data-link-icon-type="svg">psychopath</a>⁠, you have a duty to show the real evil of taking human life.</p>
            </blockquote>
          </section>
          <section id="crowley-quote">
            <h2><a href="#crowley-quote" title="Link to section: § 'Crowley Quote'">Crowley Quote</a></h2>
            <p><a href="https://www.lesswrong.com/posts/vhxywjnBH6ioRnnt3/crowley-on-religious-experience#comment-3bc4kL4QnNc9TjNTz" data-link-icon="LW" data-link-icon-type="text">Scott Alexander</a> posted a piece linking to an except titled “<a href="https://en.wikipedia.org/wiki/Aleister_Crowley" data-link-icon="wikipedia" data-link-icon-type="svg">Crowley</a> on Religious Experience”.</p>
            <p>The link was broken, but Alexander brought it up in the context of an <a href="https://www.lesswrong.com/posts/Fwt4sDDacko8Sh5iR/the-sacred-mundane#comment-qAHp6JRjeY7ixgYas" data-link-icon="LW" data-link-icon-type="text">earlier discussion</a> where he also quoted Crowley; searching <em>those</em> quotes reveals that it must have been excerpts from <em>Magick: Book 4</em>.</p>
          </section>
          <section id="finding-the-right-sage">
            <h2><a href="#finding-the-right-sage" title="Link to section: § 'Finding The Right SAGE'">Finding The Right ‘SAGE’</a></h2>
            <p><a href="https://www.lesswrong.com/posts/CKpByWmsZ8WmpHtYa/competent-elites#comment-jzCu3bdgoQ77Y5hZN" data-link-icon="LW" data-link-icon-type="text">Phil Goetz</a> noted that an anti-aging conference named “SAGE” had become impossible to find in Google due to a <em>LGBT</em> aging conference also named SAGE.</p>
            <p>Regular searches would fail, but a combination of tricks worked: <code>SAGE anti-aging conference</code> combined with restricting Google search to 2003–2005 time-range turned up a citation to its website as the fourth hit, <code>http://www.sagecrossroads.net</code> (which has ironically since died).</p>
          </section>
          <section id="uk-charity-financials">
            <h2><a href="#uk-charity-financials" title="Link to section: § 'UK Charity Financials'">UK Charity Financials</a></h2>
            <p>The <a href="https://www.lesswrong.com/posts/qqhdj3W3vSfB5E9ss/siai-an-examination?commentId=7CwWf6wN2DtNfv3tF" data-link-icon="LW" data-link-icon-type="text">Future of Humanity Institute (FHI) doesn’t clearly provide</a> charity financial forms akin to the US Form 990s, making it hard to find out information about its budget or results.</p>
            <p>FHI doesn’t show up in the CC, NPC, or <a href="https://en.wikipedia.org/wiki/Candid_(organization)" data-link-icon="wikipedia" data-link-icon-type="svg">GuideStar</a>⁠, which are the first places to check for charity finances, so I went a little broader afield and tried a site search on the FHI website: <code>budget site:fhi.ox.ac.uk</code>. This immediately turned up FHI’s own documentation of its activities and budgets, such as the 2007 annual report; I used part of its title as a new Google search: <code>future of humanity institute achievements report site:fhi.ox.ac.uk</code>.</p>
          </section>
          <section id="nobel-lineage-research">
            <h2><a href="#nobel-lineage-research" title="Link to section: § 'Nobel Lineage Research'">Nobel Lineage Research</a></h2>
            <p><a href="https://www.lesswrong.com/posts/hC83eKp9LFpw9FBks/link-holistic-learning-ebook#comment-egNZtRAF8C2KTPKsu" data-link-icon="LW" data-link-icon-type="text">John Maxwell</a> referred to a forgotten study on high correlation between Nobelist professors &amp; Nobelist grad students (almost entirely a selection effect, I would bet). I was able to refind it in 7 minutes.</p>
            <p>I wasted a few searches like <code>factor predicting Nobel prize</code> or <code>Nobel prize graduate student</code> in Google Scholar, until I search for <code>Nobel laureate "graduate student"</code>; the second hit was a citation, which is a little unusual for Google Scholar and meant it was important, and it had the critical word <em>mutual</em> in it—simultaneous partners in Nobel work is somewhat rare, but temporally separated teams don’t work for prizes, and I suspected that it was exactly what I was looking for. Googling the title, I soon found a PDF like <a href="https://gwern.net/doc/psychology/2004-viau.pdf" id="pilc2501-2004" data-link-icon="pdf" data-link-icon-type="svg" title="pilc2501 2004">“Eminent Scientists’ Demotivation in School: A symptom of an incurable disease?”<span>, <span><span>Viau</span><span>2004</span></span></span></a> <span>which confirmed it (and <span><span>Viau</span><span>2004</span></span> is interesting in its own right as a contribution to the Conscientious vs IQ question). I then followed it to a useful paragraph:</span></p>
            <blockquote>
              <p>In a study conducted with 92 American winners of the Nobel Prize, Zuckerman (1977) discovered that 48 of them had worked as graduate students or assistants with professors who were themselves Nobel Prize award-winners. As pointed out by Zuckerman (1977), the fact that 11 Nobel prizewinners have had the great physicist Rutherford as a mentor is an example of just how significant a good mentor can be during one’s studies and training. It then appears that most eminent scientists did have people to stimulate them during their childhood and mentor(s) during their studies. But, what exactly is the nature of these people’s contribution.</p>
              <ul>
                <li>Zuckerman, H. (1977). <em>Scientific Elite: Nobel Laureates in the United States</em>. New York: Free Press.</li>
              </ul>
            </blockquote>
            <p>GS lists &gt;900 citations of this book, so there may well be additional or followup studies covering the 40 years since. Or, also relevant is “Zuckerman, H. (1983). The scientific elite: Nobel laureates’ mutual influences. In R. S. Albert (Ed.), <em>Genius and eminence</em> (pp.&nbsp;241–252). New York: Pergamon Press”, and “Zuckerman H. ‘Sociology of Nobel Prizes’, <em>Scientific American</em> 217 (5): 25&amp; 1967.”</p>
          </section>
          <section id="dead-url">
            <h2><a href="#dead-url" title="Link to section: § 'Dead URL'">Dead URL</a></h2>
            <p><a href="https://www.lesswrong.com/posts/wAhgxmCf2ebHha5BJ/psa-please-list-your-references-don-t-just-link-them#comment-MMH9H4Y7iNDjfirZF" data-link-icon="LW" data-link-icon-type="text">A link to a research article in a post by Morendil</a> broke, he had not provided any formal citation data, <em>and</em> the original domain blocks all crawlers in its <code>robots.txt</code> so IA would not work. What to do?</p>
            <p>The simplest solution was to search a direct quote, turning up a Scribd mirror; Scribd is a parasite website, where people upload copies from elsewhere, which ought to make one wonder where the <em>original</em> came from. (It often shows up before the original in any search engine, because it automatically runs OCR on submissions, making them more visible to search engines.) With a copy of the journal issue to work with, you can easily find the official HP archives and <a href="https://www.hpl.hp.com/hpjournal/pdfs/IssuePDFs/1989-04.pdf" data-link-icon="pdf" data-link-icon-type="svg">download the original PDF</a>⁠.</p>
            <p>If that hadn’t worked, searching for the URL without <code>/pg_2/</code> in it yields the full citation, and then that can be looked up normally. Finally, somewhat more dangerous would be trying to find the article just by author surname &amp; year.</p>
          </section>
          <section id="description-but-no-citation">
            <h2><a href="#description-but-no-citation" title="Link to section: § 'Description But No Citation'">Description But No Citation</a></h2>
            <p>A 2013 <a href="https://gwern.net/doc/www/www.medicaldaily.com/edf8f97057799b156cf565a4ffd0494f310d3395.html" rel="archived alternate nofollow" data-url-original="https://www.medicaldaily.com/psychologists-discover-how-people-subconsciously-become-their-favorite-fictional-characters-240435" title="Psychologists Discover How People Subconsciously Become Their Favorite Fictional Characters (Original URL: https://www.medicaldaily.com/psychologists-discover-how-people-subconsciously-become-their-favorite-fictional-characters-240435 )">Medical Daily</a> on the effects of reading fiction omitted any link or citation to the research in question. But it is easy to find.</p>
            <p>The article says the authors are one Kaufman &amp; Libby, and implies it was published in the last year. So: go to Google Scholar, punch in <code>Kaufman Libby</code>, limit to ‘Since 2012’; and the correct paper ( <a href="https://gwern.net/doc/www/tiltfactor.org/227553b28ae45d80f73f5e2ffa17420c06c85833.pdf" id="kaufman-libby-2012" data-link-icon="pdf" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://tiltfactor.org/wp-content/uploads2/Kaufman_Libby2012_JPSPadvanceonlinepublication.pdf" title="Kaufman &amp; Libby 2012 (Original URL: https://tiltfactor.org/wp-content/uploads2/Kaufman_Libby2012_JPSPadvanceonlinepublication.pdf )">“Changing beliefs and behavior through experience-taking”</a>) is the first hit with fulltext available on the right-hand side as the text link “[PDF] from <code>tiltfactor.org</code>” &amp; many other domains.</p>
          </section>
          <section id="finding-followups">
            <h2><a href="#finding-followups" title="Link to section: § 'Finding Followups'">Finding Followups</a></h2>
            <p><a href="https://www.lesswrong.com/posts/X6APQeHhXH9mbredM/soylent-orange-whole-food-open-source-soylent#comment-PWDQq3f5qSqWRc82c" data-link-icon="LW" data-link-icon-type="text">Is soy milk bad for you</a> as one study suggests? Has anyone replicated it? This is easy to look into a little if you use the power of reverse citation search!</p>
            <p>Plug <code>Brain aging and midlife tofu consumption</code> into Google Scholar, one of the little links under the first hit points to “Cited by 176”; if you click on that, you can hit a checkbox for “Search within citing articles”; then you can search a query like <code>experiment OR randomized OR blind</code> which yields <a href="https://scholar.google.com/scholar?q=experiment+OR+randomized+OR+blind&amp;btnG=&amp;as_sdt=20005&amp;sciodt=0%2C9&amp;cites=14459450472515815282&amp;scipsc=1" data-link-icon="google-scholar" data-link-icon-type="svg">121 results</a>⁠. The <a href="https://gwern.net/doc/www/n.neurology.org/d3d3621441fed99260a76d7b3a08b1eacafd1fbb.html" id="henderson-al-2012" rel="archived alternate nofollow" data-url-original="https://n.neurology.org/content/78/23/1841.short" title="'Long-term soy isoflavone supplementation and cognition in women: A randomized, controlled trial', Henderson et al 2012 (Original URL: https://n.neurology.org/content/78/23/1841.short )">first result</a> shows no negative effect and a trend to a benefit, the second is inaccessible, the second &amp; third are reviews whose abstract suggests it would argue for benefits, and the fourth discusses sleep &amp; mood benefits to soy diets. At least from a quick skim, this claim is not replicating, and I am dubious about it.</p>
          </section>
          <section id="how-many-homeless">
            <h2><a href="#how-many-homeless" title="Link to section: § 'How Many Homeless?'">How Many Homeless?</a></h2>
            <p>Does NYC really have 114,000+ homeless school children? This case study demonstrates the critical skill of <em>noticing</em> the need to search at all, and the search itself is almost trivial.</p>
            <p><span>Won’t someone think of the children?</span> In March 2020, as <a href="https://en.wikipedia.org/wiki/COVID-19_pandemic_in_the_United_States" data-link-icon="wikipedia" data-link-icon-type="svg">New York coronavirus cases began their exponential increase</a> centered in Manhattan (with a similar trend to Wuhan/​Iran/​Italy), NYC Mayor <a href="https://en.wikipedia.org/wiki/Bill_de_Blasio" data-link-icon="wikipedia" data-link-icon-type="svg">Bill de Blasio</a> refused to take social distancing/​quarantine measures like ordering the NYC public school system closed, and this delay until 16 March contributed to the epidemic’s unchecked spread in NYC; one justification was that there were “114,085 homeless children” who received social services like free laundry through the schools. This number has been widely cited in the media by the <em>NYT</em>, <em>WSJ</em>, etc, and was vaguely sourced to “state data” reported by “Advocates for Children of New York”. This is a terrible reason to not deal with a pandemic that could kill tens of thousands of New Yorkers, as there are many ways to deliver services which do not require every child in NYC to attend school &amp; spread infections—but first, is this number even true?</p>
            <p><span>Basic numeracy: implausibly-large!</span> Activists of any stripe are untrustworthy sources, and a number like 114k should make any numerate person uneasy even without any <a href="https://en.wikipedia.org/wiki/Fermi_problem" data-link-icon="wikipedia" data-link-icon-type="svg">Fermi estimation</a> or fact-checking; “114,085” is suspiciously precise for such a difficult-to-measure or define thing like homelessness, and it’s well-known that the population of NYC is ~8m or 8,000k—is it really the case that around 1 in every 70 people living in NYC is a homeless child age ~5–18 attending a public school? They presumably have at least 1 parent, and probably younger siblings, so that would bring it up to &gt;228k or 1 in every &lt;35 inhabitants of NYC being homeless in general. Depending on additional factors like transiency &amp; turnover, the fraction could go much higher still. Does that make sense? No, not really. This quoted number is either surprising, or there is something missing.</p>
            <p><span>Redefining “homeless”.</span> Fortunately, the suspiciously-precise number and attribution make this a good place to start for a search. Searching for the number and the name of the activist group instantly turns up <a href="https://gwern.net/doc/www/www.advocatesforchildren.org/4396d149ff553a24534dfa3063f32211fbb8fe9c.html" rel="archived alternate nofollow" data-url-original="https://www.advocatesforchildren.org/node/1403" title="New Data Show Number of NYC Students who are Homeless Topped 100,000 for Fourth Consecutive Year (Original URL: https://www.advocatesforchildren.org/node/1403 )">the source press release</a>⁠, and the reasons for the bizarrely high number are revealed: the statistic actually redefines ‘homelessness’ to include living with relatives or friends, and counts any experience of any length in the previous year as rendering that student ‘homeless’ at the moment.</p>
            <blockquote>
              <p>The data, which come from the New York State Education Department, show that in the 2018-2019 school year, New York City district and charter schools identified 114,085, or one in ten, students as homeless. More than 34,000 students were living in New York City’s shelters, and more than twice that number (73,750) were living ‘doubled-up’ in temporary housing situations with relatives, friends, or others…“This problem is immense. The number of New York City students who experienced homelessness last year—85% of whom are Black or Hispanic—could fill the Barclays Center six times,” said Kim Sweet, AFC’s Executive Director. “The City won’t be able to break the cycle of homelessness until we address the dismal educational outcomes for students who are homeless.”</p>
            </blockquote>
            <p>The <a href="https://gwern.net/doc/www/www.coalitionforthehomeless.org/376804c98cc59e6939f6e3879828c286a3f1ee22.html" rel="archived alternate nofollow" data-url-original="https://www.coalitionforthehomeless.org/todays-read-new-york-city-had-114000-homeless-students-last-year/" title="Today's Read: New York City Had 114,000 Homeless Students Last Year (Original URL: https://www.coalitionforthehomeless.org/todays-read-new-york-city-had-114000-homeless-students-last-year/ )"><em>WSJ</em>’s article</a> (but not headline) confirms that ‘experienced’ does indeed mean ‘at any time in the year for any length of time’, rather than ‘at the moment’:</p>
            <blockquote>
              <p>City district and charter schools had 114,085 students without their own homes at some point last year, topping 100,000 for the fourth year in a row, according to state data released in a report Monday from Advocates for Children of New York, a nonprofit seeking better services for the disadvantaged. Most children were black or Hispanic, and living “doubled up” with friends, relatives or others. But more than 34,000 slept in city shelters at some point, a number larger than the entire enrollment of many districts, such as Buffalo, Rochester or Yonkers.</p>
            </blockquote>
            <p><span>Less than meet the eye.</span> So the actual number of ‘homelessness’ (in the sense that everyone reading those media articles understands it) is less than a third the quote, 34k, and that 34k number is likely itself a loose estimate of how many students would be homeless at the time of a coronavirus closure. This number is far more plausible and intuitive, and while one might wonder about what the underlying NYS Education Department numbers would reveal if fact-checked further, that’s probably unnecessary for showing how ill-founded the anti-closure argument is, since even by the activists’ own description, the relevant number is far smaller than 114k.</p>
          </section>
          <section id="citation-url-with-typo">
            <h2><a href="#citation-url-with-typo" title="Link to section: § 'Citation URL With Typo'">Citation URL With Typo</a></h2>
            <p><a href="https://gwern.net/doc/iq/high/2015-hofman.pdf" id="hofman-2015" data-link-icon="pdf" data-link-icon-type="svg" title="'Evolution of the Human Brain: From Matter to Mind', Hofman 2015">“Evolution of the Human Brain: From Matter to Mind”<span>, <span><span>Hofman</span><span>2015</span></span></span></a>⁠, discusses the limits to the intelligence of increasingly large primate brains due to considerations like increasing latency and overheating. One citation attempting to extrapolate upper bounds is “Biological limits to information processing in the human brain”<span>, <span><span title="et al">Cochrane</span> <span>et al</span> <span>1995</span></span>.</span></p>
            <p>The source information is merely a broken URL: <code>http://www.cochrane.org.uk/opinion/archive/articles.phd</code> which stands out for looking doubly-wrong: “.phd” is almost certainly a typo for “.ph<em>p</em>” (probably muscle memory on the part of Hofman from “PhD”), but it also gives a hint that the entire URL is wrong: why would an article or essay be named anything like <code>archive/articles.php</code>? That sounds like an <em>index</em> page listing all the available articles.</p>
            <p>After trying and failing to find Cochrane’s paper in the usual places, I returned to the hint. The Internet Archive doesn’t have that page under either possible URL, but the directory strongly hints that all of the papers would exist at URLs like <code>archive/brain.php</code> or <code>archive/information-processing.php</code>, and we can look up all of the URLs the IA has under that directory—how many could there be? <a href="https://web.archive.org/web/*/http://www.cochrane.org.uk/opinion/archive/*" data-link-icon="internetarchive" data-link-icon-type="svg">A lot</a>⁠, but only one has the keyword “brain” in it, providing us <a href="https://gwern.net/doc/iq/1995-cochrane-biologicallimitstoinformationprocessinginthebrain.html" id="cochrane-et-al-1995" title="'Biological limits to information processing in the human brain', Cochrane et al 1995">the paper itself</a>⁠.</p>
            <p>If that hadn’t worked, there was at least one other version hiding in the IA. When I googled the quoted title “Biological limits to information processing in the human brain”, the hits all appeared to be useless citations repeating the original Hofman citation—but for a crucial difference, as they cite a different URL (note the shift to an ‘archive.cochrane.org’ subdomain rather than the subdirectory <code>cochrane.org.uk/opinion/archive/</code>, and change of extension from <code>.html</code> to <code>.php</code>):</p>
            <ul>
              <li>
                <p>hit 5:</p>
                <blockquote>
                  <p>Biological Limits to Information Processing in the Human Brain. Retrieved from: <code>http://archive.cochrane.org.uk/opinion/archive/articles/brain9a.php</code></p>
                </blockquote>
              </li>
              <li>
                <p>hit 7:</p>
                <blockquote>
                  <p>Biological Limits to Information Processing in the Human Brain. Available online at: <code>http://archive.cochrane.org.uk/opinion/archive/articles/brain9a.php</code>; Da Costa …</p>
                </blockquote>
              </li>
            </ul>
            <p>Aside from confirming that it was indeed a ‘.php’ extension, that URL gives you <a href="https://web.archive.org/web/20161201053731/http://archive.cochrane.org.uk/opinion/archive/articles/brain9a.php" data-link-icon="internetarchive" data-link-icon-type="svg">a second copy of the paper in the IA</a>⁠. Unfortunately, the image links are broken in both versions, and the image subdirectories also seem to be empty in both IA versions, though there’s no weird JS image loading badness, so I’d guess that the image links were always broken, at least by 2004. There’s no indication it was ever published or mirrored anywhere else, so there’s not much you can do about it other than to contact Peter Cochrane (who is still alive and actively publishing although he leaves this particular article off his <a href="https://gwern.net/doc/www/petercochrane.com/d4de8653934460ebcbfc19cbf90149aa967b7949.html" rel="archived alternate nofollow" data-url-original="https://petercochrane.com/personal/publications" title="(Original URL: https://petercochrane.com/personal/publications )">publication list</a>).</p>
          </section>
          <section id="connotations">
            <h2><a href="#connotations" title="Link to section: § 'Connotations'">Connotations</a></h2>
            <p>A commenter <a href="https://www.lesswrong.com/posts/oFMywHmJffsCSDNB7/using-evolution-for-marriage-or-sex#comment-AJ5xdSRjq7mwtR7Ea" data-link-icon="LW" data-link-icon-type="text">who shall remain nameless</a> wrote</p>
            <blockquote>
              <p>I challenge you to find an example of someone saying “this den of X” where X does not have a negative connotation.</p>
            </blockquote>
            <p>I found a <a href="https://www.memphisdailynews.com/news/2012/nov/15/this-den-of-grizzlies-players-doesnt-bluff/" title="This Den of Grizzlies Players Doesn't Bluff">positive connotation within 5s</a> using my Google hotkey for <code>"this den of "</code>, and, curious about further ones, found additional uses of the phrase in regard to dealing with rattlesnakes in Google Books.</p>
          </section>
          <section id="too-narrow">
            <h2><a href="#too-narrow" title="Link to section: § 'Too Narrow'">Too Narrow</a></h2>
            <p>A failure case study: <a href="https://www.lesswrong.com/posts/wKWvodoAt3zRhyC4x/rationality-quotes-november-2012#comment-c4yECdhdDHoMvNWEs" data-link-icon="LW" data-link-icon-type="text">The_Duck</a> looked for but failed to find other uses of a famous <a href="https://en.wikipedia.org/wiki/Ludwig_Wittgenstein" data-link-icon="wikipedia" data-link-icon-type="svg">Wittgenstein</a> anecdote. His mistake was being <em>too specific</em>:</p>
            <blockquote>
              <p>Yes, clearly my Google-fu is lacking. I think I searched for phrases like “sun went around the Earth,” which fails because your quote has “sun went round the Earth.”</p>
            </blockquote>
            <p>As discussed in the search tips, when you’re formulating a search, you want to balance how many hits you get, aiming for a sweet spot of a few hundred high-quality hits to review—the broader your formulation, the more likely the hits will include your target (if it exists) but the more hits you’ll return. In The_Duck’s case, he used an overly-specific search, which would turn up only 2 hits at most; this should have been a hint to loosen the search, such as by dropping quotes or dropping keywords.</p>
            <p>In this case, my reasoning would go something like this, laid out explicitly: ‘“Wittgenstein” is almost guaranteed to be on the same page as any instance of this quote, since the quote is about Wittgenstein; LW, however, doesn’t discuss Wittgenstein much, so there won’t be many hits in the first place; to find this quote, I only need to narrow down those hits a <em>little</em>, and after “Wittgenstein”, the most fundamental core word to this quote is “Earth” or “sun”, so I’ll toss one of them in and… ah, there’s the quote!’</p>
            <p>If I were searching the general Internet, my reasoning would go more like “‘Wittgenstein’ will be on, like, a <em>million</em> websites; I need to narrow that down a <em>lot</em> to hope to find it; so maybe ‘Wittgenstein’ <em>and</em> ‘Earth’ <em>and</em> ‘Sun’… nope, nothing on the first page, so toss in <code>'goes around' OR 'go around'</code>—ah there it is!”</p>
            <p>(Actually, for the general Internet, just <code>Wittgenstein earth sun</code> turns up a first page mostly about this anecdote, several of which include all the details one could need.)</p>
          </section>
          <section id="try-it">
            <h2><a href="#try-it" title="Link to section: § 'Try It'">Try It</a></h2>
            <p>Someone asked on IRC: “anybody here know that one artist with the really creepy art sytle [sic] that starts with a z?”</p>
            <p>I googled: ‘that one artist with the really creepy art sytle [sic] that starts with a z’. It was hit #2, <a href="https://en.wikipedia.org/wiki/Zdzis%C5%82aw_Beksi%C5%84ski" data-link-icon="wikipedia" data-link-icon-type="svg">Zdzisław Beksiński</a>⁠. (DuckDuckGo, incidentally, buries Beksiński several pages in, and I didn’t find him in Bing at all.)</p>
          </section>
          <section id="really-just-try-it">
            <h2><a href="#really-just-try-it" title="Link to section: § 'Really, Just Try It'">Really, Just Try It</a></h2>
            <p>Quanticle asked:</p>
            <blockquote>
              <p>There’s a sci-fi book I’m thinking of, where the protagonist is a scout soldier fighting an endless war against an insectoid species. It reads like a cross between <em>Ender’s Game</em> and <em>Starship Troopers</em> (but is not written by John Sclazi or is <em>The Forever War</em>) and the main story takes place inside a frame story where two other people are actually “reading” this soldier’s memories from his salvaged battlesuit. There is a planet called “Golden”, where the soldier is allegedly from. Does anyone have any idea what I’m talking about?</p>
            </blockquote>
            <p>The search <code>book about a soldier from the planet golden</code> immediately turned up <a href="https://en.wikipedia.org/wiki/John_Steakley" data-link-icon="wikipedia" data-link-icon-type="svg">John Steakley’s</a> <a href="https://en.wikipedia.org/wiki/Armor_(novel)" data-link-icon="wikipedia" data-link-icon-type="svg"><em>Armor</em></a>⁠. (This was showing off a little—<em>Armor</em> is well-regarded and difficult to forget, and I’d read it a long time ago and already knew the answer, pace the hacker koan<a href="#fn20" id="fnref20" role="doc-noteref"><sup>20</sup></a>⁠.)</p>
            <p>Quanticle noted that “You know, I searched for similar phrases, but I ended up fixating on the soldier’s key phrase, where he called his battle-trance”The Machine”, and that dragged in lots of irrelevancies.” (A good intuition for search engine use would shy away from using any word or phrase as incredibly generic as “the machine”.)</p>
          </section>
          <section id="try-it-1">
            <h2><a href="#try-it-1" title="Link to section: § '(Try It!)'">(Try It!)</a></h2>
            <p>FeepingCreature asked, while designing a compiler for a custom language,</p>
            <blockquote>
              <p>Hey, what was the official name for Lisp’s “data and code” thing?</p>
            </blockquote>
            <p>I already knew that it is “<a href="https://en.wikipedia.org/wiki/Homoiconicity" data-link-icon="wikipedia" data-link-icon-type="svg">homoiconicity</a>”, but I bet that <code>official name for Lisp's "data and code" thing</code> would work if I tried it in Google. It did.</p>
          </section>
          <section id="yes-that-works-too">
            <h2><a href="#yes-that-works-too" title="Link to section: § 'Yes, That Works Too'">Yes, That Works Too</a></h2>
            <p><a href="https://gwern.net/doc/www/old.reddit.com/4780683b1e77b3f92360405ebe92ba3f468fefe9.html" data-link-icon="alphabet" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://old.reddit.com/r/slatestarcodex/comments/p21d1t/for_gods_sake_google_it/h8ibsff/" title="(Original URL: https://www.reddit.com/r/slatestarcodex/comments/p21d1t/for_gods_sake_google_it/h8ibsff/ )">Grayson81</a>:</p>
            <blockquote>
              <p>One thing that’s rather shocking to those of us who used search engines (and even directories like Yahoo before they got the idea of becoming real search engines from Google) is just how good they’ve got at understanding a vague, poorly written or mistaken search.</p>
              <p>…I remember trying to explain how Google works to my mother ten years ago and explaining why “who’s that actress? You know, the one with the eyes. Not <a href="https://en.wikipedia.org/wiki/Katy_Perry" data-link-icon="wikipedia" data-link-icon-type="svg">Katy Perry</a>” isn’t a question that a computer can answer. Now she can Google exactly that and all of the top results are telling her that she’s thinking of <a href="https://en.wikipedia.org/wiki/Zooey_Deschanel" data-link-icon="wikipedia" data-link-icon-type="svg">Zooey Deschanel</a>!</p>
            </blockquote>
          </section>
          <section id="comics">
            <h2><a href="#comics" title="Link to section: § 'Comics'">Comics</a></h2>
            <p><a href="https://juliagalef.com/">Julia Galef</a> tweeted:</p>
            <blockquote>
              <p>I read a webcomic ~15 years ago that I’ve been unable to find since, even with my best google-fu. It involved a robot living a bleak life as a working stiff. At the end he cracked open his “skull” and there was a small dying creature inside. The art style was less cartoony, and more like Moebius, I think? And maybe it was wordless? And, sorry, it wasn’t a “webcomic” in the sense of a long-running thing. It was a self-contained story, maybe 15 pages long?</p>
            </blockquote>
            <p>Ultimately rediscovering that</p>
            <blockquote>
              <p>The comic was called <a href="https://gwern.net/doc/fiction/science-fiction/2004-chivers-headcase.pdf" id="chivers-2004" data-link-icon="pdf" data-link-icon-type="svg" title="'Headcase', Chivers 2004">“Headcase”</a> and it was by Sam Chivers.</p>
            </blockquote>
            <p>Unfortunately, no mirrors of it appeared online or on Chivers’s current website, and discussions of it mentioned that it was interesting for being an <a href="https://en.wikipedia.org/wiki/Adobe_Flash" data-link-icon="wikipedia" data-link-icon-type="svg">Adobe Flash</a> webcomic. Worse still, nothing useful appeared <a href="https://web.archive.org/web/2020*/http://www.realitytax.com/*" data-link-icon="internetarchive" data-link-icon-type="svg">in the Internet Archive for the original website</a>—somehow the IA appeared to have missed any relevant <code>.swf</code> files, and ‘head’/​‘case’ turned up no relevant looking filenames. It might have been buried in the opaquely-named images, and my usual next step would be to download the IA archives and inspect every image, but in other hits, I found that an obscure comics publisher had published an anthology involving Chivers, and <a href="https://gwern.net/doc/www/theslingsandarrows.com/8a9eded3ebec4e1a610ff3ca854d8a0c2c5fe963.html" id="plowright-2020" rel="archived alternate nofollow" data-url-original="https://theslingsandarrows.com/prophecy-anthology-volume-1/" title="'<em>Prophecy Anthology Volume 1</em>, review', Plowright 2020 (Original URL: https://theslingsandarrows.com/prophecy-anthology-volume-1/ )">closer inspection</a> confirmed that “Headcase” was in fact published in their (long out of print) 2004 anthology <em>Prophecies: Volume 1</em>. (Not a prophetic name inasmuch as there was no volume 2.)</p>
            <p>In one of the usual ironies of linkrot, Chivers presumably taking down “Headcase” for print publication in <em>Prophecy</em> may have preserved it, as while I am unable to find any digital copies, the paper version is easily obtained as a used book &amp; scanned at modest cost.</p>
          </section>
          <section id="beating-pdf-passwords">
            <h2><a href="#beating-pdf-passwords" title="Link to section: § 'Beating PDF Passwords'">Beating PDF Passwords</a></h2>
            <p><span id="astronomy"><a href="https://cognitivemedium.com/vme" data-link-icon="MN" data-link-icon-type="text">A physics article</a></span> mentioned they had been unable to get <a href="https://gwern.net/doc/science/1973-drake.pdf" id="drake-1973" data-link-icon="pdf" data-link-icon-type="svg" title="'Life on a Neutron Star: An Interview With Frank Drake', Drake 1973">an old 1973 interview</a> in a popular magazine; as is usually the case for non-scholarly magazines, after looking thoroughly, I could find no trace of it anywhere (not even in libraries or used-magazine sellers) other than an expensive DVD collection of back issues 1970–2010 still being sold by the publisher. Reasoning that if they had digitized the archives and were even selling it as a DVD collection, they ought to provide subscribers access to them as well, I signed up—they didn’t! So I resorted to the DVD, as, worst-case, I should be able to get it running under <a href="https://en.wikipedia.org/wiki/Wine_(software)" data-link-icon="wikipedia" data-link-icon-type="svg">WINE</a> if nothing else, and can screenshot the interview.</p>
            <p>The DVDs turned out to store all the PDFs as encrypted PDFs and the metadata in an ancient opaque database format I’d never heard of. Despite WINE AppDB’s claims, the viewing software only partially worked, and I set about attacking the PDFs directly. They used actual encryption, so pdftk couldn’t strip the passwording. Given the viewing software, I hypothesized that there was either a single master password or per-PDF passwords stored in the database.</p>
            <p>In the hopes of it being a single short master password, I installed <a href="https://en.wikipedia.org/wiki/John_the_Ripper" data-link-icon="wikipedia" data-link-icon-type="svg">John the Ripper</a> (JtR) jumbo edition and extracted the hash of a random file to attack: <code>/snap/john-the-ripper/current/run/pdf2john.pl *.pdf &gt; ~/hash</code>. (Note: pdf2john is not in the default JtR, and it depends on JtR internal files so you can’t easily just copy it out of the <a href="https://en.wikipedia.org/wiki/GitHub" data-link-icon="wikipedia" data-link-icon-type="svg">Github</a> repo &amp; run it, as I discovered the hard way. You need to install the jumbo edition.) The password hashes of all the PDFs indeed turned out to be the same, so it used a master password. A simple attack with default password-space could be executed as <code>john-the-ripper ~/hash</code>. While I waited for all of the DVDs to copy, I saw that JtR was getting something like only a hundred thousand hashes/​s on my 16 Threadripper CPU cores, and did not have any success up to 5-character passwords.</p>
            <p>If the password wasn’t really short, CPU wouldn’t be enough. I decided to switch to <a href="https://en.wikipedia.org/wiki/Hashcat" data-link-icon="wikipedia" data-link-icon-type="svg">Hashcat</a> to put my 2×1080ti Nvidia GPUs to good use, as they ought to run hundreds of times faster than JtR. (To convert the JtR hash format to Hashcat hash format, you delete the colon-separated filename field at the beginning of each line.) Hashcat uses a <a href="https://gwern.net/doc/www/hashcat.net/87fbd82f8b8794603fb3b0cca174c21310b4741b.html" rel="archived alternate nofollow" data-url-original="https://hashcat.net/wiki/doku.php?id=mask_attack" title="(Original URL: https://hashcat.net/wiki/doku.php?id=mask_attack )">powerful but confusing</a> DSL of specifying the exact password-space, and I made a reasonable guess that if the original programmer was so lazy as to use a single master password, he would also use a simple alphanumeric password (uppercase + lowercase + decimal numbers), and nothing harder to type or read. To specify the PDF hash type and an attack starting at 1-character alphanumeric &amp; increasing, I wound up with the incantation <code>hashcat -m 10500 ~/hash.cat -w 3 --force -a 3 --increment -1 '?l?u?d' ?1?1?1?1?1?1?1?1?1?1?1</code>.</p>
            <p>Hashcat worked much better and within an hour had bruteforced on the order of 170 billion hashes and up somewhere around 8 characters. This did not succeed either. At this point, another programmer thought it’d be fun to participate and, while reverse-engineering the executable to see how it decrypted PDFs, suggested that the master password was probably hardcoded as a string literal inside the viewer executable. One could just dump all the strings inside it with the CLI utility <code>strings *.exe &gt; strings.txt</code>, and then use it as a Hashcat password list. To my chagrin, when I finally got around to trying <code>cat strings.txt | hashcat -m 10500 ~/hash.cat -w 3</code>, it finished within 1s.</p>
            <p>The password turned out to be <code>B775tO11dQvu74</code>. I was right that it was alphanumerical, but at a length of 14 characters, I doubt I would have brute-forced it. (He successfully reverse-engineered it and discovered the viewer had been used for several other magazine archives as well, apparently, and simply switched master passwords to decrypt each one; the other passwords left in the executable were <code>PbS19LuXd2pTXw</code>, <code>1386r8wRrH01</code>, &amp; <code>mfU33QQNlAFGI1</code>.)</p>
            <p>I then decrypted the PDF (<code>for PDF in *.pdf; do pdftk "$PDF" input_pw "B775tO11dQvu74" output foo.pdf &amp;&amp; mv foo.pdf "$PDF"; done</code>), extracted &amp; uploaded the interview, and archived the collection elsewhere.</p>
          </section>
          <section id="lewontins-thesis">
            <h2><a href="#lewontins-thesis" title="Link to section: § 'Lewontin’s Thesis'">Lewontin’s Thesis</a></h2>
            <p>In <a href="https://gwern.net/doc/www/www.nature.com/e4b871d14e7cf16b5f751d743dcdba1981962da0.pdf" data-link-icon="n" data-link-icon-type="text" rel="archived alternate nofollow" data-url-original="https://www.nature.com/articles/266283a0.pdf" title="Caricature of Darwinism (Original URL: https://www.nature.com/articles/266283a0.pdf )">a vituperative review in <em>Nature</em></a> in 1977-03-17, the Harvard-professor <a href="https://en.wikipedia.org/wiki/Richard_Lewontin" data-link-icon="wikipedia" data-link-icon-type="svg">R. C. Lewontin</a> excoriated <a href="https://en.wikipedia.org/wiki/Richard_Dawkins" data-link-icon="wikipedia" data-link-icon-type="svg">Richard Dawkins’s</a> classic <a href="https://en.wikipedia.org/wiki/The_Selfish_Gene" data-link-icon="wikipedia" data-link-icon-type="svg"><em>The Selfish Gene</em></a> and <a href="https://en.wikipedia.org/wiki/Sociobiology" data-link-icon="wikipedia" data-link-icon-type="svg">sociobiology</a> in general, giving as an example</p>
            <blockquote>
              <p>For more than 40 years evolutionary theory has remained free of a naive selectionism, but in recent times there has been a return to the extreme form of the adaptationist program, as evolutionists have rediscovered behaviour. Beginning with the undoubted truth that behaviour must, like morphology and physiology, be subject to the force of <a href="https://en.wikipedia.org/wiki/Natural_selection" data-link-icon="wikipedia" data-link-icon-type="svg">natural selection</a>⁠, the new Panglossians end with the old error that all describable behaviour must be the direct product of natural selection. The scientific manifestation of this trend can be seen in every issue of say, <em>The American Naturalist</em>, which is permeated by the language, if not the formal apparatus, of <a href="https://en.wikipedia.org/wiki/Game_theory" data-link-icon="wikipedia" data-link-icon-type="svg">game theory</a>⁠, and in the development of the school of ‘sociobiology’, among whose more extraordinary productions is a recent highly praised dissertation explaining <a href="https://en.wikipedia.org/wiki/Fellatio" data-link-icon="wikipedia" data-link-icon-type="svg"><em>fellatio</em></a> and <a href="https://en.wikipedia.org/wiki/Cunnilingus" data-link-icon="wikipedia" data-link-icon-type="svg"><em>cunnilingus</em></a> among the upper middle classes as an adaptive response to constant resources. The popular manifestation of this new caricature of Darwinism reaches its most extreme form in <em>The Selfish Gene</em> by Richard Dawkins.</p>
            </blockquote>
            <p>As is common in book reviews, Lewontin provides no citations, and <a href="https://twitter.com/DevoEvoMed/status/1478785200964476929" data-link-icon="twitter" data-link-icon-type="svg">2 biologists</a> were curious but unable to figure out what Lewontin was referring to despite searching.</p>
            <p>The thesis in question is easy to find in under a minute, because the context gives so many hints: Lewontin refers to it as notorious &amp; widely discussed so it will have many substantive citations (if only to attack it); it is ‘recent’ (and sociobiology was a heated controversy so it is unlikely to be ‘recent’ in the sense of ‘a quiet field of research still mulling over a provocative paper from 2 decades’ before, but more like ‘within the past 2 or 3 years’ &amp; certainly at least 1970–1977), it is a ‘dissertation’ and so single-authored &amp; almost certainly a PhD thesis by someone who became at least a postgrad researcher (because a master’s thesis would be too low-status to be discussed or praised, or singled out for abuse in <em>Nature</em>—it would be unclassy for a chaired Harvard professor to attack such a junior grad student’s work there like that), and it likely uses the words “fellatio” and “cunnilingus” as technical terms &amp; decorous Latinate scientific censoring.</p>
            <p>If we plug into Google Scholar a date-range of 1970–1977 and the simplest possible query <code>fellatio cunninglingus "evolutionary psychology" OR sociobiology</code> or <code>fellatio cunninglingus sociobiology</code> or <code>fellatio cunninglingus "evolutionary psychology"</code>, we see in GS 2 hits (for the former) or among the hits (latter), the immediately-relevant looking <a href="https://gwern.net/doc/genetics/selection/natural/human/1977-weinrich.pdf" id="weinrich-1977" data-link-icon="pdf" data-link-icon-type="svg" title="'Human sociobiology: Pair-bonding and resource predictability (effects of social class and race)', Weinrich 1977">“Human sociobiology: Pair-bonding and resource predictability (effects of social class and race)”<span>, <span><span>Weinrich</span><span>1977</span></span></span></a> and <a href="https://gwern.net/doc/genetics/selection/natural/human/1976-weinrich.pdf" id="weinrich-1976" data-link-icon="pdf" data-link-icon-type="svg" title="'Human Reproductive Strategy: I. Environmental Predictability And Reproductive Strategy; Effects Of Social Class And Race. II. Homosexuality And Non-Reproduction; Some Evolutionary Models', Weinrich 1976">“Human Reproductive Strategy: I. Environmental Predictability And Reproductive Strategy; Effects Of Social Class And…”<span>, <span><span>Weinrich</span><span>1976</span></span></span></a>⁠, both by the same author ( <a href="https://scholar.google.com/scholar?cites=15430285300114043496&amp;as_sdt=20000005&amp;sciodt=0,21" data-link-icon="google-scholar" data-link-icon-type="svg">148</a>+<a href="https://scholar.google.com/scholar?cites=4719348106040602943&amp;as_sdt=20000005&amp;sciodt=0,21" data-link-icon="google-scholar" data-link-icon-type="svg">16</a> citations, quite healthy); the single-authorship &amp; <code>search.proquest.com</code> domain for the latter immediately tells us that it’s a PhD thesis; clicking verifies that the thesis was at Harvard (which gives it both prestige Lewontin loathes &amp; ensures he could easily hear of it); the similarity of titles suggests that the paper is a condensed version of the thesis (reading the paper suggests this isn’t entirely true but is more of an update); Weinrich did indeed go on to a long career (at <a href="https://en.wikipedia.org/wiki/San_Diego_University" data-link-icon="wikipedia" data-link-icon-type="svg">San Diego University</a>⁠, publishing <a href="https://scholar.google.com/citations?user=qIeHxgkAAAAJ&amp;view_op=list_works&amp;alert_preview_top_rm=2&amp;sortby=pubdate" data-link-icon="google-scholar" data-link-icon-type="svg">up until 2014</a>); there are attacks like <a href="https://gwern.net/doc/genetics/selection/natural/human/1978-lande.pdf" id="lande-weinrich-1978" data-link-icon="pdf" data-link-icon-type="svg" title="Are Humans Maximizing Reproductive Success? [with Reply]"><span><span>Lande</span><span>1987</span></span></a> showing it did not pass without notice; and even the ProQuest preview of the abstract looks consistent with Lewontin’s summary (there can’t be that many such theses!).</p>
            <p><span>So, we can be sure that Lewontin is referring to <span><span>Weinrich</span><span>1976</span></span>.</span></p>
          </section>
          <section id="edward-tellers-atom-alphabet">
            <h2><a href="#edward-tellers-atom-alphabet" title="Link to section: § 'Edward Teller’s Atom Alphabet'">Edward Teller’s “Atom Alphabet”</a></h2>
            <p>Nuclear physicist <a href="https://en.wikipedia.org/wiki/Edward_Teller" data-link-icon="wikipedia" data-link-icon-type="svg">Edward Teller</a> wrote a rhyming ‘atom alphabet’ about the nuclear era, but only a few of the letters like A/​B/​S are ever quoted. Did he write a <em>whole</em> alphabet?</p>
            <p><a href="https://gwern.net/doc/www/old.reddit.com/a2b78313f9aa5bc4e79048c9003b6e1509d3448a.html" data-link-icon="reddit" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://old.reddit.com/r/unsong/comments/4pzyvq/edward_tellers_atom_alphabet_1946/" title="(Original URL: https://www.reddit.com/r/unsong/comments/4pzyvq/edward_tellers_atom_alphabet_1946/ )">Tracing citations back</a> to a <em>Time</em> magazine &amp; <a href="https://en.wikipedia.org/wiki/Laura_Fermi" data-link-icon="wikipedia" data-link-icon-type="svg">Laura Fermi’s</a> memoir strongly implies that he did not, and only write A/​B/​F/​H/​S. (There has been at least one effort <a href="https://www.reddit.com/r/unsong/comments/zckyg0/completing_edward_tellers_atom_alphabet_with/" data-link-icon="reddit" data-link-icon-type="svg">to write the rest</a>⁠.)</p>
          </section>
          <section id="pressley-et-al-1989">
            <h2><a href="#pressley-et-al-1989" title="Link to section: § 'Pressley et al 1989'"><span><span title="et al">Pressley</span> <span>Et Al</span> <span>1989</span></span></a></h2>
            <p>In <a href="https://www.patreon.com/posts/reading-and-85345515" data-link-icon="patreon" data-link-icon-type="svg">a discussion of learning</a>⁠, <a href="https://gwern.net/doc/www/andymatuschak.org/991e56a3a61f84d8cb1025af60ccfa6c60da6ccb.html" rel="archived alternate nofollow" data-url-original="https://andymatuschak.org/" title="(Original URL: https://andymatuschak.org/ )">Andy Matuschak</a> referenced a paper on an <a href="https://gwern.net/doc/psychology/cognitive-bias/illusion-of-depth/index" title="'illusion-of-depth bias tag', N/A 2023">illusion-of-depth</a> in reading comprehension (related to illusions of learning from using cramming rather than <a href="https://gwern.net/spaced-repetition" id="gwern-spaced-repetition" title="‘Spaced Repetition for Efficient Learning’, Gwern 2009">spaced repetition</a>), but mentioned he had been unable to find a copy anywhere to verify it. The citation for this paper was:</p>
            <blockquote>
              <p>Pressley, M., Ghatala, E. S., Pirie, J., &amp; Woloshyn, V. E. (1990). <a href="https://gwern.net/doc/psychology/cognitive-bias/illusion-of-depth/1990-pressley.pdf" id="pressley-et-al-1990" data-link-icon="pdf" data-link-icon-type="svg" title="'Being really, really certain you know the main idea doesn&amp;#39;t mean you do', Pressley et al 1990">“Being really, really certain you know the main idea doesn’t mean you do”</a>⁠. <a href="https://gwern.net/doc/psychology/1990-zutell-literacytheoryandresearch39thnationalreadingconference.pdf" id="zutell-mccormick-1990" data-link-icon="pdf" data-link-icon-type="svg" title="‘<em>Literacy Theory and Research: Analyses from Multiple Paradigms. Proceedings of the Annual Meeting of the National Reading Conference (39th, AUstin, Texas, November 28–December 2, 1989)’, Zutell &amp; McCormick 1990"><em>National Reading Conference Yearbook</em>, 39</a>⁠, 249–256.</p>
            </blockquote>
            <p>I rose to the challenge.</p>
            <p><span>Standard checks.</span> Matuschak is indeed correct that this paper does not show up in any of the usual places, nor does ‘yearbook’ #9 seem to show up; this nut will not be cracked instantly. We do not see any encouraging hints if we google the citation (only a sporadic handful of later citations to it, which are sporadic enough to suggest that they too <a href="https://gwern.net/leprechaun#citogenesis-how-often-do-researchers-not-read-the-papers-they-cite" id="gwern-leprechaun-citogenesis-how-often-do-researchers-not-read-the-papers-they-cite" title="‘Leprechaun Hunting &amp; Citogenesis § Citogenesis: How Often Do Researchers Not Read The Papers They Cite?’, Gwern 2014">are citing papers they have not read</a> &amp; that this will be hard to find). University &amp; ProQuest databases turn up nothing for either.</p>
            <p>This begins to look anomalous, so I broadened the search in Google. Here I stumbled across several of the yearbooks hosted at what looks like the National Reading Conference’s website; a targeted <code>site:</code> search, alas, fails to turn up anything useful. They may have scanned some later yearbooks, but apparently not the 1989 one…? Unfortunately, a dead end.</p>
            <p><span>Barkless dogs.</span> So we turn to book sources, like used-book search engines. We can find many of these yearbooks used at reasonable prices, but <em>not</em> #39—not a trace of it! This is odd. Being the 39<sup>th</sup> yearbook, with the others often available, would imply that it is available too: such serial publications don’t usually vary that much from year to year—if the ones before &amp; after it are easy to get, it should be too. What one notices is that the titles don’t look anything like “<em>National Reading Conference Yearbook</em>, 39”: this citation must be wrong, that’s not how they were titled! With this in mind, we can search for a used copy to buy &amp; scan, but this would be premature to do: now we have explained the prior absence of hits, and need to redo our searches; we thought there was no scan online before, but we know that was misleading so it may exist after all.</p>
            <p><span>Alternate titles.</span> Knowing this, we can search more broadly in Google, and skimming search results, look what we find! The PDF snippet reveals that our quarry, “Proceedings of the Annual Meeting of The National Reading Conference (39<sup>th</sup>…)” has been hidden behind the long uncited title “<em>Literacy Theory and Research: Analyses from Multiple Paradigms</em>”. Well, no wonder you can’t find it normally, and also (disappointingly but unsurprisingly), no wonder everyone copies the same incorrect citation.</p>
            <figure>
              <img alt="Screenshot of key Google search hit, revealing the Academia.edu PDF copy of ERIC scan of National Reading Conference Yearbook #39." decoding="async" height="301" loading="lazy" src="https://gwern.net/doc/technology/google/2023-07-08-gwern-google-searchcasestudy-pressleyetal1990academiaeduhit.png" width="1227">
              
            </figure>
            <p><span>Alternate paths.</span> <span>Downloading it, <span><span title="et al">Pressley</span> <span>et al</span> <span>1989</span></span> turns out to be buried on pg256 of this PDF; now that we know what to look for, this book turns out to have been easily findable after all—we can readily find the original non-Academia.edu PDF on our old friend</span> <a href="https://en.wikipedia.org/wiki/Education_Resources_Information_Center" data-link-icon="wikipedia" data-link-icon-type="svg">ERIC</a><a href="#fn21" id="fnref21" role="doc-noteref"><sup>21</sup></a> and can find other yearbooks easily. We can also doublecheck other strategies: for example, if we had known the full names of the authors rather than the abbreviated ones in the citation, and we had googled something like “Michael Pressley, Elizabeth Ghatala, Jennifer Pirie, Vera E. Woloshyn”, that would have matched the indexed fulltext PDFs immediately. (Since you can often find the full names of authors even if the citation abbreviates them, this is a good tactic to know.)</p>
            <p>Thus, in this instance, it’s crucial to remember that citations can be inaccurate and one must try variations. Over-fixating on the book title can hamper efforts to locate the article, which was, in reality, merely a click away.</p>
          </section>
        </section>
        <section id="see-also">
          <h2><a href="#see-also" title="Link to section: § 'See Also'">See Also</a></h2>
          <div>
            <ul>
              <li>
                <a href="https://gwern.net/fulltext" id="gwern-fulltext" title="Jailbreak copies of these and I will pay you money.">My outstanding research paper /  book bounties</a>
              </li>
              <li>
                <a href="https://gwern.net/tank" id="gwern-tank" title="AI folklore tells a story about a neural network trained to detect tanks which instead learned to detect time of day; investigating, this probably never happened.">“The Neural Net Tank Urban Legend”</a>
              </li>
              <li>
                <a href="https://gwern.net/leprechaun" id="gwern-leprechaun" title="'Leprechaun Hunting &amp; Citogenesis', Branwen 2014">“Leprechaun hunting and historical context”</a>
              </li>
            </ul>
          </div>
        </section>
        <section id="external-links">
          <h2><a href="#external-links" title="Link to section: § 'External Links'">External Links</a></h2>
          <ul>
            <li>
              <a href="https://www.millionshort.com/">“Million Short”</a> (search engine overlay which removes top 100/​1k/​10k/​100k/​1m domains from hits, exposing obscurer sites which may be highly novel)
            </li>
            <li>Practice G search problems: <a href="https://web.archive.org/web/20140221080504/https://www.wired.com/geekdad/tag/a-google-a-day/" data-link-icon="alphabet" data-link-icon-type="svg">“A Google A Day”</a>⁠; <a href="https://gwern.net/doc/www/www.codespaces.com/5a3860e4bcce8a5dd82b5ae5ab7ccf8abaec643e.html" data-link-icon="alphabet" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://www.codespaces.com/power-searching-with-google.html" title="(Original URL: https://www.codespaces.com/power-searching-with-google.html )">Google Power Searching course</a> (OK for beginners but you may want to skip the videos in favor of the slides)
            </li>
            <li>
              <a href="https://www.lesswrong.com/posts/37sHjeisS9uJufi4u/scholarship-how-to-do-it-efficiently" data-link-icon="LW" data-link-icon-type="text">“Scholarship: How to Do It Efficiently”</a>
            </li>
            <li>
              <a href="https://www.drmaciver.com/2019/05/how-to-do-hard-things/">“How to do hard things”</a>
            </li>
            <li>
              <a href="https://xkcd.com/627/" data-link-icon="XKCD" data-link-icon-type="text,quad,sans">“Tech Support Cheat Sheet”</a>
            </li>
            <li>
              <a href="https://academia.stackexchange.com/questions/90318/do-repositories-of-translated-papers-exist/93209#93209" data-link-icon="stackexchange" data-link-icon-type="svg">“Do repositories of translated papers exist?”</a>
            </li>
            <li>
              <a href="https://gwern.net/doc/www/old.reddit.com/c15cf848ea8449716b62762738bbe5cd16ba50c2.html" data-link-icon="reddit" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://old.reddit.com/r/DataHoarder/" title="(Original URL: https://www.reddit.com/r/DataHoarder/ )"> / ​r / ​DataHoarder</a>⁠/ ​<a href="https://gwern.net/doc/www/old.reddit.com/ece168c0ec8756bd91bf377d211255fd692a04a5.html" data-link-icon="reddit" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://old.reddit.com/r/Piracy/" title="(Original URL: https://www.reddit.com/r/Piracy/ )"> / ​r / ​Piracy</a>
            </li>
            <li>Archive Team’s <a href="https://wiki.archiveteam.org/index.php?title=ArchiveBot" data-link-icon="internetarchive" data-link-icon-type="svg">Archive Bot</a>
            </li>
            <li>
              <a href="https://beepb00p.xyz/pkm-search.html" id="gerasimov-2019" data-link-icon="🤖" data-link-icon-type="text" title="'Building personal search infrastructure for your knowledge and code: Overview of search tools for desktop and mobile; using Emacs and Ripgrep as desktop search engine', Gerasimov 2019">“Building personal search infrastructure for your knowledge and code: Overview of search tools for desktop and mobile; using Emacs and Ripgrep as desktop search engine”</a>
            </li>
            <li>
              <a href="https://www.lesswrong.com/posts/d6yNW5T6J9rtnGizc/give-it-a-google" data-link-icon="alphabet" data-link-icon-type="svg">“Give it a google!”</a>
            </li>
            <li>
              <a href="https://www.lesswrong.com/posts/TCTtaFPqbMrQhttCD/five-routes-of-access-to-scientific-literature" data-link-icon="LW" data-link-icon-type="text">DeepDyve suggestion</a>
            </li>
            <li>
              <a href="https://blog.gingerbeardman.com/2023/05/24/ordering-photocopies-from-japans-national-library/">“Ordering photocopies from Japan’s National Library”</a>
            </li>
            <li>Discussion: <a href="https://en.wikipedia.org/wiki/Hacker_News" data-link-icon="wikipedia" data-link-icon-type="svg">HN</a>: <a href="https://gwern.net/doc/www/news.ycombinator.com/1825cf2969c723cbf78c03c2d1b7ac593e927f8c.html" data-link-icon="hn" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://news.ycombinator.com/item?id=18666574" title="(Original URL: https://news.ycombinator.com/item?id=18666574 )">1</a>⁠, <a href="https://gwern.net/doc/www/news.ycombinator.com/30721ae2ac80c788520ed537f405c797d8eac58b.html" data-link-icon="hn" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://news.ycombinator.com/item?id=26847596" title="(Original URL: https://news.ycombinator.com/item?id=26847596 )">2</a>⁠; <a href="https://gwern.net/doc/www/old.reddit.com/0d023966a0c138c7c6861c80a2054b9b3c114aa3.html" data-link-icon="SSC" data-link-icon-type="text,tri" rel="archived alternate nofollow" data-url-original="https://old.reddit.com/r/slatestarcodex/comments/a5ljk1/internet_search_tips_effective_use_of/" title="(Original URL: https://www.reddit.com/r/slatestarcodex/comments/a5ljk1/internet_search_tips_effective_use_of/ )">Reddit</a>⁠; <a href="https://www.lesswrong.com/posts/EF6YAq2aD5dt2sgeN/summary-internet-search-tips-by-gwern-branwen" data-link-icon="LW" data-link-icon-type="text">LW</a>
            </li>
          </ul>
        </section>
        <section id="appendix">
          <h2><a href="#appendix" title="Link to section: § 'Appendix'">Appendix</a></h2>
          <section id="searching-the-google-reader-archives">
            <h2><a href="#searching-the-google-reader-archives" title="Link to section: § 'Searching the Google Reader archives'">Searching the Google Reader Archives</a></h2>
            <div>
              <blockquote>
                <p>A tutorial on how to do manual searches of the 2013 <a href="https://en.wikipedia.org/wiki/Google_Reader" data-link-icon="wikipedia" data-link-icon-type="svg">Google Reader</a> archives on the <a href="https://en.wikipedia.org/wiki/Internet_Archive" data-link-icon="wikipedia" data-link-icon-type="svg">Internet Archive</a>⁠. Google Reader provides fulltext mirrors of many websites which are long gone and not otherwise available even in the IA; however, the Archive Team archives are extremely user-unfriendly and challenging to use even for programmers. I explain how to find &amp; extract specific websites.</p>
              </blockquote>
            </div>
            <p>A little-known way to ‘undelete’ a blog or website is to use Google Reader (GR). <span>Unusual archive: Google Reader.</span> GR crawled regularly almost all blogs’ RSS feeds; RSS feeds often contain the fulltext of articles. If a blog author writes an article, the fulltext is included in the RSS feed, GR downloads it, and then the author changes their mind and edits or deletes it, GR would redownload the new version but it would continue to show the version the old version as well (you would see two versions, chronologically). If the author blogged regularly and so GR had learned to check regularly, it could hypothetically grab different edited versions, even, not just ones with weeks or months in between. Assuming that GR did not, as it sometimes did for inscrutable reasons, stop displaying the historical archives and only showed the last 90 days or so to readers; I was never able to figure out why this happened or if indeed it really did happen and was not some sort of UI problem. Regardless, if all went well, this let you undelete an article, albeit perhaps with messed up formatting or something. Sadly, GR was closed back in 2013 and you cannot simply log in and look for blogs.</p>
            <p><span>Archive Team mirrored Google Reader.</span> However, before it was closed, <a href="https://wiki.archiveteam.org/index.php?title=Google_Reader" data-link-icon="internetarchive" data-link-icon-type="svg">Archive Team</a> launched a major effort to download as much of GR as possible. So in that dump, there may be archives of all of a random blog’s posts. Specifically: if a GR user subscribed to it; if Archive Team knew about it; if they requested it in time before closure; and if GR did keep full archives stretching back to the first posting.</p>
            <p><span>AT mirror is raw binary data.</span> Downside: the Archive Team dump is <em>not</em> in an easily browsed format, and merely figuring out what it <em>might</em> have is difficult. In fact, it’s so difficult that before researching Craig Wright in November–December 2015, I never had an urgent enough reason to figure out how to get anything out of it before, and I’m not sure I’ve ever seen anyone actually use it before; Archive Team takes the attitude that it’s better to preserve the data somehow and let posterity worry about <em>using</em> it. (There is a site which claimed to be a frontend to the dump but when I tried to use it, <a href="https://github.com/hubgit/archiveteam-reader-warc-extract/issues/1" data-link-icon="github" data-link-icon-type="svg">it was broken</a> &amp; still is in December 2018.)</p>
            
            <section id="results">
              <h3><a href="#results" title="Link to section: § 'Results'">Results</a></h3>
              <p><span>Success: raw HTML.</span> My <code>dd</code> extraction was successful, and the resulting HTML/​RSS could then be browsed with a command like <code>cat *.warc | fold --spaces -width=200 | less</code>. They can probably also be converted to a local form and browsed, although they won’t include any of the site assets like images or CSS/​JS, since the original RSS feed assumes you can load any references from the original website and didn’t do any kind of <a href="https://en.wikipedia.org/wiki/Data_URI_scheme" data-link-icon="wikipedia" data-link-icon-type="svg">data-URI</a> or mirroring (not, after all, having been intended for archive purposes in the first place…)</p>
            </section>
          </section>
        </section>
        <section role="doc-endnotes" id="footnotes">
          <hr>
          <ol>
            <li id="fn1" role="doc-endnote">
              <p>For example, the <code>info:</code> operator is entirely useless. The <code>link:</code> operator, in almost a decade of me trying it once in a great while, has never returned remotely as many links to my website as Google Webmaster Tools returns for inbound links, and seems to have been disabled entirely at some point.<a href="#fnref1" role="doc-backlink">↩︎</a></p>
            </li>
            <li id="fn2" role="doc-endnote">
              <p>WP is increasingly out of date &amp; unrepresentative due to increasingly narrow policies about sourcing &amp; preprints, part of its overall <a href="https://gwern.net/inclusionism" id="gwern-inclusionism" title="'In Defense of Inclusionism', Branwen 2009">deletionist decay</a>⁠, so it’s not a good place to look for references. It is a good place to look for key terminology, though.<a href="#fnref2" role="doc-backlink">↩︎</a></p>
            </li>
            <li id="fn3" role="doc-endnote">
              <p>When I was a kid, I knew I could just ask my reference librarian to request any book I wanted by providing the unique ID, the <a href="https://en.wikipedia.org/wiki/ISBN" data-link-icon="wikipedia" data-link-icon-type="svg">ISBN</a>⁠, and there was a physical copy of the book inside the Library of Congress; made sense. I never understood how I was supposed to get these “paper” things my popular science books or newspaper articles would sometimes cite—where <em>was</em> a paper, exactly? If it was published in <em>The Journal of Papers</em>, where did I get this journal? My library only had a few score magazine subscriptions, certainly not all of these <em>Science</em> and <em>Nature</em> and beyond. The bitter answer turns out to be: ‘nowhere’. There is no unique identifier (the majority of papers lack any DOI still), and there is no central repository nor anyone in charge—only a chaotic patchwork of individual libraries and defunct websites. Thus, books tend to be easy to get, but a paper can be a multi-decade odyssey taking one to the depths of the Internet Archive or purchasing from sketchy Chinese websites who hire pirates to infiltrate private databases.<a href="#fnref3" role="doc-backlink">↩︎</a></p>
            </li>
            <li id="fn4" role="doc-endnote">
              <p>Most search engines will treat any space or separation as an implicit <code>AND</code>, but I find it helpful to be explicit about it to make sure I’m searching what I think I’m searching.<a href="#fnref4" role="doc-backlink">↩︎</a></p>
            </li>
            <li id="fn5" role="doc-endnote">
              <p>This probably explains part of why no one cites that paper, and those who cite it clearly have not actually read it, even though it invented racial admixture analysis, which, since reinvented by others, has become a major method in medical genetics.<a href="#fnref5" role="doc-backlink">↩︎</a></p>
            </li>
            <li id="fn6" role="doc-endnote">
              <p>University ILL privileges are one of the most underrated fringe benefits of being a student, if you do any kind of research or hobbyist reading—you can request almost anything you can find in <a href="https://en.wikipedia.org/wiki/WorldCat" data-link-icon="wikipedia" data-link-icon-type="svg">WorldCat</a>⁠, whether it’s an ultra-obscure book or a master’s thesis from 1950! Why <em>wouldn’t</em> you make regular use of it‽ Of things I miss from being a student, ILL is near the top.<a href="#fnref6" role="doc-backlink">↩︎</a></p>
            </li>
            <li id="fn7" role="doc-endnote">
              <p>The complaint and indictment are not necessarily the same thing. An indictment frequently will leave out many details and confine itself to listing what the defendant is accused of. Complaints tend to be much richer in detail. However, sometimes there will be only one and not the other, perhaps because the more detailed complaint has been sealed (possibly precisely because it is more detailed).<a href="#fnref7" role="doc-backlink">↩︎</a></p>
            </li>
            <li id="fn8" role="doc-endnote">
              <p>Trial testimony can run to hundreds of pages and blow through your remaining PACER budget, so one must be careful. In particular, testimony operates under an interesting &amp; <a href="https://slate.com/news-and-politics/2017/03/outrageous-trial-transcript-fees-are-bad-for-defendants-journalists-and-democracy.html" id="eisenberg-2017" data-link-icon="S" data-link-icon-type="text,sans" title="Public Record, Astronomical Price: Court reporters charge outrageous fees to reproduce trial transcripts. That's bad for defendants, journalists, and democracy.">controversial</a> <a href="https://en.wikipedia.org/wiki/Price_discrimination" data-link-icon="wikipedia" data-link-icon-type="svg">price discrimination</a> system related to how <a href="https://en.wikipedia.org/wiki/Court_reporter" data-link-icon="wikipedia" data-link-icon-type="svg">court stenographers</a> report—who are not necessarily paid employees but may be contractors or freelancers—intended to ensure covering transcription costs: the transcript initially may cost hundreds of dollars, intended to extract full value from those who need the trial transcript immediately, such as lawyers or journalists, but then a while later, PACER drops the price to something more reasonable. That is, the first “original” fee costs a fortune, but then “copy” fees are cheaper. So for <a href="https://www.uscourts.gov/services-forms/federal-court-reporting-program">the US federal court system</a>⁠, the “original”, when ordered within hours of the testimony, will cost &lt;$7.25/​page but then the second person ordering the same transcript pays only &lt;$1.20/​page &amp; everyone subsequently &lt;$0.90/​page, and as further time passes, that drops to &lt;$0.60 (and I believe after a few months, PACER will then charge only the standard $0.10). So, when it comes to trial transcript on PACER, patience pays off.<a href="#fnref8" role="doc-backlink">↩︎</a></p>
            </li>
            <li id="fn9" role="doc-endnote">
              <p>I’ve heard that LexisNexis terminals are sometimes available for public use in places like federal libraries or courthouses, but I have never tried this myself.<a href="#fnref9" role="doc-backlink">↩︎</a></p>
            </li>
            <li id="fn10" role="doc-endnote">
              <p>Curiously, in historical textual criticism of copied manuscripts, it’s the opposite: <a href="https://en.wikipedia.org/wiki/Lectio_brevior" data-link-icon="wikipedia" data-link-icon-type="svg">shorter = truer</a>⁠. But with memories or paraphrases, longer = truer, because those tend to elide details and mutate into catchier versions when the transmitter is not ostensibly exactly copying a text.<a href="#fnref10" role="doc-backlink">↩︎</a></p>
            </li>
            <li id="fn11" role="doc-endnote">
              <p>The quick summary of DOIs is that they are “ISBNs but for research papers”; they are those odd slash-separated alphanumeric strings you see around, typically of a form like <code>10.000/abc.1234</code>. (Unlike ISBNs, the DOI standard is <em>very</em> loose, with about the only hard requirement being that there must be one <code>/</code> character in it, so almost any string is a DOI, even hateful ones like this genuine DOI: <code>10.1890/0012-9658(2001)082[1655:SVITDB]2.0.CO;2</code>.) Many papers have no DOI, or the DOI was assigned retroactively, but if they have a DOI, it can be the most reliable way to query any database for them.<a href="#fnref11" role="doc-backlink">↩︎</a></p>
            </li>
            <li id="fn12" role="doc-endnote">
              <p>I advise prepending, like <code>https://sci-hub.st/https://journal.com</code> instead of appending, like <code>https://journal.com.sci-hub.st/</code> because the former is slightly easier to type but more importantly, Sci-Hub does not have SSL certificates set up properly (I assume they’re missing a wildcard) and so appending the Sci-Hub domain will fail to work in many web browsers due to HTTPS errors! However, if prepended, it’ll always work correctly.<a href="#fnref12" role="doc-backlink">↩︎</a></p>
            </li>
            <li id="fn13" role="doc-endnote">
              <p>Academic publishers like to use the dark pattern of putting a little icon, labeled “full access” or “access” etc, where an Open Access indicator would go, knowing that if you are not intimately familiar with that publisher’s site design &amp; examining it carefully, you’ll be fooled. Another dark pattern is the unannounced temporary paper: in particular, the <a href="https://en.wikipedia.org/wiki/American_Psychological_Association" data-link-icon="wikipedia" data-link-icon-type="svg">APA</a>⁠, <a href="https://en.wikipedia.org/wiki/National_Bureau_of_Economic_Research" data-link-icon="wikipedia" data-link-icon-type="svg">NBER</a>⁠, &amp; <em>Cell</em> are fond of unpaywalling PDFs to exploit media coverage, and then unpredictably, silently, revoking access later and breaking links.<a href="#fnref13" role="doc-backlink">↩︎</a></p>
            </li>
            <li id="fn14" role="doc-endnote">
              <p>To further illustrate this IA feature: if one was looking for Alex St.&nbsp;John’s entertaining memoir <a href="https://web.archive.org/web/20130227012620/http://www.alexstjohn.com/WP/2013/02/16/judgment-day-continued/" data-link-icon="internetarchive" data-link-icon-type="svg">“Judgment Day Continued…”</a>⁠, a 2013 account of organizing the wild <a href="https://doomwiki.org/wiki/Judgment_Day">1996 <em>Doom</em> tournament</a> thrown by Microsoft, but one didn’t have the URL handy, one could search the entire domain by going to <code>https://web.archive.org/web/*/http://www.alexstjohn.com/*</code> and using the filter with “judgment”, or if one at least remembered it was in 2013, one could narrow it down further to <code>https://web.archive.org/web/*/http://www.alexstjohn.com/WP/2013/*</code> and then filter or search by hand.<a href="#fnref14" role="doc-backlink">↩︎</a></p>
            </li>
            <li id="fn15" role="doc-endnote">
              <p>If any Blogspot employee is reading this, <em>for god’s sake stop this insanity</em>!<a href="#fnref15" role="doc-backlink">↩︎</a></p>
            </li>
            <li id="fn16" role="doc-endnote">
              <p>Uploading is not as hard as it may seem. <a href="https://library.bz/main/upload/" data-link-icon="raven" data-link-icon-type="svg">There is a web interface</a> (user/​password: “genesis”/​“upload”). Uploading large files can fail, so I usually use the FTP server: <code>curl -T "$FILE" ftp://anonymous@ftp.libgen.is/upload/</code>. <a href="#fnref16" role="doc-backlink">↩︎</a></p>
            </li>
            <li id="fn17" role="doc-endnote">
              <p>Although flatbed scanning is sometimes destructive too—I’ve cracked the spine of books while pressing them flat into a flatbed scanner.<a href="#fnref17" role="doc-backlink">↩︎</a></p>
            </li>
            <li id="fn18" role="doc-endnote">
              <p>My workaround is to export from gscan2pdf as DjVu, which avoids the bug, then convert the DjVu files with <code>ddjvu -format=pdf</code>; this strips any OCR, so I add OCR with <a href="https://github.com/ocrmypdf/OCRmyPDF" data-link-icon="github" data-link-icon-type="svg"><code>ocrmypdf</code></a> and metadata with <code>exiftool</code>.<a href="#fnref18" role="doc-backlink">↩︎</a></p>
            </li>
            <li id="fn19" role="doc-endnote">
              <p>One exception is Google Docs: one can append <code>/mobilebasic</code> to (as of 2023-01-04) get a simplified HTML view which can be archived. For example, <a href="https://web.archive.org/web/20230104213430/https://docs.google.com/document/d/1oIlLt1uqutTP8725wezfZ2mjc-IPfOFCdc6hlRIb-KM/mobilebasic" data-link-icon="alphabet" data-link-icon-type="svg" title="BerSevenTimes, 2022-11-21">“A Comprehensive Guide to Dakimakuras as a Hobby”</a> is available only as a Google Docs page but the URL <code>https://docs.google.com/document/d/1oIlLt1uqutTP8725wezfZ2mjc-IPfOFCdc6hlRIb-KM/mobilebasic</code> will work with the Internet Archive.<a href="#fnref19" role="doc-backlink">↩︎</a></p>
            </li>
            <li id="fn20" role="doc-endnote">
              <p><a href="http://www.catb.org/jargon/html/koans.html" data-link-icon="ESR" data-link-icon-type="text,tri,sans" title="Some AI Koans">“Tom Knight and the Lisp Machine”</a> (from the <a href="https://en.wikipedia.org/wiki/Jargon_File" data-link-icon="wikipedia" data-link-icon-type="svg">Jargon File</a>):</p>
              <blockquote>
                <p>A novice was trying to fix a broken <a href="https://en.wikipedia.org/wiki/Lisp_machine" data-link-icon="wikipedia" data-link-icon-type="svg">Lisp machine</a> by turning the power off and on.</p>
                <p><a href="https://en.wikipedia.org/wiki/Tom_Knight_(scientist)" data-link-icon="wikipedia" data-link-icon-type="svg">Knight</a>⁠, seeing what the student was doing, spoke sternly: “You cannot fix a machine by just power-cycling it with no understanding of what is going wrong.”</p>
                <p>Knight turned the machine off and on.</p>
              </blockquote><a href="#fnref20" role="doc-backlink">↩︎</a>
            </li>
            <li id="fn21" role="doc-endnote">
              <p>ERIC is one of the good websites for fulltext &amp; scans. It’s always a harbor in the storms of the Internet, with irreplaceable scans, especially of older gray literature like pre-WWW government publications or preprints.<a href="#fnref21" role="doc-backlink">↩︎</a></p>
            </li>
          </ol>
        </section>
        <section id="backlinks-section">
          <h2><a href="#backlinks-section" title="Link to section: § 'Further Reading'">Further Reading</a></h2><a id="backlinks" href="https://gwern.net/metadata/annotation/backlink/%252Fsearch.html" title="Reverse citations/backlinks for this page (the list of other pages which link to this page).">[Backlinks]</a>
        </section>
        <section id="link-bibliography-section">
          <h2><a href="#link-bibliography-section" title="Link to section: § 'Link Bibliography'">Link Bibliography</a></h2><a id="link-bibliography" href="https://gwern.net/metadata/annotation/link-bibliography/%252Fsearch.html" title="Bibliography of links cited in this page (forward citations). Lazily-transcluded version at footer of page for easier scrolling.">[Link bibliography]</a>
        </section>
        <section id="similars-section">
          <h2><a href="#similars-section" title="Link to section: § 'Similar Links'">Similar Links</a></h2><a id="similars" href="https://gwern.net/metadata/annotation/similar/%252Fsearch.html" title="Similar links for this link (by text embedding). Lazily-transcluded version at footer of page for easier scrolling.">[Similars]</a>
        </section>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FBI improperly used 702 surveillance powers on US senator (222 pts)]]></title>
            <link>https://thehill.com/homenews/administration/4110850-fbi-improperly-used-702-surveillance-powers-on-us-senator/</link>
            <guid>36822654</guid>
            <pubDate>Sat, 22 Jul 2023 02:39:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thehill.com/homenews/administration/4110850-fbi-improperly-used-702-surveillance-powers-on-us-senator/">https://thehill.com/homenews/administration/4110850-fbi-improperly-used-702-surveillance-powers-on-us-senator/</a>, See on <a href="https://news.ycombinator.com/item?id=36822654">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
	
<p>The FBI improperly used surveillance powers to conduct searches for information on a U.S. senator, a state lawmaker and a state judge, according to court records released Friday as part of a public records request.&nbsp;</p>



<p>The FBI’s improper use of Section 702 of the Foreign Intelligence Surveillance Act was documented in an opinion from the Foreign Intelligence Surveillance Court (FISC) and is sure to pose challenges for an intelligence community lobbying for the reauthorization for what it sees as one of its most vital tools.</p>





<p>The tool – which allowed for warrantless spying on foreigners located abroad – has long been criticized as a backdoor tool for gaining information on Americans who may be communicating with those being surveilled.</p>



<p>And critics complain the information gathered by the agency through 702 is too easily tapped for investigations with no foreign nexus.</p>



<p>The surveillance court outlined three examples of instances where FBI personnel conducted searches of “sensitive query terms,” like those of U.S. public officials or candidates, without first seeking approval from the FBI’s deputy director.</p>



<p>“In June 2022, an analyst conducted four queries of Section 702 information using the last names of a U.S. Senator and a state senator, without further limitation,” the opinion states.&nbsp;</p>



<p>While the two were believed to be targets of “a specific foreign intelligence service,” the National Security Division at the Department of Justice determined the FBI did not meet the needed standard for running such a query.&nbsp;</p>



<p>And in October of that year, “a Staff Operations Specialist ran a query using the Social Security number of a state judge who “had complained to [the] FBI about alleged civil right violations perpetrated by a municipal chief of police.”</p>





<p>The opinion does not make clear the identity of those searched.</p>



<p>The American Civil Liberties Union (ACLU), whose efforts prompted the release of the court opinion, highlighted other alarming patterns.</p>



<p>“These disturbing new revelations show how Section 702 surveillance, a spy program the government claims is focused on foreign adversaries, is routinely used against Americans, immigrants, and people who are not accused of any wrongdoing,” Patrick Toomey, deputy director of the ACLU’s National Security Project, said in a statement.</p>





<p>“The FBI continues to break the rules put in place to protect Americans, running illegal searches on public officials including a U.S. senator, and it’s long past time for Congress to step in. As Congress debates reauthorizing Section 702, these opinions make clear why fundamental reforms are urgently needed.”</p>



<p>The FBI and Justice Department in recent weeks have noted the roll out of some FISA reforms – pointing to a&nbsp;<a href="https://thehill.com/policy/national-security/3978746-fisa-702-searches-foreign-nationals-rise-citizen-queries-drop/" target="_blank" rel="noreferrer noopener">drop in overall queries</a>&nbsp;that involved U.S. citizens.</p>



<p>The opinion, originally filed in April, does comment on improvements from the bureau.</p>





<p>“Despite the reported errors, there is reason to believe that the FBI has been doing a better job in applying the querying standard,” Judge Rudolph Contreras writes in the opinion.</p>



<p>“In some cases, F.B.I. personnel apparently misapplied the querying standard to a group of similarly situated persons, but those violations do not approach the scale of a number of prior ones.”</p>



<p>The FBI stressed that detail in its response to the opinion’s release.</p>





<p>“The 2023 FISC Opinion confirms the significant improvement in the FBI’s Section 702 querying compliance since the implementation of our substantial reforms,” FBI Director Christopher Wray said in a statement.&nbsp;</p>



<p>“Section 702 is critical in our fight against foreign adversaries. We take seriously our role in protecting national security and we take just as seriously our responsibility to be good stewards of our Section 702 authorities. Compliance is an ongoing endeavor, and we recently announced new additional accountability measures. We will continue to focus on using our Section 702 authorities to protect American lives and keeping our Homeland safe, while safeguarding civil rights and liberties.”</p>



<p>It’s not the first time a lawmaker has been improperly searched via FISA 702, with Rep. Darin LaHood (R-Ill.) saying in March that his name was searched using the tool.</p>





<p>Section 702 is set to expire at the end of the year, and lawmakers on both sides of the aisle have said they will refuse to back its reauthorization without significant reforms.</p>



<p>The FBI on Friday sent a letter to House and Senate leaders noting that several different reviews found agents have complied with FISA guidelines at least 98 percent of the time.</p>



<p>But in a call with reporters Friday, a senior FBI official said the agency is working on building trust with lawmakers who may feel personally impacted by the issue.</p>





<p>“We are communicating as much as we can to build that level of confidence so that they understand how we are using the tool and how we are holding people accountable for when they are not using the tool correctly. But also to make sure they understand when we do and do not do such things as query members of Congress,” the official said in response to a question from The Hill.</p>



<p>“There was an unacceptably high level of non compliance and various non compliance queering behavior that was going on,” the official added.&nbsp;</p>



<p>“We’ve been very open about [how] we accepted the fact that that was unacceptable. That’s not what we expect from ourselves as an organization.”&nbsp;</p>







<p>Sen. Ron Wyden (D-Ore.), however, said lawmakers are not assured that intelligence agencies are being fully forthcoming about how they use FISA.</p>



<p>“For years, as government officials have provided misleadingly narrow testimony about who is targeted under Section 702, I have pushed to get the government to come clean.&nbsp; The revelation that 702 is used against ‘foreign governments and related entities’ directly impacts Americans’ privacy, as American journalists, businesspeople, students and others all have legitimate reason to communicate with foreign governments,” Wyden said in a statement.</p>



<p>“The fact they can be swept up in 702 collection further highlights the need for reforms to protect their privacy.”</p>

</div><p>Copyright 2023 Nexstar Media Inc. All rights reserved. This material may not be published, broadcast, rewritten, or redistributed.</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Employees Bid on Anchor Brewery (152 pts)]]></title>
            <link>https://vinepair.com/booze-news/anchor-employees-brewery-takeover-bid/</link>
            <guid>36821861</guid>
            <pubDate>Sat, 22 Jul 2023 00:23:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://vinepair.com/booze-news/anchor-employees-brewery-takeover-bid/">https://vinepair.com/booze-news/anchor-employees-brewery-takeover-bid/</a>, See on <a href="https://news.ycombinator.com/item?id=36821861">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		
		<p><em>This is a developing story, check back for updates.</em></p>
<p>At a meeting last Wednesday at Anchor Brewing Co., executives told brewery employees that the historic San Francisco firm would be shut down after over a century and a half in business. One week later, employees have something to tell the executives: if you’ll sell us Anchor, we’ll figure out a way to buy it.</p>
<p>In a brief letter sent Wednesday evening and shared with VinePair, the business agent for Anchor Brewing Union advised Sapporo USA president Mike Minami “that workers of Anchor Brewing have met, discussed, and decided to launch an effort to purchase the brewery and run it as a worker co-op.”</p>
<p>“We are not asking for a handout or charity,” wrote Pedro de Sá, a business agent at International Longshore and Warehouse Union Local 6, which represents roughly 40 workers at the brewery. “All we want is a fair shot at being able to continue to do our jobs, make the beer we love, and keep this historic institution open. We do not want the brewery and brand we love to be sold off before we even had a chance.”</p>
<p>de Sá, speaking on behalf of union workers who voted earlier in the day to take this step, asked Minami to respond by the end of the day on Friday, July 21 indicating whether Sapporo USA was open to working “cooperatively and transparently through this process” with the union, specifically with regards to “creat[ing] the framework and rais[ing] the funds necessary for this purchase.”</p>
<p>Patrick Machel, a production worker at the brewery and a shop steward for the Anchor Brewing Union, says that the vast majority of the union’s rank-and-file workers, as well as an unspecified number of managers, support the longshot effort. “Most of us that work here were born and raised here. We work here because we love it, we grew up with Steam Beer,” he tells VinePair. Now, they’ll try to save Anchor from the scrap heap.</p>
<p>VinePair first <a href="https://vinepair.com/booze-news/anchor-brewing-company-sale/">reported</a> that Sapporo USA was on the verge of selling or shuttering Anchor on the evening of July 11. Less than 12 hours after our initial report, Sam Singer, a representative for Anchor and Sapporo USA, issued a press release announcing the brewery would “cease operations and liquidate the business following a combination of challenging economic factors and declining sales.” (The release did not mention Sapporo USA, but current and former workers were quick to tell <a href="https://vinepair.com/articles/sapporo-usa-anchor-brewing-liquidation-analysis/">VinePair’s Hop Take column</a> that the parent company mismanaged the brewery into dysfunction.)</p>
<p>As word spread of Anchor’s imminent closure last week, San Franciscans <a href="https://www.sfgate.com/food/article/anchor-brewing-final-beers-flying-off-shelves-sf-18199789.php">flocked</a> to the unmistakable Art Deco plant on Potrero Hill to pay their respects to the brewery that has kept the City by The Bay stocked with steam beer since 1871. Lines at the neighboring Anchor Public Taps stretched around the block as people clamored to buy whatever beer was left in the tanks.</p>
<p>What would happen to Anchor? In a year of searching, the company’s release claims, no buyer had emerged to acquire it whole, as a going concern. (The release does not state the price Sapporo USA was asking for the firm; it acquired Anchor six years ago in a provisional $85 million deal.) Last week, Narragansett Beer <a href="https://vinepair.com/booze-news/narragansett-beer-petition-anchor-brewing/">circulated</a> a petition to drum up support for rescuing the brewery, and several private-equity investors, perhaps impressed by the outpouring of local love for the august old brand, expressed interest to this reporter about acquiring it.</p>
<p>This past weekend, a handful of San Francisco entrepreneur types <a href="https://www.sfchronicle.com/food/wine/article/save-anchor-steam-18199818.php">described</a> to the hometown paper their plans for resurrecting Anchor; the ideas included a website to tease future crowdfunding opportunities, and a reality show about bringing the idiosyncratic brewery back to life working-titled “How hard could it be.” But the plan outlined last week in the release still stands: to turn Anchor over to an assignee for the benefit of creditors (A.B.C.), a third-party manager tasked with the orderly wind-down and sale of the business and its assets to whoever would buy them, and for whatever purpose.</p>
<p>Workers want to preempt Anchor’s real estate, equipment, and intellectual property being sold off piecemeal to the highest bidders by acquiring it from Sapporo USA and running it as a co-op, says Machel.</p>
<p>“We couldn’t go down without some way of fighting for ourselves and the community we love.”</p>
<p><em><strong>This story is a part of <a href="https://vinepair.com/business-of-drinks/">VP Pro</a>, our free content platform and newsletter for the drinks industry, covering wine, beer, and liquor — and beyond. <a href="https://vinepair.com/vp-pro-join/">Sign up for VP Pro now!</a></strong></em></p>		
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Hollywood is on strike because CEOs fell for Silicon Valley’s magical thinking (144 pts)]]></title>
            <link>https://www.latimes.com/business/technology/story/2023-07-21/column-hollywood-sag-aftra-strike-strike-silicon-valleys-magical-thinking</link>
            <guid>36821347</guid>
            <pubDate>Fri, 21 Jul 2023 23:19:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.latimes.com/business/technology/story/2023-07-21/column-hollywood-sag-aftra-strike-strike-silicon-valleys-magical-thinking">https://www.latimes.com/business/technology/story/2023-07-21/column-hollywood-sag-aftra-strike-strike-silicon-valleys-magical-thinking</a>, See on <a href="https://news.ycombinator.com/item?id=36821347">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-element="story-body" data-subscriber-content=""> <p>In one respect, the <a href="https://www.latimes.com/entertainment-arts/business/story/2023-07-16/sag-aftra-strike-actors-writers-strike-hollywood-production-film-tv-disruption-fall-season"><u>actors and writers of Hollywood</u></a> uniting on the picket lines in <a href="https://www.latimes.com/entertainment-arts/business/story/2023-07-14/actors-strike-sag-aftra-joins-writers-guild-picket-lines"><u>a historic, industry-shaking strike</u></a> is a tale as old as time: one of workers fighting bosses for better pay. Yet the reason this battle is shaping up to be so uniquely intractable and momentous — as you might have gathered from all the headlines about  artificial intelligence and streaming economics — is very much of our moment.</p><p>But it’s not, ultimately, technology that’s at the root of the problem. It’s that the studio executives both new and old have embraced the powerful — and ultimately disastrous — magical thinking pumped out by Silicon Valley for the last  10 years.</p><p>Studio heads are touting the disruptive properties of digital streaming, the transformative power of AI, a brave, unpredictable new world for entertainment writ large — and how writers and actors must adapt to this new future. But just as it did when it was issuing from the tech sector during the 2010s, this talk too often amounts to a smokescreen that lets executives and investors line their pockets and risks leaving workers holding the bag.</p><p>“These companies blew up a successful business model that the public enjoyed,  that was immensely profitable,  and they replaced it with a mishmash that we have now,” Adam Conover, the star of “Adam Ruins Everything”<i> </i>and a  negotiating committee member of the Writers Guild of America, tells me. “And now, they’re refusing to update the contract to reflect those changes.”</p><p>We’ve heard a lot about the ways that studios want to reserve the right to use AI — to create endlessly usable digital replicas of actors, to generate scripts that writers <a href="https://www.latimes.com/business/technology/story/2023-05-11/column-the-writers-strike-is-only-the-beginning-a-rebellion-against-ai-is-underway"><u>will be paid lower rates to fix up</u></a>. We’ve also heard about the new economic picture ushered in by streaming, about an industry in the throes of change, and the necessity of belt-tightening as a result. </p><p>We’ve heard Disney Chief Executive Bob Iger saying the  demand by the Screen Actors Guild for fair payment in the new digital landscape “isn’t realistic,” and heard how Netflix saw declining user sign-ups and stock prices last year. Yet  Iger reportedly makes <a href="https://www.rollingstone.com/tv-movies/tv-movie-features/disney-staffers-angry-ceo-bob-iger-actors-strike-writers-strike-1234789713/" target="_blank"><u>$27 million a year</u></a>, while Netflix <a href="https://www.wsj.com/articles/netflix-nflx-q2-earnings-report-2023-92a620c8" target="_blank"><u>just raked in $1.5 billion in net profit in the last quarter</u></a>.</p><p>So what’s really going on? And how did we get here?</p><p>First, we need to understand why the 2010s may well come to be remembered as the great decade of magical thinking for Silicon Valley. Drunk on a truly transformational first decade of the 21st century — one that saw Google, Amazon, the iPhone and social media storm the world stage — flush tech investors turned their sights toward the next generation of startups, eager to see them do the same.</p><p>The formula for seeking out that next multibillion-dollar “unicorn,” in hindsight, was pretty simple: The next wave of startups had to promise that it would disrupt a stale industry with a newer, high-tech, app-driven alternative, promise the potential for vast scale and promise that it could do so fast. So we saw the rise of Uber and Lyft, each of which vowed to revolutionize transit, and we got the likes of WeWork, which set out to usher in the future of co-working, and Theranos, which would do the same for at-home blood testing.</p><p>We know how it ended. Uber and Lyft have never been sustainably profitable, WeWork collapsed dramatically when it became clear that it was merely a wildly over-leveraged real estate company, and Theranos’ futuristic medical technology was outright fraudulent. </p><p>Unlike many of the 21st century’s first-wave tech companies and products, which found both markets and roads to profitability, these were pipe dreams, propped up by a fire hose of investment cash, big-talking founders and the very real — and at the time, quite understandable! — sense that Silicon Valley was the place that determined how the future was made.</p><p>As the 2010s began, Netflix sat somewhere between the old guard and the new. It introduced online streaming in 2007, and had a real product with real demand, as well as an established business in its DVD-by-mail rental service. Yet its ambitions were hypercharged by a newfangled sense that it could disrupt the old school Hollywood industry and scale endlessly — there was no reason everyone in the world with access to a screen couldn’t subscribe.</p><p><a href="https://www.reuters.com/article/us-netflix-stock/netflix-shares-soar-after-icahn-reports-10-percent-stake-purchase-idUSBRE89U1GA20121101" target="_blank"><u>Big-name investors</u></a> sank hundreds of millions into Netflix’s new vision. As it began producing original content in 2013, it applied a distinctly next-wave Silicon Valley ethos. It would make massive upfront investments, bankrolling huge productions such as the David Fincher-helmed, Kevin Spacey-starring “House of Cards,” elbowing its way into the prestige TV pack, promising not only to compete but also to do it better: It would offer all the episodes at once, on demand, and viewers could consume them whenever and however they wanted. Cable would become obsolete. The future was cutting the cord.</p><p>As with Uber and Lyft, whose bottomless chests of venture capital allowed them to conquer new markets once dominated by stodgy old competitors — in their case, the taxi cartels and livery cab companies — price was no object.</p><p>Right out the gate, episodes for original Netflix shows such as “House of Cards” and “Orange Is the New Black”<i> </i>cost $4 million a pop. (So did episodes of shows that few remember today, such as “Hemlock Grove.”) The spending was profligate — it soon rose to rates of <a href="https://www.indiewire.com/features/general/netflix-originals-budget-15-billion-1202036683/" target="_blank"><u>$15 billion a year</u></a> on new content — but as it did for the magical valley startups, the strategy “worked.”</p><p>“What happens is Netflix becomes the Wall Street darling, and all these other companies,” like Amazon, Disney, Apple, HBO, Paramount and NBC, “race to adopt Netflix’s business model,” Conover says. </p><p>Herein lies the trouble. Amid this boom, which for a few years ushered in a gold rush for writers and talent, Netflix et al. adopted another key ingredient of Silicon Valley’s approach: secrecy. Data about shows’ performance and viewer habits were kept proprietary; we  knew only what the streamers wanted us to know. That went for customers, performers, writers and for investors. Streaming is an inscrutable black box, about which so many stories might be told.</p><p>It’s a sticking point in the negotiations — actors and writers on streaming series want a better way to calculate the value of their work, given that the residuals they earn are so much lower than for network or cable shows. The studios have resisted. “The reason nobody really wants to open the books on this is because if Wall Street got a look,” one Hollywood insider <a href="https://www.vulture.com/2023/06/streaming-industry-netflix-max-disney-hulu-apple-tv-prime-video-peacock-paramount.html" target="_blank"><u>told New York Magazine</u></a>, “they’d have a collective stroke.”</p><p>What we’re seeing now is the fantastical thinking that Netflix and its followers could continue endless expansion running up against the physics of the real world — there are now 238 million Netflix subscribers, but those numbers <a href="https://www.latimes.com/entertainment-arts/business/story/2022-04-19/lat-et-ct-netflix-loses-subscriber-first-quarter">dropped for the first time</a> last year, and the company had to claw them back by nibbling at the corners, <a href="https://www.latimes.com/entertainment-arts/business/story/2021-03-11/netflix-password-sharing-policing">cutting off password sharing</a> and launching new, cheaper tiers that run ads.</p><p>The boom times are over. Executives know it. Wall Street knows it. And the story that we’re in a revolutionary moment of technological transformation will run out of gas soon. So the bosses are using that moment to do what Silicon Valley wound up doing when its other big swings didn’t pan out: squeeze labor. </p><p>Just as Uber and Lyft, which promised drivers rich rewards and flexible fares, started reducing rates and making it harder to earn those rewards, Netflix and the streaming cohort cut in its mold are now trying to square their promises of world conquest by slashing worker pay under the fog of magical thinking.</p><p>It’s been noted, and correctly so, that entertainment industry labor disputes often erupt when there’s a change in technology — from theaters screening projected films to the cathode ray tube of the home television, say, or the rise of YouTube and other online content in the 2000s  — and that happens for a reason. Historically, executives and management use a disorienting new technology to try to justify lowering wages of their workers, and they have done so since the days of the Industrial Revolution. </p><p>“The old CEOs knew they had to work with the unions, bargain with us,” Conover says. “The new ones don’t. So part of the point of the strike is us as labor showing the tech CEOs that no, you actually do have to deal fairly with the unions.”</p><p>Conover notes that it’s jarring to see the streamers plead poverty as an excuse not to negotiate with talent in good faith, given that show budgets and profits have both gone up. </p><p>“Netflix lied to the public and Wall Street,” he says, telling them, “‘you can watch every show ever made in perpetuity, with no ads, for $15.99 a month forever.’ That’s like Movie Pass” (the much-hyped app that allowed users to see unlimited movies for a monthly fee, before quickly going bankrupt). “That’s ludicrous.” </p><p>Ludicrous if you want to pay the people who actually create those shows for you, anyway.</p><p>What Netflix and the streamers are trying to do now is seal in a new standard under which writers and actors are treated in much the way that Uber and the gig app companies treat their independent contractor drivers. </p><p>“Uber is a perfect example,” Conover says. “Its drivers need to supply their own cars, their own gas, their own insurance and so on.” The drivers are on their own, with few to no benefits or protections, and are expected to maximize profits for the company. “And Netflix is trying to do the same thing.”</p><p>Unlike Uber, Netflix really <i>is </i>quite profitable. But in order to sustain the mythical levels of growth it has promised investors, it is turning to similar tactics — cutting workers’ hours, making work more precarious and unpredictable and reducing pay. It’s a far cry from the sleek, automated futures promised by the studio executives.</p><p>As with the biggest companies of Silicon Valley’s magical thinking era, it’s often hard to parse whether the ones touting the game-changing technologies themselves even believe in these visions — do studio execs really think consumers want to watch a parade of digital replicas of their favorite actors parroting lines from an AI-generated script? Or are they simply aware that the mere threat of such a future gives them leverage and power over the workers of today?</p><p>In the end, the answer is immaterial. Silicon Valley’s invasion of Hollywood brought with it science fictional notions of growth for the industry, a penchant for secrecy and unaccountability and the expectation that it could get away with treating workers like robots or invisible code. We’re seeing what happens when those notions meet, for one of the first times, with a powerful, organized resistance.</p><p>Personally, I’m hoping this one gets a Hollywood ending — and not the ending so many Silicon Valley startups got over the last 10 years.</p> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[NativePHP: A framework for building desktop apps using PHP (136 pts)]]></title>
            <link>https://nativephp.com/docs/1/getting-started/introduction</link>
            <guid>36820555</guid>
            <pubDate>Fri, 21 Jul 2023 22:06:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nativephp.com/docs/1/getting-started/introduction">https://nativephp.com/docs/1/getting-started/introduction</a>, See on <a href="https://news.ycombinator.com/item?id=36820555">Hacker News</a></p>
<div id="readability-page-1" class="page"><p><span>⚠️</span>
                    <span>
                        NativePHP is currently an <em>alpha</em> release and is not ready for production applications
                        yet.
                    </span>
                </p><div>
                    <h2 id="hello-nativephp"><a href="#hello-nativephp"><p>#</p></a>Hello, NativePHP!</h2>
<p>NativePHP is a new framework for rapidly building rich, native desktop applications using PHP. If you're already a PHP
developer, you'll feel right at home. If you're new to PHP, we think you'll find NativePHP easy to pick up and use.
Whatever your path, we think you're going to be productive quickly.</p>
<p>NativePHP is taking the world by storm, enabling PHP developers to create true cross-platform, native apps
using the tools and technologies they already know: HTML, CSS, Javascript, and, of course, PHP.</p>
<p>And they said PHP was dead.</p>
<h2 id="what-exactly-is-nativephp"><a href="#what-exactly-is-nativephp"><p>#</p></a>What exactly is NativePHP?</h2>
<p>Strictly speaking, NativePHP is a combination of elements:</p>
<ol>
<li>A collection of easy-to-use classes - abstractions - to enable you to interact with a variety of host operating
system features.</li>
<li>A set of tools to enable building and bundling your native application using either the Electron or Tauri browser
environment.</li>
<li>A static PHP runtime that allows your app to run on any user's system with zero effort on their part.</li>
</ol>
<h2 id="what-nativephp-isnt"><a href="#what-nativephp-isnt"><p>#</p></a>What NativePHP isn't</h2>
<p>NativePHP is not an especially opinionated way to build native apps. Right now, we only support a Laravel driver, but
we're already working on making it work whatever framework you're using - and even if you're not using a framework at
all.</p>
<p>NativePHP is not a GUI framework. We don't want to tell you how to build your app. You can choose whatever UI toolset
makes you and your team feel most productive.</p>
<p>Building a React front-end? No problem. Vue? Sure. Livewire or Inertia? Doesn't matter! Plain old HTML and CSS?
You got it. Tailwind? Bootstrap? Material UI? Whatever you want.</p>
<p>NativePHP is not some new custom fork of PHP. This is the good old PHP you know and love.</p>
<h2 id="whats-in-the-box"><a href="#whats-in-the-box"><p>#</p></a>What's in the box?</h2>
<p>NativePHP comes with a bunch of useful features out of the box, including:</p>
<ul>
<li>Window management</li>
<li>Menu management</li>
<li>File management</li>
<li>Database support (SQLite)</li>
<li>Native notifications</li>
</ul>
<p>All of this and more is explored in the rest of these docs.</p>
<h2 id="what-can-i-build-with-nativephp"><a href="#what-can-i-build-with-nativephp"><p>#</p></a>What can I build with NativePHP?</h2>
<p>Honestly, anything you want. We believe NativePHP is going to empower thousands of developers to build all kinds of
applications. The only limit is your imagination.</p>
<p>You could build a menubar app that lets you manage your cron jobs, or a cool new launcher app, or a screen recorder
that puts cowboy hats on every smiley-face emoji it sees.</p>
<p>(You should totally build that last one.)</p>
<h2 id="whats-next"><a href="#whats-next"><p>#</p></a>What's next?</h2>
<p>Go read the docs! We've tried to make them as comprehensive as possible, but if you find something missing, please
feel free to <a href="https://github.com/nativephp/nativephp.com">contribute</a>.</p>
<p>This site and all the NativePHP are open source and available on <a href="https://github.com/nativephp">GitHub</a>.</p>
<p>Ready to jump in? <a href="https://nativephp.com/docs/1/getting-started/installation">Let's get started</a>.</p>
<h2 id="credits"><a href="#credits"><p>#</p></a>Credits</h2>
<p>NativePHP wouldn't be possible without the following projects and the hard work of all of their wonderful contributors:</p>
<ul>
<li>
<a href="https://php.net/">PHP</a>
</li>
<li>
<a href="https://electronjs.org/">Electron</a>
</li>
<li>
<a href="https://tauri.studio/">Tauri</a>
</li>
<li>
<a href="https://laravel.com/">Laravel</a>
</li>
<li>
<a href="https://symfony.com/">Symfony</a>
</li>
<li>
<a href="https://github.com/crazywhalecc/static-php-cli/">Static PHP CLI</a>
</li>
</ul>
<p>NativePHP is a copyright of and maintained by <a href="https://twitter.com/marcelpociot">Marcel Pociot</a> and
<a href="https://twitter.com/simonhamp">Simon Hamp</a>.</p>

                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Managing Kitchen Fruit Flies with a Little Shop of Horrors (286 pts)]]></title>
            <link>https://blog.zaccohn.com/Fruitflies-and-the-Little-Shop-of-Horrors/</link>
            <guid>36820469</guid>
            <pubDate>Fri, 21 Jul 2023 21:58:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.zaccohn.com/Fruitflies-and-the-Little-Shop-of-Horrors/">https://blog.zaccohn.com/Fruitflies-and-the-Little-Shop-of-Horrors/</a>, See on <a href="https://news.ycombinator.com/item?id=36820469">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <p><img src="https://blog.zaccohn.com/images/blog_pitcherplants.jpeg" alt=""></p>

<p>I live in Seattle on a fairly wooded property. Every summer since we’ve moved here, we end up with <em>swarms</em> of fruit flies in the kitchen. They congregate around the compost bin and the fruit bowl (where there are always lots of bananas). We aren’t slobbish - I do the dishes and wipe down the counters every night, take the compost out and wash the bin 2-3x a week. Keeping everything washed and clean helps, but the fruit flies still build up over time. And if there’s even the slightest deviation from the cleaning schedule, within 2-3 days the fruit flies have built up exponentially and there are 50-100 of them swarming around.</p>

<p>Our previous remedy, iterated on and honed over years, was to leave a few traps out. We found what worked best was a short, wide brimmed glass (or tuppaware container) with a little bit of wine, a splash of apple cider vinegar, a drop of dish soap, then hit it with a spray of hot water to get a lot of suds and bubbles. When the swarms were particularly bad, one of these traps could catch dozens overnight, but we had to refill and refresh them constantly and the mass-graves of floating fruit flies were somewhat unsightly.</p>

<p>Earlier this Spring I was reading about symbotic relationships between humans and nature, and that gave me an idea to try some carnivorous plants.</p>

<p>Venus Fly Traps are the most well known type of carnivorous plant. They have sensitive little trigger hairs in their leaves, and when a fly lands and disturbs one of the hairs, the two lobes snap shut to trap the fly. The plant digests the fly before opening back up, ready for its next meal. The downside is they can take a week or more to open back up! That’s not nearly high-volume enough to deal with my fruit fly problem.</p>

<p>Some additional research taught me about a more passive type of carnivorous plant called a “pitcher plant.” There are many varieties, but generally their leaves form tubes that are open on top. These tubes are full of liquid - a mixture of rainwater and digestive fluids. Flies are attracted to the scent, fly in, then fall into the liquid. They’re trapped there until they drown, then are slowly digested. The same pitcher can catch many, many flies, and even smaller pitcher plants can have between 6 and 12 pitchers.</p>

<p>These sounded perfect! I ran up to the local plant nursery and got three carnivorous “Pitcher plants.” I got two different varieties - which internet research suggests are a Purple Pitcher Plant (<a href="https://en.m.wikipedia.org/wiki/Sarracenia_purpurea">Sarracenia Purpurea</a>) and what I think is a <a href="https://en.wikipedia.org/wiki/Sarracenia_leucophylla">Sarracenia Leucophylla</a> (but could be a <a href="https://en.wikipedia.org/wiki/Sarracenia_flava">Sarracenia Flava</a>).</p>

<p>I named them Audrey III, Audrey IV, and Audrey V. They were about the size in the photos when I got them. They were mature enough to have 6-8 open pitchers, and were growing another 6-8 juvenile pitchers. Each plant was roughly $10 each.</p>

<p>I’ve been disappointed by Audrey III and V’s performance (they’re either the Leucophylla or Flava species), but Audrey IV (the Purple Pitcher Plant) is a <strong>beast</strong>. These days I see one fruit fly buzzing around sometimes, but never more than that. When I look in Audrey IV’s pitchers, she’s been busy - just now I counted ten or eleven fruitflies and two house flies.</p>

<p>Passive countermeasures like Audrey IV works great because it prevents them from going exponential. If you’re taking fruit flies out early and continuously, they don’t have a chance to reproduce. A female fruit fly starts mating 8 hours after it emerges from the larval state, and lays about 400 eggs, which take 12-15 hours to hatch at typical room temperature. Needless to say - you gotta keep these under control!</p>

<p><img src="https://blog.zaccohn.com/images/blog_lavender.jpeg" width="100"> I did notice for a time they were still congregating by the compost and weren’t being drawn to Audrey’s sweet scents. More internet research seemed to indicate they didn’t like don’t like the smell of lavender, so I cut some lavender flowers and put them between the compost bin’s lid and filter. That didn’t seem to be effective, so I spritzed some much higher density lavender essential oil on the compost bin filter. Later that night I watched as a fly kept going into the holes in the lid, then back out, then in, but then back out. It didn’t like the smell! Success!</p>

<p>Since then, there’s been no congregation of fruit flies around the compost. I still see one or two flying around the kitchen, but Audrey IV is keeping them under control.</p>

<p>So that’s my official two-part recommendation for managing fruit flies: get yourself an Audrey IV and spritz some lavender essential oil on your compost bin filter to keep them out.</p>

<h2 id="taking-care-of-a-pitcher-plant">Taking care of a Pitcher Plant</h2>
<p>A few notes on taking care of your new Audrey.</p>
<ol>
  <li><strong>You have to use distilled water.</strong> If you water them with sink water they’ll be dead within a day or two. These plants evolved in swampy, very nutrient-poor soils (that’s why they evolved to get their nutrients from their prey). The minerals in sink water are enough to overwhelm and poison your pitcher plants.</li>
  <li><strong>Damp, but not soaked, soil.</strong> When you water them, you want the soil to be damp but not waterlogged. Although you should look up the needs of your specific species of Audrey.</li>
  <li><strong>Filling the pitcher.</strong> For certain types of pitcher plants, you’ll want to fill up their pitchers with (distilled) water. Some types of pitcher plants have an opening at the top without any sort of leaf covering it (like Audrey IV). These types of plants are designed to supplement their digestive juices with rain water they catch. Since it presumably doesn’t rain inside your house like it does outside, you’ll want to use an eye dropper or a straw to drip some distilled water into the pitchers. Generally try to fill them 3/4 of the way. If your pitcher plant has a “hood” - or part of the leaf that’s covering the opening - that’s designed to shield it from the rain and you may not need to fill it up. Look up your particular species for specific instructions.</li>
  <li><strong>Hand-feeding your pitcher plant.</strong> Outside of fruit fly season, you’ll want to feed your pitcher plant a snack every so often. I use dehydrated mealworms or bloodworms from the pet food store (typically used to feed reptiles, etc). Use tweezers to grab one and drop it into a pitcher. Keep an eye on how fast they digest to figure out the optimal feeding schedule for your plant - but it’s probably going to be close to 3-4 per plant once every 2-3 weeks.</li>
</ol>

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Book Review: The Laws of Trading (112 pts)]]></title>
            <link>https://astralcodexten.substack.com/p/your-book-review-the-laws-of-trading</link>
            <guid>36820105</guid>
            <pubDate>Fri, 21 Jul 2023 21:32:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://astralcodexten.substack.com/p/your-book-review-the-laws-of-trading">https://astralcodexten.substack.com/p/your-book-review-the-laws-of-trading</a>, See on <a href="https://news.ycombinator.com/item?id=36820105">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><span>[</span><em>This is one of the finalists in the 2023 book review contest, written by an ACX reader who will remain anonymous until after voting is done. I’ll be posting about one of these a week for several months. When you’ve read them all, I’ll ask you to vote for a favorite, so remember which ones you liked</em><span>]</span></p><p><span>A book about trading isn’t ever </span><strong>actually</strong><span> about trading</span></p><p><span>. It is either:</span></p><ul><li><p><span>A former trader sharing stories from their glory days, e.g. </span><em>Liar’s Poker</em><span>, the exposé that morphed into a how-to guide, or</span></p></li><li><p><span>Tales of Icarus flying too close to the sun, where readers revel in schadenfreude, e.g., </span><em>When Genius Failed</em><span>.</span></p></li></ul><p><span>With </span><em><a href="https://www.amazon.com/Laws-Trading-Traders-Decision-Making-Everyone/dp/1119574218/ref=sr_1_1?crid=1CFYGH6Q0TUPK&amp;keywords=the+laws+of+trading&amp;qid=1689973717&amp;sprefix=the+laws+of+trading%2Caps%2C144&amp;sr=8-1" rel="">The Laws of Trading</a></em><span>, Agustin Lebron has written something different: part love letter to trading, part philosophical treatise on epistemology and modeling the world around us, and part guide to applied decision-making. Lebron’s Laws are Laws of the Jungle, not Laws of Nature. He views financial markets as the most competitive Darwinian environment on Earth, where participants must adapt or die.</span></p><p><span>According to Lebron, the book is for people working in finance and trading, as well as anyone in the business of making rational decisions.</span><em> </em><span>This explicitly rationalist bent is similar to Julia Galef’s </span><em>The Scout Mindset </em><span>or Annie Duke’s </span><em>Thinking in Bets. </em><span>Where </span><em>The Laws of Trading </em><span>sets itself apart is with the best description of financial market dynamics that I’ve ever seen while diving deep into philosophical concepts.</span></p><p><span>Why trust Lebron? He is an engineer, worked as a quantitative trader and researcher at Jane Street, and has a deep understanding of trading. He has what Taleb would describe as </span><strong>skin in the game</strong><em>.</em><span> You and I may read Astral Codex Ten in our spare time, post on LessWrong, and navel gaze about our epistemic certainty, but at the end of the day most of us are pursuing rationality for fun, as a hobby. Traders like Lebron pursue rationality as a profession: Their livelihood depends on having a better model of the world than their competition. There are lessons to learn from them that apply to our daily lives.</span></p><p><em>Know why you are doing a trade before you trade.</em><span>&nbsp;</span></p><blockquote><p>“What is trading about? Fundamentally, it’s about the relationship between you and the rest of the world.”</p></blockquote><p>Right now, you’re making a trade.&nbsp;</p><p>You’re trading your time to read this book review. You have a cost: you could be spending time with your loved ones, exercising, working, sleeping. You might be hoping to learn something, to take away lessons that you can apply to your life, or simply to entertain yourself. Here, off the bat, are two key insights:</p><ol><li><p>We are all making trades, all of the time.</p></li><li><p>We need a framework for thinking about these trades.</p></li></ol><p>Lebron’s first law states that we must know ourselves and our motivations for trading before we trade. We tell ourselves many stories, but someone with intellectual honesty – the person with the most alignment between their motivations and actions – will take money from the person who didn’t go through the work to understand their own motivations.&nbsp;</p><p><span>There is a reason that Citadel and other hedge funds </span><a href="https://www.investopedia.com/terms/p/paymentoforderflow.asp" rel="">pay millions of dollars to trade with retail</a><span>. They know why they are trading: to maximize profit. And the dilettante who “trades for fun” will be eaten alive by a firm with a much better model of a) the world and b) the dilettante themself.</span></p><p>Why did I write this book review? To test my intellectual mettle. I could easily have posted this book review elsewhere, but no, I wanted to see how I stack up against other ACX Book Review contest participants.&nbsp;</p><p>Similarly, this is often the reason people get into trading. One motivation that Lebron explicitly calls out is intellectual validation. You can toil in obscurity for years as an academic. But in trading, there is a quick feedback loop. If your P&amp;L showed $10M last year and the guy sitting next to you showed $8M, you have demonstrated who is “cleverer” and established a clear hierarchy.&nbsp;</p><p><span>What lessons here transfer to our daily lives? Like Paul Graham, Lebron encourages us to </span><a href="http://www.paulgraham.com/identity.html" rel="">keep our identities small</a><span>. He gives the standard decision-making advice to write down your framework and reasoning for why you made a decision at a specific point in time, in order to avoid biases after the fact.&nbsp;</span></p><p>This section of the book contained good general advice, but nothing that will be particularly new for the median ACX reader.&nbsp;&nbsp;</p><p><em>You’re never happy with the amount you traded.</em></p><p><span>Now we start to get into the good stuff. Financial markets are an information aggregation mechanism, relying on multiple parties’ beliefs and recursive Bayesian updates of an individual actor’s beliefs based on the beliefs of others</span></p><p><span>.</span></p><p><span>Market mechanics demonstrate Bayesian beliefs in action. The following quote is quite long, so skip over it if you don’t want to dive deep into the psychology of making a market. I retained it in full because this is quite literally the best description I’ve ever seen of the Bayesian dance between two </span><a href="https://www.investopedia.com/terms/m/marketmaker.asp" rel="">market makers</a><span>:</span></p><blockquote><p><em>“You are a market maker in South African mining companies. Through years of effort and continual improvement, you have built a trading model for the company Veldt Resources. You walk into work one day, ready to set up your trading for the day. It's a stock that doesn't trade much, and usually there are only two market makers: you and another (we'll call her Jo). She's sharp, and she competes well to trade against customer orders that come in.</em></p><p><em>Your model has Veldt valued at 54.35 ZAR (South African rand). You're going to start quoting the stock, so you're about to turn on your machine making a market 54.25 - 54.45 (1000x)</em></p><em>. Before you turn on, you check the current market and notice that Jo has already turned on and she's making her market 53.50 - 54.00 (2000x). If you were to turn on your machine, your market would cross her market, and you would buy 1000 shares from her for 54.00.</em><p><em>You now need to make a decision. Whose model do you believe more, yours or Jo's? If you believe yours, you should turn on your machine, trade at 54.00, and expect to make money. If you believe Jo's model, you should adjust your own model parameters to match her market and turn on, making a similar market to hers.</em></p><p><em>What to do? As with many dichotomies, this is a false one. And as with many decision processes, Bayesian reasoning lights the way…</em></p><p><em>…Jo presumably believes Veldt is worth around 53.75 (the average of her bid and offer). But how confident is she in her belief? The width of her market can give you a clue. It's 0.50 ZAR, whereas yours was going to be 0.20 ZAR wide. All other things equal, you should think that Jo only has 40% (0.20/0.50) of the confidence in her fair value as you do in yours.</em></p><p><em>On some absolute scale of confidence, you can say you had a belief-strength of 100 in your fair value of 54.35 (before seeing Jo's market), and Jo has a belief-strength of 40 in her fair value of 53.75 (before seeing yours). And it turns out the weighted average of these two beliefs is quite a reasonable way to combine them: 100/140 * 54.35 + 40/140 * 53.75 = 54.18. Your updated fair value, having seen Jo's market, is thus 54.18 ZAR.</em></p><p><em>This procedure is a quick, heuristic, and reduced version of Bayesian belief-updating, and a good reference on the subject is A.L. Barker's 1995 paper.</em></p><p><em>After updating, you now believe that the stock is worth 54.18. Assuming your trading costs, risk limits, and return requirements are satisfied, buying 1000 shares for 54.00 is a good trade. Naively, you might just put out a 54.00 bid for 1000 shares, trade with half the 2000 share offer, and hope to collect your expected-value ZAR.</em></p><p><em>In practice, however, you might be able to make even more. If Jo is making a 0.50 wide market, maybe she'd be willing to sell lower than 54.00. It's conceivable that if you put out a 53.90 bid for 1000 shares, Jo will sell at that price, and you collect an extra 100 ZAR!</em></p><p><em>Of course, Jo could react differently. She could see your bid and use that information to change her market, in much the same way you did before turning on. These are difficult decisions, ones where experience with the product and the market make a big difference in being able to eke out a little extra edge. Let's play it safe however and pay 54.00 for 1000 shares.</em></p><p><em>You trade, and Jo reacts by immediately canceling her market. This is not an uncommon occurrence in illiquid stocks, especially in emerging markets, so you're not too surprised. You wait a couple of minutes, mentally visualizing Jo in front of her six monitors, evaluating her trade and her model.</em></p><p><em>Finally, she turns back on. Her new market is 53.50 - 54.05 (10000x)! You reason that Jo has seen that someone (you) disagrees with her valuation of the stock. Jo is a good Bayesian like you, and so she has incorporated that information into her model and updated her beliefs about the fair value of the stock. Her updated belief is that she now wants to sell even more stock, at a marginally higher price. Clearly, she almost entirely discounts the information you've communicated to her with your trade.</em></p><p><em>How should you react? It seems fairly clear that, assuming Jo is not a crazy or incompetent market maker (usually a fair assumption), your trade was a bad one. You bought 1000 shares, when in retrospect, you would have wanted to buy much less, probably zero.</em></p><p><em>Imagine instead that Jo had turned back on with a market of 54.00 - 54.50 (1000x). Her reaction now clearly indicates the information you gave her with your trade is valuable, and she has adjusted her beliefs accordingly. Your trade was probably a good one. Don't you wish you had bought all 2000 shares on offer?</em></p><p><em>No matter what Jo's reaction is, you will be unhappy with your trade. Note that Jo will be unhappy too, since retrospectively she should have either made her initial market bigger or smaller. Welcome to the joyous world of trading!”</em></p></blockquote><p>Whether or not you make money, you have regrets! If you profited, you could have made more. If you lost money, you shouldn’t have made the trade at all. Like death and taxes, you can’t avoid adverse selection.&nbsp;</p><p>Lebron continues to highlight a few areas of trading that have adverse selection problems.</p><p><span>First, IPOs. If you buy the stock in an IPO, you expect the share price to “pop” on the first day of trading. However, if others also have this expectation, the round will be oversubscribed. You can only get the quantity of shares that you bid for when the market </span><strong>doesn’t</strong><span> think the shares will go up. So if you are able to get the shares that you want, the IPO is likely a dud. See also: Venture Capital fundraising.&nbsp;</span></p><p>Second, powerful entities that change the rules of the game while you’re playing. Exchanges nullify “erroneous” trades. Brokerages limit buying. Anyone who tried to buy GameStop stock on Robinhood on January 28, 2021, knows this form of adverse selection all too well.</p><p>Lebron also highlights “special trades”, in which you should throw the “normal rules” out of the window. This advice generalizes to other areas of life:&nbsp;</p><blockquote><p><em>“The normal rules do not apply. If you remove yourself from our usual routine, if you think hard and clearly about the specific situation, maybe you can do something good. Perhaps even great. Others will be paralyzed by inaction, but perhaps you won’t be. Crises can be opportunities.”</em></p></blockquote><p><em>Take only the risks you’re being paid to take. Hedge the others.</em><span>&nbsp;</span></p><p>In trading, as in life, you can make the right call in expected value terms but still lose due to randomness. Some of that randomness is avoidable. Some of it is not — and can be accounted for by hedging. Here, Lebron encourages us to rely on multiple risk measures and actively seek to understand the risks that we might be subject to.&nbsp;</p><p>That’s all well and good in the world of finance, with derivatives contracts. But how might this apply in other areas of life?</p><p>If you work for a publicly traded company and are compensated in stock, sell your shares as soon as you receive them. This is not because I don’t expect the share price of Microsoft/Meta/Apple/etc. to go up. The stock may very well outperform the market. But you are not being compensated for the added risk that you take on here. Your employment prospects at Microsoft/Meta/Apple/etc. are highly correlated with the share price. When the share price is down is when layoffs happen. Former Enron employees can chime in here.</p><p>Similarly, it makes sense to hedge anything that is outside of your control. Let’s say you’ve decided the crypto bear market of 2023 is a great time to start a new crypto company. Your success depends on things within your control, such as:</p><ul><li><p>Your idea</p></li><li><p>Your hard work and ability to execute</p></li><li><p>Your network for hiring</p></li><li><p>Your ability to fundraise</p></li><li><p>Etc.</p></li></ul><p>As well as some things outside of your control, such as:</p><ul><li><p>Interest rates</p></li><li><p>The current VC fundraising environment&nbsp;</p></li><li><p>The performance of crypto as a sector&nbsp;</p></li><li><p>The performance of tech overall</p></li><li><p>Etc.</p></li></ul><p><span>It might make sense to </span><strong>short </strong><span>the overall tech sector or a basket of publicly traded crypto-related companies so that your trade of time and foregone income to start your new crypto company is associated with only the risks you can control.</span></p><p>But some risks you can’t hedge. These are the more interesting ones. There is counterparty risk (your trading partner blows up), liquidity risk (the market you used to hedge dries up), or even political risk:</p><blockquote><p><em>“Living in the developed world, it’s easy to fall into the seductive assumption that the rule of law applies strongly everywhere. This is far from the case. A foreigner trading in an emerging market is frequently among the first “victims” of any political turmoil.”</em></p></blockquote><p>Lebron is meticulous in the ways that he thinks about risk. He highlights that in the markets, you need to be exceedingly paranoid to survive:</p><blockquote><p><em>“Certainly, the modern compendium of mental illnesses (DSM-5) takes a dim view of people who think everyone is out to get them. Yet financial markets are different: people really are out to get you, after all.”</em></p></blockquote><p>I don’t think enough people consider risk and the hedges you can take in the context of a career. I’ve spent the past several years working at startups, where I’ve placed a hugely levered career bet. I’m trading my time and the opportunity cost of another job to work at my current employer. My salary, stock options, expertise, and social capital that I build from working 10 hours per day is fundamentally long (and has risks associated with):</p><ul><li><p>The tech industry</p></li><li><p>My startup’s industry</p></li><li><p>My individual startup&nbsp;</p></li><li><p>Our customers’ business viability&nbsp;</p></li></ul><blockquote><p><em>“Many trades that look different on the surface can in fact be the same trade in disguise, and trades whose edge appears to derive from one risk are actually bets on another risk.”</em></p></blockquote><p><span>It might make sense to hedge some of that risk – simply having friends that work at other companies and in other industries so that all of my social capital isn’t in one basket is a start</span></p><p><span>.&nbsp;</span></p><p>My only gripe here is that I would have liked to see Lebron call out ergodicity more explicitly. Blowing up your account might be fine as a trader – if you have a decent prior track record, you can probably just get a job at a different firm – but in life other losses are less reversible. As far as we know, this is the only universe we have access to. It doesn’t matter if your bet was positive EV and you won in 51% or 75% or even 99% of universes. You should place a high premium on staying alive and having enough bankroll to play the next round of the game. This is more important outside of finance than in the world of trading.</p><p><em>Put on a risk using the most liquid instrument for that risk.</em><span>&nbsp;</span></p><p>Liquidity isn’t something I think about in daily life. But I probably should. A personal example: I gave up the liquidity of a month-to-month gym contract in New York City in February 2020. I paid one year upfront for a 10% discount. Oops.</p><p><span>Lebron also reminds us that the </span><a href="https://byrnehobart.medium.com/the-30-year-mortgage-is-an-intrinsically-toxic-product-200c901746a" rel="">30-Year Mortgage is an Intrinsically Toxic Product</a><span>, a concept that will resonate with all of the Georgists here.&nbsp;</span></p><blockquote><p><em>“The usual path to homeownership exposes people to a financial decision that would, it seems clear, be ridiculed if it were taken by any self-respecting public company.”&nbsp;</em></p></blockquote><p>Among other issues:</p><ul><li><p><em>“The home is bought and sold through an opaque cartel of brokers whose interests are demonstrably not aligned with those of their customers”</em></p></li><li><p><em>“The ability to service the debt (the mortgage) is highly correlated with local economic conditions. This means that if you lose your job and need to sell your house, you will typically find it an exceedingly bad time to try to sell your house.”</em></p></li><li><p><em>“Residential real estate has historically returned significantly below equity markets over long time horizons”&nbsp;</em></p></li></ul><p><span>But I’m not so sure that these lessons are directly applicable to other areas of life. Some of the best things in life come from lashing yourself to the mast, burning the boats behind you, </span><strong>willingly giving up</strong><span> liquidity. The deepest monogamous relationships are built from an irrational investment in one other person, saying “In sickness and in health, until death do us part.” How many scientific problems were solved because one person had an irrational willingness to: Just. Keep. Going.&nbsp;</span></p><p>Sometimes it’s powerful to use the sunk cost fallacy to your advantage. Investing in relationships, subject matter expertise, even putting down roots via *gulp* homeownership reduces your liquidity, but also leads to some of the best (if intangible) things in life.</p><p>If you can’t explain your edge in five minutes, you don’t have a very good one.&nbsp;</p><p>OR&nbsp;</p><p>The long-term profitability of an edge is inversely proportional to how long it takes to explain it.</p><p><span>The Efficient Market Hypothesis is one of the core concepts taught in Finance 101. The Efficient Market Hypothesis is a </span><strong>lie</strong><span>. The person that better understands the nature of a small sliver of the world (e.g. Apple’s share price) will make more money than others.</span></p><p>Modern financial markets are exceedingly competitive. This means that the bigger you think your edge is, the more likely it is that you’re wrong.&nbsp;</p><blockquote><p><em>“Evolutionary thinking applies quite directly when thinking about the evolution of markets. Having an edge in a mature market means understanding the world better than other traders, even ones who are already highly skilled. In fact, the marginal trader in modern financial markets is quite sophisticated and skilled indeed.”</em></p></blockquote><p><span>Lebron here warns us of getting too cute with data, of changing variables. Enough randomness will produce an “edge” that is likely to break down the second a trading strategy hits the real world. You can always find a statistical correlation if you change enough variables. But this is fundamentally the same problem facing the </span><a href="https://slatestarcodex.com/2014/04/28/the-control-group-is-out-of-control/" rel="">replication crisis</a><span> in social sciences.&nbsp;</span></p><p>Lebron argues that we need stories here. Edge is expressed in stories: an edge does not exist without a clear mental representation of that edge. Pure linear algebra does not suffice.</p><p><span>I’m not so sure. It seems like AI companies are pushing forward technology in a way that suggests that mental representations are not the only path to intelligence. Lebron discounts “black box” trading strategies without much discussion of their potential merits. Are all of </span><a href="https://en.wikipedia.org/wiki/Renaissance_Technologies" rel="">RenTech’s</a><span> models explainable by a story? The firm is notoriously secretive, so I don’t know, but I’d guess not.</span></p><blockquote><p><em>“Frequently a good trade appears, has a seemingly insurmountable difficulty, and it is mere persistence that knocks down the final barrier. There may have been many others who looked at the idea, wanted to do it, but couldn’t get past that last hurdle.”</em></p></blockquote><p><span>Before Sam Bankman-Fried was the face of Why Effective Altruism is Bad, before he even founded FTX, he made money </span><a href="https://www.bloomberg.com/news/articles/2021-04-01/the-ex-jane-street-trader-who-s-building-a-multi-billion-crypto-empire" rel="">arbitraging the difference between Bitcoin prices on Japanese and American exchanges</a><span>. I’m reminded of that trade here. It isn’t a particularly elegant trade, it doesn’t require deep technical knowledge or any models. It was a </span><strong>schlep</strong><span>. It was all operational work: figuring out how to open a Japanese bank account, transferring money between the US and Japan, standing in line for hours every day at both US and Japanese banks (presumably this wasn’t the same person).&nbsp;</span></p><p>In as technical a field as trading, sheer willpower is often what gets things done in the end.</p><p><em>The model expresses the edge.</em><span>&nbsp;</span></p><p>Lebron drills into us that a model is the tool for expressing an edge. The model is not the edge. The model does not give us unique knowledge about the world. The map is not the territory.&nbsp;</p><p>He dives into the difference between generative (G) and phenomenological (P) models. G models express a worldview and fit data into that way of thinking, whereas P models solely look at the empirical data to build a worldview.</p><p>Models of the world differ from models of markets, though. Markets have quick feedback loops, are explicit in terms of what they measure, and are easy to quantify at a specific point in time. Most of our models for the world, though, are ill-defined and explicit.</p><p><span>Models are only as good as our assumptions. As an aside, this is a common criticism of rationality or Effective Altruism – you can justify any worldview if you assign your model input weights in just the right way</span></p><p><span>. I also tend to think that “traditional” EA is overly dependent on P models, and doesn’t embrace the G models that led to economic reforms in India in the 1990s or the economic policies that led to rapid economic development in Southeast Asia in the second half of the 20th Century. Interestingly, I think a lot of longtermist EA, specifically AI alignment, leans the other way, relying on G models which explicitly assume a certain P(doom) and work backwards from there. (Though I won’t pretend to be an expert here or to understand everything, so take this with a grain of salt.)&nbsp;</span></p><p><span>Overall, startups and tech seem to take heed to Lebron’s lesson much better than the folks hanging out on this part of the internet: </span><em>“Even if a model makes good predictions about some future value or event, that knowledge is useless without also knowing how to take advantage of that prediction.”</em></p><p>Now we get a bit philosophical. By acting, you change the nature of the market. Your model predicts things that might not be true as soon as you start trading (and changing the environment) based on it.&nbsp;</p><p>When you’re right, everyone else sees the same trades that your model does and will beat you to them. When your model is wrong, others don’t act, meaning adverse selection rears its ugly head once again. So your model shows you with an edge, but in practice you only make the trades where you don’t have an edge.&nbsp;</p><p>Lebron closes by arguing that G models are best for understanding other people, and are good in and of themselves:&nbsp;</p><blockquote><p><em>“You can also see connections to traditional moral philosophy in thinking about modeling the behavior of others. To have a good G model about someone else is to have some measure of empathy and compassion for that person: what they’re like, what they think and feel, putting yourself in their shoes. Pragmatically, developing the skill of empathy and compassion for others is, aside from a moral good in itself, an excellent way to understand better the people who surround you. More people working to develop good G models of others is surely a small step to a better world.”</em></p></blockquote><p><em>If you think your costs are negligible relative to your edge, you’re wrong about at least one of them.</em></p><p>This section of the book displayed a good amount of epistemic humility, words that I didn’t expect to be typing in the context of a book about trading.</p><p><span>Lebron tells us that trades don’t exist independently in the universe — in the n-dimensional space of all possible trades seeking to optimize profitability, if you have a gigantic mountain of profitability, someone else has probably at least discovered the base. So you probably </span><strong>don’t</strong><span> have a profitable trade; rather, you are misunderstanding something about your trade. You’ve either overestimated profitability or underestimated cost.</span></p><p>Lebron highlights four types of trading costs: </p><p>[graph that didn’t show up correctly here: two axes and four quadrants, with the axes being visible ←→ invisible costs and linear ←→ nonlinear costs]</p><p>Here, we’ll focus on Quadrant 4, where he highlights a few interesting phenomena.</p><p>Herding. It’s likely that if you have a profitable trading strategy, either:</p><ol><li><p>Other firms discovered a similar strategy independently and/or</p></li><li><p>You’ve “stolen” the idea from someone else (say if you leave a firm), or vice versa</p></li></ol><p>Lebron highlights Long Term Capital Management (LTCM) as an example here, which suffered a famous blowup in 1998. This hedge fund is often discussed in the context of betting on Russia just before it defaulted on its debt, but an under-discussed aspect is the market mechanics. Other firms were copying LTCM’s trades, so there was a liquidity issue and a cascade of failures when the firm’s margin positions needed to be unwound.&nbsp;</p><p>Lebron also discusses opportunity cost, a concept with which most will be familiar. But here, he discusses the cost in the context of trading. Ultimately, this is an explore/exploit problem. How should a trading firm weigh maximizing profit for today’s strategies, as opposed to working on organizational efficiencies so that you can have the capacity to work on tomorrow’s strategies?</p><p>There is a clear career parallel here: I’ve seen so many people get locked into their current role due to inertia, whereas the ones who succeed long-term appear to prioritize their own learning and exploration.</p><p>As a case study, Lebron discusses how Bell Labs (AT&amp;T) maintained a position of dominance for half a century. He attributes this to four things:</p><p>First, they hired the best. There was interaction between three groups that did not interact at most organizations.</p><ol><li><p>Scientists and engineers who conducted exploratory research.</p></li><li><p>More applied engineers, who took the work of the first group and integrated their discoveries into existing problems at AT&amp;T.</p></li><li><p>A third group of engineers who put the work from the first two groups into production.</p></li></ol><p>This seems to have been cargo-culted at most modern tech companies. Ping-pong tables and nap pods don’t replace a true culture of cross-pollination of ideas in a boring cafeteria.&nbsp;</p><p><span>I’m reminded of the story of Richard Feynman in academia</span></p><p><span>. His colleagues who kept their office doors closed made progress on their research in the short-term, but hit stumbling blocks. Those who kept their doors open didn’t seem to make much progress initially, but eventually outpaced the “closed door” scientists. They had new ideas and research directions based on all the interesting conversations they were having with others.</span></p><p>The simple lesson here is to get outside of your bubble a bit more. Maybe the normies have something valuable to say once in a while.&nbsp;</p><p>Second, an emphasis on continuing education. This blew me away: Bell Labs developed a syllabus of graduate-level courses and taught it to any interested employee. They didn’t outsource the curriculum or the teaching.</p><p><span>Third, a technical staff that was held in just as high of an esteem as the PhDs who managed them. This seems to be why there is little innovation in government: talented engineers are treated as second-class citizens in research labs, so they work for Stripe and OpenAI instead. Similarly, one can attribute the lack of innovation in hospitals to doctors holding all of the institutional power. Often, all a hospital needs to save lives is </span><a href="https://en.wikipedia.org/wiki/The_Checklist_Manifesto" rel="">simple practices that other businesses figured out long ago</a><span>, but the hubris of MDs prevents this from happening. But I digress.&nbsp;&nbsp;</span></p><p>Fourth, a culture that embraced failure. While many companies say they have a culture of “failing fast”, how many actually mean it?&nbsp;</p><p>Some of the best parts of this book are the diversions. This book is in a sense nostalgic – edges are lost over time, trading firms come and go, entire markets disappear. All you have along the way is the knowledge that for one instant, in one market, you had knowledge that the rest of the world didn’t and used it to make one profitable trade.</p><p><em>Just because something has never happened doesn’t mean it can’t.&nbsp;</em></p><p><em>Corollary: Enough people relying on something being true makes it false.</em></p><p><span>“Impossible” and </span><a href="https://arxiv.org/pdf/1103.5672.pdf" rel="">“25-standard deviation” events</a><span> sure seem to happen awfully often in the financial industry.&nbsp;</span></p><p>Consider an airplane engine that has a 1/1,000 chance of failing. Each plane has two engines, so that if one fails the other can still operate and get everyone to the ground safely. That’s great if the engines act as completely independent variables, but what if failures are correlated?&nbsp;</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c83fb0a-dce8-47ca-9dd7-276236fa4a69_1200x742.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c83fb0a-dce8-47ca-9dd7-276236fa4a69_1200x742.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c83fb0a-dce8-47ca-9dd7-276236fa4a69_1200x742.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c83fb0a-dce8-47ca-9dd7-276236fa4a69_1200x742.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c83fb0a-dce8-47ca-9dd7-276236fa4a69_1200x742.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c83fb0a-dce8-47ca-9dd7-276236fa4a69_1200x742.png" width="1200" height="742" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/4c83fb0a-dce8-47ca-9dd7-276236fa4a69_1200x742.png&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:742,&quot;width&quot;:1200,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:&quot;Chart&quot;,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" title="Chart" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c83fb0a-dce8-47ca-9dd7-276236fa4a69_1200x742.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c83fb0a-dce8-47ca-9dd7-276236fa4a69_1200x742.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c83fb0a-dce8-47ca-9dd7-276236fa4a69_1200x742.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c83fb0a-dce8-47ca-9dd7-276236fa4a69_1200x742.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>The key insight here is that small correlations create large changes in failure probabilities. Namely, a relatively “small” correlation of 0.1 increases the probability of engine failure 100x.&nbsp;</p><p>The feedback loop of markets is great at hiding these correlations until something goes wrong. When it does, you have highly-correlated mortgage-backed securities kicking off the 2008 Financial Crisis.</p><p>One of Lebron’s more interesting insights is that markets are stochastic, self-organized feedback systems, which means that both momentum trades (a price that is going up will continue to go up) and mean-reversion trades (the exact opposite) are valuable at different points in time.</p><p>I found this to be a good framework for thinking about AI. Some folks are clearly betting on momentum – that GPT-X products will continue to improve, reaching AGI (if it hasn’t already). The other side of the coin is bets on mean-reversion, which focus on the S-curves of technology and take a historical view. I’m old enough to remember that in 2016 everyone was talking about how self-driving cars would mean the end of truckers, and there’s more demand than ever for them today.</p><p><em>Working to align everyone’s interests is time well spent.</em><span>&nbsp;</span></p><p>This is the principal-agent problem. Whenever the person investing the money is not also providing the capital, you’re going to have problems.&nbsp;</p><p>Follow the incentives. When a fund manager is paid 2% of assets under management (AUM), the incentive is to raise as much money as possible. When they are paid 20% of profits, they’re incentivized to make high-risk investments, as their upside is uncapped but their downside is capped at $0.</p><p>High-water mark provisions help with this. Basically if your fund had $1 billion AUM last year and you lost 30% this year, you now have $700 million. As the fund manager, you don’t get paid until you’re back to the $1 billion mark.</p><p>But…then you just shut down your fund, return the $700 million, and start a new fund.</p><p>Lebron argues that the only way to resolve this problem is to perfectly align capital and labor.</p><p>I wonder how much of the Renaissance Medallion fund’s success comes from a) this perfect alignment of incentives vs. b) capital limits, meaning that strategies can be executed that would not work at a larger scale.&nbsp;</p><p>Lebron argues that everyone acting as an owner is a good thing. And I tend to agree! But there’s a free-rider problem here that he doesn’t address. I’m writing this book review instead of working at my day job as a tech employee. I’m an owner — but my salary and equity was negotiated a few years ago when I signed my job offer. If I were a salesperson working on commission, perhaps I’d be singing a different tune. Aligning incentives is easier when you’re working at a job where performance is a) easily measurable and b) a direct output of your labor (say, as the Portfolio Manager at a hedge fund).</p><p>Lebron also argues that, within an organization, consistency of culture is more important than the specific culture. I fully agree – this is particularly egregious at tech companies. Many claim to support work-life balance but then ask you to work weekends, or say “we’re a family” but then lay off employees the second they have trouble raising the next round of funding. Employees can see right through this. Put your flag in the ground and say what you actually stand for. If you stand for everything, you stand for nothing.&nbsp;</p><p><em>If you don’t master technology and data, you’re losing to someone who does.</em></p><p>This point is self-explanatory and I don’t think it needs further exploration for the average Astral Codex Ten reader.&nbsp;</p><p>Will machines take over the world? Lebron straddles the line here and states in the context of trading, a human-machine hybrid still does the best work, given our complementary skill sets. Humans have higher-level thinking and understanding context, whereas computers possess the speed and iteration ability necessary to implement models. This book was released in 2019 — I’d love to see if Lebron has updated his priors at all based on recent developments in AI.</p><p>There’s also an interesting diversion here into software development. Specifically, Lebron tries to quantify technical debt, which I haven’t seen done before.</p><p><em>If you’re not getting better, you’re getting worse.</em></p><p>The markets are a very scary place, and you are in an existential arms race with your competitors.&nbsp; Adapt or die. At the individual level, group (trading desk/business unit) level, firm level, and market level. Adapt or die.&nbsp;</p><p>That may seem harsh. But no – Lebron praises trading as a positive-sum game. International financial markets allow the flow of capital from rich to poor countries, giving rich investors a return and raising the standard of living in the developing world.&nbsp;</p><p>This is a striking perspective to have on trading. I’ve heard traders describe the work they do as “net neutral” and “adding no value to the world”. Conversely, Lebron views trading as an act of creativity, a way to make the world, in one small way, a better place through creating efficiencies in markets. His philosophical approach to markets is best demonstrated through this story of a trader named Mark,&nbsp;</p><blockquote><p><em>“Tomorrow will be more difficult than today, and the day after more difficult still, and on until the day he decides to retire from the business. There is no respite and there are no pauses to the inexorable adaptation of markets.</em></p><p><em>It’s easy to view Mark’s job as a soul-destroying, almost Sisyphean effort. And indeed, it’s this ceaseless competition that does, over time, break the will of many market participants. But I will argue in what follows that the best traders view their situation with very much the opposite perspective: as a liberating and redemptive force…</em></p><p><em>…Profitable traders are some of the most intelligent, driven, perceptive, and adaptable people on earth. To relegate such a person to a life of maintenance and literally trading on past glories sounds and is soul-destroying. The essence of trading, the thing that makes it such an interesting and stimulating undertaking, is this very process of adaptation and competition.”</em></p></blockquote><p><span>One can imagine Lebron, in a previous life, penning the words </span><a href="https://en.wikipedia.org/wiki/The_Myth_of_Sisyphus" rel="">“One must imagine Sisyphus happy.”</a></p><p>Beyond the philosophy, while reading this book I was struck by the fact that trading is one of the few true apprenticeship systems that remains for white-collar work. You can career switch into the technology industry without a degree. There is a clear educational path to becoming a doctor or a lawyer. But trading is a bunch of dudes (and it’s almost always men) behind closed doors working on intellectually challenging problems. Lebron recognizes this as well:</p><blockquote><p><em>“Autodidacts in trading are like jailhouse lawyers: for every person who’s truly discovered and developed a successful strategy sui generis, there is an army of people who either significantly undervalued the teaching that others provided, or they are deluding themselves about the profitability of their trading.”</em></p></blockquote><p><em>The Laws of Trading</em><span> opens the door to this world a crack and allows the rest of us to peek in, ever so slightly.</span></p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Llama: Add grammar-based sampling (343 pts)]]></title>
            <link>https://github.com/ggerganov/llama.cpp/pull/1773</link>
            <guid>36819906</guid>
            <pubDate>Fri, 21 Jul 2023 21:17:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/ggerganov/llama.cpp/pull/1773">https://github.com/ggerganov/llama.cpp/pull/1773</a>, See on <a href="https://news.ycombinator.com/item?id=36819906">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  
  <task-lists disabled="" sortable="">
    <div>
      <p dir="auto">EDITED after updates</p>
<p dir="auto">Inspired by <a data-error-text="Failed to load title" data-id="1704730522" data-permission-text="Title is private" data-url="https://github.com/ggerganov/llama.cpp/issues/1397" data-hovercard-type="pull_request" data-hovercard-url="/ggerganov/llama.cpp/pull/1397/hovercard" href="https://github.com/ggerganov/llama.cpp/pull/1397">#1397</a> and <a href="https://github.com/grantslatton/llama.cpp/commit/007e26a99d485007f724957fa8545331ab8d50c3">grantslatton's CFG work</a>, this adds an API that takes a serialized context-free grammar to guide and constrain sampling. Also adds a sample Backus-Naur form (BNF)-like syntax in <code>main</code> for specifying a grammar for generations.</p>
<h2 dir="auto">Testing</h2>
<p dir="auto">(M2 Max, 30B)</p>
<details>
<summary>Chess</summary>
<div data-snippet-clipboard-copy-content=" % ./main -m $LLAMA_30B_Q4_0 -n 32 -p $'A good game:\n\n' --grammar-file grammars/chess.gbnf
main: build = 674 (e550234)
main: seed  = 1688014137
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 32, n_keep = 0


main: grammar:
root ::= [1] [.] [ ] move [ ] move [<U+000A>] root_4 
move ::= move_5 move_9 
root_2 ::= [1-9] root_3 [.] [ ] move [ ] move [<U+000A>] 
root_3 ::= [0-9] | 
root_4 ::= root_2 root_4 | root_2 
move_5 ::= pawn | nonpawn | castle 
pawn ::= pawn_14 [a-h] [1-8] pawn_16 
nonpawn ::= [NBKQR] nonpawn_10 nonpawn_11 nonpawn_12 [a-h] [1-8] 
castle ::= [O] [-] [O] castle_17 
move_9 ::= [+#] | 
nonpawn_10 ::= [a-h] | 
nonpawn_11 ::= [1-8] | 
nonpawn_12 ::= [x] | 
pawn_13 ::= [a-h] [x] 
pawn_14 ::= pawn_13 | 
pawn_15 ::= [=] [NBKQR] 
pawn_16 ::= pawn_15 | 
castle_17 ::= [-] [O] | 

 A good game:

1. e4 e5
2. Nf3 Nc6
3. Bb5 a6
4. Ba4 Nf6

llama_print_timings:        load time =  1144.33 ms
llama_print_timings:      sample time =    35.87 ms /    32 runs   (    1.12 ms per token)
llama_print_timings: prompt eval time =  1126.34 ms /     7 tokens (  160.91 ms per token)
llama_print_timings:        eval time =  5214.99 ms /    31 runs   (  168.23 ms per token)
llama_print_timings:       total time =  6398.45 ms"><pre><code> % ./main -m $LLAMA_30B_Q4_0 -n 32 -p $'A good game:\n\n' --grammar-file grammars/chess.gbnf
main: build = 674 (e550234)
main: seed  = 1688014137
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 32, n_keep = 0


main: grammar:
root ::= [1] [.] [ ] move [ ] move [&lt;U+000A&gt;] root_4 
move ::= move_5 move_9 
root_2 ::= [1-9] root_3 [.] [ ] move [ ] move [&lt;U+000A&gt;] 
root_3 ::= [0-9] | 
root_4 ::= root_2 root_4 | root_2 
move_5 ::= pawn | nonpawn | castle 
pawn ::= pawn_14 [a-h] [1-8] pawn_16 
nonpawn ::= [NBKQR] nonpawn_10 nonpawn_11 nonpawn_12 [a-h] [1-8] 
castle ::= [O] [-] [O] castle_17 
move_9 ::= [+#] | 
nonpawn_10 ::= [a-h] | 
nonpawn_11 ::= [1-8] | 
nonpawn_12 ::= [x] | 
pawn_13 ::= [a-h] [x] 
pawn_14 ::= pawn_13 | 
pawn_15 ::= [=] [NBKQR] 
pawn_16 ::= pawn_15 | 
castle_17 ::= [-] [O] | 

 A good game:

1. e4 e5
2. Nf3 Nc6
3. Bb5 a6
4. Ba4 Nf6

llama_print_timings:        load time =  1144.33 ms
llama_print_timings:      sample time =    35.87 ms /    32 runs   (    1.12 ms per token)
llama_print_timings: prompt eval time =  1126.34 ms /     7 tokens (  160.91 ms per token)
llama_print_timings:        eval time =  5214.99 ms /    31 runs   (  168.23 ms per token)
llama_print_timings:       total time =  6398.45 ms
</code></pre></div>
</details>
<details>
<summary>"Chess" without grammar</summary>
<div data-snippet-clipboard-copy-content="% ./main -m $LLAMA_30B_Q4_0 -n 32 -p $'A good game:\n\n'  

main: build = 645 (fd0eb66)
main: seed  = 1686286016
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 32, n_keep = 0


 A good game:

Sir Thomas Gresham, when he was building his famous Exchange at London, had the following dialogue with a mason, whose name was Richard B
llama_print_timings:        load time =  1185.47 ms
llama_print_timings:      sample time =    21.57 ms /    32 runs   (    0.67 ms per token)
llama_print_timings: prompt eval time =  1167.67 ms /     7 tokens (  166.81 ms per token)
llama_print_timings:        eval time =  4977.97 ms /    31 runs   (  160.58 ms per token)
llama_print_timings:       total time =  6188.21 ms"><pre><code>% ./main -m $LLAMA_30B_Q4_0 -n 32 -p $'A good game:\n\n'  

main: build = 645 (fd0eb66)
main: seed  = 1686286016
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 32, n_keep = 0


 A good game:

Sir Thomas Gresham, when he was building his famous Exchange at London, had the following dialogue with a mason, whose name was Richard B
llama_print_timings:        load time =  1185.47 ms
llama_print_timings:      sample time =    21.57 ms /    32 runs   (    0.67 ms per token)
llama_print_timings: prompt eval time =  1167.67 ms /     7 tokens (  166.81 ms per token)
llama_print_timings:        eval time =  4977.97 ms /    31 runs   (  160.58 ms per token)
llama_print_timings:       total time =  6188.21 ms
</code></pre></div>
</details>
<details>
<summary>Arithmetic</summary>
<div data-snippet-clipboard-copy-content=" % ./main -m $LLAMA_30B_Q4_0 -n 32 -p $'Some arithmetic practice:\n\n' \                      
--grammar 'root  ::= (expr &quot;=&quot; ws num &quot;\n&quot;)+
expr  ::= term ([-+*/] term)*
term  ::= ident | num | &quot;(&quot; ws expr &quot;)&quot; ws
ident ::= [a-z] [a-z0-9_]* ws
num   ::= [0-9]+ ws
ws    ::= [ \t\n]*'
main: build = 674 (e550234)
main: seed  = 1688014196
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 32, n_keep = 0


main: grammar:
root ::= root_5 
root_1 ::= expr [=] ws num [<U+000A>] 
expr ::= term expr_8 
ws ::= ws_12 
num ::= num_11 ws 
root_5 ::= root_1 root_5 | root_1 
term ::= ident | num | [(] ws expr [)] ws 
expr_7 ::= [-+*/] term 
expr_8 ::= expr_7 expr_8 | 
ident ::= [a-z] ident_10 ws 
ident_10 ::= [a-z0-9_] ident_10 | 
num_11 ::= [0-9] num_11 | [0-9] 
ws_12 ::= [ <U+0009><U+000A>] ws_12 | 

 Some arithmetic practice:

10 *a*1 +b*2 =640

10 *a*2 +b*3 =656


llama_print_timings:        load time =  1165.00 ms
llama_print_timings:      sample time =    41.11 ms /    32 runs   (    1.28 ms per token)
llama_print_timings: prompt eval time =  1147.76 ms /     7 tokens (  163.97 ms per token)
llama_print_timings:        eval time =  5113.92 ms /    31 runs   (  164.97 ms per token)
llama_print_timings:       total time =  6323.27 ms"><pre><code> % ./main -m $LLAMA_30B_Q4_0 -n 32 -p $'Some arithmetic practice:\n\n' \                      
--grammar 'root  ::= (expr "=" ws num "\n")+
expr  ::= term ([-+*/] term)*
term  ::= ident | num | "(" ws expr ")" ws
ident ::= [a-z] [a-z0-9_]* ws
num   ::= [0-9]+ ws
ws    ::= [ \t\n]*'
main: build = 674 (e550234)
main: seed  = 1688014196
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 32, n_keep = 0


main: grammar:
root ::= root_5 
root_1 ::= expr [=] ws num [&lt;U+000A&gt;] 
expr ::= term expr_8 
ws ::= ws_12 
num ::= num_11 ws 
root_5 ::= root_1 root_5 | root_1 
term ::= ident | num | [(] ws expr [)] ws 
expr_7 ::= [-+*/] term 
expr_8 ::= expr_7 expr_8 | 
ident ::= [a-z] ident_10 ws 
ident_10 ::= [a-z0-9_] ident_10 | 
num_11 ::= [0-9] num_11 | [0-9] 
ws_12 ::= [ &lt;U+0009&gt;&lt;U+000A&gt;] ws_12 | 

 Some arithmetic practice:

10 *a*1 +b*2 =640

10 *a*2 +b*3 =656


llama_print_timings:        load time =  1165.00 ms
llama_print_timings:      sample time =    41.11 ms /    32 runs   (    1.28 ms per token)
llama_print_timings: prompt eval time =  1147.76 ms /     7 tokens (  163.97 ms per token)
llama_print_timings:        eval time =  5113.92 ms /    31 runs   (  164.97 ms per token)
llama_print_timings:       total time =  6323.27 ms
</code></pre></div>
</details>
<details>
<summary>Arithmetic - no grammar</summary>
<div data-snippet-clipboard-copy-content=" % ./main -m $LLAMA_30B_Q4_0 -n 32 -p $'Some arithmetic practice:\n\n'                                            
main: build = 645 (fd0eb66)
main: seed  = 1686286388
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 32, n_keep = 0


 Some arithmetic practice:

\begin{code}
package main

import (
    &quot;fmt&quot;
)

func main() {
    fmt.Println(
llama_print_timings:        load time =  1171.65 ms
llama_print_timings:      sample time =    21.37 ms /    32 runs   (    0.67 ms per token)
llama_print_timings: prompt eval time =  1153.88 ms /     7 tokens (  164.84 ms per token)
llama_print_timings:        eval time =  4991.68 ms /    31 runs   (  161.02 ms per token)
llama_print_timings:       total time =  6187.91 ms"><pre><code> % ./main -m $LLAMA_30B_Q4_0 -n 32 -p $'Some arithmetic practice:\n\n'                                            
main: build = 645 (fd0eb66)
main: seed  = 1686286388
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 32, n_keep = 0


 Some arithmetic practice:

\begin{code}
package main

import (
    "fmt"
)

func main() {
    fmt.Println(
llama_print_timings:        load time =  1171.65 ms
llama_print_timings:      sample time =    21.37 ms /    32 runs   (    0.67 ms per token)
llama_print_timings: prompt eval time =  1153.88 ms /     7 tokens (  164.84 ms per token)
llama_print_timings:        eval time =  4991.68 ms /    31 runs   (  161.02 ms per token)
llama_print_timings:       total time =  6187.91 ms
</code></pre></div>
</details>
<details>
<summary>JSON</summary>
<div data-snippet-clipboard-copy-content="% ./main -m $LLAMA_30B_Q4_0 -n 64 -p $'A bit about me:\n\n' --grammar-file grammars/json.gbnf
main: build = 674 (e550234)
main: seed  = 1688014289
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 64, n_keep = 0


main: grammar:
root ::= object 
object ::= [{] ws object_11 [}] 
value ::= object | array | string | number | boolean 
array ::= [[] ws array_15 []] 
string ::= [&quot;] string_16 [&quot;] ws 
number ::= number_17 number_18 ws 
boolean ::= boolean_19 ws 
ws ::= [ <U+0009><U+000A>] ws | 
object_8 ::= string [:] ws value object_10 
object_9 ::= [,] ws string [:] ws value 
object_10 ::= object_9 object_10 | 
object_11 ::= object_8 | 
array_12 ::= value array_14 
array_13 ::= [,] ws value 
array_14 ::= array_13 array_14 | 
array_15 ::= array_12 | 
string_16 ::= [ <U+0009>!#-[]-~] string_16 | 
number_17 ::= [-] | 
number_18 ::= [0-9] number_18 | [0-9] 
boolean_19 ::= [t] [r] [u] [e] | [f] [a] [l] [s] [e] 

 A bit about me:

{
	&quot;fullName&quot;: &quot;Ramon Rodriguez&quot;,
	&quot;username&quot;: &quot;ramon&quot;,
	&quot;email&quot;: &quot;ramon@mail.com&quot;,
	&quot;phoneNumber&quot;: &quot;+1234567890&quot;,
	&quot;address&quot;: {
		
llama_print_timings:        load time =  1273.70 ms
llama_print_timings:      sample time =    82.93 ms /    64 runs   (    1.30 ms per token)
llama_print_timings: prompt eval time =  1256.36 ms /     8 tokens (  157.04 ms per token)
llama_print_timings:        eval time = 10432.05 ms /    63 runs   (  165.59 ms per token)
llama_print_timings:       total time = 11795.36 ms"><pre><code>% ./main -m $LLAMA_30B_Q4_0 -n 64 -p $'A bit about me:\n\n' --grammar-file grammars/json.gbnf
main: build = 674 (e550234)
main: seed  = 1688014289
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 64, n_keep = 0


main: grammar:
root ::= object 
object ::= [{] ws object_11 [}] 
value ::= object | array | string | number | boolean 
array ::= [[] ws array_15 []] 
string ::= ["] string_16 ["] ws 
number ::= number_17 number_18 ws 
boolean ::= boolean_19 ws 
ws ::= [ &lt;U+0009&gt;&lt;U+000A&gt;] ws | 
object_8 ::= string [:] ws value object_10 
object_9 ::= [,] ws string [:] ws value 
object_10 ::= object_9 object_10 | 
object_11 ::= object_8 | 
array_12 ::= value array_14 
array_13 ::= [,] ws value 
array_14 ::= array_13 array_14 | 
array_15 ::= array_12 | 
string_16 ::= [ &lt;U+0009&gt;!#-[]-~] string_16 | 
number_17 ::= [-] | 
number_18 ::= [0-9] number_18 | [0-9] 
boolean_19 ::= [t] [r] [u] [e] | [f] [a] [l] [s] [e] 

 A bit about me:

{
	"fullName": "Ramon Rodriguez",
	"username": "ramon",
	"email": "ramon@mail.com",
	"phoneNumber": "+1234567890",
	"address": {
		
llama_print_timings:        load time =  1273.70 ms
llama_print_timings:      sample time =    82.93 ms /    64 runs   (    1.30 ms per token)
llama_print_timings: prompt eval time =  1256.36 ms /     8 tokens (  157.04 ms per token)
llama_print_timings:        eval time = 10432.05 ms /    63 runs   (  165.59 ms per token)
llama_print_timings:       total time = 11795.36 ms
</code></pre></div>
</details>
<details>
<summary>"JSON" - no grammar</summary>
<div data-snippet-clipboard-copy-content=" % ./main -m $LLAMA_30B_Q4_0 -n 32 -p $'A bit about me:\n\n'                                                                          
main: build = 645 (fd0eb66)
main: seed  = 1686286615
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 32, n_keep = 0


 A bit about me:

A former teacher, now a full-time writer. I am the author of two novels: _The Man in the Moon_ and _The Riddle
llama_print_timings:        load time =  1291.32 ms
llama_print_timings:      sample time =    21.48 ms /    32 runs   (    0.67 ms per token)
llama_print_timings: prompt eval time =  1274.63 ms /     8 tokens (  159.33 ms per token)
llama_print_timings:        eval time =  4990.01 ms /    31 runs   (  160.97 ms per token)
llama_print_timings:       total time =  6306.01 ms"><pre><code> % ./main -m $LLAMA_30B_Q4_0 -n 32 -p $'A bit about me:\n\n'                                                                          
main: build = 645 (fd0eb66)
main: seed  = 1686286615
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 32, n_keep = 0


 A bit about me:

A former teacher, now a full-time writer. I am the author of two novels: _The Man in the Moon_ and _The Riddle
llama_print_timings:        load time =  1291.32 ms
llama_print_timings:      sample time =    21.48 ms /    32 runs   (    0.67 ms per token)
llama_print_timings: prompt eval time =  1274.63 ms /     8 tokens (  159.33 ms per token)
llama_print_timings:        eval time =  4990.01 ms /    31 runs   (  160.97 ms per token)
llama_print_timings:       total time =  6306.01 ms
</code></pre></div>
</details>
<details>
<summary>Japanese</summary>
<div data-snippet-clipboard-copy-content=" % ./main -m $LLAMA_30B_Q4_0 -n 32 -p $'Building a website can be done in 10 simple steps (from the original Japanese):\n\n' --grammar-file grammars/japanese.gbnf
main: build = 674 (e550234)
main: seed  = 1688013430
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 32, n_keep = 0


main: grammar:
root ::= root_2 root_5 
jp-char ::= hiragana | katakana | punctuation | cjk 
root_2 ::= jp-char root_2 | jp-char 
root_3 ::= [ <U+0009><U+000A>] root_4 
root_4 ::= jp-char root_4 | jp-char 
root_5 ::= root_3 root_5 | 
hiragana ::= [<U+3041>-<U+309F>] 
katakana ::= [<U+30A1>-<U+30FF>] 
punctuation ::= [<U+3001>-<U+303E>] 
cjk ::= [<U+4E00>-<U+9FFF>] 

 Building a website can be done in 10 simple steps (from the original Japanese):

一、目的は何なのか
二、お客さまを思い出して
三、お客さまのこと
llama_print_timings:        load time =  2957.19 ms
llama_print_timings:      sample time =    42.67 ms /    32 runs   (    1.33 ms per token)
llama_print_timings: prompt eval time =  2941.56 ms /    21 tokens (  140.07 ms per token)
llama_print_timings:        eval time =  5384.28 ms /    31 runs   (  173.69 ms per token)
llama_print_timings:       total time =  8387.61 ms"><pre><code> % ./main -m $LLAMA_30B_Q4_0 -n 32 -p $'Building a website can be done in 10 simple steps (from the original Japanese):\n\n' --grammar-file grammars/japanese.gbnf
main: build = 674 (e550234)
main: seed  = 1688013430
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 32, n_keep = 0


main: grammar:
root ::= root_2 root_5 
jp-char ::= hiragana | katakana | punctuation | cjk 
root_2 ::= jp-char root_2 | jp-char 
root_3 ::= [ &lt;U+0009&gt;&lt;U+000A&gt;] root_4 
root_4 ::= jp-char root_4 | jp-char 
root_5 ::= root_3 root_5 | 
hiragana ::= [&lt;U+3041&gt;-&lt;U+309F&gt;] 
katakana ::= [&lt;U+30A1&gt;-&lt;U+30FF&gt;] 
punctuation ::= [&lt;U+3001&gt;-&lt;U+303E&gt;] 
cjk ::= [&lt;U+4E00&gt;-&lt;U+9FFF&gt;] 

 Building a website can be done in 10 simple steps (from the original Japanese):

一、目的は何なのか
二、お客さまを思い出して
三、お客さまのこと
llama_print_timings:        load time =  2957.19 ms
llama_print_timings:      sample time =    42.67 ms /    32 runs   (    1.33 ms per token)
llama_print_timings: prompt eval time =  2941.56 ms /    21 tokens (  140.07 ms per token)
llama_print_timings:        eval time =  5384.28 ms /    31 runs   (  173.69 ms per token)
llama_print_timings:       total time =  8387.61 ms
</code></pre></div>
</details>
<details>
<summary>Japanese - no grammar</summary>
<div data-snippet-clipboard-copy-content="% ./main -m $LLAMA_30B_Q4_0 -n 32 -p $'Building a website can be done in 10 simple steps (from the original Japanese):\n\n' 
main: build = 674 (e550234)
main: seed  = 1688013483
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 32, n_keep = 0


 Building a website can be done in 10 simple steps (from the original Japanese):

1. Determine your goal for your site.
2. Make a plan.
3. Select the domain name.
4. Choose web
llama_print_timings:        load time =  2955.05 ms
llama_print_timings:      sample time =    22.96 ms /    32 runs   (    0.72 ms per token)
llama_print_timings: prompt eval time =  2937.10 ms /    21 tokens (  139.86 ms per token)
llama_print_timings:        eval time =  5032.41 ms /    31 runs   (  162.34 ms per token)
llama_print_timings:       total time =  8013.71 ms"><pre><code>% ./main -m $LLAMA_30B_Q4_0 -n 32 -p $'Building a website can be done in 10 simple steps (from the original Japanese):\n\n' 
main: build = 674 (e550234)
main: seed  = 1688013483
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 32, n_keep = 0


 Building a website can be done in 10 simple steps (from the original Japanese):

1. Determine your goal for your site.
2. Make a plan.
3. Select the domain name.
4. Choose web
llama_print_timings:        load time =  2955.05 ms
llama_print_timings:      sample time =    22.96 ms /    32 runs   (    0.72 ms per token)
llama_print_timings: prompt eval time =  2937.10 ms /    21 tokens (  139.86 ms per token)
llama_print_timings:        eval time =  5032.41 ms /    31 runs   (  162.34 ms per token)
llama_print_timings:       total time =  8013.71 ms
</code></pre></div>
</details>
<h2 dir="auto">Approach</h2>
<h3 dir="auto">Grammar API</h3>
<p dir="auto">The <code>llama</code> API accepts a data structure representing a context-free grammar over 32-bit code points:</p>
<div data-snippet-clipboard-copy-content="    // grammar element type
    enum llama_gretype {
        // end of rule definition
        LLAMA_GRETYPE_END            = 0,

        // start of alternate definition for rule
        LLAMA_GRETYPE_ALT            = 1,

        // non-terminal element: reference to rule
        LLAMA_GRETYPE_RULE_REF       = 2,

        // terminal element: character (code point)
        LLAMA_GRETYPE_CHAR           = 3,

        // modifies a preceding LLAMA_GRETYPE_CHAR or LLAMA_GRETYPE_CHAR_ALT to
        // be an inclusive range ([a-z])
        LLAMA_GRETYPE_CHAR_RNG_UPPER = 4,

        // modifies a preceding LLAMA_GRETYPE_CHAR or
        // LLAMA_GRETYPE_CHAR_RNG_UPPER to add an alternate char to match ([ab], [a-zA])
        LLAMA_GRETYPE_CHAR_ALT       = 5,
    };

    typedef struct llama_grammar_element {
        enum llama_gretype type;
        uint32_t           value; // Unicode code point or rule ID
    } llama_grammar_element;

    LLAMA_API struct llama_grammar * llama_grammar_init(
            const llama_grammar_element ** rules,
                                 size_t    n_rules,
                                 size_t    start_rule_index);"><pre><code>    // grammar element type
    enum llama_gretype {
        // end of rule definition
        LLAMA_GRETYPE_END            = 0,

        // start of alternate definition for rule
        LLAMA_GRETYPE_ALT            = 1,

        // non-terminal element: reference to rule
        LLAMA_GRETYPE_RULE_REF       = 2,

        // terminal element: character (code point)
        LLAMA_GRETYPE_CHAR           = 3,

        // modifies a preceding LLAMA_GRETYPE_CHAR or LLAMA_GRETYPE_CHAR_ALT to
        // be an inclusive range ([a-z])
        LLAMA_GRETYPE_CHAR_RNG_UPPER = 4,

        // modifies a preceding LLAMA_GRETYPE_CHAR or
        // LLAMA_GRETYPE_CHAR_RNG_UPPER to add an alternate char to match ([ab], [a-zA])
        LLAMA_GRETYPE_CHAR_ALT       = 5,
    };

    typedef struct llama_grammar_element {
        enum llama_gretype type;
        uint32_t           value; // Unicode code point or rule ID
    } llama_grammar_element;

    LLAMA_API struct llama_grammar * llama_grammar_init(
            const llama_grammar_element ** rules,
                                 size_t    n_rules,
                                 size_t    start_rule_index);
</code></pre></div>
<h3 dir="auto">Sampling</h3>
<p dir="auto">The grammar sampling code models a nondeterministic pushdown automaton, maintaining N stacks for the possible parse states. Sampling a token is done in two steps: a sampling API that filters candidates to those that match one of the parse stacks (<code>llama_sample_grammar</code>) and adding the chose token to the grammar (<code>llama_grammar_accept_token</code>).</p>
<h3 dir="auto">Examples</h3>
<p dir="auto">Adds <code>--grammar</code> and <code>--grammar-file</code> arguments to <code>main</code> taking a simple extended BNF to constrain generations. The parser for this format is implemented in <code>examples/grammar-parser.{h,cpp}</code>:</p>
<div data-snippet-clipboard-copy-content="// ... Supports character
// ranges, grouping, and repetition operators. As an example, a grammar for
// arithmetic might look like:
//
// root  ::= expr
// expr  ::= term ([-+*/] term)*
// term  ::= num | &quot;(&quot; space expr &quot;)&quot; space
// num   ::= [0-9]+ space
// space ::= [ \t\n]*"><pre><code>// ... Supports character
// ranges, grouping, and repetition operators. As an example, a grammar for
// arithmetic might look like:
//
// root  ::= expr
// expr  ::= term ([-+*/] term)*
// term  ::= num | "(" space expr ")" space
// num   ::= [0-9]+ space
// space ::= [ \t\n]*
</code></pre></div>
<p dir="auto">The <code>root</code> rule identifies the start of the grammar.</p>
<p dir="auto"><del>## Caveats</del></p>
<ul dir="auto">
<li><del>the binary format makes the code harder to understand and more brittle</del></li>
<li><del>the grammar contemplates 16-bit chars but it's just being applied to the 8-bit UTF-8 chars in token strings currently</del></li>
<li><del>the 1-char lookahead sampling is probably biasing generations in a weird way; further investigation on quality of outputs is probably needed</del></li>
</ul>
    </div>
  </task-lists>
  
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FreeWilly 1 and 2, two new open-access LLMs (115 pts)]]></title>
            <link>https://stability.ai/blog/freewilly-large-instruction-fine-tuned-models</link>
            <guid>36818923</guid>
            <pubDate>Fri, 21 Jul 2023 20:03:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://stability.ai/blog/freewilly-large-instruction-fine-tuned-models">https://stability.ai/blog/freewilly-large-instruction-fine-tuned-models</a>, See on <a href="https://news.ycombinator.com/item?id=36818923">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-block-type="2" id="block-92ab10ed08f1f3488e0d">
  <p>Stability AI and its <a href="https://carper.ai/" target="_blank"><span>CarperAI lab</span></a> are proud to announce <a href="https://huggingface.co/stabilityai/FreeWilly1-Delta-SafeTensor" target="_blank"><span>FreeWilly1</span></a> and its successor <a href="https://huggingface.co/stabilityai/FreeWilly2" target="_blank"><span>FreeWilly2</span></a>, two powerful new, open access, Large Language Models (LLMs). Both models demonstrate exceptional reasoning ability across varied benchmarks. FreeWilly1 leverages the original LLaMA 65B foundation model and was carefully fine-tuned with a new synthetically-generated dataset using Supervised Fine-Tune (SFT) in standard Alpaca format. Similarly, FreeWilly2 leverages the LLaMA 2 70B foundation model to reach a performance that compares favorably with GPT-3.5 for some tasks.</p><p>Both models are research experiments, and are released to foster open research under a non-commercial license. While we have conducted internal red-teaming to ensure the model remains polite and harmless, we welcome the community's feedback and help in further red-teaming.</p><p><strong>Data Generation and Collection</strong></p><p>The training for the FreeWilly models was directly inspired by the methodology pioneered by Microsoft in its paper: "Orca: Progressive Learning from Complex Explanation Traces of GPT-4.” While our data generation process is similar, we differ in our data sources.</p><p>Our variant of the dataset, containing 600,000 data points (roughly 10% of the dataset size the original Orca paper used), was created by prompting language models with high-quality instructions from the following datasets created by <a href="https://huggingface.co/conceptofmind" target="_blank"><span>Enrico Shippole</span></a>:</p><ol data-rte-list="default"><li><p><a href="https://huggingface.co/datasets/conceptofmind/cot_submix_original" target="_blank"><span>COT Submix Original</span></a></p></li><li><p><a href="https://huggingface.co/datasets/conceptofmind/niv2_submix_original" target="_blank"><span>NIV2 Submix Original</span></a></p></li><li><p><a href="https://huggingface.co/datasets/conceptofmind/flan2021_submix_original" target="_blank"><span>FLAN 2021 Submix Original</span></a></p></li><li><p><a href="https://huggingface.co/datasets/conceptofmind/t0_submix_original" target="_blank"><span>T0 Submix Original</span></a></p></li></ol><p>With this approach, we generated 500,000 examples with one simpler LLM model and an additional 100,000 with a more sophisticated LLM model. To ensure fair comparisons, we carefully filtered these datasets and removed examples that originated from evaluation benchmarks. Despite training on one-tenth the sample size of the original Orca paper (significantly reducing the cost and carbon footprint of training the model compared to the original paper), the resulting FreeWilly models demonstrate exceptional performance across various benchmarks – validating our approach to synthetically generated datasets.</p><p><strong>Performance Evaluation</strong></p><p>To internally evaluate these models, we used EleutherAI’s <a href="https://github.com/EleutherAI/lm-evaluation-harness" target="_blank"><span>lm-eval-harness</span></a>, to which we added <a href="https://github.com/dmahan93/lm-evaluation-harness/tree/add-agieval" target="_blank"><span>AGIEval</span></a>.</p><p>Both FreeWilly models excel in many areas, including intricate reasoning, understanding linguistic subtleties, and answering complex questions related to specialized domains, e.g. Law and mathematical problem-solving.</p><p><strong>Open LLM Leaderboard benchmarks:</strong></p><p>These FreeWilly results were evaluated by Stability AI researchers and independently reproduced by Hugging Face on July 21st, 2023, and published in their leaderboard.</p>
</div><div data-block-type="2" id="block-yui_3_17_2_1_1689965544627_21970">
  <p><strong>Contributing to an open future</strong></p><p>FreeWilly1 and FreeWilly2 set a new standard in the field of open access Large Language Models. They both significantly advance research, enhance natural language understanding, and enable complex tasks. We are excited about the endless possibilities that these models will bring to the AI community, and the new applications they will inspire.</p><p>We would like to express our sincere gratitude to our passionate team of researchers, engineers, and collaborators, whose remarkable efforts and dedication have enabled us to reach this significant milestone.</p><p>Stay tuned for more exciting developments, and begin exploring the incredible potential of FreeWilly today!</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Journalists should be skeptical of all sources including scientists (420 pts)]]></title>
            <link>https://natesilver.substack.com/p/journalists-should-be-skeptical-of</link>
            <guid>36818896</guid>
            <pubDate>Fri, 21 Jul 2023 20:01:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://natesilver.substack.com/p/journalists-should-be-skeptical-of">https://natesilver.substack.com/p/journalists-should-be-skeptical-of</a>, See on <a href="https://news.ycombinator.com/item?id=36818896">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p>I’m not usually one for scandals. My eyes glaze over at Congressional hearings. I’ve never read the Mueller Report. There are usually too many threads to unwind, and too many competing claims to evaluate. But I’m going to make an exception here, because we have a scandal where the facts are relatively simple and clear — but which was nevertheless extremely consequential.</p><p><span>Here’s the scandal. In March 2020, a group of scientists — in particular</span></p><p><span>, Kristian G. Andersen the of The Scripps Research Institute, Andrew Rambaut of The University of Edinburgh, Edward C. Holmes of the University of Sydney, and Robert F. Garry of Tulane University — published a paper in </span><em>Nature Medicine</em><span> that seemingly contradicted their true beliefs about COVID’s origins and which they knew to be misleading. The </span><a href="https://www.nature.com/articles/s41591-020-0820-9" rel="">paper</a><span>, “The proximal origin of SARS-CoV-2”, has been </span><a href="https://scholar.google.com/scholar?cites=4180430536993184356&amp;as_sdt=5,33&amp;sciodt=0,33&amp;hl=en" rel="">cited more than 5,900 times</a><span> and was enormously influential in shaping the debate about the origins of COVID-19.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e937c74-f2b6-478a-aa5d-c485635efa71_820x385.webp" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e937c74-f2b6-478a-aa5d-c485635efa71_820x385.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e937c74-f2b6-478a-aa5d-c485635efa71_820x385.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e937c74-f2b6-478a-aa5d-c485635efa71_820x385.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e937c74-f2b6-478a-aa5d-c485635efa71_820x385.webp 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e937c74-f2b6-478a-aa5d-c485635efa71_820x385.webp" width="820" height="385" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/2e937c74-f2b6-478a-aa5d-c485635efa71_820x385.webp&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:385,&quot;width&quot;:820,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:31870,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/webp&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e937c74-f2b6-478a-aa5d-c485635efa71_820x385.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e937c74-f2b6-478a-aa5d-c485635efa71_820x385.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e937c74-f2b6-478a-aa5d-c485635efa71_820x385.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e937c74-f2b6-478a-aa5d-c485635efa71_820x385.webp 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p><span>We know this because of a series of leaked and </span><a href="https://foia.state.gov/learn/foia.aspx" rel="">FOIAed</a><span> emails and Slack messages that have been reported on by </span><em>Public</em><span>, </span><em>Racket News, The Intercept </em><span>and </span><em>The Nation </em><span>along with other small, independent media outlets. You can find a detailed summary of the claims and a copy of the emails and messages </span><a href="https://public.substack.com/p/covid-origins-scientist-denounces" rel="">here</a><span> at </span><em>Public</em><span>. There’s also good context around the messages </span><a href="https://usrtk.org/covid-19-origins/timeline-the-proximal-origin-of-sars-cov-2/" rel="">here</a><span> (very detailed) or </span><a href="https://rogerpielkejr.substack.com/p/covidgate" rel="">here</a><span> and </span><a href="https://rogerpielkejr.substack.com/p/the-truth-is-never-going-to-come" rel="">here</a><span> (more high-level). </span></p><p><span>The messages show that the authors were highly uncertain about COVID’s origins — and if anything, they leaned more toward a lab leak than a spillover from an animal source. But none of that was expressed in the “Proximal Origin” paper, which instead said that </span><strong>“we do not believe that any type of laboratory-based scenario is plausible”.</strong><span> Granted, there is a little bit of ass-covering — “More scientific data could swing the balance of evidence to favor one hypothesis over another,” they also wrote in the paper. But the message — natural origin good, lab leak bad — was received clearly enough by mainstream news outlets. “No, the new coronavirus wasn't created in a lab, scientists say”, </span><a href="https://www.cbc.ca/news/science/coronavirus-wasnt-created-in-lab-no-signs-genetic-engineering-1.5508735" rel="">reported</a><span> the CBC in covering the paper. “COVID-19 coronavirus epidemic has a natural origin” was the </span><a href="https://www.sciencedaily.com/releases/2020/03/200317175442.htm" rel="">headline</a><span> at Science Daily.</span></p><p><span>In the Slack and email messages, the authors worked to manipulate the media narrative about COVID-19’s origins and to ensure that their private uncertainty wasn’t conveyed in conversations with reporters. They also thought they were going to get away with it. “The truth is never going to come out ”, </span><a href="https://twitter.com/mbalter/status/1679098392587255809/photo/1" rel="">wrote</a><span> Rambaut in one message. This went beyond mere motivated reasoning. There was an enormous gap between what the authors believed privately and what they stated publicly, including in the “Proximal Origin” paper — again, see the above links for more detail.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4312ffc-15ad-4abb-98af-dfcad3409f40_1600x200.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4312ffc-15ad-4abb-98af-dfcad3409f40_1600x200.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4312ffc-15ad-4abb-98af-dfcad3409f40_1600x200.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4312ffc-15ad-4abb-98af-dfcad3409f40_1600x200.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4312ffc-15ad-4abb-98af-dfcad3409f40_1600x200.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4312ffc-15ad-4abb-98af-dfcad3409f40_1600x200.png" width="1456" height="182" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d4312ffc-15ad-4abb-98af-dfcad3409f40_1600x200.png&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:182,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:93385,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4312ffc-15ad-4abb-98af-dfcad3409f40_1600x200.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4312ffc-15ad-4abb-98af-dfcad3409f40_1600x200.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4312ffc-15ad-4abb-98af-dfcad3409f40_1600x200.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4312ffc-15ad-4abb-98af-dfcad3409f40_1600x200.png 1456w" sizes="100vw"></picture></div></a></figure></div><p><span>What were the authors’ motivations to mislead the public? I think that’s also pretty straightforward. In fact, you can find prominent virologists </span><a href="https://www.nature.com/articles/d41586-021-01383-3" rel="">quoted on record</a><span> as to why the lab leak theory was so </span><em>problematic</em><span> — even if it wasn’t necessarily </span><em>wrong</em><span>. The problems fall into three buckets:</span></p><ol><li><p><span>Evidence of a lab leak could cause a political backlash — understandably, given that COVID has killed almost 7 million people — resulting in a reduction in funding for gain-of-function research and other virological research. That’s potentially important to the authors or the authors’ bosses — and the authors were </span><a href="https://twitter.com/HansMahncke/status/1682193300055285760?s=20" rel="">very aware</a><span> of the career implications for how the story would play out;</span></p></li><li><p><span>Evidence of a lab leak could </span><a href="https://www.nytimes.com/2023/02/27/business/energy-department-theory-coronavirus-china.html" rel="">upset China and undermine research collaborations</a><span>;</span></p></li><li><p><span>Evidence of a lab leak could provide validation to Trump and Republicans who </span><a href="https://www.politico.com/news/2021/06/15/wuhan-lab-trump-officials-covid-494700" rel="">touted the theory</a><span> — remember, all of this was taking place during an election year, and medical, epidemiological and public health experts had few reservations about </span><a href="https://www.cnn.com/2020/06/05/health/health-care-open-letter-protests-coronavirus-trnd/index.html" rel="">weighing in on political matters</a><span>.</span></p></li></ol><p><span>To be clear, I’m not sure how COVID originated either. I’d “buy” the lab leak at a 50 percent likelihood (I think </span><a href="https://alexwasburne.substack.com/p/the-short-case-for-a-lab-origin" rel="">this</a><span> is pretty convincing) and sell it at 80 percent, which still leaves a lot of wiggle room for me to be persuaded one way or the other.</span></p><p>But I think this is a big scandal either way. As someone who has spent a lot of time trying to convey statistical and epistemic uncertainty to the public, I’m deeply disappointed by the scientists’ conduct here and how unmoored they were from any attempt at truth-seeking.</p><p><span>The COVID origins story has also been a </span><a href="https://www.slowboring.com/p/the-medias-lab-leak-fiasco" rel="">journalistic fiasco</a><span>, with the lab leak having been dismissed as a “</span><a href="https://www.nytimes.com/2020/02/17/business/media/coronavirus-tom-cotton-china.html" rel="">conspiracy theory</a><span>” and as </span><a href="https://www.nytimes.com/2020/03/08/technology/coronavirus-misinformation-social-media.html" rel="">misinformation</a><span> even though many prominent scientists believed it to be plausible all along. Perhaps it’s tempting to give the media a pass — they </span><em>were</em><span> manipulated by the “Proximal Origin” authors, after all. But I’m not inclined to, for two reasons.</span></p><p><span>First, the coverage of the recently leaked emails and Slack messages at major center-left outlets like The New York Times has been pathetic. The Times </span><a href="https://www.nytimes.com/2023/07/11/us/politics/covid-lab-leak-fauci.html" rel="">portrayed</a><span> Andersen as the victim of a Republican witch-hunt — rather than someone at the center of a major scientific scandal of his own making.</span></p><p><span>And second, journalists ought to have decent bullshit detectors — including toward scientists, academics and other experts.</span></p><p><span>Maybe you think Andersen </span><em>et. al.</em><span> are bad apples, but the messages make clear that they were speaking for a pretty broad swath of the scientific community. Still — and maybe this is wishful thinking — but I’m going to assert that people like him are in the minority among scientists. I fairly often speak with scientists and academics myself — especially when I’m working on a research-driven book project, as I am now — and those experiences are overwhelmingly positive.</span></p><p><span>And yet, even if the incidence of bad apples is relatively rare among scientists and academics — rarer than it might be among politicians or other groups that journalists intrinsically treat with more skepticism — it’s clearly not </span><em>exceedingly</em><span> rare. It was just this week that the </span><a href="https://stanforddaily.com/2023/07/19/stanford-president-resigns-over-manipulated-research-will-retract-at-least-3-papers/" rel="">president of Stanford was forced to resign in a research scandal</a><span>. (Perhaps not coincidently, the scandal was broken by the student newspaper, </span><em>The Stanford Daily</em><span>, and not by a major center-left outlet like The Times.)</span></p><p><span>I also think journalists are more prone toward being manipulated by bad apples in academia and science than they were ten or twenty years ago. As a result of</span><a href="https://www.nytimes.com/2021/09/08/us/politics/how-college-graduates-vote.html" rel=""> increasing educational polarization</a><span>, both journalists and the expert class of scientists and academics are far more aligned politically than they once were (the very large majority are left-of-center and vote Democratic in American elections). Even if “trust the science” or “trust the experts” is </span><em>usually</em><span> right — and I think it </span><em>usually</em><span> is right! — it leaves an opening for bad apples like Andersen to exploit the trust that honest scientists have worked so hard to earn.</span></p><p><span>There’s also a generational divide in journalism, with younger journalists tending to be more openly left/progressive than their older peers — and tending to be more </span><a href="https://www.vocabulary.com/dictionary/Manichean" rel="">Manichean</a><span> in dividing the world between good and evil rather than proceeding from the notion that people and news stories are complicated and it’s not particularly their job to pass moral judgment. It’s slightly amusing that The Times fired their Pulitzer Prize-winning coronavirus reporter in middle of the pandemic — a reporter who </span><a href="https://donaldgmcneiljr1954.medium.com/how-i-learned-to-stop-worrying-and-love-the-lab-leak-theory-f4f88446b04d" rel="">saw the lab leak theory as credible</a><span> — and replaced him with another reporter who </span><a href="https://www.cnn.com/2021/05/27/media/covid-19-origins-lab-leak-media/index.html" rel="">dismissed discussion of the lab leak as “racist”</a><span>. </span></p><p>But this really isn’t complicated. All I’m suggesting is that journalists ought to treat scientists like they do any other source — that is to say, with an appropriate dose of skepticism.</p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Big Tech as the New Big Tobacco (174 pts)]]></title>
            <link>https://www.bigtechwiki.com/index.php/Big_Tech_as_the_New_Big_Tobacco</link>
            <guid>36818640</guid>
            <pubDate>Fri, 21 Jul 2023 19:44:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bigtechwiki.com/index.php/Big_Tech_as_the_New_Big_Tobacco">https://www.bigtechwiki.com/index.php/Big_Tech_as_the_New_Big_Tobacco</a>, See on <a href="https://news.ycombinator.com/item?id=36818640">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="bodyContent">
				<p>From BigTechWiki</p>
				
				
				<p><a href="#column-one">Jump to navigation</a><a href="#searchInput">Jump to search</a></p><!-- start content -->
				<div id="mw-content-text" lang="en" dir="ltr"><ul><li>Republicans and Democrats began to view Big Tech in the light Big Tobacco was, with one saying the comparison was “an appropriate analogy”</li></ul>
<ul><li>Lawmakers like Republicans Ken Buck and Cynthia Lummis and Democrat Ed Markey compared Facebook and Big Tech to Big Tobacco. Markey described Instagram as “that first childhood cigarette, meant to get teens hooked early.” Lummis agreed that comparing Facebook and Big Tech to Big Tobacco was an “appropriate analogy.” Republican Rep. Bill Johnston compared Big Tech CEOs to those from large tobacco companies, accusing the tech firms of being equally dangerous to society. Buck compared big tech to big tobacco, saying they were “harming our kids for profit.” Richard Blumenthal, who led a lawsuit against Big Tobacco in the 1990s as AG of CT, said Facebook and Big Tech were facing a “Big Tobacco moment,” comparing Facebook’s strategy papers with those done by Tobacco companies on reaching middle schoolers.<sup id="cite_ref-1"><a href="#cite_note-1">[1]</a></sup></li></ul>
<ul><li>Big Tech directly followed in Big Tobacco’s footsteps by funding academic research
<ul><li>Big Tobacco had a long history of commissioning and funding academic research to pull focus away from the proven harms of their products. Big Tech similarly started to fund institutions to ensure the “ethical development” of their technology, which led to questions about conflicts of interest and research independence. Researchers from Cornell noted that Big Tech and Big Tobacco’s funding of scientific research and development were similar in both industries: “Pump vast sums of money” into researching the problems they were creating.<sup id="cite_ref-2"><a href="#cite_note-2">[2]</a></sup></li>
<li>Both Big Tech and Big Tobacco wanted to influence research to ensure their industries sustained support and were seen as socially responsible. Researchers from Cornell said Big Tobacco invested in Academia in order to influence the research questions of those studying tobacco, hoping to find friendly academics who could be leveraged and recast the companies as socially responsible. Big Tobacco’s funding agencies worked to maintain an impartial and scientific image, even as it mainly funded research that was not about tobacco’s health impacts.</li>
<li>Much like Big Tobacco, the Academics that Big Tech invested in routinely failed to disclose their funding from Big Tech, which created a false impression of independence. The whole goal of funding the research was to exploit the confidence that is had in academia and research, because Think Tanks and organizations were treated as “neutral arbiters” by journalists and lawmakers.</li>
<li>At Big Tech funded agencies, public relations officials and lawyers were involved in plotting the overall research direction and tone. Internal Google documents directed scientists to “strike a positive tone” in their research. Further internal memos from Google showed that the company intended to use friendly academics as a key aim in its strategy to lobby against the EU’s Digital Markets Act. Big Tobacco has given hundreds of millions to research over the years and their efforts spanned across the globe. Big tobacco started its own research group, The Tobacco Industry Research Committee, in 1964 and pumped more than $130 million into the effort by 1986.</li>
<li>Big Tobacco continued this trend of investing in research across the globe, giving tens of thousands of Pounds to two think tanks in the UK that advised the government on Tobacco laws. The two think tanks criticized plans to force retailers to sell cigarettes in unbranded cartons, which was a measure supported by cancer charities and opposed by Big Tobacco. In 2019, it was reported that Tobacco companies had contributed to at least 106 think tanks in two dozen countries. The think tanks they contributed to were found to oppose plain cigarette packaging, had written to regulators in support of new tobacco products or promoted industry funded research. Big Tobacco also contributed to The Heritage Foundation, the Cato Institute and Americans For Tax Reform. As Big Tech faced pressure from proposed tech legislation, they significantly increased their spending on outside organizations, giving to nearly 771 third party organizations since 2015. A significant spike in funding of outside groups by Big Tech after federal and state officials increased scrutiny on their anti-competitive behaviors. Amazon went from contributing to 45 outside organizations in 2015 to 251 outside organizations in 2020. Google more than doubled the amount of outside groups it gave to in 2018 and 2019 compared to 2017 as it faced pressures from California’s consumer privacy law. All of this increased spending by Big Tech put a heavy pressure on academic staff to seek external sources of funding.<sup id="cite_ref-3"><a href="#cite_note-3">[3]</a></sup></li>
<li>Who Big Tech gives to and how much they contributed is murky, as think tanks and nonprofits aren’t required to disclose their funding. Despite Amazon, Facebook and Google voluntarily disclosing who they contributed to, the companies did not divulge the amounts of their contributions.</li>
<li>However, it was found that in the past 5 years, six leading academic institutes in the EU had taken tens of millions of pounds of funding from Google, Facebook, Amazon and Microsoft to research issues linked to the tech firm’s business models. The Institute For Ethics In Artificial Intelligence at the Technical University of Munich received a $7.5 million grant from Facebook in 2019. The Humboldt Institute for Internet and Society in Berlin accepted almost 14 million Euros from Google since it was founded in 2012.<sup id="cite_ref-4"><a href="#cite_note-4">[4]</a></sup></li>
<li>In the U.S., Big Tech individually contributed to various renowned and highly influential think tanks and nonprofits. Those think tanks and nonprofits included but are not limited to the Cato Institute, Heritage Foundation, International Center for Law &amp; Economics, the Information Technology &amp; Innovation foundation and the Global Antitrust Institute at George Mason University.</li>
<li>Big Tech was rewarded handsomely for their contributions to nonprofits and think tanks. Some lobbyists, scholars and think tank officials argued that Google’s donations to nonprofit groups helped explain why it had avoided damaging regulatory and enforcement decisions in the U.S. Further, the major nonprofits that Big Tech had contributed to helped facilitate introductions between the government and Big Tech.</li>
<li>The Global Antitrust Institute at George Mason University had trained more than 850 foreign judges and regulators on Antitrust at their seminars.</li>
<li>While not all of the nonprofits and think tanks held events on behalf of Big Tech, many did advocate for Big Tech in other ways. The Cato Institute argued publicly that people should be “extremely skeptical about predictions of entrenched monopoly power” for big tech. The Progressive Policy Institute president and founder Will Marshall published an op-ed arguing against breaking up Big Tech monopolies while simultaneously calling them “innovative and successful.”</li></ul></li>
<li>Big Tobacco was a lobbying “juggernaut” that invented the special interest lobbying model Big Tech used
<ul><li>In 1998, the Big Tobacco spent nearly $73 million on federal lobbying and employed over 200 lobbyists. When adjusted for inflation, the #73 million in 1998 equated to $122 million in 2021. The Dean of Harvard’s graduate school of arts and sciences said Big Tobacco had “invested in the kind of special interest lobbying” that characterized the late 20th and early 21st century American politics. Big Tobacco was known for their “giant spending” and effective lobbying.</li>
<li>Big Tobacco was said to have a “substantial” presence on Capitol Hill and had a lobbying effort so large it could only be described as a “juggernaut” by OpenSecrets. The Dean of Harvard’s graduate school of arts and sciences said Big Tobacco spent “boatloads” of money in Congress to prevent regulation as more information became public about the harm their products caused. Still to this day, Big Tobacco employed a massive amount of lobbyists, with Altria employing at least 409 lobbyists in 49 states and Reynolds employing 257 lobbyists in 39 states.</li>
<li>Big Tobacco were also big spenders politically in the 90’s and early 2000’s. In 1996, the tobacco industry contributed more than $10 million to political campaigns. In 1998, they contributed more than $8.6 million. In 2000, Big Tobacco again spent more than $8.6 million on political campaigns. And in 2002, Big Tobacco spent $9.29 million on political campaigns. Reynolds American and Altria Group also donated $1.5 million to Donald Trump’s inauguration.</li></ul></li>
<li>Big Tech invested in lobbying to the same degree that Big Tobacco did and have similarly become Washington lobbyists biggest cash cow
<ul><li>A June 2021 NY Times headline read “Tech Giants, Fearful of Proposals to Curb Them, Blitz Washington With Lobbying.” And in 2020, Big Tech spent more on lobbying than any other industry at a combined $51.72 million. Facebook spent the most out of any company in 2020 and the same year spent the most it ever had on lobbying: $19.68 million. Following in second was Amazon, who spent $17.86 million on lobbying, which was also the most the company had ever spent in a year on lobbying. Google spent $7.53 million on lobbying and Apple spent $6.6 million on lobbying in 2020. When asked what they were looking to achieve with their lobbying, none of the tec companies would detail their targets.<sup id="cite_ref-5"><a href="#cite_note-5">[5]</a></sup></li></ul></li>
<li>Big Tobacco created the model for Big Tech’s pre-empting legislation and regulation Big Tobacco offered to fund research and write legislation that would carve ou several loopholes and prevent stricter rules in the future
<ul><li>Starting in the 1980s, Big Tobacco worked to pre-empt legislation with their own corporate-written legislation, a trend that continued into recent policy debates over the legal age to buy tobacco products. Big Tobacco had worked to pre-empt laws to raise the legal age to buy smoking products from 18 to 21 by pushing new legislation that would make enforcement difficult and nullify tougher local laws. A spokesman for the Campaign For Tobacco-Free Kids argued that Big Tobacco were “masters at proposing or supporting a bill that looked good on the surface but often included provisions that [were] harmful to public health.”</li>
<li>By pre-empting legislation, Tobacco was able to halt any local efforts to limit how tobacco used. It was said that by pre-empting legislation with their own corporate-backed bills, Big Tobacco could effectively tie the hands of city governments who wanted to limit tobacco use further. Tobacco companies had been working to pre-empt legislation for decades, including pre-empting versions of the Clean Indoor Air Acts in the 1980s and 1990s. In 1994, a Philip Morris Employee even wrote that the company was “dead serious about achieving pre-emption in all 50 states.”</li></ul></li>
<li>Big Tech followed suit and began supporting legislation they felt they could control to build goodwill after scandals ravaged the industry
<ul><li>Following the Cambridge Analytica scandal, Facebook appeared to back some government regulation. The company launched a new campaign that offered concessions on the Big Tech regulatory debate to generate some goodwill while trying to reframe the larger debate on its own terms. Zuckerberg said in testimony that he welcomed privacy and misinformation regulation as long as it was the “right regulation.”</li>
<li>Zuckerberg went so far as to call on congress to make “thoughtful reform” of Section 230, which safeguarded tech platforms from being held liable for content individual users posted. Zuckerberg said a company’s liability protection under Section 230 should be conditional on their ability to prove they can moderate harmful content – regardless if it successfully removed all harmful content. Zuckerberg's proposal for Section 230 immunity reforms “could theoretically shore up Facebook’s power” as it forced smaller social media companies and startups to develop costly content moderation systems. However, Facebook executives testified before Congress that they wanted Congress to pre-empt local laws that likely included stricter privacy protections than a federal bill.</li>
<li>Ironically, just weeks before Zuckerberg’s 2018 testimony, Facebook poured hundreds of thousands into fighting a privacy ballot initiative in California. Facebook gave $200,000 to a PAC dedicated to defeating “a state ballot initiative that would expand Californian’s privacy controls. After his testimony, Facebook withdrew support for the group and then declined to say if they were involved in other efforts to oppose privacy legislation.</li></ul></li>
<li>Big Tech also used more subtle means to influence policy, like leaning heavily and quietly on trade associations.
<ul><li>A Big Tech lobbyist admitted that there was “strength in numbers” and said Big Tech could use trade associations to “do a little bit of heavy lifting.” Big Tech had increasingly been leaning on industry associations to influence public policy in Washington. Lobbyist Kate Mills, a partner at a Amazon-hired lobbying firm, admitted that Big Tech’s strategy involved leaning heavily and quietly on trade associations.</li>
<li>Amazon, Facebook and Google funded a bevy of political groups that had helped push positive polling and engaged in other “fingerprint-free tactics” designed to deter regulators seeking to break up or penalize the industry. An advocacy group funded by Big Tech had secretly written an op-ed for a local small businessman in Arizona that opposed the state’s investigation into Google. The small business owner was unaware Google had backed the group that approached him to publish the op-ed.</li>
<li>In a single year, Amazon reported spending $6.36 million on state focused “government relations efforts” in 44 states.</li></ul></li></ul>
<ul><li>Big Tech supported a wide range of industry associations that advocated and lobbied for them in D.C.
<ul><li>Big Tech has contributed to a wide range of industry associations, including but not limited to NetChoice, U.S. Chamber of Commerce, The Consumer Technology Association, The Competitive Enterprise Institute, Americans for Tax Reform, TechNet, The Small Business &amp; Entrepreneurship Council, The Internet Association and ComPITA</li>
<li>The various organizations pushed for Big Tech’s goals and defended them when they came under fire. NetChoice, “Tech’s most aggressive lobbying presence in D.C.” was a vocal opponent of antitrust action against Google. NetChoice attacked Texas’ lawsuit against Google’s anticompetitive advertising practices and attacked the DOJ’s antitrust lawsuit against Google.</li>
<li>The Consumer Technology Association spent $10 million on lobbying for Big Tech and opposed local tech regulations on their behalf. The Consumer Technology Association counted Facebook, Alphabet, Apple and Amazon as members. The group opposed proposed right to repair laws in Nevada and elsewhere.</li>
<li>Other organizations provided extra support for Big Tech when they were railing against antitrust or privacy legislation. The Progressive Policy Institute joined Google, Facebook and Amazon (all of which were donors) when the companies were fighting back against Senator Warren’s call to break up Big Tech. Facebook’s Lobbyist co-chaired a technology council at the Illinois Chamber of Commerce as the Chamber was backing the gutting of an online privacy law.</li>
<li>Facebook turned to a lower-profile trade groups such as The Internet Association and CompTIA to help block privacy legislation. 21 days after a judge ruled against Facebook in a biometric privacy act lawsuit, a Facebook backed law weakening Illinois’ biometric privacy act was introduced in the Illinois state legislature. Facebook and CompTIA were directly described as “having a hand in blocking or weakening biometric privacy bills in Montana, Washington, And Illinois.”</li>
<li>CompTIA pushed for changes to the biometric information privacy act on Facebook’s behalf, along with donating to the Republican Party of Texas, where the Republican Attorney General was the sole enforcer of the State’s Biometric Privacy Regulations</li>
<li>In 2020, Facebook launched an astroturf organization to convince federal regulators that Facebook was crucial to free speech. Facebook created American Edge to combat potential federal regulations through advertising and other means. After American Edge was formed as a nonprofit organization, it set up an accompanying social welfare group, which was a common tactic used to obscure donors. American Edge said it was important to create policies that don’t weaken companies that “share American values” as they competed globally.</li></ul></li>
<li>Much like Big Tobacco was in the 90s, Big Tech became mammoth political donors, collectively spending more than $100 million between 2016-2020
<ul><li>Most of Big Tech’s campaign contributions went towards Democrats, which increased year by year as Democrats grew louder about tech reform. Between 2016-2020, Alphabet, Google’s parent company, contributed more than $44 million in political donations. Between 2018-2020, Amazon contributed more than $26 million to political campaigns. Apple contributed more than $12 million to political campaigns between 2016-2020 and Facebook contributed more than $18 million to political campaigns between 2016-2020. Facebook also donated to all four co-sponsors of an Illinois bill to weaken the 2008 biometric information privacy act.</li></ul></li>
<li>Adding to their influence campaigns, Big Tech followed Big Tobacco’s playbook of employing revolving door techniques both Big Tobacco and Big Tech have had former employees in high level government positions and have hired former high level government officials
<ul><li>Big Tobacco found a way to deeply ingratiate themselves with the Trump and Bush administrations. Several top Bush administration staffers had backgrounds in Tobacco, including Senior Adviser Karl Rove. Vice President Pence had extensive ties to the Tobacco industry, receiving $39k in donations from RJ Reynolds and more than $60k from the industry group National Association of Convenience Stores. Senator Blumenthal noted that many of Trump’s appointees had “deep commitments to the Tobacco industry.” Former head of the FDA Scott Gottlieb worked for the e-cigarette company Kure and condemned the influence of Anti-tobacco “activists” in the FDA. The former Solicitor General Noel Francisco represented RJ Reynolds on behalf of the corporate law firm Jones Day prior to joining the federal government.</li>
<li>Big Tobacco also hired former Trump Officials as lobbyists. RJ Reynolds hired former Health and Human Services Secretary Tom Price’s deputy Chief of Staff as their lobbyists.</li>
<li>Google had an ally in the DOJ’s antitrust division during the Trump Administration and a former FTC commissioner joined a law firm Google had hired. Makan Delrahim, who led the DOJ antitrust division under Donald Trump, formerly worked on behalf of Google. After leaving office, former FTC commissioner Joshua Wright joined a law firm that represented Google before the FTC.</li></ul></li>
<li>Big Tobacco and Big Tech had a habit of running from their names after losing public trust in 2003, Philip Morris changed its name to ‘Altria Group’ after public started to feel their name “meant death”
<ul><li>Philip Morris said the name change brought “clarity” to its corporation and operating companies. In 2003, Philip Morris changed its name to ‘Altria Group’. The company said the name change brought “clarity” to its corporate structure and the relationship between the parent company to its operating companies. Philip Morris’ Senior Vice President at the time said “When people say ‘Philip Morris’, people don’t know which company you’re talking about [...] We’re more than a tobacco company.”</li>
<li>Philip Morris also owned Kraft Foods along with their tobacco company</li>
<li>In reality, the name change was a financial decision brought as a way to distance the company from the “death” people associated with them. A former FDA commissioner said Philip Morris was “running away from tobacco” with their name change. The company’s connection with Tobacco had long depressed its stock price, despite being the largest packaged goods company. To consumers, Philip Morris meant tobacco, and tobacco meant death.</li></ul></li>
<li>Facebook planned to change its company name to ‘Meta’ after facing fire for spreading misinformation
<ul><li>Facebook planned to change the name of its company to ‘Meta’ as a signal of its ambition to be known for more than social media. Facebook was reportedly investing in what it called the ‘Metaverse’ which was a digital world where people used various devices to engage with each other in a 3d environment.</li>
<li>The name change came after internal memos leaked showing the company knew about the damage it caused society. At the time of the name change, Facebook was facing some of the most intense scrutiny in its history after an internal whistleblower had leaked internal documents showing Facebook knew about the harmful effects it was having.</li>
<li>Much like Philip Morris, Facebook’s renaming was seen as a way to distance itself from the social networking controversies it was facing. TV personality Jim Cramer kind of let the cat out of the bag when he said the secret of Facebook’s valuation was because of its “habit of reinvention” Facebook’s name change was seen as directly resembling Philip Morris’ decision to change their name after controversies plagued the company. Fast Company said “for a company that brisle[d] at references to its services being akin to cigarettes, taking a page from the Big Tobacco playbook [was] a stunner.” But at the end of the day, the name change would have no impact on Facebook’s operations or executive structure. The change was largely cosmetic.<sup id="cite_ref-6"><a href="#cite_note-6">[6]</a></sup></li></ul></li>
<li>Big Tech spent more on federal lobbying from 2010-202 than the nation’s largest banks from 2000-2010 or Big Tobacco from 1996-1999
<ul><li>Since 2000, the four largest Big Tech companies – Amazon, Apple, Alphabet/Google, and Facebook – have spent $465,026,307 on federal lobbying. $434,474,221 of that total has come since 2010.</li>
<li>Additionally, nine groups that the four Big Tech companies fund have spent $98,061,827 on federal lobbying since 2000. $80,400,019 of that total has come since 2010.</li>
<li>Big Tech’s federal lobbying total eclipses that of other major toxic industries: Since 2010, the nation’s largest opioid manufacturers have spent $282,292,834 on federal lobbying. America’s seven largest banks in the leadup to the financial crisis spent $194,193,858 on federal lobbying from 2000 to 2010. From 1996 to 1999, the nation’s largest tobacco companies spent $155,750,398 on federal lobbying, or $261,306,596 in 2021 dollars.</li></ul></li></ul>
<div><ol>
<li id="cite_note-1"><span><a href="#cite_ref-1">↑</a></span> <span><a rel="nofollow" href="https://www.nytimes.com/2021/10/09/technology/facebook-big-tobacco-regulation.html">https://www.nytimes.com/2021/10/09/technology/facebook-big-tobacco-regulation.html</a></span>
</li>
<li id="cite_note-2"><span><a href="#cite_ref-2">↑</a></span> <span><a rel="nofollow" href="https://arxiv.org/abs/2009.13676">https://arxiv.org/abs/2009.13676</a></span>
</li>
<li id="cite_note-3"><span><a href="#cite_ref-3">↑</a></span> <span><a rel="nofollow" href="https://www.theguardian.com/business/ng-interactive/2019/jan/23/free-market-thinktanks-tobacco-industry">https://www.theguardian.com/business/ng-interactive/2019/jan/23/free-market-thinktanks-tobacco-industry</a></span>
</li>
<li id="cite_note-4"><span><a href="#cite_ref-4">↑</a></span> <span><a rel="nofollow" href="https://www.newstatesman.com/science-tech/big-tech/2021/07/how-google-quietly-funds-europe-s-leading-tech-policy-institutes">https://www.newstatesman.com/science-tech/big-tech/2021/07/how-google-quietly-funds-europe-s-leading-tech-policy-institutes</a></span>
</li>
<li id="cite_note-5"><span><a href="#cite_ref-5">↑</a></span> <span><a rel="nofollow" href="https://www.nytimes.com/2021/06/22/technology/amazon-apple-google-facebook-antitrust-bills.html">https://www.nytimes.com/2021/06/22/technology/amazon-apple-google-facebook-antitrust-bills.html</a></span>
</li>
<li id="cite_note-6"><span><a href="#cite_ref-6">↑</a></span> <span><a rel="nofollow" href="https://www.fastcompany.com/90424503/facebook-google-amazon-are-ramping-up-their-secretive-influence-campaigns-in-dc">https://www.fastcompany.com/90424503/facebook-google-amazon-are-ramping-up-their-secretive-influence-campaigns-in-dc</a></span>
</li>
</ol></div>
<!-- 
NewPP limit report
Cached time: 20230721193631
Cache expiry: 86400
Reduced expiry: false
Complications: []
CPU time usage: 0.034 seconds
Real time usage: 0.037 seconds
Preprocessor visited node count: 51/1000000
Post‐expand include size: 0/2097152 bytes
Template argument size: 0/2097152 bytes
Highest expansion depth: 2/40
Expensive parser function count: 0/100
Unstrip recursion depth: 0/20
Unstrip post‐expand size: 498/5000000 bytes
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%    0.000      1 -total
-->

<!-- Saved in parser cache with key btwiki_db:pcache:idhash:29-0!canonical and timestamp 20230721193631 and revision id 413. Serialized with JSON.
 -->
</div>
				
				<!-- end content -->
				
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Don’t Make Fun of Renowned Dan Brown (2013) (167 pts)]]></title>
            <link>https://onehundredpages.wordpress.com/2013/06/12/dont-make-fun-of-renowned-dan-brown/</link>
            <guid>36818501</guid>
            <pubDate>Fri, 21 Jul 2023 19:35:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://onehundredpages.wordpress.com/2013/06/12/dont-make-fun-of-renowned-dan-brown/">https://onehundredpages.wordpress.com/2013/06/12/dont-make-fun-of-renowned-dan-brown/</a>, See on <a href="https://news.ycombinator.com/item?id=36818501">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
		<main id="main" role="main">

		
			
<article id="post-945">
	
	<!-- .entry-header -->

	<div>
		<div>
<p><a href="https://onehundredpages.files.wordpress.com/2013/06/dan-brown.jpg"><img data-attachment-id="946" data-permalink="https://onehundredpages.wordpress.com/2013/06/12/dont-make-fun-of-renowned-dan-brown/dan-brown/" data-orig-file="https://onehundredpages.files.wordpress.com/2013/06/dan-brown.jpg" data-orig-size="236,363" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="dan brown" data-image-description="" data-image-caption="" data-medium-file="https://onehundredpages.files.wordpress.com/2013/06/dan-brown.jpg?w=195" data-large-file="https://onehundredpages.files.wordpress.com/2013/06/dan-brown.jpg?w=236" alt="dan brown" src="https://onehundredpages.files.wordpress.com/2013/06/dan-brown.jpg?w=768" srcset="https://onehundredpages.files.wordpress.com/2013/06/dan-brown.jpg 236w, https://onehundredpages.files.wordpress.com/2013/06/dan-brown.jpg?w=98 98w" sizes="(max-width: 236px) 100vw, 236px"></a></p>
<p>Renowned author Dan Brown woke up in his luxurious four-poster bed in his expensive $10 million house – and immediately he felt angry. Most people would have thought that the 48-year-old man had no reason to be angry. After all, the famous writer had a new book coming out. But that was the problem. A new book meant an inevitable attack on the rich novelist by the wealthy wordsmith’s fiercest foes. The critics.</p>
</div>
<p>Renowned author Dan Brown hated the critics. Ever since he had become one of the world’s top renowned authors they had made fun of him. They had mocked bestselling book&nbsp;<i>The Da Vinci Code</i>, successful novel&nbsp;<i>Digital Fortress</i>, popular tome&nbsp;<i>Deception Point</i>, money-spinning volume&nbsp;<i>Angels &amp; Demons</i>&nbsp;and chart-topping work of narrative fiction&nbsp;<i>The Lost Symbol</i>.</p>
<p>The critics said his writing was clumsy, ungrammatical, repetitive and repetitive. They said it was full of unnecessary tautology. They said his prose was swamped in a sea of mixed metaphors. For some reason they found something funny in sentences such as “His eyes went white, like a shark about to attack.”&nbsp;<i>They even say my books are packed with banal and superfluous description</i>, thought the 5ft 9in man. He particularly hated it when they said his imagery was nonsensical. It made his insect eyes flash like a rocket.</p>
<p>Renowned author Dan Brown got out of his luxurious four-poster bed in his expensive $10 million house and paced the bedroom, using the feet located at the ends of his two legs to propel him forwards. He knew he shouldn’t care what a few jealous critics thought. His new book Inferno was coming out on Tuesday, and the 480-page hardback published by Doubleday with a recommended US retail price of $29.95 was sure to be a hit. Wasn’t it?</p>
<div>
<p><i>I’ll call my agent</i>, pondered the prosperous scribe. He reached for the telephone using one of his two hands. “Hello, this is renowned author Dan Brown,” spoke renowned author Dan Brown. “I want to talk to literary agent John Unconvincingname.”</p>
<p>“Mr Unconvincingname, it’s renowned author Dan Brown,” told the voice at the other end of the line. Instantly the voice at the other end of the line was replaced by a different voice at the other end of the line. “Hello, it’s literary agent John Unconvincingname,” informed the new voice at the other end of the line.</p>
<p>“Hello agent John, it’s client Dan,” commented the pecunious scribbler. “I’m worried about new book Inferno. I think critics are going to say it’s badly written.”</p>
<p>The voice at the other end of the line gave a sigh, like a mighty oak toppling into a great river, or something else that didn’t sound like a sigh if you gave it a moment’s thought. “Who cares what the stupid critics say?” advised the literary agent. “They’re just snobs. You have millions of fans.”</p>
<p><i>That’s true</i>, mused the accomplished composer of thrillers that combined religion, high culture and conspiracy theories. His books were read by everyone from renowned politician President Obama to renowned musician Britney Spears. It was said that a copy of&nbsp;<i>The Da Vinci Code</i>&nbsp;had even found its way into the hands of renowned monarch the Queen. He was grateful for his good fortune, and gave thanks every night in his prayers to renowned deity God.</p>
<p>“Think of all the money you’ve made,” recommended the literary agent. That was true too. The thriving ink-slinger’s wealth had allowed him to indulge his passion for great art. Among his proudest purchases were a specially commissioned landscape by acclaimed painter Vincent van Gogh and a signed first edition by revered scriptwriter William Shakespeare.</p>
<p>Renowned author Dan Brown smiled, the ends of his mouth curving upwards in a physical expression of pleasure. He felt much better. If your books brought innocent delight to millions of readers, what did it matter whether you knew the difference between a transitive and an intransitive verb?</p>
<p>“Thanks, John,” he thanked. Then he put down the telephone and perambulated on foot to the desk behind which he habitually sat on a chair to write his famous books on an Apple iMac MD093B/A computer. New book Inferno, the latest in his celebrated series about fictional Harvard professor Robert Langdon, was inspired by top Italian poet Dante. It wouldn’t be the last in the lucrative sequence, either. He had all the sequels mapped out. The Mozart Acrostic. The Michelangelo Wordsearch. The Newton Sudoku.</p>
<p>The 190lb adult male human being nodded his head to indicate satisfaction and returned to his bedroom by walking there. Still asleep in the luxurious four-poster bed of the expensive $10 million house was beautiful wife Mrs Brown. Renowned author Dan Brown gazed admiringly at the pulchritudinous brunette’s blonde tresses, flowing from her head like a stream but made from hair instead of water and without any fish in. She was as majestic as the finest sculpture by Caravaggio or the most coveted portrait by Rodin.&nbsp;<i>I like the attractive woman</i>, thought the successful man.</p>
<p>Perhaps one day, inspired by beautiful wife Mrs Brown, he would move into romantic poetry, like market-leading British rhymester John Keats.<i>That would be good</i>, opined the talented person, and got back into the luxurious four-poster bed. He felt as happy as a man who has something to be happy about and is suitably happy about it.</p>
<p>Inferno by Dan Brown 470pp, Bantam Press, rrp £20</p>

</div>

			
						</div><!-- .entry-content -->

	
	<!-- .entry-footer -->
</article><!-- #post-## -->

			
<!-- #comments -->

				<!-- .navigation -->
	
		
		</main><!-- #main -->
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Slackware Linux distribution turns 30 years old (204 pts)]]></title>
            <link>https://www.theregister.com/2023/07/20/slackware_turns_30/</link>
            <guid>36818233</guid>
            <pubDate>Fri, 21 Jul 2023 19:17:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2023/07/20/slackware_turns_30/">https://www.theregister.com/2023/07/20/slackware_turns_30/</a>, See on <a href="https://news.ycombinator.com/item?id=36818233">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>This week the Slackware Linux project is celebrating its 30th anniversary. It is the oldest Linux distribution that is still in active maintenance and development.</p>
<p>Version 1.0 of Slackware was <a href="http://www.slackware.com/announce/1.0.php" rel="nofollow">announced</a> on the July 16, 1993, and project lead Patrick Volkerding, who still maintains the distribution today, celebrated with a <a href="https://www.patreon.com/posts/thirty-years-86196804" rel="nofollow">modest announcement</a>:</p>

<p>The current version, Slackware 15, <a href="https://www.theregister.com/2021/04/16/slackware_15_beta/">went into beta in 2021</a> and <a href="https://www.theregister.com/2022/02/07/slackware/">was released early last year</a>.</p>
<p>It wasn't the first distribution; that was arguably MCC Interim Linux, whose first release candidate, <a href="http://debian.mcc.ac.uk/non-debian/mcc-interim/old/0.97-p2-12/README" rel="nofollow">version 0.97</a> appeared just a couple of months after the kernel itself in 1991. Interim lacked a lot of characteristics which today are givens, such as a package manager. Several other distros <a href="https://www.linuxjournal.com/article/2755" rel="nofollow">followed</a> closely behind it, notably including SLS, the Softlanding Linux system. As this 2020 <a href="https://casadevall.pro/articles/2020/06/softlanding-linux-system-1.0.5/" rel="nofollow">write-up</a> shows, SLS was pretty basic, but it quickly inspired two offspring.</p>
<p>The <a href="https://www.theregister.com/2015/12/30/ian_murdock_debian_founder/">late Ian Murdock</a> was inspired to begin work on Debian by his dissatisfaction with SLS, as his original 1993 <a href="https://groups.google.com/g/comp.os.linux.development/c/Md3Modzg5TU/m/xty88y5OLaMJ" rel="nofollow">announcement</a> says. It took a couple of months to get that first release together, though, meaning that Debian is just very slightly younger. Its first release arrived about two months after Slackware 1.0, as <a href="https://www.theregister.com/2018/08/16/debian_at_25/">we noted for Debian's 25th anniversary</a>.</p>

    

<p>Slackware Linux began as a project to clean up and improve upon SLS, and since it's still going today, we have to say that it's succeeded in that mission. There are three variants of Slackware these days. The eponymous form remains an x86-32 system, whereas Slackware64 targets 21st century 64-bit x86 hardware. (There's also an <a href="https://arm.slackware.com/" rel="nofollow">Arm64 version</a> too, but the former PowerMac and IBM S/390 versions have been discontinued.) <em>The Reg</em> FOSS Desk put it onto one of our older machines for a test drive, and came away pleasantly surprised.</p>
<div><p><a href="https://regmedia.co.uk/2023/07/19/slack-15-boot.png" target="_blank"><img src="https://regmedia.co.uk/2023/07/19/slack-15-boot.png?x=648&amp;y=360&amp;infer_y=1" alt="Slackware64 v15 has an unwelcoming boot screen, but it's not 1996 any more. You can always just Google what to do next." title="Slackware64 v15 has an unwelcoming boot screen, but it's not 1996 any more. You can always just Google what to do next." height="360" width="648"></a></p><p>Slackware64 v15 has an unwelcoming boot screen, but it's not 1996 any more. You can always just Google what to do next</p>
</div>
<p>Way back in about 1996, emboldened by his success with <a href="https://techmonitor.ai/technology/lasermoon_touts_inexpensive_standard_linux_system_for_scientific_academic_users_unix_95_branding_in_prospect" rel="nofollow">Lasermoon Linux/FT</a> on his work PC, Slackware 3 was the first ever distro that this vulture tried to install on his own home PC: a Sunrace laptop, with external hard disk and CD-ROM drives on its built-in Adaptec SCSI interface. (Its internal IDE hard disk was occupied by OS/2 2.0, which was our personal go-to operating system of the time.) We never managed to find the correct incantation to get kernel 1.2 to load its <code>aha152x</code> driver correctly, and retired defeated.</p>
<ul>

<li><a href="https://www.theregister.com/2023/07/19/mint_212/">Mint 21.2 is desktop Linux without the faff</a></li>

<li><a href="https://www.theregister.com/2023/07/18/linux_desktop_debate/">Linux has nearly half of the desktop OS Linux market</a></li>

<li><a href="https://www.theregister.com/2023/07/17/almalinux_project_switches_focus/">AlmaLinux project climbs down from being a one-to-one RHEL clone</a></li>

<li><a href="https://www.theregister.com/2023/07/13/wayland_is_coming/">Three signs that Wayland is becoming the favored way to get a GUI on Linux</a></li>
</ul>
<p>What's surprising about Slackware today is that in some ways, it's superficially quite similar to how it was back then. There are no fripperies such as live graphical desktops here. It boots to a login prompt, and then you're expected to manually run a <code>setup</code> program, and use very 1990s DOS-style text-mode menus to tick boxes for the components that you want installed.</p>
<div><p><a href="https://regmedia.co.uk/2023/07/19/slack64-15-setup.png" target="_blank"><img src="https://regmedia.co.uk/2023/07/19/slack64-15-setup.png?x=648&amp;y=353&amp;infer_y=1" alt="The Slackware setup program doesn't look much different since the 20th century, but behind the scenes, it automates a ton of stuff away. " title="The Slackware setup program doesn't look much different since the 20th century, but behind the scenes, it automates a ton of stuff away. " height="353" width="648"></a></p><p>The Slackware setup program doesn't look much different since the 20th century, but behind the scenes, it automates a ton of stuff away</p>
</div>
<p>The flipside of this is that all of our hardware was automatically detected, and it was all remarkably easy from then on. The setup program includes a choice of graphical desktop environments, and we particularly appreciated the jokey description of Xfce as a "Cholesterol Free Desktop Environment." In fact, quite a few elements of the setup program are jokily informal – for instance, the option for individual confirmation of every package warns that installing this way will take a couple of years.</p>
<p>It didn't configure a graphical login screen by default, or even an ordinary user account, but all that was needed was to type <code>startx</code> and the desktop launched, complete with AMD Radeon graphics drivers preconfigured, and ready to connect to a wireless network. To be honest, we expected substantially more manual effort than this. It's not all a complete doddle: for example, in order to run an online update, you have to manually edit a provided list of mirrors, and uncomment one (and only one) of them.</p>

        

<p>Slackware 15 is very much <em>not</em> a lightweight distribution. Running a full update brought us perilously close to filling up our 16GB root partition, and it wasn't particularly snappy on the elderly Thinkpad W500 that we chose to test it on – although it was a bit quicker than the <a href="https://www.theregister.com/2023/07/19/mint_212/">copy of Linux Mint 21.2</a> it was dual-booting alongside. However, all the controls and config is right there, laid out for you, and if you manually prune some things, you could trim it to size quite easily.</p>
<p>It has online repositories, automatic dependency resolution, and all the bells and whistles that you'd expect from a 21st century distro – just with some of the look and feel of an original 1990s distro. It even still uses LILO by default. Running that first update, we found some worrying warnings online about building a corresponding <code>initrd</code> after you update the kernel… but all that stuff has gone away. In version 15, it's just taken care of for you, automatically.</p>

        

<p>Slackware today is in fact a modern distro, which just happens to look old fashioned due to its simple text-mode installation program, lack of a graphical desktop manager, and a few other cosmetic details. We're not sure if this is from tradition, or whether it's intentional (perhaps to scare away annoying newbies) – or, of course, it may be both. Today it's considerably easier to install than much younger distributions such as Alpine Linux or Arch Linux – or indeed than any of the BSDs, of which it's faintly reminiscent. Oh, and like BSD, it's systemd-free as well. ®</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[IMAX emulates PalmPilot software to power Oppenheimer’s 70 mm release (216 pts)]]></title>
            <link>https://arstechnica.com/gadgets/2023/07/imax-emulates-palmpilot-software-to-power-oppenheimers-70-mm-release/</link>
            <guid>36817900</guid>
            <pubDate>Fri, 21 Jul 2023 18:52:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/gadgets/2023/07/imax-emulates-palmpilot-software-to-power-oppenheimers-70-mm-release/">https://arstechnica.com/gadgets/2023/07/imax-emulates-palmpilot-software-to-power-oppenheimers-70-mm-release/</a>, See on <a href="https://news.ycombinator.com/item?id=36817900">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <h4>
      The other kind of PDA    —
</h4>
            
            <h2 itemprop="description">IMAX TikTok shows an emulated Palm PDA controlling <em>Oppenheimer's</em> 600-lb reel. </h2>
                    </div><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/07/oppenheimer-800x362.jpg" alt="Cillian Murphy in">
      <figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/07/oppenheimer-scaled.jpg" data-height="1157" data-width="2560">Enlarge</a> <span>/</span> Cillian Murphy in <em> Oppenheimer</em>.</p></figcaption>  </figure>

  




<!-- cache hit 296:single/related:d5a2ef92719af72bf29e17b49d627ab5 --><!-- empty -->
<p>It's a big week for IMAX, which has been promoting today's release of <em>Oppenheimer</em>. It's a particularly big deal for IMAX because the film is the first to get a 70 mm IMAX release since 2020's <em>Tenet</em>. So, you could understand why the company took to social media to boast of the size and magnitude of running the film, which is <a href="https://apnews.com/article/oppenheimer-christopher-nolan-0f8c1fdc4a358decee6105cac91a90ae">said</a> to be 11 miles long and 600 pounds. But in addition to the blockbuster IMAX release is something that hasn't been a showstopper in ages: a PDA.</p>
<p>And you can't discuss personal digital assistants (PDAs) without mentioning PalmPilots. The Palm computing devices were once the epitome of handheld technological organization. But Palm Computing, which endured a series of acquisitions before HP <a href="https://www.businessinsider.com/live-hps-earnings-call-2011-8">sunset the brand</a> in 2011, made other devices besides PalmPilots. One of those is the Palm m130, which is apparently IMAX projectionists' ideal controller for running 70 mm film.</p>
<p>As shown in IMAX's TikTok video below, the 70 mm print for <em>Oppenheimer</em> is so large that they had to extend their film platter. That's fascinating and all, but so is the emulated 2002 PDA apparently running things:</p>
<blockquote cite="https://www.tiktok.com/@imax/video/7255327705313430830" data-video-id="7255327705313430830">
<section><a title="@imax" href="https://www.tiktok.com/@imax?refer=embed" target="_blank" rel="noopener">@imax</a> Constantly pushing the boundaries of film . <a title="oppenheimer" href="https://www.tiktok.com/tag/oppenheimer?refer=embed" target="_blank" rel="noopener">#Oppenheimer</a> <a title="christophernolan" href="https://www.tiktok.com/tag/christophernolan?refer=embed" target="_blank" rel="noopener">#ChristopherNolan</a> <a title="imax" href="https://www.tiktok.com/tag/imax?refer=embed" target="_blank" rel="noopener">#IMAX</a> <a title="♬ original sound - IMAX" href="https://www.tiktok.com/music/original-sound-7255327683477883690?refer=embed" target="_blank" rel="noopener">♬ original sound - IMAX</a></section>
</blockquote>
<p><br>
The m130 wasn't even <a href="https://www.wired.com/2002/03/new-palm-a-tough-sell-for-biz/">top of the line</a> when it came out in 2002. It did, however, bring color (12-bit, to be exact) to Palm's M-series of handhelds. It debuted at $279 with a 2-inch, 160×160 screen and a 33 Motorola Dragonball VZ processor. But that was just the magic needed for IMAX's purposes, and so it hasn't changed a thing. The only difference is that it's using emulations in at least some cases. According to <a href="https://www.theverge.com/23801118/imax-movie-palm-pilot-oppenheimer">The Verge</a>, the TikTok video shows the PDA emulated on a 10.1-inch Windows tablet for businesses, the Winmate W10IB3S-PCH2AC-POE Panel PC. It's easy to find Palm OS emulators <a href="https://cloudpilot-emu.github.io/">online</a>, as noted by <a href="https://www.vice.com/en/article/88x5gb/imax-still-runs-on-palmpilot-operating-system">Vice's Motherboard</a>.</p>                                            
                                                        
<p>The PDA emulation controls the theater's Quick Turn Reel Units (where workers <a href="https://www.youtube.com/watch?v=_uFyp1WS1Fw">load the physical film reels</a>), which can also have integrated controllers instead.</p>
<p>Motherboard contacted IMAX about the antiquity and a company spokesperson said, "The original Quick Turn Reel Units operated on PalmPilots. In advance of the release of <em>Oppenheimer</em>, IMAX Engineering designed and manufactured an emulator that mimics the look and feel of a PalmPilot to keep it simple and familiar for IMAX film projectionists."</p>
<p>It's possible that some IMAX theaters still have physical PDAs. Ars Technica reached out to IMAX for clarification and will update this story if we hear back. As The Verge noted, a YouTuber named Yves Leibowitz, who shares video from an IMAX theater at an aquarium with 70 mm support, has physical Palm devices in his <a href="https://www.youtube.com/watch?v=_uFyp1WS1Fw">videos</a>.</p>
<figure><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/07/Untitled.jpg" data-height="1014" data-width="1215" alt="A closer look at the emulated PDA. "><img alt="A closer look at the emulated PDA. " src="https://cdn.arstechnica.net/wp-content/uploads/2023/07/Untitled-640x534.jpg" width="640" height="534" srcset="https://cdn.arstechnica.net/wp-content/uploads/2023/07/Untitled.jpg 2x"></a><figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/07/Untitled.jpg" data-height="1014" data-width="1215">Enlarge</a> <span>/</span> A closer look at the emulated PDA. </p></figcaption></figure>
<p>So what does the timeless emulator do? An IMAX rep told The Verge that it includes controls for the left and right sides of a 3D projector, which is "from the days of the 45-minute 3D documentaries, where there was a right eye print and a left eye print which both ran through the projector at the same time.” Workers can use the emulator to set which platter is ready for film or for feeding the projector film. The emulator can also tell a worker when the platters are available to run.</p>
<h2>If it ain't broke...</h2>
<p>Twenty-one-year-old emulated PDAs may not be what you'd expect to power one of the year's most publicized movie releases, but if you look at the converse speeds at which technology and business processes tend to evolve, it feels less surprising.</p>                                            
                                                        
<p>Earlier this year, we got a sneak peek at a Chuck E. Cheese that was <em>finally</em> moving its animatronics off <a href="https://arstechnica.com/information-technology/2023/01/chuck-e-cheese-still-uses-floppy-disks-in-2023-but-not-for-long/">floppy disks</a> and into the modern age of ... DVDs. The company's not alone in using dated technologies that mainstream consumers have largely forgotten. Businesses with long-standing procedures and systems often rely on technologies prominent when those systems were created. It's common for machines for things like medical equipment, aircraft, embroidery machines, and plastic molding to <a href="https://arstechnica.com/gadgets/2023/03/why-the-floppy-disk-just-wont-die/">rely on floppy disks</a>.</p>
<p>Similarly, IMAX is seemingly working with technology it's familiar with and, thus, doesn't require new or advanced training or big purchases and upgrades.</p>
<p>Meanwhile, 70 mm IMAX film releases like <em>Oppenheimer</em> don't come often, and when they do, only 30 theaters in the world can support them, <a href="https://www.cnbc.com/2023/07/19/where-to-watch-oppenheimer-in-70mm-imax-.html">CNBC</a> reported, and not necessarily all of them will (<em>Tenet's</em> 70 mm release, for example, was limited to 11 theaters due to pandemic restrictions, CNBC said). That makes any need for upgrades and overhauls less urgent.</p>
<p>“If 70mm IMAX had a resurgence then I’d expect that they’d update the [Quick Turn Reel Unit] controllers. Until then, it’s best to ride it until the wheels fall off,” an IMAX rep told The Verge.</p>
<p>For anyone still wondering what the big deal is about <a href="https://www.filmlinc.org/daily/what-is-70mm/">70 mm film</a> (besides the size), the movie's <a href="https://www.oppenheimermovie.com/tickets/formats/">website</a> says <em>Oppenheimer</em> was "shot using a combination of 5-perf 65 mm and 15 perf IMAX film." The site claims that "when presented on 70 mm IMAX, the sequences shot on 15 perf IMAX are printed full quality in their native format—the highest quality imaging format ever devised, offering 10 times the resolution of standard formats, and filling the giant IMAX screens from top to bottom."</p>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[MiniZinc (222 pts)]]></title>
            <link>https://www.minizinc.org/</link>
            <guid>36817628</guid>
            <pubDate>Fri, 21 Jul 2023 18:32:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.minizinc.org/">https://www.minizinc.org/</a>, See on <a href="https://news.ycombinator.com/item?id=36817628">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                <p>
                    MiniZinc is a <a href="https://www.minizinc.org/license.html">free and open-source</a> <b>constraint modeling language</b>.  
                </p>
                <p>
                    You can use MiniZinc to model constraint satisfaction and optimization problems in a <b>high-level</b>,
                    <b>solver-independent</b> way, taking advantage of a large
                    <a href="https://www.minizinc.org/doc-latest/en/lib.html">library of pre-defined constraints</a>.
                    Your model is then compiled into FlatZinc, a solver input language that is understood by
                    <a href="https://www.minizinc.org/software.html#flatzinc">a wide range of solvers</a>.
                </p>
                
                <p>
                    MiniZinc is developed at <a href="http://www.monash.edu/">Monash University</a> with support from <a href="https://optima.org.au/">OPTIMA</a>.

                </p><h2>Getting started</h2>
                <p>  
                  To get started with MiniZinc, <a href="https://www.minizinc.org/software.html">download the MiniZinc distribution
                  and the IDE</a> and have a look at the <a href="https://www.minizinc.org/doc-latest/en/index.html">MiniZinc Handbook</a>,
                  which contains a tutorial introduction (also available in <a href="https://www.minizinc.org/doc-latest/chi/index.html">Chinese</a>).
                </p>

                <h2>Learn MiniZinc</h2>
                <p>We have developed an extensive online course!
                    Head over to Coursera's <a href="https://www.coursera.org/learn/basic-modeling">Basic Modeling for Discrete Optimization</a>
                    and <a href="https://www.coursera.org/learn/advanced-modeling">Advanced Modeling for Discrete Optimization</a>
                    courses for an in-depth introduction to constraint modeling using MiniZinc.
                </p>
                
                <p>The book <a href="https://www.springer.com/gp/book/9783030417314"><i>Building Decision Support Systems using MiniZinc</i></a> by Mark Wallace
                    introduces readers to the principles of intelligent decision support systems (IDSS) and how to build them with MiniZinc.</p>

                <h2>Merchandise</h2>
                <p>Get your <a href="https://www.redbubble.com/people/guidodiug/works/32129494-minizinc">MiniZinc stickers, mugs, t-shirts</a> etc. (sold at cost price)!</p>

                <h2>News</h2>

                <ul>
                <li><b>2023-06-20</b> MiniZinc 2.7.6 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.7.6">change log</a>).</li>
                <li><b>2023-06-07</b> MiniZinc 2.7.5 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.7.5">change log</a>).</li>
                <li><b>2023-05-11</b> MiniZinc 2.7.4 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.7.4">change log</a>).</li>
                <li><b>2023-04-20</b> MiniZinc 2.7.3 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.7.3">change log</a>).</li>    
                <li><b>2023-04-05</b> MiniZinc 2.7.2 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.7.2">change log</a>).</li>    
                <li><b>2023-03-31</b> MiniZinc 2.7.1 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.7.1">change log</a>).</li>    
                <li><b>2023-02-23</b> MiniZinc 2.7.0 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.7.0">change log</a>).</li>
                <li><b>2023-02-13</b> First <a href="https://www.minizinc.org/challenge2023/call_for_problems.html">Call for MiniZinc problem submissions</a> has been made for the MiniZinc Challenge 2023.</li>
                <li><b>2022-08-04</b> The MiniZinc Challenge 2022 results available <a href="https://www.minizinc.org/challenge2022/results2022.html">here</a>. </li>
                <li><b>2022-06-23</b> MiniZinc 2.6.4 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.6.4">change log</a>).</li>
                <li><b>2022-05-06</b> MiniZinc 2.6.3 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.6.3">change log</a>).</li>
                <li><b>2022-03-03</b> MiniZinc 2.6.2 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.6.2">change log</a>).</li>
                <li><b>2022-03-10</b> First <a href="https://www.minizinc.org/challenge2022/call_for_problems.html">Call for MiniZinc problem submissions</a> has been made for the MiniZinc Challenge 2022.</li>
                <li><b>2022-03-03</b> MiniZinc 2.6.1 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.6.1">change log</a>).</li>
                <li><b>2022-02-22</b> MiniZinc 2.6.0 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.6.0">change log</a>).</li>
                <li><b>2021-10-29</b> The MiniZinc Challenge 2021 results available <a href="https://www.minizinc.org/challenge2021/results2021.html">here</a>. </li>
                <li><b>2021-05-07</b> First <a href="https://www.minizinc.org/challenge2021/call_for_problems.html">Call for MiniZinc problem submissions</a> has been made for the MiniZinc Challenge 2021.</li>
                <li><b>2021-03-19</b> MiniZinc 2.5.5 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.5.5">change log</a>).</li>
                <li><b>2021-03-16</b> MiniZinc 2.5.4 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.5.4">change log</a>).</li>
                <li><b>2020-11-24</b> MiniZinc 2.5.3 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.5.3">change log</a>).</li>
                <li><b>2020-11-09</b> MiniZinc 2.5.2 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.5.2">change log</a>).</li>
                <li><b>2020-10-22</b> MiniZinc 2.5.1 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.5.1">change log</a>).</li>
                <li><b>2020-10-06</b> MiniZinc 2.5.0 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.5.0">change log</a>).</li>
                <li><b>2020-05-22</b> <a href="https://www.springer.com/gp/book/9783030417314"><i>Building Decision Support Systems using MiniZinc</i></a> by Mark Wallace is now available</li>
                <li><b>2020-03-04</b> MiniZinc 2.4.3 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.4.3">change log</a>).</li>
                <li><b>2020-01-10</b> MiniZinc 2.4.2 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.4.2">change log</a>).</li>
                <li><b>2019-12-20</b> MiniZinc 2.4.1 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.4.1">change log</a>).</li>
                <li><b>2019-12-13</b> MiniZinc 2.4.0 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.4.0">change log</a>).</li>
                <li><b>2019-10-03</b> The MiniZinc Challenge 2019 results available <a href="https://www.minizinc.org/challenge2019/results2019.html">here</a>. </li>
                <li><b>2019-09-12</b> MiniZinc 2.3.2 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.3.2">change log</a>).</li>
                <li><b>2019-07-10</b> MiniZinc 2.3.1 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.3.1">change log</a>).</li>
                <li><b>2019-06-26</b> MiniZinc 2.3.0 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.3.0">change log</a>).</li>
                <li><b>2019-03-07</b> First <a href="https://www.minizinc.org/challenge2019/call_for_problems.html">Call for MiniZinc problem submissions</a> has been made for the MiniZinc Challenge 2019.</li>
                <li><b>2018-10-31</b> MiniZinc 2.2.3 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.2.3">change log</a>).</li>
                <li><b>2018-10-26</b> MiniZinc 2.2.2 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.2.2">change log</a>).</li>
                <li><b>2018-09-20</b> Amendments of the MiniZinc Challenge 2018 results had to be made due to an issue with the solution checker. More details are available <a href="https://www.minizinc.org/challenge2018/results2018.html">here</a>. Thanks to Gustav Björdal and Michael Marte for reporting.</li>
                <li><b>2018-09-06</b> MiniZinc 2.2.1 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.2.1">change log</a>).</li>
                <li><b>2018-08-28</b> The MiniZinc Challenge 2018 results available <a href="https://www.minizinc.org/challenge2018/results2018.html">here</a>. </li>
                <li><b>2018-08-24</b> MiniZinc 2.2.0, a major release with many new features has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.2.0">change log</a>).</li>
                <li><b>2018-03-08</b> 11th edition of the <a href="https://www.minizinc.org/challenge2018/challenge.html">MiniZinc Challenge</a> has been announced.</li>
                <li><b>2018-01-10</b> MiniZinc 2.1.7 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.1.7">change log</a>).</li>
                <li><a href="https://www.minizinc.org/oldnews.html">Older news items</a></li>
                </ul>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[For BSD Unix, It's Sayonara (1992) (120 pts)]]></title>
            <link>https://www.tech-insider.org/unix/research/1992/0622.html</link>
            <guid>36817482</guid>
            <pubDate>Fri, 21 Jul 2023 18:22:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tech-insider.org/unix/research/1992/0622.html">https://www.tech-insider.org/unix/research/1992/0622.html</a>, See on <a href="https://news.ycombinator.com/item?id=36817482">Hacker News</a></p>
<div id="readability-page-1" class="page">
<b>News</b><p><b>For BSD Unix, It's Sayonara </b></p>
<p>Jason Levitt and Evan Schuman<br>
Open Systems Today </p>
<p>June 22, 1992</p>
<p>Berkeley, Calif. -- The end of a major computing era will come next month 
when the final release of BSD Unix gets shipped, marking the University of 
California at Berkeley's withdrawal from the operating system business. </p>
<p>A lack of funding and the increasing sophistication of commercial Unix 
implementations have combined to halt Unix development at the university, 
meaning that 4.4BSD Unix-set to go Alpha by next month, with general 
availability by December-will be Berkeley's last OS. </p>
<p>BSD has been popular in the academic community for many reasons, mostly 
because-since 1988-it has not required a license fee and often features 
cutting-edge technology years before commercial computer vendors' versions. </p>
<p>"With any commercial version of Unix, you usually have to sign your life 
away," said Evi Nemeth, an associate professor of computer science at the 
University of Colorado at Boulder, adding that this no-license feature made BSD 
ideal for teaching students about operating systems and networking. </p>
<p>BSD Unix was responsible for much of the Unix innovation during the 1980s and 
came into being around 1978 when Berkeley graduate student Bill Joy added 
virtual memory capability to a VAX 11/780 port of Unix. The resulting system was 
named 3BSD (4BSD in 1980) and became the dominant Unix version at universities.
</p>
<p>Since that time, nearly all of the important Unix enhancements have come from 
the BSD releases of Unix. Collectively, these enhancements are often referred to 
as the Berkeley "extensions" and are now part of System V Release 4. The 
programming API for OSF/1 is based on 4.3BSD libraries and system calls. </p>
<p>Originally, BSD was funded by the government through DARPA. But that funding 
was cut off in 1988 when the vendor community started to show a strong interest 
in doing its own development. </p>
<p>Since 1988, BSD research and staffing has been supplied through vendor 
grants, mostly from Hewlett-Packard, the Open Software Foundation and Cray 
Research. </p>
<p>Kirk McKusick, the Berkeley research computer scientist who is in charge of 
the BSD project, added that NASA Ames also has been a major sponsor. </p>
<p>"It's becoming increasingly difficult to get funding from the private 
sector," he said. "With the recession, these companies are obviously looking at 
the bottom line and external research is an item that can be easily reduced."
</p>
<p>While fund raising has gotten more difficult, today's technology has forced 
the operating system to grow substantially more complicated, with the 100 
different commands from a few years ago now at 500 commands, McKusick said. </p>
<p>"The complexity has grown almost exponentially," he said, adding that his 
staff of four would need be doubled to "continue the level of quality." </p>
<p>Also, McKusick said, the university itself "is not as interested in having us 
around as they did 10 years ago" because vendors today-such as Cisco 
Systems-have packaged some of the networking technology that made his team so 
indispensable before for systems administration. </p>
<p>"We are so good at getting our stuff disseminated that we are no longer 
needed," he said. </p>
<p>Another factor contributing to the OS' demise, said Keith Bostic, fellow 
Berkeley programmer and the project's second-in-command, was the increasing 
sophistication of vendors in working with Unix. </p>
<p>In the early 1980s, Bostic said, just about the entire Unix community was 
either using a form of BSD or AT&amp;T's System V. "If you bought {Unix} from DEC, 
you were running BSD. If you bought {Unix} from Sun, you were running BSD," he 
said. "In today's climate, it is not the same as 1980." </p>
<p>Bostic said that today's Unix vendors are more sophisticated and are making 
many more changes to whatever version of Unix they are starting with. </p>
<p>BSD 4.3 "was the last version that major vendors shipped right out of the 
box. Vendors now tend to pick and choose," he said. "The vendors are basically 
going to lose a research group." </p>
<p>There are still options to secure BSD code, with one company, Berkeley 
Software Design (Falls Church, Va.), a company employing former Berkeley 
programmer Mike Karels, planning to offer a commercial version of Unix for SPARC 
systems based on the 4.4BSD code but free of AT&amp;T source licensing requirements. 
It currently offers BSD/386, a version of Unix for 386 machines based on the 
Berkeley NET2 release. </p>
<p>And there are several outfits that will distribute the code freely, often 
directly on the net. </p>
<p>The University of Colorado's Nemeth, regarded as an expert on Unix security 
and perhaps best known for having co-authored the Unix System Administration 
Handbook, said last week that she would like to have her university conduct some 
of the operating system research that Berkeley is now abandoning. </p>
<p>One of the most popular accomplishments of the BSD team, said Nemeth and 
others, was its sifting through mountains of software out in the industry, 
finding the best examples and incorporating them into a BSD version. McKusick 
said it was often a matter of convincing contributors "that they would rather 
have fame than fortune." </p>
<p>Nemeth cited a more colorful-and oft-cited-description: "It was a matter of 
their taking it in and peeing on it until it smelled like Berkeley." </p>
<p>"This is a valuable function and the community needs the service," she said, 
adding that she is trying to convince DARPA to resume funding BSD research at 
her university with it paying for three to four full-time staff, two or three 
graduate students and two or three undergraduate students. Nemeth estimated that 
she would need about $700,000. </p>
<p>But she said last week that she now is leaning toward securing interim 
funding from industry, in an attempt to demonstrate to DARPA that her people can 
do the job effectively. </p>
<p>Nemeth said that she is hesitant, though, to have vendor support made 
permanent. "I don't see having to constantly hustle for money."</p>

<p>Copyright 1992 CMP Publications, Inc. All rights reserved.</p>


</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Web Environment Integrity API (433 pts)]]></title>
            <link>https://github.com/RupertBenWiser/Web-Environment-Integrity</link>
            <guid>36817305</guid>
            <pubDate>Fri, 21 Jul 2023 18:09:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/RupertBenWiser/Web-Environment-Integrity">https://github.com/RupertBenWiser/Web-Environment-Integrity</a>, See on <a href="https://news.ycombinator.com/item?id=36817305">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-turbo-body="">
      


    <div>
      <p><a href="#start-of-content">Skip to content</a>
      <span data-view-component="true">
    <span data-view-component="true"></span>
</span></p><header role="banner" data-color-mode="light" data-light-theme="light" data-dark-theme="dark">
  

  <div>
    <div>
      <a href="https://github.com/" aria-label="Homepage" data-ga-click="(Logged out) Header, go to homepage, icon:logo-wordmark">
        
      </a>

        <div>
          <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&amp;source=header-repo" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/RupertBenWiser/Web-Environment-Integrity&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="d70e84e9f9dca6c4052317ffe225baad48a9b2d4823c9c6c4d304f38494e8473">
            Sign&nbsp;up
          </a>
        </p></div>

      
    </div>


    <div>
          <nav aria-label="Global">
            <ul>
                <li>
      
      <div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Actions&quot;,&quot;label&quot;:&quot;ref_cta:Actions;&quot;}" href="https://github.com/features/actions">
      
      <div>
        <p>Actions</p><p>
        Automate any workflow
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Packages&quot;,&quot;label&quot;:&quot;ref_cta:Packages;&quot;}" href="https://github.com/features/packages">
      
      <div>
        <p>Packages</p><p>
        Host and manage packages
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Security&quot;,&quot;label&quot;:&quot;ref_cta:Security;&quot;}" href="https://github.com/features/security">
      
      <div>
        <p>Security</p><p>
        Find and fix vulnerabilities
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Codespaces&quot;,&quot;label&quot;:&quot;ref_cta:Codespaces;&quot;}" href="https://github.com/features/codespaces">
      
      <div>
        <p>Codespaces</p><p>
        Instant dev environments
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Copilot&quot;,&quot;label&quot;:&quot;ref_cta:Copilot;&quot;}" href="https://github.com/features/copilot">
      
      <div>
        <p>Copilot</p><p>
        Write better code with AI
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Code review&quot;,&quot;label&quot;:&quot;ref_cta:Code review;&quot;}" href="https://github.com/features/code-review">
      
      <div>
        <p>Code review</p><p>
        Manage code changes
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Issues&quot;,&quot;label&quot;:&quot;ref_cta:Issues;&quot;}" href="https://github.com/features/issues">
      
      <div>
        <p>Issues</p><p>
        Plan and track work
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Discussions&quot;,&quot;label&quot;:&quot;ref_cta:Discussions;&quot;}" href="https://github.com/features/discussions">
      
      <div>
        <p>Discussions</p><p>
        Collaborate outside of code
      </p></div>

    
</a></li>

            </ul>
          </div>
          <div>
              <p><span id="product-explore-heading">Explore</span></p><ul aria-labelledby="product-explore-heading">
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to All features&quot;,&quot;label&quot;:&quot;ref_cta:All features;&quot;}" href="https://github.com/features">
      All features

    
</a></li>

                <li>
  <a target="_blank" data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Documentation&quot;,&quot;label&quot;:&quot;ref_cta:Documentation;&quot;}" href="https://docs.github.com/">
      Documentation

    
</a></li>

                <li>
  <a target="_blank" data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to GitHub Skills&quot;,&quot;label&quot;:&quot;ref_cta:GitHub Skills;&quot;}" href="https://skills.github.com/">
      GitHub Skills

    
</a></li>

                <li>
  <a target="_blank" data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Blog&quot;,&quot;label&quot;:&quot;ref_cta:Blog;&quot;}" href="https://github.blog/">
      Blog

    
</a></li>

            </ul>
          </div>
      </div>
</li>


                <li>
      
      <div>
          <div>
              <p><span id="solutions-for-heading">For</span></p><ul aria-labelledby="solutions-for-heading">
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to Enterprise&quot;,&quot;label&quot;:&quot;ref_cta:Enterprise;&quot;}" href="https://github.com/enterprise">
      Enterprise

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to Teams&quot;,&quot;label&quot;:&quot;ref_cta:Teams;&quot;}" href="https://github.com/team">
      Teams

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to Startups&quot;,&quot;label&quot;:&quot;ref_cta:Startups;&quot;}" href="https://github.com/enterprise/startups">
      Startups

    
</a></li>

                <li>
  <a target="_blank" data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to Education&quot;,&quot;label&quot;:&quot;ref_cta:Education;&quot;}" href="https://education.github.com/">
      Education

    
</a></li>

            </ul>
          </div>
          <div>
              <p><span id="solutions-by-solution-heading">By Solution</span></p><ul aria-labelledby="solutions-by-solution-heading">
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to CI/CD &amp;amp; Automation&quot;,&quot;label&quot;:&quot;ref_cta:CI/CD &amp;amp; Automation;&quot;}" href="https://github.com/solutions/ci-cd/">
      CI/CD &amp; Automation

    
</a></li>

                <li>
  <a target="_blank" data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to DevOps&quot;,&quot;label&quot;:&quot;ref_cta:DevOps;&quot;}" href="https://resources.github.com/devops/">
      DevOps

    
</a></li>

                <li>
  <a target="_blank" data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to DevSecOps&quot;,&quot;label&quot;:&quot;ref_cta:DevSecOps;&quot;}" href="https://resources.github.com/devops/fundamentals/devsecops/">
      DevSecOps

    
</a></li>

            </ul>
          </div>
          <div>
              <p><span id="solutions-resources-heading">Resources</span></p><ul aria-labelledby="solutions-resources-heading">
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to Customer Stories&quot;,&quot;label&quot;:&quot;ref_cta:Customer Stories;&quot;}" href="https://github.com/customer-stories">
      Customer Stories

    
</a></li>

                <li>
  <a target="_blank" data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to White papers, Ebooks, Webinars&quot;,&quot;label&quot;:&quot;ref_cta:White papers, Ebooks, Webinars;&quot;}" href="https://resources.github.com/">
      White papers, Ebooks, Webinars

    
</a></li>

                <li>
  <a target="_blank" data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to Partners&quot;,&quot;label&quot;:&quot;ref_cta:Partners;&quot;}" href="https://partner.github.com/">
      Partners

    
</a></li>

            </ul>
          </div>
      </div>
</li>


                <li>
      
      <div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to GitHub Sponsors&quot;,&quot;label&quot;:&quot;ref_cta:GitHub Sponsors;&quot;}" href="https://github.com/sponsors">
      
      <div>
        <p>GitHub Sponsors</p><p>
        Fund open source developers
      </p></div>

    
</a></li>

            </ul>
          </div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to The ReadME Project&quot;,&quot;label&quot;:&quot;ref_cta:The ReadME Project;&quot;}" href="https://github.com/readme">
      
      <div>
        <p>The ReadME Project</p><p>
        GitHub community articles
      </p></div>

    
</a></li>

            </ul>
          </div>
          <div>
              <p><span id="open-source-repositories-heading">Repositories</span></p><ul aria-labelledby="open-source-repositories-heading">
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to Topics&quot;,&quot;label&quot;:&quot;ref_cta:Topics;&quot;}" href="https://github.com/topics">
      Topics

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to Trending&quot;,&quot;label&quot;:&quot;ref_cta:Trending;&quot;}" href="https://github.com/trending">
      Trending

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to Collections&quot;,&quot;label&quot;:&quot;ref_cta:Collections;&quot;}" href="https://github.com/collections">
      Collections

    
</a></li>

            </ul>
          </div>
      </div>
</li>


                <li>
    <a data-analytics-event="{&quot;category&quot;:&quot;Header menu top item (logged out)&quot;,&quot;action&quot;:&quot;click to go to Pricing&quot;,&quot;label&quot;:&quot;ref_cta:Pricing;&quot;}" href="https://github.com/pricing">Pricing</a>
</li>

            </ul>
          </nav>

        <div>
                


<qbsearch-input data-scope="repo:RupertBenWiser/Web-Environment-Integrity" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="TOFqL3IsSOkP2RP7Whs-FRbAKNymOsfTq1lEcorjNQ_UqiuwYjvFpkj7Mf5KZWKttIePXlBbsmxJzfzA_D6Amg" data-max-custom-scopes="10" data-header-redesign-enabled="false" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="RupertBenWiser/Web-Environment-Integrity" data-current-org="" data-current-owner="RupertBenWiser" data-logged-in="false">
  <div data-modal-dialog-overlay="" data-action="click:qbsearch-input#searchInputContainerClicked">
  <modal-dialog data-action="close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose" data-target="qbsearch-input.searchSuggestionsDialog" role="dialog" id="search-suggestions-dialog" aria-modal="true" aria-labelledby="search-suggestions-dialog-header" data-view-component="true">
      <h2 id="search-suggestions-dialog-header">Search code, repositories, users, issues, pull requests...</h2>
    
</modal-dialog></div>
  
  <div>
    
<div data-modal-dialog-overlay="">
  <modal-dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" role="dialog" id="feedback-dialog" aria-modal="true" aria-disabled="true" aria-describedby="feedback-dialog-title feedback-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="feedback-dialog-title">
        Provide feedback
      </h2>
    </p>
    
  </div>
      <div data-view-component="true">        <!-- '"` --><!-- </textarea></xmp> --><form id="code-search-feedback-form" data-turbo="false" action="/search/feedback" accept-charset="UTF-8" method="post">
          <p>We read every piece of feedback, and take your input very seriously.</p>
          
          
          <label for="include_email">Include my email address so I can be contacted</label>
</form></div>
      
</modal-dialog></div>

    <custom-scopes data-target="qbsearch-input.customScopesManager">
    
<div data-modal-dialog-overlay="">
  <modal-dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" role="dialog" id="custom-scopes-dialog" aria-modal="true" aria-disabled="true" aria-describedby="custom-scopes-dialog-title custom-scopes-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="custom-scopes-dialog-title">
        Saved searches
      </h2>
        <h2 id="custom-scopes-dialog-description">Use saved searches to filter your results more quickly</h2>
    </p>
    
  </div>
      
      
</modal-dialog></div>
    </custom-scopes>
  </div>
</qbsearch-input><div>
            <p><a href="https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2FRupertBenWiser%2FWeb-Environment-Integrity" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/RupertBenWiser/Web-Environment-Integrity&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="01e3ed5febbe8bc7ce93175543274d99ddddc9287a0c31d4bea8d40f578b6b71" data-ga-click="(Logged out) Header, clicked Sign in, text:sign-in">
              Sign in
            </a>
          </p></div>

            <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&amp;source=header-repo&amp;source_repo=RupertBenWiser%2FWeb-Environment-Integrity" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/RupertBenWiser/Web-Environment-Integrity&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="01e3ed5febbe8bc7ce93175543274d99ddddc9287a0c31d4bea8d40f578b6b71" data-analytics-event="{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/<user-name>/<repo-name>;ref_cta:Sign up;ref_loc:header logged out&quot;}">
              Sign up
            </a>
        </p></div>
      </div>
  </div>
</header>

      
    </div>

  








    


    
    <include-fragment data-base-src="https://github.com/notifications/beta/shelf"></include-fragment>






  <div itemscope="" itemtype="http://schema.org/SoftwareSourceCode" data-commit-hovercards-enabled="" data-discussion-hovercards-enabled="" data-issue-and-pr-hovercards-enabled="">
    <main id="js-repo-pjax-container">
      
  




    






  
  <div id="repository-container-header" data-turbo-replace="">

      <div>

        <div>
      
    
    <p><span itemprop="author">
      <a rel="author" data-hovercard-type="user" data-hovercard-url="/users/RupertBenWiser/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/RupertBenWiser">
        RupertBenWiser
</a>    </span>
    <span>/</span>
    <strong itemprop="name">
      <a data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" href="https://github.com/RupertBenWiser/Web-Environment-Integrity">Web-Environment-Integrity</a>
    </strong>

    <span></span><span>Public</span>
  </p></div>

        <div id="repository-details-container" data-turbo-replace="">
            <ul>
    
      

  <li>
            <a href="https://github.com/login?return_to=%2FRupertBenWiser%2FWeb-Environment-Integrity" rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;notification subscription menu watch&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/RupertBenWiser/Web-Environment-Integrity&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="293d9a82a60f90833694d5820eee59ef0df39d68f49e83d7e5b15d78ce605170" aria-label="You must be signed in to change notification settings" data-view-component="true">    Notifications
</a>
  </li>

  <li>
          <a icon="repo-forked" id="fork-button" href="https://github.com/login?return_to=%2FRupertBenWiser%2FWeb-Environment-Integrity" rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;repo details fork button&quot;,&quot;repository_id&quot;:632520759,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/RupertBenWiser/Web-Environment-Integrity&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="5aa5809df7db030699b13deecdd19445904a135559f2af25249dddf6be869a54" data-view-component="true">    Fork
    <span id="repo-network-counter" data-pjax-replace="true" data-turbo-replace="true" title="21" data-view-component="true">21</span>
</a>
  </li>

  <li>
        <div data-view-component="true">
        <a href="https://github.com/login?return_to=%2FRupertBenWiser%2FWeb-Environment-Integrity" rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;star button&quot;,&quot;repository_id&quot;:632520759,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/RupertBenWiser/Web-Environment-Integrity&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="63d22802c5b163a4f30d19ed6eef47b4d81941c9749061a904d7b89bc133e5db" aria-label="You must be signed in to star a repository" data-view-component="true">    <span data-view-component="true">
          Star
</span>          <span id="repo-stars-counter-star" aria-label="64 users starred this repository" data-singular-suffix="user starred this repository" data-plural-suffix="users starred this repository" data-turbo-replace="true" title="64" data-view-component="true">64</span>
</a>        </div>
  </li>


    

</ul>

        </div>
      </div>

        <div id="responsive-meta-container" data-turbo-replace="">

    

    <p>
        <a href="https://github.com/RupertBenWiser/Web-Environment-Integrity/stargazers">
          
          <span>64</span>
          stars
</a>        <a href="https://github.com/RupertBenWiser/Web-Environment-Integrity/forks">
          
          <span>21</span>
          forks
</a>        <a href="https://github.com/RupertBenWiser/Web-Environment-Integrity/activity">
          
          <span>Activity</span>
</a>    </p>

      <div>
        <div data-view-component="true">
        <a href="https://github.com/login?return_to=%2FRupertBenWiser%2FWeb-Environment-Integrity" rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;star button&quot;,&quot;repository_id&quot;:632520759,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/RupertBenWiser/Web-Environment-Integrity&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="63d22802c5b163a4f30d19ed6eef47b4d81941c9749061a904d7b89bc133e5db" aria-label="You must be signed in to star a repository" data-view-component="true">    <span data-view-component="true">
          Star
</span>
</a>        </div>
        <p>
                <a href="https://github.com/login?return_to=%2FRupertBenWiser%2FWeb-Environment-Integrity" rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;notification subscription menu watch&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/RupertBenWiser/Web-Environment-Integrity&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="293d9a82a60f90833694d5820eee59ef0df39d68f49e83d7e5b15d78ce605170" aria-label="You must be signed in to change notification settings" data-view-component="true">    Notifications
</a>
        </p>
      </div>
  </div>


          <nav data-pjax="#js-repo-pjax-container" aria-label="Repository" data-view-component="true">

  <ul data-view-component="true">
      <li data-view-component="true">
  <a id="code-tab" href="https://github.com/RupertBenWiser/Web-Environment-Integrity" data-tab-item="i0code-tab" data-selected-links="repo_source repo_downloads repo_commits repo_releases repo_tags repo_branches repo_packages repo_deployments /RupertBenWiser/Web-Environment-Integrity" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-hotkey="g c" data-analytics-event="{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Code&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}" aria-current="page" data-view-component="true">
    
              
        <span data-content="Code">Code</span>
          <span id="code-repo-tab-count" data-pjax-replace="" data-turbo-replace="" title="Not available" data-view-component="true"></span>


    
</a></li>
      <li data-view-component="true">
  <a id="issues-tab" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/issues" data-tab-item="i1issues-tab" data-selected-links="repo_issues repo_labels repo_milestones /RupertBenWiser/Web-Environment-Integrity/issues" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-hotkey="g i" data-analytics-event="{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Issues&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}" data-view-component="true">
    
              
        <span data-content="Issues">Issues</span>
          <span id="issues-repo-tab-count" data-pjax-replace="" data-turbo-replace="" title="51" data-view-component="true">51</span>


    
</a></li>
      <li data-view-component="true">
  <a id="pull-requests-tab" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/pulls" data-tab-item="i2pull-requests-tab" data-selected-links="repo_pulls checks /RupertBenWiser/Web-Environment-Integrity/pulls" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-hotkey="g p" data-analytics-event="{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Pull requests&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}" data-view-component="true">
    
              
        <span data-content="Pull requests">Pull requests</span>
          <span id="pull-requests-repo-tab-count" data-pjax-replace="" data-turbo-replace="" title="2" data-view-component="true">2</span>


    
</a></li>
      <li data-view-component="true">
  <a id="actions-tab" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/actions" data-tab-item="i3actions-tab" data-selected-links="repo_actions /RupertBenWiser/Web-Environment-Integrity/actions" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-hotkey="g a" data-analytics-event="{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Actions&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}" data-view-component="true">
    
              
        <span data-content="Actions">Actions</span>
          <span id="actions-repo-tab-count" data-pjax-replace="" data-turbo-replace="" title="Not available" data-view-component="true"></span>


    
</a></li>
      <li data-view-component="true">
  <a id="projects-tab" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/projects" data-tab-item="i4projects-tab" data-selected-links="repo_projects new_repo_project repo_project /RupertBenWiser/Web-Environment-Integrity/projects" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-hotkey="g b" data-analytics-event="{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Projects&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}" data-view-component="true">
    
              
        <span data-content="Projects">Projects</span>
          


    
</a></li>
      <li data-view-component="true">
  <a id="security-tab" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/security" data-tab-item="i5security-tab" data-selected-links="security overview alerts policy token_scanning code_scanning /RupertBenWiser/Web-Environment-Integrity/security" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-hotkey="g s" data-analytics-event="{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Security&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}" data-view-component="true">
    
              
        <span data-content="Security">Security</span>
          <include-fragment src="/RupertBenWiser/Web-Environment-Integrity/security/overall-count" accept="text/fragment+html"></include-fragment>

    
</a></li>
      <li data-view-component="true">
  <a id="insights-tab" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/pulse" data-tab-item="i6insights-tab" data-selected-links="repo_graphs repo_contributors dependency_graph dependabot_updates pulse people community /RupertBenWiser/Web-Environment-Integrity/pulse" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-analytics-event="{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Insights&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}" data-view-component="true">
    
              
        <span data-content="Insights">Insights</span>
          <span id="insights-repo-tab-count" data-pjax-replace="" data-turbo-replace="" title="Not available" data-view-component="true"></span>


    
</a></li>
</ul>
    <div data-view-component="true">        <details data-view-component="true">
    <summary role="button" data-view-component="true">          <div>
            
            <p><span>More</span>
          </p></div>
</summary>
    <details-menu role="menu" data-view-component="true">          <ul>
              
              
              
              
              
              
              
          </ul>
</details-menu>
</details></div>
</nav>

  </div>

  



<turbo-frame id="repo-content-turbo-frame" target="_top" data-turbo-action="advance">
    <div id="repo-content-pjax-container">
  


  

  <include-fragment src="/RupertBenWiser/Web-Environment-Integrity/spoofed_commit_check/7998217b3d7334a71c26c52aeeadc1c6b1ba1dc4" data-test-selector="spoofed-commit-check"></include-fragment>

  <div data-view-component="true">
  <div data-view-component="true">        
        
        <div>
  
<div>
  <details id="branch-select-menu" data-hydro-click-payload="{&quot;event_type&quot;:&quot;repository.click&quot;,&quot;payload&quot;:{&quot;target&quot;:&quot;REFS_SELECTOR_MENU&quot;,&quot;repository_id&quot;:632520759,&quot;originating_url&quot;:&quot;https://github.com/RupertBenWiser/Web-Environment-Integrity&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="44d089c48373dc35e4e44d462abd09000039cc8c32fc11bab9faf0bfe1d7ba67">
    <summary data-hotkey="w" title="Switch branches or tags">
      
      <span data-menu-button="">main</span>
      <span></span>
    </summary>

    
<div>
    <header>
      <span>Switch branches/tags</span>
      
    </header>

    <input-demux data-action="tab-container-change:input-demux#storeInput tab-container-changed:input-demux#updateInput">
      <tab-container>
        

        

        <div role="tabpanel" id="ref-list-branches" data-filter-placeholder="Filter branches/tags" tabindex="">
          <ref-selector type="branch" data-targets="input-demux.sinks" data-action="
              input-entered:ref-selector#inputEntered
              tab-selected:ref-selector#tabSelected
              focus-list:ref-selector#focusFirstListMember
            " query-endpoint="/RupertBenWiser/Web-Environment-Integrity/refs" cache-key="v0:1689925634.0" current-committish="bWFpbg==" default-branch="bWFpbg==" name-with-owner="UnVwZXJ0QmVuV2lzZXIvV2ViLUVudmlyb25tZW50LUludGVncml0eQ==" prefetch-on-mouseover="">

            <template data-target="ref-selector.fetchFailedTemplate">
              <div class="SelectMenu-message" data-index="{{ index }}">Could not load branches</div>
            </template>

              <template data-target="ref-selector.noMatchTemplate">
    <div class="SelectMenu-message">Nothing to show</div>
</template>


            

              

<template data-target="ref-selector.itemTemplate">
  <a href="https://github.com/RupertBenWiser/Web-Environment-Integrity/tree/{{ urlEncodedRefName }}" class="SelectMenu-item" role="menuitemradio" rel="nofollow" aria-checked="{{ isCurrent }}" data-index="{{ index }}">
    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check SelectMenu-icon SelectMenu-icon--check">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    <span class="flex-1 css-truncate css-truncate-overflow {{ isFilteringClass }}">{{ refName }}</span>
    <span hidden="{{ isNotDefault }}" class="Label Label--secondary flex-self-start">default</span>
  </a>
</template>


              
          </ref-selector>

        </div>

        
      </tab-container>
    </input-demux>
  </div>

  </details>

</div>


<div data-modal-dialog-overlay="">
  <modal-dialog role="dialog" id="warn-tag-match-create-branch-dialog" aria-modal="true" aria-labelledby="warn-tag-match-create-branch-dialog-header" data-view-component="true">
      <header>
        <div>
          <p>
            <h2 id="warn-tag-match-create-branch-dialog-header">Name already in use</h2>
          </p>
          
        </div>
      </header>
    <div>
      
          <p>      A tag already exists with the provided branch name. Many Git commands accept both tag and branch names, so creating this branch may cause unexpected behavior. Are you sure you want to create this branch?
</p>

    </div>
      
</modal-dialog></div>



  <p>
    <a data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/branches">
          
          <strong>2</strong>
          <span>branches</span>
    </a>
    <a data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/tags">
      
        <strong>0</strong>
        <span>tags</span>
    </a>
  </p>

  

  <include-fragment src="/RupertBenWiser/Web-Environment-Integrity/overview_actions/main"></include-fragment>


    <p><span>
        
<get-repo>
    
    <details data-action="
               toggle:get-repo#onDetailsToggle
               keydown:get-repo#onDetailsKeydown">
        <summary data-hydro-click="{&quot;event_type&quot;:&quot;repository.click&quot;,&quot;payload&quot;:{&quot;repository_id&quot;:632520759,&quot;target&quot;:&quot;CLONE_OR_DOWNLOAD_BUTTON&quot;,&quot;originating_url&quot;:&quot;https://github.com/RupertBenWiser/Web-Environment-Integrity&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="2a850bb66106159d97ab9bd5e4e79b14c52c6a46a2f26d039aa174ad06cbde5f" data-view-component="true">    <span>
      <span>Code</span>
    </span>
      <span>
        
      </span>
</summary>  
      <div data-target="get-repo.modal">
    <tab-container data-view-component="true">
  <div with_panel="true" data-view-component="true">
    
    <ul role="tablist" aria-label="Choose where to access your code" data-view-component="true">
        <li role="presentation" data-view-component="true">
  </li>
        <li role="presentation" data-view-component="true">
  </li>
</ul>    
</div>    <div id="local-panel" role="tabpanel" tabindex="0" aria-labelledby="local-tab" data-view-component="true">          <ul>
              <li>
  <a href="https://docs.github.com/articles/which-remote-url-should-i-use" target="_blank" aria-label="Which remote URL should I use?">
  
</a>

<div>
  <p>
  Clone
</p></div>

<tab-container>

  

  <div role="tabpanel">
    

    <p>
        Use Git or checkout with SVN using the web URL.
    </p>
  </div>


  
</tab-container>

</li>
<li data-platforms="windows,mac">
  <a data-hydro-click="{&quot;event_type&quot;:&quot;clone_or_download.click&quot;,&quot;payload&quot;:{&quot;feature_clicked&quot;:&quot;OPEN_IN_DESKTOP&quot;,&quot;git_repository_type&quot;:&quot;REPOSITORY&quot;,&quot;repository_id&quot;:632520759,&quot;originating_url&quot;:&quot;https://github.com/RupertBenWiser/Web-Environment-Integrity&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="0e082088e719e3706dceff570cd728dcc71018e70b8c36e4cd0ce22013aec0f8" data-action="click:get-repo#showDownloadMessage" href="https://desktop.github.com/">
    
    Open with GitHub Desktop
</a></li>
<li>
  <a rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;clone_or_download.click&quot;,&quot;payload&quot;:{&quot;feature_clicked&quot;:&quot;DOWNLOAD_ZIP&quot;,&quot;git_repository_type&quot;:&quot;REPOSITORY&quot;,&quot;repository_id&quot;:632520759,&quot;originating_url&quot;:&quot;https://github.com/RupertBenWiser/Web-Environment-Integrity&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="3228739be0257e0437c387b54e0f4d4c40aeacbd38fbcf1c77cc602cca3390f7" data-ga-click="Repository, download zip, location:repo overview" data-open-app="link" data-turbo="false" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/archive/refs/heads/main.zip">
    
    Download ZIP
</a></li>

          </ul>
</div>
    
</tab-container></div>
    </details>


</get-repo>

    </span>

    <span>
        

    </span>
</p></div>




        


<div>
  <div>
    <h2>Latest commit</h2>
    <div data-issue-and-pr-hovercards-enabled="">
      
  <div>
  <p><a data-test-selector="commits-avatar-stack-avatar-link" data-hovercard-type="user" data-hovercard-url="/users/yoavweiss/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/yoavweiss">
        <img data-test-selector="commits-avatar-stack-avatar-image" src="https://avatars.githubusercontent.com/u/786187?s=48&amp;v=4" width="24" height="24" alt="@yoavweiss">
</a>      <a data-test-selector="commits-avatar-stack-avatar-link" data-hovercard-type="user" data-hovercard-url="/users/RupertBenWiser/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/RupertBenWiser">
        <img data-test-selector="commits-avatar-stack-avatar-image" src="https://avatars.githubusercontent.com/u/26461279?s=48&amp;v=4" width="24" height="24" alt="@RupertBenWiser">
</a>  </p>
</div>
  <div>
    <div>
          <p><a title="View all commits by yoavweiss" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/commits?author=yoavweiss">yoavweiss</a>
    
   and
  <a title="View all commits by RupertBenWiser" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/commits?author=RupertBenWiser">RupertBenWiser</a>
  

        <span>
          <a data-pjax="true" data-test-selector="commit-tease-commit-message" title="Create CODE_OF_CONDUCT.md" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/commit/7998217b3d7334a71c26c52aeeadc1c6b1ba1dc4">Create CODE_OF_CONDUCT.md</a>
        </span>
    </p></div>
    <div>
        <include-fragment accept="text/fragment+html" src="/RupertBenWiser/Web-Environment-Integrity/commit/7998217b3d7334a71c26c52aeeadc1c6b1ba1dc4/rollup?direction=sw"></include-fragment>
      <p><a href="https://github.com/RupertBenWiser/Web-Environment-Integrity/commit/7998217b3d7334a71c26c52aeeadc1c6b1ba1dc4" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame">
        7998217
      </a></p><a href="https://github.com/RupertBenWiser/Web-Environment-Integrity/commit/7998217b3d7334a71c26c52aeeadc1c6b1ba1dc4" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame">
        <relative-time datetime="2023-07-21T07:46:43Z">Jul 21, 2023</relative-time>
      </a>
    </div>
  </div>
  <div>
      <div>
        <p><a data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-test-selector="commit-tease-commit-message" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/commit/7998217b3d7334a71c26c52aeeadc1c6b1ba1dc4">Create CODE_OF_CONDUCT.md</a>
      </p></div>
    <p><code>7998217</code>
    </p>
  </div>
      <div>
        <h2>Git stats</h2>
        <ul>
          <li>
            <a data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/commits/main">
              
              <span>
                    <strong>22</strong>
                    <span aria-label="Commits on main">
                      commits
                    </span>
              </span>
            </a>
          </li>
        </ul>
      </div>
    </div>
  </div>
    <h2 id="files">Files</h2>
    


    <p><a data-hotkey="y" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/tree/7998217b3d7334a71c26c52aeeadc1c6b1ba1dc4">Permalink</a></p><div data-view-component="true">
  <p>
    Failed to load latest commit information.


  
</p></div>  <div role="grid" aria-labelledby="files" data-hpc="">
      <div role="row">
        <p>Type</p>
        <p>Name</p>
        <p>Latest commit message</p>
        <p>Commit time</p>
      </div>

        <div role="row">
          

          <div role="rowheader">
            <p><span><a title="This path skips through empty directories" data-turbo-frame="repo-content-turbo-frame" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/tree/main/.github/workflows"><span>.github/</span>workflows</a></span>
          </p></div>

          <div role="gridcell">
              <p><span>
                    <a data-pjax="true" title="Add github workflow to publish to gh-pages branch

This should auto process the bikeshed on push to main and publish
to the gh-pages branch.

Also updating the WebIDL to pass validation." href="https://github.com/RupertBenWiser/Web-Environment-Integrity/commit/f8448c38fd41470d828ad1b1ec691a2b424f1118">Add github workflow to publish to gh-pages branch</a>
              </span>
          </p></div>

          <p role="gridcell">
              <relative-time tense="past" datetime="2023-06-20T14:19:28Z" data-view-component="true">June 20, 2023 14:19</relative-time>
          </p>

        </div>
        <div role="row">
          

          <div role="rowheader">
            <p><span><a title="docs" data-turbo-frame="repo-content-turbo-frame" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/tree/main/docs">docs</a></span>
          </p></div>

          <div role="gridcell">
              <p><span>
                    <a data-pjax="true" title="Add hash type and DOMException" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/commit/f6bf35350c59e856deafdac65569b71a3413155b">Add hash type and DOMException</a>
              </span>
          </p></div>

          <p role="gridcell">
              <relative-time tense="past" datetime="2023-07-17T10:55:18Z" data-view-component="true">July 17, 2023 10:55</relative-time>
          </p>

        </div>
        <div role="row">
          

          <div role="rowheader">
            <p><span><a title=".gitignore" data-turbo-frame="repo-content-turbo-frame" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/blob/main/.gitignore">.gitignore</a></span>
          </p></div>

          <div role="gridcell">
              <p><span>
                    <a data-pjax="true" title="Add gitignore

Ignoring local spec files generated in the docs directory." href="https://github.com/RupertBenWiser/Web-Environment-Integrity/commit/1866c954426f2529f008362b6b7686cbff605388">Add gitignore</a>
              </span>
          </p></div>

          <p role="gridcell">
              <relative-time tense="past" datetime="2023-06-20T15:20:21Z" data-view-component="true">June 20, 2023 15:20</relative-time>
          </p>

        </div>
        <div role="row">
          

          <div role="rowheader">
            <p><span><a title="CODE_OF_CONDUCT.md" data-turbo-frame="repo-content-turbo-frame" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/blob/main/CODE_OF_CONDUCT.md">CODE_OF_CONDUCT.md</a></span>
          </p></div>

          <div role="gridcell">
              <p><span>
                    <a data-pjax="true" title="Create CODE_OF_CONDUCT.md" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/commit/7998217b3d7334a71c26c52aeeadc1c6b1ba1dc4">Create CODE_OF_CONDUCT.md</a>
              </span>
          </p></div>

          <p role="gridcell">
              <relative-time tense="past" datetime="2023-07-21T09:46:43+02:00" data-view-component="true">July 21, 2023 09:46</relative-time>
          </p>

        </div>
        <div role="row">
          

          <div role="rowheader">
            <p><span><a title="README.md" data-turbo-frame="repo-content-turbo-frame" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/blob/main/README.md">README.md</a></span>
          </p></div>

          <div role="gridcell">
              <p><span>
                    <a data-pjax="true" title="Update spec link to be github page instead" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/commit/b8a049e76e04de712993a821a7482a85e281adbc">Update spec link to be github page instead</a>
              </span>
          </p></div>

          <p role="gridcell">
              <relative-time tense="past" datetime="2023-06-21T10:00:27Z" data-view-component="true">June 21, 2023 10:00</relative-time>
          </p>

        </div>
        <div role="row">
          

          <div role="rowheader">
            <p><span><a title="explainer.md" data-turbo-frame="repo-content-turbo-frame" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/blob/main/explainer.md">explainer.md</a></span>
          </p></div>

          <div role="gridcell">
              <p><span>
                    <a data-pjax="true" title="use eTLD+1, not TLD" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/commit/c7366e82ecdba4c49aef945175ef90e8c9d6b47d">use eTLD+1, not TLD</a>
              </span>
          </p></div>

          <p role="gridcell">
              <relative-time tense="past" datetime="2023-04-27T10:01:28+01:00" data-view-component="true">April 27, 2023 10:01</relative-time>
          </p>

        </div>
    </div>




</div>

  
    
      <div id="readme" data-tagsearch-path="README.md" data-tagsearch-lang="Markdown">

        <div>
          <p>
            <h2>
              <a href="#readme" data-view-component="true">README.md</a>
            </h2>
          </p>
        </div>

          <div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">Web Environment Integrity API</h2>
<p dir="auto">This repository details the proposal to add a new API for determining the integrity
of web environments:</p>
<div dir="auto" data-snippet-clipboard-copy-content="const attestation = await navigator.getEnvironmentIntegrity(&quot;...&quot;);"><pre><span>const</span> <span>attestation</span> <span>=</span> <span>await</span> <span>navigator</span><span>.</span><span>getEnvironmentIntegrity</span><span>(</span><span>"..."</span><span>)</span><span>;</span></pre></div>
<p dir="auto">The <a href="https://github.com/RupertBenWiser/Web-Environment-Integrity/blob/main/explainer.md">explainer</a> goes gives a high level overview of the proposal.</p>
<p dir="auto">The <a href="https://rupertbenwiser.github.io/Web-Environment-Integrity/" rel="nofollow">spec</a> currently describes how this is being prototyped in Chromium.</p>
</article>
          </div>
      </div>



</div>
  <div data-pjax="" data-view-component="true">
        <div>
            <h2>About</h2>

    <p>
      No description, website, or topics provided.
    </p>


    <h3>Resources</h3>
    <p>
      <a data-analytics-event="{&quot;category&quot;:&quot;Repository Overview&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;location:sidebar;file:readme&quot;}" href="#readme">
        
        Readme
</a>    </p>

  

    <h3>Code of conduct</h3>
    <p>
      <a href="https://github.com/RupertBenWiser/Web-Environment-Integrity/blob/main/CODE_OF_CONDUCT.md" data-analytics-event="{&quot;category&quot;:&quot;Repository Overview&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;location:sidebar;file:code of conduct&quot;}">
        
        Code of conduct
      </a>
    </p>


<include-fragment src="/RupertBenWiser/Web-Environment-Integrity/hovercards/citation/sidebar_partial?tree_name=main">
</include-fragment>



<p>
  <a data-turbo-frame="repo-content-turbo-frame" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/activity" data-view-component="true">
    
    <span>Activity</span>
</a></p>

<h3>Stars</h3>
<p>
  <a href="https://github.com/RupertBenWiser/Web-Environment-Integrity/stargazers" data-view-component="true">
    
    <strong>64</strong>
    stars
</a></p>

<h3>Watchers</h3>
<p>
  <a href="https://github.com/RupertBenWiser/Web-Environment-Integrity/watchers" data-view-component="true">
    
    <strong>20</strong>
    watching
</a></p>

<h3>Forks</h3>
<p>
  <a href="https://github.com/RupertBenWiser/Web-Environment-Integrity/forks" data-view-component="true">
    
    <strong>21</strong>
    forks
</a></p>

  <div>
    <p><a href="https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2FRupertBenWiser%2FWeb-Environment-Integrity&amp;report=RupertBenWiser+%28user%29">
        Report repository
</a>  </p></div>

          </div>

        
        
            <div>
                <h2 data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame">
  <a href="https://github.com/RupertBenWiser/Web-Environment-Integrity/releases" data-view-component="true">
    Releases
</a></h2>

    <p>No releases published</p>

              </div>

        
        
            <div>
                <h2>
  <a href="https://github.com/users/RupertBenWiser/packages?repo_name=Web-Environment-Integrity" data-view-component="true">
    Packages
      
</a></h2>


      <p>
        No packages published <br>
      </p>



              </div>

        
        
            <div>
                <h2>
  <a href="https://github.com/RupertBenWiser/Web-Environment-Integrity/graphs/contributors" data-view-component="true">
    Contributors
      <span title="3" data-view-component="true">3</span>
</a></h2>


    
  <ul>
    <li>
      <a href="https://github.com/apps/github-actions">
        <img src="https://avatars.githubusercontent.com/in/15368?s=64&amp;v=4" alt="@github-actions[bot]" size="32" height="32" width="32" data-view-component="true">
      </a>
      <span data-view-component="true">
        <a href="https://github.com/apps/github-actions">
          <strong>github-actions[bot]</strong>
          
        </a>
</span>    </li>
    <li>
      <a href="https://github.com/yoavweiss" data-hovercard-type="user" data-hovercard-url="/users/yoavweiss/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self">
        <img src="https://avatars.githubusercontent.com/u/786187?s=64&amp;v=4" alt="@yoavweiss" size="32" height="32" width="32" data-view-component="true">
      </a>
      <span data-view-component="true">
        <a href="https://github.com/yoavweiss">
          <strong>yoavweiss</strong>
          <span>Yoav Weiss</span>
        </a>
</span>    </li>
    <li>
      <a href="https://github.com/bakkot" data-hovercard-type="user" data-hovercard-url="/users/bakkot/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self">
        <img src="https://avatars.githubusercontent.com/u/1653598?s=64&amp;v=4" alt="@bakkot" size="32" height="32" width="32" data-view-component="true">
      </a>
      <span data-view-component="true">
        <a href="https://github.com/bakkot">
          <strong>bakkot</strong>
          <span>Kevin Gibbons</span>
        </a>
</span>    </li>
</ul>





              </div>

        
        
              </div>
  
</div></div>

</turbo-frame>


    </main>
  </div>

          




  

    <template id="site-details-dialog">
  <details class="details-reset details-overlay details-overlay-dark lh-default color-fg-default hx_rsm" open="">
    <summary role="button" aria-label="Close dialog"></summary>
    <details-dialog class="Box Box--overlay d-flex flex-column anim-fade-in fast hx_rsm-dialog hx_rsm-modal">
      <button class="Box-btn-octicon m-0 btn-octicon position-absolute right-0 top-0" type="button" aria-label="Close dialog" data-close-dialog="">
        <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-x">
    <path d="M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z"></path>
</svg>
      </button>
      <div class="octocat-spinner my-6 js-details-dialog-spinner"></div>
    </details-dialog>
  </details>
</template>

    

    <template id="snippet-clipboard-copy-button">
  <div class="zeroclipboard-container position-absolute right-0 top-0">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn js-clipboard-copy m-2 p-0 tooltipped-no-delay" data-copy-feedback="Copied!" data-tooltip-direction="w">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon m-2">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none m-2">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div>
</template>
<template id="snippet-clipboard-copy-button-unpositioned">
  <div class="zeroclipboard-container">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn btn-invisible js-clipboard-copy m-2 p-0 tooltipped-no-delay d-flex flex-justify-center flex-items-center" data-copy-feedback="Copied!" data-tooltip-direction="w">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div>
</template>




    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[TSMC warns over deepening slump in chipmaking sector (101 pts)]]></title>
            <link>https://www.ft.com/content/f433971d-fd8e-4ed3-91e9-e25a96284ea0</link>
            <guid>36817267</guid>
            <pubDate>Fri, 21 Jul 2023 18:06:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ft.com/content/f433971d-fd8e-4ed3-91e9-e25a96284ea0">https://www.ft.com/content/f433971d-fd8e-4ed3-91e9-e25a96284ea0</a>, See on <a href="https://news.ycombinator.com/item?id=36817267">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="site-content" data-trackable="trial-barrier-grid" data-barrier="trial" data-barrier-is-sandbox="false">
			<div data-o-component="o-subs-card" data-offer-id="41218b9e-c8ae-c934-43ad-71b13fcb4465" data-offer-prominence="primary" data-offer-title="Trial" data-tracking-context="{&quot;title&quot;:&quot;Trial&quot;,&quot;brief&quot;:&quot;Try full digital access and see why over 1 million readers subscribe to the FT&quot;,&quot;offerId&quot;:&quot;41218b9e-c8ae-c934-43ad-71b13fcb4465&quot;,&quot;price&quot;:&quot;$1 for 4 weeks&quot;,&quot;prominence&quot;:&quot;primary&quot;,&quot;skuIds&quot;:[],&quot;description&quot;:&quot;For 4 weeks receive unlimited Premium digital access to the FT's trusted, award-winning business news&quot;}">
					<h3>Try unlimited access</h3>

					<p>Try full digital access and see why over 1 million readers subscribe to the FT</p><p>Only
						CHF&nbsp;1 for 4 weeks
				</p>

					

				</div>
			<p>
				<h4>Explore our subscriptions</h4>
			</p>
			<div>
					<h5>Individual</h5>
					<p>Find the plan that suits you best.</p>
					
				</div>
			<div>
					<h5>Professional</h5>
					<p>Premium access for businesses and educational institutions.</p>
					
				</div>
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: What are the best papers you read in your life? (188 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=36817231</link>
            <guid>36817231</guid>
            <pubDate>Fri, 21 Jul 2023 18:04:01 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=36817231">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="36818754"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36818754" href="https://news.ycombinator.com/vote?id=36818754&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>Claude Shannon's "A Mathematical Theory of Communication"[1] is often considered a classic. I think this is because:<p>1. It's quite readable as a narrative.</p><p>2. The maths is not pages of first principle derivations as if the reader is not familiar with the basics of algebraic substitution.</p><p>3. The diagrams and graphs are genuinely useful and remove the need for many, many thousands of words that others may have used instead of, or in addition to, the core narrative.</p><p>4. It deals with an abstract concept but roots it in concrete mathematical and physical terms. He touches on specific examples.</p><p>5. It's quite short given the breadth of subject area.</p><p>[1] <a href="https://people.math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf" rel="nofollow noreferrer">https://people.math.harvard.edu/~ctm/home/text/others/shanno...</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36819339"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36819339" href="https://news.ycombinator.com/vote?id=36819339&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>His easily-understandable yet mind-blowing ideas of hyperspheres of information (and a reliable communications channel having a definition!? What?) changed my brain permanently.<p>This is the paper I was going to cite as well.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="36819215"><td></td></tr>
            <tr id="36818482"><td></td></tr>
            <tr id="36818350"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36818350" href="https://news.ycombinator.com/vote?id=36818350&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><br><div>
                  <p><span>If you are looking for quality I suggest you look at the IPCC reports. Each word is carefully chosen, every claim backed by mountains of evidence. They're written to be read and understood by non-experts. They exist to inform decision making that will literally determine the fate of our species. As such, they may be failing at their goal, but not for a lack of effort by the authors.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36818777"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36818777" href="https://news.ycombinator.com/vote?id=36818777&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><br><div>
                  <p><span>Agreed, with one caveat. Over time governments have more and more been trying to influence the reports. It all came to a head with the last one, where a set of researchers released their draft ahead of time in protest over undue influence. They still synthesize relevant research from past years, but there are some problems now. Research published after the first draft cannot be included, so the report is somewhat outdated by the time it's released. Beautifully crafted though.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="36818726"><td></td></tr>
                  <tr id="36821453"><td></td></tr>
            <tr id="36818660"><td></td></tr>
            <tr id="36819037"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36819037" href="https://news.ycombinator.com/vote?id=36819037&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>Gillian Russell, “Epistemic Viciousness in the Martial Arts,”<p>It is about traditional martial arts masters, trapped in their echo chamber, sniffing their own farts. The whole industry gets its ass kicked by mixed martial arts. Basically street thugs versus shaolin kung fu masters.</p><p>it describes in-group bias, echo chambers, and cognitive dissonance in large groups. Very applicable in modern science, politics and so on.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="36817581"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36817581" href="https://news.ycombinator.com/vote?id=36817581&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><br><div>
                  <p><span>The Bitcoin whitepaper. It started my curiosity in the computer security industry (employed for 5 years now) and the rabbithole of trying to understand every design decision behind the cryptosystem.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36818276"><td></td></tr>
            <tr id="36818960"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36818960" href="https://news.ycombinator.com/vote?id=36818960&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><br><div>
                  <p><span>Agreed, this is a must-read, very well-written paper. Even though it turned out the world didn't really need cryptocurrencies.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36820340"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_36820340" href="https://news.ycombinator.com/vote?id=36820340&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>Agree with your assessment of cryptocurrencies in general but having seen the adoption of Bitcoin in authoritarian and inflationary regimes, the world most certainly does need access to a digital peer-to-peer currency that is censorship-resistant and virtually immune to debasement.<p>Even if you argue that Bitcoin as it has evolved has flaws, it is the best implementation we’ve come up with so far. Like democracy, it isn’t perfect but it is much better for its use case than anything else we have come up with to date.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="36820043"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36820043" href="https://news.ycombinator.com/vote?id=36820043&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><br><div>
                  <p><span>The Bitcoin whitepaper is one of my cherished reads. The other is the BitTorrent whitepaper. Both technologies changed the technical and non-technical worlds, and the fundamental protocols are clearly explained in their respective papers.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="36818851"><td></td></tr>
            <tr id="36818368"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36818368" href="https://news.ycombinator.com/vote?id=36818368&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><br><div>
                  <p><span>Not sure anybody here appreciates social science, but I will never not give a shout-out to "Decoupling Rape" by Whiteman and Cooper. Such an authentic account, while still managing to stay relevant to abstract and higher-order debates in my field. I suspect many have not read it because it is so heart-wrenching though.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36818521"><td></td></tr>
                <tr id="36818709"><td></td></tr>
                        <tr id="36818604"><td></td></tr>
            <tr id="36821359"><td></td></tr>
            <tr id="36818397"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36818397" href="https://news.ycombinator.com/vote?id=36818397&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>Like Kleobis and Biton, we won't know until I am dead.<p>However thus far, a paper that literally changed my life: "Value Dependence Graphs: Representation Without Taxation", D. Weise, R. F. Crew, M. Ernst, B. Steensgaard, POPL 1994.  (This was the proverbial butterfly flap that moved me through three countries).</p><p>There are many many other good papers and it's not a one-dimension metric so it's hard to pick out winners.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="36819045"><td></td></tr>
                <tr id="36819896"><td></td></tr>
                  <tr id="36820899"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36820899" href="https://news.ycombinator.com/vote?id=36820899&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>Probably this paper [1] is very well known among the classic HN audience, but I dare to leave this link here for the ones who missed it. It is an easy read and it just explains with plain words the backbone of the UNIX system as it was envisioned 50 years ago.<p>[1] <a href="https://dsf.berkeley.edu/cs262/unix.pdf" rel="nofollow noreferrer">https://dsf.berkeley.edu/cs262/unix.pdf</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="36819051"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36819051" href="https://news.ycombinator.com/vote?id=36819051&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>"A Security Kernel Based on the Lambda-Calculus" by Jonathan A. Rees is pretty high up there: <a href="https://dspace.mit.edu/handle/1721.1/5944" rel="nofollow noreferrer">https://dspace.mit.edu/handle/1721.1/5944</a><p>I read this a few years back as I was going down an object-capability rabbit hole and found it extremely compelling. (And also made me disappointed that most of the systems we use today do not work like this! Code execution vulnerabilities would be so much less immediately hazardous if they did.)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="36818522"><td></td></tr>
            <tr id="36819113"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36819113" href="https://news.ycombinator.com/vote?id=36819113&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>This is probably among the best I have read: <a href="https://scholars.unh.edu/cgi/viewcontent.cgi?article=1462&amp;context=dissertation" rel="nofollow noreferrer">https://scholars.unh.edu/cgi/viewcontent.cgi?article=1462&amp;co...</a><p>In a system with growing inequality where the rich benefit at the expense of the poor, this artificial redistribution can go on for some time, but once the inequality gets so bad that people revolt, then the amount of "guard labor" that needs to be performed goes up. Poverty and desperation makes people more likely to perform "guard labor" because it gives them a chance to escape poverty and avoid being targeted themselves which further feeds into authoritarian politicians gaining more power as they have no trouble finding soldiers willing to maintain the inequality. This works but only until guard labor reaches such a critical mass that half the population engages in it. Once that point is crossed, guard labor will start defecting against the current political leadership and conduct a military coup.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="36818472"><td></td></tr>
            <tr id="36819993"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36819993" href="https://news.ycombinator.com/vote?id=36819993&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>Congestion Avoidance and Control (1988) by Van Jacobson: <a href="https://ee.lbl.gov/papers/congavoid.pdf" rel="nofollow noreferrer">https://ee.lbl.gov/papers/congavoid.pdf</a><p>Often called "the paper which saved the internet" due to solving congestion collapse on the ARPANET, and inventing the fundamentals of TCP Congestion Control still used countless times every single day on all computers everywhere. It's very readable and presents complex math in easily understood graphs for non-math people.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="36820767"><td></td></tr>
            <tr id="36818724"><td></td></tr>
            <tr id="36818995"><td></td></tr>
                <tr id="36820616"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36820616" href="https://news.ycombinator.com/vote?id=36820616&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><br><div>
                  <p><span>I remember seeing “Possible Girls” cited somewhere as an example of the pointlessness of contemporary academic philosophy, but for years I couldn't find it again. A very entertaining re-read, thanks for sharing.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="36819937"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36819937" href="https://news.ycombinator.com/vote?id=36819937&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><br><div>
                  <p><span>A quantitative description of membrane current and its application to conduction and excitation in nerve
A L HODGKIN, A F HUXLEY
J Physiol. 1952 Aug;117(4):500-44.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="36818376"><td></td></tr>
                <tr id="36818908"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36818908" href="https://news.ycombinator.com/vote?id=36818908&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>Didn't think I'd come across a DTW paper here.<p>Have you seen anything worth reading in that line of literature which addresses a more practical issue of segment sizing and segment overlap on accuracy?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="36819023"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36819023" href="https://news.ycombinator.com/vote?id=36819023&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>“What is it like to be a bat” (Nagel)<p>“The Spandrels of San Marco and the Panglossian Paradigm”, (Gould et al)</p><p>“ A quantitative description of membrane current and its application to conduction and excitation in nerve” (hodgkin and huxley)</p><p>a few other that don’t come to mind right now
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="36819126"><td></td></tr>
            <tr id="36818311"><td></td></tr>
            <tr id="36819093"><td></td></tr>
                <tr id="36821415"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36821415" href="https://news.ycombinator.com/vote?id=36821415&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>There's a lot of non-Chomskian linguistics out there. Basically if you look for "linguistic typology" there's a probably at least 90% chance that Chomsky will be totally irrelevant.<p>(Some of my favourites in that area used to be Martin Haspelmath, Balthasar Bickel, Gilbert Lazard, ... - but I haven't kept myself up to date with the literature for years now)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="36819313"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36819313" href="https://news.ycombinator.com/vote?id=36819313&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>My idea of being explicit and clear changed dramatically after I was exposed to D. Harel's "Statecharts: a visual formalism for complex systems".<p>Ironically, I think the paper presents more than just the idea and examples of statecharts, rather it also _implicitly_ contains a _method_ for discovering mechanism - the long winded example of the author's digital watch, in my eyes, is a marvel.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="36819208"><td></td></tr>
            <tr id="36819111"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36819111" href="https://news.ycombinator.com/vote?id=36819111&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><br><div>
                  <p><span>Have most people read a paper? I see threads like these with some many interesting suggestion, but are they read by people outside of their general area of study or expertise? I read quite a bit of fiction, but I've never really been able to read anything much past an abstract which much understanding. I have no science background. Am I missout on something?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36820644"><td></td></tr>
            <tr id="36819246"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36819246" href="https://news.ycombinator.com/vote?id=36819246&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><br><div>
                  <p><span>Generally you need background knowledge to read papers. A quick way to gain necessary background knowledge is to read literature reviews or surveys. If you can't understand even reviews, surveys, or introductions, it is time to read textbooks.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="36818920"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36818920" href="https://news.ycombinator.com/vote?id=36818920&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>"Retinoic Acid and Arsenic Trioxide for Acute Promyelocytic Leukemia" by Lo-Coco et al. from 2013.[0]<p>This paper presents a cure for an extremely aggressive cancer using vitamin A and arsenic. Its a unique, relatively benign treatment strategy that completely avoids chemotherapy. As far as I know this is the best result in all of oncology, though the cancer it treats is very rare.</p><p>The most well known paper in oncology that is probably more interesting to a general audience is "The Hallmarks of Cancer" by Hanahan and Weinberg.[1]</p><p>[0] <a href="https://www.nejm.org/doi/full/10.1056/nejmoa1300874" rel="nofollow noreferrer">https://www.nejm.org/doi/full/10.1056/nejmoa1300874</a></p><p>[1] <a href="https://www.cell.com/cell/fulltext/S0092-8674(00)81683-9?_returnURL=https%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS0092867400816839%3Fshowall%3Dtrue" rel="nofollow noreferrer">https://www.cell.com/cell/fulltext/S0092-8674(00)81683-9?_re...</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="36819128"><td></td></tr>
            <tr id="36818962"><td></td></tr>
            <tr id="36818985"><td></td></tr>
            <tr id="36818688"><td></td></tr>
                <tr id="36818888"><td></td></tr>
                <tr id="36818987"><td></td></tr>
                        <tr id="36819024"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36819024" href="https://news.ycombinator.com/vote?id=36819024&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>I can give example of one of worst papers.<p>Original IPFS paper is one of worst papers that I had read.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36820673"><td></td></tr>
                  <tr id="36819087"><td></td></tr>
            <tr id="36819066"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36819066" href="https://news.ycombinator.com/vote?id=36819066&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><br><div>
                  <p><span>Lisanne Bainbridge, Ironies of Automation. Especially timely now when every company is bolting a LLM onto the side of their software.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="36820388"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36820388" href="https://news.ycombinator.com/vote?id=36820388&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>Not a paper, but <i>The Extravagant Universe</i> by Robert Kirschner describes decades worth of observation and data collection in astronomy, coming together with experimental discoveries from particle colliders and evolving theory in order to eventually converge upon the now-standard ΛCDM model in cosmology. Also includes an enormous background on the century worth of discoveries that eventually resulted in the type-1A supernova becoming a sufficiently reliable standard candle to measure the distance to galaxies far enough away that the redshift demonstrated accelerating expansion of the universe. So many things they needed to work out, from dust diffraction patterns to the differences in how spectrum evolves over the two weeks or so from the initial explosion event to figure out exactly when in the timeline each observation is taking place. Combine that with the logistics of telescope scheduling and the sparsity of observations when you're looking at something as large as the entire universe and your telescope can only cover so much at any one time. It gives you a tremendous appreciation for the sheer amount of work and patience that goes into this, slowly collecting evidence over decades, waiting for technology to develop before certain evidence is even possible to collect, and eventually seeing lines of evidence all point in the same direction, but only after a literal lifetime of work to get there.<p>Nothing else has ever made me appreciate how hard science really is and how little the general public understands it.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mali Government takes back .ml domain, brings down one of largest Lemmy servers (124 pts)]]></title>
            <link>https://very.bignutty.xyz/notes/9hfv05qcs5xf7irr</link>
            <guid>36817179</guid>
            <pubDate>Fri, 21 Jul 2023 18:00:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://very.bignutty.xyz/notes/9hfv05qcs5xf7irr">https://very.bignutty.xyz/notes/9hfv05qcs5xf7irr</a>, See on <a href="https://news.ycombinator.com/item?id=36817179">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="splash"><p><img id="splashIcon" src="https://very.bignutty.xyz/static-assets/splash.svg?1689984012144"><span id="splashText">Loading...</span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Death Valley Just Had the Hottest Midnight on Record (106 pts)]]></title>
            <link>https://www.msn.com/en-us/weather/topstories/death-valley-just-had-the-hottest-midnight-on-record/ar-AA1e2u4W</link>
            <guid>36817046</guid>
            <pubDate>Fri, 21 Jul 2023 17:50:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.msn.com/en-us/weather/topstories/death-valley-just-had-the-hottest-midnight-on-record/ar-AA1e2u4W">https://www.msn.com/en-us/weather/topstories/death-valley-just-had-the-hottest-midnight-on-record/ar-AA1e2u4W</a>, See on <a href="https://news.ycombinator.com/item?id=36817046">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[There’s a heatwave in the sea and scientists are worried (146 pts)]]></title>
            <link>https://www.bbc.com/future/article/20230720-theres-a-heatwave-in-the-sea-and-scientists-are-worried</link>
            <guid>36816982</guid>
            <pubDate>Fri, 21 Jul 2023 17:45:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bbc.com/future/article/20230720-theres-a-heatwave-in-the-sea-and-scientists-are-worried">https://www.bbc.com/future/article/20230720-theres-a-heatwave-in-the-sea-and-scientists-are-worried</a>, See on <a href="https://news.ycombinator.com/item?id=36816982">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="headline-futurearticle20230720-theres-a-heatwave-in-the-sea-and-scientists-are-worried"><div><p>(Image credit: </p><!-- --><p>European Union/Copernicus Sentinel-2</p><!-- --><p>)</p></div><div><picture><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0g237hm.webp" type="image/webp"><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0g237hm.jpg" type="image/jpeg"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0g237hm.webp" type="image/webp"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0g237hm.jpg" type="image/jpeg"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0g237hm.webp" type="image/webp"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0g237hm.jpg" type="image/jpeg"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0g237hm.webp" type="image/webp"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0g237hm.jpg" type="image/jpeg"><img loading="lazy" draggable="false" title="Satellite image of coral bleaching at Islamorada, Florida (Credit: European Union/Copernicus Sentinel-2)" src="https://ychef.files.bbci.co.uk/976x549/p0g237hm.jpg" alt="Satellite image of coral bleaching at Islamorada, Florida (Credit: European Union/Copernicus Sentinel-2)" id=""></picture></div></div><div><article><div><p>Could warmer ocean temperatures be a sign climate change has progressed further than we thought?</p><div><p>T</p><div><p>The month of June and the first few days of July were hotter than any in recorded history, <a href="https://public.wmo.int/en/media/news/preliminary-data-shows-hottest-week-record-unprecedented-sea-surface-temperatures-and">according to the World Meteorological Organization (WMO)</a>. Residents in the south of the US and <a href="https://www.bbc.com/news/world-europe-66242277">southern Europe</a> have been enduring sweltering temperatures, bringing <a href="https://www.bbc.co.uk/news/world-us-canada-66218321">excessive heat warnings</a>, <a href="https://www.bbc.com/news/science-environment-66237960">wildfires</a> and <a href="https://www.bbc.com/reel/video/p0fz7y12/why-extreme-heat-makes-air-quality-worse">plummeting air quality</a>. However, records are not just being broken on land – but in the water.</p>
<p>Global ocean sea surface temperatures were higher than any previous June on record, according to a <a href="https://climate.copernicus.eu/copernicus-record-north-atlantic-warmth-hottest-june-record-globally">report by the Copernicus Climate Change Service</a>, with satellite readings in the <a href="https://climate.copernicus.eu/record-breaking-north-atlantic-ocean-temperatures-contribute-extreme-marine-heatwaves">North Atlantic in particular "off the charts</a>". Last month also <a href="https://www.noaa.gov/news/earth-just-had-its-hottest-june-on-record">set a record</a> at the US National Oceanic and Atmospheric Administration (NOAA) for the biggest difference between expected and actual sea surface temperatures.</p>
<p><a href="https://www.noaa.gov/news/ongoing-marine-heat-waves-in-us-waters-explained">Water temperatures around Florida</a>, in particular, <a href="https://twitter.com/BMcNoldy/status/1678095286206382086">have been particularly warm</a>. Scientists have also been <a href="https://www.integratedecosystemassessment.noaa.gov/regions/california-current/california-current-marine-heatwave-tracker-blobtracker">tracking a large ongoing marine heatwave off the west coast of the US and Canada</a>&nbsp;since it formed in May.</p>
<p>While the heatwave has since lessened in the north-east Atlantic, according to non-profit science organisation&nbsp;<a href="https://www.mercator-ocean.eu/en/news/mercator-ocean-marine-heatwave-bulletin-for-11-july-2023">Mercator Ocean</a> International, another in the western Mediterranean now appears to be intensifying, particularly around the Strait of Gibraltar. This week, sea surface temperatures along the coasts of Southern Spain and North Africa were 2-4C (3.6-7.2F) higher than they would normally be at this time of year, with some spots 5C (9F) above the long-term average.</p>
<p>Extreme marine temperatures have also recently been observed around <a href="https://www.esa.int/ESA_Multimedia/Images/2023/06/UK_suffers_marine_heatwave">Ireland, the UK and in the Baltic Sea</a>, as well as <a href="https://www.mercator-ocean.eu/en/news/sea-surface-temperatures-record-high-2023/">areas near New Zealand and Australia</a>. More recently, scientists <a href="https://www.mercator-ocean.eu/en/news/marine-heatwaves-europe-july-18-2023/">suspect a possible heatwave</a> south of Greenland in the Labrador Sea.</p>
<p>"We are having these huge marine heatwaves in different areas of the ocean unexpectedly evolve very early in the year, very strong and over large areas," says Karina von Schuckmann, an oceanographer at Mercator Ocean.</p></div></div><div id="future/article/20230720-theres-a-heatwave-in-the-sea-and-scientists-are-worried-p0g237dg"><picture><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0g237dg.webp" type="image/webp"><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0g237dg.jpg" type="image/jpeg"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0g237dg.webp" type="image/webp"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0g237dg.jpg" type="image/jpeg"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0g237dg.webp" type="image/webp"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0g237dg.jpg" type="image/jpeg"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0g237dg.webp" type="image/webp"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0g237dg.jpg" type="image/jpeg"><img loading="lazy" draggable="false" title="The northern Atlantic Ocean and Mediterranean Sea have experienced record-breaking sea temperatures over the past few months (Credit: European Union/Copernicus)" src="https://ychef.files.bbci.co.uk/976x549/p0g237dg.jpg" alt="The northern Atlantic Ocean and Mediterranean Sea have experienced record-breaking sea temperatures over the past few months (Credit: European Union/Copernicus)" id=""></picture><div><p>The northern Atlantic Ocean and Mediterranean Sea have experienced record-breaking sea temperatures over the past few months (Credit: European Union/Copernicus)</p></div></div><div><p>Carlo Buontempo, director of the European Union's Copernicus Climate Change Service, says scientists expect big temperature variations in the Pacific Ocean associated with the <a href="https://www.bbc.com/future/article/20230525-what-will-an-el-nino-in-2023-mean-for-you">El Niño weather</a> pattern, a phase of planet-warming weather <a href="https://www.bbc.co.uk/news/science-environment-65839060">which is just beginning</a><em>, </em>although NOAA is <a href="https://www.noaa.gov/news/ongoing-marine-heat-waves-in-us-waters-explained">monitoring</a> a large heatwave in the Gulf of Alaska that has been sitting offshore since late 2022. (<em>Read more from BBC Future about <a href="https://www.bbc.com/future/article/20230525-what-will-an-el-nino-in-2023-mean-for-you">what another El Niño will mean for you</a></em>.)</p>
<p>But what we're currently seeing in the North Atlantic is "truly unprecedented", says Buontempo.</p>
<p>Scientists are still trying to unravel its full causes.</p>
<p>Short-term changes in regional atmospheric and ocean circulation patterns can provide the conditions for periods of intense heat in the sea lasting for weeks, months or even years.</p>
<p>But long-term increases in ocean temperature driven by an increase in greenhouse gas emissions are a key factor in recent heatwaves. About 90% of excess heat generated by anthropogenic climate change has been stored in the ocean, and the past two decades have seen a <a href="https://essd.copernicus.org/articles/15/1675/2023/essd-15-1675-2023.html">doubling in the rate of heat</a> accumulating in the Earth's climate system.</p>
<p><em>You might also like:</em></p>
<ul>
<li><strong><a href="https://www.bbc.com/future/article/20230706-the-simple-ways-cities-can-adapt-to-heatwaves">The simple ways cities can adapt to heatwaves</a>)</strong></li>
<li><strong><a href="https://www.bbc.com/future/article/20230718-the-fiery-row-behind-europes-mythological-heatwave-names">The fiery row behind Europe's mythological heatwave names</a></strong></li>
<li><strong><a href="https://www.bbc.com/future/article/20230630-will-texas-become-too-hot-for-humans">Will Texas become too hot for humans?</a></strong></li>
</ul>
<p>A 2021 <a href="https://www.ipcc.ch/report/ar6/wg1/chapter/chapter-9/">expert report</a> by the Intergovernmental Panel on Climate Change (IPCC) found marine heatwaves doubled in frequency between 1982 and 2016, and have become both more intense and longer since the 1980s.</p>
<p>Another potential contributing factor is the volume of aerosols in the atmosphere, which <a href="https://earthobservatory.nasa.gov/features/Aerosols">have a slight cooling effect</a> but appear to <a href="https://www.nasa.gov/feature/esnt/2022/nasa-study-finds-evidence-that-fuel-regulation-reduced-air-pollution-from-shipping">have dropped</a> as a result of a drive to clean up the shipping industry. More recently, there has been an unusual lack of dust blown from the Sahara, which also normally has <a href="https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2021JC017282">a cooling impact</a>.</p></div><div><p>The current marine heatwaves could even get worse. While experts do not think <a href="https://public.wmo.int/en/media/press-release/world-meteorological-organization-declares-onset-of-el-ni%C3%B1o-conditions">El Niño</a> itself was a driver of the North Atlantic event, <a href="https://public.wmo.int/en/media/news/preliminary-data-shows-hottest-week-record-unprecedented-sea-surface-temperatures-and">the WMO expects it</a> to add fuel to wider ocean heating.</p>
<p>Experts are concerned because marine heatwaves can affect ocean life, fisheries and weather patterns.</p>
<p>Record high temperatures along the Western Australian coast during the summer of 2010/2011 resulted in "<a href="https://www.sciencedirect.com/science/article/abs/pii/S0924796312002059?via%3Dihub">devastating" fish mortality</a>&nbsp;and destroyed kelp forests, <a href="https://link.springer.com/chapter/10.1007/978-3-030-71330-0_12">fundamentally changing the coastal ecosystem</a>. Several years later, an unprecedented marine heatwave caused by climate change and amplified by a strong El Niño caused <a href="https://elibrary.gbrmpa.gov.au/jspui/bitstream/11017/3206/1/Final-report-2016-coral-bleaching-GBR.pdf">the worst coral bleaching ever seen</a> on the Great Barrier Reef in 2016.</p>
<p>Marine heatwaves can <a href="https://www.nature.com/articles/s41598-018-24530-9">trigger mass coral bleaching events</a> and have already been increasing the <a href="https://www.nature.com/articles/s41586-018-0041-2">stress that reef ecosystems</a> are under around the world. The high termpeatures can cause the coral polyps to expel the zooxanthellae living inside their tissue, causing them to turn white and leaving them <a href="https://oceanservice.noaa.gov/facts/coral_bleach.html">more vulnerable to disease and other threats</a>.</p>
<p>In the Mediterranean Sea, exceptional temperatures over the 2015-19 period led to <a href="https://onlinelibrary.wiley.com/doi/full/10.1111/gcb.16301">repeated mass deaths</a> of key species such as corals and seaweed. <a href="https://www.annualreviews.org/doi/abs/10.1146/annurev-marine-032122-121437">One recent study</a> described marine heatwaves such as these as "pervasive stressors to marine ecosystems globally".</p>
<p>Marine heatwaves are also making it easier for <a href="https://www.iucn.org/resources/issues-briefs/invasive-alien-species-and-climate-change">invasive species</a> to thrive. Japanese kelp, for example, <a href="https://www.frontiersin.org/articles/10.3389/fmars.2019.00084/full">proliferated in New Zealand</a> when a marine heatwave in 2017-2018 in the Tasman Sea killed off <a href="https://www.frontiersin.org/articles/10.3389/fmars.2019.00084/full">native southern bull kelp</a> in the area.</p>
<p>Dan Smale, a marine ecologist at the UK's Marine Biological Association and a member of the <a href="http://www.marineheatwaves.org/">Marine Heatwaves International Working Group</a>, says "short, sharp shocks" do not give species time to redistribute and <a href="https://www.nature.com/articles/s41558-019-0412-1">those at the limit of temperatures their bodies can cope with are particularly at risk</a>. But even around the UK coastline, which is not considered to be an extreme environment and where scientists expect ecosystems to gradually change, a marine heatwave could end up being lethal if it continues through the summer.&nbsp;</p>
<p>However, there is still a lot to learn about the impact of marine heatwaves compared with those on land because monitoring is more difficult and there is a lack of long-term records, says Smale. "The data we get from satellites since the early 1980s has been amazing… but the problem is trying to then go deeper," he says.</p></div><div id="future/article/20230720-theres-a-heatwave-in-the-sea-and-scientists-are-worried-p0g237j6"><picture><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0g237j6.webp" type="image/webp"><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0g237j6.jpg" type="image/jpeg"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0g237j6.webp" type="image/webp"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0g237j6.jpg" type="image/jpeg"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0g237j6.webp" type="image/webp"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0g237j6.jpg" type="image/jpeg"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0g237j6.webp" type="image/webp"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0g237j6.jpg" type="image/jpeg"><img loading="lazy" draggable="false" title="High water temperatures can destroy vital marine habitats such as kelp forests, which offer sanctuary and provide food for many fish species (Credit: Getty Images)" src="https://ychef.files.bbci.co.uk/976x549/p0g237j6.jpg" alt="High water temperatures can destroy vital marine habitats such as kelp forests, which offer sanctuary and provide food for many fish species (Credit: Getty Images)" id=""></picture><div><p>High water temperatures can destroy vital marine habitats such as kelp forests, which offer sanctuary and provide food for many fish species (Credit: Getty Images)</p></div></div><div><p>A significant drop in phytoplankton <a href="https://www.mercator-ocean.eu/en/news/record-high-sea-surface-temperatures-north-atlantic-drop-in-phytoplankton-el-nino-costal-el-nino/">has already been seen</a> in the western North Atlantic, which Mercator Ocean attributes to the recent heatwave. This spring bloom is crucial because it <a href="https://www.mccip.org.uk/sites/default/files/2021-07/15_plankton_2020.pdf">provides most of the energy</a> needed to sustain the region's marine food chain and makes a substantial contribution to global ocean CO2 uptake.</p>
<p>The economics of regional fisheries could be affected too. A 2012 heatwave over the north-west Atlantic led marine species that favour warm water to move northwards and migrate earlier, <a href="https://tos.org/oceanography/article/fisheries-management-in-a-changing-climate-lessonsfrom-the-2012-ocean-heat-">changing when and how much</a> seafood could be caught.</p>
<p>The North Atlantic is also a key driver of extreme weather. High sea surface temperatures <a href="https://www.nasa.gov/audience/forstudents/k-4/stories/nasa-knows/what-are-hurricanes-k4.html">can fuel hurricanes</a>, although whether the developing El Niño will exacerbate or <a href="https://doi.org/10.1175/JCLI-D-13-00687.1">dampen this effect</a> over the next year remains to be seen. Further inland, the warmth of the North Atlantic is the most important factor behind the alternating cycle of drought and heavy rain in <a href="https://earthobservatory.nasa.gov/images/88670/atlantic-multi-decadal-oscillation-and-drought-in-africa">central Africa</a>.</p>
<p>More broadly, experts say the persistence of recent marine heatwaves is a worrying sign about how climate change is unfolding, alongside <a href="https://www.bbc.co.uk/news/world-europe-66197368">heatwaves on land</a>, unusual <a href="https://www.researchgate.net/publication/371731505_Water_ice_society_and_ecosystems_in_the_Hindu_Kush_Himalaya_An_outlook">melting of snow cover in the Himalayas</a> and a <a href="https://www.bbc.com/news/science-environment-64649596">loss of sea ice</a>. Von Schuckmann notes that, even if humans stopped pumping CO2 into the air tomorrow, the oceans would continue to warm up for many years yet. "I am concerned as a climate scientist that we are further than we thought we are."</p>
<p>--</p>
<p><em>Join one million Future fans by liking us on </em><a href="https://www.facebook.com/BBCFuture/"><strong><em>Facebook</em></strong></a><em>, or follow us on </em><a href="https://twitter.com/BBC_Future"><strong><em>Twitter</em></strong></a><em> or </em><a href="https://www.instagram.com/bbcfuture_official/"><strong><em>Instagram</em></strong></a><em>.</em></p>
<p><em>If you liked this story, </em><a href="https://cloud.email.bbc.com/SignUp10_08"><strong><em>sign up for the weekly bbc.com features newsletter</em></strong></a><em>, called "The Essential List" – a handpicked selection of stories from BBC </em><a href="https://www.bbc.com/future/"><strong><em>Future</em></strong></a><em>, </em><a href="https://www.bbc.com/culture/"><strong><em>Culture</em></strong></a><em>, </em><a href="https://www.bbc.com/worklife/"><strong><em>Worklife</em></strong></a><em>, </em><a href="https://www.bbc.com/travel/"><strong><em>Travel</em></strong></a> <em>and </em><a href="https://www.bbc.com/reel"><strong><em>Reel</em></strong></a><em> delivered to your inbox every Friday.</em></p></div></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA['Mystery company' buys land worth $800M near Travis AFB, raising concerns (110 pts)]]></title>
            <link>https://abc7news.com/travis-afb-air-force-base-flannery-associates-llc-john-garamendi/13527836/</link>
            <guid>36816387</guid>
            <pubDate>Fri, 21 Jul 2023 17:00:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://abc7news.com/travis-afb-air-force-base-flannery-associates-llc-john-garamendi/13527836/">https://abc7news.com/travis-afb-air-force-base-flannery-associates-llc-john-garamendi/13527836/</a>, See on <a href="https://news.ycombinator.com/item?id=36816387">Hacker News</a></p>
<div id="readability-page-1" class="page"><article data-testid="prism-article-body"><p><span>FAIRFIELD, Calif. (KGO) -- </span>The United States Air Force is investigating a company that's purchased $800 million of land near Travis Air Force Base, one of the most critical military bases in the U.S. But after eight months of investigation, government officials have been unable to identify who's behind it nor rule out any threat to national security.</p><p>"We're very, very concerned about this," said Rep. John Garamendi (D-CA08). "It's so extensive and so secret and it's impossible to get any information about what's happening here."</p><p>Congressman Garamendi raised the alarm to the U.S. Air Force -- prompting a federal investigation.</p><p><b>MORE: <a data-testid="prism-linkbase" href="https://abc7news.com/chinese-surveillance-balloon-antony-blinken-spy-operation-photos/12788242/">Chinese surveillance balloon part of massive program over 5 continents: Blinken</a></b></p><p><b>Stephanie Sierra:</b> "In your briefings on the matter, do you have any reason to believe the purchase of this land is for spying?"</p><p><b>Rep. Garamendi:</b> "I have every reason in the world to believe that this land is adjacent to a critical national security platform Travis Air Force Base. Therefore -- an area where spy operations or any other nefarious activity could take place...that could detrimentally impact the ability of Travis Air Force Base to operate in a moment of national emergency."</p><p>Public records show the company "Flannery Associates LLC" began purchasing land around the military base in 2018. The controversy was first reported by the <a data-testid="prism-linkbase" rel="nofollow" href="https://www.wsj.com/articles/investors-bought-nearly-1-billion-in-land-near-a-california-air-force-base-officials-want-to-know-who-exactly-they-are-fd868e38" target="_blank">Wall Street Journal</a>. Investigators say those acquisitions ramped up in 2023.</p><p>"Now literally three sides of that base are totally controlled by the Flannery group," Rep. Garamendi said.</p><p>Yet no one - including local, state, and federal officials -- can seem to track down who's behind the group.</p><p>"Who are these people?" Garamendi said. "Where did they get the money where they could pay five to ten times the normal value that others would pay for this farmland?"</p><p>Even after eight months of investigation, Garamendi says federal authorities are still struggling to get those answers.</p><p><b>MORE: <a data-testid="prism-linkbase" href="https://abc7news.com/jonathan-and-diana-toebbe-spy-couple-nuclear-submarine-navy-engineer/12435396/">Navy engineer, wife sentenced after trying to sell US nuclear submarines secrets</a></b></p><p>"To this day we don't know where these people are coming from," Garamendi said.</p><p><a data-testid="prism-linkbase" href="https://abc7news.com/about/newsteam/stephanie-sierra/">I-Team reporter Stephanie Sierra</a> asked Garamendi if there is any reason to believe China is tied to this group.</p><p>"I have reason to be concerned," he responded.</p><p>Last year 300 acres of farmland were purchased near Minot Air Force Base in North Dakota. Garamendi called it a '"spy base."</p><p>"That base is where we launch our airplanes to figure out what's going on across the world," he said. "A company in China was acquiring land around that base and wanted to build a 400-foot silo that could look directly into the base... and we were like 'whoa, whoa, whoa, what's going on there?'"</p><p>Garamendi says the attorney representing Flannery Associates indicated the firm is made up of a group of families, 97 percent of whom are allegedly American, looking to diversify their portfolio from equities to real assets - including agricultural land.</p><p>But the congressman is skeptical.</p><p>"We have heard scheme after scheme that makes no sense at all," Rep. Garamendi said. "We're going to build a deep water port. Really? Around Travis Air Force Base? Which is 10 miles from the Bay. No, you're not... We're going to farm... well at that price you're going to lose a lot of money farming. Well, we're going to build a city... No, you're not going to build a city...so none of the reasons why the land is being acquired make any sense at all."</p><p><b>MORE: <a data-testid="prism-linkbase" href="https://abc7news.com/homes-near-travis-air-force-base-affordable-housing-solano-county-houses-in-fairfield-georgetown-project/9016432/">Why 300 homes next to Travis AFB have been sitting empty for a decade</a></b></p><p>The attorney representing Flannery Associates sent a letter to the U.S. Dept. of Agriculture, one of several agencies investigating the matter, issuing a formal response.</p><p><i>"No foreign person or group holds any significant interest or substantial control over Flannery, either now or at the time of any land purchase made by Flannery,"</i> the letter said.</p><p>The company added they don't comment on its investments.</p><p><b>Sierra:</b> "What do you think is happening?"</p><p><b>Rep. Garamendi:</b> "I don't know, it doesn't make any sense... It's the secrecy... Why are you doing this in secret? If you're not a nefarious operation, why are you keeping it secret?"</p><p>According to Garamendi, Flannery Associates has also acquired land around the interstate electrical grid system stemming from the Columbia River into Central California - including land that houses wind turbines that provide significant power into Northern California.</p><p>In the meantime, Garamendi says the company continues to negatively impact the farming community in Solano County. He says at least 10 landowners are being sued by Flannery, accused of being engaged in an illegal scheme to prevent the company from buying their land.</p><p><b>Take a look at more <a data-testid="prism-linkbase" href="https://abc7news.com/iteam/">stories and videos by the ABC7 News I-Team.</a></b> </p><div data-testid="prism-inline-image"><figure data-testid="prism-figure"><a data-testid="prism-linkbase" href="https://abc7news.com/abc-news-live-local-watch/11513295/"><img alt="Now Streaming 24/7 Click Here" data-testid="prism-image" draggable="false" src="https://cdn.abcotvs.com/dip/images/11518842_247-NOWSTREAMING_1280x720.png"></a><figcaption></figcaption></figure></div><p> <i>If you're on the ABC7 News app, <a data-testid="prism-linkbase" href="https://abc7news.com/abc-news-live-local-watch/11513295/">click here to watch live</a></i></p></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Diablo (226 pts)]]></title>
            <link>https://www.filfre.net/2023/07/diablo/</link>
            <guid>36815781</guid>
            <pubDate>Fri, 21 Jul 2023 16:25:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.filfre.net/2023/07/diablo/">https://www.filfre.net/2023/07/diablo/</a>, See on <a href="https://news.ycombinator.com/item?id=36815781">Hacker News</a></p>
Couldn't get https://www.filfre.net/2023/07/diablo/: Error: Request failed with status code 404]]></description>
        </item>
        <item>
            <title><![CDATA[‘World of Warcraft’ players trick AI-scraping website into publishing nonsense (324 pts)]]></title>
            <link>https://www.forbes.com/sites/paultassi/2023/07/21/world-of-warcraft-players-trick-ai-scraping-games-website-into-publishing-nonsense/</link>
            <guid>36815744</guid>
            <pubDate>Fri, 21 Jul 2023 16:22:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.forbes.com/sites/paultassi/2023/07/21/world-of-warcraft-players-trick-ai-scraping-games-website-into-publishing-nonsense/">https://www.forbes.com/sites/paultassi/2023/07/21/world-of-warcraft-players-trick-ai-scraping-games-website-into-publishing-nonsense/</a>, See on <a href="https://news.ycombinator.com/item?id=36815744">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><figure role="presentation"><figcaption><fbs-accordion><p>The story</p></fbs-accordion><small>Zleague, I mean reddit</small></figcaption></figure>
<p>As someone who writes about video games for a living, I am deeply annoyed/terrified about the prospect of AI-run websites not necessarily replacing me, but doing things like at the very least, crowding me out of Google, given that Google does not seem to care whatsoever whether content is AI-generated or not.</p>


<p>That’s why it’s refreshing to see a little bit of justice dished out in a very funny way from a gaming community. The <em>World of Warcraft</em> subreddit recently realized that a website, zleague.gg (I am not linking to it), which runs a blog attached to some of sort of gaming app which is its main business, has been scraping reddit threads, feeding them through an AI and summarizing them with “key takeaways” and regurgitated paragraphs that all follow the same format. It’s gross, and yet it generates an article long enough with enough keywords to show up on Google.</p>

<p>Well, the redditors got annoyed and decided to mess with the bots. On r/WoW, they made <a href="https://www.reddit.com/r/wow/comments/154umm2/im_so_excited_they_finally_introduced_glorbo/" target="_blank" title="https://www.reddit.com/r/wow/comments/154umm2/im_so_excited_they_finally_introduced_glorbo/" rel="nofollow noopener noreferrer" data-ga-track="ExternalLink:https://www.reddit.com/r/wow/comments/154umm2/im_so_excited_they_finally_introduced_glorbo/" aria-label="a lengthy thread discussing the arrival of Glorbo in the game">a lengthy thread discussing the arrival of Glorbo in the game</a>, a new feature that, as you may be able to guess from the name, is not real.</p>


<blockquote>
 “I have to say, since they started hinting at it in Hearthstone in 1994, it was obvious that they would introduce Glorbo to World of Warcraft sooner or later. I feel like Dragonflight has been win after win so far, like when they brought back Chen Stormstout as the end boss of the new Karazhan? Absolutely amazing!”
</blockquote>
<p>And it…worked. Zleague auto-published a post titled “World of Warcraft Players Excited For Glorbo’s Introduction. Here’s are the “key takeaways”:</p>


<ul>
 <li>“Players express excitement for Glorbo’s arrival and its potential impact on the game.”</li>
 <li>“Some players have reservations about the mandatory item Klikclac and its effect on casual players.”</li>
 <li>“Rumors of Stormsong Valley becoming the new location for the Halfhill Market and farming sim mini-game generate enthusiasm.”</li>
 <li>“Appreciation for previous game changes, such as the inclusion of Klaxxi as a playable race.”</li>
</ul>


<p>That is… all essentially nonsense. The article was left online for a while but has finally been taken down (<a href="https://archive.ph/4mOWr#selection-1103.139-1103.245" target="_blank" title="https://archive.ph/4mOWr#selection-1103.139-1103.245" rel="nofollow noopener noreferrer" data-ga-track="ExternalLink:https://archive.ph/4mOWr#selection-1103.139-1103.245" aria-label="here’s a mirror, it’s hilarious">here’s a mirror, it’s hilarious</a>). All the authors listed as having bylines on the site are fake. It appears this entire thing is run with close to zero oversight.</p>

<p>It’s a weird situation because the site is not “stealing” in the traditional sense, directly plagiarizing without credit. It is citing reddit threads and their authors and even embedding the reddit post a lot of the time. But while getting story ideas from reddit and expanding on them is one thing, given that these are often the biggest communities for individual games on the internet, it’s a different matter to simply auto-feed reddit threads into an AI and have them spit this out. But again, there’s nothing to stop this. These subreddits can’t <em>only</em> fill themselves with joke articles to screw up a site like this, even if this one specific example is good for a laugh.</p>


<p>The only way this will ever be stopped is if Google steps in and dramatically deranks or bans AI-based sites like this, as begging for Google traffic crumbs is the only reason these sites exist in the first place. But since Google has its own very obvious vested interest in AI, I am not holding my breath.</p>
<p>Anyway, get hyped for Glorbo, I hear it’s the best change since the quest to depose Quackion, the Aspect of Ducks.</p>
<p><strong><em>Follow me </em></strong><a href="https://twitter.com/PaulTassi" target="_blank" title="https://twitter.com/PaulTassi" rel="nofollow noopener noreferrer" data-ga-track="ExternalLink:https://twitter.com/PaulTassi" aria-label="on Twitter"><strong data-ga-track="ExternalLink:https://twitter.com/PaulTassi"><em data-ga-track="ExternalLink:https://twitter.com/PaulTassi">on Twitter</em></strong></a><strong><em>, </em></strong><a href="https://www.threads.net/@paul.tassi" target="_blank" title="https://www.threads.net/@paul.tassi" rel="nofollow noopener noreferrer" data-ga-track="ExternalLink:https://www.threads.net/@paul.tassi" aria-label="Threads"><strong data-ga-track="ExternalLink:https://www.threads.net/@paul.tassi"><em data-ga-track="ExternalLink:https://www.threads.net/@paul.tassi">Threads</em></strong></a><strong><em>, </em></strong><a href="https://www.youtube.com/channel/UCg6K8i6OGobyZNoPIsCW9uQ?sub_confirmation=1" target="_blank" title="https://www.youtube.com/channel/UCg6K8i6OGobyZNoPIsCW9uQ?sub_confirmation=1" rel="nofollow noopener noreferrer" data-ga-track="ExternalLink:https://www.youtube.com/channel/UCg6K8i6OGobyZNoPIsCW9uQ?sub_confirmation=1" aria-label="YouTube"><strong data-ga-track="ExternalLink:https://www.youtube.com/channel/UCg6K8i6OGobyZNoPIsCW9uQ?sub_confirmation=1"><em data-ga-track="ExternalLink:https://www.youtube.com/channel/UCg6K8i6OGobyZNoPIsCW9uQ?sub_confirmation=1">YouTube</em></strong></a><a href="https://www.youtube.com/channel/UCg6K8i6OGobyZNoPIsCW9uQ" target="_blank" title="https://www.youtube.com/channel/UCg6K8i6OGobyZNoPIsCW9uQ?sub_confirmation=1" rel="nofollow noopener noreferrer" data-ga-track="ExternalLink:https://www.youtube.com/channel/UCg6K8i6OGobyZNoPIsCW9uQ" aria-label=","><strong data-ga-track="ExternalLink:https://www.youtube.com/channel/UCg6K8i6OGobyZNoPIsCW9uQ"><em data-ga-track="ExternalLink:https://www.youtube.com/channel/UCg6K8i6OGobyZNoPIsCW9uQ">,</em></strong></a> <strong><em>and </em></strong><a href="https://www.instagram.com/paul.tassi/?hl=en" target="_blank" title="https://www.instagram.com/paul.tassi/?hl=en" rel="nofollow noopener noreferrer" data-ga-track="ExternalLink:https://www.instagram.com/paul.tassi/?hl=en" aria-label="Instagram"><strong data-ga-track="ExternalLink:https://www.instagram.com/paul.tassi/?hl=en"><em data-ga-track="ExternalLink:https://www.instagram.com/paul.tassi/?hl=en">Instagram</em></strong></a><strong><em>. Subscribe to my free weekly content round-up newsletter, </em></strong><a href="https://paultassi.substack.com/welcome" target="_blank" title="https://paultassi.substack.com/welcome" rel="nofollow noopener noreferrer" data-ga-track="ExternalLink:https://paultassi.substack.com/welcome" aria-label="God Rolls"><strong data-ga-track="ExternalLink:https://paultassi.substack.com/welcome"><em data-ga-track="ExternalLink:https://paultassi.substack.com/welcome">God Rolls</em></strong></a><strong><em>.</em></strong></p>
<p><strong><em>Pick up my sci-fi novels the </em></strong><a href="https://www.amazon.com/gp/product/B08G1MRFTM?ref_=dbs_dp_rwt_sb_tkin&amp;binding=kindle_edition" target="_blank" title="https://www.amazon.com/gp/product/B08G1MRFTM?ref_=dbs_dp_rwt_sb_tkin&amp;binding=kindle_edition" rel="nofollow noopener noreferrer" data-ga-track="ExternalLink:https://www.amazon.com/gp/product/B08G1MRFTM?ref_=dbs_dp_rwt_sb_tkin&amp;binding=kindle_edition" aria-label="Herokiller series"><strong data-ga-track="ExternalLink:https://www.amazon.com/gp/product/B08G1MRFTM?ref_=dbs_dp_rwt_sb_tkin&amp;binding=kindle_edition"><em data-ga-track="ExternalLink:https://www.amazon.com/gp/product/B08G1MRFTM?ref_=dbs_dp_rwt_sb_tkin&amp;binding=kindle_edition">Herokiller series</em></strong></a> <strong><em>and </em></strong><a href="https://www.amazon.com/dp/B08KYDGG73?binding=paperback&amp;ref=dbs_dp_rwt_sb_pc_tpbk" target="_blank" title="https://www.amazon.com/dp/B08KYDGG73?binding=paperback&amp;ref=dbs_dp_rwt_sb_pc_tpbk" rel="nofollow noopener noreferrer" data-ga-track="ExternalLink:https://www.amazon.com/dp/B08KYDGG73?binding=paperback&amp;ref=dbs_dp_rwt_sb_pc_tpbk" aria-label="The Earthborn Trilogy"><strong data-ga-track="ExternalLink:https://www.amazon.com/dp/B08KYDGG73?binding=paperback&amp;ref=dbs_dp_rwt_sb_pc_tpbk"><em data-ga-track="ExternalLink:https://www.amazon.com/dp/B08KYDGG73?binding=paperback&amp;ref=dbs_dp_rwt_sb_pc_tpbk">The Earthborn Trilogy</em></strong></a>.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[RFC 9420 a.k.a. Messaging Layer Security (164 pts)]]></title>
            <link>https://blog.phnx.im/rfc-9420-mls/</link>
            <guid>36815705</guid>
            <pubDate>Fri, 21 Jul 2023 16:19:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.phnx.im/rfc-9420-mls/">https://blog.phnx.im/rfc-9420-mls/</a>, See on <a href="https://news.ycombinator.com/item?id=36815705">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <p>Today, the Messaging Layer Security (MLS) protocol has been published as <a href="https://datatracker.ietf.org/doc/html/rfc9420?ref=blog.phnx.im">RFC 9420</a>, a standards track document by the Internet Engineering Task Force (IETF). MLS is the first standardized and fully specified end-to-end encryption protocol. The specification is freely accessible, and its security has been analyzed in a series of academic publications.</p><p>Our team has been involved in the design and development of the MLS protocol since the very beginning. Over the course of five years, along with others from the MLS IETF working group, we have iterated to combine modern academic proposals with real-life requirements from the industry. The protocol has already proven its aptitude in large-scale deployments with major companies like Cisco and RingCentral having already integrated an early version of MLS into their products, serving millions of users.</p><p>This blog post gives a high-level overview of MLS, its practical applications, and why it matters.</p><h2 id="the-early-days-and-the-standardization-process">The early days and the standardization process</h2><p>Prior to MLS, a comprehensive specification of a protocol for end-to-end encryption informed by industry-wide input did not exist.</p><p>Protocols like the <a href="https://otr.cypherpunks.ca/?ref=blog.phnx.im">Off-the-Record protocol</a>, the <a href="https://wickr.com/wickrs-messaging-protocol/?ref=blog.phnx.im">Wickr protocol</a>, and the <a href="https://www.signal.org/docs/?ref=blog.phnx.im">Signal protocol</a> paved the way with modern security properties and asynchronous messaging capabilities.</p><p>The Signal protocol introduced the asynchronous mode of operation the Off-the-Record protocol was lacking and has made end-to-end encryption available to mobile messaging. It has since become the reference for practical and high-quality end-to-end encryption. However, a <a href="https://github.com/SilentCircle/libzina?ref=blog.phnx.im">few</a> <a href="https://github.com/wireapp/proteus?ref=blog.phnx.im">derivatives</a> <a href="https://gitlab.matrix.org/matrix-org/olm?ref=blog.phnx.im">emerged</a> due to the lack of both a full specification and permissively licensed implementations. These derivatives have seen different levels of analysis and every provider has had to maintain their own libraries.</p><p>Generally, existing protocols were typically focused on end-to-end encryption between two peers. Using them to protect group chats with many peers proved difficult and either meant compromising on security properties or accepting high computational and bandwidth costs.</p><p><a href="https://www.mozilla.org/?ref=blog.phnx.im">Various</a> <a href="http://cisco.com/?ref=blog.phnx.im">stakeholders</a> <a href="http://facebook.com/">from</a> <a href="http://google.com/?ref=blog.phnx.im">the</a> <a href="http://wire.com/?ref=blog.phnx.im">industry</a> <a href="https://www.ox.ac.uk/?ref=blog.phnx.im">and</a> <a href="http://inria.fr/?ref=blog.phnx.im">academia</a> identified these gaps and started initial talks for an open standard for asynchronous group messaging with modern security properties solving an entire range of issues. In March 2018, these “<a href="https://datatracker.ietf.org/meeting/101/materials/minutes-101-mls-00?ref=blog.phnx.im">Birds of a Feather” finally flocked together</a> and the MLS working group was subsequently established.</p><p>During the protocol design process, the working group followed an iterative approach that involved multiple rounds of review, feedback, and refinement. Regular members of the working group, as well as other interested individuals, carefully reviewed the Internet-Drafts, providing feedback, suggesting changes, and engaging in technical discussions. Numerous cryptographic experts from academia and industry analyzed MLS and the different security guarantees it aims to provide, sharing their findings in <a href="https://datatracker.ietf.org/doc/html/draft-ietf-mls-architecture-10?ref=blog.phnx.im#name-cryptographic-analysis-of-t">several academic publications</a>. This was particularly beneficial to mitigate security issues before deploying it in production environments.</p><h2 id="how-is-mls-different-from-existing-protocols">How is MLS different from existing protocols?</h2><p>Compared to existing protocols such as the Off-the-Record and the Signal protocol, MLS offers improvements in multiple ways.</p><h2 id="efficiency-do-more-with-less">Efficiency: Do more with less</h2><p>Secure messaging protocols in use today were designed as one-to-one protocols, with group messaging functionality built directly from one-to-one channels between all group members. This leaves the sender of a message to encrypt and upload a message for each other group member individually, leading to a complexity of O(n), where n is the number of members in a group. In contrast, MLS typically has costs of O(log n) for the same scenario, making it well-suited even for large groups.</p><p>Constructions such as <a href="https://www.whatsapp.com/security/WhatsApp-Security-Whitepaper.pdf?ref=blog.phnx.im">Sender Keys</a> improve the efficiency of the approach of one-to-one protocols, however, their security guarantees do not reach those of the base protocol. In particular, achieving good <em>Post-Compromise Security</em> guarantees is prohibitively expensive with Sender Keys. In other words, removing users from a group chat or ensuring a compromised device has no long-term negative impact incurs high bandwidth and computation costs for all members of the group. To recover from a compromise of a single member of the group, all other members have to broadcast an update of their key material. This leads to an overall cost of computation and bandwidth of O(n^2) for a group size of n and requires all group members to come online at least once. In contrast, MLS has an update operation with complexity of O(log n) &nbsp;that requires only the compromised member to be online for the group to recover from the compromise.</p><p>MLS achieves its low complexity through the use of a binary tree. This means that the number of required operations and the payload size do not increase linearly with the group size but rather only logarithmically after a short warm-up period. Example: In a group with 1000 members, the number of required operations to calculate new group keys would only be 10 as opposed to 1000 with existing protocols. With an assumed base payload size of 100 B per key negotiation, the total payload size would only be 1 KB instead of 100 KB.</p><figure><img src="https://blog.phnx.im/content/images/2023/07/MLS-performance-projection-1.png" alt="" loading="lazy" width="2000" height="1600" srcset="https://blog.phnx.im/content/images/size/w600/2023/07/MLS-performance-projection-1.png 600w, https://blog.phnx.im/content/images/size/w1000/2023/07/MLS-performance-projection-1.png 1000w, https://blog.phnx.im/content/images/size/w1600/2023/07/MLS-performance-projection-1.png 1600w, https://blog.phnx.im/content/images/size/w2400/2023/07/MLS-performance-projection-1.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Performance projection: Number of operations required to calculate new group keys with MLS (blue) versus existing group messaging protocols (red).</figcaption></figure><h2 id="a-new-security-notion-group-integrity">A new security notion: Group Integrity</h2><p>As existing protocols don’t have a notion of groups, messaging apps either manage group membership on the server side in plain text or combine the end-to-end encryption protocol with an additional group management protocol such as <a href="https://eprint.iacr.org/2019/1416.pdf?ref=blog.phnx.im">Signal’s Private Group System</a>.</p><p>In MLS, all group members cryptographically agree on the current state of the group, including who is a part of it. As a consequence, a group member can only decrypt messages from other group members if the sender and the receiver generally agree on the group state and specifically on who is in the group. In other words, it becomes impossible for a third party to add a member to a group without all existing members of the group being aware of it.</p><h2 id="synchronizing-data-in-a-distributed-system-a-hard-problem-becomes-easier">Synchronizing data in a distributed system: A hard problem becomes easier</h2><p>Distributing and synchronizing data across multiple clients can be a daunting task. Aside from confidentiality, MLS also addresses the issue of synchronizing data between members of a group. The corresponding mechanism is directly derived from the group integrity property. Instead of only agreeing on a member list, members of a group can agree on arbitrary data. MLS relies on a component called Delivery Service that ensures an in-order delivery of MLS messages. This ordering then dictates how clients move incrementally from one group state to the next. </p><p>With that, an MLS group can become a distribution channel for whatever data needs to be synchronized between different entities by guaranteeing cryptographical agreement on previous extension messages. In other words, this simply means that members of a group can be sure all other members saw the same messages previously.</p><h2 id="extensible-tune-it-for-your-needs">Extensible: Tune it for your needs</h2><p>MLS is also extensible, which means that the protocol can be modified, or additional data can be added to the state of a group. The latter can be used, for example, to attach data such as a group name or an image to the group state.</p><p>The protocol has a negotiation mechanism that ensures that extensions are only used if they are supported by all members of a group. Group members also agree on which extensions are mandatory in a group.</p><p>Since MLS is fundamentally also a group key negotiation protocol, additional cryptographic key material can be exported by all members of a group. This mechanism – called Exporter – can be used to derive encryption keys. For example, participants of audio/video calls or conferences can use MLS to generate encryption keys for end-to-end encryption of the media streams.</p><h2 id="future-proof-version-and-cipher-suite-agility">Future-proof: Version and cipher suite agility</h2><p>In contrast to many existing end-to-end encryption protocols, MLS allows members to signal which versions of MLS and which MLS cipher suites they support. In the future, this lets applications safely transition to a newer version of MLS or gradually roll out support for new cipher suites without confusion between individual clients. An example of such a transition could be that a secure messaging application rolls out MLS and later wants to transition to a post-quantum secure cipher suite.</p><h2 id="the-next-steps">The next steps</h2><p>Now that the standard is established, we focus more on making end-to-end encryption ubiquitous. We believe that accessibility to the technology is paramount, and we want to complement the specification with a general-purpose implementation published under a permissive license: <a href="https://openmls.tech/?ref=blog.phnx.im">OpenMLS</a>. Along with our partners at <a href="https://cryspen.com/?ref=blog.phnx.im">Cryspen</a>, we have evolved OpenMLS over the years into a software library that can be used in various projects. OpenMLS is licensed under the <a href="https://opensource.org/license/mit/?ref=blog.phnx.im">MIT license</a> to minimize friction and make it broadly accessible.</p><h2 id="additional-resources">Additional resources</h2><ul><li>See the full specification: <a href="https://datatracker.ietf.org/doc/html/rfc9420?ref=blog.phnx.im">RFC 9420</a></li><li>Don’t want to read anymore? Listen to the <a href="https://scw.quest/2023/04/22/mls/?ref=blog.phnx.im">Security Cryptography Whatever Podcast episode about MLS</a></li><li>Tired of listening? Watch the <a href="https://www.youtube.com/watch?v=zrjmpyc8YrE&amp;ref=blog.phnx.im">Black Hat talk on MLS: Towards a New Era of Secure Group Messaging</a></li></ul><hr><p>Our team has been active in the secure messaging field for over a decade and co-authored the MLS protocol specification. If you are interested in using MLS in general or our MLS implementation (<a href="https://openmls.tech/?ref=blog.phnx.im">OpenMLS</a>) in particular in your application, do not hesitate to <a href="mailto:hello@phnx.im">contact us</a> and let us know how we can help. We offer consulting services around MLS and messaging architecture as well as development services related to OpenMLS.</p>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[In the LLM space, "open source" is being used to mean "downloadable weights" (344 pts)]]></title>
            <link>https://www.alessiofanelli.com/blog/llama2-isnt-open-source</link>
            <guid>36815255</guid>
            <pubDate>Fri, 21 Jul 2023 15:49:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.alessiofanelli.com/blog/llama2-isnt-open-source">https://www.alessiofanelli.com/blog/llama2-isnt-open-source</a>, See on <a href="https://news.ycombinator.com/item?id=36815255">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2>LLaMA2 isn't "Open Source" - and why it doesn't matter<br><span>Posted on <!-- -->7/20/2023</span></h2><p>Almost a decade ago I started an open source company, and I’ve since been involved in the OSS community as a founder, contributor, speaker, and investor. The internet wouldn’t be what it is today if it wasn’t for the amazing open source projects that power most of the digital infrastructure of our world, so it’s a topic that has always been close to my heart.</p><p>When LLaMA2 came out, many of the folks I respect in the community were upset about misusing the term “open source” when referring to the model.</p><p><img src="https://www.alessiofanelli.com/images/yann.png" alt="Yann" parentname="p"></p><p>While it’s mostly open, there are caveats such as you can’t use the model commercially if you had more than 700M MAUs as of the release date, and you also cannot use the model output to train another large language model. These types of restrictions don’t play well with the open source ethos. But while I agree that LLaMA2 cannot be called open source in the traditional meaning of the word, I also think that it doesn’t matter. The term “open source” needs to evolve (once again) in the world of AI models.</p><h2>From Free to Open</h2><p>I wrote a long history of the free software and open source movement <a href="https://www.alessiofanelli.com/blog/history-of-open-source-licensing" parentname="p">here</a>, so I won’t bore you with the details again. What you need to know is that since the 1976 “Open Letter to Hobbyists”, there’s always been tension between the commercial interests of software companies and the curiosity of hackers who wanted to circumvent its restriction. The “free software” movement started in the 70s in the MIT AI lab with Richard Stallman and eventually the GNU project in 1983. The GPL “copyleft” license was created, and projects like Red Hat, MySQL, Git, and Ubuntu adopted it.</p><p>The term “open source” came to be in 1998 thanks to MIT’s Christine Peterson; at the “Freeware Summit”, the term “free software” was officially deprecated in favor of “open source software”. As time went by, the “free” and “open source” software communities diverged as they had different ideas of what free and open meant. Free software, as specified by the Free Software Foundation, is only a subset of open source software and uses very permissive licenses such as GPL and Apache.</p><p>In the last decade, there was another bifurcation, this time created by the tension between commercial open source companies and the cloud hyperscalers. Elastic and MongoDB transitioned their open source projects to the “Server-Side Public License” (SSPL) which allows developers to use the product commercially, as long as what they are offering isn’t a hosted version of the product. The goal was to block AWS from re-hosting their products as cloud services and profiting from them. The SSPL also infringes on the OSS ideals and is not recognized by the OSI as an open source license. Yet, the majority of developers still say that MongoDB is open source. More and more the term "open source" is losing its freedom connotations and turning almost synonymous with "source available" in developers' minds.</p><h2>From Source to Weights</h2><p>With the rise of open models like Dolly, MPT, LLaMA, etc., we are seeing a similar bifurcation in the community. For most AI engineers, “open source” today means “downloadable weights”, nothing more. Heather Meeker has proposed a definition for <a href="https://github.com/Open-Weights/Definition" parentname="p">“open weights”</a>, but there’s still no community consensus. The question is whether or not open weights are enough for a model to be called open source; a software analogy would be a project releasing its binaries without the source code to re-build it from scratch.</p><p>For a model to be truly open source and retrainable from scratch, the creators would need to share all their training code, pre-training dataset, fine-tuning preferences, RLHF examples, etc. The problem is the cost of these training runs: even if someone were to release everything, it’s cost-prohibitive to train models from scratch for most developers and companies, so having access to the final weights is preferred anyway.</p><p><img src="https://www.alessiofanelli.com/images/open-models.png" alt="Open Models" parentname="p"></p><p>In the LLMs space, the term "open source" is used interchangeably to define a wide range of openness levels:</p><ul><li parentname="ul"><strong parentname="li">Open models:</strong> these are models like RedPajama and MPT-7B, they have open weights available for commercial use (under Apache 2.0 license), but can also be re-trained from scratch since the dataset is open source. You can find a guide on how to train your own RedPajama model <a href="https://github.com/Lightning-AI/lit-llama/blob/main/howto/train_redpajama.md" parentname="li">here</a>.</li><li parentname="ul"><strong parentname="li">Open weights:</strong> StableLM is an open model trained by StabilityAI. While the weights are available and are licensed under Apache 2.0, the dataset used to train isn’t available to the public. From their README: “StableLM-Base-Alpha is pre-trained on a new experimental dataset built atop The Pile and is threes times larger at approximately 1.5T tokens.”</li><li parentname="ul"><strong parentname="li">Restricted weights:</strong> this is LLaMA2. The pre-training dataset is also unavailable, and while the weights are supposed to be open for commercial use, they have specific limitations that we mentioned above.</li><li parentname="ul"><strong parentname="li">Contaminated weights:</strong> models like Dolly 1.0 and LLaMA1 are part of this category. The weights are released openly, but the dataset used to train them doesn’t allow for commercial use, making it technically open but practically unusable.</li></ul><p>For the foreseeable future, open source and open weights will be used interchangeably, and I think that’s okay. The important thing is that more and more of this work is done as openly as possible. It’s okay to be disappointed with the LLaMA2 license, but Meta just packaged ~$2M worth of FLOPS into a Github repo, and I think that will be a net positive for the progress of this space.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[By 2028 there must be fast chargers every 60 km on the EU’s key motorways (120 pts)]]></title>
            <link>https://www.fleeteurope.com/en/new-energies/europe/article/fast-chargers-every-60-km-key-eu-motorways?a=FJA05&amp;t%5B0%5D=Charging&amp;curl=1</link>
            <guid>36814754</guid>
            <pubDate>Fri, 21 Jul 2023 15:11:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.fleeteurope.com/en/new-energies/europe/article/fast-chargers-every-60-km-key-eu-motorways?a=FJA05&#x26;t%5B0%5D=Charging&#x26;curl=1">https://www.fleeteurope.com/en/new-energies/europe/article/fast-chargers-every-60-km-key-eu-motorways?a=FJA05&#x26;t%5B0%5D=Charging&#x26;curl=1</a>, See on <a href="https://news.ycombinator.com/item?id=36814754">Hacker News</a></p>
<div id="readability-page-1" class="page"><div property="content:encoded">
        <p>By 2028, there must be fast chargers at least every 60 km on the EU’s key motorways. That is the most eyecatching measure of several approved by the European Parliament to improve EV charging. Others focus on increasing charging speed and making it easier to pay for charging. All are part of the EU’s ‘Fit for 55’ package, aimed at reducing emissions by 55% by 2030.</p>  <p>The maximum-distance rule for fast chargers applies to TEN-T (<em>pictured)</em>, an EU-wide network of key traffic corridors with a total length of 24,500 km. The mandated fast chargers along these roads all must have an output of at least 400 kW by 2026, and 600 kW by 2028.&nbsp;</p>  <p>Specifically for electric buses and trucks, the European Parliament mandated charging points at most 120 km apart by 2028 on at least half the network, each heavy-duty charger with an output of 1,400 to 2,800 kW, depending on the road.&nbsp;</p>  <p>In addition to these minimum requirements for the density and speed of the fast charger network, the European parliament also wants more simplicity and transparency when it comes to payment:</p>  <ul> 	<li>All customers must be able to pay with cards or contactless devices (at present, some charging networks require subscriptions or app downloads).&nbsp;</li> 	<li>All prices must be clearly displayed to the customers: in euros per kW or per minute/session. &nbsp;</li> 	<li>By 2027, the EU will develop a public database of charging stations, with information on pricing, availability, and waiting times.&nbsp;</li> </ul>  <p>Not forgetting other sustainable alternatives to ICEs, the European Parliament mandated at least one hydrogen refueling station every 200 km along TEN-T motorways by 2031.&nbsp;</p>  <p>The new alternative fuel infrastructure rules have already been approved by the European Parliament, but will only enter into force six months after approval by the European Council.&nbsp;</p>  <p>In a separate move, the UK has formulated similar proposals to improve the availability and reliability of public EV charging. For example: the British government wants to reduce the share of charging stations out of service from 8% in 2019 to 1% (as is already the case in the Netherlands), and will require that charging station operators provide a 24-hour helpline for their customers.</p>  <p><em>Image: Directorate-General for Mobility and Transport, European Commission – CC BY-SA 4.0</em></p> 
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[India’s ban on rice exports raises fear of global food price rises (121 pts)]]></title>
            <link>https://www.theguardian.com/business/2023/jul/21/india-ban-on-rice-exports-raises-fear-of-global-food-price-rises</link>
            <guid>36814627</guid>
            <pubDate>Fri, 21 Jul 2023 15:01:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/business/2023/jul/21/india-ban-on-rice-exports-raises-fear-of-global-food-price-rises">https://www.theguardian.com/business/2023/jul/21/india-ban-on-rice-exports-raises-fear-of-global-food-price-rises</a>, See on <a href="https://news.ycombinator.com/item?id=36814627">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>India has banned non-basmati white rice exports to curb domestic inflation, raising fears of further increases in global food prices just days after <a href="https://www.theguardian.com/business/2023/jul/20/rising-grain-prices-russia-pullout-black-sea-deal-food-crisis-fears" data-link-name="in body link">wheat and corn prices were sent climbing</a> by Russia’s termination of a key grain deal.</p><p>The immediate ban, introduced after heavy rains hit domestic crops, follows the failure of a 20% duty on international exports introduced in September to curb foreign demand, which has soared after extreme climate conditions hit production in countries.</p><p>India is the world’s largest rice exporter, accounting for more than 40% of global shipments. While the ban does not apply to higher-grade basmati rice – India’s best-known variety – non-basmati white rice accounts for about 25% of exports.</p><p>International sales of Indian rice soared by 35% in the year to June, contributing to a 3% rise in domestic prices over the past month alone. People in India are paying 11.5% more for rice than a year ago, according to its ministry of consumer affairs, food and public distribution.</p><p>The Indian government said the ban, <a href="https://www.pib.gov.in/PressReleasePage.aspx?PRID=1941139" data-link-name="in body link">introduced on Thursday evening</a>, would “ensure adequate availability of non-basmati white rice in the Indian market” and lead to lowering of prices for domestic consumers.</p><p>Soaring food inflation has put pressure on the BJP government in Delhi in the run-up to national elections next year and state-level elections in the months to come.</p><p>India’s move sent the price of rice from several Asian countries higher on global markets, while traders said they expected prices to rise substantially in the coming days.</p><p>The price of India’s 5% broken parboiled variety had already been hovering this week close to a five-year peak between $421 and $428 (£328-334) a metric tonne, and on Friday it stood at about $424.50.</p><p>Thailand and Vietnam, respectively the world’s second and third-largest rice exporters, have also experienced rises in the prices of their 5% broken rice in recent times. Even before the announcement, Vietnam’s rice was trading at its highest level since 2011, and has since moved higher, while Thailand’s variety jumped to levels not seen for more than two years.</p><p>Global food supplies have been hit by Russia’s war in Ukraine, which has driven up commodity and grain prices around the world.</p><p>Russia’s decision earlier in the week to <a href="https://www.theguardian.com/world/2023/jul/17/russia-decision-not-extend-black-sea-grain-deal-final" data-link-name="in body link">pull out of the year-old UN-brokered Black Sea grain initiative</a>, which guaranteed safe passage for vessels carrying cereals, has prompted fresh concerns about a global food crisis.</p><figure data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.NewsletterSignupBlockElement"><a data-ignore="global-link-styling" href="#EmailSignup-skip-link-11">skip past newsletter promotion</a><p id="EmailSignup-skip-link-11" tabindex="0" aria-label="after newsletter promotion" role="note">after newsletter promotion</p></figure><p>Before the move by the Kremlin, the grain price had fallen by more a third (35%), while the wheat price had declined 14% since January and corn prices had been trading 20% lower.</p><p>The US has pledged a further $250m (£194m) to create and expand other routes for Ukrainian grain to leave the country, but Russia’s defence ministry has in effect said any ship leaving a Ukrainian port <a href="https://www.theguardian.com/world/2023/jul/20/what-was-the-black-sea-grain-deal-and-why-did-it-collapse" data-link-name="in body link">will be a legitimate military target</a>, raising fears that supplies could face further disruption.</p><p>The interruption of Ukrainian grain exports comes as important growing regions in the US have been hit by unusually hot weather and lack of rain, leading to a reduction in forecasts for the US wheat harvest, with stocks estimated to fall to a 16-year low.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How Turborepo is porting from Go to Rust (110 pts)]]></title>
            <link>https://vercel.com/blog/how-turborepo-is-porting-from-go-to-rust?nxtPslug=how-turborepo-is-porting-from-go-to-rust</link>
            <guid>36814019</guid>
            <pubDate>Fri, 21 Jul 2023 14:14:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://vercel.com/blog/how-turborepo-is-porting-from-go-to-rust?nxtPslug=how-turborepo-is-porting-from-go-to-rust">https://vercel.com/blog/how-turborepo-is-porting-from-go-to-rust?nxtPslug=how-turborepo-is-porting-from-go-to-rust</a>, See on <a href="https://news.ycombinator.com/item?id=36814019">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>In <a href="https://vercel.com/blog/turborepo-migration-go-rust" rel="noopener" target="_blank">a previous blog post</a>, we talked about <b>why</b> we are porting <a href="https://turbo.build/?utm_source=turbo&amp;utm_medium=blog&amp;utm_campaign=turborepo_porting" rel="noopener" target="_blank">Turborepo, the high-performance build system for JavaScript and TypeScript</a>, from Go to Rust. Now, let's talk about <b>how</b>.</p><p>Today, our porting effort is in full swing, moving more and more code to Rust. But when we were starting out, we had to make sure that porting was feasible for us to accomplish. A migration from one language to another is no small task and there's a lot of research to do up front to ensure that the end goal is attainable. </p><p>Here’s how we started the process, validated our current porting strategy, and made the call to port Turborepo to Rust.</p><h2><span id="port-vs.-full-rewrite"></span><a href="#port-vs.-full-rewrite">Port vs. full rewrite</a><span><svg data-testid="geist-icon" fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24" style="color:currentColor;width:0.75em;height:0.75em"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71"></path></svg></span></h2><p>When we were planning our migration, we briefly considered a full, ground-up rewrite. But, talking the idea through, we realized it wouldn't fit our goals as well as an incremental port would.</p><h3><span id="what-is-an-incremental-port"></span><a href="#what-is-an-incremental-port">What is an incremental port?</a><span><svg data-testid="geist-icon" fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24" style="color:currentColor;width:0.75em;height:0.75em"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71"></path></svg></span></h3><p>Incremental porting moves code piece-by-piece, running new and old code together at the same time. The goal for the chunk of code being moved is to keep the behavior exactly the same as before it was ported.</p><div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="Frame 427319409.png" loading="lazy" width="2880" height="2113" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2FmZz2Um8re3MZXucpSZdoV%2F890469916054b2f0b364c13514e825b4%2FFrame_427319409.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2FmZz2Um8re3MZXucpSZdoV%2F890469916054b2f0b364c13514e825b4%2FFrame_427319409.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="Frame 427319402 (1).png" loading="lazy" width="1920" height="1409" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2Fc17bo47fBBuBQztRawrOp%2Fe16450ef2ef20d0c7bf2dc709912fc1b%2FFrame_427319402__1_.png&amp;w=1920&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x, https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2Fc17bo47fBBuBQztRawrOp%2Fe16450ef2ef20d0c7bf2dc709912fc1b%2FFrame_427319402__1_.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2Fc17bo47fBBuBQztRawrOp%2Fe16450ef2ef20d0c7bf2dc709912fc1b%2FFrame_427319402__1_.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div></div><div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="iPhone 8 Plus - 6.png" loading="lazy" width="621" height="628" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F6ZaHYc4GhEIKfRL2c1erpl%2F59f7fc484abd77f372331aec1f583d84%2FiPhone_8_Plus_-_6.png&amp;w=640&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x, https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F6ZaHYc4GhEIKfRL2c1erpl%2F59f7fc484abd77f372331aec1f583d84%2FiPhone_8_Plus_-_6.png&amp;w=1920&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F6ZaHYc4GhEIKfRL2c1erpl%2F59f7fc484abd77f372331aec1f583d84%2FiPhone_8_Plus_-_6.png&amp;w=1920&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="iPhone 8 Plus - 2.png" loading="lazy" width="621" height="628" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F1b7106hvxHFzTGUpGnkJtO%2F33e299c2b1216be88278d462c085e32e%2FiPhone_8_Plus_-_2.png&amp;w=640&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x, https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F1b7106hvxHFzTGUpGnkJtO%2F33e299c2b1216be88278d462c085e32e%2FiPhone_8_Plus_-_2.png&amp;w=1920&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F1b7106hvxHFzTGUpGnkJtO%2F33e299c2b1216be88278d462c085e32e%2FiPhone_8_Plus_-_2.png&amp;w=1920&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div></div><p>In our case, this means we need to have our Go code and Rust code interoperating with each other. We want to do a simple translation, explicitly avoiding making improvements or changing functionality when we're swapping out languages for the slice of code. That way, we can do intensive testing against both sets of code, and complete the migration as quickly as possible.</p><h3><span id="why-we-didn't-do-a-full-rewrite"></span><a href="#why-we-didn't-do-a-full-rewrite">Why we didn't do a full rewrite</a><span><svg data-testid="geist-icon" fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24" style="color:currentColor;width:0.75em;height:0.75em"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71"></path></svg></span></h3><p>Full rewrites are very tempting. They are more simple to write and ship, as you don't need to worry about your "before" and "after" code working together. You also get a clean slate to write a new and improved version, without the warts and technical debt of the previous iteration. However, full rewrites also come with some serious downsides.</p><div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="Frame 427319410.png" loading="lazy" width="1920" height="735" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F7nb5vSuSQZXEKsUUsYGNVl%2Ff0f6be9ab08484fb087d5583d5720278%2FFrame_427319410.png&amp;w=1920&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x, https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F7nb5vSuSQZXEKsUUsYGNVl%2Ff0f6be9ab08484fb087d5583d5720278%2FFrame_427319410.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F7nb5vSuSQZXEKsUUsYGNVl%2Ff0f6be9ab08484fb087d5583d5720278%2FFrame_427319410.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="Frame 427319404 (1).png" loading="lazy" width="1920" height="735" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F7bF6sXF2wD092FiiuBXyGV%2Ff5f57209b1f25030cb3e106a2a6189d1%2FFrame_427319404__1_.png&amp;w=1920&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x, https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F7bF6sXF2wD092FiiuBXyGV%2Ff5f57209b1f25030cb3e106a2a6189d1%2FFrame_427319404__1_.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F7bF6sXF2wD092FiiuBXyGV%2Ff5f57209b1f25030cb3e106a2a6189d1%2FFrame_427319404__1_.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div></div><div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="iPhone 8 Plus - 11.png" loading="lazy" width="414" height="459" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F365RREyHsEytwZlyGKa985%2F24ca1793a87a50ac37bdfea84c2964a5%2FiPhone_8_Plus_-_11.png&amp;w=640&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x, https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F365RREyHsEytwZlyGKa985%2F24ca1793a87a50ac37bdfea84c2964a5%2FiPhone_8_Plus_-_11.png&amp;w=828&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F365RREyHsEytwZlyGKa985%2F24ca1793a87a50ac37bdfea84c2964a5%2FiPhone_8_Plus_-_11.png&amp;w=828&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="iPhone 8 Plus - 16.png" loading="lazy" width="414" height="459" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2FWdkdfyBr5TwUufLIYBxRf%2Ff5066270eea29c7ef149ba6eb3c95528%2FiPhone_8_Plus_-_16.png&amp;w=640&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x, https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2FWdkdfyBr5TwUufLIYBxRf%2Ff5066270eea29c7ef149ba6eb3c95528%2FiPhone_8_Plus_-_16.png&amp;w=828&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2FWdkdfyBr5TwUufLIYBxRf%2Ff5066270eea29c7ef149ba6eb3c95528%2FiPhone_8_Plus_-_16.png&amp;w=828&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div></div><p>First, a full rewrite tends to require a complete halt to shipping new features. Otherwise, you run the risk of chasing a moving target as the old codebase grows while you try to catch up with your new code. </p><p>A full rewrite also does not guarantee a better user experience. Often, a rewrite ends up less than seamless, as it's not feasible for the new version to match the old one, feature for feature, edge case for edge case. As the surface area of the rewrite grows, there's more room for error and users can end up frustrated with breaking changes and missing features.</p><p>Full rewrites also require building up an entirely new codebase, which is a large quantity of unused code. In our experience, unused code, even when verified with tests, can be a breeding ground for bugs. We wanted to make sure that any new Rust code was properly exercised as we moved through our porting effort.</p><h2><span id="we-chose-to-port"></span><a href="#we-chose-to-port">We chose to port</a><span><svg data-testid="geist-icon" fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24" style="color:currentColor;width:0.75em;height:0.75em"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71"></path></svg></span></h2><p>Therefore, we decided to <b>port</b> Turborepo to Rust instead of doing a full rewrite.</p><p>Porting did necessitate some tradeoffs. We had to introduce a significant amount of complexity into our codebase, so that we could interoperate between Go and Rust. This complexity meant slower developer velocity to start, but we look forward to workflow improvements going forward, particularly when our porting effort has finished.</p><p>More importantly, we knew we could continue shipping features to Turborepo users while porting. All things considered, we determined that this was a reasonable compromise and the path that we would take.</p><h3><span id="starting-the-port"></span><a href="#starting-the-port">Starting the port </a><span><svg data-testid="geist-icon" fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24" style="color:currentColor;width:0.75em;height:0.75em"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71"></path></svg></span></h3><p>We chose to start by writing a small, new Turborepo feature in Rust. This way, we could add new functionality from the roadmap for users, integrate Rust into our build process, and interact with existing Go code as little as possible to reduce our initial complexity.</p><p>Once we'd laid this groundwork, we knew that we could slowly port more and more code to Rust over time.</p><h2><span id="global-turbo"></span><a href="#global-turbo">Global <code>turbo</code></a><span><svg data-testid="geist-icon" fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24" style="color:currentColor;width:0.75em;height:0.75em"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71"></path></svg></span></h2><p>We decided to have our first Rust feature be <a href="https://turbo.build/blog/turbo-1-7-0#global-turbo?utm_source=turbo&amp;utm_medium=blog&amp;utm_campaign=turborepo_porting" rel="noopener" target="_blank">global <code>turbo</code></a>, a feature that allows users to install Turborepo as a globally available command on their machine. </p><p>A global installation of <code>turbo</code> will look for a locally installed <code>turbo</code> program in the repository, execute it if it exists, and otherwise fallback to the global <code>turbo</code> binary. That way, you can easily run <code>turbo</code> from anywhere in your repository, but also keep a specific version of <code>turbo</code> pinned in your <code>package.json</code>.</p><div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="Frame 427319413.png" loading="lazy" width="1650" height="740" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2FqPT2LsrOLLG4ISEyuv92G%2F2427d2381392e4acc95dc51d1cf9edca%2FFrame_427319413.png&amp;w=1920&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x, https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2FqPT2LsrOLLG4ISEyuv92G%2F2427d2381392e4acc95dc51d1cf9edca%2FFrame_427319413.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2FqPT2LsrOLLG4ISEyuv92G%2F2427d2381392e4acc95dc51d1cf9edca%2FFrame_427319413.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="Frame 427319414.png" loading="lazy" width="1650" height="740" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F2gbJI96SblT7dXxZWZDYsD%2F6877030625b5c53c3523ad96db1d468d%2FFrame_427319414.png&amp;w=1920&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x, https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F2gbJI96SblT7dXxZWZDYsD%2F6877030625b5c53c3523ad96db1d468d%2FFrame_427319414.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F2gbJI96SblT7dXxZWZDYsD%2F6877030625b5c53c3523ad96db1d468d%2FFrame_427319414.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div></div><div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="iPhone 8 Plus - 19.png" loading="lazy" width="414" height="647" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F3DzjEq5stkry2IiCm6zh4U%2Fd5f38eda9664709a42fbbc2e8707ec74%2FiPhone_8_Plus_-_19.png&amp;w=640&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x, https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F3DzjEq5stkry2IiCm6zh4U%2Fd5f38eda9664709a42fbbc2e8707ec74%2FiPhone_8_Plus_-_19.png&amp;w=828&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F3DzjEq5stkry2IiCm6zh4U%2Fd5f38eda9664709a42fbbc2e8707ec74%2FiPhone_8_Plus_-_19.png&amp;w=828&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="iPhone 8 Plus - 5.png" loading="lazy" width="414" height="647" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F7beQhPRdj8OYxzfUcYgEbU%2Fd2e5d1a6a0d94b65231122a21672217e%2FiPhone_8_Plus_-_5.png&amp;w=640&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x, https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F7beQhPRdj8OYxzfUcYgEbU%2Fd2e5d1a6a0d94b65231122a21672217e%2FiPhone_8_Plus_-_5.png&amp;w=828&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F7beQhPRdj8OYxzfUcYgEbU%2Fd2e5d1a6a0d94b65231122a21672217e%2FiPhone_8_Plus_-_5.png&amp;w=828&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div></div><p>This feature is implemented through what we started calling "the Rust shim," a bit of Rust code that wraps the existing Go code. The Go portion is compiled via CGO as a C static library and then linked to the Rust binary. Luckily, global <code>turbo</code> only required a few features from the rest of Turborepo's code, such as reading configuration and navigating the file system. </p><h2><span id="cli-parsing"></span><a href="#cli-parsing">CLI parsing</a><span><svg data-testid="geist-icon" fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24" style="color:currentColor;width:0.75em;height:0.75em"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71"></path></svg></span></h2><p>As we implemented global <code>turbo</code>, we realized we needed to parse a few command line arguments like <code>--cwd</code>, the argument for setting <code>turbo</code>'s current working directory.</p><p>After global <code>turbo</code>, it made sense to continue by porting the rest of the CLI argument parser to Rust. To parse arguments, we use the <a href="https://docs.rs/clap/latest/clap/" rel="noopener" target="_blank"><code>clap</code> crate</a> (Rust’s equivalent of an npm package). <code>clap</code> lets you define a data type with the arguments, annotate it a little bit, and it will automatically create a parser.</p><p>With the pieces in place, we had to work on sending the args from the Rust entry point to the Go code. For better or worse, <a href="https://faultlore.com/blah/c-isnt-a-language/" rel="noopener" target="_blank">C is the standard for foreign function interfacing (FFI)</a>, so we had to use C to communicate between Rust and Go.</p><div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="InlineGraphic_1920xVariable (1).png" loading="lazy" width="1920" height="1084" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F2FGPm6ksIA7bGzZzY7CYkd%2F06b7d487cbcf5237ae9f917574cf7a51%2FInlineGraphic_1920xVariable__1_.png&amp;w=1920&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x, https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F2FGPm6ksIA7bGzZzY7CYkd%2F06b7d487cbcf5237ae9f917574cf7a51%2FInlineGraphic_1920xVariable__1_.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F2FGPm6ksIA7bGzZzY7CYkd%2F06b7d487cbcf5237ae9f917574cf7a51%2FInlineGraphic_1920xVariable__1_.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="InlineGraphic_1920xVariable.png" loading="lazy" width="1920" height="1084" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F7sVbowOCnYSjNrOyxfD5NF%2F0fdf484cf4ced36f67e0ab879514d099%2FInlineGraphic_1920xVariable.png&amp;w=1920&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x, https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F7sVbowOCnYSjNrOyxfD5NF%2F0fdf484cf4ced36f67e0ab879514d099%2FInlineGraphic_1920xVariable.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F7sVbowOCnYSjNrOyxfD5NF%2F0fdf484cf4ced36f67e0ab879514d099%2FInlineGraphic_1920xVariable.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div></div><div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="InlineGraphic_1920xVariable (3).png" loading="lazy" width="414" height="416" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F1M9EpwZDGRt4PqXnS41B6p%2F0cc3e7336ee39882508a6dd112db9a5f%2FInlineGraphic_1920xVariable__3_.png&amp;w=640&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x, https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F1M9EpwZDGRt4PqXnS41B6p%2F0cc3e7336ee39882508a6dd112db9a5f%2FInlineGraphic_1920xVariable__3_.png&amp;w=828&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F1M9EpwZDGRt4PqXnS41B6p%2F0cc3e7336ee39882508a6dd112db9a5f%2FInlineGraphic_1920xVariable__3_.png&amp;w=828&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="InlineGraphic_1920xVariable (2).png" loading="lazy" width="414" height="416" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F7s2Gq0JKjOQkBQ9ZAOqEGw%2F4b0db3626aa7e7b7b10b95e8fdf8d631%2FInlineGraphic_1920xVariable__2_.png&amp;w=640&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x, https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F7s2Gq0JKjOQkBQ9ZAOqEGw%2F4b0db3626aa7e7b7b10b95e8fdf8d631%2FInlineGraphic_1920xVariable__2_.png&amp;w=828&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F7s2Gq0JKjOQkBQ9ZAOqEGw%2F4b0db3626aa7e7b7b10b95e8fdf8d631%2FInlineGraphic_1920xVariable__2_.png&amp;w=828&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div></div><p>We wanted to avoid having too many types in C, as we weren’t confident that we could write cross-platform C types that played well with both Rust and Go. Instead, we decided to serialize our arguments to JSON and send it to Go as a string. Even though JSON serialization does have some overhead, we knew that the arguments struct would only be a few hundred bytes in size, so the performance impact would be minimal.</p><p>On the Rust side, we used another cornerstone crate of the Rust ecosystem, <a href="https://docs.rs/serde/latest/serde/" rel="noopener" target="_blank"><code>serde</code></a>, which lets you serialize and deserialize data in various different formats, using some minimal annotation. For the Go side, we were already using JSON in the codebase, so it was easy to receive the JSON string and deserialize it into a Go struct. </p><h2><span id="ship-it"></span><a href="#ship-it">Ship it?</a><span><svg data-testid="geist-icon" fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24" style="color:currentColor;width:0.75em;height:0.75em"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71"></path></svg></span></h2><p>With these two features ported, we were ready to ship our first hybrid Go-Rust release.</p><p>However, before we could release, we needed to make sure the Go-Rust binary worked in all the various contexts that Turborepo is used, <a href="https://turbo.build/repo/docs/installing?utm_source=turbo&amp;utm_medium=blog&amp;utm_campaign=turborepo_porting" rel="noopener" target="_blank">like the different operating systems and  Linux distros that we support</a>. As we tested our code, we started noticing some issues on a couple platforms.</p><h3><span id="windows-difficulties"></span><a href="#windows-difficulties">Windows difficulties</a><span><svg data-testid="geist-icon" fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24" style="color:currentColor;width:0.75em;height:0.75em"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71"></path></svg></span></h3><p>On Windows, there are two main toolchains, <a href="https://en.wikipedia.org/wiki/Microsoft_Visual_C%2B%2B" rel="noopener" target="_blank">Microsoft Visual C++ (MSVC)</a> and <a href="https://en.wikipedia.org/wiki/MinGW" rel="noopener" target="_blank">Minimalist GNU for Windows (MinGW)</a>.</p><p>Go <b>only</b> uses MinGW, but we were using Rust with MSVC. This caused some runtime issues, but, luckily, the solution was simple: we moved our Rust toolchain to MinGW.</p><p>Next up, we had some issues with paths. Windows has a couple concepts of paths, including what’s called a Universal Naming Convention (UNC) path. When you ask Windows to canonicalize a path (resolve all symlinks and normalize components of the path), it gives you a UNC path.</p><p>However, despite the name, UNC paths are not supported everywhere—sometimes not even by Windows itself! This caused a few bugs where we’d provide a UNC path and get an invalid path error. The solution was to use a helpful Rust crate called <a href="https://docs.rs/dunce/latest/dunce/" rel="noopener" target="_blank">dunce</a> that lets you canonicalize a path and get a non-UNC path back, handling the intricacies of this problem for us.</p><h3><span id="alpine-linux"></span><a href="#alpine-linux">Alpine Linux</a><span><svg data-testid="geist-icon" fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24" style="color:currentColor;width:0.75em;height:0.75em"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71"></path></svg></span></h3><p>The second set of challenges came with Alpine Linux. At Vercel, we use Alpine, a common operating system for cloud computing, to create lightweight containers for building your projects.</p><p>Alpine, though, does not come with <code>glibc</code>, the de-facto implementation of the C standard library. This is a problem because many binaries assume <code>glibc</code> is installed and don’t package it themselves. There are some libraries that pave over this issue using packages like <code>gcompat</code> or <code>libc6-compat</code>, but they didn’t end up working for us because the version of <code>glibc</code> that Rust requires was too modern for our supported targets. When we’d try to run the binary, we’d get errors that the required <code>glibc</code> version was not available.</p><p>As a result, we decided to compile Turborepo as a fully static binary. This meant that we packaged our own C standard library implementation using <code>musl</code> (since you can't statically link <code>glibc</code> due to licensing issues). This seems to work just fine for both Rust and Go: Rust lets you set the C standard library in the target (<code>aarch64-unknown-linux-musl</code> vs. <code>aarch64-unknown-linux-gnu</code>) and Go does not use a C standard library by default.</p><p>However, when we ran this statically linked binary, it would return a segmentation fault. Even worse, when we inspected with a debugger, we’d find a corrupted stack. And, even worser, the segfault appeared to be coming from the Go runtime itself!</p><hr><p>After a lot of searching, we tracked down a <a href="https://github.com/golang/go/issues/13492" rel="noopener" target="_blank">seven year-old GitHub issue</a> which explained that Go cannot be compiled as a C static library with <code>musl</code>. This posed a significant challenge, as Alpine Linux is an essential platform for Turborepo and its users. We had to go back to the drawing board and figure out how we could ship our Go-Rust combination.</p><p>Eventually, after a ton more deliberation, we came up with a solution: we’d compile our Go code and our Rust code as two separate binaries. The Rust code would call the Go code and pass the args serialized to JSON via the CLI.</p><div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="Frame 427319412.png" loading="lazy" width="1920" height="917" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F1VOl0eTFS33pkNLbtrzhY%2F6811cbf8065443e0ba46c5c365b9fca4%2FFrame_427319412.png&amp;w=1920&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x, https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F1VOl0eTFS33pkNLbtrzhY%2F6811cbf8065443e0ba46c5c365b9fca4%2FFrame_427319412.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F1VOl0eTFS33pkNLbtrzhY%2F6811cbf8065443e0ba46c5c365b9fca4%2FFrame_427319412.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="Frame 427319408.png" loading="lazy" width="1920" height="917" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F3KbndugMu2gM4Nu8Eoq3dj%2F41cb0b6578dbd822c77f08f2bada4066%2FFrame_427319408.png&amp;w=1920&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x, https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F3KbndugMu2gM4Nu8Eoq3dj%2F41cb0b6578dbd822c77f08f2bada4066%2FFrame_427319408.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F3KbndugMu2gM4Nu8Eoq3dj%2F41cb0b6578dbd822c77f08f2bada4066%2FFrame_427319408.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div></div><div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="iPhone 8 Plus - 14.png" loading="lazy" width="414" height="506" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F5QibrcV35p6zu0Rpzriwn5%2F57872cf4a380ba9c3ec780a02c370775%2FiPhone_8_Plus_-_14.png&amp;w=640&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x, https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F5QibrcV35p6zu0Rpzriwn5%2F57872cf4a380ba9c3ec780a02c370775%2FiPhone_8_Plus_-_14.png&amp;w=828&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F5QibrcV35p6zu0Rpzriwn5%2F57872cf4a380ba9c3ec780a02c370775%2FiPhone_8_Plus_-_14.png&amp;w=828&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="iPhone 8 Plus - 18.png" loading="lazy" width="414" height="506" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F2547NHodIcPCgR7ITmjnM0%2F4366bba1f016889729cfc1c729554907%2FiPhone_8_Plus_-_18.png&amp;w=640&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x, https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F2547NHodIcPCgR7ITmjnM0%2F4366bba1f016889729cfc1c729554907%2FiPhone_8_Plus_-_18.png&amp;w=828&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F2547NHodIcPCgR7ITmjnM0%2F4366bba1f016889729cfc1c729554907%2FiPhone_8_Plus_-_18.png&amp;w=828&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div></div><p>We knew that the args were small enough that they could be passed via CLI without too much of a performance hit. And because we were using a serialization format, the code changes were extremely small. All we had to do was change how Rust was sending the JSON string to Go.</p><p>With that, we were able to get our first hybrid Go-Rust release out the door. The first version of <code>turbo</code> that was shipped to you using these compilation strategies was <a href="https://turbo.build/blog/turbo-1-7-0?utm_source=turbo&amp;utm_medium=blog&amp;utm_campaign=turborepo_porting" rel="noopener" target="_blank">version 1.7.0</a>.</p><h2><span id="what-we-learned"></span><a href="#what-we-learned">What we learned</a><span><svg data-testid="geist-icon" fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24" style="color:currentColor;width:0.75em;height:0.75em"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71"></path></svg></span></h2><p>Through this effort, we've learned a lot about moving from one language to another. Let's take note of what we've found.</p><h3><span id="serialization-is-useful-for-ffi"></span><a href="#serialization-is-useful-for-ffi">Serialization is useful for FFI</a><span><svg data-testid="geist-icon" fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24" style="color:currentColor;width:0.75em;height:0.75em"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71"></path></svg></span></h3><p>Our first takeaway is that serialization formats are very useful for interoperability. By serializing to JSON, a format with robust support in both Go and Rust, we were able to minimize our FFI surface area, and avoid a whole class of cross-platform, cross-language bugs. When we had to switch from a single, linked binary to two binaries, we were able to do so with relative ease because our FFI surface area was so small.</p><p>The tradeoff here is that serialization and deserialization is slow. You can only depend on this technique if either you know your serialized payloads will be small or you don't care about the performance hit for your use case.</p><h3><span id="porting-takes-preparation"></span><a href="#porting-takes-preparation">Porting takes preparation</a><span><svg data-testid="geist-icon" fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24" style="color:currentColor;width:0.75em;height:0.75em"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71"></path></svg></span></h3><p>The second takeaway is that incremental porting is feasible but requires lots of careful testing and strategizing. We ran into quite a few tricky bugs and we caught these issues through lots of automated and manual testing. You can <a href="https://github.com/vercel/turbo/tree/main/.github/workflows" rel="noopener" target="_blank">check out our (and Turbopack's) testing suites in our GitHub workflows</a>.</p><p>Testing is also extremely important for nailing down the behavior of your code, whether it’s the exact edge cases of CLI parsing, or the order in which configuration is loaded. These exact details are not so crucial when you’re writing your first implementation, but they’re absolutely paramount to avoid breaking changes during a port or rewrite. You should aim to write tests <b>before</b> you start porting code, so that you have a known specification to work against.</p><h3><span id="cross-compatibility-is-difficult"></span><a href="#cross-compatibility-is-difficult">Cross-compatibility is difficult</a><span><svg data-testid="geist-icon" fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24" style="color:currentColor;width:0.75em;height:0.75em"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71"></path></svg></span></h3><p>The third takeaway is that cross-platform, cross-language release engineering is extremely challenging. Every platform, language, and compiler has their own quirks that can make interoperability difficult and, the more things you have working together, the more opportunities you have for a new complication.</p><h3><span id="porting-is-worth-it-for-us"></span><a href="#porting-is-worth-it-for-us">Porting is worth it for us</a><span><svg data-testid="geist-icon" fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24" style="color:currentColor;width:0.75em;height:0.75em"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71"></path></svg></span></h3><p>Finally, while porting from Go to Rust has been challenging, it has proven to be the correct choice for us strategically. Even with our porting effort going on, we've been able to ship new features, handle bugs in existing functionality, and keep helping our users while we migrate. It's required some extraordinarily tricky debugging, careful planning, and rigorous testing, but we believe it has been worth it.</p><h2><span id="try-out-(ported)-turborepo"></span><a href="#try-out-(ported)-turborepo">Try out (ported) Turborepo</a><span><svg data-testid="geist-icon" fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24" style="color:currentColor;width:0.75em;height:0.75em"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71"></path></svg></span></h2><p>This week, Turborepo saved 5,742 hours of time for the product engineers and CI machines at Vercel. If you want to try out the same technology in just a few minutes, <a href="https://vercel.com/blog/vercel-remote-cache-turbo" rel="noopener" target="_blank">check out our article</a> on how you can get started with <a href="https://vercel.com/docs/concepts/monorepos/remote-caching" rel="noopener" target="_blank">Vercel Remote Cache</a>.</p><div><p data-version="v1">Explore more</p><div><a href="https://vercel.com/templates/next.js/turborepo-next-basic"><div><p><img data-version="v1" alt="Screenshot of template" loading="lazy" decoding="async" data-nimg="fill" sizes="25vw" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F2JxNyYATuuV7WPuJ31kF9Q%2F433990aa4c8e7524a9095682fb08f0b1%2FBasic.png&amp;w=256&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 256w, https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F2JxNyYATuuV7WPuJ31kF9Q%2F433990aa4c8e7524a9095682fb08f0b1%2FBasic.png&amp;w=384&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 384w, https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F2JxNyYATuuV7WPuJ31kF9Q%2F433990aa4c8e7524a9095682fb08f0b1%2FBasic.png&amp;w=640&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 640w, https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F2JxNyYATuuV7WPuJ31kF9Q%2F433990aa4c8e7524a9095682fb08f0b1%2FBasic.png&amp;w=750&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 750w, https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F2JxNyYATuuV7WPuJ31kF9Q%2F433990aa4c8e7524a9095682fb08f0b1%2FBasic.png&amp;w=828&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 828w, https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F2JxNyYATuuV7WPuJ31kF9Q%2F433990aa4c8e7524a9095682fb08f0b1%2FBasic.png&amp;w=1080&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1080w, https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F2JxNyYATuuV7WPuJ31kF9Q%2F433990aa4c8e7524a9095682fb08f0b1%2FBasic.png&amp;w=1200&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1200w, https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F2JxNyYATuuV7WPuJ31kF9Q%2F433990aa4c8e7524a9095682fb08f0b1%2FBasic.png&amp;w=1920&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1920w, https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F2JxNyYATuuV7WPuJ31kF9Q%2F433990aa4c8e7524a9095682fb08f0b1%2FBasic.png&amp;w=2048&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2048w, https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F2JxNyYATuuV7WPuJ31kF9Q%2F433990aa4c8e7524a9095682fb08f0b1%2FBasic.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 3840w" src="https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F2JxNyYATuuV7WPuJ31kF9Q%2F433990aa4c8e7524a9095682fb08f0b1%2FBasic.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></div></a><a href="https://turbo.build/" rel="noopener" target="_blank"><div><p><img data-version="v1" alt="Visit turbo.build" loading="lazy" decoding="async" data-nimg="fill" sizes="25vw" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F6AXDBERJ8a3qkQkJbDMojJ%2F47691b985c3f224b0e2742564a3a5ef1%2FCleanShot_2023-07-13_at_14.50.43_2x.png&amp;w=256&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 256w, https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F6AXDBERJ8a3qkQkJbDMojJ%2F47691b985c3f224b0e2742564a3a5ef1%2FCleanShot_2023-07-13_at_14.50.43_2x.png&amp;w=384&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 384w, https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F6AXDBERJ8a3qkQkJbDMojJ%2F47691b985c3f224b0e2742564a3a5ef1%2FCleanShot_2023-07-13_at_14.50.43_2x.png&amp;w=640&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 640w, https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F6AXDBERJ8a3qkQkJbDMojJ%2F47691b985c3f224b0e2742564a3a5ef1%2FCleanShot_2023-07-13_at_14.50.43_2x.png&amp;w=750&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 750w, https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F6AXDBERJ8a3qkQkJbDMojJ%2F47691b985c3f224b0e2742564a3a5ef1%2FCleanShot_2023-07-13_at_14.50.43_2x.png&amp;w=828&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 828w, https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F6AXDBERJ8a3qkQkJbDMojJ%2F47691b985c3f224b0e2742564a3a5ef1%2FCleanShot_2023-07-13_at_14.50.43_2x.png&amp;w=1080&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1080w, https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F6AXDBERJ8a3qkQkJbDMojJ%2F47691b985c3f224b0e2742564a3a5ef1%2FCleanShot_2023-07-13_at_14.50.43_2x.png&amp;w=1200&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1200w, https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F6AXDBERJ8a3qkQkJbDMojJ%2F47691b985c3f224b0e2742564a3a5ef1%2FCleanShot_2023-07-13_at_14.50.43_2x.png&amp;w=1920&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1920w, https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F6AXDBERJ8a3qkQkJbDMojJ%2F47691b985c3f224b0e2742564a3a5ef1%2FCleanShot_2023-07-13_at_14.50.43_2x.png&amp;w=2048&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2048w, https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F6AXDBERJ8a3qkQkJbDMojJ%2F47691b985c3f224b0e2742564a3a5ef1%2FCleanShot_2023-07-13_at_14.50.43_2x.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 3840w" src="https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F6AXDBERJ8a3qkQkJbDMojJ%2F47691b985c3f224b0e2742564a3a5ef1%2FCleanShot_2023-07-13_at_14.50.43_2x.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></div></a></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Dementia risk linked to blood-protein imbalance in middle age (302 pts)]]></title>
            <link>https://www.nature.com/articles/d41586-023-02374-2</link>
            <guid>36813564</guid>
            <pubDate>Fri, 21 Jul 2023 13:34:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nature.com/articles/d41586-023-02374-2">https://www.nature.com/articles/d41586-023-02374-2</a>, See on <a href="https://news.ycombinator.com/item?id=36813564">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                    <figure>
 <picture>
  <source type="image/webp" srcset="https://media.nature.com/lw767/magazine-assets/d41586-023-02374-2/d41586-023-02374-2_25825424.jpg?as=webp 767w, https://media.nature.com/lw319/magazine-assets/d41586-023-02374-2/d41586-023-02374-2_25825424.jpg?as=webp 319w" sizes="(max-width: 319px) 319px, (min-width: 1023px) 100vw,  767px">
  <img alt="Visualization showing a brain affected by Alzheimer's disease." loading="lazy" src="https://media.nature.com/lw767/magazine-assets/d41586-023-02374-2/d41586-023-02374-2_25825424.jpg">
  <figcaption>
   <p><span>A slice through the brain of a person with Alzheimer’s disease, the most common cause of dementia.</span><span>Credit: Anatomical Travelogue/Science Photo Library</span></p>
  </figcaption>
 </picture>
</figure><p>A study that followed thousands of people over 25 years has identified proteins linked to the development of dementia if their levels are unbalanced during middle age.</p><p>The findings, published in <i>Science Translational Medicine </i>on 19 July<sup><a href="#ref-CR1" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">1</a></sup>, could contribute to the development of new diagnostic tests, or even treatments, for dementia-causing diseases.</p><p>Most of the proteins have functions unrelated to the brain.</p><p>“We’re seeing so much involvement of the peripheral biology decades before the typical onset of dementia,” says study author Keenan Walker, a neuroscientist at the US National Institute on Aging in Bethesda, Maryland.</p><article data-label="Related">
  <a href="https://www.nature.com/articles/d41586-023-00954-w" data-track="click" data-track-label="recommended article"><img alt="" src="https://media.nature.com/w400/magazine-assets/d41586-023-02374-2/d41586-023-02374-2_25434040.jpg"><p>Conquering Alzheimer’s: a look at the therapies of the future</p></a>
 </article><p>Equipped with blood samples from more than 10,000 participants, Walker and his colleagues questioned whether they could find predictors of dementia years before its onset by looking at a person’s proteome — the collection of all the proteins expressed throughout the body. They searched for any signs of dysregulation — when proteins are at levels much higher or lower than normal.</p><p>The samples were collected as part of an ongoing study that began in 1987. Participants returned for examination six times over three decades, and during this time, around 1 in 5 of them developed dementia.</p><p>The researchers found 32 proteins that, if dysregulated in people aged 45 to 60, were strongly associated with an elevated chance of developing dementia in later life. It is unclear how exactly these proteins might be involved in the disease, but the link is “highly unlikely to be due to just chance alone”, says Walker.</p><p>“Not all the proteins showed changes in both plasma and brain tissues,” says Nicholas Seyfried, a biochemist and neurologist at Emory University in Atlanta, Georgia. For example, one of the proteins found with the strongest association with dementia risk — called GDF15 — was not detected in the brain, suggesting that “mechanisms below the neck could also play a role”, he adds.</p><p>Walker says that although a person’s proteome by itself cannot predict their risk of getting dementia, it could perhaps bolster the strength of existing predictors — such as age and family history.</p><h2>Protein balance</h2><p>As expected, some of the proteins that researchers identified are active in the brain — but most have other roles in the body. A handful were linked to proteostasis — the process of carefully balancing protein levels in the proteome.</p><p>This regulation is important in preventing proteins from going rogue and clumping together, which is what happens to the amyloid and tau proteins in the brains of people with Alzheimer’s disease, the most common cause of dementia.</p><article data-label="Related">
  <a href="https://www.nature.com/news/how-to-defeat-dementia-1.20949" data-track="click" data-track-label="recommended article"><img alt="" src="https://media.nature.com/w400/magazine-assets/d41586-023-02374-2/d41586-023-02374-2_15713358.jpg"><p>How to defeat dementia</p></a>
 </article><p>The study found altered levels of many of the proteins both in the brain tissues of those who had died with Alzheimer’s disease, and in the blood of those still living with it. These were associated with the presence of amyloid and tau proteins, which suggests they are somehow involved in processes specific to the disease.</p><p>Other proteins identified in the study were linked to the immune system, adding to “growing evidence for the role of innate and adaptive immune function in dementia”, says Jin-Tai Yu, a physician-scientist who specializes in dementia at Fudan University in Shanghai, China. Yu and his team have previously found that people with immune diseases are more vulnerable to Alzheimer’s later in life<sup><a href="#ref-CR2" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">2</a></sup>.</p><p>There is still a long way to go in understanding exactly how any of these proteins fit into the physiology of dementia, and a much better understanding of the underlying mechanisms is needed before people can benefit. Such insights “could potentially open doors for early interventions”, says Seyfried. For Walker, the aim in future is to determine whether these proteins could potentially be used as markers to identify various dysregulated pathways in people with dementia and to help provide more personalized treatments.</p>
                </div><div id="references" aria-labelledby="Bib1"><h2 id="Bib1">References</h2></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[90s Internet: When 20 hours online triggered an email from my ISP’s president (195 pts)]]></title>
            <link>https://arstechnica.com/gadgets/2023/07/the-90s-internet-when-20-hours-online-triggered-an-email-from-my-isps-president/</link>
            <guid>36813210</guid>
            <pubDate>Fri, 21 Jul 2023 12:56:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/gadgets/2023/07/the-90s-internet-when-20-hours-online-triggered-an-email-from-my-isps-president/">https://arstechnica.com/gadgets/2023/07/the-90s-internet-when-20-hours-online-triggered-an-email-from-my-isps-president/</a>, See on <a href="https://news.ycombinator.com/item?id=36813210">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/07/banj-edwards-terminally-online2-800x450.jpg" alt="The ‘90s Internet: When 20 hours online triggered an email from my ISP’s president">
      <figcaption><p>Banj Edwards | Aurich Lawson | Getty Images</p></figcaption>  </figure>

  




<!-- cache hit 288:single/related:a53e128e87d5db82176cc5af52b3d616 --><!-- empty -->
<p>"When checking the system this morning, I noticed your account logged in for over 20 hours," begins a December 1998 email from the president of my dial-up Internet service provider (ISP) at the time. "Our service is unlimited, but we ask that you actually be using the connection while logged in."</p>

<p>Today, when it seems like everyone is online 24/7 through smartphones and broadband, I'd be weird if I <em>wasn't online</em> for 20 hours straight. But 1998 in Raleigh, North Carolina, was different. In an age of copper telephone lines and dial-up modems, Internet access wasn't usually an always-on situation for a home user in the US. Each occupied telephone line meant another ISP customer couldn't use it—and no one could call you, either.</p>
<p>But I'm getting ahead of myself—why do I have an email from 1998?</p>
<h2>A voice from the past</h2>

<p>I save everything. It's just <a href="https://www.pcmag.com/news/gear-envy-my-collection-of-500-plus-pieces-of-computer-and-gaming-hardware">what I do</a>.</p>
<p>Being an amateur data archivist has served me well during my <a href="https://benjedwards.com/works.php">career</a> writing about tech. About eight years ago, I decided to search my archives for old email files and import them all into Apple Mail for OS X, organizing them chronologically so I could look at them all in one place. I found Internet emails going as far back as 1995, when I started using a POP3 client instead of <a href="https://en.wikipedia.org/wiki/Pine_(email_client)">Pine</a>. While browsing emails from 1998, I found a curious nugget from another era that blew me away.</p>
<blockquote><p>From: Eugene J. Fourney III<br>
Date: December 18, 1998 11:21 AM<br>
Subject: Online for 20 hours straight</p>
<p>Thank you for allowing NetWorks to provide Internet service.</p>
<p>I am writing because when checking the system this morning, I<br>
noticed your account logged in for over 20 hours.</p>
<p>Our service is unlimited, but we ask that you actually be using the<br>
connection while logged in. This has not been the case on occasion with<br>
your account.</p>
<p>We must ask that you take measures to ensure that you disconnect after<br>
any given session. Our resources must be shared between many customers,<br>
and the only way to accomplish that is for people to close the<br>
connection when they are not actively using it.</p>
<p>Please help with this by checking your dialer settings, and setting it<br>
to disconnect after 30 minutes of inactivity. Please also uncheck the<br>
option in your email program that automatically checks mail every 10<br>
minutes, or set it to some number higher than 30 minutes.</p>
<p>If you need help in locating these settings or want to discuss this<br>
further, please contact me at this email address or at our offices at<br>
518-0351 or 518-8034.</p>
<p>Gene Fourney</p></blockquote>
<p>I vaguely remember getting this email and thinking it was ridiculous because the connection was supposedly "unlimited." My family paid NetWorks a monthly fee (a $24.95 "Family Plan" for three user IDs) that allowed me, my dad, and my brother to connect to the Internet as much as we wanted—or so I thought. I showed the email to my father, who shrugged it off.</p>                                            
                                                        

<p>Between 1995 and 2000, I used a dial-up ISP, which meant that I had to call in to the ISP using a regular copper phone line and a dial-up modem running at anywhere between 14.4Kbps to 56Kbps over the years. Since most people also used their telephone lines for talking with their voice, there was a basic assumption that most calls to the ISP would be temporary. If your line was occupied, you would miss incoming calls. In my situation, my parents had set up a second phone line exclusively for my BBS in 1993 so I could spend as much time online as necessary without worrying about blocking incoming phone calls to my family.</p>
<p>A key issue I had with the email was the implication that I wasn't using my Internet connection during those 20 hours. I'm pretty sure I was using it, and not just for automatically checking my email every 30 minutes, as the email suggests.</p>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Primo – a visual CMS with Svelte blocks, a code editor, and SSG (274 pts)]]></title>
            <link>https://primocms.org</link>
            <guid>36813086</guid>
            <pubDate>Fri, 21 Jul 2023 12:38:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://primocms.org">https://primocms.org</a>, See on <a href="https://news.ycombinator.com/item?id=36813086">Hacker News</a></p>
<div id="readability-page-1" class="page">

    
    <div id="section-885d7628">
        <header>
            
            <div>
                <h2><!-- HTML_TAG_START -->
                    <p>Primo is a visual CMS that makes it a blast to build <strong>pages</strong>, manage <strong>content</strong>, and edit <strong>code</strong> - one block at a time.</p><!-- HTML_TAG_END -->
                </h2>


                
            </div>
            <div>
                <figure><iframe src="https://player.vimeo.com/video/838469641?h=df40df2d2c&amp;badge=0&amp;loop=1&amp;autopause=0&amp;player_id=0&amp;autoplay=1&amp;muted=1&amp;loop=1&amp;title=0&amp;sidedock=0&amp;controls=&amp;app_id=58479" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen="" title="Landing Page Demo"></iframe></figure>
                
            </div>
        </header>

    </div>
    <section id="section-ddd59217">
            <header>
                <h2>The modern monolithic CMS</h2>
                <h3>Primo combines delightful content management with the power of modern development</h3>
            </header>
            <div>
                <div>
                    <div>
                        <h2>Drag-n-drop page building</h2>
                        <p>Build your site's pages by dragging and dropping your directly blocks onto the page, unencumbered by overwhelming design options.</p>
                    </div>
                    <figure><img src="https://kdtzsoeklezpgshpzqtf.supabase.co/storage/v1/object/public/images/7c1dc1a3-c9eb-4364-b31b-951ecfc2641d/1682111950401Screen%20Shot%202023-04-21%20at%205.17.27%20PM.png" alt=""></figure>
                </div>
                <div>
                    <div>
                        <h2>Visual content editing</h2>
                        <p>Update your text, images, and links directly on the page or open up the Fields view to manage your content from a structured view.</p>
                    </div>
                    <figure><img src="https://kdtzsoeklezpgshpzqtf.supabase.co/storage/v1/object/public/images/7c1dc1a3-c9eb-4364-b31b-951ecfc2641d/Screen%20Shot%202023-04-21%20at%205.22.39%20PM.png1682112222228" alt=""></figure>
                </div>
                <div>
                    <div>
                        <h2>Integrated development</h2>
                        <p>Access each block's code with a click - right from your browser. And since each block is a <a href="https://svelte.dev/">Svelte</a> component, there's no limit to what you can make.</p>
                    </div>
                    <figure><img src="https://kdtzsoeklezpgshpzqtf.supabase.co/storage/v1/object/public/images/7c1dc1a3-c9eb-4364-b31b-951ecfc2641d/Screen%20Shot%202023-04-21%20at%205.25.06%20PM.png1682112330379" alt=""></figure>
                </div>
            </div>
        </section>
    <div id="section-d294b81b">
                <ul>
                    <li>
                        <h3><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="" role="img" width="1em" height="1em" viewBox="0 0 256 256"><!-- HTML_TAG_START -->
                                <path fill="currentColor" d="m213.66 66.34l-40-40A8 8 0 0 0 168 24H88a16 16 0 0 0-16 16v16H56a16 16 0 0 0-16 16v144a16 16 0 0 0 16 16h112a16 16 0 0 0 16-16v-16h16a16 16 0 0 0 16-16V72a8 8 0 0 0-2.34-5.66ZM136 192H88a8 8 0 0 1 0-16h48a8 8 0 0 1 0 16Zm0-32H88a8 8 0 0 1 0-16h48a8 8 0 0 1 0 16Zm64 24h-16v-80a8 8 0 0 0-2.34-5.66l-40-40A8 8 0 0 0 136 56H88V40h76.69L200 75.31Z"></path><!-- HTML_TAG_END -->
                            </svg>
                            <span><!-- HTML_TAG_START -->Static Sites<!-- HTML_TAG_END --></span>
                        </h3>
                        <p>Your websites are secure, scalable to millions, and fast-loading - no fancy plugins necessary.</p>
                    </li>
                    <li>
                        <h3><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="" role="img" width="1em" height="1em" viewBox="0 0 24 24"><!-- HTML_TAG_START -->
                                <path fill="currentColor" d="M12 5.5A3.5 3.5 0 0 1 15.5 9a3.5 3.5 0 0 1-3.5 3.5A3.5 3.5 0 0 1 8.5 9A3.5 3.5 0 0 1 12 5.5M5 8c.56 0 1.08.15 1.53.42c-.15 1.43.27 2.85 1.13 3.96C7.16 13.34 6.16 14 5 14a3 3 0 0 1-3-3a3 3 0 0 1 3-3m14 0a3 3 0 0 1 3 3a3 3 0 0 1-3 3c-1.16 0-2.16-.66-2.66-1.62a5.536 5.536 0 0 0 1.13-3.96c.45-.27.97-.42 1.53-.42M5.5 18.25c0-2.07 2.91-3.75 6.5-3.75s6.5 1.68 6.5 3.75V20h-13v-1.75M0 20v-1.5c0-1.39 1.89-2.56 4.45-2.9c-.59.68-.95 1.62-.95 2.65V20H0m24 0h-3.5v-1.75c0-1.03-.36-1.97-.95-2.65c2.56.34 4.45 1.51 4.45 2.9V20Z"></path><!-- HTML_TAG_END -->
                            </svg>
                            <span><!-- HTML_TAG_START -->Real-time collaboration<!-- HTML_TAG_END --></span>
                        </h3>
                        <p>Invite any number of collaborators as developers or content editors and edit your pages together. </p>
                    </li>
                    <li>
                        <h3><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="" role="img" width="1em" height="1em" viewBox="0 0 24 24"><!-- HTML_TAG_START -->
                                <g fill="currentColor">
                                    <path fill-rule="evenodd" d="M14 7a1 1 0 0 0-1 1v8a1 1 0 0 0 1 1h4a1 1 0 0 0 1-1V8a1 1 0 0 0-1-1h-4Zm3 2h-2v6h2V9Z" clip-rule="evenodd"></path>
                                    <path d="M6 7a1 1 0 0 0 0 2h4a1 1 0 1 0 0-2H6Zm0 4a1 1 0 1 0 0 2h4a1 1 0 1 0 0-2H6Zm-1 5a1 1 0 0 1 1-1h4a1 1 0 1 1 0 2H6a1 1 0 0 1-1-1Z"></path>
                                    <path fill-rule="evenodd" d="M4 3a3 3 0 0 0-3 3v12a3 3 0 0 0 3 3h16a3 3 0 0 0 3-3V6a3 3 0 0 0-3-3H4Zm16 2H4a1 1 0 0 0-1 1v12a1 1 0 0 0 1 1h16a1 1 0 0 0 1-1V6a1 1 0 0 0-1-1Z" clip-rule="evenodd"></path>
                                </g><!-- HTML_TAG_END -->
                            </svg>
                            <span><!-- HTML_TAG_START -->Multisite to the max<!-- HTML_TAG_END --></span>
                        </h3>
                        <p data-key="items[2].description"><!-- HTML_TAG_START -->
                            <h2>Create an unlimited number of websites on a single server and start new sites in seconds.</h2><!-- HTML_TAG_END -->
                        </p>
                    </li>
                    <li>
                        <h3><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="" role="img" width="1em" height="1em" viewBox="0 0 24 24"><!-- HTML_TAG_START -->
                                <path fill="currentColor" d="M12 2A10 10 0 0 0 2 12c0 4.42 2.87 8.17 6.84 9.5c.5.08.66-.23.66-.5v-1.69c-2.77.6-3.36-1.34-3.36-1.34c-.46-1.16-1.11-1.47-1.11-1.47c-.91-.62.07-.6.07-.6c1 .07 1.53 1.03 1.53 1.03c.87 1.52 2.34 1.07 2.91.83c.09-.65.35-1.09.63-1.34c-2.22-.25-4.55-1.11-4.55-4.92c0-1.11.38-2 1.03-2.71c-.1-.25-.45-1.29.1-2.64c0 0 .84-.27 2.75 1.02c.79-.22 1.65-.33 2.5-.33c.85 0 1.71.11 2.5.33c1.91-1.29 2.75-1.02 2.75-1.02c.55 1.35.2 2.39.1 2.64c.65.71 1.03 1.6 1.03 2.71c0 3.82-2.34 4.66-4.57 4.91c.36.31.69.92.69 1.85V21c0 .27.16.59.67.5C19.14 20.16 22 16.42 22 12A10 10 0 0 0 12 2Z"></path><!-- HTML_TAG_END -->
                            </svg>
                            <span><!-- HTML_TAG_START -->Deploy to Github<!-- HTML_TAG_END --></span>
                        </h3>
                        <p data-key="items[3].description"><!-- HTML_TAG_START -->
                            <h2 id="deployyoursitetoagithubrepositoryfromthereyoucaneasilydeployittoanywebhost">Deploy your site to a Github repository. From there you can easily deploy it to any web host.</h2><!-- HTML_TAG_END -->
                        </p>
                    </li>
                    <li>
                        <h3><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="" role="img" width="1em" height="1em" viewBox="0 0 24 24"><!-- HTML_TAG_START -->
                                <g fill="currentColor">
                                    <path fill-rule="evenodd" d="M14 7a1 1 0 0 0-1 1v8a1 1 0 0 0 1 1h4a1 1 0 0 0 1-1V8a1 1 0 0 0-1-1h-4Zm3 2h-2v6h2V9Z" clip-rule="evenodd"></path>
                                    <path d="M6 7a1 1 0 0 0 0 2h4a1 1 0 1 0 0-2H6Zm0 4a1 1 0 1 0 0 2h4a1 1 0 1 0 0-2H6Zm-1 5a1 1 0 0 1 1-1h4a1 1 0 1 1 0 2H6a1 1 0 0 1-1-1Z"></path>
                                    <path fill-rule="evenodd" d="M4 3a3 3 0 0 0-3 3v12a3 3 0 0 0 3 3h16a3 3 0 0 0 3-3V6a3 3 0 0 0-3-3H4Zm16 2H4a1 1 0 0 0-1 1v12a1 1 0 0 0 1 1h16a1 1 0 0 0 1-1V6a1 1 0 0 0-1-1Z" clip-rule="evenodd"></path>
                                </g><!-- HTML_TAG_END -->
                            </svg>
                            <span><!-- HTML_TAG_START -->
                                Themes
                                <!-- HTML_TAG_END --></span>
                        </h3>
                        <p>Hit the ground running with one of Primo's free themes and customize it in seconds using CSS variables.</p>
                    </li>
                    <li>
                        <h3><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="" role="img" width="1em" height="1em" viewBox="0 0 24 24"><!-- HTML_TAG_START -->
                                <g fill="currentColor">
                                    <path d="M8.51 2h6.98c.232 0 .41 0 .566.015c1.108.109 2.015.775 2.4 1.672H5.544c.385-.897 1.292-1.563 2.4-1.672C8.098 2 8.276 2 8.51 2Zm-2.2 2.723c-1.39 0-2.53.84-2.91 1.954a2.587 2.587 0 0 0-.024.07c.398-.12.813-.2 1.232-.253c1.08-.139 2.446-.139 4.032-.139h6.892c1.586 0 2.951 0 4.032.139c.42.054.834.132 1.232.253a2.173 2.173 0 0 0-.023-.07c-.38-1.114-1.52-1.954-2.911-1.954H6.31Z"></path>
                                    <path fill-rule="evenodd" d="M8.672 7.542h6.656c3.374 0 5.062 0 6.01.987c.947.987.724 2.511.278 5.56l-.422 2.892c-.35 2.391-.525 3.587-1.422 4.303c-.897.716-2.22.716-4.867.716h-5.81c-2.646 0-3.97 0-4.867-.716c-.897-.716-1.072-1.912-1.422-4.303l-.422-2.891c-.447-3.05-.67-4.574.278-5.561c.948-.987 2.636-.987 6.01-.987ZM8 18c0-.414.373-.75.833-.75h6.334c.46 0 .833.336.833.75s-.373.75-.833.75H8.833c-.46 0-.833-.336-.833-.75Z" clip-rule="evenodd"></path>
                                </g><!-- HTML_TAG_END -->
                            </svg>
                            <span><!-- HTML_TAG_START -->Primo Library<!-- HTML_TAG_END --></span>
                        </h3>
                        <p>Access a growing library of pre-built blocks which automatically adapt to your site's design.</p>
                    </li>
                </ul>

                </div>
    <div id="section-3d86c4f7">
                <h2>Spin up speedy, secure, scalable static sites in seconds.</h2>
                <p><!-- HTML_TAG_START -->
                    <h2>Set up your own Primo server in under 5 minutes and manage unlimited sites with ease. Don't want to manage your own server? Try Primo Cloud for free.</h2><!-- HTML_TAG_END -->
                </p>
                <p><a href="https://docs.primocms.org/getting-started"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="" role="img" width="1em" height="1em" viewBox="0 0 512 512"><!-- HTML_TAG_START -->
                            <ellipse cx="256" cy="128" fill="none" stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="32" rx="192" ry="80"></ellipse>
                            <path fill="none" stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="32" d="M448 214c0 44.18-86 80-192 80S64 258.18 64 214m384 86c0 44.18-86 80-192 80S64 344.18 64 300"></path>
                            <path fill="none" stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="32" d="M64 127.24v257.52C64 428.52 150 464 256 464s192-35.48 192-79.24V127.24"></path><!-- HTML_TAG_END -->
                        </svg>
                        Self-host
                    </a>
                    <a href="https://primocms.org/cloud"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="" role="img" width="1em" height="1em" viewBox="0 0 24 24"><!-- HTML_TAG_START -->
                            <path fill="currentColor" d="M12 6c2.62 0 4.88 1.86 5.39 4.43l.3 1.5l1.53.11A2.98 2.98 0 0 1 22 15c0 1.65-1.35 3-3 3H6c-2.21 0-4-1.79-4-4c0-2.05 1.53-3.76 3.56-3.97l1.07-.11l.5-.95A5.469 5.469 0 0 1 12 6m0-2C9.11 4 6.6 5.64 5.35 8.04A5.994 5.994 0 0 0 0 14c0 3.31 2.69 6 6 6h13c2.76 0 5-2.24 5-5c0-2.64-2.05-4.78-4.65-4.96A7.49 7.49 0 0 0 12 4z"></path><!-- HTML_TAG_END -->
                        </svg>
                        Primo Cloud
                    </a>
                </p>
            </div>
    <section id="section-dbc84ff9">
            <h2>Frequently Asked Questions</h2>
            <div><p>Primo is under full-time development and is in the process of becoming a nonprofit organization. Any funds generated from White Glove and Cloud will go towards funding further development, in the same vein as <a href="https://ghost.org/">Ghost CMS</a>.</p>
                    
                </div>
        </section>
    <div id="section-b18b744b">
                <div>
                    <h2>Hear about future updates, including:</h2>
                    <h3><!-- HTML_TAG_START -->
                        <ul>
                            <li>
                                <p><strong>Using it headless</strong> alongside SvelteKit, NextJS, etc.</p>
                            </li>
                            <li>
                                <p><strong>Design fields</strong> to give content editors predefined style options.</p>
                            </li>
                            <li>
                                <p><strong>Cloud functions</strong> for writing backend code from Primo.</p>
                            </li>
                        </ul><!-- HTML_TAG_END -->
                    </h3>
                </div>
                <div>
                    
                    <p><img src="https://track.mailerlite.com/webforms/o/5039306/j2m2z7?v1637419080" width="1" height="1" alt=".">
                </p></div>
                
                
            </div>
    

    


</div>]]></description>
        </item>
    </channel>
</rss>