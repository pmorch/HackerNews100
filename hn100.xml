<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Fri, 05 Apr 2024 18:00:05 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[M 4.7 Earthquake 7 km N of Whitehouse Station, New Jersey – USGS (354 pts)]]></title>
            <link>https://earthquake.usgs.gov/earthquakes/eventpage/at00sbh3yv/executive</link>
            <guid>39942880</guid>
            <pubDate>Fri, 05 Apr 2024 14:34:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://earthquake.usgs.gov/earthquakes/eventpage/at00sbh3yv/executive">https://earthquake.usgs.gov/earthquakes/eventpage/at00sbh3yv/executive</a>, See on <a href="https://news.ycombinator.com/item?id=39942880">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <p>
            The Earthquake Event Page application supports most recent browsers,
            <a href="https://angular.io/guide/browser-support">view supported browsers</a>. Or, try our
            <a href="https://earthquake.usgs.gov/earthquakes/feed/">Real-time Notifications, Feeds, and Web Services</a>.
          </p>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[So you wanna de-bog yourself (152 pts)]]></title>
            <link>https://www.experimental-history.com/p/so-you-wanna-de-bog-yourself</link>
            <guid>39942288</guid>
            <pubDate>Fri, 05 Apr 2024 13:43:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.experimental-history.com/p/so-you-wanna-de-bog-yourself">https://www.experimental-history.com/p/so-you-wanna-de-bog-yourself</a>, See on <a href="https://news.ycombinator.com/item?id=39942288">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0e291074-3499-4db2-9bf9-95886db0a438_1725x1225.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0e291074-3499-4db2-9bf9-95886db0a438_1725x1225.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0e291074-3499-4db2-9bf9-95886db0a438_1725x1225.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0e291074-3499-4db2-9bf9-95886db0a438_1725x1225.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0e291074-3499-4db2-9bf9-95886db0a438_1725x1225.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0e291074-3499-4db2-9bf9-95886db0a438_1725x1225.jpeg" width="594" height="421.8379120879121" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/0e291074-3499-4db2-9bf9-95886db0a438_1725x1225.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1034,&quot;width&quot;:1456,&quot;resizeWidth&quot;:594,&quot;bytes&quot;:359033,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0e291074-3499-4db2-9bf9-95886db0a438_1725x1225.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0e291074-3499-4db2-9bf9-95886db0a438_1725x1225.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0e291074-3499-4db2-9bf9-95886db0a438_1725x1225.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0e291074-3499-4db2-9bf9-95886db0a438_1725x1225.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a><figcaption>Photo cred: my dad</figcaption></figure></div><p>Strangers sometimes ask me for advice, which is both flattering and alarming, because I only know about the things I write here, and sometimes not even those. </p><p>For instance, someone recently asked me if I had any advice about how to teach people to fly planes, which makes me wonder: who’s running the pilot education system?? Now, whenever I get on a plane, I scrutinize the captain to see if they have that “A blogger taught me how to fly” kind of look.</p><p><span>I often don't know how to respond to such questions, on account of my general incompetence. But I've realized that most of these folks have something in common: they're </span><em>stuck</em><span>. They’re looking for advice less in the sense of “any good restaurants around here?” and more in the sense of “everything kinda sucks right now and I’d like to change that but I don’t know how?”</span></p><p><span>Being stuck is the psychological equivalent of standing knee-deep in a fetid bog, bog in every direction, bog as far as the eye can see. You go wading in search of dry land and only find more bog. Nothing works, no options seem good, it’s all bleh and meh and ho hum and no thanks and </span><em>more bog</em><span>. This is the kind of dire situation that drives people to do crazy things like ask a blogger for advice.</span></p><p>Fortunately, I’ve spent much of my life in that very bog. Some say I was born in it, a beautiful bouncing baby bog boy. And I've learned that no matter how you ended up there—your marriage has stalled, you're falling behind in your classes, your trainee pilots keep flying into the side of a mountain—the forces that keep you in the bog are always the same. There are, in fact, only three, although they each come in a variety of foul flavors.</p><p><span>It's a new year, the annual Great De-bogging, when we all attempt to heave ourselves out of the muck and into a better life. So here, to aid you, is my compendium of bog phenomena, the myriad ways I get myself stuck, because unsticking myself always seems to be a matter of finding a name for the thing happening to me.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1-140270094" href="https://www.experimental-history.com/p/so-you-wanna-de-bog-yourself#footnote-1-140270094" target="_self" rel="">1</a></span><span> May this catalog serve you well, and may your planes always be flown by people who never learned anything from me. </span></p><p>Most of my attempts to get unstuck look, from the outside, like I'm doing nothing at all. I'm standing motionless in the bog, crying, “THIS IS ME TRYING!” That means I've got insufficient activation energy—I can't muster the brief but extraordinary output of effort it takes to escape the bog, so I stay right where I am.</p><p>There are few different ways to end up here. </p><p>People will sometimes approach me with projects I don't really want to do. But if I do them, those people will smile and shake my hand and go, “We feel positive emotions, and it's because of you!” and that will feel good. So I often end up signing on to these projects, feeling resentful the whole time, cursing myself for choosing—freely!—to work hard on things I don't care about.</p><p><span>This is </span><em>gutterballing</em><span>: excelling, but in slightly the wrong direction. For most of its journey, after all, the gutterball is getting closer to the pins. It's only at the end that it barely, but dramatically, misses.</span></p><p>Gutterballing is a guaranteed way to stay stuck in the bog because people will love you for it. “You're doing the right thing!” they'll shout as you sink into the swamp. “We approve of this!”</p><p><span>Sometimes when I'm stuck, someone will be like, “Why don't you do [reasonable option]?” and I'll go, “Hold on there, buddy! Don't you see this option has </span><em>downsides</em><span>? Find me one with only upsides, and then we'll talk!”</span></p><p><span>I'm </span><em>waiting for jackpot</em><span>, refusing to do anything until an option arises that dominates all other options on all dimensions. Strangely, this never seems to happen. </span></p><p>Often, I'm waiting for the biggest jackpot of all: the spontaneous remission of all my problems without any effort required on my part. Someone suggests a way out of my predicament and I go, “Hmm, I dunno, do you have any solutions that involve me doing everything 100% exactly like I'm doing it right now, and getting better outcomes?”</p><p><span>Okay, this is a version of </span><em>waiting for jackpot</em><span>, but it's so common that it deserves its own entry. </span></p><p>Sometimes I'll know exactly what I need to do in order to leave the bog, but I'm too afraid to do it. I'm afraid to tell the truth, or make someone mad, or take a risk. And so I dither, hoping that the future will not require me to be brave. </p><p><span>Everybody thinks this is a bad strategy because it merely prolongs my suffering, but that's not why it's a dumb thing to do. Yes, every moment I dither is a moment I suffer. But when I finally do the brave thing, that's not the climax of my suffering—that moment is the </span><em>opposite </em><span>of suffering. Being brave feels good. I mean, have you ever stood up to a bully, or conquered stage fright, or finally stopped being embarrassed about what you love? It's the most wonderful feeling in the world. Whenever you chicken out, you don't just feel the pain of cowardice; you miss out on the pleasure of courage.</span></p><p><span>Medieval knights used to wander around hoping for honorable adventures to pop up so that they could demonstrate their bravery. They were </span><em>desperate</em><span> for big, scary dragons to appear. When I put off doing the brave thing, I am </span><em>declining the dragon</em><span>: missing an opportunity to do something that might be scary in the moment but would ultimately make me feel great.</span></p><p><span>About half of my friends </span><em>kind of </em><span>hate their jobs, so they're moderately unhappy most of the time, but never unhappy enough to leave. This is the </span><em>mediocrity trap</em><span>: situations that are bad-but-not-too-bad keep you forever in their orbit because they never inspire the frustration it takes to achieve escape velocity.</span></p><p>The mediocrity trap is a nasty way to end up in the bog. Terrible situations, once exited, often become funny stories or proud memories. Mediocre situations, long languished in, simply become Lost Years—boring to both live through and talk about, like you're sitting in a waiting room with no cell reception, no wifi, and no good magazines, waiting for someone to come in and tell you it's time to start living.</p><p><span>(I have previously written about this phenomenon as an </span><a href="https://www.experimental-history.com/p/underrated-ideas-in-psychology" rel="">underrated idea in psychology</a><span>.)</span></p><p>I spend a lot of time thinking about my problems, but it usually looks like this:</p><p><span>“Oh boy, what a problem! A real whopper, I'd say. Massive, even. Get a load of this problem, would ya! Wowzers!” I can spend </span><em>days </em><span>doing this. “How big would you say that problem is? Large? Huge? And that's just its size! Don't get me started on its depth.”</span></p><p><span>This isn't solving the problem; this is </span><em>stroking </em><span>the problem. It looks like a good use of time, but it's just a form of </span><a href="https://www.experimental-history.com/p/socially-acceptable-anxiety-is-still" rel="">socially acceptable anxiety</a><span>, a way to continue your suffering indefinitely by becoming obsessed with it.</span></p><p>Even if you've worked up a big enough head of steam to launch yourself out of the bog, you still have to aim properly. (“I’m doing it! I'm doing it!” I shout as I crash land onto my launch pad.)</p><p>Here are a few of my recurring bad escape plans:</p><p><span>I played a lot of </span><em>Call of Duty </em><span>in high school, and I used to roll with a gang of bad boys who would battle other gangs online.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-2-140270094" href="https://www.experimental-history.com/p/so-you-wanna-de-bog-yourself#footnote-2-140270094" target="_self" rel="">2</a></span></p><p>We weren't very good. Whenever we lost the first round, which was almost always, we would regroup in the pregame lobby—basically the online locker room—and decide what we really need to do in the next round is “try harder.” As if the reason we had all just been shot in the head 25 times in a row was that we were not sufficiently dedicated to avoiding getting shot in the head. Armed with the most dimwit plan of all time, we would march into battle once more and lose just as badly. As our virtual corpses piled up, we'd yell at each other, “Guys, stop dying!”</p><p><span>This is the </span><em>try harder fallacy</em><span>. I behold my situation and conclude that, somehow, I will improve it in the future by just sort of wishing it to be different, and then I get indignant that nothing happens. Like, “Um, excuse me! I've been doing all of this very diligent </span><em>desiring </em><span>for things to be different, and yet they remain the same, could someone please look into this?”</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-3-140270094" href="https://www.experimental-history.com/p/so-you-wanna-de-bog-yourself#footnote-3-140270094" target="_self" rel="">3</a></span></p><p><span>The </span><em>try harder fallacy </em><span>has a cousin called the</span><em> infinite effort illusion</em><span>, which is the idea that you have this secret unused stock of effort that you can deploy in the future to get yourself unstuck. I'm always a week late responding to emails? No problem, I'll simply uncork my Strategic Effort Reserve and clear my correspondence debt.</span></p><p>This never works because there is no Strategic Effort Reserve. All of my effort is currently accounted for somewhere. If I want to spend more of it on something, I have to spend less of it on something else. If I’m consistently not getting something done, it’s probably because I don’t want to—at least, not enough to cannibalize that time from something else—and I haven’t admitted that to myself yet. </p><p>I spend a lot of stints in the bog wailing about how I don’t have enough time. “Oh, if there were only 25 hours in the day,” I lament, “the things I would accomplish!”</p><p>But here’s a stupid question: what am I mad about, exactly? That I don't have a time-turner? That I can’t find a little eddy in the spacetime continuum where I can hide out while I cross a few more things off my to-do list? Do I really believe that the way to get unstuck is to ruminate on how unfair it is that time marches ever forward at one second per second?</p><p><span>This is </span><em>blaming God</em><span>: pinning the responsibility for my current predicament on something utterly unchangeable. And while many religions teach that God intervenes in human affairs, none of them, as far as I know, believe that he responds to whining. (Would </span><em>you </em><span>worship a god who does miracles if you just annoy him enough?)</span></p><p><span>Some problems are like getting a diploma: you work at it for a while, and then you're done forever. Learning how to ride a bike is a classic </span><em>diploma problem</em><span>. </span></p><p><span>But most problems aren’t like that. They’re more like </span><em>toothbrushing problems</em><span>: you have to work at them forever until you die. You can’t, as far as I know, just brush your teeth really really well and then let ‘em ride forever.</span></p><p><span>When I had a </span><a href="https://www.experimental-history.com/p/its-very-weird-to-have-a-skull-full" rel="">skull full of poison</a><span>, I assumed feeling good again was a diploma problem. I just had to find the right lever to pull and—yoink!—back to the good times forever. People warned me it wasn't going to be like this and I didn't believe them; I assumed they had simply failed to earn their diplomas.</span></p><p>I only started making progress when I realized I was facing a toothbrushing problem: feeling normal again would probably require me to do stuff every day for the rest of my life. I might get better at doing that stuff, just like when you first start brushing your teeth as a kid you get toothpaste everywhere and end up swallowing half of it, and eventually you learn not to do that. But even when you're a toothbrushing expert, it still takes you a couple minutes every day. You could be mad about that, but it won’t make your teeth any cleaner. </p><p>Here’s one of my favorite bad escape plans: I’ll just be a different person in the future. Like, “I know I hate working out, but in the future I will overcome this by not being such a baby about it.” Or, “I find quantum physics boring, so I’ll just learn about it later, when I find it more interesting.”</p><p><span>These are </span><em>fantastical metamorphoses</em><span>. I have not, so far, woken up one day and found myself different in all the ways that would make my life easier. I do hope this happens, but I’ve stopped betting on it. </span></p><p>People are always causing me problems by doing foolish things like trying to drive on highways while I'm also trying to drive on them, or expecting me to pay rent every month, or not realizing my genius and putting me in charge of things. In these cases, it feels like the only solution is to get other people to act differently. I'm only stuck because other people are unreasonable!</p><p><span>A good word for this is </span><em>puppeteering</em><span>: trying to solve your problems by controlling the actions of other humans. Puppeteering often looks attractive because other people's actions seem silly and therefore easily changeable. Funnily enough, it doesn't feel that way to them. They have lifetimes of backstory that lead them to act the way that they do, and their actions are, on average, only as changeable as yours. So unless you think of yourself as being easily redirected with a few tugs of your strings, puppeteering is probably not going to get you out of the bog.</span></p><p><span>A confession: most of my bogs are imaginary. The world doesn’t stick me there; </span><em>I </em><span>stick me there. These are, paradoxically, the most difficult bogs to escape, because it requires realizing that my perception of reality is not reality, and a lot of the mind is dedicated to preventing that exact thought.</span></p><p>Every kid learns to play the “floor is lava” game, where you pretend that you'll get incinerated if you touch the carpet. Even toddlers can pick it up, which reveals something profound: very early on, we acquire the ability to pretend that fake problems are real. We then spend the rest of our lives doing exactly that.</p><p><span>Often, when I’m stuck, it’s because I've made up a game for myself and decided that I’m losing at it. I haven’t achieved enough. I am not working hard enough and I am also, somehow, not having enough fun. These games have elaborate rules, like “I have to be as successful as my most successful friend, but everything I've done so far doesn't count,” and I’m supposed to feel very bad if I break them. It’s like playing the absolute dumbest version of </span><em>the floor is lava</em><span>.</span></p><p><span>Did I create these games by thinking really hard about how to live a good life? No! I pulled them out of my butt. Or someone else pulled them out of </span><em>their </em><span>butt, and I said, “Ooh, can I have some of that?”</span></p><p>During the Trump administration, I took on a part time job: keeping up with all the outrages. Every twenty minutes or so I would have to check my phone in case any new outrages had occurred, so that I could...collect them? Make them into a scrapbook? I'm not sure. </p><p><span>I now think of this as </span><em>super surveillance</em><span>, tracking every problem in the world as if they were all somehow, ultimately, my problems. Super surveillance is an express ticket to the bog, because the world is full of problems and you'd be lucky to solve even a single one.</span></p><p><span>I know some people think that super surveillance is virtuous, but they mainly seem to spend their time looking at screens and feeling bad, and this doesn't seem to solve any of the problems that they're monitoring. To them, I suppose, the most saintly life possible is one spent sitting in front of a hundred screens, eyelids held open with surgical instruments, </span><em>A Clockwork Orange</em><span>-style, bearing witness to all human suffering simultaneously. I, uh, feel differently.</span></p><p><span>(See also: </span><a href="https://www.experimental-history.com/p/reading-the-news-is-the-new-smoking" rel="">Reading the news is the new smoking</a><span>.)</span></p><p>Sometimes I get this feeling like, “Nothing will ever work out for me, I will always be unhappy, the rest of my life will be a sort of wandering twilight punctuated with periods of misery.”</p><p>And my wife will go, “You're hungry.”</p><p>And I'll go, “No, no, this is true unhappiness, it comes to me unadulterated from hell itself, it lives inside my bones, I am persecuted by God, you could not possibly know what it's like to be me.”</p><p>And then I'll eat a burrito and be like, “Never mind I'm fine!”</p><p><span>This is </span><em>hedgehogging</em><span>: refusing to be influenced by others, even when you should. </span></p><p>You know how, when you go up in a tall building and look down at the street, everybody looks not just small, but kind of silly? Like, “Aww, look at those tiny little guys, walking around in their suits like they're people! They don't even know they're so small!”</p><p><span>This is how other people's problems</span><em> </em><span>look to me. A friend will tell me, “I'm stressed!” and I'll go, “Aww, what a silly little problem, walking around like it's real! Just don't be stressed, and then you won't be stressed!”</span></p><p><em>My </em><span>problems, on the other hand, are like 50-foot-tall moody teenagers. They're so big and so real and so complicated! They cannot possibly be solved! I can only flee from them, hide among the rubble, and peek out at them with horror!</span></p><p><span>Such is the result of the </span><em>personal problems growth ray</em><span>, which makes all of your own problems seem larger than life, while other people's stay actual size. This makes reasonable solutions look unreasonable—the actions that solved </span><em>your</em><span> human-sized problems could never solve </span><em>my</em><span> giganto-problems; they can only be addressed with either a lifetime of cowering or a tactical nuke.</span></p><p>In graduate school, I made the terrible mistake of signing up for a professional development seminar. We would convene every week for 90 minutes of discussions like “OH NO WE'LL NEVER GET PROFESSOR JOBS WE'RE ALL SCREWED” and “THE WORLD IS TOO MUCH AND I AM TOO SMALL” and “HELP HELP HELP”.</p><p>One week, we spent half the session arguing about whether you should print your name in bold when listing your publications on your CV. Like:</p><blockquote><p><span>Tweedledum, M.R. &amp; Mastroianni, A.M.,&nbsp; (2024). Please give me a job I will do anything, including publishing this terrible paper. </span><em>The Journal of Desperation, 4</em><span>(12), 122-137.</span></p></blockquote><p>vs.</p><blockquote><p><span>Tweedledum, M.R. &amp; </span><strong>Mastroianni, A.M.</strong><span>, (2024). Please give me a job I will do anything, including publishing this terrible paper. </span><em>The Journal of Desperation, 4</em><span>(12), 122-137.</span></p></blockquote><p><span>Some people thought bolding your name helps time-pressed hiring committees quickly assess your academic output. Other people objected that bolding your name looks presumptuous. A debate ensued. I forget who won—oh yes, it was </span><em>none of us </em><span>because this is a stupid thing to care about. </span></p><p><span>This is </span><em>obsessing over tiny predictors</em><span>. It's scary to admit that you can't control the future; it's a lot easier to distract yourself by trying to optimize every decision, no matter how insignificant. </span></p><p>(If you're at the point where you're spending 45 minutes debating the use of bold letters on your CV, perhaps you should consider pulling up a list of every god and praying to all of them in turn, in case one of them is real and decides to help you.)</p><p><span>Parents who want to get their kids into elite colleges have perfected the art of obsessing over tiny predictors. When I gave campus tours, I would run into them all the time: “Should my kid play the timpani or the oboe?” “How many semicolons can you use in the personal essay?” “Can we include dental records to demonstrate a history of good brushing?” The joke was on them, of course: stressing about all those tiny things only makes you anxious, and even if your kid gets into a fancy school, they could still end up as a </span><em>blogger</em><span>.</span></p><p><span>Sometimes people will be like, “Well, whatcha gonna do, life is suffering,” and I’ll be like, “Haha sure is,” waiting for them to laugh too, but they won’t laugh, and I’ll realize, to my horror, that </span><em>they’re not joking</em><span>. Some people think the bog is </span><em>life</em><span>!</span></p><p><span>I get why you might think this if you’ve experienced lots of misfortune. If you, say, </span><a href="https://en.wikipedia.org/wiki/Tsutomu_Yamaguchi" rel="">survived</a><span> the atomic bombing of Hiroshima and then took the train to Nagasaki just in time for the atomic bombing of that city, too, you'd probably have a gloomy outlook on life.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-4-140270094" href="https://www.experimental-history.com/p/so-you-wanna-de-bog-yourself#footnote-4-140270094" target="_self" rel="">4</a></span></p><p><span>But most of the people I know who feel this way haven’t survived any atomic bombings at all. They’re usually people with lots of education and high-paying jobs and supportive relationships and a normal amount of tragedies, people who have all the raw materials for a good life but can’t seem to make one for themselves. Their problem is they believe that </span><em>satisfaction is impossible</em><span>. Like they’re standing in a kitchen full of eggs, flour, oil, sugar, butter, baking powder, a mixer, and an oven, and they throw their hands up and say, “I can’t make a cake! Cakes don’t even exist!”</span></p><p>In the big scheme of things, I haven't been alive for all that long. So there are probably lots of ways into the bog I haven't discovered yet. But I've been down there enough times to see the same patterns repeat, and sometimes I can even interrupt them. </p><p>That's why having goofy names for them matters so much, because it reminds me not to believe the biggest bog lie of all: that I'm stuck in a situation unlike any I, or anyone else, has ever seen before. If you believe that, it's no wonder you'd suffer from insufficient activation energy, or bad escape plans, or self-bogging: you have no idea what to do, because you don't think anything you've learned, or anything anyone else has learned, can help you at all. Whenever I feel that way, whenever I think I'm in a bespoke bog, created just for me by a universe that hates me, if I can think to myself, “Oh, I'm gutterballing right now,” I can feel my foot hit solid ground, and I can start hoisting myself onto dry land.</p><p><span>So, best of luck in 2024, and all the years to come after that. May you only spend as much time in the bog as is necessary to learn the lessons it has to teach you. And for goodness sake, if you see the side of a mountain coming toward you, </span><em>pull up</em><span>.</span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Top Israeli spy chief exposes his true identity in online security lapse (244 pts)]]></title>
            <link>https://www.theguardian.com/world/2024/apr/05/top-israeli-spy-chief-exposes-his-true-identity-in-online-security-lapse</link>
            <guid>39942122</guid>
            <pubDate>Fri, 05 Apr 2024 13:28:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/world/2024/apr/05/top-israeli-spy-chief-exposes-his-true-identity-in-online-security-lapse">https://www.theguardian.com/world/2024/apr/05/top-israeli-spy-chief-exposes-his-true-identity-in-online-security-lapse</a>, See on <a href="https://news.ycombinator.com/item?id=39942122">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>The identity of the commander of Israel’s Unit 8200 is a closely guarded secret. He occupies one of the most sensitive roles in the military, leading one of the world’s most powerful surveillance agencies, comparable<strong> </strong>to the US National Security Agency.</p><p>Yet after spending more than two decades operating in the shadows, the Guardian can reveal how the controversial spy chief – whose name is Yossi Sariel – has left his identity exposed online.</p><p>The embarrassing security lapse is linked to a book he published on Amazon, which left a digital trail to a private Google account created in his name, along with his unique ID and links to the account’s maps and calendar profiles.</p><p>The Guardian has confirmed with multiple sources that Sariel is the secret author of The Human Machine Team, a book in which he offers a radical vision for how artificial intelligence can transform the relationship between military personnel and machines.</p><p>Published in 2021 using a pen name composed of his initials, Brigadier General YS, it provides a blueprint for the advanced AI-powered systems that the Israel Defense Forces (IDF) have been pioneering during the six-month war in <a href="https://www.theguardian.com/world/gaza" data-link-name="in body link" data-component="auto-linked-tag">Gaza</a>.</p><p>An electronic version of the book included an anonymous email address that can easily be traced to Sariel’s name and Google account. Contacted by the Guardian, an IDF spokesperson said the email address was not Sariel’s personal one, but “dedicated specifically for issues to do with the book itself”.</p><gu-island name="InteractiveBlockComponent" priority="critical" deferuntil="idle" props="{&quot;url&quot;:&quot;https://interactive.guim.co.uk/embed/from-tool/generic/index.html?vertical=News&amp;opinion-tint=false&amp;title=Get%20in%20touch&amp;description=Do%20you%20have%20information%20about%20this%20story%3F%20Email%20%3Ca%20style%3D%22color%3A%23ab0613%22%20href%3D%22mailto%3Aharry.davies%40theguardian.com%22%3Eharry.davies%40theguardian.com%3C%2Fa%3E%2C%20or%20(using%20a%20non-work%20phone)%20use%20%3Ca%20style%3D%22color%3A%23ab0613%22%20href%3D%22https%3A%2F%2Fsignal.me%2F%23p%2F%2B447721857348%22%3ESignal%3C%2Fa%3E%20or%20%3Ca%20style%3D%22color%3A%23ab0613%22%20href%3D%22https%3A%2F%2Fapi.whatsapp.com%2Fsend%3Fphone%3D447721857348%22%3EWhatsApp%3C%2Fa%3E%20to%20message%20%2B44%207721%20857348.%20For%20the%20most%20secure%20communications%2C%20use%20%3Ca%20style%3D%22color%3A%23ab0613%22%20href%3D%22https%3A%2F%2Fwww.theguardian.com%2Fsecuredrop%22%3ESecureDrop%3C%2Fa%3E%20or%20see%20%3Ca%20style%3D%22color%3A%23ab0613%22%20href%3D%22https%3A%2F%2Fwww.theguardian.com%2Fhelp%2Fng-interactive%2F2017%2Fmar%2F17%2Fcontact-the-guardian-securely%22%3Eour%20guide%3C%2Fa%3E.&amp;link=false&quot;,&quot;scriptUrl&quot;:&quot;https://interactive.guim.co.uk/embed/iframe-wrapper/0.1/boot.js&quot;,&quot;alt&quot;:&quot;Do you have information about this story? Email harry.davies@theguardian.com, or (using a non-work phone) use Signal or WhatsApp to message +44 7721 857348.&quot;,&quot;format&quot;:{&quot;display&quot;:0,&quot;theme&quot;:0,&quot;design&quot;:0},&quot;elementId&quot;:&quot;af82107b-9f03-4ad8-9e96-5fdc485038ae&quot;,&quot;isMainMedia&quot;:false}" config="{&quot;renderingTarget&quot;:&quot;Web&quot;,&quot;darkModeAvailable&quot;:false}"><figure id="af82107b-9f03-4ad8-9e96-5fdc485038ae" data-alt="Do you have information about this story? Email harry.davies@theguardian.com, or (using a non-work phone) use Signal or WhatsApp to message +44 7721 857348." data-testid="interactive-element-Do%20you%20have%20information%20about%20this%20story?%20Email%20harry.davies@theguardian.com,%20or%20(using%20a%20non-work%20phone)%20use%20Signal%20or%20WhatsApp%20to%20message%20+44%207721%20857348." data-spacefinder-role="inline"><a data-name="placeholder" href="https://interactive.guim.co.uk/embed/from-tool/generic/index.html?vertical=News&amp;opinion-tint=false&amp;title=Get%20in%20touch&amp;description=Do%20you%20have%20information%20about%20this%20story%3F%20Email%20%3Ca%20style%3D%22color%3A%23ab0613%22%20href%3D%22mailto%3Aharry.davies%40theguardian.com%22%3Eharry.davies%40theguardian.com%3C%2Fa%3E%2C%20or%20(using%20a%20non-work%20phone)%20use%20%3Ca%20style%3D%22color%3A%23ab0613%22%20href%3D%22https%3A%2F%2Fsignal.me%2F%23p%2F%2B447721857348%22%3ESignal%3C%2Fa%3E%20or%20%3Ca%20style%3D%22color%3A%23ab0613%22%20href%3D%22https%3A%2F%2Fapi.whatsapp.com%2Fsend%3Fphone%3D447721857348%22%3EWhatsApp%3C%2Fa%3E%20to%20message%20%2B44%207721%20857348.%20For%20the%20most%20secure%20communications%2C%20use%20%3Ca%20style%3D%22color%3A%23ab0613%22%20href%3D%22https%3A%2F%2Fwww.theguardian.com%2Fsecuredrop%22%3ESecureDrop%3C%2Fa%3E%20or%20see%20%3Ca%20style%3D%22color%3A%23ab0613%22%20href%3D%22https%3A%2F%2Fwww.theguardian.com%2Fhelp%2Fng-interactive%2F2017%2Fmar%2F17%2Fcontact-the-guardian-securely%22%3Eour%20guide%3C%2Fa%3E.&amp;link=false">Do you have information about this story? Email harry.davies@theguardian.com, or (using a non-work phone) use Signal or WhatsApp to message +44 7721 857348.</a></figure></gu-island><p>The security blunder is likely to place further pressure on Sariel, who is said to “live and breathe” intelligence but whose tenure running the IDF’s elite cyber intelligence division has become mired in controversy.</p><p>Unit 8200, once revered within Israel and beyond for intelligence capabilities that rivalled those of the UK’s GCHQ, is thought to have built a vast surveillance apparatus to closely monitor the <a href="https://www.theguardian.com/world/palestinian-territories" data-link-name="in body link" data-component="auto-linked-tag">Palestinian territories</a>.</p><p>However, it has been criticised over its failure to foresee and prevent Hamas’s deadly 7 October assault last year on southern Israel, in which Palestinian militants killed nearly 1,200 Israelis and kidnapped about 240 people.</p><p>Since the Hamas-led attacks, there have been accusations that Unit 8200’s “technological hubris” came at the expense of more conventional intelligence-gathering techniques.</p><p>In its war in Gaza, the IDF appears to have fully embraced Sariel’s vision of the future, in which military technology represents a new frontier where AI is being used to fulfil increasingly complex tasks on the battlefield.</p><figure id="d40a9427-66eb-4f33-8ae5-ac2a73e09213" data-spacefinder-role="showcase" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-2"><picture><source srcset="https://i.guim.co.uk/img/media/f9c3ded3c6dabea6c0aaf7257ce69d90eeeb39f5/0_165_4937_2962/master/4937.jpg?width=880&amp;dpr=2&amp;s=none" media="(min-width: 1300px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 1300px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/f9c3ded3c6dabea6c0aaf7257ce69d90eeeb39f5/0_165_4937_2962/master/4937.jpg?width=880&amp;dpr=1&amp;s=none" media="(min-width: 1300px)"><source srcset="https://i.guim.co.uk/img/media/f9c3ded3c6dabea6c0aaf7257ce69d90eeeb39f5/0_165_4937_2962/master/4937.jpg?width=800&amp;dpr=2&amp;s=none" media="(min-width: 1140px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 1140px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/f9c3ded3c6dabea6c0aaf7257ce69d90eeeb39f5/0_165_4937_2962/master/4937.jpg?width=800&amp;dpr=1&amp;s=none" media="(min-width: 1140px)"><source srcset="https://i.guim.co.uk/img/media/f9c3ded3c6dabea6c0aaf7257ce69d90eeeb39f5/0_165_4937_2962/master/4937.jpg?width=640&amp;dpr=2&amp;s=none" media="(min-width: 980px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 980px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/f9c3ded3c6dabea6c0aaf7257ce69d90eeeb39f5/0_165_4937_2962/master/4937.jpg?width=640&amp;dpr=1&amp;s=none" media="(min-width: 980px)"><source srcset="https://i.guim.co.uk/img/media/f9c3ded3c6dabea6c0aaf7257ce69d90eeeb39f5/0_165_4937_2962/master/4937.jpg?width=620&amp;dpr=2&amp;s=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/f9c3ded3c6dabea6c0aaf7257ce69d90eeeb39f5/0_165_4937_2962/master/4937.jpg?width=620&amp;dpr=1&amp;s=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/f9c3ded3c6dabea6c0aaf7257ce69d90eeeb39f5/0_165_4937_2962/master/4937.jpg?width=605&amp;dpr=2&amp;s=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/f9c3ded3c6dabea6c0aaf7257ce69d90eeeb39f5/0_165_4937_2962/master/4937.jpg?width=605&amp;dpr=1&amp;s=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/f9c3ded3c6dabea6c0aaf7257ce69d90eeeb39f5/0_165_4937_2962/master/4937.jpg?width=445&amp;dpr=2&amp;s=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/f9c3ded3c6dabea6c0aaf7257ce69d90eeeb39f5/0_165_4937_2962/master/4937.jpg?width=445&amp;dpr=1&amp;s=none" media="(min-width: 320px)"><img alt="Debris among trees and Israeli officer" src="https://i.guim.co.uk/img/media/f9c3ded3c6dabea6c0aaf7257ce69d90eeeb39f5/0_165_4937_2962/master/4937.jpg?width=445&amp;dpr=1&amp;s=none" width="445" height="266.981972858011" loading="lazy"></picture></div><figcaption><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>The aftermath of the 7 October attacks at the Supernova music festival. Some have blamed Unit 8200’s ‘technological hubris’ for the intelligence failure.</span> Photograph: Manuel de Almeida/EPA</figcaption></figure><p>Sariel argued in the published book three years ago that his ideas about using machine learning to transform modern warfare should become mainstream. “We just need to take them from the periphery and deliver them to the centre of the stage,” he wrote.</p><p>One section of the book heralds the concept of an AI-powered “targets machine”, descriptions of which closely resemble the target recommendation systems the IDF is now known have been <a href="https://www.theguardian.com/world/2024/apr/03/israel-gaza-ai-database-hamas-airstrikes" data-link-name="in body link">relying upon in its bombardment of Gaza</a>.</p><p>Over the last six months, the IDF has deployed multiple AI-powered decision support systems that have been rapidly developed and refined by Unit 8200 under Sariel’s leadership.</p><p>They include <a href="https://www.theguardian.com/world/2023/dec/01/the-gospel-how-israel-uses-ai-to-select-bombing-targets" data-link-name="in body link">the Gospel</a> and <a href="https://www.theguardian.com/world/2024/apr/03/israel-gaza-ai-database-hamas-airstrikes" data-link-name="in body link">Lavender</a>, two target recommendation systems that have been revealed in reports by the Israeli-Palestinian publication <a href="https://www.972mag.com/lavender-ai-israeli-army-gaza/" data-link-name="in body link">+972 magazine</a>, its Hebrew-language outlet Local Call and the Guardian.</p><p>The IDF says its AI systems are intended to assist human intelligence officers, who are required to verify that military suspects are legitimate targets under international law. A spokesperson said the military used “various types of tools and methods”, adding: “Evidently, there are tools that exist in order to benefit intelligence researchers that are based on artificial intelligence.”</p><h2 id="targets-machine"><strong>Targets machine</strong></h2><p>On Wednesday, +972 and Local Call placed the spotlight on the link between Unit 8200 and the book authored by <a href="https://www.972mag.com/lavender-ai-israeli-army-gaza/" data-link-name="in body link">a mysteriously named Brigadier General YS</a>.</p><p>Sariel is understood to have written the book with the IDF’s permission after a year as a visiting researcher at the US National Defense University in Washington DC, where he made the case for using AI to transform modern warfare.</p><p>Aimed at high-ranking military commanders and security officials, the book articulates a “human-machine teaming” concept that seeks to achieve synergy between humans and AI, rather than constructing fully autonomous systems.</p><p>It reflects Sariel’s ambition to become a “thought leader”, according to one former intelligence official. In the 2000s, he was a leading member of a group of academically minded spies known as “the Choir”, which agitated for an overhaul of Israeli intelligence practices.</p><figure id="cf9d0f0e-4e8e-4b28-9f6b-ae965fdee7bb" data-spacefinder-role="showcase" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-3"><picture><source srcset="https://i.guim.co.uk/img/media/95300b36426b0d87b569f18ee8cae9ea9942e884/0_360_4032_2419/master/4032.jpg?width=880&amp;dpr=2&amp;s=none" media="(min-width: 1300px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 1300px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/95300b36426b0d87b569f18ee8cae9ea9942e884/0_360_4032_2419/master/4032.jpg?width=880&amp;dpr=1&amp;s=none" media="(min-width: 1300px)"><source srcset="https://i.guim.co.uk/img/media/95300b36426b0d87b569f18ee8cae9ea9942e884/0_360_4032_2419/master/4032.jpg?width=800&amp;dpr=2&amp;s=none" media="(min-width: 1140px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 1140px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/95300b36426b0d87b569f18ee8cae9ea9942e884/0_360_4032_2419/master/4032.jpg?width=800&amp;dpr=1&amp;s=none" media="(min-width: 1140px)"><source srcset="https://i.guim.co.uk/img/media/95300b36426b0d87b569f18ee8cae9ea9942e884/0_360_4032_2419/master/4032.jpg?width=640&amp;dpr=2&amp;s=none" media="(min-width: 980px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 980px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/95300b36426b0d87b569f18ee8cae9ea9942e884/0_360_4032_2419/master/4032.jpg?width=640&amp;dpr=1&amp;s=none" media="(min-width: 980px)"><source srcset="https://i.guim.co.uk/img/media/95300b36426b0d87b569f18ee8cae9ea9942e884/0_360_4032_2419/master/4032.jpg?width=620&amp;dpr=2&amp;s=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/95300b36426b0d87b569f18ee8cae9ea9942e884/0_360_4032_2419/master/4032.jpg?width=620&amp;dpr=1&amp;s=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/95300b36426b0d87b569f18ee8cae9ea9942e884/0_360_4032_2419/master/4032.jpg?width=605&amp;dpr=2&amp;s=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/95300b36426b0d87b569f18ee8cae9ea9942e884/0_360_4032_2419/master/4032.jpg?width=605&amp;dpr=1&amp;s=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/95300b36426b0d87b569f18ee8cae9ea9942e884/0_360_4032_2419/master/4032.jpg?width=445&amp;dpr=2&amp;s=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/95300b36426b0d87b569f18ee8cae9ea9942e884/0_360_4032_2419/master/4032.jpg?width=445&amp;dpr=1&amp;s=none" media="(min-width: 320px)"><img alt="Destruction near al-Shifa hospital in Gaza  " src="https://i.guim.co.uk/img/media/95300b36426b0d87b569f18ee8cae9ea9942e884/0_360_4032_2419/master/4032.jpg?width=445&amp;dpr=1&amp;s=none" width="445" height="266.9779265873016" loading="lazy"></picture></div><figcaption><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>Destruction near al-Shifa hospital in Gaza on 1 April. The book argues that using AI to create military targets can be more efficient.</span> Photograph: Anadolu/Getty Images</figcaption></figure><p>An Israeli press report suggests that by 2017 he was head of intelligence for the IDF’s central command. His subsequent elevation to commander of Unit 8200 amounted to an endorsement by the military establishment of his technological vision for the future.</p><p>Sariel refers in the book to “a revolution” in recent years within the IDF, which has “developed a new concept of intelligence centric warfare to connect intelligence to the fighters in the field”. He advocates going further still, fully merging intelligence and warfare, in particular when conducting lethal targeting operations.</p><p>In one chapter of the book, he provides a template for how to construct an effective targets machine drawing on “big data” that a human brain could not process. “The machine needs enough data regarding the battlefield, the population, visual information, cellular data, social media connections, pictures, cellphone contacts,” he writes. “The more data and the more varied it is, the better.”</p><p>Such a targets machine, he said, would draw on complex models that make predictions built “on lots of small, diverse features”, listing examples such as “people who are with a Hezbollah member in a WhatsApp group, people who get new cellphones every few months, those who change their addresses frequently”.</p><p>He argues that using AI to create potential military targets can be more efficient and avoid “bottlenecks” created by intelligence officials or soldiers. “There is a human bottleneck for both locating the new targets and decision-making to approve the targets. There is also the bottleneck of how to process a great amount of data. Then there is the bottleneck of connecting the intelligence to the fire.” He adds: “A team consisting of machines and investigators can blast the bottleneck wide open.”</p><h2 id="intelligence-divide"><strong>Intelligence divide</strong></h2><p>Disclosure of Sariel’s security lapse comes at a difficult time for the intelligence boss. In February, he came under public scrutiny in Israel when the Israeli newspaper Maariv published <a href="https://www.maariv.co.il/journalists/Article-1078519" data-link-name="in body link">an account</a> of recriminations within Unit 8200 after the 7 October attacks.</p><p>Sariel was not named in the article, which referred to Unit 8200’s commander only as “Y”. However, the rare public criticism brought into focus a divide within Israel’s intelligence community over its biggest failure in a generation.</p><p>Sariel’s critics, the report said, believe Unit 8200’s prioritisation of “addictive and exciting” technology over more old-fashioned intelligence methods had led to the disaster. One veteran official told the newspaper the unit under Sariel had “followed the new intelligence bubble”.</p><p>For his part, Sariel is quoted as telling colleagues that 7 October will “haunt him” until his last day. “I accept responsibility for what happened in the most profound sense of the word,” he said. “We were defeated. I was defeated.”</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Big Tech's underground race to buy AI training data (113 pts)]]></title>
            <link>https://www.reuters.com/technology/inside-big-techs-underground-race-buy-ai-training-data-2024-04-05/</link>
            <guid>39942104</guid>
            <pubDate>Fri, 05 Apr 2024 13:27:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/technology/inside-big-techs-underground-race-buy-ai-training-data-2024-04-05/">https://www.reuters.com/technology/inside-big-techs-underground-race-buy-ai-training-data-2024-04-05/</a>, See on <a href="https://news.ycombinator.com/item?id=39942104">Hacker News</a></p>
Couldn't get https://www.reuters.com/technology/inside-big-techs-underground-race-buy-ai-training-data-2024-04-05/: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[Cloudflare acquires PartyKit to allow developers to build real-time multi-user (124 pts)]]></title>
            <link>https://blog.cloudflare.com/cloudflare-acquires-partykit</link>
            <guid>39941859</guid>
            <pubDate>Fri, 05 Apr 2024 13:03:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.cloudflare.com/cloudflare-acquires-partykit">https://blog.cloudflare.com/cloudflare-acquires-partykit</a>, See on <a href="https://news.ycombinator.com/item?id=39941859">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post"><article><p>04/05/2024</p><section><p>4 min read</p><div><figure><img src="https://blog.cloudflare.com/content/images/2024/04/PartyKit-and-Cloudflare.png" alt="Cloudflare acquires PartyKit to allow developers to build real-time multi-user applications" loading="lazy" width="2400" height="1350"></figure><p>We're thrilled to announce that PartyKit, an open source platform for deploying real-time, collaborative, multiplayer applications, is now a part of Cloudflare. This acquisition marks a significant milestone in our journey to redefine the boundaries of serverless computing, making it more dynamic, interactive, and, importantly, stateful.</p><h3 id="defining-the-future-of-serverless-compute-around-state">Defining the future of serverless compute around state</h3><p>Building real-time applications on the web have always been difficult. Not only is it a distributed systems problem, but you need to provision and manage infrastructure, databases, and other services to maintain state across multiple clients. This complexity has traditionally been a barrier to entry for many developers, especially those who are just starting out.</p><p><a href="https://blog.cloudflare.com/introducing-workers-durable-objects">We announced Durable Objects in 2020</a> as a way of building synchronized real time experiences for the web. Unlike regular serverless functions that are ephemeral and stateless, Durable Objects are stateful, allowing developers to build applications that maintain state across requests. They also act as an ideal synchronization point for building real-time applications that need to maintain state across multiple clients. Combined with WebSockets, Durable Objects can be used to build a wide range of applications, from multiplayer games to collaborative drawing tools.</p><p>In 2022, PartyKit began as a project to further explore the capabilities of Durable Objects and make them more accessible to developers by exposing them through familiar components. In seconds, you could create a project that configured behavior for these objects, and deploy it to Cloudflare. By integrating with popular libraries such as <a href="https://github.com/yjs/yjs">Yjs</a> (the gold standard in collaborative editing) and React, PartyKit made it possible for developers to build a wide range of use cases, from multiplayer games to collaborative drawing tools, into their applications.</p><p>Building experiences with real-time components was previously only accessible to multi-billion dollar companies, but new computing primitives like Durable Objects on the edge make this accessible to regular developers and teams. With PartyKit now under our roof, we're doubling down on our commitment to this future — a future where serverless is stateful.</p><p>We’re excited to give you a preview into our shared vision for applications, and the use cases we’re excited to simplify together.</p><h3 id="making-state-for-serverless-easy">Making state for serverless easy</h3><p>Unlike conventional approaches that rely on external databases to maintain state, thereby complicating scalability and increasing costs, PartyKit leverages Cloudflare's Durable Objects to offer a seamless model where stateful serverless functions can operate as if they were running on a single machine, maintaining state across requests. This innovation not only simplifies development but also opens up a broader range of use cases, including real-time computing, collaborative editing, and multiplayer gaming, by allowing thousands of these "machines" to be spun up globally, each maintaining its own state. PartyKit aims to be a complement to traditional serverless computing, providing a more intuitive and efficient method for developing applications that require stateful behavior, thereby marking the "next evolution" of serverless computing.</p><h3 id="simplifying-websockets-for-real-time-interaction">Simplifying WebSockets for Real-Time Interaction</h3><p>WebSockets have revolutionized how we think about bidirectional communication on the web. Yet, the challenge has always been about scaling these interactions to millions without a hitch. Cloudflare Workers step in as the hero, providing a serverless framework that makes real-time applications like chat services, multiplayer games, and collaborative tools not just possible but scalable and efficient.</p><h3 id="powering-games-and-multiplayer-applications-without-limits">Powering Games and Multiplayer Applications Without Limits</h3><p>Imagine building multiplayer platforms where the game never lags, the collaboration is seamless, and video conferences are crystal clear. Cloudflare's Durable Objects morph the stateless serverless landscape into a realm where persistent connections thrive. PartyKit's integration into this ecosystem means developers now have a powerhouse toolkit to bring ambitious multiplayer visions to life, without the traditional overheads.</p><p>This is especially critical in gaming — there are few areas where low-latency and real-time interaction matter more. Every millisecond, every lag, every delay defines the entire experience. With PartyKit's capabilities integrated into Cloudflare, developers will be able to leverage our combined technologies to create gaming experiences that are not just about playing but living the game, thanks to scalable, immersive, and interactive platforms.</p><h3 id="the-toolkit-for-building-local-first-applications">The toolkit for building Local-First applications</h3><p>The Internet is great, and increasingly always available, but there are still a few situations where we are forced to disconnect — whether on a plane, a train, or a beach.</p><p>The premise of local-first applications is that work doesn't stop when the Internet does. Wherever you left off in your doc, you can keep working on it, assuming the state will be restored when you come back online. By storing data on the client and syncing when back online, these applications offer resilience and responsiveness that's unmatched. Cloudflare's vision, enhanced by PartyKit's technology, aims to make local-first not just an option but the standard for application development.</p><h3 id="whats-next-for-partykit-users">What's next for PartyKit users?</h3><p>Users can expect their existing projects to continue working as expected. We will be adding more features to the platform, including the ability to create and use PartyKit projects inside existing Workers and Pages projects. There will be no extra charges to use PartyKit for commercial purposes, other than the standard usage charges for Cloudflare Workers and other services. Further, we're going to expand the roadmap to begin working on integrations with popular frameworks and libraries, such as React, Vue, and Angular. We're deeply committed to executing on the PartyKit vision and roadmap, and we're excited to see what you build with it.</p><h3 id="the-beginning-of-a-new-chapter">The Beginning of a New Chapter</h3><p>The acquisition of PartyKit by Cloudflare isn't just a milestone for our two teams; it's a leap forward for developers everywhere. Together, we're not just building tools; we're crafting the foundation for the next generation of Internet applications. The future of serverless is stateful, and with PartyKit's expertise now part of our arsenal, we're more ready than ever to make that future a reality.</p><p>Welcome to the Cloudflare team, PartyKit. Look forward to building something remarkable together.</p></div></section><div><p>We protect <a target="_blank" href="https://www.cloudflare.com/network-services/" rel="noreferrer">entire corporate networks</a>, help customers build <a target="_blank" href="https://workers.cloudflare.com/" rel="noreferrer">Internet-scale applications efficiently</a>, accelerate any <a target="_blank" href="https://www.cloudflare.com/performance/accelerate-internet-applications/" rel="noreferrer">website or Internet application</a>, <a target="_blank" href="https://www.cloudflare.com/ddos/" rel="noreferrer">ward off DDoS attacks</a>, keep <a target="_blank" href="https://www.cloudflare.com/application-security/" rel="noreferrer">hackers at bay</a>, and can help you on <a target="_blank" href="https://www.cloudflare.com/products/zero-trust/" rel="noreferrer">your journey to Zero Trust</a>.</p><p>Visit <a target="_blank" href="https://one.one.one.one/" rel="noreferrer">1.1.1.1</a> from any device to get started with our free app that makes your Internet faster and safer.</p><p>To learn more about our mission to help build a better Internet, <a target="_blank" href="https://www.cloudflare.com/learning/what-is-cloudflare/" rel="noreferrer">start here</a>. If you're looking for a new career direction, check out <a target="_blank" href="https://www.cloudflare.com/careers" rel="noreferrer">our open positions</a>.</p></div><a href="https://blog.cloudflare.com/tag/developer-week">Developer Week</a><a href="https://blog.cloudflare.com/tag/acquisitions">Acquisitions</a><a href="https://blog.cloudflare.com/tag/workers">Cloudflare Workers</a><a href="https://blog.cloudflare.com/tag/ai">AI</a><a href="https://blog.cloudflare.com/tag/durable-objects">Durable Objects</a></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Almost no one cares if your site is not on social media (118 pts)]]></title>
            <link>https://notes.ghed.in/posts/2024/no-one-cares-site-on-social-media/</link>
            <guid>39940922</guid>
            <pubDate>Fri, 05 Apr 2024 11:04:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://notes.ghed.in/posts/2024/no-one-cares-site-on-social-media/">https://notes.ghed.in/posts/2024/no-one-cares-site-on-social-media/</a>, See on <a href="https://news.ycombinator.com/item?id=39940922">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>


<p>5/4/2024</p>




<p>In March 2024, I ran an experiment in my Portuguese-written blog: I stopped distributing its content on social media (Mastodon, mostly) and messaging apps (Telegram and WhatsApp channels). It has a small following in a few places — ~2,9k on Telegram, ~450 on WhatsApp and three Mastodon profiles (two with autopost) that sums ~5k followers.</p>

<p>The result was that… little has changed.</p>

<p>The blog got ~107k unique visitors who viewed ~172k pages. Compared to the average of the previous six months, the March figures were 33.7% and 30.3% higher, respectively.</p>

<p>The reason for this increase, however, was an uncontrollable external player: Google. On March 27<sup>th</sup>, I posted a link in our readers forum of a Brazilian viral anonymous Google spreadsheet with reports of bad companies to work for. Google, for any inexplicable reason, put this link in front of many pairs of eyes, and almost 38k people arrived at my blog in the few days remaining in March.</p>

<p>(This created tragicomic situations, such as people posting anonymous reports of toxic companies in the comments of the blog and one that threatened to sue me if I didn’t take down the spreadsheet.)</p>

<!--break-->
<p>Without this little crazy viral, the audience in March would have been 13.7% and 28.8% lower than the average of the previous six months. What makes more sense, but I don’t know if it’s fair to take viral out of the equation.</p>

<p>In February, for instance, Google aimed its cannon of people at a report I wrote about using Kindle without an Amazon account. Why? Who knows! In that month, this single text accounted for 27.7% of unique visitors and 18.5% of page views.</p>

<p>Like any authoritarian entity, Google punishes and graces without clear criteria. Today you get free traffic from a meaningless viral, tomorrow… Maybe my next experiment is to take my blog off the Google Search.</p>

<p><code>***</code></p>

<p>Social media, those I was absent from in March, give no web traffic at all — and that’s not news. Even for this reason I have unfolded my work in them in two ways: either by automating the distribution of the site’s content, or by replicating it in full. In both, I don’t have the expectation of increasing access/traffic to my blog.</p>

<p>There is a manifest unwillingness, in some cases, of social platforms with external websites and links. And it’s general. It’s rare for me to believe in something that comes out of the mouth of a big tech C-level, but Adam Mosseri, from Meta, <a href="https://www.threads.net/@mosseri/post/CuZ3LjhNl0m">is right</a> regarding this: the headache that these companies get when supporting journalism does not compensate for the tiny return they have, because these companies don’t care about the subjectivity and nuances of complex or hard subjects and, in fact, they do not earn anything by sending users out of their domains.</p>

<p>If my operation depended on traffic, I would worry more about all these numbers and presence on social media. (And Google, on whom modern journalism <a href="https://retrododo.com/google-is-killing-retro-dodo/">is dependent and/or hostage</a>, depending on how you face the situation.) That’s not my case.</p>

<p>And, because that’s not the case, raw numbers don’t tell the whole story of my March social media blackout. Some readers missed seeing updates on Mastodon, Telegram, even LinkedIn. Not that there is a lack of ways to follow what I post, but it’s that, like it or not, online life happens in these places and visiting sites directly, following them by RSS or even by the newsletter are practices out of fashion.</p>

<p><code>***</code></p>

<p>That said, how do we continue from now on? I don’t share the optimism of colleagues who participated in the last <a href="https://reutersinstitute.politics.ox.ac.uk/journalism-media-and-technology-trends-and-predictions-2024">Reuters Institute annual survey of trends and predictions</a>, that WhatsApp and Threads will be spaces to leverage reach. They are both Meta platforms, after all.</p>

<p>Another popular trend, focusing on direct traffic, has already been a reality in my blog for a good few years. I will continue to invest in this and in decentralized platforms. Reader’s support, spreading the word and funding the project (there’s a <a href="https://manualdousuario.net/apoie/">paid subscription offer</a>), is essential.</p>

<p>Do you know those action movie traps, in which the characters are in a room and opposite walls are slowly approaching in order to crush them? I see the web there in the middle, squeezed between cheap social media platforms and stupid generative artificial intelligences.</p>

<p><code>***</code></p>

<p>The funniest thing about all this? There was little variation in the gain and loss (in the case of X/Twitter) of followers. I almost forget to mention this, for you to feel how I’m concerned with social media.</p>

<p>By the way, the audience stats of my Portuguese-written blog, object of this experiment, <a href="https://manualdousuario.net/?koko-analytics-dashboard=1">are open</a>.</p>




</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Proton Mail says Outlook for Windows is Microsoft's new data collection service (112 pts)]]></title>
            <link>https://www.ghacks.net/2024/01/12/proton-mail-says-that-the-new-outlook-app-for-windows-is-microsofts-new-data-collection-service/</link>
            <guid>39939363</guid>
            <pubDate>Fri, 05 Apr 2024 06:44:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ghacks.net/2024/01/12/proton-mail-says-that-the-new-outlook-app-for-windows-is-microsofts-new-data-collection-service/">https://www.ghacks.net/2024/01/12/proton-mail-says-that-the-new-outlook-app-for-windows-is-microsofts-new-data-collection-service/</a>, See on <a href="https://news.ycombinator.com/item?id=39939363">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
              <p>Proton has accused Microsoft's new <a href="https://www.ghacks.net/2023/07/20/microsoft-brings-new-outlook-for-windows-and-windows-copilot-for-all-windows-dev-channel-users/" target="_blank" rel="noopener" data-wpel-link="internal">Outlook for Windows</a> app for becoming a data collection service. It has outlined the various ways and data that the email app harvests from end users.</p>
<p>Proton Mail's <a href="https://proton.me/blog/outlook-is-microsofts-new-data-collection-service" target="_blank" rel="noopener nofollow external noreferrer" data-wpel-link="external">article</a> is about a week old and flew under my radar, but given that user privacy is at stake, I think it warrants a discussion here. The Switzerland-based email service has termed the new Outlook as a surveillance tool that is used for targeted advertising.</p>
<h3><strong>Microsoft Outlook is sharing user data with 772 advertisers</strong></h3>
<p>According to Proton, some users in Europe who download the new Outlook for Windows app, will see a modal (pop-up) that displays a user agreement, which mentions that Microsoft shares your data with 772 third-parties. Yes, you read that right, 772. The only reason you may see that pop-up is because the European Union's General Data Protection Regulation (GDPR) makes it mandatory for web services to inform users about data collection and cookies. The rest of the world isn't as lucky.</p>
<p><img decoding="async" src="https://www.ghacks.net/wp-content/uploads/2024/01/New-Microsoft-Outlook-shares-user-data-with-advertisers.jpg" alt="New Microsoft Outlook shares user data with advertisers" width="1200" height="828"></p>
<p>Interestingly, users in the U.K. can view a "list of advertising partners" that are working with the Redmond company. Instead of a universal toggle to opt-out of these ads, the app displays a toggle for each advertising company, along with a privacy policy for each ad service. Proton says that these policies are written in a way to confuse users, allowing the companies to sell the personal data of users to third-parties.</p>
<p>The agreement allows these entities to do the following</p>
<ul>
<li>Store and/or access information on the user’s device.</li>
<li>Develop and improve products</li>
<li>Personalize ads and content</li>
<li>Measure ads and content</li>
<li>Derive audience insights</li>
<li>Obtain precise geolocation data</li>
<li>Identify users through device scanning</li>
</ul>
<p>I don't think users are going to mind all these companies looking over their shoulder and reading their mails, right? Actually, it is much worse than you think. Microsoft's advertising policy mentions that it does not collect personal data from emails, chats or documents for targeted ads. Data that is collected via telemetry is used to improve the user experience. But Proton says that Microsoft Outlook collects the following data from users:</p>
<ul>
<li>Name and contact data</li>
<li>Passwords</li>
<li>Demographic data</li>
<li>Payment data</li>
<li>Subscription and licensing data</li>
<li>Search queries</li>
<li>Device and usage data</li>
<li>Error reports and performance data</li>
<li>Voice data</li>
<li>Text, inking, and typing data</li>
<li>Images</li>
<li>Location data</li>
<li>Content</li>
<li>Feedback and ratings</li>
<li>Traffic data</li>
</ul>
<p>Most of those are not even related to sending and receiving mails, I'm not even sure how this can be legal. Microsoft shares the data with Service providers, User-directed entities, Payment processing providers and Third parties that perform online advertising services for Microsoft.</p>
<p>Even the <a href="https://www.ghacks.net/2023/03/07/microsoft-outlook-for-mac-is-now-free-for-all-users/" target="_blank" rel="noopener" data-wpel-link="internal">Mac version</a> of the new Outlook isn't spared from these shenanigans. It displays ads that look similar to message notifications. Some of these are ads come from third-parties, while some are ads for Microsoft's other apps, such as Microsoft 365.</p>
<p><img decoding="async" src="https://www.ghacks.net/wp-content/uploads/2024/01/New-Microsoft-Outlook-ads-in-macOS-app.jpg" alt="New Microsoft Outlook ads in macOS app" width="1200" height="757"></p>
<p>That's just wonderful. If you want to dive in to Microsoft's <a href="https://privacy.microsoft.com/en-US/privacystatement#mainpersonaldatawecollectmodule" target="_blank" rel="noopener nofollow external noreferrer" data-wpel-link="external">Privacy Policy</a>, read it here.</p>
<p>(Images via Proton and Microsoft)</p>
<h3><strong>Outlook "steals" your email passwords</strong></h3>
<p>As Martin pointed out in <a href="https://www.ghacks.net/2023/11/10/the-new-outlook-may-give-microsoft-access-to-third-party-emails-and-logins/" target="_blank" rel="noopener" data-wpel-link="internal">November 2023</a>, German blogs, Heise and CT had discovered that syncing third-party email accounts such as Gmail, Yahoo with Outlook would allow the app to send the passwords (IMAP and SMTP credentials) and other data (emails, contacts, and calendar).</p>
<p>If you think that's bad, wait till you read this. You cannot use the new Outlook app without syncing these data with Microsoft's servers, i.e. your usernames and passwords are sent to the company's cloud servers. While the data is sent using TLS, the IMAP and SMTP username and password are sent to Microsoft in plain text. This could allow the company to access your emails, and share the data with third-parties.</p>
<p>Proton alleges that Microsoft has proven that it is no different from Google, Meta and other such companies that indulge in data collection and ad delivery services.</p>
<p>I can't say I like the Outlook app, the old Mail app is/was better, the new one is just a web wrapper for Outlook.com. If you don't want to use Outlook for Windows, just right-click on the app in the Start menu and select Uninstall. You can also do this from the Settings &gt; Apps &gt; Installed Apps section. But, don't be surprised if Outlook comes back after a Windows Update.</p>
<p><a href="https://www.thunderbird.net/en-US/" target="_blank" rel="noopener nofollow external noreferrer" data-wpel-link="external">Thunderbird</a> and Apple Mail for macOS are the only desktop email clients I use, and recommend. What about you, got any favorites? Or do you use the new Outlook for Windows app?</p>
<div id="snippet-box"><p>Summary</p><div itemscope="" itemtype="https://schema.org/Article"><div itemprop="image" itemscope="" itemtype="https://schema.org/ImageObject"><p><img width="180" src="https://www.ghacks.net/wp-content/uploads/2024/01/Proton-says-that-Outlook-is-Microsofts-new-data-collection-service.jpg" alt="Proton Mail says that the new Outlook app for Windows is Microsoft's new data collection service"></p><meta itemprop="url" content="https://www.ghacks.net/wp-content/uploads/2024/01/Proton-says-that-Outlook-is-Microsofts-new-data-collection-service.jpg"></div><div><p>Article Name</p><p><span itemprop="headline">Proton Mail says that the new Outlook app for Windows is Microsoft's new data collection service</span></p><p>Description</p><p><span itemprop="description">Proton calls the new Outlook app for Windows a data collection service that spies on users.</span></p><p>Author</p><p><span itemprop="name">Ashwin</span>
							</p>
							<div itemprop="publisher" itemscope="" itemtype="https://schema.org/Organization"><p>Publisher</p><p><span itemprop="name">Ghacks Technology News</span>
							</p>
							

							<p>Logo</p><div itemprop="logo" itemscope="" itemtype="https://schema.org/ImageObject"><picture><source srcset="https://www.ghacks.net/wp-content/uploads/2005/10/ghacks-technology-news.webp " type="image/webp"><img src="https://www.ghacks.net/wp-content/uploads/2005/10/ghacks-technology-news.jpg" width="180" alt="Ghacks Technology News"> </picture><meta itemprop="url" content="https://www.ghacks.net/wp-content/uploads/2005/10/ghacks-technology-news.jpg"></div></div><meta itemscope="" itemprop="mainEntityOfPage" itemtype="https://schema.org/WebPage" itemid="https://www.ghacks.net/2024/01/12/proton-mail-says-that-the-new-outlook-app-for-windows-is-microsofts-new-data-collection-service/"><meta itemprop="datePublished" content="2024-01-12T12:18:45+01:00"><meta itemprop="dateModified" content="2024-01-12T12:19:00+01:00"></div>
					</div></div><p>
                              Advertisement
                
                          </p><!-- /22152718/ghacks_in-content -->
            

                
          
                
                  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FFmpeg 7.0 Released (465 pts)]]></title>
            <link>https://ffmpeg.org//index.html#pr7.0</link>
            <guid>39938703</guid>
            <pubDate>Fri, 05 Apr 2024 04:31:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ffmpeg.org//index.html#pr7.0">https://ffmpeg.org//index.html#pr7.0</a>, See on <a href="https://news.ycombinator.com/item?id=39938703">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="index">

  <div>
    <p>
      <h2>
        A complete, cross-platform solution to record, convert and stream audio and video.
      </h2>
    </p> <!-- col -->
     <!-- col -->
  </div> <!-- row -->

  <div>
    <h3>Converting <strong>video</strong> and <strong>audio</strong> has never been so easy.
    </h3>
    <pre>$ ffmpeg -i input.mp4 output.avi</pre>
    
  </div> <!-- well -->

  <h2 id="news">
    <span>
      <a href="https://ffmpeg.org//main.rss"><strong></strong></a> &nbsp;
      <a href="https://twitter.com/FFmpeg"><strong><i></i></strong></a> &nbsp;
      <a href="https://www.facebook.com/ffmpeg"><strong><i></i></strong></a>
    </span>
    News
  </h2>

  <h3 id="pr7.0">April 5th, 2024, FFmpeg 7.0 "Dijkstra"</h3>
  <p>
  A new major release, <a href="https://ffmpeg.org//download.html#release_7.0">FFmpeg 7.0 "Dijkstra"</a>,
  is now available for download. The most noteworthy changes for most users are
  a <a href="#vvcdec">native VVC decoder</a> (currently experimental, until more
  fuzzing is done), <a href="#iamf">IAMF support</a>, or a
  <a href="#cli_threading">multi-threaded <code>ffmpeg</code> CLI tool</a>.
  </p>

  <p>
  This release is <em>not</em> backwards compatible, removing APIs deprecated before 6.0.
  The biggest change for most library callers will be the removal of the old bitmask-based
  channel layout API, replaced by the <code>AVChannelLayout</code> API allowing such
  features as custom channel ordering, or Ambisonics. Certain deprecated <code>ffmpeg</code>
  CLI options were also removed, and a C11-compliant compiler is now required to build
  the code.
  </p>

  <p>
  As usual, there is also a number of new supported formats and codecs, new filters, APIs,
  and countless smaller features and bugfixes. Compared to 6.1, the <code>git</code> repository
  contains almost ∼2000 new commits by ∼100 authors, touching &gt;100000 lines in
  ∼2000 files — thanks to everyone who contributed. See the
  <a href="https://git.videolan.org/?p=ffmpeg.git;a=blob_plain;f=Changelog;hb=n7.0">Changelog</a>,
  <a href="https://git.videolan.org/?p=ffmpeg.git;a=blob_plain;f=doc/APIchanges;hb=n7.0">APIchanges</a>,
  and the git log for more comprehensive lists of changes.
  </p>

  <h3 id="vvcdec">January 3rd, 2024, native VVC decoder</h3>
  <p>
  The <code>libavcodec</code> library now contains a native VVC (Versatile Video Coding)
  decoder, supporting a large subset of the codec's features. Further optimizations and
  support for more features are coming soon. The code was written by Nuo Mi, Xu Mu,
  Frank Plowman, Shaun Loo, and Wu Jianhua.
  </p>

  <h3 id="iamf">December 18th, 2023, IAMF support</h3>
  <p>
  The <code>libavformat</code> library can now read and write <a href="https://aomediacodec.github.io/iamf/">IAMF</a>
  (Immersive Audio) files. The <code>ffmpeg</code> CLI tool can configure IAMF structure with the new
  <code>-stream_group</code> option. IAMF support was written by James Almer.
  </p>

  <h3 id="cli_threading">December 12th, 2023, multi-threaded <code>ffmpeg</code> CLI tool</h3>
  <p>
  Thanks to a major refactoring of the <code>ffmpeg</code> command-line tool, all the major
  components of the transcoding pipeline (demuxers, decoders, filters, encodes, muxers) now
  run in parallel. This should improve throughput and CPU utilization, decrease latency,
  and open the way to other exciting new features.
  </p>

  <p>
  Note that you should <em>not</em> expect significant performance improvements in cases
  where almost all computational time is spent in a single component (typically video
  encoding).
  </p>

  <h3 id="pr6.1">November 10th, 2023, FFmpeg 6.1 "Heaviside"</h3>
  <p>
    <a href="https://ffmpeg.org//download.html#release_6.1">FFmpeg 6.1 "Heaviside"</a>, a new
    major release, is now available! Some of the highlights:
  </p>
  <ul>
    <li>libaribcaption decoder</li>
    <li>Playdate video decoder and demuxer</li>
    <li>Extend VAAPI support for libva-win32 on Windows</li>
    <li>afireqsrc audio source filter</li>
    <li>arls filter</li>
    <li>ffmpeg CLI new option: -readrate_initial_burst</li>
    <li>zoneplate video source filter</li>
    <li>command support in the setpts and asetpts filters</li>
    <li>Vulkan decode hwaccel, supporting H264, HEVC and AV1</li>
    <li>color_vulkan filter</li>
    <li>bwdif_vulkan filter</li>
    <li>nlmeans_vulkan filter</li>
    <li>RivaTuner video decoder</li>
    <li>xfade_vulkan filter</li>
    <li>vMix video decoder</li>
    <li>Essential Video Coding parser, muxer and demuxer</li>
    <li>Essential Video Coding frame merge bsf</li>
    <li>bwdif_cuda filter</li>
    <li>Microsoft RLE video encoder</li>
    <li>Raw AC-4 muxer and demuxer</li>
    <li>Raw VVC bitstream parser, muxer and demuxer</li>
    <li>Bitstream filter for editing metadata in VVC streams</li>
    <li>Bitstream filter for converting VVC from MP4 to Annex B</li>
    <li>scale_vt filter for videotoolbox</li>
    <li>transpose_vt filter for videotoolbox</li>
    <li>support for the P_SKIP hinting to speed up libx264 encoding</li>
    <li>Support HEVC,VP9,AV1 codec in enhanced flv format</li>
    <li>apsnr and asisdr audio filters</li>
    <li>OSQ demuxer and decoder</li>
    <li>Support HEVC,VP9,AV1 codec fourcclist in enhanced rtmp protocol</li>
    <li>CRI USM demuxer</li>
    <li>ffmpeg CLI '-top' option deprecated in favor of the setfield filter</li>
    <li>VAAPI AV1 encoder</li>
    <li>ffprobe XML output schema changed to account for multiple variable-fields elements within the same parent element</li>
    <li>ffprobe -output_format option added as an alias of -of</li>
  </ul>
  <p>
    This release had been overdue for at least half a year, but due to constant activity in the repository,
    had to be delayed, and we were finally able to branch off the release recently, before some of the large
    changes scheduled for 7.0 were merged.
  </p>
  <p>
    Internally, we have had a number of changes too. The FFT, MDCT, DCT and DST implementation used for codecs
    and filters has been fully replaced with the faster libavutil/tx (full article about it coming soon).<br>
    This also led to a reduction in the the size of the compiled binary, which can be noticeable in small builds.<br>
    There was a very large reduction in the total amount of allocations being done on each frame throughout video decoders,
    reducing overhead.<br>
    RISC-V optimizations for many parts of our DSP code have been merged, with mainly the large decoders being left.<br>
    There was an effort to improve the correctness of timestamps and frame durations of each packet, increasing the
    accurracy of variable frame rate video.
  </p>
  <p>
    Next major release will be version 7.0, scheduled to be released in February. We will attempt to better stick
    to the new release schedule we announced at the start of this year.
  </p>
  <p>
    We strongly recommend users, distributors, and system integrators to upgrade unless they use current git master.
  </p>

  <h3 id="vk2023">May 31st, 2023, Vulkan decoding</h3>
  <p>
    A few days ago, Vulkan-powered decoding hardware acceleration code was merged into the codebase.
    This is the first vendor-generic and platform-generic decode acceleration API, enabling the
    same code to be used on multiple platforms, with very minimal overhead.
    This is also the first multi-threaded hardware decoding API, and our code makes full use of this,
    saturating all available decode engines the hardware exposes.
  </p>
  <p>
    Those wishing to test the code can read our
    <a href="https://trac.ffmpeg.org/wiki/HWAccelIntro#Vulkan">documentation page</a>.
    For those who would like to integrate FFmpeg's Vulkan code to demux, parse, decode, and receive
    a VkImage to present or manipulate, documentation and examples are available in our source tree.
    Currently, using the latest available git checkout of our
    <a href="https://git.videolan.org/?p=ffmpeg.git;a=summary">repository</a> is required.
    The functionality will be included in stable branches with the release of version 6.1, due
    to be released soon.
  </p>
  <p>
    As this is also the first practical implementation of the specifications, bugs may be present,
    particularly in drivers, and, although passing verification, the implementation itself.
    New codecs, and encoding support are also being worked on, by both the Khronos organization
    for standardizing, and us as implementing it, and giving feedback on improving.
  </p>

  <h3 id="pr6.0">February 28th, 2023, FFmpeg 6.0 "Von Neumann"</h3>
  <p>
    A new major release, <a href="https://ffmpeg.org//download.html#release_6.0">FFmpeg 6.0 "Von Neumann"</a>,
    is now available for download. This release has many new encoders and decoders, filters,
    ffmpeg CLI tool improvements, and also, changes the way releases are done. All major
    releases will now bump the version of the ABI. We plan to have a new major release each
    year. Another release-specific change is that deprecated APIs will be removed after 3
    releases, upon the next major bump.
    This means that releases will be done more often and will be more organized.
  </p>
  <p>
    New decoders featured are Bonk, RKA, Radiance, SC-4, APAC, VQC, WavArc and a few ADPCM formats.
    QSV and NVenc now support AV1 encoding. The FFmpeg CLI (we usually reffer to it as ffmpeg.c
    to avoid confusion) has speed-up improvements due to threading, as well as statistics options,
    and the ability to pass option values for filters from a file. There are quite a few new audio
    and video filters, such as adrc, showcwt, backgroundkey and ssim360, with a few hardware ones too.
    Finally, the release features many behind-the-scenes changes, including a new FFT and MDCT
    implementation used in codecs (expect a blog post about this soon), numerous bugfixes, better
    ICC profile handling and colorspace signalling improvement, introduction of a number of RISC-V
    vector and scalar assembly optimized routines, and a few new improved APIs, which can be viewed
    in the doc/APIchanges file in our tree.
    A few submitted features, such as the Vulkan improvements and more FFT optimizations will be in the
    next minor release, 6.1, which we plan to release soon, in line with our new release schedule.
    Some highlights are:
  </p>
  <ul>
    <li>Radiance HDR image support</li>
    <li>ddagrab (Desktop Duplication) video capture filter</li>
    <li>ffmpeg -shortest_buf_duration option</li>
    <li>ffmpeg now requires threading to be built</li>
    <li>ffmpeg now runs every muxer in a separate thread</li>
    <li>Add new mode to cropdetect filter to detect crop-area based on motion vectors and edges</li>
    <li>VAAPI decoding and encoding for 10/12bit 422, 10/12bit 444 HEVC and VP9</li>
    <li>WBMP (Wireless Application Protocol Bitmap) image format</li>
    <li>a3dscope filter</li>
    <li>bonk decoder and demuxer</li>
    <li>Micronas SC-4 audio decoder</li>
    <li>LAF demuxer</li>
    <li>APAC decoder and demuxer</li>
    <li>Media 100i decoders</li>
    <li>DTS to PTS reorder bsf</li>
    <li>ViewQuest VQC decoder</li>
    <li>backgroundkey filter</li>
    <li>nvenc AV1 encoding support</li>
    <li>MediaCodec decoder via NDKMediaCodec</li>
    <li>MediaCodec encoder</li>
    <li>oneVPL support for QSV</li>
    <li>QSV AV1 encoder</li>
    <li>QSV decoding and encoding for 10/12bit 422, 10/12bit 444 HEVC and VP9</li>
    <li>showcwt multimedia filter</li>
    <li>corr video filter</li>
    <li>adrc audio filter</li>
    <li>afdelaysrc audio filter</li>
    <li>WADY DPCM decoder and demuxer</li>
    <li>CBD2 DPCM decoder</li>
    <li>ssim360 video filter</li>
    <li>ffmpeg CLI new options: -stats_enc_pre[_fmt], -stats_enc_post[_fmt], -stats_mux_pre[_fmt]</li>
    <li>hstack_vaapi, vstack_vaapi and xstack_vaapi filters</li>
    <li>XMD ADPCM decoder and demuxer</li>
    <li>media100 to mjpegb bsf</li>
    <li>ffmpeg CLI new option: -fix_sub_duration_heartbeat</li>
    <li>WavArc decoder and demuxer</li>
    <li>CrystalHD decoders deprecated</li>
    <li>SDNS demuxer</li>
    <li>RKA decoder and demuxer</li>
    <li>filtergraph syntax in ffmpeg CLI now supports passing file contents as option values</li>
    <li>hstack_qsv, vstack_qsv and xstack_qsv filters</li>
  </ul>
  <p>
    We strongly recommend users, distributors, and system integrators to
    upgrade unless they use current git master.
  </p>

  <h3 id="pr5.1">July 22nd, 2022, FFmpeg 5.1 "Riemann"</h3>
  <p>
    <a href="https://ffmpeg.org//download.html#release_5.1">FFmpeg 5.1 "Riemann"</a>, a new
    major release, is now available! Some of the highlights:
  </p>
  <ul>
    <li>add ipfs/ipns protocol support</li>
    <li>dialogue enhance audio filter</li>
    <li>dropped obsolete XvMC hwaccel</li>
    <li>pcm-bluray encoder</li>
    <li>DFPWM audio encoder/decoder and raw muxer/demuxer</li>
    <li>SITI filter</li>
    <li>Vizrt Binary Image encoder/decoder</li>
    <li>avsynctest source filter</li>
    <li>feedback video filter</li>
    <li>pixelize video filter</li>
    <li>colormap video filter</li>
    <li>colorchart video source filter</li>
    <li>multiply video filter</li>
    <li>PGS subtitle frame merge bitstream filter</li>
    <li>blurdetect filter</li>
    <li>tiltshelf audio filter</li>
    <li>QOI image format support</li>
    <li>ffprobe -o option</li>
    <li>virtualbass audio filter</li>
    <li>VDPAU AV1 hwaccel</li>
    <li>PHM image format support</li>
    <li>remap_opencl filter</li>
    <li>added chromakey_cuda filter</li>
  </ul>
  <p>
    We strongly recommend users, distributors, and system integrators to
    upgrade unless they use current git master.
  </p>

  <h3 id="pr5.0">January 17th, 2022, FFmpeg 5.0 "Lorentz"</h3>
  <p>
    <a href="https://ffmpeg.org//download.html#release_5.0">FFmpeg 5.0 "Lorentz"</a>, a new
    major release, is now available! For this long-overdue release, a major effort
    underwent to remove the old encode/decode APIs and replace them with an
    N:M-based API, the entire libavresample library was removed, libswscale
    has a new, easier to use AVframe-based API, the Vulkan code was much improved,
    many new filters were added, including libplacebo integration, and finally,
    DoVi support was added, including tonemapping and remuxing. The default
    AAC encoder settings were also changed to improve quality.
    Some of the changelog highlights:
  </p>
  <ul>
    <li>ADPCM IMA Westwood encoder</li>
    <li>Westwood AUD muxer</li>
    <li>ADPCM IMA Acorn Replay decoder</li>
    <li>Argonaut Games CVG demuxer</li>
    <li>Argonaut Games CVG muxer</li>
    <li>Concatf protocol</li>
    <li>afwtdn audio filter</li>
    <li>audio and video segment filters</li>
    <li>Apple Graphics (SMC) encoder</li>
    <li>hsvkey and hsvhold video filters</li>
    <li>adecorrelate audio filter</li>
    <li>atilt audio filter</li>
    <li>grayworld video filter</li>
    <li>AV1 Low overhead bitstream format muxer</li>
    <li>swscale slice threading</li>
    <li>MSN Siren decoder</li>
    <li>scharr video filter</li>
    <li>apsyclip audio filter</li>
    <li>morpho video filter</li>
    <li>amr parser</li>
    <li>(a)latency filters</li>
    <li>GEM Raster image decoder</li>
    <li>asdr audio filter</li>
    <li>speex decoder</li>
    <li>limitdiff video filter</li>
    <li>xcorrelate video filter</li>
    <li>varblur video filter</li>
    <li>huesaturation video filter</li>
    <li>colorspectrum source video filter</li>
    <li>RTP packetizer for uncompressed video (RFC 4175)</li>
    <li>bitpacked encoder</li>
    <li>VideoToolbox VP9 hwaccel</li>
    <li>VideoToolbox ProRes hwaccel</li>
    <li>support loongarch.</li>
    <li>aspectralstats audio filter</li>
    <li>adynamicsmooth audio filter</li>
    <li>libplacebo filter</li>
    <li>vflip_vulkan, hflip_vulkan and flip_vulkan filters</li>
    <li>adynamicequalizer audio filter</li>
    <li>yadif_videotoolbox filter</li>
    <li>VideoToolbox ProRes encoder</li>
    <li>anlmf audio filter</li>
  </ul>
  <p>
    We strongly recommend users, distributors, and system integrators to
    upgrade unless they use current git master.
  </p>

  <h3 id="irc2021">June 19th, 2021, IRC</h3>
  <p>
    We have a new IRC home at Libera Chat
    now! Feel free to join us at #ffmpeg and #ffmpeg-devel. More info at <a href="https://ffmpeg.org/contact.html#IRCChannels">contact#IRCChannels</a>
  </p>

  <h3 id="pr4.4">April 8th, 2021, FFmpeg 4.4 "Rao"</h3>
  <p>
    <a href="https://ffmpeg.org//download.html#release_4.4">FFmpeg 4.4 "Rao"</a>, a new
    major release, is now available! Some of the highlights:
  </p>
  <ul>
    <li>AudioToolbox output device</li>
    <li>MacCaption demuxer</li>
    <li>PGX decoder</li>
    <li>chromanr video filter</li>
    <li>VDPAU accelerated HEVC 10/12bit decoding</li>
    <li>ADPCM IMA Ubisoft APM encoder</li>
    <li>Rayman 2 APM muxer</li>
    <li>AV1 encoding support SVT-AV1</li>
    <li>Cineform HD encoder</li>
    <li>ADPCM Argonaut Games encoder</li>
    <li>Argonaut Games ASF muxer</li>
    <li>AV1 Low overhead bitstream format demuxer</li>
    <li>RPZA video encoder</li>
    <li>ADPCM IMA MOFLEX decoder</li>
    <li>MobiClip FastAudio decoder</li>
    <li>MobiClip video decoder</li>
    <li>MOFLEX demuxer</li>
    <li>MODS demuxer</li>
    <li>PhotoCD decoder</li>
    <li>MCA demuxer</li>
    <li>AV1 decoder (Hardware acceleration used only)</li>
    <li>SVS demuxer</li>
    <li>Argonaut Games BRP demuxer</li>
    <li>DAT demuxer</li>
    <li>aax demuxer</li>
    <li>IPU decoder, parser and demuxer</li>
    <li>Intel QSV-accelerated AV1 decoding</li>
    <li>Argonaut Games Video decoder</li>
    <li>libwavpack encoder removed</li>
    <li>ACE demuxer</li>
    <li>AVS3 demuxer</li>
    <li>AVS3 video decoder via libuavs3d</li>
    <li>Cintel RAW decoder</li>
    <li>VDPAU accelerated VP9 10/12bit decoding</li>
    <li>afreqshift and aphaseshift filters</li>
    <li>High Voltage Software ADPCM encoder</li>
    <li>LEGO Racers ALP (.tun &amp; .pcm) muxer</li>
    <li>AV1 VAAPI decoder</li>
    <li>adenorm filter</li>
    <li>ADPCM IMA AMV encoder</li>
    <li>AMV muxer</li>
    <li>NVDEC AV1 hwaccel</li>
    <li>DXVA2/D3D11VA hardware accelerated AV1 decoding</li>
    <li>speechnorm filter</li>
    <li>SpeedHQ encoder</li>
    <li>asupercut filter</li>
    <li>asubcut filter</li>
    <li>Microsoft Paint (MSP) version 2 decoder</li>
    <li>Microsoft Paint (MSP) demuxer</li>
    <li>AV1 monochrome encoding support via libaom &gt;= 2.0.1</li>
    <li>asuperpass and asuperstop filter</li>
    <li>shufflepixels filter</li>
    <li>tmidequalizer filter</li>
    <li>estdif filter</li>
    <li>epx filter</li>
    <li>Dolby E parser</li>
    <li>shear filter</li>
    <li>kirsch filter</li>
    <li>colortemperature filter</li>
    <li>colorcontrast filter</li>
    <li>PFM encoder</li>
    <li>colorcorrect filter</li>
    <li>binka demuxer</li>
    <li>XBM parser</li>
    <li>xbm_pipe demuxer</li>
    <li>colorize filter</li>
    <li>CRI parser</li>
    <li>aexciter audio filter</li>
    <li>exposure video filter</li>
    <li>monochrome video filter</li>
    <li>setts bitstream filter</li>
    <li>vif video filter</li>
    <li>OpenEXR image encoder</li>
    <li>Simbiosis IMX decoder</li>
    <li>Simbiosis IMX demuxer</li>
    <li>Digital Pictures SGA demuxer and decoders</li>
    <li>TTML subtitle encoder and muxer</li>
    <li>identity video filter</li>
    <li>msad video filter</li>
    <li>gophers protocol</li>
    <li>RIST protocol via librist</li>
  </ul>
  <p>
    We strongly recommend users, distributors, and system integrators to
    upgrade unless they use current git master.
  </p>

  <h3 id="pr4.3">June 15th, 2020, FFmpeg 4.3 "4:3"</h3>
  <p>
    <a href="https://ffmpeg.org//download.html#release_4.3">FFmpeg 4.3 "4:3"</a>, a new
    major release, is now available! Some of the highlights:
  </p>
  <ul>
    <li>v360 filter</li>
    <li>Intel QSV-accelerated MJPEG decoding</li>
    <li>Intel QSV-accelerated VP9 decoding</li>
    <li>Support for TrueHD in mp4</li>
    <li>Support AMD AMF encoder on Linux (via Vulkan)</li>
    <li>IMM5 video decoder</li>
    <li>ZeroMQ protocol</li>
    <li>support Sipro ACELP.KELVIN decoding</li>
    <li>streamhash muxer</li>
    <li>sierpinski video source</li>
    <li>scroll video filter</li>
    <li>photosensitivity filter</li>
    <li>anlms filter</li>
    <li>arnndn filter</li>
    <li>bilateral filter</li>
    <li>maskedmin and maskedmax filters</li>
    <li>VDPAU VP9 hwaccel</li>
    <li>median filter</li>
    <li>QSV-accelerated VP9 encoding</li>
    <li>AV1 encoding support via librav1e</li>
    <li>AV1 frame merge bitstream filter</li>
    <li>AV1 Annex B demuxer</li>
    <li>axcorrelate filter</li>
    <li>mvdv decoder</li>
    <li>mvha decoder</li>
    <li>MPEG-H 3D Audio support in mp4</li>
    <li>thistogram filter</li>
    <li>freezeframes filter</li>
    <li>Argonaut Games ADPCM decoder</li>
    <li>Argonaut Games ASF demuxer</li>
    <li>xfade video filter</li>
    <li>xfade_opencl filter</li>
    <li>afirsrc audio filter source</li>
    <li>pad_opencl filter</li>
    <li>Simon &amp; Schuster Interactive ADPCM decoder</li>
    <li>Real War KVAG demuxer</li>
    <li>CDToons video decoder</li>
    <li>siren audio decoder</li>
    <li>Rayman 2 ADPCM decoder</li>
    <li>Rayman 2 APM demuxer</li>
    <li>cas video filter</li>
    <li>High Voltage Software ADPCM decoder</li>
    <li>LEGO Racers ALP (.tun &amp; .pcm) demuxer</li>
    <li>AMQP 0-9-1 protocol (RabbitMQ)</li>
    <li>Vulkan support</li>
    <li>avgblur_vulkan, overlay_vulkan, scale_vulkan and chromaber_vulkan filters</li>
    <li>ADPCM IMA MTF decoder</li>
    <li>FWSE demuxer</li>
    <li>DERF DPCM decoder</li>
    <li>DERF demuxer</li>
    <li>CRI HCA decoder</li>
    <li>CRI HCA demuxer</li>
    <li>overlay_cuda filter</li>
    <li>switch from AvxSynth to AviSynth+ on Linux</li>
    <li>mv30 decoder</li>
    <li>Expanded styling support for 3GPP Timed Text Subtitles (movtext)</li>
    <li>WebP parser</li>
    <li>tmedian filter</li>
    <li>maskedthreshold filter</li>
    <li>Support for muxing pcm and pgs in m2ts</li>
    <li>Cunning Developments ADPCM decoder</li>
    <li>asubboost filter</li>
    <li>Pro Pinball Series Soundbank demuxer</li>
    <li>pcm_rechunk bitstream filter</li>
    <li>scdet filter</li>
    <li>NotchLC decoder</li>
    <li>gradients source video filter</li>
    <li>MediaFoundation encoder wrapper</li>
    <li>untile filter</li>
    <li>Simon &amp; Schuster Interactive ADPCM encoder</li>
    <li>PFM decoder</li>
    <li>dblur video filter</li>
    <li>Real War KVAG muxer</li>
  </ul>
  <p>
    We strongly recommend users, distributors, and system integrators to
    upgrade unless they use current git master.
  </p>

  <h3 id="photosensitivity">October 5th, 2019, Bright Lights</h3>
  <p>
  FFmpeg has added a realtime bright flash removal filter to libavfilter.
  </p>
  <p>
  Note that this filter is not FDA approved, nor are we medical professionals.
  Nor has this filter been tested with anyone who has photosensitive epilepsy.
  FFmpeg and its photosensitivity filter are not making any medical claims.
  </p>
  <p>
  That said, this is a new video filter that may help photosensitive people
  watch tv, play video games or even be used with a VR headset to block
  out epiletic triggers such as filtered sunlight when they are outside.
  Or you could use it against those annoying white flashes on your tv screen.
  The filter fails on some input, such as the
  <a href="https://www.youtube.com/watch?v=8L_9hXnUzRk">Incredibles 2 Screen Slaver</a>
  scene. It is not perfect. If you have other clips that you want this filter to
  work better on, please report them to us on our <a href="http://trac.ffmpeg.org/">trac</a>.
  </p>
  <p>
  <a href="http://ffmpeg.org/~compn/output20p8.mp4">See for yourself</a>.
  Example was made with -vf photosensitivity=20:0.8
  </p>
  <p>
  We are not professionals. Please use this in your medical studies to
  advance epilepsy research. If you decide to use this in a medical
  setting, or make a hardware hdmi input output realtime tv filter,
  or find another use for this, <a href="mailto:compn@ffmpeg.org">please let me know</a>.
  This filter was a feature request of mine
  <a href="https://trac.ffmpeg.org/ticket/2104">since 2013</a>.
  </p>

  <h3 id="pr4.2">August 5th, 2019, FFmpeg 4.2 "Ada"</h3>
  <p>
    <a href="https://ffmpeg.org//download.html#release_4.2">FFmpeg 4.2 "Ada"</a>, a new
    major release, is now available! Some of the highlights:
  </p>
  <ul>
    <li>tpad filter</li>
    <li>AV1 decoding support through libdav1d</li>
    <li>dedot filter</li>
    <li>chromashift and rgbashift filters</li>
    <li>freezedetect filter</li>
    <li>truehd_core bitstream filter</li>
    <li>dhav demuxer</li>
    <li>PCM-DVD encoder</li>
    <li>GIF parser</li>
    <li>vividas demuxer</li>
    <li>hymt decoder</li>
    <li>anlmdn filter</li>
    <li>maskfun filter</li>
    <li>hcom demuxer and decoder</li>
    <li>ARBC decoder</li>
    <li>libaribb24 based ARIB STD-B24 caption support (profiles A and C)</li>
    <li>Support decoding of HEVC 4:4:4 content in nvdec and cuviddec</li>
    <li>removed libndi-newtek</li>
    <li>agm decoder</li>
    <li>KUX demuxer</li>
    <li>AV1 frame split bitstream filter</li>
    <li>lscr decoder</li>
    <li>lagfun filter</li>
    <li>asoftclip filter</li>
    <li>Support decoding of HEVC 4:4:4 content in vdpau</li>
    <li>colorhold filter</li>
    <li>xmedian filter</li>
    <li>asr filter</li>
    <li>showspatial multimedia filter</li>
    <li>VP4 video decoder</li>
    <li>IFV demuxer</li>
    <li>derain filter</li>
    <li>deesser filter</li>
    <li>mov muxer writes tracks with unspecified language instead of English by default</li>
    <li>added support for using clang to compile CUDA kernels</li>
  </ul>
  <p>
    We strongly recommend users, distributors, and system integrators to
    upgrade unless they use current git master.
  </p>

  <h3 id="pr4.1">November 6th, 2018, FFmpeg 4.1 "al-Khwarizmi"</h3>
  <p>
    <a href="https://ffmpeg.org//download.html#release_4.1">FFmpeg 4.1 "al-Khwarizmi"</a>, a new
    major release, is now available! Some of the highlights:
  </p>
  <ul>
    <li>deblock filter</li>
    <li>tmix filter</li>
    <li>amplify filter</li>
    <li>fftdnoiz filter</li>
    <li>aderivative and aintegral audio filters</li>
    <li>pal75bars and pal100bars video filter sources</li>
    <li>mbedTLS based TLS support</li>
    <li>adeclick and adeclip filters</li>
    <li>libtensorflow backend for DNN based filters like srcnn</li>
    <li>VC1 decoder is now bit-exact</li>
    <li>ATRAC9 decoder</li>
    <li>lensfun wrapper filter</li>
    <li>colorconstancy filter</li>
    <li>AVS2 video decoder via libdavs2</li>
    <li>IMM4 video decoder</li>
    <li>Brooktree ProSumer video decoder</li>
    <li>MatchWare Screen Capture Codec decoder</li>
    <li>WinCam Motion Video decoder</li>
    <li>1D LUT filter (lut1d)</li>
    <li>RemotelyAnywhere Screen Capture decoder</li>
    <li>cue and acue filters</li>
    <li>Support for AV1 in MP4 and Matroska/WebM</li>
    <li>transpose_npp filter</li>
    <li>AVS2 video encoder via libxavs2</li>
    <li>amultiply filter</li>
    <li>Block-Matching 3d (bm3d) denoising filter</li>
    <li>acrossover filter</li>
    <li>ilbc decoder</li>
    <li>audio denoiser as afftdn filter</li>
    <li>AV1 parser</li>
    <li>sinc audio filter source</li>
    <li>chromahold filter</li>
    <li>setparams filter</li>
    <li>vibrance filter</li>
    <li>S12M timecode decoding in h264</li>
    <li>xstack filter</li>
    <li>(a)graphmonitor filter</li>
    <li>yadif_cuda filter</li>
  </ul>
  <p>
    We strongly recommend users, distributors, and system integrators to
    upgrade unless they use current git master.
  </p>

  <h3 id="pr4.0">April 20th, 2018, FFmpeg 4.0 "Wu"</h3>
  <p>
    <a href="https://ffmpeg.org//download.html#release_4.0">FFmpeg 4.0 "Wu"</a>, a new
    major release, is now available! Some of the highlights:
  </p>
  <ul>
    <li>Bitstream filters for editing metadata in H.264, HEVC and MPEG-2 streams</li>
    <li>Experimental MagicYUV encoder</li>
    <li>TiVo ty/ty+ demuxer</li>
    <li>Intel QSV-accelerated MJPEG encoding</li>
    <li>native aptX and aptX HD encoder and decoder</li>
    <li>NVIDIA NVDEC-accelerated H.264, HEVC, MJPEG, MPEG-1/2/4, VC1, VP8/9 hwaccel decoding</li>
    <li>Intel QSV-accelerated overlay filter</li>
    <li>mcompand audio filter</li>
    <li>acontrast audio filter</li>
    <li>OpenCL overlay filter</li>
    <li>video mix filter</li>
    <li>video normalize filter</li>
    <li>audio lv2 wrapper filter</li>
    <li>VAAPI MJPEG and VP8 decoding</li>
    <li>AMD AMF H.264 and HEVC encoders</li>
    <li>video fillborders filter</li>
    <li>video setrange filter</li>
    <li>support LibreSSL (via libtls)</li>
    <li>Dropped support for building for Windows XP. The minimum supported Windows version is Windows Vista.</li>
    <li>deconvolve video filter</li>
    <li>entropy video filter</li>
    <li>hilbert audio filter source</li>
    <li>aiir audio filter</li>
    <li>Removed the ffserver program</li>
    <li>Removed the ffmenc and ffmdec muxer and demuxer</li>
    <li>VideoToolbox HEVC encoder and hwaccel</li>
    <li>VAAPI-accelerated ProcAmp (color balance), denoise and sharpness filters</li>
    <li>Add android_camera indev</li>
    <li>codec2 en/decoding via libcodec2</li>
    <li>native SBC encoder and decoder</li>
    <li>drmeter audio filter</li>
    <li>hapqa_extract bitstream filter</li>
    <li>filter_units bitstream filter</li>
    <li>AV1 Support through libaom</li>
    <li>E-AC-3 dependent frames support</li>
    <li>bitstream filter for extracting E-AC-3 core</li>
    <li>Haivision SRT protocol via libsrt</li>
    <li>vfrdet filter</li>
  </ul>
  <p>
    We strongly recommend users, distributors, and system integrators to
    upgrade unless they use current git master.
  </p>

  <h3 id="pr3.4">October 15th, 2017, FFmpeg 3.4 "Cantor"</h3>
  <p>
    <a href="https://ffmpeg.org//download.html#release_3.4">FFmpeg 3.4 "Cantor"</a>, a new
    major release, is now available! Some of the highlights:
  </p>
  <ul>
    <li>deflicker video filter</li>
    <li>doubleweave video filter</li>
    <li>lumakey video filter</li>
    <li>pixscope video filter</li>
    <li>oscilloscope video filter</li>
    <li>update cuvid/nvenc headers to Video Codec SDK 8.0.14</li>
    <li>afir audio filter</li>
    <li>scale_cuda CUDA based video scale filter</li>
    <li>librsvg support for svg rasterization</li>
    <li>crossfeed audio filter</li>
    <li>spec compliant VP9 muxing support in MP4</li>
    <li>surround audio filter</li>
    <li>sofalizer filter switched to libmysofa</li>
    <li>Gremlin Digital Video demuxer and decoder</li>
    <li>headphone audio filter</li>
    <li>superequalizer audio filter</li>
    <li>roberts video filter</li>
    <li>additional frame format support for Interplay MVE movies</li>
    <li>support for decoding through D3D11VA in ffmpeg</li>
    <li>limiter video filter</li>
    <li>libvmaf video filter</li>
    <li>Dolby E decoder and SMPTE 337M demuxer</li>
    <li>unpremultiply video filter</li>
    <li>tlut2 video filter</li>
    <li>floodfill video filter</li>
    <li>pseudocolor video filter</li>
    <li>raw G.726 muxer and demuxer, left- and right-justified</li>
    <li>NewTek NDI input/output device</li>
    <li>FITS demuxer and decoder</li>
    <li>FITS muxer and encoder</li>
    <li>despill video filter</li>
    <li>haas audio filter</li>
    <li>SUP/PGS subtitle muxer</li>
    <li>convolve video filter</li>
    <li>VP9 tile threading support</li>
    <li>KMS screen grabber</li>
    <li>CUDA thumbnail filter</li>
    <li>V4L2 mem2mem HW assisted codecs</li>
    <li>Rockchip MPP hardware decoding</li>
    <li>vmafmotion video filter</li>
  </ul>
  <p>
    We strongly recommend users, distributors, and system integrators to
    upgrade unless they use current git master.
  </p>

  <h3 id="pr3.3">April 13th, 2017, FFmpeg 3.3 "Hilbert"</h3>
  <p>
    <a href="https://ffmpeg.org//download.html#release_3.3">FFmpeg 3.3 "Hilbert"</a>, a new
    major release, is now available! Some of the highlights:
  </p>
  <ul>
    <li>Apple Pixlet decoder</li>
    <li>NewTek SpeedHQ decoder</li>
    <li>QDMC audio decoder</li>
    <li>PSD (Photoshop Document) decoder</li>
    <li>FM Screen Capture decoder</li>
    <li>ScreenPressor decoder</li>
    <li>XPM decoder</li>
    <li>DNxHR decoder fixes for HQX and high resolution videos</li>
    <li>ClearVideo decoder (partial)</li>
    <li>16.8 and 24.0 floating point PCM decoder</li>
    <li>Intel QSV-accelerated VP8 video decoding</li>
    <li>native Opus encoder</li>
    <li>DNxHR 444 and HQX encoding</li>
    <li>Quality improvements for the (M)JPEG encoder</li>
    <li>VAAPI-accelerated MPEG-2 and VP8 encoding</li>
    <li>premultiply video filter</li>
    <li>abitscope multimedia filter</li>
    <li>readeia608 filter</li>
    <li>threshold filter</li>
    <li>midequalizer filter</li>
    <li>MPEG-7 Video Signature filter</li>
    <li>add internal ebur128 library, remove external libebur128 dependency</li>
    <li>Intel QSV video scaling and deinterlacing filters</li>
    <li>Sample Dump eXchange demuxer</li>
    <li>MIDI Sample Dump Standard demuxer</li>
    <li>Scenarist Closed Captions demuxer and muxer</li>
    <li>Support MOV with multiple sample description tables</li>
    <li>Pro-MPEG CoP #3-R2 FEC protocol</li>
    <li>Support for spherical videos</li>
    <li>CrystalHD decoder moved to new decode API</li>
    <li>configure now fails if autodetect-libraries are requested but not found</li>
  </ul>
  <p>
    We strongly recommend users, distributors, and system integrators to
    upgrade unless they use current git master.
  </p>

  <h3 id="gsoc2016finalreport">October 30th, 2016, Results: Summer Of Code 2016.</h3>
  <p>
    This has been a long time coming but we wanted to give a proper closure to our participation in this run of the program and it takes time. Sometimes it's just to get the final report for each project trimmed down, others, is finalizing whatever was still in progress when the program finished: final patches need to be merged, TODO lists stabilized, future plans agreed; you name it.
  </p>
  <p>
    Without further ado, here's the silver-lining for each one of the projects we sought to complete during this Summer of Code season:
  </p>
  <h4>FFv1 (Mentor: Michael Niedermayer)</h4>
  <p>
    Stanislav Dolganov designed and implemented experimental support for motion estimation and compensation in the lossless FFV1 codec. The design and implementation is based on the snow video codec, which uses OBMC. Stanislav's work proved that significant compression gains can be achieved with inter frame compression. FFmpeg welcomes Stanislav to continue working beyond this proof of concept and bring its advances into the official FFV1 specification within the IETF.
  </p>
  <h4>Self test coverage (Mentor: Michael Niedermayer)</h4>
  <p>
    Petru Rares Sincraian added several self-tests to FFmpeg and successfully went through the in-some-cases tedious process of fine tuning tests parameters to avoid known and hard to avoid problems, like checksum mismatches due to rounding errors on the myriad of platforms we support. His work has improved the code coverage of our self tests considerably.
  </p>
  <h4>MPEG-4 ALS encoder implementation (Mentor: Thilo Borgmann)</h4>
  <p>
    Umair Khan updated and integrated the ALS encoder to fit in the current FFmpeg codebase. He also implemented a missing feature for the ALS decoder that enables floating-point sample decoding. FFmpeg support for MPEG-4 ALS has been improved significantly by Umair's work. We welcome him to keep maintaining his improvements and hope for great contributions to come.
  </p>
  <h4>Tee muxer improvements (Mentor: Marton Balint)</h4>
  <p>
    Ján Sebechlebský's generic goal was to improve the tee muxer so it tolerated blocking IO and allowed transparent error recovery. During the design phase it turned out that this functionality called for a separate muxer, so Ján spent his summer working on the so-called FIFO muxer, gradually fixing issues all over the codebase. He succeeded in his task, and the FIFO muxer is now part of the main repository, alongside several other improvements he made in the process.
  </p>
  <h4>TrueHD encoder (Mentor: Rostislav Pehlivanov)</h4>
  <p>
    Jai Luthra's objective was to update the out-of-tree and pretty much abandoned MLP (Meridian Lossless Packing) encoder for libavcodec and improve it to enable encoding to the TrueHD format. For the qualification period the encoder was updated such that it was usable and throughout the summer, successfully improved adding support for multi-channel audio and TrueHD encoding. Jai's code has been merged into the main repository now. While a few problems remain with respect to LFE channel and 32 bit sample handling, these are in the process of being fixed such that effort can be finally put in improving the encoder's speed and efficiency.
  </p>
  <h4>Motion interpolation filter (Mentor: Paul B Mahol)</h4>
  <p>
    Davinder Singh investigated existing motion estimation and interpolation approaches from the available literature and previous work by our own: Michael Niedermayer, and implemented filters based on this research. These filters allow motion interpolating frame rate conversion to be applied to a video, for example, to create a slow motion effect or change the frame rate while smoothly interpolating the video along the motion vectors. There's still work to be done to call these filters 'finished', which is rather hard all things considered, but we are looking optimistically at their future.
  </p>
  <p>
    And that's it. We are happy with the results of the program and immensely thankful for the opportunity of working with such an amazing set of students. We can be a tough crowd but our mentors did an amazing job at hand holding our interns through their journey. Thanks also to Google for this wonderful program and to everyone that made room in their busy lives to help making GSoC2016 a success. See you in 2017!
  </p>
  <h3 id="sdl1">September 24th, 2016, SDL1 support dropped.</h3>
  <p>
    Support for the SDL1 library has been dropped, due to it no longer being maintained (as of
    January, 2012) and it being superseded by the SDL2 library. As a result, the SDL1 output device
    has also been removed and replaced by an SDL2 implementation. Both the ffplay and opengl output
    devices have been updated to support SDL2.
  </p>
  <h3 id="pr3.1.2">August 9th, 2016, FFmpeg 3.1.2 "Laplace"</h3>
  <p>
    <a href="https://ffmpeg.org//download.html#release_3.1">FFmpeg 3.1.2</a>, a new point release from the 3.1 release branch, is now available!
    It fixes several bugs.
  </p>
  <p>
    We recommend users, distributors, and system integrators, to upgrade unless they use current git master.
  </p>
  <h3 id="ffserv">July 10th, 2016, ffserver program being dropped</h3>
  <p>
    After thorough deliberation, we're announcing that we're about to drop the ffserver program from the project starting with the next release.
    ffserver has been a problematic program to maintain due to its use of internal APIs, which complicated the recent cleanups to the libavformat
    library, and block further cleanups and improvements which are desired by API users and will be easier to maintain. Furthermore the program has
    been hard for users to deploy and run due to reliability issues, lack of knowledgable people to help and confusing configuration file syntax.
    Current users and members of the community are invited to write a replacement program to fill the same niche that ffserver did using the new APIs
    and to contact us so we may point users to test and contribute to its development.
  </p>
  <h3 id="pr3.1.1">July 1st, 2016, FFmpeg 3.1.1 "Laplace"</h3>
  <p>
    <a href="https://ffmpeg.org//download.html#release_3.1">FFmpeg 3.1.1</a>, a new point release from the 3.1 release branch, is now available!
    It mainly deals with a few ABI issues introduced in the previous release.
  </p>
  <p>
    We strongly recommend users, distributors, and system integrators, especially those who experienced issues upgrading from 3.0, to
    upgrade unless they use current git master.
  </p>

  <h3 id="pr3.1">June 27th, 2016, FFmpeg 3.1 "Laplace"</h3>
  <p>
    <a href="https://ffmpeg.org//download.html#release_3.1">FFmpeg 3.1 "Laplace"</a>, a new
    major release, is now available! Some of the highlights:
  </p>
  <ul>
    <li>DXVA2-accelerated HEVC Main10 decoding</li>
    <li>fieldhint filter</li>
    <li>loop video filter and aloop audio filter</li>
    <li>Bob Weaver deinterlacing filter</li>
    <li>firequalizer filter</li>
    <li>datascope filter</li>
    <li>bench and abench filters</li>
    <li>ciescope filter</li>
    <li>protocol blacklisting API</li>
    <li>MediaCodec H264 decoding</li>
    <li>VC-2 HQ RTP payload format (draft v1) depacketizer and packetizer</li>
    <li>VP9 RTP payload format (draft v2) packetizer</li>
    <li>AudioToolbox audio decoders</li>
    <li>AudioToolbox audio encoders</li>
    <li>coreimage filter (GPU based image filtering on OSX)</li>
    <li>libdcadec removed</li>
    <li>bitstream filter for extracting DTS core</li>
    <li>ADPCM IMA DAT4 decoder</li>
    <li>musx demuxer</li>
    <li>aix demuxer</li>
    <li>remap filter</li>
    <li>hash and framehash muxers</li>
    <li>colorspace filter</li>
    <li>hdcd filter</li>
    <li>readvitc filter</li>
    <li>VAAPI-accelerated format conversion and scaling</li>
    <li>libnpp/CUDA-accelerated format conversion and scaling</li>
    <li>Duck TrueMotion 2.0 Real Time decoder</li>
    <li>Wideband Single-bit Data (WSD) demuxer</li>
    <li>VAAPI-accelerated H.264/HEVC/MJPEG encoding</li>
    <li>DTS Express (LBR) decoder</li>
    <li>Generic OpenMAX IL encoder with support for Raspberry Pi</li>
    <li>IFF ANIM demuxer &amp; decoder</li>
    <li>Direct Stream Transfer (DST) decoder</li>
    <li>loudnorm filter</li>
    <li>MTAF demuxer and decoder</li>
    <li>MagicYUV decoder</li>
    <li>OpenExr improvements (tile data and B44/B44A support)</li>
    <li>BitJazz SheerVideo decoder</li>
    <li>CUDA CUVID H264/HEVC decoder</li>
    <li>10-bit depth support in native utvideo decoder</li>
    <li>libutvideo wrapper removed</li>
    <li>YUY2 Lossless Codec decoder</li>
    <li>VideoToolbox H.264 encoder</li>
  </ul>
  <p>
    We strongly recommend users, distributors, and system integrators to
    upgrade unless they use current git master.
  </p>

  <h3 id="gsoc2016">March 16th, 2016, Google Summer of Code</h3>
  <p>
    FFmpeg has been accepted as a <a href="https://summerofcode.withgoogle.com/">Google Summer of Code</a> open source organization. If you wish to
    participate as a student see our <a href="https://trac.ffmpeg.org/wiki/SponsoringPrograms/GSoC/2016">project ideas page</a>.
    You can already get in contact with mentors and start working on qualification tasks as well as register at google and submit your project proposal draft.
    Good luck!
  </p>

  <h3 id="pr3.0">February 15th, 2016, FFmpeg 3.0 "Einstein"</h3>
  <p>
    <a href="https://ffmpeg.org//download.html#release_3.0">FFmpeg 3.0 "Einstein"</a>, a new
    major release, is now available! Some of the highlights:
  </p>
  <ul>
    <li><a href="#aac_encoder_stable">The native FFmpeg AAC encoder has seen extensive improvements and is no longer considered experimental</a></li>
    <li><a href="#removing_external_aac_encoders">Removed support for libvo-aacenc and libaacplus</a></li>
    <li>Over 30 new filters have been added</li>
    <li>Many ASM optimizations</li>
    <li>VP9 Hardware Acceleration (DXVA2 and VA-API)</li>
    <li>Cineform HD decoder</li>
    <li>New DCA decoder based on libdcadec with full support for DTS-HD extensions</li>
    <li>As with all major releases expect major backward incompatible API/ABI changes</li>
    <li>See the <a href="https://git.videolan.org/?p=ffmpeg.git;a=blob_plain;f=Changelog;hb=n3.0">Changelog</a> for a list of more updates</li>
  </ul>
  <p>
    We strongly recommend users, distributors, and system integrators to
    upgrade unless they use current git master.
  </p>

  <h3 id="removing_external_aac_encoders">January 30, 2016, Removing support for two external AAC encoders</h3>
  <p>
    We have just removed support for VisualOn AAC encoder (libvo-aacenc) and
    libaacplus in FFmpeg master.
  </p>
  <p>
    Even before marking our internal AAC encoder as
    <a href="#aac_encoder_stable">stable</a>, it was known that libvo-aacenc
    was of an inferior quality compared to our native one for most samples.
    However, the VisualOn encoder was used extensively by the Android Open
    Source Project, and we would like to have a tested-and-true stable option
    in our code base.
  </p>
  <p>
    When first committed in 2011, libaacplus filled in the gap of encoding
    High Efficiency AAC formats (HE-AAC and HE-AACv2), which was not supported
    by any of the encoders in FFmpeg at that time.
  </p>
  <p>
    The circumstances for both have changed. After the work spearheaded by
    Rostislav Pehlivanov and Claudio Freire, the now-stable FFmpeg native AAC
    encoder is ready to compete with much more mature encoders. The Fraunhofer
    FDK AAC Codec Library for Android was added in 2012 as the fourth
    supported external AAC encoder, and the one with the best quality and the
    most features supported, including HE-AAC and HE-AACv2.
  </p>
  <p>
    Therefore, we have decided that it is time to remove libvo-aacenc and
    libaacplus. If you are currently using libvo-aacenc, prepare to transition
    to the native encoder (<code>aac</code>) when updating to the next version
    of FFmpeg. In most cases it is as simple as merely swapping the encoder
    name. If you are currently using libaacplus, start using FDK AAC
    (<code>libfdk_aac</code>) with an appropriate <code>profile</code> option
    to select the exact AAC profile that fits your needs. In both cases, you
    will enjoy an audible quality improvement and as well as fewer licensing
    headaches.
  </p>
  <p>
    Enjoy!
  </p>

  <h3 id="pr2.8.5">January 16, 2016, FFmpeg 2.8.5, 2.7.5, 2.6.7, 2.5.10</h3>
  <p>
    We have made several new point releases (<b><a href="https://ffmpeg.org//download.html#release_2.8">2.8.5</a>,
      <a href="https://ffmpeg.org//download.html#release_2.7">2.7.5</a>,
      <a href="https://ffmpeg.org//download.html#release_2.6">2.6.7</a>,
      <a href="https://ffmpeg.org//download.html#release_2.5">2.5.10</a></b>).
    They fix various bugs, as well as CVE-2016-1897 and CVE-2016-1898.
    Please see the changelog for each release for more details.
  </p>
  <p>
    We recommend users, distributors and system integrators to upgrade unless they use
    current git master.
  </p>

  <h3 id="aac_encoder_stable">December 5th, 2015, The native FFmpeg AAC encoder is now stable!</h3>
  <p>
    After seven years the native FFmpeg AAC encoder has had its experimental flag
    removed and declared as ready for general use. The encoder is transparent
    at 128kbps for most samples tested with artifacts only appearing in extreme
    cases. Subjective quality tests put the encoder to be of equal or greater
    quality than most of the other encoders available to the public.
  </p>
  <p>
    Licensing has always been an issue with encoding AAC audio as most of the
    encoders have had a license making FFmpeg unredistributable if compiled with
    support for them. The fact that there now exists a fully open and truly
    free AAC encoder integrated directly within the project means a lot to those
    who wish to use accepted and widespread standards.
  </p>
  <p>
    The majority of the work done to bring the encoder up to quality was started
    during this year's GSoC by developer Claudio Freire and Rostislav Pehlivanov.
    Both continued to work on the encoder with the latter joining as a developer
    and mainainer, working on other parts of the project as well. Also, thanks
    to <a href="http://d.hatena.ne.jp/kamedo2/">Kamedo2</a> who does comparisons
    and tests, the original authors and all past and current contributors to the
    encoder. Users are suggested and encouraged to use the encoder and provide
    feedback or breakage reports through our <a href="https://trac.ffmpeg.org/">bug tracker</a>.
  </p>

  
  <p>
    A big thank you note goes to our newest supporters: MediaHub and Telepoint.
    Both companies have donated a dedicated server with free of charge internet
    connectivity. Here is a little bit about them in their own words:
  </p>

  <ul>
    <li>
      <p>
        <a href="http://www.telepoint.bg/en/">Telepoint</a> is the biggest
        carrier-neutral data center in Bulgaria. Located in the heart of Sofia
        on a cross-road of many Bulgarian and International networks, the
        facility is a fully featured Tier 3 data center that provides flexible
        customer-oriented colocation solutions (ranging from a server to a
        private collocation hall) and a high level of security.
      </p>
    </li>

    <li>
      <p>
        MediaHub Ltd. is a Bulgarian IPTV platform and services provider which
        uses FFmpeg heavily since it started operating a year ago. <i>"Donating
        to help keep FFmpeg online is our way of giving back to the community"
        </i>.
      </p>
    </li>
  </ul>

  <p>
    Thanks Telepoint and MediaHub for their support!
  </p>

  <h3 id="gsoc2015_result">September 29th, 2015, GSoC 2015 results</h3>

  <p>
    FFmpeg participated to the latest edition of
    the <a href="http://www.google-melange.com/gsoc/homepage/google/gsoc2015">Google
    Summer of Code</a> Project. FFmpeg got a total of 8 assigned
    projects, and 7 of them were successful.
  </p>

  <p>We want to thank <a href="https://www.google.com/">Google</a>, the
    participating students, and especially the mentors who joined this
    effort. We're looking forward to participating in the next GSoC
    edition!
  </p>

  <p>
    Below you can find a brief description of the final outcome of
    each single project.
  </p>

  <h4>Basic servers for network protocols, mentee: Stephan Holljes, mentor: Nicolas George</h4>

  <p>
    Stephan Holljes's project for this session of Google Summer of Code was to
    implement basic HTTP server features for libavformat, to complement the
    already present HTTP client and RTMP and RTSP server code.
  </p>

  <p>
    The first part of the project was to make the HTTP code capable of accepting
    a single client; it was completed partly during the qualification period and
    partly during the first week of the summer. Thanks to this work, it is now
    possible to make a simple HTTP stream using the following commands:
  </p>

  <pre>    ffmpeg -i /dev/video0 -listen 1 -f matroska \
    -c:v libx264 -preset fast -tune zerolatency http://:8080
    ffplay http://localhost:8080/
  </pre>

  <p>
    The next part of the project was to extend the code to be able to accept
    several clients, simultaneously or consecutively. Since libavformat did not
    have an API for that kind of task, it was necessary to design one. This part
    was mostly completed before the midterm and applied shortly afterwards.
    Since the ffmpeg command-line tool is not ready to serve several clients,
    the test ground for that new API is an example program serving hard-coded
    content.
  </p>

  <p>
    The last and most ambitious part of the project was to update ffserver to
    make use of the new API. It would prove that the API is usable to implement
    real HTTP servers, and expose the points where more control was needed. By
    the end of the summer, a first working patch series was undergoing code
    review.
  </p>

  <h4>Browsing content on the server, mentee: Mariusz Szczepańczyk, mentor: Lukasz Marek</h4>

  <p>
    Mariusz finished an API prepared by the FFmpeg community and implemented
    Samba directory listing as qualification task.
  </p>

  <p>
    During the program he extended the API with the possibility to
    remove and rename files on remote servers. He completed the
    implementation of these features for file, Samba, SFTP, and FTP
    protocols.
  </p>

  <p>
    At the end of the program, Mariusz provided a sketch of an
    implementation for HTTP directory listening.
  </p>

  <h4>Directshow digital video capture, mentee: Mate Sebok, mentor: Roger Pack</h4>

  <p>
    Mate was working on directshow input from digital video sources. He
    got working input from ATSC input sources, with specifiable tuner.
  </p>

  <p>
    The code has not been committed, but a patch of it was sent to the
    ffmpeg-devel mailing list for future use.
  </p>

  <p>
    The mentor plans on cleaning it up and committing it, at least for the
    ATSC side of things. Mate and the mentor are still working trying to
    finally figure out how to get DVB working.
  </p>

  <h4>Implementing full support for 3GPP Timed Text Subtitles, mentee: Niklesh Lalwani, mentor: Philip Langdale</h4>

  <p>
    Niklesh's project was to expand our support for 3GPP Timed Text
    subtitles. This is the native subtitle format for mp4 containers, and
    is interesting because it's usually the only subtitle format supported
    by the stock playback applications on iOS and Android devices.
  </p>

  <p>
    ffmpeg already had basic support for these subtitles which ignored all
    formatting information - it just provided basic plain-text support.
  </p>

  <p>
    Niklesh did work to add support on both the encode and decode side for
    text formatting capabilities, such as font size/colour and effects like
    bold/italics, highlighting, etc.
  </p>

  <p>
    The main challenge here is that Timed Text handles formatting in a very
    different way from most common subtitle formats. It uses a binary
    encoding (based on mp4 boxes, naturally) and stores information
    separately from the text itself. This requires additional work to track
    which parts of the text formatting applies to, and explicitly dealing
    with overlapping formatting (which other formats support but Timed
    Text does not) so it requires breaking the overlapping sections into
    separate non-overlapping ones with different formatting.
  </p>

  <p>
    Finally, Niklesh had to be careful about not trusting any size
    information in the subtitles - and that's no joke: the now infamous
    Android stagefright bug was in code for parsing Timed Text subtitles.
  </p>

  <p>
    All of Niklesh's work is committed and was released in ffmpeg 2.8.
  </p>

<h4>libswscale refactoring, mentee: Pedro Arthur, mentors: Michael Niedermayer, Ramiro Polla</h4>

  <p>
    Pedro Arthur has modularized the vertical and horizontal scalers.
    To do this he designed and implemented a generic filter framework
    and moved the existing scaler code into it. These changes now allow
    easily adding removing, splitting or merging processing steps.
    The implementation was benchmarked and several alternatives were
    tried to avoid speed loss.
  </p>

  <p>
    He also added gamma corrected scaling support.
    An example to use gamma corrected scaling would be:
  </p>

  <pre>    ffmpeg -i input -vf scale=512:384:gamma=1 output
  </pre>

  <p>
    Pedro has done impressive work considering the short time available,
    and he is a FFmpeg committer now. He continues to contribute to
    FFmpeg, and has fixed some bugs in libswscale after GSoC has
    ended.
  </p>

  <h4>AAC Encoder Improvements, mentee: Rostislav Pehlivanov, mentor: Claudio Freire</h4>

  <p>
    Rostislav Pehlivanov has implemented PNS, TNS, I/S coding and main
    prediction on the native AAC encoder. Of all those extensions, only
    TNS was left in a less-than-usable state, but the implementation has
    been pushed (disabled) anyway since it's a good basis for further
    improvements.
  </p>

  <p>
    PNS replaces noisy bands with a single scalefactor representing the
    energy of that band, gaining in coding efficiency considerably, and
    the quality improvements on low bitrates are impressive for such a
    simple feature.
  </p>

  <p>
    TNS still needs some polishing, but has the potential to reduce coding
    artifacts by applying noise shaping in the temporal domain (something
    that is a source of annoying, notable distortion on low-entropy
    bands).
  </p>

  <p>
    Intensity Stereo coding (I/S) can double coding efficiency by
    exploiting strong correlation between stereo channels, most effective
    on pop-style tracks that employ panned mixing. The technique is not as
    effective on classic X-Y recordings though.
  </p>

  <p>
    Finally, main prediction improves coding efficiency by exploiting
    correlation among successive frames. While the gains have not been
    huge at this point, Rostislav has remained active even after the GSoC,
    and is polishing both TNS and main prediction, as well as looking for
    further improvements to make.
  </p>

  <p>
    In the process, the MIPS port of the encoder was broken a few times,
    something he's also working to fix.
  </p>

  <h4>Animated Portable Network Graphics (APNG), mentee: Donny Yang, mentor: Paul B Mahol</h4>

  <p>
    Donny Yang implemented basic keyframe only APNG encoder as the
    qualification task. Later he wrote interframe compression via
    various blend modes. The current implementation tries all blend
    modes and picks one which takes the smallest amount of memory.
  </p>

  <p>
    Special care was taken to make sure that the decoder plays
    correctly all files found in the wild and that the encoder
    produces files that can be played in browsers that support APNG.
  </p>

  <p>
    During his work he was tasked to fix any encountered bug in the
    decoder due to the fact that it doesn't match APNG
    specifications. Thanks to this work, a long standing bug in the
    PNG decoder has been fixed.
  </p>

  <p>
    For latter work he plans to continue working on the encoder,
    making it possible to select which blend modes will be used in the
    encoding process. This could speed up encoding of APNG files.
  </p>

  <h3 id="pr2.8">September 9th, 2015, FFmpeg 2.8</h3>
  <p>
    We published release <b><a href="https://ffmpeg.org//download.html#release_2.8">2.8</a></b> as new major version.
    It contains all features and bug fixes of the git master branch from September 8th. Please see
    the <b><a href="https://raw.githubusercontent.com/FFmpeg/FFmpeg/release/2.8/Changelog">changelog</a></b>
    for a list of the most important changes.
  </p>
  <p>
    We recommend users, distributors and system integrators to upgrade unless they use current git master.
  </p>

  <h3 id="message">August 1st, 2015, A message from the FFmpeg project</h3>
  <p>
    Dear multimedia community,
  </p>
  <p>
    The resignation of Michael Niedermayer as leader of FFmpeg yesterday has
    come by surprise. He has worked tirelessly on the FFmpeg project for many
    years and we must thank him for the work that he has done. We hope that in
    the future he will continue to contribute to the project. In the coming
    weeks, the FFmpeg project will be managed by the active contributors.
  </p>
  <p>
    The last four years have not been easy for our multimedia community - both
    contributors and users. We should now look to the future, try to find
    solutions to these issues, and to have reconciliation between the forks,
    which have split the community for so long.
  </p>
  <p>
    Unfortunately, much of the disagreement has taken place in inappropriate
    venues so far, which has made finding common ground and solutions
    difficult. We aim to discuss this in our communities online over the coming
    weeks, and in person at the <a href="https://www.videolan.org/videolan/events/vdd15/">VideoLAN Developer
    Days</a> in Paris in September: a neutral venue for the entire open source
    multimedia community.
  </p>
  <p>
    The FFmpeg project.
  </p>

  <h3 id="needhost">July 4th, 2015, FFmpeg needs a new host</h3>
  <p><b>UPDATE:</b> We have received more than 7 offers for hosting and servers, thanks a lot to everyone!</p>
  <p>
    After graciously hosting our projects (<a href="http://www.ffmpeg.org/">FFmpeg</a>, <a href="http://www.mplayerhq.hu/">MPlayer</a>
    and <a href="http://rtmpdump.mplayerhq.hu/">rtmpdump</a>) for 4 years, Arpi (our hoster) has informed us that we have to secure a new host somewhere else immediately.
  </p>
  <p>
    If you want to host an open source project, please let us know, either on <a href="http://ffmpeg.org/mailman/listinfo/ffmpeg-devel">ffmpeg-devel</a>
    mailing list or irc.freenode.net #ffmpeg-devel.
  </p>
  <p>
    We use about 4TB of storage and at least 4TB of bandwidth / month for various mailing lists, <a href="http://trac.ffmpeg.org/">trac</a>, <a href="http://samples.ffmpeg.org/">samples repo</a>, svn, etc.
  </p>

  <h3 id="pr2.6.1">March 16, 2015, FFmpeg 2.6.1</h3>
  <p>
    We have made a new major release (<b><a href="https://ffmpeg.org//download.html#release_2.6">2.6</a></b>)
    and now one week afterward 2.6.1. It contains all features and bugfixes of the git master branch from the 6th March.
    Please see the <b><a href="http://git.videolan.org/?p=ffmpeg.git;a=blob;f=RELEASE_NOTES;hb=release/2.6">Release Notes</a></b> for a
    list of note-worthy changes.
  </p>
  <p>
    We recommend users, distributors and system integrators to upgrade unless they use
    current git master.
  </p>

  <h3 id="gsoc2015">March 4, 2015, Google Summer of Code</h3>
  <p>
    FFmpeg has been accepted as a <a href="http://www.google-melange.com/gsoc/homepage/google/gsoc2015">Google Summer of Code</a> Project. If you wish to
    participate as a student see our <a href="https://trac.ffmpeg.org/wiki/SponsoringPrograms/GSoC/2015">project ideas page</a>.
    You can already get in contact with mentors and start working on qualification tasks. Registration
    at Google for students will open March 16th. Good luck!
  </p>

  <h3 id="clt2015">March 1, 2015, Chemnitzer Linux-Tage</h3>
  <p>
    We happily announce that FFmpeg will be represented at Chemnitzer Linux-Tage
    (CLT) in Chemnitz, Germany. The event will take place on 21st and 22nd of March.
  </p>

  <p>
    More information can be found <a href="https://chemnitzer.linux-tage.de/2015/en/">here</a>
  </p>

  <p>
    We demonstrate usage of FFmpeg, answer your questions and listen to
    your problems and wishes. <strong>If you have media files that cannot be
    processed correctly with FFmpeg, be sure to have a sample with you
    so we can have a look!</strong>
  </p>
  <p>
    For the first time in our CLT history, there will be an <strong>FFmpeg workshop</strong>!
    You can read the details <a href="https://chemnitzer.linux-tage.de/2015/de/programm/beitrag/209">here</a>.
    The workshop is targeted at FFmpeg beginners. First the basics of
    multimedia will be covered. Thereafter you will learn how to use
    that knowledge and the FFmpeg CLI tools to analyse and process media
    files. The workshop is in German language only and prior registration
    is necessary. The workshop will be on Saturday starting at 10 o'clock.
  </p>
  <p>
    We are looking forward to meet you (again)!
  </p>

  <h3 id="pr2.5">December 5, 2014, FFmpeg 2.5</h3>
  <p>
    We have made a new major release (<b><a href="https://ffmpeg.org//download.html#release_2.5">2.5</a></b>)
    It contains all features and bugfixes of the git master branch from the 4th December.
    Please see the <b><a href="http://git.videolan.org/?p=ffmpeg.git;a=blob;f=RELEASE_NOTES;hb=release/2.5">Release Notes</a></b> for a
    list of note-worthy changes.
  </p>
  <p>
    We recommend users, distributors and system integrators to upgrade unless they use
    current git master.
  </p>

  <h3 id="ffmpeg_back_in_sid">October 10, 2014, FFmpeg is in Debian unstable again</h3>
  <p>
    We wanted you to know there are
    <a href="https://packages.debian.org/search?keywords=ffmpeg&amp;searchon=sourcenames&amp;suite=unstable&amp;section=main">
    FFmpeg packages in Debian unstable</a> again. <strong>A big thank-you
    to Andreas Cadhalpun and all the people that made it possible.</strong> It has been anything but simple.
  </p>
  <p>
    Unfortunately that was already the easy part of this news. The bad news is the packages probably won't
    migrate to Debian testing to be in the upcoming release codenamed jessie.
    <a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=763148">Read the argumentation over at Debian.</a>
  </p>
  <p>
    <strong>However things will come out in the end, we hope for your continued remarkable support!</strong>
  </p>

  <h3 id="opw03">October 8, 2014, FFmpeg secured a place in OPW!</h3>
  <p>
    Thanks to a generous 6K USD donation by Samsung (Open Source Group),
    FFmpeg will be welcoming at least 1 "Outreach Program for Women" intern
    to work with our community for an initial period starting December 2014
    (through March 2015).
  </p>

  <p>
    We all know FFmpeg is used by the industry, but even while there are
    countless products building on our code, it is not at all common for
    companies to step up and help us out when needed. So a big thank-you
    to Samsung and the OPW program committee!
  </p>

  <p>
    If you are thinking on participating in OPW as an intern, please take
    a look at our <a href="https://trac.ffmpeg.org/wiki/SponsoringPrograms/OPW/2014-12">OPW wiki page</a>
    for some initial guidelines. The page is still a work in progress, but
    there should be enough information there to get you started. If you, on
    the other hand, are thinking on sponsoring work on FFmpeg through the
    OPW program, please get in touch with us at opw@ffmpeg.org. With your
    help, we might be able to secure some extra intern spots for this round!
  </p>

  <h3 id="pr2.4">September 15, 2014, FFmpeg 2.4</h3>
  <p>
    We have made a new major release (<b><a href="https://ffmpeg.org//download.html#release_2.4">2.4</a></b>)
    It contains all features and bugfixes of the git master branch from the 14th September.
    Please see the <b><a href="http://git.videolan.org/?p=ffmpeg.git;a=blob;f=RELEASE_NOTES;hb=release/2.4">Release Notes</a></b> for a
    list of note-worthy changes.
  </p>
  <p>
    We recommend users, distributors and system integrators to upgrade unless they use
    current git master.
  </p>

  <h3 id="pr2.3.3">August 20, 2014, FFmpeg 2.3.3, 2.2.7, 1.2.8</h3>
  <p>
    We have made several new point releases (<b><a href="https://ffmpeg.org//download.html#release_2.3">2.3.3</a>,
      <a href="https://ffmpeg.org//download.html#release_2.2">2.2.7</a>,
      <a href="https://ffmpeg.org//download.html#release_1.2">1.2.8</a></b>).
    They fix various bugs, as well as CVE-2014-5271 and CVE-2014-5272.
    Please see the changelog for more details.
  </p>
  <p>
    We recommend users, distributors and system integrators to upgrade unless they use
    current git master.
  </p>

  <h3 id="opw02">July 29, 2014, Help us out securing our spot in OPW</h3>
  <p>
    Following our previous post regarding our participation on this year's
    OPW (Outreach Program for Women), we are now reaching out to our users
    (both individuals and companies) to help us gather the needed money to
    secure our spot in the program.<br>
    We need to put together 6K USD as a minimum but securing more funds would
    help us towards getting more than one intern.<br>
    You can donate by credit card using
    <a href="https://co.clickandpledge.com/advanced/default.aspx?wid=56226">
    Click&amp;Pledge</a> and selecting the "OPW" option. If you would like to
    donate by money transfer or by check, please get in touch by
    <a href="mailto:opw@ffmpeg.org">e-mail</a> and we will get back to you
    with instructions.<br>Thanks!
  </p>

  <h3 id="newweb">July 20, 2014, New website</h3>
  <p>
    The FFmpeg project is proud to announce a brand new version of the website
    made by <a href="http://db0.fr/">db0</a>. While this was initially motivated
    by the need for a larger menu, the whole website ended up being redesigned,
    and most pages got reworked to ease navigation. We hope you'll enjoy
    browsing it.
  </p>

  <h3 id="pr2.3">July 17, 2014, FFmpeg 2.3</h3>
  <p>
    We have made a new major release (<b><a href="https://ffmpeg.org//download.html#release_2.3">2.3</a></b>)
    It contains all features and bugfixes of the git master branch from the 16th July.
    Please see the <b><a href="http://git.videolan.org/?p=ffmpeg.git;a=blob;f=RELEASE_NOTES;hb=489d066">Release Notes</a></b> for a
    list of note-worthy changes.
  </p>
  <p>
    We recommend users, distributors and system integrators to upgrade unless they use
    current git master.
  </p>

  <h3 id="opw01">July 3, 2014, FFmpeg and the Outreach Program For Women</h3>
  <p>
    FFmpeg has started the process to become an OPW includer organization for the
    next round of the program, with internships starting December 9. The
    <a href="https://gnome.org/opw/">OPW</a> aims to "Help women (cis and trans)
    and genderqueer to get involved in free and open source software". Part of the
    process requires securing funds to support at least one internship (6K USD), so
    if you were holding on your donation to FFmpeg, this is a great chance for you
    to come forward, get in touch and help both the project and a great initiative!
  </p>
  <p>
    We have set up an <a href="mailto:opw@ffmpeg.org">email address</a> you can use
    to contact us about donations and general inquires regarding our participation
    in the program. Hope to hear from you soon!
  </p>

  <h3 id="pr2.2.4">June 29, 2014, FFmpeg 2.2.4, 2.1.5, 2.0.5, 1.2.7, 1.1.12, 0.10.14</h3>
  <p>
    We have made several new point releases (<b><a href="https://ffmpeg.org//download.html#release_2.2">2.2.4</a>,
      <a href="https://ffmpeg.org//download.html#release_2.1">2.1.5</a>,
      <a href="https://ffmpeg.org//download.html#release_2.0">2.0.5</a>,
      <a href="https://ffmpeg.org//download.html#release_1.2">1.2.7</a>,
      <a href="https://ffmpeg.org//download.html#release_1.1">1.1.12</a>,
      <a href="https://ffmpeg.org//download.html#release_0.10">0.10.14</a></b>).
    They fix a
    <a href="http://blog.securitymouse.com/2014/06/raising-lazarus-20-year-old-bug-that.html">security issue in the LZO implementation</a>,
    as well as several other bugs. See the git log for details.
  </p>
  <p>
    We recommend users, distributors and system integrators to upgrade unless they use
    current git master.
  </p>


  <h3 id="lt2014">May 1, 2014, LinuxTag</h3>
  <p>
    Once again FFmpeg will be represented at LinuxTag in Berlin, Germany. The event will
    take place from 8th to 10th of May. Please note that this year's LinuxTag is at a
    different location closer to the city center.
  </p>

  <p>
    We will have a shared booth with XBMC and VideoLAN.
    <b>
      If you have media files that cannot be processed correctly with
      FFmpeg, be sure to have a sample with you so we can have a look!
    </b>
  </p>

  <p>
    More information about LinuxTag can be found <a href="http://www.linuxtag.org/2014/">here</a>
  </p>

  <p>
    We are looking forward to see you in Berlin!
  </p>

  <h3 id="heartbleed">April 18, 2014, OpenSSL Heartbeat bug</h3>
  <p>
    Our server hosting the Trac issue tracker was vulnerable to the attack
    against OpenSSL known as "heartbleed". The OpenSSL software library
    was updated on 7th of April, shortly after the vulnerability was publicly
    disclosed. We have changed the private keys (and certificates) for all
    FFmpeg servers. The details were sent to the mailing lists by
    Alexander Strasser, who is part of the project server team. Here is a
    link to the user mailing list
    <a href="https://lists.ffmpeg.org/pipermail/ffmpeg-user/2014-April/020968.html">archive</a>
    .
  </p><p>
    We encourage you to read up on
    <a href="https://www.schneier.com/blog/archives/2014/04/heartbleed.html">"OpenSSL heartbleed"</a>.
    <b>It is possible that login data for the issue tracker was exposed to
      people exploiting this security hole. You might want to change your password
      in the tracker and everywhere else you used that same password.</b>
  </p>

  <h3 id="pr2.2.1">April 11, 2014, FFmpeg 2.2.1</h3>
  <p>
    We have made a new point releases (<b><a href="https://ffmpeg.org//download.html#release_2.2">2.2.1</a></b>).
    It contains bug fixes for Tickets #2893, #3432, #3469, #3486, #3495 and #3540 as well as
    several other fixes.
    See the git log for details.
  </p>

  <h3 id="pr2.2">March 24, 2014, FFmpeg 2.2</h3>
  <p>
    We have made a new major release (<b><a href="https://ffmpeg.org//download.html#release_2.2">2.2</a></b>)
    It contains all features and bugfixes of the git master branch from 1st March.
    A partial list of new stuff is below:
  </p>
  <pre>    - HNM version 4 demuxer and video decoder
    - Live HDS muxer
    - setsar/setdar filters now support variables in ratio expressions
    - elbg filter
    - string validation in ffprobe
    - support for decoding through VDPAU in ffmpeg (the -hwaccel option)
    - complete Voxware MetaSound decoder
    - remove mp3_header_compress bitstream filter
    - Windows resource files for shared libraries
    - aeval filter
    - stereoscopic 3d metadata handling
    - WebP encoding via libwebp
    - ATRAC3+ decoder
    - VP8 in Ogg demuxing
    - side &amp; metadata support in NUT
    - framepack filter
    - XYZ12 rawvideo support in NUT
    - Exif metadata support in WebP decoder
    - OpenGL device
    - Use metadata_header_padding to control padding in ID3 tags (currently used in
    MP3, AIFF, and OMA files), FLAC header, and the AVI "junk" block.
    - Mirillis FIC video decoder
    - Support DNx444
    - libx265 encoder
    - dejudder filter
    - Autodetect VDA like all other hardware accelerations
  </pre>
  <p>
    We recommend users, distributors and system integrators to upgrade unless they use
    current git master.
  </p>

  <h3 id="clt2014">February 3, 2014, Chemnitzer Linux-Tage</h3>
  <p>
    We happily announce that FFmpeg will be represented at `Chemnitzer Linux-Tage'
    in Chemnitz, Germany. The event will take place on 15th and 16th of March.
  </p>

  <p>
    More information can be found <a href="http://chemnitzer.linux-tage.de/2014/en/info/">here</a>
  </p>

  <p>
    We invite you to visit us at our booth located in the Linux-Live area!
    There we will demonstrate usage of FFmpeg, answer your questions and listen to
    your problems and wishes.
  </p>
  <p>
    <b>
      If you have media files that cannot be processed correctly with
      FFmpeg, be sure to have a sample with you so we can have a look!
    </b>
  </p>
  <p>
    We are looking forward to meet you (again)!
  </p>


  <h3 id="trac_sec">February 9, 2014, trac.ffmpeg.org / trac.mplayerhq.hu Security Breach</h3>
  <p>
    The server on which FFmpeg and MPlayer Trac issue trackers were
    installed was compromised. The affected server was taken offline
    and has been replaced and all software reinstalled.
    FFmpeg Git, releases, FATE, web and mailinglists are on other servers
    and were not affected. We believe that the original compromise happened
    to a server, unrelated to FFmpeg and MPlayer, several months ago.
    That server was used as a source to clone the VM that we recently moved
    Trac to. It is not known if anyone used the backdoor that was found.
  </p>
  <p>
    We recommend all users to change their passwords.
    <b>Especially users who use a password on Trac that they also use
      elsewhere, should change that password at least elsewhere.</b>
  </p>


  <h3 id="ffmpeg_rfp">November 12, 2013, FFmpeg RFP in Debian</h3>
  <p>
    Since the splitting of Libav the Debian/Ubuntu maintainers have followed
    the Libav fork. Many people have requested the packaging of ffmpeg in
    Debian, as it is more feature-complete and in many cases less buggy.
  </p>
  <p>
    <a href="http://cynic.cc/blog/">Rogério Brito</a>, a Debian developer,
    has proposed a Request For Package (RFP) in the Debian bug tracking
    system.
  </p>
  <p>
    Please let the Debian and Ubuntu developers know that you support packaging
    of the real FFmpeg! See Debian <a href="http://bugs.debian.org/cgi-bin/bugreport.cgi?bug=729203">ticket #729203</a>
    for more details.
  </p>

  <h3 id="pr2.1">October 28, 2013, FFmpeg 2.1</h3>
  <p>
    We have made a new major release (<b><a href="https://ffmpeg.org//download.html#release_2.1">2.1</a></b>)
    It contains all features and bugfixes of the git master branch from 28th October.
    A partial list of new stuff is below:
  </p>
  <pre>    - aecho filter
    - perspective filter ported from libmpcodecs
    - ffprobe -show_programs option
    - compand filter
    - RTMP seek support
    - when transcoding with ffmpeg (i.e. not streamcopying), -ss is now accurate
    even when used as an input option. Previous behavior can be restored with
    the -noaccurate_seek option.
    - ffmpeg -t option can now be used for inputs, to limit the duration of
    data read from an input file
    - incomplete Voxware MetaSound decoder
    - read EXIF metadata from JPEG
    - DVB teletext decoder
    - phase filter ported from libmpcodecs
    - w3fdif filter
    - Opus support in Matroska
    - FFV1 version 1.3 is stable and no longer experimental
    - FFV1: YUVA(444,422,420) 9, 10 and 16 bit support
    - changed DTS stream id in lavf mpeg ps muxer from 0x8a to 0x88, to be
    more consistent with other muxers.
    - adelay filter
    - pullup filter ported from libmpcodecs
    - ffprobe -read_intervals option
    - Lossless and alpha support for WebP decoder
    - Error Resilient AAC syntax (ER AAC LC) decoding
    - Low Delay AAC (ER AAC LD) decoding
    - mux chapters in ASF files
    - SFTP protocol (via libssh)
    - libx264: add ability to encode in YUVJ422P and YUVJ444P
    - Fraps: use BT.709 colorspace by default for yuv, as reference fraps decoder does
    - make decoding alpha optional for prores, ffv1 and vp6 by setting
    the skip_alpha flag.
    - ladspa wrapper filter
    - native VP9 decoder
    - dpx parser
    - max_error_rate parameter in ffmpeg
    - PulseAudio output device
    - ReplayGain scanner
    - Enhanced Low Delay AAC (ER AAC ELD) decoding (no LD SBR support)
    - Linux framebuffer output device
    - HEVC decoder, raw HEVC demuxer, HEVC demuxing in TS, Matroska and MP4
    - mergeplanes filter
  </pre>
  <p>
    We recommend users, distributors and system integrators to upgrade unless they use
    current git master.
  </p>

  

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[She slept with a violin on her pillow (128 pts)]]></title>
            <link>https://www.nytimes.com/2024/04/04/arts/violin-italy-antonio-stradivari-ayoung-an.html</link>
            <guid>39938452</guid>
            <pubDate>Fri, 05 Apr 2024 03:37:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2024/04/04/arts/violin-italy-antonio-stradivari-ayoung-an.html">https://www.nytimes.com/2024/04/04/arts/violin-italy-antonio-stradivari-ayoung-an.html</a>, See on <a href="https://news.ycombinator.com/item?id=39938452">Hacker News</a></p>
Couldn't get https://www.nytimes.com/2024/04/04/arts/violin-italy-antonio-stradivari-ayoung-an.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[A Japanese hikikomori released a game after 6 years of development [video] (189 pts)]]></title>
            <link>https://www.youtube.com/watch?v=LJBv_hvvbBg</link>
            <guid>39938348</guid>
            <pubDate>Fri, 05 Apr 2024 03:14:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.youtube.com/watch?v=LJBv_hvvbBg">https://www.youtube.com/watch?v=LJBv_hvvbBg</a>, See on <a href="https://news.ycombinator.com/item?id=39938348">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Google Books Is Indexing AI-Generated Garbage (195 pts)]]></title>
            <link>https://www.404media.co/google-books-is-indexing-ai-generated-garbage/</link>
            <guid>39938126</guid>
            <pubDate>Fri, 05 Apr 2024 02:31:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.404media.co/google-books-is-indexing-ai-generated-garbage/">https://www.404media.co/google-books-is-indexing-ai-generated-garbage/</a>, See on <a href="https://news.ycombinator.com/item?id=39938126">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <article>
          <div>
              
<!--kg-card-begin: html-->
  <div>
    <h5>Subscribe</h5>
    <div>
      <p>Join the newsletter to get the latest updates.</p>
      <form data-members-form="subscribe">
        
        
        <div>
          
          <p>
            Great! Check your inbox and click the link.
          </p>
        </div>
        <div>
          
          <p>
            Please enter a valid email address.
          </p>
        </div>
      </form>
    </div>
  </div>

<!--kg-card-end: html-->

<!--kg-card-begin: html-->

<!--kg-card-end: html-->
<p>Google Books is indexing low quality, AI-generated books that will turn up in search results, and could possibly impact Google Ngram viewer, an important tool used by researchers to track language use throughout history.&nbsp;</p><p>I was able to find the AI-generated books with the same method we’ve previously used to find AI-generated <a href="https://www.vice.com/en/article/5d9bvn/ai-spam-is-already-flooding-the-internet-and-it-has-an-obvious-tell?ref=404media.co"><u>Amazon product reviews</u></a>, papers published in <a href="https://www.404media.co/scientific-journals-are-publishing-papers-with-ai-generated-text/"><u>academic journals</u></a>, and online <a href="https://www.404media.co/google-search-really-has-gotten-worse-researchers-find/"><u>articles</u></a>. Searching Google Books for the term “As of my last knowledge update,” which is associated with ChatGPT-generated answers, returns dozens of books that include that phrase. Some of the books are about ChatGPT, machine learning, AI, and other related subjects and include the phrase because they are discussing ChatGPT and its outputs. These books appear to be written by humans. However, most of the books in the first eight pages of results turned up by the search appear to be AI-generated and are not about AI.</p><p>For example, the 2024 book <em>Bears, Bulls, and Wolves: Stock Trading for the Twenty-Year-Old</em> by Tristin McIver, bills itself as “a transformative journey into the world of stock trading” and “a comprehensive guide designed for beginners eager to unlock the mysteries of financial markets.” In reality, it reads like ChatGPT-generated text with surface, Wikipedia-level analysis of complex financial events like Facebook’s initial public offering or the 2008 financial crisis summed up in a few short paragraphs: </p><div><p>"Despite the initial hiccups, Facebook’s stock eventually found its footing in the market. Over the years following the IPO, the company’s share price experienced fluctuations but also demonstrated resilience, reflecting the dynamic nature of the tech industry. <b><strong>As of my last knowledge update in January 2022</strong></b>, Facebook had evolved into Meta Platforms, Inc., reflecting its expansion beyond social media into virtual reality and the metaverse."</p></div><p>Other books appear to be outdated to the point of being useless at the time they are published because they are generated with a version of ChatGPT with an old “knowledge update.” For example, <em>Maximize Your Twitter Presence: 101 Strategies for Marketing Success</em> by Shu Chen Hou was published in March of 2024, according to a listing for the same book on <a href="https://www.amazon.in/dp/B0CX57Z33J?tag=wonderslate-21&amp;linkCode=osi&amp;th=1&amp;psc=1&amp;ref=404media.co"><u>Amazon</u></a>. As is the case with many AI-generated books, the same author has published dozens and dozens of books, in this case mostly children’s books with AI-generated art.&nbsp;</p><p>At the end of a multiple page section in <em>Maximize Your Twitter Presence</em> about how to become verified on Twitter (now X), the books says “As of my last update in September 2021, Twitter was in the process of evaluating and updating its verification criteria and process, so the steps and requirements may have changed since then.” Twitter, of course, was acquired by Elon Musk in 2022, and famously upended the verification process entirely, which can now simply be purchased.&nbsp;</p><p>“I cannot believe that they [Google] don't know what they're putting into Google Books search,” Gary Price, a librarian, consultant, and editor of the Library Journal's infoDOCKET, told me in a call. “They're just ingesting all this material, however it gets to them, but I have to believe that they know that this stuff is AI generated. And they would be doing themselves and users a big favor by labeling it as such.”</p><p>These AI-generated books are very similar to the type of AI-generated books we’ve <a href="https://www.404media.co/ai-generated-mushroom-foraging-books-amazon/"><u>found</u></a> on <a href="https://www.404media.co/ai-generated-kara-swisher-biographies-flood-amazon/"><u>Amazon</u></a>, and in fact, many of the books appear on both Amazon and Google Play Books. But one unintended outcome of Google Books indexing AI-generated text is its possible future inclusion in Google Ngram viewer.&nbsp;</p><p>Google Ngram viewer is a search tool that charts the frequencies of words or phrases over the years in published books scanned by Google dating back to 1500 and up to 2019, the most recent update to the Google Books corpora. Google said that none of the AI-generated books I flagged are currently informing Ngram viewer results.</p><p>“Our automated systems aim to surface relevant, high quality books for a given search, and the books in question appeared for an uncommon, specific search query,” a Google spokesperson said. “None of the identified books have factored into Ngram viewer results.”</p><p>When I asked specifically if these books will be filtered out of Google Ngram viewer corpora in the future, the Google spokesperson said “We’re committed to ensuring that the Ngram viewer remains a high quality resource, and will continue to evaluate our approach as the world of book publishing evolves.”</p><p>Ngram viewer is <a href="https://journals.plos.org/plosone/article?id=10.1371%2Fjournal.pone.0213554&amp;ref=404media.co"><u>far from perfect</u></a>, but it’s often cited in academic papers because it allows researchers to track cultural change as it is reflected in books. If AI-generated books start informing Ngram viewer results in the future, the meaning of these results will change entirely. Either they will be unreliable for teaching us about human-made culture, or they say something perhaps more bleak: that human-made culture is being replaced by AI-generated content. In some ways, this is already happening. Whether you’re on <a href="https://www.404media.co/facebooks-algorithm-is-boosting-ai-spam-that-links-to-ai-generated-ad-laden-click-farms/"><u>Facebook</u></a>, <a href="https://www.404media.co/ai-generated-grandma-porn-is-flooding-the-internet/"><u>porn sites</u></a>, or looking for books on <a href="https://www.404media.co/ai-generated-kara-swisher-biographies-flood-amazon/"><u>Amazon</u></a>, much of what we’re seeing online is AI-generated and not always disclosed as such.&nbsp;</p><p>“This seems like there will be a type of runaway feedback loop, right?” Alex Hanna, director of research at the <a href="https://www.dair-institute.org/?ref=404media.co"><u>Distributed AI Research Institute (DAIR)</u></a>, told me in an email. “Ngram viewer is already a pretty noisy signal for things which computational social scientists and linguists may care about, but it'll probably be completely unusable in a few years.”</p><p>Google also didn’t say whether it has or is formulating a policy to filter out AI-generated books from Google Books, and it did not remove any of the AI-generated books I’ve flagged to the company. “We continually work to adapt our systems and policies to ensure users find helpful and relevant books within the Google Books corpus,” the Google spokesperson said.&nbsp;</p><p>“It strikes me as another instance of AI-generated text becoming an ouroboros, where AI-generated content will be ingested into Google Books, then Google using the content to train new models,” Hanna said. “I'm sure they will say they have a ‘quality filter’ but I'm sure the details of such won't be described anywhere publicly.”</p>
<!--kg-card-begin: html-->

<!--kg-card-end: html-->

                    <div>
    <div>
      <p>About the author</p>
      <p>Emanuel Maiberg is interested in little known communities and processes that shape technology, troublemakers, and petty beefs. Email him at emanuel@404media.co
</p>
      
    </div>
      <p><img data-src="/content/images/2023/08/headshot-1.jpg" alt="Emanuel Maiberg" src="https://www.404media.co/content/images/2023/08/headshot-1.jpg">  
      </p>
  </div>
          </div>
        </article>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenBSD 7.5 Released (273 pts)]]></title>
            <link>https://www.openbsd.org/75.html</link>
            <guid>39938072</guid>
            <pubDate>Fri, 05 Apr 2024 02:19:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.openbsd.org/75.html">https://www.openbsd.org/75.html</a>, See on <a href="https://news.ycombinator.com/item?id=39938072">Hacker News</a></p>
<div id="readability-page-1" class="page">


<table>
<tbody><tr>
<td>
<a href="https://www.openbsd.org/images/King_of_Kings.jpg">
<img width="227" height="303" src="https://www.openbsd.org/images/King_of_Kings-s.gif" alt="King of Kings"></a>
</td><td>
Released Apr 5, 2024. (56th OpenBSD release)<br>
Copyright 1997-2024, Theo de Raadt.<p>

Artwork by Stipan Morian.
</p><ul>
<li>See the information on <a href="https://www.openbsd.org/ftp.html">the FTP page</a> for
    a list of mirror machines.
</li><li>Go to the <code>pub/OpenBSD/7.5/</code> directory on
    one of the mirror sites.
</li><li>Have a look at <a href="https://www.openbsd.org/errata75.html">the 7.5 errata page</a> for a list
    of bugs and workarounds.
</li><li>See a <a href="https://www.openbsd.org/plus75.html">detailed log of changes</a> between the
    7.4 and 7.5 releases.
</li><li><a href="https://man.openbsd.org/signify.1">signify(1)</a>
    pubkeys for this release:<table>
<tbody><tr><td>
openbsd-75-base.pub:
</td><td>
<a href="https://ftp.openbsd.org/pub/OpenBSD/7.5/openbsd-75-base.pub">
RWRGj1pRpprAfgeF/rgld4ubduChLvTkigA1Zj7WLDsVA4qfYSWOEI8q
</a></td></tr><tr><td>
openbsd-75-fw.pub:
</td><td>
RWQ6EsXr4NMYvyLICug3dLHfmbpXlVasF1jbt3GVNQsosgB5+PgaufBu
</td></tr><tr><td>
openbsd-75-pkg.pub:
</td><td>
RWS/sEFDvf+rjUmS1WROzxH05pB1kB7JRRq76DUGUhCE0Ks8AdpjP5pD
</td></tr><tr><td>
openbsd-75-syspatch.pub:
</td><td>
RWRAAZC5WcFgn+8b5msDR+yDVCx4ziLaSQI2sy7e4GFY42nFW9p7mP2t
</td></tr></tbody></table>
</li></ul>
<p>
All applicable copyrights and credits are in the src.tar.gz,
sys.tar.gz, xenocara.tar.gz, ports.tar.gz files, or in the
files fetched via <code>ports.tar.gz</code>.
</p></td></tr></tbody></table>

<hr>

<section id="new">
<h3>What's New</h3>
<p>
This is a partial list of new features and systems included in OpenBSD 7.5.
For a comprehensive list, see the <a href="https://www.openbsd.org/plus75.html">changelog</a> leading <!-- plus? XXX -->
to 7.5.

</p><ul>

<!--
<li>New/extended platforms:
  <ul>
  <li>...
  </ul>
-->

<li>Various kernel improvements:
  <ul>
  <li>Added <a href="https://man.openbsd.org/bt.5">bt(5)</a> and <a href="https://man.openbsd.org/btrace.8">btrace(8)</a> support for
	binary modulo operator ('%').
  </li><li>Added a TIMEOUT_MPSAFE flag to <a href="https://man.openbsd.org/timeout.9">timeout(9)</a>.
  </li><li>Added IBM encoded version of the "Spleen 8x16" font, usable as console font.
  </li><li>Cleanup and machine-independent refactoring of three context
	switch paths outside of mi_switch(): when a process forks and the new
	proc needs to be scheduled by proc_trampoline, cpu_hatch: when booting
	APs, and sched_exit: when a proc exits.
  </li><li>Made <a href="https://man.openbsd.org/vscsi.4">vscsi(4)</a>
	'vscsi_filtops' mpsafe and extended the 'sc_state_mtx' <a href="https://man.openbsd.org/mutex.9">mutex(9)</a> to protect
	'sc_klist' knotes list.
  </li><li>Made out-of-swap checking more robust, preventing potential deadlocks.
  </li><li>Eliminated the ioctl whitelist that <a href="https://man.openbsd.org/bio.4">bio(4)</a> will tunnel for other
	devices, allowing bio to be used with other (non-raid) related
	devices.
  </li><li>On msdos filesystems, ensure that a complete struct fsinfo is read
	even if the filesystem sectors are smaller.
  </li><li>Implemented per-CPU caching for the page table page (vp) pool and
	the PTE descriptor (pted) pool in the arm64 pmap implementation. This
	significantly reduces the side-effects of lock contention on the
	kernel map lock and leads to significant speedups on machines with
	many CPU cores.
  </li><li>Implemented <a href="https://man.openbsd.org/acpi.4">acpi(4)</a>
	RootPathString support in the LoadTable() AML function, fixing OpenBSD
	boot on an older version of Hyper-V.
  </li><li>Fixed Linux NFS clients freezing after five minutes of inactivity.
  </li><li>Fixed core file writing when a file map into memory has later been
	truncated to be smaller than the mapping.
  </li><li>Disallow <a href="https://man.openbsd.org/madvise.2">madvise(2)</a> and <a href="https://man.openbsd.org/msync.2">msync(2)</a> memory/mapping
	destructive operations on immutable memory regions. Instead return EPERM.
  </li><li>Added new amd64-only sysctl machdep.retpoline which says whether
	the cpu requires the retpoline branch target injection mitigation.
  </li><li>Added new accounting flag ABTCFI to <a href="https://man.openbsd.org/acct.5">acct(5)</a> to indicate SIGILL +
	code ILL_BTCFI has occurred in the process.
  </li></ul>

</li><li>SMP Improvements
  <ul>
  <li>Some network timers run without kernel lock.
  </li><li>TCP syn cache timer runs with shared net lock.
  </li><li><a href="https://man.openbsd.org/bind.2">bind(2)</a>
	and <a href="https://man.openbsd.org/connect.2">connect(2)</a>
	system calls can run in parallel.
  </li><li>Packet counter for <a href="https://man.openbsd.org/lo.4">lo(4)</a> loopback
	interface are MP safe.
  </li><li>Split protocol control block table for UDP into IPv4
	and IPv6 tables to allow concurrent access.
  </li><li>UDP packets can be sent in parallel by multiple threads.
  </li></ul>

</li><li>Direct Rendering Manager and graphics drivers
  <ul>
  <li>Updated <a href="https://man.openbsd.org/drm.4">drm(4)</a>
      to Linux 6.6.19.
  </li><li>New <a href="https://man.openbsd.org/arm64/apldcp.4">apldcp(4)</a> and
      <a href="https://man.openbsd.org/arm64/apldrm.4">apldrm(4)</a> drivers
      for Apple display coprocessor.
  </li></ul>

</li><li>VMM/VMD improvements
  <ul>
  <li>Fixed IRQ storm caused by edge-triggered devices such as the UART.
  </li><li>Fixed block size calculation for vioscsi devices.
  </li><li>Added io instruction length to vm exit information, allowing
      <a href="https://man.openbsd.org/vmd.8">vmd(8)</a> to perform validation
      in userspace.
  </li><li>Adopted new <a href="https://man.openbsd.org/imsg_init.3">imsg_get_*(3)</a>
      api.
  </li><li>Rewrote vionet devices to allow zero-copy data transfers between host and
      guest.
  </li><li>Improved error messages related to <a href="https://man.openbsd.org/getgrnam.3">
      getgrnam(3)</a> usage and out of <a href="https://man.openbsd.org/tap.4">tap(4)
      </a> device conditions.
  </li><li>Fixed various things found by smatch static analyzer.
  </li><li>Fixed various file descriptor lifecycle issues and leaks across
      <a href="https://man.openbsd.org/fork.2">fork(2)</a>/
      <a href="https://man.openbsd.org/execve.2">execve(2)</a> usage.
  </li><li>Added multi-threading support to vionet device emulation, improving latency.
  </li><li>Fixed <a href="https://man.openbsd.org/vmm.4">vmm(4)</a> instability on Intel
      VMX hosts by updating GDTR &amp; TR if vcpu moves host cpus.
  </li><li>Added EPT flushing upon <a href="https://man.openbsd.org/vmm.4">vmm(4)</a>
      enabling VMX mode.
  </li><li>Added branch predictor flushing if IBPB is supported.
  </li><li>Corrected restoring GDTR and IDTR limits upon VMX guest exit.
  </li><li>Corrected handling of CPUID 0xd subleaves
  </li><li>Added additional use of VERW and register clobbering to mitigate RFDS
      vulnerabilities on Intel Atom cores. 
  </li></ul>

</li><li>Various new userland features:
  <ul>
  <li>Made <a href="https://man.openbsd.org/malloc.3">malloc(3)</a> save
	backtraces to show in leak dump with depth of backtrace set via malloc
	option D (aka 1), 2, 3 or 4.
  </li><li>Added support for <a href="https://man.openbsd.org/cksum.1">cksum(1)</a> -c checking base64
	digests in reverse mode.
  </li><li>Added <a href="https://man.openbsd.org/kdump.1">kdump(1)</a> [-p
	program] to filter dumps by basename.
  </li><li>Made <a href="https://man.openbsd.org/ps.1">ps(1)</a> accept numerical user IDs.
  </li><li>Built and provide the tzdata.zi and leap-seconds.list files from
	zoneinfo. Some third-party software now expects these files to be
	installed. Provide the zonenow.tab file, a table where each row
	stands for a timezone where civil timestamps are predicted to agree
	from now on.
  </li><li>Added basic write support for <a href="https://man.openbsd.org/pax.1">pax(1)</a> format archives.
  </li><li>Added 'pax' format support for files over 8GB to <a href="https://man.openbsd.org/tar.1">tar(1)</a>.
  </li><li>Added 'pax' format support for mtime and atime to <a href="https://man.openbsd.org/tar.1">tar(1)</a>.
  </li><li>Extended <a href="https://man.openbsd.org/imsg_init.3">imsg</a>
	and the <a href="https://man.openbsd.org/ibuf_add.3">ibuf</a> buffer
	manipulation API with useful getter methods. Unified file descriptor
	passing in all imsg using programs with the use of the imsg_get_fd()
	function.
  </li><li>Added <a href="https://man.openbsd.org/mkdtemps.3">mkdtemps(3)</a>, identical
	to <a href="https://man.openbsd.org/mkdtemp.3">mkdtemp(3)</a> except
	that it permits a suffix to exist in the template.
  </li><li>Added <a href="https://man.openbsd.org/mktemp.1">mktemp(1)</a>
	suffix support for compatibility with the GNU version. It is now
	possible to use templates where the Xs are not at the end.
  </li></ul>

</li><li>Various bugfixes and tweaks in userland:
  <ul>
  <li>Silenced list of specific firmware not needing update in <a href="https://man.openbsd.org/pkg_add.1">pkg_add(1)</a>.
  </li><li>Improved <a href="https://man.openbsd.org/ls.1">ls(1)</a> horizontal alignment in long format.
  </li><li>Added <a href="https://man.openbsd.org/bioctl.8">bioctl(8)</a> retry on empty passphrase.
  </li><li>Fixed <a href="https://man.openbsd.org/unveil.2">unveil(2)</a> in
	<a href="https://man.openbsd.org/patch.1">patch(1)</a> with explicit
	patchfile.
  </li><li>Made gnu99 the default for gcc 3.3.6 and 4.2.1 rather than defaulting to gnu89.
  <!-- fdisk -->
  </li><li>Enhanced <a href="https://man.openbsd.org/fdisk.8">fdisk(8)</a> 'flag' to accept hex values.
  </li><li>Prevented <a href="https://man.openbsd.org/fdisk.8">fdisk(8)</a>
	'flag' from altering other GPT partition attributes when flagging a
	partition as the only bootable partition.
  </li><li>Allow <a href="https://man.openbsd.org/fdisk.8">fdisk(8)</a> to
	add GPT partitions of protected types, making it possible to provision
	virtual machine images that need a "BIOS Boot" partition.

  </li><li>Added group handling matching <a href="https://man.openbsd.org/fbtab.5">fbtab(5)</a> to xenodm.
  </li><li>Made <a href="https://man.openbsd.org/grep.1">grep(1)</a> -m behavior match GNU grep.
  </li><li>Tweaked the default memory limits in /etc/login.conf on several
	architectures to account for increased memory requirements, for
	example when compiling or linking under user pbuild.
  </li><li>Initialize all terminals with "tset -I", thereby avoiding extra
	newlines to be printed.
  </li><li>Added <a href="https://man.openbsd.org/mkhybrid.8">mkhybrid(8)</a>
	'-e' (-eltorito-boot-efi) option for writing an EFI eltorito boot
	image, in addition to or instead of the x86 boot image, to the output
	file.
  </li><li>Added <a href="https://man.openbsd.org/openrsync.1">openrsync(1)</a>
	--omit-dir-times (-O) to omit directories from --times, as well as
	--no-O and --no-omit-dir-times options for compatibility.
  </li><li>Implemented <a href="https://man.openbsd.org/openrsync.1">openrsync(1)</a>
	--omit-link-times (-J) option to omit symlinks from --times.
  </li><li>Added accounting flag and <a href="https://man.openbsd.org/lastcomm.1">lastcomm(1)</a> report for
	<a href="https://man.openbsd.org/pinsyscalls.2">syscall pinning</a> violations.
  </li><li>Added <a href="https://man.openbsd.org/ktrace.1">ktrace(1)</a> and
	<a href="https://man.openbsd.org/kdump.1">kdump(1)</a> support to
	observe <a href="https://man.openbsd.org/pinsyscall.2">pinsyscall(2)</a>
	violations.
  </li><li>Changed <a href="https://man.openbsd.org/ftp.1">ftp(1)</a> to
	avoid use of the interactive shell if -o is given.
  </li><li>Moved non-daemon services to run in a different <a href="https://man.openbsd.org/rc.8">rc(8)</a> process group to avoid
	SIGHUP at boot.
  </li><li>Changed <a href="https://man.openbsd.org/ld.so.1">ld.so(1)</a> to only load the first libc version encountered
	requested and substituting it for all further loads, ensuring that the
	libc version requested by an executable itself is the one loaded.
  </li><li>Significantly (for small programs) reduce the size of statically
	linked binaries by splitting several libc internal functions into
	separate compilation and thus linkage units. Specifically <a href="https://man.openbsd.org/getpwnam.3">getpwnam(3)</a> does not
	need the full YP socket setup and does not use all possible <a href="https://man.openbsd.org/dbopen.3">dbopen(3)</a> database
	backends.
  </li><li>Added <a href="https://man.openbsd.org/vi.1">vi(1)</a>
	showfilename set option to display the file name in the lower left
	corner.
  </li><li>Added backup of disklabel for <a href="https://man.openbsd.org/softraid.4">softraid(4)</a> chunks to <a href="https://man.openbsd.org/security.8">security(8)</a>.
  </li></ul>

</li><li>Improved hardware support and driver bugfixes, including:
  <ul>
  <li>New <a href="https://man.openbsd.org/arm64/ampchwm.4">ampchwm(4)</a>
      driver for Ampere Altra power telemetry.
  </li><li>New <a href="https://man.openbsd.org/rkspi.4">rkspi(4)</a>
      driver for Rockchip SPI controller.
  </li><li>Support for RK806 PMIC in
      <a href="https://man.openbsd.org/rkpmic.4">rkpmic(4)</a>.
  </li><li>Support for Allwinner H616 in
      <a href="https://man.openbsd.org/sxisyscon.4">sxisyscon(4)</a>,
      <a href="https://man.openbsd.org/sxiccmu.4">sxiccmu(4)</a>,
      <a href="https://man.openbsd.org/sxipio.4">sxipio(4)</a>,
      <a href="https://man.openbsd.org/sximmc.4">sximmc(4)</a> and
      <a href="https://man.openbsd.org/ehci.4">ehci(4)</a>.
  </li><li>Support for Allwinner D1 in
      <a href="https://man.openbsd.org/sxidog.4">sxidog(4)</a>,
      <a href="https://man.openbsd.org/sxiccmu.4">sxiccmu(4)</a>,
      <a href="https://man.openbsd.org/sxipio.4">sxipio(4)</a>,
      <a href="https://man.openbsd.org/sximmc.4">sximmc(4)</a> and
      <a href="https://man.openbsd.org/ehci.4">ehci(4)</a>.
  </li><li>Support for Aero and Sea SAS HBAs in
      <a href="https://man.openbsd.org/mpii.4">mpii(4)</a>.
  </li><li>Support for SAS3816 and SAS3916 in
      <a href="https://man.openbsd.org/mfii.4">mfii(4)</a>.
  </li><li>In <a href="https://man.openbsd.org/xbf.4">xbf(4)</a>, allowed Xen
	to use backing store devices with 4K-byte sectors.
  </li><li>Added <a href="https://man.openbsd.org/fanpwr.4">fanpwr(4)</a>
	support for the Rockchip RK8602 and RK8603 voltage regulators.
  </li><li>Support keyboard backlights on Apple Powerbooks.
  </li><li>Added operating performance point info about each arm64 cpu and
	expose the states of thermal zones as <a href="https://man.openbsd.org/kstat.1">kstats(1)</a>.
  </li><li>Overhauled <a href="https://man.openbsd.org/ugold.4">ugold(4)</a> temperature sensor
	identification logic and added support for additional devices.
  </li><li>Made <a href="https://man.openbsd.org/uthum.4">uthum(4)</a>
	TEMPer{1,2} devices display negative degC.
  </li><li>Improve support for audio devices that via attach multiple <a href="https://man.openbsd.org/uaudio.4">uaudio(4)</a> drivers.
  </li><li>In <a href="https://man.openbsd.org/nvme.4">nvme(4)</a> don't create
  <a href="https://man.openbsd.org/sd.4">sd(4)</a> devices larger than the namespace.
  </li><li>Fix <a href="https://man.openbsd.org/nvme.4">nvme(4)</a> decoding of status fields.
  </li></ul>

</li><li>New or improved network hardware support:
  <ul>
  <li>Utilize full checksum offload capabilities of
	<a href="https://man.openbsd.org/vio.4">vio(4)</a> and
	<a href="https://man.openbsd.org/vmx.4">vmx(4)</a>.
  </li><li>TCP Segmentation Offload (TSO) is also used in
	<a href="https://man.openbsd.org/bnxt.4">bnxt(4)</a> and
	<a href="https://man.openbsd.org/em.4">em(4)</a>.
  </li><li>Enabled TCP Segmentation Offload (TSO) in <a href="https://man.openbsd.org/ixl.4">ixl(4)</a>.
  </li><li>The Synopsys Ethernet Quality-of-Service Controller
	(<a href="https://man.openbsd.org/dwqe.4">dwqe(4)</a>) is enabled for
	amd64.
  </li><li>Added initial support for Elkhart Lake Ethernet to <a href="https://man.openbsd.org/dwqe.4">dwqe(4)</a>.
  </li><li>Support for AX88179A in
      <a href="https://man.openbsd.org/axen.4">axen(4)</a>.
  </li><li>Intel I225 and I226 Ethernet Controller
	<a href="https://man.openbsd.org/igc.4">igc(4)</a> enabled for
	sparc64.
  </li><li>Allwinner EMAC Ethernet Controller
	<a href="https://man.openbsd.org/dwxe.4">dwxe(4)</a> enabled for
	riscv64.
  </li><li>Corrected wrong register offset macros for <a href="https://man.openbsd.org/dwqe.4">dwqe(4)</a> DMA burst length.
  </li><li>Fixed Tx watchdog trigger and freeze in <a href="https://man.openbsd.org/dwqe.4">dwqe(4)</a>.
  </li><li>Updated <a href="https://man.openbsd.org/rge.4">rge(4)</a>
	microcode, initialization and reset behavior.
  </li><li>Prevented a potential <a href="https://man.openbsd.org/bnxt.4">bnxt(4)</a> crash after failure
	to bring up a queue.
  </li></ul>

</li><li>Added or improved wireless network drivers:
  <ul>
  <li>Introduce <a href="https://man.openbsd.org/qwx.4">qwx(4)</a>,
  a port of the Linux ath11k driver for QCNFA765 devices.
  Available on the amd64 and arm64 platforms.
  </li><li>Fix Tx rate selection for management frames in
  <a href="https://man.openbsd.org/iwx.4">iwx(4)</a>.
  </li><li>Fix <a href="https://man.openbsd.org/iwx.4">iwx(4)</a> loading the wrong
  firmware image on some devices.
  </li><li>Make <a href="https://man.openbsd.org/bfwm.4">bwfm(4)</a> work with MAC
  addresses set via ifconfig lladdr.
  </li><li>Ensure that <a href="https://man.openbsd.org/iwm.4">iwm(4)</a> uses the
  80MHz primary channel index announced in beacons.
  </li><li>Avoid using MCS-9 in <a href="https://man.openbsd.org/iwm.4">iwm(4)</a>
  Tx rate selection if 40 MHz is disabled to prevent firmware errors.
  </li><li>Ensure that <a href="https://man.openbsd.org/iwm.4">iwm(4)</a> and
  <a href="https://man.openbsd.org/iwx.4">iwx(4)</a> devices announce VHT
  capabilities in probe requests.
  </li><li>Fix bug in <a href="https://man.openbsd.org/iwm.4">iwm(4)</a>,
  <a href="https://man.openbsd.org/iwx.4">iwx(4)</a>, and
  <a href="https://man.openbsd.org/iwn.4">iwn(4)</a> which could result
  in some channels missing from scan results.
  </li><li>Enable <a href="https://man.openbsd.org/iwm.4">iwm(4)</a> on the
  arm64 platform.
  </li></ul>

</li><li>IEEE 802.11 wireless stack improvements and bugfixes:
  <ul>
  <li> Ignore 40/80 MHz wide channel configurations which do not appear
  in the 802.11ac spec. This prevents device firmware errors which
  occurred when an access point announced an invalid channel configuration.
  </li></ul>

</li><li>Installer, upgrade and bootloader improvements:
  <ul>
  <li>Add support for disk encryption in unattended installations with
	<a href="https://man.openbsd.org/autoinstall.8">autoinstall(8)</a>,
	both with a plaintext passphrase or a keydisk.
  </li><li>Removed default sets answer in <a href="https://man.openbsd.org/autoinstall.8">autoinstall(8)</a>
	response file such that it now populates only with non-defaults.
  </li><li>Made <a href="https://man.openbsd.org/fw_update.8">fw_update(8)</a> verify but
	not overwrite SHA256.sig.
  </li><li>Improved <a href="https://man.openbsd.org/fw_update.8">fw_update(8)</a> output on
	errors and improved ftp error handling.
  </li><li>Added support in the installer to encrypt the root disk with a key disk.
  </li><li>Prevent re-starting the automatic upgrade on octeon and
	powerpc64, as is already done on other platforms.
  </li><li>Added CD install images to arm64.
  </li><li>Make the amd64 cdXX.iso and installXX.iso CD images bootable in
	EFI mode (by creating an EFI system partition containing the EFI boot
	loaders to be installed as an El Torito boot image).
  </li></ul>

</li><li>Security improvements:
  <ul>
  <li>Introduce pinsyscalls(2): The kernel and <a href="https://man.openbsd.org/ld.so.1">ld.so(1)</a> register the
	precise entry location of every system call used by a program, as
	described in the new ELF section .openbsd.syscalls inside ld.so and
	libc.so. ld.so uses the new syscall <a href="https://man.openbsd.org/pinsyscalls.2">pinsyscalls(2)</a> to
	tell the kernel the precise entry location of system calls in
	libc.so.<br>
      Attempting to use a different system call entry instruction to
	perform a non-corresponding system call operation will fail and the
	process will be terminated with signal SIGABRT.
  </li><li>Removed support for <a href="https://man.openbsd.org/syscall.2">syscall(2)</a>, the
	"indirection system call," a dangerous alternative entry point for all
	system calls.<br>
      Together with <a href="https://man.openbsd.org/pinsyscalls.2">pinsyscalls(2)</a> this
	change makes it impossible to perform system call through any other
	way than the libc system call wrapper functions.<br>
      Users of syscall(2), such as Perl and the Go programming
	language were converted to use the libc functions.
  </li><li>Added <a href="https://man.openbsd.org/pledge.2">pledge(2)</a>
	stdio before parsing pfkey messages to <a href="https://man.openbsd.org/ipsecctl.8">ipsecctl(8)</a> -m and -s.
  </li><li>Tightened the <a href="https://man.openbsd.org/pledge.2">pledge(2)</a> in <a href="https://man.openbsd.org/pax.1">pax(1)</a> in List and Append
	modes.
  </li><li>Created __OpenBSD versions of llvm cxa guard implementation
	using <a href="https://man.openbsd.org/futex.2">futex(2)</a> with the
	correct number of arguments and without using <a href="https://man.openbsd.org/syscall.2">syscall(2)</a>.
  </li><li>Improvements in Pointer Authentication (PAC) and Branch Target
	Identification (BTI) on arm64.
  </li></ul>

</li><li>Changes in the network stack:
  <ul>
  <li>Enable IPv6 support in <a href="https://man.openbsd.org/ppp.4">ppp(4)</a>
  </li><li>Socket with sequenced packet type and control messages
	handle end of record correctly.
  </li><li>The routing table has a generation number.  That means
	cached routes at sockets will be invalidated when the routing
	table changes.  Especially with dynamic routing daemons
	local connections use the up to date route.
  </li><li>Route cache hits an misses are printed in
	<a href="https://man.openbsd.org/netstat.1">netstat(1)</a>
	statistics.  
  </li><li>Prevented <a href="https://man.openbsd.org/wg.4">wg(4)</a>
	getting stuck on peer destruction.
  </li><li>Made <a href="https://man.openbsd.org/umb.4">umb(4)</a> delete any
	existing v4 address before setting a new one, allowing keeping of a
	working default route when the address changes.
  </li><li>Forwarded TCP LRO disabling to parent devices and disabled TCP LR0
	on bridged <a href="https://man.openbsd.org/vlan.4">vlan(4)</a> and
	default for <a href="https://man.openbsd.org/bpe.4">bpe(4)</a>, <a href="https://man.openbsd.org/nvgre.4">nvgre(4)</a> and <a href="https://man.openbsd.org/vxlan.4">vxlan(4)</a>.
  </li><li>Fixed race between <a href="https://man.openbsd.org/ifconfig.8">ifconfig(8)</a> destroy of
	an interface and the ARP timer.
  </li><li>Added statistics counters for the route cache, reporting cache
	hits and misses. This is shown in <a href="https://man.openbsd.org/netstat.1">netstat(1)</a> with
	<code>netstat -s</code>.
  </li></ul>

</li><li>The following changes were made to the <a href="https://man.openbsd.org/pf.4">pf(4)</a> firewall:
  <ul>
  <li>tcpdump on <a href="https://man.openbsd.org/pflog.4">pflog(4)</a> interface shows
	packets dropped by the default rule with the "block" action.  Although
	the default rules is a "pass" rule, it blocks malformed packets.  Now
	this is correctly logged.
  </li><li>Adjustments to keep up firewall aware of MP related changes in
	the network stack.
  </li><li>Fix handling of multiple <code>-K</code>(<code>-k</code>) options in
	<a href="https://man.openbsd.org/pfctl.8">pfctl(8)</a>, so behavior
	matches what's described in manual.
  </li><li>Make <a href="https://man.openbsd.org/pfctl.8">pfctl(8)</a> show
	all tables in all anchors with <code>pfctl -a "*" -sT</code>.
  </li><li>Added check to ensure <a href="https://man.openbsd.org/pfctl.8">pfctl(8)</a> -f won't accept a
	directory and install an empty ruleset.
  </li><li>Added validation for IPv4 packet options in <a href="https://man.openbsd.org/divert.4">divert(4)</a>.
  </li></ul>

</li><li>Routing daemons and other userland network improvements:
<ul>
  <li>IPsec support was improved:
  <ul>
  <li>Made <a href="https://man.openbsd.org/iked.8">iked(8)</a> always
	prefer group from the initial KE payload as responder if supported.
  </li><li>Corrected renewal of expired certificates in <a href="https://man.openbsd.org/iked.8">iked(8)</a>.
  </li><li>Added an <a href="https://man.openbsd.org/iked.8">iked(8)</a>
	debug message when no policy is found.
  </li><li>Implemented a per connection peerid for <a href="https://man.openbsd.org/iked.8">iked(8)</a> control replies.
  </li><li>Made <a href="https://man.openbsd.org/iked.8">iked(8)</a>
	trigger retransmission only for fragment 1/x to prevent each received
	fragment triggering retransmission of the full fragment queue.
  </li><li>Prevent routing loops by dropping already encrypted packets that are going through <a href="https://man.openbsd.org/sec.4">sec(4)</a> again.
  </li></ul>

  </li><li>In <a href="https://man.openbsd.org/bgpd.8">bgpd(8)</a>,
  <ul>
    <li>Rewrite the internal message passing mechanism to use a new
	memory-safe API.
    </li><li>Rewrite most protocol parsers to use the new memory-safe API.
	Convert the UPDATE parser, all of RTR, as well as both the MRT dump
	code in bgpd and the parser in bgpctl.
    </li><li>Improve RTR logging, error handling and version negotiation.
  </li></ul>

  </li><li><a href="https://man.openbsd.org/rpki-client.8">rpki-client(8)</a> saw these and more changes:
  <ul>
	<li>Add ability to constrain an RPKI Trust Anchor's effective signing
	authority to a limited set of Internet numbers. This allows Relying
	Parties to enjoy the potential benefits of assuming trust, but within
	a bounded scope.
	</li><li>Following a 'failed fetch' (described in RFC 9286), emit a warning and
	continue with a previously cached Manifest file.
	</li><li>Emit a warning when the remote repository presents a Manifest with an
	unexpected manifestNumber.
	</li><li>Improved CRL extension checking.
	</li><li>Experimental support for the P-256 signature algorithm.
	<!-- 8.8. -->
	</li><li>A failed manifest fetch could result in a NULL pointer dereference or
	a use after free.
	</li><li>Reject non-conforming RRDP delta elements that contain neither publish
	nor a withdraw element and fall back to the RRDP snapshot.
	</li><li>Refactoring and minor bug fixes in the warning display functions.
	<!-- 8.9 -->
	</li><li>The handling of manifests fetched via rsync or RRDP was reworked to
	fully conform to RFC 9286.
	</li><li>Fix a race condition between closing an idle connection and scheduling a
	new request on it.
	</li><li>The evaluation time specified with -P now also applies to trust anchor
	certificates.
	</li><li>Check that the entire CMS eContent was consumed. Previously, trailing
	data would be silently discarded on deserialization of products.
	</li><li>In file mode do not consider overclaiming intermediate CA certificates
	as invalid.  OAA warning is still issued.
	</li><li>Print the revocation time of certificates in file mode.
	</li><li>Be more careful when converting OpenSSL numeric identifiers (NIDs)
	to strings.
	<!-- 9.0 -->
	</li><li>Added support for RPKI Signed Prefix Lists.
	</li><li>Added an -x flag to opt into parsing and evaluation of file types that are
	still considered experimental.
	</li><li>Added a metric to track the number of new files that were moved to the
	validated cache.
	</li><li>Ensure that the FileAndHashes list in a Manifest contains no duplicate
	file names and no duplicate hashes.
  </li></ul>

  </li><li>In <a href="https://man.openbsd.org/smtpd.8">smtpd(8)</a>,
  <ul>
	<li>Add <code>Message-Id</code> as needed for messages received on
	    the submission port.
	</li><li>Added support for RFC 7505 "Null MX" handling and treat
	    an MX of "localhost" as it were a "Null MX".
	</li><li>Allow inline tables and filter listings in
	    <a href="https://man.openbsd.org/smtpd.conf.5">smtpd.conf(5)</a>
	    to span over multiple lines.
	</li><li>Enabled <abbr title="Delivery Status Notification">DSN</abbr>
	    for the implicit socket too.
	</li><li>Added the
	    <a href="https://man.openbsd.org/smtpd.conf.5#no-dsn~2">no-dsn</a>
	    option for <code>listen on socket</code> too.
	</li><li>Reject headers that start with a space or a tab.
	</li><li>Fixed parsing of the <code>ORCPT</code> parameter.
	</li><li>Fixed table lookups of IPv6 addresses.
	</li><li>Fixed handling of escape characters in To, From and Cc headers.
	</li><li>Run <abbr title="Local Mail Transfer Protocol">LMTP</abbr>
	    deliveries as the recipient user again.
	</li><li>Disallow custom commands and file reading in root's
	    <code>.forward</code> file.
	</li><li>Do not process other users <code>.forward</code> files when
	    an alternate delivery user is provided in a dispatcher.
	</li><li>Unify the <a href="https://man.openbsd.org/table.5">table(5)</a>
	    parser used in
	    <a href="https://man.openbsd.org/smtpd.8">smtpd(8)</a> and
	    <a href="https://man.openbsd.org/makemap.8">makemap(8)</a>.
	</li><li>Allow to use <a href="https://man.openbsd.org/table.5">table(5)</a>
	    mappings on various match constraints.
  </li></ul>
<!-- OTHER -->
  </li><li>Many other changes in various network programs and libraries:
  <ul>
<!-- syslogd -->
        <li>If a DNS name is configured as remote syslog server,
	  <a href="https://man.openbsd.org/syslogd.8">syslogd(8)</a>
	  retries to resolve the loghost name periodically until it succeeds.
	  UDP packets that get lost during that period are counted and
	  logged later.
	</li><li>Added counting of dropped UDP packets to <a href="https://man.openbsd.org/syslogd.8">syslogd(8)</a>.
	</li><li>Prevented use after free of TLS context at <a href="https://man.openbsd.org/syslogd.8">syslogd(8)</a> shutdown.
<!-- dhcp -->
	</li><li>Introduced <a href="https://man.openbsd.org/dhcpd.8">dhcpd(8)</a>
	  log output to stderr and '-v' option to make this output more verbose.
	</li><li>In <a href="https://man.openbsd.org/dhcpd.8">dhcpd(8)</a>, made <a href="https://man.openbsd.org/dhcp-options.5">dhcp-options(5)</a>
	  recognize option ipv6-only-preferred (RFC8925).
	</li><li>Allowed <a href="https://man.openbsd.org/dhcpleased.8">dhcpleased(8)</a> to
	  request "IPv6-only preferred" and deconfigure IPv4 on the interface if
	  the server replies with this option.
<!-- more -->
	</li><li>Fixed <a href="https://man.openbsd.org/radiusd.8">radiusd(8)</a>
	  to properly fixup MPPE-{Send,Recv}-Key and Tunnel-Password attributes of the
	  response.
	</li><li>Added nochroot parameter to <a href="https://man.openbsd.org/radiusd.8">radiusd(8)</a>
	  module_drop_privilege() so that modules can use <a href="https://man.openbsd.org/unveil.2">unveil(2)</a> instead of <a href="https://man.openbsd.org/chroot.2">chroot(2)</a> if needed.
	</li><li>Ensured correct denominators when converting NTP fixed point
	  values to double and vice-versa in <a href="https://man.openbsd.org/ntpd.8">ntpd(8)</a>.
	</li><li>In the resolver, do not short-circuit resolution of localhost
	  when AI_NUMERICHOST is set. Ensure that a proper string is returned by <a href="https://man.openbsd.org/getaddrinfo.3">getaddrinfo(3)</a> when
	  AI_CANONNAME or AI_FQDN is set.
	</li><li>Added <a href="https://man.openbsd.org/ifconfig.8">ifconfig(8)</a>
	  support for specifying ports on the src address in tunnel endpoints of
	  <a href="https://man.openbsd.org/gif.4">gif(4)</a>, <a href="https://man.openbsd.org/gre.4">gre(4)</a> and related
	  tunnel interfaces.
	</li><li>Added an <a href="https://man.openbsd.org/ifconfig.8">ifconfig(8)</a> endpoint
	  command for "bridges" that use addresses as endpoints, usable to add
	  static entries on interfaces like <a href="https://man.openbsd.org/vxlan.4">vxlan(4)</a>.
	</li><li>Tightened up <a href="https://man.openbsd.org/relayd.8">relayd(8)</a> HTTP header parsing.
	</li><li>Deferred <a href="https://man.openbsd.org/relayd.8">relayd(8)</a>
	  relay_read_http header parsing until after line continuation,
	  preventing potential request smuggling attacks.
	</li><li>Improved <a href="https://man.openbsd.org/httpd.8">httpd(8)</a>
	  auto-index, adding human-readable file sizes and allowing per-column
	  sorting.
	</li><li>Switched to using whois.internic.net for <a href="https://man.openbsd.org/whois.1">whois(1)</a> -i.
  </li></ul>
</li></ul><!-- Routing daemons and other userland network improvements -->

</li><li><a href="https://man.openbsd.org/tmux.1">tmux(1)</a> improvements and bug fixes:
  <ul>
  <li>Made <a href="https://man.openbsd.org/tmux.1">tmux(1)</a> unzoom
	a window at the start of destroy so it doesn't happen later after the
	layout has been freed.
  </li><li>Prevented <a href="https://man.openbsd.org/tmux.1">tmux(1)</a> use
	of combined UTF-8 characters that are too long.
  </li><li>Corrected <a href="https://man.openbsd.org/tmux.1">tmux(1)</a>
	handling of window ops with no pane.
  </li><li>Removed flags from the prefix before comparing with the received
	key so that <a href="https://man.openbsd.org/tmux.1">tmux(1)</a>
	modifier keys with flags work correctly.
  </li><li>Increased buffer size to avoid truncating styles in <a href="https://man.openbsd.org/tmux.1">tmux(1)</a>.
  </li><li>Added two new values for the <a href="https://man.openbsd.org/tmux.1">tmux(1)</a> destroy-unattached
	option to destroy sessions only if they are not members of sessions
	groups.
  </li></ul>

</li><li>LibreSSL version 3.9.0
  <ul>
  <li>Portable changes
    <ul>
    <li>libcrypto no longer exports compat symbols in cmake builds.
    </li><li>Most compatibility symbols are prefixed with <code>libressl_</code>
      to avoid symbol clashes in static links.
    </li><li>Fixed various warnings on Windows.
    </li><li>Removed assert pop-ups with Windows debug builds.
    </li><li>Fixed crashes and hangs in Windows ARM64 builds.
    </li><li>Improved control-flow enforcement (CET) support.
    </li></ul>
  </li><li>Internal improvements
    <ul>
    <li>Converted uses of <code>OBJ_bsearch_()</code> to standard
      <a href="https://man.openbsd.org/bsearch">bsearch(3)</a>.
    </li><li>Greatly simplified <code>by_file_ctrl()</code>.
    </li><li>Simplified and cleaned up the OBJ_ API.
    </li><li>Cleaned up the <a href="https://man.openbsd.org/EVP_CipherInit">EVP_Cipher{Init,Update,Final}(3)</a> implementations.
    </li><li>Removed unused function pointers from X.509 stores and contexts.
    </li><li>A lot of cleanup and reorganization in EVP.
    </li><li>Removed all remaining <code>ENGINE</code> tentacles.
    </li><li>Simplified internals of <code>X509_TRUST</code> handling.
    </li><li>Made deletion from a <a href="https://man.openbsd.org/lh_delete">lhash</a>
      doall callback safe.
    </li><li>Rewrote <a href="https://man.openbsd.org/BIO_dump">BIO_dump*(3)</a> internals
      to be less bad.
    </li></ul>
  </li><li>Documentation improvements
    <ul>
    <li><code>ENGINE</code> documentation was updated to reflect reality.
    </li><li>Made EVP API documentation more accurate and less incoherent. 
    </li><li>Call out some shortcomings of the <code>EC_KEY_set_*</code> API explicitly.
    </li></ul>
  </li><li>Testing and proactive security
    <ul>
    <li>Bug fixes and simplifications in the Wycheproof tests.
    </li></ul>
  </li><li>Compatibility changes
    <ul>
    <li>Added ChaCha20 and chacha20 aliases for ChaCha.
    </li><li><a href="https://man.openbsd.org/SSL_library_init">SSL_library_init(3)</a>
      now has the same effect as OPENSSL_init_ssl().
    </li><li><code>EVP_add_{cipher,digest}()</code> were removed. From the <code>OBJ_NAME</code> API,
      only <a href="https://man.openbsd.org/OBJ_NAME_do_all">OBJ_NAME_do_all*()</a> remain.
      In particular, it is no longer possible to add aliases for ciphers and digests.
    </li><li>The thread unsafe global tables are no longer supported. It is no
      longer possible to add aliases for ciphers and digests, custom ASN.1
      strings table entries, ASN.1 methods, PKEY methods, digest methods,
      CRL methods, purpose and trust identifiers, or X.509 extensions.
    </li><li>Removed the _cb() and _fp() versions of
      <a href="https://man.openbsd.org/BIO_dump">BIO_dump{,_indent}()</a>.
    </li><li><code>BIO_set()</code> was removed.
    </li><li><code>BIO_{sn,v,vsn}printf()</code> were removed.
    </li><li>Turn the long dysfunctional
      <a href="https://man.openbsd.org/openssl(1)">openssl(1)</a>
      <code>s_client -pause</code> into a noop.
    </li><li><a href="https://man.openbsd.org/openssl(1)">openssl(1)</a> <code>x509</code>
     now supports <code>-new</code>, <code>-force_pubkey</code>, <code>-multivalue-rdn</code>,
      <code>-set_issuer</code> <code>-set_subject</code>, and <code>-utf8</code>.
    </li><li>Support ECDSA with SHA-3 signature algorithms.
    </li><li>Support HMAC with truncated SHA-2 and SHA-3 as PBE PRF.
    </li><li>GOST and STREEBOG support was removed.
    </li><li><code>CRYPTO_THREADID</code>, <code>_LHASH</code>, <code>_STACK</code> and
      <code>X509_PURPOSE</code> are now opaque, <code>X509_CERT_AUX</code> and
      <code>X509_TRUST</code> were removed from the public API.
    </li><li><a href="https://man.openbsd.org/ASN1_STRING_TABLE_get()">ASN1_STRING_TABLE_get(3)</a>
      and <a href="https://man.openbsd.org/X509_PURPOSE_get0">X509_PURPOSE_get0*(3)</a> now
      return const pointers.
    </li><li><code>EVP_{CIPHER,MD}_CTX_init()</code>'s signatures and semantics now match
      OpenSSL's behavior.
    </li><li><code>sk_find_ex()</code> and <code>OBJ_bsearch_()</code> were removed.
    </li><li><a href="https://man.openbsd.org/CRYPTO_malloc">CRYPTO_malloc(3)</a> was fixed to use
      <code>size_t</code> argument.  <code>CRYPTO_malloc()</code>
      and <code>CRYPTO_free()</code> now accept file and line arguments.
    </li><li>A lot of decrepit CRYPTO memory API was removed.
    </li></ul>
  </li><li>Bug fixes
    <ul>
    <li>Fixed aliasing issues in <code>BN_mod_exp_simple()</code> and <code>BN_mod_exp_recp()</code>.
    </li><li>Fixed numerous misuses of
      <a href="https://man.openbsd.org/X509_ALGOR_set0">X509_ALGOR_set0(3)</a>
      resulting in leaks and potentially incorrect encodings.
    </li><li>Fixed potential double free in
      <a href="https://man.openbsd.org/X509v3_asid_add_id_or_range">X509v3_asid_add_id_or_range(3)</a>.
    </li><li>Stopped using <code>ASN1_time_parse()</code> outside of libcrypto.
    </li><li>Prepared <a href="https://man.openbsd.org/OPENSSL_gmtime">OPENSSL_gmtime(3)</a> and
      <a href="https://man.openbsd.org/OPENSSL_timegm">OPENSSL_timegm(3)</a> as public API
      wrappers of internal functions compatible with BoringSSL API.
    </li><li>Removed <code>print_bin()</code> to avoid overwriting the stack with 5 bytes
      of <code>"&nbsp;"</code> when ECPK parameters are printed with large
      indentation.
    </li><li>Avoid a <code>NULL</code> dereference after memory allocation failure during TLS
      version downgrade.
    </li><li>Fixed various bugs in CMAC internals.
    </li><li>Fixed 4-byte overreads in GHASH assembly on amd64 and i386.
    </li><li>Fixed various NULL dereferences in PKCS #12 code due to mishandling
      of OPTIONAL content in PKCS #7 ContentInfo.
    </li><li>Aligned <a href="https://man.openbsd.org/SSL_shutdown">SSL_shutdown(3)</a>
      behavior in TLSv1.3 with the legacy stack.
    </li><li>Fixed the new X.509 verifier to find trust anchors in the trusted
      stack.
    </li></ul>
  </li></ul>

</li><li>OpenSSH 9.6 and OpenSSH 9.7
  <ul>
  <li>Security fixes
    <ul>
    <li><a href="https://man.openbsd.org/ssh.1">ssh(1)</a>, <a href="https://man.openbsd.org/sshd.8">sshd(8)</a>: implement protocol extensions to thwart the
       so-called "Terrapin attack" discovered by Fabian Bäumer, Marcus
       Brinkmann and Jörg Schwenk. This attack allows a MITM to effect a
       limited break of the integrity of the early encrypted SSH transport
       protocol by sending extra messages prior to the commencement of
       encryption, and deleting an equal number of consecutive messages
       immediately after encryption starts. A peer SSH client/server
       would not be able to detect that messages were deleted.
    
       <br>While cryptographically novel, the security impact of this attack
       is fortunately very limited as it only allows deletion of
       consecutive messages, and deleting most messages at this stage of
       the protocol prevents user authentication from proceeding and
       results in a stuck connection.
    
       <br>The most serious identified impact is that it lets a MITM to
       delete the SSH2_MSG_EXT_INFO message sent before authentication
       starts, allowing the attacker to disable a subset of the keystroke
       timing obfuscation features introduced in OpenSSH 9.5. There is no
       other discernable impact to session secrecy or session integrity.
    
    </li><li><a href="https://man.openbsd.org/ssh-agent.1">ssh-agent(1)</a>: when adding PKCS#11-hosted private keys while
       specifying destination constraints, if the PKCS#11 token returned
       multiple keys then only the first key had the constraints applied.
       Use of regular private keys, FIDO tokens and unconstrained keys
       are unaffected.

    </li><li><a href="https://man.openbsd.org/ssh.1">ssh(1)</a>: if an invalid user or hostname that contained shell
       metacharacters was passed to <a href="https://man.openbsd.org/ssh.1">ssh(1)</a>, and a ProxyCommand,
       LocalCommand directive or "match exec" predicate referenced the
       user or hostname via %u, %h or similar expansion token, then
       an attacker who could supply arbitrary user/hostnames to <a href="https://man.openbsd.org/ssh.1">ssh(1)</a>
       could potentially perform command injection depending on what
       quoting was present in the user-supplied <a href="https://man.openbsd.org/ssh_config.5">ssh_config(5)</a> directive.
    
       <br>OpenSSH 9.6 now
       bans most shell metacharacters from user and hostnames supplied
       via the command-line. This countermeasure is not guaranteed to be
       effective in all situations, as it is infeasible for <a href="https://man.openbsd.org/ssh.1">ssh(1)</a> to
       universally filter shell metacharacters potentially relevant to
       user-supplied commands.
    
       <br>User/hostnames provided via <a href="https://man.openbsd.org/ssh_config.5">ssh_config(5)</a> are not subject to these
       restrictions, allowing configurations that use strange names to
       continue to be used, under the assumption that the user knows what
       they are doing in their own configuration files.
    </li></ul>
  </li><li>New features
    <ul>
    <li><a href="https://man.openbsd.org/ssh.1">ssh(1)</a>, <a href="https://man.openbsd.org/sshd.8">sshd(8)</a>: add a "global" ChannelTimeout type that watches
       all open channels and will close all open channels if there is no
       traffic on any of them for the specified interval. This is in
       addition to the existing per-channel timeouts added recently.
    <br>This supports situations like having both session and x11
       forwarding channels open where one may be idle for an extended
       period but the other is actively used. The global timeout could
       close both channels when both have been idle for too long.
    
    </li><li>All: make DSA key support compile-time optional, defaulting to on.
    </li></ul>
  </li><li>Bugfixes
    <ul>
    <li><a href="https://man.openbsd.org/sshd.8">sshd(8)</a>: don't append an unnecessary space to the end of subsystem
       arguments (<a href="https://bugzilla.mindrot.org/show_bug.cgi?id=3667">bz3667</a>)
    
    </li><li><a href="https://man.openbsd.org/ssh.1">ssh(1)</a>: fix the multiplexing "channel proxy" mode, broken when
       keystroke timing obfuscation was added. (<a href="https://github.com/openssh/openssh-portable/pull/463">GHPR#463</a>)
    
    </li><li><a href="https://man.openbsd.org/ssh.1">ssh(1)</a>, <a href="https://man.openbsd.org/sshd.8">sshd(8)</a>: fix spurious configuration parsing errors when
       options that accept array arguments are overridden (<a href="https://bugzilla.mindrot.org/show_bug.cgi?id=3657">bz3657</a>).
    
    </li><li><a href="https://man.openbsd.org/ssh-agent.1">ssh-agent(1)</a>: fix potential spin in signal handler (<a href="https://bugzilla.mindrot.org/show_bug.cgi?id=3670">bz3670</a>)
    
    </li><li>Many fixes to manual pages and other documentation, including
       <a href="https://github.com/openssh/openssh-portable/pull/462">GHPR#462</a>, <a href="https://github.com/openssh/openssh-portable/pull/454">GHPR#454</a>, <a href="https://github.com/openssh/openssh-portable/pull/442">GHPR#442</a> and <a href="https://github.com/openssh/openssh-portable/pull/441">GHPR#441</a>.
    
    </li><li>Greatly improve interop testing against PuTTY.
    </li></ul>
  </li></ul>

</li><li>Ports and packages:
  <p>Many pre-built packages for each architecture:
  <!-- number of FTP packages minus SHA256, SHA256.sig, index.txt -->
  </p><ul>
    <li>aarch64:    12145
    </li><li>amd64:      12309
    </li><li>arm:        XXX
    </li><li>i386:       10830
    </li><li>mips64:     8674
    </li><li>powerpc:    XXX
    </li><li>powerpc64:  8469
    </li><li>riscv64:    10508
    </li><li>sparc64:    9432
  </li></ul>

  <p>Some highlights:
  </p><ul><!-- XXX all need to be checked/updated 2024-03-02 -->
    <li>Asterisk 16.30.1, 18.21.0 and 20.6.0
    </li><li>Audacity 3.4.2
    </li><li>CMake 3.28.3
    </li><li>Chromium 122.0.6261.111
    </li><li>Emacs 29.2
    </li><li>FFmpeg 4.4.4
    </li><li>GCC 8.4.0 and 11.2.0
    </li><li>GHC 9.6.4
    </li><li>GNOME 45
    </li><li>Go 1.22.1
    </li><li>JDK 8u402, 11.0.22, 17.0.10 and 21.0.2
    </li><li>KDE Applications 23.08.4
    </li><li>KDE Frameworks 5.115.0
    </li><li>KDE Plasma 5.27.10
    </li><li>Krita 5.2.2
    </li><li>LLVM/Clang 13.0.0, 16.0.6 and 17.0.6
    </li><li>LibreOffice 24.2.1.2
    </li><li>Lua 5.1.5, 5.2.4, 5.3.6 and 5.4.6
    </li><li>MariaDB 10.9.8
    </li><li>Mono 6.12.0.199
    </li><li>Mozilla Firefox 123.0.1 and ESR 115.8.0
    </li><li>Mozilla Thunderbird 115.8.1
    </li><li>Mutt 2.2.13 and NeoMutt 20240201
    </li><li>Node.js 18.19.1
    </li><li>OCaml 4.14.1
    </li><li>OpenLDAP 2.6.7
    </li><li>PHP 7.4.33, 8.0.30, 8.1.27, 8.2.16 and 8.3.3
    </li><li>Postfix 3.8.6
    </li><li>PostgreSQL 16.2
    </li><li>Python 2.7.18, 3.9.18, 3.10.13 and 3.11.8
    </li><li>Qt 5.15.12 (+ kde patches) and 6.6.1
    </li><li>R 4.2.3
    </li><li>Ruby 3.1.4, 3.2.3 and 3.3.0
    </li><li>Rust 1.76.0
    </li><li>SQLite 3.44.2
    </li><li>Shotcut 23.07.29
    </li><li>Sudo 1.9.15.5
    </li><li>Suricata 7.0.3
    </li><li>Tcl/Tk 8.5.19 and 8.6.13
    </li><li>TeX Live 2023
    </li><li>Vim 9.1.139 and Neovim 0.9.5
    </li><li>Xfce 4.18.1
  </li></ul>
  </li><li>As usual, steady improvements in manual pages and other documentation.

</li><li>The system includes the following major components from outside suppliers:
  <ul><!-- XXX all need to be checked/updated 2024-03-02 -->
    <li>Xenocara (based on X.Org 7.7 with xserver 21.1.11 + patches,
        freetype 2.13.0, fontconfig 2.14.2, Mesa 23.1.9, xterm 378,
        xkeyboard-config 2.20, fonttosfnt 1.2.3 and more)
    </li><li>LLVM/Clang 16.0.6 (+ patches)
    </li><li>GCC 4.2.1 (+ patches) and 3.3.6 (+ patches)
    </li><li>Perl 5.36.3 (+ patches)
    </li><li>NSD 4.8.0
    </li><li>Unbound 1.18.0
    </li><li>Ncurses 5.7
    </li><li>Binutils 2.17 (+ patches)
    </li><li>Gdb 6.3 (+ patches)
    </li><li>Awk January 22, 2024
    </li><li>Expat 2.6.0
    </li><li>zlib 1.3.1 (+ patches)
  </li></ul>

</li></ul>
</section>

<hr>

<section id="install">
<h3>How to install</h3>
<p>
Please refer to the following files on the mirror site for
extensive details on how to install OpenBSD 7.5 on your machine:

</p><ul>
<li><a href="https://ftp.openbsd.org/pub/OpenBSD/7.5/alpha/INSTALL.alpha">
	.../OpenBSD/7.5/alpha/INSTALL.alpha</a>
</li><li><a href="https://ftp.openbsd.org/pub/OpenBSD/7.5/amd64/INSTALL.amd64">
	.../OpenBSD/7.5/amd64/INSTALL.amd64</a>
</li><li><a href="https://ftp.openbsd.org/pub/OpenBSD/7.5/arm64/INSTALL.arm64">
	.../OpenBSD/7.5/arm64/INSTALL.arm64</a>
</li><li><a href="https://ftp.openbsd.org/pub/OpenBSD/7.5/armv7/INSTALL.armv7">
	.../OpenBSD/7.5/armv7/INSTALL.armv7</a>
</li><li><a href="https://ftp.openbsd.org/pub/OpenBSD/7.5/hppa/INSTALL.hppa">
	.../OpenBSD/7.5/hppa/INSTALL.hppa</a>
</li><li><a href="https://ftp.openbsd.org/pub/OpenBSD/7.5/i386/INSTALL.i386">
	.../OpenBSD/7.5/i386/INSTALL.i386</a>
</li><li><a href="https://ftp.openbsd.org/pub/OpenBSD/7.5/landisk/INSTALL.landisk">
	.../OpenBSD/7.5/landisk/INSTALL.landisk</a>
</li><li><a href="https://ftp.openbsd.org/pub/OpenBSD/7.5/loongson/INSTALL.loongson">
	.../OpenBSD/7.5/loongson/INSTALL.loongson</a>
</li><li><a href="https://ftp.openbsd.org/pub/OpenBSD/7.5/luna88k/INSTALL.luna88k">
	.../OpenBSD/7.5/luna88k/INSTALL.luna88k</a>
</li><li><a href="https://ftp.openbsd.org/pub/OpenBSD/7.5/macppc/INSTALL.macppc">
	.../OpenBSD/7.5/macppc/INSTALL.macppc</a>
</li><li><a href="https://ftp.openbsd.org/pub/OpenBSD/7.5/octeon/INSTALL.octeon">
	.../OpenBSD/7.5/octeon/INSTALL.octeon</a>
</li><li><a href="https://ftp.openbsd.org/pub/OpenBSD/7.5/powerpc64/INSTALL.powerpc64">
	.../OpenBSD/7.5/powerpc64/INSTALL.powerpc64</a>
</li><li><a href="https://ftp.openbsd.org/pub/OpenBSD/7.5/riscv64/INSTALL.riscv64">
	.../OpenBSD/7.5/riscv64/INSTALL.riscv64</a>
</li><li><a href="https://ftp.openbsd.org/pub/OpenBSD/7.5/sparc64/INSTALL.sparc64">
	.../OpenBSD/7.5/sparc64/INSTALL.sparc64</a>
</li></ul>
</section>

<hr>

<section id="quickinstall">
<p>
Quick installer information for people familiar with OpenBSD, and the use of
the "<a href="https://man.openbsd.org/disklabel.8">disklabel</a> -E" command.
If you are at all confused when installing OpenBSD, read the relevant
INSTALL.* file as listed above!

</p><h3>OpenBSD/alpha:</h3>

<p>
If your machine can boot from CD, you can write <i>install75.iso</i> or
<i>cd75.iso</i> to a CD and boot from it.
Refer to INSTALL.alpha for more details.

</p><h3>OpenBSD/amd64:</h3>

<p>
If your machine can boot from CD, you can write <i>install75.iso</i> or
<i>cd75.iso</i> to a CD and boot from it.
You may need to adjust your BIOS options first.

</p><p>
If your machine can boot from USB, you can write <i>install75.img</i> or
<i>miniroot75.img</i> to a USB stick and boot from it.

</p><p>
If you can't boot from a CD, floppy disk, or USB,
you can install across the network using PXE as described in the included
INSTALL.amd64 document.

</p><p>
If you are planning to dual boot OpenBSD with another OS, you will need to
read INSTALL.amd64.

</p><h3>OpenBSD/arm64:</h3>

<p>
If your machine can boot from CD, you can write <i>install75.iso</i> or
<i>cd75.iso</i> to a CD and boot from it.

</p><p>
To boot from disk, write <i>install75.img</i> or <i>miniroot75.img</i> to a
disk and boot from it after connecting to the serial console.  Refer to
INSTALL.arm64 for more details.

</p><h3>OpenBSD/armv7:</h3>

<p>
Write a system specific miniroot to an SD card and boot from it after connecting
to the serial console.  Refer to INSTALL.armv7 for more details.

</p><h3>OpenBSD/hppa:</h3>

<p>
Boot over the network by following the instructions in INSTALL.hppa or the
<a href="https://www.openbsd.org/hppa.html#install">hppa platform page</a>.

</p><h3>OpenBSD/i386:</h3>

<p>
If your machine can boot from CD, you can write <i>install75.iso</i> or
<i>cd75.iso</i> to a CD and boot from it.
You may need to adjust your BIOS options first.

</p><p>
If your machine can boot from USB, you can write <i>install75.img</i> or
<i>miniroot75.img</i> to a USB stick and boot from it.

</p><p>
If you can't boot from a CD, floppy disk, or USB,
you can install across the network using PXE as described in
the included INSTALL.i386 document.

</p><p>
If you are planning on dual booting OpenBSD with another OS, you will need to
read INSTALL.i386.

</p><h3>OpenBSD/landisk:</h3>

<p>
Write <i>miniroot75.img</i> to the start of the CF
or disk, and boot normally.

</p><h3>OpenBSD/loongson:</h3>

<p>
Write <i>miniroot75.img</i> to a USB stick and boot bsd.rd from it
or boot bsd.rd via tftp.
Refer to the instructions in INSTALL.loongson for more details.

</p><h3>OpenBSD/luna88k:</h3>

<p>
Copy 'boot' and 'bsd.rd' to a Mach or UniOS partition, and boot the bootloader
from the PROM, and then bsd.rd from the bootloader.
Refer to the instructions in INSTALL.luna88k for more details.

</p><h3>OpenBSD/macppc:</h3>

<p>
Burn the image from a mirror site to a CDROM, and power on your machine
while holding down the <i>C</i> key until the display turns on and
shows <i>OpenBSD/macppc boot</i>.

</p><p>
Alternatively, at the Open Firmware prompt, enter <i>boot cd:,ofwboot
/7.5/macppc/bsd.rd</i>

</p><h3>OpenBSD/octeon:</h3>

<p>
After connecting a serial port, boot bsd.rd over the network via DHCP/tftp.
Refer to the instructions in INSTALL.octeon for more details.

</p><h3>OpenBSD/powerpc64:</h3>

<p>
To install, write <i>install75.img</i> or <i>miniroot75.img</i> to a
USB stick, plug it into the machine and choose the <i>OpenBSD
install</i> menu item in Petitboot.
Refer to the instructions in INSTALL.powerpc64 for more details.

</p><h3>OpenBSD/riscv64:</h3>

<p>
To install, write <i>install75.img</i> or <i>miniroot75.img</i> to a
USB stick, and boot with that drive plugged in.
Make sure you also have the microSD card plugged in that shipped with the
HiFive Unmatched board.
Refer to the instructions in INSTALL.riscv64 for more details.

</p><h3>OpenBSD/sparc64:</h3>

<p>
Burn the image from a mirror site to a CDROM, boot from it, and type
<i>boot cdrom</i>.

</p><p>
If this doesn't work, or if you don't have a CDROM drive, you can write
<i>floppy75.img</i> or <i>floppyB75.img</i>
(depending on your machine) to a floppy and boot it with <i>boot
floppy</i>. Refer to INSTALL.sparc64 for details.

</p><p>
Make sure you use a properly formatted floppy with NO BAD BLOCKS or your install
will most likely fail.

</p><p>
You can also write <i>miniroot75.img</i> to the swap partition on
the disk and boot with <i>boot disk:b</i>.

</p><p>
If nothing works, you can boot over the network as described in INSTALL.sparc64.
</p></section>

<hr>

<section id="upgrade">
<h3>How to upgrade</h3>
<p>
If you already have an OpenBSD 7.4 system, and do not want to reinstall,
upgrade instructions and advice can be found in the
<a href="https://www.openbsd.org/faq/upgrade75.html">Upgrade Guide</a>.
</p></section>

<hr>

<section id="sourcecode">
<h3>Notes about the source code</h3>
<p>
<code>src.tar.gz</code> contains a source archive starting at <code>/usr/src</code>.
This file contains everything you need except for the kernel sources,
which are in a separate archive.
To extract:
</p><blockquote><pre># <kbd>mkdir -p /usr/src</kbd>
# <kbd>cd /usr/src</kbd>
# <kbd>tar xvfz /tmp/src.tar.gz</kbd>
</pre></blockquote>
<p>
<code>sys.tar.gz</code> contains a source archive starting at <code>/usr/src/sys</code>.
This file contains all the kernel sources you need to rebuild kernels.
To extract:
</p><blockquote><pre># <kbd>mkdir -p /usr/src/sys</kbd>
# <kbd>cd /usr/src</kbd>
# <kbd>tar xvfz /tmp/sys.tar.gz</kbd>
</pre></blockquote>
<p>
Both of these trees are a regular CVS checkout.  Using these trees it
is possible to get a head-start on using the anoncvs servers as
described <a href="https://www.openbsd.org/anoncvs.html">here</a>.
Using these files
results in a much faster initial CVS update than you could expect from
a fresh checkout of the full OpenBSD source tree.
</p></section>

<hr>

<section id="ports">
<h3>Ports Tree</h3>
<p>
A ports tree archive is also provided.  To extract:
</p><blockquote><pre># <kbd>cd /usr</kbd>
# <kbd>tar xvfz /tmp/ports.tar.gz</kbd>
</pre></blockquote>
<p>
Go read the <a href="https://www.openbsd.org/faq/ports/index.html">ports</a> page
if you know nothing about ports
at this point.  This text is not a manual of how to use ports.
Rather, it is a set of notes meant to kickstart the user on the
OpenBSD ports system.
</p><p>
The <i>ports/</i> directory represents a CVS checkout of our ports.
As with our complete source tree, our ports tree is available via
<a href="https://www.openbsd.org/anoncvs.html">AnonCVS</a>.
So, in order to keep up to date with the -stable branch, you must make
the <i>ports/</i> tree available on a read-write medium and update the tree
with a command like:
</p><blockquote><pre># <kbd>cd /usr/ports</kbd>
# <kbd>cvs -d anoncvs@server.openbsd.org:/cvs update -Pd -rOPENBSD_7_5</kbd>
</pre></blockquote>
<p>
[Of course, you must replace the server name here with a nearby anoncvs
server.]
</p><p>
Note that most ports are available as packages on our mirrors. Updated
ports for the 7.5 release will be made available if problems arise.
</p><p>
If you're interested in seeing a port added, would like to help out, or just
would like to know more, the mailing list
<a href="https://www.openbsd.org/mail.html">ports@openbsd.org</a> is a good place to know.
</p></section>


</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Former University of Iowa hospital employee used fake identity for 35 years (312 pts)]]></title>
            <link>https://www.thegazette.com/crime-courts/former-university-of-iowa-hospital-employee-used-fake-identity-for-35-years/</link>
            <guid>39938005</guid>
            <pubDate>Fri, 05 Apr 2024 02:07:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.thegazette.com/crime-courts/former-university-of-iowa-hospital-employee-used-fake-identity-for-35-years/">https://www.thegazette.com/crime-courts/former-university-of-iowa-hospital-employee-used-fake-identity-for-35-years/</a>, See on <a href="https://news.ycombinator.com/item?id=39938005">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="article-wrapper" tabindex="-1">

            

            
            <article id="gazette_article" data-article-title="Former University of Iowa Hospital employee used fake identity for 35 years">

                <!-- .entry-header -->

                <div>

                    
<!-- NEW PARSER -->
               <figure data-width="300" data-height="354">
                <a href="https://imengine.public.prod.cdr.navigacloud.com/?uuid=8375d0cf-dc51-5af5-84a5-17a88fc21a9d&amp;type=preview&amp;q=60&amp;function=fit&amp;maxsize=1200" target="_blank">
            <img itemprop="contentUrl" data-uuid="8375d0cf-dc51-5af5-84a5-17a88fc21a9d" srcset="
                    https://imengine.public.prod.cdr.navigacloud.com/?uuid=8375d0cf-dc51-5af5-84a5-17a88fc21a9d&amp;function=cover&amp;type=preview&amp;source=false&amp;q=75&amp;width=300&amp;height=157 300w,
                    https://imengine.public.prod.cdr.navigacloud.com/?uuid=8375d0cf-dc51-5af5-84a5-17a88fc21a9d&amp;function=cover&amp;type=preview&amp;source=false&amp;q=75&amp;width=600&amp;height=314 600w,
                    https://imengine.public.prod.cdr.navigacloud.com/?uuid=8375d0cf-dc51-5af5-84a5-17a88fc21a9d&amp;function=cover&amp;type=preview&amp;source=false&amp;q=75&amp;width=900&amp;height=471 900w,
                    https://imengine.public.prod.cdr.navigacloud.com/?uuid=8375d0cf-dc51-5af5-84a5-17a88fc21a9d&amp;function=cover&amp;type=preview&amp;source=false&amp;q=75&amp;width=1200&amp;height=629 1200w,
                    https://imengine.public.prod.cdr.navigacloud.com/?uuid=8375d0cf-dc51-5af5-84a5-17a88fc21a9d&amp;function=cover&amp;type=preview&amp;source=false&amp;q=75&amp;width=1500&amp;height=786 1500w" src="https://imengine.public.prod.cdr.navigacloud.com/?uuid=8375d0cf-dc51-5af5-84a5-17a88fc21a9d&amp;function=cover&amp;type=preview&amp;source=false&amp;width=1200&amp;height=629" alt="Matthew David Keirans">
        </a>
                    <figcaption data-uuid="8375d0cf-dc51-5af5-84a5-17a88fc21a9d">
                Matthew David Keirans
                            </figcaption>
        </figure>
            <p>A former University of Iowa Hospital employee pleaded guilty Monday to federal charges that he had been living under another man’s identity since 1988, causing the other man to be falsely imprisoned for identity theft and sent to a mental hospital.</p>
                <p>Matthew David Keirans, 58, was convicted of one count of false statement to a National Credit Union Administration insured institution — punishable by up to 30 years in federal prison — and one count of aggravated identity theft — punishable by up to two years in federal prison.</p>
                <p>Keirans worked as a systems architect in the hospital’s IT department from June 28, 2013 to July 20, 2023, when he was terminated for misconduct related to the identity theft investigation.</p>
                
<p>Although a news release from the U.S. Attorney's Office for the Northern District of Iowa states Keirans was an administrator at the hospital, a hospital representative said he was not a senior leader in the organization.</p>
                <p>Keirans worked at the hospital under the name William Donald Woods, an alias he had been using since about 1988, when he worked with the real William Woods at a hot dog cart in Albuquerque, N.M.</p>
                <h2>Use of Woods’ identity</h2>
                <p>Keirans used Woods’ identity “in every aspect of his life,” including obtaining employment, insurance and official documents, and even paying taxes under the name, according to a plea agreement signed by Keirans.</p>
                <p>In 1990, Keirans obtained a fraudulent Colorado identification card with Woods’ name and birthday. He used the ID to get a job at a fast-food restaurant and to get a Colorado bank account. He bought a car for $600 in 1991, using Wood’s name, with two $300 checks that bounced.</p>
                <!--<div class='opscoad-ad-leaderboard-article'></div>-->

<p>He drove the stolen car to Idaho, where it broke down and he abandoned it. He withdrew all his money from the Colorado bank using an ATM in Idaho and left the state. An arrest warrant was issued for Woods in Colorado because of the stolen car, though documents don’t indicate whether Woods was arrested at that time.</p>
                <p>It wasn’t the first time Keirans had stolen a car. When he was 16, he stole a car after running away from his adoptive parents’ home in San Francisco. He was arrested at the time in Oregon, under his own name, but never appeared in court, according to court documents.</p>
                <p>In 1994 — six years after he started using Woods’ name — Keirans got married. He had a child, whose last name is Woods.</p>
                <p>In 2012 — 24 years after he started using Woods’ name — Keirans fraudulently acquired a copy of Woods’ birth certificate from the state of Kentucky using information he found about Woods’ family on Ancestry.com.</p>
                <p>By 2013, Keirans had moved to eastern Wisconsin. He started his IT job with UI Hospitals and worked remotely. He earned more than $700,000 in his 10 years working for the hospital. In 2023, his salary was $140,501, according to the hospital.</p>
                <p>Keirans obtained multiple vehicle and personal loans from Iowa credit unions under Woods’ name between 2016 and 2022, totaling more than $200,000. He also had money stored in a national bank under Woods’ name, court documents state.</p>
                <h2>Woods’ arrest</h2>
                <p>In 2019, the real William Woods was homeless, living in Los Angeles. He went to a branch of the national bank and explained that he recently discovered someone was using his credit and had accumulated a lot of debt.</p>
                <p>Woods didn’t want to pay the debt and asked to know the account numbers for any accounts he had open at the bank so he could close them.</p>
                <p>Woods gave the bank employee his real Social Security card and an authentic California Identification card, which matched the information the bank had on file. Because there was a large amount of money in the accounts, the bank employee asked Woods a series of security questions that he was unable to answer.</p>
                <p>The bank employee called Keirans, whose the phone number was connected to the accounts. He answered the security questions correctly and said no one in California should have access to the accounts.</p>
                <p>The employee called the Los Angeles Police Department, and officers spoke with Woods and Keirans. Keirans faxed the Los Angeles officers a copy of Woods’ Social Security card and birth certificate, as well as a Wisconsin driver’s license Keirans had acquired under Woods’ name.</p>
                <p>The driver’s license had the name William David Woods — David is Keirans’ real middle name — rather than William Donald Woods. When questioned, Keiran told an LAPD officer he sometimes used David as a middle name, but his real name was William Donald Woods.</p>
                <p>The real Woods was arrested and charged with identity theft and false impersonation, under a misspelling of Keirans’ name: Matthew Kierans.</p>
                <p>Because Woods continued to insist, throughout the judicial process, that he was William Woods and not Matthew Kierans, a judge ruled in February 2020 that he was not mentally competent to stand trial and he was sent to a mental hospital in California, where he received psychotropic medication and other mental health treatment.</p>
                <p>In March 2021, Woods pleaded no contest to the identity theft charges — meaning he accepted the conviction but did not admit guilt. He was sentenced to two years imprisonment with credit for the two years he already served in the county jail and the hospital and was released. He was also ordered to pay $400 in fines and to stop using the name William Woods.</p>
                <p>He did not stop. Woods continued to attempt to regain his identity by filing customer disputes with financial organizations in an attempt to clear his credit report. He also reached out to multiple law enforcement agencies, including the Hartland Police Department in Wisconsin, where Keirans lived.</p>
                <h2>UI investigation</h2>
                <p>Woods eventually discovered where Keirans was working, and in January 2023 he reached out to the University of Iowa Hospitals’ security department, who referred his complaint to the University of Iowa Police Department.</p>
                <p>University of Iowa Police Detective Ian Mallory opened an investigation into the case. Mallory found the biological father listed on Woods’ birth certificate — which both Woods and Keirans had sent him an official copy of — and tested the father’s DNA against Woods’ DNA. The test proved Woods was the man’s son.</p>
                <p>On July 17, 2023, Mallory interviewed Keirans. He asked Keirans what his father’s name was, and Keirans accidentally gave the name of his own adoptive father. Mallory then confronted Keirans with the DNA evidence, and Keirans responded by saying, “my life is over” and “everything is gone.” He then confessed to the prolonged identity theft, according to court documents.</p>
                <h2>Charges</h2>
                <p>Keirans was taken into custody July 18, 2023, and charged in Johnson County with false use of birth certificate and providing false identification information.</p>
                <p>He pleaded guilty Aug. 14 to false use of birth certificate and the other charge was dropped. He was sentenced to 20 days in Johnson County Jail, with credit for time served.</p>
                <p>On Aug. 29, a complaint was filed in federal court against Keirans. He was indicted Dec. 12, on five counts of false statement to a National Credit Union Administration insured institution and two counts of aggravated identity theft. He pleaded guilty Monday to one count of each charge, and the other counts were dropped.</p>
                <p>A sentencing has not yet been scheduled. Keirans is currently in the custody of the U.S. Marshals Service, according to a news release about his plea.</p>
                <p><em id="emphasis-c8d675f04e9b24fbf74d047ec42e3dbd">Comments: (319) 398-8328; emily.andersen@thegazette.com</em></p>
    
                </div>

                <!-- .entry-footer -->

            </article>


                            
            
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Big Tech Is Trying to Prevent Debate About Its Social Harms (180 pts)]]></title>
            <link>https://foreignpolicy.com/2024/04/04/big-tech-digital-trade-regulation/</link>
            <guid>39937427</guid>
            <pubDate>Fri, 05 Apr 2024 00:21:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://foreignpolicy.com/2024/04/04/big-tech-digital-trade-regulation/">https://foreignpolicy.com/2024/04/04/big-tech-digital-trade-regulation/</a>, See on <a href="https://news.ycombinator.com/item?id=39937427">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>Platforms like Google, Facebook, and Amazon are not only shaping our economy, but our society—with questions of privacy, monopoly power, online racial discrimination, misinformation, hate speech, incitement, and impacts on mental health at the fore of the policy debate.</p><div>
						<p>Platforms like Google, Facebook, and Amazon are not only shaping our economy, but our society—with questions of privacy, monopoly power, online racial discrimination, misinformation, hate speech, incitement, and impacts on mental health at the fore of the policy debate.</p>
<p>In a democratic society, designing policies to mitigate the harms—while preserving the benefits that these platforms bring, and keeping true to a range of principles and ideals to which most Americans subscribe—is hard. It often entails balancing one individual’s rights against another’s.</p>
<p>But an issue that unites Americans across political and geographic divides is that these corporations, collectively known as “Big Tech,” have too much power over nearly every facet of our lives. Even those, like X, that have lost the confidence of advertisers have the power to push whatever agenda they want. Big Tech monopolists are squeezing consumers, workers, and smaller businesses, and, with social media’s business model of engagement through enragement, contributing to the polarization of our society.</p>
<p>A robust debate is underway over the new rules needed for the digital era to deal with the host of digital harms with which our society has become concerned. But special-interest lobbyists have been trying to make an end run around the democratic process, seeking to tie our hands through binding trade agreements before we figure out what’s right. Big Tech lobbyists are exploiting the secrecy surrounding ongoing negotiations at the World Trade Organization (WTO) and <a href="https://www.afronomicslaw.org/category/analysis/afcftas-digital-trade-rules-are-not-fit-africa">elsewhere</a> in an attempt to quietly <a href="https://rethinktrade.org/reports/international-preemption-by-trade-agreement/">rig</a> international rules. These so-called digital trade rules would impose binding constraints on efforts by Congress, the Biden administration, and their counterparts around the world to regulate the digital sphere. The United States and other WTO signatory countries would be subject to trade sanctions unless and until they eliminate domestic policies that WTO enforcement tribunals deem to violate such constraints.</p>
<p>Big Tech’s trade-pact <a href="https://www.nytimes.com/2023/11/27/opinion/google-facebook-ai-trade.html">ploy</a> is to create a global digital architecture where America’s digital giants can continue to dominate abroad and are unfettered at home and elsewhere. These tech giants are motivated not by patriotism but by money. In pushing for particular rules in international trade agreements, the lobbyists are trying to foreclose debate, arguing that any government intervention, including those actions designed to promote competition and prevent digital harms, is an unfair and inefficient restraint on trade. The result of this backdoor strategy, were it successful, would be to <a href="https://rethinktrade.org/reports/international-preemption-by-trade-agreement/">constrain</a> the U.S. government—and its partners—from adopting and enforcing privacy, data security, competition, and other policies in the public interest.</p>
<hr>
<p><span>This is not the first time</span> that trade negotiations have been used to enshrine corporate profits at the expense of the public interest. For decades, Big Pharma has successfully fought for trade-pact rules to expand patent protections, <a href="https://www.nytimes.com/2005/07/02/business/worldbusiness/drug-lobby-got-a-victory-in-trade-pact-vote.html">limiting</a> affordable access to lifesaving medicines. We saw the consequences in the HIV/AIDS and COVID-19 pandemics, with many dying needlessly as a few countries refused to grant the intellectual property waiver that would have allowed increased production and lower, more affordable prices of generics.</p>
<p>Big Tech learned the lessons of Big Pharma, and since at least the second Obama term has been <a href="https://prospect.org/justice/big-tech-investigations-started-2012/">engaged</a> in stealthily trying to embed restrictions on legislation and regulations in trade pacts.</p>
<p>Its use of this strategy became widely visible in October 2023, when the Biden administration formally <a href="https://ielp.worldtradelaw.net/2023/10/the-us-changes-its-mind-in-the-wto-e-commerce-negotiations.html">withdrew</a> U.S. support for four specific provisions limiting digital regulation that lobbyists had convinced the Trump administration to propose at the WTO four years before. (The Trump-era terms that the Biden administration refused to support were a departure from provisions incorporated into earlier U.S. trade agreements and appear in <a href="https://www.unilu.ch/en/faculties/faculty-of-law/professorships/managing-director-internationalisation/research/taped/">almost none</a> of the nearly 200 existing trade agreements with digital trade or e-commerce provisions worldwide.)</p>
<p>Not surprisingly, Big Tech lobbyists are now on a desperate mission to reverse the Biden administration’s decision. (The administration had already <a href="https://www.reuters.com/business/finance/us-suspends-indo-pacific-talks-key-aspects-digital-trade-lawmakers-2023-11-08/">suspended</a> talks on similar provisions in Indo-Pacific Economic Framework talks last year.) Their lobbyists have <a href="https://www.uschamber.com/international/trade-agreements/u-s-chamber-and-other-associations-letter-to-nsc-nec-on-digital-trade">geared up</a> the U.S. Chamber of Commerce and just about every other corporate lobbying group to help.</p>
    <!-- fp_choose_placement_related_posts -->

<p>The strong Biden stance at the WTO came after <a href="https://www.warren.senate.gov/imo/media/doc/2023.04.21%20Letter%20to%20USTR,%20Commerce%20re.%20digital%20trade%20and%20competition.pdf">Democratic</a> and <a href="https://www.vance.senate.gov/wp-content/uploads/2023/05/IPEF-Letter.pdf">Republican</a> senators and representatives, <a href="https://rethinktrade.org/letters-filings/letters-yelp-business-coalitions-more-firms-thank-biden-administration-for-digital-trade-move/">businesses</a> from Yelp to Match.com to news media companies, <a href="https://aflcio.org/worker-centered-digital-agenda">unions</a>, <a href="https://www.repair.org/blog/2023/09/12/tradeletter">farm groups</a>, <a href="https://rethinktrade.org/article/civil-rights-groups-warn-trade-talks-may-hurt-efforts-to-counter-discriminatory-algorithms/">civil rights groups</a>, and others had asked the administration to stop Big Tech’s digital trade tactic.</p>
<p>The smaller digital companies knew better than most how Big Tech was using anticompetitive practices to tilt an already-difficult playing field against them, and they worried that the digital rules being pushed in the trade agreements by Big Tech would make it all the more difficult for competition authorities to do what they could to enhance a competitive marketplace. A more competitive marketplace will lead to a stronger tech sector that benefits workers and larger U.S. firms as well as small businesses.</p>
<p>Not surprisingly, the lobbyists from digital firms with market power want rules that would enable them to entrench and extend that power. One of the four provisions Big Tech was trying to get at the WTO would <a href="https://www.washingtonpost.com/documents/9ee18cda-efb8-44ac-a84d-b53b48534a91.pdf?itid=lk_inline_manual_6">label most competition policies</a> as illegal trade barriers that must be eliminated. This rule, a perversion of the trade nondiscrimination principle, would constrain government actions against digital companies’ market dominance, threatening competition policies from the European Union’s <a href="https://commission.europa.eu/strategy-and-policy/priorities-2019-2024/europe-fit-digital-age/digital-markets-act-ensuring-fair-and-open-digital-markets_en">Digital Markets Act</a> to the bipartisan <a href="https://www.congress.gov/bill/117th-congress/senate-bill/2992">American Innovation and Choice Online Act</a> proposed in the United States. This rule would undermine Australian and Canadian legislation that requires mega-platforms that monopolize the advertising sector to negotiate compensation with the news media whose content they profit from without paying for it, as well as a <a href="https://rethinktrade.org/reports/digital-trade-doublespeak-big-techs-hijack-of-trade-lingo-to-attack-anti-monopoly-and-competition-policies/">Korean law</a> that would require fair play from app stores. The bipartisan <a href="https://www.congress.gov/bill/117th-congress/senate-bill/673">Journalism Competition and Preservation Act</a> and the <a href="https://www.congress.gov/bill/117th-congress/senate-bill/2710">Open App Markets Act</a> bills would enact similar policies in the United States; Big Tech’s proposed digital trade rules threaten these as well.</p>
<p>Another of the Trump-era Big Tech demands at the WTO was that digital trade rules guarantee platforms and data brokers almost absolute control over our personal data. Locking these corporate rights into a trade pact would undermine government enforcement of much-needed U.S. national privacy protections—or even laws that keep sensitive American data from unfriendly nations, such as the data broker oversight bill that unanimously <a href="https://www.theverge.com/2024/3/20/24106991/house-data-broker-foreign-adversaries-bill-passes">passed</a> the House on March 20, 2024.</p>
<p>A recent <a href="https://www.whitehouse.gov/briefing-room/presidential-actions/2024/02/28/executive-order-on-preventing-access-to-americans-bulk-sensitive-personal-data-and-united-states-government-related-data-by-countries-of-concern/">executive order</a> from U.S. President Joe Biden on “preventing access to Americans’ bulk sensitive personal data and United States government-related data by countries of&nbsp;concern” regulates flows of Americans’ sensitive geolocation, biometric, health, and other data for national security reasons. This order would stop big platforms and data brokers from their recently exposed <a href="https://www.iccl.ie/digital-data/americas-hidden-security-crisis/">practice</a> of selling sensitive information to the Chinese and Russian governments. But if Big Tech gets its way, the House-passed bill—and Biden’s executive order—would be forbidden as illegal trade barriers under the digital trade agreement.</p>
<p>But while Big Tech demands that ordinary citizens give up their privacy, it is demanding for itself new secrecy rights not available in U.S. law. This includes a rule that would <a href="https://rethinktrade.org/reports/ai-report/">thwart governments</a> from conducting pre-reviews of automated decision-making algorithms. These algorithms, when used by businesses, can determine who gets loans, jobs, apartments, and even who gets bail or jail. Prescreening is needed to safeguard Americans from harms caused by the use of algorithms that can disguise not only racial, ethnic, age, and gender discrimination but wage and hour <a href="https://harpers.org/archive/2015/03/the-spy-who-fired-me/">abuses</a> and facilitate consumer rip-offs like algorithmic pricing that <a href="http://alexandermackay.org/files/Dynamic%20Pricing%20Algorithms,%20Consumer%20Harm,%20and%20Regulatory%20Response.pdf">charges some consumers more</a> than others. There is no check on these algorithms at the moment, and screening is central to numerous bipartisan bills as well as the president’s <a href="https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/">executive order</a> on AI.</p>
<p>The secrecy provisions would also undermine “right to repair” policies that guarantee access to software updates and “digital keys” so people can update and repair their phones and other products and save money by using independent repair shops to fix equipment.</p>
<hr>
<p><span>One key tactic</span> the lobbyists are employing in this fight is to try to direct the debate away from Big Tech misconduct and into a foreign-policy frame, claiming that the industry’s demands are essential for U.S. global leadership if we are to win the economic war with China. Their argument that somehow the United States’ withdrawing support for unpopular digital trade proposals promoted by Big Tech lobbyists would strengthen China’s hand, or make Chinese proposals with no support at the WTO suddenly popular, is absurd.</p>
<p>To the extent that there is any connection between these rules and America’s geopolitical interests, we would better our position by promoting standards that align with <a href="https://rethinktrade.org/reports/paper-the-biden-administrations-digital-trade-pivot-and-what-should-be-next/">our values</a>. Many countries would join the U.S. in supporting rules that ban forced data localization and promote the data flows needed for the internet to function, while also not conferring new rights over our data to private firms and providing room for privacy policies.</p>
<p>There’s also the claim from industry lobbyists that strong new secrecy protections are necessary to keep China or other countries from stealing U.S. innovations. Yet China and all WTO signatory nations already are bound to WTO “<a href="https://www.wto.org/english/tratop_e/trips_e/intel2_e.htm">trade secrets</a>” rules that, like U.S. law, forbid governments from sharing confidential business information, including algorithms and source code, that they may access for safety inspections. Enforcement actions against China or other violators make sense. But banning all governments from inspecting AI will only mean the industry interests evade oversight by those governments that do follow the rule of law.</p>
<hr>
<p><span>Many of the provisions</span> in question are complex—and it is exactly that complexity the lobbyists try to use to their advantage, arguing that these are matters too complicated for ordinary people. Because digital rules are written in arcane trade jargon, their meaning is often unclear. For instance, the industry-favored rules forbidding governments from regulating data flows appear to have an exception for policies “necessary to achieve a legitimate public policy objective.” Except the provision replicates existing WTO exception language that is packed with legal hurdles—exceptions to the exceptions—and that has proved to be entirely ineffective: In the 48 attempts where countries have tried to make use of this exception to defend some policy, WTO tribunals have <a href="http://www.citizen.org/article/wto-general-exceptions-trade-laws-faulty-ivory-tower/">ruled against the exception’s use</a> 46 times.</p>
<p>But once unpacked from trade-lingo arcana, it is painfully apparent that these digital trade proposals would handcuff Congress, the Biden administration, and future administrations as well, preventing them from doing much of what the American public is demanding to curb Big Tech abuses and for which there is bipartisan support.</p>
<p>Whether one agrees or disagrees with a particular measure to promote competition and circumscribe digital harms is not the question. There is a debate to be had about how best to circumscribe the digital harms and how best to promote competition consistent with a reasonable interpretation of the Constitution and our values. Some think that Europe’s actions, like its Digital Markets Act (DMA) and Digital Services Act (DSA), have gone too far; others think they haven’t gone far enough. Some worry that Australia’s bargaining code won’t deliver enough to small news outlets and will give too much to the already-powerful Murdoch news empire. (I have my views: We need stronger competition and digital protection laws than the DMA and DSA, and the Australian bargaining code is an important first step in redressing a set of major problems.)</p>
<p>What should not be controversial is that critical decisions must not be made stealthily within trade agreements, but rather through a robust public discussion.</p>
<p>But special-interest battles never end quietly. There is a strong rear-guard action by the Big Tech lobby to reverse the Biden administration’s October decision. Improbably, some elements of the Biden administration seem to support that mission.</p>
<p>I stand strongly with the mainstream of the Biden administration and the American people who want a safe, competitive digital economy, one that neither invades our privacy nor discriminates.</p>
<p>As U.S. Trade Representative Katherine Tai said in a <a href="https://www.youtube.com/watch?v=nwT5GfbxTMY&amp;t=186s">recent speech</a>, “[These] issues are very much consequential, not just for trade and economics, but for our entire society.”</p>

											</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Xr0: C but Safe (133 pts)]]></title>
            <link>https://xr0.dev/</link>
            <guid>39936291</guid>
            <pubDate>Thu, 04 Apr 2024 21:58:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://xr0.dev/">https://xr0.dev/</a>, See on <a href="https://news.ycombinator.com/item?id=39936291">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		
<div id="nav">
	
	<p>
		<h2 id="subtitle">C&nbsp;But&nbsp;Safe</h2>
	</p>
	
	
	
	
	<p><a href="https://xr0.zulipchat.com/">
			<img src="https://xr0.dev/static/img/zulip.svg">
		</a>
		<a href="https://github.com/xr0-org/xr0">
			<img id="gh" src="https://xr0.dev/static/img/gh.svg">
		</a>
		<a href="https://git.sr.ht/~lbnz/xr0" id="srht">
			<img src="https://xr0.dev/static/img/sr.ht.svg">
		</a>
	</p>
</div>




	<p>Xr0 is a verifier for C.
It eliminates many stubborn instances of undefined behaviour, like
use-after-frees, double frees,
null pointer dereferences
and the use of uninitialised memory.</p>
<p>Xr0 uses C-like annotations to verify code:</p>
<pre tabindex="0"><code>void *
alloc() ~ [ return malloc(1); ] /* caller must free */
{
        return malloc(1);
}
</code></pre><details>
<summary>More about the annotations</summary>
<p>They’re attached to every function that is potentially unsafe and express what
its callers need to know to use it safely:</p>
<pre tabindex="0"><code>void *
alloc_if(int x) ~ [ if (x) return malloc(1); ] /* caller must free if x != 0 */
{
        if (x) {
                return malloc(1);
        } else {
                return NULL;
        }
}
</code></pre><p>The really subtle safety bugs creep in through layers of function calls.
Xr0 makes this impossible, because everything needed to secure safety is
distributed through every function call, so that no subtle mistake can creep in.
It “quantum entangles” the safety semantics of every part of the program with
every other part.
Think of it like a infinitely rich type system that rises to the demands of your
program’s structure.
You still have to make the code safe; Xr0 just checks your work.
Thus Xr0 is magical like the wand, not the magician.
The real magic comes from the programmer.</p>
</details>
<p>Xr0 is a work in progress and currently verifies a subset of C89.
Its most significant limitation is we haven’t yet implemented verification for
loops and recursive functions, so these are being bridged by axiomatic
annotations.
Xr0 1.0.0 will enable programming in C with no undefined behaviour, but for now
it’s useful for verifying sections of programs.</p>
<p>Xr0 is written in pure C and is open source.
View it on <a href="https://github.com/xr0-org/xr0">GitHub</a> or
<a href="https://git.sr.ht/~lbnz/xr0">SourceHut</a>.</p>
<h2 id="intrigued">Intrigued?</h2>
<p>Read the <a href="https://xr0.dev/learn">tutorial</a> and give Xr0 a <a href="https://xr0.dev/try">spin</a>.</p>
<p>If you want to go deeper, engage with <a href="https://xr0.dev/theses">our theses</a>, which explain
how Xr0 will make C safe, and take a look at
<a href="https://xr0.dev/vision-roadmap">our vision and roadmap</a>.</p>

<p>Come and talk to us on the <a href="https://xr0.zulipchat.com/">Xr0 Zulip</a>, or
via email <a href="mailto:betz@xr0.dev">here</a> and <a href="mailto:a@xr0.dev">here</a>.</p>

<p>The Xr0 project is grateful for generous support from</p>
<div>
	
	<p>
		An open-source modern team chat app designed to keep both live and
		asynchronous conversations organized.
		</p>
</div>





	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[German state ditches Microsoft for Linux and LibreOffice (458 pts)]]></title>
            <link>https://www.zdnet.com/article/german-state-ditches-microsoft-for-linux-and-libreoffice/</link>
            <guid>39936284</guid>
            <pubDate>Thu, 04 Apr 2024 21:57:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.zdnet.com/article/german-state-ditches-microsoft-for-linux-and-libreoffice/">https://www.zdnet.com/article/german-state-ditches-microsoft-for-linux-and-libreoffice/</a>, See on <a href="https://news.ycombinator.com/item?id=39936284">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><figure><div><picture><source media="(max-width: 767px)" srcset="https://www.zdnet.com/a/img/resize/21408df868ca5508c5769937ae347ae1401b4b03/2024/04/04/c7995ab6-ca68-4c8e-87a8-21d8aab4b25c/libreoffice20iconst.jpg?auto=webp&amp;width=768" alt="libreoffice20iconst.jpg"><source media="(max-width: 1023px)" srcset="https://www.zdnet.com/a/img/resize/91b518b0ead26c323a3d0d18314deacc30b677e3/2024/04/04/c7995ab6-ca68-4c8e-87a8-21d8aab4b25c/libreoffice20iconst.jpg?auto=webp&amp;width=1024" alt="libreoffice20iconst.jpg"><source media="(max-width: 1440px)" srcset="https://www.zdnet.com/a/img/resize/34c2f02f9c580ff977f70093dd7f22a9200c770b/2024/04/04/c7995ab6-ca68-4c8e-87a8-21d8aab4b25c/libreoffice20iconst.jpg?auto=webp&amp;width=1280" alt="libreoffice20iconst.jpg"> <img src="https://www.zdnet.com/a/img/resize/34c2f02f9c580ff977f70093dd7f22a9200c770b/2024/04/04/c7995ab6-ca68-4c8e-87a8-21d8aab4b25c/libreoffice20iconst.jpg?auto=webp&amp;width=1280" alt="libreoffice20iconst.jpg" width="1280" height="331.32010353753236" fetchpriority="low"></picture></div> <figcaption> <span>The Document Foundation</span></figcaption></figure><p>Thanks to hardware vendors working hand-in-glove with Microsoft, many people never realize there are alternatives to Windows and Office.&nbsp;</p><p>But that's not the case in the European Union (EU) and China, where computer users know all about Microsoft's dominance on the desktop -- and many don't like it. So, when Dirk Schrödter, digitalization minister for the German state of Schleswig-Holstein,&nbsp; announced the state government would&nbsp;<a href="https://www.schleswig-holstein.de/DE/landesregierung/ministerien-behoerden/I/Presse/PI/2024/CdS/240403_cds_it-arbeitsplatz.html#link={%22role%22:%22standard%22,%22href%22:%22https://www.schleswig-holstein.de/DE/landesregierung/ministerien-behoerden/I/Presse/PI/2024/CdS/240403_cds_it-arbeitsplatz.html%22,%22target%22:%22_blank%22,%22absolute%22:%22%22,%22linkText%22:%22switch%20from%20proprietary%20software%20\%22towards%20free,%20open-source%20systems%22}" target="_blank" rel="noopener noreferrer nofollow">switch from proprietary software</a> "towards free, open-source systems and digitally sovereign IT workplaces for the state administration's approximately 30,000 employees," there was cause for rejoicing among Linux desktop fans.</p><p><strong>Also: <a href="https://www.zdnet.com/article/best-linux-desktops-for-beginners/" rel="follow">The best Linux distros for beginners: Expert tested</a></strong></p><p>Specifically, Schleswig-Holstein is dumping Windows and Office for Linux and the popular open-source office suite, <a href="https://www.libreoffice.org/" target="_blank" rel="noopener noreferrer nofollow">LibreOffice</a>. The Schleswig-Holstein cabinet made this decision not because of Linux and LibreOffice's technical superiority, but because it values "<a href="https://www.europarl.europa.eu/RegData/etudes/BRIE/2020/651992/EPRS_BRI(2020)651992_EN.pdf" target="_blank" rel="noopener noreferrer nofollow">digital sovereignty.</a>"</p><p>In the EU, digital sovereignty means protecting citizens' data from being vacuumed up by foreign companies and enabling European tech companies to compete with their American and Chinese rivals.&nbsp;</p><!----><p>As <a href="https://www.documentfoundation.org/" target="_blank" rel="noopener noreferrer nofollow">The Document Foundation</a>, the organization backing LibreOffice, put it, "The term digital sovereignty is very important here. If a public administration uses proprietary, closed software that can't be studied or modified, it is very difficult to know what happens to users' data."</p><p>Exactly.</p><p>Although <a href="https://www.zdnet.com/article/heres-how-microsoft-will-change-windows-to-comply-with-eu-laws/" rel="follow">Microsoft is trying</a> to meet the EU's digital sovereignty requirements, European governments aren't -- shall we say -- all that trusting. Schrödter explained:</p><blockquote><p>"We have no influence on the operating processes of such [proprietary] solutions and the handling of data, including a possible outflow of data to third countries. As a state, we have a great responsibility towards our citizens and companies to ensure that their data is kept safe with us, and we must ensure that we are always in control of the IT solutions we use and that we can act independently as a state."</p></blockquote><p><strong>Also: <a href="https://www.zdnet.com/article/thinking-about-switching-to-linux-things-you-need-to-know/" rel="follow">Thinking about switching to Linux? 10 things you need to know</a></strong></p><p>There are other reasons the state is parting ways with Office and Windows: To save money and increase security. "The use of open source software also benefits from improved IT security, cost-effectiveness, data protection, and seamless collaboration between different systems," Schrödter said."</p><p>Going forward, the plan is to replace Microsoft Office with LibreOffice, Windows with a yet-to-be-determined Linux desktop distro, and other Microsoft-specific programs with open-source equivalents. For example, the plan is to use <a href="https://nextcloud.com/" target="_blank" rel="noopener noreferrer nofollow">Nextcloud</a>, <a href="https://software.open-xchange.com/products/appsuite/doc/OX-Mail-Clients-User-Guide-English-v7.8.1.pdf" target="_blank" rel="noopener noreferrer nofollow">Open Xchange/Thunderbird</a>, and the <a href="https://www.univention.com/products/ucs/functions/active-directory-connection/" target="_blank" rel="noopener noreferrer nofollow">Univention Active Directory (AD)</a> connector to replace Sharepoint and Exchange/Outlook.</p><p>If some of this sounds familiar, congratulations on having a great memory. Munich, the capital of Bavaria, Germany,&nbsp;<a href="https://www.zdnet.com/article/munich-breaks-with-windows-for-linux/" rel="follow">switched from Windows to Linux in 2004</a>. That move lasted for a decade before Munich returned to Windows -- in no small part because the mayor wanted <a href="https://www.zdnet.com/article/linux-not-windows-why-munich-is-shifting-back-from-microsoft-to-open-source-again/" rel="follow">Microsoft to move its headquarters to Munich</a>.&nbsp;</p><p><strong>Also: <a href="https://www.zdnet.com/home-and-office/work-life/5-ways-libreoffice-meets-my-writing-needs-better-than-google-docs-can/" rel="follow">5 ways LibreOffice meets my writing needs better than Google Docs can</a></strong></p><p>Other countries, notably China, have proverbs that say they are much more stubborn when shifting gears from Windows to Linux. The last few Chinese government <a href="https://techhq.com/2022/07/open-source-china-linux-kylin-kernel-desktop-de-microsoft/" target="_blank" rel="noopener noreferrer nofollow">PCs running Windows have been replaced</a> by systems mostly using Kylin Linux. The latest version of <a href="https://www.zdnet.com/article/ubuntu-kylin-is-a-beautiful-operating-system-with-some-intriguing-features/" rel="follow">Kylin Linux</a> started life as an <a href="https://ubuntu.com/" target="_blank" rel="noopener noreferrer nofollow">Ubuntu Linux</a> clone optimized for the Chinese language.&nbsp;</p><p>In China, as in Europe, a large part of the motivation for the move was so that the local governments and organizations, rather than Microsoft, would control their desktop. This may not be why Linux fans wanted to see users abandon Windows, but it will do.&nbsp;</p><div id="pinbox-b82f3805-3ad5-4fd0-9cb0-1b5e5efa4091"><h4>Open Source</h4> <!---->  </div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mario meets Pareto: multi-objective optimization of Mario Kart builds (1404 pts)]]></title>
            <link>https://www.mayerowitz.io/blog/mario-meets-pareto</link>
            <guid>39936246</guid>
            <pubDate>Thu, 04 Apr 2024 21:53:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.mayerowitz.io/blog/mario-meets-pareto">https://www.mayerowitz.io/blog/mario-meets-pareto</a>, See on <a href="https://news.ycombinator.com/item?id=39936246">Hacker News</a></p>
<div id="readability-page-1" class="page"><div slot="foreground"><section><p>Finding the fastest driver is as simple as ranking them by their <i data-svelte-h="svelte-nndadd">speed</i>
                    statistic. Here you might think that
                    <img src="https://r2.mayerowitz.io/mk8_data/images/64px-MK8_Bowser_Icon.png" alt="Bowser" loading="lazy">Bowser or
                    <img src="https://r2.mayerowitz.io/mk8_data/images/64px-MK8_Wario_Icon.png" alt="Wario" loading="lazy">Wario are a no-brainer.</p></section> <section><p>But you can't just rely on
                    speed
                    to find the optimal build. You have to consider
                    one as well. Now, finding the best
                    
                    is not trivial anymore — you have to make trade-offs between

                    
                    and
                     <br>  </p></section> <section><p>Look closely though! You'll find out that some options are always <i data-svelte-h="svelte-sv5bxj">dominated</i>. Let's focus on this poor
                    <img src="https://r2.mayerowitz.io/mk8_data/images/64px-MK8_Koopa_Icon.png" alt="Koopa Troopa" loading="lazy">Koopa for instance.</p></section> <section><p><img src="https://r2.mayerowitz.io/mk8_data/images/64px-MK8_Cat_Peach_Icon.png" alt="Cat Peach" loading="lazy">Cat Peach has more speed for the same acceleration, and
                    <img src="https://r2.mayerowitz.io/mk8_data/images/64px-MK8_Toadette_Icon.png" alt="Toadette" loading="lazy">Toadette has more acceleration for the same speed. Between you and me, if you
                    want to win, never allow
                    <img src="https://r2.mayerowitz.io/mk8_data/images/64px-MK8_Koopa_Icon.png" alt="Koopa Troopa" loading="lazy">Koopa to sit in your kart!</p></section> <section><p>You can identify all efficient drivers that, unlike Koopa, are never dominated
                    on both <i data-svelte-h="svelte-nndadd">speed</i> and <i data-svelte-h="svelte-b95v2w">acceleration</i>. Together, they form what is called
                    the <i data-svelte-h="svelte-az7ies">Pareto front</i> (or frontier).</p></section> <section><p>Mind you: all elements on the frontier are not equally good. You probably won't
                    pick a driver sitting on the edge of the frontier because you want some balance
                    between <i data-svelte-h="svelte-nndadd">speed</i> and <i data-svelte-h="svelte-b95v2w">acceleration</i>. The Pareto <i data-svelte-h="svelte-17tvgv7">efficiency</i> is an
                    objective criteria to filter out suboptimal choices, but you still need to make up
                    your final decision.</p></section> <div><p>Given your play style and skills, you may put more
                    <span data-svelte-h="svelte-1spn57m">weight</span> on one statistic over
                    the other. Those preferences will reveal the component on the frontier that
                    suits you the best.
                    </p> <p>Best
                        
                        : {}<br></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tool Use (function calling) (189 pts)]]></title>
            <link>https://docs.anthropic.com/claude/docs/tool-use</link>
            <guid>39936048</guid>
            <pubDate>Thu, 04 Apr 2024 21:35:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://docs.anthropic.com/claude/docs/tool-use">https://docs.anthropic.com/claude/docs/tool-use</a>, See on <a href="https://news.ycombinator.com/item?id=39936048">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-container"><section><div data-testid="RDMD"><p>Claude is capable of interacting with external client-side tools and functions, allowing you to equip Claude with your own custom tools to perform a wider variety of tasks.</p>
<blockquote theme="🎉"><h2><span>🎉</span><p>Tool use public beta</p></h2><p>We're excited to announce that tool use is now in public beta! To access this feature, you'll need to include the anthropic-beta: tools-2024-04-04 header in your API requests. </p><p>We'll be iterating on this open beta over the coming weeks, so we appreciate all your feedback. Please share your ideas and suggestions using this <a target="_self" href="https://forms.gle/BFnYc6iCkWoRzFgk7">form</a>.</p></blockquote>
<p>Here's an example of how to provide tools to Claude using the Messages API:</p>
<div role="tabpanel"><pre><code data-lang="shell" name="" tabindex="0">curl https://api.anthropic.com/v1/messages \
  -H "content-type: application/json" \
  -H "x-api-key: $ANTHROPIC_API_KEY" \
  -H "anthropic-version: 2023-06-01" \
  -H "anthropic-beta: tools-2024-04-04" \
  -d '{
    "model": "claude-3-opus-20240229",
    "max_tokens": 1024,
    "tools": [
      {
        "name": "get_weather",
        "description": "Get the current weather in a given location",
        "input_schema": {
          "type": "object",
          "properties": {
            "location": {
              "type": "string",
              "description": "The city and state, e.g. San Francisco, CA"
            }
          },
          "required": ["location"]
        }
      }
    ],
    "messages": [
      {
        "role": "user",
        "content": "What is the weather like in San Francisco?"
      }
    ]
  }'
</code></pre><pre><code data-lang="python" name="Python" tabindex="0">import anthropic

client = anthropic.Anthropic()

response = client.beta.tools.messages.create(
    model="claude-3-opus-20240229",
    max_tokens=1024,
    tools=[
        {
            "name": "get_weather",
            "description": "Get the current weather in a given location",
            "input_schema": {
                "type": "object",
                "properties": {
                    "location": {
                        "type": "string",
                        "description": "The city and state, e.g. San Francisco, CA",
                    }
                },
                "required": ["location"],
            },
        }
    ],
    messages=[{"role": "user", "content": "What's the weather like in San Francisco?"}],
)
print(response)
</code></pre></div>
<p>Please note that during the beta period:</p>
<ul>
<li>Streaming (<code data-lang="" name="" tabindex="0">stream=true</code>) is not yet supported. We plan to add streaming support in a future beta version.</li>
<li>While the feature is production-ready, we may introduce multiple beta versions before the final release.</li>
<li>Tool use is not yet available on third-party platforms like Vertex AI or AWS Bedrock, but is coming soon.</li>
</ul>
<hr>

<p>Using tools with Claude involves the following steps:</p>
<ol>
<li>
<p><strong>Provide Claude with tools and a user prompt:</strong> (API request)</p>
<ul>
<li>Define the set of tools you want Claude to have access to, including their names, descriptions, and input schemas. </li>
<li>Provide a user prompt that may require the use of one or more of these tools to answer, such as "What is the weather in San Francisco?".</li>
</ul>
</li>
<li>
<p><strong>Claude uses a tool:</strong> (API response)</p>
<ul>
<li>Claude assesses the user prompt and decides whether any of the available tools would help with the user's query or task. If so, it also decides which tool(s) to use and with what inputs.</li>
<li>Claude constructs a properly formatted tool use request. </li>
<li>The API response will have a <code data-lang="" name="" tabindex="0">stop_reason</code> of <code data-lang="" name="" tabindex="0">tool_use</code>, indicating that Claude wants to use an external tool.</li>
</ul>
</li>
<li>
<p><strong>Extract tool input, run code, and return results:</strong> (API request)</p>
<ul>
<li>On the client side, you should extract the tool name and input from Claude's tool use request.</li>
<li>Run the actual tool code on the client side. </li>
<li>Return the results to Claude by continuing the conversation with a new <code data-lang="" name="" tabindex="0">user</code> message containing a <code data-lang="" name="" tabindex="0">tool_result</code> content block.</li>
</ul>
</li>
<li>
<p><strong>Claude uses tool result to formulate a response:</strong> (API response) </p>
<ul>
<li>After receiving the tool results, Claude will use that information to formulate its final response to the original user prompt.</li>
</ul>
</li>
</ol>
<p>Steps (3) and (4) are optional — for some workflows, Claude using the tool is all the information you need, and you might not need to return tool results back to Claude.</p>
<blockquote theme="💡"><h2><span>💡</span><p>All tools are user-provided</p></h2><p>It's important to note that Claude does not have access to any built-in server-side tools. All tools must be explicitly provided by you, the user, in each API request. This gives you full control and flexibility over the tools Claude can use.</p></blockquote>
<hr>

<p>Tools are specified in the <code data-lang="" name="" tabindex="0">tools</code> top-level parameter of the API request. Each tool definition includes:</p>
<ul>
<li><code data-lang="" name="" tabindex="0">name</code>: The name of the tool. Must match the regex <code data-lang="" name="" tabindex="0">^[a-zA-Z0-9_-]{1,64}$</code>.</li>
<li><code data-lang="" name="" tabindex="0">description</code>: A detailed plaintext description of what the tool does, when it should be used, and how it behaves. </li>
<li><code data-lang="" name="" tabindex="0">input_schema</code>: A <a target="_self" href="https://json-schema.org/">JSON Schema</a> object defining the expected parameters for the tool.</li>
</ul>
<p>Here's an example simple tool definition:</p>
<div role="tabpanel"><pre><code data-lang="json" name="" tabindex="0">{
  "name": "get_weather",
  "description": "Get the current weather in a given location",
  "input_schema": {
    "type": "object", 
    "properties": {
      "location": {
        "type": "string",
        "description": "The city and state, e.g. San Francisco, CA"
      },
      "unit": {
        "type": "string",
        "enum": ["celsius", "fahrenheit"],
        "description": "The unit of temperature, either 'celsius' or 'fahrenheit'"
      }
    },
    "required": ["location"]
  }
}
</code></pre></div>
<p>This tool, named <code data-lang="" name="" tabindex="0">get_weather</code>, expects an input object with a required <code data-lang="" name="" tabindex="0">location</code> string and an optional <code data-lang="" name="" tabindex="0">unit</code> string that must be either "celsius" or "fahrenheit".</p>

<p>To get the best performance out of Claude when using tools, follow these guidelines:</p>
<ul>
<li>
<p><strong>Provide extremely detailed descriptions.</strong> This is by far the most important factor in tool performance. Your descriptions should explain every detail about the tool, including:</p>
<ul>
<li>What the tool does</li>
<li>When it should be used (and when it shouldn't)</li>
<li>What each parameter means and how it affects the tool's behavior</li>
<li>Any important caveats or limitations, such as what information the tool does not return if the tool name is unclear</li>
</ul>
<p>The more context you can give Claude about your tools, the better it will be at deciding when and how to use them. Aim for at least 3-4 sentences per tool description, more if the tool is complex.</p>
</li>
<li>
<p><strong>Prioritize descriptions over examples.</strong> While you can include examples of how to use a tool in its description or in the accompanying prompt, this is less important than having a clear and comprehensive explanation of the tool's purpose and parameters. Only add examples after you've fully fleshed out the description.</p>
</li>
</ul>
<p>Here's an example of a good tool description:</p>
<div role="tabpanel"><pre><code data-lang="json" name="" tabindex="0">{
  "name": "get_stock_price",
  "description": "Retrieves the current stock price for a given ticker symbol. The ticker symbol must be a valid symbol for a publicly traded company on a major US stock exchange like NYSE or NASDAQ. The tool will return the latest trade price in USD. It should be used when the user asks about the current or most recent price of a specific stock. It will not provide any other information about the stock or company.",
  "input_schema": {
    "type": "object",
    "properties": {
      "ticker": {
        "type": "string",
        "description": "The stock ticker symbol, e.g. AAPL for Apple Inc."
      }
    },
    "required": ["ticker"]
  }
}
</code></pre></div>
<p>In contrast, here's an example of a poor tool description:</p>
<div role="tabpanel"><pre><code data-lang="json" name="" tabindex="0">{
  "name": "get_stock_price",
  "description": "Gets the stock price for a ticker.",
  "input_schema": {
    "type": "object",
    "properties": {
      "ticker": {
        "type": "string"
      }
    },
    "required": ["ticker"]  
  }
}
</code></pre></div>
<p>The good description clearly explains what the tool does, when to use it, what data it returns, and what the <code data-lang="" name="" tabindex="0">ticker</code> parameter means. The poor description is too brief and leaves Claude with many open questions about the tool's behavior and usage.</p>
<hr>

<p>When Claude decides to use one of the tools you've provided, it will return a response with a <code data-lang="" name="" tabindex="0">stop_reason</code> of <code data-lang="" name="" tabindex="0">tool_use</code> and one or more <code data-lang="" name="" tabindex="0">tool_use</code> content blocks in the API response that include:</p>
<ul>
<li><code data-lang="" name="" tabindex="0">id</code>: A unique identifier for this particular tool use block. This will be used to match up the tool results later.</li>
<li><code data-lang="" name="" tabindex="0">name</code>: The name of the tool being used.</li>
<li><code data-lang="" name="" tabindex="0">input</code>: An object containing the input being passed to the tool, conforming to the tool's <code data-lang="" name="" tabindex="0">input_schema</code>.</li>
</ul>
<p>Here's an example API response with a <code data-lang="" name="" tabindex="0">tool_use</code> content block:</p>
<div role="tabpanel"><pre><code data-lang="json" name="" tabindex="0">{
  "id": "msg_01Aq9w938a90dw8q",
  "model": "claude-3-opus-20240229",
  "stop_reason": "tool_use",
  "role": "assistant",
  "content": [
    {
      "type": "text",
      "text": "&lt;thinking&gt;I need to use the get_weather, and the user wants SF, which is likely San Francisco, CA.&lt;/thinking&gt;"
    },
    {
      "type": "tool_use",
      "id": "toolu_01A09q90qw90lq917835lq9",
      "name": "get_weather",
      "input": {"location": "San Francisco, CA", "unit": "celsius"}
    }
  ]
}
</code></pre></div>
<p>When you receive a tool use response, you should:</p>
<ol>
<li>Extract the <code data-lang="" name="" tabindex="0">name</code>, <code data-lang="" name="" tabindex="0">id</code>, and <code data-lang="" name="" tabindex="0">input</code> from the <code data-lang="" name="" tabindex="0">tool_use</code> block.</li>
<li>Run the actual tool in your codebase corresponding to that tool name, passing in the tool <code data-lang="" name="" tabindex="0">input</code>.</li>
<li>[optional] Continue the conversation by sending a new message with the <code data-lang="" name="" tabindex="0">role</code> of <code data-lang="" name="" tabindex="0">user</code>, and a <code data-lang="" name="" tabindex="0">content</code> block containing the <code data-lang="" name="" tabindex="0">tool_result</code> type and the following information:
<ul>
<li><code data-lang="" name="" tabindex="0">tool_use_id</code>: The <code data-lang="" name="" tabindex="0">id</code> of the tool use request this is a result for.</li>
<li><code data-lang="" name="" tabindex="0">content</code>: The result of the tool, as a string (e.g. <code data-lang="" name="" tabindex="0">"content": "65 degrees"</code>) or list of nested content blocks (e.g. <code data-lang="" name="" tabindex="0">"content": [{"type": "text", "text": "65 degrees"}]\</code>). During beta, only the <code data-lang="" name="" tabindex="0">text</code> type content blocks are supported for <code data-lang="" name="" tabindex="0">tool_result</code> content.</li>
<li><code data-lang="" name="" tabindex="0">is_error</code> (optional): Set to <code data-lang="" name="" tabindex="0">true</code> if the tool execution resulted in an error.</li>
</ul>
</li>
</ol>
<p>Here's an example of returning a successful tool result:</p>
<div role="tabpanel"><pre><code data-lang="json" name="" tabindex="0">{
  "role": "user",
  "content": [
    {
      "type": "tool_result",
      "tool_use_id": "toolu_01A09q90qw90lq917835lq9",
      "content": "65 degrees"
    }
  ]
}
</code></pre></div>
<p>This is equivalent to the following fully-expanded <code data-lang="" name="" tabindex="0">content</code> form:</p>
<div role="tabpanel"><pre><code data-lang="json" name="" tabindex="0">{
  "role": "user",
  "content": [
    {
      "type": "tool_result",
      "tool_use_id": "toolu_01A09q90qw90lq917835lq9",
      "content": [{"type": "text", "text": "65 degrees"}]
    }
  ]
}
</code></pre></div>
<p>And here's an example of returning an error result:</p>
<div role="tabpanel"><pre><code data-lang="json" name="" tabindex="0">{
  "role": "user",
  "content": [
    {
      "type": "tool_result",
      "tool_use_id": "toolu_01A09q90qw90lq917835lq9",
      "content": "ConnectionError: the weather service API is not available (HTTP 500)",
      "is_error": true
    }
  ]
}
</code></pre></div>
<p>After receiving the tool result, Claude will use that information to continue generating a response to the original user prompt.</p>
<p>You can also return a non-erroneous tool result with empty <code data-lang="" name="" tabindex="0">content</code>, indicating that the tool ran successfully without any output:</p>
<div role="tabpanel"><pre><code data-lang="json" name="" tabindex="0">{
  "role": "user",
  "content": [
    {
      "type": "tool_result",
      "tool_use_id": "toolu_01A09q90qw90lq917835lq9",
    }
  ]
}
</code></pre></div>
<blockquote theme="💡"><h2><span>💡</span><p>Differences from other APIs</p></h2><p>You may be familiar with other APIs that return tool use as separate from the model's primary output, or which use a special-purpose <code data-lang="" name="" tabindex="0">tool</code> or <code data-lang="" name="" tabindex="0">function</code> message <code data-lang="" name="" tabindex="0">role</code>.</p><p>In contrast, Anthropic's models and API are built around alternating <code data-lang="" name="" tabindex="0">user</code> and <code data-lang="" name="" tabindex="0">assistant</code> messages, where each message is an array of rich content blocks: <code data-lang="" name="" tabindex="0">text</code>, <code data-lang="" name="" tabindex="0">image</code>, <code data-lang="" name="" tabindex="0">tool_use</code>, and <code data-lang="" name="" tabindex="0">tool_result</code>.</p><p>In this format, <code data-lang="" name="" tabindex="0">user</code> messages represents client-side and user / human-managed content, and <code data-lang="" name="" tabindex="0">assistant</code> messages represent server-side and AI-managed content. As such, there is no special <code data-lang="" name="" tabindex="0">tool</code> or <code data-lang="" name="" tabindex="0">function</code> message <code data-lang="" name="" tabindex="0">role</code>, and you should include <code data-lang="" name="" tabindex="0">tool_result</code> blocks in the <code data-lang="" name="" tabindex="0">content</code> of your <code data-lang="" name="" tabindex="0">user</code> messages.</p></blockquote>
<br>
<hr>

<p>In some cases, you may want Claude to use a specific tool to answer the user's question, even if Claude thinks it could provide an answer without using a tool. You can encourage this by adding explicit instructions to do so in a <code data-lang="" name="" tabindex="0">user</code> message, like: <code data-lang="" name="" tabindex="0">What's the weather like in London? Use the get_weather tool in your response.</code></p>
<p>By explicitly telling Claude to use the <code data-lang="" name="" tabindex="0">get_weather</code> tool, you can encourage it to make use the tool you want. This technique can be useful for testing and debugging your tool integrations, or when you know that the tool should always be used, regardless of input.</p>
<hr>

<p>Tools do not necessarily need to be client-side functions — you can use tools anytime you want the model to return JSON output that follows a provided schema. For example, you might use a <code data-lang="" name="" tabindex="0">record_summary</code> tool with a particular schema. See <a target="_self" href="https://docs.anthropic.com/claude/docs/tool-use-examples">tool use examples</a> for a full working example.</p>
<hr>

<p>There are a few different types of errors that can occur when using tools with Claude:</p>

<p>If the tool itself throws an error during execution (e.g. a network error when fetching weather data), you can return the error message in the <code data-lang="" name="" tabindex="0">content</code> along with <code data-lang="" name="" tabindex="0">"is_error": true</code>:</p>
<div role="tabpanel"><pre><code data-lang="json" name="" tabindex="0">{
  "role": "user", 
  "content": [
    {
      "type": "tool_result",
      "tool_use_id": "toolu_01A09q90qw90lq917835lq9",
      "content": "ConnectionError: the weather service API is not available (HTTP 500)",
      "is_error": true
    }
  ]
}
</code></pre></div>
<p>Claude will then incorporate this error into its response to the user, e.g. "I'm sorry, I was unable to retrieve the current weather because the weather service API is not available. Please try again later."</p>

<p>If Claude's response is cut off due to hitting the <code data-lang="" name="" tabindex="0">max_tokens</code> limit, and the truncated response contains an incomplete tool use block, you'll need to retry the request with a higher <code data-lang="" name="" tabindex="0">max_tokens</code> value to get the full tool use.</p>

<p>If Claude's attempted use of a tool is invalid (e.g. missing required parameters), it usually means that the there wasn't enough information for Claude to use the tool correctly. Your best bet during development is to try the request again with more-detailed <code data-lang="" name="" tabindex="0">description</code> values in your tool definitions.</p>
<p>However, you can also continue the conversation forward with a <code data-lang="" name="" tabindex="0">tool_result</code> that indicates the error, and Claude will try to use the tool again with the missing information filled in:</p>
<div role="tabpanel"><pre><code data-lang="json" name="" tabindex="0">{
  "role": "user",
  "content": [
    {
      "type": "tool_result",
      "tool_use_id": "toolu_01A09q90qw90lq917835lq9",
      "content": "Error: Missing required 'location' parameter",
      "is_error": true
    }
  ]
}
</code></pre></div>
<hr>

<p>When using tools, Claude will often show its "chain of thought", i.e. the step-by-step reasoning it uses to break down the problem and decide which tools to use. The Claude 3 Opus model will always do this, and Sonnet and Haiku can be prompted into doing it.</p>
<p>For example, given the prompt "What's the weather like in San Francisco right now, and what time is it there?", Claude might respond with:</p>
<div role="tabpanel"><pre><code data-lang="json" name="" tabindex="0">{
  "role": "assistant",
  "content": [
    {
      "type": "text",
      "text": "&lt;thinking&gt;To answer this question, I will: 1. Use the get_weather tool to get the current weather in San Francisco. 2. Use the get_time tool to get the current time in the America/Los_Angeles timezone, which covers San Francisco, CA.&lt;/thinking&gt;"
    },
    {
      "type": "tool_use",
      "id": "toolu_01A09q90qw90lq917835lq9",
      "name": "get_weather",
      "input": {"location": "San Francisco, CA"}
    }
  ]
}
</code></pre></div>
<p>This chain of thought gives insight into Claude's reasoning process and can help you debug unexpected behavior. </p>
<p>With the Claude 3 Sonnet model, chain of thought is less common by default, but you can prompt Claude to show its reasoning by adding something like "Before answering, explain your reasoning step-by-step in <!-- --> tags." to the user message or system prompt. For a more in depth example, see <a target="_self" href="https://docs.anthropic.com/claude/docs/tool-use-examples#chain-of-thought-tool-use-example">chain of thought tool use example</a>.</p>
<p>It's important to note that while the <code data-lang="" name="" tabindex="0">&lt;thinking&gt;</code> tags are a common convention Claude uses to denote its chain of thought, the exact format (such as what this XML tag is named) may change over time. Your code should treat the chain of thought like any other assistant-generated text, and not rely on the presence or specific formatting of the <code data-lang="" name="" tabindex="0">&lt;thinking&gt;</code> tags.</p>
<hr>

<p>When using tools with Claude, keep the following limitations and best practices in mind:</p>
<ul>
<li>
<p><strong>Use Claude 3 Opus for navigating complex tool use, Haiku if dealing with straightforward tools</strong>: Opus is able to handle the most simultaneous tools and is better at catching missing arguments compared to other models. It is more likely to ask for clarification in ambiguous cases where an argument is not explicitly given or when a tool may not be necessary to complete the user request. Haiku defaults to trying to use tools more frequently (even if not relevant to the query) and will infer missing parameters if they are not explicitly given. </p>
</li>
<li>
<p><strong>Number of tools</strong>: All models can handle correcting choosing a tool from 250+ tools provided the user query contains all necessary parameters for the intended tool with &gt;90% accuracy.<br>
These limits apply to the total number of tools, regardless of complexity. A "complex" tool would be one with a large number of parameters or parameters with complex schemas (e.g. nested objects).</p>
</li>
<li>
<p><strong>Complex and deeply nested tools</strong>: Just like a human, Claude can work better with simpler interfaces and simpler tools. If Claude is struggling to correctly use your tool, try to flatten the input schema away from deeply nested json objects, and reduce the number of inputs.</p>
</li>
<li>
<p><strong>Sequential tool use</strong>: Claude generally prefers to use one tool at a time, then use the output of that tool to inform its next action. While you can prompt Claude to use multiple tools in parallel by carefully designing your prompt and tools, this may lead to Claude filling in dummy values for parameters that depend on the results of earlier tool use. For best results, design your workflow and tools to elicit and work with a series of sequential tool use from Claude.</p>
</li>
<li>
<p><strong>Retries</strong>: If Claude's tool use request is invalid or missing required parameters, you can return an error response and Claude will usually retry the request with the missing information filled in. However, after 2-3 failed attempts, Claude may give up and return an apology to the user instead of retrying further.</p>
</li>
<li>
<p><strong>Debugging</strong>: When debugging unexpected tool use behavior, pay attention to Claude's chain of thought output (if any) to understand why it's making the choices it's making. You can also try prompting Claude to use a specific tool to see if that leads to the expected behavior. If Claude is misusing a tool, double check that your tool descriptions and schemas are clear and unambiguous.</p>
</li>
<li>
<p><strong>&lt;search_quality_reflection&gt; tags</strong>: At times when using search tools, the model may return &lt;search_quality_reflection&gt; XML tags and a search quality score in its response. To stop the model from doing this, add the sentence "Do not reflect on the quality of the returned search results in your response." to the end of your prompt.</p>
</li>
</ul>
<p>By keeping these limitations and guidelines in mind, you can design effective tools and agentic orchestrations that significantly extend Claude's capabilities to tackle a wide variety of tasks.</p>
<hr>

<p>Tool use is a powerful technique for extending Claude's capabilities by connecting it to external data sources and functionality. With a well-designed set of tools, you can enable Claude to tackle a huge variety of tasks that would be impossible with its base knowledge alone.</p>
<p>Some potential next steps to explore:</p>
<ul>
<li><strong>Browse our tool use cookbooks</strong>: explore our repository of ready-to-implement tool use code examples, such as:
<ul>
<li><a target="_self" href="https://github.com/anthropics/anthropic-cookbook/blob/main/tool_use/calculator_tool.ipynb">Using a calculator tool with Claude</a> </li>
<li><a target="_self" href="https://github.com/anthropics/anthropic-cookbook/blob/main/tool_use/customer_service_agent.ipynb">Creating a customer service agent with client-side tools</a> </li>
<li><a target="_self" href="https://github.com/anthropics/anthropic-cookbook/blob/main/tool_use/extracting_structured_json.ipynb">Extracting structured JSON using Claude and tool use</a> </li>
</ul>
</li>
<li><strong>Improve tool use quality and reliability</strong>: Iterate and improve on your tool descriptions and prompts to elicit more reliable and accurate tool use from Claude </li>
<li><strong>Expand Claude's capabilities</strong>:
<ul>
<li>Experiment with different tools and schemas to see how Claude handles different types of input and output formats.</li>
<li>Chain multiple tools together to break down complex tasks into a series of simpler steps. </li>
<li>Build agentic orchestrations where Claude can complete a variety of tasks end to end as if it were an assistant.</li>
<li>Explore complex tool use architectures such as giving Claude tools to do RAG search, or to call on smaller model subagents, such as Haiku, to carry out tasks on its behalf</li>
</ul>
</li>
</ul>
<p>As you build with tool use, we'd love to hear your feedback and see what you create! Join our developer <a target="_self" href="https://anthropic.com/discord">Discord</a> to share your projects and discuss tips and techniques with other developers.</p>
<p>We're excited to see how you use tool use to push the boundaries of what's possible with Claude. Happy building!</p></div><p><i></i>Updated<!-- --> <!-- -->about 11 hours ago<!-- --> </p><hr></section><section><nav><ul><li><a href="#"><i></i>Table of Contents</a></li><li><ul>
<li>
<a href="#how-tool-use-works">How tool use works</a>
</li>
<li>
<a href="#specifying-tools">Specifying tools</a>
<ul>
<li><a href="#best-practices-for-tool-definitions">Best practices for tool definitions</a></li>
</ul>
</li>
<li>
<a href="#tool-use-and-tool-result-content-blocks">Tool use and tool result content blocks</a>
</li>
<li>
<a href="#forcing-tool-use">Forcing tool use</a>
</li>
<li>
<a href="#json-output">JSON output</a>
</li>
<li>
<a href="#error-handling">Error handling</a>
</li>
<li>
<a href="#chain-of-thought-tool-use">Chain of thought tool use</a>
</li>
<li>
<a href="#tool-use-best-practices-and-limitations">Tool use best practices and limitations</a>
</li>
<li>
<a href="#next-steps">Next steps</a>
</li>
</ul></li></ul></nav></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Roku files patent to inject ads via HDMI (109 pts)]]></title>
            <link>https://patents.google.com/patent/US20230388589A1/en</link>
            <guid>39936016</guid>
            <pubDate>Thu, 04 Apr 2024 21:31:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://patents.google.com/patent/US20230388589A1/en">https://patents.google.com/patent/US20230388589A1/en</a>, See on <a href="https://news.ycombinator.com/item?id=39936016">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
      

      <article itemscope="" itemtype="http://schema.org/ScholarlyArticle">
  <h2 itemprop="pageTitle">US20230388589A1 - Hdmi customized ad insertion 
      - Google Patents</h2>
  <span itemprop="title">Hdmi customized ad insertion 
     </span>

  <meta itemprop="type" content="patent">
  <a href="https://patentimages.storage.googleapis.com/5d/74/0c/85594d53a6014d/US20230388589A1.pdf" itemprop="pdfLink">Download PDF</a>
  <h2>Info</h2>

  <dl>
    <dt>Publication number</dt>
    <dd itemprop="publicationNumber">US20230388589A1</dd>
    <meta itemprop="numberWithoutCodes" content="20230388589">
    <meta itemprop="kindCode" content="A1">
    <meta itemprop="publicationDescription" content="Patent application publication">
    <span>US20230388589A1</span>
    <span>US18/446,596</span>
    <span>US202318446596A</span>
    <span>US2023388589A1</span>
    <span>US 20230388589 A1</span>
    <span>US20230388589 A1</span>
    <span>US 20230388589A1</span>
    <span>  </span>
    <span> </span>
    <span> </span>
    <span>US 202318446596 A</span>
    <span>US202318446596 A</span>
    <span>US 202318446596A</span>
    <span>US 2023388589 A1</span>
    <span>US2023388589 A1</span>
    <span>US 2023388589A1</span>

    <dt>Authority</dt>
    <dd itemprop="countryCode">US</dd>
    <dd itemprop="countryName">United States</dd>

    <dt>Prior art keywords</dt>
    <dd itemprop="priorArtKeywords" repeat="">display device</dd>
    <dd itemprop="priorArtKeywords" repeat="">content</dd>
    <dd itemprop="priorArtKeywords" repeat="">video frame</dd>
    <dd itemprop="priorArtKeywords" repeat="">determining</dd>
    <dd itemprop="priorArtKeywords" repeat="">video</dd>

    <dt>Prior art date</dt>
    <dd><time itemprop="priorArtDate" datetime="2022-02-17">2022-02-17</time></dd>

    <dt>Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)</dt>
    <dd itemprop="legalStatusIfi" itemscope="">
      <span itemprop="status">Pending</span>
    </dd>
  </dl>

  <dt>Application number</dt>
  <dd itemprop="applicationNumber">US18/446,596</dd>

  

  

  <dt>Inventor</dt>
  <dd itemprop="inventor" repeat="">Purushottam NARAYANA</dd>
  <dd itemprop="inventor" repeat="">Andre Goddard Rosa</dd>

  <dt>Current Assignee (The listed assignees may be inaccurate. Google has not performed a legal analysis and makes no representation or warranty as to the accuracy of the list.)</dt>
  <dd itemprop="assigneeCurrent" repeat="">
    Roku Inc
  </dd>

  <dt>Original Assignee</dt>
  <dd itemprop="assigneeOriginal" repeat="">Roku Inc</dd>

  <dt>Priority date (The priority date is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the date listed.)</dt>
  <dd><time itemprop="priorityDate" datetime="2022-02-17">2022-02-17</time></dd>

  <dt>Filing date</dt>
  <dd><time itemprop="filingDate" datetime="2023-08-09">2023-08-09</time></dd>

  <dt>Publication date</dt>
  <dd><time itemprop="publicationDate" datetime="2023-11-30">2023-11-30</time></dd>

  
  <dd itemprop="events" itemscope="" repeat="">
    <time itemprop="date" datetime="2023-08-09">2023-08-09</time>
    <span itemprop="title">Application filed by Roku Inc</span>
    <span itemprop="type">filed</span>
    <span itemprop="critical" content="true" bool="">Critical</span>
    
    
    
    <span itemprop="assigneeSearch">Roku Inc</span>
  </dd>
  <dd itemprop="events" itemscope="" repeat="">
    <time itemprop="date" datetime="2023-08-09">2023-08-09</time>
    <span itemprop="title">Priority to US18/446,596</span>
    <span itemprop="type">priority</span>
    <span itemprop="critical" content="true" bool="">Critical</span>
    
    
    <span itemprop="documentId">patent/US20230388589A1/en</span>
    
  </dd>
  <dd itemprop="events" itemscope="" repeat="">
    <time itemprop="date" datetime="2023-11-28">2023-11-28</time>
    <span itemprop="title">Assigned to ROKU, INC.</span>
    <span itemprop="type">reassignment</span>
    
    
    
    
    <span itemprop="assigneeSearch">ROKU, INC.</span>
    <span itemprop="description" repeat="">ASSIGNMENT OF ASSIGNORS INTEREST (SEE DOCUMENT FOR DETAILS).</span>
    <span itemprop="description" repeat="">Assignors: NARAYANA, PURUSHOTTAM, GODDARD ROSA, ANDRE</span>
  </dd>
  <dd itemprop="events" itemscope="" repeat="">
    <time itemprop="date" datetime="2023-11-30">2023-11-30</time>
    <span itemprop="title">Publication of US20230388589A1</span>
    <span itemprop="type">publication</span>
    <span itemprop="critical" content="true" bool="">Critical</span>
    
    
    <span itemprop="documentId">patent/US20230388589A1/en</span>
    
  </dd>
  <dd itemprop="events" itemscope="" repeat="">
    <time itemprop="date">Status</time>
    <span itemprop="title">Pending</span>
    <span itemprop="type">legal-status</span>
    <span itemprop="critical" content="true" bool="">Critical</span>
    <span itemprop="current" content="true" bool="">Current</span>
    
    
    
  </dd>

  <h2>Links</h2>
  <ul>
    <li itemprop="links" itemscope="" repeat="">
          <meta itemprop="id" content="usptoLink">
          <a href="https://appft.uspto.gov/netacgi/nph-Parser?Sect1=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=/netahtml/PTO/srchnum.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PG01&amp;s1=20230388589.PGNR." itemprop="url" target="_blank"><span itemprop="text">USPTO</span></a>
        </li>
        
        <li itemprop="links" itemscope="" repeat="">
          <meta itemprop="id" content="usptoPatentCenterLink">
          <a href="https://patentcenter.uspto.gov/applications/18446596" itemprop="url" target="_blank"><span itemprop="text">USPTO PatentCenter</span></a>
        </li>
        <li itemprop="links" itemscope="" repeat="">
          <meta itemprop="id" content="usptoAssignmentLink">
          <a href="https://assignment.uspto.gov/patent/index.html#/patent/search/resultFilter?searchInput=20230388589" itemprop="url" target="_blank"><span itemprop="text">USPTO Assignment</span></a>
        </li>

    <li itemprop="links" itemscope="" repeat="">
        <meta itemprop="id" content="espacenetLink">
        <a href="https://worldwide.espacenet.com/publicationDetails/biblio?CC=US&amp;NR=2023388589A1&amp;KC=A1&amp;FT=D" itemprop="url" target="_blank"><span itemprop="text">Espacenet</span></a>
      </li>
      

    

    
      <li itemprop="links" itemscope="" repeat="">
        <meta itemprop="id" content="globalDossierLink">
        <a href="https://globaldossier.uspto.gov/#/result/publication/US/20230388589/1" itemprop="url" target="_blank"><span itemprop="text">Global Dossier</span></a>
      </li>

      

      

      

      <li itemprop="links" itemscope="" repeat="">
        <meta itemprop="id" content="stackexchangeLink">
        <a href="https://patents.stackexchange.com/questions/tagged/US20230388589" itemprop="url"><span itemprop="text">Discuss</span></a>
      </li>
      
  </ul>

  <ul itemprop="concept" itemscope="">
    <li itemprop="match" itemscope="" repeat="">
      <span itemprop="id">238000003780</span>
      <span itemprop="name">insertion</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat="">title</span>
      <span itemprop="sections" repeat="">abstract</span>
      <span itemprop="sections" repeat="">description</span>
      <span itemprop="count">37</span>
    </li>
    <li itemprop="match" itemscope="" repeat="">
      <span itemprop="id">230000037431</span>
      <span itemprop="name">insertion</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat="">title</span>
      <span itemprop="sections" repeat="">abstract</span>
      <span itemprop="sections" repeat="">description</span>
      <span itemprop="count">37</span>
    </li>
    <li itemprop="match" itemscope="" repeat="">
      <span itemprop="id">238000000034</span>
      <span itemprop="name">method</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat="">claims</span>
      <span itemprop="sections" repeat="">abstract</span>
      <span itemprop="sections" repeat="">description</span>
      <span itemprop="count">39</span>
    </li>
    <li itemprop="match" itemscope="" repeat="">
      <span itemprop="id">230000005236</span>
      <span itemprop="name">sound signal</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat="">claims</span>
      <span itemprop="sections" repeat="">description</span>
      <span itemprop="count">24</span>
    </li>
    <li itemprop="match" itemscope="" repeat="">
      <span itemprop="id">238000005516</span>
      <span itemprop="name">engineering process</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat="">claims</span>
      <span itemprop="sections" repeat="">description</span>
      <span itemprop="count">6</span>
    </li>
    <li itemprop="match" itemscope="" repeat="">
      <span itemprop="id">238000002156</span>
      <span itemprop="name">mixing</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat="">claims</span>
      <span itemprop="sections" repeat="">description</span>
      <span itemprop="count">3</span>
    </li>
    <li itemprop="match" itemscope="" repeat="">
      <span itemprop="id">238000004519</span>
      <span itemprop="name">manufacturing process</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat="">abstract</span>
      <span itemprop="sections" repeat="">description</span>
      <span itemprop="count">7</span>
    </li>
    <li itemprop="match" itemscope="" repeat="">
      <span itemprop="id">238000004590</span>
      <span itemprop="name">computer program</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat="">abstract</span>
      <span itemprop="sections" repeat="">description</span>
      <span itemprop="count">5</span>
    </li>
    <li itemprop="match" itemscope="" repeat="">
      <span itemprop="id">230000006870</span>
      <span itemprop="name">function</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat="">description</span>
      <span itemprop="count">89</span>
    </li>
    <li itemprop="match" itemscope="" repeat="">
      <span itemprop="id">238000012545</span>
      <span itemprop="name">processing</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat="">description</span>
      <span itemprop="count">32</span>
    </li>
    <li itemprop="match" itemscope="" repeat="">
      <span itemprop="id">238000010586</span>
      <span itemprop="name">diagram</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat="">description</span>
      <span itemprop="count">16</span>
    </li>
    <li itemprop="match" itemscope="" repeat="">
      <span itemprop="id">238000001514</span>
      <span itemprop="name">detection method</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat="">description</span>
      <span itemprop="count">13</span>
    </li>
    <li itemprop="match" itemscope="" repeat="">
      <span itemprop="id">238000004891</span>
      <span itemprop="name">communication</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat="">description</span>
      <span itemprop="count">12</span>
    </li>
    <li itemprop="match" itemscope="" repeat="">
      <span itemprop="id">239000000872</span>
      <span itemprop="name">buffer</span>
      <span itemprop="domain">Substances</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat="">description</span>
      <span itemprop="count">8</span>
    </li>
    <li itemprop="match" itemscope="" repeat="">
      <span itemprop="id">230000008859</span>
      <span itemprop="name">change</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat="">description</span>
      <span itemprop="count">8</span>
    </li>
    <li itemprop="match" itemscope="" repeat="">
      <span itemprop="id">230000001755</span>
      <span itemprop="name">vocal effect</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat="">description</span>
      <span itemprop="count">6</span>
    </li>
    <li itemprop="match" itemscope="" repeat="">
      <span itemprop="id">230000002452</span>
      <span itemprop="name">interceptive effect</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat="">description</span>
      <span itemprop="count">4</span>
    </li>
    <li itemprop="match" itemscope="" repeat="">
      <span itemprop="id">230000008569</span>
      <span itemprop="name">process</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat="">description</span>
      <span itemprop="count">4</span>
    </li>
    <li itemprop="match" itemscope="" repeat="">
      <span itemprop="id">230000003068</span>
      <span itemprop="name">static effect</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat="">description</span>
      <span itemprop="count">4</span>
    </li>
    <li itemprop="match" itemscope="" repeat="">
      <span itemprop="id">238000013459</span>
      <span itemprop="name">approach</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat="">description</span>
      <span itemprop="count">3</span>
    </li>
    <li itemprop="match" itemscope="" repeat="">
      <span itemprop="id">235000019993</span>
      <span itemprop="name">champagne</span>
      <span itemprop="domain">Nutrition</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat="">description</span>
      <span itemprop="count">3</span>
    </li>
    <li itemprop="match" itemscope="" repeat="">
      <span itemprop="id">238000004458</span>
      <span itemprop="name">analytical method</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat="">description</span>
      <span itemprop="count">2</span>
    </li>
    <li itemprop="match" itemscope="" repeat="">
      <span itemprop="id">230000001413</span>
      <span itemprop="name">cellular effect</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat="">description</span>
      <span itemprop="count">2</span>
    </li>
    <li itemprop="match" itemscope="" repeat="">
      <span itemprop="id">230000007246</span>
      <span itemprop="name">mechanism</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat="">description</span>
      <span itemprop="count">2</span>
    </li>
    <li itemprop="match" itemscope="" repeat="">
      <span itemprop="id">230000003287</span>
      <span itemprop="name">optical effect</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat="">description</span>
      <span itemprop="count">2</span>
    </li>
    <li itemprop="match" itemscope="" repeat="">
      <span itemprop="id">230000000737</span>
      <span itemprop="name">periodic effect</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat="">description</span>
      <span itemprop="count">2</span>
    </li>
    <li itemprop="match" itemscope="" repeat="">
      <span itemprop="id">230000004044</span>
      <span itemprop="name">response</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat="">description</span>
      <span itemprop="count">2</span>
    </li>
    <li itemprop="match" itemscope="" repeat="">
      <span itemprop="id">238000005070</span>
      <span itemprop="name">sampling</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat="">description</span>
      <span itemprop="count">2</span>
    </li>
    <li itemprop="match" itemscope="" repeat="">
      <span itemprop="id">241000272194</span>
      <span itemprop="name">Ciconiiformes</span>
      <span itemprop="domain">Species</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat="">description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope="" repeat="">
      <span itemprop="id">101000969688</span>
      <span itemprop="name">Homo sapiens Macrophage-expressed gene 1 protein</span>
      <span itemprop="domain">Proteins</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat="">description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope="" repeat="">
      <span itemprop="id">102100021285</span>
      <span itemprop="name">Macrophage-expressed gene 1 protein</span>
      <span itemprop="domain">Human genes</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat="">description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope="" repeat="">
      <span itemprop="id">241000278713</span>
      <span itemprop="name">Theora</span>
      <span itemprop="domain">Species</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat="">description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope="" repeat="">
      <span itemprop="id">235000013405</span>
      <span itemprop="name">beer</span>
      <span itemprop="domain">Nutrition</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat="">description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope="" repeat="">
      <span itemprop="id">238000006243</span>
      <span itemprop="name">chemical reaction</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat="">description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope="" repeat="">
      <span itemprop="id">238000013500</span>
      <span itemprop="name">data storage</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat="">description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope="" repeat="">
      <span itemprop="id">239000011521</span>
      <span itemprop="name">glass</span>
      <span itemprop="domain">Substances</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat="">description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope="" repeat="">
      <span itemprop="id">238000012986</span>
      <span itemprop="name">modification</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat="">description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope="" repeat="">
      <span itemprop="id">230000004048</span>
      <span itemprop="name">modification</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat="">description</span>
      <span itemprop="count">1</span>
    </li>
    <li itemprop="match" itemscope="" repeat="">
      <span itemprop="id">238000012805</span>
      <span itemprop="name">post-processing</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0.000</span>
      <span itemprop="sections" repeat="">description</span>
      <span itemprop="count">1</span>
    </li>
  </ul>

  <section>
    <h2>Images</h2>
    
  </section>

  <section>
    <h2>Classifications</h2>
    <ul>
      <li>
        <ul itemprop="classifications" itemscope="" repeat="">
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H</span>—<span itemprop="Description">ELECTRICITY</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H04</span>—<span itemprop="Description">ELECTRIC COMMUNICATION TECHNIQUE</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H04N</span>—<span itemprop="Description">PICTORIAL COMMUNICATION, e.g. TELEVISION</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H04N21/00</span>—<span itemprop="Description">Selective content distribution, e.g. interactive television or video on demand [VOD]</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H04N21/40</span>—<span itemprop="Description">Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H04N21/45</span>—<span itemprop="Description">Management operations performed by the client for facilitating the reception of or the interaction with the content or administrating data related to the end-user or to the client device itself, e.g. learning user preferences for recommending movies, resolving scheduling conflicts</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H04N21/458</span>—<span itemprop="Description">Scheduling content for creating a personalised stream, e.g. by combining a locally stored advertisement with an incoming stream; Updating operations, e.g. for OS modules ; time-related management operations</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="FirstCode" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope="" repeat="">
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">G</span>—<span itemprop="Description">PHYSICS</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">G06</span>—<span itemprop="Description">COMPUTING; CALCULATING OR COUNTING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">G06V</span>—<span itemprop="Description">IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">G06V20/00</span>—<span itemprop="Description">Scenes; Scene-specific elements</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">G06V20/40</span>—<span itemprop="Description">Scenes; Scene-specific elements in video content</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">G06V20/44</span>—<span itemprop="Description">Event detection</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope="" repeat="">
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">G</span>—<span itemprop="Description">PHYSICS</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">G06</span>—<span itemprop="Description">COMPUTING; CALCULATING OR COUNTING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">G06V</span>—<span itemprop="Description">IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">G06V20/00</span>—<span itemprop="Description">Scenes; Scene-specific elements</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">G06V20/40</span>—<span itemprop="Description">Scenes; Scene-specific elements in video content</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">G06V20/48</span>—<span itemprop="Description">Matching video sequences</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope="" repeat="">
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H</span>—<span itemprop="Description">ELECTRICITY</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H04</span>—<span itemprop="Description">ELECTRIC COMMUNICATION TECHNIQUE</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H04N</span>—<span itemprop="Description">PICTORIAL COMMUNICATION, e.g. TELEVISION</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H04N21/00</span>—<span itemprop="Description">Selective content distribution, e.g. interactive television or video on demand [VOD]</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H04N21/40</span>—<span itemprop="Description">Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H04N21/43</span>—<span itemprop="Description">Processing of content or additional data, e.g. demultiplexing additional data from a digital video stream; Elementary client operations, e.g. monitoring of home network or synchronising decoder's clock; Client middleware</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H04N21/431</span>—<span itemprop="Description">Generation of visual interfaces for content selection or interaction; Content or additional data rendering</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H04N21/4312</span>—<span itemprop="Description">Generation of visual interfaces for content selection or interaction; Content or additional data rendering involving specific graphical features, e.g. screen layout, special fonts or colors, blinking icons, highlights or animations</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope="" repeat="">
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H</span>—<span itemprop="Description">ELECTRICITY</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H04</span>—<span itemprop="Description">ELECTRIC COMMUNICATION TECHNIQUE</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H04N</span>—<span itemprop="Description">PICTORIAL COMMUNICATION, e.g. TELEVISION</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H04N21/00</span>—<span itemprop="Description">Selective content distribution, e.g. interactive television or video on demand [VOD]</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H04N21/40</span>—<span itemprop="Description">Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H04N21/43</span>—<span itemprop="Description">Processing of content or additional data, e.g. demultiplexing additional data from a digital video stream; Elementary client operations, e.g. monitoring of home network or synchronising decoder's clock; Client middleware</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H04N21/433</span>—<span itemprop="Description">Content storage operation, e.g. storage operation in response to a pause request, caching operations</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H04N21/4333</span>—<span itemprop="Description">Processing operations in response to a pause request</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope="" repeat="">
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H</span>—<span itemprop="Description">ELECTRICITY</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H04</span>—<span itemprop="Description">ELECTRIC COMMUNICATION TECHNIQUE</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H04N</span>—<span itemprop="Description">PICTORIAL COMMUNICATION, e.g. TELEVISION</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H04N21/00</span>—<span itemprop="Description">Selective content distribution, e.g. interactive television or video on demand [VOD]</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H04N21/40</span>—<span itemprop="Description">Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H04N21/43</span>—<span itemprop="Description">Processing of content or additional data, e.g. demultiplexing additional data from a digital video stream; Elementary client operations, e.g. monitoring of home network or synchronising decoder's clock; Client middleware</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H04N21/436</span>—<span itemprop="Description">Interfacing a local distribution network, e.g. communicating with another STB or one or more peripheral devices inside the home</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H04N21/4363</span>—<span itemprop="Description">Adapting the video or multiplex stream to a specific local network, e.g. a IEEE 1394 or Bluetooth® network</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H04N21/43632</span>—<span itemprop="Description">Adapting the video or multiplex stream to a specific local network, e.g. a IEEE 1394 or Bluetooth® network involving a wired protocol, e.g. IEEE 1394</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H04N21/43635</span>—<span itemprop="Description">HDMI</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope="" repeat="">
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H</span>—<span itemprop="Description">ELECTRICITY</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H04</span>—<span itemprop="Description">ELECTRIC COMMUNICATION TECHNIQUE</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H04N</span>—<span itemprop="Description">PICTORIAL COMMUNICATION, e.g. TELEVISION</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H04N21/00</span>—<span itemprop="Description">Selective content distribution, e.g. interactive television or video on demand [VOD]</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H04N21/40</span>—<span itemprop="Description">Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H04N21/43</span>—<span itemprop="Description">Processing of content or additional data, e.g. demultiplexing additional data from a digital video stream; Elementary client operations, e.g. monitoring of home network or synchronising decoder's clock; Client middleware</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H04N21/44</span>—<span itemprop="Description">Processing of video elementary streams, e.g. splicing a video clip retrieved from local storage with an incoming video stream, rendering scenes according to MPEG-4 scene graphs</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H04N21/44008</span>—<span itemprop="Description">Processing of video elementary streams, e.g. splicing a video clip retrieved from local storage with an incoming video stream, rendering scenes according to MPEG-4 scene graphs involving operations for analysing video streams, e.g. detecting features or characteristics in the video stream</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope="" repeat="">
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H</span>—<span itemprop="Description">ELECTRICITY</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H04</span>—<span itemprop="Description">ELECTRIC COMMUNICATION TECHNIQUE</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H04N</span>—<span itemprop="Description">PICTORIAL COMMUNICATION, e.g. TELEVISION</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H04N21/00</span>—<span itemprop="Description">Selective content distribution, e.g. interactive television or video on demand [VOD]</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H04N21/40</span>—<span itemprop="Description">Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H04N21/43</span>—<span itemprop="Description">Processing of content or additional data, e.g. demultiplexing additional data from a digital video stream; Elementary client operations, e.g. monitoring of home network or synchronising decoder's clock; Client middleware</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H04N21/44</span>—<span itemprop="Description">Processing of video elementary streams, e.g. splicing a video clip retrieved from local storage with an incoming video stream, rendering scenes according to MPEG-4 scene graphs</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H04N21/44016</span>—<span itemprop="Description">Processing of video elementary streams, e.g. splicing a video clip retrieved from local storage with an incoming video stream, rendering scenes according to MPEG-4 scene graphs involving splicing one content stream with another content stream, e.g. for substituting a video clip</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope="" repeat="">
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H</span>—<span itemprop="Description">ELECTRICITY</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H04</span>—<span itemprop="Description">ELECTRIC COMMUNICATION TECHNIQUE</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H04N</span>—<span itemprop="Description">PICTORIAL COMMUNICATION, e.g. TELEVISION</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H04N21/00</span>—<span itemprop="Description">Selective content distribution, e.g. interactive television or video on demand [VOD]</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H04N21/40</span>—<span itemprop="Description">Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H04N21/47</span>—<span itemprop="Description">End-user applications</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H04N21/472</span>—<span itemprop="Description">End-user interface for requesting content, additional data or services; End-user interface for interacting with content, e.g. for content reservation or setting reminders, for requesting event notification, for manipulating displayed content</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H04N21/47217</span>—<span itemprop="Description">End-user interface for requesting content, additional data or services; End-user interface for interacting with content, e.g. for content reservation or setting reminders, for requesting event notification, for manipulating displayed content for controlling playback functions for recorded or on-demand content, e.g. using progress bars, mode or play-point indicators or bookmarks</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope="" repeat="">
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H</span>—<span itemprop="Description">ELECTRICITY</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H04</span>—<span itemprop="Description">ELECTRIC COMMUNICATION TECHNIQUE</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H04N</span>—<span itemprop="Description">PICTORIAL COMMUNICATION, e.g. TELEVISION</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H04N21/00</span>—<span itemprop="Description">Selective content distribution, e.g. interactive television or video on demand [VOD]</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H04N21/80</span>—<span itemprop="Description">Generation or processing of content or additional data by content creator independently of the distribution process; Content per se</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H04N21/81</span>—<span itemprop="Description">Monomedia components thereof</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">H04N21/812</span>—<span itemprop="Description">Monomedia components thereof involving advertisement data</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
      <li>
        <ul itemprop="classifications" itemscope="" repeat="">
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">G</span>—<span itemprop="Description">PHYSICS</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">G06</span>—<span itemprop="Description">COMPUTING; CALCULATING OR COUNTING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">G06V</span>—<span itemprop="Description">IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">G06V2201/00</span>—<span itemprop="Description">Indexing scheme relating to image or video recognition or understanding</span>
            <meta itemprop="IsCPC" content="true">
          </li>
          <li itemprop="classifications" itemscope="" repeat="">
            <span itemprop="Code">G06V2201/10</span>—<span itemprop="Description">Recognition assisted with metadata</span>
            <meta itemprop="Leaf" content="true"><meta itemprop="Additional" content="true"><meta itemprop="IsCPC" content="true">
          </li>
        </ul>
      </li>
    </ul>
  </section>

  

  

  <section>
    <h2>Definitions</h2>
    <ul>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">This disclosure</span>
        <span itemprop="definition">is generally directed to inserting ads for display and more particularly to inserting customized ads for display based on paused media content.</span>
        <meta itemprop="num_attr" content="0002">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Content</span>
        <span itemprop="definition">such as a movie or TV show</span>
        <meta itemprop="num_attr" content="0003">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">a user's experience of the content</span>
        <span itemprop="definition">is typically confined to the TV and to speakers connected to the TV.</span>
        <meta itemprop="num_attr" content="0003">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">a user</span>
        <span itemprop="definition">can control the consumption of media services by selecting media content for streaming, playing, pausing, and unpausing streaming media content.</span>
        <meta itemprop="num_attr" content="0003">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">An example embodiment</span>
        <span itemprop="definition">operates by detecting a pause event in one or more frames (e.g., audio or video frames) received via a HDMI connection, and during the pause event, recognizing content within the one or more frames.</span>
        <meta itemprop="num_attr" content="0004">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Some embodiments</span>
        <span itemprop="definition">include receiving a control signal via the HDMI connection and determining information about the source device, and/or information about the application running on the source device.</span>
        <meta itemprop="num_attr" content="0004">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Some embodiments</span>
        <span itemprop="definition">include determining an ad based on i) the content within the one or more frames, and/or ii) information about the source device and/or information about the application running on the source device. The ad can be displayed on the display device.</span>
        <meta itemprop="num_attr" content="0004">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Some embodiments</span>
        <span itemprop="definition">include a display device detecting a pause event in one or more frames received via an HDMI connection, and during the pause event, recognizing content within the one or more frames. Some embodiments include determining an ad based on the content within the one or more frames, and presenting the ad on the display device.</span>
        <meta itemprop="num_attr" content="0005">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Detecting the pause event</span>
        <span itemprop="definition">can include: i) receiving a remote control pass through pause signal; ii) detecting a silent audio signal via the HDMI connection, and determining that a video frame of the one or more frames has not changed; and/or iii) detecting a pause icon from the one or more frames using computer vision (CV) technology, and detecting no change from a first video frame to a second video frame, where the first video frame and the second video frame are of the one or more frames.</span>
        <meta itemprop="num_attr" content="0005">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">CV</span>
        <span itemprop="definition">computer vision</span>
        <meta itemprop="num_attr" content="0005">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">recognizing the content</span>
        <span itemprop="definition">includes analyzing a first video frame or a first audio frame of the one or more frames using automatic content recognition (ACR) technology, and determining a fingerprint, a watermark, or a cue tone corresponding to the first video frame or the first audio frame, where the fingerprint, watermark, and/or cue tone is used to identify information about content corresponding to the first video frame or the first audio frame.</span>
        <meta itemprop="num_attr" content="0006">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">ACR</span>
        <span itemprop="definition">automatic content recognition</span>
        <meta itemprop="num_attr" content="0006">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">recognizing the content</span>
        <span itemprop="definition">includes analyzing a first video frame of the one or more frames using CV technology, and determining metadata corresponding to the first video frame, where the metadata is used to identify one or more objects corresponding to the first video frame.</span>
        <meta itemprop="num_attr" content="0006">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Some embodiments</span>
        <span itemprop="definition">include receiving a control signal via the HDMI connection and determining service product description (SPD) from the control signal, where the ad is determined based on the SPD. Some embodiments further include detecting an auto low latency mode (ALLM) from the control signal, where the ad is based on the ALLM. Some embodiments further include detecting a variable refresh rate (VRR) from the control signal, where the ad is based on the VRR.</span>
        <meta itemprop="num_attr" content="0007">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">SPD</span>
        <span itemprop="definition">service product description</span>
        <meta itemprop="num_attr" content="0007">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">ALLM</span>
        <span itemprop="definition">auto low latency mode</span>
        <meta itemprop="num_attr" content="0007">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">VRR</span>
        <span itemprop="definition">variable refresh rate</span>
        <meta itemprop="num_attr" content="0007">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">determining the ad</span>
        <span itemprop="definition">includes transmitting the VRR to a network, and receiving the ad corresponding to the VRR from the network. In some examples, determining the ad includes transmitting a fingerprint, watermark, cue tone, or metadata corresponding to the content to a network, and receiving a corresponding ad from the network.</span>
        <meta itemprop="num_attr" content="0008">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Some embodiments</span>
        <span itemprop="definition">include transmitting an SPD or an ALLM corresponding to a control signal received via the HDMI connection, to a network, and receiving an ad corresponding to the SPD or the ALLM from the network. Some embodiments include presenting the ad on a graphics plane of the display device, blending the graphics plane with a video plane comprising a first video frame of the one or more frames, and presenting the blended planes on the display device.</span>
        <meta itemprop="num_attr" content="0009">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">FIG. 1</span>
        <span itemprop="definition">illustrates a block diagram of a multimedia environment, according to some embodiments.</span>
        <meta itemprop="num_attr" content="0012">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">FIG. 2</span>
        <span itemprop="definition">illustrates a block diagram of a streaming media device, according to some embodiments.</span>
        <meta itemprop="num_attr" content="0013">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">FIG. 3</span>
        <span itemprop="definition">illustrates a first block diagram of a display device, according to some embodiments.</span>
        <meta itemprop="num_attr" content="0014">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">FIG. 4</span>
        <span itemprop="definition">illustrates a method for a display device, according to some embodiments.</span>
        <meta itemprop="num_attr" content="0015">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">FIG. 5</span>
        <span itemprop="definition">illustrates an example computer system useful for implementing various embodiments.</span>
        <meta itemprop="num_attr" content="0016">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">FIG. 6</span>
        <span itemprop="definition">illustrates a block diagram of a second media device, according to some embodiments.</span>
        <meta itemprop="num_attr" content="0017">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">FIG. 7 A</span>
        <span itemprop="definition">illustrates a block diagram of a second display device, according to some embodiments.</span>
        <meta itemprop="num_attr" content="0018">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">FIG. 7 B</span>
        <span itemprop="definition">illustrates a block diagram of a third display device, according to some embodiments.</span>
        <meta itemprop="num_attr" content="0019">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">FIG. 8</span>
        <span itemprop="definition">illustrates a block diagram of a third media device, according to some embodiments.</span>
        <meta itemprop="num_attr" content="0020">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">FIG. 9</span>
        <span itemprop="definition">illustrates a block diagram of a fourth display device, according to some embodiments.</span>
        <meta itemprop="num_attr" content="0021">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">a display device</span>
        <span itemprop="definition">coupled via a high-definition media interface (HDMI) connection, to a media device where the media device provides media content.</span>
        <meta itemprop="num_attr" content="0023">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">HDMI</span>
        <span itemprop="definition">high-definition media interface</span>
        <meta itemprop="num_attr" content="0023">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the display device</span>
        <span itemprop="definition">can determine that a pause event has occurred and insert an ad shown on the display device.</span>
        <meta itemprop="num_attr" content="0023">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the detection of the pause event</span>
        <span itemprop="definition">can trigger the insertion of a relevant ad.</span>
        <meta itemprop="num_attr" content="0023">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">some embodiments</span>
        <span itemprop="definition">include determining the context and/or content of the media content that is paused, and selecting an ad that is customized to the determined context and/or content to be displayed on the display device.</span>
        <meta itemprop="num_attr" content="0023">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the display device</span>
        <span itemprop="definition">may be coupled via a media interface connection other than HDMI to a media device.</span>
        <meta itemprop="num_attr" content="0023">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">multimedia environment 102</span>
        <span itemprop="definition">may be implemented using and/or may be part of a multimedia environment 102 shown in FIG. 1 . It is noted, however, that multimedia environment 102 is provided solely for illustrative purposes, and is not limiting. Embodiments of this disclosure may be implemented using and/or may be part of environments different from and/or in addition to the multimedia environment 102 , as will be appreciated by persons skilled in the relevant art(s) based on the teachings contained herein. An example of the multimedia environment 102 shall now be described.</span>
        <meta itemprop="num_attr" content="0024">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">FIG. 1</span>
        <span itemprop="definition">illustrates a block diagram of a multimedia environment 102 , according to some embodiments.</span>
        <meta itemprop="num_attr" content="0025">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">multimedia environment 102</span>
        <span itemprop="definition">may be directed to streaming media.</span>
        <meta itemprop="num_attr" content="0025">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">this disclosure</span>
        <span itemprop="definition">is applicable to any type of media (instead of or in addition to streaming media), as well as any mechanism, means, protocol, method and/or process for distributing media.</span>
        <meta itemprop="num_attr" content="0025">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the multimedia environment 102</span>
        <span itemprop="definition">may include one or more media systems 104 .</span>
        <meta itemprop="num_attr" content="0026">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">a media system 104</span>
        <span itemprop="definition">could represent a family room, a kitchen, a backyard, a home theater, a school classroom, a library, a car, a boat, a bus, a plane, a movie theater, a stadium, an auditorium, a park, a bar, a restaurant, or any other location or space where it is desired to receive and play streaming content.</span>
        <meta itemprop="num_attr" content="0026">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">User(s) 132</span>
        <span itemprop="definition">may operate with the media system 104 to select and consume content.</span>
        <meta itemprop="num_attr" content="0026">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Each media system 104</span>
        <span itemprop="definition">may include one or more media devices 106 each coupled to one or more display devices 108 . It is noted that terms such as “coupled,” “connected to,” “attached,” “linked,” “combined” and similar terms may refer to physical, electrical, magnetic, logical, etc., connections, unless otherwise specified herein.</span>
        <meta itemprop="num_attr" content="0027">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Media device 106</span>
        <span itemprop="definition">may be a streaming media device, DVD or BLU-RAY device, audio/video playback device, cable box, and/or digital video recording device, to name just a few examples.</span>
        <meta itemprop="num_attr" content="0028">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Display device 108</span>
        <span itemprop="definition">may be a monitor, television (TV), computer, smart phone, tablet, wearable (such as a watch or glasses), appliance, internet of things (IoT) device, and/or projector, to name just a few examples.</span>
        <meta itemprop="num_attr" content="0028">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">media device 106</span>
        <span itemprop="definition">can be a part of, integrated with, operatively coupled to, and/or connected to its respective display device 108 .</span>
        <meta itemprop="num_attr" content="0028">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Each media device 106</span>
        <span itemprop="definition">may be configured to communicate with network 118 via a communication device 114 .</span>
        <meta itemprop="num_attr" content="0029">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the communication device 114</span>
        <span itemprop="definition">may include, for example, a cable modem or satellite TV transceiver.</span>
        <meta itemprop="num_attr" content="0029">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the media device 106</span>
        <span itemprop="definition">may communicate with the communication device 114 over a link 116 , wherein the link 116 may include wireless (such as WiFi) and/or wired connections.</span>
        <meta itemprop="num_attr" content="0029">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the network 118</span>
        <span itemprop="definition">can include, without limitation, wired and/or wireless intranet, extranet, Internet, cellular, Bluetooth, infrared, and/or any other short range, long range, local, regional, global communications mechanism, means, approach, protocol and/or network, as well as any combination(s) thereof.</span>
        <meta itemprop="num_attr" content="0030">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Media system 104</span>
        <span itemprop="definition">may include a remote control 110 .</span>
        <meta itemprop="num_attr" content="0031">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the remote control 110</span>
        <span itemprop="definition">can be any component, part, apparatus and/or method for controlling the media device 106 and/or display device 108 , such as a remote control, a tablet, laptop computer, smartphone, wearable, on-screen controls, integrated control buttons, audio controls, or any combination thereof, to name just a few examples.</span>
        <meta itemprop="num_attr" content="0031">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the remote control 110</span>
        <span itemprop="definition">wirelessly communicates with the media device 106 and/or display device 108 using cellular, Bluetooth, infrared, etc., or any combination thereof.</span>
        <meta itemprop="num_attr" content="0031">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the remote control 110</span>
        <span itemprop="definition">may include a microphone 112 , which is further described below.</span>
        <meta itemprop="num_attr" content="0031">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the multimedia environment 102</span>
        <span itemprop="definition">may include a plurality of content servers 120 (also called content providers, channels or sources). Although only one content server 120 is shown in FIG. 1 , in practice the multimedia environment 102 may include any number of content servers 120 . Each content server 120 may be configured to communicate with network 118 .</span>
        <meta itemprop="num_attr" content="0032">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Each content server 120</span>
        <span itemprop="definition">may store content 122 and metadata 124 .</span>
        <meta itemprop="num_attr" content="0033">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Content 122</span>
        <span itemprop="definition">may include any combination of music, videos, movies, TV programs, multimedia, images, still pictures, text, graphics, gaming applications, advertisements, programming content, public service content, government content, local community content, software, and/or any other content or data objects in electronic form.</span>
        <meta itemprop="num_attr" content="0033">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">metadata 124</span>
        <span itemprop="definition">comprises data about content 122 .</span>
        <meta itemprop="num_attr" content="0034">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">metadata 124</span>
        <span itemprop="definition">may include associated or ancillary information indicating or related to writer, director, producer, composer, artist, actor, summary, chapters, production, history, year, trailers, alternate versions, related content, applications, and/or any other information pertaining or relating to the content 122 .</span>
        <meta itemprop="num_attr" content="0034">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Metadata 124</span>
        <span itemprop="definition">may also or alternatively include links to any such information pertaining or relating to the content 122 .</span>
        <meta itemprop="num_attr" content="0034">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Metadata 124</span>
        <span itemprop="definition">may also or alternatively include one or more indexes of content 122 , such as but not limited to a trick mode index.</span>
        <meta itemprop="num_attr" content="0034">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the multimedia environment 102</span>
        <span itemprop="definition">may include one or more system servers 126 .</span>
        <meta itemprop="num_attr" content="0035">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the system servers 126</span>
        <span itemprop="definition">may operate to support the media devices 106 from the cloud. It is noted that the structural and functional aspects of the system servers 126 may wholly or partially exist in the same or different ones of the system servers 126 .</span>
        <meta itemprop="num_attr" content="0035">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the system servers 126</span>
        <span itemprop="definition">may also include an audio command processing module 130 .</span>
        <meta itemprop="num_attr" content="0036">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the remote control 110</span>
        <span itemprop="definition">may include a microphone 112 .</span>
        <meta itemprop="num_attr" content="0036">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the microphone 112</span>
        <span itemprop="definition">may receive audio data from users 132 (as well as other sources, such as the display device 108 ).</span>
        <meta itemprop="num_attr" content="0036">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the media device 106</span>
        <span itemprop="definition">may be audio responsive, and the audio data may represent verbal commands from the user 132 to control the media device 106 as well as other components in the media system 104 , such as the display device 108 .</span>
        <meta itemprop="num_attr" content="0036">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the audio data received by the microphone 112 in the remote control 110</span>
        <span itemprop="definition">is transferred to the media device 106 , which is then forwarded to the audio command processing module 130 in the system servers 126 .</span>
        <meta itemprop="num_attr" content="0036">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the audio command processing module 130</span>
        <span itemprop="definition">may operate to process and analyze the received audio data to recognize the user 132 's verbal command.</span>
        <meta itemprop="num_attr" content="0036">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the audio command processing module 130</span>
        <span itemprop="definition">may then forward the verbal command back to the media device 106 for processing.</span>
        <meta itemprop="num_attr" content="0036">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the audio data</span>
        <span itemprop="definition">may be alternatively or additionally processed and analyzed by an audio command processing module 216 in the media device 106 (see FIG. 2 ).</span>
        <meta itemprop="num_attr" content="0037">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the media device 106 and the system servers 126</span>
        <span itemprop="definition">may then cooperate to pick one of the verbal commands to process (either the verbal command recognized by the audio command processing module 130 in the system servers 126 , or the verbal command recognized by the audio command processing module 216 in the media device 106 ).</span>
        <meta itemprop="num_attr" content="0037">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">FIG. 2</span>
        <span itemprop="definition">illustrates a block diagram of an example media device 106 , according to some embodiments.</span>
        <meta itemprop="num_attr" content="0038">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Media device 106</span>
        <span itemprop="definition">may include a streaming module 202 , processing module 204 , storage/buffers 208 , and user interface module 206 .</span>
        <meta itemprop="num_attr" content="0038">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the user interface module 206</span>
        <span itemprop="definition">may include the audio command processing module 216 .</span>
        <meta itemprop="num_attr" content="0038">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the media device 106</span>
        <span itemprop="definition">may also include one or more audio decoders 212 and one or more video decoders 214 .</span>
        <meta itemprop="num_attr" content="0039">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Each audio decoder 212</span>
        <span itemprop="definition">may be configured to decode audio of one or more audio formats, such as but not limited to AAC, HE-AAC, AC3 (Dolby Digital), EAC3 (Dolby Digital Plus), WMA, WAV, PCM, MP3, OGG GSM, FLAC, AU, AIFF, and/or VOX, to name just some examples.</span>
        <meta itemprop="num_attr" content="0040">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">each video decoder 214</span>
        <span itemprop="definition">may be configured to decode video of one or more video formats, such as but not limited to MP4 (mp4, m4a, m4v, f4v, f4a, m4b, m4r, f4b, mov), 3GP (3gp, 3gp2, 3g2, 3gpp, 3gpp2), OGG (ogg, oga, ogv, ogx), WMV (wmv, wma, asf), WEBM, FLV, AVI, QuickTime, HDV, MXF (OPla, OP-Atom), MPEG-TS, MPEG-2 PS, MPEG-2 TS, WAV, Broadcast WAV, LXF, GXF, and/or VOB, to name just some examples.</span>
        <meta itemprop="num_attr" content="0041">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">MP4</span>
        <span itemprop="definition">mp4, m4a, m4v, f4v, f4a, m4b, m4r, f4b, mov</span>
        <meta itemprop="num_attr" content="0041">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">3GP</span>
        <span itemprop="definition">3gp, 3gp</span>
        <meta itemprop="num_attr" content="0041">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Each video decoder 214</span>
        <span itemprop="definition">may include one or more video codecs, such as but not limited to H.263, H.264, HEV, MPEG1, MPEG2, MPEG-TS, MPEG-4, Theora, 3GP, DV, DVCPRO, DVCPRO, DVCProHD, IMX, XDCAM HD, XDCAM HD422, and/or XDCAM EX, to name just some examples.</span>
        <meta itemprop="num_attr" content="0041">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">video codecs</span>
        <span itemprop="definition">such as but not limited to H.263, H.264, HEV, MPEG1, MPEG2, MPEG-TS, MPEG-4, Theora, 3GP, DV, DVCPRO, DVCPRO, DVCProHD, IMX, XDCAM HD, XDCAM HD422, and/or XDCAM EX, to name just some examples.</span>
        <meta itemprop="num_attr" content="0041">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the user 132</span>
        <span itemprop="definition">may interact with the media device 106 via, for example, the remote control 110 .</span>
        <meta itemprop="num_attr" content="0042">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the user 132</span>
        <span itemprop="definition">may use the remote control 110 to interact with the user interface module 206 of the media device 106 to select content, such as a movie, TV show, music, book, application, game, etc.</span>
        <meta itemprop="num_attr" content="0042">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the streaming module 202 of the media device 106</span>
        <span itemprop="definition">may request the selected content from the content server(s) 120 over the network 118 .</span>
        <meta itemprop="num_attr" content="0042">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the content server(s) 120</span>
        <span itemprop="definition">may transmit the requested content to the streaming module 202 .</span>
        <meta itemprop="num_attr" content="0042">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the media device 106</span>
        <span itemprop="definition">may transmit the received content to the display device 108 for playback to the user 132 .</span>
        <meta itemprop="num_attr" content="0042">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the streaming module 202</span>
        <span itemprop="definition">may transmit the content to the display device 108 in real time or near real time as it receives such content from the content server(s) 120 .</span>
        <meta itemprop="num_attr" content="0043">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the media device 106</span>
        <span itemprop="definition">may store the content received from content server(s) 120 in storage/buffers 208 for later playback on display device 108 .</span>
        <meta itemprop="num_attr" content="0043">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">media device 106</span>
        <span itemprop="definition">may be a streaming media device (e.g., a set top box or a gaming device) coupled to display device 108 via an HDMI connection 107 (e.g., an HDMI cable).</span>
        <meta itemprop="num_attr" content="0044">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">HDMI connection 107</span>
        <span itemprop="definition">e.g., an HDMI cable</span>
        <meta itemprop="num_attr" content="0044">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">user 132</span>
        <span itemprop="definition">may select HDMI as a source input for media streaming on display device 108 .</span>
        <meta itemprop="num_attr" content="0044">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">User 132</span>
        <span itemprop="definition">may use remote control 110 to communicate with media device 106 via radio interface 111 .</span>
        <meta itemprop="num_attr" content="0044">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">media device 106</span>
        <span itemprop="definition">e.g., a source device</span>
        <meta itemprop="num_attr" content="0044">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the corresponding video frames</span>
        <span itemprop="definition">may be paused (e.g., halted).</span>
        <meta itemprop="num_attr" content="0044">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">media device 106</span>
        <span itemprop="definition">may transmit a pause icon in a signal and the pause icon may be presented on display device 108 (e.g., a smart TV).</span>
        <meta itemprop="num_attr" content="0044">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">display device 108</span>
        <span itemprop="definition">did not detect a pause event. Consequently, display device 108 would not insert an ad during the pause event, or analyze the content and/or context of the paused media content to determine a customized ad, and display the customized ad on a graphics plane of display device 108 .</span>
        <meta itemprop="num_attr" content="0044">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">FIG. 6</span>
        <span itemprop="definition">illustrates a block diagram of media device 600 , according to some embodiments.</span>
        <meta itemprop="num_attr" content="0045">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">media device 600</span>
        <span itemprop="definition">may be described with reference to elements from other figures in the disclosure.</span>
        <meta itemprop="num_attr" content="0045">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">HDMI output 680</span>
        <span itemprop="definition">may support HDMI connection 107 of FIG. 1 , where HDMI connection 107 is coupled to display device 108 of FIG. 1 .</span>
        <meta itemprop="num_attr" content="0045">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">User interface module 620 and audio command processing module 625</span>
        <span itemprop="definition">can correspond to user interface module 206 and audio command processing module 216 of FIG. 2 .</span>
        <meta itemprop="num_attr" content="0045">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Processor 630</span>
        <span itemprop="definition">may correspond to processing module 204 of FIG. 2 .</span>
        <meta itemprop="num_attr" content="0045">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Buffers/storage 640 , audio decoder 660 , and video decoder 650</span>
        <span itemprop="definition">may correspond to storage/buffers 208 , audio decoder(s) 212 , and video decoder(s) 214 of FIG. 2 .</span>
        <meta itemprop="num_attr" content="0045">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Media device 600</span>
        <span itemprop="definition">includes applications 610 that can include streaming applications 612 , broadcast/tuner 614 , USB inputs 616 , and gaming application 618 .</span>
        <meta itemprop="num_attr" content="0046">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">media device 600</span>
        <span itemprop="definition">can be a gaming device.</span>
        <meta itemprop="num_attr" content="0046">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Applications 610</span>
        <span itemprop="definition">can be a source of information.</span>
        <meta itemprop="num_attr" content="0046">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Processor 630</span>
        <span itemprop="definition">can extract audio and video data from corresponding applications and place the extracted audio and video data into buffers/storage 640 .</span>
        <meta itemprop="num_attr" content="0046">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">post processing module 670</span>
        <span itemprop="definition">can perform scaling of images, color improvements, and lip synching functions, for example, before outputting video frames via HDMI output 680 to a display device (e.g., display device 108 of FIG. 1 , display device 108 of FIG. 3 , display device 700 of FIG. 7 A , display device 705 of FIG.</span>
        <meta itemprop="num_attr" content="0046">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">a display device</span>
        <span itemprop="definition">e.g., display device 108 of FIG. 1 , display device 108 of FIG. 3 , display device 700 of FIG. 7 A , display device 705 of FIG.</span>
        <meta itemprop="num_attr" content="0046">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">media device 600</span>
        <span itemprop="definition">transmits a service product description (SPD), auto low latency mode (ALLM), or a variable refresh rate (VRR) to display device 700 of FIG. 7 A , display device 705 of FIG. 7 B , or display device 900 of FIG. 9 .</span>
        <meta itemprop="num_attr" content="0046">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">SPD</span>
        <span itemprop="definition">service product description</span>
        <meta itemprop="num_attr" content="0046">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">ALLM</span>
        <span itemprop="definition">auto low latency mode</span>
        <meta itemprop="num_attr" content="0046">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">VRR</span>
        <span itemprop="definition">variable refresh rate</span>
        <meta itemprop="num_attr" content="0046">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">FIG. 8</span>
        <span itemprop="definition">illustrates a block diagram of media device 800 , according to some embodiments.</span>
        <meta itemprop="num_attr" content="0047">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">media device 800</span>
        <span itemprop="definition">may be described with reference to elements from other figures in the disclosure.</span>
        <meta itemprop="num_attr" content="0047">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">HDMI output 880 , processor 830 , buffers/storage 840 , audio decoder 860 , and video decoder 850 media device 800</span>
        <span itemprop="definition">may correspond to HDMI output 680 , processor 630 , buffers/storage 640 , audio decoder 660 , and video decoder 650 of media device 600 of FIG. 6 .</span>
        <meta itemprop="num_attr" content="0047">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Media device 800</span>
        <span itemprop="definition">includes applications 810 that may be a data source including but not limited to input application 816 , network application 814 , and media application 817 .</span>
        <meta itemprop="num_attr" content="0048">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Input application 816</span>
        <span itemprop="definition">can include but is not limited to input applications corresponding to a joystick, a microphone, and/or a remote control device.</span>
        <meta itemprop="num_attr" content="0048">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Network application 814</span>
        <span itemprop="definition">can include but is not limited to Wi-FiTM, BluetoothTM, ZigbeeTM, and/or a tuner.</span>
        <meta itemprop="num_attr" content="0048">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Media application 817</span>
        <span itemprop="definition">can include but is not limited to a transport stream, a movie, a game, and/or music.</span>
        <meta itemprop="num_attr" content="0048">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Processor 830</span>
        <span itemprop="definition">can extract audio and video data from corresponding applications and place the extracted audio and video data into buffers/storage 840 .</span>
        <meta itemprop="num_attr" content="0049">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">output video frames</span>
        <span itemprop="definition">are transmitted via HDMI output 880 to a display device (e.g., display device 108 of FIG. 1 , display device 108 of FIG. 3 , display device 700 of FIG. 7 A , display device 705 of FIG. 7 B , and/or display device 900 of FIG. 9 ).</span>
        <meta itemprop="num_attr" content="0049">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">media device 800</span>
        <span itemprop="definition">transmits an SPD, an ALLM, or a VRR to display device 700 , display device 705 of FIG. 7 B , or display device 900 of FIG. 9 .</span>
        <meta itemprop="num_attr" content="0049">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">FIG. 3</span>
        <span itemprop="definition">illustrates a block diagram of display device 108 , according to some embodiments.</span>
        <meta itemprop="num_attr" content="0050">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">display device 108</span>
        <span itemprop="definition">may be described with reference to elements from other figures in the disclosure.</span>
        <meta itemprop="num_attr" content="0050">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">HDMI module 310</span>
        <span itemprop="definition">may support HDMI connection 107 of FIG. 1 , where HDMI connection 107 is coupled to media device 106 of FIG. 1 or FIG. 2 .</span>
        <meta itemprop="num_attr" content="0050">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Display device 108</span>
        <span itemprop="definition">can include ACR module 320 , CV module 325 , ad insertion module 330 , processing module 340 , video scaling and frame rate conversion (FRC) module 350 , graphics module 360 , display module 370 , and memory 380 .</span>
        <meta itemprop="num_attr" content="0050">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Bus 390</span>
        <span itemprop="definition">can coupled the elements of display device 108 .</span>
        <meta itemprop="num_attr" content="0050">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">ACR module 320</span>
        <span itemprop="definition">can analyze a video frame and generate a unique fingerprint and/or unique watermark with information about the content of the video frame.</span>
        <meta itemprop="num_attr" content="0051">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the unique fingerprint and/or watermark</span>
        <span itemprop="definition">may include multiple patches of content within the video frame.</span>
        <meta itemprop="num_attr" content="0051">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the unique fingerprint and/or watermark</span>
        <span itemprop="definition">may be compared against a known reference fingerprint or reference watermark to identify the video content based on the match.</span>
        <meta itemprop="num_attr" content="0051">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the match</span>
        <span itemprop="definition">may identify for example, a movie title, actor, rating, where the movie can be found for viewing, production house, etc.</span>
        <meta itemprop="num_attr" content="0051">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the unique fingerprint and/or watermark</span>
        <span itemprop="definition">can correspond to content particular to the video frame itself.</span>
        <meta itemprop="num_attr" content="0051">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the fingerprints and/or watermark generated from different consecutive video frames</span>
        <span itemprop="definition">can be compared. If two or more generated fingerprints and/or watermarks are the same, that can indicate no change in content (e.g., the video or movie may be paused.)</span>
        <meta itemprop="num_attr" content="0051">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">ACR module 320</span>
        <span itemprop="definition">can analyze an audio frame and generate a unique fingerprint and/or unique watermark with information about the content of the audio frame.</span>
        <meta itemprop="num_attr" content="0052">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the unique fingerprint and/or watermark</span>
        <span itemprop="definition">may include multiple patches of content within the audio frame.</span>
        <meta itemprop="num_attr" content="0052">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the unique fingerprint and/or watermark</span>
        <span itemprop="definition">may be compared against a known reference fingerprint or reference watermark to identify the audio content based on the match.</span>
        <meta itemprop="num_attr" content="0052">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the match</span>
        <span itemprop="definition">may identify for example, a movie title, actor, rating, where the movie can be found for viewing, production house, etc.</span>
        <meta itemprop="num_attr" content="0052">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the unique fingerprint and/or watermark</span>
        <span itemprop="definition">can correspond to content particular to the audio frame itself.</span>
        <meta itemprop="num_attr" content="0052">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the fingerprints and/or watermark generated from different consecutive audio frames</span>
        <span itemprop="definition">can be compared. If two or more generated fingerprints and/or watermarks are the same, that can indicate no change in content (e.g., the audio or movie may be paused.)</span>
        <meta itemprop="num_attr" content="0052">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">ACR module 320</span>
        <span itemprop="definition">can analyze a video frame and/or an audio frame and generate a unique cue tone (e.g., a cue tone compliant with American National Standards Institute (ANSI)/Society of Cable and Telecommunications Engineers (SCTE) standards defined in ANSI/SCTE 35 2013) with information about the content of the video frame and/or audio frame.</span>
        <meta itemprop="num_attr" content="0053">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">a unique cue tone</span>
        <span itemprop="definition">e.g., a cue tone compliant with American National Standards Institute (ANSI)/Society of Cable and Telecommunications Engineers (SCTE) standards defined in ANSI/SCTE 35 2013</span>
        <meta itemprop="num_attr" content="0053">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">CV module 325</span>
        <span itemprop="definition">can analyze a video frame and generate metadata.</span>
        <meta itemprop="num_attr" content="0054">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the metadata</span>
        <span itemprop="definition">can be used to recognize objects within the video frame, or one or more video frames.</span>
        <meta itemprop="num_attr" content="0054">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the metadata</span>
        <span itemprop="definition">can for example, recognize images and/or objects within the video frame.</span>
        <meta itemprop="num_attr" content="0054">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Examples of the metadata</span>
        <span itemprop="definition">can include for example, items depicted in the video frame such as a bicycle, car, a beer bottle, a mountain, and/or scenery.</span>
        <meta itemprop="num_attr" content="0054">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Display device 108</span>
        <span itemprop="definition">can detect a pause event by using: i) a remote control pass through function; ii) a silent audio signal; and/or iii) pause icon recognition.</span>
        <meta itemprop="num_attr" content="0055">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">display device 108</span>
        <span itemprop="definition">may use a remote control pass through function to detect a pause event.</span>
        <meta itemprop="num_attr" content="0056">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">media device 106</span>
        <span itemprop="definition">may be configured to support Consumer Electronics Control (CEC) (e.g., remote control pass through) functions including but not limited to: power on, power off, pause key, play key, and so on.</span>
        <meta itemprop="num_attr" content="0056">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">CEC</span>
        <span itemprop="definition">Consumer Electronics Control</span>
        <meta itemprop="num_attr" content="0056">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">user 132 using remote control 110</span>
        <span itemprop="definition">can transmit a pause key via radio interface 111 to the media device which transmits the pause key signal to display device 108 .</span>
        <meta itemprop="num_attr" content="0056">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">display device 108</span>
        <span itemprop="definition">can readily detect a pause event based on the pause key signal being received from the media device across HDMI connection 107 .</span>
        <meta itemprop="num_attr" content="0056">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the detection of the pause event</span>
        <span itemprop="definition">may be performed in hardware by processing module 340 , by processing module 340 executing software stored in memory 380 , or a combination thereof.</span>
        <meta itemprop="num_attr" content="0056">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Processing module 340</span>
        <span itemprop="definition">may include one or more processors, for example.</span>
        <meta itemprop="num_attr" content="0056">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">display device 108</span>
        <span itemprop="definition">can detect a pause event based on a silent audio signal received from media device 106 as well as determining that one or more video frames received from media device 106 is not changing. The unchanging video frames in conjunction with the silent audio signal can be used to determine that a pause event is detected.</span>
        <meta itemprop="num_attr" content="0057">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">a silent audio signal</span>
        <span itemprop="definition">can be an audio signal corresponding to one or more video or audio frames received from media device 106 that may not be within a human audible frequency range. In other words, the silent audio signal volume is so low that user 132 may not hear the silent audio signal, but the silent audio signal is present.</span>
        <meta itemprop="num_attr" content="0057">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">display device 108</span>
        <span itemprop="definition">can determine that one or more video frames received are not changing by utilizing periodic sampling.</span>
        <meta itemprop="num_attr" content="0057">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">ACR module 320 and/or CV module 325</span>
        <span itemprop="definition">can be used to determine that contents are not changing between consecutive video frames.</span>
        <meta itemprop="num_attr" content="0057">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">a fingerprint and/or watermark</span>
        <span itemprop="definition">can be generated by ACR module 320 for each frame received and the generated fingerprints or watermarks can be compared. If the generated fingerprints and/or watermarks are different, then the one or more video frames are changing and a pause event is unlikely, even if a silent audio signal is detected. If however, the fingerprints and/or watermarks are the same (e.g., fingerprints and/or watermarks from 3-4 consecutive frames are unchanged) and a silent audio signal is detected, then display device 108 determines that a pause event is detected. In other words, user 132 may have paused streaming data at media device 106 , perhaps by using remote control 110 .</span>
        <meta itemprop="num_attr" content="0058">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the detection of the silent audio signal and/or the comparison of the fingerprints and/or watermarks from different video frames</span>
        <span itemprop="definition">can be performed in hardware by processing module 340 , by processing module 340 executing software stored in memory 380 , or a combination thereof.</span>
        <meta itemprop="num_attr" content="0058">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">metadata</span>
        <span itemprop="definition">can be generated by CV module 325 for each frame received and the generated metadata can be compared. If the generated metadata are different, then the one or more video frames are changing and a pause event is unlikely, even if a silent audio signal is detected. If however, the metadata for each frame are the same (e.g., metadata from 3-4 consecutive frames are unchanged) and a silent audio signal is detected, then display device 108 determines that a pause event is detected. In other words, user 132 may have paused streaming data at media device 106 , perhaps by using remote control 110 .</span>
        <meta itemprop="num_attr" content="0059">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the detection of the silent audio signal and/or the comparison of the metadata from different video frames</span>
        <span itemprop="definition">can be performed in hardware by processing module 340 , by processing module 340 executing software stored in memory 380 , or a combination thereof.</span>
        <meta itemprop="num_attr" content="0059">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">display device 108</span>
        <span itemprop="definition">can detect a pause event based on a recognition of a pause icon.</span>
        <meta itemprop="num_attr" content="0060">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">CV module 325</span>
        <span itemprop="definition">can analyze media content (e.g., one or more video frames) received via HDMI connection 107 from media device 106 to generate metadata that identifies objects in a video frame (e.g., a type of car, an actor, a pause icon, a penguin, or a bee on a flower.)</span>
        <meta itemprop="num_attr" content="0060">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">a pause icon</span>
        <span itemprop="definition">is detected in one or more consecutive video frames received via HDMI module 310 , then a pause event is detected.</span>
        <meta itemprop="num_attr" content="0060">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the detection of the pause icon in one or more consecutive video frames</span>
        <span itemprop="definition">can be performed in hardware by processing module 340 , by processing module 340 executing software stored in memory 380 , or a combination thereof.</span>
        <meta itemprop="num_attr" content="0060">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">display device 108</span>
        <span itemprop="definition">After display device 108 determines that a pause event is detected (e.g., based on a remote control pass through function, a silent audio detected with unchanging video frames, or a pause icon detected with no motion in video frames), display device 108 can perform content recognition on the video frame and/or audio frame of the pause event (e.g., a scene of a movie that is paused).</span>
        <meta itemprop="num_attr" content="0061">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">ACR module 320</span>
        <span itemprop="definition">may generate a fingerprint and/or watermark for the video frame and/or the audio frame.</span>
        <meta itemprop="num_attr" content="0061">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">CV module 325</span>
        <span itemprop="definition">may generate metadata that corresponds to objects identified or recognized within the video frame.</span>
        <meta itemprop="num_attr" content="0061">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Display device 108</span>
        <span itemprop="definition">can use the fingerprint, watermark, and/or the metadata to determine one or more appropriate ads (e.g., advertisements), add the ad(s) to a graphics plane, and present the ad(s) on display device 108 for a portion of or a duration of the pause event.</span>
        <meta itemprop="num_attr" content="0062">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">ads</span>
        <span itemprop="definition">e.g., advertisements</span>
        <meta itemprop="num_attr" content="0062">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">ad insertion module 330</span>
        <span itemprop="definition">may receive a notice of the pause event detection from processing module 340 ) the corresponding fingerprint and/or watermark from ACR module 320 , and/or the corresponding metadata from CV module 325 .</span>
        <meta itemprop="num_attr" content="0062">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Ad insertion module 330</span>
        <span itemprop="definition">can use the corresponding fingerprint, watermark, and/or metadata to select one or more relevant ads to be presented on display device 108 .</span>
        <meta itemprop="num_attr" content="0062">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the fingerprint and/or watermark</span>
        <span itemprop="definition">may correspond to a certain movie title, famous actor, and movie genre.</span>
        <meta itemprop="num_attr" content="0062">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the metadata</span>
        <span itemprop="definition">may correspond to a champagne bottle and mountain scenery.</span>
        <meta itemprop="num_attr" content="0062">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the relevant ads</span>
        <span itemprop="definition">may include the famous actor, a type of champagne, vacation opportunities that include the mountain scenery recognized.</span>
        <meta itemprop="num_attr" content="0062">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the one or more relevant ads</span>
        <span itemprop="definition">may be static (e.g., a still image) or dynamic (e.g., a gif, a short video, an animation, an interactive screen).</span>
        <meta itemprop="num_attr" content="0062">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">input from user 132 regarding the interactive screen</span>
        <span itemprop="definition">e.g., a survey</span>
        <meta itemprop="num_attr" content="0062">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">additional information</span>
        <span itemprop="definition">may be transmitted to a mobile device corresponding to a customer account associated with display device 108 (e.g., email, text).</span>
        <meta itemprop="num_attr" content="0062">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Ad insertion module 330</span>
        <span itemprop="definition">may transmit the one or more relevant ads to graphics module 360 to be added to a graphics plane (not shown) of display device 108 .</span>
        <meta itemprop="num_attr" content="0063">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the one or more video frames that are received</span>
        <span itemprop="definition">may be received and processed by video scaling and FRC 350 .</span>
        <meta itemprop="num_attr" content="0063">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the one or more video frames</span>
        <span itemprop="definition">can be added to a video plane of display device 108 (e.g., a last video frame used in the detection of the pause event can be added to the video plane).</span>
        <meta itemprop="num_attr" content="0063">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the video plane and the graphics plane</span>
        <span itemprop="definition">can be blended (e.g., merged) together and the data of the blended planes can be received by display module 370 for presentation on display device 108 .</span>
        <meta itemprop="num_attr" content="0063">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the graphics plane</span>
        <span itemprop="definition">may be displayed in front of the video plane (e.g., overlaid to be viewed on top of the video plane).</span>
        <meta itemprop="num_attr" content="0063">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the images and/or ads of the graphics plane</span>
        <span itemprop="definition">can be transparent.</span>
        <meta itemprop="num_attr" content="0063">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">a selection function from remote control 110</span>
        <span itemprop="definition">can be passed through media device 106 to display device 108 to make a selection from the graphics plane. The functions above may be performed by processing module 340 , executing software of the various modules that may be stored in memory 380 , or a combination of hardware and software.</span>
        <meta itemprop="num_attr" content="0063">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">FIG. 7 A</span>
        <span itemprop="definition">illustrates a block diagram of display device 700 , according to some embodiments.</span>
        <meta itemprop="num_attr" content="0064">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">display device 700</span>
        <span itemprop="definition">may utilize control signal information received via an HDMI connection in addition to video frames, to determine appropriate and relevant ads to present on display device 700 .</span>
        <meta itemprop="num_attr" content="0064">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the relevant ads</span>
        <span itemprop="definition">are presented on display device 700 during a pause event.</span>
        <meta itemprop="num_attr" content="0064">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">HDMI input 710</span>
        <span itemprop="definition">may support HDMI connection 107 of FIG. 1 , where HDMI connection 107 is coupled to media device 106 of FIG. 1 .</span>
        <meta itemprop="num_attr" content="0065">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">HDMI input 710 , ACR 730 , computer vision 740 , ad insertion 750 , graphics module 770 , memory 780 , and video scaling and FRC 782 , and display panel 790</span>
        <span itemprop="definition">can correspond respectively to HDMI module 310 , ACR module 320 , CV module 325 , ad insertion module 330 , graphics module 360 , memory 380 , video scaling and FRC 350 , and display module 370 of FIG. 3 .</span>
        <meta itemprop="num_attr" content="0065">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">display device 700</span>
        <span itemprop="definition">may be coupled via HDMI connection to a media device (e.g., media device 600 of FIG. 6 or media device 800 of FIG. 8 ).</span>
        <meta itemprop="num_attr" content="0066">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">media device 600</span>
        <span itemprop="definition">can be a gaming device.</span>
        <meta itemprop="num_attr" content="0066">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Display device 700</span>
        <span itemprop="definition">can receive video frames as well as one or more control signals from media device 600 via HDMI input 710 .</span>
        <meta itemprop="num_attr" content="0066">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the control signals</span>
        <span itemprop="definition">can include a product information signal, a latency mode signal, or a refresh rate signal from media device 600 .</span>
        <meta itemprop="num_attr" content="0066">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Product information function 722</span>
        <span itemprop="definition">can be a function of processor 720 that determines SPD about the source, such as media device 600 , from the product information signal. Examples of SPD include the type of gaming device platform, and/or the model of the gaming device platform.</span>
        <meta itemprop="num_attr" content="0066">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the product information signal</span>
        <span itemprop="definition">can include an SPD InfoFrame that communicates the name and product type of a source device such as media device 600 (e.g., a video game console) to a sink such as display device 700 (e.g., a television (TV)).</span>
        <meta itemprop="num_attr" content="0066">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">a source device</span>
        <span itemprop="definition">such as media device 600 (e.g., a video game console)</span>
        <meta itemprop="num_attr" content="0066">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">a sink</span>
        <span itemprop="definition">such as display device 700 (e.g., a television (TV)).</span>
        <meta itemprop="num_attr" content="0066">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the video game console</span>
        <span itemprop="definition">may transmit the following SPD via the product information signal to display device 700 .</span>
        <meta itemprop="num_attr" content="0066">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the SPD</span>
        <span itemprop="definition">can include the following:</span>
        <meta itemprop="num_attr" content="0066">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">display device 700</span>
        <span itemprop="definition">can display an advertisement of a newer model of media device 600 , in this example, a newer model than video game console model 1. Display device 700 can also display an advertisement of a competitor product.</span>
        <meta itemprop="num_attr" content="0070">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Latency mode function 724</span>
        <span itemprop="definition">can be a function of processor 720 that determines an ALLM from a latency mode signal received from media device 600 .</span>
        <meta itemprop="num_attr" content="0071">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the ALLM</span>
        <span itemprop="definition">can indicate whether or not gaming application 618 running (e.g., executing) on media device 600 is a low latency application. Accordingly, display device 700 utilizes resources to enable corresponding low latency performance supporting gaming application 618 .</span>
        <meta itemprop="num_attr" content="0071">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the ALLM</span>
        <span itemprop="definition">enables media device 600 (e.g., a source like a video game console) to automatically enable or disable the low latency performance of display device 700 (e.g., a sink like a TV) without requiring a user to navigate to menus of display device 700 (e.g., the sink's menus) to set the optimal latency corresponding to the content of media device 600 (e.g., gaming application 618 such as the video game console gaming content).</span>
        <meta itemprop="num_attr" content="0071">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Media device 600</span>
        <span itemprop="definition">may transmit the latency mode signal via an HDMI Forum Vendor Specific Info Frame (HF-VSIF).</span>
        <meta itemprop="num_attr" content="0071">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the 5th byte in an HF-VSIF</span>
        <span itemprop="definition">may include an ALLM_Mode field which can be either 0 or 1.</span>
        <meta itemprop="num_attr" content="0071">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">ALLM_Mode</span>
        <span itemprop="definition">1</span>
        <meta itemprop="num_attr" content="0071">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">media device 600</span>
        <span itemprop="definition">e.g., a source like the video game console</span>
        <meta itemprop="num_attr" content="0071">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">display device 700</span>
        <span itemprop="definition">e.g., a sink like a TV</span>
        <meta itemprop="num_attr" content="0071">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">latency mode function 724</span>
        <span itemprop="definition">can determine (a value of) the ALLM that can be used as an indication that the user has started playing a game and hence relevant advertisements related to the game can be displayed to the user via display device 700 .</span>
        <meta itemprop="num_attr" content="0071">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Refresh rate function 726</span>
        <span itemprop="definition">can be a function of processor 720 that determines a VRR for advanced gaming applications from the refresh rate signal.</span>
        <meta itemprop="num_attr" content="0072">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the VRR</span>
        <span itemprop="definition">can be a dynamic display refresh rate that can continuously and seamlessly vary on the fly (e.g., change during streaming).</span>
        <meta itemprop="num_attr" content="0072">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the VRR</span>
        <span itemprop="definition">can be transmitted by media device 600 using a Video Timing Extended Metadata Packet (EMP) in the refresh rate signal.</span>
        <meta itemprop="num_attr" content="0072">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">EMP</span>
        <span itemprop="definition">Video Timing Extended Metadata Packet</span>
        <meta itemprop="num_attr" content="0072">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">display device 700</span>
        <span itemprop="definition">can advertise sources and/or applications that offer similarly advanced types of VRR and/or more advanced types of VRR (e.g., VRRs supported by Free Sync offered by AMD graphics cards or GSync offered by NVIDIA graphics cards).</span>
        <meta itemprop="num_attr" content="0072">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">display device 700</span>
        <span itemprop="definition">can utilize the control signal information (e.g., SPD from product information function 722 , ALLM from latency mode function 724 , and/or VRR from refresh rate function 726 ) to determine relevant ads to be presented on display panel 790 .</span>
        <meta itemprop="num_attr" content="0072">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">control signal information</span>
        <span itemprop="definition">e.g., SPD from product information function 722 , ALLM from latency mode function 724 , and/or VRR from refresh rate function 726 .</span>
        <meta itemprop="num_attr" content="0072">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">display device 700</span>
        <span itemprop="definition">may detect a pause event by using: i) a remote control pass through function; ii) a silent audio signal; and/or iii) pause icon recognition.</span>
        <meta itemprop="num_attr" content="0073">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">display device 700</span>
        <span itemprop="definition">can readily detect a pause event based on a pause key signal (e.g. a remote control pass through function) being received from the media device across an HDMI connection (e.g., HDMI connection 107 ) via HDMI input 710 .</span>
        <meta itemprop="num_attr" content="0073">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the detection of a pause event</span>
        <span itemprop="definition">may be performed in hardware by processor 720 , by processor 720 executing software stored in memory 780 , or a combination thereof.</span>
        <meta itemprop="num_attr" content="0073">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Processor 720</span>
        <span itemprop="definition">may include one or more processors, for example. In some embodiments, processor 720 may execute software stored in a different memory (not shown).</span>
        <meta itemprop="num_attr" content="0073">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">display device 700</span>
        <span itemprop="definition">can detect a pause event based on a silent audio signal received from the media device (e.g., media device 106 , media device 600 , or media device 800 ) as well as determine that one or more video frames received from the media device is not changing.</span>
        <meta itemprop="num_attr" content="0074">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">a fingerprint and/or watermark</span>
        <span itemprop="definition">can be generated by ACR 730 for each frame received and the generated fingerprints and/or watermarks can be compared.</span>
        <meta itemprop="num_attr" content="0074">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">CV 740</span>
        <span itemprop="definition">can generate metadata for each video frame received and generated metadata from consecutive video frames can be compared. When the fingerprints, watermarks, and/or metadata from consecutive video frames are unchanged in conjunction with a silent audio signal, then a pause event is detected.</span>
        <meta itemprop="num_attr" content="0074">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the detection of a pause event based on the silent audio signal and the unchanging video frames</span>
        <span itemprop="definition">may be performed in hardware by processor 720 , by processor 720 executing software stored in memory 780 , or a combination thereof.</span>
        <meta itemprop="num_attr" content="0074">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Processor 720</span>
        <span itemprop="definition">may include one or more processors, for example. In some embodiments, processor 720 may execute software stored in a different memory (not shown).</span>
        <meta itemprop="num_attr" content="0074">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">display device 108</span>
        <span itemprop="definition">can detect a pause event based on pause icon recognition.</span>
        <meta itemprop="num_attr" content="0075">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">CV 740</span>
        <span itemprop="definition">can analyze media content (e.g., one or more video frames) received via HDMI input 710 from the media device to generate metadata that identifies objects (e.g., a pause icon) in a video frame.</span>
        <meta itemprop="num_attr" content="0075">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">metadata from one or more consecutive video frames received</span>
        <span itemprop="definition">include a pause icon, and a determination is made that the video frames are not changing, a processor can determine that a pause event has been detected.</span>
        <meta itemprop="num_attr" content="0075">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the detection of a pause icon and the unchanging video frames</span>
        <span itemprop="definition">may be performed in hardware by processor 720 , by processor 720 executing software stored in memory 780 , or a combination thereof.</span>
        <meta itemprop="num_attr" content="0075">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Processor 720</span>
        <span itemprop="definition">may include one or more processors, for example. In some embodiments, processor 720 may execute software stored in a different memory (not shown).</span>
        <meta itemprop="num_attr" content="0075">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">display device 700</span>
        <span itemprop="definition">After display device 700 determines that a pause event is detected (e.g., based on a remote control pass through function, silent audio detected with unchanging video frames, and/or a pause icon recognition with no motion of the video frames), display device 700 can perform content recognition on the video frame of the pause event (e.g., a scene of a movie that is paused) to determine relevant ads to be presented on display panel 790 for a period of or duration of the pause event.</span>
        <meta itemprop="num_attr" content="0076">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">ACR 730</span>
        <span itemprop="definition">may generate a fingerprint and/or watermark for the video frame that enables determination of the video (e.g., the movie) including the video frame, and data associated with the video (e.g., actors, movie title, genre).</span>
        <meta itemprop="num_attr" content="0076">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">computer vision 740</span>
        <span itemprop="definition">may generate metadata that corresponds to objects (e.g., champagne bottle, mountain scenery) identified or recognized within the video frame.</span>
        <meta itemprop="num_attr" content="0076">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the fingerprints, watermarks, and/or metadata generated</span>
        <span itemprop="definition">can be used to determine relevant ad to be displayed on display device 700 for a portion of or the duration of the pause event.</span>
        <meta itemprop="num_attr" content="0076">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">display device 700</span>
        <span itemprop="definition">can perform content recognition on an audio frame of the pause event (e.g., a scene of a movie that is paused) to determine relevant ads to be presented on display panel 790 for a period of or duration of the pause event.</span>
        <meta itemprop="num_attr" content="0077">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">ACR 730</span>
        <span itemprop="definition">may generate a fingerprint and/or watermark for the audio frame that enables determination of the content (e.g., the movie) including the audio frame, and data associated with the audio frame (e.g., actors, movie title, genre).</span>
        <meta itemprop="num_attr" content="0077">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the fingerprints, watermarks, and/or metadata</span>
        <span itemprop="definition">can be used to determine relevant ad to be displayed on display device 700 for a portion of or the duration of the pause event.</span>
        <meta itemprop="num_attr" content="0077">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">display device 700</span>
        <span itemprop="definition">can utilize the information obtained from control signals (e.g., SPD, ALLM, and/or VRR) to determine one or more appropriate ads to be presented on display panel 790 during a portion or duration of the pause event.</span>
        <meta itemprop="num_attr" content="0078">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">control signals</span>
        <span itemprop="definition">e.g., SPD, ALLM, and/or VRR</span>
        <meta itemprop="num_attr" content="0078">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">display device 700</span>
        <span itemprop="definition">utilizes the content recognition data of one or more video frames (e.g., fingerprints and/or watermarks from ACR 730 and/or metadata from computer vision 740 ) in conjunction with SPD, ALLM, and/or VRR to determine one or more appropriate ads to be presented on display panel 790 during a portion or duration of the pause event.</span>
        <meta itemprop="num_attr" content="0078">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">video frames</span>
        <span itemprop="definition">e.g., fingerprints and/or watermarks from ACR 730 and/or metadata from computer vision 740</span>
        <meta itemprop="num_attr" content="0078">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">SPD</span>
        <span itemprop="definition">e.g., fingerprints and/or watermarks from ACR 730 and/or metadata from computer vision 740</span>
        <meta itemprop="num_attr" content="0078">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the corresponding fingerprint and/or watermark from ACR 730</span>
        <span itemprop="definition">can be utilized by ad insertion 750 to select one or more relevant ads to be presented on display device 700 .</span>
        <meta itemprop="num_attr" content="0079">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the fingerprint and/or watermark</span>
        <span itemprop="definition">may correspond to a certain gaming application 618 .</span>
        <meta itemprop="num_attr" content="0079">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the metadata</span>
        <span itemprop="definition">may correspond to the genre of gaming application 618 (e.g., magical creatures, sports arena, vehicles).</span>
        <meta itemprop="num_attr" content="0079">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the SPD</span>
        <span itemprop="definition">may indicate the particular gaming system or gaming console and the model, and the ALLM may indicate low latency is needed along with a certain VRR for advanced gaming.</span>
        <meta itemprop="num_attr" content="0079">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the SPD</span>
        <span itemprop="definition">can include a unique ID that corresponds to a particular hardware device and/or model of the hardware device.</span>
        <meta itemprop="num_attr" content="0079">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">ad insertion 750</span>
        <span itemprop="definition">determines one or more relevant ads.</span>
        <meta itemprop="num_attr" content="0079">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">a relevant ad</span>
        <span itemprop="definition">may include a new model gaming system, a competitor gaming system, and/or one or more gaming applications that utilize a corresponding ALLM and/or corresponding VRR within a similar genre. Many variations are possible.</span>
        <meta itemprop="num_attr" content="0079">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">ad insertion 750</span>
        <span itemprop="definition">transmits the corresponding fingerprint and/or watermark from ACR 730 , the corresponding metadata from CV 740 , SPD from product information function 722 , ALLM from latency mode function 724 , and/or VRR from refresh rate function 726 to network 760 (e.g., a cloud network) for the determination of the relevant ads and receive the relevant ads from network 760 .</span>
        <meta itemprop="num_attr" content="0079">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">network 760</span>
        <span itemprop="definition">e.g., a cloud network</span>
        <meta itemprop="num_attr" content="0079">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the one or more relevant ads</span>
        <span itemprop="definition">may be static (e.g., a still image), dynamic (e.g., a gif, a short video, an animation, an interactive screen), or a link for purchasing one or more items in the relevant ad.</span>
        <meta itemprop="num_attr" content="0080">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">input from user 132 regarding the interactive screen</span>
        <span itemprop="definition">e.g., a survey</span>
        <meta itemprop="num_attr" content="0080">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">crowdsource server 128</span>
        <span itemprop="definition">e.g., a survey</span>
        <meta itemprop="num_attr" content="0080">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">additional information</span>
        <span itemprop="definition">may be transmitted to a mobile device corresponding to a customer account associated with display device 700 (e.g., email, text).</span>
        <meta itemprop="num_attr" content="0080">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the corresponding fingerprint and/or watermark from ACR 730 , the corresponding metadata from CV 740 , SPD from product information function 722 , ALLM from latency mode function 724 , VRR from refresh rate function 726 , and/or the one or more relevant ads</span>
        <span itemprop="definition">may be stored in a historical profile corresponding to user 132 and/or media device 600 .</span>
        <meta itemprop="num_attr" content="0080">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Ad insertion 750 and/or network 760</span>
        <span itemprop="definition">may utilize the historical profile in conjunction with current data (e.g., fingerprint and/or watermark from ACR 730 , metadata from CV 740 , SPD from product information function 722 , ALLM from latency mode function 724 , and/or VRR from refresh rate function 726 , to determine current relevant ads.</span>
        <meta itemprop="num_attr" content="0080">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Ad insertion 750</span>
        <span itemprop="definition">may transmit the one or more relevant ads to graphics module 770 to be added to a graphics plane 775 of display device 700 .</span>
        <meta itemprop="num_attr" content="0081">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the one or more video frames that are received</span>
        <span itemprop="definition">may be stored in memory 780 , and processed by video scaling and FRC 782 .</span>
        <meta itemprop="num_attr" content="0081">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the one or more processed video frames</span>
        <span itemprop="definition">can be added to video plane 784 of display device 700 (e.g., a last video frame used in the detection of the pause event can be added to video plane 784 ).</span>
        <meta itemprop="num_attr" content="0081">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">video plane 784 and graphics plane 775</span>
        <span itemprop="definition">can be blended (e.g., merged) together and the data of the blended planes can be received by display panel 790 for presentation on display device 700 .</span>
        <meta itemprop="num_attr" content="0081">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">graphics plane 775</span>
        <span itemprop="definition">may be displayed in front of video plane 784 (e.g., overlaid to be viewed on top of video plane 784 ).</span>
        <meta itemprop="num_attr" content="0081">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the images and/or ads of graphics plane 775</span>
        <span itemprop="definition">can be transparent.</span>
        <meta itemprop="num_attr" content="0081">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">a selection function from remote control 110</span>
        <span itemprop="definition">can be passed through media device 600 to display device 700 to make a selection from the graphics plane. The functions above may be performed by processor 720 , executing software of the various modules that may be stored in memory 780 , or a combination of hardware and software.</span>
        <meta itemprop="num_attr" content="0081">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">FIG. 7 B</span>
        <span itemprop="definition">illustrates a block diagram of display device 705 , according to some embodiments.</span>
        <meta itemprop="num_attr" content="0082">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">elements of display device 705</span>
        <span itemprop="definition">may be described with reference to elements from other figures in the disclosure.</span>
        <meta itemprop="num_attr" content="0082">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">functions of display device 705</span>
        <span itemprop="definition">may be similar to that of display device 700 of FIG. 7 A , but network 765 includes the following functions: product information function 722 , latency mode function 724 , refresh rate function 726 , ACR 730 and/or computer vision 740 , determines relevant ads to be presented on display panel 790 , and transmits the relevant ads to ad insertion 750 .</span>
        <meta itemprop="num_attr" content="0082">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">FIG. 9</span>
        <span itemprop="definition">illustrates a block diagram of display device 900 , according to some embodiments.</span>
        <meta itemprop="num_attr" content="0083">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">elements of display device 900</span>
        <span itemprop="definition">may be described with reference to elements from other figures in the disclosure.</span>
        <meta itemprop="num_attr" content="0083">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">functions of display device 900</span>
        <span itemprop="definition">may be similar to that of display device 700 of FIG. 7 A .</span>
        <meta itemprop="num_attr" content="0083">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">HDMI input 910 , product information function 922 , latency mode function 924 , refresh rate function 926 , ACR 930 , computer vision 940 , processor 920 , ad insertion 950 , graphics module 970 , graphics plane 975 , video plane 984 , memory 980 , and video scaling and FRC 982 , and display panel 990</span>
        <span itemprop="definition">can correspond respectively to HDMI input 710 , product information function 722 , latency mode function 724 , refresh rate function 726 , ACR 730 , computer vision 740 , processor 720 , ad insertion 750 , graphics module 770 , graphics plane 775 , video plane 784 , memory 780 , and video scaling and FRC 782 , and display panel 790 of FIG. 7 A .</span>
        <meta itemprop="num_attr" content="0083">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">display device 900</span>
        <span itemprop="definition">can execute one or more functions product information function 922 , latency mode function 924 , refresh rate function 926 , ACR 930 and/or computer vision 940 via corresponding processor(s) (not shown) that are different from processor 920 .</span>
        <meta itemprop="num_attr" content="0084">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">one or more of the functions product information function 922 , latency mode function 924 , refresh rate function 926 , ACR 930 and/or computer vision 940</span>
        <span itemprop="definition">may be performed by network 960 , processor 920 , and/or a different processor (not shown).</span>
        <meta itemprop="num_attr" content="0084">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">HDMI input 910</span>
        <span itemprop="definition">receives video frames and control signals from media device 600 and/or media device 800 .</span>
        <meta itemprop="num_attr" content="0085">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">network 960</span>
        <span itemprop="definition">provides the video frames to HDMI input 910 .</span>
        <meta itemprop="num_attr" content="0085">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">FIG. 4</span>
        <span itemprop="definition">illustrates method 400 for a display device, according to some embodiments.</span>
        <meta itemprop="num_attr" content="0086">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">method 400</span>
        <span itemprop="definition">may be described with reference to elements from other figures in the disclosure.</span>
        <meta itemprop="num_attr" content="0086">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">method 400</span>
        <span itemprop="definition">may be performed by a display device (e.g., display device 108 of FIG. 1 and FIG. 3 , display device 700 of FIG. 7 A , display device 705 of FIG. 7 B , and/or display device 900 of FIG. 9 ).</span>
        <meta itemprop="num_attr" content="0086">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">a display device</span>
        <span itemprop="definition">e.g., display device 108 of FIG. 1 and FIG. 3 , display device 700 of FIG. 7 A , display device 705 of FIG. 7 B , and/or display device 900 of FIG. 9 ).</span>
        <meta itemprop="num_attr" content="0086">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the display device</span>
        <span itemprop="definition">can determine whether CEC (e.g., remote control pass through) functions are enabled. When CEC functions are enabled (e.g., set), method 400 proceeds to 410 . Otherwise, method 400 proceeds to 435 .</span>
        <meta itemprop="num_attr" content="0087">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">CEC</span>
        <span itemprop="definition">remote control pass through</span>
        <meta itemprop="num_attr" content="0087">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">display device 108</span>
        <span itemprop="definition">determines whether a pause key signal has been received. For example, user 132 may have selected a pause key on remote control 110 . Since CEC functions are enabled, the pause key signal passes through a media device (e.g., media device 106 of FIG. 1 or FIG. 2 , media device 600 of FIG. 6 , and/or media device 800 of FIG. 8 ) to a display device (e.g., display device 108 of FIG. 1 and FIG. 3 , display device 700 of FIG. 7 A , display device 705 of FIG. 7 B , or display device 900 of FIG. 9 ) via an HDMI connection (e.g., HDMI connection 107 of FIG. 1 ) or HDMI input 710 , or HDMI input 910 .</span>
        <meta itemprop="num_attr" content="0088">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the display device</span>
        <span itemprop="definition">determines that a pause event has been detected, and method 400 proceeds to 415 and 418 . Otherwise, method 400 returns to 405 .</span>
        <meta itemprop="num_attr" content="0088">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the display device</span>
        <span itemprop="definition">performs content recognition on the one or more video frames received from the media device 106 (e.g., the one or more video frames from which the pause event is determined). In some embodiments, when a pause event has been detected, the display device performs content recognition on the one or more audio frames received from the media device 106 (e.g., the one or more audio frames from which the pause event is determined).</span>
        <meta itemprop="num_attr" content="0089">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the content recognition</span>
        <span itemprop="definition">may be performed by an ACR function (e.g., ACR Module 320 , ACR 730 , network 760 , ACR 930 , or Network 960 ) that determines corresponding fingerprints and/or watermarks, or by a CV function (e.g., CV module 325 , computer vision 740 , network 760 , computer vision 940 , and/or network 960 ) that determines corresponding metadata.</span>
        <meta itemprop="num_attr" content="0089">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">ACR function</span>
        <span itemprop="definition">e.g., ACR Module 320 , ACR 730 , network 760 , ACR 930 , or Network 960</span>
        <meta itemprop="num_attr" content="0089">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">CV function</span>
        <span itemprop="definition">e.g., CV module 325 , computer vision 740 , network 760 , computer vision 940 , and/or network 960</span>
        <meta itemprop="num_attr" content="0089">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the display device</span>
        <span itemprop="definition">performs source device recognition and/or application recognition based on received control signals including but not limited to a product information signal, a latency mode signal, or a refresh rate signal.</span>
        <meta itemprop="num_attr" content="0090">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">a product information function</span>
        <span itemprop="definition">enables the display device to determine the SPD that can include the type of gaming device or gaming platform (e.g., a video game console) and the model number.</span>
        <meta itemprop="num_attr" content="0090">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the latency mode function</span>
        <span itemprop="definition">enables the display device to determine the ALLM, whether an application in use works best with low latency (e.g., gaming application 618 , input application 816 , or media application 817 ).</span>
        <meta itemprop="num_attr" content="0090">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the refresh rate function</span>
        <span itemprop="definition">enables the display device to determine the VRR and that the application in use may be an advanced (e.g., sophisticated) gaming application.</span>
        <meta itemprop="num_attr" content="0090">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the display device</span>
        <span itemprop="definition">determines an appropriate ad corresponding to the determined fingerprints, watermarks, metadata, and/or information from the control signals (e.g., SPD, ALLM, VRR).</span>
        <meta itemprop="num_attr" content="0091">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">an ad insertion function</span>
        <span itemprop="definition">e.g., ad insertion module 330 , ad insertion 750 , or ad insertion 950</span>
        <meta itemprop="num_attr" content="0091">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the control signals</span>
        <span itemprop="definition">e.g., SPD, ALLM, VRR.</span>
        <meta itemprop="num_attr" content="0091">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the ad insertion function</span>
        <span itemprop="definition">communicates with a network (e.g., network 118 via communication device 114 , network 760 , or network 960 ) to exchange the fingerprints, watermarks, metadata, and/or information from the control signals (e.g., SPD, ALLM, VRR) and/or receive one or more relevant ads to be displayed on the display device (e.g., display device 108 , display device 700 , display device 705 , or display device 900 ) during the pause event.</span>
        <meta itemprop="num_attr" content="0091">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the one or more relevant ads</span>
        <span itemprop="definition">may include a static or dynamic image.</span>
        <meta itemprop="num_attr" content="0091">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the display device</span>
        <span itemprop="definition">transmits the video frames and/or control signals received via an HDMI connection to a network (e.g., network 118 , network 760 , and/or network 960 ).</span>
        <meta itemprop="num_attr" content="0092">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">a network</span>
        <span itemprop="definition">e.g., network 118 , network 760 , and/or network 960 .</span>
        <meta itemprop="num_attr" content="0092">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the network</span>
        <span itemprop="definition">performs one or more of the ACR functions, CV functions, and control signal analysis to determine the one or more fingerprints, watermarks, metadata, and/or information from the control signals (e.g., SPD, ALLM, VRR). Further, the network can determine an appropriate ad corresponding to the fingerprints, watermarks, metadata, and/or information from the control signals (e.g., SPD, ALLM, VRR).</span>
        <meta itemprop="num_attr" content="0092">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the network</span>
        <span itemprop="definition">can transmit the appropriate ad to the ad insertion function (e.g., ad insertion module 330 , ad insertion 750 , or ad insertion 950 ).</span>
        <meta itemprop="num_attr" content="0092">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the network</span>
        <span itemprop="definition">performs one or more of the ACR functions, CV functions, and control signal analysis to determine the one or more fingerprints, watermarks, metadata, and/or information from the control signals (e.g., SPD, ALLM, VRR).</span>
        <meta itemprop="num_attr" content="0093">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">a processor</span>
        <span itemprop="definition">e.g., processor 720 , processor 920 , or other processor (not shown) of the display device performs the remaining functions that the network does not perform, and transmits the output to the network (e.g., directly or via the ad insertion function).</span>
        <meta itemprop="num_attr" content="0093">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the network</span>
        <span itemprop="definition">utilizes the one or more fingerprints, watermarks, metadata, and/or information obtained from the control signals (e.g., SPD, ALLM, and/or VRR) to determine the one or more appropriate ads, and transmits the one or more appropriate ads to the ad insertion function.</span>
        <meta itemprop="num_attr" content="0093">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">control signals</span>
        <span itemprop="definition">e.g., SPD, ALLM, and/or VRR</span>
        <meta itemprop="num_attr" content="0093">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the processor</span>
        <span itemprop="definition">e.g., processor 720 , processor 920 , or other processor (not shown) of the display device performs the remaining functions that the network does not perform, and transmits the output to the ad insertion function.</span>
        <meta itemprop="num_attr" content="0094">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the ad insertion function</span>
        <span itemprop="definition">also receives the one or more fingerprints, watermarks, metadata, and/or information obtained from the control signals (e.g., SPD, ALLM, and/or VRR) determined by the network.</span>
        <meta itemprop="num_attr" content="0094">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the ad insertion function</span>
        <span itemprop="definition">uses the received data from the processor and the network to determine one or more appropriate ads.</span>
        <meta itemprop="num_attr" content="0094">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the ad insertion function</span>
        <span itemprop="definition">communicates the one or more relevant ads to be displayed on the display device (e.g., display device 108 , display device 700 , display device 705 , or display device 900 ) during the pause event.</span>
        <meta itemprop="num_attr" content="0095">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the one or more relevant ads</span>
        <span itemprop="definition">may include a static or dynamic image.</span>
        <meta itemprop="num_attr" content="0095">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the display device</span>
        <span itemprop="definition">can add one or more of the one or more appropriate ads to a graphics plane of the display device.</span>
        <meta itemprop="num_attr" content="0096">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the ad insertion function</span>
        <span itemprop="definition">may transmit the one or more relevant ads to a graphics module (e.g., graphics module 360 , graphics module 770 , graphics module 970 ) to be added to the graphics plane (e.g., graphics plane 775 , graphics plane 975 ).</span>
        <meta itemprop="num_attr" content="0096">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the display device</span>
        <span itemprop="definition">presents the one or more appropriate ads during the pause event.</span>
        <meta itemprop="num_attr" content="0097">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the graphics plane and the video plane</span>
        <span itemprop="definition">may blended (e.g., aligned) and a display module (e.g., display module 370 , display panel 790 , display panel 990 ) may present the one or more appropriate ads on a screen of the display device.</span>
        <meta itemprop="num_attr" content="0097">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the display device</span>
        <span itemprop="definition">determines that the pause event ends, and the display device stops presenting the one or more appropriate ads on the screen.</span>
        <meta itemprop="num_attr" content="0097">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the determination that the pause event ends</span>
        <span itemprop="definition">can include but is not limited to: receiving a play key input (e.g., when CEC is set) from remote control 110 ; detecting that silent audio is not received or that video frames are changing; and/or determining that a pause icon is no longer detected or motion is detected in the video frames (e.g., via a CV function.)</span>
        <meta itemprop="num_attr" content="0097">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the display device</span>
        <span itemprop="definition">can determine whether a silent audio signal is detected. When a silent audio signal is detected, method 400 proceeds to 440 . Otherwise, method 400 proceeds to 455 .</span>
        <meta itemprop="num_attr" content="0098">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">display device 108</span>
        <span itemprop="definition">determines whether one or more video frames is unchanging (e.g., stopped). For example, processing module 340 can perform periodic sampling on a received video frame. In some examples, the determination of the change may be by performing content recognition functions periodically.</span>
        <meta itemprop="num_attr" content="0099">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">method 400</span>
        <span itemprop="definition">proceeds to 415 .</span>
        <meta itemprop="num_attr" content="0099">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">method 400</span>
        <span itemprop="definition">returns to 405 to detect a pause event.</span>
        <meta itemprop="num_attr" content="0099">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the display device</span>
        <span itemprop="definition">determines whether a pause icon is detected among the one or more video frames received.</span>
        <meta itemprop="num_attr" content="0100">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the CV function</span>
        <span itemprop="definition">can analyze the content of one or more video frames to recognize a pause icon.</span>
        <meta itemprop="num_attr" content="0100">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">method 400</span>
        <span itemprop="definition">proceeds to 460 . Otherwise, method 400 returns to 405 .</span>
        <meta itemprop="num_attr" content="0100">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">display device 108</span>
        <span itemprop="definition">determines whether there is a change in the one or more audio and/or video frames received.</span>
        <meta itemprop="num_attr" content="0101">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the CV function</span>
        <span itemprop="definition">can determine whether the content and/or context of one or more of the video frames received changes.</span>
        <meta itemprop="num_attr" content="0101">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">an ACR function</span>
        <span itemprop="definition">determines based on video and/or audio frames whether the content of the video and/or audio frames received have changed. Display device can use the corresponding fingerprints, watermarks, and/or metadata to determine whether content has changed. In some examples, the determination of the change may be performed by content recognition functions periodically.</span>
        <meta itemprop="num_attr" content="0101">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">method 400</span>
        <span itemprop="definition">proceeds to 415 and/or 418 . Otherwise, method 400 returns to 405 .</span>
        <meta itemprop="num_attr" content="0101">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">FIG. 5</span>
        <span itemprop="definition">Various embodiments may be implemented, for example, using one or more well-known computer systems, such as computer system 500 shown in FIG. 5 .</span>
        <meta itemprop="num_attr" content="0102">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">media device 106 , media device 600 , media device 800 , display device 108 , display device 700 , display device 705 , or display device 900 , and/or method 400</span>
        <span itemprop="definition">may be implemented using combinations or sub-combinations of computer system 500 .</span>
        <meta itemprop="num_attr" content="0102">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">one or more computer systems 500</span>
        <span itemprop="definition">may be used, for example, to implement any of the embodiments discussed herein, as well as combinations and sub-combinations thereof.</span>
        <meta itemprop="num_attr" content="0102">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Computer system 500</span>
        <span itemprop="definition">may include one or more processors (also called central processing units, or CPUs), such as a processor 504 .</span>
        <meta itemprop="num_attr" content="0103">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">processors</span>
        <span itemprop="definition">also called central processing units, or CPUs</span>
        <meta itemprop="num_attr" content="0103">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Processor 504</span>
        <span itemprop="definition">may be connected to a communication infrastructure 506 (that can be a bus).</span>
        <meta itemprop="num_attr" content="0103">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Computer system 500</span>
        <span itemprop="definition">may also include user input/output device(s) 503 , such as monitors, keyboards, pointing devices, etc., which may communicate with communication infrastructure 506 through user input/output interface(s) 502 .</span>
        <meta itemprop="num_attr" content="0104">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">user input/output device(s) 503</span>
        <span itemprop="definition">such as monitors, keyboards, pointing devices, etc.</span>
        <meta itemprop="num_attr" content="0104">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">communication infrastructure 506</span>
        <span itemprop="definition">may communicate with user input/output interface(s) 502 .</span>
        <meta itemprop="num_attr" content="0104">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">processors 504</span>
        <span itemprop="definition">may be a graphics processing unit (GPU).</span>
        <meta itemprop="num_attr" content="0105">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">a GPU</span>
        <span itemprop="definition">may be a processor that is a specialized electronic circuit designed to process mathematically intensive applications.</span>
        <meta itemprop="num_attr" content="0105">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">the GPU</span>
        <span itemprop="definition">may have a parallel structure that is efficient for parallel processing of large blocks of data, such as mathematically intensive data common to computer graphics applications, images, videos, etc.</span>
        <meta itemprop="num_attr" content="0105">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Computer system 500</span>
        <span itemprop="definition">may also include a main or primary memory 508 , such as random access memory (RAM).</span>
        <meta itemprop="num_attr" content="0106">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Main memory 508</span>
        <span itemprop="definition">may include one or more levels of cache.</span>
        <meta itemprop="num_attr" content="0106">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Main memory 508</span>
        <span itemprop="definition">may have stored therein control logic (i.e., computer software) and/or data.</span>
        <meta itemprop="num_attr" content="0106">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Computer system 500</span>
        <span itemprop="definition">may also include one or more secondary storage devices or memory 510 .</span>
        <meta itemprop="num_attr" content="0107">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Secondary memory 510</span>
        <span itemprop="definition">may include, for example, a hard disk drive 512 and/or a removable storage device or drive 514 .</span>
        <meta itemprop="num_attr" content="0107">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Removable storage drive 514</span>
        <span itemprop="definition">may be a floppy disk drive, a magnetic tape drive, a compact disk drive, an optical storage device, tape backup device, and/or any other storage device/drive.</span>
        <meta itemprop="num_attr" content="0107">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Removable storage drive 514</span>
        <span itemprop="definition">may interact with a removable storage unit 518 .</span>
        <meta itemprop="num_attr" content="0108">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Removable storage unit 518</span>
        <span itemprop="definition">may include a computer usable or readable storage device having stored thereon computer software (control logic) and/or data.</span>
        <meta itemprop="num_attr" content="0108">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Removable storage unit 518</span>
        <span itemprop="definition">may be a floppy disk, magnetic tape, compact disk, DVD, optical storage disk, and/any other computer data storage device.</span>
        <meta itemprop="num_attr" content="0108">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Removable storage drive 514</span>
        <span itemprop="definition">may read from and/or write to removable storage unit 518 .</span>
        <meta itemprop="num_attr" content="0108">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Secondary memory 510</span>
        <span itemprop="definition">may include other means, devices, components, instrumentalities or other approaches for allowing computer programs and/or other instructions and/or data to be accessed by computer system 500 .</span>
        <meta itemprop="num_attr" content="0109">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Such means, devices, components, instrumentalities or other approaches</span>
        <span itemprop="definition">may include, for example, a removable storage unit 522 and an interface 520 .</span>
        <meta itemprop="num_attr" content="0109">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Examples of the removable storage unit 522 and the interface 520</span>
        <span itemprop="definition">may include a program cartridge and cartridge interface (such as that found in video game devices), a removable memory chip (such as an EPROM or PROM) and associated socket, a memory stick and USB or other port, a memory card and associated memory card slot, and/or any other removable storage unit and associated interface.</span>
        <meta itemprop="num_attr" content="0109">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Computer system 500</span>
        <span itemprop="definition">may further include a communication or network interface 524 .</span>
        <meta itemprop="num_attr" content="0110">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Communication interface 524</span>
        <span itemprop="definition">may enable computer system 500 to communicate and interact with any combination of external devices, external networks, external entities, etc. (individually and collectively referenced by reference number 528 ).</span>
        <meta itemprop="num_attr" content="0110">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">communication interface 524</span>
        <span itemprop="definition">may allow computer system 500 to communicate with external or remote devices 528 over communications path 526 , which may be wired and/or wireless (or a combination thereof), and which may include any combination of LANs, WANs, the Internet, etc.</span>
        <meta itemprop="num_attr" content="0110">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Control logic and/or data</span>
        <span itemprop="definition">may be transmitted to and from computer system 500 via communication path 526 .</span>
        <meta itemprop="num_attr" content="0110">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Computer system 500</span>
        <span itemprop="definition">may also be any of a personal digital assistant (PDA), desktop workstation, laptop or notebook computer, netbook, tablet, smart phone, smart watch or other wearable, appliance, part of the Internet-of-Things, and/or embedded system, to name a few non-limiting examples, or any combination thereof.</span>
        <meta itemprop="num_attr" content="0111">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">PDA</span>
        <span itemprop="definition">personal digital assistant</span>
        <meta itemprop="num_attr" content="0111">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Computer system 500</span>
        <span itemprop="definition">may be a client or server, accessing or hosting any applications and/or data through any delivery paradigm, including but not limited to remote or distributed cloud computing solutions; local or on-premises software (“on-premise” cloud-based solutions); “as a service” models (e.g., content as a service (CaaS), digital content as a service (DCaaS), software as a service (SaaS), managed software as a service (MSaaS), platform as a service (PaaS), desktop as a service (DaaS), framework as a service (FaaS), backend as a service (BaaS), mobile backend as a service (MBaaS), infrastructure as a service (IaaS), etc.); and/or a hybrid model including any combination of the foregoing examples or other services or delivery paradigms.</span>
        <meta itemprop="num_attr" content="0112">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">“as a service” models</span>
        <span itemprop="definition">e.g., content as a service (CaaS), digital content as a service (DCaaS), software as a</span>
        <meta itemprop="num_attr" content="0112">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Any applicable data structures, file formats, and schemas in computer system 500</span>
        <span itemprop="definition">may be derived from standards including but not limited to JavaScript Object Notation (JSON), Extensible Markup Language (XML), Yet Another Markup Language (YAML), Extensible Hypertext Markup Language (XHTML), Wireless Markup Language (WML), MessagePack, XML User Interface Language (XUL), or any other functionally similar representations alone or in combination.</span>
        <meta itemprop="num_attr" content="0113">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">JSON</span>
        <span itemprop="definition">JavaScript Object Notation</span>
        <meta itemprop="num_attr" content="0113">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">XML</span>
        <span itemprop="definition">Extensible Markup Language</span>
        <meta itemprop="num_attr" content="0113">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">YAML</span>
        <span itemprop="definition">Yet Another Markup Language</span>
        <meta itemprop="num_attr" content="0113">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">XHTML</span>
        <span itemprop="definition">Extensible Hypertext Markup Language</span>
        <meta itemprop="num_attr" content="0113">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">WML</span>
        <span itemprop="definition">Wireless Markup Language</span>
        <meta itemprop="num_attr" content="0113">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">MessagePack</span>
        <span itemprop="definition">XML User Interface Language</span>
        <meta itemprop="num_attr" content="0113">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">XUL</span>
        <span itemprop="definition">XML User Interface Language</span>
        <meta itemprop="num_attr" content="0113">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">a tangible, non-transitory apparatus or article of manufacture</span>
        <span itemprop="definition">comprising a tangible, non-transitory computer useable or readable medium having control logic (software) stored thereon may also be referred to herein as a computer program product or program storage device.</span>
        <meta itemprop="num_attr" content="0114">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">control logic</span>
        <span itemprop="definition">when executed by one or more data processing devices (such as computer system 500 or processor(s) 504 ), may cause such data processing devices to operate as described herein.</span>
        <meta itemprop="num_attr" content="0114">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">references herein to “one embodiment,” “an embodiment,” “an example embodiment,” or similar phrases</span>
        <span itemprop="definition">indicate that the embodiment described may include a particular feature, structure, or characteristic, but every embodiment may not necessarily include the particular feature, structure, or characteristic. Moreover, such phrases are not necessarily referring to the same embodiment. Further, when a particular feature, structure, or characteristic is described in connection with an embodiment, it would be within the knowledge of persons skilled in the relevant art(s) to incorporate such feature, structure, or characteristic into other embodiments whether or not explicitly mentioned or described herein. Additionally, some embodiments can be described using the expression “coupled” and “connected” along with their derivatives. These terms are not necessarily intended as synonyms for each other.</span>
        <meta itemprop="num_attr" content="0119">
      </li>
      <li itemprop="definitions" itemscope="" repeat="">
        <span itemprop="subject">Coupled</span>
        <span itemprop="definition">can also mean that two or more elements are not in direct contact with each other, but yet still co-operate or interact with each other.</span>
        <meta itemprop="num_attr" content="0119">
      </li>
    </ul>
  </section>

  


  <section itemprop="abstract" itemscope="">
    <h2>Abstract</h2>
    
    <div itemprop="content" html=""><abstract mxw-id="PA645596694" lang="EN" load-source="patent-office">
    <p>Disclosed herein are system, apparatus, article of manufacture, method and/or computer program product embodiments, and/or combinations and sub-combinations thereof, for ad insertion by a display device coupled to a media device via a high-definition media interface (HDMI) connection, where the media device provides media content and/or a control signal. When the media device pauses the media content, the display device can determine that a pause event has occurred and insert an ad shown on the display device. Further, some embodiments include determining the context and/or content of the media content that is paused, and determining an ad that is customized to the determined context and/or content to be displayed on the display device. In some embodiments, the display device can determine additional information from the control signal that may also be used to determine the ad to be displayed on the display device.</p>
  </abstract>
  </div>
  </section>

  <section itemprop="description" itemscope="">
    <h2>Description</h2>
    
    <div itemprop="content" html=""><ul mxw-id="PDES442137613" lang="EN" load-source="patent-office">
    
    <heading id="h-0001">CROSS-REFERENCE TO RELATED APPLICATIONS</heading>
    <li> <para-num num="[0001]"> </para-num> <p>This application is a continuation application of U.S. application Ser. No. 17/674,339, filed Feb. 17, 2022, which is incorporated herein in its entirety.</p>
    
    
    </li> <heading id="h-0002">BACKGROUND</heading>
    <heading id="h-0003">Field</heading>
    <li> <para-num num="[0002]"> </para-num> <p>This disclosure is generally directed to inserting ads for display and more particularly to inserting customized ads for display based on paused media content.</p>
    </li> <heading id="h-0004">Background</heading>
    <li> <para-num num="[0003]"> </para-num> <p>Content, such as a movie or TV show, is typically displayed on a television or other display screen for watching by users. Accordingly, a user's experience of the content is typically confined to the TV and to speakers connected to the TV. A user can control the consumption of media services by selecting media content for streaming, playing, pausing, and unpausing streaming media content.</p>
    </li> <heading id="h-0005">SUMMARY</heading>
    <li> <para-num num="[0004]"> </para-num> <p>Provided herein are system, apparatus, article of manufacture, method and/or computer program product embodiments, and/or combinations and sub-combinations thereof, for high-definition multimedia interface (HDMI) customized ad insertion. An example embodiment operates by detecting a pause event in one or more frames (e.g., audio or video frames) received via a HDMI connection, and during the pause event, recognizing content within the one or more frames. Some embodiments include receiving a control signal via the HDMI connection and determining information about the source device, and/or information about the application running on the source device. Some embodiments include determining an ad based on i) the content within the one or more frames, and/or ii) information about the source device and/or information about the application running on the source device. The ad can be displayed on the display device.</p>
    </li> <li> <para-num num="[0005]"> </para-num> <p>Some embodiments include a display device detecting a pause event in one or more frames received via an HDMI connection, and during the pause event, recognizing content within the one or more frames. Some embodiments include determining an ad based on the content within the one or more frames, and presenting the ad on the display device. Detecting the pause event can include: i) receiving a remote control pass through pause signal; ii) detecting a silent audio signal via the HDMI connection, and determining that a video frame of the one or more frames has not changed; and/or iii) detecting a pause icon from the one or more frames using computer vision (CV) technology, and detecting no change from a first video frame to a second video frame, where the first video frame and the second video frame are of the one or more frames.</p>
    </li> <li> <para-num num="[0006]"> </para-num> <p>In some embodiments, recognizing the content includes analyzing a first video frame or a first audio frame of the one or more frames using automatic content recognition (ACR) technology, and determining a fingerprint, a watermark, or a cue tone corresponding to the first video frame or the first audio frame, where the fingerprint, watermark, and/or cue tone is used to identify information about content corresponding to the first video frame or the first audio frame. In some embodiments, recognizing the content includes analyzing a first video frame of the one or more frames using CV technology, and determining metadata corresponding to the first video frame, where the metadata is used to identify one or more objects corresponding to the first video frame.</p>
    </li> <li> <para-num num="[0007]"> </para-num> <p>Some embodiments include receiving a control signal via the HDMI connection and determining service product description (SPD) from the control signal, where the ad is determined based on the SPD. Some embodiments further include detecting an auto low latency mode (ALLM) from the control signal, where the ad is based on the ALLM. Some embodiments further include detecting a variable refresh rate (VRR) from the control signal, where the ad is based on the VRR.</p>
    </li> <li> <para-num num="[0008]"> </para-num> <p>In some embodiments, determining the ad includes transmitting the VRR to a network, and receiving the ad corresponding to the VRR from the network. In some examples, determining the ad includes transmitting a fingerprint, watermark, cue tone, or metadata corresponding to the content to a network, and receiving a corresponding ad from the network.</p>
    </li> <li> <para-num num="[0009]"> </para-num> <p>Some embodiments include transmitting an SPD or an ALLM corresponding to a control signal received via the HDMI connection, to a network, and receiving an ad corresponding to the SPD or the ALLM from the network. Some embodiments include presenting the ad on a graphics plane of the display device, blending the graphics plane with a video plane comprising a first video frame of the one or more frames, and presenting the blended planes on the display device.</p>
    </li> <li> <para-num num="[0010]"> </para-num> <p>Further embodiments, features, and advantages of the present disclosure, as well as the structure and operation of the various embodiments of the present disclosure, are described in detail below with reference to the accompanying drawings.</p>
    
    
    </li> <description-of-drawings>
      <heading id="h-0006">BRIEF DESCRIPTION OF THE FIGURES</heading>
      <li> <para-num num="[0011]"> </para-num> <p>The accompanying drawings are incorporated herein and form a part of the specification.</p>
      </li> <li> <para-num num="[0012]"> </para-num> <div id="p-0013" num="0012"> <figref idrefs="DRAWINGS">FIG. <b>1</b> </figref><p> illustrates a block diagram of a multimedia environment, according to some embodiments.</p></div>
      </li> <li> <para-num num="[0013]"> </para-num> <div id="p-0014" num="0013"> <figref idrefs="DRAWINGS">FIG. <b>2</b> </figref><p> illustrates a block diagram of a streaming media device, according to some embodiments.</p></div>
      </li> <li> <para-num num="[0014]"> </para-num> <div id="p-0015" num="0014"> <figref idrefs="DRAWINGS">FIG. <b>3</b> </figref><p> illustrates a first block diagram of a display device, according to some embodiments.</p></div>
      </li> <li> <para-num num="[0015]"> </para-num> <div id="p-0016" num="0015"> <figref idrefs="DRAWINGS">FIG. <b>4</b> </figref><p> illustrates a method for a display device, according to some embodiments.</p></div>
      </li> <li> <para-num num="[0016]"> </para-num> <div id="p-0017" num="0016"> <figref idrefs="DRAWINGS">FIG. <b>5</b> </figref><p> illustrates an example computer system useful for implementing various embodiments.</p></div>
      </li> <li> <para-num num="[0017]"> </para-num> <div id="p-0018" num="0017"> <figref idrefs="DRAWINGS">FIG. <b>6</b> </figref><p> illustrates a block diagram of a second media device, according to some embodiments.</p></div>
      </li> <li> <para-num num="[0018]"> </para-num> <div id="p-0019" num="0018"> <figref idrefs="DRAWINGS">FIG. <b>7</b>A</figref><p> illustrates a block diagram of a second display device, according to some embodiments.</p></div>
      </li> <li> <para-num num="[0019]"> </para-num> <div id="p-0020" num="0019"> <figref idrefs="DRAWINGS">FIG. <b>7</b>B</figref><p> illustrates a block diagram of a third display device, according to some embodiments.</p></div>
      </li> <li> <para-num num="[0020]"> </para-num> <div id="p-0021" num="0020"> <figref idrefs="DRAWINGS">FIG. <b>8</b> </figref><p> illustrates a block diagram of a third media device, according to some embodiments.</p></div>
      </li> <li> <para-num num="[0021]"> </para-num> <div id="p-0022" num="0021"> <figref idrefs="DRAWINGS">FIG. <b>9</b> </figref><p> illustrates a block diagram of a fourth display device, according to some embodiments.</p></div>
    </li> </description-of-drawings>
    
    
    <li> <para-num num="[0022]"> </para-num> <p>In the drawings, like reference numbers generally indicate identical or similar elements. Additionally, generally, the left-most digit(s) of a reference number identifies the drawing in which the reference number first appears.</p>
    </li> <heading id="h-0007">DETAILED DESCRIPTION</heading>
    <li> <para-num num="[0023]"> </para-num> <p>Provided herein are system, apparatus, device, method and/or computer program product embodiments, and/or combinations and sub-combinations thereof, for ad insertion by a display device coupled via a high-definition media interface (HDMI) connection, to a media device where the media device provides media content. When the media device pauses the media content, the display device can determine that a pause event has occurred and insert an ad shown on the display device. In other words, the detection of the pause event can trigger the insertion of a relevant ad. After the pause event is detected, some embodiments include determining the context and/or content of the media content that is paused, and selecting an ad that is customized to the determined context and/or content to be displayed on the display device. In some embodiments, the display device may be coupled via a media interface connection other than HDMI to a media device.</p>
    </li> <li> <para-num num="[0024]"> </para-num> <div id="p-0025" num="0024"><p>Various embodiments of this disclosure may be implemented using and/or may be part of a </p><figure-callout id="102" label="multimedia environment" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">multimedia environment</figure-callout> <p><b>102</b> shown in </p><figref idrefs="DRAWINGS">FIG. <b>1</b> </figref><p>. It is noted, however, that </p><figure-callout id="102" label="multimedia environment" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">multimedia environment</figure-callout> <p><b>102</b> is provided solely for illustrative purposes, and is not limiting. Embodiments of this disclosure may be implemented using and/or may be part of environments different from and/or in addition to the </p><figure-callout id="102" label="multimedia environment" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">multimedia environment</figure-callout> <p><b>102</b>, as will be appreciated by persons skilled in the relevant art(s) based on the teachings contained herein. An example of the </p><figure-callout id="102" label="multimedia environment" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">multimedia environment</figure-callout> <p><b>102</b> shall now be described.</p></div>
    </li> <heading id="h-0008">Multimedia Environment</heading>
    <li> <para-num num="[0025]"> </para-num> <div id="p-0026" num="0025"> <figref idrefs="DRAWINGS">FIG. <b>1</b> </figref><p> illustrates a block diagram of a </p><figure-callout id="102" label="multimedia environment" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">multimedia environment</figure-callout> <p><b>102</b>, according to some embodiments. In a non-limiting example, </p><figure-callout id="102" label="multimedia environment" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">multimedia environment</figure-callout> <p><b>102</b> may be directed to streaming media. However, this disclosure is applicable to any type of media (instead of or in addition to streaming media), as well as any mechanism, means, protocol, method and/or process for distributing media.</p></div>
    </li> <li> <para-num num="[0026]"> </para-num> <div id="p-0027" num="0026"><p>The </p><figure-callout id="102" label="multimedia environment" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">multimedia environment</figure-callout> <p><b>102</b> may include one or </p><figure-callout id="104" label="more media systems" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">more media systems</figure-callout> <p><b>104</b>. A </p><figure-callout id="104" label="media system" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">media system</figure-callout> <p><b>104</b> could represent a family room, a kitchen, a backyard, a home theater, a school classroom, a library, a car, a boat, a bus, a plane, a movie theater, a stadium, an auditorium, a park, a bar, a restaurant, or any other location or space where it is desired to receive and play streaming content. User(s) <b>132</b> may operate with the </p><figure-callout id="104" label="media system" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">media system</figure-callout> <p><b>104</b> to select and consume content.</p></div>
    </li> <li> <para-num num="[0027]"> </para-num> <div id="p-0028" num="0027"><p>Each </p><figure-callout id="104" label="media system" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">media system</figure-callout> <p><b>104</b> may include one or </p><figure-callout id="106" label="more media devices" filenames="US20230388589A1-20231130-D00001.png,US20230388589A1-20231130-D00002.png" state="{{state}}">more media devices</figure-callout> <p><b>106</b> each coupled to one or </p><figure-callout id="108" label="more display devices" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">more display devices</figure-callout> <p><b>108</b>. It is noted that terms such as “coupled,” “connected to,” “attached,” “linked,” “combined” and similar terms may refer to physical, electrical, magnetic, logical, etc., connections, unless otherwise specified herein.</p></div>
    </li> <li> <para-num num="[0028]"> </para-num> <div id="p-0029" num="0028"> <figure-callout id="106" label="Media device" filenames="US20230388589A1-20231130-D00001.png,US20230388589A1-20231130-D00002.png" state="{{state}}">Media device</figure-callout> <p><b>106</b> may be a streaming media device, DVD or BLU-RAY device, audio/video playback device, cable box, and/or digital video recording device, to name just a few examples. </p><figure-callout id="108" label="Display device" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">Display device</figure-callout> <p><b>108</b> may be a monitor, television (TV), computer, smart phone, tablet, wearable (such as a watch or glasses), appliance, internet of things (IoT) device, and/or projector, to name just a few examples. In some embodiments, </p><figure-callout id="106" label="media device" filenames="US20230388589A1-20231130-D00001.png,US20230388589A1-20231130-D00002.png" state="{{state}}">media device</figure-callout> <p><b>106</b> can be a part of, integrated with, operatively coupled to, and/or connected to its </p><figure-callout id="108" label="respective display device" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">respective display device</figure-callout> <p><b>108</b>.</p></div>
    </li> <li> <para-num num="[0029]"> </para-num> <div id="p-0030" num="0029"><p>Each </p><figure-callout id="106" label="media device" filenames="US20230388589A1-20231130-D00001.png,US20230388589A1-20231130-D00002.png" state="{{state}}">media device</figure-callout> <p><b>106</b> may be configured to communicate with </p><figure-callout id="118" label="network" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">network</figure-callout> <p><b>118</b> via a </p><figure-callout id="114" label="communication device" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">communication device</figure-callout> <p><b>114</b>. The </p><figure-callout id="114" label="communication device" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">communication device</figure-callout> <p><b>114</b> may include, for example, a cable modem or satellite TV transceiver. The </p><figure-callout id="106" label="media device" filenames="US20230388589A1-20231130-D00001.png,US20230388589A1-20231130-D00002.png" state="{{state}}">media device</figure-callout> <p><b>106</b> may communicate with the </p><figure-callout id="114" label="communication device" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">communication device</figure-callout> <p><b>114</b> over a </p><figure-callout id="116" label="link" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">link</figure-callout> <p><b>116</b>, wherein the </p><figure-callout id="116" label="link" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">link</figure-callout> <p><b>116</b> may include wireless (such as WiFi) and/or wired connections.</p></div>
    </li> <li> <para-num num="[0030]"> </para-num> <div id="p-0031" num="0030"><p>In various embodiments, the </p><figure-callout id="118" label="network" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">network</figure-callout> <p><b>118</b> can include, without limitation, wired and/or wireless intranet, extranet, Internet, cellular, Bluetooth, infrared, and/or any other short range, long range, local, regional, global communications mechanism, means, approach, protocol and/or network, as well as any combination(s) thereof.</p></div>
    </li> <li> <para-num num="[0031]"> </para-num> <div id="p-0032" num="0031"> <figure-callout id="104" label="Media system" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">Media system</figure-callout> <p><b>104</b> may include a </p><figure-callout id="110" label="remote control" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">remote control</figure-callout> <p><b>110</b>. The </p><figure-callout id="110" label="remote control" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">remote control</figure-callout> <p><b>110</b> can be any component, part, apparatus and/or method for controlling the </p><figure-callout id="106" label="media device" filenames="US20230388589A1-20231130-D00001.png,US20230388589A1-20231130-D00002.png" state="{{state}}">media device</figure-callout> <p><b>106</b> and/or </p><figure-callout id="108" label="display device" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">display device</figure-callout> <p><b>108</b>, such as a remote control, a tablet, laptop computer, smartphone, wearable, on-screen controls, integrated control buttons, audio controls, or any combination thereof, to name just a few examples. In an embodiment, the </p><figure-callout id="110" label="remote control" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">remote control</figure-callout> <p><b>110</b> wirelessly communicates with the </p><figure-callout id="106" label="media device" filenames="US20230388589A1-20231130-D00001.png,US20230388589A1-20231130-D00002.png" state="{{state}}">media device</figure-callout> <p><b>106</b> and/or </p><figure-callout id="108" label="display device" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">display device</figure-callout> <p><b>108</b> using cellular, Bluetooth, infrared, etc., or any combination thereof. The </p><figure-callout id="110" label="remote control" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">remote control</figure-callout> <p><b>110</b> may include a </p><figure-callout id="112" label="microphone" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">microphone</figure-callout> <p><b>112</b>, which is further described below.</p></div>
    </li> <li> <para-num num="[0032]"> </para-num> <div id="p-0033" num="0032"><p>The </p><figure-callout id="102" label="multimedia environment" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">multimedia environment</figure-callout> <p><b>102</b> may include a plurality of content servers <b>120</b> (also called content providers, channels or sources). Although only one </p><figure-callout id="120" label="content server" filenames="US20230388589A1-20231130-D00001.png" state="{{state}}">content server</figure-callout> <p><b>120</b> is shown in </p><figref idrefs="DRAWINGS">FIG. <b>1</b> </figref><p>, in practice the </p><figure-callout id="102" label="multimedia environment" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">multimedia environment</figure-callout> <p><b>102</b> may include any number of </p><figure-callout id="120" label="content servers" filenames="US20230388589A1-20231130-D00001.png" state="{{state}}">content servers</figure-callout> <p><b>120</b>. Each </p><figure-callout id="120" label="content server" filenames="US20230388589A1-20231130-D00001.png" state="{{state}}">content server</figure-callout> <p><b>120</b> may be configured to communicate with </p><figure-callout id="118" label="network" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">network</figure-callout> <p><b>118</b>.</p></div>
    </li> <li> <para-num num="[0033]"> </para-num> <div id="p-0034" num="0033"><p>Each </p><figure-callout id="120" label="content server" filenames="US20230388589A1-20231130-D00001.png" state="{{state}}">content server</figure-callout> <p><b>120</b> may store </p><figure-callout id="122" label="content" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">content</figure-callout> <p><b>122</b> and </p><figure-callout id="124" label="metadata" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">metadata</figure-callout> <p><b>124</b>. </p><figure-callout id="122" label="Content" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">Content</figure-callout> <p><b>122</b> may include any combination of music, videos, movies, TV programs, multimedia, images, still pictures, text, graphics, gaming applications, advertisements, programming content, public service content, government content, local community content, software, and/or any other content or data objects in electronic form.</p></div>
    </li> <li> <para-num num="[0034]"> </para-num> <div id="p-0035" num="0034"><p>In some embodiments, </p><figure-callout id="124" label="metadata" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">metadata</figure-callout> <p><b>124</b> comprises data about </p><figure-callout id="122" label="content" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">content</figure-callout> <p><b>122</b>. For example, </p><figure-callout id="124" label="metadata" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">metadata</figure-callout> <p><b>124</b> may include associated or ancillary information indicating or related to writer, director, producer, composer, artist, actor, summary, chapters, production, history, year, trailers, alternate versions, related content, applications, and/or any other information pertaining or relating to the </p><figure-callout id="122" label="content" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">content</figure-callout> <p><b>122</b>. </p><figure-callout id="124" label="Metadata" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">Metadata</figure-callout> <p><b>124</b> may also or alternatively include links to any such information pertaining or relating to the </p><figure-callout id="122" label="content" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">content</figure-callout> <p><b>122</b>. </p><figure-callout id="124" label="Metadata" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">Metadata</figure-callout> <p><b>124</b> may also or alternatively include one or more indexes of </p><figure-callout id="122" label="content" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">content</figure-callout> <p><b>122</b>, such as but not limited to a trick mode index.</p></div>
    </li> <li> <para-num num="[0035]"> </para-num> <div id="p-0036" num="0035"><p>The </p><figure-callout id="102" label="multimedia environment" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">multimedia environment</figure-callout> <p><b>102</b> may include one or </p><figure-callout id="126" label="more system servers" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">more system servers</figure-callout> <p><b>126</b>. The </p><figure-callout id="126" label="system servers" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">system servers</figure-callout> <p><b>126</b> may operate to support the </p><figure-callout id="106" label="media devices" filenames="US20230388589A1-20231130-D00001.png,US20230388589A1-20231130-D00002.png" state="{{state}}">media devices</figure-callout> <p><b>106</b> from the cloud. It is noted that the structural and functional aspects of the </p><figure-callout id="126" label="system servers" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">system servers</figure-callout> <p><b>126</b> may wholly or partially exist in the same or different ones of the </p><figure-callout id="126" label="system servers" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">system servers</figure-callout> <p><b>126</b>.</p></div>
    </li> <li> <para-num num="[0036]"> </para-num> <div id="p-0037" num="0036"><p>The </p><figure-callout id="126" label="system servers" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">system servers</figure-callout> <p><b>126</b> may also include an audio </p><figure-callout id="130" label="command processing module" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">command processing module</figure-callout> <p><b>130</b>. As noted above, the </p><figure-callout id="110" label="remote control" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">remote control</figure-callout> <p><b>110</b> may include a </p><figure-callout id="112" label="microphone" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">microphone</figure-callout> <p><b>112</b>. The </p><figure-callout id="112" label="microphone" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">microphone</figure-callout> <p><b>112</b> may receive audio data from users <b>132</b> (as well as other sources, such as the display device <b>108</b>). In some embodiments, the </p><figure-callout id="106" label="media device" filenames="US20230388589A1-20231130-D00001.png,US20230388589A1-20231130-D00002.png" state="{{state}}">media device</figure-callout> <p><b>106</b> may be audio responsive, and the audio data may represent verbal commands from the </p><figure-callout id="132" label="user" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">user</figure-callout> <p><b>132</b> to control the </p><figure-callout id="106" label="media device" filenames="US20230388589A1-20231130-D00001.png,US20230388589A1-20231130-D00002.png" state="{{state}}">media device</figure-callout> <p><b>106</b> as well as other components in the </p><figure-callout id="104" label="media system" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">media system</figure-callout> <p><b>104</b>, such as the </p><figure-callout id="108" label="display device" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">display device</figure-callout> <p><b>108</b>. In some embodiments, the audio data received by the </p><figure-callout id="112" label="microphone" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">microphone</figure-callout> <p><b>112</b> in the </p><figure-callout id="110" label="remote control" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">remote control</figure-callout> <p><b>110</b> is transferred to the </p><figure-callout id="106" label="media device" filenames="US20230388589A1-20231130-D00001.png,US20230388589A1-20231130-D00002.png" state="{{state}}">media device</figure-callout> <p><b>106</b>, which is then forwarded to the audio </p><figure-callout id="130" label="command processing module" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">command processing module</figure-callout> <p><b>130</b> in the </p><figure-callout id="126" label="system servers" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">system servers</figure-callout> <p><b>126</b>. The audio </p><figure-callout id="130" label="command processing module" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">command processing module</figure-callout> <p><b>130</b> may operate to process and analyze the received audio data to recognize the </p><figure-callout id="132" label="user" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">user</figure-callout> <p><b>132</b>'s verbal command. The audio </p><figure-callout id="130" label="command processing module" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">command processing module</figure-callout> <p><b>130</b> may then forward the verbal command back to the </p><figure-callout id="106" label="media device" filenames="US20230388589A1-20231130-D00001.png,US20230388589A1-20231130-D00002.png" state="{{state}}">media device</figure-callout> <p><b>106</b> for processing.</p></div>
    </li> <li> <para-num num="[0037]"> </para-num> <div id="p-0038" num="0037"><p>In some embodiments, the audio data may be alternatively or additionally processed and analyzed by an audio </p><figure-callout id="216" label="command processing module" filenames="US20230388589A1-20231130-D00002.png" state="{{state}}">command processing module</figure-callout> <p><b>216</b> in the media device <b>106</b> (see </p><figref idrefs="DRAWINGS">FIG. <b>2</b> </figref><p>). The </p><figure-callout id="106" label="media device" filenames="US20230388589A1-20231130-D00001.png,US20230388589A1-20231130-D00002.png" state="{{state}}">media device</figure-callout> <p><b>106</b> and the </p><figure-callout id="126" label="system servers" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">system servers</figure-callout> <p><b>126</b> may then cooperate to pick one of the verbal commands to process (either the verbal command recognized by the audio </p><figure-callout id="130" label="command processing module" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">command processing module</figure-callout> <p><b>130</b> in the </p><figure-callout id="126" label="system servers" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">system servers</figure-callout> <p><b>126</b>, or the verbal command recognized by the audio </p><figure-callout id="216" label="command processing module" filenames="US20230388589A1-20231130-D00002.png" state="{{state}}">command processing module</figure-callout> <p><b>216</b> in the media device <b>106</b>).</p></div>
    </li> <li> <para-num num="[0038]"> </para-num> <div id="p-0039" num="0038"> <figref idrefs="DRAWINGS">FIG. <b>2</b> </figref><p> illustrates a block diagram of an </p><figure-callout id="106" label="example media device" filenames="US20230388589A1-20231130-D00001.png,US20230388589A1-20231130-D00002.png" state="{{state}}">example media device</figure-callout> <p><b>106</b>, according to some embodiments. </p><figure-callout id="106" label="Media device" filenames="US20230388589A1-20231130-D00001.png,US20230388589A1-20231130-D00002.png" state="{{state}}">Media device</figure-callout> <p><b>106</b> may include a </p><figure-callout id="202" label="streaming module" filenames="US20230388589A1-20231130-D00002.png" state="{{state}}">streaming module</figure-callout> <p><b>202</b>, </p><figure-callout id="204" label="processing module" filenames="US20230388589A1-20231130-D00002.png" state="{{state}}">processing module</figure-callout> <p><b>204</b>, storage/</p><figure-callout id="208" label="buffers" filenames="US20230388589A1-20231130-D00002.png" state="{{state}}">buffers</figure-callout> <p><b>208</b>, and </p><figure-callout id="206" label="user interface module" filenames="US20230388589A1-20231130-D00002.png" state="{{state}}">user interface module</figure-callout> <p><b>206</b>. As described above, the </p><figure-callout id="206" label="user interface module" filenames="US20230388589A1-20231130-D00002.png" state="{{state}}">user interface module</figure-callout> <p><b>206</b> may include the audio </p><figure-callout id="216" label="command processing module" filenames="US20230388589A1-20231130-D00002.png" state="{{state}}">command processing module</figure-callout> <p><b>216</b>.</p></div>
    </li> <li> <para-num num="[0039]"> </para-num> <div id="p-0040" num="0039"><p>The </p><figure-callout id="106" label="media device" filenames="US20230388589A1-20231130-D00001.png,US20230388589A1-20231130-D00002.png" state="{{state}}">media device</figure-callout> <p><b>106</b> may also include one or more </p><figure-callout id="212" label="audio decoders" filenames="US20230388589A1-20231130-D00002.png" state="{{state}}">audio decoders</figure-callout> <p><b>212</b> and one or </p><figure-callout id="214" label="more video decoders" filenames="US20230388589A1-20231130-D00002.png" state="{{state}}">more video decoders</figure-callout> <p><b>214</b>.</p></div>
    </li> <li> <para-num num="[0040]"> </para-num> <div id="p-0041" num="0040"><p>Each </p><figure-callout id="212" label="audio decoder" filenames="US20230388589A1-20231130-D00002.png" state="{{state}}">audio decoder</figure-callout> <p><b>212</b> may be configured to decode audio of one or more audio formats, such as but not limited to AAC, HE-AAC, AC3 (Dolby Digital), EAC3 (Dolby Digital Plus), WMA, WAV, PCM, MP3, OGG GSM, FLAC, AU, AIFF, and/or VOX, to name just some examples.</p></div>
    </li> <li> <para-num num="[0041]"> </para-num> <div id="p-0042" num="0041"><p>Similarly, each </p><figure-callout id="214" label="video decoder" filenames="US20230388589A1-20231130-D00002.png" state="{{state}}">video decoder</figure-callout> <p><b>214</b> may be configured to decode video of one or more video formats, such as but not limited to MP4 (mp4, m4a, m4v, f4v, f4a, m4b, m4r, f4b, mov), 3GP (3gp, 3gp2, 3g2, 3gpp, 3gpp2), OGG (ogg, oga, ogv, ogx), WMV (wmv, wma, asf), WEBM, FLV, AVI, QuickTime, HDV, MXF (OPla, OP-Atom), MPEG-TS, MPEG-2 PS, MPEG-2 TS, WAV, Broadcast WAV, LXF, GXF, and/or VOB, to name just some examples. Each </p><figure-callout id="214" label="video decoder" filenames="US20230388589A1-20231130-D00002.png" state="{{state}}">video decoder</figure-callout> <p><b>214</b> may include one or more video codecs, such as but not limited to H.263, H.264, HEV, MPEG1, MPEG2, MPEG-TS, MPEG-4, Theora, 3GP, DV, DVCPRO, DVCPRO, DVCProHD, IMX, XDCAM HD, XDCAM HD422, and/or XDCAM EX, to name just some examples.</p></div>
    </li> <li> <para-num num="[0042]"> </para-num> <div id="p-0043" num="0042"><p>Now referring to both </p><figref idrefs="DRAWINGS">FIGS. <b>1</b> and <b>2</b> </figref><p>, in some embodiments, the </p><figure-callout id="132" label="user" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">user</figure-callout> <p><b>132</b> may interact with the </p><figure-callout id="106" label="media device" filenames="US20230388589A1-20231130-D00001.png,US20230388589A1-20231130-D00002.png" state="{{state}}">media device</figure-callout> <p><b>106</b> via, for example, the </p><figure-callout id="110" label="remote control" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">remote control</figure-callout> <p><b>110</b>. For example, the </p><figure-callout id="132" label="user" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">user</figure-callout> <p><b>132</b> may use the </p><figure-callout id="110" label="remote control" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">remote control</figure-callout> <p><b>110</b> to interact with the </p><figure-callout id="206" label="user interface module" filenames="US20230388589A1-20231130-D00002.png" state="{{state}}">user interface module</figure-callout> <p><b>206</b> of the </p><figure-callout id="106" label="media device" filenames="US20230388589A1-20231130-D00001.png,US20230388589A1-20231130-D00002.png" state="{{state}}">media device</figure-callout> <p><b>106</b> to select content, such as a movie, TV show, music, book, application, game, etc. The </p><figure-callout id="202" label="streaming module" filenames="US20230388589A1-20231130-D00002.png" state="{{state}}">streaming module</figure-callout> <p><b>202</b> of the </p><figure-callout id="106" label="media device" filenames="US20230388589A1-20231130-D00001.png,US20230388589A1-20231130-D00002.png" state="{{state}}">media device</figure-callout> <p><b>106</b> may request the selected content from the content server(s) <b>120</b> over the </p><figure-callout id="118" label="network" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">network</figure-callout> <p><b>118</b>. The content server(s) <b>120</b> may transmit the requested content to the </p><figure-callout id="202" label="streaming module" filenames="US20230388589A1-20231130-D00002.png" state="{{state}}">streaming module</figure-callout> <p><b>202</b>. The </p><figure-callout id="106" label="media device" filenames="US20230388589A1-20231130-D00001.png,US20230388589A1-20231130-D00002.png" state="{{state}}">media device</figure-callout> <p><b>106</b> may transmit the received content to the </p><figure-callout id="108" label="display device" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">display device</figure-callout> <p><b>108</b> for playback to the </p><figure-callout id="132" label="user" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">user</figure-callout> <p><b>132</b>.</p></div>
    </li> <li> <para-num num="[0043]"> </para-num> <div id="p-0044" num="0043"><p>In streaming embodiments, the </p><figure-callout id="202" label="streaming module" filenames="US20230388589A1-20231130-D00002.png" state="{{state}}">streaming module</figure-callout> <p><b>202</b> may transmit the content to the </p><figure-callout id="108" label="display device" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">display device</figure-callout> <p><b>108</b> in real time or near real time as it receives such content from the content server(s) <b>120</b>. In non-streaming embodiments, the </p><figure-callout id="106" label="media device" filenames="US20230388589A1-20231130-D00001.png,US20230388589A1-20231130-D00002.png" state="{{state}}">media device</figure-callout> <p><b>106</b> may store the content received from content server(s) <b>120</b> in storage/</p><figure-callout id="208" label="buffers" filenames="US20230388589A1-20231130-D00002.png" state="{{state}}">buffers</figure-callout> <p><b>208</b> for later playback on </p><figure-callout id="108" label="display device" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">display device</figure-callout> <p><b>108</b>.</p></div>
    </li> <heading id="h-0009">HDMI Customized Ad Insertion</heading>
    <li> <para-num num="[0044]"> </para-num> <div id="p-0045" num="0044"><p>Referring to </p><figref idrefs="DRAWINGS">FIG. <b>1</b> </figref><p>, </p><figure-callout id="106" label="media device" filenames="US20230388589A1-20231130-D00001.png,US20230388589A1-20231130-D00002.png" state="{{state}}">media device</figure-callout> <p><b>106</b> may be a streaming media device (e.g., a set top box or a gaming device) coupled to </p><figure-callout id="108" label="display device" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">display device</figure-callout> <p><b>108</b> via an HDMI connection <b>107</b> (e.g., an HDMI cable). For example, </p><figure-callout id="132" label="user" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">user</figure-callout> <p><b>132</b> may select HDMI as a source input for media streaming on </p><figure-callout id="108" label="display device" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">display device</figure-callout> <p><b>108</b>. </p><figure-callout id="132" label="User" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">User</figure-callout> <p><b>132</b> may use </p><figure-callout id="110" label="remote control" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">remote control</figure-callout> <p><b>110</b> to communicate with </p><figure-callout id="106" label="media device" filenames="US20230388589A1-20231130-D00001.png,US20230388589A1-20231130-D00002.png" state="{{state}}">media device</figure-callout> <p><b>106</b> via </p><figure-callout id="111" label="radio interface" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">radio interface</figure-callout> <p><b>111</b>. In previous solutions, when </p><figure-callout id="132" label="user" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">user</figure-callout> <p><b>132</b> paused media content provided by media device <b>106</b> (e.g., a source device) the corresponding video frames may be paused (e.g., halted). In some </p><figure-callout id="106" label="examples media device" filenames="US20230388589A1-20231130-D00001.png,US20230388589A1-20231130-D00002.png" state="{{state}}">examples media device</figure-callout> <p><b>106</b> may transmit a pause icon in a signal and the pause icon may be presented on display device <b>108</b> (e.g., a smart TV). In previous solutions, </p><figure-callout id="108" label="display device" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">display device</figure-callout> <p><b>108</b> did not detect a pause event. Consequently, </p><figure-callout id="108" label="display device" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">display device</figure-callout> <p><b>108</b> would not insert an ad during the pause event, or analyze the content and/or context of the paused media content to determine a customized ad, and display the customized ad on a graphics plane of </p><figure-callout id="108" label="display device" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">display device</figure-callout> <p><b>108</b>.</p></div>
    </li> <li> <para-num num="[0045]"> </para-num> <div id="p-0046" num="0045"> <figref idrefs="DRAWINGS">FIG. <b>6</b> </figref><p> illustrates a block diagram of </p><figure-callout id="600" label="media device" filenames="US20230388589A1-20231130-D00006.png" state="{{state}}">media device</figure-callout> <p><b>600</b>, according to some embodiments. For illustration purposes and not a limitation, </p><figure-callout id="600" label="media device" filenames="US20230388589A1-20231130-D00006.png" state="{{state}}">media device</figure-callout> <p><b>600</b> may be described with reference to elements from other figures in the disclosure. For example, </p><figure-callout id="680" label="HDMI output" filenames="US20230388589A1-20231130-D00006.png" state="{{state}}">HDMI output</figure-callout> <p><b>680</b> may support </p><figure-callout id="107" label="HDMI connection" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">HDMI connection</figure-callout> <p><b>107</b> of </p><figref idrefs="DRAWINGS">FIG. <b>1</b> </figref><p>, where </p><figure-callout id="107" label="HDMI connection" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">HDMI connection</figure-callout> <p><b>107</b> is coupled to </p><figure-callout id="108" label="display device" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">display device</figure-callout> <p><b>108</b> of </p><figref idrefs="DRAWINGS">FIG. <b>1</b> </figref><p>. User interface module <b>620</b> and audio </p><figure-callout id="625" label="command processing module" filenames="US20230388589A1-20231130-D00006.png" state="{{state}}">command processing module</figure-callout> <p><b>625</b> can correspond to </p><figure-callout id="206" label="user interface module" filenames="US20230388589A1-20231130-D00002.png" state="{{state}}">user interface module</figure-callout> <p><b>206</b> and audio </p><figure-callout id="216" label="command processing module" filenames="US20230388589A1-20231130-D00002.png" state="{{state}}">command processing module</figure-callout> <p><b>216</b> of </p><figref idrefs="DRAWINGS">FIG. <b>2</b> </figref><p>. </p><figure-callout id="630" label="Processor" filenames="US20230388589A1-20231130-D00006.png" state="{{state}}">Processor</figure-callout> <p><b>630</b> may correspond to </p><figure-callout id="204" label="processing module" filenames="US20230388589A1-20231130-D00002.png" state="{{state}}">processing module</figure-callout> <p><b>204</b> of </p><figref idrefs="DRAWINGS">FIG. <b>2</b> </figref><p>. Buffers/</p><figure-callout id="640" label="storage" filenames="US20230388589A1-20231130-D00006.png" state="{{state}}">storage</figure-callout> <p><b>640</b>, </p><figure-callout id="660" label="audio decoder" filenames="US20230388589A1-20231130-D00006.png" state="{{state}}">audio decoder</figure-callout> <p><b>660</b>, and </p><figure-callout id="650" label="video decoder" filenames="US20230388589A1-20231130-D00006.png" state="{{state}}">video decoder</figure-callout> <p><b>650</b> may correspond to storage/</p><figure-callout id="208" label="buffers" filenames="US20230388589A1-20231130-D00002.png" state="{{state}}">buffers</figure-callout> <p><b>208</b>, audio decoder(s) <b>212</b>, and video decoder(s) <b>214</b> of </p><figref idrefs="DRAWINGS">FIG. <b>2</b> </figref><p>.</p></div>
    </li> <li> <para-num num="[0046]"> </para-num> <div id="p-0047" num="0046"> <figure-callout id="600" label="Media device" filenames="US20230388589A1-20231130-D00006.png" state="{{state}}">Media device</figure-callout> <p><b>600</b> includes </p><figure-callout id="610" label="applications" filenames="US20230388589A1-20231130-D00006.png" state="{{state}}">applications</figure-callout> <p><b>610</b> that can include </p><figure-callout id="612" label="streaming applications" filenames="US20230388589A1-20231130-D00006.png" state="{{state}}">streaming applications</figure-callout> <p><b>612</b>, broadcast/</p><figure-callout id="614" label="tuner" filenames="US20230388589A1-20231130-D00006.png" state="{{state}}">tuner</figure-callout> <p><b>614</b>, USB inputs <b>616</b>, and </p><figure-callout id="618" label="gaming application" filenames="US20230388589A1-20231130-D00006.png" state="{{state}}">gaming application</figure-callout> <p><b>618</b>. In some embodiments, </p><figure-callout id="600" label="media device" filenames="US20230388589A1-20231130-D00006.png" state="{{state}}">media device</figure-callout> <p><b>600</b> can be a gaming device. </p><figure-callout id="610" label="Applications" filenames="US20230388589A1-20231130-D00006.png" state="{{state}}">Applications</figure-callout> <p><b>610</b> can be a source of information. </p><figure-callout id="630" label="Processor" filenames="US20230388589A1-20231130-D00006.png" state="{{state}}">Processor</figure-callout> <p><b>630</b> can extract audio and video data from corresponding applications and place the extracted audio and video data into buffers/</p><figure-callout id="640" label="storage" filenames="US20230388589A1-20231130-D00006.png" state="{{state}}">storage</figure-callout> <p><b>640</b>. After audio and video decoding, </p><figure-callout id="670" label="post processing module" filenames="US20230388589A1-20231130-D00006.png" state="{{state}}">post processing module</figure-callout> <p><b>670</b> can perform scaling of images, color improvements, and lip synching functions, for example, before outputting video frames via </p><figure-callout id="680" label="HDMI output" filenames="US20230388589A1-20231130-D00006.png" state="{{state}}">HDMI output</figure-callout> <p><b>680</b> to a display device (e.g., </p><figure-callout id="108" label="display device" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">display device</figure-callout> <p><b>108</b> of </p><figref idrefs="DRAWINGS">FIG. <b>1</b> </figref><p>, </p><figure-callout id="108" label="display device" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">display device</figure-callout> <p><b>108</b> of </p><figref idrefs="DRAWINGS">FIG. <b>3</b> </figref><p>, </p><figure-callout id="700" label="display device" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">display device</figure-callout> <p><b>700</b> of </p><figref idrefs="DRAWINGS">FIG. <b>7</b>A</figref><p>, </p><figure-callout id="705" label="display device" filenames="US20230388589A1-20231130-D00008.png" state="{{state}}">display device</figure-callout> <p><b>705</b> of </p><figref idrefs="DRAWINGS">FIG. <b>7</b>B</figref><p>, and/or </p><figure-callout id="900" label="display device" filenames="US20230388589A1-20231130-D00010.png" state="{{state}}">display device</figure-callout> <p><b>900</b> of </p><figref idrefs="DRAWINGS">FIG. <b>9</b> </figref><p>). In some embodiments, </p><figure-callout id="600" label="media device" filenames="US20230388589A1-20231130-D00006.png" state="{{state}}">media device</figure-callout> <p><b>600</b> transmits a service product description (SPD), auto low latency mode (ALLM), or a variable refresh rate (VRR) to </p><figure-callout id="700" label="display device" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">display device</figure-callout> <p><b>700</b> of </p><figref idrefs="DRAWINGS">FIG. <b>7</b>A</figref><p>, </p><figure-callout id="705" label="display device" filenames="US20230388589A1-20231130-D00008.png" state="{{state}}">display device</figure-callout> <p><b>705</b> of </p><figref idrefs="DRAWINGS">FIG. <b>7</b>B</figref><p>, or </p><figure-callout id="900" label="display device" filenames="US20230388589A1-20231130-D00010.png" state="{{state}}">display device</figure-callout> <p><b>900</b> of </p><figref idrefs="DRAWINGS">FIG. <b>9</b> </figref><p>.</p></div>
    </li> <li> <para-num num="[0047]"> </para-num> <div id="p-0048" num="0047"> <figref idrefs="DRAWINGS">FIG. <b>8</b> </figref><p> illustrates a block diagram of </p><figure-callout id="800" label="media device" filenames="US20230388589A1-20231130-D00009.png" state="{{state}}">media device</figure-callout> <p><b>800</b>, according to some embodiments. For illustration purposes and not a limitation, </p><figure-callout id="800" label="media device" filenames="US20230388589A1-20231130-D00009.png" state="{{state}}">media device</figure-callout> <p><b>800</b> may be described with reference to elements from other figures in the disclosure. For example, </p><figure-callout id="880" label="HDMI output" filenames="US20230388589A1-20231130-D00009.png" state="{{state}}">HDMI output</figure-callout> <p><b>880</b>, </p><figure-callout id="830" label="processor" filenames="US20230388589A1-20231130-D00009.png" state="{{state}}">processor</figure-callout> <p><b>830</b>, buffers/</p><figure-callout id="840" label="storage" filenames="US20230388589A1-20231130-D00009.png" state="{{state}}">storage</figure-callout> <p><b>840</b>, </p><figure-callout id="860" label="audio decoder" filenames="US20230388589A1-20231130-D00009.png" state="{{state}}">audio decoder</figure-callout> <p><b>860</b>, and </p><figure-callout id="850" label="video decoder" filenames="US20230388589A1-20231130-D00009.png" state="{{state}}">video decoder</figure-callout> <p><b>850</b></p><figure-callout id="800" label="media device" filenames="US20230388589A1-20231130-D00009.png" state="{{state}}">media device</figure-callout> <p><b>800</b> may correspond to </p><figure-callout id="680" label="HDMI output" filenames="US20230388589A1-20231130-D00006.png" state="{{state}}">HDMI output</figure-callout> <p><b>680</b>, </p><figure-callout id="630" label="processor" filenames="US20230388589A1-20231130-D00006.png" state="{{state}}">processor</figure-callout> <p><b>630</b>, buffers/</p><figure-callout id="640" label="storage" filenames="US20230388589A1-20231130-D00006.png" state="{{state}}">storage</figure-callout> <p><b>640</b>, </p><figure-callout id="660" label="audio decoder" filenames="US20230388589A1-20231130-D00006.png" state="{{state}}">audio decoder</figure-callout> <p><b>660</b>, and </p><figure-callout id="650" label="video decoder" filenames="US20230388589A1-20231130-D00006.png" state="{{state}}">video decoder</figure-callout> <p><b>650</b> of </p><figure-callout id="600" label="media device" filenames="US20230388589A1-20231130-D00006.png" state="{{state}}">media device</figure-callout> <p><b>600</b> of </p><figref idrefs="DRAWINGS">FIG. <b>6</b> </figref><p>.</p></div>
    </li> <li> <para-num num="[0048]"> </para-num> <div id="p-0049" num="0048"> <figure-callout id="800" label="Media device" filenames="US20230388589A1-20231130-D00009.png" state="{{state}}">Media device</figure-callout> <p><b>800</b> includes </p><figure-callout id="810" label="applications" filenames="US20230388589A1-20231130-D00009.png" state="{{state}}">applications</figure-callout> <p><b>810</b> that may be a data source including but not limited to input </p><figure-callout id="816" label="application" filenames="US20230388589A1-20231130-D00009.png" state="{{state}}">application</figure-callout> <p><b>816</b>, </p><figure-callout id="814" label="network application" filenames="US20230388589A1-20231130-D00009.png" state="{{state}}">network application</figure-callout> <p><b>814</b>, and media application <b>817</b>. </p><figure-callout id="816" label="Input application" filenames="US20230388589A1-20231130-D00009.png" state="{{state}}">Input application</figure-callout> <p><b>816</b> can include but is not limited to input applications corresponding to a joystick, a microphone, and/or a remote control device. </p><figure-callout id="814" label="Network application" filenames="US20230388589A1-20231130-D00009.png" state="{{state}}">Network application</figure-callout> <p><b>814</b> can include but is not limited to Wi-Fi™, Bluetooth™, Zigbee™, and/or a tuner. Media application <b>817</b> can include but is not limited to a transport stream, a movie, a game, and/or music.</p></div>
    </li> <li> <para-num num="[0049]"> </para-num> <div id="p-0050" num="0049"> <figure-callout id="830" label="Processor" filenames="US20230388589A1-20231130-D00009.png" state="{{state}}">Processor</figure-callout> <p><b>830</b> can extract audio and video data from corresponding applications and place the extracted audio and video data into buffers/</p><figure-callout id="840" label="storage" filenames="US20230388589A1-20231130-D00009.png" state="{{state}}">storage</figure-callout> <p><b>840</b>. After audio and video decoding, output video frames are transmitted via </p><figure-callout id="880" label="HDMI output" filenames="US20230388589A1-20231130-D00009.png" state="{{state}}">HDMI output</figure-callout> <p><b>880</b> to a display device (e.g., </p><figure-callout id="108" label="display device" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">display device</figure-callout> <p><b>108</b> of </p><figref idrefs="DRAWINGS">FIG. <b>1</b> </figref><p>, </p><figure-callout id="108" label="display device" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">display device</figure-callout> <p><b>108</b> of </p><figref idrefs="DRAWINGS">FIG. <b>3</b> </figref><p>, </p><figure-callout id="700" label="display device" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">display device</figure-callout> <p><b>700</b> of </p><figref idrefs="DRAWINGS">FIG. <b>7</b>A</figref><p>, </p><figure-callout id="705" label="display device" filenames="US20230388589A1-20231130-D00008.png" state="{{state}}">display device</figure-callout> <p><b>705</b> of </p><figref idrefs="DRAWINGS">FIG. <b>7</b>B</figref><p>, and/or </p><figure-callout id="900" label="display device" filenames="US20230388589A1-20231130-D00010.png" state="{{state}}">display device</figure-callout> <p><b>900</b> of </p><figref idrefs="DRAWINGS">FIG. <b>9</b> </figref><p>). In some embodiments, </p><figure-callout id="800" label="media device" filenames="US20230388589A1-20231130-D00009.png" state="{{state}}">media device</figure-callout> <p><b>800</b> transmits an SPD, an ALLM, or a VRR to display </p><figure-callout id="700" label="device" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">device</figure-callout> <p><b>700</b>, </p><figure-callout id="705" label="display device" filenames="US20230388589A1-20231130-D00008.png" state="{{state}}">display device</figure-callout> <p><b>705</b> of </p><figref idrefs="DRAWINGS">FIG. <b>7</b>B</figref><p>, or </p><figure-callout id="900" label="display device" filenames="US20230388589A1-20231130-D00010.png" state="{{state}}">display device</figure-callout> <p><b>900</b> of </p><figref idrefs="DRAWINGS">FIG. <b>9</b> </figref><p>.</p></div>
    </li> <li> <para-num num="[0050]"> </para-num> <div id="p-0051" num="0050"> <figref idrefs="DRAWINGS">FIG. <b>3</b> </figref><p> illustrates a block diagram of </p><figure-callout id="108" label="display device" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">display device</figure-callout> <p><b>108</b>, according to some embodiments. For illustration purposes and not a limitation, </p><figure-callout id="108" label="display device" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">display device</figure-callout> <p><b>108</b> may be described with reference to elements from other figures in the disclosure. For example, </p><figure-callout id="310" label="HDMI module" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">HDMI module</figure-callout> <p><b>310</b> may support </p><figure-callout id="107" label="HDMI connection" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">HDMI connection</figure-callout> <p><b>107</b> of </p><figref idrefs="DRAWINGS">FIG. <b>1</b> </figref><p>, where </p><figure-callout id="107" label="HDMI connection" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">HDMI connection</figure-callout> <p><b>107</b> is coupled to </p><figure-callout id="106" label="media device" filenames="US20230388589A1-20231130-D00001.png,US20230388589A1-20231130-D00002.png" state="{{state}}">media device</figure-callout> <p><b>106</b> of </p><figref idrefs="DRAWINGS">FIG. <b>1</b> </figref><p> or </p><figref idrefs="DRAWINGS">FIG. <b>2</b> </figref><p>. </p><figure-callout id="108" label="Display device" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">Display device</figure-callout> <p><b>108</b> can include </p><figure-callout id="320" label="ACR module" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">ACR module</figure-callout> <p><b>320</b>, </p><figure-callout id="325" label="CV module" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">CV module</figure-callout> <p><b>325</b>, </p><figure-callout id="330" label="ad insertion module" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">ad insertion module</figure-callout> <p><b>330</b>, </p><figure-callout id="340" label="processing module" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">processing module</figure-callout> <p><b>340</b>, video scaling and frame rate conversion (FRC) </p><figure-callout id="350" label="module" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">module</figure-callout> <p><b>350</b>, </p><figure-callout id="360" label="graphics module" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">graphics module</figure-callout> <p><b>360</b>, </p><figure-callout id="370" label="display module" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">display module</figure-callout> <p><b>370</b>, and </p><figure-callout id="380" label="memory" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">memory</figure-callout> <p><b>380</b>. </p><figure-callout id="390" label="Bus" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">Bus</figure-callout> <p><b>390</b> can coupled the elements of </p><figure-callout id="108" label="display device" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">display device</figure-callout> <p><b>108</b>.</p></div>
    </li> <li> <para-num num="[0051]"> </para-num> <div id="p-0052" num="0051"> <figure-callout id="320" label="ACR module" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">ACR module</figure-callout> <p><b>320</b> can analyze a video frame and generate a unique fingerprint and/or unique watermark with information about the content of the video frame. For example, the unique fingerprint and/or watermark may include multiple patches of content within the video frame. The unique fingerprint and/or watermark may be compared against a known reference fingerprint or reference watermark to identify the video content based on the match. The match may identify for example, a movie title, actor, rating, where the movie can be found for viewing, production house, etc. In some examples, the unique fingerprint and/or watermark can correspond to content particular to the video frame itself. The fingerprints and/or watermark generated from different consecutive video frames can be compared. If two or more generated fingerprints and/or watermarks are the same, that can indicate no change in content (e.g., the video or movie may be paused.)</p></div>
    </li> <li> <para-num num="[0052]"> </para-num> <div id="p-0053" num="0052"><p>In some embodiments, </p><figure-callout id="320" label="ACR module" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">ACR module</figure-callout> <p><b>320</b> can analyze an audio frame and generate a unique fingerprint and/or unique watermark with information about the content of the audio frame. For example, the unique fingerprint and/or watermark may include multiple patches of content within the audio frame. The unique fingerprint and/or watermark may be compared against a known reference fingerprint or reference watermark to identify the audio content based on the match. The match may identify for example, a movie title, actor, rating, where the movie can be found for viewing, production house, etc. In some examples, the unique fingerprint and/or watermark can correspond to content particular to the audio frame itself. The fingerprints and/or watermark generated from different consecutive audio frames can be compared. If two or more generated fingerprints and/or watermarks are the same, that can indicate no change in content (e.g., the audio or movie may be paused.)</p></div>
    </li> <li> <para-num num="[0053]"> </para-num> <div id="p-0054" num="0053"><p>In some </p><figure-callout id="320" label="embodiments ACR module" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">embodiments ACR module</figure-callout> <p><b>320</b> can analyze a video frame and/or an audio frame and generate a unique cue tone (e.g., a cue tone compliant with American National Standards Institute (ANSI)/Society of Cable and Telecommunications Engineers (SCTE) standards defined in ANSI/SCTE 35 2013) with information about the content of the video frame and/or audio frame.</p></div>
    </li> <li> <para-num num="[0054]"> </para-num> <div id="p-0055" num="0054"> <figure-callout id="325" label="CV module" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">CV module</figure-callout> <p><b>325</b> can analyze a video frame and generate metadata. The metadata can be used to recognize objects within the video frame, or one or more video frames. The metadata can for example, recognize images and/or objects within the video frame. Examples of the metadata can include for example, items depicted in the video frame such as a bicycle, car, a beer bottle, a mountain, and/or scenery.</p></div>
    </li> <li> <para-num num="[0055]"> </para-num> <div id="p-0056" num="0055"> <figure-callout id="108" label="Display device" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">Display device</figure-callout> <p><b>108</b> can detect a pause event by using: i) a remote control pass through function; ii) a silent audio signal; and/or iii) pause icon recognition.</p></div>
    </li> <li> <para-num num="[0056]"> </para-num> <div id="p-0057" num="0056"><p>In some embodiments, </p><figure-callout id="108" label="display device" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">display device</figure-callout> <p><b>108</b> may use a remote control pass through function to detect a pause event. For example, </p><figure-callout id="106" label="media device" filenames="US20230388589A1-20231130-D00001.png,US20230388589A1-20231130-D00002.png" state="{{state}}">media device</figure-callout> <p><b>106</b> may be configured to support Consumer Electronics Control (CEC) (e.g., remote control pass through) functions including but not limited to: power on, power off, pause key, play key, and so on. For example, </p><figure-callout id="132" label="user" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">user</figure-callout> <p><b>132</b> using </p><figure-callout id="110" label="remote control" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">remote control</figure-callout> <p><b>110</b> can transmit a pause key via </p><figure-callout id="111" label="radio interface" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">radio interface</figure-callout> <p><b>111</b> to the media device which transmits the pause key signal to display </p><figure-callout id="108" label="device" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">device</figure-callout> <p><b>108</b>. In this example, </p><figure-callout id="108" label="display device" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">display device</figure-callout> <p><b>108</b> can readily detect a pause event based on the pause key signal being received from the media device across </p><figure-callout id="107" label="HDMI connection" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">HDMI connection</figure-callout> <p><b>107</b>. The detection of the pause event may be performed in hardware by processing </p><figure-callout id="340" label="module" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">module</figure-callout> <p><b>340</b>, by processing </p><figure-callout id="340" label="module" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">module</figure-callout> <p><b>340</b> executing software stored in </p><figure-callout id="380" label="memory" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">memory</figure-callout> <p><b>380</b>, or a combination thereof. </p><figure-callout id="340" label="Processing module" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">Processing module</figure-callout> <p><b>340</b> may include one or more processors, for example.</p></div>
    </li> <li> <para-num num="[0057]"> </para-num> <div id="p-0058" num="0057"><p>In some embodiments, </p><figure-callout id="108" label="display device" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">display device</figure-callout> <p><b>108</b> can detect a pause event based on a silent audio signal received from </p><figure-callout id="106" label="media device" filenames="US20230388589A1-20231130-D00001.png,US20230388589A1-20231130-D00002.png" state="{{state}}">media device</figure-callout> <p><b>106</b> as well as determining that one or more video frames received from </p><figure-callout id="106" label="media device" filenames="US20230388589A1-20231130-D00001.png,US20230388589A1-20231130-D00002.png" state="{{state}}">media device</figure-callout> <p><b>106</b> is not changing. The unchanging video frames in conjunction with the silent audio signal can be used to determine that a pause event is detected. A silent audio signal can be an audio signal corresponding to one or more video or audio frames received from </p><figure-callout id="106" label="media device" filenames="US20230388589A1-20231130-D00001.png,US20230388589A1-20231130-D00002.png" state="{{state}}">media device</figure-callout> <p><b>106</b> that may not be within a human audible frequency range. In other words, the silent audio signal volume is so low that </p><figure-callout id="132" label="user" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">user</figure-callout> <p><b>132</b> may not hear the silent audio signal, but the silent audio signal is present. In addition to detecting a silent audio signal, </p><figure-callout id="108" label="display device" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">display device</figure-callout> <p><b>108</b> can determine that one or more video frames received are not changing by utilizing periodic sampling. In some examples, </p><figure-callout id="320" label="ACR module" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">ACR module</figure-callout> <p><b>320</b> and/or </p><figure-callout id="325" label="CV module" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">CV module</figure-callout> <p><b>325</b> can be used to determine that contents are not changing between consecutive video frames.</p></div>
    </li> <li> <para-num num="[0058]"> </para-num> <div id="p-0059" num="0058"><p>In some embodiments, a fingerprint and/or watermark can be generated by </p><figure-callout id="320" label="ACR module" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">ACR module</figure-callout> <p><b>320</b> for each frame received and the generated fingerprints or watermarks can be compared. If the generated fingerprints and/or watermarks are different, then the one or more video frames are changing and a pause event is unlikely, even if a silent audio signal is detected. If however, the fingerprints and/or watermarks are the same (e.g., fingerprints and/or watermarks from 3-4 consecutive frames are unchanged) and a silent audio signal is detected, then display </p><figure-callout id="108" label="device" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">device</figure-callout> <p><b>108</b> determines that a pause event is detected. In other words, </p><figure-callout id="132" label="user" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">user</figure-callout> <p><b>132</b> may have paused streaming data at </p><figure-callout id="106" label="media device" filenames="US20230388589A1-20231130-D00001.png,US20230388589A1-20231130-D00002.png" state="{{state}}">media device</figure-callout> <p><b>106</b>, perhaps by using </p><figure-callout id="110" label="remote control" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">remote control</figure-callout> <p><b>110</b>. The detection of the silent audio signal and/or the comparison of the fingerprints and/or watermarks from different video frames can be performed in hardware by processing </p><figure-callout id="340" label="module" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">module</figure-callout> <p><b>340</b>, by processing </p><figure-callout id="340" label="module" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">module</figure-callout> <p><b>340</b> executing software stored in </p><figure-callout id="380" label="memory" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">memory</figure-callout> <p><b>380</b>, or a combination thereof.</p></div>
    </li> <li> <para-num num="[0059]"> </para-num> <div id="p-0060" num="0059"><p>In some embodiments, metadata can be generated by </p><figure-callout id="325" label="CV module" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">CV module</figure-callout> <p><b>325</b> for each frame received and the generated metadata can be compared. If the generated metadata are different, then the one or more video frames are changing and a pause event is unlikely, even if a silent audio signal is detected. If however, the metadata for each frame are the same (e.g., metadata from 3-4 consecutive frames are unchanged) and a silent audio signal is detected, then display </p><figure-callout id="108" label="device" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">device</figure-callout> <p><b>108</b> determines that a pause event is detected. In other words, </p><figure-callout id="132" label="user" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">user</figure-callout> <p><b>132</b> may have paused streaming data at </p><figure-callout id="106" label="media device" filenames="US20230388589A1-20231130-D00001.png,US20230388589A1-20231130-D00002.png" state="{{state}}">media device</figure-callout> <p><b>106</b>, perhaps by using </p><figure-callout id="110" label="remote control" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">remote control</figure-callout> <p><b>110</b>. The detection of the silent audio signal and/or the comparison of the metadata from different video frames can be performed in hardware by processing </p><figure-callout id="340" label="module" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">module</figure-callout> <p><b>340</b>, by processing </p><figure-callout id="340" label="module" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">module</figure-callout> <p><b>340</b> executing software stored in </p><figure-callout id="380" label="memory" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">memory</figure-callout> <p><b>380</b>, or a combination thereof.</p></div>
    </li> <li> <para-num num="[0060]"> </para-num> <div id="p-0061" num="0060"><p>In some embodiments, </p><figure-callout id="108" label="display device" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">display device</figure-callout> <p><b>108</b> can detect a pause event based on a recognition of a pause icon. For example, </p><figure-callout id="325" label="CV module" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">CV module</figure-callout> <p><b>325</b> can analyze media content (e.g., one or more video frames) received via </p><figure-callout id="107" label="HDMI connection" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">HDMI connection</figure-callout> <p><b>107</b> from </p><figure-callout id="106" label="media device" filenames="US20230388589A1-20231130-D00001.png,US20230388589A1-20231130-D00002.png" state="{{state}}">media device</figure-callout> <p><b>106</b> to generate metadata that identifies objects in a video frame (e.g., a type of car, an actor, a pause icon, a penguin, or a bee on a flower.) When a pause icon is detected in one or more consecutive video frames received via </p><figure-callout id="310" label="HDMI module" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">HDMI module</figure-callout> <p><b>310</b>, then a pause event is detected. The detection of the pause icon in one or more consecutive video frames can be performed in hardware by processing </p><figure-callout id="340" label="module" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">module</figure-callout> <p><b>340</b>, by processing </p><figure-callout id="340" label="module" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">module</figure-callout> <p><b>340</b> executing software stored in </p><figure-callout id="380" label="memory" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">memory</figure-callout> <p><b>380</b>, or a combination thereof.</p></div>
    </li> <li> <para-num num="[0061]"> </para-num> <div id="p-0062" num="0061"><p>After </p><figure-callout id="108" label="display device" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">display device</figure-callout> <p><b>108</b> determines that a pause event is detected (e.g., based on a remote control pass through function, a silent audio detected with unchanging video frames, or a pause icon detected with no motion in video frames), </p><figure-callout id="108" label="display device" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">display device</figure-callout> <p><b>108</b> can perform content recognition on the video frame and/or audio frame of the pause event (e.g., a scene of a movie that is paused). In some embodiments, </p><figure-callout id="320" label="ACR module" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">ACR module</figure-callout> <p><b>320</b> may generate a fingerprint and/or watermark for the video frame and/or the audio frame. In some embodiments, </p><figure-callout id="325" label="CV module" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">CV module</figure-callout> <p><b>325</b> may generate metadata that corresponds to objects identified or recognized within the video frame.</p></div>
    </li> <li> <para-num num="[0062]"> </para-num> <div id="p-0063" num="0062"> <figure-callout id="108" label="Display device" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">Display device</figure-callout> <p><b>108</b> can use the fingerprint, watermark, and/or the metadata to determine one or more appropriate ads (e.g., advertisements), add the ad(s) to a graphics plane, and present the ad(s) on </p><figure-callout id="108" label="display device" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">display device</figure-callout> <p><b>108</b> for a portion of or a duration of the pause event. For example, after the pause event detection (e.g., </p><figure-callout id="330" label="ad insertion module" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">ad insertion module</figure-callout> <p><b>330</b> may receive a notice of the pause event detection from processing module <b>340</b>) the corresponding fingerprint and/or watermark from </p><figure-callout id="320" label="ACR module" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">ACR module</figure-callout> <p><b>320</b>, and/or the corresponding metadata from </p><figure-callout id="325" label="CV module" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">CV module</figure-callout> <p><b>325</b>. </p><figure-callout id="330" label="Ad insertion module" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">Ad insertion module</figure-callout> <p><b>330</b> can use the corresponding fingerprint, watermark, and/or metadata to select one or more relevant ads to be presented on </p><figure-callout id="108" label="display device" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">display device</figure-callout> <p><b>108</b>. The fingerprint and/or watermark may correspond to a certain movie title, famous actor, and movie genre. The metadata may correspond to a champagne bottle and mountain scenery. The relevant ads may include the famous actor, a type of champagne, vacation opportunities that include the mountain scenery recognized. The one or more relevant ads may be static (e.g., a still image) or dynamic (e.g., a gif, a short video, an animation, an interactive screen). In some embodiments, input from </p><figure-callout id="132" label="user" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">user</figure-callout> <p><b>132</b> regarding the interactive screen (e.g., a survey) can be collected and transmitted to crowdsource </p><figure-callout id="128" label="server" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">server</figure-callout> <p><b>128</b>. In some embodiments in response to input corresponding to the one or more relevant ads, additional information may be transmitted to a mobile device corresponding to a customer account associated with display device <b>108</b> (e.g., email, text).</p></div>
    </li> <li> <para-num num="[0063]"> </para-num> <div id="p-0064" num="0063"> <figure-callout id="330" label="Ad insertion module" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">Ad insertion module</figure-callout> <p><b>330</b> may transmit the one or more relevant ads to </p><figure-callout id="360" label="graphics module" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">graphics module</figure-callout> <p><b>360</b> to be added to a graphics plane (not shown) of </p><figure-callout id="108" label="display device" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">display device</figure-callout> <p><b>108</b>. The one or more video frames that are received may be received and processed by video scaling and </p><figure-callout id="350" label="FRC" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">FRC</figure-callout> <p><b>350</b>. The one or more video frames can be added to a video plane of display device <b>108</b> (e.g., a last video frame used in the detection of the pause event can be added to the video plane). In some embodiments, the video plane and the graphics plane can be blended (e.g., merged) together and the data of the blended planes can be received by </p><figure-callout id="370" label="display module" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">display module</figure-callout> <p><b>370</b> for presentation on </p><figure-callout id="108" label="display device" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">display device</figure-callout> <p><b>108</b>. In some embodiments the graphics plane may be displayed in front of the video plane (e.g., overlaid to be viewed on top of the video plane). In some embodiments the images and/or ads of the graphics plane can be transparent. In some embodiments a selection function from </p><figure-callout id="110" label="remote control" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">remote control</figure-callout> <p><b>110</b> can be passed through </p><figure-callout id="106" label="media device" filenames="US20230388589A1-20231130-D00001.png,US20230388589A1-20231130-D00002.png" state="{{state}}">media device</figure-callout> <p><b>106</b> to display </p><figure-callout id="108" label="device" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">device</figure-callout> <p><b>108</b> to make a selection from the graphics plane. The functions above may be performed by </p><figure-callout id="340" label="processing module" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">processing module</figure-callout> <p><b>340</b>, executing software of the various modules that may be stored in </p><figure-callout id="380" label="memory" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">memory</figure-callout> <p><b>380</b>, or a combination of hardware and software.</p></div>
    </li> <li> <para-num num="[0064]"> </para-num> <div id="p-0065" num="0064"> <figref idrefs="DRAWINGS">FIG. <b>7</b>A</figref><p> illustrates a block diagram of </p><figure-callout id="700" label="display device" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">display device</figure-callout> <p><b>700</b>, according to some embodiments. For example, </p><figure-callout id="700" label="display device" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">display device</figure-callout> <p><b>700</b> may utilize control signal information received via an HDMI connection in addition to video frames, to determine appropriate and relevant ads to present on </p><figure-callout id="700" label="display device" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">display device</figure-callout> <p><b>700</b>. In some embodiments the relevant ads are presented on </p><figure-callout id="700" label="display device" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">display device</figure-callout> <p><b>700</b> during a pause event.</p></div>
    </li> <li> <para-num num="[0065]"> </para-num> <div id="p-0066" num="0065"><p>For illustration purposes and not a limitation, </p><figure-callout id="700" label="display device" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">display device</figure-callout> <p><b>700</b> may be described with reference to elements from other figures in the disclosure. For example, HDMI input <b>710</b> may support </p><figure-callout id="107" label="HDMI connection" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">HDMI connection</figure-callout> <p><b>107</b> of </p><figref idrefs="DRAWINGS">FIG. <b>1</b> </figref><p>, where </p><figure-callout id="107" label="HDMI connection" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">HDMI connection</figure-callout> <p><b>107</b> is coupled to </p><figure-callout id="106" label="media device" filenames="US20230388589A1-20231130-D00001.png,US20230388589A1-20231130-D00002.png" state="{{state}}">media device</figure-callout> <p><b>106</b> of </p><figref idrefs="DRAWINGS">FIG. <b>1</b> </figref><p>. </p><figure-callout id="710" label="HDMI input" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">HDMI input</figure-callout> <p><b>710</b>, </p><figure-callout id="730" label="ACR" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">ACR</figure-callout> <p><b>730</b>, </p><figure-callout id="740" label="computer vision" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">computer vision</figure-callout> <p><b>740</b>, </p><figure-callout id="750" label="ad insertion" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">ad insertion</figure-callout> <p><b>750</b>, </p><figure-callout id="770" label="graphics module" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">graphics module</figure-callout> <p><b>770</b>, </p><figure-callout id="780" label="memory" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">memory</figure-callout> <p><b>780</b>, and video scaling and </p><figure-callout id="782" label="FRC" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">FRC</figure-callout> <p><b>782</b>, and </p><figure-callout id="790" label="display panel" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">display panel</figure-callout> <p><b>790</b> can correspond respectively to </p><figure-callout id="310" label="HDMI module" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">HDMI module</figure-callout> <p><b>310</b>, </p><figure-callout id="320" label="ACR module" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">ACR module</figure-callout> <p><b>320</b>, </p><figure-callout id="325" label="CV module" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">CV module</figure-callout> <p><b>325</b>, </p><figure-callout id="330" label="ad insertion module" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">ad insertion module</figure-callout> <p><b>330</b>, </p><figure-callout id="360" label="graphics module" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">graphics module</figure-callout> <p><b>360</b>, </p><figure-callout id="380" label="memory" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">memory</figure-callout> <p><b>380</b>, video scaling and </p><figure-callout id="350" label="FRC" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">FRC</figure-callout> <p><b>350</b>, and </p><figure-callout id="370" label="display module" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">display module</figure-callout> <p><b>370</b> of </p><figref idrefs="DRAWINGS">FIG. <b>3</b> </figref><p>.</p></div>
    </li> <li> <para-num num="[0066]"> </para-num> <div id="p-0067" num="0066"><p>In some embodiments, </p><figure-callout id="700" label="display device" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">display device</figure-callout> <p><b>700</b> may be coupled via HDMI connection to a media device (e.g., </p><figure-callout id="600" label="media device" filenames="US20230388589A1-20231130-D00006.png" state="{{state}}">media device</figure-callout> <p><b>600</b> of </p><figref idrefs="DRAWINGS">FIG. <b>6</b> </figref><p> or </p><figure-callout id="800" label="media device" filenames="US20230388589A1-20231130-D00009.png" state="{{state}}">media device</figure-callout> <p><b>800</b> of </p><figref idrefs="DRAWINGS">FIG. <b>8</b> </figref><p>). In some embodiments, </p><figure-callout id="600" label="media device" filenames="US20230388589A1-20231130-D00006.png" state="{{state}}">media device</figure-callout> <p><b>600</b> can be a gaming device. </p><figure-callout id="700" label="Display device" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">Display device</figure-callout> <p><b>700</b> can receive video frames as well as one or more control signals from </p><figure-callout id="600" label="media device" filenames="US20230388589A1-20231130-D00006.png" state="{{state}}">media device</figure-callout> <p><b>600</b> via </p><figure-callout id="710" label="HDMI input" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">HDMI input</figure-callout> <p><b>710</b>. The control signals can include a product information signal, a latency mode signal, or a refresh rate signal from </p><figure-callout id="600" label="media device" filenames="US20230388589A1-20231130-D00006.png" state="{{state}}">media device</figure-callout> <p><b>600</b>. </p><figure-callout id="722" label="Product information function" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">Product information function</figure-callout> <p><b>722</b> can be a function of </p><figure-callout id="720" label="processor" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">processor</figure-callout> <p><b>720</b> that determines SPD about the source, such as </p><figure-callout id="600" label="media device" filenames="US20230388589A1-20231130-D00006.png" state="{{state}}">media device</figure-callout> <p><b>600</b>, from the product information signal. Examples of SPD include the type of gaming device platform, and/or the model of the gaming device platform. As an example, the product information signal can include an SPD InfoFrame that communicates the name and product type of a source device such as media device <b>600</b> (e.g., a video game console) to a sink such as display device <b>700</b> (e.g., a television (TV)). When a video game console is coupled to a TV, the video game console may transmit the following SPD via the product information signal to display </p><figure-callout id="700" label="device" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">device</figure-callout> <p><b>700</b>. The SPD can include the following:
</p></div> </li> <ul> <li id="ul0001-0001" num="0000"> <ul> <li id="ul0002-0001" num="0067">Source Information=8 (indicating e.g., a game)</li> <li id="ul0002-0002" num="0068">Vendor Name=Company A</li> <li id="ul0002-0003" num="0069">Product Description=Video game console model 1</li> </ul> </li> </ul>

    <li> <para-num num="[0070]"> </para-num> <div id="p-0068" num="0070"><p>Using the above SPD information, </p><figure-callout id="700" label="display device" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">display device</figure-callout> <p><b>700</b> can display an advertisement of a newer model of </p><figure-callout id="600" label="media device" filenames="US20230388589A1-20231130-D00006.png" state="{{state}}">media device</figure-callout> <p><b>600</b>, in this example, a newer model than video game console model 1. </p><figure-callout id="700" label="Display device" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">Display device</figure-callout> <p><b>700</b> can also display an advertisement of a competitor product.</p></div>
    </li> <li> <para-num num="[0071]"> </para-num> <div id="p-0069" num="0071"> <figure-callout id="724" label="Latency mode function" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">Latency mode function</figure-callout> <p><b>724</b> can be a function of </p><figure-callout id="720" label="processor" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">processor</figure-callout> <p><b>720</b> that determines an ALLM from a latency mode signal received from </p><figure-callout id="600" label="media device" filenames="US20230388589A1-20231130-D00006.png" state="{{state}}">media device</figure-callout> <p><b>600</b>. The ALLM can indicate whether or not </p><figure-callout id="618" label="gaming application" filenames="US20230388589A1-20231130-D00006.png" state="{{state}}">gaming application</figure-callout> <p><b>618</b> running (e.g., executing) on </p><figure-callout id="600" label="media device" filenames="US20230388589A1-20231130-D00006.png" state="{{state}}">media device</figure-callout> <p><b>600</b> is a low latency application. Accordingly, </p><figure-callout id="700" label="display device" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">display device</figure-callout> <p><b>700</b> utilizes resources to enable corresponding low latency performance supporting </p><figure-callout id="618" label="gaming application" filenames="US20230388589A1-20231130-D00006.png" state="{{state}}">gaming application</figure-callout> <p><b>618</b>. For example, the ALLM enables media device <b>600</b> (e.g., a source like a video game console) to automatically enable or disable the low latency performance of display device <b>700</b> (e.g., a sink like a TV) without requiring a user to navigate to menus of display device <b>700</b> (e.g., the sink's menus) to set the optimal latency corresponding to the content of media device <b>600</b> (e.g., </p><figure-callout id="618" label="gaming application" filenames="US20230388589A1-20231130-D00006.png" state="{{state}}">gaming application</figure-callout> <p><b>618</b> such as the video game console gaming content). </p><figure-callout id="600" label="Media device" filenames="US20230388589A1-20231130-D00006.png" state="{{state}}">Media device</figure-callout> <p><b>600</b> may transmit the latency mode signal via an HDMI Forum Vendor Specific Info Frame (HF-VSIF). The 5th byte in an HF-VSIF may include an ALLM_Mode field which can be either 0 or 1. If ALLM_Mode=1, media device <b>600</b> (e.g., a source like the video game console) requests that display device <b>700</b> (e.g., a sink like a TV) switches to game mode. If ALLM_Mode=0, </p><figure-callout id="600" label="media device" filenames="US20230388589A1-20231130-D00006.png" state="{{state}}">media device</figure-callout> <p><b>600</b> requests that display </p><figure-callout id="700" label="device" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">device</figure-callout> <p><b>700</b> turns off game mode. Accordingly, </p><figure-callout id="724" label="latency mode function" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">latency mode function</figure-callout> <p><b>724</b> can determine (a value of) the ALLM that can be used as an indication that the user has started playing a game and hence relevant advertisements related to the game can be displayed to the user via </p><figure-callout id="700" label="display device" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">display device</figure-callout> <p><b>700</b>.</p></div>
    </li> <li> <para-num num="[0072]"> </para-num> <div id="p-0070" num="0072"> <figure-callout id="726" label="Refresh rate function" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">Refresh rate function</figure-callout> <p><b>726</b> can be a function of </p><figure-callout id="720" label="processor" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">processor</figure-callout> <p><b>720</b> that determines a VRR for advanced gaming applications from the refresh rate signal. In some embodiments, the VRR can be a dynamic display refresh rate that can continuously and seamlessly vary on the fly (e.g., change during streaming). The VRR can be transmitted by </p><figure-callout id="600" label="media device" filenames="US20230388589A1-20231130-D00006.png" state="{{state}}">media device</figure-callout> <p><b>600</b> using a Video Timing Extended Metadata Packet (EMP) in the refresh rate signal. Using the VRR, </p><figure-callout id="700" label="display device" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">display device</figure-callout> <p><b>700</b> can advertise sources and/or applications that offer similarly advanced types of VRR and/or more advanced types of VRR (e.g., VRRs supported by Free Sync offered by AMD graphics cards or GSync offered by NVIDIA graphics cards). In some embodiments, </p><figure-callout id="700" label="display device" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">display device</figure-callout> <p><b>700</b> can utilize the control signal information (e.g., SPD from </p><figure-callout id="722" label="product information function" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">product information function</figure-callout> <p><b>722</b>, ALLM from </p><figure-callout id="724" label="latency mode function" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">latency mode function</figure-callout> <p><b>724</b>, and/or VRR from refresh rate function <b>726</b>) to determine relevant ads to be presented on </p><figure-callout id="790" label="display panel" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">display panel</figure-callout> <p><b>790</b>.</p></div>
    </li> <li> <para-num num="[0073]"> </para-num> <div id="p-0071" num="0073"><p>In some embodiments, </p><figure-callout id="700" label="display device" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">display device</figure-callout> <p><b>700</b> may detect a pause event by using: i) a remote control pass through function; ii) a silent audio signal; and/or iii) pause icon recognition. For example, </p><figure-callout id="700" label="display device" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">display device</figure-callout> <p><b>700</b> can readily detect a pause event based on a pause key signal (e.g. a remote control pass through function) being received from the media device across an HDMI connection (e.g., HDMI connection <b>107</b>) via </p><figure-callout id="710" label="HDMI input" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">HDMI input</figure-callout> <p><b>710</b>. The detection of a pause event may be performed in hardware by </p><figure-callout id="720" label="processor" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">processor</figure-callout> <p><b>720</b>, by </p><figure-callout id="720" label="processor" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">processor</figure-callout> <p><b>720</b> executing software stored in </p><figure-callout id="780" label="memory" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">memory</figure-callout> <p><b>780</b>, or a combination thereof. </p><figure-callout id="720" label="Processor" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">Processor</figure-callout> <p><b>720</b> may include one or more processors, for example. In some embodiments, </p><figure-callout id="720" label="processor" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">processor</figure-callout> <p><b>720</b> may execute software stored in a different memory (not shown).</p></div>
    </li> <li> <para-num num="[0074]"> </para-num> <div id="p-0072" num="0074"><p>In some embodiments, </p><figure-callout id="700" label="display device" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">display device</figure-callout> <p><b>700</b> can detect a pause event based on a silent audio signal received from the media device (e.g., </p><figure-callout id="106" label="media device" filenames="US20230388589A1-20231130-D00001.png,US20230388589A1-20231130-D00002.png" state="{{state}}">media device</figure-callout> <p><b>106</b>, </p><figure-callout id="600" label="media device" filenames="US20230388589A1-20231130-D00006.png" state="{{state}}">media device</figure-callout> <p><b>600</b>, or media device <b>800</b>) as well as determine that one or more video frames received from the media device is not changing. For example, a fingerprint and/or watermark can be generated by </p><figure-callout id="730" label="ACR" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">ACR</figure-callout> <p><b>730</b> for each frame received and the generated fingerprints and/or watermarks can be compared. In some embodiments, </p><figure-callout id="740" label="CV" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">CV</figure-callout> <p><b>740</b> can generate metadata for each video frame received and generated metadata from consecutive video frames can be compared. When the fingerprints, watermarks, and/or metadata from consecutive video frames are unchanged in conjunction with a silent audio signal, then a pause event is detected. The detection of a pause event based on the silent audio signal and the unchanging video frames may be performed in hardware by </p><figure-callout id="720" label="processor" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">processor</figure-callout> <p><b>720</b>, by </p><figure-callout id="720" label="processor" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">processor</figure-callout> <p><b>720</b> executing software stored in </p><figure-callout id="780" label="memory" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">memory</figure-callout> <p><b>780</b>, or a combination thereof. </p><figure-callout id="720" label="Processor" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">Processor</figure-callout> <p><b>720</b> may include one or more processors, for example. In some embodiments, </p><figure-callout id="720" label="processor" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">processor</figure-callout> <p><b>720</b> may execute software stored in a different memory (not shown).</p></div>
    </li> <li> <para-num num="[0075]"> </para-num> <div id="p-0073" num="0075"><p>In some embodiments, </p><figure-callout id="108" label="display device" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">display device</figure-callout> <p><b>108</b> can detect a pause event based on pause icon recognition. For example, </p><figure-callout id="740" label="CV" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">CV</figure-callout> <p><b>740</b> can analyze media content (e.g., one or more video frames) received via HDMI input <b>710</b> from the media device to generate metadata that identifies objects (e.g., a pause icon) in a video frame. When metadata from one or more consecutive video frames received include a pause icon, and a determination is made that the video frames are not changing, a processor can determine that a pause event has been detected. The detection of a pause icon and the unchanging video frames may be performed in hardware by </p><figure-callout id="720" label="processor" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">processor</figure-callout> <p><b>720</b>, by </p><figure-callout id="720" label="processor" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">processor</figure-callout> <p><b>720</b> executing software stored in </p><figure-callout id="780" label="memory" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">memory</figure-callout> <p><b>780</b>, or a combination thereof. </p><figure-callout id="720" label="Processor" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">Processor</figure-callout> <p><b>720</b> may include one or more processors, for example. In some embodiments, </p><figure-callout id="720" label="processor" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">processor</figure-callout> <p><b>720</b> may execute software stored in a different memory (not shown).</p></div>
    </li> <li> <para-num num="[0076]"> </para-num> <div id="p-0074" num="0076"><p>After </p><figure-callout id="700" label="display device" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">display device</figure-callout> <p><b>700</b> determines that a pause event is detected (e.g., based on a remote control pass through function, silent audio detected with unchanging video frames, and/or a pause icon recognition with no motion of the video frames), </p><figure-callout id="700" label="display device" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">display device</figure-callout> <p><b>700</b> can perform content recognition on the video frame of the pause event (e.g., a scene of a movie that is paused) to determine relevant ads to be presented on </p><figure-callout id="790" label="display panel" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">display panel</figure-callout> <p><b>790</b> for a period of or duration of the pause event. For example, </p><figure-callout id="730" label="ACR" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">ACR</figure-callout> <p><b>730</b> may generate a fingerprint and/or watermark for the video frame that enables determination of the video (e.g., the movie) including the video frame, and data associated with the video (e.g., actors, movie title, genre). In some embodiments, </p><figure-callout id="740" label="computer vision" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">computer vision</figure-callout> <p><b>740</b> may generate metadata that corresponds to objects (e.g., champagne bottle, mountain scenery) identified or recognized within the video frame. The fingerprints, watermarks, and/or metadata generated can be used to determine relevant ad to be displayed on </p><figure-callout id="700" label="display device" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">display device</figure-callout> <p><b>700</b> for a portion of or the duration of the pause event.</p></div>
    </li> <li> <para-num num="[0077]"> </para-num> <div id="p-0075" num="0077"><p>In some embodiments, after </p><figure-callout id="700" label="display device" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">display device</figure-callout> <p><b>700</b> determines that a pause event is detected (e.g., based on a remote control pass through function, silent audio detected with unchanging video frames, and/or a pause icon recognition with no motion of the video frames), </p><figure-callout id="700" label="display device" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">display device</figure-callout> <p><b>700</b> can perform content recognition on an audio frame of the pause event (e.g., a scene of a movie that is paused) to determine relevant ads to be presented on </p><figure-callout id="790" label="display panel" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">display panel</figure-callout> <p><b>790</b> for a period of or duration of the pause event. For example, </p><figure-callout id="730" label="ACR" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">ACR</figure-callout> <p><b>730</b> may generate a fingerprint and/or watermark for the audio frame that enables determination of the content (e.g., the movie) including the audio frame, and data associated with the audio frame (e.g., actors, movie title, genre). The fingerprints, watermarks, and/or metadata (from computer vision <b>740</b>) generated can be used to determine relevant ad to be displayed on </p><figure-callout id="700" label="display device" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">display device</figure-callout> <p><b>700</b> for a portion of or the duration of the pause event.</p></div>
    </li> <li> <para-num num="[0078]"> </para-num> <div id="p-0076" num="0078"><p>In some embodiments, after </p><figure-callout id="700" label="display device" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">display device</figure-callout> <p><b>700</b> determines that a pause event is detected (e.g., based on a remote control pass through function, silent audio detected with unchanging video frames, and/or a pause icon and no motion of the video frames), </p><figure-callout id="700" label="display device" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">display device</figure-callout> <p><b>700</b> can utilize the information obtained from control signals (e.g., SPD, ALLM, and/or VRR) to determine one or more appropriate ads to be presented on </p><figure-callout id="790" label="display panel" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">display panel</figure-callout> <p><b>790</b> during a portion or duration of the pause event. In some embodiments, </p><figure-callout id="700" label="display device" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">display device</figure-callout> <p><b>700</b> utilizes the content recognition data of one or more video frames (e.g., fingerprints and/or watermarks from </p><figure-callout id="730" label="ACR" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">ACR</figure-callout> <p><b>730</b> and/or metadata from computer vision <b>740</b>) in conjunction with SPD, ALLM, and/or VRR to determine one or more appropriate ads to be presented on </p><figure-callout id="790" label="display panel" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">display panel</figure-callout> <p><b>790</b> during a portion or duration of the pause event.</p></div>
    </li> <li> <para-num num="[0079]"> </para-num> <div id="p-0077" num="0079"><p>For example, after a pause event is detected (e.g., </p><figure-callout id="750" label="ad insertion" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">ad insertion</figure-callout> <p><b>750</b> may receive a notice of the pause event detection from processor <b>720</b>), the corresponding fingerprint and/or watermark from </p><figure-callout id="730" label="ACR" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">ACR</figure-callout> <p><b>730</b>, the corresponding metadata from </p><figure-callout id="740" label="CV" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">CV</figure-callout> <p><b>740</b>, SPD from </p><figure-callout id="722" label="product information function" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">product information function</figure-callout> <p><b>722</b>, ALLM from </p><figure-callout id="724" label="latency mode function" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">latency mode function</figure-callout> <p><b>724</b>, and/or VRR from </p><figure-callout id="726" label="refresh rate function" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">refresh rate function</figure-callout> <p><b>726</b> can be utilized by </p><figure-callout id="750" label="ad insertion" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">ad insertion</figure-callout> <p><b>750</b> to select one or more relevant ads to be presented on </p><figure-callout id="700" label="display device" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">display device</figure-callout> <p><b>700</b>. For example, the fingerprint and/or watermark may correspond to a </p><figure-callout id="618" label="certain gaming application" filenames="US20230388589A1-20231130-D00006.png" state="{{state}}">certain gaming application</figure-callout> <p><b>618</b>. The metadata may correspond to the genre of gaming application <b>618</b> (e.g., magical creatures, sports arena, vehicles). The SPD may indicate the particular gaming system or gaming console and the model, and the ALLM may indicate low latency is needed along with a certain VRR for advanced gaming. The SPD can include a unique ID that corresponds to a particular hardware device and/or model of the hardware device. In some embodiments, </p><figure-callout id="750" label="ad insertion" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">ad insertion</figure-callout> <p><b>750</b> determines one or more relevant ads. A relevant ad may include a new model gaming system, a competitor gaming system, and/or one or more gaming applications that utilize a corresponding ALLM and/or corresponding VRR within a similar genre. Many variations are possible. In some embodiments, </p><figure-callout id="750" label="ad insertion" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">ad insertion</figure-callout> <p><b>750</b> transmits the corresponding fingerprint and/or watermark from </p><figure-callout id="730" label="ACR" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">ACR</figure-callout> <p><b>730</b>, the corresponding metadata from </p><figure-callout id="740" label="CV" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">CV</figure-callout> <p><b>740</b>, SPD from </p><figure-callout id="722" label="product information function" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">product information function</figure-callout> <p><b>722</b>, ALLM from </p><figure-callout id="724" label="latency mode function" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">latency mode function</figure-callout> <p><b>724</b>, and/or VRR from </p><figure-callout id="726" label="refresh rate function" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">refresh rate function</figure-callout> <p><b>726</b> to network <b>760</b> (e.g., a cloud network) for the determination of the relevant ads and receive the relevant ads from </p><figure-callout id="760" label="network" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">network</figure-callout> <p><b>760</b>.</p></div>
    </li> <li> <para-num num="[0080]"> </para-num> <div id="p-0078" num="0080"><p>The one or more relevant ads may be static (e.g., a still image), dynamic (e.g., a gif, a short video, an animation, an interactive screen), or a link for purchasing one or more items in the relevant ad. In some embodiments, input from </p><figure-callout id="132" label="user" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">user</figure-callout> <p><b>132</b> regarding the interactive screen (e.g., a survey) can be collected and transmitted to crowdsource </p><figure-callout id="128" label="server" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">server</figure-callout> <p><b>128</b>. In some embodiments in response to input corresponding to the one or more relevant ads, additional information may be transmitted to a mobile device corresponding to a customer account associated with display device <b>700</b> (e.g., email, text). In some embodiments the corresponding fingerprint and/or watermark from </p><figure-callout id="730" label="ACR" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">ACR</figure-callout> <p><b>730</b>, the corresponding metadata from </p><figure-callout id="740" label="CV" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">CV</figure-callout> <p><b>740</b>, SPD from </p><figure-callout id="722" label="product information function" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">product information function</figure-callout> <p><b>722</b>, ALLM from </p><figure-callout id="724" label="latency mode function" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">latency mode function</figure-callout> <p><b>724</b>, VRR from </p><figure-callout id="726" label="refresh rate function" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">refresh rate function</figure-callout> <p><b>726</b>, and/or the one or more relevant ads may be stored in a historical profile corresponding to </p><figure-callout id="132" label="user" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">user</figure-callout> <p><b>132</b> and/or </p><figure-callout id="600" label="media device" filenames="US20230388589A1-20231130-D00006.png" state="{{state}}">media device</figure-callout> <p><b>600</b>. </p><figure-callout id="750" label="Ad insertion" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">Ad insertion</figure-callout> <p><b>750</b> and/or </p><figure-callout id="760" label="network" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">network</figure-callout> <p><b>760</b> may utilize the historical profile in conjunction with current data (e.g., fingerprint and/or watermark from </p><figure-callout id="730" label="ACR" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">ACR</figure-callout> <p><b>730</b>, metadata from </p><figure-callout id="740" label="CV" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">CV</figure-callout> <p><b>740</b>, SPD from </p><figure-callout id="722" label="product information function" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">product information function</figure-callout> <p><b>722</b>, ALLM from </p><figure-callout id="724" label="latency mode function" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">latency mode function</figure-callout> <p><b>724</b>, and/or VRR from </p><figure-callout id="726" label="refresh rate function" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">refresh rate function</figure-callout> <p><b>726</b>, to determine current relevant ads.</p></div>
    </li> <li> <para-num num="[0081]"> </para-num> <div id="p-0079" num="0081"> <figure-callout id="750" label="Ad insertion" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">Ad insertion</figure-callout> <p><b>750</b> may transmit the one or more relevant ads to </p><figure-callout id="770" label="graphics module" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">graphics module</figure-callout> <p><b>770</b> to be added to a </p><figure-callout id="775" label="graphics plane" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">graphics plane</figure-callout> <p><b>775</b> of </p><figure-callout id="700" label="display device" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">display device</figure-callout> <p><b>700</b>. The one or more video frames that are received may be stored in </p><figure-callout id="780" label="memory" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">memory</figure-callout> <p><b>780</b>, and processed by video scaling and </p><figure-callout id="782" label="FRC" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">FRC</figure-callout> <p><b>782</b>. The one or more processed video frames can be added to </p><figure-callout id="784" label="video plane" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">video plane</figure-callout> <p><b>784</b> of display device <b>700</b> (e.g., a last video frame used in the detection of the pause event can be added to video plane <b>784</b>). In some embodiments, </p><figure-callout id="784" label="video plane" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">video plane</figure-callout> <p><b>784</b> and </p><figure-callout id="775" label="graphics plane" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">graphics plane</figure-callout> <p><b>775</b> can be blended (e.g., merged) together and the data of the blended planes can be received by </p><figure-callout id="790" label="display panel" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">display panel</figure-callout> <p><b>790</b> for presentation on </p><figure-callout id="700" label="display device" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">display device</figure-callout> <p><b>700</b>. In some </p><figure-callout id="775" label="embodiments graphics plane" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">embodiments graphics plane</figure-callout> <p><b>775</b> may be displayed in front of video plane <b>784</b> (e.g., overlaid to be viewed on top of video plane <b>784</b>). In some embodiments the images and/or ads of </p><figure-callout id="775" label="graphics plane" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">graphics plane</figure-callout> <p><b>775</b> can be transparent. In some embodiments a selection function from </p><figure-callout id="110" label="remote control" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">remote control</figure-callout> <p><b>110</b> can be passed through </p><figure-callout id="600" label="media device" filenames="US20230388589A1-20231130-D00006.png" state="{{state}}">media device</figure-callout> <p><b>600</b> to display </p><figure-callout id="700" label="device" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">device</figure-callout> <p><b>700</b> to make a selection from the graphics plane. The functions above may be performed by </p><figure-callout id="720" label="processor" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">processor</figure-callout> <p><b>720</b>, executing software of the various modules that may be stored in </p><figure-callout id="780" label="memory" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">memory</figure-callout> <p><b>780</b>, or a combination of hardware and software.</p></div>
    </li> <li> <para-num num="[0082]"> </para-num> <div id="p-0080" num="0082"> <figref idrefs="DRAWINGS">FIG. <b>7</b>B</figref><p> illustrates a block diagram of </p><figure-callout id="705" label="display device" filenames="US20230388589A1-20231130-D00008.png" state="{{state}}">display device</figure-callout> <p><b>705</b>, according to some embodiments. For illustration purposes and not a limitation, elements of </p><figure-callout id="705" label="display device" filenames="US20230388589A1-20231130-D00008.png" state="{{state}}">display device</figure-callout> <p><b>705</b> may be described with reference to elements from other figures in the disclosure. For example, functions of </p><figure-callout id="705" label="display device" filenames="US20230388589A1-20231130-D00008.png" state="{{state}}">display device</figure-callout> <p><b>705</b> may be similar to that of </p><figure-callout id="700" label="display device" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">display device</figure-callout> <p><b>700</b> of </p><figref idrefs="DRAWINGS">FIG. <b>7</b>A</figref><p>, but network <b>765</b> includes the following functions: </p><figure-callout id="722" label="product information function" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">product information function</figure-callout> <p><b>722</b>, </p><figure-callout id="724" label="latency mode function" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">latency mode function</figure-callout> <p><b>724</b>, </p><figure-callout id="726" label="refresh rate function" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">refresh rate function</figure-callout> <p><b>726</b>, </p><figure-callout id="730" label="ACR" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">ACR</figure-callout> <p><b>730</b> and/or </p><figure-callout id="740" label="computer vision" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">computer vision</figure-callout> <p><b>740</b>, determines relevant ads to be presented on </p><figure-callout id="790" label="display panel" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">display panel</figure-callout> <p><b>790</b>, and transmits the relevant ads to </p><figure-callout id="750" label="ad insertion" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">ad insertion</figure-callout> <p><b>750</b>.</p></div>
    </li> <li> <para-num num="[0083]"> </para-num> <div id="p-0081" num="0083"> <figref idrefs="DRAWINGS">FIG. <b>9</b> </figref><p> illustrates a block diagram of </p><figure-callout id="900" label="display device" filenames="US20230388589A1-20231130-D00010.png" state="{{state}}">display device</figure-callout> <p><b>900</b>, according to some embodiments. For illustration purposes and not a limitation, elements of </p><figure-callout id="900" label="display device" filenames="US20230388589A1-20231130-D00010.png" state="{{state}}">display device</figure-callout> <p><b>900</b> may be described with reference to elements from other figures in the disclosure. For example, functions of </p><figure-callout id="900" label="display device" filenames="US20230388589A1-20231130-D00010.png" state="{{state}}">display device</figure-callout> <p><b>900</b> may be similar to that of </p><figure-callout id="700" label="display device" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">display device</figure-callout> <p><b>700</b> of </p><figref idrefs="DRAWINGS">FIG. <b>7</b>A</figref><p>. For example, </p><figure-callout id="910" label="HDMI input" filenames="US20230388589A1-20231130-D00010.png" state="{{state}}">HDMI input</figure-callout> <p><b>910</b>, </p><figure-callout id="922" label="product information function" filenames="US20230388589A1-20231130-D00010.png" state="{{state}}">product information function</figure-callout> <p><b>922</b>, </p><figure-callout id="924" label="latency mode function" filenames="US20230388589A1-20231130-D00010.png" state="{{state}}">latency mode function</figure-callout> <p><b>924</b>, </p><figure-callout id="926" label="refresh rate function" filenames="US20230388589A1-20231130-D00010.png" state="{{state}}">refresh rate function</figure-callout> <p><b>926</b>, </p><figure-callout id="930" label="ACR" filenames="US20230388589A1-20231130-D00010.png" state="{{state}}">ACR</figure-callout> <p><b>930</b>, </p><figure-callout id="940" label="computer vision" filenames="US20230388589A1-20231130-D00010.png" state="{{state}}">computer vision</figure-callout> <p><b>940</b>, </p><figure-callout id="920" label="processor" filenames="US20230388589A1-20231130-D00010.png" state="{{state}}">processor</figure-callout> <p><b>920</b>, </p><figure-callout id="950" label="ad insertion" filenames="US20230388589A1-20231130-D00010.png" state="{{state}}">ad insertion</figure-callout> <p><b>950</b>, </p><figure-callout id="970" label="graphics module" filenames="US20230388589A1-20231130-D00010.png" state="{{state}}">graphics module</figure-callout> <p><b>970</b>, </p><figure-callout id="975" label="graphics plane" filenames="US20230388589A1-20231130-D00010.png" state="{{state}}">graphics plane</figure-callout> <p><b>975</b>, </p><figure-callout id="984" label="video plane" filenames="US20230388589A1-20231130-D00010.png" state="{{state}}">video plane</figure-callout> <p><b>984</b>, </p><figure-callout id="980" label="memory" filenames="US20230388589A1-20231130-D00010.png" state="{{state}}">memory</figure-callout> <p><b>980</b>, and video scaling and </p><figure-callout id="982" label="FRC" filenames="US20230388589A1-20231130-D00010.png" state="{{state}}">FRC</figure-callout> <p><b>982</b>, and </p><figure-callout id="990" label="display panel" filenames="US20230388589A1-20231130-D00010.png" state="{{state}}">display panel</figure-callout> <p><b>990</b> can correspond respectively to HDMI input <b>710</b>, </p><figure-callout id="722" label="product information function" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">product information function</figure-callout> <p><b>722</b>, </p><figure-callout id="724" label="latency mode function" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">latency mode function</figure-callout> <p><b>724</b>, </p><figure-callout id="726" label="refresh rate function" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">refresh rate function</figure-callout> <p><b>726</b>, </p><figure-callout id="730" label="ACR" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">ACR</figure-callout> <p><b>730</b>, </p><figure-callout id="740" label="computer vision" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">computer vision</figure-callout> <p><b>740</b>, </p><figure-callout id="720" label="processor" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">processor</figure-callout> <p><b>720</b>, </p><figure-callout id="750" label="ad insertion" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">ad insertion</figure-callout> <p><b>750</b>, </p><figure-callout id="770" label="graphics module" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">graphics module</figure-callout> <p><b>770</b>, </p><figure-callout id="775" label="graphics plane" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">graphics plane</figure-callout> <p><b>775</b>, </p><figure-callout id="784" label="video plane" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">video plane</figure-callout> <p><b>784</b>, </p><figure-callout id="780" label="memory" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">memory</figure-callout> <p><b>780</b>, and video scaling and </p><figure-callout id="782" label="FRC" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">FRC</figure-callout> <p><b>782</b>, and </p><figure-callout id="790" label="display panel" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">display panel</figure-callout> <p><b>790</b> of </p><figref idrefs="DRAWINGS">FIG. <b>7</b>A</figref><p>.</p></div>
    </li> <li> <para-num num="[0084]"> </para-num> <div id="p-0082" num="0084"><p>In some embodiments, </p><figure-callout id="900" label="display device" filenames="US20230388589A1-20231130-D00010.png" state="{{state}}">display device</figure-callout> <p><b>900</b> can execute one or more functions </p><figure-callout id="922" label="product information function" filenames="US20230388589A1-20231130-D00010.png" state="{{state}}">product information function</figure-callout> <p><b>922</b>, </p><figure-callout id="924" label="latency mode function" filenames="US20230388589A1-20231130-D00010.png" state="{{state}}">latency mode function</figure-callout> <p><b>924</b>, </p><figure-callout id="926" label="refresh rate function" filenames="US20230388589A1-20231130-D00010.png" state="{{state}}">refresh rate function</figure-callout> <p><b>926</b>, </p><figure-callout id="930" label="ACR" filenames="US20230388589A1-20231130-D00010.png" state="{{state}}">ACR</figure-callout> <p><b>930</b> and/or </p><figure-callout id="940" label="computer vision" filenames="US20230388589A1-20231130-D00010.png" state="{{state}}">computer vision</figure-callout> <p><b>940</b> via corresponding processor(s) (not shown) that are different from </p><figure-callout id="920" label="processor" filenames="US20230388589A1-20231130-D00010.png" state="{{state}}">processor</figure-callout> <p><b>920</b>. In some embodiments one or more of the functions </p><figure-callout id="922" label="product information function" filenames="US20230388589A1-20231130-D00010.png" state="{{state}}">product information function</figure-callout> <p><b>922</b>, </p><figure-callout id="924" label="latency mode function" filenames="US20230388589A1-20231130-D00010.png" state="{{state}}">latency mode function</figure-callout> <p><b>924</b>, </p><figure-callout id="926" label="refresh rate function" filenames="US20230388589A1-20231130-D00010.png" state="{{state}}">refresh rate function</figure-callout> <p><b>926</b>, </p><figure-callout id="930" label="ACR" filenames="US20230388589A1-20231130-D00010.png" state="{{state}}">ACR</figure-callout> <p><b>930</b> and/or </p><figure-callout id="940" label="computer vision" filenames="US20230388589A1-20231130-D00010.png" state="{{state}}">computer vision</figure-callout> <p><b>940</b> may be performed by </p><figure-callout id="960" label="network" filenames="US20230388589A1-20231130-D00010.png" state="{{state}}">network</figure-callout> <p><b>960</b>, </p><figure-callout id="920" label="processor" filenames="US20230388589A1-20231130-D00010.png" state="{{state}}">processor</figure-callout> <p><b>920</b>, and/or a different processor (not shown).</p></div>
    </li> <li> <para-num num="[0085]"> </para-num> <div id="p-0083" num="0085"><p>In some embodiments, </p><figure-callout id="910" label="HDMI input" filenames="US20230388589A1-20231130-D00010.png" state="{{state}}">HDMI input</figure-callout> <p><b>910</b> receives video frames and control signals from </p><figure-callout id="600" label="media device" filenames="US20230388589A1-20231130-D00006.png" state="{{state}}">media device</figure-callout> <p><b>600</b> and/or </p><figure-callout id="800" label="media device" filenames="US20230388589A1-20231130-D00009.png" state="{{state}}">media device</figure-callout> <p><b>800</b>. In some embodiments, </p><figure-callout id="960" label="network" filenames="US20230388589A1-20231130-D00010.png" state="{{state}}">network</figure-callout> <p><b>960</b> provides the video frames to HDMI input <b>910</b>.</p></div>
    </li> <li> <para-num num="[0086]"> </para-num> <div id="p-0084" num="0086"> <figref idrefs="DRAWINGS">FIG. <b>4</b> </figref><p> illustrates method <b>400</b> for a display device, according to some embodiments. For illustration purposes and not a limitation, method <b>400</b> may be described with reference to elements from other figures in the disclosure. For example, method <b>400</b> may be performed by a display device (e.g., </p><figure-callout id="108" label="display device" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">display device</figure-callout> <p><b>108</b> of </p><figref idrefs="DRAWINGS">FIG. <b>1</b> </figref><p> and </p><figref idrefs="DRAWINGS">FIG. <b>3</b> </figref><p>, </p><figure-callout id="700" label="display device" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">display device</figure-callout> <p><b>700</b> of </p><figref idrefs="DRAWINGS">FIG. <b>7</b>A</figref><p>, </p><figure-callout id="705" label="display device" filenames="US20230388589A1-20231130-D00008.png" state="{{state}}">display device</figure-callout> <p><b>705</b> of </p><figref idrefs="DRAWINGS">FIG. <b>7</b>B</figref><p>, and/or </p><figure-callout id="900" label="display device" filenames="US20230388589A1-20231130-D00010.png" state="{{state}}">display device</figure-callout> <p><b>900</b> of </p><figref idrefs="DRAWINGS">FIG. <b>9</b> </figref><p>).</p></div>
    </li> <li> <para-num num="[0087]"> </para-num> <p>At <b>405</b>, the display device can determine whether CEC (e.g., remote control pass through) functions are enabled. When CEC functions are enabled (e.g., set), method <b>400</b> proceeds to <b>410</b>. Otherwise, method <b>400</b> proceeds to <b>435</b>.</p>
    </li> <li> <para-num num="[0088]"> </para-num> <div id="p-0086" num="0088"><p>At <b>410</b>, </p><figure-callout id="108" label="display device" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">display device</figure-callout> <p><b>108</b> determines whether a pause key signal has been received. For example, </p><figure-callout id="132" label="user" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">user</figure-callout> <p><b>132</b> may have selected a pause key on </p><figure-callout id="110" label="remote control" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">remote control</figure-callout> <p><b>110</b>. Since CEC functions are enabled, the pause key signal passes through a media device (e.g., </p><figure-callout id="106" label="media device" filenames="US20230388589A1-20231130-D00001.png,US20230388589A1-20231130-D00002.png" state="{{state}}">media device</figure-callout> <p><b>106</b> of </p><figref idrefs="DRAWINGS">FIG. <b>1</b> </figref><p> or </p><figref idrefs="DRAWINGS">FIG. <b>2</b> </figref><p>, </p><figure-callout id="600" label="media device" filenames="US20230388589A1-20231130-D00006.png" state="{{state}}">media device</figure-callout> <p><b>600</b> of </p><figref idrefs="DRAWINGS">FIG. <b>6</b> </figref><p>, and/or </p><figure-callout id="800" label="media device" filenames="US20230388589A1-20231130-D00009.png" state="{{state}}">media device</figure-callout> <p><b>800</b> of </p><figref idrefs="DRAWINGS">FIG. <b>8</b> </figref><p>) to a display device (e.g., </p><figure-callout id="108" label="display device" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">display device</figure-callout> <p><b>108</b> of </p><figref idrefs="DRAWINGS">FIG. <b>1</b> </figref><p> and </p><figref idrefs="DRAWINGS">FIG. <b>3</b> </figref><p>, </p><figure-callout id="700" label="display device" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">display device</figure-callout> <p><b>700</b> of </p><figref idrefs="DRAWINGS">FIG. <b>7</b>A</figref><p>, </p><figure-callout id="705" label="display device" filenames="US20230388589A1-20231130-D00008.png" state="{{state}}">display device</figure-callout> <p><b>705</b> of </p><figref idrefs="DRAWINGS">FIG. <b>7</b>B</figref><p>, or </p><figure-callout id="900" label="display device" filenames="US20230388589A1-20231130-D00010.png" state="{{state}}">display device</figure-callout> <p><b>900</b> of </p><figref idrefs="DRAWINGS">FIG. <b>9</b> </figref><p>) via an HDMI connection (e.g., </p><figure-callout id="107" label="HDMI connection" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">HDMI connection</figure-callout> <p><b>107</b> of </p><figref idrefs="DRAWINGS">FIG. <b>1</b> </figref><p>) or </p><figure-callout id="710" label="HDMI input" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">HDMI input</figure-callout> <p><b>710</b>, or </p><figure-callout id="910" label="HDMI input" filenames="US20230388589A1-20231130-D00010.png" state="{{state}}">HDMI input</figure-callout> <p><b>910</b>. When a pause key signal has been received, the display device determines that a pause event has been detected, and method <b>400</b> proceeds to <b>415</b> and <b>418</b>. Otherwise, method <b>400</b> returns to <b>405</b>.</p></div>
    </li> <li> <para-num num="[0089]"> </para-num> <div id="p-0087" num="0089"><p>At <b>415</b>, when a pause event has been detected, the display device performs content recognition on the one or more video frames received from the media device <b>106</b> (e.g., the one or more video frames from which the pause event is determined). In some embodiments, when a pause event has been detected, the display device performs content recognition on the one or more audio frames received from the media device <b>106</b> (e.g., the one or more audio frames from which the pause event is determined). The content recognition may be performed by an ACR function (e.g., </p><figure-callout id="320" label="ACR Module" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">ACR Module</figure-callout> <p><b>320</b>, </p><figure-callout id="730" label="ACR" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">ACR</figure-callout> <p><b>730</b>, </p><figure-callout id="760" label="network" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">network</figure-callout> <p><b>760</b>, </p><figure-callout id="930" label="ACR" filenames="US20230388589A1-20231130-D00010.png" state="{{state}}">ACR</figure-callout> <p><b>930</b>, or Network <b>960</b>) that determines corresponding fingerprints and/or watermarks, or by a CV function (e.g., </p><figure-callout id="325" label="CV module" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">CV module</figure-callout> <p><b>325</b>, </p><figure-callout id="740" label="computer vision" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">computer vision</figure-callout> <p><b>740</b>, </p><figure-callout id="760" label="network" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">network</figure-callout> <p><b>760</b>, </p><figure-callout id="940" label="computer vision" filenames="US20230388589A1-20231130-D00010.png" state="{{state}}">computer vision</figure-callout> <p><b>940</b>, and/or network <b>960</b>) that determines corresponding metadata.</p></div>
    </li> <li> <para-num num="[0090]"> </para-num> <div id="p-0088" num="0090"><p>At <b>418</b>, when a pause event has been detected, the display device performs source device recognition and/or application recognition based on received control signals including but not limited to a product information signal, a latency mode signal, or a refresh rate signal. For example, a product information function enables the display device to determine the SPD that can include the type of gaming device or gaming platform (e.g., a video game console) and the model number. The latency mode function enables the display device to determine the ALLM, whether an application in use works best with low latency (e.g., </p><figure-callout id="618" label="gaming application" filenames="US20230388589A1-20231130-D00006.png" state="{{state}}">gaming application</figure-callout> <p><b>618</b>, </p><figure-callout id="816" label="input application" filenames="US20230388589A1-20231130-D00009.png" state="{{state}}">input application</figure-callout> <p><b>816</b>, or media application <b>817</b>). The refresh rate function enables the display device to determine the VRR and that the application in use may be an advanced (e.g., sophisticated) gaming application.</p></div>
    </li> <li> <para-num num="[0091]"> </para-num> <div id="p-0089" num="0091"><p>At <b>420</b>, the display device determines an appropriate ad corresponding to the determined fingerprints, watermarks, metadata, and/or information from the control signals (e.g., SPD, ALLM, VRR). For example, an ad insertion function (e.g., </p><figure-callout id="330" label="ad insertion module" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">ad insertion module</figure-callout> <p><b>330</b>, </p><figure-callout id="750" label="ad insertion" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">ad insertion</figure-callout> <p><b>750</b>, or ad insertion <b>950</b>) can determine the appropriate ad corresponding to the fingerprints, watermarks, metadata, and/or information from the control signals (e.g., SPD, ALLM, VRR). In some embodiments, the ad insertion function communicates with a network (e.g., </p><figure-callout id="118" label="network" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">network</figure-callout> <p><b>118</b> via </p><figure-callout id="114" label="communication device" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">communication device</figure-callout> <p><b>114</b>, </p><figure-callout id="760" label="network" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">network</figure-callout> <p><b>760</b>, or network <b>960</b>) to exchange the fingerprints, watermarks, metadata, and/or information from the control signals (e.g., SPD, ALLM, VRR) and/or receive one or more relevant ads to be displayed on the display device (e.g., </p><figure-callout id="108" label="display device" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">display device</figure-callout> <p><b>108</b>, </p><figure-callout id="700" label="display device" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">display device</figure-callout> <p><b>700</b>, </p><figure-callout id="705" label="display device" filenames="US20230388589A1-20231130-D00008.png" state="{{state}}">display device</figure-callout> <p><b>705</b>, or display device <b>900</b>) during the pause event. The one or more relevant ads may include a static or dynamic image.</p></div>
    </li> <li> <para-num num="[0092]"> </para-num> <div id="p-0090" num="0092"><p>In some embodiments, the display device transmits the video frames and/or control signals received via an HDMI connection to a network (e.g., </p><figure-callout id="118" label="network" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">network</figure-callout> <p><b>118</b>, </p><figure-callout id="760" label="network" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">network</figure-callout> <p><b>760</b>, and/or network <b>960</b>). In some embodiments the network performs one or more of the ACR functions, CV functions, and control signal analysis to determine the one or more fingerprints, watermarks, metadata, and/or information from the control signals (e.g., SPD, ALLM, VRR). Further, the network can determine an appropriate ad corresponding to the fingerprints, watermarks, metadata, and/or information from the control signals (e.g., SPD, ALLM, VRR). The network can transmit the appropriate ad to the ad insertion function (e.g., </p><figure-callout id="330" label="ad insertion module" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">ad insertion module</figure-callout> <p><b>330</b>, </p><figure-callout id="750" label="ad insertion" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">ad insertion</figure-callout> <p><b>750</b>, or ad insertion <b>950</b>).</p></div>
    </li> <li> <para-num num="[0093]"> </para-num> <div id="p-0091" num="0093"><p>In some embodiments the network performs one or more of the ACR functions, CV functions, and control signal analysis to determine the one or more fingerprints, watermarks, metadata, and/or information from the control signals (e.g., SPD, ALLM, VRR). A processor (e.g., </p><figure-callout id="720" label="processor" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">processor</figure-callout> <p><b>720</b>, </p><figure-callout id="920" label="processor" filenames="US20230388589A1-20231130-D00010.png" state="{{state}}">processor</figure-callout> <p><b>920</b>, or other processor (not shown) of the display device performs the remaining functions that the network does not perform, and transmits the output to the network (e.g., directly or via the ad insertion function). The network utilizes the one or more fingerprints, watermarks, metadata, and/or information obtained from the control signals (e.g., SPD, ALLM, and/or VRR) to determine the one or more appropriate ads, and transmits the one or more appropriate ads to the ad insertion function.</p></div>
    </li> <li> <para-num num="[0094]"> </para-num> <div id="p-0092" num="0094"><p>In some embodiments, the processor (e.g., </p><figure-callout id="720" label="processor" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">processor</figure-callout> <p><b>720</b>, </p><figure-callout id="920" label="processor" filenames="US20230388589A1-20231130-D00010.png" state="{{state}}">processor</figure-callout> <p><b>920</b>, or other processor (not shown) of the display device performs the remaining functions that the network does not perform, and transmits the output to the ad insertion function. The ad insertion function also receives the one or more fingerprints, watermarks, metadata, and/or information obtained from the control signals (e.g., SPD, ALLM, and/or VRR) determined by the network. The ad insertion function uses the received data from the processor and the network to determine one or more appropriate ads.</p></div>
    </li> <li> <para-num num="[0095]"> </para-num> <div id="p-0093" num="0095"><p>The ad insertion function communicates the one or more relevant ads to be displayed on the display device (e.g., </p><figure-callout id="108" label="display device" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">display device</figure-callout> <p><b>108</b>, </p><figure-callout id="700" label="display device" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">display device</figure-callout> <p><b>700</b>, </p><figure-callout id="705" label="display device" filenames="US20230388589A1-20231130-D00008.png" state="{{state}}">display device</figure-callout> <p><b>705</b>, or display device <b>900</b>) during the pause event. The one or more relevant ads may include a static or dynamic image.</p></div>
    </li> <li> <para-num num="[0096]"> </para-num> <div id="p-0094" num="0096"><p>At <b>425</b>, the display device can add one or more of the one or more appropriate ads to a graphics plane of the display device. For example, the ad insertion function may transmit the one or more relevant ads to a graphics module (e.g., </p><figure-callout id="360" label="graphics module" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">graphics module</figure-callout> <p><b>360</b>, </p><figure-callout id="770" label="graphics module" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">graphics module</figure-callout> <p><b>770</b>, graphics module <b>970</b>) to be added to the graphics plane (e.g., </p><figure-callout id="775" label="graphics plane" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">graphics plane</figure-callout> <p><b>775</b>, graphics plane <b>975</b>).</p></div>
    </li> <li> <para-num num="[0097]"> </para-num> <div id="p-0095" num="0097"><p>At <b>430</b>, the display device presents the one or more appropriate ads during the pause event. For example, the graphics plane and the video plane may blended (e.g., aligned) and a display module (e.g., </p><figure-callout id="370" label="display module" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">display module</figure-callout> <p><b>370</b>, </p><figure-callout id="790" label="display panel" filenames="US20230388589A1-20231130-D00007.png,US20230388589A1-20231130-D00008.png" state="{{state}}">display panel</figure-callout> <p><b>790</b>, display panel <b>990</b>) may present the one or more appropriate ads on a screen of the display device. In some embodiments, the display device determines that the pause event ends, and the display device stops presenting the one or more appropriate ads on the screen. The determination that the pause event ends can include but is not limited to: receiving a play key input (e.g., when CEC is set) from </p><figure-callout id="110" label="remote control" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">remote control</figure-callout> <p><b>110</b>; detecting that silent audio is not received or that video frames are changing; and/or determining that a pause icon is no longer detected or motion is detected in the video frames (e.g., via a CV function.)</p></div>
    </li> <li> <para-num num="[0098]"> </para-num> <p>Returning to <b>435</b>, when CEC functions are not set, the display device can determine whether a silent audio signal is detected. When a silent audio signal is detected, method <b>400</b> proceeds to <b>440</b>. Otherwise, method <b>400</b> proceeds to <b>455</b>.</p>
    </li> <li> <para-num num="[0099]"> </para-num> <div id="p-0097" num="0099"><p>At <b>440</b>, when silent audio has been detected, </p><figure-callout id="108" label="display device" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">display device</figure-callout> <p><b>108</b> determines whether one or more video frames is unchanging (e.g., stopped). For example, </p><figure-callout id="340" label="processing module" filenames="US20230388589A1-20231130-D00003.png" state="{{state}}">processing module</figure-callout> <p><b>340</b> can perform periodic sampling on a received video frame. In some examples, the determination of the change may be by performing content recognition functions periodically. When the video frame is determined to be unchanging, method <b>400</b> proceeds to <b>415</b>. When the video frames are changing, method <b>400</b> returns to <b>405</b> to detect a pause event.</p></div>
    </li> <li> <para-num num="[0100]"> </para-num> <p>At <b>455</b>, the display device determines whether a pause icon is detected among the one or more video frames received. For example, the CV function can analyze the content of one or more video frames to recognize a pause icon. When a pause icon is detected, method <b>400</b> proceeds to <b>460</b>. Otherwise, method <b>400</b> returns to <b>405</b>.</p>
    </li> <li> <para-num num="[0101]"> </para-num> <div id="p-0099" num="0101"><p>At <b>460</b>, </p><figure-callout id="108" label="display device" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">display device</figure-callout> <p><b>108</b> determines whether there is a change in the one or more audio and/or video frames received. For example, the CV function can determine whether the content and/or context of one or more of the video frames received changes. In some embodiments, an ACR function determines based on video and/or audio frames whether the content of the video and/or audio frames received have changed. Display device can use the corresponding fingerprints, watermarks, and/or metadata to determine whether content has changed. In some examples, the determination of the change may be performed by content recognition functions periodically. When no change in the audio and/or video frames is detected method <b>400</b> proceeds to <b>415</b> and/or <b>418</b>. Otherwise, method <b>400</b> returns to <b>405</b>.</p></div>
    </li> <heading id="h-0010">Example Computer System</heading>
    <li> <para-num num="[0102]"> </para-num> <div id="p-0100" num="0102"><p>Various embodiments may be implemented, for example, using one or more well-known computer systems, such as </p><figure-callout id="500" label="computer system" filenames="US20230388589A1-20231130-D00005.png" state="{{state}}">computer system</figure-callout> <p><b>500</b> shown in </p><figref idrefs="DRAWINGS">FIG. <b>5</b> </figref><p>. For example, </p><figure-callout id="106" label="media device" filenames="US20230388589A1-20231130-D00001.png,US20230388589A1-20231130-D00002.png" state="{{state}}">media device</figure-callout> <p><b>106</b>, </p><figure-callout id="600" label="media device" filenames="US20230388589A1-20231130-D00006.png" state="{{state}}">media device</figure-callout> <p><b>600</b>, </p><figure-callout id="800" label="media device" filenames="US20230388589A1-20231130-D00009.png" state="{{state}}">media device</figure-callout> <p><b>800</b>, </p><figure-callout id="108" label="display device" filenames="US20230388589A1-20231130-D00000.png,US20230388589A1-20231130-D00001.png" state="{{state}}">display device</figure-callout> <p><b>108</b>, </p><figure-callout id="700" label="display device" filenames="US20230388589A1-20231130-D00007.png" state="{{state}}">display device</figure-callout> <p><b>700</b>, </p><figure-callout id="705" label="display device" filenames="US20230388589A1-20231130-D00008.png" state="{{state}}">display device</figure-callout> <p><b>705</b>, or </p><figure-callout id="900" label="display device" filenames="US20230388589A1-20231130-D00010.png" state="{{state}}">display device</figure-callout> <p><b>900</b>, and/or method <b>400</b> may be implemented using combinations or sub-combinations of </p><figure-callout id="500" label="computer system" filenames="US20230388589A1-20231130-D00005.png" state="{{state}}">computer system</figure-callout> <p><b>500</b>. Also or alternatively, one or </p><figure-callout id="500" label="more computer systems" filenames="US20230388589A1-20231130-D00005.png" state="{{state}}">more computer systems</figure-callout> <p><b>500</b> may be used, for example, to implement any of the embodiments discussed herein, as well as combinations and sub-combinations thereof.</p></div>
    </li> <li> <para-num num="[0103]"> </para-num> <div id="p-0101" num="0103"> <figure-callout id="500" label="Computer system" filenames="US20230388589A1-20231130-D00005.png" state="{{state}}">Computer system</figure-callout> <p><b>500</b> may include one or more processors (also called central processing units, or CPUs), such as a </p><figure-callout id="504" label="processor" filenames="US20230388589A1-20231130-D00005.png" state="{{state}}">processor</figure-callout> <p><b>504</b>. </p><figure-callout id="504" label="Processor" filenames="US20230388589A1-20231130-D00005.png" state="{{state}}">Processor</figure-callout> <p><b>504</b> may be connected to a communication infrastructure <b>506</b> (that can be a bus).</p></div>
    </li> <li> <para-num num="[0104]"> </para-num> <div id="p-0102" num="0104"> <figure-callout id="500" label="Computer system" filenames="US20230388589A1-20231130-D00005.png" state="{{state}}">Computer system</figure-callout> <p><b>500</b> may also include user input/output device(s) <b>503</b>, such as monitors, keyboards, pointing devices, etc., which may communicate with </p><figure-callout id="506" label="communication infrastructure" filenames="US20230388589A1-20231130-D00005.png" state="{{state}}">communication infrastructure</figure-callout> <p><b>506</b> through user input/output interface(s) <b>502</b>.</p></div>
    </li> <li> <para-num num="[0105]"> </para-num> <div id="p-0103" num="0105"><p>One or more of </p><figure-callout id="504" label="processors" filenames="US20230388589A1-20231130-D00005.png" state="{{state}}">processors</figure-callout> <p><b>504</b> may be a graphics processing unit (GPU). In an embodiment, a GPU may be a processor that is a specialized electronic circuit designed to process mathematically intensive applications. The GPU may have a parallel structure that is efficient for parallel processing of large blocks of data, such as mathematically intensive data common to computer graphics applications, images, videos, etc.</p></div>
    </li> <li> <para-num num="[0106]"> </para-num> <div id="p-0104" num="0106"> <figure-callout id="500" label="Computer system" filenames="US20230388589A1-20231130-D00005.png" state="{{state}}">Computer system</figure-callout> <p><b>500</b> may also include a main or </p><figure-callout id="508" label="primary memory" filenames="US20230388589A1-20231130-D00005.png" state="{{state}}">primary memory</figure-callout> <p><b>508</b>, such as random access memory (RAM). </p><figure-callout id="508" label="Main memory" filenames="US20230388589A1-20231130-D00005.png" state="{{state}}">Main memory</figure-callout> <p><b>508</b> may include one or more levels of cache. </p><figure-callout id="508" label="Main memory" filenames="US20230388589A1-20231130-D00005.png" state="{{state}}">Main memory</figure-callout> <p><b>508</b> may have stored therein control logic (i.e., computer software) and/or data.</p></div>
    </li> <li> <para-num num="[0107]"> </para-num> <div id="p-0105" num="0107"> <figure-callout id="500" label="Computer system" filenames="US20230388589A1-20231130-D00005.png" state="{{state}}">Computer system</figure-callout> <p><b>500</b> may also include one or more secondary storage devices or </p><figure-callout id="510" label="memory" filenames="US20230388589A1-20231130-D00005.png" state="{{state}}">memory</figure-callout> <p><b>510</b>. </p><figure-callout id="510" label="Secondary memory" filenames="US20230388589A1-20231130-D00005.png" state="{{state}}">Secondary memory</figure-callout> <p><b>510</b> may include, for example, a </p><figure-callout id="512" label="hard disk drive" filenames="US20230388589A1-20231130-D00005.png" state="{{state}}">hard disk drive</figure-callout> <p><b>512</b> and/or a removable storage device or drive <b>514</b>. </p><figure-callout id="514" label="Removable storage drive" filenames="US20230388589A1-20231130-D00005.png" state="{{state}}">Removable storage drive</figure-callout> <p><b>514</b> may be a floppy disk drive, a magnetic tape drive, a compact disk drive, an optical storage device, tape backup device, and/or any other storage device/drive.</p></div>
    </li> <li> <para-num num="[0108]"> </para-num> <div id="p-0106" num="0108"> <figure-callout id="514" label="Removable storage drive" filenames="US20230388589A1-20231130-D00005.png" state="{{state}}">Removable storage drive</figure-callout> <p><b>514</b> may interact with a </p><figure-callout id="518" label="removable storage unit" filenames="US20230388589A1-20231130-D00005.png" state="{{state}}">removable storage unit</figure-callout> <p><b>518</b>. </p><figure-callout id="518" label="Removable storage unit" filenames="US20230388589A1-20231130-D00005.png" state="{{state}}">Removable storage unit</figure-callout> <p><b>518</b> may include a computer usable or readable storage device having stored thereon computer software (control logic) and/or data. </p><figure-callout id="518" label="Removable storage unit" filenames="US20230388589A1-20231130-D00005.png" state="{{state}}">Removable storage unit</figure-callout> <p><b>518</b> may be a floppy disk, magnetic tape, compact disk, DVD, optical storage disk, and/any other computer data storage device. </p><figure-callout id="514" label="Removable storage drive" filenames="US20230388589A1-20231130-D00005.png" state="{{state}}">Removable storage drive</figure-callout> <p><b>514</b> may read from and/or write to </p><figure-callout id="518" label="removable storage unit" filenames="US20230388589A1-20231130-D00005.png" state="{{state}}">removable storage unit</figure-callout> <p><b>518</b>.</p></div>
    </li> <li> <para-num num="[0109]"> </para-num> <div id="p-0107" num="0109"> <figure-callout id="510" label="Secondary memory" filenames="US20230388589A1-20231130-D00005.png" state="{{state}}">Secondary memory</figure-callout> <p><b>510</b> may include other means, devices, components, instrumentalities or other approaches for allowing computer programs and/or other instructions and/or data to be accessed by </p><figure-callout id="500" label="computer system" filenames="US20230388589A1-20231130-D00005.png" state="{{state}}">computer system</figure-callout> <p><b>500</b>. Such means, devices, components, instrumentalities or other approaches may include, for example, a removable storage unit <b>522</b> and an </p><figure-callout id="520" label="interface" filenames="US20230388589A1-20231130-D00005.png" state="{{state}}">interface</figure-callout> <p><b>520</b>. Examples of the removable storage unit <b>522</b> and the </p><figure-callout id="520" label="interface" filenames="US20230388589A1-20231130-D00005.png" state="{{state}}">interface</figure-callout> <p><b>520</b> may include a program cartridge and cartridge interface (such as that found in video game devices), a removable memory chip (such as an EPROM or PROM) and associated socket, a memory stick and USB or other port, a memory card and associated memory card slot, and/or any other removable storage unit and associated interface.</p></div>
    </li> <li> <para-num num="[0110]"> </para-num> <div id="p-0108" num="0110"> <figure-callout id="500" label="Computer system" filenames="US20230388589A1-20231130-D00005.png" state="{{state}}">Computer system</figure-callout> <p><b>500</b> may further include a communication or </p><figure-callout id="524" label="network interface" filenames="US20230388589A1-20231130-D00005.png" state="{{state}}">network interface</figure-callout> <p><b>524</b>. </p><figure-callout id="524" label="Communication interface" filenames="US20230388589A1-20231130-D00005.png" state="{{state}}">Communication interface</figure-callout> <p><b>524</b> may enable </p><figure-callout id="500" label="computer system" filenames="US20230388589A1-20231130-D00005.png" state="{{state}}">computer system</figure-callout> <p><b>500</b> to communicate and interact with any combination of external devices, external networks, external entities, etc. (individually and collectively referenced by reference number <b>528</b>). For example, </p><figure-callout id="524" label="communication interface" filenames="US20230388589A1-20231130-D00005.png" state="{{state}}">communication interface</figure-callout> <p><b>524</b> may allow </p><figure-callout id="500" label="computer system" filenames="US20230388589A1-20231130-D00005.png" state="{{state}}">computer system</figure-callout> <p><b>500</b> to communicate with external or </p><figure-callout id="528" label="remote devices" filenames="US20230388589A1-20231130-D00005.png" state="{{state}}">remote devices</figure-callout> <p><b>528</b> over </p><figure-callout id="526" label="communications path" filenames="US20230388589A1-20231130-D00005.png" state="{{state}}">communications path</figure-callout> <p><b>526</b>, which may be wired and/or wireless (or a combination thereof), and which may include any combination of LANs, WANs, the Internet, etc. Control logic and/or data may be transmitted to and from </p><figure-callout id="500" label="computer system" filenames="US20230388589A1-20231130-D00005.png" state="{{state}}">computer system</figure-callout> <p><b>500</b> via </p><figure-callout id="526" label="communication path" filenames="US20230388589A1-20231130-D00005.png" state="{{state}}">communication path</figure-callout> <p><b>526</b>.</p></div>
    </li> <li> <para-num num="[0111]"> </para-num> <div id="p-0109" num="0111"> <figure-callout id="500" label="Computer system" filenames="US20230388589A1-20231130-D00005.png" state="{{state}}">Computer system</figure-callout> <p><b>500</b> may also be any of a personal digital assistant (PDA), desktop workstation, laptop or notebook computer, netbook, tablet, smart phone, smart watch or other wearable, appliance, part of the Internet-of-Things, and/or embedded system, to name a few non-limiting examples, or any combination thereof.</p></div>
    </li> <li> <para-num num="[0112]"> </para-num> <div id="p-0110" num="0112"> <figure-callout id="500" label="Computer system" filenames="US20230388589A1-20231130-D00005.png" state="{{state}}">Computer system</figure-callout> <p><b>500</b> may be a client or server, accessing or hosting any applications and/or data through any delivery paradigm, including but not limited to remote or distributed cloud computing solutions; local or on-premises software (“on-premise” cloud-based solutions); “as a service” models (e.g., content as a service (CaaS), digital content as a service (DCaaS), software as a service (SaaS), managed software as a service (MSaaS), platform as a service (PaaS), desktop as a service (DaaS), framework as a service (FaaS), backend as a service (BaaS), mobile backend as a service (MBaaS), infrastructure as a service (IaaS), etc.); and/or a hybrid model including any combination of the foregoing examples or other services or delivery paradigms.</p></div>
    </li> <li> <para-num num="[0113]"> </para-num> <div id="p-0111" num="0113"><p>Any applicable data structures, file formats, and schemas in </p><figure-callout id="500" label="computer system" filenames="US20230388589A1-20231130-D00005.png" state="{{state}}">computer system</figure-callout> <p><b>500</b> may be derived from standards including but not limited to JavaScript Object Notation (JSON), Extensible Markup Language (XML), Yet Another Markup Language (YAML), Extensible Hypertext Markup Language (XHTML), Wireless Markup Language (WML), MessagePack, XML User Interface Language (XUL), or any other functionally similar representations alone or in combination. Alternatively, proprietary data structures, formats or schemas may be used, either exclusively or in combination with known or open standards.</p></div>
    </li> <li> <para-num num="[0114]"> </para-num> <div id="p-0112" num="0114"><p>In some embodiments, a tangible, non-transitory apparatus or article of manufacture comprising a tangible, non-transitory computer useable or readable medium having control logic (software) stored thereon may also be referred to herein as a computer program product or program storage device. This includes, but is not limited to, </p><figure-callout id="500" label="computer system" filenames="US20230388589A1-20231130-D00005.png" state="{{state}}">computer system</figure-callout> <p><b>500</b>, </p><figure-callout id="508" label="main memory" filenames="US20230388589A1-20231130-D00005.png" state="{{state}}">main memory</figure-callout> <p><b>508</b>, </p><figure-callout id="510" label="secondary memory" filenames="US20230388589A1-20231130-D00005.png" state="{{state}}">secondary memory</figure-callout> <p><b>510</b>, and </p><figure-callout id="518" label="removable storage units" filenames="US20230388589A1-20231130-D00005.png" state="{{state}}">removable storage units</figure-callout> <p><b>518</b> and <b>522</b>, as well as tangible articles of manufacture embodying any combination of the foregoing. Such control logic, when executed by one or more data processing devices (such as </p><figure-callout id="500" label="computer system" filenames="US20230388589A1-20231130-D00005.png" state="{{state}}">computer system</figure-callout> <p><b>500</b> or processor(s) <b>504</b>), may cause such data processing devices to operate as described herein.</p></div>
    </li> <li> <para-num num="[0115]"> </para-num> <div id="p-0113" num="0115"><p>Based on the teachings contained in this disclosure, it will be apparent to persons skilled in the relevant art(s) how to make and use embodiments of this disclosure using data processing devices, computer systems and/or computer architectures other than that shown in </p><figref idrefs="DRAWINGS">FIG. <b>5</b> </figref><p>. In particular, embodiments can operate with software, hardware, and/or operating system implementations other than those described herein.</p></div>
    </li> <heading id="h-0011">CONCLUSION</heading>
    <li> <para-num num="[0116]"> </para-num> <p>It is to be appreciated that the Detailed Description section, and not any other section, is intended to be used to interpret the claims. Other sections can set forth one or more but not all exemplary embodiments as contemplated by the inventor(s), and thus, are not intended to limit this disclosure or the appended claims in any way.</p>
    </li> <li> <para-num num="[0117]"> </para-num> <p>While this disclosure describes exemplary embodiments for exemplary fields and applications, it should be understood that the disclosure is not limited thereto. Other embodiments and modifications thereto are possible, and are within the scope and spirit of this disclosure. For example, and without limiting the generality of this paragraph, embodiments are not limited to the software, hardware, firmware, and/or entities illustrated in the figures and/or described herein. Further, embodiments (whether or not explicitly described herein) have significant utility to fields and applications beyond the examples described herein.</p>
    </li> <li> <para-num num="[0118]"> </para-num> <p>Embodiments have been described herein with the aid of functional building blocks illustrating the implementation of specified functions and relationships thereof. The boundaries of these functional building blocks have been arbitrarily defined herein for the convenience of the description. Alternate boundaries can be defined as long as the specified functions and relationships (or equivalents thereof) are appropriately performed. Also, alternative embodiments can perform functional blocks, steps, operations, methods, etc. using orderings different than those described herein.</p>
    </li> <li> <para-num num="[0119]"> </para-num> <p>References herein to “one embodiment,” “an embodiment,” “an example embodiment,” or similar phrases, indicate that the embodiment described may include a particular feature, structure, or characteristic, but every embodiment may not necessarily include the particular feature, structure, or characteristic. Moreover, such phrases are not necessarily referring to the same embodiment. Further, when a particular feature, structure, or characteristic is described in connection with an embodiment, it would be within the knowledge of persons skilled in the relevant art(s) to incorporate such feature, structure, or characteristic into other embodiments whether or not explicitly mentioned or described herein. Additionally, some embodiments can be described using the expression “coupled” and “connected” along with their derivatives. These terms are not necessarily intended as synonyms for each other. For example, some embodiments can be described using the terms “connected” and/or “coupled” to indicate that two or more elements are in direct physical or electrical contact with each other. The term “coupled,” however, can also mean that two or more elements are not in direct contact with each other, but yet still co-operate or interact with each other.</p>
    </li> <li> <para-num num="[0120]"> </para-num> <p>The breadth and scope of this disclosure should not be limited by any of the above-described exemplary embodiments, but should be defined only in accordance with the following claims and their equivalents.</p>
    
  </li> </ul>
  </div>
  </section>

  <section itemprop="claims" itemscope="">
    <h2>Claims (<span itemprop="count">20</span>)</h2>
    
    <div mxw-id="PCLM438283089" lang="EN" load-source="patent-office" itemprop="content" html="">
    <claim-statement>What is claimed is:</claim-statement>
    <div id="CLM-00001" num="00001"> <p><b>1</b>. A computer implemented method for a display device, comprising:
</p><p>detecting a pause event in one or more frames received via a high-definition multimedia interface (HDMI) connection;</p> <p>receiving a control signal via the HDMI connection;</p> <p>detecting an auto low latency mode (ALLM) in the control signal;</p> <p>during the pause event, recognizing content within the one or more frames;</p> <p>determining an ad based on the ALLM or the content within the one or more frames; and</p> <p>presenting the ad on the display device.</p> </div> <div id="CLM-00002" num="00002"> <p><b>2</b>. The computer implemented method of </p><claim-ref idref="CLM-00001">claim 1</claim-ref><p>, wherein the detecting the pause event comprises: receiving a remote control pass through pause signal.</p></div> <div id="CLM-00003" num="00003"> <p><b>3</b>. The computer implemented method of </p><claim-ref idref="CLM-00001">claim 1</claim-ref><p>, wherein the detecting the pause event comprises:
</p><p>detecting a silent audio signal via the HDMI connection; and</p> <p>determining that the first video frame and the second video frame are identical.</p> </div> <div id="CLM-00004" num="00004"> <p><b>4</b>. The computer implemented method of </p><claim-ref idref="CLM-00001">claim 1</claim-ref><p>, wherein the recognizing the content comprises:
</p><p>analyzing the first video frame or a first audio frame of the one or more frames using automatic content recognition (ACR) technology; and</p> <p>determining, based on the analyzing, a fingerprint, a watermark, or a cue tone corresponding to the first video frame or the first audio frame, wherein the fingerprint, the watermark, or the cue tone is used to identify information about content corresponding to the first video frame or the first audio frame.</p> </div> <div id="CLM-00005" num="00005"> <p><b>5</b>. The computer implemented method of </p><claim-ref idref="CLM-00001">claim 1</claim-ref><p>, wherein the recognizing the content comprises:
</p><p>analyzing the first video frame using the CV technology; and</p> <p>determining, based on the analyzing, metadata corresponding to the first video frame, wherein the metadata is used to identify one or more objects corresponding to the first video frame.</p> </div> <div id="CLM-00006" num="00006"> <p><b>6</b>. The computer implemented method of </p><claim-ref idref="CLM-00001">claim 1</claim-ref><p>, further comprising:
</p><p>determining a service product description (SPD) from the control signal, wherein the determining the ad is further based on the SPD.</p> </div> <div id="CLM-00007" num="00007"> <p><b>7</b>. The computer implemented method of </p><claim-ref idref="CLM-00001">claim 1</claim-ref><p>, further comprising:
</p><p>detecting a variable refresh rate (VRR) from the control signal, wherein the determining the ad is further based on the VRR.</p> </div> <div id="CLM-00008" num="00008"> <p><b>8</b>. The computer implemented method of </p><claim-ref idref="CLM-00007">claim 7</claim-ref><p>, wherein the determining the ad comprises:
</p><p>transmitting the VRR to a network; and</p> <p>receiving the ad corresponding to the VRR from the network.</p> </div> <div id="CLM-00009" num="00009"> <p><b>9</b>. The computer implemented method of </p><claim-ref idref="CLM-00001">claim 1</claim-ref><p>, wherein the determining the ad comprises:
</p><p>transmitting a fingerprint, a watermark, or metadata corresponding to the content to a network; and</p> <p>receiving the ad corresponding to the fingerprint, the watermark, or the metadata from the network.</p> </div> <div id="CLM-00010" num="00010"> <p><b>10</b>. The computer implemented method of </p><claim-ref idref="CLM-00001">claim 1</claim-ref><p>, wherein the determining the ad comprises:
</p><p>transmitting a service product description (SPD) corresponding to the control signal received to a network; and</p> <p>receiving the ad corresponding to the SPD from the network.</p> </div> <div id="CLM-00011" num="00011"> <p><b>11</b>. The computer implemented method of </p><claim-ref idref="CLM-00001">claim 1</claim-ref><p>, wherein the determining the ad comprises:
</p><p>transmitting the ALLM corresponding to the control signal received to a network; and</p> <p>receiving the ad corresponding to the ALLM from the network.</p> </div> <div id="CLM-00012" num="00012"> <p><b>12</b>. The computer implemented method of </p><claim-ref idref="CLM-00001">claim 1</claim-ref><p>, wherein the presenting the ad comprises:
</p><p>presenting the ad on a graphics plane of the display device;</p> <p>blending the graphics plane with a video plane comprising the first video frame; and</p> <p>presenting the blended planes on the display device.</p> </div> <div id="CLM-00013" num="00013"> <p><b>13</b>. A system, comprising:
</p><p>a memory; and</p> <div><p>at least one processor coupled to the memory and configured to:
</p><p>detect a pause event in one or more frames received via a high-definition multimedia interface (HDMI) connection;</p>
<p>receive a control signal via the HDMI connection;</p>
<p>detect an auto low latency mode (ALLM) in the control signal;</p>
<p>during the pause event, recognize content within the one or more frames;</p>
<p>determine an ad based on the ALLM or the content within the one or more frames; and</p>
<p>present the ad on a display device.</p>
</div> </div> <div id="CLM-00014" num="00014"> <p><b>14</b>. The system of </p><claim-ref idref="CLM-00013">claim 13</claim-ref><p>, wherein to detect the pause event, the at least one processor is configured to receive a remote control pass through pause signal.</p></div> <div id="CLM-00015" num="00015"> <p><b>15</b>. The system of </p><claim-ref idref="CLM-00013">claim 13</claim-ref><p>, wherein to detect the pause event, the at least one processor is configured to:
</p><p>detect a silent audio signal via the HDMI connection; and</p> <p>determine that the first video frame and the second video frame are identical.</p> </div> <div id="CLM-00016" num="00016"> <p><b>16</b>. The system of </p><claim-ref idref="CLM-00013">claim 13</claim-ref><p>, wherein to recognize the content, the at least one processor is configured to:
</p><p>analyze the first video frame or a first audio frame of the one or more frames using automatic content recognition (ACR) technology; and</p> <p>determine, based on the analyzing, a fingerprint, a watermark, or a cue tone corresponding to the first video frame or the first audio frame, wherein the fingerprint, the watermark, or the cue tone is used to identify information about content corresponding to the first video frame or the first audio frame.</p> </div> <div id="CLM-00017" num="00017"> <p><b>17</b>. A non-transitory computer-readable medium having instructions stored thereon that, when executed by a computing device, cause the computing device to perform operations comprising:
</p><p>detecting a pause event in one or more frames received via a high-definition multimedia interface (HDMI) connection;</p> <p>receiving a control signal via the HDMI connection;</p> <p>detecting an auto low latency mode (ALLM) in the control signal;</p> <p>during the pause event, recognizing content within the one or more frames;</p> <p>determining an ad based on the ALLM or the content within the one or more frames; and</p> <p>presenting the ad on a display device.</p> </div> <div id="CLM-00018" num="00018"> <p><b>18</b>. The non-transitory computer-readable medium of </p><claim-ref idref="CLM-00017">claim 17</claim-ref><p>, wherein the operations further comprise:
</p><p>receiving a control signal via the HDMI connection; and</p> <p>determining a service product description (SPD) or a variable refresh rate (VRR) from the control signal, wherein the determining the ad is further based on the SPD or the VRR.</p> </div> <div id="CLM-00019" num="00019"> <p><b>19</b>. The non-transitory computer-readable medium of </p><claim-ref idref="CLM-00017">claim 17</claim-ref><p>, wherein the determining the ad comprises:
</p><p>transmitting the ALLM corresponding to the control signal received to a network; and</p> <p>receiving the ad corresponding to the ALLM from the network.</p> </div> <div id="CLM-00020" num="00020"> <p><b>20</b>. The non-transitory computer-readable medium of </p><claim-ref idref="CLM-00017">claim 17</claim-ref><p>, wherein the presenting the ad comprises:
</p><p>presenting the ad on a graphics plane of the display device;</p> <p>blending the graphics plane with a video plane comprising the first video frame; and</p> <p>presenting the blended planes on the display device.</p> </div> </div>
  </section>

  <section itemprop="application" itemscope="">

    <section itemprop="metadata" itemscope="">
      <span itemprop="applicationNumber">US18/446,596</span>
      <span itemprop="priorityDate">2022-02-17</span>
      <span itemprop="filingDate">2023-08-09</span>
      <span itemprop="title">Hdmi customized ad insertion 
     </span>
      <span itemprop="ifiStatus">Pending</span>
      
      <a href="https://patents.google.com/patent/US20230388589A1/en">
        <span itemprop="representativePublication">US20230388589A1</span>
        (<span itemprop="primaryLanguage">en</span>)
      </a>
    </section>

    <h2>Priority Applications (1)</h2>
    <table>
      <thead>
        <tr>
          <th>Application Number</th>
          <th>Priority Date</th>
          <th>Filing Date</th>
          <th>Title</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="priorityApps" itemscope="" repeat="">
          <td>
            <span itemprop="applicationNumber">US18/446,596</span>
            
            <a href="https://patents.google.com/patent/US20230388589A1/en">
              <span itemprop="representativePublication">US20230388589A1</span>
                (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
          <td itemprop="priorityDate">2022-02-17</td>
          <td itemprop="filingDate">2023-08-09</td>
          <td itemprop="title">Hdmi customized ad insertion 
     </td>
        </tr>
      </tbody>
    </table>

    <h2>Applications Claiming Priority (2)</h2>
    <table>
      <thead>
        <tr>
          <th>Application Number</th>
          <th>Priority Date</th>
          <th>Filing Date</th>
          <th>Title</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="appsClaimingPriority" itemscope="" repeat="">
          <td>
            <span itemprop="applicationNumber">US17/674,339</span>
            <a href="https://patents.google.com/patent/US11785300B2/en">
              <span itemprop="representativePublication">US11785300B2</span>
                (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
          <td itemprop="priorityDate">2022-02-17</td>
          <td itemprop="filingDate">2022-02-17</td>
          <td itemprop="title">HDMI customized ad insertion 
       </td>
        </tr>
        <tr itemprop="appsClaimingPriority" itemscope="" repeat="">
          <td>
            <span itemprop="applicationNumber">US18/446,596</span>
            <a href="https://patents.google.com/patent/US20230388589A1/en">
              <span itemprop="representativePublication">US20230388589A1</span>
                (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
          <td itemprop="priorityDate">2022-02-17</td>
          <td itemprop="filingDate">2023-08-09</td>
          <td itemprop="title">Hdmi customized ad insertion 
     </td>
        </tr>
      </tbody>
    </table>

    <h2>Related Parent Applications (1)</h2>
    <table>
      <thead>
        <tr>
          <th>Application Number</th>
          <th>Title</th>
          <th>Priority Date</th>
          <th>Filing Date</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="parentApps" itemscope="" repeat="">
          <td>
            <span itemprop="applicationNumber">US17/674,339</span>
            <span itemprop="relationType">Continuation</span>
            <a href="https://patents.google.com/patent/US11785300B2/en">
              <span itemprop="representativePublication">US11785300B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
          <td itemprop="priorityDate">2022-02-17</td>
          <td itemprop="filingDate">2022-02-17</td>
          <td itemprop="title">HDMI customized ad insertion 
       </td>
        </tr>
      </tbody>
    </table>

    

    <h2>Publications (1)</h2>
    <table>
      <thead>
        <tr>
          <th>Publication Number</th>
          <th>Publication Date</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="pubs" itemscope="" repeat="">
          <td>
            <span itemprop="publicationNumber">US20230388589A1</span>
            
            <span itemprop="thisPatent">true</span>
            <a href="https://patents.google.com/patent/US20230388589A1/en">
              US20230388589A1
              (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
          <td itemprop="publicationDate">2023-11-30</td>
        </tr>
      </tbody>
    </table>

  </section>

  <section itemprop="family" itemscope="">
    <h2>Family</h2>
    <h2>ID=87558289</h2>

    <h2>Family Applications (2)</h2>
    <table>
      <thead>
        <tr>
          <th>Application Number</th>
          <th>Title</th>
          <th>Priority Date</th>
          <th>Filing Date</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="applications" itemscope="" repeat="">
          <td>
            <span itemprop="applicationNumber">US17/674,339</span>
            <span itemprop="ifiStatus">Active</span>
            
            <a href="https://patents.google.com/patent/US11785300B2/en">
              <span itemprop="representativePublication">US11785300B2</span>
                (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
          <td itemprop="priorityDate">2022-02-17</td>
          <td itemprop="filingDate">2022-02-17</td>
          <td itemprop="title">HDMI customized ad insertion 
       </td>
        </tr>
        <tr itemprop="applications" itemscope="" repeat="">
          <td>
            <span itemprop="applicationNumber">US18/446,596</span>
            <span itemprop="ifiStatus">Pending</span>
            
            <a href="https://patents.google.com/patent/US20230388589A1/en">
              <span itemprop="representativePublication">US20230388589A1</span>
                (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
          <td itemprop="priorityDate">2022-02-17</td>
          <td itemprop="filingDate">2023-08-09</td>
          <td itemprop="title">Hdmi customized ad insertion 
     </td>
        </tr>
      </tbody>
    </table>

    <h2>Family Applications Before (1)</h2>
    <table>
      <thead>
        <tr>
          <th>Application Number</th>
          <th>Title</th>
          <th>Priority Date</th>
          <th>Filing Date</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="beforeApplications" itemscope="" repeat="">
          <td>
            <span itemprop="applicationNumber">US17/674,339</span>
            <span itemprop="ifiStatus">Active</span>
            
            <a href="https://patents.google.com/patent/US11785300B2/en">
                <span itemprop="representativePublication">US11785300B2</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
          </td>
          <td itemprop="priorityDate">2022-02-17</td>
          <td itemprop="filingDate">2022-02-17</td>
          <td itemprop="title">HDMI customized ad insertion 
       </td>
        </tr>
      </tbody>
    </table>

    

    <h2>Country Status (1)</h2>
    <table>
      <thead>
        <tr>
          <th>Country</th>
          <th>Link</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="countryStatus" itemscope="" repeat="">
          <td>
            <span itemprop="countryCode">US</span>
            (<span itemprop="num">2</span>)
            <meta itemprop="thisCountry" content="true">
          </td>
          <td>
            <a href="https://patents.google.com/patent/US11785300B2/en">
              <span itemprop="representativePublication">US11785300B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
        </tr>
      </tbody>
    </table>

    

    

    

    <h2>Family Cites Families (32)</h2>
    <table>
      <caption>* Cited by examiner, † Cited by third party</caption>
      <thead>
        <tr>
          <th>Publication number</th>
          <th>Priority date</th>
          <th>Publication date</th>
          <th>Assignee</th>
          <th>Title</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="backwardReferencesFamily" itemscope="" repeat="">
          <td>
            <a href="https://patents.google.com/patent/EP1076337A4/en">
              <span itemprop="publicationNumber">EP1076337A4</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">1998-04-27</td>
          <td itemprop="publicationDate">2005-05-04</td>
          <td><span itemprop="assigneeOriginal">Hitachi Ltd</span></td>
          <td itemprop="title">Recorder/reproducer 
       </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope="" repeat="">
          <td>
            <a href="https://patents.google.com/patent/US7263714B2/en">
              <span itemprop="publicationNumber">US7263714B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2001-01-18</td>
          <td itemprop="publicationDate">2007-08-28</td>
          <td><span itemprop="assigneeOriginal">Blackarrow, Inc.</span></td>
          <td itemprop="title">Providing content interruptions 
       </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope="" repeat="">
          <td>
            <a href="https://patents.google.com/patent/US20050216932A1/en">
              <span itemprop="publicationNumber">US20050216932A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2004-03-24</td>
          <td itemprop="publicationDate">2005-09-29</td>
          <td><span itemprop="assigneeOriginal">Daniel Danker</span></td>
          <td itemprop="title">Targeted advertising in conjunction with on-demand media content 
       </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope="" repeat="">
          <td>
            <a href="https://patents.google.com/patent/US8014882B2/en">
              <span itemprop="publicationNumber">US8014882B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2004-04-06</td>
          <td itemprop="publicationDate">2011-09-06</td>
          <td><span itemprop="assigneeOriginal">Panasonic Corporation</span></td>
          <td itemprop="title">Particular program detection device, method, and program 
       </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope="" repeat="">
          <td>
            <a href="https://patents.google.com/patent/JP2005328282A/en">
              <span itemprop="publicationNumber">JP2005328282A</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2004-05-13</td>
          <td itemprop="publicationDate">2005-11-24</td>
          <td><span itemprop="assigneeOriginal">Hitachi Ltd</span></td>
          <td itemprop="title">Portable terminal 
       </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope="" repeat="">
          <td>
            <a href="https://patents.google.com/patent/CN102523063A/en">
              <span itemprop="publicationNumber">CN102523063A</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2004-08-09</td>
          <td itemprop="publicationDate">2012-06-27</td>
          <td><span itemprop="assigneeOriginal">尼尔森（美国）有限公司</span></td>
          <td itemprop="title">Methods and apparatus to monitor audio/visual content from various sources 
       </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope="" repeat="">
          <td>
            <a href="https://patents.google.com/patent/KR100694060B1/en">
              <span itemprop="publicationNumber">KR100694060B1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2004-10-12</td>
          <td itemprop="publicationDate">2007-03-12</td>
          <td><span itemprop="assigneeOriginal">삼성전자주식회사</span></td>
          <td itemprop="title">Apparatus and method for synchronizing video and audio 
       </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope="" repeat="">
          <td>
            <a href="https://patents.google.com/patent/US7461338B2/en">
              <span itemprop="publicationNumber">US7461338B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2005-01-07</td>
          <td itemprop="publicationDate">2008-12-02</td>
          <td><span itemprop="assigneeOriginal">Essociate, Inc.</span></td>
          <td itemprop="title">Advertising markup language 
       </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope="" repeat="">
          <td>
            <a href="https://patents.google.com/patent/JP2007267259A/en">
              <span itemprop="publicationNumber">JP2007267259A</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2006-03-29</td>
          <td itemprop="publicationDate">2007-10-11</td>
          <td><span itemprop="assigneeOriginal">Toshiba Corp</span></td>
          <td itemprop="title">Image processing apparatus and file reproducing method 
       </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope="" repeat="">
          <td>
            <a href="https://patents.google.com/patent/JP4336364B2/en">
              <span itemprop="publicationNumber">JP4336364B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2006-11-17</td>
          <td itemprop="publicationDate">2009-09-30</td>
          <td><span itemprop="assigneeOriginal">三菱電機株式会社</span></td>
          <td itemprop="title">
  Television receiver
 
     </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope="" repeat="">
          <td>
            <a href="https://patents.google.com/patent/US9076154B1/en">
              <span itemprop="publicationNumber">US9076154B1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2008-04-15</td>
          <td itemprop="publicationDate">2015-07-07</td>
          <td><span itemprop="assigneeOriginal">Google Inc.</span></td>
          <td itemprop="title">Advertising in collaborative environments 
       </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope="" repeat="">
          <td>
            <a href="https://patents.google.com/patent/US20100023960A1/en">
              <span itemprop="publicationNumber">US20100023960A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2008-07-22</td>
          <td itemprop="publicationDate">2010-01-28</td>
          <td><span itemprop="assigneeOriginal">General Instrument Corporation</span></td>
          <td itemprop="title">Detection of Video Program Viewing Behavior for Correlation with Advertisement Presentation 
       </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope="" repeat="">
          <td>
            <a href="https://patents.google.com/patent/US20100064261A1/en">
              <span itemprop="publicationNumber">US20100064261A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2008-09-09</td>
          <td itemprop="publicationDate">2010-03-11</td>
          <td><span itemprop="assigneeOriginal">Microsoft Corporation</span></td>
          <td itemprop="title">Portable electronic device with relative gesture recognition mode 
       </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope="" repeat="">
          <td>
            <a href="https://patents.google.com/patent/US20100086277A1/en">
              <span itemprop="publicationNumber">US20100086277A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2008-10-03</td>
          <td itemprop="publicationDate">2010-04-08</td>
          <td><span itemprop="assigneeOriginal">Guideworks, Llc</span></td>
          <td itemprop="title">Systems and methods for deleting viewed portions of recorded programs 
       </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope="" repeat="">
          <td>
            <a href="https://patents.google.com/patent/US9167312B2/en">
              <span itemprop="publicationNumber">US9167312B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2009-11-24</td>
          <td itemprop="publicationDate">2015-10-20</td>
          <td><span itemprop="assigneeOriginal">Verizon Patent And Licensing Inc.</span></td>
          <td itemprop="title">Pause-based advertising methods and systems 
       </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope="" repeat="">
          <td>
            <a href="https://patents.google.com/patent/US9237294B2/en">
              <span itemprop="publicationNumber">US9237294B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2010-03-05</td>
          <td itemprop="publicationDate">2016-01-12</td>
          <td><span itemprop="assigneeOriginal">Sony Corporation</span></td>
          <td itemprop="title">Apparatus and method for replacing a broadcasted advertisement based on both heuristic information and attempts in altering the playback of the advertisement 
       </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope="" repeat="">
          <td>
            <a href="https://patents.google.com/patent/US20110255840A1/en">
              <span itemprop="publicationNumber">US20110255840A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2010-04-16</td>
          <td itemprop="publicationDate">2011-10-20</td>
          <td><span itemprop="assigneeOriginal">Bornsen Brett L</span></td>
          <td itemprop="title">Advertisements through a digital video recorder (dvr) 
       </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope="" repeat="">
          <td>
            <a href="https://patents.google.com/patent/US10715864B2/en">
              <span itemprop="publicationNumber">US10715864B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2013-03-14</td>
          <td itemprop="publicationDate">2020-07-14</td>
          <td><span itemprop="assigneeOriginal">Oracle America, Inc.</span></td>
          <td itemprop="title">System and method for universal, player-independent measurement of consumer-online-video consumption behaviors 
       </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope="" repeat="">
          <td>
            <a href="https://patents.google.com/patent/US8954346B1/en">
              <span itemprop="publicationNumber">US8954346B1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2013-06-03</td>
          <td itemprop="publicationDate">2015-02-10</td>
          <td><span itemprop="assigneeOriginal">Inadco, Inc.</span></td>
          <td itemprop="title">Serving form ads with a video 
       </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope="" repeat="">
          <td>
            <a href="https://patents.google.com/patent/US20150296250A1/en">
              <span itemprop="publicationNumber">US20150296250A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2014-04-10</td>
          <td itemprop="publicationDate">2015-10-15</td>
          <td><span itemprop="assigneeOriginal">Google Inc.</span></td>
          <td itemprop="title">Methods, systems, and media for presenting commerce information relating to video content 
       </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope="" repeat="">
          <td>
            <a href="https://patents.google.com/patent/US9432662B2/en">
              <span itemprop="publicationNumber">US9432662B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2014-11-25</td>
          <td itemprop="publicationDate">2016-08-30</td>
          <td><span itemprop="assigneeOriginal">Echostar Technologies L.L.C.</span></td>
          <td itemprop="title">Systems and methods for picture quality monitoring 
       </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope="" repeat="">
          <td>
            <a href="https://patents.google.com/patent/US20160165059A1/en">
              <span itemprop="publicationNumber">US20160165059A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2014-12-05</td>
          <td itemprop="publicationDate">2016-06-09</td>
          <td><span itemprop="assigneeOriginal">Facebook, Inc.</span></td>
          <td itemprop="title">Mobile device audio tuning 
       </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope="" repeat="">
          <td>
            <a href="https://patents.google.com/patent/US9646421B2/en">
              <span itemprop="publicationNumber">US9646421B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2015-04-14</td>
          <td itemprop="publicationDate">2017-05-09</td>
          <td><span itemprop="assigneeOriginal">International Business Machines Corporation</span></td>
          <td itemprop="title">Synchronizing an augmented reality video stream with a displayed video stream 
       </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope="" repeat="">
          <td>
            <a href="https://patents.google.com/patent/US20160378276A1/en">
              <span itemprop="publicationNumber">US20160378276A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2015-06-29</td>
          <td itemprop="publicationDate">2016-12-29</td>
          <td><span itemprop="assigneeOriginal">Rovi Guides, Inc.</span></td>
          <td itemprop="title">Methods and apparatus for generating for display portions of media assets 
       </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope="" repeat="">
          <td>
            <a href="https://patents.google.com/patent/EP4131118A1/en">
              <span itemprop="publicationNumber">EP4131118A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2017-01-20</td>
          <td itemprop="publicationDate">2023-02-08</td>
          <td><span itemprop="assigneeOriginal">Huawei Technologies Co., Ltd.</span></td>
          <td itemprop="title">Advertisement display method, and terminal 
       </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope="" repeat="">
          <td>
            <a href="https://patents.google.com/patent/US11651316B2/en">
              <span itemprop="publicationNumber">US11651316B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2017-07-14</td>
          <td itemprop="publicationDate">2023-05-16</td>
          <td><span itemprop="assigneeOriginal">Allstate Insurance Company</span></td>
          <td itemprop="title">Controlling vehicles using contextual driver and/or rider data based on automatic passenger detection and mobility status 
       </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope="" repeat="">
          <td>
            <a href="https://patents.google.com/patent/US11245958B2/en">
              <span itemprop="publicationNumber">US11245958B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2018-11-16</td>
          <td itemprop="publicationDate">2022-02-08</td>
          <td><span itemprop="assigneeOriginal">Roku, Inc.</span></td>
          <td itemprop="title">Detection of mute and compensation therefor during media replacement event 
       </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope="" repeat="">
          <td>
            <a href="https://patents.google.com/patent/EP3991427A1/en">
              <span itemprop="publicationNumber">EP3991427A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2019-06-28</td>
          <td itemprop="publicationDate">2022-05-04</td>
          <td><span itemprop="assigneeOriginal">Dolby Laboratories Licensing Corporation</span></td>
          <td itemprop="title">Video content type metadata for high dynamic range 
       </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope="" repeat="">
          <td>
            <a href="https://patents.google.com/patent/US11323766B2/en">
              <span itemprop="publicationNumber">US11323766B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2019-10-03</td>
          <td itemprop="publicationDate">2022-05-03</td>
          <td><span itemprop="assigneeOriginal">Dolby International Ab</span></td>
          <td itemprop="title">Method and device for providing audio/video content to a rendering device 
       </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope="" repeat="">
          <td>
            <a href="https://patents.google.com/patent/KR20210057354A/en">
              <span itemprop="publicationNumber">KR20210057354A</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2019-11-12</td>
          <td itemprop="publicationDate">2021-05-21</td>
          <td><span itemprop="assigneeOriginal">삼성전자주식회사</span></td>
          <td itemprop="title">Electronic apparatus and control method thereof 
       </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope="" repeat="">
          <td>
            <a href="https://patents.google.com/patent/US11405667B2/en">
              <span itemprop="publicationNumber">US11405667B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2020-06-17</td>
          <td itemprop="publicationDate">2022-08-02</td>
          <td><span itemprop="assigneeOriginal">Yieldmo, Inc.</span></td>
          <td itemprop="title">Method for serving interactive digital advertising content within a streaming platform 
       </td>
        </tr>
        <tr itemprop="backwardReferencesFamily" itemscope="" repeat="">
          <td>
            <a href="https://patents.google.com/patent/US11082679B1/en">
              <span itemprop="publicationNumber">US11082679B1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2021-01-12</td>
          <td itemprop="publicationDate">2021-08-03</td>
          <td><span itemprop="assigneeOriginal">Iamchillpill Llc.</span></td>
          <td itemprop="title">Synchronizing secondary audiovisual content based on frame transitions in streaming content 
       </td>
        </tr>
      </tbody>
    </table>

    <ul>
      <li itemprop="applicationsByYear" itemscope="" repeat="">
        <span itemprop="year">2022</span>
        <ul>
          <li itemprop="application" itemscope="" repeat="">
            <span itemprop="filingDate">2022-02-17</span>
            <span itemprop="countryCode">US</span>
            <span itemprop="applicationNumber">US17/674,339</span>
            <a href="https://patents.google.com/patent/US11785300B2/en"><span itemprop="documentId">patent/US11785300B2/en</span></a>
            <span itemprop="legalStatusCat">active</span>
            <span itemprop="legalStatus">Active</span>
            
          </li>
        </ul>
      </li>
      <li itemprop="applicationsByYear" itemscope="" repeat="">
        <span itemprop="year">2023</span>
        <ul>
          <li itemprop="application" itemscope="" repeat="">
            <span itemprop="filingDate">2023-08-09</span>
            <span itemprop="countryCode">US</span>
            <span itemprop="applicationNumber">US18/446,596</span>
            <a href="https://patents.google.com/patent/US20230388589A1/en"><span itemprop="documentId">patent/US20230388589A1/en</span></a>
            <span itemprop="legalStatusCat">active</span>
            <span itemprop="legalStatus">Pending</span>
            <span itemprop="thisApp" content="true" bool=""></span>
          </li>
        </ul>
      </li>
    </ul>

    </section>

  

  

  

  <section>
    <h2>Also Published As</h2>
    <table>
      <thead>
        <tr>
          <th>Publication number</th>
          <th>Publication date</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="docdbFamily" itemscope="" repeat="">
          <td>
            <a href="https://patents.google.com/patent/US11785300B2/en">
              <span itemprop="publicationNumber">US11785300B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
          <td itemprop="publicationDate">2023-10-10</td>
        </tr>
        <tr itemprop="docdbFamily" itemscope="" repeat="">
          <td>
            <a href="https://patents.google.com/patent/US20230262289A1/en">
              <span itemprop="publicationNumber">US20230262289A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
          <td itemprop="publicationDate">2023-08-17</td>
        </tr>
      </tbody>
    </table>
  </section>

  <section>
    <h2>Similar Documents</h2>
    <table>
      <thead>
        <tr>
          <th>Publication</th>
          <th>Publication Date</th>
          <th>Title</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="similarDocuments" itemscope="" repeat="">
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="https://patents.google.com/patent/US10834296B2/en">
                <span itemprop="publicationNumber">US10834296B2</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2020-11-10">2020-11-10</time>
            
            
          </td>
          <td itemprop="title">Dynamically adjusting video to improve synchronization with audio 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope="" repeat="">
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="https://patents.google.com/patent/US11611788B2/en">
                <span itemprop="publicationNumber">US11611788B2</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2023-03-21">2023-03-21</time>
            
            
          </td>
          <td itemprop="title">Adaptive switching in a whole home entertainment system 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope="" repeat="">
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="https://patents.google.com/patent/US11611797B2/en">
                <span itemprop="publicationNumber">US11611797B2</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2023-03-21">2023-03-21</time>
            
            
          </td>
          <td itemprop="title">Providing over-the-air content to any device 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope="" repeat="">
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="https://patents.google.com/patent/US11388474B2/en">
                <span itemprop="publicationNumber">US11388474B2</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2022-07-12">2022-07-12</time>
            
            
          </td>
          <td itemprop="title">Server-side scene change content stitching 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope="" repeat="">
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="https://patents.google.com/patent/US20230379521A1/en">
                <span itemprop="publicationNumber">US20230379521A1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2023-11-23">2023-11-23</time>
            
            
          </td>
          <td itemprop="title">Managing content segments of linear tv content and over-the-top (ott) content 
     </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope="" repeat="">
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="https://patents.google.com/patent/US20230010754A1/en">
                <span itemprop="publicationNumber">US20230010754A1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2023-01-12">2023-01-12</time>
            
            
          </td>
          <td itemprop="title">Non-television experience triggers 
     </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope="" repeat="">
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="https://patents.google.com/patent/US11871091B2/en">
                <span itemprop="publicationNumber">US11871091B2</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2024-01-09">2024-01-09</time>
            
            
          </td>
          <td itemprop="title">Dynamically generating and highlighting references to content segments in videos related to a main video that is being watched 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope="" repeat="">
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="https://patents.google.com/patent/US11785300B2/en">
                <span itemprop="publicationNumber">US11785300B2</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2023-10-10">2023-10-10</time>
            
            
          </td>
          <td itemprop="title">HDMI customized ad insertion 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope="" repeat="">
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="https://patents.google.com/patent/US11936941B2/en">
                <span itemprop="publicationNumber">US11936941B2</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2024-03-19">2024-03-19</time>
            
            
          </td>
          <td itemprop="title">Dynamically generating and highlighting references to content segments in videos related to a main video that is being watched 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope="" repeat="">
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="https://patents.google.com/patent/US11770566B1/en">
                <span itemprop="publicationNumber">US11770566B1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2023-09-26">2023-09-26</time>
            
            
          </td>
          <td itemprop="title">Automatically determining an optimal supplemental content spot in a media stream 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope="" repeat="">
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="https://patents.google.com/patent/US11627368B1/en">
                <span itemprop="publicationNumber">US11627368B1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2023-04-11">2023-04-11</time>
            
            
          </td>
          <td itemprop="title">Automatic offering and switching to a higher quality media stream 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope="" repeat="">
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="https://patents.google.com/patent/US20230106992A1/en">
                <span itemprop="publicationNumber">US20230106992A1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2023-04-06">2023-04-06</time>
            
            
          </td>
          <td itemprop="title">Combined Media Capability for Multiple Media Devices 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope="" repeat="">
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="https://patents.google.com/patent/US11930226B2/en">
                <span itemprop="publicationNumber">US11930226B2</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2024-03-12">2024-03-12</time>
            
            
          </td>
          <td itemprop="title">Emotion evaluation of contents 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope="" repeat="">
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="https://patents.google.com/patent/US20240064354A1/en">
                <span itemprop="publicationNumber">US20240064354A1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2024-02-22">2024-02-22</time>
            
            
          </td>
          <td itemprop="title">Recommendation system with reduced bias based on a view history 
     </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope="" repeat="">
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="https://patents.google.com/patent/US11838581B2/en">
                <span itemprop="publicationNumber">US11838581B2</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2023-12-05">2023-12-05</time>
            
            
          </td>
          <td itemprop="title">Preserving channel lock and performing dynamic ad insertion (DAI) in a multi-device setup 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope="" repeat="">
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="https://patents.google.com/patent/US20230421850A1/en">
                <span itemprop="publicationNumber">US20230421850A1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2023-12-28">2023-12-28</time>
            
            
          </td>
          <td itemprop="title">Replacement of digital content in data streams 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope="" repeat="">
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="https://patents.google.com/patent/US11792568B2/en">
                <span itemprop="publicationNumber">US11792568B2</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2023-10-17">2023-10-17</time>
            
            
          </td>
          <td itemprop="title">Power control for speaker devices in a wireless media system 
       </td>
        </tr>
        <tr itemprop="similarDocuments" itemscope="" repeat="">
          <td>
            <meta itemprop="isPatent" content="true">
              <a href="https://patents.google.com/patent/US20240015354A1/en">
                <span itemprop="publicationNumber">US20240015354A1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2024-01-11">2024-01-11</time>
            
            
          </td>
          <td itemprop="title">Automatic parental control using a remote control or mobile app 
       </td>
        </tr>
      </tbody>
    </table>
  </section>

  <section>
    <h2>Legal Events</h2>
    <table>
      <thead>
        <tr>
          <th>Date</th>
          <th>Code</th>
          <th>Title</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="legalEvents" itemscope="" repeat="">
          <td><time itemprop="date" datetime="2023-08-22">2023-08-22</time></td>
          <td itemprop="code">STPP</td>
          <td itemprop="title">Information on status: patent application and granting procedure in general</td>
          <td>
            <p itemprop="attributes" itemscope="" repeat="">
              <strong itemprop="label">Free format text</strong>:
              <span itemprop="value">DOCKETED NEW CASE - READY FOR EXAMINATION</span>
            </p>
          </td>
        </tr>
        <tr itemprop="legalEvents" itemscope="" repeat="">
          <td><time itemprop="date" datetime="2023-11-28">2023-11-28</time></td>
          <td itemprop="code">AS</td>
          <td itemprop="title">Assignment</td>
          <td>
            <p itemprop="attributes" itemscope="" repeat="">
              <strong itemprop="label">Owner name</strong>:
              <span itemprop="value">ROKU, INC., CALIFORNIA</span>
            </p>
            <p itemprop="attributes" itemscope="" repeat="">
              <strong itemprop="label">Free format text</strong>:
              <span itemprop="value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:NARAYANA, PURUSHOTTAM;GODDARD ROSA, ANDRE;SIGNING DATES FROM 20220201 TO 20220207;REEL/FRAME:065676/0190</span>
            </p>
          </td>
        </tr>
      </tbody>
    </table>
  </section>

</article>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Cory Doctorow on Kagi Search (187 pts)]]></title>
            <link>https://pluralistic.net/2024/04/04/teach-me-how-to-shruggie/</link>
            <guid>39935805</guid>
            <pubDate>Thu, 04 Apr 2024 21:06:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pluralistic.net/2024/04/04/teach-me-how-to-shruggie/">https://pluralistic.net/2024/04/04/teach-me-how-to-shruggie/</a>, See on <a href="https://news.ycombinator.com/item?id=39935805">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-8449">
	<!-- .entry-header -->

	
	
	<div>
		<p><!--
Tags:
john stewart, the daily show, apple, monopoly, lina khan, ftc, too big to fail, too big to jail, monopoly, monopolism, trustbusting, antitrust, search, enshittification, kagi,

Summary:
Too big to care; Hey look at this; Upcoming appearances; Recent appearances; Latest books; Upcoming books

URL:
https://pluralistic.net/2024/04/04/teach-me-how-to-shruggie/

Title:
Pluralistic: Too big to care (04 Apr 2024) teach-me-how-to-shruggie

Bullet:
👼🏼

Separator:
^-^-^-^-^-^-^-^-^-^-^-^-^-^-^-^-^-^-^-^-^-^-^-^-^-^-^-^-^-^-^

Top Sources:
None

--><br>
<a href="https://pluralistic.net/2024/04/04/teach-me-how-to-shruggie/"><img decoding="async" src="https://i0.wp.com/craphound.com/images/04Apr2024.jpg?w=840&amp;ssl=1" data-recalc-dims="1"></a></p>
<h2>Today's links</h2>
<ul>
<li><a href="https://pluralistic.net/2024/04/04/teach-me-how-to-shruggie/#kagi">Too big to care</a>: Enshittification is a choice.
</li>
<li><a href="https://pluralistic.net/2024/04/04/teach-me-how-to-shruggie/#linkdump">Hey look at this</a>: Delights to delectate.
</li>
<li><a href="https://pluralistic.net/2024/04/04/teach-me-how-to-shruggie/#retro">This day in history</a>: 2009, 2014, 2019, 2023
</li>
<li><a href="https://pluralistic.net/2024/04/04/teach-me-how-to-shruggie/#upcoming">Upcoming appearances</a>: Where to find me.
</li>
<li><a href="https://pluralistic.net/2024/04/04/teach-me-how-to-shruggie/#recent">Recent appearances</a>: Where I've been.
</li>
<li><a href="https://pluralistic.net/2024/04/04/teach-me-how-to-shruggie/#latest">Latest books</a>: You keep readin' em, I'll keep writin' 'em.
</li>
<li><a href="https://pluralistic.net/2024/04/04/teach-me-how-to-shruggie/#upcoming-books">Upcoming books</a>: Like I said, I'll keep writin' 'em.
</li>
<li><a href="https://pluralistic.net/2024/04/04/teach-me-how-to-shruggie/#bragsheet">Colophon</a>: All the rest.
</li>
</ul>

<hr>
<p><a name="kagi"></a><br>
<img decoding="async" alt="A demon from Bosch's Garden of Earthly Delights. It has a bulbous, tick-like body and the legs of a hoofed animal. Its ass is open, revealing a hollow space within, populated by other demons. A flag sprouts from its back. It has been altered so that its face is a Google 'G' logo and the flag bears a tiny Android logo. Its broad, flat hat is decorated the the 'shrug' ASCII art." src="https://i0.wp.com/craphound.com/images/too-big-to-care.jpg?w=840&amp;ssl=1" data-recalc-dims="1"></p>
<h2>Too big to care (<a href="https://pluralistic.net/2024/04/04/teach-me-how-to-shruggie/#kagi">permalink</a>)</h2>
<p>Remember the first time you used Google search? It was like magic. After years of progressively worsening search quality from Altavista and Yahoo, Google was literally stunning, a gateway to the very best things on the internet.</p>
<p>Today, Google has a 90% search market-share. They got it the hard way: they cheated. Google spends tens of billions of dollars on payola in order to ensure that they are the default search engine behind <em>every</em> search box you encounter on every device, every service and every website:</p>
<p><a href="https://pluralistic.net/2023/10/03/not-feeling-lucky/#fundamental-laws-of-economics">https://pluralistic.net/2023/10/03/not-feeling-lucky/#fundamental-laws-of-economics</a></p>
<p>Not coincidentally, Google's search is getting progressively, monotonically worse. It is a cesspool of botshit, spam, scams, and nonsense. Important resources that I never bothered to bookmark because I could find them with a quick Google search no longer show up in the first <em>ten</em> screens of results:</p>
<p><a href="https://pluralistic.net/2024/02/21/im-feeling-unlucky/#not-up-to-the-task">https://pluralistic.net/2024/02/21/im-feeling-unlucky/#not-up-to-the-task</a></p>
<p>Even after all that payola, Google is still absurdly profitable. They have so much money, they were able to do a <em>$80 billion</em> stock buyback. Just a few months later, Google fired 12,000 skilled technical workers. Essentially, Google is saying that they don't need to spend money on quality, because we're all locked into using Google search. It's cheaper to buy the default search box everywhere in the world than it is to make a product that is so good that even if we tried another search engine, we'd still prefer Google.</p>
<p>This is enshittification. Google is shifting value away from end users (searchers) and business customers (advertisers, publishers and merchants) to itself:</p>
<p><a href="https://pluralistic.net/2024/03/05/the-map-is-not-the-territory/#apor-locksmith">https://pluralistic.net/2024/03/05/the-map-is-not-the-territory/#apor-locksmith</a></p>
<p>And here's the thing: there are search engines out there that are <em>so good</em> that if you just try them, you'll get that same feeling you got the first time you tried Google.</p>
<p>When I was in Tucson last month on my book-tour for my new novel <em>The Bezzle</em>, I crashed with my pals Patrick and Teresa Nielsen Hayden. I've know them since I was a teenager (Patrick is my editor).</p>
<p>We were sitting in his living room on our laptops – just like old times! – and Patrick asked me if I'd tried Kagi, a new search-engine.</p>
<p>Teresa chimed in, extolling the advanced search features, the "lenses" that surfaced specific kinds of resources on the web.</p>
<p>I hadn't even heard of Kagi, but the Nielsen Haydens are among the most effective researchers I know – both in their professional editorial lives and in their many obsessive hobbies. If it was good enough for them…</p>
<p>I tried it. It was <em>magic</em>.</p>
<p>No, seriously. All those things Google couldn't find anymore? Top of the search pile. Queries that generated <em>pages</em> of spam in Google results? Fucking <em>pristine</em> on Kagi – the right answers, over and over again.</p>
<p>That was <em>before</em> I started playing with Kagi's lenses and other bells and whistles, which elevated the search experience from "magic" to <em>sorcerous</em>.</p>
<p>The catch is that Kagi costs money – after 100 queries, they want you to cough up $10/month ($14 for a couple or $20 for a family with up to six accounts, and some kid-specific features):</p>
<p><a href="https://kagi.com/settings?p=billing_plan&amp;amp;plan=family">https://kagi.com/settings?p=billing_plan&amp;amp;plan=family</a></p>
<p>I immediately bought a family plan. I've been using it for a month. I've basically stopped using Google search altogether.</p>
<p>Kagi just let me get a lot more done, and I assumed that they were some kind of wildly capitalized startup that was running their own crawl and and their own data-centers. But this morning, I read Jason Koebler's <em>404 Media</em> report on his own experiences using it:</p>
<p><a href="https://www.404media.co/friendship-ended-with-google-now-kagi-is-my-best-friend/">https://www.404media.co/friendship-ended-with-google-now-kagi-is-my-best-friend/</a></p>
<p>Koebler's piece contained a key detail that I'd somehow missed:</p>
<blockquote><p>
  When you search on Kagi, the service makes a series of “anonymized API calls to traditional search indexes like Google, Yandex, Mojeek, and Brave,” as well as a handful of other specialized search engines, Wikimedia Commons, Flickr, etc. Kagi then combines this with its own web index and news index (for news searches) to build the results pages that you see. So, essentially, you are getting some mix of Google search results combined with results from other indexes.
</p></blockquote>
<p>In other words: <em>Kagi is a heavily customized, anonymized front-end to Google</em>.</p>
<p>The implications of this are <em>stunning</em>. It means that Google's enshittified search-results are a <em>choice</em>. Those ad-strewn, sub-Altavista, spam-drowned search pages are <em>a feature</em>, not a bug. Google <em>prefers</em> those results to Kagi, because Google makes more money out of shit than they would out of delivering a good product:</p>
<p><a href="https://www.theverge.com/2024/4/2/24117976/best-printer-2024-home-use-office-use-labels-school-homework">https://www.theverge.com/2024/4/2/24117976/best-printer-2024-home-use-office-use-labels-school-homework</a></p>
<p>No <em>wonder</em> Google spends a whole-ass Twitter <em>every year</em> to make sure you never try a rival search engine. Bottom line: they ran the numbers and figured out their most profitable course of action is to enshittify their flagship product and bribe their "competitors" like Apple and Samsung so that you never try another search engine and have another one of those <em>magic</em> moments that sent all those Jeeves-askin' Yahooers to Google a quarter-century ago.</p>
<p>One of my favorite TV comedy bits is Lily Tomlin as Ernestine the AT&amp;T operator; Tomlin would do these pitches for the Bell System and end every ad with "We don't care. We don't have to. We're the phone company":</p>
<p><a href="https://snltranscripts.jt.org/76/76aphonecompany.phtml">https://snltranscripts.jt.org/76/76aphonecompany.phtml</a></p>
<p>Speaking of TV comedy: this week saw FTC chair Lina Khan appear on <em>The Daily Show</em> with Jon Stewart. It was <em>amazing</em>:</p>
<p><a href="https://www.youtube.com/watch?v=oaDTiWaYfcM">https://www.youtube.com/watch?v=oaDTiWaYfcM</a></p>
<p>The coverage of Khan's appearance has focused on Stewart's revelation that when he was doing a show on Apple TV, the company prohibited him from interviewing her (presumably because of her hostility to tech monopolies):</p>
<p><a href="https://www.thebignewsletter.com/p/apple-got-caught-censoring-its-own">https://www.thebignewsletter.com/p/apple-got-caught-censoring-its-own</a></p>
<p>But for me, the big moment came when Khan described tech monopolists as "too big to care."</p>
<p>What a phrase!</p>
<p>Since the subprime crisis, we're all familiar with businesses being "too big to fail" and "too big to jail." But "too big to <em>care</em>?" Oof, that got me <em>right in the feels</em>.</p>
<p>Because that's what it feels like to use enshittified Google. That's what it feels like to discover that Kagi – the good search engine – is mostly Google with the weights adjusted to serve users, not shareholders.</p>
<p>Google used to care. They cared because they were worried about competitors and regulators. They cared because their workers <em>made</em> them care:</p>
<p><a href="https://www.vox.com/future-perfect/2019/4/4/18295933/google-cancels-ai-ethics-board">https://www.vox.com/future-perfect/2019/4/4/18295933/google-cancels-ai-ethics-board</a></p>
<p>Google doesn't care anymore. They don't have to. They're the search company.</p>
<hr>

<h2>Hey look at this (<a href="https://pluralistic.net/2024/04/04/teach-me-how-to-shruggie/#linkdump">permalink</a>)</h2>
<p><img decoding="async" src="https://i0.wp.com/craphound.com/images/heylookatthis.jpg?w=840&amp;ssl=1" data-recalc-dims="1"></p>
<ul>
<li>The Retraction Watch Mass Resignations List <a href="https://retractionwatch.com/the-retraction-watch-mass-resignations-list/">https://retractionwatch.com/the-retraction-watch-mass-resignations-list/</a> (h/t Gregory Charlin)
</li>
<li>
<p>I am the Comic / Comic Book Walk <a href="https://www.kickstarter.com/projects/cecilseaskull/i-am-the-comic-comic-book-walk">https://www.kickstarter.com/projects/cecilseaskull/i-am-the-comic-comic-book-walk</a></p>
</li>
<li>
<p>Capitalists Hate Capitalism <a href="https://locusmag.com/2024/03/cory-doctorow-capitalists-hate-capitalism/">https://locusmag.com/2024/03/cory-doctorow-capitalists-hate-capitalism/</a></p>
</li>
</ul>
<hr>
<p><a name="retro"></a><br>
<img decoding="async" alt="A Wayback Machine banner." src="https://i0.wp.com/craphound.com/images/wayback-machine-hed-796x416.png?resize=796%2C416&amp;ssl=1" data-recalc-dims="1"></p>
<h2>This day in history (<a href="https://pluralistic.net/2024/04/04/teach-me-how-to-shruggie/#retro">permalink</a>)</h2>
<p>#15yrsago Why URL shorteners suck <a href="https://joshua.schachter.org/2009/04/on-url-shorteners">https://joshua.schachter.org/2009/04/on-url-shorteners</a></p>
<p>#15yrsago Heinlein’s house for sale <a href="https://web.archive.org/web/20090406105617/https://mcginnis.com/listings/detail.php?lid=41846127&amp;limit=0&amp;offset=0&amp;aid=005900204&amp;oid=005900002&amp;temp=1057&amp;aname=Sharon+Roland&amp;aimg=1&amp;chome=1&amp;agent_hasfeat=2&amp;&amp;posc=6&amp;post=10&amp;cfq=elegant%3Dyes%26property_category%3D1%26county%3D41%26aid%3D005900204%26oid%3D005900002%26temp%3D1057%26aname%3DSharon%2BRoland%26aimg%3D1%26chome%3D1%26agent_hasfeat%3D2%26SRSearchDate%3D1238781456%26SRRecordCount%3D10%26SRPage%3D1%26SRPageCount%3D1%26SRPageLinks%3D6">https://web.archive.org/web/20090406105617/https://mcginnis.com/listings/detail.php?lid=41846127&amp;limit=0&amp;offset=0&amp;aid=005900204&amp;oid=005900002&amp;temp=1057&amp;aname=Sharon+Roland&amp;aimg=1&amp;chome=1&amp;agent_hasfeat=2&amp;&amp;posc=6&amp;post=10&amp;cfq=elegant%3Dyes%26property_category%3D1%26county%3D41%26aid%3D005900204%26oid%3D005900002%26temp%3D1057%26aname%3DSharon%2BRoland%26aimg%3D1%26chome%3D1%26agent_hasfeat%3D2%26SRSearchDate%3D1238781456%26SRRecordCount%3D10%26SRPage%3D1%26SRPageCount%3D1%26SRPageLinks%3D6</a></p>
<p>#15yrsago Game industry exec celebrates 60+ hour work-weeks <a href="https://web.archive.org/web/20090405131359/playthisthing.com/mothers-dont-let-your-children-grow-be-game-developers">https://web.archive.org/web/20090405131359/playthisthing.com/mothers-dont-let-your-children-grow-be-game-developers</a></p>
<p>#15yrsago Nine year old’s survey project excluded from school because he learned some people don’t think of themselves as male or female <a href="https://thefourthvine.livejournal.com/102417.html">https://thefourthvine.livejournal.com/102417.html</a></p>
<p>#15yrsago Help save Bruce Sterling and Jasmina Tesanovic from US immigration hell! <a href="https://web.archive.org/web/20090405213303/http://blog.wired.com/sterling/2009/04/bruce-sterling.html">https://web.archive.org/web/20090405213303/http://blog.wired.com/sterling/2009/04/bruce-sterling.html</a></p>
<p>#15yrsago Pneumatic tube-based systems — the real series of tubes <a href="https://www.youtube.com/watch?v=MvSeL_LfdbA">https://www.youtube.com/watch?v=MvSeL_LfdbA</a></p>
<p>#15yrsago Berlusconi declares war on the press <a href="https://www.repubblica.it/2009/04/sezioni/esteri/nato-strasburgo/calunnia-tv/calunnia-tv.html">https://www.repubblica.it/2009/04/sezioni/esteri/nato-strasburgo/calunnia-tv/calunnia-tv.html</a></p>
<p>#10yrsago Private equity, an infection that is eating the world <a href="https://web.archive.org/web/20140330004925/https://www.ericgarland.co/2014/03/29/parasite-economy/">https://web.archive.org/web/20140330004925/https://www.ericgarland.co/2014/03/29/parasite-economy/</a></p>
<p>#10yrsago UK Tories call for a national of slaves <a href="https://www.antipope.org/charlie/blog-static/2014/04/a-nation-of-slaves.html">https://www.antipope.org/charlie/blog-static/2014/04/a-nation-of-slaves.html</a></p>
<p>#10yrsago Daniel Ellsberg to keynote HOPE X in NYC this summer <a href="https://www.2600.com/content/daniel-ellsberg-keynote-hope-x">https://www.2600.com/content/daniel-ellsberg-keynote-hope-x</a></p>
<p>#10yrsago Yahoo beefs up security in two meaningful and important ways <a href="https://www.eff.org/deeplinks/2014/04/yahoo-protects-users-lots-more-encryption">https://www.eff.org/deeplinks/2014/04/yahoo-protects-users-lots-more-encryption</a></p>
<p>#10yrsago The Gettysburg Address: A Graphic Adaptation, a nuanced and moving history of race, slavery and the Civil War <a href="https://memex.craphound.com/2014/04/04/the-gettysburg-address-a-graphic-adaptation-a-nuanced-and-moving-history-of-race-slavery-and-the-civil-war/">https://memex.craphound.com/2014/04/04/the-gettysburg-address-a-graphic-adaptation-a-nuanced-and-moving-history-of-race-slavery-and-the-civil-war/</a></p>
<p>#10yrsago Britain is turning into a country that can’t tell its terrorists from its journalists <a href="https://memex.craphound.com/2014/04/03/britain-is-turning-into-a-country-that-cant-tell-its-terrorists-from-its-journalists/">https://memex.craphound.com/2014/04/03/britain-is-turning-into-a-country-that-cant-tell-its-terrorists-from-its-journalists/</a></p>
<p>#10yrsago Stop-and-frisk as the most visible element of deep, violent official American racism <a href="https://www.theatlantic.com/national/archive/2014/04/what-i-learned-about-stop-and-frisk-from-watching-my-black-son/359962/">https://www.theatlantic.com/national/archive/2014/04/what-i-learned-about-stop-and-frisk-from-watching-my-black-son/359962/</a></p>
<p>#10yrsago David “Debt” Graeber evicted, implicates NYPD intelligence, claims revenge-harassment for OWS participation <a href="http://nielsenhayden.com/makinglight/archives/015820.html">http://nielsenhayden.com/makinglight/archives/015820.html</a></p>
<p>#10yrsago Open net gets a huge boost in the EU: net neutrality and no roaming fees <a href="https://web.archive.org/web/20140405234420/http://www.marietjeschaake.eu/2014/04/mep-european-parliament-supports-proposal-schaake-to-enshrine-net-neutrality-in-european-law/">https://web.archive.org/web/20140405234420/http://www.marietjeschaake.eu/2014/04/mep-european-parliament-supports-proposal-schaake-to-enshrine-net-neutrality-in-european-law/</a></p>
<p>#10yrsago Cats of Tanglewood Forest: illustrated modern folktale from Charles de Lint and Charles Vess <a href="https://memex.craphound.com/2014/04/03/cats-of-tanglewood-forest-illustrated-modern-folktale-from-charles-de-lint-and-charles-vess/">https://memex.craphound.com/2014/04/03/cats-of-tanglewood-forest-illustrated-modern-folktale-from-charles-de-lint-and-charles-vess/</a></p>
<p>#10yrsago House Science Committee: a parliament of Creationists, Climate Deniers (and dunces) <a href="https://www.scientificamerican.com/blog/the-curious-wavefunction/the-house-of-representatives-committee-on-science-is-turning-into-a-national-embarrassment/">https://www.scientificamerican.com/blog/the-curious-wavefunction/the-house-of-representatives-committee-on-science-is-turning-into-a-national-embarrassment/</a></p>
<p>#10yrsago Big Data has big problems <a href="https://www.ft.com/content/21a6e7d8-b479-11e3-a09a-00144feabdc0">https://www.ft.com/content/21a6e7d8-b479-11e3-a09a-00144feabdc0</a></p>
<p>#5yrsago 540 million Facebook users’ data exposed by third party developers <a href="https://www.upguard.com/breaches/facebook-user-data-leak">https://www.upguard.com/breaches/facebook-user-data-leak</a></p>
<p>#5yrsago Elizabeth Warren proposes holding execs criminally liable for scams and data breaches <a href="https://www.washingtonpost.com/opinions/elizabeth-warren-its-time-to-scare-corporate-america-straight/2019/04/02/ca464ab0-5559-11e9-8ef3-fbd41a2ce4d5_story.html">https://www.washingtonpost.com/opinions/elizabeth-warren-its-time-to-scare-corporate-america-straight/2019/04/02/ca464ab0-5559-11e9-8ef3-fbd41a2ce4d5_story.html</a></p>
<p>#5yrsago How EFF’s Eva Galperin plans to destroy the stalkerware industry <a href="https://www.wired.com/story/eva-galperin-stalkerware-kaspersky-antivirus/">https://www.wired.com/story/eva-galperin-stalkerware-kaspersky-antivirus/</a></p>
<p>#5yrsago After years of insisting that DRM in HTML wouldn’t block open source implementations, Google says it won’t support open source implementations <a href="https://memex.craphound.com/2019/04/03/after-years-of-insisting-that-drm-in-html-wouldnt-block-open-source-implementations-google-says-it-wont-support-open-source-implementations/">https://memex.craphound.com/2019/04/03/after-years-of-insisting-that-drm-in-html-wouldnt-block-open-source-implementations-google-says-it-wont-support-open-source-implementations/</a></p>
<p>#5yrsago After months of insisting that #Article13 doesn’t require filters, top EU Commissioner says “Article 13 requires filters” <a href="https://memex.craphound.com/2019/04/03/after-months-of-insisting-that-article13-doesnt-require-filters-top-eu-commissioner-says-article-13-requires-filters/">https://memex.craphound.com/2019/04/03/after-months-of-insisting-that-article13-doesnt-require-filters-top-eu-commissioner-says-article-13-requires-filters/</a></p>
<p>#5yrsago Notices at Intel press event seem to say attending photographers must assign copyright to all pictures and videos to the company? <a href="https://web.archive.org/web/20200616222543/http://mitchwagner.com/2019/04/02/video-consent-notice-posted-discreetly-in-a-couple-of-places-on-the-walls-at-the-intel-press-analyst-event-today/">https://web.archive.org/web/20200616222543/http://mitchwagner.com/2019/04/02/video-consent-notice-posted-discreetly-in-a-couple-of-places-on-the-walls-at-the-intel-press-analyst-event-today/</a></p>
<p>#5yrsago Patagonia tells banks and oil companies that they can no longer buy co-branded vests <a href="https://www.buzzfeednews.com/article/katienotopoulos/patagonia-power-vest-policy-change">https://www.buzzfeednews.com/article/katienotopoulos/patagonia-power-vest-policy-change</a></p>
<p>#5yrsago Talking about Radicalized with the CBC: Privilege, atavism, techno-realism and seizing the means of information <a href="https://www.cbc.ca/books/cory-doctorow-on-radicalized-the-problem-with-superheroes-and-writing-speculative-fiction-in-a-jaded-world-1.5080939">https://www.cbc.ca/books/cory-doctorow-on-radicalized-the-problem-with-superheroes-and-writing-speculative-fiction-in-a-jaded-world-1.5080939</a></p>
<p>#5yrsago News organizations have all but abandoned their archives <a href="https://memex.craphound.com/2019/04/04/news-organizations-have-all-but-abandoned-their-archives/">https://memex.craphound.com/2019/04/04/news-organizations-have-all-but-abandoned-their-archives/</a></p>
<p>#5yrsago After Christchurch shooting, Australia doubles down on being stampeded into catastrophically stupid tech laws <a href="https://memex.craphound.com/2019/04/04/after-christchurch-shooting-australia-doubles-down-on-being-stampeded-into-catastrophically-stupid-tech-laws/">https://memex.craphound.com/2019/04/04/after-christchurch-shooting-australia-doubles-down-on-being-stampeded-into-catastrophically-stupid-tech-laws/</a></p>
<p>#5yrsago A rapidly proliferating software license bars use by companies with poor labor practices <a href="https://www.wired.com/story/how-github-helping-overworked-chinese-programmers/">https://www.wired.com/story/how-github-helping-overworked-chinese-programmers/</a></p>
<p>#5yrsago “Open source” companies are playing games with licensing to sneak in proprietary code, freeze out competitors, fight enclosure <a href="https://www.scalevp.com/insights/making-sense-of-a-crazy-year-in-open-source/">https://www.scalevp.com/insights/making-sense-of-a-crazy-year-in-open-source/</a></p>
<p>#5yrsago Fear that far-right terrorists will stage attacks if Brexit is canceled <a href="https://theintercept.com/2019/04/04/specter-far-right-violence-haunts-brexit-britain/">https://theintercept.com/2019/04/04/specter-far-right-violence-haunts-brexit-britain/</a></p>
<p>#1yrago Elizabeth Warren on weaponized budget models <a href="https://pluralistic.net/2023/04/04/cbo-says-no/#wealth-tax">https://pluralistic.net/2023/04/04/cbo-says-no/#wealth-tax</a></p>
<p>#1yrago The problem with economic models <a href="https://pluralistic.net/2023/04/03/all-models-are-wrong/#some-are-useful">https://pluralistic.net/2023/04/03/all-models-are-wrong/#some-are-useful</a></p>
<hr>

<h2>Upcoming appearances (<a href="https://pluralistic.net/2024/04/04/teach-me-how-to-shruggie/#upcoming">permalink</a>)</h2>
<p><img decoding="async" alt="A photo of me onstage, giving a speech, holding a mic." src="https://i0.wp.com/craphound.com/images/appearances.jpg?w=840&amp;ssl=1" data-recalc-dims="1"></p>
<ul>
<li>Computer Pasts/Computer Futures (NYU/virtual), Apr 4<br>
<a href="https://steinhardt.nyu.edu/events/deans-public-square-series-computer-pasts-computer-futures">https://steinhardt.nyu.edu/events/deans-public-square-series-computer-pasts-computer-futures</a>
</li>
<li>
<p>The Bezzle at Harvard Berkman-Klein Center, with Randall Munroe (Boston), Apr 11<br>
<a href="https://cyber.harvard.edu/events/enshittification">https://cyber.harvard.edu/events/enshittification</a></p>
</li>
<li>
<p>RISD Debates in AI (Providence), Apr 12<br>
<a href="https://involved.risd.edu/event/9777963">https://involved.risd.edu/event/9777963</a></p>
</li>
<li>
<p>The Bezzle at Anderson's Books (Chicago), Apr 17<br>
<a href="https://www.andersonsbookshop.com/event/cory-doctorow-1">https://www.andersonsbookshop.com/event/cory-doctorow-1</a></p>
</li>
<li>
<p>Torino Biennale Tecnologia (Apr 19-21)<br>
<a href="https://www.turismotorino.org/en/experiences/events/biennale-tecnologia">https://www.turismotorino.org/en/experiences/events/biennale-tecnologia</a></p>
</li>
<li>
<p>Canadian Centre for Policy Alternatives (Winnipeg), May 2<br>
<a href="https://www.eventbrite.ca/e/cory-doctorow-tickets-798820071337?aff=oddtdtcreator">https://www.eventbrite.ca/e/cory-doctorow-tickets-798820071337?aff=oddtdtcreator</a></p>
</li>
<li>
<p>Tartu Prima Vista Literary Festival (May 5-11)<br>
<a href="https://tartu2024.ee/en/kirjandusfestival/">https://tartu2024.ee/en/kirjandusfestival/</a></p>
</li>
<li>
<p>Tim O’Reilly and Cory Doctorow on “Enshittification” and the Future of AI (May 14)<br>
<a href="https://www.oreilly.com/live-events/tim-oreilly-and-cory-doctorow-on-enshittification-and-the-future-of-ai/0642572001651/">https://www.oreilly.com/live-events/tim-oreilly-and-cory-doctorow-on-enshittification-and-the-future-of-ai/0642572001651/</a></p>
</li>
<li>
<p>Media Ecology Association keynote (Amherst, NY), Jun 6-9<br>
<a href="https://media-ecology.org/convention">https://media-ecology.org/convention</a></p>
</li>
<li>
<p>American Association of Law Libraries keynote (Chicago), Jul 21<br>
<a href="https://www.aallnet.org/conference/agenda/keynote-speaker/">https://www.aallnet.org/conference/agenda/keynote-speaker/</a></p>
</li>
</ul>
<hr>
<p><a name="recent"></a><br>
<img decoding="async" alt="A screenshot of me at my desk, doing a livecast." src="https://i0.wp.com/craphound.com/images/recentappearances.jpg?w=840&amp;ssl=1" data-recalc-dims="1"></p>
<h2>Recent appearances (<a href="https://pluralistic.net/2024/04/04/teach-me-how-to-shruggie/#recent">permalink</a>)</h2>
<ul>
<li>The Scam Economy (Lost Dollar Business Club)<br>
<a href="https://www.youtube.com/watch?v=SChg9ZiY_bk">https://www.youtube.com/watch?v=SChg9ZiY_bk</a>
</li>
<li>
<p>Private Prisons, Finance Ghouls and The Bezzle (It Could Happen Here)<br>
<a href="https://www.iheart.com/podcast/105-it-could-happen-here-30717896/episode/private-prisons-finance-ghouls-and-the-161844728/">https://www.iheart.com/podcast/105-it-could-happen-here-30717896/episode/private-prisons-finance-ghouls-and-the-161844728/</a></p>
</li>
<li>
<p>Cory Doctorow’s new tech crime thriller takes us back to the days of Yahoo! (Betakit)<br>
<a href="https://betakit.com/cory-doctorow-the-bezzle-betakit-podcast/">https://betakit.com/cory-doctorow-the-bezzle-betakit-podcast/</a></p>
</li>
</ul>
<hr>
<p><a name="latest"></a><br>
<img decoding="async" alt="A grid of my books with Will Stahle covers.." src="https://i0.wp.com/craphound.com/images/recent.jpg?w=840&amp;ssl=1" data-recalc-dims="1"></p>
<h2>Latest books (<a href="https://pluralistic.net/2024/04/04/teach-me-how-to-shruggie/#latest">permalink</a>)</h2>
<ul>
<li>The Bezzle: a sequel to "Red Team Blues," about prison-tech and other grifts, Tor Books (US), Head of Zeus (UK), February 2024 (<a href="http://the-bezzle.org/">the-bezzle.org</a>). Signed, personalized copies at Dark Delicacies (<a href="https://www.darkdel.com/store/p3062/Available_Feb_20th%3A_The_Bezzle_HB.html#/">https://www.darkdel.com/store/p3062/Available_Feb_20th%3A_The_Bezzle_HB.html#/</a>).
</li>
<li>
<p>"The Lost Cause:" a solarpunk novel of hope in the climate emergency, Tor Books (US), Head of Zeus (UK), November 2023 (<a href="http://lost-cause.org/">http://lost-cause.org</a>). Signed, personalized copies at Dark Delicacies (<a href="https://www.darkdel.com/store/p3007/Pre-Order_Signed_Copies%3A_The_Lost_Cause_HB.html#/">https://www.darkdel.com/store/p3007/Pre-Order_Signed_Copies%3A_The_Lost_Cause_HB.html#/</a>)</p>
</li>
<li>
<p>"The Internet Con": A nonfiction book about interoperability and Big Tech (Verso) September 2023 (<a href="http://seizethemeansofcomputation.org/">http://seizethemeansofcomputation.org</a>). Signed copies at Book Soup (<a href="https://www.booksoup.com/book/9781804291245">https://www.booksoup.com/book/9781804291245</a>).</p>
</li>
<li>
<p>"Red Team Blues": "A grabby, compulsive thriller that will leave you knowing more about how the world works than you did before." Tor Books <a href="http://redteamblues.com/">http://redteamblues.com</a>. Signed copies at Dark Delicacies (US): <a href="https://www.darkdel.com/store/p2873/Wed%2C_Apr_26th_6pm%3A_Red_Team_Blues%3A_A_Martin_Hench_Novel_HB.html#/"> and Forbidden Planet (UK): </a><a href="https://forbiddenplanet.com/385004-red-team-blues-signed-edition-hardcover/">https://forbiddenplanet.com/385004-red-team-blues-signed-edition-hardcover/</a>.</p>
</li>
<li>
<p>"Chokepoint Capitalism: How to Beat Big Tech, Tame Big Content, and Get Artists Paid, with Rebecca Giblin", on how to unrig the markets for creative labor, Beacon Press/Scribe 2022 <a href="https://chokepointcapitalism.com/">https://chokepointcapitalism.com</a></p>
</li>
<li>
<p>"Attack Surface": The third Little Brother novel, a standalone technothriller for adults. The <em>Washington Post</em> called it "a political cyberthriller, vigorous, bold and savvy about the limits of revolution and resistance." Order signed, personalized copies from Dark Delicacies <a href="https://www.darkdel.com/store/p1840/Available_Now%3A_Attack_Surface.html">https://www.darkdel.com/store/p1840/Available_Now%3A_Attack_Surface.html</a></p>
</li>
<li>
<p>"How to Destroy Surveillance Capitalism": an anti-monopoly pamphlet analyzing the true harms of surveillance capitalism and proposing a solution. <a href="https://onezero.medium.com/how-to-destroy-surveillance-capitalism-8135e6744d59?sk=f6cd10e54e20a07d4c6d0f3ac011af6b">https://onezero.medium.com/how-to-destroy-surveillance-capitalism-8135e6744d59?sk=f6cd10e54e20a07d4c6d0f3ac011af6b</a>) (signed copies: <a href="https://www.darkdel.com/store/p2024/Available_Now%3A__How_to_Destroy_Surveillance_Capitalism.html">https://www.darkdel.com/store/p2024/Available_Now%3A__How_to_Destroy_Surveillance_Capitalism.html</a>)</p>
</li>
<li>
<p>"Little Brother/Homeland": A reissue omnibus edition with a new introduction by Edward Snowden: <a href="https://us.macmillan.com/books/9781250774583">https://us.macmillan.com/books/9781250774583</a>; personalized/signed copies here: <a href="https://www.darkdel.com/store/p1750/July%3A__Little_Brother_%26_Homeland.html">https://www.darkdel.com/store/p1750/July%3A__Little_Brother_%26_Homeland.html</a></p>
</li>
<li>
<p>"Poesy the Monster Slayer" a picture book about monsters, bedtime, gender, and kicking ass. Order here: <a href="https://us.macmillan.com/books/9781626723627">https://us.macmillan.com/books/9781626723627</a>. Get a personalized, signed copy here: <a href="https://www.darkdel.com/store/p2682/Corey_Doctorow%3A_Poesy_the_Monster_Slayer_HB.html#/">https://www.darkdel.com/store/p2682/Corey_Doctorow%3A_Poesy_the_Monster_Slayer_HB.html#/</a>.</p>
</li>
</ul>
<hr>
<p><a name="upcoming-books"></a><br>
<img decoding="async" alt="A cardboard book box with the Macmillan logo." src="https://i0.wp.com/craphound.com/images/upcoming-books.jpg?w=840&amp;ssl=1" data-recalc-dims="1"></p>
<h2>Upcoming books (<a href="https://pluralistic.net/2024/04/04/teach-me-how-to-shruggie/#upcoming-books">permalink</a>)</h2>
<ul>
<li>Picks and Shovels: a sequel to "Red Team Blues," about the heroic era of the PC, Tor Books, February 2025
</li>
<li>
<p>Unauthorized Bread: a graphic novel adapted from my novella about refugees, toasters and DRM, FirstSecond, 2025</p>
</li>
</ul>
<hr>
<p><a name="bragsheet"></a><br>
<img decoding="async" src="https://i0.wp.com/craphound.com/images/colophonimages.jpeg?w=840&amp;ssl=1" data-recalc-dims="1"></p>
<h2>Colophon (<a href="https://pluralistic.net/2024/04/04/teach-me-how-to-shruggie/#bragsheet">permalink</a>)</h2>
<p>Today's top sources:</p>
<p><b>Currently writing: </b></p>
<ul>
<li>A Little Brother short story about DIY insulin PLANNING
</li>
<li>
<p>Picks and Shovels, a Martin Hench noir thriller about the heroic era of the PC. FORTHCOMING TOR BOOKS JAN 2025</p>
</li>
<li>
<p>Vigilant, Little Brother short story about remote invigilation. FORTHCOMING ON TOR.COM</p>
</li>
<li>
<p>Spill, a Little Brother short story about pipeline protests. FORTHCOMING ON TOR.COM</p>
</li>
</ul>
<p><b>Latest podcast:</b> Subprime gadgets <a href="https://craphound.com/news/2024/03/31/subprime-gadgets/">https://craphound.com/news/2024/03/31/subprime-gadgets/</a></p>
<hr>
<p><img decoding="async" src="https://i0.wp.com/craphound.com/images/by.svg.png?w=840&amp;ssl=1" data-recalc-dims="1"></p>
<p>This work – excluding any serialized fiction – is licensed under a Creative Commons Attribution 4.0 license. That means you can use it any way you like, including commercially, provided that you attribute it to me, Cory Doctorow, and include a link to pluralistic.net.</p>
<p><a href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</a></p>
<p>Quotations and images are not included in this license; they are included either under a limitation or exception to copyright, or on the basis of a separate license. Please exercise caution.</p>
<hr>
<h2>How to get Pluralistic:</h2>
<p>Blog (no ads, tracking, or data-collection):</p>
<p><a href="http://pluralistic.net/">Pluralistic.net</a></p>
<p>Newsletter (no ads, tracking, or data-collection):</p>
<p><a href="https://pluralistic.net/plura-list">https://pluralistic.net/plura-list</a></p>
<p>Mastodon (no ads, tracking, or data-collection):</p>
<p><a href="https://mamot.fr/@pluralistic">https://mamot.fr/@pluralistic</a></p>
<p>Medium (no ads, paywalled):</p>
<p><a href="https://doctorow.medium.com/">https://doctorow.medium.com/</a></p>
<p>Twitter (mass-scale, unrestricted, third-party surveillance and advertising):</p>
<p><a href="https://twitter.com/doctorow">https://twitter.com/doctorow</a></p>
<p>Tumblr (mass-scale, unrestricted, third-party surveillance and advertising):</p>
<p><a href="https://mostlysignssomeportents.tumblr.com/tagged/pluralistic">https://mostlysignssomeportents.tumblr.com/tagged/pluralistic</a></p>
<p>"<em>When life gives you SARS, you make sarsaparilla</em>" -Joey "Accordion Guy" DeVilla</p>

	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Language models as compilers: Simulating pseudocode execution (155 pts)]]></title>
            <link>https://arxiv.org/abs/2404.02575</link>
            <guid>39934956</guid>
            <pubDate>Thu, 04 Apr 2024 19:46:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2404.02575">https://arxiv.org/abs/2404.02575</a>, See on <a href="https://news.ycombinator.com/item?id=39934956">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
    <div><p><span>Authors:</span><a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chae,+H">Hyungjoo Chae</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim,+Y">Yeonghyeon Kim</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim,+S">Seungone Kim</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ong,+K+T">Kai Tzu-iunn Ong</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kwak,+B">Beong-woo Kwak</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim,+M">Moohyeon Kim</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim,+S">Seonghwan Kim</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kwon,+T">Taeyoon Kwon</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chung,+J">Jiwan Chung</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu,+Y">Youngjae Yu</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yeo,+J">Jinyoung Yeo</a></p></div>            
    <p><a href="https://arxiv.org/pdf/2404.02575">View PDF</a></p><blockquote>
            <span>Abstract:</span>Algorithmic reasoning refers to the ability to understand the complex patterns behind the problem and decompose them into a sequence of reasoning steps towards the solution. Such nature of algorithmic reasoning makes it a challenge for large language models (LLMs), even though they have demonstrated promising performance in other reasoning tasks. Within this context, some recent studies use programming languages (e.g., Python) to express the necessary logic for solving a given instance/question (e.g., Program-of-Thought) as inspired by their strict and precise syntaxes. However, it is non-trivial to write an executable code that expresses the correct logic on the fly within a single inference call. Also, the code generated specifically for an instance cannot be reused for others, even if they are from the same task and might require identical logic to solve. This paper presents Think-and-Execute, a novel framework that decomposes the reasoning process of language models into two steps. (1) In Think, we discover a task-level logic that is shared across all instances for solving a given task and then express the logic with pseudocode; (2) In Execute, we further tailor the generated pseudocode to each instance and simulate the execution of the code. With extensive experiments on seven algorithmic reasoning tasks, we demonstrate the effectiveness of Think-and-Execute. Our approach better improves LMs' reasoning compared to several strong baselines performing instance-specific reasoning (e.g., CoT and PoT), suggesting the helpfulness of discovering task-level logic. Also, we show that compared to natural language, pseudocode can better guide the reasoning of LMs, even though they are trained to follow natural language instructions.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Hyungjoo Chae [<a href="https://arxiv.org/show-email/ded24a23/2404.02575">view email</a>]      <br>    <strong>[v1]</strong>
        Wed, 3 Apr 2024 08:49:11 UTC (1,323 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Slowroads (106 pts)]]></title>
            <link>https://slowroads.io/</link>
            <guid>39934881</guid>
            <pubDate>Thu, 04 Apr 2024 19:39:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://slowroads.io/">https://slowroads.io/</a>, See on <a href="https://news.ycombinator.com/item?id=39934881">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Fake AI law firms are sending fake DMCA threats to generate fake SEO gains (231 pts)]]></title>
            <link>https://arstechnica.com/gadgets/2024/04/fake-ai-law-firms-are-sending-fake-dmca-threats-to-generate-fake-seo-gains/</link>
            <guid>39934696</guid>
            <pubDate>Thu, 04 Apr 2024 19:23:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/gadgets/2024/04/fake-ai-law-firms-are-sending-fake-dmca-threats-to-generate-fake-seo-gains/">https://arstechnica.com/gadgets/2024/04/fake-ai-law-firms-are-sending-fake-dmca-threats-to-generate-fake-seo-gains/</a>, See on <a href="https://news.ycombinator.com/item?id=39934696">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <header>
            <h4>
      Dewey Fakum &amp; Howe, LLP    —
</h4>
            
            <h2 itemprop="description">How one journalist found himself targeted by generative AI over a keyfob photo.</h2>
                    </header>
        <div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2024/04/GettyImages-672156981-800x749.jpg" alt="Face composed of many pixellated squares, joining together">
      <figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2024/04/GettyImages-672156981-scaled.jpg" data-height="2396" data-width="2560">Enlarge</a> <span>/</span> A person made of many parts, similar to the attorney who handles both severe criminal law and copyright takedowns for an Arizona law firm.</p><p>Getty Images</p></figcaption>  </figure>

  




<!-- cache hit 423:single/related:e4f33b538e4def223233d4b540e53a3e --><!-- empty -->
<p>If you run a personal or hobby website, getting a copyright notice from a law firm about an image on your site can trigger some fast-acting panic. As someone who has paid to settle a news service-licensing issue before, I can empathize with anybody who wants to make this kind of thing go away.</p>
<p>Which is why a new kind of angle-on-an-angle scheme can seem both obvious to spot and likely effective. Ernie Smith, the prolific, ever-curious writer behind the newsletter <a href="https://tedium.co/">Tedium</a>, received a "DMCA Copyright Infringement Notice" in late March from "Commonwealth Legal," representing the "Intellectual Property division" of Tech4Gods.</p>
<p>The issue was with <a href="https://unsplash.com/photos/a-close-up-of-a-cell-phone-on-a-car-dashboard-MQYdpvztfsE">a photo of a keyfob</a>&nbsp;from legitimate photo service Unsplash&nbsp;used in service of a post about <a href="https://midrange.tedium.co/issues/the-great-key-fob-caper/">a strange Uber ride Smith once took</a>. As Smith <a href="https://writing.exchange/@ernie/112180217732787648">detailed in a Mastodon thread</a>, the purported firm needed him to "add a credit to our client immediately" through a link to Tech4Gods, and said it should be "addressed in the next five business days." Removing the image "does not conclude the matter," and should Smith not have taken action, the putative firm would have to "activate" its case, relying on <a href="https://www.law.cornell.edu/uscode/text/17/512">DMCA 512(c)</a> (which, <a href="https://www.copyright.gov/512/">in many readings</a>, actually does grant relief should a website owner, unaware of infringing material, "act expeditiously to remove" said material). The email unhelpfully points to the main page of the <a href="http://archive.org/">Internet Archive</a>&nbsp;so that Smith might review "past usage records."</p>
<figure><img alt="A slice of the website for Commonwealth Legal Services, with every word of that phrase, including &quot;for,&quot; called into question." src="https://cdn.arstechnica.net/wp-content/uploads/2024/04/Screenshot-2024-04-04-at-2.15.28%E2%80%AFPM.png" width="1832" height="1024"><figcaption><p>A slice of the website for Commonwealth Legal Services, with every word of that phrase, including "for," called into question.</p><p>Commonwealth Legal Services</p></figcaption></figure>
<p>There are quite a few issues with Commonwealth Legal's request, as detailed by Smith and<a href="https://www.404media.co/a-law-firm-of-ai-generated-lawyers-is-sending-fake-threats-as-an-seo-scam/">&nbsp;404 Media</a>. Chief among them is that <a href="https://www.commonwealth-team.net/?ref=404media.co">Commonwealth Legal</a>, a firm theoretically based in Arizona (which <a href="https://www.merriam-webster.com/grammar/whats-the-difference-between-a-commonwealth-and-a-state">is not a commonwealth</a>), almost certainly does not exist. Despite the 2018 copyright displayed on the site, the firm's website domain was seemingly <a href="https://whois.domaintools.com/commonwealth-team.net">registered on March 1, 2024</a>, with a Canadian IP location. The address on the firm's site leads to a location that, to say the least, <a href="https://writing.exchange/@ernie/112180244964385367">does not match the "fourth floor" indicated on the website</a>.</p>                                            
                                                        
<p>While the law firm's website is stuffed full of stock images, so are many websites for professional services. The real tell is the site's <a href="https://www.commonwealth-team.net/attorneys/">list of attorneys</a>, most of which, as 404 Media puts it, have "vacant, thousand-yard stares" common to AI-generated faces. AI detection firm <a href="http://realitydefender.com/">Reality Defender</a> told 404 Media that his service spotted AI generation in every attorneys' image, "most likely by a Generative Adversarial Network (GAN) model."</p>
<p>Then there are the attorneys' bios, which offer surface-level competence underpinned by bizarre setups. Five of the 12 supposedly come from acclaimed law schools at Harvard, Yale, Stanford, and University of Chicago. The other seven seem to have graduated from the top five results you might get for "Arizona Law School." <a href="https://www.commonwealth-team.net/attorneys/sarah-walker/">Sarah Walker</a> has a practice based on "Copyright Violation and Judicial Criminal Proceedings," a quite uncommon pairing. Sometimes she is "upholding the rights of artists," but she can also "handle high-stakes criminal cases." Walker, it seems, couldn't pick just one track at Yale Law School.</p>
<p>Why would someone go to the trouble of making a law firm out of NameCheap, stock art, and AI images (and seemingly copy) to send quasi-legal demands to site owners? Backlinks, that's why. Backlinks are links from a site that Google (or others, but almost always Google) holds in high esteem to a site trying to rank up. Whether spammed, traded, generated, or demanded through a fake firm, <a href="https://arstechnica.com/information-technology/2015/07/inside-an-online-content-mill-or-writing-4156-words-a-day-just-to-earn-lunch-money/">backlinks power the search engine optimization</a> (SEO) gray, to very dark gray, market. For all their touted algorithmic (and now AI) prowess, search engines have always had a hard time <a href="https://arstechnica.com/gaming/2017/04/an-interview-with-cory-doctorow-on-beating-death-post-scarcity-and-everything/2/">gauging backlink quality and context</a>, so some site owners still buy backlinks.</p>
<p>The owner of Tech4Gods told 404 Media's Jason Koebler that he did buy backlinks for his gadget review site (with "AI writing assistants"). He disclaimed owning the disputed image or any images and made vague suggestions that a disgruntled former contractor may be trying to poison his ranking with spam links.</p>
<p>Asked by Ars if he had heard back from "Commonwealth Legal" now that five business days were up, <a href="https://bsky.app/profile/ernie.tedium.co/post/3kpdg6vsard2u">Ernie Smith tells Ars</a>: "No, alas."</p>
<p><em>This post was updated at 4:50 p.m. Eastern to include Ernie Smith's response.</em></p>

                                                </div>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Understanding and managing the impact of machine learning models on the web (120 pts)]]></title>
            <link>https://www.w3.org/reports/ai-web-impact/</link>
            <guid>39934584</guid>
            <pubDate>Thu, 04 Apr 2024 19:11:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.w3.org/reports/ai-web-impact/">https://www.w3.org/reports/ai-web-impact/</a>, See on <a href="https://news.ycombinator.com/item?id=39934584">Hacker News</a></p>
<div id="readability-page-1" class="page">

<section id="abstract"><h2>Abstract</h2>
<p>
This document proposes an analysis of the systemic impact of <a data-link-type="dfn|abstract-op" href="#dfn-artificial-intelligence-system" id="ref-for-dfn-artificial-intelligence-system-1">AI systems</a>, and in particular ones based on <a data-link-type="dfn|abstract-op" href="#dfn-model" id="ref-for-dfn-model-1">Machine Learning models</a>, on the Web, and the role that Web standardization may play in managing that impact.
</p>
</section>
<section id="sotd"><h2>Status of This Document</h2>
<p>
This document is intended to capture the current shared understanding of the <a href="https://www.w3.org/staff/"><abbr title="World Wide Web Consortium">W3C</abbr> Team</a> on the current and expected impact of developments linked to <a data-link-type="dfn|abstract-op" href="#dfn-artificial-intelligence-system" id="ref-for-dfn-artificial-intelligence-system-2">Artificial Intelligence systems</a> on the Web, and identifying explorations the World Wide Web Consortium  community has started or ought to be starting, to manage that impact. It does not represent any consensus from the <abbr title="World Wide Web Consortium">W3C</abbr> Membership nor is it a standardization document.
</p>
<p>
 The document was authored by Dominique Hazaël-Massieux (<a href="mailto:dom@w3.org">dom@w3.org</a>), with significant contributions from the rest of the <abbr title="World Wide Web Consortium">W3C</abbr> Team.</p>
<p>
This document aims first and foremost to help structure discussions on what may be needed at the standardization level to make the systemic impact of AI (and specifically, <a data-link-type="dfn|abstract-op" href="#dfn-model" id="ref-for-dfn-model-2">Machine Learning models</a>) less harmful or more manageable. It is bound to be incomplete and sometimes wrong - we are gathering input and feedback in <a href="https://github.com/w3c/ai-web-impact/issues">GitHub</a>, preferably before June 30, 2024.
</p>
<p>
Depending on the feedback received, possible next steps include more in-depth stakeholder interviews, a dedicated <abbr title="World Wide Web Consortium">W3C</abbr> Workshop, or developing a standardization roadmap.</p>

</section><nav id="toc"><h2 id="table-of-contents">Table of Contents</h2><ol><li><a href="#abstract">Abstract</a></li><li><a href="#sotd">Status of This Document</a></li><li><a href="#executive-summary"><bdi>1. </bdi>Executive Summary</a></li><li><a href="#introduction"><bdi>2. </bdi>Introduction</a><ol><li><a href="#terminology"><bdi>2.1 </bdi>Terminology</a></li></ol></li><li><a href="#intersections-between-ai-systems-and-the-web"><bdi>3. </bdi>Intersections between AI systems and the Web</a></li><li><a href="#ethics-and-societal-impact"><bdi>4. </bdi>Ethics and societal impact</a><ol><li><a href="#respecting-autonomy-and-transparency"><bdi>4.1 </bdi>Respecting <span>autonomy</span> and <span>transparency</span></a><ol><li><a href="#transparency-on-ai-generated-content"><bdi>4.1.1 </bdi>Transparency on AI-generated content</a></li><li><a href="#transparency-on-ai-mediated-services"><bdi>4.1.2 </bdi>Transparency on AI-mediated services</a></li></ol></li><li><a href="#right-to-privacy-and-data-control"><bdi>4.2 </bdi>Right to <span>privacy and data control</span></a></li><li><a href="#safety-and-security"><bdi>4.3 </bdi><span>Safety and security</span></a></li><li><a href="#sustainability"><bdi>4.4 </bdi><span>Sustainability</span></a></li><li><a href="#balancing-content-creators-incentives-and-consumers-rights"><bdi>4.5 </bdi>Balancing content creators incentives and consumers rights</a><ol><li><a href="#comparison-with-search-engines"><bdi>4.5.1 </bdi>Comparison with search engines</a></li></ol></li></ol></li><li><a href="#interop"><bdi>5. </bdi>Impact of <span data-link-type="dfn|abstract-op">AI systems</span> on interoperability</a></li><li><a href="#references"><bdi>A. </bdi>References</a><ol><li><a href="#informative-references"><bdi>A.1 </bdi>Informative references</a></li></ol></li></ol></nav>

<section id="executive-summary">
  

  <p><a data-link-type="dfn|abstract-op" href="#dfn-model" id="ref-for-dfn-model-3">Machine Learning models</a> support a new generation of <a data-link-type="dfn|abstract-op" href="#dfn-artificial-intelligence-system" id="ref-for-dfn-artificial-intelligence-system-3">AI systems</a>. These models are often <a data-link-type="dfn|abstract-op" data-lt="training" href="#dfn-training" id="ref-for-dfn-training-1">trained</a> on a large amount of Web content, deployed at scale through web interfaces, and can be used to generate plausible content at unprecedented speed and cost.</p>
  <p>Given the scope and scale of these intersections, this wave of <a data-link-type="dfn|abstract-op" href="#dfn-artificial-intelligence-system" id="ref-for-dfn-artificial-intelligence-system-4">AI systems</a> is having potential systemic impact on the Web and some of the equilibriums on which its ecosystem had grown.</p>
  <p>This document reviews these intersections through their ethical, societal and technical impacts and highlights a number of areas where standardization, guidelines and interoperability could help manage these changes:</p>
  <ul>
    <li>a <a href="#b7">consent mechanism for the use of Web content in training pipelines</a>,</li>
    <li><a href="#b1">labeling content as computer-generated</a>,</li>
    <li><a href="#b2">surfacing training sources in model cards</a>,</li>
    <li><a href="#b3">exposing model-backed Web APIs</a>,</li>
    <li><a href="#b4">personal data stores</a> to reduce risk of private data exposure,</li>
    <li><a href="#b5">strengthening credentials and identity mechanisms</a> in light of new impersonation risks,</li>
    <li>an <a href="#b6">evaluation framework for the environmental impact of Web standards</a>,</li>
    <li>a <a href="#b8">framework to manage interoperability based on model inference</a>, including for non-deterministic models.</li>
  </ul>
  <p>We are <a href="https://github.com/w3c/ai-web-impact/issues">seeking input</a> from the community on proposals that could help make progress on these topics, and on other topics that this document has failed to identify.</p>
</section>

<section id="introduction">



<p>
Recent developments in the decades-long computer science field of Artificial Intelligence have made a number of systems emerge that already have started having <strong>systemic</strong> impacts on the Web and can be expected to further transform a number of shared expectations on which the health of the Web had relied so far.
</p>
<p>
To help structure a conversation within the <abbr title="World Wide Web Consortium">W3C</abbr> community (and possibly with other Web-related standards organization) about these transformations, this document collects the current shared understanding among the <abbr title="World Wide Web Consortium">W3C</abbr> Team of the intersections of "<a data-link-type="dfn|abstract-op" href="#dfn-artificial-intelligence" id="ref-for-dfn-artificial-intelligence-1">Artificial Intelligence</a>", more specifically in the field of <a data-link-type="dfn|abstract-op" href="#dfn-model" id="ref-for-dfn-model-4">Machine Learning models</a> (including Large Language Models and other so called generative AI models), with the Web as a system, and ongoing <abbr title="World Wide Web Consortium">W3C</abbr> development in this space. It is also a goal to raise questions about additional explorations that may be needed as further developments in this space arise.
</p>
<p>
That current understanding is bound to be incomplete or sometimes plain wrong; we hope that by publishing this document and inviting community reviews on it, we iteratively improve this shared understanding and help build a community roadmap to increase the positive impact and decrease the harms that are emerging in this intersection.
</p>
<section id="terminology">



<p>
The term "Artificial Intelligence" covers a very broad spectrum of algorithms, techniques and technologies. [<cite><a data-link-type="biblio" href="#bib-iso/iec-22989" title="Artificial intelligence concepts and terminology">ISO/IEC-22989</a></cite>] defines <dfn id="dfn-artificial-intelligence" tabindex="0" aria-haspopup="dialog" data-dfn-type="dfn">Artificial Intelligence</dfn> as "research and development of mechanisms and applications of <a data-link-type="dfn|abstract-op" href="#dfn-artificial-intelligence-system" id="ref-for-dfn-artificial-intelligence-system-5">AI systems</a>", with <dfn data-lt="Artificial Intelligence system|AI system" data-plurals="ai systems|artificial intelligence systems" id="dfn-artificial-intelligence-system" tabindex="0" aria-haspopup="dialog" data-dfn-type="dfn">AI system</dfn>s being "an engineered system that generates outputs such as content, forecasts, recommendations or decisions for a given set of human-defined objectives". At the time of the writing of this document in early 2024, the gist of the Web ecosystem conversation on Artificial Intelligence is mostly about systems based on <dfn id="dfn-machine-learning" tabindex="0" aria-haspopup="dialog" data-dfn-type="dfn">Machine Learning</dfn> ("process of optimizing model parameters through computational techniques, such that the model's behavior reflects the data or experience") and its software manifestation, <dfn data-lt="model|Machine Learning model" data-plurals="machine learning models" id="dfn-model" tabindex="0" aria-haspopup="dialog" data-dfn-type="dfn">Machine Learning model</dfn>s ("mathematical construct that generates an inference or prediction based on input data or information").
</p>
<p>
While we acknowledge the much broader meaning of Artificial Intelligence and its intersection with a number of other Web- and <abbr title="World Wide Web Consortium">W3C</abbr>-related activities (e.g., the Semantic Web and Linked Data), this document willfully focuses only on the current conversation around the impact that these <a data-link-type="dfn|abstract-op" href="#dfn-model" id="ref-for-dfn-model-5">Machine Learning models</a> are bringing to the Web. We further acknowledge that this document has been developed during, and is partially a response to, a cycle of inflated expectations and investments in that space. That situation underlines the need for a framework to structure the conversation.
</p>
<p>
Because of this focus on <a data-link-type="dfn|abstract-op" href="#dfn-machine-learning" id="ref-for-dfn-machine-learning-1">Machine Learning</a>, this document analyzes AI impact through the two main phases needed to operate <a data-link-type="dfn|abstract-op" href="#dfn-model" id="ref-for-dfn-model-6">Machine Learning models</a>: <dfn id="dfn-training" tabindex="0" aria-haspopup="dialog" data-dfn-type="dfn">training</dfn> ("process to determine or to improve the parameters of a Machine Learning model, based on a Machine Learning algorithm, by using training data") and <dfn data-lt="run|running|inference" id="dfn-run" tabindex="0" aria-haspopup="dialog" data-dfn-type="dfn">inference</dfn> (the actual usage of these models to produce their expected outcomes), which we also casually refer as running a model.
</p>
</section>
</section>
<section id="intersections-between-ai-systems-and-the-web">



<p>
A major role the Web plays is as a platform for content creators to expose at scale their content to content consumers. AI directly relates to these two sides of the platform:
</p>
<ul>

<li>In a number of cases, models are trained based on content crawled from the Web; the combination of scale and structure in that content (made possible by the underlying standards) has made it an invaluable source of training data that backs some of the most visible results in recent AI developments, such as large language models or image/video generators;

</li><li>Conversely, a number of these AI models can be used to generate content at unprecedented scale, which the reach of the Web allows to deploy seamlessly to the billions of users of the platform.
</li>
</ul>
<p>
When looking more specifically at the browser-mediated part of the Web which remains primarily a client/server architecture, AI models can be <a data-link-type="dfn|abstract-op" href="#dfn-run" id="ref-for-dfn-run-1">run</a> either on the server-side or on the client-side (and somewhat more marginally at this point, in a <a href="https://github.com/webmachinelearning/proposals/issues/5">hybrid-fashion between the two</a>). On the client side, they can either be provided and operated by the browser (either at the user's request, or at the application's request), or entirely by the client-side application itself.
</p>
<p>
It's also worth noting that as <a data-link-type="dfn|abstract-op" href="#dfn-artificial-intelligence-system" id="ref-for-dfn-artificial-intelligence-system-6">AI systems</a> are gaining rapid adoption, their intersection with the Web is bound to evolve and possibly trigger new systemic impact; for instance, emerging <a data-link-type="dfn|abstract-op" href="#dfn-artificial-intelligence-system" id="ref-for-dfn-artificial-intelligence-system-7">AI systems</a> that combine <a data-link-type="dfn|abstract-op" href="#dfn-model" id="ref-for-dfn-model-7">Machine Learning models</a> and content loaded from the Web in real-time may induce revisiting in depth the role and user experience of Web browsers in consuming or searching content.
</p>
</section>
<section id="ethics-and-societal-impact">



<p>
The <a href="https://www.w3.org/TR/ethical-web-principles/"><abbr title="World Wide Web Consortium">W3C</abbr>'s Technical Architecture Group Ethical Web Principles</a> [<cite><a data-link-type="biblio" href="#bib-ethical-web-principles" title="Ethical Web Principles">ethical-web-principles</a></cite>] includes ensuring "<a href="https://www.w3.org/TR/ethical-web-principles/#noharm">the Web should not cause harm to society</a>".
</p>
<p>
As described above, the Web is already a key enabler in some of the recent developments in Artificial Intelligence, and the usage and impact of Artificial Intelligence is being multiplied in scale through its distribution via the Web. This calls for the <abbr title="World Wide Web Consortium">W3C</abbr> community as stewards of the Web to understand potential harms emerging from that combination and to identify potential mitigations to these harms.
</p>
<p>
The <a href="https://www.w3.org/TR/webmachinelearning-ethics/">Ethical Principles for Web Machine Learning</a> [<cite><a data-link-type="biblio" href="#bib-webmachinelearning-ethics" title="Ethical Principles for Web Machine Learning">webmachinelearning-ethics</a></cite>] started in the <a href="https://www.w3.org/groups/wg/webmachinelearning">Web Machine Learning Working Group</a> combine values and principles from the UNESCO <a href="https://unesdoc.unesco.org/ark:/48223/pf0000380455">Recommendation on the Ethics of Artificial Intelligence</a> [<cite><a data-link-type="biblio" href="#bib-unesco-ai" title="Recommendation on the Ethics of Artificial Intelligence">UNESCO-AI</a></cite>] with Web-specific principles from the Ethical Web Principles to identify 4 values and 11 principles that integration of Machine Learning on the Web should follow, and which have helped structure this document.
</p>
<section id="respecting-autonomy-and-transparency">

<section id="transparency-on-ai-generated-content">




<p>
Recent <a data-link-type="dfn|abstract-op" href="#dfn-artificial-intelligence-system" id="ref-for-dfn-artificial-intelligence-system-8">AI systems</a> are able to assist in the partial or complete creation of content (textual, graphic, audio and video) at a level of (at least superficially) credible quality and in quantities beyond that developed by humans. This provides both opportunities and risks for content creators, but more importantly, it creates a systemic risk for content consumers in no longer being able to distinguish or discover authoritative or curated content in a sea of credible (but either possibly or willfully wrong) generated content.
</p>
<p>
That need is pressing directly for end-users as they individually consume content, but also applies to agents that end-users rely on: typically, search engines would likely benefit from transparency on purely AI generated content. Somewhat ironically, crawlers used to train AI models are likely to need such a signal as well, since <a data-link-type="dfn|abstract-op" href="#dfn-training" id="ref-for-dfn-training-2">training</a> models on the output of models may create unexpected and unwanted results.
</p>
<p>
We do not know of any solution that could guarantee (e.g., through cryptography) that a given piece of content was or was not generated (partially or entirely) by <a data-link-type="dfn|abstract-op" href="#dfn-artificial-intelligence-system" id="ref-for-dfn-artificial-intelligence-system-9">AI systems</a>. That gap unfortunately leaves a systemic risk in terms of misinformation and spam that should be of grave concern for the health of the Web as a content distribution platform and of society as a whole.
</p>
<div id="b1">
<p>
A plausible role of standards in this space would be to at least facilitate the <strong>labeling of content</strong> to indicate whether it is the result of a <strong>computer-generated process</strong>. While such labels are unlikely to be enforceable through technical means, they could gain broad adoption with a combination of being automatically added by <a data-link-type="dfn|abstract-op" href="#dfn-artificial-intelligence-system" id="ref-for-dfn-artificial-intelligence-system-10">AI systems</a> (possibly with enough friction that removing them would be at least somewhat costly at scale), and possibly serve as hooks in the regulatory context.
</p>
<p>
A number of proposals have already emerged in this space, which may benefit from more visibility, discussion and ultimately, scalable deployment:
</p>
<ul>
<li><a href="https://c2pa.org/specifications/specifications/1.3/ai-ml/ai_ml.html">C2PA Guidance for AI and Machine Learning</a> [<cite><a data-link-type="biblio" href="#bib-c2pa-ai" title="Guidance for Artificial Intelligence and Machine Learning">C2PA-AI</a></cite>]

</li><li><a href="https://iptc.org/news/iptc-releases-draft-of-digital-source-type-vocabulary-to-support-synthetic-media/">IPTC synthetic media</a> [<cite><a data-link-type="biblio" href="#bib-iptc-dst" title="Digital Source Type vocabulary">IPTC-DST</a></cite>] and its matching representation in <a href="https://github.com/schemaorg/schemaorg/issues/3392">Schema.org</a> [<cite><a data-link-type="biblio" href="#bib-schema-org" title="Schema.org">schema-org</a></cite>]

</li><li><a href="https://github.com/whatwg/html/issues/9479">Proposal: Meta Tag for AI Generated Content</a> in [<cite><a data-link-type="biblio" href="#bib-html" title="HTML Standard">HTML</a></cite>] (individual submission)
</li>
</ul>
<p>
An area that could be explored is role Web browsers might play in surfacing labelling or provenance information of content, e.g., embedded content such as images or video. This can currently be done by publishers' websites or independent verifiers, but integrating this capability into the browser could make the information more convenient for users to access, as well as being independent of any particular publisher or website where the same content may be viewed.
</p>
</div>
</section>
<section id="transparency-on-ai-mediated-services">



<p>
A well-known issue with relying operationally on <a data-link-type="dfn|abstract-op" href="#dfn-model" id="ref-for-dfn-model-8">Machine Learning models</a> is that they will integrate and possibly strengthen any <dfn id="dfn-bias" tabindex="0" aria-haspopup="dialog" data-dfn-type="dfn">bias</dfn> ("systematic difference in treatment of certain objects, people or groups in comparison to others" [[[<cite><a data-link-type="biblio" href="#bib-iso/iec-22989" title="Artificial intelligence concepts and terminology">ISO/IEC-22989</a></cite>]) in the data that was used during their <a data-link-type="dfn|abstract-op" href="#dfn-training" id="ref-for-dfn-training-3">training</a>. <a data-link-type="dfn|abstract-op" href="#dfn-bias" id="ref-for-dfn-bias-1">Bias</a> commonly occurs in other algorithms and human decision processes. Where <a data-link-type="dfn|abstract-op" href="#dfn-artificial-intelligence-system" id="ref-for-dfn-artificial-intelligence-system-11">AI systems</a> make that <a data-link-type="dfn|abstract-op" href="#dfn-bias" id="ref-for-dfn-bias-2">bias</a> a bigger challenge is because these models are at this point harder to audit and amend since they operate mostly as a closed box.
</p>
<p>
Such <a data-link-type="dfn|abstract-op" href="#dfn-bias" id="ref-for-dfn-bias-3">bias</a> will disproportionately affect users whose expected input or output is less well represented in training data (as e.g., discussed in the <a href="https://www.w3.org/WAI/research/ai2023/">report from the 2023 AI &amp; Accessibility research symposium</a> [<cite><a data-link-type="biblio" href="#bib-wai-ai" title="Artificial Intelligence (AI) and Accessibility Research Symposium 2023">WAI-AI</a></cite>]), which intuitively is likely to correlate strongly with users already disenfranchised by society and technology - e.g., if your language, appearance or behavior doesn't fit the mainstream-expected norm, you're less likely to feature in mainstream content and thus less visible or misrepresented in training data.
</p>
<p>
Until better tools emerge to facilitate at least the systematic detection of such <a data-link-type="dfn|abstract-op" href="#dfn-bias" id="ref-for-dfn-bias-4">bias</a>, encouraging and facilitating the systematic publication of information on whether a Machine Learning model is in use, and how such a model was trained and checked for <a data-link-type="dfn|abstract-op" href="#dfn-bias" id="ref-for-dfn-bias-5">bias</a> may help end-users make more informed choices about the services they use (which, of course, only helps if they have a choice in the first place, which may not apply e.g., to some government-provided services).
</p>


<p>
As described below, these APIs also raise engineering questions about how to ensure they provide the 

<a href="#interop">level of interoperability</a> that have been expected from more traditionally deterministic algorithms.
</p>
</section>
</section>

<section id="right-to-privacy-and-data-control">



<p>
Models trained on un-triaged or partially triaged content off the Web are bound to include personally identifiable information (PII). The same is true for models trained on data that users have chosen to share (for public consumption or not) with service providers. These models can often be made to retrieve and share that information with any user who knows how to ask, which breaks expectations of privacy for those whose personal information was collected, and is likely to be in breach with privacy regulations in a number of jurisdictions. Worse, they create risks for new types of attacks (see <a href="#safety-and-security" data-matched-text="[[[#safety-and-security]]]"><bdi>4.3 </bdi><span>Safety and security</span></a>).
</p>
<p>
  While the exclusion rules discussed in the context of content creation could partially help with the first situation, they would not help with the second one. This problem space is likely to be under heavy regulatory and legal scrutiny.</p>
  <p>From a technical standardization perspective, beyond labeling content, the emergence of user data being repurposed for model <a data-link-type="dfn|abstract-op" href="#dfn-training" id="ref-for-dfn-training-4">training</a> and some of the pushback it is generating may bring renewed momentum (from user and service provider alike) behind decentralized architectures that leave user data under less centralized control (as illustrated by the recent widening adoption of Activity Streams).</p>
<div id="b4">
  <p>A particularly relevant instance of that pattern is emerging with so-called <strong>personal data stores</strong>: these provide ways for users to exert more fine-grained control of their data, by separating more clearly the roles of data store and data processor (which, in a traditional cloud infrastructure, would otherwise typically be handled by a single entity). 
</p>

<p>
That topic has most recently surfaced in <abbr title="World Wide Web Consortium">W3C</abbr> through the <a href="https://lists.w3.org/Archives/Public/public-new-work/2023Sep/0007.html">proposed charter for a SOLID Working Group</a> late 2023 (a charter that the <abbr title="World Wide Web Consortium">W3C</abbr> community has recognized as important, but where there is not yet consensus).
</p>
</div>

<p>
Allowing to <a data-link-type="dfn|abstract-op" href="#dfn-run" id="ref-for-dfn-run-2">run</a> a model on personal data without uploading that data to a server is one of the key motivations behind the browser <a href="https://www.w3.org/TR/webnn/">Web Neural Network API</a> [<cite><a data-link-type="biblio" href="#bib-webnn" title="Web Neural Network API">WEBNN</a></cite>] which, completing the computing capabilities already provided by <a href="https://www.w3.org/groups/wg/wasm/">WebAssembly</a> [<cite><a data-link-type="biblio" href="#bib-wasm-core-2" title="WebAssembly Core Specification">WASM-CORE-2</a></cite>] and <a href="https://www.w3.org/groups/wg/gpu/">WebGPU</a> [<cite><a data-link-type="biblio" href="#bib-webgpu" title="WebGPU">WEBGPU</a></cite>], provides additional Machine Learning specific optimizations to <a data-link-type="dfn|abstract-op" href="#dfn-run" id="ref-for-dfn-run-3">run</a> models efficiently from within the browser (and thus, on the end-user device). 
</p>
</section>
<section id="safety-and-security">



<p>
A number of <a data-link-type="dfn|abstract-op" href="#dfn-model" id="ref-for-dfn-model-10">Machine Learning models</a> have significantly lowered the cost of generating credible textual, as well as audio and video (real-time or recorded) impersonations of real persons. This creates significant risks of upscaling the capabilities of phishing and other types of frauds, and thus raising much higher the barriers to establish trust in online interactions. If users no longer feel safe in their digitally-mediated interactions, the Web will no longer be able to play its role as a platform for these interactions.
</p>

</section>
<section id="sustainability">



<p>
<a data-link-type="dfn|abstract-op" href="#dfn-training" id="ref-for-dfn-training-5">Training</a> and <a data-link-type="dfn|abstract-op" href="#dfn-run" id="ref-for-dfn-run-4">running</a> <a data-link-type="dfn|abstract-op" href="#dfn-model" id="ref-for-dfn-model-11">Machine Learning models</a> can prove very resource-intensive, in particular in terms of power- and water-consumption. The imperative of reducing humanity's footprint on natural resources should apply particularly strongly to the technologies that standardization helps deploy at scale. 
</p>
<p>There is relatively new but promising work in the <a href="https://www.w3.org/community/sustyweb/">Sustainable Web Design Community Group</a> (a <a href="https://lists.w3.org/Archives/Public/public-new-work/2024Mar/0000.html">candidate to become a standardization Working Group</a>) to explain how to <a href="https://www.w3.org/blog/2023/introducing-web-sustainability-guidelines/">use Web technologies in a sustainable way</a>.</p>
<p> The <a href="https://github.com/Green-Software-Foundation/sci"> Green Software Foundation Software Carbon Intensity Working Group </a> is developing a score to calculate carbon footprint of software applications. </p>
<p><abbr title="World Wide Web Consortium">W3C</abbr> still lacks a well-defined <strong>framework to evaluate the environmental impact of its standards</strong>. Given the documented high environmental impact of <a data-link-type="dfn|abstract-op" href="#dfn-artificial-intelligence-system" id="ref-for-dfn-artificial-intelligence-system-12">AI systems</a>, it will surely become more important that <abbr title="World Wide Web Consortium">W3C</abbr> groups that are expected to accelerate the deployment of <a data-link-type="dfn|abstract-op" href="#dfn-model" id="ref-for-dfn-model-12">Machine Learning models</a> take a proactive approach in exploring and documenting how they envision the environmental impact of their work, and possible mitigations they might identify.</p>
</section>
<section id="balancing-content-creators-incentives-and-consumers-rights">




<p>
Some of the largest and most visible <a data-link-type="dfn|abstract-op" href="#dfn-model" id="ref-for-dfn-model-13">Machine Learning models</a> are known or assumed to have been trained with materials crawled from the Web, without the explicit consent of their creators or publishers.
</p>
<p>
The controversy that has emerged from that situation is being debated (and in some cases, arbitrated) through the lens of copyright law.
</p>
<p>
It is not our place to determine if and how various copyright legislation bears on that particular usage. Beyond legal considerations, the copyright system creates a (relatively) shared understanding between creators and consumers that, by default, content cannot be redistributed, remixed, adapted or built upon without creators' consent. This shared understanding made it possible for a lot of content to be openly distributed on the Web. It also allowed creators to consider a variety of monetization options (subscription, pay per view, advertising) for their content grounded on the assumption that consumers will always reach their pages.
</p>
<p>
A number of <a data-link-type="dfn|abstract-op" href="#dfn-artificial-intelligence-system" id="ref-for-dfn-artificial-intelligence-system-13">AI systems</a> combine (1) automated large-scale consumption of Web content, and (2) production at scale of content, in ways that do not recognize or otherwise compensate content it was trained from.
</p>

<p>
While some of these tensions are not new (as discussed below), systems based on Machine Learning are poised to upend the existing balance. Unless a new sustainable equilibrium is found, this exposes the Web to the following undesirable outcomes:
</p>
<ul>

<li>Significantly less open distributed content (which would likely have a disproportionate impact on the less wealthy part of the population)

</li><li>A less appealing platform to distribute content
</li>
</ul>
<p>
A less direct risk may emerge from changes in copyright laws meant to help to rebalance the situation but which would reduce the rights from content consumers and then undermine the value of the Web as a platform for which content distribution is a key value proposition.
</p>
<section id="comparison-with-search-engines">



<p>
A number of the tensions emerging around the re-use of content crawled at scale from the Web have a long history given the central role that search engines play for the Web. Indeed, search engines provide (and absorb) value from their ability to retrieve and organize information from content on the Web, and they heavily rely on the standardized infrastructure this content is built on to achieve these results.
</p>
<p>
The more or less implicit contract that emerged between search engines and content providers has been that search engines can retrieve, parse and partially display content from the providers, in exchange of bringing more visibility and traffic to them. A further assumption has been encoded in the way the Web operates that this contract is the default for anyone making content available publicly on the Web, with an opt-out mechanism encoded via the <a href="https://www.rfc-editor.org/rfc/rfc9309.html"><code>robots.txt</code> directives</a> [<cite><a data-link-type="biblio" href="#bib-rfc9309" title="Robots Exclusion Protocol">RFC9309</a></cite>].
</p>
<p>
Over time, in addition to the links to sites matching the user's query, search engines have integrated more ways to surface content directly from the target Web sites: either through rich snippets (typically made possible by the use of schema.org metadata) or through embedded preview (e.g., what the <a href="https://amp.dev/">AMP project</a> enabled). These changes were frequently accompanied by sometimes challenging discussions around the balance between bringing additional visibility to crawled content and reducing the incentive from end-users to visit the source website (e.g., because they may have already received sufficient information from the search results page).
</p>
<p>
In a certain number of cases, <a data-link-type="dfn|abstract-op" href="#dfn-artificial-intelligence-system" id="ref-for-dfn-artificial-intelligence-system-14">AI systems</a> are used as an alternative or complement to what users would traditionally have used a search engine for (and indeed, are increasingly integrated into search engine interfaces). So it seems useful to explore to what extent the lessons learned from the evolutionary process balancing the needs from search engines and from content creators can inform the discussion on crawlers used to train <a data-link-type="dfn|abstract-op" href="#dfn-model" id="ref-for-dfn-model-14">Machine Learning models</a>.
</p>
<p>
In making that comparison, it's also important to note significant differences:
</p>
<ul>

<li>The implicit contract that content creators expect from search engines crawlers –i.e., that they will bring exposure to their content– does not have a systematic equivalent for content integrated into <a data-link-type="dfn|abstract-op" href="#dfn-artificial-intelligence-system" id="ref-for-dfn-artificial-intelligence-system-15">AI systems</a>; while some such systems are gaining the ability to point back to the source of their training data used in a given <a data-link-type="dfn|abstract-op" href="#dfn-run" id="ref-for-dfn-run-5">inference</a>, this is hardly a widespread feature of these systems, nor is it obvious it could be applied systematically (e.g., would linking back to sources for a generated image even make sense?); even if it could, fewer sources would likely be exposed than in a typical search engine results page, and the incentives for the user to follow the links would likely be substantially lower.

</li><li><code>robots.txt</code> directives allow specific rules to be given to specific crawlers based on their user agent; while this has been practically manageable when dealing with (for better or for worse) few well-known search engine crawlers, expecting content creators to maintain potential allow- and block-lists of the rapidly expanding number of crawlers deployed to retrieve training data seems unlikely to achieve sustainable results.
</li>
</ul>
<p>
Given the likely different expectations around the quid-pro-quo of crawling in the context of <a data-link-type="dfn|abstract-op" href="#dfn-artificial-intelligence-system" id="ref-for-dfn-artificial-intelligence-system-16">AI systems</a>, it is not obvious that the permission-less pattern inherited from the early days of the Web (robots.txt was designed in 1994) would be a satisfactory match to ensure the long term sustainability of content publication on the Web (itself presumably in the long term interest of AI crawlers themselves).
</p>

</section>
</section>
</section>
<section id="impact-of-ai-systems-on-interoperability">



<p>
  A key part of <a href="https://www.w3.org/TR/w3c-vision/#vision-web"><abbr title="World Wide Web Consortium">W3C</abbr>'s vision for the Web</a> [<cite><a data-link-type="biblio" href="#bib-w3c-vision" title="Vision for W3C">w3c-vision</a></cite>] is to ensure the Web is developed around principles of interoperability: that is, for technologies that <abbr title="World Wide Web Consortium">W3C</abbr> codifies as Web standards, to ensure they are implemented and deployed in a way that will work the same across products, allowing for greater choice for users and fostering the long term viability of the content.</p>
<p>When the algorithm on which interoperability relies is deterministic, ensuring interoperability is a matter of describing in sufficient detail and clarity the said algorithm, and running sufficient testing on the products to verify they achieve the intended result. The move to more <a href="https://www.w3.org/TR/design-principles/#algorithms">algorithmic specifications</a> [<cite><a data-link-type="biblio" href="#bib-design-principles" title="Web Platform Design Principles">design-principles</a></cite>] and thorough automated testing (e.g., through the <a href="https://web-platform-tests.org/">Web Platform Tests project</a>) has largely been driven by the goal of providing a robust interoperable platform.
</p>
<div id="b8">
<p>
As discussed above, <a data-link-type="dfn|abstract-op" href="#dfn-model" id="ref-for-dfn-model-16">Machine Learning models</a> are already finding their way into standardized Web APIs. These creates two challenges to our interoperability goals:
</p>
<ul>

<li><a data-link-type="dfn|abstract-op" href="#dfn-model" id="ref-for-dfn-model-17">Machine Learning models</a> are mostly not built or described as a series of algorithmic steps. If a given standardized behavior is expected to be best fulfilled by <a data-link-type="dfn|abstract-op" href="#dfn-model" id="ref-for-dfn-model-18">Machine Learning models</a>, how should that behavior be specified? How can it be tested to a level that sufficiently verifies an <strong>interoperable outcome across products that would use different models</strong>? What impact would it have on the fingerprinting surface of the browsers?

</li><li>A number of important <a data-link-type="dfn|abstract-op" href="#dfn-model" id="ref-for-dfn-model-19">Machine Learning models</a> are not deterministic; if or when some of these <strong>non-deterministic models</strong> get exposed in standardized APIs, this consistency question is no longer limited to two products using two different models, since a given input would no longer produce a predetermined output. It is not clear to us at the moment how to prepare for interoperable behaviors based on non-deterministic models, which probably raises the question of whether and how such models should be acceptable as part of interoperable implementations.
</li>
</ul>
</div>
<p>
A possible consequence of these challenges is a reduction of the scope of what can be meaningfully made interoperable and standardized as a possibly growing number of features get mediated by <a data-link-type="dfn|abstract-op" href="#dfn-model" id="ref-for-dfn-model-20">Machine Learning models</a> (similar to the <a href="https://datatracker.ietf.org/doc/html/draft-tschofenig-post-standardization-02">postulated impact of growing capabilities of web applications on the need to standardize protocols</a>). In that context, discussions e.g., around AI-based codecs point towards possible significant changes in the interoperability landscape.
</p>
</section>


<section id="references">
    
    <dl><dt id="bib-c2pa-ai">[C2PA-AI]</dt><dd>
      <a href="https://c2pa.org/specifications/specifications/1.3/ai-ml/ai_ml.html"><cite>Guidance for Artificial Intelligence and Machine Learning</cite></a>.  C2PA. URL: <a href="https://c2pa.org/specifications/specifications/1.3/ai-ml/ai_ml.html">https://c2pa.org/specifications/specifications/1.3/ai-ml/ai_ml.html</a>
    </dd><dt id="bib-design-principles">[design-principles]</dt><dd>
      <a href="https://www.w3.org/TR/design-principles/"><cite>Web Platform Design Principles</cite></a>. Sangwhan Moon; Lea Verou.  W3C. 30 January 2024. W3C Working Group Note. URL: <a href="https://www.w3.org/TR/design-principles/">https://www.w3.org/TR/design-principles/</a>
    </dd><dt id="bib-digital-credentials">[DIGITAL-CREDENTIALS]</dt><dd>
      <a href="https://wicg.github.io/digital-identities/"><cite>Digital Credentials</cite></a>.  WICG. March 2024. URL: <a href="https://wicg.github.io/digital-identities/">https://wicg.github.io/digital-identities/</a>
    </dd><dt id="bib-ethical-web-principles">[ethical-web-principles]</dt><dd>
      <a href="https://www.w3.org/TR/ethical-web-principles/"><cite>Ethical Web Principles</cite></a>. Daniel Appelquist; Hadley Beeman; Amy Guy.  W3C. 19 March 2024. W3C Working Group Note. URL: <a href="https://www.w3.org/TR/ethical-web-principles/">https://www.w3.org/TR/ethical-web-principles/</a>
    </dd><dt id="bib-fedcm">[FEDCM]</dt><dd>
      <a href="https://fedidcg.github.io/FedCM/"><cite>Federated Credential Management API</cite></a>.  W3C. Draft Community Group Report. URL: <a href="https://fedidcg.github.io/FedCM/">https://fedidcg.github.io/FedCM/</a>
    </dd><dt id="bib-html">[HTML]</dt><dd>
      <a href="https://html.spec.whatwg.org/multipage/"><cite>HTML Standard</cite></a>. Anne van Kesteren; Domenic Denicola; Ian Hickson; Philip Jägenstedt; Simon Pieters.  WHATWG. Living Standard. URL: <a href="https://html.spec.whatwg.org/multipage/">https://html.spec.whatwg.org/multipage/</a>
    </dd><dt id="bib-iptc-dst">[IPTC-DST]</dt><dd>
      <a href="https://cv.iptc.org/newscodes/digitalsourcetype/"><cite>Digital Source Type vocabulary</cite></a>.  IPTC. URL: <a href="https://cv.iptc.org/newscodes/digitalsourcetype/">https://cv.iptc.org/newscodes/digitalsourcetype/</a>
    </dd><dt id="bib-iso/iec-22989">[ISO/IEC-22989]</dt><dd>
      <a href="https://www.iso.org/standard/74296.html"><cite>Artificial intelligence concepts and terminology</cite></a>.  ISO/IEC. July 2022. Published. URL: <a href="https://www.iso.org/standard/74296.html">https://www.iso.org/standard/74296.html</a>
    </dd><dt id="bib-model-cards">[MODEL-CARDS]</dt><dd>
      <a href="https://arxiv.org/pdf/1810.03993.pdf"><cite>Model Cards for Model Reporting</cite></a>. M. Mitchell; S. Wu; A. Zaldivar; P. Barnes; L. Vasserman; B. Hutchinson; E. Spitzer; I. Deborah Raji; T. Gebru. 14 Juan 2019. URL: <a href="https://arxiv.org/pdf/1810.03993.pdf">https://arxiv.org/pdf/1810.03993.pdf</a>
    </dd><dt id="bib-rfc9309">[RFC9309]</dt><dd>
      <a href="https://www.rfc-editor.org/rfc/rfc9309"><cite>Robots Exclusion Protocol</cite></a>. M. Koster; G. Illyes; H. Zeller; L. Sassman.  IETF. September 2022. Proposed Standard. URL: <a href="https://www.rfc-editor.org/rfc/rfc9309">https://www.rfc-editor.org/rfc/rfc9309</a>
    </dd><dt id="bib-schema-org">[schema-org]</dt><dd>
      <a href="https://schema.org/"><cite>Schema.org</cite></a>. W3C Schema.org Community Group.  W3C. 6.0. URL: <a href="https://schema.org/">https://schema.org/</a>
    </dd><dt id="bib-shape-detection-api">[SHAPE-DETECTION-API]</dt><dd>
      <a href="https://wicg.github.io/shape-detection-api/"><cite>Accelerated Shape Detection in Images</cite></a>.  WICG. cg-draft. URL: <a href="https://wicg.github.io/shape-detection-api/">https://wicg.github.io/shape-detection-api/</a>
    </dd><dt id="bib-speech-api">[SPEECH-API]</dt><dd>
      <a href="https://wicg.github.io/speech-api/"><cite>Web Speech API</cite></a>.  WICG. cg-draft. URL: <a href="https://wicg.github.io/speech-api/">https://wicg.github.io/speech-api/</a>
    </dd><dt id="bib-tdmrep">[TDMRep]</dt><dd>
      <a href="https://www.w3.org/community/reports/tdmrep/CG-FINAL-tdmrep-20240202/"><cite>Final Community Group Report</cite></a>.  Text and Data Mining Reservation Protocol Community Group. February 2024. URL: <a href="https://www.w3.org/community/reports/tdmrep/CG-FINAL-tdmrep-20240202/">https://www.w3.org/community/reports/tdmrep/CG-FINAL-tdmrep-20240202/</a>
    </dd><dt id="bib-trust.txt">[TRUST.TXT]</dt><dd>
      <a href="https://journallist.net/reference-document-for-trust-txt-specifications"><cite>Specification for trust.txt file and underlying system</cite></a>.  JournalList.net. May 2020. URL: <a href="https://journallist.net/reference-document-for-trust-txt-specifications">https://journallist.net/reference-document-for-trust-txt-specifications</a>
    </dd><dt id="bib-unesco-ai">[UNESCO-AI]</dt><dd>
      <a href="https://unesdoc.unesco.org/ark:/48223/pf0000380455"><cite>Recommendation on the Ethics of Artificial Intelligence</cite></a>.  UNESCO. 2021. URL: <a href="https://unesdoc.unesco.org/ark:/48223/pf0000380455">https://unesdoc.unesco.org/ark:/48223/pf0000380455</a>
    </dd><dt id="bib-vc-data-model">[VC-DATA-MODEL]</dt><dd>
      <a href="https://www.w3.org/TR/vc-data-model/"><cite>Verifiable Credentials Data Model v1.1</cite></a>. Manu Sporny; Grant Noble; Dave Longley; Daniel Burnett; Brent Zundel; Kyle Den Hartog.  W3C. 3 March 2022. W3C Recommendation. URL: <a href="https://www.w3.org/TR/vc-data-model/">https://www.w3.org/TR/vc-data-model/</a>
    </dd><dt id="bib-w3c-ml-ws">[W3C-ML-WS]</dt><dd>
      <a href="https://www.w3.org/2020/06/machine-learning-workshop/report.html"><cite>W3C Workshop Report on Web and Machine Learning</cite></a>.  W3C. October 2020. URL: <a href="https://www.w3.org/2020/06/machine-learning-workshop/report.html">https://www.w3.org/2020/06/machine-learning-workshop/report.html</a>
    </dd><dt id="bib-w3c-vision">[w3c-vision]</dt><dd>
      <a href="https://www.w3.org/TR/w3c-vision/"><cite>Vision for W3C</cite></a>. Chris Wilson.  W3C. 26 October 2023. W3C Working Group Note. URL: <a href="https://www.w3.org/TR/w3c-vision/">https://www.w3.org/TR/w3c-vision/</a>
    </dd><dt id="bib-wai-ai">[WAI-AI]</dt><dd>
      <a href="https://www.w3.org/WAI/research/ai2023/"><cite>Artificial Intelligence (AI) and Accessibility Research Symposium 2023</cite></a>.  W3C Web Accessibility Initiative. Jan 2023. URL: <a href="https://www.w3.org/WAI/research/ai2023/">https://www.w3.org/WAI/research/ai2023/</a>
    </dd><dt id="bib-wasm-core-2">[WASM-CORE-2]</dt><dd>
      <a href="https://www.w3.org/TR/wasm-core-2/"><cite>WebAssembly Core Specification</cite></a>. Andreas Rossberg.  W3C. 5 March 2024. W3C Working Draft. URL: <a href="https://www.w3.org/TR/wasm-core-2/">https://www.w3.org/TR/wasm-core-2/</a>
    </dd><dt id="bib-webgpu">[WEBGPU]</dt><dd>
      <a href="https://www.w3.org/TR/webgpu/"><cite>WebGPU</cite></a>. Kai Ninomiya; Brandon Jones; Jim Blandy.  W3C. 23 March 2024. W3C Working Draft. URL: <a href="https://www.w3.org/TR/webgpu/">https://www.w3.org/TR/webgpu/</a>
    </dd><dt id="bib-webmachinelearning-ethics">[webmachinelearning-ethics]</dt><dd>
      <a href="https://www.w3.org/TR/webmachinelearning-ethics/"><cite>Ethical Principles for Web Machine Learning</cite></a>. Anssi Kostiainen.  W3C. 8 January 2024. W3C Working Group Note. URL: <a href="https://www.w3.org/TR/webmachinelearning-ethics/">https://www.w3.org/TR/webmachinelearning-ethics/</a>
    </dd><dt id="bib-webnn">[WEBNN]</dt><dd>
      <a href="https://www.w3.org/TR/webnn/"><cite>Web Neural Network API</cite></a>. Ningxin Hu; Dwayne Robinson.  W3C. 25 March 2024. W3C Candidate Recommendation. URL: <a href="https://www.w3.org/TR/webnn/">https://www.w3.org/TR/webnn/</a>
    </dd></dl>
  </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Rule-based NLP system beats LLM for analysis of psychiatric clinical notes (115 pts)]]></title>
            <link>https://arxiv.org/abs/2403.17199</link>
            <guid>39934322</guid>
            <pubDate>Thu, 04 Apr 2024 18:47:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2403.17199">https://arxiv.org/abs/2403.17199</a>, See on <a href="https://news.ycombinator.com/item?id=39934322">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
    <div><p><span>Authors:</span><a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Patra,+B+G">Braja Gopal Patra</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lepow,+L+A">Lauren A. Lepow</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kumar,+P+K+R+J">Praneet Kasi Reddy Jagadeesh Kumar</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vekaria,+V">Veer Vekaria</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sharma,+M+M">Mohit Manoj Sharma</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Adekkanattu,+P">Prakash Adekkanattu</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fennessy,+B">Brian Fennessy</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hynes,+G">Gavin Hynes</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Landi,+I">Isotta Landi</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sanchez-Ruiz,+J+A">Jorge A. Sanchez-Ruiz</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ryu,+E">Euijung Ryu</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Biernacka,+J+M">Joanna M. Biernacka</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nadkarni,+G+N">Girish N. Nadkarni</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Talati,+A">Ardesheer Talati</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Weissman,+M">Myrna Weissman</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Olfson,+M">Mark Olfson</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mann,+J+J">J. John Mann</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Charney,+A+W">Alexander W. Charney</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pathak,+J">Jyotishman Pathak</a></p></div>            
    <p><a href="https://arxiv.org/pdf/2403.17199">View PDF</a>
    <a href="https://arxiv.org/html/2403.17199v1">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>Background: Social support (SS) and social isolation (SI) are social determinants of health (SDOH) associated with psychiatric outcomes. In electronic health records (EHRs), individual-level SS/SI is typically documented as narrative clinical notes rather than structured coded data. Natural language processing (NLP) algorithms can automate the otherwise labor-intensive process of data extraction.
<br>Data and Methods: Psychiatric encounter notes from Mount Sinai Health System (MSHS, n=300) and Weill Cornell Medicine (WCM, n=225) were annotated and established a gold standard corpus. A rule-based system (RBS) involving lexicons and a large language model (LLM) using FLAN-T5-XL were developed to identify mentions of SS and SI and their subcategories (e.g., social network, instrumental support, and loneliness).
<br>Results: For extracting SS/SI, the RBS obtained higher macro-averaged f-scores than the LLM at both MSHS (0.89 vs. 0.65) and WCM (0.85 vs. 0.82). For extracting subcategories, the RBS also outperformed the LLM at both MSHS (0.90 vs. 0.62) and WCM (0.82 vs. 0.81).
<br>Discussion and Conclusion: Unexpectedly, the RBS outperformed the LLMs across all metrics. Intensive review demonstrates that this finding is due to the divergent approach taken by the RBS and LLM. The RBS were designed and refined to follow the same specific rules as the gold standard annotations. Conversely, the LLM were more inclusive with categorization and conformed to common English-language understanding. Both approaches offer advantages and are made available open-source for future testing.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Braja Gopal Patra [<a href="https://arxiv.org/show-email/58487443/2403.17199">view email</a>]      <br>    <strong>[v1]</strong>
        Mon, 25 Mar 2024 21:19:50 UTC (402 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The design philosophy of Great Tables (436 pts)]]></title>
            <link>https://posit-dev.github.io/great-tables/blog/design-philosophy/</link>
            <guid>39933833</guid>
            <pubDate>Thu, 04 Apr 2024 18:00:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://posit-dev.github.io/great-tables/blog/design-philosophy/">https://posit-dev.github.io/great-tables/blog/design-philosophy/</a>, See on <a href="https://news.ycombinator.com/item?id=39933833">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="quarto-content">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main id="quarto-document-content">




<p>We’ve spent a lot of time thinking about tables. Tables—like plots—are crucial as a last step toward presenting information. There is surprising sophistication and nuance in designing effective tables. Over the past 5,000 years, they’ve evolved from simple grids to highly structured displays of data. Although we argue that the mid-1900s served as a high point, the popularization and wider accessibility of computing seemingly brought us back to the simple, ancient times.</p>
<p>Okay, it’s not all <em>that bad</em> but the workers of data are today confronted with an all-too-familiar dilemma: copy your data into a tool like Excel to make the table, or, display an otherwise unpolished table. Through the exploration of the qualities that make tables shine, the backstory of tables as a display of data, and the issues faced today, it’s clear how we can solve the <strong>great table dilemma</strong> with <a href="https://github.com/posit-dev/great-tables"><strong>Great Tables</strong></a>.</p>
<p><img src="https://posit-dev.github.io/great-tables/blog/design-philosophy/computer_tables.png"></p>
<p>
Tables made with computers (left to right): (1) a DataFrame printed at the console, (2) an Excel table, and (3) a <strong>Great Tables</strong> table.
</p>
<section id="what-is-a-table-really">
<h3 data-anchor-id="what-is-a-table-really">What is a table, really?</h3>
<p>Before getting to what makes tables <em>shine</em> we should first define what a table is. This is surprisingly hard! But I believe it can be boiled down to two basic rules:</p>
<ul>
<li>the data is represented as columns and rows</li>
<li>the data is primarily text</li>
</ul>
<p>Let’s look at an example of a simple table with actual data to tie this theory to practice.</p>
<div id="1ae40fd7" data-execution_count="1">

<table data-quarto-disable-processing="false" data-quarto-bootstrap="false">

<tbody><tr>
  <th rowspan="1" colspan="1" scope="col" id="Name">Name</th>
  <th rowspan="1" colspan="1" scope="col" id="Address">Address</th>
  <th rowspan="1" colspan="1" scope="col" id="City">City</th>
  <th rowspan="1" colspan="1" scope="col" id="Postcode">Postcode</th>
  <th rowspan="1" colspan="1" scope="col" id="DOB">DOB</th>
  <th rowspan="1" colspan="1" scope="col" id="Height">Height</th>
  <th rowspan="1" colspan="1" scope="col" id="Weight">Weight</th>
</tr>
</tbody><tbody>
<tr>
  <td>Dustin B. Roach</td>
  <td>1183 Columbia Road</td>
  <td>Holly Oak, DE</td>
  <td>19809</td>
  <td>1970-09-16</td>
  <td>5' 9"</td>
  <td>202.5</td>
</tr>
<tr>
  <td>Iwona Adamczyk</td>
  <td>ul. Zabłudowska 133</td>
  <td>Warszawa</td>
  <td>04-788</td>
  <td>1976-01-03</td>
  <td>5' 5"</td>
  <td>123.7</td>
</tr>
<tr>
  <td>Geneviève Massé</td>
  <td>1415 rue Principale</td>
  <td>Amos, QC</td>
  <td>J9T 1E4</td>
  <td>1967-12-08</td>
  <td>5' 3"</td>
  <td>136.3</td>
</tr>
<tr>
  <td>João Souza Lima</td>
  <td>Rua Cosmorama, 538</td>
  <td>São Paulo-SP</td>
  <td>04648-080</td>
  <td>2001-04-21</td>
  <td>6' 2"</td>
  <td>231.0</td>
</tr>
<tr>
  <td>Maddison McCabe</td>
  <td>149 Raymond Street</td>
  <td>Strathern</td>
  <td>Invercargill 9812</td>
  <td>1982-03-05</td>
  <td>5' 8"</td>
  <td>146.1</td>
</tr>
</tbody>


</table>

</div>
<p>
A table of named individuals along with a select set of characteristics.
</p>
<p>This table arranges records containing personal characteristics as columns and rows. Each person is a row, and each characteristic makes up a different column. The characteristics use different types of data, like dates, numbers, and text. This arrangement makes it easy to look up individual values or make comparisons across the different rows or columns.</p>
<p>Note that there are horizontal lines separating the rows. This aesthetic touch, while not strictly required for a table, serves as a visual reinforcement for separating the individual rows.</p>
<p>The order of the columns matters, and that we start with the <code>Name</code> column here is no accident. If that column were the last (i.e., furthest to the right), it would be slightly more confusing for the reader since the subject for the record isn’t immediate. In addition to order, column labels play an important role for indicating what data is in each column. They’re not always necessary but in most cases they remove the guesswork for what type of data is contained within each column.</p>
<p>We’ll go into some detail later about how <a href="https://github.com/posit-dev/great-tables"><strong>Great Tables</strong></a> provides affordances for structuring information for better legibility and how the package can be used to adorn the table with other structural elements. For now, our conception of a table can be summarized in this schematic.</p>
<p><img src="https://posit-dev.github.io/great-tables/blog/design-philosophy/a_simple_table.png"></p>
<p>
A simple table has: (1) cells containing data, (2) an arrangement of columns and rows, and (3) column labels to describe the type data in each column.
</p>
<p>Now, let’s go back: way back. In examining where tables came from, we might better understand the great story of tables.</p>
</section>
<section id="the-early-history-of-tables">
<h3 data-anchor-id="the-early-history-of-tables">The early history of tables</h3>
<p>Tables emerged from square grids. When grids are made like this, you invariably generate containers that may hold some sort of information. The earliest known examples of grids go very far back in human history. Twenty-five thousand year old representations of the grid are found on the walls of the Lascaux and Niaux caves in France<a href="#fn1" id="fnref1" role="doc-noteref"><sup>1</sup></a>.</p>
<p><img src="https://posit-dev.github.io/great-tables/blog/design-philosophy/cave_grids.png"></p>
<p>
Reproductions of early grids found on cave walls.
</p>
<p>In the second century BC, the Greek astronomer Hipparchus used latitude and longitude to locate celestial and terrestrial positions<a href="#fn2" id="fnref2" role="doc-noteref"><sup>2</sup></a>. At around AD 150, Ptolmey published <em>Geographia</em>, which contains 25 geographical maps accompanied by methodologies for their construction using grids<a href="#fn3" id="fnref3" role="doc-noteref"><sup>3</sup></a>. The Romans employed a grid system called <em>centuriation</em>, which can be described as land measurement (using surveyors’ instruments) to realize the formation of square grids using roads, canals, or agricultural plots<a href="#fn4" id="fnref4" role="doc-noteref"><sup>4</sup></a>.</p>
<p>When agriculture became more widespread (ca. 10,000 years ago), there was the need to document and manage economic transactions to do with farming, livestock, and the division of labor. In the fourth millennium BC, Mesopotamian cities that traded with far way kingdoms needed to keep such records. Clay tablets recovered from the ancient Sumerian city of Uruk show early yet sophisticated tables. Here is a drawing of one of the recovered tablets, which contains an accounting of deliveries of barley and malt from two individuals for the production of beer<a href="#fn5" id="fnref5" role="doc-noteref"><sup>5</sup></a>.</p>
<p><img src="https://posit-dev.github.io/great-tables/blog/design-philosophy/uruk_tablet_with_annotations.png"></p>
<p>
Drawing of clay tablet from Sumerian city of Uruk, circa 3200-3000 BC. Uruk III Tablet (MSVO 3, 51, Louvre Museum, Paris, France). Annotated with the meanings of the columns, rows, and cells.
</p>
<p>Note that the recovered tablet is meant to be read from right to left. Inside each box is an ideogram (a symbol that represented a word or idea) and a numerical value representing a quantity.</p>
<p>Its structure is where things get super interesting:</p>
<ul>
<li>Rows: there are roughly two rows, each corresponding to an individual.</li>
<li>Columns: the first two columns from the right contain counts of malt (rightmost column) and barley (second rightmost column).</li>
<li>Subtotals: the third column from the right sums barley and malt within each individual, and the left-most column displays the grand total.</li>
</ul>
<p>As a bonus, the table has a footer, since the bottom row contains the name of the official in charge.</p>
<p>Zooming ahead about a thousand years, you start to see more systematically structured tables. Here’s a photo of a cuneiform tablet that was originally from Mesopotamia (from the Temple of Enlil at Nippur, ca. 1850 BC)<a href="#fn6" id="fnref6" role="doc-noteref"><sup>6</sup></a>, containing sources of revenue and monthly disbursements for 50 temple personnel.</p>
<p><img src="https://posit-dev.github.io/great-tables/blog/design-philosophy/nippur_cuneiform_tablet.png"></p>
<p>
Cuneiform tablet, temple of Enlil at Nippur, (CBS 3323, University of Pennsylvania).
</p>
<p>You can see right away that there is a more regular grid and, if you probe deeper, there are more similarities than differerences with the tables of today. While difficult to pick them out, the following table elements are present<a href="#fn7" id="fnref7" role="doc-noteref"><sup>7</sup></a>:</p>
<ul>
<li>column headings (month names) and row titles (names/professions of individuals).</li>
<li>cells with no information (look at the blank or smooth cells along rows)</li>
<li>numerical values in the cells</li>
<li>subtotals for each individual every six months</li>
<li>grand totals</li>
<li>annotations with explanatory notes</li>
</ul>
<p>Later on, tables were less inscribed on clay and more on wax tablets, papyrus, and paper. The media have changed, writing technologies have changed, and the design and presentation of tables also went through changes.</p>
</section>
<section id="midcentury-modern-tables">
<h3 data-anchor-id="midcentury-modern-tables">Midcentury modern tables</h3>
<p>Perhaps the best period for tables was around the middle of the 20th century. Technologies for table (and surrounding document) preparation included the offset printer, the typewriter, and varitype<a href="#fn8" id="fnref8" role="doc-noteref"><sup>8</sup></a> (my favorite). The technologies were sufficiently advanced as to allow the precise typesetting of table elements. While of course constrained by the limited space available on pages, tabular design at this point had many workable solutions for fitting tables into single pages or dispersing the tabular content across multiple pages. The combination of advanced printing technology with advanced knowledge of tabular design resulted in <em>beautiful tables</em>.</p>
<p>There’s no greater embodiment of that pairing of technology and design than the <a href="https://www2.census.gov/library/publications/1949/general/tabular-presentation.pdf"><em>Manual of Tabular Presentation</em></a><a href="#fn9" id="fnref9" role="doc-noteref"><sup>9</sup></a>, written and published by the United States Bureau of the Census. It is truly a remarkable work which goes into great detail on how the department imagines the ideal designs of information-rich tables. The work articulates the different parts of a table (and each part is given a descriptive name), sparing no detail when describing those different table parts in rigorous detail. Throughout its hundreds of pages, the authors make strong recommendations on what to do (and what <em>not</em> to do) for many tabulation scenarios. When poring over the tables visually depicted in the book, you can’t help but see that tables can both look really good <em>and</em> contain a density of information. The promise and the result is a balance of form and function.</p>
<p>We at <a href="https://github.com/posit-dev/great-tables"><strong>Great Tables</strong></a> borrow liberally from this work because many of its tabular design principles are just as good now as they were back then (and we’ll talk about what we took from that work in the next section). We’ll end this brief section with a visual montage of snippets from the <em>Census Manual</em>, which provides a glimpse of the sound advice on offer.</p>
<p><img src="https://posit-dev.github.io/great-tables/blog/design-philosophy/snippets_from_manual_tablular_presentation.png"></p>
<p>
Little nuggets of wisdom from the <em>Census Manual</em>. This may very well be the ultimate book on tabular design.
</p>
</section>
<section id="the-late-history-of-tables">
<h3 data-anchor-id="the-late-history-of-tables">The late history of tables</h3>
<p>With computing technologies becoming more accessible by the 1970s and 1980s, people were able to generate tables in both electronic and print form. The democratization of computational tables arguably began with VisiCalc in 1979, a massive success that initiated the computing category of spreadsheeting software. There’s an undeniable advantage to having data analyzed and transformed in computing environments, but, this comes at a cost. This is what it looked like:</p>
<p><img src="https://posit-dev.github.io/great-tables/blog/design-philosophy/visicalc.png"></p>
<p>
This is a table in VisiCalc (earliest example of a table in a spreadsheet application). It’s pretty crude compared to the tables in print but the advantage here is that you can calculate values quickly.
</p>
<p>The grid cells couldn’t be styled with borders for presentation purposes, the values couldn’t be formatted, and the tables couldn’t even be printed. I mean, <a href="https://www.pcjs.org/software/pcx86/app/other/visicalc/1981/">try it out</a> and you’ll see that this is quite limited in more than a few ways.</p>
<p>Over time, and this took about 10-15 years, tables-within-spreadsheets got a little easier on the eyes. By the early 1990s, Excel could paint borders on your tables, better typographical support was available, and the formatting of values was fully-featured (though, <a href="https://www.cnet.com/tech/computing/prevent-excel-from-reformatting-two-numbers-to-a-date-and-month/">wonky</a>). Great! Problem solved, right? Not really.</p>
<p>While Excel tables from the last three decades looked much better than 1980s-spreadsheet-borne tables, they could never hold a candle to the what was shown in the <em>Census Manual</em> (no matter how much of an Excel expert you became). Further to this, data analysis started to became a thing accomplished outside of Excel. One example of that is Python and its use inside Jupyter notebooks. We now have a bag of problematic scenarios</p>
<ul>
<li>all Python: analyze data and generate tables all in Python (bad tables)</li>
<li>all Excel: analyze data and make tables in Excel (less flexible analysis)</li>
<li>split-brained: analyze data in Python, copy over to Excel to make tables (not reproducible)</li>
</ul>
<p>All of these are suboptimal solutions. We propose that it is far better to do everything in Python: the data ingestion, the data analysis, and the data visualization. The visualization step is what’s done for plots and other types of graphics composed from data, it shouldn’t be any different when it comes to generating summary tables.</p>
</section>
<section id="approach-to-tables-taken-by-great-tables">
<h3 data-anchor-id="approach-to-tables-taken-by-great-tables">Approach to tables taken by <strong>Great Tables</strong></h3>
<p><a href="https://github.com/posit-dev/great-tables"><strong>Great Tables</strong></a> restores the elegance of midcentury tables with the power of a coding interface. With <a href="https://github.com/posit-dev/great-tables"><strong>Great Tables</strong></a> anyone can make beautiful tables in Python. Our framework expresses a table as a combination of six independent components. With this framework, you can structure the table, format the values, and style the table. We firmly believe that the methods offered in the package enable people to construct a wide variety of useful tables that work across many disciplines.</p>
<p>You build with <a href="https://github.com/posit-dev/great-tables"><strong>Great Tables</strong></a> iteratively, starting off with your table body from code, adding styling, formatting and other components.&nbsp;Here is a schematic that outlines our terminology and depicts how the different table components are related to each other:</p>
<p><img src="https://posit-dev.github.io/great-tables/blog/design-philosophy/composition_of_a_table_in_GT.png"></p>
<p>
A schematic with the complete set of table components that can be utilized in <strong>Great Tables</strong>.
</p>
<p>Note the following six component pieces:</p>
<ul>
<li><strong>Table Header</strong>: a place for a title and subtitle, where you can succinctly describe the table content</li>
<li><strong>Column Labels</strong>: the column labels define the content of each column, and spanners are headings over groups of columns</li>
<li><strong>Stub Head</strong>: the ‘top-left’ location, where a label could be used in a variety of ways</li>
<li><strong>Row Stub</strong>: for row information, including row grouping labels</li>
<li><strong>Table Body</strong>: contains cells and so it’s where the data lives</li>
<li><strong>Table Footer</strong>: a place for additional information pertaining to the table content</li>
</ul>
<p>Here’s a table that takes advantage of the different components available in <a href="https://github.com/posit-dev/great-tables"><strong>Great Tables</strong></a>. It contains the names and addresses of people.</p>
<div id="ac03b112" data-execution_count="2">
<details>
<summary>Show the code</summary>
<div id="cb1"><pre><code><span id="cb1-1"><span>from</span> great_tables <span>import</span> GT, md, system_fonts</span>
<span id="cb1-2"></span>
<span id="cb1-3">(</span>
<span id="cb1-4">    GT(simple_table, rowname_col<span>=</span><span>"Name"</span>)</span>
<span id="cb1-5">    .tab_header(title<span>=</span><span>"Names, Addresses, and Characteristics of Remote Correspondents"</span>)</span>
<span id="cb1-6">    .tab_stubhead(label<span>=</span>md(<span>"*Name*"</span>))</span>
<span id="cb1-7">    .tab_spanner(label<span>=</span><span>"Location"</span>, columns<span>=</span>[<span>"Address"</span>, <span>"City"</span>, <span>"Postcode"</span>])</span>
<span id="cb1-8">    .tab_spanner(label<span>=</span><span>"Personal Characteristics"</span>, columns<span>=</span>[<span>"DOB"</span>, <span>"Height"</span>, <span>"Weight"</span>])</span>
<span id="cb1-9">    .tab_source_note(source_note<span>=</span>md(<span>"**Data last updated**: December 18, 2022."</span>))</span>
<span id="cb1-10">    .fmt_date(columns<span>=</span><span>"DOB"</span>, date_style<span>=</span><span>"m_day_year"</span>)</span>
<span id="cb1-11">    .fmt_integer(columns<span>=</span><span>"Weight"</span>, pattern<span>=</span><span>"</span><span>{x}</span><span> lbs"</span>)</span>
<span id="cb1-12">    .opt_stylize()</span>
<span id="cb1-13">    .opt_align_table_header(align<span>=</span><span>"left"</span>)</span>
<span id="cb1-14">    .opt_vertical_padding(scale<span>=</span><span>0.75</span>)</span>
<span id="cb1-15">    .tab_options(</span>
<span id="cb1-16">        table_font_names<span>=</span>system_fonts(name<span>=</span><span>"rounded-sans"</span>),</span>
<span id="cb1-17">        table_font_size<span>=</span><span>"14px"</span>,</span>
<span id="cb1-18">    )</span>
<span id="cb1-19">)</span></code></pre></div>
</details>
<div id="kheciylykv" data-execution_count="2">

<table data-quarto-disable-processing="false" data-quarto-bootstrap="false">
<thead>
  <tr>
    <th colspan="7">Names, Addresses, and Characteristics of Remote Correspondents</th>
  </tr>
</thead>
<tbody><tr>
  <th rowspan="2" colspan="1" scope="col" id="<em>Name</em>"><em>Name</em></th>
  <th rowspan="1" colspan="3" scope="colgroup" id="Location">
    <span>Location</span>
  </th>
  <th rowspan="1" colspan="3" scope="colgroup" id="Personal Characteristics">
    <span>Personal Characteristics</span>
  </th>
</tr>
<tr>
  <th rowspan="1" colspan="1" scope="col" id="Address">Address</th>
  <th rowspan="1" colspan="1" scope="col" id="City">City</th>
  <th rowspan="1" colspan="1" scope="col" id="Postcode">Postcode</th>
  <th rowspan="1" colspan="1" scope="col" id="DOB">DOB</th>
  <th rowspan="1" colspan="1" scope="col" id="Height">Height</th>
  <th rowspan="1" colspan="1" scope="col" id="Weight">Weight</th>
</tr>
</tbody><tbody>
<tr>
  <th>Dustin B. Roach</th>
  <td>1183 Columbia Road</td>
  <td>Holly Oak, DE</td>
  <td>19809</td>
  <td>Sep 16, 1970</td>
  <td>5' 9"</td>
  <td>202 lbs</td>
</tr>
<tr>
  <th>Iwona Adamczyk</th>
  <td>ul. Zabłudowska 133</td>
  <td>Warszawa</td>
  <td>04-788</td>
  <td>Jan 3, 1976</td>
  <td>5' 5"</td>
  <td>124 lbs</td>
</tr>
<tr>
  <th>Geneviève Massé</th>
  <td>1415 rue Principale</td>
  <td>Amos, QC</td>
  <td>J9T 1E4</td>
  <td>Dec 8, 1967</td>
  <td>5' 3"</td>
  <td>136 lbs</td>
</tr>
<tr>
  <th>João Souza Lima</th>
  <td>Rua Cosmorama, 538</td>
  <td>São Paulo-SP</td>
  <td>04648-080</td>
  <td>Apr 21, 2001</td>
  <td>6' 2"</td>
  <td>231 lbs</td>
</tr>
<tr>
  <th>Maddison McCabe</th>
  <td>149 Raymond Street</td>
  <td>Strathern</td>
  <td>Invercargill 9812</td>
  <td>Mar 5, 1982</td>
  <td>5' 8"</td>
  <td>146 lbs</td>
</tr>
</tbody>
  <tfoot>
  
  <tr>
    <td colspan="7"><strong>Data last updated</strong>: December 18, 2022.</td>
  </tr>

</tfoot>

</table>

</div>
</div>
<p>
A table of named individuals redone, <strong>Great Tables</strong> style!
</p>
<p>Notice that there is a blue row stub component that makes the row labels distinct from the body of the table. This is important because each person described forms a unique observation and we want to highlight the subject of each row. The heading provides context on what’s contained within the table. The two column spanners arrange the columns into sensible groupings (e.g., ‘Location’). The consistent use of blue lines and cell backgrounds gives the table a professional look.</p>
<p>If you look at the table code above you’ll see that every method for modifying the table starts with <code>tab_</code>. These particular methods are concerned with adding a table component (e.g., <code>tab_header()</code> creates a <strong>Table Header</strong>) and they’re designed to be easy and straightforward to use.</p>
<section id="formatting">
<h4 data-anchor-id="formatting">Formatting</h4>
<p>Table structuring is important, but not the only thing. Tables in different disciplines have a certain set of display requirements specific for any values shown. Even something as simple as a number can be formatted in many different ways depending on a community’s norms and expectations. This extends to a very wide area when we consider that dates, times, and currencies also need to be formatted.</p>
<p>Depending on your display requirements, a raw value like 134,000 could presented as:</p>
<ul>
<li>scientific notation (<code>fmt_scientific()</code>): 1.34 × 10<sup>5</sup></li>
<li>a number in the German locale (<code>fmt_number()</code>): 134.000,00</li>
<li>a compact integer value (<code>fmt_integer()</code>): 134K</li>
</ul>
<p>The problem grows worse when values need to be conveyed as images or plots. If you’re a medical analyst, for example, you might need to effectively convey whether test results for a patient are improving or worsening over time. Reading such data as a sequence of numbers across a row can slow interpretation. But by using <em>nanoplots</em>, available as the <code>fmt_nanoplot()</code> formatting method, readers can spot trends right away. Here’s an example that provides test results over a series of days.</p>
<div id="00377bad" data-execution_count="3">
<details>
<summary>Show the code</summary>
<div id="cb2"><pre><code><span id="cb2-1"><span>import</span> great_tables</span>
<span id="cb2-2"><span>from</span> great_tables <span>import</span> GT, md</span>
<span id="cb2-3"><span>from</span> great_tables.data <span>import</span> illness</span>
<span id="cb2-4"><span>import</span> polars <span>as</span> pl</span>
<span id="cb2-5"></span>
<span id="cb2-6">illness_mini <span>=</span> (</span>
<span id="cb2-7">    pl.from_pandas(illness)</span>
<span id="cb2-8">    .head(<span>10</span>)</span>
<span id="cb2-9">    .select(</span>
<span id="cb2-10">        <span>"test"</span>, values<span>=</span>pl.concat_str(pl.exclude(<span>"test"</span>, <span>"units"</span>), separator<span>=</span><span>" "</span>, ignore_nulls<span>=</span><span>True</span>)</span>
<span id="cb2-11">    )</span>
<span id="cb2-12">    .<span>slice</span>(<span>1</span>, <span>9</span>)</span>
<span id="cb2-13">)</span>
<span id="cb2-14"></span>
<span id="cb2-15">(</span>
<span id="cb2-16">    GT(illness_mini, rowname_col<span>=</span><span>"test"</span>)</span>
<span id="cb2-17">    .fmt_nanoplot(columns<span>=</span><span>"values"</span>)</span>
<span id="cb2-18">    .tab_header(md(<span>"Partial summary of daily tests&lt;br&gt;performed on YF patient"</span>))</span>
<span id="cb2-19">    .tab_stubhead(label<span>=</span>md(<span>"**Test**"</span>))</span>
<span id="cb2-20">    .cols_label(values<span>=</span>md(<span>"*Progression*"</span>))</span>
<span id="cb2-21">    .cols_align(align<span>=</span><span>"center"</span>, columns<span>=</span><span>"values"</span>)</span>
<span id="cb2-22">    .tab_source_note(source_note<span>=</span><span>"Measurements from Day 3 through to Day 8."</span>)</span>
<span id="cb2-23">)</span></code></pre></div>
</details>
<div id="gxarjpxzxd" data-execution_count="3">

<table data-quarto-disable-processing="false" data-quarto-bootstrap="false">
<thead>
  <tr>
    <th colspan="2">Partial summary of daily tests<br>performed on YF patient</th>
  </tr>
</thead>
<tbody><tr>
  <th rowspan="1" colspan="1" scope="col" id="<strong>Test</strong>"><strong>Test</strong></th>
  <th rowspan="1" colspan="1" scope="col" id="<em>Progression</em>"><em>Progression</em></th>
</tr>
</tbody><tbody>
<tr>
  <th>WBC</th>
  <td><p><svg role="img" viewBox="0 0 550 130" style="height: 2em; margin-left: auto; margin-right: auto; font-size: inherit; overflow: visible; vertical-align: middle; position:relative;"><defs><pattern id="area_pattern" width="8" height="8" patternUnits="userSpaceOnUse"><path d="M 0,8 l 8,-8 M -1,1 l 4,-4 M 6,10 l 4,-4" stroke="#FF0000" stroke-width="1.5" stroke-linecap="round" shape-rendering="geometricPrecision"></path></pattern></defs><path d="M 50.0,110.2018278750952 106.25,114.00990099009901 162.5,92.45620715917745 218.75,90.28560548362529 275.0,35.90632140137091 331.25,15.0 387.5,57.76466108149276 443.75,115.0 500.0,92.15156130997715 500.0,125 50.0,125 Z" stroke="transparent" stroke-width="2" fill="url(#area_pattern)" fill-opacity="0.7"></path><path d="M 50.0,110.2018278750952 C 75.0,110.2018278750952 81.25,114.00990099009901 106.25,114.00990099009901 C 131.25,114.00990099009901 137.5,92.45620715917745 162.5,92.45620715917745 C 187.5,92.45620715917745 193.75,90.28560548362529 218.75,90.28560548362529 C 243.75,90.28560548362529 250.0,35.90632140137091 275.0,35.90632140137091 C 300.0,35.90632140137091 306.25,15.0 331.25,15.0 C 356.25,15.0 362.5,57.76466108149276 387.5,57.76466108149276 C 412.5,57.76466108149276 418.75,115.0 443.75,115.0 C 468.75,115.0 475.0,92.15156130997715 500.0,92.15156130997715" stroke="#4682B4" stroke-width="8" fill="none"></path><circle cx="50.0" cy="110.2018278750952" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="106.25" cy="114.00990099009901" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="162.5" cy="92.45620715917745" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="218.75" cy="90.28560548362529" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="275.0" cy="35.90632140137091" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="331.25" cy="15.0" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="387.5" cy="57.76466108149276" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="443.75" cy="115.0" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="500.0" cy="92.15156130997715" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><g><rect x="0" y="0" width="65" height="130" stroke="transparent" stroke-width="0" fill="transparent"></rect><text x="0" y="19.0" fill="transparent" stroke="transparent" font-size="25">30.3</text><text x="0" y="126.0" fill="transparent" stroke="transparent" font-size="25">4.00</text></g><g><rect x="40.0" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="60.0" y="20" fill="transparent" stroke="transparent" font-size="30px">5.26</text></g><g><rect x="96.25" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="116.25" y="20" fill="transparent" stroke="transparent" font-size="30px">4.26</text></g><g><rect x="152.5" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="172.5" y="20" fill="transparent" stroke="transparent" font-size="30px">9.92</text></g><g><rect x="208.75" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="228.75" y="20" fill="transparent" stroke="transparent" font-size="30px">10.5</text></g><g><rect x="265.0" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="285.0" y="20" fill="transparent" stroke="transparent" font-size="30px">24.8</text></g><g><rect x="321.25" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="341.25" y="20" fill="transparent" stroke="transparent" font-size="30px">30.3</text></g><g><rect x="377.5" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="397.5" y="20" fill="transparent" stroke="transparent" font-size="30px">19.0</text></g><g><rect x="433.75" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="453.75" y="20" fill="transparent" stroke="transparent" font-size="30px">4.00</text></g><g><rect x="490.0" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="510.0" y="20" fill="transparent" stroke="transparent" font-size="30px">10.0</text></g></svg></p></td>
</tr>
<tr>
  <th>Neutrophils</th>
  <td><p><svg role="img" viewBox="0 0 550 130" style="height: 2em; margin-left: auto; margin-right: auto; font-size: inherit; overflow: visible; vertical-align: middle; position:relative;"><defs><pattern id="area_pattern" width="8" height="8" patternUnits="userSpaceOnUse"><path d="M 0,8 l 8,-8 M -1,1 l 4,-4 M 6,10 l 4,-4" stroke="#FF0000" stroke-width="1.5" stroke-linecap="round" shape-rendering="geometricPrecision"></path></pattern></defs><path d="M 50.0,103.59753675009932 106.25,104.19348430671434 162.5,91.47993643226063 218.75,50.59793404847041 275.0,35.22248708780295 331.25,15.0 387.5,57.034167659912605 443.75,115.0 500.0,91.16209773539929 500.0,125 50.0,125 Z" stroke="transparent" stroke-width="2" fill="url(#area_pattern)" fill-opacity="0.7"></path><path d="M 50.0,103.59753675009932 C 75.0,103.59753675009932 81.25,104.19348430671434 106.25,104.19348430671434 C 131.25,104.19348430671434 137.5,91.47993643226063 162.5,91.47993643226063 C 187.5,91.47993643226063 193.75,50.59793404847041 218.75,50.59793404847041 C 243.75,50.59793404847041 250.0,35.22248708780295 275.0,35.22248708780295 C 300.0,35.22248708780295 306.25,15.0 331.25,15.0 C 356.25,15.0 362.5,57.034167659912605 387.5,57.034167659912605 C 412.5,57.034167659912605 418.75,115.0 443.75,115.0 C 468.75,115.0 475.0,91.16209773539929 500.0,91.16209773539929" stroke="#4682B4" stroke-width="8" fill="none"></path><circle cx="50.0" cy="103.59753675009932" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="106.25" cy="104.19348430671434" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="162.5" cy="91.47993643226063" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="218.75" cy="50.59793404847041" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="275.0" cy="35.22248708780295" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="331.25" cy="15.0" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="387.5" cy="57.034167659912605" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="443.75" cy="115.0" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="500.0" cy="91.16209773539929" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><g><rect x="0" y="0" width="65" height="130" stroke="transparent" stroke-width="0" fill="transparent"></rect><text x="0" y="19.0" fill="transparent" stroke="transparent" font-size="25">27.2</text><text x="0" y="126.0" fill="transparent" stroke="transparent" font-size="25">2.00</text></g><g><rect x="40.0" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="60.0" y="20" fill="transparent" stroke="transparent" font-size="30px">4.87</text></g><g><rect x="96.25" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="116.25" y="20" fill="transparent" stroke="transparent" font-size="30px">4.72</text></g><g><rect x="152.5" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="172.5" y="20" fill="transparent" stroke="transparent" font-size="30px">7.92</text></g><g><rect x="208.75" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="228.75" y="20" fill="transparent" stroke="transparent" font-size="30px">18.2</text></g><g><rect x="265.0" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="285.0" y="20" fill="transparent" stroke="transparent" font-size="30px">22.1</text></g><g><rect x="321.25" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="341.25" y="20" fill="transparent" stroke="transparent" font-size="30px">27.2</text></g><g><rect x="377.5" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="397.5" y="20" fill="transparent" stroke="transparent" font-size="30px">16.6</text></g><g><rect x="433.75" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="453.75" y="20" fill="transparent" stroke="transparent" font-size="30px">2.00</text></g><g><rect x="490.0" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="510.0" y="20" fill="transparent" stroke="transparent" font-size="30px">8.00</text></g></svg></p></td>
</tr>
<tr>
  <th>RBC</th>
  <td><p><svg role="img" viewBox="0 0 550 130" style="height: 2em; margin-left: auto; margin-right: auto; font-size: inherit; overflow: visible; vertical-align: middle; position:relative;"><defs><pattern id="area_pattern" width="8" height="8" patternUnits="userSpaceOnUse"><path d="M 0,8 l 8,-8 M -1,1 l 4,-4 M 6,10 l 4,-4" stroke="#FF0000" stroke-width="1.5" stroke-linecap="round" shape-rendering="geometricPrecision"></path></pattern></defs><path d="M 50.0,22.878787878787897 106.25,15.0 162.5,68.03030303030303 218.75,49.84848484848486 275.0,71.36363636363637 331.25,115.0 387.5,95.60606060606061 443.75,75.0 500.0,29.54545454545456 500.0,125 50.0,125 Z" stroke="transparent" stroke-width="2" fill="url(#area_pattern)" fill-opacity="0.7"></path><path d="M 50.0,22.878787878787897 C 75.0,22.878787878787897 81.25,15.0 106.25,15.0 C 131.25,15.0 137.5,68.03030303030303 162.5,68.03030303030303 C 187.5,68.03030303030303 193.75,49.84848484848486 218.75,49.84848484848486 C 243.75,49.84848484848486 250.0,71.36363636363637 275.0,71.36363636363637 C 300.0,71.36363636363637 306.25,115.0 331.25,115.0 C 356.25,115.0 362.5,95.60606060606061 387.5,95.60606060606061 C 412.5,95.60606060606061 418.75,75.0 443.75,75.0 C 468.75,75.0 475.0,29.54545454545456 500.0,29.54545454545456" stroke="#4682B4" stroke-width="8" fill="none"></path><circle cx="50.0" cy="22.878787878787897" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="106.25" cy="15.0" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="162.5" cy="68.03030303030303" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="218.75" cy="49.84848484848486" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="275.0" cy="71.36363636363637" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="331.25" cy="115.0" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="387.5" cy="95.60606060606061" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="443.75" cy="75.0" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="500.0" cy="29.54545454545456" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><g><rect x="0" y="0" width="65" height="130" stroke="transparent" stroke-width="0" fill="transparent"></rect><text x="0" y="19.0" fill="transparent" stroke="transparent" font-size="25">5.98</text><text x="0" y="126.0" fill="transparent" stroke="transparent" font-size="25">2.68</text></g><g><rect x="40.0" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="60.0" y="20" fill="transparent" stroke="transparent" font-size="30px">5.72</text></g><g><rect x="96.25" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="116.25" y="20" fill="transparent" stroke="transparent" font-size="30px">5.98</text></g><g><rect x="152.5" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="172.5" y="20" fill="transparent" stroke="transparent" font-size="30px">4.23</text></g><g><rect x="208.75" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="228.75" y="20" fill="transparent" stroke="transparent" font-size="30px">4.83</text></g><g><rect x="265.0" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="285.0" y="20" fill="transparent" stroke="transparent" font-size="30px">4.12</text></g><g><rect x="321.25" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="341.25" y="20" fill="transparent" stroke="transparent" font-size="30px">2.68</text></g><g><rect x="377.5" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="397.5" y="20" fill="transparent" stroke="transparent" font-size="30px">3.32</text></g><g><rect x="433.75" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="453.75" y="20" fill="transparent" stroke="transparent" font-size="30px">4.00</text></g><g><rect x="490.0" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="510.0" y="20" fill="transparent" stroke="transparent" font-size="30px">5.50</text></g></svg></p></td>
</tr>
<tr>
  <th>Hb</th>
  <td><p><svg role="img" viewBox="0 0 550 130" style="height: 2em; margin-left: auto; margin-right: auto; font-size: inherit; overflow: visible; vertical-align: middle; position:relative;"><defs><pattern id="area_pattern" width="8" height="8" patternUnits="userSpaceOnUse"><path d="M 0,8 l 8,-8 M -1,1 l 4,-4 M 6,10 l 4,-4" stroke="#FF0000" stroke-width="1.5" stroke-linecap="round" shape-rendering="geometricPrecision"></path></pattern></defs><path d="M 50.0,23.235294117647065 106.25,44.41176470588235 162.5,55.0 218.75,67.94117647058823 275.0,115.0 331.25,100.88235294117648 387.5,91.47058823529412 443.75,62.05882352941176 500.0,15.0 500.0,125 50.0,125 Z" stroke="transparent" stroke-width="2" fill="url(#area_pattern)" fill-opacity="0.7"></path><path d="M 50.0,23.235294117647065 C 75.0,23.235294117647065 81.25,44.41176470588235 106.25,44.41176470588235 C 131.25,44.41176470588235 137.5,55.0 162.5,55.0 C 187.5,55.0 193.75,67.94117647058823 218.75,67.94117647058823 C 243.75,67.94117647058823 250.0,115.0 275.0,115.0 C 300.0,115.0 306.25,100.88235294117648 331.25,100.88235294117648 C 356.25,100.88235294117648 362.5,91.47058823529412 387.5,91.47058823529412 C 412.5,91.47058823529412 418.75,62.05882352941176 443.75,62.05882352941176 C 468.75,62.05882352941176 475.0,15.0 500.0,15.0" stroke="#4682B4" stroke-width="8" fill="none"></path><circle cx="50.0" cy="23.235294117647065" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="106.25" cy="44.41176470588235" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="162.5" cy="55.0" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="218.75" cy="67.94117647058823" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="275.0" cy="115.0" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="331.25" cy="100.88235294117648" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="387.5" cy="91.47058823529412" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="443.75" cy="62.05882352941176" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="500.0" cy="15.0" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><g><rect x="0" y="0" width="65" height="130" stroke="transparent" stroke-width="0" fill="transparent"></rect><text x="0" y="19.0" fill="transparent" stroke="transparent" font-size="25">160</text><text x="0" y="126.0" fill="transparent" stroke="transparent" font-size="25">75.0</text></g><g><rect x="40.0" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="60.0" y="20" fill="transparent" stroke="transparent" font-size="30px">153</text></g><g><rect x="96.25" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="116.25" y="20" fill="transparent" stroke="transparent" font-size="30px">135</text></g><g><rect x="152.5" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="172.5" y="20" fill="transparent" stroke="transparent" font-size="30px">126</text></g><g><rect x="208.75" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="228.75" y="20" fill="transparent" stroke="transparent" font-size="30px">115</text></g><g><rect x="265.0" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="285.0" y="20" fill="transparent" stroke="transparent" font-size="30px">75.0</text></g><g><rect x="321.25" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="341.25" y="20" fill="transparent" stroke="transparent" font-size="30px">87.0</text></g><g><rect x="377.5" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="397.5" y="20" fill="transparent" stroke="transparent" font-size="30px">95.0</text></g><g><rect x="433.75" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="453.75" y="20" fill="transparent" stroke="transparent" font-size="30px">120</text></g><g><rect x="490.0" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="510.0" y="20" fill="transparent" stroke="transparent" font-size="30px">160</text></g></svg></p></td>
</tr>
<tr>
  <th>PLT</th>
  <td><p><svg role="img" viewBox="0 0 550 130" style="height: 2em; margin-left: auto; margin-right: auto; font-size: inherit; overflow: visible; vertical-align: middle; position:relative;"><defs><pattern id="area_pattern" width="8" height="8" patternUnits="userSpaceOnUse"><path d="M 0,8 l 8,-8 M -1,1 l 4,-4 M 6,10 l 4,-4" stroke="#FF0000" stroke-width="1.5" stroke-linecap="round" shape-rendering="geometricPrecision"></path></pattern></defs><path d="M 50.0,99.9125364431487 106.25,110.26239067055393 162.5,114.34402332361516 218.75,114.78134110787173 275.0,97.32507288629738 331.25,111.13702623906705 387.5,115.0 443.75,87.8862973760933 500.0,15.0 500.0,125 50.0,125 Z" stroke="transparent" stroke-width="2" fill="url(#area_pattern)" fill-opacity="0.7"></path><path d="M 50.0,99.9125364431487 C 75.0,99.9125364431487 81.25,110.26239067055393 106.25,110.26239067055393 C 131.25,110.26239067055393 137.5,114.34402332361516 162.5,114.34402332361516 C 187.5,114.34402332361516 193.75,114.78134110787173 218.75,114.78134110787173 C 243.75,114.78134110787173 250.0,97.32507288629738 275.0,97.32507288629738 C 300.0,97.32507288629738 306.25,111.13702623906705 331.25,111.13702623906705 C 356.25,111.13702623906705 362.5,115.0 387.5,115.0 C 412.5,115.0 418.75,87.8862973760933 443.75,87.8862973760933 C 468.75,87.8862973760933 475.0,15.0 500.0,15.0" stroke="#4682B4" stroke-width="8" fill="none"></path><circle cx="50.0" cy="99.9125364431487" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="106.25" cy="110.26239067055393" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="162.5" cy="114.34402332361516" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="218.75" cy="114.78134110787173" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="275.0" cy="97.32507288629738" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="331.25" cy="111.13702623906705" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="387.5" cy="115.0" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="443.75" cy="87.8862973760933" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="500.0" cy="15.0" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><g><rect x="0" y="0" width="65" height="130" stroke="transparent" stroke-width="0" fill="transparent"></rect><text x="0" y="19.0" fill="transparent" stroke="transparent" font-size="25">300</text><text x="0" y="126.0" fill="transparent" stroke="transparent" font-size="25">25.6</text></g><g><rect x="40.0" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="60.0" y="20" fill="transparent" stroke="transparent" font-size="30px">67.0</text></g><g><rect x="96.25" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="116.25" y="20" fill="transparent" stroke="transparent" font-size="30px">38.6</text></g><g><rect x="152.5" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="172.5" y="20" fill="transparent" stroke="transparent" font-size="30px">27.4</text></g><g><rect x="208.75" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="228.75" y="20" fill="transparent" stroke="transparent" font-size="30px">26.2</text></g><g><rect x="265.0" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="285.0" y="20" fill="transparent" stroke="transparent" font-size="30px">74.1</text></g><g><rect x="321.25" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="341.25" y="20" fill="transparent" stroke="transparent" font-size="30px">36.2</text></g><g><rect x="377.5" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="397.5" y="20" fill="transparent" stroke="transparent" font-size="30px">25.6</text></g><g><rect x="433.75" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="453.75" y="20" fill="transparent" stroke="transparent" font-size="30px">100</text></g><g><rect x="490.0" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="510.0" y="20" fill="transparent" stroke="transparent" font-size="30px">300</text></g></svg></p></td>
</tr>
<tr>
  <th>ALT</th>
  <td><p><svg role="img" viewBox="0 0 550 130" style="height: 2em; margin-left: auto; margin-right: auto; font-size: inherit; overflow: visible; vertical-align: middle; position:relative;"><defs><pattern id="area_pattern" width="8" height="8" patternUnits="userSpaceOnUse"><path d="M 0,8 l 8,-8 M -1,1 l 4,-4 M 6,10 l 4,-4" stroke="#FF0000" stroke-width="1.5" stroke-linecap="round" shape-rendering="geometricPrecision"></path></pattern></defs><path d="M 50.0,15.0 106.25,16.582722594729457 162.5,64.96335568376736 218.75,81.83221581163261 275.0,102.41072820832684 331.25,109.8261344144706 387.5,111.07515983159209 443.75,115.0 500.0,114.68033681584282 500.0,125 50.0,125 Z" stroke="transparent" stroke-width="2" fill="url(#area_pattern)" fill-opacity="0.7"></path><path d="M 50.0,15.0 C 75.0,15.0 81.25,16.582722594729457 106.25,16.582722594729457 C 131.25,16.582722594729457 137.5,64.96335568376736 162.5,64.96335568376736 C 187.5,64.96335568376736 193.75,81.83221581163261 218.75,81.83221581163261 C 243.75,81.83221581163261 250.0,102.41072820832684 275.0,102.41072820832684 C 300.0,102.41072820832684 306.25,109.8261344144706 331.25,109.8261344144706 C 356.25,109.8261344144706 362.5,111.07515983159209 387.5,111.07515983159209 C 412.5,111.07515983159209 418.75,115.0 443.75,115.0 C 468.75,115.0 475.0,114.68033681584282 500.0,114.68033681584282" stroke="#4682B4" stroke-width="8" fill="none"></path><circle cx="50.0" cy="15.0" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="106.25" cy="16.582722594729457" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="162.5" cy="64.96335568376736" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="218.75" cy="81.83221581163261" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="275.0" cy="102.41072820832684" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="331.25" cy="109.8261344144706" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="387.5" cy="111.07515983159209" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="443.75" cy="115.0" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="500.0" cy="114.68033681584282" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><g><rect x="0" y="0" width="65" height="130" stroke="transparent" stroke-width="0" fill="transparent"></rect><text x="0" y="19.0" fill="transparent" stroke="transparent" font-size="25">12.8K</text><text x="0" y="126.0" fill="transparent" stroke="transparent" font-size="25">9.00</text></g><g><rect x="40.0" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="60.0" y="20" fill="transparent" stroke="transparent" font-size="30px">12.8K</text></g><g><rect x="96.25" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="116.25" y="20" fill="transparent" stroke="transparent" font-size="30px">12.6K</text></g><g><rect x="152.5" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="172.5" y="20" fill="transparent" stroke="transparent" font-size="30px">6.43K</text></g><g><rect x="208.75" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="228.75" y="20" fill="transparent" stroke="transparent" font-size="30px">4.26K</text></g><g><rect x="265.0" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="285.0" y="20" fill="transparent" stroke="transparent" font-size="30px">1.62K</text></g><g><rect x="321.25" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="341.25" y="20" fill="transparent" stroke="transparent" font-size="30px">673</text></g><g><rect x="377.5" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="397.5" y="20" fill="transparent" stroke="transparent" font-size="30px">512</text></g><g><rect x="433.75" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="453.75" y="20" fill="transparent" stroke="transparent" font-size="30px">9.00</text></g><g><rect x="490.0" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="510.0" y="20" fill="transparent" stroke="transparent" font-size="30px">50.0</text></g></svg></p></td>
</tr>
<tr>
  <th>AST</th>
  <td><p><svg role="img" viewBox="0 0 550 130" style="height: 2em; margin-left: auto; margin-right: auto; font-size: inherit; overflow: visible; vertical-align: middle; position:relative;"><defs><pattern id="area_pattern" width="8" height="8" patternUnits="userSpaceOnUse"><path d="M 0,8 l 8,-8 M -1,1 l 4,-4 M 6,10 l 4,-4" stroke="#FF0000" stroke-width="1.5" stroke-linecap="round" shape-rendering="geometricPrecision"></path></pattern></defs><path d="M 50.0,15.0 106.25,24.739189246311874 162.5,52.798537430781586 218.75,78.32586549435685 275.0,105.81033098025955 331.25,110.22340110749461 387.5,111.75571712389568 443.75,115.0 500.0,114.89432303335165 500.0,125 50.0,125 Z" stroke="transparent" stroke-width="2" fill="url(#area_pattern)" fill-opacity="0.7"></path><path d="M 50.0,15.0 C 75.0,15.0 81.25,24.739189246311874 106.25,24.739189246311874 C 131.25,24.739189246311874 137.5,52.798537430781586 162.5,52.798537430781586 C 187.5,52.798537430781586 193.75,78.32586549435685 218.75,78.32586549435685 C 243.75,78.32586549435685 250.0,105.81033098025955 275.0,105.81033098025955 C 300.0,105.81033098025955 306.25,110.22340110749461 331.25,110.22340110749461 C 356.25,110.22340110749461 362.5,111.75571712389568 387.5,111.75571712389568 C 412.5,111.75571712389568 418.75,115.0 443.75,115.0 C 468.75,115.0 475.0,114.89432303335165 500.0,114.89432303335165" stroke="#4682B4" stroke-width="8" fill="none"></path><circle cx="50.0" cy="15.0" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="106.25" cy="24.739189246311874" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="162.5" cy="52.798537430781586" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="218.75" cy="78.32586549435685" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="275.0" cy="105.81033098025955" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="331.25" cy="110.22340110749461" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="387.5" cy="111.75571712389568" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="443.75" cy="115.0" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="500.0" cy="114.89432303335165" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><g><rect x="0" y="0" width="65" height="130" stroke="transparent" stroke-width="0" fill="transparent"></rect><text x="0" y="19.0" fill="transparent" stroke="transparent" font-size="25">23.7K</text><text x="0" y="126.0" fill="transparent" stroke="transparent" font-size="25">15.0</text></g><g><rect x="40.0" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="60.0" y="20" fill="transparent" stroke="transparent" font-size="30px">23.7K</text></g><g><rect x="96.25" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="116.25" y="20" fill="transparent" stroke="transparent" font-size="30px">21.4K</text></g><g><rect x="152.5" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="172.5" y="20" fill="transparent" stroke="transparent" font-size="30px">14.7K</text></g><g><rect x="208.75" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="228.75" y="20" fill="transparent" stroke="transparent" font-size="30px">8.69K</text></g><g><rect x="265.0" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="285.0" y="20" fill="transparent" stroke="transparent" font-size="30px">2.19K</text></g><g><rect x="321.25" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="341.25" y="20" fill="transparent" stroke="transparent" font-size="30px">1.14K</text></g><g><rect x="377.5" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="397.5" y="20" fill="transparent" stroke="transparent" font-size="30px">782</text></g><g><rect x="433.75" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="453.75" y="20" fill="transparent" stroke="transparent" font-size="30px">15.0</text></g><g><rect x="490.0" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="510.0" y="20" fill="transparent" stroke="transparent" font-size="30px">40.0</text></g></svg></p></td>
</tr>
<tr>
  <th>TBIL</th>
  <td><p><svg role="img" viewBox="0 0 550 130" style="height: 2em; margin-left: auto; margin-right: auto; font-size: inherit; overflow: visible; vertical-align: middle; position:relative;"><defs><pattern id="area_pattern" width="8" height="8" patternUnits="userSpaceOnUse"><path d="M 0,8 l 8,-8 M -1,1 l 4,-4 M 6,10 l 4,-4" stroke="#FF0000" stroke-width="1.5" stroke-linecap="round" shape-rendering="geometricPrecision"></path></pattern></defs><path d="M 50.0,43.18627450980391 106.25,26.887254901960773 162.5,30.931372549019606 218.75,18.125 275.0,36.997549019607845 331.25,50.600490196078425 387.5,15.0 443.75,115.0 500.0,103.48039215686273 500.0,125 50.0,125 Z" stroke="transparent" stroke-width="2" fill="url(#area_pattern)" fill-opacity="0.7"></path><path d="M 50.0,43.18627450980391 C 75.0,43.18627450980391 81.25,26.887254901960773 106.25,26.887254901960773 C 131.25,26.887254901960773 137.5,30.931372549019606 162.5,30.931372549019606 C 187.5,30.931372549019606 193.75,18.125 218.75,18.125 C 243.75,18.125 250.0,36.997549019607845 275.0,36.997549019607845 C 300.0,36.997549019607845 306.25,50.600490196078425 331.25,50.600490196078425 C 356.25,50.600490196078425 362.5,15.0 387.5,15.0 C 412.5,15.0 418.75,115.0 443.75,115.0 C 468.75,115.0 475.0,103.48039215686273 500.0,103.48039215686273" stroke="#4682B4" stroke-width="8" fill="none"></path><circle cx="50.0" cy="43.18627450980391" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="106.25" cy="26.887254901960773" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="162.5" cy="30.931372549019606" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="218.75" cy="18.125" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="275.0" cy="36.997549019607845" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="331.25" cy="50.600490196078425" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="387.5" cy="15.0" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="443.75" cy="115.0" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="500.0" cy="103.48039215686273" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><g><rect x="0" y="0" width="65" height="130" stroke="transparent" stroke-width="0" fill="transparent"></rect><text x="0" y="19.0" fill="transparent" stroke="transparent" font-size="25">163</text><text x="0" y="126.0" fill="transparent" stroke="transparent" font-size="25">0</text></g><g><rect x="40.0" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="60.0" y="20" fill="transparent" stroke="transparent" font-size="30px">117</text></g><g><rect x="96.25" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="116.25" y="20" fill="transparent" stroke="transparent" font-size="30px">144</text></g><g><rect x="152.5" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="172.5" y="20" fill="transparent" stroke="transparent" font-size="30px">137</text></g><g><rect x="208.75" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="228.75" y="20" fill="transparent" stroke="transparent" font-size="30px">158</text></g><g><rect x="265.0" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="285.0" y="20" fill="transparent" stroke="transparent" font-size="30px">127</text></g><g><rect x="321.25" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="341.25" y="20" fill="transparent" stroke="transparent" font-size="30px">105</text></g><g><rect x="377.5" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="397.5" y="20" fill="transparent" stroke="transparent" font-size="30px">163</text></g><g><rect x="433.75" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="453.75" y="20" fill="transparent" stroke="transparent" font-size="30px">0</text></g><g><rect x="490.0" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="510.0" y="20" fill="transparent" stroke="transparent" font-size="30px">18.8</text></g></svg></p></td>
</tr>
<tr>
  <th>DBIL</th>
  <td><p><svg role="img" viewBox="0 0 550 130" style="height: 2em; margin-left: auto; margin-right: auto; font-size: inherit; overflow: visible; vertical-align: middle; position:relative;"><defs><pattern id="area_pattern" width="8" height="8" patternUnits="userSpaceOnUse"><path d="M 0,8 l 8,-8 M -1,1 l 4,-4 M 6,10 l 4,-4" stroke="#FF0000" stroke-width="1.5" stroke-linecap="round" shape-rendering="geometricPrecision"></path></pattern></defs><path d="M 50.0,65.38220986796387 106.25,42.31063238359973 162.5,49.25990271021543 218.75,15.0 275.0,33.137595552467005 331.25,56.90410006949271 387.5,27.23071577484365 443.75,115.0 500.0,110.27449617790133 500.0,125 50.0,125 Z" stroke="transparent" stroke-width="2" fill="url(#area_pattern)" fill-opacity="0.7"></path><path d="M 50.0,65.38220986796387 C 75.0,65.38220986796387 81.25,42.31063238359973 106.25,42.31063238359973 C 131.25,42.31063238359973 137.5,49.25990271021543 162.5,49.25990271021543 C 187.5,49.25990271021543 193.75,15.0 218.75,15.0 C 243.75,15.0 250.0,33.137595552467005 275.0,33.137595552467005 C 300.0,33.137595552467005 306.25,56.90410006949271 331.25,56.90410006949271 C 356.25,56.90410006949271 362.5,27.23071577484365 387.5,27.23071577484365 C 412.5,27.23071577484365 418.75,115.0 443.75,115.0 C 468.75,115.0 475.0,110.27449617790133 500.0,110.27449617790133" stroke="#4682B4" stroke-width="8" fill="none"></path><circle cx="50.0" cy="65.38220986796387" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="106.25" cy="42.31063238359973" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="162.5" cy="49.25990271021543" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="218.75" cy="15.0" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="275.0" cy="33.137595552467005" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="331.25" cy="56.90410006949271" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="387.5" cy="27.23071577484365" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="443.75" cy="115.0" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><circle cx="500.0" cy="110.27449617790133" r="10" stroke="#FFFFFF" stroke-width="4" fill="#FF0000"></circle><g><rect x="0" y="0" width="65" height="130" stroke="transparent" stroke-width="0" fill="transparent"></rect><text x="0" y="19.0" fill="transparent" stroke="transparent" font-size="25">144</text><text x="0" y="126.0" fill="transparent" stroke="transparent" font-size="25">0</text></g><g><rect x="40.0" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="60.0" y="20" fill="transparent" stroke="transparent" font-size="30px">71.4</text></g><g><rect x="96.25" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="116.25" y="20" fill="transparent" stroke="transparent" font-size="30px">105</text></g><g><rect x="152.5" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="172.5" y="20" fill="transparent" stroke="transparent" font-size="30px">94.6</text></g><g><rect x="208.75" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="228.75" y="20" fill="transparent" stroke="transparent" font-size="30px">144</text></g><g><rect x="265.0" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="285.0" y="20" fill="transparent" stroke="transparent" font-size="30px">118</text></g><g><rect x="321.25" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="341.25" y="20" fill="transparent" stroke="transparent" font-size="30px">83.6</text></g><g><rect x="377.5" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="397.5" y="20" fill="transparent" stroke="transparent" font-size="30px">126</text></g><g><rect x="433.75" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="453.75" y="20" fill="transparent" stroke="transparent" font-size="30px">0</text></g><g><rect x="490.0" y="0" width="20" height="130" stroke="transparent" stroke-width="12" fill="transparent"></rect><text x="510.0" y="20" fill="transparent" stroke="transparent" font-size="30px">6.80</text></g></svg></p></td>
</tr>
</tbody>
  <tfoot>
  
  <tr>
    <td colspan="2">Measurements from Day 3 through to Day 8.</td>
  </tr>

</tfoot>

</table>

</div>
</div>
<p>Notice that if you hover over the data points, you still get values for each of the days. We designed nanoplots to be stripped down plotting visualizations that balance the quick visual interpretation of a plot against the compactness of a table.</p>
<p><a href="https://github.com/posit-dev/great-tables"><strong>Great Tables</strong></a> contains a lot of functionality for formatting. If you peeked at the code in the above table displays you might have noticed there are methods beginning with <code>fmt_</code> (i.e., <code>fmt_date()</code>, <code>fmt_integer()</code>, <code>fmt_nanoplot()</code>). We want to make many formatting methods available to serve different users’ needs. We also want them to be easy to use, but with many useful options to provide flexibility for all your formatting tasks.</p>
</section>
<section id="great-tables-is-focused-on-display">
<h4 data-anchor-id="great-tables-is-focused-on-display">Great Tables is focused on display</h4>
<p>There are myriad ways that people interact with tables. <a href="https://github.com/posit-dev/great-tables"><strong>Great Tables</strong></a> is focused on the display of tables for publication and presentation. If you’re analyzing data in a database, you might want a simple table display that offers controls to navigate and filter hundreds, thousands, maybe even more records. And that is great for those situations.</p>
<p>The publication of results is a entirely different task, and the emphasis here is on structuring, formatting, and styling. We believe that beautiful table displays should do the following:</p>
<ul>
<li>make information easier to digest</li>
<li>provide extra context wherever needed</li>
<li>adhere to the style of the document or of the organization</li>
</ul>
<p>We wanted to help the type of user that wanted to present data in this way. This is typically what you see in journal articles, in books, and in reports. We think the area of static summary tables deserves it’s own focus. This class of tables can look <em>great</em> and we offer various <code>opt_*()</code> methods in the <a href="https://github.com/posit-dev/great-tables"><strong>Great Tables</strong></a> API so it’s that much easier to provide a great table to your readers.</p>
</section>
</section>
<section id="in-conclusion">
<h3 data-anchor-id="in-conclusion">In conclusion</h3>
<p>Tables have come a long way and we’ve learned a lot from our continued research in tabular design. We hope to make the <a href="https://github.com/posit-dev/great-tables"><strong>Great Tables</strong></a> package useful for your generation of summary tables. Given there’s ample room for innovation in this area, we’ll keep plugging away at doing that work to improve the API. We measure success by the quality of the tables the package is able to produce and we always keep that goal top of mind.</p>
<p>We’re very excited about where things are going with <a href="https://github.com/posit-dev/great-tables"><strong>Great Tables</strong></a> and we geniunely appreciate community feedback. If ever you want to talk tables with us, you’re always welcome to jump into our <a href="https://discord.com/invite/Ux7nrcXHVV">Discord Server</a> and drop us a line!</p>
<p>Many thanks to Curtis Kephart and <a href="https://anthonywbaker.com/">Anthony Baker</a> for providing helpful advice when writing this article.</p>


</section>


<section id="quarto-appendix" role="doc-endnotes"><h2>Footnotes</h2>

<ol>
<li id="fn1"><p>Taylor, B. (2021). Lunar timekeeping in Upper Paleolithic Cave Art. <em>PRAEHISTORIA New Series</em>, <em>3</em>(13), 215–232.<a href="#fnref1" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Duke, D. W. (2002). Hipparchus’ Coordinate System. <em>Archive for History of Exact Sciences</em>, <em>56</em>(5), 427-433.<a href="#fnref2" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p><a href="https://en.wikipedia.org/wiki/Geography_(Ptolemy)">https://en.wikipedia.org/wiki/Geography_(Ptolemy)</a><a href="#fnref3" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>Palet, J. M. and Orengo, H. A., The Roman Centuriated Landscape: Conception, Genesis, and Development as Inferred from the Ager Tarraconensis Case. <em>American Journal of Archaeology</em>, <em>115</em>(3), 383-402.<a href="#fnref4" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>Marchese, F. T., Exploring the Origins of Tables for Information Visualization. <em>Proceedings of the 2011 15th International Conference on Information Visualisation</em>, 13-15 July 2011, doi:10.1109/IV.2011.36.<a href="#fnref5" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>M. W. Green, The construction and implementation of the cuneiform writing system, <em>Visible Writing</em>, <em>15</em>, 1981, 345-72.<a href="#fnref6" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>Robson, E., “Tables and tabular formatting in Sumer, Babylonia, and Assyria, 2500-50 BCE” in M. Campbell-Kelly, M. Croarken, R.G. Flood, and E. Robson (eds.), <em>The History of Mathematical Tables from Sumer to Spreadsheets</em>. Oxford: Oxford University Press, 2003, 18–47.<a href="#fnref7" role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p><a href="https://site.xavier.edu/polt/typewriters/varityper.html">https://site.xavier.edu/polt/typewriters/varityper.html</a><a href="#fnref8" role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p>Manual of Tabular Presentation: An Outline of Theory and Practice in the Presentation of Statistical Data in Tables for Publication. United States. Bureau of the Census. U.S. Government Printing Office, 1949. Resource available at: <a href="https://www2.census.gov/library/publications/1949/general/tabular-presentation.pdf">https://www2.census.gov/library/publications/1949/general/tabular-presentation.pdf</a>.<a href="#fnref9" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></main> <!-- /main -->

</div></div>]]></description>
        </item>
    </channel>
</rss>