(ignoring known css parsing error)
<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Mon, 29 Dec 2025 05:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[You can make up HTML tags (112 pts)]]></title>
            <link>https://maurycyz.com/misc/make-up-tags/</link>
            <guid>46416945</guid>
            <pubDate>Mon, 29 Dec 2025 02:47:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://maurycyz.com/misc/make-up-tags/">https://maurycyz.com/misc/make-up-tags/</a>, See on <a href="https://news.ycombinator.com/item?id=46416945">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>



<time datetime="2025-08-02">Aug 2, 2025</time>



(<a href="http://maurycyz.com/tags/programming">Programming</a>) 



<p>Instead of writing HTML like this:</p>
<div><pre tabindex="0"><code data-lang="html"><span><span>&lt;<span>div</span> <span>class</span><span>=</span><span>cool-thing</span>&gt;
</span></span><span><span>Hello, World!
</span></span><span><span>&lt;/<span>div</span>&gt;
</span></span></code></pre></div><p>… you can write HTML like this:</p>
<div><pre tabindex="0"><code data-lang="html"><span><span>&lt;<span>cool-thing</span>&gt;
</span></span><span><span>Hello, World!
</span></span><span><span>&lt;/<span>cool-thing</span>&gt;
</span></span></code></pre></div><p>… and CSS like this:</p>
<div><pre tabindex="0"><code data-lang="css"><span><span><span>cool-thing</span> {
</span></span><span><span>	<span>display</span>: <span>block</span>;
</span></span><span><span>	<span>font-weight</span>: <span>bold</span>;
</span></span><span><span>	<span>text-align</span>: <span>center</span>;
</span></span><span><span>	<span>filter</span>: drop-shadow(<span>0</span> <span>0</span> <span>0.5</span><span>em</span> <span>#ff0</span>);
</span></span><span><span>	<span>color</span>: <span>#ff0</span>;
</span></span><span><span>}
</span></span></code></pre></div>
<cool-thing>
Hello, World!
</cool-thing>

<p>Browsers handle unrecognized tags by treating them as a generic element, with no effect beyond what’s specified in the CSS.
This isn’t just a weird quirk, but is <a href="https://html.spec.whatwg.org/multipage/dom.html#htmlunknownelement">standardized behavior</a>.
If you include hyphens in the name, you can guarantee that your tag won’t appear in any future versions of HTML.</p>
<p>While you should use descriptive built-in tags if they exist, if it’s a choice between &lt;div&gt; and &lt;span&gt;,
making up your own tag provides better readability then using a bunch of class names.</p>
<p>As an example, if you have a bunch of nested tags:</p>
<div><pre tabindex="0"><code data-lang="html"><span><span>&lt;<span>div</span> <span>class</span><span>=</span><span>article</span>&gt;
</span></span><span><span>&lt;<span>div</span> <span>class</span><span>=</span><span>article-header</span>&gt;
</span></span><span><span>&lt;<span>div</span> <span>class</span><span>=</span><span>article-quote</span>&gt;
</span></span><span><span>&lt;<span>div</span> <span>class</span><span>=</span><span>quote-body</span>&gt;
</span></span><span><span>... a bunch more HTML ...
</span></span><span><span>&lt;/<span>div</span>&gt;
</span></span><span><span>&lt;/<span>div</span>&gt;
</span></span><span><span>&lt;/<span>div</span>&gt;
</span></span><span><span>&lt;/<span>div</span>&gt;
</span></span></code></pre></div><p>Good luck trying to insert something inside of “article-heading” but after “article-quote” on the first try.
This problem vanishes if you use descriptive tag names — no &lt;/div&gt; counting required:</p>
<div><pre tabindex="0"><code data-lang="html"><span><span>&lt;<span>main-article</span>&gt;
</span></span><span><span>&lt;<span>article-header</span>&gt;
</span></span><span><span>&lt;<span>article-quote</span>&gt;
</span></span><span><span>&lt;<span>quote-body</span>&gt;
</span></span><span><span>... a bunch more HTML ...
</span></span><span><span>&lt;/<span>quote-body</span>&gt;
</span></span><span><span>&lt;/<span>article-quote</span>&gt;
</span></span><span><span><span>&lt;!-- here! --&gt;</span>
</span></span><span><span>&lt;/<span>article-header</span>&gt;
</span></span><span><span>&lt;/<span>main-article</span>&gt;
</span></span></code></pre></div>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Rich Hickey: Thanks AI (121 pts)]]></title>
            <link>https://gist.github.com/richhickey/ea94e3741ff0a4e3af55b9fe6287887f</link>
            <guid>46415945</guid>
            <pubDate>Mon, 29 Dec 2025 00:20:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gist.github.com/richhickey/ea94e3741ff0a4e3af55b9fe6287887f">https://gist.github.com/richhickey/ea94e3741ff0a4e3af55b9fe6287887f</a>, See on <a href="https://news.ycombinator.com/item?id=46415945">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="file-thanksai-md" tabindex="0" role="region" aria-label="ThanksAI.md content, created by richhickey on 09:25PM yesterday.">
    <article itemprop="text">
<p dir="auto">I got this email:</p>
<blockquote>
<p dir="auto">Rich,</p>
<p dir="auto">Your creation of Clojure ...</p>
<p dir="auto"><code>sycophantic blather worthy of a third grader's homework assignment to write a letter to a public figure you don't know, using sources you don't understand, to  express an emotion unfelt, with no intention whatsoever</code></p>
<p dir="auto">Claude Haiku 4.5</p>
</blockquote>
<p dir="auto">Ah, Christmas time. That time of year when our hearts are warmed by the best wishes of an idiot robot. All tingly from the experience, and in the holiday spirit, I thought I'd write my own letter of thanks to those bringing us this next generation of 'AI'.</p>
<p dir="auto"><h3 dir="auto"><em>Dear 'AI' purveyors,</em></h3><a id="user-content-dear-ai-purveyors" aria-label="Permalink: Dear 'AI' purveyors," href="#dear-ai-purveyors"></a></p>
<p dir="auto">How shall I thank thee, let me count the ways:</p>
<p dir="auto">Should I thank you for pirating the entire historical output of creative humanity and then asserting ownership of your loot?</p>
<p dir="auto">For destroying education?</p>
<p dir="auto">For raising utility rates and killing the environment?</p>
<p dir="auto">For wasting vast quantities of developer time trying to coax some useful output from your BS generators, time which could instead be used communicating to interns and entry-level devs who, being actually intelligent, could learn from what they are told, and maintain what they make?</p>
<p dir="auto">For eliminating entry-level jobs, and thus the path to experience, ensuring future generations of unskilled, unemployable people?</p>
<p dir="auto">For giving me a fake person to talk to when I need support instead of an actual person who understands what I'm saying, can help me faster, and has a chance of caring?</p>
<p dir="auto">For replacing search results with summary BS?</p>
<p dir="auto">For providing the tools to fill the internet with slop, making actual human content almost impossible to find?</p>
<p dir="auto">For enticing CEOs with the promise to save some fraction of a percent on personnel costs, not actually be any faster, cutting off their future labor pool while only experiencing a modest to severe reduction in product quality, integrity and customer satisfaction (tradeoffs they are apparently eager to make)?</p>
<p dir="auto">For replacing musical expression with the sounds of robot parrots chirping?</p>
<p dir="auto">For adding an 'AI' feature to every flipping thing, most such features requiring a deep invasion of privacy?</p>
<p dir="auto">For running the second biggest and most damaging con of this century (running hard at first)?</p>
<p dir="auto"><strong><em>I think not.</em></strong></p>
<p dir="auto">This email was a reminder that agentic 'AI' is sure to flood the remainder of human communication channels with BS, swamping many services, and making every interaction with people not in the same room suspect, and filtering it a time-consuming waste, forever.</p>
<p dir="auto"><strong><em>When did we stop considering things failures that create more problems than they solve?</em></strong></p>
<p dir="auto"><h3 dir="auto"><em>Rich</em></h3><a id="user-content-rich" aria-label="Permalink: Rich" href="#rich"></a></p>
</article>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[CEOs are hugely expensive. Why not automate them? (195 pts)]]></title>
            <link>https://www.newstatesman.com/business/companies/2023/05/ceos-salaries-expensive-automate-robots</link>
            <guid>46415488</guid>
            <pubDate>Sun, 28 Dec 2025 23:17:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.newstatesman.com/business/companies/2023/05/ceos-salaries-expensive-automate-robots">https://www.newstatesman.com/business/companies/2023/05/ceos-salaries-expensive-automate-robots</a>, See on <a href="https://news.ycombinator.com/item?id=46415488">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="the-post">

        
<header>
    <!-- Normal closing div -->
          
     
</header><!-- .entry-header-outer /-->
    
        <div id="figarocontent">
                <div>
        <figure>

        <img width="1038" height="692" src="https://dl6pgk4f88hky.cloudfront.net/2021/06/gettyimages-838665582-scaled.jpg" alt="" decoding="async" fetchpriority="high" srcset="https://dl6pgk4f88hky.cloudfront.net/2021/06/gettyimages-838665582-scaled.jpg 2560w, https://dl6pgk4f88hky.cloudfront.net/2021/06/gettyimages-838665582-300x200.jpg 300w, https://dl6pgk4f88hky.cloudfront.net/2021/06/gettyimages-838665582-1024x683.jpg 1024w, https://dl6pgk4f88hky.cloudfront.net/2021/06/gettyimages-838665582-768x512.jpg 768w, https://dl6pgk4f88hky.cloudfront.net/2021/06/gettyimages-838665582-1536x1024.jpg 1536w, https://dl6pgk4f88hky.cloudfront.net/2021/06/gettyimages-838665582-2048x1365.jpg 2048w, https://dl6pgk4f88hky.cloudfront.net/2021/06/gettyimages-838665582-101x67.jpg 101w, https://dl6pgk4f88hky.cloudfront.net/2021/06/gettyimages-838665582-397x265.jpg 397w" sizes="(max-width: 1407px) 1407px, (max-width: 335px) 335px, (max-width: 705px) 705px, (max-width: 335px) 335px, (max-width: 689px) 689px, (max-width: 336px) 336px, (max-width: 210px) 210px, (max-width: 101px) 101px, (max-width: 1024px) 1024px, (max-width: 101px) 101px, (max-width: 397px) 397px, (max-width: 464px) 464px, (max-width: 797px) 797px, (max-width: 960px) 960px, (max-width: 314px) 314px, (max-width: 464px) 464px, (max-width: 735px) 735px, (max-width: 1038px) 1038px">
                <figcaption> (Photo By Chung Sung-Jun/Getty images)</figcaption>
            </figure>
</div>



                <p><em>On Wednesday 31 May, it was reported that Alex Mahon, CEO of Channel 4, could receive<a href="https://www.theguardian.com/uk-news/2023/may/31/channel-4-boss-alex-mahon-could-get-stations-biggest-ever-payday-of-14m" target="_blank" rel="noopener"> record annual pay of £1.4m</a>. This article was originally published on 26 April 2021 and asks, as Executive pay continues to rise, does a company need a CEO at all?</em></p>



<p>Over the next two weeks, the boards of <a href="https://news.sky.com/story/bae-systems-on-defensive-over-golden-handcuffs-deal-for-sought-after-ceo-12280257" target="_blank" rel="noopener nofollow">BAE Systems</a>, <a href="https://news.sky.com/story/looming-astrazeneca-pay-row-provides-latest-headache-for-ceo-soriot-12284677" target="_blank" rel="noopener nofollow">AstraZeneca</a>, <a href="https://www.reuters.com/article/glencore-ceo-pay-idUSL1N2M90QZ" target="_blank" rel="noopener nofollow">Glencore</a>,  <a href="https://www.thetimes.co.uk/article/flutter-entertainment-shareholder-revolt-chief-executive-pay-rise-hostelworld-v6j3khkx2" target="_blank" rel="noopener nofollow">Flutter Entertainment</a> and the <a href="https://news.sky.com/story/london-stock-exchange-faces-investor-backlash-over-chiefs-25-pay-rise-12262725" target="_blank" rel="noopener nofollow">London Stock Exchange</a> all face the possibility of shareholder revolts over executive pay at their forthcoming annual general meetings (AGMs). As the AGM season begins, there is a particular focus on pay.</p>



<p>Executive pay is often the most contentious item at an AGM, but this year is clearly exceptional. The people running companies that have been severely impacted by <a href="https://www.newstatesman.com/tag/covid-19" target="_blank" rel="noopener">Covid-19</a> can’t be blamed for the devastation of their revenues by the pandemic, but they also can’t take credit for the government stimulus that has kept them afloat. Last week, for example, nearly 40 per cent of shareholders in the estate agents Foxtons <a href="https://propertyindustryeye.com/last-weeks-foxtons-agm-must-serve-as-a-wake-up-call-for-the-board/" target="_blank" rel="noopener nofollow">voted against</a> its chief executive officer, Nicholas Budden, receiving a bonus of just under £1m; Foxtons has received about £7m in direct government assistance and is benefiting from the government’s <a href="https://www.newstatesman.com/business/sectors/2021/04/who-benefits-when-government-pumps-housing-market" target="_blank" rel="noopener">continued inflation of the housing market</a>. The person who has done most to ensure Foxtons’ ongoing good fortune is not Nicholas Budden but <a href="https://www.newstatesman.com/tag/rishi-sunak" target="_blank" rel="noopener">Rishi Sunak</a>. </p>



<p>Under the Enterprise and Regulatory Reform Act, executive pay is voted on at least every three years, and this process forces shareholders and the public to confront how much the people at the top take home. Tim Steiner, the highest-paid CEO in the FTSE 100, was paid £58.7m in 2019 for running Ocado, which is <a href="https://www.cipd.co.uk/Images/ftse-100-executive-pay-report_tcm18-82375.pdf" target="_blank" rel="noopener">2,605 times the median income of his employees</a> for that year, while the average FTSE100 CEO makes more than £15,000 a day.  </p><section>
                        <p><a href="https://www.newstatesman.com/business/companies/2023/05/javascript(void);"><img decoding="async" src="https://dl6pgk4f88hky.cloudfront.net/2021/09/TNS_master_logo.svg"></a>
                        </p>
                            <p>Treat yourself or a friend this Christmas to a New Statesman subscription for just £2 </p>
                            
                        </section>



<p>As the High Pay Centre’s annual assessment of CEO pay points out, a top-heavy wage bill extends beyond the CEO, and could be unsustainable for any company this year. “When one considers high earners beyond the CEO”, says the report, ”there is actually quite significant potential for companies to safeguard jobs and incomes by asking higher-paid staff to make sacrifices”.</p>



<p>In the longer term, as companies commit to greater automation of many roles, it’s pertinent to ask whether a company needs a CEO at all.  </p>



<p>A few weeks ago Christine Carrillo, an American tech CEO, raised this question herself when she tweeted a spectacularly tone-deaf appreciation of her executive assistant, whose work allows Carrillo to “write [and] surf every day” as well as “cook dinner and read every night”. In Carrillo’s unusually frank description of the work her EA does – most of her emails, most of the work on fundraising, playbooks, operations, recruitment, research, updating investors, invoicing “and so much more” – she guessed that this unnamed worker “saves me 60% of time”.</p>



<p>Predictably, a horde arrived to point out that if someone else is doing 60 per cent of Carrillo’s job, they should be paid 50 per cent more than her. But as Carrillo – with a frankly breathtaking lack of self-awareness – informed another commenter, her EA is based in the Philippines. The main (and often the only) reason to outsource a role is to pay less for it.</p>



<p><strong><em>[See also: <a href="https://www.newstatesman.com/new-statesman-view/2023/05/the-scourge-of-greedflation" target="_blank" rel="noopener">The scourge of greedflation</a>]</em></strong></p>



<p>If most of a CEO’s job can be outsourced, this suggests it could also be automated. But while <a href="https://www.newstatesman.com/business/companies" target="_blank" rel="noopener">companies</a> are racing to automate entry- and mid-level roles, senior executives and decision makers show much less interest in automating themselves.</p>



<p>There’s a good argument for automating from the top rather than from the bottom. As we know from the annotated copy of <em>Thinking, Fast and Slow</em> that sits (I assume) on every CEO’s Isamu Noguchi nightstand, human decision-making is the product of irrational biases and assumptions. This is one of the reasons strategy is so difficult, and roles that involve strategic decision-making are so well paid. But the difficulty of making genuinely rational strategic decisions, and the cost of the people who do so, are also good reasons to hand this work over to software.</p>



<p>Automating jobs can be risky, especially in public-facing roles. After Microsoft sacked a large team of journalists in 2020 in order to <a href="https://www.theverge.com/2020/5/30/21275524/microsoft-news-msn-layoffs-artificial-intelligence-ai-replacements" target="_blank" rel="noopener nofollow">replace them with AI</a>, it almost immediately had to contend with the <a href="https://www.standard.co.uk/tech/microsoft-robot-ai-editors-jade-thirwall-little-mix-a4463706.html" target="_blank" rel="noopener nofollow">PR disaster</a> of the software’s failure to distinguish between two women of colour. Amazon had to abandon its AI recruitment tool after it <a href="https://www.reuters.com/article/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G" target="_blank" rel="noopener nofollow">learned to discriminate against women</a>. And when GPT-3, one of the most advanced AI language models, was used as a medical chatbot in 2020, it responded to a (simulated) patient presenting with suicidal ideation by <a href="https://www.theregister.com/2020/10/28/gpt3_medical_chatbot_experiment/" target="_blank" rel="noopener nofollow">telling them to kill themselves</a>.</p>



<p>What links these examples is that they were all attempts to automate the kind of work that happens without being scrutinised by lots of other people in a company. Top-level strategic decisions are different. They are usually debated before they’re put into practice – unless, and this is just another reason to automate them, employees feel they can’t speak up for fear of incurring the CEO’s displeasure.</p>



<p>Where automated management – or “<a href="https://www.ibm.com/blogs/journey-to-ai/2020/04/the-rise-of-decision-intelligence-ai-that-optimizes-decision-making/" target="_blank" rel="noopener nofollow">decision intelligence</a>”, as Google and IBM call it – has been deployed, it’s produced impressive results. Hong Kong’s mass transit system put software in charge of scheduling its maintenance <a href="https://www.cs.cityu.edu.hk/~hwchun/AIProjects/stories/allocation/mtrcscheduling/" target="_blank" rel="noopener nofollow">in 2004</a>, and enjoys a reputation as one of the world’s most punctual and best-run metros.   </p>



<p>Clearly, chief execs didn’t get where they are today by volunteering to clear out their corner offices and hand over their caviar spittoons to robots. But management is a very large variable cost that only seems to increase – Persimmon’s <a href="https://www.verdict.co.uk/persimmons-chief-executive-bonus-comparison/" target="_blank" rel="noopener nofollow">bonus scheme</a> paid out half a billion pounds to 150 execs in a single year – while technology moves in the other direction, becoming cheaper and more reliable over time.</p>



<p>It is often asked whether CEO pay is fair or ethical. But company owners and investors should be asking if their top management could be done well by a machine – and if so, why is it so expensive?</p>



<p><strong><em>[See also: <a href="https://www.newstatesman.com/business/the-business-interview/2023/02/modern-milkman-ceo-simon-mellin-boris-johnson" target="_blank" rel="noopener">The milkman on a mission</a>]</em></strong></p>
<div>
    <h6>Content from our partners</h6>

        
            
            
        </div>

                        
                                        
        

    
                
                                    <!-- <div class="dianomiMainDiv" style="min-height: 50px;position: relative!important;">
         
                        <div id='div-gpt-ad-3393934-1'>
                        <script>
                            googletag.cmd.push(function() { googletag.display('div-gpt-ad-3393934-1'); });
                        </script>
                        </div>
                    </div> -->
                    
                    
				            </div><!-- .entry-content /-->

        



    </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[62 years in the making: NYC's newest water tunnel nears the finish line (103 pts)]]></title>
            <link>https://ny1.com/nyc/all-boroughs/news/2025/11/09/water--dep--tunnels-</link>
            <guid>46415426</guid>
            <pubDate>Sun, 28 Dec 2025 23:05:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ny1.com/nyc/all-boroughs/news/2025/11/09/water--dep--tunnels-">https://ny1.com/nyc/all-boroughs/news/2025/11/09/water--dep--tunnels-</a>, See on <a href="https://news.ycombinator.com/item?id=46415426">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Turn on the tap, and water flows without a second thought. But deep beneath New York City, hundreds of feet below street level, workers are finishing a project that’s been under construction for more than half a century — a massive water tunnel that will help keep that simple act possible for generations to come.</p>
<p>Tunnel No. 3, as it’s known, is one of the most ambitious infrastructure projects in the city’s history.</p>
<p>When complete, it will ensure New Yorkers continue to receive clean water from upstate reservoirs — some more than 125 miles away — while allowing long-overdue maintenance on the city’s two older tunnels, built in 1917 and 1936.</p>
<div><hr>

<h4><b>What You Need To Know</b></h4>
<h5><ul>
<li>About 95% of New York City’s water supply flows into the city by gravity through three water tunnels</li>
<br>
<li>Tunnels 1 and 2 were completed in 1917 and 1936, respectively</li>
<br>
<li>Construction on Tunnel 3 began in 1970 and currently serves the Bronx and Manhattan</li>
<br>
<li>The final two shafts in Queens are expected to be completed by 2032, allowing for long-term repairs to the city’s aging water infrastructure</li>
</ul>
</h5>
<hr>

</div>
<p>City Department of Environmental Protection Commissioner Rohit Aggarwala and DEP Portfolio Manager Lauren D’Attile recently took an elevator nearly 800 feet down to see the progress for themselves.</p>
<p>“It’s not quite as far down as the Empire State Building is tall, but it’s getting there,” Aggarwala said during the 10-minute descent.</p>
<p>Down below, flashlights cut through the darkness as water dripped from the rock walls. Workers stood in waterproof boots along the cool, damp concrete — the result of decades of digging, drilling and sealing off bare rock to create a watertight tunnel system.</p>
<p>“When this tunnel was originally constructed, it was built by a tunnel boring machine, which is a very large piece of equipment with cutter heads on the front,” said D’Attile. “We drill the tunnel and after that we line that bare rock with a couple of feet of concrete — so that’s what you’re seeing now, because this tunnel is complete.”</p>
<p>Construction on Tunnel No. 3 began in 1970.</p>
<p>The Bronx and Manhattan already receive water from it, and the final phase — extending service to Brooklyn and Queens — is expected to be completed by 2032.</p>
<p>“The project started in 1970, it will be finished in 2032 — that’s 62 years to build this thing,” Aggarwala said. “But a project like this is going to serve New York for two, three hundred years, who knows how much longer than that. Seems worth it. Totally worth it. It’s what makes the city work because we are constantly investing in our future.”</p>
<p>When it’s complete, the DEP will finally be able to take the older tunnels offline for repairs — a step city engineers have waited decades to take.</p>
<p>Above ground, New Yorkers will keep turning on their faucets, washing dishes, and filling glasses — rarely thinking about the billion gallons of water flowing through the underground arteries that make city life possible.</p>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What an unprocessed photo looks like (859 pts)]]></title>
            <link>https://maurycyz.com/misc/raw_photo/</link>
            <guid>46415225</guid>
            <pubDate>Sun, 28 Dec 2025 22:35:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://maurycyz.com/misc/raw_photo/">https://maurycyz.com/misc/raw_photo/</a>, See on <a href="https://news.ycombinator.com/item?id=46415225">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>



<time datetime="2025-12-27">Dec 27, 2025</time>



(<a href="http://maurycyz.com/tags/photography">Photography</a>) 



<p>Here’s a photo of a Christmas tree, as my camera’s sensor sees it:</p>
<p><img src="https://maurycyz.com/misc/raw_photo/xmas1.jpg" alt=""></p>
<center>Sensor data with the 14 bit ADC values mapped to 0-255 RGB.</center>
<!-- Black point compensation --> 
<p>It’s not even black-and-white, it’s gray-and-gray.
This is becuase while the ADC’s output can theoretically go from 0 to 16382, the actual data doesn’t cover that whole range:</p>
<p><img src="https://maurycyz.com/misc/raw_photo/hist1.png" alt=""></p>
<center>Histogram of raw image</center>
<p>The real range of ADC values is ~2110 to ~136000.
Let’s set those values as the white and black in the image:</p>
<p><strong>V<sub>new</sub> = (V<sub>old</sub> - Black)/(White - Black)</strong></p>
<p><img src="https://maurycyz.com/misc/raw_photo/xmas2.jpg" alt=""></p>
<center>Progress</center>
<p>Much better, but it’s still more monochromatic then I remember the tree being.
Camera sensors aren’t actually able to see color: They only measure how much light hit each pixel.</p>
<p>In a color camera, the sensor is covered by a grid of alternating <a href="https://en.wikipedia.org/wiki/Bayer_filter">color filters</a>:</p>
<p><img src="https://maurycyz.com/misc/raw_photo/xmas3.png" alt=""></p>
<p>Let’s color each pixel the same as the filter it’s looking through:</p>
<p><img src="https://maurycyz.com/misc/raw_photo/xmas4.png" alt=""></p>
<center>Bayer matrix overlay</center>
<p>This version is  more colorful, but each pixel only has one third of it’s RGB color.
To fix this, I just averaged the values each pixel with it’s neighbors:</p>
<p><img src="https://maurycyz.com/misc/raw_photo/xmas5.png" alt=""></p>
<center>Demosaicing results</center>
<p>Applying this process to the whole photo gives the lights some color:</p>
<p><img src="https://maurycyz.com/misc/raw_photo/xmas6.jpg" alt=""></p>
<center>Demosaiced tree</center>
<p>However, the image is still very dark.
This is because monitors don’t have as much dynamic range as the human eye, or a camera sensor:
Even if you are using an OLED, the screen still has some ambient light reflecting off of it and limiting how black it can get.</p>
<p>There’s also another, sneaker factor causing this:</p>
<p><img src="https://maurycyz.com/misc/raw_photo/lin.png" alt=""></p>
<center>True linear gradient</center>
<p>Our perception of brightness is non-linear.</p>
<p>If brightness values are quantized, most of the ADC bins will be wasted on nearly identical shades of white while every other tone is crammed into the bottom.
Because this is an inefficient use of memory, most color spaces assign extra bins to darker colors:</p>
<p><img src="https://maurycyz.com/misc/raw_photo/nonlin.png" alt=""></p>
<center>sRGB gradient</center>
<p>As a result of this, if the linear data is displayed directly, it will appear much darker then it should be.</p>
<p>Both problems can be solved by applying a non-linear curve to each color channel to brighten up the dark areas… but this doesn’t quite work out:</p>
<p><img src="https://maurycyz.com/misc/raw_photo/xmas7.jpg" alt=""></p>
<center>ohno</center>
<p>Some of this green cast is caused by the camera sensor being intrinsically more sensitive to green light, but some of it is my fault:
There are twice as many green pixels in the filter matrix.
When combined with my rather naive demosaicing, this resulted in the green channel being boosted even higher.</p>
<p>In either case, it can fixed with proper white-balance:
Equalize the channels by multiply each one with a constant.</p>
<p>However, because the image is now non-linear, I have to go back a step to do this.
Here’s the dark image from before with all the values temporarily scaled up so I can see the problem:</p>
<p><img src="https://maurycyz.com/misc/raw_photo/xmas8.jpg" alt=""></p>
<p>… here’s that image with the green taken down to mach the other channels:</p>
<p><img src="https://maurycyz.com/misc/raw_photo/xmas9.jpg" alt=""></p>
<center>Banishing the green</center>
<p>… and after re-applying the curve:</p>
<p><img src="https://maurycyz.com/misc/raw_photo/xmas10.jpg" alt=""></p>
<center>Finally: A decent photo.</center>
<p>This is really just the bare minimum:
I haven’t done any color calibration, the white balance isn’t perfect, there’s lots of noise that needs to be cleaned up…</p>
<p>Additionally, applying the curve to each color channel accidentally desaturated the highlights.
This effect looks rather good — and is what we’ve come to expect from film — but it’s has de-yellowed the star.
It’s possible to separate the luminance and curve it while preserving color.
On it’s own, this would make the LED Christmas lights into an overstaturated mess, but combining both methods can produce nice results.</p>
<p>For comparison, here’s the image my camera produced from the same data:</p>
<p><img src="https://maurycyz.com/misc/raw_photo/xmas0.jpg" alt=""></p>
<center>"in camera" JPEG image.</center>
<p>Far from being an “unedited” photo: there’s a huge amount of math that’s gone into making an image that nicely represents what the subject looks like in person.</p>
<p>There’s nothing that happens when you adjust the contrast or white balance in editing software that the camera hasn’t done under the hood.
The edited image isn’t “faker” then the original: they are different renditions of the same data.</p>
<p>In the end, replicating human perception is hard, and it’s made harder when constrained to the limitations of display technology or printed images.
There’s nothing wrong with tweaking the image when the automated algorithms make the wrong call.</p>


        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Dolphin Progress Report: Release 2512 (106 pts)]]></title>
            <link>https://dolphin-emu.org/blog/2025/12/22/dolphin-progress-report-release-2512/</link>
            <guid>46414916</guid>
            <pubDate>Sun, 28 Dec 2025 21:57:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dolphin-emu.org/blog/2025/12/22/dolphin-progress-report-release-2512/">https://dolphin-emu.org/blog/2025/12/22/dolphin-progress-report-release-2512/</a>, See on <a href="https://news.ycombinator.com/item?id=46414916">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <header>
<img src="https://dolphin-emu.org/m/user/blog/progress-report/2512/progressreportheader2512.avif" alt="progressreportheader2512.avif"> 
<img src="https://dolphin-emu.org/m/user/blog/progress-report/2512/progressreportheader2512-mini.avif" alt="progressreportheader2512-mini.avif"> 
</header>

<p>With the holiday season reaching its apex, we have a few surprises for those of you that have been patiently waiting.  The latest release of Dolphin is stuffed with treats.  Our first present is presentation - <em>frame presentation</em>, that is.  Two new options have arrived and will help users both reduce latency and smooth out games that struggle with frame pacing.</p>
<p>Some games do outright naughty things that make emulation difficult.  A slew of them are being coerced onto the nice list this year thanks to a sack full of patches that bypass their troublesome behaviors.  Fans of the Broadband Adapter (BBA) have a great present tailored just to them: a new local mode BBA!  Designed for allowing multiple instances of Dolphin on the same computer to connect together, it's perfect for use with Parsec or other similar services.  And perhaps another gift will have you singing your favorite Wii hits?</p>
<p>But alas, what fun would the holiday season be if we spoiled all the gifts?  Read on to unwrap the latest edition of the Dolphin Progress Report.</p>
<p>...</p>
<p>...</p>
<p>Huh?  We've received word that apparently the <em>Android users</em> have made the nice list?  Really?  That can't be right... but this gift is addressed to them.</p>


<p>After <em>more than a couple</em> bumps in the road, RetroAchievements support has finally arrived on the Android version of Dolphin!  In Release 2512, the core achievement experience is now available in your pocket.  This initial version hasn't quite reached parity yet with the desktop experience, but we didn't want to hold things up any longer.  The important thing for Android RetroAchievements users is that you can log in and unlock achievements in <a href="https://retroachievements.org/system/16-gamecube/games">supported GameCube games</a>. Because some menus are incomplete, it may be best to have the <a href="https://retroachievements.org/">RetroAchievements website</a> open in the background for achievement lists and other things while we finish up the in-app UI.</p>

<h3 id="notable-changes"><strong>Notable Changes</strong><a href="#notable-changes" title="Permanent link">¶</a></h3>
<h4 id="2509-493-add-rush-frame-presentation-and-smooth-frame-presentation-options-by-billiard"><strong><a href="https://dolphin-emu.org/download/dev/master/2509-493/">2509-493 - Add Rush Frame Presentation and Smooth Frame Presentation Options</a></strong>  by <strong><a href="https://github.com/jordan-woyak">Billiard</a></strong><a href="#2509-493-add-rush-frame-presentation-and-smooth-frame-presentation-options-by-billiard" title="Permanent link">¶</a></h4>
<p>Latency was once a huge challenge for emulators, and it is still a major concern.  At one point not too long ago, it was pretty much infeasible for most emulators to match the latency of their console counterparts.  Compared to a dedicated game console racing the beam on a CRT television, emulators had to deal with sluggish OS window managers with on-by-default triple-buffer V-Sync holding three frames back, first-gen wireless controllers that added latency right at the source of input, slower displays that added several <a href="https://www.gamesindustry.biz/digitalfoundry-tech-focus-battle-against-latency">additional frames of latency</a> (much more if that display was a TV without game mode), and on top of everything the emulator still needed to do its job and take time to actually emulate everything.</p>
<p>Dolphin <em>just</em> missed out on the worst of this. By the time Dolphin's performance and compatibility were good enough for users to worry about things like latency, the overall situation had improved dramatically.  Low latency and high refresh rate monitors paired with features like <a href="https://dolphin-emu.org/blog/2014/07/31/dolphin-progress-report-july-2014/#40-2286-d3d-exclusive-fullscreen-by-armada651">Exclusive Fullscreen</a> removed most of the major bottlenecks that emulators had to fight against.</p>
<p>The designs of the GameCube and Wii <em>also</em> afford Dolphin some opportunities that other emulators don't have.  The GameCube/Wii are double buffer V-Sync'd by default, resulting in a final input latency of roughly 60ms on a CRT in an optimized 60fps title.  However, because of <a href="https://dolphin-emu.org/blog/2017/11/19/hybridxfb/">how the XFB Output Pipeline works</a>, Dolphin has the opportunity to bypass the buffers and grab those XFB copies early, and immediately present them directly to the screen. We call this feature <em>Immediately Present XFB</em>, and it cuts out quite a bit of the latency present on the console.</p>
<p>Tricks like these let Dolphin match console latency as long as the host device is capable enough.  On extremely optimal setups with low latency VRR monitors combined with <em>Immediately Present XFB</em>, Dolphin could even dip a frame <em>below</em> real console latency!</p>
<p>There are some caveats, though.  While <em>Immediately Present XFB</em> is a powerful tool for reducing latency, it is also a hack that relies on games behaving in a specific manner.  If a game messes with the XFB pipeline, such as if it applies post processing using the CPU, or stitches together multiple XFB Copies, the hack will cause Dolphin to output nonsensical garbage.</p>




<p>Even when <em>Immediate</em> isn't outright breaking the game, the XFB pipeline is a big part of how some games handle frame pacing, so bypassing it can make the game feel less smooth.  For the best experience in many games, a user probably would prefer superior latency <em>and</em> good frame pacing.</p>


<p>And that was <strong><a href="https://github.com/jordan-woyak">Billiard's</a></strong> goal.  He saw an opportunity to improve the situation and started work on two new options.  One feature was a way to reduce latency without disrupting how the game rendered, and the other would allow smoother frame pacing even in games that struggled on real console.  How would he accomplish these feats?  Well, by making the emulator throttle <em>smarter</em>.</p>
<hr>
<p>Modern computers are powerful enough to emulate <a href="https://wiki.dolphin-emu.org/index.php?title=Star_Wars_Rogue_Squadron_III:_Rebel_Strike"><em>most</em></a> GameCube and Wii games faster than the original hardware could run them. Disable the framelimiter and try it for yourself! To keep emulation on pace, Dolphin’s <em>Throttle</em> function stalls emulation to produce a <em>mostly</em> properly paced simulation of the original hardware. Throttling is necessary for playable emulation on modern systems, but making the host CPU wait <em>adds time</em>. If input from the user and stalls are aligned poorly, throttling can add a small amount of latency.</p>
<p>To address this, Billiard has added a new throttling mode called <em>Rush Frame Presentation</em>, where throttling becomes centered around presenting the frame as soon as it can after the input is read. In theory, this reduces the time between click and photon and can have a very noticeable effect, especially in lower frame rate titles.  To the end user, all of this is completely invisible.  All of this is happening <em>sub-frame</em>, so Dolphin still will throttle the appropriate amount of time to maintain the correct frame rate.</p>
<p>The faster your computer, the more of an effect this will have because it will be able to emulate the part of the frame faster.  We can easily catch the difference in <a href="https://wiki.dolphin-emu.org/index.php?title=The_Legend_of_Zelda:_The_Wind_Waker">The Legend of Zelda: Wind Waker</a> and <a href="https://wiki.dolphin-emu.org/index.php?title=Super_Mario_Sunshine">Super Mario Sunshine</a> by using a high speed camera, for example.</p>
<p>
<figure>
<video controls="" playsinline="">
<source src="https://dolphin-emu.org/m/user/blog/progress-report/2512/cropped-sms-av1.webm" alt="cropped-sms-av1.webm (AV1)" type="video/webm" codecs="av01.0.00M.08, opus">
<source src="https://dolphin-emu.org/m/user/blog/progress-report/2512/cropped-sms-vp9.webm" alt="cropped-sms-vp9.webm (VP9)" type="video/webm" codecs="vp9">
<source src="https://dolphin-emu.org/m/user/blog/progress-report/2512/cropped-sms-h264.mp4" alt="cropped-sms-h264.mp4 (h.264)" type="video/mp4">
</video>

<figcaption>Here we can visually see the reduced latency that Rush provides. This is somewhere between 8 - 14ms.<br><sub>Click/tap to Play.</sub></figcaption>
</figure>
</p>

<p>Some games will also see a <em>further</em> benefit by combining <em>Immediately Present XFB</em> with <em>Rush Frame Presentation</em>.  Unfortunately, this combination can lead certain games to looking gnarly as they will just be spitting out the image at whatever point they're finished rendering during a frame.  That's why the second new option is important.</p>
<h5 id="smoothing-things-out"><strong>Smoothing Things Out</strong><a href="#smoothing-things-out" title="Permanent link">¶</a></h5>
<p><em>Immediately Present XFB</em> could already cause poor frame pacing, and now <em>Rush Frame Presentation</em> could make it even worse.  In some games, it can get so poor that VRR monitors will fall out of their operating range!</p>
<p><em>Smooth Frame Presentation</em> allows Dolphin to delay presentation by roughly 1-2ms so that it can more consistently output frames, using previous frame times as a heuristic.  This option can be used in any game that has poor frame pacing in order to try to improve the situation.</p>


<p>The results of <em>Smooth Frame Presentation</em> are good enough that a lot of games that needed the XFB Output Pipeline enabled by default because of frame pacing issues can now take advantage of the lower input latency provided by <em>Immediately Present XFB</em> and <em>Rush Frame Presentation</em> without any noticeable side-effects.</p>
<p>Even if you're using neither of the latency features, some games just have bad frame pacing even on real console.  <em>Smooth Frame Presentation</em> can help them, too.  There are rare cases, especially when using <em>Rush Frame Presentation</em> alongside <em>Immediately Present XFB</em>, where a game's output will be so inconsistent that smoothing won't help.  We're looking at you, <a href="https://wiki.dolphin-emu.org/index.php?title=Dragon_Ball_Z:_Budokai">Dragon Ball Z: Budokai</a>.</p>


<h5 id="outside-verification"><strong>Outside Verification</strong><a href="#outside-verification" title="Permanent link">¶</a></h5>
<p>All of these results sound great, but outside of a few camera tests on lower frame rate games, we were mostly trusting latency offset numbers <em>provided by Dolphin</em>.  Testers did also report better latency, but given that the <a href="https://en.wikipedia.org/wiki/Placebo">placebo effect</a> exists and these are such small differences, we wanted more concrete data.  But other than just <em>game feel</em>, how do you test latency?</p>
<p>In the past, we've used the light sensor present on <a href="https://wiki.dolphin-emu.org/index.php?title=Rock_Band_3">Rock Band 3</a> guitars alongside an in-game synchronization test to get some very rough offset values.  The problem with that is that it will only ever test one game, and the guitar controller isn't particularly viable in most games outside of unusual controller runs.</p>
<p>Before making any claims about our latency, we wanted to do our due dilligence in respect to both Dolphin and real hardware.  To accomplish this, we contacted some professionals that have been fighting against latency for quite some time.  <strong><a href="https://github.com/JLaferri">Fizzi</a></strong> from <a href="https://slippi.gg/">Slippi.gg</a>  and adapter expert <strong><a href="https://github.com/JulienBernard3383279">Arte</a></strong> graciously donated their time and helped us measure latency in the latest version of Dolphin versus console.   <strong><a href="https://github.com/JulienBernard3383279">Arte</a></strong> <a href="https://www.input-integrity.com/">specifically developed a GameCube controller adapter with a photon sensor</a> designed to determine controller latency, which is rather convenient because <em>that's exactly what we want to measure</em>.</p>
<p>Their GameCube controller adapter polls the controller at 1000Hz, and a light sensor on it can be programmed to look for certain changes in output from the game.  By having access to both the source of the input and the change on the screen, the adapter can provide a real world measurement of how exactly how long it takes for a user input to result in a change on the display - what is commonly referred to as "click to photon".  As an added bonus, the adapter can also be hooked up to real console with no conversion or added latency, letting us compare directly with games running on real hardware and a CRT.</p>

<p>The exciting thing about these numbers is that they confirm our experience.  Dolphin's latency compares favorably to console.  To be fair to the GameCube, <strong><a href="https://github.com/JulienBernard3383279">Arte</a></strong>'s emulation setup included a modern low-latency 144Hz monitor and the lowest latency controller adapter.   Dolphin couldn't quite compete with Slippi, but most of that can be attributed to deep modifications to how <a href="https://wiki.dolphin-emu.org/index.php?title=Super_Smash_Bros._Melee">Super Smash Bros. Melee</a> outputs.</p>
<p>For all the samples above, an input bug present in the original game has been patched out.  This is to make getting consistent results a little bit easier.  That fix did mean that combining <em>Rush Frame Presentation</em> and <em>Immediately Present XFB</em> no longer benefited that title when testing.  However, <strong><a href="https://github.com/JulienBernard3383279">Arte</a></strong> modified the test to work with other games, and some games respond incredibly well when combining Rush and Immediate.</p>

<!--
Immediate: 105.9 / 105.8 / 110.2 / 110.2
Immediate + RFP: 96.5 / 99.6 / 99.2 / 96.8
-->

<!-- The below is the windwakerlatency.js backup. If we can get that working, comment this out instead
<div class="media-block wider"> 
<figure>
<img src="https://dolphin-emu.org/m/user/blog/progress-report/2512/windwakerlatency-lowchart.png" alt="windwakerlatency-backupchart.png">
<figcaption></figcaption>
</figure>
</div>
--->

<p>Due to time constraints with holiday vacations, adjusting the photon sensor for different games, we weren't able to gather all of the numbers we wanted from other games.  However, with <a href="https://wiki.dolphin-emu.org/index.php?title=The_Legend_of_Zelda:_The_Wind_Waker">Wind Waker</a> the numbers were interesting enough that we managed to get enough samples <em>right under the wire</em>, at least in Dolphin.  The graph above shows latency with default settings, <em>Immediately Present XFB</em> and the combined efforts of <em>Immediately Present XFB</em> and <em>Rush Frame Presentation</em>.  Note that the default settings were measured last, and as such the error range is estimated.</p>
<p>The reason why we wanted to squeeze in this particular case is because it demonstrates that combining <em>Rush Frame Presentation</em> and <em>Immediately Present XFB</em> can result in lower latency than what was possible before.  This is not always true, and this 10ms reduction is from an ideal example.  Unmodified <a href="https://wiki.dolphin-emu.org/index.php?title=Super_Smash_Bros._Melee">Melee</a>, for instance, showed the combination reducing latency by less than 4ms.  Some games saw no benefit from combining both features together.</p>
<p>In the end, how much these two new options will help varies greatly depending on the game and setup.  Currently, we've left them both disabled by default in the Configuration -&gt; Advanced Tab, but that may change as the settings get more testing and we gauge what users want the most.</p>
<h4 id="2509-74-gamecube-add-sdl-stock-profile-by-samb"><strong><a href="https://dolphin-emu.org/download/dev/master/2509-74/">2509-74 - GameCube - Add SDL Stock Profile</a></strong>  by <strong><a href="https://github.com/Sam-Belliveau">Samb</a></strong><a href="#2509-74-gamecube-add-sdl-stock-profile-by-samb" title="Permanent link">¶</a></h4>
<p>Unlike the wacky Wii Remote and its mess of attachments, the GameCube Controller mostly mirrors modern controllers.  Sure, the sticks can't be pushed in, it's missing a shoulder button, the two stage analog+digital triggers can be tricky, and the face buttons are weird. But at the end of the day, it's a four face button, twin stick controller with a D-pad. Close enough?</p>
<p>So we have added an SDL Profile that players can use to speed up their GameCube controller mapping. </p>


<p>Using the profile is simple:</p>
<ol>
<li>Go the GameCube "Standard Controller" mapping window.</li>
<li>Select your controller from the Device dropdown. Pick the variant that starts with "SDL".</li>
<li>Select the <code>SDL Gamepad (Stock)</code> Profile and click Load.</li>
<li>Optional: Calibrate your joysticks (please don't skip this Hall effect users!) and set up deadzone.</li>
<li>Enjoy.  </li>
</ol>
<p>Since the GameCube controller doesn't map 1:1 to modern controllers, this is a <em>best guess</em> stock profile that will <em>reasonably</em> work for most people, most controllers, and most games. If a game demands a button combination that doesn't work with your hands on your controller, or if the face buttons or any other button simply aren't to your liking, you can build from the stock profile and adjust everything until it's just right.</p>
<h4 id="2509-237-and-2509-339-add-option-to-reset-settings-back-to-default-by-joshuavandaele-and-simonx22"><strong><a href="https://dolphin-emu.org/download/dev/master/2509-237/">2509-237</a></strong> and <strong><a href="https://dolphin-emu.org/download/dev/master/2509-339/">2509-339</a></strong> - <strong>Add Option to Reset Settings Back to Default</strong> by <strong><a href="https://github.com/JoshuaVandaele">JoshuaVandaele</a></strong> and <strong><a href="https://github.com/Simonx22">Simonx22</a></strong><a href="#2509-237-and-2509-339-add-option-to-reset-settings-back-to-default-by-joshuavandaele-and-simonx22" title="Permanent link">¶</a></h4>
<p>Dolphin is a complicated emulator with a lot of options.  Some of it is definitely our fault, and some of it is just the reality of trying to emulate something as complicated as the GameCube and Wii.  To the average user, a lot of these settings aren't immediately obvious, even with descriptions.</p>
<p>"<em>Emulated Memory this?  EFB, XFB that, VBI what?</em>"</p>
<p>The most experienced users (and even developers) can sometimes get frustrated enough with an issue that <a href="https://en.wiktionary.org/wiki/percussive_maintenance">percussive maintenance</a> is necessary, leading to one changing lots of settings around until <em>something</em> happens.  Sometimes this works, leading to a temporary moment of joy, before it all comes crashing down when none of your other games will boot.  Some people might be able to backtrack and figure out what went wrong, but a lot of users are left lost.</p>
<p>Until recently, users had to delete the Dolphin settings files from their computer to restore everything to default.   No one liked that, but a button to reset settings was non-trivial thanks to <a href="https://dolphin-emu.org/blog/2017/07/01/dolphin-progress-report-june-2017/#50-4171-videoconfig-port-to-layered-configuration-system-by-merrymage">Dolphin's multiple layers of settings</a> that are a handful to manage.</p>
<p>Thankfully, <strong><a href="https://github.com/JoshuaVandaele">JoshuaVandaele</a></strong> was finally able to sort out all of the implementation details and give us the long awaited "Reset All Settings" button.</p>


<p>Thanks to <strong><a href="https://github.com/Simonx22">Simonx22</a></strong>, Android users also get access to this feature.  It can be found in the advanced settings menu in the Android GUI.</p>
<h4 id="2509-217-gamepatch-modify-certain-games-to-behave-better-in-dolphin-by-supersamus-with-additional-contributors"><strong><a href="https://dolphin-emu.org/download/dev/master/2509-217/">2509-217 - GamePatch:  Modify Certain Games to Behave Better in Dolphin</a></strong>  by <strong><a href="https://github.com/SuperSamus">SuperSamus</a></strong> with additional contributors<a href="#2509-217-gamepatch-modify-certain-games-to-behave-better-in-dolphin-by-supersamus-with-additional-contributors" title="Permanent link">¶</a></h4>
<p>Some games are more strenuous to emulate than others.  Sometimes it's because the <a href="https://wiki.dolphin-emu.org/index.php?title=The_Last_Story">game pushes the console</a>, and other times it's because the game does something <a href="https://dolphin-emu.org/blog/2025/09/16/dolphin-progress-report-release-2509/#2506-29-game-patch-defang-the-disney-trio-of-destruction-by-josjuice-and-billiard">annoying to emulate - maliciously or not.</a></p>
<p>The latter situation can be especially frustrating, as sometimes 99% of what the game does is fine, with just <em>one</em> little behavior, design decision, or sometimes even an underlying bug causing problems for Dolphin.</p>
<p><strong><a href="https://github.com/SuperSamus">SuperSamus</a></strong> identified a few common game behaviors that causes Dolphin a lot of headaches.  Properly fixing these issues would difficult, with some requiring large rewrites to the emulator that probably will never come.  Fortunately, there is a simpler solution: patch out the difficult to emulate game behaviors.  These small patches increase emulation performance, and sometimes even work around other unwanted behaviors.</p>
<h5 id="complex-idle-loops"><strong>Complex Idle Loops</strong><a href="#complex-idle-loops" title="Permanent link">¶</a></h5>
<p>Idle loops are a sequence of instructions that makes the CPU run laps doing nothing while it waits for something to happen.  Obviously, emulating a CPU burning cycles doing nothing isn't efficient for an emulator, so one of Dolphin's earliest optimizations was the ability to detect and skip these idle loops. This feature is fairly standard among emulators and is called <em>Idle Skipping</em>.</p>
<p>Idle loops are more common than you might think. It's very rare for a game to absolutely max out the console's CPU, so <em>for the majority of frames</em> the CPU will idle a bit. And as long as Dolphin can detect the idle loops, they can be skipped to increase overall performance.  <em>Idle Skipping</em> is one of the key things that make some areas of a game more demanding than others, especially on the CPU side of things.  Essentially, <em>Idle Skipping</em> is less effective the more that the CPU has to do.</p>
<p>Dolphin can't detect all idle loops, and the scope of what it can find is rather limited.  We have to find as many idle loops as accurately as possible while also ensuring that we don't invest too much time and resources into finding them.  The more complex the heuristic is, the more of an impact it will have on the JIT.  As such, some games have annoying idle loops that we know about but are not worth detecting.</p>
<p><a href="https://wiki.dolphin-emu.org/index.php?title=Need_for_Speed:_Nitro">Need for Speed: Nitro</a> and <a href="https://wiki.dolphin-emu.org/index.php?title=Rayman_Raving_Rabbids">Rayman Raving Rabbids</a> are two such games with these complex idle loops. After examining their code in detail, <strong><a href="https://github.com/SuperSamus">SuperSamus</a></strong> realized that their idling behaviors could be modified with a patch that would allow Dolphin to more easily detect and skip them.</p>
<p>This results in <em>massive</em> performance boosts, especially in lighter areas, with some menus running at four times as fast.  Of course, heavier areas see less of a benefit. We'll have a chart showing some of the raw numbers at the end.</p>
<h5 id="running-uncapped"><strong>Running Uncapped</strong><a href="#running-uncapped" title="Permanent link">¶</a></h5>
<p>Dolphin is not a cycle accurate emulator.  In fact, Dolphin is fundamentally not designed to be cycle accurate, especially with GPU operations. Dolphin's emulated GPU was designed to be <strong>infinitely fast</strong>, only being limited by other factors like CPU emulation or the maximum performance of the host device. Nowadays, it has been tamed a bit with synchronization points that provide a rough approximation of the timings of the original <a href="https://dolphin-emu.org/blog/2025/09/16/dolphin-progress-report-release-2509/#processor-processing">command processor</a>, but it is still by no means accurate, let alone <em>cycle</em> accurate. Also, rendering is still infinitely fast, as the only thing that limits it is the speed of your host GPU.</p>
<p>And yet, most games run at the correct frame rate, because they <em>limit themselves</em>.</p>
<p>The GameCube and Wii were designed for analog TVs, so they used the analog television's sign to start a new frame as a synchronization point called the <a href="https://dolphin-emu.org/blog/2023/02/12/dolphin-progress-report-december-2022-january-2023/#50-18271-video-hack-vbi-skip-by-sam-belliveau">Vertical Blanking Interupt (VBI)</a>. All a game had to do was start a new frame every time it saw a VBI and finish the frame before the next VBI, and it would be perfectly synchronized to the frame rate of the display. That's it. It was simple and efficient, so the vast majority of GameCube and Wii library tie their frame rates to the VBI. Thanks to that, Dolphin's early developers didn't even need to care about how fast the emulated GPU runs; as long Dolphin emits VBIs at the correct frequency, most games will just run at the correct frame rate regardless of what's going on under the hood. And this gives Dolphin bonuses like not emulating GPU slowdown, allowing games that struggled on console to perform much better in Dolphin.</p>
<p>But the GameCube and Wii don't have operating systems. Games run on the bare metal and have full control of the machine, so developers could do <em>whatever they wanted</em>.  And some games eschew the VBI and run <strong>uncapped</strong>.</p>
<p>Uncapped games break Dolphin's assumptions. They can render way, <em>way</em> too fast.  For example, when running <a href="https://wiki.dolphin-emu.org/index.php?title=Hulk">Hulk (2003)</a> in Dolphin, it only displays at 60 FPS, but the physics engine could be doing hundreds of steps per second behind the scenes.  This is cool because technically a game like this can easily be hacked to run at higher frame rates, but <em>terrible</em> because it hammers people's devices with all kinds of unnecessary work!</p>
<p>It gets even worse from here.  The physics engine's independence from the output frame rate isn't <em>perfect</em>.  If the number of steps per second gets too high, small rounding and math errors start to accumulate, and parts of the game not properly tuned to run at these higher frame rates start to break.  This mostly results in dialogue timing issues, but in one stage halfway through the game, it causes a physics calculation issue where a required ledge can't be climbed, essentially softlocking the player.</p>


<p>Some other games choose to synchronize to the VBI, but don't bother in incredibly simple scenes where the frame rate doesn't matter.  This is most commonly seen with splash screens and loading screens.  One such game with this behavior is <a href="https://wiki.dolphin-emu.org/index.php?title=Bully:_Scholarship_Edition">Bully: Scholarship Edition</a>. Most of the time it is perfectly stable, but because the loading screens are uncapped, it can actually cause the game to randomly hang on transitions.  <a href="https://wiki.dolphin-emu.org/index.php?title=The_Simpsons_Hit_%26_Run">The Simpsons Hit &amp; Run</a> also has this issue, but only during the initial load.  While most desktop computers are able to handle the initial load relatively well, Android users have reported tremendous slowdowns where the loading time would take more than 45 seconds.</p>
<p><strong><a href="https://github.com/SuperSamus">SuperSamus</a></strong> identified these problems and either created patches for these behaviors themselves, or helped others with those titles create patches.  Most of these patches are only one or two lines and simply limit the game's frame rate to the VBI frequency.  The patches prevent the game from slamming Dolphin's overpowered emulated GPU, greatly increasing performance while fixing issues caused by the games running internally at too high of a frame rate.</p>
<p>This comes with a little bonus - since they are now bound to the VBI frequency, you can now use <em>VBI Frequency Override</em> to adjust their frame rate up or down as desired, allowing Dolphin to take advantage of the fact that these games "support" running at higher frame rates.</p>
<p>In addition to the games above that had emulation bugs caused by framelimiting, <strong><a href="https://github.com/SuperSamus">SuperSamus</a></strong> and <strong><a href="https://github.com/jordan-woyak">Billiard</a></strong> also created limiter patches for the following games purely for performance reasons:</p>
<ul>
<li><a href="https://wiki.dolphin-emu.org/index.php?title=Conduit_2">Conduit 2</a></li>
<li><a href="https://wiki.dolphin-emu.org/index.php?title=Driver:_San_Francisco">Driver: San Francisco</a></li>
<li><a href="https://wiki.dolphin-emu.org/index.php?title=Monsters_Inc._Scream_Arena">Monsters Inc. Scream Arena</a></li>
<li><a href="https://wiki.dolphin-emu.org/index.php?title=Tetris_Worlds">Tetris Worlds</a></li>
</ul>
<!--
BEFORE/AFTER PATCHES PERF

AMD 9950x3D RTX 4090 4x IR

Need For Speed Nitro: Main Menu:  Before 236, After 806
Driver: San Francisco: City: Before 86, After 210
Conduit 2: - Before: 142 fps, After 264 fps
Hulk(2003): Before: 179, After: 511 fps
-->

<center><p>Somewhat ironically, by slowing down uncapped games we improve their performance in Dolphin, so when turning off Dolphin's framelimiter they go much faster. ...ignore that and use this as a measure of their performance improvement. If a game's frame rate doubled in this chart, then the performance required to run that game at fullspeed has been roughly halved.</p></center>

<p>These numbers don't tell the whole story on some of these games.  <a href="https://wiki.dolphin-emu.org/index.php?title=Hulk">Hulk (2003)</a> and other games which ran uncapped would get progressively worse performance in Dolphin depending on how <em>light</em> the scene was to render.</p>
<p>As a final reminder, these patches should not be considered proper solutions to fixing uncapped games.  They are purely to increase playability of these titles.</p>
<h5 id="eggmania-eggstream-madness"><strong>Eggmania: Eggstream Madness</strong><a href="#eggmania-eggstream-madness" title="Permanent link">¶</a></h5>
<p>The <em>Force Progressive Output</em> patch we included for the Japanese version of this game was causing it to crash on boot.  Since we were adding new patches and <strong><a href="https://github.com/extrems">extrems</a></strong> had already pointed us to a <em>correct</em> version of the patch, we decided to update it alongside all of the other patches.</p>
<p>Despite being the Japanese version of a rather obscure game, this crash was somehow reported multiple times by different users.  For the two of you out there waiting, the fix is finally here.</p>
<h4 id="2509-242-bba-ipc-for-bba-between-multiple-instances-of-dolphin-on-the-same-machine-by-cristian64"><strong><a href="https://dolphin-emu.org/download/dev/master/2509-242/">2509-242 - BBA:  IPC for BBA Between Multiple Instances of Dolphin on the Same Machine</a></strong>  by <strong><a href="https://github.com/cristian64">cristian64</a></strong><a href="#2509-242-bba-ipc-for-bba-between-multiple-instances-of-dolphin-on-the-same-machine-by-cristian64" title="Permanent link">¶</a></h4>
<p>The Broadband Adapter (BBA) for the GameCube was all about connecting games to a network. Whether across the hall with a Local Area Network (LAN) or across the continent with the information superhighway, the BBA brought Nintendo consoles together like nothing before it! Well, except the <a href="https://dolphin-emu.org/blog/2024/04/30/dolphin-progress-report-february-march-and-april-2024/#50-21253-implement-modem-adapter-by-fuzziqersoftware">Modem Adapter</a>, but we're not talking about that today.</p>
<p>Dolphin has supported the BBA emulation for many years.  An early LLE implementation was fairly accurate, but required the user to setup TAP servers and suffered from performance bottlenecks with said TAP servers depending on the operating system.  It wasn't until <a href="https://dolphin-emu.org/blog/2022/09/13/dolphin-progress-report-july-and-august-2022/#50-16838-add-hle-broadband-device-by-schthack-and-many-additional-fixes-by-sepalani">BBA-HLE</a> in 2022 that BBA emulation became readily accessible to the average user.</p>


<p>BBA-HLE is great if you want to connect Dolphin to another computer or real hardware.  But if you want to run multiple instances <em>on the same computer</em>, things get more complicated.  While it was technically possible through networking trickery, it was far beyond what we'd expect of the average user.</p>
<p><strong><a href="https://github.com/cristian64">cristian64</a></strong> realized that this problem could be pretty cleanly solved by using a library called <code>cpp-ipc</code>.  This library would allow <em>separate instances</em> of Dolphin on the same machine to share data easily and efficiently through Inter-Process Communication (IPC).  Instead of using a network stack, we can just simulate the instances of Dolphin being in their very own network and let them communicate without the need for any outside support. </p>
<p>With BBA-IPC added, here's a quick rundown of the many options you have for BBA.</p>
<ul>
<li><strong>Broadband Adapter (TAP)</strong>: Dolphin's LLE solution for the Broadband Adapter that requires a TAP interface.</li>
<li><strong>Broadband Adapter (XLink-Kai)</strong>:  LLE solution that can connect to the Xlink-Kai service to allow players on separate networks to connect together.  Success highly depends on each game's latency tolerance and the latency between the players.</li>
<li><strong>Broadband Adapter (HLE)</strong>:  HLE solution that hooks the Broadband Adapter up to the host's network interface to connect with other devices on the network or to a server for certain online games.</li>
<li><strong>Broadband Adapter (IPC)</strong>:  HLE solution that allows Dolphin instances on the same machine to share memory and communicate directly without the need for a host network.</li>
</ul>
<p>BBA-IPC allows for easy testing of BBA features on a single PC, and can also be used in conjunction with game streaming services like Parsec to play BBA titles over the internet without needing to meet the strict latency requirements of emulating the BBA over the internet. This is admittedly a rather niche usecase for BBA, but the feature is relatively compact and easy to maintain.</p>
<p>Currently, only Windows and Linux are supported by BBA-IPC, but if there is enough interest, <strong><a href="https://github.com/cristian64">cristian64</a></strong> has already found another library that could let us support this in other operating systems.</p>
<h4 id="2509-250-iptop-make-inetaton-async-by-sepalani"><strong><a href="https://dolphin-emu.org/download/dev/master/2509-250/">2509-250 - IP/Top: Make InetAToN async</a></strong>  by <strong><a href="https://github.com/sepalani">sepalani</a></strong><a href="#2509-250-iptop-make-inetaton-async-by-sepalani" title="Permanent link">¶</a></h4>
<p>Playing <a href="https://wiki.dolphin-emu.org/index.php?title=Mario_Kart_Wii">Mario Kart Wii</a> online in Dolphin back when WFC support was first added was a rather rough experience.  It was functional, but slow and stuttery, just enough to be playable and help players with preserving traffic to the official WFC in the final months before the servers were finally shut down.</p>
<p>But that wasn't the end.  Thanks to revival efforts, many Wii games still have online communities, with <a href="https://wiki.dolphin-emu.org/index.php?title=Mario_Kart_Wii">Mario Kart Wii</a> being quite possibly the biggest.  In the years since, Dolphin's Wi-Fi emulation has gotten to the point that users can play alongside real Wiis in most games without any issues.</p>
<p>Well, <em>most</em> users.  Unfortunately, even in modern builds of Dolphin there were a couple of users having severe stuttering and freezing problems, and all of them were using Android devices.  These problems were handwaved away as typical Android performance issues at first, but after closer examination, it was obvious that there was something else going wrong.  One user recorded us tons of examples and helped narrow down what was happening.</p>
<p>
<figure>
<video controls="" playsinline="">
<source src="https://dolphin-emu.org/m/user/blog/progress-report/2512/mariokartjoinhang-av1.webm" alt="mariokartjoinhang-av1.webm (AV1)" type="video/webm" codecs="av01.0.00M.08, opus">
<source src="https://dolphin-emu.org/m/user/blog/progress-report/2512/mariokartjoinhang-vp9.webm" alt="mariokartjoinhang-vp9.webm (VP9)" type="video/webm" codecs="vp9">
<source src="https://dolphin-emu.org/m/user/blog/progress-report/2512/mariokartjoinhang-h264.mp4" alt="mariokartjoinhang-h264.mp4 (h.264)" type="video/mp4">
</video>

<figcaption>For one user, the pauses were long enough to lock up the emulator altogether.<br><sub>Click/tap to Play. File has audio.</sub></figcaption>
</figure>
</p>

<p>They (accurately!) surmized that it had something to do with a player joining or leaving the online lobby.  In <a href="https://wiki.dolphin-emu.org/index.php?title=Mario_Kart_Wii">Mario Kart Wii</a>, players can join or leave a race mid-match, with new players spectating until the next race began.  The only mystery left was figuring out why this was only happening to a couple of users while everyone else was fine.</p>
<p>Using their wealth of knowledge from working on the <a href="https://wiki.dolphin-emu.org/index.php?title=Monster_Hunter_Tri">Monster Hunter Tri</a> <a href="https://forum.wii-homebrew.com/index.php/Thread/60432-Monster-Hunter-Tri-private-server-progress/">replacement Wi-Fi servers</a>, <strong><a href="https://github.com/sepalani">sepalani</a></strong> jumped in and investigated the issue.  Same as us, they couldn't find any issues at first. They were able to play without any kind of freezing, even on their phone.  However, after unlocking the frame rate on a desktop computer, <strong><a href="https://github.com/sepalani">sepalani</a></strong> noticed a small hitch when the function <code>InetAToN</code> was called.  This hitch was impossible to see when running at normal speed, but when running at 1000%+ speed, the dip was just barely noticeable.</p>
<p><code>InetAToN</code> is a standard networking function that takes an IP address string and converts it into its equivalent binary form. For example, the string <code>192.51.100.50</code> would be transformed into the hexadecimal number <code>0xC0336432</code>. On the Wii, <code>InetAToN</code> has some additional functionality that is unusual: in addition to text-based IPs, it also accepts <em>hostnames</em> as inputs. This means that a developer can choose to pass a hostname like <code>google.com</code> into <code>InetAToN</code>, and the function will perform a <a href="https://www.cloudflare.com/en-us/learning/dns/what-is-dns/">Domain Name System</a> (DNS) lookup to resolve the hostname into an IP address. </p>
<p><strong><a href="https://github.com/sepalani">sepalani</a></strong> figured out that if a hostname was provided to <code>InetAToN</code> and the resulting DNS lookup was slow enough, the function would cause a stutter because Dolphin waits for the result of the lookup before continuing. The time it takes for a DNS lookup to finish varies depending on various factors, such as the user's internet connection. On a desktop PC connected to home internet, the lookup would complete before the user even saw a frame drop. But many of our Android users are connected to the internet via cellular data, which can have particularly poor latency depending on signal strength and network congestion.</p>
<p>Therefore, <strong><a href="https://github.com/sepalani">sepalani</a></strong> changed <code>InetAToN</code> to be non-blocking so that DNS resolution can take as long as it wants without locking up the emulator.</p>
<h4 id="2509-481-sdio-fix-csdcid-emulation-by-naim2000"><strong><a href="https://dolphin-emu.org/download/dev/master/2509-481/">2509-481 - SDIO: Fix CSD/CID emulation</a></strong>  by <strong><a href="https://github.com/Naim2000">Naim2000</a></strong><a href="#2509-481-sdio-fix-csdcid-emulation-by-naim2000" title="Permanent link">¶</a></h4>
<p>There's no way to sugarcoat this one.  This was a pretty bad %$#&amp; up.  Dolphin's SD card emulation was broken, and has been broken for a very long time.  Yet somehow, <em>it worked</em>. This is one of the dangers of emulation - sometimes you can do something very wrong yet the software just trudges on.  </p>
<p>The modern Wii homebrew scene lives off of SD Cards.  It's a convenient tool available on <em>most</em> Wiis, and can be used in conjunction with the <a href="https://wiki.dolphin-emu.org/index.php?title=Homebrew_Channel">Homebrew Channel</a>, BootMii, and other essential homebrew.  It's not uncommon to see a 32GB SD card in a Wii loaded with homebrew emulators, software, and game mods.</p>
<p>One oddity about the Wii is that it was released <em>without</em> support for the then new <a href="https://en.wikipedia.org/wiki/SD_card#SDHC">SDHC standard</a> (2GB to 32GB SD cards).  This would be rectified in <a href="https://wiibrew.org/wiki/System_Menu_4.0">an update three years later</a>, but the damage was done.  <a href="https://hackmii.com/2009/02/why-the-wii-will-never-get-any-better/">Thanks to the way Nintendo designed the Wii's software stack</a>, games released prior to SDHC support being added would be forced to use older IOSes that lacked SDHC support.  Even if your System Menu, homebrew, and newer games worked with your big SD card, a game like <a href="https://wiki.dolphin-emu.org/index.php?title=Super_Smash_Bros._Brawl">Super Smash Bros. Brawl</a> wouldn't.  At least without some help.</p>
<p>The <a href="https://wiki.dolphin-emu.org/index.php?title=Super_Smash_Bros._Brawl">Brawl</a> community refused to be restricted by Nintendo's paltry limitations. They used homebrew to load the game with newer IOS versions and even patched the game to remove the nonsensical 3 minute time limit on replays.  Small patches like these were just the beginning, as the community started making bigger changes to the game, like balance patches Brawl+ and Brawl-, and eventually full game overhauls like Project M and its offspring.</p>
<p>The Smash Bros. community is still pushing the limits of homebrew on both the Wii and Dolphin.  One such effort is <a href="https://www.rexbuild.site/">Super Smash REX</a>.  REX has an astounding amount of stages, music, and characters to the point that just the base mod is over <em>8GB</em> in size.  And that's where we come into all of this.</p>
<p>A developer from REX reached out to us about how they were reaching some kind of limit with the virtual SD card in Dolphin. Once the amount of data on the SD card exceeded <strong>10.7GiB</strong>, Dolphin's SD card support would completely fall apart.</p>


<p>This actually wasn't <em>too surprising</em>.  There have been scattered reports from <a href="https://wiki.dolphin-emu.org/index.php?title=Rock_Band_3">Rock Band 3</a> and <a href="https://wiki.dolphin-emu.org/index.php?title=Category:Just_Dance_(Series)">Just Dance</a> failing when too much DLC was installed to the SD card.  However, reproducing those issues required owning a mountain of DLC, which none of us did.  With REX, everything was readily available and the actual launcher was just a homebrew application.  This made reproducing the issue much easier, and they did most of the work for us.</p>
<p>The key detail was that the files on the SD card didn't even have to relate to the mod.  We could just fill it with cat pictures, load up the <a href="https://wiki.dolphin-emu.org/index.php?title=Homebrew_Channel">Homebrew Channel</a> or any other homebrew that relied on the SD card, and watch the fireworks.  What could be going wrong?</p>
<hr>
<p>In a community as old as the GameCube/Wii scene, there are some voices that <em>must</em> be heeded.  Before the REX developers reached out to us, one of the Supreme GameCube/Wii Sages, <strong><a href="https://github.com/extrems">extrems</a></strong>, hadst been prognosticating doom since the new year if a bug with the card ID (CID) and card-specific data (CSD) registers in our SD card emulation was not mended.  Verily, it came to pass.</p>


<p>The problem was extremely straightforward.  When the emulated Wii queried the virtual SD card for its capabilities, such as size and speed, Dolphin would return <em>complete garbage</em> due to the reports being in the wrong byte order.  The strange part of this was that SD card emulation even worked <em>at all</em>.</p>
<p>When REX reported there were SD card issues, we quickly thought of the flaws that <strong><a href="https://github.com/extrems">extrems</a></strong> pointed out to us.  However, knowing the problem and fixing it were two very different things.  Our attempts to make things right only made things worse.  Two different developers took a stab at it, and both left SD card emulation completely non-functional.  We were left defeated and efforts on the problem slowed.</p>
<p>In mid-November, <strong><a href="https://github.com/jordan-woyak">Billiard</a></strong> was perusing <s>Pull Requests</s> ancient tomes of knowledge that fell through the cracks. One such tome was named "SDIO: report write lock status".  Emulating a SD card's write lock switch was a rather unimportant implementation detail that would not affect emulation.  As such, there was no rush to review it.  But when <strong><a href="https://github.com/jordan-woyak">Billiard</a></strong> did finally get to reviewing it, he saw that it <em>also fixed Dolphin's CID and CSD byte ordering</em>.</p>
<p>A few quick reviews and a rebase later, and the bug was finally quelled.  Now Dolphin properly works with virtual SD cards up to 32GB in size.</p>
<p> 
<figure>
<a href="https://dolphin-emu.org/m/user/blog/progress-report/2512/projectrexfixed.mp4">
<video muted="" autoplay="" loop="" playsinline="">
<source src="https://dolphin-emu.org/m/user/blog/progress-report/2512/projectrexfixed-av1.webm" alt="projectrexfixed-av1.webm (AV1)" type="video/webm" codecs="av01.0.00M.08, opus">
<source src="https://dolphin-emu.org/m/user/blog/progress-report/2512/projectrexfixed-vp9.webm" alt="projectrexfixed-vp9.webm (VP9)" type="video/webm" codecs="vp9">
<source src="https://dolphin-emu.org/m/user/blog/progress-report/2512/projectrexfixed-h264.mp4" alt="projectrexfixed-h264 (h.264)" type="video/mp4">
</video>
</a>
<figcaption>This is how Super Smash REX's intro is supposed to look.</figcaption>
</figure>
</p>

<h4 id="2509-542-usb-emulated-support-for-logitech-microphone-for-wii-by-biendeo"><strong><a href="https://dolphin-emu.org/download/dev/master/2509-542/">2509-542 - USB:  Emulated Support for Logitech Microphone for Wii</a></strong>  by <strong><a href="https://github.com/Biendeo">Biendeo</a></strong><a href="#2509-542-usb-emulated-support-for-logitech-microphone-for-wii-by-biendeo" title="Permanent link">¶</a></h4>
<p>The Logitech Microphone is an iconic accessory for the Nintendo Wii.  <a href="https://wiki.dolphin-emu.org/index.php?title=Category:USB_Microphone_(Input_supported)">Roughly 100 games</a>, including popular titles in the <a href="https://wiki.dolphin-emu.org/index.php?title=Category:Guitar_Hero_(Series)">Guitar Hero</a> and <a href="https://wiki.dolphin-emu.org/index.php?title=Category:Rock_Band_(Series)">Rock Band</a> series, support the peripheral.</p>
<p>Dolphin has had support for the <em>physical</em> Logitech Microphone via USB Passthrough for years, but even as other USB peripherals received their emulated counterparts, those wanting to sing into an emulated Wii using generic microphones had to wait.  <a href="https://dolphin-emu.org/blog/2025/06/04/dolphin-progress-report-release-2506/#2503-580-wii-speak-emulation-by-shuffle2-degasus-noahpistilli-and-sepalani">Even the maligned Wii Speak received support</a> before the Logitech Microphone, despite the fact that it supported far fewer games and was much more complicated to implement.  This is just how emulation works sometimes. The more complicated, less useful accessory was just far more interesting than the popular, yet generic accessory.</p>
<p>But the foundation created for emulating the Wii Speak did lend itself well toward implementing a second microphone accessory in Dolphin.  After all, the Wii Speak <em>was</em> a microphone, so a few people took shots at adapting the Wii Speak code to work with the Logitech Microphone.</p>
<p>First, <a href="https://github.com/supermilkdude67">supermilkdude67</a> posted a WIP fork with very basic support that fizzled out.  A few months later, <a href="https://retroachievements.org/forums/topic/32317">a certain announcement</a> brought renewed interest toward making the many singing games more accessible to users.  <strong><a href="https://github.com/Biendeo">Biendeo</a></strong> took over the mantle using the initial fork as a base.  With some help from veteran Dolphin developers, a few fixes, and some upgrades to the GUI, it was ready to go.</p>


<p>You can now emulate the Logitech Microphone with any standard PC microphone!  The exact volume levels might need to be adjusted depending on the input source, so make sure you properly calibrate before your first jam session. Given that this is a new feature, compatiblity isn't perfect, and some games may take more fiddling than others.</p>
<p>For our Android users, things aren't ready yet.  While the core feature should be mostly compatible between the two environments, it will need a completely different GUI.  As such, it might be a while before everything gets ported over to our Android builds.</p>
<h4 id="2509-406-on-screen-display-add-new-default-font-by-trytwo"><strong><a href="https://dolphin-emu.org/download/dev/master/2509-406/">2509-406 - On-Screen Display:  Add New Default Font</a></strong>  by <strong><a href="https://github.com/TryTwo">TryTwo</a></strong><a href="#2509-406-on-screen-display-add-new-default-font-by-trytwo" title="Permanent link">¶</a></h4>
<p>Dolphin's On-Screen Display is an important part of communicating with users, whether it's statistics, performance metrics, or notifications from features like RetroAchievements.  Unfortunately, the pixel font we were using could be hard to read, especially for some users with HiDPI screens.  <strong><a href="https://github.com/TryTwo">TryTwo</a></strong> improved the situation by <a href="https://dolphin-emu.org/download/dev/master/2509-59/">adding the ability to change the font size of on-screen display messages</a>, but this didn't solve the problem - making a pixel font larger can look quite bad, especially at non-integer scales.  Dolphin needed a new font that could scale to arbitrary resolutions while still looking clear.</p>
<p>With this change, Dolphin's OSD now uses a proper vector font!</p>


<p>Vera Sans Mono is the new default font.  We think that in pretty much every scenario, it's easier to read than our old font.  However, <strong><a href="https://github.com/TryTwo">TryTwo</a></strong> figured that since we were adding a font anyway, that Dolphin could just provide the ability for users to override the font.  So if you're unsatisfied with our typography tastes, add the font of your choice to the "Load" folder of your User directory and name it "OSD_Font.ttf". Any TrueType font will work!</p>


<p>Now that the On-Screen Display has even more options, we've decided to consolidate them within their own config section.  So if you're looking to adjust what is displayed, font size, or if you want them disabled altogether, the settings can now be found in one place within the On-Screen Display section of the Configuration window.</p>
<h4 id="2509-554-ax-hle-fix-low-pass-filter-edge-case-by-flacs"><strong><a href="https://dolphin-emu.org/download/dev/master/2509-554/">2509-554 - AX-HLE: Fix Low Pass Filter Edge Case</a></strong>  by <strong><a href="https://github.com/tilka">flacs</a></strong><a href="#2509-554-ax-hle-fix-low-pass-filter-edge-case-by-flacs" title="Permanent link">¶</a></h4>
<p>If you were an arcade junkie in the late 90s and early 2000s, then you're probably familiar with the Midway classic <em><a href="https://wiki.dolphin-emu.org/index.php?title=Category:NFL_Blitz_(Series)">NFL Blitz</a></em>.  Authentic teams thrust into a deliberately inaccurate simulation with colorful gameplay and flashy graphics made the series a bombastic hit in arcades.  And of course, the blisteringly difficult AI that would <em>absolutely cheat</em> drained quarters from avid players, making it enticing for arcade owners as well.</p>


<p>In this, we're not talking about beloved or hated arcade games, but instead the home console exclusive <a href="https://wiki.dolphin-emu.org/index.php?title=NFL_Blitz_Pro">NFL Blitz Pro</a>.  This attempt to adapt to the console landscape was a commercial failure that lacked the charm and personality of the earlier titles.  And we can confirm the popularity thing - this title had broken audio by default in Dolphin for <em>over four years</em> with no one making a formal bug report and only two forgotten comments throughout our community.</p>
<p>It wasn't until <strong><a href="https://github.com/jordan-woyak">Billiard</a></strong> was testing games to see if they worked with <em>Immediately Present XFB</em> that we became aware that the game's sound was broken.</p>


<p>After doing some quick testing, <strong><a href="https://github.com/jordan-woyak">Billiard</a></strong> realized that DSP-LLE resolved the issue, and with no further leads he made a setting adjustment and <a href="https://dolphin-emu.org/download/dev/master/2509-551/">disabled HLE audio for this game by default in 2509-551</a>.</p>


<p>The very next day, <strong><a href="https://github.com/tilka">flacs</a></strong> saw the audio regression, found what build broke it, figured out why it was broken, <em>and</em> fixed the issue.  <a href="https://wiki.dolphin-emu.org/index.php?title=NFL_Blitz_Pro">NFL Blitz Pro</a> is another game that uses the low-pass filter.  In Dolphin, the low-pass filter was notoriously broken and left <a href="https://dolphin-emu.org/blog/2021/08/01/dolphin-progress-report-june-and-july-2021/#50-14712-dsp-hle-re-enable-low-pass-filter-by-flacs-original-fix-by-merrymage">completely disabled for many, many years</a>.  During the process in which the feature was finally fixed and re-enabled, no one thought to test this game. If we had, we would have noticed that it hit an edge-case in the HLE implementation of the low-pass filter.</p>
<p>When the game reserves a region of memory, its memory allocator sets all bytes within the region to <code>0xAB</code>.  This behavior isn't necessarily abnormal, as the initial state of the memory shouldn't matter. When using freshly allocated memory, it is best practice to first initialize it with sane default values before attempting to use it. Unfortunately, the developers of <a href="https://wiki.dolphin-emu.org/index.php?title=NFL_Blitz_Pro">NFL Blitz Pro</a> forgot to perfom this initialization when reserving memory for the game's audio engine. The <a href="https://www.ign.com/articles/1999/07/30/the-musyx-experience">MusyX library</a> determines if the low-pass filter is enabled by checking if the appropriate bytes within its assigned memory region are not zero.  Because <code>0xAB</code> is not zero, the library assumes that the low-pass filter should be enabled.</p>
<p>Because most audio related memory is still in the default state of <code>0xAB</code>, the two low pass filter coefficients are <em>also</em> set to <code>0xABAB</code>.  When DSP-HLE goes to calculate how much the low-pass filter should quiet or amplify things, it adds these values together.  For our purposes, the values are interpreted by the game as 16-bit fixed point values, so the coefficients would be roughly <code>1.341156</code>.  These two values <em>added together</em> are supposed to add up to about <code>1.0</code>, but in this case the result is roughly <code>2.682312</code>.  DSP-HLE sees this number and boosts the volume accordingly, making things sound rather unpleasant.</p>
<p> 
<figure>
<audio controls="">
<source src="https://dolphin-emu.org/m/user/blog/progress-report/2512/nfl-blitz-pro_broken-filter.mp3" type="audio/mpeg"> Your browser does not support the audio tag. </audio> 
<figcaption>It's a little loud.</figcaption>
</figure>
</p>
<p>The programmers were using uninitialized memory by accident, which is a game bug.  Regardless of their intent, these were the values that the game used.  So why was Dolphin broken?  <strong><a href="https://github.com/tilka">flacs</a></strong> figured out that the second filter value is actually a <em>signed</em> value.  For a typical 16-bit fixed point value, this means positive values are <code>0x0000</code> to <code>0x7FFF</code>, and negative values are <code>0x8000</code> to <code>0xFFFF</code>.  <code>0xABAB</code> is supposed to be interpreted as a <em>negative</em> value.</p>
<p>With the bug fixed, the equation changes to <code>1.34 + (-0.66)</code>, giving us a coefficient sum of roughly <code>0.68</code>.  The filter is still active and now <em>lowering</em> the volume of the game, but this is accurate to real hardware. It seems that the developers worked around the filter's unintentional activation by just making the game louder to compensate.  By handling these uninitialized values correctly, DSP-HLE now produces proper audio in this title.</p>
<p> 
<figure>
<audio controls="">
<source src="https://dolphin-emu.org/m/user/blog/progress-report/2512/nfl-blitz-pro_correct-filter.mp3" type="audio/mpeg">Your browser does not support the audio tag. </audio> 
<figcaption>With the filtering corrected, we can now enjoy NFL Blitz Pro's sporting and uplifting football music in DSP-HLE once again.</figcaption>
</figure>
</p>
<hr>
<h3 id="this-releases-contributors"><strong>This Release's Contributors...</strong><a href="#this-releases-contributors" title="Permanent link">¶</a></h3>
<p>Special thanks to <a href="https://github.com/dolphin-emu/dolphin/graphs/contributors?from=2025-09-15&amp;to=2025-12-21&amp;type=c">all of the contributors</a> that incremented Dolphin by 585 commits after Release 2509!</p>

<hr>


<!-- tooltip code below -->







    
    
    

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Unity's Mono problem: Why your C# code runs slower than it should (150 pts)]]></title>
            <link>https://marekfiser.com/blog/mono-vs-dot-net-in-unity/</link>
            <guid>46414819</guid>
            <pubDate>Sun, 28 Dec 2025 21:41:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://marekfiser.com/blog/mono-vs-dot-net-in-unity/">https://marekfiser.com/blog/mono-vs-dot-net-in-unity/</a>, See on <a href="https://news.ycombinator.com/item?id=46414819">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
			<p>Execution of C# code in Unity’s Mono runtime is slow by today’s standards, much slower than you might expect! Our game runs 2-3x faster on modern .NET compared to Unity’s Mono, and in a few small benchmarks I measured speedups of up to 15x. I’ve spent some time investigating what’s going on and in this article I will present my findings and why everyone should want Unity’s .NET modernization to become production-ready as soon as possible.</p>
		
<h2 id="How-did-we-get-here">How did we get here</h2>

<p>
	Unity uses the Mono framework to run C# programs and back in 2006 it was one of the only viable multi-platform implementations of .NET.
	Mono is also open-source, allowing Unity to do some tweaks to better suit game development.
</p>
<p>
	An interesting twist happened nearly 10 years later.
	In 2014, Microsoft began open-sourcing .NET (notably .NET Core later that year) and in June 2016, .NET Core 1.0 shipped with official cross-platform support.
	Since then, the .NET ecosystem gained momentum and lots of improvements have been made, including the Roslyn compiler platform, a new JIT (just-in-time compiler), performance improvements, more features, etc.
</p>
<p>
	In 2018, <a href="https://xoofx.github.io/blog/2018/04/06/porting-unity-to-coreclr/" target="_blank">Unity engineers discussed</a> that they are working on porting the engine to .NET CoreCLR, the multi-platform version of Common Language Runtime (CLR), a component that runs .NET programs.
	Their main motivations behind this project were performance and convergence.
	In their post they said:
</p>
<blockquote>...CoreCLR could be great for Unity game developers, as it will provide a significant boost in performance, by an order of 2x to 5x compare to the Mono runtime sometimes up to x10 on some workload!</blockquote>
<p>
	Unfortunately, now it’s the end of 2025 and we still can’t run games on CoreCLR.
</p>


<h2 id="The-performance-gap">The performance gap</h2>

<p>
	We don’t hear about the performance gap between Mono and .NET much, likely because it is not possible to run games written for Unity under modern .NET.
	But we can still do a direct comparison with code that does not depend on Unity directly.
</p>
<p>
	Our game has a unique architecture – we strictly separate the game simulation code (business logic) from rendering.
	So much so that the simulation code does not depend on Unity’s libraries and can be compiled and run under any .NET version.
</p>
<p>
	One day I was debugging an issue in map generation and it was time-consuming because it was taking over 2 minutes to start a game.
	To make debugging faster, I’ve written a unit test, hoping to cut down on the turn-around time since Unity takes 15+ seconds just to crunch new DLLs and reload the domain before the game can be launched and it also initializes rendering stuff that I did not care about.
	When I ran the test, it finished in 40 seconds.
	I was quite surprised that it was more than 3x faster, so I started digging deeper.
</p>
<p>
	Long story short, <a href="#figure-1" title="Go to figure 1: A trace of game startup in Unity and .NET, Debug mode.">Figure 1</a> shows traces from a profiler showing the difference between the game launching in Unity running under Mono vs. a unit test running under .NET.
</p>
<p>
	<i>Note that all shown benchmarks are using either Unity 6.0 or .NET 10.</i>
</p>

<div id="figure-1"><p><span>Figure 1: A trace of game startup in Unity and .NET, Debug mode.</span></p></div>

<p>
	So our benchmark shows that loading a save file, generating a map, and initializing the simulation takes 100 seconds in Unity/Mono but only 38 seconds in .NET.
	This result alone is already something that may raise eyebrows and has real consequences of how you may want to approach debugging and testing.
</p>
<p>
	I also know from experience with Unity that Release mode running as a standalone executable (without the Unity editor) is much faster, so I decided to test that next.
</p>

<h2 id="NET-vs-Mono-in-standalone-Release-mode">.NET vs. Mono in standalone Release mode</h2>
<p>
	Debug mode slowness is not great, but even non-optimized C++ code can be slow.
	To compare the real performance gap between Mono and .NET, let’s run the same benchmark as above but in release mode, standalone executable.
</p>
<p>
	First up: Unity. I’ve run our deploy script to get an optimized executable and run it directly.
	Unsurprisingly, optimized standalone executable is beating Unity editor by a big margin, more than 3x faster.
	Next, the same code running under .NET in Release mode.
	<a href="#figure-2" title="Go to figure 2: A trace of game startup in Unity and .NET, Release mode">Figure 2</a> shows the results.
</p>
<div id="figure-2"><p><span>Figure 2: A trace of game startup in Unity and .NET, Release mode</span></p></div>

<p>
	Yep. 12 seconds.
	It’s actually mind-boggling how much work is being done in these 12 seconds and when I saw this for the first time, I was not only shocked, but also impressed.
	Just so you know, a 4k × 4k map is being generated using all available threads out of hundreds of combined noise functions in like 3 seconds.
	<a href="#figure-3" title="Go to figure 3: The expanded trace of the 12-second run from above. The blue boxes after the highlighted area is the actual unit test, stepping the game.">Figure 3</a> shows the trace expanded.
</p>
<p><a href="https://marekfiser.com/blog/mono-vs-dot-net-in-unity/img/DotNet-release-detail.982.png" title="The expanded trace of the 12-second run from above. The blue boxes after the highlighted area is the actual unit test, stepping the game." data-size="2272x1619"><img src="https://marekfiser.com/blog/mono-vs-dot-net-in-unity/img/DotNet-release-detail-w719-h512.982.png" width="719" height="512" alt="The expanded trace of the 12-second run from above. The blue boxes after the highlighted area is the actual unit test, stepping the game." srcset="https://marekfiser.com/blog/mono-vs-dot-net-in-unity/img/DotNet-release-detail-w1437-h1024.982.png 2x"></a><span>Figure 3: The expanded trace of the 12-second run from above. The blue boxes after the highlighted area is the actual unit test, stepping the game.</span></p>
<p>
	If you are interested in seeing the actual x86 assembly generated by Mono and .NET JITs, see the Extras section at the end of this article.
</p>


<h2 id="Conclusion">Conclusion</h2>

<p>
	As you can see from the presented benchmarks, Mono is massively behind .NET in terms of performance.
	This is primarily due to differences in runtime optimizations and JIT that generates unoptimized assembly.
	The actual speedup surely depends on the code itself, but from my research, 1.5-3x speedup of C# execution is very likely for most projects.
</p>
<p>
	If you are a game developer using Unity, or even a player, you can now understand that <b>CoreCLR would be a massive boost to performance of games and even the Unity editor</b>.
	Unfortunately, for the past 8 years, Unity leadership was more interested in “other things” and did not give .NET modernization the attention it deserves.
</p>
<p>
	Some view .NET modernization as support for new language features in C#, but that is just a cherry on top.
	New C# adds some handy features, but the new JIT can deliver multi-x speedups.
</p>
<p>
	At this year's Unite conference, <a href="https://www.youtube.com/watch?v=rEKmARCIkSI&amp;t=1502s" target="_blank">Unity announced</a>
	that CoreCLR is still ongoing but it won’t be production ready in 2026.
	The good news is that it now seems to be on the Unity 6.x roadmap, and not left for later versions as suggested by 2024’s Unite presentation.
</p>
<div id="figure-4"><p><span>Figure 4: Slides from Unite 2025 showing that .NET Modernization is planned for 6.x release with unannounced date.</span></p></div>
<p>
	Moreover, CoreCLR is not just new JIT and C#, it unlocks broader and better-optimized support for things like Span&lt;T&gt;-style APIs, hardware intrinsics, and newer SIMD paths that devs cannot use these days.
	These features could add another multiplier to the performance gains for some classes of code.
	For example, our map generator heavily uses 2D and 3D simplex noise.
	I bet that having access to new runtime features in CoreCLR could speed up the map generation by another 2x.
</p>
<p>
	Unity has a technology called Burst that automatically converts marked C# methods to optimized native assembly via the LLVM compiler.
	This sounds neat as it can avoid the poor JIT performance, but the downside is that Burst has strict limitations on what can be converted and supports only subset of C#.
	I believe that CoreCLR with modern JIT will have very similar performance characteristics to Burst.
	I am curious what would happen in a universe where Unity invested all the time and effort in CoreCLR support and high-performance C#, instead of developing and maintaining Burst.
</p>
<p>
	Another interesting consequence of CoreCLR support is the ability to pre-compile the .NET intermediate assembly to machine code using ahead-of-time compilation (AOT).
	AOT can further improve startup time and is essential on platforms where JIT is restricted (notably iOS).
	Nowadays, Unity solves this with IL2CPP that takes the intermediate code and compiles it to C++ which is then optimized and compiled to native assembly.
	However, <a href="https://discussions.unity.com/t/the-unity-engine-roadmap-unite-2025/1696495/65" target="_blank">according to RichardFine (Unity staff)</a>,
	using CoreCLR AOT is not planned and IL2CPP is here to stay:
</p>
<blockquote>AOT for IL2CPP is completely independent of AOT for CoreCLR (which we have no plans to adopt anyway).
GC behaviour on IL2CPP improves when we upgrade the GC there, it’s not really affected by CoreCLR at all.</blockquote>
<p>
	In conclusion, CoreCLR won’t magically fix every bottleneck in a Unity game, but it does fix many of the code generation inefficiencies and allows writing higher-performance code.
	The benchmark presented in this article is meant to illustrate that modern .NET has spent years squeezing more work into fewer CPU cycles, and Unity users are largely locked out of those gains today.
</p>
<p>
	If Unity can deliver production-ready CoreCLR support, it won’t just mean “newer C#”.
	It will mean faster runtime performance, faster iteration times, more performance headroom, no domain reload, 
	better GC behavior, and maybe even more managed code and less native code. 
	Until then, the gap will remain an invisible tax on every Unity project that leans on managed code.
</p>
<p>
	I’m cheering for you, Unity devs, CoreCLR for the win!
</p>
<p><img src="https://marekfiser.com/blog/mono-vs-dot-net-in-unity/img/CoreClrForTheWin.606.png" width="613" height="433" alt="CoreCLR in Unity engine for the win!"></p>

<p>
	I have actually dug much deeper into the performance aspects of Mono vs .NET but for the sake of this article not being too long, here is a brief summary.
</p>
<p>
	<a href="#code-1" title="Go to code listing 1: Simple benchmark code">Code listing 1</a> shows the testing code.
	It does some basic summing of custom structs that are wrappers around ints.
	This is an interesting example because Mono is very bad at inlining and simplifying expressions, even obvious ones, and we have plenty of structs like these in our code base (e.g. Quantity, MechPower, Tile2i, etc).

</p>

<div id="code-1"><p><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
</pre></td><td><pre><span>static</span> <span>class</span> Program {

	<span>static</span> <span>void</span> Main() {
		Console.WriteLine(RunTest(<span>int</span>.MaxValue));
	}

	<span>public</span> <span>static</span> TestStruct RunTest(<span>int</span> iterations) {
		TestStruct value1 = <span>new</span> TestStruct(iterations % 2);
		TestStruct value2 = <span>new</span> TestStruct(iterations % 7);
		TestStruct value3 = <span>new</span> TestStruct(iterations % 13);

		TestStruct result = <span>default</span>;

		<span>for</span> (<span>int</span> i = 0; i &lt; iterations; ++i) {
			result += value1 + value2;
			result += value1 + value3;
		}

		<span>return</span> result;
	}

}

<span>readonly</span> <span>struct</span> TestStruct {

    <span>public</span> <span>readonly</span> <span>int</span> Value;

    <span>public</span> TestStruct(<span>int</span> value) {
        Value = value;
    }

    <span>public</span> <span>static</span> TestStruct <span>operator</span> +(TestStruct lhs, TestStruct rhs) {
        <span>return</span> <span>new</span> TestStruct(lhs.Value + rhs.Value);
    }

    <span>public</span> <span>override</span> <span>string</span> ToString() =&gt; Value.ToString();

}</pre></td></tr></tbody></table></code></p></div>

<p>
	To obtain assembly code, I’ve compiled the code in Release mode and ran it as a standalone executable.
	Then, I attached a debugger to the running process. An easy way to find this loop was to make it long/infinite and just break the program at any time, it would end up in that loop.
</p>
<p>
	First, let’s take a look at .NET. Here is the x64 assembly of the for-loop section of the code.
</p>
<div id="code-2"><p><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
</pre></td><td><pre><span>add</span> r8d,edx
<span>add</span> edx,r10d
00007FFDEC338E88:
    <span>mov</span>  r10d,r8d
    <span>add</span>  r9d,r10d
    <span>mov</span>  r10d,edx
    <span>add</span>  r9d,r10d
    <span>inc</span>  ecx
    <span>cmp</span>  ecx,eax
    <span>jl</span>   00007FFDEC338E88</pre></td></tr></tbody></table></code></p></div>
<p>
	In both cases, the full loop of <code>int.MaxValue</code> iterations took around 750 ms on my machine.
</p>
<p>
	This looks neat. Even if you don’t read assembly, you can see that there are two add instructions, one decrement, and one jump.
	It seems that the JIT hoisted the invariant sums <code>a = value1 + value2</code> and <code>b = value1 + value3</code> out of the loop and then just accumulates them.
</p>
<p>
	I also tested x86 assembly, and it looks very similar:
</p>
<div id="code-3"><p><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
</pre></td><td><pre>082E18D0:
    <span>lea</span>  ebx,[esi+edi]
    <span>add</span>  eax,ebx
    <span>lea</span>  ebx,[esi+edx]
    <span>add</span>  eax,ebx
    <span>dec</span>  ecx
    <span>jne</span>  082E18D0</pre></td></tr></tbody></table></code></p></div>
<p>
	Interestingly, the loop direction was reversed, counting down.
	This saves one instruction as comparison to zero and conditional jump can be done as one instruction.
</p>
<p>
	Now let’s look at Mono’s x64 assembly.
</p>
<div id="code-4"><p><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
</pre></td><td><pre>1E87D2F3E20:
    <span>movsxd</span>  rax,dword ptr [rsp+0C0h]
    <span>mov</span>     dword ptr [rsp+40h],eax
    <span>movsxd</span>  rax,dword ptr [rsp+0B8h]
    <span>mov</span>     dword ptr [rsp+38h],eax
    <span>movsxd</span>  rax,dword ptr [rsp+40h]
    <span>mov</span>     dword ptr [rsp+0A0h],eax
    <span>movsxd</span>  rax,dword ptr [rsp+38h]
    <span>mov</span>     dword ptr [rsp+98h],eax
    <span>movsxd</span>  rax,dword ptr [rsp+0A0h]
    <span>movsxd</span>  rcx,dword ptr [rsp+98h]
    <span>add</span>     eax,ecx
    <span>mov</span>     dword ptr [rsp+90h],0
    <span>mov</span>     dword ptr [rsp+90h],eax
    <span>mov</span>     dword ptr [rsp+30h],eax
    <span>movsxd</span>  rax,dword ptr [rsp+0A8h]
    <span>mov</span>     dword ptr [rsp+88h],eax
    <span>movsxd</span>  rax,dword ptr [rsp+30h]
    <span>mov</span>     dword ptr [rsp+80h],eax
    <span>movsxd</span>  rax,dword ptr [rsp+88h]
    <span>movsxd</span>  rcx,dword ptr [rsp+80h]
    <span>add</span>     eax,ecx
    <span>mov</span>     dword ptr [rsp+78h],0
    <span>mov</span>     dword ptr [rsp+78h],eax
    <span>mov</span>     dword ptr [rsp+0A8h],eax
    <span>mov</span>     dword ptr [rsp+28h],eax
    <span>movsxd</span>  rax,dword ptr [rsp+0C0h]
    <span>mov</span>     dword ptr [rsp+20h],eax
    <span>movsxd</span>  rax,dword ptr [rsp+0B0h]
    <span>mov</span>     dword ptr [rsp+18h],eax
    <span>movsxd</span>  rax,dword ptr [rsp+20h]
    <span>mov</span>     dword ptr [rsp+70h],eax
    <span>movsxd</span>  rax,dword ptr [rsp+18h]
    <span>mov</span>     dword ptr [rsp+68h],eax
    <span>movsxd</span>  rax,dword ptr [rsp+70h]
    <span>movsxd</span>  rcx,dword ptr [rsp+68h]
    <span>add</span>     eax,ecx
    <span>mov</span>     dword ptr [rsp+60h],0
    <span>mov</span>     dword ptr [rsp+60h],eax
    <span>mov</span>     dword ptr [rsp+10h],eax
    <span>movsxd</span>  rax,dword ptr [rsp+28h]
    <span>mov</span>     dword ptr [rsp+58h],eax
    <span>movsxd</span>  rax,dword ptr [rsp+10h]
    <span>mov</span>     dword ptr [rsp+50h],eax
    <span>movsxd</span>  rax,dword ptr [rsp+58h]
    <span>movsxd</span>  rcx,dword ptr [rsp+50h]
    <span>add</span>     eax,ecx
    <span>mov</span>     dword ptr [rsp+48h],0
    <span>mov</span>     dword ptr [rsp+48h],eax
    <span>mov</span>     dword ptr [rsp+0A8h],eax
    <span>inc</span>     esi
    <span>cmp</span>     esi,7FFFFFFFh
    <span>jl</span>      1E87D2F3E20</pre></td></tr></tbody></table></code></p></div>
<p>
	As you can see just from the number of instructions, this code will run way slower.
	The full loop of <code>int.MaxValue</code> iterations took around 11500 ms, that’s ~15x slower.
</p>
<p>
	In the assembly you can see the four add instructions in the loop, the “inefficient” increment + comparison + jump (instead of decrement + conditional jump), and most importantly a sea of mov instructions, which are just memory copies from inefficient inlining of the struct fields.
	Basically Mono is just tossing values around memory.
</p>
<p>
	I have also tested assembly compiled in Debug mode running in the Unity editor and it’s even worse.
	The full loop takes 67 seconds (67000 ms)! In Unity Editor, the JIT likely switches to far less optimized codegen and includes additional checks/sequence-point overhead, which balloons runtime.
</p>
<p>
	Takeaway: modern .NET’s JIT can scalarize tiny value types and hoist invariant work so the hot loop becomes a handful of register ops, while Mono often fails to do so and ends up shuffling values through memory, exactly the kind of gap that shows up as slowdowns in real simulation-heavy code.
</p>

	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Software engineers should be a little bit cynical (139 pts)]]></title>
            <link>https://www.seangoedecke.com/a-little-bit-cynical/</link>
            <guid>46414723</guid>
            <pubDate>Sun, 28 Dec 2025 21:29:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.seangoedecke.com/a-little-bit-cynical/">https://www.seangoedecke.com/a-little-bit-cynical/</a>, See on <a href="https://news.ycombinator.com/item?id=46414723">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><header></header><section><p>A lot of my readers <a href="https://lobste.rs/c/ch8tn0">call</a> <a href="https://news.ycombinator.com/item?id=46085088">me</a> <a href="https://news.ycombinator.com/item?id=46082989">a cynic</a> when I say things like “you should do things that <a href="https://www.seangoedecke.com/how-to-ship">make your manager happy</a>” or “big tech companies <a href="https://www.seangoedecke.com/bad-code-at-big-companies">get to decide</a> what projects you work on”. Alex Wennerberg put the “Sean Goedecke is a cynic” case well in his post <a href="https://alexwennerberg.com/blog/2025-11-28-engineering.html"><em>Software Engineers Are Not Politicians</em></a>. Here are some excerpts:</p>
<blockquote>
<p>I have no doubt that [Sean’s] advice is quite effective for navigating the upper levels of an organization dedicated to producing a large, mature software product. But what is lost is any sort of conception of value. Is it too naive to say that engineers are more than “tools in a political game”, they are specialized professionals whose role is to apply their expertise towards solving meaningful problems?</p>
</blockquote>
<blockquote>
<p>The irony is that this kind of thinking destroys a company’s ability to actually make money … the idea that engineers should begin with a self-conception of doing what their manager tells them to is, to me, very bleak. It may be a good way to operate smoothly within a bureaucratic organization, and of course, one must often make compromises and take direction, but it is a bad way to do good work.</p>
</blockquote>
<p>I can see why people would think this way. But I <em>love</em> working in big tech companies! I do see myself as a professional solving meaningful problems. And I think navigating the organization to put real features or improvements in the hands of users is an excellent way - maybe the best way - to do good work.</p>
<p>Why do I write such cynical posts, then? Well, I think that a small amount of cynicism is necessary in order to think clearly about how organizations work, and to avoid falling into the trap of being overly cynical. In general, I think <strong>good engineers ought to be a little bit cynical</strong>.</p>
<h3>The idealist view is more cynical than idealists think</h3>
<p>One doctrinaire “idealist” view of software engineering goes something like this. I’m obviously expressing it in its most lurid form, but I do think many people believe this more or less literally:<sup id="fnref-1"><a href="#fn-1">1</a></sup></p>
<blockquote>
<p>We live in a late-stage-capitalist hellscape, where large companies are run by aspiring robber barons who have no serious convictions beyond desiring power. All those companies want is for obedient engineering drones to churn out bad code fast, so they can goose the (largely fictional) stock price. Meanwhile, end-users are left holding the bag: paying more for worse software, being hassled by advertisements, and dealing with bugs that are unprofitable to fix. The only thing an ethical software engineer can do is to try and find some temporary niche where they can defy their bosses and do real, good engineering work, or to retire to a hobby farm and write elegant open-source software in their free time.</p>
</blockquote>
<p>When you write it all out, I think it’s clear to see that this is <em>incredibly</em> cynical. At the very least, it’s a cynical way to view your coworkers and bosses, who are largely people like you: doing a job, balancing a desire to do good work with the need to please their own bosses. It’s a cynical way to view the C-staff of a company. I think it’s also inaccurate: from my limited experience, the people who run large tech companies really do want to deliver good software to users.</p>
<p>It’s idealistic only in the sense that it does not accept the need for individual software engineers to compromise. According to this view, <em>you</em> never need to write bad software. No matter how hard the company tells you to compromise and just get something out, you’re morally required to plant your feet and tell them to go to hell. In fact, by doing so, you’re taking a stand against the general degeneration of the modern software world. You’re protecting - unsung, like Batman - the needs of the end-user who will never know you exist.</p>
<p>I can certainly see the appeal of this view! But I don’t think it’s an <em>idealistic</em> appeal. It comes from seeing the world as fundamentally corrupted and selfish, and believing that real positive change is impossible. In other words, <strong>I think it’s a <em>cynical</em> appeal.</strong></p>
<h3>The cynical view is more idealistic than idealists think</h3>
<p>I don’t see a hard distinction between engineers being “tools in a political game” and professionals who solve meaningful problems. In fact, I think that in practice <strong>almost all meaningful problems are solved by playing political games</strong>.</p>
<p>There are very few problems that you can solve entirely on your own. Software engineers encounter more of these problems than average, because the nature of software means that a single engineer can have huge leverage by sitting down and making a single code change. But in order to make changes to large products - for instance, to make it possible for GitHub’s 150M users to <a href="https://docs.github.com/en/get-started/writing-on-github/working-with-advanced-formatting/writing-mathematical-expressions">use LaTeX in markdown</a> - you need to coordinate with many other people at the company, which means you need to be involved in politics.</p>
<p>It is just a plain fact that software engineers are not the movers and shakers in large tech organizations. They do not set the direction of the company. To the extent that they have political influence, it’s in how they translate the direction of the company into specific technical changes. But <strong>that is actually quite a lot of influence!</strong> </p>
<p>Large tech companies serve hundreds of millions (or billions) of users. Small changes to these products can have a massive positive or negative effect in the aggregate. As I see it, choosing to engage in the messy, political process of making these changes - instead of washing your hands of it as somehow impure - is an act of idealism. </p>
<p>I think the position of a software engineer in a large tech company is similar to people who go into public service: idealistically hoping that they can do some good, despite knowing that they themselves will never set the broad strokes of government policy.</p>
<p>Of course, big-tech software engineers are paid far better, so many people who go into this kind of work in fact are purely financially-motivated cynics. But I’m not one of them! I think it’s possible, by doing good work, to help steer the giant edifice of a large tech company for the better.</p>
<h3>Cynicism as inoculation</h3>
<p>Cynical writing is like most medicines: the dose makes the poison. A healthy amount of cynicism can serve as an inoculation from being overly cynical.</p>
<p>If you don’t have an slightly cynical explanation for why engineers write bad code in large tech companies - such as the one I write about <a href="https://www.seangoedecke.com/bad-code-at-big-companies">here</a> - you risk adopting an overly cynical one. For instance, you might think that big tech engineers are being <a href="https://news.ycombinator.com/item?id=46082989">deliberately demoralized</a> as part of an anti-labor strategy to prevent them from unionizing, which is nuts. Tech companies are simply not set up to engage in these kind of conspiracies.</p>
<p>If you don’t have a slightly cynical explanation for why large tech companies sometimes make inefficient decisions - such as <a href="https://www.seangoedecke.com/seeing-like-a-software-company">this one</a> - you risk adopting an overly cynical one. For instance, you might think that tech companies are full of incompetent <a href="https://news.ycombinator.com/item?id=46133179">losers</a>, which is simply not true. Tech companies have a normal mix of strong and <a href="https://www.seangoedecke.com/weak-engineers">weak engineers</a>.</p>
<h3>Final thoughts</h3>
<p><strong>Idealist writing is massively over-represented in writing about software engineering</strong>. There is no shortage of books or blog posts (correctly) explaining that we ought to value good code, that we ought to be kind to our colleagues, that we ought to work on projects with positive real-world impact, and so on. There <em>is</em> a shortage of writing that accurately describes how big tech companies operate.</p>
<p>Of course, cynical writing can harm people: by making them sad, or turning them into bitter cynics. But <strong>idealist writing can harm people too</strong>. There’s a whole generation of software engineers who came out of the 2010s with a <em>factually incorrect</em> model of how big tech companies work, and who are effectively being fed into the woodchipper in the 2020s. They would be better off if they internalized a correct model of how these companies work: not just less likely to get into trouble, but better at achieving their own idealist goals<sup id="fnref-2"><a href="#fn-2">2</a></sup>.</p>
</section><p>If you liked this post, consider<!-- --> <a href="https://buttondown.com/seangoedecke" target="_blank">subscribing</a> <!-- -->to email updates about my new posts, or<!-- --> <a href="https://news.ycombinator.com/submitlink?u=https://www.seangoedecke.com/a-little-bit-cynical/&amp;t=Software%20engineers%20should%20be%20a%20little%20bit%20cynical" target="_blank">sharing it on Hacker News</a>.<!-- --> Here's a preview of a related post that shares tags with this one.</p><blockquote><p>You can't design software you don't work on</p><div><p>Only the engineers who work on a large software system can meaningfully participate in the design process. That’s because you cannot do good software design without an intimate understanding of the concrete details of the system. In other words, <strong>generic software design advice is typically useless</strong> for most practical software design problems.</p><p>What is generic software design? It’s “designing to the problem”: the kind of advice you give when you have a reasonable understanding of the <em>domain</em>, but very little knowledge of the existing <em>codebase</em>. Unfortunately, this is the only kind of advice you’ll read in software books and blog posts. Engineers love giving generic software design advice for the same reason that all technical professionals love “talking shop”. However, you should be very careful about applying generic advice to your concrete day-to-day work problems.<br><a href="https://www.seangoedecke.com/you-cant-design-software-you-dont-work-on/">Continue reading...</a></p></div></blockquote><hr></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[MongoBleed Explained Simply (145 pts)]]></title>
            <link>https://bigdata.2minutestreaming.com/p/mongobleed-explained-simply</link>
            <guid>46414475</guid>
            <pubDate>Sun, 28 Dec 2025 21:03:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bigdata.2minutestreaming.com/p/mongobleed-explained-simply">https://bigdata.2minutestreaming.com/p/mongobleed-explained-simply</a>, See on <a href="https://news.ycombinator.com/item?id=46414475">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p><strong>MongoBleed, </strong><span>officially CVE-2025-14847, is a recently-uncovered extremely sensitive vulnerability affecting basically all versions of MongoDB since </span><strong>~2017</strong><span>.</span></p><p><span>It is a bug in the </span><strong><span>zlib</span><span data-state="closed"><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1-182764771" href="https://bigdata.2minutestreaming.com/p/mongobleed-explained-simply#footnote-1-182764771" target="_self" rel="">1</a></span></strong><span> message compression path in MongoDB.</span></p><p><span>It allows an attacker to read off any uninitialized heap memory, meaning </span><em><strong>anything</strong></em><span> that was allocated to memory from a previous database operation could be read.</span></p><p><span>The bug was introduced in 2017</span><span data-state="closed"><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-2-182764771" href="https://bigdata.2minutestreaming.com/p/mongobleed-explained-simply#footnote-2-182764771" target="_self" rel="">2</a></span><span>. It is dead-easy to exploit - it only requires connectivity to the database (no auth needed). It is fixed as of writing, but some EOL versions (3.6, 4.0, 4.2) will not get it.</span></p><p>Let’s get a few basics out of the way before we explain the bug:</p><ul><li><p>MongoDB uses its own TCP wire protocol instead of e.g HTTP. This is standard for databases, especially ones chasing high performance.</p></li><li><p><span>Mongo uses the </span><a href="https://en.wikipedia.org/wiki/BSON" rel="">BSON</a><span> format for messages</span><span data-state="closed"><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-3-182764771" href="https://bigdata.2minutestreaming.com/p/mongobleed-explained-simply#footnote-3-182764771" target="_self" rel="">3</a></span><span>. It’s basically binary json but with some key optimizations. We will talk about one later because it is essential to the exploit.</span></p></li><li><p>Mongo doesn’t have endpoints or RPCs. It only uses a single op code called OP_MSG.</p></li><li><p><span>The OP_MSG command contains a BSON message. The contents of the message denote what type of request it is. Concretely, it’s the first field of the message that marks the request type. </span><span data-state="closed"><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-4-182764771" href="https://bigdata.2minutestreaming.com/p/mongobleed-explained-simply#footnote-4-182764771" target="_self" rel="">4</a></span></p></li><li><p><span>The request can be compressed. In that case, an OP_COMPRESSED message is sent</span><a href="https://www.mongodb.com/docs/manual/reference/mongodb-wire-protocol#op_compressed" rel=""> which wraps</a><span> the now-compressed OP_MSG BSON.</span></p></li><li><p>The request then looks like this:</p></li></ul><pre><code>     OP_COMPRESSED message
┌────────────────────────────┐
│ standard header (16 bytes) │
├────────────────────────────┤
│ originalOpcode (int32)     │
│ uncompressedSize (int32)   │
│ compressorId (int8)        │
│ compressed OP payload      │
└────────────────────────────┘</code></pre><ul><li><p><span>Critically, the </span><code>uncompressedSize</code><span> field denotes how large the payload is once it’s uncompressed.</span></p></li></ul><p>The first part of the exploit is to get the server to wrongfully think that an overly-large OP_MSG is coming.</p><p><span>An attacker can send a falsefully large </span><code>`uncompressedSize`</code><span> field, say 1MB</span><span data-state="closed"><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-5-182764771" href="https://bigdata.2minutestreaming.com/p/mongobleed-explained-simply#footnote-5-182764771" target="_self" rel="">5</a></span><span>, when in reality the underlying message is 1KB uncompressed. </span></p><p><span>This will make the server</span><strong> allocate a 1MB buffer</strong><span> in memory to decompress the message into. This is fine.</span></p><p>The critical bug here is that, once finished decompressing, the server does NOT check the actual resulting size of the newly-uncompressed payload.</p><p><span>Instead, it trusts the user’s input and uses that as the canonical size of the payload, even if it got a different number.</span><span data-state="closed"><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-6-182764771" href="https://bigdata.2minutestreaming.com/p/mongobleed-explained-simply#footnote-6-182764771" target="_self" rel="">6</a></span><span> </span></p><p>The result is an in-memory representation of the BSON message which looks something like this:</p><pre><code>[ 1KB of REAL DATA |      999KB of UNREFERENCED HEAP GARBAGE       ]
                   ↑                                               ↑
        actual length (1KB)                     user input length (1MB)</code></pre><p>Like in every programming language, when a variables in the code goes out of scope, the runtime marks the memory it previously took up as available.</p><p>In most modern languages, the memory gets zeroed out. In other words, the old bytes that used to take up the space get deleted.</p><p><span>In C/C++, this doesn’t happen. When you allocate memory via </span><code>`malloc()`</code><span>, you get whatever was previously there.</span></p><p>Since Mongo is writen in C++, that unreferenced heap garbage part can represent anything that was in memory from previous operations, including:</p><ul><li><p>Cleartext passwords and credentials</p></li><li><p>Session tokens / API keys</p></li><li><p>Customer data and PII</p></li><li><p>Database configs and system info</p></li><li><p>Docker paths and client IP addresses</p></li></ul><pre><code>[ REAL BSON DATA | password: 123 | apiKey: jA2sa | ip: 219.117.127.202 ]</code></pre><p>Now that the server has wrongfully allocated some potentially-sensitive data to the input message, the only thing left for the attacker is to somehow get the server return the data.</p><p><span>As mentioned, BSON is Mongo’s way of serializing JSON. </span><a href="https://bsonspec.org/" rel="">As mentioned on its site</a><span>, it was designed with efficiency in mind:</span></p><blockquote><h3><strong>3. Efficient</strong></h3><p><span>En­cod­ing data to BSON and de­cod­ing from BSON can be per­formed very quickly in most lan­guages due to </span><strong>the use of C data types</strong><span>.</span></p></blockquote><p><span>C famously uses </span><strong>null-terminated</strong><span> </span><strong>strings</strong><span data-state="closed"><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-7-182764771" href="https://bigdata.2minutestreaming.com/p/mongobleed-explained-simply#footnote-7-182764771" target="_self" rel="">7</a></span><span>. A null-terminated string means that a null byte is used to mark the end of the string:</span></p><pre><code><span>char* s = "hello"
// in memory, this is represented as an array of characters with the last element being the null terminator: h e l l o </span><strong>\0</strong></code></pre><p>The way such strings get parsed is very simple - the deserializer reads every character until it finds a null terminator.</p><p>If you recall, I said earlier that the first field of the BSON message denotes what type of “RPC” the command is.</p><p>As such, the first thing a server does when handling an incoming message over the wire is… parse the first field!</p><p>Because fields are strings, and strings are null-terminated CStrings, the deserializing logic in the MongoDB server parses the field until the first null terminator found.</p><p><span>An attacker can send a compressed, invalid BSON object that does NOT contain a null terminator. This forces the server to continue scanning through foreign data in the wrongly-allocated memory buffer until it finds the first null terminator (</span><strong>\0</strong><span>)</span></p><pre><code><code># Conceptual
[ REAL DATA |             UNREFERENCED HEAP GARBAGE                 ]
# Practical Example
[ { "a      | password: 123\0 | apiKey: jA2sa | ip: 219.117.127.202 ]</code></code></pre><p>As the first null terminator is right after the password, the server would now think that the first field of the BSON is:</p><pre><code>"a      | password: 123"</code></pre><p>Obviously that is an invalid BSON field, so the server responds with an error to the client. In order to be helpful, the response contains an error message that shows which field was invalid:</p><pre><code><span>{
  "ok": 0,
  "errmsg": "invalid BSON field name 'a      | </span><strong>password: 123</strong><span>'",
  "code": 2,
  "codeName": "BadValue"
}</span></code></pre><p>Boom. The attacker successfully got the server to leak data to it.</p><p>Any serious attacker would then run this over and over again, thousands of time a second, until they believe they’ve scanned the majority of the database’s heap. They can then repeat this ad infinitum.</p><p><span>The impact of this is particularly nasty, because the request-response parsing cycle happens </span><strong>before any authentication can be made</strong><span>. This makes sense, since you cannot begin to authenticate a request you still haven’t deserialized.</span></p><p><span>This allows </span><strong>any</strong><span> attacker to gain access to </span><strong>any</strong><span> piece of potentially-sensitive data. The only thing they need is internet access to the database.</span></p><p><span>Exposing your database to the internet is a practice that’s heavily frowned upon</span><span data-state="closed"><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-8-182764771" href="https://bigdata.2minutestreaming.com/p/mongobleed-explained-simply#footnote-8-182764771" target="_self" rel="">8</a></span><span>. At the same time, Shodan shows that there are over </span><a href="https://www.shodan.io/search?query=Product%3A%22MongoDB%22" rel="">213,000 publicly-accessible Mongo databases</a><span>.</span></p><p><span>The PR that introduced the bug was from </span><a href="https://github.com/mongodb/mongo/pull/1152" rel="">May 2017</a><span>. This means that, roughly from version 3.6.0, any publicly-accessible MongoDB instance has been vulnerable to this.</span></p><p>It is unknown whether the exploit was known and exploited by actors prior to its disclosure. Given the simplicity of it, I bet it was.</p><p>As of the exploit’s disclosure, which happened on 19th of December, it has been a race to patch the database.</p><p><span>Sifting through Git history, it seems like the fix was initially committed on </span><a href="https://api.github.com/repos/mongodb/mongo/commits/505b660a14698bd2b5233bd94da3917b585c5728" rel="">the 17th of December</a><span>. Interestingly enough, it was only merged a full 5 days after - </span><a href="https://github.com/mongodb/mongo/commit/505b660a14698bd2b5233bd94da3917b585c5728#diff-e5f6e2daef81ce1c3c4e9f7d992bd6ff9946b3b4d98a601e4d9573e5ef0cb07dR77" rel="">on the 22nd of December</a><span> (1-line fix btw).</span></p><p><span>That beig said, MongoDB 8.0.17 containing the fix </span><a href="https://www.mongodb.com/docs/manual/release-notes/8.0/?utm_source=chatgpt.com#8.0.17---dec-19--2025" rel="">was released on Dec 19</a><span>, consistent with the CVE publish data. But JIRA activity shows that patches went out on </span><a href="https://jira.mongodb.org/browse/SERVER-115508" rel="">the 22nd of December</a><span>.</span></p><p><span>Because there’s no official timeline posted, members of the community like me have to guess. As of writing, 10 days later in Dec 28, 2025, Mongo have </span><a href="https://www.mongodb.com/company/blog" rel="">still NOT properly addressed the issue publicly</a><span>.</span></p><p><span>They only issued </span><a href="https://www.mongodb.com/community/forums/t/important-mongodb-patch-available/332977" rel="">a community disclosure</a><span> of the CVE </span><strong>a full five days</strong><span> after the publication of it. It is then, on the 24th of December, that they announced that all of their database instances in their cloud service Atlas were fully patched.</span></p><p>I believe this implies that all Atlas databases exposed to the internet were vulnerable to this issue for almost a week. By default, Atlas databases use an IP allowlist for connectivity. But users could configure it to allow connections from anywhere.</p><p> Mongo says that they haven’t verified exploitation so far:</p><blockquote><p>“at this time, we have no evidence that this issue has been exploited or that any customer data has been compromised”</p></blockquote><p>Mitigation is admittedly very easy, you have one of two choices:</p><ol><li><p>Update to the newest patch</p></li><li><p><span>Disable </span><a href="https://feed.yopp.me/@alex/115787980028314032" rel="">zlib network compression</a></p></li></ol><p>I found the latter wasn’t circulated a lot in online talk, but I understand is just as good as a short-term mitigation.</p><p><span>The tech lead for Security at Elastic coined the name MongoBleed by posting a Python script that acts as a proof of concept to exploiting the vulnerability: </span><a href="https://github.com/joe-desimone/mongobleed" rel="">https://github.com/joe-desimone/mongobleed</a></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!USk9!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8c4b36c-c9bb-4fa1-b454-8a489b1433ab_1170x706.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!USk9!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8c4b36c-c9bb-4fa1-b454-8a489b1433ab_1170x706.png 424w, https://substackcdn.com/image/fetch/$s_!USk9!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8c4b36c-c9bb-4fa1-b454-8a489b1433ab_1170x706.png 848w, https://substackcdn.com/image/fetch/$s_!USk9!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8c4b36c-c9bb-4fa1-b454-8a489b1433ab_1170x706.png 1272w, https://substackcdn.com/image/fetch/$s_!USk9!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8c4b36c-c9bb-4fa1-b454-8a489b1433ab_1170x706.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!USk9!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8c4b36c-c9bb-4fa1-b454-8a489b1433ab_1170x706.png" width="528" height="318.6051282051282" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b8c4b36c-c9bb-4fa1-b454-8a489b1433ab_1170x706.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:706,&quot;width&quot;:1170,&quot;resizeWidth&quot;:528,&quot;bytes&quot;:176674,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://bigdata.2minutestreaming.com/i/182764771?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8c4b36c-c9bb-4fa1-b454-8a489b1433ab_1170x706.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/$s_!USk9!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8c4b36c-c9bb-4fa1-b454-8a489b1433ab_1170x706.png 424w, https://substackcdn.com/image/fetch/$s_!USk9!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8c4b36c-c9bb-4fa1-b454-8a489b1433ab_1170x706.png 848w, https://substackcdn.com/image/fetch/$s_!USk9!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8c4b36c-c9bb-4fa1-b454-8a489b1433ab_1170x706.png 1272w, https://substackcdn.com/image/fetch/$s_!USk9!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8c4b36c-c9bb-4fa1-b454-8a489b1433ab_1170x706.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>https://cyberplace.social/@GossiTheDog/115786817774728155</figcaption></figure></div><a href="https://x.com/dez_/status/2004351287715156023?s=20" target="_blank" rel="noopener noreferrer" data-component-name="Twitter2ToDOM"><div data-attrs="{&quot;url&quot;:&quot;https://x.com/dez_/status/2004351287715156023?s=20&quot;,&quot;full_text&quot;:&quot;🎅mongobleed - poc for CVE-2025-14847. Leaks data from mongodb instances due to flaw in zlib message decompression.  Reminiscent of heartbleed ❤️ &quot;,&quot;username&quot;:&quot;dez_&quot;,&quot;name&quot;:&quot;Joe Desimone&quot;,&quot;profile_image_url&quot;:&quot;https://pbs.substack.com/profile_images/1350629165633036293/WMZ3Dd9C_normal.jpg&quot;,&quot;date&quot;:&quot;2025-12-26T00:39:20.000Z&quot;,&quot;photos&quot;:[{&quot;img_url&quot;:&quot;https://pbs.substack.com/media/G9DitlgXEAI-h2z.png&quot;,&quot;link_url&quot;:&quot;https://t.co/bsxIs6g0oK&quot;}],&quot;quoted_tweet&quot;:{},&quot;reply_count&quot;:11,&quot;retweet_count&quot;:109,&quot;like_count&quot;:554,&quot;impression_count&quot;:68569,&quot;expanded_url&quot;:null,&quot;video_url&quot;:null,&quot;belowTheFold&quot;:true}"><div><div title="User"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!PzDh!,w_40,h_40,c_fill,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fpbs.substack.com%2Fprofile_images%2F1350629165633036293%2FWMZ3Dd9C.jpg 40w, https://substackcdn.com/image/fetch/$s_!PzDh!,w_80,h_80,c_fill,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fpbs.substack.com%2Fprofile_images%2F1350629165633036293%2FWMZ3Dd9C.jpg 80w, https://substackcdn.com/image/fetch/$s_!PzDh!,w_120,h_120,c_fill,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fpbs.substack.com%2Fprofile_images%2F1350629165633036293%2FWMZ3Dd9C.jpg 120w" sizes="40px"><img src="https://substackcdn.com/image/fetch/$s_!PzDh!,w_40,h_40,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fpbs.substack.com%2Fprofile_images%2F1350629165633036293%2FWMZ3Dd9C.jpg" sizes="40px" alt="X avatar for @dez_" srcset="https://substackcdn.com/image/fetch/$s_!PzDh!,w_40,h_40,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fpbs.substack.com%2Fprofile_images%2F1350629165633036293%2FWMZ3Dd9C.jpg 40w, https://substackcdn.com/image/fetch/$s_!PzDh!,w_80,h_80,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fpbs.substack.com%2Fprofile_images%2F1350629165633036293%2FWMZ3Dd9C.jpg 80w, https://substackcdn.com/image/fetch/$s_!PzDh!,w_120,h_120,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fpbs.substack.com%2Fprofile_images%2F1350629165633036293%2FWMZ3Dd9C.jpg 120w" width="40" height="40" draggable="false" loading="lazy"></picture></div><p><span>Joe Desimone</span><span>@dez_</span></p><svg role="img" style="height:20px;width:20px;" width="20" height="20" viewBox="0 0 20 20" fill="var(--color-fg-primary)" stroke-width="1.8" stroke="#000" xmlns="http://www.w3.org/2000/svg"><g><title></title><path stroke="none" fill-rule="evenodd" clip-rule="evenodd" d="M13.2879 19.1666L8.66337 12.575L2.87405 19.1666H0.424805L7.57674 11.0258L0.424805 0.833252H6.71309L11.0717 7.04577L16.5327 0.833252H18.982L12.1619 8.59699L19.5762 19.1666H13.2879ZM16.0154 17.3083H14.3665L3.93176 2.69159H5.58092L9.7601 8.54422L10.4828 9.55981L16.0154 17.3083Z"></path></g></svg></div><p>🎅mongobleed - poc for CVE-2025-14847. Leaks data from mongodb instances due to flaw in zlib message decompression.  Reminiscent of heartbleed ❤️ </p><p><img src="https://pbs.substack.com/media/G9DitlgXEAI-h2z.png" loading="lazy"></p><div><p><span>12:39 AM · Dec 26, 2025</span><span> · </span><span>68.6K Views</span></p><p><span>11 Replies</span><span> · </span><span>109 Reposts</span><span> · </span><span>554 Likes</span></p></div></div></a><p><span>This is particularly interesting, because despite being different systems, Mongo competes with Elastic on </span><a href="https://www.mongodb.com/products/platform/atlas-vector-search" rel="">Vector Search</a><span>, </span><a href="https://www.mongodb.com/products/platform/atlas-search" rel="">Text Search</a><span> and </span><a href="https://www.mongodb.com/solutions/use-cases/analytics" rel="">Analytical</a><span> use cases.</span></p><ul><li><p>The exploit allows attackers to read arbitrary heap data, including user data, plaintext passwords, api keys/secrets, and more.</p></li><li><p>It is performed by leveraging a simple, malformed zlib-compressed request.</p></li><li><p>MongoDB versions from 2017-2025 are vulnerable to this exploit.</p></li><li><p>Rough timeline:</p><ul><li><p><span>June 1, 2017: </span><a href="https://github.com/mongodb/mongo/commit/85d4a3a085c67f2258b60b07259db73e2f29ea50" rel="">Commit introducing the bug</a><span> gets merged.</span></p></li><li><p><span>Dec 17, 2025: Code for the fix is written (</span><a href="https://api.github.com/repos/mongodb/mongo/commits/505b660a14698bd2b5233bd94da3917b585c5728" rel="">original commit date</a><span>).</span></p></li><li><p><span>Dec 19, 2025: CVE </span><a href="https://www.cve.org/CVERecord?id=CVE-2025-14847" rel="">officially published</a><span>.</span></p></li><li><p><span>Dec 22, 2025: Code with the fix </span><em><a href="https://github.com/mongodb/mongo/commit/505b660a14698bd2b5233bd94da3917b585c5728" rel="">is merged</a></em><span>.</span></p></li><li><p><span>Dec 24, 2025: MongoDB </span><a href="https://www.mongodb.com/community/forums/t/important-mongodb-patch-available/332977" rel="">announce the patch</a><span>, say all Atlas databases are patched.</span></p></li></ul></li><li><p>On Dec 24th, MongoDB reported they have no evidence of anybody exploiting the CVE. Given the fact this exploit lived on for ~8 years, and their honey-pot cloud service Atlas took a full 5 days to patch since the official CVE publish date… I find that hard to believe.</p></li><li><p>MongoDB have not apologized yet.</p></li><li><p><span>There are </span><a href="https://www.shodan.io/search?query=Product%3A%22MongoDB%22" rel="">over 213k+</a><span> potentially vulnerable internet-exposed MongoDB instances, ensuring that this exploit is </span><strong>web scale</strong><span>:</span></p></li></ul><div id="youtube2-b2F-DItXtZs" data-attrs="{&quot;videoId&quot;:&quot;b2F-DItXtZs&quot;,&quot;startTime&quot;:null,&quot;endTime&quot;:null}" data-component-name="Youtube2ToDOM"><p><iframe src="https://www.youtube-nocookie.com/embed/b2F-DItXtZs?rel=0&amp;autoplay=0&amp;showinfo=0&amp;enablejsapi=0" frameborder="0" loading="lazy" gesture="media" allow="autoplay; fullscreen" allowautoplay="true" allowfullscreen="true" width="728" height="409"></iframe></p></div><ul><li><p><span>Official CVE: </span><a href="https://nvd.nist.gov/vuln/detail/CVE-2025-14847" rel="">https://nvd.nist.gov/vuln/detail/CVE-2025-14847</a><span> (Dec 19, 2025)</span></p></li><li><p><span>PR introducing the bug: </span><a href="https://github.com/mongodb/mongo/pull/1152" rel="">https://github.com/mongodb/mongo/pull/1152</a><span> (May 2017)</span></p></li><li><p><span>Commit fixing the issue: </span><a href="https://github.com/mongodb/mongo/commit/505b660a14698bd2b5233bd94da3917b585c5728#diff-e5f6e2daef81ce1c3c4e9f7d992bd6ff9946b3b4d98a601e4d9573e5ef0cb07dR77" rel="">https://github.com/mongodb/mongo/commit/505b660a14698bd2b5233bd94da3917b585c5728#diff-e5f6e2daef81ce1c3c4e9f7d992bd6ff9946b3b4d98a601e4d9573e5ef0cb07dR77</a></p></li><li><p><span>Security Report on the incident, including fix versions: </span><a href="https://www.ox.security/blog/attackers-could-exploit-zlib-to-exfiltrate-data-cve-2025-14847/" rel="">https://www.ox.security/blog/attackers-could-exploit-zlib-to-exfiltrate-data-cve-2025-14847/</a></p></li><li><p><span>Write-up on how to detect exploitation attempts via log analysis:  </span><a href="https://blog.ecapuano.com/p/hunting-mongobleed-cve-2025-14847" rel="">https://blog.ecapuano.com/p/hunting-mongobleed-cve-2025-14847</a></p></li><li><p><span>Somebody also vibe-coded a detector: </span><a href="https://github.com/Neo23x0/mongobleed-detector" rel="">https://github.com/Neo23x0/mongobleed-detector</a></p></li></ul><div data-component-name="DigestPostEmbed"><a href="https://bigdata.2minutestreaming.com/p/how-aws-s3-scales-with-tens-of-millions-of-hard-drives" rel="noopener" target="_blank"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!CqEG!,w_140,h_140,c_fill,f_webp,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2c663f78-f119-45d7-83e8-fb4268dae83f_1456x1048.png"><img src="https://substackcdn.com/image/fetch/$s_!CqEG!,w_140,h_140,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2c663f78-f119-45d7-83e8-fb4268dae83f_1456x1048.png" sizes="100vw" alt="how AWS S3 serves 1 petabyte per second on top of slow HDDs" width="140" height="140"></picture></div></a></div><div data-component-name="DigestPostEmbed"><a href="https://bigdata.2minutestreaming.com/p/event-streaming-is-topping-out" rel="noopener" target="_blank"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!2QUZ!,w_140,h_140,c_fill,f_webp,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc9bd8bb2-f073-4e43-8ad5-e2446470645d_1456x816.png"><img src="https://substackcdn.com/image/fetch/$s_!2QUZ!,w_140,h_140,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc9bd8bb2-f073-4e43-8ad5-e2446470645d_1456x816.png" sizes="100vw" alt="Event Streaming is Topping Out" width="140" height="140"></picture></div></a></div><div data-component-name="DigestPostEmbed"><a href="https://bigdata.2minutestreaming.com/p/why-was-apache-kafka-created" rel="noopener" target="_blank"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!EmZj!,w_140,h_140,c_fill,f_webp,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84290a14-c8e4-4bd7-b10c-03dfe7793d37_1200x630.png"><img src="https://substackcdn.com/image/fetch/$s_!EmZj!,w_140,h_140,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84290a14-c8e4-4bd7-b10c-03dfe7793d37_1200x630.png" sizes="100vw" alt="Why Was Apache Kafka Created?" width="140" height="140"></picture></div></a></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Stepping down as Mockito maintainer after 10 years (238 pts)]]></title>
            <link>https://github.com/mockito/mockito/issues/3777</link>
            <guid>46414078</guid>
            <pubDate>Sun, 28 Dec 2025 20:14:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/mockito/mockito/issues/3777">https://github.com/mockito/mockito/issues/3777</a>, See on <a href="https://news.ycombinator.com/item?id=46414078">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-testid="markdown-body" data-team-hovercards-enabled="true" data-turbolinks="false"><p dir="auto">In March 2026, I will be Mockito maintainer for 10 years (nearly a third of my whole life). Looking ahead, I decided that a decade milestone is a good moment to pass on maintainership to other folks. In the coming months until March, I will spend time ensuring a smooth transition in maintainership.</p>
<p dir="auto">In this issue I list several considerations why I made the decision. Communication and discussion of plans for future maintainership will be somewhere else, most likely in a separate GitHub issue. Stay tuned for that.</p>
<h2 dir="auto">Energy drain because of JVM agent change</h2>
<p dir="auto">As you might know, Mockito 5 shipped a breaking change where its main artifact is now an agent. That's because starting JVM 22, the previous so-called "dynamic attachment of agents" is put behind a flag. This change makes sense from a security point-of-view and I support it.</p>
<p dir="auto">However, the way this was put forward to Mockito maintainers was energy draining to say the least. Mockito is probably the biggest user of such an agent and is often looked at for inspiration by other projects. As such, Mockito often pioneers on supporting JVM features, built on a solid foundation with ByteBuddy. Modules was such a feature that took months of hard work by Rafael to figure out, including providing feedback to JVM maintainers.</p>
<p dir="auto">Unfortunately such a collaborative way of working was not the case when discussing agents. To me, it felt like the feature was presented as a done deal because of security. While dynamic attachment is problematic in many ways, no alternative solutions were proposed. That's okay, as Mockito pioneers on these solutions, yet in this case I felt we were left alone.</p>
<p dir="auto">My personal take is that folks involved with the change severely underestimated the societal impact that it had. The fact that proper build support is non-existent to this day shows that agents are not a priority. That's okay if it isn't a priority, but when it was communicated with Mockito I perceived it as "Mockito is holding the JVM ecosystem back by using dynamic attachment, please switch immediately and figure it out on your own".</p>
<p dir="auto">Here, the fact that I (and others) are volunteers doing their best for the project, is important to understand the societal impact. When you put individuals under pressure, who do this work in their own time out of goodwill, things crumble. It's commonly joked about with XKCD's on the fact that the whole open source world relies on a couple of individuals. That couldn't be more true in this situation, where the collaborative system collapses when too much pressure is put on individual folks.</p>
<p dir="auto">This saga planted the seed to reconsider my position as maintainer.</p>
<h2 dir="auto">Kotlin as the future and odd one out</h2>
<p dir="auto">It's undeniable that Kotlin as a language has grown in popularity in recent years. While Mockito maintains several flavors for JVM languages, these packages typically include sugar that makes integration nicer. In all cases, mockito-core remains the place where functionality is implemented.</p>
<p dir="auto">Unfortunately, this model doesn't nicely apply to Kotlin. Where almost all JVM languages work similarly under the hood, Kotlin often does things differently. This means that in several places in mockito-core, there are separate flows dedicated to Kotlin. Most often that's a direct result of Kotlin doing (in my opinion) shenanigans on the JVM that the JVM never intended to support, yet was able to.</p>
<p dir="auto">Even within Kotlin itself, features don't work consistently. Suspend functions are the most well-known example. As such, Mockito code becomes more spaghetti, it's API sometimes fully duplicated just to support a core Kotlin language feature and overall less maintainable.</p>
<p dir="auto">While I fully understand the reasons that developers enjoy the feature richness of Kotlin as a programming language, its underlying implementation has significant downsides for projects like Mockito. Quite frankly, it's not fun to deal with.</p>
<p dir="auto">To me, a future where Kotlin becomes more predominant is not a future that makes me hopeful I can keep on dedicating energy to Mockito.</p>
<h2 dir="auto">Alternative open source activities</h2>
<p dir="auto">I have always been a fan of open source work and have contributed to hundreds of projects in all these years. Mockito is my most important project, but I have also consistently worked on others. In recent months, I have rediscovered the joy of programming by working on Servo. It's a web engine written in Rust.</p>
<p dir="auto">When I need to choose how I want to spend my 2 hours of evening time in a given week, I rarely preferred Mockito in the last year. In the past, Mockito was my go-to and I enjoyed it a lot. Nowadays, Servo and related projects provide significantly more enjoyment.</p>
<p dir="auto">Justifying why I needed to work on Mockito becomes difficult when (because of the above reasons) it feels like a chore. Volunteering work shouldn't feel like a chore, at least not for a long time.</p>
<h2 dir="auto">Summing it up</h2>
<p dir="auto">As you have read, these three factors combined led me to the decision. The first point explains why I started to doubt my position, the second point why I am not hopeful for things to change in a good way and the third point how I found enjoyment in a different way.</p>
<p dir="auto">While these points had impact on me as maintainer, my hypothesis is that it doesn't apply to others in the same way. I know others are eager to work on Kotlin support for example. That's why I concluded that a decade is enough time to have helped Mockito forward. Now it's time for somebody else to take over, as I believe that's in the best interest of Mockito as a project. Because ultimately that's why I chose to become maintainer in the first place: I believed that with my work, I could improve Mockito for millions of software engineers.</p>
<p dir="auto">For those wondering: yes I wholeheartedly advise everyone to take on a volunteering task such as maintaining an open source project. It was an honour and privilege to do so and I thank those that I enjoyed working with.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[PySDR: A Guide to SDR and DSP Using Python (152 pts)]]></title>
            <link>https://pysdr.org/content/intro.html</link>
            <guid>46413975</guid>
            <pubDate>Sun, 28 Dec 2025 20:02:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pysdr.org/content/intro.html">https://pysdr.org/content/intro.html</a>, See on <a href="https://news.ycombinator.com/item?id=46413975">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="introduction" role="main">
<h2><span>1. </span>Introduction<a href="#introduction" title="Permalink to this headline">¶</a></h2>
<div id="purpose-and-target-audience">
<h2>Purpose and Target Audience<a href="#purpose-and-target-audience" title="Permalink to this headline">¶</a></h2>
<p>First and foremost, a couple important terms:</p>
<dl>
<dt><strong>Software-Defined Radio (SDR):</strong></dt><dd><p>As a <em>concept</em> it refers to using software to perform signal processing tasks that were traditionally performed by hardware, specific to radio/RF applications.  This software can be run on a general-purpose computer (CPU), FPGA, or even GPU, and it can be used for real-time applications or offline processing of recorded signals.  Analogous terms include “software radio” and “RF digital signal processing”.</p>
<p>As a <em>thing</em> (e.g., “an SDR”) it typically refers to a device that you can plug an antenna into and receive RF signals, with the digitized RF samples being sent to a computer for processing or recording (e.g., over USB, Ethernet, PCI).  Many SDRs also have transmit capabilities, allowing the computer to send samples to the SDR which then transmits the signal at a specified RF frequency.  Some embedded-style SDRs include an onboard computer.</p>
</dd>
<dt><strong>Digital Signal Processing (DSP):</strong></dt><dd>The digital processing of signals; in our case, RF signals.</dd>
</dl>
<p>This textbook acts as a hands-on introduction to the areas of DSP, SDR, and wireless communications.  It is designed for someone who is:</p>
<ol>
<li>Interested in <em>using</em> SDRs to do cool stuff</li>
<li>Good with Python</li>
<li>Relatively new to DSP, wireless communications, and SDR</li>
<li>A visual learner, preferring animations over equations</li>
<li>Better at understanding equations <em>after</em> learning the concepts</li>
<li>Looking for concise explanations, not a 1,000 page textbook</li>
</ol>
<p>An example is a Computer Science student interested in a job involving wireless communications after graduation, although it can be used by anyone itching to learn about SDR who has programming experience.  As such, it covers the necessary theory to understand DSP techniques without the intense math that is usually included in DSP courses.  Instead of burying ourselves in equations, an abundance of images and animations are used to help convey the concepts, such as the Fourier series complex plane animation below.  I believe that equations are best understood <em>after</em> learning the concepts through visuals and practical exercises.  The heavy use of animations is why PySDR will never have a hard copy version being sold on Amazon.</p>
<p><a href="https://pysdr.org/_images/fft_logo_wide.gif"><img alt="The PySDR logo created using a Fourier transform" src="https://pysdr.org/_images/fft_logo_wide.gif"></a></p><p>This textbook is meant to introduce concepts quickly and smoothly, enabling the reader to perform DSP and use SDRs intelligently.  It’s not meant to be a reference textbook for all DSP/SDR topics; there are plenty of great textbooks already out there, such as <a href="https://www.analog.com/en/education/education-library/software-defined-radio-for-engineers.html" rel="noopener noreferrer" target="_blank">Analog Device’s SDR textbook</a> and <a href="http://www.dspguide.com/" rel="noopener noreferrer" target="_blank">dspguide.com</a>.  You can always use Google to recall trig identities or the Shannon limit.  Think of this textbook like a gateway into the world of DSP and SDR: it’s lighter and less of a time and monetary commitment, when compared to more traditional courses and textbooks.</p>
<p>To cover foundational DSP theory, an entire semester of “Signals and Systems”, a typical course within electrical engineering, is condensed into a few chapters.  Once the DSP fundamentals are covered, we launch into SDRs, although DSP and wireless communications concepts continue to come up throughout the textbook.</p>
<p>Code examples are provided in Python.  They utilize NumPy, which is Python’s standard library for arrays and high-level math.  The examples also rely upon Matplotlib, which is a Python plotting library that provides an easy way to visualize signals, arrays, and complex numbers.  Note that while Python is “slower” than C++ in general, most math functions within Python/NumPy are implemented in C/C++ and heavily optimized.  Likewise, the SDR API we use is simply a set of Python bindings for C/C++ functions/classes.  Those who have little Python experience yet a solid foundation in MATLAB, Ruby, or Perl will likely be fine after familiarizing themselves with Python’s syntax.</p>
</div>
<div id="contributing">
<h2>Contributing<a href="#contributing" title="Permalink to this headline">¶</a></h2>
<p>If you got value from PySDR, please share it with colleagues, students, and other lifelong learners who may be interested in the material.  You can also donate through the <a href="https://www.patreon.com/PySDR" rel="noopener noreferrer" target="_blank">PySDR Patreon</a> as a way to say thanks and get your name on the left of every page below the chapter list.</p>
<p>If you get through any amount of this textbook and email me at <a href="https://pysdr.org/cdn-cgi/l/email-protection#e28f839081c4c1d1d5d9c4c1d7d0d9c4c1d6dad9929b918690c4c1d6d4d98d9085" rel="noopener noreferrer" target="_blank">marc<span>@</span>pysdr<span>.</span>org</a> with questions/comments/suggestions, then congratulations, you will have contributed to this textbook!  You can also edit the source material directly on the <a href="https://github.com/777arc/PySDR/tree/master/content" rel="noopener noreferrer" target="_blank">textbook’s GitHub page</a> (your change will start a new pull request).  Feel free to submit an issue or even a Pull Request (PR) with fixes or improvements.  Those who submit valuable feedback/fixes will be permanently added to the acknowledgments section below.  Not good at Git but have changes to suggest?  Feel free to email me at <a href="https://pysdr.org/cdn-cgi/l/email-protection#3c515d4e5f1a1f0f0b071a1f090e071a1f0804074c454f584e1a1f080a07534e5b" rel="noopener noreferrer" target="_blank">marc<span>@</span>pysdr<span>.</span>org</a>.</p>
</div>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[No, it's not a battleship (121 pts)]]></title>
            <link>https://www.navalgazing.net/No-its-not</link>
            <guid>46413790</guid>
            <pubDate>Sun, 28 Dec 2025 19:41:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.navalgazing.net/No-its-not">https://www.navalgazing.net/No-its-not</a>, See on <a href="https://news.ycombinator.com/item?id=46413790">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>This week has seen the announcement by the Trump Administration that they are going to be building "battleships", a subject that is well within my beat, so I figured I would take the time to start by saying that these are nothing of the sort.  Defining the battleship is slightly tricky, but the best version I have is that it is a <a href="https://www.navalgazing.net/A-Brief-History-of-the-Battleship">large, gun-armed armored warship</a>.  This proposal is certainly large, but it doesn't really classify as gun-armed, in that the guns are clearly secondary weapons, and there's been no discussion of armor at all.  So whatever these are, they aren't battleships.  Their closest cousin is the Soviet <em>Kirov</em> class, which likewise are somewhat hard to classify, but in the <a href="https://www.navalgazing.net/The-Alaska-Class-Part-2">finest tradition of the USN</a>, I'm going to go with "Large Missile Cruiser" for these.  But the fact that they're being called by the wrong name, while personally extremely annoying, is just the tip of the iceberg.
</p>
<p><span> <img width="600" src="https://www.navalgazing.net/attach/DefiantSpecs.jpg?v=1766498855.jpg" alt=""></span></p>
<p>First, a look at the announced specs, as given above.  The dimensions are somewhat large given the displacement, as they're a pretty close match for <em>Iowa</em>, which is 50%+ heavier at full load, although they're also not too far from the <em>Alaska</em>s, of roughly the same displacement.  The length might make sense if they were going for nuclear power, because a very long hull would <a href="https://www.navalgazing.net/Ship-Resistance-and-Speed">minimize power requirements</a>, but it seems that it's <a href="https://www.navalgazing.net/Modern-Propulsion-Part-3" rel="nofollow">IEP</a> instead.  But then we get to armament, and things get weird.  It starts with the new ship-launched nuclear cruise missile that Trump has been pushing since his first term.  This is basically a replacement for the <a href="https://www.navalgazing.net/Tomahawk-Part-1">nuclear Tomahawk</a>, and whatever the logic for or against such a program might be, there's the problem that I'm pretty sure there's no need to have this new "battleship" to use the missile.  Details on the missile are very sketchy, but given that the base program is targeted at submarines, it probably can just go in the VLS with everything else.  If it can't that's a requirements problem, and we should change those instead of spending money on this thing.  I'm sure the crews will love it, too, given the need to guard the VLS all the time to avoid letting anyone know if there are actually nukes aboard.  
<a id="break"></a>
</p>
<p>Second, there are cells for Conventional Prompt Strike, which is the current hypersonic weapon that they're pushing.  It's not in service yet, and I'm <a href="https://www.navalgazing.net/Hypersonic-Weapons-Part-1">skeptical how much real value it will deliver</a>.  I'm also not entirely sure how many missiles will actually be aboard.  <em>Zumwalt</em> recently got four tubes in place of her forward gun, each of which carries three missiles, and I could see either four tubes/12 missiles or 12 tubes/36 missiles, with the latter maybe making more sense given the size of the ship.  The graphic provided by the Navy (below) is curiously unhelpful about this, almost like it was put together by someone who doesn't understand any of this stuff.
</p>
<p><span> <img width="600" src="https://www.navalgazing.net/attach/The_Golden_Fleet_USS_Defiant_Munitions-2048x1036.jpg?v=1766846152.jpg" alt=""> </span></p>
<p>Then there's 128 cells of <a href="https://www.navalgazing.net/VLS">VLS</a>, which is obviously the main armament of any surface warship in this day and age.  Now, this is almost exactly the same number of VLS cells carried by a <a href="https://www.navalgazing.net/The-Ticonderoga-Class"><em>Ticonderoga</em> class cruiser</a> on 10,000 tons,<a id="fnr1_1" href="#fn1_1"><sup>1</sup></a> which raises a fair number of questions about the efficiency of the design relative to a slightly stretched <a href="https://www.navalgazing.net/The-Arleigh-Burke-Class"><em>Burke</em></a> or any number of proposed designs that would be half the size of this thing.
</p>
<p>The secondary armament is even worse.  It starts with a railgun, which has become one of the perennial "next generation" weapons that never seems to get anywhere.  I remember reading about how cool they were going to be almost 20 years ago, and over the last few years, the program seems to have been basically cancelled.  The problem is that if you make an electrical explosion, it's sort of hard to stop it from eroding the rails, and nobody has been able to get a "barrel life" long enough to justify sticking it on a ship, even after investigating some rather amusing systems to change the rails in the field.  The 5" guns are fine, although putting them both forward is a bit odd, and I'm <a href="https://www.navalgazing.net/Lasers-at-Sea-Part-1">a big fan of lasers</a>.  The tertiary armament is even weirder.  <a href="https://www.navalgazing.net/RAM">RAM</a> makes sense as a backup for something like this, but the number of 30 mm guns is a bit odd given that they're basically for shooting and drones and small boats, and you already have lasers for that.  But better safe than sorry.  Then there's ODIN, which is a laser-based dazzler system.  And I'm sorry, but if you are going to put more lasers on, why not put on more full-size lasers?  They can also dazzle things you don't want to shoot down.  ODIN was developed for cases where you didn't have the power or (probably) integration to want a full-powered laser, but that isn't a problem here.  And then you have nebulous "counter UxS systems", which certainly hit current buzzwords, but otherwise leave us with no idea what they do.
</p>
<p><span> <img width="600" src="https://www.navalgazing.net/attach/Trump_Battleship_Poster_Battle_Hi-Res_v5-1-2048x1229.jpg?v=1766846147.jpg" alt=""><br><span>But look how pretty it is!  That's what matters, right?</span></span></p>
<p>On the whole, it's pretty clearly a grab-bag of stuff that sounded cool, thrown together without any real attempt to explain how is this better spending an equivalent amount of money on <em>Burke</em>s or on the DDG(X) program, which was going to come in around 15,000 tons, and which this is allegedly supposed to replace.  Apparently, a lot of this is driven because Trump thinks that modern ships are ugly, and should look good.  And I'm not entirely in disagreement with him on that.  I love a beautiful ship as much as anyone, but I also strive to keep my aesthetic judgements separate from my policy judgements.  I also think that there's some value in having good-looking ships when you're doing port visits and the like, and have even toyed with a "cheap capital ship" to be able to gain some of the benefits I discussed for <a href="https://www.navalgazing.net/Reactivation">the <em>Iowa</em>s in the 1980s</a>.  But that would not have been billed as the future of the Navy, more an interesting side project, and I'm far from sure it would actually be a good use of our limited defense budget.
</p>
<p>We've seen a similarly casual approach to procurement policy with the replacement for <em>Constellation</em>.  SecNav Phelan has announced that it will be a minimum-change version of the National Security Cutter design, with a flexible mission module slot added on and maybe <a href="https://www.navalgazing.net/RAM">RAM</a>, in hopes of getting in the water more quickly.  Now, they might actually be able to make "getting a ship launched by 2028" on this one, particularly if they're able to reuse components from the cutter <em>Friedman</em> (WMSL-760), which was cancelled back in July, with an unclear amount of work already done.  But the result will be something more much like the "minimum viable warship"/Type 31 than a true multi-role frigate, and we should be careful not to confuse the two.  In particular, even if the mission module slots get filled with VLS carrying, say, <a href="https://www.navalgazing.net/ESSM">ESSM</a>, the ship does not have the sort of radar necessary to be considered a serious air defense asset on the modern battlefield.  I gamed this out in Command: Modern Operations, which doubles as a mid-grade military simulation tool.  Both the new ship, apparently designated FF(X) and FFG-62 handled a salvo of 8 conventional C-802-type sea-skimming missiles without too much trouble.  But then I upped the threat to <a href="https://www.navalgazing.net/NSM">NSM</a> and things changed radically.  FFG-62 picked them up at 18.5 nm, just inside the radar horizon, and began firing at about 15 nm, with none of the missiles getting closer than 9.3 nm.  The NSC-based design, with its much worse radar, didn't pick them up until 3.7 nm, when it was too late to do anything other than a single RAM and a few ineffective shots from <a href="https://www.navalgazing.net/Phalanx">Phalanx</a> and the 57 mm gun.  NSC also has no onboard sonar system, although one based on the LCS version might be adaptable for use from the mission deck, at an obvious cost in air defense capability.  But it's "An American Design from an American Shipyard", so we're going to build it anyway, instead of more <em>Constellation</em>s.
</p>
<p><span> <img width="600" src="https://www.navalgazing.net/attach/USCGC_Midgett_arrives_to_Honolulu_for_first_time.jpg?v=1766846386.jpg" alt=""></span></p>
<p>I am also bothered by the name.  Not <em>Defiant</em>, which is a fine name for a warship, even if lacking in any particular heritage in the USN.  But calling the ships the Trump class is...  Look, I've been <a href="https://www.navalgazing.net/We-need-to-talk-about-ship-names">banging on about this for some time</a>, and naming things after someone who is not only alive but in office is just gross.  Also, a complete misunderstanding of how class names work in the American tradition.  The British sometimes will pick a theme name, but we just take the first-ordered ship of the class,<a id="fnr1_2" href="#fn1_2"><sup>2</sup></a> and use that.  So even if this does end up getting into the water, it will probably be as the <em>Defiant</em> class.  And I'm not hopeful for that happening.  This is pretty clearly a very early design, intended to cater to someone whose understanding of naval matters comes entirely from vague memories of Victory at Sea<a id="fnr1_3" href="#fn1_3"><sup>3</sup></a> and various yachts.  It's going to take years to turn it into something we can build, and its fate past 2028 is going to depend on whoever ends up winning that election, a subject I'm not competent to speculate on.
</p>
<p>The design is also pushing the limits of "steel is cheap and air is free", a doctrine I am usually a fierce partisan of.  I think that view is pretty straightforwardly true when you're talking about putting 4,000 tons of combat systems in a 6,000 ton hull.  But at some point, other factors start to take over.  There's a least a little bit of wisdom in the <a href="https://www.navalgazing.net/Types-82-and-42">Type 42 view</a> that if you have extra space, people will try to install stuff in it.  I was also worried about drydocking, but apparently, pretty much every drydock we have that supports DDGs also can handle LHDs, which are about the same size as this thing.  More importantly, even if this ship was considerably more capable than DDG(X), which it mostly isn't, it can only be in one place at a time, and we have a lot of commitments.  A ship in the wrong place isn't all that much better than no ship at all, so there are reasons to want numbers.
</p>
<p><span> <img width="600" src="https://www.navalgazing.net/attach/DefiantBB_NoText_Final2_forReal.png?v=1766846151.png" alt=""><br><span>Shas'ui made an excellent summary of the program on the Naval Gazing Discord</span></span></p>
<p>Ultimately, this entire thing is silly.  This is a ludicrously overgrown destroyer/cruiser (so far as those are separate things these days) without even a figleaf of justification for its size.  And even if there was some justification for the size, it definitely isn't a battleship.  Also, on a personal note, I would really appreciate it if the Administration stopped dropping significant naval news on the weeks of major holidays, because it adds something to my plate that I would rather not have to deal with.
</p>
<hr>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Building a macOS app to know when my Mac is thermal throttling (256 pts)]]></title>
            <link>https://stanislas.blog/2025/12/macos-thermal-throttling-app/</link>
            <guid>46410402</guid>
            <pubDate>Sun, 28 Dec 2025 11:51:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://stanislas.blog/2025/12/macos-thermal-throttling-app/">https://stanislas.blog/2025/12/macos-thermal-throttling-app/</a>, See on <a href="https://news.ycombinator.com/item?id=46410402">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main-content"><article><header><div><p><time datetime="2025-12-27 22:33:00.601 +0000 UTC">27 December 2025</time><span>·</span><span>2204 words</span><span>·</span><span title="Reading time">11 mins</span></p></div><div><picture><source srcset="https://stanislas.blog/2025/12/macos-thermal-throttling-app/mac-throttle_hu_fd91f6e5cc3e5ff7.webp 330w,https://stanislas.blog/2025/12/macos-thermal-throttling-app/mac-throttle_hu_b573e1e8b9b63ca7.webp 660w
,https://stanislas.blog/2025/12/macos-thermal-throttling-app/mac-throttle_hu_57fe643193b6214a.webp 1024w
,https://stanislas.blog/2025/12/macos-thermal-throttling-app/mac-throttle_hu_6d3c5a2fa9ef56d5.webp 1320w" sizes="100vw" type="image/webp"><img width="1596" height="1100" data-zoom-src="https://stanislas.blog/2025/12/macos-thermal-throttling-app/mac-throttle.png" src="https://stanislas.blog/2025/12/macos-thermal-throttling-app/mac-throttle_hu_fa2e75ce3cb92b4b.png" srcset="https://stanislas.blog/2025/12/macos-thermal-throttling-app/mac-throttle_hu_1215a78af35bc126.png 330w,https://stanislas.blog/2025/12/macos-thermal-throttling-app/mac-throttle_hu_fa2e75ce3cb92b4b.png 660w
,https://stanislas.blog/2025/12/macos-thermal-throttling-app/mac-throttle_hu_ba1d91e322f298e8.png 1024w
,https://stanislas.blog/2025/12/macos-thermal-throttling-app/mac-throttle_hu_1219593febb198bc.png 1320w" sizes="100vw"></picture></div></header><div><p>This is the story about how I built <a href="https://github.com/angristan/MacThrottle" target="_blank" rel="noreferrer">MacThrottle</a>.</p><p>I’ve been very happy with my M2 MacBook Air for the past few years. However, when using an external display, especially a very demanding one like a 4K 120Hz display, I’ve noticed it started struggling more. Since it lacks fans, you can’t hear it struggling, but you can feel it as everything becomes very slow or unresponsive: that’s when thermal throttling kicks in.</p><p>I know it’s thermal throttling because I can see in iStat Menus that my CPU usage is 100% while the power usage in watts goes down.</p><p>It’s even more obvious with <a href="https://www.seense.com/menubarstats/mxpg/" target="_blank" rel="noreferrer">MX Power Gadget</a>: You can see the power usage and frequency of the performance core dropping, as usage keeps being 100%:</p><figure><img src="https://stanislas.blog/2025/12/macos-thermal-throttling-app/mx-power-gadget-throttling.png" alt="MX Power Gadget"></figure><p>I’ve also hit thermal throttling with my work MacBook Pro. It’s the 14" M4 Max variant, <a href="https://www.bestlaptop.deals/articles/m4-macbook-pros-ultimate-review-performance-power-efficiency-battery-life?utm_source=chatgpt.com#Sustained-Performance" target="_blank" rel="noreferrer">which is the worst variant</a> because the thermal envelope of the 14" is too small for the max output for the M4 Max. On my previous 14" M1 Pro MacBook Pro, I’ve never even heard the fans in 3 years…</p><p>That being said, I still love Apple Silicon for the performance and power usage, it’s still a dramatic improvement over the Intel days. 🫶</p><p>Anyway, I wanted to know: is there a way to tell if the Apple Silicon SoC is thermal throttling, that is not based on heuristics like in my screenshot?</p><h2 id="getting-the-thermal-state-programmatically">Getting the thermal state programmatically <span><a href="#getting-the-thermal-state-programmatically" aria-label="Anchor">#</a></span></h2><p>This was a wilder ride than I expected. It’s possible to know programmatically if the Mac is throttled, because macOS exposes this in various but inconsistent ways.</p><p>The approach that Apple recommends is to use <a href="https://developer.apple.com/documentation/foundation/processinfo/thermalstate-swift.enum" target="_blank" rel="noreferrer"><code>ProcessInfo.thermalState</code></a> from <code>Foundation</code>:</p><div><pre tabindex="0"><code data-lang="swift"><span><span>➜  <span>~</span> swift <span>-</span>e '<span>import</span> Foundation; print([<span>"nominal"</span>, <span>"fair"</span>, <span>"serious"</span>, <span>"critical"</span>][ProcessInfo.processInfo.thermalState.rawValue])'
</span></span><span><span>nominal
</span></span></code></pre></div><p>Sounds good, right? However, I knew that another tool could provide this information, though it needed root: <a href="https://ss64.com/mac/powermetrics.html" target="_blank" rel="noreferrer"><code>powermetrics</code></a>.</p><div><pre tabindex="0"><code data-lang="sh"><span><span>➜  ~ sudo powermetrics -s thermal
</span></span><span><span>
</span></span><span><span>Password:
</span></span><span><span>Machine model: Mac14,2
</span></span><span><span>OS version: 25B78
</span></span><span><span>Boot arguments:
</span></span><span><span>Boot time: Sun Nov <span>23</span> 10:19:29 <span>2025</span>
</span></span><span><span>
</span></span><span><span>
</span></span><span><span>
</span></span><span><span>*** Sampled system activity <span>(</span>Wed Dec <span>17</span> 09:48:34 <span>2025</span> +0100<span>)</span> <span>(</span>5001.07ms elapsed<span>)</span> ***
</span></span><span><span>
</span></span><span><span>
</span></span><span><span>
</span></span><span><span>**** Thermal pressure ****
</span></span><span><span>
</span></span><span><span>Current pressure level: Nominal
</span></span><span><span>
</span></span><span><span>
</span></span><span><span>*** Sampled system activity <span>(</span>Wed Dec <span>17</span> 09:48:39 <span>2025</span> +0100<span>)</span> <span>(</span>5001.25ms elapsed<span>)</span> ***
</span></span><span><span>
</span></span><span><span>
</span></span><span><span>
</span></span><span><span>**** Thermal pressure ****
</span></span><span><span>
</span></span><span><span>Current pressure level: Nominal
</span></span></code></pre></div><p>(yes the output has that many newlines)</p><p>Both report the pressure level to be “nominal”, they must be the same…right?</p><p>After running a few stress tests <code>stress-ng --cpu 0 -t 600</code>, I started to see the two values diverge!</p><p>For some reason, the granularity is different between <code>ProcessInfo.thermalState</code> and <code>powermetrics</code>. They have a different amount of possible states and they don’t line up.</p><p>Here is my empirical experience:</p><table><thead><tr><th><code>ProcessInfo.thermalState</code></th><th><code>powermetrics</code></th></tr></thead><tbody><tr><td>nominal</td><td>nominal</td></tr><tr><td><strong>fair</strong></td><td><strong>moderate</strong></td></tr><tr><td><strong>fair</strong></td><td><strong>heavy</strong></td></tr></tbody></table><p>I never managed to hit these states, so I don’t know if they match, but they’re technically defined:</p><table><thead><tr><th><code>ProcessInfo.thermalState</code></th><th><code>powermetrics</code></th></tr></thead><tbody><tr><td>serious</td><td>trapping</td></tr><tr><td>critical</td><td>sleeping</td></tr></tbody></table><p>In practice, when my Mac starts getting hot, from the <code>powermetrics</code> perspective it goes into <code>moderate</code>, and when it starts throttling, it goes into <code>heavy</code>. The problem is that with <code>ProcessInfo</code>, both are covered by the <code>fair</code> state, so it’s not really useful to know when the Mac is <em>actually</em> throttling. ☹️</p><p>I thought maybe this was an iOS vs macOS thing? But <a href="https://developer.apple.com/library/archive/documentation/Performance/Conceptual/power_efficiency_guidelines_osx/RespondToThermalStateChanges.html" target="_blank" rel="noreferrer">Apple references it in the macOS docs</a> as well. Maybe it was more consistent on Intel Macs?</p><p>I stumbled upon <a href="https://dmaclach.medium.com/thermals-and-macos-c0db81062889" target="_blank" rel="noreferrer">this article</a> from Dave MacLachlan, a Googler working on Apple stuff, from 2020. I learned that there are other CLI tools to get thermal data, but they don’t seem to work on my Apple Silicon MacBook:</p><div><pre tabindex="0"><code data-lang="sh"><span><span>➜ sudo thermal levels
</span></span><span><span>Thermal levels are unsupported on this machine.
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="sh"><span><span>➜ sudo pmset -g thermlog
</span></span><span><span>Note: No thermal warning level has been recorded
</span></span><span><span>Note: No performance warning level has been recorded
</span></span><span><span>Note: No CPU power status has been recorded
</span></span><span><span>^C
</span></span></code></pre></div><p>But the most interesting thing I learned is that the data <code>powermetrics</code> shows is actually coming from <code>thermald</code>. And <code>thermald</code> writes the current thermal pressure to the Darwin notification system (<code>notifyd</code>)!</p><div><pre tabindex="0"><code data-lang="sh"><span><span>➜ notifyutil -g com.apple.system.thermalpressurelevel
</span></span><span><span>
</span></span><span><span>com.apple.system.thermalpressurelevel <span>0</span>
</span></span></code></pre></div><p>The various levels are defined in <code>OSThermalNotification.h</code> according to the article. Indeed:</p><div><pre tabindex="0"><code data-lang="sh"><span><span>➜  ~ xcrun --sdk macosx --show-sdk-path
</span></span><span><span>/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX26.2.sdk
</span></span><span><span>➜  ~ SDK<span>=</span><span>"</span><span>$(</span>xcrun --sdk macosx --show-sdk-path<span>)</span><span>"</span>
</span></span><span><span>➜  ~ find <span>"</span>$SDK<span>/usr/include"</span> -name <span>'OSThermalNotification.h'</span>
</span></span><span><span>/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX26.2.sdk/usr/include/libkern/OSThermalNotification.h
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="c"><span><span>➜  <span>~</span> head <span>-</span>n <span>52</span> <span>"/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX26.2.sdk/usr/include/libkern/OSThermalNotification.h"</span>
</span></span><span><span><span>/*
</span></span></span><span><span><span> * Copyright (c) 2007 Apple Inc. All rights reserved.
</span></span></span><span><span><span> *
</span></span></span><span><span><span> * @APPLE_LICENSE_HEADER_START@
</span></span></span><span><span><span> *
</span></span></span><span><span><span> * This file contains Original Code and/or Modifications of Original Code
</span></span></span><span><span><span> * as defined in and that are subject to the Apple Public Source License
</span></span></span><span><span><span> * Version 2.0 (the 'License'). You may not use this file except in
</span></span></span><span><span><span> * compliance with the License. Please obtain a copy of the License at
</span></span></span><span><span><span> * http://www.opensource.apple.com/apsl/ and read it before using this
</span></span></span><span><span><span> * file.
</span></span></span><span><span><span> *
</span></span></span><span><span><span> * The Original Code and all software distributed under the License are
</span></span></span><span><span><span> * distributed on an 'AS IS' basis, WITHOUT WARRANTY OF ANY KIND, EITHER
</span></span></span><span><span><span> * EXPRESS OR IMPLIED, AND APPLE HEREBY DISCLAIMS ALL SUCH WARRANTIES,
</span></span></span><span><span><span> * INCLUDING WITHOUT LIMITATION, ANY WARRANTIES OF MERCHANTABILITY,
</span></span></span><span><span><span> * FITNESS FOR A PARTICULAR PURPOSE, QUIET ENJOYMENT OR NON-INFRINGEMENT.
</span></span></span><span><span><span> * Please see the License for the specific language governing rights and
</span></span></span><span><span><span> * limitations under the License.
</span></span></span><span><span><span> *
</span></span></span><span><span><span> * @APPLE_LICENSE_HEADER_END@
</span></span></span><span><span><span> */</span>
</span></span><span><span>
</span></span><span><span><span>#ifndef _OSTHERMALNOTIFICATION_H_
</span></span></span><span><span><span>#define _OSTHERMALNOTIFICATION_H_
</span></span></span><span><span>
</span></span><span><span><span>#include</span> <span>&lt;_bounds.h&gt;</span><span>
</span></span></span><span><span><span>#include</span> <span>&lt;sys/cdefs.h&gt;</span><span>
</span></span></span><span><span><span>#include</span> <span>&lt;Availability.h&gt;</span><span>
</span></span></span><span><span><span>#include</span> <span>&lt;TargetConditionals.h&gt;</span><span>
</span></span></span><span><span>
</span></span><span><span><span>_LIBC_SINGLE_BY_DEFAULT</span>()
</span></span><span><span>
</span></span><span><span><span>/*
</span></span></span><span><span><span>**  OSThermalNotification.h
</span></span></span><span><span><span>**
</span></span></span><span><span><span>**  Notification mechanism to alert registered tasks when device thermal conditions
</span></span></span><span><span><span>**  reach certain thresholds. Notifications are triggered in both directions
</span></span></span><span><span><span>**  so clients can manage their memory usage more and less aggressively.
</span></span></span><span><span><span>**
</span></span></span><span><span><span>*/</span>
</span></span><span><span>
</span></span><span><span>__BEGIN_DECLS
</span></span><span><span>
</span></span><span><span><span>/* Define pressure levels usable by OSThermalPressureLevel */</span>
</span></span><span><span><span>typedef</span> <span>enum</span> {
</span></span><span><span><span>#if TARGET_OS_OSX || TARGET_OS_MACCATALYST
</span></span></span><span><span>        kOSThermalPressureLevelNominal <span>=</span> <span>0</span>,
</span></span><span><span>        kOSThermalPressureLevelModerate,
</span></span><span><span>        kOSThermalPressureLevelHeavy,
</span></span><span><span>        kOSThermalPressureLevelTrapping,
</span></span><span><span>        kOSThermalPressureLevelSleeping
</span></span></code></pre></div><p>The funny thing is that <code>OSThermalNotification.h</code> is barely referenced anywhere, there are only three pages of Google results. <a href="https://bazel.googlesource.com/bazel/+/refs/heads/release-9.0.0-pre.20241023.1rc1/src/main/native/darwin/system_thermal_monitor_jni.cc" target="_blank" rel="noreferrer">It seems to be used in Bazel</a> for example. That post was a big help.</p><p>What’s great about this approach is that it doesn’t require root! I can subscribe to the notification system for the <code>com.apple.system.thermalpressurelevel</code> event to get the (good) thermal state!</p><p>Here is a snippet to get it in Swift:</p><div><pre tabindex="0"><code data-lang="swift"><span><span><span>import</span> Foundation
</span></span><span><span>
</span></span><span><span>@_silgen_name(<span>"notify_register_check"</span>)
</span></span><span><span><span>private</span> <span>func</span> <span>notify_register_check</span>(
</span></span><span><span>  <span>_</span> name: <span>UnsafePointer</span>&lt;<span>CChar</span>&gt;, <span>_</span> token: <span>UnsafeMutablePointer</span>&lt;<span>Int32</span>&gt;
</span></span><span><span>) -&gt; <span>UInt32</span>
</span></span><span><span>@_silgen_name(<span>"notify_get_state"</span>)
</span></span><span><span><span>private</span> <span>func</span> <span>notify_get_state</span>(<span>_</span> token: <span>Int32</span>, <span>_</span> state: <span>UnsafeMutablePointer</span>&lt;<span>UInt64</span>&gt;) -&gt; <span>UInt32</span>
</span></span><span><span>@_silgen_name(<span>"notify_cancel"</span>)
</span></span><span><span><span>private</span> <span>func</span> <span>notify_cancel</span>(<span>_</span> token: <span>Int32</span>) -&gt; <span>UInt32</span>
</span></span><span><span>
</span></span><span><span><span>let</span> notifyOK: <span>UInt32</span> = <span>0</span>
</span></span><span><span><span>let</span> name = <span>"com.apple.system.thermalpressurelevel"</span>
</span></span><span><span>
</span></span><span><span><span>var</span> token: <span>Int32</span> = <span>0</span>
</span></span><span><span><span>let</span> reg = name.withCString { notify_register_check($0, &amp;token) }
</span></span><span><span><span>guard</span> reg == notifyOK <span>else</span> { <span>fatalError</span>(<span>"notify_register_check failed: </span><span>\(</span>reg<span>)</span><span>"</span>) }
</span></span><span><span><span>defer</span> { <span>_</span> = notify_cancel(token) }
</span></span><span><span>
</span></span><span><span><span>var</span> state: <span>UInt64</span> = <span>0</span>
</span></span><span><span><span>let</span> got = notify_get_state(token, &amp;state)
</span></span><span><span><span>guard</span> got == notifyOK <span>else</span> { <span>fatalError</span>(<span>"notify_get_state failed: </span><span>\(</span>got<span>)</span><span>"</span>) }
</span></span><span><span>
</span></span><span><span><span>let</span> label =
</span></span><span><span>  <span>switch</span> state {
</span></span><span><span>  <span>case</span> <span>0</span>: <span>"nominal"</span>
</span></span><span><span>  <span>case</span> <span>1</span>: <span>"moderate"</span>
</span></span><span><span>  <span>case</span> <span>2</span>: <span>"heavy"</span>
</span></span><span><span>  <span>case</span> <span>3</span>: <span>"trapping"</span>
</span></span><span><span>  <span>case</span> <span>4</span>: <span>"sleeping"</span>
</span></span><span><span>  <span>default</span>: <span>"unknown(</span><span>\(</span>state<span>)</span><span>)"</span>
</span></span><span><span>  }
</span></span><span><span>
</span></span><span><span><span>print</span>(<span>"</span><span>\(</span>state<span>)</span><span> </span><span>\(</span>label<span>)</span><span>"</span>)
</span></span></code></pre></div><p>Prints:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>➜  ~ swift thermal.swift
</span></span><span><span><span>0</span> nominal
</span></span></code></pre></div><p>Now that I had a useful value to work with, it was time to build the app.</p><h2 id="building-macthrottle">Building MacThrottle <span><a href="#building-macthrottle" aria-label="Anchor">#</a></span></h2><p>Armed with Opus 4.5, I set out to build a little menu bar app where I could see, at a glance, if my Apple Silicon die was trying to save itself from crossing 110°C. I called it <a href="https://github.com/angristan/MacThrottle" target="_blank" rel="noreferrer">MacThrottle</a>.</p><p>I built a simple SwiftUI app for the menu bar that shows me the status in a superbly original thermometer icon. The thermometer is filled depending on the thermal state, and its color changes from green to red. I have like 20 menu bar icons and they’re all monochromatic, so the color in the thermometer is very subtle to keep things consistent.</p><p>The app is a simple SwiftUI app. Apple provides a scene called <a href="https://developer.apple.com/documentation/SwiftUI/MenuBarExtra" target="_blank" rel="noreferrer">MenuBarExtra</a> to render a menu bar control. It was simpler than I expected! To make it a pure menu bar app with no dock icon, you just need to set <code>LSUIElement</code> to <code>true</code> in <code>Info.plist</code>.</p><figure><img src="https://stanislas.blog/2025/12/macos-thermal-throttling-app/mac-throttle-old.png" alt="An early version of MacThrottle"><figcaption>An early version of MacThrottle, just reporting the thermal state</figcaption></figure><h3 id="first-approach-root-helper-for-powermetrics">First approach: root helper for <code>powermetrics</code> <span><a href="#first-approach-root-helper-for-powermetrics" aria-label="Anchor">#</a></span></h3><p>I explained the various approaches to get the thermal pressure level in the previous section. But when I was building the app, I discovered later on that <code>thermald</code> was publishing the thermal state to <code>notifyd</code>. So at first, I thought I had to use <code>powermetrics</code> to get useful thermal state changes. Since that unfortunately requires root access, the app needed root access too.</p><p>To reduce the scope of what runs as root, I did not run the app itself as root. Instead, the app does not work by default, but it gives you the option to install a helper. It does this through an AppleScript <code>with administrator privileges</code> to prompt for access.</p><p>The helper is just a bash script run as a launchd daemon:</p><div><pre tabindex="0"><code data-lang="xml"><span><span>➜  ~ cat /Library/LaunchDaemons/com.macthrottle.thermal-monitor.plist
</span></span><span><span><span>&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span>
</span></span><span><span><span>&lt;!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd"&gt;</span>
</span></span><span><span><span>&lt;plist</span> <span>version=</span><span>"1.0"</span><span>&gt;</span>
</span></span><span><span><span>&lt;dict&gt;</span>
</span></span><span><span>    <span>&lt;key&gt;</span>Label<span>&lt;/key&gt;</span>
</span></span><span><span>    <span>&lt;string&gt;</span>com.macthrottle.thermal-monitor<span>&lt;/string&gt;</span>
</span></span><span><span>    <span>&lt;key&gt;</span>ProgramArguments<span>&lt;/key&gt;</span>
</span></span><span><span>    <span>&lt;array&gt;</span>
</span></span><span><span>        <span>&lt;string&gt;</span>/usr/local/bin/mac-throttle-thermal-monitor<span>&lt;/string&gt;</span>
</span></span><span><span>    <span>&lt;/array&gt;</span>
</span></span><span><span>    <span>&lt;key&gt;</span>RunAtLoad<span>&lt;/key&gt;</span>
</span></span><span><span>    <span>&lt;true/&gt;</span>
</span></span><span><span>    <span>&lt;key&gt;</span>KeepAlive<span>&lt;/key&gt;</span>
</span></span><span><span>    <span>&lt;true/&gt;</span>
</span></span><span><span><span>&lt;/dict&gt;</span>
</span></span><span><span><span>&lt;/plist&gt;</span>
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="sh"><span><span>➜  ~ cat /usr/local/bin/mac-throttle-thermal-monitor
</span></span><span><span><span>#!/bin/bash</span>
</span></span><span><span>OUTPUT_FILE<span>=</span><span>"/tmp/mac-throttle-thermal-state"</span>
</span></span><span><span>
</span></span><span><span><span>while</span> true; <span>do</span>
</span></span><span><span>    THERMAL_OUTPUT<span>=</span><span>$(</span>powermetrics -s thermal -n <span>1</span> -i <span>1</span> 2&gt;/dev/null | grep -i <span>"Current pressure level"</span><span>)</span>
</span></span><span><span>
</span></span><span><span>    <span>if</span> <span>echo</span> <span>"</span>$THERMAL_OUTPUT<span>"</span> | grep -qi <span>"sleeping"</span>; <span>then</span>
</span></span><span><span>        PRESSURE<span>=</span><span>"sleeping"</span>
</span></span><span><span>    <span>elif</span> <span>echo</span> <span>"</span>$THERMAL_OUTPUT<span>"</span> | grep -qi <span>"trapping"</span>; <span>then</span>
</span></span><span><span>        PRESSURE<span>=</span><span>"trapping"</span>
</span></span><span><span>    <span>elif</span> <span>echo</span> <span>"</span>$THERMAL_OUTPUT<span>"</span> | grep -qi <span>"heavy"</span>; <span>then</span>
</span></span><span><span>        PRESSURE<span>=</span><span>"heavy"</span>
</span></span><span><span>    <span>elif</span> <span>echo</span> <span>"</span>$THERMAL_OUTPUT<span>"</span> | grep -qi <span>"moderate"</span>; <span>then</span>
</span></span><span><span>        PRESSURE<span>=</span><span>"moderate"</span>
</span></span><span><span>    <span>elif</span> <span>echo</span> <span>"</span>$THERMAL_OUTPUT<span>"</span> | grep -qi <span>"nominal"</span>; <span>then</span>
</span></span><span><span>        PRESSURE<span>=</span><span>"nominal"</span>
</span></span><span><span>    <span>else</span>
</span></span><span><span>        PRESSURE<span>=</span><span>"unknown"</span>
</span></span><span><span>    <span>fi</span>
</span></span><span><span>
</span></span><span><span>    <span>echo</span> <span>"{\"pressure\":\"</span>$PRESSURE<span>\",\"timestamp\":</span><span>$(</span>date +%s<span>)</span><span>}"</span> &gt; <span>"</span>$OUTPUT_FILE<span>"</span>
</span></span><span><span>    chmod <span>644</span> <span>"</span>$OUTPUT_FILE<span>"</span>
</span></span><span><span>    sleep <span>10</span>
</span></span><span><span><span>done</span>
</span></span></code></pre></div><p>The bash script writes the thermal state to a file every few seconds and the app reads it every few seconds!</p><h3 id="using-the-thermald-ipc-notifications">Using the <code>thermald</code> IPC notifications <span><a href="#using-the-thermald-ipc-notifications" aria-label="Anchor">#</a></span></h3><p>Once I discovered I could use the notification system without elevated privileges, <a href="https://github.com/angristan/MacThrottle/commit/20f3861073634b7c42fc427eb151c07ba2bfe2c6" target="_blank" rel="noreferrer">I replaced the helper</a> by code in the app to read the value from the notification system directly. Much simpler 🎉</p><h3 id="temperature-and-fans">Temperature and fans <span><a href="#temperature-and-fans" aria-label="Anchor">#</a></span></h3><p>I wanted to show the temperature and fan speed (when supported) in a little graph in the menu bar app. This would allow me to correlate the thermal state with increased temperature, for example.</p><p>Again, there are multiple APIs to read the temperature. First, I <a href="https://github.com/angristan/MacThrottle/blob/7ccdb5939fb5530ba87e5376e8b6589c4a3aa081/MacThrottle/Services/TemperatureReaders.swift#L245" target="_blank" rel="noreferrer">started using an undocumented API from IOKit</a>, but I realised I was getting ~80ºC max, while iStat Menus or MX Power Gadget would show &gt;100ºC.</p><p><a href="https://github.com/exelban/stats/tree/master/SMC" target="_blank" rel="noreferrer">Stats</a>, the open source alternative to iStat Menus, helped me use the SMC instead and get the correct values. But the SMC is a much more unstable API because each SoC has <a href="https://github.com/angristan/MacThrottle/blob/7ccdb5939fb5530ba87e5376e8b6589c4a3aa081/MacThrottle/Services/TemperatureReaders.swift#L58-L60" target="_blank" rel="noreferrer">different keys</a> to access the temperature data:</p><div><pre tabindex="0"><code data-lang="swift"><span><span><span>private</span> <span>let</span> m1Keys = [<span>"Tp01"</span>, <span>"Tp05"</span>, <span>"Tp09"</span>, <span>"Tp0D"</span>, <span>"Tp0H"</span>, <span>"Tp0L"</span>, <span>"Tp0P"</span>, <span>"Tp0X"</span>, <span>"Tp0b"</span>]
</span></span><span><span><span>private</span> <span>let</span> m2Keys = [<span>"Tp01"</span>, <span>"Tp05"</span>, <span>"Tp09"</span>, <span>"Tp0D"</span>, <span>"Tp0X"</span>, <span>"Tp0b"</span>, <span>"Tp0f"</span>, <span>"Tp0j"</span>]
</span></span><span><span><span>private</span> <span>let</span> m3Keys = [<span>"Tf04"</span>, <span>"Tf09"</span>, <span>"Tf0A"</span>, <span>"Tf0B"</span>, <span>"Tf0D"</span>, <span>"Tf0E"</span>, <span>"Tf44"</span>, <span>"Tf49"</span>, <span>"Tf4A"</span>, <span>"Tf4B"</span>]
</span></span></code></pre></div><p>Though the M3 keys seem to work on my M4 Max work MacBook Pro…</p><p>I ended up using SMC first to get the accurate temperature and fall back to IOKit if SMC doesn’t work.</p><p>For the graph, I wanted a compact visualization that would show me the thermal history at a glance.</p><p>The graph packs three layers of information:</p><ul><li>Colored background segments for each thermal state (green for nominal, yellow for moderate, orange for heavy, red for critical)</li><li>A solid line for CPU temperature with a dynamic Y-axis that adjusts to actual values</li><li>A dashed cyan line for fan speed percentage (on Macs that have fans)</li></ul><p>I didn’t want to spend too much time making a super fancy graph system. Since it polls every two seconds, the graph gets very busy after a while. So I decided to keep it down to 10 minutes, since the thermal state history is mostly interesting short-term.</p><p>I also added hover tooltips using <code>onContinuousHover</code>.</p><p>When the system was under load, I noticed the graph hovering was not very smooth on my 120Hz display. I found out I can add <a href="https://www.hackingwithswift.com/books/ios-swiftui/enabling-high-performance-metal-rendering-with-drawinggroup" target="_blank" rel="noreferrer"><code>.drawingGroup</code> to my SwiftUI canvas to use GPU rendering!</a>. Indeed, I <a href="https://github.com/angristan/MacThrottle/commit/b85e55c65423a2a8385dcf40b0853a38e5bbd130" target="_blank" rel="noreferrer">added it</a>, and it was smooth again.</p><figure><img src="https://stanislas.blog/2025/12/macos-thermal-throttling-app/mac-throttle-with-fans.jpeg" alt="MacThrottle showing fan speed"><figcaption>Graph with pressure state, temp and fans. Tooltip on hover to get past value is supported.</figcaption></figure><h3 id="adding-macos-notifications">Adding macOS notifications <span><a href="#adding-macos-notifications" aria-label="Anchor">#</a></span></h3><p>I also added notifications so I get alerted when the state changes, in case I miss the menu bar icon. It can alert on specific state transitions, and optionally on recovery. This is useful to know when it’s time to kill a VS Code instance or a Docker container!</p><figure><img src="https://stanislas.blog/2025/12/macos-thermal-throttling-app/mac-throttle-notification.png" alt="MacThrottle notification alerting of heavy thermal pressure"><figcaption>To be fair, it can get a bit noisy on a struggling MacBook Air…</figcaption></figure><p>It’s true that I usually already notice when the Mac is getting slow, but sometimes the Mac gets slow when it’s swapping heavily. At least now I know when it’s just too hot.</p><h3 id="launching-the-app-at-login">Launching the app at Login <span><a href="#launching-the-app-at-login" aria-label="Anchor">#</a></span></h3><p>Of course, I want the app to start automatically now, since it works so well!</p><p>I expected that I would need to write <code>.plist</code> again, but no, it’s extremely easy to prompt the user to add a “login item” as macOS calls it, using <a href="https://developer.apple.com/documentation/servicemanagement/smappservice" target="_blank" rel="noreferrer"><code>SMAppService</code></a>.</p><div><pre tabindex="0"><code data-lang="swift"><span><span>SMAppService.mainApp.register()    <span>// enable auto-start</span>
</span></span><span><span>SMAppService.mainApp.unregister()  <span>// disable auto-start</span>
</span></span><span><span>SMAppService.mainApp.status == .enabled  <span>// check current state</span>
</span></span></code></pre></div><h2 id="how-to-use-it">How to use it <span><a href="#how-to-use-it" aria-label="Anchor">#</a></span></h2><p>Since I don’t have an Apple Developer account, I can’t notarize the app, so installing it from the <a href="https://github.com/angristan/MacThrottle/releases" target="_blank" rel="noreferrer">releases</a> is going to require a few extra clicks in <code>Privacy and Security</code>.</p><p>And for Macs that disallow it entirely, building from source with Xcode is the only way. I added instructions <a href="https://github.com/angristan/MacThrottle?tab=readme-ov-file#option-2-build-locally" target="_blank" rel="noreferrer">in the README</a>.</p><p>Hope this is useful to someone else!</p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Learn computer graphics from scratch and for free (221 pts)]]></title>
            <link>https://www.scratchapixel.com</link>
            <guid>46410210</guid>
            <pubDate>Sun, 28 Dec 2025 11:08:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.scratchapixel.com">https://www.scratchapixel.com</a>, See on <a href="https://news.ycombinator.com/item?id=46410210">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>Learn computer graphics from scratch and for free.</p>
<p>The usual beloved lessons.<br>A blog, some private courses,<br>and an upcoming book project!</p>


<div id="section">
	<p>The Foundations of 3D Rendering</p>
	<p>These lessons are structured to introduce 3D rendering concepts in a beginner-friendly order. Unlike most resources, we start with hands-on results before diving into theory.</p>
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		

</div><!-- end of section -->

<div id="section">
	<p>Mathematics for Computer Graphics</p>
	<p>This section is dedicated to explaining the mathematical theories and tools used in creating images and simulations with a computer. It's not intended as a starting point, but rather as a reference to be consulted when these topics are mentioned in lessons from other sections.</p>
		
		
		
		
		
		
		
		

</div><!-- end of section -->

<div id="section">
	<p>Computer Graphics Gems</p>
	<p>A collection of lessons on specific topics that don’t necessarily fit into any broad category but are nonetheless interesting and cool.</p>
		

</div><!-- end of section -->

<div id="section">
	<p>Geometry</p>
	<p>Methods to define shapes in computer graphics.</p>
		

</div><!-- end of section -->

<div id="section">
	<p>Digital Imaging</p>
	<p>Saving and reading images to and from disk, image file formats, color spaces, color management, and basic image processing.</p>
		
		
		

</div><!-- end of section -->

<div id="section">
	<p>Procedural Generation of Virtual Worlds</p>
	<p>Procedural simulation of natural phenomena.</p>
		
		
		

</div><!-- end of section -->

<div id="section">
	<p>Tooling</p>
	<p>Various techniques useful for developing 3D tools and interacting with 3D content in general.</p>
		
		
		

</div><!-- end of section -->
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Last Year on My Mac: Look Back in Disbelief (448 pts)]]></title>
            <link>https://eclecticlight.co/2025/12/28/last-year-on-my-mac-look-back-in-disbelief/</link>
            <guid>46409969</guid>
            <pubDate>Sun, 28 Dec 2025 10:12:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://eclecticlight.co/2025/12/28/last-year-on-my-mac-look-back-in-disbelief/">https://eclecticlight.co/2025/12/28/last-year-on-my-mac-look-back-in-disbelief/</a>, See on <a href="https://news.ycombinator.com/item?id=46409969">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-first_letter="I">
		<p>If someone had told me 12 months ago what was going to happen this past year, I wouldn’t have believed them. Skipping swiftly past all the political, economic and social turmoil, I come to the interface changes brought in macOS Tahoe with Liquid Glass. After three months of strong feedback during beta-testing, I was disappointed when Tahoe was released on 15 September to see how little had been addressed. When 26.1 followed on 3 November it had only regressed, and 26.2 has done nothing. Here I summarise my opinions on where Tahoe’s overhaul has gone wrong.</p>
<h4>What goes round</h4>
<p>Almost all the content displayed in windows is best suited to rectangular views. Images, video, webpages and other text crave areas bounded by right angles. Gentle rounding on the corners, as in Sequoia, is fine, but the significantly increased radius enforced in Tahoe is a misfit. This either leads to cropping of contents, or reduction in size of the view and wasted space.</p>
<p><span><a href="https://eclecticlight.co/wp-content/uploads/2025/06/roundrect1.jpg"><img data-attachment-id="86914" data-permalink="https://eclecticlight.co/2025/06/15/last-week-on-my-mac-fidelity-in-design/roundrect1/" data-orig-file="https://eclecticlight.co/wp-content/uploads/2025/06/roundrect1.jpg" data-orig-size="1530,1165" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="roundrect1" data-image-description="" data-image-caption="" data-medium-file="https://eclecticlight.co/wp-content/uploads/2025/06/roundrect1.jpg?w=300" data-large-file="https://eclecticlight.co/wp-content/uploads/2025/06/roundrect1.jpg?w=940" src="https://eclecticlight.co/wp-content/uploads/2025/06/roundrect1.jpg" alt="" width="940" height="716" srcset="https://eclecticlight.co/wp-content/uploads/2025/06/roundrect1.jpg?w=940&amp;h=716 940w, https://eclecticlight.co/wp-content/uploads/2025/06/roundrect1.jpg?w=150&amp;h=114 150w, https://eclecticlight.co/wp-content/uploads/2025/06/roundrect1.jpg?w=300&amp;h=228 300w, https://eclecticlight.co/wp-content/uploads/2025/06/roundrect1.jpg?w=768&amp;h=585 768w, https://eclecticlight.co/wp-content/uploads/2025/06/roundrect1.jpg?w=1024&amp;h=780 1024w, https://eclecticlight.co/wp-content/uploads/2025/06/roundrect1.jpg?w=1440&amp;h=1096 1440w, https://eclecticlight.co/wp-content/uploads/2025/06/roundrect1.jpg 1530w" sizes="(max-width: 940px) 100vw, 940px"></a></span></p>
<p>Cropping is misleading, as seen in this enlarged view of a thumbnail image in the Finder’s Gallery view, compared to the larger version shown below. The thumbnail misrepresents what’s in the original.</p>
<p><span><a href="https://eclecticlight.co/wp-content/uploads/2025/06/roundrect2.jpg"><img data-attachment-id="86915" data-permalink="https://eclecticlight.co/2025/06/15/last-week-on-my-mac-fidelity-in-design/roundrect2/" data-orig-file="https://eclecticlight.co/wp-content/uploads/2025/06/roundrect2.jpg" data-orig-size="1408,1061" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="roundrect2" data-image-description="" data-image-caption="" data-medium-file="https://eclecticlight.co/wp-content/uploads/2025/06/roundrect2.jpg?w=300" data-large-file="https://eclecticlight.co/wp-content/uploads/2025/06/roundrect2.jpg?w=940" src="https://eclecticlight.co/wp-content/uploads/2025/06/roundrect2.jpg" alt="" width="940" height="708" srcset="https://eclecticlight.co/wp-content/uploads/2025/06/roundrect2.jpg?w=940&amp;h=708 940w, https://eclecticlight.co/wp-content/uploads/2025/06/roundrect2.jpg?w=150&amp;h=113 150w, https://eclecticlight.co/wp-content/uploads/2025/06/roundrect2.jpg?w=300&amp;h=226 300w, https://eclecticlight.co/wp-content/uploads/2025/06/roundrect2.jpg?w=768&amp;h=579 768w, https://eclecticlight.co/wp-content/uploads/2025/06/roundrect2.jpg?w=1024&amp;h=772 1024w, https://eclecticlight.co/wp-content/uploads/2025/06/roundrect2.jpg 1408w" sizes="(max-width: 940px) 100vw, 940px"></a></span></p>
<p>Among Apple’s claims for this new look is greater consistency. But two windows in the same app, both created using SwiftUI, can’t even share a common radius, as shown below in Providable running in macOS 26.2.</p>
<p><span><a href="https://eclecticlight.co/wp-content/uploads/2025/12/understab1.jpg"><img data-attachment-id="89997" data-permalink="https://eclecticlight.co/2025/12/28/last-year-on-my-mac-look-back-in-disbelief/understab1/" data-orig-file="https://eclecticlight.co/wp-content/uploads/2025/12/understab1.jpg" data-orig-size="827,661" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="understab1" data-image-description="" data-image-caption="" data-medium-file="https://eclecticlight.co/wp-content/uploads/2025/12/understab1.jpg?w=300" data-large-file="https://eclecticlight.co/wp-content/uploads/2025/12/understab1.jpg?w=827" loading="lazy" src="https://eclecticlight.co/wp-content/uploads/2025/12/understab1.jpg" alt="" width="827" height="661" srcset="https://eclecticlight.co/wp-content/uploads/2025/12/understab1.jpg 827w, https://eclecticlight.co/wp-content/uploads/2025/12/understab1.jpg?w=150&amp;h=120 150w, https://eclecticlight.co/wp-content/uploads/2025/12/understab1.jpg?w=300&amp;h=240 300w, https://eclecticlight.co/wp-content/uploads/2025/12/understab1.jpg?w=768&amp;h=614 768w" sizes="(max-width: 827px) 100vw, 827px"></a></span></p>
<h4>Out of control</h4>
<p>Tahoe has also increased the size of its controls, without using that to improve their clarity. The best way to see that is in my Mallyshag demo app.</p>
<p><span><a href="https://eclecticlight.co/wp-content/uploads/2025/06/mallyshag2.png"><img data-attachment-id="87172" data-permalink="https://eclecticlight.co/2025/06/29/last-week-on-my-mac-plan-ahead-with-this-summers-mallyshag/mallyshag2/" data-orig-file="https://eclecticlight.co/wp-content/uploads/2025/06/mallyshag2.png" data-orig-size="958,214" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="mallyshag2" data-image-description="" data-image-caption="" data-medium-file="https://eclecticlight.co/wp-content/uploads/2025/06/mallyshag2.png?w=300" data-large-file="https://eclecticlight.co/wp-content/uploads/2025/06/mallyshag2.png?w=940" loading="lazy" src="https://eclecticlight.co/wp-content/uploads/2025/06/mallyshag2.png" alt="" width="940" height="210" srcset="https://eclecticlight.co/wp-content/uploads/2025/06/mallyshag2.png?w=940&amp;h=210 940w, https://eclecticlight.co/wp-content/uploads/2025/06/mallyshag2.png?w=150&amp;h=34 150w, https://eclecticlight.co/wp-content/uploads/2025/06/mallyshag2.png?w=300&amp;h=67 300w, https://eclecticlight.co/wp-content/uploads/2025/06/mallyshag2.png?w=768&amp;h=172 768w, https://eclecticlight.co/wp-content/uploads/2025/06/mallyshag2.png 958w" sizes="(max-width: 940px) 100vw, 940px"></a></span></p>
<p>This looks good in Sequoia above, but becomes a mess in Tahoe (below) because of its changed control dimensions.</p>
<p><span><a href="https://eclecticlight.co/wp-content/uploads/2025/06/mallyshag3.png"><img data-attachment-id="87173" data-permalink="https://eclecticlight.co/2025/06/29/last-week-on-my-mac-plan-ahead-with-this-summers-mallyshag/mallyshag3/" data-orig-file="https://eclecticlight.co/wp-content/uploads/2025/06/mallyshag3.png" data-orig-size="960,206" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="mallyshag3" data-image-description="" data-image-caption="" data-medium-file="https://eclecticlight.co/wp-content/uploads/2025/06/mallyshag3.png?w=300" data-large-file="https://eclecticlight.co/wp-content/uploads/2025/06/mallyshag3.png?w=940" loading="lazy" src="https://eclecticlight.co/wp-content/uploads/2025/06/mallyshag3.png" alt="" width="940" height="202" srcset="https://eclecticlight.co/wp-content/uploads/2025/06/mallyshag3.png?w=940&amp;h=202 940w, https://eclecticlight.co/wp-content/uploads/2025/06/mallyshag3.png?w=150&amp;h=32 150w, https://eclecticlight.co/wp-content/uploads/2025/06/mallyshag3.png?w=300&amp;h=64 300w, https://eclecticlight.co/wp-content/uploads/2025/06/mallyshag3.png?w=768&amp;h=165 768w, https://eclecticlight.co/wp-content/uploads/2025/06/mallyshag3.png 960w" sizes="(max-width: 940px) 100vw, 940px"></a></span></p>
<p>Those three buttons are significantly wider, so now overlap one another and are wider than the text box below. The user sees no benefit to this, though, as the text within the controls is identical.</p>
<h4>Iconoclasm</h4>
<p>App icons need to be both distinguishable and readily recalled. The first ensures that we can tell one from another, and relies on all the visual cues we can muster, including colours, form and content. Tahoe enforces a rule that everything in the icon must be fitted inside its uniform square with rounded corners, so restricting cues to colours and contents. As a result, the icons of many bundled and other Apple apps have become harder to distinguish in a crowded Dock. Some, including Apple’s Developer app and the App Store, are indistinguishable, while others have degenerated into vague blotches.</p>
<p><span><a href="https://eclecticlight.co/wp-content/uploads/2025/12/unicon15.jpg"><img data-attachment-id="90002" data-permalink="https://eclecticlight.co/2025/12/28/last-year-on-my-mac-look-back-in-disbelief/unicon15/" data-orig-file="https://eclecticlight.co/wp-content/uploads/2025/12/unicon15.jpg" data-orig-size="1145,1109" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="unicon15" data-image-description="" data-image-caption="" data-medium-file="https://eclecticlight.co/wp-content/uploads/2025/12/unicon15.jpg?w=300" data-large-file="https://eclecticlight.co/wp-content/uploads/2025/12/unicon15.jpg?w=940" loading="lazy" src="https://eclecticlight.co/wp-content/uploads/2025/12/unicon15.jpg" alt="" width="940" height="910" srcset="https://eclecticlight.co/wp-content/uploads/2025/12/unicon15.jpg?w=940&amp;h=910 940w, https://eclecticlight.co/wp-content/uploads/2025/12/unicon15.jpg?w=150&amp;h=145 150w, https://eclecticlight.co/wp-content/uploads/2025/12/unicon15.jpg?w=300&amp;h=291 300w, https://eclecticlight.co/wp-content/uploads/2025/12/unicon15.jpg?w=768&amp;h=744 768w, https://eclecticlight.co/wp-content/uploads/2025/12/unicon15.jpg?w=1024&amp;h=992 1024w, https://eclecticlight.co/wp-content/uploads/2025/12/unicon15.jpg 1145w" sizes="(max-width: 940px) 100vw, 940px"></a></span></p>
<p>Above are most of the apps bundled in Sequoia, and below are those in Tahoe.</p>
<p><span><a href="https://eclecticlight.co/wp-content/uploads/2025/12/unicon26.jpg"><img data-attachment-id="90003" data-permalink="https://eclecticlight.co/2025/12/28/last-year-on-my-mac-look-back-in-disbelief/unicon26/" data-orig-file="https://eclecticlight.co/wp-content/uploads/2025/12/unicon26.jpg" data-orig-size="1309,937" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="unicon26" data-image-description="" data-image-caption="" data-medium-file="https://eclecticlight.co/wp-content/uploads/2025/12/unicon26.jpg?w=300" data-large-file="https://eclecticlight.co/wp-content/uploads/2025/12/unicon26.jpg?w=940" loading="lazy" src="https://eclecticlight.co/wp-content/uploads/2025/12/unicon26.jpg" alt="" width="940" height="673" srcset="https://eclecticlight.co/wp-content/uploads/2025/12/unicon26.jpg?w=940&amp;h=673 940w, https://eclecticlight.co/wp-content/uploads/2025/12/unicon26.jpg?w=150&amp;h=107 150w, https://eclecticlight.co/wp-content/uploads/2025/12/unicon26.jpg?w=300&amp;h=215 300w, https://eclecticlight.co/wp-content/uploads/2025/12/unicon26.jpg?w=768&amp;h=550 768w, https://eclecticlight.co/wp-content/uploads/2025/12/unicon26.jpg?w=1024&amp;h=733 1024w, https://eclecticlight.co/wp-content/uploads/2025/12/unicon26.jpg 1309w" sizes="(max-width: 940px) 100vw, 940px"></a></span></p>
<h4>Whiteout</h4>
<p>In real life, whiteouts are dangerous because they’re so disorienting. There’s no horizon, no features in the landscape, and no clues to navigation. We see and work best in visual environments that are rich in colour and tonal contrasts. Tahoe has continued a trend for Light Mode to be bleached-out white, and Dark Mode to be a moonless night. Seeing where controls, views and contents start and end is difficult, and leaves them suspended in the whiteout.</p>
<p><span><a href="https://eclecticlight.co/wp-content/uploads/2025/09/tahoelightstd.jpg"><img data-attachment-id="88381" data-permalink="https://eclecticlight.co/2025/09/15/appearance-matters-get-tahoe-looking-in-better-shape/tahoelightstd/" data-orig-file="https://eclecticlight.co/wp-content/uploads/2025/09/tahoelightstd.jpg" data-orig-size="1140,737" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="tahoelightstd" data-image-description="" data-image-caption="" data-medium-file="https://eclecticlight.co/wp-content/uploads/2025/09/tahoelightstd.jpg?w=300" data-large-file="https://eclecticlight.co/wp-content/uploads/2025/09/tahoelightstd.jpg?w=940" loading="lazy" src="https://eclecticlight.co/wp-content/uploads/2025/09/tahoelightstd.jpg" alt="" width="940" height="608" srcset="https://eclecticlight.co/wp-content/uploads/2025/09/tahoelightstd.jpg?w=940&amp;h=608 940w, https://eclecticlight.co/wp-content/uploads/2025/09/tahoelightstd.jpg?w=150&amp;h=97 150w, https://eclecticlight.co/wp-content/uploads/2025/09/tahoelightstd.jpg?w=300&amp;h=194 300w, https://eclecticlight.co/wp-content/uploads/2025/09/tahoelightstd.jpg?w=768&amp;h=497 768w, https://eclecticlight.co/wp-content/uploads/2025/09/tahoelightstd.jpg?w=1024&amp;h=662 1024w, https://eclecticlight.co/wp-content/uploads/2025/09/tahoelightstd.jpg 1140w" sizes="(max-width: 940px) 100vw, 940px"></a></span></p>
<p>In light mode, with default transparency, tool icons and text are clearly distinguished tonally, as are some controls including buttons and checkboxes. However, text entry fields are indistinguishable from the background, and there’s a general lack of demarcation, particularly between controls and the list view below.</p>
<p><span><a href="https://eclecticlight.co/wp-content/uploads/2025/10/tahoelightnorm.png"><img data-attachment-id="88855" data-permalink="https://eclecticlight.co/2025/10/12/last-week-on-my-mac-tahoes-elephant/tahoelightnorm/" data-orig-file="https://eclecticlight.co/wp-content/uploads/2025/10/tahoelightnorm.png" data-orig-size="2298,325" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="tahoelightnorm" data-image-description="" data-image-caption="" data-medium-file="https://eclecticlight.co/wp-content/uploads/2025/10/tahoelightnorm.png?w=300" data-large-file="https://eclecticlight.co/wp-content/uploads/2025/10/tahoelightnorm.png?w=940" loading="lazy" src="https://eclecticlight.co/wp-content/uploads/2025/10/tahoelightnorm.png" alt="" width="940" height="133" srcset="https://eclecticlight.co/wp-content/uploads/2025/10/tahoelightnorm.png?w=940&amp;h=133 940w, https://eclecticlight.co/wp-content/uploads/2025/10/tahoelightnorm.png?w=1880&amp;h=266 1880w, https://eclecticlight.co/wp-content/uploads/2025/10/tahoelightnorm.png?w=150&amp;h=21 150w, https://eclecticlight.co/wp-content/uploads/2025/10/tahoelightnorm.png?w=300&amp;h=42 300w, https://eclecticlight.co/wp-content/uploads/2025/10/tahoelightnorm.png?w=768&amp;h=109 768w, https://eclecticlight.co/wp-content/uploads/2025/10/tahoelightnorm.png?w=1024&amp;h=145 1024w, https://eclecticlight.co/wp-content/uploads/2025/10/tahoelightnorm.png?w=1440&amp;h=204 1440w" sizes="(max-width: 940px) 100vw, 940px"></a></span></p>
<h4>Wet-on-wet</h4>
<p>This technique is used in watercolours to merge layers of colour diffusely, and the best description of some of the results of transparency in Liquid Glass. My examples speak for themselves, and are drawn first from Apple’s own design for System Settings.</p>
<p><span><a href="https://eclecticlight.co/wp-content/uploads/2025/12/understain1.jpg"><img data-attachment-id="89998" data-permalink="https://eclecticlight.co/2025/12/28/last-year-on-my-mac-look-back-in-disbelief/understain1/" data-orig-file="https://eclecticlight.co/wp-content/uploads/2025/12/understain1.jpg" data-orig-size="1519,234" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="understain1" data-image-description="" data-image-caption="" data-medium-file="https://eclecticlight.co/wp-content/uploads/2025/12/understain1.jpg?w=300" data-large-file="https://eclecticlight.co/wp-content/uploads/2025/12/understain1.jpg?w=940" loading="lazy" src="https://eclecticlight.co/wp-content/uploads/2025/12/understain1.jpg" alt="" width="940" height="145" srcset="https://eclecticlight.co/wp-content/uploads/2025/12/understain1.jpg?w=940&amp;h=145 940w, https://eclecticlight.co/wp-content/uploads/2025/12/understain1.jpg?w=150&amp;h=23 150w, https://eclecticlight.co/wp-content/uploads/2025/12/understain1.jpg?w=300&amp;h=46 300w, https://eclecticlight.co/wp-content/uploads/2025/12/understain1.jpg?w=768&amp;h=118 768w, https://eclecticlight.co/wp-content/uploads/2025/12/understain1.jpg?w=1024&amp;h=158 1024w, https://eclecticlight.co/wp-content/uploads/2025/12/understain1.jpg?w=1440&amp;h=222 1440w, https://eclecticlight.co/wp-content/uploads/2025/12/understain1.jpg 1519w" sizes="(max-width: 940px) 100vw, 940px"></a></span></p>
<p>Transparency of the Search box at the top of the sidebar on the left renders it incomprehensible when it’s underlaid by scrolled navigational content.</p>
<p><span><a href="https://eclecticlight.co/wp-content/uploads/2025/12/understain2.jpg"><img data-attachment-id="89999" data-permalink="https://eclecticlight.co/2025/12/28/last-year-on-my-mac-look-back-in-disbelief/understain2/" data-orig-file="https://eclecticlight.co/wp-content/uploads/2025/12/understain2.jpg" data-orig-size="1533,223" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="understain2" data-image-description="" data-image-caption="" data-medium-file="https://eclecticlight.co/wp-content/uploads/2025/12/understain2.jpg?w=300" data-large-file="https://eclecticlight.co/wp-content/uploads/2025/12/understain2.jpg?w=940" loading="lazy" src="https://eclecticlight.co/wp-content/uploads/2025/12/understain2.jpg" alt="" width="940" height="137" srcset="https://eclecticlight.co/wp-content/uploads/2025/12/understain2.jpg?w=940&amp;h=137 940w, https://eclecticlight.co/wp-content/uploads/2025/12/understain2.jpg?w=150&amp;h=22 150w, https://eclecticlight.co/wp-content/uploads/2025/12/understain2.jpg?w=300&amp;h=44 300w, https://eclecticlight.co/wp-content/uploads/2025/12/understain2.jpg?w=768&amp;h=112 768w, https://eclecticlight.co/wp-content/uploads/2025/12/understain2.jpg?w=1024&amp;h=149 1024w, https://eclecticlight.co/wp-content/uploads/2025/12/understain2.jpg?w=1440&amp;h=209 1440w, https://eclecticlight.co/wp-content/uploads/2025/12/understain2.jpg 1533w" sizes="(max-width: 940px) 100vw, 940px"></a></span></p>
<p>Although the view title <em>Keyboard</em> remains readable, bleed-through of underlying colours is confusing, distracting and aesthetically upsetting.</p>
<p>My next examples show the same window in Providable with a selected list row being scrolled up behind what used to be a window title bar.</p>
<p><span><a href="https://eclecticlight.co/wp-content/uploads/2025/12/understain3.jpg"><img data-attachment-id="90000" data-permalink="https://eclecticlight.co/2025/12/28/last-year-on-my-mac-look-back-in-disbelief/understain3/" data-orig-file="https://eclecticlight.co/wp-content/uploads/2025/12/understain3.jpg" data-orig-size="1506,688" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="understain3" data-image-description="" data-image-caption="" data-medium-file="https://eclecticlight.co/wp-content/uploads/2025/12/understain3.jpg?w=300" data-large-file="https://eclecticlight.co/wp-content/uploads/2025/12/understain3.jpg?w=940" loading="lazy" src="https://eclecticlight.co/wp-content/uploads/2025/12/understain3.jpg" alt="" width="940" height="429" srcset="https://eclecticlight.co/wp-content/uploads/2025/12/understain3.jpg?w=940&amp;h=429 940w, https://eclecticlight.co/wp-content/uploads/2025/12/understain3.jpg?w=150&amp;h=69 150w, https://eclecticlight.co/wp-content/uploads/2025/12/understain3.jpg?w=300&amp;h=137 300w, https://eclecticlight.co/wp-content/uploads/2025/12/understain3.jpg?w=768&amp;h=351 768w, https://eclecticlight.co/wp-content/uploads/2025/12/understain3.jpg?w=1024&amp;h=468 1024w, https://eclecticlight.co/wp-content/uploads/2025/12/understain3.jpg?w=1440&amp;h=658 1440w, https://eclecticlight.co/wp-content/uploads/2025/12/understain3.jpg 1506w" sizes="(max-width: 940px) 100vw, 940px"></a></span></p>
<p>With the window in focus, the selection colour overwhelms the traffic light controls and window title, which should read <em>Drop Files.</em> This also draws attention to the limited width necessary to accommodate rectangular content in a window with excessively rounded corners.</p>
<p><span><a href="https://eclecticlight.co/wp-content/uploads/2025/12/understain4.jpg"><img data-attachment-id="90001" data-permalink="https://eclecticlight.co/2025/12/28/last-year-on-my-mac-look-back-in-disbelief/understain4/" data-orig-file="https://eclecticlight.co/wp-content/uploads/2025/12/understain4.jpg" data-orig-size="1418,600" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="understain4" data-image-description="" data-image-caption="" data-medium-file="https://eclecticlight.co/wp-content/uploads/2025/12/understain4.jpg?w=300" data-large-file="https://eclecticlight.co/wp-content/uploads/2025/12/understain4.jpg?w=940" loading="lazy" src="https://eclecticlight.co/wp-content/uploads/2025/12/understain4.jpg" alt="" width="940" height="398" srcset="https://eclecticlight.co/wp-content/uploads/2025/12/understain4.jpg?w=940&amp;h=398 940w, https://eclecticlight.co/wp-content/uploads/2025/12/understain4.jpg?w=150&amp;h=63 150w, https://eclecticlight.co/wp-content/uploads/2025/12/understain4.jpg?w=300&amp;h=127 300w, https://eclecticlight.co/wp-content/uploads/2025/12/understain4.jpg?w=768&amp;h=325 768w, https://eclecticlight.co/wp-content/uploads/2025/12/understain4.jpg?w=1024&amp;h=433 1024w, https://eclecticlight.co/wp-content/uploads/2025/12/understain4.jpg 1418w" sizes="(max-width: 940px) 100vw, 940px"></a></span></p>
<p>Out of focus the selected row is less overwhelming, but traffic lights and title have dissipated in grey blur.</p>
<p>I’m sure that, in the right place and time, transparency effects of Liquid Glass can be visually pleasing. Not only is this the wrong time and place, but those with visual impairment can no longer remove or even reduce these effects, as the <strong>Reduce Transparency</strong> control in Accessibility settings no longer reduces transparency in any useful way. That was one of the regressions in 26.1 that hasn’t been addressed in 26.2.</p>
<h4>Summary</h4>
<p>macOS Tahoe’s visual interface:</p>
<ul>
<li>Fits largely rectangular contents into windows with excessively rounded corners.</li>
<li>Enlarges controls without any functional benefit.</li>
<li>Results in app icons being more uniform, thus less distinguishable and memorable.</li>
<li>Fails to distinguish tools, controls and other interface elements using differences in tone, so making them harder to use.</li>
<li>Makes a mess where transparent layers are superimposed, and won’t reduce transparency when that’s needed to render its interface more accessible.</li>
</ul>
<p>Maybe this is because I’m getting older, but that gives me the benefit of having experienced Apple’s older interfaces, with their exceptional quality and functionality.</p>
<p><span><img data-attachment-id="73511" data-permalink="https://eclecticlight.co/icloud20142/" data-orig-file="https://eclecticlight.co/wp-content/uploads/2023/08/icloud20142.png" data-orig-size="1280,720" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="icloud20142" data-image-description="" data-image-caption="" data-medium-file="https://eclecticlight.co/wp-content/uploads/2023/08/icloud20142.png?w=300" data-large-file="https://eclecticlight.co/wp-content/uploads/2023/08/icloud20142.png?w=940" loading="lazy" src="https://eclecticlight.co/wp-content/uploads/2023/08/icloud20142.png?w=940" alt="icloud20142" srcset="https://eclecticlight.co/wp-content/uploads/2023/08/icloud20142.png 1280w, https://eclecticlight.co/wp-content/uploads/2023/08/icloud20142.png?w=150&amp;h=84 150w, https://eclecticlight.co/wp-content/uploads/2023/08/icloud20142.png?w=300&amp;h=169 300w, https://eclecticlight.co/wp-content/uploads/2023/08/icloud20142.png?w=768&amp;h=432 768w, https://eclecticlight.co/wp-content/uploads/2023/08/icloud20142.png?w=1024&amp;h=576 1024w" sizes="(max-width: 1280px) 100vw, 1280px"></span></p>
<p>That was little more than a decade ago, in 2014. Not that I want to turn the clock back, but it would be really helpful if I could read clearly what’s on my display once again.</p>
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Hungry Fat Cells Could Someday Starve Cancer (153 pts)]]></title>
            <link>https://www.ucsf.edu/news/2025/01/429411/how-hungry-fat-cells-could-someday-starve-cancer-death</link>
            <guid>46409928</guid>
            <pubDate>Sun, 28 Dec 2025 10:04:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ucsf.edu/news/2025/01/429411/how-hungry-fat-cells-could-someday-starve-cancer-death">https://www.ucsf.edu/news/2025/01/429411/how-hungry-fat-cells-could-someday-starve-cancer-death</a>, See on <a href="https://news.ycombinator.com/item?id=46409928">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="block-ucsf-content">
  
    
      


<main>
    <a id="main-content" tabindex="-1"></a>
        
<div data-history-node-id="429411">
  <div>
          
                <figure>
    
          <figcaption>Electron microscopy of fat organoids that were implanted to out-compete tumors. Image by Desai Lab</figcaption>
      </figure>
      
        
  </div>


  <header>
    







              <h2>Scientists transformed energy-storing white fat cells into calorie-burning ‘beige’ fat. Once implanted, they outcompeted tumors for resources, beating back five different types of cancer in lab experiments.</h2>
      
<p>

            
      By
  
    <a href="https://www.ucsf.edu/bio/levi-gadye">Levi Gadye</a></p>
  </header>
</div>
<div>
  

   


    <div><p>Liposuction and plastic surgery aren’t often mentioned in the same breath as cancer.</p>

<p>But they are the inspiration for a new approach to treating cancer that uses engineered fat cells to deprive tumors of nutrition.</p>

<p>Researchers at UC San Francisco used the gene editing technology CRISPR to turn ordinary white fat cells into “beige” fat cells, which voraciously consume calories to make heat. The work is funded by the National Institute of Health (NIH).</p>

<p>Then, they implanted them near tumors the way plastic surgeons inject fat from one part of the body to plump up another. The fat cells scarfed up all the nutrients, starving most of the tumor cells to death. The approach even worked when the fat cells were implanted in mice far from the sites of their tumors.</p>

<p>The approach's reliance on a common procedure could speed its use as a new form of cellular therapy.</p>

<p>“We already routinely remove fat cells with liposuction and put them back via plastic surgery,” said <a href="https://profiles.ucsf.edu/nadav.ahituv">Nadav Ahituv</a>, PhD, director of the <a href="https://humangenetics.ucsf.edu/">UCSF Institute for Human Genetics</a> and professor in the Department of Bioengineering and Therapeutic Sciences. He is the senior author of the paper, which appears Feb. 4 in <em><a href="https://www.nature.com/articles/s41587-024-02551-2">Nature Biotechnology</a></em>. “These fat cells can be easily manipulated in the lab and safely placed back into the body, making them an attractive platform for cellular therapy, including for cancer.”</p>

<figure>


<figcaption>Clumps of energy-hungry beige fat cells, made from white fat cells taken via liposuction, ate up all excess nutrients and starved growing tumors in an animal model. The tumors shrank - even when the fat cells were implanted far from the tumor.&nbsp;<em>Image by Desai Lab</em></figcaption>
</figure>


<h2><br>
Cold therapy sparks a new idea</h2>

<p>Ahituv and his post-doc at the time, Hai Nguyen, PhD, were aware of studies that showed exposure to cold could suppress cancer in mice. One experiment even showed it could help a patient with non-Hodgkin lymphoma. Scientists concluded that the cancer cells were starving because the cold was activating brown fat cells.</p>

<p>But cold therapy isn’t a viable option for cancer patients with fragile health. So, Ahituv and Nguyen turned to the idea of using beige fat, wagering that they could engineer it to burn enough calories, even in the absence of cold, to deprive tumors of the fuel they needed to grow.</p>

<p>Nguyen, who is the first author of the paper, used CRISPR to activate genes that are dormant in white fat cells but are active in brown fat cells, in the hopes of finding the ones that would transform the white fat cells into the hungriest of beige fat cells.</p>

<p>A gene called UCP1 rose to the top. Nguyen grew UCP1 beige fat cells and cancer cells in a “trans-well” petri dish. The cancer cells were on the bottom and the fat cells were above them in separate compartments that kept the cells apart but forced them to share nutrients. The results were shocking.</p>

<p>“In our very first trans-well experiment, very few cancer cells survived. We thought we had messed something up – we were sure it was a mistake,” Ahituv recalled. “So, we repeated it multiple times, and we kept seeing the same effect.”</p>

<p>The beige fat cells held sway over two different types of breast cancer cells, as well as colon, pancreatic and prostate cancer cells.</p>

<dom-twocolumn-layout data-column1-color="transparent" data-column1-size="50" data-column2-color="transparent" data-column2-size="50">
	<div slot="column1">
	


	<p><strong>No fat cells:</strong> Actively-multiplying cancer cells (pink) are seen in a mouse predisposed to develop breast cancer. &nbsp;</p>
	</div>

	<div slot="column2">
	


	<p><strong>Fat cells are added:</strong> When fat cells were implanted in the breast, far fewer cancer cells were able to multiply. &nbsp;</p>
	</div>
</dom-twocolumn-layout>

<h2>Cancer is no match for hungry fat</h2>

<p>But the researchers still didn’t know if the beige fat cells would work in a more realistic context. So, they turned to fat organoids, which are coherent clumps of cells grown in a dish, to see if they could beat tumor cells when they were implanted next to tumors in mice. The approach worked against breast cancer, as well as pancreatic and prostate cancer cells. The cancer cells starved as the fat cells gobbled up all the available nutrients.</p>

<p>Once implanted into mice that were genetically predisposed to develop cancer, the beige fat cells were so powerful that they suppressed pancreatic and breast tumors. Beige fat even worked when it was implanted far away from the breast cancer cells.</p>

<figure>


<figcaption>Fat cells grown in a petri dish. <em>Image by Ahituv Lab</em></figcaption>
</figure>


<p>To see how the fat cells would work in human tissue, Ahituv and Nguyen teamed up with <a href="https://profiles.ucsf.edu/jennifer.rosenbluth">Jennifer Rosenbluth</a>, MD, PhD, a breast cancer specialist at UCSF. Rosenbluth had amassed a library of breast cancer tissue from mastectomies containing both fat cells and cancer cells.</p>

<p>“Because the breast has a lot of fat, we could get fat from the same patient, modify the fat and grow it in a single trans-well experiment with that patient’s own breast cancer cells,” Ahituv said.</p>

<p>These same-patient beige fat cells outcompeted breast cancer cells in petri dishes – and when they were implanted together in mouse models.</p>

<p>Knowing that cancers have preferred diets, the researchers engineered fat just to eat certain nutrients. Certain forms of pancreatic cancer, for example, rely on uridine when glucose is scarce. So, they programmed the fat cells to eat just uridine, and they easily outcompeted the pancreatic cancer cells. This suggested that fat could be adapted to any cancer’s dietary preferences.</p>

<h2>A new approach to living cell therapy</h2>

<p>Fat cells have many advantages when it comes to living cell therapies, according to Ahituv. They are easy to obtain from patients. They grow well in the laboratory and can be engineered to express different genes and take on different biological roles. And they behave well once they are put back into the body, not straying from the location where they’re implanted and playing nice with the immune system.</p>

<p>It’s a conclusion supported by decades of plastic surgery.</p>

<p>“With fat cells, there’s less interaction with the environment, so there’s very little worry of the cells leaking out into the body, where they might cause problems,” Ahituv said.</p>

<p>Fat cells can also be programmed to emit signals or carry out more complicated tasks.</p>

<p>And their ability to defeat cancer even when they are not right next to tumors could prove invaluable for treating hard-to-reach cancers like glioblastoma, which affects the brain, as well as many other diseases.</p>

<p>“We think these cells could also be designed to sense glucose in the bloodstream and release insulin, for diabetes, or suck up iron in diseases where there’s excessive iron like hemochromatosis,” Ahituv said. “The sky’s the limit for these fat cells.”</p>
</div>

    

<div>
  
                  <div>


<dom-threecolumn-layout data-column1-color="transparent" data-column1-size="20" data-column2-color="transparent" data-column2-size="60" data-column3-color="transparent" data-column3-size="20">
	

	<div slot="column2">
	


	<h3>A pioneering scientist is lost too soon</h3>

	<p>The discovery of how hungry fat cells could suppress cancer began in 2021, when Hai Nguyen, PhD, joined Ahituv’s lab. Nguyen had years of experience working with fat cells in the laboratory. But he wasn’t aware of their cancer-fighting potential until an experiment pitting engineered beige fat cells against cancer cells tipped them off.</p>

	<p>Amazed at how the beige fat was able to starve the tumors, they tested the engineered cells against all sorts of cancers in the lab. The project grew to include other scientists and cancer specialists at UCSF and across the country, offering a proof of principle that the approach could work against a wide range of cancers.</p>

	<p>Nguyen moved to UT Austin to start his own lab in January 2024 but passed away suddenly in November before he could finish the final experiments. The paper, of which he is the first author, is dedicated to him.</p>

	<p>“Hai was one of the most amazing post-docs I’ll ever have and a great friend,” Ahituv said. “We are heartbroken. He has left us with this incredible gift of a technology that could truly change lives.”</p>

	
	</div>

	
</dom-threecolumn-layout>
</div>
            
                  <div>



<h3>A pioneering scientist is lost<br>
too soon</h3>

<p>The discovery of how hungry fat cells could suppress cancer began in 2021, when Hai Nguyen, PhD, joined Ahituv’s lab. Nguyen had years of experience working with fat cells in the laboratory. But he wasn’t aware of their cancer-fighting potential until an experiment pitting engineered beige fat cells against cancer cells tipped them off.</p>

<p>Amazed at how the beige fat was able to starve the tumors, they tested the engineered cells against all sorts of cancers in the lab. The project grew to include other scientists and cancer specialists at UCSF and across the country, offering a proof of principle that the approach could work against a wide range of cancers.</p>

<p>Nguyen moved to UT Austin to start his own lab in January 2024 but passed away suddenly in November before he could finish the final experiments. The paper, of which he is the first author, is dedicated to him.</p>

<p>“Hai was one of the most amazing post-docs I’ll ever have and a great friend,” Ahituv said. “We are heartbroken. He has left us with this incredible gift of a technology that could truly change lives.”</p>
</div>
            
</div>

  
<div>
  
              <p><br>
<strong>Authors:</strong> In addition to Ahituv, Nguyen, and Rosenbluth, other UCSF authors include Kelly An, Yusuke Ito, Bhushan N. Kharbikar, PhD, Rory Sheng, Breanna Paredes, MS, Elizabeth Murray, Kimberly Pham, Michael Bruck, Xujia Zhou, MS, PhD, Cassidy Biellak, Aki Ushiki, PhD, Mai Nobuhara, MS, Daniel A. Bernards, PhD, Mark Jesus M. Magbanua, PhD, Laura A. Huppert, MD, Heinz Hammerlindl, PhD, Laura Esserman, MD, MBA, Tejal A. Desai, PhD, and Sook Wah Yee, MPharm. For all authors see the paper.</p>

<p><strong>Funding:</strong> The work was funded in part by the UCSF Sandler Program for Breakthrough Biomedical Research, the UCSF Living Therapeutics Initiative, the National Institutes of Health (1R01DK124769, 1R01CA283826) and the California Institute for Regenerative Medicine. Ahituv is a cofounder and on the scientific advisory board of Regel Therapeutics.</p>

<p><strong>Disclosures:</strong> Ahituv receives funding from BioMarin Pharmaceutical Incorporate. Ahituv has filed a patent application covering embodiments and concepts disclosed in the manuscript. For all funding and disclosures see the paper.</p>

      
</div>






</div>
  </main>




  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A new research shows that 21-33% of YouTube's feed may consist of AI slop (157 pts)]]></title>
            <link>https://www.kapwing.com/blog/ai-slop-report-the-global-rise-of-low-quality-ai-videos/</link>
            <guid>46409125</guid>
            <pubDate>Sun, 28 Dec 2025 07:14:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.kapwing.com/blog/ai-slop-report-the-global-rise-of-low-quality-ai-videos/">https://www.kapwing.com/blog/ai-slop-report-the-global-rise-of-low-quality-ai-videos/</a>, See on <a href="https://news.ycombinator.com/item?id=46409125">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
                <p>As the debate over the <a href="https://www.kapwing.com/blog/the-most-used-prompts-for-ai-videos-and-images/"><u>creative and ethical value</u></a> of using AI to generate video rages on, users are getting interesting results out of the machine, and artist-led AI content is gaining respect in some areas. Top <a href="https://lfw.org.uk/course/introduction-to-ai/?ref=kapwing.com"><u>film schools</u></a> now offer courses on the use and ethics of AI in film production, and the world’s best-known brands are utilizing AI in their creative process — albeit <a href="https://www.creativebloq.com/design/advertising/devastating-graphic-shows-just-how-bad-the-coca-cola-christmas-ad-really-is?ref=kapwing.com"><u>with mixed results</u></a>.</p><p>Sadly, others are gaming the novelty of AI’s prompt-and-go content, using these engines to churn out vast quantities of AI “slop” — the “spam” of the video-first age. </p><p>Wiktionary defines a <a href="https://en.wiktionary.org/wiki/slopper?ref=kapwing.com"><u>slopper</u></a> as “Someone who is overreliant on generative AI tools such as ChatGPT; a producer of AI slop.” Along with the proliferation of “brainrot” videos online, sloppers are making it tough for principled and talented creators to get their videos seen.</p>
<!--kg-card-begin: html-->
<table><colgroup><col></colgroup><tbody><tr><td><p dir="ltr"><span>AI Slop</span><span>: Careless, low-quality content generated using automatic computer applications and distributed to farm views and subscriptions or sway political opinion.</span></p><p dir="ltr"><span>Brainrot</span><span>: Compulsive, nonsensical, low-quality video content that creates the effect of corroding the viewer’s mental or intellectual state while watching; often generated with AI.</span></p></td></tr></tbody></table>
<!--kg-card-end: html-->
<p>The main point of AI slop and brainrot videos is to grab your attention, and this type of content seems harder and harder to avoid. But exactly how prevalent is it in the grand scheme of things? </p><p><a href="https://www.kapwing.com/?ref=kapwing.com"><u>Kapwing</u></a> analyzed the view and subscriber counts of trending AI slop and brainrot YouTube channels to find out which ones are competing most fiercely with handmade content around the world and how much revenue the leading sloppers are making.</p><h2 id="what-we-did">What We Did</h2><p>We identified the top 100 trending YouTube channels in every country and noted the AI slop channels. Next, we used socialblade.com to retrieve the number of views, subscribers, and estimated yearly revenue for these channels and aggregated these figures for each country to deduce their popularity. We also created a new YouTube account to record the number of AI slop and brainrot videos among the first 500 YouTube Shorts we cycled through to get an idea of the new-user experience.</p><h2 id="key-findings">Key Findings</h2><ul><li><strong>Spain’s</strong> trending AI slop channels have a combined <strong>20.22 million subscribers</strong> — the most of any country.</li><li>In <strong>South Korea</strong>, the trending AI slop channels have amassed <strong>8.45 billion views</strong>.</li><li>The AI slop channel with the most views is India’s <strong><em>Bandar Apna Dost</em></strong> (<strong>2.07 billion views</strong>).<ul><li>The channel has estimated annual earnings of <strong>$4,251,500</strong>.</li></ul></li><li><strong>U.S.</strong>-based slop channel <strong><em>Cuentos Facinantes </em></strong>[sic] has the most subscribers of any slop channel globally (<strong>5.95 million</strong>).</li><li><a href="https://www.youtube.com/watch?v=g75A8vi9PVU&amp;ref=kapwing.com">Brainrot videos</a> account for around <strong>33%</strong> of the first 500 YouTube shorts on a new user’s feed.</li></ul><h2 id="spanish-and-south-korean-ai-slop-channels-have-most-devoted-viewerships">Spanish and South Korean AI Slop Channels Have Most Devoted Viewerships</h2><p>First, we analyzed the 100 top trending video channels in every country to see how prevalent AI slop has become locally.</p><p>We found that Spain has 20.22 million AI slop channel subscribers among its trending channels. This is despite Spain having fewer AI slop channels (eight) among its top 100 channels than countries including Pakistan (20), Egypt (14), South Korea (11) and the U.S. (nine). The U.S. has the third-most slop subscribers (14.47 million) — 28.4% fewer than Spain but 13.18% more than fourth-placed Brazil (12.56 million).</p><figure><img src="https://www.kapwing.com/blog/content/images/2025/11/01_The-Countries-Where-Trending-AI-Slop-Channels-Have-the-Most-Subscribers-.png" alt="" loading="lazy" width="2000" height="2500" srcset="https://www.kapwing.com/blog/content/images/size/w600/2025/11/01_The-Countries-Where-Trending-AI-Slop-Channels-Have-the-Most-Subscribers-.png 600w, https://www.kapwing.com/blog/content/images/size/w1000/2025/11/01_The-Countries-Where-Trending-AI-Slop-Channels-Have-the-Most-Subscribers-.png 1000w, https://www.kapwing.com/blog/content/images/size/w1600/2025/11/01_The-Countries-Where-Trending-AI-Slop-Channels-Have-the-Most-Subscribers-.png 1600w, https://www.kapwing.com/blog/content/images/2025/11/01_The-Countries-Where-Trending-AI-Slop-Channels-Have-the-Most-Subscribers-.png 2400w" sizes="(min-width: 720px) 720px"><figcaption><span>The Countries Where Trending AI Slop Channels Have the Most Subscribers </span></figcaption></figure><p>Spain’s AI slop subscriber base is boosted significantly by one channel, <a href="https://www.youtube.com/@Imperiodejesus?ref=kapwing.com"><em><u>Imperio de jesus</u></em></a>, which had 5.87 million subscribers at the time of analysis, making it the world’s second biggest AI slop channel (see <em>A Spanish-Language U.S. AI Slop Channel is the World’s Most-Subscribed</em> below).</p><p>Promising to strengthen “faith in Jesus through fun interactive quizzes,” the channel’s videos put the Son of God in a range of either/or scenarios where he must give the correct answer to get the better of Satan, the Grinch and others. Two other Spanish channels with over 3.5 million subscribers each focus on comedy/brainrot shorts.</p><p>While Spain’s eight trending AI slop channels may have the most subscribers, South Korea’s 11 trenders have the most views: some 8.45 billion in total. This is nearly 1.6 times as many as second-placed Pakistan (5.34B), 2.5 times as many as the third-placed U.S. (3.39B) and 3.4 times as many as Spain (2.52B).</p><figure><img src="https://www.kapwing.com/blog/content/images/2025/11/02_The-Countries-Where-Trending-AI-Slop-Channels-Have-the-Most-Views.png" alt="" loading="lazy" width="2000" height="2500" srcset="https://www.kapwing.com/blog/content/images/size/w600/2025/11/02_The-Countries-Where-Trending-AI-Slop-Channels-Have-the-Most-Views.png 600w, https://www.kapwing.com/blog/content/images/size/w1000/2025/11/02_The-Countries-Where-Trending-AI-Slop-Channels-Have-the-Most-Views.png 1000w, https://www.kapwing.com/blog/content/images/size/w1600/2025/11/02_The-Countries-Where-Trending-AI-Slop-Channels-Have-the-Most-Views.png 1600w, https://www.kapwing.com/blog/content/images/2025/11/02_The-Countries-Where-Trending-AI-Slop-Channels-Have-the-Most-Views.png 2400w" sizes="(min-width: 720px) 720px"><figcaption><span>The Countries Where Trending AI Slop Channels Have the Most Views</span></figcaption></figure><p>South Korean AI slop channel <em>Three Minutes Wisdom</em> alone accounts for nearly a quarter of the country’s massive view count, with 2.02 billion views. <em>Three Minutes Wisdom</em> has the second-highest view count of any trending slop channel globally, and we estimate the channel’s annual ad income to be around US$4,036,500.</p><p>The channel’s 140 videos typically feature photorealistic(ish) footage of wild animals being defeated by cute pets, and the URL in the bio appears to be an affiliate link to Coupang, South Korea’s largest online retailer.</p><h2 id="a-spanish-language-us-ai-slop-channel-is-the-world%E2%80%99s-most-subscribed">A Spanish-language U.S. AI Slop Channel is the World’s Most-Subscribed</h2><p>Next, we identified the specific channels with the most subscribers and views globally. U.S.-based <em>Cuentos Facinantes </em>[sic] has 5.95 million subscribers, making it the trending AI slop channel with the biggest following. This is only 1.4% more than <em>Imperio de jesus </em>(5.87M) but over 50% more than the eighth-, ninth- and tenth-most subscribed slop channels.</p><figure><img src="https://www.kapwing.com/blog/content/images/2025/11/03_The-Most-Subscribed-AI-Slop-Youtube-Channels.png" alt="" loading="lazy" width="2000" height="2500" srcset="https://www.kapwing.com/blog/content/images/size/w600/2025/11/03_The-Most-Subscribed-AI-Slop-Youtube-Channels.png 600w, https://www.kapwing.com/blog/content/images/size/w1000/2025/11/03_The-Most-Subscribed-AI-Slop-Youtube-Channels.png 1000w, https://www.kapwing.com/blog/content/images/size/w1600/2025/11/03_The-Most-Subscribed-AI-Slop-Youtube-Channels.png 1600w, https://www.kapwing.com/blog/content/images/2025/11/03_The-Most-Subscribed-AI-Slop-Youtube-Channels.png 2400w" sizes="(min-width: 720px) 720px"><figcaption><span>The Most Subscribed AI Slop YouTube Channels</span></figcaption></figure><p><em>Cuentos Facinantes</em> [sic] (Fascinating Tales) has attracted some 1.28 billion views, serving up low-quality <a href="https://www.kapwing.com/kai/create/dragon-ball-image-generator?ref=kapwing.com"><em>Dragon Ball</em>-themed videos</a>. The channel was established in 2020, but the earliest video currently hosted is from as recently as Jan. 8, 2025.</p><p>Five of the other ten trending AI slop channels with the most views are based in South Korea, with others in Egypt, Brazil and Pakistan. But the channel with the most views of all is in India. <em>Bandar Apna Dost</em> features over 500 videos, mainly “featuring a realistic monkey in hilarious, dramatic, and heart-touching human-style situations,” Many of which are variations on identical set-ups. The channel also has around 100,000 followers on Instagram; on Facebook, the videos are attributed to a ‘digital creator’ named Surajit Karmakar.</p><figure><img src="https://www.kapwing.com/blog/content/images/2025/11/04_The-AI-Slop-Youtube-Channels-With-the-Most-Views.png" alt="" loading="lazy" width="2000" height="2500" srcset="https://www.kapwing.com/blog/content/images/size/w600/2025/11/04_The-AI-Slop-Youtube-Channels-With-the-Most-Views.png 600w, https://www.kapwing.com/blog/content/images/size/w1000/2025/11/04_The-AI-Slop-Youtube-Channels-With-the-Most-Views.png 1000w, https://www.kapwing.com/blog/content/images/size/w1600/2025/11/04_The-AI-Slop-Youtube-Channels-With-the-Most-Views.png 1600w, https://www.kapwing.com/blog/content/images/2025/11/04_The-AI-Slop-Youtube-Channels-With-the-Most-Views.png 2400w" sizes="(min-width: 720px) 720px"><figcaption><span>The AI Slop YouTube Channels With the Most Views</span></figcaption></figure><p>If they’re monetizing their views, channels like <em>Bandar Apna Dost</em> may be making millions of dollars per year. But YouTube faces a dilemma over AI content.&nbsp;</p><p>On the one hand, YouTube CEO Neal Mohan cites generative AI as the biggest game-changer for YouTube since the original “revelation” that ordinary folk wanted to watch each other’s videos, saying that generative AI can do for video what the synthesizer did for music.</p><p>On the other hand, the company worries that its advertisers will feel <a href="https://futurism.com/youtube-drowning-ai-slop?ref=kapwing.com"><u>devalued</u></a> by having their ads attached to slop.</p><figure><img src="https://www.kapwing.com/blog/content/images/2025/11/05_The-Highest-Earning-AI-Slop-Youtube-Channels.png" alt="" loading="lazy" width="2000" height="2500" srcset="https://www.kapwing.com/blog/content/images/size/w600/2025/11/05_The-Highest-Earning-AI-Slop-Youtube-Channels.png 600w, https://www.kapwing.com/blog/content/images/size/w1000/2025/11/05_The-Highest-Earning-AI-Slop-Youtube-Channels.png 1000w, https://www.kapwing.com/blog/content/images/size/w1600/2025/11/05_The-Highest-Earning-AI-Slop-Youtube-Channels.png 1600w, https://www.kapwing.com/blog/content/images/2025/11/05_The-Highest-Earning-AI-Slop-Youtube-Channels.png 2400w" sizes="(min-width: 720px) 720px"><figcaption><span>The Highest Earning AI Slop YouTube Channels</span></figcaption></figure><p>The AI slop channels with the highest potential earnings mostly line up with the top ten for views. This is because Social Blade <a href="https://socialblade.com/help/how-are-estimated-earnings-calculated?ref=kapwing.com"><u>estimates channel income</u></a> based on annual views, and most of these channels’ videos have been published over the last few months. Using an average rate of revenue per 1,000 views, <em>Bandar Apna Dost</em> has an estimated annual revenue of $4.25 million.</p><p>“The genius is going to lie whether you did it in a way that was profoundly original or creative,” <a href="https://www.wired.com/story/youtube-thinks-ai-is-its-next-big-bang/?ref=kapwing.com"><u>Mohan told Wired</u></a>. “Just because the content is 75 percent AI generated doesn't make it any better or worse than a video that’s 5 percent AI generated. What's important is that it was done by a human being.” </p><p>Whether those flooding the platform with auto-generated content to make a buck care about being known as creative geniuses is another matter.</p><h2 id="on-a-new-youtube-feed-33-of-videos-are-brainrot">On A New YouTube Feed, 33% of Videos are Brainrot</h2><p>Finally, we simulated the experience of an untainted YouTube shorts algorithm by establishing a new YouTube account and noting the occurrence of AI slop or brainrot videos among the first 500 videos in the feed. While we were spared either of these for the first 16 videos in the feed, in total, 104 (21%) of the first 500 videos were AI-generated, and 165 (33%) of those 500 videos were brainrot.</p><figure><img src="https://www.kapwing.com/blog/content/images/2025/11/06_The-Density-of-AI-Slop-on-the-YouTube-Feed.png" alt="" loading="lazy" width="2000" height="2500" srcset="https://www.kapwing.com/blog/content/images/size/w600/2025/11/06_The-Density-of-AI-Slop-on-the-YouTube-Feed.png 600w, https://www.kapwing.com/blog/content/images/size/w1000/2025/11/06_The-Density-of-AI-Slop-on-the-YouTube-Feed.png 1000w, https://www.kapwing.com/blog/content/images/size/w1600/2025/11/06_The-Density-of-AI-Slop-on-the-YouTube-Feed.png 1600w, https://www.kapwing.com/blog/content/images/2025/11/06_The-Density-of-AI-Slop-on-the-YouTube-Feed.png 2400w" sizes="(min-width: 720px) 720px"><figcaption><span>The Density of AI Slop on the YouTube Feed</span></figcaption></figure><p>Whether this prevalence of slop and brainrot on our test feed represents the engineering of YouTube’s algorithm or the sheer proliferation of such videos that are being uploaded is a mystery that only Google can answer. But the <a href="https://www.theguardian.com/technology/2025/aug/11/cat-soap-operas-and-babies-trapped-in-space-the-ai-slop-taking-over-youtube?ref=kapwing.com"><u>Guardian’s analysis</u></a> of YouTube’s figures for July revealed that nearly “one in 10 of the fastest growing YouTube channels globally are showing AI-generated content only.”&nbsp;</p><p>And brainrot, like AI slop, is a mixed blessing for YouTube as a company: it may lack the soul or professionalism with which YouTube’s advertisers wish to be associated, but brainrot is moreish by design. </p><p>Brainrot’s natural home is the feed, whether viewers are compelled to keep watching to “<a href="https://www.nytimes.com/2024/06/13/style/brainrot-internet-addiction-social-media-tiktok.html?ref=kapwing.com"><u>numb</u></a>” themselves from the trials of the world around them, or to stay up to date with the potentially infinite “<a href="https://italianbrainrot.miraheze.org/wiki/Italian_Brainrot_Wiki?ref=kapwing.com"><u>lore</u></a>” of emergent brainrot subgenres, which incorporate recurring characters and themes.</p><p>The term “AI slop” has been variously pinned to “<a href="https://simonwillison.net/2024/May/8/slop/?ref=kapwing.com"><u>unreviewed</u></a>” content, to AI-generated media that may have been reviewed but with minimal quality standards (like Coke’s Christmas ads), and to <em>all</em> AI-generated content. As <a href="https://robhorning.substack.com/p/born-sloppy?ref=kapwing.com"><u>Rob Horning</u></a> points out, the idea that only <em>some</em> AI media is slop propagates the idea that the rest is legitimate and the technology’s proliferation is inevitable.</p><p>Part of the threat of AI slop and some forms of brainrot is in how they have been normalized and may come across as harmless fun. But slop and brainrot prey on the laziest areas of our mental faculties. Researchers have shown how the “<a href="https://phys.org/news/2025-02-exposure-deepfakes-international.html?ref=kapwing.com"><u>illusory truth effect</u></a>” makes people more likely to believe in claims or imagery the more often they encounter it. AI tools make it easy for bad-faith actors to construct a fake enemy or situation that supports their underlying political beliefs or goals. <a href="https://sciety.org/articles/activity/10.21203/rs.3.rs-6471307/v1?ref=kapwing.com"><u>Seeing is believing</u></a>, studies have shown, even when the viewer has been explicitly told that a video is fake.&nbsp;</p><p>Meanwhile, “information of any kind, in enough quantities, becomes noise,” writes researcher and artist <a href="https://mail.cyberneticforests.com/slop-infrastructures-1-2/?ref=kapwing.com"><u>Eryk Salvaggio</u></a>. The prevalence of AI slop is “a symptom of information exhaustion, and an increased human dependency on algorithmic filters to sort the world on our behalf.” And, as <a href="https://dougshapiro.substack.com/p/trust-is-the-new-oil?ref=kapwing.com"><u>Doug Shapiro</u></a> notes, as this noise drowns out the signal on the web, including social networks, the value of <em>trust</em> will rise — and so will corporate and political efforts to fabricate and manipulate trust.</p><p>And this is why, rather than attending film school to study AI techniques, it may be more valuable for creators and consumers alike — especially those still in school — to double down on Media Studies.</p><h3 id="methodology-sources">Methodology &amp; Sources</h3><p>We manually researched the top 100 trending YouTube channels in every country (on playboard.co) to isolate the AI slop channels.&nbsp;</p><p>We then used socialblade.com to retrieve the number of views, subscribers and estimated yearly revenue (using the midpoint values) for these channels.</p><p>We aggregated these figures for each country's AI slop channels to get an idea of their popularity.</p><p>In addition, we created a new YouTube account and recorded the number of AI slop and <a href="https://www.youtube.com/watch?v=g75A8vi9PVU&amp;ref=kapwing.com">brainrot videos</a> among the first 500 YouTube Shorts we cycled through to get an idea of the new-user experience.</p><p>Data is correct as of October 2025.</p>
            </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Growing up in “404 Not Found”: China's nuclear city in the Gobi Desert (725 pts)]]></title>
            <link>https://substack.com/inbox/post/182743659</link>
            <guid>46408988</guid>
            <pubDate>Sun, 28 Dec 2025 06:43:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://substack.com/inbox/post/182743659">https://substack.com/inbox/post/182743659</a>, See on <a href="https://news.ycombinator.com/item?id=46408988">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[C++ says “We have try. . . finally at home” (112 pts)]]></title>
            <link>https://devblogs.microsoft.com/oldnewthing/20251222-00/?p=111890</link>
            <guid>46408984</guid>
            <pubDate>Sun, 28 Dec 2025 06:42:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://devblogs.microsoft.com/oldnewthing/20251222-00/?p=111890">https://devblogs.microsoft.com/oldnewthing/20251222-00/?p=111890</a>, See on <a href="https://news.ycombinator.com/item?id=46408984">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="single-wrapper">
    
    <article data-clarity-region="article" id="post-111890">
        <div data-bi-area="body_article" data-bi-id="post_page_body_article">
            <p>Many languages¹ that have exceptions also have a <code>finally</code> clause, so you can write</p>
<pre>try {
    ⟦ stuff ⟧
} finally {
    always();
}
</pre>
<p>A quick checks shows that this control structure exists in Java, C#, Python, JavaScript, but not C++.</p>
<p>C++ says, “We have <code>try</code>…finally at home.”</p>
<p>In C++, the way to get a block of code to execute when control leaves a block is to put it in a destructor, because destructors run when control leaves a block. This is the trick used by the Windows Implementation Library’s <a href="https://github.com/microsoft/wil/wiki/RAII-resource-wrappers#wilscope_exit"> wil::<wbr>scope_exit</a> function: The lambda you provide is placed inside a custom object whose destructor runs the lambda.</p>
<pre>auto ensure_cleanup = wil::scope_exit([&amp;] { always(); });

⟦ stuff ⟧
</pre>
<p>Although the principle is the same, there are some quirks in how each language treats the case where the <code>finally</code> or destructor itself throws an exception.</p>
<p>If control leaves the guarded block without an exception, then any uncaught exception that occurs in the <code>finally</code> block or the destructor is thrown from the <code>try</code> block. All the languages seem to agree on this.</p>
<p>If control leaves the guarded block with an exception, and the <code>finally</code> block or destructor <i>also</i> throws an exception, then the behavior varies by language.</p>
<ul>
<li>In Java, Python, JavaScript, and C# an exception thrown from a <code>finally</code> block overwrites the original exception, and the original exception is lost. <b>Update</b>: Adam Rosenfield points out that Python 3.2 now saves the original exception as the context of the new exception, but it is still the new exception that is thrown.</li>
<li>In C++, an exception thrown from a destructor triggers automatic program termination if the destructor is running due to an exception.²</li>
</ul>
<p>So C++ gives you the ability to run code when control leaves a scope, but your code had better not allow an exception to escape if you know what’s good for you.</p>
<p>¹ The Microsoft compiler also supports the <code>__try</code> and <code>__finally</code> keywords for structured exception handling. These are, however, intended for C code. Don’t use them in C++ code because <a title="Can I throw a C++ exception from a structured exception?" href="https://devblogs.microsoft.com/oldnewthing/20170728-00/?p=96706"> they interact with C++ exceptions in sometimes-confusing ways</a>.</p>
<p>² This is why <code>wil::<wbr>scope_exit</code> documents that it will terminate the process if the lambda throws an exception. There is an alternate function <code>wil::<wbr>scope_<wbr>exit_<wbr>log</code> that logs and then ignores exceptions that are thrown from the lambda. There is no variation that gives you Java-like behavior.</p>
        </div><!-- .entry-content -->

        <!-- AI Disclaimer -->
            </article>
    
</div><div><!-- Author section -->
            <h2>Author</h2>
            <div><div><p><img src="https://devblogs.microsoft.com/oldnewthing/wp-content/uploads/sites/38/2019/02/RaymondChen_5in-150x150.jpg" alt="Raymond Chen"></p></div><p>Raymond has been involved in the evolution of Windows for more than 30 years. In 2003, he began a Web site known as The Old New Thing which has grown in popularity far beyond his wildest imagination, a development which still gives him the heebie-jeebies. The Web site spawned a book, coincidentally also titled The Old New Thing (Addison Wesley 2007). He occasionally appears on the Windows Dev Docs Twitter account to tell stories which convey no useful information.</p></div>        </div></div>]]></description>
        </item>
    </channel>
</rss>