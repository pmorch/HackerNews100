<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 03 Apr 2024 15:00:06 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[No joke: FTC boss goes on the Daily Show and is told Apple tried to block her (146 pts)]]></title>
            <link>https://www.theregister.com/2024/04/02/ftc_boss_apple_daily_show/</link>
            <guid>39916939</guid>
            <pubDate>Wed, 03 Apr 2024 13:05:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2024/04/02/ftc_boss_apple_daily_show/">https://www.theregister.com/2024/04/02/ftc_boss_apple_daily_show/</a>, See on <a href="https://news.ycombinator.com/item?id=39916939">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p><span>Comment</span> Generally the head of US government agencies and comedy don't mix, but on Monday night Lina Khan, boss of the Federal Trade Commission, was on the Daily Show recounting how the agency is going after Amazon, Facebook and others over monopolistic practices. She also got evidence of her <em>persona non grata</em> status with Cook &amp; Co.</p>
<p>Khan was welcomed onto the telly news commentary show, chaired once again by Jon Stewart, with cheers from the crowd - again not something many US government officials hear. The exception to this is possibly Rob Joyce, the former White House cybersecurity coordinator and recently <a target="_blank" rel="nofollow" href="https://www.nsa.gov/Press-Room/Press-Releases-Statements/Press-Release-View/Article/3681065/national-security-agency-announces-retirement-of-cybersecurity-director/">retired</a> NSA cybersecurity director, who got a <a target="_blank" href="https://www.theregister.com/2018/01/22/rob_joyce_hacking/">standing ovation</a> at the Shmoocon infosec conference after a presentation on how he hacks Christmas tree lights for fun.</p>
<p>In the 20-minute interview, Khan gave details on an ongoing lawsuit against Amazon's behavior - notably allegedly spamming search results pages and hiking fees on small businesses, which she said was "harming customers."</p>

    

<p>You can replay her appearance on the Comedy Central / Paramount+ / kinda YouTube program below.</p>

        


        

<p>
  <a href="https://www.youtube.com/watch?v=oaDTiWaYfcM" data-media="x-videoplayer">Youtube Video</a>
</p>
<p>It was going to be a tough fight, she said, since her watchdog agency has just 1,200 staff and Amazon has "monopoly money," and can throw ten times that number of lawyers at the case. "We're pretty out-gunned but not out-matched," she asserted.</p>

        

<p>But then Stewart dropped his bombshell: After a two-season podcast series with Apple he told Khan he wanted to get her on the show but Cupertino really wasn't keen.</p>
<p>"Apple asked us not to do it, to have you. They literally said 'please don't talk to her'... I didn't think they cared for you," Stewart said. Khan made an admirable, and nearly successful, attempt to keep a straight face.</p>
<p>Stewart also alleged that Apple refused to let his team make jokes about AI. He quit the podcast abruptly last October, reportedly citing Apple's heavy handed approach to censoring certain topics and guests.</p>

        

<p>"This just shows the dangers when you concentrate so much power and so much decision-making in a small number of companies," she argued.</p>
<p>"Going back all the way to the founding there was a recognition that in the same way that you need the Constitution to create checks and balances in our political sphere, you also needed the antitrust and anti-monopoly laws to safeguard against concentration of economic power because you don't want an autocrat of trade in the same way you don't want a monarch."</p>
<ul>

<li><a href="https://www.theregister.com/2024/02/16/ftc_ai_fakes/">FTC asks normal folks if they'd like AI impersonation scam protection, too</a></li>

<li><a href="https://www.theregister.com/2024/02/14/amazon_ftc_antitrust/">Date set for for epic Amazon-FTC antitrust showdown</a></li>

<li><a href="https://www.theregister.com/2024/02/02/ftc_blackbaud_settlement/">Blackbaud settles with FTC after that IT breach exposed millions of people's info</a></li>

<li><a href="https://www.theregister.com/2024/01/25/ftc_ai_inquiry/">FTC drills into Amazon, Microsoft, Google over billions pledged to OpenAI, Anthropic</a></li>
</ul>
<p>The amount of consolidation in the tech industry is harming competition, she argued. The FTC's case against Meta (<a target="_blank" href="https://www.theregister.com/2020/12/09/facebook_crushed_competitors_to_maintain/">started</a> before Khan got the top job) was a case in point - Facebook realized it couldn't defeat Instagram and WhatsApp, so just bought them, she asserted.</p>
<h3>So, how's that working out? Pretty good it seems</h3>
<p>When Khan <a target="_blank" href="https://www.theregister.com/2021/06/16/lina_khan_ftc/">was appointed</a> FTC chair in 2021 it must have sent shivers down the spine of many in the tech industry, particularly in Seattle.</p>
<p>Her 2017 <a target="_blank" rel="nofollow" href="https://www.yalelawjournal.org/pdf/e.710.Khan.805_zuvfyyeh.pdf">paper</a> [PDF] titled "Amazon's antitrust paradox" lays out the case that too few players exert a disproportionate amount of power in the tech industry.</p>
<p>And while traditionally monopolies were thought of as a single company dominating the industry (<em>cough</em>, Microsoft in the 1990s), customers are still shafted if even a few businesses corner a market.</p>
<p>As an immigrant to Silicon Valley and the San Francisco Bay Area it is astonishing to this humble vulture that this free-market nation is anything but in so many areas. Though it depends on where one lives, good luck getting a decent, healthy choice of ISP or cellphone carrier. And for a region that is a major tech hub of America the internet speeds and prices came as a rude shock.</p>
<p>Coming from Europe where telcos fight for your business, the change was remarkable. This hack may have been somewhat terse with a Verizon staffer trying to tell me that paying for text messages (an engineering function that carries the most minimal of data loads) was cheap at the price of just $5 a month. But with so little choice such predatory pricing is possible.</p>
<p>So far, the FTC appears to be getting much more muscular in going after alleged monopolistic practices, and it's about time. Frankly it's insane that an agency with such an important role in ensuring fair and open markets has such tiny staffing levels and funding.</p>
<p>But while the regulator is small it does have legal powers, and is increasingly asserting them. The question is how far can they be pushed, and with what consequences.</p>
<p>On <em>The Register</em>, when folks get fined we generally cite the sometimes large figures involved as a proportion of current profit, to give some perspective. When the FTC imposed a $5bn fine on Facebook back in 2019 over the <a target="_blank" href="https://www.theregister.com/2019/07/12/ftc_facebook_settlement_proposal/">Cambridge Analytica scandal</a>, for example, that amounted to one percent of its market cap. Zuckerberg must have been shaking in his sneakers.</p>
<p>And this was the point Khan made: "Over the last couple of decades we've seen how businesses can just treat fines as a cost of doing business. And we need to make sure we're actually deterring illegal behavior."</p>
<p>The Tl;dr: Businesses only obey the bottom line. Â®</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Every Dunder Method in Python (137 pts)]]></title>
            <link>https://www.pythonmorsels.com/every-dunder-method/</link>
            <guid>39915968</guid>
            <pubDate>Wed, 03 Apr 2024 11:18:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.pythonmorsels.com/every-dunder-method/">https://www.pythonmorsels.com/every-dunder-method/</a>, See on <a href="https://news.ycombinator.com/item?id=39915968">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>You've just made a class.
You made a <code>__init__</code> method.
Now what?</p>
<p>Python includes <em>tons</em> of <a href="https://www.pythonmorsels.com/what-are-dunder-methods/" target="_blank">dunder methods</a> ("double underscore" methods) which allow us to deeply customize how our custom classes interact with Python's many features.
What dunder methods could you add to your class to make it friendly for other Python programmers who use it?</p>
<p>Let's take a look at <strong>every dunder method in Python</strong>, with a focus on when each method is useful.</p>
<p>Note that the Python documentation refers to these as <a href="https://docs.python.org/3/glossary.html#term-special-method" target="_blank">special methods</a> and notes the synonym "magic method" but <em>very</em> <a href="https://docs.python.org/3/reference/lexical_analysis.html#reserved-classes-of-identifiers" target="_blank">rarely</a> uses the term "dunder method".
However, "dunder method" is a fairly common Python colloquialism, as noted in my <a href="https://www.pythonmorsels.com/terms/" target="_blank">unofficial Python glossary</a>.</p>
<p>You can use the links scattered throughout this page for more details on any particular dunder method.
For a list of all of them, see the cheat sheet in the final section.</p>
<div>
<p><a href="#cheat-sheet">Just show me the cheat sheet</a>
</p></div>
<h2 id="the-3-essential-dunder-methods">The 3 essential dunder methods ð</h2>
<p>There are 3 dunder methods that <em>most</em> classes should have: <a href="https://www.pythonmorsels.com/what-is-init/" target="_blank"><code>__init__</code></a>, <a href="https://www.pythonmorsels.com/customizing-string-representation-your-objects/" target="_blank"><code>__repr__</code></a>, and <a href="https://www.pythonmorsels.com/overloading-equality-in-python/" target="_blank"><code>__eq__</code></a>.</p>
<table>
<thead>
<tr>
<th>Operation</th>
<th>Dunder Method Call</th>
<th>Returns</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>T(a, b=3)</code></td>
<td><code>T.__init__(x, a, b=3)</code></td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>repr(x)</code></td>
<td><code>x.__repr__()</code></td>
<td><code>str</code></td>
</tr>
<tr>
<td><code>x == y</code></td>
<td><code>x.__eq__(y)</code></td>
<td>Typically <code>bool</code></td>
</tr>
</tbody>
</table>
<p>The <a href="https://www.pythonmorsels.com/what-is-init/" target="_blank"><code>__init__</code></a> method is the <strong>initializer</strong> (not to be confused with the <a href="#construction-and-finalizing" target="_blank">constructor</a>), the <a href="https://www.pythonmorsels.com/customizing-string-representation-your-objects/" target="_blank"><code>__repr__</code></a> method customizes an object's string representation, and the <a href="https://www.pythonmorsels.com/overloading-equality-in-python/" target="_blank"><code>__eq__</code></a> method customizes what it means for objects to be <em>equal</em> to one another.</p>
<p>The <code>__repr__</code> method is particularly helpful at the <a href="https://www.pythonmorsels.com/using-the-python-repl/" target="_blank">the Python REPL</a> and when debugging.</p>
<h2 id="equality-and-hashability">Equality and hashability ð°</h2>
<p>In addition to the <code>__eq__</code> method, Python has 2 other dunder methods for determining the "value" of an object in relation to other objects.</p>
<table>
<thead>
<tr>
<th>Operation</th>
<th>Dunder Method Call</th>
<th>Returns</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>x == y</code></td>
<td><code>x.__eq__(y)</code></td>
<td>Typically <code>bool</code></td>
</tr>
<tr>
<td><code>x != y</code></td>
<td><code>x.__ne__(y)</code></td>
<td>Typically <code>bool</code></td>
</tr>
<tr>
<td><code>hash(x)</code></td>
<td><code>x.__hash__()</code></td>
<td><code>int</code></td>
</tr>
</tbody>
</table>
<p>Python's <code>__eq__</code> method typically returns <code>True</code>, <code>False</code>, or <a href="https://www.pythonmorsels.com/when-to-use-notimplemented/" target="_blank"><code>NotImplemented</code></a> (if objects can't be compared).
The default <code>__eq__</code> implementation relies on the <code>is</code> operator, which checks for <strong><a href="https://www.pythonmorsels.com/equality-vs-identity/" target="_blank">identity</a></strong>.</p>
<p>The default implementation of <code>__ne__</code> calls <code>__eq__</code> and negates any boolean return value given (or returns <code>NotImplemented</code> if <code>__eq__</code> did).
This default behavior is usually "good enough", so <strong>you'll almost never see <code>__ne__</code> implemented</strong>.</p>
<p>Hashable objects can be used as keys in dictionaries or values in sets.
All objects in Python are <a href="https://www.pythonmorsels.com/what-are-hashable-objects/" target="_blank">hashable</a> by default, but if you've written a custom <code>__eq__</code> method then your objects <em>won't</em> be hashable without a custom <code>__hash__</code> method.
But <strong>the hash value of an object must never change</strong> or <a href="https://pym.dev/p/2ysgz/" target="_blank">bad things will happen</a> so <strong>typically only <em>immutable</em> objects implement <code>__hash__</code></strong>.</p>
<p>For implementing equality checks, see <a href="https://www.pythonmorsels.com/overloading-equality-in-python/" target="_blank"><code>__eq__</code> in Python</a>.
For implementing hashability, see <a href="https://www.pythonmorsels.com/making-hashable-objects/" target="_blank">making hashable objects in Python</a>.</p>
<h2 id="orderability">Orderability âï¸</h2>
<p>Python's comparison operators (<code>&lt;</code>, <code>&gt;</code>, <code>&lt;=</code>, <code>&gt;=</code>) can all be overloaded with dunder methods as well.
The comparison operators also power functions that rely on the relative ordering of objects, like <code>sorted</code>, <code>min</code>, and <code>max</code>.</p>
<table>
<thead>
<tr>
<th>Operation</th>
<th>Dunder Method Call</th>
<th>Returns</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>&lt;</code></td>
<td><code>__lt__</code></td>
<td>Typically <code>bool</code></td>
</tr>
<tr>
<td><code>&gt;</code></td>
<td><code>__gt__</code></td>
<td>Typically <code>bool</code></td>
</tr>
<tr>
<td><code>&lt;=</code></td>
<td><code>__le__</code></td>
<td>Typically <code>bool</code></td>
</tr>
<tr>
<td><code>&gt;=</code></td>
<td><code>__ge__</code></td>
<td>Typically <code>bool</code></td>
</tr>
</tbody>
</table>
<p>If you plan to implement all of these operators in the <em>typical</em> way (where <code>x &lt; y</code> would be the same as asking <code>y &gt; x</code>) then the <a href="https://docs.python.org/3/library/functools.html#functools.total_ordering" target="_blank"><code>total_ordering</code> decorator</a> from Python's <code>functools</code> module will come in handy.</p>
<h2 id="type-conversions-and-string-formatting">Type conversions and string formatting âï¸</h2>
<p>Python has a number of dunder methods for converting objects to a different type.</p>
<table>
<thead>
<tr>
<th>Function</th>
<th>Dunder Method Call</th>
<th>Returns</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>str(x)</code></td>
<td><code>x.__str__()</code></td>
<td><code>str</code></td>
</tr>
<tr>
<td><code>bool(x)</code></td>
<td><code>x.__bool__()</code></td>
<td><code>bool</code></td>
</tr>
<tr>
<td><code>int(x)</code></td>
<td><code>x.__int__()</code></td>
<td><code>int</code></td>
</tr>
<tr>
<td><code>float(x)</code></td>
<td><code>x.__float__()</code></td>
<td><code>float</code></td>
</tr>
<tr>
<td><code>bytes(x)</code></td>
<td><code>x.__bytes__()</code></td>
<td><a href="https://pym.dev/p/2ysgz/" target="_blank"><code>bytes</code></a></td>
</tr>
<tr>
<td><code>complex(x)</code></td>
<td><code>x.__complex__()</code></td>
<td><a href="https://docs.python.org/3/glossary.html#term-complex-number" target="_blank"><code>complex</code></a></td>
</tr>
<tr>
<td><code>f"{x:s}"</code></td>
<td><code>x.__format__(s)</code></td>
<td><code>str</code></td>
</tr>
<tr>
<td><code>repr(x)</code></td>
<td><code>x.__repr__()</code></td>
<td><code>str</code></td>
</tr>
</tbody>
</table>
<p>The <code>__bool__</code> function is used for <a href="https://www.pythonmorsels.com/truthiness/" target="_blank">truthiness</a> checks, though <code>__len__</code> is used as a fallback.</p>
<p>If you needed to make an object that acts like a number (like <a href="https://docs.python.org/3/library/decimal.html" target="_blank"><code>decimal.Decimal</code></a> or <a href="https://docs.python.org/3/library/fractions.html" target="_blank"><code>fractions.Fraction</code></a>), you'll want to implement <code>__int__</code>, <code>__float__</code>, and <code>__complex__</code> so your objects can be converted to other numbers.
If you wanted to make an object that could be used in a <code>memoryview</code> or could otherwise be converted to <code>bytes</code>, you'll want a <code>__bytes__</code> method.</p>
<p>The <code>__format__</code> and <code>__repr__</code> methods are different string conversion flavors.
Most string conversions rely the <code>__str__</code> method, but the default <code>__str__</code> implementation simply calls <code>__repr__</code>.</p>
<p>The <code>__format__</code> method is used by all <a href="https://www.pythonmorsels.com/string-formatting/" target="_blank">f-string conversions</a>, by the <code>str</code> class's <code>format</code> method, and by the (rarely used) built-in <code>format</code> function.
This method allows <code>datetime</code> objects to <a href="https://www.pythonmorsels.com/string-formatting/#formatting-datetime-objects" target="_blank">support custom format specifiers</a>.</p>
<h2 id="context-managers">Context managers ðª</h2>
<p>A context manager is an object that can be used in a <code>with</code> block.</p>
<table>
<thead>
<tr>
<th>Use</th>
<th>Dunder Method Call</th>
<th>Returns</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>with</code> block enter</td>
<td><code>x.__enter__()</code></td>
<td>A value given to <code>as</code></td>
</tr>
<tr>
<td><code>with</code> block exit</td>
<td><code>x.__exit__(exc_type, exc, traceback)</code></td>
<td>Truthy/falsey value</td>
</tr>
</tbody>
</table>
<p>For more on context managers see, <a href="https://www.pythonmorsels.com/what-is-a-context-manager/" target="_blank">what is a context manager</a> and <a href="https://www.pythonmorsels.com/creating-a-context-manager/" target="_blank">creating a context manager</a>.</p>
<h2 id="containers-and-collections">Containers and collections ðï¸</h2>
<p>Collections (a.k.a. containers) are essentially data structures or objects that act like data stuctures.
Lists, dictionaries, sets, strings, and tuples are all examples of collections.</p>
<table>
<thead>
<tr>
<th>Operation</th>
<th>Dunder Method Call</th>
<th>Return Type</th>
<th>Implemented</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>len(x)</code></td>
<td><code>x.__len__()</code></td>
<td>integer</td>
<td>Very common</td>
</tr>
<tr>
<td><code>iter(x)</code></td>
<td><code>x.__iter__()</code></td>
<td>iterator</td>
<td>Very common</td>
</tr>
<tr>
<td><code>for item in x: ...</code></td>
<td><code>x.__iter__()</code></td>
<td>iterator</td>
<td>Very common</td>
</tr>
<tr>
<td><code>x[a]</code></td>
<td><code>x.__getitem__(a)</code></td>
<td>any object</td>
<td>Common</td>
</tr>
<tr>
<td><code>x[a] = b</code></td>
<td><code>x.__setitem__(a, b)</code></td>
<td>None</td>
<td>Common</td>
</tr>
<tr>
<td><code>del x[a]</code></td>
<td><code>x.__delitem__(a)</code></td>
<td>None</td>
<td>Common</td>
</tr>
<tr>
<td><code>a in x</code></td>
<td><code>x.__contains__(a)</code></td>
<td>bool</td>
<td>Common</td>
</tr>
<tr>
<td><code>reversed(x)</code></td>
<td><code>x.__reversed__()</code></td>
<td>iterator</td>
<td>Common</td>
</tr>
<tr>
<td><code>next(x)</code></td>
<td><code>x.__next__()</code></td>
<td>any object</td>
<td>Uncommon</td>
</tr>
<tr>
<td><code>x[a]</code></td>
<td><code>x.__missing__(a)</code></td>
<td>any object</td>
<td>Uncommon</td>
</tr>
<tr>
<td><code>operator.length_hint(x)</code></td>
<td><code>x.__length_hint__()</code></td>
<td>integer</td>
<td>Uncommon</td>
</tr>
</tbody>
</table>
<p>The <code>__iter__</code> method is used by the <code>iter</code> function <em>and</em> for all forms of iteration: <a href="https://www.pythonmorsels.com/writing-a-for-loop/" target="_blank"><code>for</code> loops</a>, <a href="https://www.pythonmorsels.com/what-are-list-comprehensions/" target="_blank">comprehensions</a>, <a href="https://www.pythonmorsels.com/tuple-unpacking/" target="_blank">tuple unpacking</a>, and <a href="https://www.pythonmorsels.com/unpacking-iterables-iterables/" target="_blank">using <code>*</code> for iterable unpacking</a>.</p>
<p>While the <code>__iter__</code> method is necessary for creating a custom iterable, the <code>__next__</code> method is necessary for creating a custom iterator (which is much less common).
The <code>__missing__</code> method is only ever called by the <code>dict</code> class on itself, unless another class decides to implement <code>__missing__</code>.
The <code>__length_hint__</code> method supplies a length guess for structures which do not support <code>__len__</code> so that lists or other structures can be pre-sized more efficiently.</p>
<p>Also see: <a href="https://www.pythonmorsels.com/iterator-protocol/" target="_blank">the iterator protocol</a>, <a href="https://www.pythonmorsels.com/making-the-len-function-work-on-your-python-objects/" target="_blank">implementing <code>__len__</code></a>, and <a href="https://www.pythonmorsels.com/supporting-index-and-key-lookups/" target="_blank">implementing <code>__getitem__</code></a>.</p>
<h2 id="callability">Callability âï¸</h2>
<p>Functions, classes, and all other <a href="https://www.pythonmorsels.com/callables/" target="_blank">callable objects</a> rely on the <code>__call__</code> method.</p>
<table>
<thead>
<tr>
<th>Operation</th>
<th>Dunder Method Call</th>
<th>Return Type</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>x(a, b=c)</code></td>
<td><code>x.__call__(a, b=c)</code></td>
<td>any object</td>
</tr>
</tbody>
</table>
<p>When a class is called, its <a href="https://docs.python.org/3/glossary.html#term-metaclass" target="_blank">metaclass</a>'s <code>__call__</code> method is used.
When a class <em>instance</em> is called, the class's <code>__call__</code> method is used.</p>
<p>For more on callability, see <a href="https://www.pythonmorsels.com/class-function-and-callable/" target="_blank">Callables: Python's "functions" are sometimes classes</a>.</p>
<h2 id="arithmetic-operators">Arithmetic operators â</h2>
<p>Python's dunder methods are often described as a tool for "operator overloading".
Most of this "operator overloading" comes in the form of Python's various arithmetic operators.</p>
<p>There are two ways to break down the arithmetic operators:</p>
<ul>
<li>Mathematical (e.g. <code>+</code>, <code>-</code>, <code>*</code>, <code>/</code>, <code>%</code>) versus bitwise (e.g. <code>&amp;</code>, <code>|</code>, <code>^</code>, <code>&gt;&gt;</code>, <code>~</code>)</li>
<li>Binary (between 2 values, like <code>x + y</code>) versus unary (before 1 value, like <code>+x</code>)</li>
</ul>
<p>The mathematical operators are much more common than the bitwise ones and the binary ones are a bit more common than the unary ones.</p>
<p>These are the binary mathematical arithmetic operators:</p>
<table>
<thead>
<tr>
<th>Operation</th>
<th>Left-Hand Method</th>
<th>Right-Hand Method</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>x + y</code></td>
<td><code>__add__</code></td>
<td><code>__radd__</code></td>
<td>Add / Concatenate</td>
</tr>
<tr>
<td><code>x - y</code></td>
<td><code>__sub__</code></td>
<td><code>__rsub__</code></td>
<td>Subtract</td>
</tr>
<tr>
<td><code>x * y</code></td>
<td><code>__mul__</code></td>
<td><code>__rmul__</code></td>
<td>Multiply</td>
</tr>
<tr>
<td><code>x / y</code></td>
<td><code>__truediv__</code></td>
<td><code>__rtruediv__</code></td>
<td>Divide</td>
</tr>
<tr>
<td><code>%</code></td>
<td><code>__mod__</code></td>
<td><code>__rmod__</code></td>
<td>Modulo</td>
</tr>
<tr>
<td><code>x // y</code></td>
<td><code>__floordiv__</code></td>
<td><code>__rfloordiv__</code></td>
<td><a href="https://www.pythonmorsels.com/integer-division/" target="_blank">Integer division</a></td>
</tr>
<tr>
<td><code>**</code></td>
<td><code>__pow__</code></td>
<td><code>__rpow__</code></td>
<td>Exponentiate</td>
</tr>
<tr>
<td><code>x @ y</code></td>
<td><code>__matmul__</code></td>
<td><code>__rmatmul__</code></td>
<td>Matrix multiply</td>
</tr>
</tbody>
</table>
<p>Each of these operators includes left-hand and right-hand methods.
If <code>x.__add__(y)</code> returns <a href="https://www.pythonmorsels.com/when-to-use-notimplemented/" target="_blank"><code>NotImplemented</code></a>, then <code>y.__radd__(x)</code> will be attempted.
See <a href="https://www.pythonmorsels.com/arithmetic-dunder-methods/" target="_blank">arithmetic dunder methods</a> for more.</p>
<p>These are the binary bitwise arithmetic operators:</p>
<table>
<thead>
<tr>
<th>Operation</th>
<th>Left-Hand Method</th>
<th>Right-Hand Method</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>x &amp; y</code></td>
<td><code>__and__</code></td>
<td><code>__rand__</code></td>
<td>AND</td>
</tr>
<tr>
<td><code>x | y</code></td>
<td><code>__or__</code></td>
<td><code>__ror__</code></td>
<td>OR</td>
</tr>
<tr>
<td><code>x ^ y</code></td>
<td><code>__xor__</code></td>
<td><code>__rxor__</code></td>
<td>XOR</td>
</tr>
<tr>
<td><code>x &gt;&gt; y</code></td>
<td><code>__rshift__</code></td>
<td><code>__rrshift__</code></td>
<td>Right-shift</td>
</tr>
<tr>
<td><code>x &lt;&lt; y</code></td>
<td><code>__lshift__</code></td>
<td><code>__rlshift__</code></td>
<td>Left-shift</td>
</tr>
</tbody>
</table>
<p>These are Python's unary arithmetic operators:</p>
<table>
<thead>
<tr>
<th>Operation</th>
<th>Dunder Method</th>
<th>Variety</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>-x</code></td>
<td><code>__neg__</code></td>
<td>Mathematical</td>
<td>Negate</td>
</tr>
<tr>
<td><code>+x</code></td>
<td><code>__pos__</code></td>
<td>Bitwise</td>
<td>Affirm</td>
</tr>
<tr>
<td><code>~x</code></td>
<td><code>__invert__</code></td>
<td>Bitwise</td>
<td>Invert</td>
</tr>
</tbody>
</table>
<p>The unary <code>+</code> operator typically <a href="https://stackoverflow.com/questions/16819023/whats-the-purpose-of-the-pos-unary-operator-in-python" target="_blank">has no effect</a>, though some objects use it for a specific operation.
For example <a href="https://www.pythonmorsels.com/using-counter/#removing-negative-counts" target="_blank">using <code>+</code> on <code>collections.Counter</code> objects</a> will remove non-positive values.</p>
<p>Python's arithmetic operators are often used for non-arithmetic ends: <a href="https://www.pythonmorsels.com/sequence/" target="_blank">sequences</a> use <code>+</code> to concatenate and <code>*</code> to self-concatenate and <a href="https://www.pythonmorsels.com/practical-uses-of-sets/" target="_blank">sets</a> use <code>&amp;</code> for intersection, <code>|</code> for union, <code>-</code> for asymmetric difference, and <code>^</code> for symmetric difference.
Arithmetic operators are sometimes overloaded for more creative uses too.
For example, <code>pathlib.Path</code> objects <a href="https://docs.python.org/3/library/pathlib.html#operators" target="_blank">use <code>/</code> to create child paths</a>.</p>
<h2 id="in-place-arithmetic-operations">In-place arithmetic operations â»ï¸</h2>
<p>Python includes many dunder methods for <strong>in-place</strong> operations.
If you're making a <a href="https://www.pythonmorsels.com/terms/#mutable" target="_blank">mutable</a> object that supports any of the arithmetic operations, you'll want to implement the related in-place dunder method(s) as well.</p>
<table>
<thead>
<tr>
<th>Operation</th>
<th>Dunder Method Call</th>
<th>Returns</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>x += y</code></td>
<td><code>x.__iadd__(y)</code></td>
<td>Typically <code>self</code></td>
</tr>
<tr>
<td><code>x -= y</code></td>
<td><code>x.__isub__(y)</code></td>
<td>Typically <code>self</code></td>
</tr>
<tr>
<td><code>x *= y</code></td>
<td><code>x.__imul__(y)</code></td>
<td>Typically <code>self</code></td>
</tr>
<tr>
<td><code>x /= y</code></td>
<td><code>x.__itruediv__(y)</code></td>
<td>Typically <code>self</code></td>
</tr>
<tr>
<td><code>x %= y</code></td>
<td><code>x.__imod__(y)</code></td>
<td>Typically <code>self</code></td>
</tr>
<tr>
<td><code>x //= y</code></td>
<td><code>x.__ifloordiv__(y)</code></td>
<td>Typically <code>self</code></td>
</tr>
<tr>
<td><code>x **= y</code></td>
<td><code>x.__ipow__(y)</code></td>
<td>Typically <code>self</code></td>
</tr>
<tr>
<td><code>x @= y</code></td>
<td><code>x.__imatmul__(y)</code></td>
<td>Typically <code>self</code></td>
</tr>
<tr>
<td><code>x &amp;= y</code></td>
<td><code>x.__iand__(y)</code></td>
<td>Typically <code>self</code></td>
</tr>
<tr>
<td><code>x |= y</code></td>
<td><code>x.__ior__(y)</code></td>
<td>Typically <code>self</code></td>
</tr>
<tr>
<td><code>x ^= y</code></td>
<td><code>x.__ixor__(y)</code></td>
<td>Typically <code>self</code></td>
</tr>
<tr>
<td><code>x &gt;&gt;= y</code></td>
<td><code>x.__irshift__(y)</code></td>
<td>Typically <code>self</code></td>
</tr>
<tr>
<td><code>x &lt;&lt;= y</code></td>
<td><code>x.__ilshift__(y)</code></td>
<td>Typically <code>self</code></td>
</tr>
</tbody>
</table>
<p>All of Python's binary arithmetic operators work in <strong>augmented assignment statements</strong>, which involve using an operator followed by the <code>=</code> sign to assign to an object while performing an operation on it.</p>
<p>Augmented assignments on <strong>mutable objects</strong> are <a href="https://www.pythonmorsels.com/augmented-assignments-mutate/" target="_blank">expected to mutate the original object</a>, thanks to the mutable object implementing the appropriate dunder method for in-place arithmetic.</p>
<p>When no dunder method is found for an in-place operation, Python performs the operation followed by an assignment.
<strong>Immutable objects typically do <em>not</em> implement dunder methods for in-place operations</strong>, since they should return a new object instead of changing the original.</p>
<h2 id="built-in-math-functions">Built-in math functions ð§®</h2>
<p>Python also includes dunder methods for many math-related functions, both <a href="https://www.pythonmorsels.com/built-in-functions-in-python/#type" target="_blank">built-in functions</a> and some functions in the <code>math</code> library.</p>
<table>
<thead>
<tr>
<th>Operation</th>
<th>Dunder Method Call</th>
<th>Returns</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>divmod(x, y)</code></td>
<td><code>x.__divmod__(y)</code></td>
<td>2-item tuple</td>
</tr>
<tr>
<td><code>divmod(x, y)</code></td>
<td><code>y.__rdivmod__(x)</code></td>
<td>2-item tuple</td>
</tr>
<tr>
<td><code>abs(x)</code></td>
<td><code>x.__abs__()</code></td>
<td><code>float</code></td>
</tr>
<tr>
<td><code>sequence[x]</code></td>
<td><code>x.__index__()</code></td>
<td><code>int</code></td>
</tr>
<tr>
<td><code>round(x)</code></td>
<td><code>x.__round__()</code></td>
<td>Number</td>
</tr>
<tr>
<td><code>math.trunc(x)</code></td>
<td><code>x.__trunc__()</code></td>
<td>Number</td>
</tr>
<tr>
<td><code>math.floor(x)</code></td>
<td><code>x.__floor__()</code></td>
<td>Number</td>
</tr>
<tr>
<td><code>math.ceil(x)</code></td>
<td><code>x.__ceil__()</code></td>
<td>Number</td>
</tr>
</tbody>
</table>
<p>Python's <code>divmod</code> function performs <a href="https://www.pythonmorsels.com/integer-division/" target="_blank">integer division</a> (<code>//</code>) and a modulo operation (<code>%</code>) at the same time.
Note that, just like the many binary arithmetic operators, <code>divmod</code> will also check for an <code>__rvidmod__</code> method if it needs to ask the <em>second</em> argument to handle the operation.</p>
<p>The <code>__index__</code> method is for making integer-like objects.
This method losslessly converts to an integer, unlike <code>__int__</code> which may perform a "lossy" integer conversion (e.g. from <code>float</code> to <code>int</code>).
It's used by operations that require <em>true</em> integers, such as <a href="https://www.pythonmorsels.com/slicing/" target="_blank">slicing</a>, indexing, and <code>bin</code>, <code>hex</code>, and <code>oct</code> functions (<a href="https://pym.dev/p/2k9zt/" target="_blank">example</a>).</p>
<h2 id="attribute-access">Attribute access ð</h2>
<p>Python even includes dunder methods for controlling what happens when you access, delete, or assign any attribute on an object!</p>
<table>
<thead>
<tr>
<th>Operation</th>
<th>Dunder Method Call</th>
<th>Returns</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>x.missing</code></td>
<td><code>x.__getattr__("missing")</code></td>
<td>Attribute value</td>
</tr>
<tr>
<td><code>x.anything</code></td>
<td><code>x.__getattribute__("anything")</code></td>
<td>Attribute value</td>
</tr>
<tr>
<td><code>x.thing = value</code></td>
<td><code>x.__setattr__("thing", value)</code></td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>del x.thing</code></td>
<td><code>x.__delattr__("thing")</code></td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>dir(x)</code></td>
<td><code>x.__dir__()</code></td>
<td>List of strings</td>
</tr>
</tbody>
</table>
<p>The <code>__getattribute__</code> method is called for <em>every</em> attribute access, while the <code>__getattr__</code> method is only called after Python <em>fails</em> to find a given attribute.
All method calls and attribute accesses call <code>__getattribute__</code> so implementing it correctly is challenging (due to accidental <a href="https://www.pythonmorsels.com/what-is-recursion/" target="_blank">recursion</a>).</p>
<p>The <code>__dir__</code> method should return an iterable of attribute names (as strings).
When <a href="https://www.pythonmorsels.com/built-in-functions-in-python/#dir" target="_blank">the <code>dir</code> function</a> calls <code>__dir__</code>, it converts the returned iterable into a sorted list (like <a href="https://www.pythonmorsels.com/sorting-in-python/" target="_blank"><code>sorted</code></a> does).</p>
<p>The built-in <code>getattr</code>, <a href="https://www.pythonmorsels.com/python-setattr/" target="_blank"><code>setattr</code></a>, and <code>delattr</code> functions correspond to the dunder methods of the same name, but they're only intended for dynamic attribute access (not <em>all</em> attribute accesses).</p>

<p>Now we're getting into the really unusual dunder methods.
Python includes many dunder methods for metaprogramming-related features.</p>
<table>
<thead>
<tr>
<th>Implemented on</th>
<th>Operation</th>
<th>Dunder Method Call</th>
<th>Returns</th>
</tr>
</thead>
<tbody>
<tr>
<td>Metaclasses</td>
<td><code>class T: ...</code></td>
<td><code>type(base).__prepare__()</code></td>
<td>mapping</td>
</tr>
<tr>
<td>Metaclasses</td>
<td><code>isinstance(x, T)</code></td>
<td><code>T.__instancecheck__(x)</code></td>
<td><code>bool</code></td>
</tr>
<tr>
<td>Metaclasses</td>
<td><code>issubclass(U, T)</code></td>
<td><code>T.__subclasscheck__(U)</code></td>
<td><code>bool</code></td>
</tr>
<tr>
<td>Any class</td>
<td><code>class U(T): ...</code></td>
<td><code>T.__init_subclass__(U)</code></td>
<td><code>None</code></td>
</tr>
<tr>
<td>Any class</td>
<td>(Called manually)</td>
<td><code>T.__subclasses__()</code></td>
<td><code>list</code></td>
</tr>
<tr>
<td>Any class</td>
<td><code>class U(x): ...</code></td>
<td><code>x.__mro_entries__([x])</code></td>
<td><code>tuple</code></td>
</tr>
<tr>
<td>Any class</td>
<td><code>T[y]</code></td>
<td><code>T.__class_getitem__(y)</code></td>
<td>an item</td>
</tr>
</tbody>
</table>
<p>The <code>__prepare__</code> method customizes the dictionary that's used for a class's initial namespace.
This is used to pre-populate dictionary values or customize the dictionary type (<a href="https://pym.dev/p/23wfv/" target="_blank">silly example</a>).</p>
<p>The <code>__instancecheck__</code> and <code>__subclasscheck__</code> methods override the functionality of <code>isinstance</code> and <code>issubclass</code>.
Python's ABCs use these to practice <a href="https://www.pythonmorsels.com/goose-typing/" target="_blank">goose typing</a> (<a href="https://www.pythonmorsels.com/duck-typing/" target="_blank">duck typing</a> <em>while</em> type checking).</p>
<p>The <code>__init_subclass__</code> method allows classes to hook into subclass initialization (<a href="https://pym.dev/p/246z6/" target="_blank">example</a>).
Classes <em>also</em> have a <code>__subclasses__</code> method (on their <a href="https://docs.python.org/3/glossary.html#term-metaclass" target="_blank">metaclass</a>) but it's not typically overridden.</p>
<p>Python calls <code>__mro_entries__</code> during <a href="https://www.pythonmorsels.com/inheriting-one-class-another/" target="_blank">class inheritance</a> for any base classes that are not <em>actually</em> classes.
The <a href="https://docs.python.org/3/library/typing.html#typing.NamedTuple" target="_blank"><code>typing.NamedTuple</code></a> function uses this to pretend it's a class (<a href="https://pym.dev/p/2qgzd/" target="_blank">see here</a>).</p>
<p>The <code>__class_getitem__</code> method allows a class to be subscriptable (<em>without</em> its metaclass needing a <code>__getitem__</code> method).
This is typically used for enabling fancy type annotations (e.g. <code>list[int]</code>).</p>
<h2 id="descriptors">Descriptors ð·ï¸</h2>
<p><a href="https://docs.python.org/3/glossary.html#term-descriptor" target="_blank">Descriptors</a> are objects that, when attached to a class, can hook into the access of the attribute name they're attached to on that class.</p>
<table>
<thead>
<tr>
<th>Operation</th>
<th>Dunder Method Call</th>
<th>Returns</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>class T: x = U()</code></td>
<td><code>T.x.__set_name__(T, 'x')</code></td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>t.x</code></td>
<td><code>T.x.__get__(t, T)</code></td>
<td>The value</td>
</tr>
<tr>
<td><code>t.x = y</code></td>
<td><code>T.x.__set__(t, y)</code></td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>del t.x</code></td>
<td><code>T.x.__delete__(t)</code></td>
<td><code>None</code></td>
</tr>
</tbody>
</table>
<p>The descriptor protocol is <em>mostly</em> a feature that exists to make Python's <code>property</code> decorator work, though it is also used by a number of third-party libraries.</p>
<h2 id="buffers">Buffers ð¾</h2>
<p>Implementing a low-level memory array?
You need Python's <a href="https://docs.python.org/3/reference/datamodel.html#emulating-buffer-types" target="_blank">buffer protocol</a>.</p>
<table>
<thead>
<tr>
<th>Operation</th>
<th>Dunder Method Call</th>
<th>Returns</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>memoryview(x)</code></td>
<td><code>x.__buffer__(flags)</code></td>
<td><code>memoryview</code></td>
</tr>
<tr>
<td><code>del memoryview(x)</code></td>
<td><code>x.__release_buffer__(m)</code></td>
<td><code>None</code></td>
</tr>
</tbody>
</table>
<p>The <code>__release_buffer__</code> method is called when the buffer that's returned from <code>__buffer__</code> is deleted.</p>
<p>Python's buffer protocol is typically implemented in C, since it's meant for low level objects.</p>
<h2 id="asynchronous-operations">Asynchronous operations ð¤¹</h2>
<p>Want to implement an asynchronous context manager?
You need these dunder methods:</p>
<ul>
<li><code>__aenter__</code>: just like <code>__enter__</code>, but it returns an awaitable object</li>
<li><code>__aexit__</code>: just like <code>__exit__</code>, but it returns an awaitable object</li>
</ul>
<p>Need to support asynchronous iteration?
You need these dunder methods:</p>
<ul>
<li><code>__aiter__</code>: must return an asynchronous iterator</li>
<li><code>__anext__</code>: like <code>__next__</code> or non-async iterators, but this must return an awaitable object and this should raise <code>StopAsyncIteration</code> instead of <code>StopIteration</code></li>
</ul>
<p>Need to make your own awaitable object?
You need this dunder method:</p>
<ul>
<li><code>__await__</code>: returns an iterator</li>
</ul>
<p>I have little experience with custom asynchronous objects, so look elsewhere for more details.</p>
<h2 id="construction-and-finalizing">Construction and finalizing ð­</h2>
<p>The last few dunder methods are related to object creation and destruction.</p>
<table>
<thead>
<tr>
<th>Operation</th>
<th>Dunder Method Call</th>
<th>Returns</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>T(a, b=3)</code></td>
<td><code>T.__new__(T, a, b=3)</code></td>
<td>New instance (<code>x</code>)</td>
</tr>
<tr>
<td><code>T(a, b=3)</code></td>
<td><code>T.__init__(x, a, b=3)</code></td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>del x</code></td>
<td><code>x.__del__()</code></td>
<td><code>None</code></td>
</tr>
</tbody>
</table>
<p>Calling a class returns a new class instance thanks to the <code>__new__</code> method.
The <code>__new__</code> method is Python's <strong>constructor method</strong>, though unlike constructors in many programming languages, you should almost <em>never</em> define your own <code>__new__</code> method.
To control object creation, prefer the initializer (<code>__init__</code>), not the constructor (<code>__new__</code>).
<a href="https://pym.dev/p/28r9m/" target="_blank">Here's an odd <code>__new__</code> example</a>.</p>
<p>You could think of <code>__del__</code> as a "destructor" method, though it's actually called the <strong>finalizer method</strong>.
Just before an object is deleted, its <code>__del__</code> method is called (<a href="https://pym.dev/p/2hexg/" target="_blank">example</a>).
Files implement a <code>__del__</code> method that closes the file and any binary file buffer that it may be linked to.</p>
<h2 id="library-specific-dunder-methods">Library-specific dunder methods ð§°</h2>
<p>Some standard library modules define custom dunder methods that aren't used anywhere else:</p>
<ul>
<li><a href="https://www.pythonmorsels.com/dataclasses/" target="_blank">dataclasses</a> support a <code>__post_init__</code> method</li>
<li><code>abc.ABC</code> classes have a <code>__subclasshook__</code> method which <code>abc.ABCMeta</code> calls in its <code>__subclasscheck__</code> method (more in <a href="https://www.pythonmorsels.com/goose-typing/" target="_blank">goose typing</a>)</li>
<li>Path-like objects have a <code>__fspath__</code> method, which returns the file path as a string</li>
<li>Python's <code>copy</code> module will use the <code>__copy__</code> and <code>__deepcopy__</code> methods if present</li>
<li>Pickling relies on <code>__getnewargs_ex__</code> or <code>__getargs__</code>, though <code>__getstate__</code> and <code>__setstate__</code> can customize further and <code>__reduce__</code> or <code>__reduce_ex__</code> are even lower-level</li>
<li><code>sys.getsizeof</code> relies on the <code>__sizeof__</code> method to get an object's size (in bytes)</li>
</ul>
<h2 id="dunder-attributes">Dunder attributes ð</h2>
<p>In addition to dunder methods, Python has many non-method <strong>dunder attributes</strong>.</p>
<p>Here are some of the more common dunder attributes you'll see:</p>
<ul>
<li><code>__name__</code>: name of a function, classes, or module</li>
<li><code>__module__</code>: module name for a function or class</li>
<li><code>__doc__</code>: <a href="https://www.pythonmorsels.com/docstrings/" target="_blank">docstring</a> for a function, class, or module</li>
<li><code>__class__</code>: an object's class (call <a href="https://www.pythonmorsels.com/built-in-functions-in-python/#type" target="_blank">Python's <code>type</code> function</a> instead)</li>
<li><code>__dict__</code>: most objects store their attributes here (see <a href="https://www.pythonmorsels.com/where-are-attributes-stored/" target="_blank">where are attributes stored?</a>)</li>
<li><code>__slots__</code>: classes using this are more memory efficient than classes using <code>__dict__</code></li>
<li><code>__match_args__</code>: classes can define a tuple noting the significance of positional attributes when the class is used in structural pattern matching (<code>match</code>-<code>case</code>)</li>
<li><code>__mro__</code>: a class's method resolution order used when for attribute lookups and <code>super()</code> calls</li>
<li><code>__bases__</code>: the direct parent classes of a class</li>
<li><code>__file__</code>: the file that defined the module object (though not always present!)</li>
<li><code>__wrapped__</code>: functions decorated with <a href="https://docs.python.org/3/library/functools.html#functools.wraps" target="_blank"><code>functools.wraps</code></a> use this to point to the original function</li>
<li><code>__version__</code>: commonly used for noting the version of a package</li>
<li><code>__all__</code>: modules can use this to customize the behavior of <code>from my_module import *</code></li>
<li><code>__debug__</code>: running Python with <code>-O</code> sets this to <code>False</code> and disables Python's <code>assert</code> statements</li>
</ul>
<p>Those are only the more commonly seen dunder attributes.
Here are some more:</p>
<ul>
<li>Functions have <code>__defaults__</code>, <code>__kwdefaults__</code>, <code>__code__</code>, <code>__globals__</code>, and <code>__closure__</code></li>
<li>Both functions and classes have <code>__qualname__</code>, <code>__annotations__</code>, and <code>__type_params__</code></li>
<li>Instance methods have <code>__func__</code> and <code>__self__</code></li>
<li>Modules may also have <code>__loader__</code>, <code>__package__</code>, <code>__spec__</code>, and <code>__cached__</code> attributes</li>
<li>Packages have a <code>__path__</code> attribute</li>
<li>Exceptions have <code>__traceback__</code>, <code>__notes__</code>, <code>__context__</code>, <code>__cause__</code>, and <code>__suppress_context__</code></li>
<li>Descriptors use <code>__objclass__</code></li>
<li>Metaclasses use <code>__classcell__</code></li>
<li>Python's <code>weakref</code> module uses <code>__weakref__</code></li>
<li><a href="https://docs.python.org/3/library/stdtypes.html#type-annotation-types-generic-alias-union" target="_blank">Generic aliases</a> have <code>__origin__</code>, <code>__args__</code>, <code>__parameters__</code>, and <code>__unpacked__</code></li>
<li>The <code>sys</code> module has <code>__stdout__</code> and <code>__stderr__</code> which point to the original <code>stdout</code> and <code>stderr</code> versions</li>
</ul>
<p>Additionally, these dunder attributes are used by various standard library modules: <code>__covariant__</code>, <code>__contravariant__</code>, <code>__infer_variance__</code>, <code>__bound__</code>, <code>__constraints__</code>.
And Python includes a built-in <code>__import__</code> function which you're not supposed to use (<code>importlib.import_module</code> is preferred) and CPython has a <code>__builtins__</code> variable that points to the <code>builtins</code> module (but this is an implementation detail and <code>builtins</code> should be explicitly imported when needed instead).
Also importing from the <code>__future__</code> module can enable specific Python feature flags and Python will look for a <code>__main__</code> module within packages to make them runnable as CLI scripts.</p>
<p>And that's just <em>most</em> of the dunder attribute names you'll find floating around in Python. ðµ</p>
<h2 id="cheat-sheet">Every dunder method: a cheat sheet â­</h2>
<p>This is every Python dunder method organized in categories and ordered very roughly by the <strong>most commonly seen</strong> methods first.
Some caveats are noted below.</p>
<table>
<thead>
<tr>
<th>Category</th>
<th>Operation</th>
<th>Dunder Method Call</th>
<th>Returns</th>
</tr>
</thead>
<tbody>
<tr>
<td>Object Creation</td>
<td><code>x = T(a, b)</code></td>
<td><code>x.__init__(a, b)</code></td>
<td><code>None</code></td>
</tr>
<tr>
<td>Object Creation</td>
<td><code>x = T(a, b)</code></td>
<td><code>T.__new__(T, a, b)</code></td>
<td>New instance (<code>x</code>)</td>
</tr>
<tr>
<td>Finalizer</td>
<td><code>del x</code> (ish)</td>
<td><code>x.__del__()</code></td>
<td><code>None</code></td>
</tr>
<tr>
<td>Comparisons</td>
<td><code>x == y</code></td>
<td><code>x.__eq__(y)</code></td>
<td>Typically <code>bool</code></td>
</tr>
<tr>
<td>Comparisons</td>
<td><code>x != y</code></td>
<td><code>x.__ne__(y)</code></td>
<td>Typically <code>bool</code></td>
</tr>
<tr>
<td>Comparisons</td>
<td><code>x &lt; y</code></td>
<td><code>x.__lt__(y)</code></td>
<td>Typically <code>bool</code></td>
</tr>
<tr>
<td>Comparisons</td>
<td><code>x &gt; y</code></td>
<td><code>x.__rt__(y)</code></td>
<td>Typically <code>bool</code></td>
</tr>
<tr>
<td>Comparisons</td>
<td><code>x &lt;= y</code></td>
<td><code>x.__le__(y)</code></td>
<td>Typically <code>bool</code></td>
</tr>
<tr>
<td>Comparisons</td>
<td><code>x &gt;= y</code></td>
<td><code>x.__ge__(y)</code></td>
<td>Typically <code>bool</code></td>
</tr>
<tr>
<td>Hashability</td>
<td><code>hash(x)</code></td>
<td><code>x.__hash__()</code></td>
<td><code>int</code></td>
</tr>
<tr>
<td>Conversions</td>
<td><code>repr(x)</code></td>
<td><code>x.__repr__()</code></td>
<td>Always <code>str</code></td>
</tr>
<tr>
<td>Conversions</td>
<td><code>str(x)</code></td>
<td><code>x.__str__()</code></td>
<td>Always <code>str</code></td>
</tr>
<tr>
<td>Conversions</td>
<td><code>bool(x)</code></td>
<td><code>x.__bool__()</code></td>
<td>Always <code>bool</code></td>
</tr>
<tr>
<td>Conversions</td>
<td><code>int(x)</code></td>
<td><code>x.__int__()</code></td>
<td>Always <code>int</code></td>
</tr>
<tr>
<td>Conversions</td>
<td><code>float(x)</code></td>
<td><code>x.__float__()</code></td>
<td>Always <code>float</code></td>
</tr>
<tr>
<td>Conversions</td>
<td><code>bytes(x)</code></td>
<td><code>x.__bytes__()</code></td>
<td>Always <code>bytes</code></td>
</tr>
<tr>
<td>Conversions</td>
<td><code>complex(x)</code></td>
<td><code>x.__complex__()</code></td>
<td>Always <code>complex</code></td>
</tr>
<tr>
<td>Conversions</td>
<td><code>format(x, s)</code></td>
<td><code>x.__format__(s)</code></td>
<td>Always <code>str</code></td>
</tr>
<tr>
<td>Context Managers</td>
<td><code>with x as c:</code></td>
<td><code>x.__enter__()</code></td>
<td>The <code>c</code> object</td>
</tr>
<tr>
<td>Context Managers</td>
<td><code>with x as c:</code></td>
<td><code>x.__exit__()</code></td>
<td>Truthy/falsey value</td>
</tr>
<tr>
<td>Collections</td>
<td><code>len(x)</code></td>
<td><code>x.__len__()</code></td>
<td><code>int</code></td>
</tr>
<tr>
<td>Collections</td>
<td><code>iter(x)</code></td>
<td><code>x.__iter__()</code></td>
<td>An iterator</td>
</tr>
<tr>
<td>Collections</td>
<td><code>x[a]</code></td>
<td><code>x.__getitem__(a)</code></td>
<td></td>
</tr>
<tr>
<td>Collections</td>
<td><code>x[a] = b</code></td>
<td><code>x.__setitem__(a, b)</code></td>
<td><code>None</code></td>
</tr>
<tr>
<td>Collections</td>
<td><code>del x[a]</code></td>
<td><code>x.__delitem__(a)</code></td>
<td><code>None</code></td>
</tr>
<tr>
<td>Collections</td>
<td><code>a in x</code></td>
<td><code>x.__contains__(a)</code></td>
<td><code>bool</code></td>
</tr>
<tr>
<td>Collections</td>
<td><code>reversed(x)</code></td>
<td><code>x.__reversed__()</code></td>
<td>An iterator</td>
</tr>
<tr>
<td>Collections</td>
<td><code>next(x)</code></td>
<td><code>x.__next__()</code></td>
<td>Next iterator item</td>
</tr>
<tr>
<td>Collections</td>
<td><code>x[a]</code></td>
<td><code>x.__missing__(a)</code></td>
<td></td>
</tr>
<tr>
<td>Collections</td>
<td></td>
<td><code>x.__length_hint__()</code></td>
<td><code>int</code></td>
</tr>
<tr>
<td>Arithmetic</td>
<td><code>x + y</code></td>
<td><code>x.__add__(y)</code></td>
<td></td>
</tr>
<tr>
<td>Arithmetic</td>
<td><code>x + y</code></td>
<td><code>y.__radd__(x)</code></td>
<td></td>
</tr>
<tr>
<td>Arithmetic</td>
<td><code>x - y</code></td>
<td><code>x.__sub__(y)</code></td>
<td></td>
</tr>
<tr>
<td>Arithmetic</td>
<td><code>x - y</code></td>
<td><code>y.__rsub__(x)</code></td>
<td></td>
</tr>
<tr>
<td>Arithmetic</td>
<td><code>x * y</code></td>
<td><code>x.__mul__(y)</code></td>
<td></td>
</tr>
<tr>
<td>Arithmetic</td>
<td><code>x * y</code></td>
<td><code>y.__rmul__(x)</code></td>
<td></td>
</tr>
<tr>
<td>Arithmetic</td>
<td><code>x / y</code></td>
<td><code>x.__truediv__(y)</code></td>
<td></td>
</tr>
<tr>
<td>Arithmetic</td>
<td><code>x / y</code></td>
<td><code>y.__rtruediv__(x)</code></td>
<td></td>
</tr>
<tr>
<td>Arithmetic</td>
<td><code>x % y</code></td>
<td><code>x.__mod__(y)</code></td>
<td></td>
</tr>
<tr>
<td>Arithmetic</td>
<td><code>x % y</code></td>
<td><code>y.__rmod__(x)</code></td>
<td></td>
</tr>
<tr>
<td>Arithmetic</td>
<td><code>x // y</code></td>
<td><code>x.__floordiv__(y)</code></td>
<td></td>
</tr>
<tr>
<td>Arithmetic</td>
<td><code>x // y</code></td>
<td><code>y.__rfloordiv__(x)</code></td>
<td></td>
</tr>
<tr>
<td>Arithmetic</td>
<td><code>x ** y</code></td>
<td><code>x.__pow__(y)</code></td>
<td></td>
</tr>
<tr>
<td>Arithmetic</td>
<td><code>x ** y</code></td>
<td><code>y.__rpow__(x)</code></td>
<td></td>
</tr>
<tr>
<td>Arithmetic</td>
<td><code>x @ y</code></td>
<td><code>x.__matmul__(y)</code></td>
<td></td>
</tr>
<tr>
<td>Arithmetic</td>
<td><code>x @ y</code></td>
<td><code>y.__rmatmul__(x)</code></td>
<td></td>
</tr>
<tr>
<td>Arithmetic</td>
<td><code>x &amp; y</code></td>
<td><code>x.__and__(y)</code></td>
<td></td>
</tr>
<tr>
<td>Arithmetic</td>
<td><code>x &amp; y</code></td>
<td><code>y.__rand__(x)</code></td>
<td></td>
</tr>
<tr>
<td>Arithmetic</td>
<td><code>x | y</code></td>
<td><code>x.__or__(y)</code></td>
<td></td>
</tr>
<tr>
<td>Arithmetic</td>
<td><code>x | y</code></td>
<td><code>y.__ror__(x)</code></td>
<td></td>
</tr>
<tr>
<td>Arithmetic</td>
<td><code>x ^ y</code></td>
<td><code>x.__xor__(y)</code></td>
<td></td>
</tr>
<tr>
<td>Arithmetic</td>
<td><code>x ^ y</code></td>
<td><code>y.__rxor__(x)</code></td>
<td></td>
</tr>
<tr>
<td>Arithmetic</td>
<td><code>x &gt;&gt; y</code></td>
<td><code>x.__rshift__(y)</code></td>
<td></td>
</tr>
<tr>
<td>Arithmetic</td>
<td><code>x &gt;&gt; y</code></td>
<td><code>y.__rrshift__(x)</code></td>
<td></td>
</tr>
<tr>
<td>Arithmetic</td>
<td><code>x &lt;&lt; y</code></td>
<td><code>x.__lshift__(y)</code></td>
<td></td>
</tr>
<tr>
<td>Arithmetic</td>
<td><code>x &lt;&lt; y</code></td>
<td><code>y.__rlshift__(x)</code></td>
<td></td>
</tr>
<tr>
<td>Arithmetic</td>
<td><code>-x</code></td>
<td><code>x.__neg__()</code></td>
<td></td>
</tr>
<tr>
<td>Arithmetic</td>
<td><code>+x</code></td>
<td><code>x.__pos__()</code></td>
<td></td>
</tr>
<tr>
<td>Arithmetic</td>
<td><code>~x</code></td>
<td><code>x.__invert__()</code></td>
<td></td>
</tr>
<tr>
<td>Math functions</td>
<td><code>divmod(x, y)</code></td>
<td><code>x.__divmod__(y)</code></td>
<td>2-item tuple</td>
</tr>
<tr>
<td>Math functions</td>
<td><code>abs(x)</code></td>
<td><code>x.__abs__()</code></td>
<td><code>float</code></td>
</tr>
<tr>
<td>Math functions</td>
<td></td>
<td><code>x.__index__()</code></td>
<td><code>int</code></td>
</tr>
<tr>
<td>Math functions</td>
<td><code>round(x)</code></td>
<td><code>x.__round__()</code></td>
<td>Number</td>
</tr>
<tr>
<td>Math functions</td>
<td><code>math.trunc(x)</code></td>
<td><code>x.__trunc__()</code></td>
<td>Number</td>
</tr>
<tr>
<td>Math functions</td>
<td><code>math.floor(x)</code></td>
<td><code>x.__floor__()</code></td>
<td>Number</td>
</tr>
<tr>
<td>Math functions</td>
<td><code>math.ceil(x)</code></td>
<td><code>x.__ceil__()</code></td>
<td>Number</td>
</tr>
<tr>
<td>Assignment</td>
<td><code>x += y</code></td>
<td><code>x.__iadd__(y)</code></td>
<td>Typically <code>self</code></td>
</tr>
<tr>
<td>Assignment</td>
<td><code>x -= y</code></td>
<td><code>x.__isub__(y)</code></td>
<td>Typically <code>self</code></td>
</tr>
<tr>
<td>Assignment</td>
<td><code>x *= y</code></td>
<td><code>x.__imul__(y)</code></td>
<td>Typically <code>self</code></td>
</tr>
<tr>
<td>Assignment</td>
<td><code>x /= y</code></td>
<td><code>x.__itruediv__(y)</code></td>
<td>Typically <code>self</code></td>
</tr>
<tr>
<td>Assignment</td>
<td><code>x %= y</code></td>
<td><code>x.__imod__(y)</code></td>
<td>Typically <code>self</code></td>
</tr>
<tr>
<td>Assignment</td>
<td><code>x //= y</code></td>
<td><code>x.__ifloordiv__(y)</code></td>
<td>Typically <code>self</code></td>
</tr>
<tr>
<td>Assignment</td>
<td><code>x **= y</code></td>
<td><code>x.__ipow__(y)</code></td>
<td>Typically <code>self</code></td>
</tr>
<tr>
<td>Assignment</td>
<td><code>x @= y</code></td>
<td><code>x.__imatmul__(y)</code></td>
<td>Typically <code>self</code></td>
</tr>
<tr>
<td>Assignment</td>
<td><code>x &amp;= y</code></td>
<td><code>x.__iand__(y)</code></td>
<td>Typically <code>self</code></td>
</tr>
<tr>
<td>Assignment</td>
<td><code>x |= y</code></td>
<td><code>x.__ior__(y)</code></td>
<td>Typically <code>self</code></td>
</tr>
<tr>
<td>Assignment</td>
<td><code>x ^= y</code></td>
<td><code>x.__ixor__(y)</code></td>
<td>Typically <code>self</code></td>
</tr>
<tr>
<td>Assignment</td>
<td><code>x &gt;&gt;= y</code></td>
<td><code>x.__irshift__(y)</code></td>
<td>Typically <code>self</code></td>
</tr>
<tr>
<td>Assignment</td>
<td><code>x &lt;&lt;= y</code></td>
<td><code>x.__ilshift__(y)</code></td>
<td>Typically <code>self</code></td>
</tr>
<tr>
<td>Attributes</td>
<td><code>x.y</code></td>
<td><code>x.__getattribute__('y')</code></td>
<td></td>
</tr>
<tr>
<td>Attributes</td>
<td><code>x.y</code></td>
<td><code>x.__getattr__('y')</code></td>
<td></td>
</tr>
<tr>
<td>Attributes</td>
<td><code>x.y = z</code></td>
<td><code>x.__setattr__('y', z)</code></td>
<td><code>None</code></td>
</tr>
<tr>
<td>Attributes</td>
<td><code>del x.y</code></td>
<td><code>x.__delattr__('y')</code></td>
<td><code>None</code></td>
</tr>
<tr>
<td>Attributes</td>
<td><code>dir(x)</code></td>
<td><code>x.__dir__()</code></td>
<td>An iterable</td>
</tr>
<tr>
<td>Descriptors</td>
<td><code>class T: x = U()</code></td>
<td><code>T.x.__set_name__(T, 'x')</code></td>
<td><code>None</code></td>
</tr>
<tr>
<td>Descriptors</td>
<td><code>t.x</code></td>
<td><code>T.x.__get__(t, T)</code></td>
<td></td>
</tr>
<tr>
<td>Descriptors</td>
<td><code>t.x = y</code></td>
<td><code>T.x.__set__(t, y)</code></td>
<td><code>None</code></td>
</tr>
<tr>
<td>Descriptors</td>
<td><code>del t.x</code></td>
<td><code>T.x.__delete__(t)</code></td>
<td><code>None</code></td>
</tr>
<tr>
<td>Class stuff</td>
<td><code>class U(T): ...</code></td>
<td><code>T.__init_subclass__(U)</code></td>
<td><code>None</code></td>
</tr>
<tr>
<td>Class stuff</td>
<td><code>class U(x): ...</code></td>
<td><code>x.__mro_entries__([x])</code></td>
<td><code>tuple</code></td>
</tr>
<tr>
<td>Class stuff</td>
<td><code>T[y]</code></td>
<td><code>T.__class_getitem__(y)</code></td>
<td></td>
</tr>
<tr>
<td>Metaclasses</td>
<td><code>class T: ...</code></td>
<td><code>type(base).__prepare__()</code></td>
<td><code>dict</code>/mapping</td>
</tr>
<tr>
<td>Metaclasses</td>
<td><code>isinstance(x, T)</code></td>
<td><code>T.__instancecheck__(x)</code></td>
<td><code>bool</code></td>
</tr>
<tr>
<td>Metaclasses</td>
<td><code>issubclass(U, T)</code></td>
<td><code>T.__subclasscheck__(U)</code></td>
<td><code>bool</code></td>
</tr>
<tr>
<td>Async</td>
<td><code>await x</code> (ish)</td>
<td><code>x.__await__()</code></td>
<td>An iterator</td>
</tr>
<tr>
<td>Async</td>
<td><code>async with x:</code></td>
<td><code>x.__aenter__()</code></td>
<td>An awaitable</td>
</tr>
<tr>
<td>Async</td>
<td><code>async with x:</code></td>
<td><code>x.__aexit__()</code></td>
<td>An awaitable</td>
</tr>
<tr>
<td>Async</td>
<td><code>async for a in x:</code></td>
<td><code>x.__aiter__()</code></td>
<td>An awaitable</td>
</tr>
<tr>
<td>Async</td>
<td><code>async for a in x:</code></td>
<td><code>x.__anext__()</code></td>
<td>An awaitable</td>
</tr>
<tr>
<td>Buffers</td>
<td><code>memoryview(x)</code></td>
<td><code>x.__buffer__(flags)</code></td>
<td><code>memoryview</code></td>
</tr>
<tr>
<td>Buffers</td>
<td><code>del memoryview(x)</code></td>
<td><code>x.__release_buffer__(m)</code></td>
<td><code>None</code></td>
</tr>
</tbody>
</table>
<p>The above table has a slight but consistent <em>untruth</em>.
Most of these dunder methods are not <em>actually</em> called on an object directly but are instead called on the <em>type</em> of that object: <code>type(x).__add__(x, y)</code> instead of <code>x.__add__(y)</code>.
This distinction mostly matters with metaclass methods.</p>
<p>I've also purposely excluded library-specific dunder methods (like <code>__post_init__</code>) and dunder methods you're unlikely to ever define (like <code>__subclasses__</code>).
See those below.</p>
<table>
<thead>
<tr>
<th>Category</th>
<th>Operation</th>
<th>Dunder Method Call</th>
<th>Returns</th>
</tr>
</thead>
<tbody>
<tr>
<td>Dataclasses</td>
<td><code>x = T(a, b)</code></td>
<td><code>T.__post_init__(a, b)</code></td>
<td><code>None</code></td>
</tr>
<tr>
<td>Copying</td>
<td><code>copy.copy(x)</code></td>
<td><code>x.__copy__()</code></td>
<td>New object</td>
</tr>
<tr>
<td>Copying</td>
<td><code>copy.deepcopy(x)</code></td>
<td><code>x.__deepcopy__(memo)</code></td>
<td>New object</td>
</tr>
<tr>
<td><a href="https://docs.python.org/3/library/pickle.html#pickling-class-instances" target="_blank">Pickling</a></td>
<td><code>pickle.dumps(x)</code></td>
<td><code>x.__getnewargs__()</code></td>
<td>A 2-item tuple</td>
</tr>
<tr>
<td>Pickling</td>
<td><code>pickle.dumps(x)</code></td>
<td><code>x.__getnewargs_ex__()</code></td>
<td>A 2-item tuple</td>
</tr>
<tr>
<td>Pickling</td>
<td><code>pickle.dumps(x)</code></td>
<td><code>x.__getstate__()</code></td>
<td>A meaningful state</td>
</tr>
<tr>
<td>Pickling</td>
<td><code>pickle.dumps(x)</code></td>
<td><code>x.__reduce__()</code></td>
<td>A 2-6 item tuple</td>
</tr>
<tr>
<td>Pickling</td>
<td><code>pickle.dumps(x)</code></td>
<td><code>x.__reduce_ex__(4)</code></td>
<td>A 2-6 item tuple</td>
</tr>
<tr>
<td>Pickling</td>
<td><code>pickle.loads(b)</code></td>
<td><code>x.__setstate__(state)</code></td>
<td><code>None</code></td>
</tr>
<tr>
<td>pathlib</td>
<td><a href="https://docs.python.org/3/library/os.html#os.fspath" target="_blank"><code>os.fspath(x)</code></a></td>
<td><code>p.__fspath__()</code></td>
<td><code>str</code> or <code>bytes</code></td>
</tr>
<tr>
<td>sys</td>
<td><code>sys.getsizeof(x)</code></td>
<td><code>x.__sizeof__()</code></td>
<td><code>int</code> (size in bytes)</td>
</tr>
<tr>
<td>Class stuff</td>
<td>None?</td>
<td><code>x.__subclasses__()</code></td>
<td>Subclasses iterable</td>
</tr>
<tr>
<td>ABCs</td>
<td><code>issubclass(U, T)</code></td>
<td><code>T.__subclasshook__(U)</code></td>
<td><code>bool</code></td>
</tr>
</tbody>
</table>
<p>So, Python includes 103 "normal" dunder methods, 12 library-specific dunder methods, and at least 52 other dunder attributes of various types.
That's over 150 unique <code>__dunder__</code> names!
I <strong>do not recommend</strong> memorizing these: let Python do its job and look up the dunder method or attribute that you need to implement/find whenever you need it.</p>
<p>Keep in mind that <strong>you're not meant to invent your own dunder methods</strong>.
Sometimes you'll see third-party libraries that <em>do</em> invent their own dunder method, but this isn't encouraged and it can be quite confusing for users who run across such methods and assume they're "<em>real</em>" dunder methods.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[PyTorch Library for Running LLM on Intel CPU and GPU (129 pts)]]></title>
            <link>https://github.com/intel-analytics/ipex-llm</link>
            <guid>39915594</guid>
            <pubDate>Wed, 03 Apr 2024 10:28:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/intel-analytics/ipex-llm">https://github.com/intel-analytics/ipex-llm</a>, See on <a href="https://news.ycombinator.com/item?id=39915594">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><div dir="auto"><p dir="auto">Important</p><p dir="auto"><em><strong><code>bigdl-llm</code> has now become <code>ipex-llm</code> (see the migration guide <a href="https://ipex-llm.readthedocs.io/en/latest/doc/LLM/Quickstart/bigdl_llm_migration.html" rel="nofollow">here</a>); you may find the original <code>BigDL</code> project <a href="https://github.com/intel-analytics/BigDL-2.x">here</a>.</strong></em></p>
</div>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">ð« IPEX-LLM</h2><a id="user-content--ipex-llm" aria-label="Permalink: ð« IPEX-LLM" href="#-ipex-llm"></a></p>
<p dir="auto"><strong><code>IPEX-LLM</code></strong> is a PyTorch library for running <strong>LLM</strong> on Intel CPU and GPU <em>(e.g., local PC with iGPU, discrete GPU such as Arc, Flex and Max)</em> with very low latency<sup><a href="#user-content-fn-1-81ce39395d1a85f86f714ef670a086f0" id="user-content-fnref-1-81ce39395d1a85f86f714ef670a086f0" data-footnote-ref="" aria-describedby="footnote-label">1</a></sup>.</p>
<div dir="auto"><p dir="auto">Note</p>
<ul dir="auto">
<li><em>It is built on top of <strong>Intel Extension for PyTorch</strong> (<strong><code>IPEX</code></strong>), as well as the excellent work of <strong><code>llama.cpp</code></strong>, <strong><code>bitsandbytes</code></strong>, <strong><code>vLLM</code></strong>, <strong><code>qlora</code></strong>, <strong><code>AutoGPTQ</code></strong>, <strong><code>AutoAWQ</code></strong>, etc.</em></li>
<li><em>It provides seamless integration with <a href="https://ipex-llm.readthedocs.io/en/latest/doc/LLM/Quickstart/llama_cpp_quickstart.html" rel="nofollow">llama.cpp</a>, <a href="https://ipex-llm.readthedocs.io/en/latest/doc/LLM/Quickstart/webui_quickstart.html" rel="nofollow">Text-Generation-WebUI</a>, <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels">HuggingFace tansformers</a>, <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/LLM-Finetuning">HuggingFace PEFT</a>, <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/LangChain">LangChain</a>, <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/LlamaIndex">LlamaIndex</a>, <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/Deepspeed-AutoTP">DeepSpeed-AutoTP</a>, <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/vLLM-Serving">vLLM</a>, <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/src/ipex_llm/serving/fastchat">FastChat</a>, <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/LLM-Finetuning/DPO">HuggingFace TRL</a>, <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/Applications/autogen">AutoGen</a>, <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/ModelScope-Models">ModeScope</a>, etc.</em></li>
<li><em><strong>50+ models</strong> have been optimized/verified on <code>ipex-llm</code> (including LLaMA2, Mistral, Mixtral, Gemma, LLaVA, Whisper, ChatGLM, Baichuan, Qwen, RWKV, and more); see the complete list <a href="#verified-models">here</a>.</em></li>
</ul>
</div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Latest Update ð¥</h2><a id="user-content-latest-update-" aria-label="Permalink: Latest Update ð¥" href="#latest-update-"></a></p>
<ul dir="auto">
<li>[2024/03] <code>bigdl-llm</code> has now become <code>ipex-llm</code> (see the migration guide <a href="https://ipex-llm.readthedocs.io/en/latest/doc/LLM/Quickstart/bigdl_llm_migration.html" rel="nofollow">here</a>); you may find the original <code>BigDL</code> project <a href="https://github.com/intel-analytics/bigdl-2.x">here</a>.</li>
<li>[2024/02] <code>ipex-llm</code> now supports directly loading model from <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/ModelScope-Models">ModelScope</a> (<a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/ModelScope-Models">é­æ­</a>).</li>
<li>[2024/02] <code>ipex-llm</code> added inital <strong>INT2</strong> support (based on llama.cpp <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Advanced-Quantizations/GGUF-IQ2">IQ2</a> mechanism), which makes it possible to run large-size LLM (e.g., Mixtral-8x7B) on Intel GPU with 16GB VRAM.</li>
<li>[2024/02] Users can now use <code>ipex-llm</code> through <a href="https://github.com/intel-analytics/text-generation-webui">Text-Generation-WebUI</a> GUI.</li>
<li>[2024/02] <code>ipex-llm</code> now supports <em><a href="https://ipex-llm.readthedocs.io/en/latest/doc/LLM/Inference/Self_Speculative_Decoding.html" rel="nofollow">Self-Speculative Decoding</a></em>, which in practice brings <strong>~30% speedup</strong> for FP16 and BF16 inference latency on Intel <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/Speculative-Decoding">GPU</a> and <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/Speculative-Decoding">CPU</a> respectively.</li>
<li>[2024/02] <code>ipex-llm</code> now supports a comprehensive list of LLM <strong>finetuning</strong> on Intel GPU (including <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/LLM-Finetuning/LoRA">LoRA</a>, <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/LLM-Finetuning/QLoRA">QLoRA</a>, <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/LLM-Finetuning/DPO">DPO</a>, <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/LLM-Finetuning/QA-LoRA">QA-LoRA</a> and <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/LLM-Finetuning/ReLora">ReLoRA</a>).</li>
<li>[2024/01] Using <code>ipex-llm</code> <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/LLM-Finetuning/QLoRA">QLoRA</a>, we managed to finetune LLaMA2-7B in <strong>21 minutes</strong> and LLaMA2-70B in <strong>3.14 hours</strong> on 8 Intel Max 1550 GPU for <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/LLM-Finetuning/QLoRA/alpaca-qlora">Standford-Alpaca</a> (see the blog <a href="https://www.intel.com/content/www/us/en/developer/articles/technical/finetuning-llms-on-intel-gpus-using-bigdl-llm.html" rel="nofollow">here</a>).</li>
</ul>
<details><summary>More updates</summary>
<br>
<ul dir="auto">
<li>[2023/12] <code>ipex-llm</code> now supports <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/LLM-Finetuning/ReLora">ReLoRA</a> (see <em><a href="https://arxiv.org/abs/2307.05695" rel="nofollow">"ReLoRA: High-Rank Training Through Low-Rank Updates"</a></em>).</li>
<li>[2023/12] <code>ipex-llm</code> now supports <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/mixtral">Mixtral-8x7B</a> on both Intel <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/mixtral">GPU</a> and <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/mixtral">CPU</a>.</li>
<li>[2023/12] <code>ipex-llm</code> now supports <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/LLM-Finetuning/QA-LoRA">QA-LoRA</a> (see <em><a href="https://arxiv.org/abs/2309.14717" rel="nofollow">"QA-LoRA: Quantization-Aware Low-Rank Adaptation of Large Language Models"</a></em>).</li>
<li>[2023/12] <code>ipex-llm</code> now supports <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/More-Data-Types">FP8 and FP4 inference</a> on Intel <em><strong>GPU</strong></em>.</li>
<li>[2023/11] Initial support for directly loading <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Advanced-Quantizations/GGUF">GGUF</a>, <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Advanced-Quantizations/AWQ">AWQ</a> and <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Advanced-Quantizations/GPTQ">GPTQ</a> models into <code>ipex-llm</code> is available.</li>
<li>[2023/11] <code>ipex-llm</code> now supports <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/vLLM-Serving">vLLM continuous batching</a> on both Intel <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/vLLM-Serving">GPU</a> and <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/vLLM-Serving">CPU</a>.</li>
<li>[2023/10] <code>ipex-llm</code> now supports <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/LLM-Finetuning/QLoRA">QLoRA finetuning</a> on both Intel <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/LLM-Finetuning/QLoRA">GPU</a> and <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/QLoRA-FineTuning">CPU</a>.</li>
<li>[2023/10] <code>ipex-llm</code> now supports <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/src/ipex_llm/llm/serving">FastChat serving</a> on on both Intel CPU and GPU.</li>
<li>[2023/09] <code>ipex-llm</code> now supports <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU">Intel GPU</a> (including iGPU, Arc, Flex and MAX).</li>
<li>[2023/09] <code>ipex-llm</code> <a href="https://github.com/intel-analytics/ipex-llm-tutorial">tutorial</a> is released.</li>
</ul>
</details> 
<p dir="auto"><h2 tabindex="-1" dir="auto"><code>ipex-llm</code> Demos</h2><a id="user-content-ipex-llm-demos" aria-label="Permalink: ipex-llm Demos" href="#ipex-llm-demos"></a></p>
<p dir="auto">See the <em><strong>optimized performance</strong></em> of <code>chatglm2-6b</code> and <code>llama-2-13b-chat</code> models on 12th Gen Intel Core CPU and Intel Arc GPU below.</p>
<table>
  <tbody><tr>
    <td colspan="2">12th Gen Intel Core CPU</td>
    <td colspan="2">Intel Arc GPU</td>
  </tr>
  <tr>
    <td>
      <a href="https://llm-assets.readthedocs.io/en/latest/_images/chatglm2-6b.gif" rel="nofollow"><img src="https://camo.githubusercontent.com/5187917ac33da777422df36def0302560f3b9d9d79b4b020764e0fa701b611c7/68747470733a2f2f6c6c6d2d6173736574732e72656164746865646f63732e696f2f656e2f6c61746573742f5f696d616765732f63686174676c6d322d36622e676966" data-animated-image="" data-canonical-src="https://llm-assets.readthedocs.io/en/latest/_images/chatglm2-6b.gif"></a>
    </td>
    <td>
      <a href="https://llm-assets.readthedocs.io/en/latest/_images/llama-2-13b-chat.gif" rel="nofollow"><img src="https://camo.githubusercontent.com/4a27da6ff50259d31abd699ed6c247d3fc6e6d1f893437eb8d724aca3a397cf8/68747470733a2f2f6c6c6d2d6173736574732e72656164746865646f63732e696f2f656e2f6c61746573742f5f696d616765732f6c6c616d612d322d3133622d636861742e676966" data-animated-image="" data-canonical-src="https://llm-assets.readthedocs.io/en/latest/_images/llama-2-13b-chat.gif"></a>
    </td>
    <td>
      <a href="https://llm-assets.readthedocs.io/en/latest/_images/chatglm2-arc.gif" rel="nofollow"><img src="https://camo.githubusercontent.com/c2e9977f1f6da5638a29338d6ab92626b5f145c477702172a57fd56a6f051c49/68747470733a2f2f6c6c6d2d6173736574732e72656164746865646f63732e696f2f656e2f6c61746573742f5f696d616765732f63686174676c6d322d6172632e676966" data-animated-image="" data-canonical-src="https://llm-assets.readthedocs.io/en/latest/_images/chatglm2-arc.gif"></a>
    </td>
    <td>
      <a href="https://llm-assets.readthedocs.io/en/latest/_images/llama2-13b-arc.gif" rel="nofollow"><img src="https://camo.githubusercontent.com/72c7b4450963b24247649726d8f4cefe1f7d70ae75729309fae63447e8b55995/68747470733a2f2f6c6c6d2d6173736574732e72656164746865646f63732e696f2f656e2f6c61746573742f5f696d616765732f6c6c616d61322d3133622d6172632e676966" data-animated-image="" data-canonical-src="https://llm-assets.readthedocs.io/en/latest/_images/llama2-13b-arc.gif"></a>
    </td>
  </tr>
  <tr>
    <td><code>chatglm2-6b</code></td>
    <td><code>llama-2-13b-chat</code></td>
    <td><code>chatglm2-6b</code></td>
    <td><code>llama-2-13b-chat</code></td>
  </tr>
</tbody></table>
<p dir="auto"><h2 tabindex="-1" dir="auto"><code>ipex-llm</code> Quickstart</h2><a id="user-content-ipex-llm-quickstart" aria-label="Permalink: ipex-llm Quickstart" href="#ipex-llm-quickstart"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Install <code>ipex-llm</code></h3><a id="user-content-install-ipex-llm" aria-label="Permalink: Install ipex-llm" href="#install-ipex-llm"></a></p>
<ul dir="auto">
<li><a href="https://ipex-llm.readthedocs.io/en/latest/doc/LLM/Quickstart/install_windows_gpu.html" rel="nofollow">Windows GPU</a>: installing <code>ipex-llm</code> on Windows with Intel GPU</li>
<li><a href="https://ipex-llm.readthedocs.io/en/latest/doc/LLM/Quickstart/install_linux_gpu.html" rel="nofollow">Linux GPU</a>: installing <code>ipex-llm</code> on Linux with Intel GPU</li>
<li><a href="https://github.com/intel-analytics/ipex-llm/blob/main/docker/llm">Docker</a>: using <code>ipex-llm</code> dockers on Intel CPU and GPU</li>
<li><em>For more details, please refer to the <a href="https://ipex-llm.readthedocs.io/en/latest/doc/LLM/Overview/install.html" rel="nofollow">installation guide</a></em></li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Run <code>ipex-llm</code></h3><a id="user-content-run-ipex-llm" aria-label="Permalink: Run ipex-llm" href="#run-ipex-llm"></a></p>
<ul dir="auto">
<li><a href="https://ipex-llm.readthedocs.io/en/latest/doc/LLM/Quickstart/llama_cpp_quickstart.html" rel="nofollow">llama.cpp</a>: running <strong>ipex-llm for llama.cpp</strong> (<em>using C++ interface of <code>ipex-llm</code> as an accelerated backend for <code>llama.cpp</code> on Intel GPU</em>)</li>
<li><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/vLLM-Serving">vLLM</a>: running <code>ipex-llm</code> in <code>vLLM</code> on both Intel <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/vLLM-Serving">GPU</a> and <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/vLLM-Serving">CPU</a></li>
<li><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/src/ipex_llm/serving/fastchat">FastChat</a>: running <code>ipex-llm</code> in <code>FastChat</code> serving on on both Intel GPU and CPU</li>
<li><a href="https://github.com/intel-analytics/Langchain-Chatchat">LangChain-Chatchat RAG</a>: running <code>ipex-llm</code> in <code>LangChain-Chatchat</code> (<em>Knowledge Base QA using <strong>RAG</strong> pipeline</em>)</li>
<li><a href="https://ipex-llm.readthedocs.io/en/latest/doc/LLM/Quickstart/webui_quickstart.html" rel="nofollow">Text-Generation-WebUI</a>: running <code>ipex-llm</code> in <code>oobabooga</code> <strong>WebUI</strong></li>
<li><a href="https://ipex-llm.readthedocs.io/en/latest/doc/LLM/Quickstart/benchmark_quickstart.html" rel="nofollow">Benchmarking</a>: running  (latency and throughput) benchmarks for <code>ipex-llm</code> on Intel CPU and GPU</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Code Examples</h3><a id="user-content-code-examples" aria-label="Permalink: Code Examples" href="#code-examples"></a></p>
<ul dir="auto">
<li>Low bit inference
<ul dir="auto">
<li><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model">INT4 inference</a>: <strong>INT4</strong> LLM inference on Intel <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model">GPU</a> and <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model">CPU</a></li>
<li><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/More-Data-Types">FP8/FP4 inference</a>: <strong>FP8</strong> and <strong>FP4</strong> LLM inference on Intel <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/More-Data-Types">GPU</a></li>
<li><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/More-Data-Types">INT8 inference</a>: <strong>INT8</strong> LLM inference on Intel <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/More-Data-Types">GPU</a> and <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/More-Data-Types">CPU</a></li>
<li><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Advanced-Quantizations/GGUF-IQ2">INT2 inference</a>: <strong>INT2</strong> LLM inference (based on llama.cpp IQ2 mechanism) on Intel <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Advanced-Quantizations/GGUF-IQ2">GPU</a></li>
</ul>
</li>
<li>FP16/BF16 inference
<ul dir="auto">
<li><strong>FP16</strong> LLM inference on Intel <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/Speculative-Decoding">GPU</a>, with possible <a href="https://ipex-llm.readthedocs.io/en/latest/doc/LLM/Inference/Self_Speculative_Decoding.html" rel="nofollow">self-speculative decoding</a> optimization</li>
<li><strong>BF16</strong> LLM inference on Intel <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/Speculative-Decoding">CPU</a>, with possible <a href="https://ipex-llm.readthedocs.io/en/latest/doc/LLM/Inference/Self_Speculative_Decoding.html" rel="nofollow">self-speculative decoding</a> optimization</li>
</ul>
</li>
<li>Save and load
<ul dir="auto">
<li><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Save-Load">Low-bit models</a>: saving and loading <code>ipex-llm</code> low-bit models</li>
<li><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Advanced-Quantizations/GGUF">GGUF</a>: directly loading GGUF models into <code>ipex-llm</code></li>
<li><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Advanced-Quantizations/AWQ">AWQ</a>: directly loading AWQ models into <code>ipex-llm</code></li>
<li><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Advanced-Quantizations/GPTQ">GPTQ</a>: directly loading GPTQ models into <code>ipex-llm</code></li>
</ul>
</li>
<li>Finetuning
<ul dir="auto">
<li>LLM finetuning on Intel <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/LLM-Finetuning">GPU</a>, including <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/LLM-Finetuning/LoRA">LoRA</a>, <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/LLM-Finetuning/QLoRA">QLoRA</a>, <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/LLM-Finetuning/DPO">DPO</a>, <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/LLM-Finetuning/QA-LoRA">QA-LoRA</a> and <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/LLM-Finetuning/ReLora">ReLoRA</a></li>
<li>QLoRA finetuning on Intel <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/QLoRA-FineTuning">CPU</a></li>
</ul>
</li>
<li>Integration with community libraries
<ul dir="auto">
<li><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels">HuggingFace tansformers</a></li>
<li><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/PyTorch-Models">Standard PyTorch model</a></li>
<li><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/Deepspeed-AutoTP">DeepSpeed-AutoTP</a></li>
<li><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/LLM-Finetuning/HF-PEFT">HuggingFace PEFT</a></li>
<li><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/LLM-Finetuning/DPO">HuggingFace TRL</a></li>
<li><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/LangChain">LangChain</a></li>
<li><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/LlamaIndex">LlamaIndex</a></li>
<li><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/Applications/autogen">AutoGen</a></li>
<li><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/ModelScope-Models">ModeScope</a></li>
</ul>
</li>
<li><a href="https://github.com/intel-analytics/ipex-llm-tutorial">Tutorials</a></li>
</ul>
<p dir="auto"><em>For more details, please refer to the <code>ipex-llm</code> document <a href="https://ipex-llm.readthedocs.io/" rel="nofollow">website</a>.</em></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Verified Models</h2><a id="user-content-verified-models" aria-label="Permalink: Verified Models" href="#verified-models"></a></p>
<p dir="auto">Over 50 models have been optimized/verified on <code>ipex-llm</code>, including <em>LLaMA/LLaMA2, Mistral, Mixtral, Gemma, LLaVA, Whisper, ChatGLM2/ChatGLM3, Baichuan/Baichuan2, Qwen/Qwen-1.5, InternLM</em> and more; see the list below.</p>
<table>
<thead>
<tr>
<th>Model</th>
<th>CPU Example</th>
<th>GPU Example</th>
</tr>
</thead>
<tbody>
<tr>
<td>LLaMA <em>(such as Vicuna, Guanaco, Koala, Baize, WizardLM, etc.)</em></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/Native-Models">link1</a>, <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/vicuna">link2</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/vicuna">link</a></td>
</tr>
<tr>
<td>LLaMA 2</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/Native-Models">link1</a>, <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/llama2">link2</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/llama2">link</a></td>
</tr>
<tr>
<td>ChatGLM</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/chatglm">link</a></td>
<td></td>
</tr>
<tr>
<td>ChatGLM2</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/chatglm2">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/chatglm2">link</a></td>
</tr>
<tr>
<td>ChatGLM3</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/chatglm3">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/chatglm3">link</a></td>
</tr>
<tr>
<td>Mistral</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/mistral">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/mistral">link</a></td>
</tr>
<tr>
<td>Mixtral</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/mixtral">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/mixtral">link</a></td>
</tr>
<tr>
<td>Falcon</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/falcon">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/falcon">link</a></td>
</tr>
<tr>
<td>MPT</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/mpt">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/mpt">link</a></td>
</tr>
<tr>
<td>Dolly-v1</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/dolly_v1">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/dolly-v1">link</a></td>
</tr>
<tr>
<td>Dolly-v2</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/dolly_v2">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/dolly-v2">link</a></td>
</tr>
<tr>
<td>Replit Code</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/replit">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/replit">link</a></td>
</tr>
<tr>
<td>RedPajama</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/Native-Models">link1</a>, <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/redpajama">link2</a></td>
<td></td>
</tr>
<tr>
<td>Phoenix</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/Native-Models">link1</a>, <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/phoenix">link2</a></td>
<td></td>
</tr>
<tr>
<td>StarCoder</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/Native-Models">link1</a>, <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/starcoder">link2</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/starcoder">link</a></td>
</tr>
<tr>
<td>Baichuan</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/baichuan">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/baichuan">link</a></td>
</tr>
<tr>
<td>Baichuan2</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/baichuan2">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/baichuan2">link</a></td>
</tr>
<tr>
<td>InternLM</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/internlm">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/internlm">link</a></td>
</tr>
<tr>
<td>Qwen</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/qwen">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/qwen">link</a></td>
</tr>
<tr>
<td>Qwen1.5</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/qwen1.5">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/qwen1.5">link</a></td>
</tr>
<tr>
<td>Qwen-VL</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/qwen-vl">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/qwen-vl">link</a></td>
</tr>
<tr>
<td>Aquila</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/aquila">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/aquila">link</a></td>
</tr>
<tr>
<td>Aquila2</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/aquila2">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/aquila2">link</a></td>
</tr>
<tr>
<td>MOSS</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/moss">link</a></td>
<td></td>
</tr>
<tr>
<td>Whisper</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/whisper">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/whisper">link</a></td>
</tr>
<tr>
<td>Phi-1_5</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/phi-1_5">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/phi-1_5">link</a></td>
</tr>
<tr>
<td>Flan-t5</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/flan-t5">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/flan-t5">link</a></td>
</tr>
<tr>
<td>LLaVA</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/PyTorch-Models/Model/llava">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/PyTorch-Models/Model/llava">link</a></td>
</tr>
<tr>
<td>CodeLlama</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/codellama">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/codellama">link</a></td>
</tr>
<tr>
<td>Skywork</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/skywork">link</a></td>
<td></td>
</tr>
<tr>
<td>InternLM-XComposer</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/internlm-xcomposer">link</a></td>
<td></td>
</tr>
<tr>
<td>WizardCoder-Python</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/wizardcoder-python">link</a></td>
<td></td>
</tr>
<tr>
<td>CodeShell</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/codeshell">link</a></td>
<td></td>
</tr>
<tr>
<td>Fuyu</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/fuyu">link</a></td>
<td></td>
</tr>
<tr>
<td>Distil-Whisper</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/distil-whisper">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/distil-whisper">link</a></td>
</tr>
<tr>
<td>Yi</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/yi">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/yi">link</a></td>
</tr>
<tr>
<td>BlueLM</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/bluelm">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/bluelm">link</a></td>
</tr>
<tr>
<td>Mamba</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/PyTorch-Models/Model/mamba">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/PyTorch-Models/Model/mamba">link</a></td>
</tr>
<tr>
<td>SOLAR</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/solar">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/solar">link</a></td>
</tr>
<tr>
<td>Phixtral</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/phixtral">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/phixtral">link</a></td>
</tr>
<tr>
<td>InternLM2</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/internlm2">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/internlm2">link</a></td>
</tr>
<tr>
<td>RWKV4</td>
<td></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/rwkv4">link</a></td>
</tr>
<tr>
<td>RWKV5</td>
<td></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/rwkv5">link</a></td>
</tr>
<tr>
<td>Bark</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/PyTorch-Models/Model/bark">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/PyTorch-Models/Model/bark">link</a></td>
</tr>
<tr>
<td>SpeechT5</td>
<td></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/PyTorch-Models/Model/speech-t5">link</a></td>
</tr>
<tr>
<td>DeepSeek-MoE</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/deepseek-moe">link</a></td>
<td></td>
</tr>
<tr>
<td>Ziya-Coding-34B-v1.0</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/ziya">link</a></td>
<td></td>
</tr>
<tr>
<td>Phi-2</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/phi-2">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/phi-2">link</a></td>
</tr>
<tr>
<td>Yuan2</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/yuan2">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/yuan2">link</a></td>
</tr>
<tr>
<td>Gemma</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/gemma">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/gemma">link</a></td>
</tr>
<tr>
<td>DeciLM-7B</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/deciLM-7b">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/deciLM-7b">link</a></td>
</tr>
<tr>
<td>Deepseek</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/deepseek">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/deepseek">link</a></td>
</tr>
<tr>
<td>StableLM</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/stablelm">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/stablelm">link</a></td>
</tr>
</tbody>
</table>
<section data-footnotes="">
<ol dir="auto">
<li id="user-content-fn-1-81ce39395d1a85f86f714ef670a086f0">
<p dir="auto">Performance varies by use, configuration and other factors. <code>ipex-llm</code> may not optimize to the same degree for non-Intel products. Learn more at <a href="http://www.intel.com/PerformanceIndex">www.Intel.com/PerformanceIndex</a>. <a href="#user-content-fnref-1-81ce39395d1a85f86f714ef670a086f0" data-footnote-backref="" aria-label="Back to reference 1">â©</a></p>
</li>
</ol>
</section>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Redict 7.3.0, a copyleft fork of Redis, is now available (184 pts)]]></title>
            <link>https://redict.io/posts/2024-04-03-redict-7.3.0-released/</link>
            <guid>39915473</guid>
            <pubDate>Wed, 03 Apr 2024 10:10:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://redict.io/posts/2024-04-03-redict-7.3.0-released/">https://redict.io/posts/2024-04-03-redict-7.3.0-released/</a>, See on <a href="https://news.ycombinator.com/item?id=39915473">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
  <h2>
    <a href="https://redict.io/posts/2024-04-03-redict-7.3.0-released/">Redict 7.3.0 is now available</a>
    <br><small>Drew DeVault</small>
  </h2>
  
  <h5>April 3, 2024</h5>



  

  



<p>The Redict community is pleased to announce the release of Redict 7.3.0, the
first stable version of our copyleft fork of RedisÂ® OSS 7.2.4.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> You can
download the release <a href="https://codeberg.org/redict/redict/releases/tag/7.3.0">on Codeberg</a>, or download one of our official
<a href="https://redict.io/docs/install/containers/">container images</a> from registry.redict.io.</p>
<p>We have written comprehensive documentation detailing our <a href="https://redict.io/docs/redis-compat/">compatibility with
RedisÂ® OSS 7.2.4</a>, which also provides detailed documentation for
various migration scenarios, such as for users of the official RedisÂ®
containers on Docker Hub, downstream package maintainers, and so on.</p>
<p>We have tested Redict thoroughly with a variety of migration scenarios, but we
may have missed a detail that pertains to your use-case. If you have any issues
or questions with respect to the migration process, please <a href="https://redict.io/docs/community">join our community
spaces</a> to get help.</p>
<h2 id="why-redict">
  Why Redict?
  <a href="#why-redict">#</a>
</h2>
<p>You may be wondering why Redict would be of interest to you, particularly when
compared with <a href="https://www.linuxfoundation.org/press/linux-foundation-launches-open-source-valkey-community">Valkey</a>, another RedisÂ® fork that was announced on Thursday.</p>
<p>In technical terms, we are focusing on stability and long-term maintenance, and
on achieving excellence within our current scope. We believe that Redict is near
feature-complete and that it is more valuable to our users if we take a
conservative stance to innovation and focus on long-term reliability instead.
This is in part a choice weâve made to distinguish ourselves from Valkey, whose
commercial interests are able to invest more resources into developing more
radical innovations, but also an acknowledgement of a cultural difference
between our projects, in that the folks behind Redict place greater emphasis on
software with a finite scope and ambitions towards long-term stability
rather than focusing on long-term growth in scope and complexity.</p>
<p>We will happily pull useful changes from software with permissive licenses, such
as Valkey, to improve Redict; such is the value of permissive software and the
key advantage of free software generally. However, we will do so at a more
conservative pace, so that our users can enjoy stability first and shiny new
features second. We are also going to focus on establishing and maintaining a
good relationship with downstream distributions, prioritizing their needs with
respect to tasks such as de-vendoring Lua and jemalloc.</p>
<p>Redict also has social and political aims which differ from other forks. In
short, we believe in an approach which is built from an independent, grassroots,
and community-focused means of building our software. We are not governed by the
consensus of a small group of commercial interests, but rather by an independent
and community-driven consensus. Importantly, we have also chosen to protect our
software from further exploitation by applying the Lesser GNU General Public
License (LGPL) to our work.</p>
<p>Our choice of license prevents the hard work of our contributors from being
incorporated into the now-proprietary RedisÂ® software, and from any future
attempts to create proprietary distributions of Redict. However, our choice of
the LGPL balances this concern with the needs of commercial users&nbsp;â we
have selected this license in part to ensure that cloud providers can continue
to offer Redict to their customers without being subject to onerous compliance
regimes.</p>
<blockquote>
  <strong>Note</strong>: Check out our <a href="https://redict.io/docs/license">About the license</a> page for more
information about the license of Redict.
</blockquote>

<p>Weâve made these choices because we believe they are essential in providing for
a future which is based on free software, and in which the rug cannot be pulled
out from under our users and contributors again. We believe it is essential to
make these choices now, at the onset of our fork, especially in response to the
crisis that the RedisÂ® community is faced with at the hands of its
commercial stewards. If you donât want your investment in this software to risk
another artificial crisis in the name of profit, if you want to enjoy the
protection of copyleft and a guarantee that your software will remain free, then
we encourage you to adopt Redict for your needs.</p>
<p>We have also taken this opportunity to re-evaluate our infrastructure and double
down on using free software. Rather than continuing to use the proprietary
GitHub forge, we have elected to use the non-profit, free software
<a href="https://codeberg.org/">Codeberg</a> as our home, and we run our continuous
integration on <a href="https://sourcehut.org/">SourceHut</a>, which is also free software.
Moreover, rather than gathering on Discord, we have chosen instead to set up our
community on <a href="https://redict.io/docs/community">Matrix and IRC</a>. We believe that the RedisÂ® license
change provides us an opportunity to focus on our values as members of the free
software community, to exercise solidarity, and to lend our strength to
re-enforce the broader free software ecosystem. As such, we felt it important to
choose free software solutions for our infrastructure needs.</p>
<h2 id="acknowledgements">
  Acknowledgements
  <a href="#acknowledgements">#</a>
</h2>
<p>Iâd like to extend a personal âthanksâ to everyone who was involved in bringing
this fork to life. In particular, Micke Nordin and Hugo, for their work on the
Redict containers; Lucas Dohmen, for his extensive work on the documentation and
website; and Anna, for her work forking and maintaining <a href="https://codeberg.org/redict/hiredict">hiredict</a>; as well as
everyone who contributed small patches here and there, and everyone who helped
with the rapid turn-around and testing of Redictâs release candidates. Shoutout
to @janWilejan for designing our logo, and to everyone else who submitted their
artwork for consideration.</p>
<p>Thanks are also due, of course, to all of the many contributors who worked on
RedisÂ® OSS, commercial contributors and independent contributors alike,
whose work forms the foundation of our codebase, as well as all of those who
worked on the extensive Creative Commons documentation that was adapted for
Redict. We also extend our gratitude to the community downstream of RedisÂ®
OSS, including downstream distributions, cloud services, and countless users,
all of whom nourished its growth as free software.</p>
<h2 id="whats-next">
  Whatâs next?
  <a href="#whats-next">#</a>
</h2>
<p>We focused on a very conservative set of changes for the initial release, to
maximize backwards compatibility and ease the transition for new users. Going
forward, we do have some plans to make conservative improvements.</p>
<p>Among the planned changes are:</p>
<ul>
<li>Modernizing the build system (<a href="https://muon.build/">muon</a> is the leading
candidate)</li>
<li>Forking the <em>ecosystem</em>, in particular RedisÂ® client libraries (this is a
great way for you to help!)</li>
<li>De-vendoring dependencies such as Lua and jemalloc</li>
</ul>
<p>Lucas is also planning to invest heavily in Redictâs documentation, such that we
become the reference of choice for all participants in this ecosystem. Anna has
some changes planned for <a href="https://codeberg.org/redict/hiredict">hiredict</a> as well (our fork of the official RedisÂ®
C client library), including build system improvements and better conformance
with Unix norms.</p>
<p>We will also be happy to consider improvements from any community member â come
join us! We will welcome you as equals â independent and commercial users
alike!</p>

</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Reflections on Distrusting xz (246 pts)]]></title>
            <link>https://joeyh.name/blog/entry/reflections_on_distrusting_xz/</link>
            <guid>39914981</guid>
            <pubDate>Wed, 03 Apr 2024 08:56:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://joeyh.name/blog/entry/reflections_on_distrusting_xz/">https://joeyh.name/blog/entry/reflections_on_distrusting_xz/</a>, See on <a href="https://news.ycombinator.com/item?id=39914981">Hacker News</a></p>
<div id="readability-page-1" class="page"><article class="page">







<section id="pagebody" role="main">
<p>Was the ssh backdoor the only goal that "Jia Tan" was pursuing
with their multi-year operation against xz?</p>

<p>I doubt it, and if not, then every fix so far has been incomplete,
because everything is still running code written by that entity.</p>

<p>If we assume that they had a multilayered plan, that their every action was
calculated and malicious, then we have to think about the full threat
surface of using xz. This quickly gets into nightmare scenarios of the
"trusting trust" variety.</p>

<p>What if xz contains a hidden buffer overflow or other vulnerability, that
can be exploited by the xz file it's decompressing? This would let the
attacker target other packages, as needed.</p>

<p>Let's say they want to target gcc. Well, gcc contains a lot of
documentation, which includes png images. So they spend a while getting
accepted as a documentation contributor on that project, and get added to
it a png file that is specially constructed, it has additional binary data
appended that exploits the buffer overflow. And instructs xz to modify the
source code that comes later when decompressing <code>gcc.tar.xz</code>.</p>

<p>More likely, they wouldn't bother with an actual trusting trust attack on
gcc, which would be a lot of work to get right. One problem with the ssh
backdoor is that well, not all servers on the internet run ssh. (Or
systemd.) So webservers seem a likely target of this kind of second stage
attack. Apache's docs include png files, nginx does not, but there's always
scope to add improved documentation to a project.</p>

<p>When would such a vulnerability have been introduced? In February, "Jia
Tan" wrote a <a href="https://git.tukaani.org/?p=xz.git;a=commitdiff;h=de5c5e417645ad8906ef914bc059d08c1462fc29">new decoder for xz</a>.
This added 1000+ lines of new C code across several commits. So much code
and in just the right place to insert something like this. And why take on
such a significant project just two months before inserting the ssh
backdoor? "Jia Tan" was already fully accepted as maintainer, and doing
lots of other work, it doesn't seem to me that they needed to start this
rewrite as part of their cover.</p>

<p>They were working closely with xz's author Lasse Collin in this, by
indications exchanging patches offlist as they developed it. So Lasse
Collin's commits in this time period are also worth scrutiny, because
they could have been influenced by "Jia Tan". One that
caught my eye comes immediately afterwards:
<a href="https://git.tukaani.org/?p=xz.git;a=commitdiff;h=e0c0ee475c0800c08291ae45e0d66aa00d5ce604">"prepares the code for alternative C versions and inline assembly"</a>
Multiple versions and assembly mean even more places to hide such a
security hole.</p>

<p>I stress that I have not found such a security hole, I'm only considering
what the worst case possibilities are. I think we need to fully consider
them in order to decide how to fully wrap up this mess.</p>

<p>Whether such stealthy security holes have been introduced into xz by "Jia
Tan" or not, there are definitely indications that the ssh backdoor was not
the end of what they had planned.</p>

<p>For one thing, the "test file" based system they introduced
<a href="https://openwall.com/lists/oss-security/2024/03/30/15">was extensible</a>.
They could have been planning to add more test files later, that backdoored
xz in further ways.</p>

<p>And then there's the matter of the disabling of the Landlock sandbox. This
was not necessary for the ssh backdoor, because the sandbox is only used by
the <code>xz</code> command, not by liblzma. So why did they potentially tip their
hand by adding that rogue "." that disables the sandbox?</p>

<p>A sandbox would not prevent the kind of attack I discuss above, where xz is
just modifying code that it decompresses. Disabling the sandbox suggests
that they were going to make xz run arbitrary code, that perhaps wrote to
files it shouldn't be touching, to install a backdoor in the system.</p>

<p>Both deb and rpm use xz compression, and with the sandbox disabled,
whether they link with liblzma or run the <code>xz</code> command, a backdoored xz can
write to any file on the system while dpkg or rpm is running and noone is
likely to notice, because that's the kind of thing a package manager does.</p>

<p>My impression is that all of this was well planned and they were in it for
the long haul. They had no reason to stop with backdooring ssh, except for
the risk of additional exposure. But they decided to take that risk, with
the sandbox disabling. So they planned to do more, and every commit
by "Jia Tan", and really every commit that they could have influenced
needs to be distrusted.</p>

<p>This is why I've suggested to Debian that they
<a href="https://bugs.debian.org/1068024">revert to an earlier version of xz</a>.
That would be my advice to anyone distributing xz.</p>

<p>I do have a <a href="https://git.joeyh.name/index.cgi/xz-unscathed/">xz-unscathed</a>
fork which I've carefully constructed to avoid all "Jia Tan" involved
commits. It feels good to not need to worry about <code>dpkg</code> and <code>tar</code>.
I only plan to maintain this fork minimally, eg security fixes.
Hopefully Lasse Collin will consider these possibilities and address
them in his response to the attack.</p>

</section>



</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HP Disables Printer Functionality Until You Install the HP Smart App (128 pts)]]></title>
            <link>https://twitter.com/Schappi/status/1775384892970533208/photo/1</link>
            <guid>39914293</guid>
            <pubDate>Wed, 03 Apr 2024 06:38:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/Schappi/status/1775384892970533208/photo/1">https://twitter.com/Schappi/status/1775384892970533208/photo/1</a>, See on <a href="https://news.ycombinator.com/item?id=39914293">Hacker News</a></p>
Couldn't get https://twitter.com/Schappi/status/1775384892970533208/photo/1: Error: Request failed with status code 400]]></description>
        </item>
        <item>
            <title><![CDATA[The Rise and Fall of 3M's Floppy Disk (116 pts)]]></title>
            <link>https://spectrum.ieee.org/3m-floppy</link>
            <guid>39913505</guid>
            <pubDate>Wed, 03 Apr 2024 04:05:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://spectrum.ieee.org/3m-floppy">https://spectrum.ieee.org/3m-floppy</a>, See on <a href="https://news.ycombinator.com/item?id=39913505">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-headline="The Rise and Fall of 3Mâs Floppy Disk" data-elid="2667647674" data-post-url="https://spectrum.ieee.org/3m-floppy" data-authors="Ernie Smith" data-page-title="The Rise and Fall of 3Mâs Floppy Disk - IEEE Spectrum"><p><em>A version of this post </em><a href="https://tedium.co/2023/11/17/3m-floppy-disks-history/" rel="noopener noreferrer" target="_blank"><em>originally appeared</em></a><em> on</em><a href="https://tedium.co/" target="_blank"><em>Tedium</em></a><em>, Ernie Smithâs newsletter, which hunts for the end of the long tail. </em></p><p>
	If you ask the average person what the company 3M does, odds are if they have a few gray hairs hanging out on their scalp, they might say that the company makes floppy disks. Now, this was once true, but 
	<a href="https://www.3m.com/" rel="noopener noreferrer" target="_blank">if you look on 3Mâs own website</a>, you will see no mention of this legacyâitâs a firm that sells abrasive materials, adhesive tapes, filters, films, personal protective equipment, and medical equipment. (Younger people, if they recognize 3M, itâs probably because of Post-it notes, or more recently its N95 masks)
</p><p>
	Floppies have had a surprisingly long lifeâin January 2024, 
	<a href="https://arstechnica.com/gadgets/2024/01/floppy-disk-requirements-finally-axed-from-japan-government-regulations/" rel="noopener noreferrer" target="_blank">Japan announced</a> it will no longer require floppy-disk copies of government submissions. But 3M got out of the data-storage business about 28 years ago, when it transferred its floppy disk manufacturing to a spin-off called Imation. Imation is still around, under the name Glassbridge Enterprises, but with a much smaller profile.
</p><p><img alt="One yellow and one orange Imation 3M 3 \u00bd inch floppy diskettes on a gray background." data-rm-shortcode-id="09f8f834227ac15c2241ffede9966750" data-rm-shortcode-name="rebelmouse-image" data-runner-src="https://spectrum.ieee.org/media-library/one-yellow-and-one-orange-imation-3m-3-u00bd-inch-floppy-diskettes-on-a-gray-background.jpg?id=51890455&amp;width=980" height="1250" id="d995a" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/one-yellow-and-one-orange-imation-3m-3-u00bd-inch-floppy-diskettes-on-a-gray-background.jpg?id=51890455&amp;width=980" width="2000"><small placeholder="Add Photo Caption...">3Mâs spin-off, Imation, continued producing floppy disks after 3M itself left the business. </small><small placeholder="Add Photo Credit..."><a href="https://spectrum.ieee.org/">IEEE Spectrum</a></small></p><p>
	Even with that said, those gray-hairs will frequently claim that of the many makers of floppies out there, 3M made the best ones. Given that, I was curious to figure out exactly why 3M became the most memorable brand in data storage during the formative days of computing, and why it abandoned the product.
</p><h2>How 3M Became a Key Innovator in the Production of Magnetic Data Storage</h2><p>
	Now, to be clear, 3M did not invent magnetic storageâthat was done by Austro-German engineer 
	<a href="https://www.computerhistory.org/storageengine/audio-recorder-uses-low-cost-magnetic-tape/" rel="noopener noreferrer" target="_blank">Fritz Pfleumer</a>, in 1928. He created audio tape, a recording medium that started as broad strips of paper coated with iron-powder granules, and eventually moved to less-fragile cellulose acetate with help from what would become another big name in floppy disks, BASF. At first, the innovation didnât spread outside of Germany because of World War II.
</p><p>
	Nor was 3M the first company to popularize magnetic mediaâ
	<a href="https://tedium.co/2022/08/26/tape-hiss-noise-history/" rel="noopener noreferrer" target="_blank">that was Ampex</a>, which commercialized the tape recorder in the late 1940s. That was the point when magnetic tape turned into a major innovation in the world of musicâone that, famously, <a href="https://ethw.org/First-Hand:Bing_Crosby_and_the_Recording_Revolution" rel="noopener noreferrer" target="_blank">Bing Crosby got to first</a> because he gave financial support to Ampex. Incidentally, Ampexâs later spinoff, Memorex, represented <a href="https://tedium.co/2021/09/03/memorex-tape-history/" rel="noopener noreferrer" target="_blank">Silicon Valleyâs first true startup</a>.
</p><blockquote>âOf all the businesses 3M has shed over its 100 years, the two seminal decisions that people point to as most significant involved the sale of 3Mâs Duplicating Products business to Harris Corporation in Atlanta, Georgia, and the spin-off of 3Mâs data-storage and imaging-systems businesses in 1996 creating a new company called Imation in Oakdale, Minnesota...â</blockquote><p>
	Before World War II, one company did attempt to manufacture a tape recorder in the U.S. based on Pfluemerâs magnetic-tape invention. That firm, the Brush Development Co., 
	<a href="https://www.radiomuseum.org/dsp_hersteller_detail.cfm?company_id=2092" rel="noopener noreferrer" target="_blank">had developed a device called the Soundmirror</a>, produced by a Hungarian inventor named Semi J. Begun, who was likely something of a competitor to Pfleumer: Also a German, he had moved to the United States and developed a steel-based magnetic tape. The invention was used by the U.S. military during the war, and the company revisited the idea immediately after. But, it needed someone to manufacture magnetic tape for it to use.
</p><p>
	As author David Morton noted in his 2006 book 
	<em>Sound Recording: The Life Story of a Technology</em>, <a href="https://www.google.com/books/edition/Sound_Recording/0ZmjkJwxyWcC?hl=en&amp;gbpv=1&amp;pg=PA121&amp;printsec=frontcover" rel="noopener noreferrer" target="_blank">3M was one of the best-suited companies on the market</a> to help Brush out. Thatâs because the groundbreaking work that the company had done to develop pressure-sensitive adhesive tape was an essential element of making magnetic tape effective.
</p><p><img alt="Black and white historical photo of a man in worker overall and a cap applying newspaper and tape to an old car." data-rm-shortcode-id="7b3354061aa56d651ce26122330f6db6" data-rm-shortcode-name="rebelmouse-image" data-runner-src="https://spectrum.ieee.org/media-library/black-and-white-historical-photo-of-a-man-in-worker-overall-and-a-cap-applying-newspaper-and-tape-to-an-old-car.jpg?id=51890488&amp;width=980" height="930" id="8f6d5" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/black-and-white-historical-photo-of-a-man-in-worker-overall-and-a-cap-applying-newspaper-and-tape-to-an-old-car.jpg?id=51890488&amp;width=980" width="1240"><small placeholder="Add Photo Caption...">3Mâs adhesive-tape technology transferred readily to magnetic tape. </small><small placeholder="Add Photo Credit...">3M</small></p><p>
	Strangely enough, Richard Gurley Drew, the inventor of much of 3Mâs tape technology, was a musicianâhe played banjo in a local orchestraâwhen he took a job with the company. He probably didnât realize he was inventing a key element of 20th-century recording technology when he observed that auto body shops needed a way to âmask offâ areas of vehicles that were being whittled down with sandpaper, but his observation would prove useful to the invention of masking tape.
</p><p data-rm-resized-container="25%"><img alt="Zoom in of disordered rectangles on the left and ordered rectangles on the right, over advertisement text. " data-rm-shortcode-id="ee09b3f7acae42e757ef6377cf6773be" data-rm-shortcode-name="rebelmouse-image" data-runner-src="https://spectrum.ieee.org/media-library/zoom-in-of-disordered-rectangles-on-the-left-and-ordered-rectangles-on-the-right-over-advertisement-text.jpg?id=51890495&amp;width=980" height="850" id="7d359" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/zoom-in-of-disordered-rectangles-on-the-left-and-ordered-rectangles-on-the-right-over-advertisement-text.jpg?id=51890495&amp;width=980" width="620"><small placeholder="Add Photo Caption...">In the mid-1950s, 3M advertised its Scotch audio reel-to-reel tape.</small><small placeholder="Add Photo Credit..."><a href="https://archive.org/details/am-1955-03/page/n3/mode/2up" rel="noopener noreferrer" target="_blank">Audio Magazine/Internet Archive</a>/Scotch</small></p><p><a href="https://www.smithsonianmag.com/innovation/how-invention-scotch-tape-led-revolution-how-companies-managed-employees-180972437/" rel="noopener noreferrer" target="_blank">As <em>Smithsonian Magazine</em> notes</a>, the formulation he developed, combining cabinetmakerâs glue with glycerin, proved to be just the right level of easy-to-remove adhesive that it became an out-and-out phenomenon. You might know his invention, developed in 1925, as Scotch Tape.
</p><p>
	In 1930, he followed it up with another invention that was even more amazingâtape made from cellophane, which by its nature was totally transparent. Another 3M employee developed the tape dispenser, and the two inventions reshaped offices the world over.
</p><p>
	So, when Brush looked to others to produce its recording medium, 3M was well positioned to help out due to magnetic tapeâs similarity with its Scotch Tape. Brush eventually moved to other manufacturers, like Dupont. But the experience led 3M to continue developing metal-oxide tape technology, leading to the creation of the Scotch 111 reel-to-reel tape, which was one of the most popular types used in recording studios throughout the 1950s, according to the 
	<a href="https://museumofmagneticsoundrecording.org/Manufacturers3M.html" rel="noopener noreferrer" target="_blank"><em>Museum of Magnetic Sound Recording</em></a>.
</p><p>
	I admittedly have long had a fascination with these reel-to-reel tapes. A number of years ago, back when I lived in Milwaukee, I found a couple of blank reel-to-reel tapes created by 3M using the Scotch name. I bought them from a junk store, and maybe paid $2 for them. They managed to follow me through three states and five cities, and now sit on 
	<a href="https://midrange.tedium.co/issues/bless-this-mess/" rel="noopener noreferrer" target="_blank">my intentionally organized pile of junk</a>. Based on my analysis of the container and the logotype it uses, they date to the mid-1960s or earlier. (No, I have not tried to record on them.)
</p><p><img alt="A hand holds a rectangular package labeled Scotch magnetic tape." data-rm-shortcode-id="dba7c144e1565d8d93e5eca846dc9f37" data-rm-shortcode-name="rebelmouse-image" data-runner-src="https://spectrum.ieee.org/media-library/a-hand-holds-a-rectangular-package-labeled-scotch-magnetic-tape.jpg?id=51890540&amp;width=980" height="1536" id="7458c" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/a-hand-holds-a-rectangular-package-labeled-scotch-magnetic-tape.jpg?id=51890540&amp;width=980" width="2048"><small placeholder="Add Photo Caption...">Iâve owned this blank Scotch 150 reel-to-reel tape for nearly 20 years. It is 50 to 60 years old. </small><small placeholder="Add Photo Credit...">Ernie Smith</small></p><p>
	For years, 3Mâs reel-to-reels had one of the strongest reputations in the music industry; they were built to be of superhigh quality. But you might be wondering, how did 3M make the leap from reel-to-reel tape to floppies? It feels like just as strange a leap as a masking tape company developing reel-to-reel audio tape.
	<br></p><p>
	But, again, it happened.
</p><h3>How 3Mâs Tapes Went From Music to Data</h3><p>
	3M didnât develop the floppy disk drive, either. 
	<a href="https://tedium.co/2023/07/22/alan-shugart-floppy-disk-history/" target="_blank">IBM did, and Shugart Associates further improved it</a> by making it small enough for regular users.
</p><p><img alt="One 3M 5 \u00bc\u201d Floppy disk in a sleeve stands against a gray background." data-rm-shortcode-id="43b65ca8e6f0dca5e3362d6bde5ec2b0" data-rm-shortcode-name="rebelmouse-image" data-runner-src="https://spectrum.ieee.org/media-library/one-3m-5-u00bc-u201d-floppy-disk-in-a-sleeve-stands-against-a-gray-background.jpg?id=51890553&amp;width=980" height="1250" id="f22da" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/one-3m-5-u00bc-u201d-floppy-disk-in-a-sleeve-stands-against-a-gray-background.jpg?id=51890553&amp;width=980" width="2000"><small placeholder="Add Photo Caption...">3M manufactured a signature 5.25-inch floppy disk. </small><small placeholder="Add Photo Credit...">IEEE Spectrum</small></p><p>
	But 3M, much as with mechanical tape, was well positioned to improve on it, leveraging its skills with mechanical media in the budding computing industry. In a way, 3M came to media manufacturing from the opposite direction than its disk-selling competitor Memorex did. Memorex started with computers and gradually came to develop and improve tape-based technology, which eventually evolved into floppy disks. On the other hand, 3M started with the raw materials and the manufacturing processes, and combined those into computingâs greatest commodity item, the floppy disk.
</p><p>
	3M got into the floppy disk market around the 
	<a href="https://books.google.com/books?id=pWBoOXVjuZ0C&amp;pg=PT10#v=onepage&amp;q&amp;f=false" rel="noopener noreferrer" target="_blank">fall of 1973</a>. It was not the only manufacturer of disks out thereâsome names from this era include Verbatim, Control Data, Dysan, and BASF. Most of these companies started with computing technologyâfor example, Dysan worked closely with Shugart Associates on the 5.25-inch floppy. But 3M wasnât alone in starting with the raw materials. BASF, a German chemical manufacturer, has a somewhat similar corporate history and logo design to fellow thick-Helvetica enthusiast 3M. (Though 3M obviously <a href="https://www.basf.com/global/en/who-we-are/history/chronology/1925-1944/1939-1945.html" rel="noopener noreferrer" target="_blank">never associated with the Nazis</a> during World War II, so thereâs that.)
</p><p data-rm-resized-container="25%"><img alt="Four different magnetic storage devices on a purple background. " data-rm-shortcode-id="08705882c5d1fc80ce7ccd70dfbe7c2a" data-rm-shortcode-name="rebelmouse-image" data-runner-src="https://spectrum.ieee.org/media-library/four-different-magnetic-storage-devices-on-a-purple-background.jpg?id=51890570&amp;width=980" height="1633" id="8ae6d" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/four-different-magnetic-storage-devices-on-a-purple-background.jpg?id=51890570&amp;width=980" width="1246"><small placeholder="Add Photo Caption...">3M branched out beyond standard floppy disks with a variety of magnetic-tape storage media.</small><small placeholder="Add Photo Credit..."><a href="https://books.google.com/books?id=VFLlZVMEa_EC&amp;pg=PA52&amp;hl=en&amp;sa=X&amp;ved=2ahUKEwiR4LTHxMyCAxUeFlkFHTdCCdgQ6AF6BAgSEAI#v=onepage&amp;q=Floptical%203m&amp;f=false" rel="noopener noreferrer" target="_blank">ComputerWorld/Google Books</a>/3M</small></p><p>
	3M didnât rest on its laurels with the floppy disk either, and tried to push the technology further, most notably with 
	<a href="https://www.storagenewsletter.com/2018/09/25/history-1991-floptical-by-insite-peripherals/" rel="noopener noreferrer" target="_blank">Floptical disk technology</a>, which Jim Adkisson, who helped create the 5.25-inch floppy at Shugart Associates, developed in the 1980s. A partnership of 3M, Maxell, and <a href="https://tedium.co/2016/12/06/iomega-zip-disk-click-of-death-history/" rel="noopener noreferrer" target="_blank">Iomega</a> created the Floptical disk, which could hold 20 megabytes of data on something that looked a lot like a 3.5-inch floppy. Unfortunately the floptical disk flopped, losing out to products like Iomegaâs iconic <a href="https://www.computinghistory.org.uk/det/22978/Iomega-Zip-Drive-100-Parallel/" rel="noopener noreferrer" target="_blank">Zip drives</a>.
</p><p>
	3M also worked in more specialized media, developing high-capacity optical disks that fit into standard floppy and optical disk mechanisms, as well as high-end tape drives intended for the server room rather than your cassette player.
</p><p>
	In many ways, 3M was out front on one of the most important elements of computing and was making huge profits from it. But by the end of 1995, those days were done. What changed?
</p><p><span data-rm-shortcode-id="7620f5c6d1db2474feabc8fb1ec83bbc"><iframe frameborder="0" height="auto" type="lazy-iframe" scrolling="no" data-runner-src="https://www.youtube.com/embed/bOHKgENMcGQ?rel=0" width="100%"></iframe></span><small placeholder="Add Photo Caption...">3M advertised its floppy disk as more reliable than the competition in no uncertain terms. </small></p><h3>What Led 3M to Kick a Multibillion-Dollar Business to the Curb</h3><p>
	By 1995, 3Mâs magnetic-media arm had evolved into a US $2.3 billion business, according to
	<a href="https://content.time.com/time/subscriber/article/0,33009,985024-1,00.html" rel="noopener noreferrer" target="_blank"><em>Time</em></a>, which made it a significant chunk of 3Mâs overall offering.
</p><p>
	But at that time, high technologyâ
	<em>especially</em> consumer technologyâwas starting to look like a bad bet for legacy companies. This was around the same period that AT&amp;T, still smarting from misadventures like the <a href="https://www.inverse.com/input/features/fax-on-the-beach-the-story-of-atts-eo-communicator-90s-ipad-flop" rel="noopener noreferrer" target="_blank">EO Personal Communicator</a>, spun off Bell Labs as Lucent Technologies.
</p><p>
	3Mâs story, in its own words, suggests a similar crisis of culture. In 
	<a href="https://multimedia.3m.com/mws/media/171240O/3m-century-of-innovation-book.pdf" rel="noopener noreferrer" target="_blank"><em>A Century of Innovation</em></a>, a book published by the company in 2002, around the time of its 100-year anniversary, the company compared the creation of the spin-off, which it called âthe most wrenching decision in its history,â to that of its determination eight years earlier to sell its Duplicating Products Division, which sold copying machines:
</p><p><em>Of all the businesses 3M has shed over its 100 years, the two seminal decisions that people point to as most significant involved the sale of 3Mâs Duplicating Products business to Harris Corporation in Atlanta, Georgia, and the spin-off of 3Mâs data-storage and imaging-systems businesses in 1996 creating a new company called Imation in Oakdale, Minnesota, near 3M headquarters. The two decisions have several elements in commonâboth involved businesses that 3M created and, in fact, ranked number one in the marketplace for decades. They were âhomegrownâ businessesâlargely created within 3M and commercialized and built with the energy of many internal sponsors and champions. The businesses were risky because the products were based on pioneering technologies. They not only changed the basis of competition; they also created all new, global industries. The businesses were highly profitable for decades, and they represented a significant share of the companyâs total annual revenues. They also produced many of 3Mâs next generation of leaders.</em></p><p>
	So what happened? Essentially, despite the companyâs success working in industrial and professional settings, doing things for consumers like producing videotapes, floppy disks, and cassettes meant moving out of its comfort zone. These products, initially developed for businesses, grew so popular that they suddenly needed to be available at every big-box store and drugstore alike, and, Post-its aside, retail was not a fit for the kind of company 3M was.
</p><p>
	But more significantly, other companies were simply better at undercutting, and per the corporate biography, that required some tough decisions to be made:
</p><p><em>While it sold its products for little or no profit, its competition sold their products for even less. Even though the consumer business had huge growth potential, 3M had little experience with a low-cost, low-profit-margin model.</em></p><p><em> The markings were clearâexit this business, even though 3M invented it. To stay in the âdog fightâ meant 3M had to invest enormous amounts of money in order to remain the low-cost producer, with no assurance that profit margins ever would improve. âExiting it was the right decision,â [former senior vice president Al] Huber said.</em></p><p>
	Seeing what came after, itâs hard to disagree. While floppies were still a significant medium in the mid-1990s, it was obvious that they would not be enough capacity for the next generation of data hoarders. It would only be a couple of years before Apple would put the first dagger in the heart of the floppy disk with 
	<a href="https://en.wikipedia.org/wiki/IMac_G3" rel="noopener noreferrer" target="_blank">the iMac</a>, breaking with tradition by releasing a personal computer in 1998 with no built-in floppy disk drive.
</p><p><span data-rm-shortcode-id="5b53a6e7ab0f74ffc4d7a5fed5a851a5"><iframe frameborder="0" height="auto" type="lazy-iframe" scrolling="no" data-runner-src="https://www.youtube.com/embed/3qkQi3zZVhg?rel=0" width="100%"></iframe></span><small placeholder="Add Photo Caption...">Imation carried on a floppy-disk ad campaign through the late 1990s. </small></p><p>
	That was a harbinger of what was to come. Within a decade of the decision, floppy drives, compact cassettes, and videotapesâthe three key elements of 3Mâs move into consumer-driven magnetic mediaâhad fallen by the wayside. Imation, still active today, is owned by O-Jin Corp., a Korean technology company 
	<a href="http://www.imation.com/board/bbs/board.php?bo_table=news_en&amp;wr_id=11" rel="noopener noreferrer" target="_blank">that basically bought it for its trademarked name</a>.</p><p>Much like its one-time competitor Memorex, Imation is a technology ghost kitchen. Its former corporate parent 3M, meanwhile, has a market cap of $51.33 billion at the time of this writing.</p><h3>3Mâs Magnetic Legacy</h3><p>
	In a lot of ways, I think 3Mâs persisting deep association with computing, despite the fact that the company left the field decades ago, comes down to the fact that it had a very recognizable logo design during its computer heyday.</p><p><span></span>My first experience with 3M was seeing its bright red logo on floppy disks used in classrooms with Apple IIe computers in the late 1980s and early â90s. 3M was instantly recognizable among those responsible for creating the disks we needed to load up <em>Number Munchers</em> and <em>Commander Keen</em>, and as a result, its name is forever imprinted into the brains of retro-tech nerds the world over. It is a memory that gives me warm feelings.
</p><p>
	But 3M, for a number of reasons, is not a company that carries a lot of goodwill with younger generations. For example, the company is closely associated with the manufacturing of a variety of chemicals, including PFOS (Perfluorooctane sulfonate), a key ingredient in Scotchguard and other water-resistant materials. Itâs one of many PFAS (perfluoroalkyl and polyfluoroalkyl) substances that are believed to be harmful to humans.
</p><p>
	The floppy disks that I and other elder millennials associate with a company that was essential to our youthful computing experience are long gone, shuttled away as a non-core business for a giant corporation that is best described as an amalgamation of non-core businesses loosely held together by a logo and backing in chemistry and raw materials.
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Intel discloses $7B operating loss for chip-making unit (183 pts)]]></title>
            <link>https://www.reuters.com/technology/intel-discloses-financials-foundry-business-2024-04-02/</link>
            <guid>39912854</guid>
            <pubDate>Wed, 03 Apr 2024 01:56:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/technology/intel-discloses-financials-foundry-business-2024-04-02/">https://www.reuters.com/technology/intel-discloses-financials-foundry-business-2024-04-02/</a>, See on <a href="https://news.ycombinator.com/item?id=39912854">Hacker News</a></p>
Couldn't get https://www.reuters.com/technology/intel-discloses-financials-foundry-business-2024-04-02/: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[7.4 earthquake in Taiwan, 34km depth (444 pts)]]></title>
            <link>https://earthquake.usgs.gov/earthquakes/map/?extent=16.34123,-246.42334&amp;extent=28.51697,-223.43994</link>
            <guid>39912330</guid>
            <pubDate>Wed, 03 Apr 2024 00:24:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://earthquake.usgs.gov/earthquakes/map/?extent=16.34123,-246.42334&#x26;extent=28.51697,-223.43994">https://earthquake.usgs.gov/earthquakes/map/?extent=16.34123,-246.42334&#x26;extent=28.51697,-223.43994</a>, See on <a href="https://news.ycombinator.com/item?id=39912330">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <p>
            The Latest Earthquakes application supports most recent browsers,
            <a href="https://angular.io/guide/browser-support" target="_blank">view supported browsers</a>.
          </p>
          <p>
            If the application does not load, try our
            <a href="https://earthquake.usgs.gov/legacy/map/" target="_blank"> legacy Latest Earthquakes application</a>.
          </p>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ReALM: Reference Resolution as Language Modeling (114 pts)]]></title>
            <link>https://arxiv.org/abs/2403.20329</link>
            <guid>39911961</guid>
            <pubDate>Tue, 02 Apr 2024 23:26:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2403.20329">https://arxiv.org/abs/2403.20329</a>, See on <a href="https://news.ycombinator.com/item?id=39911961">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2403.20329">View PDF</a>
    <a href="https://arxiv.org/html/2403.20329v1">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>Reference resolution is an important problem, one that is essential to understand and successfully handle context of different kinds. This context includes both previous turns and context that pertains to non-conversational entities, such as entities on the user's screen or those running in the background. While LLMs have been shown to be extremely powerful for a variety of tasks, their use in reference resolution, particularly for non-conversational entities, remains underutilized. This paper demonstrates how LLMs can be used to create an extremely effective system to resolve references of various types, by showing how reference resolution can be converted into a language modeling problem, despite involving forms of entities like those on screen that are not traditionally conducive to being reduced to a text-only modality. We demonstrate large improvements over an existing system with similar functionality across different types of references, with our smallest model obtaining absolute gains of over 5% for on-screen references. We also benchmark against GPT-3.5 and GPT-4, with our smallest model achieving performance comparable to that of GPT-4, and our larger models substantially outperforming it.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Joel Ruben Antony Moniz [<a href="https://arxiv.org/show-email/954052bb/2403.20329">view email</a>]      <br>    <strong>[v1]</strong>
        Fri, 29 Mar 2024 17:59:06 UTC (7,019 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A Gentle Introduction to the Art of Mathematics (169 pts)]]></title>
            <link>https://giam.southernct.edu/GIAM/</link>
            <guid>39911587</guid>
            <pubDate>Tue, 02 Apr 2024 22:36:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://giam.southernct.edu/GIAM/">https://giam.southernct.edu/GIAM/</a>, See on <a href="https://news.ycombinator.com/item?id=39911587">Hacker News</a></p>
<div id="readability-page-1" class="page">
<center>
</center>

<hr>

<center><img src="https://giam.southernct.edu/GIAM/GIAM-3.1-cover-small.jpg"></center>

<hr>

<p>GIAM (a Gentle Introduction to the Art of Mathematics) is a free,
open-source textbook -- the current version is 3.1.  GIAM covers several 
topics in the foundations of mathematics (logic, sets, relations, 
functions and cardinality) and introduces the reader to many techniques 
of mathematical proof (direct, indirect, contradiction, contrapositive, 
mathematical induction, combinatorial proofs and magic).  There are 
amusing quotations at the start of each chapter.

</p><hr>
<p>The <a href="https://giam.southernct.edu/GIAM/GIAM.pdf">text</a>.
</p><p>The exercise <a href="https://giam.southernct.edu/GIAM/GIAM-hw.pdf">workbook</a>.
</p><p>The hints and solutions <a href="https://giam.southernct.edu/GIAM/GIAM-solutions_manual.pdf">manual</a>.
</p><hr>

<p>
Some links to <a href="https://giam.southernct.edu/GIAM/review-links.html">reviews</a>.

</p><p>
GIAM is licensed under the <a href="https://giam.southernct.edu/GIAM/fdl-1.3-standalone.html">GNU Free Documentation License version 1.3</a>

</p><p>
GIAM is typeset using PDFLaTeX.  Figures were produced with XFiG.  
Photographs were modified using GIMP.  A compressed tarball of the
source files for GIAM is <a href="https://giam.southernct.edu/GIAM/GIAM-src-1_14_2014.tar.gz">here</a>. The source code for
GIAM is hosted at <a href="https://github.com/osj1961/giam.git">GitHub</a>.

</p><p>GIAM is now available in hardcopy as a printed-on-demand paperback 
from <a href="https://www.createspace.com/4609716">CreateSpace</a>.  
Please rest assured that GIAM will remain available for free download from this site. 

</p><p>There are alternative versions of GIAM available <a href="https://giam.southernct.edu/GIAM/versions.html">here</a>.










</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How the XZ Backdoor Works (180 pts)]]></title>
            <link>https://lwn.net/SubscriberLink/967192/6c39d47b5f299a23/</link>
            <guid>39911311</guid>
            <pubDate>Tue, 02 Apr 2024 22:00:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lwn.net/SubscriberLink/967192/6c39d47b5f299a23/">https://lwn.net/SubscriberLink/967192/6c39d47b5f299a23/</a>, See on <a href="https://news.ycombinator.com/item?id=39911311">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<!-- $Id: slink-trial,v 1.1 2005-11-04 21:27:01 corbet Exp $ -->
<center>
<table>
<tbody><tr><td>
<h3>Welcome to LWN.net</h3>
<p>
The following subscription-only content has been made available to you 
by an LWN subscriber.  Thousands of subscribers depend on LWN for the 
best news from the Linux and free software communities.  If you enjoy this 
article, please consider accepting the trial offer on the right.  Thank you
for visiting LWN.net!
</p></td><td>
<div>
<h3>Free trial subscription</h3>
           <p>
           Try LWN for free for 1 month: no payment
           or credit card required.  <a href="https://lwn.net/Promo/slink-trial2-3/claim">Activate
           your trial subscription now</a> and see why thousands of
           readers subscribe to LWN.net.
           
</p></div>
</td>
</tr>

</tbody></table>
</center>

<p>
Versions 5.6.0 and 5.6.1 of the
<a href="https://git.tukaani.org/?p=xz.git;a=summary">XZ</a>
compression utility and library
were shipped with <a href="https://lwn.net/Articles/967180">a backdoor</a> that targeted
<a href="https://www.openssh.com/">OpenSSH</a>.
Andres Freund
<a href="https://lwn.net/ml/oss-security/20240329155126.kjjfduxw2yrlxgzm@awork3.anarazel.de/">
discovered</a> the backdoor by
noticing that <a href="https://lwn.net/Articles/967194/">failed SSH logins were taking a lot of
CPU time</a> while doing some
micro-benchmarking, and tracking down the backdoor from there. It was introduced
by XZ co-maintainer "Jia Tan" â a probable alias for person or persons unknown.
The backdoor is a sophisticated attack with multiple parts, from the build
system, to link time, to run time.
</p>

<p>
The community response to the attack is just as interesting as the technical
aspects. For more information on that, refer to <a href="https://lwn.net/Articles/967866">this
companion article</a>.
</p>

<h4>Build time</h4>

<p>
The backdoor consists of several distinct phases, starting when the package is
being built. Gynvael Coldwind wrote
<a href="https://gynvael.coldwind.pl/?lang=en&amp;id=782">an in-depth investigation</a>
of the build-time parts of the backdoor.
Releases of XZ were provided via GitHub, which has since disabled
the maintainers' accounts and taken the releases offline. Like many projects that
use <a href="https://www.gnu.org/software/autoconf/">GNU Autoconf</a>,
XZ made releases that provided
several versions of the source for
download â an automatically generated tarball containing the source and related
files in the repository, along with versions containing the generated
build files. Those extra files include the <tt>configure</tt> script and makefiles for
the project.
Releasing
versions that contain the generated files allows downstream users of the software to
build without needing to install Autoconf.
</p>

<p>
In this case, however, the scripts in the maintainer-provided source tarballs
were not generated by Autoconf. Instead, one of the build scripts
contained the first stage of the exploit in <tt>m4/build-to-host.m4</tt>. This
script is originally from the <a href="https://www.gnu.org/software/gnulib/">Gnulib</a>
library; it provides a macro that converts
between the style of pathname used by the build environment and the
run-time environment of the program.
The version in these XZ releases was modified to extract the next stage
of the exploit, which is contained in
<tt>tests/files/bad-3-1corrupt_lzma2.xz</tt>.
</p>

<p>
This file is included in the repository, ostensibly as part of XZ's test suite,
though it was never used by those tests. It was committed well before the
release of version 5.6.0. The file, supposedly a corrupted XZ file,
is actually a valid XZ stream with some bytes
swapped â for example, <tt>0x20</tt> is swapped with occurrences of <tt>0x09</tt>
and vice versa.
When decoded, it yields <a href="https://lwn.net/Articles/967979">a shell script</a> that
unpacks and executes the next stage of the backdoor.
</p>

<p>
The next stage of the backdoor is located in
<tt>tests/files/good-large_compressed.lzma</tt>. This is the
<tt>injected.txt</tt> file
attached to Freund's message. That file contains more than just the
next stage of the script â it also contains additional binary data that forms
the actual backdoor itself. The final script skips over the header of the file
from which it was extracted, and then uses <tt>awk</tt> to decrypt the remainder
of the file. Finally, that decrypted stream is
decompressed using the XZ command-line program,
in order to extract a pre-compiled file called
<tt>liblzma_la-crc64-fast.o</tt>, which is also attached to Freund's message.
</p>

<h4>Link time</h4>

<p>
The extracted file is a 64-bit relocatable ELF library.
The remainder of the build process links it into the final <tt>liblzma</tt>
library which ends up being loaded into OpenSSH on some distributions.
Those distributions
<a href="https://sources.debian.org/patches/openssh/1:9.2p1-2%2Bdeb12u2/systemd-readiness.patch/">
patch</a> OpenSSH to use systemd for daemon-readiness notifications;
<tt>libsystemd</tt> in turn depends on liblzma for compressing journal files.
Lennart Poettering has since
<a href="https://mastodon.social/@pid_eins/112202687764571433">posted</a> some
example code showing how to let applications use systemd readiness notifications without
pulling in the entire library.
When the malicious
<tt>liblzma</tt> is used by a dynamically linked process, it uses the
<a href="https://sourceware.org/glibc/wiki/GNU_IFUNC">indirect function</a>
mechanism to involve itself in the <a href="https://lwn.net/Articles/961117">linking process</a>.
</p>

<p>
Indirect functions are a feature of the GNU C library (glibc) that permits a developer to
include several versions of a function and select which version to use at
dynamic linking time. Indirect functions are useful for including optimized versions of a
function that rely on specific hardware features, for example. In this case, the
backdoor provides its own version of the indirect function
resolvers <tt>crc32_resolve()</tt> and <tt>crc64_resolve()</tt> that select
versions of <tt>crc32()</tt> and <tt>crc64()</tt> to use, respectively.
<tt>liblzma</tt> does not usually use indirect functions, but using faster
functions to calculate checksums does sound like a plausible use of the feature.
This plausible deniability is probably why the exploit itself lives in a file
called <tt>liblzma_la-crc64-fast.o</tt>.
</p>

<p>
When the dynamic linker finalizes the locations of those functions, it
calls the backdoor's resolver functions. At
this point, dynamic linking is still in progress, so many of the
linker's internal data structures have not yet been made read-only. This would
let the backdoor manipulate libraries that had already been loaded by
overwriting entries in the procedure linkage table (PLT) or global offset table
(GOT). However, <tt>liblzma</tt> is loaded fairly early in the link order of
OpenSSH, which
means that the <a href="https://www.openssl.org/">OpenSSL</a>
cryptography functions that are the backdoor's ultimate
target may not have been loaded yet.
</p>

<p>
To deal with that, the backdoor adds an
<a href="https://www.man7.org/linux/man-pages/man7/rtld-audit.7.html">
audit hook</a>. The dynamic linker calls all the registered audit hooks
when it is resolving a symbol. The backdoor uses this to wait until it
sees the <a href="https://linux.die.net/man/3/rsa_public_decrypt">
<tt>RSA_public_decrypt@got.plt</tt></a> symbol being resolved. Despite the
name, this function is actually part of handling an RSA signature (which is a
decryption operation) â OpenSSH calls
it while validating an RSA certificate provided by the client
during a connection.
</p>

<h4>Run time</h4>

<p>
Once the backdoor detects this function being linked, it replaces the function
with its
own version. What the altered version does is still being investigated, but at
least one of its functions is to attempt to extract a command from the
public-key
field of the provided RSA certificate (which means that certificates that are
used in this attack cannot actually be used to authenticate normally).
The backdoor checks whether the command is
signed by the attacker's private key and has valid formatting. If it does, then
the backdoor directly runs the given command as the user running <tt>sshd</tt>,
which is usually root.
</p>

<p>
Anthony Weems has put together
<a href="https://github.com/amlweems/xzbot">an explanation</a> of the run-time
portion of the exploit, including a honeypot to detect attempts to use the
exploit, and code to generate command payloads.
Using the backdoor involves signing the command to be executed with a private
key, but the attacker's is not available, so the backdoored server needs to be
patched to use another private key.
This also means that detecting backdoored servers remotely is nearly
impossible, since they will not react any differently to connections that don't
use the attacker's private key.
</p>

<p>
Ultimately, the effect of the backdoor appears to be that a compromised SSH
server which receives a connection with a hand-crafted RSA certificate for
authentication can be made to run attacker-controlled code.
</p>

<h4>Anti-analysis</h4>

<p>
The design of the backdoor makes it difficult to notice without directly inspecting
<tt>liblzma</tt>. For example, the choice to enable remote code execution rather
than an authentication bypass means that use of the exploit does not detect a
login session that could be noticed by traditional administration tools.
The backdoor's code
also uses several techniques to make discovery more
difficult.
For example, the string "RSA_public_decrypt@got.plt",
which is used by the audit hook, never appears in the binary of the exploit.
Instead, it uses a <a href="https://en.wikipedia.org/wiki/Trie">trie</a>
to hold various strings. Serge Bazanski posted
<a href="https://gist.github.com/q3k/af3d93b6a1f399de28fe194add452d01">a
list</a> of strings in the malicious <tt>liblzma</tt> encoded this way.
</p>

<p>
Examining that list shows that <tt>RSA_public_decrypt</tt> is likely not the
only function interfered with; several other cryptography routines are listed.
It also shows various functions and strings that are used to interfere with
OpenSSH's logging. This is not yet confirmed, but it seems likely that a
compromised SSH server would not actually log any connection attempts that use
the exploit.
</p>

<p>
The backdoor also includes many checks to ensure it is running in the expected
environment â a standard precaution for modern malware that is intended to make
reverse-engineering more difficult. The backdoor is only active
under specific circumstances, including: running in a non-graphical
environment, as root, in a binary located at <tt>/usr/sbin/sshd</tt>, with
<tt>sshd</tt> having the expected ELF header, and where none
of its functions have had a breakpoint inserted by a debugger. Despite these
obstacles,
community efforts to reverse-engineer and explain the remainder of the
backdoor's code
<a href="https://gist.github.com/smx-smx/a6112d54777845d389bd7126d6e9f504">
remain underway</a>.
</p>

<p>
The backdoor also includes code that patches the binary of <tt>sshd</tt> itself
to disable <a href="https://man7.org/linux/man-pages/man2/seccomp.2.html">
<tt>seccomp()</tt></a> and prevent the program from creating a
<a href="https://en.wikipedia.org/wiki/Chroot">chroot sandbox</a> for
its children. In total, the code of the backdoor is 87KB, which is plenty of
space for additional unpleasant surprises. Many people have put together their
own summaries of the exploit, including
<a href="https://gist.github.com/thesamesam/223949d5a074ebc3dce9ee78baad9e27">
this comprehensive FAQ</a> by Sam James, which links to other resources.
</p>

<h4>Being safe</h4>

<p>
The exploit was caught promptly, so almost no users were affected. Debian sid,
Fedora Rawhide, the Fedora 40 beta,
openSUSE Tumbleweed, and Kali Linux all briefly shipped the
compromised package. NixOS unstable also shipped the compromised version, but was not
vulnerable because it does not patch OpenSSH to link <tt>libsystemd</tt>.
Tan also included
some other changes to the XZ code to make detecting and mitigating the backdoor
more difficult, such as
<a href="https://git.tukaani.org/?p=xz.git;a=blobdiff;f=CMakeLists.txt;h=d2b1af7ab0ab759b6805ced3dff2555e2a4b3f8e;hp=76700591059711e3a4da5b45cf58474dac4e12a7;hb=328c52da8a2bbb81307644efdb58db2c422d9ba7;hpb=eb8ad59e9bab32a8d655796afd39597ea6dcc64d">
sabotaging</a> sandboxing measures and making preemptive efforts to redirect
security reports. Even though the exploit did not reach their stable versions,
several distributions are nonetheless
taking steps to move to a version of XZ that does not contain
any commits from Tan, so users should expect to see security updates related to
that soon. Readers may also
wish to refer to the security notice for their distribution for more specific
information.
</p><br clear="all">
               <br clear="all">
               <blockquote>
<p>
<b>Did you like this article?</b>  Please accept our 
<a href="https://lwn.net/Promo/slink-trial2-3/claim">trial subscription offer</a> to be
able to see more content like it and to participate in the discussion.
</p>
</blockquote>
<hr><p>
           (<a href="https://lwn.net/Login/?target=/Articles/967192/">Log in</a> to post comments)
           </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Science fiction and the death of the sun (110 pts)]]></title>
            <link>https://www.typebarmagazine.com/2024/03/24/science-fiction-and-the-death-of-the-sun/</link>
            <guid>39911155</guid>
            <pubDate>Tue, 02 Apr 2024 21:39:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.typebarmagazine.com/2024/03/24/science-fiction-and-the-death-of-the-sun/">https://www.typebarmagazine.com/2024/03/24/science-fiction-and-the-death-of-the-sun/</a>, See on <a href="https://news.ycombinator.com/item?id=39911155">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h3><strong>By Gwen C. Katz</strong></h3><p><span>Why is early speculative fiction so grim?</span></p><p><span>From potions that turn people into psychopathic murderers to alien invasions only defeated by coincidental quirks of biology, turn-of-the-20th-century sci-fi carries a distinct tone that the arc of history bends towards catastrophe. Most commentators have looked to social and political factors to explain this tone. There are plenty to choose fromârunaway income inequality, rampant corruption, crushing working-class living conditions. These issues were certainly present in the minds of early sci-fi authors, many of whomâsuch as H.G. Wells, who drafted a precursor to the UN Declaration of Human Rightsâwere progressive reformists.&nbsp;</span></p><p><span>But thereâs another factor that isnât often mentioned: They thought the sun was on the brink of death.</span></p><p><span>Contextualizing stories to their moment in the history of science is more difficult than placing them within political and social history. We donât all take mandatory science history classes in school. Yet important scientific discoveries have a major impact on culture, from Cold War nuclear anxiety to the neon-drenched cyberpunk of the early computer era. And in the 19</span><span>th</span><span> and early 20</span><span>th</span><span> centuries, one of the biggest unanswered scientific questions was: How does the sun work?</span></p><p><span>During the Age of Enlightenment (yes, we really are starting that far back), as the scientific method replaced religion as the explanation for physical phenomena, the predominant scientific belief was that the universe and the bodies within it were endless. If God didnât create the universe 6000 years ago, maybe it had simply always existed. Observationally, the sun has always been there throughout human history and itâs just as bright today as it was yesterday, so itâs logical to conclude that it will always be there. This basic belief in the static nature of the universe proved to be a hurdle for many scientific discoveriesâfor instance, one of the reasons the theory of evolution took time to be accepted was that extinction was not a widely-accepted phenomenon.</span></p><p><span>Science fiction was not yet a codified genre in this era, and few other than theologians were pondering the eventual fate of the earth. Yet there were premonitions. In 1815, Mount Tambora exploded in the most powerful volcanic eruption in recorded history. The resultant ash darkened skies around the world and plunged the planet into a cold spell dubbed The Year Without a Summer.</span></p><p><span>In the midst of this, Lord Byron wrote his 1816 poem </span><a href="https://www.poetryfoundation.org/poems/43825/darkness-56d222aeeee1b"><i><span>Darkness</span></i></a><span>, envisioning a world where the sun never returned:</span></p><blockquote><p><span>The bright sun was extinguishâd, and the stars</span></p><p><span>Did wander darkling in the eternal space,</span></p><p><span>Rayless, and pathless, and the icy earth</span></p><p><span>Swung blind and blackening in the moonless airâ¦</span></p><p><span>The waves were dead; the tides were in their grave,</span></p><p><span>The moon, their mistress, had expirâd before;</span></p><p><span>The winds were witherâd in the stagnant air,</span></p><p><span>And the clouds perishâd; Darkness had no need</span></p><p><span>Of aid from themâShe was the Universe.</span></p></blockquote><p><span>Byronâs primary focus was the human drama of these final days, and he drew primarily from imagination, not scientific theory. Yet his vision of a frozen, sunless earth foreshadowed later discoveries with remarkable prescience.</span></p><p><span>The codifying of the laws of thermodynamics in the mid-19</span><span>th</span><span> century prompted a major reevaluation of scientistsâ assumptions about the universe. The first law of thermodynamics stated that energy had to come from somewhere. The second stated that it had to eventually run out.</span></p><p><span>Outside of fundamentalist Christian circles, most natural laws donât inspire strong emotional reactions beyond interest and curiosity. But thereâs a certain ennui to the second law of thermodynamics. While the billiard-hall laws of Newtonian mechanics run just as happily in reverse, entropy does not. It leaks out from every system, every interaction, always larger than before. What is broken can never be truly mended, it reminds us. What is lost can never be truly regained. Your every action, however mindful, is one more step on the inevitable journey to the heat-death of the universe.</span></p><p><span>The sun could no longer simply be an infinite energy source in the sky. The&nbsp; magnificent beaconâs energy had to be finite, and it had to be caused by something. But what? Such a vast amount of power was a major challenge to the 19</span><span>th</span><span>-century model of physics.</span></p><p><span>The first explanation was offered by Robert Mayer in 1848, and again by Lord Kelvin a few years later: The sun is glowing because meteors are constantly crashing into it. This theory raised immediate and obvious problems. Where are all these meteors coming from? Why canât we see them? </span><i><span>How are we not all dead</span></i><span>, since the meteors would presumably be raining their fiery fury on the earth at the same rate? âNo doubt meteors fall into the sun, as assumed by Mayer and Thomson [Kelvin],â </span><a href="https://www.scientificamerican.com/article/the-age-of-the-sun-and-the-earth/"><span>wrote Florian Cajori</span></a><span> for </span><i><span>Scientific American</span></i><span> in 1908, âbut the Mayer-Thomson theory made demands upon these meteors that bordered on extravagance.â</span></p><p><span>The first tenable explanation arrived in 1854 by Herman von Helmholtz: Gravitational contraction. As the heavy sun collapses under its own weight, the immense heat and pressure cause it to incandesce. Mathematically, this works. Stars are blackbodies, a type of material thatâs black when cool and glows different colors when heated in a predictable sequence: Red, orange, yellow, white, and at its hottest, blue (iron being forged is a familiar example, though it never gets hot enough to glow blue). This suggested a very simple stellar life cycle: Hot, blue-white stars must be the youngest, gradually cooling to yellow, then red, before ceasing to glow altogether.</span></p><p><span>Moreover, unlike the mystery meteors, this theory is finite and quantifiable. Eventually, the sun would finish collapsing, the heat would dissipate, and it would slowly cool and darken into an inert lump ofâ¦stuff. (They were still hazy on that point; as late as the 1920s Arthur Eddington would be using models that assumed stars were almost entirely iron.) Knowing its mass, they could calculate how fast this would happen. So for the first time, it was possible to estimate the lifetime of the sun.</span></p><p><span>And the number was not large.</span></p><p><span>Initial estimates put the sunâs lifespan at around 20 million years. It could hardly be much younger than that, so its lifetime appeared to be mostly over. Soon it would burn out. What about the earth? It would freeze over, its orbit would decay, and it would draw closer to the husk of the sun, becoming tidally locked. Ultimately, it would fall into the remains of the sun and be destroyed, but not until long after all life went extinct. Humanity had, perhaps, a couple million years left before the sky darkened and the earth succumbed to eternal winter. Not a cheery thought.</span></p><p><span>Of course, a million years is hardly an imminent deadline on a human timescaleâitâs still a hundred times the duration of all human civilization to dateâbut nevertheless, the idea that our worldâs time was mostly up cast a bit of a pall.</span></p><p><span>Smack in the middle of these discussions, the natural world provided a most vivid illustration. In 1883, Krakatoa erupted nearly as violently as Tambora, ushering in another volcanic winter. (The 1800s were not a good century for volcanoes. Unless you were a geologist.) For the scientifically-minded, it must have felt like a premonition of earthâs eventual fate.</span></p><p><span>And yet the gravitation theory didnât add up. For one thing, there was geology. While astrophysicists examined the sun, geologists were estimating the age of the earth based on its internal temperature, and their research dated the earth to some hundreds of millions or billions of years old. Biologists studying fossils estimated a similar age. Everyone agreed that the sun had to be older than the earth, so where did the discrepancy lie? âLord Kelvin,â </span><a href="https://zenodo.org/records/1429642"><span>quoth Eddington</span></a><span> in 1920, ââ¦made strenuous efforts to induce geologists and biologists to accommodate their demands to this time-scale. I do not think they proved altogether tractable.â</span></p><p><span>For another thing, if the light came from incandescence, what on earth was a pulsar? Surely a star couldnât be alternately collapsing and un-collapsing.</span></p><p><span>Still, gravitation was the best anyone had, and this theory was taught to students for a solid seventy years. Among these students were the early luminaries of science fiction. The image of the earthâs long, slow descent into an endless ice age lodged itself firmly into their voracious minds, to percolate out in their works. Sometimes this was subconscious, in the form of the melancholic speculative fiction that dominated the genreâs early years. Other times, the sunâs imminent demise and its effect on humanity are the subject of the story itself: The dying-earth genre, which peaked in the first decades of the 20</span><span>th</span><span> century.</span></p><p><span>The most well-known example is </span><a href="https://gutenberg.org/cache/epub/35/pg35-images.html#chap14"><i><span>The Time Machine</span></i></a><span> by H.G. Wells (1895). In one of the bookâs most memorable scenes, in a frenzied struggle to escape the Morlocks, the Time Traveler accidentally sends his machine forward in time instead of back and briefly journeys to the end of the Earth. The scene that greets him is a dismal one:</span></p><blockquote><p><span>The sky was no longer blue. North-eastward it was inky black, and out of the blackness shone brightly and steadily the pale white stars. Overhead it was a deep Indian red and starless, and south-eastward it grew brighter to a glowing scarlet where, cut by the horizon, lay the huge hull of the sun, red and motionlessâ¦There were no breakers and no waves, for not a breath of wind was stirring. Only a slight oily swell rose and fell like a gentle breathing, and showed that the eternal sea was still moving and livingâ¦</span></p><p><span>I cannot convey the sense of abominable desolation that hung over the world. The red eastern sky, the northward blackness, the salt Dead Sea, the stony beach crawling with these foul, slow-stirring monsters, the uniform poisonous-looking green of the lichenous plants, the thin air that hurts oneâs lungs: all contributed to an appalling effectâ¦</span></p><p><span>All the sounds of man, the bleating of sheep, the cries of birds, the hum of insects, the stir that makes the background of our livesâall that was over.</span></p></blockquote><p><span>The bright red sky evokes the dramatic volcanic sunsets following Krakatoa, which, twelve years later, must have still been a vivid memory. The still, lifeless sea recalls Byron.</span></p><p><span>But of particular note is the large, motionless red sun. The description resembles a red giant, and other than the cold temperature it would be easy to mistake this for modern astrophysics, where growing into a red giant marks the end of the sunâs life. In fact, Wells is depicting something completely different: The earth growing much closer to the sun due to orbital decay. Tidally locked, it no longer has day and night, but exists in a perpetual twilight with the sun fixed in a single place. The sun is larger because itâs closer; itâs red because itâs a cooling blackbody. The image of the large, red, cold, stationary sun would appear over and over in melancholic science fiction.</span></p><p><span>But horror author/sailor/bodybuilder William Hope Hodgson proved to be the champion of the dying-earth genre. Hodgson (who was an impressionable six-year-old at the time of Krakatoa) returned to this well twice at length. The first was his slightly brilliant, entirely delirious 1908 novel </span><i><span>The House on the Borderland</span></i><span>. In its </span><a href="https://www.gutenberg.org/cache/epub/10002/pg10002-images.html#XVII"><span>extended flash-forward sequence</span></a><span>, he flexes his understanding of the scientific theory of the day, describing the sun as:</span></p><blockquote><p><span>â¦a tremendous globe of a glowing copper-bronze hue; in parts ringed with blood-red bands; in others, with the dusky ones, that I have already mentionedâ¦these markings were due, probably, to differences in temperature of the various areas; the red representing those parts where the heat was still fervent, and the black those portions which were already comparatively cool.</span></p></blockquote><p><span>In a moment of drama, the sun devours Mercury:</span></p><blockquote><p><span>All at once, during one of these periods of life, a sudden flame cut across the nightâa quick glare that lit up the dead earth, shortly; giving me a glimpse of its flat lonesomeness. The light appeared to come from the sunâshooting out from somewhere near its center, diagonally. A moment, I gazed, startled. Then the leaping flame sank, and the gloom fell again. But now it was not so dark; and the sun was belted by a thin line of vivid, white light. I stared, intently. Had a volcano broken out on the sun? Yet, I negatived the thought, as soon as formed. I felt that the light had been far too intensely white, and large, for such a cause.</span></p><p><span>Another idea there was, that suggested itself to me. It was, that one of the inner planets had fallen into the sunâbecoming incandescent, under that impactâ¦</span></p><p><span>After that one burst of flame, the light had shown, only as an encircling band of bright fire. Now, however, as I watched, it began slowly to sink into a ruddy tint, and, later, to a dark, copper-red color; much as the sun had done. Presently, it sank to a deeper hue; and, in a still further space of time, it began to fluctuate; having periods of glowing, and anon, dying. Thus, after a great while, it disappeared.</span></p><p><span>Long before this, the smoldering edge of the sun had deadened into blackness. And so, in that supremely future time, the world, dark and intensely silent, rode on its gloomy orbit around the ponderous mass of the dead sun.</span></p></blockquote><p><span>Hodgsonâs second foray into the death of the earth comes from his magnum opus, </span><a href="https://gutenberg.org/cache/epub/10662/pg10662-images.html"><i><span>The Night Land</span></i></a> <span>(1912), a 600-page slog so notoriously impenetrable that even H.P. Lovecraft </span><a href="https://www.hplovecraft.com/writings/texts/essays/shil.aspx"><span>criticized its</span></a><span> âpainful verboseness.â The novel is set millions of years in the future, when the sun has long since burned out and the earth is a frozen wasteland inhabited by monsters. The last few million humans all live in one giant, technologically advanced pyramid, remembering the death of the sun only as a legendary creation story.</span></p><p><span>Hodgsonâs depictions contain fanciful embellishments, but they are also peppered with meticulous scientific detail. In </span><i><span>The House on the Borderland</span></i><span>, carbon dioxide precipitates out of the atmosphere and falls as snow, and in the absence of an atmosphere, all sound becomes inaudible. In </span><i><span>The Night Land</span></i><span>, the earthâs crust has cracked as it cooled, creating fissures hundreds of miles deep. In one of the bookâs most melancholic moments, the protagonist finds a book predicting that humanityâs remnants might relocate from the frozen surface to the bottom of these fissures, where it was still warmâonly to realize that the icy wasteland he inhabits </span><i><span>is</span></i><span> the bottom of the fissure, that humanity made the journey thousands of years ago, and that there is no deeper refuge to flee to.</span></p><p><span>But while Wells and Hodgson were writing, science was progressing. In 1898, an upstart named Marie Curie showed up with some glowing rocks and upended everything.</span></p><p><span>Radium gave off impossibly vast amounts of energy seemingly out of nowhere, in defiance of all known physical laws. Atomic theory, mechanics, astrophysicsâall had to rethink their fundamental assumptions in a true scientific revolution. There had to be another source of energy, enormous in magnitude, locked within the atoms themselves.</span></p><p><span>Nuclear energy.</span></p><p><span>Nuclear science opened up intriguing new possibilities to explain the sun. What if it was radiating energy from radioactive isotopes? No more was the sun on the brink of deathâradium could fuel the sun for billions of years. And the problem of the sunâs age suddenly dissipated like polonium in a test tube.</span></p><p><span>âThe sun is full of radiumâ may sound like an outlandish theory, but it was more sensible than it seems: scientists knew the sun contained helium (that is, in fact, where helium gets its name), and at the time, the only known source of helium was the radioactive decay of radium.</span></p><p><span>Gravitation did not go down without a fight. Lord Kelvin adamantly defended it against a battalion of younger scientists, including George Darwin (son of That Other Darwin), who Cajori quotes saying, âI think we have no right to assume that the sun is incapable of liberating atomic energy to a degree at least comparable with that which it would do if made of radium.â Despite the evidence against it, the gravitation theory would shamble on for another couple of decades, says Eddington, ânot alive, but an unburied corpse.â</span></p><p><span>As it happens, the radium theory wasnât correct either. It took another couple of decades before Arthur Eddington, in the same 1920 article quoted above, spitballed the theory which ultimately turned out to be correct: âThe atoms of all elements are built of hydrogen atoms bound togetherâ¦wherever it did occur a great amount of energy must have been set free; in a star a vast quantity of energy is being set free which is hitherto unaccounted for. You may draw a conclusion if you like.â In other words, nuclear fusion.</span></p><p><span>Like the radium theory, fusion allowed for a sun that might be billions of years old. These theories offered only a reprieve, but did not alter the ultimate sentence. Regardless of its power source, the sun would eventually run out of fuel, cool off, and go dark. All life on earth would die.</span></p><p><span>These new theories took the âweâre-all-about-to-dieâ urgency out of the death of the sun, and the dying-earth genre began to lose popularity. Yet the image of the dying sun was still a poignant one. Several sci-fi authors were drawn to the topic in this era, armed with the new scientific knowledge.</span></p><p><span>Now-disgraced sci-fi patriarch John W. Campbell tackled the dying earth in his short story </span><a href="https://archive.org/details/sim_astounding-science-fiction_1935-10_16_2/page/n9/mode/1up"><span>âNightâ</span></a><span> (1935, published under the pseudonym Don A. Stuart). An experimental device accidentally transports a pilot to the end of the universe. He is met with an earth long since frozen, its automated machinery broken down long after all humans had perished:</span></p><blockquote><p><span>There were frozen, huddled heaps that might once have been men. Little fellows with fear forever frozen on their faces huddled helplessly over something that must once have been a heating device. Dead perhaps, since the last storm old Earth had known, tens of billions of years agoâ¦</span></p><p><span>Again I saw that agonizing struggle of the eternally faithful machines trying to repair themselves once more to serve their masters who were dead a million million years. I could see it again in the frozen, exhausted postures of the repair machines, stilled forever in their hopeless endeavors, the last poor dregs of energy spilled in fruitless conflict with time.</span></p></blockquote><p><span>Campbell was well-versed in the latest science. âFrom hydrogen,â he says, âthe heaviest of elements can be built up, and energy released,â but the stars âhad burned their hydrogen until it was a remnant so small the action could not go on.â And this future is not a few millions of years off, but âbillions on billions of years,â when not only the sun, but all the stars have burned out.&nbsp;</span></p><p><span>And yet the imagery of the sun remains familiar:</span></p><blockquote><p><span>It was four timesâsix timesâthe size of the Sun I knew. And it wasnât setting. It was forty-five degrees from the horizon. It was red. Blood-red. And there wasnât the slightest bit of radiant heat reaching my face from it. That Sun was cold.</span></p></blockquote><p><span>(Note, however, that Wellsâs vivid red sunset is not present. Campbell, born in 1910, did not experience Krakatoa.)</span></p><p><span>Astrophysics can show up in the smallest of traces. Did I mention Lovecraft? In </span><a href="https://www.hplovecraft.com/writings/texts/fiction/sot.aspx"><i><span>The Shadow out of Time</span></i></a><span> (1936), he briefly mentions the Yithâs future fate:</span></p><blockquote><p><span>Later, as the earthâs span closed, the transferred minds would again migrate through time and spaceâto another stopping-place in the bodies of the bulbous vegetable entities of Mercury. But there would be races after them, clinging pathetically to the cold planet and burrowing to its horror-filled core, before the utter end.</span></p></blockquote><p><span>The Yith moving </span><i><span>inward</span></i><span> in the solar system, not outward, indicates that Lovecraft, like his contemporaries, believed the sun would cool.</span></p><p><span>The modern stellar life cycle took several more years to work out. Red giants were the sticking point. Discovered at the turn of the century, they simply didnât fit into any of the models. A first guess, during the era of the gravitation theory, suggested that they were young stars. Instead of hottest to coldest, the stellar life cycle moved from largest to smallest. A star began life as a red giant, and then gravitational contraction shrank it into a sunlike star, then a red dwarf. When that didnât hold up, most astronomers concluded that red giants were their own thing.</span></p><p><span>The idea that red giants were in fact very old stars was first tenuously proposed in 1933, but only seriously considered in 1939. In the years that followed, a series of increasingly sophisticated models made it clear that red giants were a late stage of stellar evolution. Instead of gradually burning out, the sun would inflate into a flaming behemoth. The earth would not âgo gently into that good night,â but would be devoured by this ball of fire.</span></p><p><span>The idea of being incinerated by the sun is not exactly a delightful one, but itâs significantly less angsty than the image of the lifeless, cold earth floating for eternity in the black void. Perhaps itâs simply that itâs a quicker end. Or perhaps itâs the part where the red giant collapses, spewing its gasses out across the galaxy to become the next generation of stars. Star stuff we are, and to star stuff we shall return.</span></p><p><span>The image of the earth being devoured by the sun is not without a certain drama of its own, and it makes an occasional appearance in sci-fi to this day. </span><a href="https://www.seizethepress.com/2023/09/04/the-dream-with-no-dreamer-stp8/"><span>âThe Dream with no Dreamerâ</span></a><span> by Evan Forman (2023) eloquently envisions this end:</span></p><blockquote><p><span>After the cities had been put down and the planet flayed of life, the pyramids and pharaohâs tombs were melted down to slag beneath the light of an expanding star. Then the buried dead were cremated in liquifying soil, the mountains tucked away into its volcanic folds.</span></p></blockquote><p><span>Overall, though, this end just doesnât have the same narrative potential, and certainly nowhere near the same urgency. Thus, the discovery of the modern stellar life cycle heralded the end of the melancholic depictions of the dying earth. Meanwhile, science fiction at large had evolved from Victorian pessimism to the techno-optimism of the pulp era. The dying-earth genre didnât vanish on the spot, but it transformed into a stock setting for sword-and-sorcery stories set in the far future where modern civilizationâs technology has long since been lost, beginning with Clark Ashton Smithâs </span><i><span>Zothique</span></i><span> stories, and the scientific underpinnings gradually dwindled away. You can see the modern descendants of these stories in the likes of </span><i><span>Horizon Zero Dawn</span></i><span>.</span></p><p><span>Yet the dying-earth imagery would linger in the minds of a generation of writers who had grown up with it, occasionally percolating to the surface outside of science fiction, in genres that had no reason to be bound by scientific accuracy. In </span><i><span>The Magicianâs Nephew</span></i><span> (1955), C.S. Lewis references the image of the burned-out sun to depict the dying world of Charn:</span></p><blockquote><p><span>âWas it the Deplorable Word that made your sun like that?â asked Digory.</span></p><p><span>âLike what?â said Jadis.</span></p><p><span>âSo big, so red, and so cold.â</span></p><p><span>âIt has always been so,â said Jadis. âAt least, for hundreds of thousands of years. Have you a different sort of sun in your world?â</span></p></blockquote><p><span>It wasnât only sci-fi authors who found literary inspiration in the image of the dying sun. In fact, one of the genres most profoundly affected was poetry. Many prominent poets were deeply interested in the natural world and studied astronomy, and they too were influenced by the melancholia of the dying-earth era.</span></p><p><span>T.S. Eliot was an admirer of Arthur Eddington and kept up on his discoveries. Sometimes this knowledge of astronomy surfaces in his works with great clarity.</span><a href="https://allpoetry.com/the-hollow-men"><span> âThe Hollow Menâ</span></a><span> (1925) is one of Eliotâs darkest works. Written (by his own admission) during a severe bout of depression, the scarecrow-like titular hollow men whisper meaninglessly to each other in a âvalley of dying starsâ that bears striking resemblance to the dying-earth stories:</span></p><blockquote><p><span>This is the dead land</span></p><p><span>This is cactus land</span></p><p><span>Here the stone images</span></p><p><span>Are raised, here they receive</span></p><p><span>The supplication of a dead manâs hand</span></p><p><span>Under the twinkle of a fading star.</span></p></blockquote><p><span>Cosmic death saturates the poem. The wind is described as âMore distant and more solemn/Than a fading star.â âDeathâs twilight kingdomâ makes several appearancesâbut is it the underworld or is it a description of earth in its final days, âThis last meeting placeâ where the hollow men hopelessly gather, awaiting an inevitable death like the frozen men from âNightâ?</span></p><p><span>The poem ends with the most famous lines of T.S. Eliotâs oeuvre:</span></p><blockquote><p><i><span>This is the way the world ends</span></i></p><p><i><span>This is the way the world ends</span></i></p><p><i><span>This is the way the world ends</span></i></p><p><i><span>Not with a bang but a whimper.</span></i></p></blockquote><p><span>The âbangâ here is the Apocalypse that marks the end of the earth in traditional Christian theology (not, as one might guess, a supernova). In the depths of depression, Eliot rejects the churchâs image of a fiery doomsday, finding more to relate to in the painfully slow, cold death offered by science.</span></p><p><span>Nor was he the only poet to observe the dichotomy between the cold death presented by science and the hot death presented by religion. But first, a story. There is an </span><a href="https://www.amerlit.com/poems/POEMS%20Frost,%20Robert%20Fire%20and%20Ice%20(1920%201923)%20analysis%20by%204%20critics.pdf"><span>oft-repeated anecdote</span></a><span> that, in 1920, Robert Frost asked astronomer Harlow Shapley how the world would end, and Shapley told him that it would either be incinerated by the sun, or somehow escape and slowly freezeâand was blindsided a few months later when a reference to this conversation appeared in a poem.</span></p><p><span>You should find this story immediately suspect. Neither Shapley nor anyone else in 1920 had any reason to think the sun would destroy the earth. And the provenance of the story doesnât inspire confidence: Frost commentator Tom Hansen claimed in 2000 that Shapley had related the story in a talk in 1960. The meteor theory had more compelling evidence than this. So, unfortunately, weâve got to mark this one as an urban legend.</span></p><p><span>But Frost </span><i><span>did</span></i><span> enjoy astronomy, and it makes an appearance in many of his poems. In </span><a href="https://www.poetryfoundation.org/poems/44273/the-star-splitter"><span>âThe Star-Splitterâ</span></a><span> (1923), a farmer buys a telescope âTo satisfy a lifelong curiosity/About our place among the infinities.â And he kept up with the latest discoveries. </span><a href="https://www.englishliterature.info/2021/07/skeptic-by-robert-frost-analysis.html"><span>âSkepticâ</span></a><span> (1947), for instance, references Edwin Hubbleâs discovery of redshift (while simultaneously expressing doubt about it:</span></p><blockquote><p><span>I donât believe what makes you red in the face</span></p><p><span>Is after explosion going away so fast.</span></p></blockquote><p><span>So while Shapley may never have spoken to frost, we have every reason to believe that Frost had theories of the death of the sun in mind when he wrote his 1920 poem </span><a href="https://www.poetryfoundation.org/poems/44263/fire-and-ice"><span>âFire and Iceâ</span></a><span>. You already know the poemâsome of you, no doubt, by heartâbut Iâm including it here anyways:</span></p><blockquote><p><span>Some say the world will end in fire,</span></p><p><span>Some say in ice.</span></p><p><span>From what Iâve tasted of desire</span></p><p><span>I hold with those who favor fire.</span></p><p><span>But if it had to perish twice,</span></p><p><span>I think I know enough of hate</span></p><p><span>To say that for destruction ice</span></p><p><span>Is also great</span></p><p><span>And would suffice.</span></p></blockquote><p><span>The poemâs metaphorical message is so resonant that itâs easy to overlook its literal meaning. Scientists at the time really did believe the world would end in ice, disagreeing with theologians, who claimed it would end in fire. For Frost, this disagreement about the physical world created an analogy for the different forms of human cruelty.</span></p><p><span>And so our journey takes us from the roots of science fiction to perhaps the most famous poem of the 20</span><span>th</span><span> century. Itâs a cosmic microcosm of the creative artsâ relationship to all science: Curiosity and inspiration mingled with doubt and pessimism, the love of discovery colliding with the fear that we might wish we had never found out.</span></p><p><span>For while the dying-earth genre came to an end in the 1940s, physics was not done inspiring nihilistic visions of the future. I leave you with one final prescient quote from Arthur Eddington: âIf, indeed, the sub-atomic energy in the stars is being freely used to maintain their great furnaces, it seems to bring a little nearer to fulfilment our dream of controlling this latent power for the well-being of the human raceâor for its suicide.â&nbsp;</span><img decoding="async" src="https://e7tj565ac8j.exactdn.com/wp-content/uploads/2023/11/cropped_transparent_T.png." data-src="https://e7tj565ac8j.exactdn.com/wp-content/uploads/2023/11/cropped_transparent_T.png." alt=""></p><h5>Gwen C. Katz is the lead developer and wolfmaster of Nightwell Games, as well as an author, artist, and former mad scientist. She lives in Pasadena, California with her husband and a revolving door of transient animals. Her upcoming game, Surradia, is a deduction game that unravels the disappearance of three magical artists in interbellum France. You can visit her game studio at&nbsp;<a href="http://nightwellgames.com/" target="_blank" rel="noopener" data-saferedirecturl="https://www.google.com/url?q=http://nightwellgames.com&amp;source=gmail&amp;ust=1705506002308000&amp;usg=AOvVaw2VOx-ZSgXVrPUcOmbHxo7y">nightwellgames.com</a>.</h5><h6>Photo by Chris Barbalis.</h6></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A Brazilian special-forces unit fighting to save the Amazon (166 pts)]]></title>
            <link>https://www.newyorker.com/magazine/2024/04/08/the-brazilian-special-forces-unit-fighting-to-save-the-amazon</link>
            <guid>39910383</guid>
            <pubDate>Tue, 02 Apr 2024 20:14:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.newyorker.com/magazine/2024/04/08/the-brazilian-special-forces-unit-fighting-to-save-the-amazon">https://www.newyorker.com/magazine/2024/04/08/the-brazilian-special-forces-unit-fighting-to-save-the-amazon</a>, See on <a href="https://news.ycombinator.com/item?id=39910383">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-journey-hook="client-content" data-testid="BodyWrapper"><figure data-testid="IframeEmbed"><div data-testid="IframeEmbedContainer"><p><span><p>Listen to this article.</p>
</span></p></div></figure><p>In a clearing in the Brazilian Amazon, I stood with a group of armed men, discussing a viral TikTok video. The video, shot from a helicopter full of illegal miners, showed a vast stretch of rain forest, with dense foliage extending in all directions. The only sign of human habitation was below: a dirt circle surrounded by fanlike lean-tos made of wooden poles and palm fronds. It was a <em>maloca</em>, a traditional compound of the Yanomami, an Indigenous group that inhabits a remote territory in the rain forest of northern Brazil.</p><p>As the helicopter hovered, five Yanomami ran into the clearing, gazing up at the intruders. Several lifted bows and shot arrows. The miners whooped with derisive laughter. âLook at the cannibals,â one of them cried. Another said, âGo on, throw the arrow,â before telling his friends, âLetâs get out of here.â They flew away, yelling, âBunch of faggots!â</p><p>For many viewers, the video was a rare document of an encounter with <em>isolados</em>âmembers of a Yanomami community living with no links to the outside world. For the armed men I was with, it was evidence: a potential lead in a high-profile initiative, sponsored by President Luiz InÃ¡cio Lula da Silva, to dislodge thousands of illicit miners from Yanomami territory.</p><p>The menâfighters with combat gear and assault riflesâbelonged to a tiny special-forces unit known as the Specialized Inspection Group, or G.E.F. Most of them wore face coverings; mining in the rain forest is increasingly infiltrated by violent criminals, making it dangerous for them to reveal their identity. The G.E.F.âs leader and co-founder was Felipe Finger, a wiry man in his forties with a salt-and-pepper beard. Finger trained in forestry engineering, and his unit works under the Brazilian ministry for the environment. But he has spent much of his adult life in armed operations to protect the wilderness, and he talks like a soldier, with frequent references to operations and objectives and neutralizing threats. The current mission was known to national authorities as Operation Freedom. Finger and his men called it Operation XapirÃ­, from a Yanomami word for nature spirits.</p><p>The group formed a circle as Finger laid out the dayâs targets. On a G.P.S., he pointed to a yellow circle showing where the <em>isolados</em> had been harassed in the TikTok video, and then red dots, representing the miners, in an irregular cluster around them. Miners had been detected roughly eight miles from the <em>isolados</em>âmeaning that they had penetrated dangerously far into a protected ecosystem. âWherever they go, the miners destroy everything, entire river systems,â Finger said indignantly. âAnd they do it at the expense of these highly vulnerable people.â</p><p>The Amazon faces many threats. The constant proliferation of road networksâboth legal and illegalâbrings new settlements, and growing human populations burn forests to clear land for cattle and crops. The rain forest is enduring an unprecedented drought, and in Roraima, the state where the Yanomami territory is situated, wildfires set off by such slash-and-burn efforts have spread out of control; more than four thousand square miles burned there this year, releasing vast amounts of carbon into the atmosphere. But mining for gold and cassiterite, a mineral used in electronics, exacerbates the environmental problems with singular ferocity. Wildcat miners, using giant excavators, dredgers, and mercury, can devastate miles of river and forest in a matter of days. With the price of gold now above two thousand dollars an ounce on the global market, a rush is under way in the Amazon, and illegal prospecting accounts for more than half of Brazilâs supply.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>The G.E.F. team was travelling to its targets in two helicopters. Finger took the lead, along with another founder of the unitâRoberto Cabral, a boyish-looking man of fifty-five. When a mine site was found, their chopper would go in first, in case there was gunfire.</p><p>As the helicopters picked their way through the forest, Finger radioed to say that he had âa situation.â We followed G.P.S. coÃ¶rdinates to a river bend, where his chopper had landed on a sandbank. Just upriver was a boat, loaded with equipment and fuel cannistersâa minerâs supply launch. Finger and several of his men waded toward it, their weapons drawn, but its occupants had fled. While we looked on, the G.E.F. men torched the boat, a plume of fire rising from the water.</p><p>A few miles downriver, the helicopters paused over a scarred patch of jungle and a carved-out stretch of riverbank: a mine that the team had destroyed in a previous operation. There was no evidence that digging had resumed, but not far off were signs of another minersâ camp: a huddle of plastic tents barely visible beneath the tree canopy. In a clearing at the edge of the river, the miners had driven rows of cut saplings into the dirtâa low-tech defense against landing helicopters. Eventually, Finger found a way to set down, and his men yanked the poles from the sand and threw them aside.</p><p>The team fanned out and searched for miners, but there was no one in sight. When the G.E.F. canât catch <em>garimpeiros</em>, as the illegal miners are called, the goal is to destroy their camps and their equipment: excavators, planes, house-size dredging rafts used to dig up the river bottom. The team quickly found the mine pit, an ugly gouge of muddy water with a pump, a giant hose, and a sluice, along with a truck engine that served as a generator. Using cans of fuel left by the miners, they doused the machinery and lit it on fire. For good measure, one of them peppered the generator with bullets.</p><p>While a few men stood guard, scanning the forest edges, others moved through the tents and a cookhouse area, searching for anything that might provide a clue to who controls the mines. (Some were makeshift local operations; others were run by crime syndicates or shadow investors in major cities.) Then they piled up flammable materials and set the rest of the camp ablaze.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>As we watched the fire spread, a small plane buzzed away over the trees. It belonged to the miners, Cabral said; they must have been warned that the G.E.F. was coming. He pointed to a white rectangular antenna on a tall pole in the center of the camp and said, âStarlinkââElon Muskâs portable satellite-communications system. One of the men hacked at the pole with a machete until it toppled, and Finger broke the antenna and took the modem. The G.E.F. fighters are well trained, and equipped with satellite imaging, combat gear, assault rifles, and night-vision goggles provided by the U.S. State Department. Increasingly, though, their opponents have similar resources. The dayâs raid had destroyed a facility that might have employed a dozen miners. The number of people involved in illegal mining in the Brazilian Amazon is believed to be as many as half a million.</p><p>For four years, Lulaâs predecessor, Jair Bolsonaro, insisted that the crisis in the rain forest was an elaborate hoax. A far-right former military officer who embraced Donald Trump as an ally and a role model, Bolsonaro maintained that advocates for the environment and for Indigenous rights were part of a communist-globalist conspiracy. He ran for the Presidency promising to dismantle environmental safeguards, and his supporters took him at his word. He assumed office in January, 2019, and within months an estimated twenty thousand <em>garimpeiros</em> were at work in Yanomami land. Despite Yanomami leadersâ pleas for help and a Supreme Court judgeâs order for the miners to be forced out, Bolsonaro did nothing.</p><p>Lula, a veteran left-wing politician who served as Brazilâs President from 2003 to 2010, took office again last year, after a perilously close election. By then, the Yanomami were enduring a crisis, with malaria, hunger, and infant malnutrition spreading widely; hundreds of children had died. Outsiders committed growing numbers of rapes and murders, including incidents in which miners on motorboats shot and teargassed Yanomami as they sped past a riverside community.</p><figure><p><span><div data-attr-viewport-monitor=""><a data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.newyorker.com/cartoon/a28077&quot;}" href="https://www.newyorker.com/cartoon/a28077" rel="noopener" target="_blank"><picture></picture></a><p><span>âBy the power vested in me, from this day forth you may text each other as many times in a row as you want without worrying that youâre coming across as desperate.â</span></p><p><span>Cartoon by Ali Solomon and Miriam Jayaratna</span></p></div></span></p></figure><p>The crisis gave Lula an opportunity to present himself as a savior, and in one of his first acts as President he flew to Boa Vista, the capital of Roraima. He toured a clinic that treated Indigenous patients, and in emotional remarks afterward he blamed Bolsonaro for âthe neglect and abandonment of the Yanomami.â It was âmore than a humanitarian crisis,â he added. âWhat I saw was a genocide.â He vowed to end illegal mining on Indigenous land, just as he had vowed, during the campaign, to achieve âzero deforestationâ in the rain forest by 2030. âThe planet needs the Amazon alive,â he said.</p><p>Lula declared a public-health emergency and ordered an ambitious series of raids to eject the miners. After operations began, in February, 2023, dramatic footage emerged of security forces surging in and destroying equipment, and of miners fleeing the forest. By June, Lula declared the Yanomami land âfree of illegal mining.â Soon afterward, his government promoted new statistics showing that illegal deforestation in the Amazon had fallen thirty-four per cent in six months.</p><p>Last August, in the city of BelÃ©m, Lula presided over a meeting of regional heads of state, and called on them to join him in realizing âa new Amazonian dreamââa grand plan for conservation linked to sustainable development. A few months later, in Dubai for the annual climate-change conference, Lula hailed Brazilâs progress in preserving the rain forest, and celebrated its selection as the site of the 2025 summit.</p><p>But, for all Lulaâs talk about a green future, the large-scale operations in Roraima lasted only a few months. The armed forces, which had joined last yearâs initiative only reluctantly, ceased coÃ¶perating. It wasnât even clear how much loyalty the new President could expect from the military, a largely conservative body that ran the country as a dictatorship from 1964 to 1985. After the inauguration, Bolsonaro partisans had launched a chaotic assault on the Presidential palace, Congress, and the Supreme Court, and some police and members of the military had assisted the mob. Lula subsequently pushed out the commanders of the Army and of the police force that guards the capital. But the military is still regarded as hostile to Lulaânot to mention to the idea of Indigenous rights.</p><p>When I visited Roraima, authorities there said that <em>garimpeiros</em> had been returning to Yanomami territory. Some politicians were not only tacitly accommodating the miners but in some cases coÃ¶perating with them. For many people in Brazil, the lure of easy money far outweighed environmental concerns. Even the judge who had tried to force Bolsonaro to intervene in the Amazon, LuÃ­s Roberto Barroso, acknowledged the persistence of the problem. âThere is an inescapable reality,â he told me, âwhich is that you have people living in poverty sitting on top of vast wealth.â</p><p>Boa Vista is a low-slung city of half a million people, spread along the banks of the Rio Branco. Although Brazil has a complex web of laws to protect the wilderness, settler communities inevitably find ways to profit from the minerals and the timber found in the rain forest, and Boa Vista is booming. Newly built avenues are lined with ostentatious villas, restaurants, and boutiques. Downtown, a childrenâs water park has been constructed next to an artificial beach, decorated with huge, colorfully painted statues of anacondas, jaguars, anteaters, and crocodiles. Near the government offices, a modernist stone sculpture depicts a prospector panning for gold.</p><p>Local officials leave little doubt about their support for mining. In 2022, the Roraima state legislature enacted a law that prohibited destroying equipment confiscated from illegal miners within its jurisdiction. Outside the office of the governor, a Bolsonaro ally named Antonio Denarium, miners and ranchers gathered to celebrate with a barbecue and concert, under a banner that read âGarimpo Is Legal.â (Last year, after Lula took office, Brazilâs Supreme Court threw out the law.)</p><p>Cognizant of the local attitudes, the G.E.F. keeps its presence in Boa Vista quiet. When Iâd arrived, I was told to check into a hotel and wait. Nearly a week later, I got a call telling me that an unmarked car would take me to meet the team at one of the helicopter launchpads that it uses in town: a walled-in grassy patch at the regional headquarters of the federal police. Around the wall were rusting carcasses of helicopters and airplanes confiscated from miners on previous raids. A couple of years before, an angry group had protested the seizures by attempting to set a government helicopter on fire.</p><p>The G.E.F. helicopters took us past the edge of Boa Vista, where vast, treeless cattle ranches and soy farms stretch into the distance. In thirty minutes of flying at a hundred and twenty miles an hour, we could see the open plains start to give way to forest, until my chopper landed at a site where the paved road turns to red-dirt track. It was the teamâs refuelling point before seeking out mines in Yanomami territory. Near a farmhouse, a shiny steel tanker was parked by a mango tree. The truck drove several hours from Boa Vista each morning with an armed escort.</p><p>During the raids last spring, the G.E.F. had been able to refuel in a Yanomami community where the military maintained an outpost. But, a few weeks before my visit, the Air Force had suddenly removed the fuel tank, offering no explanation. The arrangement at the farm was provisional and seemed unlikely to last. One of the agents providing security told me that men in a pickup truck had pulled up early that morning, taken pictures of the tanker and its guards, and then driven away.</p><p>Within a few minutes of taking off again, we had entered Yanomami territory: a rolling green blanket, punctuated only occasionally by the bright-yellow flowers of an ipÃª tree. Deep in the forest, we set down at a gouged mining area. In a camp under the trees, we found a cook fire still burning. The miners clearly werenât far away.</p><p>The G.E.F. members started to burn the camp, monitoring the flames to make sure that they didnât spread. While the men worked, Finger quietly headed into the forest, like a hunting dog that had picked up a scent. Fifteen minutes later, he reappeared with a woman in tow. He explained that heâd found underwear drying on a clothesline and a stack of warm pancakes in the mess, and he figured the campâs cook must be nearby. Heâd found her hiding in some bushes. She was in her fifties, wearing a pink dress and carrying a bag stuffed with belongings. She looked frightened.</p><p>Speaking in breathy bursts, she told Cabral and Finger that her name was Margarida. She was a widow, and after her husbandâs death she had struggled to pay rent and buy food. She had arrived at the mine two days before, after a long river journey, she said, and she didnât know anything about its operationânot even what the minersâ names were. Cabral, looking skeptical, asked what her salary was. She gave a figure that amounted to about four hundred dollars a month. It was a suspiciously small amount, but the cooks, invariably women, were the worst-paid employees of the mines; younger cooks earned extra money as sex workers or were coerced into prostitution.</p><p>No one could say precisely how many miners had made their way back into the territory after last yearâs raids, or had never left, but one government ministry recently estimated the number at about seven thousand. Many of the people who worked the mines were impoverished locals looking for any job they could find; others made a career of it. At one camp, weâd come across the rÃ©sumÃ© of a thirty-seven-year-old named JosÃ©, who had been a sales assistant at an auto-parts shop in Boa Vista, then moved to the city of Manaus to work in a shoe store. His legal employment history ended in 2016, which presumably was when he had turned to illegal mining. Finger drew a distinction between people like Margarida and those like JosÃ©. âThese simpler people, a hundred per cent are there for financial gains,â he said. âBut many of the miners are in this for a better life style. If he can make five thousand reais per week mining, why would he stay in the city earning a thousand or less?â</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>Indigenous people who got involved in mining had more complex incentives. Many were motivated by fear, some by necessity, others by the lure of consumer goods that miners offered, including liquor, shotguns, and new iPhones. âIf an Indigenous person was co-opted by a criminal, either simply to turn a blind eye or to directly participate, itâs a sign that the state failed,â Finger argued. âThe state is not present, and the criminals managed to occupy this gap. And some Indigenous people, without another way to carry on their lives there, end up getting involved.â</p><p>The G.E.F. team sometimes showed concern for the miners; when they found prescription medicine during a raid, they threw it clear of the burn zone so that its owner could retrieve it. But, when I asked Cabral if we were going to fly the cook out with us, he shook his head. âShe got herself here,â he said. âShe can get herself out.â He reassured me that most of the miners attached to the camp were hiding in the forest and would surely emerge as soon as we left. With their food stores destroyed, they would have to evacuate the jungle, and would make the journey together.</p><p>Heading back to the choppers, Finger was frustrated. This mine had been destroyed not long before. âThey were quiet for a couple of months,â he said. âBut when they saw that the operations had decreased they came back, and theyâve learned how to adapt to our tactics.â He pointed to a wide trail leading from the mine into the forest. It was a track for A.T.V.s, built under tree cover to thwart detection from the sky. On his G.P.S., Finger measured our distance from the <em>isolados</em>. âLess than thirty miles,â he said. âItâs very close, considering the range some Yanomami need for hunting.â</p><p>For four decades, the Amazon has existed in a state of persistent conflictâprotected by federal law but threatened by the people who live there. On the way to Boa Vista, Iâd had lunch in BrasÃ­lia with Sydney Possuelo, who had seen much of this history at first hand. Possuelo is a legendary <em>sertanista</em>âone of the jungle scouts who made the first contacts with isolated people. He started travelling into the Amazon six decades ago. Since then, he has hiked thousands of miles through unexplored jungle, been shot by arrows, and made first contact with seven Indigenous groups. Now eighty-three, he occupies a position in the Brazilian consciousness somewhere between Buffalo Bill and John Muir.</p><p>We met at an open-air restaurant and sat outside, at his request, until a tropical downpour forced us indoors. We were joined by Rubens Valente, the author of âThe Rifles and the Arrows,â an authoritative book on Indigenous resistance movements. A soft-spoken man of fifty-four, Valente is one of a very few Brazilian journalists who have made a career of reporting on the Amazon and its Indigenous inhabitants. This media inattention is symptomatic of a larger national neglect, which is partly a result of geography. The rain forest makes up seventy-eight per cent of Brazilâs landmass but contains less than fifteen per cent of its population. For Brazilians who live outside the Amazon, it can seem as remote and exotic as it does to Americans.</p><p>As a young man, Possuelo worked for <em>FUNAI</em>, Brazilâs agency for Indigenous affairs. In those days, the Indigenous were thought of as âwild Indians,â and Possueloâs job was to initiate contact in order to âtameâ them; the military government planned to open the âgreen hellâ of the Amazon to development by building a highway through it.</p><p>By the early nineteen-eighties, Possuelo had begun to understand that exposure to the outside world was largely disastrous for Indigenous groups. Many succumbed to disease; others suffered from alcoholism and sexual exploitation, their forests targeted by unscrupulous loggers and miners. Some chiefs sold access to their lands and began to make profits of their own.</p><p>In 1987, after the fall of Brazilâs dictatorship, Possuelo created a department at <em>FUNAI</em> that organized expeditions to confirm the presence of <em>isolados</em>, to legally protect their territoriesâbut he insisted they be left alone unless they initiated contact. âThe true importance of the <em>isolados</em> isnât in their numbers,â Possuelo told me. âItâs in their languages and cultures and societies, about which we know little, and that has to be respected.â A new constitution, instituted the following year, contained provisions to protect Indigenous lands. Soon afterward, Possuelo led the demarcation of the vast Yanomami territory, a chunk of jungle that spans almost twenty-four million acresâan area larger than Portugalâalong the border with Venezuela.</p><figure><p><span><div data-attr-viewport-monitor=""><a data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.newyorker.com/cartoon/a26800&quot;}" href="https://www.newyorker.com/cartoon/a26800" rel="noopener" target="_blank"><picture></picture></a><p><span>âIâm not great at this whole networking thing.â</span></p><p><span>Cartoon by Johnny DiNapoli</span></p></div></span></p></figure><p>In those days, the Yanomami were one of Brazilâs most secluded Indigenous groups; regular contact with the outside world had begun barely two decades before. Today, about thirty thousand Yanomami live in the Brazilian Amazon. Spread out in some three hundred communities, they live much as they always have, in <em>malocas</em> that house communal groups of several dozen families. They hunt, fish, and gather fruit in the forest, and also grow a few cropsâplantains, cassava, maizeâfor their sustenance.</p><p>The gold in Yanomami rivers has been a problem for as long as outsiders have made their way into the jungle. Possuelo said that, in the early nineties, there were perhaps forty thousand miners operating there, but that he and his allies had forced most of them out. It was harder now, though. The Indigenous were more involved in the trade, and the miners were better equipped and more organized. Perhaps most important, he said, the military wasnât helping to protect the Yanomami. The armed forces maintained three bases in the territory, but, he said, it had not deployed soldiers to stop river traffic, or consistently used aerial surveillance to prevent the miners from coming in. The military had opposed the creation of the Yanomami territory from the beginning, Possuelo explained; when he was marking its borders, the commander of the Army accused him of advancing an independent âYanomami empire,â stretching across the border with Venezuela. Possuelo laughed as he recalled news stories that the military had orchestrated to spread the conspiracy theory.</p><p>Valente said that the armed forcesâ view of the Amazon hadnât changed: âThe military fundamentally doesnât believe in conservation. They think the development of the wilderness is necessary and see it as inevitable.â He showed me a book titled âThe Yanomami Farce,â released in 1995 by the Armyâs publishing house. The cover depicts a blond, fair-skinned man holding up a mask with the face of a Yanomami man in a feather headdress. The book, written by an Army colonel, argued that the Yanomami were not a real Indigenous community but the invention of an international cabal that intended to take over the Amazon. Bolsonaro promoted the same idea, accusing Greenpeace and environmentalist celebrities like Leonardo DiCaprio of being part of this nefarious master plan.</p><p>Yet Possuelo was also skeptical of the current governmentâs campaign, pointing out that Lula had acted after a Supreme Court judge ordered the government to remove the miners. âThe fact is that the Brazilian state has never liked the Indians,â he said. âThe left doesnât like the Indians, and the right doesnât&nbsp;like the Indians, and the center doesnât like the Indians, either.â</p><p>One afternoon, as we approached a mine from the air, a crew of panicked miners went running into the forest. One of them fell over a log, scrambled to his feet, and took off again. As I followed their progress, something caught my eye: two dazzling macaws, flying away from the commotion. After we landed, I found macaw feathers, yellow and blue, hanging on a string from a pole in the camp. Cabral shook his head and said that the <em>garimpeiros</em> must have hunted and eaten the bird. âThe animals die a silent death,â he said mournfully.</p><p>For a public servant, Cabral is unusually outspokenâat least on Instagram, where his account is devoted to denouncing animal cruelty. In one recent post, he shared a photograph of someoneâs pet parrot, with green feathers tinged yellow. âThis is mistreatment,â he wrote. âThe yellow pigmentation indicates nutritional deficiency. A trained environmental agent would notice and fine the person responsible.â</p><p>At the camp, Finger told Cabral that he had found signs of an active site deeper in the forest. We followed him, moving silently along a path through the woods. As we advanced, we could hear a dog barking. Finger scouted ahead, then crept back and motioned for us to follow. In a clearing, there was a wooden shack and a cookhouse, abandoned except for a black dog with distended teats, yowling in distress. Then we heard a peculiar squalling from a box next to the shack. Cabral lifted a plastic cover, revealing a mass of wriggling puppies, just a few days old. He picked up a couple and held them, then walked to a rack where the miners had been drying bush meatâtapir, he guessed. He threw a piece to the mother dog, which began devouring it.</p><p>The team searched through belongings, but no one poured gas or piled up flammables. Were they going to burn the place? I asked. The men didnât answer; they were looking at Cabral, fussing over the puppies. Eventually, Finger barked, âLetâs go.â As the team fell in, Cabral told me that they were leaving the camp intact because of the puppies: âWe could move them away from the shack, but the mother might run away in fright and not be able to find them afterward.â One of the men joked that, if there had been a child in the camp instead of the puppies, they would have burned the shack. Cabral laughed and shook his head, but he didnât protest.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>Early in his career, Cabral acquired the nickname Rambo, but it seemed mostly like a joke. He had taken up armed patrols only in service of wildlife conservation, his lifelong passion. He came from Juiz de Fora, a city in Brazilâs interior, and spent his childhood immersed in nature, watching wildlife programs and reading about animals. âThis is all I ever wanted to do,â he told me. He earned a degree in biology and another in ecology, then joined <em>IBAMA</em>, a branch of the environment ministry that protects threatened ecosystems.</p><p>Working in the Amazon, Cabral became increasingly aware that ecological abuses converged with other crimes: gunrunning, drug trafficking, homicides. But the Brazilian government dealt with these things through a patchwork of federal bureaucracies and police agencies, with no force that had both the requisite scientific knowledge and military-style training. In 2013, Cabral secured approval to build a unit of rangers who were committed to saving the environment, by force if necessary. The next year, he was shot in the shoulder when he and his men surprised illegal loggers in the woods; he was back at work in less than two months.</p><p>The members of the G.E.F. are biology nerds who found themselves carrying gunsâa gang of jungle Ghostbusters. They undergo intensive training, developed by a specialized police unit that fights organized crime. âThere are courses on weaponry and shooting, survival in operational environments, vertical activities, and aerial operations,â Finger said. âWe had a tactical-entry course, but adapted to our realityâthey focus mostly on urban operations, while we focus on rural areas, forest environments.â <em>IBAMA</em> has twenty-eight hundred employees, but very few apply for the training, and fewer still qualify. Out of the twenty or so who tried out most recently, Finger said, only four were accepted.</p><p>Finger had the physique and the temperament of a natural athlete. Growing up in the city of CuiabÃ¡, in Brazilâs farm belt, he had played soccer well enough to consider a career, but ended up emulating his father, who ran the forestry-engineering department at the local university. Even working in ecology, he was drawn to action. âIf I had stayed in soccer, Iâd have played offense,â he said, laughing. After college, he had found his way to <em>IBAMA</em> and helped establish the G.E.F.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>Most members of his team had graduate degrees in the sciences. Renato, a muscular man of thirty-four with a shaved head, had specialized in fish ecology. During raids, he did a lot of the heavy lifting, keeping up a cheerful patter as he destroyed mine equipment; other times he fixed engines. Alexandre, forty-eight and the father of two young girls, had worked in a national park and in fisheries regulation before taking the G.E.F. training course. âIâd never imagined working with weapons,â he said, but he had shown an unexpected aptitude. He was generally a guard, calmly scrutinizing the surrounding forest with a gun at his shoulder.</p><p>The only nonscientist was Marcusâa former lawyer, forty-two, tall and rangy, with an easygoing manner. At the headquarters, in BrasÃ­lia, he procured weapons and ammunition for the group; in the field, he was often a guard. Growing up in the interior province of GoiÃ¡s, he aspired to be a photographer for skate magazines, until his parents persuaded him to go to law school instead. Halfway through, he attended a ceremony of the UniÃ£o do Vegetal, a Christian sect that incorporates ayahuasca in its sacraments. âDuring the opening chant, I left my body,â he recalled. âI started to see the Amazon rain forest and found myself walking through it in a uniform with a team, while Indigenous people chanted behind me. That moment filled me with joy, and there I discovered the mission of my life.â</p><p>In BrasÃ­lia, I met Lula in his office, a capacious room with a corner view of the city. He acknowledged that his administration had allowed the situation in Roraima to deteriorate again. âWe should have done something, and we didnât do it,â he said. Yet he seemed wary of criticizing the military, whose support he needs to remain in power. Even as he allowed that the armed forces âcould have made mistakes,â he said, âI donât think we need to single out someone responsible.â All the ministries involved had failed, he suggested: âHere in Brazil, we used to say that a dog that has too many owners will starve, because everyone thinks that the other owner gave him food.â (He also noted that the armed forces had flown nine hundred and forty missions distributing aid to the Yanomami, and that ânot one dumped cargo on anyoneâs head, as happened in Gaza.â)</p><figure><p><span><div data-attr-viewport-monitor=""><a data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.newyorker.com/cartoon/a28166-rd&quot;}" href="https://www.newyorker.com/cartoon/a28166-rd" rel="noopener" target="_blank"><picture></picture></a><p><span>Cartoon by Roz Chast</span></p></div></span></p></figure><p>Part of the problem with policing the territory was its sheer size, he said. There was also the fact that some of the miners are Venezuelans who have crossed the border, which meant that arresting them and blowing up their boats risked creating an international incident. âIf we send in the military to take such actions, I could face problems,â he said.</p><p>The greatest problem, in Lulaâs telling, was that Bolsonaro had left him a mess. âThe state machinery was dismantledâeverything that has to do with climate change, everything that has to do with Indigenous people, everything that has to do with environmental conservation,â he said. Bolsonaro had reduced <em>IBAMA</em>âs staff of rangers by sixty per cent, and had imposed similar cuts at the agencies for Indigenous affairs and the environment. The agencies that worked in the Amazon were handed to archconservative military officers. The environment ministry was given to an advocate of deregulation, who later resigned after being accused of involvement in an illicit logging scheme. (The minister denied any wrongdoing.) <em>FUNAI</em>âs Indigenous-outreach department went to an evangelical preacher who had previously sought out isolated groups to convert them. The director he replaced, Bruno Pereira, kept up his work independently. In 2022, he was murdered, along with a British reporter named Dom Phillips, while investigating illegal intrusions in the Javari valley.</p><p>During the Bolsonaro years, the G.E.F. struggled with political interference, and for one eight-month stretch was confined to base. Now it had the governmentâs public blessing, but it still didnât have the support it needed. There were vexing limitations on making arrests. âIf we catch someone in the act of committing a crime, we can arrest the criminal and take them to the federal police,â Finger said. But Brazilian law made it nearly impossible to imprison mine workers, so the G.E.F. detained only those who had what Finger called ârelevant strategic interestââpeople higher in the command structure, who are rarely in the field. âIf itâs just a worker at the mining site, we identify them but usually leave them there.â</p><p>The miners were brazenly aware of the G.E.F.âs limits. On one raid, we flew over a camp on a forested hill, where a man stood blithely watching as we circled. Cabral explained that he had probably deduced, correctly, that there was nowhere for us to land the helicopters. Technology provided another kind of cover. âWherever the miners have Starlink, weâre at a real disadvantage,â Finger told me. âThey can warn each other there is a raid going on in the territory, and they can organize their work better.â</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>Some members of the G.E.F. felt increasingly that Lulaâs administration was doing only what was necessary to preserve its image. âThere are few people in this government who really care about the conservation of the wilderness,â one told me. âLula is not really an environmentalist himselfâitâs more that heâs worried about international public opinion.â Cabral lamented that, even aside from the Yanomami crisis, obvious solutions to environmental problems were being ignored. If sawmills were properly licensed and monitored, for example, it would hugely reduce illegal logging.</p><p>Of course, Cabral said, things had improved since the previous administration. <em>IBAMA</em> was being rebuilt, and its ranks of active rangers had expanded slightly. Nevertheless, there were roughly eight hundred rangers responsible for all of Brazilâs regions, including not just the Amazon but also the Pantanal wetlands and the immense Atlantic coastline. The country needed at least five thousand more, Cabral saidâyet the salaries were paltry, with the most experienced rangers earning no more than a rookie in the federal police. Cabral himself made about twenty-five hundred dollars a month. Even so, he wouldnât change jobs, he said: âI love what I do.â But others were losing patience; not long after my visit, employees at <em>IBAMA</em> and other environmental agencies began to protest by refusing to go on field operations.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>Cabral told me how many members the G.E.F. had only after swearing me to secrecy. It was a shockingly low number. Finger, who was listening in, explained, âItâs hard to find people who want this kind of life. People want to go to a desk and work for some hours and then go home.â I asked Cabral how much bigger the team would need to be in order to flush the miners from Yanomami territory. âWith thirty-six men, I could do two operations simultaneously, which would be ideal,â he replied. It would still be a small team, but with the right kind of backup, he said, it could achieve a lot. To address all of the mining hot spots around the Amazon, he guessed, the G.E.F. would need at least three hundred and twenty menâmany times what he had.</p><p>As we walked through the forest on raids, we were shaded by huge trees, and when we emerged into the cleared spaces around mines there was a sudden shock of heat. The signs of extraction were always the same: gouged earth, trees felled and burned, the forest floor stripped to bare soil. The camps were usually crude: stick palisades, covered in black or blue tarps, and open-sided cookhouses littered with charred pots and cans of sardines. On one mess table, I saw a Bible, an acetylene torch with a bottle of mercury, and a supply ledger listing aspirin, ointment for sores, and stomach medication. On another, I saw shotgun cartridges and a pair of black assault rifles. There was often the smell of food being cooked and eaten in close range of stagnant water and places where people shit.</p><p>At one mine, Finger led the column up an A.T.V. trail that stretched into the forest, and as we left camp the light grew dimmer and the trill of cicadas swelled. A few hundred feet along the path, two shots cracked through the trees. We all threw ourselves on the ground and waited tensely, until word came down the line that it was Finger who had fired. When we caught up with him, he was still scanning the woods with his weapon ready. He had spotted a man with a gun and had fired before his opponent could. The man had fled, apparently unharmed.</p><p>In some ways, the sweeps that Lula ordered last year had only increased the danger for Finger and his men. Most of the impoverished locals who worked in the mines had fled, and many of those who had taken their place were better armed and better fundedâoften because they were linked to criminal groups. The most fearsome was a SÃ£o Paulo-based crime syndicate known as the P.C.C., from a Portuguese phrase meaning âFirst Command of the Capital.â The P.C.C., founded in a prison annex known as Big Piranha, had grown into Brazilâs largest criminal enterprise, with connections to the Calabrian Mob and a significant presence in the global cocaine trade. Gold prospecting offered the gang both revenue and opportunities to launder drug money.</p><p>Early in 2023, the G.E.F. had arrived in Roraima and started collecting intelligence. âIn three uninterrupted months acting daily on the ground, we were able to gather a lot of precise information about how the P.C.C. was operating,â Finger said. The gang supplied miners with equipment and guns, and also sent its members to supervise and provide security. I saw one video, taken by a terrified, whispering Yanomami man, of heavily armed men hiking up a ravaged riverbed as he hid in the bushes a few feet away. Gang members helped transport gold out of the territory, and in settlements they sold drugs and ran prostitution rings.</p><p>On April 30th, G.E.F. members joined a group of federal highway police to raid an encampment occupied by the P.C.C. âThe operation took place during the day, on a Sunday,â an agent who was involved told me. âIt was by helicopterâthe only way to reach the area surgically.â A river incursion would have been risky: the miners knew the terrain better.</p><p>The helicopters that <em>ibama</em> supplied for the mission werenât bulletproof, so they dropped the men and left as quickly as they couldââa very quick infiltration to avoid being hit.â As the patrol moved through the jungle, gunfire came from off the trail several times. âWe knew that the risk of an armed confrontation was real,â the agent said. âWe had prepared for it, planned for it.â Nevertheless, the first burst of gunfire was jarring: âI thought to myself, We have to apply the techniques weâve learned and come back alive. We have our families to take care of.â In training courses, he said, âthere is a bell that you ring when you give up. In the middle of the war, there is no bell.â</p><p>When the shooting stopped, the government agents were safe and four criminals had been killed. Among them was Sandro Moraes de Carvalhoâa gangster known as Presidente, the P.C.C.âs commander in the area. The firefight made national news, drawing attention to the Amazon, and Brazilâs minister of justice announced that he was sending in more than two hundred armed officers. âIt was the most important action in the history of the G.E.F.,â Finger told me.</p><p>Finger avoided discussing his more dangerous missions with his wife. âI donât know if she doesnât ask to avoid knowing the details, for psychological reasonsâbut she doesnât ask, and I donât tell,â he said. âIf my mother knew, she wouldnât sleep.â But he showed few reservations about the use of force. âThe idea that criminal groups can take over territory and hold Indigenous people hostage is more than a humanitarian emergencyâit is a war,â he said. âIndigenous people are just like us, and maybe better than us. But their lives are being destroyed. The state needs to come in and protect them and treat them like Brazilians.â</p><p>The Yanomami do not have a single leader, but Davi Kopenawa, a shaman in his late sixties, is widely acknowledged as their representative to the outside world. Kopenawa, who is sometimes referred to as âthe Dalai Lama of the jungle,â maintains a home in the forest, but he spends much of his time in Boa Vista, spreading awareness of his peopleâs concerns from the offices of the Hutukara Yanomami Association.</p><p>One morning, I visited the associationâs compound, which overlooked the Rio Branco and was secured with surveillance cameras and a wall topped with electrified razor wire. Past the gate, I found Kopenawa inspecting a small strip of garden that ran between the security wall and the house, which was painted an institutional gray. Barefoot, in shorts and a T-shirt, Kopenawa had wooden plugs in his earlobes and a stick in his hand. He stood scowling at a line of small bushes that had recently been planted next to the wall. In halting Portuguese, he grumbled, âThis isnât a real garden. Itâs the kind of thing white people plant to say they like plants.â</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>Inside, his office walls were hung with photographs of the Yanomami, taken by some of the earliest visitors: a vision of life before the incursion of outsiders. Kopenawa perched in a chair and toyed with a macaw feather on his desk as we talked. I asked if he had thought of going with Lula to the climate conference in Dubai. Kopenawa waved his stick and grimaced. âThatâs just for white people.â He liked Lula, he said, but Lula did not grasp the full extent of what was happening in Yanomami territory. He hadnât even been thereâonly to Boa Vista, he said chidinglyâand little had changed since he had declared the health emergency. In one place, Kopenawa said, the miners had built a road right into their land. In another, they had surrounded a community, razing its forest; now some Yanomami there were working for the miners and had become addicted to drugs.</p><p>Kopenawa suggested that the military was being duplicitous. âThey just come to make it appear as if everything is all right,â he said. âBut theyâre not taking out the minersâtheyâre supporting them.â He asked me to pass a message to the President: âTell Lula that the problems of the Yanomami people have not been resolved, that illegal mining continues, that I am worried about our children. Tell him that criminals with guns have joined the minersâand the police are afraid to go there.â He added, âLula has been travelling a lot all over the world. But he should come here, to our land, which has been invaded. We need his help, too.â</p><p>The local authorities were worse, Kopenawa said: âThey donât like or respect us. All they want is to exploit our land and to rob our forest.â He had received death threats, which is why his security wall had been reinforced. The house next door to the associationâs belonged to an influential senator named Chico Rodrigues, who, like the stateâs governor, was a Bolsonaro ally. Rodrigues had made news in 2020, when federal police raided his house as part of an investigation into the embezzlement of <em>COVID</em>-19 relief funds. Agents searched him and found more than five thousand dollarsâ worth of Brazilian cash hidden in his underwear and his clothes. Rodrigues had previously been fined for illegally razing more than fifteen hundred acres of rain forest and converting it into cattle range, but he never paid. (He has maintained his innocence on both counts.)</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>Back on the street, as I got into a car, a mud-spattered pickup pulled in front of me. A group of rough-looking young men got out and buzzed at the security door of Rodriguesâs house, an imposing white multilevel place that loomed over the associationâs compound. As they were shown in, a Yanomami man in the car with me whispered, â<em>Garimpo</em>.â</p><p>When I met with Lula, he told me that he hoped to return to Roraima. âItâs important to go there again,â he said, adding, âWe have a human obligation to solve this issue.â Despite the increasing problems in the region, he spoke energetically of his plans. His administration recently passed an emergency measure that allocated more than two hundred million dollars to efforts in the Yanomami territory. âWeâre going to hire more federal police,â he said. âWeâre going to hire more armed forces.â In order to facilitate a more coherent response, his administration had set up a multi-agency âcoÃ¶rdinating centerâ in Boa Vista, run by one of his close loyalists; it opened in mid-March. âSix months from now, you come back to Brazil and weâll have another conversation,â Lula assured me.</p><p>Marina Silva, Lulaâs environment minister, suggested that the concerns would be difficult to address. When I visited her office, she was preparing for the latest climate-change summit, where she would appear alongside Lula. She looked exhausted. Silva, the daughter of an Amazonian rubber tapper, is a bespectacled woman with an ethereal presence who has spent decades leading efforts to safeguard Brazilâs wilderness. She served as Lulaâs environment minister during his first tenure, and although she succeeded in fighting deforestation, differences emerged between them over a series of infrastructure projects, which included a huge hydroelectric dam and a major road in the rain forest. She finally resigned, citing âgrowing resistance by important sectors of the government and society.â Still, after the calamitous Bolsonaro Presidency, she had agreed to rejoin Lula, in the hope of repairing the damage.</p><p>In her office, Silva chose her words carefully, saying, âThere have been some advances and also challenges.â Lulaâs first advance, obviously, was the âreÃ«stablishment of democracy.â Immediately after taking office, she pointed out, he had signed five decrees to protect the environment. Yet his administration had also auctioned off oil- and gas-drilling rights in nearly two hundred areas; there is talk that Lula may authorize the paving of a five-hundred-mile-long road through the rain forest.</p><p>A large portion of Brazilâs exports rely on farming and natural-resource extraction, and implementing a policy of âzero deforestationâ would require rebuilding the economy. Silva acknowledged that there was âno magic keyâ to changing a development model that was three hundred years old. âIt will require pressure, sustained policies, and also sustained investment,â she said. Unless the government found ways to provide economic solutions for its citizens, its plans would be doomed, she suggested. The only way forward was to be âsustainable,â and to âcreate an environmental consciousness among Brazilians.â She was talking, in effect, about a revolutionary change in the way her countryâs citizens imagined their lives.</p><p>On the morning of our last raid, the rain in the jungle was too heavy to fly in, so we had to wait out the storm at a new refuelling pointâa farm farther into the forest. The last place had fallen through; the owner, under pressure from his <em>garimpo</em> neighbors, had told the team to refuel elsewhere. The new farm had a Starlink connection, and, as the rains abated, a pilot said that he was sure the farm manager would warn the miners that we were coming.</p><p>He was right: at the first target site, the <em>garimpeiros</em> were speeding away on A.T.V.s by the time we approached. We found a string of mines, connected by trails, with two airstrips carved out of the forest. A stretch of riverbank perhaps two miles long had been smashed and ruined. Marcus, the former lawyer, said that G.E.F. members often told themselves, âWe wonât end the degradation of the Amazonâwe will only postpone the end of the Amazon.â As we hiked around one of the mine pits, he&nbsp;confessed that he feared that âthe Yanomami jungle would become like Rio, all of it in the hands of criminal organizations.â</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>On our flight back, my pilot, Franke, found a radio frequency where <em>garimpo</em> pilots were talking. As we listened, one gave his coÃ¶rdinates to another. Frankeâs co-pilot traced them to an airstrip in the woodsâjust a few miles from the G.E.F. teamâs new refuelling point. Franke passed the information to Finger, in the other helicopter, and they agreed to try to intercept the plane before it could take off.</p><p>The laws concerning intercepting planes are intricate. âI can set fire to clandestine airstrips but not shoot planes down,â Finger told me. Aircraft discovered on the ground can be destroyed or flown to Boa Vista, though there was no way of knowing that they were in good enough condition to make the trip safely. The best hope was to apprehend the people on board. âWhen we manage to get our hands on the pilot, we take them into custody,â Finger said.</p><p>As we approached the airstrip, the <em>garimpo</em> plane, a Cessna, quickly took off, heading farther into Yanomami territory. Finger and Franke raced after it, as the <em>garimpeiro</em> pilot took evasive actionâbanking hard to the left, then dropping down till his plane almost brushed the treetops.</p><p>While the Cessna sped above the forest, we chased after it, listening to its pilot shouting over the radio, âHeâs on my back!â But the <em>garimpeiro</em> stayed tauntingly ahead of us; as Franke explained, our chopperâs top speed was the same as the Cessnaâs. Franke watched the fuel gauge anxiously as he flew. Weâd started the chase with not much more gas than we needed to get back to base, and the needle was dropping fast. Finally, Finger had to peel away, and soon afterward so did we. As we watched, the plane flew on into the jungle.</p><p>Despite these kinds of frustrations, the G.E.F. team maintained a stubborn resolve. Alexandre, the fisheries expert, told me, âIn the remote areas where we work, our efforts have consequencesâwe manage to halt encroachment. Even if itâs a little antâs work, itâs possible to see the progress.â But Finger described their efforts as a zero-sum game. As the G.E.F. chased out miners from Roraima, others were encroaching on KayapÃ³ territory, and on protected Munduruku land. An Indigenous settlement called SararÃ©, on the Bolivian border, was increasingly worrisome. âThe feeling of fighting a losing battle is constant,â Finger said.</p><p>On one raid, Franke slowed the rotors and pulled into a wide circle over the forest, gesturing for me to look out the window. Below us was a clearing, with a circle of lean-tos at the center. According to Frankeâs G.P.S., it was the same <em>maloca</em> the miners had flown over two weeks earlier, terrifying the <em>isolados</em> in the TikTok video. There was no sign of life now; the <em>maloca</em> appeared abandoned.</p><p>As we flew away, Franke pointed down again. I could see a river, its muddy banks gouged and punched, with shining pools of stagnant waterâthe signs of a mining operation. I asked him how far we were from the <em>maloca</em>. âOne point seven kilometres,â he said. The mine was deserted, and the miners were gone, for now. But so, it seemed, were the Yanomami.&nbsp;â¦</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Anonymous public voicemail inbox (353 pts)]]></title>
            <link>https://afterthebeep.tel/</link>
            <guid>39910119</guid>
            <pubDate>Tue, 02 Apr 2024 19:49:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://afterthebeep.tel/">https://afterthebeep.tel/</a>, See on <a href="https://news.ycombinator.com/item?id=39910119">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <table>
            <tbody><tr>
                <th>#</th>
                <th>Date</th>
                <th>Length</th>
                <th>Memo</th>
            </tr>
            <tr data-audio="/messages/eb9f7d9fd1584965948ac692fec5548f.mp3">
                <td>22</td>
                <td><time datetime="2024-04-02T17:07:47-04:00">2024/04/02  5:07 PM EDT</time></td>
                <td>0:18</td>
                <td>Whistling a tune</td>
            </tr>
            <tr data-audio="/messages/0760a6e4c9b148ddbf2314dce67eb4e5.mp3">
                <td>21</td>
                <td><time datetime="2024-04-02T17:06:18-04:00">2024/04/02  5:06 PM EDT</time></td>
                <td>0:54</td>
                <td>Kids these days</td>
            </tr>
            <tr data-audio="/messages/8ecaebe50d6de7ab8e720e4f0ac9a04b.mp3">
                <td>20</td>
                <td><time datetime="2024-04-02T17:04:13-04:00">2024/04/02  5:04 PM EDT</time></td>
                <td>0:13</td>
                <td>???</td>
            </tr>
            <tr data-audio="/messages/95f6d1801d9b33f3b2e4de6be660ac44.mp3">
                <td>19</td>
                <td><time datetime="2024-04-02T17:00:31-04:00">2024/04/02  5:00 PM EDT</time></td>
                <td>0:18</td>
                <td>Animals are cool, I like animals</td>
            </tr>
            <tr data-audio="/messages/95b8fb05f9c7666a1ac7c85b88bdf461.mp3">
                <td>18</td>
                <td><time datetime="2024-04-02T16:53:31-04:00">2024/04/02  4:53 PM EDT</time></td>
                <td>0:07</td>
                <td>Your refrigerator is running</td>
            </tr>
            <tr data-audio="/messages/00d017ff07e0a483bbef30dcbcad115c.mp3">
                <td>17</td>
                <td><time datetime="2024-04-02T16:51:46-04:00">2024/04/02  4:51 PM EDT</time></td>
                <td>0:06</td>
                <td>Farewell, toodle-too</td>
            </tr>
            <tr data-audio="/messages/02479d90bce2ba4db18a59eb03225c99.mp3">
                <td>16</td>
                <td><time datetime="2024-04-02T16:51:45-04:00">2024/04/02  4:51 PM EDT</time></td>
                <td>0:07</td>
                <td>Hello world, this is a message</td>
            </tr>
            <tr data-audio="/messages/61a6d21ce3885e16de11813538648456.mp3">
                <td>15</td>
                <td><time datetime="2024-04-02T16:44:25-04:00">2024/04/02  4:44 PM EDT</time></td>
                <td>0:06</td>
                <td>Welcome to planet Earth</td>
            </tr>
            <tr data-audio="/messages/01294a9b6d8dc0fd01051065b54161f4.mp3">
                <td>14</td>
                <td><time datetime="2024-04-02T16:42:50-04:00">2024/04/02  4:42 PM EDT</time></td>
                <td>0:32</td>
                <td>I mean like really steep stairs</td>
            </tr>
            <tr data-audio="/messages/58cd8334b5f40f1b776f5efccd98d5f5.mp3">
                <td>13</td>
                <td><time datetime="2024-04-02T16:35:11-04:00">2024/04/02  4:35 PM EDT</time></td>
                <td>0:02</td>
                <td>Heheh</td>
            </tr>
            <tr data-audio="/messages/e91bbba7e0cfb606c4284f65f1b9d28f.mp3">
                <td>12</td>
                <td><time datetime="2024-04-02T16:32:30-04:00">2024/04/02  4:32 PM EDT</time></td>
                <td>0:12</td>
                <td>Never stop loving yourself, bitch!</td>
            </tr>
            <tr data-audio="/messages/b26373cdb93bda76a3509253a2478e20.mp3">
                <td>11</td>
                <td><time datetime="2024-04-02T16:29:41-04:00">2024/04/02  4:29 PM EDT</time></td>
                <td>0:39</td>
                <td>Hoping for a tornado in a far off field</td>
            </tr>
            <tr data-audio="/messages/1c48b304b3ff23699ed343879a93624d.mp3">
                <td>10</td>
                <td><time datetime="2024-04-02T16:27:14-04:00">2024/04/02  4:27 PM EDT</time></td>
                <td>0:02</td>
                <td>Hack the planet!</td>
            </tr>
            <tr data-audio="/messages/5a665dc2820c31035a9ce7ebf2c4f771.mp3">
                <td>9</td>
                <td><time datetime="2024-04-02T16:14:17-04:00">2024/04/02  4:14 PM EDT</time></td>
                <td>0:34</td>
                <td>This is Jacob calling about your colon</td>
            </tr>
            <tr data-audio="/messages/a6ac5d052d66f93c2677f78fd7c65bb8.mp3">
                <td>8</td>
                <td><time datetime="2024-04-02T16:12:45-04:00">2024/04/02  4:12 PM EDT</time></td>
                <td>0:27</td>
                <td>Itâs 1994 calling, things are extreme!</td>
            </tr>
            <tr data-audio="/messages/054f1b0c956dd9c1c97076a76da69ba4.mp3">
                <td>7</td>
                <td><time datetime="2024-04-02T16:11:59-04:00">2024/04/02  4:11 PM EDT</time></td>
                <td>0:40</td>
                <td>Greetings from the Black Sea coast</td>
            </tr>
            <tr data-audio="/messages/8b2e6eda657b499091a8f9458dc33104.mp3">
                <td>6</td>
                <td><time datetime="2024-04-02T16:09:12-04:00">2024/04/02  4:09 PM EDT</time></td>
                <td>0:11</td>
                <td>Tonight I went fishing</td>
            </tr>
            <tr data-audio="/messages/840aa2598e343f1994df081beb66deaa.mp3">
                <td>5</td>
                <td><time datetime="2024-03-31T23:35:28-04:00">2024/03/31 11:35 PM EDT</time></td>
                <td>0:43</td>
                <td>Happy Easter, Jesus</td>
            </tr>
            <tr data-audio="/messages/4422f8d0c1ad3d8203b83e8ef8aeaeda.mp3">
                <td>4</td>
                <td><time datetime="2023-07-08T03:26:49-04:00">2023/07/08  3:26 AM EDT</time></td>
                <td>0:58</td>
                <td>Thank you to Ellie</td>
            </tr>
            <tr data-audio="/messages/03a7a7746e0156dd6e71fe3b0c1fda11.mp3">
                <td>3</td>
                <td><time datetime="2023-07-01T23:06:31-04:00">2023/07/01 11:06 PM EDT</time></td>
                <td>0:23</td>
                <td>Check out <a href="https://bsoa.bandcamp.com/" target="_blank">Blue Skies Over Alaska</a></td>
            </tr>
            <tr data-audio="/messages/51f5e871e4d7d728518d30abf45a8b13.mp3">
                <td>2</td>
                <td><time datetime="2023-05-28T22:46:59-04:00">2023/05/28 10:46 PM EDT</time></td>
                <td>1:23</td>
                <td>Boy, am I overwhelmed</td>
            </tr>
            <tr data-audio="/messages/d3d8766b6f989edbc6353853485c6976.mp3">
                <td>1</td>
                <td><time datetime="2023-05-06T06:17:40-04:00">2023/05/06  6:17 AM EDT</time></td>
                <td>1:01</td>
                <td>Yooooo, I LOVE you dude</td>
            </tr>
        </tbody></table>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A rudimentary simulation of the three-body problem (197 pts)]]></title>
            <link>https://github.com/achristmascarl/three_body</link>
            <guid>39909123</guid>
            <pubDate>Tue, 02 Apr 2024 18:23:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/achristmascarl/three_body">https://github.com/achristmascarl/three_body</a>, See on <a href="https://news.ycombinator.com/item?id=39909123">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">â¨ three_body</h2><a id="user-content--three_body" aria-label="Permalink: â¨ three_body" href="#-three_body"></a></p>
<p dir="auto">a very rudimentary simulation of the three-body problem. i was curious how far we could get with just euler's method and a small time step, and it turns out we can get something pretty visually interesting!</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/achristmascarl/three_body/blob/main/three_body.gif"><img src="https://github.com/achristmascarl/three_body/raw/main/three_body.gif" alt="three body problem gif" data-animated-image=""></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/achristmascarl/three_body/blob/main/three_body.png"><img src="https://github.com/achristmascarl/three_body/raw/main/three_body.png" alt="three body problem image"></a></p>
<p dir="auto">i was also curious about what would happen if the polar coordinates of the bodies over time were translated into rgb values and animated; the results are below.</p>
<p dir="auto"><strong>warning</strong>: some of the transitions from this orbit are pretty abrupt, so there may be flashing colors.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/achristmascarl/three_body/blob/main/color.gif"><img src="https://github.com/achristmascarl/three_body/raw/main/color.gif" alt="three body problem color gif" data-animated-image=""></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">sources</h2><a id="user-content-sources" aria-label="Permalink: sources" href="#sources"></a></p>
<p dir="auto">the starting positions for the graphics above are for periodic orbit F<sub>10</sub> from this paper: <a href="https://arxiv.org/abs/1805.07980" rel="nofollow">https://arxiv.org/abs/1805.07980</a></p>
<p dir="auto">This is what F<sub>10</sub> looks like when solved with ODE solver dop853 (according to the paper):</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/achristmascarl/three_body/blob/main/paper_f10.png"><img src="https://github.com/achristmascarl/three_body/raw/main/paper_f10.png" width="450px" alt="F10 from the paper"></a></p>
<p dir="auto">as you can see, although the overall shape is similar/recognizeable, the error in the calculations above grow fairly noticeable after just 2 periods.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Study uses wearables to show that physical activity lengthens REM latency (144 pts)]]></title>
            <link>https://news.utexas.edu/2024/04/01/move-more-sleep-better-ut-study-finds/</link>
            <guid>39908798</guid>
            <pubDate>Tue, 02 Apr 2024 17:58:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://news.utexas.edu/2024/04/01/move-more-sleep-better-ut-study-finds/">https://news.utexas.edu/2024/04/01/move-more-sleep-better-ut-study-finds/</a>, See on <a href="https://news.ycombinator.com/item?id=39908798">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
              <p>AUSTIN, Texas â A new study by an interdisciplinary team of researchers at The University of Texas at Austin provides the most reliable validation to date of the connection between physical activity, sleep quality and psychological health.</p>
<p>The study found that physical activity lengthened REM latency â that is, the time it takes to enter the REM stage. This may indicate that exercise helps consolidate deeper sleep stages before transitioning into REM sleep, which is when we tend to have vivid dreams and our brains seem to be as active as they are when weâre awake.</p>
<p>Scientific studies backed by anecdotal evidence already testify to the fact that when we exercise regularly, we sleep better. And, when we sleep better, we feel better. Although there is ample scientific evidence to support this, until now the studies have been conducted in lab settings, with conclusions drawn from observing experiences after just one nightâs sleep.&nbsp;Such limited methodologies are problematic for any scientific study, regardless of how widely accepted the findings may be.</p>
<p>The <a href="https://www.nature.com/articles/s41598-024-56332-7">study</a>, published in Nature Scientific Reports<em>, </em>investigated how daily physical activity patterns affect sleep stages and emotional well-being in a natural environment â at home, at work and during daily activities â over several months.</p>
<p>The research team used advanced wearable technology to track sleep and activity levels in 82 young adults. A wrist-worn activity tracker recorded both movement and heart rate. From those signals, periods of deep (NREM) sleep&nbsp;and REM sleep, along with physical activity, could be determined. A separate smartphone app was used to collect self-reported well-being data.</p>
<p>The study emerged from a pilot study conducted as part of <a href="https://bridgingbarriers.utexas.edu/whole-communities-whole-health">Whole CommunitiesâWhole Health</a>, a grand challenge research program that takes an interdisciplinary approach to how health care data are collected while also engaging communities and participants in the research process. This more wide-reaching study successfully replicated many of the findings previously conducted in sleep labs: namely, that engaging in both low-intensity and moderate-to-vigorous physical activity was linked to deeper, more restorative sleep, and that better sleep was in turn associated with more energy and less stress the following morning.</p>
<p>The key difference this time was the researchersâ innovative use of wearable technology, which allowed for continuous monitoring of participantsâ behaviors, providing a comprehensive picture of daily activities and their impact on sleep and mood over multiple weeks, even months.</p>
<p>âYou can learn a lot from lab studies, but obviously there are limitations to studying the sleep patterns of individual participants in just one night,â said <a href="https://liberalarts.utexas.edu/psychology/faculty/bsb57">Benjamin Baird</a>, a research assistant professor of psychology and one of the authors of the study. âItâs an unfamiliar, clinical-type setting, which can be stressful. And you canât really look over time, either. So, there are always questions about generalizability from that kind of design.â</p>
<p>Baird said that researchers were able to address for the first time how these differences in sleep architecture are associated with peopleâs perceived well-being. Sleep architecture refers to the structure of each 90- to 120-minute-long sleep cycle: the three stages of non-REM sleep (light, deep and deepest NREM sleep) and REM sleep, which makes up the final 25% or so of each cycle.</p>
<p>âWeâve shown using a standard Fitbit that anyone could wear â not even an expensive scientific device â that it is actually sensitive to these sorts of sleep architecture measures, and in a way thatâs showing predictive results,â said <a href="https://liberalarts.utexas.edu/psychology/faculty/dms2529">David M. Schnyer</a>, a co-author and chair of the Department of Psychology. âThe world is your oyster now. You can use this device to study all manner of different sleep architecture data related to lifestyle â related to mood and mood disorders â in the field, not in a lab, that people might have thought was not possible previously.â</p>

            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Amazon Ditches 'Just Walk Out' Checkouts at Its Grocery Stores (459 pts)]]></title>
            <link>https://gizmodo.com/amazon-reportedly-ditches-just-walk-out-grocery-stores-1851381116</link>
            <guid>39908579</guid>
            <pubDate>Tue, 02 Apr 2024 17:39:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gizmodo.com/amazon-reportedly-ditches-just-walk-out-grocery-stores-1851381116">https://gizmodo.com/amazon-reportedly-ditches-just-walk-out-grocery-stores-1851381116</a>, See on <a href="https://news.ycombinator.com/item?id=39908579">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Amazon is phasing out its <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;Internal link&quot;,&quot;https://gizmodo.com/amazon-tests-grocery-store-with-no-checkout-1789683651&quot;,{&quot;metric25&quot;:1}]]" href="https://gizmodo.com/amazon-tests-grocery-store-with-no-checkout-1789683651">checkout-less grocery stores</a></span> with âJust Walk Outâ technology, first reported by <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.theinformation.com/articles/amazons-grocery-stores-to-drop-just-walk-out-checkout-tech?rc=5xvgzc&quot;,{&quot;metric25&quot;:1}]]" href="https://www.theinformation.com/articles/amazons-grocery-stores-to-drop-just-walk-out-checkout-tech?rc=5xvgzc" target="_blank" rel="noopener noreferrer">The Information</a></span> Tuesday. The companyâs senior vice president of grocery stores says theyâre moving away from Just Walk Out, which relied on cameras and sensors to track what people were leaving the store with.</p><div data-video-id="195188" data-monetizable="true" data-position="sidebar" data-video-title="Top 5 Shopping Tips for Amazon Prime Day" data-video-blog-id="4" data-video-network="gizmodo" data-video-duration="296" data-playlist="195188,191746,191426" data-current="195188"><div><p>Top 5 Shopping Tips for Amazon Prime Day</p></div><video disablepictureinpicture="" muted="" playsinline="" width="100%" height="100%" crossorigin="anonymous" preload="none"><source data-src="https://vid.kinja.com/prod/195188/195188_240p.mp4" label="240p" type="video/mp4"><source data-src="https://vid.kinja.com/prod/195188/195188_480p.mp4" label="480p" type="video/mp4"><source data-src="https://vid.kinja.com/prod/195188/195188_720p.mp4" label="720p" type="video/mp4"><source data-src="https://vid.kinja.com/prod/195188/195188_1080p.mp4" label="1080p" type="video/mp4"><track kind="captions" label="English" src="https://kinja.com/api/videoupload/caption/20646.vtt" srclang="en"></video><div><ul><li data-label="">Off</li><li data-label="English">English</li></ul></div></div><p>Just over half of Amazon Fresh stores are equipped with Just Walk Out. The technology allows customers to skip checkout altogether by scanning a QR code when they enter the store. Though it seemed completely automated, Just Walk Out relied on more than <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.theinformation.com/articles/how-amazons-big-bet-on-just-walk-out-stumbled?rc=5xvgzc&quot;,{&quot;metric25&quot;:1}]]" href="https://www.theinformation.com/articles/how-amazons-big-bet-on-just-walk-out-stumbled?rc=5xvgzc" target="_blank" rel="noopener noreferrer">1,000 people in India watching and labeling videos</a></span> to ensure accurate checkouts. The cashiers were simply moved off-site, and they watched you as you shopped.</p><p>Instead, Amazon is moving towards <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;Internal link&quot;,&quot;https://gizmodo.com/amazons-next-big-bet-on-cashless-shopping-is-a-smart-gr-1844377270&quot;,{&quot;metric25&quot;:1}]]" href="https://gizmodo.com/amazons-next-big-bet-on-cashless-shopping-is-a-smart-gr-1844377270">Dash Carts</a></span>, a scanner and screen thatâs embedded in your shopping cart, allowing you to checkout as you shop. These offer a more reliable solution than Just Walk Out. Amazon Fresh stores will also feature self check out counters from now on, for people who arenât Amazon members.</p><p>âWeâre rolling out Amazon Dash Cart, our smart-shopping carts,â said an Amazon spokesperson to Gizmodo. Amazon confirmed this feature is replacing its Just Walk Out technology in existing stores. <br></p><p>Just Walk Out was first <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;Internal link&quot;,&quot;https://gizmodo.com/amazon-tests-grocery-store-with-no-checkout-1789683651&quot;,{&quot;metric25&quot;:1}]]" href="https://gizmodo.com/amazon-tests-grocery-store-with-no-checkout-1789683651">introduced in 2016</a></span>, presenting Amazonâs biggest and boldest innovation in grocery shopping. The technology seemed incredible, but there were some stumbles. It often took hours for customers to receive receipts after leaving the store, largely because offshore cashiers were rewatching videos and assigning items to different customers. The system of scanners and video cameras in each store is also incredibly expensive.</p><p>According to The Information, <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.theinformation.com/articles/how-amazons-big-bet-on-just-walk-out-stumbled?rc=5xvgzc&quot;,{&quot;metric25&quot;:1}]]" href="https://www.theinformation.com/articles/how-amazons-big-bet-on-just-walk-out-stumbled?rc=5xvgzc" target="_blank" rel="noopener noreferrer">700 out of 1,000 Just Walk Out sales required human reviewers as of 2022</a></span>. This widely missed Amazonâs internal goals of reaching less than 50 reviews per 1,000 sales. Amazon called this characterization inaccurate, and disputes how many purchases require reviews.</p><p>âThe primary role of our Machine Learning data associates is to annotate video images, which is necessary for continuously improving the underlying machine learning model powering,â said an Amazon spokesperson to Gizmodo. However, the spokesperson acknowledged these associates validate âa small minorityâ of shopping visits when AI canât determine a purchase. </p><p>Amazon Fresh, the e-commerce giantâs grocery store first launched in 2007, has just over 40 locations around the United States. The company also owns Whole Foods, and many of Amazon Freshâs experiments are seen as precursors for the large chain.</p><p>The company is reportedly keeping Just Walk Out technology in a small number of Fresh stores in the United Kingdom, and some of its Amazon Go convenience stores. Amazon has also implemented Just Walk Out technology at <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;Internal link&quot;,&quot;https://gizmodo.com/amazon-walk-out-houston-astros-cheaters-payment-ballpar-1848794315&quot;,{&quot;metric25&quot;:1}]]" href="https://gizmodo.com/amazon-walk-out-houston-astros-cheaters-payment-ballpar-1848794315">several ballparks </a></span>around the country. These locations will keep the technology going.</p><p>Amazon is trying to further break into the grocery space to grow into another billion-dollar market. Though it owns Whole Foods, the e-commerce giant still doesnât compete with food goliaths like Walmart, Costco, and Kroger. Amazonâs push away from expensive tests like Just Walk Out may be a sign the company is looking to further expand its presence as a supermarket.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Everything I know about SSDs (2019) (185 pts)]]></title>
            <link>https://kcall.co.uk/ssd/index.html</link>
            <guid>39908146</guid>
            <pubDate>Tue, 02 Apr 2024 17:06:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://kcall.co.uk/ssd/index.html">https://kcall.co.uk/ssd/index.html</a>, See on <a href="https://news.ycombinator.com/item?id=39908146">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>

<div>
<p><span size="+1"><b>March 2019:</b></span>

</p><p><span size="+1"><b>Introduction:</b></span>

</p><p>I started writing this rather long page for my own benefit, when I acquired a upgrade from my old 2006 Win 8 250 gb HDD PC to a Dell Optiflex 3010 with a 128 gb SSD. I never used more than 30 or 40 gb of the system drive, and I'm not a gamer or an avid film or music collector either. Not on a PC anyway. As I played with my new kit the further I went I realised that I knew very little about NAND flash in SSDs, just how SSDs work, how do they read and write and store data, and what sort of trickery do they employ? I can visualise an HDD, writing tiny magnetic patterns on a rotating surface, but SSDs are different, vastly different.

</p><p>There's also quite a few misconceptions about SSDs which seem persistent, and it would be nice to examine them if not perhaps quash a few of them. Perhaps I was guilty of harbouring quite a few misconceptions myself. However it started, this article grew into, shall we say, a mid-level technical discussion. If all you need to know is that SSDs are quiet, reliable, fast, and will work for years, then there's no need to read any further. If however, you think that knowing how to read a 3D TLC NAND flash cell is interesting, then you have little option but to plough on.

</p><p>As much of the detailed information as possible has been sourced from corporate and private technical articles, with quite a lot from Seagate and WD, and the wonderfully named Flash Memory Summit. Some of the conclusions I've made are from just trying to apply what logic I can along with common sense. Such is the complexity of NAND flash controllers, the variance in their methods of operation, and the speed of their development, that trying to comprehend let alone keep up with them is difficult to say the least. I can't say whether what I've written isn't confusing or is even true, but it's more of a guide than a bible. There'll be some repetition too. And it will soon be out of date. 

</p><p>I am obliged to those I have borrowed from, and will also be obliged to those who point out any errors without any reward apart from that of contribution. I've tried to explain what is different with SSDs, and why it is so hard to grasp with our ingrained HDD minds.

</p><p>The first misconception might be the plural of SSD: gramatically it should be, so I'm told, SSDs, but SSD's is almost as commonplace. Here I will stick to one SSD, many SSDs.

</p><p><b>Software and hardware:</b>

</p><p>This article was written in 2019 onwards and deals almost exclusively with NAND flash in the form of pc or laptop storage devices we know as SSDs. I shan't complicate things even more by referring to the ubiquitous flash drive or other NAND flash devices. If significant differences exist I shall try to note them as and when that occurs, but the default is the internal drive. Nowhere here is there anything about flash storage in phones, etc.

</p><p>Most of the detail was produced whilst my PC was running Windows 10 Home, with a fairly modest internal 2.5" WD Green 120 gb SSD. This uses a Silicon Motion SM2258XT controller and four 32 GiB SanDisk 05497 032G 15nm 3D TLC memory chips with an inbuilt SLC cache of unknown capacity. As this article tries to discuss the behaviour of SSDs as a whole it shouldn't matter what host operating or file system is used, but in my case it's Windows and NTFS. Nothing here is specific to a particular brand or type of SSD, it should all be generic. We're really dealing with the principles of SSD operation.

</p><p>The only additional software applications I have used are Piriform's excellent Recuva, which can list both live and deleted files and their cluster allocations, and HexDen (HxD), a very usable and capable hex editor. Recuva is free from www.piriform.com, and HexDen is also free from www.mh-nexus.de. I use the portable versions of both pieces of software.

</p><p>All the conclusions and opinions here are entirely my own work, and any data taken from my own pc. It would be wise to verify, or at least agree with my reasoning, before accepting these words as the truth. Much of this is a simplified explanation of a very complex subject.

</p><p><b>SSD Physical Internals:</b>

</p><p>Poking inside an SSD is something of a disappointment, a small pc board with a few NAND flash chips and a controller chip, lightweight and a little flimsy. As for the software inside the controller, I can only summarise the basic tasks. It seems commonplace that controllers are bought in from external manufacturers, as indeed are the memory chips. SSD controller software is proprietary, very complex and highly guarded, but all controllers have to do basic tasks, even if we don't quite know how. Only those tasks can be discussed here, the very clever tweaks and tricks will have to remain known only to the manufacturer. I'll start with a little groundwork.

</p><p><b>NAND Flash:</b>

</p><p>I wasn't going to delve into the internals of NAND flash, there are enough frankly bemusing articles on Wikipedia for all that. All you really need to know is that NAND (NOT-AND) flash memory stores information in arrays of cells made from floating-gate transistors. The floating gate can either have no charge of electrons, and be in an 'empty' logical state, or be charged with electrons at various voltage thresholds and be in a logical state which represents a value. NAND flash is non-volatile and retains its state even when the SSD is not powered up. Oh yes, it's called flash because a large chunk of cells can be erased (flashed) at a time.

</p><p>But if you want to know more, go ahead. Here the term cell and transistor refer to the same physical entity and are used interchangeably, and I won't keep saying NAND all the time.

</p><p>Flash memory comprises multiple two-dimensional arrays of transistors, and supports three basic operations, read, program (write) and erase. Apart from the flash arrays, the flash chip includes command and status registers, a control unit, decoders, analogue circuits, buffers, and address and data buses. A separate chip holding the SSD controller sends read, program, or erase commands to the flash chip. In a read operation the controller passes the physical address to the flash chip which locates the data and sends it back to the controller. in a program operation the data and physical address are passed to the chip. In an erase operation, only the physical address is passed to the chip.

</p><p>The ï¬ash chip's latches store data transferred to and from the flash arrays, and the sense ampliï¬ers detect bit line voltages during read operations. The controller monitors the command sent to the chip using the status register. The controller also includes Error Checking and Correction (EEC) algorithms to manage error and reliability issues in the chip and to ensure that correct data is read or written.

</p><p>Each row of an array is connected by a Word line, and each column by a Bit line. At the intersection of a row and column is a Floating Gate Transistor, or cell, where the logical data is stored. Word lines are connected to the transistors in parallel, and bit lines in series. The ends of the bit lines are connected to sense amplifiers.

</p><p>Flash arrays are partitioned into blocks, and blocks are divided into pages. Within a block the cells connected to each word line constitute a page. The cells connected to the bit lines give the number of pages in a block. Common page sizes are 4k, 8k or 16k, with 128 to 256 pages making a block size between 512k and 4mb. A page is the smallest granularity of data that can be addressed by the chip control unit.

</p><p>Read or program operations involve the chip controller selecting the relevant block using the block decoder, then selecting a page in the block using the page decoder. The chip controller is also responsible for activating the correct analogue circuitry to generate the voltages needed for program and erase operations.

</p><p>Although the number of cells in each row is nominally equivalent to the page size, the actual number of cells in each row is higher than the stated capacity of each page. This is because each page contains a set of spare cells as well as data cells. The spare cells store the ECC bits for that page as well as the physical to logical address mapping for the page. The controller may also save additional metadata information about the page in the spare area. During a read operation, the entire page (including the bits in the spare area) is transmitted to the controller. The ECC logic in the controller checks and correct the read data. During a program operation the controller transmits both the user data and the ECC bits to the flash memory.

</p><p>Upon system boot the controller scans the spare area of each page in the entire flash array to load the logical to physical address mapping into its own memory (there may be other techiques for holding mapping data in the controller). The controller holds the logical to physical address mapping in the Flash Translation Layer (FTL). The FTL also performs garbage collection to clear invalid pages following writes, and performs wear-leveling to ensure that all the ï¬ash blocks are used, evenly.

</p><p>Since flash does not support in-place updates, a page needs to be erased before its contents can be programmed; but unlike a program or a read operation which work at a page granularity, the erase operation is performed at a block granularity.

</p><p><b>2D and 3D, and Layers:</b>

</p><p>In flash architecture a block of planar flash, a two-dimensional array of cells, is rather unsurprisingly called 2D flash. If one (or more) array is stacked on top of each other then it's 3D flash. 3D NAND flash is built on one chip, up to 32 layers, and was devised to drive costs down when planar flash reached its scaling limit: 3D flash costs little more than 2D to produce, but multiplies the storage capacity immensely. In both 2D and 3D the cells in each page (the rows) are connected by Word Lines, and the cells at each offset within a page (the columns) are connected with a Bit Line (to put it very simply).

</p><p>3D flash is not the same as layered flash, where separate very thin chips are arranged in a stack. This is prohibitively expensive. Most modern consumer SSDs (in the 2010's) use 3D TLC flash.

</p><p><b>Can I see one?</b>

</p><p>The cell size on end-user flash is minute, with 15nm being common, and ranges from 43nm down to 12nm. Actually cell size, or cell diameter, is misleading, as the stated size is not a measurement of any dimension of a cell but a measure of the distance between discrete components on the chip. The silicon layers on the chip are approximately 0.5 to 3nm thick: by comparison a hydrogen atom is 0.1nm in diameter, and the silicon atoms used in chip manufacture 0.2nm. A nanometre (nm) is indeed exceedingly small, a billionth of a metre, and as an analogy if one mn were the size of a standard marble (about 13mm) then one metre would be the size of the earth. The power of a billion is impressive.

</p><p><b>SLC, MLC, TLC, QLC and Beyond:</b>

</p><p>A Single-Level Cell (SLC) has one threshold of electron charge to indicate the state of one bit, one or zero. A Multi-Level Cell (MLC) holds a voltage denoting the state of two bits, with three different thresholds representing 11, 10, 00 and 01. A Triple-Level Cell (TLC) holds the state of three bits, 111, 110, 100, 101, 001, 000, 010, and 011. The 15 thresholds used in Quad-level cells (QLC) can be deduced if anyone is at all interested. (I have seen other variations of what these threshold values represent in bit terms.)

</p><p>Unfortunately when the double level cell was developed it was called a multi-level cell and given the acronym MLC, thus forcing everyone to type out multi-level cell laboriously when they want to refer to multiple level cells. If only it had been called a double-level cell we could use DLC, TLC, and QLC freely and use MLC to describe the lot, but it's too late for that now. If only flash had stopped at SLC, with its yes/no one/zero state, these explanations would be far easier to write, and hopefully far easier to grasp.

</p><p>With multi-level cells physical NAND pages represent two or more logical pages. The two bits belonging to a MLC are separately mapped to two logical pages. Odd numbered pages (including zero) are mapped to the least significant (RH) bit, and even numbered pages are mapped to the most significant (LH) bit. Similarly, the three bits belonging to a TLC are separately mapped to three logical pages, and a QLC is mapped to four logical pages (The page numbering for TLC and QLC is unknown).

</p><p>The more bits a multi-level cell has to support affects the cell's performance. With SLC the controller only has to check if one threshold has been exceeded. With MLC the cell can have four values, with TLC eight, and QLC 16. Reading the correct value of the cell requires the SSD controller to use precise voltages and multiple reads to ascertain the charge in the cell. It's also apparent that if a single physical page supports multiple logical pages then that page will be read and written more frequently than a SLC page, with consequent affect on its life expectancy. Furthermore it would seem self-evident that a TLC SSD would need only a third of the physical cells required in an SLC device, so my 120 gb TLC SSD would actually hold only 40 gb of NAND cells. 

</p><p>High-use enterprise SSDs used to be the province of the SLC, with it's greater speed, endurance, reliability and read/write capabilities, MLC and TLC are gaining acceptance for enterprise use. The end-user consumer SSD market gets the cheaper higher capacity but slower and more fragile multiple level cells.

</p><p><b>Why is Nothing One?</b>

</p><p>Anyone still following this may have noticed a common factor in both single and multi-level cells, in that an empty cell - where the floating gate has no charge - represents one. Unlike HDDs, where any bit pattern can be written anywhere, a default logical state of ones is present on an empty SSD page. This is because there is only one programming function on the cells, to move electrons across the floating gate. NAND flash cells can only be programmed to a state of zero, there is no ability to program a one. With multi-level calls the default is still one across all pages, but a logical one can be represented even after the cell has been programmed and there are electrons present across the gate.

</p><p>Ever since Fibonacci introduced the Hindu-Arabic numeral system with its concept of zero into European mathematics in 1202, the human mind associates zero with empty and one with full. To be empty and represent one is rather perplexing, and appears to be mainly from convention (an empty state <i>could</i> represent zero but would required inverters on the data lines). Possibly the circuitry is less complex, and possibly the ability of an empty cell to conduct a charge implies that it is a one.

</p><p><b>They're all SLC anyway:</b>

</p><p>After all this it's perhaps worth emphasising that NAND flash, whatever its intended use, is all physically SLC. If you could look into a TLC cell you wouldn't see 101, or 011, or whatever. There can only ever be one quantity of electrons in a cell, no matter how that quantity is interpreted. The SSD controller knows whether the cells are to be treated as SLC, MLC etc and programs them accordingly, measures the electron count, and determines what logical value it represents. But even quad cells can only contain one value, just as do SLC cells. 

</p><p><b>The Myths and Misconceptions:</b>

</p><p>And now we come to the myths, misconceptions and the real reason for writing this article, what happens when an SSD page is read, written and rewritten, and how does this affect deleted file recovery? On one hand we have NTFS, designed specifically for HDDs way before SSDs became easily available, NAND flash with its own unique way of operating, and several billion humans with years of ingrained HDD use and expectations. And here, if I haven't already, I shall use SSD interchangeably if incorrectly for NAND flash.

</p><p><b>Storage Device Controllers:</b>

</p><p>All HDDs, SSDs and flash drives have an internal controller. It's the way that the storage device can be, in the words of Microsoft, abstracted from the host. That abstraction is done by logical block addressing, where each cluster capable of being addressed on the storage device is known to the host by an ascending number (the LBA). The storage device controller maps that number to the sectors or pages on the device. To the host this mapping is constant - a cluster remains mapped to the same LBA until the host changes it. On an HDD this relationship is physical and fixed: in its simplist deconstruction an HDD controller just reads and writes whatever sectors the host asks it to. It doesn't have to think about what was there before, it just does what it's told and writes new data on top of the old. It does that because it can, there's nothing preventing a new cluster being written directly on top of the same sectors of an old one. On an SSD it's different.

</p><p>With an SSD the host still uses the LBA addressing system with the constant reconciliation between LBA and cluster number. It knows that the device is a SSD and has a few tricks to accommodate this, but they will come later. The SSD controller however has many tricks to reconcile the host's file system, written for HDDs, with the demands of NAND flash.

</p><p><b>Flash Translation Layer:</b>

</p><p>The host still uses LBA addressing to address the SSD for read and writes, as it knows no other. These commands are intercepted by the Flash Translation Layer on the SSD controller. The FTL maintains a map of LBAs to physical block addresses, and and passes the translated PBA to the controller. This map is required because unlike an HDD the LBA to PBA relationship is volatile. It's volatile because of the way data is written to NAND flash.

</p><p>An empty page, with all cells uncharged, contains by default all ones. If a hex editor is used to look at an SSD's empty sectors however, it will be presented with clusters of zeroes. This is because empty pages are not allocated to the LBA/PBA mapping table. Instead, if a read request is issued for an empty page a default page of zeroes is returned. This applies to both unallocated clusters and those which are part of a file: the SSD does not allocate a page and change all its cells from ones to zeroes.

</p><p><b>Floating Gate Transistors:</b>

</p><p>This section might be helpful before plunging into reads and writes, and here cell and (FG)transistor become interchangable (a cell is a transistor). For more, much more, about floating gate MOSFET (Metal-Oxide-Semiconductor Field-Effect Transistors) there is always Wikipedia.

</p><p>A FGMOS transistor has three terminals, gate, drain, and source. When a voltage is applied to the gate a current can flow from the source to the drain. Low voltages applied to the gate cause the voltage flowing from source to drain to vary proportionally to the gate voltage. At a higher voltage the proportional response stops and the gate closes regardless.

</p><p>The charge in the floating gate alters the voltage threshold of the transistor, i.e. at what point the gate will close. When the gate voltage is above a certain value, around 0.5 V, the gate will always close. When the voltage is below this value, the closing of the gate is determined by the floating gate voltage.

</p><p>If the floating gate has no charge then a low voltage applied to the gate closes the gate and allows current to flow from source to drain. If the floating gate has a charge then a higher voltage needs to be applied to the gate for it to close and current to flow. The charge in the floating gate changes how much voltage must be applied to the gate in order for it to close and conduct.

</p><p><b>SSD Reads:</b>

</p><p>There's nothing inherent in the design of NAND flash that prevents reading and writing to and from individual cells. However in line with NAND flash's design goal to be simple and small the standard commands that NAND chips accept are structured such that a page is the smallest addressable unit. This eliminates space that would be needed to hold additional instructions and cell-to-page maps.

</p><p>To read a single page, and the cells within it, the page needs to be isolated from the other pages within the block. To do this the pages not being read are temporarily disabled.

</p><p>All cells/transistors in the same block row (a page) are connected in parallel with a Word Line to the transistors' gates. All transistors in the same block column (cell offset) are chained in series with a Bit Line connecting the drain of one to the source of the next. At the end of each bit line is a sense amplifier. When a read takes place a pass-through voltage is applied to all word lines except the page being read. The pass-through voltage is close to or higher than the highest possible threshold voltage and forces the transistors <i>in all pages not being read</i> to close whether they have a stored charge or not. All bit lines are energised with a low current.

</p><p>The word line for the page being read is given a reference voltage, and all the bit line sense amplifiers read. Transistors holding a high enough electron count will not be closed by the reference voltage, and the bit line current will not pass through the source/drain chain to the sense amplifier. Transistors with no charge, or a charge below the threshold, will be closed by the reference voltage and conduct the bit line current to the sense amplifier. Several reads at varying threshold voltages are required to determine the logical state of a multi-level cell.

</p><p>(To add, or avoid, more confusion a floating gate transistor can be either open or closed. An open gate does not conduct an electrical charge, and a closed gate does. So if the gate is open nothing can get through, and if it's closed it can. No wonder we're confused.)

</p><p>It can be seen from this that to read one page in a block requires that all transistors in every page in the block receive either a pass-through or one or more reference voltages. It also appears that this will still apply even if some or all of the other pages in the block are empty. This becomes significant in Read Disturbance below.

</p><p><b>Interpreting the results:</b>

</p><p>It is quite easy to grasp the concept behind reading an SLC. Only one threshold applies to SLC flash so only one test voltage is required - the floating gate either will or will not close. if the threshold voltage closes the gate then the bit line current passes to the sense amplifier and the stored value is one. If it doesn't then it's zero.

</p><p>Multi-level cells are different, and the reasoning behind the stored value bit order becomes apparent. In a MLC the possible user bit combinations are 11, 10, 00 and 01, separated by three threshold values. To read the most significant (l/h) bit only requires one read, of the middle threshold voltage. If the gate closes then the MSB is one, if it doesn't then the MSB is zero, no matter what is in the least significant bit. To read the LSB (r/h) two reads are required, one of threshold one, and one of threshold three. If the read of threshold one closes the gate then the LSB is set to one and read two is not required. If the gate opens then a read of threshold three is taken. If it closes the LSB is set to zero. If it doesn't then the value is one.

</p><p>The bit combinations in TLC cells are 111, 110, 100, 101, 001, 000, 010, and 011, separated by seven threshold values, and are more tricky to grasp. The MSB bit again only requires one read of the middle threshold, as in MLC. The central bit requires two reads, at threshold two and six, and the LSB requires four reads, at thresholds one, three, five and seven.

</p><p>All multi-cell pages based on the MSB (l/h) are treated as SLC, with only one read required to determine the user bit value.

</p><p><b>SSD Writes:</b>

</p><p>The most significant aspect of NAND flash, the widest fork in the HDD/SSD path, and the fundamental, pivotal factor in what follows, is that data can only be written to an empty SSD page. This is not new, nor is it in any way unknown, but it has the greatest implications for data security and recovery.

</p><p>While SSDs can read and write to individual pages, they cannot overwrite pages, as the voltages required to revert a zero to a one would damage adjacent cells. All writes and rewrites need an empty page. Unlike HDDs, where a compete cluster is written to the disk whatever was there previously, the act of writing an SSD page allocates an empty page with its default of all ones, and an electrical charge is applied to the cells that require changing to zeroes. This is as true for multi-level cells as it is for SLCs, as the no-charge all-ones pattern is either replaced with a charge representing another pattern, or is left alone. This is a once-only process.

</p><p>When a write request is issued an empty page is allocated, usually within the same block, and the data written. The LBA/PBA map in the FTL is updated to allocate the new page to the relevant LBA. The LBA will always remain the same to the host: no matter which page is allocated the host will never know. This is the same process if the user data is being rewritten or if it is a new file allocation: the only difference is that the rewrite will have slightly more work to do. The old page will be flagged as invalid and will be inacessible to the host, but will still take up space within its block as it cannot be reused.

</p><p>Whilst it's easy to grasp writing to SLC pages, multi-level cell pages are more difficult to visualise. The controller accumulates new writes in the SSD cache until enough logical pages to fill a physical page are gathered, and then writes the physical page. This entails the fewest writes to the page. If a logical page in a multi-level page is amended it would require a new page to be allocated and all logical pages rewritten, as the individual values in the physical page can't be altered. If a logical page is deleted then I surmise that the deleted logical page is flagged as invalid, and when the block becomes a candidate for garbage collection any valid logical pages are consolidated before writing. In other words a multi-level page, or at least the majority of them, will always contain a full compliment of logical pages.

</p><p>It's apparent that if NAND flash handles data writes in this way - and it does - the SSD will eventually become full of valid and invalid pages, and performance will gradually slow to a crawl. Although an individual SSD page can't be erased a block can, and this method is used to return blocks to a writable state. To expedite this, and to ensure that a pool of empty blocks is always available for writes, the SSD controller uses Garbage Collection.

</p><p><b>Garbage Collection:</b>

</p><p>Garbage Collection is enabled on the humblest up to the highest capacity SSD: without it NAND flash would be unusable. Garbage Collection is part of the SSD controller and its work is unknown to the host. In its simplest form GC takes a block holding valid and invalid pages, copies the valid pages to a new empty block, updates the LBA mapping tables, and consigns the old block to the invalid block pool. There the block and its pages are reset to empty state, and the block added to the available block pool. Thus a pool of available blocks should always be available for write activity. As long as there is power to the SSD GC will do its work, it cannot be stopped. There are various sophisticated techniques for GC routines, all proprietary and mainly known only to the manufacturers.

</p><p>When an SSD arrives new from the factory writes will gradually fill the drive in a progressive, linear pattern until the addressable storage space has been entirely written. However once garbage collection begins, the method by which the data is written - sequential vs random - affects performance. Sequentially written data writes whole blocks, and when the data is replaced the whole block is marked as invalid. During garbage collection nothing needs to be moved to another block. This is the fastest possible garbage collection - i.e. no garbage to collect. When data is written randomly invalid pages are scattered throughout the SSD. When garbage collection acts on a block containing randomly written data, more data must be moved to a new block before the block can be erased.

</p><p><b>The Garbage Collection Conundrum:</b>

</p><p>Garbage Collection can either take place in the background, when the host is idle, or the foreground, as and when it is needed for a write. Whilst background GC may seem to be preferrable, it has drawbacks. If the host uses a power-saving mode when idle, GC will either wait for the device to restart with a consequent user delay for GC to complete, or wake the device up and reduce battery life whilst the host is 'idle'. Furthermore GC has no knowledge of the data it is collecting. Inevitably some data will be subject to GC and then be deleted shortly afterwards, incurring another bout of GC and consequent additional and unnecessary writes (write amplification, the ratio of actual writes to data writes). Foreground GC, seemingly the antithesis of performance, avoids the power-saving problems, only incurs writes when they are actually required, and with fast cache and highly developed GC algorithms presents no noticeable performance penalty to the user. The trend in modern GC appears to be foreground collection, or a combination of foreground and background collection.

</p><p>Based on foreground garbage collection, and that most user activity is random, then the inevitable conclusion is that the SSD will spend most of its life at full capacity, if by that we mean available blocks, even though the allocated space appears to the host to be low.

</p><p>However there is another potential problem with SSDs, and that is to do with a historical event: the way that file systems were designed.

</p><p><b>File Systems - What you see isn't what you get:</b>

</p><p>Host file systems were designed in the days when HDDs reigned supreme, simply because SSDs had yet to arrive in an available and affordable form. The file system does not take into account the needs of NAND flash. Files are constantly being updated: they get allocated, moved and deleted, and grow and shrink in size. The way the file system handles this is incompatible with the workings of NAND flash.

</p><p>It's worth emphasising that storage devices are abstracted from the host operating system. Whilst an array of folders and files are displayed by Explorer in a form wholly comprehensible to a human, it's all an illusion. What Explorer is showing is a logical construct created entirely from metadata held within the file system's tables. The storage device controller knows nothing about files or folders, or tables or operating systems: all an HDD or SDD sees are commands to read or write specific sectors, which it does faithfully. An SSD has one advantage over an HDD however, it knows that some pages hold data, and are mapped to an LBA, and some pages are empty, hold no valid data, and are not mapped to an LBA. Conversely an HDD does not need to know this, to an HDD all sectors are the same.

</p><p><b>File Deletion:</b>

</p><p>In NTFS, when a file is deleted the entry in the Master File Table is flagged as such, and the cluster bitmap is amended to flag the file's clusters as available for reuse. The delete process takes place entirely within the MFT and the cluster bitmap. This is perfectly adequate for an HDD, as NTFS can simply reuse the MFT entry and the clusters whenever it wishes. On an SSD the process from NTFS's point is exactly the same, as NTFS has no other way of deleting files. However all the SSD sees is exactly what an HDD would see, updates to a few pages. Neither an HDD nor an SSD knows that it's the MFT and cluster bit map being updated, as they have no knowledge of such things. As there is no activity on the deleted file's clusters, the SSD's pages holding the clusters remain mapped to their LBAs in the FTL. The SSD's FTL has no way of knowing that these pages are no longer allocated by NTFS: to the SSD the pages are still valid and will not be cleaned up by garbage collection.

</p><p>As these 'dead' pages are allocated to an LBA they could be released when files are allocated or extended and the host uses that LBA. In this case the page will be flagged as invalid and a new page used. However it is inevitable that eventually a significant amount of unused and unwanted baggage which is not flagged for garbage collection will be pointlessly maintained by the SSD controller and be unavailable for reuse. To overcome this, and to correlate the hosts view of allocated and unallocated pages with the SSD's, NTFS from Windows 7 onwards acquired the TRIM command.

</p><p><b>SSD Detection:</b>

</p><p>Although the storage device is abstracted from the File System, to enable some of the file system's SSD tweaks it needs to know whether the device is an HDD or SSD. There are various ways to do this, including querying the rotational speed of the device, which on an SSD should be zero (or perhaps one). This seems the most widely used and most proficient method.

</p><p><b>TRIM:</b>

</p><p>TRIM (it isn't an acronym) is a SATA command sent by the file system to the SSD controller to indicate that particular pages no longer contain live data, and are therfore candidates for garbage collection. TRIM is only supported in Windows on NTFS volumes. It is invoked on file deletion, partition deletion, and disk formatting. TRIM has to be supported by the SSD and enabled in NTFS to take effect. The command 'fsutil behavior query disabledeletenotify' returns 0 if TRIM is enabled in the operating system. It does not mean that the SSD supports it (or even if an SSD is actually installed) but all modern SSDs support a version of it.

</p><p>There are three different types of TRIM defined in the SATA protocol and implemented in SSD drives. Non-deterministic TRIM: where each read command after a TRIM may return different data; Deterministic TRIM (DRAT): where all read commands after a TRIM return the same data (i.e. become determinate) and do not change until new data is written; and Deterministic Read Zero after TRIM (DZAT): where all read commands after a TRIM return zeroes until the page is written with new data. By the way whilst DRAT returns data on a read it is not the userdata that was ptrviously there bafore the TRIM: it is random.

</p><p>Fortunately Non-Deterministic TRIM is rarely used, and Windows does not support DRAT, so a read of a trimmed page - which is easily done with a hex aditor - invokes DZAT and returns zeroes immediately after the TRIM command is issued. The physical pages may not have been cleaned immediately following the TRIM command, but the SSD controller knows that there is no valid data held at the trimmed page address.

</p><p>TRIM tells the FTL that the pages allocated to specific LBAs are to be classed as invalid. When a block no longer has any free pages, or a specific threshold is reached, the block is a candidate for garbage collection. Live data is copied to a new empty block, and the original block is erased and made available for reuse.

</p><p>TRIM is an asynchronous command that is queued for low-priority operation. It does not need or send a response. The size of the TRIM queue is limited and in times of high activity some TRIM commands may be dropped. There is no indication that this takes place, so some unwanted pages may escape garbage collection.

</p><p><b>RETRIM:</b>

</p><p>Windows Defragger - now called Storage Optimiser - has an option to Optimise SSDs. This does not defrag the SSD but sends a series of TRIM commands to all unallocated pages identified in NTFS's cluster bitmap. This global TRIM (or RETRIM) command is run at a granularity that the TRIM queue will never exceed its permitted size and no RETRIM commands will be dropped. A RETRIM is run automatically once a month by the storage optimiser.

</p><p><b>Over-provisioning:</b>

</p><p>All NAND flash devices use over-provisioning, additional capacity for extra write operations, controller firmware, failed block replacements, and other features utilised by the SSD controller. This capacity is not physically separate from the user capacity but is simply an amount of space in excess of that which can be allocated by the host. The specific pages within this excess space will vary dynamically as the SSD is used. According to Seagate, the minimum reserve is the difference between binary and decimal naming conventions. An SSD is marketed as a storage device and its capacity is measured in gigabytes (1,000,000,000 Bytes). NAND flash however is memory and is measured in gibibytes (1,073,741,824 bytes), making the minimum overprovisioning percentage just over 7.37%. Even if an SSD appears to the host to be full, it will still have 7.37% of available space with which to keep functioning and performing writes (although write performance will be diabolical). Manufacturers may further reduce the amount of capacity available to the user and set it aside as additional over-provisioning, in addition to the built-in 7.37%. Additional over-provisioning can also be created by the host by allocating a partition that does not use the drive's full capacity. The unallocated space will automatically be used by the controller as dynamic over-provisioning.

</p><p>My humble WD SSD has four 32 gb chips but a specified capacity of 120 gb, meaning that it has 8 gb set aside as additional over-provisioning. Add this to the 7.37% minimum (9.4 gb) and the 17.4 gb equates to almost 15% over-provisioning space.

</p><p><b>Wear Levelling:</b>

</p><p>Some files are written once and remain untouched for the rest of their life. Others have few updates, some very many. As a consequence some blocks will hardly ever see the invalid block pool and have a very low erase/write count, and some will be in the pool every few minutes and have a very heavy count. To spread the wear so that all blocks are subject to erase/writes equally, and the performance of the SSD is maintained over its life, wear levelling is used. Wear levelling uses algorithms to indentify blocks with the lowest erase count and move the contents to high erase count blocks; and to select low erase count blocks for new allocations. As with garbage collection, wear levelling is far more complex than I could possibly deduce, let alone explain.

</p><p><b>Read Disturbance:</b>

</p><p>SSD reads are not quite free, there is a price to pay. As described above, a read of one page generates a pass-through voltage on all other cells in the block. This voltage is likely to be below the highest threshold value that could be held by the cell, but it still generates a weak programming effect on the cells, which can unintentionally shift their threshold voltages. The pass-through voltage induces electric tunnelling that can shift the voltages of the unread cells to a higher value, disturbing the cell contents. As the size of flash cells is reduced the transistor oxide becomes thinner and in turn increases this tunnelling effect, with fewer read operations required to neighbouring pages for the unread flash cells to become disturbed, and move into a different logical state. Cells holding lower threshold values are more susceptible to read disturbance.

</p><p>Thus each read can cause the threshold voltages of other unread cells in the same block to shift to a higher value. After a significant amount of reads this can cause read errors for those cells. A read count is kept for each block and if it is exceeded the block is rewritten. The count is high for SLC cells, around 1m, lower for 25 nm MLC at around 40,000, and much lower for 15 nm TLC cells.

</p><p><b>File Recovery:</b>

</p><p>And now we come to deleted file recovery. NTFS goes through exactly the same process to delete a file on an SSD as it does on an HDD, with the exception of the additional TRIM command. And the TRIM command (assuming it's executed) and a few SSD quirks destroys any practicable chance of deleted file recovery.

</p><p>TRIM commands, as described above, have a complimentary setting within the SSD controller in the form of DRAT and DZAT. (I don't believe that non-deterministic TRIM is used in any reputable SSD, and I don't think that Windows supports DRAT, but I have no proof.) The implementation of DZAT means that immediately on successful execution of the TRIM command (which will in most cases be immediately on file deletion) any attempt to read the TRIMed page will return zeroes. The data on the page will still exist until the block is processed by the garbage collector, but that data is not accessible from the host by any practicable means, or any general software.

</p><p>Garbage collection is independent of the host device and will be invoked at the will of the SSD's controller. Once the process is started it cannot be stopped, apart from powering off the SSD. Once powered up again the garbage collector will resume its duties to completion.

</p><p>Deleted file recovery on a modern SSD is next to impossible for the end user, and under Windows as close to impossible as you can get. A theoretical examination of the chips would most likely show compressed and encrypted data, striped over multiple blocks, and no possibility of relating one page of data to another across the multiple millions of pages. There is a very small possibility of recovering recently deleted files by powering off the SSD immediately and sending it to a professional data recovery company. They may recover some data, given enough time and money.

</p><p>After a session of file deletion, such as running Piriform's CCleaner, run Recuva on the SSD. The headers of the deleted files found (and presumably the rest of the file) will all be zeroes. This is TRIM and DZAT doing their work in a few seconds, killing any chance of deleted file recovery. Of course TRIM can be disabled, at the cost of performance, but it's probably better to be a little less cavalier when deleting files that might be wanted later.

</p><p><b>Deletd File Security:</b>

</p><p>The notion of secure file deletion - overwriting a file's data before deletion - is irrelevant, and if any other pattern except zeroes is chosen is just additional and pointless wear on the SSD. Even overwriting with zeroes will cause transaction log and other files to be written, so secure file deletion on an SSD should never be used. Wiping Free Space is far worse for pointless writes, and is even more futile than secure file deletion. The deleted files just aren't there any more.

</p><p><b>The OCZ Myth:</b>

</p><p>Some years ago (as a little light relief to all these acres of text) the OCZ forums were buzzing with the latest method of regaining performance on their SSDs: run Piriform's CCleaner Wipe Free Space, with one overwrite pass of zeroes. Although performance may have been regained, logic, and common sense, went out of the window. The theory was that overwriting the pages with zeroes was equivalent to erasing blocks (this was before the days of TRIM). This was nonsense, and should have been apparent from the start. The default state of an empty page is all ones, not zeroes, and how could a piece of software possibly erase NAND flash?. The real reason was that as CCleaner was filling the pages with zeroes the SSD controller simply unmapped the pages and showed default pages of zeroes to the host. The invalid pages were then candidates for garbage collection, which gave a much greater pool of blocks to call upon on writes, and hence a better performance. A sort of RETRIM before that was invented.

</p><p><b>SSD Defragmentation:</b>

</p><p>One of the SSD mantras is that an SSD should never be defragged. Whilst there is little (there is a little) to be gained from rearranging clusters into adjacent pages - an SSD has no significant overhead in random reads - an SSD defrag is not entirely verboten. In fact from Windows 8 onwards the Storage Optimiser will defrag an SSD if certain conditions are met. If System Restore is enabled, the fragmentation level is above 10%, and at least one month has passed since the last defrag, Windows Storage Optimiser Scheduled Maintenance will defrag the SSD. This is what Microsoft calls a Traditional Defrag, it is not an Optimise (RETRIM). The defrag is required to reduce the extents on the volume snapshot files when system restore is enabled.

</p><p>There is nothing to be afraid of in a monthly defrag. Most users won't hit the 10% fragmented criteria so a simple RETRIM will be run, and Windows 10 users won't get defragged anyway (System Restore is disabled in Widows 10 by default). The reduction in life of an SSD will not be noticed. Furthermore, although SSDs are not fazed by random reads, files do get fragmented and that means a significant increase in I/Os. An occasional clearup is a boon.

</p><p><b>SSD Lifetime:</b>

There are many users worried about the life expectancy of their SSDs. Yes, continuous write/erase cycles, and the added and unseen write amplification, do take a toll on the life of NAND flash. Using an SSD does wear it out. My WD Green 120 gb SSD, a TLC SSD from a reputable manufacturer but at the very lowest cost, has an estimated life of 1 million+ hours and a write limit if 40 terabytes. One million hours is 114 years, so we can forget that. As for writes, at 1 gb a day - far more than my current rate of data use - it would take the same 114 years to reach 40 tb. Even with massive write overhead this SSD is not going to wear out in the forseeable future. If all 128 gib of available flash is used equally, the 40 tb equates to 312 writes per cell, a very conservative number.

</p><p><b>The End:</b>

</p><p>The only thing to add is that NAND flash, SSDs, and especially SSD controllers, are far more sophisticated, complex and incomprehensible than what has been written here, what I know, what I could possibly comprehend, and what I could possibly explain. I should also add secret, as their software is proprietary. Whilst an HDD is a marvel of complex electro-mechanical engineering at a ridiculously low cost, the SSD is an equally marvellous and complex piece of electronics and software at a minimally higher cost. We should be thankful for both.

</p><p>You can return to my home page <a href="http://kcall.co.uk/" target="_top"><i>here</i></a>

</p><p>If you have any questions, comments or criticisms at all then I'd be pleased to hear them: please email me at kes at kcall dot co dot uk.

</p><p><span size="2" color="maroon">Â© Webmaster. All rights reserved. 

</span></p></div>



</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[CityGaussian: Real-time high-quality large-scale scene rendering with Gaussians (443 pts)]]></title>
            <link>https://dekuliutesla.github.io/citygs/</link>
            <guid>39907876</guid>
            <pubDate>Tue, 02 Apr 2024 16:46:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dekuliutesla.github.io/citygs/">https://dekuliutesla.github.io/citygs/</a>, See on <a href="https://news.ycombinator.com/item?id=39907876">Hacker News</a></p>
<div id="readability-page-1" class="page">


<div>
          
          <p>
            <span>
              He Guan<sup>1,2</sup>,</span>
            <span>
              Chuanchen Luo<sup>1</sup>,
            </span>
            <span>
              Lue Fan<sup>1,2</sup>,
            </span>
            <span>
              Junran Peng<sup>1</sup>,
            </span>
            <span>
              Zhaoxiang Zhang<sup>1,2,3,4</sup>,
            </span>
          </p>

          <p><span><sup>1</sup>Institute of Automation, Chinese Academy of Sciences</span>
            <span><sup>2</sup>University of Chinese Academy of Sciences (UCAS)</span>
            <span><sup>3</sup>Centre for Artificial Intelligence and Robotics (HKISI, CAS)</span>
            <span><sup>4</sup>State Key Laboratory of Multimodal Artificial Intelligence Systems (MAIS)</span>
          </p>

          
        </div>




<div>
        <h2>Abstract</h2>
        <p>
            The advancement of real-time 3D scene reconstruction and novel view synthesis has been 
            significantly propelled by 3D Gaussian Splatting (3DGS). However, effectively training 
            large-scale 3DGS and rendering it in real-time across various scales remains challenging. 
            This paper introduces CityGaussian (CityGS), which employs a novel divide-and-conquer 
            training approach and Level-of-Detail (LoD) strategy for efficient large-scale 3DGS 
            training and rendering. Specifically, the global scene prior and adaptive training data 
            selection enables efficient training and seamless fusion. Based on fused Gaussian primitives, 
            we generate different detail levels through compression, and realize fast rendering across 
            various scales through the proposed block-wise detail levels selection and aggregation 
            strategy. Extensive experimental results on large-scale scenes demonstrate that our approach 
            attains state-of-the-art rendering quality, enabling consistent real-time rendering of 
            large-scale scenes across vastly different scales.
          </p>
      </div>

<div>
      <h2>Comparison With SOTA</h2>
      <p><img alt="Architecture" src="https://dekuliutesla.github.io/citygs/static/images/table.png" width="100%">
    </p></div>


<div>

      <!-- CityGS: No LoD -->
      <div>
        <h2>CityGS: No LoD</h2>
        <div>
          <p>
              Without our proposed LoD technique, the MatrixCity is depicted by 25 million Gaussians. The consequent speed of 18 FPS (tested on A100) leads to unpleasant roaming experience.
            </p>

        </div>
      </div>
      <!--/ CityGS: No LoD. -->

      <!-- CityGS. -->
      <div>
          <h2>CityGS</h2>
          <p>
            With the support of LoD, our CityGS can be rendered in real-time under vastly different scales. The average speed is 36 FPS (tested on A100).
          </p>
          <!-- <video id="video_10m" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/video_10m.mp4"
                    type="video/mp4">
          </video> -->
        </div>
      <!--/ CityGS. -->
      
    </div>

<div>
    <h2>Visual Comparisons</h2>
    
    
  </div>

<div id="BibTeX">
    <h2>BibTeX</h2>
    <pre><code>@misc{liu2024citygaussian,
      title={CityGaussian: Real-time High-quality Large-Scale Scene Rendering with Gaussians}, 
      author={Yang Liu and He Guan and Chuanchen Luo and Lue Fan and Junran Peng and Zhaoxiang Zhang},
      year={2024},
      eprint={2404.01133},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}</code></pre>
  </div>

<div>
        <h2>References</h2>

        <div>
          <p>
            [Turki 2022] Turki, H., Ramanan, D., Satyanarayanan, M.: Mega-nerf: Scalable construction of large-scale nerfs for virtual fly-throughs. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 12922â12931 (2022)
          </p>
          <p>
            [Zhenxing 2022] Zhenxing, M., Xu, D.: Switch-nerf: Learning scene decomposition with mixture of experts for large-scale neural radiance fields. In: The Eleventh International Conference on Learning Representations (2022)
          </p>
          <p>
            [Yuqi 2023] Zhang, Y., Chen, G., Cui, S.: Efficient large-scale scene representation with a hybrid of high-resolution grid and plane features. arXiv preprint arXiv:2303.03003 (2023)
          </p>  
          <p>
            [Bernhard 2023] Kerbl, B., Kopanas, G., LeimkÃ¼hler, T., Drettakis, G.: 3d gaussian splatting for real-time radiance field rendering. ACM Transactions on Graphics 42(4) (2023)
          </p>
        </div>
      </div>







</div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: 3D + 2D: Testing out my cross-platform WASM graphics engine (470 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=39907845</link>
            <guid>39907845</guid>
            <pubDate>Tue, 02 Apr 2024 16:44:32 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=39907845">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><td><table>
        <tbody><tr id="39907845">
      <td><span></span></td>      <td><center><a id="up_39907845" href="https://news.ycombinator.com/vote?id=39907845&amp;how=up&amp;goto=item%3Fid%3D39907845"></a></center></td><td><span><a href="https://news.ycombinator.com/item?id=39907845">3D + 2D: Testing out my cross-platform WASM graphics engine</a></span></td></tr><tr><td colspan="2"></td><td><span>
          <span id="score_39907845">112 points</span> by <a href="https://news.ycombinator.com/user?id=seanisom">seanisom</a> <span title="2024-04-02T16:44:32"><a href="https://news.ycombinator.com/item?id=39907845">3 hours ago</a></span> <span id="unv_39907845"></span> | <a href="https://news.ycombinator.com/hide?id=39907845&amp;goto=item%3Fid%3D39907845">hide</a> | <a href="https://hn.algolia.com/?query=3D%20%2B%202D%3A%20Testing%20out%20my%20cross-platform%20WASM%20graphics%20engine&amp;type=story&amp;dateRange=all&amp;sort=byDate&amp;storyText=false&amp;prefix&amp;page=0">past</a> | <a href="https://news.ycombinator.com/fave?id=39907845&amp;auth=f4a205beed782d8a9c166da489fbeb136a787d7c">favorite</a> | <a href="https://news.ycombinator.com/item?id=39907845">34&nbsp;comments</a>        </span>
              </td></tr>
    <tr></tr><tr><td colspan="2"></td><td><div><p>I used to work at Adobe on the infrastructure powering big applications like Photoshop and  Acrobat. One of our worst headaches was making these really powerful codebases work on desktop, web, mobile, and the cloud without having to completely rewrite them.  For example, to get Lightroom and Photoshop working on the web we took a winding path through JavaScript, Googleâs PNaCl, asm.js, and finally WebAssembly, all while having to rethink our GPU architecture around these devices. We even had to get single-threaded builds working and rebuild the UI around Web Components. Today the web builds work great, but it was a decade-long journey to get there!</p><p>The graphics stack continues to be one of the biggest bottlenecks in portability. One day I realized that WebAssembly (Wasm) actually held the solution to the madness. Itâs runnable anywhere, embeddable into anything, and performant enough for real-time graphics. So I quit my job and dove into the adventure of creating a portable, embeddable WASM-based graphics framework from the ground up: high-level enough for app developers to easily make whatever graphics they want, and low-level enough to take full advantage of the GPU and everything else needed for a high-performance application.</p><p>I call it Renderlet to emphasize the embeddable aspect â you can make self-contained graphics modules that do just what you want, connect them together, and make them run <i>on</i> anything or <i>in</i> anything with trivial interop.</p><p>If you think of how Unity made it easy for devs to build cross-platform games, the idea is to do the same thing for all visual applications.</p><p>Somewhere along the way I got into YC as a solo founder (!) but mostly Iâve been heads-down building this thing for the last 6 months. Itâs not <i>quite</i> ready for an open alpha release, but itâs closeâclose enough that Iâm ready to write about it, show it off, and start getting feedback. This is the thing I dreamed of as an application developer, and I want to know what you think!</p><p>When Rive open-sourced their 2D vector engine and made a splash on HN a couple weeks ago (<a href="https://news.ycombinator.com/item?id=39766893">https://news.ycombinator.com/item?id=39766893</a>), I was intrigued. Riveâs renderer is built as a higher-level 2D API similar to SVG, whereas the Wander renderer (the open-source runtime part of Renderlet) exposes a lower-level 3D API over the GPU. Could Renderlet use its GPU backend to run the Rive Renderer library, enabling any 3D app to have a 2D vector backend? Yes it can - I implemented it!</p><p>You can see it working here: <a href="https://vimeo.com/929416955" rel="nofollow">https://vimeo.com/929416955</a> and thereâs a deep technical dive here: <a href="https://github.com/renderlet/wander/wiki/Using-renderlet-with-rive%E2%80%90renderer">https://github.com/renderlet/wander/wiki/Using-renderlet-wit...</a>. The code for my runtime Wasm Renderer (a.k.a. Wander) is here: <a href="https://github.com/renderlet/wander">https://github.com/renderlet/wander</a>.</p><p>Iâll come back and do a proper Show HN or Launch HN when the compiler is ready for anyone to use and I have the integration working on all platforms, but I hope this is interesting enough to take a look at now. I want to hear what you think of this!</p></div></td></tr>        <tr></tr><tr><td colspan="2"></td><td><form action="comment" method="post"></form></td></tr>  </tbody></table>
  </td></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Princeton group open sources "SWE-agent", with 12% fix rate for GitHub issues (282 pts)]]></title>
            <link>https://github.com/princeton-nlp/SWE-agent</link>
            <guid>39907468</guid>
            <pubDate>Tue, 02 Apr 2024 16:16:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/princeton-nlp/SWE-agent">https://github.com/princeton-nlp/SWE-agent</a>, See on <a href="https://news.ycombinator.com/item?id=39907468">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto">
  <a href="https://www.swe-agent.com/" rel="nofollow">
    <img src="https://github.com/princeton-nlp/SWE-agent/raw/main/assets/swe-agent-banner.png" alt="swe-agent.com">
  </a>
</p>
<p dir="auto">
  <a href="https://swe-agent.com/" rel="nofollow"><strong>Website &amp; Demo</strong></a>&nbsp; | &nbsp;
  <a href="https://discord.gg/AVEFbBn2rH" rel="nofollow"><strong>Discord</strong></a>&nbsp; | &nbsp;
  <strong>Paper [coming April 10th]</strong>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">ð Overview <a name="user-content-overview"></a></h2><a id="user-content--overview-" aria-label="Permalink: ð Overview " href="#-overview-"></a></p>
<p dir="auto">SWE-agent turns LMs (e.g. GPT-4) into software engineering agents that can fix bugs and issues in real GitHub repositories.</p>
<p dir="auto">On the full <a href="https://github.com/princeton-nlp/SWE-bench">SWE-bench</a> test set, SWE-agent resolves <strong>12.29%</strong> of issues, achieving the state-of-the-art performance on the full test set.</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/princeton-nlp/SWE-agent/blob/main/assets/results+preview.png"><img src="https://github.com/princeton-nlp/SWE-agent/raw/main/assets/results+preview.png"></a>
</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">â¨ Agent-Computer Interface (ACI) <a name="user-content-aci"></a></h3><a id="user-content--agent-computer-interface-aci-" aria-label="Permalink: â¨ Agent-Computer Interface (ACI) " href="#-agent-computer-interface-aci-"></a></p>
<p dir="auto">We accomplish these results by designing simple LM-centric commands and feedback formats to make it easier for the LM to browse the repository, view, edit and execute code files. We call this an <strong>Agent-Computer Interface</strong> (ACI) and build the SWE-agent repository to make it easy to iterate on ACI design for repository-level coding agents.</p>
<p dir="auto">Just like how typical language models requires good prompt engineering, good ACI design leads to much better results when using agents. As we show in our paper, a baseline agent without a well-tuned ACI does much worse than SWE-agent.</p>
<p dir="auto">SWE-agent contains features that we discovered to be immensly helpful during the agent-computer interface design process:</p>
<ol dir="auto">
<li>We add a linter that runs when an edit command is issued, and do not let the edit command go through if the code isn't syntactically correct.</li>
<li>We supply the agent with a special-built file viewer, instead of having it just <code>cat</code> files. We found that this file viewer works best when displaying just 100 lines in each turn. The file editor that we built has commands for scrolling up and down and for performing a search within the file.</li>
<li>We supply the agent with a special-built full-directory string searching command. We found that it was important for this tool to succintly list the matches- we simply list each file that had at least one match. Showing the model more context about each match proved to be too confusing for the model.</li>
<li>When commands have an empty output we return a message saying "Your command ran successfully and did not produce any output."</li>
</ol>
<p dir="auto">Read our paper for more details.</p>
<div data-snippet-clipboard-copy-content="@misc{yang2024sweagent,
      title={SWE-agent: Agent Computer Interfaces Enable Software Engineering Language Models}, 
      author={John Yang and Carlos E. Jimenez and Alexander Wettig and Shunyu Yao and Karthik Narasimhan and Ofir Press},
      year={2024},
}"><pre><code>@misc{yang2024sweagent,
      title={SWE-agent: Agent Computer Interfaces Enable Software Engineering Language Models}, 
      author={John Yang and Carlos E. Jimenez and Alexander Wettig and Shunyu Yao and Karthik Narasimhan and Ofir Press},
      year={2024},
}
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">ð Setup <a name="user-content-setup"></a></h2><a id="user-content--setup-" aria-label="Permalink: ð Setup " href="#-setup-"></a></p>
<ol dir="auto">
<li><a href="https://docs.docker.com/engine/install/" rel="nofollow">Install Docker</a>, then start Docker locally.</li>
<li><a href="https://docs.anaconda.com/free/miniconda/miniconda-install/" rel="nofollow">Install Miniconda</a>, then create the <code>swe-agent</code> environment with <code>conda env create -f environment.yml</code></li>
<li>Activate using <code>conda activate swe-agent</code>.</li>
<li>Run <code>./setup.sh</code> to create the <code>swe-agent</code> docker image.</li>
<li>Create a <code>keys.cfg</code> file at the root of this repository and fill in the following:</li>
</ol>
<div data-snippet-clipboard-copy-content="OPENAI_API_KEY: 'OpenAI API Key Here if using OpenAI Model (optional)'
ANTHROPIC_API_KEY: 'Anthropic API Key Here if using Anthropic Model (optional)'
GITHUB_TOKEN: 'GitHub Token Here (required)'"><pre><code>OPENAI_API_KEY: 'OpenAI API Key Here if using OpenAI Model (optional)'
ANTHROPIC_API_KEY: 'Anthropic API Key Here if using Anthropic Model (optional)'
GITHUB_TOKEN: 'GitHub Token Here (required)'
</code></pre></div>
<p dir="auto">See the following links for tutorials on obtaining <a href="https://docs.anthropic.com/claude/reference/getting-started-with-the-api" rel="nofollow">Anthropic</a>, <a href="https://platform.openai.com/docs/quickstart/step-2-set-up-your-api-key" rel="nofollow">OpenAI</a>, and <a href="https://github.com/princeton-nlp/SWE-agent/blob/main">Github</a> tokens.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">ð½ Usage <a name="user-content-usage"></a></h2><a id="user-content--usage-" aria-label="Permalink: ð½ Usage " href="#-usage-"></a></p>
<p dir="auto">There are two steps to the SWE-agent pipeline. First SWE-agent takes an input GitHub issue and returns a pull request that attempts to fix it. We call that step <em>inference</em>. The second step (currently, only available for issues in the SWE-bench benchmark) is to <em>evaluate</em> the pull request to verify that it has indeed fixed the issue.</p>
<p dir="auto"><em>NOTE</em>: At this moment, there are known issues with a small number of repositories that don't install properly for <code>arm64</code> / <code>aarch64</code> architecture computers. We're working on a fix, but if you'd like to run and evaluate on the entirety of SWE-bench, the easiest way is by using an <code>x86</code> machine.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">ð©âð» Inference <a name="user-content-inference"></a></h3><a id="user-content--inference-" aria-label="Permalink: ð©âð» Inference " href="#-inference-"></a></p>
<p dir="auto"><strong>Inference on <em>any</em> GitHub Issue</strong>: Using this script, you can run SWE-agent on any GitHub issue!</p>
<div data-snippet-clipboard-copy-content="python run.py --model_name gpt4 \
  --data_path https://github.com/pvlib/pvlib-python/issues/1603 --config_file config/default_from_url.yaml"><pre><code>python run.py --model_name gpt4 \
  --data_path https://github.com/pvlib/pvlib-python/issues/1603 --config_file config/default_from_url.yaml
</code></pre></div>
<p dir="auto"><strong>Inference on SWE-bench</strong>: Run SWE-agent on <a href="https://www.swebench.com/lite.html" rel="nofollow">SWE-bench Lite</a> and generate patches.</p>
<div data-snippet-clipboard-copy-content="python run.py --model_name gpt4 \
  --per_instance_cost_limit 2.00 \
  --config_file ./config/default.yaml"><pre><code>python run.py --model_name gpt4 \
  --per_instance_cost_limit 2.00 \
  --config_file ./config/default.yaml
</code></pre></div>
<p dir="auto">If you'd like to run on a <em>single</em> issue from SWE-bench, use the <code>--instance_filter</code> option as follows:</p>
<div data-snippet-clipboard-copy-content="python run.py --model_name gpt4 \
  --instance_filter marshmallow-code__marshmallow-1359"><pre><code>python run.py --model_name gpt4 \
  --instance_filter marshmallow-code__marshmallow-1359
</code></pre></div>
<ul dir="auto">
<li>See the <a href="https://github.com/princeton-nlp/SWE-agent/blob/main/scripts"><code>scripts/</code></a> folder for other useful scripts and details.</li>
<li>See the <a href="https://github.com/princeton-nlp/SWE-agent/blob/main/config"><code>config/</code></a> folder for details about how you can define your own configuration!</li>
<li>See the <a href="https://github.com/princeton-nlp/SWE-agent/blob/main/agent"><code>swe-agent/agent/</code></a> folder for details about the logic behind configuration based workflows.</li>
<li>See the <a href="https://github.com/princeton-nlp/SWE-agent/blob/main/swe-agent/environment"><code>swe-agent/environment/</code></a> folder for details about the <code>SWEEnv</code> environment (interface + implementation).</li>
<li>See the <a href="https://github.com/princeton-nlp/SWE-agent/blob/main/trajectories"><code>trajectories/</code></a> folder for details about the output of <code>run.py</code>.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">ð§ª Evaluation <a name="user-content-evaluation"></a></h3><a id="user-content--evaluation-" aria-label="Permalink: ð§ª Evaluation " href="#-evaluation-"></a></p>
<p dir="auto">This step is only available for issues from the SWE-bench set. To evaluate generated pull requests:</p>
<div data-snippet-clipboard-copy-content="cd evaluation/
./run_eval.sh <predictions_path>"><pre><code>cd evaluation/
./run_eval.sh &lt;predictions_path&gt;
</code></pre></div>
<p dir="auto">Replace <code>&lt;predictions_path&gt;</code> with the path to the model's predictions, which should be generated from the <em>Inference</em> step. The <code>&lt;predictions_path&gt;</code> arguments should look like <code>../trajectories/&lt;username&gt;/&lt;model&gt;-&lt;dataset&gt;-&lt;hyperparams&gt;/all_preds.jsonl</code></p>
<ul dir="auto">
<li>See the <a href="https://github.com/princeton-nlp/SWE-agent/blob/main/evaluation"><code>evaluation/</code></a> folder for details about how evaluation works.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">ð« Contributions <a name="user-content-contributions"></a></h2><a id="user-content--contributions-" aria-label="Permalink: ð« Contributions " href="#-contributions-"></a></p>
<ul dir="auto">
<li>If you'd like to ask questions, learn about upcoming features, and participate in future development, join our <a href="https://discord.gg/AVEFbBn2rH" rel="nofollow">Discord community</a>!</li>
<li>If you'd like to contribute to the codebase, we welcome <a href="https://github.com/princeton-nlp/SWE-agent/issues">issues</a> and <a href="https://github.com/princeton-nlp/SWE-agent/pulls">pull requests</a>!</li>
<li>If you'd like to see a post or tutorial about some topic, please let us know via an <a href="https://github.com/princeton-nlp/SWE-agent/issues">issue</a>.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">ðªª License <a name="user-content-license"></a></h2><a id="user-content--license-" aria-label="Permalink: ðªª License " href="#-license-"></a></p>
<p dir="auto">MIT. Check <code>LICENSE</code>.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Canoo spent double its annual revenue on the CEO's private jet (287 pts)]]></title>
            <link>https://techcrunch.com/2024/04/01/canoo-spent-double-its-annual-revenue-on-the-ceos-private-jet-in-2023/</link>
            <guid>39906924</guid>
            <pubDate>Tue, 02 Apr 2024 15:33:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://techcrunch.com/2024/04/01/canoo-spent-double-its-annual-revenue-on-the-ceos-private-jet-in-2023/">https://techcrunch.com/2024/04/01/canoo-spent-double-its-annual-revenue-on-the-ceos-private-jet-in-2023/</a>, See on <a href="https://news.ycombinator.com/item?id=39906924">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				<p id="speakable-summary">Tucked inside Canooâs 2023 earnings report is a nugget regarding the use of CEO Tony Aquilaâs private jet â just one of many expenses that<span> illustrates the gap between spending and revenue at the EV startup.</span></p>
<p>Canoo posted Monday its fourth-quarter and full-year earnings for 2023 in a <a href="https://ir.stockpr.com/canoo/sec-filings-email/content/0001628280-24-014075/goev-20231231.htm#i5cf4fcff5f5a4438b15ae9a52ca671ee_112" target="_blank" rel="noopener">regulatory filing</a> that shows a company burning through cash as it tries to scale up volume production of its commercial electric vehicles and avoid the same fate as other EV startups, like recently bankrupt <a href="https://techcrunch.com/tag/arrival/">Arrival</a>. The regulatory filing once again contained a âgoing concernâ warning â which has <a href="https://techcrunch.com/2022/05/10/canoo-warns-it-may-not-have-enough-funds-to-bring-evs-to-market/" target="_blank" rel="noopener">persisted since 2022</a> â as well as some progress on the expenses and revenue fronts.</p>
<p><span>The company generated $886,000 in revenue in 2023 compared to zero dollars in 2022, as the company delivered 22 vehicles to entities like NASA and the state of Oklahoma. And it did reduce its loss from operations by nearly half, from $506 million in 2022 to $267 million in 2023. </span><span>The revenue-to-losses gap is still considerable though: The company reported total net losses of $302.6 million in 2023.&nbsp;</span></p>
<p>Still, one only needs to look at what Canoo is paying to rent the CEOâs private jet to put those âwinsâ into perspective. Under a deal reached in November 2020, Canoo reimburses Aquila Family Ventures, an entity owned by the CEO, for use of an aircraft. In 2023, Canoo spent $1.7 million on this reimbursement â thatâs double the amount of revenue it generated. Canoo paid Aquila Family Ventures $1.3 million in 2022 and $1.8 million in 2021 for use of the aircraft.</p>
<p>Separately, Canoo also paid Aquila Family Ventures $1.7 million in 2023, $1.1 million in 2022 and $500,000 in 2021 for shared services support in its Justin, Texas, corporate office facility, according to regulatory filings.</p>
<p>This could be chalked up to small monetary potatoes&nbsp;if&nbsp;Canoo reaches its revenue forecast for 2024 of $50 million to $100 million.</p>
<p>Weâve asked Canoo for comment and will update this post if we hear back.</p>
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Recreating the Flying Toasters screen saver for the Vision Pro (153 pts)]]></title>
            <link>https://abhipray.com/posts/flying_toasters/</link>
            <guid>39906887</guid>
            <pubDate>Tue, 02 Apr 2024 15:31:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://abhipray.com/posts/flying_toasters/">https://abhipray.com/posts/flying_toasters/</a>, See on <a href="https://news.ycombinator.com/item?id=39906887">Hacker News</a></p>
<div id="readability-page-1" class="page"><section><article><header><div><p><span>
<time datetime="2024-04-01T00:00:00Z">April 1, 2024</time></span>
<span>
4-minute read</span></p></div></header><div><p>I recently decided to make an app for the Apple Vision Pro (AVP) during a two-week break between jobs. I wanted to explore its potential and learn some new skills. My day job primarily involves low-level firmware; I hadnât built a user-facing app in a whileâmy last iOS app experience was back in high school in 2011! This was a chance to see how app development has evolved in 2024, especially with modern code generation tools.</p><h2 id="inspiration-and-the-screensaver-idea">Inspiration and the âScreensaverâ Idea
<a href="#inspiration-and-the-screensaver-idea">
<span>Link to heading</span></a></h2><p>After brainstorming with friends, one suggested I look into the classic âFlying Toastersâ screensaver by After Dark (released in 1989). I watched a video of it and thought it would be a perfect starter project!</p><p><iframe src="https://www.youtube.com/embed/Ft5DIBAvXIU" allowfullscreen="" title="YouTube Video"></iframe></p><p>I was especially excited to bring the concept of a âscreensaverâ to this new platform. Historically, screensavers served a practical purpose on CRT monitorsâpreventing screen burn-ins. From Wikipedia:</p><blockquote><p>Screen burn-in, image burn-in, ghost image, or shadow image, is a permanent discoloration of areas on an electronic display such as a cathode ray tube (CRT) in an old computer monitor or television set. It is caused by cumulative non-uniform use of the screen.
One way to combat screen burn-in was the use of screensavers, which would move an image around to ensure that no one area of the screen remained illuminated for too long.</p></blockquote><p>Today, screensavers primarily serve aesthetic and entertainment purposes, activating during periods of user inactivity. My aim was to incorporate a similar, inactivity-based trigger for the AVP screensaver. Initially, my plan was to employ gaze tracking to identify moments when a user might be âzoned outâ. Due to privacy considerations, Apple restricts access to such sensor data. As a workaround, users can signal their activity by periodically tapping a button within the appâs main control window, effectively resetting the inactivity timer. The app also allows users the flexibility to customize the timeout duration, transforming the screensaver into a gentle nudge to take breaks from using the AVP.</p><h2 id="the-screensaver-itself">The Screensaver Itself
<a href="#the-screensaver-itself">
<span>Link to heading</span></a></h2><p>The screensaver features flying toasters soaring across your real-world environment. They emerge from a portal showing the sun and disappear into a portal showing the moon. It was fun adding silly little features like:</p><ul><li>Gesture controls: Scale and rotate the portals to your liking.</li><li>Toaster interaction: Tap a toaster to trigger a whimsical phrase. Baby toasters occasionally make an appearance too!</li><li>Customization: Adjust toaster count, toastiness level, colors, and music. Or, activate âghost modeâ to prevent collisions if the on-screen chaos gets overwhelming.</li></ul><p>Check out the app previews and screenshots on the app store to get a visual: <a href="https://apps.apple.com/us/app/flying-toasters/id6479964879" target="_blank" rel="noopener">https://apps.apple.com/us/app/flying-toasters/id6479964879</a></p><h2 id="technical-challenges">Technical Challenges
<a href="#technical-challenges">
<span>Link to heading</span></a></h2><p>Here are some specific challenges I overcame during the development process:</p><ul><li><p>Learning Swift: Although Iâd used Objective-C for an iOS app back in high school, I wanted to learn Appleâs recommended way of writing apps. I spent time reading <a href="https://carlosicaza.com/swiftbooks/SwiftLanguage.pdf" target="_blank" rel="noopener">Swift tutorials</a> and practicing in <a href="https://developer.apple.com/swift-playgrounds/" target="_blank" rel="noopener">Swift Playgrounds</a>. ChatGPT and Gemini were also great resources for code editing and debugging.</p></li><li><p>3D Animation/Art: I had no prior experience with 3D animation. I started with a 3D-printable toaster model and followed <a href="https://www.youtube.com/watch?v=VuMu4tAzFjw" target="_blank" rel="noopener">tutorials</a> to animate the wings. Creating those toasts was trickier! I couldnât find the right textures for different toastiness levels â after a lot of trial and error (and a hundred attempts with Photoshopâs generative fill), I finally got those realistic-looking textures.</p></li><li><p>Portal Gestures: Appleâs <a href="https://developer.apple.com/documentation/realitykit/transforming-realitykit-entities-with-gestures?changes=_8" target="_blank" rel="noopener">example code</a> was key for implementing intuitive scaling and rotation gestures for the portals.</p></li><li><p>Toaster Physics vs. Animation: I found out the hard way that RealityKitâs physics engine and strict animation paths (using FromToByAnimation()) donât always play nicely together. My chaotic collision solution? Random launch points with a minimum distance constraint, random <a href="https://cubic-bezier.com/" target="_blank" rel="noopener">cubic-bezier</a> curve paths, and plenty of linear/angular damping on those toasters. If the toastersâ movements are still subjectively chaotic, the user can opt out of collisions by turning on ghost mode.</p></li><li><p>Head Tracking: I wanted the toastersâ whimsical phrases to appear in speech bubbles that always faced the user. RealityKit doesnât directly track head position, but I adapted a clever <a href="https://stackoverflow.com/questions/77577395/how-to-know-users-position-in-surrounding-space-in-visionos/77616297#77616297" target="_blank" rel="noopener">ARKit workaround</a> to achieve this.</p></li></ul><h2 id="the-future">The future
<a href="#the-future">
<span>Link to heading</span></a></h2><p>This project was a blast! If you have an AVP and end up seeing the flying toasters in action, please let me know what you think! Just as the original Flying Toasters screensaver evolved over a decade (see <a href="https://www.youtube.com/watch?v=Ft5DIBAvXIU&amp;list=PLxRwNKfqQOI1_pp6Cp4p1MnpCsoqCx2cK&amp;index=2" target="_blank" rel="noopener">the YouTube playlist here</a>), I anticipate if there is enough interest and feedback, I will improve the experience. So do share feedback!</p></div></article>
</section></div>]]></description>
        </item>
    </channel>
</rss>