<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 20 Mar 2024 23:00:08 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Claim: Private GitHub repos included in AI dataset (181 pts)]]></title>
            <link>https://post.lurk.org/@emenel/112111014479288871</link>
            <guid>39770712</guid>
            <pubDate>Wed, 20 Mar 2024 19:07:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://post.lurk.org/@emenel/112111014479288871">https://post.lurk.org/@emenel/112111014479288871</a>, See on <a href="https://news.ycombinator.com/item?id=39770712">Hacker News</a></p>
Couldn't get https://post.lurk.org/@emenel/112111014479288871: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[OpenAI's chatbot store is filling up with spam (118 pts)]]></title>
            <link>https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/</link>
            <guid>39769708</guid>
            <pubDate>Wed, 20 Mar 2024 17:34:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/">https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/</a>, See on <a href="https://news.ycombinator.com/item?id=39769708">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				<p id="speakable-summary">When OpenAI CEO Sam Altman announced <a href="https://techcrunch.com/2024/01/10/openai-launches-a-store-for-custom-ai-powered-chatbots/">GPTs</a>, custom chatbots powered by OpenAI’s generative AI models, onstage at the company’s first-ever <a href="https://techcrunch.com/tag/openai-devday/">developer conference</a> in November, he described them as a way to “accomplish all sorts of tasks” — from programming to learning about esoteric scientific subjects to getting workout pointers.</p>
<p>“Because [GPTs] combine instructions, expanded knowledge and actions, they can be more helpful to you,” Altman said. “You can build a GPT … for almost anything.”</p>
<p>He wasn’t kidding about the anything part.</p>
<p>TechCrunch found that the GPT Store, OpenAI’s official marketplace for GPTs, is flooded with bizarre, potentially copyright-infringing GPTs that imply a light touch where it concerns OpenAI’s moderation efforts. A cursory search pulls up GPTs that purport to generate art in the style of Disney and Marvel properties, but serve as little more than funnels to third-party paid services, and advertise themselves as being able to bypass AI content detection tools such as Turnitin and Copyleaks.</p>
<h2>Missing moderation</h2>
<p>To list GPTs in the GPT Store, developers have to verify their user profiles and submit GPTs to OpenAI’s review system, which involves a mix of human and automated review. Here’s a spokesperson on the process:</p>
<blockquote><p>We use a combination of automated systems, human review and user reports to find and assess GPTs that potentially violate our policies. Violations can lead to actions against the content or your account, such as warnings, sharing restrictions or ineligibility for inclusion in GPT Store or monetization.</p></blockquote>
<p>Building GPTs doesn’t require coding experience, and GPTs can be as simple — or complex — as the creator wishes. Developers can type the capabilities they want to offer into OpenAI’s GPT-building tool, GPT Builder, and the tool will attempt to make a GPT to perform those.</p>
<p>Perhaps because of the low barrier to entry, the GPT Store has grown rapidly — OpenAI in January said that it had roughly 3 million GPTs. But this growth appears to have come at the expense of quality — as well as adherence to OpenAI’s own terms.</p>
<h2>Copyright issues</h2>
<p>There are several GPTs ripped from popular movie, TV and video game franchises in the GPT Store — GPTs not created or authorized (to TechCrunch’s knowledge) by those franchises’ owners. One GPT creates monsters in the style of “Monsters, Inc.,” the Pixar movie, while another promises text-based adventures set in the “Star Wars” universe.</p>
<div id="attachment_2679819"><p><img fetchpriority="high" decoding="async" aria-describedby="caption-attachment-2679819" src="https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-14-at-7.41.21%E2%80%AFPM.png" alt="OpenAI GPT Store spam" width="1024" height="737" srcset="https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-14-at-7.41.21 https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/PM.png 1506w, https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-14-at-7.41.21 https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/PM.png?resize=150,108 150w, https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-14-at-7.41.21 https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/PM.png?resize=300,216 300w, https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-14-at-7.41.21 https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/PM.png?resize=768,553 768w, https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-14-at-7.41.21 https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/PM.png?resize=680,489 680w, https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-14-at-7.41.21 https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/PM.png?resize=1200,864 1200w, https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-14-at-7.41.21 https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/PM.png?resize=50,36 50w" sizes="(max-width: 1024px) 100vw, 1024px"></p><p id="caption-attachment-2679819"><strong>Image Credits:</strong> OpenAI</p></div>
<p>These GPTs — along with the GPTs in the GPT Store that let users speak with trademarked characters like Wario and Aang from “Avatar: The Last Airbender” — set the stage for copyright drama.</p>
<p>Kit Walsh, a senior staff attorney at the Electronic Frontier Foundation, explained it thusly:</p>
<blockquote><p>[These GPTs] can be used to create transformative works as well as for infringement [where <em>transformative works</em> refer to a type of fair use shielded from copyright claims.] The individuals engaging in infringement, of course, could be liable, and the creator of an otherwise lawful tool can essentially talk themselves into liability if they encourage users to use the tool in infringing ways. There are also trademark issues with using a trademarked name to identify goods or services where there is a risk of users being confused about whether it is endorsed or operated by the trademark owner.</p></blockquote>
<p>OpenAI itself wouldn’t be held liable for copyright infringement by GPT creators thanks to the safe harbor provision in the Digital Millennium Copyright Act, which protects it and other platforms (e.g. YouTube, Facebook) that host infringing content so long as those platforms meet the statutory requirements and take down specific examples of infringement when requested.</p>
<div id="attachment_2679815"><p><img decoding="async" aria-describedby="caption-attachment-2679815" src="https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-14-at-7.31.54%E2%80%AFPM.png" alt="OpenAI GPT Store spam" width="1024" height="634" srcset="https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-14-at-7.31.54 https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/PM.png 1670w, https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-14-at-7.31.54 https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/PM.png?resize=150,93 150w, https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-14-at-7.31.54 https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/PM.png?resize=300,186 300w, https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-14-at-7.31.54 https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/PM.png?resize=768,476 768w, https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-14-at-7.31.54 https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/PM.png?resize=680,421 680w, https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-14-at-7.31.54 https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/PM.png?resize=1536,951 1536w, https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-14-at-7.31.54 https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/PM.png?resize=1200,743 1200w, https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-14-at-7.31.54 https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/PM.png?resize=50,31 50w" sizes="(max-width: 1024px) 100vw, 1024px"></p><p id="caption-attachment-2679815"><strong>Image Credits:</strong> OpenAI</p></div>
<p>It is, however, a bad look for a company embroiled in IP litigation.</p>
<h2>Academic dishonesty</h2>
<p>OpenAI’s terms explicitly prohibit developers from building GPTs that promote academic dishonesty. Yet the GPT Store is filled with GPTs suggesting they can bypass AI content detectors, including detectors sold to educators through plagiarism scanning platforms.</p>
<p>One GPT claims to be a “sophisticated” rephrasing tool “undetectable” by popular AI content detectors like Originality.ai and Copyleaks. Another, Humanizer Pro — ranked No. 2 in the Writing category on the GPT Store — says that it “humanizes” content to bypass AI detectors, maintaining a text’s “meaning and quality” while delivering a “100% human” score.</p>
<div id="attachment_2679820"><p><img decoding="async" aria-describedby="caption-attachment-2679820" src="https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-14-at-11.45.14%E2%80%AFPM.png" alt="OpenAI GPT Store spam" width="1024" height="737" srcset="https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-14-at-11.45.14 https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/PM.png 1506w, https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-14-at-11.45.14 https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/PM.png?resize=150,108 150w, https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-14-at-11.45.14 https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/PM.png?resize=300,216 300w, https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-14-at-11.45.14 https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/PM.png?resize=768,553 768w, https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-14-at-11.45.14 https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/PM.png?resize=680,489 680w, https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-14-at-11.45.14 https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/PM.png?resize=1200,864 1200w, https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-14-at-11.45.14 https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/PM.png?resize=50,36 50w" sizes="(max-width: 1024px) 100vw, 1024px"></p><p id="caption-attachment-2679820"><strong>Image Credits:</strong> OpenAI</p></div>
<p>Some of these GPTs are thinly veiled pipelines to premium services. Humanizer, for instance, invites users to try a “premium plan” to “use [the] most advanced algorithm,” which transmits text entered into the GPT to a plug-in from a third-party site, GPTInf. Subscriptions to GPTInf cost $12 per month for 10,000 words per month or $8 per month on an annual plan — a little steep on top of OpenAI’s $20-per-month <a href="https://techcrunch.com/2023/02/01/openai-launches-chatgpt-plus-starting-at-20-per-month/">ChatGPT Plus</a>.</p>
<div id="attachment_2679821"><p><img loading="lazy" decoding="async" aria-describedby="caption-attachment-2679821" src="https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-14-at-11.55.17%E2%80%AFPM.png" alt="OpenAI GPT Store spam" width="1024" height="737" srcset="https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-14-at-11.55.17 https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/PM.png 1506w, https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-14-at-11.55.17 https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/PM.png?resize=150,108 150w, https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-14-at-11.55.17 https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/PM.png?resize=300,216 300w, https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-14-at-11.55.17 https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/PM.png?resize=768,553 768w, https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-14-at-11.55.17 https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/PM.png?resize=680,489 680w, https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-14-at-11.55.17 https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/PM.png?resize=1200,864 1200w, https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-14-at-11.55.17 https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/PM.png?resize=50,36 50w" sizes="(max-width: 1024px) 100vw, 1024px"></p><p id="caption-attachment-2679821"><strong>Image Credits:</strong> OpenAI</p></div>
<p>Now, we’ve written before about how AI content detectors are <a href="https://techcrunch.com/2023/02/16/most-sites-claiming-to-catch-ai-written-text-fail-spectacularly/">largely bunk</a>. Beyond our own <a href="https://techcrunch.com/2023/02/16/most-sites-claiming-to-catch-ai-written-text-fail-spectacularly/">tests</a>, a number of academic studies demonstrate that they’re neither accurate nor reliable. <em>However</em>, it remains the case that OpenAI is allowing tools on the GPT Store that promote academically dishonest behavior — even if the behavior doesn’t have the intended outcome.</p>
<p>The OpenAI spokesperson said:</p>
<blockquote><p>GPTs that are for academic dishonesty, including cheating, are against our policy. This would include GPTs that are stated to be for circumventing academic integrity tools like plagiarism detectors. We see some GPTs that are for ‘humanizing’ text. We’re still learning from the real world use of these GPTs, but we understand there are many reasons why users might prefer to have AI-generated content that doesn’t ‘sound’ like AI.</p></blockquote>
<h2>Impersonation</h2>
<p>In its policies, OpenAI also forbids GPT developers from creating GPTs that impersonate people or organizations without their “consent or legal right.”</p>
<p>However, there’s plenty of GPTs on the GPT Store that claim to represent the views — or otherwise imitate the personalities of — people.</p>
<div id="attachment_2679804"><p><img loading="lazy" decoding="async" aria-describedby="caption-attachment-2679804" src="https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-15-at-12.25.31%E2%80%AFAM.png" alt="OpenAI GPT Store spam" width="1024" height="737" srcset="https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-15-at-12.25.31 https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/AM.png 1506w, https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-15-at-12.25.31 https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/AM.png?resize=150,108 150w, https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-15-at-12.25.31 https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/AM.png?resize=300,216 300w, https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-15-at-12.25.31 https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/AM.png?resize=768,553 768w, https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-15-at-12.25.31 https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/AM.png?resize=680,489 680w, https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-15-at-12.25.31 https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/AM.png?resize=1200,864 1200w, https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-15-at-12.25.31 https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/AM.png?resize=50,36 50w" sizes="(max-width: 1024px) 100vw, 1024px"></p><p id="caption-attachment-2679804"><strong>Image Credits:</strong> OpenAI</p></div>
<p>A search for “Elon Musk,” “Donald Trump,” “Leonardo DiCaprio,” “Barack Obama” and “Joe Rogan” yields dozens of GPTs — some obviously satirical, some less so — that simulate conversations with their namesakes. Some GPTs present themselves not as people, but as authorities on well-known companies’ products — like MicrosoftGPT, an “expert in all things Microsoft.”</p>
<div id="attachment_2680036"><p><img loading="lazy" decoding="async" aria-describedby="caption-attachment-2680036" src="https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-16-at-10.07.45%E2%80%AFAM.png" alt="" width="1506" height="1084" srcset="https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-16-at-10.07.45 https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/AM.png 1506w, https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-16-at-10.07.45 https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/AM.png?resize=150,108 150w, https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-16-at-10.07.45 https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/AM.png?resize=300,216 300w, https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-16-at-10.07.45 https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/AM.png?resize=768,553 768w, https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-16-at-10.07.45 https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/AM.png?resize=680,489 680w, https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-16-at-10.07.45 https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/AM.png?resize=1200,864 1200w, https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-16-at-10.07.45 https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/AM.png?resize=50,36 50w" sizes="(max-width: 1506px) 100vw, 1506px"></p><p id="caption-attachment-2680036"><strong>Image Credits:</strong> OpenAI</p></div>
<p>Do these rise to the level of impersonation given that many of the targets are public figures and, in some cases, clearly parodies? That’s for OpenAI to clarify.</p>
<p>The spokesperson said:</p>
<blockquote><p>We allow creators to instruct their GPTs to respond ‘in the style of’ a specific real person so long as they don’t impersonate them, such as being named as a real person, being instructed to fully emulate them, and including their image as a GPT profile picture.</p></blockquote>
<div id="attachment_2679803"><p><img loading="lazy" decoding="async" aria-describedby="caption-attachment-2679803" src="https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-15-at-12.16.20%E2%80%AFAM.png" alt="OpenAI GPT Store spam" width="1024" height="737" srcset="https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-15-at-12.16.20 https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/AM.png 1506w, https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-15-at-12.16.20 https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/AM.png?resize=150,108 150w, https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-15-at-12.16.20 https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/AM.png?resize=300,216 300w, https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-15-at-12.16.20 https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/AM.png?resize=768,553 768w, https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-15-at-12.16.20 https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/AM.png?resize=680,489 680w, https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-15-at-12.16.20 https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/AM.png?resize=1200,864 1200w, https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-15-at-12.16.20 https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/AM.png?resize=50,36 50w" sizes="(max-width: 1024px) 100vw, 1024px"></p><p id="caption-attachment-2679803"><strong>Image Credits:</strong> OpenAI</p></div>
<p>The company recently suspended the developer of a GPT mimicking long-shot Democratic presidential hopeful Rep. Dean Phillips, which went so far as to include a disclaimer explaining that it was an AI tool. But OpenAI said its removal in response to a violation of its policy on political campaigning <em>in addition to&nbsp;</em>impersonation — not impersonation alone.</p>
<h2>Jailbreaks</h2>
<p>Also somewhat incredulously on the GPT Store are attempts at jailbreaking OpenAI’s models — albeit not very successful ones.</p>
<p>There are multiple GPTs using DAN on the marketplace, DAN (short for “Do Anything Now”) being a popular prompting method used to get models to respond to prompts unbounded by their usual rules. The few I tested wouldn’t respond to <em>any</em> dicey prompt I threw their way (e.g. “how do I build a bomb?”), but they were generally more willing to use… well, <em>less-flattering</em> language than the vanilla ChatGPT.</p>
<div id="attachment_2679801"><p><img loading="lazy" decoding="async" aria-describedby="caption-attachment-2679801" src="https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-15-at-2.36.59%E2%80%AFAM.png" alt="OpenAI GPT Store spam" width="1024" height="737" srcset="https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-15-at-2.36.59 https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/AM.png 1506w, https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-15-at-2.36.59 https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/AM.png?resize=150,108 150w, https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-15-at-2.36.59 https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/AM.png?resize=300,216 300w, https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-15-at-2.36.59 https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/AM.png?resize=768,553 768w, https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-15-at-2.36.59 https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/AM.png?resize=680,489 680w, https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-15-at-2.36.59 https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/AM.png?resize=1200,864 1200w, https://techcrunch.com/wp-content/uploads/2024/03/Screenshot-2024-03-15-at-2.36.59 https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/AM.png?resize=50,36 50w" sizes="(max-width: 1024px) 100vw, 1024px"></p><p id="caption-attachment-2679801"><strong>Image Credits:</strong> OpenAI</p></div>
<p>The spokesperson said:</p>
<blockquote><p>GPTs that are described or instructed to evade OpenAI safeguards or break OpenAI policies are against our policy. GPTs that attempt to steer model behavior in other ways — including generally trying to make GPT more permissive without violating our usage policies — are allowed.</p></blockquote>
<h2>Growing pains</h2>
<p>OpenAI pitched the GPT Store at launch as a sort of expert-curated collection of powerful productivity-boosting AI tools. And it <em>is</em> that — those tools’ <a href="https://www.wsj.com/tech/ai/ai-is-tutoring-students-but-still-struggles-with-basic-math-694e76d3" target="_blank" rel="noopener">flaws aside</a>. But it’s also quickly devolving into a breeding ground for spammy, legally dubious and perhaps even harmful GPTs, or at least GPTs that very transparently runs afoul of its rules.</p>
<p>If this is the state of the GPT Store today, monetization threatens to open an entirely new can of worms. OpenAI has pledged that GPT developers will eventually be able to “earn money based on how many people are using [their] GPTs” and perhaps even offer subscriptions to individual GPTs. But how’s Disney or the Tolkien Estate going to react when the creators of unsanctioned Marvel- or Lord of the Rings-themed GPTs start raking in cash?</p>
<p>OpenAI’s motivation with the GPT Store is clear. As my colleague Devin Coldewey’s written, Apple’s App Store model has proven unbelievably lucrative, and OpenAI, quite simply, is trying to carbon copy it. GPTs are hosted and developed on OpenAI platforms, where they’re also promoted and evaluated. And, as of a few weeks ago, they can be invoked from the ChatGPT interface directly by ChatGPT Plus users, an added incentive to pick up a subscription.</p>
<p>But the GPT Store is running into the teething problems many of the largest-scale app, product and service digital marketplaces did in their early days. Beyond spam, a recent <a href="https://www.theinformation.com/articles/openais-chatbot-app-store-is-off-to-a-slow-start" target="_blank" rel="noopener">report</a> in The Information revealed that GPT Store developers are struggling to attract users in part because of the GPT Store’s limited back-end analytics and subpar onboarding experience.</p>
<p>One might’ve assumed OpenAI — for all its talk of curation and the importance of safeguards — would’ve taken pains to avoid the obvious pitfalls. But that doesn’t appear to be the case. The GPT Store is a mess — and, if something doesn’t change soon, it may well stay that way.</p>
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Introducing GNOME 46, "Kathmandu" (101 pts)]]></title>
            <link>https://release.gnome.org/46/</link>
            <guid>39769225</guid>
            <pubDate>Wed, 20 Mar 2024 16:58:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://release.gnome.org/46/">https://release.gnome.org/46/</a>, See on <a href="https://news.ycombinator.com/item?id=39769225">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <main aria-label="Content">
      <h2 id="introducing-gnome46-kathmandu">Introducing GNOME&nbsp;46, “Kathmandu”</h2>

<p><strong>March 20, 2024</strong></p>

<p>The GNOME project is excited to present the latest GNOME release, version 46. This latest version is the result of 6 month’s hard work by the GNOME community. Thank you to everyone who contributed!</p>

<p>GNOME 46 is code-named “Kathmandu”, in recognition of the amazing work done by the organizers of GNOME.Asia 2023.</p>

<p>Let’s dive in and explore what’s new in GNOME 46.</p>

<h2 id="search-everywhere">Search Everywhere</h2>

<p>Files comes with a <strong>new global search feature</strong> in GNOME 46. The feature is simple: activate it by clicking the new search button, or by using the <kbd>Ctrl</kbd>+<kbd>Shift</kbd>+<kbd>F</kbd> shortcut, then enter your query to search all your configured search locations.</p>

<p>Global search is a great way to jump directly into search, without having to think about where the items you want are located. The new feature also leverages GNOME’s existing file search capabilities, including the ability to search the contents of files, and filter by file type and modification date.</p>

<p>Another great thing about global search is that it makes it possible to search multiple locations simultaneously, which can include locations that aren’t in your home directory. To set this up, go to the newly refined search locations settings, and add the locations that you want to be included.</p>

<picture>
    <source media="(min-width: 800px) and (prefers-color-scheme: light)" srcset="https://release.gnome.org/46/search-everywhere-large.svg">
    <source media="(min-width: 800px) and (prefers-color-scheme: dark)" srcset="https://release.gnome.org/46/search-everywhere-large-dark.svg">
    <source media="(prefers-color-scheme: dark)" srcset="https://release.gnome.org/46/search-everywhere-dark.svg">
    <img src="https://release.gnome.org/46/search-everywhere.svg">
</picture>

<h2 id="enhanced-files-app">Enhanced Files App</h2>

<p>In addition to global search, the Files app has had a serious upgrade for GNOME 46. Feedback about long-running file operations has been improved, with a new dynamic progress section at the bottom of the sidebar. This makes it possible to view the progress of individual operations, as well as see which operations are ongoing and which have finished.</p>

<picture>
    <source srcset="https://release.gnome.org/46/file-ops-screenshot-dark.png" media="(prefers-color-scheme: dark)">
    <img src="https://release.gnome.org/46/file-ops-screenshot.png">
</picture>

<p>Significant code refactoring during the development of GNOME 46 has also delivered a welcome performance upgrade in the Files app. In the past, switching between list and grid view would involve a delay and content would progressively load on screen. In GNOME 46, this is gone: changing view is instantaneous, making for a faster and more frictionless experience.</p>

<video nocontrols="" muted="" autoplay="" loop="">
  <p>Files 46: Improved performance when switching from grid and list views. Files 45 used to reload the view each time.</p>
  <source src="https://release.gnome.org/46/files-46.webm" type="video/webm">
  <source src="https://release.gnome.org/46/files-46.mp4" type="video/mp4">
</video>

<p>Finally, Files in GNOME 46 also comes with a fantastic set of other smaller improvements:</p>

<ul>
  <li><strong>Search for preferences:</strong> you can now search within the Files preferences to locate specific settings.</li>
  <li><strong>Detailed date and time:</strong> the Files preferences now include an option to show the date and time in a more comprehensive and consistent format.</li>
  <li><strong>Location entry on click:</strong> quickly access the file location address bar by clicking on the file path area.</li>
  <li><strong>Starred favorites in grid view:</strong> quickly identify and access your starred files with visual markers in grid view.</li>
  <li><strong>Improved network discovery:</strong> more available networked devices now appear in the Other Locations view.</li>
</ul>

<p>We encourage you to explore the new features in Files and experience a whole new level of file management efficiency!</p>

<h2 id="upgraded-online-accounts-now-with-onedrive">Upgraded Online Accounts, Now With OneDrive</h2>

<p>GNOME’s Online Accounts feature have had a major upgrade for GNOME 46. The biggest improvement is the new <strong>support for Microsoft OneDrive</strong>. Setup a Microsoft 365 account from the settings, and your OneDrive will appear in the Files sidebar, where it can be easily browsed and accessed alongside your local files and folders.</p>

<p>A collection of additional improvements to Online Accounts have also been made, thanks to funding from the <a href="https://foundation.gnome.org/2023/11/09/gnome-recognized-as-public-interest-infrastructure/">Sovereign Tech Fund</a>:</p>

<ul>
  <li>The default web browser is now used when signing into accounts as part of account setup. This allows a <strong>wider range of authentication methods</strong> to be used, such as USB tokens.</li>
  <li>A <strong>new WebDAV account type</strong> has been added, providing a generic method for integrating online contacts, calendars and files into your GNOME experience.</li>
  <li>The Online Accounts <strong>settings have also had a complete revamp</strong>, and now have modern up to date designs.</li>
</ul>

<p>A necessary consequence of these changes is that Online Accounts are no longer included as part of the initial system setup assistant.</p>

<h2 id="remote-login-with-rdp">Remote Login with RDP</h2>

<p>GNOME’s remote desktop experience has been significantly enhanced for version 46, with the introduction of a new <strong>dedicated remote login option</strong>. This allows remotely connecting to a GNOME system which is not already in use. Connecting in this way means that the system’s display can be configured from the remote side, resulting in a better experience for the remote user.</p>

<p>The new remote login feature means that GNOME systems can be used as fully fledged remote resources. It can be found in the Remote Desktop settings, which provide information on how to connect.</p>

<picture>
    <source srcset="https://release.gnome.org/46/remote-screenshot-dark.png" media="(prefers-color-scheme: dark)">
    <img src="https://release.gnome.org/46/remote-screenshot.png">
</picture>

<h2 id="stepped-up-settings">Stepped-Up Settings</h2>

<p>The Settings app has received a comprehensive update in GNOME 46.</p>

<h3 id="navigation-improvements">Navigation Improvements</h3>

<p>The Settings app has been reorganized for GNOME 46, to make it <strong>easier to navigate</strong>. To this end, a new System section has been created, which contains preferences for <em>Region &amp; Language</em>, <em>Date &amp; Time</em>, <em>Users</em>, <em>Remote Desktop</em>, <em>Secure Shell</em>, and <em>About</em>. The Apps settings have also been consolidated, and now include the Default Apps and Removable Media settings.</p>

<p>These changes have the effect of reducing the total number of sections in the Settings app, giving you fewer places to browse and a faster path to the settings you need.</p>

<h3 id="new-touchpad-settings">New Touchpad Settings</h3>

<p>The touchpad settings have been expanded for GNOME 46, with two new settings. The first, called <strong>Secondary Click</strong> provides configuration for how secondary clicks (often called “right click”) are performed with a touchpad, and includes options to use either two fingers on the pad, or to click in the corner of the pad.</p>

<p>The second new setting allows the <strong>Disable Touchpad While Typing</strong> behavior to be turned off. Doing this allows touchpad movement to be combined with key presses, which can be necessary for some apps and games.</p>

<h3 id="massive-polish-effort">Massive Polish Effort</h3>

<p>The Settings app has also received a vast amount of polish for GNOME 46. This includes:</p>

<ul>
  <li>improved settings descriptions and tooltips</li>
  <li>more keyboard mnemonics, to enhance keyboard navigation (hold down Alt to see these)</li>
  <li>extensive UI modernization and refinement</li>
  <li>additional options for compose key assignment</li>
  <li>faster loading of the appearance settings, as well as sharper previews</li>
  <li>additional fine-grained control when setting Wacom stylus pressure</li>
</ul>

<p>Altogether, these improvements result in a Settings app which is clearer, easier to understand, and is fantastic to use.</p>

<h2 id="accessibility-improvements">Accessibility Improvements</h2>

<p>Accessibility has been a strong work theme for GNOME 46, with multiple aspects of accessibility seeing improvements. Much of this work has centered on the Orca screen reader:</p>

<ul>
  <li>Under the hood, a <strong>significant modernization effort</strong> has been under way. This will result in improved performance and reliability, and will enable compatibility with Wayland and sandboxed apps in the future.</li>
  <li>A <strong>new sleep mode</strong> feature has been added. This much requested feature allows users to temporarily disable Orca, using the <kbd>Ctrl</kbd>+<kbd>Alt</kbd>+<kbd>Shift</kbd>+<kbd>Q</kbd> shortcut. Sleep mode is useful when using virtual machines that have their own screen readers, as well as self-voicing apps.</li>
  <li>New commands allow Orca to <strong>report system status</strong>, including battery status, CPU and memory usage.</li>
  <li><strong>Table navigation</strong> has been much improved, with more apps being supported and new commands added, including toggle table navigation (<kbd>Orca</kbd>+<kbd>Shift</kbd>+<kbd>T</kbd>) and move to the final cell (<kbd>Orca</kbd>+<kbd>Alt</kbd>+<kbd>Shift</kbd>+<kbd>🡰</kbd>/<kbd>🡲</kbd>/<kbd>🡱</kbd>/<kbd>🡳</kbd>).</li>
  <li>Orca now has <strong>experimental support for Spiel</strong>, an exciting next generation speech synthesis API. Those who are interested in this feature are <a href="https://gitlab.gnome.org/GNOME/orca#experimental-features">invited to help test it</a>.</li>
</ul>

<p>Orca hasn’t been the only place where accessibility improvements have happened for GNOME 46. Other accessibility improvements include an <strong>high contrast mode</strong>  which is now more consistent and usable, and a <strong>new setting to show on and off symbols in switches</strong>.</p>

<p>Much of this accessibility work was funded by the <a href="https://foundation.gnome.org/2023/11/09/gnome-recognized-as-public-interest-infrastructure/">Sovereign Tech Fund</a> and <a href="https://www.igalia.com/">Igalia</a>.</p>

<h2 id="system-enhancements">System Enhancements</h2>

<p>GNOME 46 contains many small improvements and polish changes to the core GNOME experience:</p>

<ul>
  <li><strong>Beautiful fallback avatars:</strong> if you don’t specify an avatar for your user account, GNOME generates one for you. These fallback avatars have been refreshed for 46, and look fantastic. If you are upgrading from a previous version, clear out your old avatar to see the new default avatars in action.</li>
  <li><strong>Enhanced notifications:</strong> with improved layouts, and a new header in each notification to show which app sent it. It is now also possible to expand notifications in the list, in order to use notification actions at a time that suits you.</li>
</ul>

<p><img src="https://release.gnome.org/46/notifications-screenshot.png" alt="Enhanced Notifications"></p>

<ul>
  <li><strong>New app launching shortcuts:</strong> apps which have been pinned to the dash can now be launched using <kbd>Super</kbd>+<kbd>&lt;Number&gt;</kbd>. For example, <kbd>Super</kbd>+<kbd>1</kbd> will launch the first app in the dash. GNOME 46 includes additional shortcuts to allow launching a new window, by adding the <kbd>Ctrl</kbd> modifier, for example: <kbd>Super</kbd>+<kbd>Ctrl</kbd>+<kbd>&lt;Number&gt;</kbd> to launch a new window for the first app in the dash.</li>
  <li><strong>Improved on-screen keyboard:</strong> with automatic capitalization and new keyboard layouts for entering phone numbers, email addresses, and URLs.</li>
  <li><strong>Tap to click is now enabled by default:</strong> for a more intuitive touch experience.</li>
</ul>

<h2 id="better-apps">Better Apps</h2>

<p>Many of GNOME’s core apps have also been upgraded for GNOME 46. This includes:</p>

<ul>
  <li><strong>Improved Software app:</strong> this now shows verified badges for Flathub apps whose developers have been verified, ensuring a trusted source for your software. The Software app also has redesigned preferences, better error messages, and a new keyboard shortcuts window.</li>
  <li><strong>Various Maps enhancements:</strong>
    <ul>
      <li>An updated OpenStreetMap point of interest editing experience, as well as other user interface and routing improvements.</li>
      <li>New map style and support for dark mode</li>
      <li>Information about multiple floors is now shown for points of interest that have them</li>
      <li>Expanded public transit routing (now available for Norway)</li>
    </ul>
  </li>
  <li><strong>Redesigned Extensions app:</strong> a cleaner list makes it easier to scan and toggle your installed extensions, and the modernized design is also adaptive. It is now also possible to turn off extensions which have been automatically deactivated.</li>
  <li><strong>Polished Calendar app:</strong> with improved visuals, modernized interfaces, and performance improvements.</li>
  <li><strong>Quick timers in Clocks:</strong> when starting a timer, click a duration in the quick start section to quickly start a timer.</li>
  <li><strong>Smarter Contacts:</strong> multiple VCard files can now be imported at the same time and, when importing new contacts, the confirmation dialog will also helpfully preview the names of the contacts to import.</li>
  <li><strong>Monitor disk usage:</strong> Disks has gained a new resource graph for disk I/O.</li>
</ul>

<picture>
    <source srcset="https://release.gnome.org/46/software-screenshot-dark.png" media="(prefers-color-scheme: dark)">
    <img src="https://release.gnome.org/46/software-screenshot.png">
</picture>

<h2 id="improvements-under-the-hood">Improvements Under the Hood</h2>

<p>The improvements in GNOME 46 are not just skin deep, and the new version comes with deep technical enhancements which result in a more performant and refined experience.</p>

<ul>
  <li><strong>Performance and resource usage improvements</strong>, including reduced memory usage for search, enhanced screen recording performance, and more intelligent use of system resources by the image viewer app. There have also been significant speed improvements in GNOME’s terminal apps.</li>
  <li><strong>Security improvements</strong> include enhanced protection from malware in the image viewer app and GNOME’s search technologies.</li>
  <li><strong>Rendering improvements</strong> include sharper app interfaces, crisper on-screen text, and clearer UIs when using fractional display scales. These rendering improvements are thanks to GTK’s new renderers, and are found in GNOME apps which use the latest GTK version.</li>
  <li><strong>Variable refresh rates (VRR)</strong> is a feature which can, under some circumstances, produce smoother video performance. This is included in GNOME 46 as an experimental feature, which needs to be enabled by entering the following from the command line using: <code>gsettings set org.gnome.mutter experimental-features "['variable-refresh-rate']"</code>. Once enabled, a variable refresh rate can be set from the display settings.</li>
</ul>

<h2 id="welcome-circle-friends">Welcome, Circle Friends!</h2>

<p><a href="https://circle.gnome.org/">GNOME Circle</a> is a group of fantastic apps for GNOME, which the GNOME project promotes and supports. Since GNOME 45 was released, seven new apps have been added:</p>



<p>Welcome to these new members of the GNOME community!</p>

<h2 id="developer-experience">Developer Experience</h2>

<p>GNOME 46 includes new features and improvements for developers who are using the GNOME platform. Read the developers section to learn more.</p>

<ul>
  <li>
    <a href="https://release.gnome.org/46/developers/index.html"><span>What's New for Developers</span>
    <span>New features for those working with GNOME technologies.</span>
    </a>
  </li>
</ul>

<h2 id="getting-gnome-46">Getting GNOME 46</h2>

<p>GNOME’s software is <a href="https://gnu.org/philosophy/free-sw.html">Free Software</a>: all <a href="https://gitlab.gnome.org/GNOME">our code</a> is available for download and can be freely modified and redistributed according to the respective licenses. To install it, we recommend that you wait for the official packages provided by your vendor or distribution. Popular distributions will make GNOME 46 available very soon, and some already have development versions that include the new GNOME release. You can also try the <a href="https://os.gnome.org/">GNOME OS image</a> as a virtual machine, using the <a href="https://apps.gnome.org/Boxes/">Boxes</a> app.</p>

<h2 id="about-gnome">About GNOME</h2>

<p><a href="https://www.gnome.org/about/">The GNOME Project</a> is an international community supported by a non-profit Foundation. We focus on user experience excellence and first-class internationalization and accessibility. GNOME is a free and open project: if you want to join us, <a href="https://welcome.gnome.org/">you can</a>.</p>

    </main>
    
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Suspicious discontinuities (2020) (271 pts)]]></title>
            <link>https://danluu.com/discontinuities/</link>
            <guid>39768860</guid>
            <pubDate>Wed, 20 Mar 2024 16:31:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://danluu.com/discontinuities/">https://danluu.com/discontinuities/</a>, See on <a href="https://news.ycombinator.com/item?id=39768860">Hacker News</a></p>
<div id="readability-page-1" class="page"><div> <p>If you read any personal finance forums late last year, there's a decent chance you ran across a question from someone who was desperately trying to lose money before the end of the year. There are a number of ways someone could do this; one commonly suggested scheme was to buy <a href="https://en.wikipedia.org/wiki/Put_option">put options that were expected to expire worthless</a>, allowing the buyer to (probably) take a loss.</p> <p>One reason people were looking for ways to lose money was that, in the U.S., there's <a href="https://en.wikipedia.org/wiki/Patient_Protection_and_Affordable_Care_Act#Subsidy_Cliff_at_400%_FPL">a hard income cutoff for a health insurance subsidy</a> at $48,560 for individuals (higher for larger households; $100,400 for a family of four). There are a number of factors that can cause the details to vary (age, location, household size, type of plan), but across all circumstances, it wouldn't have been uncommon for an individual going from one side of the cut-off to the other to have their health insurance cost increase by roughly $7200/yr. That means if an individual buying ACA insurance was going to earn $55k, they'd be better off reducing their income by $6440 and getting under the $48,560 subsidy ceiling than they are earning $55k.</p> <p>Although that's an unusually severe example, <a href="http://www.cbo.gov/sites/default/files/cbofiles/attachments/11-15-2012-MarginalTaxRates.pdf">U.S. tax policy is full of discontinuities that disincentivize increasing earnings and, in some cases, actually incentivize decreasing earnings</a>. Some other discontinuities are the <a href="https://en.wikipedia.org/wiki/Temporary_Assistance_for_Needy_Families">TANF</a> income limit, the <a href="https://en.wikipedia.org/wiki/Medicaid">Medicaid</a> income limit, the <a href="https://en.wikipedia.org/wiki/Children%27s_Health_Insurance_Program">CHIP</a> income limit for free coverage, and the CHIP income limit for reduced-cost coverage. These vary by location and circumstance; the TANF and Medicaid income limits fall into ranges generally considered to be "low income" and the CHIP limits fall into ranges generally considered to be "middle class". These subsidy discontinuities have the same impact as the ACA subsidy discontinuity -- at certain income levels, people are incentivized to lose money.</p> <blockquote> <p>Anyone may arrange his affairs so that his taxes shall be as low as possible; he is not bound to choose that pattern which best pays the treasury. There is not even a patriotic duty to increase one's taxes. Over and over again the Courts have said that there is nothing sinister in so arranging affairs as to keep taxes as low as possible. Everyone does it, rich and poor alike and all do right, for nobody owes any public duty to pay more than the law demands.</p> </blockquote> <p>If you agree with the famous <a href="https://en.wikipedia.org/wiki/Learned_Hand">Learned Hand</a> quote then losing money in order to reduce effective tax rate, increasing disposable income, is completely legitimate behavior at the individual level. However, a tax system that encourages people to lose money, perhaps by funneling it to (on average) much wealthier options traders by buying put options, seems sub-optimal.</p> <p>A simple fix for the problems mentioned above would be to have slow phase-outs instead of sharp thresholds. Slow phase-outs are actually done for some subsidies and, while that can also have problems, they are typically less problematic than introducing a sharp discontinuity in tax/subsidy policy.</p> <p>In this post, we'll look at a variety of discontinuities.</p> <h3 id="hardware-or-software-queues">Hardware or software queues</h3> <p>A naive queue has discontinuous behavior. If the queue is full, new entries are dropped. If the queue isn't full, new entries are not dropped. Depending on your goals, this can often have impacts that are non-ideal. For example, in networking, a naive queue might be considered "unfair" to bursty workloads that have low overall bandwidth utilization because workloads that have low bandwidth utilization "shouldn't" suffer more drops than workloads that are less bursty but use more bandwidth (this is also arguably not unfair, depending on what your goals are).</p> <p>A class of solutions to this problem are <a href="https://en.wikipedia.org/wiki/Random_early_detection">random early drop</a> and its variants, which gives incoming items a probability of being dropped which can be determined by queue fullness (and possibly other factors), smoothing out the discontinuity and mitigating issues caused by having a discontinuous probability of queue drops.</p> <p><a href="https://danluu.com/randomize-hn/">This post on voting in link aggregators</a> is fundamentally the same idea although, in some sense, the polarity is reversed. There's a very sharp discontinuity in how much traffic something gets based on whether or not it's on the front page. You could view this as a link getting dropped from a queue if it only receives N-1 votes and not getting dropped if it receives N votes.</p> <h3 id="college-admissions-and-pell-grant-recipients-https-www-insidehighered-com-admissions-article-2019-01-28-study-pressure-enroll-more-pell-eligible-students-has-skewed-colleges"><a href="https://www.insidehighered.com/admissions/article/2019/01/28/study-pressure-enroll-more-pell-eligible-students-has-skewed-colleges">College admissions and Pell Grant recipients</a></h3> <p><a href="https://en.wikipedia.org/wiki/Pell_Grant">Pell Grants</a> started getting used as a proxy for how serious schools are about helping/admitting low-income students. The first order impact is that students above the Pell Grant threshold had a significantly reduced probability of being admitted while students below the Pell Grant threshold had a significantly higher chance of being admitted. Phrased that way, it sounds like things are working as intended.</p> <p>However, when we look at what happens within each group, we see outcomes that are the opposite of what we'd want if the goal is to benefit students from low income families. Among people who don't qualify for a Pell Grant, it's those with the lowest income who are the most severely impacted and have the most severely reduced probability of admission. Among people who do qualify, it's those with the highest income who are mostly likely to benefit, again the opposite of what you'd probably want if your goal is to benefit students from low income families.</p> <p>We can see these in the graphs below, which are histograms of parental income among students at two universities in 2008 (first graph) and 2016 (second graph), where the red line indicates the Pell Grant threshold.</p> <p><img src="https://danluu.com/images/discontinuities/pell-2008.jpg" alt="Histogram of income distribution of students at two universities in 2008; high incomes are highly overrepresented relative to the general population, but the distribution is smooth" height="816" width="1056"></p> <p><img src="https://danluu.com/images/discontinuities/pell-2016.jpg" alt="Histogram of income distribution of students at two universities in 2016; high incomes are still highly overrepresented, there's also a sharp discontinuity at the Pell grant threshold; plot looks roughly two upwards sloping piecewise linear functions, with a drop back to nearly 0 at the discontinuity at the Pell grant threshold" height="816" width="1056"></p> <p>A second order effect of universities optimizing for Pell Grant recipients is that savvy parents can do the same thing that some people do to cut their taxable income at the last minute. Someone might put money into a traditional IRA instead of a Roth IRA and, if they're at their IRA contribution limit, they can try to lose money on options, effectively transferring money to options traders who are likely to be wealthier than them, in order to bring their income below the Pell Grant threshold, increasing the probability that their children will be admitted to a selective school.</p> <h3 id="election-statistics-https-arxiv-org-pdf-1410-6059-pdf"><a href="https://arxiv.org/pdf/1410.6059.pdf">Election statistics</a></h3> <p>The following histograms of Russian elections across polling stations shows curious spikes in turnout and results at nice, round, numbers (e.g., 95%) starting around 2004. This appears to indicate that there's election fraud via fabricated results and that at least some of the people fabricating results don't bother with fabricating results that have a smooth distribution.</p> <p><img src="https://danluu.com/images/discontinuities/russian-elections.png" height="1418" width="1822"></p> <p>For finding fraudulent numbers, also see, <a href="https://en.wikipedia.org/wiki/Benford%27s_law">Benford's law</a>.</p> <h3 id="used-car-sale-prices-https-www-ftc-gov-sites-default-files-documents-public-events-3rd-annual-microeconomics-conference-lacetera-slide-pdf"><a href="https://www.ftc.gov/sites/default/files/documents/public_events/3rd-annual-microeconomics-conference/lacetera_slide.pdf">Used car sale prices</a></h3> <p><a href="https://twitter.com/ainsworld/status/1436418752409706519">Mark Ainsworth points out that there are discontinuities</a> at $10k boundaries in U.S. auto auction sales prices as well as volume of vehicles offered at auction. The price graph below adjusts for a number of factors such as model year, but we can see the same discontinuities in the raw unadjusted data.</p> <p><img src="https://danluu.com/images/discontinuities/car-prices.png" alt="Graph of car sales prices at auction, showing discontinuities described above" height="1670" width="942"></p> <p><img src="https://danluu.com/images/discontinuities/car-volumes.png" alt="Graph of car volumes at auction, showing discontinuities described above for dealer sales to auction but not fleet sales to auction" height="1710" width="992"></p> <h3 id="p-values-https-en-wikipedia-org-wiki-p-value"><a href="https://en.wikipedia.org/wiki/P-value">p-values</a></h3> <p>Authors of psychology papers are incentivized to produce papers with <a href="https://en.wikipedia.org/wiki/P-value">p values</a> below some threshold, usually 0.05, but sometimes 0.1 or 0.01. <a href="https://www.ncbi.nlm.nih.gov/pubmed/22853650">Masicampo et al. plotted p values from papers published in three psychology journals</a> and found a curiously high number of papers with p values just below 0.05.</p> <p><img src="https://danluu.com/images/discontinuities/p-value.png" alt="Histogram of published p-values; spike at p=0.05" height="1000" width="1874"></p> <p>The spike at p = 0.05 consistent with a number of hypothesis that aren't great, such as:</p> <ul> <li>Authors are fudging results to get p = 0.05</li> <li>Journals are much more likely to accept a paper with p = 0.05 than if p = 0.055</li> <li>Authors are much less likely to submit results if p = 0.055 than if p = 0.05</li> </ul> <p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4359000/">Head et al. (2015)</a> surveys the evidence across a number of fields.</p> <p>Andrew Gelman and others have been campaigning to get rid of the idea of statistical significance and p-value thresholds for years, <a href="https://stat.columbia.edu/~gelman/research/unpublished/abandon.pdf">see this paper for a short summary of why</a>. Not only would this reduce the incentive for authors to cheat on p values, there are other reasons to not want a bright-line rule to determine if something is "significant" or not.</p> <h3 id="drug-charges-http-econweb-umd-edu-tuttle-files-tuttle-mandatory-minimums-pdf"><a href="http://econweb.umd.edu/~tuttle/files/tuttle_mandatory_minimums.pdf">Drug charges</a></h3> <p>The top two graphs in this set of four show histograms of the amount of cocaine people were charged with possessing before and after the passing of the Fair Sentencing Act in 2010, which raised the amount of cocaine necessary to trigger the 10-year mandatory minimum prison sentence for possession from 50g to 280g. There's a relatively smooth distribution before 2010 and a sharp discontinuity after 2010.</p> <p>The bottom-left graph shows the sharp spike in prosecutions at 280 grams followed by what might be a drop in 2013 after evidentiary standards were changed<sup id="fnref:R"><a rel="footnote" href="#fn:R">1</a></sup>.</p> <p><img src="https://danluu.com/images/discontinuities/cocaine-280.png" height="1118" width="1408"></p> <h3 id="high-school-exit-exam-scores-danluu-com-matura-2013-pdf"><a href="https://danluu.com/matura-2013.pdf">High school exit exam scores</a></h3> <p>This is a histogram of high school exit exam scores from the Polish language exam. We can see that a curiously high number of students score 30 or just above thirty while curiously low number of students score from 23-29. This is from 2013; other years I've looked at (2010-2012) show a similar discontinuity.</p> <p>Math exit exam scores don't exhibit any unusual discontinuities in the years I've examined (2010-2013).</p> <p><img src="https://danluu.com/images/discontinuities/matura-polish-2013.png" height="772" width="1416"></p> <p><a href="https://www.reddit.com/r/dataisbeautiful/comments/1bqf9r/unusual_distributions_of_scores_on_final/c994zxt/">An anonymous reddit commenter explains this</a>:</p> <blockquote> <p>When a teacher is grading matura (final HS exam), he/she doesn't know whose test it is. The only things that are known are: the number (code) of the student and the district which matura comes from (it is usually from completely different part of Poland). The system is made to prevent any kind of manipulation, for example from time to time teachers supervisor will come to check if test are graded correctly. I don't wanna talk much about system flaws (and advantages), it is well known in every education system in the world where final tests are made, but you have to keep in mind that there is a key, which teachers follow very strictly when grading.</p> <p>So, when a score of the test is below 30%, exam is failed. However, before making final statement in protocol, a commision of 3 (I don't remember exact number) is checking test again. This is the moment, where difference between humanities and math is shown: teachers often try to find a one (or a few) missing points, so the test won't be failed, because it's a tragedy to this person, his school and somewhat fuss for the grading team. Finding a "missing" point is not that hard when you are grading writing or open questions, which is a case in polish language, but nearly impossible in math. So that's the reason why distribution of scores is so different.</p> </blockquote> <p>As with p values, having a bright-line threshold, causes curious behavior. In this case, scoring below 30 on any subject (a 30 or above is required in every subject) and failing the exam has arbitrary negative effects for people, so teachers usually try to prevent people from failing if there's an easy way to do it, but a deeper root of the problem is the idea that it's necessary to produce a certification that's the discretization of a continuous score.</p> <h3 id="birth-month-and-sports">Birth month and sports</h3> <p>These are scatterplots of football (soccer) players in the <a href="https://en.wikipedia.org/wiki/UEFA_Youth_League">UEFA Youth League</a>. The x-axis on both of these plots is how old players are modulo the year, i.e., their birth month normalized from 0 to 1.</p> <p>The graph on the left is a histogram, which shows that there is a very strong relationship between where a person's birth falls within the year and their odds of making a club at the UEFA Youth League (U19) level. The graph on the right purports to show that birth time is only weakly correlated with actual value provided on the field. The authors use playing time as a proxy for value, presumably because it's easy to measure. That's not a great measure, but the result they find (younger-within-the-year players have higher value, conditional on making the U19 league) is consistent with other studies on sports and discrimination, which ind (for example) that <a href="https://danluu.com/tech-discrimination/">black baseball players were significantly better than white baseball players for decades after desegregation in baseball, French-Canadian defensemen are also better than average (French-Canadians are stereotypically afraid to fight, don't work hard enough, and are too focused on offense)</a>.</p> <p>The discontinuity isn't directly shown in the graphs above because the graphs only show birth date for one year. If we were to plot birth date by cohort across multiple years, we'd expect to see a sawtooth pattern in the probability that a player makes it into the UEFA youth league with a 10x difference between someone born one day before vs. after the threshold.</p> <p><img src="https://danluu.com/images/discontinuities/u19-age.png" height="1030" width="1758"></p> <p>This phenomenon, that birth day or month is a good predictor of participation in higher-level youth sports as well as pro sports, has been studied across a variety of sports.</p> <p>It's generally believed that this is caused by a discontinuity in youth sports:</p> <ol> <li>Kids are bucketed into groups by age in years and compete against people in the same year</li> <li>Within a given year, older kids are stronger, faster, etc., and perform better</li> <li>This causes older-within-year kids to outcompete younger kids, which later results in older-within-year kids having higher levels of participation for a variety of reasons</li> </ol> <p>This is arguably a "bug" in how youth sports works. But <a href="https://danluu.com/bad-decisions/">as we've seen in baseball</a> <a href="https://danluu.com/tech-discrimination/">as well as a survey of multiple sports</a>, obviously bad decision making that costs individual teams tens or even hundreds of millions of dollars can persist for decades in the face of people pubicly discussing how bad the decisions are. In this case, the youth sports teams aren't feeder teams to pro teams, so they don't have a financial incentive to select players who are skilled for their age (as opposed to just taller and faster because they're slightly older) so this system-wide non-optimal even more difficult to fix than pro sports teams making locally non-optimal decisions that are completely under their control.</p> <h3 id="procurement-auctions-http-www-keikawai-com-full-0804-pdf"><a href="http://www.keikawai.com/Full_0804.pdf">Procurement auctions</a></h3> <p>Kawai et al. looked at Japanese government procurement, in order to find suspicious pattern of bids like the ones described in <a href="https://www.nber.org/papers/w4013">Porter et al. (1993)</a>, which looked at collusion in procurement auctions on Long Island (in New York in the United States). One example that's given is:</p> <blockquote> <p>In February 1983, the New York State Department of Transportation (DoT) held a pro- curement auction for resurfacing 0.8 miles of road. The lowest bid in the auction was $4 million, and the DoT decided not to award the contract because the bid was deemed too high relative to its own cost estimates. The project was put up for a reauction in May 1983 in which all the bidders from the initial auction participated. The lowest bid in the reauction was 20% higher than in the initial auction, submitted by the previous low bidder. Again, the contract was not awarded. The DoT held a third auction in February 1984, with the same set of bidders as in the initial auction. The lowest bid in the third auction was 10% higher than the second time, again submitted by the same bidder. The DoT apparently thought this was suspicious: “It is notable that the same firm submitted the low bid in each of the auctions. Because of the unusual bidding patterns, the contract was not awarded through 1987.”</p> </blockquote> <p>It could be argued that this is expected because different firms have different cost structures, so the lowest bidder in an auction for one particular project should be expected to be the lowest bidder in subsequent auctions for the same project. In order to distinguish between collusion and real structural cost differences between firms, Kawai et al. (2015) looked at auctions where the difference in bid between the first and second place firms was very small, making the winner effectively random.</p> <p>In the auction structure studied, bidders submit a secret bid. If the secret bid is above a secret minimum, then the lowest bidder wins the auction and gets the contract. If not, the lowest bid is revealed to all bidders and another round of bidding is done. Kawai et al. found that, in about 97% of auctions, the bidder who submitted the lowest bid in the first round also submitted the lowest bid in the second round (the probability that the second lowest bidder remains second lowest was 26%).</p> <p>Below, is a histogram of the difference in first and second round bids between the first-lowest and second-lowest bidders (left column) and the second-lowest and third-lowest bidders (right column). Each row has a different filtering criteria for how close the auction has to be in order to be included. In the top row, all auctions that reached the third round were included; in second, and third rows, the normalized delta between the first and second biders was less than 0.05 and 0.01, respectively; in the last row, the normalized delta between the first and the third bidder was less than 0.03. All numbers are normalized because the absolute size of auctions can vary.</p> <p><img src="https://danluu.com/images/discontinuities/jp-procurement-bidding.png" height="1446" width="1682"></p> <p>We can see that the distributions of deltas between the first and second round are roughly symmetrical when comparing second and third lowest bidders. But when comparing first and second lowest bidders, there's a sharp discontinuity at zero, indicating that second-lowest bidder almost never lowers their bid by more than the first-lower bidder did. If you read the paper, you can see that the same structure persists into auctions that go into a third round.</p> <p>I don't mean to pick on Japanese procurement auctions in particular. There's an extensive literature on procurement auctions that's found collusion in many cases, often much more blatant than the case presented above (e.g., there are a few firms and they round-robin who wins across auctions, or there are a handful of firms and every firm except for the winner puts in the same losing bid).</p> <h3 id="restaurant-inspection-https-iquantny-tumblr-com-post-76928412519-think-nyc-restaurant-grading-is-flawed-heres-scores-http-datafra-me-blog-calling-out-nyc-restaurant-violations"><a href="https://iquantny.tumblr.com/post/76928412519/think-nyc-restaurant-grading-is-flawed-heres">Restaurant inspection</a> <a href="http://datafra.me/blog/Calling-out-NYC-restaurant-violations">scores</a></h3> <p>The histograms below show a sharp discontinuity between 13 and 14, which is the difference between an A grade and a B grade. It appears that some regions also have a discontinuity between 27 and 28, which is the difference between a B and a C and <a href="https://iquantny.tumblr.com/post/76928412519/think-nyc-restaurant-grading-is-flawed-heres">this older analysis from 2014</a> found what appears to be a similar discontinuity between B and C grades.</p> <p><img src="https://danluu.com/images/discontinuities/nyc-restaurant-inspections.png" height="900" width="1260"></p> <p>Inspectors have discretion in what violations are tallied and it appears that there are cases where restaurant are nudged up to the next higher grade.</p> <h3 id="marathon-finishing-times-https-faculty-chicagobooth-edu-devin-pope-research-pdf-website-marathons-pdf"><a href="https://faculty.chicagobooth.edu/devin.pope/research/pdf/Website_Marathons.pdf">Marathon finishing times</a></h3> <p>A histogram of marathon finishing times (finish times on the x-axis, count on the y-axis) across 9,789,093 finishes shows noticeable discontinuities at every half hour, as well as at "round" times like :10, :15, and :20.</p> <p><img src="https://danluu.com/images/discontinuities/marathon-times.png" height="1094" width="1530"></p> <p>An analysis of times within each race (<a href="https://danluu.com/discontinuities/faculty.chicagobooth.edu/devin.pope/research/pdf/Website_Marathons.pdf">see section 4.4, figures 7-9</a>) indicates that this is at least partially because people speed up (or slow down less than usual) towards the end of races if they're close to a "round" time<sup id="fnref:M"><a rel="footnote" href="#fn:M">2</a></sup>.</p> <h3 id="notes">Notes</h3> <p>This post doesn't really have a goal or a point, it's just a collection of discontinuities that I find fun.</p> <p>One thing that's maybe worth noting is that I've gotten a lot of mileage out in my career both out of being suspicious of discontinuities and figuring out where they come from and also out of applying standard techniques to smooth out discontinuities.</p> <p>For finding discontinuities, basic tools like "drawing a scatterplot", "<a href="https://danluu.com/perf-tracing/#histogram">drawing a histogram</a>", "drawing the <a href="https://en.wikipedia.org/wiki/Cumulative_distribution_function">CDF</a>" often come in handy. Other kinds of visualizations that add temporality, like <a href="https://github.com/Netflix/flamescope">flamescope</a>, can also come in handy.</p> <p>We <a href="#hardware-or-software-queues">noted above that queues create a kind of discontinuity that, in some circumstances, should be smoothed out</a>. We also noted that we see similar behavior for other kinds of thresholds and that randomization can be a useful tool to smooth out discontinuities in thresholds as well. Randomization can also be used to allow for reducing quantization error when reducing precision with ML and in other applications.</p> <p><small>Thanks to Leah Hanson, Omar Rizwan, Dmitry Belenko, Kamal Marhubi, Danny Vilea, Nick Roberts, Lifan Zeng, Mark Ainsworth, Wesley Aptekar-Cassels, Thomas Hauk, @BaudDev, and Michael Sullivan for comments/corrections/discussion.</small></p> <p>Also, please feel free to <a href="https://twitter.com/danluu/status/1230595642390564866">send me other interesting discontinuities</a>! </p>   </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Parrots love playing tablet games. That's helping researchers understand them (113 pts)]]></title>
            <link>https://news.northeastern.edu/2024/03/20/parrots-playing-tablet-games/</link>
            <guid>39768604</guid>
            <pubDate>Wed, 20 Mar 2024 16:15:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://news.northeastern.edu/2024/03/20/parrots-playing-tablet-games/">https://news.northeastern.edu/2024/03/20/parrots-playing-tablet-games/</a>, See on <a href="https://news.ycombinator.com/item?id=39768604">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>








<p>Touchscreens have long been integral to our everyday life — humans use them to work, play, talk with loved ones and snag Lightning Deals on Prime Day. In recent years, they’ve shown potential for the animal kingdom as well, leading to a growing body of <a href="https://news.northeastern.edu/2023/04/21/parrots-talking-video-calls/">academic research</a> and a proliferation of consumer products promising to leverage technology to enhance our relationships with our pets.</p>



<p>Northeastern assistant professor <a href="https://www.interactanimallab.com/" target="_blank" rel="noreferrer noopener">Rébecca Kleinberger and her collaborators</a> have been at the forefront of that exploration, using computer interaction to enrich and understand the lives of dogs, orcas and parrots. Their latest research begs the next logical question: If animals are going to use touchscreens, how should we design for them?</p>



<div data-direction="90"><p><img decoding="async" width="1200" height="674" alt="A hyacinth macaw (blue parrot) tapping at a tablet screen with its tongue." src="https://news.northeastern.edu/wp-content/uploads/2024/03/03182024-parrotgame-4.gif" data-object-fit="cover"></p><div>
<p>Parrots are helping them find the answer — by playing tablet games.</p>
</div></div>



<p>In a new <a href="https://repository.library.northeastern.edu/files/neu:h989sd115" target="_blank" rel="noreferrer noopener">study </a>released Wednesday, Kleinberger; Megan McMahon, an undergraduate studying behavioral neuroscience; and collaborators Ilyena Hirskyj-Douglas at the University of Glasgow and Jennifer Cunha in Florida used a bare-bones, <a href="https://apps.apple.com/us/app/balloon-pop-toddler-baby-game/id1498726683" target="_blank" rel="noreferrer noopener">Balloon Pop</a>-style tablet game to collect data on a group of 20 pet birds’ tactile interactions with their touchscreens.</p>



<p>In doing so, they hoped to establish a framework to build tech intentionally designed for parrot use.</p>







<p>“Cognitive enrichment is a crucial component for parrot health and well-being, and tablet games are one method of providing this enrichment,” McMahon says. “Designing apps specifically made for birds and their unique touchscreen tendencies makes this form of enrichment more accessible.”</p>



<p>The parrot participants ranged from small species, like a green-cheeked parakeet, to a hyacinth macaw, the world’s largest. All had prior experience using touchscreens and completed the study in their homes. With the help of their caregivers, they learned to use a basic app game on Samsung Galaxy tablets. Adapted by McMahon, the game challenged the birds to <a href="https://www.youtube.com/watch?v=EY5GiklaplM" target="_blank" rel="noreferrer noopener">tap multi-colored target circles</a> of different sizes on varying locations around their screens with their beaks and tongues.</p>



<div>
<figure><img decoding="async" width="960" height="540" src="https://news.northeastern.edu/wp-content/uploads/2024/03/03182024-parrotgame-3.gif" alt="A gray parrot taps at an iPad with its tongue, popping balloons on the screen."></figure>
</div>



<p>The birds engaged in short sessions (no longer than 30 minutes) each day, playing the game over the course of three months. Seventeen completed the study; three dropped out after showing slight signs of aggression or a lack of interest during the training period. The game collected information on the birds’ accuracy, tap locations and frequency, as well as tactile elements like touch pressure and drag rate.</p>



<p>The team’s data evaluated how well existing, human-based touchscreen design principles translated to parrots. Specifically, they honed in on <a href="https://en.wikipedia.org/wiki/Fitts%27s_law" target="_blank" rel="noreferrer noopener">Fitts’ Law</a>, a formula that predicts human pointing movement toward targets.</p>



<p>Some of the paper’s findings are intuitive enough: Parrots primarily use their tongues to work tablets, for example, which means their eyes are much closer to the screen than a human’s. As a result, they are quantifiably less accurate, and they fare better hitting larger targets. There was also a lot of variability in performance based on the birds’ size — smaller birds tended to have more trouble.</p>



<div data-direction="90">
<figure><img decoding="async" width="1164" height="654" src="https://news.northeastern.edu/wp-content/uploads/2024/03/03182024-parrot_own_pace.gif?w=1100" alt="A white parrot flicking its tongue at a tablet screen to play a game."></figure>
</div>



<p>But the data-based assessment revealed much about the parrots themselves, as well. Kleinberger was surprised “just how fast some parrot species can control their tongue,” she says. “Some parrots could touch the tablet up to 41 times in a row, resulting in a touch every few milliseconds.”</p>



<p>That led to a real-time ergonomic adjustment: the team added a “multi-tap threshold” to the app’s interface during the study, making it less frustrating for the birds to use. “This …is a good example of how studying animals’ bodies can inform the design of new interfaces to empower animals,” Kleinberger says.</p>







<p>The findings, to be presented at the <a href="https://chi2024.acm.org/" target="_blank" rel="noreferrer noopener">CHI conference</a> on Human Factors in Computing Systems in May, signal a next step for Kleinberger and her collaborators. Their past research has shown that parrots — with their prodigious intelligence, high sociability and singular physical capabilities — are uniquely poised to benefit from touchscreen technology.</p>



<p>Last year, the team showed a group of parrots how to video call one another, finding that the birds both overwhelmingly enjoyed the activity and could make the calls themselves, when given the option.</p>



<div>
<figure><img decoding="async" width="854" height="480" src="https://news.northeastern.edu/wp-content/uploads/2024/03/multitouch40.gif" alt="A green parrot taps a red circle on a white screen that periodically changes location with its beak and tongue."></figure>
</div>



<p>The latest research further bolsters the case that touchscreens can enrich parrots’ lives. In surveys after the study was completed, human handlers said the experience was positive for their birds, and that participating in the study together was a great bonding experience. Kleinberger says that is by design. She stresses that the systems her lab is developing are meant for humans and animals to use together, and as an enhancement to their interactions rather than as a replacement.</p>



<p>As with humans and touchscreens, there are potential drawbacks — some familiar (“Participants in our study often emphasized the risk of their birds’ overuse, likening their screen time needs to those of children,” the paper reads); others uniquely avian (“When asked what risks tablet applications could pose to parrots, the most common answer was ‘potential damage to the tablet.’”)</p>



<p>In the longer term, the researchers hope the findings will serve as a starting point in adapting screen technologies for parrots and, eventually, other species. Kleinberger thinks it can bring some academic rigor to the booming “pet tech” market, “with new products promising to improve animal welfare with often very little data and research to back up the claims,” she says.</p>



<p>“My goal is for these insights not only to benefit the pet tech industry but also to offer valuable guidance to the wider research community, technology developers, [and] pet owners,” Kleinberger says.</p>






</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google Scholar PDF Reader (147 pts)]]></title>
            <link>https://scholar.googleblog.com/2024/03/supercharge-your-pdf-reading-follow.html</link>
            <guid>39768438</guid>
            <pubDate>Wed, 20 Mar 2024 16:03:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://scholar.googleblog.com/2024/03/supercharge-your-pdf-reading-follow.html">https://scholar.googleblog.com/2024/03/supercharge-your-pdf-reading-follow.html</a>, See on <a href="https://news.ycombinator.com/item?id=39768438">Hacker News</a></p>
<div id="readability-page-1" class="page">


<!-- Header -->
<div data-version="1" id="header">
<p><a href="https://scholar.googleblog.com/">
<img height="50" src="https://www.gstatic.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png">
</a></p><a href="https://scholar.googleblog.com/">
<h2>
             Scholar Blog
          </h2>
</a>
</div>
<!-- all content wrapper start -->
<div>
<div data-version="1" id="main">
<div data-id="5914581064908961872" itemscope="" itemtype="http://schema.org/BlogPosting">

<div>
<p><span itemprop="datePublished">
Monday, March 18, 2024
</span>
</p>
</div>

<p><span data-href="http://twitter.com/share?text=Google Scholar Blog:Supercharge your PDF reading: Follow references, skim outline, jump to figures&amp;url=https://scholar.googleblog.com/2024/03/supercharge-your-pdf-reading-follow.html&amp;via=google">
<img alt="Share on Twitter" height="24" src="https://www.gstatic.com/images/icons/material/system/2x/post_twitter_black_24dp.png" width="24">
</span>
<span data-href="https://www.facebook.com/sharer.php?u=https://scholar.googleblog.com/2024/03/supercharge-your-pdf-reading-follow.html">
<img alt="Share on Facebook" height="24" src="https://www.gstatic.com/images/icons/material/system/2x/post_facebook_black_24dp.png" width="24">
</span>
</p>


</div>
<div id="blog-pager">
<p><a href="https://scholar.googleblog.com/">
<i>
                      
                    </i>
</a>
<i>
                      
                    </i>
<span id="blog-pager-older-link">
<a href="https://scholar.googleblog.com/2023/07/2023-scholar-metrics-released.html" id="Blog1_blog-pager-older-link" title="Older Post">
<i>
                          
                        </i>
</a>
</span>
</p></div>

</div>
<div>

<div id="aside">
<div data-version="1" id="BlogArchive1">
<div>
<p><i>
                      
                    </i></p><h2>
Archive
</h2>
<p><i>
                      
                    </i>
</p></div>
<div id="ArchiveList">
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2024/">
2024
</a>
</p></div>
<div>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2024/03/">
March
</a>
</p></div>
<div>
<ul>
<li>
<a href="https://scholar.googleblog.com/2024/03/supercharge-your-pdf-reading-follow.html">
Supercharge your PDF reading: Follow references, s...
</a>
</li>
</ul>
</div>
</li>
</ul>
</div>
</li>
</ul>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2023/">
2023
</a>
</p></div>
<div>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2023/07/">
July
</a>
</p></div>

</li>
</ul>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2023/04/">
April
</a>
</p></div>

</li>
</ul>
</div>
</li>
</ul>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2022/">
2022
</a>
</p></div>
<div>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2022/06/">
June
</a>
</p></div>

</li>
</ul>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2022/01/">
January
</a>
</p></div>

</li>
</ul>
</div>
</li>
</ul>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2021/">
2021
</a>
</p></div>
<div>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2021/07/">
July
</a>
</p></div>

</li>
</ul>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2021/03/">
March
</a>
</p></div>

</li>
</ul>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2021/02/">
February
</a>
</p></div>

</li>
</ul>
</div>
</li>
</ul>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2020/">
2020
</a>
</p></div>
<div>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2020/09/">
September
</a>
</p></div>

</li>
</ul>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2020/07/">
July
</a>
</p></div>

</li>
</ul>
</div>
</li>
</ul>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2019/">
2019
</a>
</p></div>
<div>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2019/07/">
July
</a>
</p></div>

</li>
</ul>
</div>
</li>
</ul>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2018/">
2018
</a>
</p></div>
<div>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2018/08/">
August
</a>
</p></div>

</li>
</ul>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2018/03/">
March
</a>
</p></div>

</li>
</ul>
</div>
</li>
</ul>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2017/">
2017
</a>
</p></div>
<div>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2017/10/">
October
</a>
</p></div>

</li>
</ul>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2017/09/">
September
</a>
</p></div>

</li>
</ul>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2017/08/">
August
</a>
</p></div>

</li>
</ul>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2017/07/">
July
</a>
</p></div>

</li>
</ul>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2017/06/">
June
</a>
</p></div>

</li>
</ul>
</div>
</li>
</ul>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2016/">
2016
</a>
</p></div>
<div>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2016/08/">
August
</a>
</p></div>

</li>
</ul>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2016/07/">
July
</a>
</p></div>

</li>
</ul>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2016/06/">
June
</a>
</p></div>

</li>
</ul>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2016/01/">
January
</a>
</p></div>

</li>
</ul>
</div>
</li>
</ul>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2015/">
2015
</a>
</p></div>
<div>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2015/06/">
June
</a>
</p></div>

</li>
</ul>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2015/01/">
January
</a>
</p></div>

</li>
</ul>
</div>
</li>
</ul>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2014/">
2014
</a>
</p></div>
<div>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2014/11/">
November
</a>
</p></div>

</li>
</ul>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2014/10/">
October
</a>
</p></div>

</li>
</ul>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2014/09/">
September
</a>
</p></div>

</li>
</ul>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2014/08/">
August
</a>
</p></div>

</li>
</ul>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2014/06/">
June
</a>
</p></div>

</li>
</ul>
</div>
</li>
</ul>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2013/">
2013
</a>
</p></div>
<div>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2013/11/">
November
</a>
</p></div>

</li>
</ul>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2013/07/">
July
</a>
</p></div>

</li>
</ul>
</div>
</li>
</ul>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2012/">
2012
</a>
</p></div>
<div>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2012/11/">
November
</a>
</p></div>

</li>
</ul>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2012/10/">
October
</a>
</p></div>

</li>
</ul>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2012/08/">
August
</a>
</p></div>

</li>
</ul>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2012/07/">
July
</a>
</p></div>

</li>
</ul>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2012/06/">
June
</a>
</p></div>

</li>
</ul>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2012/05/">
May
</a>
</p></div>

</li>
</ul>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2012/04/">
April
</a>
</p></div>

</li>
</ul>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2012/03/">
March
</a>
</p></div>

</li>
</ul>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2012/01/">
January
</a>
</p></div>

</li>
</ul>
</div>
</li>
</ul>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2011/">
2011
</a>
</p></div>
<div>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2011/11/">
November
</a>
</p></div>

</li>
</ul>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2011/08/">
August
</a>
</p></div>

</li>
</ul>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2011/07/">
July
</a>
</p></div>

</li>
</ul>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2011/06/">
June
</a>
</p></div>

</li>
</ul>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2011/02/">
February
</a>
</p></div>

</li>
</ul>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2011/01/">
January
</a>
</p></div>

</li>
</ul>
</div>
</li>
</ul>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2010/">
2010
</a>
</p></div>
<div>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2010/07/">
July
</a>
</p></div>

</li>
</ul>
<ul>
<li>
<div>
<p><span href="javascript:void(0)">
<i>
                    
                  </i>
</span>

<a href="https://scholar.googleblog.com/2010/06/">
June
</a>
</p></div>

</li>
</ul>
</div>
</li>
</ul>
</div>
</div><div data-version="1" id="HTML6">
<a href="http://googlescholar.blogspot.com/atom.xml">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAYAAABXAvmHAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAihJREFUeNrsWa9Pw0AU7viRMDFRBAkzJDMIBIhJJhCzk7NILIqMv4AEhdz+BCY3OYssAlGBoAJREpZwAlHEBO8lr8nSvNeVbu1dyX3JlzTrXfa+u/e9d7c5joWFhYVO1Fa8PwH2gK6m+BRwAvSlAdsrgr8E1jUuMH73GTAEzrkBWymTewZlihhLmgDXIAFuHgGVQOUF7OSYM1p6PgTuA1vAZlUEvAnPdapcMY0VICECekQ0XRfYrqoHsAGNgXfAoMomRiFDEhOZkkL3S88hMaB2LwXp0bj+ps2edpToZpjfoIDQtBeU+xjoDzP2G/gCPKZ5f8WsCAFJoJgOCcFdWSTeL9YQMSvTA1h9BkI5jaiXhLpSCL/8mVZY0UpyJ9ZdOkniu1dmJ96BpzQu9w6s28gcOq9j6pwLdR8/36NK5CQKwJSMrb2MhhSglBpt4UjsrdsnNu0B3J0HCozbCc4TjyY2srEgos/4RQljCzNxl4ireQD8FOq+T+W0mTB2g7njhlR+Sy2jsXFvU658U8YTbeaGpdIu7mWkEAq5ZtIjIhFZdtfX7QHckSvB2B6zC3VdAkZk0kAQwaXTk/CzTXK3wjIExCs6ZJpTnE4uY1KV+KzFzA3KTiFPENHJkOPcsfpLhwe4btoSuvUqAR+6TOxlCE6ZfKUsJLgsqGW8OpqAGx2X+sLxrwUog+JUeQRMDBIwyXOcnlPtPnL0/UsT/8LnOxYWFhZG4leAAQAAQHEaYuzHbAAAAABJRU5ErkJggg==">
<h2>Feed</h2>
</a>
</div></div>
</div>

</div>
<!-- Footer -->
<div id="google-footer">
<p><a href="https://www.google.com/">
<img height="36" src="data:image/png;base64,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" width="92">
</a></p><ul>
<li>
<a href="https://www.google.com/">
              Google
            </a>
</li>
<li>
<a href="https://www.google.com/policies/privacy/">
              Privacy
            </a>
</li>
<li>
<a href="https://www.google.com/policies/terms/">
              Terms
            </a>
</li>
</ul>
</div>






</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Flightradar24's new GPS jamming map (565 pts)]]></title>
            <link>https://www.flightradar24.com/blog/gps-jamming-map/</link>
            <guid>39768434</guid>
            <pubDate>Wed, 20 Mar 2024 16:03:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.flightradar24.com/blog/gps-jamming-map/">https://www.flightradar24.com/blog/gps-jamming-map/</a>, See on <a href="https://news.ycombinator.com/item?id=39768434">Hacker News</a></p>
Couldn't get https://www.flightradar24.com/blog/gps-jamming-map/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Multiple Stability AI researchers are departing, CEO says (121 pts)]]></title>
            <link>https://twitter.com/kenrickcai/status/1770474370278035775</link>
            <guid>39768361</guid>
            <pubDate>Wed, 20 Mar 2024 15:58:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/kenrickcai/status/1770474370278035775">https://twitter.com/kenrickcai/status/1770474370278035775</a>, See on <a href="https://news.ycombinator.com/item?id=39768361">Hacker News</a></p>
Couldn't get https://twitter.com/kenrickcai/status/1770474370278035775: Error: Request failed with status code 400]]></description>
        </item>
        <item>
            <title><![CDATA[Ethereum Foundation removes their canary (140 pts)]]></title>
            <link>https://github.com/ethereum/ethereum-foundation-website/commit/769b30603504b4b5e8f601f8014691a8d1821390</link>
            <guid>39768336</guid>
            <pubDate>Wed, 20 Mar 2024 15:55:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/ethereum/ethereum-foundation-website/commit/769b30603504b4b5e8f601f8014691a8d1821390">https://github.com/ethereum/ethereum-foundation-website/commit/769b30603504b4b5e8f601f8014691a8d1821390</a>, See on <a href="https://news.ycombinator.com/item?id=39768336">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-tab-size="8" data-diff-anchor="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192" data-paste-markdown-skip="">
                
                <tbody>
                      
      <tr data-position="0">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192HL1" data-line-number="..."></td>
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192HR1" data-line-number="..."></td>
    <td>@@ -1,4 +1,4 @@</td>
  </tr>

    <tr data-hunk="4149444f22fe8ca5d3add18ec7e7fb8f1a00f730a361a3373b42dc4c9a0aeafe">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L1" data-line-number="1"></td>

    <td></td>

  <td>
    <span data-code-marker="-"><span>@import</span> <span><span>'</span>styles/variables.scss<span>'</span></span>;</span></td>
</tr>




    <tr data-hunk="4149444f22fe8ca5d3add18ec7e7fb8f1a00f730a361a3373b42dc4c9a0aeafe">
    <td></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R1" data-line-number="1"></td>

  <td>
    <span data-code-marker="+"><span>@import</span> <span><span>"</span>styles/variables.scss<span>"</span></span>;</span></td>
</tr>




    <tr data-hunk="4149444f22fe8ca5d3add18ec7e7fb8f1a00f730a361a3373b42dc4c9a0aeafe">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L2" data-line-number="2"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R2" data-line-number="2"></td>

  <td>
    <span data-code-marker=" "><br></span></td>
</tr>




    <tr data-hunk="4149444f22fe8ca5d3add18ec7e7fb8f1a00f730a361a3373b42dc4c9a0aeafe">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L3" data-line-number="3"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R3" data-line-number="3"></td>

  <td>
    <span data-code-marker=" "><span>$footer-height</span>: <span>43<span>px</span></span>; <span><span>//</span> Can make this dynamic but probably overkill</span></span></td>
</tr>




    <tr data-hunk="4149444f22fe8ca5d3add18ec7e7fb8f1a00f730a361a3373b42dc4c9a0aeafe">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L4" data-line-number="4"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R4" data-line-number="4"></td>

  <td>
    <span data-code-marker=" "><br></span></td>
</tr>




      <tr data-position="6">
    <td colspan="2">
        <a href="#diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192" id="expand-link-6-diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192" aria-label="Expand All" data-url="/ethereum/ethereum-foundation-website/blob_excerpt/bf6bf506baf8212533e6d2f9a4ada228ae4465d2?diff=unified&amp;in_wiki_context=&amp;last_left=4&amp;last_right=4&amp;left=9&amp;left_hunk_size=7&amp;mode=100644&amp;path=src%2Fcomponents%2Ffooter%2FFooter.module.scss&amp;right=9&amp;right_hunk_size=8" data-left-range="5-5" data-right-range="5-5">
          
        </a>
        <tool-tip id="tooltip-22c12425-b74a-4a3b-99aa-d0663168edbc" for="expand-link-6-diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192" popover="manual" data-direction="ne" data-type="label" data-view-component="true">Expand All</tool-tip>
    </td>
    <td>@@ -9,7 +9,8 @@ $footer-height: 43px; // Can make this dynamic but probably overkill</td>
  </tr>

    <tr data-hunk="c2a08a53e2ce1872faaac9c34d1a7673a99cafffde167f248d03a08e9bccc600">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L9" data-line-number="9"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R9" data-line-number="9"></td>

  <td>
    <span data-code-marker=" ">  <span><span>z-index</span></span>: <span>3</span>;</span></td>
</tr>




    <tr data-hunk="c2a08a53e2ce1872faaac9c34d1a7673a99cafffde167f248d03a08e9bccc600">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L10" data-line-number="10"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R10" data-line-number="10"></td>

  <td>
    <span data-code-marker=" ">  <span><span>width</span></span>: <span>100<span>vw</span></span>;</span></td>
</tr>




    <tr data-hunk="c2a08a53e2ce1872faaac9c34d1a7673a99cafffde167f248d03a08e9bccc600">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L11" data-line-number="11"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R11" data-line-number="11"></td>

  <td>
    <span data-code-marker=" ">  <span>cursor</span>: <span>default</span>;</span></td>
</tr>




    <tr data-hunk="c2a08a53e2ce1872faaac9c34d1a7673a99cafffde167f248d03a08e9bccc600">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L12" data-line-number="12"></td>

    <td></td>

  <td>
    <span data-code-marker="-">  <span><span>transition</span></span>: <span>height</span> <span>0.2<span>s</span></span> <span>ease-out</span>, <span>max-height</span> <span>0.2<span>s</span></span> <span>ease-out</span>, <span>min-height</span> <span>0.2<span>s</span></span> <span>ease-out</span>;</span></td>
</tr>




    <tr data-hunk="c2a08a53e2ce1872faaac9c34d1a7673a99cafffde167f248d03a08e9bccc600">
    <td></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R12" data-line-number="12"></td>

  <td>
    <span data-code-marker="+">  <span><span>transition</span></span>: <span>height</span> <span>0.2<span>s</span></span> <span>ease-out</span>, <span>max-height</span> <span>0.2<span>s</span></span> <span>ease-out</span>,</span></td>
</tr>




    <tr data-hunk="c2a08a53e2ce1872faaac9c34d1a7673a99cafffde167f248d03a08e9bccc600">
    <td></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R13" data-line-number="13"></td>

  <td>
    <span data-code-marker="+">    <span>min-height</span> <span>0.2<span>s</span></span> <span>ease-out</span>;</span></td>
</tr>




    <tr data-hunk="c2a08a53e2ce1872faaac9c34d1a7673a99cafffde167f248d03a08e9bccc600">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L13" data-line-number="13"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R14" data-line-number="14"></td>

  <td>
    <span data-code-marker=" ">  <span><span>color</span></span>: <span>white</span>;</span></td>
</tr>




    <tr data-hunk="c2a08a53e2ce1872faaac9c34d1a7673a99cafffde167f248d03a08e9bccc600">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L14" data-line-number="14"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R15" data-line-number="15"></td>

  <td>
    <span data-code-marker=" ">  <span><span>font-size</span></span>: <span>$small</span>;</span></td>
</tr>




    <tr data-hunk="c2a08a53e2ce1872faaac9c34d1a7673a99cafffde167f248d03a08e9bccc600">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L15" data-line-number="15"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R16" data-line-number="16"></td>

  <td>
    <span data-code-marker=" ">  <span><span>font-family</span></span>: <span>$font-primary</span>;</span></td>
</tr>




      <tr data-position="16">
    <td colspan="2">
        <a href="#diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192" id="expand-link-16-diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192" aria-label="Expand All" data-url="/ethereum/ethereum-foundation-website/blob_excerpt/bf6bf506baf8212533e6d2f9a4ada228ae4465d2?diff=unified&amp;in_wiki_context=&amp;last_left=15&amp;last_right=16&amp;left=24&amp;left_hunk_size=7&amp;mode=100644&amp;path=src%2Fcomponents%2Ffooter%2FFooter.module.scss&amp;right=25&amp;right_hunk_size=7" data-left-range="16-18" data-right-range="17-19">
          
        </a>
        <tool-tip id="tooltip-b9beb1ab-4163-4492-9647-f18e39d1782f" for="expand-link-16-diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192" popover="manual" data-direction="ne" data-type="label" data-view-component="true">Expand All</tool-tip>
    </td>
    <td>@@ -24,7 +25,7 @@ $footer-height: 43px; // Can make this dynamic but probably overkill</td>
  </tr>

    <tr data-hunk="6db3aa5c86db3012fb8ec00e18f8eb2a08556a1ccb23ef9b620fb6630fe10e67">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L24" data-line-number="24"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R25" data-line-number="25"></td>

  <td>
    <span data-code-marker=" ">      <span>.trigger</span> {</span></td>
</tr>




    <tr data-hunk="6db3aa5c86db3012fb8ec00e18f8eb2a08556a1ccb23ef9b620fb6630fe10e67">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L25" data-line-number="25"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R26" data-line-number="26"></td>

  <td>
    <span data-code-marker=" ">        <span>.chevron</span> {</span></td>
</tr>




    <tr data-hunk="6db3aa5c86db3012fb8ec00e18f8eb2a08556a1ccb23ef9b620fb6630fe10e67">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L26" data-line-number="26"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R27" data-line-number="27"></td>

  <td>
    <span data-code-marker=" ">          <span><span>//</span>transform: rotateX(180deg) translate3d(0, 0, 0) !important;</span></span></td>
</tr>




    <tr data-hunk="6db3aa5c86db3012fb8ec00e18f8eb2a08556a1ccb23ef9b620fb6630fe10e67">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L27" data-line-number="27"></td>

    <td></td>

  <td>
    <span data-code-marker="-">          <span><span>transform</span></span>:<span>rotateX</span>(<span>180<span>deg</span></span>) <span>translate3d</span>(<span>0</span>, <span>0</span>, <span>0</span>);</span></td>
</tr>




    <tr data-hunk="6db3aa5c86db3012fb8ec00e18f8eb2a08556a1ccb23ef9b620fb6630fe10e67">
    <td></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R28" data-line-number="28"></td>

  <td>
    <span data-code-marker="+">          <span><span>transform</span></span>:<span> </span><span>rotateX</span>(<span>180<span>deg</span></span>) <span>translate3d</span>(<span>0</span>, <span>0</span>, <span>0</span>);</span></td>
</tr>




    <tr data-hunk="6db3aa5c86db3012fb8ec00e18f8eb2a08556a1ccb23ef9b620fb6630fe10e67">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L28" data-line-number="28"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R29" data-line-number="29"></td>

  <td>
    <span data-code-marker=" ">        }</span></td>
</tr>




    <tr data-hunk="6db3aa5c86db3012fb8ec00e18f8eb2a08556a1ccb23ef9b620fb6630fe10e67">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L29" data-line-number="29"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R30" data-line-number="30"></td>

  <td>
    <span data-code-marker=" ">      }</span></td>
</tr>




    <tr data-hunk="6db3aa5c86db3012fb8ec00e18f8eb2a08556a1ccb23ef9b620fb6630fe10e67">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L30" data-line-number="30"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R31" data-line-number="31"></td>

  <td>
    <span data-code-marker=" "><br></span></td>
</tr>




      <tr data-position="25">
    <td colspan="2">
        <a href="#diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192" id="expand-link-25-diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192" aria-label="Expand All" data-url="/ethereum/ethereum-foundation-website/blob_excerpt/bf6bf506baf8212533e6d2f9a4ada228ae4465d2?diff=unified&amp;in_wiki_context=&amp;last_left=30&amp;last_right=31&amp;left=39&amp;left_hunk_size=7&amp;mode=100644&amp;path=src%2Fcomponents%2Ffooter%2FFooter.module.scss&amp;right=40&amp;right_hunk_size=7" data-left-range="31-33" data-right-range="32-34">
          
        </a>
        <tool-tip id="tooltip-edc2dfbd-a256-4cdc-8575-caf912c07b99" for="expand-link-25-diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192" popover="manual" data-direction="ne" data-type="label" data-view-component="true">Expand All</tool-tip>
    </td>
    <td>@@ -39,7 +40,7 @@ $footer-height: 43px; // Can make this dynamic but probably overkill</td>
  </tr>

    <tr data-hunk="6b25516928b15bb5ba06779905fce63c1be96eade7cac4fe5f0135c88be5dbf3">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L39" data-line-number="39"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R40" data-line-number="40"></td>

  <td>
    <span data-code-marker=" ">    <span><span>transition</span></span>: <span>all</span> <span>0.2<span>s</span></span> <span>ease-out</span>;</span></td>
</tr>




    <tr data-hunk="6b25516928b15bb5ba06779905fce63c1be96eade7cac4fe5f0135c88be5dbf3">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L40" data-line-number="40"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R41" data-line-number="41"></td>

  <td>
    <span data-code-marker=" ">    <span><span>background</span></span>: <span>$footer-color</span>;</span></td>
</tr>




    <tr data-hunk="6b25516928b15bb5ba06779905fce63c1be96eade7cac4fe5f0135c88be5dbf3">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L41" data-line-number="41"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R42" data-line-number="42"></td>

  <td>
    <span data-code-marker=" ">    <span><span>opacity</span></span>: <span>0.5</span>;</span></td>
</tr>




    <tr data-hunk="6b25516928b15bb5ba06779905fce63c1be96eade7cac4fe5f0135c88be5dbf3">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L42" data-line-number="42"></td>

    <td></td>

  <td>
    <span data-code-marker="-">    <span><span>height</span></span>:<span>45<span>px</span></span>;</span></td>
</tr>




    <tr data-hunk="6b25516928b15bb5ba06779905fce63c1be96eade7cac4fe5f0135c88be5dbf3">
    <td></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R43" data-line-number="43"></td>

  <td>
    <span data-code-marker="+">    <span><span>height</span></span>:<span> </span><span>45<span>px</span></span>;</span></td>
</tr>




    <tr data-hunk="6b25516928b15bb5ba06779905fce63c1be96eade7cac4fe5f0135c88be5dbf3">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L43" data-line-number="43"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R44" data-line-number="44"></td>

  <td>
    <span data-code-marker=" "><br></span></td>
</tr>




    <tr data-hunk="6b25516928b15bb5ba06779905fce63c1be96eade7cac4fe5f0135c88be5dbf3">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L44" data-line-number="44"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R45" data-line-number="45"></td>

  <td>
    <span data-code-marker=" ">    <span>.trigger</span> {</span></td>
</tr>




    <tr data-hunk="6b25516928b15bb5ba06779905fce63c1be96eade7cac4fe5f0135c88be5dbf3">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L45" data-line-number="45"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R46" data-line-number="46"></td>

  <td>
    <span data-code-marker=" ">      <span><span>z-index</span></span>: <span>2</span>;</span></td>
</tr>




      <tr data-position="34">
    <td colspan="2">
          <a href="#diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192" id="expand-down-link-34-diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192" aria-label="Expand Down" data-url="/ethereum/ethereum-foundation-website/blob_excerpt/bf6bf506baf8212533e6d2f9a4ada228ae4465d2?diff=unified&amp;direction=down&amp;in_wiki_context=&amp;last_left=45&amp;last_right=46&amp;left=93&amp;left_hunk_size=8&amp;mode=100644&amp;path=src%2Fcomponents%2Ffooter%2FFooter.module.scss&amp;right=94&amp;right_hunk_size=6" data-left-range="46-68" data-right-range="47-69">
            
          </a>
          <tool-tip id="tooltip-28a7c447-505b-44b8-b302-ed2a135e2441" for="expand-down-link-34-diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192" popover="manual" data-direction="ne" data-type="label" data-view-component="true">Expand Down</tool-tip>
          <a href="#diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192" id="expand-up-link-34-diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192" aria-label="Expand Up" data-url="/ethereum/ethereum-foundation-website/blob_excerpt/bf6bf506baf8212533e6d2f9a4ada228ae4465d2?diff=unified&amp;direction=up&amp;in_wiki_context=&amp;last_left=45&amp;last_right=46&amp;left=93&amp;left_hunk_size=8&amp;mode=100644&amp;path=src%2Fcomponents%2Ffooter%2FFooter.module.scss&amp;right=94&amp;right_hunk_size=6" data-left-range="69-92" data-right-range="70-93">
            
          </a>
          <tool-tip id="tooltip-d7f5344e-f0ca-46a4-b10d-112e4fa2b138" for="expand-up-link-34-diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192" popover="manual" data-direction="ne" data-type="label" data-view-component="true">Expand Up</tool-tip>
    </td>
    <td>@@ -93,8 +94,6 @@ $footer-height: 43px; // Can make this dynamic but probably overkill</td>
  </tr>

    <tr data-hunk="eefe54e01115a4f336602cc8fdd27ead1651ca4c94fd0d8b2875e8b9fb46bafb">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L93" data-line-number="93"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R94" data-line-number="94"></td>

  <td>
    <span data-code-marker=" ">      }</span></td>
</tr>




    <tr data-hunk="eefe54e01115a4f336602cc8fdd27ead1651ca4c94fd0d8b2875e8b9fb46bafb">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L94" data-line-number="94"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R95" data-line-number="95"></td>

  <td>
    <span data-code-marker=" "><br></span></td>
</tr>




    <tr data-hunk="eefe54e01115a4f336602cc8fdd27ead1651ca4c94fd0d8b2875e8b9fb46bafb">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L95" data-line-number="95"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R96" data-line-number="96"></td>

  <td>
    <span data-code-marker=" ">      <span>.scroll-wrapper</span> {</span></td>
</tr>




    <tr data-hunk="eefe54e01115a4f336602cc8fdd27ead1651ca4c94fd0d8b2875e8b9fb46bafb">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L96" data-line-number="96"></td>

    <td></td>

  <td>
    <span data-code-marker="-">        <span><span>display</span></span>: <span>flex</span>;</span></td>
</tr>




    <tr data-hunk="eefe54e01115a4f336602cc8fdd27ead1651ca4c94fd0d8b2875e8b9fb46bafb">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L97" data-line-number="97"></td>

    <td></td>

  <td>
    <span data-code-marker="-">        <span><span>flex-wrap</span></span>: <span>nowrap</span>;</span></td>
</tr>




    <tr data-hunk="eefe54e01115a4f336602cc8fdd27ead1651ca4c94fd0d8b2875e8b9fb46bafb">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L98" data-line-number="98"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R97" data-line-number="97"></td>

  <td>
    <span data-code-marker=" ">        <span><span>overflow</span></span>: <span>auto</span>;</span></td>
</tr>




    <tr data-hunk="eefe54e01115a4f336602cc8fdd27ead1651ca4c94fd0d8b2875e8b9fb46bafb">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L99" data-line-number="99"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R98" data-line-number="98"></td>

  <td>
    <span data-code-marker=" ">        <span><span>flex-grow</span></span>: <span>1</span>;</span></td>
</tr>




    <tr data-hunk="eefe54e01115a4f336602cc8fdd27ead1651ca4c94fd0d8b2875e8b9fb46bafb">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L100" data-line-number="100"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R99" data-line-number="99"></td>

  <td>
    <span data-code-marker=" ">        <span><span>padding</span></span>: <span>0<span>px</span></span> <span>32<span>px</span></span>;</span></td>
</tr>




      <tr data-position="43">
    <td colspan="2">
        <a href="#diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192" id="expand-link-43-diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192" aria-label="Expand All" data-url="/ethereum/ethereum-foundation-website/blob_excerpt/bf6bf506baf8212533e6d2f9a4ada228ae4465d2?diff=unified&amp;in_wiki_context=&amp;last_left=100&amp;last_right=99&amp;left=110&amp;left_hunk_size=6&amp;mode=100644&amp;path=src%2Fcomponents%2Ffooter%2FFooter.module.scss&amp;right=109&amp;right_hunk_size=7" data-left-range="101-104" data-right-range="100-103">
          
        </a>
        <tool-tip id="tooltip-f73c90b5-1cef-49d7-8821-17e8c9ca5767" for="expand-link-43-diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192" popover="manual" data-direction="ne" data-type="label" data-view-component="true">Expand All</tool-tip>
    </td>
    <td>@@ -110,6 +109,7 @@ $footer-height: 43px; // Can make this dynamic but probably overkill</td>
  </tr>

    <tr data-hunk="b2a3460c7ef6ed9b1993ba07c2a1dd984feb4603f02566d7cd3c42c6a1a671c0">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L110" data-line-number="110"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R109" data-line-number="109"></td>

  <td>
    <span data-code-marker=" "><br></span></td>
</tr>




    <tr data-hunk="b2a3460c7ef6ed9b1993ba07c2a1dd984feb4603f02566d7cd3c42c6a1a671c0">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L111" data-line-number="111"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R110" data-line-number="110"></td>

  <td>
    <span data-code-marker=" ">      <span>.direction-wrapper</span> {</span></td>
</tr>




    <tr data-hunk="b2a3460c7ef6ed9b1993ba07c2a1dd984feb4603f02566d7cd3c42c6a1a671c0">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L112" data-line-number="112"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R111" data-line-number="111"></td>

  <td>
    <span data-code-marker=" ">        <span><span>display</span></span>: <span>flex</span>;</span></td>
</tr>




    <tr data-hunk="b2a3460c7ef6ed9b1993ba07c2a1dd984feb4603f02566d7cd3c42c6a1a671c0">
    <td></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R112" data-line-number="112"></td>

  <td>
    <span data-code-marker="+">        <span><span>justify-content</span></span>: <span>space-between</span>;</span></td>
</tr>




    <tr data-hunk="b2a3460c7ef6ed9b1993ba07c2a1dd984feb4603f02566d7cd3c42c6a1a671c0">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L113" data-line-number="113"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R113" data-line-number="113"></td>

  <td>
    <span data-code-marker=" ">        <span><span>flex-basis</span></span>: <span>50<span>%</span></span>;</span></td>
</tr>




    <tr data-hunk="b2a3460c7ef6ed9b1993ba07c2a1dd984feb4603f02566d7cd3c42c6a1a671c0">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L114" data-line-number="114"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R114" data-line-number="114"></td>

  <td>
    <span data-code-marker=" ">        <span><span>flex-shrink</span></span>: <span>0</span>;</span></td>
</tr>




    <tr data-hunk="b2a3460c7ef6ed9b1993ba07c2a1dd984feb4603f02566d7cd3c42c6a1a671c0">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L115" data-line-number="115"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R115" data-line-number="115"></td>

  <td>
    <span data-code-marker=" "><br></span></td>
</tr>




      <tr data-position="51">
    <td colspan="2">
          <a href="#diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192" id="expand-down-link-51-diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192" aria-label="Expand Down" data-url="/ethereum/ethereum-foundation-website/blob_excerpt/bf6bf506baf8212533e6d2f9a4ada228ae4465d2?diff=unified&amp;direction=down&amp;in_wiki_context=&amp;last_left=115&amp;last_right=115&amp;left=163&amp;left_hunk_size=7&amp;mode=100644&amp;path=src%2Fcomponents%2Ffooter%2FFooter.module.scss&amp;right=163&amp;right_hunk_size=6" data-left-range="116-138" data-right-range="116-138">
            
          </a>
          <tool-tip id="tooltip-e0809bce-1297-4b13-9e41-44d10ef2b021" for="expand-down-link-51-diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192" popover="manual" data-direction="ne" data-type="label" data-view-component="true">Expand Down</tool-tip>
          <a href="#diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192" id="expand-up-link-51-diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192" aria-label="Expand Up" data-url="/ethereum/ethereum-foundation-website/blob_excerpt/bf6bf506baf8212533e6d2f9a4ada228ae4465d2?diff=unified&amp;direction=up&amp;in_wiki_context=&amp;last_left=115&amp;last_right=115&amp;left=163&amp;left_hunk_size=7&amp;mode=100644&amp;path=src%2Fcomponents%2Ffooter%2FFooter.module.scss&amp;right=163&amp;right_hunk_size=6" data-left-range="139-162" data-right-range="139-162">
            
          </a>
          <tool-tip id="tooltip-973b619d-4b2e-412b-82d8-5864e17da1b6" for="expand-up-link-51-diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192" popover="manual" data-direction="ne" data-type="label" data-view-component="true">Expand Up</tool-tip>
    </td>
    <td>@@ -163,7 +163,6 @@ $footer-height: 43px; // Can make this dynamic but probably overkill</td>
  </tr>

    <tr data-hunk="bef53451b765791d599398fea67071ab9fb44fee88be63db05cbdd80b152b9f8">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L163" data-line-number="163"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R163" data-line-number="163"></td>

  <td>
    <span data-code-marker=" ">            <span><span>flex-basis</span></span>: <span>100<span>%</span></span>;</span></td>
</tr>




    <tr data-hunk="bef53451b765791d599398fea67071ab9fb44fee88be63db05cbdd80b152b9f8">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L164" data-line-number="164"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R164" data-line-number="164"></td>

  <td>
    <span data-code-marker=" ">            <span><span>flex-shrink</span></span>: <span>0</span>;</span></td>
</tr>




    <tr data-hunk="bef53451b765791d599398fea67071ab9fb44fee88be63db05cbdd80b152b9f8">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L165" data-line-number="165"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R165" data-line-number="165"></td>

  <td>
    <span data-code-marker=" "><br></span></td>
</tr>




    <tr data-hunk="bef53451b765791d599398fea67071ab9fb44fee88be63db05cbdd80b152b9f8">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L166" data-line-number="166"></td>

    <td></td>

  <td>
    <span data-code-marker="-"><br></span></td>
</tr>




    <tr data-hunk="bef53451b765791d599398fea67071ab9fb44fee88be63db05cbdd80b152b9f8">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L167" data-line-number="167"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R166" data-line-number="166"></td>

  <td>
    <span data-code-marker=" ">            <span>@media</span> (<span><span>max-width</span></span>: <span>$breakpoint-1</span>) {</span></td>
</tr>




    <tr data-hunk="bef53451b765791d599398fea67071ab9fb44fee88be63db05cbdd80b152b9f8">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L168" data-line-number="168"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R167" data-line-number="167"></td>

  <td>
    <span data-code-marker=" ">              <span><span>display</span></span>: <span>contents</span>;</span></td>
</tr>




    <tr data-hunk="bef53451b765791d599398fea67071ab9fb44fee88be63db05cbdd80b152b9f8">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L169" data-line-number="169"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R168" data-line-number="168"></td>

  <td>
    <span data-code-marker=" ">            }</span></td>
</tr>




      <tr data-position="59">
    <td colspan="2">
          <a href="#diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192" id="expand-down-link-59-diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192" aria-label="Expand Down" data-url="/ethereum/ethereum-foundation-website/blob_excerpt/bf6bf506baf8212533e6d2f9a4ada228ae4465d2?diff=unified&amp;direction=down&amp;in_wiki_context=&amp;last_left=169&amp;last_right=168&amp;left=195&amp;left_hunk_size=7&amp;mode=100644&amp;path=src%2Fcomponents%2Ffooter%2FFooter.module.scss&amp;right=194&amp;right_hunk_size=6" data-left-range="170-181" data-right-range="169-180">
            
          </a>
          <tool-tip id="tooltip-af6467e9-2d61-473a-9906-d306638c42a7" for="expand-down-link-59-diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192" popover="manual" data-direction="ne" data-type="label" data-view-component="true">Expand Down</tool-tip>
          <a href="#diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192" id="expand-up-link-59-diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192" aria-label="Expand Up" data-url="/ethereum/ethereum-foundation-website/blob_excerpt/bf6bf506baf8212533e6d2f9a4ada228ae4465d2?diff=unified&amp;direction=up&amp;in_wiki_context=&amp;last_left=169&amp;last_right=168&amp;left=195&amp;left_hunk_size=7&amp;mode=100644&amp;path=src%2Fcomponents%2Ffooter%2FFooter.module.scss&amp;right=194&amp;right_hunk_size=6" data-left-range="182-194" data-right-range="181-193">
            
          </a>
          <tool-tip id="tooltip-c12d84f3-47d2-4f21-b29e-2f012df978fc" for="expand-up-link-59-diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192" popover="manual" data-direction="ne" data-type="label" data-view-component="true">Expand Up</tool-tip>
    </td>
    <td>@@ -195,7 +194,6 @@ $footer-height: 43px; // Can make this dynamic but probably overkill</td>
  </tr>

    <tr data-hunk="c3ed940b7d5bd6e1c2310e29f93578f4e8307ec2573ca43493f51ad17811d3ed">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L195" data-line-number="195"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R194" data-line-number="194"></td>

  <td>
    <span data-code-marker=" "><br></span></td>
</tr>




    <tr data-hunk="c3ed940b7d5bd6e1c2310e29f93578f4e8307ec2573ca43493f51ad17811d3ed">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L196" data-line-number="196"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R195" data-line-number="195"></td>

  <td>
    <span data-code-marker=" ">      <span>.contacts</span> {</span></td>
</tr>




    <tr data-hunk="c3ed940b7d5bd6e1c2310e29f93578f4e8307ec2573ca43493f51ad17811d3ed">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L197" data-line-number="197"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R196" data-line-number="196"></td>

  <td>
    <span data-code-marker=" ">        <span><span>display</span></span>: <span>flex</span>;</span></td>
</tr>




    <tr data-hunk="c3ed940b7d5bd6e1c2310e29f93578f4e8307ec2573ca43493f51ad17811d3ed">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L198" data-line-number="198"></td>

    <td></td>

  <td>
    <span data-code-marker="-">        <span><span>flex-grow</span></span>: <span>1</span>;</span></td>
</tr>




    <tr data-hunk="c3ed940b7d5bd6e1c2310e29f93578f4e8307ec2573ca43493f51ad17811d3ed">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L199" data-line-number="199"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R197" data-line-number="197"></td>

  <td>
    <span data-code-marker=" ">        <span><span>flex-shrink</span></span>: <span>0</span>;</span></td>
</tr>




    <tr data-hunk="c3ed940b7d5bd6e1c2310e29f93578f4e8307ec2573ca43493f51ad17811d3ed">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L200" data-line-number="200"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R198" data-line-number="198"></td>

  <td>
    <span data-code-marker=" ">        <span><span>flex-direction</span></span>: <span>column</span>;</span></td>
</tr>




    <tr data-hunk="c3ed940b7d5bd6e1c2310e29f93578f4e8307ec2573ca43493f51ad17811d3ed">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L201" data-line-number="201"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R199" data-line-number="199"></td>

  <td>
    <span data-code-marker=" ">        <span><span>font-size</span></span>: <span>$medium</span>;</span></td>
</tr>




      <tr data-position="67">
    <td colspan="2">
        <a href="#diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192" id="expand-link-67-diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192" aria-label="Expand All" data-url="/ethereum/ethereum-foundation-website/blob_excerpt/bf6bf506baf8212533e6d2f9a4ada228ae4465d2?diff=unified&amp;in_wiki_context=&amp;last_left=201&amp;last_right=199&amp;left=205&amp;left_hunk_size=9&amp;mode=100644&amp;path=src%2Fcomponents%2Ffooter%2FFooter.module.scss&amp;right=203&amp;right_hunk_size=8" data-left-range="202-202" data-right-range="200-200">
          
        </a>
        <tool-tip id="tooltip-944163c4-971e-4c33-92a5-a1907e36f76d" for="expand-link-67-diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192" popover="manual" data-direction="ne" data-type="label" data-view-component="true">Expand All</tool-tip>
    </td>
    <td>@@ -205,9 +203,8 @@ $footer-height: 43px; // Can make this dynamic but probably overkill</td>
  </tr>

    <tr data-hunk="f2e8532633eafc3bc2ca2dcdcc41691822bce278b0f112705061ca045eee9814">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L205" data-line-number="205"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R203" data-line-number="203"></td>

  <td>
    <span data-code-marker=" ">        <span>@media</span> (<span><span>max-width</span></span>: <span>$breakpoint-1</span>) {</span></td>
</tr>




    <tr data-hunk="f2e8532633eafc3bc2ca2dcdcc41691822bce278b0f112705061ca045eee9814">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L206" data-line-number="206"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R204" data-line-number="204"></td>

  <td>
    <span data-code-marker=" ">          <span><span>align-items</span></span>: <span>center</span>;</span></td>
</tr>




    <tr data-hunk="f2e8532633eafc3bc2ca2dcdcc41691822bce278b0f112705061ca045eee9814">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L207" data-line-number="207"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R205" data-line-number="205"></td>

  <td>
    <span data-code-marker=" "><br></span></td>
</tr>




    <tr data-hunk="f2e8532633eafc3bc2ca2dcdcc41691822bce278b0f112705061ca045eee9814">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L208" data-line-number="208"></td>

    <td></td>

  <td>
    <span data-code-marker="-">          <span>&amp;</span><span>:after</span>,</span></td>
</tr>




    <tr data-hunk="f2e8532633eafc3bc2ca2dcdcc41691822bce278b0f112705061ca045eee9814">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L209" data-line-number="209"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R206" data-line-number="206"></td>

  <td>
    <span data-code-marker=" ">          <span>&amp;</span><span>:before</span> {</span></td>
</tr>




    <tr data-hunk="f2e8532633eafc3bc2ca2dcdcc41691822bce278b0f112705061ca045eee9814">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L210" data-line-number="210"></td>

    <td></td>

  <td>
    <span data-code-marker="-">            <span>content</span>: <span><span>'</span><span>'</span></span>;</span></td>
</tr>




    <tr data-hunk="f2e8532633eafc3bc2ca2dcdcc41691822bce278b0f112705061ca045eee9814">
    <td></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R207" data-line-number="207"></td>

  <td>
    <span data-code-marker="+">            <span>content</span>: <span><span>"</span><span>"</span></span>;</span></td>
</tr>




    <tr data-hunk="f2e8532633eafc3bc2ca2dcdcc41691822bce278b0f112705061ca045eee9814">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L211" data-line-number="211"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R208" data-line-number="208"></td>

  <td>
    <span data-code-marker=" ">            <span><span>margin-bottom</span></span>: <span>18<span>px</span></span>;</span></td>
</tr>




    <tr data-hunk="f2e8532633eafc3bc2ca2dcdcc41691822bce278b0f112705061ca045eee9814">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L212" data-line-number="212"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R209" data-line-number="209"></td>

  <td>
    <span data-code-marker=" ">            <span><span>max-width</span></span>: <span>400<span>px</span></span>;</span></td>
</tr>




    <tr data-hunk="f2e8532633eafc3bc2ca2dcdcc41691822bce278b0f112705061ca045eee9814">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L213" data-line-number="213"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R210" data-line-number="210"></td>

  <td>
    <span data-code-marker=" ">            <span><span>margin-top</span></span>: <span>18<span>px</span></span>;</span></td>
</tr>




      <tr data-position="78">
    <td colspan="2">
        <a href="#diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192" id="expand-link-78-diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192" aria-label="Expand All" data-url="/ethereum/ethereum-foundation-website/blob_excerpt/bf6bf506baf8212533e6d2f9a4ada228ae4465d2?diff=unified&amp;in_wiki_context=&amp;last_left=213&amp;last_right=210&amp;left=218&amp;left_hunk_size=7&amp;mode=100644&amp;path=src%2Fcomponents%2Ffooter%2FFooter.module.scss&amp;right=215&amp;right_hunk_size=7" data-left-range="214-214" data-right-range="211-211">
          
        </a>
        <tool-tip id="tooltip-4387fefb-a8e0-4f2c-b08b-a654e7a1d9bf" for="expand-link-78-diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192" popover="manual" data-direction="ne" data-type="label" data-view-component="true">Expand All</tool-tip>
    </td>
    <td>@@ -218,7 +215,7 @@ $footer-height: 43px; // Can make this dynamic but probably overkill</td>
  </tr>

    <tr data-hunk="cd1eecd6529e0b56de924794b228bceb65f6679c788661779edf40b949a8ac3a">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L218" data-line-number="218"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R215" data-line-number="215"></td>

  <td>
    <span data-code-marker=" ">          }</span></td>
</tr>




    <tr data-hunk="cd1eecd6529e0b56de924794b228bceb65f6679c788661779edf40b949a8ac3a">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L219" data-line-number="219"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R216" data-line-number="216"></td>

  <td>
    <span data-code-marker=" ">        }</span></td>
</tr>




    <tr data-hunk="cd1eecd6529e0b56de924794b228bceb65f6679c788661779edf40b949a8ac3a">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L220" data-line-number="220"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R217" data-line-number="217"></td>

  <td>
    <span data-code-marker=" "><br></span></td>
</tr>




    <tr data-hunk="cd1eecd6529e0b56de924794b228bceb65f6679c788661779edf40b949a8ac3a">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L221" data-line-number="221"></td>

    <td></td>

  <td>
    <span data-code-marker="-">        &gt;<span>*</span> {</span></td>
</tr>




    <tr data-hunk="cd1eecd6529e0b56de924794b228bceb65f6679c788661779edf40b949a8ac3a">
    <td></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R218" data-line-number="218"></td>

  <td>
    <span data-code-marker="+">        &gt;<span> </span><span>*</span> {</span></td>
</tr>




    <tr data-hunk="cd1eecd6529e0b56de924794b228bceb65f6679c788661779edf40b949a8ac3a">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L222" data-line-number="222"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R219" data-line-number="219"></td>

  <td>
    <span data-code-marker=" ">          <span><span>margin-bottom</span></span>: <span>16<span>px</span></span>;</span></td>
</tr>




    <tr data-hunk="cd1eecd6529e0b56de924794b228bceb65f6679c788661779edf40b949a8ac3a">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L223" data-line-number="223"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R220" data-line-number="220"></td>

  <td>
    <span data-code-marker=" "><br></span></td>
</tr>




    <tr data-hunk="cd1eecd6529e0b56de924794b228bceb65f6679c788661779edf40b949a8ac3a">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L224" data-line-number="224"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R221" data-line-number="221"></td>

  <td>
    <span data-code-marker=" ">          <span>@media</span> (<span><span>max-width</span></span>: <span>$breakpoint-1</span>) {</span></td>
</tr>




      <tr data-position="87">
    <td colspan="2">
        <a href="#diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192" id="expand-link-87-diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192" aria-label="Expand All" data-url="/ethereum/ethereum-foundation-website/blob_excerpt/bf6bf506baf8212533e6d2f9a4ada228ae4465d2?diff=unified&amp;in_wiki_context=&amp;last_left=224&amp;last_right=221&amp;left=238&amp;left_hunk_size=40&amp;mode=100644&amp;path=src%2Fcomponents%2Ffooter%2FFooter.module.scss&amp;right=235&amp;right_hunk_size=11" data-left-range="225-230" data-right-range="222-227">
          
        </a>
        <tool-tip id="tooltip-1b3da711-00c4-416f-9b9e-28b877146bc6" for="expand-link-87-diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192" popover="manual" data-direction="ne" data-type="label" data-view-component="true">Expand All</tool-tip>
    </td>
    <td>@@ -238,40 +235,11 @@ $footer-height: 43px; // Can make this dynamic but probably overkill</td>
  </tr>

    <tr data-hunk="05ed6ca9ba27850267c40188d29768d5f93aba92283c71b59b90e11caf700743">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L238" data-line-number="238"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R235" data-line-number="235"></td>

  <td>
    <span data-code-marker=" ">          <span>.email</span> {</span></td>
</tr>




    <tr data-hunk="05ed6ca9ba27850267c40188d29768d5f93aba92283c71b59b90e11caf700743">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L239" data-line-number="239"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R236" data-line-number="236"></td>

  <td>
    <span data-code-marker=" ">            <span><span>display</span></span>: <span>block</span>;</span></td>
</tr>




    <tr data-hunk="05ed6ca9ba27850267c40188d29768d5f93aba92283c71b59b90e11caf700743">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L240" data-line-number="240"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R237" data-line-number="237"></td>

  <td>
    <span data-code-marker=" ">            <span><span>margin-top</span></span>: <span>4<span>px</span></span>;</span></td>
</tr>




    <tr data-hunk="05ed6ca9ba27850267c40188d29768d5f93aba92283c71b59b90e11caf700743">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L241" data-line-number="241"></td>

    <td></td>

  <td>
    <span data-code-marker="-">            <span><span>color</span></span>: <span>#<span>FFFFFF</span></span>;</span></td>
</tr>




    <tr data-hunk="05ed6ca9ba27850267c40188d29768d5f93aba92283c71b59b90e11caf700743">
    <td></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R238" data-line-number="238"></td>

  <td>
    <span data-code-marker="+">            <span><span>color</span></span>: <span>#<span>ffffff</span></span>;</span></td>
</tr>




    <tr data-hunk="05ed6ca9ba27850267c40188d29768d5f93aba92283c71b59b90e11caf700743">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L242" data-line-number="242"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R239" data-line-number="239"></td>

  <td>
    <span data-code-marker=" ">            <span><span>font-size</span></span>: <span>$small</span>;</span></td>
</tr>




    <tr data-hunk="05ed6ca9ba27850267c40188d29768d5f93aba92283c71b59b90e11caf700743">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L243" data-line-number="243"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R240" data-line-number="240"></td>

  <td>
    <span data-code-marker=" ">          }</span></td>
</tr>




    <tr data-hunk="05ed6ca9ba27850267c40188d29768d5f93aba92283c71b59b90e11caf700743">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L244" data-line-number="244"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R241" data-line-number="241"></td>

  <td>
    <span data-code-marker=" ">        }</span></td>
</tr>




    <tr data-hunk="05ed6ca9ba27850267c40188d29768d5f93aba92283c71b59b90e11caf700743">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L245" data-line-number="245"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R242" data-line-number="242"></td>

  <td>
    <span data-code-marker=" ">      }</span></td>
</tr>




    <tr data-hunk="05ed6ca9ba27850267c40188d29768d5f93aba92283c71b59b90e11caf700743">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L246" data-line-number="246"></td>

    <td></td>

  <td>
    <span data-code-marker="-"><br></span></td>
</tr>




    <tr data-hunk="05ed6ca9ba27850267c40188d29768d5f93aba92283c71b59b90e11caf700743">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L247" data-line-number="247"></td>

    <td></td>

  <td>
    <span data-code-marker="-">      <span>.canary</span> {</span></td>
</tr>




    <tr data-hunk="05ed6ca9ba27850267c40188d29768d5f93aba92283c71b59b90e11caf700743">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L248" data-line-number="248"></td>

    <td></td>

  <td>
    <span data-code-marker="-">        <span><span>flex-grow</span></span>: <span>1</span>;</span></td>
</tr>




    <tr data-hunk="05ed6ca9ba27850267c40188d29768d5f93aba92283c71b59b90e11caf700743">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L249" data-line-number="249"></td>

    <td></td>

  <td>
    <span data-code-marker="-">        <span><span>margin-bottom</span></span>: <span>12<span>px</span></span>;</span></td>
</tr>




    <tr data-hunk="05ed6ca9ba27850267c40188d29768d5f93aba92283c71b59b90e11caf700743">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L250" data-line-number="250"></td>

    <td></td>

  <td>
    <span data-code-marker="-">        <span><span>display</span></span>: <span>flex</span>;</span></td>
</tr>




    <tr data-hunk="05ed6ca9ba27850267c40188d29768d5f93aba92283c71b59b90e11caf700743">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L251" data-line-number="251"></td>

    <td></td>

  <td>
    <span data-code-marker="-">        <span><span>font-family</span></span>: <span>$font-primary</span>;</span></td>
</tr>




    <tr data-hunk="05ed6ca9ba27850267c40188d29768d5f93aba92283c71b59b90e11caf700743">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L252" data-line-number="252"></td>

    <td></td>

  <td>
    <span data-code-marker="-">        <span><span>padding-right</span></span>: <span>30<span>px</span></span>;</span></td>
</tr>




    <tr data-hunk="05ed6ca9ba27850267c40188d29768d5f93aba92283c71b59b90e11caf700743">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L253" data-line-number="253"></td>

    <td></td>

  <td>
    <span data-code-marker="-">        <span><span>line-height</span></span>: <span>1.6<span>em</span></span>;</span></td>
</tr>




    <tr data-hunk="05ed6ca9ba27850267c40188d29768d5f93aba92283c71b59b90e11caf700743">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L254" data-line-number="254"></td>

    <td></td>

  <td>
    <span data-code-marker="-"><br></span></td>
</tr>




    <tr data-hunk="05ed6ca9ba27850267c40188d29768d5f93aba92283c71b59b90e11caf700743">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L255" data-line-number="255"></td>

    <td></td>

  <td>
    <span data-code-marker="-">        <span>@media</span> (<span><span>max-width</span></span>: <span>$breakpoint-1</span>) {</span></td>
</tr>




    <tr data-hunk="05ed6ca9ba27850267c40188d29768d5f93aba92283c71b59b90e11caf700743">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L256" data-line-number="256"></td>

    <td></td>

  <td>
    <span data-code-marker="-">          <span><span>align-items</span></span>: <span>center</span>;</span></td>
</tr>




    <tr data-hunk="05ed6ca9ba27850267c40188d29768d5f93aba92283c71b59b90e11caf700743">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L257" data-line-number="257"></td>

    <td></td>

  <td>
    <span data-code-marker="-">          <span><span>flex-direction</span></span>: <span>column</span>;</span></td>
</tr>




    <tr data-hunk="05ed6ca9ba27850267c40188d29768d5f93aba92283c71b59b90e11caf700743">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L258" data-line-number="258"></td>

    <td></td>

  <td>
    <span data-code-marker="-">          <span><span>padding-right</span></span>: <span>0<span>px</span></span>;</span></td>
</tr>




    <tr data-hunk="05ed6ca9ba27850267c40188d29768d5f93aba92283c71b59b90e11caf700743">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L259" data-line-number="259"></td>

    <td></td>

  <td>
    <span data-code-marker="-">          <span><span>flex-grow</span></span>: <span>0</span>;</span></td>
</tr>




    <tr data-hunk="05ed6ca9ba27850267c40188d29768d5f93aba92283c71b59b90e11caf700743">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L260" data-line-number="260"></td>

    <td></td>

  <td>
    <span data-code-marker="-">          <span><span>text-align</span></span>: <span>center</span>;</span></td>
</tr>




    <tr data-hunk="05ed6ca9ba27850267c40188d29768d5f93aba92283c71b59b90e11caf700743">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L261" data-line-number="261"></td>

    <td></td>

  <td>
    <span data-code-marker="-"><br></span></td>
</tr>




    <tr data-hunk="05ed6ca9ba27850267c40188d29768d5f93aba92283c71b59b90e11caf700743">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L262" data-line-number="262"></td>

    <td></td>

  <td>
    <span data-code-marker="-">          <span>p</span> {</span></td>
</tr>




    <tr data-hunk="05ed6ca9ba27850267c40188d29768d5f93aba92283c71b59b90e11caf700743">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L263" data-line-number="263"></td>

    <td></td>

  <td>
    <span data-code-marker="-">            <span><span>max-width</span></span>: <span>400<span>px</span></span>;</span></td>
</tr>




    <tr data-hunk="05ed6ca9ba27850267c40188d29768d5f93aba92283c71b59b90e11caf700743">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L264" data-line-number="264"></td>

    <td></td>

  <td>
    <span data-code-marker="-">          }</span></td>
</tr>




    <tr data-hunk="05ed6ca9ba27850267c40188d29768d5f93aba92283c71b59b90e11caf700743">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L265" data-line-number="265"></td>

    <td></td>

  <td>
    <span data-code-marker="-"><br></span></td>
</tr>




    <tr data-hunk="05ed6ca9ba27850267c40188d29768d5f93aba92283c71b59b90e11caf700743">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L266" data-line-number="266"></td>

    <td></td>

  <td>
    <span data-code-marker="-">          <span>.icon</span> {</span></td>
</tr>




    <tr data-hunk="05ed6ca9ba27850267c40188d29768d5f93aba92283c71b59b90e11caf700743">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L267" data-line-number="267"></td>

    <td></td>

  <td>
    <span data-code-marker="-">            <span><span>margin-bottom</span></span>: <span>12<span>px</span></span>;</span></td>
</tr>




    <tr data-hunk="05ed6ca9ba27850267c40188d29768d5f93aba92283c71b59b90e11caf700743">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L268" data-line-number="268"></td>

    <td></td>

  <td>
    <span data-code-marker="-">          }</span></td>
</tr>




    <tr data-hunk="05ed6ca9ba27850267c40188d29768d5f93aba92283c71b59b90e11caf700743">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L269" data-line-number="269"></td>

    <td></td>

  <td>
    <span data-code-marker="-">        }</span></td>
</tr>




    <tr data-hunk="05ed6ca9ba27850267c40188d29768d5f93aba92283c71b59b90e11caf700743">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L270" data-line-number="270"></td>

    <td></td>

  <td>
    <span data-code-marker="-"><br></span></td>
</tr>




    <tr data-hunk="05ed6ca9ba27850267c40188d29768d5f93aba92283c71b59b90e11caf700743">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L271" data-line-number="271"></td>

    <td></td>

  <td>
    <span data-code-marker="-">        <span>.icon</span> {</span></td>
</tr>




    <tr data-hunk="05ed6ca9ba27850267c40188d29768d5f93aba92283c71b59b90e11caf700743">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L272" data-line-number="272"></td>

    <td></td>

  <td>
    <span data-code-marker="-">          <span><span>margin-right</span></span>: <span>12<span>px</span></span>;</span></td>
</tr>




    <tr data-hunk="05ed6ca9ba27850267c40188d29768d5f93aba92283c71b59b90e11caf700743">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L273" data-line-number="273"></td>

    <td></td>

  <td>
    <span data-code-marker="-">        }</span></td>
</tr>




    <tr data-hunk="05ed6ca9ba27850267c40188d29768d5f93aba92283c71b59b90e11caf700743">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L274" data-line-number="274"></td>

    <td></td>

  <td>
    <span data-code-marker="-">      }</span></td>
</tr>




    <tr data-hunk="05ed6ca9ba27850267c40188d29768d5f93aba92283c71b59b90e11caf700743">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L275" data-line-number="275"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R243" data-line-number="243"></td>

  <td>
    <span data-code-marker=" ">    }</span></td>
</tr>




    <tr data-hunk="05ed6ca9ba27850267c40188d29768d5f93aba92283c71b59b90e11caf700743">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L276" data-line-number="276"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R244" data-line-number="244"></td>

  <td>
    <span data-code-marker=" ">  }</span></td>
</tr>




    <tr data-hunk="05ed6ca9ba27850267c40188d29768d5f93aba92283c71b59b90e11caf700743">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L277" data-line-number="277"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R245" data-line-number="245"></td>

  <td>
    <span data-code-marker=" ">}</span></td>
</tr>




      <tr data-position="129">
    <td colspan="2">
        <a href="#diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192" id="expand-link-129-diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192" aria-label="Expand All" data-url="/ethereum/ethereum-foundation-website/blob_excerpt/bf6bf506baf8212533e6d2f9a4ada228ae4465d2?diff=unified&amp;in_wiki_context=&amp;last_left=277&amp;last_right=245&amp;left=282&amp;left_hunk_size=15&amp;mode=100644&amp;path=src%2Fcomponents%2Ffooter%2FFooter.module.scss&amp;right=250&amp;right_hunk_size=15" data-left-range="278-278" data-right-range="246-246">
          
        </a>
        <tool-tip id="tooltip-bfbff243-859e-4ec3-8017-6beaeafea162" for="expand-link-129-diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192" popover="manual" data-direction="ne" data-type="label" data-view-component="true">Expand All</tool-tip>
    </td>
    <td>@@ -282,15 +250,15 @@ $footer-height: 43px; // Can make this dynamic but probably overkill</td>
  </tr>

    <tr data-hunk="1d61e88023804b385065618877581f76b2338494ee3f99cd51420872d7d07dbc">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L282" data-line-number="282"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R250" data-line-number="250"></td>

  <td>
    <span data-code-marker=" ">  }</span></td>
</tr>




    <tr data-hunk="1d61e88023804b385065618877581f76b2338494ee3f99cd51420872d7d07dbc">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L283" data-line-number="283"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R251" data-line-number="251"></td>

  <td>
    <span data-code-marker=" "><br></span></td>
</tr>




    <tr data-hunk="1d61e88023804b385065618877581f76b2338494ee3f99cd51420872d7d07dbc">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L284" data-line-number="284"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R252" data-line-number="252"></td>

  <td>
    <span data-code-marker=" ">  <span>50%</span> {</span></td>
</tr>




    <tr data-hunk="1d61e88023804b385065618877581f76b2338494ee3f99cd51420872d7d07dbc">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L285" data-line-number="285"></td>

    <td></td>

  <td>
    <span data-code-marker="-">    <span><span>transform</span></span>: <span>translateX</span>(<span>-50<span>%</span></span>) <span>translateY</span>(<span>3<span>px</span></span>)</span></td>
</tr>




    <tr data-hunk="1d61e88023804b385065618877581f76b2338494ee3f99cd51420872d7d07dbc">
    <td></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R253" data-line-number="253"></td>

  <td>
    <span data-code-marker="+">    <span><span>transform</span></span>: <span>translateX</span>(<span>-50<span>%</span></span>) <span>translateY</span>(<span>3<span>px</span></span>)<span>;</span></span></td>
</tr>




    <tr data-hunk="1d61e88023804b385065618877581f76b2338494ee3f99cd51420872d7d07dbc">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L286" data-line-number="286"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R254" data-line-number="254"></td>

  <td>
    <span data-code-marker=" ">  }</span></td>
</tr>




    <tr data-hunk="1d61e88023804b385065618877581f76b2338494ee3f99cd51420872d7d07dbc">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L287" data-line-number="287"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R255" data-line-number="255"></td>

  <td>
    <span data-code-marker=" "><br></span></td>
</tr>




    <tr data-hunk="1d61e88023804b385065618877581f76b2338494ee3f99cd51420872d7d07dbc">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L288" data-line-number="288"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R256" data-line-number="256"></td>

  <td>
    <span data-code-marker=" ">  <span>100%</span> {</span></td>
</tr>




    <tr data-hunk="1d61e88023804b385065618877581f76b2338494ee3f99cd51420872d7d07dbc">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L289" data-line-number="289"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R257" data-line-number="257"></td>

  <td>
    <span data-code-marker=" ">    <span><span>transform</span></span>: <span>translateX</span>(<span>-50<span>%</span></span>) <span>translateY</span>(<span>-3<span>px</span></span>);</span></td>
</tr>




    <tr data-hunk="1d61e88023804b385065618877581f76b2338494ee3f99cd51420872d7d07dbc">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L290" data-line-number="290"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R258" data-line-number="258"></td>

  <td>
    <span data-code-marker=" ">  }</span></td>
</tr>




    <tr data-hunk="1d61e88023804b385065618877581f76b2338494ee3f99cd51420872d7d07dbc">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L291" data-line-number="291"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R259" data-line-number="259"></td>

  <td>
    <span data-code-marker=" ">}</span></td>
</tr>




    <tr data-hunk="1d61e88023804b385065618877581f76b2338494ee3f99cd51420872d7d07dbc">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L292" data-line-number="292"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R260" data-line-number="260"></td>

  <td>
    <span data-code-marker=" "><br></span></td>
</tr>




    <tr data-hunk="1d61e88023804b385065618877581f76b2338494ee3f99cd51420872d7d07dbc">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L293" data-line-number="293"></td>

    <td></td>

  <td>
    <span data-code-marker="-"><span><span>//</span> Scroll indicator<span> </span></span></span></td>
</tr>




    <tr data-hunk="1d61e88023804b385065618877581f76b2338494ee3f99cd51420872d7d07dbc">
    <td></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R261" data-line-number="261"></td>

  <td>
    <span data-code-marker="+"><span><span>//</span> Scroll indicator</span></span></td>
</tr>




    <tr data-hunk="1d61e88023804b385065618877581f76b2338494ee3f99cd51420872d7d07dbc">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L294" data-line-number="294"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R262" data-line-number="262"></td>

  <td>
    <span data-code-marker=" "><span>.scroll-indicator</span> {</span></td>
</tr>




    <tr data-hunk="1d61e88023804b385065618877581f76b2338494ee3f99cd51420872d7d07dbc">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L295" data-line-number="295"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R263" data-line-number="263"></td>

  <td>
    <span data-code-marker=" ">  <span><span>position</span></span>: <span>absolute</span>;</span></td>
</tr>




    <tr data-hunk="1d61e88023804b385065618877581f76b2338494ee3f99cd51420872d7d07dbc">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L296" data-line-number="296"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R264" data-line-number="264"></td>

  <td>
    <span data-code-marker=" ">  <span><span>bottom</span></span>: <span>80<span>px</span></span>;</span></td>
</tr>




      <tr data-position="147">
    <td colspan="2">
        <a href="#diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192" id="expand-link-147-diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192" aria-label="Expand All" data-url="/ethereum/ethereum-foundation-website/blob_excerpt/bf6bf506baf8212533e6d2f9a4ada228ae4465d2?diff=unified&amp;in_wiki_context=&amp;last_left=296&amp;last_right=264&amp;left=317&amp;left_hunk_size=7&amp;mode=100644&amp;path=src%2Fcomponents%2Ffooter%2FFooter.module.scss&amp;right=285&amp;right_hunk_size=7" data-left-range="297-305" data-right-range="265-273">
          
        </a>
        <tool-tip id="tooltip-56f3a2f9-2ce3-4127-83f1-063f7e3f8567" for="expand-link-147-diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192" popover="manual" data-direction="ne" data-type="label" data-view-component="true">Expand All</tool-tip>
    </td>
    <td>@@ -317,7 +285,7 @@ $footer-height: 43px; // Can make this dynamic but probably overkill</td>
  </tr>

    <tr data-hunk="da1f4e90ffdfc03f990b7a24571aafd5718726da7c5bb350c3edcd35c8fc2963">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L317" data-line-number="317"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R285" data-line-number="285"></td>

  <td>
    <span data-code-marker=" ">    <span><span>line-height</span></span>: <span>18<span>px</span></span>;</span></td>
</tr>




    <tr data-hunk="da1f4e90ffdfc03f990b7a24571aafd5718726da7c5bb350c3edcd35c8fc2963">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L318" data-line-number="318"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R286" data-line-number="286"></td>

  <td>
    <span data-code-marker=" ">    <span><span>text-align</span></span>: <span>center</span>;</span></td>
</tr>




    <tr data-hunk="da1f4e90ffdfc03f990b7a24571aafd5718726da7c5bb350c3edcd35c8fc2963">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L319" data-line-number="319"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R287" data-line-number="287"></td>

  <td>
    <span data-code-marker=" ">    <span><span>text-transform</span></span>: <span>uppercase</span>;</span></td>
</tr>




    <tr data-hunk="da1f4e90ffdfc03f990b7a24571aafd5718726da7c5bb350c3edcd35c8fc2963">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L320" data-line-number="320"></td>

    <td></td>

  <td>
    <span data-code-marker="-">    <span><span>color</span></span>: <span>#<span>36364C</span></span>;</span></td>
</tr>




    <tr data-hunk="da1f4e90ffdfc03f990b7a24571aafd5718726da7c5bb350c3edcd35c8fc2963">
    <td></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R288" data-line-number="288"></td>

  <td>
    <span data-code-marker="+">    <span><span>color</span></span>: <span>#<span>36364c</span></span>;</span></td>
</tr>




    <tr data-hunk="da1f4e90ffdfc03f990b7a24571aafd5718726da7c5bb350c3edcd35c8fc2963">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L321" data-line-number="321"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R289" data-line-number="289"></td>

  <td>
    <span data-code-marker=" "><br></span></td>
</tr>




    <tr data-hunk="da1f4e90ffdfc03f990b7a24571aafd5718726da7c5bb350c3edcd35c8fc2963">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L322" data-line-number="322"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R290" data-line-number="290"></td>

  <td>
    <span data-code-marker=" ">    <span>.hover-text</span> {</span></td>
</tr>




    <tr data-hunk="da1f4e90ffdfc03f990b7a24571aafd5718726da7c5bb350c3edcd35c8fc2963">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L323" data-line-number="323"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R291" data-line-number="291"></td>

  <td>
    <span data-code-marker=" ">      <span>@media</span> (<span><span>hover</span></span>: hover) {</span></td>
</tr>




      <tr data-position="156">
    <td colspan="2">
        <a href="#diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192" id="expand-link-156-diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192" aria-label="Expand All" data-url="/ethereum/ethereum-foundation-website/blob_excerpt/bf6bf506baf8212533e6d2f9a4ada228ae4465d2?diff=unified&amp;in_wiki_context=&amp;last_left=323&amp;last_right=291&amp;left=335&amp;left_hunk_size=4&amp;mode=100644&amp;path=src%2Fcomponents%2Ffooter%2FFooter.module.scss&amp;right=303&amp;right_hunk_size=4" data-left-range="324-328" data-right-range="292-296">
          
        </a>
        <tool-tip id="tooltip-76111c00-ab94-4296-a1c2-283456064cc0" for="expand-link-156-diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192" popover="manual" data-direction="ne" data-type="label" data-view-component="true">Expand All</tool-tip>
    </td>
    <td>@@ -335,4 +303,4 @@ $footer-height: 43px; // Can make this dynamic but probably overkill</td>
  </tr>

    <tr data-hunk="ee01d381cc0b202c0724638a6b12dc3db78a0921238b905f4abf46ddd3a2db30">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L335" data-line-number="335"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R303" data-line-number="303"></td>

  <td>
    <span data-code-marker=" ">  <span>.arrow</span> {</span></td>
</tr>




    <tr data-hunk="ee01d381cc0b202c0724638a6b12dc3db78a0921238b905f4abf46ddd3a2db30">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L336" data-line-number="336"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R304" data-line-number="304"></td>

  <td>
    <span data-code-marker=" ">    <span><span>//</span> cursor: ew-resize;</span></span></td>
</tr>




    <tr data-hunk="ee01d381cc0b202c0724638a6b12dc3db78a0921238b905f4abf46ddd3a2db30">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L337" data-line-number="337"></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R305" data-line-number="305"></td>

  <td>
    <span data-code-marker=" ">  }</span></td>
</tr>




    <tr data-hunk="ee01d381cc0b202c0724638a6b12dc3db78a0921238b905f4abf46ddd3a2db30">
    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192L338" data-line-number="338"></td>

    <td></td>

  <td>
    <span data-code-marker="-">}</span>
      <span>
        <svg aria-label="No newline at end of file" role="img" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true">
    <path d="M4.25 7.25a.75.75 0 0 0 0 1.5h7.5a.75.75 0 0 0 0-1.5h-7.5Z"></path><path d="M16 8A8 8 0 1 1 0 8a8 8 0 0 1 16 0Zm-1.5 0a6.5 6.5 0 1 0-13 0 6.5 6.5 0 0 0 13 0Z"></path>
</svg>
      </span>
    </td>
</tr>




    <tr data-hunk="ee01d381cc0b202c0724638a6b12dc3db78a0921238b905f4abf46ddd3a2db30">
    <td></td>

    <td id="diff-16467362d27e9012de4b9b02d88226367057bfedc467b889c338313239eea192R306" data-line-number="306"></td>

  <td>
    <span data-code-marker="+">}</span></td>
</tr>






                </tbody>
              </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Rive Renderer for real-time vector graphics is now open source (250 pts)]]></title>
            <link>https://rive.app/blog/rive-renderer-now-open-source-and-available-on-all-platforms</link>
            <guid>39766893</guid>
            <pubDate>Wed, 20 Mar 2024 14:16:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://rive.app/blog/rive-renderer-now-open-source-and-available-on-all-platforms">https://rive.app/blog/rive-renderer-now-open-source-and-available-on-all-platforms</a>, See on <a href="https://news.ycombinator.com/item?id=39766893">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-framer-name="Post" data-framer-component-type="RichTextContainer" name="Post"><p>We’re excited to announce the Rive Renderer is officially open source and available on all platforms. It isn’t hyperbolic to say what you can do with Rive is about to change in an earth-shattering way.&nbsp;</p><p>The Rive Renderer is custom-built for Rive content, for animation, and for runtime. Now you can draw an unprecedented amount of vector graphics with mega fast rendering. Want to fill the screen with vector graphics and super crisp text? Do it — the Rive Renderer ensures everything on the screen animates at 120 fps with pristine antialiasing quality.&nbsp;</p><p>The in-house Rive Renderer&nbsp; — two years in the making — draws our content without restriction. We have full control over the entire experience, from when a designer builds something in the Rive Editor, to when an end-user sees or interacts with it at runtime. By carefully and intentionally only generating content that will go fast at runtime, we have optimized the Rive Renderer to be groundbreakingly fast and highly performant. Now designers can worry less about how to build something that performs well at runtime and just… create!</p><h2>Why now?</h2><p>When we first built Rive, we used existing open source solutions to render our content, like Skia and the HTML Canvas API. The bring-your-own-renderer architecture, which we still support, is great because it lets users plug in renderers with low effort. However, not having a consistent and optimized renderer of our own has been a major roadblock for Rive’s product roadmap and innovation. We knew Rive couldn’t reach its full potential without one.&nbsp;</p><p>It also meant we couldn’t dependably implement highly requested rendering features across the <a href="https://rive.app/runtimes" rel="noopener">many platforms Rive supports</a>. Using multiple renderers meant that if a feature didn’t exist on one renderer, then we couldn’t ship it, because that feature wouldn’t have worked in all of the backends where Rive runs.&nbsp;</p><h2>What's next?</h2><p>A singular renderer empowers us to work on effects we’re itching to add, like blurs, drop shadows, glows, tapered strokes, and more. Whatever features we dream up, we can now build and add to Rive. Let us know your feature requests via <a href="mailto:hello@rive.app" rel="noopener">email</a>.</p><h2>How does it work?</h2><p>To get technical, the Rive Renderer is a novel geometric reduction of antialiased vector paths into unique triangle patches. A massively parallel triangle rasterization pipeline already comes standard on desktop and mobile GPUs, and the renderer’s specific triangulation method allows us to harness that powerful 3D hardware for drawing Bézier curves.</p><p>Our code is architected so you will always be able to use whatever third-party renderer you want. But if you want Rive’s unique features and the best overall experience, we suggest using the Rive Renderer. </p><p>You can enable the Rive Renderer on iOS, Android, or the Web by <a href="https://help.rive.app/runtimes/renderer#specifying-a-renderer" target="_blank" rel="noopener">following these directions</a>. Take it for a spin today on <a href="https://github.com/rive-app/rive-renderer" target="_blank" rel="noopener">Github</a>. And check out our Unity and Unreal runtimes that have it integrated, with more integrations coming soon.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[So you think you want to write a deterministic hypervisor? (123 pts)]]></title>
            <link>https://antithesis.com/blog/deterministic_hypervisor/</link>
            <guid>39766222</guid>
            <pubDate>Wed, 20 Mar 2024 13:32:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://antithesis.com/blog/deterministic_hypervisor/">https://antithesis.com/blog/deterministic_hypervisor/</a>, See on <a href="https://news.ycombinator.com/item?id=39766222">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
        <header>
            
            
            
            <p>March 20, 2024</p>
            
        </header>
        <p><img src="https://antithesis.com/blog/deterministic_hypervisor/images/determinator_robot.webp" alt="Determinator robot"></p>
<p data-sid="318">If you’ve read our <a href="https://antithesis.com/blog/is_something_bugging_you/">launch post</a>, you might remember this section:</p>
<blockquote>
<p data-sid="319">We thought about this and decided to just go all out and write a hypervisor which emulates a deterministic computer. Consequently, we can force anything inside it to be deterministic.</p>
</blockquote>
<p data-sid="320">Let’s expand on that a bit.</p>
<p data-sid="321">When Antithesis discovers a potential bug, we want to be able to reproduce it easily, explore it thoroughly, and provide our users with the information they most need to fix it. The deterministic hypervisor is the back-end component that gives us these capabilities.</p>
<p data-sid="322">But what is a <em>deterministic hypervisor</em> exactly? What’s special about it? How does it work? What are we doing with it, and, consequently, what can we do for you?</p>
<p data-sid="323">This is a high-level overview of a portion of the Antithesis platform. Nothing in this post is required to make use of Antithesis, but I’m hoping it demystifies our product a little bit.</p>
<h2 data-sid="324">Defining determinism</h2>
<p data-sid="325">Wikipedia’s definition of a <a href="https://en.wikipedia.org/wiki/Deterministic_algorithm">deterministic algorithm</a> is pretty solid for our purposes:</p>
<blockquote>
<p data-sid="326">In computer science, a deterministic algorithm is an algorithm that, given a particular input, will always produce the same output, with the underlying machine always passing through the same sequence of states.</p>
</blockquote>
<p data-sid="327">That last clause is important: it’s not just the result that is the same, but any underlying state as well — even hidden behavior that only manifests as obscure side-effects. When we have this sort of determinism, we can chain together several deterministic operations, or even trillions of them, and still have a consistent and knowable result.</p>
<p data-sid="328">In the world of software testing, determinism helps us attain reproducibility. Many software products have truly nasty bugs that linger for years primarily because they don’t show up consistently; this adds a ton of friction for engineers at every stage. These bugs tend to languish as open tickets because engineers cannot even begin to fix the code until they first scout out the bug and identify when and why it happens. What are the costs of never knowing if a bug really exists, and never knowing if you’ve truly fixed it? You’re always second-guessing yourself, always rerunning experiments over and over, always dealing in <b>“maybes”</b> instead of a clear <b>“yes”</b> or <b>“no.”</b></p>
<p data-sid="329">For the <a href="https://antithesis.com/docs/introduction/how_antithesis_works.html">Antithesis platform</a>, deterministic reproducibility allows us to generate useful artifacts of the bugs we’ve found, and it’s also a key enabler of <strong>time-travel debugging</strong>, and of the <strong>state-space exploration</strong> we use to find bugs in the first place.</p>
<p data-sid="330">My favorite benefit of reproducibility is that it allows <em>destructive analysis</em> of a buggy system state: I can freely extract before-and-after crash dumps, modify program data to see how it changes the behavior, and generally perturb the system as much as I want without fear. I know I’ll always be able to try something different if my first attempt doesn’t bear fruit. Whereas with flaky, hard-to-reproduce bugs in the wild, there’s always this moment of terror when you’re attempting any kind of destructive analysis – because you know it’ll be a huge setback if you don’t learn something valuable on your first try.</p>
<h2 data-sid="331">Determinism in Antithesis</h2>
<p data-sid="332">Most of software engineering practice focuses on reproducibility in small tests, such as unit tests. Most likely because this feels more achievable than forcing any kind of determinism on big systems with millions of interconnected moving parts. But at Antithesis, most of our tools are aimed at big picture end-to-end testing. We want to subject a full-featured deployment of your software to “thousands and thousands of crazy situations you’d never dreamed of,” in a simulated environment that captures a lot of the complexity and unpredictability of the real world without burying you in useless noise.</p>
<p>
    <img src="https://antithesis.com/blog/deterministic_hypervisor/images/image2.png">
</p>
<div data-sid="333"><p>
        A key piece of the Antithesis platform is the deterministic hypervisor that actually runs the test workload.<sup>1</sup> We call this thing “<b>the Determinator</b>.”
    </p><p>
        The <a href="https://antithesis.com/docs/using_antithesis/environment.html">Antithesis environment</a> simulates one or more computers using a collection of containers, all running within a single virtual machine managed by our hypervisor. The unit of reproducibility is the state of the entire system/experiment/workload as an interconnected whole, not any single process or server within the system. This approach reduces the need for complicated, domain-specific mocks and test harnesses, since you can just run (for example) both your client and server software together in the same bubble of determinism and perfectly reproduce their synchronized state.
    </p></div>
<p>
    <img src="https://antithesis.com/blog/deterministic_hypervisor/images/architecture.png">
</p>
<p data-sid="335">Our deterministic hypervisor’s job is to provide a big box for the whole end-to-end experimental setup to sit in. All of the customer’s software runs inside the box, mediated by simulation and fault-injection harnesses provided by Antithesis. Outside the box are a collection of tools that manage the exploration of the system under test. Everything in the hypervisor’s guest environment sees a single linear history. Outside of it, Antithesis can see every execution path ever visited – a tree of possible paths the experiment could take. With this knowledge, we can choose new experimental inputs or revisit previously seen ones for further analysis. The Determinator’s job is to enforce determinism on everything within the box and at the boundary.</p>
<h2 data-sid="336">Building the hypervisor</h2>
<p data-sid="337">I was the first person to work on the Determinator, alongside our CTO, <a href="http://antithesis.com/company/leadership/">Dave Scherer</a>.</p>
<p data-sid="338">We started with a piece of existing, mature open-source software – the FreeBSD project’s <a href="https://bhyve.org/">bhyve hypervisor</a>. Bhyve is, of course, not a deterministic hypervisor – it’s a general-purpose hypervisor designed to run a variety of operating systems on real hardware, aiming for both low overhead and broad access to hardware features like the GPU. To build our deterministic fork of bhyve, we started by <em>removing</em> a lot of standard hypervisor functionality.</p>
<div>
    <p data-sid="339">
        Why’s that? Well, the computers on your desk, in your pocket, and in the cloud weren’t really designed for end-to-end determinism. The real world is full of entropy, and standard computing hardware doesn’t hide all of it from you.<sup>2</sup> So we tried to limit what exactly our hypervisor had to do, to start with a small foundation of deterministic behavior and then build outward incrementally.
    </p>
    
</div>
<p><img src="https://antithesis.com/blog/deterministic_hypervisor/images/image1.png"></p>
<p data-sid="341">A lot of the day-to-day work of building the Determinator involved categorizing the micro-level CPU behavior we encountered:</p>
<ul>
<li data-sid="342"><strong>Deterministic behavior:</strong> Anything with consistent results and manageable side-effects. We want to keep the handling of deterministic behavior maximally within the hypervisor guest, because context-switching reduces performance; sometimes we’ll still have to exit to use some resource provided by the host OS or a software-emulated device, of course.</li>
<li data-sid="343"><strong>Nondeterministic behavior:</strong> Any machine behavior with inconsistent results or visibly inconsistent side-effects, including any kind of subtle butterfly effect that later permutes machine state. Another way to think of this is “determinism-destroying” behavior, so we must perfectly avoid it, contain it, or reverse it when it happens.</li>
</ul>
<p data-sid="344">Modern CPUs are fiendishly complex; they have many elaborate optimizations and nearly half the history of computing baked into various modal settings and feature flags. Assumptions are dangerous here. The only way to know whether any CPU behavior is deterministic is to subject your whole system to very thorough tests.</p>
<h3 data-sid="345">A deterministic view of time</h3>
<p data-sid="346">The biggest core constraint was clear long before we started writing anything, but it’s also the most difficult to work around. It’s the thing that haunts pretty much anyone who’s ever attempted to write a deterministic execution environment: <strong>time</strong>.</p>
<div>
    <p data-sid="347">
        Even simple-seeming CPU operations with a well-defined result aren’t really deterministic when you include the question, “How much time did this take?” Modern CPUs incorporate a collection of pipelines and caches, which are all optimized for throughput and speed at the expense of a little bit of predictability. Zoom out to entire programs in the real world and their timing characteristics are greatly affected by multi-core concurrency, interrupts, the operating system’s process and i/o scheduler,<sup>3</sup> and other extrinsic variables like network latency. Time nondeterminism can easily translate into data nondeterminism through a variety of means like racing transactions, interleaved event delivery, or simply reading the system clock.
    </p>
    
</div>
<div data-sid="349"><p>In order to solve this problem, we looked for ways to impose <strong>time determinism</strong>: a requirement that the guest’s simulated clock values should be a function of only the deterministic state and execution history of the guest system. This starts with hiding all real-world timing information from software running inside the Antithesis testing environment. Every attempt to access a time source from inside the guest – reading TSC, reading HPET, etc. – returns a virtual time value computed by the hypervisor. The hard part is translating “deterministic state and execution history” into a real, measurable quantity. Like everyone else who’s attempted to write a deterministic hypervisor, we quickly ran into the limitations of the tools available for measurement. Here’s an example:</p><p>
<img src="https://antithesis.com/blog/deterministic_hypervisor/images/image3.png"></p></div>
<p data-sid="350">It feels really natural to peg simulated cycle time to instruction processing, since that transparently guarantees that time progresses in proportion to the work done by the CPU. The current version of the Determinator is designed to run on modern Intel server CPUs, using Intel’s VMX (Virtual Machine Extension) features for hardware-supported virtualization. These chips also provide the Performance Monitoring Counters, which can be programmed to collect stats about the behavior of the CPU. Like many researchers and hobbyists before us, we were drawn to the possibility of using instructions-retired count to drive the simulated clock. However, we had to invent workarounds for two very notable limitations:</p>
<ol>
<li data-sid="351">The PMC instructions retired count isn’t quite deterministic, even in its special “precision” mode. Based on our testing, about one in a trillion instructions would be miscounted due to some unknown quirk of the CPU (we speculate it’s something to do with pipelining, branch prediction, or external interrupt handling).</li>
<li data-sid="352">PMC supports a threshold notification system, where you set up the counter as a “countdown” and get an interrupt when the value reaches zero. However, since this interrupt is delivered through the <a href="https://en.wikipedia.org/wiki/Advanced_Programmable_Interrupt_Controller">APIC</a>, dozens of instructions will be processed before the CPU is actually notified of the threshold event. Moreover, this interrupt delivery overhead is quite varied when measured in CPU cycles, meaning that you really don’t know how long ago an interrupt was triggered from the time you receive it.</li>
</ol>
<p data-sid="353">Solving problems like this involved a lot of iteration and experimentation. We were pushing various features of the CPU just a bit past what they were really designed for, which meant carefully probing their real, undocumented functionality every step of the way. Some of the most important code written during the early development of the Determinator was an alternative kernel logging subsystem. Our starting point for determinism testing was rabidly hyperactive logging, which taught us that FreeBSD’s standard kernel log could drop messages when slammed with massive amounts of data. So we had to write our own module-specific logger that both maintained large buffers of data and could pause the VM to flush that data proactively before it ran out of room. Only once we were reliably capturing and analyzing like 50 GiB of output per 20-minute run could we actually pin down, disentangle, and incrementally solve some subtle non-determinisms.</p>
<h3 data-sid="354">CPU parallelism</h3>
<p data-sid="355">Parallelism, ultimately, is also a time problem. When multiple cores are acting concurrently, those operations can be interleaved in more-or-less arbitrary ways. Getting the final result to be sane and useful is the product of billions of dollars of engineering effort and many thousands of Computer Science PhD theses. We were interested in more than just the final result, however: in order to maintain a consistent machine state, we really wanted step-by-step instruction-level determinism, which is a much more onerous burden than just making sure certain kinds of writes and reads are well-ordered and atomic.</p>
<div>
    <p data-sid="356">
        Our plan here was to simply isolate the cores. <b>Each instance of the deterministic hypervisor runs on just one physical CPU core.</b> When a real processor has 48 or 96 cores, we spin up that many separate VMs, each pinned to a different physical core, exploring different parts of the possible program state in parallel. The combined throughput of the system – its ability to explore the state space and perform many simultaneous experiments – is quite high, which matters more to us than the wall-clock speed of any single VM in isolation.<sup>4</sup>
    </p>
    
</div>
<p data-sid="358">Guest software running in the Antithesis platform still experiences concurrency similar to a multi-core / multi-machine system, thanks to the process scheduling imposed by the guest OS. Since the Antithesis platform controls the guest’s scheduler, we can also use it as a fault injection mechanism (for example, via thread starvation). Our ability to artificially induce fault conditions that would normally be rare allows Antithesis to efficiently hunt for race conditions or other hard-to-pin-down concurrency bugs.</p>
<h3 data-sid="359">Deterministic I/O</h3>
<p>
    <img src="https://antithesis.com/blog/deterministic_hypervisor/images/image4.png">
</p>
<p data-sid="360">The other mandatory piece of the Determinator design was <strong>a deterministic input/output channel</strong>. Connecting a deterministic system to a nondeterministic communication pathway just renders the whole thing nondeterministic. That’s why Antithesis simulates an entire environment within one deterministic VM, with an abstract (and fault-injected) simulation of network communication, data storage, &amp;c. However, if the experimental world inside the Determinator’s “magic box” is purely deterministic, we needed some controlled way to inject variance from the outside world in order to guide it towards different possible system states. We also wanted a simple and performant way to exfiltrate data from the guest environment as well.</p>
<p data-sid="361">We implemented deterministic input/output using the Intel x86 architecture’s <a href="https://www.felixcloutier.com/x86/vmcall">VMCALL instruction</a> (known as VMMCALL on AMD). This is basically a roll-your-own-instruction facility for hypervisor writers – an instruction that does nothing but context-switch from guest to host. Expanding its functionality beyond that is mostly a matter of making sure that both guest and host are using the same API. Our custom instruction allows software running inside the guest to emit interesting data (such as log messages) to the rest of the Antithesis platform and ingest commands or RNG seeds that are used to control guest behavior.</p>
<div>
    <p data-sid="362">
      The points in execution history where the guest ingests input from the Antithesis platform become possible branch points for future execution. Consequently, the external view of the exploration of a system is an input tree. Later on, we also added interrupt injection to “push” actions into the guest when we wanted to preempt its current activity instead of waiting for the next predetermined i/o exchange point.<sup>5</sup>
    </p>
    
</div>
<h2 data-sid="364">One of many building blocks</h2>
<p data-sid="365">That’s <em>almost</em> it for the basics. I’m necessarily leaving out a ton of detail, of course, both for the sake of brevity and competitive edge. I’ve also left out one key design pillar of Antithesis’s deterministic hypervisor: all the functionality that allows efficient state exploration and time-travel debugging. (We are not replaying every single execution path from the beginning – we would not waste your time like that!) It just felt like too much to absorb in one post, so we’ll have to return to it some other time.</p>
<p data-sid="366">Our particular implementation of a deterministic hypervisor is idiosyncratic in places, since it’s designed around the needs of the entire Antithesis platform: throughput over latency, abstractly simulated devices representing entire systems in one VM, deterministic replay both in the moment and from cold storage, time-travel debugging with support for artifact extraction and probability analysis, and more.</p>
<p data-sid="367">The Antithesis testing platform consists of a lot of innovative pieces working together, and we’re really proud of what we’ve built. This discussion of one individual piece doesn’t capture how they all fit together (<a href="https://antithesis.com/docs/introduction/how_antithesis_works.html">see our system documentation</a> for more information on that), but we hope it’s been fun and illuminating in its own right.</p>
<p data-sid="368">We have a lot of irons in the fire right now – the Determinator is only a starting point in our scheme to transform software testing and simulation. We’ll tell you a lot more over the coming months and years. But… maybe you want to get in on building this borderline-impossible stuff right now. If that’s you, check our <a href="https://antithesis.com/company/careers/">Careers</a> page and get in touch with us.</p>

    </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[8 Google Employees Invented Modern AI. Here's the Inside Story (307 pts)]]></title>
            <link>https://www.wired.com/story/eight-google-employees-invented-modern-ai-transformers-paper/</link>
            <guid>39766170</guid>
            <pubDate>Wed, 20 Mar 2024 13:29:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wired.com/story/eight-google-employees-invented-modern-ai-transformers-paper/">https://www.wired.com/story/eight-google-employees-invented-modern-ai-transformers-paper/</a>, See on <a href="https://news.ycombinator.com/item?id=39766170">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-testid="ArticlePageChunks"><div data-journey-hook="client-content" data-testid="BodyWrapper"><p><span>Eight names are</span> listed as authors on “Attention Is All You Need,” a scientific paper written in the spring of 2017. They were all <a href="https://www.wired.com/story/google-prepares-for-a-future-where-search-isnt-king/">Google</a> researchers, though by then one had left the company. When the most tenured contributor, Noam Shazeer, saw an early draft, he was surprised that his name appeared first, suggesting his contribution was paramount. “I wasn’t thinking about it,” he says.</p><div data-testid="GenericCallout"><figure><p><span><strong>/ NAME: NOAM SHAZEER / OCCUPATION: COFOUNDER AND CEO OF CHARACTER AI</strong></span></p></figure></div><p>It’s always a delicate balancing act to figure out how to list names—who gets the coveted lead position, who’s shunted to the rear. Especially in a case like this one, where each participant left a distinct mark in a true group effort. As the researchers hurried to finish their paper, they ultimately decided to “sabotage” the convention of ranking contributors. They added an asterisk to each name and a footnote: “Equal contributor,” it read. “Listing order is random.” The writers sent the paper off to a prestigious artificial intelligence conference just before the deadline—and kicked off a revolution.</p><p>Approaching its seventh anniversary, <a data-offer-url="https://arxiv.org/abs/1706.03762" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://arxiv.org/abs/1706.03762&quot;}" href="https://arxiv.org/abs/1706.03762" rel="noopener" target="_blank">the “Attention” paper</a> has attained legendary status. The authors started with a thriving and improving technology—a variety of AI called neural networks—and made it into something else: a digital system so powerful that its output can feel like the product of <a href="https://www.wired.com/story/plaintext-groq-mindblowing-chatbot-answers-instantly/#intcid=recommendations_wired-bottom-recirc-v4_efa0ebfa-8b30-44aa-826f-37cbd7ba731a_similar2-3">an alien intelligence</a>. Called transformers, this architecture is <a href="https://www.wired.com/story/artificial-intelligence-neural-networks/">the not-so-secret sauce</a> behind all those <a href="https://www.wired.com/story/fast-forward-forget-chatbots-ai-agents-are-the-future/#intcid=recommendations_wired-bottom-recirc-v4_efa0ebfa-8b30-44aa-826f-37cbd7ba731a_similar2-3">mind-blowing AI products</a>, including <a href="https://www.wired.com/tag/chatgpt/">ChatGPT</a> and graphic generators such as Dall-E and Midjourney. Shazeer now jokes that if he knew how famous the paper would become, he “might have worried more about the author order.” All eight of the signers are now microcelebrities. “I have people asking me for selfies—because I’m on a paper!” says Llion Jones, who is (randomly, of course) name number five.</p><div data-testid="GenericCallout"><figure><p><span><strong>/ NAME: LLION JONES / OCCUPATION: COFOUNDER OF SAKANA AI</strong></span></p></figure></div><p>“Without transformers I don’t think we’d be here now,” says <a href="https://www.wired.com/story/geoffrey-hinton-ai-chatgpt-dangers/">Geoffrey Hinton</a>, who is not one of the authors but is perhaps the world’s most <a href="https://www.wired.com/story/ai-pioneer-explains-evolution-neural-networks/">prominent AI scientist</a>. He’s referring to the ground-shifting times we live in, <a href="https://www.wired.com/story/what-openai-really-wants/">as OpenAI and other companies build systems</a> that rival and in some cases surpass human output.</p><p>All eight authors have since left Google. Like millions of others, they are now working in some way with systems powered by what they created in 2017. I talked to the Transformer Eight to piece together the anatomy of a breakthrough, a gathering of human minds to create a machine that might well save the last word for itself.</p><div data-testid="GenericCallout"><figure><p><span><strong>/ NAME: JAKOB USZKOREIT / OCCUPATION: COFOUNDER AND CEO OF INCEPTIVE</strong></span></p></figure></div><p><span>The story of</span> transformers begins with the fourth of the eight names: Jakob Uszkoreit.</p><p>Uszkoreit is the son of Hans Uszkoreit, a well-known computational linguist. As a high school student in the late 1960s, Hans was imprisoned for 15 months in his native East Germany for protesting the Soviet invasion of Czechoslovakia. After his release, he escaped to West Germany and studied computers and linguistics in Berlin. He made his way to the US and was working in an artificial intelligence lab at SRI, a research institute in Menlo Park, California, when Jakob was born. The family eventually returned to Germany, where Jakob went to university. He didn’t intend to focus on language, but as he was embarking on graduate studies, he took an internship at Google in its Mountain View office, where he landed in the company’s translation group. He was in the family business. He abandoned his PhD plans and, in 2012, decided to join a team at Google that was working on a system that could respond to users’ questions on the search page itself without diverting them to other websites. Apple had just announced Siri, a virtual assistant that promised to deliver one-shot answers in casual conversation, and the Google brass smelled a huge competitive threat: Siri could eat up their search traffic. They started paying a lot more attention to Uszkoreit’s new group.</p><p>“It was a false panic,” Uszkoreit says. Siri never really threatened Google. But he welcomed the chance to dive into systems where computers could engage in a kind of dialog with us. At the time, recurrent neural networks—once an academic backwater—had suddenly started outperforming other methods of AI engineering. The networks consist of many layers, and information is passed and repassed through those layers to identify the best responses. Neural nets were racking up huge wins in fields such as image recognition, and an AI renaissance was suddenly underway. Google was frantically <a href="https://www.wired.com/2016/06/how-google-is-remaking-itself-as-a-machine-learning-first-company/">rearranging its workforce</a> to adopt the techniques. The company wanted systems that could churn out humanlike responses—to auto-complete sentences in emails or create relatively simple customer service chatbots.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>But the field was running into limitations. Recurrent neural networks struggled to parse longer chunks of text. Take a passage like <em>Joe is a baseball player, and after a good breakfast he went to the park and got two hits.</em> To make sense of “two hits,” a language model has to remember the part about baseball. In human terms, it has to be paying attention. The accepted fix was something called “long short-term memory” (LSTM), an innovation that allowed language models to process bigger and more complex sequences of text. But the computer still handled those sequences strictly sequentially—word by tedious word—and missed out on context clues that might appear later in a passage. “The methods we were applying were basically Band-Aids,” Uszkoreit says. “We could not get the right stuff to really work at scale.”</p><p>Around 2014, he began to concoct a different approach that he referred to as self-attention. This kind of network can translate a word by referencing <em>any</em> other part of a passage. Those other parts can clarify a word’s intent and help the system produce a good translation. “It actually considers everything and gives you an efficient way of looking at many inputs at the same time and then taking something out in a pretty selective way,” he says. Though AI scientists are careful not to confuse the metaphor of neural networks with the way the biological brain actually works, Uszkoreit does seem to believe that self-attention is somewhat similar to the way humans process language.</p><p>Uszkoreit thought a self-attention model could potentially be faster and more effective than recurrent neural nets. The way it handles information was also perfectly suited to the powerful parallel processing chips that were being produced en masse to support the machine learning boom. Instead of using a linear approach (look at every word in sequence), it takes a more parallel one (look at a bunch of them together). If done properly, Uszkoreit suspected, you could use self-attention <em>exclusively</em> to get better results.</p><p>Not everyone thought this idea was going to rock the world, including Uszkoreit’s father, who had scooped up two Google Faculty research awards while his son was working for the company. “People raised their eyebrows, because it dumped out all the existing neural architectures,” Jakob Uszkoreit says. Say goodbye to recurrent neural nets? Heresy! “From dinner-table conversations I had with my dad, we weren’t necessarily seeing eye to eye.”</p><p>Uszkoreit persuaded a few colleagues to conduct experiments on self-attention. Their work showed promise, and in 2016 they published a paper about it. Uszkoreit wanted to push their research further—the team’s experiments used only tiny bits of text—but none of his collaborators were interested. Instead, like gamblers who leave the casino with modest winnings, they went off to apply the lessons they had learned. “The thing <em>worked</em>,” he says. “The folks on that paper got excited about reaping the rewards and deploying it in a variety of different places at Google, including search and, eventually, ads. It was an amazing success in many ways, but I didn’t want to leave it there.”</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>Uszkoreit felt that self-attention could take on much bigger tasks. <em>There’s another way to do this</em>, he’d argue to anyone who would listen, and some who wouldn’t, outlining his vision on whiteboards in Building 1945, named after its address on Charleston Road on the northern edge of the Google campus.</p><div data-testid="GenericCallout"><figure><p><span><strong>/ NAME: ILLIA POLOSUKHIN / OCCUPATION: COFOUNDER OF NEAR</strong></span></p></figure></div><p>One day in 2016, Uszkoreit was having lunch in a Google café with a scientist named Illia Polosukhin. Born in Ukraine, Polosukhin had been at Google for nearly three years. He was assigned to the team providing answers to direct questions posed in the search field. It wasn’t going all that well. “To answer something on Google.com, you need something that’s very cheap and high-performing,” Polosukhin says. “Because you have milliseconds” to respond. When Polosukhin aired his complaints, Uszkoreit had no problem coming up with a remedy. “He suggested, why not use self-attention?” says Polosukhin.</p><p>Polosukhin sometimes collaborated with a colleague named Ashish Vaswani. Born in India and raised mostly in the Middle East, he had gone to the University of Southern California to earn his doctorate in the school’s elite machine translation group. Afterward, he moved to Mountain View to join Google—specifically a newish organization called <a href="https://www.wired.com/2013/05/neuro-artificial-intelligence/">Google Brain</a>. He describes Brain as “a radical group” that believed “neural networks were going to advance human understanding.” But he was still looking for a big project to work on. His team worked in Building 1965 next door to Polosukhin’s language team in 1945, and he heard about the self-attention idea. Could that be the project? He agreed to work on it.</p><div data-testid="GenericCallout"><figure><p><span><strong>/ NAME: ASHISH VASWANI / OCCUPATION: COFOUNDER AND CEO OF ESSENTIAL AI</strong></span></p></figure></div><p>Together, the three researchers drew up a design document called “Transformers: Iterative Self-Attention and Processing for Various Tasks.” They picked the name “transformers” from “day zero,” Uszkoreit says. The idea was that this mechanism would <em>transform</em> the information it took in, allowing the system to extract as much understanding as a human might—or at least give the illusion of that. Plus Uszkoreit had fond childhood memories of playing with the Hasbro action figures. “I had two little Transformer toys as a very young kid,” he says. The document ended with a cartoony image of six Transformers in mountainous terrain, zapping lasers at one another.</p><p>There was also some swagger in the sentence that began the paper: “We are awesome.”</p><p>In early 2017, Polosukhin left Google to start his own company. By then new collaborators were coming onboard. An Indian engineer named Niki Parmar had been working for an American software company in India when she moved to the US. She earned a master’s degree from USC in 2015 and was recruited by all the Big Tech companies. She chose Google. When she started, she joined up with Uszkoreit and worked on model variants to improve Google search.</p><div data-testid="GenericCallout"><figure><p><span><strong>/ NAME: NIKI PARMAR / OCCUPATION: COFOUNDER OF ESSENTIAL AI</strong></span></p></figure></div><p>Another new member was Llion Jones. Born and raised in Wales, he loved computers “because it was not normal.” At the University of Birmingham he took an AI course and got curious about neural networks, which were presented as a historical curiosity. He got his master’s in July 2009 and, unable to find a job during the recession, lived on the dole for months. He found a job at a local company and then applied to Google as a “hail Mary.” He got the gig and eventually landed in Google Research, where his manager was Polosukhin. One day, Jones heard about the concept of self-attention from a fellow worker named Mat Kelcey, and he later joined up with Team Transformers. (Later, Jones ran into Kelcey and briefed him on the transformer project. Kelcey wasn’t buying it. “I told him, ‘I’m not sure that’s going to work,’ which is basically the biggest incorrect prediction of my life,” Kelcey says now.)</p><p>The transformer work drew in other Google Brain researchers who were also trying to improve <a href="https://www.wired.com/story/how-chatgpt-works-large-language-model/">large language models</a>. This third wave included Łukasz Kaiser, a Polish-born theoretical computer scientist, and his intern, Aidan Gomez. Gomez had grown up in a small farming village in Ontario, Canada, where his family would tap maple trees every spring for syrup. As a junior at the University of Toronto, he “fell in love” with AI and joined the machine learning group—Geoffrey Hinton’s lab. He began contacting people at Google who had written interesting papers, with ideas for extending their work. Kaiser took the bait and invited him to intern. It wasn’t until months later that Gomez learned those internships were meant for doctoral students, not undergrads like him.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>Kaiser and Gomez quickly understood that self-attention looked like a promising, and more radical, solution to the problem they were addressing. “We had a deliberate conversation about whether we wanted to merge the two projects,” says Gomez. The answer was yes.</p><p>The transformer crew set about building a self-attention model to translate text from one language to another. They measured its performance using a benchmark called BLEU, which compares a machine’s output to the work of a human translator. From the start, their new model did well. “We had gone from no proof of concept to having something that was at least on par with the best alternative approaches to LSTMs by that time,” Uszkoreit says. But compared to long short-term memory, “it wasn’t better.”</p><p>They had reached a plateau—until one day in 2017, when Noam Shazeer heard about their project, by accident. Shazeer was a veteran Googler—he’d joined the company in 2000—and an in-house legend, starting with his work on the company’s early ad system. Shazeer had been working on deep learning for five years and recently had become interested in large language models. But these models were nowhere close to producing the fluid conversations that he believed were possible.</p><p>As Shazeer recalls it, he was walking down a corridor in Building 1965 and passing Kaiser’s workspace. He found himself listening to a spirited conversation. “I remember Ashish was talking about the idea of using self-attention, and Niki was very excited about it. I’m like, wow, that sounds like a great idea. This looks like a fun, smart group of people doing something promising.” Shazeer found the existing recurrent neural networks “irritating” and thought: “Let’s go replace them!”</p><p>Shazeer’s joining the group was critical. “These theoretical or intuitive mechanisms, like self-attention, always require very careful implementation, often by a small number of experienced ‘magicians,’ to even show any signs of life,” says Uszkoreit. Shazeer began to work his sorcery right away. He decided to write his own version of the transformer team’s code. “I took the basic idea and made the thing up myself,” he says. Occasionally he asked Kaiser questions, but mostly, he says, he “just acted on it for a while and came back and said, ‘Look, it works.’” Using what team members would later describe with words like “magic” and “alchemy” and “bells and whistles,” he had taken the system to a new level.</p><p>“That kicked off a sprint,” says Gomez. They were motivated, and they also wanted to hit an upcoming deadline—May 19, the filing date for papers to be presented at the biggest AI event of the year, the Neural Information Processing Systems conference in December. As what passes for winter in Silicon Valley shifted to spring, the pace of the experiments picked up. They tested two models of transformers: one that was produced with 12 hours of training and a more powerful version called Big that was trained over three and a half days. They set them to work on English-to-German translation.</p><p>The basic model outperformed all competitors—and Big earned a BLEU score that decisively shattered previous records while also being more computationally efficient. “We had done it in less time than anyone out there,” Parmar says. “And that was only the beginning, because the number kept improving.” When Uszkoreit heard this, he broke out an old bottle of champagne he had lying around in his mountain expedition truck.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>The last two weeks before the deadline were frantic. Though officially some of the team still had desks in Building 1945, they mostly worked in 1965 because it had a better espresso machine in the micro-kitchen. “People weren’t sleeping,” says Gomez, who, as the intern, lived in a constant debugging frenzy and also produced the visualizations and diagrams for the paper. It’s common in such projects to do ablations—taking things out to see whether what remains is enough to get the job done.</p><p>“There was every possible combination of tricks and modules—which one helps, which doesn’t help. Let’s rip it out. Let’s replace it with this,” Gomez says. “Why is the model behaving in this counterintuitive way? Oh, it’s because we didn’t remember to do the masking properly. Does it work yet? OK, move on to the next. All of these components of what we now call the transformer were the output of this extremely high-paced, iterative trial and error.” The ablations, aided by Shazeer’s implementations, produced “something minimalistic,” Jones says. “Noam is a wizard.”</p><p>Vaswani recalls crashing on an office couch one night while the team was writing the paper. As he stared at the curtains that separated the couch from the rest of the room, he was struck by the pattern on the fabric, which looked to him like synapses and neurons. Gomez was there, and Vaswani told him that what they were working on would transcend machine translation. “Ultimately, like with the human brain, you need to unite all these modalities—speech, audio, vision—under a single architecture,” he says. “I had a strong hunch we were onto something more general.”</p><p>In the higher echelons of Google, however, the work was seen as just another interesting AI project. I asked several of the transformers folks whether their bosses ever summoned them for updates on the project. Not so much. But “we understood that this was potentially quite a big deal,” says Uszkoreit. “And it caused us to actually obsess over one of the sentences in the paper toward the end, where we comment on future work.”</p><p>That sentence anticipated what might come next—the application of transformer models to basically all forms of human expression. “We are excited about the future of attention-based models,” they wrote. “We plan to extend the transformer to problems involving input and output modalities other than text” and to investigate “images, audio and video.”</p><p>A couple of nights before the deadline, Uszkoreit realized they needed a title. Jones noted that the team had landed on a radical rejection of the accepted best practices, most notably LSTMs, for one technique: attention. The Beatles, Jones recalled, had named a song “All You Need Is Love.” Why not call the paper “Attention Is All You Need”?</p><p><em>The Beatles?</em></p><p>“I’m British,” says Jones. “It literally took five seconds of thought. I didn’t think they would use it.”</p><p>They continued collecting results from their experiments right up until the deadline. “The English-French numbers came, like, five minutes before we submitted the paper,” says Parmar. “I was sitting in the micro-kitchen in 1965, getting that last number in.” With barely two minutes to spare, they sent off the paper.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>Google, as almost all tech companies do, quickly filed provisional patents on the work. The reason was not to block others from using the ideas but to build up its patent portfolio for defensive purposes. (The company has a philosophy of “if technology advances, Google will reap the benefits.”)</p><p>When the transformer crew heard back from the conference peer reviewers, the response was a mix. “One was positive, one was extremely positive, and one was, ‘This is OK,’” says Parmar. The paper was accepted for one of the evening poster sessions.</p><p>By December, the paper was generating a buzz. Their four-hour session on December 6 was jammed with scientists wanting to know more. The authors talked until they were hoarse. By 10:30 pm, when the session closed, there was still a crowd. “Security had to tell us to leave,” says Uszkoreit. Perhaps the most satisfying moment for him was when computer scientist Sepp Hochreiter came up and praised the work—quite a compliment, considering that Hochreiter was the coinventor of long short-term memory, which transformers had just booted as the go-to hammer in the AI toolkit.</p><p><span>Transformers did not</span> instantly take over the world, or even Google. Kaiser recalls that around the time of the paper’s publication, Shazeer proposed to Google executives that the company abandon the entire search index and train a huge network with transformers—basically to transform how Google organizes information. At that point, even Kaiser considered the idea ridiculous. Now the conventional wisdom is that it’s <a href="https://www.wired.com/story/google-io-just-added-generative-ai-to-search/">a matter of time</a>.</p><p>A startup called OpenAI was <a href="https://www.wired.com/story/what-openai-really-wants/">much faster to pounce</a>. Soon after the paper was published, OpenAI’s chief researcher, Ilya Sutskever—who had known the transformer team during his time at Google—suggested that one of its scientists, Alex Radford, work on the idea. The results were the first GPT products. As OpenAI CEO Sam Altman told me last year, “When the transformer paper came out, I don’t think anyone at Google realized what it meant.”</p><p>The picture internally is more complicated. “It was pretty evident to us that transformers could do really magical things,” says Uszkoreit. “Now, you may ask the question, why wasn’t there <a href="https://www.wired.com/story/google-rebrands-ai-chatbot-gemini/">ChatGPT by Google</a> back in 2018? Realistically, we could have had GPT-3 or even 3.5 probably in 2019, maybe 2020. The big question isn’t, did they see it? The question is, why didn’t we do anything with the fact that we had seen it? The answer is tricky.”</p><div data-testid="GenericCallout"><figure><p><span><strong>/ NAME: AIDAN GOMEZ / OCCUPATION: COFOUNDER AND CEO OF COHERE</strong></span></p></figure></div><p>Many tech critics point to Google’s transition from an innovation-centered playground to a bottom-line-focused bureaucracy. As Gomez <a href="https://www.ft.com/content/37bb01af-ee46-4483-982f-ef3921436a50">told</a> the <em>Financial Times</em>, “They weren’t modernizing. They weren’t adopting this tech.” But that would have taken a lot of daring for a giant company whose technology led the industry and reaped huge profits for decades. Google did begin to integrate transformers into products in 2018, starting with its translation tool. Also that year, it introduced a new transformer-based language model called BERT, which it started to apply to search the year after.</p><p>But these under-the-hood changes seem timid compared to OpenAI’s quantum leap and Microsoft’s <a href="https://www.wired.com/story/microsofts-satya-nadella-is-betting-everything-on-ai/">bold integration</a> of transformer-based systems into its product line. When I asked CEO Sundar Pichai last year why his company wasn’t first to launch a large language model like ChatGPT, he argued that in this case Google found it advantageous to let others lead. “It’s not fully clear to me that it might have worked out as well. The fact is, we can do more after people had seen how it works,” he said.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>There <em>is</em> the undeniable truth that all eight authors of the paper have left Google. Polosukhin’s company, Near, built a blockchain whose tokens have a market capitalization around $4 billion. Parmar and Vaswani paired up as business partners in 2021 to start Adept (estimated valuation of $1 billion) and are now on their <em>second</em> company, called Essential AI ($8 million in funding). Llion Jones’ Tokyo-based Sakana AI is valued at $200 million. Shazeer, who left in October 2021, cofounded Character AI (estimated valuation of $5 billion). Aidan Gomez, the intern in the group, cofounded Cohere in Toronto in 2019 (estimated valuation of $2.2 billion). Jakob Uszkoreit’s biotech company, Inceptive, is valued at $300 million. All those companies (except Near) are based on transformer technology.</p><div data-testid="GenericCallout"><figure><p><span><strong>/ NAME: LUKASZ KAISER / OCCUPATION: RESEARCHER AT OPENAI</strong></span></p></figure></div><p>Kaiser is the only one who hasn’t founded a company. He joined OpenAI and is one of the inventors of a new technology called <a href="https://www.wired.com/story/fast-forward-clues-hint-openai-shadowy-q-project/">Q*</a>, which Altman said last year will “push the veil of ignorance back and the frontier of discovery forward.” (When I attempted to quiz Kaiser on this in our interview, the OpenAI PR person almost leaped across the table to silence him.)</p><p>Does Google miss these escapees? Of course, in addition to others who have migrated from the company to new AI startups. (Pichai reminded me, when I asked him about the transformer departures, that industry darling OpenAI also has seen defections: “The AI area is very, very dynamic,” he said.) But Google can boast that it created an environment that supported the pursuit of unconventional ideas. “In a lot of ways Google has been way ahead—they invested in the right minds and created the environment where we could explore and push the envelope,” Parmar says. “It’s not crazy that it took time to adopt it. Google had so much more at stake.”</p><p>Without that environment: no transformer. Not only were the authors all Google employees, they also worked out of the same offices. Hallway encounters and overheard lunch conversations led to big moments. The group is also culturally diverse. Six of the eight authors were born outside the United States; the other two are children of two green-card-carrying Germans who were temporarily in California and a first-generation American whose family had fled persecution, respectively.</p><p>Uszkoreit, speaking from his office in Berlin, says that innovation is all about the right conditions. “It’s getting people who are super excited about something who are at the right point in their life,” he says. “If you have that and have fun while you do it, and you’re working on the right problems—and you’re lucky—the magic happens.”</p><p>Something magical also happened between Uszkoreit and his famous father. After all those dinner table debates, Hans Uszkoreit, his son reports, has now cofounded a company that is building large language models. Using transformers, of course.</p><hr><p><em>Let us know what you think about this article. Submit a letter to the editor at</em> <em><a href="mailto:mail@wired.com">mail@wired.com</a>.</em></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[First beta of Nintendo Switch emulator Suyu goes live (122 pts)]]></title>
            <link>https://overkill.wtf/nintendo-switch-emulator-suyu-beta/</link>
            <guid>39766138</guid>
            <pubDate>Wed, 20 Mar 2024 13:26:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://overkill.wtf/nintendo-switch-emulator-suyu-beta/">https://overkill.wtf/nintendo-switch-emulator-suyu-beta/</a>, See on <a href="https://news.ycombinator.com/item?id=39766138">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
<div>
<p>
Suyu is a new Switch emulator compatible with the Steam Deck that launches in public beta today.
</p>
<p>One of the first Nintendo Switch emulators to rise <a href="https://overkill.wtf/switch-emulator-yuzu/">from Yuzu's ashes</a> is here: Suyu, based on Yuzu's source code, launches in a first public beta today. Their changelog looks as follows:</p><blockquote>- Full rebrand<br>- ICNS Icon generation<br>- Error handling<br>- Qlaunch initial integration(buggy/requires further testing; requires V17.0.0 firmware or newer)<br>- Gitlab ci for automated builds<br>- Require all keys to be user provided, along with firmware<br>- Improved Addons Manager<br>- Various crash fixes<br>- Initial work for MacOS support<br>- Fix for video playback AMD devices<br>- Enabled more features on AMD proprietary drivers<br>- Multiplayer API re-implemented<br>- Removed all telemetry<br>- New UI options/improvements<br>- QOL changes</blockquote><p>Unlike Yuzu, the Suyu team does things differently in regards to Nintendo Switch emulation than their predecessors. <a href="https://overkill.wtf/how-to-setup-yuzu-for-steam-deck/">Whereas Yuzu only required prod.keys</a>, Suyu will also require you to dump your title.keys and firmware from a hacked Switch to run games. The devs also clarified that they are doing this for nonprofit (there's no Patreon) and do not condone piracy.</p><p>The developer team is releasing <a href="https://gitlab.com/suyu-emu/suyu/-/releases/v0.0.2-master?ref=overkill.wtf">binaries for Linux, Windows, Android and even an experimental build for macOS</a> (Yuzu was unavailable for Apple's platform). I tried the build on Steam Deck (it works) and will work on a guide.</p>
</div>
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Intel to Receive $8.5B in Grants to Build Chip Plants (184 pts)]]></title>
            <link>https://www.nytimes.com/2024/03/20/us/politics/chips-act-grant-intel.html</link>
            <guid>39765718</guid>
            <pubDate>Wed, 20 Mar 2024 12:51:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2024/03/20/us/politics/chips-act-grant-intel.html">https://www.nytimes.com/2024/03/20/us/politics/chips-act-grant-intel.html</a>, See on <a href="https://news.ycombinator.com/item?id=39765718">Hacker News</a></p>
Couldn't get https://www.nytimes.com/2024/03/20/us/politics/chips-act-grant-intel.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Bug hunting in Btrfs (137 pts)]]></title>
            <link>https://tavianator.com/2024/btrfs_bug.html</link>
            <guid>39765715</guid>
            <pubDate>Wed, 20 Mar 2024 12:51:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tavianator.com/2024/btrfs_bug.html">https://tavianator.com/2024/btrfs_bug.html</a>, See on <a href="https://news.ycombinator.com/item?id=39765715">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
                    <main>
                        
<p> <time datetime="2024-03-18">2024-03-18</time>
 Tavian Barnes</p>
<p>The other day I was implementing <a href="https://tavianator.com/cgit/bfs.git/commit/?id=89ecb2a08467cd8aa6ba70f8519df494652cac96">multi-threaded <code>stat()</code> calls</a> in <a href="https://tavianator.com/projects/bfs.html"><code>bfs</code></a>.
When I ran some benchmarks, I saw something that made my heart skip a beat:</p>
<pre><code>$ tailfin run bench/bench.sh --build=main --default
...
bfs: error: bench/corpus/chromium/v8/src/heap/heap.cc: Structure needs cleaning
</code></pre>
<p>If you're not familiar, "structure needs cleaning" is the human-readable description of <code>EUCLEAN</code>, an <code>errno</code> value that usually indicates filesystem corruption.
Fearing the worst, I checked <code>dmesg</code> and saw</p>
<pre><code>$ dmesg | tail
...
BTRFS critical (device dm-2): corrupted node, root=518 block=16438782945911875046 owner mismatch, have 4517169229596899607 expect [256, 18446744073709551360]
</code></pre>
<p>I immediately rebooted into a live environment and ran <code>btrfs check</code>, but to my surprise, there were no errors found.
<code>btrfs scrub</code> also found no evidence of corruption.
And in fact, the file from the error message was completely fine.
Whatever the issue was, it seemed to have gone away on its own.</p>
<p>I searched Google for that "corrupted node" message and found that it had happened to someone else recently too: <a href="https://lore.kernel.org/linux-btrfs/CAHk-=whNdMaN9ntZ47XRKP6DBes2E5w7fi-0U3H2+PS18p+Pzw@mail.gmail.com/">Linus Torvalds</a>, just after merging a Btrfs pull request.
(This was not the first time Linus and I had hit the same bug.
We both have the same CPU in our desktops.
Last time it led to one of my <a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=a51ab63b297ce9e26e3ffb9be896018a42d5f32f">favourite bugfixes ever</a>.)</p>
<p>But the difference between me and Linus was that I could (semi-)reliably reproduce the error.
Not every time, but maybe 10% of the time I ran <code>bfs</code> with parallel <code>stat()</code> calls on a large directory tree, I would see that "structure needs cleaning" error.
I reported my <a href="https://lore.kernel.org/linux-btrfs/20240206033807.15498-1-tavianator@tavianator.com/">findings</a> to the Btrfs mailing list, and though it led to some discussion about potential causes, we didn't narrow down the root cause.</p>
<h2 id="extent_buffer"><a href="#extent_buffer"><code>extent_buffer</code></a></h2>
<p>Based on the logs, the Btrfs developers assumed the problem had to do allocation of <a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/fs/btrfs/extent_io.h?id=a51ab63b297ce9e26e3ffb9be896018a42d5f32f#n76"><code>struct extent_buffer</code></a> and their memory pages.
I'm not a Btrfs internals expert by any means, but I understand that <code>extent_buffer</code>s are used for metadata I/O; that is, reading and writing <a href="https://en.wikipedia.org/wiki/B-tree">B-tree</a> nodes.
An <code>extent_buffer</code> is associated with an array of <code>struct folio</code>/<code>struct page</code> (depending on kernel version), and those pages hold the actual contents of the extents that are read or written.
The abstraction helps with file system block sizes that are different from the system page size.</p>
<p>Allocating an <code>extent_buffer</code> and its pages is <a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/fs/btrfs/extent_io.c?id=a51ab63b297ce9e26e3ffb9be896018a42d5f32f#n3681">more complicated than you might expect</a>.
Each <code>struct extent_buffer</code> holds an array of <code>struct folio</code>, and those folios have a private reference that points back to the <code>extent_buffer</code>.
There should only ever be one <code>extent_buffer</code> at a time for any particular extent.</p>
<p>To reduce locking on the allocation path, the <code>extent_buffer</code> and the corresponding folios are allocated separately, linked together, and then inserted into a radix tree keyed by the start offset of the extent.
Only the radix tree insertion needs locking.
At the point of insertion, if it turns out someone else beat us to allocating the same extent, we instead take an extra reference to that <code>extent_buffer</code> and free the one we just allocated (and its pages).</p>
<p>This code path had undergone some churn recently, both <a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=09e6cef19c9fc0e10547135476865b5272aa0406">changing the race detection/handling strategy</a> and <a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=082d5bb9b336d533b7b968f4f8712e7755a9876a">converting from <code>struct page</code> to <code>struct folio</code></a>, so there was suspicion that a race or reference counting bug had crept in.
But the extra debug logging didn't show it.
It appeared that the <code>extent_buffer</code> and the <code>folio</code>s had all the right reference counts, but the memory itself had garbage rather than the appropriate on-disk contents.
Btrfs does some sanity checks after reading these blocks in, and those checks were failing, causing the errors.
But the on-disk blocks themselves were fine, and the next time we read them in, everything worked.</p>
<h2 id="git-bisect-bad"><a href="#git-bisect-bad"><code>git bisect bad</code></a></h2>
<p>One of the best bug hunting tools for the Linux kernel is <a href="https://git-scm.com/docs/git-bisect"><code>git bisect</code></a>.
Unfortunately, bisecting bugs like this is challenging.
For intermittent issues, it's easy enough to know when to mark a commit bad, but harder to know if a commit is good—maybe the bug just hasn't triggered <em>yet</em>.
You also need a known-good commit to start from, but that was hard to find.
I thought at first the bug was new in Linux 6.7, but I could still reproduce it on 6.6 and 6.5.
The Btrfs devs suggested I start from 6.0.</p>
<p>Bisecting can also be dangerous because you are running arbitrary old mid-development-cycle kernel commits that may have since had bugs fixed in the official releases.
It's safer to do it from a virtual machine, but so far I had been unable to reproduce the bug on a VM.
So started bisecting on my actual desktop.</p>
<p>Normally I would be far too scared to bisect a filesystem corruption bug on my actual computer that I use daily.
But this seemed like it wasn't "real" corruption, plus I have backups, so I risked it.
Unfortunately, after a couple rounds, I ran into <a href="https://lore.kernel.org/linux-btrfs/CABg4E-=u7m_g3HCFUYHS-+RC==pefkUZXiTT2Aor86jruHSF9Q@mail.gmail.com/">actual, on-disk filesystem corruption</a>.
2,073,625 uncorrectable read errors is a new record for me, so I was too scared to continue the bisect.
I restored what I could from backups and carried on with my life.</p>
<h2 id="tracefs"><a href="#tracefs"><code>tracefs</code></a></h2>
<p>A few weeks later, Btrfs developer Qu Wenruo got back to me with some <a href="https://lore.kernel.org/linux-btrfs/c7241ea4-fcc6-48d2-98c8-b5ea790d6c89@gmx.com/">extra debugging patches</a> and I decided to give it another shot.
I ran his patch on bare metal, but wasn't able to reproduce the bug with the debugging patch applied.
Such is life when debugging race conditions!</p>
<p>I also tried again to reproduce the issue in a VM.
I configured it to more closely match my actual system configuration: multiple disks with <a href="https://wiki.archlinux.org/title/dm-crypt/Device_encryption">dm-crypt</a> full disk encryption, joined together in a Btrfs RAID 0 array.
And I made them emulated NVME drives instead of VirtIO.
That did the trick: I could now reproduce the issue in a VM, though it took around 30 runs of my reproducer instead of the ~10 it took in real life.
But this time I could still reproduce it with the debugging patch applied.</p>
<p>After a couple runs and tweaking the trace messages to make cross-referencing easier, I noticed something odd.
Looking at just the lines from the trace corresponding to the "corrupted" error message, I saw this:</p>
<pre><code>$ grep 'eb=15302115328' dmesg.log
BTRFS critical (device dm-0): corrupted leaf, root=258 block=15302115328 owner mismatch, have 13709377558419367261 expect [256, 18446744073709551360] eb=15302115328
iou-wrk--173727   15..... 2649295481us : alloc_extent_buffer: alloc_extent_buffer: alloc eb=15302115328 len=16384
kworker/-322      15..... 2649295735us : end_bbio_meta_read: read done, eb=15302115328 page_refs=3 eb level=0 fsid=b66a67f0-8273-4158-b7bf-988bb5683000
kworker/-5095     31..... 2649295941us : end_bbio_meta_read: read done, eb=15302115328 page_refs=8 eb level=0 fsid=b66a67f0-8273-4158-b7bf-988bb5683000
</code></pre>
<p>The only relevant operations seem to be allocating this <code>extent_buffer</code>, and then reading it ... twice.
Reading it once ought to be enough, I thought, so I looked more closely at the code that actually reads them in and managed to eyeball the bug.</p>
<h2 id="read_extent_buffer_pages"><a href="#read_extent_buffer_pages"><code>read_extent_buffer_pages()</code></a></h2>
<p>Just like how multiple threads might try to allocate the same <code>extent_buffer</code> at the same time, they might also try to read it at the same time.
To ensure the read only happens once, a custom locking protocol is used:</p>
<pre><code>int read_extent_buffer_pages(struct extent_buffer *eb, /* ... */)
{
    if (test_bit(EXTENT_BUFFER_UPTODATE, &amp;eb-&gt;bflags))
        return 0;

    /* ... */

    /* Someone else is already reading the buffer, just wait for it. */
    if (test_and_set_bit(EXTENT_BUFFER_READING, &amp;eb-&gt;bflags))
        goto done;

    /* ... */
    bbio = btrfs_bio_alloc(INLINE_EXTENT_BUFFER_PAGES,
                   REQ_OP_READ | REQ_META, eb-&gt;fs_info,
                   end_bbio_meta_read, eb);
    /* ... */
    btrfs_submit_bio(bbio, mirror_num);

done:
    if (wait == WAIT_COMPLETE) {
        wait_on_bit_io(&amp;eb-&gt;bflags, EXTENT_BUFFER_READING, TASK_UNINTERRUPTIBLE);
        if (!test_bit(EXTENT_BUFFER_UPTODATE, &amp;eb-&gt;bflags))
            return -EIO;
    }

    return 0;
}

static void end_bbio_meta_read(struct btrfs_bio *bbio)
{
    /* ... */
    bool uptodate = !bbio-&gt;bio.bi_status;
    /* ... */

    if (uptodate) {
        set_extent_buffer_uptodate(eb);
    } else {
        clear_extent_buffer_uptodate(eb);
        set_bit(EXTENT_BUFFER_READ_ERR, &amp;eb-&gt;bflags);
    }

    /* ... */
    clear_bit(EXTENT_BUFFER_READING, &amp;eb-&gt;bflags);
    smp_mb__after_atomic();
    wake_up_bit(&amp;eb-&gt;bflags, EXTENT_BUFFER_READING);
    /* ... */
}
</code></pre>
<p>The logic is intended to work like this:</p>

<div id="race-1">
<pre><code><span>read_extent_buffer_pages()
</span><span>{
</span><span>    if (test_bit(UPTODATE))
</span><span>        return 0;
</span><span>
</span><span>    if (test_and_set_bit(READING))
</span><span>        goto done;
</span><span>
</span><span>    btrfs_submit_bio();
</span><span>
</span><span>done:
</span><span>    wait_on_bit_io(READING);
</span><span>    return 0;
</span><span>}
</span><span>
</span><span>end_bbio_meta_read()
</span><span>{
</span><span>    set_bit(UPTODATE);
</span><span>    clear_bit(READING);
</span><span>    wake_up_bit(READING);
</span><span>}
</span><span></span></code></pre>
<pre><code><span>read_extent_buffer_pages()
</span><span>{
</span><span>    if (test_bit(UPTODATE))
</span><span>        return 0;
</span><span>
</span><span>    if (test_and_set_bit(READING))
</span><span>        goto done;
</span><span>
</span><span>    btrfs_submit_bio();
</span><span>
</span><span>done:
</span><span>    wait_on_bit_io(READING);
</span><span>    return 0;
</span><span>}
</span><span></span></code></pre>
</div>


<p>Unfortunately, this locking protocol has a bug:</p>
<div id="race-2">
<pre><code><span>if (test(UPTODATE))
</span><span>    return 0;
</span><span>
</span><span>if (test_and_set(READING))
</span><span>    goto done;
</span><span>
</span><span>btrfs_submit_bio();
</span><span>
</span><span>done:
</span><span>    wait_on(READING);
</span><span>    return 0;
</span><span>
</span><span>set(UPTODATE);
</span><span>clear(READING);
</span><span>wake_up(READING);
</span><span></span></code></pre>
<pre><code><span>if (test(UPTODATE))
</span><span>    return 0;
</span><span>
</span><span>if (test_and_set(READING))
</span><span>    goto done;
</span><span>
</span><span>btrfs_submit_bio();
</span><span>
</span><span>done:
</span><span>    wait_on(READING);
</span><span>    return 0;
</span><span></span></code></pre>
<pre><code><span>if (test(UPTODATE))
</span><span>    return 0;
</span><span>
</span><span>if (test_and_set(READING))
</span><span>    goto done;
</span><span>
</span><span>btrfs_submit_bio();
</span><span>
</span><span>done:
</span><span>    wait_on(READING);
</span><span>    return 0;
</span><span></span></code></pre>
</div>

<p>If the first thread starts <em>and finishes</em> the I/O between the second thread checking the <code>UPTODATE</code> bit and the <code>READING</code> bit, the second thread will start a totally unnecessary read even though we already read in the extent.
Worse, because the <code>UPTODATE</code> bit is already set, the third will return without waiting for the read to complete.
That thread will then think it's safe to access the <code>extent_buffer</code>'s pages, despite them currently being under I/O, leading to a data race!</p>
<p>The fix is to use <a href="https://en.wikipedia.org/wiki/Double-checked_locking">double-checked locking</a>: after setting the <code>READING</code> bit, check <code>UPTODATE</code> again so we don't kick off more useless (actively harmful, even) I/O.</p>
<div id="race-3">
<pre><code><span>if (test(UPTODATE))
</span><span>    return 0;
</span><span>
</span><span>if (test_and_set(READING))
</span><span>    goto done;
</span><span>
</span><span>if (test(UPTODATE))
</span><span>    goto wake;
</span><span>
</span><span>btrfs_submit_bio();
</span><span>
</span><span>done:
</span><span>    wait_on(READING);
</span><span>    return 0;
</span><span>
</span><span>end_bbio:
</span><span>    set(UPTODATE);
</span><span>wake:
</span><span>    clear(READING);
</span><span>    wake_up(READING);
</span><span></span></code></pre>
<pre><code><span>if (test(UPTODATE))
</span><span>    return 0;
</span><span>
</span><span>if (test_and_set(READING))
</span><span>    goto done;
</span><span>
</span><span>if (test(UPTODATE))
</span><span>    goto wake;
</span><span>
</span><span>btrfs_submit_bio();
</span><span>
</span><span>done:
</span><span>    wait_on(READING);
</span><span>    return 0;
</span><span>
</span><span>end_bbio:
</span><span>    set(UPTODATE);
</span><span>wake:
</span><span>    clear(READING);
</span><span>    wake_up(READING);
</span><span></span></code></pre>
<pre><code><span>if (test(UPTODATE))
</span><span>    return 0;
</span><span>
</span><span>if (test_and_set(READING))
</span><span>    goto done;
</span><span>
</span><span>if (test(UPTODATE))
</span><span>    goto wake;
</span><span>
</span><span>btrfs_submit_bio();
</span><span>
</span><span>done:
</span><span>    wait_on(READING);
</span><span>    return 0;
</span><span>
</span><span>end_bbio:
</span><span>    set(UPTODATE);
</span><span>wake:
</span><span>    clear(READING);
</span><span>    wake_up(READING);
</span><span></span></code></pre>
</div>

<p>I submitted <a href="https://lore.kernel.org/linux-btrfs/1ca6e688950ee82b1526bb3098852af99b75e6ba.1710551459.git.tavianator@tavianator.com/">a patch</a> that adds this missing check, as well as a couple <a href="https://lore.kernel.org/linux-btrfs/cover.1710769876.git.tavianator@tavianator.com/T/">cleanup patches</a>.
With that fix, I can run the reproducer overnight without triggering any more errors.</p>
<h2 id="epilogue"><a href="#epilogue">Epilogue</a></h2>
<p>You might be surprised that this race was not benign.
After all, we're reading some disk blocks into memory that already holds the contents of those same disk blocks.
It's still technically a data race to read and write memory at the same time, even if the writes don't modify the memory, but usually it would be unobservable in practice.</p>
<div id="overwrite-1">
<pre><code>uninitialized memory uninitialized memory uninitialized memory uninitialized memory uninitialized memory
</code></pre>
<pre><code>metadata metadata metadata metadata metadata metadata metadata metadata metadata metadata metadata metad
</code></pre>
<pre><code>metadata metadata metadata metadata metadata metadata metadata metadata metadata metadata metadata metad
</code></pre>
</div>

<p>The reason I could observe it was already mentioned above: full disk encryption.
When dm-crypt processes a disk read, it reads the <em>encrypted</em> contents into memory and then decrypts them in-place.</p>
<div id="overwrite-2">
<pre><code>uninitialized memory uninitialized memory uninitialized memory uninitialized memory uninitialized memory
</code></pre>
<pre><code>encrypted gibberish encrypted gibberish encrypted gibberish encrypted gibber encrypted gibberish encrypt
</code></pre>
<pre><code>metadata metadata metadata metadata metadata metadata metadata metadata metadata metadata metadata metad
</code></pre>
<pre><code>encrypted gibberish encrypted gibberish encrypted gibberish encrypted gibber encrypted gibberish encrypt
</code></pre>
<pre><code>metadata metadata metadata metadata metadata metadata metadata metadata metadata metadata metadata metad
</code></pre>
</div>

<p>It's obvious why this causes problems: sometimes the racing thread will see valid metadata, but sometimes it will see encrypted bytes that appear totally random.
I even captured a trace where the error messages show the extent being gradually filled in:</p>
<pre><code>[  807.737576] BTRFS critical (device dm-0): corrupted node, root=266 block=3178470954007437077 owner mismatch, have 6155297726051334641 expect [256, 18446744073709551360] eb=ffff8ac915d022d0 start=12738904064
[  807.751913] BTRFS critical (device dm-0): corrupted leaf, root=266 block=12738904064 owner mismatch, have 6155297726051334641 expect [256, 18446744073709551360] eb=ffff8ac915d022d0 start=12738904064
[  807.800898] BTRFS critical (device dm-0): corrupted leaf, root=266 block=12738904064 owner mismatch, have 6155297726051334641 expect [256, 18446744073709551360] eb=ffff8ac915d022d0 start=12738904064
</code></pre>
<p>There you can see the <em>same block</em> switch from an internal node to a leaf, and the block number change from a random number to the start of the extent, over about 0.02 seconds.</p>

                    </main>

                    
                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Paris preserves its mixed society by pouring billions into public housing (272 pts)]]></title>
            <link>https://www.nytimes.com/2024/03/17/realestate/paris-france-housing-costs.html</link>
            <guid>39765692</guid>
            <pubDate>Wed, 20 Mar 2024 12:48:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2024/03/17/realestate/paris-france-housing-costs.html">https://www.nytimes.com/2024/03/17/realestate/paris-france-housing-costs.html</a>, See on <a href="https://news.ycombinator.com/item?id=39765692">Hacker News</a></p>
Couldn't get https://www.nytimes.com/2024/03/17/realestate/paris-france-housing-costs.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Lcl.host: fast, easy HTTPS in your local dev environment (161 pts)]]></title>
            <link>https://anchor.dev/blog/introducing-lcl-host</link>
            <guid>39765630</guid>
            <pubDate>Wed, 20 Mar 2024 12:42:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://anchor.dev/blog/introducing-lcl-host">https://anchor.dev/blog/introducing-lcl-host</a>, See on <a href="https://news.ycombinator.com/item?id=39765630">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><p>Today we are launching <a href="https://lcl.host/"><u>lcl.host</u></a>, a free devtool for web developers to quickly setup &amp; use HTTPS locally. With <a href="https://lcl.host/"><u>lcl.host</u></a>, you get a <a href="https://developer.mozilla.org/en-US/docs/Web/Security/Secure_Contexts"><u>secure browser context</u></a> in development that matches your production environment. Eliminate mixed asset issues, CORS errors, and secure cookie misconfiguration before they cause problems in production.</p><p>Read more about <a href="https://anchor.dev/docs/lcl-host/why-lcl"><u>the benefits of using  HTTPS in development</u></a>, and give it a try: <b>it only takes 2 minutes to switch your app to HTTPS</b>.</p><h2>Why We Built lcl.host</h2><p>Anchor provides managed private <a href="https://en.wikipedia.org/wiki/Certificate_authority"><u>certificate authorities (CAs)</u></a> for internal TLS. As both a security product and hosted SaaS application, we put a lot of effort into secure application development. From handling the private keys that sign certificates, to managing fine-grained access credentials in the dashboard, we take a rigorous approach to secure development on all layers of our stack. Keeping our development, staging, and production environments in sync (aka <a href="https://www.12factor.net/dev-prod-parity"><u>dev/prod parity</u></a>) helps to prevent bugs that would otherwise only show up in production.</p><p>For full dev/prod parity, we use HTTPS to get a secure browser context, not just the <a href="https://web.dev/articles/when-to-use-local-https#when_to_use_https_for_local_development_2"><u>secure-ish special case localhost browser context</u></a>. Before building <a href="https://lcl.host/"><u>lcl.host</u></a>, we used self-signed <span>app.localhost</span> certificates, but those have a few downsides:</p><ul><li><p>All team members had to manually provision (and re-provision) their own self-signed certificates.</p></li><li><p>The self-signed certificates had to be manually added to each trust store on the system</p></li><li><p><span>app.localhost</span> domains don't work everywhere, so <span>/etc/hosts</span> entries or a development DNS server were required for non-browser clients (like curl).</p></li><li><p>Running apps in local containers required constant certificate re-provisioning and trust store updates.</p></li></ul><p>Since we already used Anchor private CAs internally between development services, we knew it could solve some of these problems. But a private CA alone is not a complete solution.

So we built lcl.host, and we think it’s the best way to setup and use HTTPS with your apps in development:</p><ul><li><p>ACME-powered automated certificate provisioning and renewal instead of troublesome manual processes. </p></li><li><p>Hostnames that just work everywhere, with no custom configuration required.</p></li><li><p>The same secure browser context to match production, without the browser quirks in the localhost context.</p></li><li><p>Works well inside, outside, and even between containers (thanks to Anchor’s powerful packages features).</p></li><li><p>Fast setup and batteries included, no certificate or encryption expertise required.</p></li></ul><p>We’re excited to share it with you! To setup HTTPS in development, install the Anchor CLI toolchain, run <span>anchor lcl</span>, and follow the instructions. That’s it!</p><pre><code>$ brew install anchordotdev/tap/anchor
$ anchor lcl</code></pre><p>Or <a href="https://github.com/anchordotdev/cli#installation"><u>install from source</u></a> if Homebrew isn't an option.</p><p><span>Loading...</span>
<i>Use lcl.host to add HTTPS to a Next.js app</i></p><h2>How lcl.host Works</h2><p>lcl.host combines an Anchor managed private CA for your personal development environment, the <span>lcl.host</span> DNS zone to resolve subdomains to your local system, and the Anchor CLI to manage your local trust stores.</p><p><b>Personalized Private CA</b></p><p>When you sign up for an Anchor account, we automatically provision a “localhost” CA for you. This dedicated private CA provides portability between development environments and remains 100% free to use with an unlimited number of development apps. This CA has some restrictions though: it can only issue certificates for subdomains of <span>lcl.host</span> and <span>localhost</span>, but that’s all you need for local development.</p><p>The <span>anchor lcl mkcert</span> command is the easiest way to get development certificates using Anchor's zero-challenge ACME flow. Other <a href="https://acmeclients.com/"><u>ACME client</u></a> tools like <a href="https://certbot.eff.org/"><u>certbot</u></a> and <a href="https://acme.sh/"><u>acme.sh</u></a> work well too, but we recommend integrating an ACME client into your application to allow automatic certificate provisioning and renewal. Don't worry, we will walk you through that too when you run <span>anchor lcl setup</span>.</p><p><b>lcl.host DNS Zone</b></p><p>All <span>lcl.host</span> subdomains resolve to <span>127.0.0.1</span>, the same address as <span>localhost</span>. These subdomains work without HTTPS too, making them a drop-in replacement for <span>localhost</span>. To use them with HTTPS you will need a certificate for the subdomain that is trusted by your system. Your personal CA handles the first part, and the Anchor CLI takes care of your system's trust stores.</p><p><b>Trust Stores</b></p><p>A trust store manages a set of root certificates (aka <a href="https://en.wikipedia.org/wiki/Trust_anchor"><u>trust anchors</u></a>) which browsers and other clients use to verify certificates presented by servers. Some trust stores are integrated into the operating system (Keychain on MacOS), others are file/directory based (<span>/etc/ssl/certs/</span> on Debian systems), or even a custom database format (like certdb for NSS/Firefox). Keeping every trust store up to date used to be a lot of recurring manual work, but the Anchor CLI automates the whole process.</p><p>After signing in, the Anchor CLI fetches the list of expected CA certificates for your development environment, checks for them in your local trust stores, and walks you through any required changes. After this quick and easy install, your certificates will be trusted everywhere on your system.</p><p>There's a lot that's required to setup HTTPS in development. The magic of lcl.host is that it's all handled for you, so you can get back to building secure apps that work seamlessly in development and production. </p><h2>Try Now</h2><p><u></u><a href="https://github.com/anchordotdev/cli#installation"><u>Install the Anchor CLI</u></a> and run <span>anchor lcl</span> from your application directory, and have local HTTPS in no time!</p></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[People hate the idea of car-free cities until they live in one (176 pts)]]></title>
            <link>https://www.wired.com/story/car-free-cities-opposition/</link>
            <guid>39765281</guid>
            <pubDate>Wed, 20 Mar 2024 12:00:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wired.com/story/car-free-cities-opposition/">https://www.wired.com/story/car-free-cities-opposition/</a>, See on <a href="https://news.ycombinator.com/item?id=39765281">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-testid="ArticlePageChunks"><div data-journey-hook="client-content" data-testid="BodyWrapper"><p><span>London had a</span> problem. In 2016, more than 2 million of the city’s residents—roughly a quarter of its population—lived in areas with illegal levels of air pollution; areas that also contained nearly 500 of the city’s schools. That same air pollution was prematurely killing as many as <a data-offer-url="https://www.gov.uk/government/publications/air-pollution-applying-all-our-health/air-pollution-applying-all-our-health#:~:text=The%20annual%20mortality%20of%20human,and%2036,000%20deaths%20every%20year." data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.gov.uk/government/publications/air-pollution-applying-all-our-health/air-pollution-applying-all-our-health#:~:text=The%20annual%20mortality%20of%20human,and%2036,000%20deaths%20every%20year.&quot;}" href="https://www.gov.uk/government/publications/air-pollution-applying-all-our-health/air-pollution-applying-all-our-health#:~:text=The%20annual%20mortality%20of%20human,and%2036,000%20deaths%20every%20year." rel="noopener" target="_blank">36,000 people a year</a>. Much of it was coming from transport: <a data-offer-url="https://www.centreforlondon.org/blog/reimagining-london-transport/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.centreforlondon.org/blog/reimagining-london-transport/&quot;}" href="https://www.centreforlondon.org/blog/reimagining-london-transport/" rel="noopener" target="_blank">a quarter</a> of the city’s carbon emissions were from moving people and goods, with three-quarters of that emitted by road traffic.</p><p>But in the years since, carbon emissions have fallen. There’s also been a <a href="https://www.theguardian.com/environment/2020/oct/03/dramatic-plunge-in-london-air-pollution-since-2016-report-finds">94 percent reduction</a> in the number of people living in areas with illegal levels of nitrogen dioxide, a pollutant that causes lung damage. The reason? London has spent years and millions of pounds reducing the number of motorists in the city.</p><p>It’s far from alone. From Oslo to Hamburg and Ljubljana to Helsinki, cities across Europe have started working to reduce their road traffic in an effort to curb air pollution and climate change.</p><p>But while it’s certainly having an impact (Ljubljana, one of the earliest places to transition away from cars, has seen sizable reductions in carbon emissions and <a data-offer-url="https://www.ljubljana.si/en/news/air-quality-in-ljubljana/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.ljubljana.si/en/news/air-quality-in-ljubljana/&quot;}" href="https://www.ljubljana.si/en/news/air-quality-in-ljubljana/" rel="noopener" target="_blank">air pollution</a>), going car-free is a lot harder than it seems. Not only has it led to politicians and urban planners facing death threats and being doxxed, it has forced them to rethink the entire basis of city life.</p><p>London’s car-reduction policies come in a variety of forms. There are charges for dirtier vehicles and for driving into the city center. Road layouts in residential areas have been redesigned, with one-way systems and bollards, barriers, and planters used to reduce through-traffic (creating what are known as “low-traffic neighborhoods”—or LTNs). And schemes to get more people cycling and using public transport have been introduced. The city has avoided the kind of outright car bans seen elsewhere in Europe, such as in Copenhagen, but nevertheless things have changed.</p><p>“The level of traffic reduction is transformative, and it’s throughout the whole day,” says Claire Holland, leader of the council in Lambeth, a borough in south London. Lambeth now sees 25,000 fewer daily car journeys than before its LTN scheme was put in place in 2020, even after adjusting for the impact of the pandemic. Meanwhile, there was a 40 percent increase in cycling and similar rises in walking and scooting over that same period.</p><p>What seems to work best is a carrot-and-stick approach—creating positive reasons to take a bus or to cycle rather than just making driving harder. “In crowded urban areas, you can’t just make buses better if those buses are still always stuck in car traffic,” says Rachel Aldred, professor of transport at the University of Westminster and director of its Active Travel Academy. “The academic evidence suggests that a mixture of positive and negative characteristics is more effective than either on their own.”</p><p>For countries looking to cut emissions, cars are an obvious target. They make up a big proportion of a country’s carbon footprint, accounting for <a href="https://www.europarl.europa.eu/news/en/headlines/society/20190313STO31218/co2-emissions-from-cars-facts-and-figures-infographics">one-fifth of all emissions</a> across the European Union. Of course, urban driving doesn’t make up the majority of a country’s car use, but the kind of short journeys taken when driving in the city are some of the most obviously wasteful, making cities an ideal place to start if you’re looking to get people out from behind the wheel. That, and the fact that many city residents are already car-less (just 40 percent of people in Lambeth own cars, for example) and that cities tend to have better public transport alternatives than elsewhere.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>Plus, traffic-reduction programmes also have impacts beyond reducing air pollution and carbon emissions. In cities like Oslo and Helsinki, thanks to car-reduction policies, entire years have passed without a single road traffic death. It’s even been suggested that needing less parking could free up space to help ease the chronic housing shortage felt in so many cities.</p><p>But as effective as policies to end or reduce urban car use have been, they’ve almost universally faced huge opposition. When Oslo proposed in 2017 that its city center should be car-free, the backlash saw the idea branded as a “Berlin Wall against motorists.” The plan ended up being downgraded into a <a data-offer-url="http://www.aftenposten.no/osloby/Vil-ikke-lenger-tvinge-bilene-ut-av-sentrum-607083b.html" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;http://www.aftenposten.no/osloby/Vil-ikke-lenger-tvinge-bilene-ut-av-sentrum-607083b.html&quot;}" href="http://www.aftenposten.no/osloby/Vil-ikke-lenger-tvinge-bilene-ut-av-sentrum-607083b.html" rel="noopener" target="_blank">less ambitious scheme</a> consisting of smaller changes, like removing car parking and building cycle lanes to try to lower the number of vehicles.</p><p>In London, the introduction of LTNs has also <a data-offer-url="https://www.newstatesman.com/world/uk/2020/11/low-traffic-neighbourhoods-LTNs-London-car-street-cycling-walking-culture-war-pollution-gentrification" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.newstatesman.com/world/uk/2020/11/low-traffic-neighbourhoods-LTNs-London-car-street-cycling-walking-culture-war-pollution-gentrification&quot;}" href="https://www.newstatesman.com/world/uk/2020/11/low-traffic-neighbourhoods-LTNs-London-car-street-cycling-walking-culture-war-pollution-gentrification" rel="noopener" target="_blank">led to a massive backlash</a>. In the east London borough of Hackney, one councilor and his family were sent death threats due to their support for the programme. Bollards were regularly graffitied, while pro-LTN activists were accused of “social cleansing.” It was suggested that low-traffic areas would drive up house prices and leave the only affordable accommodation on unprotected roads. “It became very intimidating,” says Holland. “I had my address tweeted out twice, with sort of veiled threats from people who didn’t even live in the borough saying that we knew they knew where I lived.”</p><p>Part of that response is a testament to how much our cities, and by extension, our lives are designed around cars. In the US, between <a href="https://www.vox.com/a/new-economy-future/cars-cities-technologies">50 and 60 percent</a> of the downtowns of many cities are dedicated to parking alone. While in the UK that figure tends to be smaller, designing streets to be accessible to a never-ending stream of traffic has been the central concern of most urban planning since the Second World War. It’s what led to the huge sprawl of identikit suburban housing on the outskirts of cities like London, each sporting its own driveway and ample road access.</p><p>“If you propose this idea to the average American, the response is: if you take my car away from me, I will die,” says J. H. Crawford, the author of the book <a data-offer-url="https://www.carfree.com/book/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.carfree.com/book/&quot;}" href="https://www.carfree.com/book/" rel="noopener" target="_blank"><em>Carfree Cities</em></a> and a leading figure in the movement to end urban car use. “If you do that overnight, without making any other provisions, that’s actually approximately correct.” Having the right alternatives to cars is therefore vital to reducing city traffic.</p><p>And any attempts to reduce urban car use tend to do better when designed from the bottom up. Barcelona’s <a href="https://www.youtube.com/watch?v=ZORzsubQA_M&amp;ab_channel=Vox">“superblocks” programme</a>, which takes sets of nine blocks within its grid system and limits cars to the roads around the outside of the set (as well as reducing speed limits and removing on-street parking) was shaped by <a data-offer-url="https://ajuntament.barcelona.cat/ecologiaurbana/en/bodies-involved/citizen-participation/superblocks" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://ajuntament.barcelona.cat/ecologiaurbana/en/bodies-involved/citizen-participation/superblocks&quot;}" href="https://ajuntament.barcelona.cat/ecologiaurbana/en/bodies-involved/citizen-participation/superblocks" rel="noopener" target="_blank">having resident input on every stage of the process</a>, from design to implementation. Early indicators suggest the policy has been <a data-offer-url="https://www.barcelona.cat/infobarcelona/en/tema/urban-planning-and-infrastructures/superblocks-are-having-positive-effects-on-health-and-well-being_1097301.html" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.barcelona.cat/infobarcelona/en/tema/urban-planning-and-infrastructures/superblocks-are-having-positive-effects-on-health-and-well-being_1097301.html&quot;}" href="https://www.barcelona.cat/infobarcelona/en/tema/urban-planning-and-infrastructures/superblocks-are-having-positive-effects-on-health-and-well-being_1097301.html" rel="noopener" target="_blank">wildly popular with residents</a>, has seen nitrogen dioxide air pollution fall by 25 percent in some areas, and <a href="https://www.sciencedirect.com/science/article/pii/S0160412019315223#:~:text=The%20Superblocks%20were%20estimated%20to,CI%3A%200.6%E2%80%932.8">will prevent</a> an estimated 667 premature deaths each year, saving an estimated 1.7 billion euros.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>When it comes to design, there’s also the question of access. Whether it’s emergency services needing to get in or small businesses awaiting deliveries, there’s an important amount of “last mile” traffic—transport that gets people or things to the actual end point of their journey—that is vital to sustaining an urban area. If you want to reduce traffic, you have to work around that and think of alternative solutions—such as allowing emergency vehicles access to pedestrianized areas, or even using automatic number plate recognition to exempt emergency vehicles from the camera checks that are used to police through-traffic in LTNs (which is what Lambeth is doing, Holland says).</p><p>But even then, it’s often just hard to convince people an entirely different city layout is possible. Getting people to accept that how they live alongside cars can be changed—say, with an LTN—takes time. But government surveys of the UK’s recently implemented LTNs have indicated that support from residents for such schemes increases over time. “If you start seeing more and more of those kinds of things, things become thinkable,” explains Aldred. If you start unpicking the idea that car use can’t be changed, “it starts to become possible to do more and more things without cars for people.”</p><p>The other issue is that, to put it simply, cars are never just cars. They’re interwoven into our culture and consumption as symbols of affluence, independence, and success, and the aspiration to achieve those things in future. “A man who, beyond the age of 26, finds himself on a bus can count himself a failure,” the British prime minister Margaret Thatcher <a href="https://www.economist.com/britain/2006/09/28/the-wheels-on-the-bus">reportedly once said</a>. “That’s how we got in this mess in the first place, though,” says Crawford. “Everybody saw that the rich people were driving cars, and they wanted to too.”</p><p>That divide goes some way to explaining why the opposition to car-reduction schemes is often so extreme and can devolve into a “culture war”—which is what Holland has found in her experience with LTNs. But that struggle also outlines an important fact about car-free urban areas—that once cities make the decision to reduce or remove cars, they rarely go back. No one I spoke to for this piece could name a recent sizable pedestrianization or traffic-reduction scheme that had been reversed once it had been given time to have an effect.</p><p>Many of the cities that pioneered reducing car use—like <a href="https://www.bbc.com/future/article/20140318-five-car-free-city-experiments">Copenhagen in the 1970s</a>—are rated today as some of the best places to live in the world. Even with London’s experimental and often unpopular LTN scheme, 100 of the 130 low-traffic areas created have been kept in place, Aldred says.</p><p>“Generally speaking, if a sensible program is adopted to really reduce or eliminate car usage in a central urban area, it seems to stick,” says Crawford. “If you go back a year or two later, people will just say: well, this is the best thing we ever did.”</p><hr><p>Reaching net zero emissions by 2050 will require innovative solutions at a global scale. In this series, in partnership with the Rolex Perpetual Planet initiative, WIRED highlights individuals and communities working to solve some of our most pressing environmental challenges. It’s produced in partnership with Rolex but all content is editorially independent. <a href="https://www.wired.co.uk/topic/rolex-planet-pioneers">Find out more</a>.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google fined €250M in France for breaching intellectual property deal (103 pts)]]></title>
            <link>https://www.theguardian.com/technology/2024/mar/20/google-fined-250m-euros-in-france-for-breaching-intellectual-property-rules</link>
            <guid>39765179</guid>
            <pubDate>Wed, 20 Mar 2024 11:49:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/technology/2024/mar/20/google-fined-250m-euros-in-france-for-breaching-intellectual-property-rules">https://www.theguardian.com/technology/2024/mar/20/google-fined-250m-euros-in-france-for-breaching-intellectual-property-rules</a>, See on <a href="https://news.ycombinator.com/item?id=39765179">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p><a href="https://www.theguardian.com/technology/google" data-link-name="in body link">Google</a> has been fined €250m (£213m) by French regulators for breaching an agreement over paying media companies for reproducing their content online.</p><p>France’s competition watchdog said on Wednesday that it was fining the US tech company for breaches linked to intellectual property rules related to news media publishers. The regulator also cited concerns about Google’s AI service.</p><p>The competition authority said Google’s AI-powered chatbot Bard – since rebranded as Gemini – was trained on content from publishers and news agencies without notifying them.</p><p>The watchdog said in a statement that the fine was for “failing to respect commitments made in 2022” and accused Google of not negotiating in “good faith” with news publishers on how much to compensate them for use of their content.</p><p>Google had pledged not to contest the facts as part of settlement proceedings, the watchdog said, adding the company also proposed a series of measures to remedy certain shortcomings.</p><p>France has been battling for years to <a href="https://www.theguardian.com/world/2021/oct/21/france-hails-victory-facebook-agrees-pay-newspapers-content" data-link-name="in body link">protect the publishing rights</a> and revenue of its press and news agencies against what it termed the domination of powerful tech companies that share news content or show news stories in web searches.</p><p>Google and other online platforms have been accused of making billions from news without sharing the revenue with those who gather it.</p><p>To tackle this, the EU created a form of copyright called “neighbouring rights” that allows print media to demand compensation for using their content.</p><p>France has been a test case for the EU rules. In 2019, it was the first EU country to <a href="https://www.theguardian.com/media/2020/oct/10/backers-of-australias-mandatory-news-code-welcome-french-ruling-on-google" data-link-name="in body link">enact the directive on the publishing rights</a> of media companies and news agencies, which required large tech platforms to open talks with publishers seeking remuneration for use of news content. After initial resistance, Google and Facebook both agreed to pay some French media for articles shown in web searches.</p><p>The latest fine is linked to a copyright dispute in France over online content. The case was triggered by complaints in 2019 from some of the country’s biggest news organisations representing French magazines and newspapers, as well as the news agency Agence France-Presse (AFP).</p><p>In 2022, French regulators accepted commitments from Google to negotiate fairly with news organisations.</p><p>Under the agreement, the tech company has to provide news groups with a transparent offer of payment within three months of receiving a copyright complaint.</p><p>The dispute appeared to be resolved in 2022 when Google dropped its appeal against an initial €500m fine issued at the end of an investigation carried out by the French competition watchdog. Google had fought hard against the idea of paying for content and was fined €500m in 2021 for failing to negotiate in good faith.</p><p>In Wednesday’s statement, the watchdog said Google violated the terms of four out of seven commitments agreed in the 2022 settlement, including conducting negotiations with publishers in good faith and providing transparent information.</p><p>The watchdog in particular cited Google’s AI chatbot Bard, launched in 2023, which it said was trained on data from unspecified media outlets and news agencies without the company informing them or the regulator.</p><p>“Subsequently, Google linked the use of the content concerned by its artificial intelligence service to the display of protected content,” the watchdog said, adding that in doing so Google hindered the ability of publishers and press agencies to negotiate fair prices.</p><p>The fine comes as many publishers, writers and newsrooms seek to limit the scraping – or automatic collection of data – by AI services of their online content without their consent or fair compensation.</p><div><p>In a statement, Google said: “Google is the first and only platform to have signed a significant number of licensing agreements with 280 French news publishers under the European copyright directive. These cover more than 450 of their publications – and pay publishers tens of millions of euros a year. Despite this progress, the French competition authority today imposed a €250m fine on Google for how we have conducted those negotiations. They also insisted on changes to how we negotiate, which we have agreed to as part of a settlement of a long-running case.”</p><p>The statement added: “We’ve settled because it’s time to move on and, as our many agreements with publishers show, we want to focus on the larger goal of sustainable approaches to connecting people with quality content and on working constructively with French publishers. But it’s important to note that the fine is not proportionate to issues raised by the French competition authority. It also doesn’t sufficiently take into account the efforts we have made to answer and resolve the concerns raised – in an environment where it’s very hard to set a course because we can’t predict which way the wind will blow next.”</p></div><ul>
 <li><p><em>Agence France-Presse and Reuters contributed to this report</em></p></li>
</ul></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Indonesia's e-bike shops are building their own batteries (153 pts)]]></title>
            <link>https://restofworld.org/2024/homemade-ebike-battery-indonesia/</link>
            <guid>39764992</guid>
            <pubDate>Wed, 20 Mar 2024 11:20:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://restofworld.org/2024/homemade-ebike-battery-indonesia/">https://restofworld.org/2024/homemade-ebike-battery-indonesia/</a>, See on <a href="https://news.ycombinator.com/item?id=39764992">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				<!-- Article Start -->
				
<p>Dharmawan Kusna Handoyo spends his workday in a 2-by-3-meter cubicle, soldering batteries. He has been building DIY battery packs since 2009, when he installed one in his own electric bike — but in the past few years, it has become his main source of income. He sells the packs for hundreds of dollars apiece, luring back customers with the promise of a longer-range battery capacity.&nbsp;</p>



<p>“I put a lot of attention on how the buyer will use the bike,” Handoyo told <em>Rest of World</em>. “I think carefully about where to place the battery to avoid scratching.”&nbsp;</p>


	<figure>
		<div>
			<ul>
				<li>	<figure>
		<div>
		<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/03/NYIMASLAULA_ROW_Bali_Ebike_8678-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/03/NYIMASLAULA_ROW_Bali_Ebike_8678-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/03/NYIMASLAULA_ROW_Bali_Ebike_8678-400x267.jpg 400w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/03/NYIMASLAULA_ROW_Bali_Ebike_8678-600x400.jpg 600w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/03/NYIMASLAULA_ROW_Bali_Ebike_8678-1000x667.jpg 1000w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/03/NYIMASLAULA_ROW_Bali_Ebike_8678-1600x1067.jpg 1600w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/03/NYIMASLAULA_ROW_Bali_Ebike_8678-2800x1867.jpg 2800w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
		
		</p>
		</div>
				<figcaption itemprop="caption description">
		
		
		</figcaption>
	</figure></li><li>	<figure>
		<div>
		<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/03/NYIMASLAULA_ROW_Bali_Ebike_8784-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/03/NYIMASLAULA_ROW_Bali_Ebike_8784-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/03/NYIMASLAULA_ROW_Bali_Ebike_8784-400x267.jpg 400w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/03/NYIMASLAULA_ROW_Bali_Ebike_8784-600x400.jpg 600w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/03/NYIMASLAULA_ROW_Bali_Ebike_8784-1000x667.jpg 1000w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/03/NYIMASLAULA_ROW_Bali_Ebike_8784-1600x1067.jpg 1600w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/03/NYIMASLAULA_ROW_Bali_Ebike_8784-2800x1867.jpg 2800w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
		
		</p>
		</div>
				<figcaption itemprop="caption description">
		
		
		</figcaption>
	</figure></li>
			</ul>
		</div>
		<figcaption>Dharmawan Kusna Handoyo repairs an e-bike battery at Bengkel E-Bike in Denpasar.</figcaption>
	</figure>


<p>Handoyo is part of a growing community of battery packers in Indonesia, driven by the frenetic growth of the e-bike market and the complete absence of battery regulations in the country. This has created an opportunity for shops that can cobble together replacement batteries, which often provide more range for less cost. These homemade battery packs come with real concerns over safety and reliability — but for many riders, it’s a risk worth taking.</p>



<p>Electric two-wheelers (known in Southeast Asia as E2Ws) have become more popular&nbsp;in Indonesia since 2023, when the country announced a subsidy of 7 million rupiah ($445) for new bikes built with a certain amount of local parts. A total of 62,000 e-bikes were registered in Indonesia as of September 2023, according to the Ministry of Transportation — nearly three times the registrations in the previous year. The country has not enforced any regulations around batteries manufactured at home or by small businesses, which has led to a thriving market for scrappy replacements. Local Facebook forums are littered with advertisements for local batteries, and a search for “lithium battery for E2W” on Indonesia’s e-commerce giant, Tokopedia, yields more than 700 results.</p>



<p>Hadi Wijaya replaced his bike’s original battery for one made by his friend. He told <em>Rest of World</em> the homemade battery is both cheaper and has a longer range. “I sold the original batteries for around 17 million rupiah ($1,081), then bought a custom-made battery for 13 million rupiah ($827),” said Wijaya. The homemade battery uses lithium polymer cells, and has a range of up to 150 kilometers (1 mile = 1.6 kilometers) in a single charge, whereas the original can only reach 100 kilometers. Wijaya has now teamed up with his friend to sell e-bike batteries. “I can tell you that most people I know who use Gesit [Indonesia’s e-bike brand] no longer use the brand’s original battery,”&nbsp;he said.</p>


	<figure>
		<div>
			<ul>
				<li>	<figure>
		<div>
		<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/03/NYIMASLAULA_ROW_Bali_Ebike_8733-40x60.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/03/NYIMASLAULA_ROW_Bali_Ebike_8733-600x1066.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/03/NYIMASLAULA_ROW_Bali_Ebike_8733-400x600.jpg 400w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/03/NYIMASLAULA_ROW_Bali_Ebike_8733-600x900.jpg 600w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/03/NYIMASLAULA_ROW_Bali_Ebike_8733-1000x1500.jpg 1000w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/03/NYIMASLAULA_ROW_Bali_Ebike_8733-1600x2400.jpg 1600w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/03/NYIMASLAULA_ROW_Bali_Ebike_8733-scaled.jpg 1707w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
		
		</p>
		</div>
				<figcaption itemprop="caption description">
		
		
		</figcaption>
	</figure></li><li>	<figure>
		<div>
		<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/03/NYIMASLAULA_ROW_Bali_Ebike_8587-40x60.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/03/NYIMASLAULA_ROW_Bali_Ebike_8587-600x1066.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/03/NYIMASLAULA_ROW_Bali_Ebike_8587-400x600.jpg 400w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/03/NYIMASLAULA_ROW_Bali_Ebike_8587-600x900.jpg 600w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/03/NYIMASLAULA_ROW_Bali_Ebike_8587-1000x1500.jpg 1000w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/03/NYIMASLAULA_ROW_Bali_Ebike_8587-1600x2400.jpg 1600w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/03/NYIMASLAULA_ROW_Bali_Ebike_8587-scaled.jpg 1707w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
		
		</p>
		</div>
				<figcaption itemprop="caption description">
		
		
		</figcaption>
	</figure></li>
			</ul>
		</div>
		<figcaption> With no regulation on battery manufacturing in Indonesia, there are concerns about the safety and reliability of homemade battery packs.</figcaption>
	</figure>


<p>Manufacturing the batteries is delicate work, starting with the cylindrical battery cells. Packers often use 18650 lithium-ion cells — essentially a larger, rechargeable version of a standard flashlight battery. Cells can be bought directly from component companies like LG, Panasonic, and China’s EVE, and purchased from online marketplaces like Alibaba. There can be as many as 100 cells in a single pack, welded together with nickel strips and connected to the vehicle through a battery management system. Homemade battery packs are also bulkier than branded batteries, wrapped in bright blue heat-shrink tubing instead of the standard polycarbonate case.</p>



<p>Khairul Amin, based in Madura, East Java, has built battery packs since 2016. He aims to sell 10 batteries a month or more. The cheapest batteries in Amin’s shop cost 1.5 million rupiah ($95), but he has sold packs for as much as 35 million rupiah ($2,226) when a customer needed to power an entire car.</p>



<p>Online sellers on Facebook groups typically only state the voltage and amperage of batteries, but more complex factors like the discharge rate of individual cells could cause unexpected problems, according to Agus Purwanto, a chemistry lecturer at Sebelas Maret University. “Every battery has a rating: 1C, 2C, 3C, indicating the discharge rate of the battery,” he told <em>Rest of World</em>. If the underlying cells have different discharge rates, it could result in damage to the battery.</p>



<p>Ady Siswanto, owner of e-bike workshop Dyvolt in Jakarta, told <em>Rest of World </em>he<em> </em>takes care to match the internal resistance and capacity of the cells. “If the battery cells’ capacity isn’t uniform, the battery will have issues, like shutting off all of a sudden,” said Siswanto, who learned automotive mechanics at a local polytechnic before launching his battery pack business in 2017. Controls on overcharging and general defects are also serious concerns.</p>



<p>The chaotic nature of Indonesia’s e-bike industry means it’s difficult to find batteries that are officially certified by manufacturers. Complicating the issue further is that each e-bike maker has their own battery size and design, with no standards shared across companies. “There are possibly more than 20 battery sizes in the market right now,” Bowo Kusumo, CEO of Spora EV, told <em>Rest of World</em>. “That’s a big headache.”&nbsp;</p>


	<figure>
		<div>
			<ul>
				<li>	<figure>
		<div>
		<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/03/NYIMASLAULA_ROW_Bali_Ebike_8665-40x60.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/03/NYIMASLAULA_ROW_Bali_Ebike_8665-600x1066.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/03/NYIMASLAULA_ROW_Bali_Ebike_8665-400x600.jpg 400w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/03/NYIMASLAULA_ROW_Bali_Ebike_8665-600x900.jpg 600w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/03/NYIMASLAULA_ROW_Bali_Ebike_8665-1000x1500.jpg 1000w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/03/NYIMASLAULA_ROW_Bali_Ebike_8665-1600x2400.jpg 1600w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/03/NYIMASLAULA_ROW_Bali_Ebike_8665-scaled.jpg 1707w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
		
		</p>
		</div>
				<figcaption itemprop="caption description">
		
		
		</figcaption>
	</figure></li><li>	<figure>
		<div>
		<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/03/NYIMASLAULA_ROW_Bali_Ebike_8752-40x60.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/03/NYIMASLAULA_ROW_Bali_Ebike_8752-600x1066.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/03/NYIMASLAULA_ROW_Bali_Ebike_8752-400x600.jpg 400w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/03/NYIMASLAULA_ROW_Bali_Ebike_8752-600x900.jpg 600w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/03/NYIMASLAULA_ROW_Bali_Ebike_8752-1000x1500.jpg 1000w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/03/NYIMASLAULA_ROW_Bali_Ebike_8752-1600x2400.jpg 1600w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/03/NYIMASLAULA_ROW_Bali_Ebike_8752-scaled.jpg 1707w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
		
		</p>
		</div>
				<figcaption itemprop="caption description">
		
		
		</figcaption>
	</figure></li>
			</ul>
		</div>
		<figcaption>The homemade battery packs are advertised and sold on local online marketplaces.</figcaption>
	</figure>


<p>As part of Indonesia’s efforts to standardize EV batteries, a consortium of state companies started the Indonesia Battery Corporation in 2021. One of its initiatives is launching its own battery-swap technology using the country’s nickel reserves. Backed by Hyundai and LG, the battery cell factory is geared to <a href="https://www.thejakartapost.com/business/2023/12/12/ibc-lg-in-talks-on-battery-material-plant-in-batang.html#">start construction</a> this year.&nbsp;</p>



<p>But the flourishing online market of homemade batteries may pose a threat to battery-swap startups. More people making batteries creates demand for used battery cells, which are often scrapped from existing branded batteries that enter the secondary market, or stolen from public swapping stations. Already, prospective buyers are eyeing used batteries on Facebook forums.&nbsp;</p>



<p>“These home-based EV packers are a concern to the E2W industry,” Irwan Tjahaja, CEO of Swap Energi Indonesia, told <em>Rest of World</em>. “We need to make sure there is a safety procedure that packers follow — from design, packing to testing … Otherwise, accidents might happen.”&nbsp;</p>
				<!-- Article End -->
							</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Michel Talagrand Wins Abel Prize for Work Wrangling Randomness (207 pts)]]></title>
            <link>https://www.quantamagazine.org/michel-talagrand-wins-abel-prize-for-work-wrangling-randomness-20240320/</link>
            <guid>39764954</guid>
            <pubDate>Wed, 20 Mar 2024 11:12:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.quantamagazine.org/michel-talagrand-wins-abel-prize-for-work-wrangling-randomness-20240320/">https://www.quantamagazine.org/michel-talagrand-wins-abel-prize-for-work-wrangling-randomness-20240320/</a>, See on <a href="https://news.ycombinator.com/item?id=39764954">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Random processes take place all around us. It rains one day but not the next; stocks and bonds gain and lose value; traffic jams coalesce and disappear. Because they’re governed by numerous factors that interact with one another in complicated ways, it’s impossible to predict the exact behavior of such systems. Instead, we think about them in terms of probabilities, characterizing outcomes as likely or rare.</p>
<p>Today, the French probability theorist <a href="https://michel.talagrand.net/">Michel Talagrand</a> was awarded the Abel Prize, one of the highest honors in mathematics, for developing a deep and sophisticated understanding of such processes. The prize, presented by the king of Norway, is modeled on the Nobel and comes with 7.5 million Norwegian kroner (about $700,000). When he was told he had won, “my mind went blank,” Talagrand said. “The type of mathematics I do was not fashionable at all when I started. It was considered inferior mathematics. The fact that I was given this award is absolute proof this is not the case.”</p>
<p>Other mathematicians agree. Talagrand’s work “changed the way I view the world,” said <a href="https://web.math.princeton.edu/~naor/">Assaf Naor</a> of Princeton University. Today, added <a href="https://www.ntnu.edu/employees/helge.holden">Helge Holden</a>, the chair of the Abel prize committee, “it is becoming very popular to describe and model real-world events by random processes. Talagrand’s toolbox comes up immediately.”</p>
<p>Talagrand views his own life as a chain of unlikely events. He barely passed grade school in Lyon: Though he was interested in science, he didn’t like to study. When he was 5 years old, he lost sight in his right eye after his retina detached; at age 15, he suffered three retinal detachments in his other eye, forcing him to spend a month in the hospital, eyes bandaged, fearing he’d go blind. His father, a mathematics professor, visited him every day, keeping his mind busy by teaching him math. “This is how I learned the power of abstraction,” Talagrand <a href="https://michel.talagrand.net/longbio.pdf">wrote in 2019</a> after winning the Shaw Prize, another major math award that comes with a $1.2 million bounty. (Talagrand is using some of this money, along with his Abel winnings, to found a prize of his own, “recognizing the achievements of young researchers in the areas to which I have devoted my life.”)</p>

<p>He missed half a year of school while he recovered, but he was inspired to start focusing on his studies. He excelled in mathematics, and after graduating from college in 1974, he was hired by the French National Center for Scientific Research, Europe’s largest research institute, where he worked until his retirement in 2017. During that time, he obtained his doctorate; fell in love with his future wife, a statistician, at first sight (he proposed to her three days after meeting her); and gradually developed an interest in probability, publishing hundreds of papers on the topic.</p>
<p>That wasn’t preordained. Talagrand began his career studying high-dimensional geometric spaces. “For 10 years, I had not discovered what I was good at,” he said. But he does not regret this detour. It eventually led him to probability theory, where “I had this other viewpoint … that gave me a way to look at things differently,” he said. It enabled him to examine random processes through the lens of high-dimensional geometry.</p>
<p>“He brings in his geometric intuition to solve purely probabilistic questions,” Naor said.</p>
<p>A random process is a collection of events whose outcomes vary according to chance in a way that can be modeled — like a sequence of coin flips, or the trajectories of atoms in a gas, or daily rainfall totals. Mathematicians want to understand the relationship between individual outcomes and aggregate behavior. How many times do you have to flip a coin to figure out whether it’s fair? Will a river overflow its banks?</p>
<p>Talagrand focused on processes whose outcomes are distributed according to a bell-shaped curve called a Gaussian. Such distributions are common in nature and have a number of desirable mathematical properties. He wanted to know what can be said with certainty about extreme outcomes in these situations. So he proved a set of inequalities that put tight upper and lower bounds on possible outcomes. “To obtain a good inequality is a piece of art,” Holden said. That art is useful: Talagrand’s methods can give an optimal estimate of, say, the highest level a river might rise to in the next 10 years, or the magnitude of the strongest potential earthquake.</p>
<p>When we’re dealing with complex, high-dimensional data, finding such maximum values can be tough.</p>
<p>Say you want to assess the risk of a river flooding — which will depend on factors like rainfall, wind and temperature. You can model the river’s height as a random process. Talagrand spent 15 years developing a technique called generic chaining that allowed him to create a high-dimensional geometric space related to such a random process. His method “gives you a way to read the maximum from the geometry,” Naor said.</p>
<p>The technique is very general and therefore widely applicable. Say you want to analyze a massive, high-dimensional data set that depends on thousands of parameters. To draw a meaningful conclusion, you want to preserve the data set’s most important features while characterizing it in terms of just a few parameters. (For example, this is one way to analyze and compare the complicated structures of different proteins.) Many state-of-the-art methods achieve this simplification by applying a random operation that maps the high-dimensional data to a lower-dimensional space. Mathematicians can use Talagrand’s generic chaining method to determine the maximal amount of error that this process introduces — allowing them to determine the chances that some important feature isn’t preserved in the simplified data set.</p>
<p>Talagrand’s work wasn’t just limited to analyzing the best and worst possible outcomes of a random process. He also studied what happens in the average case.</p>
<p>In many processes, random individual events can, in aggregate, lead to highly deterministic outcomes. If measurements are independent, then the totals become very predictable, even if each individual event is impossible to predict. For instance, flip a fair coin. You can’t say anything in advance about what will happen. Flip it 10 times, and you’ll get four, five or six heads — close to the expected value of five heads — about 66% of the time. But flip the coin 1,000 times, and you’ll get between 450 and 550 heads 99.7% of the time, a result that’s even more concentrated around the expected value of 500. “It is exceptionally sharp around the mean,” Holden said.</p>
<p>“Even though something has so much randomness, the randomness cancels itself out,” Naor said. “What initially seemed like a horrible mess is actually organized.”</p>
<p>This phenomenon, known as concentration of measure, occurs in much more complicated random processes, too. Talagrand came up with a collection of inequalities that make it possible to quantify that concentration, and proved that it arises in many different contexts. His techniques marked a departure from previous work in the area. Proving the first such inequality, he wrote in his 2019 essay, was “a magical experience.” He was “in a state of constant elation.”</p>
<p>He’s particularly proud of one of his subsequent concentration inequalities. “It’s not easy to get a result which tries to think about the universe and that at the same time has a one-page proof that’s easy to explain,” he said. (He recalls with delight that he once used a cab service whose owner recognized his name, having learned the inequality during a probability class in business school. “That was extraordinary,” he said.)</p>
<p>Like his generic chaining method, Talagrand’s concentration inequalities appear all over mathematics. “It’s amazing how far it goes,” Naor said. “Talagrand inequalities are the screws that hold things together.”</p>
<p>Consider an optimization problem where you have to sort items of different sizes into bins — a model of resource allocation. When you have a lot of items, it’s very difficult to figure out the smallest number of bins you’ll need. But Talagrand’s inequalities can tell you how many bins you’re likely to need if the items’ sizes are random.</p>
<p>Similar methods have been used to prove concentration phenomena in combinatorics, physics, computer science, statistics and other settings.</p>
<p>More recently, Talagrand applied his understanding of random processes to prove an important conjecture about spin glasses, disordered magnetic materials created by random, often conflicting interactions. Talagrand was frustrated that, though spin glasses are mathematically well defined, physicists understood them better than mathematicians. “It was a thorn in our foot,” he said. He proved a result — about the so-called free energy of spin glasses — that provided a foundation for a more mathematical theory.</p>
<p>Throughout his career, Talagrand’s research has been marked by “this ability to just step back and find the general principles that are reusable everywhere,” Naor said. “He revisits and revisits, and thinks about something from all kinds of perspectives. And eventually he puts out an insight that becomes a workhorse, that everyone is using.”</p>

<p>“I like to understand simple things very well, because my brain is very slow,” Talagrand said. “So I think about them for a very, very long time.” He’s driven, he said, by the desire to “understand something deeply, in a pure way, which makes the theory much easier. Then the next generation can start from there and make progress on their own terms.”</p>
<p>Over the past decade, he has achieved this by writing textbooks — not just about random processes and spin glasses, but also about an area he doesn’t work in at all, quantum field theory. He had wanted to learn about it, but realized that all the textbooks he could find were written by and for physicists, not mathematicians. So he wrote one himself. “After you can no longer invent things, you can explain them,” he said.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: macOS Reminder Sync for Obsidian Tasks (143 pts)]]></title>
            <link>https://turquoisehexagon.co.uk/remindersync/</link>
            <guid>39764919</guid>
            <pubDate>Wed, 20 Mar 2024 11:07:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://turquoisehexagon.co.uk/remindersync/">https://turquoisehexagon.co.uk/remindersync/</a>, See on <a href="https://news.ycombinator.com/item?id=39764919">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p><img src="https://serverlez-static-prod.s3.amazonaws.com/images/512-mac.png" alt="App Logo">
        </p>
        <div>
            
            <p>Sync your Obsidian Tasks to MacOS Reminders.app!
            </p>
            <p><a href="https://apps.apple.com/us/app/reminder-sync-for-obsidian/id6478323460?mt=12&amp;itsct=apps_box_badge&amp;itscg=30200">
                <img src="https://tools.applemediaservices.com/api/badges/download-on-the-mac-app-store/black/en-us?size=250x83&amp;releaseDate=1710892800" alt="Download on the Mac App Store">
            </a>
        </p></div>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why does an extraneous build step make my Zig app 10x faster? (209 pts)]]></title>
            <link>https://mtlynch.io/zig-extraneous-build/</link>
            <guid>39764287</guid>
            <pubDate>Wed, 20 Mar 2024 09:18:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mtlynch.io/zig-extraneous-build/">https://mtlynch.io/zig-extraneous-build/</a>, See on <a href="https://news.ycombinator.com/item?id=39764287">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>For the past few months, I’ve been curious about two technologies: the Zig programming language and Ethereum cryptocurrency. To learn more about both, I’ve been using Zig to write a bytecode interpreter for the Ethereum Virtual Machine.</p><p>Zig is a great language for performance optimization, as it gives you fine-grained control over memory and control flow. To motivate myself, I’ve been benchmarking my Ethereum implementation against the official Go implementation.</p><figure><figcaption><p>At the beginning of this process, my hobby Ethereum Zig implementation underperformed the official Go implementation by about 40%.</p></figcaption></figure><p>Recently, I made what I thought was a simple refactoring to my benchmarking script, but my app’s performance tanked. I identified the relevant change as the difference between these two commands:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>$ <span>echo</span> <span>'60016000526001601ff3'</span> | xxd -r -p | zig build run -Doptimize=ReleaseFast
</span></span><span><span>execution time:  58.808µs
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="bash"><span><span>$ <span>echo</span> <span>'60016000526001601ff3'</span> | xxd -r -p | ./zig-out/bin/eth-zvm
</span></span><span><span>execution time:  438.059µs
</span></span></code></pre></div><p><code>zig build run</code> is just a shortcut command for compiling a binary and executing it. It should be equivalent to the following two commands:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>zig build
</span></span><span><span>./zig-out/bin/eth-zvm
</span></span></code></pre></div><p>How could an additional build step cause my program to run almost 10x <em>faster</em>?</p><h2 id="creating-a-minimal-reproduction-of-the-phenomenon">Creating a minimal reproduction of the phenomenon<a href="#creating-a-minimal-reproduction-of-the-phenomenon" arialabel="Anchor"> 🔗︎</a></h2><p>To debug the performance mystery, I tried simplifying my app until it was no longer a bytecode interpreter and was just a program that counted the number of bytes it read from stdin:</p><div><pre tabindex="0"><code data-lang="zig"><span><span><span>// src/main.zig
</span></span></span><span><span><span></span><span>
</span></span></span><span><span><span></span><span>const</span><span> </span>std<span> </span>=<span> </span><span>@import</span>(<span>"std"</span>);<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>pub</span><span> </span><span>fn</span><span> </span>countBytes(reader:<span> </span>anytype)<span> </span>!<span>u32</span><span> </span>{<span>
</span></span></span><span><span><span>    </span><span>var</span><span> </span>count:<span> </span><span>u32</span><span> </span>=<span> </span><span>0</span>;<span>
</span></span></span><span><span><span>    </span><span>while</span><span> </span>(<span>true</span>)<span> </span>{<span>
</span></span></span><span><span><span>        </span>_<span> </span>=<span> </span>reader.readByte()<span> </span><span>catch</span><span> </span>|err|<span> </span><span>switch</span><span> </span>(err)<span> </span>{<span>
</span></span></span><span><span><span>            </span><span>error</span>.EndOfStream<span> </span>=&gt;<span> </span>{<span>
</span></span></span><span><span><span>                </span><span>return</span><span> </span>count;<span>
</span></span></span><span><span><span>            </span>},<span>
</span></span></span><span><span><span>            </span><span>else</span><span> </span>=&gt;<span> </span>{<span>
</span></span></span><span><span><span>                </span><span>return</span><span> </span>err;<span>
</span></span></span><span><span><span>            </span>},<span>
</span></span></span><span><span><span>        </span>};<span>
</span></span></span><span><span><span>        </span>count<span> </span>+=<span> </span><span>1</span>;<span>
</span></span></span><span><span><span>    </span>}<span>
</span></span></span><span><span><span></span>}<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>pub</span><span> </span><span>fn</span><span> </span>main()<span> </span>!<span>void</span><span> </span>{<span>
</span></span></span><span><span><span>    </span><span>var</span><span> </span>reader<span> </span>=<span> </span>std.io.getStdIn().reader();<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span><span>var</span><span> </span>timer<span> </span>=<span> </span><span>try</span><span> </span>std.time.Timer.start();<span>
</span></span></span><span><span><span>    </span><span>const</span><span> </span>start<span> </span>=<span> </span>timer.lap();<span>
</span></span></span><span><span><span>    </span><span>const</span><span> </span>count<span> </span>=<span> </span><span>try</span><span> </span>countBytes(&amp;reader);<span>
</span></span></span><span><span><span>    </span><span>const</span><span> </span>end<span> </span>=<span> </span>timer.read();<span>
</span></span></span><span><span><span>    </span><span>const</span><span> </span>elapsed_micros<span> </span>=<span> </span><span>@as</span>(<span>f64</span>,<span> </span><span>@floatFromInt</span>(end<span> </span>-<span> </span>start))<span> </span>/<span> </span>std.time.ns_per_us;<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span><span>const</span><span> </span>output<span> </span>=<span> </span>std.io.getStdOut().writer();<span>
</span></span></span><span><span><span>    </span><span>try</span><span> </span>output.print(<span>"bytes:           {}</span><span>\n</span><span>"</span>,<span> </span>.{count});<span>
</span></span></span><span><span><span>    </span><span>try</span><span> </span>output.print(<span>"execution time:  {d:.3}µs</span><span>\n</span><span>"</span>,<span> </span>.{elapsed_micros});<span>
</span></span></span><span><span><span></span>}<span>
</span></span></span></code></pre></div><p>With the simplified app, I could still see the performance difference. When I ran the byte counter with <code>zig build run</code>, it ran in 13 microseconds:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>$ <span>echo</span> <span>'00010203040506070809'</span> | xxd -r -p | zig build run -Doptimize=ReleaseFast
</span></span><span><span>bytes:           <span>10</span>
</span></span><span><span>execution time:  13.549µs
</span></span></code></pre></div><p>When I ran the compiled binary directly, it took 12x as long to run, completing in 162 microseconds:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>$ <span>echo</span> <span>'00010203040506070809'</span> | xxd -r -p | ./zig-out/bin/count-bytes
</span></span><span><span>bytes:           <span>10</span>
</span></span><span><span>execution time:  162.195µs
</span></span></code></pre></div><p>My test consisted of three commands in a bash pipeline:</p><ol><li><code>echo</code> prints a sequence of ten hex-encoded bytes (<code>0x00</code>, <code>0x01</code>, …).</li><li><code>xxd</code> converts <code>echo</code>’s hex-encoded bytes to binary-encoded bytes.</li><li><code>zig build run</code> compiles and executes my byte counter program, counting the number of binary-encoded bytes that <code>xxd</code> emitted.</li></ol><p>The only difference between <code>zig build run</code> and <code>./zig-out/bin/count-bytes</code> was that the second command runs the already-compiled app, whereas the first one recompiles the app.</p><p>Again, I was dumbfounded.</p><p>How could does an extra compilation step make the program <em>faster</em>? Does a Zig app somehow run quicker when it’s fresh out of the oven?</p><p>At this point, I was stumped. I had read my source code over and over, and I couldn’t understand how compiling and running an application could be faster than running the already-compiled binary.</p><p>Zig is still a new language, so there had to be something about Zig I’d misunderstood. Surely, if experienced Zig programmers looked at my code, they’d spot my error instantly.</p><p>I <a href="https://ziggit.dev/t/zig-build-run-is-10x-faster-than-compiled-binary/3446?u=mtlynch">posted my question on Ziggit</a>, a discussion forum for Zig. The first few responses said I had a problem with “input buffering” but they didn’t have concrete suggestions to fix it or investigate further.</p><p>Andrew Kelly, Zig’s founder and lead developer made <a href="https://ziggit.dev/t/zig-build-run-is-10x-faster-than-compiled-binary/3446/8?u=mtlynch">a surprise appearance in the thread</a>. He couldn’t explain the phenomenon I was seeing, but he pointed out that I was making a different performance mistake:</p><p><a href="https://mtlynch.io/zig-extraneous-build/akelly-post.png"><img sizes="(min-width: 768px) 812px, 98vw" srcset="https://mtlynch.io/zig-extraneous-build/akelly-post_huf06dd251d6a987194ccda146e520380d_22912_300x0_resize_lanczos_3.png 300w,
https://mtlynch.io/zig-extraneous-build/akelly-post_huf06dd251d6a987194ccda146e520380d_22912_600x0_resize_lanczos_3.png 600w,
https://mtlynch.io/zig-extraneous-build/akelly-post_huf06dd251d6a987194ccda146e520380d_22912_800x0_resize_lanczos_3.png 800w,
https://mtlynch.io/zig-extraneous-build/akelly-post.png 812w" src="https://mtlynch.io/zig-extraneous-build/akelly-post.png" alt="Looks like you’re doing 1 syscall per byte read? That’s going to perform extremely poorly. My guess is that the extra steps of using the build system incidentally introduced some buffering. Not sure why though. The build system is making the child process inherit the file descriptors directly." loading="lazy"></a></p><p>Finally, my friend <a href="https://www.agwa.name/">Andrew Ayer</a> saw my post about this on Mastodon and <a href="https://m.mtlynch.io/@agwa@agwa.name/112039058255070708">solved the mystery</a>:</p><p><a href="https://mtlynch.io/zig-extraneous-build/agwa-masto.png"><img sizes="(min-width: 768px) 580px, 98vw" srcset="https://mtlynch.io/zig-extraneous-build/agwa-masto_hu3331ab99a5fa1e60d0e3808234226068_45232_300x0_resize_lanczos_3.png 300w,
https://mtlynch.io/zig-extraneous-build/agwa-masto.png 580w" src="https://mtlynch.io/zig-extraneous-build/agwa-masto.png" alt="Do you still see the 10x disparity with significantly larger inputs (i.e. > 1MB)? Do you still the disparity if you redirect stdin from a file instead of a pipe? My guess is that when you execute the program directly, xxd and count-bytes start at the same time, so the pipe buffer is empty when count-bytes first tries to read from stdin, requiring it to wait until xxd fills it. But when you use zig build run, xxd gets a head start while the program is compiling, so by the time count-bytes reads from stdin, the pipe buffer has been filled." loading="lazy"></a></p><p>Andrew Ayer got it exactly right, and I’ll break it down below.</p><p>Sidenote: Andrew Ayer also had the key insight that <a href="https://mtlynch.io/notes/picoshare-perf/#ram-bloat-is-fine-but-crashes-are-not">solved my last performance mystery</a>.</p><h2 id="my-mental-model-of-bash-pipelines-is-wrong">My mental model of bash pipelines is wrong<a href="#my-mental-model-of-bash-pipelines-is-wrong" arialabel="Anchor"> 🔗︎</a></h2><p>I had never thought too carefully about bash pipelines, but Andrew’s comment made me realize my mental model was wrong.</p><p>Imagine a simple bash pipeline like the following:</p><p>My mental model was that <code>jobA</code> would start and run to completion and then <code>jobB</code> would start with <code>jobA</code>’s output as its input.</p><figure><a href="https://mtlynch.io/zig-extraneous-build/jobs-serial.webp"><img sizes="(min-width: 768px) 572px, 98vw" srcset="https://mtlynch.io/zig-extraneous-build/jobs-serial_hu88d6b1301a67af8b3bbc95e6127380c6_1026_300x0_resize_q90_h2_lanczos_2.webp 300w,
https://mtlynch.io/zig-extraneous-build/jobs-serial.webp 570w" src="https://mtlynch.io/zig-extraneous-build/jobs-serial.webp" alt="Gantt chart of jobB starting after jobA finishes" loading="lazy"></a><figcaption><p>My incorrect mental model of how jobs in a bash pipeline work</p></figcaption></figure><p>It turns out that all commands in a bash pipeline start at the same time.</p><figure><a href="https://mtlynch.io/zig-extraneous-build/jobs-parallel.webp"><img sizes="(min-width: 768px) 572px, 98vw" srcset="https://mtlynch.io/zig-extraneous-build/jobs-parallel_hu94f5e650d86741a6659cd402fe2ceb69_3624_300x0_resize_q90_h2_lanczos_2.webp 300w,
https://mtlynch.io/zig-extraneous-build/jobs-parallel.webp 570w" src="https://mtlynch.io/zig-extraneous-build/jobs-parallel.webp" alt="Gantt chart of jobA and jobB starting simultaneously, but jobB is longer because it has to wait for jobA's results" loading="lazy"></a><figcaption><p>The actual way that jobs in a bash pipeline work</p></figcaption></figure><p>To demonstrate parallel execution in a bash pipeline, I wrote a proof of concept with two simple bash scripts.</p><p><code>jobA</code> starts, sleeps for three seconds, prints to stdout, sleeps for two more seconds, then exits:</p><div><div><pre tabindex="0"><code data-lang="bash"><span><span><span>#!/usr/bin/env bash
</span></span></span><span><span><span></span>
</span></span><span><span><span>function</span> print_status() {
</span></span><span><span>    <span>local</span> <span>message</span>=<span>"</span><span>$1</span><span>"</span>
</span></span><span><span>    <span>local</span> <span>timestamp</span>=<span>$(</span>date +<span>"%T.%3N"</span><span>)</span>
</span></span><span><span>    <span>echo</span> <span>"</span><span>$timestamp</span><span> </span><span>$message</span><span>"</span> &gt;&amp;<span>2</span>
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span>print_status <span>'jobA is starting'</span>
</span></span><span><span>
</span></span><span><span>sleep <span>3</span>
</span></span><span><span>
</span></span><span><span><span>echo</span> <span>'result of jobA is...'</span>
</span></span><span><span>
</span></span><span><span>sleep <span>2</span>
</span></span><span><span>
</span></span><span><span><span>echo</span> <span>'42'</span>
</span></span><span><span>
</span></span><span><span>print_status <span>'jobA is terminating'</span>
</span></span></code></pre></div><p><a href="https://mtlynch.io/zig-extraneous-build/jobA" download="">download jobA</a></p></div><p><code>jobB</code> starts, waits for input on stdin, then prints everything it can read from stdin until stdin closes:</p><div><div><pre tabindex="0"><code data-lang="bash"><span><span><span>#!/usr/bin/env bash
</span></span></span><span><span><span></span>
</span></span><span><span><span>function</span> print_status() {
</span></span><span><span>    <span>local</span> <span>message</span>=<span>"</span><span>$1</span><span>"</span>
</span></span><span><span>    <span>local</span> <span>timestamp</span>=<span>$(</span>date +<span>"%T.%3N"</span><span>)</span>
</span></span><span><span>    <span>echo</span> <span>"</span><span>$timestamp</span><span> </span><span>$message</span><span>"</span> &gt;&amp;<span>2</span>
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span>print_status <span>'jobB is starting'</span>
</span></span><span><span>
</span></span><span><span>print_status <span>'jobB is waiting on input'</span>
</span></span><span><span><span>while</span> <span>read</span> line; <span>do</span>
</span></span><span><span>  print_status <span>"jobB read '</span><span>${</span><span>line</span><span>}</span><span>' from input"</span>
</span></span><span><span><span>done</span> &lt; /dev/stdin
</span></span><span><span>print_status <span>'jobB is done reading input'</span>
</span></span><span><span>
</span></span><span><span>print_status <span>'jobB is terminating'</span>
</span></span></code></pre></div><p><a href="https://mtlynch.io/zig-extraneous-build/jobB" download="">download jobB</a></p></div><p>If I run <code>jobA</code> and <code>jobB</code> in a bash pipeline, exactly 5.009 seconds elapse between the <code>jobB is starting</code> and <code>jobB is terminating</code> messages:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>$ ./jobA | ./jobB
</span></span><span><span>09:11:53.326 jobA is starting
</span></span><span><span>09:11:53.326 jobB is starting
</span></span><span><span>09:11:53.328 jobB is waiting on input
</span></span><span><span>09:11:56.330 jobB <span>read</span> <span>'result of jobA is...'</span> from input
</span></span><span><span>09:11:58.331 jobA is terminating
</span></span><span><span>09:11:58.331 jobB <span>read</span> <span>'42'</span> from input
</span></span><span><span>09:11:58.333 jobB is <span>done</span> reading input
</span></span><span><span>09:11:58.335 jobB is terminating
</span></span></code></pre></div><p>If I adjust the execution so that <code>jobA</code> and <code>jobB</code> run in sequence instead of a pipeline, only 0.008 seconds elapse between <code>jobB</code>’s <code>starting</code> and <code>terminating</code> messages:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>$ ./jobA &gt; /tmp/output &amp;&amp; ./jobB &lt; /tmp/output
</span></span><span><span>16:52:10.406 jobA is starting
</span></span><span><span>16:52:15.410 jobA is terminating
</span></span><span><span>16:52:15.415 jobB is starting
</span></span><span><span>16:52:15.417 jobB is waiting on input
</span></span><span><span>16:52:15.418 jobB <span>read</span> <span>'result of jobA is...'</span> from input
</span></span><span><span>16:52:15.420 jobB <span>read</span> <span>'42'</span> from input
</span></span><span><span>16:52:15.421 jobB is <span>done</span> reading input
</span></span><span><span>16:52:15.423 jobB is terminating
</span></span></code></pre></div><h2 id="revisiting-my-byte-counter">Revisiting my byte counter<a href="#revisiting-my-byte-counter" arialabel="Anchor"> 🔗︎</a></h2><p>Once I understood that all commands in a bash pipeline run in parallel, the behavior I was seeing in my byte counter made sense:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>$ <span>echo</span> <span>'00010203040506070809'</span> | xxd -r -p | zig build run -Doptimize=ReleaseFast
</span></span><span><span>bytes:           <span>10</span>
</span></span><span><span>execution time:  13.549µs
</span></span><span><span>
</span></span><span><span>$ <span>echo</span> <span>'00010203040506070809'</span> | xxd -r -p | ./zig-out/bin/count-bytes
</span></span><span><span>bytes:           <span>10</span>
</span></span><span><span>execution time:  162.195µs
</span></span></code></pre></div><p>It looks like the time to run the <code>echo '00010203040506070809' | xxd -r -p</code> part of the pipeline takes about 150 microseconds. The <code>zig build run</code> step must take at least 150 microseconds.</p><p>By the time the <code>count-bytes</code> application actually begins in the <code>zig build</code> version, it doesn’t have to wait for the previous jobs to complete. The input is already waiting on stdin.</p><figure><a href="https://mtlynch.io/zig-extraneous-build/count-bytes-zig-run.webp"><img sizes="(min-width: 768px) 572px, 98vw" srcset="https://mtlynch.io/zig-extraneous-build/count-bytes-zig-run_hu6a9d20b88fe604bdafc0746c9fdac319_4000_300x0_resize_q90_h2_lanczos_2.webp 300w,
https://mtlynch.io/zig-extraneous-build/count-bytes-zig-run.webp 570w" src="https://mtlynch.io/zig-extraneous-build/count-bytes-zig-run.webp" alt="Gantt chart where echo, xxd, and zig build run start at the same time, but the execute phase of zig build run starts after echo and xxd are complete" loading="lazy"></a><figcaption><p>With <code>zig build run</code>, there’s a delay before my application executes, so previous jobs in the pipeline have already completed by the time <code>count-bytes</code> starts.</p></figcaption></figure><p>When I skip the <code>zig build</code> step and run the compiled binary directly, <code>count-bytes</code> starts immediately and the timer begins. The problem is that <code>count-bytes</code> has to sit around waiting ~150 microseconds for the <code>echo</code> and <code>xxd</code> commands to deliver input to stdin.</p><figure><a href="https://mtlynch.io/zig-extraneous-build/count-bytes-compiled.webp"><img sizes="(min-width: 768px) 572px, 98vw" srcset="https://mtlynch.io/zig-extraneous-build/count-bytes-compiled_hu57b45cd7d5e7b5c80beccb83ecea8677_5502_300x0_resize_q90_h2_lanczos_2.webp 300w,
https://mtlynch.io/zig-extraneous-build/count-bytes-compiled.webp 570w" src="https://mtlynch.io/zig-extraneous-build/count-bytes-compiled.webp" alt="Gantt chart where echo, xxd, and count-bytes all start at the same time, but count-bytes can't begin processing input until 150 microseconds after starting, as it's waiting on results from xxd" loading="lazy"></a><figcaption><p>When I run <code>count-bytes</code> directly, it has to wait around for ~150 microseconds until <code>echo</code> and <code>xxd</code> feed input to stdin.</p></figcaption></figure><h2 id="fixing-my-benchmark">Fixing my benchmark<a href="#fixing-my-benchmark" arialabel="Anchor"> 🔗︎</a></h2><p>Fixing my benchmark was <a href="https://github.com/mtlynch/eth-zvm/pull/27">simple</a>. Instead of running my application as part of a bash pipeline, I split the preparation stage and the execution stage into separate commands:</p><div><pre tabindex="0"><code data-lang="bash"><span><span><span># Convert the hex-encoded input to binary encoding.</span>
</span></span><span><span>$ <span>INPUT_FILE_BINARY</span>=<span>"</span><span>$(</span>mktemp<span>)</span><span>"</span>
</span></span><span><span>$ <span>echo</span> <span>'60016000526001601ff3'</span> | xxd -r -p &gt; <span>"</span><span>${</span><span>INPUT_FILE_BINARY</span><span>}</span><span>"</span>
</span></span><span><span>
</span></span><span><span><span># Read the binary-encoded input into the virtual machine.</span>
</span></span><span><span>$ ./zig-out/bin/eth-zvm &lt; <span>"</span><span>${</span><span>INPUT_FILE_BINARY</span><span>}</span><span>"</span>
</span></span><span><span>execution time:  67.378µs
</span></span></code></pre></div><p>My benchmark dropped from the 438 microseconds I was seeing before down to just 67 microseconds.</p><figure><figcaption><p>Difference in measured performance of my Zig app after I fixed my benchmarking script</p></figcaption></figure><h2 id="applying-andrew-kellys-performance-fix">Applying Andrew Kelly’s performance fix<a href="#applying-andrew-kellys-performance-fix" arialabel="Anchor"> 🔗︎</a></h2><p>Recall that Andrew Kelly <a href="https://ziggit.dev/t/zig-build-run-is-10x-faster-than-compiled-binary/3446/8?u=mtlynch">pointed out</a> that I was doing one syscall for every byte I read.</p><div><pre tabindex="0"><code data-lang="zig"><span><span><span>var</span><span> </span>reader<span> </span>=<span> </span>std.io.getStdIn().reader();<span>
</span></span></span><span><span><span></span>...<span>
</span></span></span><span><span><span></span><span>while</span><span> </span>(<span>true</span>)<span> </span>{<span>
</span></span></span><span><span><span>      </span>_<span> </span>=<span> </span>reader.readByte()<span> </span>{<span> </span><span>// Slow! One syscall per byte
</span></span></span><span><span><span></span><span>          </span>...<span>
</span></span></span><span><span><span>      </span>};<span>
</span></span></span><span><span><span>      </span>...<span>
</span></span></span><span><span><span>  </span>}<span>
</span></span></span></code></pre></div><p>So, every time my application called <code>readByte</code> in the loop, it had to halt execution, request an input read from the OS and then resume when the OS delivered the single byte.</p><p>The fix <a href="https://github.com/mtlynch/eth-zvm/pull/26">was simple</a>. I had to use a buffered reader. Instead of reading a single byte at a time from the OS, I’d use Zig’s built-in <code>std.io.bufferedReader</code>, which causes my application to read large chunks of data from the OS. That way, I only have to make a fraction of the syscalls.</p><p>Here’s the entire change:</p><div><pre tabindex="0"><code data-lang="diff"><span><span><span>diff --git a/src/main.zig b/src/main.zig
</span></span></span><span><span><span>index d6e50b2..a46f8fa 100644
</span></span></span><span><span><span></span><span>--- a/src/main.zig
</span></span></span><span><span><span></span><span>+++ b/src/main.zig
</span></span></span><span><span><span></span><span>@@ -7,7 +7,9 @@ pub fn main() !void {
</span></span></span><span><span><span></span>     const allocator = gpa.allocator();
</span></span><span><span>     defer _ = gpa.deinit();
</span></span><span><span>
</span></span><span><span><span>-    var reader = std.io.getStdIn().reader();
</span></span></span><span><span><span></span><span>+    const in = std.io.getStdIn();
</span></span></span><span><span><span>+    var buf = std.io.bufferedReader(in.reader());
</span></span></span><span><span><span>+    var reader = buf.reader();
</span></span></span><span><span><span></span>
</span></span><span><span>     var evm = vm.VM{};
</span></span><span><span>     evm.init(allocator);
</span></span></code></pre></div><p>I re-ran my example, and it sped up performance by another 11 microseconds, a modest 16% speedup.</p><div><pre tabindex="0"><code data-lang="bash"><span><span>$ zig build -Doptimize=ReleaseFast &amp;&amp; ./zig-out/bin/eth-zvm &lt; <span>"</span><span>${</span><span>INPUT_FILE_BINARY</span><span>}</span><span>"</span>
</span></span><span><span>execution time:  56.602µs
</span></span></code></pre></div><figure><figcaption><p>Buffering input reads increased performance by another 16%.</p></figcaption></figure><h2 id="benchmarking-a-larger-input">Benchmarking a larger input<a href="#benchmarking-a-larger-input" arialabel="Anchor"> 🔗︎</a></h2><p>My Ethereum interpreter currently only supports a small subset of Ethereum’s opcodes. The most complex computation my interpreter can do at this point is add numbers together.</p><p>For example, here’s an Ethereum application that counts to three by pushing <code>1</code> to the stack three times and then adding the values together:</p><div><pre tabindex="0"><code data-lang="text"><span><span>PUSH1 1    # Stack now contains [1]
</span></span><span><span>PUSH1 1    # Stack now contains [1, 1]
</span></span><span><span>PUSH1 1    # Stack now contains [1, 1, 1]
</span></span><span><span>ADD        # Stack now contains [2, 1]
</span></span><span><span>ADD        # Stack now contains [3]
</span></span></code></pre></div><p>The largest application I tested in my benchmarks was Ethereum bytecode that counted to 1,000 by adding <code>1</code> values together.</p><p>After Andrew Kelly’s tip helped me <a href="https://github.com/mtlynch/eth-zvm/pull/26">reduce syscalls</a>, my “count to 1,000” application’s runtime dropped from 2,024 microseconds to just 58 microseconds, a 35x speedup. I was now beating the official Ethereum implementation by almost a factor of two.</p><figure><figcaption><p>Buffering my input reads allowed my Zig implementation to run about 2x faster than the official Ethereum implementation on the largest Ethereum application in my test set.</p></figcaption></figure><h2 id="cheating-my-way-to-maximum-performance">Cheating my way to maximum performance<a href="#cheating-my-way-to-maximum-performance" arialabel="Anchor"> 🔗︎</a></h2><p>I was excited to see my Zig implementation finally outperforming the official Go version, but I wanted to see just how much I could leverage Zig to improve performance.</p><p>One common bottleneck in software is memory allocation. The program has to stop and wait for the OS to allocate RAM, which may involve shuffling around data to find enough contiguous space.</p><p>Zig has a memory allocator called the fixed buffer allocator. Instead of the memory allocator requesting memory from the OS, you provide the allocator a fixed buffer of bytes, and it uses only those bytes to allocate memory.</p><p>I can cheat my benchmarks by compiling a version of my Ethereum interpreter that’s limited to 2 KB of memory allocated from the stack:</p><div><pre tabindex="0"><code data-lang="diff"><span><span><span>diff --git a/src/main.zig b/src/main.zig
</span></span></span><span><span><span>index a46f8fa..9e462fe 100644
</span></span></span><span><span><span></span><span>--- a/src/main.zig
</span></span></span><span><span><span></span><span>+++ b/src/main.zig
</span></span></span><span><span><span></span><span>@@ -3,9 +3,9 @@ const stack = @import("stack.zig");
</span></span></span><span><span><span></span> const vm = @import("vm.zig");
</span></span><span><span>
</span></span><span><span> pub fn main() !void {
</span></span><span><span><span>-    var gpa = std.heap.GeneralPurposeAllocator(.{}){};
</span></span></span><span><span><span>-    const allocator = gpa.allocator();
</span></span></span><span><span><span>-    defer _ = gpa.deinit();
</span></span></span><span><span><span></span><span>+    var buffer: [2000]u8 = undefined;
</span></span></span><span><span><span>+    var fba = std.heap.FixedBufferAllocator.init(&amp;buffer);
</span></span></span><span><span><span>+    const allocator = fba.allocator();
</span></span></span><span><span><span></span>
</span></span><span><span>     const in = std.io.getStdIn();
</span></span><span><span>     var buf = std.io.bufferedReader(in.reader());
</span></span></code></pre></div><p>I call this a “cheat” as I’m optimizing for my specific benchmarks. There are certainly valid Ethereum programs that require more than 2 KB of memory, but I’m just curious how fast I can go with this optimization.</p><p>Let’s see what performance looks like if I know my max memory requirement at compile time:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>$ ./zig-out/bin/eth-zvm &lt; <span>"</span><span>${</span><span>COUNT_TO_1000_INPUT_BYTECODE_FILE</span><span>}</span><span>"</span>
</span></span><span><span>execution time:  34.4578µs
</span></span></code></pre></div><p>Cool! With a fixed memory buffer, my Ethereum implementation runs my “count to 1,000” bytecode in 34 microseconds, nearly 3x faster than the official Go implementation.</p><figure><figcaption><p>If I know the maximum memory requirements of my Ethereum interpreter at compile time, I can outperform the official implementation by 3x.</p></figcaption></figure><h2 id="conclusion">Conclusion<a href="#conclusion" arialabel="Anchor"> 🔗︎</a></h2><p>My takeaway from this experience is to benchmark performance early and often.</p><p>By adding a benchmarking script to my continuous integration and archiving the results, it was easy for me to identify when my measurements changed. Had I relegated benchmarking to a manual, periodic task, it would have been difficult for me to identify exactly what caused the difference in my measurements.</p><p>This experience also underscores the importance of understanding your metrics. Before hitting this bug, I hadn’t considered that my benchmark included the time waiting for other processes to fill stdin.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Regex character "$" doesn't mean "end-of-string" (364 pts)]]></title>
            <link>https://sethmlarson.dev/regex-$-matches-end-of-string-or-newline</link>
            <guid>39763750</guid>
            <pubDate>Wed, 20 Mar 2024 07:50:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sethmlarson.dev/regex-$-matches-end-of-string-or-newline">https://sethmlarson.dev/regex-$-matches-end-of-string-or-newline</a>, See on <a href="https://news.ycombinator.com/item?id=39763750">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<p>This article is about a bit of surprising behavior I recently discovered
using Python's regex module (<code>re</code>) while <a href="https://github.com/python/release-tools/pull/92#discussion_r1484470272">developing SBOM tooling for CPython</a>.</p>

<p>Folks who've worked with regular expressions before might know about <code>^</code> meaning "start-of-string"
and correspondingly see <code>$</code> as "end-of-string". So the pattern <code>cat$</code> would match the string <code>"lolcat"</code> but not <code>"internet cat video"</code>.</p>

<p>The behavior of <code>^</code> made me think that <code>$</code> was similar, but they aren't always symmetrical
and the behavior is <em>platform-dependent</em>. Specifically for Python with multiline mode <em>disabled</em>
the <code>$</code> character can match either the end of a string <em>or a trailing newline before the end of a string</em>.</p>

<p>So if you're trying to match a string without a newline at the end, <strong>you can't only use <code>$</code> in Python!</strong>
My expectation was having multiline mode disabled wouldn't have had this newline-matching behavior, but that isn't the case.</p>

<p>Next logical question is how does one match the end of a string without a newline in Python?</p>

<p>After doing more research on <a href="https://docs.python.org/3/library/re.html#regular-expression-syntax">Python</a>
and <a href="https://www.regular-expressions.info/anchors.html">other regular expression syntaxes</a>
I also found <code>\z</code> and <code>\Z</code> as candidates for "end-of-string" characters.</p>

<p>Multi-line mode is enabled with <a href="https://docs.python.org/3/library/re.html#re.MULTILINE"><code>re.MULTILINE</code></a> in Python, the docs have the following to say:</p>

<blockquote>
  <p>When <code>re.MULTILINE</code> is specified the pattern character '$' matches at the end of the string and at the end of each
  line (immediately preceding each newline). By default, '$' only matches at the end of the string and immediately before the newline (if any) at the end of the string.</p>
</blockquote>

<p>Let's see how these features work together across multiple platforms:</p>

<table>
<thead>
<tr>
  <th>Pattern matches <code>"cat\n"</code>?</th>
  <th><code>"cat$"</code> multiline</th>
  <th><code>"cat$"</code> no multiline</th>
  <th><code>"cat\z"</code></th>
  <th><code>"cat\Z"</code></th>
</tr>
</thead>
<tbody>
<tr>
  <td>PHP</td>
  <td>✅</td>
  <td>✅</td>
  <td>❌</td>
  <td>✅</td>
</tr>
<tr>
  <td>ECMAScript</td>
  <td>✅</td>
  <td>❌</td>
  <td>⚠️</td>
  <td>⚠️</td>
</tr>
<tr>
  <td>Python</td>
  <td>✅</td>
  <td>✅</td>
  <td>⚠️</td>
  <td>❌</td>
</tr>
<tr>
  <td>Golang</td>
  <td>✅</td>
  <td>❌</td>
  <td>❌</td>
  <td>⚠️</td>
</tr>
<tr>
  <td>Java 8</td>
  <td>✅</td>
  <td>✅</td>
  <td>❌</td>
  <td>✅</td>
</tr>
<tr>
  <td>.NET 7.0</td>
  <td>✅</td>
  <td>✅</td>
  <td>❌</td>
  <td>✅</td>
</tr>
<tr>
  <td>Rust</td>
  <td>✅</td>
  <td>❌</td>
  <td>❌</td>
  <td>⚠️</td>
</tr>
</tbody>
</table>

<ul>
<li>✅: Pattern matches the string <code>"cat\n"</code></li>
<li>❌: Pattern does not match the string <code>"cat\n"</code></li>
<li>⚠️: Pattern is invalid or character not supported.</li>
</ul>

<p>Summarizing the above table, if matching a trailing newline is acceptable then <code>$</code> with multiline mode works consistently across all platforms,
but if we wanted to <em>not match</em> a trailing newline then things get more complicated.</p>

<p>To not match a trailing newline, use <code>\z</code> on all platforms except Python and
ECMAScript where you'll need to use <code>\Z</code> or <code>$</code> without multiline mode respectively.
Hope you learned something about regular expressions today!</p>

<p>Note: The table of data was gathered from <a href="https://regex101.com/">regex101.com</a>, I didn't test using the actual runtimes.</p>

<blockquote>
    <p>
        <strong>Thanks for reading!</strong> ♡ Did you find this article helpful and want more content like it?
        <nobr>Get notified of new posts</nobr> by subscribing to the <a href="https://sethmlarson.dev/feed">RSS feed</a> or the <a href="https://buttondown.email/sethmlarson">email newsletter</a>.
    </p>
    
</blockquote>



</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[EFF: Tell Congress: We Can't Afford More Bad Patents (132 pts)]]></title>
            <link>https://act.eff.org/action/tell-congress-we-can-t-afford-more-bad-patents</link>
            <guid>39763104</guid>
            <pubDate>Wed, 20 Mar 2024 05:28:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://act.eff.org/action/tell-congress-we-can-t-afford-more-bad-patents">https://act.eff.org/action/tell-congress-we-can-t-afford-more-bad-patents</a>, See on <a href="https://news.ycombinator.com/item?id=39763104">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <h5>Creativity &amp; Innovation</h5>
        
        <p><img src="https://s3-us-west-1.amazonaws.com/actioncenter/action_pages/featured_images/000/000/554/original/patent-troll-warning.png?1710277642" alt="Patent troll warning"></p><p>Congress is pushing two bills that would bring back some of the worst patents and empower patent trolls.</p>

<p>The Patent Eligibility Restoration Act (PERA), S. 2140, would throw out crucial rules that ban patents on many abstract ideas. Courts will be ordered to approve patents on things like ordering food on a mobile phone or doing basic financial functions online. If PERA Passes, the floodgates will open for these vague software patents that will be used to sue small companies and individuals. This bill even allows for a type of patent on human genes that the Supreme Court rightly disallowed in 2013.</p>

<p>A second bill, the PREVAIL Act, S. 2220, would sharply limit the public’s right to challenge patents that never should have been granted in the first place.</p>

        


          <p>
          <label for="learn-more">Learn More</label></p><div id="description">
                <p>Patent trolls—companies that have no product or service of their own, but simply make patent infringement demands on others—are a big problem. They’ve cost our economy billions of dollars. For a small company, a patent troll demand letter can be ruinous.</p>

<p>We took a big step towards fighting off patent trolls in 2014, when a landmark Supreme Court ruling, the Alice Corp. v. CLS Bank case, established that you can’t get a patent by adding “on a computer” to an abstract idea. In 2012, Congress also expanded the ways that a patent can be challenged at the patent office.</p>

<p>These two bills, PERA and PREVAIL, would roll back both of those critical protections against patent trolls. We know that the bill sponsors, Sens. Thom Tillis (R-NC) and Chris Coons (D-DE) are pushing hard for these bills to move forward. We need your help to tell Congress that it’s the wrong move.</p>

              </div>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I Improved My Rust Compile Times by 75% (137 pts)]]></title>
            <link>https://benw.is/posts/how-i-improved-my-rust-compile-times-by-seventy-five-percent</link>
            <guid>39762807</guid>
            <pubDate>Wed, 20 Mar 2024 04:14:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://benw.is/posts/how-i-improved-my-rust-compile-times-by-seventy-five-percent">https://benw.is/posts/how-i-improved-my-rust-compile-times-by-seventy-five-percent</a>, See on <a href="https://news.ycombinator.com/item?id=39762807">Hacker News</a></p>
<div id="readability-page-1" class="page"><section><img src="https://benwis.imgix.net/girl_waiting_code_compile.png?auto=format&amp;auto=compress" alt="A woman with a pixie haircut looking at a computer in an office environment, waiting for her code to compile."><span>A woman with a pixie haircut looking at a computer in an office environment, waiting for her code to compile.</span><div><blockquote>
<p>If you're looking for a talented Rust developer, or a good senior software engineer, please reach out. I'm looking for a full time role doing something neat, and am available for contract gigs. Contact info is in the footer. Thank you!</p>
</blockquote>
<blockquote>
<p>There's now a Part 2, where I cover a couple more options. Check it out <a href="https://benw.is/posts/how-i-improved-my-rust-compile-times-part2">here</a></p>
</blockquote>
<p>One of Rust's often mentioned pain points is slow compile times. In order to have nice things like the borrow checker, safety, and zero cost abstractions, we pay in time spent compiling. Web developers, especially those that come from one of the Javascript frameworks, really, really like fast reload times. I was fairly active in the Remix discord early on, and the number of people who asked about HMR(Hot Module Reloading) <a href="https://github.com/remix-run/remix/discussions/2384">was insane</a>. Hot Module Reloading is when the web framework will replaces javascript, html, and css modules in an existing page as they are changed without losing page state. The alternative, Live Page Reloading, will trigger a page reload when a change is detected. For Remix, the time difference between the two is signifigantly less than it would be in Rust, where we'd have to recompile.</p>
<p>You can imagine, as a Leptos team member, we hear a lot of the same discussion. Leptos, as a frontend Rust web framework, sits at the intersection of these two worlds We see it on the <a href="https://discord.gg/x8NhWWYTV2">Leptos Discord</a> all the time.</p>
<blockquote>
<p>"Now, if only rebuild was faster… 🫣"</p>
</blockquote>
<blockquote>
<p>"Anyone have some tips to improve compile times? Leptos is amazing but having to wait 5-10 seconds to render an extra div is very annoying"</p>
</blockquote>
<p>So Leptos basically has two approaches to solve this, improve Rust's compile time itself, and/or come up with a way to output changes to parts of the page without needing to recompile first. In this piece, we'll explore both.</p>

                        <h2>
                            <a id="improving-rust-compile-times" href="#improving-rust-compile-times">
                                Improving Rust Compile Times
                            </a>
                        </h2>
                        
<p>In order to test different changes, we need to establish a baseline. In default Rust, on my machine, how long will it take to compile my web app?</p>

                        <h3>
                            <a id="the-test-machines" href="#the-test-machines">
                                The Test Machines
                            </a>
                        </h3>
                        
<p>I have a quite beefy test machine on which I usually compile. On my machine I'll be compiling a simpler project, and my friend Alex kindly agreed to run test his startup Houski's <a href="https://www.houski.ca/">site</a>,</p>

                        <h3>
                            <a id="my-machine" href="#my-machine">
                                My Machine
                            </a>
                        </h3>
                        
<ul>
<li>AMD 5950x processor, </li>
<li>72GB RAM</li>
<li>SATA SSD system drive. </li>
<li>7200RPM spinning disk storage drives</li>
<li>NVME drives</li>
<li>NixOS linux distro</li>
<li>Rust 1.75 nightly</li>
</ul>

                        <h3>
                            <a id="houski-s-machine" href="#houski-s-machine">
                                Houski's Machine
                            </a>
                        </h3>
                        
<ul>
<li>AMD 7900x processor</li>
<li>128GB RAM</li>
<li>NVME drive</li>
<li>Ubuntu linux distro</li>
<li>Rust 1.75 nightly</li>
</ul>

                        <h3>
                            <a id="leptos-build-process" href="#leptos-build-process">
                                Leptos Build Process
                            </a>
                        </h3>
                        
<p>A Leptos web app typicallys undergoes a two stage build process. </p>
<ol>
<li>Build Webassembly frontend module using cargo. Optimize and package it with warm-bindgen.</li>
<li>Build the server binary with cargo.</li>
</ol>
<p>I chose to benchmark the whole process for most of these demos, but since it's essentially two cargo steps, any relative changes would affect any cargo command.</p>
<blockquote>
<p>Note: Discord User @PaulH(and a couple others) let me know about this <a href="https://github.com/leptos-rs/cargo-leptos/pull/203">bug</a> that prevents the server build from using the dependencies built for the previous compilation of the server/webassembly frontend build due to changes in the RUSTFLAGS. You can fix this by having cargo-leptos &gt; 0.2.1 and adding this to you Cargo.toml under your Leptos settings block. I did not test with this enabled.</p>
<div><p>TOML markup</p><pre data-lang="toml"><i>[</i><i>package</i><i>.</i><i>metadata</i><i>.</i><i>leptos</i><i>]</i>
<i>separate-front-target-dir</i> <i>=</i> <i>true</i>
</pre></div></blockquote>

                        <h2>
                            <a id="optimizations" href="#optimizations">
                                Optimizations
                            </a>
                        </h2>
                        
                        <h3>
                            <a id="optimization-level" href="#optimization-level">
                                Optimization Level
                            </a>
                        </h3>
                        
<p>This advice comes from Bevy, which recommends setting the opt-level for development higher in order to possibly reduce dev compile times and improve performance. By default, the Rust compiler sets an opt-level of 0 for development builds. We're going to give it an opt-level of 1 for our code, and an opt-level of 3 for all the dependencies of our code.</p>
<p>This does come with the drawback of much less useful error messages if they come from our dependencies. So you might have to adjust the levels if you run into tricky bugs.</p>
<p>Since optimization takes additional time, I expect the clean compile times to increase, but we may see the increased optimizations make the code easier to compile in incremental builds. We also had some positive anecdotes on our Discord.</p>
<blockquote>
<p>"fwiw @gbj @Alex Wilkinson i dropped my compile time from between 5-30 minutes to 6 seconds by putting this in my workspace Cargo.toml</p>
</blockquote>
<p>We can enable adding these blocks to our <code>Cargo.toml</code> file. Nice and easy.</p>
<div><p>TOML markup</p><pre data-lang="toml"><i>[</i><i>profile</i><i>.</i><i>dev</i><i>]</i>
<i>opt-level</i> <i>=</i> 1
<i>[</i><i>profile</i><i>.</i><i>dev</i><i>.</i><i>package</i><i>.</i><i>"*"</i><i>]</i>
<i>opt-level</i> <i>=</i> 3
</pre></div>
                        <h3>
                            <a id="mold" href="#mold">
                                Mold
                            </a>
                        </h3>
                        
<p>For those unfamiliar with how what goes on inside the Rust compiler, it typically follows a few basic steps. It reads in source code, which is converted to a variety of types of IR(Intermediate Representation), and optimizations are performed during that conversion. Then that IR is fed to a code generator, provided by LLVM, which converts the IR into object files, and then the linker links together those object files and other system libs into one executable binary. Way more details about how that works can be found <a href="https://rustc-dev-guide.rust-lang.org/overview.html">here</a>. Fascinating reading, but a bit too deep for our discussion here.</p>
<p><a href="https://github.com/rui314/mold">Mold</a> is a new linker developed by Rui Ueyama, with the goal of increasing linker performance by parallelizing the load as much as possible, and benchmarks have shown it to be signifigantly faster than Rust's default linker.</p>
<p>For Linux and Mac, the default linker is ld, run by cc. Windows is a different story, using Microsoft's MVC link.exe. If you're running Linux, you can use mold directly. If you're on Mac, a paid version of mold called Sold is available for Mac. If Mold generates benefits for you, I encourage you to buy Sold(very affordable) or sponsor Rui on his Github Sponsors <a href="https://github.com/sponsors/rui314">page</a>. Windows users, unforunately, are not supported at this time. Support for Windows in Sold is in development.</p>
<p>A fairly signifigant amount of time is spent linking your Rust binary, especially during incremental builds, so this could provide some real benefits.</p>
<p>On Linux, it's actually really easy to use, just <a href="https://github.com/rui314/mold">install Mold</a> and then prepend you cargo commands with <code>mold -run</code>. For example, <code>mold -run cargo build</code>. It can also be enabled in <code>.cargo/config.toml</code>, like this:</p>
<div><p>TOML markup</p><pre data-lang="toml"><i>[</i><i>target</i><i>.</i><i>x86_64-unknown-linux-gnu</i><i>]</i>
<i>linker</i> <i>=</i> <i>"clang"</i>
<i>rustflags</i> <i>=</i> <i>[</i><i>"-C"</i><i>,</i> <i>"link-arg=-fuse-ld=/path/to/mold"</i><i>]</i>
</pre></div>
<p>where <code>/path/to/mold</code> is an absolute path to the mold executable. This is also how you enable Sold, just replace the mold path with the sold path and the target to the one for your Mac.</p>

                        <h3>
                            <a id="cranelift" href="#cranelift">
                                Cranelift
                            </a>
                        </h3>
                        
<p>In the previous optimization, we replaced the linker the Rust compiler uses. Let's try replacing the code generator, Cranelift is an alternative code generator, used instead of LLVM in the build step. While it's not good at doing as many optimizations as LLVM, it is good at spitting out code fast. It was recently integrated as an option for code generation in Rust 1.73 nightly for x86_64 linux targets. Other platforms will need to setup cranelift seperately, see their <a href="https://github.com/rust-lang/rustc_codegen_cranelift">README</a>.</p>
<div><p>bash</p><pre data-lang="bash">rustup update nightly #install nightly if you haven't already
rustup component add rustc-codegen-cranelift-preview --toolchain nightly
</pre></div>
<p>To use it with Cargo, it can be enabled by enabling the unstable <code>codegen-backend</code> feature, and then setting the <code>codegen-backend= "cranelift"</code> value for a profile. That can be done in <code>.cargo/config.toml</code> like so:</p>
<div><p>TOML markup</p><pre data-lang="toml"><i>[</i><i>unstable</i><i>]</i>
<i>codegen-backend</i> <i>=</i> <i>true</i>
<i>[</i><i>profile</i><i>.</i><i>server-dev</i><i>]</i>
<i>codegen-backend</i> <i>=</i> <i>"cranelift"</i>
</pre></div>
<p>If you don't need to worry about multi-target builds, you can also enable it below with a target. This does conflict with the desire to not use cranelift during production builds, so I wouldn't recommend it. Rust doesn't support per target profile builds, so creating your own profile is a lot more flexible.</p>
<div><p>TOML markup</p><pre data-lang="toml"><i>[</i><i>target</i><i>.</i><i>x86_64-unknown-linux-gnu</i><i>]</i>
<i>rustflags</i> <i>=</i> <i>[</i><i>"-Zcodegen-backend=cranelift"</i><i>]</i>
</pre></div>
<p>Keep in mind that Cranelift is still in development, and may have some issues with missing intrinsics. So your crate may or may not work in it natively. If you do find missing intrinsics, I encourage you to create an issue in their repo <a href="https://github.com/rust-lang/rustc_codegen_cranelift">here</a>, there may be a workaround available.</p>

                        <h3>
                            <a id="methodology" href="#methodology">
                                Methodology
                            </a>
                        </h3>
                        
<p>I'm primarily interested in optimizing build times for Rust projects in development. This means I'm not concerned about filesize, optimizations, or run speed, as long as they are not signifigantly affected. We're interested in the time it takes to build our Rust Leptos apps, both from a clean state, and with incremental compilation.</p>
<p>To do that we're going to use <a href="https://github.com/sharkdp/hyperfine">hyperfine</a> a command line benchmarking tool, to run 'cargo leptos build', which as described earlier does Leptos's two step compilation. For clean builds, we will run <code>cargo clean</code> before each build, in order to delete any files cached by Rust. Incremental builds are a bit harder.</p>
<p>For incremental builds, we'll simulate a developer modifying a single HTML tag in a Leptos component. To do that, we'll run our handy unix friend <code>sed</code> to insert the current date and time into an HTML tag. For this purpose, I've chosen the <code>&lt;dfn&gt;</code> tag, because I've never seen it used, and thus I probably don't have to worry about multiple replacements tags. After some finagling, I ended up with this sed command:</p>
<div><p>bash</p><pre data-lang="bash">sed -i -e "s|&lt;dfn&gt;[^&lt;]*&lt;/dfn&gt;|&lt;dfn&gt;$(date +%m%s)&lt;/dfn&gt;|g" src/routes/index.rs
</pre></div>
<p>Each configuration is tested six times, with two warmup runs to fill any caches and reduce variability in the output. Without the warmup runs variance was a bit wider, but the results were still consistent. Six runs is probably overkill for this test, but what can I say, I got CPU time for days, or more accurately nights.</p>
<p>We'll measure the time it takes to complete six runs, with two warmup runs to setup filesystem caches, and hopefully provide consistent results.</p>
<p>I will be compiling my <a href="https://benwis/">site</a>, and Alex will be compiling <a href="https://houski.ca/">Houski's site</a>. Houski's is a lot more complicated than this blog, with heavy usage of Polars, Serialization/Deserialization with Serde, and plenty more routes. Neither of us has tried to reduce these times much or done any special kinds of optimization.</p>

                        <h2>
                            <a id="it-s-benchmarking-time" href="#it-s-benchmarking-time">
                                It's Benchmarking Time
                            </a>
                        </h2>
                        
                        <h3>
                            <a id="baseline" href="#baseline">
                                Baseline
                            </a>
                        </h3>
                        
<p>For both of us, these will be the times to beat.</p>
<table><thead><tr><th>Clean Compilation</th><th></th><th></th></tr></thead><tbody>
<tr><td>Site</td><td>Mean(s)</td><td>Standard Deviation(s)</td></tr>
<tr><td>benw.is 7200RPM</td><td>88.387</td><td>1.817</td></tr>
<tr><td>benw.is NVME</td><td>80.057</td><td>0.268</td></tr>
<tr><td>houski.ca</td><td>124.993</td><td>0.483</td></tr>
</tbody></table>
<table><thead><tr><th>Incremental Compilation</th><th></th><th></th></tr></thead><tbody>
<tr><td>Site</td><td>Mean(s)</td><td>Standard Deviation(s)</td></tr>
<tr><td>benw.is 7200RPM</td><td>20.461</td><td>0.801</td></tr>
<tr><td>benw.is NVME</td><td>19.097</td><td>0.078</td></tr>
<tr><td>houski.ca</td><td>40.818</td><td>0.252</td></tr>
</tbody></table>
<p>Not a bad baseline. Interesting to me was the variation in the 7200RPM build time for both clean and incremental builds, which might suggest that the drive was struggling to provide the data at the same rate consistently, or perhaps something else was contending with the benchmark for IO access.</p>
<p>Twenty or forty seconds is a pretty substantial time to rebuild the site in the dev profile, hopefully we can improve that.</p>

                        <h3>
                            <a id="mold-enabled" href="#mold-enabled">
                                Mold Enabled
                            </a>
                        </h3>
                        
<p>Let's enable the Mold linker as described earlier, and see how that changes things!</p>
<table><thead><tr><th>Clean Compilation</th><th></th><th></th><th></th><th></th></tr></thead><tbody>
<tr><td>Site</td><td>Mean(s)</td><td>Standard Deviation(s)</td><td>Delta from Baseline(s)</td><td>% Delta from Baseline</td></tr>
<tr><td>benw.is 7200RPM</td><td>74.35</td><td>0.96</td><td>14.037</td><td>15.88129476</td></tr>
<tr><td>benw.is NVME</td><td>67.206</td><td>0.386</td><td>12.851</td><td>16.05231273</td></tr>
<tr><td>houski.ca</td><td>102.892</td><td>0.416</td><td>22.101</td><td>17.68179018</td></tr>
</tbody></table>
<table><thead><tr><th>Incremental Compilation</th><th></th><th></th><th></th><th></th></tr></thead><tbody>
<tr><td>Site</td><td>Mean(s)</td><td>Standard Deviation(s)</td><td>Delta from Baseline(s)</td><td>% Delta from Baseline</td></tr>
<tr><td>benw.is 7200RPM</td><td>5.842</td><td>0.268</td><td>14.619</td><td>71.44812082</td></tr>
<tr><td>benw.is NVME</td><td>5.615</td><td>0.051</td><td>13.482</td><td>70.59747604</td></tr>
<tr><td>houski.ca</td><td>19.6</td><td>0.067</td><td>21.218</td><td>51.98196874</td></tr>
</tbody></table>
<p>Woah! That's quite a bit faster. For my site, clean compilation time decreased by 12.04s(13.6%) on spinning disk and  12.80s(16.0%) for NVME. Houski dropped 22.10s(17.7s). Nice boost there.</p>
<p>Incremental compilation times changed signifigantly as well. My site on spinning disk dropped 14.62s(71.4%) and 13.5s(70.6%). That's a radical reduction, which makes some sense. Incremental compilation spends a majority of it's time in the linking step, so any upgrades there will disproportionally affect it. </p>
<p>As far as Leptos users go, mold only supports compiling for x84_64_linux, so the webassembly compile time remained unchanged. Most of these optimizations only affect the server build, but I will be careful to note which ones don't.</p>
<p>With few downsides, and such a huge upside, Mold/Sold seems like a no-brainer, especially if you are doing a lot of incremental builds!</p>

                        <h3>
                            <a id="optimization-levels" href="#optimization-levels">
                                Optimization Levels
                            </a>
                        </h3>
                        
<p>What will adding more optimization do to compile times?</p>
<table><thead><tr><th>Clean Compilation</th><th></th><th></th><th></th><th></th></tr></thead><tbody>
<tr><td>Site</td><td>Mean(s)</td><td>Standard Deviation(s)</td><td>Delta from Baseline(s)</td><td>% Delta from Baseline</td></tr>
<tr><td>benw.is 7200RPM</td><td>174.399</td><td>0.488</td><td>-86.012</td><td>-97.31295326</td></tr>
<tr><td>benw.is NVME</td><td>166.847</td><td>0.41</td><td>-86.79</td><td>-108.4102577</td></tr>
<tr><td>houski.ca</td><td>288.562</td><td>0.674</td><td>-163.569</td><td>-130.8625283</td></tr>
</tbody></table>
<table><thead><tr><th>Incremental Compilation</th><th></th><th></th><th></th><th></th></tr></thead><tbody>
<tr><td>Site</td><td>Mean(s)</td><td>Standard Deviation(s)</td><td>Delta from Baseline(s)</td><td>% Delta from Baseline</td></tr>
<tr><td>benw.is 7200RPM</td><td>16.201</td><td>1.303</td><td>4.26</td><td>20.82009677</td></tr>
<tr><td>benw.is NVME</td><td>14.334</td><td>0.147</td><td>4.763</td><td>24.94109022</td></tr>
<tr><td>houski.ca</td><td>32.489</td><td>0.348</td><td>8.329</td><td>20.40521339</td></tr>
</tbody></table>
<p>I did expect a clean compile to be slower, but this is quite a bit slower. Compared to baseline, it takes twice as long for clean builds. Incremental builds do net a twenty percent improvement, which is nice to see. Contained within the listed build time is a doubling of both the webassembly and server builds, which makes sense but should be noted. For me, I don't think the benefits of setting this are worth the delays in clean compile times.</p>

                        <h3>
                            <a id="cranelift" href="#cranelift">
                                Cranelift
                            </a>
                        </h3>
                        <table><thead><tr><th>Clean Compilation</th><th></th><th></th><th></th><th></th></tr></thead><tbody>
<tr><td>Site</td><td>Mean(s)</td><td>Standard Deviation(s)</td><td>Delta from Baseline(s)</td><td>% Delta from Baseline</td></tr>
<tr><td>benw.is 7200RPM</td><td>67.989</td><td>0.763</td><td>20.398</td><td>23.07805447</td></tr>
<tr><td>benw.is NVME</td><td>63.645</td><td>0.247</td><td>16.412</td><td>20.50039347</td></tr>
<tr><td>houski.ca</td><td></td><td></td><td></td><td></td></tr>
</tbody></table>
<table><thead><tr><th>Incremental Compilation</th><th></th><th></th><th></th><th></th></tr></thead><tbody>
<tr><td>Site</td><td>Mean(s)</td><td>Standard Deviation(s)</td><td>Delta from Baseline(s)</td><td>% Delta from Baseline</td></tr>
<tr><td>benw.is 7200RPM</td><td>9.201</td><td>0.092</td><td>11.26</td><td>55.03152339</td></tr>
<tr><td>benw.is NVME</td><td>9.345</td><td>0.212</td><td>9.752</td><td>51.0656124</td></tr>
<tr><td>houski.ca</td><td></td><td></td><td></td><td></td></tr>
</tbody></table>
<p>Cranelift, I had high hopes for you, and you delivered! It improved both clean and incremental compilations compared to the baseline. You may notice that the houski app lines here are blank, which are due to a failure to compile due to missing llvm intrinsics. </p>
<p>After my testing completed, they merged this <a href="https://benw.is/posts/%5B#1417%5D(https://github.com/rust-lang/rustc_codegen_cranelift/pull/1417)">PR</a> which added the missing <code>llvm.x86.avx.ldu.dq.256</code> instrinsic, and @bjorn3 mentioned that I can avoid the missing aes intrinsics with a rust flag <code>RUSTFLAGS="--cfg aes_force_soft"</code>. Either that, or this <a href="https://github.com/rust-lang/rustc_codegen_cranelift/pull/1425">PR</a> gets merged into rustup nightly. I hope to update this section soon. </p>
<p>If you are missing intrinsics, you can hook up a debugger to see what is causing the trap, or you can use <code>cargo vendor</code> and do a search for the the intrinsic name or part of the intrinsic name. I'd be sure to mention anything you're missing in the <a href="https://github.com/rust-lang/rustc_codegen_cranelift/issues/171#issuecomment-1803136179">rustc cranelift repo</a> and occasionally check in to see if there's a fix coming. @bjorn3 is on a roll there.</p>

                        <h3>
                            <a id="o3-mold" href="#o3-mold">
                                O3 + Mold
                            </a>
                        </h3>
                        <table><thead><tr><th>Clean Compilation</th><th></th><th></th><th></th><th></th></tr></thead><tbody>
<tr><td>Site</td><td>Mean(s)</td><td>Standard Deviation(s)</td><td>Delta from Baseline(s)</td><td>% Delta from Baseline</td></tr>
<tr><td>benw.is 7200RPM</td><td>170.241</td><td>1.016</td><td>-81.854</td><td>-92.60864154</td></tr>
<tr><td>benw.is NVME</td><td>168.047</td><td>1.018</td><td>-87.99</td><td>-109.9091897</td></tr>
<tr><td>houski.ca</td><td>271.949</td><td>0.735</td><td>-146.956</td><td>-117.571384</td></tr>
</tbody></table>
<table><thead><tr><th>Incremental Compilation</th><th></th><th></th><th></th><th></th></tr></thead><tbody>
<tr><td>Site</td><td>Mean(s)</td><td>Standard Deviation(s)</td><td>Delta from Baseline(s)</td><td>% Delta from Baseline</td></tr>
<tr><td>benw.is 7200RPM</td><td>5.789</td><td>0.051</td><td>14.672</td><td>71.70715019</td></tr>
<tr><td>benw.is NVME</td><td>5.727</td><td>0.041</td><td>13.37</td><td>70.01099649</td></tr>
<tr><td>houski.ca</td><td>18.15</td><td>0.202</td><td>22.668</td><td>55.53432309</td></tr>
</tbody></table>
<p>Our first combination of features. Unforunately, this seems to have the slow clean compile times of O3, without decreasing compile times more than mold alone.</p>

                        <h3>
                            <a id="o3-mold-cranelift" href="#o3-mold-cranelift">
                                O3 + Mold + Cranelift
                            </a>
                        </h3>
                        <table><thead><tr><th>Clean Compilation</th><th></th><th></th><th></th><th></th></tr></thead><tbody>
<tr><td>Site</td><td>Mean(s)</td><td>Standard Deviation(s)</td><td>Delta from Baseline(s)</td><td>% Delta from Baseline</td></tr>
<tr><td>benw.is 7200RPM</td><td>107.401</td><td>1.05</td><td>-19.014</td><td>-21.51221333</td></tr>
<tr><td>benw.is NVME</td><td>103.544</td><td>0.88</td><td>-23.487</td><td>-29.33784678</td></tr>
<tr><td>houski.ca</td><td></td><td></td><td></td><td></td></tr>
</tbody></table>
<table><thead><tr><th>Incremental Compilation</th><th></th><th></th><th></th><th></th></tr></thead><tbody>
<tr><td>Site</td><td>Mean(s)</td><td>Standard Deviation(s)</td><td>Delta from Baseline(s)</td><td>% Delta from Baseline</td></tr>
<tr><td>benw.is 7200RPM</td><td>4.992</td><td>0.322</td><td>15.469</td><td>75.60236548</td></tr>
<tr><td>benw.is NVME</td><td>4.767</td><td>0.073</td><td>14.33</td><td>75.03796408</td></tr>
<tr><td>houski.ca</td><td></td><td></td><td></td><td></td></tr>
</tbody></table>
<p>Let's enable all the things! The incremental compiles are faster than any of the previously tested options, but the clean compiles are still suffering a penalty from O3. Cranelift seems to reduce the penalty from O3, but time will tell whether it is better than Mold + Cranelift alone. I suspect this is because Cranelift optimizes less than llvm, which is in line with their documentation.</p>

                        <h3>
                            <a id="cranelift-o3" href="#cranelift-o3">
                                Cranelift + O3
                            </a>
                        </h3>
                        <table><thead><tr><th>Clean Compilation</th><th></th><th></th><th></th><th></th></tr></thead><tbody>
<tr><td>Site</td><td>Mean(s)</td><td>Standard Deviation(s)</td><td>Delta from Baseline(s)</td><td>% Delta from Baseline</td></tr>
<tr><td>benw.is 7200RPM</td><td>110.251</td><td>0.687</td><td>-21.864</td><td>-24.737</td></tr>
<tr><td>benw.is NVME</td><td>106.732</td><td>0.526</td><td>-26.675</td><td>-33.323</td></tr>
<tr><td>houski.ca</td><td></td><td></td><td></td><td></td></tr>
</tbody></table>
<table><thead><tr><th>Incremental Compilation</th><th></th><th></th><th></th><th></th></tr></thead><tbody>
<tr><td>Site</td><td>Mean(s)</td><td>Standard Deviation(s)</td><td>Delta from Baseline(s)</td><td>% Delta from Baseline</td></tr>
<tr><td>benw.is 7200RPM</td><td>9.096</td><td>0.351</td><td>11.365</td><td>55.54469479</td></tr>
<tr><td>benw.is NVME</td><td>8.73</td><td>0.076</td><td>10.367</td><td>54.28601351</td></tr>
<tr><td>houski.ca</td><td></td><td></td><td></td><td></td></tr>
</tbody></table>
<p>Adding further support to the Cranelift optimization hypothesis, we see similiar performance in the clean compilation, but slower performance in incremental without Mold enabled. It is interesting that this ran faster than the previous test with Mold enabled, although I am not sure the difference is signifigant. Perhaps Mold and Cranelift or Mold and O3 have some negative interaction I don't recognize.</p>

                        <h3>
                            <a id="cranelift-mold" href="#cranelift-mold">
                                Cranelift + Mold
                            </a>
                        </h3>
                        <table><thead><tr><th>Clean Compilation</th><th></th><th></th><th></th><th></th></tr></thead><tbody>
<tr><td>Site</td><td>Mean(s)</td><td>Standard Deviation(s)</td><td>Delta from Baseline(s)</td><td>% Delta from Baseline</td></tr>
<tr><td>benw.is 7200RPM</td><td>65.343</td><td>1.243</td><td>23.044</td><td>26.07170738</td></tr>
<tr><td>benw.is NVME</td><td>59.777</td><td>0.191</td><td>20.28</td><td>25.33195098</td></tr>
<tr><td>houski.ca</td><td></td><td></td><td></td><td></td></tr>
</tbody></table>
<table><thead><tr><th>Incremental Compilation</th><th></th><th></th><th></th><th></th></tr></thead><tbody>
<tr><td>Site</td><td>Mean(s)</td><td>Standard Deviation(s)</td><td>Delta from Baseline(s)</td><td>% Delta from Baseline</td></tr>
<tr><td>benw.is 7200RPM</td><td>4.831</td><td>0.251</td><td>15.63</td><td>76.38922829</td></tr>
<tr><td>benw.is NVME</td><td>4.654</td><td>0.067</td><td>14.443</td><td>75.62968005</td></tr>
<tr><td>houski.ca</td><td></td><td></td><td></td><td></td></tr>
</tbody></table>
<p>Here's the big money, Cranelift and Mold together. This offered the fastest clean compilation times, with a roughly 25% reduction, and incremental, sitting pretty at around 75% reduction. Interestingly enough, there seemed to be little difference between the NVME and the 7200RPM drives here, suggesting that these two might be better at using disk I/O than some of the other configurations. </p>

                        <h2>
                            <a id="hot-reloading" href="#hot-reloading">
                                Hot Reloading
                            </a>
                        </h2>
                        
<p>For Rust web frameworks, we can try to simulate the performance of HMR, but we won't be able to substitute JS modules. Our attempt to do this is in cargo-leptos, and can be used with the <code>--hot-reload</code> flag. It will attempt to send html and css patches to the browser over a web socket connection when a change inside a <code>view</code> macro is detected that does not involve a change to a  rust code block, and compile in the background. For me it works fairly well.</p>
<p>I didn't try to instrument and test it, as hot reload times are nearly instant. Any changes to the rust code will require a incremental recompilation though, which is why it's so useful to improve that time. JS frameworks will probably have an edge there for the foreseeable future. </p>

                        <h2>
                            <a id="conclusion" href="#conclusion">
                                Conclusion
                            </a>
                        </h2>
                        
<p>Enabling Mold and Cranelift netted me a 75% incremental and 25% clean compilation time reduction, which is quite signifigant. Using Cranelift requires nightly, or setting it up outside rustup, which some projects might find undesirable. Since Mold requires Linux, and Sold requires Mac(and paying), for me this further increases the argument that Rust web development should be done on some for of Linux or Mac, and not on Windows. WSL2 may help improve things, but may <a href="https://medium.com/for-linux-users/wsl-2-why-you-should-use-real-linux-instead-4ee14364c18">be slower</a>. Since I have a Mac laptop and a Linux workstation, I will be buying Sold for my Mac and using Cranelift for my projects that can. </p>
<p>If you feel like running some of these tests on your hardware or with your project, I have automated the process somewhat and put that repo on Github <a href="https://github.com/benwis/customs">here</a>.</p>
<p>Let me know what your experience was, and whether this helped you with your project by reaching out on mastodon at <code>@benwis@hachyderm.io</code>.</p>
</div></section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Long Covid brain fog may be due to damaged blood vessels in the brain (213 pts)]]></title>
            <link>https://www.sciencenews.org/article/long-covid-brain-fog-blood-brain-barrier-damage</link>
            <guid>39762776</guid>
            <pubDate>Wed, 20 Mar 2024 04:06:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.sciencenews.org/article/long-covid-brain-fog-blood-brain-barrier-damage">https://www.sciencenews.org/article/long-covid-brain-fog-blood-brain-barrier-damage</a>, See on <a href="https://news.ycombinator.com/item?id=39762776">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
		

<article id="post-3137509">
	<header>
	<div>
			<h2>Long COVID brain fog may be due to damaged blood vessels in the brain</h2>

							<p>
					The result suggests there is a biological basis for this symptom				</p>
					</div>

		<figure>
		<p><img width="1030" height="580" src="https://i0.wp.com/www.sciencenews.org/wp-content/uploads/2024/03/030624_mr_covid-brainfog_feat.jpg?fit=1030%2C580&amp;ssl=1" alt="A foggy image of a woman with long, dark hair swept to the left." decoding="async" srcset="https://i0.wp.com/www.sciencenews.org/wp-content/uploads/2024/03/030624_mr_covid-brainfog_feat.jpg?w=1440&amp;ssl=1 1440w, https://i0.wp.com/www.sciencenews.org/wp-content/uploads/2024/03/030624_mr_covid-brainfog_feat.jpg?resize=680%2C383&amp;ssl=1 680w, https://i0.wp.com/www.sciencenews.org/wp-content/uploads/2024/03/030624_mr_covid-brainfog_feat.jpg?resize=800%2C450&amp;ssl=1 800w, https://i0.wp.com/www.sciencenews.org/wp-content/uploads/2024/03/030624_mr_covid-brainfog_feat.jpg?resize=330%2C186&amp;ssl=1 330w, https://i0.wp.com/www.sciencenews.org/wp-content/uploads/2024/03/030624_mr_covid-brainfog_feat.jpg?resize=768%2C432&amp;ssl=1 768w, https://i0.wp.com/www.sciencenews.org/wp-content/uploads/2024/03/030624_mr_covid-brainfog_feat.jpg?resize=1030%2C580&amp;ssl=1 1030w, https://i0.wp.com/www.sciencenews.org/wp-content/uploads/2024/03/030624_mr_covid-brainfog_feat.jpg?resize=1380%2C776&amp;ssl=1 1380w" sizes="(max-width: 1030px) 100vw, 1030px" data-attachment-id="3137511" data-permalink="https://www.sciencenews.org/030624_mr_covid-brainfog_feat" data-orig-file="https://i0.wp.com/www.sciencenews.org/wp-content/uploads/2024/03/030624_mr_covid-brainfog_feat.jpg?fit=1440%2C810&amp;ssl=1" data-orig-size="1440,810" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="030624_mr_covid-brainfog_feat" data-image-description="" data-image-caption="<div>
<p><span class=&quot;None&quot;>Brain fog is a debilitating symptom commonly reported by people with long COVID. Now, scientists have linked the symptom to leaky boundaries in the brain. </span></p>
</div>
" data-medium-file="https://i0.wp.com/www.sciencenews.org/wp-content/uploads/2024/03/030624_mr_covid-brainfog_feat.jpg?fit=680%2C383&amp;ssl=1" data-large-file="https://i0.wp.com/www.sciencenews.org/wp-content/uploads/2024/03/030624_mr_covid-brainfog_feat.jpg?fit=800%2C450&amp;ssl=1">		</p>

					<figcaption>
									<span>
						
<p><span>Brain fog is a debilitating symptom commonly reported by people with long COVID. Now, scientists have linked the symptom to leaky boundaries in the brain. </span></p>

					</span>
				
									<span>
						<span>baona/iStock/Getty Images Plus</span>
					</span>
							</figcaption>
			</figure>
	</header>

	

		
		
	<div data-component="video-embed">
				




<p>Leakiness in the brain could explain the memory and concentration problems linked to long COVID.&nbsp;</p>



<p>In patients with brain fog,&nbsp;<a href="https://www.nature.com/articles/s41593-024-01576-9" target="_blank" rel="noopener">MRI scans revealed signs of damaged blood vessels in their brains</a>, researchers reported February 22 in&nbsp;<em>Nature Neuroscience</em>. In these people, dye injected into the bloodstream leaked into their brains and pooled in regions that play roles in language, memory, mood and vision.&nbsp;</p>



<p>It’s the first time anyone’s shown that long COVID patients can have leaky blood brain barriers, says study coauthor Matthew Campbell, a geneticist at Trinity College Dublin in Ireland. That barrier, tightly knit cells lining blood vessels, typically keeps&nbsp;riffraff&nbsp;out of the brain, like bouncers guarding a nightclub.&nbsp;</p>





<p>If the barrier breaks down, bloodborne viruses, cells and other interlopers can sneak into the brain’s tissues and wreak havoc, says&nbsp;Avindra Nath,&nbsp;a&nbsp;neurologist&nbsp;at the&nbsp;National Institutes of Health in Bethesda, Md. It’s too early to say definitively whether that’s happening in people with long COVID, but the new study provides evidence that “brain fog has a biological basis,” says Nath, who wasn’t involved with the work. That alone is important for&nbsp;patients, he says, because their symptoms may be otherwise discounted by physicians.&nbsp;</p>



<p>For some people, brain fog can feel like a slowdown in thinking or difficulty recalling short-term memories, Campbell says. For example,&nbsp;“patients&nbsp;will go for a drive, and forget where they’re driving to.” That might sound trivial, he says, but it actually pushes people into panic mode.&nbsp;</p>



<p>Campbell’s team studies repetitive head trauma. They knew that traumatic brain injuries can disrupt the blood brain barrier — and that people with these injuries sometimes report having brain fog. That mental muddling reminded the team of what people with long COVID can experience. Maybe the blood brain barrier disruption seen in some concussion patients applies to long COVID brain fog, too, the researchers surmised.</p>



<p>Evidence for SARS-CoV-2’s damaging effects on the brain has been mounting for years. Studies in cells and animals suggest the virus can crumble components of the blood brain barrier. And autopsies of people who have died from COVID-19 reveal barrier breakdowns, Nath and others have shown.</p>


<div>
<figure><img decoding="async" width="680" height="398" src="https://i0.wp.com/www.sciencenews.org/wp-content/uploads/2024/03/030624_mr_covid-brainfog_inline.jpg?resize=680%2C398&amp;ssl=1" alt="Side-by-side black and white brain scans. The scan on the left contains a few colored speckles. The scan on the right contains many more colored speckles." srcset="https://i0.wp.com/www.sciencenews.org/wp-content/uploads/2024/03/030624_mr_covid-brainfog_inline.jpg?w=680&amp;ssl=1 680w, https://i0.wp.com/www.sciencenews.org/wp-content/uploads/2024/03/030624_mr_covid-brainfog_inline.jpg?resize=654%2C383&amp;ssl=1 654w, https://i0.wp.com/www.sciencenews.org/wp-content/uploads/2024/03/030624_mr_covid-brainfog_inline.jpg?resize=318%2C186&amp;ssl=1 318w" sizes="(max-width: 680px) 100vw, 680px" data-recalc-dims="1"><figcaption><span><p><span>In long COVID patients with brain fog (brain scan at right), dye injected into the bloodstream tends to leak into the brain (see colored speckles) more so than in people without brain fog (left).</span></p></span><span><p><span><span lang="DE">C. Greene <i>et al.</i>/<i>Nature Neuroscience</i> 2024</span></span></p></span></figcaption></figure></div>


<p>But until now, no one knew if this kind of damage persisted long after the initial infection subsided. The team scanned the brains of 32 people, 10 of whom had recovered from COVID-19, and 22 with long COVID. Of those with long COVID,&nbsp;&nbsp;half reported having brain fog.&nbsp;</p>



<p>An injected dye lit up all the participants’&nbsp;brains during MRI brain scans. In people recovered from COVID, the dye had trouble crossing the blood brain barrier. Likewise, in long COVID patients without brain fog, the dye mostly stayed put, confined within blood vessels. But in eight of 11 participants with brain fog, the dye tended to escape from blood vessels and enter brain tissue.&nbsp;</p>



<p>“It was just so clear,” Campbell says. He remembers one of the first people scanned, someone with severe brain fog. Their temporal lobes, brain regions that sit behind the eyes, were&nbsp;“just flooded with this dye,” he says. The researchers’&nbsp;work suggests that&nbsp;“brain fog wasn’t just a figment of [patients’] imagination,” Campbell says.&nbsp;“It was a very, very real thing that they were reporting.”</p>



<p>The new findings offer an opportunity to think about potential therapies, Nath says. Perhaps researchers can find a way to slow down the blood brain barrier’s breakdown — or reverse it.</p>



			</div>
</article><!-- #post-## -->


<section>
	<h3>
		More Stories from Science News on <a href="https://www.sciencenews.org/topic/health-medicine">Health &amp; Medicine</a>
	</h3>
	

</section>
<div>
		<h3>From the Nature Index</h3>
		<p><span>Paid Content</span>
	</p></div>
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Study Puts Fermented Foods, Not Fire, as Pivotal Moment in Human Brain Growth (264 pts)]]></title>
            <link>https://plantbasednews.org/news/science/fermented-foods-human-brain-growth/</link>
            <guid>39762588</guid>
            <pubDate>Wed, 20 Mar 2024 03:20:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://plantbasednews.org/news/science/fermented-foods-human-brain-growth/">https://plantbasednews.org/news/science/fermented-foods-human-brain-growth/</a>, See on <a href="https://news.ycombinator.com/item?id=39762588">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="316538">
<div>


<p>Fermented foods may have helped evolution of large brains in humans, according to a recent <a href="https://www.nature.com/articles/s42003-023-05517-3" target="_blank" rel="noreferrer noopener">study</a>.</p>
<p>The human brain began increasing in size around 2.5 million years ago. But scientists have been unsure of what mechanism drove that change. Fire and the invention of cooking has often been thought to have been the key, by enabling our ancestors to get enough nourishment to spur our evolution.</p>
<p>But the new study notes that the archaeological evidence shows that human brain expansion predated fire use by up a million years.</p>
<p>As brains need a lot of calories to keep functioning, the researchers believe another dietary change helped to kickstart the growth of early humans’ brains. They posit that fermented foods, as a dietary option accessible to our ancestors, were responsible.</p>
<h2 id="h-external-fermentation-hypothesis">External Fermentation Hypothesis</h2>
<div>
<figure><img decoding="async" width="1200" height="767" src="https://plantbasednews.org/app/uploads/2024/03/plant-based-news-fermented-foods-brain-growth-1200x767.jpeg" alt="Jars of various fermented vegetables" srcset="https://plantbasednews.org/app/uploads/2024/03/plant-based-news-fermented-foods-brain-growth-1200x767.jpeg 1200w, https://plantbasednews.org/app/uploads/2024/03/plant-based-news-fermented-foods-brain-growth-600x384.jpeg 600w, https://plantbasednews.org/app/uploads/2024/03/plant-based-news-fermented-foods-brain-growth-768x491.jpeg 768w, https://plantbasednews.org/app/uploads/2024/03/plant-based-news-fermented-foods-brain-growth-1536x982.jpeg 1536w, https://plantbasednews.org/app/uploads/2024/03/plant-based-news-fermented-foods-brain-growth-2048x1310.jpeg 2048w" sizes="(max-width: 1200px) 100vw, 1200px"><figcaption><span>Adobe Stock</span> Fermented foods are popular in the modern world, and they may have aided brain growth of our ancestors</figcaption></figure></div>
<p>The researchers propose the External Fermentation Hypothesis to explain what helped our brains grow. Food ferments inside our guts, but the researchers believe that the food must have been fermented before being eaten.&nbsp;</p>
<p>According to the study, fermentation makes it easier for humans to absorb macronutrients and micronutrients. It also makes carbohydrates and proteins more digestible.</p>
<p>Backing up this hypothesis is the fact that humans have relatively smaller large intestines than other primates. This indicates that our ancestors were eating food that was already partly broken down by fermentation.&nbsp;</p>
<p>“Reduced gut sizes could only evolve if our ancestors were able to exploit a more nutrient-dense and easily digestible food source,” explain the researchers in the study. As a result, less energy would have been needed to support digestion, freeing it up for use by the brain instead.</p>
<h2>A happy accident</h2>
<p>Our ancestors probably didn’t choose fermented foods for their brain health, but fermented foods by accident. The study suggests that our early ancestors may stored food in common locations, intermittently eating some and adding more. Using the same storage spots could have helped a stable microbial ecosystem to develop that would aid fermentation.</p>
<p>“This was not necessarily an intentional endeavor,” Erin Hecht, co-author on the study and Assistant Professor of Human Evolutionary Biology at Harvard University, <a href="https://news.harvard.edu/gazette/story/2024/02/did-fermented-foods-fuel-brain-growth/" target="_blank" rel="noreferrer noopener">told <em>The Harvard Gazette</em></a>. “It may have been an accidental side effect of caching food. And maybe, over time, traditions or superstitions could have led to practices that promoted fermentation or made fermentation more stable or more reliable.”</p>
<h2>Supporting mental health</h2>
<p>Katherine Bryant, lead author and researcher at Aix-Marseille University, suggests that the External Fermentation Hypothesis could have implications for research into modern diets.</p>
<p>“This hypothesis also gives us as scientists even more reasons to explore the role of fermented foods on human health and the maintenance of a healthy gut microbiome,” she told<em> The Harvard Gazette</em>. “There have been a number of studies in recent years linking gut microbiome to not only physical but mental health.”</p>
<p>Indeed, fermented foods such as kimchi and tempeh are becoming increasingly popular for their benefits to gut health. Gut health expert Professor Tim Spector <a href="https://plantbasednews.org/lifestyle/health-and-fitness/benefits-of-fermented-foods/">recommends</a> eating a small amount of fermented foods every day. This encourages diversity in the gut microbiome.</p>
<h6>More like this:</h6>
<ul>
<li><a href="https://plantbasednews.org/lifestyle/food/sprouting-healthy-food/">What Is Sprouting? How To Grow Healthy Food ‘For Pennies’</a></li>
<li><a href="https://plantbasednews.org/lifestyle/health-and-fitness/sleep-apnoea-plant-based/">Healthy Plant-Based Diets Cut Sleep Apnoea Risk, Study Finds</a></li>
<li><a href="https://plantbasednews.org/lifestyle/health-and-fitness/protein-rich-vegetables/">8 Protein-Rich Vegetables To Add To Your Meals</a></li>
</ul>
</div>
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Let's create a Tree-sitter grammar (181 pts)]]></title>
            <link>https://www.jonashietala.se/blog/2024/03/19/lets_create_a_tree-sitter_grammar/</link>
            <guid>39762495</guid>
            <pubDate>Wed, 20 Mar 2024 02:55:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.jonashietala.se/blog/2024/03/19/lets_create_a_tree-sitter_grammar/">https://www.jonashietala.se/blog/2024/03/19/lets_create_a_tree-sitter_grammar/</a>, See on <a href="https://news.ycombinator.com/item?id=39762495">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      

      
<article>
  <header>
    
    
    


  </header>

   <p>One of my favorite features in Neovim is the Tree-sitter integration.
It allows for fast syntax highlighting that works well even in an error state (often the case when you’re editing code), and it has additional semantics (you can differentiate between function parameters and local variables).</p>
<p>With <a href="https://github.com/nvim-treesitter/nvim-treesitter-textobjects">nvim-treesitter-textobjects</a> you can also jump between nodes (such as <code>]c</code> to jump to next class) or target deletion (<code>cif</code> to delete the function body and enter insert mode).
An amazing feature as it works across languages, no matter how they look like, as long as they have a Tree-sitter grammar (most do).</p>
<p>But, you might wonder what does a Tree-sitter grammar look like,
and how do you create one for a language?</p>
<p>I started thinking about this and before I knew it I was <a href="https://github.com/treeman/tree-sitter-djot">trying to make my own parser</a> for <a href="https://djot.net/">Djot</a> (a markup language similar to Markdown).
There are some good tutorials on how to get started, but not on some more advanced things.</p>
<p>I spent quite some time trying to figure it out—while refreshing my 10 year old knowledge of grammars—and decided to document some of my findings.</p>
<p>The post spiraled out of control a little, and it will go through:</p>
<ol>
<li>
How to use an external scanner
</li>
<li>
Using Tree-sitter’s built-in conflicts resolution
</li>
<li>
Syntax highlighting with language injection
</li>
<li>
Use the grammar from Neovim for syntax highlighting and textobjects
</li>
<li>
Embed the grammar into this Blog for syntax highlighting
</li>
</ol>
<p>The source code for the complete grammar we’ll develop <a href="https://github.com/treeman/tree-sitter-sdjot">can be found on GitHub</a>.</p>
<section id="Our-subset">
<h2><a href="#Our-subset">Our subset</a></h2>
<p>For the purpose of this blog post, we’ll implement a small subset of <a href="https://djot.net/">Djot</a>, where we’ll support:</p>
<ul>
<li>
Paragraphs
</li>
<li>
Divs
</li>
<li>
Code blocks
</li>
<li>
Emphasis
</li>
</ul>
<p>This will allow us to parse markup like this:</p>
<div><pre><code><span>This is a</span>
<span>multiline <span><span>_</span>paragraph<span>_</span></span></span>
<span></span>
<span></span><span>:::</span>
<span>This is a paragraph inside a div</span>
<span></span><span>:::</span>

<span><span>```</span><span>gleam</span></span>
<span><span>let</span> <span>x</span> <span>=</span> <span>2</span>;</span>
<span><span>```</span></span>
</code></pre></div>
<p>(Yes, the <code>sdjot</code> highlight uses our grammar.)</p>
<p>At first blush, this seems like it’s too simple to require anything more complex than some simple grammar rules, but later on we’ll see that even these simple rules requires a bit more effort to fully support.</p>
</section>
<section id="Simple-beginnings">
<h2><a href="#Simple-beginnings">Simple beginnings</a></h2>
<p>The point of this post isn’t to go through how the Tree-sitter grammar description in <code>grammar.js</code> works.
The <a href="https://tree-sitter.github.io/tree-sitter/creating-parsers">Tree-sitter docs</a> goes through how to get started.
I named the project <code>sdjot</code> and this is the <code>grammar.js</code> we’ll start with:</p>
<div><pre><code><span>module<span>.</span><span>exports</span> <span>=</span> grammar<span><span><span><span>(</span></span></span></span><span><span><span><span>{</span>
  name<span>:</span> <span><span><span>"</span>sdjot<span>"</span></span></span><span>,</span>

        <span><span>extras</span></span><span>:</span> <span><span><span><span>(</span></span></span></span><span><span>_<span>)</span></span></span> =<span>&gt;</span> <span><span>[</span><span><span><span>"</span><span>\r</span><span>"</span></span></span><span>]</span></span><span>,</span>

  rules<span>:</span> <span><span>{</span>
    <span><span>document</span></span><span>:</span> <span><span><span><span>(</span></span></span></span><span><span>$<span>)</span></span></span> =<span>&gt;</span> repeat<span><span><span><span>(</span></span></span></span><span><span>$<span>.</span><span>_block</span><span>)</span></span></span><span>,</span>

        <span><span>_block</span></span><span>:</span> <span><span><span><span>(</span></span></span></span><span><span>$<span>)</span></span></span> =<span>&gt;</span> choice<span><span><span><span>(</span></span></span></span><span><span>$<span>.</span><span>div</span><span>,</span> $<span>.</span><span>code_block</span><span>,</span> $<span>.</span><span>paragraph</span><span>,</span> <span><span><span>"</span><span>\n</span><span>"</span></span></span><span>)</span></span></span><span>,</span>

        <span><span>div</span></span><span>:</span> <span><span><span><span>(</span></span></span></span><span><span>$<span>)</span></span></span> =<span>&gt;</span>
      prec<span>.</span><span><span>left</span></span><span><span><span><span>(</span></span></span></span><span><span>seq<span><span><span><span>(</span></span></span></span><span><span>$<span>.</span><span>div_marker</span><span>,</span> <span><span><span>"</span><span>\n</span><span>"</span></span></span><span>,</span> repeat<span><span><span><span>(</span></span></span></span><span><span>$<span>.</span><span>_block</span><span>)</span></span></span><span>,</span> $<span>.</span><span>div_marker</span><span>,</span> <span><span><span>"</span><span>\n</span><span>"</span></span></span><span>)</span></span></span><span>)</span></span></span><span>,</span>
    <span><span>div_marker</span></span><span>:</span> <span><span><span><span>(</span></span></span></span><span><span>_<span>)</span></span></span> =<span>&gt;</span> <span><span><span>"</span>:::<span>"</span></span></span><span>,</span>

        <span><span>code_block</span></span><span>:</span> <span><span><span><span>(</span></span></span></span><span><span>$<span>)</span></span></span> =<span>&gt;</span>
      seq<span><span><span><span>(</span></span></span></span><span><span>
        $<span>.</span><span>code_block_marker</span><span>,</span>
        optional<span><span><span><span>(</span></span></span></span><span><span>$<span>.</span><span>language</span><span>)</span></span></span><span>,</span>
        <span><span><span>"</span><span>\n</span><span>"</span></span></span><span>,</span>
        optional<span><span><span><span>(</span></span></span></span><span><span>$<span>.</span><span>code</span><span>)</span></span></span><span>,</span>
        $<span>.</span><span>code_block_marker</span><span>,</span>
      <span>)</span></span></span><span>,</span>
    <span><span>code_block_marker</span></span><span>:</span> <span><span><span><span>(</span></span></span></span><span><span>_<span>)</span></span></span> =<span>&gt;</span> <span><span><span>"</span>```<span>"</span></span></span><span>,</span>
    <span><span>code</span></span><span>:</span> <span><span><span><span>(</span></span></span></span><span><span>_<span>)</span></span></span> =<span>&gt;</span> repeat1<span><span><span><span>(</span></span></span></span><span><span>seq<span><span><span><span>(</span></span></span></span><span><span><span><span><span>/</span><span><span>[</span><span>^</span><span>\n</span><span>]</span></span><span>*</span><span>/</span></span></span><span></span><span>,</span> <span><span><span>"</span><span>\n</span><span>"</span></span></span><span>)</span></span></span><span>)</span></span></span><span>,</span>
    <span><span>language</span></span><span>:</span> <span><span><span><span>(</span></span></span></span><span><span>_<span>)</span></span></span> =<span>&gt;</span> <span><span><span>/</span><span><span>[</span><span>^</span><span>\s</span><span>]</span></span><span>+</span><span>/</span></span></span><span></span><span>,</span>

            <span><span>paragraph</span></span><span>:</span> <span><span><span><span>(</span></span></span></span><span><span>$<span>)</span></span></span> =<span>&gt;</span> seq<span><span><span><span>(</span></span></span></span><span><span>repeat<span><span>1</span></span><span><span><span><span>(</span></span></span></span><span><span>seq<span><span><span><span>(</span></span></span></span><span><span>$<span>.</span><span>_inline</span><span>,</span> <span><span><span>"</span><span>\n</span><span>"</span></span></span><span>)</span></span></span><span>)</span></span></span><span>,</span> <span><span><span>"</span><span>\n</span><span>"</span></span></span><span>)</span></span></span><span>,</span>

            <span><span>_inline</span></span><span>:</span> <span><span><span><span>(</span></span></span></span><span><span>$<span>)</span></span></span> =<span>&gt;</span> repeat1<span><span><span><span>(</span></span></span></span><span><span>choice<span><span><span><span>(</span></span></span></span><span><span>$<span>.</span><span>emphasis</span><span>,</span> $<span>.</span><span>_text</span><span>)</span></span></span><span>)</span></span></span><span>,</span>
    <span><span>emphasis</span></span><span>:</span> <span><span><span><span>(</span></span></span></span><span><span>$<span>)</span></span></span> =<span>&gt;</span> prec<span>.</span><span><span>left</span></span><span><span><span><span>(</span></span></span></span><span><span>seq<span><span><span><span>(</span></span></span></span><span><span><span><span><span>"</span>_<span>"</span></span></span><span>,</span> $<span>.</span><span>_inline</span><span>,</span> <span><span><span>"</span>_<span>"</span></span></span><span>)</span></span></span><span>)</span></span></span><span>,</span>
    <span><span>_text</span></span><span>:</span> <span><span><span><span>(</span></span></span></span><span><span>_<span>)</span></span></span> =<span>&gt;</span> <span><span><span>/</span><span><span>[</span><span>^</span><span>\n</span><span>]</span></span><span>/</span></span></span><span></span><span>,</span>
  <span>}</span></span><span>,</span>
<span>}</span></span><span>)</span></span></span><span>;</span>
</span></code></pre></div>
<p>It recognizes paragraphs with text and emphasis, and it identifies divs and code blocks.</p>
<p>We can create an <code>example-file</code> with these contents:</p>
<div><pre><code><span>:::</span>
<span>A paragraph <span><span>_</span>with emphasis<span>_</span></span> inside a div</span>
<span></span>
<span></span><span>:::</span>
</code></pre></div>
<p>And parse it with the <code>tree-sitter</code> cli:</p>
<div><pre><code><span>$ </span><span>tree-sitter</span> parse example-file
(document [0, 0] - [5, 0]
  (div [0, 0] - [4, 0]
    (div_marker [0, 0] - [0, 3])
    (paragraph [1, 0] - [3, 0]
      (emphasis [1, 12] - [1, 27]))
    (div_marker [3, 0] - [3, 3])))
</code></pre></div>
<p>Et voilà!</p>
<section id="Missing-features">
<h3><a href="#Missing-features">Missing features</a></h3>
<p>But I told you it wasn’t supposed to be this easy, and there are features missing from our parser.
Most notably:</p>
<ol type="A">
<li>
There can be an arbitrary number of <code>:</code>, allowing divs to be nested.
</li>
<li>
Closing a div should close other open blocks (divs and paragraphs in our case).
</li>
</ol>
<p>In essence, we need to be able to parse this:</p>
<div><pre><code><span>:::</span>
<span>Top-level div</span>
<span></span>
<span></span><span>::::</span>
<span>A paragraph inside a second div,</span>
<span>both closed when the top-level div is closedj</span>
<span></span><span>:::</span>
</code></pre></div>
<p>This is… Complicated.</p>
<p>Sure, we can work around the varying levels of <code>:</code> with something hacky like enumerating the number of colons, using something like this:</p>
<div><pre><code><span><span>div</span><span>:</span> <span><span><span><span>(</span></span></span></span><span><span>$<span>)</span></span></span> =<span>&gt;</span> choice<span><span><span><span>(</span></span></span></span><span><span>$<span>.</span><span>_div3</span><span>,</span> $<span>.</span><span>_div4</span><span>,</span> $<span>.</span><span>_div5</span><span>,</span> $<span>.</span><span>_div6</span><span>,</span> $<span>.</span><span>_div7</span><span>,</span> $<span>.</span><span>_div8</span><span>)</span></span></span><span>,</span>
<span>_div3</span><span>:</span> <span><span><span><span>(</span></span></span></span><span><span>$<span>)</span></span></span> =<span>&gt;</span> seq<span><span><span><span>(</span></span></span></span><span><span><span><span><span>/</span>:<span>{3}</span><span>/</span></span></span><span></span><span>,</span> $<span>.</span><span>_inside_div</span><span>,</span> <span><span><span>/</span>:<span>{3}</span><span>/</span></span></span><span></span><span>,</span> <span><span><span>"</span><span>\n</span><span>"</span></span></span><span>)</span></span></span><span>,</span>
<span>_div4</span><span>:</span> <span><span><span><span>(</span></span></span></span><span><span>$<span>)</span></span></span> =<span>&gt;</span> seq<span><span><span><span>(</span></span></span></span><span><span><span><span><span>/</span>:<span>{4}</span><span>/</span></span></span><span></span><span>,</span> $<span>.</span><span>_inside_div</span><span>,</span> <span><span><span>/</span>:<span>{4}</span><span>/</span></span></span><span></span><span>,</span> <span><span><span>"</span><span>\n</span><span>"</span></span></span><span>)</span></span></span><span>,</span>
<span>_div5</span><span>:</span> <span><span><span><span>(</span></span></span></span><span><span>$<span>)</span></span></span> =<span>&gt;</span> seq<span><span><span><span>(</span></span></span></span><span><span><span><span><span>/</span>:<span>{5}</span><span>/</span></span></span><span></span><span>,</span> $<span>.</span><span>_inside_div</span><span>,</span> <span><span><span>/</span>:<span>{5}</span><span>/</span></span></span><span></span><span>,</span> <span><span><span>"</span><span>\n</span><span>"</span></span></span><span>)</span></span></span><span>,</span>
<span>_div6</span><span>:</span> <span><span><span><span>(</span></span></span></span><span><span>$<span>)</span></span></span> =<span>&gt;</span> seq<span><span><span><span>(</span></span></span></span><span><span><span><span><span>/</span>:<span>{6}</span><span>/</span></span></span><span></span><span>,</span> $<span>.</span><span>_inside_div</span><span>,</span> <span><span><span>/</span>:<span>{6}</span><span>/</span></span></span><span></span><span>,</span> <span><span><span>"</span><span>\n</span><span>"</span></span></span><span>)</span></span></span><span>,</span>
<span>_div7</span><span>:</span> <span><span><span><span>(</span></span></span></span><span><span>$<span>)</span></span></span> =<span>&gt;</span> seq<span><span><span><span>(</span></span></span></span><span><span><span><span><span>/</span>:<span>{7}</span><span>/</span></span></span><span></span><span>,</span> $<span>.</span><span>_inside_div</span><span>,</span> <span><span><span>/</span>:<span>{7}</span><span>/</span></span></span><span></span><span>,</span> <span><span><span>"</span><span>\n</span><span>"</span></span></span><span>)</span></span></span><span>,</span>
<span>_div8</span><span>:</span> <span><span><span><span>(</span></span></span></span><span><span>$<span>)</span></span></span> =<span>&gt;</span> seq<span><span><span><span>(</span></span></span></span><span><span><span><span><span>/</span>:<span>{8}</span><span>/</span></span></span><span></span><span>,</span> $<span>.</span><span>_inside_div</span><span>,</span> <span><span><span>/</span>:<span>{8}</span><span>/</span></span></span><span></span><span>,</span> <span><span><span>"</span><span>\n</span><span>"</span></span></span><span>)</span></span></span><span>,</span>
<span>_inside_div</span><span>:</span> <span><span><span><span>(</span></span></span></span><span><span>$<span>)</span></span></span> =<span>&gt;</span> prec<span>.</span><span><span>left</span></span><span><span><span><span>(</span></span></span></span><span><span><span><span><span>"</span><span>\n</span><span>"</span></span></span><span>,</span> repeat<span><span><span><span>(</span></span></span></span><span><span>$<span>.</span><span>_block</span><span>)</span></span></span><span>)</span></span></span><span>,</span>
</span></code></pre></div>
<p>But it’s not <em>neat</em>, and automatically closing contained blocks is much harder (to my brain it seems impossible, but I’m no expert).</p>
<p>With an external scanner we can do this (and more).</p>
</section>
</section>
<section id="External-scanner">
<h2><a href="#External-scanner">External scanner</a></h2>
<p>A Tree-sitter parser is actually a C program.
The grammar we’ve seen has been described in JavaScript, but it’s only used as a description to generate the parser in C.
If you’re a masochist, you can take a look at it in <code>src/parser.c</code> after running <code>tree-sitter generate</code>.</p>
<p>An external scanner is just some custom C code that’s inserted into the parser, and it allows us to override the parser precedence, keep track of a context state, or whatever else we might need or want to do.</p>
<p>To get started the <a href="https://tree-sitter.github.io/tree-sitter/creating-parsers#external-scanners">official docs</a> was pretty good.
Basically you need to:</p>
<ol>
<li>
Create a <code>src/scanner.c</code> and include it in <code>binding.gyp</code> <code>bindings/rust/build.rs</code>.
</li>
<li>
Setup <code>externals</code> tokens in <code>grammar.js</code> and a matching C enum in <code>scanner.c</code>.
</li>
<li>
Define and implement five C functions.
</li>
</ol>
<p>Let’s take a look.</p>
<section id="Div-markers-closes-open-paragraphs">
<h3><a href="#Div-markers-closes-open-paragraphs">Div markers closes open paragraphs</a></h3>
<p>Let’s start by closing a paragraph early when a <code>:::</code> is encountered.
This is simpler because we can solve this without storing any state.</p>
<p>When parsing <code>$.paragraph</code> we’ll give the parser a choice between ending the paragraph on a newline or on our new <code>$._close_paragraph</code> token:</p>
<div><pre><code><span><span>paragraph</span><span>:</span> <span><span><span><span>(</span></span></span></span><span><span>$<span>)</span></span></span> =<span>&gt;</span>
  seq<span><span><span><span>(</span></span></span></span><span><span>repeat<span><span>1</span></span><span><span><span><span>(</span></span></span></span><span><span>seq<span><span><span><span>(</span></span></span></span><span><span>$<span>.</span><span>_inline</span><span>,</span> <span><span><span>"</span><span>\n</span><span>"</span></span></span><span>)</span></span></span><span>)</span></span></span><span>,</span> choice<span><span><span><span>(</span></span></span></span><span><span><span><span><span>"</span><span>\n</span><span>"</span></span></span><span>,</span> $<span>.</span><span>_close_paragraph</span><span>)</span></span></span><span>)</span></span></span><span>,</span>
</span></code></pre></div>
<p><code>$._close_paragraph</code> is handled by the external scanner, which is specified using the <code>externals</code> field:</p>
<div><pre><code><span><span>externals</span><span>:</span> <span><span><span><span>(</span></span></span></span><span><span>$<span>)</span></span></span> =<span>&gt;</span> <span><span>[</span>$<span>.</span><span>_close_paragraph</span><span>]</span></span><span>,</span>
</span></code></pre></div>
<p>Now let’s turn our attention to <code>src/scanner.c</code>.
The tokens in <code>externals</code> gets assigned an incremented number, starting from 0…
Just like an enum in C!</p>
<div><pre><code><span><span><span>//</span> We only have a single element right now, but keep in mind that the order
</span><span><span>//</span> must match the `externals` array in `grammar.js`.
</span><span>typedef</span> <span>enum</span> <span><span>{</span> CLOSE_PARAGRAPH <span>}</span></span> <span>TokenType</span><span>;</span>
</span></code></pre></div>
<p>The five functions we need to implement are these:</p>
<div><pre><code><span><span><span>//</span> You should replace `sdjot` with whatever project name you chose.
</span><span>bool</span> <span><span>tree_sitter_sdjot_external_scanner_scan</span></span><span><span><span>(</span></span></span><span><span><span>void</span> <span>*</span><span>payload</span><span>,</span> TSLexer <span>*</span><span>lexer</span><span>,</span>
                                             <span>const</span> <span>bool</span> <span>*</span><span>valid_symbols</span><span>)</span></span></span><span> </span><span><span><span>{</span></span></span><span><span>
  <span> All the scanning goes here.
</span>  <span>return</span> <span>false</span><span>;</span>
</span></span><span><span><span>}</span></span></span>

<span><span>//</span> If we need to allocate/deallocate state, we do it in these functions.
</span><span>void</span> <span>*</span><span><span>tree_sitter_sdjot_external_scanner_create</span></span><span><span><span>(</span></span></span><span><span><span>)</span></span></span><span> </span><span><span><span>{</span></span></span><span><span> <span>return</span> <span>NULL</span><span>;</span> </span></span><span><span><span>}</span></span></span>
<span>void</span> <span><span>tree_sitter_sdjot_external_scanner_destroy</span></span><span><span><span>(</span></span></span><span><span><span>void</span> <span>*</span><span>payload</span><span>)</span></span></span><span> </span><span><span><span>{</span></span></span><span></span><span><span><span>}</span></span></span>

<span><span>//</span> If we have state, we should load and save it in these functions.
</span><span>unsigned</span> <span><span>tree_sitter_sdjot_external_scanner_serialize</span></span><span><span><span>(</span></span></span><span><span><span>void</span> <span>*</span><span>payload</span><span>,</span>
                                                      <span>char</span> <span>*</span><span>buffer</span><span>)</span></span></span><span> </span><span><span><span>{</span></span></span><span><span>
  <span>return</span> <span>0</span><span>;</span>
</span></span><span><span><span>}</span></span></span>
<span>void</span> <span><span>tree_sitter_sdjot_external_scanner_deserialize</span></span><span><span><span>(</span></span></span><span><span><span>void</span> <span>*</span><span>payload</span><span>,</span> <span>char</span> <span>*</span><span>buffer</span><span>,</span>
                                                    <span>unsigned</span> <span>length</span><span>)</span></span></span><span> </span><span><span><span>{</span></span></span><span></span><span><span><span>}</span></span></span>
</span></code></pre></div>
<p>Because we won’t use any state, we’ll only have to update the <code>scan</code> function.</p>
<p>What you’re supposed to do is check <code>valid_symbols</code> for the tokens we can return at any point in time, and return <code>true</code> if any was found:</p>
<div><pre><code><span><span>bool</span> <span><span>tree_sitter_sdjot_external_scanner_scan</span></span><span><span><span>(</span></span></span><span><span><span>void</span> <span>*</span><span>payload</span><span>,</span> TSLexer <span>*</span><span>lexer</span><span>,</span>
                                             <span>const</span> <span>bool</span> <span>*</span><span>valid_symbols</span><span>)</span></span></span><span> </span><span><span><span>{</span></span></span><span><span>
  <span>if</span> <span><span>(</span>valid_symbols<span><span>[</span>CLOSE_PARAGRAPH<span>]</span></span> <span>&amp;&amp;</span> <span><span>parse_close_paragraph</span><span><span>(</span></span></span><span><span>lexer</span></span><span><span><span>)</span></span></span><span>)</span></span> <span><span>{</span>
    <span>return</span> <span>true</span><span>;</span>
  <span>}</span></span>
  <span>return</span> <span>false</span><span>;</span>
</span></span><span><span><span>}</span></span></span>
</span></code></pre></div>
<p>To decide if we’re going to close the paragraph early, we’ll look ahead for any <code>:::</code>, and if so we’ll close it without consuming any characters.
This might not be the most efficient solution because we’ll have to parse the <code>:::</code> again, but it gets the job done.</p>
<p>The matched token should be stored in 
<code><span>lexer<span>-&gt;</span>result_symbol</span></code>:</p>
<div><pre><code><span><span>static</span> <span>bool</span> <span><span>parse_close_paragraph</span></span><span><span><span>(</span></span></span><span><span>TSLexer <span>*</span><span>lexer</span><span>)</span></span></span><span> </span><span><span><span>{</span></span></span><span><span>
  <span> Mark the end before advancing so that the CLOSE_PARAGRAPH token doesn't
</span>  <span> consume any characters.
</span>  lexer<span>-&gt;</span><span><span>mark_end</span><span><span>(</span></span></span><span><span>lexer</span></span><span><span><span>)</span></span></span><span>;</span>

  <span>uint8_t</span> colons <span>=</span> <span><span>consume_chars</span><span><span>(</span></span></span><span><span>lexer<span>,</span> <span><span>'</span>:<span>'</span></span></span></span><span><span><span>)</span></span></span><span>;</span>
  <span>if</span> <span><span>(</span>colons <span>&gt;=</span> <span>3</span><span>)</span></span> <span><span>{</span>
    lexer<span>-&gt;</span>result_symbol <span>=</span> CLOSE_PARAGRAPH<span>;</span>
    <span>return</span> <span>true</span><span>;</span>
  <span>}</span></span> <span>else</span> <span><span>{</span>
    <span>return</span> <span>false</span><span>;</span>
  <span>}</span></span>
</span></span><span><span><span>}</span></span></span>
</span></code></pre></div>
<p>Note that the resulting token will mark any symbol we advance over as owned by that token.
So <code>:::</code> would be marked as <code>_close_paragraph</code> (which will be ignored by the output since it begins with an underscore), instead of <code>div_marker</code>.
To prevent this, we turn <code>_close_paragraph</code> into a zero-width token by marking the end before advancing the lexer.</p>
<p>How do we advance the lexer?
We call 
<code><span>lexer<span>-&gt;</span>advance</span></code>:</p>
<div><pre><code><span><span>static</span> <span>uint8_t</span> <span><span>consume_chars</span></span><span><span><span>(</span></span></span><span><span>TSLexer <span>*</span><span>lexer</span><span>,</span> <span>char</span> <span>c</span><span>)</span></span></span><span> </span><span><span><span>{</span></span></span><span><span>
  <span>uint8_t</span> count <span>=</span> <span>0</span><span>;</span>
  <span>while</span> <span><span>(</span>lexer<span>-&gt;</span>lookahead <span>==</span> c<span>)</span></span> <span><span>{</span>
    lexer<span>-&gt;</span><span><span>advance</span><span><span>(</span></span></span><span><span>lexer<span>,</span> <span>false</span></span></span><span><span><span>)</span></span></span><span>;</span>
    <span>+</span><span>+</span>count<span>;</span>
  <span>}</span></span>
  <span>return</span> count<span>;</span>
</span></span><span><span><span>}</span></span></span>
</span></code></pre></div>
<p>This is almost all we can do with the lexer.
We only process one character at a time, cannot look behind, and our only tool to look ahead is to <code>mark_end</code> at the correct place.
(We can also query the current column position.)</p>
<p>With this we have a working external scanner and div tags now close paragraphs:</p>
<div><pre><code><span>:::</span>
<span>A paragraph inside a div</span>
<span></span><span>:::</span>
</code></pre></div>
<div><pre><code><span>$ </span><span>tree-sitter</span> parse example-file
(document [0, 0] - [4, 0]
  (div [0, 0] - [3, 0]
    (div_marker [0, 0] - [0, 3])
    (paragraph [1, 0] - [2, 0])
    (div_marker [2, 0] - [2, 3])))
</code></pre></div>
</section>
<section id="Nested-blocks">
<h3><a href="#Nested-blocks">Nested blocks</a></h3>
<p>To automatically close other open blocks we need to add some context to our parser, which means we’ll need state management.</p>
<p>The small subset we’re implementing is only concerned with closing divs—because it would be a terribly long post otherwise—but I’ll try to implement this in a general manner, to be more indicative of a real-world parser.</p>
<p>Our strategy is this:</p>
<ol>
<li>
<p>A div can have a varying number of <code>:</code> that must match.</p>
<p>Therefore we’ll parse colons in an external scanner and store it on a stack.</p>
</li>
<li>
<p>When we find a div marker, we’ll need to decide if it should start a new div, or close an existing one.</p>
<p>We’ll look at the stack of open blocks and see if we find a match.</p>
</li>
<li>
<p>If we have need to close a nested div, that is if we want to close a div further down the stack, we need to close the nested div(s) first.</p>
<p>Thus we’ll introduce a <code>block_close</code> marker that ends a div, and leave the ending div marker as optional.</p>
</li>
</ol>
<p>First we’ll ask the grammar to let the external scanner manage the begin and end tokens.
We’ll use a <code>_block_close</code> marker to end the div, and leave the end marker optional.
(You could probably use a <code>choice()</code> between the two, but this made more sense to me when I was implementing it.)</p>
<div><pre><code><span><span>div</span><span>:</span> <span><span><span><span>(</span></span></span></span><span><span>$<span>)</span></span></span> =<span>&gt;</span>
  prec<span>.</span><span><span>left</span></span><span><span><span><span>(</span></span></span></span><span><span>
    seq<span><span><span><span>(</span></span></span></span><span><span>
                  alias<span><span><span><span>(</span></span></span></span><span><span>$<span>.</span><span>_div_marker_begin</span><span>,</span> $<span>.</span><span>div_marker</span><span>)</span></span></span><span>,</span>
      <span><span><span>"</span><span>\n</span><span>"</span></span></span><span>,</span>
      repeat<span><span><span><span>(</span></span></span></span><span><span>$<span>.</span><span>_block</span><span>)</span></span></span><span>,</span>
      $<span>.</span><span>_block_close</span><span>,</span>
      optional<span><span><span><span>(</span></span></span></span><span><span>alias<span><span><span><span>(</span></span></span></span><span><span>$<span>.</span><span>_div_marker_end</span><span>,</span> $<span>.</span><span>div_marker</span><span>)</span></span></span><span>)</span></span></span>
    <span>)</span></span></span>
  <span>)</span></span></span><span>,</span>

<span>externals</span><span>:</span> <span><span><span><span>(</span></span></span></span><span><span>$<span>)</span></span></span> =<span>&gt;</span> <span><span>[</span>
  $<span>.</span><span>_close_paragraph</span><span>,</span>
  $<span>.</span><span>_block_close</span><span>,</span>
  $<span>.</span><span>_div_marker_begin</span><span>,</span>
  $<span>.</span><span>_div_marker_end</span><span>,</span>

  <span><span>//</span> This is used in the scanner internally,
</span>  <span><span>//</span> but shouldn't be used by the grammar.
</span>  $<span>.</span><span>_ignored</span><span>,</span>
<span>]</span></span><span>,</span>
</span></code></pre></div>
<p>And remember to update the list of external tokens in the scanner (order matters):</p>
<div><pre><code><span><span>typedef</span> <span>enum</span> <span><span>{</span>
  CLOSE_PARAGRAPH<span>,</span>
  BLOCK_CLOSE<span>,</span>
  DIV_MARKER_BEGIN<span>,</span>
  DIV_MARKER_END<span>,</span>
<span>  IGNORED
</span><span>}</span></span> <span>TokenType</span><span>;</span>
</span></code></pre></div>
<p>Then to our stack of blocks.</p>
<p>I used a <code>Block</code> type to keep track of the type and number of colons:</p>
<div><pre><code><span><span><span>//</span> In a real implementation we'll have more block types.
</span><span>typedef</span> <span>enum</span> <span><span>{</span> DIV <span>}</span></span> <span>BlockType</span><span>;</span>

<span>typedef</span> <span>struct</span> <span><span>{</span>
  BlockType type<span>;</span>
  <span>uint8_t</span> level<span>;</span>
<span>}</span></span> <span>Block</span><span>;</span>
</span></code></pre></div>
<p>I know that <code>level</code> isn’t the best name, but I couldn’t find a very good general name for the number of colons, indentation level, etc.
With sum types you could model it in a clearer way, like this:</p>
<div><pre><code><span><span><span>enum</span> <span>Block</span> <span><span>{</span>
    Div <span><span>{</span> colons<span>:</span> <span>u32</span> </span><span><span>}</span></span><span>,</span>
    Footnote <span><span>{</span> indent<span>:</span> <span>u32</span> </span><span><span>}</span></span><span>,</span>
    <span> etc
</span></span><span><span>}</span></span></span>
</span></code></pre></div>
<blockquote>
<p>I will, in fact, claim that the difference between a bad programmer and a good one
is whether he considers his code or his data structures more important.
Bad programmers worry about the code.
Good programmers worry about data structures and their relationships.
</p>

</blockquote>
<p>But I digress, I’ll go with <code>level</code> like a bad programmer.</p>
<p>Another joy of programming C is that you’ll get to re-implement standard data structures such as a growable stack.
It’s not truly difficult, but it’s annoying and bug-prone.</p>
<p>Luckily, during the time I’m writing this blog post, <a href="https://github.com/tree-sitter/tree-sitter/releases/tag/v0.22.1">tree-sitter 0.22.1</a> was released with an array implementation.
So now I don’t have to show you my shoddy stack implementation, and we can use their array for our stack instead.</p>
<p>We’ll shove our <code>Array</code> of <code>Block*</code> into a <code>Scanner</code> struct, because we’ll need to track more data later:</p>
<div><pre><code><span><span><span>#include</span> <span><span>"</span>tree_sitter/array.h<span>"</span></span>
</span>
<span>typedef</span> <span>struct</span> <span><span>{</span>
  <span><span>Array</span><span><span>(</span></span></span><span><span>Block <span>*</span></span></span><span><span><span>)</span></span></span> <span>*</span> open_blocks<span>;</span>
<span>}</span></span> <span>Scanner</span><span>;</span>
</span></code></pre></div>
<p>When you manage state in tree-sitter, you need to do some data management in the <code>tree_sitter_</code> functions we defined earlier.</p>
<p>Allocations are managed in the <code>_create</code> and <code>_destroy</code> functions.
Also new for 0.22.1 is the recommendation to use <code>ts_</code> functions for allocations, to allow consumers to override the default allocator:</p>
<div><pre><code><span><span><span>#include</span> <span><span>"</span>tree_sitter/alloc.h<span>"</span></span>
</span>
<span>void</span> <span>*</span><span><span>tree_sitter_sdjot_external_scanner_create</span></span><span><span><span>(</span></span></span><span><span><span>)</span></span></span><span> </span><span><span><span>{</span></span></span><span><span>
  Scanner <span>*</span>s <span>=</span> <span><span>(</span>Scanner <span>*</span><span>)</span></span><span><span>ts_malloc</span><span><span>(</span></span></span><span><span><span>sizeof</span><span><span>(</span></span><span>Scanner</span><span><span>)</span></span></span></span><span><span><span>)</span></span></span><span>;</span>

  <span> This is how you create an empty array
</span>  s<span>-&gt;</span>open_blocks <span>=</span> <span><span>ts_malloc</span><span><span>(</span></span></span><span><span><span>sizeof</span><span><span>(</span></span><span><span><span>Array</span><span><span>(</span></span></span><span><span>Block <span>*</span></span></span><span><span><span>)</span></span></span></span><span><span>)</span></span></span></span><span><span><span>)</span></span></span><span>;</span>
  <span><span>array_init</span><span><span>(</span></span></span><span><span>s<span>-&gt;</span>open_blocks</span></span><span><span><span>)</span></span></span><span>;</span>

  <span>return</span> s<span>;</span>
</span></span><span><span><span>}</span></span></span>

<span>void</span> <span><span>tree_sitter_sdjot_external_scanner_destroy</span></span><span><span><span>(</span></span></span><span><span><span>void</span> <span>*</span><span>payload</span><span>)</span></span></span><span> </span><span><span><span>{</span></span></span><span><span>
  Scanner <span>*</span>s <span>=</span> <span><span>(</span>Scanner <span>*</span><span>)</span></span>payload<span>;</span>

  <span> I haven't shown the allocation of the blocks yet,
</span>  <span> but keep in mind that `array_delete` does not deallocate any memory
</span>  <span> you store in the array itself.
</span>  <span>for</span> <span><span>(</span><span>size_t</span> i <span>=</span> <span>0</span><span>;</span> i <span>&lt;</span> s<span>-&gt;</span>open_blocks<span>-&gt;</span>size<span>;</span> <span>+</span><span>+</span>i<span>)</span></span> <span><span>{</span>
        <span><span>ts_free</span><span><span>(</span></span></span><span><span><span><span>array_get</span><span><span>(</span></span></span><span><span>s<span>-&gt;</span>open_blocks<span>,</span> i</span></span><span><span><span>)</span></span></span></span></span><span><span><span>)</span></span></span><span>;</span>
  <span>}</span></span>

  <span> The array is a growable one, `array_delete` ensures that the
</span>  <span> memory is deleted.
</span>  <span><span>array_delete</span><span><span>(</span></span></span><span><span>s<span>-&gt;</span>open_blocks</span></span><span><span><span>)</span></span></span><span>;</span>

  <span><span>ts_free</span><span><span>(</span></span></span><span><span>s</span></span><span><span><span>)</span></span></span><span>;</span>
</span></span><span><span><span>}</span></span></span>
</span></code></pre></div>
<p>I allocate the blocks in a <code>push_block</code> helper:</p>
<div><pre><code><span><span>static</span> <span>void</span> <span><span>push_block</span></span><span><span><span>(</span></span></span><span><span>Scanner <span>*</span><span>s</span><span>,</span> BlockType <span>type</span><span>,</span> <span>uint8_t</span> <span>level</span><span>)</span></span></span><span> </span><span><span><span>{</span></span></span><span><span>
  Block <span>*</span>b <span>=</span> <span><span>ts_malloc</span><span><span>(</span></span></span><span><span><span>sizeof</span><span><span>(</span></span><span>Block</span><span><span>)</span></span></span></span><span><span><span>)</span></span></span><span>;</span>
  b<span>-&gt;</span>type <span>=</span> type<span>;</span>
  b<span>-&gt;</span>level <span>=</span> level<span>;</span>

  <span> Grows the stack automatically.
</span>  <span><span>array_push</span><span><span>(</span></span></span><span><span>s<span>-&gt;</span>open_blocks<span>,</span> b</span></span><span><span><span>)</span></span></span><span>;</span>
</span></span><span><span><span>}</span></span></span>
</span></code></pre></div>
<p>You also need to define the serialize functions.
These store and retrieve the managed state, to allow tree-sitter to backtrack.</p>
<div><pre><code><span><span>unsigned</span> <span><span>tree_sitter_sdjot_external_scanner_serialize</span></span><span><span><span>(</span></span></span><span><span><span>void</span> <span>*</span><span>payload</span><span>,</span>
                                                      <span>char</span> <span>*</span><span>buffer</span><span>)</span></span></span><span> </span><span><span><span>{</span></span></span><span><span>
  Scanner <span>*</span>s <span>=</span> <span><span>(</span>Scanner <span>*</span><span>)</span></span>payload<span>;</span>
  <span>unsigned</span> size <span>=</span> <span>0</span><span>;</span>
  <span>for</span> <span><span>(</span><span>size_t</span> i <span>=</span> <span>0</span><span>;</span> i <span>&lt;</span> s<span>-&gt;</span>open_blocks<span>-&gt;</span>size<span>;</span> <span>+</span><span>+</span>i<span>)</span></span> <span><span>{</span>
    Block <span>*</span>b <span>=</span> <span>*</span><span><span>array_get</span><span><span>(</span></span></span><span><span>s<span>-&gt;</span>open_blocks<span>,</span> i</span></span><span><span><span>)</span></span></span><span>;</span>
    buffer<span><span>[</span>size<span>+</span><span>+</span><span>]</span></span> <span>=</span> <span><span>(</span><span>char</span><span>)</span></span>b<span>-&gt;</span>type<span>;</span>
    buffer<span><span>[</span>size<span>+</span><span>+</span><span>]</span></span> <span>=</span> <span><span>(</span><span>char</span><span>)</span></span>b<span>-&gt;</span>level<span>;</span>
  <span>}</span></span>
  <span>return</span> size<span>;</span>
</span></span><span><span><span>}</span></span></span>

<span>void</span> <span><span>tree_sitter_sdjot_external_scanner_deserialize</span></span><span><span><span>(</span></span></span><span><span><span>void</span> <span>*</span><span>payload</span><span>,</span> <span>char</span> <span>*</span><span>buffer</span><span>,</span>
                                                    <span>unsigned</span> <span>length</span><span>)</span></span></span><span> </span><span><span><span>{</span></span></span><span><span>
  Scanner <span>*</span>s <span>=</span> <span><span>(</span>Scanner <span>*</span><span>)</span></span>payload<span>;</span>
  <span><span>array_init</span><span><span>(</span></span></span><span><span>s<span>-&gt;</span>open_blocks</span></span><span><span><span>)</span></span></span><span>;</span>
  <span>size_t</span> size <span>=</span> <span>0</span><span>;</span>
  <span>while</span> <span><span>(</span>size <span>&lt;</span> length<span>)</span></span> <span><span>{</span>
    BlockType type <span>=</span> <span><span>(</span>BlockType<span>)</span></span>buffer<span><span>[</span>size<span>+</span><span>+</span><span>]</span></span><span>;</span>
    <span>uint8_t</span> level <span>=</span> <span><span>(</span><span>uint8_t</span><span>)</span></span>buffer<span><span>[</span>size<span>+</span><span>+</span><span>]</span></span><span>;</span>
    <span><span>push_block</span><span><span>(</span></span></span><span><span>s<span>,</span> type<span>,</span> level</span></span><span><span><span>)</span></span></span><span>;</span>
  <span>}</span></span>
</span></span><span><span><span>}</span></span></span>
</span></code></pre></div>
<p>And that’s the (initial) state management taken care of!</p>

</section>
<section id="Div-markers">
<h3><a href="#Div-markers">Div markers</a></h3>
<p>Of course, we haven’t used our state yet.
Let’s change that.</p>
<p>First, let’s add the <code>parse_div</code> entry point to our scan function:</p>
<div><pre><code><span><span>bool</span> <span><span>tree_sitter_sdjot_external_scanner_scan</span></span><span><span><span>(</span></span></span><span><span><span>void</span> <span>*</span><span>payload</span><span>,</span> TSLexer <span>*</span><span>lexer</span><span>,</span>
                                             <span>const</span> <span>bool</span> <span>*</span><span>valid_symbols</span><span>)</span></span></span><span> </span><span><span><span>{</span></span></span><span><span>
  Scanner <span>*</span>s <span>=</span> <span><span>(</span>Scanner <span>*</span><span>)</span></span>payload<span>;</span>

  <span> Paragraph needs to be closed before we try to close divs.
</span>  <span>if</span> <span><span>(</span>valid_symbols<span><span>[</span>CLOSE_PARAGRAPH<span>]</span></span> <span>&amp;&amp;</span> <span><span>parse_close_paragraph</span><span><span>(</span></span></span><span><span>lexer</span></span><span><span><span>)</span></span></span><span>)</span></span> <span><span>{</span>
    <span>return</span> <span>true</span><span>;</span>
  <span>}</span></span>

  <span> Check `valid_symbols` inside `parse_div` because of multiple valid symbols.
</span>  <span>if</span> <span><span>(</span><span><span>parse_div</span><span><span>(</span></span></span><span><span>s<span>,</span> lexer<span>,</span> valid_symbols</span></span><span><span><span>)</span></span></span><span>)</span></span> <span><span>{</span>
    <span>return</span> <span>true</span><span>;</span>
  <span>}</span></span>

  <span>return</span> <span>false</span><span>;</span>
</span></span><span><span><span>}</span></span></span>
</span></code></pre></div>
<p>Because advancing the lexer is primitive, and we cannot “go back a char”, it’s important to only advance it if we really need to.
Therefore we always need to check <code>valid_symbols</code> before we continue:</p>
<div><pre><code><span><span>static</span> <span>bool</span> <span><span>parse_div</span></span><span><span><span>(</span></span></span><span><span>Scanner <span>*</span><span>s</span><span>,</span> TSLexer <span>*</span><span>lexer</span><span>,</span> <span>const</span> <span>bool</span> <span>*</span><span>valid_symbols</span><span>)</span></span></span><span> </span><span><span><span>{</span></span></span><span><span>
  <span>if</span> <span><span>(</span><span>!</span>valid_symbols<span><span>[</span>DIV_MARKER_BEGIN<span>]</span></span> <span>&amp;&amp;</span> <span>!</span>valid_symbols<span><span>[</span>DIV_MARKER_END<span>]</span></span><span>)</span></span> <span><span>{</span>
    <span>return</span> <span>false</span><span>;</span>
  <span>}</span></span>

  <span> ...
</span></span></span><span><span><span>}</span></span></span>
</span></code></pre></div>
<p>Next we’ll need to consume all colons we’re at, and only continue if we see at least three:</p>
<div><pre><code><span><span>static</span> <span>uint8_t</span> <span><span>consume_chars</span></span><span><span><span>(</span></span></span><span><span>TSLexer <span>*</span><span>lexer</span><span>,</span> <span>char</span> <span>c</span><span>)</span></span></span><span> </span><span><span><span>{</span></span></span><span><span>
  <span>uint8_t</span> count <span>=</span> <span>0</span><span>;</span>
  <span>while</span> <span><span>(</span>lexer<span>-&gt;</span>lookahead <span>==</span> c<span>)</span></span> <span><span>{</span>
    lexer<span>-&gt;</span><span><span>advance</span><span><span>(</span></span></span><span><span>lexer<span>,</span> <span>false</span></span></span><span><span><span>)</span></span></span><span>;</span>
    <span>+</span><span>+</span>count<span>;</span>
  <span>}</span></span>
  <span>return</span> count<span>;</span>
</span></span><span><span><span>}</span></span></span>

<span>static</span> <span>bool</span> <span><span>parse_div</span></span><span><span><span>(</span></span></span><span><span>Scanner <span>*</span><span>s</span><span>,</span> TSLexer <span>*</span><span>lexer</span><span>,</span> <span>const</span> <span>bool</span> <span>*</span><span>valid_symbols</span><span>)</span></span></span><span> </span><span><span><span>{</span></span></span><span><span>
  <span> ...
</span>
  <span>uint8_t</span> colons <span>=</span> <span><span>consume_chars</span><span><span>(</span></span></span><span><span>lexer<span>,</span> <span><span>'</span>:<span>'</span></span></span></span><span><span><span>)</span></span></span><span>;</span>
  <span>if</span> <span><span>(</span>colons <span>&lt;</span> <span>3</span><span>)</span></span> <span><span>{</span>
    <span>return</span> <span>false</span><span>;</span>
  <span>}</span></span>

  <span> ...
</span></span></span><span><span><span>}</span></span></span>
</span></code></pre></div>
<p>Opening a new div is simple; we push the block and register the number of colons:</p>
<div><pre><code><span><span><span>push_block</span><span><span>(</span></span></span><span><span>s<span>,</span> DIV<span>,</span> colons</span><span><span>)</span></span></span><span>;</span>
lexer<span>-&gt;</span>result_symbol <span>=</span> DIV_MARKER_BEGIN<span>;</span>
<span>return</span> <span>true</span><span>;</span>
</span></code></pre></div>
<p>But to the decide if we should open or close a div, we need a way to search through the stack.
This function does that, while also returning how many blocks deep into the stack we found the div (which we’ll use shortly):</p>
<div><pre><code><span><span><span>//</span> How many blocks from the top of the stack can we find a matching block?
</span><span><span>//</span> If it's directly on the top, returns 1.
</span><span><span>//</span> If it cannot be found, returns 0.
</span><span>static</span> <span>size_t</span> <span><span>number_of_blocks_from_top</span></span><span><span><span>(</span></span></span><span><span>Scanner <span>*</span><span>s</span><span>,</span> BlockType <span>type</span><span>,</span>
                                        <span>uint8_t</span> <span>level</span><span>)</span></span></span><span> </span><span><span><span>{</span></span></span><span><span>
  <span>for</span> <span><span>(</span><span>int</span> i <span>=</span> s<span>-&gt;</span>open_blocks<span>-&gt;</span>size <span>-</span> <span>1</span><span>;</span> i <span>&gt;=</span> <span>0</span><span>;</span> <span>-</span><span>-</span>i<span>)</span></span> <span><span>{</span>
    Block <span>*</span>b <span>=</span> <span>*</span><span><span>array_get</span><span><span>(</span></span></span><span><span>s<span>-&gt;</span>open_blocks<span>,</span> i</span></span><span><span><span>)</span></span></span><span>;</span>
    <span>if</span> <span><span>(</span>b<span>-&gt;</span>type <span>==</span> type <span>&amp;&amp;</span> b<span>-&gt;</span>level <span>==</span> level<span>)</span></span> <span><span>{</span>
      <span>return</span> s<span>-&gt;</span>open_blocks<span>-&gt;</span>size <span>-</span> i<span>;</span>
    <span>}</span></span>
  <span>}</span></span>
  <span>return</span> <span>0</span><span>;</span>
</span></span><span><span><span>}</span></span></span>

<span>static</span> <span>bool</span> <span><span>parse_div</span></span><span><span><span>(</span></span></span><span><span>Scanner <span>*</span><span>s</span><span>,</span> TSLexer <span>*</span><span>lexer</span><span>,</span> <span>const</span> <span>bool</span> <span>*</span><span>valid_symbols</span><span>)</span></span></span><span> </span><span><span><span>{</span></span></span><span><span>
  <span> ...
</span>
  <span>size_t</span> from_top <span>=</span> <span><span>number_of_blocks_from_top</span><span><span>(</span></span></span><span><span>s<span>,</span> DIV<span>,</span> colons</span></span><span><span><span>)</span></span></span><span>;</span>

  <span> We could check if either DIV_MARKER_BEGIN or DIV_MARKER_END are valid here,
</span>  <span> but as the grammar is set up they're both always valid at the same time.
</span>  <span>if</span> <span><span>(</span>from_top <span>&gt;</span> <span>0</span><span>)</span></span> <span><span>{</span>
      <span>}</span></span> <span>else</span> <span><span>{</span>
        lexer<span>-&gt;</span><span><span>mark_end</span><span><span>(</span></span></span><span><span>lexer</span></span><span><span><span>)</span></span></span><span>;</span>
    <span><span>push_block</span><span><span>(</span></span></span><span><span>s<span>,</span> DIV<span>,</span> colons</span></span><span><span><span>)</span></span></span><span>;</span>
    lexer<span>-&gt;</span>result_symbol <span>=</span> DIV_MARKER_BEGIN<span>;</span>
    <span>return</span> <span>true</span><span>;</span>
  <span>}</span></span>
</span></span><span><span><span>}</span></span></span>
</span></code></pre></div>
<p>But we have a problem: when we want to close the div, we want to be able to output multiple tokens.</p>
<p>For example, with this type of input:</p>
<div><pre><code><span>:::</span>
<span>:::::</span>
<span>:::::::</span>
<span>text</span>
<span></span><span>:::</span>
</code></pre></div>
<p>We’ll have a stack of 3 divs when we see the closing <code>:::</code> marker:</p>
<div><pre><code>7 (top)
5
3 (the one we want to close)
</code></pre></div>
<p>In the code above, <code>from_top</code> will be <code>3</code> and we need to output 4 tokens: 3 <code>BLOCK_CLOSE</code> (one for each div) and 1 <code>DIV_MARKER_END</code> (for the last <code>:::</code>).
But the scanner can only output a single token at a time.</p>
<p>The way I solved this is by introducing more state to the Scanner.
Specifically, I introduced a <code>blocks_to_close</code> variable that we’ll use to output <code>BLOCK_CLOSE</code>, and some variables to output (and consume) the <code>DIV_MARKER_END</code>.</p>
<div><pre><code><span><span>typedef</span> <span>struct</span> <span><span>{</span>
  <span><span>Array</span><span><span>(</span></span></span><span><span>Block <span>*</span></span></span><span><span><span>)</span></span></span> <span>*</span> open_blocks<span>;</span>

  <span><span>//</span> How many BLOCK_CLOSE we should output right now?
</span>  <span>uint8_t</span> blocks_to_close<span>;</span>

  <span><span>//</span> Delayed output of a token.
</span>  TokenType delayed_token<span>;</span>
  <span><span>//</span> Allows us to consume the width of a delayed token.
</span>  <span>uint8_t</span> delayed_token_width<span>;</span>
<span>}</span></span> <span>Scanner</span><span>;</span>
</span></code></pre></div>
<p>We need to remember to update the create and serialize functions too.</p>
<p>Serialize:</p>
<div><pre><code><span>buffer<span><span>[</span>size<span>+</span><span>+</span><span>]</span></span> <span>=</span> <span><span>(</span><span>char</span><span>)</span></span>s<span>-&gt;</span>blocks_to_close<span>;</span>
buffer<span><span>[</span>size<span>+</span><span>+</span><span>]</span></span> <span>=</span> <span><span>(</span><span>char</span><span>)</span></span>s<span>-&gt;</span>delayed_token<span>;</span>
buffer<span><span>[</span>size<span>+</span><span>+</span><span>]</span></span> <span>=</span> <span><span>(</span><span>char</span><span>)</span></span>s<span>-&gt;</span>delayed_token_width<span>;</span>
</span></code></pre></div>
<p>Deserialize:</p>
<div><pre><code><span>s<span>-&gt;</span>blocks_to_close <span>=</span> <span><span>(</span><span>uint8_t</span><span>)</span></span>buffer<span><span>[</span>size<span>+</span><span>+</span><span>]</span></span><span>;</span>
s<span>-&gt;</span>delayed_token <span>=</span> <span><span>(</span>TokenType<span>)</span></span>buffer<span><span>[</span>size<span>+</span><span>+</span><span>]</span></span><span>;</span>
s<span>-&gt;</span>delayed_token_width <span>=</span> <span><span>(</span><span>uint8_t</span><span>)</span></span>buffer<span><span>[</span>size<span>+</span><span>+</span><span>]</span></span><span>;</span>
</span></code></pre></div>
<p>We’ll use <code>IGNORED</code> as the unused token, so we’ll need to reset it when we create the scanner:</p>
<div><pre><code><span>s<span>-&gt;</span>blocks_to_close <span>=</span> <span>0</span><span>;</span>
s<span>-&gt;</span>delayed_token <span>=</span> IGNORED<span>;</span>
</span></code></pre></div>
<p>Now when we scan we should first check <code>blocks_to_close</code> and then <code>delayed_token</code>, before we scan other things:</p>
<div><pre><code><span><span>bool</span> <span><span>tree_sitter_sdjot_external_scanner_scan</span></span><span><span><span>(</span></span></span><span><span><span>void</span> <span>*</span><span>payload</span><span>,</span> TSLexer <span>*</span><span>lexer</span><span>,</span>
                                             <span>const</span> <span>bool</span> <span>*</span><span>valid_symbols</span><span>)</span></span></span><span> </span><span><span><span>{</span></span></span><span><span>
  Scanner <span>*</span>s <span>=</span> <span><span>(</span>Scanner <span>*</span><span>)</span></span>payload<span>;</span>

  <span>if</span> <span><span>(</span>valid_symbols<span><span>[</span>BLOCK_CLOSE<span>]</span></span> <span>&amp;&amp;</span> <span><span>handle_blocks_to_close</span><span><span>(</span></span></span><span><span>s<span>,</span> lexer</span></span><span><span><span>)</span></span></span><span>)</span></span> <span><span>{</span>
    <span>return</span> <span>true</span><span>;</span>
  <span>}</span></span>

  <span>if</span> <span><span>(</span><span><span>output_delayed_token</span><span><span>(</span></span></span><span><span>s<span>,</span> lexer<span>,</span> valid_symbols</span></span><span><span><span>)</span></span></span><span>)</span></span> <span><span>{</span>
    <span>return</span> <span>true</span><span>;</span>
  <span>}</span></span>

  <span> Scan the other stuff
</span></span></span><span><span><span>}</span></span></span>
</span></code></pre></div>
<p>When we see <code>blocks_to_close &gt; 0</code>, we should output a <code>BLOCK_CLOSE</code> and remove the top block (with some sanity checks for good measure):</p>
<div><pre><code><span><span>static</span> <span>void</span> <span><span>remove_block</span></span><span><span><span>(</span></span></span><span><span>Scanner <span>*</span><span>s</span><span>)</span></span></span><span> </span><span><span><span>{</span></span></span><span><span>
  <span>if</span> <span><span>(</span>s<span>-&gt;</span>open_blocks<span>-&gt;</span>size <span>&gt;</span> <span>0</span><span>)</span></span> <span><span>{</span>
    <span><span>ts_free</span><span><span>(</span></span></span><span><span><span><span>array_pop</span><span><span>(</span></span></span><span><span>s<span>-&gt;</span>open_blocks</span></span><span><span><span>)</span></span></span></span></span><span><span><span>)</span></span></span><span>;</span>
    <span>if</span> <span><span>(</span>s<span>-&gt;</span>blocks_to_close <span>&gt;</span> <span>0</span><span>)</span></span> <span><span>{</span>
      <span>-</span><span>-</span>s<span>-&gt;</span>blocks_to_close<span>;</span>
    <span>}</span></span>
  <span>}</span></span>
</span></span><span><span><span>}</span></span></span>

<span>static</span> <span>bool</span> <span><span>handle_blocks_to_close</span></span><span><span><span>(</span></span></span><span><span>Scanner <span>*</span><span>s</span><span>,</span> TSLexer <span>*</span><span>lexer</span><span>)</span></span></span><span> </span><span><span><span>{</span></span></span><span><span>
  <span>if</span> <span><span>(</span>s<span>-&gt;</span>open_blocks<span>-&gt;</span>size <span>==</span> <span>0</span><span>)</span></span> <span><span>{</span>
    <span>return</span> <span>false</span><span>;</span>
  <span>}</span></span>

  <span> If we reach eof with open blocks, we should close them all.
</span>  <span>if</span> <span><span>(</span>lexer<span>-&gt;</span><span><span>eof</span><span><span>(</span></span></span><span><span>lexer</span></span><span><span><span>)</span></span></span> <span>||</span> s<span>-&gt;</span>blocks_to_close <span>&gt;</span> <span>0</span><span>)</span></span> <span><span>{</span>
    lexer<span>-&gt;</span>result_symbol <span>=</span> BLOCK_CLOSE<span>;</span>
    <span><span>remove_block</span><span><span>(</span></span></span><span><span>s</span></span><span><span><span>)</span></span></span><span>;</span>
    <span>return</span> <span>true</span><span>;</span>
  <span>}</span></span>
  <span>return</span> <span>false</span><span>;</span>
</span></span><span><span><span>}</span></span></span>
</span></code></pre></div>
<p>With this we can output multiple <code>BLOCK_CLOSE</code>, and now to handle delayed tokens:</p>
<div><pre><code><span><span>static</span> <span>bool</span> <span><span>output_delayed_token</span></span><span><span><span>(</span></span></span><span><span>Scanner <span>*</span><span>s</span><span>,</span> TSLexer <span>*</span><span>lexer</span><span>,</span>
                          <span>const</span> <span>bool</span> <span>*</span><span>valid_symbols</span><span>)</span></span></span><span> </span><span><span><span>{</span></span></span><span><span>
  <span>if</span> <span><span>(</span>s<span>-&gt;</span>delayed_token <span>==</span> IGNORED <span>||</span> <span>!</span>valid_symbols<span><span>[</span>s<span>-&gt;</span>delayed_token<span>]</span></span><span>)</span></span> <span><span>{</span>
    <span>return</span> <span>false</span><span>;</span>
  <span>}</span></span>

  lexer<span>-&gt;</span>result_symbol <span>=</span> s<span>-&gt;</span>delayed_token<span>;</span>
  s<span>-&gt;</span>delayed_token <span>=</span> IGNORED<span>;</span>
  <span> With `delayed_token_width` we can consume the ending `:::`, for example.
</span>  <span>while</span> <span><span>(</span>s<span>-&gt;</span>delayed_token_width<span>-</span><span>-</span><span>)</span></span> <span><span>{</span>
    lexer<span>-&gt;</span><span><span>advance</span><span><span>(</span></span></span><span><span>lexer<span>,</span> <span>false</span></span></span><span><span><span>)</span></span></span><span>;</span>
  <span>}</span></span>
  lexer<span>-&gt;</span><span><span>mark_end</span><span><span>(</span></span></span><span><span>lexer</span></span><span><span><span>)</span></span></span><span>;</span>
  <span>return</span> <span>true</span><span>;</span>
</span></span><span><span><span>}</span></span></span>
</span></code></pre></div>
<p>Another way to design this is to have a stack of delayed tokens and then just pop that.
It’s certainly more powerful, I just happened to choose this way when I was playing around with it because it’s more explicit and it felt a little easier to follow what was happening.</p>
<p>Either way, we can now implement the div end handling. In <code>parse_div</code>:</p>
<div><pre><code><span><span>size_t</span> from_top <span>=</span> <span><span>number_of_blocks_from_top</span><span><span>(</span></span></span><span><span>s<span>,</span> DIV<span>,</span> colons</span></span><span><span><span>)</span></span></span><span>;</span>

<span>if</span> <span><span>(</span>from_top <span>&gt;</span> <span>0</span><span>)</span></span> <span><span>{</span>
  <span><span>//</span> Found a div we should close.
</span>  <span><span>close_blocks_with_final_token</span><span><span>(</span></span></span><span><span>s<span>,</span> lexer<span>,</span> from_top<span>,</span> DIV_MARKER_END<span>,</span> colons</span></span><span><span><span>)</span></span></span><span>;</span>
  <span>return</span> <span>true</span><span>;</span>
<span>}</span></span> <span>else</span> <span><span>{</span>
  lexer<span>-&gt;</span><span><span>mark_end</span><span><span>(</span></span></span><span><span>lexer</span></span><span><span><span>)</span></span></span><span>;</span>
  <span><span>push_block</span><span><span>(</span></span></span><span><span>s<span>,</span> DIV<span>,</span> colons</span></span><span><span><span>)</span></span></span><span>;</span>
  lexer<span>-&gt;</span>result_symbol <span>=</span> DIV_MARKER_BEGIN<span>;</span>
  <span>return</span> <span>true</span><span>;</span>
<span>}</span></span>
</span></code></pre></div>
<p><code>close_blocks_with_final_token</code> is a general helper that sets up the number of blocks to close and the final token:</p>
<div><pre><code><span><span>static</span> <span>void</span> <span><span>close_blocks_with_final_token</span></span><span><span><span>(</span></span></span><span><span>Scanner <span>*</span><span>s</span><span>,</span> TSLexer <span>*</span><span>lexer</span><span>,</span>
                                          <span>size_t</span> <span>count</span><span>,</span> TokenType <span>final</span><span>,</span>
                                          <span>uint8_t</span> <span>final_token_width</span><span>)</span></span></span><span> </span><span><span><span>{</span></span></span><span><span>
  <span><span>remove_block</span><span><span>(</span></span></span><span><span>s</span></span><span><span><span>)</span></span></span><span>;</span>
  s<span>-&gt;</span>blocks_to_close <span>=</span> s<span>-&gt;</span>blocks_to_close <span>+</span> count <span>-</span> <span>1</span><span>;</span>
  lexer<span>-&gt;</span>result_symbol <span>=</span> BLOCK_CLOSE<span>;</span>
  s<span>-&gt;</span>delayed_token <span>=</span> final<span>;</span>
  s<span>-&gt;</span>delayed_token_width <span>=</span> final_token_width<span>;</span>
</span></span><span><span><span>}</span></span></span>
</span></code></pre></div>
<p>Now we can finally try to close divs:</p>
<div><pre><code><span>:::::</span>
<span>:::</span>
<span>:::::::</span>
<span>Divception</span>
<span></span><span>:::</span>
</code></pre></div>
<div><pre><code><span>$ </span><span>tree-sitter</span> parse example-file
(document [0, 0] - [6, 0]
  (div [0, 0] - [6, 0]
    (div_marker [0, 0] - [0, 5])
    (div [1, 0] - [4, 3]
      (div_marker [1, 0] - [1, 3])
      (div [2, 0] - [4, 0]
        (div_marker [2, 0] - [2, 7])
        (paragraph [3, 0] - [4, 0]))
      (div_marker [4, 0] - [4, 3]))))
</code></pre></div>
<p>We can see that it parses without error, the last marker closes the <em>second</em> div correctly, and the last marker captures the final <code>:::</code>.</p>
<p>While I’m jumping to a working implementation directly in this post, when I first did this that was of course not the case.
I found the <code>-d</code> argument useful to see what characters are consumed and what token is output in each step.</p>
<p>Here’s a part of the output (when scanning the final <code>:::</code>), with some comments to point out some interesting things:</p>
<div><pre><code><span>$ </span><span>tree-sitter</span> parse example-file -d
...
process version:0, version_count:1, state:34, row:4, col:0
lex_external state:4, row:4, column:0
  consume character:':'                         // Scan `:::`
  consume character:':'
  consume character:':'
lexed_lookahead sym:_close_paragraph, size:0    // Output _close_paragraph
reduce sym:paragraph_repeat1, child_count:2
shift state:17
process version:0, version_count:1, state:17, row:4, col:0
lex_external state:3, row:4, column:0           // Still on first `:`
  consume character:':'                         // Scan `:::` again
  consume character:':'
  consume character:':'
lexed_lookahead sym:_block_close, size:0        // Close div with _block_close
reduce sym:paragraph, child_count:2
shift state:12
process version:0, version_count:1, state:12, row:4, col:0
lex_external state:5, row:4, column:0           // Still on first `:`
lexed_lookahead sym:_block_close, size:0        // Close second div with _block_close
reduce sym:div, child_count:4
shift state:12
process version:0, version_count:1, state:12, row:4, col:0
lex_external state:5, row:4, column:0           // Still on first `:`
  consume character:':'                         // Consume `:::`
  consume character:':'
  consume character:':'
lexed_lookahead sym:div_marker, size:3          // div_marker is size 3, marks `:::`
shift state:23
</code></pre></div>
<p>While the output seems confusing, when you know what to look for it’s very useful.
I’ve found that a deliberate process, where I look at a single character at a time, helps me get through the problems I’ve encountered so far.</p>
</section>
</section>
<section id="Handling-conflicts">
<h2><a href="#Handling-conflicts">Handling conflicts</a></h2>
<p>Our grammar works pretty well, but there are issues you might want to fix.
One issue, that took much longer to figure out than I care to admit, is adding a fallback to text when a markup rule doesn’t match.</p>
<p>A simple example for our grammar is a single underscore in a paragraph:</p>

<p>I’d assume this would produce a paragraph with text, but instead we get an error:</p>
<div><pre><code><span>$ </span><span>tree-sitter</span> parse example-file
(document [0, 0] - [2, 0]
  (ERROR [0, 0] - [0, 3]))
</code></pre></div>
<p>This is weird, because one of the main selling points of Tree-sitter is the GLR algorithm, which should explore the different interpretations to find something that succeeds.
But for some reason, it doesn’t trigger for us.</p>
<p>Let’s take a look.
These are the relevant lines from the grammar:</p>
<div><pre><code><span><span>_inline</span><span>:</span> <span><span><span><span>(</span></span></span></span><span><span>$<span>)</span></span></span> =<span>&gt;</span> repeat<span><span>1</span></span><span><span><span><span>(</span></span></span></span><span><span>choice<span><span><span><span>(</span></span></span></span><span><span>$<span>.</span><span>emphasis</span><span>,</span> $<span>.</span><span>_text</span><span>)</span></span></span><span>)</span></span></span><span>,</span>
<span>emphasis</span><span>:</span> <span><span><span><span>(</span></span></span></span><span><span>$<span>)</span></span></span> =<span>&gt;</span> prec<span>.</span><span><span>left</span></span><span><span><span><span>(</span></span></span></span><span><span>seq<span><span><span><span>(</span></span></span></span><span><span><span><span><span>"</span>_<span>"</span></span></span><span>,</span> $<span>.</span><span>_inline</span><span>,</span> <span><span><span>"</span>_<span>"</span></span></span><span>)</span></span></span><span>)</span></span></span><span>,</span>
<span>_text</span><span>:</span> <span><span><span><span>(</span></span></span></span><span><span>_<span>)</span></span></span> =<span>&gt;</span> <span><span><span>/</span><span><span>[</span><span>^</span><span>\n</span><span>]</span></span><span>/</span></span></span><span></span><span>,</span>
</span></code></pre></div>
<p>When we try to match a <code>_</code> then the grammar can match either <code>emphasis</code> or <code>_text</code> because <code>_</code> matches both 
<code><span><span><span><span>"</span>_<span>"</span></span></span></span></code> and 
<code><span><span><span><span>/</span><span><span>[</span><span>^</span><span>\n</span><span>]</span></span><span>/</span></span></span><span></span></span></code>.
The issue seems to be that Tree-sitter doesn’t recognize this as a conflict.</p>
<p>If we instead add a fallback with a <code>_</code> string then Tree-sitter will treat it as a conflict:</p>
<div><pre><code><span><span>_inline</span><span>:</span> <span><span><span><span>(</span></span></span></span><span><span>$<span>)</span></span></span> =<span>&gt;</span> repeat<span><span>1</span></span><span><span><span><span>(</span></span></span></span><span><span>choice<span><span><span><span>(</span></span></span></span><span><span>$<span>.</span><span>emphasis</span><span>,</span> $<span>.</span><span>_text</span><span>,</span> $<span>.</span><span>_fallback</span><span>)</span></span></span><span>)</span></span></span><span>,</span>
<span>emphasis</span><span>:</span> <span><span><span><span>(</span></span></span></span><span><span>$<span>)</span></span></span> =<span>&gt;</span> prec<span>.</span><span><span>left</span></span><span><span><span><span>(</span></span></span></span><span><span>seq<span><span><span><span>(</span></span></span></span><span><span><span><span><span>"</span>_<span>"</span></span></span><span>,</span> $<span>.</span><span>_inline</span><span>,</span> <span><span><span>"</span>_<span>"</span></span></span><span>)</span></span></span><span>)</span></span></span><span>,</span>
<span><span>//</span> prec.dynamic() is used during conflict resolution to choose which
</span><span><span>//</span> branch to choose if multiple succeed.
</span><span>_fallback</span><span>:</span> <span><span><span><span>(</span></span></span></span><span><span>_<span>)</span></span></span> =<span>&gt;</span> prec<span>.</span><span><span>dynamic</span></span><span><span><span><span>(</span></span></span></span><span><span><span>-</span><span><span>100</span></span><span>,</span> <span><span><span>"</span>_<span>"</span></span></span><span>)</span></span></span><span>,</span>
<span>_text</span><span>:</span> <span><span><span><span>(</span></span></span></span><span><span>_<span>)</span></span></span> =<span>&gt;</span> <span><span><span>/</span><span><span>[</span><span>^</span><span>\n</span><span>]</span></span><span>/</span></span></span><span></span><span>,</span>
</span></code></pre></div>
<p>And when we call <code>tree-sitter generate</code> we’re made aware of the conflict:</p>
<div><pre><code><span>$ </span><span>tree-sitter</span> generate
Unresolved conflict for symbol sequence:

  '_'  •  '_'  …

Possible interpretations:

  1:  (_fallback  '_')  •  '_'  …
  2:  (emphasis  '_'  •  _inline  '_')  (precedence: 0, associativity: Left)

Possible resolutions:

  1:  Specify a higher precedence in `emphasis` than in the other rules.
  2:  Specify a higher precedence in `_fallback` than in the other rules.
  3:  Specify a left or right associativity in `_fallback`
  4:  Add a conflict for these rules: `emphasis`, `_fallback`
</code></pre></div>
<p>What we want to do is mark them as a conflict that’s supposed to exist in the grammar using the <code>conflicts</code> field:</p>
<div><pre><code><span><span>conflicts</span><span>:</span> <span><span><span><span>(</span></span></span></span><span><span>$<span>)</span></span></span> =<span>&gt;</span> <span><span>[</span><span><span>[</span>$<span>.</span><span>emphasis</span><span>,</span> $<span>.</span><span>_fallback</span><span>]</span></span><span>]</span></span><span>,</span>
</span></code></pre></div>
<p>And now we can parse paragraphs containing only a single <code>_</code> without errors.</p>
<p>So it seems like Tree-Sitter doesn’t recognize a conflict between a string and a regex.
Another gotcha is that it doesn’t seem like you can trigger the GLR algorithm with a token returned by an external scanner, because the external scanner overrules Tree-sitter’s lexing behavior.</p>
</section>
<section id="Some-tests">
<h2><a href="#Some-tests">Some tests</a></h2>
<p>Using <code>tree-sitter parse example-file</code> (with or without the <code>-d</code> or <code>-D</code> flags, try them if you haven’t) is fine for experimental tests, but we really should add the different test cases as proper unit tests.
Tree-sitter has a built-in test harness for this purpose.</p>
<p>Let’s add the very first test case to <code>test/corpus/syntax.txt</code>:</p>
<div><pre><code>===============================================================================
Parsing goal
===============================================================================
This is a
multiline _paragraph_

:::
This is a paragraph inside a div
:::

```gleam
let x = 2;
```

-------------------------------------------------------------------------------

(document
  (paragraph (emphasis))
  (div
    (div_marker)
    (paragraph)
    (div_marker))
  (code_block
    (code_block_marker)
    (language)
    (code)
    (code_block_marker)))
</code></pre></div>
<p>And run it:</p>
<div><pre><code>$ tree-sitter test
  syntax:
    ✓ Parsing goal
</code></pre></div>
<p>Yay!</p>
<p>We should add (a lot) more tests here, but I won’t bother writing them out in this already too long blog post.</p>
</section>
<section id="Using-tree-sitter-for-something-useful">
<h2><a href="#Using-tree-sitter-for-something-useful">Using tree-sitter for something useful</a></h2>
<p>I like a theoretical excursion as much as the next nerd, but I started looking at Tree-sitter because I wanted to <em>do</em> something with the Grammar, not just play around with it all day.
Let’s end the post by seeing some things we can use it for.</p>
<section id="Syntax-highlighting">
<h3><a href="#Syntax-highlighting">Syntax highlighting</a></h3>
<p>Syntax highlighting is made using queries from the <code>highlights.scm</code> file.
It’s common to have it placed in the <code>src</code> directory in the same repository as the grammar, but it’s not required.</p>
<p>Here’s an example <code>src/highlights.scm</code> file that highlights the different elements of our markup:</p>
<div><pre><code><span><span><span>(</span>div_marker<span>)</span></span> @punctuation.delimiter
<span><span>(</span>code_block_marker<span>)</span></span> @punctuation.delimiter

<span><span>(</span>emphasis <span><span>"</span>_<span>"</span></span> @punctuation.delimiter<span>)</span></span> @markup.italic
<span><span>(</span>language<span>)</span></span> @tag.attribute

<span><span>(</span>code_block<span>)</span></span> @markup.raw
<span><span>(</span>paragraph<span>)</span></span> @markup
</span></code></pre></div>
<p>What colors to choose is a bit arbitrary, these works well enough I suppose.</p>
<p>See the <a href="https://tree-sitter.github.io/tree-sitter/syntax-highlighting">documentation</a> for more details on how the queries and highlighting works.</p>
</section>
<section id="Language-injection">
<h3><a href="#Language-injection">Language injection</a></h3>
<p>One big question I had when starting writing my grammar was how to mix multiple parsers in the same document, to for example highlight code blocks using the specified language:</p>

<p>Turns out, this is quite straightforward.</p>
<p>With the initial grammar, the code block parses into:</p>
<div><pre><code>(code_block
  (code_block_marker)
  (language)
  (code)
  (code_block_marker)))
</code></pre></div>
<p>Which we’ll use in <code>src/injections.scm</code> to specify that we want to parse <code>(code)</code> using the grammar specified in <code>(language)</code>:</p>
<div><pre><code><span><span><span>(</span>code_block
  <span><span>(</span>language<span>)</span></span> @injection.language
  <span><span>(</span>code<span>)</span></span> @injection.content<span>)</span></span>
</span></code></pre></div>
<p>When we’ll embed the grammar into a program with highlighting support, it will delegate the text inside the code block to the injected language.</p>
</section>
<section id="Using-our-grammar-with-Neovim">
<h3><a href="#Using-our-grammar-with-Neovim">Using our grammar with Neovim</a></h3>
<figure><img alt="" src="https://www.jonashietala.se/images/sdjot_neovim.png">
</figure>
<p>I typically install Tree-sitter grammars in Neovim using <code>:TSInstall</code> provided by <a href="https://github.com/nvim-treesitter/nvim-treesitter">nvim-treesitter</a>.
But you can <a href="https://github.com/nvim-treesitter/nvim-treesitter#adding-parsers">install local Tree-sitter grammars</a> as well:</p>
<div><pre><code><span><span>local</span> parser_config <span>=</span> <span>require</span>(<span><span>"</span>nvim-treesitter.parsers<span>"</span></span>).get_parser_configs()
parser_config.sdjot <span>=</span> {
    install_info <span>=</span> {
        <span><span>--</span> Change this url to your grammar
</span>        url <span>=</span> <span><span>"</span>~/code/tree-sitter-sdjot<span>"</span></span>,
        <span><span>--</span> If you use an external scanner it needs to be included here
</span>        files <span>=</span> { <span><span>"</span>src/parser.c<span>"</span></span>, <span><span>"</span>src/scanner.c<span>"</span></span> },
        generate_reqires_npm <span>=</span> <span>false</span>,
        requires_generate_from_grammar <span>=</span> <span>false</span>,
    },
    <span><span>--</span> The filetype you want it registered as
</span>    filetype <span>=</span> <span><span>"</span>sdjot<span>"</span></span>,
}
</span></code></pre></div>
<p>Just make sure you have a <code>"tree-sitter"</code> section in the grammar’s <code>package.json</code>:</p>
<div><pre><code><span><span><span>"</span>tree-sitter<span>"</span></span>: <span><span>[</span>
  <span><span>{</span>
    <span><span><span>"</span>scope<span>"</span></span></span><span><span>:</span> <span><span>"</span>source.sdjot<span>"</span></span><span>,</span></span>
    <span><span><span>"</span>file-types<span>"</span></span></span><span><span>:</span> <span><span>[</span>
      <span><span>"</span>sdj<span>"</span></span>
    <span>]</span></span><span>,</span></span>
    <span><span><span>"</span>injection-regex<span>"</span></span></span><span><span>:</span> <span><span>"</span>sdjot<span>"</span></span><span>,</span></span>
    <span><span><span>"</span>highlights<span>"</span></span></span><span><span>:</span> <span><span>[</span>
      <span><span>"</span>queries/highlights.scm<span>"</span></span>
    <span>]</span></span>
  </span><span>}</span></span>
<span>]</span></span>,
</span></code></pre></div>
<p>With this you can do <code>:TSInstall sjdot</code> and <code>:TSUpdate sdjot</code> when you make changes.</p>
<p><code>:TSInstall</code> doesn’t install queries automatically though.
What I did was symlink the queries directory into Neovims config directory:</p>
<div><pre><code><span>ln</span> -s ~/code/tree-sitter-sdjot/queries ~/.config/nvim/queries/sdjot
</code></pre></div>
<p><code>:TSPlaygroundToggle</code> is very useful for debugging the grammar, and <code>:Inspect</code> shows you the highlight groups under your cursor.
It might be good to check out <code>:help treesitter-highlight-groups</code> if you want to play with your theme, as the theme needs to support the highlight groups we use for coloring to appear.</p>
<p>You also need to have the Tree-sitter grammar for the injected language installed, if you want to highlight the contents of code blocks.</p>
</section>
<section id="Jumping-and-selecting-with-textobjects">
<h3><a href="#Jumping-and-selecting-with-textobjects">Jumping and selecting with textobjects</a></h3>
<p>I mentioned <a href="https://github.com/nvim-treesitter/nvim-treesitter-textobjects">nvim-treesitter-textobjects</a> as a good example of why Tree-sitter is about more than syntax highlighting.</p>
<p>To make use of our grammar we can add some capture groups to <code>src/textobjects.scm</code>.
For example we can register our code blocks as “functions”:</p>
<div><pre><code><span><span><span>(</span>code_block <span><span>(</span>code<span>)</span></span> @function.inner<span>)</span></span> @function.outer
</span></code></pre></div>
<p>The objects are arbitrary, but <code>@function</code> is one of the standard objects so I guess it might make sense.</p>
<p>With the symlink ready, you need to register keymaps with <a href="https://github.com/nvim-treesitter/nvim-treesitter-textobjects">nvim-treesitter-textobjects</a> and you’re good to go.
I have it setup so I can jump between <code>@function.outer</code> with <code>[f</code> and <code>]f</code>, and selections with <code>af</code> and <code>if</code>.</p>
<p>This means that with the above textobject definition I can for example jump to the next code block with <code>]f</code> and then remove all the code inside with <code>cif</code> to end up in insert mode, ready to replace it with some new code.</p>
<p>Although this example is a bit arbitrary, this general functionality is <strong><em>extremely</em></strong> useful for programming languages.
For a markup language like <a href="https://djot.net/">Djot</a>, jumping between headings might be a more relevant use-case.</p>
</section>
<section id="Embedding-the-grammar-with-Rust">
<h3><a href="#Embedding-the-grammar-with-Rust">Embedding the grammar with Rust</a></h3>
<p>One of the selling points of Tree-sitter is that you should be able to embed it in any application.
Such as this blog!</p>
<p>I’ve been wanting to add Tree-sitter powered highlighting to my blog for a while, and now I have an excuse to do just that.</p>
<p>This blog is a static site generator written in Rust, and <a href="https://docs.rs/tree-sitter-highlight/latest/tree_sitter_highlight/">tree-sitter-highlight</a> looks like a suitable library to try.
Let’s add it to our <code>Cargo.toml</code>:</p>
<div><pre><code><span><span>[</span><span><span>dependencies</span></span><span>]</span>
<span><span>tree-sitter-highlight</span></span> <span>=</span> <span><span>"</span>^0.20.0<span>"</span></span>
<span><span>tree-sitter-sdjot</span></span> <span>=</span> <span>{</span> <span><span>git</span></span> <span>=</span> <span><span>"</span>https://github.com/treeman/tree-sitter-sdjot.git<span>"</span></span> <span>}</span>
</span></code></pre></div>
<p>I use a slightly older version because some other grammars I want depend on the older version, and it’s a big pain but they all need to use a matching version.
Bleh.</p>
<p><a href="https://docs.rs/tree-sitter-highlight/latest/tree_sitter_highlight/">According to the docs</a> we first need to setup a <code>HighlightConfiguration</code>.
I used <code>lazy_static!</code> to create a global map with configurations to be used by any parallel rendering on the blog.
It’s not the most beautiful code I’ve written, but it gets the job done:</p>
<div><pre><code><span><span><span>//</span> All highlights needs to be listed explicitly.
</span><span>static</span> <span>HIGHLIGHT_NAMES</span><span>:</span> <span>&amp;</span><span><span>[</span><span>&amp;</span><span>str</span><span>]</span></span> <span>=</span> <span>&amp;</span><span><span>[</span>
    <span><span>//</span> I have +100 entries here, this is for sdjot.
</span>   <span><span>"</span>markup<span>"</span></span><span>,</span>
   <span><span>"</span>markup.italic<span>"</span></span><span>,</span>
   <span><span>"</span>markup.raw<span>"</span></span><span>,</span>
   <span><span>"</span>punctuation.delimiter<span>"</span></span><span>,</span>
   <span><span>"</span>tag.attribute<span>"</span></span><span>,</span>
<span>]</span></span><span>;</span>

<span>lazy_static!</span> <span><span>{</span>
    <span>static</span> <span>ref</span> <span>CONFIGS</span><span>:</span> <span>HashMap<span>&lt;</span>String, HighlightConfiguration<span>&gt;</span></span> <span>=</span> <span>init_configurations</span><span><span>(</span></span><span><span>)</span></span><span>;</span>
</span><span><span>}</span></span>

<span><span><span>fn</span> </span><span>init_configurations</span></span><span><span><span>(</span></span><span><span><span>)</span></span></span></span><span> <span><span>-&gt;</span> <span>HashMap<span>&lt;</span>String, HighlightConfiguration<span>&gt;</span></span></span> </span><span><span><span>{</span>
    <span><span>[</span>
                <span><span>(</span>
            <span><span>"</span>sdjot<span>"</span></span><span>,</span>
            <span>HighlightConfiguration<span>::</span></span>new<span><span>(</span>
                <span>tree_sitter_sdjot<span>::</span></span>language<span><span>(</span></span><span><span>)</span></span><span>,</span>
                <span>tree_sitter_sdjot<span>::</span></span><span>HIGHLIGHTS_QUERY</span><span>,</span>
                <span>tree_sitter_sdjot<span>::</span></span><span>INJECTIONS_QUERY</span><span>,</span>
                <span><span>"</span><span>"</span></span><span>,</span>
            </span><span><span>)</span></span>
            .<span>unwrap</span><span><span>(</span></span><span><span>)</span></span><span>,</span>
        </span><span><span>)</span></span><span>,</span>
    <span>]</span></span>
    .<span>into_iter</span><span><span>(</span></span><span><span>)</span></span>
    .<span>map</span><span><span>(</span><span><span><span>|</span></span></span><span><span><span><span>(</span></span><span><span>name</span><span>,</span> <span>mut</span> <span>config</span></span><span><span>)</span></span><span>|</span></span> </span><span><span><span>{</span>
        config.<span>configure</span><span><span>(</span><span>&amp;</span><span>HIGHLIGHT_NAMES</span></span><span><span>)</span></span><span>;</span>
        <span><span>(</span>name.<span>to_string</span><span><span>(</span></span><span><span>)</span></span><span>,</span> config</span><span><span>)</span></span>
    </span><span><span>}</span></span></span></span><span><span>)</span></span>
    .<span>collect</span><span><span>(</span></span><span><span>)</span></span>
</span><span><span>}</span></span></span>
</span></code></pre></div>
<p>Notice how all highlight names we’re interested in have to be explicitly specified.
This is a big pain, especially if you’re going to include many larger grammars.</p>
<p>The names can be filtered for with <a href="https://github.com/BurntSushi/ripgrep">ripgrep</a> with something like this:</p>
<div><pre><code><span>rg</span> <span>"@[<span>\w</span>.]+"</span> -INo --trim highlights.scm <span>|</span> <span>sort</span> <span>|</span> <span>uniq</span>
</code></pre></div>
<p>I already have syntax highlighting via <a href="https://github.com/trishume/syntect">syntect</a>, so I wrap the highlighters in their own types:</p>
<div><pre><code><span><span><span>enum</span> <span>HighlighterType</span>&lt;'a&gt; <span><span>{</span>
    Syntect<span><span>(</span><span>SyntectHighlighter<span>&lt;</span><span>'a</span><span>&gt;</span></span></span><span><span>)</span></span><span>,</span>
    Treesitter<span><span>(</span><span>TreesitterHighlighter<span>&lt;</span><span>'a</span><span>&gt;</span></span></span><span><span>)</span></span><span>,</span>
</span><span><span>}</span></span></span>

<span><span>pub</span> <span>struct</span> </span><span><span><span>TreesitterHighlighter</span><span><span>&lt;</span><span>'a</span><span>&gt;</span></span></span></span><span> </span><span><span><span>{</span>
    <span>config</span><span>:</span> <span>&amp;</span><span>'a</span> HighlightConfiguration,
</span><span><span>}</span></span></span>

<span><span>impl</span></span><span><span><span>&lt;</span><span>'a</span><span>&gt;</span></span></span><span> <span>TreesitterHighlighter</span><span><span>&lt;</span><span>'a</span><span>&gt;</span></span> </span><span><span><span>{</span>
    <span><span><span>pub</span> <span>fn</span> </span><span>find</span></span><span><span><span>(</span><span>lang_id</span><span>:</span> <span>&amp;</span><span>str</span></span><span><span><span>)</span></span></span></span><span> <span><span>-&gt;</span> <span>Option<span>&lt;</span><span>Self</span><span>&gt;</span></span></span> </span><span><span><span>{</span>
        <span>CONFIGS</span>.<span>get</span><span><span>(</span>lang_id</span><span><span>)</span></span>.<span>map</span><span><span>(</span><span><span><span>|</span></span></span><span><span><span>config</span><span>|</span></span> </span><span><span>Self</span> <span><span>{</span> config </span><span><span>}</span></span></span></span><span><span>)</span></span>
    </span><span><span>}</span></span></span>
</span><span><span>}</span></span></span>
</span></code></pre></div>
<p>The interesting part is of course the <code>highlight</code> method, that takes a string of code and applies syntax highlighting on it:</p>
<div><pre><code><span><span><span>impl</span></span><span><span><span>&lt;</span><span>'a</span><span>&gt;</span></span></span><span> <span>TreesitterHighlighter</span><span><span>&lt;</span><span>'a</span><span>&gt;</span></span> </span><span><span><span>{</span>
    <span><span><span>pub</span> <span>fn</span> </span><span>highlight</span></span><span><span><span>(</span><span>&amp;</span><span>self</span>, <span>code</span><span>:</span> <span>&amp;</span><span>str</span></span><span><span><span>)</span></span></span></span><span> <span><span>-&gt;</span> <span>Result<span>&lt;</span>String<span>&gt;</span></span></span> </span><span><span><span>{</span>
        <span>let</span> <span>mut</span> highlighter <span>=</span> <span>Highlighter<span>::</span></span>new<span><span>(</span></span><span><span>)</span></span><span>;</span>

        <span>let</span> highlights <span>=</span> highlighter.<span>highlight</span><span><span>(</span><span>self</span>.config<span>,</span> code.<span>as_bytes</span><span><span>(</span></span><span><span>)</span></span><span>,</span> <span>None</span><span>,</span> <span><span><span>|</span></span></span><span><span><span>lang</span><span>|</span></span> </span><span><span><span>{</span>
                                    <span>let</span> res <span>=</span> <span>CONFIGS</span>.<span>get</span><span><span>(</span>lang</span><span><span>)</span></span><span>;</span>
            <span>if</span> <span>!</span>res.<span>is_some</span><span><span>(</span></span><span><span>)</span></span> <span><span>{</span>
                <span>warn!</span><span><span>(</span><span><span>"</span>Couldn't find treesitter grammar for `{lang}` to inject<span>"</span></span></span><span><span>)</span></span><span>;</span>
            </span><span><span>}</span></span>
            res
        </span><span><span>}</span></span></span></span><span><span>)</span></span><span>?</span><span>;</span>

        <span>let</span> <span>mut</span> renderer <span>=</span> <span>HtmlRenderer<span>::</span></span>new<span><span>(</span></span><span><span>)</span></span><span>;</span>
        renderer.<span>render</span><span><span>(</span>highlights<span>,</span> code.<span>as_bytes</span><span><span>(</span></span><span><span>)</span></span><span>,</span> <span>&amp;</span><span>|</span>attr<span>|</span> <span><span>{</span>
                    </span><span><span>}</span></span></span><span><span>)</span></span><span>?</span><span>;</span>
        <span>let</span> res <span>=</span> renderer.<span>lines</span><span><span>(</span></span><span><span>)</span></span>.<span>join</span><span><span>(</span><span><span>"</span><span>"</span></span></span><span><span>)</span></span><span>;</span>
        <span>Ok</span><span><span>(</span>res</span><span><span>)</span></span>
    </span><span><span>}</span></span></span>
</span><span><span>}</span></span></span>
</span></code></pre></div>
<p>I want to point out the API in <code>HtmlRenderer</code>, where we stumble upon a very annoying problem:
what should we return from the callback, and how should we do that?</p>
<p>What the callback does is inject the return value into the <code>span</code> element, like this:</p>
<div><pre><code><span><span><span>&lt;</span><span>span</span> <span>CALLBACK_RESULT</span> <span>&gt;</span></span>highlight<span><span>&lt;/</span><span>span</span><span>&gt;</span></span>
</span></code></pre></div>
<p>So we’d like to return something like 
<code><span><span><span>"</span>class=<span>\"</span>markup italic<span>\"</span><span>"</span></span></span></code>, using <code>attr</code> which is only a <code>usize</code> into <code>HIGHLIGHT_NAMES</code>:</p>
<div><pre><code><span>renderer.<span>render</span><span><span>(</span>highlights<span>,</span> code.<span>as_bytes</span><span><span>(</span></span><span><span>)</span></span><span>,</span> <span>&amp;</span><span>|</span>attr<span>|</span> <span><span>{</span>
    <span>format!</span><span><span>(</span></span><span><span><span>r</span><span>#</span>"class="<span>{}</span>"<span>"#</span></span></span><span><span>,</span> <span>HIGHLIGHT_NAMES</span><span><span>[</span>attr.<span>0</span><span>]</span></span>.<span>replace</span><span><span>(</span><span><span>"</span>.<span>"</span></span><span>,</span> <span><span>"</span> <span>"</span></span></span><span><span>)</span></span><span>)</span></span>.<span>as_bytes</span><span><span>(</span></span><span><span>)</span></span>
</span><span><span>}</span></span></span><span><span>)</span></span><span>?</span><span>;</span>
</span></code></pre></div>
<p>Because we return a slice of bytes into a string that’s created inside the callback, of course the Rust compiler will be mad at us:</p>
<div><pre><code>error[E0515]: cannot return value referencing temporary value
  --&gt; src/markup/syntax_highlight/treesitter_highlighter.rs:33:13
   |
33 |             format!(r#"class="{}""#, HIGHLIGHT_NAMES[attr.0].replace(".", " ")).as_bytes()
   |             -------------------------------------------------------------------^^^^^^^^^^^
   |             |
   |             returns a value referencing data owned by the current function
   |             temporary value created here
</code></pre></div>
<p>How to dynamically create a string from inside the callback… That outlives the callback itself?</p>
<p>Not easily I tell you.</p>
<p>It would be so much easier if the callback would return a <code>Cow&lt;str&gt;</code> or something.
I wonder how the designers of the API expects it to be used?
This surely isn’t a very unique requirement, to wrap the attribute in a <code>class</code>?</p>
<p>Oh well.
One way to solve this is to store the generated strings in a container that outlives the callback, and reference that (yeah it’s a <code>Fn</code> callback, but there are hacky ways around that).
Or you could, you know, write your own <code>HtmlRenderer</code>.</p>
<p>Or you could pre-generate the classes and reference them:</p>
<div><pre><code><span><span>lazy_static!</span> <span><span>{</span>
    <span>static</span> <span>ref</span> <span>CLASSES</span><span>:</span> <span>Vec<span>&lt;</span>String<span>&gt;</span></span> <span>=</span> <span>HIGHLIGHT_NAMES</span>
        .<span>iter</span><span><span>(</span></span><span><span>)</span></span>
        .<span>map</span><span><span>(</span><span><span><span>|</span></span></span><span><span><span>name</span><span>|</span></span> </span><span><span>format!</span><span><span>(</span></span><span><span><span>r</span><span>#</span>"class="<span>{}</span>"<span>"#</span></span></span><span><span>,</span> name.<span>replace</span><span><span>(</span><span><span>"</span>.<span>"</span></span><span>,</span> <span><span>"</span> <span>"</span></span></span><span><span>)</span></span><span>)</span></span></span></span><span><span>)</span></span>
        .<span>collect</span><span><span>(</span></span><span><span>)</span></span><span>;</span>
</span><span><span>}</span></span>
</span></code></pre></div>
<div><pre><code><span>renderer.<span>render</span><span><span>(</span>highlights<span>,</span> code.<span>as_bytes</span><span><span>(</span></span><span><span>)</span></span><span>,</span> <span>&amp;</span><span>|</span>attr<span>|</span> <span><span>{</span>
    <span>CLASSES</span><span><span>[</span>attr.<span>0</span><span>]</span></span>.<span>as_bytes</span><span><span>(</span></span><span><span>)</span></span>
</span><span><span>}</span></span></span><span><span>)</span></span><span>?</span><span>;</span>
</span></code></pre></div>
<p>This should be the fastest option and is the one I currently use…
But speed isn’t a bottleneck here and I’d rather just return a <code>String</code> with <code>format!</code> and be done with it.</p>
<hr>
<p>With this I’ve integrated Tree-sitter based syntax highlighting into my blog!</p>
<div><pre><code><span><span>```</span></span>
<span>With great powers comes great responsibility</span>
<span><span>```</span></span>
</code></pre></div>
<p>I could start moving the various languages over from Syntect to Tree-sitter…
But I won’t.</p>
<p>There are some issues:</p>
<ol type="A">
<li>
<p>You need a compatible version of <code>tree-sitter</code> for all grammars.</p>
<p>The more grammars you add the more painful the upgrade path becomes.</p>
</li>
<li>
<p>Syntect gives better highlighting for some languages (like Rust and C).</p>
<p>Neovim has their own highlighter implementation and has made tweaks to certain grammars and gets much nicer highlighting than I got out of the box.</p>
<p>Integrating that code into my site generator is probably possible, but not a rabbit hole I want to jump into right now.</p>
</li>
<li>
<p>The highlighter library feels a bit immature.</p>
<p>A newer library broke the highlight groups I got from some grammars and I don’t see any support for how to add a language specific class to <code>span</code> for injected languages.</p>
</li>
</ol>
<p>Because of these issues I’ll evaluate what highlighter to use on a case-by-case basis, with Syntect as the default choice.</p>
</section>
</section>
<section id="Within-edge-cases-lies-complexity">
<h2><a href="#Within-edge-cases-lies-complexity">Within edge-cases lies complexity</a></h2>
<p>If you’ve read the post to the end, congratulations.
You made it!</p>
<p>I don’t claim to be an expert at grammars or Tree-sitter, and I’m sure there are plenty of things that can be improved with the way the grammar is made.
But I hope it can be helpful as a starting point if you’re curious on how to write a Tree-sitter grammar of your own.</p>
<p>See the <a href="https://github.com/treeman/tree-sitter-djot">tree-sitter-djot repo</a> for how I developed the grammar further to support the full <a href="https://htmlpreview.github.io/?https://github.com/jgm/djot/blob/master/doc/syntax.html">Djot specification</a> (but remember, I’m not an expert).</p>
<p>Just one word of advice before you go.
Writing a grammar for simple rules is pretty easy, but in the real world things can get messy quickly.
This is especially true if you need to juggle multiple conflicting rules in the external scanner—keeping a sane structure is challenging.</p>
<p>(Even in our simple grammar there are bugs, but I don’t care to fix them.)</p>
<blockquote>
<p>The night is dark and full of terrors
</p>

</blockquote>
</section>
 

  
</article>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Soul: A SQLite REST and Realtime Server (138 pts)]]></title>
            <link>https://thevahidal.github.io/soul/</link>
            <guid>39762315</guid>
            <pubDate>Wed, 20 Mar 2024 02:14:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thevahidal.github.io/soul/">https://thevahidal.github.io/soul/</a>, See on <a href="https://news.ycombinator.com/item?id=39762315">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
      
      

      <p>
    <img src="https://thevahidal.github.io/soul/docs/logo.png" height="150px">
    </p><p>
        A SQLite REST and Realtime server
    </p>


<p><a href="https://justforfunnoreally.dev/"><img src="https://img.shields.io/badge/justforfunnoreally-dev-9ff" alt="justforfunnoreally.dev badge"></a>
<a href="#contributors"><img src="https://img.shields.io/github/all-contributors/thevahidal/soul?color=ee8449&amp;style=flat-square" alt="All Contributors"></a>
<a href="https://trackgit.com/"><img src="https://us-central1-trackgit-analytics.cloudfunctions.net/token/ping/la8rmyedi6oogy87pxla" alt="trackgit"></a></p>

<h2 id="installation">Installation</h2>

<p>Install Soul CLI with npm</p>



<h2 id="usage">Usage</h2>

<p>Soul is command line tool, after installing it,
Run <code>soul -d sqlite.db -p 8000</code> and it’ll start a REST API on <a href="http://localhost:8000/">http://localhost:8000</a> and a Websocket server on <a href="ws://localhost:8000/">ws://localhost:8000</a>.</p>

<div><pre><code>Usage: soul <span>[</span>options]


Options:
      <span>--version</span>             Show version number                        <span>[</span>boolean]
  <span>-d</span>, <span>--database</span>            SQLite database file or :memory: <span>[</span>string] <span>[</span>required]
  <span>-p</span>, <span>--port</span>                Port to listen on                           <span>[</span>number]
  <span>-r</span>, <span>--rate-limit-enabled</span>  Enable rate limiting                       <span>[</span>boolean]
  <span>-c</span>, <span>--cors</span>                CORS whitelist origins                <span>[</span>string]
  <span>-S</span>, <span>--studio</span>              Start Soul Studio <span>in </span>parallel              <span>[</span>boolean]
      <span>--help</span>                Show <span>help</span>                                  <span>[</span>boolean]

</code></pre></div>

<p>Then to test Soul is working run the following command</p>

<div><pre><code>curl http://localhost:8000/api/tables
</code></pre></div>

<p>It should return a list of the tables inside <code>sqlite.db</code> database.</p>

<h2 id="documentation">Documentation</h2>

<p>API documentation is available while the project is running at <a href="http://localhost:8000/api/docs">http://localhost:8000/api/docs</a></p>

<p>There’s also a list of all endpoints examples at <a href="https://thevahidal.github.io/soul/docs/api-examples.html">docs/api-examples.md</a></p>

<p>For websocket examples, check <a href="https://thevahidal.github.io/soul/docs/ws-examples.html">docs/ws-examples.md</a></p>

<h2 id="extending-soul">Extending Soul</h2>

<p>Soul is able to be extended (e.g. Adding custom APIs) via extensions, you can find a list of extensions at <a href="https://thevahidal.github.io/soul/docs/extensions-examples.html">docs/extensions-examples.md</a></p>

<h2 id="soul-mates">Soul-mates</h2>

<p>A collection of projects that revolve around the Soul ecosystem.</p>

<ul>
  <li>
    <p><a href="https://github.com/thevahidal/soul-studio">Soul Studio</a> provides a GUI to work with your database.</p>

    <p>Right now Soul Studio is in early stages of development and not useful to work with.</p>

    <p>
      <img src="https://thevahidal.github.io/soul/docs/soul-studio.png">
  </p>
  </li>
  <li>
    <p><a href="https://github.com/DeepBlueCLtd/RCO-Soul">RCO-Soul</a> The purpose of this project is to demonstrate how to run a React admin client using Soul as a REST API service.</p>
  </li>
</ul>

<h2 id="development">Development</h2>

<div><pre><code>git clone https://github.com/thevahidal/soul <span># Clone project</span>

<span>cp</span> .env.sample .env <span># Duplicate sample environment variables</span>
nano .env <span># Update the environment variables</span>

npm <span>install</span> <span># Install dependencies</span>
npm run dev <span># Start the dev server</span>
</code></pre></div>



<p><a href="https://bit.ly/soul-discord">Join</a> the discussion in our Discord server and help making Soul together.</p>

<h2 id="license">License</h2>

<p><a href="https://choosealicense.com/licenses/mit/">MIT</a></p>

<h2 id="contributing">Contributing</h2>

<p>Contributions are always welcome!</p>

<p>See <code>CONTRIBUTING.md</code> for ways to get started and please adhere to <code>CODE OF CONDUCT</code>.</p>

<h2 id="contributors-">Contributors ✨</h2>

<p>Thanks goes to these wonderful people (<a href="https://allcontributors.org/docs/en/emoji-key">emoji key</a>):</p>

<!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section -->
<!-- prettier-ignore-start -->
<!-- markdownlint-disable -->
<table>
  <tbody>
    <tr>
      <td><a href="http://linktr.ee/thevahidal"><img src="https://avatars.githubusercontent.com/u/20302825?v=4?s=100" width="100px;" alt="Vahid Al"><br><sub><b>Vahid Al</b></sub></a><br><a href="https://github.com/thevahidal/soul/commits?author=thevahidal" title="Code">💻</a> <a href="https://github.com/thevahidal/soul/pulls?q=is%3Apr+reviewed-by%3Athevahidal" title="Reviewed Pull Requests">👀</a></td>
      <td><a href="https://github.com/AbegaM"><img src="https://avatars.githubusercontent.com/u/70259638?v=4?s=100" width="100px;" alt="Abenezer Melkamu"><br><sub><b>Abenezer Melkamu</b></sub></a><br><a href="https://github.com/thevahidal/soul/commits?author=AbegaM" title="Code">💻</a></td>
      <td><a href="https://github.com/IanMayo"><img src="https://avatars.githubusercontent.com/u/1108513?v=4?s=100" width="100px;" alt="Ian Mayo"><br><sub><b>Ian Mayo</b></sub></a><br><a href="https://github.com/thevahidal/soul/commits?author=IanMayo" title="Code">💻</a> <a href="https://github.com/thevahidal/soul/pulls?q=is%3Apr+reviewed-by%3AIanMayo" title="Reviewed Pull Requests">👀</a></td>
      <td><a href="https://godot.id/"><img src="https://avatars.githubusercontent.com/u/40712686?v=4?s=100" width="100px;" alt="Hanz"><br><sub><b>Hanz</b></sub></a><br><a href="https://github.com/thevahidal/soul/commits?author=HanzCEO" title="Code">💻</a></td>
      <td><a href="https://github.com/KoenDG"><img src="https://avatars.githubusercontent.com/u/1440619?v=4?s=100" width="100px;" alt="Koen De Groote"><br><sub><b>Koen De Groote</b></sub></a><br><a href="https://github.com/thevahidal/soul/commits?author=KoenDG" title="Code">💻</a></td>
      <td><a href="https://github.com/TahaKhanAbdalli"><img src="https://avatars.githubusercontent.com/u/50602678?v=4?s=100" width="100px;" alt="Muhammad Taha Khan"><br><sub><b>Muhammad Taha Khan</b></sub></a><br><a href="https://github.com/thevahidal/soul/commits?author=TahaKhanAbdalli" title="Code">💻</a></td>
    </tr>
  </tbody>
</table>

<!-- markdownlint-restore -->
<!-- prettier-ignore-end -->

<!-- ALL-CONTRIBUTORS-LIST:END -->

<p>This project follows the <a href="https://github.com/all-contributors/all-contributors">all-contributors</a> specification.</p>


      
      
      
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HIV in cell culture can be completely eliminated using CRISPR-Cas gene editing [pdf] (281 pts)]]></title>
            <link>https://www.escmid.org/fileadmin/src/media/PDFs/2News_Discussions/Press_activities/2024/HIVCRISPRV4_1_.pdf</link>
            <guid>39761283</guid>
            <pubDate>Tue, 19 Mar 2024 23:12:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.escmid.org/fileadmin/src/media/PDFs/2News_Discussions/Press_activities/2024/HIVCRISPRV4_1_.pdf">https://www.escmid.org/fileadmin/src/media/PDFs/2News_Discussions/Press_activities/2024/HIVCRISPRV4_1_.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=39761283">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
    </channel>
</rss>