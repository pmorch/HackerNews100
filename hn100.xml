<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 31 Oct 2023 13:00:04 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[German court declares Do Not Track to be legally binding (637 pts)]]></title>
            <link>https://www.vzbv.de/urteile/gericht-untersagt-datenschutzverstoesse-von-linkedin</link>
            <guid>38081633</guid>
            <pubDate>Tue, 31 Oct 2023 08:22:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.vzbv.de/urteile/gericht-untersagt-datenschutzverstoesse-von-linkedin">https://www.vzbv.de/urteile/gericht-untersagt-datenschutzverstoesse-von-linkedin</a>, See on <a href="https://news.ycombinator.com/item?id=38081633">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><strong>Das soziale Netzwerk LinkedIn darf auf seiner Webseite nicht mehr mitteilen, dass es auf „Do-Not-Track“-Signale nicht reagiert, mit denen </strong><strong>Nutzer:innen</strong><strong> der Nachverfolgung („Tracking“) ihres Surfverhaltens per Browsereinstellung widersprechen. Das hat das Landgericht Berlin nach einer Klage des Verbraucherzentrale Bundesverbands (vzbv) entschieden. Das Gericht untersagte dem Unternehmen außerdem eine Voreinstellung, nach der das Profil des Mitglieds auch auf anderen Webseiten und Anwendungen sichtbar ist. Bereits im vergangenen Jahr hatte das Gericht den ungebetenen Versand von E-Mails an Nichtmitglieder untersagt.</strong><strong>&nbsp;</strong></p>

<p>„Wenn Verbraucher:innen die ,Do-Not-Track‘-Funktion ihres Browsers aktivieren, ist das eine klare Botschaft: Sie wollen nicht, dass ihr Surfverhalten für Werbe- und andere Zwecke ausgespäht wird“, sagt Rosemarie Rodden, Rechtsreferenin beim vzbv. „Webseitenbetreiber müssen dieses Signal respektieren.“</p>

<p>Widerspruch gegen Tracking ignoriert&nbsp;</p>

<p>Internetsurfer:innen können über ihren Browser einstellen, dass die besuchten Webseiten ein „Do-Not-Track“ (DNT)-Signal erhalten. Es übermittelt ihren Wunsch, dass die Online-Aktivitäten nicht nachverfolgt und ausgewertet werden. LinkedIn hatte auf seiner Internetseite mitgeteilt, dass es auf solche DNT-Signale nicht reagiert. Somit können auch gegen den Willen der Nutzer:innen personenbezogene Daten wie die IP-Adresse und Informationen über die Nutzung der Webseite etwa für Analyse- und Marketingzwecke ausgewertet werden, auch von Drittanbietern.&nbsp;&nbsp;</p>

<p>Das Landgericht Berlin schloss sich der Auffassung des vzbv an, dass die Mitteilung des Unternehmens irreführend war. Sie suggeriere, dass die Benutzung des DNT-Signals rechtlich irrelevant sei und die Beklagte ein solches Signal nicht zu beachten brauche. Das treffe nicht zu. Das Widerspruchsrecht gegen die Verarbeitung persönlicher Daten könne nach der Datenschutzgrundverordnung auch per automatisierten Verfahren ausgeübt werden. Ein DNT-Signal stelle einen wirksamen Widerspruch dar.&nbsp;</p>

<p>Einen weiteren Antrag in diesem Zusammenhang lehnte das Gericht aus prozessualen Gründen ab.&nbsp;</p>

<p>Profil ohne erforderliche Einwilligung veröffentlicht&nbsp;</p>

<p>In allen weiteren Punkten war die vzbv-Klage ohne Einschränkung erfolgreich. Das Gericht untersagte LinkedIn, bei der erstmaligen Anmeldung die Funktion „Sichtbarkeit des Profils“ zu aktivieren. Durch diese Voreinstellung war das persönliche LinkedIn-Profil ohne Zustimmung auch für Nicht-Mitglieder sowie außerhalb des Netzwerkes – etwa auf Suchmaschinen – öffentlich sichtbar. Die Richter:innen stellten klar, dass ein von vornherein aktivierter Schalter nicht die Anforderungen an eine wirksame Einwilligung in die Veröffentlichung personenbezogener Daten erfüllt. „Nutzerprofile dürfen nicht automatisch öffentlich einsehbar sein, wenn sie angelegt werden“, so Rosemarie Rodden.</p>

<p>Ungebetener E-Mail-Versand verboten&nbsp;</p>

<p>Einem Teil der Klage hatte das LG Berlin bereits im vergangenen Jahr stattgegeben. So ist es LinkedIn inzwischen verboten, E-Mail-Einladungen an Verbraucher:innen zu versenden, die nicht Mitglied des Netzwerks sind und die der Verwendung ihrer E-Mail-Adresse nicht zugestimmt haben. Außerdem untersagte das Gericht in einem weiteren Teil-Anerkenntnisurteil die Verwendung mehrerer Bestimmungen in den Geschäftsbedingungen des Unternehmens, darunter Klauseln, nach denen nur die englische Vertragsfassung verbindlich sein soll und ein Rechtsstreit nur im irischen Dublin ausgetragen werden darf.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[$95 AMD CPU Becomes 16GB GPU to Run AI Software (129 pts)]]></title>
            <link>https://www.tomshardware.com/news/dollar95-amd-cpu-becomes-16gb-gpu-to-run-ai-software</link>
            <guid>38080233</guid>
            <pubDate>Tue, 31 Oct 2023 04:19:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tomshardware.com/news/dollar95-amd-cpu-becomes-16gb-gpu-to-run-ai-software">https://www.tomshardware.com/news/dollar95-amd-cpu-becomes-16gb-gpu-to-run-ai-software</a>, See on <a href="https://news.ycombinator.com/item?id=38080233">Hacker News</a></p>
<div id="readability-page-1" class="page"><article aria-label="article" data-id="3g3qGx7rGpBfYQ9mWcwfqC">
<header>
<nav aria-label="Breadcrumbs">
<ol>
<li>
<a href="https://www.tomshardware.com/news" aria-label="Return to News" data-before-rewrite-localise="https://www.tomshardware.com/news">News</a>
</li>
</ol>
</nav>


</header>
<section>
<div itemprop="image" itemscope="" itemtype="https://schema.org/ImageObject">
<div>
<picture><source type="image/webp" alt="Ryzen CPU" onerror="if(this.src &amp;&amp; this.src.indexOf('missing-image.svg') !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" srcset="https://cdn.mos.cms.futurecdn.net/ctNMqLHz2U3dj65TY2Uj6H-320-80.jpg.webp 320w, https://cdn.mos.cms.futurecdn.net/ctNMqLHz2U3dj65TY2Uj6H-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/ctNMqLHz2U3dj65TY2Uj6H-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/ctNMqLHz2U3dj65TY2Uj6H-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/ctNMqLHz2U3dj65TY2Uj6H-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/ctNMqLHz2U3dj65TY2Uj6H-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/ctNMqLHz2U3dj65TY2Uj6H-1920-80.jpg.webp 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/ctNMqLHz2U3dj65TY2Uj6H.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/ctNMqLHz2U3dj65TY2Uj6H.jpg"><source type="image/jpeg" alt="Ryzen CPU" onerror="if(this.src &amp;&amp; this.src.indexOf('missing-image.svg') !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" srcset="https://cdn.mos.cms.futurecdn.net/ctNMqLHz2U3dj65TY2Uj6H-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/ctNMqLHz2U3dj65TY2Uj6H-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/ctNMqLHz2U3dj65TY2Uj6H-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/ctNMqLHz2U3dj65TY2Uj6H-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/ctNMqLHz2U3dj65TY2Uj6H-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/ctNMqLHz2U3dj65TY2Uj6H-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/ctNMqLHz2U3dj65TY2Uj6H-1920-80.jpg 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/ctNMqLHz2U3dj65TY2Uj6H.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/ctNMqLHz2U3dj65TY2Uj6H.jpg"><img src="https://cdn.mos.cms.futurecdn.net/ctNMqLHz2U3dj65TY2Uj6H-320-80.jpg" alt="Ryzen CPU" onerror="if(this.src &amp;&amp; this.src.indexOf('missing-image.svg') !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" srcset="https://cdn.mos.cms.futurecdn.net/ctNMqLHz2U3dj65TY2Uj6H-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/ctNMqLHz2U3dj65TY2Uj6H-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/ctNMqLHz2U3dj65TY2Uj6H-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/ctNMqLHz2U3dj65TY2Uj6H-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/ctNMqLHz2U3dj65TY2Uj6H-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/ctNMqLHz2U3dj65TY2Uj6H-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/ctNMqLHz2U3dj65TY2Uj6H-1920-80.jpg 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/ctNMqLHz2U3dj65TY2Uj6H.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/ctNMqLHz2U3dj65TY2Uj6H.jpg"></picture>
</div>
<meta itemprop="url" content="https://cdn.mos.cms.futurecdn.net/ctNMqLHz2U3dj65TY2Uj6H.jpg">
<meta itemprop="height" content="600">
<meta itemprop="width" content="338">
<figcaption itemprop="caption description">
<span>Ryzen CPU</span>
<span itemprop="copyrightHolder">(Image credit: AMD)</span>
</figcaption>
</div>

<div id="article-body">
<p>The newer <a href="https://www.tomshardware.com/reviews/amd-ryzen-5-5600g-review" data-before-rewrite-localise="https://www.tomshardware.com/reviews/amd-ryzen-5-5600g-review">Ryzen 5 5600G</a> (Cezanne) has replaced the <a href="https://www.tomshardware.com/news/amd-ryzen-7-5800x3d-5700X-Ryzen-5-5600-5500-4600G-4500-4100" data-before-rewrite-localise="https://www.tomshardware.com/news/amd-ryzen-7-5800x3d-5700X-Ryzen-5-5600-5500-4600G-4500-4100">Ryzen 5 4600G</a> (Renoir) as one of the <a href="https://www.tomshardware.com/reviews/best-cpus,3986.html" data-before-rewrite-localise="https://www.tomshardware.com/reviews/best-cpus,3986.html">best CPUs</a> for gaming. However, a trick has breathed new life into the Ryzen 5 4600G, transforming the budget Zen 2 APU into a 16GB graphics card to run AI applications on Linux.</p><p>Not everyone has to budget to buy or rent a <a href="https://www.tomshardware.com/news/nvidia-hopper-h100-gpu-revealed-gtc-2022" data-before-rewrite-localise="https://www.tomshardware.com/news/nvidia-hopper-h100-gpu-revealed-gtc-2022">Nvidia H100</a> (Hopper) to experiment with AI. With the current demand for AI-focused graphics cards, you may be unable to access one even if you have the money. Luckily, you don't need an expensive <a href="https://www.tomshardware.com/news/nvidia-makes-1000-profit-on-h100-gpus-report" data-before-rewrite-localise="https://www.tomshardware.com/news/nvidia-makes-1000-profit-on-h100-gpus-report">H100</a>, an <a href="https://www.tomshardware.com/news/nvidia-ampere-A100-gpu-7nm" data-before-rewrite-localise="https://www.tomshardware.com/news/nvidia-ampere-A100-gpu-7nm">A100</a> (Ampere), or one of the <a href="https://www.tomshardware.com/reviews/best-gpus,4380.html" data-before-rewrite-localise="https://www.tomshardware.com/reviews/best-gpus,4380.html">best graphics cards</a> for AI. One <a href="https://old.reddit.com/r/Amd/comments/15t0lsm/i_turned_a_95_amd_apu_into_a_16gb_vram_gpu_and_it/" target="_blank" data-url="https://old.reddit.com/r/Amd/comments/15t0lsm/i_turned_a_95_amd_apu_into_a_16gb_vram_gpu_and_it/">Redditor</a> demonstrated how a Ryzen 5 4600G retailing for <a href="https://click.linksynergy.com/deeplink?id=kXQk6%2AivFEQ&amp;mid=44583&amp;u1=tomshardware-us-1219916483187876400&amp;murl=https%3A%2F%2Fwww.newegg.com%2Famd-ryzen-5-4600g-ryzen-5-4000-g-series%2Fp%2FN82E16819113744" target="_blank" data-url="https://www.newegg.com/amd-ryzen-5-4600g-ryzen-5-4000-g-series/p/N82E16819113744" data-hl-processed="hawklinks" data-placeholder-url="https://click.linksynergy.com/deeplink?id=kXQk6%2AivFEQ&amp;mid=44583&amp;u1=hawk-custom-tracking&amp;murl=https%3A%2F%2Fwww.newegg.com%2Famd-ryzen-5-4600g-ryzen-5-4000-g-series%2Fp%2FN82E16819113744" rel="sponsored noopener" referrerpolicy="no-referrer-when-downgrade" data-google-interstitial="false" data-merchant-name="newegg.com" data-merchant-id="107327" data-merchant-url="newegg.com" data-merchant-network="LS">$95</a> can tackle different AI workloads.</p><p>The Ryzen 5 4600G, which came out in 2020, is a hexa-core, 12-thread APU with Zen 2 cores that operate with a base and boost clock of 3.7 GHz and 4.2 GHz. The 65W chip also wields a Radeon Vega iGPU with seven compute units clocked up to 1.9 GHz. Remember that APUs don't have dedicated memory but share system memory. You can determine the amount of memory inside the motherboard’s BIOS. In this case, the Redditor had 32GB of DDR4 and allocated 16GB to the Ryzen 5 4600G. Typically, 16GB is the maximum amount of memory you can dedicate to the iGPU. However, some user reports claim that certain ASRock AMD motherboards allow for higher memory allocation, rumored up to 64GB.</p><p>The trick converts the Ryzen 5 4600G into a 16GB "graphics card," flaunting more memory than some of Nvidia's latest <a href="https://www.tomshardware.com/features/nvidia-ada-lovelace-and-geforce-rtx-40-series-everything-we-know" data-before-rewrite-localise="https://www.tomshardware.com/features/nvidia-ada-lovelace-and-geforce-rtx-40-series-everything-we-know">GeForce RTX 40-series</a> SKUs, such as the <a href="https://www.tomshardware.com/reviews/nvidia-geforce-rtx-4070-review" data-before-rewrite-localise="https://www.tomshardware.com/reviews/nvidia-geforce-rtx-4070-review">GeForce RTX 4070</a> or <a href="https://www.tomshardware.com/reviews/nvidia-geforce-rtx-4070-ti-review-a-costly-70-class-gpu" data-before-rewrite-localise="https://www.tomshardware.com/reviews/nvidia-geforce-rtx-4070-ti-review-a-costly-70-class-gpu">GeForce RTX 4070 Ti</a>, which are limited to 12GB. Logically, the APU doesn't deliver the same performance as a high-end graphics card, but at least it won't run out of memory during AI workloads, as 16GB is plenty for non-serious tasks.</p><p>AMD's <a href="https://www.tomshardware.com/news/amd-to-expand-rocm-support-to-pro-and-consumer-rdna-3-gpus-this-fall" data-before-rewrite-localise="https://www.tomshardware.com/news/amd-to-expand-rocm-support-to-pro-and-consumer-rdna-3-gpus-this-fall">Radeon Open Compute platform</a> (ROCm) doesn't officially support Ryzen APUs. Third-party companies, such as BruhnBruhn Holding, offer experimental packages of ROCm that'll work with APUs. That means APUs can work with PyTorch and TensorFlow frameworks, opening the gate to most AI software. We wonder if AMD's latest mobile Ryzen chips, like Phoenix that taps into DDR5 memory, can work and what kind of performance they bring.</p><p>The Redditor shared a <a href="https://www.youtube.com/watch?v=HPO7fu7Vyw4" target="_blank" data-url="https://www.youtube.com/watch?v=HPO7fu7Vyw4">YouTube video</a> claiming that the Ryzen 5 4600G could run a plethora of AI applications, including Stable Diffusion, FastChat, MiniGPT-4, Alpaca-LoRA, Whisper, LLM, and LLaMA. Unfortunately, he only provided demos for Stable Diffusion, an AI image generator based on text input. He doesn't detail how he got the Ryzen 5 4600G to work with the AI software on his Linux system. The YouTuber has vouched to release a thorough video of the setup process.&nbsp;</p><p>As for the performance, the Ryzen 5 4600G only took around one minute and 50 seconds to generate a 512 x 512-pixel image with the default setting of 50 steps. It's an excellent result for a $95 APU and rivals some high-end processors. The author said he used DDR4 memory but didn't list the specifications. Although the Ryzen 5 4600G natively supports DDR4-3200, many samples can hit DDR4-4000, so it would be fascinating to see AI performance scaling with faster memory.</p><p>The experiment is fantastic for those who own a Ryzen 5 4600G or Ryzen 5 5600G and want to play around with AI. For those who don't, throwing $500 into an APU build doesn't make much sense when you can probably get a discrete graphics card that offers better performance. For instance, AMD's <a href="https://www.tomshardware.com/news/amd-brags-about-cheaper-16gb-gpus" data-before-rewrite-localise="https://www.tomshardware.com/news/amd-brags-about-cheaper-16gb-gpus">Radeon 16GB graphics cards</a> start at $499, and Nvidia recently launched the <a href="https://www.tomshardware.com/reviews/nvidia-geforce-rtx-4060-ti-16gb-review" data-before-rewrite-localise="https://www.tomshardware.com/reviews/nvidia-geforce-rtx-4060-ti-16gb-review">GeForce RTX 4060 Ti 16GB</a>, which has a similar starting price.</p>
</div>
<div data-hydrate="true" id="slice-container-newsletterForm-articleInbodyContent"><section><p>Join the experts who read Tom's Hardware for the inside track on enthusiast PC tech news — and have for over 25 years. We'll send breaking news and in-depth reviews of CPUs, GPUs, AI, maker hardware and more straight to your inbox.</p></section></div>
<div id="slice-container-authorBio"><p>Zhiye Liu is a Freelance News Writer at Tom’s Hardware US. Although he loves everything that’s hardware, he has a soft spot for CPUs, GPUs, and RAM.</p></div>



<!-- Drop in a standard article here maybe? -->


</section>




<div id="slice-container-relatedArticles"><p><h5>Most Popular</h5></p></div>

</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Can you use your "free will"? Try your hand (193 pts)]]></title>
            <link>https://people.ischool.berkeley.edu/~nick/aaronson-oracle/</link>
            <guid>38079512</guid>
            <pubDate>Tue, 31 Oct 2023 02:36:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://people.ischool.berkeley.edu/~nick/aaronson-oracle/">https://people.ischool.berkeley.edu/~nick/aaronson-oracle/</a>, See on <a href="https://news.ycombinator.com/item?id=38079512">Hacker News</a></p>
<div id="readability-page-1" class="page">
  
  Press the 'f' and 'd' keys randomly. As randomly as you can. I'll try to predict which key you'll press next.
  <p>Keep pressing!</p>
  A rolling mean of my accuracy in predicting what key you'll press. (I'll start predicting once I get a few keypresses from you).

  <p>
  My last guesses (most recent at top):
  </p>

<p>
What's going on here? This is an <a href="https://github.com/elsehow/aaronson-oracle">Aaronson Oracle</a>.
</p>


</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Xbox will block third-party controllers to "preserve the console experience" (163 pts)]]></title>
            <link>https://www.nme.com/news/gaming-news/xbox-will-block-third-party-controllers-to-preserve-the-console-experience-3525752</link>
            <guid>38078143</guid>
            <pubDate>Tue, 31 Oct 2023 00:35:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nme.com/news/gaming-news/xbox-will-block-third-party-controllers-to-preserve-the-console-experience-3525752">https://www.nme.com/news/gaming-news/xbox-will-block-third-party-controllers-to-preserve-the-console-experience-3525752</a>, See on <a href="https://news.ycombinator.com/item?id=38078143">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-td-block-uid="tdi_95"><p><a href="https://www.nme.com/brands/microsoft">Microsoft</a> will not allow players to use unauthorised third-party controllers and accessories for their <a href="https://www.nme.com/tag/xbox">Xbox</a> from November in the interest of “performance, security, and safety”.</p>
<ul>
<li><strong>READ MORE: <a href="https://www.nme.com/features/gaming-features/the-mountain-goats-john-darnielle-talks-magic-the-gathering-secret-lair-set-3483851">The Mountain Goats’ John Darnielle talks writing a prophecy for ‘Magic: The Gathering’</a></strong></li>
</ul>
<p><a href="https://www.windowscentral.com/gaming/xbox/xboxs-new-policy-say-goodbye-to-unofficial-accessories-after-november" target="_blank" rel="noopener"><em>Windows Central</em> </a>reported that players have been encountering error “0x82d60002” when they attach a third-party accessory in an article from October 29.</p>
<p>“Using unauthorised accessories compromises your gaming experience. For this reason, the unauthorised accessory will be blocked from use on 11/12/2023,” read the pop-up on the console. It then advised the player to return the product to the store or talk to the manufacturer.</p>
<figure id="attachment_3525788" aria-describedby="caption-attachment-3525788"><img decoding="async" fetchpriority="high" src="https://www.nme.com/wp-content/uploads/2023/10/unauthorised-xbox-controllers-not-going-to-work-after-november-2.jpg" alt="" width="2000" height="1270" srcset="https://www.nme.com/wp-content/uploads/2023/10/unauthorised-xbox-controllers-not-going-to-work-after-november-2.jpg 2000w, https://www.nme.com/wp-content/uploads/2023/10/unauthorised-xbox-controllers-not-going-to-work-after-november-2-400x254.jpg 400w, https://www.nme.com/wp-content/uploads/2023/10/unauthorised-xbox-controllers-not-going-to-work-after-november-2-800x508.jpg 800w, https://www.nme.com/wp-content/uploads/2023/10/unauthorised-xbox-controllers-not-going-to-work-after-november-2-696x442.jpg 696w, https://www.nme.com/wp-content/uploads/2023/10/unauthorised-xbox-controllers-not-going-to-work-after-november-2-1392x884.jpg 1392w, https://www.nme.com/wp-content/uploads/2023/10/unauthorised-xbox-controllers-not-going-to-work-after-november-2-1068x678.jpg 1068w" sizes="(max-width: 2000px) 100vw, 2000px"><figcaption id="caption-attachment-3525788">An Xbox controller Credit: Jose Gil via Unsplash</figcaption></figure>
<p>In a statement supplied to<a href="https://www.gamesindustry.biz/xbox-will-block-unauthorized-third-party-controllers" target="_blank" rel="noopener"><em> GamesIndustry.biz</em></a>, Microsoft explained that the error is in fact part of its new policy which will be rolled out worldwide from November 17.</p>
<p>“Microsoft and other licensed Xbox hardware partners’ accessories are designed and manufactured with quality standards for performance, security, and safety,” it said.</p>
<p>“Unauthorised accessories can compromise the gaming experience on Xbox consoles (<a href="https://www.nme.com/tag/xbox-one">Xbox One</a>, <a href="https://www.nme.com/tag/xbox-series-xs">Xbox Series X/S</a>.) Gamers may receive a pop-up warning that their accessory is unauthorised.</p>
<p>“Eventually, the unauthorised accessory will be blocked from use to preserve the console gaming experience. For a full list of accessories that are supported on Xbox consoles, please visit www.xbox.com/accessories.”</p>
<p>Sources who spoke to<em> Windows Central</em> suggested that through this Microsoft is attempting to make the manufacture of official third-party controllers easier.</p>
<figure id="attachment_3525791" aria-describedby="caption-attachment-3525791"><img decoding="async" src="https://www.nme.com/wp-content/uploads/2023/10/unauthorised-xbox-controllers-not-going-to-work-after-november-3.jpg" alt="" width="2000" height="1270" srcset="https://www.nme.com/wp-content/uploads/2023/10/unauthorised-xbox-controllers-not-going-to-work-after-november-3.jpg 2000w, https://www.nme.com/wp-content/uploads/2023/10/unauthorised-xbox-controllers-not-going-to-work-after-november-3-400x254.jpg 400w, https://www.nme.com/wp-content/uploads/2023/10/unauthorised-xbox-controllers-not-going-to-work-after-november-3-800x508.jpg 800w, https://www.nme.com/wp-content/uploads/2023/10/unauthorised-xbox-controllers-not-going-to-work-after-november-3-696x442.jpg 696w, https://www.nme.com/wp-content/uploads/2023/10/unauthorised-xbox-controllers-not-going-to-work-after-november-3-1392x884.jpg 1392w, https://www.nme.com/wp-content/uploads/2023/10/unauthorised-xbox-controllers-not-going-to-work-after-november-3-1068x678.jpg 1068w" sizes="(max-width: 2000px) 100vw, 2000px"><figcaption id="caption-attachment-3525791">An Xbox controller Credit: Kamil S via Unsplash</figcaption></figure>
<p>This way, new controllers will be allowed to use wireless features that work with the Xbox, potentially by putting a security chip inside them. However, it will spell the end of those that already exist if they were not approved by Microsoft.</p>
<p>In other gaming news, <a href="https://www.nme.com/games/the-finals"><em>The Finals</em> </a>has been criticised for <a href="https://www.nme.com/news/gaming-news/the-finals-sloppy-ai-voice-acting-criticised-by-voice-actors-3525621">the use of AI to voice its commentators and contestants</a>, though the developer explained that this “gets [the team] far enough in terms of quality”.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apple unveils the new MacBook Pro featuring the M3 family of chips (107 pts)]]></title>
            <link>https://www.apple.com/newsroom/2023/10/apple-unveils-new-macbook-pro-featuring-m3-chips/</link>
            <guid>38078065</guid>
            <pubDate>Tue, 31 Oct 2023 00:30:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.apple.com/newsroom/2023/10/apple-unveils-new-macbook-pro-featuring-m3-chips/">https://www.apple.com/newsroom/2023/10/apple-unveils-new-macbook-pro-featuring-m3-chips/</a>, See on <a href="https://news.ycombinator.com/item?id=38078065">Hacker News</a></p>
<div id="readability-page-1" class="page">


	
    







 
<nav id="ac-localnav" lang="en-US" role="navigation" aria-label="Newsroom" data-analytics-region="local nav" data-sticky="">
	
    
    
        




    
    

</nav>



<main id="main" role="main"> 



<span id="opens-in-new-window">opens in new window</span>

	

<section>
<article data-analytics-activitymap-region-id="article">






    
    
    











    <div>
        

        <div>
                    
                    
                        <span>PRESS RELEASE</span>
                    
                    
                        <span>October 30, 2023</span>
                    
                    
                </div>

        <div>
                
                
                
                    <h2>
                        
    
        Apple unveils the new MacBook&nbsp;Pro featuring the M3 family of chips, making the world’s best pro laptop even&nbsp;better
    

                    </h2>
                
            </div>

        <div>
                
                
                    14-inch MacBook Pro with M3 now starts at $1,599
<p>
14- and 16-inch models with M3 Pro and M3 Max are available in a gorgeous new space black finish
                
            </p></div>

        
            
    
    
    
    
    

        

    </div>







    
    
    




    
        
        
        
        
            <figure aria-label="Media, Two MacBook Pro devices are shown against a black background, with one facing forward and one facing backward.">
                <div>
                     
                        
                        <div>
                            Today Apple unveiled MacBook Pro featuring the next generation of M3 chips.
                        </div>
                    
                    
                    
                    
                    <a href="https://www.apple.com/newsroom/images/2023/10/apple-unveils-new-macbook-pro-featuring-m3-chips/article/Apple-MacBook-Pro-2up-231030.zip" download="" data-analytics-title="Download image" aria-label="Download media, Two MacBook Pro devices are shown against a black background, with one facing forward and one facing backward."></a>
                </div>
            </figure>
        
        
    








    
    
    


     
     
    
    
        <div>
             
                 <div><span>CUPERTINO, CALIFORNIA</span> Apple today announced a new <a href="https://www.apple.com/macbook-pro/" target="_blank">MacBook Pro lineup</a> featuring the all-new family of M3 chips: M3, M3 Pro, and M3 Max. With a next-generation GPU architecture and a faster CPU, the M3 family brings even more performance and remarkable new capabilities to MacBook Pro. The new 14‑inch MacBook Pro with M3 is not only great for everyday tasks, but also delivers phenomenal sustained performance in pro apps and games. Perfect for aspiring creatives, students, and entrepreneurs, it now starts at $1,599. The 14- and 16‑inch MacBook Pro with M3 Pro provides even greater performance and additional unified memory support, enabling more demanding workflows for users like coders, creatives, and researchers. The 14- and 16‑inch MacBook Pro with M3 Max delivers performance and capabilities that push the limits of computing. With a monster GPU and a powerful CPU, along with support for up to 128GB of unified memory, MacBook Pro with M3 Max enables extreme workflows and multitasking across pro apps for users like machine learning programmers, 3D artists, and video editors. M3 Pro and M3 Max models also now come in space black, a gorgeous dark aluminum finish.
</div>
                 
             
                 <div>All MacBook Pro models feature a brilliant Liquid Retina XDR display with 20 percent brighter SDR content, a built-in 1080p camera, an immersive six-speaker sound system, and a wide array of connectivity options. With up to 22 hours of battery life,<sup>1</sup> the lineup offers the ultimate in pro portability, delivering the same performance whether plugged in or on battery, so users can take their workflows anywhere. Customers can order the new MacBook Pro starting today, with availability beginning November 7.
</div>
                 
             
                 <div>“There is nothing quite like MacBook Pro. With the remarkable power-efficient performance of Apple silicon, up to 22 hours of battery life, a stunning Liquid Retina XDR display, and advanced connectivity, MacBook Pro empowers users to do their life’s best work,” said John Ternus, Apple’s senior vice president of Hardware Engineering. “With the next generation of M3 chips, we’re raising the bar yet again for what a pro laptop can do. We’re excited to bring MacBook Pro and its best-in-class capabilities to the broadest set of users yet, and for those upgrading from an Intel-based MacBook Pro, it’s a game-changing experience in every way.”
</div>
                 
             
         </div>
 

    
    
    






  
    
    
    
    
      <figure aria-label="Media, A person wearing headphones uses the new MacBook Pro while looking out a window into a harbor.">
        <div>
             
              
              <div>
                The new MacBook Pro lineup delivers incredible performance, a brilliant Liquid Retina XDR display, a wide array of connectivity, and up to 22 hours of battery life for the ultimate in pro portability.
              </div>
            
            
            
            
            <a href="https://www.apple.com/newsroom/images/2023/10/apple-unveils-new-macbook-pro-featuring-m3-chips/article/Apple-MacBook-Pro-lifestyle-231030.zip" download="" data-analytics-title="Download image" aria-label="Download media, A person wearing headphones uses the new MacBook Pro while looking out a window into a harbor."></a>
          </div>
      </figure>
    
  






    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>The M3 Family Arrives</strong>
</h2>
                 
             
                 <div>The M3 family of chips continues Apple silicon’s tremendous pace of innovation. M3, M3 Pro, and M3 Max are the first chips for a personal computer built using the industry-leading 3-nanometer technology. With a faster, more efficient next-generation GPU, these chips deliver the biggest leap forward in graphics architecture ever for Apple silicon. Featuring a breakthrough technology called Dynamic Caching, the GPU allocates the use of local memory in hardware in real time so only the exact amount of memory needed is used for each task. This dramatically increases GPU utilization and performance for the most demanding pro apps and games.
</div>
                 
             
                 <div>The GPU also brings new rendering features to Apple silicon, including hardware-accelerated mesh shading for greater capability and efficiency with geometry processing, enabling more visually complex scenes. And hardware-accelerated ray tracing comes to the Mac for the first time, enabling games to render more accurate shadows and reflections to create more realistic environments.
</div>
                 
             
         </div>
 

    
    
    






  
    
    
    
    
      <figure aria-label="Media, A graphic with three squares representing M3, M3 Pro, and M3 Max chips.">
        <div>
             
              
              <div>
                With the power-efficient performance of M3, M3 Pro, and M3 Max, there is a MacBook Pro for everyone.
              </div>
            
            
            
            
            <a href="https://www.apple.com/newsroom/images/2023/10/apple-unveils-new-macbook-pro-featuring-m3-chips/article/Apple-MacBook-Pro-M3-chip-series-3up-231030.zip" download="" data-analytics-title="Download image" aria-label="Download media, A graphic with three squares representing M3, M3 Pro, and M3 Max chips."></a>
          </div>
      </figure>
    
  






    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>14-inch MacBook Pro with M3</strong>
</h2>
                 
             
                 <div>For users pursuing their passions — from students and business owners to aspiring musicians and video editors — MacBook Pro with M3 is the ideal laptop. The 14‑inch MacBook Pro with M3 is up to 60 percent faster than the 13‑inch MacBook Pro with M1, and with its advanced thermal system, it unleashes the full potential of M3 for sustained performance.<sup>2</sup> Starting at $1,599, it delivers more performance and capabilities than ever at a great value.
</div>
                 
             
                 <div><strong>With MacBook Pro with M3:</strong>
</div>
                 
             
                 <div><ul>
<li>Render performance in Final Cut Pro is up to 7.4x faster than the 13-inch MacBook Pro with Core i7,<sup>3</sup> and up to 60 percent faster than the 13‑inch MacBook Pro with M1.<sup>2</sup></li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Code compilation in Xcode is up to 3.7x faster than the 13-inch MacBook Pro with Core i7,<sup>3</sup> and up to 40 percent faster than the 13‑inch MacBook Pro with M1.<sup>2</sup></li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Spreadsheet performance in Microsoft Excel is up to 3.5x faster than the 13‑inch MacBook Pro with Core i7,<sup>3</sup> and up to 40 percent faster than the 13‑inch MacBook Pro with M1.<sup>2</sup></li>
</ul>
</div>
                 
             
         </div>
 

    
    
    






  
    
    
    
    
      <figure aria-label="Media, The new MacBook Pro with M3 with an Xcode workflow.">
        <div>
             
              
              <div>
                MacBook Pro with M3 enables users to compile and test millions of lines of code in Xcode with even greater speed.
              </div>
            
            
            
            
            <a href="https://www.apple.com/newsroom/images/2023/10/apple-unveils-new-macbook-pro-featuring-m3-chips/article/Apple-MacBook-Pro-M3-Xcode-231030.zip" download="" data-analytics-title="Download image" aria-label="Download media, The new MacBook Pro with M3 with an Xcode workflow."></a>
          </div>
      </figure>
    
  






    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>14- and 16-inch MacBook Pro with M3 Pro</strong>
</h2>
                 
             
                 <div>For users with more demanding workflows like coders, creatives, and researchers, MacBook Pro with M3 Pro provides even greater performance, supports more unified memory, and is now up to 40 percent faster than the 16‑inch model with M1 Pro.<sup>4</sup>
</div>
                 
             
                 <div><strong>With MacBook Pro with M3 Pro:</strong>
</div>
                 
             
                 <div><ul>
<li>Filter and function performance in Adobe Photoshop is up to 3x faster than the fastest Intel-based MacBook Pro,<sup>5</sup> and up to 40 percent faster than the 16‑inch MacBook Pro with M1 Pro.<sup>4</sup></li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Basecalling for DNA sequencing in Oxford Nanopore MinKNOW is up to 20x faster than the fastest Intel-based MacBook Pro,<sup>5</sup> and up to 36 percent faster than the 16‑inch MacBook Pro with M1 Pro.<sup>4</sup></li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Text-based editing in Adobe Premiere Pro is up to 1.7x faster than the 16-inch Intel-based MacBook Pro,<sup>5</sup> and up to 30 percent faster than the 16‑inch MacBook Pro with M1 Pro.<sup>4</sup></li>
</ul>
</div>
                 
             
         </div>
 

    
    
    






  
    
    
    
    
      <figure aria-label="Media, The new MacBook Pro with M3 Pro with an Adobe Photoshop workflow.">
        <div>
             
              
              <div>
                MacBook Pro with M3 Pro delivers faster filter and function performance in Adobe Photoshop.
              </div>
            
            
            
            
            <a href="https://www.apple.com/newsroom/images/2023/10/apple-unveils-new-macbook-pro-featuring-m3-chips/article/Apple-MacBook-Pro-M3-Pro-Photoshop-231030.zip" download="" data-analytics-title="Download image" aria-label="Download media, The new MacBook Pro with M3 Pro with an Adobe Photoshop workflow."></a>
          </div>
      </figure>
    
  






    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>14-inch and 16-inch MacBook Pro with M3 Max</strong>
</h2>
                 
             
                 <div>MacBook Pro with M3 Max provides performance and capabilities for those with extreme workflows like machine learning programmers, 3D artists, and video editors. It is up to 2.5x faster than the 16-inch MacBook Pro with M1 Max,<sup>6</sup> and up to 11x faster than the fastest Intel-based MacBook Pro model.<sup>5</sup> It also supports up to 128GB of unified memory, enabling creators to easily work on large and complex projects spanning multiple pro apps and plugins, or compose huge film scores where entire orchestral libraries are instantly available from memory.
</div>
                 
             
                 <div><strong>With MacBook Pro with M3 Max:</strong>
</div>
                 
             
                 <div><ul>
<li>Simulation of dynamical systems in MathWorks MATLAB is up to 5.5x faster than the fastest Intel-based MacBook Pro,<sup>5</sup> and up to 2x faster than the 16‑inch MacBook Pro with M1 Max.<sup>6</sup></li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Render performance in Maxon Redshift is up to 5.3x faster than the fastest Intel-based MacBook Pro,<sup>5</sup> and up to 2.5x faster than the 16‑inch MacBook Pro with M1 Max.<sup>6</sup></li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Noise reduction in Blackmagic DaVinci Resolve Studio is up to 2.7x faster than the fastest Intel-based MacBook Pro,<sup>5</sup> and up to 65 percent faster than the 16‑inch MacBook Pro with M1 Max.<sup>6</sup></li>
</ul>
</div>
                 
             
         </div>
 

    
    
    


    
    
        
        
        
            <div role="group" aria-label="gallery" data-component-list="MixinGallery" id="macbook-pro-with-m3-max">
            <nav role="presentation">
                <ul role="tablist">
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-3b8080c99634aa97fa40ab6c654b4508" href="#gallery-3b8080c99634aa97fa40ab6c654b4508" data-ac-gallery-trigger="gallery-3b8080c99634aa97fa40ab6c654b4508"><span>The new MacBook Pro with M3 Max with a MathWorks MATLAB workflow.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-e1b4390198f23af0b691ae74c2e46dd5" href="#gallery-e1b4390198f23af0b691ae74c2e46dd5" data-ac-gallery-trigger="gallery-e1b4390198f23af0b691ae74c2e46dd5"><span>The new MacBook Pro with M3 Max with a Maxon Redshift workflow.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-7f637b110defd0f856598f87ce4fabc3" href="#gallery-7f637b110defd0f856598f87ce4fabc3" data-ac-gallery-trigger="gallery-7f637b110defd0f856598f87ce4fabc3"><span>The new MacBook Pro with M3 Max with a Blackmagic DaVinci Resolve Studio workflow.</span></a>
                        </li>
                    
                </ul>
            </nav>
            <div>
                
                    
                        
                        <div id="gallery-3b8080c99634aa97fa40ab6c654b4508" aria-labelledby="gallery-dotnav-3b8080c99634aa97fa40ab6c654b4508" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:matlab">
                                
                                <div>
                                    <div>MacBook Pro with M3 Max makes working on large and complex data models in MathWorks MATLAB even more fluid.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2023/10/apple-unveils-new-macbook-pro-featuring-m3-chips/article/Apple-MacBook-Pro-M3-Max-MATLAB-231030.zip" download="" data-analytics-title="Download image" aria-label="Download media, The new MacBook Pro with M3 Max with a MathWorks MATLAB workflow."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-e1b4390198f23af0b691ae74c2e46dd5" aria-labelledby="gallery-dotnav-e1b4390198f23af0b691ae74c2e46dd5" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:maxon-redshift">
                                
                                <div>
                                    <div>MacBook Pro with M3 Max enables users to model and iterate remarkably complex 3D content in Cinema 4D with Maxon Redshift.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2023/10/apple-unveils-new-macbook-pro-featuring-m3-chips/article/Apple-MacBook-Pro-M3-Max-Cinema-4D-231030.zip" download="" data-analytics-title="Download image" aria-label="Download media, The new MacBook Pro with M3 Max with a Maxon Redshift workflow."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-7f637b110defd0f856598f87ce4fabc3" aria-labelledby="gallery-dotnav-7f637b110defd0f856598f87ce4fabc3" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:davinci-resolve">
                                
                                <div>
                                    <div>With the new MacBook Pro with M3 Max, video post-production work on the highest-resolution content in apps like Blackmagic DaVinci Resolve Studio is a breeze, thanks to two ProRes engines.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2023/10/apple-unveils-new-macbook-pro-featuring-m3-chips/article/Apple-MacBook-Pro-M3-Max-DaVinci-Resolve-231030.zip" download="" data-analytics-title="Download image" aria-label="Download media, The new MacBook Pro with M3 Max with a Blackmagic DaVinci Resolve Studio workflow."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
            </div>
            
                
                
                <nav role="presentation">
                    
                        <ul>
                            <li>
                                
                            </li>
                            <li>
                                
                            </li>
                        </ul>
                    
                </nav>
            
        </div>
    


    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>Now Available in Space Black</strong>
</h2>
                 
             
                 <div>MacBook Pro models with M3 Pro and M3 Max are available in space black, a stunning new color that’s unmistakably pro. The finish features a breakthrough chemistry that forms an anodization seal to greatly reduce fingerprints. M3 Pro and M3 Max models are also available in silver, and the 14‑inch MacBook Pro with M3 is available in silver and space gray.
</div>
                 
             
         </div>
 

    
    
    


    
    
        
        
        
            <div role="group" aria-label="gallery" data-component-list="MixinGallery" id="macbook-pro-space-black">
            <nav role="presentation">
                <ul role="tablist">
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-452c57ac9902a30be3b095be69405ef0" href="#gallery-452c57ac9902a30be3b095be69405ef0" data-ac-gallery-trigger="gallery-452c57ac9902a30be3b095be69405ef0"><span>A closed MacBook Pro is shown from overhead on a white background.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-29128ef59e2e61598421fae20f737378" href="#gallery-29128ef59e2e61598421fae20f737378" data-ac-gallery-trigger="gallery-29128ef59e2e61598421fae20f737378"><span>An overheard view of the new MacBook Pro in space black, focusing on the keyboard.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-54cd2703c76a4c2cc50c1bc5d82d5fea" href="#gallery-54cd2703c76a4c2cc50c1bc5d82d5fea" data-ac-gallery-trigger="gallery-54cd2703c76a4c2cc50c1bc5d82d5fea"><span>The thin new MacBook Pro shown from the side.</span></a>
                        </li>
                    
                </ul>
            </nav>
            <div>
                
                    
                        
                        <div id="gallery-452c57ac9902a30be3b095be69405ef0" aria-labelledby="gallery-dotnav-452c57ac9902a30be3b095be69405ef0" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:closed-top-view">
                                
                                <div>
                                    <div>MacBook Pro with M3 Pro or M3 Max is available in a stunning new color, space black.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2023/10/apple-unveils-new-macbook-pro-featuring-m3-chips/article/Apple-MacBook-Pro-top-view-231030.zip" download="" data-analytics-title="Download image" aria-label="Download media, A closed MacBook Pro is shown from overhead on a white background."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-29128ef59e2e61598421fae20f737378" aria-labelledby="gallery-dotnav-29128ef59e2e61598421fae20f737378" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:keyboard-close-up">
                                
                                <div>
                                    <div>MacBook Pro with M3 Pro or M3 Max is available in a stunning new color, space black.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2023/10/apple-unveils-new-macbook-pro-featuring-m3-chips/article/Apple-MacBook-Pro-keyboard-231030.zip" download="" data-analytics-title="Download image" aria-label="Download media, An overheard view of the new MacBook Pro in space black, focusing on the keyboard."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-54cd2703c76a4c2cc50c1bc5d82d5fea" aria-labelledby="gallery-dotnav-54cd2703c76a4c2cc50c1bc5d82d5fea" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:side-view">
                                
                                <div>
                                    <div>MacBook Pro with M3 Pro or M3 Max is available in a stunning new color, space black.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2023/10/apple-unveils-new-macbook-pro-featuring-m3-chips/article/Apple-MacBook-Pro-side-view-231030.zip" download="" data-analytics-title="Download image" aria-label="Download media, The thin new MacBook Pro shown from the side."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
            </div>
            
                
                
                <nav role="presentation">
                    
                        <ul>
                            <li>
                                
                            </li>
                            <li>
                                
                            </li>
                        </ul>
                    
                </nav>
            
        </div>
    


    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>A Game Changer for Upgraders</strong><br>

</h2>
                 
             
                 <div>The new MacBook Pro is a big upgrade for any user, especially those who have not upgraded from an Intel-based Mac. The M3 Max model is up to 11x faster than the fastest Intel-based MacBook Pro model.<sup>5</sup> With the power efficiency of Apple silicon, for the vast majority of workloads, users will never hear the fans. Battery life also soars with up to 11 additional hours compared to the fastest Intel-based MacBook Pro model,<sup>5</sup> and unlike many PC laptops, MacBook Pro delivers the same incredible performance whether plugged in or on battery. The Liquid Retina XDR display is the world’s best laptop display, with an exceptional 1000 nits sustained and 1600 nits of peak brightness for HDR content, impressive contrast ratio, vivid colors, and an outstanding viewing angle. SDR content is now displayed at up to 600 nits, which is 20 percent brighter than before.
</div>
                 
             
         </div>
 

    
    
    






  
    
    
    
    
      <figure aria-label="Media, A person with pink hair is shown on the new MacBook Pro as part of a video editing workflow.">
        <div>
             
              
              <div>
                All MacBook Pro models feature an industry-leading Liquid Retina XDR display, which is unrivaled for creating and enjoying content.
              </div>
            
            
            
            
            <a href="https://www.apple.com/newsroom/images/2023/10/apple-unveils-new-macbook-pro-featuring-m3-chips/article/Apple-MacBook-Pro-Liquid-Retina-display-DaVinci-Resolve-231030.zip" download="" data-analytics-title="Download image" aria-label="Download media, A person with pink hair is shown on the new MacBook Pro as part of a video editing workflow."></a>
          </div>
      </figure>
    
  






    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>macOS Sonoma</strong>
</h2>
                 
             
                 <div>macOS Sonoma brings a rich set of features to the Mac for work and play. Users can now place widgets right on the desktop, interact with them with just a click, and access the extensive ecosystem of iPhone widgets on their Mac through the magic of Continuity. Video conferencing is even more engaging with features to help users present remotely, including Presenter Overlay, which places the presenter on top of the content being shared; and Reactions, which enable fun gesture-triggered video effects in cinematic quality. In Safari, Profiles keeps browsing separate between multiple topics or projects, and web apps provide faster access to favorite sites. And a collection of stunning new screen savers features slow-motion videos of locations around the world.
</div>
                 
             
                 <div>macOS Sonoma also takes full advantage of the capabilities of Apple silicon, offering powerful new features for pros. The new high performance mode in Screen Sharing enables extremely responsive remote access to another Mac so pros can securely work on their highest-quality content from anywhere. Game Mode prioritizes graphics tasks to deliver consistently high frame rates and drastically reduce latency with wireless accessories for even more immersive gameplay with titles like Baldur’s Gate 3, Lies of P, and DEATH STRANDING DIRECTOR’S CUT.
</div>
                 
             
         </div>
 

    
    
    


    
    <div data-component-list="ScrollAnimationDefault AutoPlayVideo">
        <div>Game Mode in macOS Sonoma delivers an optimized gaming experience and works with all Mac games, including new titles like Baldur’s Gate 3.</div>
        
            <a aria-label="Download video: MacBook Pro Baldur’s Gate gameplay" data-analytics-title="Download video - MacBook Pro Baldur’s Gate gameplay" download="" href="https://www.apple.com/newsroom/videos/macbook-pro-baldurs-gate-3/downloads/Apple-MacBook-Pro-gaming-Baldurs-Gate-3-231030.zip">
            </a>
        
    </div>






    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>Better for the Environment</strong>
</h2>
                 
             
                 <div>MacBook Pro is built to last. The enclosure is created from a custom alloy that uses 100 percent recycled aluminum and is incredibly durable. MacBook Pro also uses 100 percent recycled rare earth elements in all magnets, and 100 percent recycled tin soldering and gold plating in multiple printed circuit boards. MacBook Pro is also free of numerous harmful substances such as beryllium, brominated flame retardants, and mercury, and 100 percent of the wood fiber in the packaging is recycled or comes from responsibly managed forests.
</div>
                 
             
                 <div>Today, Apple is carbon neutral for global corporate operations, and by 2030, plans to be carbon neutral across the entire manufacturing supply chain and all product life cycles. This means that every Apple device sold, from component manufacturing, assembly, transport, customer use, all the way to recycling and material recovery, will be carbon neutral.
</div>
                 
             
         </div>
 

    
    
    


     
     
    
    
        <div>
             
                 
                 
             
                 <div><ul>
<li>Customers can order the new MacBook Pro starting today, Monday, October 30, on <a href="https://www.apple.com/store/" target="_blank">apple.com/store</a> and in the Apple Store app in 27 countries and regions, including the U.S. It will begin arriving to customers, and will be in Apple Store locations and Apple Authorized Resellers, starting Tuesday, November 7.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>The 14-inch MacBook Pro with M3 starts at <strong>$1,599</strong> (U.S.) and <strong>$1,499</strong> (U.S.) for education; the 14‑inch MacBook Pro with M3 Pro starts at <strong>$1,999</strong> (U.S.) and <strong>$1,849 </strong>(U.S.) for education; and the 16‑inch MacBook Pro starts at <strong>$2,499</strong> (U.S.) and <strong>$2,299 </strong>(U.S.) for education.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Additional technical specifications, configure-to-order options, and accessories are available at <a href="https://www.apple.com/mac/" target="_blank">apple.com/mac</a>.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>With Apple Trade In, customers can trade in their current computer and get credit toward a new Mac. Customers can visit <a href="https://www.apple.com/shop/trade-in/" target="_blank">apple.com/shop/trade-in</a> to see what their device is worth.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Every customer who buys a Mac from Apple can enjoy a free Online Personal Session with an Apple Specialist, get their product set up in select stores — including help with data transfer — and receive guidance on how to make their new Mac work the way they want.</li>
</ul>
</div>
                 
             
         </div>
 

    
    
    




    
    
        
    


    
    
    



    
    
    




    




    
    
    





    
    
    <div>
            <ol>
<li>Testing was conducted by Apple in September and October 2023 using preproduction 16‑inch MacBook Pro systems with Apple M3 Pro, a 12-core CPU, an 18-core GPU, 36GB of RAM, and 512GB SSD. The wireless web test measures battery life by wirelessly browsing 25 popular websites with display brightness set to eight clicks from bottom. The Apple TV app movie playback test measures battery life by playing back HD 1080p content with display brightness set to eight clicks from bottom. Battery life varies by use and configuration. See <a href="https://www.apple.com/batteries/" target="_blank">apple.com/batteries</a> for more information.</li>
<li>Results are compared to the previous-generation 13‑inch MacBook Pro with Apple M1, an 8-core CPU, an 8-core GPU, 16GB of RAM, and 2TB SSD.</li>
<li>Results are compared to previous-generation 1.7GHz quad-core Intel Core i7-based 13‑inch MacBook&nbsp;Pro systems with Intel Iris Plus Graphics 645, 16GB of RAM, and 2TB SSD.</li>
<li>Results are compared to the previous-generation 16‑inch MacBook Pro with Apple M1 Pro, a 10-core CPU, a 16-core GPU, 32GB of RAM, and 8TB SSD.</li>
<li>Results are compared to previous-generation 2.4GHz 8-core Intel Core i9-based 16‑inch MacBook Pro systems with Radeon Pro 5600M graphics with 8GB of HBM2, 64GB of RAM, and 8TB SSD.</li>
<li>Results are compared to the previous-generation 16‑inch MacBook Pro with Apple M1 Max, a 10-core CPU, a 32-core GPU, 64GB of RAM, and 8TB SSD.</li>
</ol>

        </div>



    
    
    






    
















	
	
	
		















	
	

</article>



</section>
</main>


	

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apple unveils M3, M3 Pro, and M3 Max, the most advanced chips for a PC (753 pts)]]></title>
            <link>https://www.apple.com/newsroom/2023/10/apple-unveils-m3-m3-pro-and-m3-max-the-most-advanced-chips-for-a-personal-computer/</link>
            <guid>38078063</guid>
            <pubDate>Tue, 31 Oct 2023 00:30:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.apple.com/newsroom/2023/10/apple-unveils-m3-m3-pro-and-m3-max-the-most-advanced-chips-for-a-personal-computer/">https://www.apple.com/newsroom/2023/10/apple-unveils-m3-m3-pro-and-m3-max-the-most-advanced-chips-for-a-personal-computer/</a>, See on <a href="https://news.ycombinator.com/item?id=38078063">Hacker News</a></p>
<div id="readability-page-1" class="page">


	
    







 
<nav id="ac-localnav" lang="en-US" role="navigation" aria-label="Newsroom" data-analytics-region="local nav" data-sticky="">
	
    
    
        




    
    

</nav>



<main id="main" role="main"> 



<span id="opens-in-new-window">opens in new window</span>

	

<section>
<article data-analytics-activitymap-region-id="article">






    
    
    











    <div>
        

        <div>
                    
                    
                        <span>PRESS RELEASE</span>
                    
                    
                        <span>October 30, 2023</span>
                    
                    
                </div>

        <div>
                
                
                
                    <h2>
                        
    
        Apple unveils M3, M3&nbsp;Pro, and M3&nbsp;Max, the most advanced chips for a personal computer
    

                    </h2>
                
            </div>

        <div>
                
                
                    The industry’s first 3-nanometer chips for a personal computer debut a next-generation GPU architecture and deliver dramatic performance improvements, a faster CPU and Neural Engine, and support for more unified memory
                
            </div>

        
            
    
    
    
    
    

        

    </div>







    
    
    






  
    
    
    
    
      <figure aria-label="Media, The M3, M3 Pro, and M3 Max chips.">
        <div>
             
              
              <div>
                For the first time, Apple&nbsp;is introducing three&nbsp;chips at once: M3, M3 Pro, and M3 Max, the most advanced chips ever built for a personal computer.
              </div>
            
            
            
            
            <a href="https://www.apple.com/newsroom/images/2023/10/Apple-unveils-M3-M3-Pro-and-M3-Max/article/Apple-M3-chip-series-231030.zip" download="" data-analytics-title="Download image" aria-label="Download media, The M3, M3 Pro, and M3 Max chips."></a>
          </div>
      </figure>
    
  






    
    
    


     
     
    
    
        <div>
             
                 <div><span>CUPERTINO, CALIFORNIA</span>&nbsp;Apple today announced M3, M3 Pro, and M3 Max, three chips featuring groundbreaking technologies that deliver dramatically increased performance and unleash new capabilities for Mac. These are the first personal computer chips built using the industry-leading 3-nanometer process technology, allowing more transistors to be packed into a smaller space and improving speed and efficiency. Together, M3, M3 Pro, and M3 Max show how far Apple silicon for the Mac has come since the debut of the M1 family of chips.&nbsp;
</div>
                 
             
                 <div>The M3 family of chips features a next-generation GPU that represents the biggest leap forward in graphics architecture ever for Apple silicon. The GPU is faster and more efficient, and introduces a new technology called Dynamic Caching, while bringing new rendering features like hardware-accelerated ray tracing and mesh shading to Mac for the first time. Rendering speeds are now up to 2.5x faster than on the M1 family of chips.<sup>1</sup> The CPU performance cores and efficiency cores are 30 percent and 50 percent faster than those in M1, respectively, and the Neural Engine is 60 percent faster than the Neural Engine in the M1 family of chips. And, a new media engine now includes support for AV1 decode, providing more efficient and high-quality video experiences from streaming services. The M3 family of chips continues the tremendous pace of innovation in Apple silicon, and brings massive enhancements and new features to the new <a href="https://www.apple.com/macbook-pro/" target="_blank">MacBook Pro</a> and <a href="https://www.apple.com/imac/" target="_blank">iMac</a>.
</div>
                 
             
                 <div>“Apple silicon has completely redefined the Mac experience. Every aspect of its architecture is designed for performance and power efficiency,” said Johny Srouji, Apple’s senior vice president of Hardware Technologies. “With 3-nanometer technology, a next-generation GPU architecture, a higher-performance CPU, faster Neural Engine, and support for even more unified memory, M3, M3 Pro, and M3 Max are the most advanced chips ever built for a personal computer.”
</div>
                 
             
         </div>
 

    
    
    






  
    
    
    
    
      <figure aria-label="Media, The architecture of M3, M3 Pro, and M3 Max.">
        <div>
             
              
              <div>
                The M3 family of chips is built using the industry-leading 3-nanometer process technology, and continues the tremendous pace of innovation in Apple silicon.
              </div>
            
            
            
            
            <a href="https://www.apple.com/newsroom/images/2023/10/Apple-unveils-M3-M3-Pro-and-M3-Max/article/Apple-M3-chip-series-architecture-231030.zip" download="" data-analytics-title="Download image" aria-label="Download media, The architecture of M3, M3 Pro, and M3 Max."></a>
          </div>
      </figure>
    
  






    
    
    


     
     
    
    
        <div>
             
                 <h2>All-New GPU Features Dynamic Caching, Mesh Shading, and Hardware-Accelerated Ray Tracing
</h2>
                 
             
                 <div>The next-generation GPU inside the M3 family of chips represents the largest leap forward in graphics architecture for Apple silicon. It features Dynamic Caching that, unlike traditional GPUs, allocates the use of local memory in hardware in real time. With Dynamic Caching, only the exact amount of memory needed is used for each task. This is an industry first, transparent to developers, and the cornerstone of the new GPU architecture. It dramatically increases the average utilization of the GPU, which significantly increases performance for the most demanding pro apps and games.
</div>
                 
             
                 <div>With the M3 family of chips, hardware-accelerated ray tracing comes to the Mac for the first time. Ray tracing models the properties of light as it interacts with a scene, allowing apps to create extremely realistic and physically accurate images. This, along with the new graphics architecture, allows pro apps to deliver up to 2.5x the speed of the M1 family of chips. Game developers can use ray tracing for more accurate shadows and reflections, creating deeply immersive environments. Additionally, the new GPU brings hardware-accelerated mesh shading to the Mac, delivering greater capability and efficiency to geometry processing, and enabling more visually complex scenes in games and graphics-intensive apps. This breakthrough GPU architecture enables all of these enhancements and features while maintaining Apple silicon’s legendary power efficiency. In fact, the M3 GPU is able to deliver the same performance as M1 using nearly half the power, and up to 65 percent more performance at its peak.
</div>
                 
             
         </div>
 

    
    
    


    
    <div data-component-list="ScrollAnimationDefault AutoPlayVideo">
        <div>The next-generation GPU inside the M3 family of chips represents the largest leap forward in graphics architecture ever for Apple&nbsp;silicon, featuring&nbsp;Dynamic Caching, mesh shading, and hardware-accelerated ray tracing.</div>
        
            <a aria-label="Download video: M3 Family of Chips GPU" data-analytics-title="Download video - M3 Family of Chips GPU" download="" href="https://www.apple.com/newsroom/videos/m3-chip-series-cinema/downloads/Apple-M3-chip-series-Cinema-4D-231030.zip">
            </a>
        
    </div>






    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>A Faster and More Efficient CPU</strong>
</h2>
                 
             
                 <div>The next-generation CPU in M3, M3 Pro, and M3 Max features architectural improvements to the performance and efficiency cores. The performance cores are up to 30 percent faster than those in the M1 family, so tasks like compiling and testing millions of lines of code in Xcode are even faster, and musicians can use hundreds of audio tracks, plug-ins, and virtual instruments in Logic Pro. The efficiency cores are up to 50 percent faster than the efficiency cores in M1, so everyday tasks are faster than ever, while allowing the system to maximize battery life. Together, these cores create a CPU that delivers the same multithreaded performance as M1 using as little as half the power, and up to 35 percent more performance at peak power.
</div>
                 
             
         </div>
 

    
    
    


    
    
        
        
        
            <div role="group" aria-label="gallery" data-component-list="MixinGallery" id="m3-chip-series-cores">
            <nav role="presentation">
                <ul role="tablist">
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-d40b1a3d8e645760c799bcb759b7fc43" href="#gallery-d40b1a3d8e645760c799bcb759b7fc43" data-ac-gallery-trigger="gallery-d40b1a3d8e645760c799bcb759b7fc43"><span>A chart comparing the efficiency cores in M3 chips versus M1 chips. </span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-36433a20473ea7abc562070d10aedbfd" href="#gallery-36433a20473ea7abc562070d10aedbfd" data-ac-gallery-trigger="gallery-36433a20473ea7abc562070d10aedbfd"><span>A chart comparing the performance cores in M3 chips versus M1 chips.</span></a>
                        </li>
                    
                </ul>
            </nav>
            <div>
                
                    
                        
                        <div id="gallery-d40b1a3d8e645760c799bcb759b7fc43" aria-labelledby="gallery-dotnav-d40b1a3d8e645760c799bcb759b7fc43" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:efficiency">
                                
                                <div>
                                    <div>The M3 family of chips feature efficiency cores that are up to 50 percent faster than those in the M1 family.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2023/10/Apple-unveils-M3-M3-Pro-and-M3-Max/article/Apple-M3-chip-series-efficiency-cores-comparison-231030.zip" download="" data-analytics-title="Download image" aria-label="Download media, A chart comparing the efficiency cores in M3 chips versus M1 chips. "></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-36433a20473ea7abc562070d10aedbfd" aria-labelledby="gallery-dotnav-36433a20473ea7abc562070d10aedbfd" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:performance">
                                
                                <div>
                                    <div>The performance cores of the M3 family of chips are up to 30 percent faster than those in the M1 family.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2023/10/Apple-unveils-M3-M3-Pro-and-M3-Max/article/Apple-M3-chip-series-performance-cores-comparison-231030.zip" download="" data-analytics-title="Download image" aria-label="Download media, A chart comparing the performance cores in M3 chips versus M1 chips."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
            </div>
            
                
                
                <nav role="presentation">
                    
                        <ul>
                            <li>
                                
                            </li>
                            <li>
                                
                            </li>
                        </ul>
                    
                </nav>
            
        </div>
    


    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>Unrivaled Unified Memory Architecture, up to 128GB</strong>
</h2>
                 
             
                 <div>Each chip in the M3 family features a unified memory architecture, a hallmark of Apple silicon. This delivers high bandwidth, low latency, and unmatched power efficiency. Having a single pool of memory within a custom package means all of the technologies in the chip can access the same data without copying it between multiple pools of memory, further improving performance and efficiency, and reducing the amount of memory a system requires for the majority of tasks. Additionally, support for up to 128GB of memory unlocks workflows previously not possible on a laptop, such as AI developers working with even larger transformer models with billions of parameters.
</div>
                 
             
         </div>
 

    
    
    


    
    
        
        
        
            <div role="group" aria-label="gallery" data-component-list="MixinGallery" id="unified-memory-architecture-m3-family-of-chips">
            <nav role="presentation">
                <ul role="tablist">
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-0db6a7b4edcfc72ac5d65ad827b63049" href="#gallery-0db6a7b4edcfc72ac5d65ad827b63049" data-ac-gallery-trigger="gallery-0db6a7b4edcfc72ac5d65ad827b63049"><span>The design of the unified memory architecture of M3. </span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-0e291e01da161bd03e7149decbfb4154" href="#gallery-0e291e01da161bd03e7149decbfb4154" data-ac-gallery-trigger="gallery-0e291e01da161bd03e7149decbfb4154"><span>The design of the unified memory architecture of M3 Pro.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-faa586fd5670aa71b21a72bb0fb64184" href="#gallery-faa586fd5670aa71b21a72bb0fb64184" data-ac-gallery-trigger="gallery-faa586fd5670aa71b21a72bb0fb64184"><span>The design of the unified memory architecture of M3 Max.</span></a>
                        </li>
                    
                </ul>
            </nav>
            <div>
                
                    
                        
                        <div id="gallery-0db6a7b4edcfc72ac5d65ad827b63049" aria-labelledby="gallery-dotnav-0db6a7b4edcfc72ac5d65ad827b63049" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:m3">
                                
                                <div>
                                    <div>The unified memory architecture of M3 delivers high bandwidth, low latency, unmatched power efficiency, and supports up to 24GB of fast, unified memory.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2023/10/Apple-unveils-M3-M3-Pro-and-M3-Max/article/Apple-M3-chip-series-unified-memory-architecture-M3-231030.zip" download="" data-analytics-title="Download image" aria-label="Download media, The design of the unified memory architecture of M3."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-0e291e01da161bd03e7149decbfb4154" aria-labelledby="gallery-dotnav-0e291e01da161bd03e7149decbfb4154" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:m3-pro">
                                
                                <div>
                                    <div>The unified memory architecture of M3 Pro supports up to 36GB of fast, unified memory, enabling larger projects to be tackled on MacBook Pro when users are on the go.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2023/10/Apple-unveils-M3-M3-Pro-and-M3-Max/article/Apple-M3-chip-series-unified-memory-architecture-M3-Pro-231030.zip" download="" data-analytics-title="Download image" aria-label="Download media, The design of the unified memory architecture of M3 Pro."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-faa586fd5670aa71b21a72bb0fb64184" aria-labelledby="gallery-dotnav-faa586fd5670aa71b21a72bb0fb64184" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:m3-max">
                                
                                <div>
                                    <div>The unified memory architecture of M3 Max supports up to 128GB of fast, unified memory, allowing pros to accomplish tasks previously&nbsp;not possible&nbsp;on a laptop.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2023/10/Apple-unveils-M3-M3-Pro-and-M3-Max/article/Apple-M3-chip-series-unified-memory-architecture-M3-Max-231030.zip" download="" data-analytics-title="Download image" aria-label="Download media, The design of the unified memory architecture of M3 Max."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
            </div>
            
                
                
                <nav role="presentation">
                    
                        <ul>
                            <li>
                                
                            </li>
                            <li>
                                
                            </li>
                        </ul>
                    
                </nav>
            
        </div>
    


    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>Custom Engines for AI and Video</strong>
</h2>
                 
             
                 <div>M3, M3 Pro, and M3 Max also have an enhanced Neural Engine to accelerate powerful machine learning (ML) models. The Neural Engine is up to 60 percent faster than in the M1 family of chips, making AI/ML workflows even faster while keeping data on device to preserve privacy. Powerful AI image processing tools, like noise reduction and super resolution in Topaz, get even faster. Scene edit detection in Adobe Premiere and Smart Conform in Final Cut Pro also see a boost in performance.
</div>
                 
             
                 <div>All three chips in the M3 family also have an advanced media engine, providing hardware acceleration to the most popular video codecs, including H.264, HEVC, ProRes, and ProRes RAW. And for the first time, the media engine supports AV1 decoding, enabling power-efficient playback of streaming services to further extend battery life.
</div>
                 
             
         </div>
 

    
    
    






  
    
    
    
    
      <figure aria-label="Media, A chart comparing the performance cores of the new Neural Engine in M3, M3 Pro, and M3 Max to the M1 family of chips.">
        <div>
             
              
              <div>
                The Neural Engine in M3, M3 Pro, and M3 Max is up to 60 percent faster than in the M1 family of chips, making AI and machine learning workflows even faster.
              </div>
            
            
            
            
            <a href="https://www.apple.com/newsroom/images/2023/10/Apple-unveils-M3-M3-Pro-and-M3-Max/article/Apple-M3-chip-series-Neural-Engine-performance-231030.zip" download="" data-analytics-title="Download image" aria-label="Download media, A chart comparing the performance cores of the new Neural Engine in M3, M3 Pro, and M3 Max to the M1 family of chips."></a>
          </div>
      </figure>
    
  






    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>M3: Phenomenal Performance for the Most Popular&nbsp;Systems</strong>
</h2>
                 
             
                 <div>M3 features 25 billion transistors — 5 billion more than M2. It has a 10-core GPU featuring the next-generation architecture that is 65 percent faster than M1 for graphics performance. Games like Myst have incredibly realistic lighting, shadows, and reflections. M3 has an 8-core CPU, with four performance cores and four efficiency cores, that is up to 35 percent faster than M1 for CPU performance. And it supports up to 24GB of unified memory.
</div>
                 
             
         </div>
 

    
    
    


    
    <div data-component-list="ScrollAnimationDefault AutoPlayVideo">
        <div>Graphics-intensive games like Myst have incredibly realistic lighting, shadows, and reflections, thanks to the next-generation GPU of M3.</div>
        
            <a aria-label="Download video: M3 GPU" data-analytics-title="Download video - M3 GPU" download="" href="https://www.apple.com/newsroom/videos/m3-chip-series-myst/downloads/Apple-M3-chip-series-gaming-graphics-Myst-231030.zip">
            </a>
        
    </div>






    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>M3 Pro: For Users Who Need Even More Performance</strong>
</h2>
                 
             
                 <div>M3 Pro consists of 37 billion transistors and an 18-core GPU, delivering extremely fast performance when working on more graphics-intensive tasks. The GPU is up to 40 percent faster than M1 Pro. Support for unified memory goes up to 36GB, enabling larger projects to be tackled on MacBook Pro when users are on the go. The 12-core CPU design has six performance cores and six efficiency cores, offering single-threaded performance that is up to 30 percent faster than M1 Pro. Actions like stitching together and manipulating enormous panoramic photos in Adobe Photoshop are faster than ever with M3 Pro on the new MacBook Pro.
</div>
                 
             
         </div>
 

    
    
    


    
    <div data-component-list="ScrollAnimationDefault AutoPlayVideo">
        <div>Tasks like stitching together and manipulating enormous panoramic photos in Adobe Photoshop are faster than ever with the GPU and CPU of M3 Pro.</div>
        
            <a aria-label="Download video: M3 Pro GPU and CPU" data-analytics-title="Download video - M3 Pro GPU and CPU" download="" href="https://www.apple.com/newsroom/videos/m3-chip-series-photoshop/downloads/Apple-M3-chip-series-M3-Pro-Photoshop-231030.zip">
            </a>
        
    </div>






    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>M3 Max: A Tremendous Leap in Performance for the Most Demanding Pro Workloads</strong>
</h2>
                 
             
                 <div>M3 Max pushes the transistor count up to 92 billion and takes pro performance to the next level. The 40-core GPU is up to 50 percent faster than M1 Max, and support for up to 128GB of unified memory allows AI developers to work with even larger transformer models with billions of parameters. The 16-core CPU features 12 performance cores and four efficiency cores, achieving astonishing performance that’s up to 80 percent faster than M1 Max. And with two ProRes engines, M3 Max makes video post-production work on even the highest-resolution content fast and fluid, whether using DaVinci Resolve, Adobe Premiere Pro, or Final Cut Pro. M3 Max is designed for pros needing the highest performance available in a MacBook Pro with industry-leading battery life in a pro laptop.
</div>
                 
             
         </div>
 

    
    
    






  
    
    
    
    
      <figure aria-label="Media, iMacs with M3.">
        <div>
             
              
              <div>
                M3 Max consists of 92 billion transistors and delivers a tremendous increase in performance for the most demanding pro workloads.
              </div>
            
            
            
            
            <a href="https://www.apple.com/newsroom/images/2023/10/Apple-unveils-M3-M3-Pro-and-M3-Max/article/Apple-M3-chip-series-M3-Max-video-editing-231030.zip" download="" data-analytics-title="Download image" aria-label="Download media, iMacs with M3."></a>
          </div>
      </figure>
    
  






    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>Better for the Environment</strong>
</h2>
                 
             
                 <div>The power-efficient performance of M3, M3 Pro, and M3 Max helps the new MacBook Pro and iMac meet Apple’s high standards for energy efficiency, and helps the new MacBook Pro achieve the longest battery life ever in a Mac — up to 22 hours.<sup>2</sup> This results in less time needing to be plugged in and less energy consumed over its lifetime.
</div>
                 
             
                 <div>Today, Apple is carbon neutral for global corporate operations, and by 2030, plans to have net-zero climate impact across the entire business, which includes the entire manufacturing supply chain and life cycle of every product. This means that every chip in every Mac, from design to manufacturing, will be carbon neutral.
</div>
                 
             
         </div>
 

    
    
    




    
    
        
    


    
    
    



    
    
    




    




    
    
    





    
    
    <div>
            <ol>
<li>Results are compared to the previous-generation 16-inch MacBook Pro with M1 Max, a 10-core CPU, a 32-core GPU, 64GB of RAM, and 8TB SSD.</li>
<li>Testing was conducted by Apple in September and October 2023 using preproduction 16-inch MacBook Pro systems with Apple M3 Pro, a 12-core CPU, an 18-core GPU, 36GB of RAM, and 512GB SSD. The wireless web test measures battery life by wirelessly browsing 25 popular websites with display brightness set to eight clicks from the bottom. The Apple TV app movie playback test measures battery life by playing back HD 1080p content with display brightness set to eight clicks from the bottom. Battery life varies by use and configuration. See <a href="https://www.apple.com/batteries/" target="_blank">apple.com/batteries</a> for more information.</li>
</ol>

        </div>



    
    
    






    
















	
	
	
		















	
	

</article>



</section>
</main>


	

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Android and RISC-V: What you need to know to be ready (288 pts)]]></title>
            <link>https://opensource.googleblog.com/2023/10/android-and-risc-v-what-you-need-to-know.html</link>
            <guid>38077889</guid>
            <pubDate>Tue, 31 Oct 2023 00:12:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://opensource.googleblog.com/2023/10/android-and-risc-v-what-you-need-to-know.html">https://opensource.googleblog.com/2023/10/android-and-risc-v-what-you-need-to-know.html</a>, See on <a href="https://news.ycombinator.com/item?id=38077889">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-body-5908382786815064734" itemprop="articleBody">
<meta content="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiNWkLqiiKr8EV8U963tdp3bsR5hWzKLp4OYTNEz98a4h5QZ7djoJ3XIYypMTIE_5LRY8KFsKE11L2ZBGOomzPAiFRlXpJFncNTpofay-_tomg89lXHvRs98OSCk6OQkjf6jVVzHVfPcME1D5NBwramBQFTwlfOktrzjQDQPXC91AytSeBrbhjLxLB6IWI/s1600/Social%20-%20OSS%20-%20Android%20and%20RISC-V%20What%20you%20need%20to%20know%20to%20be%20ready.png" name="twitter:image">
<p>

<a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgnVLspuvjvGDJuJj89-C-J9WncBEaAiu_4kmzd1RW4JhFVKgucRUiGrR3NPBvZVxwHXUTEUsGcXEqDXtqItq4t_C0u9BWXZl0cdUdbjHaqWd_G72cZyBPCQVN-vk6zP3yABEQZXIcqCAJk3xjQ25P7Ly3e0kFjm55q1PXDVO_no6C1OZRHKlSyzgod-xU/s1600/Header%20-%20OSS%20-%20Android%20and%20RISC-V%20What%20you%20need%20to%20know%20to%20be%20ready.png"><img data-original-height="800" data-original-width="1058" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgnVLspuvjvGDJuJj89-C-J9WncBEaAiu_4kmzd1RW4JhFVKgucRUiGrR3NPBvZVxwHXUTEUsGcXEqDXtqItq4t_C0u9BWXZl0cdUdbjHaqWd_G72cZyBPCQVN-vk6zP3yABEQZXIcqCAJk3xjQ25P7Ly3e0kFjm55q1PXDVO_no6C1OZRHKlSyzgod-xU/s1600/Header%20-%20OSS%20-%20Android%20and%20RISC-V%20What%20you%20need%20to%20know%20to%20be%20ready.png"></a></p><p>Android is an open source operating system that is freely available to port to many devices and architectures. As such it supports many different device types and CPU architectures. We’re excited to be adding a new one to that list - RISC-V. </p>

<p><a href="https://riscv.org/" target="_blank">RISC-V</a> is a free and open instruction set architecture (ISA), bringing the same spirit of industry-wide collaboration and innovation that we see in software around <a href="https://opensource.org/" target="_blank">open source</a> to the hardware ecosystem. Invented <a href="https://riscv.org/about/history/" target="_blank">10 years ago</a> at the University of California, Berkeley, RISC-V has seen rapid adoption in embedded and microcontroller spaces, and in recent years has expanded into accelerators, servers, and mobile computing.</p>

<p>In November of 2022, we announced at the RISC-V Summit that we were accepting patches for RISC-V:</p>

<iframe allowfullscreen="" height="355" src="https://www.youtube.com/embed/70O_RmTWP58" width="100%" youtube-src-id="70O_RmTWP58"></iframe>

<p>The latest update that we have is that now not only are we accepting patches, but we have begun to mature support for RISC-V in Android. RISC-V is a modular ISA, meaning that there are a large number of optional extensions. We have also determined an initial set that we feel is critical to ensure that any CPU running RISC-V will have all of the features we expect to achieve high performance. This set includes the rva22 profile as well as the vector and vector crypto extensions. This update was provided at the RISC-V summit in Europe:</p>

<iframe allowfullscreen="" height="355" src="https://www.youtube.com/embed/xLwdUn3DQp8" width="100%" youtube-src-id="xLwdUn3DQp8"></iframe>

<p>You can build, test, and run the Android support for RISC-V on your own machine as well now! Just like other platform targets in AOSP, you can use the <a href="https://source.android.com/docs/setup/create/cuttlefish" target="_blank">Cuttlefish</a> Virtual Device <a href="https://github.com/google/android-riscv64" target="_blank">support</a>:</p>

<table><colgroup></colgroup><tbody><tr><td><code id="code-output"><span><span>$ </span>lunch aosp_cf_riscv64_phone-userdebug
<span>$ </span>m -j
<span>$ </span>launch_cvd -cpus=<span>8</span> -memory_mb=<span>8192</span></span></code></td></tr></tbody></table>

<p>Then, you can use <span>vncviewer</span> to connect to the running device and interact.</p>

<p><img alt="Moving image of vncviewer running on an Android device" id="imgCaption" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg3v8et5Vd6_ZPwaPPzWdy2b6pvkpJnBN0-cKGupeQwdBSR7_IxBlqGoFACGGc1EAU9q4s9LTqLlLZt7dHiNAUjC2uU0H3IGiJkL_wENRxkNcLzEBIxej2bzznTpQyK8_65Xc0PE6qLK88fnyI4erogsMq2lWghTi87TkH4keNYRNE4VY2qR0Dydx2nlYU/s1600/Demo-ASOP.gif"></p>

<p>At this time, <a href="https://android-review.googlesource.com/q/owner:maohan4761%2540gmail.com" target="_blank">these patches</a> will support building and running a basic Android Open Source Project experience, but are not yet fully optimized. For example, work on a fully optimized backend for the Android Runtime (ART) is still a work in progress. Additionally, AOSP, our external projects, and compilers haven’t generated fully optimized, reduced code that also takes advantage of the latest ratified extensions, such as the one for <a href="https://github.com/riscv/riscv-v-spec/releases/tag/v1.0" target="_blank">vectors</a>. However, we believe that it is ready to allow experimentation and collaboration.</p> 

<p>Later this year, we expect to have the NDK ABI finalized and canary builds available on Android’s public <a href="https://ci.android.com/builds/branches/aosp-master-ndk/grid" target="_blank">CI</a> soon and RISC-V on x86-64 &amp; ARM64 available for easier testing of riscv64 Android applications on a host machine. By 2024, the plan is to have emulators available publicly, with a full feature set to test applications for various device form factors! As recently <a href="https://www.qualcomm.com/news/releases/2023/10/qualcomm-to-bring-risc-v-based-wearable-platform-to--wear-os-by-" target="_blank">announced</a> in our collaboration with Qualcomm, we expect wearables to be the first form factor available.</p>

<p>However, just porting the Android operating system itself is not enough! We are working with the community and <a href="https://riseproject.dev/" target="_blank">RISE</a> (RISC-V Software Ecosystem). The RISE Project has been established to provide a way to accelerate the availability of software for high-performance and power-efficient RISC-V processor cores running high-level operating systems. That includes not only Android, but also Linux and other operating systems across a variety of application domains, including high-performance computing. The RISE Project includes members from Andes, Google, Intel, Imagination Technologies, MediaTek, Nvidia, Qualcomm Technologies, Red Hat, Rivos, Samsung, SiFive, T-Head, and Ventana.</p>

<p>Google is also continuing and expanding our strong investments at <a href="https://riscv.org/" target="_blank">RISC-V International</a>, even beyond our long-standing Premium membership and <a href="https://foundation.rust-lang.org/board/" target="_blank">board participation</a>. We also have many other contributors in key roles on horizontal committees, working groups, and technical committees to ensure that specifications are rapidly being designed and ratified to benefit not only Android but also many other use cases.</p>

<p>Android's support for RISC-V is dependent on a wide range of contributions from <a href="https://github.com/llvm/llvm-project/" target="_blank">toolchain</a> to basic support libraries. We are very appreciative of the ongoing efforts which requires countless projects to support RISC-V build configurations and quality implementations.  If you are interested in contributing please visit the following resources:</p>
<ul>
<li><a href="https://github.com/google/android-riscv64" target="_blank">https://github.com/google/android-riscv64</a> for detailed information on how to build and test the RISC-V support in Android, list of known issues and opportunities to contribute to AOSP at <a href="https://source.android.com/" target="_blank">source.android.com</a> and toolchain projects and support libraries.</li>
<li>Subscribe to <a href="https://lists.riscv.org/g/sig-android" target="_blank">RISC-V Android SIG</a> mailing list or join directly, if your organization is a member of RISC-V International to stay tuned in to progress and offer your suggestions and feedback.</li>
</ul>

<p>Make sure to stay tuned as we look into ways to make it as easy for Android developers writing native to target new platforms as it is for our Java and Kotlin developers! </p>

<p>Planning to head to the RISC-V International Summit in November? Find us there– we’ll be hosting a <a href="https://events.linuxfoundation.org/riscv-summit/program/schedule/" target="_blank">Community Collaboration Breakfast on Wednesday morning</a>! Not attending the conference but interested? Learn more and register <a href="https://events.linuxfoundation.org/riscv-summit/" target="_blank">here</a>.</p>

<p><em>By Lars Bergstrom – Android Platform Programming Languages &amp; Greg Simon - Google Low-level Operating System</em></p>



</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[World's most popular painter sent his followers after me because of my review (363 pts)]]></title>
            <link>https://news.artnet.com/opinion/devon-rodriguez-parasocial-aesthetics-2380960</link>
            <guid>38077684</guid>
            <pubDate>Mon, 30 Oct 2023 23:52:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://news.artnet.com/opinion/devon-rodriguez-parasocial-aesthetics-2380960">https://news.artnet.com/opinion/devon-rodriguez-parasocial-aesthetics-2380960</a>, See on <a href="https://news.ycombinator.com/item?id=38077684">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-post-id="2380960">
									<p>A little more than a week ago, I wrote <a href="https://news.artnet.com/opinion/devon-rodriguez-painter-tiktok-underground-2373157" target="_blank" rel="noopener">a review</a> of an art show by the artist and TikTok sensation Devon Rodriguez, best known for live drawing subway riders. He is, by some measures, the most famous artist in the world, with many millions of social media followers. He did not like the review.</p>
<p>It went up on a Friday. On Saturday morning, I woke up to a tidal wave of anger from Rodriguez on <a href="https://www.instagram.com/p/CyGPe42gBSt/" target="_blank" rel="noopener">Instagram</a>, tagging me across scores of posts. Hundreds of his followers went on the attack, swarming my Instagram: “loser,” “hater,” “pathetic,” “jealous,” “your a dick,” and on and on and on. There were many creative variations on “kill yourself.” Others said they were going to get me fired, or said things like, “we are going to start a cancellation campaign against you.” A large number thought that defending Rodriguez meant calling me bald, ugly, fat, or whatever they thought could get under my skin. Most didn’t seem to have actually read my article. A contingent went after my wife. “Some women will do anything for money,” one commented. That one was funny, actually.</p>
<p>After a few days Rodriguez ceased tagging me, and the wave of hate cooled down. “@benstoppable love will always outshine being a hater, I hope I taught you that today,” Rodriguez posted.</p>
<div id="attachment_2381034"><p><img aria-describedby="caption-attachment-2381034" loading="lazy" src="https://news.artnet.com/app/news-upload/2023/10/devon-rodriguez-screenshot-1-628x1024.jpg" alt="Screenshot of a post by Devon Rodriguez to Instagram stories. " width="628" height="1024" srcset="https://news.artnet.com/app/news-upload/2023/10/devon-rodriguez-screenshot-1-628x1024.jpg 628w, https://news.artnet.com/app/news-upload/2023/10/devon-rodriguez-screenshot-1-184x300.jpg 184w, https://news.artnet.com/app/news-upload/2023/10/devon-rodriguez-screenshot-1-31x50.jpg 31w, https://news.artnet.com/app/news-upload/2023/10/devon-rodriguez-screenshot-1.jpg 797w" sizes="(max-width: 628px) 100vw, 628px"></p><p id="caption-attachment-2381034">Screenshot of a post by Devon Rodriguez to Instagram stories.</p></div>
<p>Meanwhile, I also received an urgent email from UTA Artist Space: “Devon (who we represent) nor UTA was given a chance to respond to this very negative and one-sided article.” I wrote back that I had never heard of an artist demanding to comment on a review in advance, but that if Rodriguez or UTA wanted to write a reply, we would publish it.</p>
<p>It’s not the first time that an artist has been mad at me—only the first time that an artist with this particular type of fame has gone out of his way to unleash his fans in this way. It’s also not anywhere near the worst or most important thing going on in the world, obviously. Nevertheless, I do think it raises some larger issues worth thinking about.</p>
<div id="attachment_2381063"><p><img aria-describedby="caption-attachment-2381063" loading="lazy" src="https://news.artnet.com/app/news-upload/2023/10/devon-rodriguez-screenshot-2-1-607x1024.jpg" alt="Screenshot of a post by Devon Rodriguez to Instagram stories." width="607" height="1024" srcset="https://news.artnet.com/app/news-upload/2023/10/devon-rodriguez-screenshot-2-1-607x1024.jpg 607w, https://news.artnet.com/app/news-upload/2023/10/devon-rodriguez-screenshot-2-1-178x300.jpg 178w, https://news.artnet.com/app/news-upload/2023/10/devon-rodriguez-screenshot-2-1-911x1536.jpg 911w, https://news.artnet.com/app/news-upload/2023/10/devon-rodriguez-screenshot-2-1-30x50.jpg 30w, https://news.artnet.com/app/news-upload/2023/10/devon-rodriguez-screenshot-2-1.jpg 945w" sizes="(max-width: 607px) 100vw, 607px"></p><p id="caption-attachment-2381063">Screenshot of a post by Devon Rodriguez to Instagram stories.</p></div>
<h4><strong>A Shifting Attention Economy&nbsp;</strong></h4>
<p>In his torrent of posts, Rodriguez takes big issue with my opener: “Devon Rodriguez is almost certainly the most famous artist in the world, at least on one level,” I wrote. “Almost no one I know has ever heard of him. Except if you say: ‘he’s the painter who draws people on the subway, from TikTok.’ Then sometimes they will light up with recognition.”</p>
<p>His response: “no one he knows has ever heard of me… as if the people that HE knows are more important than everybody else in this world that follows me.. Sorry that I’m not a part of your pretentious circle&nbsp;@benstoppable.”</p>
<div id="attachment_2380606"><p><img aria-describedby="caption-attachment-2380606" loading="lazy" src="https://news.artnet.com/app/news-upload/2023/07/77744E04-52A0-4728-9AA4-E34ABCD2C48E_1_201_a-589x1024.jpeg" alt="Screenshot of a post by Devon Rodriguez to Instagram stories." width="589" height="1024" srcset="https://news.artnet.com/app/news-upload/2023/07/77744E04-52A0-4728-9AA4-E34ABCD2C48E_1_201_a-589x1024.jpeg 589w, https://news.artnet.com/app/news-upload/2023/07/77744E04-52A0-4728-9AA4-E34ABCD2C48E_1_201_a-173x300.jpeg 173w, https://news.artnet.com/app/news-upload/2023/07/77744E04-52A0-4728-9AA4-E34ABCD2C48E_1_201_a-883x1536.jpeg 883w, https://news.artnet.com/app/news-upload/2023/07/77744E04-52A0-4728-9AA4-E34ABCD2C48E_1_201_a-29x50.jpeg 29w, https://news.artnet.com/app/news-upload/2023/07/77744E04-52A0-4728-9AA4-E34ABCD2C48E_1_201_a.jpeg 1100w" sizes="(max-width: 589px) 100vw, 589px"></p><p id="caption-attachment-2380606">Screenshot of a post by Devon Rodriguez to Instagram stories.</p></div>
<p>But the spirit of the article is clearly, if you read it, the <em>exact</em>&nbsp;<em>opposite</em> of what Rodriguez seems to think it is: I’m arguing that traditional art circles should take the phenomenon seriously, and think through what is really going on with this kind of art career. Rodriguez has a lot of cultural clout—but the fact is that most people who go to museums and galleries or who regularly read about art haven’t heard of him.</p>
<p>This is a very weird feature of the cultural present. Instead of art that gains traction over time via traditional channels and then breaks out to a wider audience, there are now regularly art phenomena that get <a href="https://news.artnet.com/art-world/immersive-van-gogh-experiences-1983011" target="_blank" rel="noopener">explosively popular</a> with an immense audience, leaving art institutions and everyone else to <a href="https://news.artnet.com/opinion/beeple-everydays-review-1951656" target="_blank" rel="noopener">sort out</a> what a particular cultural trend means after it has already happened.</p>
<div id="attachment_2380600"><p><img aria-describedby="caption-attachment-2380600" loading="lazy" src="https://news.artnet.com/app/news-upload/2023/07/CA7ED81F-8FB0-4B1F-B45E-F8D1506DF1EB_1_201_a-522x1024.jpeg" alt="Screenshot of a post by Devon Rodriguez to Instagram stories." width="522" height="1024" srcset="https://news.artnet.com/app/news-upload/2023/07/CA7ED81F-8FB0-4B1F-B45E-F8D1506DF1EB_1_201_a-522x1024.jpeg 522w, https://news.artnet.com/app/news-upload/2023/07/CA7ED81F-8FB0-4B1F-B45E-F8D1506DF1EB_1_201_a-153x300.jpeg 153w, https://news.artnet.com/app/news-upload/2023/07/CA7ED81F-8FB0-4B1F-B45E-F8D1506DF1EB_1_201_a-783x1536.jpeg 783w, https://news.artnet.com/app/news-upload/2023/07/CA7ED81F-8FB0-4B1F-B45E-F8D1506DF1EB_1_201_a-1044x2048.jpeg 1044w, https://news.artnet.com/app/news-upload/2023/07/CA7ED81F-8FB0-4B1F-B45E-F8D1506DF1EB_1_201_a-25x50.jpeg 25w, https://news.artnet.com/app/news-upload/2023/07/CA7ED81F-8FB0-4B1F-B45E-F8D1506DF1EB_1_201_a-979x1920.jpeg 979w, https://news.artnet.com/app/news-upload/2023/07/CA7ED81F-8FB0-4B1F-B45E-F8D1506DF1EB_1_201_a.jpeg 1125w" sizes="(max-width: 522px) 100vw, 522px"></p><p id="caption-attachment-2380600">Screenshot of a post by Devon Rodriguez to Instagram stories.</p></div>
<p>Rodriguez is acting as if he is being unfairly scrutinized when he is one of the most influential artists out there, someone who works with <a href="https://www.tiktok.com/@devonrodriguezart/video/7272593458991287594" target="_blank" rel="noopener">A-list celebrities</a>, who the <a href="https://www.nytimes.com/2021/09/27/realestate/tiktok-subway-artist-renters-lower-east-side.html" target="_blank" rel="noopener"><em>New York Times</em></a> says has made as much as $30,000 a day working with mega-brands like Cheetos, who has numerous press agents working to stage-manage his image, who is the ambassador for what contemporary art <em>is</em>&nbsp;to the largest possible audience—he even teaches a <a href="https://www.masterclass.com/sessions/classes/create-realistic-paintings-you-are-proud-of" target="_blank" rel="noopener">Masterclass</a> on realistic portrait painting!</p>
<div>
<p><iframe loading="lazy" title="Drawing a portrait with hot Cheetos! #shorts" width="500" height="281" src="https://www.youtube.com/embed/l2HTnEwQF9Y?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe></p>
</div>
<p>“Dude has PRs putting him in the room with <a href="https://www.tiktok.com/@devonrodriguezart/video/7254988301164219690" target="_blank" rel="noopener">the president</a> and he’s acting like you are gatekeeping him,” someone wrote me. (I should mention that I’ve received a lot of support too.)</p>
<p>In fact, the only way I can understand Rodriguez’s incredibly thin-skinned reaction to my article is that he has managed to rise to this status of apex visibility without <em>any kind of critical writing about him at all</em>. It’s all just been feel-good profiles, so that the first critical word feels like a huge crisis. That’s a relatively new kind of situation for an artist to be in, and worth analyzing.</p>
<div id="attachment_2380596"><p><img aria-describedby="caption-attachment-2380596" loading="lazy" src="https://news.artnet.com/app/news-upload/2023/07/18658AEA-0E92-44FF-B5EA-7E9415C2559D_1_201_a-591x1024.jpeg" alt="Screenshot of a post by Devon Rodriguez to Instagram stories. " width="591" height="1024" srcset="https://news.artnet.com/app/news-upload/2023/07/18658AEA-0E92-44FF-B5EA-7E9415C2559D_1_201_a-591x1024.jpeg 591w, https://news.artnet.com/app/news-upload/2023/07/18658AEA-0E92-44FF-B5EA-7E9415C2559D_1_201_a-173x300.jpeg 173w, https://news.artnet.com/app/news-upload/2023/07/18658AEA-0E92-44FF-B5EA-7E9415C2559D_1_201_a-886x1536.jpeg 886w, https://news.artnet.com/app/news-upload/2023/07/18658AEA-0E92-44FF-B5EA-7E9415C2559D_1_201_a-29x50.jpeg 29w, https://news.artnet.com/app/news-upload/2023/07/18658AEA-0E92-44FF-B5EA-7E9415C2559D_1_201_a-1107x1920.jpeg 1107w, https://news.artnet.com/app/news-upload/2023/07/18658AEA-0E92-44FF-B5EA-7E9415C2559D_1_201_a.jpeg 1124w" sizes="(max-width: 591px) 100vw, 591px"></p><p id="caption-attachment-2380596">Screenshot of a post by Devon Rodriguez to Instagram stories.</p></div>
<h4><strong>Art Criticism and Parasocial Relationships</strong></h4>
<p>“If you don’t have anything nice to say, don’t say anything at all” was a phrase that commenters repeated a lot. Rodriguez’s art content makes people happy, so why be “negative?” Quite a few people posted variations on, “what is even the point of art critics?” So let me say what purpose an article like the one I wrote might serve.</p>
<p>First: With regard to the paintings themselves, simply repeating press-release hype isn’t healthy for anyone. It happens all the time that artists get stuck doing whatever first brought them success, and dealers or marketers encourage them to just do the same thing because it’s the easiest thing to sell, thereby undermining what could be a more enduring career.</p>
<p>As I repeat in the article, Rodriguez seems a gifted painter, in a photo-inspired realist style. At the same time, when it comes to the show I reviewed, “<a href="https://utaartistspace.com/exhibitions/underground/" target="_blank" rel="noopener">Underground,</a>” the subject matter is well-trodden territory. We have 100-plus years of painters doing subway scenes, from <a href="https://whitney.org/collection/works/1560" target="_blank" rel="noopener">Reginald Marsh</a> to <a href="https://www.jordancasteel.com/2018-2017" target="_blank" rel="noopener">Jordan Casteel</a>, so the question of what is different or exceptional about these particular versions of the theme is accented. Maybe this doesn’t matter to his audience, but it probably <em>does</em> matter to people who are interested in painting.</p>
<p>Still, my question was not even this. It was whether the paintings on their own were enough to explain his extraordinary popularity. And the answer to that question is clearly no.</p>
<div id="attachment_2373240"><p><img aria-describedby="caption-attachment-2373240" loading="lazy" src="https://news.artnet.com/app/news-upload/2023/10/devon-rodriguez-underground-1024x768.jpeg" alt="A visitor looks at paintings in &quot;Underground.&quot; P" width="1024" height="768" srcset="https://news.artnet.com/app/news-upload/2023/10/devon-rodriguez-underground-1024x768.jpeg 1024w, https://news.artnet.com/app/news-upload/2023/10/devon-rodriguez-underground-300x225.jpeg 300w, https://news.artnet.com/app/news-upload/2023/10/devon-rodriguez-underground-1536x1152.jpeg 1536w, https://news.artnet.com/app/news-upload/2023/10/devon-rodriguez-underground-50x38.jpeg 50w, https://news.artnet.com/app/news-upload/2023/10/devon-rodriguez-underground.jpeg 1800w" sizes="(max-width: 1024px) 100vw, 1024px"></p><p id="caption-attachment-2373240">A visitor looks at paintings in “Underground.” Photo by Ben Davis.</p></div>
<p>That brings me to the second point, which is where the case of Devon Rodriguez is specifically interesting. Basically, I’m arguing that we should think of his social media posts as part of his practice, to be reviewed in and of themselves. These are, after all, not just <em>how</em> he got famous; in some sense they are what he is really famous for. And they are in many cases clearly staged. (There is a <a href="https://www.reddit.com/r/ArtistLounge/comments/ldrbro/devon_rodriguez_the_artist_who_got_famous_for_his/" target="_blank" rel="noopener">long and robust online debate</a> by artists about how real his subway clips are.)</p>
<p>Take <a href="https://www.tiktok.com/@devonrodriguezart/video/7286157229861162286?lang=en" target="_blank" rel="noopener">his post</a> from October 4, where Rodriguez draws a dancer on the London Underground, who turns out to be Sabrina Bahsoon, a.k.a. “<a href="https://mashable.com/article/tiktok-tube-girl" target="_blank" rel="noopener">Tube Girl</a>.” “I love your moves—are you a professional dancer?” Rodriguez asks at the climax of the clip as he hands the drawing to Bahsoon, who has three quarters of a million TikTok followers and signed with <a href="https://www.thehivemanagement.com/new-faces/sabrina-bahsoon/#book" target="_blank" rel="noopener">The Hive&nbsp;modeling agency</a> this year. “Definitely not!” she replies, feigning surprise.</p>
<div>
<p><iframe loading="lazy" title="Look who I saw on the tube @Sabrina Bahsoon ✍🏼  #devonrodriguezart #shorts" width="500" height="281" src="https://www.youtube.com/embed/7ww3AN8dW4U?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe></p>
</div>

<p>What do his fans think is going on here? That Rodriguez happened to be in London, and happened to come upon another famous TikToker, and that she continued to dance in front of him for 30 minutes as he sat drawing her, with multiple cameras filming the two of them and his drawing pad, as he created a hyper-detailed portrait of Bahsoon that looks like it is sourced from a close-up photo? The comments are full of people marveling: “How did you do that? She wasn’t standing still. Absolutely incredible.” Or: “HOW DO YOU DRAW THEM WHEN THEY ARE MOVING A LOT?” Or: “Your work is amazing. I keep wondering how you keep the pencil steady on a moving train.” Great questions!</p>
<p>Is it “mean” to point out how fake this is? If there’s no criticism of it, here’s what I think will happen: All the marketing companies and PR people looking to piggyback on Rodriguez’s popularity will stuff his feed with more and more cringe celebrity content and half-baked promo ideas until his social-media presence is bled dry of whatever charm it has.</p>
<div id="attachment_2373239"><p><img aria-describedby="caption-attachment-2373239" loading="lazy" src="https://news.artnet.com/app/news-upload/2023/10/devon-rodriguez-video-1024x814.jpeg" alt="Video by UTA Artist Space telling the Devon Rodriguez story, shown in &quot;Underground.&quot; P" width="1024" height="814" srcset="https://news.artnet.com/app/news-upload/2023/10/devon-rodriguez-video-1024x814.jpeg 1024w, https://news.artnet.com/app/news-upload/2023/10/devon-rodriguez-video-300x239.jpeg 300w, https://news.artnet.com/app/news-upload/2023/10/devon-rodriguez-video-1536x1221.jpeg 1536w, https://news.artnet.com/app/news-upload/2023/10/devon-rodriguez-video-50x40.jpeg 50w, https://news.artnet.com/app/news-upload/2023/10/devon-rodriguez-video.jpeg 1800w" sizes="(max-width: 1024px) 100vw, 1024px"></p><p id="caption-attachment-2373239">Video by UTA Artist Space telling the Devon Rodriguez story, shown in “Underground.” Photo by Ben Davis.</p></div>
<p>And meanwhile, a lot of fans coming across art through his channel will get a totally confused idea of how contemporary art-celebrity works. Which brings me to the last and most important answer to the question of why I think it’s worth writing about Rodriguez seriously: Because he is a role model for a ton of young artists, and they deserve an actual assessment of what is going on.</p>
<p>“While Devon is instantly recognizable as a TikTok sensation, his story about his rise as a fine artist—from his childhood in the South Bronx to his Subway paintings and achieving Masterclass-worthy expertise—is something we are incredibly excited to share with the art world and beyond,” his agent, Arthur Lewis, wrote in <a href="https://d3kiriw2ovsgup.cloudfront.net/wp-content/uploads/2023/08/26153557/Press-Release_Devon-Rodriguez-Exhibition-Announcement-FINAL.pdf" target="_blank" rel="noopener">the press release</a> for “Underground.” Artists’ personal stories have long been part of how art is marketed, from Vincent van Gogh to Frida Kahlo, but in those cases, the artists’ paintings attracted interest first, and the biography became part of its legend as its fame grew. Today, personal biography and narrative are more important than ever in the gallery—most art comes equipped with some kind of story. But social media gives an added twist: Hordes of people can feel as if they have a relationship with a painter like Devon Rodriguez without ever having had any direct experience of his painting at all.</p>
<div id="attachment_2373728"><p><img aria-describedby="caption-attachment-2373728" loading="lazy" src="https://news.artnet.com/app/news-upload/2023/10/devon-rodriguez-1024x1004.jpg" alt="Devon Rodriguez with fans at the opening of &quot;Underground.&quot;" width="1024" height="1004" srcset="https://news.artnet.com/app/news-upload/2023/10/devon-rodriguez-1024x1004.jpg 1024w, https://news.artnet.com/app/news-upload/2023/10/devon-rodriguez-300x294.jpg 300w, https://news.artnet.com/app/news-upload/2023/10/devon-rodriguez-1536x1505.jpg 1536w, https://news.artnet.com/app/news-upload/2023/10/devon-rodriguez-50x50.jpg 50w, https://news.artnet.com/app/news-upload/2023/10/devon-rodriguez.jpg 1800w" sizes="(max-width: 1024px) 100vw, 1024px"></p><p id="caption-attachment-2373728">Devon Rodriguez with fans at the opening of “Underground.” Photo by Ben Davis.</p></div>
<p>“What if he was your son??” someone posted at me angrily. This comment is emblematic. It’s not the kind of thing one normally says about an artist getting a critical review (unless the criticism is extremely over the top and disproportionate to the status of the artist in question). Generally, the point of presenting an art show in public is to see if it can hold the attention of people who don’t directly know you.</p>
<p>But it seems to me that the majority of Rodriguez’s fans are most engaged by his appealing social-media persona, <em>not</em> his actual artworks. If this is the case, then it’s logical to think that it changes how criticism is perceived. His followers feel like I am attacking a person they like, not judging artworks or analyzing a media phenomenon. I think that explains the character of the reaction, which has a level of raw personal anger completely out of joint with what I wrote in my article.</p>
<p>Recently there’s been a lot of writing on the increasing currency of “<a href="https://www.theatlantic.com/family/archive/2023/04/parasocial-relationships-imaginary-connections-fans-celebrities/673645/" target="_blank" rel="noopener">parasocial relationships</a>” in media, that is, the imaginary, one-sided friendships people develop with celebrities and influencers in their heads. It seems to me that Devon Rodriguez’s title as the “most popular painter in the world” shows what a powerful cultural force a “parasocial aesthetic” can be—it’s probably more powerful (or at least more accessible) than interest in paint on canvas.</p>
<p>All the same, Devon Rodriguez’s art agents and PR handlers might gently tell him that, if one of the things you are selling is likability and good vibes, cheering on this kind of vicious reaction every time you get a review you don’t like is probably not a sustainable career path.</p>
<p><em>Follow <a href="https://www.facebook.com/artnet" target="_blank">Artnet News</a> on Facebook: </em></p>


<p><em><a href="http://link.artnet.com/join/522/newscta&amp;hash=8e9534fb495110baf97a368037111816" target="_blank">Want to stay ahead of the art world? Subscribe to our newsletter to get the breaking news, eye-opening interviews, and incisive critical takes that drive the conversation forward.</a></em>
								</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[RedPajama v2 Open Dataset with 30T Tokens for Training LLMs (192 pts)]]></title>
            <link>https://together.ai/blog/redpajama-data-v2</link>
            <guid>38077521</guid>
            <pubDate>Mon, 30 Oct 2023 23:38:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://together.ai/blog/redpajama-data-v2">https://together.ai/blog/redpajama-data-v2</a>, See on <a href="https://news.ycombinator.com/item?id=38077521">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page" role="main">
        
          
<article id="sections" data-page-sections="6358d155bd7bbd5929470f3f">
  
  
    
    


  


<div data-content-field="main-content" data-item-id="" data-test="page-section" data-section-theme="white" data-section-id="6358d155bd7bbd5929470f41" data-controller="SectionWrapperController" data-current-styles="{
&quot;imageOverlayOpacity&quot;: 0.15,
&quot;backgroundWidth&quot;: &quot;background-width--full-bleed&quot;,
&quot;sectionHeight&quot;: &quot;section-height--medium&quot;,
&quot;horizontalAlignment&quot;: &quot;horizontal-alignment--center&quot;,
&quot;verticalAlignment&quot;: &quot;vertical-alignment--middle&quot;,
&quot;contentWidth&quot;: &quot;content-width--wide&quot;,
&quot;sectionTheme&quot;: &quot;white&quot;,
&quot;sectionAnimation&quot;: &quot;none&quot;,
&quot;backgroundMode&quot;: &quot;image&quot;
}" data-current-context="{
&quot;video&quot;: {
&quot;playbackSpeed&quot;: 0.5,
&quot;filter&quot;: 1,
&quot;filterStrength&quot;: 0,
&quot;zoom&quot;: 0,
&quot;videoSourceProvider&quot;: &quot;none&quot;
},
&quot;backgroundImageId&quot;: null,
&quot;backgroundMediaEffect&quot;: null,
&quot;divider&quot;: null,
&quot;typeName&quot;: &quot;blog-basic-grid&quot;
}" data-animation="none">
  <article id="article-">
  
    <div data-layout-label="Post Body" data-type="item" id="item-653fcd044516ae2c146247c8"><div data-block-type="2" id="block-e96c46a09961732b7c75">
  <p>Today, we’re releasing a new version of the RedPajama dataset, with 30 trillion filtered and deduplicated tokens (100+ trillions raw) from 84 CommonCrawl dumps covering 5 languages, along with 40+ pre-computed data quality annotations that can be used for further filtering and weighting.&nbsp;</p><p>Over the last half a year, we have been pleased to see that RedPajama-1T, which we released in March, has ignited the creation of many new language models. So many people from the community have downloaded this 5TB dataset---more than 190,000 times and have been using them <a href="https://huggingface.co/search/full-text?q=redpajama"><span>in such creative ways</span></a>! RedPajama-1T consists of 1 trillion high-quality English tokens, but it was only the first step. Today, with the release of RedPajama-V2, we are making a further step towards the development of open datasets by releasing a massive, 30 trillion token web dataset. This is, to our best knowledge, the largest public dataset released specifically for LLM training. Even more excitingly, we include 40+ pre-computed quality annotations, allowing the community to further filter and weigh the data. Specifically, this release includes:</p><ul data-rte-list="default"><li><p>Over 100 billion text documents with 100+ trillion raw tokens from 84 CommonCrawl dumps;</p></li><li><p>40+ of the most widely used quality annotations pre-computed for a deduplicated 30 trillion tokens subset;</p></li><li><p>Five languages: English, French, Spanish, German, and Italian</p></li><li><p>All data processing scripts are open source and available on <a href="https://github.com/togethercomputer/RedPajama-Data"><span>GitHub</span></a>; all data are available on <a href="https://huggingface.co/datasets/togethercomputer/RedPajama-Data-V2"><span>HuggingFace</span></a>.</p></li></ul><h2>Why RedPajama-Data-v2 and How to Use it?</h2><p>A central ingredient to state-of-the-art open LLMs like Llama, Mistral, Falcon, MPT, and the RedPajama models is the large amounts of high-quality data that these models are trained on. For example, Llama 2 is trained on 2.4 trillion carefully curated tokens. The most prominent data sources are the crawls made publicly available by <a href="https://commoncrawl.org/"><span>CommonCrawl</span></a>. However, this data is crude and is not ideal for direct use for LLM training due to artifacts arising from the conversion of HTML to plain text, sources of generally low quality, and biases inherent to the distribution of content on the web. Getting the right dataset and data mixture is painful and any LLM developer has to go through the laborious, time-consuming, energy-intensive and expensive steps of processing and filtering this crude data. Although there have been several community projects around this effort, such as <a href="https://arxiv.org/abs/1910.10683"><span>C4</span></a>, <a href="https://huggingface.co/datasets/togethercomputer/RedPajama-Data-1T"><span>RedPajama-1T,</span></a> <a href="https://huggingface.co/datasets/tiiuae/falcon-refinedweb"><span>Refinedweb (Falcon)</span></a>, <a href="https://github.com/allenai/dolma"><span>Dolma (AI2)</span></a> and <a href="https://huggingface.co/datasets/cerebras/SlimPajama-627B"><span>SlimPajama</span></a>, many of them only cover a small portion of the CommonCrawl crawls; moreover, they represent a very specific way in which data are filtered.</p><p>With RedPajama-Data-v2, our goal is to lift this burden off the community and provide a pool of web data serving as a base from which high quality datasets for LLM training can be extracted and based on which LLM training data can be thoroughly researched. It provides, to our best knowledge, the most complete coverage on CommonCrawl (with 84 dumps processed). More importantly, we provide 40+ quality annotations — the result of different ML classifiers on data quality, minhash results that can be used for fuzzy deduplication, or heuristics such as “the fraction of words that contain no alphabetical character”. We provide our best effort implementations of quality annotations used in <a href="https://arxiv.org/abs/1910.10683"><span>C4</span></a>, <a href="https://arxiv.org/abs/2112.11446"><span>Gopher</span></a>, <a href="https://arxiv.org/abs/2305.13169"><span>Pretrainer’s Guide</span></a>, <a href="https://arxiv.org/abs/2306.01116"><span>RefinedWeb</span></a> and <a href="https://arxiv.org/abs/2302.03169"><span>Data Selection for Language Models via Importance Resampling</span></a>. These annotations provide a way for an LLM developer to easily slice and filter the data, combining these into a new data quality pipeline to create their own pre-training dataset.</p><p>Here are some examples! The following code snippets show how one can implement commonly used filtering rules in combination with the RedPajama-V2 dataset. For example, implementing the Gopher rules and use these to filter out documents that do not comply with the Gopher rules is as easy as:</p>
</div><div data-block-type="44" id="block-yui_3_17_2_1_1698681423568_26784"><pre><code>def gopher_rules_pass(sample) -&gt; bool:
    """ function returns True if the sample complies with Gopher rules """
    signals = json.loads(sample["quality_signals"])

    # rule 1: number of words between 50 and 10'000
    word_count = signals["rps_doc_word_count"][0][2]
    if word_count &lt; 50 or word_count &gt; 10_000:
        return False

    # rule 2: mean word length between 3 and 10
    mean_word_length = signals["rps_doc_mean_word_length"][0][2]
    if mean_word_length &lt; 3 or mean_word_length &gt; 10:
        return False

    # rule 2: symbol to word ratio below 0.1
    symbol_word_ratio = signals["rps_doc_symbol_to_word_ratio"][0][2]
    if  symbol_word_ratio &gt; 0.1:
        return False

    # rule 3: 90% of lines need to start without a bullet point
    n_lines = signals["ccnet_nlines"][0][2]
    n_lines_bulletpoint_start = sum(map(lambda ln: ln[2], signals["rps_lines_start_with_bulletpoint"]))
    if n_lines_bulletpoint_start / n_lines &gt; 0.9:
        return False

    # rule 4: the ratio between characters in the most frequent 2-gram and the total number 
    # of characters must be below 0.2
    top_2_gram_frac = signals["rps_doc_frac_chars_top_2gram"][0][2]
    if top_2_gram_frac &gt; 0.2:
        return False

    # rule 5: ...


    return True

ds = load_dataset("togethercomputer/RedPajama-Data-V2", name="sample")
filtered_dataset = list(filter(gopher_rules_pass, ds["train"]))</code></pre>

</div><div data-block-type="2" id="block-yui_3_17_2_1_1698681423568_28590">

<p>In the above snippet, we have used the “sample” config to load just a subset of the dataset. In case you want to load the full dataset for, e.g., snapshot 2023-14 in English, you can run: </p>



</div><div data-block-type="44" id="block-yui_3_17_2_1_1698681423568_30060"><pre><code>ds_iterator = load_dataset(
    "togethercomputer/RedPajama-Data-V2", 
    partition="head_middle",
    snapshots=["2023-14"], 
    languages=["en"], 
    name="default"
)</code></pre>

</div><div data-block-type="2" id="block-yui_3_17_2_1_1698681423568_30693">

<p>We can also use the rules used in RedPajama-v1 or C4:</p>



</div><div data-block-type="44" id="block-yui_3_17_2_1_1698681423568_32118">
<pre><code>def rpv1_rules_pass(sample) -&gt; bool:
    """ function returns True if the sample complies with the filtering rules used in RP-V1 """
    signals = json.loads(sample["quality_signals"])

    # rule 1: the wikipedia reference classifier score must be higher than 0.25
    wikiref_score = signals["rps_doc_ml_wikiref_score"][0][2]
    if wikiref_score &lt; 0.25:
        return False

    return True</code></pre>
<pre><code>def c4_rules_pass(sample) -&gt; bool:
    """ function returns True if the sample complies with the filtering rules used in C4 """
    signals = json.loads(sample["quality_signals"])

    # rule 1: at least 3 sentences
    num_sentences = signals["rps_doc_num_sentences"][0][2]
    if num_sentences &lt; 3:
        return False

    # rule 2: page may not contain bad words
    n_bad_words = signals["rps_doc_ldnoobw_words"][0][2]
    if n_bad_words &gt; 0:
        return False

    # rule 3: page may not contain placeholder "lorem ipsum" text
    lorem_ipsum = signals["rps_doc_lorem_ipsum"][0][2]
    if lorem_ipsum &gt; 0:
        return False

    # rule 4: ...

    return True</code></pre>
</div><div data-block-type="2" id="block-yui_3_17_2_1_1698681423568_32890">
  <p>In the current release, we include 40+ quality annotations, but we very much view this as a “living” project where new additions will be made over time as the field moves towards a better understanding of LLM training data. We hope the community provides feedback, and we are looking forward to continuing to enrich our current pool of annotations.</p><h3>Data Processing Steps</h3><p>RedPajama-V2 focuses on CommonCrawl. Other data sources such as Wikipedia are available in <a href="https://huggingface.co/datasets/togethercomputer/RedPajama-Data-1T"><span>RedPajama-V1</span></a>. We also encourage you to enrich your data mixture with the <a href="https://huggingface.co/datasets/bigcode/the-stack"><span>Stack</span></a> (by BigScience) for code and <a href="https://allenai.org/data/s2orc"><span>s2orc</span></a> (by AI2) for scientific articles. RedPajama-V2 is built from the ground up based on publicly available web data, consisting of 84 crawls provided by CommonCrawl. The core components that this dataset is made of, are the source data (plain text), 40+ quality annotations, and deduplication clusters.</p><h3>Creating the Source Data</h3><p>The first processing step in building this dataset is to pass each CommonCrawl snapshot through the <a href="https://aclanthology.org/2020.lrec-1.494/"><span>CCNet pipeline</span></a>. We choose this pipeline due to its light processing, aligning with our guiding principle of preserving as much information in the raw dataset as possible and allowing downstream model developers to filter or reweight the dataset. We use the language filter in CCNet and keep five languages in this release: English, French, Spanish, German and Italian. This processing step produces 100 billion individual text documents.&nbsp;</p><h3>Quality Annotations</h3><p>In addition to the text documents processed by CCNet, we compute over 40 of the most widely used quality annotations for the “head” and “middle” buckets. The primary purpose of these annotations is to allow downstream model developers to filter or reweight the dataset based on their criteria, and to foster research into how these annotations should be used. In addition, we also plan, with the help of the community, to include more quality signals over time. With this release, we publish a first set of quality annotations, which consists of our implementations of the most common quality annotations that are described in <a href="https://arxiv.org/abs/1910.10683"><span>C4</span></a>, <a href="https://arxiv.org/abs/2112.11446"><span>Gopher</span></a>, <a href="https://arxiv.org/abs/2305.13169"><span>Pretrainer’s Guide</span></a>, <a href="https://arxiv.org/abs/2306.01116"><span>RefinedWeb</span></a>, in addition to several signals described in <a href="https://arxiv.org/abs/2302.03169"><span>other papers</span></a>. These annotations fall into the following categories:</p><ul data-rte-list="default"><li><p>Quality signals indicating how <strong>natural</strong> a given piece of text is. This includes simple heuristic measures such as the number of sentences, the number of words, the fraction of all-caps words, among others.</p></li><li><p>Quality signals indicating how <strong>repetitive</strong> a given piece of text is. Here follow the Gopher rules (<a href="https://arxiv.org/abs/2112.11446"><span>Rae et al.</span></a>) and compute the fraction of characters that appear in duplicated word n-grams and the fraction of characters in the most frequent word n-gram appearing in the documents.</p></li><li><p><strong>Content-based</strong> quality signals are comprised of signals that take the content into account such as the density of words appearing in a list of blocked words (similar to C4), or documents which come from a list of domains flagged as containing potentially harmful or otherwise offensive content.&nbsp;</p></li><li><p><strong>ML-based</strong> quality signals revolve around the idea of measuring how similar a given text is to a high-quality domain. Here we use fasttext classifiers trained on various high quality domains such as Wikipedia, as well as importance weights as proposed by <a href="https://arxiv.org/abs/2302.03169"><span>Xie et al</span></a>.</p></li><li><p><strong>Deduplication</strong> signals with pre-computed Minhash signatures (with 128 permutations) which can be used for fuzzy deduplication at different degrees.</p></li></ul>
</div><div data-block-type="23" id="block-yui_3_17_2_1_1698681423568_42292">






  <table>
    <colgroup>
<col>
<col>
<col>
<col>
</colgroup>

<thead>
<tr>
<th>
<p><strong>Annotation Tag</strong></p>
</th>
<th>
<p><strong>Description</strong></p>
</th>
<th>
<p><strong>Category</strong></p>
</th>
<th>
<p><strong>Reference</strong></p>
</th>
</tr>
<tr>
<td>
<p>ccnet_bucket</p>
</td>
<td>
<p>head, middle or tail bucket of the perplexity score</p>
</td>
<td>
<p>CCNet</p>
</td>
<td>
<p><a href="https://aclanthology.org/2020.lrec-1.494/" target="_blank" rel="noopener">CCNet</a></p>
</td>
</tr>
<tr>
<td>
<p>ccnet_language_score</p>
</td>
<td>
<p>score of the language identification model</p>
</td>
<td>
<p>CCNet</p>
</td>
<td>
<p><a href="https://aclanthology.org/2020.lrec-1.494/" target="_blank" rel="noopener">CCNet</a></p>
</td>
</tr>
<tr>
<td>
<p>ccnet_length</p>
</td>
<td>
<p>number of characters</p>
</td>
<td>
<p>CCNet</p>
</td>
<td>
<p><a href="https://aclanthology.org/2020.lrec-1.494/" target="_blank" rel="noopener">CCNet</a></p>
</td>
</tr>
<tr>
<td>
<p>ccnet_nlines</p>
</td>
<td>
<p>number of lines</p>
</td>
<td>
<p>CCNet</p>
</td>
<td>
<p><a href="https://aclanthology.org/2020.lrec-1.494/" target="_blank" rel="noopener">CCNet</a></p>
</td>
</tr>
<tr>
<td>
<p>ccnet_original_length</p>
</td>
<td>
<p>number of characters before in-document line deduplication</p>
</td>
<td>
<p>CCNet</p>
</td>
<td>
<p><a href="https://aclanthology.org/2020.lrec-1.494/" target="_blank" rel="noopener">CCNet</a></p>
</td>
</tr>
<tr>
<td>
<p>ccnet_original_nlines</p>
</td>
<td>
<p>number of lines before in-document line deduplication</p>
</td>
<td>
<p>CCNet</p>
</td>
<td>
<p><a href="https://aclanthology.org/2020.lrec-1.494/" target="_blank" rel="noopener">CCNet</a></p>
</td>
</tr>
<tr>
<td>
<p>ccnet_perplexity</p>
</td>
<td>
<p>perplexity of an LM trained on Wikipedia</p>
</td>
<td>
<p>CCNet</p>
</td>
<td>
<p><a href="https://aclanthology.org/2020.lrec-1.494/" target="_blank" rel="noopener">CCNet</a></p>
</td>
</tr>
<tr>
<td>
<p>rps_doc_books_importance</p>
</td>
<td>
<p>Given a bag of {1,2}-wordgram model trained on Books p, and a model trained on the source domain q, This is the logarithm of the ratio p(doc)/q(doc).</p>
</td>
<td>
<p>ML Heuristics</p>
</td>
<td>
<p><a href="https://arxiv.org/abs/2302.03169" target="_blank" rel="noopener">Importance Resampling (Xie et al.)</a></p>
</td>
</tr>
<tr>
<td>
<p>rps_doc_openwebtext_importance</p>
</td>
<td>
<p>Given a bag of {1,2}-wordgram model trained on OpenWebText p, and a model trained on the source domain q, this is the logarithm of the ratio p(doc)/q(doc).</p>
</td>
<td>
<p>ML Heuristics</p>
</td>
<td>
<p><a href="https://arxiv.org/abs/2302.03169" target="_blank" rel="noopener">Importance Resampling (Xie et al.)</a></p>
</td>
</tr>
<tr>
<td>
<p>rps_doc_wikipedia_importance</p>
</td>
<td>
<p>Given a bag of {1,2}-wordgram model trained on Wikipedia articles p, and a model trained on the source domain q, this is the logarithm of the ratio p(doc)/q(doc).</p>
</td>
<td>
<p>ML Heuristics</p>
</td>
<td>
<p><a href="https://arxiv.org/abs/2302.03169" target="_blank" rel="noopener">Importance Resampling (Xie et al.)</a></p>
</td>
</tr>
</thead>
<tbody>
<tr>
<td>rps_doc_ml_wikiref_score</td>
<td>Fasttext classifier prediction for the document being a Wikipedia reference. This is the same fasttext model used in the RedPajama-1T dataset. Only applies to English data..</td>
<td>ML Heuristics</td>
<td><a href="https://arxiv.org/abs/2302.13971" target="_blank" rel="noopener">LLaMA</a>, <a href="https://huggingface.co/datasets/togethercomputer/RedPajama-Data-1T" target="_blank" rel="noopener">RedPajama-1T</a></td>
</tr>
<tr>
<td>rps_doc_ml_palm_score</td>
<td>Fasttext classifier prediction for the document being a Wikipedia article, OpenWebText sample or a RedPajama-V1 book. Only for English data.</td>
<td>ML Heuristics</td>
<td><a href="https://arxiv.org/abs/2204.02311" target="_blank" rel="noopener">PaLM</a>, <a href="https://arxiv.org/abs/2112.06905" target="_blank" rel="noopener">GLaM</a></td>
</tr>
<tr>
<td>rps_doc_ml_wikipedia_score</td>
<td>Fasttext classifier prediction for the document being a Wikipedia article. This is used for non-English data</td>
<td>ML Heuristics</td>
<td>-</td>
</tr>
<tr>
<td>rps_doc_curly_bracket</td>
<td>The ratio between the number of occurrences of '{' or '}' and the number of characters in the raw text.</td>
<td>Natural Language</td>
<td><a href="https://arxiv.org/abs/1910.10683" target="_blank" rel="noopener">C4</a></td>
</tr>
<tr>
<td>rps_doc_frac_all_caps_words</td>
<td>The fraction of words in the content that only consist of uppercase letters. This is based on the raw content.</td>
<td>Natural Language</td>
<td><a href="https://arxiv.org/abs/2305.13169" target="_blank" rel="noopener">Pretrainer’s Guide</a></td>
</tr>
<tr>
<td>rps_doc_frac_lines_end_with_ellipsis</td>
<td>The fraction of lines that end with an ellipsis, where an ellipsis is defined as either "..." or "…".</td>
<td>Natural Language</td>
<td><a href="https://arxiv.org/abs/2306.01116" target="_blank" rel="noopener">RefinedWeb</a>,<a href="https://arxiv.org/abs/2112.11446" target="_blank" rel="noopener">Gopher</a></td>
</tr>
<tr>
<td>rps_doc_frac_no_alph_words</td>
<td>The fraction of words that contain no alphabetical character.</td>
<td>Natural Language</td>
<td><a href="https://arxiv.org/abs/2306.01116" target="_blank" rel="noopener">RefinedWeb</a>,<a href="https://arxiv.org/abs/2112.11446" target="_blank" rel="noopener">Gopher</a></td>
</tr>
<tr>
<td>rps_doc_lorem_ipsum</td>
<td>The ratio between the number of occurrences of 'lorem ipsum' and the number of characters in the content after normalisation.</td>
<td>Natural Language</td>
<td><a href="https://arxiv.org/abs/1910.10683" target="_blank" rel="noopener">C4</a></td>
</tr>
<tr>
<td>rps_doc_mean_word_length</td>
<td>The mean length of words in the content after normalisation.</td>
<td>Natural Language</td>
<td><a href="https://arxiv.org/abs/2306.01116" target="_blank" rel="noopener">RefinedWeb</a>,<a href="https://arxiv.org/abs/2112.11446" target="_blank" rel="noopener">Gopher</a></td>
</tr>
<tr>
<td>rps_doc_stop_word_fraction</td>
<td>The ratio between the number of stop words and the number of words in the document. Stop words are obtained from<a href="https://github.com/6/stopwords-json" target="_blank" rel="noopener"> https://github.com/6/stopwords-json</a>.</td>
<td>Natural Language</td>
<td><a href="https://arxiv.org/abs/2306.01116" target="_blank" rel="noopener">RefinedWeb</a>,<a href="https://arxiv.org/abs/2112.11446" target="_blank" rel="noopener">Gopher</a></td>
</tr>
<tr>
<td>rps_doc_symbol_to_word_ratio</td>
<td>The ratio of symbols to words in the content.. Symbols are defined "#", "...", and "…".</td>
<td>Natural Language</td>
<td><a href="https://arxiv.org/abs/2306.01116" target="_blank" rel="noopener">RefinedWeb</a>,<a href="https://arxiv.org/abs/2112.11446" target="_blank" rel="noopener">Gopher</a></td>
</tr>
<tr>
<td>rps_doc_frac_unique_words</td>
<td>The fraction of unique words in the content. This is also known as the degeneracy of a text sample. Calculated based on the normalised content.</td>
<td>Natural Language</td>
<td><a href="https://arxiv.org/abs/2305.13169" target="_blank" rel="noopener">Pretrainer’s Guide</a></td>
</tr>
<tr>
<td>rps_doc_unigram_entropy</td>
<td>The entropy of the unigram distribution of the content. This measures the diversity of the content and is computed using sum(-x / total * log(x / total)) where the sum is taken over counts of unique words in the normalised content.</td>
<td>Natural Language</td>
<td>-</td>
</tr>
<tr>
<td>rps_doc_word_count</td>
<td>The number of words in the content after normalisation.</td>
<td>Natural Language</td>
<td><a href="https://arxiv.org/abs/2306.01116" target="_blank" rel="noopener">RefinedWeb</a>,<a href="https://arxiv.org/abs/2112.11446" target="_blank" rel="noopener">Gopher</a></td>
</tr>
<tr>
<td>rps_lines_ending_with_terminal_punctution_mark</td>
<td>Indicates whether a line ends with a terminal punctuation mark. A terminal punctuation mark is defined as one o: ".", "!", "?", "”".</td>
<td>Natural Language</td>
<td><a href="https://arxiv.org/abs/1910.10683" target="_blank" rel="noopener">C4</a></td>
</tr>
<tr>
<td>rps_lines_javascript_counts</td>
<td>The number of occurrences of the word "javascript" in each line.</td>
<td>Natural Language</td>
<td><a href="https://arxiv.org/abs/1910.10683" target="_blank" rel="noopener">C4</a></td>
</tr>
<tr>
<td>rps_lines_num_words</td>
<td>The number of words in each line. This is computed based on the normalised text.</td>
<td>Natural Language</td>
<td><a href="https://arxiv.org/abs/1910.10683" target="_blank" rel="noopener">C4</a>, <a href="https://arxiv.org/abs/2306.01116" target="_blank" rel="noopener">RefinedWeb</a></td>
</tr>
<tr>
<td>rps_lines_numerical_chars_fraction</td>
<td>The ratio between number of numerical characters and total number of characters in each line. This is based on the normalised content.</td>
<td>Natural Language</td>
<td><a href="https://arxiv.org/abs/2306.01116" target="_blank" rel="noopener">RefinedWeb</a></td>
</tr>
<tr>
<td>rps_lines_start_with_bulletpoint</td>
<td>Whether the lines that start with a bullet point symbol. The following set of unicodes are considered a bullet point: \u2022 (bullet point), \u2023 (triangular bullet point), \u25B6 (black right pointing triangle), \u25C0 (black left pointing triangle), \u25E6 (white bullet point), \u25A0 (black square), \u25A1 (white square), \u25AA (black small square), \u25AB (white small square), \u2013 (en dash).</td>
<td>Natural Language</td>
<td><a href="https://arxiv.org/abs/2306.01116" target="_blank" rel="noopener">RefinedWeb</a>,<a href="https://arxiv.org/abs/2112.11446" target="_blank" rel="noopener">Gopher</a></td>
</tr>
<tr>
<td>rps_lines_uppercase_letter_fraction</td>
<td>The ratio between number of uppercase letters and total number of characters in each line. This is based on the raw text.</td>
<td>Natural Language</td>
<td><a href="https://arxiv.org/abs/2306.01116" target="_blank" rel="noopener">RefinedWeb</a></td>
</tr>
<tr>
<td>rps_doc_num_sentences</td>
<td>The number of sentences in the content. This is calculated using the regular expression r'\b[^.!?]+[.!?]*'.</td>
<td>Natural Language</td>
<td><a href="https://arxiv.org/abs/1910.10683" target="_blank" rel="noopener">C4</a></td>
</tr>
<tr>
<td>rps_doc_frac_chars_dupe_10grams</td>
<td>The fraction of characters in duplicate word 10grams.&nbsp;</td>
<td>Repetitiveness</td>
<td><a href="https://arxiv.org/abs/2306.01116" target="_blank" rel="noopener">RefinedWeb</a>,<a href="https://arxiv.org/abs/2112.11446" target="_blank" rel="noopener">Gopher</a></td>
</tr>
<tr>
<td>rps_doc_frac_chars_dupe_5grams</td>
<td>The fraction of characters in duplicate word 5grams.&nbsp;</td>
<td>Repetitiveness</td>
<td><a href="https://arxiv.org/abs/2306.01116" target="_blank" rel="noopener">RefinedWeb</a>,<a href="https://arxiv.org/abs/2112.11446" target="_blank" rel="noopener">Gopher</a></td>
</tr>
<tr>
<td>rps_doc_frac_chars_dupe_6grams</td>
<td>The fraction of characters in duplicate word 6grams.</td>
<td>Repetitiveness</td>
<td><a href="https://arxiv.org/abs/2306.01116" target="_blank" rel="noopener">RefinedWeb</a>,<a href="https://arxiv.org/abs/2112.11446" target="_blank" rel="noopener">Gopher</a></td>
</tr>
<tr>
<td>rps_doc_frac_chars_dupe_7grams</td>
<td>The fraction of characters in duplicate word 7grams.</td>
<td>Repetitiveness</td>
<td><a href="https://arxiv.org/abs/2306.01116" target="_blank" rel="noopener">RefinedWeb</a>,<a href="https://arxiv.org/abs/2112.11446" target="_blank" rel="noopener">Gopher</a></td>
</tr>
<tr>
<td>rps_doc_frac_chars_dupe_8grams</td>
<td>The fraction of characters in duplicate word 8grams.</td>
<td>Repetitiveness</td>
<td><a href="https://arxiv.org/abs/2306.01116" target="_blank" rel="noopener">RefinedWeb</a>,<a href="https://arxiv.org/abs/2112.11446" target="_blank" rel="noopener">Gopher</a></td>
</tr>
<tr>
<td>rps_doc_frac_chars_dupe_9grams</td>
<td>The fraction of characters in duplicate word 9grams.&nbsp;</td>
<td>Repetitiveness</td>
<td><a href="https://arxiv.org/abs/2306.01116" target="_blank" rel="noopener">RefinedWeb</a>,<a href="https://arxiv.org/abs/2112.11446" target="_blank" rel="noopener">Gopher</a></td>
</tr>
<tr>
<td>rps_doc_frac_chars_top_2gram</td>
<td>The fraction of characters in the top word 2gram.</td>
<td>Repetitiveness</td>
<td><a href="https://arxiv.org/abs/2306.01116" target="_blank" rel="noopener">RefinedWeb</a>,<a href="https://arxiv.org/abs/2112.11446" target="_blank" rel="noopener">Gopher</a></td>
</tr>
<tr>
<td>rps_doc_frac_chars_top_3gram</td>
<td>The fraction of characters in the top word 3gram.</td>
<td>Repetitiveness</td>
<td><a href="https://arxiv.org/abs/2306.01116" target="_blank" rel="noopener">RefinedWeb</a>,<a href="https://arxiv.org/abs/2112.11446" target="_blank" rel="noopener">Gopher</a></td>
</tr>
<tr>
<td>rps_doc_frac_chars_top_4gram</td>
<td>The fraction of characters in the top word 4gram.</td>
<td>Repetitiveness</td>
<td><a href="https://arxiv.org/abs/2306.01116" target="_blank" rel="noopener">RefinedWeb</a>,<a href="https://arxiv.org/abs/2112.11446" target="_blank" rel="noopener">Gopher</a></td>
</tr>
<tr>
<td>rps_doc_ldnoobw_words</td>
<td>The number of sequences of words that are contained in the List-of-Dirty-Naughty-Obscene-and-Otherwise-Bad-Words blocklist. The blocklist is obtained from<a href="https://github.com/LDNOOBW/List-of-Dirty-Naughty-Obscene-and-Otherwise-Bad-Words" target="_blank" rel="noopener"> https://github.com/LDNOOBW/List-of-Dirty-Naughty-Obscene-and-Otherwise-Bad-Words</a></td>
<td>Sensitive / toxic content</td>
<td><a href="https://arxiv.org/abs/1910.10683" target="_blank" rel="noopener">C4</a></td>
</tr>
<tr>
<td>rps_doc_ut1_blacklist</td>
<td>A categorical id corresponding to the list of categories of the domain of the document. Categories are obtained from the UT1 blacklist. The list is obtained from<a href="https://dsi.ut-capitole.fr/blacklists/" target="_blank" rel="noopener"> https://dsi.ut-capitole.fr/blacklists/</a></td>
<td>Sensitive / toxic content</td>
<td><a href="https://arxiv.org/abs/2306.01116" target="_blank" rel="noopener">RefinedWeb</a></td>
</tr>
<tr>
<td>minhash_signature_0.7</td>
<td>Banded minhash signature of the document, for fuzzy deduplication at Jaccard similarity 0.7. The signature is based on 128 hash functions and grouped into 14 bands and 9 rows for LSH.</td>
<td>Deduplication</td>
<td><a href="https://huggingface.co/datasets/cerebras/SlimPajama-627B" target="_blank" rel="noopener">SlimPajama</a>,<a href="https://arxiv.org/abs/2306.01116" target="_blank" rel="noopener">RefinedWeb</a></td>
</tr>
<tr>
<td>minhash_signature_0.8</td>
<td>Banded minhash signature of the document, for fuzzy deduplication at Jaccard similarity 0.8. The signature is based on 128 hash functions and grouped into 9 bands and 13 rows for LSH.</td>
<td>Deduplication</td>
<td><a href="https://huggingface.co/datasets/cerebras/SlimPajama-627B" target="_blank" rel="noopener">SlimPajama</a>,<a href="https://arxiv.org/abs/2306.01116" target="_blank" rel="noopener">RefinedWeb</a></td>
</tr>
<tr>
<td>minhash_signature_0.9</td>
<td>Banded minhash signature of the document, for fuzzy deduplication at Jaccard similarity 0.9. The signature is based on 128 hash functions and grouped into 5 bands and 25 rows for LSH..</td>
<td>Deduplication</td>
<td><a href="https://huggingface.co/datasets/cerebras/SlimPajama-627B" target="_blank" rel="noopener">SlimPajama</a>,<a href="https://arxiv.org/abs/2306.01116" target="_blank" rel="noopener">RefinedWeb</a></td>
</tr>
<tr>
<td>minhash_signature_1.0</td>
<td>Banded minhash signature of the document, for fuzzy deduplication at Jaccard similarity 1.0. The signature is based on 128 hash functions and grouped into 1 band and 128 rows for LSH.</td>
<td>Deduplication</td>
<td><a href="https://huggingface.co/datasets/cerebras/SlimPajama-627B" target="_blank" rel="noopener">SlimPajama</a>,<a href="https://arxiv.org/abs/2306.01116" target="_blank" rel="noopener">RefinedWeb</a></td>
</tr>
</tbody>
</table>
</div><div data-block-type="2" id="block-yui_3_17_2_1_1698681423568_42372">
  <p>In addition to these minhash signatures, we conduct exact deduplication with a Bloom filter over the sha1 hash-digest of the document. These are stored as a separate quality annotation file to allow the original non-duplicated distribution to be recovered to facilitate research in this direction.</p><h3>Dataset Statistics</h3><p>RedPajama-v2 processed 84 CommonCrawl crawls and consists of 113B documents in the five languages (English, German, French, Spanish, and Italian). While we keep the tail partition of the resulting data, consisting of an estimated 80B documents, we also compute the number of documents and tokens for the head and middle partitions (before and after deduplication). Interestingly, while this reduces the token count by 60%, the number of documents decreases disproportionately more by 71%, indicating that the tail documents are generally shorter.</p>
</div><div data-block-type="23" id="block-yui_3_17_2_1_1698683165778_15314">






<table>
  <colgroup>
<col>
<col>
<col>
</colgroup>

  <tbody><tr>
    <th>Partition</th>
    <th># Documents</th>
    <th>Estimated Token Count</th>
  </tr>
  <tr>
    <td>head + middle + tail</td>
    <td>113.3B</td>
    <td>123.7T</td>
  </tr>
  <tr>
    <td>head + middle</td>
    <td>32.8B</td>
    <td>50.7T</td>
  </tr>
  <tr>
    <td>head + middle (deduplicated)</td>
    <td>20.8B</td>
    <td>30.4T</td>
  </tr>
</tbody></table>


</div><div data-block-type="2" id="block-yui_3_17_2_1_1698683165778_15386">

<p>We further deduplicated the head+middle documents using a Bloom filter, which leads to a reduction in the dataset size by roughly 40%. In the following figure, we show the development of the number of documents in the head+middle partition, as a function of the point in time of the crawl. What stands out here is that there is a relatively stable number until 2018, and a significantly smaller number of documents between 2014 and 2016 (up to 10x for, e.g., German). It is also worth noting how the number of unique documents over time develops. Specifically, since we ran the deduplication from the newest snapshot to the oldest, one expects an increasingly smaller number of unique documents in the corpus, which can be observed from the figure below (note the log-scale). However, it is worth pointing out the sudden drop in unique documents occurring for the crawls between 2014 and 2017. We believe that this can be explained from a different list of seeds used by the CommonCrawl web crawler during that period.&nbsp;</p>



</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1698683165778_33695">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/f4a00f65-e85c-489c-9a1d-0d556cbdb3e5/ccsnapshot.png" data-image="https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/f4a00f65-e85c-489c-9a1d-0d556cbdb3e5/ccsnapshot.png" data-image-dimensions="1600x500" data-image-focal-point="0.5,0.5" alt="" data-load="false" src="https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/f4a00f65-e85c-489c-9a1d-0d556cbdb3e5/ccsnapshot.png" width="1600" height="500" sizes="100vw" srcset="https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/f4a00f65-e85c-489c-9a1d-0d556cbdb3e5/ccsnapshot.png?format=100w 100w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/f4a00f65-e85c-489c-9a1d-0d556cbdb3e5/ccsnapshot.png?format=300w 300w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/f4a00f65-e85c-489c-9a1d-0d556cbdb3e5/ccsnapshot.png?format=500w 500w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/f4a00f65-e85c-489c-9a1d-0d556cbdb3e5/ccsnapshot.png?format=750w 750w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/f4a00f65-e85c-489c-9a1d-0d556cbdb3e5/ccsnapshot.png?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/f4a00f65-e85c-489c-9a1d-0d556cbdb3e5/ccsnapshot.png?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/f4a00f65-e85c-489c-9a1d-0d556cbdb3e5/ccsnapshot.png?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">
                
            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="2" id="block-yui_3_17_2_1_1698683165778_34046">

<p>In the next figure, we show the distribution of the number of tokens per document, for the tail and the head+middle partitions. With a median per-document token count of 380, the tail documents are considerably shorter than the head+middle documents where the median is 741.</p>



</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1698683165778_36781">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/4d71048e-7502-4c9f-bf35-6351607a7e91/image9.png" data-image="https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/4d71048e-7502-4c9f-bf35-6351607a7e91/image9.png" data-image-dimensions="800x500" data-image-focal-point="0.5,0.5" alt="" data-load="false" src="https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/4d71048e-7502-4c9f-bf35-6351607a7e91/image9.png" width="800" height="500" sizes="100vw" srcset="https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/4d71048e-7502-4c9f-bf35-6351607a7e91/image9.png?format=100w 100w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/4d71048e-7502-4c9f-bf35-6351607a7e91/image9.png?format=300w 300w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/4d71048e-7502-4c9f-bf35-6351607a7e91/image9.png?format=500w 500w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/4d71048e-7502-4c9f-bf35-6351607a7e91/image9.png?format=750w 750w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/4d71048e-7502-4c9f-bf35-6351607a7e91/image9.png?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/4d71048e-7502-4c9f-bf35-6351607a7e91/image9.png?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/4d71048e-7502-4c9f-bf35-6351607a7e91/image9.png?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">
                
            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="2" id="block-yui_3_17_2_1_1698683165778_37132">

<p>While the raw documents provide the basis for the RedPajama-V2 corpus, a further central component are the quality signals which we have computed for all documents in the head+middle partition. In the figure below, we show the distribution of the quality signals computed for documents from the 2023-06 snapshot.</p>



</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1698683165778_39354">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/9821b312-cd22-4a39-9c48-200384da9cd8/image8.png" data-image="https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/9821b312-cd22-4a39-9c48-200384da9cd8/image8.png" data-image-dimensions="1500x700" data-image-focal-point="0.5,0.5" alt="" data-load="false" src="https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/9821b312-cd22-4a39-9c48-200384da9cd8/image8.png" width="1500" height="700" sizes="100vw" srcset="https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/9821b312-cd22-4a39-9c48-200384da9cd8/image8.png?format=100w 100w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/9821b312-cd22-4a39-9c48-200384da9cd8/image8.png?format=300w 300w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/9821b312-cd22-4a39-9c48-200384da9cd8/image8.png?format=500w 500w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/9821b312-cd22-4a39-9c48-200384da9cd8/image8.png?format=750w 750w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/9821b312-cd22-4a39-9c48-200384da9cd8/image8.png?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/9821b312-cd22-4a39-9c48-200384da9cd8/image8.png?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/9821b312-cd22-4a39-9c48-200384da9cd8/image8.png?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">
                
            </p>
          </div>
        
          
        

        
          
          <figcaption>
            <p>Histograms of CCNet quality Signals for English documents from the 2023-06 snapshot.</p>
          </figcaption>
        
      
        </figure>
      

    </div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1698683165778_43389">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/d4d54f27-72e9-417a-b1e3-526cbdddd13b/image10.png" data-image="https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/d4d54f27-72e9-417a-b1e3-526cbdddd13b/image10.png" data-image-dimensions="1500x700" data-image-focal-point="0.5,0.5" alt="" data-load="false" src="https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/d4d54f27-72e9-417a-b1e3-526cbdddd13b/image10.png" width="1500" height="700" sizes="100vw" srcset="https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/d4d54f27-72e9-417a-b1e3-526cbdddd13b/image10.png?format=100w 100w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/d4d54f27-72e9-417a-b1e3-526cbdddd13b/image10.png?format=300w 300w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/d4d54f27-72e9-417a-b1e3-526cbdddd13b/image10.png?format=500w 500w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/d4d54f27-72e9-417a-b1e3-526cbdddd13b/image10.png?format=750w 750w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/d4d54f27-72e9-417a-b1e3-526cbdddd13b/image10.png?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/d4d54f27-72e9-417a-b1e3-526cbdddd13b/image10.png?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/d4d54f27-72e9-417a-b1e3-526cbdddd13b/image10.png?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">
                
            </p>
          </div>
        
          
        

        
          
          <figcaption>
            <p>Histograms of ML heuristics quality Signals for English documents from the 2023-06 snapshot.</p>
          </figcaption>
        
      
        </figure>
      

    </div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1698683165778_46468">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/7e4cacb1-0822-4f89-aa83-c3ae0c52a38b/image6.png" data-image="https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/7e4cacb1-0822-4f89-aa83-c3ae0c52a38b/image6.png" data-image-dimensions="1429x1999" data-image-focal-point="0.5,0.5" alt="" data-load="false" src="https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/7e4cacb1-0822-4f89-aa83-c3ae0c52a38b/image6.png" width="1429" height="1999" sizes="100vw" srcset="https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/7e4cacb1-0822-4f89-aa83-c3ae0c52a38b/image6.png?format=100w 100w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/7e4cacb1-0822-4f89-aa83-c3ae0c52a38b/image6.png?format=300w 300w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/7e4cacb1-0822-4f89-aa83-c3ae0c52a38b/image6.png?format=500w 500w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/7e4cacb1-0822-4f89-aa83-c3ae0c52a38b/image6.png?format=750w 750w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/7e4cacb1-0822-4f89-aa83-c3ae0c52a38b/image6.png?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/7e4cacb1-0822-4f89-aa83-c3ae0c52a38b/image6.png?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/7e4cacb1-0822-4f89-aa83-c3ae0c52a38b/image6.png?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">
                
            </p>
          </div>
        
          
        

        
          
          <figcaption>
            <p>Histograms of natural language quality Signals for English documents from the 2023-06 snapshot.</p>
          </figcaption>
        
      
        </figure>
      

    </div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1698683165778_49611">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/8efd8ad6-8e29-4b8d-b9cd-21d66c1035d6/image4.png" data-image="https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/8efd8ad6-8e29-4b8d-b9cd-21d66c1035d6/image4.png" data-image-dimensions="1500x1050" data-image-focal-point="0.5,0.5" alt="" data-load="false" src="https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/8efd8ad6-8e29-4b8d-b9cd-21d66c1035d6/image4.png" width="1500" height="1050" sizes="100vw" srcset="https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/8efd8ad6-8e29-4b8d-b9cd-21d66c1035d6/image4.png?format=100w 100w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/8efd8ad6-8e29-4b8d-b9cd-21d66c1035d6/image4.png?format=300w 300w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/8efd8ad6-8e29-4b8d-b9cd-21d66c1035d6/image4.png?format=500w 500w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/8efd8ad6-8e29-4b8d-b9cd-21d66c1035d6/image4.png?format=750w 750w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/8efd8ad6-8e29-4b8d-b9cd-21d66c1035d6/image4.png?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/8efd8ad6-8e29-4b8d-b9cd-21d66c1035d6/image4.png?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/8efd8ad6-8e29-4b8d-b9cd-21d66c1035d6/image4.png?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">
                
            </p>
          </div>
        
          
        

        
          
          <figcaption>
            <p>Histograms of quality signals measuring the repetitiveness of a text document. For English documents from the 2023-06 snapshot.</p>
          </figcaption>
        
      
        </figure>
      

    </div><div data-block-type="2" id="block-yui_3_17_2_1_1698683165778_39713">
  <h3>Dataset Structure</h3><p>The core of the dataset is composed of the text documents, accompanied by the quality annotations and deduplication clusters. The structure largely follows the one defined by CCNet. Specifically, the documents for a given CommonCrawl snapshot (say, e.g., 2018-43) are partitioned into 5k shards where the key indicates the shard, language of the document, and the perplexity bucket (partition). The quality annotations and duplicates follow the same logic and “mirror” the source filenames:</p>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1698683165778_85785">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/d88d8402-b8ca-4251-9c38-2617b7e7fbc1/image12.png" data-image="https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/d88d8402-b8ca-4251-9c38-2617b7e7fbc1/image12.png" data-image-dimensions="1200x1468" data-image-focal-point="0.5,0.5" alt="" data-load="false" src="https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/d88d8402-b8ca-4251-9c38-2617b7e7fbc1/image12.png" width="1200" height="1468" sizes="100vw" srcset="https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/d88d8402-b8ca-4251-9c38-2617b7e7fbc1/image12.png?format=100w 100w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/d88d8402-b8ca-4251-9c38-2617b7e7fbc1/image12.png?format=300w 300w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/d88d8402-b8ca-4251-9c38-2617b7e7fbc1/image12.png?format=500w 500w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/d88d8402-b8ca-4251-9c38-2617b7e7fbc1/image12.png?format=750w 750w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/d88d8402-b8ca-4251-9c38-2617b7e7fbc1/image12.png?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/d88d8402-b8ca-4251-9c38-2617b7e7fbc1/image12.png?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/d88d8402-b8ca-4251-9c38-2617b7e7fbc1/image12.png?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">
                
            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="2" id="block-yui_3_17_2_1_1698683165778_86135">

<p>The document files are left untouched and correspond 1-to-1 to the CCNet output, including the metadata fields. The quality signals, on the other hand, include document ids, metadata, and the quality signals themselves:</p>



</div><div data-block-type="44" id="block-yui_3_17_2_1_1698683165778_61898"><pre><code>{
  "id": "2018-43/0000/en_head.json.gz/0", 
  "id_int": 7972430436813205988, 
  "metadata":{
    "cc_segment": "crawl-data/...",
    "cc_net_source": "2018-43/0000/en_head.json.gz",
    "url": "...",
    "source_domain": "...",
    "language": "en",
    "snapshot_id": "2018-43"
  },
  "quality_signals": {
    "ccnet_original_length": [[0, 7033, 8711.0]],
    "...": "...",
    "rps_doc_stop_word_fraction": [[0, 7033, 0.45121107]],
    "rps_lines_num_words": [[0, 25, 2], ..., [6980, 7033, 10]]
  }
}</code></pre>

</div><div data-block-type="2" id="block-yui_3_17_2_1_1698683165778_61964">
  <p>Since we have quality signals that can characterise the quality on a line level (e.g., whether a line ends in a terminal punctuation mark), or on a document level we choose the logic used by <a href="https://github.com/allenai/dolma"><span>Dolma</span></a>, allowing for a unified representation of different types of signals. Specifically, each score corresponds to an array of tuples `(start, end, score)` where start and end correspond to the span in the document string where the score “applies”.</p><h3>A “Living” Dataset</h3><p>We envision the release of this dataset to be the start of a larger, community-driven development of large-scale datasets for LLMs. Along the data axis, we hope to continuously grow this pool and enrich it with additional domains and new snapshots over time. Along the data quality side, we view the current set of quality signals as an initial base set of signals that we hope to grow with new additions. In that sense, RedPajama-v2 should be seen as a pool that grows over time as the community learns more about harnessing the data for training performant language models. In the future, we plan to add more quality annotations such as: Contamination annotations against popular LLM benchmarks, topic modelling and classification annotations for each document, and other annotations that the community is excited about!</p><h3>Model Building at Together</h3><p>Together is building open models based on RedPajama-Dataset-V2, and we also help companies and organizations build custom models built with principled mixes of open and their proprietary datasets. If you are evaluating solutions to build models, please contact us here.&nbsp;</p><h2>Acknowledgments</h2><p>We are appreciative to so many partners and collaborators that together are pushing forward the frontier of open LLM models.&nbsp;</p><ul data-rte-list="default"><li><p>Thank you to the OLMo team at <a href="https://allenai.org/"><span>AI2</span></a> and friends at <a href="https://opengpt-x.de/en/"><span>OpenGPT-X</span></a> for the insightful discussions about datasets and data quality! Also for everyone who builds on the RedPajama dataset, including <a href="https://www.cerebras.net/">Cerebras</a> for their SlimPajama efforts, and the over 500 models built on RedPajama to date by the open-source AI community.</p></li><li><p>We are grateful to the great team at <a href="https://www.eleuther.ai/"><span>EleutherAI</span></a> for paving the path on open training datasets with The Pile and for open-sourcing code we use in training some of the RedPajama models.&nbsp;</p></li><li></li></ul>
</div></div>
  
</article>

</div>

  
</article>


          

          
            
              

            
          
        
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Grug Brained Developer (2022) (417 pts)]]></title>
            <link>https://grugbrain.dev/</link>
            <guid>38076886</guid>
            <pubDate>Mon, 30 Oct 2023 22:33:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://grugbrain.dev/">https://grugbrain.dev/</a>, See on <a href="https://news.ycombinator.com/item?id=38076886">Hacker News</a></p>
<div id="readability-page-1" class="page">
    <div>
  <p><a href="https://www.redbubble.com/i/sticker/Programmer-Grug-by-colossalbreaker/42915272.EJUG5">
    <img alt="grug" src="https://grugbrain.dev/grug.png">
  </a></p><h2>
     The Grug Brained Developer<br>
     <small>A layman's guide to thinking like the self-aware smol brained</small>
  </h2>
</div>
<h2>Introduction</h2>
<p>this collection of thoughts on software development gathered by grug brain developer</p>
<p>grug brain developer not so smart, but grug brain developer program many long year and learn some things
although mostly still confused</p>
<p>grug brain developer try collect learns into small, easily digestible and funny page, not only for you, the young grug, but also for him
because as grug brain developer get older he forget important things, like what had for breakfast or if put pants on</p>
<p>big brained developers are many, and some not expected to like this, make sour face</p>
<p><em>THINK</em> they are big brained developers many, many more, and more even definitely probably maybe not like this, many
sour face (such is internet)</p>
<p>(note: grug once think big brained but learn hard way)</p>
<p>is fine!</p>
<p>is free country sort of and end of day not really matter too much, but grug hope you fun reading and maybe learn from
many, many mistake grug make over long program life</p>
<h2><a name="grug-on-complexity"></a><a href="#grug-on-complexity">The Eternal Enemy: Complexity</a></h2>
<p>apex predator of grug is complexity</p>
<p>complexity bad</p>
<p>say again:</p>
<p>complexity <em>very</em> bad</p>
<p><em>you</em> say now:</p>
<p>complexity <em>very</em>, <em>very</em> bad</p>
<p>given choice between complexity or one on one against t-rex, grug take t-rex: at least grug see t-rex</p>
<p>complexity is spirit demon that enter codebase through well-meaning but ultimately very clubbable non grug-brain
developers and project managers who not fear complexity spirit demon or even know about sometime</p>
<p>one day code base understandable and grug can get work done, everything good!</p>
<p>next day impossible: complexity demon spirit has entered code and very dangerous situation!</p>
<p>grug no able see complexity demon, but grug sense presence in code base</p>
<p>demon complexity spirit mocking him make change here break unrelated thing there what!?! mock mock mock ha ha so funny
grug love programming and not becoming shiney rock speculator like grug senior advise</p>
<p>club not work on demon spirit complexity and bad idea actually hit developer who let spirit in with club: sometimes grug
himself!</p>
<p>sadly, often grug himself</p>
<p>so grug say again and say often: complexity <em>very</em>, <em>very</em> bad</p>
<h2><a name="grug-on-saying-no"></a><a href="#grug-on-saying-no">Saying No</a></h2>
<p>best weapon against complexity spirit demon is magic word: "no"</p>
<p>"no, grug not build that feature"</p>
<p>"no, grug not build that abstraction"</p>
<p>"no, grug not put water on body every day or drink less black think juice you stop repeat ask now"</p>
<p>note, this good engineering advice but bad career advice: "yes" is magic word for more shiney rock and put in
charge of large tribe of developer</p>
<p>sad but true: learn "yes" then learn blame other grugs when fail, ideal career advice</p>
<p>but grug must to grug be true, and "no" is magic grug word.  Hard say at first, especially if you nice grug and don't like
disappoint people (many such grugs!) but  easier over time even though shiney rock pile not as high as might otherwise be</p>
<p>is ok: how many shiney rock grug really need anyway?</p>
<h2><a name="grug-on-saying-ok"></a><a href="#grug-on-saying-ok">Saying ok</a></h2>
<p>sometimes compromise necessary or no shiney rock, mean no dinosaur meat, not good, wife firmly remind grug
about young grugs at home need roof, food, and so forth, no interest in complexity demon spirit rant by grug for
fiftieth time</p>
<p>in this situation, grug recommend "ok"</p>
<p>"ok, grug build that feature"</p>
<p>then grug spend time think of <a href="https://en.wikipedia.org/wiki/Pareto_principle">80/20 solution</a> to problem and build that instead.<br>
80/20 solution say "80 want with 20 code"  solution maybe not have all bell-whistle that project manager want, maybe a
little ugly, but work and deliver most value, and keep demon complexity spirit at bay for most part to extent</p>
<p>sometimes probably best just not tell project manager and do it 80/20 way.  easier forgive than permission, project managers
mind like butterfly at times overworked and dealing with many grugs.  often forget what even feature supposed to do or move on or
quit or get fired grug see many such cases</p>
<p>anyway is in project managers best interest anyway so grug not to feel too bad for this approach usually</p>
<h2><a name="grug-on-factring-your-code"></a><a href="#grug-on-factring-your-code">Factoring Your Code</a></h2>
<p>next strategy very harder: break code base up properly (fancy word: "factor your code properly")  here is hard give general
advice because each system so different.  however, one thing grug come to believe: not factor your application too early!</p>
<p>early on in project everything very abstract and like water: very little solid holds for grug's struggling brain to hang
on to.  take time to develop "shape" of system and learn what even doing.  grug try not to factor in early part of project
and then, at some point, good cut-points emerge from code base</p>
<p>good cut point has narrow interface with rest of system: small number of functions or abstractions that hide complexity
demon internally, like trapped in crystal</p>
<p>grug quite satisfied when complexity demon trapped properly in crystal, is best feeling to trap mortal enemy!</p>
<p>grug try watch patiently as cut points emerge from code and slowly refactor, with code base taking shape over time along
with experience.  no hard/ fast rule for this: grug know cut point when grug see cut point, just take time to build
skill in seeing, patience</p>
<p>sometimes grug go too early and get abstractions wrong, so grug bias towards waiting</p>
<p>big brain developers often not like this at all and invent many abstractions start of project</p>
<p>grug tempted to reach for club and yell "big brain no maintain code!  big brain move on next architecture committee
leave code for grug deal with!"</p>
<p>but grug learn control passions, major difference between grug and animal</p>
<p>instead grug try to limit damage of big brain developer early in project by giving them thing like
UML diagram (not hurt code, probably throw away anyway) or by demanding working demo tomorrow</p>
<p>working demo especially good trick: force big brain make something to actually work to talk about and code to look at that do
thing, will help big brain see reality on ground more quickly</p>
<p>remember!  big brain have big brain!  need only be harness for good and not in service of spirit complexity demon on
accident, many times seen</p>
<p>(best grug brain able to herd multiple big brain in right direction and produce many complexity demon trap crystals, large
shiney rock pile awaits such grug!)</p>
<p>also sometimes call demo approach "prototype", sound fancier to project manager</p>
<p>grug say prototype early in software making, <em>especially</em> if many big brains</p>
<h2><a name="grug-on-testing"></a><a href="#grug-on-testing">Testing</a></h2>
<p>grug have love/hate relationship with test: test save grug many, many uncountable time and grug love and respect test</p>
<p>unfortunately also many test shamans exist.  some test shaman make test idol, demand things like "first test" before grug
even write code or have any idea what grug doing domain!</p>
<p>how grug test what grug not even understand domain yet!?</p>
<p>"Oh, don't worry: the tests will show you what you need to do."</p>
<p>grug once again catch grug slowly reaching for club, but grug stay calm</p>
<p>grug instead prefer write most tests after prototype phase, when code has begun firm up</p>
<p>but, note well: grug must here be very disciplined!</p>
<p>easy grug to move on and not write tests because "work on grugs machine"!</p>
<p>this very, very bad: no guarantee work on other machine and no guarantee work on grug machine in future, many times</p>
<p>test shaman have good point on importance of test, even if test shaman often sometimes not complete useful
feature in life and talk only about test all time, deserve of club but heart in right place</p>
<p>also, test shaman often talk unit test very much, but grug not find so useful.  grug experience that ideal tests are not
unit test or either end-to-end test, but in-between test</p>
<p><a href="https://en.wikipedia.org/wiki/Unit_testing">unit tests</a> fine, ok, but break as implementation change (much compared api!)
and make refactor hard and, frankly, many bugs anyway often due interactions other code.  often throw away when code change.</p>
<p>grug write unit test mostly at start of project, help get things going but not get too attached or expect value long time</p>
<p><a href="https://smartbear.com/solutions/end-to-end-testing/">end to end</a> tests good, show whole system work, but! hard to
understand when break and drive grug crazy very often, sometimes grugs just end up ignoring because "oh, that break all
time"  very bad!</p>
<p>in-between tests, grug hear shaman call <a href="https://en.wikipedia.org/wiki/Integration_testing">"integration tests"</a> sometime
often with sour look on face. but grug say integration test sweet spot according to grug: high level enough test correctness
of system, low level enough, with good debugger, easy to see what break</p>
<p>grug prefer some unit tests especially at start but not 100% all code test and definitely not "first test".  "test along
the way" work pretty well for grug, especially as grug figure things out</p>
<p>grug focus much ferocious integration test effort as cut point emerge and system stabilize!  cut point api hopefully stable
compared implementation and integration test remain valuable many long time, and easy debug</p>
<p>also small, well curated end-to-end test suite is created to be kept working religiously on pain of clubbing. focus of important
end-to-end test on most common UI features and few most important edge cases, but not too many or become impossible maintain
and then ignored</p>
<p>this ideal set of test to grug</p>
<p>you may not like, but this peak grug testing</p>
<p>also, grug dislike <a href="https://en.wikipedia.org/wiki/Mock_object">mocking</a> in test, prefer only when absolute necessary
to (rare/never) and coarse grain mocking (cut points/systems) only at that</p>
<p>one exception "first test" dislike by grug: when bug found.  grug always try first reproduce bug with regression test
<em>then</em> fix bug, this case only for some reason work better</p>
<h2><a name="grug-on-agile"></a><a href="#grug-on-agile">Agile</a></h2>
<p>grug think agile not terrible, not good</p>
<p>end of day, not worst way to organize development, maybe better than others grug supposes is fine</p>
<p>danger, however, is agile shaman!  many, many shiney rock lost to agile shaman!</p>
<p>whenever agile project fail, agile shaman say "you didn't do agile right!"  grug note this awfully convenient for agile
shaman, ask more shiney rock better agile train young grugs on agile, danger!</p>
<p>grug tempted reach for club when too much agile talk happen but always stay calm</p>
<p>prototyping, tools and hiring good grugs better key to success software: agile process ok and help some but sometimes hurt taken
too seriously</p>
<p>grug say <a href="https://en.wikipedia.org/wiki/No_Silver_Bullet">no silver club</a> fix all software problems no matter what agile
shaman say (danger!)</p>
<h2><a name="grug-on-refactoring"></a><a href="#grug-on-refactoring">Refactoring</a></h2>
<p>refactoring fine activity and often good idea, especially later in project when code firmed up</p>
<p>however, grug note that many times in career "refactors" go horribly off rails and end up causing more harm than good</p>
<p>grug not sure exactly why some refactors work well, some fail, but grug notice that larger refactor, more
likely failure appear to be</p>
<p>so grug try to keep refactors relatively small and not be "too far out from shore" during refactor.  ideally system work
entire time and each step of finish before other begin.</p>
<p>end-to-end tests are life saver here, but often very hard understand why broke... such is refactor life.</p>
<p>also grug notice that introducing too much abstraction often lead to refactor failure and system failure.  good example
was <a href="https://www.webopedia.com/definitions/j2ee/">J2EE</a> introduce, many big brain sit around thinking too much abstraction, nothing good came of it many project hurt</p>
<p>another good example when company grug work for introduce <a href="https://www.techtarget.com/searchnetworking/definition/OSGi">OSGi</a> to help
manage/trap spriit complexity demon in code base.  not only OSGi not help, but make complexity demon much more powerful!
took multiple man year of best developers to rework as well to boot!  more complex spirit and now features impossible
implement! very bad!</p>
<h2><a name="grug-on-chestertons-fence"></a><a href="#grug-on-chestertons-fence">Chesterton's Fence</a></h2>
<p>wise grug shaman <a href="https://en.wikipedia.org/wiki/G._K._Chesterton">chesterton</a> once say</p>
<blockquote>
<p>here exists in such a case a certain institution or law; let us say, for the sake of simplicity, a fence or gate erected across a road. The more modern type of reformer goes gaily up to it and says, “I don’t see the use of this; let us clear it away.” To which the more intelligent type of reformer will do well to answer: “If you don’t see the use of it, I certainly won’t let you clear it away. Go away and think. Then, when you can come back and tell me that you do see the use of it, I may allow you to destroy it.”</p>
</blockquote>
<p>many older grug learn this lesson well not start tearing code out willy nilly, no matter how ugly look</p>
<p>grug understand all programmer platonists at some level wish music of spheres perfection in code.  but danger is here,
world is ugly and gronky many times and so also must code be</p>
<p>humility not often come big brained or think big brained
easily or grug even, but grug often find "oh, grug no like look of this, grug fix" lead many hours pain grug and no better or system
worse even</p>
<p>grug early on in career often charge into code base waving club wildly and smash up everything, learn not good</p>
<p>grug not say no improve system ever, quite foolish, but recommend take time understand system first especially bigger system is and
is respect code working today even if not perfect</p>
<p>here tests often good hint for why fence not to be smashed!</p>
<h2><a name="grug-on-microservices"></a><a href="#grug-on-microservices">Microservices</a></h2>
<p>grug wonder why big brain take hardest problem, factoring system correctly, and introduce network call too</p>
<p>seem very confusing to grug</p>
<h2><a name="grug-on-tools"></a><a href="#grug-on-tools">Tools</a></h2>
<p>grug love tool.  tool and control passion what separate grug from dinosaurs!  tool allow grug brain to create code that
not possible otherwise by doing thinking for grug, always good relief! grug always spend time in new place learning
tools around him to maximize productivity: learn tools for two weeks make development often twice faster and often
have dig around ask other developers help, no docs</p>
<p>code completion in IDE allow grug not have remembered all API, very important!</p>
<p>java programming nearly impossible without it for grug!</p>
<p>really make grug think some time</p>
<p>good debugger worth weight in shiney rocks, in fact also more: when faced with bug grug would often trade all shiney rock and
perhaps few children for good debugger and anyway debugger no weigh anything far as grug can tell</p>
<p>grug always recommend new programmer learn available debugger very deeply, features like conditional break points, expression
evaluation, stack navigation, etc teach new grug more about computer than university class often!</p>
<p>grug say never be not improving tooling</p>
<h2><a name="grug-on-type-systems"></a><a href="#grug-on-type-systems">Type Systems</a></h2>
<p>grug very like type systems make programming easier.  for grug, type systems most value when grug hit dot on keyboard and
list of things grug can do pop up magic.  this 90% of value of type system or more to grug</p>
<p>big brain type system shaman often say type correctness main point type system, but grug note some big brain type system
shaman not often ship code.  grug suppose code never shipped is correct, in some sense, but not really what grug mean
when say correct</p>
<p>grug say tool magic pop up of what can do and complete of code major most benefit of type system, correctness also good but not
so nearly so much</p>
<p>also, often sometimes caution beware big brains here!</p>
<p>some type big brain think in type systems and talk in lemmas, potential danger!</p>
<p>danger abstraction too high, big brain type system code become astral projection of platonic generic turing model of
computation into code base.  grug confused and agree some level very elegant but also very hard do anything like
record number of club inventory for Grug Inc. task at hand</p>
<p>generics especially dangerous here, grug try limit generics to container classes for most part where most value add</p>
<p>temptation generics very large is trick!  spirit demon complex love this one trick! beware!</p>
<p>always most value type system come: hit dot see what grug can do, never forget!</p>
<h2><a name="grug-on-expression-complexity"></a><a href="#grug-on-expression-complexity">Expression Complexity</a></h2>
<p>grug once like to minimize lines of code much as possible.  write code like this:</p>
<pre><code>  if(contact &amp;&amp; !contact.isActive() &amp;&amp; (contact.inGroup(FAMILY) || contact.inGroup(FRIENDS))) {
    // ...
  }
</code></pre>
<p>over time grug learn this hard debug, learn prefer write like so:</p>
<pre><code>  if(contact) {
    var contactIsInactive = !contact.isActive();
    var contactIsFamilyOrFriends = contact.inGroup(FAMILY) || contact.inGroup(FRIENDS);
    if(contactIsInactive &amp;&amp; contactIsFamilyOrFriends) {
        // ...
    }
  }
</code></pre>
<p>grug hear screams from young grugs at horror of many line of code and pointless variable and grug prepare defend self with club</p>
<p>club fight start with other developers attack and grug yell: "easier debug!  see result of each expression more clearly and good name!  easier
understand conditional expression!  EASIER DEBUG!"</p>
<p>definitely easier debug and once club fight end calm down and young grug think a bit, they realize grug right</p>
<p>grug still catch grug writing code like first example and often regret, so grug not judge young grug</p>
<h2><a name="grug-on-dry"></a><a href="#grug-on-dry">DRY</a></h2>
<p><a href="https://en.wikipedia.org/wiki/Don%27t_repeat_yourself">DRY</a> mean Don't Repeat Self, powerful maxim over mind of most
developers</p>
<p>grug respect DRY and good advice, however grug recommend balance in all things, as gruggest big brain aristotle recommend</p>
<p>grug note humourous graph by Lea Verou correspond with grug passion not repeat:</p>
<img alt="code concerns over time" src="https://grugbrain.dev/over-time.png">
<p>over time past ten years program grug not as concerned repeat code.  so long as repeat code simple enough and obvious
enough, and grug begin feel repeat/copy paste code with small variation is better than many callback/closures passed arguments
or elaborate object model: too hard complex for too little benefit at times</p>
<p>hard balance here, repeat code always still make grug stare and say "mmm" often, but experience show repeat code
sometimes often better than complex DRY solution</p>
<p>note well!  grug encourage over literal developer not take does work line too serious, is joke</p>
<h2><a name="grug-on-soc"></a><a href="#grug-on-soc">Separation of Concerns (SoC)</a></h2>
<p><a href="https://en.wikipedia.org/wiki/Separation_of_concerns">Separation of Concern (SoC)</a> another powerful idea over many developer
mind, idea to separate different aspects of system into distinct sections code</p>
<p>canonical example from web development: separation of style (css file), markup (html file) and logic (javascript file)</p>
<p>here grug much more sour faced than DRY and in fact write big brained essay on alternative design principle
<a href="https://htmx.org/essays/locality-of-behaviour/">locality of behavior (LoB)</a> against SoC</p>
<p>grug much prefer put code on the thing that do the thing.  now when grug look at the thing grug know the thing what the
thing do, alwasy good relief!</p>
<p>when separate of concern grug must often all over tarnation many file look understand what how button do, much confuse
and time waste: bad!</p>
<h2><a name="grug-on-closures"></a><a href="#grug-on-closures">Closures</a></h2>
<p>grug like closures for right job and that job usually abstracting operation over collection of objects</p>
<p>grug warn closures like salt, type systems and generics: small amount go long way, but easy spoil things too much use
give heart attack</p>
<p>javascript developers call very special complexity demon spirit in javascript "callback hell" because too much closure
used by javascript libraries very sad but also javascript developer get what deserved let grug be frank</p>
<h2><a name="grug-on-logging"></a><a href="#grug-on-logging">Logging</a></h2>
<p>grug huge fan of logging and encourage lots of it, especially in cloud deployed.  some non-grugs say logging expensive
and not important.  grug used think this way no more</p>
<p>funny story: grug learn idol <a href="https://en.wikipedia.org/wiki/Rob_Pike">rob pike</a> working on logging at google and decide:
"if rob pike working on logging, what grug do there?!?" so not pursue.  turn out logging <em>very</em> important to google so
of course best programmer work on it, grug!</p>
<p>don't be such grug brain, grug, much less shiney rock now!</p>
<p>oh well, grug end up at good company anyway and rob pike dress habit
<a href="https://www.youtube.com/watch?v=KINIAgRpkDA">increasingly erratic</a>, so all work out in end, but
point stand: logging very important!</p>
<p>grug tips on logging are:</p>
<ul>
<li>log all major logical branches within code (if/for)</li>
<li>if "request" span multiple machine in cloud infrastructure, include request ID in all so logs can be grouped</li>
<li>if possible make log level dynamically controlled, so grug can turn on/off when need debug issue (many!)</li>
<li>if possible make log level per user, so can debug specific user issue</li>
</ul>
<p>last two points are especially handy club when fighting bugs in production systems very often</p>
<p>unfortunately log libraries often very complex (java, <a href="https://stackify.com/logging-java/">why you do?</a>) but worth investing
time in getting logging infrastructure "just right" pay off big later in grug experience</p>
<p>logging need taught more in schools, grug think</p>
<h2><a name="grug-on-concurrency"></a><a href="#grug-on-concurrency">Concurrency</a></h2>
<p>grug, like all sane developer, fear concurrency</p>
<p>as much as possible, grug try to rely on simple concurrency models like stateless web request handlers and simple
remote job worker queues where jobs no interdepend and simple api</p>
<p><a href="https://en.wikipedia.org/wiki/Optimistic_concurrency_control">optimistic concurrency</a> seem work well for web stuff</p>
<p>occasionally grug reach for <a href="https://en.wikipedia.org/wiki/Thread-local_storage">thread local variable</a>, usually when
writing framework code</p>
<p>some language have good concurrent data structure, like java <a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/ConcurrentHashMap.html">ConcurrentHashMap</a>
but still need careful grug work to get right</p>
<p>grug has never used <a href="https://en.wikipedia.org/wiki/Erlang_(programming_language)">erlang</a>, hear good things, but language
look wierd to grug sorry</p>
<h2><a name="grug-on-optimizing"></a><a href="#grug-on-optimizing">Optimizing</a></h2>
<p>ultra biggest of brain developer once say:</p>
<blockquote>
<p>premature optimization is the root of all evil</p>
</blockquote>
<p>this everyone mostly know and grug in humble violent agreement with ultra biggest of big brain</p>
<p>grug recommend always to have concrete, real world perf profile showing specific perf issue before begin optimizing.</p>
<p>never know what actual issue might be, grug often surprise!  very often!</p>
<p>beware only cpu focus: easy to see cpu and much big o notation thinking having been done in school,
but often not root of all slowness, surprise to many including grug</p>
<p>hitting network equivalent of many, many millions cpu cycle and always to be minimized if possible, note well big brain
microservice developer!</p>
<p>inexperienced big brain developer see nested loop and often say "O(n^2)?  Not on my watch!"</p>
<p>complexity demon spirit smile</p>
<h2><a name="grug-on-apis"></a><a href="#grug-on-apis">APIs</a></h2>
<p>grug love good apis.  good apis not make grug think too much</p>
<p>unfortunately, many apis very bad, make grug think quite a bit.  this happen many reasons, here two:</p>
<ul>
<li>API creators think in terms of implementation or domain of API, rather than in terms of use of API</li>
<li>API creators think too abstract and big brained</li>
</ul>
<p>usually grug not care too deeply about detail of api: want write file or sort list or whatever, just want to call
<code>write()</code> or <code>sort()</code> or whatever</p>
<p>but big brain api developers say:</p>
<p>"not so fast, grug!  is that file <em>open for write</em>? did you define a <em>Comparator</em> for that sort?"</p>
<p>grug find self restraining hand reaching for club again</p>
<p>not care about that stuff right now, just want sort and write file mr big brain!</p>
<p>grug recognize that big brain api designer have point and that <em>sometime</em> these things matter, but often do not.
big brain api developers better if design for simple cases with simple api, make complex cases possible
with more complex api</p>
<p>grug call this "layering" apis: two or three different apis at different level complexity for various grug needs</p>
<p>also, if object oriented, put api on thing instead of elsewhere. java worst at this!</p>
<p>grug want filter list in java</p>
<p>"Did you convert it to a stream?"</p>
<p>fine, grug convert to stream</p>
<p>"OK, now you can filter."</p>
<p>OK, but now need return list!  have stream!</p>
<p>"Well, did you collect your stream into a list?"</p>
<p>what?</p>
<p>"Define a Collector&lt;? super T, A, R&gt; to collect your stream into a list"</p>
<p>grug now swear on ancestor grave he club every single person in room, but count two instead and remain calm</p>
<p>put common thing like <code>filter()</code> on list and make return list, listen well big brain java api developer!</p>
<p>nobody care about "stream" or even hear of "stream" before, is not networking api, all java grugs use list mr big brain!</p>
<h2><a name="grug-on-parsing"></a><a href="#grug-on-parsing">Parsing</a></h2>
<p>grug love make programming language at drop of hat and
say <a href="https://en.wikipedia.org/wiki/Recursive_descent_parser">recursive descent</a>
most fun and beautiful way create parser</p>
<p>unfortunately many big brain school teach only parser generator tool.  here grug usual love of tool is not: parser
generator tool generate code of awful snakes nest: impossible understand, bottom up, what?  hide recursive nature of
grammar from grug and debug impossible, very bad according grug!</p>
<p>grug think this because while complexity demon bad for code base and understand, complexity demon very good for generation
of much academic papers, sad but true</p>
<p>production parser almost always recursive descent, despite ignore by schools!  grug furious when learn how simple parse
is! parsing not big brain only magic: so can you!</p>
<p>grug very elated find big brain developer Bob Nystrom redeem the big brain tribe and write excellent book on recursive
descent: <a href="https://craftinginterpreters.com/">Crafting Interpreters</a></p>
<p>book available online free, but grug highly recommend all interested grugs purchase book on general principle, provide
much big brain advice and grug love book <em>very</em> much except visitor pattern (trap!)</p>
<h2><a name="grug-on-visitor-pattern"></a><a href="#grug-on-visitor-pattern">The Visitor Pattern</a></h2>
<p><a href="https://en.wikipedia.org/wiki/Visitor_pattern">bad</a></p>
<h2><a name="grug-on-front-end-development"></a><a href="#grug-on-front-end-development">Front End Development</a></h2>
<p>some non-grugs, when faced with web development say:</p>
<p>"I know, I'll split my front end and back end codebase up and use a hot new SPA library talking to a GraphQL JSON API back end
over HTTP (which is funny because I'm not transferring hypertext)"</p>
<p>now you have two complexity demon spirit lairs</p>
<p>and, what is worse, front end complexity demon spirit even more powerful and have deep spiritual hold on entire front end
industry as far as grug can tell</p>
<p>back end developers try keep things simple and can work ok, but front end developers make very complex very quickly and
introduce lots of code, demon complex spirit</p>
<p>even when website just need put form into database or simple brochure site!</p>
<p>everyone do this now!</p>
<p>grug not sure why except maybe facebook and google say so, but that not seem very good reason to grug</p>
<p>grug not like big complex front end libraries everyone use</p>
<p>grug make <a href="https://htmx.org/">htmx</a> and <a href="https://hyperscript.org/">hyperscript</a> to avoid</p>
<p>keep complexity low, simple HTML, avoid lots javascript, the natural ether of spirit complexity demon</p>
<p>maybe they work for you, but no job post, sorry</p>
<p>react better for job and also some type application, but also you become alcolyte of complexity demon whether you like
or no, sorry such is front end life</p>
<h2><a name="grug-on-fads"></a><a href="#grug-on-fads">Fads</a></h2>
<p>grug note lots of fads in development, especially front end development today</p>
<p>back end better more boring because all bad ideas have tried at this point maybe (still retry some!)</p>
<p>still trying all bad ideas in front end development so still much change and hard to know</p>
<p>grug recommend taking all revolutionary new approach with grain salt: big brains have working for long
time on computers now, most ideas have tried at least once</p>
<p>grug not saying can't learn new tricks or no good new ideas, but also much of time wasted on recycled bad ideas, lots of
spirit complexity demon power come from putting new idea willy nilly into code base</p>
<h2><a name="grug-on-fold"></a><a href="#grug-on-fold">Fear Of Looking Dumb</a></h2>
<p>note!  very good if senior grug willing to say publicly: "hmmm, this too complex for grug"!</p>
<p>many developers Fear Of Looking Dumb (FOLD), grug also at one time FOLD, but grug learn get over: very important senior
grug say "this too complicated and confuse to me"</p>
<p>this make it ok for junior grugs to admit too complex and not understand as well, often such case!  FOLD major source of
complexity demon power over developer, especially young grugs!</p>
<p>take FOLD power away, very good of senior grug!</p>
<p>note: important to make thinking face and look big brained when saying though.  be prepare for big brain or, worse and
much more common, <em>thinks</em> is big brain to make snide remark of grug</p>
<p>be strong! no FOLD!</p>
<p>club sometimes useful here, but more often sense of humor and especially last failed project by big brain very useful,
so collect and be calm</p>
<h2><a name="grug-on-imposter-syndrom"></a><a href="#grug-on-imposter-syndrom">Impostor Syndrome</a></h2>
<p>grug note many such impostor feels in development</p>
<p>always grug one of two states: grug is ruler of all survey, wield code club like thor OR grug have no idea what doing</p>
<p>grug is mostly latter state most times, hide it pretty well though</p>
<p>now, grug make softwares of much work and <a href="https://star-history.com/#bigskysoftware/htmx&amp;bigskysoftware/_hyperscript&amp;Date">moderate open source success</a>
, and yet grug himself often feel not any idea what doing!  very often!  grug still fear make mistake break everyone code and
disappoint other grugs, imposter!</p>
<p>is maybe nature of programming for most grug to feel impostor and be ok with is best: nobody imposter if everybody imposter</p>
<p>any young grug read this far probably do fine in program career even if frustrations and worry is always to be there, sorry</p>
<h2><a name="grug-reads"></a><a href="#grug-reads">Reads</a></h2>
<p>grug like these:</p>
<ul>
<li><a href="https://www.dreamsongs.com/WorseIsBetter.html">Worse is Better</a></li>
<li><a href="https://www.dreamsongs.com/Files/worse-is-worse.pdf">Worse is Better is Worse</a></li>
<li><a href="https://www.dreamsongs.com/Files/IsWorseReallyBetter.pdf">Is Worse Really Better?</a></li>
<li><a href="https://www.goodreads.com/en/book/show/39996759-a-philosophy-of-software-design">A Philosophy of Software Design</a></li>
</ul>
<h2><a name="lol-lmao"></a><a href="#lol-lmao">Conclusion</a></h2>
<p><em>you</em> say: complexity <em>very</em>, <em>very</em> bad</p>

  
</div>]]></description>
        </item>
        <item>
            <title><![CDATA[SEC Charges SolarWinds and CISO with Fraud, Internal Control Failures (225 pts)]]></title>
            <link>https://www.sec.gov/news/press-release/2023-227</link>
            <guid>38076636</guid>
            <pubDate>Mon, 30 Oct 2023 22:08:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.sec.gov/news/press-release/2023-227">https://www.sec.gov/news/press-release/2023-227</a>, See on <a href="https://news.ycombinator.com/item?id=38076636">Hacker News</a></p>
<div id="readability-page-1" class="page"><p><h2>Complaint alleges software company misled investors about its cybersecurity practices and known risks</h2></p><p>
          Washington D.C.,           Oct. 30, 2023 —
        </p><div><p>The Securities and Exchange Commission today announced charges against Austin, Texas-based software company SolarWinds Corporation and its chief information security officer, Timothy G. Brown, for fraud and internal control failures relating to allegedly known cybersecurity risks and vulnerabilities. The complaint alleges that, from at least its October 2018 initial public offering through at least its December 2020 announcement that it was the target of a massive, nearly two-year long cyberattack, dubbed “SUNBURST,” SolarWinds and Brown defrauded investors by overstating SolarWinds' cybersecurity practices and understating or failing to disclose known risks.&nbsp;In its filings with the SEC during this period, SolarWinds allegedly misled investors by disclosing only generic and hypothetical risks at a time when the company and Brown knew of specific deficiencies in SolarWinds’ cybersecurity practices as well as the increasingly elevated risks the company faced at the same time.</p>

<p>As the complaint alleges, SolarWinds’ public statements about its cybersecurity practices and risks were at odds with its internal assessments, including a 2018 presentation prepared by a company engineer and shared internally, including with Brown, that SolarWinds’ remote access set-up was “not very secure” and that someone exploiting the vulnerability “can basically do whatever without us detecting it until it’s too late,” which could lead to “major reputation and financial loss” for SolarWinds. Similarly, as alleged in the SEC’s complaint, 2018 and 2019 presentations by Brown stated, respectively, that the “current state of security leaves us in a very vulnerable state for our critical assets” and that “[a]ccess and privilege to critical systems/data is inappropriate.”</p>

<p>In addition, the SEC’s complaint alleges that multiple communications among SolarWinds employees, including Brown, throughout 2019 and 2020 questioned the company’s ability to protect its critical assets from cyberattacks. For example, according to the SEC’s complaint, in June 2020, while investigating a cyberattack on a SolarWinds customer, Brown wrote that it was “very concerning” that the attacker may have been looking to use SolarWinds’ Orion software in larger attacks because “our backends are not that resilient;” and a September 2020 internal document shared with Brown and others stated, “the volume of security issues being identified over the last month have [sic] outstripped the capacity of Engineering teams to resolve.”</p>

<p>The SEC’s complaint alleges that Brown was aware of SolarWinds’ cybersecurity risks and vulnerabilities but failed to resolve the issues or, at times, sufficiently raise them further within the company. As a result of these lapses, the company allegedly also could not provide reasonable assurances that its most valuable assets, including its flagship Orion product, were adequately protected.</p>

<p>SolarWinds made an incomplete disclosure about the SUNBURST attack in a December 14, 2020, Form 8-K filing, following which its stock price dropped approximately 25 percent over the next two days and approximately 35 percent by the end of the month.</p>

<p>“We allege that, for years, SolarWinds and Brown ignored repeated red flags about SolarWinds’ cyber risks, which were well known throughout the company and led one of Brown’s subordinates to conclude: ‘We’re so far from being a security minded company,’” said Gurbir S. Grewal, Director of the SEC’s Division of Enforcement. “Rather than address these vulnerabilities, SolarWinds and Brown engaged in a campaign to paint a false picture of the company’s cyber controls environment, thereby depriving investors of accurate material information. Today’s enforcement action not only charges SolarWinds and Brown for misleading the investing public and failing to protect the company’s ‘crown jewel’ assets, but also underscores our message to issuers: implement strong controls calibrated to your risk environments and level with investors about known concerns.”</p>

<p>The SEC’s complaint, filed in the Southern District of New York, alleges that SolarWinds and Brown violated the antifraud provisions of the Securities Act of 1933 and of the Securities Exchange Act of 1934; SolarWinds violated reporting and internal controls provisions of the Exchange Act; and Brown aided and abetted the company’s violations. The complaint seeks permanent injunctive relief, disgorgement with prejudgment interest, civil penalties, and an officer and director bar against Brown.</p>

<p>The SEC’s investigation was conducted by W. Bradley Ney, Lory Stone, and Benjamin Brutlag, with assistance from the Trial Unit’s Christopher Bruckmann and Kristen Warden, and was supervised by Carolyn M. Welshhans and Melissa R. Hodgman. The SEC’s litigation will be led by Mr. Bruckmann and Ms. Warden under the supervision of Melissa Armstrong.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Drugmakers Are Set to Pay 23andMe Millions to Access Consumer DNA (239 pts)]]></title>
            <link>https://www.bloomberg.com/news/articles/2023-10-30/23andme-will-give-gsk-access-to-consumer-dna-data</link>
            <guid>38076530</guid>
            <pubDate>Mon, 30 Oct 2023 21:59:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bloomberg.com/news/articles/2023-10-30/23andme-will-give-gsk-access-to-consumer-dna-data">https://www.bloomberg.com/news/articles/2023-10-30/23andme-will-give-gsk-access-to-consumer-dna-data</a>, See on <a href="https://news.ycombinator.com/item?id=38076530">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
    <section>
        <h3>Why did this happen?</h3>
        <p>Please make sure your browser supports JavaScript and cookies and that you are not
            blocking them from loading.
            For more information you can review our <a href="https://www.bloomberg.com/notices/tos">Terms of
                Service</a> and <a href="https://www.bloomberg.com/notices/tos">Cookie Policy</a>.</p>
    </section>
    <section>
        <h3>Need Help?</h3>
        <p>For inquiries related to this message please <a href="https://www.bloomberg.com/feedback">contact
            our support team</a> and provide the reference ID below.</p>
        <p>Block reference ID:</p>
    </section>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Gmail, Yahoo announce new 2024 authentication requirements for bulk senders (510 pts)]]></title>
            <link>https://blog.google/products/gmail/gmail-security-authentication-spam-protection/</link>
            <guid>38074992</guid>
            <pubDate>Mon, 30 Oct 2023 20:07:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.google/products/gmail/gmail-security-authentication-spam-protection/">https://blog.google/products/gmail/gmail-security-authentication-spam-protection/</a>, See on <a href="https://news.ycombinator.com/item?id=38074992">Hacker News</a></p>
<div id="readability-page-1" class="page"><article ng-init="drawerToggle = {'open': true}">

    
    





    

    
      

<div data-analytics-module="{
    &quot;module_name&quot;: &quot;Hero Menu&quot;,
    &quot;section_header&quot;: &quot;New Gmail protections for a safer, less spammy inbox&quot;
  }">
      
      
        <p>
          Starting in 2024, we’ll require bulk senders to authenticate their emails, allow for easy unsubscription and stay under a reported spam threshold.
        </p>
      
    </div>

    

    
      







<div>
    <figure>
      <div>
  <p><img srcset="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gmail_security_policies_hero_2.width-600.format-webp.webp 600w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gmail_security_policies_hero_2.width-1200.format-webp.webp 1200w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gmail_security_policies_hero_2.width-1600.format-webp.webp 1600w" sizes="(max-width: 599px) 100vw, (max-width: 1023px) 600px, 1024px" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gmail_security_policies_hero_2.width-1200.format-webp.webp" fetchpriority="high" alt="An abstract graphic showing the Gmail logo surrounded by security-related icons, like padlocks and shields.">
  </p>
</div>

      
    </figure>
  </div>


    

    
    <div data-component="uni-drop-cap|uni-tombstone" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;New Gmail protections for a safer, less spammy inbox&quot;
         }" data-reading-time="true"><p data-block-key="z5p66">It’s clear that email has become an essential part of daily communication. And whether you’re submitting a job application or staying in touch with a loved one, your emails should be safe and secure.</p><p data-block-key="deihi">Gmail’s AI-powered defenses <a href="https://safety.google/gmail/">stop more than 99.9% of spam, phishing and malware</a> from reaching inboxes and <a href="https://blog.google/products/gmail/holiday-season-scams/">block nearly 15 billion unwanted emails</a> every day. But now, nearly 20 years after Gmail launched, the threats we face are more complex and pressing than ever.</p><p data-block-key="46ole">So today, we’re introducing new requirements for bulk senders — those who send more than 5,000 messages to Gmail addresses in one day — to keep your inbox even safer and more spam-free.</p><h2 data-block-key="fh3ee">Focus on email validation</h2><p data-block-key="cs1bi">Many bulk senders don’t appropriately secure and configure their systems, allowing attackers to easily hide in their midst. To help fix that, we’ve focused on a crucial aspect of email security: the validation that a sender is who they claim to be. As basic as it sounds, it’s still sometimes impossible to verify who an email is from given the web of antiquated and inconsistent systems on the internet.</p><p data-block-key="f1d8c">Last year we started requiring that emails sent to a Gmail address must have some form of authentication. And we’ve seen the number of unauthenticated messages Gmail users receive plummet by 75%, which has helped declutter inboxes while blocking billions of malicious messages with higher precision.</p><p data-block-key="3vage">That’s great progress, but there’s much more we need to do — starting with new requirements for large senders.</p><h2 data-block-key="53u78">New requirements for bulk senders</h2><p data-block-key="uma9">By February 2024, Gmail will start to require that bulk senders:</p><ol><li data-block-key="838h2"><b>Authenticate their email:</b> You shouldn’t need to worry about the intricacies of email security standards, but you should be able to confidently rely on an email’s source. So we're requiring those who send significant volumes to strongly authenticate their emails following well-established <a href="https://support.google.com/a/answer/174124">best practices</a>. Ultimately, this will close loopholes exploited by attackers that threaten everyone who uses email.<br></li><li data-block-key="9nsf4"><b>Enable easy unsubscription:</b> You shouldn’t have to jump through hoops to stop receiving unwanted messages from a particular email sender. It should take one click. So we’re requiring that large senders give Gmail recipients the ability to unsubscribe from commercial email in one click, and that they process unsubscription requests within two days. We’ve built these requirements on open standards so that once senders implement them, everyone who uses email benefits.<br></li><li data-block-key="ar3h6"><b>Ensure they’re sending wanted email:</b> Nobody likes spam, and Gmail already includes <a href="https://safety.google/gmail/">many tools</a> that keep unwanted messages out of your inbox. To add yet another protection, moving forward, we’ll enforce a clear spam rate threshold that senders must stay under to ensure Gmail recipients aren’t bombarded with unwanted messages. This is an industry first, and as a result, you should see even less spam in your inbox.</li></ol><p data-block-key="770m9">We aren’t the only ones pushing for these changes. Our industry partners also see the pressing need to institute them: "No matter who their email provider is, all users deserve the safest, most secure experience possible,” says Marcel Becker, Sr. Dir. Product at Yahoo. “In the interconnected world of email, that takes all of us working together. Yahoo looks forward to working with Google and the rest of the email community to make these common sense, high-impact changes the new industry standard."</p><p data-block-key="1thnm">These practices should be considered basic email hygiene, and many senders already meet most of these requirements. For those who need help to improve their systems, we’re sharing <a href="https://support.google.com/mail/answer/81126">clear guidance</a> before enforcement begins in February 2024.<br></p><p data-block-key="250nh">These changes are like a tune-up for the email world, and by fixing a few things under the hood, we can keep email running smoothly. But just like a tune-up, this is not a one-time exercise. Keeping email more secure, user friendly and spam-free requires constant collaboration and vigilance from the entire email community. And we'll keep working together to make sure your inbox stays safe.</p></div>
  </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Cloudflare Workers Are Down? (154 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=38074906</link>
            <guid>38074906</guid>
            <pubDate>Mon, 30 Oct 2023 20:01:36 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=38074906">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="38075713"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38075713" href="https://news.ycombinator.com/vote?id=38075713&amp;how=up&amp;goto=item%3Fid%3D38074906"></a></center>    </td><td><br><div>
                  <p><span>It is funny that just last a few days ago the company whose core competency is availability laughed at Okta for a breach, and they are now experiencing an outage.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38074954"><td></td></tr>
                <tr id="38075005"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38075005" href="https://news.ycombinator.com/vote?id=38075005&amp;how=up&amp;goto=item%3Fid%3D38074906"></a></center>    </td><td><p><span>Just noted on HN and already incident upgrade. Much faster "response" than most other companies:-)<p>All the best to the people fixing!
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38075623"><td></td></tr>
                  <tr id="38075117"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38075117" href="https://news.ycombinator.com/vote?id=38075117&amp;how=up&amp;goto=item%3Fid%3D38074906"></a></center>    </td><td><br><div>
                  <p><span>And just 30 minutes ago we were about to flip the switch on a months long migration to Cloudflare Pages for our new website, I guess some things weren't meant to be :')</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38075192"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38075192" href="https://news.ycombinator.com/vote?id=38075192&amp;how=up&amp;goto=item%3Fid%3D38074906"></a></center>    </td><td><br><div>
                  <p><span>Omg. What timing. I feel your pain. We recently migrated to Cloudflare Pages and I was happy at the speed and everything and now this :(. Never had a downtime when I self hosted on my DigitalOcean droplet. damn. Re-considering going back to old school nginx static site hosting.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38075709"><td></td></tr>
            <tr id="38075230"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38075230" href="https://news.ycombinator.com/vote?id=38075230&amp;how=up&amp;goto=item%3Fid%3D38074906"></a></center>    </td><td><p><span>Yep our current marketing site is NextJS hosted on Hetzner fronted by Cloudflare, fortunately that's still up and never has any problems.<p>We've moved to next-on-pages for our new marketing site and I've spent the whole day on finishing touches ready for switch over at 20:00 UTC, and now this :((
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38075289"><td></td></tr>
                        <tr id="38074919"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38074919" href="https://news.ycombinator.com/vote?id=38074919&amp;how=up&amp;goto=item%3Fid%3D38074906"></a></center>    </td><td><p><span>3:55 PM Eastern: Our entire website hosted on cloudflare pages is returning 500. I also cannot login to the dashboard either (it just spins)<p>EDIT 4:10 PM Eastern: Now I can login to the dashboard but "Workers and Pages" menu is returning errors and no access. Website still down :(</p><p>EDIT at 4:23 PM Eastern: RESOLVED. Website (cloudflare pages) is back up now for me.</p><p>Looks like they took about 25 mins to resolve.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38075058"><td></td></tr>
                <tr id="38075099"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38075099" href="https://news.ycombinator.com/vote?id=38075099&amp;how=up&amp;goto=item%3Fid%3D38074906"></a></center>    </td><td><p><span>Our main Marketing website that brings revenue is down. No Sympathy from me. It has been 20 mins now. Losing money as I type this.<p>EDIT: I panicked a little. As a dev, I should have been more sympathetic.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38075197"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38075197" href="https://news.ycombinator.com/vote?id=38075197&amp;how=up&amp;goto=item%3Fid%3D38074906"></a></center>    </td><td><br><div>
                  <p><span>It’s only reasonable to be angry but do try to remember that the people fixing this are people like you who showed up at work to build something and are instead dealing with a fire. Ask their bosses about how they got in that situation but be nice to them, they’re having an even worse day than you are.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38075277"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_38075277" href="https://news.ycombinator.com/vote?id=38075277&amp;how=up&amp;goto=item%3Fid%3D38074906"></a></center>    </td><td><br><div>
                  <p><span>Fair enough. They resolved it now and I was in a bit of panic considering our revenue depends on the website. As a developer though, I should have been more sympathetic.</span></p></div></td></tr>
        </tbody></table></td></tr>
                              <tr id="38075097"><td></td></tr>
                  <tr id="38075094"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38075094" href="https://news.ycombinator.com/vote?id=38075094&amp;how=up&amp;goto=item%3Fid%3D38074906"></a></center>    </td><td><p><span>For any terraform users that may be using code like this:<p>data "cloudflare_ip_ranges" "cloudflare_ipv4_list" {}</p><p>This is coming back with an empty list on some fields and causing havoc in terraform.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38075248"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38075248" href="https://news.ycombinator.com/vote?id=38075248&amp;how=up&amp;goto=item%3Fid%3D38074906"></a></center>    </td><td><br><div>
                  <p><span>It is shocking to me how bad to non-existent error handling is in most terraform providers.  It leads to some remarkably arcane and esoteric error messages</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38075639"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38075639" href="https://news.ycombinator.com/vote?id=38075639&amp;how=up&amp;goto=item%3Fid%3D38074906"></a></center>    </td><td><p><span>Terraform error handling <i>as a whole</i> is nuts anyway. Like, I recently tried to delete an ACM cert that still was in use in a Cloudfront distribution - didn't work, but it took <i>20 minutes</i> for Terraform to recognize that, yes, there's an API error. It shouldn't have come so far given that the API call immediately errors out when trying over the CLI or Web Console, but instead of erroring out, Terraform retried for 20 minutes until it hit some sort of timeout.<p>To make it worse, you can't even <i>kill</i> Terraform safely because while it does register your Ctrl+C, it won't interrupt an ongoing process, and if you force kill it you run the very serious risk of corrupting your state file.</p><p>Seriously, I'm looking for OpenTofu to light some fire under the ass of Hashicorp. I don't know where all the VC money went, but for what's supposed to be the golden standard of IaC solutions, it's sometimes bloody ridiculous.</p><p>(Not to mention it's written in Go of all things which means there's virtually zero tooling and documentation to debug it or to develop anything for... especially when compared to the state of the art in Java, NodeJS or PHP)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38075256"><td></td></tr>
                  <tr id="38075250"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38075250" href="https://news.ycombinator.com/vote?id=38075250&amp;how=up&amp;goto=item%3Fid%3D38074906"></a></center>    </td><td><br><div>
                  <p><span>In the time I made this post and now it's come back. Really wish that would've returned an error and not an empty list, that almost caused a disaster in my automation.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38075107"><td></td></tr>
                <tr id="38075609"><td></td></tr>
                  <tr id="38075159"><td></td></tr>
            <tr id="38075439"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38075439" href="https://news.ycombinator.com/vote?id=38075439&amp;how=up&amp;goto=item%3Fid%3D38074906"></a></center>    </td><td><p><span>I won't be the first or last to say these three things:<p>The internet was meant to stop reliance on single sources (in case of nuclear war)</p><p>The size of a house of cards increases the number of failure points</p><p>Marketers lie
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38075604"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38075604" href="https://news.ycombinator.com/vote?id=38075604&amp;how=up&amp;goto=item%3Fid%3D38074906"></a></center>    </td><td><p><span>&gt; The internet was meant to stop reliance on single sources<p>You have all the technical means. Your home server possibly won't be reachable, yes.</p><p>The global connectivity as-is is really, really, really fault tolerant.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38075079"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38075079" href="https://news.ycombinator.com/vote?id=38075079&amp;how=up&amp;goto=item%3Fid%3D38074906"></a></center>    </td><td><br><div>
                  <p><span>Complete Pages outage for me. I have several sites hosted on Cloudflare Pages and I can't access any of them, they're all returning 500's.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38075171"><td></td></tr>
                  <tr id="38075229"><td></td></tr>
            <tr id="38075040"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38075040" href="https://news.ycombinator.com/vote?id=38075040&amp;how=up&amp;goto=item%3Fid%3D38074906"></a></center>    </td><td><br><div>
                  <p><span>I can't login to my domain dashboard either. Maybe that is a downstream effect of workers being offline?</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38075504"><td></td></tr>
                <tr id="38075528"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38075528" href="https://news.ycombinator.com/vote?id=38075528&amp;how=up&amp;goto=item%3Fid%3D38074906"></a></center>    </td><td><br><div>
                  <p><span>No way to confirm, but I think so, just because NPM threw this error at me:<pre><code>     KV GET failed: 401 Unauthorized
</code></pre>
where KV could refer to the CF KV in workers</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38074961"><td></td></tr>
                <tr id="38075010"><td></td></tr>
                <tr id="38075187"><td></td></tr>
                        <tr id="38075444"><td></td></tr>
            <tr id="38075170"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38075170" href="https://news.ycombinator.com/vote?id=38075170&amp;how=up&amp;goto=item%3Fid%3D38074906"></a></center>    </td><td><br><div>
                  <p><span>It's probably bad that I noticed this just due to a large percentage of my regular online-habits suddenly breaking. I liked the old internet where websites just broke one at a time.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38074924"><td></td></tr>
            <tr id="38074985"><td></td></tr>
                <tr id="38075035"><td></td></tr>
                  <tr id="38075301"><td></td></tr>
            <tr id="38075068"><td></td></tr>
                <tr id="38075106"><td></td></tr>
                <tr id="38075148"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38075148" href="https://news.ycombinator.com/vote?id=38075148&amp;how=up&amp;goto=item%3Fid%3D38074906"></a></center>    </td><td><br><div>
                  <p><span>Ah, I don't know about Cloudflare Pages. I think they use Workers underneath. So unfortunately, there's no fix yet. Sorry.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38075158"><td></td></tr>
                              <tr id="38075265"><td></td></tr>
            <tr id="38075232"><td></td></tr>
            <tr id="38074970"><td></td></tr>
                      <tr id="38075441"><td></td></tr>
            <tr id="38074964"><td></td></tr>
            <tr id="38074931"><td></td></tr>
                <tr id="38075071"><td></td></tr>
            <tr id="38074944"><td></td></tr>
                  <tr id="38074958"><td></td></tr>
                <tr id="38075006"><td></td></tr>
                  </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apple CPU Architecture Through the Ages (180 pts)]]></title>
            <link>https://jacobbartlett.substack.com/p/through-the-ages-apple-cpu-architecture</link>
            <guid>38074739</guid>
            <pubDate>Mon, 30 Oct 2023 19:51:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jacobbartlett.substack.com/p/through-the-ages-apple-cpu-architecture">https://jacobbartlett.substack.com/p/through-the-ages-apple-cpu-architecture</a>, See on <a href="https://news.ycombinator.com/item?id=38074739">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fef56b4d8-b9c0-4766-98f4-ffebb24d9458_700x620.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fef56b4d8-b9c0-4766-98f4-ffebb24d9458_700x620.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fef56b4d8-b9c0-4766-98f4-ffebb24d9458_700x620.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fef56b4d8-b9c0-4766-98f4-ffebb24d9458_700x620.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fef56b4d8-b9c0-4766-98f4-ffebb24d9458_700x620.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fef56b4d8-b9c0-4766-98f4-ffebb24d9458_700x620.png" width="700" height="620" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/ef56b4d8-b9c0-4766-98f4-ffebb24d9458_700x620.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:620,&quot;width&quot;:700,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fef56b4d8-b9c0-4766-98f4-ffebb24d9458_700x620.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fef56b4d8-b9c0-4766-98f4-ffebb24d9458_700x620.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fef56b4d8-b9c0-4766-98f4-ffebb24d9458_700x620.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fef56b4d8-b9c0-4766-98f4-ffebb24d9458_700x620.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a><figcaption><span>CPU die of the Apple Silicon M1 system-on-a-chip — Image from </span><a href="https://www.apple.com/uk/newsroom/2020/11/apple-unleashes-m1/" rel="">Apple Newsroom</a></figcaption></figure></div><p>This is the tale of the 4 Ages of Apple CPU Architecture. Each chapter, however, also serves as a framing device for fundamental CPU concepts.</p><p>If Android is more your thing, you are free to jump between sections at will like an overclocked instruction pointer.</p><ul><li><p><a href="https://medium.com/macoclock/through-the-ages-apple-cpu-architecture-92b33abedea7#f6c3" rel="">The CPU and Registers</a></p></li><li><p><a href="https://medium.com/macoclock/through-the-ages-apple-cpu-architecture-92b33abedea7#bc26" rel="">The Arithmetic-Logic Unit</a></p></li><li><p><a href="https://medium.com/macoclock/through-the-ages-apple-cpu-architecture-92b33abedea7#db06" rel="">8-bit vs. 16-bit</a></p></li><li><p><a href="https://medium.com/macoclock/through-the-ages-apple-cpu-architecture-92b33abedea7#0dda" rel="">Endian-ness</a></p></li></ul><ul><li><p><a href="https://medium.com/macoclock/through-the-ages-apple-cpu-architecture-92b33abedea7#8d2b" rel="">CISC vs. RISC</a></p></li><li><p><a href="https://medium.com/macoclock/through-the-ages-apple-cpu-architecture-92b33abedea7#8c7c" rel="">Pipelining</a></p></li><li><p><a href="https://medium.com/macoclock/through-the-ages-apple-cpu-architecture-92b33abedea7#6e3d" rel="">Assembly Language</a></p></li><li><p><a href="https://medium.com/macoclock/through-the-ages-apple-cpu-architecture-92b33abedea7#d416" rel="">Emulation</a></p></li></ul><ul><li><p><a href="https://medium.com/macoclock/through-the-ages-apple-cpu-architecture-92b33abedea7#12f3" rel="">CPU Caches (L1, L2, L3)</a></p></li><li><p><a href="https://medium.com/macoclock/through-the-ages-apple-cpu-architecture-92b33abedea7#ef4f" rel="">Branch Prediction</a></p></li><li><p><a href="https://medium.com/macoclock/through-the-ages-apple-cpu-architecture-92b33abedea7#a850" rel="">Superscalar Architecture</a></p></li><li><p><a href="https://medium.com/macoclock/through-the-ages-apple-cpu-architecture-92b33abedea7#322c" rel="">Hyper-threading</a></p></li></ul><ul><li><p><a href="https://medium.com/macoclock/through-the-ages-apple-cpu-architecture-92b33abedea7#dfb2" rel="">Heterogeneous Computing</a></p></li><li><p><a href="https://medium.com/macoclock/through-the-ages-apple-cpu-architecture-92b33abedea7#391a" rel="">Unified Memory Architecture</a></p></li><li><p><a href="https://medium.com/macoclock/through-the-ages-apple-cpu-architecture-92b33abedea7#fa64" rel="">Out-of-order Execution</a></p></li><li><p><a href="https://medium.com/macoclock/through-the-ages-apple-cpu-architecture-92b33abedea7#1cc0" rel="">Physics: The Ultimate Constraint</a></p></li></ul><p>I’m no evangelist, but it doesn’t take a fanboy to acknowledge that Apple is an impressive company.</p><p><span>They invented the </span><a href="https://macdailynews.com/2019/05/16/apples-iphone-is-the-most-successful-product-of-all-time/" rel="">most successful product in the history of capitalism</a><span>, and subsequently became the first business to hit a $1T market cap. Through hit products like the iPod, unparalleled branding, and the reality distortion field of Steve Jobs, they even managed to make tech </span><em>cool</em><span>.</span></p><p><span>Behind this impressive execution is a borderline-obsessive hardware optimisation: Since the Mac was released </span><a href="https://www.youtube.com/watch?v=VtvjbmoDx-I" rel="">in 1984</a><span>, Apple has migrated its CPU architecture </span><strong>three times</strong><span>.</span></p><p>This is no easy feat.</p><p><span>Every time a computer company announces a CPU architecture migration, there is widespread skepticism about whether the business can survive </span><em>its entire software ecosystem being deprecated at once</em><span>.</span></p><p><span>In the days when software still came in cardboard boxes, this skepticism bordered on incredulity. John Dvorak, prominent tech columnist, suggested the 2005 move to Intel x86 was a precursor to </span><a href="https://web.archive.org/web/20060409115933/http://www.pcmag.com/article2/0,1895,1927885,00.asp" rel="">bringing Apple onto Windows</a><span>.</span></p><blockquote><p><span>Apple is the undisputed </span><em><strong>king</strong></em><span> of CPU architecture migrations.</span></p></blockquote><p>Apple’s tolerance for pain in the short term has allowed them to master the processor game. Each new CPU architecture allowed Apple to stay competitive against existential threats; or to place themselves head-and-shoulders above the competition.</p><p>Today, we’re going on an odyssey through the 4 eras of Apple CPU architectures. I’ll colour in the business context — why each migration was necessary — and will show you how Apple survived each transition to end up even stronger than before.</p><p>Along the way, we’ll learn some critical CPU concepts as we go. Chip technology becomes more and more advanced as time marches on, offering us a convenient learning curve as we travel Through The Ages.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6e6bd540-cd5d-42d6-9241-af44ce10c444_573x505.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6e6bd540-cd5d-42d6-9241-af44ce10c444_573x505.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6e6bd540-cd5d-42d6-9241-af44ce10c444_573x505.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6e6bd540-cd5d-42d6-9241-af44ce10c444_573x505.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6e6bd540-cd5d-42d6-9241-af44ce10c444_573x505.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6e6bd540-cd5d-42d6-9241-af44ce10c444_573x505.jpeg" width="573" height="505" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/6e6bd540-cd5d-42d6-9241-af44ce10c444_573x505.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:505,&quot;width&quot;:573,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6e6bd540-cd5d-42d6-9241-af44ce10c444_573x505.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6e6bd540-cd5d-42d6-9241-af44ce10c444_573x505.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6e6bd540-cd5d-42d6-9241-af44ce10c444_573x505.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6e6bd540-cd5d-42d6-9241-af44ce10c444_573x505.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><span>Internal die of the Motorola 68,000 CPU — Image from </span><a href="https://www.cpu-world.com/CPUs/68000/die/L_Motorola-MC68000L8.jpg" rel="">cpu-world.com</a></figcaption></figure></div><p>1981.</p><p>Reagan. MTV. Indiana Jones.</p><p>Apple is stumbling.</p><p>Its early breakout success and cash cow, the Wozniak wizardry of the 1977 Apple II, was creaking under its age.</p><p>The IBM PC has just hit the mass market, precipitating an unprecedented influx of purchase orders for PCs. 24-year-old whizkid Bill Gates was asked to supply IBM’s operating system.</p><blockquote><p><em>In 10 years, let’s check in on our friends at IBM to see how this move went.</em></p></blockquote><p>Apple’s LISA is shaping up to be their flagship product. After being a huge jerk to everybody for 5 years, Steve Jobs has been relegated by the board to run the low-end Macintosh project.</p><p><span>Initially a cheaper mass-market consumer product, the Macintosh under Jobs pivoted to focus on one thing: </span><a href="https://www.howtogeek.com/677270/deja-vu-a-brief-history-of-every-mac-cpu-architecture/" rel="">upstaging the LISA team</a><span>. Steve introduced a cutting-edge </span><a href="https://crm.org/articles/xerox-parc-and-the-origins-of-gui" rel="">totally-not-stolen</a><span> graphical user interface to the Macintosh and demanded his team find the most advanced hardware available at the time.</span></p><p><span>If you want to </span><em>make a dent in the personal computer universe</em><span>, your choice of CPU is critical. This is the hardware in which your OS lives and the platform upon which you nurture your software ecosystem.</span></p><p><span>Very early PCs — the sort that hobbyists like Wozniak assembled in their garages — </span><a href="https://lowendmac.com/2014/cpus-motorola-68000/" rel="">used 8-bit CPUs</a><span>. But if you’re designing a powerful mass-market computer in the early 1980s, you’re going to want to use modern 16-bit processor architecture. There are really three major choices available: The Intel 8088, the Zilog Z8000, or the Motorola 68k.</span></p><p>Here, 8-bit and 16-bit refers to the size, or “width” in bits, of the registers and data bus with which the CPU works.</p><p><span>Let’s get on the same page: a </span><strong>CPU</strong><span> is a device that moves data from computer memory (RAM) into fast temporary memory (registers), runs operations on this data, then moves the output back into memory.</span></p><p><span>A </span><strong>register</strong><span> is the tiniest unit of electronic memory — they each hold just a few bits in the heart of the CPU. The CPU follows instructions (a computer program) to perform operations on this data — manipulating the bits (</span><code>1</code><span>s and </span><code>0</code><span>s).</span></p><p><span>These operations are performed by the </span><strong>Arithmetic-Logic Unit</strong><span> (ALU). This is basically a collection of circuits that perform simple, specialised jobs, such as:</span></p><ul><li><p><span>Adding up binary numbers, e.g. </span><code>0010</code><span> + </span><code>0101</code><span> = </span><code>0111</code></p></li><li><p><span>Perform logical operations, e.g. </span><code>NOT</code><span> </span><code>0000</code><span> = </span><code>1111</code></p></li><li><p><span>Shift bits around, e.g. left-shifting </span><code>0011</code><span> by 1 place becomes </span><code>0110</code></p></li></ul><p><span>The CPU’s control unit decodes instructions one at a time to decide what </span><em>data</em><span> should move to which </span><em>register</em><span>, and which </span><em>register’s data</em><span> should go through which </span><em>ALU circuitry</em><span>.</span></p><p>Perform these operations lots of times, very quickly, and it adds up to outputs such as matrix multiplication, collision physics in a video game, or rasterising image data into on-screen pixels.</p><p>So why does bit width matter?</p><p><span>An 8-bit CPU can run a </span><code>NOT</code><span> operation on </span><code>0010110</code><span> in one clock cycle, inverting its bits into </span><code>1101001</code><span>. A 16-bit CPU leaves this in the dust, converting a hefty </span><code>10100100010110</code><span> into </span><code>01011001101001</code><span> in the same amount of time.</span></p><p>Moreover, a single 8-bit register can point at 2⁸ different byte ‘addresses’ in RAM — a meagre 256 locations in which we can look for data. Due to this limitation, most 8-bit computers needed two registers to store memory addresses. 16-bit registers, or two 8-bit registers stacked against each other, can point to 2¹⁶ memory addresses, meaning access to 64kB of memory.</p><p><strong>Endian-ness</strong><span> becomes a major compatibility consideration when upgrading from 8-bit (1 byte) to 16-bit CPUs (2 bytes). Systems are either big-endian or little-endian, which defines the order in which they store bytes — for example, the number 41,394, in hexadecimal fashion, would be stored on registers as </span><code>A1 B2</code><span> in big-endian systems and </span><code>B2 A1</code><span> in little-endian systems.</span></p><p><span>Lastly, the “</span><strong>data bus</strong><span>” refers to the circuity that connects the CPU to main memory; so a 16-bit bus is essentially twice as fast as an 8-bit bus at reading and writing data to and from memory.</span></p><p>Are we all on the same page? Let’s get back to Apple.</p><p>Let’s imagine you’re Apple’s VP of Hardware presenting to Jobs.</p><p>Which chip architecture do you think you’d choose?</p><ul><li><p>8/16-bit microprocessor — 8-bit registers with a 16-bit data bus.</p></li><li><p>20-bit memory addressing range — supports 640kB of RAM.</p></li><li><p>The IBM PC uses this chip architecture, so it has a strong existing software ecosystem.</p></li><li><p>Low-end price point of ~$35 (in 1983 dollars) thanks to Intel’s massive economies of scale.</p></li><li><p>Little-endian.</p></li></ul><ul><li><p>Pure 16-bit microprocessor — 16-bit registers and 16-bit data bus.</p></li><li><p>23-bit memory addressing rage — supports 8MB of RAM</p></li><li><p>Few large competitors use this architecture, minimal software ecosystem.</p></li><li><p><span>Mid-range price point of ~</span><a href="https://thechipletter.substack.com/p/captain-zilog-crushed-supplemental" rel="">$55 in 1983 dollars</a><span> while looking to build market share.</span></p></li><li><p>(Mostly) big-endian.</p></li></ul><ul><li><p>16/32-bit microprocessor — 32-bit registers with a 16-bit data bus.</p></li><li><p>24-bit memory addressing range —supports 16MB of RAM.</p></li><li><p>Atari and Commodore use this chip architecture, some existing dev ecosystem.</p></li><li><p>Prior supplier relationship with Motorola through the Apple I, Apple II, and LISA.</p></li><li><p>Mid-to-high-end price point of ~$70 in 1983 dollars.</p></li><li><p>Big-endian.</p></li></ul><p><span>Overall, the Motorola 68k appeared to be the forward-thinking choice to </span><a href="https://www.youtube.com/watch?v=VtvjbmoDx-I" rel="">show why 1984 won’t be like 1984</a><span>. The weaker dev ecosystem and compatibility was a necessary sacrifice to provide brand differentiation against the dominant IBM PC.</span></p><p><span>What’s more, the 68k had a (mostly) </span><strong>orthogonal</strong><span> instruction set — this meant that (almost) every CPU operation could be performed on (almost) every register, whereas many competing CPUs had instructions restricted to specific registers. Orthogonality makes a CPU much easier to program, which is ideal when nurturing a nascent software ecosystem.</span></p><p>The 16MB addressing range ended up becoming critical: the Macintosh reserved the top 12MB of RAM for the OS, leaving a pithy 4MB of computer memory shared between software applications.</p><p>If you ever looked, dismayed, at the storage space available in your 16GB iPod Touch in 2012, you’ll know that nothing changes.</p><p>The year is 1994.</p><p>Steve Jobs was ousted by Apple 8 years ago, and is busy inventing Pixar and NeXT.</p><p>Apple is losing relevance.</p><p>Their former bitter PC rival, IBM, was in the long, painful process of having their lunch eaten by Microsoft.</p><p><span>Intel and Bill Gates, who was more commonly known as “the devil” in the 1990s, had entered an unholy marriage referred to as </span><em><a href="https://www.mayin.org/ajayshah/MEDIA/1998/wintel.html" rel="">Wintel</a><span> </span></em><span>that was carving out near-monopolies for both businesses.</span></p><p><span>Beyond consistent improvement to their powerful x86 chip architecture, Intel had just produced the greatest innovation since the transistor: giving their chip a cool name. The </span><em>Pentium </em><span>processor powered the Microsoft market-share munching machine.</span></p><p>That’s not to downplay the power of x86 chip architecture: Intel was earning its dominance with a 100MHz clock speeds and unparalleled power efficiency. The Motorola 68,000 chip family that carried the Macintosh into the 90’s was failing to keep up.</p><p>With the computer world under threat from monopoly, Apple joined up with its longtime partner, Motorola, and an unlikely ally, IBM. The plan: use the power of friendship to fight the forces of capitalism.</p><p>The AIM (Apple, IBM, Motorola) alliance was born. They realised that the x86 architecture had a key weakness: it utilised CISC architecture.</p><p><span>In response, AIM deployed a RISCy tactic: </span><strong>PowerPC</strong><span>.</span></p><p>There are two opposing chip design philosophies:</p><ul><li><p><strong>CISC</strong><span> (Complex Instruction Set Computer)</span></p></li><li><p><strong>RISC</strong><span> (Reduced Instruction Set Computer)</span></p></li></ul><p><span>To understand this, we need to get a handle on what is meant by </span><strong>Instruction Sets</strong><span>. In the previous section, I mentioned the CPU is running </span><em>operations</em><span> every </span><em>clock cycle</em><span>. These operations include things like moving data between registers, arithmetic, and logic operations.</span></p><p><span>Each CPU, constrained by the actual physical layout of its circuitry, can perform a limited number of different operations. These individual operations are represented by </span><strong>Assembly Language</strong><span>, also called machine code. This code is fed into the processor as a sequence of binary instructions and performed sequentially.</span></p><p>The two schools of thought lead to divergent approaches for building microprocessors:</p><ul><li><p><strong>CISC </strong><span>accepts a complex instruction set to continue adding functionality to your CPU. Eventually, you gain the power to perform complex multi-step processing with single instructions, such as the (in)famous </span><em>evaluate polynomial</em><span> instruction, </span><code>POLY</code><span>. While this felt like magic, it also meant lots of internal state was held by the processor — and devastating performance hits if anything goes wrong.</span></p></li><li><p><strong>RISC</strong><span> takes the “Keep it simple, stupid!” approach. The big pitfall in CISC was complexity for the developers. The compiler engineers writing for CISC architectures had to consult 500-page manuals to find the instructions they might need, while RISC engineers were laughing with the 60-ish instructions stored in their registers — I mean — brains.</span></p></li></ul><p><span>To really see the primary performance boost endowed by RISC, you need to understand </span><strong>Pipelining</strong><span> by looking at the fetch-decode-execute cycle. In short, in a single clock cycle — the time for one operation to execute on the CPU — one of three things is done:</span></p><ul><li><p><strong>Fetch:</strong><span> The CPU fetches the next machine code instruction from memory.</span></p></li><li><p><strong>Decode</strong><span>: The CPU’s control unit interprets the instruction to work out what it actually does.</span></p></li><li><p><strong>Execute: </strong><span>The CPU executes the instruction — that is; moving data between registers and memory, or pushing bits through logic units.</span></p></li></ul><p><span>When your CPU uses a simpler RISC instruction set, these steps each take a single cycle, and you can </span><em>line up these operations concurrently</em><span>. In each clock cycle, you can get 3 instruction running, 1 at each of the 3 stages, in parallel. This results in (on average) one machine code operation executed per clock cycle.</span></p><p><span>When using CISC, each steps might not take a consistent 1-cycle-per-step. For the </span><code>POLY</code><span> operation, the execute step alone might take 10 cycles for an x² expression. In CISC, it’s hard to get your operations lining up nicely and therefore it’s tough to get good performance on complex instructions.</span></p><p>Pipelining, in short, is the concept of interleaving these instructions concurrently.</p><p>Apple and the AIM alliance hatched their scheme.</p><p>PowerPC, a modern Reduced Instruction Set Computer microprocessor architecture, was built to compete directly with the dominant Intel x86 architecture.</p><p>PowerPC promised better efficiency — that is, more CPU operations per watt of electricity — and since Apple controlled both software and hardware, they could optimise the Mac OS for this processor architecture.</p><p>Now they just had to migrate their ecosystem.</p><p>Software written for one processor doesn’t necessarily run on another. Different families of processors naturally contain different instruction sets — that is, the list of assembly instructions that define each CPU operation.</p><p>Here’s a slice of Motorola 68k assembly code:</p><pre><code>MOVE.L  $1000, D0     ; Load longword from address $1000 into data register D0
MOVE.L  $1004, D1     ; Load longword from address $1004 into data register D1
ADD.L   D1, D0        ; Add the values in D0 and D1, result stored in D0
MOVE.L  $1000, D0     ; Load longword from address $1000 into data register D1
NOT.L   D1            ; Invert all bits in D1</code></pre><p>And now, here is what PowerPC assembly code looked like:</p><pre><code>lwz     r3, 0x1000    ; Load word from address 0x1000 into register r3
lwz     r4, 0x1004    ; Load word from address 0x1004 into register r4
add     r5, r3, r4    ; Add the values in r3 and r4, result stored in r5
lwz     r3, 0x1000    ; Load word from address 0x1000 into register r3
not     r4, r3        ; Invert all bits in r3 and store the result in r4</code></pre><p><span>Since the machine instructions themselves are different, all the existing software in Apple’s ecosystem would need to be re-compiled, and in some cases re-written (such as when writing compiler software, or when code makes </span><a href="https://www.reddit.com/r/AskComputerScience/comments/1tg6dw/when_apple_made_the_switch_from_powerpc_to_intel/" rel="">assumptions about endian-ness</a><span>), in order to work on PowerPC machines.</span></p><p>Apple needed a plan.</p><p>Apple developed two strategies to manage this transition:</p><p><span>A </span><strong>Emulator</strong><span> was developed where PowerPC could </span><a href="https://computerhistory.org/blog/transplanting-the-macs-central-processor-gary-davidian-and-his-68000-emulator/" rel="">emulate the Motorola CPU</a><span>. This translates instructions from one instruction set architecture to another in real-time.</span></p><p>This, unsurprisingly, incurs a huge performance cost. Fortunately, since the PowerPC CPUs were so powerful, emulation wasn’t usually a massive issue for consumers who were upgrading their hardware.</p><p><span>Another strategy which Apple employed was to use “</span><strong>fat binaries</strong><span>” for software during the transition period. This allowed software to contain code compiled for both 68k and PowerPC architectures. Therefore, engineers could ship a single app which worked on both Mac CPU platforms by containing two separate binaries.</span></p><p><span>In the era when 80MB was a </span><em>decent</em><span> hard drive, this was pretty annoying, so </span><a href="https://apple.fandom.com/wiki/Fat_binary" rel="">a cottage industry</a><span> of binary stripping tools spawned so end-users only needed to save the one that worked on their device.</span></p><p>Overall, Apple’s migration was a success. Moving from 68k to PowerPC lent a massive performance boost. Emulation and fat binaries allowed the software ecosystem to transition without a major hitch.</p><p><span>Unfortunately, the </span><em>Wintel</em><span> alliance was barely touched. Their market dominance grew to unprecedented levels with the release of Pentium and Windows 95. Windows grew into </span><em>the</em><span> default computing platform, tragically transforming school ICT curriculums the world over into “how to use Microsoft Office”.</span></p><p><span>Now that they had a solid hardware platform, Apple’s antiquated System 7 Mac OS became the primary headwind. </span><a href="https://www.quora.com/Why-did-Apple-buy-NeXT-Computer" rel="">Internal projects to create a modern competitor to Windows had failed</a><span>, which meant an acquisition was the only way out of a tailspin — simply buying a new OS.</span></p><p>This laid the groundwork for Apple’s purchase of NeXT and the return of Steve Jobs.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0ac0a9dd-fd43-42c8-97d4-1cbc51128deb_500x419.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0ac0a9dd-fd43-42c8-97d4-1cbc51128deb_500x419.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0ac0a9dd-fd43-42c8-97d4-1cbc51128deb_500x419.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0ac0a9dd-fd43-42c8-97d4-1cbc51128deb_500x419.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0ac0a9dd-fd43-42c8-97d4-1cbc51128deb_500x419.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0ac0a9dd-fd43-42c8-97d4-1cbc51128deb_500x419.jpeg" width="500" height="419" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/0ac0a9dd-fd43-42c8-97d4-1cbc51128deb_500x419.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:419,&quot;width&quot;:500,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0ac0a9dd-fd43-42c8-97d4-1cbc51128deb_500x419.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0ac0a9dd-fd43-42c8-97d4-1cbc51128deb_500x419.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0ac0a9dd-fd43-42c8-97d4-1cbc51128deb_500x419.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0ac0a9dd-fd43-42c8-97d4-1cbc51128deb_500x419.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><span>Intel Pentium 4 600 Series die (the large block to the left is its hefty 2MB L2 cache) — from </span><a href="https://www.anandtech.com/show/1621/3" rel="">AnandTech</a></figcaption></figure></div><p>By the early 2000s, Apple had its mojo back.</p><p><span>Jobs is CEO. An era-defining software transition to Mac OS X had been a success. The iPod has turned a struggling computer company with single-digit market share into a </span><a href="https://www.cnet.com/tech/mobile/features/inventing-the-ipod-how-really-big-risks-paid-off-for-apple/" rel="">consumer electronics powerhouse</a><span>.</span></p><p><span>Desktops dominated the 80s, the 90s, and the turn of the millennium. But as </span><a href="https://www.intel.com/content/www/us/en/history/virtual-vault/articles/moores-law.html" rel="">Moore’s Law</a><span> marches inexorably onwards, electronics are miniaturising and </span><a href="https://www.theguardian.com/technology/2009/oct/28/laptops-sales-desktop-computers" rel="">laptops are becoming big business</a><span>.</span></p><p>When your hardware isn’t connected to mains electricity, battery becomes a bottleneck. With performance-per-watt the foremost concern, one thing became clear in the early 2000s: PowerPC architecture was failing to keep pace behind the Intel x86 behemoth.</p><p><span>Intel had simply been out-executing, out-manufacturing, and out-R&amp;D-ing the competition. Their </span><a href="https://www.quora.com/Why-was-the-PowerPC-architecture-unable-to-keep-up-with-Intel-x86" rel="">vast installed base</a><span> of Windows hardware granted an unbeatable ecosystem of compatible software, and printed money to further invest in deepening the Intel processor technology moat.</span></p><p><span>The early-2000s PowerPC CPUs used far too much power and generated </span><a href="https://everymac.com/mac-answers/macintel-faq/why-did-apple-switch-to-intel.html" rel="">far too much heat</a><span> to create the ultra-thin </span><a href="https://www.cultofmac.com/522973/macbook-air-worlds-thinnest-notebook/" rel="">MacBook Air</a><span> that Jobs was envisioning. With more than 50% of their revenues already drawn from laptop computers, the decision was clear: to compete, Apple </span><em>had</em><span> to switch to Intel.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fecc3b4c4-aea0-4495-919b-eaa9e4656f30_700x369.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fecc3b4c4-aea0-4495-919b-eaa9e4656f30_700x369.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fecc3b4c4-aea0-4495-919b-eaa9e4656f30_700x369.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fecc3b4c4-aea0-4495-919b-eaa9e4656f30_700x369.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fecc3b4c4-aea0-4495-919b-eaa9e4656f30_700x369.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fecc3b4c4-aea0-4495-919b-eaa9e4656f30_700x369.png" width="700" height="369" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/ecc3b4c4-aea0-4495-919b-eaa9e4656f30_700x369.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:369,&quot;width&quot;:700,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fecc3b4c4-aea0-4495-919b-eaa9e4656f30_700x369.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fecc3b4c4-aea0-4495-919b-eaa9e4656f30_700x369.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fecc3b4c4-aea0-4495-919b-eaa9e4656f30_700x369.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fecc3b4c4-aea0-4495-919b-eaa9e4656f30_700x369.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><span>Steve Jobs announces the switch from PowerPC to Intel at </span><a href="https://www.youtube.com/watch?v=JcHQXMAd0c0" rel="">WWDC 2005</a></figcaption></figure></div><p>Jobs explained it best at Apple’s 2005 Worldwide Developer Conference:</p><blockquote><p><em>“I stood up here two years ago in front of you and I promised you a 3 GHz Mac, and we haven’t been able to deliver that to you yet.</em></p><p><em>… As we look ahead we can of envision some amazing products we want to build for you and we don’t know how to build them with the future PowerPC roadmap.”</em></p></blockquote><p><strong>But my favourite part of the video?</strong></p><blockquote><p><em>“So get on Xcode 2.1 and get your copy today. There will be a copy for everybody at the registration desk immediately following this keynote.”</em></p></blockquote><p><span>As someone who became a developer in the 2010s, picking up a CD at a conference for your latest Xcode update seems so </span><em>quaint</em><span>. I wonder if the 2005 Betas were as glitchy as we are used to today.</span></p><p>What really fascinates me, however, is this:</p><p><span>Intel x86 processors are descended from a family of instruction set architectures pioneered in 1978 with the Intel 8086. Future processors, such as 1982's Intel 80186 or 2000’s Pentium 4, maintained backwards compatibility with this original instruction set. You’re reading that right: a program compiled on 8086 in the 70s would run fine in the 2000s </span><em>without any modification</em><span>.</span></p><p>But software ecosystem is just part of the story.</p><p>By 2006, high-end Intel x86 processors were projected to produce almost 5x the performance per watt compared to PowerPC, and nearly 1.5x the clock speed.</p><p>Intel was innovating on all aspects of their CPUs, such as:</p><ul><li><p>CPU Caches (L1, L2, and L3)</p></li><li><p>Branch Prediction</p></li><li><p>Superscalar Architecture</p></li></ul><p>Let’s go over these in some detail, since they are really important concepts in modern CPU performance. No piece single-handedly made Intel’s x86 the winner — the interconnected nature of a CPU meant that optimisation across all these components (and more) kept x86 ahead of the pack.</p><p>As previously explained, a CPU takes data from memory (RAM), places it in ultra-fast registers on the processor chip, and performs operations on that data. But at gigahertz clock speeds (1,000,000,000 operations per second), fetching instructions and data from RAM is far too slow.</p><p>Therefore, CPUs evolved on-chip caches to store middling amounts of data. These act as intermediary miniature blocks of RAM, stored physically closer to the chip itself, and allow for faster access to the necessary data.</p><p>These caches are themselves tiered:</p><ul><li><p><span>The </span><strong>L1 Cache </strong><span>is the smallest, fastest tier — directly integrated with the CPU core to store a small amount of data (a few kB) for rapid retrieval. Since these are integrated so close to the processor circuitry itself, there is an L1 Cache for each CPU core.</span></p></li><li><p><span>The </span><strong>L2 Cache</strong><span> is the middle layer, balancing speed and capacity, usually integrated somewhere on the CPU chip itself (and like all middle siblings, usually left to the side). This cache could be partitioned for each CPU core, or shared between them all.</span></p></li><li><p><span>The </span><strong>L3 Cache</strong><span> is the final buffer before the dreaded cache miss forces the CPU to search for data in RAM — a pyrrhic round-trip across the motherboard and back. This tier of storage is a shared memory pool of many megabytes between all CPU cores.</span></p></li></ul><p>This diagram from Harvard’s CS course explains better than I ever could:</p><p><span>Whenever a CPU needs to fetch instructions or data that isn’t stored in the nearest cache, it’s known as a </span><em>cache miss</em><span>. It needs to fetch from the next tier of cache, or the next tier, or RAM, or disk! This can badly impact speed and efficiency.</span></p><p>As a macro-scale analogy, consider how slowly your app appears to load when your program has to look for data over the network, instead of from local storage. Round-trips on the nano-scale of a CPU can add up quickly.</p><p><span>By the mid-2000s, </span><a href="https://forums.macrumors.com/threads/analysis-x86-vs-ppc-this-article-is-concerned-with-the-tec.31775/" rel="">Intel’s x86 CPU caches dwarfed those on PowerPC</a><span>, meaning lower latency and better performance. When supplemented with improved pre-fetching and predictive algorithms, expensive cache misses became less of a problem on x86.</span></p><p>These in turn improved performance-per-watt because when data is next to the processor, less electricity is physically being moved through the CPU’s circuitry to move bytes of memory around.</p><p>Branch Prediction sounds like arcane, occult magick when you first hear about it.</p><p><span>Branch instructions are the assembly code versions of conditional statements such as </span><code>if</code><span>/</span><code>else</code><span> — manifesting on the processor as </span><a href="https://blog.cloudflare.com/branch-predictor/" rel="">jumps, calls, and returns</a><span>. Clever CPUs use statistics to guess where the code is going, and try to keep the instruction pipeline filled for maximum utilisation.</span></p><p><span>The mechanism for this involves hardware algorithms built directly into the circuits of the CPU. A buffer called the Branch History Table caches recent branch outcomes. </span><a href="https://www.geeksforgeeks.org/correlating-branch-prediction/" rel="">Patterns are analysed</a><span> to draw predictions.</span></p><p><span>Advanced branch predictors apply the ultimate YOLO method: speculative execution, where instructions on the predicted branch are executed </span><em>before the outcome is confirmed</em><span>.</span></p><p>Intel’s silicon crystal balls helped the x86 processor go far faster than non-psychic CPUs.</p><p><span>Superscalar architecture is the ultimate in multitasking. Superscalar CPUs can simultaneously </span><a href="https://www.elprocus.com/superscalar-processor" rel="">execute multiple instructions</a><span> during a single clock cycle:</span></p><ul><li><p><span>In the </span><strong>fetch</strong><span> phase, the CPU collects multiple instructions from the operation pipeline.</span></p></li><li><p><span>The </span><strong>decode</strong><span> phase utilises multiple decoder units to evaluate each instruction.</span></p></li><li><p><span>These instructions may be dispatched to different </span><strong>execution </strong><span>units of the CPU.</span></p></li></ul><p>This architecture works because operations such as arithmetic, moving memory between registers, and floating-point operations require different pieces of circuitry on the ALU. Therefore, if you’re clever, several instructions can be performed in parallel.</p><p><span>This is a tough process to get right. </span><a href="https://kb.iu.edu/d/aett" rel="">Bottlenecks can occur</a><span> if multiple simultaneous operations need to use the same resource such as the same register or the same ALU adder circuit. Dependency issues can also lead to stalls, especially if an instruction is stuck waiting on the result of another longer-running operation.</span></p><p>Intel had the will and, more importantly, the R&amp;D dollars, to get superscalar architecture working effectively on their CPU cores.</p><p>As well as caching, branch prediction, and superscalar architecture, Intel’s x86 chips further optimised many features of their CPUs:</p><ul><li><p><strong>Advanced pipelining</strong><span> that split the fetch, decode, execute cycle </span><a href="https://arstechnica.com/gadgets/2011/04/ask-ars-whats-the-relationship-between-cpu-clockspeed-and-performance/" rel="">into up to 21 stages</a><span> that allowed for far more instructions to run per second at a given clock speed.</span></p></li><li><p><span>Increased </span><a href="https://www.quora.com/To-what-degree-do-applications-for-x86-processors-utilize-multiple-cores-for-parallel-execution" rel="">numbers of </a><strong><a href="https://www.quora.com/To-what-degree-do-applications-for-x86-processors-utilize-multiple-cores-for-parallel-execution" rel="">execution units</a><span> </span></strong><span>in the ALUs to allow for easier parallelisation of operations from superscalar architecture.</span></p></li><li><p><strong>Hyper-threading</strong><span> which allowed a single CPU core to present to the OS as 2 logical cores, enabling one core to </span><a href="https://www.androidauthority.com/intel-hyper-threading-explained-1226271/" rel="">execute 2 threads simultaneously</a><span>.</span></p></li></ul><p>Apple again employed their time-honoured transition techniques for a smooth CPU architecture migration.</p><p>Apple introduced universal binaries built for both CPU architectures, which could be set up with a simple Xcode build configuration.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F93a73a6c-9564-4efe-b6a9-1575811df41f_700x370.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F93a73a6c-9564-4efe-b6a9-1575811df41f_700x370.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F93a73a6c-9564-4efe-b6a9-1575811df41f_700x370.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F93a73a6c-9564-4efe-b6a9-1575811df41f_700x370.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F93a73a6c-9564-4efe-b6a9-1575811df41f_700x370.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F93a73a6c-9564-4efe-b6a9-1575811df41f_700x370.png" width="700" height="370" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/93a73a6c-9564-4efe-b6a9-1575811df41f_700x370.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:370,&quot;width&quot;:700,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F93a73a6c-9564-4efe-b6a9-1575811df41f_700x370.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F93a73a6c-9564-4efe-b6a9-1575811df41f_700x370.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F93a73a6c-9564-4efe-b6a9-1575811df41f_700x370.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F93a73a6c-9564-4efe-b6a9-1575811df41f_700x370.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><span>Steve Jobs explains how to build a Universal Binary in Xcode at </span><a href="https://www.youtube.com/watch?v=JcHQXMAd0c0" rel="">WWDC 2005</a></figcaption></figure></div><p><span>Apple also introduced Rosetta, a </span><a href="https://www.wikiwand.com/en/Rosetta_(software)" rel="">dynamic binary translator</a><span> which Apple described as “the most amazing software you’ll never see”. It was embedded in Mac OS X Tiger, the first OS released on x86 Macs, and allowed PowerPC apps to run on x86 </span><em>automagically</em><span>.</span></p><p><span>Apple goes very far out of their way to explain that </span><a href="https://web.archive.org/web/20101116094453/http://www.apple.com/asia/rosetta/" rel="">Rosetta is not an emulator </a><span>— Rosetta dynamically translates code ‘on the fly’ as your program runs. In practice, what this meant was that PowerPC CPU instructions and OS system calls from the application binary were translated into equivalent x86 assembly and syscalls.</span></p><p><span>Apple under-promised with a years-long transition timeline and over-delivered way ahead of schedule, </span><a href="https://www.apple.com/uk/newsroom/2008/01/15Apple-Introduces-MacBook-Air-The-Worlds-Thinnest-Notebook/" rel="">fulfilling Jobs’ dreams of tiny form factors </a><span>and bringing Apple into the modern age.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50724fa6-477e-445f-8c3b-a351b9149e52_678x646.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50724fa6-477e-445f-8c3b-a351b9149e52_678x646.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50724fa6-477e-445f-8c3b-a351b9149e52_678x646.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50724fa6-477e-445f-8c3b-a351b9149e52_678x646.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50724fa6-477e-445f-8c3b-a351b9149e52_678x646.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50724fa6-477e-445f-8c3b-a351b9149e52_678x646.png" width="678" height="646" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/50724fa6-477e-445f-8c3b-a351b9149e52_678x646.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:646,&quot;width&quot;:678,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50724fa6-477e-445f-8c3b-a351b9149e52_678x646.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50724fa6-477e-445f-8c3b-a351b9149e52_678x646.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50724fa6-477e-445f-8c3b-a351b9149e52_678x646.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50724fa6-477e-445f-8c3b-a351b9149e52_678x646.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><span>Annotated diagram of the 2020 Mac Mini M1 CPU die, from </span><a href="https://www.anandtech.com/show/16252/mac-mini-apple-m1-tested" rel="">AnandTech</a></figcaption></figure></div><p><span>Anyone who’s read </span><a href="https://www.waterstones.com/book/steve-jobs/walter-isaacson/9780349140438" rel="">Walter Isaacson’s</a><span> book on Jobs will know Apple’s ethos, and their ultimate competitive advantage: the tight integration of hardware and software to produce </span><em>insanely great</em><span> products.</span></p><p><span>Reliance on Intel for x86 CPUs meant a sometimes painful dependency on Intel’s </span><a href="https://wccftech.com/apple-macbook-air-delay-intel/" rel="">supply constraints</a><span> and </span><a href="https://www.cnbc.com/2020/07/24/intel-chip-delay-shows-exactly-why-apple-is-right-to-move-to-arm.html" rel="">release delays</a><span> which sometimes impacted Apple’s roadmap.</span></p><p><span>For decades, the CPU had been </span><em>the one that got away</em><span>. From the off-the-shelf </span><a href="https://www.apple1registry.com/en/theapple1.html" rel="">MOS 6502</a><span> microprocessor of the Apple I to the high-end </span><a href="https://support.apple.com/kb/SP797?locale=en_GB" rel="">Intel Xeon</a><span> CPU of the 2019 Mac Pro, Apple never truly owned this part of the value chain.</span></p><p>But now, they could.</p><p>The O.G. 2G iPhone released in 2007 with an ARM CPU supplied by Samsung. At the turn of the decade, however, from the iPhone 4, Apple began to design its own chips, starting with the A4.</p><p>Apple iterated. And then continued to iterate.</p><p>2020.</p><p>The iPhone is the god of all cash cows.</p><p><span>Apple, now the most valuable publicly-traded company on the planet, is plowing $20,000,000,000 of cash flow into R&amp;D </span><a href="https://www.macrotrends.net/stocks/charts/AAPL/apple/research-development-expenses" rel="">like it’s nothing</a><span>.</span></p><p><em>Wait a moment</em><span> — before we get to the present day, we need to go back in history a bit. This might get bumpy.</span></p><p><span>In 2008, Apple purchased </span><a href="https://www.computerworld.com/article/2536788/apple-to-buy-processor-designer-p-a--semi--says-report.html" rel="">P.A. Semiconductor</a><span> for $278m, a CPU design company known for high-end low-power processors. P.A.’s CPUs were originally based on IBM’s Power architecture — the very same instruction set used by the AIM alliance in the PowerPC Macs.</span></p><p>At the time, Android OS was entering the smartphone market. Owning its own chip designs would allow the iPhone to differentiate further from competitors in the newly crowded market. The acquisition also allowed Apple, famous for its obsessive degree of secrecy, to keep its best proprietary chip designs hush-hush in-house.</p><p><span>This acquisition was supplemented a decade later, in 2018, with a partial </span><a href="https://www.theverge.com/2018/10/11/17963112/apple-dialog-chipmaker-power-management-acquihire-acquisition" rel="">acqui-hire of Dialog</a><span>, a European chip designer, for $300m.</span></p><p><em>Alright, can we talk about M1 now?</em></p><p><span>No. First, we must go back </span><em>even</em><span> further.</span></p><p><span>ARM’s RISC instruction set and chip designs are dominant today. ARM was in fact </span><a href="https://www.google.com/search?q=arm+fgounded+by+apple&amp;oq=arm+fgounded+by+apple&amp;aqs=chrome..69i57j46i131i199i433i465i512l2j0i131i433i512j46i131i199i433i465i512l2j0i433i512l2j46i131i199i433i465i512.1998j0j4&amp;sourceid=chrome&amp;ie=UTF-8" rel="">founded in 1990</a><span> as a joint venture between Apple and Acorn Computers. Legend has it — and by legend I mean </span><a href="https://www.quora.com/Why-is-Apples-M1-chip-so-fast-yet-power-consumption-so-much-lower-compared-to-mainstream-technology-from-chip-leaders-Intel-AMD-Whats-special-about-its-design-architecture-that-made-it-so-amazing" rel="">this unsourced claim on Quora</a><span> — that Steve Jobs convinced Acorn to abandon their hardware products and focus on low-power processor design.</span></p><p><span>I </span><em>want to</em><span> believe it, because it’s just perfectly emblematic of the long-term thinking that made Apple what it is today.</span></p><p>Anyway. You follow? Grand. Back to 2020.</p><p>Apple Engineers had been designing and iterating upon the ARM chips in the iPhone and iPad for years.</p><p>Due to the mobile form factor — it’s tough to fit cooling fans in your pocket — power consumption and heat efficiency are the big concerns. RISC architecture is the clear answer to this, supplanting the x86 giant in mobile use cases.</p><p><span>And by 2020, these ARM CPUs had been improving </span><em>fast</em><span>.</span></p><p><em>Way faster</em><span> than Intel’s x86 chips.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7691df53-c1de-44c1-bb4b-688ddd1ad63a_678x732.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7691df53-c1de-44c1-bb4b-688ddd1ad63a_678x732.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7691df53-c1de-44c1-bb4b-688ddd1ad63a_678x732.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7691df53-c1de-44c1-bb4b-688ddd1ad63a_678x732.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7691df53-c1de-44c1-bb4b-688ddd1ad63a_678x732.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7691df53-c1de-44c1-bb4b-688ddd1ad63a_678x732.png" width="678" height="732" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7691df53-c1de-44c1-bb4b-688ddd1ad63a_678x732.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:732,&quot;width&quot;:678,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7691df53-c1de-44c1-bb4b-688ddd1ad63a_678x732.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7691df53-c1de-44c1-bb4b-688ddd1ad63a_678x732.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7691df53-c1de-44c1-bb4b-688ddd1ad63a_678x732.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7691df53-c1de-44c1-bb4b-688ddd1ad63a_678x732.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><span>The quintessential disruption graph, from </span><a href="https://www.anandtech.com/show/16226/apple-silicon-m1-a14-deep-dive/4" rel="">AnandTech</a></figcaption></figure></div><p><span>Apple’s custom ARM CPUs had improved to the point where </span><a href="https://www.anandtech.com/show/16226/apple-silicon-m1-a14-deep-dive/4" rel="">there was no question about it</a><span>—they was powerful enough to use </span><a href="https://www.macrumors.com/guide/apple-silicon/" rel="">in Apple laptops</a><span>.</span></p><p>In 2020, Apple announced its third great Mac CPU architecture transition with the M1 — heralding the age of Apple Silicon.</p><p><span>The M1 was the first iteration of the “M family” of </span><em>Apple Silicon</em><span> chips, their custom hardware for Mac laptops and desktops. It has siblings such as the M1 Pro, the M1 Max, and the M1 Ultra. Today, you can even buy M2 chips in the latest hardware (but I’m holding out for M3 before I start petitioning my CTO).</span></p><p><span>The M1 is a </span><a href="https://www.production-expert.com/production-expert-1/why-are-the-apple-m1-m1-pro-and-m1-max-chips-so-fast" rel="">system-on-a-chip</a><span> (SoC). This is an approach to building hardware that differs from standard desktop PCs. Instead of mounting interchangeable components on a motherboard (such as CPU, storage, RAM, graphics card), SoCs integrate everything into a single component, which is why the approach lent itself naturally to space-constrained mobile devices.</span></p><p>Upgrading to an M1 MacBook for the first time is like magic. A real game-changer. Everything is lightning-fast, the cooling fan never seems to switch on, and the battery lasts all day on a single charge.</p><p><span>How is the M1 so powerful, when using</span><em> so little power?</em></p><p>As mentioned in the Intel section, the interconnected nature of a CPU usually makes it tough to evaluate outperformance between chip architectures.</p><p>Intel’s primary performance driver has been to shrink transistors and fit more, faster, CPU cores onto the chip. More, faster, CPU cores leads naturally to higher performance.</p><p><span>But in the case of the M1, there is a completely different approach which leads to its outperformance: </span><strong>Specialisation</strong><span>.</span></p><p><span>The M1 chips apply a </span><a href="https://debugger.medium.com/why-is-apples-m1-chip-so-fast-3262b158cba2" rel="">heterogeneous computing strategy</a><span>. This means specialised components for specific workloads. PC gamers are already familiar with this. For decades, Nvidia has been selling graphics cards — GPUs — to handle the specialised parallel workloads you encounter with videogame rendering engines.</span></p><p>Apple takes this approach to the next level with a radical shift in the direction of heterogeneous workloads. The components of the M1 SoC are specialised for many computing tasks:</p><ul><li><p>Image processing circuitry</p></li><li><p>Mathematical signal processors</p></li><li><p>AI-accelerating neural engines</p></li><li><p>Dedicated video encoder and decoders</p></li><li><p>A secure enclave for encrypted storage</p></li><li><p>8 GPU cores with 128 parallel execution units</p></li><li><p><span>4 high-performance </span><em><a href="https://www.anandtech.com/show/16252/mac-mini-apple-m1-tested" rel="">Firestorm</a></em><a href="https://www.anandtech.com/show/16252/mac-mini-apple-m1-tested" rel=""> CPU cores</a></p></li><li><p><span>4 efficient, low-energy </span><em>Icestorm</em><span> CPU cores</span></p></li></ul><p><span>This approach to utilising twin sets of CPUs was coined by ARM as </span><a href="https://www.arm.com/technologies/big-little" rel="">big.LITTLE architecture</a><span>, which optimises power consumption for those general CPU workloads not dispatched to specialist components.</span></p><p><span>The Firestorm CPUs relentlessly execute time-sensitive workloads requested by the user; while the Icestorm CPUs handle background workloads more slowly while consuming </span><a href="https://www.imore.com/mac-apple-silicon-transition-everything-you-need-know" rel="">90% less power</a><span>.</span></p><p>As well as the core heterogeneous architecture of the Apple Silicon SoC, there are some further supplementary reasons for the astonishing M1 performance:</p><ul><li><p>Unified Memory Architecture</p></li><li><p>Out-of-order Execution</p></li><li><p>Physics: The Ultimate Constraint</p></li></ul><p><span>The M1 chips have a </span><strong><a href="https://debugger.medium.com/why-is-apples-m1-chip-so-fast-3262b158cba2" rel="">unified memory architecture</a></strong><span> shared between GPU and CPUs. This is a masterstroke for performance. When sending data to an external GPU for processing, a CPU usually needs to copy data into the memory owned by the GPU, before it could be picked up for processing.</span></p><blockquote><p><em><span>This is the problem </span><strong>Metal</strong><span> was introduced to solve — intermediary translation of a graphics driver utilises the CPU, which introduces a serious performance bottleneck when you really want graphics instructions to go to the GPU.</span></em></p><p><em><span>Interested? Read more in my previous entry in this series, </span><a href="https://medium.com/better-programming/through-the-ages-apple-animation-apis-2ab5925f546b#f4ef" rel="">Through the Ages: Apple Animation APIs</a><span>.</span></em></p></blockquote><p>Why don’t all processors have integrated graphics?</p><p>In order to get this right, Apple had to solve two major problems that arise when integrating CPU and GPU onto a SoC:</p><ul><li><p>CPUs and GPUs like their data formatted differently. CPUs love to nibble small bytes little and often, GPUs like to guzzle massive blobs of data, infrequently, for massively parallel processing.</p></li><li><p>GPUs make heat. A lot of heat. This is why graphics cards have integrated cooling fans for that “jumbo jet” aesthetic.</p></li></ul><p>Apple’s approach allocates the same blocks of memory — both RAM and L3 cache — shared between both processors, in a format that can supply big chunks that the GPU likes at the high throughput that the CPU requires. Their ARM chips are low-energy enough to integrate on the same die without melting a hole through your lap(top).</p><p>While the heterogeneous architecture allows specialised workloads to go to the best tool for the job, the Firestorm CPU cores themselves are extremely powerful for general workloads.</p><p><span>We previously discussed superscalar architecture that enabled CPU cores to simultaneously fetch, decode, and dispatch multiple instructions at once. The M1 chips, by virtue of their RISC architecture, allow Apple to take this to the next level with </span><a href="https://debugger.medium.com/why-is-apples-m1-chip-so-fast-3262b158cba2#8ac1" rel="">out-of-order execution</a><span>.</span></p><p>ARM RISC instructions are all 4 bytes long (32 bits), while x86 CISC instructions vary from 1–15 bytes. This means ARM chips can easily split up a continuous stream of instruction bytes straight to decoders without any analysis overhead.</p><p><span>The basic M1 chip has an insane </span><strong>8 decoders</strong><span>, which the Firestorm CPU cores fill simultaneously each clock cycle. These instructions are dispatched in parallel to its various specialised pieces of circuitry.</span></p><p><span>Apple Silicon analyses a dependency graph between hundreds of instructions at once, so it knows what can be dispatched now and what needs to wait on results. Pair this with its </span><a href="https://drive.google.com/file/d/1WrMYCZMnhsGP4o3H33ioAUKL_bjuJSPt/view" rel="">advanced branch prediction</a><span>, and the M1 CPU is essentially </span><a href="https://mistborn.fandom.com/wiki/Atium" rel="">burning Atium</a><span>.</span></p><p>There is one final reason this SoC is so fast and so power-efficient. It’s the same concept we looked at when learning about CPU caches.</p><p><span>Simply put, everything on the M1 chip is physically so close together. Even with electrical signals moving literally at lightning speed, operations are simply </span><em>faster</em><span> when there is less distance to travel.</span></p><p>At GHz clock speeds, those nanoseconds add up.</p><p>For the M1 Ultra chips, designed to give the maximum output, Apple took a more blunt instrument out of its tool-belt. Instead of an extreme ultraviolet lithography machine, Tim Cook took out a sledgehammer.</p><p><span>The M1 Ultra chip is </span><a href="https://www.wired.com/story/apple-m1-ultra-chip-moores-law/" rel="">simply two M1 Max chips stuck together</a><span>.</span></p><p>It’s perhaps a little more subtle than that — the bridging structure enables a pretty inter-chip throughput of 2.5TB/s, which allows the components to behave exactly as if they’re the same chip.</p><p>Apple continued to apply its battle-tested approach for the transition from Intel x86 to Apple Silicon.</p><p>Developers can build universal apps which contain both Intel and Apple Silicon binaries. Additionally, Rosetta has been upgraded to Rosetta II to invisibly interpret Intel instructions into ARM on-the-fly.</p><p><span>Grandiose as always, Apple claims that some </span><a href="https://www.imore.com/mac-apple-silicon-transition-everything-you-need-know" rel="">Intel apps and games will perform better</a><span> on ARM using Rosetta II than they did on their original.</span></p><p><span>It was a painful blow to Intel for one of their biggest customers to break off their longstanding partnership. Intel is somewhat </span><a href="https://9to5mac.com/2021/10/18/intels-apple-silicon-take/" rel="">in denial of reality</a><span> and is pretty sure they can catch up by investing further in their own.</span></p><p>Between Apple Silicon and the dominance of Nvidia for AI use cases, one thing is clear: Intel has been too complacent for too long.</p><blockquote><p><em>“Success breeds complacency, complacency breeds failure, only the paranoid survive”</em></p><p>- Andy Grove, Intel Co-Founder</p></blockquote><p>Originally, this was meant to be a brief history of Apple’s famous CPU architecture migrations, however as usual my curiosity kind of got away from me. I was frustrated with the surface-level depth of most of my information sources.</p><ul><li><p><span>I had to know </span><em>why</em><span> the Macintosh team picked Motorola 68k over the available options.</span></p></li><li><p><span>I had to know what made a migration to a new CPU architecture like PowerPC so </span><em>difficult</em><span>.</span></p></li><li><p><span>I had to know what actually caused Intel’s x86 architecture to be </span><em>so far ahead</em><span> of its competition.</span></p></li><li><p><span>I had to know </span><em>how on Earth</em><span> the M1 chips were so damn efficient.</span></p></li></ul><p>I reckon I did a pretty good job.</p><p>I hope you learned a little, and most importantly, had some fun on the way.</p><p>Have you used any of these architectures before? Perhaps you’ve written assembly for them, used the CPU as a component in a custom build PC, or perhaps even just been amazed at your new M1 Mac? Share your story in the comments!</p><p><span>If you liked this piece, check out my other entry in my </span><em>Through The Ages</em><span> series: </span><a href="https://jacobbartlett.substack.com/p/apple-animation-through-the-ages" rel="">Through the Ages: Apple Animation APIs</a><span>.</span></p><div data-attrs="{&quot;url&quot;:&quot;https://jacobbartlett.substack.com/p/through-the-ages-apple-cpu-architecture?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;}" data-component-name="CaptionedButtonToDOM"><p>Thank you for reading Jacob’s Tech Tavern! If you enjoyed this post, please share to help me grow my Substack audience. </p><p data-attrs="{&quot;url&quot;:&quot;https://jacobbartlett.substack.com/p/through-the-ages-apple-cpu-architecture?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;}" data-component-name="ButtonCreateButton"><a href="https://jacobbartlett.substack.com/p/through-the-ages-apple-cpu-architecture?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Use YouTube to improve your English pronunciation (480 pts)]]></title>
            <link>https://youglish.com/</link>
            <guid>38074701</guid>
            <pubDate>Mon, 30 Oct 2023 19:47:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://youglish.com/">https://youglish.com/</a>, See on <a href="https://news.ycombinator.com/item?id=38074701">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p><label title="All accents">
&nbsp;&nbsp;
All
</label>
<label title="American accent">
&nbsp;&nbsp;
United States
</label>
<label title="British accent">
&nbsp;&nbsp;
United Kingdom
</label>
<label title="Australian accent">
&nbsp;&nbsp;
Australia
</label>
<label title="Canadian accent">
&nbsp;&nbsp;
Canada
</label>
<label title="Irish accent">
&nbsp;&nbsp;
Ireland
</label>
<label title="Scottish accent">
&nbsp;&nbsp;
Scotland
</label>
<label title="New Zealand accent">
&nbsp;&nbsp;
New Zealand
</label>
</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Kart: DVC for geospatial and tabular data. Git for GIS (126 pts)]]></title>
            <link>https://kartproject.org/</link>
            <guid>38073512</guid>
            <pubDate>Mon, 30 Oct 2023 18:22:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://kartproject.org/">https://kartproject.org/</a>, See on <a href="https://news.ycombinator.com/item?id=38073512">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    
    



    <!-- Nav -->
    <nav>
      
    </nav>



    <!-- Header -->
    

    <!-- First Row -->
    <div>
        <p>
          <h2>
            Geospatial and Tabular Data in&nbsp;Git
         </h2>
            <h4>
            Kart stores geospatial and tabular data in Git, providing version control at the row and cell level.
          </h4> </p>
        </div>



    <!-- Second Row -->
    <div>
        <p>
          <h2>
            Built&nbsp;on&nbsp;Git, works&nbsp;like&nbsp;Git
         </h2>
          <h4>
            Uses standard Git repositories and Git-like CLI commands. If you know Git,  you’ll feel right at home with Kart.
          </h4> </p>
      </div>



    <!-- Third Row -->
    <div>
        <p>
          <h2>
            Supports&nbsp;current GIS&nbsp;workflows
         </h2>
          <h4>
            Provides repository working copies as GIS databases and files. Edit directly in common GIS software without plugins.
          </h4> </p>
      </div>




    <!-- Features -->
    <div>
          <!-- Title -->
          <div>
            <p>
              <h2>
                    Features
                 </h2> </p>
          </div>
          <!-- Feature Grid -->
          <div>
            <!-- ROW 1 -->
            <!-- Column 1 -->
            <div>
                <!-- Icon -->
                <p><img src="https://kartproject.org/icons/yes.png" width="54px" alt="Your choice of format"> </p>
                <!-- Text -->
                <div>
                  <h4>Your choice of format</h4>
                  <p>Support for GeoPackage, PostGIS, Microsoft SQL Server and MySQL, with more coming soon.</p>
                </div>
              </div>
            <!-- Column 2 -->
            <div>
                <!-- Icon -->
                <p><img src="https://kartproject.org/icons/layers.png" width="54px" alt="Common GIS data types"> </p>
                <!-- Text -->
                <div>
                  <h4>Common GIS data types</h4>
                  <p>Kart supports regular vector GIS point, line, and polygon features.</p>
                </div>
              </div>
            <!-- ROW 2 -->
            <!-- Column 1 -->
            <div>
                <!-- Icon -->
                <p><img src="https://kartproject.org/icons/tabular.png" width="54px" alt="Tabular data support"> </p>
                <!-- Text -->
                <div>
                  <h4>Tabular data support</h4>
                  <p>Kart also supports non-geospatial flat data tables — stored alone or in repositories with vector geospatial data.</p>
                </div>
              </div>
            <!-- Column 2 -->
            <div>
                <!-- Icon -->
                <p><img src="https://kartproject.org/icons/raster-grid.png" width="54px" alt="Raster and grid data types"> </p>
                <!-- Text -->
                <div>
                  <h4>Raster and grid data types</h4>
                  <p>Store and version control raster and grid data at the tile level.</p>
                </div>
              </div>

            <!-- ROW 3 -->
            <!-- Column 1 -->
            <div>
                <!-- Icon -->
                <p><img src="https://kartproject.org/icons/lidar.png" width="54px" alt="LAS data type"> </p>
                <!-- Text -->
                <div>
                  <h4>LAS (terrestrial LiDAR) data type</h4>
                  <p>Store and version control LAS data at the tiled file level.</p>
                </div>
              </div>
            <!-- Column 2 -->
            <div>
                <!-- Icon -->
                <p><img src="https://kartproject.org/icons/speed.png" width="54px" alt="Performance"> </p>
                <!-- Text -->
                <div>
                  <h4>Performance</h4>
                  <p>Kart operations are performed locally — a huge advantage over server-based systems.</p>
                </div>
              </div>
            
            <!-- ROW 4 -->
            <!-- Column 1 -->
            <div>
                <!-- Icon -->
                <p><img src="https://kartproject.org/icons/fork.png" width="54px" alt="Branch and merge"> </p>
                <!-- Text -->
                <div>
                  <h4>Branch and merge</h4>
                  <p>Kart supports multiple independent local branches — create, merge, and delete them in seconds.</p>
                </div>
              </div>
            <!-- Column 2 -->
            <div>
                <!-- Icon -->
                <p><img src="https://kartproject.org/icons/filtering.png" width="54px" alt="Spatial filtering"> </p>
                <!-- Text -->
                <div>
                  <h4>Spatial filtering</h4>
                  <p>Clone, alter and work with a geographical subset of a larger repo.</p>
                </div>
              </div>

            <!-- ROW 5 -->
            <!-- Column 1 -->
            <div>
                <!-- Icon -->
                <p><img src="https://kartproject.org/icons/history.png" width="54px" alt="Full change history"> </p>
                <!-- Text -->
                <div>
                  <h4>Full change history</h4>
                  <p>Review, compare, and quickly switch to any change made since the dataset's inception.</p>
                </div>
              </div>
            <!-- Column 2 -->
            <div>
                <!-- Icon -->
                <p><img src="https://kartproject.org/icons/update.png" width="54px" alt="Synchronize data"> </p>
                <!-- Text -->
                <div>
                  <h4>Synchronize data</h4>
                  <p>Accurately synchronize datasets between systems in seconds. Kart moves and applies a minimal compressed set of changes.</p>
                </div>
              </div>
            
            <!-- ROW 6 -->
            <!-- Column 1 -->
            <div>
                <!-- Icon -->
                <p><img src="https://kartproject.org/icons/storage.png" width="54px" alt="Flexible repository layout"> </p>
                <!-- Text -->
                <div>
                  <h4>Flexible repository layout</h4>
                  <p>Store multiple datasets per repository, and organize by project or dataset.</p>
                </div>
              </div>
          </div>
        </div>



          <!-- Roadmap -->
      <div>
          <!-- Title -->
          <div>
            <p>
              <h2>
                    Roadmap
                 </h2> </p>
          </div>

            <!-- Feature Grid -->

            <div>
              <!-- ROW 1 -->
              <!-- Column 1 -->
              <div>
                  <!-- Icon -->
                  <p><img src="https://kartproject.org/icons/export.png" width="54px" alt="Export into other formats"> </p>
                  <!-- Text -->
                  <div>
                    <h4>Export into other formats</h4>
                    <p>Translate datasets in Kart repos into other file formats.</p>
                  </div>
                </div>
              <!-- Column 2 -->
              <!-- ROW 2 -->
              <!-- Column 1 -->
              <div>
                  <!-- Icon -->
                  <p><img src="https://kartproject.org/icons/file-support.png" width="54px" alt="File support"> </p>
                  <!-- Text -->
                  <div>
                    <h4>File &amp; document support</h4>
                    <p>Version control of files stored and transported along with data.</p>
                  </div>
                </div>
              <!-- Column 2 -->
              <div>
                  <!-- Icon -->
                  <p><img src="https://kartproject.org/icons/xml.png" width="54px" alt="XML Metadata and License version control"> </p>
                  <!-- Text -->
                  <div>
                    <h4>XML Metadata and License version control</h4>
                    <p>Alter and version control XML metadata and license files.</p>
                  </div>
                </div>
            </div>
          </div>


          <!-- Contributors, Licences and Supporters -->
          <section>
            <div>
              <p>
                <h4>
            An open source project
         </h4>
                <h5>
            Kart (formerly Sno) is made available under a <a href="https://github.com/koordinates/kart/blob/master/COPYING" target="_blank">GPL License</a>.
          </h5> </p>
            </div>

            <!-- Title -->
            <div>
              <div>
                <p>
                  <h4>
                    Supported by
                 </h4> </p>
              </div>
              <!-- Title -->
              <div>
                <p><a href="https://koordinates.com/" target="_blank"> <img src="https://kartproject.org/logos/koordinates.png" alt="Koordinates"> </a>
                </p>
              </div>
            </div>
          </section>



          <!-- Email Form -->
          <div>
              <p>
                <h5>Stay in touch for updates</h5> </p> <p><a href="https://cdn.forms-content.sg-form.com/a16f30a6-529e-11ea-9243-4689c7fa9697" target="_blank">Sign Up</a> </p></div>
          <!-- CTA -->
          <div>
                <p>
                  <h2>
                    Get started today
                  </h2> 
                </p>
                
              </div>
          <!-- Footer -->
          
          <!-- Optional JavaScript -->
          <!-- jQuery first, then Popper.js, then Bootstrap JS -->
          
          
          


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Autism and responding to authority (2019) (122 pts)]]></title>
            <link>https://neuroclastic.com/autism-and-responding-to-authority/</link>
            <guid>38072756</guid>
            <pubDate>Mon, 30 Oct 2023 17:38:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://neuroclastic.com/autism-and-responding-to-authority/">https://neuroclastic.com/autism-and-responding-to-authority/</a>, See on <a href="https://news.ycombinator.com/item?id=38072756">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-elementor-type="single-post" data-elementor-id="20908">
								<div data-id="9887739" data-element_type="section">
						
				<div data-id="c378c0b" data-element_type="widget" data-widget_type="theme-post-title.default">
				<p>
			<h2>Autism and Responding to Authority</h2>		</p>
				</div>
				<div data-id="a700d67" data-element_type="section">
					<div data-id="e933565" data-element_type="column" data-widget_type="author-box.default">
							<p><a href="https://neuroclastic.com/author/petesire/">
					<img src="https://neuroclastic.com/wp-content/uploads/gravatar/67fc3039-c7bd-47aa-b73a-bcd567803ae5.jpeg" alt="Pete Wharmby" loading="lazy">
				</a></p>
		</div>
				<div data-id="f5e6045" data-element_type="column">
						<div data-id="3f14b79" data-element_type="widget" data-widget_type="post-info.default">
					<ul>
								<li itemprop="author">
						<a href="https://neuroclastic.com/author/petesire/">
														<span>
							<span>By </span>
										Pete Wharmby					</span>
									</a>
				</li>
				</ul>
				</div>
				<div data-id="1fb1a43" data-element_type="widget" data-widget_type="post-info.default">
					<ul>
								<li itemprop="datePublished">
						<a href="https://neuroclastic.com/2019/12/15/">
														<span>
										December 15, 2019					</span>
									</a>
				</li>
				</ul>
				</div>
						</div>
								</div>
				<div data-id="3ebbe3a" data-element_type="widget" data-widget_type="theme-post-featured-image.default">
								<p><img width="800" height="534" src="https://i0.wp.com/neuroclastic.com/wp-content/uploads/2019/12/img_0720.jpg?fit=800%2C534&amp;ssl=1" alt="statue of justice" loading="lazy" srcset="https://i0.wp.com/neuroclastic.com/wp-content/uploads/2019/12/img_0720.jpg?w=5184&amp;ssl=1 5184w, https://i0.wp.com/neuroclastic.com/wp-content/uploads/2019/12/img_0720.jpg?resize=300%2C200&amp;ssl=1 300w, https://i0.wp.com/neuroclastic.com/wp-content/uploads/2019/12/img_0720.jpg?resize=1024%2C683&amp;ssl=1 1024w, https://i0.wp.com/neuroclastic.com/wp-content/uploads/2019/12/img_0720.jpg?resize=768%2C512&amp;ssl=1 768w, https://i0.wp.com/neuroclastic.com/wp-content/uploads/2019/12/img_0720.jpg?resize=1536%2C1024&amp;ssl=1 1536w, https://i0.wp.com/neuroclastic.com/wp-content/uploads/2019/12/img_0720.jpg?resize=2048%2C1365&amp;ssl=1 2048w, https://i0.wp.com/neuroclastic.com/wp-content/uploads/2019/12/img_0720.jpg?resize=425%2C283&amp;ssl=1 425w, https://i0.wp.com/neuroclastic.com/wp-content/uploads/2019/12/img_0720.jpg?resize=600%2C400&amp;ssl=1 600w, https://i0.wp.com/neuroclastic.com/wp-content/uploads/2019/12/img_0720.jpg?w=1600&amp;ssl=1 1600w, https://i0.wp.com/neuroclastic.com/wp-content/uploads/2019/12/img_0720.jpg?w=2400&amp;ssl=1 2400w" sizes="(max-width: 800px) 100vw, 800px" data-attachment-id="8688" data-permalink="https://neuroclastic.com/autism-and-responding-to-authority/justice-goddess-themis-this-figure-has-no-specific-author-no-need-model-release/" data-orig-file="https://i0.wp.com/neuroclastic.com/wp-content/uploads/2019/12/img_0720.jpg?fit=5184%2C3456&amp;ssl=1" data-orig-size="5184,3456" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;5.6&quot;,&quot;credit&quot;:&quot;Getty Images\/iStockphoto&quot;,&quot;camera&quot;:&quot;Canon EOS 650D&quot;,&quot;caption&quot;:&quot;Justice goddess Themis. This figure has no specific author. No need model release.&quot;,&quot;created_timestamp&quot;:&quot;1512941650&quot;,&quot;copyright&quot;:&quot;This content is subject to copyright.&quot;,&quot;focal_length&quot;:&quot;55&quot;,&quot;iso&quot;:&quot;200&quot;,&quot;shutter_speed&quot;:&quot;0.016666666666667&quot;,&quot;title&quot;:&quot;Justice goddess Themis. This figure has no specific author. No need model release.&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="Justice goddess Themis. This figure has no specific author. No need model release." data-image-description="" data-image-caption="<p>Justice goddess Themis. This figure has no specific author. No need model release.</p>
" data-medium-file="https://i0.wp.com/neuroclastic.com/wp-content/uploads/2019/12/img_0720.jpg?fit=300%2C200&amp;ssl=1" data-large-file="https://i0.wp.com/neuroclastic.com/wp-content/uploads/2019/12/img_0720.jpg?fit=800%2C534&amp;ssl=1">														</p>
						</div>
				<div data-id="5de30ff" data-element_type="widget" data-widget_type="theme-post-content.default">
			<p>This will be a two part article: firstly, autistic attitudes towards those in authority, and secondly, how autistic people handle being in a position of authority.</p>
<p>I’ve written before about how autistic people often struggle to know how to act around authority figures. Actually, that’s not true– we don’t seem to <strong><em>care</em></strong> how we act around authority.</p>
<p>I think this is a vital distinction.</p>
<p>It’s not that we’re deficient, after all. It’s more that this <em>authority</em> business is a neurotypical notion that we don’t seem to share, and thus we tend to ignore it.</p>
<p><span>Let me give you an example. </span></p>
<p><span>Autistic children in school are somewhat notorious for finding it hard to adapt to the authority of teachers– some teachers more than others. This is not because they’re evil little ragamuffins, as some teachers would have it, but because their natural state is to assume equanimity. Autistic students (and I speak from long experience) will not bow to authority for authority’s sake. </span></p>
<p><span>They will respect it, if respect can be had, and they’ll do what they’re told</span><span><strong>— if it makes sense</strong></span><span>; but they won’t blindly accept authority. By this point, my teacher readers are wincing in pain as our main tool is automatically-accepted authority. </span></p>
<p><span>But what can I say? Autistic people </span><span><em>are</em></span><span> different! This is </span><span><strong>not</strong></span><span> a deficiency, in and of itself. I believe it’s an offshoot of our particular brand of empathy that we excel at. It is used to find the common ground between people, rather than the differences. I’m aware I may be romanticising autism a bit here, which is not my intention.&nbsp;</span></p>
<p>So when presented with an authority figure, autistic people seek out what makes us the same, and in doing so obliterates the arbitrary (to us at least) difference of their ‘authority.’</p>
<p>We automatically seek to be on a level with *everyone* we meet. This is subconscious and not controllable, unless we really need to. It occurs throughout our lives from childhood to old age. It makes us *really weird* to neurotypical people, who seem to accept authority happily.</p>
<p>So another example: an autistic person meets their company’s CEO. They know who they are, but they greet them as an equal. They say <em>hi</em>. They crack a Chandler-esque joke. They are relaxed and unfazed by the massive authority that is shrinking their peers down.</p>
<p>This may be great! The CEO might think, <em>Wow! Here’s a go-getting individual</em>, if they’re nice and positive. But they may also think, <em>Who is this worm with no respect for my status?</em></p>
<p>Then, we’re screwed. Similarly, this trait can absolutely ruin us when the police are involved. Its bad enough in the UK, but being #AutisticWhileBlack in the USA can get you killed in altercations with the cops when this issue is occurring, and this is happening a lot.</p>
<p>So, to recap, autistic people– at least in my assessment– don’t recognise authority as a thing in and of itself. They will bow to greater expertise, experience, morality, and creativity, very happily, but not just to <em>authority</em> alone.</p>
<p>This is a very good and a very bad thing, because sadly, unearned authority is a big part of human existence. From police and the armed forces, whose authority is granted by an abstract “State,” to random adults in the street telling kids off– it’s <em>everywhere</em>. ￼￼</p>
<p>It’s imperative that these institutions need realise that there is a <strong>significant</strong> <strong>proportion</strong> of the population who will not accept blind authority, not because they’re baddies, or naughty, but <strong>because their brains are wired differently</strong>. This needs to be accepted now.</p>
<p>I’m not excusing autistic people of bad behaviour, by the way. There are always people willing to interpret my writing in the most negative possible light. I’m simply stating its a factor that needs to be understood.</p>
<h3>Autistics in Authority</h3>
<p>But what of part two? Of autistic people in authority? How does <em>this</em> work?</p>
<p>Well, here goes…</p>
<p>Firstly, unless you’re literally the Queen, there will always be further authority above you somewhere, so all the earlier stuff applies, but when it comes to dealing with our “subordinates” (I don’t even like using the word), we perhaps tend to be very accepting, reasonable, and fair. Is this a <em>thing</em>?</p>
<p>I know from my experience of being a manager/leader that I just wanted to let people do their job, and assumed they’d do it well. I wasn’t happy issuing diktats to them or punitive messages from higher up and tended to try to shield them from all that crap.</p>
<p>But this is not how managers are meant to behave. I couldn’t handle the “telling off” side of the job (like confronting people for being ill and absent- <em>wtf</em>!?), so I handed in my notice and went back to classroom teaching.</p>
<p>I feel that autistic people might struggle with the expectations of holding authority, but ironically that we would wield authority fairly and well.</p>

                         <div><ul> <li><a href="#abh_about">About</a></li> <li><a href="#abh_posts">Latest Posts</a></li></ul><div><section itemscope="" itemprop="author" itemtype="http://schema.org/Person"><p><a href="https://neuroclastic.com/author/petesire/" target="_blank" title="Pete Wharmby" rel="nofollow"> <img alt="" src="https://i0.wp.com/neuroclastic.com/wp-content/uploads/gravatar/67fc3039-c7bd-47aa-b73a-bcd567803ae5.jpeg?w=250&amp;ssl=1" data-recalc-dims="1"></a> </p><div><p>Pete is a secondary English teacher who was diagnosed with Asperger’s in 2017 at the age of 34. Since this time he has become very active online, writing a blog about his experiences as an autistic adult and regular threads and videos on Twitter that add some insight into the autistic experience. He has written on a large variety of topics, including autistic burnout, autistic identity and masking, autism and parenthood, autistic humour and autistic interests. He is a keen writer and illustrator, though Lego is perhaps his biggest obsession. Subscribe to Pete's <a href="https://www.patreon.com/pwharmbyautism">Patreon here,</a> or <a href="https://www.buymeacoffee.com/UfTVnRY">buy Pete a coffee.</a></p></div> </section><section><p><a href="https://neuroclastic.com/author/petesire/" target="_blank" title="Pete Wharmby" rel="nofollow"><img alt="" src="https://i0.wp.com/neuroclastic.com/wp-content/uploads/gravatar/67fc3039-c7bd-47aa-b73a-bcd567803ae5.jpeg?w=250&amp;ssl=1" data-recalc-dims="1"></a></p> </section></div> </div>		</div>
						</div>
				<div data-id="7b597e5" data-element_type="section">
						<div data-id="dcd8064" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h3>Related Articles</h3>		</p>
				</div>
				
				<section id="comments" data-id="fbbed75" data-element_type="widget" data-widget_type="post-comments.theme_comments">

			<h3>
			29 Responses		</h3>

		
	<ol>
				<li id="comment-2896">
			<article id="div-comment-2896">
				<!-- .comment-meta -->

				<div>
					<p>Another problem is when the whole “doesn’t blindly submit to authority” thing is pathologized in a child, along with with asking questions (AKA “talking back”) and trying to make sense of rules.  Then the parents or teachers decide they need to “break” this “problem child” through abuse.  It doesn’t end well.  Are they just trying to teach learned helplessness?</p>

				</div><!-- .comment-content -->

							</article><!-- .comment-body -->
		<ol>
		<li id="comment-2962">
			<article id="div-comment-2962">
				<!-- .comment-meta -->

				<!-- .comment-content -->

							</article><!-- .comment-body -->
		</li><!-- #comment-## -->
		<li id="comment-3034">
			<article id="div-comment-3034">
				<!-- .comment-meta -->

				<div>
					<p>Of course they are. They are slave traders and evil.</p>

				</div><!-- .comment-content -->

							</article><!-- .comment-body -->
		</li><!-- #comment-## -->
</ol><!-- .children -->
</li><!-- #comment-## -->
		<li id="comment-2897">
			<article id="div-comment-2897">
				<!-- .comment-meta -->

				<div>
					<p>Excellent article. Thankyou for building awareness of this aspect of autistic life.</p>

				</div><!-- .comment-content -->

							</article><!-- .comment-body -->
		</li><!-- #comment-## -->
		<li id="comment-2898">
			<article id="div-comment-2898">
				<!-- .comment-meta -->

				<div>
					<p>I’m the exception to the rule here. I used to blindly bow down to authority, teachers, bosses, the police etc. That’s why I had no problem excepting authority when I went into the military. I think that this acceptance of authority was drummed into me at a very young age and my autism made me think it was the norm.</p>

				</div><!-- .comment-content -->

							</article><!-- .comment-body -->
		</li><!-- #comment-## -->
		<li id="comment-2899">
			<article id="div-comment-2899">
				<!-- .comment-meta -->

				<div>
					<p>I’m on the spectrum and I agree with the article for the most part. However, I don’t simply feel authority is equal with everyone. I’d certainly like it to be and in an idealistic world that would be the case. Personally, I think it’s something to be feared because too many people take advantage of it. As you may have said, people didn’t earn the positions that they’re in. Of course from my experience I’ve had bad experiences with all kinds of individuals in authority that abuse their power, and many of them have earned their positions simply because family members own a company, or simple favoritism. But I agree we shouldn’t blindly accept or follow it. I hate doing so and it causes a huge amount of stress for me especially when I have no choice (such as in a work place where it’s either do what they say agree or not, or leave your job). If I had a dime for every time I had a meltdown due to the stress authority causes, I’d be rich enough to buy the internet.</p>

				</div><!-- .comment-content -->

							</article><!-- .comment-body -->
		</li><!-- #comment-## -->
		<li id="comment-2901">
			<article id="div-comment-2901">
				<!-- .comment-meta -->

				<div>
					<p>That answers so many issues that I have had with authority! I am neurotypical but dont really seem to fit in anywhere. But I have had similar experiences. I can respect authority but I never seemed to have the fear that others had. Possibly because my father taught me early that it was Ok to question him on anything as long as I did not question his right to make the final decision.Of course by the time I was 16 he made it clear that he expected me to use common sense and respect for others so there were few “final decisions” that he had to make for me. So I think I learned to early to separate the authority as a person delegated to make the final decision and the person who as an individual who was placed in that position. Never realized that I was doing it. but also explains why I had issues with certain people who expected me to hold them in awe because they deemed themselves in authority of me.</p>

				</div><!-- .comment-content -->

							</article><!-- .comment-body -->
		</li><!-- #comment-## -->
		<li id="comment-2903">
			<article id="div-comment-2903">
				<!-- .comment-meta -->

				<div>
					<p>Of course, irrespective of being in charge or subordinate, we often have the compulsion to point out mistakes that person has made. Not to be nasty, but because we’re helpful: ‘surely they will want to know what they did wrong so they will not make the same mistake again’.</p>

				</div><!-- .comment-content -->

							</article><!-- .comment-body -->
		</li><!-- #comment-## -->
		<li id="comment-2910">
			<article id="div-comment-2910">
				<!-- .comment-meta -->

				<div>
					<p>I work in the pharmaceutical industry &amp; my boss said “your job is to follow procedures, not criticise management”. Funny, I thought it was to ensure our product is proven quality from go to whoa, at the least expense to our company. I have been trying to correct an unnecessarily complex quadruple check (of worksheets, NOT the product itself!) for over 18 months!</p>

				</div><!-- .comment-content -->

							</article><!-- .comment-body -->
		</li><!-- #comment-## -->
		<li id="comment-2920">
			<article id="div-comment-2920">
				<!-- .comment-meta -->

				<div>
					<p>I have the opposite tendency to want to follow my teacher’s rules and worship their authority, which was too far in the other direction for nearly all my teachers in my years of school. It caused me to majorly butt heads with one of my English professors in college. He’d always ask us “why do we read this story? Why does it appear on the syllabus?” And I’d be like “uh, duh you put it there so if we don’t read it we’ll get in trouble.” He hated that.</p>

				</div><!-- .comment-content -->

							</article><!-- .comment-body -->
		</li><!-- #comment-## -->
		<li id="comment-2942">
			<article id="div-comment-2942">
				<!-- .comment-meta -->

				<div>
					<p>Your experience in leadership is how I functioned as a charge nurse.  I surprised my peers who weren’t too thrilled with the idea of me being in charge because I can be so particular about how things are done.  </p>
<p>But as charge, I assumed my colleagues knew their jobs and how to do them.  I saw my role as making sure they had what they needed to get it done, not to micromanage their work.  </p>
<p>That didn’t fit with management by intimidation.  It lasted less than a year before I went back to floor nursing.  I’m glad.  I’m not management material.  I don’t like screwing people over and I hate office politics.  Why can’t we just do to work and do our jobs?</p>

				</div><!-- .comment-content -->

							</article><!-- .comment-body -->
		</li><!-- #comment-## -->
		<li id="comment-2944">
			<article id="div-comment-2944">
				<!-- .comment-meta -->

				<div>
					<p>The horrible version of management mentioned is actually considered bad, by management professionals. It’s common, but it is destructive. Good managers protect their teams, trust them to do their jobs, and provide guidance and help to do better. Good managers in abusive management systems need techniques to handle the difference, because they’ll get hit with the load of bull, and it can be heavy lifting.</p>
<p>High performance teams that are not completely burned out already tend to thrive with the management you describe.</p>
<p>Also, look up info on Power Distance as a cultural dimension. Both type of authority (power, knowledge, relational, etc.) and power distance apply. People will differ, and culture of origin may matter (including family culture), but yeah, power distances tend to be small with many autistic people – even where the authority is recognized.</p>

				</div><!-- .comment-content -->

							</article><!-- .comment-body -->
		</li><!-- #comment-## -->
		<li id="comment-2950">
			<article id="div-comment-2950">
				<!-- .comment-meta -->

				<div>
					<p>I think that you mean ‘equality’. “Equanimity”, in my dictionary and as I understands it, means “evenness of mind or temper”.</p>

				</div><!-- .comment-content -->

							</article><!-- .comment-body -->
		</li><!-- #comment-## -->
		<li id="comment-2968">
			
		</li><!-- #comment-## -->
		<li id="comment-2971">
			<article id="div-comment-2971">
				<!-- .comment-meta -->

				<div>
					<p>I totally agree. Also as a manager I tend to shield my team from the authoritarian crap and politics </p>

				</div><!-- .comment-content -->

							</article><!-- .comment-body -->
		</li><!-- #comment-## -->
		<li id="comment-2989">
			<article id="div-comment-2989">
				<!-- .comment-meta -->

				<!-- .comment-content -->

							</article><!-- .comment-body -->
		</li><!-- #comment-## -->
		<li id="comment-3036">
			<article id="div-comment-3036">
				<!-- .comment-meta -->

				<div>
					<p>If we are so wonderful, how come have there been many tyrannically run autistic forum sites ?</p>

				</div><!-- .comment-content -->

							</article><!-- .comment-body -->
		</li><!-- #comment-## -->
		<li id="comment-3085">
			<article id="div-comment-3085">
				<!-- .comment-meta -->

				<div>
					<p>I frankly don’t think autists are suited to capitalist authority. If you think about it. I’ll only bother to expand on my thoughts if prompted.</p>

				</div><!-- .comment-content -->

							</article><!-- .comment-body -->
		</li><!-- #comment-## -->
		<li id="comment-3174">
			
		</li><!-- #comment-## -->
		<li id="comment-4016">
			<article id="div-comment-4016">
				<!-- .comment-meta -->

				<div>
					<p>Good article.  I am looking forward to the next part.</p>
<p>Self Dx’d autist here who has been in leadership and senior management roles.  I now do lectures to MBA students on Neurodiversity. I was always considered a bit of a political liability ( I even told a top dog they should attend a training course when they were freeballing about a topic they were ignorant of).  My manager almost visibly sh*t himself as I said it.</p>
<p>In my opinion,  Respect by Autistic people is earnt,  not assumed.  This can be troublesome in social hierarchies permeated by people whose mantra is to fake it until you make it.  In fact those environments tend to be toxic to the health of Autistic people who work within them.</p>
<p>Whilst Autists are an excellent innoculation to groupthink and other disastrous effects of the dominant social hierarchy,  the drawbacks for Autistic people who gravitate into decision making roles is significant.</p>

				</div><!-- .comment-content -->

							</article><!-- .comment-body -->
		<ol>
		<li id="comment-4017">
			<article id="div-comment-4017">
				<!-- .comment-meta -->

				<div>
					<p>Also,  Autistic traits can actually result in more innovative teams.  By acting as a “sh*t umbrella” and focussing on enabling your team,  you can create a degree of psychological safety.</p>
<p>The issue is often the higher level hierarchies which end up sandwiching the autistic leader.</p>
<p>I have taken to trying to not refer to managers or leaders now and to instead refer to the functions – managers as enablers and leaders as catalyzers.  I have seen excellent enablers and catalyzers who haven’t been christened with a role of leader/manager and even more often I have seen  peo p le in roles of leaders/managers who have no capability to catalyze or enable people.</p>

				</div><!-- .comment-content -->

							</article><!-- .comment-body -->
		</li><!-- #comment-## -->
</ol><!-- .children -->
</li><!-- #comment-## -->
		<li id="comment-5922">
			
		</li><!-- #comment-## -->
		<li id="comment-7727">
			<article id="div-comment-7727">
				<!-- .comment-meta -->

				<div>
					<p>I started a job working as a classroom teacher with 30+ students 6 or 7 months ago, after successfully teaching adults and adolescents, as well as a few children 9, 10, 11 years old for the last ten years online and on an individual basis.</p>

				</div><!-- .comment-content -->

							</article><!-- .comment-body -->
		</li><!-- #comment-## -->
		<li id="comment-8065">
			<article id="div-comment-8065">
				<!-- .comment-meta -->

				<div>
					<p>This is by far one of my top favourite pieces. So relatable, and I’ve said these words before!</p>

				</div><!-- .comment-content -->

							</article><!-- .comment-body -->
		</li><!-- #comment-## -->
		<li id="comment-8783">
			<article id="div-comment-8783">
				<!-- .comment-meta -->

				<div>
					<p>“I believe it’s an offshoot of our particular brand of empathy that we excel at” – This phrase has stuck in my head and I have spent the last two days thinking about it. It’s such a kind way of interpreting so much of my way of being. I’ve decided for me it means I’m not necessarily in conflict with authority, or any of the other bafflingly weird ways that neurotypicals behave. I just a see them with more clarity.<br>
Maybe nonsense but I’m going to go with it, I think it will help, thanks.</p>

				</div><!-- .comment-content -->

							</article><!-- .comment-body -->
		</li><!-- #comment-## -->
		<li id="comment-8861">
			
		</li><!-- #comment-## -->
		<li id="comment-9954">
			<article id="div-comment-9954">
				<!-- .comment-meta -->

				<div>
					<p>I have a 7 yr old autistic grandchild and I’m relieved to see that this is a symptom of autism, not a deficiency, but what do we do about it??</p>

				</div><!-- .comment-content -->

							</article><!-- .comment-body -->
		<ol>
		<li id="comment-10366">
			<article id="div-comment-10366">
				<!-- .comment-meta -->

				<div>
					<p>Your grandchild would benefit from an explanation of the nuances of how authority is granted, exercised, and challenged correctly and in a healthy manner. For myself, the turning point was when I understood the difference between -relational- and -positional- authority. </p>
<p>Relational authority is with a person: someone whom has invested in my wellbeing or vice-versa. I’m far more likely to obey someone whom I know cares about my wellbeing and has proven that concern over time. An example of expression of relational authority would be when my grandmother asks me to do something for her or wants to give me some cogent advice. </p>
<p>Positional authority is with an office (not the person currently occupying the office), which is as an expression of the will of the governed. Obedience in this instance is proportional to the congruence of the office to its purpose (its legitimacy), as well as the manner of how that authority is expressed.</p>
<p>All that being said, obedience is a choice and not one to be taken lightly. In the most extreme case, even if someone were holding a gun to my head to compel obedience, it’s still a choice.</p>
<p>How we conduct ourselves in the presence of authority is a direct reflection of our understanding of personal agency and a deep appreciation of our responsibilities to ourselves, but also those around us. I wish you the very best with your grandchild!</p>

				</div><!-- .comment-content -->

							</article><!-- .comment-body -->
		</li><!-- #comment-## -->
</ol><!-- .children -->
</li><!-- #comment-## -->
		<li id="comment-10367">
			<article id="div-comment-10367">
				<!-- .comment-meta -->

				<div>
					<p>One aspect of the inability to recognize authority is in judging people within the hierarchy accurately. This means that you do not easily recognize who will move up and thus who you should form an allegiance with. It can significantly impair the person’s level. I think the typical corporate aggressive management type views the autistic manager with suspicion as they don’t sense the killer instinct that they possess and expect in other managers.</p>

				</div><!-- .comment-content -->

							</article><!-- .comment-body -->
		</li><!-- #comment-## -->
	</ol><!-- .comment-list -->

		


		<p id="respond">
			<h3 id="reply-title">Talk to us... what are you thinking?<small></small></h3>			
		</p>

		
		

		
</section>
						</div>
							</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Threads Software Limited gives Meta 30 days to stop using the name Threads (230 pts)]]></title>
            <link>https://www.businesswire.com/news/home/20231030082004/en/Threads-Software-Limited-Gives-Meta%E2%80%99s-Instagram-30-Days-to-Desist-from-Using-the-Service-Name-Threads</link>
            <guid>38072495</guid>
            <pubDate>Mon, 30 Oct 2023 17:20:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.businesswire.com/news/home/20231030082004/en/Threads-Software-Limited-Gives-Meta%E2%80%99s-Instagram-30-Days-to-Desist-from-Using-the-Service-Name-Threads">https://www.businesswire.com/news/home/20231030082004/en/Threads-Software-Limited-Gives-Meta%E2%80%99s-Instagram-30-Days-to-Desist-from-Using-the-Service-Name-Threads</a>, See on <a href="https://news.ycombinator.com/item?id=38072495">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
        <p>LONDON--(<span itemprop="provider publisher copyrightHolder" itemscope="itemscope" itemtype="https://schema.org/Organization" itemid="https://www.businesswire.com"><span itemprop="name"><a referrerpolicy="unsafe-url" rel="nofollow" itemprop="url" href="https://www.businesswire.com/">BUSINESS WIRE</a></span></span>)--UK software company Threads Software Limited and its lawyers have today (30 October) written to Meta’s Instagram giving it 30 days to stop using the name Threads for their service in the UK. If it does not, Threads Software Limited will seek an injunction from the English Courts.

</p>
<blockquote></blockquote>
<p>
Threads - an intelligent message hub provided by Threads Software Limited - was conceived and trademarked in 2012 by JPY Ltd. The service has been actively promoted worldwide since 2014.

</p><p>
In 2018, the first commercial sale was made in the USA, and as a result JPY Ltd spun off a new company, Threads Software Ltd. It has since licenced nearly 1,000 organisations worldwide with sales currently growing at 200% a year.

</p><p>
From April 2023, Meta’s lawyers made four offers to purchase the domain ‘threads.app’ from Threads Software Ltd. Every offer was declined. It was made clear to Meta’s Instagram that the domain was not for sale.

</p><p>
In July 2023, Meta’s Instagram announced its ‘threads’ social media platform and removed Threads Software Limited from its Facebook platform.

</p><p>
Dr John Yardley, Managing Director of Threads Software Ltd said: “Taking on a US$150 billion company is not an easy decision for us to make. We have invested 10 years in our platform, establishing a recognised brand in the name, Threads. Our business now faces a serious threat from one of the largest technology companies in the world.

</p><p>
“We recognise that this is a classic ‘David and Goliath’ battle with Meta. And whilst they may think they can use whatever name they want, that does not give them the right to use the Threads brand name.

</p><p>
“We want them to stop using the Threads name with immediate effect. If they do not, we will seek an injunction from the UK courts.”

</p><p>
<b>About Threads Software</b>

</p><p>
Threads is a Cloud-based service that captures, transcribes, and organises all of a company’s digital messages (emails and phone calls) into one easily searchable database.

</p><p>
Message meta-data is extracted to automatically and intelligently create a subscriber-specific address book, eliminating the need to manually maintain directories of contacts and companies.

</p><p>
Threads is able to provide high-quality transcriptions by extracting VoIP call and routing data at much greater resolution than most call recording systems. Additionally, by intelligently processing email data, Threads can apply vital <i>contex</i>t to phone calls and further improve its understanding of speech.

</p>
        
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Recursive Drawing (105 pts)]]></title>
            <link>http://recursivedrawing.com/</link>
            <guid>38072278</guid>
            <pubDate>Mon, 30 Oct 2023 17:06:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://recursivedrawing.com/">http://recursivedrawing.com/</a>, See on <a href="https://news.ycombinator.com/item?id=38072278">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="left">
  <p><b>Recursive Drawing</b> is an exploration of user interface ideas towards the development of a spatially-oriented programming environment.
  </p><div id="links">
    <p><a href="http://recursivedrawing.com/draw.html">Start Drawing!</a>
  </p></div>
  <p><a href="https://news.ycombinator.com/item?id=3951499" target="_blank">Complete list of instructions</a><br>(written up by Rory O'Kane)
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Approximate Nearest Neighbor Oh Yeah (Annoy) (138 pts)]]></title>
            <link>https://zilliz.com/learn/approximate-nearest-neighbor-oh-yeah-ANNOY</link>
            <guid>38072277</guid>
            <pubDate>Mon, 30 Oct 2023 17:06:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://zilliz.com/learn/approximate-nearest-neighbor-oh-yeah-ANNOY">https://zilliz.com/learn/approximate-nearest-neighbor-oh-yeah-ANNOY</a>, See on <a href="https://news.ycombinator.com/item?id=38072277">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Welcome back to <a href="https://zilliz.com/blog?tag=39&amp;page=1">Vector Database 101</a>.</p>
<p>In the previous tutorial, we deep-dived into <a href="https://zilliz.com/blog/hierarchical-navigable-small-worlds-HNSW">Hierarchical Navigable Small Worlds (HNSW)</a>. HNSW is a graph-based indexing algorithm that today is one of the most popular indexing strategies used in <a href="https://zilliz.com/learn/what-is-vector-database">vector databases</a>.</p>
<p>In this <a href="https://codelabs.milvus.io/">tutorial</a>, we'll switch gears and talk about tree-based vector indexes. Specifically, we'll talk about <strong>Approximate Nearest Neighbor Oh Yeah (Annoy)</strong>, an algorithm that uses a forest of trees to conduct the nearest neighbor search. For those familiar with random forests or gradient-boosted decision trees, Annoy can seem like a natural extension of these algorithms, only for the nearest neighbor search rather than machine learning. As with our HNSW tutorial, we'll first walk through how Annoy works from a high level before developing our own simple Python implementation.</p>
<p><iframe src="https://player.vimeo.com/video/847199990?badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen="" title="ANNOY Vector Index | Vector Database Fundamentals"></iframe></p>

<p>While HNSW is built upon the connected graph and skip list, Annoy uses binary search trees as the core data structure. The key idea behind Annoy (and other tree-based indexes) is to repeatedly partition our vector space and search only a subset of the partitions for nearest neighbors. If this sounds like IVF, you're right; the idea is the same, but the execution is slightly different.</p>
<p><img src="https://raw.github.com/spotify/annoy/master/ann.png">
</p>
<p><sub>Annoy, visualized (from https://github.com/spotify/annoy).</sub></p>
<p>The best way to understand Annoy is to visualize how a single tree is built. However, remember that high-dimensional hyperspaces are very different from 2D/3D Euclidean spaces from an intuitive perspective, so the images below are only for reference.</p>
<p>Let's start with indexing. For Annoy, this is a recursive process where the maximum size of the call stack is the depth of the tree. In the first iteration, two random dataset vectors, <strong>a</strong> and <strong>b</strong>, are selected, and the full hyperspace is split along a hyperplane equidistant from both <strong>a</strong> and <strong>b</strong>. Then, vectors in the "left" half of the hyperspace get assigned to the left half of the tree, while vectors in the "right" half of the subspace are given to the right half of the tree. Note that this can be done without actually computing the hyperplane itself - for every dataset vector, we need to determine whether <strong>a</strong> (left) or <strong>b</strong> (right) is closer.</p>
<p>
      <span>
        <a href="https://assets.zilliz.com/After_the_first_second_and_Nth_iteration_respectively_9386181d4e.png" title="" target="_blank"><img src="https://assets.zilliz.com/After_the_first_second_and_Nth_iteration_respectively_9386181d4e.png" alt="" id=""></a>
        <span></span>
      </span>
    </p>
<center>
<p>After the first, second, and Nth iteration, respectively. <a href="https://sds-aau.github.io/M3Port19/portfolio/ann/">Source</a>.</p>
</center>
<p>The second iteration repeats this process for both the left and right subtrees generated by the first iteration, resulting in a tree with a depth of two and four leaf nodes. This process continues for the third, fourth, and subsequent iterations until a leaf node has fewer than a pre-defined number of elements K. In the <a href="https://github.com/spotify/annoy/blob/master/src/annoylib.h#L892">original Annoy implementation</a>, <code>K</code> is a variable value that the user can set.</p>
<p>With the index fully built, we can now move on to querying. Given some query vector <strong>q</strong>, we can search by traversing the tree. A hyperplane splits each intermediate node, and we can determine which side of the hyperplane the query vector falls on by computing its distance to the left and right vectors. We repeat this process until we reach a leaf node containing an array of, at most, <code>K</code> vectors. We can then rank and return these vectors to the user.</p>
<p>Now we know how Annoy works, and let's start with the implementation. As usual, we'll first create a dataset of (128 dimensional) vectors:</p>
<pre><code><span>&gt;&gt;&gt; </span><span>import</span> numpy <span>as</span> np
<span>&gt;&gt;&gt; </span>dataset = np.random.normal(size=(<span>1000</span>, <span>128</span>))
</code></pre>
<p>Let's first define a <code>Node</code> class containing left and right subtrees:</p>
<pre><code><span>class</span> <span>Node</span>(<span>object</span>):
    <span>"""Initialize with a set of vectors, then call `split()`.
    """</span>

    <span>def</span> <span>__init__</span>(<span>self, ref: np.ndarray, vecs: <span>List</span>[np.ndarray]</span>):
        self._ref = ref
        self._vecs = vecs
        self._left = <span>None</span>
        self._right = <span>None</span>

<span>    @property</span>
    <span>def</span> <span>ref</span>(<span>self</span>) -&gt; <span>Optional</span>[np.ndarray]:
        <span>"""Reference point in n-d hyperspace. Evaluates to `False` if root node.
        """</span>
        <span>return</span> self._ref

<span>    @property</span>
    <span>def</span> <span>vecs</span>(<span>self</span>) -&gt; <span>List</span>[np.ndarray]:
        <span>"""Vectors for this leaf node. Evaluates to `False` if not a leaf.
        """</span>
        <span>return</span> self._vecs

<span>    @property</span>
    <span>def</span> <span>left</span>(<span>self</span>) -&gt; <span>Optional</span>[<span>object</span>]:
        <span>"""Left node.
        """</span>
        <span>return</span> self._left

<span>    @property</span>
    <span>def</span> <span>right</span>(<span>self</span>) -&gt; <span>Optional</span>[<span>object</span>]:
        <span>"""Right node.
        """</span>
        <span>return</span> self._right
</code></pre>
<p>The <code>vecs</code> variable contains a list of all vectors within the node. If the length of this list is less than some value <code>K</code>, then they will remain as-is; otherwise, these vectors will then get propagated to <code>left</code> and <code>right</code>, with <code>vecs[0]</code> and <code>vecs[1]</code> remaining as the two randomly selected vectors used to split the hyperplane.</p>
<p>Let's now move to indexing. First, Recall that every node in the tree is split by a hyperplane orthogonal to the line connecting two randomly selected dataset vectors. Conveniently, we can determine which side of the hyperplane a query vector lies on by computing distance. As usual, we'll use NumPy's vectorized math for this:</p>
<pre><code><span>def</span> <span>_is_query_in_left_half</span>(<span>q, node</span>):
   <span># returns `True` if query vector resides in left half</span>
   dist_l = np.linalg.norm(q - node.vecs[<span>0</span>])
   dist_r = np.linalg.norm(q - node.vecs[<span>1</span>])
   <span>return</span> dist_l &lt; dist_r
</code></pre>
<p>Now let's move to building the actual tree.</p>
<pre><code><span>import</span> random


<span>def</span> <span>split_node</span>(<span>node, K: <span>int</span>, imb: <span>float</span></span>) -&gt; <span>bool</span>:

    <span># stopping condition: maximum # of vectors for a leaf node</span>
    <span>if</span> <span>len</span>(node._vecs) &lt;= K:
        <span>return</span> <span>False</span>

    <span># continue for a maximum of 5 iterations</span>
    <span>for</span> n <span>in</span> <span>range</span>(<span>5</span>):
        left_vecs = []
        right_vecs = []

        <span># take two random indexes and set as left and right halves</span>
        left_ref = node._vecs.pop(np.random.randint(<span>len</span>(node._vecs)))
        right_ref = node._vecs.pop(np.random.randint(<span>len</span>(node._vecs)))

        <span># split vectors into halves</span>
        <span>for</span> vec <span>in</span> node._vecs:
            dist_l = np.linalg.norm(vec - left_ref)
            dist_r = np.linalg.norm(vec - right_ref)
            <span>if</span> dist_l &lt; dist_r:
                left_vecs.append(vec)
            <span>else</span>:
                right_vecs.append(vec)

        <span># check to make sure that the tree is mostly balanced</span>
        r = <span>len</span>(left_vecs) / <span>len</span>(node._vecs)
        <span>if</span> r &lt; imb <span>and</span> r &gt; (<span>1</span> - imb):
            node._left = Node(left_ref, left_vecs)
            node._right = Node(right_ref, right_vecs)
            <span>return</span> <span>True</span>

        <span># redo tree build process if imbalance is high</span>
        node._vecs.append(left_ref)
        node._vecs.append(right_ref)

    <span>return</span> <span>False</span>


<span>def</span> <span>_build_tree</span>(<span>node, K: <span>int</span>, imb: <span>float</span></span>):
    <span>"""Recurses on left and right halves to build a tree.
    """</span>
    node.split(K=K, imb=imb)
    <span>if</span> node.left:
        _build_tree(node.left, K=K, imb=imb)
    <span>if</span> node.right:
        _build_tree(node.right, K=K, imb=imb)


<span>def</span> <span>build_forest</span>(<span>vecs: <span>List</span>[np.ndarray], N: <span>int</span> = <span>32</span>, K: <span>int</span> = <span>64</span>, imb: <span>float</span> = <span>0.95</span></span>) -&gt; <span>List</span>[Node]:
    <span>"""Builds a forest of `N` trees.
    """</span>
    forest = []
    <span>for</span> _ <span>in</span> <span>range</span>(N):
        root = Node(<span>None</span>, vecs)
        _build_tree(root, K, imb)
        forest.append(root)
    <span>return</span> forest
</code></pre>
<p>This is a denser code block, so let's walk through it step-by-step. First, given an already-initialized <code>Node</code>, we randomly select two vectors and split the dataset into left and right halves. We then use the function we defined earlier to determine which of the two halves the subvectors belong to. Note that we've added an <code>imb</code> parameter to maintain tree balance - if one side of the tree contains more than 95% of all the subvectors, we redo the split process.</p>
<p>With node splitting in place, the <code>build_tree</code> function will recursively call itself on all nodes. Leaf nodes are defined as those which contain fewer than <code>K</code> subvectors.</p>
<p>Great, so we've built a binary tree that lets us significantly reduce the scope of our search. Now let's implement querying as well. Querying is pretty straightforward; we traverse the tree, continuously moving along the left or right branches until we've arrived at the one we're interested in:</p>
<pre><code><span>def</span> <span>_query_linear</span>(<span>vecs: <span>List</span>[np.ndarray], q: np.ndarray, k: <span>int</span></span>) -&gt; <span>List</span>[np.ndarray]:
    <span>return</span> <span>sorted</span>(vecs, key=<span>lambda</span> v: np.linalg.norm(q-v))[:k]


<span>def</span> <span>query_tree</span>(<span>root: Node, q: np.ndarray, k: <span>int</span></span>) -&gt; <span>List</span>[np.ndarray]:
    <span>"""Queries a single tree.
    """</span>

    <span>while</span> root.left <span>and</span> root.right:
        dist_l = np.linalg.norm(q - node.left.ref)
        dist_r = np.linalg.norm(q - node.right.ref)
        root = root.left <span>if</span> dist_l &lt; dist_r <span>else</span> root.right

    <span># brute-force search the nearest neighbors</span>
    <span>return</span> _query_linear(root.vecs, q, k)
</code></pre>
<p>This chunk of code will greedily traverse the tree, returning a single nearest neighbor (<code>nq = 1</code>). However, recall that we're often interested in finding multiple nearest neighbors. Additionally, multiple nearest neighbors can live in other leaf nodes as well. So how can we solve these issues?</p>
<p>(Yes, I do realize that the main character's name is spelled "Forrest" in the <a href="https://en.wikipedia.org/wiki/Forrest_Gump">American classic</a>.)</p>
<p>In a <a href="https://zilliz.com/blog/vector-index">previous tutorial on IVF</a>, recall that we often expanded our search beyond the Voronoi cell closest to the query vector. The reason is due to <em>cell edges</em> - if a query vector is close to a cell edge, it's very likely that some of its nearest neighbors may be in a neighboring cell. These "edges" are much more common in high-dimensional spaces, so a large-ish value of <code>nprobe</code> is often used when a high recall is needed.</p>
<p>We face the same problem for tree-based indexes - some of our nearest neighbors may be outside the nearest leaf node/polygon. Annoy solves this by 1) allowing searches on both sides of a split and 2) creating a <em>forest</em> of trees.</p>
<p>Let's first expand on our implementation in the previous section to search both sides of a split:</p>
<pre><code><span>def</span> <span>_select_nearby</span>(<span>node: Node, q: np.ndarray, thresh: <span>int</span> = <span>0</span></span>):
    <span>"""Functions identically to _is_query_in_left_half, but can return both.
    """</span>
    <span>if</span> <span>not</span> node.left <span>or</span> <span>not</span> node.right:
        <span>return</span> ()
    dist_l = np.linalg.norm(q - node.left.ref)
    dist_r = np.linalg.norm(q - node.right.ref)
    <span>if</span> np.<span>abs</span>(dist_l - dist_r) &lt; thresh:
        <span>return</span> (node.left, node.right)
    <span>if</span> dist_l &lt; dist_r:
        <span>return</span> (node.left,)
    <span>return</span> (node.right,)


<span>def</span> <span>_query_tree</span>(<span>root: Node, q: np.ndarray, k: <span>int</span></span>) -&gt; <span>List</span>[np.ndarray]:
    <span>"""This replaces the `query_tree` function above.
    """</span>

    pq = [root]
    nns = []
    <span>while</span> pq:
        node = pq.pop(<span>0</span>)
        nearby = _select_nearby(node, q, thresh=<span>0.05</span>)

        <span># if `_select_nearby` does not return either node, then we are at a leaf</span>
        <span>if</span> nearby:
            pq.extend(nearby)
        <span>else</span>:
            nns.extend(node.vecs)

    <span># brute-force search the nearest neighbors</span>
    <span>return</span> _query_linear(nns, q, k)


<span>def</span> <span>query_forest</span>(<span>forest: <span>List</span>[Node], q, k: <span>int</span> = <span>10</span></span>):
    nns = <span>set</span>()
    <span>for</span> root <span>in</span> forest:
        <span># merge `nns` with query result</span>
        res = _query_tree(root, q, k)
        nns.update(res)
    <span>return</span> _query_linear(nns, q, k)
</code></pre>
<p>Next, we'll add a function to allow us to build the full index as a forest of trees:</p>
<pre><code><span>def</span> <span>build_forest</span>(<span>vecs: <span>List</span>[np.ndarray], N: <span>int</span> = <span>32</span>, K: <span>int</span> = <span>64</span>, imb: <span>float</span> = <span>0.95</span></span>) -&gt; <span>List</span>[Node]:
    <span>"""Builds a forest of `N` trees.
    """</span>
    forest = []
    <span>for</span> _ <span>in</span> <span>range</span>(N):
        root = Node(<span>None</span>, vecs)
        _build_tree(root, K, imb)
        forest.append(root)
    <span>return</span> forest
</code></pre>
<p>With everything implemented, let's now put it all together, as we've done for IVF, SQ, PQ, and HNSW:</p>
<pre><code><span>from</span> typing <span>import</span> <span>List</span>, <span>Optional</span>
<span>import</span> random

<span>import</span> numpy <span>as</span> np


<span>class</span> <span>Node</span>(<span>object</span>):
    <span>"""Initialize with a set of vectors, then call `split()`.
    """</span>

    <span>def</span> <span>__init__</span>(<span>self, ref: np.ndarray, vecs: <span>List</span>[np.ndarray]</span>):
        self._ref = ref
        self._vecs = vecs
        self._left = <span>None</span>
        self._right = <span>None</span>

<span>    @property</span>
    <span>def</span> <span>ref</span>(<span>self</span>) -&gt; <span>Optional</span>[np.ndarray]:
        <span>"""Reference point in n-d hyperspace. Evaluates to `False` if root node.
        """</span>
        <span>return</span> self._ref

<span>    @property</span>
    <span>def</span> <span>vecs</span>(<span>self</span>) -&gt; <span>List</span>[np.ndarray]:
        <span>"""Vectors for this leaf node. Evaluates to `False` if not a leaf.
        """</span>
        <span>return</span> self._vecs

<span>    @property</span>
    <span>def</span> <span>left</span>(<span>self</span>) -&gt; <span>Optional</span>[<span>object</span>]:
        <span>"""Left node.
        """</span>
        <span>return</span> self._left

<span>    @property</span>
    <span>def</span> <span>right</span>(<span>self</span>) -&gt; <span>Optional</span>[<span>object</span>]:
        <span>"""Right node.
        """</span>
        <span>return</span> self._right

    <span>def</span> <span>split</span>(<span>self, K: <span>int</span>, imb: <span>float</span></span>) -&gt; <span>bool</span>:

        <span># stopping condition: maximum # of vectors for a leaf node</span>
        <span>if</span> <span>len</span>(self._vecs) &lt;= K:
            <span>return</span> <span>False</span>

        <span># continue for a maximum of 5 iterations</span>
        <span>for</span> n <span>in</span> <span>range</span>(<span>5</span>):
            left_vecs = []
            right_vecs = []

            <span># take two random indexes and set as left and right halves</span>
            left_ref = self._vecs.pop(np.random.randint(<span>len</span>(self._vecs)))
            right_ref = self._vecs.pop(np.random.randint(<span>len</span>(self._vecs)))

            <span># split vectors into halves</span>
            <span>for</span> vec <span>in</span> self._vecs:
                dist_l = np.linalg.norm(vec - left_ref)
                dist_r = np.linalg.norm(vec - right_ref)
                <span>if</span> dist_l &lt; dist_r:
                    left_vecs.append(vec)
                <span>else</span>:
                    right_vecs.append(vec)

            <span># check to make sure that the tree is mostly balanced</span>
            r = <span>len</span>(left_vecs) / <span>len</span>(self._vecs)
            <span>if</span> r &lt; imb <span>and</span> r &gt; (<span>1</span> - imb):
                self._left = Node(left_ref, left_vecs)
                self._right = Node(right_ref, right_vecs)
                <span>return</span> <span>True</span>

            <span># redo tree build process if imbalance is high</span>
            self._vecs.append(left_ref)
            self._vecs.append(right_ref)

        <span>return</span> <span>False</span>


<span>def</span> <span>_select_nearby</span>(<span>node: Node, q: np.ndarray, thresh: <span>int</span> = <span>0</span></span>):
    <span>"""Functions identically to _is_query_in_left_half, but can return both.
    """</span>
    <span>if</span> <span>not</span> node.left <span>or</span> <span>not</span> node.right:
        <span>return</span> ()
    dist_l = np.linalg.norm(q - node.left.ref)
    dist_r = np.linalg.norm(q - node.right.ref)
    <span>if</span> np.<span>abs</span>(dist_l - dist_r) &lt; thresh:
        <span>return</span> (node.left, node.right)
    <span>if</span> dist_l &lt; dist_r:
        <span>return</span> (node.left,)
    <span>return</span> (node.right,)


<span>def</span> <span>_build_tree</span>(<span>node, K: <span>int</span>, imb: <span>float</span></span>):
    <span>"""Recurses on left and right halves to build a tree.
    """</span>
    node.split(K=K, imb=imb)
    <span>if</span> node.left:
        _build_tree(node.left, K=K, imb=imb)
    <span>if</span> node.right:
        _build_tree(node.right, K=K, imb=imb)


<span>def</span> <span>build_forest</span>(<span>vecs: <span>List</span>[np.ndarray], N: <span>int</span> = <span>32</span>, K: <span>int</span> = <span>64</span>, imb: <span>float</span> = <span>0.95</span></span>) -&gt; <span>List</span>[Node]:
    <span>"""Builds a forest of `N` trees.
    """</span>
    forest = []
    <span>for</span> _ <span>in</span> <span>range</span>(N):
        root = Node(<span>None</span>, vecs)
        _build_tree(root, K, imb)
        forest.append(root)
    <span>return</span> forest


<span>def</span> <span>_query_linear</span>(<span>vecs: <span>List</span>[np.ndarray], q: np.ndarray, k: <span>int</span></span>) -&gt; <span>List</span>[np.ndarray]:
    <span>return</span> <span>sorted</span>(vecs, key=<span>lambda</span> v: np.linalg.norm(q-v))[:k]


<span>def</span> <span>_query_tree</span>(<span>root: Node, q: np.ndarray, k: <span>int</span></span>) -&gt; <span>List</span>[np.ndarray]:
    <span>"""Queries a single tree.
    """</span>

    pq = [root]
    nns = []
    <span>while</span> pq:
        node = pq.pop(<span>0</span>)
        nearby = _select_nearby(node, q, thresh=<span>0.05</span>)

        <span># if `_select_nearby` does not return either node, then we are at a leaf</span>
        <span>if</span> nearby:
            pq.extend(nearby)
        <span>else</span>:
            nns.extend(node.vecs)

    <span># brute-force search the nearest neighbors</span>
    <span>return</span> _query_linear(nns, q, k)


<span>def</span> <span>query_forest</span>(<span>forest: <span>List</span>[Node], q, k: <span>int</span> = <span>10</span></span>):
    nns = <span>set</span>()
    <span>for</span> root <span>in</span> forest:
        <span># merge `nns` with query result</span>
        res = _query_tree(root, q, k)
        nns.update(res)
    <span>return</span> _query_linear(nns, q, k)
</code></pre>
<p>And that's it for Annoy!</p>
<p>In this tutorial, we did a deep dive into Annoy, a tree-based indexing strategy with a playful name. There are better languages than Python for implementing vector search data structures due to interpreter overhead. Still, we use as much numpy-based array math. We can do many optimizations to prevent copying memory back and forth, but I'll leave them as an exercise for the reader.</p>
<p>In the following tutorial, we'll continue our deep dive into indexing strategies with a rundown of the Vamana algorithm - also known more commonly as <em>DiskANN</em> - a unique graph-based indexing algorithm that is tailored specifically towards querying directly from solid state hard drives.</p>
<p>All code for this tutorial is freely available on <a href="https://github.com/fzliu/vector-search">my Github</a>.</p>
<ol>
<li><a href="https://zilliz.com/blog/introduction-to-unstructured-data">Introduction to Unstructured Data</a></li>
<li><a href="https://zilliz.com/learn/what-is-vector-database">What is a Vector Database?</a></li>
<li><a href="https://zilliz.com/learn/comparing-vector-database-vector-search-library-and-vector-search-plugin">Comparing Vector Databases, Vector Search Libraries, and Vector Search Plugins</a></li>
<li><a href="https://zilliz.com/blog/introduction-to-milvus-vector-database">Introduction to Milvus</a></li>
<li><a href="https://zilliz.com/blog/milvus-vector-database-quickstart">Milvus Quickstart</a></li>
<li><a href="https://zilliz.com/blog/vector-similarity-search">Introduction to Vector Similarity Search</a></li>
<li><a href="https://zilliz.com/blog/vector-index">Vector Index Basics and the Inverted File Index</a></li>
<li><a href="https://zilliz.com/blog/scalar-quantization-and-product-quantization">Scalar Quantization and Product Quantization</a></li>
<li><a href="https://zilliz.com/blog/hierarchical-navigable-small-worlds-HNSW">Hierarchical Navigable Small Worlds (HNSW)</a></li>
<li><a href="https://zilliz.com/learn/approximate-nearest-neighbor-oh-yeah-ANNOY">Approximate Nearest Neighbor Oh Yeah (ANNOY)</a></li>
<li><a href="https://thesequence.substack.com/p/guest-post-choosing-the-right-vector">Choosing the Right Vector Index for Your Project</a></li>
<li><a href="https://zilliz.com/learn/DiskANN-and-the-Vamana-Algorithm">DiskANN and the Vamana Algorithm</a></li>
</ol>
<hr>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Global CO2 Levels (276 pts)]]></title>
            <link>https://www.co2levels.org/</link>
            <guid>38072267</guid>
            <pubDate>Mon, 30 Oct 2023 17:06:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.co2levels.org/">https://www.co2levels.org/</a>, See on <a href="https://news.ycombinator.com/item?id=38072267">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <div data-wow-delay=".3s" data-wow-duration=".3s">
            <h4>Real-time and Historical data</h4>
            <p>CO2 levels are updated daily with data directly from NOAA's science lab on the slopes of Moana Loa volcano on the Big Island of Hawaii.  Atmospheric carbon dioxide measurements have been collected here daily since 1959. Pre-1959 data comes from ice core data taken from Antarctica.  Historical and current atmospheric temperature can be overlayed on the graph. <a href="#sources">Learn more about the data sources</a>.</p>
          </div>
        
        <div data-wow-delay=".3s" data-wow-duration=".3s">
            <h4>Free CO<sub>2</sub> Levels Graph</h4>
            <p>This interactive graph is free to use on your website.  Simply choose your color theme and then copy and paste 2 lines of code.  Data and source code is hosted on our servers so you do not have to worry about using up your server's bandwidth. New CO2 measurement data is updated automatically  every day and temperature data is updated monthly.
          </p></div>
        
        <div data-wow-delay=".3s" data-wow-duration=".3s">
            <h4>Zoomable and Printable</h4>
            <p>View atmospheric CO<sub>2</sub> levels and/or temperature over a span of thousands of years or zoom to specific time periods.  Use your fingers to pinch and zoom on a handheld device or use a mouse with a computer. Export the chart to PNG, JPG, PDF or SVG format with the click of a button or print the chart directly from the web page.
          </p></div>

        <div data-wow-delay=".3s" data-wow-duration=".3s">
            <h4>Customizable and Responsive</h4>
            <p> Choose from  4 color themes to match your website's look and feel.  Customize the width and height of your graph or have it <a href="https://www.co2levels.org/atmospheric_co2_graph.php" target="_blank">fill your entire screen</a>.  The carbon dioxide levels graph is responsive and can automatically resize to fit whatever device or screen size it is being viewed on.</p>
          </div>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google Brain cofounder says Big Tech lying about risks of AI wiping out humanity (368 pts)]]></title>
            <link>https://www.businessinsider.com/andrew-ng-google-brain-big-tech-ai-risks-2023-10</link>
            <guid>38072218</guid>
            <pubDate>Mon, 30 Oct 2023 17:03:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.businessinsider.com/andrew-ng-google-brain-big-tech-ai-risks-2023-10">https://www.businessinsider.com/andrew-ng-google-brain-big-tech-ai-risks-2023-10</a>, See on <a href="https://news.ycombinator.com/item?id=38072218">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="piano-inline-content-wrapper" data-piano-inline-content-wrapper=""> 
                    
                    
                    
                          
                          
                          <section data-offer-key="pre-churn-offer" data-component-type="inline-offer" data-place-after-element-selector=".post-content .content-lock-content > p">
                            <article>
                              <img src="https://www.businessinsider.com/public/assets/subscription/marketing/banner-overlay/top-left.svg" alt="">
                              <img src="https://www.businessinsider.com/public/assets/subscription/marketing/banner-overlay/bottom-right.svg" alt="">
                          
                                        </article>
                          </section>
                    
                    <div data-component-type="content-lock" data-load-strategy="exclude">
                                  <ul><li>Big Tech is lying about some AI risks to shut down competition, a Google Brain cofounder has said.</li><li>Andrew Ng told The Australian Financial Review that tech leaders hoped to trigger strict regulation.</li><li>Some large tech companies didn't want to compete with open source, he added.</li></ul><div id="formContainer" data-component-type="inline-newsletter-module" data-event-label="insider_today" data-newsletter-id="1" data-list="Insider Today" data-acq-source="techinlinesignup">
                        
                        
                          <section>
                              
                        
                            <p><svg version="1.1" xmlns="http://www.w3.org/2000/svg" role="img" width="50" height="50" viewBox="0 0 50 50" style="enable-background:new 0 0 50 50;" xml:space="preserve">
                          <title>Loading</title>
                          <desc>Something is loading.</desc>
                          <path fill="#111" d="M43.935,25.145c0-10.318-8.364-18.683-18.683-18.683c-10.318,0-18.683,8.365-18.683,18.683h4.068c0-8.071,6.543-14.615,14.615-14.615c8.072,0,14.615,6.543,14.615,14.615H43.935z">
                            <animateTransform attributeType="xml" attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="0.6s" repeatCount="indefinite"></animateTransform>
                          </path>
                        </svg></p>
                            
                        
                            
                        
                            <div>
                              <p>Thanks for signing up!</p>
                              
                              <p>
                              Access your favorite topics in a personalized feed while you're on the go.
                                    </p>
                            </div>
                        
                            
                            
                          </section>
                        
                            <div>
                                <p><img src="https://www.businessinsider.com/public/assets/rebrand/newsletter-bull.png" data-old-src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 1 1'%3E%3C/svg%3E" data-src="/public/assets/rebrand/newsletter-bull.png">
                              
                              
                              
                              </p>    </div>
                        
                          
                        </div><p>A leading AI expert and Google Brain cofounder said Big Tech companies were stoking fears about the technology's risks to shut down competition.</p><p>Google Brain was a deep-learning AI research team that merged with the DeepMind division earlier this year.</p><p><a target="_blank" href="https://www.businessinsider.com/ai-godfather-top-names-possibilities-dangers-openai-chatgpt-list-2023-8?r=US&amp;IR=T#british-american-computer-scientist-andrew-ng-founded-a-massive-deep-learning-project-called-google-brain-in-2011-9" data-analytics-product-module="body_link" rel="">Andrew Ng</a>, an adjunct professor at Stanford University who taught OpenAI CEO Sam Altman, told The Australian Financial Review that <a target="_blank" href="https://www.afr.com/technology/google-brain-founder-says-big-tech-is-lying-about-ai-human-extinction-danger-20231027-p5efnz" data-analytics-product-module="body_link" rel=" nofollow">the biggest tech companies </a>hoped to trigger strict regulation with the "bad idea that AI could make us go extinct."</p><p>"There are definitely large tech companies that would rather not have to try to compete with open source, so they're creating fear of AI leading to human extinction," he told the news outlet. "It's been a weapon for lobbyists to argue for legislation that would be very damaging to the open-source community."</p><p>In May, <a target="_blank" href="https://www.businessinsider.com/ai-extinction-risk-openai-deepmind-anthropic-ceos-sam-altman-2023-5?r=US&amp;IR=T" data-analytics-product-module="body_link" rel="">AI experts and CEOs signed</a> a statement from the Center for AI Safety that compared the risks posed by AI with nuclear war and pandemics. OpenAI CEO <a target="_blank" rel="" href="https://www.businessinsider.com/sam-altman-chatgpt-openai-ceo-career-net-worth-ycombinator-prepper-2023-1" data-analytics-product-module="body_link"><u>Sam Altman</u></a>, DeepMind CEO Demis Hassabis, and Anthropic CEO Dario Amodei all put their names to the public statement.</p><p>Other AI heavyweights have issued several warnings about the <a target="_blank" href="https://www.businessinsider.com/elon-musk-ai-pause-openai-gpt4-powerful-development-2023-3?r=US&amp;IR=T" data-analytics-product-module="body_link" rel="">accelerated development of advanced</a> generative AI models, with many urging regulators to act quickly.</p><p>Governments around the world are <a target="_blank" href="https://www.businessinsider.com/ai-regulation-2023-us-eu-china-100-10?r=US&amp;IR=T" data-analytics-product-module="body_link" rel="">looking to regulate AI</a>, citing concerns over safety, potential job losses, and even the risk of human extinction. The European Union will likely be the first region to enforce oversight or <a target="_blank" rel="" href="https://www.businessinsider.com/us-copyright-office-new-rules-generative-ai-2023-8" data-analytics-product-module="body_link"><u>regulation</u></a> around generative AI.</p><p>Ng said the idea that AI could wipe out humanity could lead to policy proposals that require licensing of AI, which risked crushing innovation. Any necessary AI regulation should be created thoughtfully, he added. </p><p>Ng did not immediately respond to Insider's request for comment, made outside normal working hours.</p>
                      </div>
                    
                    
                        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Meta to charge for ad-free versions of Facebook and Instagram in Europe (168 pts)]]></title>
            <link>https://www.nytimes.com/2023/10/30/technology/facebook-meta-subscription-europe.html</link>
            <guid>38071472</guid>
            <pubDate>Mon, 30 Oct 2023 16:12:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2023/10/30/technology/facebook-meta-subscription-europe.html">https://www.nytimes.com/2023/10/30/technology/facebook-meta-subscription-europe.html</a>, See on <a href="https://news.ycombinator.com/item?id=38071472">Hacker News</a></p>
Couldn't get https://www.nytimes.com/2023/10/30/technology/facebook-meta-subscription-europe.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Razor 1911 (224 pts)]]></title>
            <link>https://en.wikipedia.org/wiki/Razor_1911</link>
            <guid>38071341</guid>
            <pubDate>Mon, 30 Oct 2023 16:05:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://en.wikipedia.org/wiki/Razor_1911">https://en.wikipedia.org/wiki/Razor_1911</a>, See on <a href="https://news.ycombinator.com/item?id=38071341">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
							

						<p>From Wikipedia, the free encyclopedia</p>
					</div><div id="mw-content-text" lang="en" dir="ltr">

<table><caption>Razor 1911</caption><tbody><tr><td colspan="2"><span typeof="mw:File"><a href="https://en.wikipedia.org/wiki/File:Razor1911_JEDACID_HQ.jpg"><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/0/00/Razor1911_JEDACID_HQ.jpg/180px-Razor1911_JEDACID_HQ.jpg" decoding="async" width="180" height="66" srcset="https://upload.wikimedia.org/wikipedia/commons/thumb/0/00/Razor1911_JEDACID_HQ.jpg/270px-Razor1911_JEDACID_HQ.jpg 1.5x, https://upload.wikimedia.org/wikipedia/commons/thumb/0/00/Razor1911_JEDACID_HQ.jpg/360px-Razor1911_JEDACID_HQ.jpg 2x" data-file-width="3440" data-file-height="1264"></a></span><p>Razor 1911</p></td></tr><tr><th scope="row">Formation</th><td>October 1985</td></tr><tr><th scope="row">Purpose</th><td><a href="https://en.wikipedia.org/wiki/Warez" title="Warez">Warez</a> / <a href="https://en.wikipedia.org/wiki/Demoscene" title="Demoscene">Demo</a></td></tr><tr><th scope="row">Location</th><td><div><ul><li><a href="https://en.wikipedia.org/wiki/Norway" title="Norway">Norway</a></li></ul></div></td></tr><tr><th scope="row"><p>Origin</p></th><td><a href="https://en.wikipedia.org/wiki/Norway" title="Norway">Norway</a></td></tr><tr><th scope="row"><p>Founders</p></th><td>Doctor No<br>Insane TTM<br>Sector9</td></tr><tr><th scope="row">Website</th><td><s><a rel="nofollow" href="http://www.razor1911.com/">razor1911.com</a></s> Currently down, latest archived snapshot available <a rel="nofollow" href="https://web.archive.org/web/20210629173434/https://razor1911.com/">here</a></td></tr></tbody></table>
<p><b>Razor 1911</b> (<b>RZR</b>) is a <a href="https://en.wikipedia.org/wiki/Warez" title="Warez">warez</a> and <a href="https://en.wikipedia.org/wiki/Demogroup" title="Demogroup">demogroup</a> founded in Norway, 1986. It was the first ever such group to be initially founded exclusively as a demogroup, before moving into warez in 1987.<sup id="cite_ref-:0_1-0"><a href="#cite_note-:0-1">[1]</a></sup> According to the US Justice Department, Razor 1911 is the oldest software cracking group that is still active on the internet.<sup id="cite_ref-2"><a href="#cite_note-2">[2]</a></sup><sup id="cite_ref-3"><a href="#cite_note-3">[3]</a></sup> Razor 1911 ran the <a href="https://en.wikipedia.org/wiki/Diskmag" title="Diskmag">diskmag</a> 'Propaganda' until 1995.<sup id="cite_ref-:0_1-1"><a href="#cite_note-:0-1">[1]</a></sup>
</p>
<meta property="mw:PageProp/toc">
<h2><span id="History">History</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Razor_1911&amp;action=edit&amp;section=1" title="Edit section: History"><span>edit</span></a><span>]</span></span></h2>
<p>The group was founded as <i>Razor 2992</i> by Doctor No, Insane TTM and Sector9 in <a href="https://en.wikipedia.org/wiki/Norway" title="Norway">Norway</a> in October 1985 as a <a href="https://en.wikipedia.org/wiki/Commodore_64" title="Commodore 64">Commodore 64</a> <a href="https://en.wikipedia.org/wiki/Software_cracking" title="Software cracking">software cracking</a> group. Shortly after, they changed from 2992 to 1911 which translates to <a href="https://en.wikipedia.org/wiki/777_(number)#Computing" title="777 (number)">777</a> in
<a href="https://en.wikipedia.org/wiki/Hexadecimal" title="Hexadecimal">hexadecimal</a>.
</p><p>Between 1987 and 1988 the group began to move away from the Commodore 64 and migrated to a new hardware platform, coding demos and cracking games for the <a href="https://en.wikipedia.org/wiki/Amiga" title="Amiga">Amiga</a>. In the very early 1990s Razor 1911 made another transition, this time to the <a href="https://en.wikipedia.org/wiki/IBM_PC" title="IBM PC">IBM PC</a>, foremost as a cracking group, but still continuing to release <a href="https://en.wikipedia.org/wiki/Crack_intro" title="Crack intro">cracktro loaders</a>, demos and music.
</p><p>Razor was a supply group on <a href="https://en.wikipedia.org/wiki/Floppy_disk" title="Floppy disk">diskette</a> from 1992 until diskettes were abandoned for <a href="https://en.wikipedia.org/wiki/CD-ROM" title="CD-ROM">CD-ROMs</a>. Throughout the 1990s Razor faced competition from many different groups, ranging from groups such as <a href="https://en.wikipedia.org/wiki/Tristar_and_Red_Sector_Incorporated" title="Tristar and Red Sector Incorporated">Tristar &amp; Red Sector inc.</a> (TRSi), <a href="https://en.wikipedia.org/wiki/International_Network_of_Crackers" title="International Network of Crackers">International Network of Crackers</a> (INC) and <a href="https://en.wikipedia.org/wiki/Fairlight_(group)" title="Fairlight (group)">Fairlight</a> (FLT) in 1994 to Prestige, <a href="https://en.wikipedia.org/w/index.php?title=Hybrid_(warez)&amp;action=edit&amp;redlink=1" title="Hybrid (warez) (page does not exist)">Hybrid</a> (HBD), and others in 1995. Razor was revitalised by new members gained from another group, Nexus, who brought with them some UK suppliers and the leaders The Speed Racer (TSR), Hot Tuna and The Gecko. Razor had a handful of others throughout the 1990s, such as Zodact, ROMKernel, The Renegade Chemist (TRC), The WiTcH KiNG, Butcher, SwiTch, Marauder, and Randall Flagg.
</p><p>Razor 1911 took a break from the demoscene in 1992. In 1993 a new demogroup calling itself Razor 1911 formed, in which Colorbird was the only original member of Razor 1911. Razor 1911 was still active as a software cracking group.<sup id="cite_ref-:0_1-2"><a href="#cite_note-:0-1">[1]</a></sup>
</p><p>In 1995 diskette releases were rapidly being supplanted by CD-ROMs, and Razor 1911 moved into the CD-ripping scene. The crew that led Razor into this new chapter included members such as TSR, Pharaoh, Fatal Error, GRIZZLY, Suspicious Image, Third Son, Hot Tuna, Beowulf, Pitbull, Bunter, Manhunter, Niteman, Vitas, Mausioso and The Punisher.
</p><p>Razor once again took on a new challenge when the <a href="https://en.wikipedia.org/wiki/ISO_9660" title="ISO 9660">ISO</a> scene was formed. Razor 1911 began to release ISOs when they became the standard of the day, led most significantly by The Punisher. He was instrumental in Razor's recovery and its solid performance in the ISO scene. Following The Punisher's retirement, Razor was led by various different people and underwent some internal problems in the form of leadership challenges. This was solved when Pitbull, an old Razor member from the 1990s, took over the leadership role. The FBI claimed him to still be the leader of Razor at the time when "<a href="https://en.wikipedia.org/wiki/Operation_Buccaneer" title="Operation Buccaneer">Operation Buccaneer</a>", an international anti-piracy operation which led to raids at the homes of over 60 piracy suspects worldwide in 2001, was carried out even though NFOs and scene activity at the time points out The Renegade Chemist as actual leader of the group.
</p><p>Sean Michael Breen was convicted in 2004 to "50 months in prison and three years of supervised release, for violating the criminal copyright laws as a member of the first computer game piracy ring on the Internet, and for defrauding Cisco Systems".<sup id="cite_ref-4"><a href="#cite_note-4">[4]</a></sup> The press release alleges them to be the leader of the group, although their nickname is not mentioned.
</p>
<h2><span id="Return">Return</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Razor_1911&amp;action=edit&amp;section=2" title="Edit section: Return"><span>edit</span></a><span>]</span></span></h2>
<p>On June 22, 2006, Razor 1911 started releasing games again. They have been releasing games fairly consistently ever since, and as of 2010 are among the most prolific groups at cracking new releases.<sup id="cite_ref-5"><a href="#cite_note-5">[5]</a></sup>
</p><p>On April 1, 2011, Razor 1911 "cracked" the TV show 101% on the French TV channel <a href="https://en.wikipedia.org/wiki/Nolife_(TV_channel)" title="Nolife (TV channel)">Nolife</a>, inducing many unwanted "bugs" and behaviors in the show. While this was a joke, the intro contained a real code giving unlimited access to the paid replay service for one day.<sup id="cite_ref-6"><a href="#cite_note-6">[6]</a></sup>
</p><p>On April 22, 2011, Razor 1911's demo division won the public choice award<sup id="cite_ref-7"><a href="#cite_note-7">[7]</a></sup> during the <a rel="nofollow" href="http://awards.scene.org/">Scene.org Awards</a> ceremony at <a href="https://en.wikipedia.org/wiki/The_Gathering_(computer_party)" title="The Gathering (computer party)">The Gathering</a> for their <a href="https://en.wikipedia.org/wiki/64k_intro" title="64k intro">64k intro</a> "Insert No Coins" coded by Rez with music from Dubmood.<sup id="cite_ref-8"><a href="#cite_note-8">[8]</a></sup>
</p>
<h2><span id="Members">Members</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Razor_1911&amp;action=edit&amp;section=3" title="Edit section: Members"><span>edit</span></a><span>]</span></span></h2>
<p>Dycus, a member of Razor 1911, died of <a href="https://en.wikipedia.org/wiki/Throat_cancer" title="Throat cancer">throat cancer</a> in 2012.<sup id="cite_ref-9"><a href="#cite_note-9">[9]</a></sup>
</p>
<h2><span id="See_also">See also</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Razor_1911&amp;action=edit&amp;section=4" title="Edit section: See also"><span>edit</span></a><span>]</span></span></h2>
<ul><li><a href="https://en.wikipedia.org/wiki/List_of_warez_groups" title="List of warez groups">List of warez groups</a></li>
<li><a href="https://en.wikipedia.org/wiki/Warez_group" title="Warez group">Warez group</a></li></ul>
<h2><span id="References">References</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Razor_1911&amp;action=edit&amp;section=5" title="Edit section: References"><span>edit</span></a><span>]</span></span></h2>
<div><ol>
<li id="cite_note-:0-1"><span>^ <a href="#cite_ref-:0_1-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-:0_1-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-:0_1-2"><sup><i><b>c</b></i></sup></a></span> <span><cite id="CITEREFPolgár2000">Polgár, Tamás 'Tomcat' (2000). <i>Freax Volume 1</i>. CSW-Verlag. pp.&nbsp;100, 148, 171. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/3981049403" title="Special:BookSources/3981049403"><bdi>3981049403</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Freax+Volume+1&amp;rft.pages=100%2C+148%2C+171&amp;rft.pub=CSW-Verlag&amp;rft.date=2000&amp;rft.isbn=3981049403&amp;rft.aulast=Polg%C3%A1r&amp;rft.aufirst=Tam%C3%A1s+%27Tomcat%27&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARazor+1911"></span></span>
</li>
<li id="cite_note-2"><span><b><a href="#cite_ref-2">^</a></b></span> <span><cite><a rel="nofollow" href="https://web.archive.org/web/20130415114316/http://www.justice.gov/criminal/cybercrime/press-releases/2003/pitmanSent.htm">"Former Leader of Razor 1911, the Oldest Game Software Piracy Ring on the Internet, Sentenced (June 6, 2003)"</a>. Archived from <a rel="nofollow" href="https://www.justice.gov/criminal/cybercrime/press-releases/2003/pitmanSent.htm">the original</a> on 2013-04-15<span>. Retrieved <span>2021-11-22</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Former+Leader+of+Razor+1911%2C+the+Oldest+Game+Software+Piracy+Ring+on+the+Internet%2C+Sentenced+%28June+6%2C+2003%29&amp;rft_id=http%3A%2F%2Fwww.justice.gov%2Fcriminal%2Fcybercrime%2Fpress-releases%2F2003%2FpitmanSent.htm&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARazor+1911"></span></span>
</li>
<li id="cite_note-3"><span><b><a href="#cite_ref-3">^</a></b></span> <span><cite id="CITEREFFisk2009">Fisk, Nathan (2009). <i>Warez Groups</i>. pp.&nbsp;193–194. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/978-0-313-33974-5" title="Special:BookSources/978-0-313-33974-5"><bdi>978-0-313-33974-5</bdi></a>. <q>Razor 1911 is widely considered to be the oldest surviving warez group, having been established in 1985.</q></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Warez+Groups&amp;rft.pages=193-194&amp;rft.date=2009&amp;rft.isbn=978-0-313-33974-5&amp;rft.aulast=Fisk&amp;rft.aufirst=Nathan&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARazor+1911"></span> </span>
</li>
<li id="cite_note-4"><span><b><a href="#cite_ref-4">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.justice.gov/archive/criminal/cybercrime/press-releases/2004/breenSent.htm">"Leader of Oldest Game Piracy Group Get 50-Month Prison Sentence"</a><span>. Retrieved <span>2023-06-30</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Leader+of+Oldest+Game+Piracy+Group+Get+50-Month+Prison+Sentence&amp;rft_id=https%3A%2F%2Fwww.justice.gov%2Farchive%2Fcriminal%2Fcybercrime%2Fpress-releases%2F2004%2FbreenSent.htm&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARazor+1911"></span></span>
</li>
<li id="cite_note-5"><span><b><a href="#cite_ref-5">^</a></b></span> <span><cite><a rel="nofollow" href="http://scenenotice.org/details.php?id=1708">"The Game Scene Charts Issue 38 December 2009 Edition"</a>. <i>SceneNotice.org</i>. 2010-01-20.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=SceneNotice.org&amp;rft.atitle=The+Game+Scene+Charts+Issue+38+December+2009+Edition&amp;rft.date=2010-01-20&amp;rft_id=http%3A%2F%2Fscenenotice.org%2Fdetails.php%3Fid%3D1708&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARazor+1911"></span> Razor 1911 is on position 10 for the year 2009.</span>
</li>
<li id="cite_note-6"><span><b><a href="#cite_ref-6">^</a></b></span> <span><a rel="nofollow" href="https://www.youtube.com/watch?v=Cve7PNySRZ4"><span>"Nolife - 101% cracked by RAZOR 1911"</span></a> on <a href="https://en.wikipedia.org/wiki/YouTube_video_(identifier)" title="YouTube video (identifier)">YouTube</a></span>
</li>
<li id="cite_note-7"><span><b><a href="#cite_ref-7">^</a></b></span> <span><cite><a rel="nofollow" href="http://awards.scene.org/awards.php?year=2010&amp;cat=11">"Scene.org Awards"</a>. 2011-04-22.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Scene.org+Awards&amp;rft.date=2011-04-22&amp;rft_id=http%3A%2F%2Fawards.scene.org%2Fawards.php%3Fyear%3D2010%26cat%3D11&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARazor+1911"></span></span>
</li>
<li id="cite_note-8"><span><b><a href="#cite_ref-8">^</a></b></span> <span><cite><a rel="nofollow" href="http://www.pouet.net/prod.php?which=55991">"pouet.net"</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=pouet.net&amp;rft_id=http%3A%2F%2Fwww.pouet.net%2Fprod.php%3Fwhich%3D55991&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARazor+1911"></span></span>
</li>
<li id="cite_note-9"><span><b><a href="#cite_ref-9">^</a></b></span> <span><cite><a rel="nofollow" href="http://www.pouet.net/topic.php?which=8696">"Rez, sorry to hear about Dycus"</a>. <i>pouët.net</i><span>. Retrieved <span>2021-03-01</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=pou%C3%ABt.net&amp;rft.atitle=Rez%2C+sorry+to+hear+about+Dycus&amp;rft_id=http%3A%2F%2Fwww.pouet.net%2Ftopic.php%3Fwhich%3D8696&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARazor+1911"></span></span>
</li>
</ol></div>
<h2><span id="External_links">External links</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Razor_1911&amp;action=edit&amp;section=6" title="Edit section: External links"><span>edit</span></a><span>]</span></span></h2>
<ul><li><a rel="nofollow" href="http://www.razor1911.com/">Razor 1911 Demo Division website</a> <a rel="nofollow" href="https://web.archive.org/web/20080330071459/http://www.razor1911.com/">Archived</a> 2008-03-30 at the <a href="https://en.wikipedia.org/wiki/Wayback_Machine" title="Wayback Machine">Wayback Machine</a></li></ul>

<!-- 
NewPP limit report
Parsed by mw1414
Cached time: 20231025211149
Cache expiry: 1814400
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.348 seconds
Real time usage: 0.472 seconds
Preprocessor visited node count: 2071/1000000
Post‐expand include size: 67362/2097152 bytes
Template argument size: 12603/2097152 bytes
Highest expansion depth: 19/100
Expensive parser function count: 5/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 35461/5000000 bytes
Lua time usage: 0.234/10.000 seconds
Lua memory usage: 7162613/52428800 bytes
Number of Wikibase entities loaded: 1/400
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  429.828      1 -total
 34.39%  147.825      4 Template:Ambox
 29.36%  126.182      1 Template:Reflist
 21.22%   91.203      1 Template:Multiple_issues
 19.39%   83.330      1 Template:Authority_control
 17.95%   77.140      2 Template:Cite_book
 14.34%   61.656      1 Template:Infobox_organization
 13.05%   56.111      1 Template:More_citations_needed
 12.83%   55.158      1 Template:Infobox
 12.62%   54.254      1 Template:Short_description
-->

<!-- Saved in parser cache with key enwiki:pcache:idhash:36161666-0!canonical and timestamp 20231025211148 and revision id 1181844709. Rendering was triggered because: page-view
 -->
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[New York Times Tech Workers to Strike This Afternoon (225 pts)]]></title>
            <link>https://www.bloomberg.com/news/articles/2023-10-30/new-york-times-tech-union-to-strike-over-office-return-contract-delays</link>
            <guid>38070098</guid>
            <pubDate>Mon, 30 Oct 2023 14:48:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bloomberg.com/news/articles/2023-10-30/new-york-times-tech-union-to-strike-over-office-return-contract-delays">https://www.bloomberg.com/news/articles/2023-10-30/new-york-times-tech-union-to-strike-over-office-return-contract-delays</a>, See on <a href="https://news.ycombinator.com/item?id=38070098">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
    <section>
        <h3>Why did this happen?</h3>
        <p>Please make sure your browser supports JavaScript and cookies and that you are not
            blocking them from loading.
            For more information you can review our <a href="https://www.bloomberg.com/notices/tos">Terms of
                Service</a> and <a href="https://www.bloomberg.com/notices/tos">Cookie Policy</a>.</p>
    </section>
    <section>
        <h3>Need Help?</h3>
        <p>For inquiries related to this message please <a href="https://www.bloomberg.com/feedback">contact
            our support team</a> and provide the reference ID below.</p>
        <p>Block reference ID:</p>
    </section>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Replacing WebRTC: real-time latency with WebTransport and WebCodecs (246 pts)]]></title>
            <link>https://quic.video/blog/replacing-webrtc/</link>
            <guid>38069974</guid>
            <pubDate>Mon, 30 Oct 2023 14:38:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://quic.video/blog/replacing-webrtc/">https://quic.video/blog/replacing-webrtc/</a>, See on <a href="https://news.ycombinator.com/item?id=38069974">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
<p>The long path to use <em>something else</em> for real-time media.</p>
<h2 id="tldr">tl;dr</h2>
<p>If you primarily use WebRTC for…</p>
<ul>
<li><strong>real-time media</strong>: it will take a while to replace WebRTC; we’re working on it.</li>
<li><strong>data channels</strong>: WebTransport is amazing and <em>actually</em> works.</li>
<li><strong>peer-to-peer</strong>: you’re stuck with WebRTC for the forseeable future.</li>
</ul>
<h2 id="disclaimer">Disclaimer</h2>
<p>I spent almost two years building/optimizing a partial WebRTC stack @ Twitch using <a href="https://github.com/pion/webrtc">pion</a>.
Our use-case was quite custom and we ultimately scrapped it, but your millage may vary.</p>
<h2 id="why-webrtc">Why WebRTC?</h2>
<p>Google released WebRTC in 2011 as a way of fixing a very specific problem:</p>
<blockquote>
<p>How do we build Google Meet?</p>
</blockquote>
<p>Back then, the web was a very different place.
Flash was the only way to do live media and it was a <em>mess</em>.
HTML5 video was primarily for pre-recorded content.
It personally took me until 2015 to write a <a href="https://reddit.com/r/Twitch/comments/3hqfkw/the_csgo_client_embeds_the_twitch_html5_player/">HTML5 player for Twitch</a> using <a href="https://developer.mozilla.org/en-US/docs/Web/API/Media_Source_Extensions_API">MSE</a>, and we’re still talking 5+ seconds of latency on a good day.</p>
<p>Transmitting video over the internet <em>in real-time</em> is hard.</p>
<p>You need a tight coupling between the video encoding and the network to avoid any form of queuing, which adds latency.
This effectively rules out TCP and forces you to use UDP.
But now you also need a video encoder/decoder that can deal with packet loss without spewing artifacts everywhere.</p>
<figure><p><img src="https://quic.video/blog/replacing-webrtc/artifact.png" alt="Video artifacts"></p><figcaption><p><a href="https://flashphoner.com/10-important-webrtc-streaming-metrics-and-configuring-prometheus-grafana-monitoring/">Source</a>.
Example of Artifacts caused by packet loss.</p></figcaption></figure>
<p>Google (correctly) determined that it would be impossible to solve these problems piecewise with new web standards.
The approach instead was to create <a href="https://webrtc.googlesource.com/src/">libwebrtc</a>, the defacto WebRTC implementation that still ships with all browsers.
It does everything, from networking to video encoding/decoding to data transfer, and it does it remarkably well.
It’s actually quite a feat of software engineering, <em>especially</em> the part where Google managed to convince Apple/Mozilla to embed a full media/networking stack into their browsers.</p>
<p>My favorite part about WebRTC is that it manages to leverage existing standards.
WebRTC is not really a protocol, but rather a collection of protocols: <a href="https://datatracker.ietf.org/doc/html/rfc8445">ICE</a>, <a href="https://datatracker.ietf.org/doc/html/rfc5389">STUN</a>, <a href="https://datatracker.ietf.org/doc/html/rfc5766">TURN</a>, <a href="https://datatracker.ietf.org/doc/html/rfc6347">DTLS</a>, <a href="https://datatracker.ietf.org/doc/html/rfc3550">RTP/RTCP</a>, <a href="https://datatracker.ietf.org/doc/html/rfc3711">SRTP</a>, <a href="https://datatracker.ietf.org/doc/html/rfc4960">SCTP</a>, <a href="https://datatracker.ietf.org/doc/html/rfc4566">SDP</a>, <a href="https://datatracker.ietf.org/doc/html/rfc6762">mDNS</a>, etc.
Throw a <a href="https://www.w3.org/TR/webrtc/">Javascript API</a> on top of these and you have WebRTC.</p>
<figure><p><img src="https://quic.video/blog/replacing-webrtc/layers.png" alt="WebRTC protocols and layers">
</p><figcaption><a href="https://hpbn.co/webrtc/">Source</a>. That’s a lot of protocols layered on top of each other.</figcaption></figure>
<h2 id="why-not-webrtc">Why not WebRTC?</h2>
<p>I wouldn’t be writing this blog post if WebRTC was perfect.
The core issue is that WebRTC is not a protocol; it’s a monolith.</p>
<p>WebRTC does a lot of things, let’s break down it down piece by piece:</p>
<ul>
<li><a href="#media">Media</a>: a full capture/encoding/networking/rendering pipeline.</li>
<li><a href="#data">Data</a>: reliable/unreliable messages.</li>
<li><a href="#p2p">P2P</a>: peer-to-peer connectability.</li>
<li><a href="#sfu">SFU</a>: a relay that selectively forwards media.</li>
</ul>
<h3 id="media">Media</h3>
<p>The WebRTC media stack is designed for conferencing and does an amazing job at it.
The problems start when you try to use it for anything else.</p>
<p>My final project at Twitch was to reduce latency by replacing HLS with WebRTC for delivery.
This seems like a no-brainer at first, but it quickly turned into <a href="https://docs.google.com/document/d/1OTnJunbpSJchdj8XI3GU9Fo-RUUFBqLO1AhlaKk5Alo/edit?usp=sharing">death by a thousand cuts</a>.
The biggest issue was that the user experience was just terrible.
Twitch doesn’t need the same aggressive latency as Google Meet, but WebRTC is hard-coded to compromise on quality.</p>
<p>In general, it’s quite difficult to customize WebRTC outside of a few configurable modes.
It’s a black box that you turn on, and if it works it works.
And if it doesn’t work, then you have to deal with the pain that is <a href="https://github.com/webrtc-sdk/libwebrtc">forking libwebrtc</a>… or just hope Google fixes it for you.</p>
<p>The protocol has some wiggle room and I really enjoyed my time tinkering with <a href="https://github.com/pion/webrtc">pion</a>.
But you’re ultimately bound by the browser implementation, unless you don’t need web support, in which case you don’t need WebRTC.</p>
<h3 id="data">Data</h3>
<p>WebRTC also has a data channel API, which is particularly useful because <a href="#webtransport">until recently</a>, it’s been the only way to send/receive “unreliable” messages from a browser.
In fact, many companies use WebRTC data channels to avoid the WebRTC media stack (ex. Zoom).</p>
<p>I went down this path too, attempting to send each video frame as an unreliable message, but it didn’t work due to fundamental flaws with <a href="https://www.rfc-editor.org/rfc/rfc9260.html">SCTP</a>.
I won’t go into the detail in this post, but I eventually hacked “datagram” support into SCTP by breaking frames into unreliable messages below the MTU size.</p>
<p>Finally! UDP* in the browser, but at what cost:</p>
<ul>
<li>a convoluted handshake that takes at least 10 (!) round trips.</li>
<li>2x the packets, because libsctp immediately ACKs every “datagram”.</li>
<li>a custom SCTP implementation, which means the browser can’t send “datagrams”.</li>
</ul>
<p>Oof.</p>
<h3 id="p2p">P2P</h3>
<p>The best and worst part about WebRTC is that it supports peer-to-peer.</p>
<p>The <a href="https://developer.mozilla.org/en-US/docs/Web/API/WebRTC_API/Connectivity">ICE handshake</a> is extremely complicated, even from the <a href="https://developer.mozilla.org/en-US/docs/Web/API/WebRTC_API/Signaling_and_video_calling">application’s point of view</a>.
Without going into detail, there’s an explosion of permutations that you need to handle based on the network topology.
Some networks block P2P (ex. symmetric NATs) while others outright block UDP, forcing you to use a TURN server a <a href="https://twitter.com/HCornflower/status/894600051506515968">non-insignificant amount of time</a>.</p>
<p>Most conferencing solutions are client-server anyway, relying on their own private network instead of public transit (aka a CDN).
However the server is still forced to perform the complicated ICE handshake which has major architecture ramifications, but I’ll save that for another blog post.</p>
<p>Note that there are rumblings of <a href="https://w3c.github.io/p2p-webtransport/">P2P WebTransport</a> and <a href="https://datatracker.ietf.org/doc/draft-seemann-quic-nat-traversal/">P2P QUIC</a>, but I wouldn’t hold my breath.</p>
<h3 id="sfu">SFU</h3>
<p>Last but not least, WebRTC scales using SFUs (Selective Forwarding Units).</p>
<figure><p><img src="https://quic.video/blog/replacing-webrtc/sfu.png" alt="SFU example"></p><figcaption><p><a href="https://blog.livekit.io/scaling-webrtc-with-distributed-mesh/">Source</a>. Participants send to a central server,
rather than directly to each other.</p></figcaption></figure>
<p>The problem with SFUs is subtle: they’re custom.</p>
<p>It requires a lot of business logic to determine <em>where</em> to forward packets.
A single server like that diagram won’t scale, nor will all of the participants be located in the same geo.
Each SFU needs to be made aware of the network topology and the location of each participant <em>somehow</em>.</p>
<p>Additionally, a good SFU will avoid dropping packets based on dependencies, otherwise you waste bandwidth on undecodable packets.
Unfortunately, determining this requires parsing each RTP packet on a <em>per-codec</em> basis.
For example, here’s a <a href="https://webrtc.googlesource.com/src/+/refs/heads/main/modules/rtp_rtcp/source/video_rtp_depacketizer_h264.cc">h.264 depacketizer</a> for libwebrtc.</p>
<p>But the biggest issue at Twitch was that SFUs share very little in common with CDNs.
One team is optimizing WebRTC, another team is optimizing HTTP, and they’re not talking to each other.</p>
<p>This is why HLS/DASH uses HTTP instead: <strong>economies of scale</strong></p>
<h2 id="replacing-webrtc-1">Replacing WebRTC</h2>
<p>Okay enough ranting about what’s wrong, let’s fix it.</p>
<p>First off, <strong>WebRTC is not going anywhere</strong>. It does a fantastic job at what it was designed for: conferencing.
It will take a long time before anything will reach feature/latency parity with WebRTC.</p>
<p>Before you can replace <strong>Web</strong>RTC, you need <strong>Web</strong>Support.
Fortunately, we now have <strong>Web</strong>Codecs and <strong>Web</strong>Transport.</p>
<h2 id="webcodecs">WebCodecs</h2>
<p><a href="https://developer.mozilla.org/en-US/docs/Web/API/WebCodecs_API">WebCodecs</a> is a new API for encoding/decoding media in the browser.
It’s remarkably simple:</p>
<ol>
<li>Capture input via <a href="https://developer.mozilla.org/en-US/docs/Web/API/Canvas_API">canvas</a> or a <a href="https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getUserMedia">media device</a>.</li>
<li><a href="https://developer.mozilla.org/en-US/docs/Web/API/VideoEncoder">VideoEncoder</a>: Input raw frames, output encoded frames.</li>
<li>Transfer those frames somehow. (ex. <a href="#webtransport">WebTransport</a>)</li>
<li><a href="https://developer.mozilla.org/en-US/docs/Web/API/VideoDecoder">VideoDecoder</a>: Input encoded frames, output raw frames.</li>
<li>Render output via <a href="https://developer.mozilla.org/en-US/docs/Web/API/Canvas_API">canvas</a> or just marvel at the pixel data.</li>
</ol>
<p>The catch is that the application is responsible for all timing.
That means you need to choose when to render each frame via <a href="https://developer.mozilla.org/en-US/docs/Web/API/window/requestAnimationFrame">requestAnimationFrame</a>.
In fact, you need to choose when to render each audio <em>sample</em> via <a href="https://developer.mozilla.org/en-US/docs/Web/API/AudioWorklet">AudioWorklet</a>.</p>
<p>The upside is that now your web application gets full control of how to render media.
It’s now possible to implement WebRTC-like behavior, like temporarily freezing video and desyncing A/V.</p>
<p>Check <a href="https://caniuse.com/webcodecs">caniuse</a> for current browser support.</p>
<h2 id="webtransport">WebTransport</h2>
<p><a href="https://developer.mozilla.org/en-US/docs/Web/API/WebCodecs_API">WebTransport</a> is a new API for transmitting data over the network.
Think of it like WebSockets, but with a few key differences:</p>
<ul>
<li><a href="https://www.rfc-editor.org/rfc/rfc9000.html">QUIC</a> not TCP.</li>
<li><a href="https://developer.mozilla.org/en-US/docs/Web/API/WebTransport_API#reliable_transmission_via_streams">Reliable streams</a> that are delivered in order.</li>
<li><strong>Semi-reliable streams</strong> by closing a stream (with an error code) to drop the tail.</li>
<li><a href="https://developer.mozilla.org/en-US/docs/Web/API/WebTransport/datagrams">Unreliable datagrams</a> that may be dropped during congestion.</li>
</ul>
<p>QUIC has too many benefits to enumerate, but some highlights:</p>
<ul>
<li>Fully encrypted</li>
<li>Congestion controlled (even datagrams)</li>
<li>Independent streams (no head-of-line blocking)</li>
<li>1-RTT handshake</li>
<li>Multiplexed over a single UDP port</li>
<li>Transparent network migration (ex. switching from Wifi to LTE)</li>
<li>Used for HTTP/3</li>
</ul>
<p>That last one is surprisingly important: WebTransport will share all of the optimizations that HTTP/3 receives.
A HTTP/3 server can simultaneously serve multiple WebTransport sessions and HTTP requests over the same connection.</p>
<p>Check <a href="https://caniuse.com/webtransport">caniuse</a> for current browser support.
Use my <a href="https://docs.rs/webtransport-quinn/latest/webtransport_quinn/">Rust library</a> for servers and native clients!</p>
<h2 id="but-how">But how?</h2>
<p>Okay, so we have WebCodecs and WebTransport, but are they actually useful?</p>
<p>I alluded to the secret behind latency earlier: avoiding queues.
Queuing can occur at any point in the media pipeline.</p>















<table><thead><tr><th>Capture/Encode</th><th>Send/Receive</th><th>Decode/Render</th></tr></thead><tbody><tr><td>—&gt;</td><td>—&gt;</td><td>—&gt;</td></tr></tbody></table>
<p>Let’s start with the easy one.
<a href="#webcodecs">WebCodecs</a> allows you to avoid queuing almost entirely.</p>















<table><thead><tr><th>Capture/Encode</th><th>Send/Receive</th><th>Decode/Render</th></tr></thead><tbody><tr><td><strong>WebCodecs</strong></td><td>?</td><td><strong>WebCodecs</strong></td></tr></tbody></table>
<p>The tricky part is the bit in the middle, the network.
It’s not as simple as throwing your hands into the air and proclaiming “UDP has no queues!”</p>
<h3 id="the-internet-of-queues">The Internet of Queues</h3>
<p>The internet is a <a href="https://en.wikipedia.org/wiki/Series_of_tubes">series of tubes</a>.
You put packets in one end and they eventually come out of the other end, kinda.
This section will get an entire blog post in the future, but until then, let’s over-simplify things.</p>
<p>Every packet you send will fight with other packets on the internet.</p>
<ul>
<li>If routers have sufficient throughput, <strong>packets arrive on time</strong>.</li>
<li>If routers have limited throughput, <strong>packets will be queued</strong>.</li>
<li>If those queues are full, <strong>packets will be dropped</strong>.</li>
</ul>
<p>There can be random packet loss, but 99% of the time we care about loss due to queuing.
Note that even datagrams may be queued by the network; a firehose of packets is never the answer.</p>
<h3 id="detecting-queuing">Detecting Queuing</h3>
<p>The goal of congestion control is to detect queuing and back off.</p>
<p>Different congestion control algorithms use different signals to detect queuing.
This is a gross oversimplification of a topic with an immense amount of research, but here’s a rough breakdown:</p>



































<table><thead><tr><th>Signal</th><th>Description</th><th>Latency</th><th>Examples</th></tr></thead><tbody><tr><td>Packet Loss</td><td>Wait until the queue is full and packets are dropped.</td><td><a href="https://en.wikipedia.org/wiki/Bufferbloat">High</a></td><td><a href="https://en.wikipedia.org/wiki/TCP_congestion_control">Reno</a>, <a href="https://en.wikipedia.org/wiki/CUBIC_TCP">CUBIC</a></td></tr><tr><td>ACK Delay</td><td>Indirectly measure the queue size via ACK RTT.</td><td>Medium</td><td><a href="https://research.google/pubs/pub45646/">BBR</a>, <a href="https://web.mit.edu/copa/">COPA</a></td></tr><tr><td>Packet Delay</td><td>Indirectly measure the queue size via packet RTT.</td><td>Low</td><td><a href="https://datatracker.ietf.org/doc/html/draft-ietf-rmcat-gcc-02">GCC</a>, <a href="https://github.com/EricssonResearch/scream">SCReAM</a></td></tr><tr><td>ECN</td><td>Get told by the router to back off.</td><td>None*</td><td><a href="https://datatracker.ietf.org/doc/rfc9330/">L4S</a></td></tr></tbody></table>
<p>There’s no single “best” congestion control algorithm; it depends on your use-case, network, and target latency.
But this is one area where WebRTC has an advantage thanks to <a href="https://webrtc.googlesource.com/src/+/refs/heads/main/docs/native-code/rtp-hdrext/transport-wide-cc-02/README.md">transport-wide-cc</a>.</p>
<h3 id="reducing-bitrate">Reducing Bitrate</h3>
<p>Once you detect queuing, the application needs to send fewer bytes.</p>
<p>In some situations we can just reduce the encoder bitrate, however:</p>
<ul>
<li>This only applies to future frames.</li>
<li>We don’t want one viewer to degrade the experience for all.</li>
<li>It’s too expensive to encode on a per-viewer basis.</li>
</ul>
<p>So basically, we have to drop encoded media in response to congestion.</p>
<p>This is the fundamental problem with TCP.
Once you queue data on a TCP socket, it can’t be undone without closing the connection.
You can’t put the toothpaste back in the tube.</p>
<figure><p><img src="https://quic.video/blog/replacing-webrtc/toothpaste.jpg" alt="TCP toothpaste"></p><figcaption><p><a href="https://knowyourmeme.com/memes/shitting-toothpaste-pooping-toothpaste">Source</a>. You earned a meme for making it
this far.</p></figcaption></figure>
<p>However, there are actually quite a few ways of dropping media with <a href="#webtransport">WebTransport</a>:</p>
<ol>
<li>Use datagrams and choose which packets to transmit. (like WebRTC)</li>
<li>Use QUIC streams and close them to stop transmissions. (like <a href="https://www.ietf.org/archive/id/draft-kpugin-rush-00.html">RUSH</a>)</li>
<li>Use QUIC streams and prioritize them. (like <a href="https://www.youtube.com/watch?v=PncdrMPVaNc">Warp</a>)</li>
</ol>
<p>I’m biased because I made the 3rd one.
WebTransport’s <a href="https://www.w3.org/TR/webtransport/#dom-webtransportsendstreamoptions-sendorder">sendOrder</a> can be used to instruct the QUIC stack what should be sent during congestion.
But that deserves an entire blog post on its own.</p>
<h2 id="replacing-webrtc-2">Replacing WebRTC</h2>
<p>But to actually replace WebRTC, we need a standard. Anybody can make their own UDP-based protocol (<em>and they do</em>), using this new web tech (<em>and they will</em>).</p>
<p>What sets <a href="https://datatracker.ietf.org/wg/moq/about/">Media over QUIC</a> apart is that we’re doing it through the IETF, the same organization that standardized WebRTC… and virtually every internet protocol.</p>
<p>It’s going to take years.<br>
It’s going to take a lot of idiots like myself who want to replace WebRTC. <br>
It’s going to take a lot of companies who are willing to bet on a new standard.<br></p>
<p>And there are major flaws with both <strong>WebCodecs</strong> and <strong>WebTransport</strong> that still need to be addressed before we’ll ever reach WebRTC parity.
To name a few:</p>
<ul>
<li>We need better <a href="https://www.w3.org/TR/webtransport/#dom-webtransportoptions-congestioncontrol">congestion control</a> in browsers.</li>
<li>We need something like <a href="https://webrtc.googlesource.com/src/+/refs/heads/main/docs/native-code/rtp-hdrext/transport-wide-cc-02/README.md">transport-wide-cc</a> in QUIC: <a href="https://www.ietf.org/archive/id/draft-smith-quic-receive-ts-00.html">like this proposal</a></li>
<li>We need echo cancellation in <a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API">WebAudio</a>, which might be possible?</li>
<li>We may need <a href="https://en.wikipedia.org/wiki/Error_correction_code#Forward_error_correction">FEC</a> in QUIC: <a href="https://datatracker.ietf.org/doc/draft-michel-quic-fec/">like this proposal</a></li>
<li>We may need more encoding options, like non-reference frames or SVC.</li>
<li>Oh yeah and full browser support: <a href="https://caniuse.com/webcodecs">WebCodecs</a> - <a href="https://caniuse.com/webtransport">WebTransport</a></li>
</ul>
<h2 id="so-yeah">So yeah…</h2>
<p>Written by <a href="https://github.com/kixelated">@kixelated</a>.
Hit me up on <a href="https://discord.gg/FCYF3p99mr">Discord</a> if you want to help!</p>
<p>Tune in for next week’s episode: <strong>Replacing HLS/DASH</strong> and then <strong>Replacing RTMP</strong>.</p>
<img src="https://quic.video/blog/kixelCat.png"></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The costs of microservices (2020) (302 pts)]]></title>
            <link>https://robertovitillo.com/costs-of-microservices/</link>
            <guid>38069915</guid>
            <pubDate>Mon, 30 Oct 2023 14:33:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://robertovitillo.com/costs-of-microservices/">https://robertovitillo.com/costs-of-microservices/</a>, See on <a href="https://news.ycombinator.com/item?id=38069915">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><header><p>November 22, 2020</p></header><p>An application typically starts its life as a monolith. Take a modern backend of a single-page Javascript application, for example - it starts out as a single stateless web service that exposes a RESTful HTTP API and uses a relational database as a backing store. The service is composed of a number of components, or libraries, that implement different business capabilities:</p><p><span>
      <a href="https://robertovitillo.com/static/20b3d909b15d98f33bee31e8357203ce/024d6/monolith.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Monolith" title="Monolith" src="https://robertovitillo.com/static/20b3d909b15d98f33bee31e8357203ce/fcda8/monolith.png" srcset="https://robertovitillo.com/static/20b3d909b15d98f33bee31e8357203ce/12f09/monolith.png 148w,https://robertovitillo.com/static/20b3d909b15d98f33bee31e8357203ce/e4a3f/monolith.png 295w,https://robertovitillo.com/static/20b3d909b15d98f33bee31e8357203ce/fcda8/monolith.png 590w,https://robertovitillo.com/static/20b3d909b15d98f33bee31e8357203ce/efc66/monolith.png 885w,https://robertovitillo.com/static/20b3d909b15d98f33bee31e8357203ce/024d6/monolith.png 961w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p><p>As the number of feature teams contributing to the same codebase increases, its components become increasingly coupled over time. This leads the teams to step on each other’s toes more and more frequently, decreasing their productivity. </p><p>The codebase becomes complex enough that nobody fully understands every part of it, and implementing new features or fixing bugs becomes time-consuming. Even if the backend is componentized into different libraries owned by different teams, a change to a library requires the service to be redeployed. And if a change introduces a bug - like a memory leak - the entire service can potentially be affected by it. Additionally, rolling back a faulty build affects the velocity of all teams, not just the one that introduced the bug.</p><p>One way to mitigate the growing pains of a <em>monolithic</em> backend is to split it into a set of independently deployable services that communicate via APIs. The APIs decouple the services from each other by creating boundaries that are hard to violate, unlike the ones between components running in the same process: </p><p><span>
      <a href="https://robertovitillo.com/static/54b0da5dd791ad53ea771e66c73f5d67/dc61a/api_gw.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Microservices" title="Microservices" src="https://robertovitillo.com/static/54b0da5dd791ad53ea771e66c73f5d67/fcda8/api_gw.png" srcset="https://robertovitillo.com/static/54b0da5dd791ad53ea771e66c73f5d67/12f09/api_gw.png 148w,https://robertovitillo.com/static/54b0da5dd791ad53ea771e66c73f5d67/e4a3f/api_gw.png 295w,https://robertovitillo.com/static/54b0da5dd791ad53ea771e66c73f5d67/fcda8/api_gw.png 590w,https://robertovitillo.com/static/54b0da5dd791ad53ea771e66c73f5d67/efc66/api_gw.png 885w,https://robertovitillo.com/static/54b0da5dd791ad53ea771e66c73f5d67/dc61a/api_gw.png 1147w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p><p>This architectural style is also referred to as the microservice architecture. The term <em>micro</em> can be misleading, though - there doesn’t have to be anything micro about the services. In fact, I would argue that if a service doesn’t do much, it just creates more operational toll than benefits. A more appropriate name for this architecture is <a href="https://en.wikipedia.org/wiki/Service-oriented_architecture">service-oriented architecture</a>, but unfortunately, that name comes with some old baggage as well. Perhaps in 10 years, we will call the same concept with yet another name, but for now we will have to stick to microservices. </p><p>Breaking down the backend by business capabilities into a set of services with well-defined boundaries allows each service to be developed and operated by a single small team. The reduced team size increases the application’s development speed for a variety of reasons:</p><ul><li>Smaller teams are more effective as the communication overhead grows <a href="https://en.wikipedia.org/wiki/The_Mythical_Man-Month">quadratically</a> with the team’s size.</li><li>As each team dictates its own release schedule and has complete control over its codebase, less cross-team communication is required, and therefore decisions can be taken in less time.</li><li>The codebase of a service is smaller and easier to digest by its developers, reducing the time it takes to ramp up new hires. Also, a smaller codebase doesn’t slow down IDEs, which makes the developers more productive. </li><li>The boundaries between services are much stronger than the boundaries between components in the same process. Because of that, when a developer needs to change a part of the backend, they only need to understand a small part of the whole. </li><li>Each service can be scaled independently and adopt a different technology stack based on its own needs. The consumers of the APIs don’t care how the functionality is implemented after all. This makes it easy to experiment and evaluate new technologies without affecting other parts of the system.</li><li>Each microservice can have its own independent data model and data store(s) that best fit its use-cases, allowing developers to change its schema without affecting other services. </li></ul><h2 id="costs"><a href="#costs" aria-label="costs permalink"></a>Costs</h2><p>The microservices architecture adds more moving parts to the overall system, and this doesn’t come for free. The cost of fully embracing microservices is only worth paying if it can be amortized across dozens of development teams. </p><p><strong>Development Experience</strong></p><p>Nothing forbids the use of different languages, libraries, and datastores for each microservice - but doing so transforms the application into an unmaintainable mess. For example, it makes it more challenging for a developer to move from one team to another if the software stack is completely different. And think of the sheer number of libraries - one for each language adopted - that need to be supported to provide common functionality that all services need, like logging.</p><p>It’s only reasonable then that a certain degree of standardization is needed. One way to do that - while still allowing some degree of freedom - is to loosely encourage specific technologies by providing a great development experience for the teams that stick with the recommended portfolio of languages and technologies.</p><p><strong>Resource Provisioning</strong></p><p>To support a large number of independent services, it should be simple to spin up new servers, data stores, and other commodity resources - you don’t want every team to come up with their own way of doing it. And once these resources have been provisioned, they have to be configured. To be able to pull this off, you will need a fair amount of automation.</p><p><strong>Communication</strong></p><p>Remote calls are expensive and introduce <a href="https://robertovitillo.com/default-timeouts/">new and fun ways</a> your systems can crumble. You will need defense mechanisms to protect against failures, like timeouts, retries and circuit breakers. You will also have to leverage asynchrony and batching to mitigate the performance hit of communicating across the network. All of which increases the system’s complexity. A lot of what I describe in my <a href="https://understandingdistributed.systems/">book about distributed systems</a> is about dealing with this complexity. </p><p>That being said, even a monolith doesn’t live in isolation as it’s being accessed by remote clients, and it’s likely to use third-party APIs as well. So eventually, these issues need to be solved there as well, albeit on a smaller scale.</p><p><strong>Continuous Integration, Delivery, and Deployment</strong></p><p>Continuous integration ensures that code changes are merged into the main branch after an automated build and test processes have run. Once a code change has been merged, it should be automatically published and deployed to a production-like environment, where a battery of integration and end-to-end tests run to ensure that the microservice doesn’t break any service that depends on it.</p><p>While testing individual microservices is not more challenging than testing a monolith, testing the integration of all the microservices is an order of magnitude harder. Very subtle and unexpected behavior can emerge when individual services interact with each other. </p><p><strong>Operations</strong></p><p>Unlike with a monolith, it’s much more expensive to staff each team responsible for a service with its own operations team. As a result, the team that develops a service is typically also on-call for it. This creates friction between development work and operational toll as the team needs to decide what to prioritize during each sprint. </p><p>Debugging systems failures becomes more challenging as well - you can’t just load the whole application on your local machine and step through it with a debugger. The system has more ways to fail, as there are more moving parts. This is why good logging and monitoring becomes crucial at all levels.</p><p><strong>Eventual Consistency</strong></p><p>A side effect of splitting an application into separate services is that the data model no longer resides in a single data store. Atomically updating records stored in different data stores, and guaranteeing strong consistency, is slow, expensive, and hard to get right. Hence, this type of architecture usually requires embracing eventual consistency.</p><h2 id="practical-considerations"><a href="#practical-considerations" aria-label="practical considerations permalink"></a>Practical Considerations</h2><p>Splitting an application into services adds a lot of complexity to the overall system. Because of that, it’s generally best to start with a monolith and split it up only when there is a good reason to do so. </p><p>Getting the boundaries right between the services is challenging - it’s much easier to move them around within a monolith until you find a sweet spot. Once the monolith is well matured and growing pains start to rise, then you can start to peel off one microservice at a time from it. </p><p>You should only start with a microservice first approach if you already have experience with it, and you either have built out a platform for it or have accounted for the time it will take you to build one. </p><hr></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I accidentally saved my company half a million dollars (759 pts)]]></title>
            <link>https://ludic.mataroa.blog/blog/i-accidentally-saved-half-a-million-dollars/</link>
            <guid>38069710</guid>
            <pubDate>Mon, 30 Oct 2023 14:15:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ludic.mataroa.blog/blog/i-accidentally-saved-half-a-million-dollars/">https://ludic.mataroa.blog/blog/i-accidentally-saved-half-a-million-dollars/</a>, See on <a href="https://news.ycombinator.com/item?id=38069710">Hacker News</a></p>
<div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/BlogPosting">
        

        

        <div itemprop="articleBody">
            <p>I saved my company half a million dollars in about five minutes. This is more money than I've made for my employers over the course of my entire career because this industry is a sham. I clicked about five buttons.</p>
<p>Let's talk about why happened and why it's a disgrace that it was even possible.</p>
<h2 id="i-background">I. Background</h2>
<p>Let's start with some background, because it is fucking <em>wild</em> that an inefficiency that took me five minutes to solve in a GUI configuration panel was allowed to persist. We <em>cancelled someone's contract</em> the week before I did this. <em>Someone lost their job</em> because no one could get their act together long enough to click the button I told them to click.</p>
<p>A few years ago, this company decided that it wanted to create an analytics platform, following the decision to become more "data driven". They hired some incredibly talented people to make this happen, and then like five times as many idiots.</p>
<p>At the time this was happening, I had just graduated and joined the organization as a data scientist. We, of course, did not do any data science, because the organization did not require any data science to be done - what they actually needed to do was fire most of the staff in every team, leaving behind the two people who actually had good domain knowledge, then allow them to collaborate with good engineering teams to build sensible processes and systems. Instead, they hired a bunch of Big Firm Consultants. You can see where this is going already.</p>
<p>Nonetheless, at the time I was young and took the organization at its word. Executives would tell us constantly how excited they were for us to roll out new A.I initiatives (then tell us there was no time, so could we please get that report to them in a spreadsheet), and I'd ask for some sort of compute to <em>perform</em> some machine learning, or even set up data pipelines.</p>
<p>It never worked. Instead, we were told that we just had to wait for the Advanced Analytics Platform (AAP) to be deployed. You see, it's December, and it's launching in January.</p>
<p>Then in January I was told to be patient, it was coming in March.</p>
<p>In June, I was told it had been put on hold due to Covid - this was a very convenient excuse because they had absolutely fucked the whole project up already, but it bought some valuable time. By the next December, I had left the organization and the AAP was still nowhere to be seen.</p>
<p>We skip ahead three years. The AAP is finally ready to launch. It turns out none of the features I needed were ever planned, so I guess they were just lying to me before I left.</p>
<p>Four engineers leave the company in the same week, and I speak with the directors because I know they need a <em>real</em> engineer in and they can't find them. I'm a substantially less experienced engineer than many of the readers here, but suffice it to say that I can read documentation without panicking, which is considered S-tier in this country. My conditions - a big pile of money and they had to put me on the AAP team because they're the only team that gets actual toys to play with.</p>
<h2 id="ii-it-fucking-sucks">II. It Fucking Sucks</h2>
<p>It's an insane dumpster fire spiderweb of technical debt and it's only like one week old. Here are some fun details.</p>
<p>I get a friend of mine hired (big fan of nepotism), and he finds, <em>on day one</em>, a file in the project's repository that deletes prod using our CI/CD pipelines if it is ever moved into the wrong folder. It comes complete with the key and password required for an admin account. It was produced by the former lead engineer, who has moved on to a new role before his sins catch up with him.</p>
<p>The entire thing is stitched together by spreadsheets that are parsed by Python, dropped into S3, parsed by Lambdas into more S3, the S3 files are picked up by MongoDB, then MongoDB records are passed by another Lambda into S3, the S3 files are pulled into Snowflake via Snowpipe, the new Snowflake data is pivoted by a Javascript stored procedure into a relational format... and that's how you edit someone's database access. That whole process is to upload like a 2KB CSV to a database that has people's database roles in it.</p>
<p>This is considered <em>more auditable</em>.</p>
<p>Everything is transformed into a CSV because the security team demanded something that could undergo easy scanning for malicious content, then they never deployed the scanning tool, so we have all the downsides of the CSVs and none of the upsides.</p>
<p>Every Lambda function, the backbone of all the ETL pipelines, starts with <code>counter = 1</code> because one of the early iterations <em>used to use a counter</em> and people have just been copying that line over and over. <em>Senior data engineers</em> have been copying that line over and over.</p>
<p>The test suites in the CI/CD pipelines have been failing for months, because someone during debugging chose to use the Linux <code>tee</code> command to log any errors to both <code>stdout</code> and a file at the same time, but <code>tee</code> successfully executing was overwriting the error code from the failing tests.</p>
<p>To get access to the password for any API we need to hit, you search for something like <code>service-password</code> in an AWS service, which returns the value... <code>service-password</code> (as in, literally all the values are the same as the keys), then you use <em>that</em> to look up the actual password in a completely different service. No one knows why we do this.</p>
<p>The script that generates configuration files for our pipelines starts with 600 lines of comments, because senior engineers have been commenting the lines out in case they're needed later. The lines are just setting the same variables to different values, and they're all on GitHub anyway.</p>
<p>This is at an organization that some percentage of readers will recognize on sheer brand strength if they're in my country.</p>
<p>I'm not even getting started, but we have to stop for now because I am going to catch fire. These details are important because now you understand the kind of operational incompetence that allows you to waste so much money on processing &lt;1TB of data per day that it dwarfs your team's salary.</p>
<h2 id="iii-the-budget">III.  The Budget</h2>
<p>The next thing to realize is that this platform never really had a chance of making any money for the organization. They do a little accounting trick (read: lying) which I'll talk about in another post that makes it seem like they've had huge wins, but really this is just many times more expensive than our previous operational model.</p>
<p>The deal is that we pretend the whole team is doing something or other, and we stay within budget because the organization can't afford to spend infinite money on this social fiction. However, the budget for our database costs was being drastically overrun. I'm not sure what the original estimate was, but I think it was intended to cost something like 200K for a year of operations, but we were now close to a million dollars.</p>
<p>Some quick facts:</p>
<ol>
<li>We use Snowflake as our database, which charges you based on the size of the computer you use to run your queries.</li>
<li>You only pay for computers while they're on.</li>
<li>We probably run a few thousand queries per week, mostly developers experimenting with little tweaks for PowerBI reports that no one reads, and on average they take about 2 seconds to run.</li>
<li><strong>The computers are set to idle for 10 minutes after every query</strong>.</li>
</ol>
<p>I noticed this about a month into joining the team, and suggested we uh... don't have the computers run for like two orders of magnitude longer than they need to for every query. I literally can't remember what was said, there was some Agile bullshit about doing a discovery piece, then it just never happened.</p>
<h2 id="iv-just-doing-the-fucking-thing">IV. Just Doing The Fucking Thing</h2>
<p>Anyway, <em>months</em> later, they finally give me a card that says "Discovery: Optimise Costs". Now I <em>have</em> to optimize costs so that I have something to say at the next standup, and fortunately I know just the thing! I'll test my hypothesis that this is all a sick joke, and I'm going to push the button that I secretly think should obviously have been pushed.</p>
<p>We've got a new guy on another team who seems excellent, so I ask management if I can give him admin credentials since we need competent people. They say no. I flick him some lower-level database credentials that I <em>technically</em> wasn't told not to do since they aren't admin credentials, and he sanity-checks that it would save money. At 4PM on the last day of the week, I ping a chat full of good engineers and no managers to make sure I'm not about to nuke everything, then just do it.</p>
<h2 id="v-chaos-reigns">V.  Chaos Reigns</h2>
<p>I return to work the following Monday. I <em>suspected</em> that this would save a bunch of money, and guess what, our projected bill dropped from a million to half a million dollars, and everyone is losing their fucking minds.</p>
<p>My team has spun this as a huge cost saving, when <em>really</em> we just applied a fire extinguisher to the pile of money that we had set alight.</p>
<p>Other teams are attacking my team, insisting that it can't be a coincidence that the one new guy joined exactly as we did this, and how was it possible we didn't know how to generate that kind of saving without his help? They are saying this because it makes them seem higher status and their teams only produce money in the land where you lie all day, but it <em>is</em> a fair question.</p>
<p>While my managers are very happy, they quietly suggest it may be unwise to roll out the changes to all the computers (I only did a few to be safe) because it would oversaturate the department to hear about us all day. And invite unwelcome questions. The subtext is that if we do this all slowly enough, it might seem like it took a lot of effort instead of just clicking buttons that I said had to be clicked almost a year ago.</p>
<p>I am asked to write some PowerPoints, which include phrases like "a careful statistical analysis of user usage patterns indicated an opportunity to more effectively allocate resources", implying that nothing was <em>wrong</em>, we just needed to collect more data before deciding not to let the expensive machines idle all day.</p>
<p>Every day, I dread someone asking me to explain what the change was, because I will have to fucking <em>yeet</em> some managers I like under a bus, but they can't resist talking about the change non-stop because it is the closest some of them will ever get to impacting the bottom line. And <em>many of them are actually decent managers</em>, it's just that this whole department, like many departments, is some sort of weird political PsyOp to get executives promoted. It's <em>cosplaying as a real business</em> and the board thinks the costume is convincing. </p>
<h2 id="vi-the-aftermaths-and-takeaways">VI. The Aftermaths and Takeaways</h2>
<p>By identifying a handful of good engineers and going totally rogue, we outperformed the entire department pretty effortlessly. The competent people are there, just made totally impotent by the organization, and I'm still convinced that this place is probably better than the median organization.</p>
<p>I ask management for a 30K raise after saving 500K and my message is still unread. I suspect I will eventually receive either nothing or 5K.</p>
<p>I have even more meetings now because everyone wants to talk about how we saved the money. I had to make a PowerPoint. Kill me.</p>
<p>I would have been better off <em>not doing anything</em>. Let that be a lesson to you. Do you hear me? I applied myself for <em>five minutes</em> against my own better judgement, had the greatest success of my career, and have immediately been punished for it. <em>Learn from my mistakes, I beg of you.</em></p>
        </div>
    </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[eBPF-based auto-instrumentation outperforms manual instrumentation (172 pts)]]></title>
            <link>https://odigos.io/blog/ebpf-instrumentation-faster-than-manual</link>
            <guid>38069659</guid>
            <pubDate>Mon, 30 Oct 2023 14:10:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://odigos.io/blog/ebpf-instrumentation-faster-than-manual">https://odigos.io/blog/ebpf-instrumentation-faster-than-manual</a>, See on <a href="https://news.ycombinator.com/item?id=38069659">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>We're developing Odigos, an open-source project for effortless distributed tracing. See more at <a href="https://github.com/keyval-dev/odigos">https://github.com/keyval-dev/odigos</a>.</p>
<p>Distributed tracing tracks the journey of requests as they move through a distributed system, offering insights for debugging, performance optimization, and end-to-end visibility. It is crucial for gaining in-depth insights into request flows within complex distributed systems.</p>
<p>However, there are two ways in which it can suck: extensive code changes (requires manual instrumentation), and a significant performance impact.</p>
<p>Odigos addresses the code change challenge by using eBPF for automating tracing without any manual effort or code changes. We generate traces in OpenTelemetry format, ensuring compatibility and avoiding vendor lock-in. You can read more <a href="https://news.ycombinator.com/item?id=34442603">here</a></p>
<p>That leaves the performance issues, which we’ve been working on. Our performance tests, which we’ll go into below, show that eBPF-based automatic instrumentation is over 20x faster than manually instrumenting code. This is achieved by separating data recording and data processing, eliminating extra workload, object allocation, and network calls during application runtime.</p>
<p>As a result, you can have the best of both worlds: automated distributed tracing with minimal performance overhead.</p>
<h2>How we tested</h2>
<p>Benchmarking latency is not a trivial task. Latency can be measured in many different ways, each with its own advantages and disadvantages. Our testing is inspired by this excellent talk by Gil Tene called <a href="https://www.youtube.com/watch?v=lJ8ydIuPFeU">How NOT to Measure Latency</a>. We are using a <a href="http://hdrhistogram.org/">High Dynamic Range Histogram</a> to visualize the results and <a href="https://github.com/giltene/wrk2">wrk2</a> to generate load.</p>
<p>In order to reduce noise as much as possible, we are running each test on a dedicated AWS bare metal instance (c5n.metal) with Intel Xeon Platinum 8000 series (Skylake-SP) processor.</p>
<p>For the target application, we are using a simple Go HTTP server written in Go 1.21 that returns a simple JSON response.</p>
<h2>Test results</h2>
<p>Each test is run for 5 minutes and generates 10,000 requests per second.
First, we ran the test without any instrumentation. Then we ran the test with manual instrumentation using <a href="https://github.com/open-telemetry/opentelemetry-go">OpenTelemetry Go SDK</a> and finally, we ran the test with <a href="https://github.com/open-telemetry/opentelemetry-go-instrumentation">eBPF-based automatic instrumentation</a>.</p>
<p><img src="https://odigos.io/images/blog/ebpf-vs-manual/results.png" alt="Test Results"></p>
<p>At the lower percentiles (up to the 99.9th percentile), the overhead of not having instrumentation, manual instrumentation, and eBPF-based automatic instrumentation is similar</p>
<p>However, at the higher percentiles (99.9th percentile and above), manual instrumentation has a significantly higher overhead than eBPF-based automatic instrumentation, which is over 20x faster.</p>
<p>If you're wondering whether the top of the spectrum matters, the answer is yes, especially in distributed environments. The following table shows how many clients will experience the 99th percentile latency according to the number of different services involved in the request (taken from Gil's talk)</p>
<p><img src="https://odigos.io/images/blog/ebpf-vs-manual/p99_is_a_lie.png" alt="p99 is a lie"></p>
<p>For maximum precision and isolation, we are generating traces containing a single span. In a production environment, we anticipate the performance difference to be even greater.</p>
<h2><strong>The performance impact of generating distributed traces</strong></h2>
<p>Let's see what happens inside our application when we generate distributed traces, either manually via SDKs or automatically via something like a Java agent or monkey patching:</p>
<ol>
<li><strong>Recording data</strong> - Spans objects that contain the relevant data are being created</li>
<li><strong>Maintaining a queue of data</strong> - Spans are being batched in a queue before being sent to the external system</li>
<li><strong>Delivering data to the external system</strong> - The application sends the data in the queue to the external system by making network calls, serializing the data, and sending it over the network.</li>
</ol>
<p>Another consideration to keep in mind is that the application runtime must now manage more objects, which can negatively impact heap size and GC performance, especially in languages with stop-the-world GC like Java. All this can lead to longer GC pauses and decreased performance. We'll dive deeper and explore this topic in a separate blog post. Stay tuned.</p>
<p>Unlike metrics and logs, distributed tracing is a stateful signal. Logs are typically written to a file, and metrics are typically pulled from an HTTP endpoint by the monitoring system (for example <code>/metrics</code> endpoint when exposing Prometheus metrics). Distributed tracing is different. It requires the application to actively send batched data to an external system.</p>
<h2>Separation between recording and processing</h2>
<p>When using eBPF to generate distributed traces, we are separating the recording of the data from the processing of the data. The recording of the data is done by the eBPF program and the processing and delivery of the data is done by a different process. This means that the application runtime does no additional work, creates no additional objects, and makes no additional network calls. The only additional overhead (compared to not having any instrumentation) is the overhead of invoking eBPF programs (context switching from user space to kernel space).</p>
<h2>Conclusion</h2>
<p>Traditionally, there has been a tradeoff between automated distributed tracing and performance.</p>
<p>Odigos solves this problem by providing a way to automate distributed tracing that actually improves performance. This is because we use eBPF-based automatic instrumentation to  reduce the overhead of generating distributed tracing data.</p>
<p><strong>As a result, you can now have the best of both worlds: automated distributed tracing without any performance overhead</strong>.</p>
<h2>More updates coming soon</h2>
<p>eBPF-based automatic instrumentation is a game-changer, enabling us to generate distributed traces <strong>without code changes</strong> or <strong>performance impact</strong>. We're just getting started and will bring this to more programming languages soon. Stay tuned!</p>
<h2>Try it out</h2>
<p>The easiest way to try eBPF-based distributed tracing today is to use our <a href="https://github.com/keyval-dev/odigos">open-source project, Odigos</a>. Please support us by starring ⭐ the project on <a href="https://github.com/keyval-dev/odigos">GitHub</a>.</p>
</div><p>If you want to learn more about how you can generate distributed traces instantly check out our GitHub repository. We'd really appreciate it if you could throw us a ⭐👇<br><a target="_blank" href="https://github.com/keyval-dev/odigos">https://github.com/keyval-dev/odigos</a></p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Private equity is devouring the U.S. economy (301 pts)]]></title>
            <link>https://www.theatlantic.com/ideas/archive/2023/10/private-equity-publicly-traded-companies/675788/</link>
            <guid>38069197</guid>
            <pubDate>Mon, 30 Oct 2023 13:25:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theatlantic.com/ideas/archive/2023/10/private-equity-publicly-traded-companies/675788/">https://www.theatlantic.com/ideas/archive/2023/10/private-equity-publicly-traded-companies/675788/</a>, See on <a href="https://news.ycombinator.com/item?id=38069197">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><header data-event-module="hero"><div><div><p>Private equity has made one-fifth of the market effectively invisible to investors, the media, and regulators.</p></div><div><figure><div><picture><source media="(prefers-reduced-motion)" srcset="https://cdn.theatlantic.com/thumbor/KqAoGR-ALX6d3-jBGpkilpaU03I=/1x0:965x542/750x422/filters:still()/media/img/mt/2023/10/StockMarketPoof/original.gif 750w, https://cdn.theatlantic.com/thumbor/Q5D6I_yQHCbAUkh-3rYKLBMBRZE=/1x0:965x542/828x466/filters:still()/media/img/mt/2023/10/StockMarketPoof/original.gif 828w, https://cdn.theatlantic.com/thumbor/XEuPcHpzWO4gGxZIDfEDeJhbvmI=/1x0:965x542/960x540/filters:still()/media/img/mt/2023/10/StockMarketPoof/original.gif 960w" sizes="(min-width: 976px) 976px, 100vw"><img alt="A photo illustration of the Wall Street bull disappearing in a white cloud" sizes="(min-width: 976px) 976px, 100vw" srcset="https://cdn.theatlantic.com/thumbor/ceBGZTUB0XWRyhFxoU7FR-BVOgU=/1x0:965x542/750x422/media/img/mt/2023/10/StockMarketPoof/original.gif 750w, https://cdn.theatlantic.com/thumbor/u5YnhlXBkjIweWXPNFR2mvu0dOM=/1x0:965x542/828x466/media/img/mt/2023/10/StockMarketPoof/original.gif 828w, https://cdn.theatlantic.com/thumbor/j46ndE6sj1BBs3_vsXowNBwva5A=/1x0:965x542/960x540/media/img/mt/2023/10/StockMarketPoof/original.gif 960w" src="https://cdn.theatlantic.com/thumbor/j46ndE6sj1BBs3_vsXowNBwva5A=/1x0:965x542/960x540/media/img/mt/2023/10/StockMarketPoof/original.gif" width="960" height="540"></picture></div><figcaption>Illustration by The Atlantic. Sources: Shutterstock; Getty.</figcaption></figure></div></div><div><p><time datetime="2023-10-30T11:30:00Z">October 30, 2023, 7:30 AM ET</time></p></div><gpt-ad format="injector" sizes-at-0="mobile-wide" targeting-pos="injector-article-start" sizes-at-976="desktop-wide"></gpt-ad></header><section data-event-module="article body"><p><em><small>Updated at 9:30 a.m. ET on October 30, 2023</small></em></p><p>T<span>he publicly traded company </span>is disappearing. In 1996, about 8,000 firms were listed in the U.S. stock market. Since then, the national economy has grown by nearly $20 trillion. The population has increased by 70 million people. And yet, today, the number of American public companies stands at <a data-event-element="inline link" href="https://www.cnn.com/2023/06/09/investing/premarket-stocks-trading/index.html">fewer than 4,000</a>. How can that be?</p><p>One answer is that the private-equity industry is devouring them. When a private-equity fund buys a publicly traded company, it takes the company private—hence the name. (If the company has not yet gone public, the acquisition keeps that from happening.) This gives the fund total control, which in theory allows it to find ways to boost profits so that it can sell the company for a big payday a few years later. In practice, going private can have more troubling consequences. The thing about public companies is that they’re, well, public. By law, they have to disclose information about their finances, operations, business risks, and legal liabilities. Taking a company private exempts it from those requirements.</p><p>That may not have been such a big deal when private equity was a niche industry. Today, however, it’s anything but. In 2000, private-equity firms managed about 4 percent of total U.S. corporate equity. By 2021, that number was closer to 20 percent. In other words, private equity has been growing nearly five times faster than the U.S. economy as a whole.</p><p id="injected-recirculation-link-0" data-view-action="view link - injected link - item 1" data-event-element="injected link" data-event-position="1"><a href="https://www.theatlantic.com/ideas/archive/2022/12/stock-market-inflation-interest-rates-recession/672612/">James Surowiecki: The method in the market’s madness</a></p><p>Elisabeth de Fontenay, a law professor at Duke University who studies corporate finance, told me that if current trends continue, “we could end up with a completely opaque economy.”</p><p>This should alarm you even if you’ve never bought a stock in your life. One-fifth of the market has been made effectively invisible to investors, the media, and regulators. Information as basic as who actually owns a company, how it makes its money, or whether it is profitable is “disappearing indefinitely into private equity darkness,” as the Harvard Law professor John Coates writes in his book <a data-event-element="inline link" href="https://tertulia.com/book/the-problem-of-twelve-when-a-few-financial-institutions-control-everything-john-coates/9798987053546?affiliate_id=atl-347"><em>The Problem of Twelve</em></a>. This is not a recipe for corporate responsibility or economic stability. A private economy is one in which companies can more easily get away with wrongdoing and an economic crisis can take everyone by surprise. And to a startling degree, a private economy is what we already have.</p><p>A<span>merica learned </span>the hard way what happens when corporations operate in the dark. Before the Great Depression, the whole U.S. economy functioned sort of like the crypto market in 2021. Companies could raise however much money they wanted from whomever they wanted. They could claim almost anything about their finances or business model. Investors often had no good way of knowing whether they were being defrauded, let alone whether to expect a good return.</p><p>Then came the worst economic crisis in U.S. history. From October to December of 1929, the stock market lost 50 percent of its value, with more losses to come. Thousands of banks collapsed, wiping out the savings of millions of Americans. Unemployment spiked to 25 percent. The Great Depression generated a crisis of confidence for American capitalism. Public hearings revealed just how rampant corporate fraud had become before the crash. In response, Congress passed the Securities Act of 1933 and the Securities Exchange Act of 1934. These laws launched a regime of “full and fair disclosure” and created a new government agency, the Securities and Exchange Commission, to enforce it. Now if companies wanted to raise money from the public, they would have to disclose a wide array of information to the public. This would include basic details about the company’s operations and finances, plus a comprehensive list of major risks facing the company, plans for complying with current and future regulations, and documentation of outstanding legal liabilities. All of these disclosures would be reviewed for accuracy by the SEC.</p><p>This regime created a new social contract for American capitalism: scale in exchange for transparency. Private companies were limited to 100 investors, putting a hard limit on how quickly they could grow. Any business that wanted to raise serious capital from the public had to submit itself to the new reporting laws. Over the next half century, this disclosure regime would underwrite the longest period of economic growth and prosperity in U.S. history. But it didn’t last. Beginning in the “Greed Is Good” 1980s, a wave of deregulatory reforms made it easier for private companies to raise capital. Most important was the National Securities Markets Improvement Act of 1996, which allowed private funds to raise an unlimited amount of money from an unlimited number of institutional investors. The law created a loophole that effectively broke the scale-for-transparency bargain. Tellingly, 1997 was the year the <a data-event-element="inline link" href="https://www.federalreserve.gov/econres/notes/feds-notes/the-post-covid-stock-listing-boom-20220617.html">number</a> of public companies in America peaked.</p><p id="injected-recirculation-link-1" data-view-action="view link - injected link - item 2" data-event-element="injected link" data-event-position="2"><a href="https://www.theatlantic.com/magazine/archive/2018/11/private-inequity/570808/">From the November 2018 issue: The death of the IPO</a></p><p>“Suddenly, private companies could raise all the money they want without even thinking about an IPO,” De Fontenay said. “That completely undermined the incentives companies had to go public.” Indeed, from 1980 to 2000, an average of 310 companies went public every year; from 2001 to 2022, only 118 did. The number briefly shot up during the coronavirus pandemic but has since fallen. (Over the same time period, the rate of mergers and acquisitions <a data-event-element="inline link" href="https://www.theatlantic.com/business/archive/2016/01/2015-mergers-acquisitions/423096/">soared</a>, which also helps explain the decline in public companies.)</p><p>Meanwhile, private equity has matured into a multitrillion-dollar industry, devoted to making short-term profits from highly leveraged transactions, operating with almost no regulatory or public scrutiny. Not all private-equity deals end in calamity, of course, and not all public companies are paragons of civic virtue. But the secrecy in which private-equity firms operate emboldens them to act more recklessly—and makes it much harder to hold them accountable when they do. Private-equity investment in nursing homes, to take just one example, <a data-event-element="inline link" href="https://www.ineteconomics.org/uploads/papers/WP_118-Appelbaum-and-Batt-2-rb-Clean.pdf">has grown</a> from about $5 billion at the turn of the century to more than $100 billion today. The results have not been pretty. The industry seems to have recognized that it could improve profit margins by cutting back on staffing while relying more on psychoactive medication. Stories abound of patients being <a data-event-element="inline link" href="https://www.washingtonpost.com/business/economy/opioid-overdoses-bedsores-and-broken-bones-what-happened-when-a-private-equity-firm-sought-profits-in-caring-for-societys-most-vulnerable/2018/11/25/09089a4a-ed14-11e8-baac-2a674e91502b_story.html">rushed</a> to the hospital after being overprescribed opioids, of bedside call buttons so <a data-event-element="inline link" href="https://www.newyorker.com/news/dispatch/when-private-equity-takes-over-a-nursing-home">poorly attended</a> that residents suffer in silence while waiting for help, of nurses being <a data-event-element="inline link" href="https://time.com/5843893/nursing-homes-workers-coronavirus/">pressured</a> to work while sick with COVID. A 2021 study <a data-event-element="inline link" href="https://www.nber.org/digest/202104/how-patients-fare-when-private-equity-funds-acquire-nursing-homes">concluded</a> that private-equity ownership was associated with about 22,500 premature nursing-home deaths from 2005 to 2017—<em>before</em> the wave of death and misery wrought by the pandemic.</p><p>Eventually, the public got wind of what was happening. The pandemic death count focused attention on the industry. Journalists and watchdog groups exposed the worst of the behaviors. Policy makers and regulators, at long last, began to take action. But by then, much of the damage had been done. “If we had some form of disclosure, we probably would have seen regulatory action a decade earlier,” Coates told me. “But instead, we’ve had 10-plus years of experimentation and abuse without anyone knowing.”</p><p>Something similar could be said about any number of industries, including <a data-event-element="inline link" href="https://www.nber.org/papers/w24976">higher education</a>, <a data-event-element="inline link" href="https://www.theatlantic.com/magazine/archive/2021/11/alden-global-capital-killing-americas-newspapers/620171/">newspapers</a>, <a data-event-element="inline link" href="https://www.theatlantic.com/magazine/archive/2018/07/toys-r-us-bankruptcy-private-equity/561758/">retail</a>, and <a data-event-element="inline link" href="https://www.theatlantic.com/ideas/archive/2020/02/how-private-equity-ruined-fairway/606625/">grocery stores</a>. Across the economy, private-equity firms are known for laying off workers, evading regulations, reducing the quality of services, and <a data-event-element="inline link" href="https://www.theatlantic.com/ideas/archive/2023/05/private-equity-firms-bankruptcies-plunder-book/673896/">bankrupting companies</a> while ensuring that their own partners are paid handsomely. The veil of secrecy makes all of this easier to execute and harder to stop.</p><p>Private-equity funds dispute many of the criticisms of the industry. They argue that the horror stories are exaggerated and that a handful of problematic firms shouldn’t tarnish the rest of the industry, which is doing great work. Freed from onerous disclosure requirements, they claim, private companies can build more dynamic, flexible businesses that generate greater returns for shareholders. But the lack of public information makes verifying these claims difficult. <a data-event-element="inline link" href="https://www.hbs.edu/ris/Publication%20Files/ReplicatingPE_201512_3859877f-bd53-4d3e-99aa-6daec2a3a2d3.pdf">Most</a> <a data-event-element="inline link" href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=473341">careful</a> <a data-event-element="inline link" href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2597259">academic</a> <a data-event-element="inline link" href="https://www.jstor.org/stable/30225708">studies</a> find that although private-equity funds slightly outperformed the stock market on average prior to the early 2000s, they no longer do so. When you take into account their high fees, they appear to be a worse investment than a simple index fund.</p><p>“These companies basically get to write their own stories,” says Alyssa Giachino, the research director at the Private Equity Stakeholder Project. “They produce their own reports. They come up with their own numbers. And there’s no one making sure they are telling the truth.”</p><p>I<span>n the Roaring ’20s,</span> the lack of corporate disclosure allowed a massive financial crisis to build up without anyone noticing. A century later, the growth of a new shadow economy could pose similar risks.</p><p>The hallmark of a private-equity deal is the so-called leveraged buyout. Funds take on massive amounts of debt to buy companies, with the goal of reselling in a few years at a profit. If all of that debt becomes hard to pay back—because of, say, an economic downturn or rising interest rates—a wave of defaults could ripple through the financial system. In fact, this has happened before: The original leveraged buyout mania of the 1980s <a data-event-element="inline link" href="https://www.latimes.com/archives/la-xpm-1989-10-29-op-140-story.html">helped spark</a> the 1989 stock-market crash. Since then, private equity has grown into a $12 trillion industry and has begun raising much of its money from unregulated, nonbank lenders, many of which are owned by the same private-equity funds taking out loans in the first place.</p><p>Meanwhile, interest rates have reached a 20-year high, posing <a data-event-element="inline link" href="https://www.wsj.com/articles/private-equity-exits-sink-to-one-of-lowest-points-in-over-a-decade-86b684b6">a direct threat</a> to private equity’s debt-heavy business model. In response, many private-equity funds have migrated toward even <a data-event-element="inline link" href="https://www.bloomberg.com/news/articles/2023-09-26/private-equity-is-piling-debt-on-itself-like-never-before?sref=BGQFqz7X">riskier forms</a> of backroom financing. Many of these involve taking on even more debt on <a data-event-element="inline link" href="https://www.ft.com/content/afc90e17-253d-49a7-bc39-dc5fbe31e648">the assumption</a> that market conditions will soon improve enough to restore profitability. If that doesn’t happen—and many of these big deals fail—the implications could be massive.</p><p id="injected-recirculation-link-2" data-view-action="view link - injected link - item 3" data-event-element="injected link" data-event-position="3"><a href="https://www.theatlantic.com/ideas/archive/2023/10/private-equity-hospitals-health-care/675779">Joe Nocera and Bethany McLean: What financial engineering does to hospitals</a></p><p>The industry counters that private markets are a better place for risky deals precisely because they have fewer ties to the real economy. A traditional bank has a bunch of ordinary depositors, whereas if a private-equity firm goes bust, the losers are institutional investors: pension funds, university endowments, wealthy fund managers. Bad, but not catastrophic. The problem, once again, is that no one knows how true that story is. Banks have to disclose information to regulators about how much they’re lending, how much capital they’re holding, and how their loans are performing. Private lenders sidestep all of that, meaning that regulators can’t know what risks exist in the system or <a data-event-element="inline link" href="https://www.reuters.com/business/finance/blackstones-first-quarter-earnings-plunge-real-estate-slowdown-2023-04-20/">how tied they are</a> to the real economy.</p><p>“Everything could be just fine,” says Ana Arsov, a managing director at Moody’s Investors Service who leads research on private lending. “But the point is that we don’t have the information we need to assess risk. Who is making these loans? How big are they? What are the terms? We just don’t know. So the worry is that the leverage in the system might grow and grow and grow without anyone noticing. And we really don’t know what the effects could be if something goes wrong.”</p><p>The government appears to be at least somewhat <a data-event-element="inline link" href="https://www.fdic.gov/news/speeches/2023/spsept2023.html#:~:text=According%20to%20the%20findings%20of,to%20their%20reliance%20on%20leverage">aware</a> of this problem. In August, the SEC <a data-event-element="inline link" href="https://www.sec.gov/news/statement/crenshaw-statement-private-fund-advisers-082323">proposed</a> a new rule requiring private-equity fund advisers to give more information to their investors. That’s better than nothing, but it hardly addresses the bad behavior or systemic risk. Nearly a century ago, Congress concluded that the nation’s economic system could not survive as long as its most powerful companies were left to operate in the shadows. It took the worst economic cataclysm in American history to learn that lesson. The question now is what it will take to learn it again.</p><hr><p><em><small>This article originally stated that Ana Arsov works for Moody's Analytics. In fact, she works for Moody's Investors Service. </small></em></p></section><gpt-ad format="injector" sizes-at-0="mobile-wide,native,house" targeting-pos="injector-most-popular" sizes-at-976="desktop-wide,native,house"></gpt-ad></article></div>]]></description>
        </item>
    </channel>
</rss>