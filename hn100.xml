<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 29 Nov 2023 04:00:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[My $500M Mars Rover Mistake: A Failure Story (381 pts)]]></title>
            <link>https://www.chrislewicki.com/articles/failurestory</link>
            <guid>38452959</guid>
            <pubDate>Tue, 28 Nov 2023 23:16:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.chrislewicki.com/articles/failurestory">https://www.chrislewicki.com/articles/failurestory</a>, See on <a href="https://news.ycombinator.com/item?id=38452959">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page" role="main">
        
          
<article id="sections" data-page-sections="62b2392057e74737ba8faefc">
  
  
    
    


  


<div data-content-field="main-content" data-item-id="" data-test="page-section" data-section-theme="white" data-section-id="62b2392057e74737ba8faf00" data-controller="SectionWrapperController" data-current-styles="{
&quot;imageOverlayOpacity&quot;: 0.15,
&quot;backgroundWidth&quot;: &quot;background-width--full-bleed&quot;,
&quot;sectionHeight&quot;: &quot;section-height--medium&quot;,
&quot;horizontalAlignment&quot;: &quot;horizontal-alignment--center&quot;,
&quot;verticalAlignment&quot;: &quot;vertical-alignment--middle&quot;,
&quot;contentWidth&quot;: &quot;content-width--medium&quot;,
&quot;sectionTheme&quot;: &quot;white&quot;,
&quot;sectionAnimation&quot;: &quot;none&quot;,
&quot;backgroundMode&quot;: &quot;image&quot;
}" data-current-context="{
&quot;video&quot;: {
&quot;playbackSpeed&quot;: 0.5,
&quot;filter&quot;: 1,
&quot;filterStrength&quot;: 0,
&quot;zoom&quot;: 0,
&quot;videoSourceProvider&quot;: &quot;none&quot;
},
&quot;backgroundImageId&quot;: null,
&quot;backgroundMediaEffect&quot;: null,
&quot;divider&quot;: null,
&quot;typeName&quot;: &quot;blog-basic-grid&quot;
}" data-animation="none">
  <article id="article-">
  
    <div data-layout-label="Post Body" data-type="item" id="item-6565180d3608ec2faec0972d"><div data-block-type="2" id="block-810346804fffcc24150a">
  <p>Some mistakes feel worse than death.&nbsp;</p><p>A February evening in 2003 started out routine at NASA’s Jet Propulsion Laboratory (JPL) in Pasadena, CA. I gowned up in cleanroom garb and passed into the High Bay 1 airlock in Building 179 where nearly all of NASA’s historic interplanetary spacecraft have been built since the Moon-bound Ranger series in the 1960s. After years of work by thousands of engineers, technicians, and scientists, there were only two weeks remaining before the Spirit Mars Rover would be transported to Cape Canaveral in Florida for launch ahead of its sibling, Opportunity.&nbsp;</p>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1701130954238_9567">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/629bbf78894a462d58b8002f/83ca1e56-d697-4726-9494-a1ec48116784/Failure+Story+Social+Image.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/629bbf78894a462d58b8002f/83ca1e56-d697-4726-9494-a1ec48116784/Failure+Story+Social+Image.jpeg" data-image-dimensions="1024x1024" data-image-focal-point="0.5,0.5" alt="" data-load="false" src="https://images.squarespace-cdn.com/content/v1/629bbf78894a462d58b8002f/83ca1e56-d697-4726-9494-a1ec48116784/Failure+Story+Social+Image.jpeg" width="1024" height="1024" sizes="100vw" srcset="https://images.squarespace-cdn.com/content/v1/629bbf78894a462d58b8002f/83ca1e56-d697-4726-9494-a1ec48116784/Failure+Story+Social+Image.jpeg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/629bbf78894a462d58b8002f/83ca1e56-d697-4726-9494-a1ec48116784/Failure+Story+Social+Image.jpeg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/629bbf78894a462d58b8002f/83ca1e56-d697-4726-9494-a1ec48116784/Failure+Story+Social+Image.jpeg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/629bbf78894a462d58b8002f/83ca1e56-d697-4726-9494-a1ec48116784/Failure+Story+Social+Image.jpeg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/629bbf78894a462d58b8002f/83ca1e56-d697-4726-9494-a1ec48116784/Failure+Story+Social+Image.jpeg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/629bbf78894a462d58b8002f/83ca1e56-d697-4726-9494-a1ec48116784/Failure+Story+Social+Image.jpeg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/629bbf78894a462d58b8002f/83ca1e56-d697-4726-9494-a1ec48116784/Failure+Story+Social+Image.jpeg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

                
            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="2" id="block-yui_3_17_2_1_1701130954238_12057">
  <p>I was into my unofficial second shift having already logged 12 hours that Wednesday. Long workdays are a nominal scenario for the assembly and test phase. Every system of a spacecraft is thoroughly tested and confirmed to be in perfect working order before it is buttoned up for the last time on Earth. Spirit and Opportunity, part of a now-historic twin mission, were among the most complex spacecraft ever built at that time and represented nearly a billion dollars invested by NASA. No pressure.&nbsp;</p><p>The rovers, between them, had 62 brushed-type motors to drive and steer the wheels, control the robotic arm, aim the cameras, point the antenna to Earth, and the various robotic origami unfolding and deployments following landing. The rover had undergone extensive testing to simulate the harsh conditions it would face on Mars as a field geologist. Especially critical are events involving pyrotechnics, as the explosive shockwaves can damage brittle carbon components inside these motors. That night, while my colleagues focused on testing the rover itself, I was tasked with verifying the integrity of the motors in the Rock Abrasion Tool (RAT) attached to the end of Spirit’s robotic arm.</p>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1701124110678_3080">

      

      
        <figure>
          
        
        

        
          
            
          
        

        
          
          <figcaption>
            <p><strong><em>Spirit (left), Opportunity (right) and Marie Curie (flight spare to Sojourner rover), Monday Feb 10, 2003. PIA04422 Courtesy NASA/JPL-Caltech</em></strong></p>
          </figcaption>
        
      
        </figure>
      

    </div><div data-block-type="2" id="block-yui_3_17_2_1_1701124110678_4439">
  <p>Disassembling and inspecting motor components after each round of environmental testing is not practical. However, we can check their internal condition by examining their electrical performance. To do this, using a device called a break-out-box, we disconnect the motor from the spacecraft and hook it up to an external power supply and strip chart recorder. A functioning motor will show a smooth, exponential decrease in electrical current during spin-up, while any problems show up as blips in the signal.</p><p>It was a test I had performed numerous times. My various roles on the project had given me the experience to decipher the maze of diagrams mapping the 10,000 pin-to-pin connections that made everything on the spacecraft work, and my responsibility in writing the instructions on how to connect and control all the motors on the rovers made me the obvious choice for this test campaign.</p><p>Inside the cleanroom, John, the electrical chief in charge there, helped me find the equipment I needed. Then Mary, our cabling expert, did the careful work of unplugging connectors and inserting test equipment on the interface I asked for. We ran our pre-test confirmation routine. The connection interface was operational, the power supply settings and strip chart setup were correct, and a quick test pulse to a reference motor validated the configuration. With everything in order, the reference motor was removed and we jumpered-in Spirit's RAT-Revolve motor, responsible for rotating the grinder and brush on a Mars rock. The testing steps were confirmed one last time, and we had a green light for pulsing the waiting motor with energy.</p><p>To get the clearest signal and reveal the smallest of imperfections from the motor, the standard procedure is to give it as much power as it wants. This makes it vitally important to send the inrush of electrons to the right place. A wrong connection could do blue-smoke-releasing catastrophic damage. Our pre-test routine was an important precaution to verify that this potentially-dangerous configuration was correct.</p><p>The pulse was sent to the motor. As always, the result was immediate, but this time, alarmingly unfamiliar. The strip chart did not look like anything we had seen before. It did not even look like a broken motor. It was decidedly — something else. My mind raced for explanations and in what seemed like an instant, arrived at the most likely explanation. My eyes followed the wires from our breakout box on the test cart to the spacecraft, and the reason for the unfamiliar signal landed like a dagger through my heart. All that power we just released did not go into the RAT-Revolve motor. Due to a mistake I had made with the break-out-box, it went the other direction on the connector interface, sending a surge of electricity straight into the spacecraft, instead of the motor.&nbsp;</p><p><em>Ooooohhhh ssshhhhiiiiitttt.</em></p>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1701124110678_5219">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/629bbf78894a462d58b8002f/509a4fa4-3a81-43b4-bd75-c178dc3d0217/Strip+Chart+PlotZ79296.jpg" data-image="https://images.squarespace-cdn.com/content/v1/629bbf78894a462d58b8002f/509a4fa4-3a81-43b4-bd75-c178dc3d0217/Strip+Chart+PlotZ79296.jpg" data-image-dimensions="2165x1481" data-image-focal-point="0.5,0.5" alt="" data-load="false" src="https://images.squarespace-cdn.com/content/v1/629bbf78894a462d58b8002f/509a4fa4-3a81-43b4-bd75-c178dc3d0217/Strip+Chart+PlotZ79296.jpg" width="2165" height="1481" sizes="100vw" srcset="https://images.squarespace-cdn.com/content/v1/629bbf78894a462d58b8002f/509a4fa4-3a81-43b4-bd75-c178dc3d0217/Strip+Chart+PlotZ79296.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/629bbf78894a462d58b8002f/509a4fa4-3a81-43b4-bd75-c178dc3d0217/Strip+Chart+PlotZ79296.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/629bbf78894a462d58b8002f/509a4fa4-3a81-43b4-bd75-c178dc3d0217/Strip+Chart+PlotZ79296.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/629bbf78894a462d58b8002f/509a4fa4-3a81-43b4-bd75-c178dc3d0217/Strip+Chart+PlotZ79296.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/629bbf78894a462d58b8002f/509a4fa4-3a81-43b4-bd75-c178dc3d0217/Strip+Chart+PlotZ79296.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/629bbf78894a462d58b8002f/509a4fa4-3a81-43b4-bd75-c178dc3d0217/Strip+Chart+PlotZ79296.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/629bbf78894a462d58b8002f/509a4fa4-3a81-43b4-bd75-c178dc3d0217/Strip+Chart+PlotZ79296.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

                
            </p>
          </div>
        
          
        

        
          
          <figcaption>
            <p><strong><em>The strip-chart plot from the test that night. It is not supposed to be flat, and instead should tail exponentially downward.</em></strong></p>
          </figcaption>
        
      
        </figure>
      

    </div><div data-block-type="2" id="block-yui_3_17_2_1_1701124110678_6350">
  <p>The possible consequences rolled over me in nauseating waves. I may have just created a $500M piece of scrap. With only two weeks until the spacecraft was delivered for launch operations, THERE WAS NO TIME to recover from a big problem. I was instantly aware that there may be only one rover launched to Mars on this synodic cycle. And my hands were holding the still-warm rover murder weapon.</p><p>I had learned from countless experiences in this and other projects that bad news doesn’t get better with age so I immediately keyed the mic on my headset and told Leo, the test conductor running the other testing in parallel, what had just happened. His response twisted the knife in my chest. ‘Yeah, we seem to have lost all spacecraft telemetry just a bit ago.’ NOT a good sign.</p><p>Everyone in my vicinity was listening in on the voice loop on their headsets, and off-mic, John unleashed a string of profanities about me that could serve as an advanced tutorial for even the most seasoned sailors. The team immediately ran the spacecraft’s emergency shutdown procedure and we were instructed to leave the cleanroom for what would probably be a damage assessment briefing.</p><p>I had turned 28 less than a month prior, looked and felt much younger, and was a few years into my first big job after college. This first significant step in my dream career as an interplanetary spacecraft engineer, which I had aspired to since junior high, was perhaps also going to be my last. Others in the system test area moved away from me as dark reality descended. Matt, the Assembly Test and Launch Operations manager, firmly instructed me to write down everything I could remember about what had just transpired. I’m not sure when the tears started, but they were probably flowing as I recorded those details alone in a conference room.</p><p>With my notes in hand, Leo and my colleagues meticulously examined the evening’s events. There were two obvious things that had happened. One, a large pulse of electricity had gone somewhere other than intended, and two, telemetry had stopped coming from the spacecraft. Ominously, but perhaps with a ray of hope, there was not an obvious link between these two things. As the team reasoned through the problem, it seemed the surge of electricity likely ended up in the H-Bridge motor driver circuit, essentially a smart traffic controller for electricity. What I did was NOT GOOD, but luckily because of something called back-EMF[1], this was one part of the rover actually designed to handle extra energy.</p><p>We decided that the errant pulse had somehow glitched the system enough to interrupt the data flow without permanently disabling it. With the spacecraft already powered off, we would do what you do with your own consumer electronics: we would turn it back on to see if the power cycle had cleared the problem.</p><p>It was close to midnight and notifications about the incident had made it up the chain of management to Pete, the Project Manager. Replanning across the entire project of a thousand people was at stake. The team, now with a lot of extra attention and oversight, re-grouped and ran the standard spacecraft power-on procedure. When booting up the spacecraft, it takes a bit for the electronics to come online, then for the software to boot up and start producing telemetry. There is a circuit that produces a pulse every clock cycle (8 times a second), turning a red light on the ground support instrument rack into a robot heartbeat indicator. The spacecraft power supply went through its familiar progression of voltage steps and currents, but after too much time, the heartbeat remained dark, and the telemetry never came.&nbsp;</p><p>I don’t really remember what happened next. Probably something about meetings in the morning to figure out what the hell do we do now?! What I do remember is the feeling of emotional devastation that followed me home where I recounted the story to my wife. I was convinced I would lose my job in the morning and space exploration history would attach my name to a particular chapter of infamy.</p><p>Back at JPL in the morning, in a meeting with a fresh shift and hold outs from the prior night of disaster, we once again worked through the detailed sequence of reconstructed events looking for clues or possible recovery, which felt more and more fleeting until one crucial piece of the puzzle was recognized.</p><p>The Fluke 87III digital multimeter is a ubiquitous tool in the labs of JPL. When I entered the cleanroom the previous night, I needed one and asked John, the sailor linguist, where I could get one for my test. All were in use, so he pointed near the spacecraft to one apparently monitoring bus voltage but not involved in any testing. I carefully removed the leads and proceeded on to my date with destiny in testing the RAT motors. The monitoring multimeter I disconnected was actually completing the circuit that powered the spacecraft's ground test telemetry. I inadvertently disabled the connection the instant I removed the leads.</p><p>We immediately realized that the next thing to do was to restore the multimeter to this duty and power up the spacecraft.</p><p>We did just that. It worked. There was a collective gasp as the telemetry flickered back to life — Spirit was not dead after all!</p><p>The team resumed testing, having lost only a few hours, and I exhaled the most monumental sigh of relief in my lifetime, reassured that I might not have actually doomed the mission to a single-rover endeavor.</p><p>The rest of that morning was a blur. Weeks of analyses followed on the RAT-Revolve motor H-bridge channel leading to detailed discussions of possible thin-film demetallization. Ultimately the project gained the confidence to disposition the hardware: Use As Is.</p><p>The long days continued. I moved to Cape Canaveral to begin the final preparations before launching the rovers to Mars, and more thrilling stress-filled moments punctuated the days and weeks. Then Spirit was on Mars, and after a year of latent stress, it turned out the RAT-Revolve motor worked just fine, and the whole experience became a life lesson.</p>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1701124110678_7789">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/629bbf78894a462d58b8002f/acfa6a85-10b6-4b76-b394-d382c1ddb0c4/You+Messed+Up+-+Accept+Lesson+transparent.png" data-image="https://images.squarespace-cdn.com/content/v1/629bbf78894a462d58b8002f/acfa6a85-10b6-4b76-b394-d382c1ddb0c4/You+Messed+Up+-+Accept+Lesson+transparent.png" data-image-dimensions="902x481" data-image-focal-point="0.5,0.5" alt="" data-load="false" src="https://images.squarespace-cdn.com/content/v1/629bbf78894a462d58b8002f/acfa6a85-10b6-4b76-b394-d382c1ddb0c4/You+Messed+Up+-+Accept+Lesson+transparent.png" width="902" height="481" sizes="100vw" srcset="https://images.squarespace-cdn.com/content/v1/629bbf78894a462d58b8002f/acfa6a85-10b6-4b76-b394-d382c1ddb0c4/You+Messed+Up+-+Accept+Lesson+transparent.png?format=100w 100w, https://images.squarespace-cdn.com/content/v1/629bbf78894a462d58b8002f/acfa6a85-10b6-4b76-b394-d382c1ddb0c4/You+Messed+Up+-+Accept+Lesson+transparent.png?format=300w 300w, https://images.squarespace-cdn.com/content/v1/629bbf78894a462d58b8002f/acfa6a85-10b6-4b76-b394-d382c1ddb0c4/You+Messed+Up+-+Accept+Lesson+transparent.png?format=500w 500w, https://images.squarespace-cdn.com/content/v1/629bbf78894a462d58b8002f/acfa6a85-10b6-4b76-b394-d382c1ddb0c4/You+Messed+Up+-+Accept+Lesson+transparent.png?format=750w 750w, https://images.squarespace-cdn.com/content/v1/629bbf78894a462d58b8002f/acfa6a85-10b6-4b76-b394-d382c1ddb0c4/You+Messed+Up+-+Accept+Lesson+transparent.png?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/629bbf78894a462d58b8002f/acfa6a85-10b6-4b76-b394-d382c1ddb0c4/You+Messed+Up+-+Accept+Lesson+transparent.png?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/629bbf78894a462d58b8002f/acfa6a85-10b6-4b76-b394-d382c1ddb0c4/You+Messed+Up+-+Accept+Lesson+transparent.png?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

                
            </p>
          </div>
        
          
        

        
          
          <figcaption>
            
          </figcaption>
        
      
        </figure>
      

    </div><div data-block-type="2" id="block-yui_3_17_2_1_1701124110678_9259">
  <h2>The Lesson</h2><p>As I've recounted this tale over time, it has not only enriched my understanding but also inspired others to explore and share their own brushes with failure. The act of sharing transforms these experiences into valuable lessons, both for the storytellers and their audience. Later in my career, at my asteroid mining startup Planetary Resources, we recognized the power of these narratives in our hiring process and team culture. We deliberately asked job candidates to share a failure story of theirs, inviting them to acknowledge and learn from their past challenges, while recognizing that failure is a natural process of learning. The core lesson I've drawn from my rover ordeal is best expressed in these words:</p>
</div><div data-block-type="31" id="block-yui_3_17_2_1_1701124110678_10505">



<figure>
  <blockquote data-animation-role="quote">
    <span>“</span>Let your scars serve you; they are an invaluable learning experience and investment in your capability and resilience.<span>”</span>
  </blockquote>
  
</figure>
</div><div data-block-type="2" id="block-yui_3_17_2_1_1701124110678_11063">
  <p>In the depths of the crisis, when the tears were flowing and everyone else in the system test center was moving away, one person walked toward me. Ernie, a wise and kind man who had come out of retirement to help with the round-the-clock spacecraft shift work approached me and put his hand around my shoulder, and in a gentle grandfatherly voice quietly reassured me. He then uttered the clear words that I will never forget: ‘Remember this feeling the next time you have to sign-off that something is OK.’</p><p>I went on to become Flight Director for Spirit and Opportunity as they explored the surface of Mars, earning NASA’s Exceptional Achievement Medal for my efforts, so obviously I didn’t get fired for this incident. But that wasn’t clear until a few days later in one of the more pivotal meetings of my life. In the tense period following the mishap, with definitive analysis still pending, passionate and polarized debates ensued about the tests' hazards, and many argued for stopping them altogether. The debate concluded, and the criticality of these tests — making sure our motors would function flawlessly on Mars — was still paramount. The tests needed to continue. And I still remember the shock when Project Manager Pete delivered the decision and the follow-on news: ‘These tests will continue. And Chris will continue to lead them as we have paid for his education. He’s the last person on Earth who would make this mistake again.’&nbsp;</p><p>I found myself returning to the 'scene of the crime' for many more tests, after I had carefully revised the procedures to eliminate the chance of repeating the same mistake. Each time I conducted this test again, Pete’s vote of confidence combined with Ernie’s words of wisdom brought with it a moment of nausea, a stark reminder of the past incident, but also the readiness and confidence to continue. The trust management showed in me, despite the initial error, marked a key moment in my career, highlighting growth and the ability to overcome challenges.</p><p>Now, whenever I'm called upon to give my approval or endorsement for something significant, I'm instantly transported back to that moment — the room, the lighting, the chair I was in, the table, the pit in my stomach, the intense mix of fear, anxiety and regret for an oversight that nearly led to catastrophe. Ernie's wisdom that day, combined with his compassionate approach during my moment of vulnerability, left an indelible mark on me. Now, when faced with critical decisions, I not only recall that experience but also strive to assist others in navigating their own challenging moments. And like Pete did for me, my aim is to aid in transforming these experiences into catalysts for growth and resilience, reinforcing the notion that our responses to adversity can define our path forward.</p><p>These stories of near misses, learning curves, and eventual triumphs are not just mine, but are shared by many who build things. In space exploration, failure is not an option — it comes pre-installed. Every misstep is a stepping stone towards greater success, and together, our collective wisdom can pave the way for future innovations, achievements and breakthroughs in developing and growing our presence in and benefit from space.</p><p>&nbsp;I’d love to learn from fellow space entrepreneurs, engineers, scientists, technicians, and others who would share their own 'Failure Stories.' If you’ve been able to overcome a failure and benefit from it, share your story on my threads on <a href="https://www.linkedin.com/posts/chrislewicki_my-500m-mars-rover-mistake-a-failurestory-activity-7135067024807882752-XE2d">LinkedIn</a>, the service formerly known as <a href="https://x.com/interplanetary/status/1729299463515369535?s=20">Twitter/X</a>, or <a href="https://bsky.app/profile/interplanetchris.bsky.social/post/3kf7ityxemm2y">BlueSky</a>.</p>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1701124110678_12031">

      

      
        <figure>
          
        
        

        
          
            
          
        

        
          
          <figcaption>
            <p>Spirit Mars rover under construction. A yellow Fluke digital multimeter (bottom left), and its essential place in line with spacecraft telemetry (January 2003)</p>
          </figcaption>
        
      
        </figure>
      

    </div><div data-block-type="31" id="block-yui_3_17_2_1_1701124110678_13361">



<figure>
  <blockquote data-animation-role="quote">
    <span>“</span>It’s in the valley of failure that we sow the seeds of success.<span>”</span>
  </blockquote>
  <figcaption>— Jason Altucher</figcaption>
</figure>
</div><div data-block-type="31" id="block-yui_3_17_2_1_1701124110678_13841">



<figure>
  <blockquote data-animation-role="quote">
    <span>“</span>No experience is in itself a cause of our success or failure. We do not suffer from the shock of our experiences—the so-called trauma—but instead we make out of them whatever suits our purposes. We are not determined by our experiences, but the meaning we give them is self-determining.<span>”</span>
  </blockquote>
  <figcaption>— Ichiro Kishimi, The Courage to Be Disliked</figcaption>
</figure>
</div><div data-block-type="31" id="block-yui_3_17_2_1_1701124110678_14402">



<figure>
  <blockquote data-animation-role="quote">
    <span>“</span>The very best news is bad news delivered early enough to fix it.<span>”</span>
  </blockquote>
  <figcaption>— Lindy Elkins-Tanton, Principal Investigator of the Psyche mission</figcaption>
</figure>
</div><div data-block-type="2" id="block-yui_3_17_2_1_1701125769052_12539">

<p>[1] Back-EMF (ElectroMotive Force): the energy a motor creates when it starts acting like a mini power generator, especially during times when it slows down or the timing isn't quite right</p>



</div></div>
  
</article>

</div>

  
</article>


          

          
            
              

            
          
        
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apple pulls plug on Goldman credit-card partnership (163 pts)]]></title>
            <link>https://www.wsj.com/finance/banking/apple-pulls-plug-on-goldman-credit-card-partnership-ca1dfb45</link>
            <guid>38452712</guid>
            <pubDate>Tue, 28 Nov 2023 22:56:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wsj.com/finance/banking/apple-pulls-plug-on-goldman-credit-card-partnership-ca1dfb45">https://www.wsj.com/finance/banking/apple-pulls-plug-on-goldman-credit-card-partnership-ca1dfb45</a>, See on <a href="https://news.ycombinator.com/item?id=38452712">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div><section><p data-type="paragraph">Apple<!-- --> is pulling the plug on its credit-card partnership with <!-- -->Goldman Sachs<!-- -->, the final nail in the coffin of the Wall Street bank’s bid to expand into consumer lending.&nbsp;&nbsp;</p><p data-type="paragraph">The tech giant recently sent a proposal to Goldman to exit from the contract in the next roughly 12-to-15 months, according to people briefed on the matter. The exit would cover their entire consumer partnership, including the credit card the companies launched in 2019 and the savings account rolled out this year.</p></section><p>Copyright ©<!-- -->2023<!-- --> Dow Jones &amp; Company, Inc. All Rights Reserved. 87990cbe856818d5eddac44c7b1cdeb8</p></div><div><div type="wtrn_cxense" aria-label="What to Read Next" data-block="doNotPrint" data-skip-nav-order="5" data-skip-label="What to Read Next" role="region" tabindex="-1"><p><h2>What to Read Next</h2></p></div><div aria-label="Sponsored Offers" data-block="doNotPrint" data-skip-nav-order="6" data-skip-label="Sponsored Offers" role="region" tabindex="-1"><p>Sponsored Offers</p><ul><li><span>Kohl's<!-- -->: <br></span><a href="https://www.wsj.com/coupons/kohls" target="_blank" rel="noreferrer">Two Day Deals: Extra 25% off online and in-store</a></li><li><span>Walmart<!-- -->: <br></span><a href="https://www.wsj.com/coupons/walmart" target="_blank" rel="noreferrer">Walmart Promo Code - $20 Off Any $50+ Order</a></li><li><span>Target<!-- -->: <br></span><a href="https://www.wsj.com/coupons/target" target="_blank" rel="noreferrer">Take 20% Off Your Entire Order - Target promo Code</a></li><li><span>Newegg<!-- -->: <br></span><a href="https://www.wsj.com/coupons/newegg" target="_blank" rel="noreferrer">10% Off Sitewide - Newegg Promo Code</a></li><li><span>Dell<!-- -->: <br></span><a href="https://www.wsj.com/coupons/dell" target="_blank" rel="noreferrer">American Express Dell Coupon Code: Grab 10% off select purchases</a></li><li><span>Best Buy<!-- -->: <br></span><a href="https://www.wsj.com/coupons/best-buy" target="_blank" rel="noreferrer">Save $1000 discount on iPhone 15 Pro and Pro Max - Best Buy coupon</a></li></ul></div></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Shutting down the Matrix bridge to Libera chat (104 pts)]]></title>
            <link>https://matrix.org/blog/2023/11/28/shutting-down-bridge-to-libera-chat/</link>
            <guid>38451920</guid>
            <pubDate>Tue, 28 Nov 2023 21:58:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://matrix.org/blog/2023/11/28/shutting-down-bridge-to-libera-chat/">https://matrix.org/blog/2023/11/28/shutting-down-bridge-to-libera-chat/</a>, See on <a href="https://news.ycombinator.com/item?id=38451920">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <p>Today we are sorry to announce that we are not able to bring the Libera Chat bridge back online. We have already begun working through clean up tasks, such as clearing ghosts, and expect to be done by December 22. If you see any bridge artifacts left past that point, please let us know.</p>
<p>If you are one of those who have relied on the bridge in the past, you may be asking: what now? You do have options.</p>
<p>People who need a bridge for their community can <a href="https://matrix.org/ecosystem/bridges/irc/">run their own</a>: the matrix-appservice-irc software is still maintained. Only its Libera Chat instance, which was configured to persist connections across restarts, is being shut down. Please be mindful of the network, and read <a href="https://libera.chat/guides/faq#are-bridges-allowed">Libera Chat’s recommendations</a> and <a href="https://libera.chat/guides/matrix">their Matrix FAQ</a> when doing so.</p>
<h2 id="background">Background</h2>
<p>We at the Matrix.org Foundation have been working behind the scenes for months with the team at Element who operated the bridge and our peers at Libera Chat. Our hope had been to address the issues that were raised about the bridge to the satisfaction of Libera and to quickly bring it back online, but ultimately the Foundation is only a facilitator in the process and does not have the resources to maintain and operate the bridge itself.</p>
<p>We know that many communities and individuals were relying on the bridge, and we regret the impact this situation has on them.</p>
<p>To date, development, maintenance, and operation of the Libera Chat bridge had been donated to the community by teams at Element. We are grateful for their work and ongoing support, and understand that limited staffing has impacted their ability to consistently prioritize work on this bridge.</p>
<p>Over the course of the last couple of years of operating the bridge, issues had been raised and work undertaken to address those issues to the extent possible with available resources.</p>
<p>Transparently, the complexity of the work meant that we didn’t get the desired results as quickly as any involved party would’ve liked. Given that, the teams came to mutual agreement to turn the bridge off until key improvements were made and verified.</p>
<p>It’s possible that the necessary work will be undertaken at some point, and Element has made it clear that they would like to make this happen. But with so many people wondering about the status and trying to make plans, we owe it to the impacted communities to provide more certainty than we’ve offered to date.</p>
<p>Long term, the Foundation’s hope is to have the resources to service its core programs as well as provide additional community services like bridge maintenance and operations. However, as an open source foundation that is still early in its journey, we must be realistic about our capacity and make hard choices about where we put our scarce resources.</p>
<p>We thank all of the involved parties for their commitment to doing right by the community and are sorry that we don’t have better news to offer at this time.</p>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Charlie Munger – Feeling Like a Victim Is Perfectly Disastrous (152 pts)]]></title>
            <link>https://www.butwhatfor.com/p/takeaway-tuesday-facing-adversity-charlie-munger</link>
            <guid>38451543</guid>
            <pubDate>Tue, 28 Nov 2023 21:27:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.butwhatfor.com/p/takeaway-tuesday-facing-adversity-charlie-munger">https://www.butwhatfor.com/p/takeaway-tuesday-facing-adversity-charlie-munger</a>, See on <a href="https://news.ycombinator.com/item?id=38451543">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-blocks"><p><b><a href="https://www.butwhatfor.com/c/charlie-munger/" target="_blank" rel="noopener noreferrer nofollow">Charlie Munger</a></b> is best known as Warren Buffett’s longtime business partner and vice chairman of Berkshire Hathaway. Independent of his work with Buffett, Munger is a successful businessman and philanthropist in his own right. An avid reader and life-long, multidisciplinary learner, he is admired for his witty life lessons and often-too-blunt pieces of advice. Born in 1924, he is 96 years young. </p><p><h2><b>When handing out misfortune, life has no obligation to be fair.</b></h2></p><div><p>In 1953, Charlie was 29 years old when he and his wife divorced. He had been married since he was 21. Charlie lost everything in the divorce, his wife keeping the family home in South Pasadena. Munger moved into “dreadful” conditions at the University Club…</p><p><b>Shortly after the divorce, Charlie learned that his son, Teddy, had leukemia</b>. In those days, there was no health insurance, you just paid everything out of pocket and <b>the death rate was near 100% since there was nothing doctors could do</b>. Rick Guerin, Charlie’s friend, said Munger would go into the hospital, hold his young son, and then walk the streets of Pasadena crying.</p><p>One year after the diagnosis, in 1955, Teddy Munger died. <b>Charlie was 31 years old, divorced, broke, and burying his 9 year old son.</b></p></div><p><h2><b>If you are misfortunate, a victim mentality is incredibly useful if you wish to remain miserable…</b></h2></p><div><p>Whenever you think that some situation or some person is ruining your life, [think that] it’s actually you who are ruining your life. It’s such a simple idea. <b>Feeling like a victim is a perfectly disastrous way to go through life</b>. </p><p>If you just take the attitude that, however bad it is in anyway, <b>it’s always your fault and you just fix it as best you can</b> – the so-called ‘iron prescription’ – <a href="https://www.youtube.com/watch?v=5U0TE4oqj24&amp;utm_source=www.butwhatfor.com&amp;utm_medium=referral&amp;utm_campaign=charlie-munger-feeling-like-a-victim-is-perfectly-disastrous" target="_blank" rel="noopener noreferrer nofollow">I think that really works</a>.</p></div><p><h2><b>… as self-pity itself is guaranteed to never improve your position.</b></h2></p><div><p>Well you can say that’s waggery, but I suggest that every time you find you’re drifting into self-pity, I don’t care what the cause, your child could be dying of cancer, <b>self-pity is not going to improve the situation…</b></p><p>It’s a ridiculous way to behave, and <b><a href="https://www.butwhatfor.com/p/suppose-wanted-kill-lot-ofpilots" target="_blank" rel="noopener noreferrer nofollow">when you avoid it you get a great advantage over everybody else</a></b>, almost everybody else, because self-pity is a standard condition and yet you can train yourself out of it.</p></div><p><h2><b>Alternatively, you can accept personal responsibility to better your situation…</b></h2></p><div><p><b>Another thing of course is life will have terrible blows, horrible blows, unfair blows, doesn’t matter</b>. And some people recover and others don’t. And there I think the attitude of Epictetus is the best. </p><p>He thought that every mischance in life was an opportunity to behave well, every mischance in life was an opportunity to learn something, and <b>your duty was not to be submerged in self-pity but to utilize the terrible blow in a constructive fashion. </b><b><a href="https://www.youtube.com/watch?v=iDcOuTdjq8E&amp;utm_source=www.butwhatfor.com&amp;utm_medium=referral&amp;utm_campaign=charlie-munger-feeling-like-a-victim-is-perfectly-disastrous" target="_blank" rel="noopener noreferrer nofollow">That is a very good idea</a></b><b>.</b></p></div><p><h2><b>… because even in the worst of situations, you can still better yourself.</b></h2></p><div><p><b>We must never forget that we may also find meaning in life even when confronted with a hopeless situation</b>, when facing a fate that cannot be changed. For what then matters is to bear witness to the uniquely human potential at its best, which is to transform a personal tragedy into a triumph, to turn one’s predicament into a human achievement.<b>&nbsp;</b></p><p><b>When we are no longer able to change a situation</b>—just think of an incurable disease such as inoperable cancer—<b>we are challenged to change ourselves</b>.</p><p><a href="https://www.rightattitudes.com/2014/11/13/viktor-frankl-the-meaning-of-suffering/?utm_source=www.butwhatfor.com&amp;utm_medium=referral&amp;utm_campaign=charlie-munger-feeling-like-a-victim-is-perfectly-disastrous" target="_blank" rel="noopener noreferrer nofollow">Quote from Viktor Frankl</a> - <a href="https://www.brainpickings.org/2013/03/26/viktor-frankl-mans-search-for-meaning/?utm_source=www.butwhatfor.com&amp;utm_medium=referral&amp;utm_campaign=charlie-munger-feeling-like-a-victim-is-perfectly-disastrous" target="_blank" rel="noopener noreferrer nofollow">Auschwitz concentration camp survivor</a></p></div><p><h2><b>And this applies to more than just you - you can shoulder some of the responsibility for others, too.</b></h2></p><div><p>My paternal grandfather was the only federal judge in Lincoln Nebraska, capital city of Nebraska and he's been there forever and he stayed there forever…</p><p>[During the Great Depression] one [of the judge’s] son-in-laws was a musician. Of course, he couldn’t make a living so <b>my grandfather, who didn't have that much money, sent him to the pharmacy school. He carefully picking a profession that couldn't fail</b>... And my uncle's soon prosperous and remained prosperous the rest of his life. </p><p>My other uncle had a bank in Stromsburg Nebraska… and of course he was a lovely man, but he was an optimist and a banker should not be an optimist. And when they closed the banks in 1933, the banking examiners came in and said you can't reopen and it was the only business he had. </p><p>Well judge Munger always saved this money and he had a lot of good first mortgages on homes occupied by teetotaling German butchers and people he’d carefully pitch. Of course he never had a default… the people were sober and hardworking and <b>so what my grandmother did is take 1/3 of his good mortgages, which is all he had, and put them in the bank and took all the lousy assets out of the bank. </b></p><p><b>So he saved two out of three of his children and I thought it was a pretty good thing to do</b>.</p></div><p><img alt="Warren Buffett's partner Charlie Munger donates millions to colleges. They just have to let him play architect. | Markets Insider" src="https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/45fcb643-871f-4b55-ad26-4e05c1f56a33/a1ffbd44-f6d3-431b-b82d-bc8f3bdf6ba6_2400x1800.jpeg"></p><p><h3>Books Related to Charlie Munger</h3></p><p><b><a href="https://amzn.to/2GZzsye?utm_source=www.butwhatfor.com&amp;utm_medium=referral&amp;utm_campaign=charlie-munger-feeling-like-a-victim-is-perfectly-disastrous" target="_blank" rel="noopener noreferrer nofollow">Damn Right!</a></b>: Biography of Charlie Munger by Janet Lowe </p><p> If you made it all the way through the article, please take a moment to share it with someone that might find it interesting, or if you haven’t yet subscribed, please consider doing so below — I appreciate your support very much! </p><p> Take care and have a great rest of the week, </p><p> — EJ </p><p><h3>See <a href="https://www.butwhatfor.com/archive" target="_blank" rel="noopener noreferrer nofollow">here</a> for an archive of recent newsletter articles</h3></p><p><a href="https://www.butwhatfor.com/" target="_blank" rel="noopener noreferrer nofollow">But What For?</a> Writing about anything, as long as it’s interesting </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Charlie Munger has died (1005 pts)]]></title>
            <link>https://www.berkshirehathaway.com/news/nov2823.pdf</link>
            <guid>38451278</guid>
            <pubDate>Tue, 28 Nov 2023 21:03:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.berkshirehathaway.com/news/nov2823.pdf">https://www.berkshirehathaway.com/news/nov2823.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=38451278">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[The dead children we must see (159 pts)]]></title>
            <link>https://www.newyorker.com/news/our-columnists/the-dead-children-we-must-see</link>
            <guid>38450908</guid>
            <pubDate>Tue, 28 Nov 2023 20:35:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.newyorker.com/news/our-columnists/the-dead-children-we-must-see">https://www.newyorker.com/news/our-columnists/the-dead-children-we-must-see</a>, See on <a href="https://news.ycombinator.com/item?id=38450908">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>In a series of <a href="https://ia800907.us.archive.org/5/items/BaudrillardJean.TheGulfWarDidNotTakePlace.IndianapolisIndianaUniversityPress1991.0004/Baudrillard%2C%20Jean.%20The%20Gulf%20War%20Did%20Not%20Take%20Place.%20Indianapolis-Indiana%20University%20Press%2C%201991._0004.pdf">three essays published in 1991</a>, the philosopher Jean Baudrillard argued that the Gulf War, which ended up with more than a hundred thousand dead Iraqis, had not really taken place. In his inimitable fashion, his argument was filled with internal contradictions, annoying trolling (Baudrillard had initially written that the Gulf War would never actually happen, which, of course, it did), and some pockets of real clarity. His ultimate argument was that what had taken place wasn’t so much a war but a one-sided aerial slaughter that was scrubbed clean through intensive media control. What people in the West saw were so-called live feeds of missiles and aerial assaults fuelled by new forms of technology, whether the Patriot missile or the stealth bomber. The war was communicated to us almost like an advertisement for a new car—here are all the new features, and here are the salesmen in the form of generals or foreign-policy experts paraded on cable news. We did not see slain enemy combatants, destroyed civilian homes.</p><p>If the Gulf War was a slaughter sold to the American public as a clean military-technology show, the <a href="https://www.newyorker.com/tag/gaza">war in Gaza</a> has been a production line of horrifying images. The footage of dead and wounded children, particularly on social media, has traumatized the world and made it clear that nothing—not even the Israeli military tightly controlling media access—can stop ordinary citizens around the world from seeing what happens when a shell hits a hospital or a school or an apartment building where families live. My guess is that this war’s lasting legacy may not be some geopolitical break after years of conflict but the images of the innocents we’ve seen, including children, killed in almost every imaginable way.</p><p>There should be no moral squishiness about any of this. If children are being slaughtered, if a father is carrying his dead daughter through a bombed-out street, or if there is footage of dead children in southern Israel, which, for now, seems to have been shown mostly in a selective way through screenings by the Israel Defense Forces, the world, at large, should see that.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>Here in the United States, we have our own procession of dead children, but they’re almost all unseen. The victims of mass shootings in schools leave behind a spectral trail. We do not see their deaths; we do not see the agony of a parent holding their child’s lifeless body. Instead, we see the surrounding context—surveillance footage of the shooter stalking through the hallways of a school, the smiling school photos of the murdered child, the brave parents speaking in shaky voices at a press conference, the faces of law-enforcement officers providing nighttime updates on the death toll. These scenes have become so familiar that they feel like studio sets for a television show we watch over and over again. In the first act, we see the aerial shots of the school. Then we are on the grounds with the shooter. And here is the local chief of police, his face overly lit from a crowd of news cameras, each with its own little spotlight, grimly updating the nation.</p><p>This show does not trade in clean advertisements in the Baudrillardian sense, but its recurrence and its familiarity draw more attention to the bodies we don’t see. We are left to imagine the scene inside a classroom. Every time I hear about a shooting at a school, I picture my own children looking up with surprise as the gunman walks through the door. But our imaginations tend to stop short, in part because the vast majority of us have <a href="https://www.newyorker.com/news/daily-comment/would-showing-graphic-images-of-mass-shootings-spur-action-to-stop-them">never seen actual carnage</a>. If the parents are willing, and believe that their child’s death can spark the outrage needed to produce an outcome that would stop or reduce these mass shootings, should we see these dead children in the same way that we have seen the dead children of Gaza? One does not have to agree upon what the solution might be—gun control or early psychiatric interventions or whatever else—to understand the calculation here. It is similar to the decision Mamie Till made when she insisted upon an open-casket funeral for her son, Emmett, saying, “I wanted the world to see what they did to my baby.”</p><p>Earlier this month, the Washington <em>Post</em> published a <a href="https://www.washingtonpost.com/nation/interactive/2023/ar-15-force-mass-shootings/?itid=hp-top-table-main_p001_f001">lengthy multimedia story</a> titled “Terror on Repeat: A rare look at the devastation caused by AR-15 shootings,” which includes photos from mass shootings that the vast majority of the public has never seen before. We see the bullet-ridden walls of the First Baptist Church in Sutherland Springs, Texas, a prayer book with a bullet hole found in the Tree of Life synagogue in Pittsburgh, a shattered glass wall at Sandy Hook Elementary, and the blood-streaked floors of a classroom at Robb Elementary in Uvalde, Texas.</p><p>In a <a href="https://www.washingtonpost.com/nation/2023/11/16/about-ar-15-graphic-content/">note</a> that accompanies the story, Sally Buzbee, the newspaper’s executive editor, writes that “the goal was to balance two crucial objectives: to advance the public’s understanding of mass killers’ increasing use of this readily available weapon, which was originally designed for war, while being sensitive to victims’ families and communities directly affected by AR-15 shootings.”</p><p>But these images have also been edited, vetted, and responsibly published through an institutional process that included, in Buzbee’s words, grappling “with our own standard practices when it comes to publishing graphic content” and “training by the Dart Center for Journalism and Trauma,” which conferred “best practices for viewing disturbing photos and discussing how publishing them could affect readers.” What this means is that the <em>Post’s</em> story tightens the focus on all the areas surrounding the images of dead children—the bloody floor of a classroom in Uvalde—but for the most part still does not show the bodies themselves.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>There are two notable exceptions. From the mass shooting at a music festival in Las Vegas, we see dozens of dead people lying on the ground. In a hallway at Robb Elementary, a photo shows two lines of white body bags. The latter image is stunning, and there is an argument to be made that the body bags are enough to convey the horror and to fully portray the destruction of these mass shootings. The anonymity the bags confer and the blankness of white allow the viewer to imagine what’s inside without any intervening politics or prejudices or narratives. The brightly painted hallway—lime green and light blue—could be at any elementary school in America. The white bags could contain anyone’s children. The anonymity is universal, and the mind is drawn immediately to the other white body bags we have seen since October 7th.</p><p>And yet I do not know if these images are enough. This is not through any fault of the <em>Post</em>, which should be credited for its exhaustive, original reporting. But because it is an institution that must be careful and must reflect the recommendations of other institutions, such as the Dart Center, the decision about publishing traumatic imagery will always be processed through existing standards and consensus. Part of that calculus involves assessing the images’ journalistic value, which, in this case, was to show the “devastation caused by AR-15 shootings.” The specificity of that framing might give it more political power, but it also feels slightly—and I do mean slightly—disingenuous. Are we really seeing all these images of carnage as a way to talk about the AR-15? Perhaps, but I imagine the <em>Post</em> also understands that the horror of the images extends well beyond the debate over one specific weapon of war.</p><p>In an excellent <a href="https://www.nytimes.com/2023/11/13/opinion/gaza-war-children-photo.html">column</a> in the New York <em>Times</em> about a photograph of six dead children in Gaza, Lydia Polgreen writes, “The news media no longer needs to disseminate an image for it to be seen. Social media bludgeons us with a flood of brutal images.” Polgreen points to a discomforting probability: when the world ultimately sees the images of dead children in a school shooting in the United States, it will likely come via social media and be taken by someone who was inside the school, or, perhaps more ghoulishly, the shooters themselves. The dam—which currently is held in place by the standards of news organizations and by law-enforcement organizations who, for understandable reasons, have tightly guarded these crime-scene photos—will inevitably break. At some point, we will see these children, and journalists will then be faced with the question of whether they should offer up a more sanitized version of what the rest of the world has already seen.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>In her editor’s note, Buzbee mentions that the <em>Post</em> talked to families of the victims, some of whom were willing to grant permission to publish photographs of their dead relatives. But the paper ultimately decided that “the potential harm to victims’ families outweighed any potential journalistic value of showing recognizable bodies.” This is a perfectly acceptable decision, but one that prompts a broader question about whether it will be these institutional processes—and institutions—that ultimately arbitrate what is and isn’t made visible. There is also the question of why the <em>Post</em> would set aside the consent of victims’ families to protect them from the potential harm of what they had agreed to do.</p><p>The arguments against facilitating such a voluntary exposure are certainly compelling. A family who agreed to have the image of their murdered child published would be opening themselves up to the public in an excruciating manner. They might also retraumatize the families of other victims. There also is a legitimate concern about privacy that a dead child can no longer demand. But I also think that it’s worth thinking pragmatically, if such a word can be used in this context. Images of dead children have great emotional and political power because most people in the world rightfully agree that their deaths are intolerable. The taboo on showing the aftermath of this violence does not exist as merely some marker of civilized society—of good taste. It comes from those who, for whatever reason, are squeamish about putting names and faces to the escalating body count, who want to keep everything abstract. This isn’t limited just to gun manufacturers or to their lobbies or to politicians defending the Second Amendment but extends to just regular parents who would rather not fixate on something that’s probably not going to happen at their kid’s school.</p><p>The past six weeks have made it clear that the world will respond to images of slaughtered children, and it’s worth asking why it’s taken this long for people to see what that looks like. There is no question that images of dead children carry an immense amount of weight, which, in turn, must be handled responsibly. But that does not mean that any attempt to get the public to see them is automatically manipulative or propagandistic. It is far more manipulative to edit out the dead children or to hide them under a veil of solemnity and manners.&nbsp;♦</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The camel, the rope, and the needle's eye (127 pts)]]></title>
            <link>http://kiwihellenist.blogspot.com/2023/11/camel.html</link>
            <guid>38450577</guid>
            <pubDate>Tue, 28 Nov 2023 20:10:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://kiwihellenist.blogspot.com/2023/11/camel.html">http://kiwihellenist.blogspot.com/2023/11/camel.html</a>, See on <a href="https://news.ycombinator.com/item?id=38450577">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-body-5675154067691015719" itemprop="description articleBody">
<p>There’s no good evidence that <i>kamilos</i> — supposedly meaning ‘rope’ — was ever even a real word in ancient Greek.</p>

<p>The myth we’re looking at is to do with the following passage in the Bible.</p>

<blockquote>
  <p>εὐκοπώτερόν ἐστιν <b>κάμηλον διὰ τῆς τρυμαλιᾶς τῆς ῥαφίδος διελθεῖν</b> ἢ πλούσιον εἰς τὴν βασιλείαν τοῦ θεοῦ εἰσελθεῖν.</p>
  <p>It is easier for <b>a camel to go through the eye of a needle</b> than for someone who is rich to enter the kingdom of God.</p>
  <p><i>Mark</i> <a href="https://www.biblegateway.com/passage/?search=Mark+10.23-25&amp;version=THGNT,NRSVUE">10.25</a> (~ <i>Matthew</i> <a href="https://www.biblegateway.com/passage/?search=Matthew+19.21-24&amp;version=THGNT,NRSVUE">19.24</a>, <i>Luke</i> <a href="https://www.biblegateway.com/passage/?search=Luke+18.22-25&amp;version=THGNT,NRSVUE">18.25</a>)</p>
</blockquote>

<p>According to the myth, ‘camel’ is a misreading: originally, it was a ‘rope’ going through a needle. Still impossible, but not surreal like ‘camel’. Supposedly, the text originally had <i>kamilos</i>, but <i>kamēlos</i> ‘camel’ and <i>kamilos</i> ‘rope’ sounded the same in imperial-era Greek, so they got mixed up.</p>

<table><tbody>
  <tr><td><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj-qRg5ieUeSWdSmYAu1me5nqfwsGrff-8-zVIEDobldAHgqISkZN_iJ0lCSIjjQ4g8fLfaHxygMOFP0MZhDXnZYWL-fcP-U4oOh10ijDnyMj_NL8wAKbMA6s29TxhOpefZhYLEKh3L91vv2J0OV8gXMBvyGBqhEImI01Eq8KHzc826P_7TvH9_qpcWjQ4/s1215/Camel%20and%20needle.jpg"><img data-original-height="614" data-original-width="1215" height="203" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj-qRg5ieUeSWdSmYAu1me5nqfwsGrff-8-zVIEDobldAHgqISkZN_iJ0lCSIjjQ4g8fLfaHxygMOFP0MZhDXnZYWL-fcP-U4oOh10ijDnyMj_NL8wAKbMA6s29TxhOpefZhYLEKh3L91vv2J0OV8gXMBvyGBqhEImI01Eq8KHzc826P_7TvH9_qpcWjQ4/w400-h203/Camel%20and%20needle.jpg" width="400"></a></td></tr>
  <tr><td>A Roman needle and a camel. Not to scale.</td></tr>
</tbody></table>

<p>The ‘rope’ theory is one of a couple of tactics for softening Jesus’ condemnation of wealth-hoarding. There’s another one about an imaginary gate in Jerusalem called ‘the eye of the needle’: that one was made up in the 11th century. But some religious groups have a strong motivation for reading this passage as being about something other than a literal camel going through a literal needle’s eye. So fake explanations tend to stick around.</p>

<p>This review is a resource for anyone who’s in doubt about what the evidence for the ‘rope’ interpretation looks like. The executive summary is this: the word supposedly meaning ‘rope’ was made up in the 5th century or shortly beforehand, and it was made up specifically to weaken Jesus’ condemnation of wealth. It’s older than the ‘eye of the needle’ gate, but it’s just as bogus.</p>

<div>
    <p><b>Note.</b> This isn’t the first debunking of its kind. My aim is to make the evidence as accessible as possible. Zahn <a href="https://archive.org/details/dasevangeliumdes0000zahn_g1d0/page/600/mode/2up">1922: 601–602 n. 71</a> cites most of the ancient evidence in German; Khalil 1978 cites much of it in French; Henry <a href="https://www.youtube.com/watch?v=sf0Fm8aVApk">2022</a> disposes of purported arguments from Aramaic, but without delving into the Greek use of <i>kamilos</i>.</p>
    <p>For the origins of the bogus ‘gate’ theory, see Ziemińska <a href="https://doi.org/10.1017/S0028688521000448">2022</a>. The gate first pops up in a fragment of Anselm of Canterbury quoted in Thomas Aquinas, <i>Catena aurea</i> on <a href="https://aquinas.cc/la/en/~CaMatt.C19.L6.PseudoChrys">on <i>Matthew</i> 19.24</a>. My translation: ‘<b>Gloss.</b> Alternatively: because there was a certain gate in Jerusalem called ‘the eye of the needle’, and a camel could not pass through it unless it laid down its burden and bent its knees. So this means that a rich person cannot travel the confined way to (eternal) life unless they lay down their uncleanness of sin and their wealth, that is, or at least by not loving (wealth).’</p>
  </div>


<h2>A review of κάμιλος</h2>

<p>I’ll carry on spelling <i>kamēlos</i> (‘camel’) and <i>kamilos</i> (supposedly ‘rope’) differently, for clarity. Ancient and mediaeval sources often spell them both <i>kamēlos</i>.</p>

<p>The earliest authentic appearance of <i>kamilos</i> is in Cyril of Alexandria (1st half of 5th century). In nearly all cases where it appears in ancient and mediaeval sources, it’s only mentioned because someone is giving it as a textual variant for ‘camel’ in the gospels. In other contexts it appears only twice, and even those are still as annotations to the word ‘camel’, and they repeat Cyril’s exact phrasing.</p>

<p>So <b>there’s no independent evidence</b> to corroborate Cyril’s claim that <i>kamilos</i> was even a real word, let alone that it was the original text in the gospels. There’s just one possible exception: one <i>possible</i> candidate for an independent use of the word — a 5th century inscription from southern Anatolia — but the interpretation of the inscription is very doubtful.</p>

<hr>

<h3>1. Sources that cite <i>kamilos</i> as a textual variant in the gospels</h3>

<p>As I said, nearly all uses of <i>kamilos</i> ‘rope’ belong to this category. These are no use at all as corroboration. They don’t show that the word could ever be used in <i>any other</i> context.</p>

<p>Cyril’s definitions (sources <b>a</b>, <b>b</b>) are echoed in most post-Cyril sources.</p>

<ol type="a">
  <li><span>Cyril of Alexandria, commentary on <i>Matthew</i> fr. 219 Reuss (1957: 226; ~ <i>Patrologia graeca</i> 72 <a href="https://archive.org/details/patrologiaecurs47migngoog/page/n215/mode/2up">429d–431a</a>)</span></li>
  <li><span>Cyril of Alexandria, commentary on <i>Luke</i>, <i>Patrologia graeca</i> 72 <a href="https://archive.org/details/patrologiaecurs47migngoog/page/n427/mode/2up">857c</a></span></li>
  <li><span>Cyril of Alexandria, <i>Against Julian the apostate</i> fr. 21 Neumann (Syriac: Neumann <a href="https://archive.org/details/iulianiimperato00neumgoog/page/n68/mode/2up">1880: 56</a>; Latin translation: Neumann <a href="https://archive.org/details/iulianiimperato00neumgoog/page/n86/mode/2up">1880: 75, fr. 29</a>; French translation: Khalil 1978: 91 n. 1)</span></li>
  <li><span><i>Tractatus de divitiis</i> 18.2 (Kessler 1999: 306 = Caspari <a href="https://archive.org/details/briefeabhandlun00caspgoog/page/54/mode/2up">1890: 55</a>)</span></li>
  <li><span>pseudo-Origen, commentary on <i>Matthew</i> fr. 390 Klostermann (<a href="https://archive.org/details/origenes-werke.-bd.-12.1-1941/page/165/mode/2up">1941: 166</a>)</span></li>
  <li><span>Photios, commentary on <i>Matthew</i> fr. 77 Reuss (Reuss 1957: 318)</span></li>
  <li><span>Theophylact, <i>Enarratio in Evangelium Matthaei</i>, <i>Patrologia graeca</i> 123 <a href="https://books.google.com/books?id=-SFJAAAAcAAJ&amp;pg=PA355#v=onepage&amp;q&amp;f=false">356d</a></span></li>
</ol>

<p>I stop at the 11th century. (Zahn goes on further, to include a 12th century citation of Cyril in Bar Hebraeus: Zahn <a href="https://archive.org/details/dasevangeliumdes0000zahn_g1d0/page/602/mode/2up">1922: 602 n. 71</a>.)</p>

<p>I’ll just quote the first two, sources <b>a</b> and <b>b</b>, from Cyril. They’re both fragments preserved in <i>catena</i> commentaries. First, Cyril on <i>Matthew</i> 19.24:</p>

<blockquote>
  <p><b>κάμηλον</b> δὲ ἐνταῦθά φησιν οὐ τὸ ζῷον τὸ ἀχθοφόρον, ἀλλὰ τὸ παχὺ σχοινίον, ἐν ᾧ δεσμεύουσι τὰς ἀγκύρας οἱ ναῦται. οὐκ ἀνήνυτον παντελῶς τοῦτο δείκνυσιν ὄν, τῷ δὲ ἄγαν δυσχερὴ λοιπὸν ἤδη πως ἐγγὺς καὶ ἀγχίθυρον τοῦ ἀδυνάτου τὸ χρῆμα τιθείς.</p>
  <p>‘camel’: he doesn’t mean the pack animal here, but the thick rope, with which sailors bind anchors. He shows that the situation isn’t absolutely permanent, but makes the matter extremely difficult for him in future, and for the present, close to and neighbouring on impossibility.</p>
</blockquote>

<p><b>Note.</b> Reuss’ text fills in a chunk that’s missing in the <i>Patrologia</i> text, based on a manuscript at Mt Athos, Great Lavra cod. B 113 (11th cent.), <a href="https://www.loc.gov/resource/amedmonastery.0027105127A-ma/?sp=102">fol. 97r</a>. Reuss silently alters δυσχερή to δυσχερεῖ: I restore the manuscript reading here.</p>

<p>And Cyril on <i>Luke</i> 18.25. This one is very bald-faced, selecting the contrived word for the express purpose of allowing rich people to go to heaven.</p>

<blockquote>
  <p><b>κάμηλον</b>· οὐ τὸ ζῶον, ἀλλὰ τὸ ἐν τοῖς πλοίοις παχὺ σχοινίον. ἔξεστι γὰρ αὐτοῖς, εἰ μὴ εἰσάπαν ἕλοιντο τὸ τῶν ὅλων ὄντων ἀπολισθεῖν, ἑτέρως εὐδοκιμεῖν, ποιῆσαι φίλους ἐκ τοῦ ἀδίκου μαμωνᾶ, ἵνα ὅταν ἐπιλίπωσε, δέξωνται αὐτοὺς εἰς τὰς αἰωνίους σκηνάς.</p>
  <p>‘camel’: not the animal, but the thick rope used on ships. For it is possible for them to arrive at blessedness in a different way, even if they don’t choose to lose all their property completely, if they use their unjust Mamon to make friends, and the friends invite them into the eternal tabernacles.</p>
</blockquote>

<p>If you’re thinking of investigating all the sources listed here, take notice of Cyril’s phrasing: τὸ παχὺ σχοινίον (‘the thick rope’), and the bit about binding anchors. You’ll see these pop up routinely in later sources, including the sources in category 3, below. That shows that they aren’t independent.</p>

<p>The only post-Cyril source worth noticing is source <b>e</b>, the spurious Origen fragment. If authentic, it would put <i>kamilos</i> back to the 3rd century. But as Theodor Zahn points out, Origen’s authentic discussions of the gospel passages are entirely unaware of the ‘rope’ interpretation (Zahn <a href="https://archive.org/details/dasevangeliumdes0000zahn_g1d0/page/600/mode/2up">1922: 601 n. 71</a>).</p>

<hr>

<h3>2. Manuscripts of the New Testament with <i>kamilos</i></h3>

<p>A handful of the thousands of manuscripts of the New Testament — none earlier than the 9th century — give the variant reading <i>kamilos</i> in one or more of the three gospel passages. Like the sources in category 1, these have no corroborative value, because they do not show the word being used in any other context.</p>

<table><tbody>
  <tr><td><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEirMAUY9gZEd6sOuiVhmRQo51qgyf6Dg6PdTAuzs0NvdyoRV7oTn3gLEeTGzSTujxFQF7OREFdsoLei3l_fwuVqb7b8akv_Ht2d4AO3iAwXBhD1erEloBB_6PHqIDVAzWin40iHuBWbh_lf4dVcjBPT2dUJ2wNAV1syWu7rcfR1Lt9Dus3vko_483HErI8/s1334/Kamilos%20-%20MSS%20with%20mixed%20readings%20-%20Paris.%20gr.%2050%20ff.26r%20and%2059v%20(Matt%2019.24,%20Mark%2010.25)%20,%20Vat.gr.%20354%20ff.%2055r,%20162r%20(Matt%2019.24,%20Luke%2018.25).jpg" imageanchor="1"><img data-original-height="1112" data-original-width="1334" height="334" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEirMAUY9gZEd6sOuiVhmRQo51qgyf6Dg6PdTAuzs0NvdyoRV7oTn3gLEeTGzSTujxFQF7OREFdsoLei3l_fwuVqb7b8akv_Ht2d4AO3iAwXBhD1erEloBB_6PHqIDVAzWin40iHuBWbh_lf4dVcjBPT2dUJ2wNAV1syWu7rcfR1Lt9Dus3vko_483HErI8/w400-h334/Kamilos%20-%20MSS%20with%20mixed%20readings%20-%20Paris.%20gr.%2050%20ff.26r%20and%2059v%20(Matt%2019.24,%20Mark%2010.25)%20,%20Vat.gr.%20354%20ff.%2055r,%20162r%20(Matt%2019.24,%20Luke%2018.25).jpg" width="400"></a></td></tr>
  <tr><td>Even when New Testament manuscripts include the <i>kamilos</i> variant, they don’t use it consistently. Top: minuscule 13 (Paris.gr. 50, 13th cent.), ff. 26r and 59v (<i>Matthew</i> 19.24, <i>Mark</i> 10.25); bottom: uncial S (Vat.gr. 354, 949 CE), ff. 55r and 162r (<i>Matthew</i> 19.24, <i>Luke</i> 18.25). The readings in the left column have <i>kamēlos</i>, the ones on the right have <i>kamilos</i>.</td></tr>
</tbody></table>

<p>Many of the <i>kamilos</i> manuscripts belong to ‘family 13’, a group of 10th–15th century manuscripts with affinities to minuscule 13, that is, <a href="https://manuscripts.csntm.org/manuscript/View/GA_13">Paris.gr. 50</a> (11th cent.). Even in ‘family 13’, <i>kamilos</i> only appears in <i>Mark</i> 10.25 and <i>Luke</i> 18.25; in <i>Matthew</i> 19.24, it’s always <i>kamēlos</i>.</p>

<p><b>Note.</b> On ‘family 13’ see Metzger and Ehrman 2005: 87. On the Armenian and Georgian translations that have affinities to ‘family 13’, and which translate using a word meaning ‘rope’, see Metzger and Ehrman 2005: 117–119; McCollum <a href="https://hmmlorientalia.wordpress.com/2015/07/23/a-camel-or-a-rope-in-the-eye-of-a-needle-the-old-georgian-witness/">2015</a>; Pirtea 2021: 331. McCollum shows that ‘camel’ is standard in the Greek, Syriac, and Athonite Georgian versions, while ‘rope’ is standard in the Armenian and pre-Athonite Georgian evidence. (He doesn’t notice that the pseudo-Origen, here source <b>e</b>, is spurious — but it’s no discredit to miss something so obscure.)</p>

<p>Here are the manuscripts that are <i>not</i> in ‘family 13’ but which have the <i>kamilos</i> variant.</p>

<ul>
  <li><i>Mark</i> 10.25: minuscules 28 and 579 (Paris.gr. 379, 11th cent.; Paris.gr. 59, 13th cent.).</li>
  <li><i>Matthew</i> 19.24: minuscules 579 and 1424 (Paris.gr. 97, 13th cent.; Chicago Gruber 152, 9th/10th cent.).</li>
  <li><i>Luke</i> 18.25: uncial S (Vat.gr. 354, 949 CE); minuscule 1424 (Chicago Gruber 152, 9th/10th cent.); possibly minuscule 579 (Paris.gr. 97; illegible).</li>
</ul>

<p>All older manuscripts — including the ancient ones, like the Sinaiticus and Vaticanus manuscripts — invariably use <i>kamēlos</i>.</p>

<hr>

<h3>3. Sources that cite <i>kamilos</i> as an annotation to ‘camel’</h3>

<p>There are two sources in this category:</p>

<ol start="8" type="a">
  <li><span>Scholion on Aristophanes, <i>Wasps</i> <a href="https://archive.org/details/ScholiaGraecaInAristophanem/page/158/mode/2up">1035</a></span></li>
  <li><span><i>Souda</i> <a href="https://archive.org/details/adler-a.-suidae-lexicon-3-./Adler%20A.%2C%20Suidae%20Lexicon%203%20%28%CE%9A-%CE%9F.%20%CE%A9%29/page/n19/mode/1up">κ.282 κάμηλος</a> (<i><a href="http://www.cs.uky.edu/~raphael/sol/sol-entries/kappa/282">Suda on line</a></i>)</span></li>
</ol>

<p>These are both mediaeval. The Aristophanes scholia may go back to the early Byzantine period; the <i>Souda</i> encyclopaedia is 10th century.</p>

<p>I’ll quote the first one in full. The background is that in 422 BCE, the comic playwright Aristophanes made a joke about camels, describing a contemporary politician as having the smell of a seal, the testicles of a bogeyman, and the arsehole of a camel. About a millennium later, an anonymous scholar explains the joke as follows:</p>

<blockquote>
  <p><b>πρωκτὸν δὲ καμήλου·</b> θερμόπρωκτος γὰρ ἡ κάμηλος καὶ λάγνος. κάμιλος δὲ τὸ παχὺ σχοινίον διὰ τοῦ ι.</p>
  <p>‘(and he had) a camel’s arsehole’: the joke is that camels are hot-arsed and lewd. And a <i>kamilos</i> is the thick rope, with an i.</p>
</blockquote>

<p>Neither <b>h</b> nor <b>i</b> uses <i>kamilos</i> in a sentence. They only cite it lexicographically — as a footnote to talking about camels. In both sources, the commentator explains what the word means. That is, the word is rare enough that a scholarly reader cannot be expected to know it. And both definitions use Cyril’s exact phrase τὸ παχὺ σχοινίον (‘the thick rope’).</p>

<p>So these sources have no corroborative value either. <i>Kamilos</i> doesn’t get used in its own right, it’s purely an appendage to ‘camel’, and even more importantly, neither source is independent of Cyril.</p>

<hr>

<h3>4. Sources that use <i>kamilos</i> independently</h3>

<p>Finally we get to the one category of evidence that could in principle corroborate that <i>kamilos</i> is a real word. However, there’s only one source that <i>might potentially</i> fall into this category, and it’s really shaky:</p>

<ol start="10" type="a">
  <li><span><i>Inscriptions de Cilicie</i> <a href="https://epigraphy.packhum.org/text/285663?&amp;bookid=692&amp;location=1661">108</a>, col. ii line 5 (Dagron and Feissel 1987: 170–185)</span></li>
</ol>

<p>This is a 5th or 6th century CE inscription found near Anazarbos (Anavarza) and held at the Adana Archaeology Museum. The inscription is a list of tariffs for various freight goods. Here’s the start of column ii, with my translation:</p>

<blockquote>
  <p>
    [ . . . κ'] β<br>
    [     ]ι̣ο̣υ̣ γο' κ' α<br>
    κρόκου γο' κ' δ<br>
    γάρου γο' κ' α<br>
    μασσίνων καμηλ( ) κ' αγ'</p>
  <p>
    [ . . . ] 2 <i>keratia</i><br>
    [     ] — per load — 1 <i>keration</i><br>
    saffron — per load — 4 <i>keratia</i><br>
    garum — per load — 1 <i>keration</i><br>
    <i>massinoi</i> — per camel load — 1⅓ <i>keratia</i></p>
</blockquote>

<p>The fifth line is the relevant one. For discussion, see Dagron and Feissel (1987: 176–177). They supplement the text as μασσίνων καμήλ(ων), which they interpret as ‘thick ropes’.</p>

<p>The meaning of both <i>massin-</i> and <i>kamēl-</i> is questionable. Dagron and Feissel think <i>massinos</i> is an adjective relating to ropes, partly because of Cyril’s interpretation of <i>kamilos</i> (source <b>a</b> above); partly because of the Syrian author John Malalas (6th century), who refers to someone being tied up with a σχοῖνος μάσσινος or ‘<i>massinos</i> rope’; and the <i>Life of Symeon Stylites the Younger</i> (7th century?), which has the 6th century Syrian saint winding a μάσ(σ)ινον σχοινίον (‘<i>mas</i>(<i>s</i>)<i>inos</i> rope’) around his body. So in this inscription they regard <i>massinōn</i> as an adjective, modifying <i>kamēl</i>(<i>ōn</i>) ‘ropes’.</p>

<p><b>Note.</b> Malalas, <i>Chronographia</i> 7.12, p. 142,35 ed. Thurn (= <a href="https://archive.org/details/corpusscriptoru04berlgoog/page/186/mode/2up">p. 186,19–20</a> ed. Dindorf); <i>Life of Symeon Stylites the Younger</i> 26 ed. van den Ven. For the latter I rely on Dagron and Feissel’s report.</p>

<p>They <i>might</i> be right. However, first, the context doesn’t favour ‘rope’: lines 3 to 11 of the inscription appear to be foodstuffs — saffron, garum, possibly gourds, possibly fenugreek, garlic, wine, and so on.</p>

<p>Second, every other line gives the freight good in the genitive case, and an indication of quantity. So line 3 gives the tariff for a γόμος <i>of</i> saffron, line 4 for a γόμος <i>of</i> garum, and so on. In lines 16–17, the price is given per unit: the tariff <i>per</i> slave, <i>per</i> bovine. Why, then, is μασσίνων genitive plural? Where’s the indication of quantity? The most intuitive answer is that that’s what καμηλ(&nbsp;) is doing there. The correct supplement is μασσίνων καμηλ(ικός), ‘a camel load of <i>massinoi</i>’. The camel was the most commonly used beast of burden in Anatolia until the 20th century (Potts 2004; İnal 2020: 71), and Dagron and Feissel themselves point out that γόμος καμηλικός is standard phrasing in the famous Palmyra tariff inscription, alongside γόμος καρρικός ‘wagon load’ and γόμος ὀνικός ‘ass load’, and with a conversion rate of 1 wagon load = 4 camel loads. As for <i>massinoi</i>, its meaning is doubtful. Even if it really is an adjective, it’s completely normal for Greek to use an adjective as a substantive.</p>

<p>The argument for κάμηλος ‘rope’ in the Anarbazos inscription isn’t intuitive, it neglects the format of the tariff list, and it relies on Cyril’s testimony — so it begs the question of whether <i>kamilos</i> is even a real word.</p>

<p>Can we be certain that this <i>isn’t</i> an instance of <i>kamilos</i> ‘rope’? Not 100% certain, no — but this inscription certainly can’t take the weight of being the <i>sole independent use</i> of the word.</p>

<hr>

<h2>Summary</h2>

<p>The word <i>kamilos</i> ‘rope’ —</p>

<ul>
  <li>first appears in the 400s CE, more than three centuries after the gospels</li>
  <li>is vanishingly rare even after that date</li>
  <li>is never, ever used in a sentence by any ancient or mediaeval writer</li>
  <li>appears only in lexicographical contexts</li>
  <li>is always cited as an annotation either to camels, or to <i>Matthew</i> 19.24</li>
  <li>is always defined, because no reader can be expected to know its meaning</li>
  <li>is usually defined using Cyril of Alexandria’s phrasing</li>
</ul>

<p>The fact that <i>kamilos</i> normally appears in the context of camels or the gospel passages makes it look very much like that is its primary context.</p>

<p>That is: <i>kamilos</i> was coined specifically to contrive a variant interpretaion of the gospels.</p>

<p>And, by the way, that’s exactly what the Liddell &amp; Scott <i>Lexicon</i> suggested all along.</p>

<blockquote>
  Perh(aps) coined as an emendation of the phrase εὐκοπώτερόν ἐστι κάμηλον διὰ τρυπήματος ῥαφίδος διελθεῖν ... Ev.Matt. 19.24
  
</blockquote>

<p>(The Greek quotation is the ‘eye of a needle’ line in <i>Matthew</i>.)</p>

<p>The upshot is that <i>kamilos</i> is just like the ‘eye of the needle’ gate: it’s a fabrication, contrived specifically to make wealthy people happy about hoarding their wealth.</p>

<p>The only potential corroboration for its existence is source <b>j</b>, the Anarbazos inscription. There it’s part of a collocation where, <i>at best</i>, both words are unclear. I’ve argued above that καμηλ(&nbsp;) is a quantity, a καμηλ(ικός) or ‘camel load’, not a rope. Even if you disagree, still, the most the inscription can show is that <i>kamilos</i> existed as a hyper-rare word in 5th century Anatolia. Does it show anything about the 1st century? Absolutely not. The inscription is an obscure speculative possibility, not a corroboration for anything.</p>


<h2>What is it about camels, anyway?</h2>

<p>A rope through the eye of a needle would have been a <i>striking</i> choice of image. A camel is ... surreal.</p>

<p>As Zahn and many others have pointed out, it isn’t unique. It’s not a <i>common</i> expression, and the Christian gospels are its earliest appearance, but there are parallels in Rabbinic sources and in the Quran. The Rabbinic sources involve elephants, not camels, but still.</p>

<p>These parallels are late, like Cyril’s made-up word, so they’re not exactly overwhelming evidence. But they have one thing going for them that <i>kamilos</i> doesn’t: they use the expression <i>in the same way as</i> the gospels, not <i>as an annotation to</i> the gospels.</p>

<blockquote>
  <p>How will you know the thoughts of your heart? By their being revealed to you in a dream. Rava said: Know that this is the case, for one is neither shown a golden palm tree <b>nor an elephant going through the eye of a needle</b> in a dream. In other words, dreams only contain images that enter a person’s mind.</p>
  <p>Berakhot <a href="https://www.sefaria.org/Berakhot.55b.21?ven=William_Davidson_Edition_-_English&amp;lang=bi">55b.21</a></p>
  <p>Rav Sheshet said mockingly to him, employing a similar style: Perhaps you are from Pumbedita, <b>where people pass an elephant through the eye of a needle</b>, i.e., they engage in specious reasoning.</p>
  <p>Bava Metzia <a href="https://www.sefaria.org/Bava_Metzia.38b.16?ven=William_Davidson_Edition_-_English&amp;lang=bi">38b.16</a></p>
  <p>Surely those who receive our revelations with denial and arrogance, the gates of heaven will not be opened for them, nor will they enter Paradise <b>until a camel passes through the eye of a needle</b>.</p>
  <p>Quran <a href="https://quran.com/7?startingVerse=40">7.40</a></p>
</blockquote>

<p>Of these, the Rabbinic texts look like decent candidates for independent testimony. The Quran, less so: its version of the aphorism is almost identical to that in the gospels. The word used in Quran 7.40 is جمل <i>jamal</i> (‘camel’). Arabic dictionaries do record an alternate reading, with the word <i>jummal</i>, ‘rope’.</p>

<p>But don’t get excited. The only locus for <i>jummal</i> in the Arabic corpus is ... this exact verse in Sura 7.</p>

<blockquote>
  Some lexicographers wondered if <i>jummal</i> is a genuine Arabic word, and indeed it is used principally in speculation around Q 7:40. It is possible that Christian exegetical speculation surrounding the Greek word <i>kamēlos</i> influenced Muslim exegetical speculation surrounding the Arabic word <i>jamal</i> and led lexicographers to develop <i>jummal</i>, an equivalent of <i>kamilos</i>, as an alternative reading of <i>jamal</i>. What seems to confirm [this] ... is that, like Christian commentators, Muslim commentators report that the rope (<i>jummal</i>) in question is the sort used for seafaring.
  <p>Reynolds 2020: 49–50</p>
</blockquote>

<p>Cyril strikes again. Everything to do with ropes in this context — Greek <i>*kamilos</i>, Aramaic <i>*gml</i>, and Arabic <i>*jummal</i> — goes back to Cyril inventing a fake word to keep rich people happy.</p>


<h2>References</h2>

<ul>
  <li>Caspari, C. P. 1890. <i>Briefe, Abhandlungen und Predigten aus den zwei letzten Jahrhunderten des kirchlichen Alterthums und dem Anfang des Mittelalters</i>. Oslo [‘Christiania’]. [Internet Archive: <a href="https://archive.org/details/briefeabhandlun00caspgoog/page/n9/mode/2up">1</a> <a href="https://archive.org/details/briefeabhandlung00caspuoft/briefeabhandlung00caspuoft/page/n5/mode/2up">2</a> <a href="https://archive.org/details/briefeabhandlun01caspgoog/page/n7/mode/2up">3</a>]</li>
  <li>Dagron, G.; Feissel, D. 1987. <i>Inscriptions de Cilicie</i>. Paris.</li>
  <li>Henry, A. M. 2022. ‘The camel and needle: did scholars mistranslate Jesus’s famous saying?’ ReligionForBreakfast. [<a href="https://www.youtube.com/watch?v=sf0Fm8aVApk">YouTube</a>]</li>
  <li>İnal, O. 2020. ‘One-humped history: the camel as historical actor in the late Ottoman Empire.’ <i>International Jounal of Middle East Studies</i> 53: 57–73. [<a href="https://doi.org/10.1017/S0020743820000987">DOI</a>]</li>
  <li>Kessler, A. 1999. <i>Reichtumskritik und Pelagianismus. Die pelagianische Diatribe de divitiis: Situierung, Lesetext, Übersetzung, Kommentar</i>. Freiburg/Fribourg (Switzerland).</li>
  <li>Khalil, S. 1978. ‘Note sur le fonds sémitique commun de l’expression “un chameau passant par le trou d’une aiguille”.’ <i>Arabica</i> 25: 89–94. [<a href="https://www.jstor.org/stable/4056713">JSTOR</a>]</li>
  <li>Klostermann, E. 1941. <i>Origenes Werke. Zwölfter Band. Origenes Matthäuserklärung iii. Fragmente und Indices. Erste Hälfte</i>. (Griechischen Schriftsteller der ersten drei Jahrhunderte). Leipzig. [<a href="https://archive.org/details/origenes-werke.-bd.-12.1-1941/page/n3/mode/2up">Internet Archive</a>]</li>
  <li>McCollum, A. C. 2015. ‘A camel or a rope in the eye of a needle? The Old Georgian witness.’ <a href="https://hmmlorientalia.wordpress.com/2015/07/23/a-camel-or-a-rope-in-the-eye-of-a-needle-the-old-georgian-witness/">hmmlorientalia</a> (23 Jul 2015).</li>
  <li>Metzger, B. M.; Ehrman, B. D. 2005. <i>The text of the New Testament. Its transmission, corruption, and restoration</i>, 4th ed. Oxford.</li>
  <li>Neumann, K. J. 1880. <i>Iuliani imperatoris librorum contra Christianos quae supersunt</i>. Leipzig. [<a href="https://archive.org/details/iulianiimperato00neumgoog/page/n6/mode/2up">Internet Archive</a>]</li>
  <li>Pirtea, A. C. 2021. ‘To pass a rope through the eye of a needle: the influence of Byzantine catenae and homiliaries on the Greek, Church Slavonic, and Old Romanian readings of Matthew 19,24.’ In: Jouravel, A.; Mathys, A. (eds.) <i>Wort- und Formenvielfalt. Festschrift für Christoph Koch zum 80. Geburtstag</i>. Berlin. 327–352. [<a href="https://www.academia.edu/48915456/To_Pass_a_Rope_through_the_Eye_of_a_Needle_The_Influence_of_Byzantine_Catenae_and_Homiliaries_on_the_Greek_Church_Slavonic_and_Old_Romanian_Readings_of_Matthew_19_24">Academia.edu</a>]</li>
  <li>Potts, D. T. 2004. ‘Camel hybridization and the role of <i>Camelus bactrianus</i> in the ancient Near East.’ <i>Journal of the Economic and Social History of the Orient</i> 47.2: 143–165. [<a href="https://www.jstor.org/stable/25165032">JSTOR</a>]</li>
  <li>Reuss, J. 1957. <i>Matthäus-Kommentare aus der griechischen Kirche</i>. Berlin. [<a href="https://archive.org/details/matthauskommenta0061reus/page/n5/mode/2up">Internet Archive</a>]</li>
  <li>Reynolds, G. S. 2020. ‘Biblical turns of phrase in the Quran.’ In: Elias, J. J.; Orfali, B. (eds.) <i>Light upon light. Essays in Islamic thought and history in honor of Gerhard Böwering</i>. Leiden/Boston. 45–69.</li>
  <li>Zahn, Th. 1922. <i>Kommentar zur Neuen Testament. Band I: das Evangelium des Matthäus</i>, 4th ed. Leipzig/Erlangen. [<a href="https://archive.org/details/dasevangeliumdes0000zahn_g1d0/page/n5/mode/2up">Internet Archive</a>]</li>
  <li>Ziemińska, A. 2022. ‘The origin of the “Needle’s Eye Gate” myth: Theophylact or Anselm?’ <i>New Testament Studies</i> 68: 358–361. [<a href="https://doi.org/10.1017/S0028688521000448">DOI</a>]</li>
</ul>

<p>Image sources: camel, <a href="https://commons.wikimedia.org/wiki/File:Headshot_of_a_camel.jpg" rel="nofollow">Wikimedia Commons</a>, CC BY-SA 4.0; needle, <a href="http://www.ancientresource.com/" rel="nofollow">www.ancientresource.com</a>; facsimiles of Paris.gr. 50, <a href="https://manuscripts.csntm.org/manuscript/View/GA_13">CSNTM</a>; Vat.gr. 354, <a href="https://digi.vatlib.it/view/MSS_Vat.gr.354">Apostolic Library</a>.</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[SDXL Turbo: A Real-Time Text-to-Image Generation Model (144 pts)]]></title>
            <link>https://stability.ai/news/stability-ai-sdxl-turbo</link>
            <guid>38450390</guid>
            <pubDate>Tue, 28 Nov 2023 19:56:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://stability.ai/news/stability-ai-sdxl-turbo">https://stability.ai/news/stability-ai-sdxl-turbo</a>, See on <a href="https://news.ycombinator.com/item?id=38450390">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-block-type="2" id="block-yui_3_17_2_1_1701191961235_4127">
  <p>Today, we are releasing SDXL Turbo, a new text-to-image mode. SDXL Turbo is based on a novel distillation technique called Adversarial Diffusion Distillation (ADD), which enables the model to synthesize image outputs in a single step and generate real-time text-to-image outputs while maintaining high sampling fidelity. For researchers and enthusiasts interested in technical details, our research paper is available <a href="https://stability.ai/research/adversarial-diffusion-distillation"><span>here</span></a>. It's important to note that SDXL Turbo is not yet intended for commercial use.</p><p><strong>Advantages of Adversarial Diffusion Distillation</strong></p><p>Featuring new advancements in diffusion model technologies, SDXL Turbo iterates on the foundation of SDXL 1.0 and implements a new distillation technique for text-to-image models: Adversarial Diffusion Distillation. By incorporating ADD, SDXL Turbo gains many advantages shared with GANs (Generative Adversarial Networks), such as single-step image outputs, while avoiding artifacts or blurriness often observed in other distillation methods. The SDXL Turbo research paper detailing this model’s new distillation technique is available <a href="https://stability.ai/research/adversarial-diffusion-distillation" target="_blank"><span>here</span></a>.</p><p><strong>Performance Benefits Compared to Other Diffusion Models</strong></p><p>To make the selection for SDXL Turbo, we compared multiple different model variants&nbsp;(StyleGAN-T++, OpenMUSE, IF-XL, SDXL, and LCM-XL) by generating outputs with the same prompt. Human evaluators were then shown two outputs at random and tasked to pick the output that most closely followed the direction of the prompt. Next, an additional test was completed with the same method for image quality. In these blind tests, SDXL Turbo was able to beat a 4-step configuration of LCM-XL with a single step, as well as beating a 50-step configuration of SDXL with only 4 steps. With these results, we can see SDXL Turbo outperforming a state-of-the-art multi-step model with substantially lower computational requirements without sacrificing image quality.&nbsp;&nbsp;</p>
</div><div data-block-type="2" id="block-yui_3_17_2_1_1701191961235_6047">
  <p>Additionally, SDXL Turbo provides major improvements to inference speed. On an A100, SDXL Turbo generates a 512x512 image in 207ms (prompt encoding + a single denoising step + decoding, fp16), where 67ms are accounted for by a single UNet forward evaluation.</p><p><strong>Explore SDXL Turbo with Clipdrop</strong></p><p>To test the capabilities of this new model, visit Stability AI's image editing platform, <a href="http://clipdrop.co/stable-diffusion-turbo" target="_blank"><span>Clipdrop,</span></a> for a beta demonstration of SDXL Turbo's real-time image generation. It's compatible with most browsers and is currently available to try for free.</p><p><strong>Commercial Applications</strong></p><p>If you want to use this model for your commercial products or purposes, please contact us <a href="https://stability.ai/contact"><span>here</span></a> to learn more. </p><p>You can also stay updated on our progress by signing up for our <a href="https://stability.ai/home#newsletter"><span>newsletter</span></a>, following us on <a href="https://twitter.com/stabilityai" target="_blank"><span>Twitter</span></a>, <a href="https://www.instagram.com/stability.ai/" target="_blank"><span>Instagram</span></a>, <a href="https://www.linkedin.com/company/stability-ai" target="_blank"><span>LinkedIn</span></a>, and joining our <a href="https://discord.gg/stablediffusion" target="_blank"><span>Discord Community</span></a><span>.</span></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Most AI startups are doomed (155 pts)]]></title>
            <link>https://weightythoughts.com/p/most-ai-startups-are-doomed</link>
            <guid>38450087</guid>
            <pubDate>Tue, 28 Nov 2023 19:28:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://weightythoughts.com/p/most-ai-startups-are-doomed">https://weightythoughts.com/p/most-ai-startups-are-doomed</a>, See on <a href="https://news.ycombinator.com/item?id=38450087">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h4 translated="">Discover more from Weighty Thoughts</h4><p>Commentary on Deep Tech, AI, and Startups</p> </div><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90ba5fdf-3ccf-4186-b338-e6a438a00917_1400x1000.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90ba5fdf-3ccf-4186-b338-e6a438a00917_1400x1000.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90ba5fdf-3ccf-4186-b338-e6a438a00917_1400x1000.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90ba5fdf-3ccf-4186-b338-e6a438a00917_1400x1000.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90ba5fdf-3ccf-4186-b338-e6a438a00917_1400x1000.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90ba5fdf-3ccf-4186-b338-e6a438a00917_1400x1000.png" width="1400" height="1000" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/90ba5fdf-3ccf-4186-b338-e6a438a00917_1400x1000.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1000,&quot;width&quot;:1400,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:615796,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90ba5fdf-3ccf-4186-b338-e6a438a00917_1400x1000.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90ba5fdf-3ccf-4186-b338-e6a438a00917_1400x1000.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90ba5fdf-3ccf-4186-b338-e6a438a00917_1400x1000.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90ba5fdf-3ccf-4186-b338-e6a438a00917_1400x1000.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p><span>The statement that most AI startups are doomed can be fairly mundane. After all, </span><em>most</em><span> </span><em>startups</em><span> are doomed, </span><a href="https://www.bls.gov/bdm/us_age_naics_00_table5.txt" rel="">just by the numbers</a><span>.</span></p><p>I’m trying to say something more provocative. Almost all startups formed from post-ChatGPT hype and who specifically label themselves as “AI startups” are doomed.</p><p>Now, I am a VC who has been investing in AI for a long time—and, in fact, originally left the hedge fund world because I saw so much happening in AI. So, I’m definitely not an AI skeptic.</p><p>That being said, I fundamentally think most of what’s getting funded in the current hype cycle is valueless from an investor’s perspective.</p><p>Let’s tackle the easiest case.</p><p><span>I’ve met numerous startups who essentially glue together a few generative AI APIs, do some prompt engineering, and slap a front-end user interface on it. Some of these products are </span><em>quite</em><span> impressive in terms of polish and what they can do.</span></p><p><span>These companies are also all doomed to either be perfectly ok businesses (but not </span><a href="http://www.paulgraham.com/growth.html" rel="">startups, by Paul Graham’s classic definition</a><span>) or die.</span></p><p><span>Obviously, if you built it over a weekend, someone else can do the same. Now, let’s say you’re a coding genius. A veritable 10X programmer prodigy! It might take everyone else in the world </span><em>several</em><span> weekends… but it’s going to get built.</span></p><p>If you basically give your project’s product away for free and are just having fun, no big deal.</p><p>However, if you start charging for it and customers start relying on it a lot, others can come in and just slightly undercut you. Maybe yours is still nicer. Being nicer does often drive product adoption and choice of one over another.</p><p>But if it’s actually important (i.e., commands a high willingness to pay and is used frequently), this is where the curse of economics and competition come into play. People are going to copy you and compete away your profits.</p><p>No defensibility and no differentiation = no profits. That’s basic economics.</p><p>Ok, so that was Econ 101 and also Startup 101. It’s not particularly unique to this area. Every hype cycle is essentially characterized by people forgetting that these rules exist, and then rediscovering them to their chagrin at the end of the cycle.</p><p><span>However, note that I’ve mainly been talking about these startups that just glue together APIs like those from ChatGPT together into UIs. </span><em>Those</em><span> obviously have very little differentiation and defensibility. Even if your UI is nicer, someone else can just come along and copy it.</span></p><p>My point is broader than just those trivial examples, though.</p><p>Let’s now apply this same logic to the underlying technology itself for LLMs like ChatGPT, Bard, LlaMA, and the like.</p><p><span>If I told you I had a fantastic technology that </span><em>everyone</em><span> will want to use, and to create it, what I had to do was:</span></p><ol><li><p>Gather all the text on the internet</p></li><li><p>Train it all using tons of GPUs and millions of dollars</p></li><li><p>Built it on well-known technologies, most of which are open-source</p></li></ol><p><span>Is that defensible? Point 1 and 2 might have some level of technical or logistical difficulty for small startups, but neither of those are particular insurmountable for other large companies—especially when combined with the fact of Point 3. All of these things are built on the same underlying architecture in transformers and LLMs. </span><strong>These LLMs have no real moat. Any large internet company can replicate them.</strong></p><p><span>And, indeed, </span><a href="https://www.semianalysis.com/p/google-we-have-no-moat-and-neither" rel="">even Alphabet/Google internally have said this</a><span>.</span></p><p>The same applies for all image and video generative AIs. Just replace Point 1 with either images or video instead (side note: video may be an exception if Alphabet can choke off easy access to YouTube).</p><p>Ok, so we’ve established that it’s not super useful to just build an API in front of other people’s technologies (our trivial case). We’ve now also talked about why the less trivial case of LLMs is fundamentally indefensible.</p><p><span>What if I flex Point 3 above, and come up with the </span><em>best version of an LLM</em><span>? Or something like it in terms of some other field of AI?</span></p><p><span>Well, in theory, that’s interesting. Except, of course, for the fact of how fast the technological frontier of </span><em>the entire industry</em><span> is moving.</span></p><p><span>What if I told you in the 1990s that I had </span><em>the best</em><span> CPU? Mine is, like, 3 times the speed of Intel!</span></p><p><span>Given the expense and incredible difficulty of developing a CPU, that is indeed quite technically impressive! Of course, then the question is, can you repeat that feat year after year? Because your problem is, given how fast semiconductor technologies are moving at the time (Moore’s Law), you have an advantage for a year or two (maybe). Intel—and everyone else—will equal your performance. If you have some special sauce that lets you </span><em>continuously</em><span> stay ahead, that’s one thing, but more likely than not, you simply stumbled on a particular set of optimizations that everyone else will adopt quickly.</span></p><p>The same issue exists in AI today. The frontier is moving too fast, and the frontier of the entire AI academic and industry research community almost certainly has more firepower than your single company.</p><p>By the way, when we’re talking about firepower, this challenge applies even at the most massive scales. For example, China—by all quiet, anecdotal accounts—is not keeping up with the global (concentrated in the US) research community in the speed of AI development. Basically, everyone who branches off proprietary models falls behind quickly and ends up adopting the global state-of-the-art anyway. AI is just even worse than semiconductors because all of it tends to be open source, which just makes it even harder to hold any sort of long-standing advantage in algorithmic prowess.</p><p>As such, you don’t get any lasting value unless you’re able to make that year or two advantage actually count in building a lasting moat—which, if you think about it, is actually extremely hard.</p><p>Ok, so we’ve gone through this process of elimination. What’s actually left?</p><p><span>Well, you can either have something that’s so compute intensive that only you could possibly do the training or inference economically. That is unlikely, in my opinion, </span><a href="https://weightythoughts.com/p/compute-is-overrated-as-ais-bottleneck" rel="">given how AI has progressed in bringing down the quantity of data and compute required to achieve a certain result</a><span>. However, note that my opinion is somewhat unpopular. You can decide for yourself whether this point is true (which I talk about in the linked article above). However, least from an investor’s perspective, even if it </span><em>is</em><span> a true advantage, I’m uncertain whether I’m thrilled about a startup strategy to accumulate more GPUs/ASICs/FPGAs than Google, Facebook, Baidu, what have you…</span></p><p><span>Secondly, you can be operating in a place where you </span><em>can’t</em><span> simply harvest the data off the internet. For example, healthcare data that is siloed in hospitals, or not even collected at all today. Or, protein folding or pharmacokinetic reaction data that has to be painstakingly collected through real-world experiments. Or a ton of other things… all of which share the characteristic that it doesn’t exist in the pure digital world and can’t simply be scraped off the internet.</span></p><p><em>That</em><span> is where I see the value of most of AI startups being generated. Places where you can’t simply decide to go collect the data without prohibitive cost, time, and simply physical world messiness. These startups can simply ride the wave of AI improvements—it doesn’t matter, the algorithms are all commoditized anyway—but are the only ones who own and hold that proprietary, next-to-impossible to get real-world data.</span></p><p><span>Note, I mentioned </span><strong>startups</strong><span>. Many forget that just because value is created on a societal level, that doesn’t necessarily mean that the value is captured by a company at all. The Internet boom in the 1990s created tons of networking infrastructure, but the companies realized massively negative ROI from their investments. It was great for bringing communities online though, but that’s a societal benefit, not a company ROI.</span></p><p><span>In a more recent case, did you know that Azure actually runs </span><a href="https://azure.microsoft.com/en-us/solutions/web3" rel="">tons of private blockchains</a><span>? It’s hard to actually break out on their financial results for various reasons, but many large companies run this stuff on Azure, making Microsoft one of the big winners in blockchain. (Yes, there’s a separate question of whether a private blockchain is really any different from, say, a database. But that’s irrelevant to my point here.)</span></p><p><span>The same thing is likely to happen with OpenAI, </span><a href="https://openai.com/blog/openai-and-microsoft-extend-partnership" rel="">where OpenAI mostly looks like an R&amp;D lab for Microsoft</a><span>. Microsoft provides the computing resources in Azure, and in return, OpenAI develops the tools that Azure will then provide as hosted services. Azure can then make a bunch of money from ChatGPT and other stuff that can be pay-as-you-go API calls. This, of course, also looks the same with Bard and Google Cloud Compute, etc. as we go.</span></p><p><span>This principle runs through most of the AI sector today. There’s going to be a </span><em>lot</em><span> of value generated that just accrues to society, and isn’t captured by any private player. Which is wonderful, by the way—this is how technology becomes one of the few “free lunches” we have in society and macroeconomics.</span></p><p>There’s also going to be a lot of value generated that is simply captured by existing industry incumbents, using their market power and scale. That’s not a free lunch for society, but is also just how capitalism works and often still generates “surplus” (Econ speak for “good stuff”) for society.</p><p><span>Finally, there’s a fairly </span><em>narrow</em><span> slice that will be both value generated, and accrue to new, young companies, that ideally then can come along and replace the incumbents (which is how healthy market turnover happens).</span></p><p><strong>Those</strong><span> are the companies that will generate outsized returns and become tomorrow’s well-known tech names—and, of course, are what VCs are theoretically looking for. In reality, most investors are being a bit more indiscriminate in slinging money at AI startups (and even big, public companies that claim to have an “AI strategy”) right now. And, as such, are mostly flushing money down the drain.</span></p><p>AI is going to change the world. But most AI startups are doomed.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Undercover in Saudi Arabia's secretive program to keep the world burning oil (135 pts)]]></title>
            <link>https://climate-reporting.org/undercover-saudi-arabia-keep-burning-oil/</link>
            <guid>38449941</guid>
            <pubDate>Tue, 28 Nov 2023 19:14:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://climate-reporting.org/undercover-saudi-arabia-keep-burning-oil/">https://climate-reporting.org/undercover-saudi-arabia-keep-burning-oil/</a>, See on <a href="https://news.ycombinator.com/item?id=38449941">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
			<!-- side content -->
			<section>
				<!-- left -->
				<p>Crown Prince Mohammed bin Salman and his energy minister, Prince Abdulaziz bin Salman (background), oversee the Oil Demand Sustainability Program. Photo: MANDEL NGAN / AFP</p>

				<!-- right -->
				<div>
																					<div x-data="{ open: false }">

										<p>
												Lawrence is an investigative journalist whose work has primarily focused on the connections between climate change, political influence and dark money. He has investigated Big Oil's war on US climate policy, fossil fuel-funded climate sceptics, and the petrostates seeking to keep the world hooked on oil. His 2021 undercover investigation into ExxonMobil’s obstruction of US climate policy led to two major Congressional inquiries. Lawrence’s work has been featured in the New York Times; Washington Post; Wall Street Journal; CNN; BBC; Financial Times; O Globo and others.											</p>
																			</div>
															<div x-data="{ open: false }">

										<p>
												Tom is a BAFTA-winning journalist and documentary filmmaker. He has filmed, produced and directed films for major broadcasters including the BBC, Channel 4, ARD, ARTE and VICE. He has investigated narco gangs in Mexico, Britain’s far-right street movements, vigilantes, underground animal rights activists and clandestine drug producers. He has conducted agenda-setting undercover investigations into corporate tax avoidance, dirty Russian money in London real estate, dark money in British politics and fossil fuel lobbying. His films have been featured in the Guardian, New York Times, Times of London, Daily Mail, Financial Times and others.											</p>
																			</div>
													
						<hr>

						<p>November 27, 2023</p>

						

													<p>This story is published in collaboration with Channel 4 News</p>
							
											</div>
			</section>

							
											<div>
									<p>Saudi Crown Prince Mohammed bin Salman is overseeing a sweeping global investment program designed to counteract the world’s efforts to reduce demand for oil and tackle climate change, according to an undercover investigation by the Centre for Climate Reporting.</p>
<p>The program, which is chaired by the Crown Prince and his energy minister, Prince Abdulaziz bin Salman, aims to boost oil consumption across Asia and Africa, with the ultimate goal of protecting Saudi oil revenues from efforts to phase out fossil fuels.</p>
<p>Saudi Arabia publicly claims to support the Paris climate change agreement, which aims to limit global temperature increases to 1.5C or 2C – requiring an almost total transformation of the way in which the world produces and consumes energy. The Crown Prince, also known as MBS, has said that the Kingdom needs to go “further and faster” in tackling climate change.</p>
<p>But an undercover investigation by the Centre for Climate Reporting (CCR) reveals how, in private, the Kingdom is seeking to ensure that emerging economies across Africa and Asia become vastly more dependent on oil, not less.</p>
<p>The Oil Demand Sustainability Program (OSP) is a vast government program with dozens of projects aimed at embedding a high-carbon, fossil fuel-dependent development model in countries across Africa and Asia. This includes meticulously researched plans to drive a major increase in gasoline and diesel-fuelled vehicles and boost jet fuel sales via increased air travel.</p>
<blockquote><p>&nbsp;“There’s a fundamental policy aim, which is to burn and exploit all Saudi’s oil reserves until the last drop”</p></blockquote>
<p>It brings together the most powerful arms of the Saudi state, including the $700 billion Saudi Public Investment Fund; the world’s largest oil company, Saudi Aramco; petrochemicals giant, Sabic; and the Kingdom’s most important ministries – all under the auspices of the Crown Prince’s supreme committee of hydrocarbon affairs.</p>
<p>When asked by an undercover reporter whether the aim of the program is to artificially stimulate oil demand to counter global efforts to reduce oil consumption and tackle climate change, a Saudi official responded: “Yes… it is one of the main objectives that we are trying to accomplish.”</p>
<p>Following a six-month investigation, the Centre for Climate Reporting can – for the first time – reveal MBS’ secret plans to keep the world hooked on oil, even as the devastating impacts of global warming are beginning to bite.</p>
<p>The investigation, based on secret recordings, documents provided by Saudi officials to undercover reporters, and an analysis of regulatory filings, reveals:</p>
<ul>
<li>A sophisticated strategy to deploy fleets of petrol and diesel-fuelled vehicles across Asia and Africa so that Saudi Arabia can “capture the increasing gasoline/diesel demand.”</li>
<li>Plans to collaborate with an undisclosed global auto manufacturer to develop and produce a cheap car that can be sold in emerging markets to give “an oil uplift for the kingdom.”</li>
<li>Plans to fast-track commercial supersonic air travel, explicitly because it consumes three times more jet fuel than normal aircraft.</li>
<li>A plan to lobby against government subsidies for electric vehicles in countries around the world.</li>
<li>Plans to encourage the use of toxic heavy fuel oil to generate power in Africa and South Asia.</li>
</ul>
<p>Responding to the investigation, Mohamed Adow, director of Power Shift Africa, a non-governmental organisation based in Nairobi focused on climate change, told CCR: “The Saudi government is like a drug dealer trying to get Africa hooked on its harmful product. The rest of the world is cleaning up its act and weaning itself off dirty and polluting fossil fuels and Saudi Arabia is getting desperate for more customers and is turning its sights on Africa.”</p>
<p>“It’s like the tobacco companies that knew the addictive and lethal nature of cigarettes yet continued to get millions of teenagers hooked on them,” Adow said, “it’s repulsive”.</p>
<p>Akinbode Oluwafemi, executive director of Corporate Accountability and Public Participation Africa (CAPPA), a civil society organisation headquartered in Lagos, told CCR that Africa needs “infrastructure that will reduce carbon emissions and not exacerbate the climate crisis.”</p>
<p>“This Saudi model is a Greek gift that will further sink Africa into climate catastrophe,” Oluwafemi said.</p>
<p>The Saudi Arabia energy ministry did not respond to a request for comment.</p>
								</div>

					
				
											<div>
																				<div>
												<p><img src="https://climate-reporting.org/wp-content/uploads/2023/11/GettyImages-1236065156.jpg" alt=""></p>
											</div>
																				<p>Saudi Crown Prince Mohammed bin Salman delivers a speech during the opening ceremony of the Saudi Green Initiative forum on October 23, 2021. (Photo by Fayez Nureldine / AFP via Getty)</p>
										</div>

					
				
											<div>
																	<h2>Climate leader</h2>
								
								<div>
									<p>Speaking at the<a href="https://saudigazette.com.sa/article/604892"> launch of the Saudi Green Initiative</a> in March 2021, Saudi Crown Prince Mohammed bin Salman, also known as MBS, said the Kingdom would become a leader on climate change. He pledged to reduce Saudi emissions to net zero by 2060 and to play a leading role internationally to tackle climate change.</p>
<p>“The Kingdom, the region and the world needs to go much further and faster in combating climate change,” MBS said, “Young people, both in the kingdom and the world, are demanding a cleaner, greener and more inclusive future, and we owe it to them to deliver on this.”</p>
<blockquote><p>“OSP’s goal is to support the deployment of&nbsp; internal combustion engine fleets across developing countries”</p></blockquote>
<p>Since then, the Kingdom has gone to great lengths to promote these commitments, with<a href="https://www.youtube.com/watch?v=hNPQPo8-jNk"> glossy promotional videos</a> claiming the country is “leading the charge in tackling energy and climate challenges.”</p>
<p>Joanna Depledge, a Research Fellow at the University of Cambridge who has authored academic papers on Saudi climate obstruction, told CCR that, despite a recent shift in tone, little has changed in the way Saudi Arabia approaches the climate change: “There’s everything you can possibly do except for reducing oil and gas production and consumption. Every single trick in the book.”</p>
<p>“It’s all part of the delay,” Depledge said, “I think basically there’s a fundamental policy aim, which is to burn and exploit all Saudi’s oil reserves until the last drop. That’s what they plan to do but that involves, obviously, a delaying of the climate change agenda and that’s what they’re doing. And all this can help to delay it.”</p>
<p>At the same time as developing the Saudi Green Initiative, MBS has overseen the development of a program designed to reverse global progress on phasing out oil, something scientists say is crucial if the world is to avoid the worst impacts of climate change.</p>
								</div>
							</div>

					
				
											<div>
																	<h2>Sustainable development</h2>
								
								<div>
									<p>Only a small amount of information about the Oil Demand Sustainability Program (OSP) is publicly available. On its website and social media channels, the Saudi energy ministry largely characterises the OSP as a sustainable development initiative aimed at providing energy access to emerging economies.</p>
<p>Regulatory filings seen by CCR suggest that this characterisation is part of a deliberate strategy to avoid public communications that might suggest the program’s primary aim is to boost Saudi oil sales. Filings on the Saudi stock exchange show that a May announcement of a deal between OSP and another state entity, the Saudi Industrial Export Company, was corrected because it accidentally referred to boosting oil demand, rather than fostering energy access.</p>
<p>In the first version of the announcement, the objective of the partnership was described as being “sustaining the demand of oil.” A day later a correction was issued, with this wording removed and replaced with “increase energy access.”</p>
								</div>
							</div>

					
				
											<div>
												<p><img src="https://climate-reporting.org/wp-content/uploads/2023/11/COMPARISON-VERTICAL.png" alt=""></p>
											</div>

					
				
											<div>
									<p>CCR also found significant differences in the way the program is presented to English and Arabic speaking audiences, including its name. The English version of the Saudi energy ministry website states that the initiative is called the “Oil Sustainability Program” and says its mission is to ensure that “hydrocarbons remain part of the global energy mix in the most efficient and sustainable way.”</p>
<p>On the Arabic version of the website, the word sustainable appears to have a completely different meaning. The initiative is called برنامج استدامة الطلب على البترول which translates to “Oil Demand Sustainability Program.” It says its purpose is to “sustain and develop the demand for hydrocarbons” and ensure “that the transition in the energy mix takes place in an effective manner, sustainable for the Kingdom of Saudi Arabia.”</p>
								</div>

					
				
											<div>
																	<h2>Cape Town</h2>
								
								<div>
									<p>In May 2023, Mohammed Al Tayyar, head of the OSP, took to the stage at the annual conference of the African Refiners &amp; Distributors Association, a members-only event in the suburbs of Cape Town. He came with a message for the assembled politicians and oil executives: “come and work with us.”</p>
<p>According to documents and audio recordings obtained by CCR, Al Tayyar travelled to South Africa to pitch OSP as a sustainable development solution to Africa’s infrastructure problems, explaining how Saudi Arabia could help increase access to energy and facilitate investment in roads, airports, and the cars and planes to make use of them.</p>
<blockquote><p>“We are actually conducting some studies to understand the psychological behaviour of these countries”</p></blockquote>
<p>Al Tayyar said that his team had developed forty-six projects, or “opportunities,” and hundreds of pages of business development strategy. The plan, he said, is to engage with stakeholders, ranging from governments and companies to international investment funds, to make them a reality.</p>
<p>Following the Cape Town conference, undercover journalists for the Centre for Climate Reporting contacted the OSP officials who had travelled to South Africa to set up a meeting. The aim was to find out more about a program which, on the surface, appears to be about helping countries in Africa and Asia to grow their economies, but which appeared to be oriented around solutions that benefit the Saudi economy.</p>
								</div>
							</div>

					
				
											<div>
																	<h2>The pitch</h2>
								
								<div>
									<p>Posing as international investors interested in funding some of the projects identified by Al Tayyar, CCR reporters attended a remote video conference with Saudi officials in Riyadh, who pitched the program’s key projects as potential areas for collaboration. During this private pitch, Saudi officials presented a different image of the OSP, based on slides not shown by Al Tayyar in Cape Town, which revealed an overriding objective to boost sales of Saudi oil.</p>
<p>The OSP officials detailed a vastly ambitious scheme, with plans to channel investment into ports, airports and roads across Asia and Africa, while ensuring that the ships, aeroplanes, cars and buses that use this infrastructure are powered by Saudi oil rather than cleaner forms of energy.</p>
<p>One of the officials, Nawaf Al-Fallaj, told the undercover reporters that the program’s forty-six projects had been selected from an initial batch of eighty, based partly on the scale to which they could boost oil demand, something he described as their “incremental demand potential”. He added that Saudi Arabia plans to deploy its sovereign wealth funds and diplomatic influence to make these projects a reality.</p>
<p>A slide deck shared on the call states that the strategy underpinning the program is to “unlock demand in emerging markets.” Undercover reporters asked the officials on the call if the aim is to artificially stimulate demand in emerging markets in order to offset a decline in oil demand due to efforts to tackle climate change. “Yes”, Al-Fallaj replied, “it’s one of the main objectives that we are trying to accomplish.”</p>
								</div>
							</div>

					
				
											<div>
								<p><iframe src="https://player.vimeo.com/video/888723692?badge=0&amp;autopause=0&amp;quality_selector=1&amp;player_id=0&amp;app_id=58479" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" title="ACCOMPLISH"></iframe></p>							</div>

					
				
											<div>
																	<h2>Increasing demand</h2>
								
								<div>
									<p>At the heart of the program is a plan to make sure that people around the world continue to drive diesel and petrol fuelled vehicles rather than switching to electric.</p>
<p>Saleh Aldayel, one of the OSP officials on the call, told undercover reporters that the plan is to facilitate investment in highways across Africa and Asia and to then fill these roads with vehicles that depend on oil. “In [the] case of roads, we aim to accelerate and enhance the impact and adoption of internal combustion engine technology,” Aldayel said</p>
<p>OSP officials were explicit about why Saudi Arabia wants to increase the number of oil-fuelled vehicles on the road, a slide deck shared by Aldayel states: “OSP’s goal is to support the deployment of ICE [internal combustion engine] fleets across developing countries to capture the increasing gasoline/diesel demand.”</p>
<p>This includes the development of ride hailing companies and local and regional bus companies. “OSP’s goal is to support the deployment of bus transportation across developing countries to capture the increasing diesel demand,” the presentation states.</p>
<p>Crucially, OSP officials said that they are in discussions with an undisclosed global auto manufacturer to develop cheap mass market cars that run on petrol or diesel and can be sold at scale in emerging markets. This would, Aldayel’s presentation says, “have an oil uplift for the kingdom.”</p>
<p>Aldayel explained there is “an opportunity for increasing availability and adoption of low-cost cars, especially in emerging markets.” This could, he said, either be through a joint venture with a car manufacturer or via micro-financing.</p>
								</div>
							</div>

					
				
											

					
				
											<div>
									<p>When undercover reporters asked for more information about the program, such as the scale of investment OSP would be undertaking and how much more oil Saudi Arabia wants to sell, they were told they would need to sign a non-disclosure agreement. But the Saudi officials did outline the detailed work that is going into the project, including psychological studies in emerging economies and mapping existing infrastructure in order to best target markets with cheap oil-fuelled vehicles.</p>
<p>“We are actually conducting some studies to understand the psychological behaviour, the infrastructure readiness of these countries, what type of cars are possible to be deployed there and even the financial capabilities of certain countries,” Aldayel said.</p>
<p>“So, it’s different from country to country. You can deploy two-wheelers in some countries, in other countries or other regions, you cannot go with the two-wheelers you have to have 4×4 cars, the smaller ones, the ones that are cheaper with not the advanced features that is more appealing for more developed countries,” he continued, “and we build a model that suits that country.”</p>
								</div>

					
				
											<div>
								<p><iframe src="https://player.vimeo.com/video/888623215?badge=0&amp;autopause=0&amp;quality_selector=1&amp;player_id=0&amp;app_id=58479" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" title="17_WEB_zoom_screen"></iframe></p>							</div>

					
				
											<div>
																	<h2>Unfair</h2>
								
								<div>
									<p>OSP officials also made it clear that Saudi Arabia sees the spread of electric vehicles (EVs) as a threat. They complained that EVs are being favoured with subsidies and other “regulatory advantages” and suggested that they might not even be better for the climate than internal combustion engine vehicles (ICEV).</p>
<p>“You know the situation that EVs are being favoured in terms of subsidies and regulatory advantage, irrespective of the actual economic and environmental competitiveness,” Aldayel said, “what we are working on is to support, to increase internal combustion engine adoptions… promoted through fair policies by working with regulators and industry leaders.”</p>
<p>The presentation shared by OSP officials claims that “global emissions regulations can be met by improved internal combustion engine vehicles and fair regulations.” It says this can partly be achieved through Saudi diplomacy, or “Kingdom relations,” and work with industry and regulators to promote internal combustion engine vehicles “through science and fair policies.”</p>
<blockquote><p>“Obviously aviation is a key market for them”</p></blockquote>
<p>The presentation shared by officials on the call describes a program of “regulatory advocacy” to “shape local and international viewpoints for policymakers,” “promote fair policies,” and “ensure the Kingdom’s view is represented in relevant global forums.”</p>
<p>A 2021<a href="https://www.nytimes.com/2022/11/21/climate/saudi-arabia-aramco-oil-solar-climate.html"> New York Times investigation</a> found that Saudi Aramco has funded huge amounts of scientific research into contentious energy issues in recent years, including studies aimed at keeping petrol and diesel vehicles competitive or casting doubt on electric vehicles.</p>
<p>Al-Tayyar, the head of OSP, told his Cape Town audience that the mining that is required for EVs will also create emissions, adding “so, we need to be very careful in pushing hard on one mode versus the other. Our view on which we base all of our efforts is having a more inclusive approach, we will need all of the above to help increase connectivity and mobility globally and Africa is a prime example for that ability to do so.”</p>
								</div>
							</div>

					
				
											<div>
																	<h2>Supersonic flight</h2>
								
								<div>
									<p>Saudi Arabia is also a major retailer of jet fuel and OSP officials outlined plans aimed at increasing sales around the world. This includes a plan to help fast-track the commercialisation of supersonic air travel, something that hasn’t been seen the demise of Concord.</p>
<p>The presentation makes clear that the incentive for doing so is that “supersonic aviation consumes more energy”, detailing that it uses three times the energy of subsonic commercial aircraft.</p>
<p>In October 2023, Saudi Arabia’s $500 billion NEOM project<a href="https://www.neom.com/en-us/newsroom/neom-announces-investment-fund"> announced</a> that it had made an investment in<a href="https://boomsupersonic.com/faq"> Boom Technology</a>, a<a href="https://www.axios.com/local/raleigh/2023/11/13/boom-supersonic-nears-first-test"> $700 million start-up</a> that aims to make commercial supersonic air travel a reality by 2030.</p>
<p>OSP also plans to facilitate investment into low-cost airlines in emerging economies across Asia and Africa. The presentation states that OSP could “facilitate investment in existing low-cost carriers with potential for expansion to fund growth through the acquisition of new aircraft and routes.”</p>
<p>To help manage the climate impacts of these plans, OSP officials said that Saudi Arabia is investing in an optimised jet fuel with at least 10% less greenhouse gas emissions compared to conventional jet fuel.</p>
<p>Joanna Depledge told CCR that Saudi obstruction has led to very little action on tackling emissions from aviation: “It’s really quite extraordinary what they’ve got away with,” she said, “they’ve just said no, even to any debate.”</p>
<p>“Because obviously, aviation is a key market for them,” Depledge said.</p>
								</div>
							</div>

					
				
											<div>
																				<div>
												<p><img src="https://climate-reporting.org/wp-content/uploads/2023/11/Screenshot-2023-11-24-at-15.09.05.png" alt=""></p>
											</div>
																				<p>Slide from OSP presentation</p>
										</div>

					
				
											<div>
																	<h2>Floating power plants</h2>
								
								<div>
									<p>In addition to transport, Saudi Arabia is also hoping to increase the use of fossil fuels for generating electricity in developing countries. The presentation portrays this as a sustainable development initiative, but the proposed solutions depend upon countries importing Saudi diesel and highly polluting heavy fuel oil.</p>
<p>This includes a plan to create “oil-powered mini-grids” in landlocked countries across Africa and South Asia. Nawaf Al-Fallaj told undercover reporters the plan is “comprised of mini-grid and off-grid power generation and includes the use of diesel and HFO [heavy fuel oil] and hybrid systems also.”</p>
<blockquote><p>“Africa has the largest potential for green energy, why can’t the Saudis fund the development of those types of infrastructure”</p></blockquote>
<p>OSP officials also outlined a plan to use “floating power plants” off the coast of Sub-Saharan Africa and South Asia. Power ships<a href="https://www.karadenizholding.com/uploads/2020-6/15934405989512020-karpowership-brochure-englishpdf.pdf"> use heavy fuel oil or liquefied natural gas</a> – usually whichever is cheapest at the time – to generate electricity. They have<a href="https://www.france24.com/en/20180823-lebanon-heavy-price-fuel-burning-barges-solve-energy-crisis"> proven controversial</a> in the past, with countries locked into high cost contracts and burning highly polluting heavy fuel oil in close proximity to towns and cities.</p>
<p>The officials added that, as part of the OSP strategy, Saudi Arabia would be accelerating upgrades to its heavy fuel oil refining capacity.</p>
								</div>
							</div>

					
				
											<div>
																				<div>
												<p><img src="https://climate-reporting.org/wp-content/uploads/2023/11/Screenshot-2023-11-24-at-15.01.20.png" alt=""></p>
											</div>
																				<p>Image from OSP presentation</p>
										</div>

					
				
											<div>
																	<h2>Leapfrogging</h2>
								
								<div>
									<p>When asked by an undercover reporter if the Saudi strategy is to ensure that developing countries don’t “leapfrog” fossil fuel-based development in favour of cleaner options like renewable energy and electrified transport, a Saudi official smiled and said “actually, we don’t believe it’s possible that they can skip this phase.”</p>
<p>Mohamed Adow of Power Shift Africa told CCR: “I will strongly disagree with anyone who says that Africa can’t leapfrog. Africa has all the essential ingredients to allow it to move away from fossil fuels.”</p>
<p>“But we need investment from rich countries that claim to be climate leaders,” Adow said, “otherwise we can expect more dodgy deals like this one, which endangers not just Africans but the global effort to ensure a safe and prosperous climate for all.”</p>
<p>Akinbode Oluwafemi of CAPPA told CCR: “As an African, I feel insulted that the Saudis think Africa is not ripe for a green economy and just transition. What Africa needs is sustainable climate financing that will allow the continent to make the transition to a climate resilient economy.”</p>
<p>“Africa has the largest potential for green energy, why can’t the Saudis fund the development of those types of infrastructure,” Oluwafemi said.</p>
								</div>
							</div>

					
				
											<div>
								<p><iframe src="https://player.vimeo.com/video/888731366?badge=0&amp;autopause=0&amp;quality_selector=1&amp;player_id=0&amp;app_id=58479" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" title="LEAPFROG 2"></iframe></p>							</div>

					
				
											<div>
																	<h2>Putting it into action</h2>
								
								<div>
									<p>Earlier this month, Saudi energy minister, Prince Abdulaziz bin Salman,<a href="https://www.spa.gov.sa/en/N1994212"> signed memoranda of understanding</a> with Rwanda, Nigeria, Chad, Ethiopia and Senegal during a diplomatic conference in Riyadh.</p>
<p>The agreements were part of an<a href="https://www.moenergy.gov.sa/en/MediaCenter/ClimateWeek/Pages/OSP-Announces-Empowering-Africa-with-Several-Saudi-Ministries.aspx"> OSP initiative</a> called “Empowering Africa,” which is framed as a sustainable development program that will fund electric cooking stoves and introduce “connectivity solutions, e-education platforms, and e-health services to rural areas in Africa.”</p>
<p>But the memoranda of understanding struck by Abdulaziz bin Salman this month as part of the initiative appear to largely focus upon oil and gas supply. This includes a deal between the<a href="https://www.spa.gov.sa/en/N1994212"> OSP and Rwanda</a> to “develop demand for hydrocarbon resources” and an agreement with Ethiopia to “<a href="https://www.ena.et/web/eng/w/eng_3559421">cooperate on oil supply</a>”. An<a href="https://twitter.com/senlokpobiri/status/1722677232131293579?s=20"> agreement with Nigeria</a> also focuses on cooperation in the oil and gas sector.</p>
<p>Significantly, the Saudi energy minister is reported to have framed the initiative as an alternative to the<a href="https://www.unep.org/about-un-environment/funding-and-partnerships/green-climate-fund"> Green Climate Fund</a>, which was set up as part of the UN climate process to support developing countries to transition to cleaner forms of energy and transport. According to Saudi newspaper, Arab News, Prince Abdulaziz bin Salman said at the event: “we have asked many of our colleagues in Africa if they have received any of the climate fund. I have yet to hear any who have.”</p>
<p>“Economies of Africa need to grow,” he added, “the people of Africa need to prosper, if these two things happen the world economy will grow and there will be a rippling effect.”</p>
<p>According to Adow: “A just transition is what Africa requires and Africans need to be proactive and ensure that the narrative of a just transition is not appropriated by polluters. We don’t want Africa’s poverty and Africa’s low emissions used to now undermine Africa’s future development.”</p>
<p>“I think the dominant narrative is that Africa lacks the resources,” Adow said, “and so you can then justify any infrastructure development including dirty development on that basis. ​​But what that misses is – if you look at the history of the world and the fossil heavy development that powered the advanced economies – that is what caused the climate crisis in the first place. And so, as the most vulnerable geography but also the one that is incredibly blessed with renewables, Africa can avoid the pitfalls of the past and realise the new opportunities of the twenty-first century.”</p>
								</div>
							</div>

					
									</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[S3 Express Is All You Need (131 pts)]]></title>
            <link>https://www.warpstream.com/blog/s3-express-is-all-you-need</link>
            <guid>38449827</guid>
            <pubDate>Tue, 28 Nov 2023 19:04:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.warpstream.com/blog/s3-express-is-all-you-need">https://www.warpstream.com/blog/s3-express-is-all-you-need</a>, See on <a href="https://news.ycombinator.com/item?id=38449827">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content"><h2>S3 Express is All You Need</h2><p>The new <a href="https://aws.amazon.com/s3/storage-classes/express-one-zone/">“AWS S3 Express One Zone”</a> low latency storage class is making waves in the data infrastructure community. A lot of people are starting to ask the obvious question: How much will it cost in practice, and what does this mean for the future of data infrastructure?</p><p>The first thing to know is that the new S3 Express storage class costs 8x more than S3 Standard per GiB stored which makes it unsuitable as the “primary” store for big data systems like Kafka and traditional data lakes.</p><p>However, individual API operations are 50% cheaper. 50% cheaper is great, but it’s not 10-20x cheaper. That means any workloads that were previously impractical due to S3 API operation costs are still impractical with the new Express storage class. Unlike S3 Standard, however, the new Express class also charges per GiB for every API operation (writes + reads) beyond 512 KiB. Another way to think about this is that every API operation comes with 512 KiB of bandwidth “free” and you pay for every byte beyond that.</p><p>We did some simple cost modeling, and this is what the cost profile looks like for PUT requests:</p><figure><p><img src="https://assets-global.website-files.com/64baaecd9c5c9b1b6c38aa0e/65662d4cd70380bc272850aa_4VB-0B8xqVF-KV7SQJVva1SbY9yF_MTdx21MRZ8qkLhtD-IeeZ7KHJAk2taIf-Q0llwn3nV2JVz9Wu-c5tHiI9aVofHS90vAnYEg0mKTmqmNzzzFdgssX5LTG5i27yf-MfE9Y2qauY3GerhQey89JsRveUhiuplKpAfsLtlAshyz5c4926NieNl31ldsPw.png" alt=""></p></figure><p>Here’s what it looks like for GET requests:</p><figure><p><img src="https://assets-global.website-files.com/64baaecd9c5c9b1b6c38aa0e/65662d4c9218cb461083df45_IsQ0xVYKFe6iiyW_Rl-Kkl6tibNJvatMT_l0fuoGae0Ux15JisBIX0Jfe4iLG6OJcee8DxPxA0_jI9p83pb75UUYftuzy0Hd1pqruQo0a4QoLZBCzIpOoRpGTKbaUklY8Z5PZifSEf0Ue5hAF3an-8uDx0QCJXid2cSYlvimQVpV3vUnX_vkfwwlbTyLeQ.png" alt=""></p></figure><p>However, remember that the new Express storage class is <em>single zone</em>. That means most modern data systems will have to manually replicate their data to two different availability zones if they want to survive the failure of a single AZ with no data loss or unavailability. So let’s double those numbers.</p><figure><p><img src="https://assets-global.website-files.com/64baaecd9c5c9b1b6c38aa0e/65662d4cb7130bca5a4c1237_uKrut9dMa4pOvkQPfAQBNCeF9y0prrQoU5ALb0lEdnKva9KEuxGHr-7s8F1q5ZNtEKQzeYOmkX9Yp569RG6zdJ2AwtBCDolIZdRA4_faDSBz5YjR3Yvy9L9K5yyYFlDc45grFI1iduvXNpFuME0-u0pqsFe5lgCTMHQiL4OTr7yX_tsua9mMTGggVHdEuA.png" alt=""></p></figure><figure><p><img src="https://assets-global.website-files.com/64baaecd9c5c9b1b6c38aa0e/65662d4cb324c727afaebae0_XbxYg7pb0THyrl0sjd9QuKEjPQwRDgYxcGY0sSnk9q8hUTlWpGcjPTlCg9ZWPWz9xGBFK0ARKVM_55YE-bt2I2S6uPmJ5VdYbpG0FrWZkvxxP3aUpQTn2WXrQ5G-DnzsWG7yduCdxSO-aKqRxdUORY67jjaYMdJBHBsJBqrMozg3fGaubRPOcZIlayQ38A.png" alt=""></p></figure><p>If you squint, the $0.016/GiB it costs to write data twice to two different S3 Express buckets in two different availability zones is <em>suspiciously</em> close to the cost of manually replicating a GiB of data between two availability zones at the application layer ($0.02/GiB). In other words, for high volume use cases, the new S3 Express storage class does not expose many new opportunities for dramatic improvements in cost or performance compared to traditional doubly or triply replicated storage systems.</p><p>However, the new storage class does open up an exciting new opportunity for all modern data infrastructure: the ability to tune an individual workload for low latency and higher cost or higher latency and lower cost <em>with the exact same architecture and code</em>.&nbsp;This will be a huge leap forward for modern data infrastructure as there is no longer any reason to design any large-scale modern data system around the availability of local disks, or block storage (like EBS).</p><p>All modern data systems, even those that need to serve low latency operational workloads, can now be built completely around object storage with data tiering only performed <em>between object storage tiers</em>. In the worst case scenario, it will still be cheaper, more durable, and significantly less error prone than manually replicating data at the application layer. In the best case scenario, you’ll be able to cut costs by an order of magnitude for high volume use cases without touching a line of code.</p><p>Of course the AWS S3 Express storage costs are still 8x higher than S3 standard, but that’s a non issue for any modern data storage system. Data can be trivially landed into low latency S3 Express buckets, and then compacted out to S3 Standard buckets asynchronously. Most modern data systems already have a form of compaction anyways, so this “storage tiering” is effectively free.</p><p>At WarpStream, we’re betting on the future of data streaming being completely object storage based. If you want to learn more about WarpStream and how it can reduce your Kafka costs and operations by an order of magnitude, <a href="https://www.warpstream.com/contact-us">contact us</a> or join <a href="https://console.warpstream.com/socials/slack">our Slack</a>.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Please don't use AI to get on the global leaderboard (121 pts)]]></title>
            <link>https://adventofcode.com/</link>
            <guid>38449233</guid>
            <pubDate>Tue, 28 Nov 2023 18:27:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://adventofcode.com/">https://adventofcode.com/</a>, See on <a href="https://news.ycombinator.com/item?id=38449233">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="sidebar"><p>Our <a href="https://adventofcode.com/2023/sponsors">sponsors</a> help make Advent of Code possible:</p><p><a href="https://www.catawiki.com/en/p/917-catawiki-advent-of-code-2023-raffle" target="_blank" onclick="if(ga)ga('send','event','sponsor','sidebar',this.href);" rel="noopener">Catawiki</a> - Turn your passion into your career. Join us! bit.ly/join-cw</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[MeshGPT: Generating triangle meshes with decoder-only transformers (523 pts)]]></title>
            <link>https://nihalsid.github.io/mesh-gpt/</link>
            <guid>38448653</guid>
            <pubDate>Tue, 28 Nov 2023 17:56:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nihalsid.github.io/mesh-gpt/">https://nihalsid.github.io/mesh-gpt/</a>, See on <a href="https://news.ycombinator.com/item?id=38448653">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                        <p>
                        We introduce <span>MeshGPT</span>, a new approach for generating triangle meshes that reflects the compactness typical of artist-created meshes, in contrast to dense triangle meshes extracted by iso-surfacing methods from neural fields. Inspired by recent advances in powerful large language models, we adopt a sequence-based approach to autoregressively generate triangle meshes as sequences of triangles.
                        </p>
                        <p>
                        We first learn a vocabulary of latent quantized embeddings, using graph convolutions, which inform these embeddings of the local mesh geometry and topology. These embeddings are sequenced and decoded into triangles by a decoder, ensuring that they can effectively reconstruct the mesh. A transformer is then trained on this learned vocabulary to predict the index of the next embedding given previous embeddings. Once trained, our model can be autoregressively sampled to generate new triangle meshes, directly generating compact meshes with sharp edges, more closely imitating the efficient triangulation patterns of human-crafted meshes.
                        </p>
                        <p>
                        <span>MeshGPT</span> demonstrates a notable improvement over state of the art mesh generation methods, with a 9% increase in shape coverage and a 30-point enhancement in FID scores across various categories.
                        </p>
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Amazon Introduces Q, an A.I. Chatbot for Companies (110 pts)]]></title>
            <link>https://www.nytimes.com/2023/11/28/technology/amazon-ai-chatbot-q.html</link>
            <guid>38448546</guid>
            <pubDate>Tue, 28 Nov 2023 17:48:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2023/11/28/technology/amazon-ai-chatbot-q.html">https://www.nytimes.com/2023/11/28/technology/amazon-ai-chatbot-q.html</a>, See on <a href="https://news.ycombinator.com/item?id=38448546">Hacker News</a></p>
Couldn't get https://www.nytimes.com/2023/11/28/technology/amazon-ai-chatbot-q.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[FDA agrees Loyal's data supports effectiveness for large dog lifespan extension (237 pts)]]></title>
            <link>https://loyalfordogs.com/posts/loyal-announces-historic-fda-milestone-for-large-dog-lifespan-extension-drug</link>
            <guid>38447491</guid>
            <pubDate>Tue, 28 Nov 2023 16:27:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://loyalfordogs.com/posts/loyal-announces-historic-fda-milestone-for-large-dog-lifespan-extension-drug">https://loyalfordogs.com/posts/loyal-announces-historic-fda-milestone-for-large-dog-lifespan-extension-drug</a>, See on <a href="https://news.ycombinator.com/item?id=38447491">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>Four years ago I founded Loyal with a simple vision — to bring to market the first drug explicitly approved and labeled for healthy lifespan extension. Loyal was only a few months old and about five people when we decided to begin by targeting the abnormally short lifespan of large breed dogs with a drug program we code-named LOY-001.&nbsp;</p>



<p>Today, I’m so proud to announce that <strong><a href="https://www.businesswire.com/news/home/20231127326868/en/FDA-Agrees-Loyal-Data-Supports-Reasonable-Expectation-of-Effectiveness-for-Large-Dog-Lifespan-Extension">Loyal has earned</a> what we believe to be the FDA’s first-ever formal acceptance that a drug can be developed and approved to extend lifespan. </strong>In regulatory parlance, we have completed the technical effectiveness portion of our conditional approval application for LOY-001’s use in large dog lifespan extension.&nbsp;</p>



<p>As there was no established regulatory path for a lifespan extension drug, we had to design from scratch a scientifically strong and logistically feasible way to demonstrate efficacy of an aging drug. This process took more than four years, resulting in the 2,300+ page technical section now approved by the FDA. It included interventional studies of LOY-001 in an FDA-accepted model of canine aging and an observational (no-drug) study of 451 dogs.</p>



<p>Our interventional studies with LOY-001 showed that the drug improved clinically-relevant aging parameters. We assessed these in laboratory studies using a dog model that represents accelerated aging. We then correlated those results with quality of life scores in the observational study, as independently measured by dog owners, and health outcomes as measured by veterinarians. This was key to show that the biological benefits of the drug are linked to clinically relevant outcomes.</p>



<p>From our data, the FDA believes LOY-001 is likely to be effective for large dog lifespan extension in the real world. Once we satisfactorily complete safety and manufacturing sections and other requirements, vets will be able to prescribe LOY-001 to extend the lifespan of large dogs while we complete the confirmatory pivotal lifespan extension study in parallel.</p>







<h2>What this means for large-breed dogs</h2>



<p>If you have a large- or giant-breed dog you may be familiar with the sad reality that these large dogs tend to live shorter lives than smaller dogs — often by half.</p>



<figure><img loading="lazy" decoding="async" width="1024" height="576" src="https://blog-admin.loyalfordogs.com/wp-content/uploads/2023/11/large-dog-small-dog-great-dane-chihuahua-average-lifespan-aging-1-1024x576.jpg" alt="Giant breeds like Great Danes have an average lifespan of 7-10 years, while tiny breeds like the Chihuahua live 14-16 years. (source: AKC, O’Neill et al 2013). Not only do they have varying lifespans, but it’s possible that aging and age-associated disease progresses differently among different breeds.
" srcset="https://blog-admin.loyalfordogs.com/wp-content/uploads/2023/11/large-dog-small-dog-great-dane-chihuahua-average-lifespan-aging-1-1024x576.jpg 1024w, https://blog-admin.loyalfordogs.com/wp-content/uploads/2023/11/large-dog-small-dog-great-dane-chihuahua-average-lifespan-aging-1-300x169.jpg 300w, https://blog-admin.loyalfordogs.com/wp-content/uploads/2023/11/large-dog-small-dog-great-dane-chihuahua-average-lifespan-aging-1-768x432.jpg 768w, https://blog-admin.loyalfordogs.com/wp-content/uploads/2023/11/large-dog-small-dog-great-dane-chihuahua-average-lifespan-aging-1-1536x864.jpg 1536w, https://blog-admin.loyalfordogs.com/wp-content/uploads/2023/11/large-dog-small-dog-great-dane-chihuahua-average-lifespan-aging-1.jpg 1999w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Giant breeds like Great Danes have an average lifespan of 7-10 years, while tiny breeds like the Chihuahua live 14-16 years. (source: AKC, O’Neill et al 2013). Not only do they have varying lifespans, but it’s possible that aging and age-associated disease progresses differently among different breeds.</figcaption></figure>



<p>This is unusual — very few if any other animals have such an extreme lifespan variation <em>within</em> the same species. Generally, the larger a mammal is, the longer its expected lifespan — a mouse may live two to three years, while elephants can live over 60 years.&nbsp;</p>



<p>Part of this lifespan disparity comes from the process of selective breeding that “created” these dog breeds.&nbsp; Historical selective breeding is understood to have created genetic issues like hip dysplasia in German Shepherds and breathing issues in brachycephalic dogs. In large- and giant-breed dogs, breeding for size caused these dogs to have highly elevated levels of IGF-1, a hormone that drives cell growth. High IGF-1 effectively drives these dogs to grow large when they’re young, but high IGF-1 levels in adult dogs are believed to accelerate their aging and reduce their healthy lifespan.</p>



<figure><img loading="lazy" decoding="async" width="1024" height="576" src="https://blog-admin.loyalfordogs.com/wp-content/uploads/2023/11/large-dogs-IGF-1-eigenmann-et-al-1984-Maxwell-et-al-1998-1024x576.jpg" alt="" srcset="https://blog-admin.loyalfordogs.com/wp-content/uploads/2023/11/large-dogs-IGF-1-eigenmann-et-al-1984-Maxwell-et-al-1998-1024x576.jpg 1024w, https://blog-admin.loyalfordogs.com/wp-content/uploads/2023/11/large-dogs-IGF-1-eigenmann-et-al-1984-Maxwell-et-al-1998-300x169.jpg 300w, https://blog-admin.loyalfordogs.com/wp-content/uploads/2023/11/large-dogs-IGF-1-eigenmann-et-al-1984-Maxwell-et-al-1998-768x432.jpg 768w, https://blog-admin.loyalfordogs.com/wp-content/uploads/2023/11/large-dogs-IGF-1-eigenmann-et-al-1984-Maxwell-et-al-1998-1536x864.jpg 1536w, https://blog-admin.loyalfordogs.com/wp-content/uploads/2023/11/large-dogs-IGF-1-eigenmann-et-al-1984-Maxwell-et-al-1998.jpg 1999w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>LOY-001 extends lifespan in part by reducing IGF-1 to levels seen in smaller-breed dogs. The IGF-1 axis is one of the most well-studied longevity pathways. In model organisms from <em>c.elegans </em>to mice, reducing IGF-1 extends healthy lifespan, and increasing IGF-1 shortens healthy lifespan. In humans, certain centenarians have been shown to have genetically lower levels of IGF-1.</p>



<p>The breakthrough moment for Loyal was connecting the biological mechanism of big dogs’ size to their short lifespan, and recognizing the big-dog-short-lifespan phenotype may not be inherent, but instead a type of “accelerated aging disorder”.</p>



<p>We designed LOY–01 as a long-acting injectable administered by your veterinarian every three to six months. In parallel, through our <a href="https://loyalfordogs.com/posts/announcing-our-partnership-with-crinetics-pharmaceuticals">recently-announced</a> partnership with Crinetics, we’re also developing LOY-003, a daily pill to address this same IGF-1 over-expression.&nbsp;</p>







<h2>A regulatory process that ensures safety and effectiveness</h2>



<p>Our product strategy has always been centered on earning FDA approval. While more challenging, time intensive, and expensive, I believe achieving FDA approval is critical to demonstrating the scientific legitimacy of lifespan extension drugs.</p>



<p>Most people know that the FDA has a rigorous system for ensuring that pharmaceutical products are safe and effective for humans. The same is true for veterinary medications — the drugs your vet prescribes to your dog, like the Rimadyl my senior Rottweiler takes for her arthritis, have been tested extensively and are regularly monitored by the FDA Center for Veterinary Medicine.</p>



<p>To obtain approval to sell the drug, companies must present extensive data to the FDA in three core areas:</p>



<ol>
<li><strong>Efficacy</strong> — It does what it says it will do; in our case, it extends the lifespan of dogs.</li>



<li><strong>Safety</strong> — It’s proven safe for dogs, and any side effects are well-understood and documented.</li>



<li><strong>Manufacturing</strong> — We can manufacture it at a consistently high quality, at scale.</li>
</ol>



<p>The health and safety of dogs is our top priority in all things, and there’s no higher bar in the United States than the FDA.&nbsp;</p>



<h2>Conditional approval helps us help dogs sooner</h2>



<p>The FDA’s expanded conditional approval process allows companies to bring certain products to patients while conducting longer effectiveness studies, specifically when the product meets an important unmet need. This helps us get treatment as early as possible to older dogs who need it most.</p>



<p>To receive conditional approval, the product must meet the same rigorous safety and manufacturing standards as drugs that are fully approved. To stay on the market beyond the five-year conditional approval period, we must demonstrate full efficacy — in our case lifespan extension — in a pivotal study.&nbsp;</p>



<h2>What this means for all dogs</h2>



<p>Each milestone we’ve achieved in this methodical, evidence-based process has demonstrated steady progress toward our vision of helping dogs live longer and stay healthy as they age.</p>



<p>This one is especially important because it marks a key step toward FDA approval based on credible, carefully reviewed data.</p>



<p>This process will make it possible for us to bring our products into veterinary clinics everywhere, and lead the charge on a new approach to age-related disease and decline.</p>



<p>That will ultimately mean more healthy years for the dogs we love — and that’s why we’re here.</p>



<p>——————</p>



<p>Thank you so much to the Loyal team for your intelligence, creativity, and determination to reach today’s milestone. Current and former team members who directly contributed to this milestone include: Alex Naka, Ashley Tovar, Ben Parsons, Brennen McKenzie, Dina Juarez-Salinas, Divya Shiroor, Ellen Ratcliff, Entonio Marietti, Erin McCandless, Frances Chen, Jess Graves, Jessica Austriaco, Jessie George, Julie Vaughn, Kaitlyn Super, Karen Greenwood, Katya Tucker, Matt Peloquin, Michael LaCroix-Fralish, Michelle Nelson, Phil Frankino, Tennery Carttar, and Tyler McQuade.&nbsp;</p>



<p>Thank you to our earliest investors and advisors, including but not limited to Dave Petrick, Greg Rosen, Josh Kopelman, Laura Deming, Linda Rhodes, and Taylor Greene, who believed in this crazy vision long before it was rational or sensible to do so.&nbsp;</p>



<p>——————</p>



<p>Here’s what the press is saying this morning:</p>



<p>New York Times <span>—</span> <a href="https://www.nytimes.com/2023/11/28/science/longevity-drugs-dogs.html" target="_blank" rel="noreferrer noopener">Could a Drug Give Your Pet More Dog Years?</a></p>



<p>WIRED — <a href="https://www.wired.com/story/a-life-extension-drug-for-big-dogs-is-getting-closer-to-reality/" target="_blank" rel="noreferrer noopener">A Life-Extension Drug for Big Dogs Is Getting Closer to Reality</a></p>



<p>Business Insider — <a href="https://www.businessinsider.com/longevity-drug-for-dogs-moves-closer-to-fda-approval-loyal-2023-11?r=US&amp;IR=T" target="_blank" rel="noreferrer noopener">An anti-aging drug for dogs promises to win owners more time with old pets. It could be FDA-approved soon.</a><span id="docs-internal-guid-e12294fd-7fff-4ca9-3497-998f97644420"></span></p>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Relational Deep Learning: Graph representation learning on relational databases [pdf] (143 pts)]]></title>
            <link>https://relbench.stanford.edu/paper.pdf</link>
            <guid>38447338</guid>
            <pubDate>Tue, 28 Nov 2023 16:16:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://relbench.stanford.edu/paper.pdf">https://relbench.stanford.edu/paper.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=38447338">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Nvidia's earnings are up 206% from last year as it continues riding the AI wave (107 pts)]]></title>
            <link>https://arstechnica.com/gadgets/2023/11/nvidias-earnings-are-up-206-from-last-year-as-it-continues-riding-the-ai-wave/</link>
            <guid>38446957</guid>
            <pubDate>Tue, 28 Nov 2023 15:47:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/gadgets/2023/11/nvidias-earnings-are-up-206-from-last-year-as-it-continues-riding-the-ai-wave/">https://arstechnica.com/gadgets/2023/11/nvidias-earnings-are-up-206-from-last-year-as-it-continues-riding-the-ai-wave/</a>, See on <a href="https://news.ycombinator.com/item?id=38446957">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <h4>
      machine earning    —
</h4>
            
            <h2 itemprop="description">Data center revenue is up 279% from the same quarter last year.</h2>
                    </div><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/11/nvidia-ai-gpu-800x407.jpeg" alt="Nvidia's AI-accelerating GPUs are driving its revenue numbers to new heights.">
      <figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/11/nvidia-ai-gpu.jpeg" data-height="1240" data-width="2440">Enlarge</a> <span>/</span> Nvidia's AI-accelerating GPUs are driving its revenue numbers to new heights.</p><p>Nvidia</p></figcaption>  </figure>

  




<!-- cache hit 112:single/related:778f2c90e2730137f4b26c7ae31507c2 --><!-- empty -->
<p>Most Ars readers still probably know Nvidia best for its decades-old GeForce graphics cards for gaming PCs, but these days Nvidia's server GPU business makes GeForce look like a hobby project.</p>
<p>That's the takeaway from <a href="https://nvidianews.nvidia.com/news/nvidia-announces-financial-results-for-third-quarter-fiscal-2024">Nvidia's Q3 earnings report</a>, which shows Nvidia's revenue up 206 percent from the same quarter last year and 34 percent from <a href="https://arstechnica.com/information-technology/2023/08/nvidia-thinks-ai-boom-is-far-from-over-as-gpu-sales-drive-big-earnings-win/">an already-very-good Q2</a>. Of the company's $18.12 billion in revenue, $14.51 billion was generated by its data center division, which includes AI-accelerating chips like <a href="https://arstechnica.com/information-technology/2023/11/nvidia-introduces-its-most-powerful-gpu-yet-designed-for-accelerating-ai/">the H200 Tensor Core GPU</a> as well as other cloud and server offerings.</p>

<p>And though GeForce revenue was a much smaller $2.86 billion, this was still a solid recovery from the same quarter of Nvidia's fiscal 2023, when GeForce GPUs earned just $1.51 billion and were down 51 percent compared to fiscal 2022. Nvidia has released several new mainstream GeForce RTX 40-series GPUs this year, including <a href="https://arstechnica.com/gadgets/2023/06/geforce-rtx-4060-review-not-thrilling-but-a-super-efficient-299-workhorse/">the $299 RTX 4060</a>. And while these more affordable GPUs aren't staggering upgrades from previous-generation cards, Steam Hardware Survey data shows the RTX 4060 and 4060 Ti are being adopted pretty quickly, more than can be said of competing GPUs like <a href="https://arstechnica.com/gadgets/2023/05/review-amds-269-rx-7600-is-a-good-1080p-card-but-the-rtx-4060-looms/">AMD's RX 7600</a> or Intel's Arc series.</p>                                            
                                                        
<p>The company's overall revenue numbers weren't looking nearly this good a year ago, either—in Q3 of fiscal 2023, the company's revenue had fallen 17 percent year over year. The quarter before that, the company <a href="https://arstechnica.com/gaming/2022/08/crypto-driven-gpu-crash-makes-nvidia-miss-q2-projections-by-1-4-billion/">missed its own projections by $1.4 billion</a> due to an oversupply of GPUs and a crypto-mining crash that reduced sales.</p>
<p>Demand for Nvidia's AI-accelerating GPUs probably won't be as volatile as demand for cryptomining GPUs was. For starters, there are big companies with big money buying up just about every HGX GPU that Nvidia can make, and companies like Microsoft and Amazon continue to make major AI announcements and investments at a steady clip—Nvidia also said it's partnering with Dropbox, Foxconn, Lenovo, and multiple other companies on various AI initiatives. And, just as in PC and workstation graphics cards, Nvidia's dominance can beget more dominance as software tools are designed for and optimized for Nvidia's chips first.</p>
<p>Still, the crypto-mining example is instructive. If this bubble bursts, or if competing products from AMD or Intel begin making a dent in Nvidia's sales, Nvidia could be in for a rough few quarters as these stratospheric revenue numbers come back to earth. Nvidia has also had trouble selling its AI chips in China, where US export restrictions on some high-performance chips have caused Nvidia <a href="https://www.reuters.com/technology/nvidia-plans-release-three-new-chips-china-local-media-2023-11-09/">to modify or stop offering some of its products</a> to meet requirements.</p>
<p>Nvidia's workstation GPUs and automotive divisions also grew year over year, though, at $416 million and $261 million, respectively, both divisions contribute a lot less to Nvidia's bottom line than the data center or GeForce products.</p>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How to Read a Paper [pdf] (200 pts)]]></title>
            <link>http://ccr.sigcomm.org/online/files/p83-keshavA.pdf</link>
            <guid>38446418</guid>
            <pubDate>Tue, 28 Nov 2023 14:59:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://ccr.sigcomm.org/online/files/p83-keshavA.pdf">http://ccr.sigcomm.org/online/files/p83-keshavA.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=38446418">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Keras 3.0 (207 pts)]]></title>
            <link>https://keras.io/keras_3/</link>
            <guid>38446353</guid>
            <pubDate>Tue, 28 Nov 2023 14:53:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://keras.io/keras_3/">https://keras.io/keras_3/</a>, See on <a href="https://news.ycombinator.com/item?id=38446353">Hacker News</a></p>
Couldn't get https://keras.io/keras_3/: Error: unable to verify the first certificate]]></description>
        </item>
        <item>
            <title><![CDATA[Hackers spent 2 years looting secrets of chipmaker NXP before being detected (197 pts)]]></title>
            <link>https://arstechnica.com/security/2023/11/hackers-spent-2-years-looting-secrets-of-chipmaker-nxp-before-being-detected/</link>
            <guid>38446027</guid>
            <pubDate>Tue, 28 Nov 2023 14:25:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/security/2023/11/hackers-spent-2-years-looting-secrets-of-chipmaker-nxp-before-being-detected/">https://arstechnica.com/security/2023/11/hackers-spent-2-years-looting-secrets-of-chipmaker-nxp-before-being-detected/</a>, See on <a href="https://news.ycombinator.com/item?id=38446027">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <header>
            <h4>
      MUM'S THE WORD    —
</h4>
            
            <h2 itemprop="description">Chipmaker claims breach had no "material adverse effect."</h2>
                    </header>
        <div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2021/07/data-breach-800x435.jpeg" alt="A cartoon man runs across a white field of ones and zeroes.">
      <figcaption></figcaption>  </figure>

  




<!-- cache hit 99:single/related:d0b793f982b0bc3e7713c01610f432d3 --><!-- empty -->
<p>A prolific espionage hacking group with ties to China spent over two years looting the corporate network of NXP, the Netherlands-based chipmaker whose silicon powers security-sensitive components found in smartphones, smartcards, and electric vehicles, a news outlet has reported.</p>
<p>The intrusion, by a group tracked under names including "Chimera" and "G0114," lasted from late 2017 to the beginning of 2020, <a href="https://www-nrc-nl.translate.goog/nieuws/2023/11/24/spionage-chinese-hackersgroep-zat-jarenlang-in-het-netwerk-van-de-nederlandse-chipfabrikant-nxp-a4182149?_x_tr_sl=auto&amp;_x_tr_tl=en&amp;_x_tr_hl=en-US">according to</a> Netherlands national news outlet NRC Handelsblad, which cited “several sources” familiar with the incident. During that time, the threat actors periodically accessed employee mailboxes and network drives in search of chip designs and other NXP intellectual property. The breach wasn’t uncovered until Chimera intruders were detected in a separate company network that connected to compromised NXP systems on several occasions. Details of the breach remained a closely guarded secret until now.</p>
<h2>No material damage</h2>
<p>NRC cited a report published (and later deleted) by security firm Fox-IT, titled <a href="https://web-archive-org.translate.goog/web/20210620162513/https://blog.fox-it.com/2021/01/12/abusing-cloud-services-to-fly-under-the-radar/?_x_tr_sl=auto&amp;_x_tr_tl=en&amp;_x_tr_hl=en-US"><em>Abusing Cloud Services to Fly Under the Radar</em></a>. It documented Chimera using cloud services from companies including Microsoft and Dropbox to receive data stolen from the networks of semiconductor makers, including one in Europe that was hit in “early Q4 2017.” Some of the intrusions lasted as long as three years before coming to light. NRC said the unidentified victim was NXP.</p>
<p>“Once nested on a first computer—patient zero—the spies gradually expand their access rights, erase their tracks in between and secretly sneak to the protected parts of the network,” NRC reporters wrote in an English translation. “They try to secrete the sensitive data they find there in encrypted archive files via cloud storage services such as Microsoft OneDrive. According to the log files that Fox-IT finds, the hackers come every few weeks to see whether interesting new data can be found at NXP&nbsp;and whether more user accounts and parts of the network can be hacked.”</p>                                            
                                                        
<p>NXP apparently did not alert customers or shareholders to the intrusion, other than a brief reference in a 2019 annual report. It read:</p>
<blockquote><p>We have, from time to time, experienced cyber-attacks attempting to obtain access to our computer systems and networks. Such incidents, whether or not successful, could result in the misappropriation of our proprietary information and technology, the compromise of personal and confidential information of our employees, customers, or suppliers, or interrupt our business. For instance, in January 2020, we became aware of a compromise of certain of our systems. We are taking steps to identify the malicious activity and are implementing remedial measures to increase the security of our systems and networks to respond to evolving threats and new information. As of the date of this filing, we do not believe that this IT system compromise has resulted in a material adverse effect on our business or any material damage to us. However, the investigation is ongoing, and we are continuing to evaluate the amount and type of data compromised. There can be no assurance that this or any other breach or incident will not have a material impact on our operations and financial results in the future.</p></blockquote>
<h2>“A big deal”</h2>
<p>NXP is Europe’s second-biggest semiconductor company behind ASML and the world’s 18th biggest chipmaker by market capitalization. Its chips are used in iPhones and Apple watches to support advanced near-field communications security mechanisms such as tag originality, tamper detection, and authentication for Apple Pay. NXP also provides chips for the MIFARE card used by transit companies, FIDO-compliant security keys, and tools for relaying data inside the networks of electric vehicles.</p>
<p>Some security researchers said it was surprising that NXP officials didn’t inform customers of the two-year intrusion by threat actors, often abbreviated as TAs.</p>
<p>“NXP chips are in a lot of products,” Jake Williams, a former hacker for the National Security Agency, <a href="https://infosec.exchange/@malwarejake/111477602993876340">wrote</a> on Mastodon. “It's likely the TA knows of specific flaws reported to NXP that can be leveraged to exploit devices the chips are embedded in, and that's assuming they didn't implement backdoors themselves. Over 2.5 years (at least), that's not unrealistic.”</p>                                            
                                                        

<p>A separate researcher who has published research in the past documenting a successful hack on a widely used product containing NXP chips voiced similar surprise.</p>
<p>“If a Chinese threat actor group gets source code or hardware designs of a chip manufacturer, these kinds of groups can use the source code even if the source code isn’t very well commented and documented,” the researcher, who asked not to be identified, said in an interview. “For me, [the intrusion] is a big deal. I was surprised NXP didn’t communicate with its customers.”</p>
<p>In an email, an NXP representative said the NRC report “is very dated as it was addressed back in 2019. As stated in our 2019 Annual Report, we became aware of a compromise of certain IT systems, and after a thorough investigation we determined that this incident did not result in a material adverse effect on our business. At NXP, we take the security of data very seriously. We learned from this experience and prioritize continually strengthening our IT systems to protect against ever-evolving cybersecurity threats.”</p>
<p>Chimera has extensive experience stealing data from a wide range of companies. The threat actor uses a variety of means to compromise its victims. In the campaign that hit NXP, hackers often leveraged account information revealed in previous data breaches of sites such as LinkedIn or Facebook. The data allowed Chimera to guess the passwords that employees used to access VPN accounts. Team members were able to bypass multi-factor authentication by changing telephone numbers associated with the accounts.</p>
<p>Security firm Cycraft <a href="https://cycraft.com/download/CyCraft-Whitepaper-Chimera_V4.1.pdf">documented </a> one two-year hacking spree that targeted semiconductor makers with operations in Taiwan, where NXP happens to have research and development facilities. An attack on one of the unnamed victims compromised 10 endpoints and another compromised 24 endpoints.</p>
<p>“The main objective of these attacks appeared to be stealing intelligence, specifically documents about IC chips, software development kits (SDKs), IC designs, source code, etc.,” Cycraft researchers wrote. “If such documents are successfully stolen, the impact can be devastating.”</p>

                                                </div>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[General Availability of the AWS SDK for Rust (140 pts)]]></title>
            <link>https://aws.amazon.com/blogs/developer/announcing-general-availability-of-the-aws-sdk-for-rust/</link>
            <guid>38445747</guid>
            <pubDate>Tue, 28 Nov 2023 14:02:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://aws.amazon.com/blogs/developer/announcing-general-availability-of-the-aws-sdk-for-rust/">https://aws.amazon.com/blogs/developer/announcing-general-availability-of-the-aws-sdk-for-rust/</a>, See on <a href="https://news.ycombinator.com/item?id=38445747">Hacker News</a></p>
<div id="readability-page-1" class="page"><section property="articleBody"> 
       <p>We’re excited to announce that the <a href="https://aws.amazon.com/sdk-for-rust/">AWS SDK for Rust</a> is now generally available and supported for production use.</p> 
       <p>The AWS SDK for Rust provides an idiomatic, type-safe API, along with the benefits of the Rust language such as <a href="https://www.rust-lang.org/">performance, reliability, and productivity</a>. The SDK supports modern Rust language features like async/await, non-blocking IO, and builders. It provides access to 300+ AWS Services, each with their own crate. The SDK works out of the box using sensible defaults but it’s also extensible, allowing users to customize it to their unique use case. The SDK is modular, allowing customers to compile crates only for the services they use. It’s also engineered to be fast. With the Rust SDK, users can quickly transfer data to and from Amazon Simple Storage Service (Amazon S3), Amazon Elastic Compute Cloud (Amazon EC2), and Amazon DynamoDB.</p> 
       <h2>Getting Started with AWS SDK for Rust</h2> 
       <p>You can access the SDK through <a href="https://crates.io/teams/github:awslabs:rust-sdk-owners">crates.io</a>. The following is an example of how to use the AWS SDK for Rust with DynamoDB to perform a common operation of listing your tables. This example assumes you already have Rust and Cargo installed <em>(If you don’t, you can</em> <a href="https://www.rust-lang.org/tools/install"><em>follow these instructions to install Rust and Cargo.</em></a><em>)</em></p> 
       <p>Create a new Rust project using <code>cargo</code>:</p> 
       <pre><code>cd &lt;your-project-directory&gt;
cargo new &lt;name-of-your-new-rust-project&gt;</code></pre> 
       <p>If this is the first time you are using an AWS SDK, you will need to set up your AWS credentials. We recommend <a href="https://docs.aws.amazon.com/cli/latest/userguide/cli-authentication-short-term.html">authenticating with short-term credentials</a>.</p> 
       <h3>Adding SDK crates to your dependencies</h3> 
       <p>Now that you’ve created your new Rust project, we’ll add some SDK crates and an async runtime. Add the following lines under <code>[dependencies]</code> in your new project’s <code>Cargo.toml</code> file:</p> 
       <pre><code>[dependencies]
aws-config = { version = "1", features = ["behavior-version-latest"] }
aws-sdk-dynamodb = "1"
tokio = { version = "1", features = ["full"] }</code></pre> 
       <p>Here’s what each of those crates does:</p> 
       <ul> 
        <li><strong>aws-config</strong>: While not strictly required, this crate makes it easy to create the configuration needed by the DynamoDB client we’ll be creating. It will handle the sourcing of AWS credentials as well as providing useful defaults.</li> 
        <li><strong>aws-sdk-dynamodb</strong>: This crate provides the client for the service we want to interact with.</li> 
        <li><strong>tokio</strong>: The AWS SDK for Rust has an async API, so an async runtime is required to run our requests. We recommend the <a href="https://tokio.rs/">Tokio</a> runtime. It’s well-supported by our SDK.</li> 
       </ul> 
       <h3>Listing your DynamoDB tables with the Rust SDK</h3> 
       <p>We’re ready to write our <code>main</code> function now:</p> 
       <pre><code>#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    let sdk_config = aws_config::load_from_env().await;
    let client = aws_sdk_dynamodb::Client::new(&amp;sdk_config);
    let res = client
        .list_tables()
        .limit(10)
        .send()
        .await?;
    println!("Current DynamoDB tables: {:?}", res.table_names());
    Ok(())
}</code></pre> 
       <p>You can now run the example program with <code>cargo</code>:</p> 
       <pre><code>cargo run</code></pre> 
       <p>The result is a list of your DynamoDB tables, or a helpful error message explaining why your request couldn’t be completed.</p> 
       <p><em>You can access many more examples in the <a href="https://github.com/awslabs/aws-sdk-rust/tree/main/examples">SDK repository</a>.</em></p> 
       <h2>Contributing to the SDK’s development</h2> 
       <p>We would like to thank everyone that submitted issues and PRs during developer preview of the AWS SDK for Rust.</p> 
       <p>We continue to accept contributions. See our <a href="https://github.com/awslabs/aws-sdk-rust/blob/main/CONTRIBUTING.md">contributing guidelines</a> to learn more.</p> 
       <p>Following are a few ways you can help:</p> 
       <ul> 
        <li><strong>Vote for the new features most important to you</strong> — We prioritize feature work based on the needs of our customers so add your comments and “+1”s to <a href="https://github.com/awslabs/aws-sdk-rust/issues">GitHub Issues</a> that are important to you.</li> 
        <li><strong>Report defects</strong> — We are committed to continued production support without breaking changes. However, please <a href="https://github.com/awslabs/aws-sdk-rust/issues/new/choose">submit a GitHub Issue</a> if you run into unexpected behavior or want to report an issue. Kindly include an <a href="http://sscce.org/">SSCCE</a> to help us reproduce the issue.</li> 
        <li><strong>Review the docs</strong> — The AWS SDK for Rust comes with support for documentation and code examples. Please create a <a href="https://github.com/awslabs/aws-sdk-rust/issues">GitHub issue</a> for any feedback for the supported documentation or code examples.</li> 
        <li><strong>Join in on the discussion</strong> — When customers have a question but don’t feel like it warrants opening a new issue, they start a <a href="https://github.com/awslabs/aws-sdk-rust/discussions" target="_blank" rel="noopener">new discussion</a>. If a customer’s issue sounds familiar to you, feel free to help them out. I’m sure they’ll appreciate it.</li> 
       </ul> 
       <h2>Our SDK’s Public Roadmap</h2> 
       <p>The AWS SDK for Rust supports 300+ services and we will continue to add support for new services and features in the future. If you’d like to see what we’re working on, you can view our <a href="https://github.com/orgs/awslabs/projects/50/">public roadmap</a>. Please add a “+1” to the features that are important to you. Your votes help us to prioritize our roadmap.</p> 
       <h2>Give it a try!</h2> 
       <p>If you’re ready to start using the AWS SDK for Rust in your own project, the “<a href="https://docs.aws.amazon.com/sdk-for-rust/latest/dg/getting-started.html" target="_blank" rel="noopener">Getting Started</a>” guide is a great place to learn more. Check it out and <a href="https://github.com/awslabs/aws-sdk-rust/discussions">let us know</a> what do you think!</p> 
       <p><strong>About the author:</strong></p> 
        
       <!-- '"` --> 
      </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[IKEA new Zigbee sensors for doors and windows, motion, water leaks are under $10 (343 pts)]]></title>
            <link>https://www.theverge.com/2023/11/28/23977693/ikea-sensors-door-window-water-motion-price-date-specs</link>
            <guid>38445745</guid>
            <pubDate>Tue, 28 Nov 2023 14:02:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/2023/11/28/23977693/ikea-sensors-door-window-water-motion-price-date-specs">https://www.theverge.com/2023/11/28/23977693/ikea-sensors-door-window-water-motion-price-date-specs</a>, See on <a href="https://news.ycombinator.com/item?id=38445745">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Ikea’s push to democratize the smart home continues with the introduction of three new Zigbee sensors that won’t break the bank. There’s Parasoll, the door and window sensor; Vallhorn, the motion sensor; and Badring, the water leakage sensor.&nbsp;They’ll all be priced less than $10 when they go on sale globally in the first half of next year.</p><p>Parasoll is a typical window and door sensor that can be discretely mounted to trigger an automation when an open / close event is detected. It can also be paired directly with an Ikea light bulb right out of the box without needing to buy and configure an Ikea Home smart hub. It’s priced at €9.99 in Europe, but exact US pricing is yet to be confirmed for it or any of Ikea’s three new sensors.</p><div><div role="button" aria-label="Zoom" tabindex="0"><figure><div><p><span><img alt="Parasoll door and window sensor pair." loading="lazy" decoding="async" data-nimg="fill" sizes="(max-width: 1023px) 100vw, 744px" srcset="https://duet-cdn.vox-cdn.com/thumbor/0x0:4000x4000/376x376/filters:focal(2000x2000:2001x2001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25114660/PE909548__1_.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:4000x4000/384x384/filters:focal(2000x2000:2001x2001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25114660/PE909548__1_.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:4000x4000/415x415/filters:focal(2000x2000:2001x2001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25114660/PE909548__1_.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:4000x4000/480x480/filters:focal(2000x2000:2001x2001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25114660/PE909548__1_.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:4000x4000/540x540/filters:focal(2000x2000:2001x2001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25114660/PE909548__1_.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:4000x4000/640x640/filters:focal(2000x2000:2001x2001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25114660/PE909548__1_.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:4000x4000/750x750/filters:focal(2000x2000:2001x2001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25114660/PE909548__1_.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:4000x4000/828x828/filters:focal(2000x2000:2001x2001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25114660/PE909548__1_.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:4000x4000/1080x1080/filters:focal(2000x2000:2001x2001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25114660/PE909548__1_.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:4000x4000/1200x1200/filters:focal(2000x2000:2001x2001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25114660/PE909548__1_.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:4000x4000/1440x1440/filters:focal(2000x2000:2001x2001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25114660/PE909548__1_.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:4000x4000/1920x1920/filters:focal(2000x2000:2001x2001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25114660/PE909548__1_.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:4000x4000/2048x2048/filters:focal(2000x2000:2001x2001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25114660/PE909548__1_.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:4000x4000/2400x2400/filters:focal(2000x2000:2001x2001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25114660/PE909548__1_.jpg 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:4000x4000/2400x2400/filters:focal(2000x2000:2001x2001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25114660/PE909548__1_.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p></div></figure></div><div><figcaption><em>Parasoll door and window sensor pair.</em></figcaption> <p><cite>Image: Ikea</cite></p></div></div><p>The Vallhorn motion sensor can be used both indoors and outdoors (with IP44 splash protection against rain) to activate lights or other automations when movement is detected. It’s powered by three AAA batteries and can be paired to directly control up to 10 Ikea smart bulbs right out of the box. It costs just €7.99 and can sense more of the room than Ikea’s <a href="https://www.theverge.com/22310841/ikea-shortcut-button-motion-sensor-homekit-smart-home-review-test">existing $14.99 / €12.99 motion sensor</a> that’s smaller but only useable indoors and needs its coin cell battery replaced more frequently.</p><div><div role="button" aria-label="Zoom" tabindex="0"><figure><div><p><span><img alt="Vallhorn motion sensor can also be placed outdoors." loading="lazy" decoding="async" data-nimg="fill" sizes="(max-width: 1023px) 100vw, 744px" srcset="https://duet-cdn.vox-cdn.com/thumbor/0x0:3098x4130/376x501/filters:focal(1549x2065:1550x2066):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25114663/PH195380__1_.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3098x4130/384x512/filters:focal(1549x2065:1550x2066):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25114663/PH195380__1_.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3098x4130/415x553/filters:focal(1549x2065:1550x2066):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25114663/PH195380__1_.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3098x4130/480x640/filters:focal(1549x2065:1550x2066):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25114663/PH195380__1_.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3098x4130/540x720/filters:focal(1549x2065:1550x2066):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25114663/PH195380__1_.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3098x4130/640x853/filters:focal(1549x2065:1550x2066):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25114663/PH195380__1_.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3098x4130/750x1000/filters:focal(1549x2065:1550x2066):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25114663/PH195380__1_.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3098x4130/828x1104/filters:focal(1549x2065:1550x2066):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25114663/PH195380__1_.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3098x4130/1080x1440/filters:focal(1549x2065:1550x2066):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25114663/PH195380__1_.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3098x4130/1200x1600/filters:focal(1549x2065:1550x2066):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25114663/PH195380__1_.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3098x4130/1440x1920/filters:focal(1549x2065:1550x2066):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25114663/PH195380__1_.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3098x4130/1920x2560/filters:focal(1549x2065:1550x2066):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25114663/PH195380__1_.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3098x4130/2048x2730/filters:focal(1549x2065:1550x2066):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25114663/PH195380__1_.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3098x4130/2400x3199/filters:focal(1549x2065:1550x2066):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25114663/PH195380__1_.jpg 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:3098x4130/2400x3199/filters:focal(1549x2065:1550x2066):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25114663/PH195380__1_.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p></div></figure></div><div><figcaption><em>Vallhorn motion sensor can also be placed outdoors.</em></figcaption> <p><cite>Image: Ikea</cite></p></div></div><p>The Badring water sensor includes a built-in siren (60dBA at 1m) that can alert you when it senses a leak. It can also trigger a mobile notification in the Ikea Home smart app for homes with an Ikea <a href="https://www.theverge.com/23420136/ikeas-dirigera-smart-home-review-price-specs">Dirigera hub ($69.99)</a> installed. Sensors like these can save homeowners a ton of money before a water leak has the opportunity to create real damage. It will cost €9.99.</p><div><div role="button" aria-label="Zoom" tabindex="0"><figure><div><p><span><img alt="The Badring sensor could save you money by detecting a water leak early." loading="lazy" decoding="async" data-nimg="fill" sizes="(max-width: 1023px) 100vw, 744px" srcset="https://duet-cdn.vox-cdn.com/thumbor/0x0:4000x4000/376x376/filters:focal(2000x2000:2001x2001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25114667/PE909549.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:4000x4000/384x384/filters:focal(2000x2000:2001x2001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25114667/PE909549.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:4000x4000/415x415/filters:focal(2000x2000:2001x2001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25114667/PE909549.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:4000x4000/480x480/filters:focal(2000x2000:2001x2001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25114667/PE909549.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:4000x4000/540x540/filters:focal(2000x2000:2001x2001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25114667/PE909549.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:4000x4000/640x640/filters:focal(2000x2000:2001x2001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25114667/PE909549.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:4000x4000/750x750/filters:focal(2000x2000:2001x2001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25114667/PE909549.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:4000x4000/828x828/filters:focal(2000x2000:2001x2001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25114667/PE909549.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:4000x4000/1080x1080/filters:focal(2000x2000:2001x2001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25114667/PE909549.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:4000x4000/1200x1200/filters:focal(2000x2000:2001x2001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25114667/PE909549.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:4000x4000/1440x1440/filters:focal(2000x2000:2001x2001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25114667/PE909549.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:4000x4000/1920x1920/filters:focal(2000x2000:2001x2001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25114667/PE909549.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:4000x4000/2048x2048/filters:focal(2000x2000:2001x2001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25114667/PE909549.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:4000x4000/2400x2400/filters:focal(2000x2000:2001x2001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25114667/PE909549.jpg 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:4000x4000/2400x2400/filters:focal(2000x2000:2001x2001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25114667/PE909549.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p></div></figure></div><div><figcaption><em>The Badring sensor could save you money by detecting a water leak early.</em></figcaption> <p><cite>Image: Ikea</cite></p></div></div><p>Of the three, the Parasoll and Badring sensors are&nbsp;<em>not</em>&nbsp;compatible with older Trådfri Home smart gateways from Ikea. All support the newer&nbsp;<a href="https://www.theverge.com/23420136/ikeas-dirigera-smart-home-review-price-specs">Dirigera hub</a>, of course, which fully integrates the sensors into <a href="https://www.theverge.com/2019/12/18/21024497/ikea-smart-home-tech-sweden-furniture-sonos-meatballs-bjorn-block">Ikea’s burgeoning lineup of smart home products</a> and Home smart app. The hub also allows Ikea’s devices to interoperate with smart home ecosystems from Google, Amazon, and Apple when at home or away.&nbsp;</p><p>Despite Matter support being just “<a href="https://www.theverge.com/23420136/ikeas-dirigera-smart-home-review-price-specs">a couple of months away</a>” over a year ago, the company still doesn’t support it. Ikea plans to eventually enable Matter by turning on the Thread radio inside the Dirigera hub to bridge Ikea’s existing Zigbee-based devices to the next-generation smart home standard. In a statement sent to <em>The Verge</em>, Ikea digital product area manager Jonas Söderqvist says the company has “decided to delay this functionality” and will provide an update “when it’s time.” The ongoing delay is understandable given that Ikea’s products already integrate well with other platforms, and the company is focused on keeping things as simple as possible for anyone who delves into the smart home on a whim while shopping for a new bookcase. And when you consider the&nbsp;<a href="https://www.theverge.com/23513535/matter-smart-home-device-testing-eve-google-apple-samsung">hurdles required</a>&nbsp;to get&nbsp;<a href="https://www.theverge.com/23823041/matter-thread-device-setup-smart-home-how-to">everything running</a>&nbsp;on Matter networks during this period of transition, Ikea’s delay is more than justified.</p><p>Vallhorn will be available in select countries including the US starting in January 2024. That’s the same month the Parasoll launches internationally, but its US rollout won’t happen until April. Badring is scheduled to begin retail sales in April in some countries but won’t hit the US until July. It’s confusing, but these staggered releases are a byproduct of Ikea’s franchise retail system.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Rustlantis: Semantic fuzzing of the Rust compiler and interpreter [pdf] (145 pts)]]></title>
            <link>https://ethz.ch/content/dam/ethz/special-interest/infk/inst-pls/plf-dam/documents/StudentProjects/MasterTheses/2023-Andy-Thesis.pdf</link>
            <guid>38445660</guid>
            <pubDate>Tue, 28 Nov 2023 13:52:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ethz.ch/content/dam/ethz/special-interest/infk/inst-pls/plf-dam/documents/StudentProjects/MasterTheses/2023-Andy-Thesis.pdf">https://ethz.ch/content/dam/ethz/special-interest/infk/inst-pls/plf-dam/documents/StudentProjects/MasterTheses/2023-Andy-Thesis.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=38445660">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[The Knight Capital Disaster (150 pts)]]></title>
            <link>https://specbranch.com/posts/knight-capital/</link>
            <guid>38445165</guid>
            <pubDate>Tue, 28 Nov 2023 12:55:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://specbranch.com/posts/knight-capital/">https://specbranch.com/posts/knight-capital/</a>, See on <a href="https://news.ycombinator.com/item?id=38445165">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p><em>This account comes from several publicly available sources as well as accounts from insiders who worked at
Knight Capital Group at the time of the issue. I am telling it second- or third-hand.</em></p>
<p>On August 1, 2012, Knight Capital fell on its sword. It experienced a software glitch that literally bankrupted the
company. Between 9:30 am and 10:15 am EST, the employees of Knight capital watched in disbelief and scrambled to
figure out what went wrong as the company acquired massive long and short positions, largely concentrated in 154
stocks, totaling 397 million shares and $7.65 billion. At 10:15, the kill switch was flipped, stopping the
company’s trading operations for the day. By early afternoon, many of Knight Capital’s employees had already
sent out resumes, expecting to be unemployed by the end of the week.</p>
<p>The root cause of the failure? A comedy of errors in several parts of their development and ops processes.</p>
<h3 id="knights-order-entry-software">Knight’s Order-entry Software</h3>
<p>Knight Capital had an application called “SMARS” which sends orders to the stock exchange. It contained some logic
to break up large orders into much smaller orders that would have less of an effect on the market. The SMARS
software accepted orders from trading strategies using a binary protocol, and contained logic to make sure that
those orders got filled at a desired price. The protocol contained fields for price, desired size, time in force,
etc. The protocol also had a flag field, which set options for a given order. Nanoseconds counted, so protobufs
and JSON were too heavy here: these commands were sent over the wire as serialized structs.</p>
<p>One such option, from the very early 2000’s, was called “power peg.” Power peg was an order type used for manual
market making: a power peg order would stay open at a given price, effectively “pegging” the stock to a given
price. If a power peg order was filled, SMARS would refresh it at the same price. It kept a count of how many
shares were filled for a power peg order, and when a certain (very large) cumulative number was hit, the power peg
order would be automatically canceled. The intended user flow was for a market maker to open a power peg order,
get it filled as many times as needed, and then cancel the order when the market was about to move.</p>
<p>In 2003, Knight Capital deprecated the power peg option. They followed almost all the steps for flag deprecation
that you would expect from a disciplined engineering department: they marked the flag as deprecated, they switched
users away from using it, and they defaulted the clients to prevent use of the option. However, they never took
the last step: removing the server code. SMARS had been written somewhat hastily, and some of the code for Power
Peg was deeply entwined with other code in the server, and as long as the tests kept working, it wouldn’t be a
big deal. During a refactor 2 years later, the tests for power peg were breaking, so they were deleted. Nobody was
using the long-deprecated option, so there was no longer a need to check its correctness.</p>
<h3 id="adding-a-new-feature">Adding a New Feature</h3>
<p>In July 2012, Knight Capital needed a flag for orders from their new Retail Liquidity Program (RLP).
Knight had opened a new line of business: buying order flow from retail brokerage and executing those orders.
Retail orders needed special handling, so SMARS needed a new flag. However, the flag word was out of new bits
for flags, so an engineer reused a bit from a deprecated flag: the power peg flag. The remaining power peg code
in SMARS was disconnected from the flag, and new RLP code was added. The code went through review successfully,
and passed a battery of automated tests.</p>
<p>The new RLP code was deployed to the SMARS system on July 27, 2012. Knight Capital officially ran a manual
deployment process: the person assigned to deploy the code would SSH into each SMARS machine, rsync the new
binary to that machine, and update some configuration to set it up to run instead of the old binary. Knight’s
operations team had seen the danger of this: to avoid missing a machine, they set up a script to perform the
process for each machine. On July 27, 2012, one member of the operations team ran the deployment script for the
new version of SMARS.</p>
<p>Unbeknownst to the team, the deployment script had a small bug: when it failed to open an SSH connection to a
machine, it would fail silently, continue to update the other machines, and report success. It was never tested
or checked in like a piece of software because it’s a script that one person wrote for convenience.</p>
<p>That day, one of ten SMARS machines was down for maintenance during the software upgrade, and rejected
an SSH connection. After its planned maintenance, the server came back up with an old version of SMARS.</p>
<p>Knight allowed the new SMARS binary to soak for 3 days before turning on RLP trades, and caught no errors.
That was to happen on August 1. They also did a limited test of RLP orders in one of the production SMARS
servers to make sure that the new logic was working correctly. The server they tested had received the new
software version, and the test was successful.</p>
<h3 id="august-1-2012">August 1, 2012</h3>
<p>Beginning at 8:01 EST on August 1, Knight began receiving retail orders through the RLP. Things were going
well, and the internal servers handling RLP orders were working exactly as they had in testing the prior days.</p>
<p>At 9:30, the market opened. Initially, trading in about 150 stocks looked like it was going wrong. Engineers
and quants were called to figure out what the problem was. New and experimental trading algorithms were shut
off. Quantitative researchers, not known for their programming prowess, were thought to have created the bug.
The RLP, now past its experimental soaking period, was allowed to continue operating.</p>
<p>From debug logs, engineers later narrowed down the problem to a bug in SMARS: orders were leaving trading
servers correctly, but somehow the firm was starting to accrue large positions on these orders, filling them
many times over. Noticing the flaw, engineers decided to roll back SMARS to its previous version, hoping to
continue trading with a known-good version.</p>
<p>After the rollback, the abnormal behavior accelerated and spread to seemingly every stock on the market. The
losses accelerated, and the SMARS software kept acquiring massive positions that were not allocated to any
trading strategy. Trading algorithms also continued to be rolled back, as bugs in those machines could have
caused the same issue, but none of this helped. Unknown to the operations department, they hadn’t rolled
back to a good version of SMARS—they had rolled back to the same bad version that had been the cause of
their problems.</p>
<p>At 10:15, the call was made to shut down trading for the day. Knight had been losing money and accruing
positions so quickly that the computers took a while to figure out exactly how bad it was.</p>
<p>Knight’s executive team now needed to figure out how to cover these positions. Some positions could be closed
manually, and some of these trades even made money. However, most of Knight’s positions were too large for this
approach. Talks began with banks and other trading partners to figure out how to get out of the hole. Exchanges
were asked if they could reverse the trades. It appeared that Knight would have a $1 billion loss on their hands,
and not anywhere near enough cash to cover it.</p>
<p>Line employees caught wind of the trouble, and many started to answer the emails from recruiters that they had
long ignored. In the afternoon of August 1, more Knight employees were working on resumes than anything else.</p>
<h3 id="the-final-fatal-flaws">The Final Fatal Flaws</h3>
<p>During the 2005 refactor of SMARS, the code for reporting power peg positions back to trading strategies had
broken, which was what caused the test failures (and the subsequent deletion of tests). If not for this
breakage, the strategies would have been allocated correct positions, and the correct trading algorithms could
have been shut down.</p>
<p>Finally, SMARS was built to be fast, and did not conduct a lot of pre-trade risk checks. That was the job for the
trading servers, and they were very accurate at it. SMARS simply accepted orders and executed them, regardless
of whether the strategy (or the firm) had the requisite capital. Since Knight was a broker-dealer and had a
direct connection to the exchange, the exchange didn’t know whether Knight had the money for their trades either,
and continued accepting orders. This type of check is the responsibility of the broker, and Knight was their own.
Trading strategies, whose risk management code had an inaccurate view of their own positions, continued to send
orders like nothing was wrong. Nobody at Knight had built any infrastructure to manage the financial risks
related to rogue order entry servers.</p>
<h3 id="aftermath">Aftermath</h3>
<p>When the dust settled, Knight was able to close its positions at a $440 million loss. On August 5, 2012, Knight
received $400 million of rescue financing that allowed them to continue operations. They rebranded as “KCG,”
and were acquired in 2013 by GETCO, another algorithmic trading company, to form KCG Holdings. They were later
acquired by Virtu Financial in 2017.</p>
<p>The story of Knight Capital prompted other trading firms to review their processes and adopt new layers of risk
checks as well as modern DevOps practices to protect themselves from being the next Knight. Some of them quietly
admitted that they were lucky: their practices were similar to the ones that brought down their competitor.
Adding risk checks to the <em>last</em> stage of an order’s life became universal in the industry, and testing and
deployment practices were largely brought into the modern era.</p>
<p>Knight Capital, the SEC, the exchanges, and FINRA conducted thorough postmortem reviews of what happened during
this incident. There was a lot of blame to go around at Knight, and they ended up paying an additional $12 million
of fines for failing to hold up their responsibilities as broker. A lot of Knight’s development practices were
changed. As of 2016, the engineer who did the update still worked at KCG. His entire management chain had been
replaced, all the way up to the CTO.</p>
<p>The story of Knight Capital today serves as a cautionary tale for trading firms who ask “what’s the worst that
could happen?”</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Eclipse ThreadX (140 pts)]]></title>
            <link>https://eclipse-foundation.blog/2023/11/21/introducing-eclipse-threadx/</link>
            <guid>38445039</guid>
            <pubDate>Tue, 28 Nov 2023 12:38:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://eclipse-foundation.blog/2023/11/21/introducing-eclipse-threadx/">https://eclipse-foundation.blog/2023/11/21/introducing-eclipse-threadx/</a>, See on <a href="https://news.ycombinator.com/item?id=38445039">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		
<h3>TL;DR – Get Engaged!</h3>



<ul>
<li><a href="mailto:collaborations@eclipse-foundation.org" target="_blank" rel="noreferrer noopener">Contact us</a> to learn how to become part of the <a href="https://projects.eclipse.org/interest-groups/threadx-interest-group" target="_blank" rel="noreferrer noopener">Eclipse ThreadX Interest Group</a></li>



<li>Contribute to the project and join the <a href="https://accounts.eclipse.org/mailing-list/threadx-dev" target="_blank" rel="noreferrer noopener">ThreadX developer mailing list</a></li>



<li>Stay connected by joining the general <a href="https://accounts.eclipse.org/mailing-list/threadx" target="_blank" rel="noreferrer noopener">ThreadX mailing list</a></li>



<li>Watch for updates at <a href="http://www.threadx.io/" target="_blank" rel="noreferrer noopener">threadx.io</a></li>
</ul>



<h3>What We’re Announcing</h3>



<p>Every once in a while, a new open source initiative comes along which is truly an industry changing event. Today, <a href="https://techcommunity.microsoft.com/t5/internet-of-things-blog/microsoft-contributes-azure-rtos-to-open-source/ba-p/3986318" target="_blank" rel="noreferrer noopener">Microsoft announced</a> that Azure RTOS, including all of its components, is going to be made available as the <a href="https://www.threadx.io/" target="_blank" rel="noreferrer noopener">Eclipse ThreadX</a> open source <a href="https://projects.eclipse.org/proposals/eclipse-threadx" target="_blank" rel="noreferrer noopener">project</a>. This new project is exactly what the highly fragmented embedded software market has needed for a very long time. ThreadX is going to be the world’s first open source real time operating system which is:</p>



<ol>
<li>Mature and scalable technology. ThreadX has been developed for over 20 years, is currently running on over 12 billion devices around the world, and is highly regarded as a high-performance, highly deterministic, real time operating system.<br></li>



<li>Made available under a permissive open source license. ThreadX is going to be licensed under the MIT license, which provides highly permissive license terms for users and adopters.<br></li>



<li>Governed under a vendor-neutral open source foundation. ThreadX is going to be governed by the Eclipse Foundation and its development process. This will guarantee a vendor-neutral governance model to manage the evolution and sustainability of ThreadX for the benefit of the entire industry.<p>AND</p></li>



<li><a href="https://learn.microsoft.com/en-us/azure/rtos/overview-rtos" target="_blank" rel="noreferrer noopener">Certified</a> for functional safety and security. ThreadX is IEC 61508, IEC 62304, ISO 26262, and EN 50128 conformance certified by SGS-TÜV Saar. ThreadX has also achieved EAL4+ Common Criteria security certification. These certifications are a big differentiator, and are unprecedented in the industry. They are a game changer, as there are currently no open source RTOS’s which have them.&nbsp;</li>
</ol>



<p>While there are other open source RTOS’s out there, none have all of the four attributes listed above. We are optimistic that, because of these attributes, ThreadX is going to rapidly expand its adoption in a wide range of use cases including aerospace, automotive, IoT, medical, transportation, automation, and consumer wearables.&nbsp;</p>



<h3>Next Steps</h3>



<p>In addition to the project, we are also announcing the creation of an interest group focused on developing an industry-supported, sustainable funding model for ThreadX. We are excited that AMD, Cypherbridge, Microsoft, NXP, PX5, Renesas, ST Microelectronics, Silicon Labs, and Witekio (an Avnet company) have all committed to supporting this conversation. We highly encourage every company with an interest in embedded technology to join to help create the future.&nbsp;</p>



<p>The ThreadX interest group’s sole focus will be on establishing a working group focused on the following:</p>



<ol>
<li><strong>Consolidate the project: </strong>There is going to be a great deal of focus on getting ThreadX moved under Eclipse Foundation governance as quickly as possible. This will involve transferring and re-licensing the code and documentation, and assigning the trademarks over the next few weeks. In parallel, we are looking for developers who have experience with the ThreadX code base to get involved as key resources from Cypherbridge, PX5, and Witekio have already done. The intent is to have the first release of ThreadX under Eclipse Foundation governance completed by the end of January 2024.<br></li>



<li><strong>Preserve the certifications: </strong>As I mentioned above, the safety and security certifications are a key differentiator for ThreadX. Maintaining those certifications while under open source governance is going to be a key factor in the evolution of ThreadX as an open source project. Fortunately, the Eclipse Foundation has been thinking about and staffing for this capability for a long time as our IoT and Software Defined Vehicle communities have similar requirements. Our intent is to develop best practices for the ThreadX community and, if required, modify and enhance our Eclipse Foundation Development Process to support the additional process requirements necessary to support safety and security. The documentation which will enable downstream adopters of ThreadX to certify their products will be made available under open licenses. This will significantly shorten the lifecycle of safety-certified products based on Eclipse ThreadX.<br></li>



<li><strong>Build the community: </strong>ThreadX represents an amazing opportunity to build an open source embedded software developer community. There will be a great deal of focus on nurturing new contributions, driving adoption via developer advocacy, and creating cross-pollination with our other communities within the Eclipse Foundation such as IoT and SDV, all while preserving the processes required for the certifications which differentiate ThreadX.<br></li>



<li><strong>Promote the brand: </strong>Returning to the original ThreadX name is purposefully intended to assure the many current adopters of this technology that this is and will remain the RTOS that they trust for their products. The new mission will be to associate the ThreadX brand with vendor-neutral governance, communicate clear market positioning, and establish compatibility programs that will provide value to current and future adopters.<br></li>



<li><strong>Grow the ecosystem: </strong>With over 10 billion devices deployed using ThreadX, it is clear that this is an important and mature technology. To ensure a sustainable future for ThreadX we need to obtain the support, participation, and contributions of all ecosystem participants: silicon/SBC manufacturers, embedded system integrators, and tool vendors. We highly encourage every company with an interest in embedded technology to join the interest group to help define and secure the future of ThreadX.</li>
</ol>



<p>Eclipse ThreadX presents the industry with a game-changing opportunity. Having a performant, mature, safety and security certified, permissively-licensed, open source RTOS under vendor-neutral governance will enable new business and product opportunities around the world. We are very excited to work with the community to make ThreadX a huge success.</p>
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Microsoft opens sources ThreadX RTOS used in Raspberry Pis (246 pts)]]></title>
            <link>https://www.theregister.com/2023/11/28/microsoft_opens_sources_threadx/</link>
            <guid>38445020</guid>
            <pubDate>Tue, 28 Nov 2023 12:35:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2023/11/28/microsoft_opens_sources_threadx/">https://www.theregister.com/2023/11/28/microsoft_opens_sources_threadx/</a>, See on <a href="https://news.ycombinator.com/item?id=38445020">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>Microsoft is open sourcing the realtime operating system that it acquired with Express Logic, donating it to the Eclipse Foundation.</p>
<p>The vendor has made its ThreadX RTOS, and the Azure RTOS development suite that includes it, open source. The company has <a href="https://techcommunity.microsoft.com/t5/internet-of-things-blog/microsoft-contributes-azure-rtos-to-open-source/ba-p/3986318" rel="nofollow">contributed Azure RTOS</a> to the stewardship of the Eclipse Foundation, where it will be <a href="https://eclipse-foundation.blog/2023/11/21/introducing-eclipse-threadx/" rel="nofollow">known as Eclipse ThreadX</a> and available under the permissive MIT licence.</p>
<p>Although there are many Real-time OSes – RTOS for short – out there, you generally don't hear much about them. You may never have heard of ThreadX, but there's a fairly good chance that you unwittingly have several copies lying around or even running right now.</p>

    

<p>There are more famous RTOSes, such as Wind River's VxWorks: it's running on Mars, inside <a href="https://www.theregister.com/2021/02/23/perseverance_landing_video/">NASA's Perseverance Rover</a> for example. Blackberry's QNX RTOS, which we called <a href="https://www.theregister.com/2015/02/18/qnx_hypervisor/">the money-making part of the business</a>, has been in the spotlight twice: once as <a href="https://www.theregister.com/2010/09/28/blackberry_tablet_runs_qnx/">the basis for RIM's Blackberry X</a> fondleslab and smartphone range, but back in the 1990s for the amazing QNX <a href="http://qnx.puslapiai.lt/qnxdemo/qnx_demo_disk.htm" rel="nofollow">single-floppy demo disk</a>.</p>

        


        

<p>ThreadX was quite pervasive, though. Microsoft claims 12 billion devices run it, and you might own some of them. For a while it powered <a href="https://www.theregister.com/2017/05/01/intel_amt_me_vulnerability/">Intel's on-chip Management Engine</a>. It is also the firmware that controls every Raspberry Pi bigger than the Pi Pico. On the Pi 1, 2 and 3, it's <a href="https://github.com/raspberrypi/documentation/blob/develop/documentation/asciidoc/computers/configuration/boot_folder.adoc" rel="nofollow">the file on your Pi's SD card</a> called <code>bootcode.bin</code>; in the Pi 4 and 400, it's called <code>start*.elf</code>. Even though it's <a href="https://github.com/raspberrypi/firmware" rel="nofollow">on GitHub</a> and <a href="https://packages.debian.org/sid/raspi-firmware" rel="nofollow">included in Debian</a>, it's a proprietary "blob" (<em>B</em>inary <em>L</em>arge <em>OB</em>ject). It's a metaphorical sealed black box which doesn't even contain Arm code: instead, it runs on the Pi's VideoCore GPU. This is the primary device, the part that boots up the Pi and controls its hardware: the Arm cores are <a href="https://raspberrypi.stackexchange.com/a/106077/125748" rel="nofollow">slave devices</a> to the VideoCore GPU.</p>
<div><p><img src="https://regmedia.co.uk/2017/10/18/rpi_with_active_cooling.jpg?x=174&amp;amp;y=115&amp;amp;crop=1" width="174" height="115" alt="Raspberry Pi active cooling"></p><h2 title="Choose between five options">Ah lovely, here's something you can do with those Raspberry Pis, NUC PCs in the bottom of the drawer: Run Ubuntu Appliances on them</h2>
<p><a href="https://www.theregister.com/2020/06/18/ubuntu_raspberry_pi/"><span>READ MORE</span></a></p></div>
<p>This, incidentally, is why Xen only runs on the Pi 4 and later: they were the first versions where the Arm cores had their own interrupt controller, and even so, <a href="https://xenproject.org/2020/09/29/xen-on-raspberry-pi-4-adventures/" rel="nofollow">it took some work</a>. We have read that in the Pi 5, it's in EEPROM and does even less, meaning that the Arm cores have more control, as this <a href="https://forums.theregister.com/post/reply/4735439" rel="nofollow"><em>Reg</em> comment</a> bears out.</p>
<p>As soon as this innocent little OS turned 21 in 2019, Microsoft grabbed it, <a href="https://www.theregister.com/2020/05/21/microsoft_build_iot/">acquiring ThreadX owners Express Logic</a> and rebranding the poor thing as <em>Azure RTOS</em>, which hasn't done any favours for its brand awareness. The purchase came soon after <a href="https://www.theregister.com/2018/10/22/freertos_iot_platform_security_flaws/">AWS took over stewardship of FreeRTOS</a>, and some observers, such as <a href="https://www.reddit.com/r/embedded/comments/181g1nk/comment/kae4gi2/?utm_source=reddit&amp;utm_medium=web2x&amp;context=3" rel="nofollow">this commenter on Reddit</a>, claim that the deal was a response to Amazon's move. After the purchase, original developer William Lamie left, starting a new company which sells a "fifth-generation" RTOS with POSIX-compatible threads, called <a href="https://px5rtos.com/about/" rel="nofollow">PX5OS</a>.</p>
<p>Even so, ThreadX is a tested and established product; some parts even have <a href="https://www.tuvsud.com/en/industries/mobility-and-automotive/automotive-and-oem/iso-26262-functional-safety/iso-26262-functional-safety-certification-programme" rel="nofollow">TÜV Functional Safety</a> (FuSa) certification, such as the <a href="https://www.st.com/resource/en/product_presentation/stm32_stm8_functional-safety-packages.pdf" rel="nofollow">STM32 version</a> [PDF]. That kind of thing is powerfully attractive to some customers.</p>
<ul>

<li><a href="https://www.theregister.com/2023/04/12/python_management_eu/">Python head hisses at looming Euro cybersecurity rules</a></li>

<li><a href="https://www.theregister.com/2022/03/08/netbeans_13_arrives/">Open-source IDE NetBeans hits v13 – tweaks for Gradle, Maven</a></li>

<li><a href="https://www.theregister.com/2021/09/23/gaia_x_edc/">Eclipse Data Connector arrives for GAIA-X, Europe's plan to protect its cloud data from foreign tech firms</a></li>

<li><a href="https://www.theregister.com/2020/05/15/microsoft_brad_smith_open_source/">Everything OK with Microsoft? Windows giant admits it was 'on the wrong side of history' with regard to open source</a></li>
</ul>
<p>At this point, only the current version <a href="https://github.com/azure-rtos" rel="nofollow">is on GitHub</a>, and we don't see any trace of a VideoCore version. Although the GPU drivers have <a href="https://www.theregister.com/2012/10/24/raspberry_pi_broadcom_soc_drivers_now_fully_open_source/">long been open source</a>, the firmware never was, and attempts to write <a href="https://github.com/christinaa/rpi-open-firmware" rel="nofollow">an independent FOSS version</a> were never completed, for <a href="https://github.com/christinaa/rpi-open-firmware/issues/37" rel="nofollow">reasons explained</a> on the project page. Now, there is at least some hope that the Raspberry Pi Foundation might be able to get permission to release the source code for its version. As of last year, the foundation had <a href="https://www.theregister.com/2022/02/28/pi_at_10/">sold over 46 million</a> of the things, and if the whole software stack were open source, that would make them even more appealing for a lot of people. ®</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Modern C++ Programming Course (441 pts)]]></title>
            <link>https://github.com/federico-busato/Modern-CPP-Programming</link>
            <guid>38444834</guid>
            <pubDate>Tue, 28 Nov 2023 12:03:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/federico-busato/Modern-CPP-Programming">https://github.com/federico-busato/Modern-CPP-Programming</a>, See on <a href="https://news.ycombinator.com/item?id=38444834">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">Modern C++ Programming</h2>
<p dir="auto">
<a target="_blank" rel="noopener noreferrer" href="https://github.com/federico-busato/Modern-CPP-Programming/blob/master/other/cpp_logo.png"><img src="https://github.com/federico-busato/Modern-CPP-Programming/raw/master/other/cpp_logo.png"></a>
</p>
<p dir="auto">
    <a href="https://github.com/federico-busato/Modern-CPP-Programming/releases" alt="Release">
        <img src="https://camo.githubusercontent.com/1b6f7342b709e71b39458b3269e058319d733d1af5fafa3a573663b8002f329f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f762f72656c656173652f666564657269636f2d62757361746f2f4d6f6465726e2d4350502d50726f6772616d6d696e673f7374796c653d666f722d7468652d6261646765" data-canonical-src="https://img.shields.io/github/v/release/federico-busato/Modern-CPP-Programming?style=for-the-badge">
    </a>
</p>
<p dir="auto">
    <a href="https://github.com/federico-busato/Modern-CPP-Programming/commits/master" alt="Commits">
        <img src="https://camo.githubusercontent.com/2c71dfa2a8357ff58974cba85f484d59caf8946a60dd51f0aa58b29cc3995b18/68747470733a2f2f62616467656e2e6e65742f6769746875622f636f6d6d6974732f666564657269636f2d62757361746f2f4d6f6465726e2d4350502d50726f6772616d6d696e673f7374796c653d666f722d7468652d6261646765267363616c653d312e32" data-canonical-src="https://badgen.net/github/commits/federico-busato/Modern-CPP-Programming?style=for-the-badge&amp;scale=1.2">
    </a>
</p>
<p dir="auto">
    <a href="https://github.com/federico-busato/Modern-CPP-Programming/network/members" alt="Forks">
        <img src="https://camo.githubusercontent.com/3c0ebfad13db3deb80ee67da0ddaf15f309737ae4718d13c642ed24b351fee2f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f666f726b732f666564657269636f2d62757361746f2f4d6f6465726e2d4350502d50726f6772616d6d696e673f7374796c653d666f722d7468652d6261646765" data-canonical-src="https://img.shields.io/github/forks/federico-busato/Modern-CPP-Programming?style=for-the-badge">
    </a>
    
        <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/32cf116583a049de0a44673102fcee773225f7f13d62140763d6c73b80d87612/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f666564657269636f2d62757361746f2f4d6f6465726e2d4350502d50726f6772616d6d696e673f7374796c653d666f722d7468652d6261646765"><img src="https://camo.githubusercontent.com/32cf116583a049de0a44673102fcee773225f7f13d62140763d6c73b80d87612/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f666564657269636f2d62757361746f2f4d6f6465726e2d4350502d50726f6772616d6d696e673f7374796c653d666f722d7468652d6261646765" data-canonical-src="https://img.shields.io/github/stars/federico-busato/Modern-CPP-Programming?style=for-the-badge"></a>
    
</p>
<h2 tabindex="-1" dir="auto">C++11  /  C++14  /  C++17  / C++20 / (C++23)</h2>
<p dir="auto">This <em>open-access</em> course is directed at those who are already familiar with C and object-oriented programming towards a proficiency level of C++ programming. The course covers the basics of C++ programming and moves on to advanced C++ semantics and concepts.</p>
<p dir="auto"><strong>Key features</strong>:</p>
<ul dir="auto">
<li><em>Free and frequently updated</em></li>
<li>Include the <em>last language standard</em> concepts and features</li>
<li><em>Practical teaching</em>: small structured descriptions associated with code</li>
<li><em>Minimal code examples</em> for showing just a specific feature or issue without digressing</li>
<li><em>Complementary language aspects</em>: tools, coding conventions, project organization, and code optimization</li>
<li><em>Experience-based</em>: many aspects, examples, and problems come from real-world cases faced during my work as software engineer</li>
</ul>
<p dir="auto">If you enjoy the course or you find it useful, please add a <strong>Star</strong></p>
<p dir="auto"><a href="https://github.com/federico-busato/Modern-CPP-Programming"><img src="https://camo.githubusercontent.com/042085f25024e237f7121bbe74b9edcae59dd62617e34f158576b52b74c9d8e3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f666564657269636f2d62757361746f2f4d6f6465726e2d4350502d50726f6772616d6d696e673f7374796c653d736f6369616c" alt="stars - Modern-CPP-Programming" data-canonical-src="https://img.shields.io/github/stars/federico-busato/Modern-CPP-Programming?style=social"></a></p>
<h2 tabindex="-1" dir="auto">CHAPTERS</h2>
<table>
<thead>
<tr>
<th></th>
<th>TITLE</th>
<th>MAIN FOCUS</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>1</strong></td>
<td><strong><a href="https://github.com/federico-busato/Modern-CPP-Programming/blob/master/01.Introduction.pdf">Introduction</a></strong></td>
<td>History of C/C++, Areas of Applications, Course introduction</td>
</tr>
<tr>
<td><strong>2</strong></td>
<td><strong><a href="https://github.com/federico-busato/Modern-CPP-Programming/blob/master/02.Basic_Concepts_I.pdf">Basic Concepts I - Fundamental Types</a></strong></td>
<td>Types overview, operators, and conversion</td>
</tr>
<tr>
<td><strong>3</strong></td>
<td><strong><a href="https://github.com/federico-busato/Modern-CPP-Programming/blob/master/03.Basic_Concepts_II.pdf">Basic Concepts II - Integral and Floating-point Types</a></strong></td>
<td>Integral and floating-point types and their arithmetic</td>
</tr>
<tr>
<td><strong>4</strong></td>
<td><strong><a href="https://github.com/federico-busato/Modern-CPP-Programming/blob/master/04.Basic_Concepts_III.pdf">Basic Concepts III - Entities and Control Flow</a></strong></td>
<td>Enumerators, structures, control flow statements</td>
</tr>
<tr>
<td><strong>5</strong></td>
<td><strong><a href="https://github.com/federico-busato/Modern-CPP-Programming/blob/master/05.Basic_Concepts_IV.pdf">Basic Concepts IV - Memory Management</a></strong></td>
<td>Heap, Stack, pointers, references, const properties, conversion operators</td>
</tr>
<tr>
<td><strong>6</strong></td>
<td><strong><a href="https://github.com/federico-busato/Modern-CPP-Programming/blob/master/06.Basic_Concepts_V.pdf">Basic Concepts V - Functions and Preprocessing</a></strong></td>
<td>Functions, lambda expressions, preprocessing directives</td>
</tr>
<tr>
<td><strong>7</strong></td>
<td><strong><a href="https://github.com/federico-busato/Modern-CPP-Programming/blob/master/07.Object_Oriented_I.pdf">Object Oriented Programming I&nbsp;-&nbsp;Class&nbsp;Concepts</a></strong></td>
<td>Class hierarchy, constructor, destructor, class keywords</td>
</tr>
<tr>
<td><strong>8</strong></td>
<td><strong><a href="https://github.com/federico-busato/Modern-CPP-Programming/blob/master/08.Object_Oriented_II.pdf">Object Oriented Programming II&nbsp;-&nbsp;Polymorphism and Operator Overloading</a></strong></td>
<td>Polymorphism, operators overloading</td>
</tr>
<tr>
<td><strong>9</strong></td>
<td><strong><a href="https://github.com/federico-busato/Modern-CPP-Programming/blob/master/09.Templates_I.pdf">Templates and Meta-programming I&nbsp;-&nbsp;Function Templates and Compile-Time Utilities</a></strong></td>
<td>Function template, type traits</td>
</tr>
<tr>
<td><strong>10</strong></td>
<td><strong><a href="https://github.com/federico-busato/Modern-CPP-Programming/blob/master/10.Templates_II.pdf">Templates and Meta-programming II&nbsp;-&nbsp;Class Templates and SFINAE</a></strong></td>
<td>Class template, SFINAE</td>
</tr>
<tr>
<td><strong>11</strong></td>
<td><strong><a href="https://github.com/federico-busato/Modern-CPP-Programming/blob/master/11.Translation_Units_I.pdf">Translation Units&nbsp;I</a></strong></td>
<td>Linkage and One Definition Rule</td>
</tr>
<tr>
<td><strong>12</strong></td>
<td><strong><a href="https://github.com/federico-busato/Modern-CPP-Programming/blob/master/12.Translation_Units_II.pdf">Translation Units&nbsp;II</a></strong></td>
<td>Dealing with multiple translation units and files,&nbsp;&nbsp;<code>#include</code>, and modules</td>
</tr>
<tr>
<td><strong>13</strong></td>
<td><strong><a href="https://github.com/federico-busato/Modern-CPP-Programming/blob/master/13.Code_Convention.pdf">Code Conventions</a></strong></td>
<td>Project organization and main code conventions</td>
</tr>
<tr>
<td><strong>14</strong></td>
<td><strong><a href="https://github.com/federico-busato/Modern-CPP-Programming/blob/master/14.Ecosystem_I.pdf">Ecosystem&nbsp;I</a></strong></td>
<td>Debugging, and testing</td>
</tr>
<tr>
<td><strong>15</strong></td>
<td><strong><a href="https://github.com/federico-busato/Modern-CPP-Programming/blob/master/15.Ecosystem_II.pdf">Ecosystem&nbsp;II</a></strong></td>
<td>Cmake,&nbsp;documenting, and other Tools</td>
</tr>
<tr>
<td><strong>16</strong></td>
<td><strong><a href="https://github.com/federico-busato/Modern-CPP-Programming/blob/master/16.Utilities.pdf">Utilities</a></strong></td>
<td>Main <code>std</code> libraries</td>
</tr>
<tr>
<td><strong>17</strong></td>
<td><strong><a href="https://github.com/federico-busato/Modern-CPP-Programming/blob/master/17.Iterators_Containers_Alg.pdf">Containers, Iterators, and Algorithms</a></strong></td>
<td>Containers, iterators, algorithms, ranges</td>
</tr>
<tr>
<td><strong>18</strong></td>
<td><strong><a href="https://github.com/federico-busato/Modern-CPP-Programming/blob/master/18.Advanced_Topics_I.pdf">Advanced Topics&nbsp;I</a></strong></td>
<td>Move semantics, universal reference, type deduction</td>
</tr>
<tr>
<td><strong>19</strong></td>
<td><strong><a href="https://github.com/federico-busato/Modern-CPP-Programming/blob/master/19.Advanced_Topics_II.pdf">Advanced Topics&nbsp;II</a></strong></td>
<td>Error handling, C++ idioms, smart pointers</td>
</tr>
<tr>
<td><strong>20</strong></td>
<td><strong><a href="https://github.com/federico-busato/Modern-CPP-Programming/blob/master/20.Optimization_I.pdf">Optimization I&nbsp;-&nbsp;Basic Concepts</a></strong></td>
<td>Ahmdal Law, performance bounds, architecture concepts (ILP, SIMD, etc.), memory hierarchy</td>
</tr>
<tr>
<td><strong>21</strong></td>
<td><strong><a href="https://github.com/federico-busato/Modern-CPP-Programming/blob/master/21.Optimization_II.pdf">Optimization II - Code Optimization</a></strong></td>
<td>Arithmetic optimizations, memory optimizations, etc.</td>
</tr>
<tr>
<td><strong>22</strong></td>
<td><strong><a href="https://github.com/federico-busato/Modern-CPP-Programming/blob/master/22.Optimization_III.pdf">Optimization III -&nbsp;Non-Coding Optimizations and Benchmarking</a></strong></td>
<td>Compiler optimizations, profiling and benchmarking tools</td>
</tr>
</tbody>
</table>
<h2 tabindex="-1" dir="auto">TOPICS IN DETAILS</h2>
<p dir="auto"><strong><a href="https://github.com/federico-busato/Modern-CPP-Programming/blob/master/01.Introduction.pdf">1. Introduction</a></strong></p>
<ul dir="auto">
<li><strong>A Little History of C/C++ Programming Languages</strong></li>
<li><strong>Areas of Application and Popularity</strong></li>
<li><strong>C++ Philosophy</strong></li>
<li><strong>C++ Weakness</strong></li>
<li><strong>Books and References</strong></li>
<li><strong>The Course</strong></li>
</ul>
<p dir="auto"><strong><a href="https://github.com/federico-busato/Modern-CPP-Programming/blob/master/02.Basic_Concepts_I.pdf">2. Basic Concepts I - Fundamental Types</a></strong></p>
<ul dir="auto">
<li><strong>Preparation</strong>: What compiler should I use?, What editor/IDE compiler should I use?, How to compile?</li>
<li><strong>Hello World</strong>: I/O Stream</li>
<li><strong>C++ Fundamental Types Overview</strong>: Arithmetic types, Non-standard arithmetic types, <code>void</code> type, Pointer type and <code>nullptr</code></li>
<li><strong>Conversion Rules</strong></li>
<li><strong><code>auto</code> declaration</strong></li>
<li><strong>C++ Operators</strong>: Operators precedence, Prefix/Postfix increment/decrement, Assignment, Compound , and Comma operators, Spaceship operator <code>&lt;=&gt;</code> , Safe Comparison Operators</li>
</ul>
<p dir="auto"><strong><a href="https://github.com/federico-busato/Modern-CPP-Programming/blob/master/03.Basic_Concepts_II.pdf">3. Basic Concepts II - Integral and Floating-point Types</a></strong></p>
<ul dir="auto">
<li><strong>Integral Data Types</strong>: Fixed width integers, <code>size_t</code> and<code>ptrdiff_t</code>, When use signed/unsigned integer? Promotion, Truncation, Undefined behavior</li>
<li><strong>Floating-point Types and Arithmetic</strong>: IEEE Floating-point Standard and Other Representations, Normal/Denormal values, Infinity, Not a Number (<code>NaN</code>), Machine Epsilon, Units at the Last Place (ULP), Cheatsheet, Summary, Arithmetic Properties, Detect Floating-point Errors</li>
<li><strong>Floating-point Issues</strong>: Catastrophic cancellation, Floating-point comparison</li>
</ul>
<p dir="auto"><strong><a href="https://github.com/federico-busato/Modern-CPP-Programming/blob/master/04.Basic_Concepts_III.pdf">4. Basic Concepts III - Entities and Control Flow</a></strong></p>
<ul dir="auto">
<li><strong>Enumerators</strong></li>
<li><strong><code>struct</code>, Bitfield, <code>union</code></strong></li>
<li><strong>Control Flow</strong>: <code>if</code> Statement, <code>for</code> Loop, Range-base <code>for</code> loop, <code>switch</code>, <code>goto</code></li>
</ul>
<p dir="auto"><strong><a href="https://github.com/federico-busato/Modern-CPP-Programming/blob/master/05.Basic_Concepts_IV.pdf">5. Basic Concepts IV - Memory Management</a></strong></p>
<ul dir="auto">
<li><strong>Heap and Stack</strong>: Stack Memory, <code>new</code>, <code>delete</code>, Non-allocating placement allocation, Non-throwing allocation, Memory leak</li>
<li><strong>Initialization</strong>: Variable initialization, Uniform initialization, Fixed-size array initialization, Structure initialization, Dynamic memory initialization</li>
<li><strong>Pointers and References</strong>: Pointer Operations, Address-of operator <code>&amp;</code>, Reference</li>
<li><strong>Constant and Literals, <code>const</code>, <code>constexpr</code>, <code>consteval</code>, <code>constinit</code></strong>, <code>if constexpr</code>, <code>std::is constant evaluated()</code>, <code>if consteval</code></li>
<li><strong><code>volatile</code> keyword</strong></li>
<li><strong>Explicit Type Conversion</strong>: <code>static_cast</code>, <code>const_cast</code>, <code>reinterpret_cast</code>, Type punning</li>
<li><code>sizeof</code> Operator</li>
</ul>
<p dir="auto"><strong><a href="https://github.com/federico-busato/Modern-CPP-Programming/blob/master/06.Basic_Concepts_V.pdf">6. Basic Concepts V - Functions and Preprocessing</a></strong></p>
<ul dir="auto">
<li><strong>Declaration and Definition</strong></li>
<li><strong>Functions</strong>: Pass by-value, Pass by-pointer, Pass by-reference, Function signature and Overloading, Overloading and <code>=delete</code>, Default parameters, Attributes</li>
<li><strong>Function Pointer and Function Objects</strong></li>
<li><strong>Lambda Expressions</strong>: Capture list, Other features, Capture list and classes</li>
<li><strong>Preprocessing</strong>: Preprocessors, Common errors, Useful macro, Stringizing operator (<code>#</code>),  <code>#error</code> and <code>warning</code>, <code>#pragma</code>, Token-Pasting Operator (<code>##</code>), Variadic Macro</li>
</ul>
<p dir="auto"><strong><a href="https://github.com/federico-busato/Modern-CPP-Programming/blob/master/07.Object_Oriented_I.pdf">7. Object-Oriented Programming I&nbsp;-&nbsp;Class&nbsp;Concepts</a></strong></p>
<ul dir="auto">
<li><strong>C++ Classes</strong>: RAII Idiom</li>
<li><strong>Class Hierarchy</strong>:  Access specifiers, Inheritance access specifiers</li>
<li><strong>Class Constructor</strong>: Default constructor, Class initialization, Uniform initialization, Delegate constructor, <code>explicit</code> keyword, <code>[[nodiscard]]</code> and classes</li>
<li><strong>Copy Constructor</strong></li>
<li><strong>Class Destructor</strong></li>
<li><strong>Defaulted  Constructors, Destructor, and Operators</strong> (<code>= default</code>)</li>
<li><strong>Class Keywords</strong>: <code>this</code>, <code>static</code>, <code>const</code>, <code>mutable</code>, <code>using</code>, <code>friend</code>, <code>delete</code></li>
</ul>
<p dir="auto"><strong><a href="https://github.com/federico-busato/Modern-CPP-Programming/blob/master/08.Object_Oriented_II.pdf">8. Object-Oriented Programming II&nbsp;-&nbsp;Polymorphism and Operator Overloading</a></strong></p>
<ul dir="auto">
<li><strong>Polymorphism</strong>: <code>virtual</code> methods, Virtual table, <code>override</code> keyword, <code>final</code> keyword, Common errors, Pure virtual method, Abstract class and interface</li>
<li><strong>Inheritance Casting and Run-time Type Identification</strong></li>
<li><strong>Operator Overloading</strong>: Overview, Comparison operator <code>&lt;</code>, Spaceship operator <code>&lt;=&gt;</code>, Subscript operator <code>[]</code>, Multidimensional Subscript operator <code>[]</code>, Function call operator <code>()</code>, static operator <code>[]</code> and operator <code>()</code>, Conversion operator <code>T()</code>, Return type overloading resolution, Increment and decrement operators <code>++</code>/<code>--</code>, Assignment operator <code>=</code>, Stream operator <code>&lt;&lt;</code>, Operator Notes</li>
<li><strong>C++ Special Objects</strong>: Aggregate, Trivial class, Standard-layout class, Plain old data (POD), Hierarchy</li>
</ul>
<p dir="auto"><strong><a href="https://github.com/federico-busato/Modern-CPP-Programming/blob/master/09.Templates_I.pdf">9. Templates and Meta-programming I -&nbsp;Function Templates and Compile-Time Utilities</a></strong></p>
<ul dir="auto">
<li><strong>Function Template</strong>: Overview, Template parameters, Template parameter - default value, Specialization, Overloading</li>
<li><strong>Template Variable</strong></li>
<li><strong>Template Parameter Types</strong>: Generic Type Notes, <code>auto</code> Placeholder, Class template parameter type, Array and pointer types, Function type</li>
<li><strong>Compile-Time Utilities</strong>: <code>static_assert</code>, <code>decltype</code> Keyword, <code>using</code> Keyword</li>
<li><strong>Type Traits</strong>: Overview, Type traits library, Type manipulation</li>
</ul>
<p dir="auto"><strong><a href="https://github.com/federico-busato/Modern-CPP-Programming/blob/master/10.Templates_II.pdf">10. Templates and Meta-programming II - &nbsp;-&nbsp;Class Templates and SFINAE</a></strong></p>
<ul dir="auto">
<li><strong>Class Template</strong>: Class specialization, Template class constructor</li>
<li><strong>Class Template - Advanced Concepts</strong>: Class + Function - Specialization, Dependent Names - <code>typename</code> and <code>template</code> Keywords, Class template hierarchy and <code>using</code>, <code>friend</code> Keyword, Template Template Arguments</li>
<li><strong>Template Meta-Programming</strong></li>
<li><strong>SFINAE: Substitution Failure Is Not An Error</strong>: Function SFINAE, Class SFINAE, Class + Function SFINAE</li>
<li><strong>Variadic Template</strong>: Folding Expression, Variadic class template</li>
<li><strong>C++20 Concepts</strong>: Overview, <code>concept</code> Keyword, <code>requires</code> Clause, <code>requires</code> Expression, <code>requires</code> Expression + Clause, <code>requires</code> Clause + Expression, <code>requires</code> and <code>constexpr</code>, Nested <code>requires</code></li>
</ul>
<p dir="auto"><strong><a href="https://github.com/federico-busato/Modern-CPP-Programming/blob/master/11.Translation_Units_I.pdf">11. Translation Units I</a></strong></p>
<ul dir="auto">
<li><strong>Basic Concepts</strong>: Translation unit, Local and global scope, Linkage</li>
<li><strong>Storage Class and Duration</strong>: Storage duration, Storage class, <code>static</code> and <code>extern</code> keywords, Internal/External linkage examples</li>
<li><strong>Linkage of <code>const</code> and <code>constexpr</code></strong>: Static Initialization Order Fiasco</li>
<li><strong>Linkage Summary</strong></li>
<li><strong>Dealing with Multiple Translation Units</strong>: Class in multiple translation units</li>
<li><strong>One Definition Rule (ODR)</strong>: Global variable issues, ODR - Point 3, <code>inline</code> functions/variables, <code>constexpr</code> and <code>inline</code></li>
<li><strong>ODR - Function Template</strong>: Cases, <code>extern</code> keyword</li>
<li><strong>ODR - Class Template</strong>: Cases, <code>extern</code> keyword</li>
<li><strong>ODR Undefined Behavior and Summary</strong></li>
</ul>
<p dir="auto"><strong><a href="https://github.com/federico-busato/Modern-CPP-Programming/blob/master/12.Translation_Units_II.pdf">12. Translation Units II</a></strong></p>
<ul dir="auto">
<li><strong><code>#include</code> Issues</strong>: Forward declaration, Include guard, Circular dependencies, Common linking errors</li>
<li><strong>C++20 Modules</strong>: Overview, Terminology, Visibility and Reachability, Module unit types, Keywords, Global module fragment, Private module fragment, Header module unit, Module partitions</li>
<li><strong>Namespace</strong>: Namespace functions vs. <code>static</code> methods, Namespace alias, Anonymous namespace, <code>inline</code> namespace, Attributes and namespace</li>
<li><strong>Compiling Multiple Translation Units</strong>: Fundamental compiler flags, Compile Methods, Deal with libraries, Build static/dynamic libraries, Find dynamic library dependencies, Analyze object/executable symbols</li>
</ul>
<p dir="auto"><strong><a href="https://github.com/federico-busato/Modern-CPP-Programming/blob/master/13.Code_Convention.pdf">13. Code Conventions</a></strong></p>
<ul dir="auto">
<li><strong>C++ Project Organization</strong>: Project directories, Project files, “Common” Project Organization Notes, Alternative - “Canonical” project organization</li>
<li><strong>Coding Styles and Conventions</strong></li>
<li><strong><code>#include</code></strong></li>
<li><strong>Macro and Preprocessing</strong></li>
<li><strong>Namespace</strong></li>
<li><strong>Variables</strong></li>
<li><strong>Functions</strong></li>
<li><strong>Structs and Classes</strong></li>
<li><strong>Control Flow</strong></li>
<li><strong>Modern C++ Features</strong></li>
<li><strong>Maintainability</strong></li>
<li><strong>Naming</strong></li>
<li><strong>Readability and Formatting</strong></li>
<li><strong>Code Documentation</strong></li>
</ul>
<p dir="auto"><strong><a href="https://github.com/federico-busato/Modern-CPP-Programming/blob/master/14.Ecosystem_I.pdf">14. Ecosystem I</a></strong></p>
<ul dir="auto">
<li><strong>Debugging</strong></li>
<li><strong>Assertion</strong></li>
<li><strong>Execution debugging</strong></li>
<li><strong>Memory Debugging</strong>: <code>valgrind</code>, Stack protection</li>
<li><strong>Sanitizers</strong>: Address sanitizer, Leak sanitizer, Memory sanitizers, Undefined behavior sanitizer</li>
<li><strong>Debugging Summary</strong></li>
<li><strong>Compiler Warnings</strong></li>
<li><strong>Static Analysis</strong></li>
<li><strong>Code Testing</strong>: Unit test, Code coverage, Fuzz testing</li>
<li><strong>Code Quality</strong>: <code>clang-tidy</code></li>
</ul>
<p dir="auto"><strong><a href="https://github.com/federico-busato/Modern-CPP-Programming/blob/master/15.Ecosystem_II.pdf">15. Ecosystem II</a></strong></p>
<ul dir="auto">
<li><strong>CMake</strong>: <code>cmake</code> and <code>ctest</code></li>
<li><strong>Code Documentation</strong>: <code>doxygen</code></li>
<li><strong>Code Statistics</strong>: Count lines of code, Cyclomatic complexity analyzer</li>
<li><strong>Other Tools</strong>: Code formatting - <code>clang-format</code>, <code>Compiler Explorer</code>, Code transformation - <code>CppInsights</code>, Code autocompletion - <code>GitHub Co-Pilot/TabNine/Kite</code>, Local code search - <code>ripgrep</code>, Code search engine - <code>searchcode/grep.app</code>, Code benchmarking - <code>Quick-Bench</code>, Font for Coding</li>
</ul>
<p dir="auto"><strong><a href="https://github.com/federico-busato/Modern-CPP-Programming/blob/master/16.Utilities.pdf">16. Utilities</a></strong></p>
<ul dir="auto">
<li><strong>I/O Stream</strong>: Manipulator, <code>ofstream/ifstream</code></li>
<li><strong>Math Libraries</strong></li>
<li><strong>Strings</strong>: <code>std::string</code>, Conversion from/to numeric  values, <code>std::string_view</code>, <code>std::format</code>, <code>std::print</code></li>
<li><strong>Random Number</strong>: Basic Concepts, C++ <code>&lt;random&gt;</code>, Seed, PRNG period and quality, Distribution, Quasi-random</li>
<li><strong>Time Measuring</strong>: Wall-Clock time, User time, System time</li>
<li><strong>Std Template Classes</strong>: <code>std::byte</code> <code>std::pair</code>, <code>std::tuple</code>, <code>std::variant</code>, <code>std::optional</code>, <code>std::any</code></li>
<li><strong>Filesystem Library</strong>: Query methods, Modify methods</li>
</ul>
<p dir="auto"><strong><a href="https://github.com/federico-busato/Modern-CPP-Programming/blob/master/17.Iterators_Containers_Alg.pdf">17. Containers, Iterators, and Algorithms</a></strong></p>
<ul dir="auto">
<li><strong>Containers and Iterators</strong></li>
<li><strong>Sequence Containers</strong>: <code>std::array</code>, <code>std::vector</code>, <code>std::list</code>, <code>std::deque</code>, <code>std::forward_list</code></li>
<li><strong>Associative Containers</strong>: <code>std::set</code>, <code>std::map</code>, <code>std::multiset</code></li>
<li><strong>Container Adaptors</strong>: <code>std::stack</code>, <code>std::queue</code>, <code>std::priority_queue</code></li>
<li><strong>View</strong>: <code>std::span</code></li>
<li><strong>Implement a Custom Iterator</strong>: Semantic, Implement a simple Iterator</li>
<li><strong>Iterator Utility Methods</strong>: <code>std::advance</code>, <code>std::next</code>, <code>std::prev</code>, <code>std::distance</code>, Container access methods, Iterator traits</li>
<li><strong>Algorithms Library</strong>: <code>std::find_if</code>, <code>std::sort</code>, <code>std::accumulate</code>, <code>std::generate</code>, <code>std::remove_if</code></li>
<li><strong>C++20 Ranges</strong>: Key concepts, Range view,  Range adaptor, Range factory, Range algorithms, Range actions</li>
</ul>
<p dir="auto"><strong><a href="https://github.com/federico-busato/Modern-CPP-Programming/blob/master/18.Advanced_Topics_I.pdf">18. Advanced Topics I</a></strong></p>
<ul dir="auto">
<li><strong>Move Semantic</strong>: <code>lvalues</code> and <code>rvalues</code> references, Move semantic, Compiler implicitly declared, <code>std::move</code></li>
<li><strong>Universal Reference and Perfect Forwarding</strong>: Universal reference, Reference collapsing rules, Perfect forwarding</li>
<li><strong>Value Categories</strong></li>
<li><strong><code>&amp;</code>, <code>&amp;&amp;</code> Ref-qualifiers and <code>volatile</code> Overloading</strong></li>
<li><strong>Copy Elision and RVO</strong></li>
<li><strong>Type Deduction</strong>: Pass by-reference, Pass by-pointer, Pass by-value, <code>auto</code> deduction</li>
<li><strong><code>const</code> Correctness</strong></li>
</ul>
<p dir="auto"><strong><a href="https://github.com/federico-busato/Modern-CPP-Programming/blob/master/19.Advanced_Topics_II.pdf">19. Advanced Topics II</a></strong></p>
<ul dir="auto">
<li><strong>Undefined Behavior</strong></li>
<li><strong>Error Handling</strong>: C++ Exceptions, Defining custom exceptions, <code>noexcept</code> keyword, Memory allocation issues, Alternative error handling approaches</li>
<li><strong>C++ Idioms</strong>: Rule of zero/three/five, Singleton, PIMPL, CRTP, Template Virtual Functions</li>
<li><strong>Smart pointers</strong>: <code>std::unique_ptr</code>, <code>std::shared_ptr</code>, <code>std::weak_ptr</code></li>
<li><strong>Concurrency</strong>: Thread Methods, Mutex, Atomic, Task-based parallelism</li>
</ul>
<p dir="auto"><strong><a href="https://github.com/federico-busato/Modern-CPP-Programming/blob/master/20.Optimization_I.pdf">20. Optimization I&nbsp;-&nbsp;Basic Concepts</a></strong></p>
<ul dir="auto">
<li><strong>Introduction</strong>: Moore’s Law, Moore’s Law limitations, Reasons for Optimizing</li>
<li><strong>Basic Concepts</strong>: Asymptotic complexity, Time-Memory Trade-off, Developing Cycle, Ahmdal's law, Throughput, Bandwidth, Latency, Performance bounds, Arithmetic intensity</li>
<li><strong>Basic Architecture Concepts</strong>: Instruction-level parallelism (ILP), Little’s law, Data-level parallelism (SIMD), Thread-level parallelism (TLP), Single Instruction Multiple Threads (SIMT), RISC, CISC Instruction sets</li>
<li><strong>Memory Hierarchy</strong>: Memory hierarchy concepts, Memory locality</li>
</ul>
<p dir="auto"><strong><a href="https://github.com/federico-busato/Modern-CPP-Programming/blob/master/21.Optimization_II.pdf">21. Optimization II&nbsp;-&nbsp;Code Optimization</a></strong></p>
<ul dir="auto">
<li><strong>I/O Operations</strong>: <code>printf</code>, Memory mapped I/O, Speed up raw data loading</li>
<li><strong>Memory Optimizations</strong>: Heap memory, Stack memory, Cache utilization, data alignment, Memory Prefetch</li>
<li><strong>Arithmetic</strong>: Data types, Operations, Conversion, Floating-point, Compiler intrinsic functions, Value in a range, Lookup table</li>
<li><strong>Control Flow</strong>: Loop hoisting, Loop unrolling, Branch hints, Compiler hints, Recursion</li>
<li><strong>Functions</strong>: Function call cost, Argument passing, Function optimizations, Function inlining, Pointers aliasing</li>
<li><strong>C++ Objects</strong>: Object RAII optimizations</li>
<li><strong>Std Library and Other Language Aspects</strong></li>
</ul>
<p dir="auto"><strong><a href="https://github.com/federico-busato/Modern-CPP-Programming/blob/master/22.Optimization_III.pdf">22. Optimization III -&nbsp;Non-Coding Optimizations and Benchmarking</a></strong></p>
<ul dir="auto">
<li><strong>Compiler Optimizations</strong>: About the compiler, Compiler optimization flags, Linker optimization flags, Architecture flags, Help the Compiler to produce better code, Profile guided optimization (PGO), Post-Processing Binary Optimizer</li>
<li><strong>Compiler Transformation Techniques</strong></li>
<li><strong>Libraries and Data Structures</strong>: External libraries, Std library</li>
<li><strong>Performance Benchmarking</strong>: What to test?, Workload/Dataset quality, Cache behavior, Stable CPU performance, Program, Multi-threads considerations, Program memory layout, Measurement overhead, Compiler optimizations, Metric evaluation</li>
<li><strong>Profiling</strong>: <code>gprof</code>, <code>uftrace</code>, <code>callgrind</code>, <code>cachegrind</code>, <code>perf</code> Linux profiler</li>
<li><strong>Parallel Computing</strong>: Concurrency vs. Parallelism, Performance scaling, Gustafson’s Law, Parallel programming languages</li>
</ul>
<h3 tabindex="-1" dir="auto">Roadmap</h3>
<ol dir="auto">
<li>Software Design Chapter</li>
<li>Build Aspects Chapter (e.g. reducing build time)</li>
</ol>
<h3 tabindex="-1" dir="auto">Essential Tool</h3>
<p dir="auto">Online compiler and execution: <a href="https://godbolt.org/" rel="nofollow">CompilerExplorer</a></p>
<ul dir="auto">
<li>for code execution: [Add new..] -&gt; [execution only]</li>
</ul>
<h3 tabindex="-1" dir="auto">Reporting bugs and contributing</h3>
<p dir="auto">If you find any typo, conceptual error, or section to improve, please report them by writing directly to me or by using the <code>issue</code> panel</p>
<p dir="auto">
    <a href="https://github.com/federico-busato/Modern-CPP-Programming-Material/issues" alt="Issues">
        <img src="https://camo.githubusercontent.com/b5b92cd46105f0494947c1a0642ff4e9ff7fdef596b3f89bd812817181a0738b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732d636c6f7365642f666564657269636f2d62757361746f2f4d6f6465726e2d4350502d50726f6772616d6d696e673f7374796c653d666f722d7468652d6261646765" data-canonical-src="https://img.shields.io/github/issues-closed/federico-busato/Modern-CPP-Programming?style=for-the-badge">
    </a>
</p>
<h2 tabindex="-1" dir="auto">Author</h2>
<p dir="auto"><code>Federico Busato</code></p>
<ul dir="auto">
<li>Twitter: <a href="https://twitter.com/fedebusato" rel="nofollow">twitter.com/fedebusato</a></li>
<li>LinkedIn: <a href="https://www.linkedin.com/in/federico-busato/" rel="nofollow">www.linkedin.com/in/federico-busato/</a></li>
</ul>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Half Life:25th Anniversary Documentary (354 pts)]]></title>
            <link>https://www.youtube.com/watch?v=TbZ3HzvFEto</link>
            <guid>38444719</guid>
            <pubDate>Tue, 28 Nov 2023 11:40:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.youtube.com/watch?v=TbZ3HzvFEto">https://www.youtube.com/watch?v=TbZ3HzvFEto</a>, See on <a href="https://news.ycombinator.com/item?id=38444719">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[PeerTube v6 is out, and powered by your ideas (360 pts)]]></title>
            <link>https://framablog.org/2023/11/28/peertube-v6-is-out-and-powered-by-your-ideas/</link>
            <guid>38443855</guid>
            <pubDate>Tue, 28 Nov 2023 09:07:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://framablog.org/2023/11/28/peertube-v6-is-out-and-powered-by-your-ideas/">https://framablog.org/2023/11/28/peertube-v6-is-out-and-powered-by-your-ideas/</a>, See on <a href="https://news.ycombinator.com/item?id=38443855">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="wtr-content" data-bg="#FFFFFF" data-fg="#6a5687" data-width="5" data-mute="" data-fgopacity="0.75" data-mutedopacity="0.5" data-placement="top" data-placement-offset="0" data-content-offset="0" data-placement-touch="top" data-placement-offset-touch="0" data-transparent="1" data-shadow="1" data-touch="1" data-non-touch="1" data-comments="" data-commentsbg="#ffcece" data-location="page" data-mutedfg="#b49cd9" data-endfg="#f44813" data-rtl=""><p><a href="https://framablog.org/2023/11/28/peertube-v6-is-out-and-powered-by-your-ideas/?print=pdf" target="_blank"><img decoding="async" src="https://framablog.org/wp-content/plugins/pdf-print/images/pdf.png" alt="image_pdf" title="Afficher le PDF"></a><a href="https://framablog.org/2023/11/28/peertube-v6-is-out-and-powered-by-your-ideas/?print=print" target="_blank"><img decoding="async" src="https://framablog.org/wp-content/plugins/pdf-print/images/print.png" alt="image_print" title="Contenu imprimé"></a></p><p>It’s #givingtuesday, so we’re giving you PeerTube v6 today&nbsp;! <a href="https://joinpeertube.org/">PeerTube</a> is the software we develop for creators, media, institutions, educators… to manage their own video platform, as an alternative to YouTube and Twitch.</p>


<p>The sixth major version is being released today and we are very proud&nbsp;! It is the most ambitious one since we added peer-to-peer livestreaming. There is a good reason for that&nbsp;: we packed this v6 with features inspired by <a href="https://ideas.joinpeertube.org/">your ideas</a>&nbsp;!</p>
<p>We are so eager to present all the work we achieved that we’ll get right into it. But stay tuned&nbsp;: in two weeks, we’ll take more time to talk about PeerTube’s history, the state of this project and the great plans we have for its future&nbsp;!</p>
<figure id="attachment_32655"><a href="https://soutenir.framasoft.org/"><img fetchpriority="high" decoding="async" src="https://framablog.org/wp-content/uploads/2023/11/3-youtube-videoraptor-light-265x300.png" alt="Illustration of Videoraptor, an insectoid monster whose three heads bear the logos of YouTube, Vimeo and Twitch." width="265" height="300" srcset="https://framablog.org/wp-content/uploads/2023/11/3-youtube-videoraptor-light-265x300.png 265w, https://framablog.org/wp-content/uploads/2023/11/3-youtube-videoraptor-light-906x1024.png 906w, https://framablog.org/wp-content/uploads/2023/11/3-youtube-videoraptor-light-768x868.png 768w, https://framablog.org/wp-content/uploads/2023/11/3-youtube-videoraptor-light-1358x1536.png 1358w, https://framablog.org/wp-content/uploads/2023/11/3-youtube-videoraptor-light-1811x2048.png 1811w" sizes="(max-width: 265px) 100vw, 265px"></a><figcaption>Click to support us and help push back Videoraptor – Illustration CC-By <a href="https://www.peppercarrot.com/en/files/framasoft.html">David Revoy</a></figcaption></figure>
<h2 id="this-year-two-minor-updates-and-a-major-achievement">This year&nbsp;: two minor updates and a major achievement</h2>
<p>In 2023, and before preparing this major update, we released only two minor versions… but one of them brought to the table a major technical feature that will help democratize video hosting even more.</p>
<h3 id="march-2023-peertube-v5-1">March 2023&nbsp;: PeerTube v5.1</h3>
<p>You’ll get more details in <a href="https://joinpeertube.org/news/release-5.1">the news dedidacted to the 5.1 release</a>, so to keep it short, this version brought&nbsp;:</p>
<ul>
<li>an «&nbsp;asking for an account&nbsp;» feature, where instance moderators can <strong>manage and moderate news account requests</strong>&nbsp;;</li>
<li>a <strong>back-to-live button</strong>, so when you can lag behind during a livestream, you can go back to the direct</li>
<li>Improvements on the <strong>authentification plugin</strong>, to facilitate signing on with external credentials</li>
</ul>
<h3 id="june-2023-peertube-5-2-">June 2023&nbsp;: PeerTube 5.2…</h3>
<p>As you’ll find out in our <a href="https://joinpeertube.org/news/release-5.2">5.2 release blogpost</a>, there were some smaller but important new features such as&nbsp;:</p>
<ul>
<li>Adapting <strong>RSS feeds to podcast standards</strong>, so any podcast client could be able to read a PeerTube channel, for example</li>
<li>The option to <strong>set the privacy of a livestream replay</strong>, that way streamers can choose beforehand if the replay of their live will be <em>Public</em>, <em>Unlisted</em>, <em>Private</em> or <em>Internal</em></li>
<li>Improved mouse-free navigation&nbsp;: for those who prefer or need to <strong>navigate using their keyboard</strong></li>
<li>And <strong>upgrades in our documentation</strong> (it’s quite thorough&nbsp;: <a href="https://docs.joinpeertube.org/">check it out</a>&nbsp;!)</li>
</ul>
<h3 id="-with-a-major-feature-remote-transcoding">…with a major feature&nbsp;: Remote Transcoding</h3>
<p>But the game changer in this 5.2 release was the new <strong>remote transcoding feature</strong>.</p>
<p>When a creator uploads a video (or when they are streaming live), PeerTube needs to transform their video file into an efficient format. This task is called video transcoding, and it consumes lots of CPU power. PeerTube admins used to need (costly) big-CPU servers for a task that wasn’t permanent… until remote transcoding.</p>
<p>Remote transcoding allows PeerTube admins to deport some or all of their transcoding tasks to another, more powerful server, one that can be shared with other admins, for example.</p>
<p><strong>It makes the whole PeerTube administration cheaper, more resilient, more power-efficient</strong>… and opens a way of sharing resources between communities&nbsp;!</p>
<p>We want, once again to thank the NGI Entrust program and the NLnet foundation for the grant that helped us achieve such a technical improvement&nbsp;!</p>
<figure id="attachment_32632"><a href="https://soutenir.framasoft.org/"><img decoding="async" src="https://framablog.org/wp-content/uploads/2023/11/3-sepia-276x300.png" alt="Drawing of Sepia, PeerTube's octopus mascot. They are wearing a superhero cape, with the initials &quot;6&quot; on his chest." width="276" height="300" srcset="https://framablog.org/wp-content/uploads/2023/11/3-sepia-276x300.png 276w, https://framablog.org/wp-content/uploads/2023/11/3-sepia-944x1024.png 944w, https://framablog.org/wp-content/uploads/2023/11/3-sepia-768x833.png 768w, https://framablog.org/wp-content/uploads/2023/11/3-sepia.png 1338w" sizes="(max-width: 276px) 100vw, 276px"></a><figcaption>Click to support us and help Sepia reach their potential – Illustration CC-By <a href="https://www.peppercarrot.com/en/files/framasoft.html">David Revoy</a></figcaption></figure>
<h2 id="peertube-v6-powered-by-your-ideas-">PeerTube v6 is Based… (on your ideas)</h2>
<p>Enough about the past, let’s detail the features of this new major version. Note that, for this whole 2023 roadmap, we developed features suggested and upvoted by… you&nbsp;! Or at least by those of you who shared your ideas on <a href="https://ideas.joinpeertube.org/">our feedback website</a>.</p>
<h3 id="protect-your-videos-with-passwords-">Protect your videos with passwords&nbsp;!</h3>
<p>That was a very awaited feature. Password-protected videos can be used in lots of situations&nbsp;: to create exclusive content, mark a step in a pedagogical plan, share videos with people trusted by the ones you trust…</p>

<p>On their PeerTube account, creators can now set a single password when they upload, import or update the settings of their videos.</p>
<p>But with our REST API, admins and developers can take it a step further. They can set and store as many passwords as they want, thus easily give and revoke access to videos.</p>
<p>This feature was the work of Wicklow, during his internship with us.</p>
<h3 id="video-storyboard-preview-what-s-coming-">Video storyboard&nbsp;: preview what’s coming&nbsp;!</h3>
<p>If you like to peruse your videos online, you might be used to hover the progress bar with your mouse or finger. Usually, a preview of the frame appears as a thumbnail&nbsp;: that’s called a storyboard feature, and that’s now available in PeerTube&nbsp;!</p>

<p>Please note that as Storyboards are only generated when uploading (or importing) a video, they will only be available for new videos of instances that upgraded to v6…</p>
<p>Or you can ask, very kindly, to your admin(s) that they use the magical <code>npm run create-generate-storyboard-job</code> command (warning&nbsp;: this task might need some CPU power), and generate storyboards for older videos.</p>
<h3 id="upload-a-new-version-of-your-video">Upload a new version of your video&nbsp;!</h3>
<p>Sometimes, video creators want to update a video, to correct a mistake, offer new informations… or just to propose a better cut of their work&nbsp;!</p>
<p>Now, with PeerTube, they can upload and replace an older version of their video. Though the older video file will be permanently erased (no backsies&nbsp;!), creators will keep the same URL, title and infos, comments, stats, etc.</p>

<p>Obviously, such a feature requires trust between videomakers and admins, who don’t want to be responsible for a cute kitten video being «&nbsp;updated&nbsp;» into an awful advertisement for cat-hating groups.</p>
<p>That’s why such a feature will only be available if admins choose to enable it on their PeerTube platforms, and will display a «&nbsp;Video re-upload&nbsp;» tag on updated videos.</p>
<h3 id="get-chapters-in-your-videos-">Get chapters in your videos&nbsp;!</h3>
<p>Creators can now add chapters to their videos on PeerTube. In a video settings page, they’ll get a new «&nbsp;chapters&nbsp;» tab where they’ll only need to specify the timecode and title of each chapter for PeerTube to add it.</p>

<p>If they import their video from another platform (<em>cough</em> YouTube <em>cough</em>), PeerTube should automatically recognize and import chapters set on this distant video.</p>
<p>When chapters are set, markers will appear and segment the progress bar. Chapter titles will be displayed when you hover or touch one of those chapters segments.</p>
<h3 id="stress-tests-performance-and-config-recommandations">Stress tests, performance and config recommandations</h3>
<p>Last year, thanks to French indie journalist David Dufresne’s Au Poste&nbsp;! livestream show and his hoster Octopuce, we got a livestream stress test with more than 400 simultaneous viewers&nbsp;: <a href="https://www.octopuce.fr/test-de-charge-dun-peertube-en-live-avec-auposte/">see the report here on Octopuce’s blog[FR]</a>.</p>
<p>Such tests are really helpful to understand where we can improve PeerTube to reduce bottlenecks, improve performance, and give advice on the best configuration for a PeerTube server if an admin plans on getting a lot of traffic.</p>
<p>That’s why this year, we have decided to realize more tests, with a thousand simultaneous users simulated both in livestream and classic video streaming conditions. Lots of thanks and datalove to Octopuce for helping us deploy our test infrastructure.</p>
<p>We will soon publish a report with our conclusions and recommended server configurations depending on usecases (late 2023, early 2024). In the meantime, early tests motivated us to <strong>add many performances improvements</strong> into this v6, such as (brace yourselves for the technical terms)&nbsp;:</p>
<ul>
<li>Process unicast HTTP job in worker threads</li>
<li>Sign ActivityPub requests in worker threads</li>
<li>Optimize recommended videos HTTP request</li>
<li>Optimize videos SQL queries when filtering on lives or tags</li>
<li>Optimize /videos/{id}/views endpoint with many viewers</li>
<li>Add ability to disable PeerTube HTTP logs</li>
</ul>
<h3 id="-and-there-s-always-more-">…and there’s always more&nbsp;!</h3>
<p>A new major version always comes with its lot of changes, improvements, bugfixes, etc. You can read <a href="https://github.com/Chocobozzz/PeerTube/releases/tag/v6.0.0">the complete log here</a>, but here are the highlights&nbsp;:</p>
<ul>
<li>We needed to settle a technical debt&nbsp;: <strong>v6 removes support for WebTorrent to focus on HLS (with WebRTC P2P)</strong>. Both are technical bricks used to get peer-to-peer streaming in web browsers, but HLS is more fitted to what we are doing (and plan to do) with PeerTube</li>
<li>The <strong>video player is more efficient</strong>
<ul>
<li>It is not being rebuilt anymore every time the video changes</li>
<li>It keeps your watching settings (speed, fullscreen, etc.) when the video changes</li>
<li>It automatically adjust its size to match the video ratio</li>
</ul>
</li>
<li>We have <strong>improved SEO</strong>, to help videos hosted on a PeerTube platform appear higher in the search results of search engines</li>
<li>We worked a lot on <strong>improving PeerTube’s accessibility</strong> on many levels, to streamline the experience of people with disabilities.</li>
</ul>
<figure id="attachment_32657"><a href="https://soutenir.framasoft.org/"><img decoding="async" src="https://framablog.org/wp-content/uploads/2023/11/5-youtube-premium-yetube-light-279x300.png" alt="Illustration de Yetube, un monstre de type Yéti avec le logo de YouTube Premium." width="279" height="300" srcset="https://framablog.org/wp-content/uploads/2023/11/5-youtube-premium-yetube-light-279x300.png 279w, https://framablog.org/wp-content/uploads/2023/11/5-youtube-premium-yetube-light-951x1024.png 951w, https://framablog.org/wp-content/uploads/2023/11/5-youtube-premium-yetube-light-768x827.png 768w, https://framablog.org/wp-content/uploads/2023/11/5-youtube-premium-yetube-light-1427x1536.png 1427w, https://framablog.org/wp-content/uploads/2023/11/5-youtube-premium-yetube-light-1903x2048.png 1903w" sizes="(max-width: 279px) 100vw, 279px"></a><figcaption>Click to support us and help push Yetube back – CC-By Illustration <a href="https://www.peppercarrot.com/en/files/framasoft.html">David Revoy</a></figcaption></figure>
<h2 id="what-about-peertube-s-future-">What about PeerTube’s future&nbsp;?</h2>
<p>With YouTube waging war against adblockers, Twitch increasingly exploiting streamers, and everyone becoming more and more aware of the toxicity of this system… PeerTube is getting traction, recognition and a growing community.</p>
<p>We have so <strong>many announcements to make about the future we plan for PeerTube</strong>, that we will publish a separate news, in two weeks. We are also planning on hosting an «&nbsp;Ask Us Anything&nbsp;» livestream, to answer the questions you’d have about PeerTube.</p>
<p>Please stay tuned by subscribing to <a href="https://joinpeertube.org/news">PeerTube’s Newsletter</a>, following <a href="https://framapiaf.org/@peertube">PeerTube’s Mastodon account</a> or keeping an eye on the <a href="https://framablog.org/">Framablog</a>.</p>
<figure id="attachment_32914"><a href="https://soutenir.framasoft.org/"><img loading="lazy" decoding="async" src="https://framablog.org/wp-content/uploads/2023/11/sepia-1024x576.jpg" alt="Drawing in the style of a fighting video game, where the octopus of PeerTube and the monster of YouTube, Twitch and Vimeo go head to head." width="1024" height="576" srcset="https://framablog.org/wp-content/uploads/2023/11/sepia-1024x576.jpg 1024w, https://framablog.org/wp-content/uploads/2023/11/sepia-300x169.jpg 300w, https://framablog.org/wp-content/uploads/2023/11/sepia-768x432.jpg 768w, https://framablog.org/wp-content/uploads/2023/11/sepia-1536x864.jpg 1536w, https://framablog.org/wp-content/uploads/2023/11/sepia.jpg 1920w" sizes="(max-width: 1024px) 100vw, 1024px"></a><figcaption>Click to support us and help Sepia push back Videoraptor – Illustration CC-By <a href="https://www.peppercarrot.com/en/files/framasoft.html">David Revoy</a></figcaption></figure>
<h2 id="thank-you-for-supporting-peertube-and-framasoft">Thank you for supporting PeerTube and Framasoft</h2>
<p>In the meantime, we want to remind you that all these developments were achieved by only one full-time payed developer, an intern, and a fabulous community (lots of datalove to Chocobozzz, Wicklow, and the many, many contributors&nbsp;: y’all are amazing&nbsp;!)</p>
<p>Framasoft being a French not-for-profit mainly funded by grassroots donations (75&nbsp;% of our yearly income comes from people like you and us), PeerTube development has been funded by two main sources&nbsp;:</p>
<ul>
<li>French-speaking FOSS enthusiasts</li>
<li>Grants from the NGI initiative, through NLnet (in 2021 &amp; 2023)</li>
</ul>
<p>If you are a non-French-speaking PeerTube aficionado, please consider <strong>supporting our work by <a href="https://soutenir.framasoft.org/">making a donation to Framasoft</a></strong>. It will greatly help us fund our many, many projects, and balance our 2024 budget.</p>
<p>Once again this year we need you, your support, your sharing to help us regain ground on the toxic GAFAM web and multiply the number of ethical digital spaces. So we’ve asked <a href="https://www.peppercarrot.com/fr/files/framasoft.html">David Revoy</a> to help us present this on our <a href="https://soutenir.framasoft.org/">support Framasoft</a> page, which we invite you to visit (because it’s beautiful) and above all to share as widely as possible&nbsp;:</p>
<p><a href="https://soutenir.framasoft.org/"><img loading="lazy" decoding="async" src="https://framablog.org/wp-content/uploads/2023/11/2023-11-28-Soutenir-Framasoft.png" alt="Screenshot of the Framasoft 2023 donation bar at 12% - €23575" width="1110" height="591" srcset="https://framablog.org/wp-content/uploads/2023/11/2023-11-28-Soutenir-Framasoft.png 1110w, https://framablog.org/wp-content/uploads/2023/11/2023-11-28-Soutenir-Framasoft-300x160.png 300w, https://framablog.org/wp-content/uploads/2023/11/2023-11-28-Soutenir-Framasoft-1024x545.png 1024w, https://framablog.org/wp-content/uploads/2023/11/2023-11-28-Soutenir-Framasoft-768x409.png 768w" sizes="(max-width: 1110px) 100vw, 1110px"></a></p>
<p><strong>If we are to balance our budget for 2024, we have five weeks to raise €176,425&nbsp;: we can’t do it without your help&nbsp;!</strong></p>
<p><a href="https://soutenir.framasoft.org/" target="_blank" rel="noopener"><strong>Support Framasoft</strong></a></p>
<p>Thanks again for supporting PeerTube,<br>
Framasoft’s team.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Is Knuth's TAOCP worth the time and effort? (2023) (219 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=38443668</link>
            <guid>38443668</guid>
            <pubDate>Tue, 28 Nov 2023 08:40:19 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=38443668">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><td><table>
        <tbody><tr id="38443668">
      <td><span></span></td>      <td><center><a id="up_38443668" href="https://news.ycombinator.com/vote?id=38443668&amp;how=up&amp;goto=item%3Fid%3D38443668"></a></center></td><td><span><a href="https://news.ycombinator.com/item?id=38443668">Ask HN: Is Knuth's TAOCP worth the time and effort? (2023)</a></span></td></tr><tr><td colspan="2"></td><td><span>
          <span id="score_38443668">112 points</span> by <a href="https://news.ycombinator.com/user?id=toinewx">toinewx</a> <span title="2023-11-28T08:40:19"><a href="https://news.ycombinator.com/item?id=38443668">3 hours ago</a></span> <span id="unv_38443668"></span> | <a href="https://news.ycombinator.com/hide?id=38443668&amp;goto=item%3Fid%3D38443668">hide</a> | <a href="https://hn.algolia.com/?query=Ask%20HN%3A%20Is%20Knuth%27s%20TAOCP%20worth%20the%20time%20and%20effort%3F&amp;type=story&amp;dateRange=all&amp;sort=byDate&amp;storyText=false&amp;prefix&amp;page=0">past</a> | <a href="https://news.ycombinator.com/fave?id=38443668&amp;auth=cbb7e6c6f888ad6103e9191e4a503745836b0d15">favorite</a> | <a href="https://news.ycombinator.com/item?id=38443668">72&nbsp;comments</a>        </span>
              </td></tr>
    <tr></tr><tr><td colspan="2"></td><td><div><p>I'm starting the first volume.
Right at the start, Knuth introduces Induction Mathematical Proof, and more specifically tries to show that we can describe it as an `algorithm mathematical proof`.</p><p>I showed it to a friend who is quite good at math, and he told me the book may be trying too hard especially in the examples variety, and how it might not be needed for comprehension's sake.</p><p>Would you still recommend this book, and if yes, in what circumstances?</p></div></td></tr>        <tr></tr><tr><td colspan="2"></td><td><form action="comment" method="post"></form></td></tr>  </tbody></table>
  </td></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Noyb files GDPR complaint against Meta over "Pay or Okay" (120 pts)]]></title>
            <link>https://noyb.eu/en/noyb-files-gdpr-complaint-against-meta-over-pay-or-okay</link>
            <guid>38443292</guid>
            <pubDate>Tue, 28 Nov 2023 07:20:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://noyb.eu/en/noyb-files-gdpr-complaint-against-meta-over-pay-or-okay">https://noyb.eu/en/noyb-files-gdpr-complaint-against-meta-over-pay-or-okay</a>, See on <a href="https://news.ycombinator.com/item?id=38443292">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          
                    

<p><strong>Today, <em>noyb </em>filed a complaint against Meta with the Austrian data protection authority. European users now have the “choice” to either consent to being tracked for personalized advertising – or pay up to €251.88 a year to retain their fundamental right to data protection on Instagram and Facebook. Not only is the cost unacceptable, but industry numbers suggest that only 3 percent of people want to be tracked – while more than 99 percent decide against a payment when faced with a “privacy fee”. If Meta gets away with this, competitors will soon follow in its footsteps. Given that the average phone has 35 apps installed, keeping your phone private could soon cost around € 8,815 a year.</strong></p>

<ul><li><a href="https://noyb.eu/sites/default/files/2023-11/Complaint%20-%20Meta%20Pay%20or%20Okay%20-%20REDACTED.pdf">Complaint with the Austrian data protection authority (automated machine-translation)</a></li>
</ul><p><strong>Another attempt to circumvent EU privacy laws.</strong> The European Court of Justice (CJEU) <a href="https://noyb.eu/en/cjeu-declares-metafacebooks-gdpr-approach-largely-illegal">ruled in July</a> that Meta’s handling of user data for personalized ads was illegal. But not only that: In January, the European Data Protection Board <a href="https://noyb.eu/en/breaking-meta-prohibited-use-personal-data-advertising">fined Meta €390 million</a> for this violation and ordered the company to obtain users’ consent, based on a <em>noyb </em><a href="https://noyb.eu/en/noybeu-filed-complaints-over-forced-consent-against-google-instagram-whatsapp-and-facebook">complaint from 2018</a>. In its next attempt to undermine EU law, Meta now wants to charge people for choosing a privacy-friendly setting. Since the beginning of November, Instagram and Facebook users have had to choose between paying up to €251.88 a year or having their personal data surveilled for targeted advertising.</p>

<p><strong>“Freely given” consent at a high price?</strong> Under EU law, consent to online tracking and personalized advertising is only valid if it is “freely given”. This is to ensure that users only give up their fundamental right to privacy if it is their genuine free will to do so. Meta has now implemented the exact opposite of a genuinely free choice: Facebook alone will introduce a “privacy fee” of up to €12.99 per month if users do not consent to their personal data being processed for targeted advertising. Each linked account (such as Instagram) will cost another €8, making a total of €251.88 a year for one person using Instagram and Facebook. By comparison: <a href="https://s21.q4cdn.com/399680738/files/doc_earnings/2023/q3/presentation/Earnings-Presentation-Q3-2023.pdf">Meta says</a> its average revenue per user in Europe between Q3 2022 and Q3 2023 was $16.79. This equates to an annual revenue of just €62,88 per user – and puts the monthly fee way out of proportion.</p>

<p>Felix Mikolasch, data protection lawyer at <em>noyb</em>: <em>“EU law requires that consent is the genuine free will of the user. Contrary to this law, Meta charges a “privacy fee” of up to €250 per year if anyone dares to exercise their fundamental right to data protection.”</em></p>

<p><strong>3 to 10 percent want personalized ads – but 99.9 percent consent.</strong> All available scientific research suggests that so-called “Pay or Okay” systems are the antithesis of free consent and fundamentally affect the “free will” of users. For example, <a href="https://arxiv.org/pdf/2309.11625.pdf">the CEO of the “Pay or Okay” provider contentpass</a> stated that 99,9 percent of visitors agree to tracking when faced with a € 1,99 fee. At the same time, <a href="https://noyb.eu/sites/default/files/2020-05/Gallup_Facebook_DE.pdf">objective surveys suggest</a> that only 3 to 10 percent of users want their personal data to be used for targeted advertising.</p>

<p>Max Schrems, Chairman of <em>noyb</em>:<em> “When 3 percent of people actually want to swim, but 99.9 percent end up in the water, every child knows that it wasn’t a “free” choice. It’s neither smart nor legal – it’s just pitiful how Meta continues to ignore EU law.”</em></p>

<p><strong>Data protection could soon cost €35,000 per family.</strong> If Meta is successful in defending this new approach, it is likely to set off a domino effect. Already now, <a href="https://techcrunch.com/2023/10/02/tiktok-begins-testing-4-99-ad-free-subscription-tier/">TikTok is reportedly testing</a> an ad-free subscription outside the US. Other app providers could follow in the near future, making online privacy unaffordable. <a href="https://www.thinkwithgoogle.com/marketing-strategies/app-and-mobile/average-number-of-apps-on-smartphones/">According to Google</a>, the average person has 35 apps installed on their smartphone. If all of these apps followed Meta’s lead and charged a similar fee, people would have to pay a “fundamental rights fee” of €8,815.80 a year. For a family of four, the price of data privacy would rise to €35,263.20 per year - more than the average full-time income in the EU. Obviously, these figures become even more extreme in EU Member States with lower average incomes.</p>

<p>Max Schrems:<em> “Fundamental rights are usually available to everyone. How many people would still exercise their right to vote if they had to pay € 250 to do so? There were times when fundamental rights were reserved for the rich. It seems Meta wants to take us back for more than a hundred years.”</em></p>

<p><strong>Privacy only for the rich. </strong>While this price is extremely high in general, it also completely ignores the very different income levels in EU countries – and the fact that <a href="https://ec.europa.eu/eurostat/documents/15234730/17582411/KS-HA-23-001-EN-N.pdf/5d783d9e-9cb3-897c-8360-5122563ae8f3?version=6.0&amp;t=1700579783008">21.6% of the EU population is at risk of poverty or social exclusion</a>. The complainant in this case, for example, is in financial distress and receives unemployment assistance. He simply cannot afford to pay another €250 a year, when he is already struggling to pay his rent.</p>

<p>Max Schrems:<em> “More than 20% of the EU population are already at risk of poverty. For the complainant in our case, as for many others, a ‘Pay or Okay’ system would mean paying the rent or having privacy.”</em></p>

<p><strong>The DPA should initiate an urgency procedure.</strong> Given the seriousness of the violations and the unusually high number of users affected, <em>noyb </em>urges the Austrian data protection authority to initiate an urgency procedure to stop the illegal processing. In addition, <em>noyb </em>suggests that the authority imposes a deterrent fine, making sure that no other company starts copying Meta’s approach.</p>
            
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Designing a SIMD Algorithm from Scratch (295 pts)]]></title>
            <link>https://mcyoung.xyz/2023/11/27/simd-base64/</link>
            <guid>38443253</guid>
            <pubDate>Tue, 28 Nov 2023 07:12:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mcyoung.xyz/2023/11/27/simd-base64/">https://mcyoung.xyz/2023/11/27/simd-base64/</a>, See on <a href="https://news.ycombinator.com/item?id=38443253">Hacker News</a></p>
<div id="readability-page-1" class="page"><div> <p><span> <span> <a href="https://mcyoung.xyz/tags.html#rust">#rust</a> <a href="https://mcyoung.xyz/tags.html#optimization">#optimization</a> </span> <span> 2023-11-27 </span> </span></p> <p>Another explainer on a fun, esoteric topic: optimizing code with SIMD (single instruction multiple data, also sometimes called <em>vectorization</em>). Designing a good, fast, portable SIMD algorithm is not a simple matter and requires thinking a little bit like a circuit designer.</p> <p>Here’s the mandatory performance benchmark graph to catch your eye.</p> <p><img src="https://mcyoung.xyz/public/simd-img/graph.png" alt="perf perf perf"></p> <p>“SIMD” often gets thrown around as a buzzword by performance and HPC (high performance computing) nerds, but I don’t think it’s a topic that has very friendly introductions out there, for a lot of reasons.</p> <ul> <li>It’s not something you will really want to care about unless you think performance is cool.</li> <li>APIs for programming with SIMD in most programming languages are <em>garbage</em> (I’ll get into why).</li> <li>SIMD algorithms are hard to think about if you’re very procedural-programming-brained. A functional programming mindset can help a lot.</li> </ul> <p>This post is mostly about <a href="https://docs.rs/vb64/latest/vb64/"><code>vb64</code></a> (which stands for <em>v</em>ector <em>b</em>ase<em>64</em>), a base64 codec I wrote to see for myself if Rust’s <code>std::simd</code> library is any good, but it’s also an excuse to talk about SIMD in general.</p> <p>What <em>is</em> SIMD, anyways? Let’s dive in.</p> <p>If you want to skip straight to the writeup on <code>vb64</code>, click <a href="#parsing-with-simd">here</a>.</p> <h2 id="problems-with-physics"><a href="#problems-with-physics">Problems with Physics</a></h2> <p>Unfortunately, computers exist in the real world<sup>[citation-needed]</sup>, and are bound by the laws of nature. SIMD has relatively little to do with theoretical CS considerations, and everything to do with <em>physics</em>.</p> <p>In the infancy of modern computing, you could simply improve performance of existing programs by buying new computers. This is often incorrectly attributed to Moore’s law (the number of transistors on IC designs doubles every two years). Moore’s law still appears to hold as of 2023, but some time in the last 15 years the <a href="https://en.wikipedia.org/wiki/Dennard_scaling">Dennard scaling</a> effect broke down. This means that denser transistors eventually means increased power dissipation density. In simpler terms, we don’t know how to continue to increase the clock frequency of computers without literally <em>liquefying</em> them.</p> <p>So, since the early aughts, the hot new thing has been bigger core counts. Make your program more multi-threaded and it will run faster on bigger CPUs. This comes with synchronization overhead, since now the cores need to cooperate. All control flow, be it jumps, virtual calls, or synchronization will result in “stall”.</p> <p>The main causes of stall are <em>branches</em>, instructions that indicate code can take one of two possible paths (like an <code>if</code> statement), and <em>memory operations</em>. Branches include all control flow: <code>if</code> statements, loops, function calls, function returns, even <code>switch</code> statements in C. Memory operations are loads and stores, especially ones that are cache-unfriendly.</p> <h3 id="procedural-code-is-slow"><a href="#procedural-code-is-slow">Procedural Code Is Slow</a></h3> <p>Modern compute cores do not execute code line-by-line, because that would be very inefficient. Suppose I have this program:</p> <div><figure><pre><code data-lang="rust"><span>let</span> <span>a</span> <span>=</span> <span>x</span> <span>+</span> <span>y</span><span>;</span>
<span>let</span> <span>b</span> <span>=</span> <span>x</span> <span>^</span> <span>y</span><span>;</span>
<span>println!</span><span>(</span><span>"{a}, {b}"</span><span>);</span></code></pre></figure></div> <p>There’s no reason for the CPU to wait to finish computing <code>a</code> before it begins computing <code>b</code>; it does not depend on <code>a</code>, and while the add is being executed, the xor circuits are idle. Computers say “program order be damned” and issue the add for <code>a</code> and the xor for <code>b</code> simultaneously. This is called <em>instruction-level parallelism</em>, and dependencies that get in the way of it are often called <em>data hazards</em>.</p> <p>Of course, the Zen 2 in the machine I’m writing this with does not have one measly adder per core. It has dozens and dozens! The opportunities for parallelism are massive, as long as the compiler in your CPU’s execution pipeline can clear any data hazards in the way.</p> <p>The better the core can do this, the more it can saturate all of the “functional units” for things like arithmetic, and the more numbers it can crunch per unit time, approaching maximum utilization of the hardware. Whenever the compiler can’t do this, the execution pipeline stalls and your code is slower.</p> <p>Branches stall because they need to wait for the branch condition to be computed before fetching the next instruction (speculative execution is a somewhat iffy workaround for this). Memory operations stall because the data needs to physically arrive at the CPU, and the speed of light is finite in this universe.</p> <p>Trying to reduce stall by improving opportunities for single-core parallelism is not a new idea. Consider the not-so-humble GPU, whose purpose in life is to render images. Images are vectors of pixels (i.e., color values), and rendering operations tend to be highly local. For example, a convolution kernel for a Gaussian blur will be two or even three orders of magnitude smaller than the final image, lending itself to locality.</p> <p>Thus, GPUs are built for divide-and-conquer: they provide primitives for doing batched operations, and extremely limited control flow.</p> <p>“SIMD” is synonymous with “batching”. It stands for “single instruction, multiple data”: a single instruction dispatches parallel operations on multiple <em>lanes</em> of data. GPUs are the original SIMD machines.</p> <h2 id="lane-wise"><a href="#lane-wise">Lane-wise</a></h2> <p>“SIMD” and “vector” are often used interchangeably. The fundamental unit a SIMD instruction (or “vector instruction”) operates on is a vector: a fixed-size array of numbers that you primarily operate on component-wise These components are called <em>lanes</em>.</p> <p>SIMD vectors are usually quite small, since they need to fit into registers. For example, on my machine, the largest vectors are 256 bits wide. This is enough for 32 bytes (a <code>u8x32</code>), 4 double-precision floats (an <code>f64x8</code>), or all kinds of things in between.</p> <p><img src="https://mcyoung.xyz/public/simd-img/vectors.png" alt="some 256-bit vectors"></p> <p>Although this doesn’t seem like much, remember that offloading the overhead of keeping the pipeline saturated by a factor of 4x can translate to that big of a speedup in latency.</p> <h3 id="one-bit-lanes"><a href="#one-bit-lanes">One-bit Lanes</a></h3> <p>The simplest vector operations are bitwise: and, or, xor. Ordinary integers can be thought of as vectors themselves, with respect to the bitwise operations. That’s literally what “bitwise” means: lanes-wise with lanes that are one bit wide. An <code>i32</code> is, in this regard, an <code>i1x32</code>.</p> <p>In fact, as a warmup, let’s look at the problem of counting the number of 1 bits in an integer. This operation is called “population count”, or <code>popcnt</code>. If we view an <code>i32</code> as an <code>i1x32</code>, <code>popcnt</code> is just a fold or reduce operation:</p> <div><figure><pre><code data-lang="rust"><span>pub</span> <span>fn</span> <span>popcnt</span><span>(</span><span>mut</span> <span>x</span><span>:</span> <span>u32</span><span>)</span> <span>-&gt;</span> <span>u32</span> <span>{</span>
  <span>let</span> <span>mut</span> <span>bits</span> <span>=</span> <span>[</span><span>0</span><span>;</span> <span>32</span><span>];</span>
  <span>for</span> <span>(</span><span>i</span><span>,</span> <span>bit</span><span>)</span> <span>in</span> <span>bits</span><span>.iter_mut</span><span>()</span><span>.enumerate</span><span>()</span> <span>{</span>
    <span>*</span><span>bit</span> <span>=</span> <span>(</span><span>x</span> <span>&gt;&gt;</span> <span>i</span><span>)</span> <span>&amp;</span> <span>1</span><span>;</span>
  <span>}</span>
  <span>bits</span><span>.into_iter</span><span>()</span><span>.fold</span><span>(</span><span>0</span><span>,</span> <span>|</span><span>total</span><span>,</span> <span>bit</span><span>|</span> <span>total</span> <span>+</span> <span>bit</span><span>)</span>
<span>}</span></code></pre></figure></div> <p>In other words, we interpret the integer as an array of bits and then add the bits together to a 32-bit accumulator. Note that the accumulator needs to be higher precision to avoid overflow: accumulating into an <code>i1</code> (as with the <code>Iterator::reduce()</code> method) will only tell us whether the number of 1 bits is even or odd.</p> <p>Of course, this produces… comically bad code, frankly. We can do much better if we notice that we can <em>vectorize</em> the addition: first we add all of the adjacent pairs of bits together, then the pairs of pairs, and so on. This means the number of adds is logarithmic in the number of bits in the integer.</p> <p>Visually, what we do is we “unzip” each vector, shift one to line up the lanes, add them, and then repeat with lanes twice as big.</p> <p><img src="https://mcyoung.xyz/public/simd-img/popcnt.png" alt="first two popcnt merge steps"></p> <p>This is what that looks like in code.</p> <div><figure><pre><code data-lang="rust"><span>pub</span> <span>fn</span> <span>popcnt</span><span>(</span><span>mut</span> <span>x</span><span>:</span> <span>u32</span><span>)</span> <span>-&gt;</span> <span>u32</span> <span>{</span>
  <span>// View x as a i1x32, and split it into two vectors</span>
  <span>// that contain the even and odd bits, respectively.</span>
  <span>let</span> <span>even</span> <span>=</span> <span>x</span> <span>&amp;</span> <span>0x55555555</span><span>;</span> <span>// 0x5 == 0b0101.</span>
  <span>let</span> <span>odds</span> <span>=</span> <span>x</span> <span>&amp;</span> <span>0xaaaaaaaa</span><span>;</span> <span>// 0xa == 0b1010.</span>
  <span>// Shift odds down to align the bits, and then add them together.</span>
  <span>// We interpret x now as a i2x16. When adding, each two-bit</span>
  <span>// lane cannot overflow, because the value in each lane is</span>
  <span>// either 0b00 or 0b01.</span>
  <span>x</span> <span>=</span> <span>even</span> <span>+</span> <span>(</span><span>odds</span> <span>&gt;&gt;</span> <span>1</span><span>);</span>

  <span>// Repeat again but now splitting even and odd bit-pairs.</span>
  <span>let</span> <span>even</span> <span>=</span> <span>x</span> <span>&amp;</span> <span>0x33333333</span><span>;</span> <span>// 0x3 == 0b0011.</span>
  <span>let</span> <span>odds</span> <span>=</span> <span>x</span> <span>&amp;</span> <span>0xcccccccc</span><span>;</span> <span>// 0xc == 0b1100.</span>
  <span>// We need to shift by 2 to align, and now for this addition</span>
  <span>// we interpret x as a i4x8.</span>
  <span>x</span> <span>=</span> <span>even</span> <span>+</span> <span>(</span><span>odds</span> <span>&gt;&gt;</span> <span>2</span><span>);</span>

  <span>// Again. The pattern should now be obvious.</span>
  <span>let</span> <span>even</span> <span>=</span> <span>x</span> <span>&amp;</span> <span>0x0f0f0f0f</span><span>;</span> <span>// 0x0f == 0b00001111.</span>
  <span>let</span> <span>odds</span> <span>=</span> <span>x</span> <span>&amp;</span> <span>0xf0f0f0f0</span><span>;</span> <span>// 0xf0 == 0b11110000.</span>
  <span>x</span> <span>=</span> <span>even</span> <span>+</span> <span>(</span><span>odds</span> <span>&gt;&gt;</span> <span>4</span><span>);</span> <span>// i8x4</span>

  <span>let</span> <span>even</span> <span>=</span> <span>x</span> <span>&amp;</span> <span>0x00ff00ff</span><span>;</span>
  <span>let</span> <span>odds</span> <span>=</span> <span>x</span> <span>&amp;</span> <span>0xff00ff00</span><span>;</span>
  <span>x</span> <span>=</span> <span>even</span> <span>+</span> <span>(</span><span>odds</span> <span>&gt;&gt;</span> <span>8</span><span>);</span>  <span>// i16x2</span>

  <span>let</span> <span>even</span> <span>=</span> <span>x</span> <span>&amp;</span> <span>0x0000ffff</span><span>;</span>
  <span>let</span> <span>odds</span> <span>=</span> <span>x</span> <span>&amp;</span> <span>0xffff0000</span><span>;</span>
  <span>// Because the value of `x` is at most 32, although we interpret this as a</span>
  <span>// i32x1 add, we could get away with just one e.g. i16 add.</span>
  <span>x</span> <span>=</span> <span>even</span> <span>+</span> <span>(</span><span>odds</span> <span>&gt;&gt;</span> <span>16</span><span>);</span>

  <span>x</span> <span>// Done. All bits have been added.</span>
<span>}</span></code></pre></figure></div> <p>This still won’t optimize down to a <code>popcnt</code> instruction, of course. The search scope for such a simplification is in the regime of superoptimizers. However, the generated code is small and fast, which is why this is the ideal implementation of <code>popcnt</code> for systems without such an instruction.</p> <p>It’s <em>especially</em> nice because it is implementable for e.g. <code>u64</code> with only one more reduction step (remember: it’s <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>log</mi><mo>⁡</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(\log n)</annotation></semantics></math></span></span></span>!), and does not at any point require a full <code>u64</code> addition.</p> <p>Even though this is “just” using scalars, divide-and-conquer approaches like this are the bread and butter of the SIMD programmer.</p> <h3 id="scaling-up-operations-on-real-vectors"><a href="#scaling-up-operations-on-real-vectors">Scaling Up: Operations on Real Vectors</a></h3> <p>Proper SIMD vectors provide more sophisticated semantics than scalars do, particularly because there is more need to provide replacements for things like control flow. Remember, control flow is slow!</p> <p>What’s actually available is highly dependent on the architecture you’re compiling to (more on this later), but the way vector instruction sets are usually structured is something like this.</p> <p>We have <em>vector registers</em> that are kind of like really big general-purpose registers. For example, on x86, most “high performance” cores (like my Zen 2) implement AVX2, which provides 256 bit <code>ymm</code> vectors. The registers themselves do not have a “lane count”; that is specified by the instructions. For example, the “vector byte add instruction” interprets the register as being divided into eight-byte lanes and adds them. The corresponding x86 instruction is <code>vpaddb</code>, which interprets a <code>ymm</code> as an <code>i8x32</code>.</p> <p>The operations you usually get are:</p> <ol> <li> <p>Bitwise operations. These don’t need to specify a lane width because it’s always implicitly <code>1</code>: they’re <em>bit</em>wise.</p> </li> <li> <p>Lane-wise arithmetic. This is addition, subtraction, multiplication, division (both int and float), and shifts<sup id="fnref:shifts-are-arithmetic" role="doc-noteref"><a href="#fn:shifts-are-arithmetic" rel="footnote">1</a></sup> (int only). Lane-wise min and max are also common. These require specifying a lane width. Typically the smallest number of lanes is two or four.</p> </li> <li> <p>Lane-wise compare. Given <code>a</code> and <code>b</code>, we can create a new <em>mask vector</em> <code>m</code> such that <code>m[i] = a[i] &lt; b[i]</code> (or any other comparison operation). A mask vector’s lanes contain boolean values with an unusual bit-pattern: all-zeros (for false) or all-ones (for true)<sup id="fnref:minus-true" role="doc-noteref"><a href="#fn:minus-true" rel="footnote">2</a></sup>.</p> <ul> <li>Masks can be used to select between two vectors: for example, given <code>m</code>, <code>x</code>, and <code>y</code>, you can form a fourth vector <code>z</code> such that <code>z[i] = m[i] ? a[i] : b[i]</code>.</li> </ul> </li> <li> <p>Shuffles (sometimes called swizzles). Given <code>a</code> and <code>x</code>, create a third vector <code>s</code> such that <code>s[i] = a[x[i]]</code>. <code>a</code> is used as a lookup table, and <code>x</code> as a set of indices. Out of bounds produces a special value, usually zero. This emulates parallelized array access without needing to actually touch RAM (RAM is extremely slow).</p> <ul> <li>Often there is a “shuffle2” or “riffle” operation that allows taking elements from one of two vectors. Given <code>a</code>, <code>b</code>, and <code>x</code>, we now define <code>s</code> as being <code>s[i] = (a ++ b)[x[i]]</code>, where <code>a ++ b</code> is a double-width concatenation. How this is actually implemented depends on architecture, and it’s easy to build out of single shuffles regardless.</li> </ul> </li> </ol> <p>(1) and (2) are ordinary number crunching. Nothing deeply special about them.</p> <p>The comparison and select operations in (3) are intended to help SIMD code stay “branchless”. Branchless code is written such that it performs the same operations regardless of its inputs, and relies on the properties of those operations to produce correct results. For example, this might mean taking advantage of identities like <code>x * 0 = 0</code> and <code>a ^ b ^ a = b</code> to discard “garbage” results.</p> <p>The shuffles described in (4) are much more powerful than meets the eye.</p> <p>For example, “broadcast” (sometimes called “splat”) makes a vector whose lanes are all the same scalar, like Rust’s <code>[42; N]</code> array literal. A broadcast can be expressed as a shuffle: create a vector with the desired value in the first lane, and then shuffle it with an index vector of <code>[0, 0, ...]</code>.</p> <p><img src="https://mcyoung.xyz/public/simd-img/broadcast.png" alt="diagram of a broadcast"></p> <p>“Interleave” (also called “zip” or “pack”) takes two vectors <code>a</code> and <code>b</code> and creates two new vectors <code>c</code> and <code>d</code> whose lanes are alternating lanes from <code>a</code> and <code>b</code>. If the lane count is <code>n</code>, then <code>c = [a[0], b[0], a[1], b[1], ...]</code> and <code>d = [a[n/2], b[n/2], a[n/2 + 1], b[n/2 + 1], ...]</code>. This can also be implemented as a shuffle2, with shuffle indices of <code>[0, n, 1, n + 1, ...]</code>. “Deinterleave” (or “unzip”, or “unpack”) is the opposite operation: it interprets a pair of vectors as two halves of a larger vector of pairs, and produces two new vectors consisting of the halves of each pair.</p> <p>Interleave can also be interpreted as taking a <code>[T; N]</code>, transmuting it to a <code>[[T; N/2]; 2]</code>, performing a matrix transpose to turn it into a <code>[[T; 2]; N/2]</code>, and then transmuting that back to <code>[T; N]</code> again. Deinterleave is the same but it transmutes to <code>[[T; 2]; N/2]</code> first.</p> <p><img src="https://mcyoung.xyz/public/simd-img/interleave.png" alt="diagram of a interleave"></p> <p>“Rotate” takes a vector <code>a</code> with <code>n</code> lanes and produces a new vector <code>b</code> such that <code>b[i] = a[(i + j) % n]</code>, for some chosen integer <code>j</code>. This is yet another shuffle, with indices <code>[j, j + 1, ..., n - 1, 0, 1, ... j - 1]</code>.</p> <p><img src="https://mcyoung.xyz/public/simd-img/rotate.png" alt="diagram of a rotate"></p> <p>Shuffles are worth trying to wrap your mind around. SIMD programming is all about reinterpreting larger-than-an-integer-sized blocks of data as smaller blocks of varying sizes, and shuffling is important for getting data into the right “place”.</p> <h3 id="intrinsics-and-instruction-selection"><a href="#intrinsics-and-instruction-selection">Intrinsics and Instruction Selection</a></h3> <p>Earlier, I mentioned that what you get varies by architecture. This section is basically a giant footnote.</p> <p>So, there’s two big factors that go into this.</p> <ol> <li>We’ve learned over time which operations tend to be most useful to programmers. x86 might have something that ARM doesn’t because it “seemed like a good idea at the time” but turned out to be kinda niche.</li> <li>Instruction set extensions are often market differentiators, even within the same vendor. Intel has AVX-512, which provides even more sophisticated instructions, but it’s only available on high-end server chips, because it makes manufacturing more expensive.</li> </ol> <p>Toolchains generalize different extensions as “target features”. Features can be detected at runtime through architecture-specific magic. On Linux, the <code>lscpu</code> command will list what features the CPU advertises that it recognizes, which correlate with the names of features that e.g. LLVM understands. What features are enabled for a particular function affects how LLVM compiles it. For example, LLVM will only emit <code>ymm</code>-using code when compiling with <code>+avx2</code>.</p> <p>So how do you write portable SIMD code? On the surface, the answer is mostly “you don’t”, but it’s more complicated than that, and for that we need to understand how the later parts of a compiler works.</p> <p>When a user requests an add by writing <code>a + b</code>, how should I decide which instruction to use for it? This seems like a trick question… <em>just</em> an <code>add</code> right? On x86, even this isn’t so easy, since you have a choice between the actual <code>add</code> instruction, or a <code>lea</code> instruction (which, among other things, preserves the <code>rflags</code> register). This question becomes more complicated for more sophisticated operations. This general problem is called <em>instruction selection</em>.</p> <p>Because which “target features” are enabled affects which instructions are available, they affect instruction selection. When I went over operations “typically available”, this means that compilers will usually be able to select good choices of instructions for them on most architectures.</p> <p>Compiling with something like <code>-march=native</code> or <code>-Ctarget-cpu=native</code> gets you “the best” code possible for the machine you’re building on, but it might not be portable<sup id="fnref:abi" role="doc-noteref"><a href="#fn:abi" rel="footnote">3</a></sup> to different processors. Gentoo was quite famous for building packages from source on user machines to take advantage of this (not to mention that they loved using <code>-O3</code>, which mostly exists to slow down build times with little benefit).</p> <p>There is also runtime feature detection, where a program decides which version of a function to call at runtime by asking the CPU what it supports. Code deployed on heterogenous devices (like cryptography libraries) often make use of this. Doing this correctly is very hard and something I don’t particularly want to dig deeply into here.</p> <p>The situation is made worse by the fact that in C++, you usually write SIMD code using “intrinsics”, which are special functions with inscrutable names like <code>_mm256_cvtps_epu32</code> that represent a low-level operation in a specific instruction set (this is a float to int cast from AVX2). Intrinsics are defined by hardware vendors, but don’t necessarily map down to single instructions; the compiler can still optimize these instructions by merging, deduplication, and through instruction selection.</p> <p>As a result you wind up writing the same code multiple times for different instruction sets, with only minor maintainability benefits over writing assembly.</p> <p>The alternative is a portable SIMD library, which does some instruction selection behind the scenes at the library level but tries to rely on the compiler for most of the heavy-duty work. For a long time I was skeptical that this approach would actually produce good, competitive code, which brings us to the actual point of this article: using Rust’s portable SIMD library to implement a somewhat fussy algorithm, and measuring performance.</p> <h2 id="parsing-with-simd"><a href="#parsing-with-simd">Parsing with SIMD</a></h2> <p>Let’s design a SIMD implementation for a well-known algorithm. Although it doesn’t look like it at first, the power of shuffles makes it possible to parse text with SIMD. And this parsing can be very, very fast.</p> <p>In this case, we’re going to implement base64 decoding. To review, base64 is an encoding scheme for arbitrary binary data into ASCII. We interpret a byte slice as a bit vector, and divide it into six-bit chunks called <em>sextets</em>. Then, each sextet from 0 to 63 is mapped to an ASCII character:</p> <ol> <li><code>0</code> to <code>25</code> go to <code>'A'</code> to <code>'Z'</code>.</li> <li><code>26</code> to <code>51</code> go to <code>'a'</code> to <code>'z'</code>.</li> <li><code>52</code> to <code>61</code> go to <code>'0'</code> to <code>'9'</code>.</li> <li><code>62</code> goes to <code>+</code>.</li> <li><code>63</code> goes to <code>/</code>.</li> </ol> <p>There <em>are</em> other variants of base64, but the bulk of the complexity is the same for each variant.</p> <p>There are a few basic pitfalls to keep in mind.</p> <ol> <li> <p>Base64 is a “big endian” format: specifically, the bits in each byte are big endian. Because a sextet can span only parts of a byte, this distinction is important.</p> </li> <li> <p>We need to beware of cases where the input length is not divisible by 4; ostensibly messages should be padded with <code>=</code> to a multiple of 4, but it’s easy to just handle messages that aren’t padded correctly.</p> </li> </ol> <p>The length of a decoded message is given by this function:</p> <div><figure><pre><code data-lang="rust"><span>fn</span> <span>decoded_len</span><span>(</span><span>input</span><span>:</span> <span>usize</span><span>)</span> <span>-&gt;</span> <span>usize</span> <span>{</span>
  <span>input</span> <span>/</span> <span>4</span> <span>*</span> <span>3</span> <span>+</span> <span>match</span> <span>input</span> <span>%</span> <span>4</span> <span>{</span>
    <span>1</span> <span>|</span> <span>2</span> <span>=&gt;</span> <span>1</span><span>,</span>
    <span>3</span> <span>=&gt;</span> <span>2</span><span>,</span>
    <span>_</span> <span>=&gt;</span> <span>0</span><span>,</span>
  <span>}</span>
<span>}</span></code></pre></figure></div> <p>Given all this, the easiest way to implement base64 is something like this.</p> <div><figure><pre><code data-lang="rust"><span>fn</span> <span>decode</span><span>(</span><span>data</span><span>:</span> <span>&amp;</span><span>[</span><span>u8</span><span>],</span> <span>out</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Vec</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>(),</span> <span>Error</span><span>&gt;</span> <span>{</span>
  <span>// Tear off at most two trailing =.</span>
  <span>let</span> <span>data</span> <span>=</span> <span>match</span> <span>data</span> <span>{</span>
    <span>[</span><span>p</span> <span>@</span> <span>..</span><span>,</span> <span>b'='</span><span>,</span> <span>b'='</span><span>]</span> <span>|</span> <span>[</span><span>p</span> <span>@</span> <span>..</span><span>,</span> <span>b'='</span><span>]</span> <span>|</span> <span>p</span> <span>=&gt;</span> <span>p</span><span>,</span>
  <span>};</span>

  <span>// Split the input into chunks of at most 4 bytes.</span>
  <span>for</span> <span>chunk</span> <span>in</span> <span>data</span><span>.chunks</span><span>(</span><span>4</span><span>)</span> <span>{</span>
    <span>let</span> <span>mut</span> <span>bytes</span> <span>=</span> <span>0u32</span><span>;</span>
    <span>for</span> <span>&amp;</span><span>byte</span> <span>in</span> <span>chunk</span> <span>{</span>
      <span>// Translate each ASCII character into its corresponding</span>
      <span>// sextet, or return an error.</span>
      <span>let</span> <span>sextet</span> <span>=</span> <span>match</span> <span>byte</span> <span>{</span>
        <span>b'A'</span><span>..=</span><span>b'Z'</span> <span>=&gt;</span> <span>byte</span> <span>-</span> <span>b'A'</span><span>,</span>
        <span>b'a'</span><span>..=</span><span>b'z'</span> <span>=&gt;</span> <span>byte</span> <span>-</span> <span>b'a'</span> <span>+</span> <span>26</span><span>,</span>
        <span>b'0'</span><span>..=</span><span>b'9'</span> <span>=&gt;</span> <span>byte</span> <span>-</span> <span>b'0'</span> <span>+</span> <span>52</span><span>,</span>
        <span>b'+'</span> <span>=&gt;</span> <span>62</span><span>,</span>
        <span>b'/'</span> <span>=&gt;</span> <span>63</span><span>,</span>
        <span>_</span> <span>=&gt;</span> <span>return</span> <span>Err</span><span>(</span><span>Error</span><span>(</span><span>...</span><span>)),</span>
      <span>};</span>

      <span>// Append the sextet to the temporary buffer.</span>
      <span>bytes</span> <span>&lt;&lt;=</span> <span>6</span><span>;</span>
      <span>bytes</span> <span>|</span><span>=</span> <span>sextet</span> <span>as</span> <span>u32</span><span>;</span>
    <span>}</span>

    <span>// Shift things so the actual data winds up at the</span>
    <span>// top of `bytes`.</span>
    <span>bytes</span> <span>&lt;&lt;=</span> <span>32</span> <span>-</span> <span>6</span> <span>*</span> <span>chunk</span><span>.len</span><span>();</span>

    <span>// Append the decoded data to `out`, keeping in mind that</span>
    <span>// `bytes` is big-endian encoded.</span>
    <span>let</span> <span>decoded</span> <span>=</span> <span>decoded_len</span><span>(</span><span>chunk</span><span>.len</span><span>());</span>
    <span>out</span><span>.extend_from_slice</span><span>(</span><span>&amp;</span><span>bytes</span><span>.to_be_bytes</span><span>()[</span><span>..</span><span>decoded</span><span>]);</span>
  <span>}</span>

  <span>Ok</span><span>(())</span>
<span>}</span></code></pre></figure></div> <p>So, what’s the process of turning this into a SIMD version? We want to follow one directive with inexorable, robotic dedication.</p> <p><strong>Eliminate all branches.</strong></p> <p>This is not completely feasible, since the input is of variable length. But we can try. There are several branches in this code:</p> <ol> <li>The <code>for chunk in</code> line. This one is is the length check: it checks if there is any data left to process.</li> <li>The <code>for &amp;byte in</code> line. This is the hottest loop: it branches once per input byte.</li> <li>The <code>match byte</code> line is several branches, to determine which of the five “valid” match arms we land in.</li> <li>The <code>return Err</code> line. Returning in a hot loop is extra control flow, which is not ideal.</li> <li>The call to <code>decoded_len</code> contains a <code>match</code>, which generates branches.</li> <li>The call to <code>Vec::extend_from_slice</code>. This contains not just branches, but potential calls into the allocator. Extremely slow.</li> </ol> <p>(5) is the easiest to deal with. The <code>match</code> is mapping the values <code>0, 1, 2, 3</code> to <code>0, 1, 1, 2</code>. Call this function <code>f</code>. Then, the sequence given by <code>x - f(x)</code> is <code>0, 0, 1, 1</code>. This just happens to equal <code>x / 2</code> (or <code>x &gt;&gt; 1</code>), so we can write a completely branchless version of <code>decoded_len</code> like so.</p> <div><figure><pre><code data-lang="rust"><span>pub</span> <span>fn</span> <span>decoded_len</span><span>(</span><span>input</span><span>:</span> <span>usize</span><span>)</span> <span>-&gt;</span> <span>usize</span> <span>{</span>
  <span>let</span> <span>mod4</span> <span>=</span> <span>input</span> <span>%</span> <span>4</span><span>;</span>
  <span>input</span> <span>/</span> <span>4</span> <span>*</span> <span>3</span> <span>+</span> <span>(</span><span>mod4</span> <span>-</span> <span>mod4</span> <span>/</span> <span>2</span><span>)</span>
<span>}</span></code></pre></figure></div> <p>That’s one branch eliminated<sup id="fnref:why-cant-llvm-do-it" role="doc-noteref"><a href="#fn:why-cant-llvm-do-it" rel="footnote">4</a></sup>. ✅</p> <p>The others will not prove so easy. Let’s turn our attention to the innermost loop next, branches (2), (3), and (4).</p> <h3 id="the-hottest-loop"><a href="#the-hottest-loop">The Hottest Loop</a></h3> <p>The superpower of SIMD is that because you operate on so much data at a time, you can unroll the loop so hard it becomes branchless.</p> <p>The insight is this: we want to load at most four bytes, do something to them, and then spit out at most three decoded bytes. While doing this operation, we may encounter a syntax error so we need to report that somehow.</p> <p>Here’s some facts we can take advantage of.</p> <ol> <li>We don’t need to figure out how many bytes are in the “output” of the hot loop: our handy branchless <code>decoded_len()</code> does that for us.</li> <li>Invalid base64 is extremely rare. We want that syntax error to cost as little as possible. If the user still cares about which byte was the problem, they can scan the input for it after the fact.</li> <li><code>A</code> is zero in base64. If we’re parsing a truncated chunk, padding it with <code>A</code> won’t change the value<sup id="fnref:pad-with-A" role="doc-noteref"><a href="#fn:pad-with-A" rel="footnote">5</a></sup>.</li> </ol> <p>This suggests an interface for the body of the “hottest loop”. We can factor it out as a separate function, and simplify since we can assume our input is always four bytes now.</p> <div><figure><pre><code data-lang="rust"><span>fn</span> <span>decode_hot</span><span>(</span><span>ascii</span><span>:</span> <span>[</span><span>u8</span><span>;</span> <span>4</span><span>])</span> <span>-&gt;</span> <span>([</span><span>u8</span><span>;</span> <span>3</span><span>],</span> <span>bool</span><span>)</span> <span>{</span>
  <span>let</span> <span>mut</span> <span>bytes</span> <span>=</span> <span>0u32</span><span>;</span>
  <span>let</span> <span>mut</span> <span>ok</span> <span>=</span> <span>true</span><span>;</span>
  <span>for</span> <span>byte</span> <span>in</span> <span>ascii</span> <span>{</span>
    <span>let</span> <span>sextet</span> <span>=</span> <span>match</span> <span>byte</span> <span>{</span>
      <span>b'A'</span><span>..=</span><span>b'Z'</span> <span>=&gt;</span> <span>byte</span> <span>-</span> <span>b'A'</span><span>,</span>
      <span>b'a'</span><span>..=</span><span>b'z'</span> <span>=&gt;</span> <span>byte</span> <span>-</span> <span>b'a'</span> <span>+</span> <span>26</span><span>,</span>
      <span>b'0'</span><span>..=</span><span>b'9'</span> <span>=&gt;</span> <span>byte</span> <span>-</span> <span>b'0'</span> <span>+</span> <span>52</span><span>,</span>
      <span>b'+'</span> <span>=&gt;</span> <span>62</span><span>,</span>
      <span>b'/'</span> <span>=&gt;</span> <span>63</span><span>,</span>
      <span>_</span> <span>=&gt;</span> <span>!</span><span>0</span><span>,</span>
    <span>};</span>

    <span>bytes</span> <span>&lt;&lt;=</span> <span>6</span><span>;</span>
    <span>bytes</span> <span>|</span><span>=</span> <span>sextet</span> <span>as</span> <span>u32</span><span>;</span>
    <span>ok</span> <span>|</span><span>=</span> <span>byte</span> <span>==</span> <span>!</span><span>0</span><span>;</span>
  <span>}</span>

  <span>// This is the `to_be_bytes()` call.</span>
  <span>let</span> <span>[</span><span>b1</span><span>,</span> <span>b2</span><span>,</span> <span>b3</span><span>,</span> <span>_</span><span>]</span> <span>=</span> <span>bytes</span><span>.to_le_bytes</span><span>();</span>
  <span>([</span><span>b3</span><span>,</span> <span>b2</span><span>,</span> <span>b1</span><span>],</span> <span>ok</span><span>)</span>
<span>}</span>

<span>// In decode()...</span>
<span>for</span> <span>chunk</span> <span>in</span> <span>data</span><span>.chunks</span><span>(</span><span>4</span><span>)</span> <span>{</span>
  <span>let</span> <span>mut</span> <span>ascii</span> <span>=</span> <span>[</span><span>b'A'</span><span>;</span> <span>4</span><span>];</span>
  <span>ascii</span><span>[</span><span>..</span><span>chunk</span><span>.len</span><span>()]</span><span>.copy_from_slice</span><span>(</span><span>chunk</span><span>);</span>

  <span>let</span> <span>(</span><span>bytes</span><span>,</span> <span>ok</span><span>)</span> <span>=</span> <span>decode_hot</span><span>(</span><span>ascii</span><span>);</span>
  <span>if</span> <span>!</span><span>ok</span> <span>{</span>
    <span>return</span> <span>Err</span><span>(</span><span>Error</span><span>)</span>
  <span>}</span>

  <span>let</span> <span>len</span> <span>=</span> <span>decoded_len</span><span>(</span><span>chunk</span><span>.len</span><span>());</span>
  <span>out</span><span>.extend_from_slice</span><span>(</span><span>&amp;</span><span>bytes</span><span>[</span><span>..</span><span>decoded</span><span>]);</span>
<span>}</span></code></pre></figure></div> <p>You’re probably thinking: why not return <code>Option&lt;[u8; 3]&gt;</code>? Returning an enum will make it messier to eliminate the <code>if !ok</code> branch later on (which we will!). We want to write branchless code, so let’s focus on finding a way of producing that three-byte output without needing to do early returns.</p> <p>Now’s when we want to start talking about vectors rather than arrays, so let’s try to rewrite our function as such.</p> <div><figure><pre><code data-lang="rust"><span>fn</span> <span>decode_hot</span><span>(</span><span>ascii</span><span>:</span> <span>Simd</span><span>&lt;</span><span>u8</span><span>,</span> <span>4</span><span>&gt;</span><span>)</span> <span>-&gt;</span> <span>(</span><span>Simd</span><span>&lt;</span><span>u8</span><span>,</span> <span>4</span><span>&gt;</span><span>,</span> <span>bool</span><span>)</span> <span>{</span>
  <span>unimplemented!</span><span>()</span>
<span>}</span></code></pre></figure></div> <p>Note that the output is now four bytes, not three. SIMD lane counts need to be powers of two, and that last element will never get looked at, so we don’t need to worry about what winds up there.</p> <p>The callsite also needs to be tweaked, but only slightly, because <code>Simd&lt;u8, 4&gt;</code> is <code>From&lt;[u8; 4]&gt;</code>.</p> <h3 id="ascii-to-sextet"><a href="#ascii-to-sextet">ASCII to Sextet</a></h3> <p>Let’s look at the first part of the <code>for byte in ascii</code> loop. We need to map each lane of the <code>Simd&lt;u8, 4&gt;</code> to the corresponding sextet, and somehow signal which ones are invalid. First, notice something special about the <code>match</code>: almost every arm can be written as <code>byte - C</code> for some constant <code>C</code>. The non-range case looks a little silly, but humor me:</p> <div><figure><pre><code data-lang="rust"><span>let</span> <span>sextet</span> <span>=</span> <span>match</span> <span>byte</span> <span>{</span>
  <span>b'A'</span><span>..=</span><span>b'Z'</span> <span>=&gt;</span> <span>byte</span> <span>-</span> <span>b'A'</span><span>,</span>
  <span>b'a'</span><span>..=</span><span>b'z'</span> <span>=&gt;</span> <span>byte</span> <span>-</span> <span>b'a'</span> <span>+</span> <span>26</span><span>,</span>
  <span>b'0'</span><span>..=</span><span>b'9'</span> <span>=&gt;</span> <span>byte</span> <span>-</span> <span>b'0'</span> <span>+</span> <span>52</span><span>,</span>
  <span>b'+'</span>        <span>=&gt;</span> <span>byte</span> <span>-</span> <span>b'+'</span> <span>+</span> <span>62</span><span>,</span>
  <span>b'/'</span>        <span>=&gt;</span> <span>byte</span> <span>-</span> <span>b'/'</span> <span>+</span> <span>63</span><span>,</span>
  <span>_</span> <span>=&gt;</span> <span>!</span><span>0</span><span>,</span>
<span>};</span></code></pre></figure></div> <p>So, it should be sufficient to build a vector <code>offsets</code> that contains the appropriate constant <code>C</code> for each lane, and then <code>let sextets = ascii - offsets;</code></p> <p>How can we build <code>offsets</code>? Using compare-and-select.</p> <div><figure><pre><code data-lang="rust"><span>// A lane-wise version of `x &gt;= start &amp;&amp; x &lt;= end`.</span>
<span>fn</span> <span>in_range</span><span>(</span><span>bytes</span><span>:</span> <span>Simd</span><span>&lt;</span><span>u8</span><span>,</span> <span>4</span><span>&gt;</span><span>,</span> <span>start</span><span>:</span> <span>u8</span><span>,</span> <span>end</span><span>:</span> <span>u8</span><span>)</span> <span>-&gt;</span> <span>Mask</span><span>&lt;</span><span>i8</span><span>,</span> <span>4</span><span>&gt;</span> <span>{</span>
  <span>bytes</span><span>.simd_ge</span><span>(</span><span>Simd</span><span>::</span><span>splat</span><span>(</span><span>start</span><span>))</span> <span>&amp;</span> <span>bytes</span><span>.simd_le</span><span>(</span><span>Simd</span><span>::</span><span>splat</span><span>(</span><span>end</span><span>))</span>
<span>}</span>

<span>// Create masks for each of the five ranges.</span>
<span>// Note that these are disjoint: for any two masks, m1 &amp; m2 == 0.</span>
<span>let</span> <span>uppers</span> <span>=</span> <span>in_range</span><span>(</span><span>ascii</span><span>,</span> <span>b'A'</span><span>,</span> <span>b'Z'</span><span>);</span>
<span>let</span> <span>lowers</span> <span>=</span> <span>in_range</span><span>(</span><span>ascii</span><span>,</span> <span>b'a'</span><span>,</span> <span>b'z'</span><span>);</span>
<span>let</span> <span>digits</span> <span>=</span> <span>in_range</span><span>(</span><span>ascii</span><span>,</span> <span>b'0'</span><span>,</span> <span>b'9'</span><span>);</span>
<span>let</span> <span>pluses</span> <span>=</span> <span>ascii</span><span>.simd_eq</span><span>([</span><span>b'+'</span><span>;</span> <span>N</span><span>]</span><span>.into</span><span>());</span>
<span>let</span> <span>solidi</span> <span>=</span> <span>ascii</span><span>.simd_eq</span><span>([</span><span>b'/'</span><span>;</span> <span>N</span><span>]</span><span>.into</span><span>());</span>

<span>// If any byte was invalid, none of the masks will select for it,</span>
<span>// so that lane will be 0 in the or of all the masks. This is our</span>
<span>// validation check.</span>
<span>let</span> <span>ok</span> <span>=</span> <span>(</span><span>uppers</span> <span>|</span> <span>lowers</span> <span>|</span> <span>digits</span> <span>|</span> <span>pluses</span> <span>|</span> <span>solidi</span><span>)</span><span>.all</span><span>();</span>

<span>// Given a mask, create a new vector by splatting `value`</span>
<span>// over the set lanes.</span>
<span>fn</span> <span>masked_splat</span><span>(</span><span>mask</span><span>:</span> <span>Mask</span><span>&lt;</span><span>i8</span><span>,</span> <span>N</span><span>&gt;</span><span>,</span> <span>value</span><span>:</span> <span>i8</span><span>)</span> <span>-&gt;</span> <span>Simd</span><span>&lt;</span><span>i8</span><span>,</span> <span>4</span><span>&gt;</span> <span>{</span>
  <span>mask</span><span>.select</span><span>(</span><span>Simd</span><span>::</span><span>splat</span><span>(</span><span>val</span><span>),</span> <span>Simd</span><span>::</span><span>splat</span><span>(</span><span>0</span><span>))</span>
<span>}</span>

<span>// Fill the the lanes of the offset vector by filling the</span>
<span>// set lanes with the corresponding offset. This is like</span>
<span>// a "vectorized" version of the `match`.</span>
<span>let</span> <span>offsets</span> <span>=</span> <span>masked_splat</span><span>(</span><span>uppers</span><span>,</span>  <span>65</span><span>)</span>
            <span>|</span> <span>masked_splat</span><span>(</span><span>lowers</span><span>,</span>  <span>71</span><span>)</span>
            <span>|</span> <span>masked_splat</span><span>(</span><span>digits</span><span>,</span>  <span>-</span><span>4</span><span>)</span>
            <span>|</span> <span>masked_splat</span><span>(</span><span>pluses</span><span>,</span> <span>-</span><span>19</span><span>)</span>
            <span>|</span> <span>masked_splat</span><span>(</span><span>solidi</span><span>,</span> <span>-</span><span>16</span><span>);</span>

<span>// Finally, Build the sextets vector.</span>
<span>let</span> <span>sextets</span> <span>=</span> <span>ascii</span><span>.cast</span><span>::</span><span>&lt;</span><span>i8</span><span>&gt;</span><span>()</span> <span>-</span> <span>offsets</span><span>;</span></code></pre></figure></div> <p>This solution is quite elegant, and will produce very competitive code, but it’s not actually ideal. We need to do a lot of comparisons here: eight in total. We also keep lots of values alive at the same time, which might lead to unwanted register pressure.</p> <h3 id="simd-hash-table"><a href="#simd-hash-table">SIMD Hash Table</a></h3> <p>Let’s look at the byte representations of the ranges. <code>A-Z</code>, <code>a-z</code>, and <code>0-9</code> are, as byte ranges, <code>0x41..0x5b</code>, <code>0x61..0x7b</code>, and <code>0x30..0x3a</code>. Notice they all have different high nybbles! What’s more, <code>+</code> and <code>/</code> are <code>0x2b</code> and <code>0x2f</code>, so the function <code>byte &gt;&gt; 4</code> is <em>almost</em> enough to distinguish all the ranges. If we subtract one if <code>byte == b'/'</code>, we have a <em>perfect hash</em> for the ranges.</p> <p>In other words, the value <code>(byte &gt;&gt; 4) - (byte == '/')</code> maps the ranges as follows:</p> <ul> <li><code>A-Z</code> goes to 4 or 5.</li> <li><code>a-z</code> goes to 6 or 7.</li> <li><code>0-9</code> goes to 3.</li> <li><code>+</code> goes to 2.</li> <li><code>/</code> goes to 1.</li> </ul> <p>This is small enough that we could cram a lookup table of values for building the <code>offsets</code> vector into another SIMD vector, and use a shuffle operation to do the lookup.</p> <p>This is not my original idea; I came across a <a href="https://github.com/WojciechMula/base64simd/issues/3">GitHub issue</a> where an anonymous user points out this perfect hash.</p> <p>Our new ascii-to-sextet code looks like this:</p> <div><figure><pre><code data-lang="rust"><span>// Compute the perfect hash for each lane.</span>
<span>let</span> <span>hashes</span> <span>=</span> <span>(</span><span>ascii</span> <span>&gt;&gt;</span> <span>Simd</span><span>::</span><span>splat</span><span>(</span><span>4</span><span>))</span>
  <span>+</span> <span>Simd</span><span>::</span><span>simd_eq</span><span>(</span><span>ascii</span><span>,</span> <span>Simd</span><span>::</span><span>splat</span><span>(</span><span>b'/'</span><span>))</span>
    <span>.to_int</span><span>()</span>  <span>// to_int() is equivalent to masked_splat(-1, 0).</span>
    <span>.cast</span><span>::</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>();</span>

<span>// Look up offsets based on each hash and subtract them from `ascii`.</span>
<span>let</span> <span>sextets</span> <span>=</span> <span>ascii</span>
    <span>// This lookup table corresponds to the offsets we used to build the</span>
    <span>// `offsets` vector in the previous implementation, placed in the</span>
    <span>// indices that the perfect hash produces.</span>
  <span>-</span> <span>Simd</span><span>::</span><span>&lt;</span><span>i8</span><span>,</span> <span>8</span><span>&gt;</span><span>::</span><span>from</span><span>([</span><span>0</span><span>,</span> <span>16</span><span>,</span> <span>19</span><span>,</span> <span>4</span><span>,</span> <span>-</span><span>65</span><span>,</span> <span>-</span><span>65</span><span>,</span> <span>-</span><span>71</span><span>,</span> <span>-</span><span>71</span><span>])</span>
    <span>.cast</span><span>::</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>()</span>
    <span>.swizzle_dyn</span><span>(</span><span>hashes</span><span>);</span></code></pre></figure></div> <p>There is a small wrinkle here: <a href="https://doc.rust-lang.org/std/simd/struct.Simd.html#method.swizzle_dyn"><code>Simd::swizzle_dyn()</code></a> requires that the index array be the same length as the lookup table. This is annoying because right now <code>ascii</code> is a <code>Simd&lt;u8, 4&gt;</code>, but that will not be the case later on, so I will simply sweep this under the rug.</p> <p>Note that we no longer get validation as a side-effect of computing the sextets vector. The same GitHub issue also provides an exact bloom-filter for checking that a particular byte is valid; you can see my implementation <a href="https://github.com/mcy/vb64/blob/894f833e933860e070dabcfcc189430c45fecbd7/src/simd.rs#L93">here</a>. I’m not sure how the OP constructed the bloom filter, but the search space is small enough that you could have written a little script to brute force it.</p> <h3 id="riffling-the-sextets"><a href="#riffling-the-sextets">Riffling the Sextets</a></h3> <p>Now comes a much tricker operation: we need to somehow pack all four sextets into three bytes. One way to try to wrap our head around what the packing code in <code>decode_hot()</code> is doing is to pass in the all-ones sextet in one of the four bytes, and see where those ones end up in the return value.</p> <p>This is not unlike how they use radioactive dyes in biology to track the moment of molecules or cells through an organism.</p> <div><figure><pre><code data-lang="rust"><span>fn</span> <span>bits</span><span>(</span><span>value</span><span>:</span> <span>u32</span><span>)</span> <span>-&gt;</span> <span>String</span> <span>{</span>
  <span>let</span> <span>[</span><span>b1</span><span>,</span> <span>b2</span><span>,</span> <span>b3</span><span>,</span> <span>b4</span><span>]</span> <span>=</span> <span>value</span><span>.reverse_bits</span><span>()</span><span>.to_le_bytes</span><span>();</span>
  <span>format!</span><span>(</span><span>"{b1:08b} {b2:08b} {b3:08b} {b4:08b}"</span><span>)</span>
<span>}</span>

<span>fn</span> <span>decode_pack</span><span>(</span><span>input</span><span>:</span> <span>[</span><span>u8</span><span>;</span> <span>4</span><span>])</span> <span>{</span>
  <span>let</span> <span>mut</span> <span>output</span> <span>=</span> <span>0u32</span><span>;</span>
  <span>for</span> <span>byte</span> <span>in</span> <span>input</span> <span>{</span>
    <span>output</span> <span>&lt;&lt;=</span> <span>6</span><span>;</span>
    <span>output</span> <span>|</span><span>=</span> <span>byte</span> <span>as</span> <span>u32</span><span>;</span>
  <span>}</span>
  <span>output</span> <span>&lt;&lt;=</span> <span>8</span><span>;</span>

  <span>println!</span><span>(</span><span>"{}</span><span>\n</span><span>{}</span><span>\n</span><span>"</span><span>,</span> <span>bits</span><span>(</span><span>u32</span><span>::</span><span>from_be_bytes</span><span>(</span><span>input</span><span>)),</span> <span>bits</span><span>(</span><span>output</span><span>));</span>
<span>}</span>

<span>decode_pack</span><span>([</span><span>0b111111</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>]);</span>
<span>decode_pack</span><span>([</span><span>0</span><span>,</span> <span>0b111111</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>]);</span>
<span>decode_pack</span><span>([</span><span>0</span><span>,</span> <span>0</span><span>,</span> <span>0b111111</span><span>,</span> <span>0</span><span>]);</span>
<span>decode_pack</span><span>([</span><span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0b111111</span><span>]);</span>

<span>// Output:</span>
<span>// 11111100 00000000 00000000 00000000</span>
<span>// 00111111 00000000 00000000 00000000</span>
<span>//</span>
<span>// 00000000 11111100 00000000 00000000</span>
<span>// 11000000 00001111 00000000 00000000</span>
<span>//</span>
<span>// 00000000 00000000 11111100 00000000</span>
<span>// 00000000 11110000 00000011 00000000</span>
<span>//</span>
<span>// 00000000 00000000 00000000 11111100</span>
<span>// 00000000 00000000 11111100 00000000</span></code></pre></figure></div> <p>Bingo. Playing around with the inputs lets us verify which pieces of the bytes wind up where. For example, by passing <code>0b110000</code> as <code>input[1]</code>, we see that the two high bits of <code>input[1]</code> correspond to the low bits of <code>output[0]</code>. I’ve written the code so that the bits in each byte are printed in little-endian order, so bits on the left are the low bits.</p> <p>Putting this all together, we can draw a schematic of what this operation does to a general <code>Simd&lt;u8, 4&gt;</code>.</p> <p><img src="https://mcyoung.xyz/public/simd-img/riffle.png" alt="the riffling operation"></p> <p>Now, there’s no single instruction that will do this for us. Shuffles can be used to move bytes around, but we’re dealing with <em>pieces</em> of bytes here. We also can’t really do a shift, since we need bits that are overshifted to move into adjacent lanes.</p> <p>The trick is to just make the lanes bigger.</p> <p>Among the operations available for SIMD vectors are lane-wise casts, which allow us to zero-extend, sign-extend, or truncate each lane. So what we can do is cast <code>sextets</code> to a vector of <code>u16</code>, do the shift there and then… somehow put the parts back together?</p> <p>Let’s see how far shifting gets us. How much do we need to shift things by? First, notice that the order of the bits within each chunk that doesn’t cross a byte boundary doesn’t change. For example, the four low bits of <code>input[1]</code> are in the same order when they become the high bits of <code>output[1]</code>, and the two high bits of <code>input[1]</code> are also in the same order when they become the low bits of <code>output[0]</code>.</p> <p>This means we can determine how far to shift by comparing the bit position of the lowest bit of a byte of <code>input</code> with the bit position of the corresponding bit in <code>output</code>.</p> <p><code>input[0]</code>’s low bit is the third bit of <code>output[0]</code>, so we need to shift <code>input[0]</code> by 2. <code>input[1]</code>’s lowest bit is the fifth bit of <code>output[1]</code>, so we need to shift by 4. Analogously, the shifts for <code>input[2]</code> and <code>input[3]</code> turn out to be 6 and 0. In code:</p> <div><figure><pre><code data-lang="rust"><span>let</span> <span>sextets</span> <span>=</span> <span>...</span><span>;</span>
<span>let</span> <span>shifted</span> <span>=</span> <span>sextets</span><span>.cast</span><span>::</span><span>&lt;</span><span>u16</span><span>&gt;</span><span>()</span> <span>&lt;&lt;</span> <span>Simd</span><span>::</span><span>from</span><span>([</span><span>2</span><span>,</span> <span>4</span><span>,</span> <span>6</span><span>,</span> <span>0</span><span>]);</span></code></pre></figure></div> <p>So now we have a <code>Simd&lt;u16, 4&gt;</code> that contains the individual chunks that we need to move around, in the high and low bytes of each <code>u16</code>, which we can think of as being analogous to a <code>[[u8; 2]; 4]</code>. For example, <code>shifted[0][0]</code> contains <code>sextet[0]</code>, but shifted. This corresponds to the red segment in the first schematic. The smaller blue segment is given by <code>shifted[1][1]</code>, i.e., the high byte of the second <code>u16</code>. It’s already in the right place within that byte, so we want <code>output[0] = shifted[0][0] | shifted[1][1]</code>.</p> <p>This suggests a more general strategy: we want to take two vectors, the low bytes and the high bytes of each <code>u16</code> in <code>shifted</code>, respectively, and somehow shuffle them so that when or’ed together, they give the desired output.</p> <p>Look at the schematic again: if we had a vector consisting of <code>[..aaaaaa, ....bbbb, ......cc]</code>, we could or it with a vector like <code>[bb......, cccc...., dddddd..]</code> to get the desired result.</p> <p>One problem: <code>dddddd..</code> is <code>shifted[3][0]</code>, i.e., it’s a low byte. If we change the vector we shift by to <code>[2, 4, 6, 8]</code>, though, it winds up in <code>shifted[3][1]</code>, since it’s been shifted up by <code>8</code> bits: a full byte.</p> <div><figure><pre><code data-lang="rust"><span>// Split shifted into low byte and high byte vectors.</span>
<span>// Same way you'd split a single u16 into bytes, but lane-wise.</span>
<span>let</span> <span>lo</span> <span>=</span> <span>shifted</span><span>.cast</span><span>::</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>();</span>
<span>let</span> <span>hi</span> <span>=</span> <span>(</span><span>shifted</span> <span>&gt;&gt;</span> <span>Simd</span><span>::</span><span>from</span><span>([</span><span>8</span><span>;</span> <span>4</span><span>]))</span><span>.cast</span><span>::</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>();</span>

<span>// Align the lanes: we want to get shifted[0][0] | shifted[1][1],</span>
<span>// shifted[1][0] | shifted[2][1], etc.</span>
<span>let</span> <span>output</span> <span>=</span> <span>lo</span> <span>|</span> <span>hi</span><span>.rotate_lanes_left</span><span>::</span><span>&lt;</span><span>1</span><span>&gt;</span><span>();</span></code></pre></figure></div> <p>Et voila, here is our new, totally branchless implementation of <code>decode_hot()</code>.</p> <div><figure><pre><code data-lang="rust"><span>fn</span> <span>decode_hot</span><span>(</span><span>ascii</span><span>:</span> <span>Simd</span><span>&lt;</span><span>u8</span><span>,</span> <span>4</span><span>&gt;</span><span>)</span> <span>-&gt;</span> <span>(</span><span>Simd</span><span>&lt;</span><span>u8</span><span>,</span> <span>4</span><span>&gt;</span><span>,</span> <span>bool</span><span>)</span> <span>{</span>
  <span>let</span> <span>hashes</span> <span>=</span> <span>(</span><span>ascii</span> <span>&gt;&gt;</span> <span>Simd</span><span>::</span><span>splat</span><span>(</span><span>4</span><span>))</span>
    <span>+</span> <span>Simd</span><span>::</span><span>simd_eq</span><span>(</span><span>ascii</span><span>,</span> <span>Simd</span><span>::</span><span>splat</span><span>(</span><span>b'/'</span><span>))</span>
      <span>.to_int</span><span>()</span>
      <span>.cast</span><span>::</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>();</span>

  <span>let</span> <span>sextets</span> <span>=</span> <span>ascii</span>
    <span>-</span> <span>Simd</span><span>::</span><span>&lt;</span><span>i8</span><span>,</span> <span>8</span><span>&gt;</span><span>::</span><span>from</span><span>([</span><span>0</span><span>,</span> <span>16</span><span>,</span> <span>19</span><span>,</span> <span>4</span><span>,</span> <span>-</span><span>65</span><span>,</span> <span>-</span><span>65</span><span>,</span> <span>-</span><span>71</span><span>,</span> <span>-</span><span>71</span><span>])</span>
      <span>.cast</span><span>::</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>()</span>
      <span>.swizzle_dyn</span><span>(</span><span>hashes</span><span>);</span>  <span>// Note quite right yet, see next section.</span>

  <span>let</span> <span>ok</span> <span>=</span> <span>/* bloom filter shenanigans */</span><span>;</span>

  <span>let</span> <span>shifted</span> <span>=</span> <span>sextets</span><span>.cast</span><span>::</span><span>&lt;</span><span>u16</span><span>&gt;</span><span>()</span> <span>&lt;&lt;</span> <span>Simd</span><span>::</span><span>from</span><span>([</span><span>2</span><span>,</span> <span>4</span><span>,</span> <span>6</span><span>,</span> <span>8</span><span>]);</span>
  <span>let</span> <span>lo</span> <span>=</span> <span>shifted</span><span>.cast</span><span>::</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>();</span>
  <span>let</span> <span>hi</span> <span>=</span> <span>(</span><span>shifted</span> <span>&gt;&gt;</span> <span>Simd</span><span>::</span><span>splat</span><span>(</span><span>8</span><span>))</span><span>.cast</span><span>::</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>();</span>
  <span>let</span> <span>output</span> <span>=</span> <span>lo</span> <span>|</span> <span>hi</span><span>.rotate_lanes_left</span><span>::</span><span>&lt;</span><span>1</span><span>&gt;</span><span>();</span>

  <span>(</span><span>output</span><span>,</span> <span>ok</span><span>)</span>
<span>}</span></code></pre></figure></div> <p>The compactness of this solution should not be understated. The simplicity of this solution is a large part of what makes it so efficient, because it aggressively leverages the primitives the hardware offers us.</p> <h3 id="scaling-up"><a href="#scaling-up">Scaling Up</a></h3> <p>Ok, so now we have to contend with a new aspect of our implementation that’s crap: a <code>Simd&lt;u8, 4&gt;</code> is tiny. That’s not even 128 bits, which are the smallest vector registers on x86. What we need to do is make <code>decode_hot()</code> generic on the lane count. This will allow us to tune the number of lanes to batch together depending on benchmarks later on.</p> <div><figure><pre><code data-lang="rust"><span>fn</span> <span>decode_hot</span><span>&lt;</span><span>const</span> <span>N</span><span>:</span> <span>usize</span><span>&gt;</span><span>(</span><span>ascii</span><span>:</span> <span>Simd</span><span>&lt;</span><span>u8</span><span>,</span> <span>N</span><span>&gt;</span><span>)</span> <span>-&gt;</span> <span>(</span><span>Simd</span><span>&lt;</span><span>u8</span><span>,</span> <span>N</span><span>&gt;</span><span>,</span> <span>bool</span><span>)</span>
<span>where</span>
  <span>// This makes sure N is a small power of 2.</span>
  <span>LaneCount</span><span>&lt;</span><span>N</span><span>&gt;</span><span>:</span> <span>SupportedLaneCount</span><span>,</span>
<span>{</span>
  <span>let</span> <span>hashes</span> <span>=</span> <span>(</span><span>ascii</span> <span>&gt;&gt;</span> <span>Simd</span><span>::</span><span>splat</span><span>(</span><span>4</span><span>))</span>
    <span>+</span> <span>Simd</span><span>::</span><span>simd_eq</span><span>(</span><span>ascii</span><span>,</span> <span>Simd</span><span>::</span><span>splat</span><span>(</span><span>b'/'</span><span>))</span>
      <span>.to_int</span><span>()</span>
      <span>.cast</span><span>::</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>();</span>

  <span>let</span> <span>sextets</span> <span>=</span> <span>ascii</span>
    <span>-</span> <span>tiled</span><span>(</span><span>&amp;</span><span>[</span><span>0</span><span>,</span> <span>16</span><span>,</span> <span>19</span><span>,</span> <span>4</span><span>,</span> <span>-</span><span>65</span><span>,</span> <span>-</span><span>65</span><span>,</span> <span>-</span><span>71</span><span>,</span> <span>-</span><span>71</span><span>])</span>
      <span>.cast</span><span>::</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>()</span>
      <span>.swizzle_dyn</span><span>(</span><span>hashes</span><span>);</span>  <span>// Works fine now, as long as N &gt;= 8.</span>

  <span>let</span> <span>ok</span> <span>=</span> <span>/* bloom filter shenanigans */</span><span>;</span>

  <span>let</span> <span>shifted</span> <span>=</span> <span>sextets</span><span>.cast</span><span>::</span><span>&lt;</span><span>u16</span><span>&gt;</span><span>()</span> <span>&lt;&lt;</span> <span>tiled</span><span>(</span><span>&amp;</span><span>[</span><span>2</span><span>,</span> <span>4</span><span>,</span> <span>6</span><span>,</span> <span>8</span><span>]);</span>
  <span>let</span> <span>lo</span> <span>=</span> <span>shifted</span><span>.cast</span><span>::</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>();</span>
  <span>let</span> <span>hi</span> <span>=</span> <span>(</span><span>shifted</span> <span>&gt;&gt;</span> <span>Simd</span><span>::</span><span>splat</span><span>(</span><span>8</span><span>))</span><span>.cast</span><span>::</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>();</span>
  <span>let</span> <span>output</span> <span>=</span> <span>lo</span> <span>|</span> <span>hi</span><span>.rotate_lanes_left</span><span>::</span><span>&lt;</span><span>1</span><span>&gt;</span><span>();</span>

  <span>(</span><span>output</span><span>,</span> <span>ok</span><span>)</span>
<span>}</span>

<span>/// Generates a new vector made up of repeated "tiles" of identical</span>
<span>/// data.</span>
<span>const</span> <span>fn</span> <span>tiled</span><span>&lt;</span><span>T</span><span>,</span> <span>const</span> <span>N</span><span>:</span> <span>usize</span><span>&gt;</span><span>(</span><span>tile</span><span>:</span> <span>&amp;</span><span>[</span><span>T</span><span>])</span> <span>-&gt;</span> <span>Simd</span><span>&lt;</span><span>T</span><span>,</span> <span>N</span><span>&gt;</span>
<span>where</span>
  <span>T</span><span>:</span> <span>SimdElement</span><span>,</span>
  <span>LaneCount</span><span>&lt;</span><span>N</span><span>&gt;</span><span>:</span> <span>SupportedLaneCount</span><span>,</span>
<span>{</span>
  <span>let</span> <span>mut</span> <span>out</span> <span>=</span> <span>[</span><span>tile</span><span>[</span><span>0</span><span>];</span> <span>N</span><span>];</span>
  <span>let</span> <span>mut</span> <span>i</span> <span>=</span> <span>0</span><span>;</span>
  <span>while</span> <span>i</span> <span>&lt;</span> <span>N</span> <span>{</span>
    <span>out</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>tile</span><span>[</span><span>i</span> <span>%</span> <span>tile</span><span>.len</span><span>()];</span>
    <span>i</span> <span>+=</span> <span>1</span><span>;</span>
  <span>}</span>
  <span>Simd</span><span>::</span><span>from_array</span><span>(</span><span>out</span><span>)</span>
<span>}</span></code></pre></figure></div> <p>We have to change virtually nothing, which is pretty awesome! But unfortunately, this code is subtly incorrect. Remember how in the <code>N = 4</code> case, the result of <code>output</code> had a garbage value that we ignore in its highest lane? Well, now that garbage data is interleaved into output: every fourth lane contains garbage.</p> <p>We can use a shuffle to delete these lanes, thankfully. Specifically, we want <code>shuffled[i] = output[i + i / 3]</code>, which skips every forth index. So, <code>shuffled[3] = output[4]</code>, skipping over the garbage value in <code>output[3]</code>. If <code>i + i / 3</code> overflows <code>N</code>, that’s ok, because that’s the high quarter of the final output vector, which is ignored anyways. In code:</p> <div><figure><pre><code data-lang="rust"><span>fn</span> <span>decode_hot</span><span>&lt;</span><span>const</span> <span>N</span><span>:</span> <span>usize</span><span>&gt;</span><span>(</span><span>ascii</span><span>:</span> <span>Simd</span><span>&lt;</span><span>u8</span><span>,</span> <span>N</span><span>&gt;</span><span>)</span> <span>-&gt;</span> <span>(</span><span>Simd</span><span>&lt;</span><span>u8</span><span>,</span> <span>N</span><span>&gt;</span><span>,</span> <span>bool</span><span>)</span>
<span>where</span>
  <span>// This makes sure N is a small power of 2.</span>
  <span>LaneCount</span><span>&lt;</span><span>N</span><span>&gt;</span><span>:</span> <span>SupportedLaneCount</span><span>,</span>
<span>{</span>
  <span>/* snip */</span>

  <span>let</span> <span>decoded_chunks</span> <span>=</span> <span>lo</span> <span>|</span> <span>hi</span><span>.rotate_lanes_left</span><span>::</span><span>&lt;</span><span>1</span><span>&gt;</span><span>();</span>
  <span>let</span> <span>output</span> <span>=</span> <span>swizzle!</span><span>(</span><span>N</span><span>;</span> <span>decoded_chunks</span><span>,</span> <span>array!</span><span>(</span><span>N</span><span>;</span> <span>|</span><span>i</span><span>|</span> <span>i</span> <span>+</span> <span>i</span> <span>/</span> <span>3</span><span>));</span>

  <span>(</span><span>output</span><span>,</span> <span>ok</span><span>)</span>
<span>}</span></code></pre></figure></div> <blockquote> <p><code>swizzle!()</code> is a helper macro<sup id="fnref:macros" role="doc-noteref"><a href="#fn:macros" rel="footnote">6</a></sup> for generating generic implementations of <code>std::simd::Swizzle</code>, and <code>array!()</code> is something I wrote for generating generic-length array constants; the closure is called once for each <code>i in 0..N</code>.</p> </blockquote> <p>So now we can decode 32 base64 bytes in parallel by calling <code>decode_hot::&lt;32&gt;()</code>. We’ll try to keep things generic from here, so we can tune the lane parameter based on benchmarks.</p> <h3 id="the-outer-loop"><a href="#the-outer-loop">The Outer Loop</a></h3> <p>Let’s look at <code>decode()</code> again. Let’s start by making it generic on the internal lane count, too.</p> <div><figure><pre><code data-lang="rust"><span>fn</span> <span>decode</span><span>&lt;</span><span>const</span> <span>N</span><span>:</span> <span>usize</span><span>&gt;</span><span>(</span><span>data</span><span>:</span> <span>&amp;</span><span>[</span><span>u8</span><span>],</span> <span>out</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Vec</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>(),</span> <span>Error</span><span>&gt;</span>
<span>where</span>
  <span>LaneCount</span><span>&lt;</span><span>N</span><span>&gt;</span><span>:</span> <span>SupportedLaneCount</span><span>,</span>
<span>{</span>
  <span>let</span> <span>data</span> <span>=</span> <span>match</span> <span>data</span> <span>{</span>
    <span>[</span><span>p</span> <span>@</span> <span>..</span><span>,</span> <span>b'='</span><span>,</span> <span>b'='</span><span>]</span> <span>|</span> <span>[</span><span>p</span> <span>@</span> <span>..</span><span>,</span> <span>b'='</span><span>]</span> <span>|</span> <span>p</span> <span>=&gt;</span> <span>p</span><span>,</span>
  <span>};</span>

  <span>for</span> <span>chunk</span> <span>in</span> <span>data</span><span>.chunks</span><span>(</span><span>N</span><span>)</span> <span>{</span> <span>// N-sized chunks now.</span>
    <span>let</span> <span>mut</span> <span>ascii</span> <span>=</span> <span>[</span><span>b'A'</span><span>;</span> <span>N</span><span>];</span>
    <span>ascii</span><span>[</span><span>..</span><span>chunk</span><span>.len</span><span>()]</span><span>.copy_from_slice</span><span>(</span><span>chunk</span><span>);</span>

    <span>let</span> <span>(</span><span>dec</span><span>,</span> <span>ok</span><span>)</span> <span>=</span> <span>decode_hot</span><span>::</span><span>&lt;</span><span>N</span><span>&gt;</span><span>(</span><span>ascii</span><span>.into</span><span>());</span>
    <span>if</span> <span>(</span><span>!</span><span>ok</span><span>)</span> <span>{</span>
      <span>return</span> <span>Err</span><span>(</span><span>Error</span><span>);</span>
    <span>}</span>

    <span>let</span> <span>decoded</span> <span>=</span> <span>decoded_len</span><span>(</span><span>chunk</span><span>.len</span><span>());</span>
    <span>out</span><span>.extend_from_slice</span><span>(</span><span>&amp;</span><span>dec</span><span>[</span><span>..</span><span>decoded</span><span>]);</span>
  <span>}</span>

  <span>Ok</span><span>(())</span>
<span>}</span></code></pre></figure></div> <p>What branches are left? There’s still the branch from <code>for chunks in ...</code>. It’s not ideal because it can’t do an exact pointer comparison, and needs to do a <code>&gt;=</code> comparison on a length instead.</p> <p>We call <code>[T]::copy_from_slice</code>, which is super slow because it needs to make a variable-length <code>memcpy</code> call, which can’t be inlined. Function calls are branches! The bounds checks are also a problem.</p> <p>We branch on <code>ok</code> every loop iteration, still. Not returning early in <code>decode_hot</code> doesn’t win us anything (yet).</p> <p>We potentially call the allocator in <code>extend_from_slice</code>, and perform another non-inline-able <code>memcpy</code> call.</p> <h3 id="preallocating-with-slop"><a href="#preallocating-with-slop">Preallocating with Slop</a></h3> <p>The last of these is the easiest to address: we can reserve space in <code>out</code>, since we know exactly how much data we need to write thanks to <code>decoded_len</code>. Better yet, we can reserve some “slop”: i.e., scratch space past where the end of the message would be, so we can perform full SIMD stores, instead of the variable-length memcpy.</p> <p>This way, in each iteration, we write the full SIMD vector, including any garbage bytes in the upper quarter. Then, the next write is offset <code>3/4 * N</code> bytes over, so it overwrites the garbage bytes with decoded message bytes. The garbage bytes from the final right get “deleted” by not being included in the final <code>Vec::set_len()</code> that “commits” the memory we wrote to.</p> <div><figure><pre><code data-lang="rust"><span>fn</span> <span>decode</span><span>&lt;</span><span>const</span> <span>N</span><span>:</span> <span>usize</span><span>&gt;</span><span>(</span><span>data</span><span>:</span> <span>&amp;</span><span>[</span><span>u8</span><span>],</span> <span>out</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Vec</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>(),</span> <span>Error</span><span>&gt;</span>
<span>where</span> <span>LaneCount</span><span>&lt;</span><span>N</span><span>&gt;</span><span>:</span> <span>SupportedLaneCount</span><span>,</span>
<span>{</span>
  <span>let</span> <span>data</span> <span>=</span> <span>match</span> <span>data</span> <span>{</span>
    <span>[</span><span>p</span> <span>@</span> <span>..</span><span>,</span> <span>b'='</span><span>,</span> <span>b'='</span><span>]</span> <span>|</span> <span>[</span><span>p</span> <span>@</span> <span>..</span><span>,</span> <span>b'='</span><span>]</span> <span>|</span> <span>p</span> <span>=&gt;</span> <span>p</span><span>,</span>
  <span>};</span>

  <span>let</span> <span>final_len</span> <span>=</span> <span>decoded_len</span><span>(</span><span>data</span><span>);</span>
  <span>out</span><span>.reserve</span><span>(</span><span>final_len</span> <span>+</span> <span>N</span> <span>/</span> <span>4</span><span>);</span>  <span>// Reserve with slop.</span>

  <span>// Get a raw pointer to where we should start writing.</span>
  <span>let</span> <span>mut</span> <span>ptr</span> <span>=</span> <span>out</span><span>.as_mut_ptr_range</span><span>()</span><span>.end</span><span>();</span>
  <span>let</span> <span>start</span> <span>=</span> <span>ptr</span><span>;</span>

  <span>for</span> <span>chunk</span> <span>in</span> <span>data</span><span>.chunks</span><span>(</span><span>N</span><span>)</span> <span>{</span> <span>// N-sized chunks now.</span>
    <span>/* snip */</span>

    <span>let</span> <span>decoded</span> <span>=</span> <span>decoded_len</span><span>(</span><span>chunk</span><span>.len</span><span>());</span>
    <span>unsafe</span> <span>{</span>
      <span>// Do a raw write and advance the pointer.</span>
      <span>ptr</span><span>.cast</span><span>::</span><span>&lt;</span><span>Simd</span><span>&lt;</span><span>u8</span><span>,</span> <span>N</span><span>&gt;&gt;</span><span>()</span><span>.write_unaligned</span><span>(</span><span>dec</span><span>);</span>
      <span>ptr</span> <span>=</span> <span>ptr</span><span>.add</span><span>(</span><span>decoded</span><span>);</span>
    <span>}</span>
  <span>}</span>

  <span>unsafe</span> <span>{</span>
    <span>// Update the vector's final length.</span>
    <span>// This is the final "commit".</span>
    <span>let</span> <span>len</span> <span>=</span> <span>ptr</span><span>.offset_from</span><span>(</span><span>start</span><span>);</span>
    <span>out</span><span>.set_len</span><span>(</span><span>len</span> <span>as</span> <span>usize</span><span>);</span>
  <span>}</span>

  <span>Ok</span><span>(())</span>
<span>}</span></code></pre></figure></div> <p>This is safe, because we’ve pre-allocated exactly the amount of memory we need, and where <code>ptr</code> lands is equal to the amount of memory actually decoded. We could also compute the final length of <code>out</code> ahead of time.</p> <p>Note that if we early return due to <code>if !ok</code>, <code>out</code> remains unmodified, because even though we did write to its buffer, we never execute the “commit” part, so the code remains correct.</p> <h3 id="delaying-failure"><a href="#delaying-failure">Delaying Failure</a></h3> <p>Next up, we can eliminate the <code>if !ok</code> branches by waiting to return an error until as late as possible: just before the <code>set_len</code> call.</p> <p>Remember our observation from before: most base64 encoded blobs are valid, so this unhappy path should be very rare. Also, syntax errors cannot cause code that follows to misbehave arbitrarily, so letting it go wild doesn’t hurt anything.</p> <div><figure><pre><code data-lang="rust"><span>fn</span> <span>decode</span><span>&lt;</span><span>const</span> <span>N</span><span>:</span> <span>usize</span><span>&gt;</span><span>(</span><span>data</span><span>:</span> <span>&amp;</span><span>[</span><span>u8</span><span>],</span> <span>out</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Vec</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>(),</span> <span>Error</span><span>&gt;</span>
<span>where</span> <span>LaneCount</span><span>&lt;</span><span>N</span><span>&gt;</span><span>:</span> <span>SupportedLaneCount</span><span>,</span>
<span>{</span>
  <span>/* snip */</span>
  <span>let</span> <span>mut</span> <span>error</span> <span>=</span> <span>false</span><span>;</span>
  <span>for</span> <span>chunk</span> <span>in</span> <span>data</span><span>.chunks</span><span>(</span><span>N</span><span>)</span> <span>{</span>
    <span>let</span> <span>mut</span> <span>ascii</span> <span>=</span> <span>[</span><span>b'A'</span><span>;</span> <span>N</span><span>];</span>
    <span>ascii</span><span>[</span><span>..</span><span>chunk</span><span>.len</span><span>()]</span><span>.copy_from_slice</span><span>(</span><span>chunk</span><span>);</span>

    <span>let</span> <span>(</span><span>dec</span><span>,</span> <span>ok</span><span>)</span> <span>=</span> <span>decode_hot</span><span>::</span><span>&lt;</span><span>N</span><span>&gt;</span><span>(</span><span>ascii</span><span>.into</span><span>());</span>
    <span>error</span> <span>|</span><span>=</span> <span>!</span><span>ok</span><span>;</span>

    <span>/* snip */</span>
  <span>}</span>

  <span>if</span> <span>error</span> <span>{</span>
    <span>return</span> <span>Err</span><span>(</span><span>Error</span><span>);</span>
  <span>}</span>

  <span>unsafe</span> <span>{</span>
    <span>let</span> <span>len</span> <span>=</span> <span>ptr</span><span>.offset_from</span><span>(</span><span>start</span><span>);</span>
    <span>out</span><span>.set_len</span><span>(</span><span>len</span> <span>as</span> <span>usize</span><span>);</span>
  <span>}</span>

  <span>Ok</span><span>(())</span>
<span>}</span></code></pre></figure></div> <p>The branch is still “there”, sure, but it’s out of the hot loop.</p> <p>Because we never hit the <code>set_len</code> call and commit whatever garbage we wrote, said garbage essentially disappears when we return early, to be overwritten by future calls to <code>Vec::push()</code>.</p> <h3 id="unroll-it-harder"><a href="#unroll-it-harder">Unroll It Harder</a></h3> <p>Ok, let’s look at the memcpy from <code>copy_from_slice</code> at the start of the hot loop. The loop has already been partly unrolled: it does <code>N</code> iterations with SIMD each step, doing something funny on the last step to make up for the missing data (padding with <code>A</code>).</p> <p>We can take this a step further by doing an “unroll and jam” optimization. This type of unrolling splits the loop into two parts: a hot vectorized loop and a cold remainder part. The hot loop <em>always</em> handles length <code>N</code> input, and the remainder runs at most once and handles <code>i &lt; N</code> input.</p> <p>Rust provides an iterator adapter for hand-rolled (lol) unroll-and-jam: <code>Iterator::chunks_exact()</code>.</p> <div><figure><pre><code data-lang="rust"><span>fn</span> <span>decode</span><span>&lt;</span><span>const</span> <span>N</span><span>:</span> <span>usize</span><span>&gt;</span><span>(</span><span>data</span><span>:</span> <span>&amp;</span><span>[</span><span>u8</span><span>],</span> <span>out</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Vec</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>(),</span> <span>Error</span><span>&gt;</span>
<span>where</span> <span>LaneCount</span><span>&lt;</span><span>N</span><span>&gt;</span><span>:</span> <span>SupportedLaneCount</span><span>,</span>
<span>{</span>
  <span>/* snip */</span>
  <span>let</span> <span>mut</span> <span>error</span> <span>=</span> <span>false</span><span>;</span>
  <span>let</span> <span>mut</span> <span>chunks</span> <span>=</span> <span>data</span><span>.chunks_exact</span><span>(</span><span>N</span><span>);</span>
  <span>for</span> <span>chunk</span> <span>in</span> <span>&amp;</span><span>mut</span> <span>chunks</span> <span>{</span>
    <span>// Simd::from_slice() can do a load in one instruction.</span>
    <span>// The bounds check is easy for the compiler to elide.</span>
    <span>let</span> <span>(</span><span>dec</span><span>,</span> <span>ok</span><span>)</span> <span>=</span> <span>decode_hot</span><span>::</span><span>&lt;</span><span>N</span><span>&gt;</span><span>(</span><span>Simd</span><span>::</span><span>from_slice</span><span>(</span><span>chunk</span><span>));</span>
    <span>error</span> <span>|</span><span>=</span> <span>!</span><span>ok</span><span>;</span>
    <span>/* snip */</span>
  <span>}</span>

  <span>let</span> <span>rest</span> <span>=</span> <span>chunks</span><span>.remainder</span><span>();</span>
  <span>if</span> <span>!</span><span>rest</span><span>.empty</span><span>()</span> <span>{</span>
    <span>let</span> <span>mut</span> <span>ascii</span> <span>=</span> <span>[</span><span>b'A'</span><span>;</span> <span>N</span><span>];</span>
    <span>ascii</span><span>[</span><span>..</span><span>chunk</span><span>.len</span><span>()]</span><span>.copy_from_slice</span><span>(</span><span>chunk</span><span>);</span>

    <span>let</span> <span>(</span><span>dec</span><span>,</span> <span>ok</span><span>)</span> <span>=</span> <span>decode_hot</span><span>::</span><span>&lt;</span><span>N</span><span>&gt;</span><span>(</span><span>ascii</span><span>.into</span><span>());</span>
    <span>/* snip */</span>
  <span>}</span>

  <span>/* snip */</span>
<span>}</span></code></pre></figure></div> <p>Splitting into two parts lets us call <code>Simd::from_slice()</code>, which performs a single, vector-sized load.</p> <h2 id="so-how-fast-is-it"><a href="#so-how-fast-is-it">So, How Fast Is It?</a></h2> <p>At this point, it looks like we’ve addressed every branch that we can, so some benchmarks are in order. I wrote a benchmark that decodes messages of every length from 0 to something like 200 or 500 bytes, and compared it against the baseline base64 implementation on crates.io.</p> <p>I compiled with <code>-Zbuild-std</code> and <code>-Ctarget-cpu=native</code> to try to get the best results. Based on some tuning, <code>N = 32</code> was the best length, since it used one YMM register for each iteration of the hot loop.</p> <p><img src="https://mcyoung.xyz/public/simd-img/graph-old.png" alt="a performance graph; our code is really good compared to the baseline, but variance is high"></p> <p>So, we have the baseline beat. But what’s up with that crazy heartbeat waveform? You can tell it has something to do with the “remainder” part of the loop, since it correlates strongly with <code>data.len() % 32</code>.</p> <p>I stared at the assembly for a while. I don’t remember what was there, but I think that <code>copy_from_slice</code> had been inlined and unrolled into a loop that loaded each byte at a time. The moral equivalent of this:</p> <div><figure><pre><code data-lang="rust"><span>let</span> <span>mut</span> <span>ascii</span> <span>=</span> <span>[</span><span>b'A'</span><span>;</span> <span>N</span><span>];</span>
<span>for</span> <span>(</span><span>a</span><span>,</span> <span>b</span><span>)</span> <span>in</span> <span>Iterator</span><span>::</span><span>zip</span><span>(</span><span>&amp;</span><span>mut</span> <span>ascii</span><span>,</span> <span>chunk</span><span>)</span> <span>{</span>
  <span>*</span><span>a</span> <span>=</span> <span>*</span><span>b</span><span>;</span>
<span>}</span></code></pre></figure></div> <p>I decided to try <code>Simd::gather_or()</code>, which is kind of like a “vectorized load”. It wound up producing worse assembly, so I gave up on using a gather and instead wrote a carefully optimized loading function by hand.</p> <h3 id="unroll-and-jam-revisited"><a href="#unroll-and-jam-revisited">Unroll and Jam, Revisited</a></h3> <p>The idea here is to perform the largest scalar loads Rust offers where possible. The strategy is again unroll and jam: perform <code>u128</code> loads in a loop and deal with the remainder separately.</p> <p>The hot part looks like this:</p> <div><figure><pre><code data-lang="rust"><span>let</span> <span>mut</span> <span>buf</span> <span>=</span> <span>[</span><span>b'A'</span><span>;</span> <span>N</span><span>];</span>

<span>// Load a bunch of big 16-byte chunks. LLVM will lower these to XMM loads.</span>
<span>let</span> <span>ascii_ptr</span> <span>=</span> <span>buf</span><span>.as_mut_ptr</span><span>();</span>
<span>let</span> <span>mut</span> <span>write_at</span> <span>=</span> <span>ascii_ptr</span><span>;</span>
<span>if</span> <span>slice</span><span>.len</span><span>()</span> <span>&gt;=</span> <span>16</span> <span>{</span>
  <span>for</span> <span>i</span> <span>in</span> <span>0</span><span>..</span><span>slice</span><span>.len</span><span>()</span> <span>/</span> <span>16</span> <span>{</span>
    <span>unsafe</span> <span>{</span>
      <span>write_at</span> <span>=</span> <span>write_at</span><span>.add</span><span>(</span><span>i</span> <span>*</span> <span>16</span><span>);</span>

      <span>let</span> <span>word</span> <span>=</span> <span>slice</span><span>.as_ptr</span><span>()</span><span>.cast</span><span>::</span><span>&lt;</span><span>u128</span><span>&gt;</span><span>()</span><span>.add</span><span>(</span><span>i</span><span>)</span><span>.read_unaligned</span><span>();</span>
      <span>write_at</span><span>.cast</span><span>::</span><span>&lt;</span><span>u128</span><span>&gt;</span><span>()</span><span>.write_unaligned</span><span>(</span><span>word</span><span>);</span>
    <span>}</span>
  <span>}</span>
<span>}</span></code></pre></figure></div> <p>The cold part seems hard to optimize at first. What’s the least number of unaligned loads you need to do to load 15 bytes from memory? It’s two! You can load a <code>u64</code> from <code>p</code>, and then another one from <code>p + 7</code>; these loads (call them <code>a</code> and <code>b</code>) overlap by one byte, but we can or them together to merge that byte, so our loaded value is <code>a as u128 | (b as u128 &lt;&lt; 56)</code>.</p> <p>A similar trick works if the data to load is between a <code>u32</code> and a <code>u64</code>. Finally, to load 1, 2, or 3 bytes, we can load <code>p</code>, <code>p + len/2</code> and <code>p + len-1</code>; depending on whether <code>len</code> is 1, 2, or 3, this will potentially load the same byte multiple times; however, this reduces the number of branches necessary, since we don’t need to distinguish the 1, 2, or 3 lines.</p> <p>This is the kind of code that’s probably easier to read than to explain.</p> <div><figure><pre><code data-lang="rust"><span>unsafe</span> <span>{</span>
  <span>let</span> <span>ptr</span> <span>=</span> <span>slice</span><span>.as_ptr</span><span>()</span><span>.offset</span><span>(</span><span>write_at</span><span>.offset_from</span><span>(</span><span>ascii_ptr</span><span>));</span>
  <span>let</span> <span>len</span> <span>=</span> <span>slice</span><span>.len</span><span>()</span> <span>%</span> <span>16</span><span>;</span>

  <span>if</span> <span>len</span> <span>&gt;=</span> <span>8</span> <span>{</span>
    <span>// Load two overlapping u64s.</span>
    <span>let</span> <span>lo</span> <span>=</span> <span>ptr</span><span>.cast</span><span>::</span><span>&lt;</span><span>u64</span><span>&gt;</span><span>()</span><span>.read_unaligned</span><span>()</span> <span>as</span> <span>u128</span><span>;</span>
    <span>let</span> <span>hi</span> <span>=</span> <span>ptr</span><span>.add</span><span>(</span><span>len</span> <span>-</span> <span>8</span><span>)</span><span>.cast</span><span>::</span><span>&lt;</span><span>u64</span><span>&gt;</span><span>()</span><span>.read_unaligned</span><span>()</span> <span>as</span> <span>u128</span><span>;</span>
    <span>let</span> <span>data</span> <span>=</span> <span>lo</span> <span>|</span> <span>(</span><span>hi</span> <span>&lt;&lt;</span> <span>((</span><span>len</span> <span>-</span> <span>8</span><span>)</span> <span>*</span> <span>8</span><span>));</span>

    <span>let</span> <span>z</span> <span>=</span> <span>u128</span><span>::</span><span>from_ne_bytes</span><span>([</span><span>b'A'</span><span>;</span> <span>16</span><span>])</span> <span>&lt;&lt;</span> <span>(</span><span>len</span> <span>*</span> <span>8</span><span>);</span>
    <span>write_at</span><span>.cast</span><span>::</span><span>&lt;</span><span>u128</span><span>&gt;</span><span>()</span><span>.write_unaligned</span><span>(</span><span>data</span> <span>|</span> <span>z</span><span>);</span>
  <span>}</span> <span>else</span> <span>if</span> <span>len</span> <span>&gt;=</span> <span>4</span> <span>{</span>
    <span>// Load two overlapping u32s.</span>
    <span>let</span> <span>lo</span> <span>=</span> <span>ptr</span><span>.cast</span><span>::</span><span>&lt;</span><span>u32</span><span>&gt;</span><span>()</span><span>.read_unaligned</span><span>()</span> <span>as</span> <span>u64</span><span>;</span>
    <span>let</span> <span>hi</span> <span>=</span> <span>ptr</span><span>.add</span><span>(</span><span>len</span> <span>-</span> <span>4</span><span>)</span><span>.cast</span><span>::</span><span>&lt;</span><span>u32</span><span>&gt;</span><span>()</span><span>.read_unaligned</span><span>()</span> <span>as</span> <span>u64</span><span>;</span>
    <span>let</span> <span>data</span> <span>=</span> <span>lo</span> <span>|</span> <span>(</span><span>hi</span> <span>&lt;&lt;</span> <span>((</span><span>len</span> <span>-</span> <span>4</span><span>)</span> <span>*</span> <span>8</span><span>));</span>

    <span>let</span> <span>z</span> <span>=</span> <span>u64</span><span>::</span><span>from_ne_bytes</span><span>([</span><span>b'A'</span><span>;</span> <span>8</span><span>])</span> <span>&lt;&lt;</span> <span>(</span><span>len</span> <span>*</span> <span>8</span><span>);</span>
    <span>write_at</span><span>.cast</span><span>::</span><span>&lt;</span><span>u64</span><span>&gt;</span><span>()</span><span>.write_unaligned</span><span>(</span><span>data</span> <span>|</span> <span>z</span><span>);</span>
  <span>}</span> <span>else</span> <span>{</span>
    <span>// Load 3 overlapping u8s.</span>

    <span>// For len       1       2       3     ...</span>
    <span>// ... this is  ptr[0]  ptr[0]  ptr[0]</span>
    <span>let</span> <span>lo</span> <span>=</span> <span>ptr</span><span>.read</span><span>()</span> <span>as</span> <span>u32</span><span>;</span>
    <span>// ... this is  ptr[0]  ptr[1]  ptr[1]</span>
    <span>let</span> <span>mid</span> <span>=</span> <span>ptr</span><span>.add</span><span>(</span><span>len</span> <span>/</span> <span>2</span><span>)</span><span>.read</span><span>()</span> <span>as</span> <span>u32</span><span>;</span>
    <span>// ... this is  ptr[0]  ptr[1]  ptr[2]</span>
    <span>let</span> <span>hi</span> <span>=</span> <span>ptr</span><span>.add</span><span>(</span><span>len</span> <span>-</span> <span>1</span><span>)</span><span>.read</span><span>()</span> <span>as</span> <span>u32</span><span>;</span>

    <span>let</span> <span>data</span> <span>=</span> <span>lo</span> <span>|</span> <span>(</span><span>mid</span> <span>&lt;&lt;</span> <span>((</span><span>len</span> <span>/</span> <span>2</span><span>)</span> <span>*</span> <span>8</span><span>))</span> <span>|</span> <span>hi</span> <span>&lt;&lt;</span> <span>((</span><span>len</span> <span>-</span> <span>1</span><span>)</span> <span>*</span> <span>8</span><span>);</span>

    <span>let</span> <span>z</span> <span>=</span> <span>u32</span><span>::</span><span>from_ne_bytes</span><span>([</span><span>b'A'</span><span>;</span> <span>4</span><span>])</span> <span>&lt;&lt;</span> <span>(</span><span>len</span> <span>*</span> <span>8</span><span>);</span>
    <span>write_at</span><span>.cast</span><span>::</span><span>&lt;</span><span>u32</span><span>&gt;</span><span>()</span><span>.write_unaligned</span><span>(</span><span>data</span> <span>|</span> <span>z</span><span>);</span>
  <span>}</span>
<span>}</span></code></pre></figure></div> <p>I learned this type of loading code while contributing to Abseil: it’s very useful for loading variable-length data for data-hungry algorithms, like a codec or a hash function.</p> <p>Here’s the same benchmark again, but with our new loading code.</p> <p><img src="https://mcyoung.xyz/public/simd-img/graph.png" alt="a performance graph; our code is even better and the variance is very tight"></p> <p>The results are really, really good. The variance is super tight, and our performance is 2x that of the baseline pretty much everywhere. <em>Success.</em></p> <h3 id="encoding-web-safe"><a href="#encoding-web-safe">Encoding? Web-Safe?</a></h3> <p>Writing an encoding function is simple enough: first, implement an <code>encode_hot()</code> function that reverses the operations from <code>decode_hot()</code>. The perfect hash from before won’t work, so you’ll need to <a href="https://github.com/mcy/vb64/blob/main/src/simd.rs#L170">invent a new one</a>.</p> <p>Also, the loading/storing code around the encoder is slightly different, too. <code>vb64</code> implements a very efficient encoding routine too, so I suggest taking a look at the source code if you’re interested.</p> <p>There is a base64 variant called web-safe base64, that replaces the <code>+</code> and <code>/</code> characters with <code>-</code> and <code>_</code>. Building a perfect hash for these is trickier: you would probably have to do something like <code>(byte &gt;&gt; 4) - (byte == '_' ? '_' : 0)</code>. I don’t support web-safe base64 yet, but only because I haven’t gotten around to it.</p> <h2 id="conclusion"><a href="#conclusion">Conclusion</a></h2> <p>My library doesn’t really solve an important problem; base64 decoding isn’t a bottleneck… anywhere that I know of, really. But writing SIMD code is really fun! Writing branchless code is often overkill but can give you a good appreciation for what your compilers can and <em>can’t</em> do for you.</p> <p>This project was also an excuse to try <code>std::simd</code>. I think it’s great overall, and generates excellent code. There’s some rough edges I’d like to see fixed to make SIMD code even simpler, but overall I’m very happy with the work that’s been done there.</p> <p>This is probably one of the most complicated posts I’ve written in a long time. SIMD (and performance in general) is a complex topic that requires a breadth of knowledge of tricks and hardware, a lot of which isn’t written down. More of it is written down now, though. ◼</p>  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Simplifying Transformer Blocks (127 pts)]]></title>
            <link>https://arxiv.org/abs/2311.01906</link>
            <guid>38442779</guid>
            <pubDate>Tue, 28 Nov 2023 05:49:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2311.01906">https://arxiv.org/abs/2311.01906</a>, See on <a href="https://news.ycombinator.com/item?id=38442779">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2311.01906.pdf">Download PDF</a></p><blockquote>
            <span>Abstract:</span>A simple design recipe for deep Transformers is to compose identical building blocks. But standard transformer blocks are far from simple, interweaving attention and MLP sub-blocks with skip connections &amp; normalisation layers in precise arrangements. This complexity leads to brittle architectures, where seemingly minor changes can significantly reduce training speed, or render models untrainable.
<br>In this work, we ask to what extent the standard transformer block can be simplified? Combining signal propagation theory and empirical observations, we motivate modifications that allow many block components to be removed with no loss of training speed, including skip connections, projection or value parameters, sequential sub-blocks and normalisation layers. In experiments on both autoregressive decoder-only and BERT encoder-only models, our simplified transformers emulate the per-update training speed and performance of standard transformers, while enjoying 15% faster training throughput, and using 15% fewer parameters.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Bobby He [<a href="https://arxiv.org/show-email/52c09d90/2311.01906">view email</a>]      <br>    <strong>[v1]</strong>
        Fri, 3 Nov 2023 13:30:52 UTC (7,026 KB)<br>
</p></div></div>]]></description>
        </item>
    </channel>
</rss>