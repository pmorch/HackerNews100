<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 20 Apr 2025 01:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Vibe Coding is not an excuse for low-quality work (123 pts)]]></title>
            <link>https://addyo.substack.com/p/vibe-coding-is-not-an-excuse-for</link>
            <guid>43739037</guid>
            <pubDate>Sat, 19 Apr 2025 20:00:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://addyo.substack.com/p/vibe-coding-is-not-an-excuse-for">https://addyo.substack.com/p/vibe-coding-is-not-an-excuse-for</a>, See on <a href="https://news.ycombinator.com/item?id=43739037">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><strong>“Move faster and break even more things.”</strong><span> </span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29688e26-bc5a-4f72-9fea-f423288af3d0_2160x1022.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29688e26-bc5a-4f72-9fea-f423288af3d0_2160x1022.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29688e26-bc5a-4f72-9fea-f423288af3d0_2160x1022.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29688e26-bc5a-4f72-9fea-f423288af3d0_2160x1022.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29688e26-bc5a-4f72-9fea-f423288af3d0_2160x1022.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29688e26-bc5a-4f72-9fea-f423288af3d0_2160x1022.png" width="2160" height="1022" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/29688e26-bc5a-4f72-9fea-f423288af3d0_2160x1022.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1022,&quot;width&quot;:2160,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:215932,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://addyo.substack.com/i/161584260?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff1e97c40-53bb-47f7-b305-dea867d9a293_2160x2160.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29688e26-bc5a-4f72-9fea-f423288af3d0_2160x1022.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29688e26-bc5a-4f72-9fea-f423288af3d0_2160x1022.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29688e26-bc5a-4f72-9fea-f423288af3d0_2160x1022.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29688e26-bc5a-4f72-9fea-f423288af3d0_2160x1022.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p><span>That twist on Silicon Valley’s old mantra echoes through recent engineering circles as “vibe coding” enters the chat. </span><strong>Yes, AI-assisted development is transforming how we build software, but it’s not a free pass to abandon rigor, review, or craftsmanship.</strong><span> "Vibe coding" is not an excuse for low-quality work.</span></p><p><span>Let’s acknowledge the good: AI-assisted coding </span><em>can</em><span> be a game-changer. It </span><strong>lowers barriers</strong><span> for new programmers and non-programmers, allowing them to produce working software by simply describing what they need. This unblocks creativity – more people can solve their own problems with custom software, part of a trend some call the </span><em><a href="https://addyo.substack.com/p/personal-software-the-unbundling" rel="">unbundling of personal software</a></em><span> (using small AI-built tools instead of one-size-fits-all apps). Even experienced engineers stand to benefit. </span></p><p><span>However, as any seasoned engineer will tell you, </span><strong>speed means nothing if the wheels fall off down the road</strong><span>. And this is where the cracks begin to show – in the gap between the </span><em>vibe</em><span> and the </span><em>reality</em><span> of building maintainable, robust software.</span></p><p><span>For all the hype, vibe coding has earned plenty of skepticism from veteran developers. The core critique: </span><em>just because an AI can spit out code quickly doesn’t mean that code is any good</em><span>. In fact, it can be downright dangerous to accept AI-generated output at face value. The joking complaint that </span><em>“two engineers can now create the tech debt of fifty”</em><span> contains a grain of truth. </span><strong>Unchecked AI-generated code can massively amplify technical debt</strong><span>, the hidden problems that make software brittle and costly to maintain.</span></p><p><span>Many early vibe-coded projects look good on the surface (“it works, ship it!”) but hide a minefield of issues: no error handling, poor performance, questionable security practices, and logically brittle code. One might say such projects are built on </span><strong>sand</strong><span>. I’ve used the term </span><strong><span>“</span><a href="https://addyo.substack.com/p/the-70-problem-hard-truths-about" rel="">house of cards code</a><span>”</span></strong><span> – code that “looks complete but collapses under real-world pressure”. If you’ve ever seen a junior developer’s first big feature that </span><em>almost</em><span> works but crumbles with one unexpected input, you get the idea. AI can churn out a lot of code quickly, but volume ≠ quality.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35589043-ada7-46f5-8243-b9b4430aa2f2_2050x2050.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35589043-ada7-46f5-8243-b9b4430aa2f2_2050x2050.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35589043-ada7-46f5-8243-b9b4430aa2f2_2050x2050.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35589043-ada7-46f5-8243-b9b4430aa2f2_2050x2050.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35589043-ada7-46f5-8243-b9b4430aa2f2_2050x2050.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35589043-ada7-46f5-8243-b9b4430aa2f2_2050x2050.jpeg" width="1456" height="1456" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/35589043-ada7-46f5-8243-b9b4430aa2f2_2050x2050.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1456,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:343905,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://addyo.substack.com/i/161584260?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35589043-ada7-46f5-8243-b9b4430aa2f2_2050x2050.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35589043-ada7-46f5-8243-b9b4430aa2f2_2050x2050.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35589043-ada7-46f5-8243-b9b4430aa2f2_2050x2050.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35589043-ada7-46f5-8243-b9b4430aa2f2_2050x2050.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35589043-ada7-46f5-8243-b9b4430aa2f2_2050x2050.jpeg 1456w" sizes="100vw"></picture></div></a></figure></div><p><em><span>"AI is like having a very eager junior developer on your team" an idea well illustrated in this illustration by </span></em></p><p><em><span>.</span></em><span> </span></p><p><span>The dangers aren’t purely hypothetical. Consider maintainability: Who will maintain an AI-written module if it’s obscure or overly complex? If even the original developer doesn’t fully understand the AI’s solution, future modifications become nightmares. Security is another huge concern – AI might generate code that </span><em>appears</em><span> to work but has SQL injection flaws or unsafe error handling. Without rigorous review, these can slip into production. There’s also the risk of </span><strong>overfitting to the prompt</strong><span>: an AI will do exactly what you ask, which might not be exactly what you truly need. Human coders often adjust a design as they implement, discovering misassumptions along the way. AI won’t catch those misassumptions unless the human in the loop notices and corrects it.</span></p><p><span>None of this is to say AI can’t write </span><strong>good</strong><span> code – it sometimes does – but rather that </span><strong>context, scrutiny, and expertise are required to discern good from bad</strong><span>. In 2025, we are essentially using a very eager but inexperienced assistant. You wouldn’t let a first-year junior dev architect your entire system unsupervised; similarly you shouldn’t blindly trust an AI’s code without oversight. The hype of “AI magic” needs to meet the reality of software engineering principles.</span></p><p><span>So, how do we strike the balance? The key is </span><strong>not</strong><span> to throw vibe coding out entirely – it </span><em>can</em><span> be incredibly useful – but to integrate it in a disciplined way. Engineers must approach AI assistance as a tool </span><em>with known limitations</em><span>, not a mystical code genie. In practice, that means keeping the human in the loop and maintaining our standards of quality. Let’s explore what that looks like.</span></p><p><span>To use vibe coding effectively, change your mindset: </span><strong>treat the AI like a super-speedy but junior developer on your team</strong><span>. In other words, you – the senior engineer or team lead – are still the one responsible for the outcome. The AI might crank out the first draft of code, but you must review it with a critical eye, refine it, and verify it meets your quality bar.</span></p><p>Experienced developers who successfully incorporate AI follow this pattern intuitively. When an AI assistant suggests code, they don’t just hit “accept” and move on. Instead, they:</p><ul><li><p><strong>Read and understand</strong><span> what the AI wrote, as if a junior dev on their team wrote it.</span></p></li><li><p><strong>Refactor</strong><span> the code into clean, modular parts if the AI’s output is monolithic or messy (which it often is). Senior engineers will break the AI’s blob into “smaller, focused modules” for clarity.</span></p></li><li><p><strong>Add missing edge-case handling</strong><span>. AI often misses corner cases or error conditions, so the human needs to insert those (null checks, input validation, etc.)</span></p></li><li><p><strong>Strengthen types and interfaces</strong><span>. If the AI used loose types or a leaky abstraction, a human can firm that up, turning implicit assumptions into explicit contracts </span></p></li><li><p><strong>Question the architecture</strong><span>. Did the AI choose an inefficient approach? Maybe it brute-forced something that should use a more optimal algorithm, or perhaps it introduced global state where a pure function would suffice. A human should examine these decisions critically.</span></p></li><li><p><strong>Write tests</strong><span> (or at least, manually test the code’s behavior). Treat AI code like any PR from a coworker: it doesn’t go in until it’s tested. If the AI wrote unit tests (some tools do), double-check those tests aren’t superficial.</span></p></li></ul><p><span>By doing this, you inject </span><em>engineering wisdom</em><span> into the AI-generated code. The combination can be powerful – the AI gets you a lot of code quickly, and your oversight ensures it’s solid. In fact, studies and anecdotes suggest senior devs get </span><strong>more value</strong><span> from AI coding tools than juniors. The reason is clear: seniors have the knowledge to steer the AI properly and fix its mistakes. Juniors may be tempted to treat the AI as an infallible authority, which it isn’t. </span></p><p><span>So, a critical rule emerges: </span><strong>Never accept AI-written code into your codebase unreviewed.</strong><span> Treat it like code from a new hire: inspect every line, ensure you </span><em>get it</em><span>. If something doesn’t make sense to you, don’t assume the AI knows better – often it doesn’t. Either refine the prompt to have the AI clarify, or rewrite that part yourself. Consider AI output as a draft that </span><strong>must</strong><span> go through code review (even if that review is just you). On a team, this means if a developer used AI to generate a chunk of code, they should be prepared to explain and defend it in the code review with peers. “It works, trust me” won’t fly – the team needs confidence that the code is understandable and maintainable by humans.</span></p><p><span>Another best practice: </span><strong>keep humans in the driver’s seat of design</strong><span>. Use the AI to implement, not to decide fundamental architectures. For example, you might use vibe coding to quickly create a CRUD REST API based on an existing schema – that’s well-defined work. But you shouldn’t ask the AI to “design a scalable microservice architecture for our product” and then blindly follow it. High-level design and critical decisions should remain human-led, with AI as a helper for the tedious parts. In essence, let the AI handle the </span><em>grunt work</em><span>, not the </span><em>brain work</em><span>. </span></p><p><strong>Communication and documentation</strong><span> also become crucial. If you prompt an AI to generate a non-trivial algorithm or use an unfamiliar library, take the time to document </span><em>why</em><span> that solution was chosen (just as you would if you wrote it yourself after research). Future maintainers – or your future self – shouldn’t be left guessing about the intent behind AI-crafted code. Some teams even log the prompts used to generate important code, effectively documenting the “conversation” that led to the code. This can help when debugging later: you can see the assumptions that were given to the AI.</span></p><p><span>In summary, </span><strong>human oversight isn’t a “nice-to-have” – it’s mandatory</strong><span>. The moment you remove the human from the loop, you’re just rolling dice on your software quality. Until AI can truly replace a senior engineer’s holistic understanding (we’re not there yet), vibe coding must be a partnership: AI accelerates, human validates.</span></p><p><span>Let’s crystallize the discussion into some actionable rules and best practices for teams adopting AI-assisted development. Think of these as the new </span><em>“move fast, but don’t break everything”</em><span> handbook – a set of guardrails to keep </span><strong>quality</strong><span> high when you’re vibing with the code.</span></p><p><strong>Rule 1: Always Review AI-Generated Code</strong><span> – No exceptions. Every block of code that AI produces should be treated as if a junior engineer wrote it. Do a code review either individually or with a peer. This includes code from Copilot, ChatGPT, Cursor, or any AI agent. If you don’t have time to review it, you don’t have time to use it. Blindly merging AI code is asking for trouble.</span></p><p><strong>Rule 2: Establish Coding Standards and Follow Them</strong><span> – AI tools will mimic whatever code they were trained on, which is a mixed bag. Define your team’s style guides, architecture patterns, and best practices, and ensure that any AI-generated code is refactored to comply. For instance, if your rule is “all functions need JSDoc comments and unit tests,” then AI output must get those comments and tests before it’s done. If your project uses a specific architecture (say, layered architecture with service/repository classes), don’t let the AI shove some ad-hoc database calls in UI code – fix it to fit your layers. Consider creating </span><strong>linting or static analysis checks</strong><span> specifically for common AI mistakes (e.g. flagging use of deprecated APIs or overly complex functions). This automates quality control on AI contributions.</span></p><p><strong>Rule 3: Use AI for Acceleration, Not Autopilot</strong><span> – In practice, this means use vibe coding to speed up well-understood tasks, not to do thinking for you. Great uses: generate boilerplate, scaffold a component, translate one language to another, draft a simple algorithm from pseudocode. Risky uses: have the AI design your module from scratch with minimal guidance, or generate code in a domain you don’t understand at all (you won’t know if it’s wrong). If you intend to keep the code, don’t stay in vibe mode – switch into engineering mode and tighten it up.</span></p><p><strong>Rule 4: Test, Test, Test</strong><span> – AI doesn’t magically guarantee correctness. Write tests for all critical paths of AI-written code. If the AI wrote the code, it may even help you write some tests – but don’t rely solely on AI-generated tests, as they might miss edge cases (or could be falsely passing due to the same flawed logic). Do manual testing too, especially for user-facing features: click through the UI, try odd inputs, see how it behaves. Many vibe-coded applications work fine for the “happy path” but fall apart with unexpected input – you want to catch that before your users do. </span></p><p><strong>Rule 5: Iterate and Refine</strong><span> – Don’t accept the first thing the AI gives you if it’s not satisfactory. Vibe coding is an iterative dialogue. If the initial output is clunky or confusing, you can prompt the AI to improve it (“simplify this code,” “split this into smaller functions,” etc.). Or you can take the draft and refactor it yourself. Often, a good approach is using the AI in </span><strong>cycles</strong><span>: prompt for an implementation, identify weaknesses, then either prompt fixes or manually adjust, and repeat. </span></p><p><strong>Rule 6: Know When to Say No</strong><span> – Sometimes, vibe coding just isn’t the right tool. Part of using it responsibly is recognizing scenarios where manual coding or deeper design work is needed. For example, if you’re dealing with a critical security module, you probably want to design it carefully and maybe only use AI to assist with small pieces (if at all). Or if the AI keeps producing a convoluted solution to a simple problem, stop and write it yourself – you might save time in the end. It’s important not to become overly reliant on the AI to solve every problem. </span><strong>Don’t let “AI did it” become an excuse for not understanding your own code.</strong><span> If after a few attempts the AI isn’t producing what you need, take back control and code it the old-fashioned way; you’ll at least have full understanding then.</span></p><p><strong>Rule 7: Document and Share Knowledge</strong><span> – Ensure that any code coming from AI is documented just as thoroughly as hand-written code (if not more). If there were non-obvious decisions or if you suspect others might be confused by what the AI produced, add comments. In team discussions, be open about what was AI-generated and what wasn’t. This helps reviewers pay extra attention to those sections. </span></p><p><span>Following these rules, teams can enjoy the productivity perks of vibe coding while mitigating the worst risks. Think of it as </span><strong>augmenting</strong><span> human developers, not replacing them. The goal is to </span><strong>co-create</strong><span> with AI: let it handle the repetitive drudge work at high speed, while humans handle the creative and critical thinking parts.</span></p><p><span>It’s also important to recognize </span><strong>where vibe coding shines and where it doesn’t</strong><span>. Not every project or task is equally suited to an AI-driven workflow. Here’s a breakdown drawn from industry discussions and early experiences:</span></p><p><strong>👍 Great Use Cases:</strong><span> </span></p><ul><li><p><em>Rapid prototyping</em><span> is perhaps the sweet spot of vibe coding. If you have an idea for a small app or feature, using an AI assistant to throw together a quick prototype or proof-of-concept can be incredibly effective. In such cases, you don’t mind if the code is a bit hacky; you just want to validate the idea. Many engineers have found success in weekend projects using only AI to code – a fun way to test a concept fast. Another good use case is </span><strong>one-off scripts or internal tools</strong><span>: e.g., a script to parse a log file, a small tool to automate a personal task, or an internal dashboard for your team. These are typically low-stakes; if the script breaks, it’s not the end of the world. Here, vibe coding can save time because you don’t need production-grade perfection, just something that works for now.</span></p></li><li><p><span>Vibe coding also works well for </span><strong>learning and exploration</strong><span>. If you’re working in a new language or API, asking an AI to generate examples can accelerate your learning. (Of course, double-check the AI’s output against official docs!) . In exploratory mode, even if the AI’s code isn’t perfect, it gives you material to tinker with and learn from. It’s like having a teaching assistant who can show you attempts, which you then refine.</span></p></li><li><p><span>Additionally, AI code generation can excel at </span><strong>structured, boilerplate-heavy tasks</strong><span>. Need to create 10 similar data classes? Or implement a rote CRUD layer? AI is great at that kind of mechanical repetition, freeing you from the tedium. As long as the pattern is clear, the AI will follow it and save you keystrokes (just verify it followed the pattern correctly).</span></p></li></ul><p><strong>👎 Not-So-Great Use Cases:</strong><span> </span></p><ul><li><p><span>On the flip side, </span><em>enterprise-grade software and complex systems</em><span> are where vibe coding often falls flat. Anything that requires a deep understanding of business logic, heavy concurrency, rigorous security, or compliance is not something to fully trust to AI generation. The AI doesn’t know your business constraints or performance requirements unless you explicitly spell them out (and even then, it may not get it right). For example, a fintech application handling payments or an aerospace control system must meet standards that current AI simply isn’t equipped to guarantee. In these domains, AI can assist in parts, but human expertise and careful QA are paramount for the final product.</span></p></li><li><p><span>Vibe coding also struggles with </span><strong>long-term maintainability</strong><span>. If you’re building a codebase that will live for years and be worked on by many developers, starting it off with a hodge-podge of AI-generated code can be a poor foundation. Without strong guidance, the architecture might be inconsistent. It’s often better to spend extra time up front building a clean framework (with or without AI help) than to patchwork a whole product via successive AI prompts. Many early adopters have observed that the initial time saved by vibe coding can be lost later during code cleanup and refactoring when the project needs to scale or adapt.</span></p></li><li><p><span>Another scenario to be wary of is </span><strong>critical algorithms or optimizations</strong><span>. AI can produce a sorting algorithm or a database query, sure – but if you need it to be highly optimized (say, a custom memory management routine, or an algorithm that must run in sub-linear time), you’re in territory where human ingenuity and deep understanding are still superior. AI might give you something that works on small data, but falls over at scale, and it won’t necessarily warn you about that. A human performance engineer would design and test with those considerations in mind from the start.</span></p></li><li><p><span>Finally, any situation where </span><strong>explainability and clarity</strong><span> are top priorities might not be ideal for vibe coding. Sometimes you need code that other people (or auditors) can easily read and reason about. If the AI comes up with a convoluted approach, it could hinder clarity. Until AI can reliably produce simple and clearly structured code (which it’s not always incentivized to do – sometimes it’s overly verbose or oddly abstract), a human touch is needed to keep things straightforward.</span></p></li></ul><p><span>In summary, </span><em>vibe coding is a powerful accelerator, but not a silver bullet.</em><span> </span></p><p><span>Use it where speed matters more than polish, and where you have the leeway to iterate and fix things. </span><strong>Avoid using it as a one-shot solution for mission-critical software</strong><span> – that’s like hiring a race car driver to drive a school bus; wrong tool for the job. Maybe one day AI will be so advanced that vibe coding truly can be the default for all development – but </span><em>today is not that day</em><span>. Today, it works best as a helper for the right problems and with the right oversight.</span></p><p><span>Vibe coding, and AI-assisted software development in general, represents a thrilling leap forward in our tools. It’s </span><strong>here to stay</strong><span>, and it will only get more sophisticated from here. Forward-looking engineering teams shouldn’t ignore it – those who harness AI effectively will likely outpace those who don’t, just as teams that embraced earlier waves of automation and better frameworks outpaced those writing everything from scratch. The message of this article is </span><em>not</em><span> to reject vibe coding, but to </span><strong>approach it with eyes open and with engineering discipline intact</strong><span>.</span></p><p><span>The big takeaway is that </span><strong>speed means nothing without quality</strong><span>. Shipping buggy, unmaintainable code faster is a false victory – you’re just speeding towards a cliff. The best engineers will balance the two: using AI to move faster </span><em>without</em><span> breaking things (at least not breaking things any more than we already do!). It’s about finding that sweet spot where AI does the heavy lifting and humans ensure everything stands up properly.</span></p><p><span>For tech leads and engineering managers, the call to action is clear: set the tone that AI is a tool to be used </span><em>responsibly</em><span>. Encourage experimentation with vibe coding, but also establish the expectations (perhaps via some of the rules we outlined) that safeguard your codebase. Make code reviews mandatory for AI-generated contributions, create an environment where asking “hey, does this make sense?” is welcome, and invest in upskilling your team to work </span><em>with</em><span> AI effectively. This might even mean training developers on how to write good prompts or how to evaluate AI suggestions critically. It’s a new skill set, akin to the shift to high-level languages or to distributed version control in the past – those who adapt sooner will reap benefits.</span></p><p>We should also keep in perspective what truly matters in software engineering: solving user problems, creating reliable systems, and continuously learning. Vibe coding is a means to an end, not an end itself. If it helps us serve users better and faster, fantastic. But if it tempts us to skip the due diligence that users ultimately rely on (like quality and security), then we must rein it in. The fundamentals – clear thinking, understanding requirements, designing for change, testing thoroughly – remain as important as ever, if not more so.</p><p><span>In the end, perhaps the ethos should be: </span><strong>“Move fast, but don’t break things – or if you do, make sure you know how to fix them.”</strong><span> Leverage the vibes to code at light speed, but back it up with the solid bedrock of engineering excellence. AI can coexist with craftsmanship; in fact, in the hands of a craftsman, it can be a powerful chisel. But the craftsman’s hand is still needed to guide that chisel to create something truly enduring and well-made.</span></p><p><span>So, vibe on, developers – just do it with care. Embrace the future, but don’t abandon the principles that got us here. </span><strong>Vibe coding is not an excuse for low-quality work</strong><span>; rather, it’s an opportunity to elevate what we can achieve </span><em>when we pair human judgment with machine generative power</em><span>. The teams that internalize this will not only move fast – they’ll build things worth keeping. </span></p><p><span>Happy coding, and keep the vibes high </span><em>and</em><span> the quality higher.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd180e6c3-45f2-45f2-8b12-af5bccbf8aa1_1890x1890.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd180e6c3-45f2-45f2-8b12-af5bccbf8aa1_1890x1890.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd180e6c3-45f2-45f2-8b12-af5bccbf8aa1_1890x1890.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd180e6c3-45f2-45f2-8b12-af5bccbf8aa1_1890x1890.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd180e6c3-45f2-45f2-8b12-af5bccbf8aa1_1890x1890.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd180e6c3-45f2-45f2-8b12-af5bccbf8aa1_1890x1890.png" width="1456" height="1456" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d180e6c3-45f2-45f2-8b12-af5bccbf8aa1_1890x1890.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1456,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:159543,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://addyo.substack.com/i/161584260?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd180e6c3-45f2-45f2-8b12-af5bccbf8aa1_1890x1890.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd180e6c3-45f2-45f2-8b12-af5bccbf8aa1_1890x1890.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd180e6c3-45f2-45f2-8b12-af5bccbf8aa1_1890x1890.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd180e6c3-45f2-45f2-8b12-af5bccbf8aa1_1890x1890.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd180e6c3-45f2-45f2-8b12-af5bccbf8aa1_1890x1890.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div></div></article></div><div id="discussion"><h4>Discussion about this post</h4></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Web Is Broken – Botnet Part 2 (241 pts)]]></title>
            <link>https://jan.wildeboer.net/2025/04/Web-is-Broken-Botnet-Part-2/</link>
            <guid>43738603</guid>
            <pubDate>Sat, 19 Apr 2025 18:59:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jan.wildeboer.net/2025/04/Web-is-Broken-Botnet-Part-2/">https://jan.wildeboer.net/2025/04/Web-is-Broken-Botnet-Part-2/</a>, See on <a href="https://news.ycombinator.com/item?id=43738603">Hacker News</a></p>
<div id="readability-page-1" class="page"><section itemprop="text">
        <p><strong>I guess you have all heard about the growing problem of AI companies trying to aggressively collect whatever data they can get their hands on to train their models. This has caused an explosive surge in web crawlers relentlessly hitting servers big and small. But who runs these crawlers? Turns out — it could be you!</strong></p>

<table>
  <tbody>
    <tr>
      <td>1.</td>
      <td><a href="https://jan.wildeboer.net/2025/02/Blocking-Stealthy-Botnets/">Those stealthy botnets</a> - How I found out about a not so new class of botnets</td>
    </tr>
    <tr>
      <td>2.</td>
      <td><a href="https://jan.wildeboer.net/2025/04/Web-is-Broken-Botnet-Part-2/">The Web is Broken</a> - <strong>Certain companies recruit app developers to create botnets by injecting “network sharing” SDKs into their apps. These botnets then use the network bandwidth of unsuspecting users of said apps to crawl the web, brute-force mail servers and other nasty things.</strong></td>
    </tr>
  </tbody>
</table>

<p>So there is a (IMHO) shady market out there that gives app developers on iOS, Android, MacOS and Windows money for including a library into their apps that sells users network bandwidth. Infatica<sup id="fnref:infaticasdk"><a href="#fn:infaticasdk" rel="footnote" role="doc-noteref">1</a></sup> is just one example, there are many more.</p>

<p>I am 99% sure that these companies cause what effectively are DDoS attacks by aggressive AI crawlers that many webmasters have to deal with since months. This business model should simply not exist. Apple, Microsoft and Google should act.</p>

<p><img src="https://jan.wildeboer.net/images/2025/04/botnet01.png" alt="Infatica explains their SDK" title="How does the monetization work?  We connect your users’ IP addresses to the Infatica peer-to-business network, which allows companies to access web data to build price aggregation platforms, perform search engine optimization, create brand protection and marketing strategies, conduct academic research, produce uptime and performance services, ensure corporate data protection, and more.">
<em>From the <a href="https://infatica.io/sdk-monetization/">Infatica SDK page</a>, explaining how app developers can make money by including the Infatica SDK</em></p>

<p>What these companies then sell to <em>their</em> customers is network access through the devices/PCs that have an app with this SDK installed<sup id="fnref:infaticasell"><a href="#fn:infaticasell" rel="footnote" role="doc-noteref">2</a></sup>. They are proud to tell you how you can funnel your (AI) web scraping etc through millions of rotating, residential and mobile IP addresses. Exactly the pattern we see hitting our servers.</p>

<p><img src="https://jan.wildeboer.net/images/2025/04/botnet02.png" alt="The offer to customers: residential IPs, Static IPs, mobile IPs etc." title="We’re offering a set of pricing plans with varying parameters including available traffic, IP address count, and other features – or you can use our flexible pricing option to fine-tune the parameters yourself.">
<em>Infatica claiming they have millions and millions of IP addresses to hand to you</em></p>

<p><img src="https://jan.wildeboer.net/images/2025/04/botnet03.png" alt="Infatica promising millions of IP addresses " title="Global Portfolio of Residential IPs Residential IP addresses make web scraping and similar activities much easier: buy proxy IPs from residential zones, your connection is safer and more anonymous.   United States 226090 IPs Russia 792251 IPs Ukraine 367600 IPs Germany 116173 IPs India 274277 IPs Poland 305109 IPs China 670301 IPs Turkey 374577 IPs Brazil 1123823 IPs Indonesia 367978 IPs Vietnam 579580 IPs Saudi Arabia 64697 IPs">
<em>What I would call “infected users” are called “residential IPs” in this specific market</em></p>

<h2 id="there-are-many">There are many</h2>

<p>Now, again, this company is just one of many selling similar services. And they all promise that they carefully check what commands their customers send to the (IMHO) infected apps on your phone and PC. Yeah, I am sure they “do no evil”. And when they do, they can claim it’s not their problem because they are merely the proxy. Again, IMHO, a shady business model.</p>

<p>Trend Micro did some research on these companies back in 2023 and it confirms my suspicions. And I guess with AI scraping this kind of business is booming.</p>

<blockquote>
  <p>„There are malicious actors who repacked freeware and shareware written by other people to conduct drive-by downloads of the Infatica peer-to-business (P2B) service“ <sup id="fnref:trendmicro"><a href="#fn:trendmicro" rel="footnote" role="doc-noteref">3</a></sup></p>
</blockquote>

<p><img src="https://jan.wildeboer.net/images/2025/04/botnet04.png" alt="Trend Micro's finding on the real use of these offerings" title="During our one month of observation, we have seen the following suspicious or malicious behaviors that Infatica proxy customers are doing via the service:  Bruteforcing of Simperium, a cross-site data synchronization service Bruteforcing of Bitwarden Scraping of house prices Scraping of Lazada and Walmart prices Creating accounts on Live.com, Instagram, and Mail.RU"></p>

<p>But IMHO (In My Humble Opinion) this also explains the explosion of bot traffic that really cripples a lot of smaller services (like my forgejo instance, that I had to make non-public).</p>

<p>So if you as an app developer include such a 3rd party SDK in your app to make some money — you are part of the problem and I think you should be held responsible for delivering malware to your users, making them botnet members.</p>

<p>Unfortunately it is next to impossible for normal users to detect the inclusion of such shady SDKs and the network traffic they cause. Not even mentioning how hard this is for admins of (small) web servers.</p>

<p>I already blogged about this <a href="https://jan.wildeboer.net/2025/02/Blocking-Stealthy-Botnets/">back in February 2025</a> but I think it is better to put what I have learned since then in this new post. I guess it won’t be my last on this topic.</p>

<h2 id="see-for-yourself">See for yourself!</h2>

<p>If you want to feel really dirty, go to <a href="https://proxyway.com/reviews?e-filter-da2a7bc-reviews_categories=proxy-providers">https://proxyway.com/reviews?e-filter-da2a7bc-reviews_categories=proxy-providers</a> for a collection of reviews on these services. It’s a huge market and I am 100% convinced that “AI” web scraping is currently the biggest “growth” driver for these companies.</p>

<p>And when I see that quite some of them rely on injecting SDKs into 3rd party apps to “extend” their “Reach” and fill their pools of “residential proxies”, I would call out these companies for distributing malware and creating botnets. But that’s just my personal opinion. I am sure they are all legit.</p>

<p><img src="https://jan.wildeboer.net/images/2025/04/botnet05.png" alt="Reviews of proxy providers" title="Page 1 of 3 of review of &quot;residential proxy providers&quot;, listing smart proxy, Oxylabs, brightdata, netnut, soax, webshare, Nimble, Infatica, Evomi, Massive, Proxyseller, Ayobyte">
<em>Page 1 of 3 with reviews of “residential proxy” providers</em></p>

<h2 id="my-conclusion">My conclusion</h2>

<p>I am now of the opinion that <em>every</em> form of web-scraping should be considered abusive behaviour and web servers should block all of them. If you think your web-scraping is acceptable behaviour, you can thank these shady companies and the “AI” hype for moving you to the bad corner.</p>

<p>Thank you for your time and interest! I hope it helps you understand why web crawlers have become a real problem and how this is more and more an attack on the foundation of the Web as it was intended to be. This “residential proxy” business is just one part of this. And we webmasters/admins can only try to block. It is getting more and more difficult to keep up with these waves. Thanks “AI”, I guess?</p>



</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Raspberry Pi Lidar Scanner (304 pts)]]></title>
            <link>https://github.com/PiLiDAR/PiLiDAR</link>
            <guid>43738561</guid>
            <pubDate>Sat, 19 Apr 2025 18:53:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/PiLiDAR/PiLiDAR">https://github.com/PiLiDAR/PiLiDAR</a>, See on <a href="https://news.ycombinator.com/item?id=43738561">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">PiLiDAR - DIY 360° 3D Panorama Scanner</h2><a id="user-content-pilidar---diy-360-3d-panorama-scanner" aria-label="Permalink: PiLiDAR - DIY 360° 3D Panorama Scanner" href="#pilidar---diy-360-3d-panorama-scanner"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto"><em>WORK IN PROGRESS</em></h2><a id="user-content-work-in-progress" aria-label="Permalink: WORK IN PROGRESS" href="#work-in-progress"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Core Features:</h2><a id="user-content-core-features" aria-label="Permalink: Core Features:" href="#core-features"></a></p>
<ul dir="auto">
<li>
<p dir="auto"><strong>LiDAR</strong>: custom serial driver for LDRobot <strong>LD06</strong>, <strong>LD19</strong> or <strong>STL27L</strong></p>
<ul dir="auto">
<li>CRC package integrity check</li>
<li><a href="https://github.com/Pioreactor/rpi_hardware_pwm">Hardware PWM</a> calibrated using curve fitting</li>
<li>2D live visualization and export (numpy or CSV)</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Panorama</strong>: 6K 360° spherical map</p>
<ul dir="auto">
<li>stitched from fisheye photos using <a href="https://hugin.sourceforge.io/" rel="nofollow"><strong>Hugin</strong> Panorama photo stitcher</a></li>
<li>constant camera exposure by reading EXIF data of automatic</li>
<li>constant white balance by iterative optimization of color gains</li>
</ul>
</li>
<li>
<p dir="auto"><strong>3D Scene</strong>: assembly of 3D scenes from 2D planes based on angle and offsets</p>
<ul dir="auto">
<li>sampling <strong>vertex colors from panorama</strong></li>
<li>Open3D visualization and export (PCD, PLY or <a href="https://github.com/davidcaron/pye57">e57</a>)</li>
<li>aligning multiple scenes using <strong>global registration</strong> and <strong>ICP fine-tuning</strong></li>
<li><strong>Poisson Surface Meshing</strong> (very slow on Pi4, recommended to run on PC)</li>
</ul>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">preliminary results</h2><a id="user-content-preliminary-results" aria-label="Permalink: preliminary results" href="#preliminary-results"></a></p>
<p dir="auto">single scans, no registration, no post processing.<br>
klick the images to open the pointclouds in Sketchfab.</p>
<p dir="auto"><a href="https://sketchfab.com/models/7997b63a3cb747f99b8f161862318bec/embed?autostart=1&amp;ui_animations=0&amp;ui_stop=0&amp;ui_inspector=0&amp;ui_watermark_link=0&amp;ui_watermark=0&amp;ui_ar=0&amp;ui_help=0&amp;ui_settings=0&amp;ui_vr=0&amp;ui_fullscreen=0&amp;ui_annotations=0" rel="nofollow"><img src="https://github.com/PiLiDAR/PiLiDAR/raw/main/images/exterior.jpeg" alt="Exterior"></a></p>
<p dir="auto"><em>Exterior Scan (colormapped Intensity)</em></p>
<p dir="auto"><a href="https://sketchfab.com/models/0311c098c57b458abe3a5d3dda9fe92b/embed?autospin=0&amp;autostart=1&amp;ui_animations=0&amp;ui_inspector=0&amp;ui_watermark_link=0&amp;ui_watermark=0&amp;ui_ar=0&amp;ui_help=0&amp;ui_settings=0&amp;ui_vr=0&amp;ui_fullscreen=0&amp;ui_annotations=0" rel="nofollow"><img src="https://github.com/PiLiDAR/PiLiDAR/raw/main/images/interior.jpeg" alt="Interior"></a></p>
<p dir="auto"><em>Interior Scan (Vertex Colors)</em></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Hardware Specs:</h2><a id="user-content-hardware-specs" aria-label="Permalink: Hardware Specs:" href="#hardware-specs"></a></p>
<ul dir="auto">
<li>
<p dir="auto">LDRobot LD06, LD19 or STL27L LiDAR</p>
</li>
<li>
<p dir="auto">Raspberry Pi HQ Camera with ArduCam M12 Lens <a href="https://www.arducam.com/doc/Arducam_M12_Lens_Kit_for_Pi_HQ_Camera.pdf" rel="nofollow">(M25156H18, p.7)</a></p>
</li>
<li>
<p dir="auto">Raspberry Pi 4</p>
</li>
<li>
<p dir="auto">NEMA17 42-23 stepper with A4988 driver</p>
</li>
<li>
<p dir="auto">Power Supply:</p>
<ul dir="auto">
<li>v1: 2x <em>18650</em> Batteries (7.2V) with step-down converter</li>
<li>v2: 10.000 mAh USB Powerbank with step-up converter</li>
</ul>
</li>
</ul>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/PiLiDAR/PiLiDAR/blob/main/images/pilidar_covershot.jpg"><img src="https://github.com/PiLiDAR/PiLiDAR/raw/main/images/pilidar_covershot.jpg" alt="PiLiDAR v1"></a>
<em>Rev. 1 using 2x 18650 Batteries and Buck Converter</em></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/PiLiDAR/PiLiDAR/blob/main/images/pilidar_covershot_v2.jpg"><img src="https://github.com/PiLiDAR/PiLiDAR/raw/main/images/pilidar_covershot_v2.jpg" alt="PiLiDAR v2"></a>
<em>Rev. 2 using 10.000 mAh Powerbank and Boost Converter</em></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">stepper driver, motor and gearbox</h3><a id="user-content-stepper-driver-motor-and-gearbox" aria-label="Permalink: stepper driver, motor and gearbox" href="#stepper-driver-motor-and-gearbox"></a></p>
<ul dir="auto">
<li>A4988 bipolar stepper driver (<a href="https://www.youtube.com/watch?v=PMS5jY7RTjo" rel="nofollow">tutorial</a>)</li>
<li>NEMA17 42x42x23 bipolar stepper (<a href="https://www.omc-stepperonline.com/e-series-nema-17-bipolar-1-8deg-17ncm-24-07oz-in-1a-42x42x23mm-4-wires-17he08-1004s" rel="nofollow">17HE08-1004S</a>, 17 Ncm torque)</li>
<li>3D-printed planetary reduction gearbox (see <a href="#fdm--3d-printing">FDM / 3D printing</a>)</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">LDRobot LiDAR Specs</h3><a id="user-content-ldrobot-lidar-specs" aria-label="Permalink: LDRobot LiDAR Specs" href="#ldrobot-lidar-specs"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/PiLiDAR/PiLiDAR/blob/main/images/lidar_comparison.jpg"><img src="https://github.com/PiLiDAR/PiLiDAR/raw/main/images/lidar_comparison.jpg" alt="LD06 vs. STL27L"></a>
<em>angular resolution of LD06 (left) vs. STL27L (right)</em></p>
<p dir="auto">LD06:</p>
<ul dir="auto">
<li>sampling frequency: 4500 Hz</li>
<li>baudrate 230400</li>
<li><a href="https://www.inno-maker.com/product/lidar-ld06/" rel="nofollow">Sales page</a></li>
<li><a href="https://www.inno-maker.com/wp-content/uploads/2020/11/LDROBOT_LD06_Datasheet.pdf" rel="nofollow">mechanical Datasheet</a></li>
<li><a href="https://storage.googleapis.com/mauser-public-images/prod_description_document/2021/315/8fcea7f5d479f4f4b71316d80b77ff45_096-6212_a.pdf" rel="nofollow">Protocol Description</a></li>
</ul>
<p dir="auto">STL27L:</p>
<ul dir="auto">
<li>sampling frequency: 21600 Hz</li>
<li>baudrate 921600</li>
<li><a href="https://github.com/May-DFRobot/DFRobot/blob/master/SEN0589_Datasheet.pdf">datasheet</a></li>
<li><a href="https://www.waveshare.com/wiki/DTOF_LIDAR_STL27L" rel="nofollow">wiki</a></li>
<li>ROS2 driver <a href="https://github.com/ldrobotSensorTeam/ldlidar_stl_ros2?tab=readme-ov-file#Instructions">git</a></li>
</ul>
<p dir="auto">Scan duration:
12s initialisation
17s shooting 4x photos
1:24m scanning 0.167° x 0.18°
37s stitching, cleanup</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">wiring</h2><a id="user-content-wiring" aria-label="Permalink: wiring" href="#wiring"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/PiLiDAR/PiLiDAR/blob/main/images/pilidar_breadboard.jpg"><img src="https://github.com/PiLiDAR/PiLiDAR/raw/main/images/pilidar_breadboard.jpg" alt="breadboard version 2"></a>
<em>Breadboard Rev. 2</em></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">LD06 / STL27L:</h3><a id="user-content-ld06--stl27l" aria-label="Permalink: LD06 / STL27L:" href="#ld06--stl27l"></a></p>
<ul dir="auto">
<li>UART Tx (yellow)</li>
<li>PWM (white)</li>
<li>GND (black)</li>
<li>VCC 5V (red)</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Raspberry Pi:</h3><a id="user-content-raspberry-pi" aria-label="Permalink: Raspberry Pi:" href="#raspberry-pi"></a></p>
<ul dir="auto">
<li>LD06 UART0 Rx: GP15</li>
<li>LD06 PWM0: GP18</li>
<li>Power Button: GP03</li>
<li>Scan Button: GP17</li>
<li>A4988 direction: GP26, step: GP19</li>
<li>A4988 microstepping mode: GP5, GP6, GP13</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Setup</h2><a id="user-content-setup" aria-label="Permalink: Setup" href="#setup"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Power Button (Wakeup &amp; Shutdown)</h3><a id="user-content-power-button-wakeup--shutdown" aria-label="Permalink: Power Button (Wakeup &amp; Shutdown)" href="#power-button-wakeup--shutdown"></a></p>
<ul dir="auto">
<li>
<p dir="auto">Wakeup is hardwired to Pin 3</p>
</li>
<li>
<p dir="auto">enable gpio-shutdown</p>
<div data-snippet-clipboard-copy-content="  echo &quot;dtoverlay=gpio-shutdown&quot; >> /boot/firmware/config.txt "><pre><code>  echo "dtoverlay=gpio-shutdown" &gt;&gt; /boot/firmware/config.txt 
</code></pre></div>
</li>
<li>
<p dir="auto">if necesessary:</p>
<div data-snippet-clipboard-copy-content="  sudo nano /etc/systemd/logind.conf
  HandlePowerKey=poweroff"><pre><code>  sudo nano /etc/systemd/logind.conf
  HandlePowerKey=poweroff
</code></pre></div>
</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">enable i2c-GPIO for GY-521 Accelerometer</h3><a id="user-content-enable-i2c-gpio-for-gy-521-accelerometer" aria-label="Permalink: enable i2c-GPIO for GY-521 Accelerometer" href="#enable-i2c-gpio-for-gy-521-accelerometer"></a></p>
<p dir="auto">GY-521 (MPU 6060): Accelerometer, Gyroscope and thermometer<br>
i2c adress: 0x68<br>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/cf7b26631a1deb5b33cb19cdac3382494d9599a97105f380cc05b0846986a4c2/68747470733a2f2f7777772e6d616b657273686f702e64652f646f776e6c6f61642f4d5055363035302d50696e6f75742e706e67"><img src="https://camo.githubusercontent.com/cf7b26631a1deb5b33cb19cdac3382494d9599a97105f380cc05b0846986a4c2/68747470733a2f2f7777772e6d616b657273686f702e64652f646f776e6c6f61642f4d5055363035302d50696e6f75742e706e67" alt="GY-521" data-canonical-src="https://www.makershop.de/download/MPU6050-Pinout.png"></a></p>
<p dir="auto">Since GPIO3 is hardwired to the Power Button, we need to use i2c-GPIO to map custom i2c pins (<a href="https://www.instructables.com/Raspberry-PI-Multiple-I2c-Devices/" rel="nofollow">tutorial</a>). Unlike serial is not getting crossed, so we connect SDA-SDA and SCL-SCL.<br>
SDA: GPIO22<br>
SCL: GPIO27</p>
<p dir="auto">disable ic2_arm and enable i2c-gpio in /boot/firmware/config.txt</p>
<div data-snippet-clipboard-copy-content="dtparam=i2c_arm=off
dtoverlay=i2c-gpio,bus=3,i2c_gpio_delay_us=1,i2c_gpio_sda=22,i2c_gpio_scl=27"><pre><code>dtparam=i2c_arm=off
dtoverlay=i2c-gpio,bus=3,i2c_gpio_delay_us=1,i2c_gpio_sda=22,i2c_gpio_scl=27
</code></pre></div>
<p dir="auto">search for devices on i2c bus 3:</p>

<p dir="auto"><h3 tabindex="-1" dir="auto">Power LED and CPU fan</h3><a id="user-content-power-led-and-cpu-fan" aria-label="Permalink: Power LED and CPU fan" href="#power-led-and-cpu-fan"></a></p>
<div data-snippet-clipboard-copy-content="# CPU fan at lower temp
echo &quot;dtoverlay=gpio-fan,gpiopin=4,temp=45000&quot; >> /boot/firmware/config.txt


# Power LED Heartbeat:
echo &quot;dtparam=pwr_led_trigger=timer&quot; >> /boot/firmware/config.txt"><pre><code># CPU fan at lower temp
echo "dtoverlay=gpio-fan,gpiopin=4,temp=45000" &gt;&gt; /boot/firmware/config.txt


# Power LED Heartbeat:
echo "dtparam=pwr_led_trigger=timer" &gt;&gt; /boot/firmware/config.txt
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Scan Button: register GPIO interrupt</h3><a id="user-content-scan-button-register-gpio-interrupt" aria-label="Permalink: Scan Button: register GPIO interrupt" href="#scan-button-register-gpio-interrupt"></a></p>
<p dir="auto">make script executable:</p>
<div data-snippet-clipboard-copy-content="chmod +x gpio_interrupt.py"><pre><code>chmod +x gpio_interrupt.py
</code></pre></div>
<p dir="auto">create new service for autostart</p>
<div data-snippet-clipboard-copy-content="sudo nano /etc/systemd/system/pilidar.service"><pre><code>sudo nano /etc/systemd/system/pilidar.service
</code></pre></div>
<p dir="auto">content:</p>
<div data-snippet-clipboard-copy-content="[Unit]
Description=PiLiDAR-Button
After=network.target

[Service]
Type=simple
User=pi
Environment=LG_WD=/tmp
ExecStart=/usr/bin/python3 /home/pi/PiLiDAR/gpio_interrupt.py
Restart=no

[Install]
WantedBy=multi-user.target"><pre><code>[Unit]
Description=PiLiDAR-Button
After=network.target

[Service]
Type=simple
User=pi
Environment=LG_WD=/tmp
ExecStart=/usr/bin/python3 /home/pi/PiLiDAR/gpio_interrupt.py
Restart=no

[Install]
WantedBy=multi-user.target
</code></pre></div>
<p dir="auto">reload daemon, enable and start service:</p>
<div data-snippet-clipboard-copy-content="sudo systemctl daemon-reload
sudo systemctl enable pilidar.service
sudo systemctl start pilidar.service"><pre><code>sudo systemctl daemon-reload
sudo systemctl enable pilidar.service
sudo systemctl start pilidar.service
</code></pre></div>
<p dir="auto">check service if necessary:</p>
<div data-snippet-clipboard-copy-content="sudo systemctl status pilidar.service"><pre><code>sudo systemctl status pilidar.service
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">set Permission for UART on Raspberry Pi</h3><a id="user-content-set-permission-for-uart-on-raspberry-pi" aria-label="Permalink: set Permission for UART on Raspberry Pi" href="#set-permission-for-uart-on-raspberry-pi"></a></p>
<p dir="auto">temporary solution:</p>
<div data-snippet-clipboard-copy-content="sudo chmod a+rw /dev/ttyS0"><pre><code>sudo chmod a+rw /dev/ttyS0
</code></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">old solution: make it permanent by disabling password for chmod:</h4><a id="user-content-old-solution-make-it-permanent-by-disabling-password-for-chmod" aria-label="Permalink: old solution: make it permanent by disabling password for chmod:" href="#old-solution-make-it-permanent-by-disabling-password-for-chmod"></a></p>
<div data-snippet-clipboard-copy-content="sudo visudo
pi ALL=(ALL:ALL) NOPASSWD: /usr/bin/chmod a+rw /dev/ttyS0"><pre><code>sudo visudo
pi ALL=(ALL:ALL) NOPASSWD: /usr/bin/chmod a+rw /dev/ttyS0
</code></pre></div>
<p dir="auto">then execute the <em>temporary</em> solution from python:</p>
<div data-snippet-clipboard-copy-content="import subprocess
command = &quot;sudo chmod a+rw /dev/ttyS0&quot;
process = subprocess.Popen(command.split(), stdout=subprocess.PIPE)
output, error = process.communicate()"><pre><code>import subprocess
command = "sudo chmod a+rw /dev/ttyS0"
process = subprocess.Popen(command.split(), stdout=subprocess.PIPE)
output, error = process.communicate()
</code></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">new solution: grant permissions to the serial port using udev rules</h4><a id="user-content-new-solution-grant-permissions-to-the-serial-port-using-udev-rules" aria-label="Permalink: new solution: grant permissions to the serial port using udev rules" href="#new-solution-grant-permissions-to-the-serial-port-using-udev-rules"></a></p>
<p dir="auto">(TODO: check and remove old!)</p>
<ul dir="auto">
<li>forget about <code>visudo</code> and the subprocess call above.</li>
<li>Open a terminal and run the following command: <code>sudo nano /etc/udev/rules.d/50-ttyS0.rules</code></li>
<li>Write the following line in the file and save it: <code>KERNEL=="ttyS0",GROUP="dialout",MODE="0660"</code></li>
<li>Run the following command to check if your user is a member of the dialout group: <code>groups</code></li>
<li>If you see <code>dialout</code> in the output, you are already a member of the group. If not, run the following command to add your user to the group: <code>sudo usermod -a -G dialout pi</code></li>
<li>Run the following command to reload the udev rules: <code>sudo udevadm control --reload-rules</code></li>
<li>Unplug and replug the serial device, or reboot the system, to apply the changes.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Hardware PWM on Raspberry Pi</h3><a id="user-content-hardware-pwm-on-raspberry-pi" aria-label="Permalink: Hardware PWM on Raspberry Pi" href="#hardware-pwm-on-raspberry-pi"></a></p>
<p dir="auto">enable GPIO_18 (PWM0) and GPIO_19 (PWM1)</p>
<div data-snippet-clipboard-copy-content="echo &quot;dtoverlay=pwm-2chan&quot; >> /boot/firmware/config.txt "><pre><code>echo "dtoverlay=pwm-2chan" &gt;&gt; /boot/firmware/config.txt 
</code></pre></div>
<p dir="auto">check if "pwm_bcm2835" now exists:</p>

<p dir="auto">Install <a href="https://github.com/Pioreactor/rpi_hardware_pwm">RPi Hardware PWM library</a>:</p>
<div data-snippet-clipboard-copy-content="pip install rpi-hardware-pwm"><pre><code>pip install rpi-hardware-pwm
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Panorama Stitching</h3><a id="user-content-panorama-stitching" aria-label="Permalink: Panorama Stitching" href="#panorama-stitching"></a></p>
<p dir="auto">install Hugin with enblend plugin</p>
<div data-snippet-clipboard-copy-content="sudo apt-get install hugin-tools enblend"><pre><code>sudo apt-get install hugin-tools enblend
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">power switching the USB port</h3><a id="user-content-power-switching-the-usb-port" aria-label="Permalink: power switching the USB port" href="#power-switching-the-usb-port"></a></p>
<p dir="auto">using <a href="https://www.baeldung.com/linux/control-usb-power-supply" rel="nofollow">uhubctl</a> cli tool. install:</p>
<div data-snippet-clipboard-copy-content="sudo apt-get install uhubctl"><pre><code>sudo apt-get install uhubctl
</code></pre></div>
<p dir="auto">list all available hubs and devices</p>

<p dir="auto">powering Raspberry Pi's USB-3-Ports (Hub 2) off / on</p>
<div data-snippet-clipboard-copy-content="sudo uhubctl -l 2 -a off
sudo uhubctl -l 2 -a on"><pre><code>sudo uhubctl -l 2 -a off
sudo uhubctl -l 2 -a on
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">jupyter over remote-ssh</h3><a id="user-content-jupyter-over-remote-ssh" aria-label="Permalink: jupyter over remote-ssh" href="#jupyter-over-remote-ssh"></a></p>
<p dir="auto">start jupyter for network access:</p>
<div data-snippet-clipboard-copy-content="jupyter notebook --ip 192.168.1.16 --no-browser PiLiDAR.ipynb"><pre><code>jupyter notebook --ip 192.168.1.16 --no-browser PiLiDAR.ipynb
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">FDM / 3D printing</h2><a id="user-content-fdm--3d-printing" aria-label="Permalink: FDM / 3D printing" href="#fdm--3d-printing"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">3D model files:</h3><a id="user-content-3d-model-files" aria-label="Permalink: 3D model files:" href="#3d-model-files"></a></p>
<ul dir="auto">
<li>
<p dir="auto">Housing and additional parts (obj and 3mf)  in <a href="https://github.com/PiLiDAR/PiLiDAR/blob/main/mechanical_design/v2/export">mechanical_design/v2/export</a>.</p>
</li>
<li>
<p dir="auto">M12 to C-Mount lens adapter (<a href="https://www.thingiverse.com/thing:4444398" rel="nofollow">thingiverse.com</a>)</p>
</li>
<li>
<p dir="auto">NEMA17 planetary reduction gearbox (<a href="https://www.printables.com/de/model/782336-nema17-planetary-gearbox-fixed" rel="nofollow">printables.com</a>)</p>
</li>
</ul>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/PiLiDAR/PiLiDAR/blob/main/images/CAD_v2.jpg"><img src="https://github.com/PiLiDAR/PiLiDAR/raw/main/images/CAD_v2.jpg" alt="CAD model"></a>
<em>Housing CAD model Rev. 2</em></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/PiLiDAR/PiLiDAR/blob/main/images/FDM.jpg"><img src="https://github.com/PiLiDAR/PiLiDAR/raw/main/images/FDM.jpg" alt="3D printing"></a>
<em>FDM printing the old front panel (Rev. 1) in PETG</em></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Serial Protocol</h2><a id="user-content-serial-protocol" aria-label="Permalink: Serial Protocol" href="#serial-protocol"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">LD06</h3><a id="user-content-ld06" aria-label="Permalink: LD06" href="#ld06"></a></p>
<p dir="auto">baudrate 230400, data bits 8, no parity, 1 stopbit<br>
sampling frequency 4500 Hz, scan frequency 5-13 Hz, distance 2cm - 12 meter, ambient light 30 kLux</p>
<p dir="auto">total package size: 48 Byte, big endian.</p>
<ul dir="auto">
<li>starting character：Length 1 Byte, fixed value 0x54, means the beginning of data packet;</li>
<li>Data Length: Length 1 Byte, the first three digits reserved, the last five digits represent the number of measured points in a packet, currently fixed value 12;</li>
<li>speed：Length 2 Byte, in degrees per second;</li>
<li>Start angle: Length: 2 Byte; unit: 0.01 degree;</li>
<li>Data: Length 36 Byte; containing 12 data points with 3 Byte each: 2 Byte distance (unit: 1 mm), 1 Byte luminance. For white objects within 6m, the typical luminance is around 200.</li>
<li>End Angle: Length: 2 Byte; unit: 0.01 degree；</li>
<li>Timestamp: Length 2 Bytes in ms, recount if reaching to MAX 30000；</li>
<li>CRC check: Length 1 Byte</li>
</ul>
<p dir="auto">The Angle value of each data point is obtained by linear interpolation of the starting angle and the ending angle.<br>
The calculation method of the angle is as following:</p>
<div data-snippet-clipboard-copy-content="step = (end_angle – start_angle)/(len – 1)  
angle = start_angle + step*i  "><pre><code>step = (end_angle – start_angle)/(len – 1)  
angle = start_angle + step*i  
</code></pre></div>
<p dir="auto">len is the length of the packet, and the i value range is [0, len].</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">remote Open3D Visualization</h2><a id="user-content-remote-open3d-visualization" aria-label="Permalink: remote Open3D Visualization" href="#remote-open3d-visualization"></a></p>
<p dir="auto">using <del><a href="https://www.open3d.org/docs/release/tutorial/visualization/web_visualizer.html" rel="nofollow"><em>Web Visualizer</em></a></del> <a href="https://plotly.com/python/" rel="nofollow">Plotly</a> to display 3D pointclouds works great in Jupyter.</p>
<p dir="auto">Plotly seems to render client-sided, unlike Open3D Web Visualizer which renders host-sided and streams jpg sequences, which strains the Pi's both CPU and WIFI.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Dumping Scans to USB Storage</h2><a id="user-content-dumping-scans-to-usb-storage" aria-label="Permalink: Dumping Scans to USB Storage" href="#dumping-scans-to-usb-storage"></a></p>
<ol dir="auto">
<li>Clone the Repo and run the installer:
<div data-snippet-clipboard-copy-content="cd /home/pi/PiLiDAR
git clone https://github.com/LaserBorg/usb_dump --depth 1
cd usb_dump &amp;&amp; chmod +x install.sh &amp;&amp; ./install.sh &quot;$(pwd)&quot;"><pre><code>cd /home/pi/PiLiDAR
git clone https://github.com/LaserBorg/usb_dump --depth 1
cd usb_dump &amp;&amp; chmod +x install.sh &amp;&amp; ./install.sh "$(pwd)"
</code></pre></div>
</li>
<li>Create the config file:
<div data-snippet-clipboard-copy-content="echo '{&quot;source_directories&quot;: [&quot;/home/pi/PiLiDAR/scans&quot;], &quot;target_root_directory&quot;: null}' > usbdump.json"><pre><code>echo '{"source_directories": ["/home/pi/PiLiDAR/scans"], "target_root_directory": null}' &gt; usbdump.json
</code></pre></div>
</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">Troubleshoot USB_dump:</h3><a id="user-content-troubleshoot-usb_dump" aria-label="Permalink: Troubleshoot USB_dump:" href="#troubleshoot-usb_dump"></a></p>
<ul dir="auto">
<li>
<p dir="auto">Check the log file:</p>

</li>
<li>
<p dir="auto">to uninstall the service, run</p>
<div data-snippet-clipboard-copy-content="chmod +x uninstall.sh &amp;&amp; ./uninstall.sh"><pre><code>chmod +x uninstall.sh &amp;&amp; ./uninstall.sh
</code></pre></div>
</li>
<li>
<p dir="auto">if the mount point is still persistend after being removed, just delete them.</p>
<div data-snippet-clipboard-copy-content="sudo rm -rf /media/pi/<your device name>"><pre><code>sudo rm -rf /media/pi/&lt;your device name&gt;
</code></pre></div>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Troubleshooting</h2><a id="user-content-troubleshooting" aria-label="Permalink: Troubleshooting" href="#troubleshooting"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Windows Serial Driver</h3><a id="user-content-windows-serial-driver" aria-label="Permalink: Windows Serial Driver" href="#windows-serial-driver"></a></p>
<p dir="auto">get <a href="https://files.waveshare.com/upload/6/63/CP210x_Universal_Windows_Driver.zip" rel="nofollow">CP210x_Universal_Windows_Driver.zip</a> here:<br>
<a href="https://www.waveshare.com/wiki/DTOF_LIDAR_STL27L#Software_Download" rel="nofollow">https://www.waveshare.com/wiki/DTOF_LIDAR_STL27L#Software_Download</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">RPi.GPIO RuntimeError: Failed to add edge detection</h3><a id="user-content-rpigpio-runtimeerror-failed-to-add-edge-detection" aria-label="Permalink: RPi.GPIO RuntimeError: Failed to add edge detection" href="#rpigpio-runtimeerror-failed-to-add-edge-detection"></a></p>
<p dir="auto">current bookworm version has deprecated sysfs GPIO interface removed.<br>
use <a href="https://pypi.org/project/rpi-lgpio/" rel="nofollow">LGPIO</a> as described <a href="https://raspberrypi.stackexchange.com/questions/147332/rpi-gpio-runtimeerror-failed-to-add-edge-detection" rel="nofollow">here</a>:</p>
<div data-snippet-clipboard-copy-content="sudo apt remove python3-rpi.gpio
sudo apt update

sudo apt install python3-rpi-lgpio

# or in an env without system packages:
pip3 install rpi-lgpio"><pre><code>sudo apt remove python3-rpi.gpio
sudo apt update

sudo apt install python3-rpi-lgpio

# or in an env without system packages:
pip3 install rpi-lgpio
</code></pre></div>
<p dir="auto">LGPIO creates temp-files (<a href="https://github.com/joan2937/lg/issues/12" data-hovercard-type="issue" data-hovercard-url="/joan2937/lg/issues/12/hovercard">issue</a>) like ".lgd-nfy0". gpio-interrupt.py executes 'export LG_WD=/tmp' to set it's CWD.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">poor performance of VS Code on Raspberry Pi</h3><a id="user-content-poor-performance-of-vs-code-on-raspberry-pi" aria-label="Permalink: poor performance of VS Code on Raspberry Pi" href="#poor-performance-of-vs-code-on-raspberry-pi"></a></p>
<p dir="auto">disable hardware acceleration for VS Code (<a href="https://code.visualstudio.com/docs/setup/raspberry-pi" rel="nofollow">source</a>)</p>
<div data-snippet-clipboard-copy-content="Preferences: Configure Runtime Arguments  
Set &quot;disable-hardware-acceleration&quot;: true"><pre><code>Preferences: Configure Runtime Arguments  
Set "disable-hardware-acceleration": true
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">pye57 on Raspberry Pi</h3><a id="user-content-pye57-on-raspberry-pi" aria-label="Permalink: pye57 on Raspberry Pi" href="#pye57-on-raspberry-pi"></a></p>
<p dir="auto">there is no wheel for arm64. build requires libxerces:</p>
<div data-snippet-clipboard-copy-content="sudo apt install libxerces-c-dev
pip install pye57"><pre><code>sudo apt install libxerces-c-dev
pip install pye57
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">add WIFI via SSH</h3><a id="user-content-add-wifi-via-ssh" aria-label="Permalink: add WIFI via SSH" href="#add-wifi-via-ssh"></a></p>
<p dir="auto"><a href="https://u-labs.de/portal/raspberry-pi-wlan-verbindung-nachtraeglich-einrichten-oder-aendern-so-geht-es-grafisch-konsole/" rel="nofollow">tutorial</a>:</p>
<div data-snippet-clipboard-copy-content="sudo nano /etc/wpa_supplicant/wpa_supplicant.conf

# make sure country code is set:
country=DE"><pre><code>sudo nano /etc/wpa_supplicant/wpa_supplicant.conf

# make sure country code is set:
country=DE
</code></pre></div>
<p dir="auto">add entry to wpa_supplicant.conf</p>
<div data-snippet-clipboard-copy-content="sudo wpa_passphrase &quot;YOUR_SSID&quot; &quot;YOUR_PASSWORD&quot; | sudo tee -a /etc/wpa_supplicant/wpa_supplicant.conf"><pre><code>sudo wpa_passphrase "YOUR_SSID" "YOUR_PASSWORD" | sudo tee -a /etc/wpa_supplicant/wpa_supplicant.conf
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">references:</h2><a id="user-content-references" aria-label="Permalink: references:" href="#references"></a></p>
<p dir="auto">inspirations</p>
<ul dir="auto">
<li><a href="https://github.com/henjin0/LIDAR_LD06_python_loder">LIDAR_LD06_python_loder</a> and <a href="https://github.com/henjin0/Lidar_LD06_for_Arduino">Lidar_LD06_for_Arduino</a> by Inoue Minoru ("<a href="https://github.com/henjin0">henjin0</a>")</li>
<li><a href="https://github.com/ShaunPrice/360-camera">ShaunPrice's</a> StereoPi-supporting fork of <a href="https://github.com/BrianBock/360-camera">BrianBock's</a> 360-camera script (Article on <a href="https://medium.com/stereopi/stitching-360-panorama-with-raspberry-pi-cm3-stereopi-and-two-fisheye-cameras-step-by-step-guide-aeca3ff35871" rel="nofollow">Medium</a>)</li>
</ul>
<p dir="auto">another Lidar implementation in Python</p>
<ul dir="auto">
<li><a href="https://github.com/Paradoxdruid/pyLIDAR">pyLIDAR</a></li>
</ul>
<p dir="auto">hardware PWM using <a href="https://gpiozero.readthedocs.io/en/stable/migrating_from_rpigpio.html#pwm-pulse-width-modulation" rel="nofollow">GPIOZero</a></p>
<p dir="auto">ICP implementations:</p>
<ul dir="auto">
<li>Aeva <a href="https://github.com/aevainc/Doppler-ICP/blob/main/README.md">Doppler-ICP</a></li>
<li>Photogrammetry &amp; Robotics Bonn <a href="https://github.com/PRBonn/kiss-icp">KISS-ICP</a> and <a href="https://github.com/PRBonn/lidar-visualizer">Lidar-Visualizer</a></li>
</ul>
<p dir="auto">3D Demo Data for global registration, ICP, meshing etc.:</p>
<ul dir="auto">
<li><a href="https://github.com/isl-org/open3d_downloads/releases/download/20220201-data/BunnyMesh.ply">BunnyMesh.ply</a> from <a href="https://github.com/isl-org/open3d_downloads/releases/tag/20220201-data">20220201-data</a></li>
<li><a href="https://github.com/isl-org/open3d_downloads/releases/download/20220301-data/DemoICPPointClouds.zip">DemoICPPointClouds.zip</a> from <a href="https://github.com/isl-org/open3d_downloads/releases/tag/20220301-data">20220301-data</a></li>
</ul>
<p dir="auto">Using a MOSFET for switching: <a href="https://elinux.org/RPi_GPIO_Interface_Circuits#Using_a_FET" rel="nofollow">tutorial</a></p>
<p dir="auto">A4988 Enable, Sleep and Reset <a href="https://www.youtube.com/watch?v=PMS5jY7RTjo" rel="nofollow">tutorial</a></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ssl.com: DCV bypass and issue fake certificates for any MX hostname (146 pts)]]></title>
            <link>https://bugzilla.mozilla.org/show_bug.cgi?id=1961406</link>
            <guid>43738485</guid>
            <pubDate>Sat, 19 Apr 2025 18:44:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1961406">https://bugzilla.mozilla.org/show_bug.cgi?id=1961406</a>, See on <a href="https://news.ycombinator.com/item?id=43738485">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="wrapper">

 


<main id="bugzilla-body" tabindex="-1">



<div id="main-inner">













<div id="module-categories">
        <p><span id="field-value-component">
      <div>
        <p><span id="component-name" tabindex="0" role="button" aria-haspopup="menu" aria-controls="component-info">CA Certificate Compliance
          
        </span></p>
      </div>
        </span>
    </p></div>






































<meta name="firefox-versions" content="{&quot;FIREFOX_AURORA&quot;:&quot;&quot;,&quot;FIREFOX_DEVEDITION&quot;:&quot;138.0b9&quot;,&quot;FIREFOX_ESR&quot;:&quot;128.9.0esr&quot;,&quot;FIREFOX_ESR115&quot;:&quot;115.22.0esr&quot;,&quot;FIREFOX_ESR_NEXT&quot;:&quot;&quot;,&quot;FIREFOX_NIGHTLY&quot;:&quot;139.0a1&quot;,&quot;LAST_MERGE_DATE&quot;:&quot;2025-03-31&quot;,&quot;LAST_RELEASE_DATE&quot;:&quot;2025-04-01&quot;,&quot;LAST_SOFTFREEZE_DATE&quot;:&quot;2025-03-27&quot;,&quot;LAST_STRINGFREEZE_DATE&quot;:&quot;2025-03-28&quot;,&quot;LATEST_FIREFOX_DEVEL_VERSION&quot;:&quot;138.0b9&quot;,&quot;LATEST_FIREFOX_OLDER_VERSION&quot;:&quot;3.6.28&quot;,&quot;LATEST_FIREFOX_RELEASED_DEVEL_VERSION&quot;:&quot;138.0b9&quot;,&quot;LATEST_FIREFOX_VERSION&quot;:&quot;137.0.2&quot;,&quot;NEXT_MERGE_DATE&quot;:&quot;2025-04-28&quot;,&quot;NEXT_RELEASE_DATE&quot;:&quot;2025-04-29&quot;,&quot;NEXT_SOFTFREEZE_DATE&quot;:&quot;2025-04-24&quot;,&quot;NEXT_STRINGFREEZE_DATE&quot;:&quot;2025-04-25&quot;}">



<div id="c0" data-comment-id="17449976"><p>User Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0</p>
<p>Steps to reproduce:</p>
<p>SSL.com failed to conduct accurate domain validation control when utilizing the BR 3.2.2.4.14 DCV method (Email to DNS TXT Contact). <strong>It incorrectly marks the hostname of the approver's email address as a verified domain</strong>, which is completely erroneous.</p>
<h2>Steps to reproduce:</h2>
<ul>
<li>Navigate to <a href="https://dcv-inspector.com/" rel="nofollow">https://dcv-inspector.com</a> and click "Start Test". You will be redirected to a URL such as <a href="https://dcv-inspector.com/test/d2b4eee07de5efcb8598f0586cbf2690" rel="nofollow">https://dcv-inspector.com/test/d2b4eee07de5efcb8598f0586cbf2690</a>.</li>
<li>Create a TXT record for the domain <code>_validation-contactemail.d2b4eee07de5efcb8598f0586cbf2690.test.dcv-inspector.com</code> with the value <code>myusername@aliyun.com</code>. Here, aliyun.com is both a cloud provider and an email provider, similar to @Yahoo.com, @Gmail.com, or @iCloud.com.</li>
<li>Visit SSL.com and request a certificate for the domain <code>d2b4eee07de5efcb8598f0586cbf2690.test.dcv-inspector.com</code>. Then, select <code>myusername@aliyun.com</code> from the email approvers list.</li>
<li>Log in to <code>myusername@aliyun.com</code>, retrieve the email that contains the DCV random value, and finalize the DCV validation process.</li>
<li>SSL.com will add the domain name of the email address (the part after the <code>@</code>. in this case, aliyun.com) to your list of verified domains.</li>
<li>To obtain certificates for aliyun.com and <a href="http://www.aliyun.com/" rel="nofollow">www.aliyun.com</a>, initiate the certificate request. SSL.com will then issue certificates for both aliyun.com and <a href="http://www.aliyun.com/" rel="nofollow">www.aliyun.com</a>.</li>
</ul>
<h2>Affected Certificates</h2>
<ul>
<li><a href="https://crt.sh/?id=17926238129" rel="nofollow">https://crt.sh/?id=17926238129</a></li>
</ul>
<p>Actual results:</p>
<p>SSL.com verified and issued aliyun.com.<br>
I'm not administrator、admin、hostmaster、postmaster、or webmaster of aliyun.com. and also, <code>_validation-contactemail</code> with the value of my email is never configured for <code>aliyun.com</code>.<br>
So,  this is wrong.</p>
<p>Expected results:</p>
<p>Don't list the email domain into verified domains.</p>
</div><div id="a1145_771641"><p>Summary: SSL.com: DCV bypass and issue certificates for any MX hostname → SSL.com: DCV bypass and issue fake certificates for any MX hostname</p></div><div id="c1"><p>SSL.com&nbsp;acknowledges this bug report and we are investigating further.</p></div><div id="c2"><p>Out of an abundance of caution, we have disabled domain validation method 3.2.2.4.14 that was used in the bug report for all SSL/TLS certificates while we investigate. We will provide a preliminary report on or before 2025-04-21.</p>
</div>



</div> 
</main> 
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Librarians Are Dangerous (375 pts)]]></title>
            <link>https://bradmontague.substack.com/p/librarians-are-dangerous</link>
            <guid>43736791</guid>
            <pubDate>Sat, 19 Apr 2025 14:49:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bradmontague.substack.com/p/librarians-are-dangerous">https://bradmontague.substack.com/p/librarians-are-dangerous</a>, See on <a href="https://news.ycombinator.com/item?id=43736791">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p>Dear Enthusiasts, </p><p><span>I write to you today as a concerned citizen.</span><br><span>Many aren’t brave enough to say it, but the time has come. So, I will say it:</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff585147d-6a94-4cdf-a583-98db4ce88992_3840x2160.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff585147d-6a94-4cdf-a583-98db4ce88992_3840x2160.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff585147d-6a94-4cdf-a583-98db4ce88992_3840x2160.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff585147d-6a94-4cdf-a583-98db4ce88992_3840x2160.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff585147d-6a94-4cdf-a583-98db4ce88992_3840x2160.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff585147d-6a94-4cdf-a583-98db4ce88992_3840x2160.png" width="1456" height="819" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f585147d-6a94-4cdf-a583-98db4ce88992_3840x2160.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:819,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:9474047,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://bradmontague.substack.com/i/160909743?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff585147d-6a94-4cdf-a583-98db4ce88992_3840x2160.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff585147d-6a94-4cdf-a583-98db4ce88992_3840x2160.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff585147d-6a94-4cdf-a583-98db4ce88992_3840x2160.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff585147d-6a94-4cdf-a583-98db4ce88992_3840x2160.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff585147d-6a94-4cdf-a583-98db4ce88992_3840x2160.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p><strong>Librarians are dangerous.</strong></p><p><em>(Dramatic music should be playing in your head right now.)</em></p><p><span>You thought they were just keepers of the quiet. Guardians of the “shhh.”</span><br><span>The ones who handed you a dusty book and pointed to a beanbag chair.</span></p><p><strong>Wrong.</strong></p><p><span>Let’s look at the facts.</span><br><span>Sure, they sit there … calmly. Quietly. With their little computers and Dewey Decimal Systems. But make no mistake …. these are </span><em>not</em><span> peaceful people.</span></p><p>Some think they’re just shelving books. No! </p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F650123a6-ab75-414e-b935-2ee8be90e5bc_3600x3600.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F650123a6-ab75-414e-b935-2ee8be90e5bc_3600x3600.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F650123a6-ab75-414e-b935-2ee8be90e5bc_3600x3600.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F650123a6-ab75-414e-b935-2ee8be90e5bc_3600x3600.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F650123a6-ab75-414e-b935-2ee8be90e5bc_3600x3600.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F650123a6-ab75-414e-b935-2ee8be90e5bc_3600x3600.png" width="1456" height="1456" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/650123a6-ab75-414e-b935-2ee8be90e5bc_3600x3600.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1456,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:16191144,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://bradmontague.substack.com/i/160909743?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F650123a6-ab75-414e-b935-2ee8be90e5bc_3600x3600.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F650123a6-ab75-414e-b935-2ee8be90e5bc_3600x3600.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F650123a6-ab75-414e-b935-2ee8be90e5bc_3600x3600.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F650123a6-ab75-414e-b935-2ee8be90e5bc_3600x3600.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F650123a6-ab75-414e-b935-2ee8be90e5bc_3600x3600.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>They’re </span><em>plotting … </em></p><p><em><strong>Plotting the overthrow of ignorance.</strong></em></p><p><span>As a kid, my idea of danger was eating Pop Rocks and Coke at the same time. At no point did I look at the librarians in my life and think, “Now </span><em>that’s</em><span> someone who could dismantle society using nothing but a hardcover and a knowing glance.”</span></p><p>But I should have.</p><p><span>Because </span><strong>librarians are dangerous</strong><span>.</span></p><p>Not in a “leap-out-of-the-shadows” kind of way. More in a “mercenaries of media literacy-knowers of where things are - masters of organized rebellion” way.</p><p><span>They can look at you and hand you a book that will COMPLETELY DESTROY YOUR WORLDVIEW… but… like… in a gentle, respectful, and </span><em>possibly laminated</em><span> way.</span></p><p><span>Let me be clear: these modern librarians are not the nostalgic memory you may have of a woman with a bun and a stamp. Today’s dangerous librarians are much more. They are </span><strong>part educator</strong><span>, </span><strong>part tech wizard, part data analyst, </strong><em><strong>and</strong></em><strong> part myth-slayer</strong><span>.</span></p><p>They can code. They can curate. They can find a book you only remember as, “blue, with a sad fox, maybe?”</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7bdc7e12-86fa-4c04-b83c-75de5f51530d_3600x3600.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7bdc7e12-86fa-4c04-b83c-75de5f51530d_3600x3600.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7bdc7e12-86fa-4c04-b83c-75de5f51530d_3600x3600.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7bdc7e12-86fa-4c04-b83c-75de5f51530d_3600x3600.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7bdc7e12-86fa-4c04-b83c-75de5f51530d_3600x3600.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7bdc7e12-86fa-4c04-b83c-75de5f51530d_3600x3600.png" width="1456" height="1456" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7bdc7e12-86fa-4c04-b83c-75de5f51530d_3600x3600.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1456,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:23061561,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://bradmontague.substack.com/i/160909743?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7bdc7e12-86fa-4c04-b83c-75de5f51530d_3600x3600.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7bdc7e12-86fa-4c04-b83c-75de5f51530d_3600x3600.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7bdc7e12-86fa-4c04-b83c-75de5f51530d_3600x3600.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7bdc7e12-86fa-4c04-b83c-75de5f51530d_3600x3600.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7bdc7e12-86fa-4c04-b83c-75de5f51530d_3600x3600.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><br><span>They host storytimes, teach kids about misinformation, explain how to 3D print a prosthetic hand, and calmly help a grown man named Todd recover his Gmail password for the seventh time. All before lunch.</span></p><p><strong>WHO DOES THAT? </strong><span>Librarians do that. </span></p><p><span>These dangerous folks believe in wild things like access. They believe in stories. They believe in </span><em>you. </em><span>They even believe in</span><em> me. </em></p><p><strong>My books wouldn’t have found nearly as many people without them.</strong><span> </span><em>WHY ARE THEY DOING THIS? What is in it for them?!?!</em></p><p><span>They believe that every student…. no matter who they are or where they’re from… deserves to find a book that says, </span><em>“You belong here.” </em><span>They give access to stories that whisper, </span><em>“You matter. You’re not alone.” </em><span>And … I mean, COME ON. This is all obviously emotional destabilization through narrative arc.</span></p><p><span>Librarians are </span><em>dangerous</em><span> and </span><em>fearless</em><span>. </span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe4c7ac60-9495-43d5-8347-088a10e401b3_3600x3600.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe4c7ac60-9495-43d5-8347-088a10e401b3_3600x3600.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe4c7ac60-9495-43d5-8347-088a10e401b3_3600x3600.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe4c7ac60-9495-43d5-8347-088a10e401b3_3600x3600.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe4c7ac60-9495-43d5-8347-088a10e401b3_3600x3600.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe4c7ac60-9495-43d5-8347-088a10e401b3_3600x3600.png" width="1456" height="1456" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/e4c7ac60-9495-43d5-8347-088a10e401b3_3600x3600.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1456,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:22997621,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://bradmontague.substack.com/i/160909743?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe4c7ac60-9495-43d5-8347-088a10e401b3_3600x3600.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe4c7ac60-9495-43d5-8347-088a10e401b3_3600x3600.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe4c7ac60-9495-43d5-8347-088a10e401b3_3600x3600.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe4c7ac60-9495-43d5-8347-088a10e401b3_3600x3600.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe4c7ac60-9495-43d5-8347-088a10e401b3_3600x3600.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Many have tried to stop them. Yet, they stare down budget cuts, criticism, rowdy teenagers, and that one weird smell in the YA section without flinching. They do their librarian things with such a gracious sort of grit that it’s terrifying.</p><p><span>And let me tell you something:</span><br><span>Do not try to debate a librarian. </span></p><p><span>You will not win.</span><br><span>You’ll walk in confident. Sure.</span><br><span>You’ll leave, though, with a tote bag and a </span><em>brand-new worldview.</em></p><p><strong>They don’t just help students find books. They help them find </strong><em><strong>themselves.</strong></em></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0379646f-5767-46ed-89a0-2c6766ad0a40_3600x3600.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0379646f-5767-46ed-89a0-2c6766ad0a40_3600x3600.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0379646f-5767-46ed-89a0-2c6766ad0a40_3600x3600.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0379646f-5767-46ed-89a0-2c6766ad0a40_3600x3600.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0379646f-5767-46ed-89a0-2c6766ad0a40_3600x3600.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0379646f-5767-46ed-89a0-2c6766ad0a40_3600x3600.png" width="383" height="383" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/0379646f-5767-46ed-89a0-2c6766ad0a40_3600x3600.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1456,&quot;width&quot;:1456,&quot;resizeWidth&quot;:383,&quot;bytes&quot;:22410237,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://bradmontague.substack.com/i/160909743?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0379646f-5767-46ed-89a0-2c6766ad0a40_3600x3600.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0379646f-5767-46ed-89a0-2c6766ad0a40_3600x3600.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0379646f-5767-46ed-89a0-2c6766ad0a40_3600x3600.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0379646f-5767-46ed-89a0-2c6766ad0a40_3600x3600.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0379646f-5767-46ed-89a0-2c6766ad0a40_3600x3600.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>So take note. This is your warning:</p><p><strong>Librarians are dangerous.</strong></p><p>They are dangerous to:</p><ul><li><p>Misinformation</p></li><li><p>Censorship</p></li><li><p>Outdated printer settings</p></li><li><p>Small thinking</p></li><li><p>apathy</p></li><li><p>loneliness</p></li><li><p>Silence where there should be a story</p></li><li><p>Anyone who underestimates a kid with a library card</p></li></ul><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d76b33d-7dd1-4c73-94d9-a7423b58bbfb_3600x3600.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d76b33d-7dd1-4c73-94d9-a7423b58bbfb_3600x3600.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d76b33d-7dd1-4c73-94d9-a7423b58bbfb_3600x3600.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d76b33d-7dd1-4c73-94d9-a7423b58bbfb_3600x3600.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d76b33d-7dd1-4c73-94d9-a7423b58bbfb_3600x3600.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d76b33d-7dd1-4c73-94d9-a7423b58bbfb_3600x3600.png" width="1456" height="1456" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/0d76b33d-7dd1-4c73-94d9-a7423b58bbfb_3600x3600.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1456,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:22042984,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://bradmontague.substack.com/i/160909743?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d76b33d-7dd1-4c73-94d9-a7423b58bbfb_3600x3600.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d76b33d-7dd1-4c73-94d9-a7423b58bbfb_3600x3600.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d76b33d-7dd1-4c73-94d9-a7423b58bbfb_3600x3600.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d76b33d-7dd1-4c73-94d9-a7423b58bbfb_3600x3600.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d76b33d-7dd1-4c73-94d9-a7423b58bbfb_3600x3600.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>They do not just guard books. They unleash them. And when a kid finds the </span><em>right</em><span> book…  the one that makes them feel seen, understood, </span><em><strong>alive</strong></em><span>... dangerous librarians know what it can do.</span></p><p><span>They are not just keepers of knowledge.</span><strong> </strong><span>They’re igniters of minds. Builders of empathy. Activists with a barcode scanner. Architects of a freer, wiser, kinder world. </span></p><p>They are the reason so many kids will grow up and realize the world is bigger, messier, and more beautiful than their textbooks ever admitted.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb907edd3-df8a-4b89-97f6-c2487017822e_3840x2160.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb907edd3-df8a-4b89-97f6-c2487017822e_3840x2160.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb907edd3-df8a-4b89-97f6-c2487017822e_3840x2160.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb907edd3-df8a-4b89-97f6-c2487017822e_3840x2160.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb907edd3-df8a-4b89-97f6-c2487017822e_3840x2160.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb907edd3-df8a-4b89-97f6-c2487017822e_3840x2160.jpeg" width="1456" height="819" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b907edd3-df8a-4b89-97f6-c2487017822e_3840x2160.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:819,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:888500,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://bradmontague.substack.com/i/160909743?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb907edd3-df8a-4b89-97f6-c2487017822e_3840x2160.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb907edd3-df8a-4b89-97f6-c2487017822e_3840x2160.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb907edd3-df8a-4b89-97f6-c2487017822e_3840x2160.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb907edd3-df8a-4b89-97f6-c2487017822e_3840x2160.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb907edd3-df8a-4b89-97f6-c2487017822e_3840x2160.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>So next time you walk past a library and think,</span><br><em>“Oh look, a quiet place for quiet people doing quiet things...”</em></p><p>Think again. I want you to remember that librarians aren’t just standing behind a desk. They stand dangerously at the frontlines of curiosity, creativity, compassion, and the fight for a better tomorrow through what we imagine today. </p><p>So go ahead. Underestimate them, but do so at your own peril.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90da3752-a2d8-4f45-89f3-d03f08c2dad2_3600x3600.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90da3752-a2d8-4f45-89f3-d03f08c2dad2_3600x3600.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90da3752-a2d8-4f45-89f3-d03f08c2dad2_3600x3600.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90da3752-a2d8-4f45-89f3-d03f08c2dad2_3600x3600.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90da3752-a2d8-4f45-89f3-d03f08c2dad2_3600x3600.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90da3752-a2d8-4f45-89f3-d03f08c2dad2_3600x3600.png" width="1456" height="1456" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/90da3752-a2d8-4f45-89f3-d03f08c2dad2_3600x3600.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1456,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:23025469,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://bradmontague.substack.com/i/160909743?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90da3752-a2d8-4f45-89f3-d03f08c2dad2_3600x3600.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90da3752-a2d8-4f45-89f3-d03f08c2dad2_3600x3600.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90da3752-a2d8-4f45-89f3-d03f08c2dad2_3600x3600.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90da3752-a2d8-4f45-89f3-d03f08c2dad2_3600x3600.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90da3752-a2d8-4f45-89f3-d03f08c2dad2_3600x3600.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><br><span>Because librarians know: The right book, in the right hands, at the right moment,</span><br><span>can change </span><strong>everything.</strong></p><p>And thank goodness for that.</p><p><span>To every librarian reading this:</span><br><strong>Stay dangerous.</strong></p><p>(Also… sorry about all the late books.)</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b64fe8c-5fc2-4587-b039-68f666dbf861_464x74.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b64fe8c-5fc2-4587-b039-68f666dbf861_464x74.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b64fe8c-5fc2-4587-b039-68f666dbf861_464x74.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b64fe8c-5fc2-4587-b039-68f666dbf861_464x74.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b64fe8c-5fc2-4587-b039-68f666dbf861_464x74.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b64fe8c-5fc2-4587-b039-68f666dbf861_464x74.png" width="232" height="37" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/2b64fe8c-5fc2-4587-b039-68f666dbf861_464x74.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:74,&quot;width&quot;:464,&quot;resizeWidth&quot;:232,&quot;bytes&quot;:20403,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://bradmontague.substack.com/i/160909743?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b64fe8c-5fc2-4587-b039-68f666dbf861_464x74.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b64fe8c-5fc2-4587-b039-68f666dbf861_464x74.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b64fe8c-5fc2-4587-b039-68f666dbf861_464x74.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b64fe8c-5fc2-4587-b039-68f666dbf861_464x74.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b64fe8c-5fc2-4587-b039-68f666dbf861_464x74.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>Last week was </span><strong>National Library Week</strong><span>! I had the privilege of speaking at the Garland County Library in Hot Springs, Arkansas, during their </span><strong>Children’s Librarian Workshop</strong><span>. Librarians and library staff from across the state gathered to share ideas and inspiration for serving young readers. Here’s a picture of me and some of their team: </span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4289d6bd-e91a-48af-acae-fdfe2690d02a_1085x815.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4289d6bd-e91a-48af-acae-fdfe2690d02a_1085x815.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4289d6bd-e91a-48af-acae-fdfe2690d02a_1085x815.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4289d6bd-e91a-48af-acae-fdfe2690d02a_1085x815.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4289d6bd-e91a-48af-acae-fdfe2690d02a_1085x815.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4289d6bd-e91a-48af-acae-fdfe2690d02a_1085x815.jpeg" width="455" height="341.7741935483871" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/4289d6bd-e91a-48af-acae-fdfe2690d02a_1085x815.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:815,&quot;width&quot;:1085,&quot;resizeWidth&quot;:455,&quot;bytes&quot;:397866,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://bradmontague.substack.com/i/160909743?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4289d6bd-e91a-48af-acae-fdfe2690d02a_1085x815.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4289d6bd-e91a-48af-acae-fdfe2690d02a_1085x815.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4289d6bd-e91a-48af-acae-fdfe2690d02a_1085x815.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4289d6bd-e91a-48af-acae-fdfe2690d02a_1085x815.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4289d6bd-e91a-48af-acae-fdfe2690d02a_1085x815.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>After several weeks of travel, this was my final stop before heading home and it was the </span><em>perfect</em><span> place to conclude refreshed and encouraged. Nothing beats being in a room full of great humans like these. So grateful for these amazing librarians who very much embody the danger I wrote about above.</span></p><p><span>ALSO! </span><em><strong>VERY</strong></em><strong> IMPORTANT </strong><em><strong>ENTHUSIAST ALERT</strong></em><strong>!</strong><span> I want to spotlight </span><strong>Beth Quarles</strong><span>, a third-grade teacher and the owner of the incredible indie bookstore </span><em><strong><a href="https://www.paperheartsbooks.com/" rel="">Paper Hearts Bookstore</a><span> </span></strong></em><span>in Little Rock, Arkansas. I signed copies of </span><em>Fail-a-Bration!, The Fantastic Bureau of Imagination, The Circles All Around Us,</em><span> and </span><em>Becoming Better Grownups</em><span> for her store. </span><strong>She still has several in stock!</strong><span> </span><strong>Go buy them out!</strong><span> </span></p><p><span>Consider supporting Beth, her team, and this wonderful shop. </span><em><strong>You can purchase signed copies from her here:</strong></em><span> </span><strong><a href="https://bookshop.org/beta-search?keywords=brad+montague" rel="">Paper Hearts Bookstore</a></strong></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc6cb3f25-0edc-41a4-9e1b-c24426583af4_2316x2232.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc6cb3f25-0edc-41a4-9e1b-c24426583af4_2316x2232.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc6cb3f25-0edc-41a4-9e1b-c24426583af4_2316x2232.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc6cb3f25-0edc-41a4-9e1b-c24426583af4_2316x2232.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc6cb3f25-0edc-41a4-9e1b-c24426583af4_2316x2232.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc6cb3f25-0edc-41a4-9e1b-c24426583af4_2316x2232.jpeg" width="360" height="346.8956043956044" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/c6cb3f25-0edc-41a4-9e1b-c24426583af4_2316x2232.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1403,&quot;width&quot;:1456,&quot;resizeWidth&quot;:360,&quot;bytes&quot;:1850108,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://bradmontague.substack.com/i/160909743?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc6cb3f25-0edc-41a4-9e1b-c24426583af4_2316x2232.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc6cb3f25-0edc-41a4-9e1b-c24426583af4_2316x2232.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc6cb3f25-0edc-41a4-9e1b-c24426583af4_2316x2232.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc6cb3f25-0edc-41a4-9e1b-c24426583af4_2316x2232.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc6cb3f25-0edc-41a4-9e1b-c24426583af4_2316x2232.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>teacher. bookseller. menace.</figcaption></figure></div><p><span>Next week, I’m back in Michigan for the </span><strong><a href="https://sc4a.org/event/curiosity-in-action/" rel="">Curiosity in Action Conference</a></strong><span>. It’s happening April 26. </span><a href="https://sc4a.org/event/curiosity-in-action/" rel=""> Some tickets still available! I’d love to see you there!</a></p><div><figure><a target="_blank" href="https://sc4a.org/event/curiosity-in-action/" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9eb5aee0-c172-4b1d-9ca8-73682bdf854e_2500x834.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9eb5aee0-c172-4b1d-9ca8-73682bdf854e_2500x834.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9eb5aee0-c172-4b1d-9ca8-73682bdf854e_2500x834.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9eb5aee0-c172-4b1d-9ca8-73682bdf854e_2500x834.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9eb5aee0-c172-4b1d-9ca8-73682bdf854e_2500x834.jpeg" width="503" height="167.89697802197801" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/9eb5aee0-c172-4b1d-9ca8-73682bdf854e_2500x834.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:486,&quot;width&quot;:1456,&quot;resizeWidth&quot;:503,&quot;bytes&quot;:351426,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:&quot;https://sc4a.org/event/curiosity-in-action/&quot;,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://bradmontague.substack.com/i/160909743?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9eb5aee0-c172-4b1d-9ca8-73682bdf854e_2500x834.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9eb5aee0-c172-4b1d-9ca8-73682bdf854e_2500x834.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9eb5aee0-c172-4b1d-9ca8-73682bdf854e_2500x834.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9eb5aee0-c172-4b1d-9ca8-73682bdf854e_2500x834.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9eb5aee0-c172-4b1d-9ca8-73682bdf854e_2500x834.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>As always, </span><strong>thank you for reading! Thanks for sharing! Thanks for supporting!</strong><span> </span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How to Write a Fast Matrix Multiplication from Scratch with Tensor Cores (2024) (103 pts)]]></title>
            <link>https://alexarmbr.github.io/2024/08/10/How-To-Write-A-Fast-Matrix-Multiplication-From-Scratch-With-Tensor-Cores.html</link>
            <guid>43736739</guid>
            <pubDate>Sat, 19 Apr 2025 14:42:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://alexarmbr.github.io/2024/08/10/How-To-Write-A-Fast-Matrix-Multiplication-From-Scratch-With-Tensor-Cores.html">https://alexarmbr.github.io/2024/08/10/How-To-Write-A-Fast-Matrix-Multiplication-From-Scratch-With-Tensor-Cores.html</a>, See on <a href="https://news.ycombinator.com/item?id=43736739">Hacker News</a></p>
<div id="readability-page-1" class="page"><div aria-label="Content">
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    
<!-- ---
layout: post
title:  "How To Write A Fast Matrix Multiplication From Scratch With NVIDIA Tensor Cores"
date:   2024-08-10 08:52:08 -0600
categories: jekyll update
--- -->




<ul id="markdown-toc">
  <li><a href="#introduction" id="markdown-toc-introduction">Introduction</a></li>
  <li>
<a href="#background" id="markdown-toc-background">Background</a>    <ul>
      <li><a href="#the-memory-wall" id="markdown-toc-the-memory-wall">The memory wall</a></li>
      <li><a href="#roofline-charts" id="markdown-toc-roofline-charts">Roofline charts</a></li>
      <li>
<a href="#rooflines-for-the-nvidia-tesla-t4" id="markdown-toc-rooflines-for-the-nvidia-tesla-t4">Rooflines for the NVIDIA Tesla T4</a>        <ul>
          <li><a href="#tensor-core-vs-ffma" id="markdown-toc-tensor-core-vs-ffma">Tensor Core vs. FFMA</a></li>
          <li><a href="#shared-memory-vs-l2-cache-vs-global-memory" id="markdown-toc-shared-memory-vs-l2-cache-vs-global-memory">Shared memory vs. L2 cache vs. global memory</a></li>
        </ul>
      </li>
      <li>
<a href="#theoretical-arithmetic-intensity" id="markdown-toc-theoretical-arithmetic-intensity">Theoretical arithmetic intensity</a>        <ul>
          <li><a href="#matrix-multiplication-vs-matrix-addition" id="markdown-toc-matrix-multiplication-vs-matrix-addition">Matrix Multiplication vs Matrix Addition</a></li>
        </ul>
      </li>
      <li>
<a href="#achievable-arithmetic-intensity-on-a-simple-computer" id="markdown-toc-achievable-arithmetic-intensity-on-a-simple-computer">Achievable arithmetic intensity on a simple computer</a>        <ul>
          <li><a href="#worst-case" id="markdown-toc-worst-case">worst case</a></li>
          <li><a href="#best-case" id="markdown-toc-best-case">best case</a></li>
          <li><a href="#realistic-case" id="markdown-toc-realistic-case">realistic case</a></li>
          <li><a href="#in-summary" id="markdown-toc-in-summary">In Summary</a></li>
        </ul>
      </li>
      <li>
<a href="#parallelized-matrix-multiplication-on-a-gpu" id="markdown-toc-parallelized-matrix-multiplication-on-a-gpu">Parallelized matrix multiplication on a GPU</a>        <ul>
          <li><a href="#hierarchical-tiling-simple-gpu" id="markdown-toc-hierarchical-tiling-simple-gpu">Hierarchical Tiling (simple gpu)</a></li>
          <li><a href="#hierarchical-tiling-real-gpu" id="markdown-toc-hierarchical-tiling-real-gpu">Hierarchical Tiling (real gpu)</a></li>
          <li>
<a href="#performance-considerations-on-a-real-gpu" id="markdown-toc-performance-considerations-on-a-real-gpu">Performance considerations on a real GPU</a>            <ul>
              <li><a href="#arithmetic-intensity-as-a-function-of-tile-dimensions" id="markdown-toc-arithmetic-intensity-as-a-function-of-tile-dimensions">Arithmetic intensity as a function of tile dimensions</a></li>
              <li><a href="#overlap-between-compute-and-data-movement" id="markdown-toc-overlap-between-compute-and-data-movement">Overlap between compute and data movement</a></li>
              <li><a href="#maximizing-memory-bandwidth" id="markdown-toc-maximizing-memory-bandwidth">Maximizing memory bandwidth</a></li>
            </ul>
          </li>
          <li><a href="#how-to-use-tensor-cores" id="markdown-toc-how-to-use-tensor-cores">How to use Tensor Cores</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
<a href="#kernels" id="markdown-toc-kernels">Kernels</a>    <ul>
      <li><a href="#kernel-1---hierarchical-tiling" id="markdown-toc-kernel-1---hierarchical-tiling">Kernel 1 - Hierarchical Tiling</a></li>
      <li><a href="#kernel-2---vectorized-memory-copy-and-loop-unrolling" id="markdown-toc-kernel-2---vectorized-memory-copy-and-loop-unrolling">Kernel 2 - Vectorized memory copy and loop unrolling</a></li>
      <li>
<a href="#kernel-3---shared-memory-swizzling" id="markdown-toc-kernel-3---shared-memory-swizzling">Kernel 3 - Shared Memory Swizzling</a>        <ul>
          <li><a href="#background-bank-conflicts-and-wavefronts" id="markdown-toc-background-bank-conflicts-and-wavefronts">Background: Bank Conflicts and Wavefronts</a></li>
          <li><a href="#ldmatrix-bank-conflicts" id="markdown-toc-ldmatrix-bank-conflicts">ldmatrix bank conflicts</a></li>
          <li><a href="#padding" id="markdown-toc-padding">Padding</a></li>
          <li><a href="#swizzling-toy-example" id="markdown-toc-swizzling-toy-example">Swizzling (toy example)</a></li>
          <li><a href="#swizzling-real-world" id="markdown-toc-swizzling-real-world">Swizzling (real world)</a></li>
        </ul>
      </li>
      <li>
<a href="#kernel-4---makeshift-async-copy" id="markdown-toc-kernel-4---makeshift-async-copy">Kernel 4 - Makeshift Async Copy</a>        <ul>
          <li><a href="#gpu-occupancy-digression" id="markdown-toc-gpu-occupancy-digression">GPU occupancy (digression)</a></li>
        </ul>
      </li>
      <li>
<a href="#kernel-5---tune-tile-dimensions" id="markdown-toc-kernel-5---tune-tile-dimensions">Kernel 5 - Tune Tile Dimensions</a>        <ul>
          <li>
<a href="#tune-tile-dimensions" id="markdown-toc-tune-tile-dimensions">tune tile dimensions</a>            <ul>
              <li><a href="#m-and-n-dimensions--l2-cache-locality" id="markdown-toc-m-and-n-dimensions--l2-cache-locality">M and N Dimensions / L2 cache locality</a></li>
              <li><a href="#k-dimension" id="markdown-toc-k-dimension">K Dimension</a></li>
            </ul>
          </li>
          <li><a href="#tile-dimensions---longer-and-thinner" id="markdown-toc-tile-dimensions---longer-and-thinner">tile dimensions - longer and thinner</a></li>
        </ul>
      </li>
      <li><a href="#kernel-5---optimize-index-calculation" id="markdown-toc-kernel-5---optimize-index-calculation">Kernel 5 - Optimize Index Calculation</a></li>
      <li><a href="#kernel-6---double-buffering" id="markdown-toc-kernel-6---double-buffering">Kernel 6 - Double Buffering</a></li>
    </ul>
  </li>
  <li>
<a href="#conclusion" id="markdown-toc-conclusion">Conclusion</a>    <ul>
      <li><a href="#things-i-didnt-do" id="markdown-toc-things-i-didnt-do">things I didn’t do</a></li>
      <li><a href="#performance-on-different-matrix-sizes" id="markdown-toc-performance-on-different-matrix-sizes">performance on different matrix sizes</a></li>
      <li><a href="#lessons-learned-newer-gpus-are-better" id="markdown-toc-lessons-learned-newer-gpus-are-better">lessons learned, newer GPUs are better</a></li>
    </ul>
  </li>
  <li><a href="#resources--acknowledgements" id="markdown-toc-resources--acknowledgements">Resources / Acknowledgements</a></li>
  <li><a href="#are-you-hiring-gpu-nerds" id="markdown-toc-are-you-hiring-gpu-nerds">Are you hiring GPU nerds?</a></li>
</ul>

<h2 id="introduction">Introduction</h2>
<p>This post details my recent efforts to write an optimized matrix multiplication kernel in CUDA using tensor cores on a NVIDIA Tesla T4 GPU. The goal is to compute $D = \alpha * A * B + \beta * C$, as fast as possible. In this equation $D,A,B$ and $C$ are large matrices full of half precision floating point numbers, and $\alpha$, $\beta$ are constants. This problem is usually referred to as a <strong>H</strong>alf-precision <strong>Ge</strong>neralized <strong>M</strong>atrix <strong>M</strong>ultiply, or <strong>HGEMM</strong> for short.</p>

<p>Tensor Cores are specialized hardware units on NVIDIA chips that implement a small matrix multiplication in hardware. I recently became interested in tensor cores for two reasons. First, it seems like <a href="https://www.semianalysis.com/i/136469751/the-gpu-rich">most</a> generative AI training and inference these days happens on A100s and H100s. Second, all of this training and inference is almost certainly running on the tensor cores of these devices, because they offer a massive throughput increase for matrix math as compared to what you get if you dont use them. From <a href="https://hazyresearch.stanford.edu/blog/2024-05-12-tk">here</a></p>
<blockquote>
  <p>An H100 GPU has 989 TFLOPs of half-precision matrix multiply compute, and ~60 TFLOPs of “everything else”. So, every cycle the tensor core is in use, you’re getting at least 94% utilization of the hardware. And every cycle the tensor core is not in use, you’re getting no more than 6% utilization of the hardware.</p>
</blockquote>

<p>Given their huge importance in the world today, when I started this project it felt to me like there is disproportionately little info and dialogue on the internet about how to use them directly. I quickly learned this lack of dialogue on the internet is probably because writing algorithms that use them is a bit of a niche interest. The basic mechanics of how to call them are not hard, however writing a kernel that can use them at anywhere close their full potential <em>is</em> hard. Their huge throughput means that in order to use them at anywhere close to their full potential, you need to move bytes though the memory hierarchy of the GPU in a maximally efficient way, and overlap the computing with this data movement. There are certain algorithmic techniques that you need to use if you want get your moneys worth from your tensor cores, this article is an exploration of these techniques.</p>

<p>I figured out the implementation details mostly by digging around the NVIDIA <a href="https://github.com/NVIDIA/cutlass/tree/main">CUTLASS</a> forums and source, and I wrote this article in order to make sure I actually understand what I am doing, and also in the hope that some fellow GPU nerds trying to work with tensor cores might find it helpful. It should be noted that this whole project was done on a Turing architecture GPU, which was state of the art in 2018, and some details of some of the optimizations discussed in this article are somewhat specific to the Turing architecture. I noticed while working on this is that the more modern Hopper architecture has dedicated hardware support that directly addresses some of the performance issues and bottlenecks that I ran into along the way when working on optimizations that target an older GPU. More modern GPUs justify their increased price tag not only with increased floating point throughput, but also with features that ease the cognitive burden on programmers who are trying to optimize kernels for them.</p>

<p>When I started my goal was to write a kernel with comparable performance to the cuBLAS <a href="https://docs.nvidia.com/cuda/cublas/#cublas-level-3-function-reference">hgemm</a> implementation, which is the closed-source, gold standard implementation released by NVIDIA. I iteratively optimized a series of 6 kernels, with the <a href="https://github.com/alexarmbr/matmul-playground/blob/main/src/kernel1.cu">first</a> achieving a measly 8% of the cuBLAS throughput, and the <a href="https://github.com/alexarmbr/matmul-playground/blob/main/src/kernel6.cu">last</a> achieving a decent 96% of the cuBLAS throughput for 8192x8192 matrices.</p>

<p>This article contains a background section that explains some theory that is helpful to have in your head when thinking about how to optimize kernels that operate on matrices. The rest of the article explains six algorithmic techniques that I used to make my kernel run as fast as possible. Code can be found <a href="https://github.com/alexarmbr/matmul-playground">here</a> on github.</p>

<p>Here is a table with the performance comparison of all of the kernels:
<img src="https://alexarmbr.github.io/images/table6.png" alt="table6"></p>

<h2 id="background">Background</h2>
<h2 id="the-memory-wall">The memory wall</h2>

<p>In the 70 or so years it has been since humanity started building transistor based computers, the capacity for performing arithmetic has been growing along the moores law exponential, while the capacity for moving data from where it is stored to where it is computed upon has not been growing exponentially. This problem is called the <a href="https://en.wikipedia.org/wiki/Random-access_memory#Memory_wall">memory wall</a> and it is one of the central problems in computer architecture today, <a href="https://horace.io/brrr_intro.html">especially</a> when it comes to deep learning workloads, and especially especially when it comes to tensor core algorithms. What this means for us is that if we want to be able to use the ~65 trillion FLOPs per second that our tensor cores are capable of, moving the corresponding number of bytes per second from DRAM may be a challenge.</p>

<h2 id="roofline-charts">Roofline charts</h2>
<p>The <a href="https://en.wikipedia.org/wiki/Roofline_model">roofline</a> model allows us to think about this conundrum a bit more precisely. The basic idea is that we imagine a simplified computer with a two level memory hierarchy, fast memory and slow memory. We can only perform computation on data that is resident in fast memory, at a peak rate of $\tau$ FLOP/sec. The slow memory has unlimited size, and it can move $\beta$ bytes/sec of data into the fast memory. Because of the memory wall, $\tau$ is way larger than $\beta$.</p>

<p><img src="https://alexarmbr.github.io/images/simple_computer.png" alt="simple_computer"></p>

<p>Any given computation has a certain number of FLOPs that need to be performed, for example to multiply a $M$ by $K$ matrix with a $K$ by $N$ matrix we need to perform $2 * M * N * K$ FLOPs. The more FLOP/sec our algorithm can achieve, the faster we can get the matrix multiplication done. The roofline model gives us an upper bound on the FLOP/sec we can achieve, subject to $\tau$ and $\beta$ which are fixed properties of our hardware. We will refer to achieved FLOP/sec as $T$ for throughput, and the upper bound on T as $T_{max}$.</p>

<p>The maximum FLOP/sec we can achieve ($T_{max}$) is modeled as a function of a variable called <em>computational intensity</em> or $I$ for short, this is a property of the algorithm we write. This metric measures the “data reuse” of our algorithm in units of FLOP/byte: for each byte moved from slow memory to fast memory, how many FLOPs do we perform on it. According to the roofline model, if you are an algorithm designer, your primary concern is to write an algorithm with high computational intensity, or in other words to maximize $I$. In practice, this means moving a chunk of data from slow memory to fast memory, and then performing as many useful operations on it as allowed by whatever algorithm you are writing. Reusing data in fast memory is important for performance, because our memory bandwidth $\beta$ limited; it is a small number compared to $\tau$, which means the transfer of this chunk of data from slow to fast memory is costly. We make the most of it by performing as many useful FLOPs as possible on it.</p>

<p>The roofline model says the upper bound on FLOP/sec ($T_{max}$) we can achieve is the minimum of our computational intensity times memory bandwidth, and the peak floating point throughput of our hardware.</p><p>

\[T_{max}=min(\beta * I, \tau)\]

</p><p>This model is saying there are two ways $T_{max}$ can be limited:</p>
<ul>
  <li>$T_{max}$ can never exceed $\tau$. Even if we perform infinity operations on each byte we move into fast memory, we are still limited by the peak floating point throughput of the hardware. $\tau$ is typically a very big number, for example for the T4 GPU, $\tau$ equals 65,000,000,000,000 FLOP/second. If $\tau$ is our limiting factor, we are in good shape, this scenario is referred to as being <em>compute bound</em>.</li>
  <li>However, $T_{max}$ may also be limited by the memory bandwidth of the device, times the computational intensity of the algorithm. If $\tau$ were infinite, the achieved floating point throughput would simply be the number of bytes/sec being moved into fast memory, times the number of FLOPs performed per byte moved, this is $\beta * I$ (notice how when you multiply $\beta * I$, the units cancel out to give FLOP/sec). If $\beta * I$ is less than $\tau$, this term becomes the limiting factor on $T_{max}$, this scenario is referred to as being <em>memory bound</em>. The thing to do in this situation is to rewrite your algorithm to increase $I$ in the hopes of your algorithm becoming compute bound.</li>
</ul>

<p>Here is the whole thing in a picture, notice how we can go from being memory bound to being compute bound by varying $I$:
<img src="https://alexarmbr.github.io/images/roofline.png" alt="roofline"></p>

<p>The red dotted line in this picture is referred to as the “balance point” of the hardware, it is the level of arithmetic intensity in units of (FLOP/byte) that we need to surpass in order to go from being memory bound to being compute bound. If we call this value $I^* $, then $I^* * \beta=\tau$ or equivalently $I^*=\frac{\tau}{\beta}$. It is a property of a particular computer, the peak floating point throughput, divided by the memory bandwidth. Because of Moore’s law, arithmetic throughput has been improving much faster than memory bandwidth, the consequence of this is that generally speaking, the newer the computer, the higher the balance point.</p>

<h2 id="rooflines-for-the-nvidia-tesla-t4">Rooflines for the NVIDIA Tesla T4</h2>
<p>Plugging in some numbers specific to the GPU we are using, and looking at the resulting roofline can inform our algorithm design, and give us some perspective on what we are in for. On a real computer, there isn’t just a single $\tau$ and $\beta$, there are multiple hardware instructions, each with a different peak throughput $\tau$, and different types of memory, each with a different bandwidth $\beta$.</p>

<h3 id="tensor-core-vs-ffma">Tensor Core vs. FFMA</h3>
<p>I found it helpful first to compare the balance point of the tensor cores with the balance point for the regular single precision math units, both with respect to global memory. This rooflines provides some intuition about why writing an efficient kernel is more challenging if you are using tensor core instructions, as opposed to the more standard, less specialized math instructions.</p>

<p>First, we need to know the global memory bandwidth $\beta_{gmem}$ of our device. NVIDIA spec sheets report <em>theoretical</em> memory bandwidth, which is <a href="https://forums.developer.nvidia.com/t/theoretical-bandwidth-vs-effective-bandwidth/48005/3?u=a14armbr">never</a> achievable in practice. The real number can be found with a benchmark, according to <a href="https://arxiv.org/pdf/1903.07486">this</a> whitepaper the achievable memory bandwidth of the T4 is 220 GB/sec (this is 68% of the 320 GB/sec theoretical memory bandwidth).</p>

<p>Next, we need to know the peak floating point throughput with the tensor core, and the peak floating point throughput without it. Similarly to memory, the theoretical numbers are <a href="https://www.thonking.ai/p/strangely-matrix-multiplications">not actually achievable</a> without the GPU catching fire or melting. I find it reasonable to use the measured throughput of the cuBLAS half precision (uses tensor cores) and single precision (doesn’t use tensor cores) GEMM kernels as the achievable floating point throughput numbers. Looking at the assembly of the cuBLAS half precision kernel we can see that the grunt work is done by <code>HMMA.1688</code>, this instruction performs a single small hardware accelerated matmul (more on this later). For the single precision GEMM kernel, the instruction that does the work is called <code>FFMA</code>, this is a scalar multiply/accumulate operation, $d=a*b+c$. According to my benchmarks, the tensor core HMMA.1688 throughput is 49439 GFLOP/sec, which we will call $\tau_{HMMA}$. The non-tensor core FFMA throughput is 7455 GFLOP/sec, which we will call $\tau_{FFMA}$. These are respectively 76% and 92% of the theoretical peak throughputs, which seems reasonable enough. The resulting rooflines look like this (these plots are typically shown on a log/log scale, this one is not):</p>

<p><img src="https://alexarmbr.github.io/images/t4_roofline.png" alt="t4_roofline"></p>

<p>This plot should give us some intuition about the comparative hardness of writing a kernel that achieves peak FLOP/sec with tensor core instructions vs. writing a kernel that achieves peak FLOP/sec with fused multiply add instructions. The hardness comes from the fact that if we want to reach a throughput of $\tau_{HMMA}$, we need ~6.6x more arithmetic intensity than we need if our goal is to reach $\tau_{FFMA}$. The two balance points in this plot tell us that with FFMA instructions we can perform ~33 FLOPs in the time it takes a byte to travel from global memory, whereas with tensor cores we can perform 224 FLOPs in this same amount of time. This means that if we took a kernel that reached peak flops achievable with FFMA instructions, simply replacing the fused multiply adds in the inner loop with tensor core instructions would <em>not</em> be sufficient to get high tensor core utilization. We would additionally need to improve the code that moves data around to increase the computational intensity by a factor of six. This is one of the things that makes writing a tensor core GEMM interesting!</p>

<h3 id="shared-memory-vs-l2-cache-vs-global-memory">Shared memory vs. L2 cache vs. global memory</h3>
<p>If we want to write a kernel that can make good use of the tensor cores, we need to be conscious of our computers memory hierarchy. The roofline model simplifies the memory hierarchy down to two storage types, one large and slow, and the other fast and instantaneous. In reality, there are more than two levels, each level has different a bandwidth and capacity, and also different considerations that must be considered in order to facilitate efficient access.</p>

<p><img src="https://alexarmbr.github.io/images/t4_memory_hierarchy.png" alt="t4_memory_hierarchy"></p>

<p>In these days of the memory wall, using the faster and smaller levels of the memory hierarchy effectively is critical. This requires some ingenuity because of the smallness: for example on the T4 the on chip shared memory has 16.6x the bandwidth of global memory, but on a given streaming multiprocessor (SM for short) it only fits 64 KiB. If we are multiplying large matrices, this is only enough space to fit a tiny portion of the problem.</p>

<p><img src="https://alexarmbr.github.io/images/t4_memory_roofline.png" alt="t4_memory_roofline"></p>

<p>The plot compares the balance point of tensor cores with respect to:</p>
<ul>
  <li>global memory or DRAM, the largest and slowest level of the memory hierarchy</li>
  <li>the L2 cache which stores recently accessed data from DRAM, and is shared between the 16 SMs on the T4</li>
  <li>shared memory, per SM fast memory that is explicitly managed.</li>
</ul>

<p>Global memory has a balance point of 224, this means that if all of our memory accesses go to DRAM, we will need to perform 224 FLOPs for each byte read from DRAM in order to keep our tensor cores busy. This turns out to be a very tall order, as we will see later when we work out how parameters in our algorithm affect the balance point (the sneak preview is that given the amount of fast memory on the T4 and some other performance considerations, achieving this balance point would be counterproductive). However, the L2 cache comes to the rescue, its balance point with respect to tensor cores is 38, which is a much more manageable number. If a good number of our memory accesses can hit the L2 cache rather than going all the way to global memory, we will have a good shot at being compute bound rather than memory bound. The moral of this story is that we need the L2 cache.</p>

<p>Shared memory is used as an explicitly managed cache that will hold small portions of the input matrices local to a particular SM (a SM is kind of analogous to a single CPU core). Within the SM, threads will load their own local portion of the problem from shared memory into register memory, which is where data must reside in order for it to be computed upon. When shared memory is operating at full bandwidth, its balance point with respect to the tensor core is 13, which means we need to cache enough data in registers to perform 13 FLOPs for each byte read from shared memory. It turns out that each SM has enough register memory to make this easily achievable. When we are optimizing this part of the algorithm, the challenge will be to enable shared memory to operate at full bandwidth, which in practice means organizing the data layout in such a way that we can read it and write it without bank conflicts. Once shared memory is at full bandwidth, sufficient arithmetic intensity will be easy to achieve. I think the shared memory balance point of 13 is worth noting though, because it tells us that shared memory alone is not fast enough to achieve peak tensor core throughput. The moral of this story is that we need registers.</p>

<h2 id="theoretical-arithmetic-intensity">Theoretical arithmetic intensity</h2>
<p>So modern computers generally have an imbalance between their arithmetic throughput and their memory bandwidth, consequently kernels that perform lots of arithmetic relative to data movement make better use of the hardware. At this point we need to think about the algorithm we are running, and forget about hardware for a moment.</p>

<h3 id="matrix-multiplication-vs-matrix-addition">Matrix Multiplication vs Matrix Addition</h3>

<p>Any given algorithm has a maximum amount of arithmetic intensity that is possible, and our goal as an algorithm designer is to write a kernel that achieves an arithmetic intensity as close to this upper bound as we can manage. Comparing the maximum arithmetic intensity that is achievable when adding two $N$ by $N$ matrices, vs. multiplying them, illustrates how different algorithms have different upper bounds in this regard.</p>

<p><img src="https://alexarmbr.github.io/images/multiplication_vs_addition.png" alt="multiplication_vs_addition"></p>

<p>In the case of matrix addition, computing a single output element requires a single arithmetic operation, which means that when we run this algorithm the amount of data movement and compute will always be directly proportional. If we are adding two $N$x$N$ matrices, the amount of data involved is $O(N^2)$, and the amount of compute required is also $O(N^2)$. So the ratio of compute to data is $\frac{O(N^2)}{O(N^2)}=O(1)$, which means matrix addition will probably be memory bound on any modern device, regardless of how clever an algorithm we write. Relative to the amount of data movement, there just isn’t that much math required, so the upper bound on achievable arithmetic intensity is low. Lots of operations in deep learning fall into this low arithmetic intensity category, a technique called kernel fusion can be helpful here.</p>

<p>Matrix multiplication however is not doomed to be memory bound, because there is more arithmetic required relative to the problem size. When multiplying two $N$ by $N$ matrices, the amount of data involved is also $O(N^2)$, but the amount of compute required is $O(N^3)$ ($O(N)$ operations per output element, times $O(N^2)$ output elements). So the ratio of compute to data is $\frac{O(N^3)}{O(N^2)}=O(N)$. There is a factor of $N$ more compute required than data movement. The upper bound on the arithmetic intensity we can achieve grows with the matrix dimension $N$. If we are multiplying sufficiently large matrices, we should be able to write an algorithm that has sufficient arithmetic intensity to be compute bound rather than memory bound.</p>

<p>So in summary the arithmetic intensity we achieve depends on the kernel we write, and it must be less than or equal to an upper bound imposed by the algorithm our kernel is implementing. Achieved arithmetic intensity, given our machine parameters $\tau$ and $\beta$ determines whether we are memory bound or compute bound. If our algorithms upper bound on arithmetic intensity allows it, we want to optimize our kernel until it is compute bound rather than memory bound.</p>

<h2 id="achievable-arithmetic-intensity-on-a-simple-computer">Achievable arithmetic intensity on a simple computer</h2>
<p>For multiplying two $N$ by $N$ matrices, the best possible arithmetic intensity we can achieve is $O(N)$. Now the question is, how do we think about all of this when it comes time to actually write a kernel? To get at this question we need a model of the computer we are running on, to start out we will use the simple computer with fast and slow memory.</p>

<h3 id="worst-case">worst case</h3>
<p>The first implementation of multiplication between two N x N matrices ($C=A*B$) on the simple computer looks like this. We load each value as soon as we need it, and store each output as soon as we are done with it. What is the ratio of compute to data movement? Is it close to the ideal of $O(N)$?</p>
<div><pre><code>allocate registers a,b,c in fast memory
for i=1...N:
    for j=1...N:
        c = 0
        for k=1...N:
            load A(i,k) into a
            load B(k,j) into b
            c += a * b
        store c into C(i,j) 

</code></pre></div>
<p>My mental model of this implementation looks something like this
<img src="https://alexarmbr.github.io/images/simple_computer_matmul_naive.png" alt="simple_computer_matmul_naive"></p>

<p>This arithmetic intensity of this implementation on the simple computer is $O(1)$, because on each iteration of the inner loop a single multiply/accumulate is performed, and only the data operated on during that iteration is loaded. There is $O(N^3)$ data movement, and $O(N^3)$ compute, which means $\frac{O(N^3)}{O(N^3)}=O(1)$ intensity, which is worse than the ideal by a factor of $O(N)$. This turns out to be the worst case.</p>

<h3 id="best-case">best case</h3>
<p>The poor intensity of the above implementation is the result of the fact that we load single elements from fast memory one at a time, only when they are needed. Only three matrix elements at a time are stored in fast memory. We can improve intensity by making better use of fast memory. To illustrate the best case scenario, imagine that fast memory was large enough to fit $A,B$ and $C$ in their entirety. If this were the case we could allocate space in fast memory for $C$, transfer the entire $A$ and $B$ upfront, perform the three nested loops with all the data already present in fast memory, and then once we are done store the entire $C$ matrix all at once back to slow memory.
<img src="https://alexarmbr.github.io/images/simple_computer_matmul_best_case.png" alt="simple_computer_matmul_best_case">
In this case, because we move each matrix only once, data movement is $O(N^2)$. Compute is the same as above, $O(N^3)$. Looking at the ratio of the two, we achieve the best case intensity, $\frac{O(N^3)}{O(N^2)}=O(N)$. However, this is unrealistic, because the entire problem will generally not fit in fast memory.</p>

<h3 id="realistic-case">realistic case</h3>
<p>We want to move more than three elements at a time between slow memory and fast memory. But we can’t move the full matrices all at once. We can compromise by moving subtiles of $A$ and $B$ from slow memory to fast memory (as large as we can fit). Each pair of input tiles we move to fast memory corresponds to a tile of the output which can be computed with a mini matrix multiplication between the input tiles we have resident in fast memory. We then move the next pair of input tiles to fast memory and then compute again.</p>

<p><img src="https://alexarmbr.github.io/images/simple_computer_matmul_realistic_case.png" alt="simple_computer_matmul_realistic_case"></p>

<p>Here is some pseudocode corresponding to the above diagram:</p>
<div><pre><code>Allocate A_tile[BN, BN], B_tile[BN,BN], C_tile[BN,BN] in fast memory

# outer loop over tiles of A and B
for i=1...N in steps of size BN:
    for j=1...N in steps of size BN:
        C_tile[: , :] = 0
        for k=1...N in steps of size BN:
            Load A[i : i+BN, k : k+BN] into A_tile
            Load B[k : k+BN, j : j+BN] into B_tile
            
            # inner loop, do a mini matmul between tiles of A and B
            # store the result in C_tile
            for tile_i=1...BN:
                for tile_j=1...BN:
                    for tile_k=1...BN:
                        C_tile[tile_i, tile_j] +=
                            A_tile[tile_i, tile_k] * B_tile[tile_k, tile_j]
            
        # once we have looped over all the tiles along the K dimension of A,B
        # store C_tile back to its place in slow memory
        Store C_tile into C[i : i + BN, j : j+BN]

</code></pre></div>
<p>What is the ratio of compute to data movement? How does it compare to the worst cast and the best case? We can answer these questions by looking at the loop structure.</p>

<p>Lets think about data movement first. There are three nested loops on the outside, each of which go from $1$ to $N$ in $BN$ sized steps. Each loop iterates $\frac{N}{BN}$ times, and since we have three levels of nesting, whatever is inside the nested loop body will happen $(\frac{N}{BN})^3$ times. Inside the loop nest, we load two tiles of size $BN^2$, one corresponding to each of the input matrices. Asymptotically this works out to $O((\frac{N}{BN})^3 * BN^2)$ data movement (we can ignore the storing of the <code>C_tile</code>, since this is only inside two of the loop nests, it only happens $\frac{N}{BN}^2$ times). Cancelling things out gives us $O(\frac{N^3}{BN})$ data movement. Notice that this a factor of $BN$ less data movement than the naive case.</p>

<p>Now compute. Same as above, we have three nested loops, the inside of this loop body will execute $(\frac{N}{BN})^3$ times. Inside the loop nests, the compute consists of the mini matmul between two $BN$ by $BN$ tiles, the three nested loops have a total of $O(BN^3)$ steps what is what we expect for multiplying together two $BN$ by $BN$ matrices. So the total amount of compute is $O((\frac{N}{BN})^3 * BN^3)$ which simplifies to just $O(N^3)$. This is the number of steps we expect for multiplying two $N$ by $N$ matrices, and it is the same as the naive case.</p>

<p>So this tiled approach has the same number of compute steps as the naive implementation, but a factor of $O(BN)$ less data movement. The arithmetic intensity works out to $O(\frac{N^3}{\frac{N^3}{BN}})=O(BN)$. In english, this is telling us that our achieved arithmetic intensity will scale linearly with the dimension of the tiles that we are fitting in fast memory.</p>

<h3 id="in-summary">In Summary</h3>

<p>The final takeaway is fairly intuitive. The best possible intensity we can achieve when multiplying two $N$ by $N$ matrices scales with the matrix dimension $N$. However, achieving this upper bound would require fitting the entire $O(N^2)$ sized problem in fast memory, which wont be possible. So we compromise by breaking down the $O(N^2)$ sized problem into lots of smaller $O(BN^2)$ sized problems, and we choose $BN$ such that all of our fast memory is filled up. The intensity we can then achieve scales with $BN$. So in practice, the intensity we can achieve is limited by the size of fast memory on our device.</p>

<h2 id="parallelized-matrix-multiplication-on-a-gpu">Parallelized matrix multiplication on a GPU</h2>
<p>Thinking about matrix multiplication on the simple computer helps build intuition about how using the memory hierarchy to our advantage can result in higher arithmetic intensity, which will help for maximizing the performance of our kernel. However the simple computer model is a bit too simple, it consists of a two level memory hierarchy and some compute that can operate at a rate of $\tau$ on the data in fast memory. Our goal is to write a fast matrix multiplication kernel that will run on a GPU, which raises the question of how a GPU is different from the simple computer.</p>

<p>On the most fundamental level that answer is that GPUs, like the simple computer, have a memory hierarchy. But on a GPU the memory hierarchy fits within a hierarchy of concurrent compute units. Here is a diagram of a simple GPU that illustrates this.</p>

<p><img src="https://alexarmbr.github.io/images/simple_gpu.png" alt="simple_gpu"></p>

<p>On the simple GPU there are three levels to the combined compute/memory hierarchy.</p>
<ul>
  <li>At the highest level is the whole GPU, which owns a big piece of DRAM (global memory). The GPU is composed of four multiprocessors, each of which are independent units of a compute, run concurrently with respect to each other and can all read/write to the same DRAM.</li>
  <li>At the middle level there is a multiprocessor which owns a piece of SRAM (shared memory), and is composed of four cores which are independent units of compute that run concurrently and can all read and write the same shared memory that is local to the multiprocessor.</li>
  <li>At the lowest level is a single compute core which owns some private register memory, and can execute a single thread and perform arithmetic independently of the rest of the computer.</li>
</ul>

<h3 id="hierarchical-tiling-simple-gpu">Hierarchical Tiling (simple gpu)</h3>
<p>So how do we use this type of computer to perform a matrix multiplication? The first useful observation is that the matrix multiplication problem can be broken down hierarchically into nested tiles. This is good news, because a hierarchical algorithm is a good fit for a hierarchical computer.</p>

<p><img src="https://alexarmbr.github.io/images/matmul_hierarchies.png" alt="matmul_hierarchies"></p>

<p>If we are computing a matrix multiplication $C=A*B$, we can divide the output matrix $C$ into non-overlapping tiles, and assign each tile to a compute unit. Each of these output tiles can then be computed with a matrix multiplication between corresponding tiles of the input, independently of the other tiles. Since our machine is hierarchical, there are compute units within compute units, and correspondingly there are matrix multiplications within matrix multiplications. We recursively break down the problem into nested tiles, until we end up at an atomic element of compute which physically is usually a single core of some sort, and logically is a single thread of execution. At this level the single thread computes a small matrix multiplication between its tiles of the input.
<img src="https://alexarmbr.github.io/images/hierarchy_combined.png" alt="hierarchy_combined"></p>

<h3 id="hierarchical-tiling-real-gpu">Hierarchical Tiling (real gpu)</h3>
<p>The above diagram shows a coarse, high level view of what a GPU implementation of hierarchical tiling looks like. When implementing this in CUDA for an NVIDIA GPU, there are some finer details we need to fill in. This tiling structure is created by:</p>
<ul>
  <li>a series of global, shared, and register memory allocations of fixed dimension</li>
  <li>nested loops which control the positions of the tiles</li>
  <li>synchronization points between threads running within a multiprocessor</li>
  <li>compute at the lowest level, which in this case is a small matrix multiplication that runs on the tensor core</li>
</ul>

<p>This kernel was my starting point, but if you are interested in reading about a series of 10 kernels which build up to one like this, I recommend reading <a href="https://siboehm.com/articles/22/CUDA-MMM">this</a>.</p>

<p><img src="https://alexarmbr.github.io/images/my_tiles_2.png" alt="tiling"></p>

<p>With this diagram my attempt is to show the correspondence between loop nests and the tiling structure. There are four levels, each level corresponds to a level of the compute hierarchy, memory hierarchy, and tile shape.</p>

<p>Here is a quick description of each level from the perspective of the compute unit relevant for that level:</p>

<ul>
  <li>
    <p><strong>CUDA Kernel / GPU level</strong>: The GPU is reading the three input matrices, $A$, $B$, and $C$ from <strong>global memory</strong>, and writing the output matrix $D$ to global memory. Each thread block is looping over the <code>K</code> dimension (aka the ‘inner’ dimension) of $A$ and $B$. This loop is incrementing <code>block_k</code> in steps of size <code>BK</code>. At each iteration we are copying the blue blocktiles from global memory to shared memory.</p>
  </li>
  <li>
    <p><strong>Thread Block / SM level</strong>: At this point the blue subtiles of $A$ and $B$ that a particular thread block needs to compute a <code>BM,BN</code> tile of the output have been copied into <strong>shared memory</strong>. This thread block is running on one of the 16 SMs on the GPU, and the shared memory is local to that SM and fast to access. Within the thread block there are 256 threads, which is 8 warps containing 32 threads each. Within the thread block, the <code>BM,BN</code> tile of the output is partitioned 8 ways, so that each of the 8 warps can work concurrently on the compute. Each of the warps is looping over the inner dimension within the block tile, this loop is incrementing <code>warp_k</code> in steps of size <code>WK</code>. At each iteration we are copying the green warp tiles from shared memory to register memory.</p>
  </li>
  <li>
    <p><strong>Warp / SM Partition</strong>: At this point the green warp tiles within the blue block tiles have been copied into <strong>register memory</strong>, and it is the responsibility of a particular warp, running on one of the 4 partitions on the <a href="https://images.app.goo.gl/Z2VVQQgXWTMddBraA">Turing SM</a> to compute the <code>WM</code> by <code>WN</code> tile of the output. Each warp computes its tile of the output by taking an outer product between the <code>WM,WK</code> tile of A and the <code>WK,WN</code> tile of B. Inside the three nested loops that compute the outer product, the we an MMA sync operation.</p>
  </li>
  <li>
    <p><strong>Tensor Core Op</strong>: Finally we get down to the last level of the hierarchy, which is a single tensor core op, this is a single hardware accelerated (16,8) x (8,8) = (16,8) matrix multiply that takes place in and out of <strong>register memory</strong>.</p>
  </li>
</ul>

<h3 id="performance-considerations-on-a-real-gpu">Performance considerations on a real GPU</h3>
<p>When implementing this structure in a CUDA kernel that targets a particular GPU architecture, there are a number of things that must be considered given that we are trying to squeeze every last drop of performance out of the hardware. I divide the performance considerations into three buckets, each optimization discussed in the rest of this article falls into one or two of these buckets.</p>

<h4 id="arithmetic-intensity-as-a-function-of-tile-dimensions">Arithmetic intensity as a function of tile dimensions</h4>
<p>The necessity of achieving high arithmetic intensity is why we have this structure of tiles within tiles, and the tile dimension is the primary knob we can turn that determines the arithmetic intensity of our kernel. In our kernel we are first loading data from global memory to shared memory, and then shared memory into registers. In both cases we are loading two rectangular tiles corresponding to the input data from slower memory to faster memory, and then eventually computing a matrix multiplication between these two inputs at the lowest level of the hierarchy. The arithmetic intensity we should achieve is a function of the tile dimensions we choose (larger is better), this is worked out below.</p>

<p><img src="https://alexarmbr.github.io/images/intensity_tile_dims.png" alt="intensity_tile_dims"></p>

<ul>
  <li>
<strong>FLOPs</strong>: At each iteration of the inner loop, each thread block multiplies a $(BM,BK)$ shaped matrix with a $(BK,BN)$, to produce a $(BM,BN)$ tile of the output. This matrix product consists of $2 * BM * BK * BN $ FLOPs (three nested loops over the dimensions, with a multiply and accumulate operation in the inner loop)</li>
  <li>
<strong>memory</strong>: The $(BM,BK)$ and $(BK,BN)$ shaped matrices are read from global memory each iteration, since each element is two bytes this comes out to a total of $2(BM * BK + BK * BN) = 2BK(BM + BN)$ bytes read, and we don’t perform any writes in the inner loop, all writes happen in the kernel epilogue.</li>
</ul>

<p>Taking the ratio of these two, the arithmetic intensity we should achieve for a given block tile size works out nicely to $\frac{BM*BN}{BM+BN} \frac{FLOP}{byte}$. For the thread block level tiles at the second level of the hierarchy, we will want to choose our tile dimensions such that this ratio is larger than the balance point of the tensor cores with respect to global memory, but we will be limited by the size of shared memory. Likewise for the warp tiles at the next level down in the hierarchy, we will want to choose the tile dimensions such that this ratio is larger than the balance point of the tensor cores with respect to shared memory, but we will be limited by the size of register memory. The former turns out to be a bit more challenging than the later.</p>

<h4 id="overlap-between-compute-and-data-movement">Overlap between compute and data movement</h4>
<p>The roofline model gives us an upper bound on arithmetic throughput $T_{max}=min(\beta * I, \tau)$. In order to achieve this upper bound, we need perfect overlap between compute and data movement. In order to see why this is, imagine we achieve an arithmetic intensity sufficient to put us in the compute bound regime of the roofline model. At this point in order for our achieved throughput to actually equal the upper bound $T_{max}=\tau$, we need to be continuously computing, any time that our compute spends idle will mean that our achieved throughput is less than the machine peak $\tau$. There are a number of reasons why our compute will spend periods of time idle, such as memory latency, data dependencies, and synchronization points.
<img src="https://alexarmbr.github.io/images/compute_data_movement_overlap.png" alt="compute_data_movement_overlap">
As illustrated above our initial loop structure has some inefficiencies in this regard.</p>

<h4 id="maximizing-memory-bandwidth">Maximizing memory bandwidth</h4>
<p>According to <a href="https://arxiv.org/pdf/1903.07486">unofficial benchmarks</a> the best achievable global memory bandwidth on the T4 is ~220 GB/sec, and the best achievable shared memory bandwidth is ~3662 GB/sec. However, an unoptimized kernel will only achieve a fraction of these numbers. The first consideration is access pattern; when groups of adjacent threads are requesting memory, some mappings of threads to data in memory are more efficient than others. The hardware that implements global memory vs. shared memory functions differently, consequently an access pattern that is optimal for reading shared memory may not be optimal for reading global memory.</p>

<p>The main consideration for global memory access is called coalescing, the one sentence summary is that maximum global memory bandwidth is achieved when adjacent threads access adjacent data in global memory (explained <a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses">here</a>). Shared memory is dove into in a <a href="#background-bank-conflicts-and-wavefronts">later</a> chapter.</p>

<h3 id="how-to-use-tensor-cores">How to use Tensor Cores</h3>
<p>This section is a brief overview of the mechanics of using tensor cores.</p>

<p>All tensor core operations are performed at the warp level in the compute hierarchy; 32 threads collaboratively load data into their registers and then synchronously execute a small hardware accelerated matrix multiply. When thinking about tensor core algorithms, we should think of the warp as an atomic element of compute, even though in reality a warp contains 32 threads capable of doing their own thing. By comparison if we were writing GEMM kernel without tensor cores, individual threads performing scalar multiply accumulate operations would be our atomic element of compute.</p>

<p>Tensor cores are accessible via two different methods. The first is via the <code>wmma</code> <a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/#wmma-description">api</a> which is part of the CUDA toolkit. <code>wmma</code> seems to be regarded as the more portable and less performant way to program tensor cores. I gave up on it pretty quickly, as it abstracts away the loading of input data from shared memory into register memory, and it turns out there are some details here which are critical for performance.</p>

<p>The other route is to use the <code>mma</code> family of instructions which are part of PTX, this option is more flexible and performant than the <code>wmma</code> route. PTX is an intermediate representation for NVIDIA GPUs that is lower level than CUDA, but higher level than SASS (this is the assembly language that NVIDIA GPUs run). PTX can be inlined in a kernel in order to call tensor cores.</p>

<p>The PTX instruction I used is <code>mma.sync.aligned.m16n8k8.row.col.f16.f16.f16.f16</code> (documentation <a href="https://docs.nvidia.com/cuda/parallel-thread-execution/#matrix-fragments-for-mma-m16n8k8">here</a>), each part of this instruction means something:</p>
<ul>
  <li>
<code>mma</code>: we are performing a matrix multiply accumulate operation</li>
  <li>
<code>sync</code>: this instruction is synchronous, all 32 threads will wait until all 32 threads are done before resuming execution</li>
  <li>
<code>aligned</code>: all 32 threads in a warp must execute this instruction, if less than 32 threads in a warp were to execute this instruction, behavior is undefined</li>
  <li>
<code>m16n8k8</code>: this is the identifier for the matrix fragment shape. This means the fragment of matrix 
$A$ has shape (16,8), the fragment of $B$ has shape (8,8), the fragments of $D$ and $C$ have shape (8,8). (Remember, the formula for a GEMM is $D = \alpha * A * B + \beta * C$). If you look at the PTX documentation linked above, there are lots of different shapes to choose from, however the Turing/Volta architectures only support a limited number. Ampere supports more, and Hopper supports even more.</li>
  <li>
<code>row</code>: the $A$ fragment should be stored in registers in a row-major layout</li>
  <li>
<code>col</code>: the $B$ fragment should be stored in register in a column-major layout</li>
  <li>
<code>f16</code>: $D$ is an fp16 matrix</li>
  <li>
<code>f16</code>: $A$ is an fp16 matrix</li>
  <li>
<code>f16</code>:&nbsp;$B$ is an fp16 matrix</li>
  <li>
<code>f16</code>: $C$ is an fp16 matrix</li>
</ul>

<p>Each <code>mma.sync</code> instruction expects a specific layout of fragment elements across the registers of the 32 threads in a warp, these layouts can be found in the PTX docs. Here is the <code>m16n8k8</code> layout:
<img src="https://alexarmbr.github.io/images/mma_fragments.png" alt="matrix_fragments"></p>

<p>These diagrams are describing a mapping between threads, registers, and matrix elements:</p>
<ul>
  <li>
<code>T0, T1, T2 ...</code> refers to the index of the thread. Thread indices in these diagrams range from 0-31 since there are 32 threads in a warp.</li>
  <li>
<code>a0, a1, a2, ... b0, b1, b2, ... c0, c1, c2</code> refer to registers that hold matrix elements.</li>
  <li>The position of each thread/register pair tells us which matrix elements go in which registers of which thread. For example, <code>T0: {a0,a1}</code> is at the top left corner of matrix fragment A, this means elements <code>(0,0)</code> and <code>(0,1)</code> in this fragment are placed in registers <code>a0</code> and <code>a1</code> of thread 0.</li>
</ul>

<p>Luckily there is another PTX instruction called <code>ldmatrix</code> (docs <a href="https://docs.nvidia.com/cuda/parallel-thread-execution/#warp-level-matrix-load-instruction-ldmatrix">here</a>) which loads a rectangular tile of data from shared memory, and shuffle matrix elements within a warp in order to create this layout for us. It can optionally transpose matrix elements as it moves them from shared memory to register, which is convenient for matrix B above, which is in a column major, or “transposed” layout.</p>

<p>The inner loop our our kernels will consist of repeatedly calling <code>ldmatrix</code> to move data from shared memory into register memory, and then repeatedly calling the <code>m16n8k8</code> variation of <code>mma.sync</code> in order to multiply tiles together with the tensor core. For this project I used a Turing architecture GPU, on Ampere the tensor core API is very similar, but with more matrix shapes supported. On Hopper, the API is expanded substantially, PTX instructions are introduced that allow a group of 128 threads to asynchronously execute a much larger matrix multiplication than <code>m16n8k8</code>.</p>

<h2 id="kernels">Kernels</h2>

<p>For the rest of this article I will discuss a series of kernels that got me to ~96% of cuBLAS level performance on a tensor core GEMM, for 8192x8192 matrices. Each kernel builds on the previous one, and the themes of each are:</p>
<ol>
  <li><a href="#kernel-1---hierarchical-tiling">hierarchical tiling</a></li>
  <li><a href="#kernel-2---vectorized-memory-copy-and-loop-unrolling">vectorized/unrolled gmem-&gt;smem transfer</a></li>
  <li><a href="#swizzling">shared memory swizzling</a></li>
  <li><a href="#kernel-4---makeshift-async-copy">makeshift async copy</a></li>
  <li><a href="#tune-tile-dimensions">tune tile dimensions</a></li>
  <li><a href="#kernel-5---optimize-index-calculation">optimized index calculation</a></li>
  <li><a href="#kernel-6---double-buffering">double buffering</a></li>
</ol>

<h2 id="kernel-1---hierarchical-tiling">Kernel 1 - Hierarchical Tiling</h2>
<p>The first kernel I wrote is an implementation of the hierarchical tiling structure shown <a href="#hierarchical-tiling-real-gpu">above</a>. Here is pseudocode for the loop structure that performs the matrix multiplication.</p>

<div><pre><code><span>// outer loop over block tiles</span>
<span>for</span> <span>(</span><span>block_k</span> <span>=</span> <span>0</span><span>;</span> <span>block_k</span> <span>&lt;</span> <span>K</span><span>;</span> <span>block_k</span> <span>+=</span> <span>BK</span><span>)</span>
<span>{</span>
    <span>// global memory to shared memory transfer</span>
    <span>A_smem</span><span>[</span><span>:</span><span>,</span><span>:</span><span>]</span> <span>=</span> <span>A_gmem</span><span>[</span><span>block_m</span><span>:</span><span>block_m</span><span>+</span><span>BM</span><span>,</span> <span>block_k</span><span>:</span><span>block_k</span><span>+</span><span>BK</span><span>]</span>
    <span>B_smem</span><span>[</span><span>:</span><span>,</span><span>:</span><span>]</span> <span>=</span> <span>B_gmem</span><span>[</span><span>block_k</span><span>:</span><span>block_k</span><span>+</span><span>BK</span><span>,</span> <span>block_n</span><span>:</span><span>block_n</span><span>+</span><span>BN</span><span>]</span>
    
    <span>// synchronize across the thread block in between</span>
    <span>// writing shared memory and reading shared memory</span>
    <span>__syncthreads</span><span>();</span>

    <span>for</span> <span>(</span><span>warp_k</span> <span>=</span> <span>0</span><span>;</span> <span>warp_k</span> <span>&lt;</span> <span>BK</span><span>;</span> <span>warp_k</span> <span>+=</span> <span>WK</span><span>)</span>
    <span>{</span>
        <span>// load from shared memory into register memory in preparation for compute phase</span>
        <span>A_reg</span><span>[</span><span>:</span> <span>,</span><span>:</span><span>]</span> <span>=</span> <span>A_smem</span><span>[</span><span>warp_m</span><span>:</span><span>warp_m</span><span>+</span><span>WM</span><span>,</span> <span>warp_k</span><span>:</span><span>warp_k</span><span>+</span><span>WK</span><span>]</span>
        <span>B_reg</span><span>[</span><span>:</span><span>,</span> <span>:</span><span>]</span> <span>=</span> <span>B_smem</span><span>[</span><span>warp_k</span><span>:</span><span>warp_k</span><span>+</span><span>WK</span><span>,</span> <span>warp_n</span><span>:</span><span>warp_n</span><span>+</span><span>WN</span><span>]</span>

        <span>// outer product over mma tiles</span>
        <span>for</span> <span>(</span><span>mma_k</span> <span>=</span> <span>0</span><span>;</span> <span>mma_k</span> <span>&lt;</span> <span>WK</span><span>;</span> <span>mma_k</span> <span>+=</span> <span>MMA_K</span><span>)</span>
        <span>{</span>
            <span>for</span> <span>(</span><span>mma_m</span> <span>=</span> <span>0</span><span>;</span> <span>mma_m</span> <span>&lt;</span> <span>WM</span><span>;</span> <span>mma_m</span> <span>+=</span> <span>MMA_M</span><span>)</span>
            <span>{</span>
                <span>for</span> <span>(</span><span>mma_n</span> <span>=</span> <span>0</span><span>;</span> <span>mma_n</span> <span>&lt;</span> <span>WN</span><span>;</span> <span>mma_n</span> <span>+=</span> <span>MMA_N</span><span>)</span>
                <span>{</span>
                    <span>mma_sync_m16n8k8</span><span>(</span>
                        <span>acc_reg</span><span>[</span><span>mma_m</span><span>:</span><span>mma_m</span><span>+</span><span>MMA_M</span><span>,</span> <span>mma_n</span><span>:</span><span>mma_n</span><span>+</span><span>MMA_N</span><span>],</span>
                        <span>A_reg</span><span>[</span><span>mma_m</span><span>:</span><span>mma_m</span><span>+</span><span>MMA_M</span><span>,</span> <span>mma_k</span><span>:</span><span>mma_k</span><span>+</span><span>MMA_K</span><span>],</span>
                        <span>B_reg</span><span>[</span><span>mma_k</span><span>:</span><span>mma_k</span><span>+</span><span>MMA_K</span><span>,</span> <span>mma_n</span><span>:</span><span>mma_n</span><span>+</span><span>MMA_N</span><span>],</span>
                        <span>acc_reg</span><span>[</span><span>mma_m</span><span>:</span><span>mma_m</span><span>+</span><span>MMA_M</span><span>,</span> <span>mma_n</span><span>:</span><span>mma_n</span><span>+</span><span>MMA_N</span><span>]</span>
                    <span>)</span>

                <span>}</span>
            <span>}</span>
        <span>}</span>
    <span>}</span>
    <span>__syncthreads</span><span>();</span>

<span>}</span>
</code></pre></div>
<p>The 8% of cublas throughput it achieves is the starting point. The rest of this article delves into some techniques I used to make it faster.</p>

<p><img src="https://alexarmbr.github.io/images/table1.png" alt="table1"></p>

<h2 id="kernel-2---vectorized-memory-copy-and-loop-unrolling">Kernel 2 - Vectorized memory copy and loop unrolling</h2>
<p>In order to improve the performance of our code, we need to know why it is slow. When writing CUDA kernels, the best tool to use for this is called NSight Compute, a profiler developed by NVIDIA that gives lots of detailed metrics about what is happening in hardware while a kernel executes. The first place I typically look is the section called “Warp State Statistics”. As a kernel is executing, each warp is being issued instructions by a scheduler. In an ideal world, the scheduler would be able to issue a new instruction each clock cycle. In the real world, it is very hard to write a kernel that can issue a new instruction every cycle, there are all sorts of reasons why on a given cycle, a warp may not be capable of executing its next instruction and will instead “stall” i.e. do nothing. The reasons for stalling can be due to capacity limits of various hardware pipelines, memory latency, or synchronization points in our kernel which require all the threads running on an SM to wait for all the other threads to catch up. The Warp State Statistics section tells us how many clock cycles the average warp spends stalled, per average instruction issued, broken down across a bunch of different categories. This gives us the information we need to target our optimizations to the least performant parts of our kernel. Here is a screenshot of what the Warp State section for Kernel 1.
<img src="https://alexarmbr.github.io/images/warp_state_kernel1.png" alt="warp_state_kernel1">
The “Warp Cycles Per Issued Instruction” field tells us that on average for each instruction issued, warps spend about ~30 cycles idle, and the table below tells us that 16 of these 30 cycles are due to the “Long Scoreboard” stall category.</p>

<p><a href="https://en.wikipedia.org/wiki/Scoreboarding">Scoreboarding</a> is an algorithm implemented in the hardware of most processors for tracking when the data dependencies for the next instruction have arrived in the registers they need to be in for the instruction to execute. Most modern CPUs are able to reorder instructions on the fly such that instructions whose operands are ready can execute ahead of instructions whose operands have yet to arrive in registers. The reordering is done in hardware, subject to constraints imposed by the data dependencies between subsequent instructions. This is called <a href="https://en.wikipedia.org/wiki/Out-of-order_execution">out of order execution</a> and it is a rather fancy technique for hiding latency. GPUs do not reorder instructions as they are executing, I would imagine because the logic required consumes a fair amount of precious transistors on the chip, and since GPUs are designed for <a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/#the-benefits-of-using-gpus">throughput</a> these transistors are better spent on things like tensor cores.</p>

<p>GPUs do however track data dependencies, but with a lot more help from the compiler as compared to CPUs. When the data required to execute the next instruction has not arrived in register memory, the warp that is executing just waits for its data to arrive. The “Long Scoreboard Stall” approximates the average number of cycles that warps spend stalled waiting for data dependencies. The fact that this stall reason accounts for ~50% of all the cycles that warps spend idle tells us that the performance of Kernel 1 is primarily limited by memory latency. This tells us we should focus on the code that is moving data from global memory onto the chip, and figure out how to minimize the latency per byte moved.</p>

<p>Reading a rectangular tile of data from global memory, and writing it to shared memory is the first thing that occurs on each iteration of the outer loop of the kernel. The easiest way to do this is for adjacent threads to access adjacent values in global memory, and write data to shared memory in the same layout that it came from in global memory. This access pattern is optimal both for reading global memory, and writing shared memory. Here is the first data transfer that I wrote:</p>

<div><pre><code><span>__device__</span> <span>void</span> <span>tileMemcpy</span><span>(</span>
    <span>half</span><span>*</span> <span>src</span><span>,</span>
    <span>half</span><span>*</span> <span>dst</span><span>,</span>
    <span>const</span> <span>unsigned</span> <span>int</span> <span>src_stride</span><span>,</span>
    <span>const</span> <span>unsigned</span> <span>int</span> <span>tile_rows</span><span>,</span>
    <span>const</span> <span>unsigned</span> <span>int</span> <span>tile_cols</span>
<span>)</span>
<span>{</span>
    <span>// flatten out 2d grid of threads into in order of increasing threadIdx.x</span>
    <span>const</span> <span>unsigned</span> <span>int</span> <span>thread_idx</span> <span>=</span> <span>threadIdx</span><span>.</span><span>y</span> <span>*</span> <span>blockDim</span><span>.</span><span>x</span> <span>+</span> <span>threadIdx</span><span>.</span><span>x</span><span>;</span>
    <span>const</span> <span>unsigned</span> <span>int</span> <span>num_threads</span> <span>=</span> <span>blockDim</span><span>.</span><span>x</span> <span>*</span> <span>blockDim</span><span>.</span><span>y</span><span>;</span>
    
    <span>// # of threads is multiple of # of columns in the tile</span>
    <span>assert</span><span>(</span><span>num_threads</span> <span>%</span> <span>tile_cols</span> <span>==</span> <span>0</span><span>);</span>
    
    <span>// assign each thread a row/column in the tile, calculate the row step</span>
    <span>const</span> <span>unsigned</span> <span>int</span> <span>row_step</span> <span>=</span> <span>num_threads</span> <span>/</span> <span>tile_cols</span><span>;</span>
    <span>const</span> <span>unsigned</span> <span>int</span> <span>thread_row</span> <span>=</span> <span>thread_idx</span> <span>/</span> <span>tile_cols</span><span>;</span>
    <span>const</span> <span>unsigned</span> <span>int</span> <span>thread_col</span> <span>=</span> <span>thread_idx</span> <span>%</span> <span>tile_cols</span><span>;</span>
    
    <span>for</span> <span>(</span><span>unsigned</span> <span>int</span> <span>r</span> <span>=</span> <span>thread_row</span><span>;</span> <span>r</span> <span>&lt;</span> <span>tile_rows</span><span>;</span> <span>r</span><span>+=</span><span>row_step</span><span>)</span>
    <span>{</span>
        <span>dst</span><span>[</span><span>r</span> <span>*</span> <span>tile_cols</span> <span>+</span> <span>thread_col</span><span>]</span> <span>=</span>  <span>src</span><span>[</span><span>r</span> <span>*</span> <span>src_stride</span> <span>+</span> <span>thread_col</span><span>];</span>
    <span>}</span>
<span>}</span>
</code></pre></div>
<p>Looking at the SASS corresponding to this <code>tileMemcpy</code> function in <a href="https://godbolt.org/z/1MeavE3GG">godbolt</a>, we can see that the copy operation inside the loop <code>dst[...] = src[...]</code> compiles to two operations from the lower level perspective of SASS, a two byte load from global memory (<code>LDG.U16</code> in SASS), followed by a two byte store (<code>STS.U16</code>), along with a bunch of index calculations and loop overhead. The long scoreboard stall prevents the store from taking place until the value we are loading has arrived in the register.</p>

<p>Here is a visualization of how this loop is executing, for a single thread:
<img src="https://alexarmbr.github.io/images/memory_latency.png" alt="memory_latency">
Latency in between the load and the store is inevitable: a request is sent to a DRAM controller, data is fetched from DRAM and then transmitted over bus. Unless we hack the laws of physics or invent a time machine we can’t get rid of the latency. But what we can do is hide it.</p>

<p>Latency hiding is a central concept in computing, and at its core is very simple. It just means that if we are performing an operation $X$ that has some latency, we want to be doing other useful work while $X$ is happening, rather than wait and do nothing. For example, if I wake up and decide I want an omlette, I would first turn on the burner and let the pan warm up, and while that is happening I would crack the eggs and grate cheese. This order of operations hides the latency of warming up the pan with the cracking of eggs and grating of cheese. If I am hungry and eager to eat the finished omlette as soon as possible, it would be silly to idly stand there and watch as the pan warms up.</p>

<p>The same principle applies to hiding the latency of the global memory loads in <code>tileMemcpy</code>. Since the copy operation is happening inside a loop, each thread is performing multiple loads and multiple stores, in an order like <code>load (stall) store, load (stall) store, ...</code>. What if we were able to rearrange these so that the order is <code>load load load (stall) store, store, store</code>. In this later ordering the data requested by the three loads will be in flight at the same time, and we can say that the latency of each load is being hidden by the other loads. The easiest way to accomplish the later ordering is by unrolling the loop in <code>tileMemcpy</code>. If we can unroll the loop, <code>nvcc</code> should be smart enough to reorder the instructions so that the global memory loads are hiding each others latency. In this case the compiler is doing for us what a CPU would do in hardware on the fly.</p>

<p>If we want to unroll the loop, the number of loop iterations must be known at compile time. The number of loop iterations is a function of the number of threads per block, and the block tile dimensions. Both of these are fixed at compile time, so passing them as template parameters into <code>tileMemcpy</code> and calculating the number of iterations as a function of these, and adding a <code>#pragma unroll</code> does the trick.</p>

<div><pre><code><span>template</span><span>&lt;</span><span>unsigned</span> <span>int</span> <span>TILE_ROWS</span><span>,</span>
<span>unsigned</span> <span>int</span> <span>TILE_COLS</span><span>,</span>
<span>unsigned</span> <span>int</span> <span>NUM_THREADS</span><span>&gt;</span>
<span>__device__</span> <span>__forceinline__</span> <span>void</span> <span>tileMemcpyUnrolled</span><span>(</span>
    <span>half</span><span>*</span> <span>src</span><span>,</span>
    <span>half</span><span>*</span> <span>dst</span><span>,</span>
    <span>const</span> <span>unsigned</span> <span>int</span> <span>src_stride</span>
<span>)</span>
<span>{</span>
    <span>// # of threads is multiple of # of columns in the tile</span>
    <span>static_assert</span><span>(</span><span>NUM_THREADS</span> <span>%</span> <span>TILE_COLS</span> <span>==</span> <span>0</span><span>);</span>
    
    <span>// flatten out 2d grid of threads into in order of increasing threadIdx.x</span>
    <span>const</span> <span>unsigned</span> <span>int</span> <span>thread_idx</span> <span>=</span> <span>threadIdx</span><span>.</span><span>y</span> <span>*</span> <span>blockDim</span><span>.</span><span>x</span> <span>+</span> <span>threadIdx</span><span>.</span><span>x</span><span>;</span>

    <span>// assign each thread a row/column in the tile, calculate how many iterations we need</span>
    <span>// to cover the whole tile</span>
    <span>constexpr</span> <span>unsigned</span> <span>int</span> <span>ROW_STEP</span> <span>=</span> <span>NUM_THREADS</span> <span>/</span> <span>TILE_COLS</span><span>;</span>
    <span>constexpr</span> <span>unsigned</span> <span>int</span> <span>NUM_ITERS</span> <span>=</span> <span>TILE_ROWS</span> <span>/</span> <span>ROW_STEP</span><span>;</span>
    <span>unsigned</span> <span>int</span> <span>thread_row</span> <span>=</span> <span>thread_idx</span> <span>/</span> <span>TILE_COLS</span><span>;</span>
    <span>const</span> <span>unsigned</span> <span>int</span> <span>thread_col</span> <span>=</span> <span>thread_idx</span> <span>%</span> <span>TILE_COLS</span><span>;</span>
    
    <span>#pragma unroll
</span>    <span>for</span> <span>(</span><span>unsigned</span> <span>int</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>NUM_ITERS</span><span>;</span> <span>i</span><span>++</span><span>)</span>
    <span>{</span>
        <span>dst</span><span>[</span><span>thread_row</span> <span>*</span> <span>TILE_COLS</span> <span>+</span> <span>thread_col</span><span>]</span> <span>=</span>  <span>src</span><span>[</span><span>thread_row</span> <span>*</span> <span>src_stride</span> <span>+</span> <span>thread_col</span><span>];</span>
        <span>thread_row</span> <span>+=</span> <span>ROW_STEP</span><span>;</span>
    <span>}</span>
    
<span>}</span>
</code></pre></div>
<p>This gives us something more along the lines of:
<img src="https://alexarmbr.github.io/images/memory_latency_unrolled.png" alt="memory_latency_unrolled">
In the initial version, the total latency of the copy operation is roughly proportional to the memory latency of the device, times the number of loop iterations. After unrolling the loop, the total latency compared to the first version should be reduced by a factor of the number of loads the compiler decides to overlap with eachother (ish).</p>

<p>The other fairly easy optimization we can make here is to increase the number of bytes being loaded per instruction. Our load operation is currently compiling to <code>LDG.U16</code>, each of these instructions loads 16 bits/2 bytes from DRAM. The widest load instruction in SASS is <code>LDG.128</code>, which loads 128 bits/16 bytes. Since our kernel is bound by memory latency and not memory bandwidth, if we use a wider load instruction will experience the same latency per memory request, but move more bytes per request. We are amortizing the latency over more bytes moved, which is a win for efficiency.</p>

<p><img src="https://alexarmbr.github.io/images/memory_latency_vectorized.png" alt="memory_latency_vectorized"></p>

<p>A quick and hacky way to accomplish this is by <code>reinterpret_cast</code>ing the <code>src</code> and <code>dst</code> pointers from <code>half</code> to <code>float4</code>, and updating the index and loop calculations accordingly. Here is a <a href="https://godbolt.org/z/v3T3x14ns">godbolt link</a> to a kernel with the vectorized and unrolled memory copy, and <a href="https://github.com/alexarmbr/matmul-playground/blob/main/src/device_utils.cuh#L73">here</a> is the code.</p>

<p>These optimizations to the memcpy increase the throughput over the first kernel by about 3x. But there is still a long way to go before we approach cuBLAS level performance
<img src="https://alexarmbr.github.io/images/table2.png" alt="table2"></p>


<p>Back to the warp state section of NSight Compute
<img src="https://alexarmbr.github.io/images/kernel2_nsight_compute.png" alt="kernel2_nsight_compute">
The long scoreboard stall is no longer the leading offender in terms of warp stalls, and our kernel got about 3x more performant after applying the optimizations described in the last section. Warps are now spending an average of ~19 cycles stalled per issued instruction due to something called “MIO Throttling.” What is MIO Throttling, and how do we address it? According to nsight compute <a href="https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html">docs</a> this means:</p>
<blockquote>
  <p>Warp was stalled waiting for the MIO (memory input/output) instruction queue to be not full. This stall reason is high in cases of extreme utilization of the MIO pipelines, which include special math instructions, dynamic branches, as well as shared memory instructions.</p>
</blockquote>

<p>In our case, this stalling is almost certainly due to shared memory instructions, since our kernel has very few dynamic branches, and no trigonometry or any other <a href="https://developer.nvidia.com/cuda-math-library">special math</a> instructions. Specifically, it is due to shared memory bank conflicts. According to <a href="https://forums.developer.nvidia.com/t/shared-memory-bank-conflicts-and-nsight-metric/115731/2?u=a14armbr">here</a> two symptoms of shared memory bank conflicts are very high L1/TEX thoughput number (currently at 97% of peak) and MIO Throttle stalls, these are both second order effects of shared memory bank conflicts. I learned at this point that if you have a kernel whose performance is being killed due to shared memory bank conflicts, this is not blatantly obvious when you look at NSight Compute, however the information is definetly there. I found that in order to see where shared memory bank conflicts were occuring, and understand their severity, I had to learn the terminology of a “wavefront”. In order to understand this term, a bit of background on shared memory is required.</p>

<h3 id="background-bank-conflicts-and-wavefronts">Background: Bank Conflicts and Wavefronts</h3>
<p>From the perspective of a CUDA program, shared memory works as follows (<a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#shared-memory-5-x">here</a> is the official guide). If you declare a <code>__shared__</code> array in your kernel, it corresponds to physical memory that is located on a specific streaming multiprocessor. Consequently this array is fast to access, but only accessible by threads on the SM, which in the language of CUDA means that shared memory arrays are local to a particular thread block. Physically the memory is spread between 32 “banks” with each bank storing an adjacent 4 bytes, like so:
<img src="https://alexarmbr.github.io/images/shmem_1.png" alt="shmem_1">
Each bank can produce a single 4 byte value per clock cycle. If our goal is to maximize our reading and writing bandwidth from shared memory, we need to keep this in mind when deciding on an access pattern. Full bandwidth is achieved when the 32 threads in a warp spread their access uniformly across the 32 banks. Bank “conflicts” occur when a single bank must produce data for more than one thread for a given request. In order to show how the ideas of bank conflicts and wavefronts tie together, here are 3 scenarios, all in a simplified world where we have 4 threads and 4 memory banks
<img src="https://alexarmbr.github.io/images/bank_conflicts_wavefronts.png" alt="bank_conflicts">
When loading or storing from shared memory, each thread requests a particular memory address that in our simplified world falls into one of the four memory banks. In scenario one, each thread is accessing data in a different bank, and the hardware calculates that these four accesses can be combined into a single transaction for the hardware to process, the word for this transaction is a <a href="https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#id26">wavefront</a>. In scenario two, the four threads access addresses that fall into two of the four banks. Since each bank is only capable of sending one word at a time, the hardware groups these four requests into two wavefronts, and the memory hardware processes the two wavefronts one after the other. Scenario three is the worst case scenario, the four threads access addresses that all fall to the 0th memory bank, and in this case the four seperate wavefronts are required to service the transactions from the four threads.</p>

<p>For four threads accessing four bytes, the “ideal” number of wavefronts is one, because (ideally) regardless of which threads are accessing which bytes, we should be able to arange our data such that all of our accesses are spread nicely accross the banks. For example scenario three as shown is less than ideal, but we could make it ideal by transposing the bytes in shared memory, this would result in the four accesses falling evenly accross the four banks. But for the layout as shown, the actual number of wavefronts is four.</p>

<p>NSight Compute will tell us per memory access:</p>
<ol>
  <li>the ideal number of wavefronts</li>
  <li>the actual number of wavefronts</li>
  <li>the number of wavefronts that are excessive, which is just 2 - 1</li>
</ol>

<p>According to the analysis above, if our code has an $n$ way bank conflict, $n$ should be equal to $\frac{actual\ wavefronts}{ideal\ wavefronts}$. We want the actual to equal the ideal, this often requires some careful thinking about how data is being laid out and how threads are accessing it.</p>

<h3 id="ldmatrix-bank-conflicts">ldmatrix bank conflicts</h3>
<p>Here is a screenshot of the per instruction actual/ideal wavefronts in NSight Compute:
<img src="https://alexarmbr.github.io/images/l1_wavefronts_source_view.png" alt="l1_wavefronts_source_view">
These <code>ldmatrix</code> commands are loading data from shared memory into thread local register memory in preparation for the MMA operations. NSight Compute tells us the ratio of actual to ideal is ~8ish, which suggests this memory access results in an 8-way bank conflict. In order to form a strategy for fixing this performance killer, we need to understand why it is happening.</p>

<p>In the tiling structure shown for Kernel 1, in each iteration of the warp loop (the green one), a single warp is responsible for reading a 64x64 tile of data from shared memory, and writing it to registers. The shared memory reads are where the bank conflicts occur. In the visualization below, on the top is a very zoomed out version of one of these 64x64 tiles, the layout across memory banks is visualized by the color of the columns. We can see that a row of 64 elements, which are 2 bytes each, nicely spans the 32 memory banks.
On the bottom is a zoomed in version of a single 8x8 tile that is brought from shared memory into registers by <code>ldmatrix</code>. Each warp is iterating over its own local 64x64 tile in 8x8 increments, calling <code>ldmatrix</code> on each little tile, this PTX instruction loads values from shared memory, and shuffles the loaded data among the registers in a warp to match the register layout that the tensor core instruction expects.
<img src="https://alexarmbr.github.io/images/mma_tile_zoom_in.png" alt="mma_tile_zoom_in">
The inner workings of <code>ldmatrix</code> are a bit opaque, it compiles to a single SASS instruction <code>LDSM...</code>, rather than multiple explicit shared memory loads and register shuffles, as one might expect. However, we dont need an understanding of <code>ldmatrix</code>s inner workings to see why the 8 way bank conflict is occuring each time we call it. Rather the 8-way bank conflict is an inevitable result of the fact that each row in a given tile is spread across the same four memory banks. One wavefront is required to read each row, and there are eight rows, which means eight wavefronts. Ideally, if the eight rows in each tile were spread evenly across the thirty two memory banks, the entire tile could be read with a single wavefront. Reading these tiles is in the inner loop of the kernel, for $8192$x$8192$ operands we read a total of $ (8192/8)^3=1,073,741,824$ of these tiles which works out to a ~shitload~ of bank conflicts. So if we care about performance, it is worth the time to fix it.</p>

<h3 id="padding">Padding</h3>
<p>In order to have a bank conflict free kernel, we need to rearrange the layout of data in shared memory such that we can read and write to shared memory without any excessive wavefronts. The challenge comes from the fact that the thread to data mapping for shared memory reads is different from that of shared memory writes. When writing, adjacent threads write adjacent values in a row, whereas when reading adjacent threads read adjacent values down a column.</p>

<p><img src="https://alexarmbr.github.io/images/row_vs_column_shmem_access.png" alt="row_vs_column_shmem_access"></p>

<p>This is a common situation in kernels that use 2d shared memory tiles, and the standard fix is to add a bit of padding (i.e. empty space) at the end of each row in the shared memory array. If we add this padding in such a way that a single row of our array no longer fits perfectly into the 32 memory banks, adjacent values in a column no longer fall into the same bank, which means we can read columns with no excessive wavefronts. This makes more sense in a picture than in words, here again is a simplified case of a mini-array (4 columns and 4 rows) stored on a mini-gpu with only 4 memory banks:
<img src="https://alexarmbr.github.io/images/simple_smem_padding.png" alt="simple_smem_padding">
Array elements are color coded by column. Notice that in the no padding case, all the array elements in a given column fall into the same memory bank. After adding the column of padding, the array elements in a given column are spread across all 4 memory banks. The padding technique could be used here to fully eliminate bank conflicts. Since we are using <a href="#kernel-2---vectorized-memory-copy-and-loop-unrolling">vectorized</a> writes to shared memory, we are writing to shared memory in 16 byte chunks at a time, and each chunk must be <a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/#device-memory-accesses">aligned</a>. Adding 16 bytes of padding to each row of shared memory would result in each 8x8 mma tile being spread across all 32 memory banks (exercise of convincing yourself of this left to reader).</p>

<p>The drawback of using the padding technique is that it requires us to allocate extra, unused space in shared memory. In Kernel 2, the shared memory tile for $A$ is 256x64, and the shared memory tile for $B$ is 128x64. If we add an extra 16 byte, or 8 element column to both of these, that will increase the amount of shared memory we allocate by 25%, for a total of increase of 6144 bytes. This wasted space turns out to be a significant drawback, when writing a high performance kernel shared memory is very precious stuff - this becomes especially apparent later down in the road when using a technique called double buffering, each threadblock in future kernels will end up using 100% of the 65536 bytes of shared memory on each SM. So, we should wonder whether there is a way to eliminate bank conflicts without wasting any shared memory space. It turns out this is very possible!</p>

<h3 id="swizzling-toy-example">Swizzling (toy example)</h3>
<p>Swizzling is probably my favorite technique that I learned in the process of working on this. The word “swizzle” has several different uses, when used in the context of cocktails it means to <a href="https://en.wikipedia.org/wiki/Swizzle_stick">stir</a> and when used in the context of GPUs it means to <a href="https://en.wikipedia.org/wiki/Swizzling_(computer_graphics)">rearrange</a>. In our context of eliminating shared memory bank conflicts in 2D tiles of data, swizzling means permuting the elements within a tile of shared memory such that we can access the data without any bank conflicts. This is one of those techniques that seemed like black magic to me until I took the time to understand it, and now I appreciate its cleverness and elegance.</p>

<p>In our 4x4 tile, we add the padding because it shifts the alignment between data and memory banks in a desirable way. Swizzling is based on the observation that we don’t need the extra padding bytes to spread column elements evenly over memory banks. Instead we can just figure out a permutation of matrix elements that spreads around the columns in the right way, and apply this permutation when we write to shared memory. Here is an illustration of a “swizzle” i.e. a permutation of elements that can eliminate bank conflicts.
<img src="https://alexarmbr.github.io/images/simple_smem_swizzled.png" alt="simple_smem_swizzled">
It is worth remembering at this point that our shared memory layout must satisfy two requirements, bank conflict free row access for writing, and bank conflict free column access for reading.</p>

<p>In all three cases, each row is consecutive in memory and spread across all four memory banks, which means each row can be written without any bank conflicts. The observation here is that when we apply our permutation or “swizzle”, we don’t want to permute elements across rows, only within rows; otherwise we might lose this property of bank conflict free writes.</p>

<p>The problem that motivated us to think about shared memory layouts was the bank conflicts that occur when we read columns. Adding the padding fixes the bank conflicts here, but at the expense of wasted shared memory. Swizzling gives us the best of both worlds; we can read columns with no bank conflicts, and no shared memory is wasted. So how do we think about applying this permutation?</p>

<p>The swizzle shown above can be implemented as a function <code>f</code> that maps indices to new indices. If <code>A</code> is the original array, <code>A_s</code> is the swizzled array, and <code>i</code> is the index of an element, then <code>A_s[f(i)] = A[i]</code>. So what is <code>f</code> here?</p>

<p>Since <code>f</code> is operating on array indices, we should think about the different ways these indices can be represented and viewed:
<img src="https://alexarmbr.github.io/images/simple_smem_indices.png" alt="simple_smem_indices">
On the far left are the 2D row and column indices. Moving to the middle, these indices can be linearized into a sequential (and in this case row major) ordering of the 16 elements in the array. Moving to the right, when we look at the sequential indices in binary we can see that the 2d structure is present in the index bits. The two least significant bits in the index encode the column and the two other bits encode the row. As a spoiler alert, <code>f</code> is going to operate from the perspective of the view on the right, the binary representation of the flat array index. Here are two observations about what <code>f</code> needs to do:</p>
<ul>
  <li>In order to avoid bank conflicts on write, we want to permute elements within a row, or in other words no elements should switch row. This means that <code>f</code> should modify the bits which encode the column, and leave alone the bits that encode the row.</li>
  <li>We want to apply a different permutation to each row, and for any given column, we want the elements in that column to be spread across all four columns in the swizzled array.</li>
</ul>

<p>We can accomplish both of these aims using the XOR function, specifically by XORing the row bits of each element with its column bits, and using the result as the new row bits. Here is a row by row break down that shows how XORing the column bits with the row bits moves around values within a row:
<img src="https://alexarmbr.github.io/images/swizzled_rows.png" alt="swizzled_rows">
The <code>f</code> that does this for us is <code>f(i) = i ^ ((i &amp; 0b1100) &gt;&gt; 2)</code>. The mask is selecting the two column bits from <code>i</code>, these two bits are then shifted right two places so that they line up with the two row bits for <code>i</code>, and then we XOR. <code>i</code>’s column bits remain unchanged.</p>

<p>Here is a visualization of the result of applying this function for all rows together:
<img src="https://alexarmbr.github.io/images/2d-swizzle.png" alt="2d-swizzle"></p>

<h3 id="swizzling-real-world">Swizzling (real world)</h3>
<p>Now we need to figure out how to use this technique to permute our shared memory layout in such a way that we can read a single 8x8 mma tile with 0 excessive wavefronts. As a reminder, here is a view of our shared memory layout, with a single tile of interest highlighted.
<img src="https://alexarmbr.github.io/images/mma_tile_zoom_in_blank.png" alt="mma_tile_zoom_in_blank"></p>

<p>Our goal is to figure out a swizzle function that spreads the 8 rows in this tile across all 32 memory banks, rather than having all 8 rows stuffed into 4 memory banks which is the case above. From the view of the full tile, the rows of the tile above would be spread like this.</p>

<p><img src="https://alexarmbr.github.io/images/mma_tile_zoom_in_swizzle.png" alt="mma_tile_zoom_in_swizzle"></p>

<p>In order to figure out what swizzle function we should use, lets look at the binary representation of an index into this tile, and assign it some structure that corresponds to our tiling scheme.</p>

<p><img src="https://alexarmbr.github.io/images/swizzle_index_groups.png" alt="swizzle_index_groups"></p>

<p>Some notes about what our swizzling function should do and not do:</p>
<ul>
  <li>We want to keep the eight elements in each MMA tile row together. In other words, eight adjacent elements in a single row of an 8x8 MMA tile are going to stay together when we apply the swizzle. This means our swizzle function is not going to touch the orange bits.</li>
  <li>Bank conflicts occur because the 8 rows within an MMA tile are all perfectly stacked on top of each other. Within an MMA tile, we want to spread these 8 rows horizontally across the entire warp tile. The blue bits encode where in the 64 element wide warp tile each MMA tile falls, so these blue bits are the ones we want our swizzle function to modify.</li>
  <li>We dont want to move elements between rows, so our swizzle function is not going to modify the green row bits. However, these green row bits provide a nice alternating pattern that we can XOR with the blue bits to mix around the MMA tiles within their row.</li>
  <li>Again, we dont want to be moving elements between rows, and the black bits (the most significant ones shown in this diagram) encode the starting row of each MMA tile. Our swizzle function is going to ignore them.</li>
</ul>

<p>So what this all means is that for each index, we want to take the blue bits, XOR them with the green bits, and replace the original blue bits with the result of this XOR. If <code>i</code> is the index we want to swizzle, this works out to:
<img src="https://alexarmbr.github.io/images/swizzled_vs_unswizzled.png" alt="swizzled_vs_unswizzled">
And just like that, we have no bank conflicts. Swizzling takes a bit more figuring out than the padding technique, the choice of swizzle function depends on the shared memory array dimensions, and the vector width we are using for reads/writes (i.e. <code>float4</code>, <code>float2</code>, <code>int</code>, e.t.c.). As a result, if we use swizzling it adds an extra consideration each time we consider changing either of these. But if you want to eliminate bank conflicts and dont want to increase your shared memory footprint in the process, swizzling becomes necessary. I think it is very elegant and clever, if you compare kernel 2 with kernel 3, there is a total of ~4 lines of code that change, these four lines are the addition of the swizzle into the shared memory index calculation.</p>

<p>I figured all this out by looking at the <code>Swizzle</code> class implemented <a href="https://github.com/NVIDIA/cutlass/blob/main/python/pycute/swizzle.py">here</a> in the CUTLASS repository. Via its three parameters, <code>bits</code>, <code>base</code>, and <code>shift</code>, this class represents a family of swizzle functions that shift and XOR bits of array indices. I have also seen examples of more exotic swizzle functions (see slide 27 <a href="https://developer.download.nvidia.com/video/gputechconf/gtc/2019/presentation/s9593-cutensor-high-performance-tensor-operations-in-cuda-v2.pdf">here</a>) that go beyond what is representable by the implementation in CUTLASS. I found it helpful to visualize the permutations applied by different swizzle functions, to help with this I wrote a bit of python <a href="https://github.com/alexarmbr/matmul-playground/blob/main/scripts/shmem_layout_viz.py">code</a> that pretty-prints arrays, applies swizzle functions, and counts bank conflicts.</p>

<p>Eliminating bank conflicts results in a ~2x speedup, and gets us to about 50% of the cuBLAS level thoughput.
<img src="https://alexarmbr.github.io/images/table3.png" alt="table3"></p>

<h2 id="kernel-4---makeshift-async-copy">Kernel 4 - Makeshift Async Copy</h2>
<p>Each optimization addresses the least performant part of the previoius kernel. After applying each optimization, if it worked, the least performant part of the kernel should change. Before fixing the shared memory bank conflicts, the shared memory operations inside the inner loop were the bottleneck. After eliminating bank conflicts, the inner loop becomes much more efficient, and the bottleneck is once again the latency of the global memory to shared memory transfer. This was addressed with vectorizing and loop unrolling in <a href="#kernel-2---vectorized-memory-copy-and-loop-unrolling">Kernel 2</a>, but after fixing bank conflicts, NSight Compute is telling us that there is more latency here to hide. Here is pseudocode of the current loop nests, with a zoomed in view of the code that needs to be improved:
<img src="https://alexarmbr.github.io/images/long_scoreboard_stall_kernel3.png" alt="long_scoreboard_stall_kernel3">
Once again the issue is that the line which performs the global memory to shared memory copy:</p>

<div><pre><code><span>dst_float4</span><span>[</span><span>dst_index</span><span>]</span> <span>=</span> <span>src_float4</span><span>[</span><span>src_index</span><span>];</span>
<span>// shared memory        // global memory</span>
</code></pre></div>

<p>This^ is a blocking operation from the perspective of hardware, in the sense that when a given thread executes the resulting assembly the thread will be stalled for the full duration of to data arriving from global memory. The above line is equivalent to this:</p>

<div><pre><code><span>float4</span> <span>tmp</span> <span>=</span> <span>src_float4</span><span>[</span><span>src_index</span><span>];</span> <span>// global memory to register</span>
<span>dst_float4</span><span>[</span><span>dst_index</span><span>]</span> <span>=</span>  <span>tmp</span><span>;</span> <span>// register to shared memory</span>
</code></pre></div>
<p>The global memory to register transfer, which is the first line, incurs latency because data is coming from off chip. When it comes time to store from register to shared memory (second line) the hardware detects that the data needed from global memory has not yet arrived in <code>tmp</code>, and execution stalls until it arrives. In <a href="#kernel-2---vectorized-memory-copy-and-loop-unrolling">Kernel 2</a> we addressed this performance issue by amortizing the latency over more data moved per transaction (vectorizing) and helping the compiler to interleave multiple loads/stores, which hides latency (loop unrolling). But NSight Compute tells us that even after these optimizations, this sort of stall, on this line specifically, accounts for about ~20% of the total clock cycles that the kernel spends stalled.</p>

<p>The key observation here is that if we break down the <code>dst[...] = src[...]</code> line into its two constituent parts, we can break them apart so that other useful work is being done while the data is in flight from global memory.
The general idea is that we can prefetch data from global memory into register storage, one <code>block_k</code> ahead of the <code>block_k</code> we are currently computing on. At a very high level we want to go from this:</p>
<div><pre><code><span>float4</span> <span>tmp</span> <span>=</span> <span>src_float4</span><span>[</span><span>src_index</span><span>];</span> <span>// global memory to register</span>
<span>// (stall while we wait for data to arrive from memory)</span>
<span>dst_float4</span><span>[</span><span>dst_index</span><span>]</span> <span>=</span>  <span>tmp</span><span>;</span> <span>// register to shared memory</span>
<span>{</span>
    <span>// compute inner loop for current block tile</span>
<span>}</span>
</code></pre></div>

<p>to this:</p>
<div><pre><code><span>float4</span> <span>tmp</span> <span>=</span> <span>src_float4</span><span>[</span><span>src_index</span><span>];</span> <span>// global memory to register</span>
<span>{</span>
    <span>// compute inner loop for previous block tile</span>
<span>}</span>
<span>dst_float4</span><span>[</span><span>dst_index</span><span>]</span> <span>=</span>  <span>tmp</span><span>;</span> <span>// register to shared memory</span>
</code></pre></div>

<p>The key improvement being made here is that we are initiating the load of data from global memory corresponding to <code>block_k</code>, and performing the compute corresponding to <code>block_k</code>-1 concurrently. In doing so we are hiding the latency of loading the <code>block_k</code> tiles of $A$ and $B$ with the computation corresponding to the <code>block_k</code>-1 tiles.</p>

<p><img src="https://alexarmbr.github.io/images/concurrent_fetch_compute.png" alt="concurrent_fetch_compute"></p>

<p>This improved overlapping of data movement and compute is accomplished by</p>
<ul>
  <li>adding new register storage to hold the data that is prefetched from global memory</li>
  <li>breaking up the global to shared memory transfer into its two components, putting these two components on opposite sides of the inner loop (over warp tiles and mma tiles)</li>
  <li>and tweaking the position of the two <code>__syncthreads()</code> in the outer loop to allow for the concurrency we want, while still preventing race conditions.</li>
</ul>

<p>Here is before/after pseudocode which shows how the data movement changes.
<img src="https://alexarmbr.github.io/images/prefetch.png" alt="prefetch"></p>

<p>This produces a nice speedup over the previous kernel, and gets us to ~70% of the HGEMM kernel.</p>

<p><img src="https://alexarmbr.github.io/images/table4.png" alt="table4"></p>

<h3 id="gpu-occupancy-digression">GPU occupancy (digression)</h3>
<p>The potential cost of this optimization is that it requires additional register storage, each thread block stores two additional block tiles worth of data in register memory. According to the Launch Statistics section in NSight Compute, we go from using 104 registers per thread in Kernel 3, to 166 registers per thread in Kernel 4. This increase resource usage per thread has the <em>potential</em> to hurt kernel performance because it can impact how many threads the hardware is capable of executing concurrently. This is a quick digression on why increasing register use per thread has the potential to hurt performance, but why in this case, it doesn’t.</p>

<p>This gets to a topic called occupancy which is central to the CUDA hardware and software implementation. Each streaming multiprocessor (SM) will maintain block, warp, and thread execution state (shared memory, registers, program counter) on chip, for as many thread blocks as can be fit. The amount of thread blocks that can be fit on an SM depends on:</p>
<ol>
  <li>how much shared memory, registers per thread, and number of threads each thread block needs to execute (this a property of a given kernel, and the launch configuration of that kernel)</li>
  <li>how much shared memory, registers per thread, and number of threads the SM can handle at once (this is a property the device, and improves from generation to genereation)</li>
</ol>

<p>If a given kernel implementation and launch configuration require only a small number of registers, a few threads, and a small amount of shared memory per block, an SM can execute lots of thread blocks concurrently. When multiple thread blocks are executing concurrently on an SM, context switching between them is free. This allows the hardware to hide stalls and latency simply by tracking which threads are capable of executing their next instruction and which are not, and issuing instructions for whichever threads are ready. The more threads the SM has to choose from, the better this works. This is called <a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#hardware-multithreading">hardware multithreading</a>, and lots of older resources on CUDA performance talk about it as the primary guiding principle for writing fast kernels.</p>

<p>At this point, the limiting factor on the number of thread blocks that can be resident on an SM is shared memory. Each thread block is allocating a $(256,64)$ tile of shared memory for for the $A$ matrix, and a $(64,128)$ tile of shared memory for the $B$ matrix. This works out to 49KB of the total of 62KB of shared memory per SM, which limits the number of thread blocks that can be resident on an SM to one at a time. So in this instance, since shared memory is the limiting factor, using more registers per thread doesn’t matter.</p>

<p>The high performance GEMM kernels typically have lower occupancy, meaning they use more shared memory and register memory per thread, and have less threads resident on an SM at once. This is primarily because of the need for high arithmetic intensity; in order to keep compute units busy with limited memory bandwidth, the more compute per thread at low levels of the memory hierarchy, the better. But the drawback of low occupancy is that the GPU will be less effective at automatic latency hiding via context switching. We can deal with this tradeoff by structuring our kernel to allow overlap between compute and data movement, this chapter is an example of this.</p>

<p>The two newest NVIDIA architectures, Ampere and especially Hopper, introduce dedicated hardware suppport that allows us to perform several components of GEMM kernels asychronously (more on this in <a href="#lessons-learned-newer-gpus-are-better">conclusion</a>). This hardware support makes writing efficient, low occupancy kernels such as these ones much easier.</p>

<h2 id="kernel-5---tune-tile-dimensions">Kernel 5 - Tune Tile Dimensions</h2>
<p>Up until this point, I found that after 10 minutes or so of looking at profiling results in NSight Compute, I would know exactly where the bottleneck in the kernel was, and what was causing it. After Kernel 4, which achieves about 70% of the cuBLAS thoughput, the profiler generally would not point to a single performance issue. In hindsight this was because the remaining 30% between kernel 4 and cuBLAS is the product of many smaller inneficiences, as opposed to one single one, and performance optimization began to have more of a trial and error flavor based on hunches, some of which turned out to be wrong. This chapter contains a description of two optimizations, that when implemented together produced a decent speedup.</p>

<h3 id="tune-tile-dimensions">tune tile dimensions</h3>

<p>At this point I began to wonder, if my kernel were still memory bound, how would I know? If you are using single precision FFMA instructions the “Speed of Light” section in NSight Compute will show you a roofline chart, but not if you are using tensor cores. I was inspired by <a href="https://www.cse.ust.hk/~weiwa/papers/yan-ipdps20.pdf">this</a> paper to try to figure it out myself in a back of the envelope sort of way.</p>

<p>A more actionable way to formulate the “am I memory bound?” question is “does the arithmetic intensity of my kernel exceed the machine’s balance point?”</p><p>

\[\frac{FLOPs\ performed}{bytes\ moved} \stackrel{?}{&gt;} \frac{\tau}{\beta}\]

</p><p>So for the left hand side, we need to substitute in numbers that are specific to our kernel, and for the right hand side we need to subsitute numbers specific to our hardware. <a href="#arithmetic-intensity-as-a-function-of-tile-dimensions">This</a> section went over how arithmetic intensity is a function of tile sizes. Namely for tile dimensions $BM,BN$ and $BK$, the arithmetic intensity we should expect is $\frac{BM * BN}{BM+BN}$. Here is a refresher of this, specific to the block tile level
<img src="https://alexarmbr.github.io/images/intensity_block_tile_dims.png" alt="intensity_block_tile_dims"> 
Notice how $BK$ cancels out in this calculation. This means when thinking about arithmetic intensity, the size of our tiles along the $K$ dimension are irrelavent. However, when thinking about other aspects of performance it is not irrelavent (more on this later).</p>

<h4 id="m-and-n-dimensions--l2-cache-locality">M and N Dimensions / L2 cache locality</h4>
<p>We now need to subsitute in numbers for our machine balance. Earlier in the roofline charts we set $\tau_{HMMA}$ to the throughput of the cuBLAS hgemm kernel, which likely errs on the side of being an underestimate. In this case, the goal is to choose tile dimensions that are large enough to put us comfortably in the compute bound regime of the roofline chart, so I would like to instead err on the side of overestimating the arithmetic throughput in the numerator of the machine balance, and err on the side of underestimating the memory bandwidth in the denominator.</p>

<p>A reasonable overestimate of $\tau_{HMMA}$ is 65,000 GFLOP/sec, which is the theoretical peak found on the T4 data sheet.</p>

<p>When it comes to the memory bandwidth in the denominator, we want to conservatively estimate our achieved memory bandwidth. In order to do this, we need to consider the effect of the L2 cache. The L2 cache is shared between the 40 streaming multiprocessors on the T4. In practice this means that when one thread block accesses data from DRAM, it is moved into the L2 cache, and accesses to the same data originating from other thread blocks will hit the L2 cache, until this piece of data is evicted.</p>

<p>According to <a href="https://stackoverflow.com/questions/46660053/is-blockidx-correlated-to-the-order-of-block-execution">people on the internet</a>, thread blocks execute in increasing order of their flattened block index. The official CUDA programming guide says that different thread blocks execute independently, and the programmer should not assume any relationship between different thread blocks. So relying on this assumption for correctness would probably be unwise, but for a quick and approximate calculation on L2 cache locality it is helpful.
<img src="https://alexarmbr.github.io/images/l2_cache_locality.png" alt="l2_cache_locality">
The basic idea here is that he accesses to the $A$ matrix from thread blocks executing at the same time have much better locality than accesses to the $B$ matrix. Most of the access to $A$ should hit the L2 cache, whereas most of the accesses to $B$ should miss, which means we should achieve roughly a 50% hit rate for global memory accesses. This means our <em>achieved</em> memory bandwidth is a 50/50 weighted sum between the DRAM bandwidth and our L2 cache bandwidth. Substituting this weighted sum in the denominator of the expression for machine balance finally gives us:</p><p>

\[\frac{BM * BN}{BM+BN} \stackrel{?}{&gt;} \frac{\tau_{HMMA}}{0.5 * \beta_{DRAM} + 0.5 * \beta_{L2}}\]

</p><p>Plugging the current block tile dimensions ($BM=256$ and $BN=128$), memory bandwidths, and theoretical arithmetic throughputs gives us</p><p>

\[\frac{256 * 128\ FLOPs}{256 + 128\ bytes} \stackrel{?}{&gt;} \frac{65,000 * 10^9\ FLOPs/sec}{0.5 * 220 * 10^9 + 0.5 * 1280 * 10^9\ bytes/sec}\]

</p><p>which works out to an arithmetic intensity of $85.3 \frac{FLOPs}{byte}$ and a machine balance of $87.24 \frac{FLOPs}{byte}$. The fact that these two numbers are very close suggests that global memory access may still be dominating our overall runtime. If we can spare the space in shared memory, increasing our $BN$ dimension from 128 to 256 might be worthwhile. If $BM$ and $BN$ are both 256, our estimated arithmetic intensity becomes $128.0 \frac{FLOPs}{byte}$, which should hopefully put us comfortablly in the compute bound regime.</p>

<p>When considering the next level down in the hierarchy, the high shared memory bandwidth gives us a bit more wiggle room. Our swizzled shared memory layouts should result in bank conflict free access, giving us the full bandwidth of 3662 GB/sec. The $WM$ and $WN$ dimensions of the warp tiles are both 64. Plugging numbers into here:</p><p>

\[\frac{WM * WN}{WM+WN} \stackrel{?}{&gt;} \frac{\tau_{HMMA}}{\beta_{shmem}}\]

</p><p>gives an arithmetic intensity of $32 \frac{FLOP}{byte}$ and a balance point of $17.7 \frac{FLOP}{byte}$. Thus it is safe to assume that shared memory loads are not the dominant factor in our kernel’s runtime. However, in order to err on the size of more arithmetic intensity I also ended up increasing $WM$ and $WN$ while making $WK$ smaller.</p>

<h4 id="k-dimension">K Dimension</h4>
<p>Different considerations come into play when considering our tile sizes along the K dimension. In our pencil and paper analysis, the tile size along the K dimension cancels out of the expression for arithmetic intensity. When thinking about tile lengths along this dimension, different considerations come into play. First, we can use it to adjust the total size of our tiles without affecting arithmetic intensity. In the case of block tiles, the total amount of bytes of shared memory they consume is $BK* (BM+ BN)* sizeof(half)$, thus increasing $BK$ by a unit increases the total size of the block tiles by $(BM+ BN)* sizeof(half)$. In deciding the length of the block tiles along the K dimension, this becomes the primary consideration. With $BN=256,BM=256$ we choose $BK=32$, with these dimensions the total amount of shared memory used by tiles of $A$ and $B$ works out to 32KiB, which is exactly half of the shared memory per streaming multiprocessor. This decision makes sense in the next section, which discusses a technique called shared memory double buffering. This optimization involves allocating two buffers in shared memory corresponding to each input matrix, so one can be written to while the other is being read. When double buffering is implemented, with these tile dimensions we will be using every available byte of shared memory on the device.</p>

<h3 id="tile-dimensions---longer-and-thinner">tile dimensions - longer and thinner</h3>
<p>Here is a visualization of the before/after:
<img src="https://alexarmbr.github.io/images/tile_dims_adjustment.png" alt="tile_dims_adjustment.png">
Both block tiles and warp tiles are made longer, and narrower along the K dimension, in order to increase arithmetic intensity. For the sake of time I combined this optimizations with the optimizations discussed below, so I did not measure the performance improvmement of this in isolation.</p>

<h2 id="kernel-5---optimize-index-calculation">Kernel 5 - Optimize Index Calculation</h2>
<p>At this point I was at about 70% of cuBLAS performance, my main strategy for using NSight Compute was to compare kernel metrics between my kernels and the cuBLAS HGEMM kernel. While the source code of the cuBLAS HGEMM implementation is not released by NVIDIA, looking at its metrics collected by NSight Compute can give us some insights into the sorts of optimization techniques that the clever folks at NVIDIA might have used when writing it.</p>

<p>The one thing that jumped out at me was that the total number of executed instructions of cuBLAS HGEMM was $94,175,232$, whereas Kernel 4 was executing $216,227,840$, over twice as many instructions as compared to Kernel 4. While Kernel 4 partly compensates for this by having a lower cycles per instruction ratio (8ish, vs 12ish for cuBLAS), this is certainly worth looking into.</p>

<p>So I wondered, why is my kernel executing twice as many instructions? Expanding the instruction mix section in NSight Compute gives us more information.
<img src="https://alexarmbr.github.io/images/instruction_mix_comparison.png" alt="instruction_mix_comparison">
The answer is that Kernel 4 is performing way more index calcuation related instructions than the cuBLAS kernel. The <code>LOP</code>, <code>IADD3</code>, and <code>SHF</code> instructions are integer and logical instructions, these are different pipelines from the tensor core and can execute concurrently with floating point math happening elsewhere on the chip. However, each warp scheduler on a streaming multiprocessor can only issue a single instruction per cycle, and so the large number of index calculation instructions is likely crowding out the issuing of the <code>HMMA</code> instructions, these are the tensor core instructions doing the heavy lifting. So what are these integer and logical instructions doing, and why are there so many of them?</p>

<p>According to NSight Compute, 92% of the total instructions executed by Kernel 4 are in the loop nest where each warp loads its region of data from shared memory into register memory, and then performs an outer product over local matrices stored in register memory with a series of <code>HMMA</code> instructions. The three nested loops that map the <code>HMMA</code> instructions to their position are all fully unrolled, so there isn’t any runtime index calculation required there.</p>

<p>However, the <code>HMMA</code> instructions operate on $8$ by $8$ tiles stored in registers, and before the compute phase the threads in each warp work collaboratively to load all of these tiles from swizzled shared memory into register memory using the <code>ldmatrix</code> PTX instruction (see <a href="#how-to-use-tensor-cores">here</a>) for an explanation of <code>ldmatrix</code>. Since at this point we are all the down at the bottom level of the tile hierarchy, the tiles are very small, and consequently we are doing this index calculation <em>lots</em> of times ($O(\frac{N^3}{8})$), and it involves multiplying by a bunch of strides, computing a modulo WRT the thread index, and several logical operations to apply the swizzling function, all of which happens at runtime.</p>

<p><img src="https://alexarmbr.github.io/images/index_calculation_inneficient.png" alt="index_calculation_inneficient"></p>

<p>In order to make this more performant, we should move as much of this calculation as possible to happen at compile time, and whatever needs to happen at runtime should be as streamlined as possible. In the index calculation code shown above, fundamentally there are three distinct and dependent steps</p>
<ol>
  <li>First each warp computes the memory address of the top left corner of the mma tile</li>
  <li>Each thread calculates the memory address of the element it will load, relative to (1)</li>
  <li>Because our shared memory layout is swizzled, each thread applies the swizzle function to the address computued in (2)
in order to get the correct memory address in the swizzled layout.</li>
</ol>

<p>All three steps are done for each of the 8x8 MMA tiles. Below is a visualization of this, the diagram below is a mini example where each MMA tile is four rows and one column, and each warp tile has 2x8 MMA tiles (using simpler examples like this allows us to make all the details as explicit as possible, and the <img title=":smiling_imp:" alt=":smiling_imp:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f608.png" height="20" width="20"> is in the details).</p>

<p><img src="https://alexarmbr.github.io/images/swizzled_index_calculation_inneficient.png" alt="swizzled_index_calculation_inneficient"></p>

<p>In the middle column, each thread has calculated the address of the value it is going to load, in the unswizzled layout. Each iteration, these pointers are advanced to the right by one column, until we get to the end of the warp tile at which point we go down to the next set of rows. If it weren’t for the swizzled layout, we could just advance the pointers by one each iteration, i.e. <code>thread_row+=1</code>. However, because the data is stored in a swizzled layout, advancing the pointers over to the next group of MMA tiles is not simply a matter of incrementing by one.</p>

<p>While incrementing by one will not work for iterating over a swizzled layout, we can achieve the equivalent effect by XORing each threads pointer with a constant.
<img src="https://alexarmbr.github.io/images/swizzled_index_calculation_efficient.png" alt="swizzled_index_calculation_efficient">
This reduces the amount of index calculation from ~13 operations in between each <code>ldmatrix</code>, down to a single XOR. After applying this optimization, the total number of instructions executed goes down to ~90M, which is slightly less than cuBLAS.</p>

<p>This illustrates the basic principle of efficiently iterating through a swizzled data layout.  In the <a href="https://github.com/alexarmbr/matmul-playground/blob/main/src/kernel5.cu#L10">actual code</a>, it is a bit more complicated because the swizzle function is more complicated, and we need to iterate through the tiles of A and B which have different dimensions from each other. Also the loops containing the <code>ldmatrix</code> instructions are manually unrolled, this makes the XORing easier, and also might allow the compiler to do a better job of interleaving the <code>ldmatrix</code> and <code>mma.sync</code> instructions to balance load between the two different pipelines.</p>

<p>The optimized index calcuation, loop unrolling, and adjusted tile dimensions are all implemented as part of the same kernel, that achieves a hard fought 1.2x speedup over the last one, and gets us to 86.7% of cuBLAS throughput.
<img src="https://alexarmbr.github.io/images/table5.png" alt="table5"></p>

<h2 id="kernel-6---double-buffering">Kernel 6 - Double Buffering</h2>
<p>Back to the profiler (for the last time). At this point many of the metrics between my kernel and cuBLAS were starting to look somewhat similiar. One thing that jumped out at me was that the threads in my kernel spend more time stalled on <code>__syncthreads()</code> than the cuBLAS kernel. At this point my kernel had a CPI (cycles per instruction) of 14, and about 2.6 of these cycles come from sychronization stalling. So this was not an egregious performance issue, but noticeable. A technique called double buffering enables you to remove one of the two <code>__syncthreads()</code> in the inner loop. After a bit of pondering I realized that this provides no guaruntee of a proportional decrease in cycles stalled on <code>__syncthreads()</code> (if you remove one <code>__syncthreads()</code>, threads might spend twice as much time stalled on the other). However, double buffering should also allow for a bit more instruction level parallelism inside the main loop, and it is implemented in CUTLASS kernels, and I had the shared memory to spare, so why not.</p>

<p>The data dependencies inside the main loop of our current GEMM kernel necessitate having two <code>__syncthreads()</code> in order to prevent race conditions in shared memory
<img src="https://alexarmbr.github.io/images/two_syncthreads.png" alt="two_syncthreads">
If we removed either, race conditions would occur because the thread to data mapping is different when writing to shared memory vs. reading it. This is because any given thread is computing on different values than the ones that it fetched from global memory and wrote to shared memory. This means that sychronization points are required to prevent race conditions, because the whole thread block must wait until all threads are done writing to shared memory before any thread starts reading from shared memory.</p>

<p>The cost of these sychronization points is less parallelism and potentially less hardware utilization. As the diagram above shows, there are four main components to the main loop.</p>
<ol>
  <li>prefetching the next block tile into registers</li>
  <li>shared memory to register transfer in preparation for compute</li>
  <li>compute</li>
  <li>writing the prefetched data back from registers to shared memory</li>
</ol>

<p>As the diagram above illustrates #4 is kept seperate from the other three because it involves writing to the data that is being read in #2, i.e. all 256 threads in a block must complete #2 before any start #4. This seperation is bad for performance, because it limits the compilers ability to interleave instructions of different types to balance load across different hardware pipelines.</p>

<p>The idea behind double buffering is that if we allocate an extra pair of shared memory buffers for the block tiles of $A$ and $B$, we can write to one pair of buffers concurrently with the other being read. This allows us to remove the second <code>__syncthreads()</code> from the mainloop. This should make things a bit faster.</p>

<p><img src="https://alexarmbr.github.io/images/one_syncthreads.png" alt="one_syncthreads"></p>

<p>The two things that changed here are the removal of one of the <code>__syncthreads()</code>, and the addition of an index that we always use  (<code>%2</code>) to track which of the two buffers is being read, and which is being written on any given iteration. The buffer that is being read and the buffer that is being written switches each iteration.</p>

<p><img src="https://alexarmbr.github.io/images/double_buffering.png" alt="double_buffering"></p>

<p>This results in a small speedup over the previous kernel. But at this stage of trying to optimize an already highly optimized kernel, I’ll take what I can get.</p>

<p><img src="https://alexarmbr.github.io/images/table6.png" alt="table_6"></p>

<h2 id="conclusion">Conclusion</h2>
<h2 id="things-i-didnt-do">things I didn’t do</h2>
<p>And this is where I called it a day! There are two avenues for further performance improvement, but the time I alloted to work on this ran out. The former is a lot easier than the latter.</p>
<ul>
  <li>
<strong>optimized epiloge</strong>- As a reminder, the GEMM problem is $D=\alpha * A * B + \beta * C$. This is two computations stuffed into one kernel. The bulk of the compute is in the matrix multiplication $C^*=A * B$. Once we multiply the two matrices, then we do $D = \alpha * C^*  + \beta * C$, this is generally referred to as the kernel epilogue. The former is an $O(N^3)$ problem, the later is $O(N^2)$. When N is large, the matrix multiplication dominates the runtime of the combined algorithm, when N is smaller the epilogue is more significant. The article focused entirely on the matrix multiplication, as this is the most interesting and important component of the GEMM problem. The kernel epilogue I used in all six kernels is innefficient - once the matrix multiplication is complete, the result is scattered across thread registers according to the <code>m16n8k8</code> MMA layout (see <a href="#appendix">below</a>), and they are written directly back to memory. This write is uncoalesced and consequently achieves less than ideal bandwidth and latency. Improving this would likely narrow the gap between Kernel 6 and cuBLAS for smaller matrix sizes.</li>
  <li>
<strong>manual instruction mix tuning for inner loop</strong>- Projects like <a href="https://github.com/NervanaSystems/maxas/wiki/SGEMM">this</a> and <a href="https://github.com/daadaada/turingas">this</a> match/exceed the performance of cuBLAS using custom built assemblers that allow them to write the kernel entirely in SASS. The inner loop of a GEMM kernel consists of shared memory loads and math instructions. If too many instructions of one type are grouped together, hardware pipelines will get overloaded and stall cycles will be incurred. If you want to write your kernels entirely in CUDA and PTX as I did, then instruction scheduling is the job of the compiler, the fact that I was able to get &gt;90% of cuBLAS performance without any inlined assembly means that nvcc probably does a pretty good job at it. However, if one were really determined to write a kernel that is as fast or faster than cuBLAS for a range of matrix sizes, this would avenue would likely be necesssary.</li>
</ul>

<h2 id="performance-on-different-matrix-sizes">performance on different matrix sizes</h2>
<p>Here is a plot that shows the performance of the kernels I wrote, compared to cuBLAS, for a bunch of different matrix dimensions.
<img src="https://alexarmbr.github.io/images/hgemm_performance.png" alt="hgemm_performance"></p>

<p>Note that the gap between the fastest kernel I wrote, and cuBLAS HGEMM is slightly larger for smaller matrices, possibly due to my unoptimized epilogue. Also possibly due to the fact that cuBLAS is selecting kernels that have been specifically tuned for those matrix dimensions.</p>

<h2 id="lessons-learned-newer-gpus-are-better">lessons learned, newer GPUs are better</h2>
<p>Given how many people and companies these days are buying NVIDIA GPUs almost exclusively for the purpose of running matrix multiplications, it seems like lots of work goes into improving the tensor cores in terms of programmability and performance between successive architectures. The tensor core throughput goes up by an order of magnitude with each new SM architecture, and the memory bandwidth also increases, but not proportionally.</p>

<p>In order to make the task of programming these powerful but imbalanced machines more manageable, the more recent Ampere and Hopper architectures introduced hardware support that enable several important parts of a GEMM kernel to run asychronously with respect to the rest of the SM. Ampere introduced hardware support for <a href="https://docs.nvidia.com/cuda/ampere-tuning-guide/index.html#asynchronous-data-copy-from-global-memory-to-shared-memory">asychronous data copying</a> from global memory to shared memory, I implemented a sort of hacked version of this using extra registers in <a href="#kernel-4---makeshift-async-copy">Kernel 4</a>. The Hopper architecture introduced something even fancier called the <a href="https://docs.nvidia.com/cuda/hopper-tuning-guide/index.html#tensor-memory-accelerator">Tensor Memory Accelerator</a>, which is essentially a copy engine that can perform index calculation, and initiate global memory transfers asychronously with respect to the rest of the SM. Thus developers writing kernels for Hopper probably dont have to worry about the efficiency of index calculation (like I did <a href="#kernel-5---optimize-index-calculation">here</a>), because this is offloaded to dedicated hardware in the TMA. Hopper also has asychronous tensor core instructions, that can read/write from/to shared memory, rather than registers (see <a href="https://research.colfax-intl.com/cutlass-tutorial-wgmma-hopper/">here</a>).</p>

<p>All of this asychronicity is a great thing for low occupancy, register hungry GEMM kernels. As discussed <a href="#gpu-occupancy-digression">here</a>, large arithmetic throughput means we need lots of fast memory to cache data, which means we cant run that many threads per SM, which means the GPU wont automatically hide our latency by context switching, which means we the programmer need to think more about how our latency is being hidden. This is where asychronicity is helpful.</p>

<p>All of this means that Hopper is kind of a new and different beast, if you look at GEMM kernels in CUTLASS that target Hopper the code has a different stucture than all of the other pre <code>sm_90</code> kernels. Hopper kernels use a producer/consumer pattern, where a relatively small number of producer threads are initiating asynchronous data copies with the TMA, and then consumer threads are managing the tensor cores. I have never worked on kernels targetting Hopper so I dont know much about this at the moment, <a href="https://hazyresearch.stanford.edu/blog/2024-05-12-tk">this</a> article provides an interesting overview of the user experience of writing kernels for Hopper.</p>

<p>This is all to say that the kernels discussed here target the Turing architecture, which was SOTA in 2018, and if you are writing kernels targeting Ampere or Hopper, the techniques you employ for latency hiding will be different and easier. I used the Tesla T4 GPU because you can rent them on AWS for ~50 cents/hour, which is about as much money as I want to spend on EC2 instances. Using an older GPU was a blessing and a curse for this project, the curse was that no special hardware support was available for hiding memory latency on calculating indices, the blessing was that I had to do all this myself which was an educational experience!</p>

<h2 id="resources--acknowledgements">Resources / Acknowledgements</h2>
<p>Most of these resources have already been linked to in various places throughout this article, but I wanted to put them all in one place. These are some resources that have educated and inspired me, in no particular order</p>

<ul>
  <li>I learned about the roofline model from Prof. Vuduc’s Intro to High Performance Computing class at Georgia Tech, all of the course videos are available <a href="https://edstem.org/us/join/GT3Qcc">here</a>, these videos are an amazing free resource if you have the time and inclination to watch them. The part of this article about rooflines and computational intensity is similiar to what is presented in the “Basic Model of Locality” section.</li>
  <li>
<a href="https://siboehm.com/articles/22/CUDA-MMM">This</a> article was a major source of inspiration for this project. Simon’s other articles are excellent as well, this is probably one of my favorite blogs on the internet at the moment.</li>
  <li>
<a href="https://horace.io/brrr_intro.html">Another</a> excellent blog about a systems view of ML. This article in particular is a very readable explanation of why things like memory bandwidth and arithmetic intensity matter when training neural nets on GPUs.</li>
  <li>Great <a href="https://hazyresearch.stanford.edu/blog/2024-05-12-tk">article</a> from a systems ML lab at stanford about the kernel engineering for the Hopper architecture.</li>
  <li>
<a href="https://github.com/NVIDIA/cutlass">This</a> is NVIDIA’s CUTLASS project, provides a bunch of abstractions that make it easier to write fast kernels.</li>
</ul>

<h2 id="are-you-hiring-gpu-nerds">Are you hiring GPU nerds?</h2>
<p>I am usually not one for self promotion, but I recently took a bit of a break from work, and now am back on the job market. If you are a hiring manager who is looking for someone to fiddle around with kernels, profilers, and/or compilers please email me!</p>


  </div>

</article>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Packing Input Frame Context in Next-Frame Prediction Models for Video Generation (226 pts)]]></title>
            <link>https://lllyasviel.github.io/frame_pack_gitpage/</link>
            <guid>43736193</guid>
            <pubDate>Sat, 19 Apr 2025 13:17:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lllyasviel.github.io/frame_pack_gitpage/">https://lllyasviel.github.io/frame_pack_gitpage/</a>, See on <a href="https://news.ycombinator.com/item?id=43736193">Hacker News</a></p>
<div id="readability-page-1" class="page">
    <div>
            <p><img src="https://lllyasviel.github.io/frame_pack_gitpage/img/logo.png">
            </p>
            <br>
            <h2>
                Packing Input Frame Context in Next-Frame Prediction Models for Video Generation
            </h2>
            
            <p>
                Stanford University
            </p>
        </div>

    <div>
                <ul>
                    <li>Diffuse thousands of frames at full fps-30 with 13B models using 6GB laptop GPU memory.</li>
                    <li>Finetune 13B video model at batch size 64 on a single 8xA100/H100 node for personal/lab
                        experiments.</li>
                    <li>Personal RTX 4090 generates at speed 2.5 seconds/frame (unoptimized) or 1.5 seconds/frame
                        (teacache).</li>
                    <li>No timestep distillation.</li>
                    <li><b>Video diffusion, but feels like image diffusion.</b></li>
                </ul>
                
            </div>

    <div>
            <h2>
                Understand FramePack in 5 seconds
            </h2>
            <p>A next-frame (or next-frame-section) prediction model looks like this:</p>
            <p><img src="https://lllyasviel.github.io/frame_pack_gitpage/img/nfp.png">
            </p>
            <br>
            <div>
                <p>So we have many input frames and want to diffuse some new frames.</p>
                <p>The idea is that we can encode the input frames to some GPU layout like this:</p>
            </div>
            <p><img src="https://lllyasviel.github.io/frame_pack_gitpage/img/gpu.png">
            </p>
            <br>
            <div>
                <p>This chart shows the logical <b>GPU memory layout</b> - frames images are not stitched.</p>
                <p>Or, say the context length of each input frame.</p>
                <p>Each frame is encoded with different patchifying kernel to achieve this.</p>
                <p>For example, in HunyuanVideo, a 480p frame is likely 1536 tokens if using (1, 2, 2) patchifying
                    kernel.</p>
                <p>Then, if changed to (2, 4, 4) patchifying kernel, a frame is 192 tokens.</p>
                <p>In this way, we can change the context length of each frame.</p>
                <p>The "more important" frames are given more GPU resources (context length) - in this example, F0 is
                    the most important as it is the nearest frame to the "next-frame prediction" target.</p>
                <p>This is O(1) computation complexity for streaming - Yes, a constant, not even O(nlogn) or O(n).</p>
            </div>
        </div>

    <div>
            <h2>
                But wait, what if ...
            </h2>
            <div>
                <p>The above idea is a very brief concept - many questions can be asked like:</p>
                <p>What if the importance of frames does not follow this simple pattern?</p>
                <p>What if I want different compression rate?</p>
                <p>If I want image-to-video, isn't the first frame most important?</p>
                <p>What if I have some user frames and I want those frames to be more important?</p>
                <p>...</p>
                <p>Great - In fact these are <b>FramePack Scheduling</b>, like these:</p>
            </div>
            <p><img src="https://lllyasviel.github.io/frame_pack_gitpage/img/ab.png">
            </p>
            <br>
            <div>
                <p>So one can get different compression patterns.</p>
                <p>One can even make the starting frames equally important so image-to-video will be happier.</p>
                <p>And all those schedulings are O(1).</p>
                <p>We have a detailed evaluation of many schedulings in the paper!</p>
            </div>
        </div>

    <div>
            <h2>
                Anti-drifting Sampling
            </h2>
            <div>
                <p>Drifting is a common problem of any next-what-what prediction model.</p>
                <p>Drifting refers to the quality degradation as the video becomes longer.</p>
                <p>Sometimes the problem is also called error accumulation or exposure bias.</p>
                <p>To see an example, you can find an arbitrary image-to-video model and
                    try to generate long videos by repeatedly using the last generated frame as inputs. The result will
                    mess up quickly after you do this 5 or 6 times, and everything will severely degrade after you do
                    this about 10 times.</p>
                <p>See also our paper for some experiments on existing methods like history noise augmentation, special cfg
                    guidance, rolling diffusion timesteps, and so on. We find out that, to solve drifting
                    fundamentally, we need to break causality and make the sampling bi-directional.</p>
                <p>Consider these sampling methods:</p>
            </div>
            <p><img src="https://lllyasviel.github.io/frame_pack_gitpage/img/sample.png">
            </p>
            <div>
                <p>(the shadowed squares are the frames generated in each streaming inference)</p>
                <p>Note that only the "vanilla sampling" is causal.</p>
                <p>Both the "anti-drifting sampling" and "inverted anti-drifting sampling" are bi-directional.</p>
                <p>The "inverted anti-drifting sampling" is important. This method is the only one that always treats
                    the first frame as an approximation target in all inferences. This method is very suitable for
                    image-to-video.</p>
            </div>
            <br>
        </div>

    <div>
            <h2>
                Image-to-5-Seconds (30fps, 150 frames)
            </h2>
            <p>All results are computed by RTX 3060 6GB laptop with 13B HY variant. (Videos compressed by h264crf18
                    to fit in GitHub repos.)</p>

            
        </div>

    <div>
            <h2>
                Image-to-60-Seconds (30fps, 1800 frames)
            </h2>
            <p>All results are computed by RTX 3060 laptop 6GB with 13B HY variant. (Videos compressed by h264crf18
                    to fit in GitHub repos.)</p>

            
        </div>

    <div>
            <h2>
                BibTeX
            </h2>
            <pre>@article{zhang2025framepack,
    title={Packing Input Frame Contexts in Next-Frame Prediction Models for Video Generation},
    author={Lvmin Zhang and Maneesh Agrawala},
    journal={Arxiv},
    year={2025}
}
</pre>
        </div>

    

    


</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Android phones will soon reboot themselves after sitting unused for three days (273 pts)]]></title>
            <link>https://arstechnica.com/gadgets/2025/04/android-phones-will-soon-reboot-themselves-after-sitting-unused-for-3-days/</link>
            <guid>43735902</guid>
            <pubDate>Sat, 19 Apr 2025 12:14:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/gadgets/2025/04/android-phones-will-soon-reboot-themselves-after-sitting-unused-for-3-days/">https://arstechnica.com/gadgets/2025/04/android-phones-will-soon-reboot-themselves-after-sitting-unused-for-3-days/</a>, See on <a href="https://news.ycombinator.com/item?id=43735902">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                      
                      
          <p>A silent update rolling out to virtually all Android devices will make your phone more secure, and all you have to do is not touch it for a few days. The new feature implements auto-restart of a locked device, which will make your personal data harder to extract. It's coming as part of a Google Play Services update, though, so there's nothing you can do to speed along the process.</p>
<p>Google is preparing to release a <a href="https://support.google.com/product-documentation/answer/14343500">new update to Play Services</a> (v25.14), which brings a raft of tweaks and improvements. First <a href="https://9to5google.com/2025/04/14/android-auto-restart-security/">spotted</a> by 9to5Google, the update was officially released on April 14, but as with all Play Services updates, it could take a week or more to reach all devices. When 25.14 arrives, Android devices will see a few minor improvements, including prettier settings screens, improved connection with cars and watches, and content previews when using Quick Share.</p>
<p>Most importantly, Play Services 25.14 adds a feature that Google describes thusly: "With this feature, your device automatically restarts if locked for 3 consecutive days."</p>
<p>This is similar to a feature known as Inactivity Reboot that Apple added to the iPhone in <a href="https://arstechnica.com/gadgets/2024/10/apple-releases-ios-18-1-macos-15-1-with-apple-intelligence/">iOS 18.1</a>. This actually caused some annoyance among law enforcement officials who believed they had suspects' phones stored in a readable state, only to find they were rebooting and becoming harder to access due to this feature.</p>

          
                      
                  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Claude Code Best Practices (317 pts)]]></title>
            <link>https://www.anthropic.com/engineering/claude-code-best-practices</link>
            <guid>43735550</guid>
            <pubDate>Sat, 19 Apr 2025 10:48:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.anthropic.com/engineering/claude-code-best-practices">https://www.anthropic.com/engineering/claude-code-best-practices</a>, See on <a href="https://news.ycombinator.com/item?id=43735550">Hacker News</a></p>
Couldn't get https://www.anthropic.com/engineering/claude-code-best-practices: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Restoring the Galaxian3 Theatre 6, 1992 six player arcade machine (194 pts)]]></title>
            <link>https://philwip.com/2025/04/14/galaxian-3-project-revival/</link>
            <guid>43735239</guid>
            <pubDate>Sat, 19 Apr 2025 09:22:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://philwip.com/2025/04/14/galaxian-3-project-revival/">https://philwip.com/2025/04/14/galaxian-3-project-revival/</a>, See on <a href="https://news.ycombinator.com/item?id=43735239">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				
<h2>Introduction</h2>



<p>During the late 1980s, Namco set out to create the world’s largest arcade game. The result was Galaxian<sup>3</sup>: Project Dragoon; a 28 player behemoth that debuted in April 1990 at the International Garden and Greenery Exposition in Osaka, Japan. Codenamed GH-28, it featured real-time, flat-shaded 3D graphics, powered by hardware derived from the System 21 platform first used by 1988’s <a href="https://www.youtube.com/watch?v=aeBNwT_S69k">Winning Run</a>.</p>



<figure><div>
<p><iframe title="UGSF ARCHIVE #003 Making of GALAXIAN3" width="770" height="433" src="https://www.youtube.com/embed/8eyjfNqTHbk?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe></p>
</div></figure>



<p>In 1991, a 16 player version (‘GM-16’) was released, introducing pre-rendered CGI backgrounds stored on LaserDisc and more performant 3D hardware. This version was sold to several arcades and establishments in the Asia region.</p>



<p>In 1992, the experience was further condensed into a room-sized, six player version: “Galaxian<sup>3</sup> Theatre 6″ (‘GT-6’). This was produced in greater numbers and saw a worldwide release.</p>







<figure data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/philwip.com\/2025\/04\/14\/galaxian-3-project-revival\/&quot;}">
<figure><a href="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/GT6_FLYER1.jpg?ssl=1"><img data-recalc-dims="1" decoding="async" width="770" height="1010" data-attachment-id="8502" data-permalink="https://philwip.com/?attachment_id=8502" data-orig-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/GT6_FLYER1.jpg?fit=850%2C1114&amp;ssl=1" data-orig-size="850,1114" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="GT6_FLYER1" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/GT6_FLYER1.jpg?fit=229%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/GT6_FLYER1.jpg?fit=770%2C1010&amp;ssl=1" data-id="8502" src="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/GT6_FLYER1.jpg?resize=770%2C1010&amp;ssl=1" alt="Promotional flyer for Galaxian3: Project Dragoon featuring details about the arcade game, including a description of its features and gameplay." srcset="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/GT6_FLYER1.jpg?resize=781%2C1024&amp;ssl=1 781w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/GT6_FLYER1.jpg?resize=229%2C300&amp;ssl=1 229w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/GT6_FLYER1.jpg?resize=768%2C1007&amp;ssl=1 768w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/GT6_FLYER1.jpg?resize=76%2C100&amp;ssl=1 76w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/GT6_FLYER1.jpg?w=850&amp;ssl=1 850w" sizes="(max-width: 770px) 100vw, 770px"></a></figure>



<figure><a href="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/GT6_FLYER2.jpg?ssl=1"><img data-recalc-dims="1" loading="lazy" decoding="async" width="770" height="1013" data-attachment-id="8503" data-permalink="https://philwip.com/?attachment_id=8503" data-orig-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/GT6_FLYER2.jpg?fit=850%2C1119&amp;ssl=1" data-orig-size="850,1119" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="GT6_FLYER2" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/GT6_FLYER2.jpg?fit=228%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/GT6_FLYER2.jpg?fit=770%2C1013&amp;ssl=1" data-id="8503" src="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/GT6_FLYER2.jpg?resize=770%2C1013&amp;ssl=1" alt="A promotional image showcasing a group of players engaged in the arcade game Galaxian3, featuring a large screen displaying space combat visuals, with futuristic game controls in front of each player." srcset="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/GT6_FLYER2.jpg?resize=778%2C1024&amp;ssl=1 778w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/GT6_FLYER2.jpg?resize=228%2C300&amp;ssl=1 228w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/GT6_FLYER2.jpg?resize=768%2C1011&amp;ssl=1 768w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/GT6_FLYER2.jpg?resize=76%2C100&amp;ssl=1 76w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/GT6_FLYER2.jpg?w=850&amp;ssl=1 850w" sizes="auto, (max-width: 770px) 100vw, 770px"></a></figure>
</figure>



<p>Source: The Arcade Flyer Archive</p>



<p>A sequel to Project Dragoon, “Attack of the Zolgear” was released in 1994 and offered as a conversion kit in the form of replacement ROMs and LaserDiscs.</p>


<div>
<figure><a href="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Zolgear-Flyer.jpg?ssl=1"><img data-recalc-dims="1" loading="lazy" decoding="async" width="770" height="1015" data-attachment-id="8505" data-permalink="https://philwip.com/?attachment_id=8505" data-orig-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Zolgear-Flyer.jpg?fit=850%2C1120&amp;ssl=1" data-orig-size="850,1120" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Zolgear Flyer" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Zolgear-Flyer.jpg?fit=228%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Zolgear-Flyer.jpg?fit=770%2C1015&amp;ssl=1" src="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Zolgear-Flyer.jpg?resize=770%2C1015&amp;ssl=1" alt="Promotional flyer for 'Attack of the Zolgear', featuring dramatic artwork of characters reacting to a looming threat, with a vibrant background and text describing the game's features." srcset="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Zolgear-Flyer.jpg?resize=777%2C1024&amp;ssl=1 777w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Zolgear-Flyer.jpg?resize=228%2C300&amp;ssl=1 228w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Zolgear-Flyer.jpg?resize=768%2C1012&amp;ssl=1 768w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Zolgear-Flyer.jpg?resize=76%2C100&amp;ssl=1 76w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Zolgear-Flyer.jpg?w=850&amp;ssl=1 850w" sizes="auto, (max-width: 770px) 100vw, 770px"></a><figcaption>Source: The Arcade Flyer Archive</figcaption></figure></div>










<p>Tragically, in the early 2000s, many Galaxian<sup>3&nbsp; </sup>installations were converted to Tsunami Visual Technologies’ Air Raid, a PC-based game, with most of the Galaxian<sup>3</sup> electronics discarded in the process.</p>



<p>As of 2025, there are four known remaining instances of GT-6; one in Europe, two in Japan and one in the USA. The latter resides at the Fun World arcade in Nashua, New Hampshire. Unfortunately the game has been out of service for over a decade, its exact condition unknown.</p>



<p>Contact was established with the owner to allow an effort to repair the game and to preserve the data contained within; specifically the ROM data and the LaserDiscs.</p>



<h2>Trip 1: March 2024</h2>



<p>A team assembled at Fun World to assess the game – myself Phil Bennett, Alex Cmaylo, Bill DeLeo and Scott Gurney. Alex and I had flown from California and we had two days to inspect the machine during the week while the arcade was closed.</p>


<div>
<figure><a href="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Fun-World.jpeg?ssl=1"><img data-recalc-dims="1" loading="lazy" decoding="async" width="770" height="578" data-attachment-id="8439" data-permalink="https://philwip.com/?attachment_id=8439" data-orig-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Fun-World.jpeg?fit=4032%2C3024&amp;ssl=1" data-orig-size="4032,3024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 12 Pro Max&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1709725930&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;5.1&quot;,&quot;iso&quot;:&quot;32&quot;,&quot;shutter_speed&quot;:&quot;0.00021199915200339&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="Fun World" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Fun-World.jpeg?fit=300%2C225&amp;ssl=1" data-large-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Fun-World.jpeg?fit=770%2C578&amp;ssl=1" src="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Fun-World.jpeg?resize=770%2C578&amp;ssl=1" alt="Exterior view of a castle-themed arcade building with a parked red Coca-Cola van in the foreground." srcset="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Fun-World.jpeg?resize=1024%2C768&amp;ssl=1 1024w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Fun-World.jpeg?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Fun-World.jpeg?resize=768%2C576&amp;ssl=1 768w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Fun-World.jpeg?resize=1536%2C1152&amp;ssl=1 1536w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Fun-World.jpeg?resize=2048%2C1536&amp;ssl=1 2048w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Fun-World.jpeg?resize=1200%2C900&amp;ssl=1 1200w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Fun-World.jpeg?resize=800%2C600&amp;ssl=1 800w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Fun-World.jpeg?resize=600%2C450&amp;ssl=1 600w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Fun-World.jpeg?resize=400%2C300&amp;ssl=1 400w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Fun-World.jpeg?resize=200%2C150&amp;ssl=1 200w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Fun-World.jpeg?resize=1134%2C851&amp;ssl=1 1134w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Fun-World.jpeg?resize=133%2C100&amp;ssl=1 133w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Fun-World.jpeg?w=2310&amp;ssl=1 2310w" sizes="auto, (max-width: 770px) 100vw, 770px"></a><figcaption>A World of Fun awaits!</figcaption></figure></div>

<div>
<figure><a href="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/G3.jpeg?ssl=1"><img data-recalc-dims="1" loading="lazy" decoding="async" width="770" height="578" data-attachment-id="8440" data-permalink="https://philwip.com/?attachment_id=8440" data-orig-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/G3.jpeg?fit=4032%2C3024&amp;ssl=1" data-orig-size="4032,3024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 12 Pro Max&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1709727408&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;5.1&quot;,&quot;iso&quot;:&quot;250&quot;,&quot;shutter_speed&quot;:&quot;0.016666666666667&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="G3" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/G3.jpeg?fit=300%2C225&amp;ssl=1" data-large-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/G3.jpeg?fit=770%2C578&amp;ssl=1" src="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/G3.jpeg?resize=770%2C578&amp;ssl=1" alt="A covered arcade game cabinet with blue tarp, partially visible seating inside; a ladder stands nearby, indicating maintenance work." srcset="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/G3.jpeg?resize=1024%2C768&amp;ssl=1 1024w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/G3.jpeg?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/G3.jpeg?resize=768%2C576&amp;ssl=1 768w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/G3.jpeg?resize=1536%2C1152&amp;ssl=1 1536w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/G3.jpeg?resize=2048%2C1536&amp;ssl=1 2048w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/G3.jpeg?resize=1200%2C900&amp;ssl=1 1200w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/G3.jpeg?resize=800%2C600&amp;ssl=1 800w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/G3.jpeg?resize=600%2C450&amp;ssl=1 600w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/G3.jpeg?resize=400%2C300&amp;ssl=1 400w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/G3.jpeg?resize=200%2C150&amp;ssl=1 200w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/G3.jpeg?resize=1134%2C851&amp;ssl=1 1134w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/G3.jpeg?resize=133%2C100&amp;ssl=1 133w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/G3.jpeg?w=2310&amp;ssl=1 2310w" sizes="auto, (max-width: 770px) 100vw, 770px"></a></figure></div>






<p>The machine is situated at the top of the third floor and was fenced off and covered by a tarp. After deeming the game electrically safe, we powered it on. Surprisingly, it appeared to work but with notable issues:</p>



<ul>
<li>Only players 1 and 2 worked</li>



<li>Sound was missing from several speakers</li>



<li>The blue output of the left-side projector was very dim and blurry</li>
</ul>







		<figure>
			
			
			
		</figure>
		










<h2>Hardware Overview</h2>



<p>Let’s examine what’s inside the machine.</p>







<h3>Video Displays</h3>


<div>
<figure><a href="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/SCREENS.jpg?ssl=1"><img data-recalc-dims="1" loading="lazy" decoding="async" width="770" height="514" data-attachment-id="8446" data-permalink="https://philwip.com/?attachment_id=8446" data-orig-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/SCREENS.jpg?fit=3504%2C2336&amp;ssl=1" data-orig-size="3504,2336" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.5&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;ILCE-7M4&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1742976143&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;40&quot;,&quot;iso&quot;:&quot;320&quot;,&quot;shutter_speed&quot;:&quot;0.0125&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="SCREENS" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/SCREENS.jpg?fit=300%2C200&amp;ssl=1" data-large-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/SCREENS.jpg?fit=770%2C514&amp;ssl=1" src="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/SCREENS.jpg?resize=770%2C514&amp;ssl=1" alt="Interior view of a Galaxian3 game cabinet showing the control panels for multiple players with numbered sections and a blank projection screen." srcset="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/SCREENS.jpg?resize=1024%2C683&amp;ssl=1 1024w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/SCREENS.jpg?resize=300%2C200&amp;ssl=1 300w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/SCREENS.jpg?resize=768%2C512&amp;ssl=1 768w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/SCREENS.jpg?resize=1536%2C1024&amp;ssl=1 1536w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/SCREENS.jpg?resize=2048%2C1365&amp;ssl=1 2048w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/SCREENS.jpg?resize=1200%2C800&amp;ssl=1 1200w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/SCREENS.jpg?resize=1134%2C756&amp;ssl=1 1134w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/SCREENS.jpg?resize=150%2C100&amp;ssl=1 150w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/SCREENS.jpg?w=2310&amp;ssl=1 2310w" sizes="auto, (max-width: 770px) 100vw, 770px"></a></figure></div>






<p>There is a large projection area on which the game is displayed by two Sony VPH-1043QJ CRT projectors mounted above the seating area. Located in the cabinets beneath the projection screens are speakers (missing on this particular machine) and flash lamps which trigger whenever the players take damage.</p>







<figure><a href="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/OHP.jpg?ssl=1"><img data-recalc-dims="1" loading="lazy" decoding="async" width="770" height="448" data-attachment-id="8447" data-permalink="https://philwip.com/?attachment_id=8447" data-orig-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/OHP.jpg?fit=3504%2C2041&amp;ssl=1" data-orig-size="3504,2041" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.5&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;ILCE-7M4&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1742976178&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;40&quot;,&quot;iso&quot;:&quot;1600&quot;,&quot;shutter_speed&quot;:&quot;0.0125&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="OHP" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/OHP.jpg?fit=300%2C175&amp;ssl=1" data-large-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/OHP.jpg?fit=770%2C448&amp;ssl=1" src="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/OHP.jpg?resize=770%2C448&amp;ssl=1" alt="Close-up view of the control box for a Galaxian3 arcade game, featuring three circular lenses behind a clear panel, mounted on a blue structure." srcset="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/OHP.jpg?resize=1024%2C596&amp;ssl=1 1024w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/OHP.jpg?resize=300%2C175&amp;ssl=1 300w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/OHP.jpg?resize=768%2C447&amp;ssl=1 768w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/OHP.jpg?resize=1536%2C895&amp;ssl=1 1536w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/OHP.jpg?resize=2048%2C1193&amp;ssl=1 2048w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/OHP.jpg?resize=1200%2C699&amp;ssl=1 1200w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/OHP.jpg?resize=1134%2C661&amp;ssl=1 1134w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/OHP.jpg?resize=172%2C100&amp;ssl=1 172w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/OHP.jpg?w=2310&amp;ssl=1 2310w" sizes="auto, (max-width: 770px) 100vw, 770px"></a></figure>











<h3>Player Controls</h3>



<figure data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/philwip.com\/2025\/04\/14\/galaxian-3-project-revival\/&quot;}">
<figure><a href="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/G3_GUN1-2.png?ssl=1"><img data-recalc-dims="1" loading="lazy" decoding="async" width="770" height="826" data-attachment-id="8413" data-permalink="https://philwip.com/?attachment_id=8413" data-orig-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/G3_GUN1-2.png?fit=1601%2C1716&amp;ssl=1" data-orig-size="1601,1716" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="G3_GUN1" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/G3_GUN1-2.png?fit=280%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/G3_GUN1-2.png?fit=770%2C826&amp;ssl=1" data-id="8413" src="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/G3_GUN1-2.png?resize=770%2C826&amp;ssl=1" alt="Close-up view of a control panel for an arcade game featuring two joystick handles, a speaker mesh, and control buttons." srcset="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/G3_GUN1-2.png?resize=955%2C1024&amp;ssl=1 955w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/G3_GUN1-2.png?resize=280%2C300&amp;ssl=1 280w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/G3_GUN1-2.png?resize=768%2C823&amp;ssl=1 768w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/G3_GUN1-2.png?resize=1433%2C1536&amp;ssl=1 1433w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/G3_GUN1-2.png?resize=1200%2C1286&amp;ssl=1 1200w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/G3_GUN1-2.png?resize=1134%2C1215&amp;ssl=1 1134w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/G3_GUN1-2.png?resize=93%2C100&amp;ssl=1 93w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/G3_GUN1-2.png?w=1601&amp;ssl=1 1601w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/G3_GUN1-2.png?w=1540&amp;ssl=1 1540w" sizes="auto, (max-width: 770px) 100vw, 770px"></a></figure>



<figure><a href="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/G3_GUN2-2.png?ssl=1"><img data-recalc-dims="1" loading="lazy" decoding="async" width="770" height="957" data-attachment-id="8412" data-permalink="https://philwip.com/?attachment_id=8412" data-orig-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/G3_GUN2-2.png?fit=1029%2C1278&amp;ssl=1" data-orig-size="1029,1278" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="G3_GUN2" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/G3_GUN2-2.png?fit=242%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/G3_GUN2-2.png?fit=770%2C957&amp;ssl=1" data-id="8412" src="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/G3_GUN2-2.png?resize=770%2C957&amp;ssl=1" alt="Top view of a control panel for the arcade game 'Galaxian3: Project Dragoon', featuring a white casing with red stripes and a blue label." srcset="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/G3_GUN2-2.png?resize=824%2C1024&amp;ssl=1 824w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/G3_GUN2-2.png?resize=242%2C300&amp;ssl=1 242w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/G3_GUN2-2.png?resize=768%2C954&amp;ssl=1 768w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/G3_GUN2-2.png?resize=81%2C100&amp;ssl=1 81w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/G3_GUN2-2.png?w=1029&amp;ssl=1 1029w" sizes="auto, (max-width: 770px) 100vw, 770px"></a></figure>
</figure>







<p>Each player has a two-axis analog control with digital buttons. A speaker mounted inside the control plays sound effects and a vibration motor provides force-feedback. Additionally, an array of LEDs on top of the control flash when the player is hit.</p>



<p>In front of the player seats, there are three Control Boxes: left, center and right.&nbsp;</p>







<h3><strong>Center Control Box</strong></h3>



<p>The central box contains most of the PCBs and two power supply units:</p>



<figure data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/philwip.com\/2025\/04\/14\/galaxian-3-project-revival\/&quot;}">
<figure><a href="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/CARD-CAGE-2.jpeg?ssl=1"><img data-recalc-dims="1" loading="lazy" decoding="async" width="770" height="578" data-attachment-id="8387" data-permalink="https://philwip.com/?attachment_id=8387" data-orig-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/CARD-CAGE-2.jpeg?fit=4032%2C3024&amp;ssl=1" data-orig-size="4032,3024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 12 Pro Max&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1709728118&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;5.1&quot;,&quot;iso&quot;:&quot;1000&quot;,&quot;shutter_speed&quot;:&quot;0.041666666666667&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="CARD CAGE 2" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/CARD-CAGE-2.jpeg?fit=300%2C225&amp;ssl=1" data-large-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/CARD-CAGE-2.jpeg?fit=770%2C578&amp;ssl=1" data-id="8387" src="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/CARD-CAGE-2.jpeg?resize=770%2C578&amp;ssl=1" alt="Close-up view of the internal circuitry and PCBs of a vintage arcade game, showing multiple green circuit boards with connectors and wiring." srcset="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/CARD-CAGE-2.jpeg?resize=1024%2C768&amp;ssl=1 1024w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/CARD-CAGE-2.jpeg?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/CARD-CAGE-2.jpeg?resize=768%2C576&amp;ssl=1 768w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/CARD-CAGE-2.jpeg?resize=1536%2C1152&amp;ssl=1 1536w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/CARD-CAGE-2.jpeg?resize=2048%2C1536&amp;ssl=1 2048w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/CARD-CAGE-2.jpeg?resize=1200%2C900&amp;ssl=1 1200w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/CARD-CAGE-2.jpeg?resize=800%2C600&amp;ssl=1 800w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/CARD-CAGE-2.jpeg?resize=600%2C450&amp;ssl=1 600w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/CARD-CAGE-2.jpeg?resize=400%2C300&amp;ssl=1 400w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/CARD-CAGE-2.jpeg?resize=200%2C150&amp;ssl=1 200w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/CARD-CAGE-2.jpeg?resize=1134%2C851&amp;ssl=1 1134w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/CARD-CAGE-2.jpeg?resize=133%2C100&amp;ssl=1 133w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/CARD-CAGE-2.jpeg?w=2310&amp;ssl=1 2310w" sizes="auto, (max-width: 770px) 100vw, 770px"></a></figure>



<figure><a href="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/CARD-CAGE.jpeg?ssl=1"><img data-recalc-dims="1" loading="lazy" decoding="async" width="770" height="578" data-attachment-id="8388" data-permalink="https://philwip.com/?attachment_id=8388" data-orig-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/CARD-CAGE.jpeg?fit=4032%2C3024&amp;ssl=1" data-orig-size="4032,3024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 12 Pro Max&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1709731830&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;5.1&quot;,&quot;iso&quot;:&quot;640&quot;,&quot;shutter_speed&quot;:&quot;0.066666666666667&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="CARD CAGE" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/CARD-CAGE.jpeg?fit=300%2C225&amp;ssl=1" data-large-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/CARD-CAGE.jpeg?fit=770%2C578&amp;ssl=1" data-id="8388" src="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/CARD-CAGE.jpeg?resize=770%2C578&amp;ssl=1" alt="An interior view of an arcade game machine showing multiple circuit boards and wiring connected in a structured layout." srcset="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/CARD-CAGE.jpeg?resize=1024%2C768&amp;ssl=1 1024w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/CARD-CAGE.jpeg?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/CARD-CAGE.jpeg?resize=768%2C576&amp;ssl=1 768w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/CARD-CAGE.jpeg?resize=1536%2C1152&amp;ssl=1 1536w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/CARD-CAGE.jpeg?resize=2048%2C1536&amp;ssl=1 2048w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/CARD-CAGE.jpeg?resize=1200%2C900&amp;ssl=1 1200w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/CARD-CAGE.jpeg?resize=800%2C600&amp;ssl=1 800w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/CARD-CAGE.jpeg?resize=600%2C450&amp;ssl=1 600w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/CARD-CAGE.jpeg?resize=400%2C300&amp;ssl=1 400w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/CARD-CAGE.jpeg?resize=200%2C150&amp;ssl=1 200w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/CARD-CAGE.jpeg?resize=1134%2C851&amp;ssl=1 1134w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/CARD-CAGE.jpeg?resize=133%2C100&amp;ssl=1 133w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/CARD-CAGE.jpeg?w=2310&amp;ssl=1 2310w" sizes="auto, (max-width: 770px) 100vw, 770px"></a></figure>
</figure>







<h3>Master PCB</h3>



<figure><a href="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/MST-PCB.jpeg?ssl=1"><img data-recalc-dims="1" loading="lazy" decoding="async" width="770" height="838" data-attachment-id="8386" data-permalink="https://philwip.com/?attachment_id=8386" data-orig-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/MST-PCB.jpeg?fit=3024%2C3291&amp;ssl=1" data-orig-size="3024,3291" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 12 Pro Max&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1709743204&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;5.1&quot;,&quot;iso&quot;:&quot;80&quot;,&quot;shutter_speed&quot;:&quot;0.066666666666667&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="MST PCB" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/MST-PCB.jpeg?fit=276%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/MST-PCB.jpeg?fit=770%2C838&amp;ssl=1" src="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/MST-PCB.jpeg?resize=770%2C838&amp;ssl=1" alt="Close-up view of a Namco PCB board used in arcade games, showing various integrated circuits, connectors, and solder points." srcset="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/MST-PCB.jpeg?resize=941%2C1024&amp;ssl=1 941w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/MST-PCB.jpeg?resize=276%2C300&amp;ssl=1 276w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/MST-PCB.jpeg?resize=768%2C836&amp;ssl=1 768w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/MST-PCB.jpeg?resize=1411%2C1536&amp;ssl=1 1411w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/MST-PCB.jpeg?resize=1882%2C2048&amp;ssl=1 1882w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/MST-PCB.jpeg?resize=1200%2C1306&amp;ssl=1 1200w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/MST-PCB.jpeg?resize=1134%2C1234&amp;ssl=1 1134w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/MST-PCB.jpeg?resize=92%2C100&amp;ssl=1 92w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/MST-PCB.jpeg?w=1540&amp;ssl=1 1540w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/MST-PCB.jpeg?w=2310&amp;ssl=1 2310w" sizes="auto, (max-width: 770px) 100vw, 770px"></a></figure>







<p>The Master PCB handles the main logic of the game and features a 24MHz 68020. The program is stored on 2MB of ROM but is primarily executed out of 512KB of SRAM. There is a 68681 DUART and Namco C139 serial communications interface but neither are used by this version of the game. This PCB was also used by the DS-5000 Mitsubishi/Namco driving simulator.</p>



<h3>Slave PCB</h3>



<figure><a href="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/SLAVE-PCB.jpeg?ssl=1"><img data-recalc-dims="1" loading="lazy" decoding="async" width="770" height="849" data-attachment-id="8389" data-permalink="https://philwip.com/?attachment_id=8389" data-orig-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/SLAVE-PCB.jpeg?fit=3024%2C3333&amp;ssl=1" data-orig-size="3024,3333" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 12 Pro Max&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1709740120&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;5.1&quot;,&quot;iso&quot;:&quot;40&quot;,&quot;shutter_speed&quot;:&quot;0.058823529411765&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="SLAVE PCB" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/SLAVE-PCB.jpeg?fit=272%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/SLAVE-PCB.jpeg?fit=770%2C849&amp;ssl=1" src="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/SLAVE-PCB.jpeg?resize=770%2C849&amp;ssl=1" alt="A close-up view of a Namco game circuit board, showing various electronic components, including microchips and connectors, with the Namco logo prominently displayed." srcset="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/SLAVE-PCB.jpeg?resize=929%2C1024&amp;ssl=1 929w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/SLAVE-PCB.jpeg?resize=272%2C300&amp;ssl=1 272w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/SLAVE-PCB.jpeg?resize=768%2C846&amp;ssl=1 768w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/SLAVE-PCB.jpeg?resize=1394%2C1536&amp;ssl=1 1394w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/SLAVE-PCB.jpeg?resize=1858%2C2048&amp;ssl=1 1858w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/SLAVE-PCB.jpeg?resize=1200%2C1323&amp;ssl=1 1200w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/SLAVE-PCB.jpeg?resize=1134%2C1250&amp;ssl=1 1134w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/SLAVE-PCB.jpeg?resize=91%2C100&amp;ssl=1 91w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/SLAVE-PCB.jpeg?w=1540&amp;ssl=1 1540w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/SLAVE-PCB.jpeg?w=2310&amp;ssl=1 2310w" sizes="auto, (max-width: 770px) 100vw, 770px"></a></figure>







<p>Physically identical to the Master PCB (though with different ROMs and jumper settings), the Slave PCB drives two sets of video hardware, one per side. Each set consists of a DSP, PGN and OBJ PCB:</p>



<h3>DSP PCB</h3>



<figure><a href="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/DSP-PCB-2.jpeg?ssl=1"><img data-recalc-dims="1" loading="lazy" decoding="async" width="770" height="864" data-attachment-id="8391" data-permalink="https://philwip.com/?attachment_id=8391" data-orig-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/DSP-PCB-2.jpeg?fit=3024%2C3391&amp;ssl=1" data-orig-size="3024,3391" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 12 Pro Max&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1709731308&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;5.1&quot;,&quot;iso&quot;:&quot;500&quot;,&quot;shutter_speed&quot;:&quot;0.033333333333333&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="DSP PCB 2" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/DSP-PCB-2.jpeg?fit=268%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/DSP-PCB-2.jpeg?fit=770%2C864&amp;ssl=1" src="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/DSP-PCB-2.jpeg?resize=770%2C864&amp;ssl=1" alt="A close-up view of a Namco circuit board featuring several chips, components, and LED indicators, showcasing its intricate design." srcset="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/DSP-PCB-2.jpeg?resize=913%2C1024&amp;ssl=1 913w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/DSP-PCB-2.jpeg?resize=268%2C300&amp;ssl=1 268w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/DSP-PCB-2.jpeg?resize=768%2C861&amp;ssl=1 768w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/DSP-PCB-2.jpeg?resize=1370%2C1536&amp;ssl=1 1370w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/DSP-PCB-2.jpeg?resize=1826%2C2048&amp;ssl=1 1826w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/DSP-PCB-2.jpeg?resize=1200%2C1346&amp;ssl=1 1200w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/DSP-PCB-2.jpeg?resize=1134%2C1272&amp;ssl=1 1134w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/DSP-PCB-2.jpeg?resize=89%2C100&amp;ssl=1 89w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/DSP-PCB-2.jpeg?w=1540&amp;ssl=1 1540w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/DSP-PCB-2.jpeg?w=2310&amp;ssl=1 2310w" sizes="auto, (max-width: 770px) 100vw, 770px"></a></figure>







<p>The DSP PCB has five TMS320C25s that handle processing of the 3D vertex data; transformation, lighting, clipping and projection. This PCB is also used by later-generation System 21 games such as Star Blade, Solvalou and Air Combat.</p>



<h3>PGN PCB</h3>



<figure><a href="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PGN-PCB.jpeg?ssl=1"><img data-recalc-dims="1" loading="lazy" decoding="async" width="770" height="863" data-attachment-id="8392" data-permalink="https://philwip.com/?attachment_id=8392" data-orig-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PGN-PCB.jpeg?fit=3024%2C3389&amp;ssl=1" data-orig-size="3024,3389" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 12 Pro Max&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1709731900&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;5.1&quot;,&quot;iso&quot;:&quot;32&quot;,&quot;shutter_speed&quot;:&quot;0.05&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="PGN PCB" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PGN-PCB.jpeg?fit=268%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PGN-PCB.jpeg?fit=770%2C863&amp;ssl=1" src="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PGN-PCB.jpeg?resize=770%2C863&amp;ssl=1" alt="Close-up view of a Namco video game circuit board featuring various integrated circuits and connections." srcset="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PGN-PCB.jpeg?resize=914%2C1024&amp;ssl=1 914w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PGN-PCB.jpeg?resize=268%2C300&amp;ssl=1 268w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PGN-PCB.jpeg?resize=768%2C861&amp;ssl=1 768w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PGN-PCB.jpeg?resize=1371%2C1536&amp;ssl=1 1371w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PGN-PCB.jpeg?resize=1827%2C2048&amp;ssl=1 1827w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PGN-PCB.jpeg?resize=1200%2C1345&amp;ssl=1 1200w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PGN-PCB.jpeg?resize=1134%2C1271&amp;ssl=1 1134w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PGN-PCB.jpeg?resize=89%2C100&amp;ssl=1 89w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PGN-PCB.jpeg?w=1540&amp;ssl=1 1540w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PGN-PCB.jpeg?w=2310&amp;ssl=1 2310w" sizes="auto, (max-width: 770px) 100vw, 770px"></a></figure>







<p>The Polygon PCB rasterizes flat-shaded polygons from the vertex data produced by the DSP PCB. The pixel data is fed into the OBJ PCB. This PCB is also used by other late-generation System 21 games.</p>



<h3>OBJ PCB</h3>



<figure><a href="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/OBJCT-PCB-3.jpeg?ssl=1"><img data-recalc-dims="1" loading="lazy" decoding="async" width="770" height="858" data-attachment-id="8393" data-permalink="https://philwip.com/?attachment_id=8393" data-orig-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/OBJCT-PCB-3.jpeg?fit=3024%2C3369&amp;ssl=1" data-orig-size="3024,3369" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 12 Pro Max&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1709732121&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;5.1&quot;,&quot;iso&quot;:&quot;500&quot;,&quot;shutter_speed&quot;:&quot;0.033333333333333&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="OBJCT PCB 3" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/OBJCT-PCB-3.jpeg?fit=269%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/OBJCT-PCB-3.jpeg?fit=770%2C858&amp;ssl=1" src="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/OBJCT-PCB-3.jpeg?resize=770%2C858&amp;ssl=1" alt="Top view of the object PCB for a vintage arcade game, featuring various chips, capacitors, and circuit board components." srcset="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/OBJCT-PCB-3.jpeg?resize=919%2C1024&amp;ssl=1 919w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/OBJCT-PCB-3.jpeg?resize=269%2C300&amp;ssl=1 269w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/OBJCT-PCB-3.jpeg?resize=768%2C856&amp;ssl=1 768w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/OBJCT-PCB-3.jpeg?resize=1379%2C1536&amp;ssl=1 1379w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/OBJCT-PCB-3.jpeg?resize=1838%2C2048&amp;ssl=1 1838w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/OBJCT-PCB-3.jpeg?resize=1200%2C1337&amp;ssl=1 1200w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/OBJCT-PCB-3.jpeg?resize=1134%2C1263&amp;ssl=1 1134w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/OBJCT-PCB-3.jpeg?resize=90%2C100&amp;ssl=1 90w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/OBJCT-PCB-3.jpeg?w=1540&amp;ssl=1 1540w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/OBJCT-PCB-3.jpeg?w=2310&amp;ssl=1 2310w" sizes="auto, (max-width: 770px) 100vw, 770px"></a></figure>







<p>The Object PCB generates 2D objects/sprites. As there is no tilemap hardware, everything non-3D is sprite-based. The sprites are combined with the 3D layer before palette lookup and digital to analog conversion. This PCB is unique to Galaxian<sup>3</sup> but very similar to the OBJ PCB of other System 21 games.</p>



<h3>V-MIX PCB</h3>



<figure><a href="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/galaxian3-V-MIX.jpg?ssl=1"><img data-recalc-dims="1" loading="lazy" decoding="async" width="770" height="991" data-attachment-id="8394" data-permalink="https://philwip.com/?attachment_id=8394" data-orig-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/galaxian3-V-MIX.jpg?fit=951%2C1223&amp;ssl=1" data-orig-size="951,1223" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;4.5&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;NIKON D70&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1224746153&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;52&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0.016666666666667&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="galaxian3-V-MIX" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/galaxian3-V-MIX.jpg?fit=233%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/galaxian3-V-MIX.jpg?fit=770%2C991&amp;ssl=1" src="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/galaxian3-V-MIX.jpg?resize=770%2C991&amp;ssl=1" alt="A close-up view of a Namco V-MIX PCB used in arcade machines, featuring various electronic components and connectors." srcset="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/galaxian3-V-MIX.jpg?resize=796%2C1024&amp;ssl=1 796w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/galaxian3-V-MIX.jpg?resize=233%2C300&amp;ssl=1 233w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/galaxian3-V-MIX.jpg?resize=768%2C988&amp;ssl=1 768w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/galaxian3-V-MIX.jpg?resize=78%2C100&amp;ssl=1 78w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/galaxian3-V-MIX.jpg?w=951&amp;ssl=1 951w" sizes="auto, (max-width: 770px) 100vw, 770px"></a><figcaption>Photo credit: andys-arcade</figcaption></figure>







<p>The video mixer PCB handles <a href="https://en.wikipedia.org/wiki/Genlock">genlock</a>, combining the LaserDisc video output with that of the OBJ PCB. It has four RGB video outputs, though only two are used by GT-6. It also appears to have four composite outputs.</p>



<h3>C-RAM PCB</h3>



<figure><a href="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/galaxian3-CRAM.jpg?ssl=1"><img data-recalc-dims="1" loading="lazy" decoding="async" width="770" height="637" data-attachment-id="8396" data-permalink="https://philwip.com/?attachment_id=8396" data-orig-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/galaxian3-CRAM.jpg?fit=1157%2C957&amp;ssl=1" data-orig-size="1157,957" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;4.5&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;NIKON D70&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1224745035&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;48&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0.016666666666667&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="galaxian3-CRAM" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/galaxian3-CRAM.jpg?fit=300%2C248&amp;ssl=1" data-large-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/galaxian3-CRAM.jpg?fit=770%2C637&amp;ssl=1" src="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/galaxian3-CRAM.jpg?resize=770%2C637&amp;ssl=1" alt="Close-up view of a Namco GAL C-RAM PCB, featuring multiple connectors and circuitry details." srcset="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/galaxian3-CRAM.jpg?resize=1024%2C847&amp;ssl=1 1024w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/galaxian3-CRAM.jpg?resize=300%2C248&amp;ssl=1 300w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/galaxian3-CRAM.jpg?resize=768%2C635&amp;ssl=1 768w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/galaxian3-CRAM.jpg?resize=1134%2C938&amp;ssl=1 1134w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/galaxian3-CRAM.jpg?resize=121%2C100&amp;ssl=1 121w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/galaxian3-CRAM.jpg?w=1157&amp;ssl=1 1157w" sizes="auto, (max-width: 770px) 100vw, 770px"></a><figcaption>Photo credit: andys-arcade</figcaption></figure>







<p>The C-RAM PCB is used for communication between the Master and Slave PCBs, featuring 32KB of SRAM and two C195 memory arbitration ASICs.</p>



<h3>RSO PCB</h3>



<figure><a href="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/RSO-PCB-3.jpeg?ssl=1"><img data-recalc-dims="1" loading="lazy" decoding="async" width="770" height="838" data-attachment-id="8398" data-permalink="https://philwip.com/?attachment_id=8398" data-orig-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/RSO-PCB-3.jpeg?fit=3024%2C3292&amp;ssl=1" data-orig-size="3024,3292" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 12 Pro Max&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1709742461&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;5.1&quot;,&quot;iso&quot;:&quot;640&quot;,&quot;shutter_speed&quot;:&quot;0.033333333333333&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="RSO PCB 3" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/RSO-PCB-3.jpeg?fit=276%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/RSO-PCB-3.jpeg?fit=770%2C838&amp;ssl=1" src="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/RSO-PCB-3.jpeg?resize=770%2C838&amp;ssl=1" alt="A close-up view of a printed circuit board showcasing various integrated circuits, connectors, and components, indicating its role in arcade game hardware." srcset="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/RSO-PCB-3.jpeg?resize=941%2C1024&amp;ssl=1 941w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/RSO-PCB-3.jpeg?resize=276%2C300&amp;ssl=1 276w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/RSO-PCB-3.jpeg?resize=768%2C836&amp;ssl=1 768w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/RSO-PCB-3.jpeg?resize=1411%2C1536&amp;ssl=1 1411w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/RSO-PCB-3.jpeg?resize=1881%2C2048&amp;ssl=1 1881w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/RSO-PCB-3.jpeg?resize=1200%2C1306&amp;ssl=1 1200w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/RSO-PCB-3.jpeg?resize=1134%2C1235&amp;ssl=1 1134w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/RSO-PCB-3.jpeg?resize=92%2C100&amp;ssl=1 92w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/RSO-PCB-3.jpeg?w=1540&amp;ssl=1 1540w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/RSO-PCB-3.jpeg?w=2310&amp;ssl=1 2310w" sizes="auto, (max-width: 770px) 100vw, 770px"></a></figure>







<p>Also known as the ‘network PCB’, the RSO PCB has six 68681 DUARTs and nine C139 serial interfaces, most of which are unused by GT-6. One 68681 is used to communicate with the LaserDisc players via an RS-232 interface. One C139 interfaces with the Sound PCB while three are used to communicate with the Personal PCBs, which handle player I/O.</p>



<h3>Sound PCB</h3>



<figure><a href="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/SOUND-PCB.jpeg?ssl=1"><img data-recalc-dims="1" loading="lazy" decoding="async" width="770" height="878" data-attachment-id="8399" data-permalink="https://philwip.com/?attachment_id=8399" data-orig-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/SOUND-PCB.jpeg?fit=3024%2C3448&amp;ssl=1" data-orig-size="3024,3448" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 12 Pro Max&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1709741923&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;5.1&quot;,&quot;iso&quot;:&quot;40&quot;,&quot;shutter_speed&quot;:&quot;0.05&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="SOUND PCB" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/SOUND-PCB.jpeg?fit=263%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/SOUND-PCB.jpeg?fit=770%2C878&amp;ssl=1" src="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/SOUND-PCB.jpeg?resize=770%2C878&amp;ssl=1" alt="A top view of a Namco sound PCB featuring multiple chips and electronic components, with various labels on the circuit board." srcset="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/SOUND-PCB.jpeg?resize=898%2C1024&amp;ssl=1 898w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/SOUND-PCB.jpeg?resize=263%2C300&amp;ssl=1 263w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/SOUND-PCB.jpeg?resize=768%2C876&amp;ssl=1 768w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/SOUND-PCB.jpeg?resize=1347%2C1536&amp;ssl=1 1347w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/SOUND-PCB.jpeg?resize=1796%2C2048&amp;ssl=1 1796w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/SOUND-PCB.jpeg?resize=1200%2C1368&amp;ssl=1 1200w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/SOUND-PCB.jpeg?resize=1134%2C1293&amp;ssl=1 1134w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/SOUND-PCB.jpeg?resize=88%2C100&amp;ssl=1 88w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/SOUND-PCB.jpeg?w=1540&amp;ssl=1 1540w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/SOUND-PCB.jpeg?w=2310&amp;ssl=1 2310w" sizes="auto, (max-width: 770px) 100vw, 770px"></a></figure>







<p>The sound PCB produces sound effects and speech. A 12MHz 68000 controls five C140 24-channel PCM sound ICs. Two are dedicated to sound effects and one is dedicated to speech, leaving three unused by GT-6.</p>











<h3><strong>Left Control Box</strong></h3>



<p>There are two PSUs and three identical PCBs:</p>



<h3>PSN PCB</h3>



<figure><a href="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PSN-PCB-2.jpeg?ssl=1"><img data-recalc-dims="1" loading="lazy" decoding="async" width="770" height="789" data-attachment-id="8401" data-permalink="https://philwip.com/?attachment_id=8401" data-orig-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PSN-PCB-2.jpeg?fit=2978%2C3053&amp;ssl=1" data-orig-size="2978,3053" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 12 Pro Max&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1709744462&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;5.1&quot;,&quot;iso&quot;:&quot;40&quot;,&quot;shutter_speed&quot;:&quot;0.11111111111111&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="PSN PCB 2" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PSN-PCB-2.jpeg?fit=293%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PSN-PCB-2.jpeg?fit=770%2C789&amp;ssl=1" src="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PSN-PCB-2.jpeg?resize=770%2C789&amp;ssl=1" alt="Close-up view of a Namco arcade PCB, featuring various electronic components, including capacitors, resistors, and microcontrollers." srcset="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PSN-PCB-2.jpeg?resize=999%2C1024&amp;ssl=1 999w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PSN-PCB-2.jpeg?resize=293%2C300&amp;ssl=1 293w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PSN-PCB-2.jpeg?resize=768%2C787&amp;ssl=1 768w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PSN-PCB-2.jpeg?resize=1498%2C1536&amp;ssl=1 1498w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PSN-PCB-2.jpeg?resize=1998%2C2048&amp;ssl=1 1998w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PSN-PCB-2.jpeg?resize=1200%2C1230&amp;ssl=1 1200w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PSN-PCB-2.jpeg?resize=1134%2C1163&amp;ssl=1 1134w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PSN-PCB-2.jpeg?resize=98%2C100&amp;ssl=1 98w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PSN-PCB-2.jpeg?w=2310&amp;ssl=1 2310w" sizes="auto, (max-width: 770px) 100vw, 770px"></a></figure>







<p>A Personal PCB handles I/O for two players. It has an 8MHz 68000 and numerous peripherals. It produces four channels of PCM sound, two per player. A C139 communicates with the RSO over an RS-422 link.</p>











<h3><strong>Right Control Box</strong></h3>


<div>
<figure><a href="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Right-Box.jpeg?ssl=1"><img data-recalc-dims="1" loading="lazy" decoding="async" width="770" height="608" data-attachment-id="8415" data-permalink="https://philwip.com/?attachment_id=8415" data-orig-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Right-Box.jpeg?fit=3669%2C2899&amp;ssl=1" data-orig-size="3669,2899" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 12 Pro Max&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1709728014&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;5.1&quot;,&quot;iso&quot;:&quot;800&quot;,&quot;shutter_speed&quot;:&quot;0.033333333333333&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="Right Box" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Right-Box.jpeg?fit=300%2C237&amp;ssl=1" data-large-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Right-Box.jpeg?fit=770%2C608&amp;ssl=1" src="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Right-Box.jpeg?resize=770%2C608&amp;ssl=1" alt="A stack of audio and video equipment including a Yamaha amplifier and Pioneer LaserDisc player, with a warning sign indicating not to move the amplifier." srcset="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Right-Box.jpeg?resize=1024%2C809&amp;ssl=1 1024w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Right-Box.jpeg?resize=300%2C237&amp;ssl=1 300w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Right-Box.jpeg?resize=768%2C607&amp;ssl=1 768w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Right-Box.jpeg?resize=1536%2C1214&amp;ssl=1 1536w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Right-Box.jpeg?resize=2048%2C1618&amp;ssl=1 2048w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Right-Box.jpeg?resize=1200%2C948&amp;ssl=1 1200w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Right-Box.jpeg?resize=1134%2C896&amp;ssl=1 1134w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Right-Box.jpeg?resize=127%2C100&amp;ssl=1 127w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Right-Box.jpeg?w=2310&amp;ssl=1 2310w" sizes="auto, (max-width: 770px) 100vw, 770px"></a></figure></div>






<h3>LaserDisc Players</h3>



<figure><a href="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LDP.jpeg?ssl=1"><img data-recalc-dims="1" loading="lazy" decoding="async" width="770" height="260" data-attachment-id="8416" data-permalink="https://philwip.com/?attachment_id=8416" data-orig-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LDP.jpeg?fit=4032%2C1361&amp;ssl=1" data-orig-size="4032,1361" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 12 Pro Max&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1709727948&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;5.1&quot;,&quot;iso&quot;:&quot;640&quot;,&quot;shutter_speed&quot;:&quot;0.066666666666667&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="LDP" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LDP.jpeg?fit=300%2C101&amp;ssl=1" data-large-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LDP.jpeg?fit=770%2C260&amp;ssl=1" src="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LDP.jpeg?resize=770%2C260&amp;ssl=1" alt="A Pioneer LaserDisc player placed on a wooden surface, showing dust accumulation, with buttons and a slot for inserting discs." srcset="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LDP.jpeg?resize=1024%2C346&amp;ssl=1 1024w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LDP.jpeg?resize=300%2C101&amp;ssl=1 300w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LDP.jpeg?resize=768%2C259&amp;ssl=1 768w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LDP.jpeg?resize=1536%2C518&amp;ssl=1 1536w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LDP.jpeg?resize=2048%2C691&amp;ssl=1 2048w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LDP.jpeg?resize=1200%2C405&amp;ssl=1 1200w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LDP.jpeg?resize=1134%2C383&amp;ssl=1 1134w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LDP.jpeg?resize=296%2C100&amp;ssl=1 296w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LDP.jpeg?w=2310&amp;ssl=1 2310w" sizes="auto, (max-width: 770px) 100vw, 770px"></a></figure>







<p>There are two industrial-grade Pioneer LD-V8000 LaserDisc players. The LaserDiscs are CAV-encoded, with the Japanese version on side A and English on side B. There are both analog and digital audio tracks present. The two discs are identical – the left-side video is on the first half of the disc and the right-side on the second.</p>



<h3>Audio Amplifiers</h3>



<figure><a href="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Amplifier.jpeg?ssl=1"><img data-recalc-dims="1" loading="lazy" decoding="async" width="770" height="578" data-attachment-id="8417" data-permalink="https://philwip.com/?attachment_id=8417" data-orig-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Amplifier.jpeg?fit=4032%2C3024&amp;ssl=1" data-orig-size="4032,3024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 12 Pro Max&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1709728028&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;5.1&quot;,&quot;iso&quot;:&quot;1000&quot;,&quot;shutter_speed&quot;:&quot;0.066666666666667&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="Amplifier" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Amplifier.jpeg?fit=300%2C225&amp;ssl=1" data-large-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Amplifier.jpeg?fit=770%2C578&amp;ssl=1" src="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Amplifier.jpeg?resize=770%2C578&amp;ssl=1" alt="A Yamaha natural sound stereo amplifier with visible dust and wear, featuring various control knobs and buttons." srcset="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Amplifier.jpeg?resize=1024%2C768&amp;ssl=1 1024w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Amplifier.jpeg?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Amplifier.jpeg?resize=768%2C576&amp;ssl=1 768w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Amplifier.jpeg?resize=1536%2C1152&amp;ssl=1 1536w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Amplifier.jpeg?resize=2048%2C1536&amp;ssl=1 2048w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Amplifier.jpeg?resize=1200%2C900&amp;ssl=1 1200w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Amplifier.jpeg?resize=800%2C600&amp;ssl=1 800w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Amplifier.jpeg?resize=600%2C450&amp;ssl=1 600w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Amplifier.jpeg?resize=400%2C300&amp;ssl=1 400w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Amplifier.jpeg?resize=200%2C150&amp;ssl=1 200w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Amplifier.jpeg?resize=1134%2C851&amp;ssl=1 1134w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Amplifier.jpeg?resize=133%2C100&amp;ssl=1 133w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Amplifier.jpeg?w=2310&amp;ssl=1 2310w" sizes="auto, (max-width: 770px) 100vw, 770px"></a></figure>







<p>Two Yamaha AX-570 stereo amplifiers produce four channels of sound: rear and front stereo.</p>











<h2>Diagnosis</h2>



<p>None of the players 3-6 inputs functioned within the game or input test, the latter showing zeroes across all analog inputs. We suspected an issue with two of the PSN PCBs. The PSN 5V supply was measured as 4.95V at PCB level, with no ripple or significant noise.&nbsp;</p>



<p>The PSN PCB has an undocumented test switch which, when enabled, will trigger sounds, Hit LED flashes and motor vibration when the player’s buttons, service and coin switches are pressed. All three PCBs behaved identically in this mode, proving that each CPU was running and able to read inputs correctly.</p>



<p>The fault followed the PCBs: installing the ‘bad’ PCBs in place of the working PCB prevented players 1 and 2 inputs from working, while installing the working PCB in any position resulted in functioning inputs. This also ruled out any cabling issues.</p>



<p>Upon powering-on the machine, the bad PCBs showed a flashing LED pattern:</p>



		<figure>
			
			
			
		</figure>
		


<p>The number of flashes was not consistent between power-cycles and sometimes there were no flashes at all. The manual explains the significance of many of the LEDs found on the other PCBs but does not include these.</p>



<p>With limited test equipment and dwindling time, diagnosing the fault seemed beyond the scope of this trip. It was decided that I would take the three PSN PCBs and the RSO PCB back with me to California, where I would bench test them and hopefully identify then repair any faults. I also took the Sound PCB for the purpose of documentation. I would aim to learn as much as humanly possible regarding the operation of the machine in order to be better prepared for our next visit.</p>



<p>Part of the remaining time was spent examining the left-side projector. It contains three separate CRTs with a liquid coolant chamber coupled to the face of each tube and three lens assemblies. Over time, crystal deposits form in the coolant chamber as a result of chemical reaction between the glycol coolant and the aluminium housing. This is informally known as “CRT fungus” and results in an obscured, blurry image. This appeared to be part of the problem with the blue channel:</p>



<figure data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/philwip.com\/2025\/04\/14\/galaxian-3-project-revival\/&quot;}">
<figure><a href="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PROJ_1.jpg?ssl=1"><img data-recalc-dims="1" loading="lazy" decoding="async" width="770" height="433" data-attachment-id="8450" data-permalink="https://philwip.com/?attachment_id=8450" data-orig-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PROJ_1.jpg?fit=4032%2C2268&amp;ssl=1" data-orig-size="4032,2268" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="PROJ_1" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PROJ_1.jpg?fit=300%2C169&amp;ssl=1" data-large-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PROJ_1.jpg?fit=770%2C433&amp;ssl=1" data-id="8450" src="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PROJ_1.jpg?resize=770%2C433&amp;ssl=1" alt="Close-up view of a CRT projector lens showing glowing red color with markings and a blurred green light in the background." srcset="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PROJ_1.jpg?resize=1024%2C576&amp;ssl=1 1024w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PROJ_1.jpg?resize=300%2C169&amp;ssl=1 300w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PROJ_1.jpg?resize=768%2C432&amp;ssl=1 768w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PROJ_1.jpg?resize=1536%2C864&amp;ssl=1 1536w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PROJ_1.jpg?resize=2048%2C1152&amp;ssl=1 2048w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PROJ_1.jpg?resize=1200%2C675&amp;ssl=1 1200w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PROJ_1.jpg?resize=1134%2C638&amp;ssl=1 1134w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PROJ_1.jpg?resize=178%2C100&amp;ssl=1 178w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PROJ_1.jpg?w=2310&amp;ssl=1 2310w" sizes="auto, (max-width: 770px) 100vw, 770px"></a></figure>



<figure><a href="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PROJ_2.jpg?ssl=1"><img data-recalc-dims="1" loading="lazy" decoding="async" width="770" height="433" data-attachment-id="8451" data-permalink="https://philwip.com/?attachment_id=8451" data-orig-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PROJ_2.jpg?fit=4032%2C2268&amp;ssl=1" data-orig-size="4032,2268" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="PROJ_2" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PROJ_2.jpg?fit=300%2C169&amp;ssl=1" data-large-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PROJ_2.jpg?fit=770%2C433&amp;ssl=1" data-id="8451" src="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PROJ_2.jpg?resize=770%2C433&amp;ssl=1" alt="Close-up view of a green-tinted CRT display showing graphic elements from a video game, with two other CRT displays partially visible on either side." srcset="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PROJ_2.jpg?resize=1024%2C576&amp;ssl=1 1024w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PROJ_2.jpg?resize=300%2C169&amp;ssl=1 300w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PROJ_2.jpg?resize=768%2C432&amp;ssl=1 768w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PROJ_2.jpg?resize=1536%2C864&amp;ssl=1 1536w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PROJ_2.jpg?resize=2048%2C1152&amp;ssl=1 2048w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PROJ_2.jpg?resize=1200%2C675&amp;ssl=1 1200w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PROJ_2.jpg?resize=1134%2C638&amp;ssl=1 1134w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PROJ_2.jpg?resize=178%2C100&amp;ssl=1 178w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PROJ_2.jpg?w=2310&amp;ssl=1 2310w" sizes="auto, (max-width: 770px) 100vw, 770px"></a></figure>



<figure><a href="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PROJ_3.jpg?ssl=1"><img data-recalc-dims="1" loading="lazy" decoding="async" width="770" height="433" data-attachment-id="8449" data-permalink="https://philwip.com/?attachment_id=8449" data-orig-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PROJ_3.jpg?fit=4032%2C2268&amp;ssl=1" data-orig-size="4032,2268" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="PROJ_3" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PROJ_3.jpg?fit=300%2C169&amp;ssl=1" data-large-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PROJ_3.jpg?fit=770%2C433&amp;ssl=1" data-id="8449" src="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PROJ_3.jpg?resize=770%2C433&amp;ssl=1" alt="Close-up view of a CRT projector lens showing a blue hue, indicating possible issues with the projection. Nearby, a green lens is visible." srcset="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PROJ_3.jpg?resize=1024%2C576&amp;ssl=1 1024w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PROJ_3.jpg?resize=300%2C169&amp;ssl=1 300w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PROJ_3.jpg?resize=768%2C432&amp;ssl=1 768w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PROJ_3.jpg?resize=1536%2C864&amp;ssl=1 1536w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PROJ_3.jpg?resize=2048%2C1152&amp;ssl=1 2048w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PROJ_3.jpg?resize=1200%2C675&amp;ssl=1 1200w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PROJ_3.jpg?resize=1134%2C638&amp;ssl=1 1134w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PROJ_3.jpg?resize=178%2C100&amp;ssl=1 178w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PROJ_3.jpg?w=2310&amp;ssl=1 2310w" sizes="auto, (max-width: 770px) 100vw, 770px"></a></figure>
</figure>







<p>The fungus can be <a href="https://www.curtpalme.com/Fungus_Removal1.shtm">removed</a> and as it so happened, we knew somebody who had performed the procedure on another Sony projector with excellent results. Next time, we would enlist him to the cause!</p>







<h2>Preservation</h2>



<p>To digitize the LaserDiscs, a <a href="https://github.com/simoninns/DomesdayDuplicator/wiki/Overview">Domesday Duplicator</a> setup was assembled and tested thoroughly prior to the trip. This turns a LaserDisc player into an extremely accurate optical scanner by sampling the raw RF signal from the player’s laser. The captures produced by this method are vastly superior to those produced from capturing the conventional output of a player. A Pioneer HLD-X0 MUSE LaserDisc player, expertly calibrated by Bill, was chosen for the process. It is equipped with a red laser with a beam far narrower than that of a traditional LaserDisc player. As a result, it is able to navigate imperfections on the disc surface such as dirt, scratches and rot significantly better.</p>



<figure data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/philwip.com\/2025\/04\/14\/galaxian-3-project-revival\/&quot;}">
<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="770" height="578" data-attachment-id="8522" data-permalink="https://philwip.com/?attachment_id=8522" data-orig-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/DOMESDAY-1.jpg?fit=4032%2C3024&amp;ssl=1" data-orig-size="4032,3024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="DOMESDAY" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/DOMESDAY-1.jpg?fit=300%2C225&amp;ssl=1" data-large-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/DOMESDAY-1.jpg?fit=770%2C578&amp;ssl=1" data-id="8522" src="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/DOMESDAY-1.jpg?resize=770%2C578&amp;ssl=1" alt="A Pioneer LaserDisc player next to a Sony monitor displaying the text 'GALAXIAN PROJECT'." srcset="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/DOMESDAY-1.jpg?resize=1024%2C768&amp;ssl=1 1024w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/DOMESDAY-1.jpg?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/DOMESDAY-1.jpg?resize=768%2C576&amp;ssl=1 768w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/DOMESDAY-1.jpg?resize=1536%2C1152&amp;ssl=1 1536w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/DOMESDAY-1.jpg?resize=2048%2C1536&amp;ssl=1 2048w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/DOMESDAY-1.jpg?resize=1200%2C900&amp;ssl=1 1200w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/DOMESDAY-1.jpg?resize=800%2C600&amp;ssl=1 800w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/DOMESDAY-1.jpg?resize=600%2C450&amp;ssl=1 600w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/DOMESDAY-1.jpg?resize=400%2C300&amp;ssl=1 400w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/DOMESDAY-1.jpg?resize=200%2C150&amp;ssl=1 200w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/DOMESDAY-1.jpg?resize=1134%2C851&amp;ssl=1 1134w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/DOMESDAY-1.jpg?resize=133%2C100&amp;ssl=1 133w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/DOMESDAY-1.jpg?w=2310&amp;ssl=1 2310w" sizes="auto, (max-width: 770px) 100vw, 770px"></figure>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="768" height="1024" data-attachment-id="8521" data-permalink="https://philwip.com/?attachment_id=8521" data-orig-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LD_ZOLGEAR-1.jpg?fit=3024%2C4032&amp;ssl=1" data-orig-size="3024,4032" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="LD_ZOLGEAR" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LD_ZOLGEAR-1.jpg?fit=225%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LD_ZOLGEAR-1.jpg?fit=768%2C1024&amp;ssl=1" data-id="8521" src="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LD_ZOLGEAR-1.jpg?resize=768%2C1024&amp;ssl=1" alt="A close-up of a LaserDisc titled 'GT-6 Zolgear', featuring a blue and white label indicating it's a Japanese version manufactured by Pioneer." srcset="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LD_ZOLGEAR-1.jpg?resize=768%2C1024&amp;ssl=1 768w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LD_ZOLGEAR-1.jpg?resize=225%2C300&amp;ssl=1 225w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LD_ZOLGEAR-1.jpg?resize=1152%2C1536&amp;ssl=1 1152w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LD_ZOLGEAR-1.jpg?resize=1536%2C2048&amp;ssl=1 1536w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LD_ZOLGEAR-1.jpg?resize=900%2C1200&amp;ssl=1 900w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LD_ZOLGEAR-1.jpg?resize=600%2C800&amp;ssl=1 600w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LD_ZOLGEAR-1.jpg?resize=450%2C600&amp;ssl=1 450w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LD_ZOLGEAR-1.jpg?resize=300%2C400&amp;ssl=1 300w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LD_ZOLGEAR-1.jpg?resize=150%2C200&amp;ssl=1 150w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LD_ZOLGEAR-1.jpg?resize=1200%2C1600&amp;ssl=1 1200w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LD_ZOLGEAR-1.jpg?resize=1134%2C1512&amp;ssl=1 1134w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LD_ZOLGEAR-1.jpg?resize=75%2C100&amp;ssl=1 75w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LD_ZOLGEAR-1.jpg?w=2310&amp;ssl=1 2310w" sizes="auto, (max-width: 768px) 100vw, 768px"></figure>
</figure>







<p>The LaserDiscs inside the players were in excellent condition, having been left mostly undisturbed over the last thirty years. The arcade had acquired extra discs but they were excessively warped and were unreadable.</p>



<p>We were very pleased with the captures produced by the setup:</p>



<figure data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/philwip.com\/2025\/04\/14\/galaxian-3-project-revival\/&quot;}">
<figure><a href="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/frame_ntsc_chroma_ar43_4445_ZOL-D2-SA-DMAP_3d.tbc_.png?ssl=1"><img data-recalc-dims="1" loading="lazy" decoding="async" width="760" height="525" data-attachment-id="8444" data-permalink="https://philwip.com/?attachment_id=8444" data-orig-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/frame_ntsc_chroma_ar43_4445_ZOL-D2-SA-DMAP_3d.tbc_.png?fit=760%2C525&amp;ssl=1" data-orig-size="760,525" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="frame_ntsc_chroma_ar43_4445_ZOL-D2-SA-DMAP_3d.tbc" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/frame_ntsc_chroma_ar43_4445_ZOL-D2-SA-DMAP_3d.tbc_.png?fit=300%2C207&amp;ssl=1" data-large-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/frame_ntsc_chroma_ar43_4445_ZOL-D2-SA-DMAP_3d.tbc_.png?fit=760%2C525&amp;ssl=1" data-id="8444" src="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/frame_ntsc_chroma_ar43_4445_ZOL-D2-SA-DMAP_3d.tbc_.png?resize=760%2C525&amp;ssl=1" alt="A futuristic spaceship flying through a colorful, star-filled space scene with vibrant light trails." srcset="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/frame_ntsc_chroma_ar43_4445_ZOL-D2-SA-DMAP_3d.tbc_.png?w=760&amp;ssl=1 760w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/frame_ntsc_chroma_ar43_4445_ZOL-D2-SA-DMAP_3d.tbc_.png?resize=300%2C207&amp;ssl=1 300w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/frame_ntsc_chroma_ar43_4445_ZOL-D2-SA-DMAP_3d.tbc_.png?resize=145%2C100&amp;ssl=1 145w" sizes="auto, (max-width: 760px) 100vw, 760px"></a></figure>



<figure><a href="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/frame_ntsc_chroma_ar43_21536_ZOL-D2-SA-DMAP_3d.tbc_.png?ssl=1"><img data-recalc-dims="1" loading="lazy" decoding="async" width="760" height="525" data-attachment-id="8443" data-permalink="https://philwip.com/?attachment_id=8443" data-orig-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/frame_ntsc_chroma_ar43_21536_ZOL-D2-SA-DMAP_3d.tbc_.png?fit=760%2C525&amp;ssl=1" data-orig-size="760,525" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="frame_ntsc_chroma_ar43_21536_ZOL-D2-SA-DMAP_3d.tbc" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/frame_ntsc_chroma_ar43_21536_ZOL-D2-SA-DMAP_3d.tbc_.png?fit=300%2C207&amp;ssl=1" data-large-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/frame_ntsc_chroma_ar43_21536_ZOL-D2-SA-DMAP_3d.tbc_.png?fit=760%2C525&amp;ssl=1" data-id="8443" src="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/frame_ntsc_chroma_ar43_21536_ZOL-D2-SA-DMAP_3d.tbc_.png?resize=760%2C525&amp;ssl=1" alt="A detailed 3D rendering of a large spacecraft surrounded by stars and a green celestial atmosphere." srcset="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/frame_ntsc_chroma_ar43_21536_ZOL-D2-SA-DMAP_3d.tbc_.png?w=760&amp;ssl=1 760w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/frame_ntsc_chroma_ar43_21536_ZOL-D2-SA-DMAP_3d.tbc_.png?resize=300%2C207&amp;ssl=1 300w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/frame_ntsc_chroma_ar43_21536_ZOL-D2-SA-DMAP_3d.tbc_.png?resize=145%2C100&amp;ssl=1 145w" sizes="auto, (max-width: 760px) 100vw, 760px"></a></figure>
</figure>







<p>Dropouts in the RF signal caused by surface imperfections manifest as lines of colored dots:</p>


<div>
<figure><a href="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/DROPOUTS.png?ssl=1"><img data-recalc-dims="1" loading="lazy" decoding="async" width="760" height="525" data-attachment-id="8427" data-permalink="https://philwip.com/?attachment_id=8427" data-orig-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/DROPOUTS.png?fit=760%2C525&amp;ssl=1" data-orig-size="760,525" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="DROPOUTS" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/DROPOUTS.png?fit=300%2C207&amp;ssl=1" data-large-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/DROPOUTS.png?fit=760%2C525&amp;ssl=1" src="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/DROPOUTS.png?resize=760%2C525&amp;ssl=1" alt="A distorted image featuring a textured green landscape, resembling a forest or a natural backdrop, with a blurred visual effect." srcset="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/DROPOUTS.png?w=760&amp;ssl=1 760w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/DROPOUTS.png?resize=300%2C207&amp;ssl=1 300w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/DROPOUTS.png?resize=145%2C100&amp;ssl=1 145w" sizes="auto, (max-width: 760px) 100vw, 760px"></a></figure></div>






<p>The Domesday Duplicator software suite supports ‘stacking’ of captures from multiple discs to minimize and potentially eliminate all dropouts (save for those present in the mastering process):</p>



<figure data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/philwip.com\/2025\/04\/14\/galaxian-3-project-revival\/&quot;}">
<figure><a href="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Dropouts-1-1.png?ssl=1"><img data-recalc-dims="1" loading="lazy" decoding="async" width="770" height="567" data-attachment-id="8433" data-permalink="https://philwip.com/?attachment_id=8433" data-orig-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Dropouts-1-1.png?fit=1878%2C1382&amp;ssl=1" data-orig-size="1878,1382" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Dropouts 1" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Dropouts-1-1.png?fit=300%2C221&amp;ssl=1" data-large-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Dropouts-1-1.png?fit=770%2C567&amp;ssl=1" data-id="8433" src="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Dropouts-1-1.png?resize=770%2C567&amp;ssl=1" alt="A graph displaying the dropout length in dots over frame numbers, showing variations in a purple line against a grid background for analysis of video signal quality." srcset="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Dropouts-1-1.png?resize=1024%2C754&amp;ssl=1 1024w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Dropouts-1-1.png?resize=300%2C221&amp;ssl=1 300w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Dropouts-1-1.png?resize=768%2C565&amp;ssl=1 768w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Dropouts-1-1.png?resize=1536%2C1130&amp;ssl=1 1536w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Dropouts-1-1.png?resize=1200%2C883&amp;ssl=1 1200w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Dropouts-1-1.png?resize=1134%2C834&amp;ssl=1 1134w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Dropouts-1-1.png?resize=136%2C100&amp;ssl=1 136w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Dropouts-1-1.png?w=1878&amp;ssl=1 1878w" sizes="auto, (max-width: 770px) 100vw, 770px"></a><figcaption>Dropout analysis of disc 1 capture</figcaption></figure>



<figure><a href="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Dropouts-2-1.png?ssl=1"><img data-recalc-dims="1" loading="lazy" decoding="async" width="770" height="567" data-attachment-id="8434" data-permalink="https://philwip.com/?attachment_id=8434" data-orig-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Dropouts-2-1.png?fit=1878%2C1382&amp;ssl=1" data-orig-size="1878,1382" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Dropouts 2" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Dropouts-2-1.png?fit=300%2C221&amp;ssl=1" data-large-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Dropouts-2-1.png?fit=770%2C567&amp;ssl=1" data-id="8434" src="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Dropouts-2-1.png?resize=770%2C567&amp;ssl=1" alt="A graph displaying visible dropout loss analysis, with the x-axis labeled 'Frame number' and the y-axis labeled 'Dropout length (in dots)'. Various purple spikes indicate instances of dropout loss across multiple frames." srcset="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Dropouts-2-1.png?resize=1024%2C754&amp;ssl=1 1024w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Dropouts-2-1.png?resize=300%2C221&amp;ssl=1 300w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Dropouts-2-1.png?resize=768%2C565&amp;ssl=1 768w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Dropouts-2-1.png?resize=1536%2C1130&amp;ssl=1 1536w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Dropouts-2-1.png?resize=1200%2C883&amp;ssl=1 1200w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Dropouts-2-1.png?resize=1134%2C834&amp;ssl=1 1134w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Dropouts-2-1.png?resize=136%2C100&amp;ssl=1 136w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Dropouts-2-1.png?w=1878&amp;ssl=1 1878w" sizes="auto, (max-width: 770px) 100vw, 770px"></a><figcaption>Dropout analysis of disc 2 capture</figcaption></figure>



<figure><a href="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Dropouts-3.png?ssl=1"><img data-recalc-dims="1" loading="lazy" decoding="async" width="770" height="567" data-attachment-id="8432" data-permalink="https://philwip.com/?attachment_id=8432" data-orig-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Dropouts-3.png?fit=1878%2C1382&amp;ssl=1" data-orig-size="1878,1382" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Dropouts 3" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Dropouts-3.png?fit=300%2C221&amp;ssl=1" data-large-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Dropouts-3.png?fit=770%2C567&amp;ssl=1" data-id="8432" src="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Dropouts-3.png?resize=770%2C567&amp;ssl=1" alt="A graph titled 'Visible Dropout Loss Analysis', showing a blank grid with labeled axes for 'Frame number' and 'Dropout length (in dots)'." srcset="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Dropouts-3.png?resize=1024%2C754&amp;ssl=1 1024w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Dropouts-3.png?resize=300%2C221&amp;ssl=1 300w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Dropouts-3.png?resize=768%2C565&amp;ssl=1 768w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Dropouts-3.png?resize=1536%2C1130&amp;ssl=1 1536w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Dropouts-3.png?resize=1200%2C883&amp;ssl=1 1200w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Dropouts-3.png?resize=1134%2C834&amp;ssl=1 1134w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Dropouts-3.png?resize=136%2C100&amp;ssl=1 136w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Dropouts-3.png?w=1878&amp;ssl=1 1878w" sizes="auto, (max-width: 770px) 100vw, 770px"></a><figcaption>Dropout analysis of discs combined</figcaption></figure>
</figure>







<p>Preserving the ROM data from the PCBs was time-consuming but straightforward, as every ROM was a socketed, standard EPROM. Where possible, we attempted to read the PALs and GALs but most had their security-fuse set, preventing data extraction.</p>



<p>The arcade had retained the ROMs and LaserDiscs for Project Dragoon when the machine was converted to Attack of the Zolgear. We preserved these also. The ROM set was an undumped, newer revision dated “MON MAR&nbsp; 1 22:30:10 1993” but unfortunately one of the unique master CPU program ROMs was missing:</p>



<figure data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/philwip.com\/2025\/04\/14\/galaxian-3-project-revival\/&quot;}">
<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="768" height="1024" data-attachment-id="8519" data-permalink="https://philwip.com/?attachment_id=8519" data-orig-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LD_PD-1.jpg?fit=3024%2C4032&amp;ssl=1" data-orig-size="3024,4032" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="LD_PD" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LD_PD-1.jpg?fit=225%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LD_PD-1.jpg?fit=768%2C1024&amp;ssl=1" data-id="8519" src="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LD_PD-1.jpg?resize=768%2C1024&amp;ssl=1" alt="A close-up of a LaserDisc with the title 'G3-THEATER6' in Japanese, produced by Pioneer and planned by Namco, showcasing vibrant rainbow patterns in the reflection." srcset="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LD_PD-1.jpg?resize=768%2C1024&amp;ssl=1 768w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LD_PD-1.jpg?resize=225%2C300&amp;ssl=1 225w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LD_PD-1.jpg?resize=1152%2C1536&amp;ssl=1 1152w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LD_PD-1.jpg?resize=1536%2C2048&amp;ssl=1 1536w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LD_PD-1.jpg?resize=900%2C1200&amp;ssl=1 900w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LD_PD-1.jpg?resize=600%2C800&amp;ssl=1 600w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LD_PD-1.jpg?resize=450%2C600&amp;ssl=1 450w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LD_PD-1.jpg?resize=300%2C400&amp;ssl=1 300w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LD_PD-1.jpg?resize=150%2C200&amp;ssl=1 150w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LD_PD-1.jpg?resize=1200%2C1600&amp;ssl=1 1200w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LD_PD-1.jpg?resize=1134%2C1512&amp;ssl=1 1134w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LD_PD-1.jpg?resize=75%2C100&amp;ssl=1 75w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LD_PD-1.jpg?w=2310&amp;ssl=1 2310w" sizes="auto, (max-width: 768px) 100vw, 768px"></figure>



<figure><a href="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/ROMs-1.jpeg?ssl=1"><img data-recalc-dims="1" loading="lazy" decoding="async" width="770" height="510" data-attachment-id="8426" data-permalink="https://philwip.com/?attachment_id=8426" data-orig-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/ROMs-1.jpeg?fit=3355%2C2222&amp;ssl=1" data-orig-size="3355,2222" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 12 Pro Max&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1709739439&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;5.1&quot;,&quot;iso&quot;:&quot;400&quot;,&quot;shutter_speed&quot;:&quot;0.025&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="ROMs" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/ROMs-1.jpeg?fit=300%2C199&amp;ssl=1" data-large-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/ROMs-1.jpeg?fit=770%2C510&amp;ssl=1" data-id="8426" src="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/ROMs-1.jpeg?resize=770%2C510&amp;ssl=1" alt="A collection of EPROM chips neatly arranged on a black foam background, labeled with various identifiers." srcset="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/ROMs-1.jpeg?resize=1024%2C678&amp;ssl=1 1024w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/ROMs-1.jpeg?resize=300%2C199&amp;ssl=1 300w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/ROMs-1.jpeg?resize=768%2C509&amp;ssl=1 768w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/ROMs-1.jpeg?resize=1536%2C1017&amp;ssl=1 1536w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/ROMs-1.jpeg?resize=2048%2C1356&amp;ssl=1 2048w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/ROMs-1.jpeg?resize=1200%2C795&amp;ssl=1 1200w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/ROMs-1.jpeg?resize=1134%2C751&amp;ssl=1 1134w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/ROMs-1.jpeg?resize=151%2C100&amp;ssl=1 151w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/ROMs-1.jpeg?w=2310&amp;ssl=1 2310w" sizes="auto, (max-width: 770px) 100vw, 770px"></a></figure>
</figure>











<h2>Hardware Analysis and Further Diagnosis</h2>



<p>To better understand the operation of the PSN PCB, I traced out a schematic covering approximately 90% of the PCB. I brute-forced the PALs that we were unable to read by conventional means (these will be uploaded to the <a href="https://wiki.pldarchive.co.uk/">PLD Archive</a> in time). On the software side, Ghidra was used to analyze the 68000 program:</p>


<div>
<figure><a href="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Ghidra.png?ssl=1"><img data-recalc-dims="1" loading="lazy" decoding="async" width="770" height="473" data-attachment-id="8453" data-permalink="https://philwip.com/?attachment_id=8453" data-orig-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Ghidra.png?fit=3744%2C2300&amp;ssl=1" data-orig-size="3744,2300" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Ghidra" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Ghidra.png?fit=300%2C184&amp;ssl=1" data-large-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Ghidra.png?fit=770%2C473&amp;ssl=1" src="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Ghidra.png?resize=770%2C473&amp;ssl=1" alt="A screenshot of a code analysis tool displaying assembly and C code for the PSN binary, with various program trees and symbols visible." srcset="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Ghidra.png?resize=1024%2C629&amp;ssl=1 1024w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Ghidra.png?resize=300%2C184&amp;ssl=1 300w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Ghidra.png?resize=768%2C472&amp;ssl=1 768w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Ghidra.png?resize=1536%2C944&amp;ssl=1 1536w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Ghidra.png?resize=2048%2C1258&amp;ssl=1 2048w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Ghidra.png?resize=1200%2C737&amp;ssl=1 1200w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Ghidra.png?resize=1134%2C697&amp;ssl=1 1134w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Ghidra.png?resize=163%2C100&amp;ssl=1 163w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Ghidra.png?w=2310&amp;ssl=1 2310w" sizes="auto, (max-width: 770px) 100vw, 770px"></a></figure></div>






<p>The first goal was to understand the function of the green and red LEDs. I discovered that the red LED denotes the assertion of the 68000’s /RESET line. After program initialization, the LED is cleared and the green LED illuminates to indicate normal program operation:</p>


<div>
<figure><a href="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LED-Schem.png?ssl=1"><img data-recalc-dims="1" loading="lazy" decoding="async" width="770" height="468" data-attachment-id="8454" data-permalink="https://philwip.com/?attachment_id=8454" data-orig-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LED-Schem.png?fit=2432%2C1480&amp;ssl=1" data-orig-size="2432,1480" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="LED Schem" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LED-Schem.png?fit=300%2C183&amp;ssl=1" data-large-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LED-Schem.png?fit=770%2C468&amp;ssl=1" src="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LED-Schem.png?resize=770%2C468&amp;ssl=1" alt="A printed circuit board schematic showing connections between various electronic components, including a 74LS374 and TD2083AP integrated circuits, with LED indicators for visual feedback." srcset="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LED-Schem.png?resize=1024%2C623&amp;ssl=1 1024w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LED-Schem.png?resize=300%2C183&amp;ssl=1 300w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LED-Schem.png?resize=768%2C467&amp;ssl=1 768w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LED-Schem.png?resize=1536%2C935&amp;ssl=1 1536w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LED-Schem.png?resize=2048%2C1246&amp;ssl=1 2048w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LED-Schem.png?resize=1200%2C730&amp;ssl=1 1200w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LED-Schem.png?resize=1134%2C690&amp;ssl=1 1134w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LED-Schem.png?resize=164%2C100&amp;ssl=1 164w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/LED-Schem.png?w=2310&amp;ssl=1 2310w" sizes="auto, (max-width: 770px) 100vw, 770px"></a></figure></div>






<p>An examination of the 68000 code revealed no power-on tests nor any possibility of initialization failure that could cause the flashing LED sequence. The events capable of triggering a reset were confirmed as:</p>



<ul>
<li>Watchdog timeout</li>



<li>Generic 68000 exception (e.g. address error, illegal instruction)</li>



<li>Changing the PCB test switch from ON to OFF</li>



<li>Reset serial packet sent by the RSO</li>
</ul>







<p>After cobbling together a power harness, I powered up each PSN PCB on my test bench. No flashing LED pattern was observed after numerous resets with the 5V supply adjusted between 4.65V and 5.1V.</p>



<p>The PSN PCB only transmits serial data upon receipt of a valid packet from the RSO. There are three types of packet:</p>



<ul>
<li>RSO-&gt;PSN: Update outputs (lamps, motors and sound)</li>



<li>PSN-&gt;RSO: Send button state and analog controller values to RSO</li>



<li>Reset: Restart the PSN program</li>
</ul>







<p>An 8-bit checksum is sent with each packet. Packets failing a checksum are dropped without consequence. An examination of the RSO code revealed that a Reset packet is sent to each PSN once during boot. There is no error handling that would cause multiple reset packets to be sent and trigger the LED sequence observed on-site. The RSO sends RSO-&gt;PSN followed by PSN-&gt;RSO packets continuously, even if the PSN board is not connected.</p>



<p>My next step was to verify that the serial link of each PSN was functioning correctly. The link is 9-bits (MSB first) at 1Mbps. The ninth bit is not a parity bit but is instead used to trigger an interrupt on the receiving C139 to denote the end of a packet. I chose an Arduino Uno with an RS-422&lt;-&gt;TTL adapter to interface with the PSN PCBs. I wrote code to transmit and receive data to and from each PSN, verifying the packet checksum on the Arduino side. No faults were found by this process.</p>



<p>I used this setup to verify that all I/O was functioning correctly:</p>



		<figure>
			
			
			
		</figure>
		






<p>The PSN PCBs were originally designed for GH-28/GM-16 and as a result there are several features unused by GT-6. Of note is the video hardware that drove small displays in the player controls, showing the player’s rank and shield status:</p>



<figure><a href="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Gun-Displays.png?ssl=1"><img data-recalc-dims="1" loading="lazy" decoding="async" width="770" height="399" data-attachment-id="8437" data-permalink="https://philwip.com/?attachment_id=8437" data-orig-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Gun-Displays.png?fit=985%2C510&amp;ssl=1" data-orig-size="985,510" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Gun Displays" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Gun-Displays.png?fit=300%2C155&amp;ssl=1" data-large-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Gun-Displays.png?fit=770%2C399&amp;ssl=1" src="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Gun-Displays.png?resize=770%2C399&amp;ssl=1" alt="Displays showing player rankings and shield power status in a video game arcade machine." srcset="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Gun-Displays.png?w=985&amp;ssl=1 985w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Gun-Displays.png?resize=300%2C155&amp;ssl=1 300w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Gun-Displays.png?resize=768%2C398&amp;ssl=1 768w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Gun-Displays.png?resize=193%2C100&amp;ssl=1 193w" sizes="auto, (max-width: 770px) 100vw, 770px"></a></figure>







<p>As for GT-6, If one was to add character ROMs and connect a 15KHz display to the video outputs, you would see a debug screen that shows the state of the input and other statistics:</p>


<div>
<figure><a href="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PSN-Debug-Screen.png?ssl=1"><img data-recalc-dims="1" loading="lazy" decoding="async" width="256" height="192" data-attachment-id="8402" data-permalink="https://philwip.com/?attachment_id=8402" data-orig-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PSN-Debug-Screen.png?fit=256%2C192&amp;ssl=1" data-orig-size="256,192" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="PSN Debug Screen" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PSN-Debug-Screen.png?fit=256%2C192&amp;ssl=1" data-large-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PSN-Debug-Screen.png?fit=256%2C192&amp;ssl=1" src="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PSN-Debug-Screen.png?resize=256%2C192&amp;ssl=1" alt="Text display from a vintage arcade game diagnostic screen showing various memory addresses and buffers." srcset="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PSN-Debug-Screen.png?w=256&amp;ssl=1 256w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PSN-Debug-Screen.png?resize=200%2C150&amp;ssl=1 200w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PSN-Debug-Screen.png?resize=133%2C100&amp;ssl=1 133w" sizes="auto, (max-width: 256px) 100vw, 256px"></a></figure></div>






<p>Using <a href="http://www.easy68k.com/">Easy68k</a>, I created a test program to verify the work RAM and C139 buffer RAM on each PSN. All PCBs passed the tests.</p>



<p>To rule out any possible issues with the RSO PCB and to recreate the communication link of the machine, I wrote a pair of 68000 programs that would send random data accompanied by a CRC back and forth between the RSO and PSN, halting on a CRC failure. I also included a RAM test for the RSO work RAM and C139 buffer RAM. No faults were detected and the signal integrity of the RS-422 link appeared fine on an oscilloscope. At this point, I was convinced the faults lay elsewhere.</p>











<h2>Trip 2: March 2025</h2>



<p>It was time to return to Fun World to attempt another repair. This year’s team added Ford Seidel and Thomas Daede, the latter of whom had experience of servicing CRT projectors. Our main objectives were to:</p>



<ul>
<li>Fix the player input issues</li>



<li>Service the left-side projector (and the right-side, time-permitting)</li>



<li>Locate the missing ROM for the undumped revision of Project Dragoon</li>
</ul>







<p>This year we were much better informed about the operation of the game and would also arrive better equipped. Ford very graciously agreed to fly with an HP 1660C logic analyzer in his carry-on luggage and arranged to borrow a digital storage oscilloscope from a friend in Boston (thank you Gally!). As a precaution, I purchased replacement components for the serial sections of the RSO and PSN PCBs: optocouplers and three sets of SN75157/SN75158 RS-422 receivers/transmitters.</p>



<p>With the PSN PCBs re-installed and the game powered-on, the previous behaviour was observed; the two ‘bad’ PCBs began flashing their LEDs. On a subsequent power-on however, one of the ‘bad’ PCBs suddenly began working, allowing players 5 and 6 to start a game!</p>



<p>During my research, I had found photos of the inside of another machine showing leads connecting the GND test points of each PSN PCB to the metal frame of the left control box. These were not present on this machine. Bill fabricated a set of ground leads and we installed them. We never again saw the dreaded flashing LED sequence. I hadn’t noted any grounding or noise issues during early probing but I was happy to accept this victory and move on. We later verified that the AC input was properly grounded.</p>


<div>
<figure><a href="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Grounded.jpg?ssl=1"><img data-recalc-dims="1" loading="lazy" decoding="async" width="768" height="1024" data-attachment-id="8456" data-permalink="https://philwip.com/?attachment_id=8456" data-orig-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Grounded.jpg?fit=3024%2C4032&amp;ssl=1" data-orig-size="3024,4032" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Grounded" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Grounded.jpg?fit=225%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Grounded.jpg?fit=768%2C1024&amp;ssl=1" src="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Grounded.jpg?resize=768%2C1024&amp;ssl=1" alt="A close-up of an EMI filter and surge protector mounted on a wall. The unit is labeled 'Parfocal Systems' and shows signs of wear, with a dirty appearance. A yellow light is illuminated in the center, indicating power status." srcset="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Grounded.jpg?resize=768%2C1024&amp;ssl=1 768w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Grounded.jpg?resize=225%2C300&amp;ssl=1 225w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Grounded.jpg?resize=1152%2C1536&amp;ssl=1 1152w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Grounded.jpg?resize=1536%2C2048&amp;ssl=1 1536w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Grounded.jpg?resize=900%2C1200&amp;ssl=1 900w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Grounded.jpg?resize=600%2C800&amp;ssl=1 600w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Grounded.jpg?resize=450%2C600&amp;ssl=1 450w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Grounded.jpg?resize=300%2C400&amp;ssl=1 300w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Grounded.jpg?resize=150%2C200&amp;ssl=1 150w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Grounded.jpg?resize=1200%2C1600&amp;ssl=1 1200w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Grounded.jpg?resize=1134%2C1512&amp;ssl=1 1134w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Grounded.jpg?resize=75%2C100&amp;ssl=1 75w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Grounded.jpg?w=2310&amp;ssl=1 2310w" sizes="auto, (max-width: 768px) 100vw, 768px"></a></figure></div>






<p>The third PSN PCB failed to work. The oscilloscope was set up and probing commenced…</p>



<p>The CPU was running normally and was servicing interrupts. However, no C139 receive interrupts were being generated. Serial data was arriving over the RSO link but probing the SN75157 line receiver showed sensible input voltages but an output plagued with errant spikes:</p>



<figure><a href="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/RigolDS2.png?ssl=1"><img data-recalc-dims="1" loading="lazy" decoding="async" width="770" height="474" data-attachment-id="8435" data-permalink="https://philwip.com/?attachment_id=8435" data-orig-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/RigolDS2.png?fit=1024%2C630&amp;ssl=1" data-orig-size="1024,630" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="RigolDS2" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/RigolDS2.png?fit=300%2C185&amp;ssl=1" data-large-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/RigolDS2.png?fit=770%2C474&amp;ssl=1" src="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/RigolDS2.png?resize=770%2C474&amp;ssl=1" alt="Screenshot of an oscilloscope displaying multiple channel waveforms, showing voltage levels over time." srcset="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/RigolDS2.png?w=1024&amp;ssl=1 1024w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/RigolDS2.png?resize=300%2C185&amp;ssl=1 300w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/RigolDS2.png?resize=768%2C473&amp;ssl=1 768w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/RigolDS2.png?resize=163%2C100&amp;ssl=1 163w" sizes="auto, (max-width: 770px) 100vw, 770px"></a><figcaption>Note the spikes on the pink signal (channel 3)</figcaption></figure>







<p>Why this IC was suddenly presenting problems despite extensive testing I did not know. The decision was made to replace it and I was glad I’d had the foresight to bring replacements! Bill desoldered the IC and installed a socket. With the new IC fitted, we eagerly applied power and noted the synchronized LED pattern across all PCBs, indicating receipt of a reset packet from the RSO:</p>



		<figure>
			
			
			
		</figure>
		






<p>In test mode all six player inputs were now working!</p>



		<figure>
			
			
			
		</figure>
		






<p>The relief was immense. Having lain on the floor for several hours, I took a much deserved walk around the arcade to stretch out and discover some exciting games:</p>


<div>
<figure><a href="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Fun-Chicken.jpeg?ssl=1"><img data-recalc-dims="1" loading="lazy" decoding="async" width="577" height="1024" data-attachment-id="8467" data-permalink="https://philwip.com/?attachment_id=8467" data-orig-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Fun-Chicken.jpeg?fit=2057%2C3648&amp;ssl=1" data-orig-size="2057,3648" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 12 Pro Max&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1709735766&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;5.1&quot;,&quot;iso&quot;:&quot;800&quot;,&quot;shutter_speed&quot;:&quot;0.033333333333333&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="Fun Chicken" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Fun-Chicken.jpeg?fit=169%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Fun-Chicken.jpeg?fit=577%2C1024&amp;ssl=1" src="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Fun-Chicken.jpeg?resize=577%2C1024&amp;ssl=1" alt="A coin-operated machine labeled 'Fun Chicken!' featuring a plastic chicken on a pedestal, designed for players to watch as the chicken lays an egg. The machine has instructions for operation." srcset="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Fun-Chicken.jpeg?resize=577%2C1024&amp;ssl=1 577w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Fun-Chicken.jpeg?resize=169%2C300&amp;ssl=1 169w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Fun-Chicken.jpeg?resize=768%2C1362&amp;ssl=1 768w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Fun-Chicken.jpeg?resize=866%2C1536&amp;ssl=1 866w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Fun-Chicken.jpeg?resize=1155%2C2048&amp;ssl=1 1155w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Fun-Chicken.jpeg?resize=1200%2C2128&amp;ssl=1 1200w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Fun-Chicken.jpeg?resize=1134%2C2011&amp;ssl=1 1134w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Fun-Chicken.jpeg?resize=56%2C100&amp;ssl=1 56w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Fun-Chicken.jpeg?w=1540&amp;ssl=1 1540w" sizes="auto, (max-width: 577px) 100vw, 577px"></a></figure></div>






<p>The day was met with further good news: with the aid of the arcade’s technician, Alex found and dumped the missing EPROM from Project Dragoon!</p>



<p>Meanwhile, Thomas, Bill and Scott were busy servicing the left-side projector:</p>


<div>
<figure><a href="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Projector.jpeg?ssl=1"><img data-recalc-dims="1" loading="lazy" decoding="async" width="770" height="906" data-attachment-id="8461" data-permalink="https://philwip.com/?attachment_id=8461" data-orig-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Projector.jpeg?fit=2655%2C3125&amp;ssl=1" data-orig-size="2655,3125" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 12 Pro Max&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1742997796&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;5.1&quot;,&quot;iso&quot;:&quot;400&quot;,&quot;shutter_speed&quot;:&quot;0.016666666666667&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="Projector" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Projector.jpeg?fit=255%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Projector.jpeg?fit=770%2C906&amp;ssl=1" src="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Projector.jpeg?resize=770%2C906&amp;ssl=1" alt="Inside view of a Sony projector showing circuit boards, CRT tubes with different color screens, and various electronic components." srcset="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Projector.jpeg?resize=870%2C1024&amp;ssl=1 870w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Projector.jpeg?resize=255%2C300&amp;ssl=1 255w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Projector.jpeg?resize=768%2C904&amp;ssl=1 768w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Projector.jpeg?resize=1305%2C1536&amp;ssl=1 1305w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Projector.jpeg?resize=1740%2C2048&amp;ssl=1 1740w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Projector.jpeg?resize=1200%2C1412&amp;ssl=1 1200w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Projector.jpeg?resize=1134%2C1335&amp;ssl=1 1134w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Projector.jpeg?resize=85%2C100&amp;ssl=1 85w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Projector.jpeg?w=1540&amp;ssl=1 1540w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Projector.jpeg?w=2310&amp;ssl=1 2310w" sizes="auto, (max-width: 770px) 100vw, 770px"></a></figure></div>






<p>The blue CRT had severe burn-in:</p>


<div>
<figure><a href="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Burn.jpeg?ssl=1"><img data-recalc-dims="1" loading="lazy" decoding="async" width="770" height="578" data-attachment-id="8421" data-permalink="https://philwip.com/?attachment_id=8421" data-orig-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Burn.jpeg?fit=4032%2C3024&amp;ssl=1" data-orig-size="4032,3024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 12 Pro Max&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1743010826&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;5.1&quot;,&quot;iso&quot;:&quot;500&quot;,&quot;shutter_speed&quot;:&quot;0.020833333333333&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="Burn" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Burn.jpeg?fit=300%2C225&amp;ssl=1" data-large-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Burn.jpeg?fit=770%2C578&amp;ssl=1" src="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Burn.jpeg?resize=770%2C578&amp;ssl=1" alt="Close-up of a LaserDisc player display showing a faded 'INSERT COINS' screen." srcset="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Burn.jpeg?resize=1024%2C768&amp;ssl=1 1024w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Burn.jpeg?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Burn.jpeg?resize=768%2C576&amp;ssl=1 768w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Burn.jpeg?resize=1536%2C1152&amp;ssl=1 1536w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Burn.jpeg?resize=2048%2C1536&amp;ssl=1 2048w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Burn.jpeg?resize=1200%2C900&amp;ssl=1 1200w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Burn.jpeg?resize=800%2C600&amp;ssl=1 800w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Burn.jpeg?resize=600%2C450&amp;ssl=1 600w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Burn.jpeg?resize=400%2C300&amp;ssl=1 400w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Burn.jpeg?resize=200%2C150&amp;ssl=1 200w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Burn.jpeg?resize=1134%2C851&amp;ssl=1 1134w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Burn.jpeg?resize=133%2C100&amp;ssl=1 133w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Burn.jpeg?w=2310&amp;ssl=1 2310w" sizes="auto, (max-width: 770px) 100vw, 770px"></a></figure></div>






<p>The coolant was removed from each chamber using a syringe and CLR was used to clean the fogged glass. We would let it sit overnight and perform the coolant change the following day.</p>


<div>
<figure><a href="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Projector-Juice.jpeg?ssl=1"><img data-recalc-dims="1" loading="lazy" decoding="async" width="770" height="578" data-attachment-id="8423" data-permalink="https://philwip.com/?attachment_id=8423" data-orig-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Projector-Juice.jpeg?fit=4032%2C3024&amp;ssl=1" data-orig-size="4032,3024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.2&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 12 Pro Max&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1743091638&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;7.5&quot;,&quot;iso&quot;:&quot;320&quot;,&quot;shutter_speed&quot;:&quot;0.016666666666667&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="Projector Juice" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Projector-Juice.jpeg?fit=300%2C225&amp;ssl=1" data-large-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Projector-Juice.jpeg?fit=770%2C578&amp;ssl=1" src="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Projector-Juice.jpeg?resize=770%2C578&amp;ssl=1" alt="Various cups containing colorful liquids and materials for servicing a project, arranged on a patterned carpet." srcset="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Projector-Juice.jpeg?resize=1024%2C768&amp;ssl=1 1024w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Projector-Juice.jpeg?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Projector-Juice.jpeg?resize=768%2C576&amp;ssl=1 768w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Projector-Juice.jpeg?resize=1536%2C1152&amp;ssl=1 1536w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Projector-Juice.jpeg?resize=2048%2C1536&amp;ssl=1 2048w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Projector-Juice.jpeg?resize=1200%2C900&amp;ssl=1 1200w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Projector-Juice.jpeg?resize=800%2C600&amp;ssl=1 800w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Projector-Juice.jpeg?resize=600%2C450&amp;ssl=1 600w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Projector-Juice.jpeg?resize=400%2C300&amp;ssl=1 400w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Projector-Juice.jpeg?resize=200%2C150&amp;ssl=1 200w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Projector-Juice.jpeg?resize=1134%2C851&amp;ssl=1 1134w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Projector-Juice.jpeg?resize=133%2C100&amp;ssl=1 133w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Projector-Juice.jpeg?w=2310&amp;ssl=1 2310w" sizes="auto, (max-width: 770px) 100vw, 770px"></a><figcaption>Don’t drink the projector juice!</figcaption></figure></div>






<p>Progress at the end of the first day was extremely promising and I hoped for a more relaxed following day.</p>



<p>The next morning, while discussing CRT projectors over breakfast, Alex searched eBay for possible replacements. Miraculously, an untested Sony VPH-1040Q was listed for auction two and half hours away in Connecticut. According to <a href="http://curtpalme.com/">curtpalme.com</a>, this uses the same tubes as the original projector. We could either swap the tubes (assuming they were in better condition) or mount the new projector in place of the old one. Alex contacted the seller and convinced him to end the auction early, offering to pay double the current asking price of $25. Ford and Alex set off on an exciting road trip to pick it up, while the rest of us returned to Fun World.</p>



<p>I spent the day collecting measurements from the running machine for the purpose of documentation (e.g. clock frequencies and interrupt signals) while the others performed the projector coolant change and calibration. A friend, Jen, dropped in to help and observe, having driven from Vermont.</p>



<p>At one point I accidentally knocked off a jumper on the RSO board and we spent twenty painful minutes wondering why the game stopped responding to inputs and would not display anything other than ‘INSERT COINS’. Said jumper determined the VBLANK interrupt source for the RSO PCB and without it, the game was effectively paused. To avoid any further stress, I ceased probing.</p>



<p>Late in the afternoon, Alex and Ford returned with the projector:</p>


<div>
<figure><a href="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Projector_In_Car.jpg?ssl=1"><img data-recalc-dims="1" loading="lazy" decoding="async" width="770" height="578" data-attachment-id="8419" data-permalink="https://philwip.com/?attachment_id=8419" data-orig-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Projector_In_Car.jpg?fit=5712%2C4284&amp;ssl=1" data-orig-size="5712,4284" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="Projector_In_Car" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Projector_In_Car.jpg?fit=300%2C225&amp;ssl=1" data-large-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Projector_In_Car.jpg?fit=770%2C578&amp;ssl=1" src="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Projector_In_Car.jpg?resize=770%2C578&amp;ssl=1" alt="A car trunk with the lid open, revealing a white object with vents inside, possibly a projection or audio device." srcset="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Projector_In_Car.jpg?resize=1024%2C768&amp;ssl=1 1024w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Projector_In_Car.jpg?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Projector_In_Car.jpg?resize=768%2C576&amp;ssl=1 768w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Projector_In_Car.jpg?resize=1536%2C1152&amp;ssl=1 1536w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Projector_In_Car.jpg?resize=2048%2C1536&amp;ssl=1 2048w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Projector_In_Car.jpg?resize=1200%2C900&amp;ssl=1 1200w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Projector_In_Car.jpg?resize=800%2C600&amp;ssl=1 800w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Projector_In_Car.jpg?resize=600%2C450&amp;ssl=1 600w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Projector_In_Car.jpg?resize=400%2C300&amp;ssl=1 400w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Projector_In_Car.jpg?resize=200%2C150&amp;ssl=1 200w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Projector_In_Car.jpg?resize=1134%2C851&amp;ssl=1 1134w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Projector_In_Car.jpg?resize=133%2C100&amp;ssl=1 133w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Projector_In_Car.jpg?w=2310&amp;ssl=1 2310w" sizes="auto, (max-width: 770px) 100vw, 770px"></a></figure></div>






<p>It appeared to be working and the tubes were bright and burn-free. The new projector was almost identical to the old unit, allowing for a drop-in replacement. Once installed in the game, the results were magnificent:</p>



<figure><a href="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/New-Projector.jpg?ssl=1"><img data-recalc-dims="1" loading="lazy" decoding="async" width="770" height="433" data-attachment-id="8481" data-permalink="https://philwip.com/?attachment_id=8481" data-orig-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/New-Projector.jpg?fit=4032%2C2268&amp;ssl=1" data-orig-size="4032,2268" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="New Projector" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/New-Projector.jpg?fit=300%2C169&amp;ssl=1" data-large-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/New-Projector.jpg?fit=770%2C433&amp;ssl=1" src="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/New-Projector.jpg?resize=770%2C433&amp;ssl=1" alt="A screen displaying a video game interface with text indicating 'INSERT COINS', showing elements like shield status and player rank. The background features starry space graphics." srcset="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/New-Projector.jpg?resize=1024%2C576&amp;ssl=1 1024w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/New-Projector.jpg?resize=300%2C169&amp;ssl=1 300w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/New-Projector.jpg?resize=768%2C432&amp;ssl=1 768w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/New-Projector.jpg?resize=1536%2C864&amp;ssl=1 1536w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/New-Projector.jpg?resize=2048%2C1152&amp;ssl=1 2048w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/New-Projector.jpg?resize=1200%2C675&amp;ssl=1 1200w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/New-Projector.jpg?resize=1134%2C638&amp;ssl=1 1134w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/New-Projector.jpg?resize=178%2C100&amp;ssl=1 178w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/New-Projector.jpg?w=2310&amp;ssl=1 2310w" sizes="auto, (max-width: 770px) 100vw, 770px"></a></figure>







<p>Alex and Ford replaced numerous burned-out fluorescent fittings and bulbs around the machine. Bill fixed several issues with the speaker wiring and fitted replacement speakers, bringing both front and rear channels back to life.</p>



<p>The vacuum-formed sign on the outside of the machine is in great condition but several plastic mounts inside had snapped over time. Thomas quickly designed and produced replacement mounts that could be bolted to the machine through existing holes. These had been printed on Bill’s 3D printer overnight and worked well:</p>



<figure data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/philwip.com\/2025\/04\/14\/galaxian-3-project-revival\/&quot;}">
<figure><a href="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Zolgear-Sign-2.jpg?ssl=1"><img data-recalc-dims="1" loading="lazy" decoding="async" width="770" height="514" data-attachment-id="8478" data-permalink="https://philwip.com/?attachment_id=8478" data-orig-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Zolgear-Sign-2.jpg?fit=3504%2C2336&amp;ssl=1" data-orig-size="3504,2336" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;5.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;ILCE-7M4&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1742976222&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;40&quot;,&quot;iso&quot;:&quot;8000&quot;,&quot;shutter_speed&quot;:&quot;0.0125&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="Zolgear Sign 2" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Zolgear-Sign-2.jpg?fit=300%2C200&amp;ssl=1" data-large-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Zolgear-Sign-2.jpg?fit=770%2C514&amp;ssl=1" data-id="8478" src="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Zolgear-Sign-2.jpg?resize=770%2C514&amp;ssl=1" alt="A colorful arcade cabinet marquee for the game 'Attack of the Zolgear', featuring dramatic graphics of a giant monster attacking a city with text highlighting game features and alerts." srcset="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Zolgear-Sign-2.jpg?resize=1024%2C683&amp;ssl=1 1024w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Zolgear-Sign-2.jpg?resize=300%2C200&amp;ssl=1 300w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Zolgear-Sign-2.jpg?resize=768%2C512&amp;ssl=1 768w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Zolgear-Sign-2.jpg?resize=1536%2C1024&amp;ssl=1 1536w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Zolgear-Sign-2.jpg?resize=2048%2C1365&amp;ssl=1 2048w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Zolgear-Sign-2.jpg?resize=1200%2C800&amp;ssl=1 1200w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Zolgear-Sign-2.jpg?resize=1134%2C756&amp;ssl=1 1134w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Zolgear-Sign-2.jpg?resize=150%2C100&amp;ssl=1 150w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/Zolgear-Sign-2.jpg?w=2310&amp;ssl=1 2310w" sizes="auto, (max-width: 770px) 100vw, 770px"></a></figure>



<figure><a href="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/3D-Mount.jpeg?ssl=1"><img data-recalc-dims="1" loading="lazy" decoding="async" width="770" height="578" data-attachment-id="8479" data-permalink="https://philwip.com/?attachment_id=8479" data-orig-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/3D-Mount.jpeg?fit=4032%2C3024&amp;ssl=1" data-orig-size="4032,3024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 12 Pro Max&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1743092952&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;5.1&quot;,&quot;iso&quot;:&quot;500&quot;,&quot;shutter_speed&quot;:&quot;0.017857142857143&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="3D Mount" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/3D-Mount.jpeg?fit=300%2C225&amp;ssl=1" data-large-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/3D-Mount.jpeg?fit=770%2C578&amp;ssl=1" data-id="8479" src="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/3D-Mount.jpeg?resize=770%2C578&amp;ssl=1" alt="A close-up view of a black 3D-printed part mounted on a surface, featuring a cylindrical shape with a hole at the top. In the background, there is a graphic design related to the game 'Attack of the Zolgear'." srcset="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/3D-Mount.jpeg?resize=1024%2C768&amp;ssl=1 1024w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/3D-Mount.jpeg?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/3D-Mount.jpeg?resize=768%2C576&amp;ssl=1 768w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/3D-Mount.jpeg?resize=1536%2C1152&amp;ssl=1 1536w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/3D-Mount.jpeg?resize=2048%2C1536&amp;ssl=1 2048w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/3D-Mount.jpeg?resize=1200%2C900&amp;ssl=1 1200w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/3D-Mount.jpeg?resize=800%2C600&amp;ssl=1 800w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/3D-Mount.jpeg?resize=600%2C450&amp;ssl=1 600w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/3D-Mount.jpeg?resize=400%2C300&amp;ssl=1 400w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/3D-Mount.jpeg?resize=200%2C150&amp;ssl=1 200w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/3D-Mount.jpeg?resize=1134%2C851&amp;ssl=1 1134w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/3D-Mount.jpeg?resize=133%2C100&amp;ssl=1 133w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/3D-Mount.jpeg?w=2310&amp;ssl=1 2310w" sizes="auto, (max-width: 770px) 100vw, 770px"></a></figure>
</figure>







<p>At this point, it was time to enjoy some credits on the newly working game!</p>



		<figure>
			
			
			
		</figure>
		














<h2>Problems</h2>



<p>Unfortunately there were issues with the newly-working machine. The day after its installation, as the arcade was about to close, the new projector began to intermittently shut down. The decision was made to remove it and swap the tubes into the old projector. Though time consuming, Thomas and Bill got the job done.</p>



<p>The next day, after the machine was in operation for about three hours, video sync issues appeared on the left-side:</p>



		<figure>
			
			
			
		</figure>
		






<p>The left-side LaserDisc player was suspected to be at fault. We had learned during our previous visit that the arcade had four spare LD-V8000 units, though none worked well enough to be swapped in. Suspecting the DEGE PCB, Bill and Scott transplanted a working PCB from the unit that showed the most promise.</p>


<div>
<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="768" height="1024" data-attachment-id="8420" data-permalink="https://philwip.com/?attachment_id=8420" data-orig-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PLAYER_STACK.jpg?fit=3024%2C4032&amp;ssl=1" data-orig-size="3024,4032" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="PLAYER_STACK" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PLAYER_STACK.jpg?fit=225%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PLAYER_STACK.jpg?fit=768%2C1024&amp;ssl=1" src="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PLAYER_STACK.jpg?resize=768%2C1024&amp;ssl=1" alt="A stack of four Pioneer LaserDisc players arranged vertically, with visible cables connected to them, placed against a fence in an arcade setting." srcset="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PLAYER_STACK.jpg?resize=768%2C1024&amp;ssl=1 768w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PLAYER_STACK.jpg?resize=225%2C300&amp;ssl=1 225w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PLAYER_STACK.jpg?resize=1152%2C1536&amp;ssl=1 1152w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PLAYER_STACK.jpg?resize=1536%2C2048&amp;ssl=1 1536w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PLAYER_STACK.jpg?resize=900%2C1200&amp;ssl=1 900w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PLAYER_STACK.jpg?resize=600%2C800&amp;ssl=1 600w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PLAYER_STACK.jpg?resize=450%2C600&amp;ssl=1 450w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PLAYER_STACK.jpg?resize=300%2C400&amp;ssl=1 300w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PLAYER_STACK.jpg?resize=150%2C200&amp;ssl=1 150w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PLAYER_STACK.jpg?resize=1200%2C1600&amp;ssl=1 1200w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PLAYER_STACK.jpg?resize=1134%2C1512&amp;ssl=1 1134w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PLAYER_STACK.jpg?resize=75%2C100&amp;ssl=1 75w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/PLAYER_STACK.jpg?w=2310&amp;ssl=1 2310w" sizes="auto, (max-width: 768px) 100vw, 768px"></figure></div>






<p>Alas, after another day of operation the problem re-appeared. Further diagnosis is needed and it is possible that there is an issue with the V-MIX PCB.</p>











<h2>Future Work</h2>



<p>Despite the issues, overall we are immensely pleased with what we achieved during our trips and I am very proud to have been part of the effort. The current fault will hopefully be fixed in time but please bear in mind that this is a time-intensive volunteer project and patience is a virtue!</p>



<p>We would recommend holding off on any road trips to play the game until it is more stable but if you do make the trip, plan to soon after the arcade opens while the machine is in a good mood! (Note that the operation of the machine is at the discretion of the arcade owner and they may choose to put it out of service until the fault is fixed).</p>



<p>There are a number of fixes and improvements that could be made:</p>



<ul>
<li>Re-install the original speakers or find modern equivalents</li>



<li>Service the power supplies</li>



<li>Replace the non-working player 5 vibration motor</li>



<li>Fine-tune the projectors</li>



<li>Perform a coolant swap on the right-side projector</li>



<li>Fix the vertical gap between the two displays</li>



<li>Investigate a solid-state replacement for the LaserDisc players</li>
</ul>







<p>Hopefully the game will continue to run well enough so that it can be enjoyed by all!</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="770" height="514" data-attachment-id="8469" data-permalink="https://philwip.com/?attachment_id=8469" data-orig-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/IMG_6272.jpg?fit=4031%2C2691&amp;ssl=1" data-orig-size="4031,2691" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="IMG_6272" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/IMG_6272.jpg?fit=300%2C200&amp;ssl=1" data-large-file="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/IMG_6272.jpg?fit=770%2C514&amp;ssl=1" src="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/IMG_6272.jpg?resize=770%2C514&amp;ssl=1" alt="The interior of an arcade game featuring the title 'Attack of the Zolgear' displayed on a large screen, with multiple gunner positions in front." srcset="https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/IMG_6272.jpg?resize=1024%2C684&amp;ssl=1 1024w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/IMG_6272.jpg?resize=300%2C200&amp;ssl=1 300w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/IMG_6272.jpg?resize=768%2C513&amp;ssl=1 768w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/IMG_6272.jpg?resize=1536%2C1025&amp;ssl=1 1536w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/IMG_6272.jpg?resize=2048%2C1367&amp;ssl=1 2048w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/IMG_6272.jpg?resize=1200%2C801&amp;ssl=1 1200w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/IMG_6272.jpg?resize=1134%2C757&amp;ssl=1 1134w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/IMG_6272.jpg?resize=150%2C100&amp;ssl=1 150w, https://i0.wp.com/philwip.com/wp-content/uploads/2025/04/IMG_6272.jpg?w=2310&amp;ssl=1 2310w" sizes="auto, (max-width: 770px) 100vw, 770px"></figure>
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A Map of British Dialects (2023) (200 pts)]]></title>
            <link>https://starkeycomics.com/2023/11/07/map-of-british-english-dialects/</link>
            <guid>43734953</guid>
            <pubDate>Sat, 19 Apr 2025 08:02:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://starkeycomics.com/2023/11/07/map-of-british-english-dialects/">https://starkeycomics.com/2023/11/07/map-of-british-english-dialects/</a>, See on <a href="https://news.ycombinator.com/item?id=43734953">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

				
<figure><a href="https://i0.wp.com/starkeycomics.com/wp-content/uploads/2023/11/British-accents-5-JPG-1.jpg?ssl=1"><img data-recalc-dims="1" decoding="async" width="697" height="974" data-attachment-id="1885" data-permalink="https://starkeycomics.com/2023/11/07/map-of-british-english-dialects/british-accents-5-jpg-1/" data-orig-file="https://i0.wp.com/starkeycomics.com/wp-content/uploads/2023/11/British-accents-5-JPG-1.jpg?fit=945%2C1321&amp;ssl=1" data-orig-size="945,1321" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="British-accents-5-JPG-1" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/starkeycomics.com/wp-content/uploads/2023/11/British-accents-5-JPG-1.jpg?fit=215%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/starkeycomics.com/wp-content/uploads/2023/11/British-accents-5-JPG-1.jpg?fit=697%2C974&amp;ssl=1" src="https://i0.wp.com/starkeycomics.com/wp-content/uploads/2023/11/British-accents-5-JPG-1.jpg?resize=697%2C974&amp;ssl=1" alt="" srcset="https://i0.wp.com/starkeycomics.com/wp-content/uploads/2023/11/British-accents-5-JPG-1.jpg?resize=733%2C1024&amp;ssl=1 733w, https://i0.wp.com/starkeycomics.com/wp-content/uploads/2023/11/British-accents-5-JPG-1.jpg?resize=215%2C300&amp;ssl=1 215w, https://i0.wp.com/starkeycomics.com/wp-content/uploads/2023/11/British-accents-5-JPG-1.jpg?resize=768%2C1074&amp;ssl=1 768w, https://i0.wp.com/starkeycomics.com/wp-content/uploads/2023/11/British-accents-5-JPG-1.jpg?w=945&amp;ssl=1 945w" sizes="(max-width: 697px) 100vw, 697px"></a></figure>



<h3><strong><em>This map took me a long time to make, and is very detailed, but will always be incomplete and inaccurate due to the nature of language. </em></strong></h3>



<h3>Why this map is so detailed</h3>



<p>The diversity of English dialects in the United Kingdom is enormous.</p>



<p>It’s common for people from either side of a river, mountain, or even town to speak noticeably different ways, with particular features that immediately mark someone out as being from a specific area, to those who have an ear for it.</p>



<p>This is pretty normal in any large region that has been speaking a language continually for 1600 years. You will find the same thing in Germany, Norway, France, and countless other countries. Languages evolve over time, and physical distance between regions means that new features often spread slowly, leading to dialectal differences. Sometimes these differences are small, and only easily recognised by people from the relevant region. Other times there are very clear distinctions, with neighbouring dialects sounding almost like different languages to those unaccustomed to them.</p>



<p>Here I have tried to capture as much nuance as possible. I’ve spent the last few years pooling together every study, survey, map, and database I can find, and then subjecting my image to several rounds of peer feedback. The members of my Facebook group, “Ah yes, the British accent”, were also a huge help in trying to make these borders as accurate as possible.  The end result is an image which is, to my knowledge, the most detailed map of British dialects ever made. But it is still very much unfinished, and it always will be.</p>







<h3>Why this map is wrong, and always will be</h3>



<p>Maps are great. They allow us to display complex geographic data in a way that is visually appealing and easily understood. But often reality is just not that simple. </p>



<p><strong>There’s no precise definition of a “dialect”</strong></p>



<p>The definition is easy enough: a dialect is a form of language that has distinct vocabulary, pronunciation (accent), and/or grammar. But how different does a way of speaking need to be to constitute a different dialect? If any noticeable difference between the way two areas speak is a dialect, then my image is actually using very broad categories and missing much detail. My own tiny hometown (on the border between “North Cumbrian” and “West Northumbrian”) has words and pronunciations that don’t fit it into either grouping, but I think showing my town as a distinct bubble here would be a dangerous precedent. During my research for this image I talked with many people who, like me, perceive their village, town, or even street as being distinct from the surrounding area, and they’re probably right. But that kind of precision would make my image far more complicated, far harder to create, and likely far less accurate in other ways. So I’ve drawn lines around larger areas where more obvious distinctions can be found, without any strong criteria for what constitutes a dialect. I’ve also tried to show the similarities between neighbouring dialects by using a colour scheme that changes gradually across the country.</p>



<p><strong>Borders between dialects are rarely hard lines</strong></p>



<p>More often than not, dialects do not suddenly change as you move from one region to another. They flow and merge over time in complex and messy ways, like coloured inks diffusing into water. Yes, there is definitely a difference between the dialect of Barrow in southern Cumbria and Carlisle in the north, but in reality the region between them is a spectrum, and the placement of any dialect border across Cumbria is pretty arbitrary. Dialects on either side of it will have more in common with each other than they do with the rest of their side of the county.</p>



<p>In an attempt to show this, the first few drafts of this map had no white borders, instead just similar neighbouring colours against each other. However, this turned out to be a nightmare for colour-blind people. I then put in a combination of dotted lines for smaller distinctions, and solid, thick lines to show different dialect groups. But that didn’t feel right either, as while it’s easy to group together the East Midlands as separate from the West Midlands, the “Mid” Midlands doesn’t really have any solid distinction like that: it’s a gradient between the two sides. So I’ve left it all as dotted lines, almost as an apology for the map’s inability to show the true messy gradient that exists. I hope they serve to convey the vagueness and permeability of these “borders”.</p>



<p>In reality these colours should blur and fade together with gradients and checkerboard markings and about 35 extra spatial dimensions, but that would very much defeat the point of trying to make an intelligible map. </p>



<p><strong>Some dialects are not geographically specific at all</strong></p>



<p>While most dialects can be described as regional, spoken mainly in one area, that isn’t always the case. London is the prime example of this: my map cops out with “London Dialects” (plural), because in reality London is incredibly diverse, and deserves its own map to show that complexity. Except no, nobody will ever map that map, because more than anywhere geography is not how London dialects are arranged. Cultural and socioeconomic background is a much bigger deciding factor, and dialects like Multicultural London English aren’t found in one area, but all across London.</p>



<p>Other examples of dialects hat aren’t in this image because they aren’t specifically regional include Received Pronunciation, the “standard” prestige dialect spoken across the southern Britain; and Pitmatic, a dialect spoken by scattered coal-mining towns across the northeast of England. </p>











<p>So yes, this map may be unsatisfying, arbitrary, and unfinished, and no amount of work on it will really change that. It exists mainly as a testament to the huge dialectal diversity of the English language within the UK, and as a way for me to express my fascination and love for that diversity.</p>







<h3>Other important notes</h3>



<p><strong>What I mean by “British”</strong></p>



<p>This is a map specifically of British English dialects. That means dialects of the English language of the UK (England, Scotland, Wales, and Northern Ireland), and the Crown Dependencies (The Isle of Man, The Bailiwick of Jersey, and the Bailiwick of Guernsey), which are not part of the UK but are “British”. It does not include Ireland, because Ireland is not British. I considered making this another of my “British and Irish” maps, but honestly this project was already enormous and impossible enough that adding the Republic of Ireland into the mix felt like a step too far. <br>If you’re unclear on the use of terms like “UK” and “British”, this post is for you:<br><a href="https://starkeycomics.com/2020/05/21/britain-vs-gb-vs-uk-vs-british-isles/"><strong>The difference between Britain, Great Britain, and the United Kingdom.</strong></a></p>



<p><strong>Why Northern Ireland is included</strong></p>



<p>I <em>did</em> include Northern Ireland, which could be a little controversial (as so many things involving NI are). Broadly speaking, there are two main groups of people in Northern Ireland: those who see themselves as Irish, and those who see themselves as British. Because there are people in Northern Ireland who see themselves as British, I think it’s fitting to include them on a map of British dialects. This does not mean everyone in Northern Ireland is British, and if I ever make a map of Irish dialects, I will also be including Northern Ireland in that, as it obviously has a major Irish population. </p>



<p>There is also a strong link between Ulster dialects and the dialects of Scotland, as both have a strong Scots influence, which makes Northern Ireland an important part of the picture here. If you want to read more about how the languages of Britain and Ireland have evolved and influenced each other, see this post:<br><a href="https://starkeycomics.com/2019/03/01/a-brief-history-of-british-and-irish-languages/"><strong>A Brief History of British and Irish Languages</strong></a></p>



<p><strong>Why Scots/Doric are not included:</strong></p>



<p>This map is specifically of the English language, and Scots (and its subset, Doric), are not English. Scots is a close sibling to English, but it is distinct enough to be considered its own language. That said, the English dialects of the Scottish Lowlands are heavily influenced by Scots (with many speakers being bilingual in the two languages), and so the dialects are largely the same as the dialects of Scots. The notable exception being that there is no English dialect called “Doric”. Similarly Welsh, Scottish Gaelic, Cornish, Manx, and Irish do not belong on this map, despite being spoken within its borders. For a full list of languages spoken in the UK and Ireland and how they relate, this is the post for you: <br><a href="https://starkeycomics.com/2019/03/01/every-native-british-and-irish-language/"><strong>Every Native British and Irish Language</strong></a></p>















<p>I’ve got a ton of other maps on my site now, but if you enjoyed this one I recommend <strong><a href="https://starkeycomics.com/2024/05/10/eight-british-and-irish-accent-maps/">Eight British and Irish Accent maps</a></strong>, which includes a bunch of maps (eight, actually) showing the differences in pronunciation of specific sounds and works in Britain and Ireland. </p>



<p>If you appreciate content like this and would like to help fund and motivate my work, I’d massively appreciate a donation to my<a href="https://www.patreon.com/starkeycomics"> <strong>Patreon account</strong></a>. As a small creator with a deep hatred of ads, my Patrons are the only income I receive for my Starkey Comics stuff, and without them I’d find it harder to justify just how much of my time and effort I put into these images.</p>



<p>Oh, and make sure to <strong><a href="https://www.facebook.com/starkeycomics/">give my facebook page a follow</a></strong>. <br>I share everything I make on my facebook page, often before I get round to sharing it here on my site.</p>




				
								
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Undercutf1 – F1 Live Timing TUI with Driver Tracker, Variable Delay (256 pts)]]></title>
            <link>https://github.com/JustAman62/undercut-f1</link>
            <guid>43734910</guid>
            <pubDate>Sat, 19 Apr 2025 07:50:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/JustAman62/undercut-f1">https://github.com/JustAman62/undercut-f1</a>, See on <a href="https://news.ycombinator.com/item?id=43734910">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto"><h2 tabindex="-1" dir="auto">undercut-f1</h2><a id="user-content-undercut-f1" aria-label="Permalink: undercut-f1" href="#undercut-f1"></a></p>
<p dir="auto">undercut-f1 is an open source F1 Live Timing client.</p>
<p dir="auto"><code>undercutf1</code> is a TUI application which uses <code>UndercutF1.Data</code> to show a Live Timing screen during sessions, and records the data for future session replays.
F1 live broadcasts are usually delayed by some undeterminable amount (usually 30-60 seconds), so the TUI allows you to delay the data being displayed so that you can match up what you see on your screen to what you see on your TV.</p>
<p dir="auto">The <code>UndercutF1.Data</code> library is provided to facilitate connectivity with the F1 Live Timing data stream, and handle all the processing of the incoming data. It also allows for "simulated" streams, where previously recorded data streams can be played back to allow for easy development/testing.</p>
<p dir="auto">Feature Highlights:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/JustAman62/undercut-f1/blob/master/docs/screenshots/race-timing-screen.png"><img src="https://github.com/JustAman62/undercut-f1/raw/master/docs/screenshots/race-timing-screen.png" alt="Timing Tower during a Race"></a></p>
<ul dir="auto">
<li><a href="#timing-tower-during-a-race">Timing Tower</a> showing for each driver:
<ul dir="auto">
<li>Live sector times, with colouring for personal/overall fastest</li>
<li>Last &amp; Best Lap</li>
<li>Current tyre</li>
<li>Age of current tyre</li>
<li>Interval to driver in front</li>
<li>Gap to leader</li>
<li>Gap <a href="#using-a-cursor-to-display-relative-gap-for-a-specific-driver">between a selected driver</a> and all other drivers (useful for monitoring pit windows)</li>
</ul>
</li>
<li><a href="#tyre-stint--strategy">Pit Stop Strategy</a> gives you at-a-glance information about all the drivers strategies</li>
<li><a href="#race-control-page">Race Control</a> messages including investigations, penalties, lap deletions, and weather</li>
<li><a href="#driver-tracker">Driver Tracker</a> shows the position of selected drivers on a live track map</li>
<li>Lap-by-lap <a href="#using-a-cursor-to-view-timing-history-by-lap">Timing History</a> to observe gaps over time</li>
</ul>

<p dir="auto"><h2 tabindex="-1" dir="auto">Table of Contents</h2><a id="user-content-table-of-contents" aria-label="Permalink: Table of Contents" href="#table-of-contents"></a></p>
<ul dir="auto">
<li><a href="#inspiration">Inspiration</a></li>
<li><a href="#undercutf1-in-action">UndercutF1 in Action</a>
<ul dir="auto">
<li><a href="#timing-tower-during-a-race">Timing Tower during a Race</a></li>
<li><a href="#using-a-cursor-to-display-relative-gap-for-a-specific-driver">Using a Cursor to Display Relative Gap for a Specific Driver</a></li>
<li><a href="#timing-tower-during-practicequalifying">Timing Tower during Practice/Qualifying</a></li>
<li><a href="#race-control-page">Race Control Page</a></li>
<li><a href="#driver-tracker">Driver Tracker</a></li>
<li><a href="#tyre-stint--strategy">Tyre Stint / Strategy</a></li>
<li><a href="#using-a-cursor-to-view-timing-history-by-lap">Using a Cursor to View Timing History by Lap</a></li>
<li><a href="#listen-to-and-transcribe-team-radio">Listen to and Transcribe Team Radio</a></li>
</ul>
</li>
<li><a href="#getting-started-with-undercutf1">Getting Started with <code>undercutf1</code></a>
<ul dir="auto">
<li><a href="#installation">Installation</a>
<ul dir="auto">
<li><a href="#install-and-run-as-a-dotnet-tool">Install and run as a dotnet tool</a></li>
<li><a href="#install-and-run-the-standalone-executable">Install and run the standalone executable</a></li>
<li><a href="#run-directly-from-source">Run directly from Source</a></li>
</ul>
</li>
<li><a href="#start-timing-for-a-live-session">Start Timing for a Live Session</a></li>
<li><a href="#start-timing-for-a-pre-recorded-session">Start Timing for a Pre-recorded Session</a></li>
<li><a href="#download-a-previous-session-data-for-replay">Download a previous session data for replay</a></li>
<li><a href="#during-the-session">During the Session</a>
<ul dir="auto">
<li><a href="#managing-delay">Managing Delay</a></li>
<li><a href="#using-the-cursor">Using the Cursor</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#configuration">Configuration</a></li>
<li><a href="#logging">Logging</a></li>
<li><a href="#live-timing-data-source">Live Timing Data Source</a></li>
<li><a href="#data-recording-and-replay">Data Recording and Replay</a></li>
<li><a href="#notice">Notice</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Inspiration</h2><a id="user-content-inspiration" aria-label="Permalink: Inspiration" href="#inspiration"></a></p>
<p dir="auto">This project is heavily inspired by the <a href="https://github.com/theOehrly/Fast-F1">FastF1 project by theOehrly</a>. They did a lot of the work understanding the SignalR stream coming from the F1 Live Timing service. Visit their project if you'd like to do any sort of data analysis on past F1 events, or gather live timing data using their module.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">UndercutF1 in Action</h2><a id="user-content-undercutf1-in-action" aria-label="Permalink: UndercutF1 in Action" href="#undercutf1-in-action"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Timing Tower during a Race</h3><a id="user-content-timing-tower-during-a-race" aria-label="Permalink: Timing Tower during a Race" href="#timing-tower-during-a-race"></a></p>
<p dir="auto">Monitor sector times and gaps, see recent race control messages, capture position changes, observe pit strategies, and more with the standard Timing Tower view.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/JustAman62/undercut-f1/blob/master/docs/screenshots/race-timing-screen.png"><img src="https://github.com/JustAman62/undercut-f1/raw/master/docs/screenshots/race-timing-screen.png" alt="Timing Tower during a Race"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Using a Cursor to Display Relative Gap for a Specific Driver</h3><a id="user-content-using-a-cursor-to-display-relative-gap-for-a-specific-driver" aria-label="Permalink: Using a Cursor to Display Relative Gap for a Specific Driver" href="#using-a-cursor-to-display-relative-gap-for-a-specific-driver"></a></p>
<p dir="auto">Use the cursor controlled by the <kbd>▼</kbd>/<kbd>▲</kbd> <code>Cursor</code> actions in the <kbd>O</kbd> <code>Timing Tower</code> screen to select a specific driver (in this case Norris) to see the relative interval between that driver and all other. This is useful for determining where a driver will fall to after a pit stop, or looking at pit windows during under cuts.</p>
<p dir="auto">Additionally, the gap between the selected drivers and those around them over the last four laps will be displayed at the bottom of the screen. This allows you to easily see evolving gaps over time and evaluate how soon a driver may catch up or pull away.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/JustAman62/undercut-f1/blob/master/docs/screenshots/relative-gap-race.png"><img src="https://github.com/JustAman62/undercut-f1/raw/master/docs/screenshots/relative-gap-race.png" alt="Relative gaps for a specific driver"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Timing Tower during Practice/Qualifying</h3><a id="user-content-timing-tower-during-practicequalifying" aria-label="Permalink: Timing Tower during Practice/Qualifying" href="#timing-tower-during-practicequalifying"></a></p>
<p dir="auto">Monitor live/best sector times, gaps, tyres, and lap deletions easily with the specialized timing tower for non-race sessions.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/JustAman62/undercut-f1/blob/master/docs/screenshots/quali-timing-screen.png"><img src="https://github.com/JustAman62/undercut-f1/raw/master/docs/screenshots/quali-timing-screen.png" alt="Timing Tower during Practice/Qualifying"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Race Control Page</h3><a id="user-content-race-control-page" aria-label="Permalink: Race Control Page" href="#race-control-page"></a></p>
<p dir="auto">The <code>Race Control</code> page shows all Race Control Messages for the session, along with other session data such as the Weather.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/JustAman62/undercut-f1/blob/master/docs/screenshots/race-control-screen.png"><img src="https://github.com/JustAman62/undercut-f1/raw/master/docs/screenshots/race-control-screen.png" alt="Race Control Page"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Driver Tracker</h3><a id="user-content-driver-tracker" aria-label="Permalink: Driver Tracker" href="#driver-tracker"></a></p>
<p dir="auto">The <code>Driver Tracker</code> page shows a track map overlayed with selected drivers. Use the <kbd>▼</kbd>/<kbd>▲</kbd> <code>Cursor</code> actions to choose drivers, then use the <kbd>⏎</kbd> <code>Toggle Select</code> action to toggle the inclusion of the driver on the track map. The driver under the current cursor position will also be highlighted on the map, and timing gaps will switch to interval between that driver and all other drivers.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/JustAman62/undercut-f1/blob/master/docs/screenshots/driver-tracker.png"><img src="https://github.com/JustAman62/undercut-f1/raw/master/docs/screenshots/driver-tracker.png" alt="Driver Tracker Page"></a></p>
<p dir="auto">NOTE: Currently the track map is only supported in the iTerm2 terminal (by implementing the <a href="https://iterm2.com/documentation-images.html" rel="nofollow">iTerm2's Inline Image Protocol</a>), and terminals which implement the <a href="https://sw.kovidgoyal.net/kitty/graphics-protocol/" rel="nofollow">Kitty Graphics Protocol</a>. Other protocols (such as Sixel) may be supported in the future. If the track map doesn't work in your terminal, please raise an issue and I will try and fix/implement support.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Tyre Stint / Strategy</h3><a id="user-content-tyre-stint--strategy" aria-label="Permalink: Tyre Stint / Strategy" href="#tyre-stint--strategy"></a></p>
<p dir="auto">The <code>Tyre Stint</code> page shows the tyre strategy for all the drivers. At a glance, see what tyres the drivers have used, how old they are, and if they are on an offset strategy to any other drivers.</p>
<p dir="auto">Use the <kbd>▼</kbd>/<kbd>▲</kbd> <code>Cursor</code> actions to view more information for a particular drivers strategy.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/JustAman62/undercut-f1/blob/master/docs/screenshots/tyre-stint-screen.png"><img src="https://github.com/JustAman62/undercut-f1/raw/master/docs/screenshots/tyre-stint-screen.png" alt="Tyre Stint"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Using a Cursor to View Timing History by Lap</h3><a id="user-content-using-a-cursor-to-view-timing-history-by-lap" aria-label="Permalink: Using a Cursor to View Timing History by Lap" href="#using-a-cursor-to-view-timing-history-by-lap"></a></p>
<p dir="auto">In the <code>Timing by Lap</code> page, you can use the cursor controlled by the <kbd>▼</kbd>/<kbd>▲</kbd> <code>Cursor</code> actions to view historical snapshots of the timing tower at the end of every lap. This view will show position changes during that lap, and relative changes in Gap and Interval. Scrolling through laps allows you to build a picture of how the race is unfolding.</p>
<p dir="auto">Charts on the right display how Gap to Leader and Lap Time for all selected drivers over the last 15 laps, letting you see trends and catch strategies unfolding.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/JustAman62/undercut-f1/blob/master/docs/screenshots/timing-history-screen.png"><img src="https://github.com/JustAman62/undercut-f1/raw/master/docs/screenshots/timing-history-screen.png" alt="Using a Cursor to View Timing History by Lap"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Listen to and Transcribe Team Radio</h3><a id="user-content-listen-to-and-transcribe-team-radio" aria-label="Permalink: Listen to and Transcribe Team Radio" href="#listen-to-and-transcribe-team-radio"></a></p>
<p dir="auto">Listen to team radio clips from anytime in the session, and use a local ML model (Whisper) to transcribe the audio on demand. Transcription accuracy is fairly low, depending on the that days audio quality and driver. Suggestions welcome for improving this!</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/JustAman62/undercut-f1/blob/master/docs/screenshots/team-radio.png"><img src="https://github.com/JustAman62/undercut-f1/raw/master/docs/screenshots/team-radio.png" alt="Listen to and Transcribe Team Radio"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Getting Started with <code>undercutf1</code></h2><a id="user-content-getting-started-with-undercutf1" aria-label="Permalink: Getting Started with undercutf1" href="#getting-started-with-undercutf1"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Installation</h3><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Install and run as a dotnet tool</h4><a id="user-content-install-and-run-as-a-dotnet-tool" aria-label="Permalink: Install and run as a dotnet tool" href="#install-and-run-as-a-dotnet-tool"></a></p>
<p dir="auto"><code>undercutf1</code> is available as a <code>dotnet</code> tool from NuGet, which means it can be installed system-wide simply by running:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Install globally using the -g flag
dotnet tool install -g undercutf1

# Assuming the dotnet tools directory is on your path, simply execute undercutf1
undercutf1"><pre><span><span>#</span> Install globally using the -g flag</span>
dotnet tool install -g undercutf1

<span><span>#</span> Assuming the dotnet tools directory is on your path, simply execute undercutf1</span>
undercutf1</pre></div>
<p dir="auto">This method is recommended as it is easy to keep the app updated using <code>dotnet tool update -g undercutf1</code>. You'll need the .NET 9 SDK installed to use this installation method. If you'd rather not install the SDK, try the <a href="#install-and-run-the-standalone-executable">standalone installation option below</a>.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Install and run the standalone executable</h4><a id="user-content-install-and-run-the-standalone-executable" aria-label="Permalink: Install and run the standalone executable" href="#install-and-run-the-standalone-executable"></a></p>
<p dir="auto">Standalone executables are attached to each GitHub release. Download the executable for your system OS/architecture and simply run it directly. The list of artifacts are available on the <a href="https://github.com/JustAman62/undercut-f1/releases/latest">release page for the latest release</a>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Download the latest executable (in this case for osx-arm64)
curl https://github.com/JustAman62/undercut-f1/releases/latest/download/undercutf1-osx-arm64 -o ./undercutf1 -L

# Execute undercutf1 to start the TUI
./undercutf1"><pre><span><span>#</span> Download the latest executable (in this case for osx-arm64)</span>
curl https://github.com/JustAman62/undercut-f1/releases/latest/download/undercutf1-osx-arm64 -o ./undercutf1 -L

<span><span>#</span> Execute undercutf1 to start the TUI</span>
./undercutf1</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Run directly from Source</h4><a id="user-content-run-directly-from-source" aria-label="Permalink: Run directly from Source" href="#run-directly-from-source"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Checkout the git repository
git clone git@github.com:JustAman62/undercut-f1.git
cd undercut-f1

# Run the console project with `dotnet run`
dotnet run --project UndercutF1.Console/UndercutF1.Console.csproj"><pre><span><span>#</span> Checkout the git repository</span>
git clone git@github.com:JustAman62/undercut-f1.git
<span>cd</span> undercut-f1

<span><span>#</span> Run the console project with `dotnet run`</span>
dotnet run --project UndercutF1.Console/UndercutF1.Console.csproj</pre></div>
<p dir="auto">By default, data will be saved and read from the <code>~/undercut-f1</code> directory. See <a href="#configuration">Configuration</a> for information on how to configure this.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Start Timing for a Live Session</h3><a id="user-content-start-timing-for-a-live-session" aria-label="Permalink: Start Timing for a Live Session" href="#start-timing-for-a-live-session"></a></p>
<ol dir="auto">
<li>Start <code>undercutf1</code> as described above</li>
<li>Navigate to the <kbd>S</kbd> <code>Session</code> Screen</li>
<li>Start a Live Session with the <kbd>L</kbd> <code>Start Live Session</code> action.</li>
<li>Switch to the Timing Tower screen with the <kbd>T</kbd> <code>Timing Tower</code> action</li>
</ol>
<p dir="auto">During the session, streamed timing data will be written to <code>~/undercut-f1/data/&lt;session-name&gt;</code>. This will allow for <a href="#start-timing-for-a-pre-recorded-session">future replays</a> of this recorded data.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Start Timing for a Pre-recorded Session</h3><a id="user-content-start-timing-for-a-pre-recorded-session" aria-label="Permalink: Start Timing for a Pre-recorded Session" href="#start-timing-for-a-pre-recorded-session"></a></p>
<p dir="auto">Data for pre-recorded sessions should be stored in the <code>~/undercut-f1/data/&lt;session-name&gt;</code> directory. Sample data can be found in this repos <a href="https://github.com/JustAman62/undercut-f1/blob/master/Sample%20Data">Sample Data</a> folder. To use this sample data, copy one of the folders to <code>~/undercut-f1/data</code> and then it will be visible in step 4 below.</p>
<ol dir="auto">
<li>
<p dir="auto">OPTIONAL: Download sample data to ~/undercut-f1/data. If you already have data, or have checked out the repository, skip to the next step.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Create the directory for the data if it doesn't exist
mkdir -p ~/undercut-f1/2024_Silverstone_Race

# Download the live and subscribe data files
curl https://raw.githubusercontent.com/JustAman62/undercut-f1/refs/heads/master/Sample%20Data/2024_Silverstone_Race/live.txt -o ~/undercut-f1/2024_Silverstone_Race/live.txt

curl https://raw.githubusercontent.com/JustAman62/undercut-f1/refs/heads/master/Sample%20Data/2024_Silverstone_Race/subscribe.txt -o ~/undercut-f1/2024_Silverstone_Race/subscribe.txt"><pre><span><span>#</span> Create the directory for the data if it doesn't exist</span>
mkdir -p <span>~</span>/undercut-f1/2024_Silverstone_Race

<span><span>#</span> Download the live and subscribe data files</span>
curl https://raw.githubusercontent.com/JustAman62/undercut-f1/refs/heads/master/Sample%20Data/2024_Silverstone_Race/live.txt -o <span>~</span>/undercut-f1/2024_Silverstone_Race/live.txt

curl https://raw.githubusercontent.com/JustAman62/undercut-f1/refs/heads/master/Sample%20Data/2024_Silverstone_Race/subscribe.txt -o <span>~</span>/undercut-f1/2024_Silverstone_Race/subscribe.txt</pre></div>
</li>
<li>
<p dir="auto">Start <code>undercutf1</code> as described <a href="#installation">above</a></p>
</li>
<li>
<p dir="auto">Navigate to the <kbd>S</kbd> <code>Session</code> Screen</p>
</li>
<li>
<p dir="auto">Start a Simulated Session with the <kbd>F</kbd> <code>Start Simulation</code> action.</p>
</li>
<li>
<p dir="auto">Select the session to start using the Up/Down arrows, then pressing <kbd>Enter</kbd></p>
</li>
<li>
<p dir="auto">Switch to the Timing Tower screen with the <kbd>T</kbd> <code>Timing Tower</code> action</p>
</li>
<li>
<p dir="auto">Optionally skip forward in time a bit by decreasing the delay with <kbd>N</kbd> (or <kbd>⇧ Shift</kbd> + <kbd>N</kbd> to decrease by 30 seconds).</p>
</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">Download a previous session data for replay</h3><a id="user-content-download-a-previous-session-data-for-replay" aria-label="Permalink: Download a previous session data for replay" href="#download-a-previous-session-data-for-replay"></a></p>
<p dir="auto">F1 provides static timing data files for already completed sessions. This data can be downloaded and converted into the same format <code>undercutf1</code> uses to save live recorded data. You can then replay the old session using the steps above.</p>
<ol dir="auto">
<li>List the meetings that have data available to import with <code>undercutf1 import &lt;year&gt;</code></li>
<li>Review the list of meetings returned from the command, and list the available sessions inside the chosen meeting with <code>undercutf1 import &lt;year&gt; --meeting-key &lt;meeting-key&gt;</code></li>
<li>Review the list of sessions, and select one to import: <code>undercutf1 import &lt;year&gt; --meeting-key &lt;meeting-key&gt; --session-key &lt;session-key&gt;</code></li>
<li>Data that is imported will be saved to the configured <code>DATA_DIRECTORY</code>. See <a href="#configuration">Configuration</a> for information on how to change this.</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">During the Session</h3><a id="user-content-during-the-session" aria-label="Permalink: During the Session" href="#during-the-session"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Managing Delay</h4><a id="user-content-managing-delay" aria-label="Permalink: Managing Delay" href="#managing-delay"></a></p>
<p dir="auto">All session data, whether live or pre-recorded, is sent to a <code>Channel</code> that acts as a delayed-queue. After a short delay, data points are pulled from the queue and processed, leading to updates on the timing screens. The amount of this delay can be changed with the <kbd>M</kbd>/<kbd>N</kbd> <code>Delay</code> actions whilst on the timing screens. Hold <kbd>⇧ Shift</kbd> to change the delay by 30 seconds instead of 5. When using <code>undercutf1</code> during a live session, you may wish to increase this delay to around ~50 seconds (actual number may vary) to match with the broadcast delay and avoid being spoiled about upcoming action.</p>
<p dir="auto">Simulated sessions start with a calculated delay equal to the amount of time between the start of the actual session and now. This means you can decrease the delay with the <kbd>N</kbd> <code>Delay</code> action to fast-forward through the session.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Using the Cursor</h4><a id="user-content-using-the-cursor" aria-label="Permalink: Using the Cursor" href="#using-the-cursor"></a></p>
<p dir="auto">There is a global cursor that is controlled with the <kbd>▼</kbd>/<kbd>▲</kbd> <code>Cursor</code> actions. What this cursor does depends on the screen, for example is can be used in the Timing Tower screen to scroll through Race Control Messages, or to select a driver on the Tower to see comparative intervals.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Configuration</h2><a id="user-content-configuration" aria-label="Permalink: Configuration" href="#configuration"></a></p>
<p dir="auto">UndercutF1 can be configured using either a simple <code>config.json</code> file, through the command line at startup, or using environment variables. JSON configuration will be loaded from <code>~/undercut-f1/config.json</code>, if it exists.</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>JSON Path</th>
<th>Command Line</th>
<th>Environment Variable</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>dataDirectory</code></td>
<td><code>--data-directory</code></td>
<td><code>UNDERCUTF1_DATADIRECTORY</code></td>
<td>The directory in which JSON timing data is read or written from.</td>
</tr>
<tr>
<td><code>verbose</code></td>
<td><code>-v|--verbose</code></td>
<td><code>UNDERCUTF1_VERBOSE</code></td>
<td>Whether verbose logging should be enabled. Default: <code>false</code>. Values: <code>true</code> or <code>false</code>.</td>
</tr>
<tr>
<td><code>apiEnabled</code></td>
<td><code>--with-api</code></td>
<td><code>UNDERCUTF1_APIENABLED</code></td>
<td>Whether the app should expose an API at <a href="http://localhost:61937/" rel="nofollow">http://localhost:61937</a>. Default: <code>false</code>. Values: <code>true</code> or <code>false</code>.</td>
</tr>
<tr>
<td><code>notify</code></td>
<td><code>--notify</code></td>
<td><code>UNDERCUTF1_NOTIFY</code></td>
<td>Whether the app should sent audible BELs to your terminal when new race control messages are received. Default: <code>true</code>. Values: <code>true</code> or <code>false</code>.</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Logging</h2><a id="user-content-logging" aria-label="Permalink: Logging" href="#logging"></a></p>
<p dir="auto"><code>UndercutF1.Data</code> writes logs using the standard <code>ILogger</code> implementation. SignalR client logs are also passed to the standard <code>ILoggerProvider</code>.</p>
<p dir="auto">When running <code>undercutf1</code> logs are available in two places:</p>
<ul dir="auto">
<li>Logs are stored in memory and viewable the <kbd>L</kbd> <code>Logs</code> screen. Logs can be scrolled on this screen, and the minimum level of logs shown can be changed with the <kbd>M</kbd> <code>Minimum Log Level</code> action.</li>
<li>Log files are written to <code>~/undercut-f1/logs</code>.</li>
</ul>
<p dir="auto">Default log level is set to <code>Information</code>. More verbose logging can be enabled with the <a href="#configuration"><code>verbose</code> config option</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Live Timing Data Source</h2><a id="user-content-live-timing-data-source" aria-label="Permalink: Live Timing Data Source" href="#live-timing-data-source"></a></p>
<p dir="auto">F1 live timing is streamed using <code>SignalR</code>. The <code>UndercutF1.Data</code> simply connects to this endpoint, subscribes to the data feed, and listens for messages. It subscribes to the following "topics":</p>
<ul dir="auto">
<li><code>Heartbeat</code></li>
<li><code>ExtrapolatedClock</code></li>
<li><code>TopThree</code></li>
<li><code>TimingStats</code></li>
<li><code>TimingAppData</code></li>
<li><code>WeatherData</code></li>
<li><code>TrackStatus</code></li>
<li><code>DriverList</code></li>
<li><code>RaceControlMessages</code></li>
<li><code>SessionInfo</code></li>
<li><code>SessionData</code></li>
<li><code>LapCount</code></li>
<li><code>TimingData</code></li>
<li><code>CarData.z</code></li>
<li><code>Position.z</code></li>
<li><code>ChampionshipPrediction</code></li>
<li><code>TeamRadio</code></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Data Recording and Replay</h2><a id="user-content-data-recording-and-replay" aria-label="Permalink: Data Recording and Replay" href="#data-recording-and-replay"></a></p>
<p dir="auto">All events received by the live timing client will be written to the configured <code>Data Directory</code>, see <a href="#configuration">see Configuration for details</a>. Files will be written to a subdirectory named using the current sessions name, e.g. <code>~/undercut-f1/data/Jeddah_Race/</code>. In this directory, two files will be written:</p>
<ul dir="auto">
<li><code>subscribe.txt</code> contains the data received at subscription time (i.e. when the live timing client connected to the stream)</li>
<li><code>live.txt</code> contains an append-log of every message received in the stream</li>
</ul>
<p dir="auto">Both of these files are required for future simulations/replays. The <code>IJsonTimingClient</code> supports loading these files and processing them in the same way live data would be. Data points will be replayed in real time, using an adjustable delay.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Notice</h2><a id="user-content-notice" aria-label="Permalink: Notice" href="#notice"></a></p>
<p dir="auto">undercut-f1 is unofficial and are not associated in any way with the Formula 1 companies. F1, FORMULA ONE, FORMULA 1, FIA FORMULA ONE WORLD CHAMPIONSHIP, GRAND PRIX and related marks are trade marks of Formula One Licensing B.V.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: New world record – verified Goldbach Conjecture up to 4*10^18+7*10^13 (225 pts)]]></title>
            <link>https://medium.com/@jay_gridbach/grid-computing-shatters-world-record-for-goldbach-conjecture-verification-1ef3dc58a38d</link>
            <guid>43734583</guid>
            <pubDate>Sat, 19 Apr 2025 06:11:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://medium.com/@jay_gridbach/grid-computing-shatters-world-record-for-goldbach-conjecture-verification-1ef3dc58a38d">https://medium.com/@jay_gridbach/grid-computing-shatters-world-record-for-goldbach-conjecture-verification-1ef3dc58a38d</a>, See on <a href="https://news.ycombinator.com/item?id=43734583">Hacker News</a></p>
Couldn't get https://medium.com/@jay_gridbach/grid-computing-shatters-world-record-for-goldbach-conjecture-verification-1ef3dc58a38d: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[JavaScript Views, the Hard Way – A Pattern for Writing UI (174 pts)]]></title>
            <link>https://github.com/matthewp/views-the-hard-way</link>
            <guid>43733636</guid>
            <pubDate>Sat, 19 Apr 2025 02:10:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/matthewp/views-the-hard-way">https://github.com/matthewp/views-the-hard-way</a>, See on <a href="https://news.ycombinator.com/item?id=43733636">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Writing JavaScript Views the Hard Way</h2><a id="user-content-writing-javascript-views-the-hard-way" aria-label="Permalink: Writing JavaScript Views the Hard Way" href="#writing-javascript-views-the-hard-way"></a></p>
<p dir="auto">Learn how to build views in plain JavaScript in a way that is maintainable, performant, and fun. <em>Writing JavaScript Views the Hard Way</em> is inspired by such books as <a href="https://learncodethehardway.org/c/" rel="nofollow">Learn C the Hard Way</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">What is this?</h2><a id="user-content-what-is-this" aria-label="Permalink: What is this?" href="#what-is-this"></a></p>
<p dir="auto">Writing JavaScript Views the Hard Way is a pattern for writing JavaScript views. It is meant to serve as an alternative to using frameworks and libraries such as <a href="https://reactjs.org/" rel="nofollow">React</a>, <a href="https://vuejs.org/" rel="nofollow">Vue</a> and <a href="https://lit-html.polymer-project.org/" rel="nofollow">lit-html</a>.</p>
<p dir="auto">It is a <strong>pattern</strong>, not a library. This document explains how to write views in such a way as to avoid the <a href="https://en.wikipedia.org/wiki/Spaghetti_code" rel="nofollow">spaghetti code</a> problems that commonly occur when writing low-level imperative code.</p>
<p dir="auto">We call this technique <em>the hard way</em> because it askews abstractions in favor of directness.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Advantages over frameworks</h3><a id="user-content-advantages-over-frameworks" aria-label="Permalink: Advantages over frameworks" href="#advantages-over-frameworks"></a></p>
<p dir="auto">There are several reasons why you might be interested in writing your views the hard way:</p>
<ul dir="auto">
<li><strong>Performance</strong>: <em>Writing JavaScript Views the Hard Way</em> uses direct imperative code, so there are no unnecessary operations performed. Whether a hot or cold path, using this technique ensures nearly the best possible performance you can get in JavaScript.</li>
<li><strong>0 dependencies</strong>: This technique uses no dependencies, so your code will <em>never</em> have to be upgraded. Have you ever used a library that released a breaking change that took you a day to upgrade? You'll never experience that problem again.</li>
<li><strong>Portability</strong>: Code written with simple imperative views is portable to any framework. That makes it perfect for low-level components that you might want to share with several framework communities. But I recommend using it on full apps as well.</li>
<li><strong>Maintainability</strong>: Despite the reputation of imperative code being difficult to maintain, views written with Writing JavaScript Views the Hard Way are <em>extremely</em> maintainable. This is because they follow strict conventions (you'll learn these later). These conventions ensure you always know where to look in a view. Additionally it follows a <em>props down, events up</em> model that makes data sharing straight-forward.</li>
<li><strong>Browser support</strong>: Code written in this manner is supported by all browsers; full-stop. We do use events to make passing data back up the component tree and our examples use a newer, nicer API, to do that, but you can use an older technique (discussed in the compatibility section) to get you back to at least IE9. But if you want to go further back than that even, substitute passing functions as props instead of using events and you can use this technique in IE6 if you want. And it will be by far the most performant solution you'll find for old browsers.</li>
<li><strong>Easier to debug</strong>: Using this approach stack traces become shallow (usually only a few function calls). This is because there are no layers between events and your code. Everything is your code, and as long as you name your functions, you'll get incredible stack traces that make it easy to trace where something goes wrong.</li>
<li><strong>Functional</strong>: This doesn't differentiate the technique vs <em>all</em> frameworks but it's worth pointing out at a benefit. <em>Writing JavaScript Views the Hard Way</em> is not functional in the immutable sense; there are definitely mutations; but it is functional in the sense that you're dealing with plain functions (no classes in sight) and without side-effects outside of the view's local state.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">The structure</h2><a id="user-content-the-structure" aria-label="Permalink: The structure" href="#the-structure"></a></p>
<p dir="auto">Enough with the arguments for now, let's talk about the structure. A view component written with <em>Writing JavaScript Views the Hard Way</em> looks like the following. This is a full <strong>hello world</strong>. From here we'll break down each part and explain it on its own.</p>
<p dir="auto">Once you understand each part you'll know how to build components/views using this pattern; it's everything you need to know.</p>
<div dir="auto" data-snippet-clipboard-copy-content="const template = document.createElement('template');
template.innerHTML = `
  <div>Hello <span id=&quot;name&quot;>world</span>!</div>
`;

function clone() {
  return document.importNode(template.content, true);
}

function init() {
  /* DOM variables */
  let frag = clone();
  let nameNode = frag.querySelector('#name');

  /* State variables */
  let name;

  /* DOM update functions */
  function setNameNode(value) {
    nameNode.textContent = value;
  }

  /* State update functions */
  function setName(value) {
    if(name !== value) {
      name = value;
      setNameNode(value);
    }
  }

  /* State logic */

  /* Event dispatchers */

  /* Event listeners */

  /* Initialization */

  function update(data = {}) {
    if(data.name) setName(data.name);
    return frag;
  }

  return update;
}

export default init;"><pre><span>const</span> <span>template</span> <span>=</span> <span>document</span><span>.</span><span>createElement</span><span>(</span><span>'template'</span><span>)</span><span>;</span>
<span>template</span><span>.</span><span>innerHTML</span> <span>=</span> <span>`</span>
<span>  &lt;div&gt;Hello &lt;span id="name"&gt;world&lt;/span&gt;!&lt;/div&gt;</span>
<span>`</span><span>;</span>

<span>function</span> <span>clone</span><span>(</span><span>)</span> <span>{</span>
  <span>return</span> <span>document</span><span>.</span><span>importNode</span><span>(</span><span>template</span><span>.</span><span>content</span><span>,</span> <span>true</span><span>)</span><span>;</span>
<span>}</span>

<span>function</span> <span>init</span><span>(</span><span>)</span> <span>{</span>
  <span>/* DOM variables */</span>
  <span>let</span> <span>frag</span> <span>=</span> <span>clone</span><span>(</span><span>)</span><span>;</span>
  <span>let</span> <span>nameNode</span> <span>=</span> <span>frag</span><span>.</span><span>querySelector</span><span>(</span><span>'#name'</span><span>)</span><span>;</span>

  <span>/* State variables */</span>
  <span>let</span> <span>name</span><span>;</span>

  <span>/* DOM update functions */</span>
  <span>function</span> <span>setNameNode</span><span>(</span><span>value</span><span>)</span> <span>{</span>
    <span>nameNode</span><span>.</span><span>textContent</span> <span>=</span> <span>value</span><span>;</span>
  <span>}</span>

  <span>/* State update functions */</span>
  <span>function</span> <span>setName</span><span>(</span><span>value</span><span>)</span> <span>{</span>
    <span>if</span><span>(</span><span>name</span> <span>!==</span> <span>value</span><span>)</span> <span>{</span>
      <span>name</span> <span>=</span> <span>value</span><span>;</span>
      <span>setNameNode</span><span>(</span><span>value</span><span>)</span><span>;</span>
    <span>}</span>
  <span>}</span>

  <span>/* State logic */</span>

  <span>/* Event dispatchers */</span>

  <span>/* Event listeners */</span>

  <span>/* Initialization */</span>

  <span>function</span> <span>update</span><span>(</span><span>data</span> <span>=</span> <span>{</span><span>}</span><span>)</span> <span>{</span>
    <span>if</span><span>(</span><span>data</span><span>.</span><span>name</span><span>)</span> <span>setName</span><span>(</span><span>data</span><span>.</span><span>name</span><span>)</span><span>;</span>
    <span>return</span> <span>frag</span><span>;</span>
  <span>}</span>

  <span>return</span> <span>update</span><span>;</span>
<span>}</span>

<span>export</span> <span>default</span> <span>init</span><span>;</span></pre></div>
<p dir="auto">This is the basic structure. More details are to follow. First let's concentrate on the module's parts and exports.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">template</h3><a id="user-content-template" aria-label="Permalink: template" href="#template"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="const template = document.createElement('template');
template.innerHTML = `
  <div>Hello <span id=&quot;name&quot;>world</span>!</div>
`;"><pre><span>const</span> <span>template</span> <span>=</span> <span>document</span><span>.</span><span>createElement</span><span>(</span><span>'template'</span><span>)</span><span>;</span>
<span>template</span><span>.</span><span>innerHTML</span> <span>=</span> <span>`</span>
<span>  &lt;div&gt;Hello &lt;span id="name"&gt;world&lt;/span&gt;!&lt;/div&gt;</span>
<span>`</span><span>;</span></pre></div>
<p dir="auto">This is the view's template. It's a <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/template" rel="nofollow">&lt;template&gt;</a> element. Setting its <code>innerHTML</code> causes the browser to parse and save this HTML as the template's <code>template.content</code> property. This is a <a href="https://developer.mozilla.org/en-US/docs/Web/API/DocumentFragment" rel="nofollow">DocumentFragment</a> that can be quickly cloned.</p>
<p dir="auto">Notice that there are no interpolations with data. This is because, as of now, the browser doesn't support any such API. In the spirit of <em>The Hard Way</em> we use only what the browser gives us.</p>
<p dir="auto">So instead of interpolating, we add elements at points within the HTML that we will want to update later. In this example we have <code>&lt;span id="name"&gt;world&lt;/span&gt;</code>. This gives us something that we can query and update later (via <code>frag.querySelector('#name')</code> for example).</p>
<blockquote>
<p dir="auto"><em>Note</em>: ids are global to the document. If the component you are working on is likely to be used multiple times in an application (such as a list item) you should probably not use ids, but rather a class name or possibly a <a href="https://developer.mozilla.org/en-US/docs/Learn/HTML/Howto/Use_data_attributes" rel="nofollow">data attribute</a>.</p>
</blockquote>
<p dir="auto"><h3 tabindex="-1" dir="auto">clone()</h3><a id="user-content-clone" aria-label="Permalink: clone()" href="#clone"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="function clone() {
  return document.importNode(template.content, true);
}"><pre><span>function</span> <span>clone</span><span>(</span><span>)</span> <span>{</span>
  <span>return</span> <span>document</span><span>.</span><span>importNode</span><span>(</span><span>template</span><span>.</span><span>content</span><span>,</span> <span>true</span><span>)</span><span>;</span>
<span>}</span></pre></div>
<p dir="auto">This function is mostly for convenience. All it does is clone the template and return the result.</p>
<p dir="auto">However there are cases where you might want to slightly adjust the output. <a href="https://developer.mozilla.org/en-US/docs/Web/API/Document/importNode" rel="nofollow">document.importNode</a> returns a fragment; there are cases where you want the returned node to be an <strong>element</strong> (mostly so that the consumer of your view can set up event listeners). So to return the root element you can change <strong>clone</strong> to:</p>
<div dir="auto" data-snippet-clipboard-copy-content="function clone() {
  return document.importNode(template.content, true).firstElementChild;
}"><pre><span>function</span> <span>clone</span><span>(</span><span>)</span> <span>{</span>
  <span>return</span> <span>document</span><span>.</span><span>importNode</span><span>(</span><span>template</span><span>.</span><span>content</span><span>,</span> <span>true</span><span>)</span><span>.</span><span>firstElementChild</span><span>;</span>
<span>}</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">init()</h3><a id="user-content-init" aria-label="Permalink: init()" href="#init"></a></p>
<p dir="auto">This is the function that gets called by parent views in order to create a new view instance. Going with our hello world example, a consumer that wants to insert this into the page would do:</p>
<div dir="auto" data-snippet-clipboard-copy-content="<!doctype html>
<html lang=&quot;en&quot;>
<title>Hello world</title>

<main></main>

<script type=&quot;module&quot;>
  import init from './view.js';

  const main = document.querySelector('main');
  const update = init();

  main.appendChild(update({ name: 'world' }));
</script>"><pre><span>&lt;!doctype html<span>&gt;</span></span>
<span>&lt;</span><span>html</span> <span>lang</span>="<span>en</span>"<span>&gt;</span>
<span>&lt;</span><span>title</span><span>&gt;</span>Hello world<span>&lt;/</span><span>title</span><span>&gt;</span>

<span>&lt;</span><span>main</span><span>&gt;</span><span>&lt;/</span><span>main</span><span>&gt;</span>

<span>&lt;</span><span>script</span> <span>type</span>="<span>module</span>"<span>&gt;</span>
  <span>import</span> <span>init</span> <span>from</span> <span>'./view.js'</span><span>;</span>

  <span>const</span> <span>main</span> <span>=</span> <span>document</span><span>.</span><span>querySelector</span><span>(</span><span>'main'</span><span>)</span><span>;</span>
  <span>const</span> <span>update</span> <span>=</span> <span>init</span><span>(</span><span>)</span><span>;</span>

  <span>main</span><span>.</span><span>appendChild</span><span>(</span><span>update</span><span>(</span><span>{</span> <span>name</span>: <span>'world'</span> <span>}</span><span>)</span><span>)</span><span>;</span>
<span>&lt;/</span><span>script</span><span>&gt;</span></pre></div>
<p dir="auto">Notice here that <code>view</code> returns another function, <code>update</code>. This is the way that parent views can pass props down to the view. We'll discuss this concept more in the <a href="https://github.com/matthewp/views-the-hard-way/blob/main/update">#update</a> section.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">React comparison</h4><a id="user-content-react-comparison" aria-label="Permalink: React comparison" href="#react-comparison"></a></p>
<p dir="auto">Since <code>init</code> creates a new view instance, it's similar in that way to a component's constructor. To give an example, <a href="https://reactjs.org/docs/react-component.html#constructor" rel="nofollow">React.Component</a> does setup work in its constructor and updates happen in its <code>render</code>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="class Welcome extends React.Component {
  constructor(props) {
    super(props);
    this.state = {};
  }

  render() {
    return <div>Hello {this.props.name}!</div>;
  }
}"><pre><span>class</span> <span>Welcome</span> <span>extends</span> <span>React</span><span>.</span><span>Component</span> <span>{</span>
  <span>constructor</span><span>(</span><span>props</span><span>)</span> <span>{</span>
    <span>super</span><span>(</span><span>props</span><span>)</span><span>;</span>
    <span>this</span><span>.</span><span>state</span> <span>=</span> <span>{</span><span>}</span><span>;</span>
  <span>}</span>

  <span>render</span><span>(</span><span>)</span> <span>{</span>
    <span>return</span> <span>&lt;</span><span>div</span><span>&gt;</span>Hello <span>{</span><span>this</span><span>.</span><span>props</span><span>.</span><span>name</span><span>}</span>!<span>&lt;/</span><span>div</span><span>&gt;</span><span>;</span>
  <span>}</span>
<span>}</span></pre></div>
<p dir="auto">Using this component in another class illustrates how <em>Writing JavaScript Views the Hard Way</em> is similar:</p>
<div dir="auto" data-snippet-clipboard-copy-content="class App {
  render() {
    return <Welcome name=&quot;world&quot; />
  }
}"><pre><span>class</span> <span>App</span> <span>{</span>
  <span>render</span><span>(</span><span>)</span> <span>{</span>
    <span>return</span> <span>&lt;</span><span>Welcome</span> <span>name</span><span>=</span><span>"world"</span> <span>/&gt;</span>
  <span>}</span>
<span>}</span></pre></div>
<p dir="auto">To make the comparison, in our parent component/view we do:</p>
<div dir="auto" data-snippet-clipboard-copy-content="function init() {
  /* DOM variables */
  let frag = clone();
  let hostNode = frag.querySelector('#host');

  /* DOM views */
  let updateWelcome = welcomeView();

  /* DOM update functions */
  function setHostNode(welcomeFrag) {
    hostNode.appendChild(welcomeFrag());
  }

  /* Initialization */
  setHostNode(updateWelcome());

  function update(data = {}) {
    // This is equivalent to render() being called.
    if(data.name) updateWelcome(data);

    return frag;
  }

  return update;
}"><pre><span>function</span> <span>init</span><span>(</span><span>)</span> <span>{</span>
  <span>/* DOM variables */</span>
  <span>let</span> <span>frag</span> <span>=</span> <span>clone</span><span>(</span><span>)</span><span>;</span>
  <span>let</span> <span>hostNode</span> <span>=</span> <span>frag</span><span>.</span><span>querySelector</span><span>(</span><span>'#host'</span><span>)</span><span>;</span>

  <span>/* DOM views */</span>
  <span>let</span> <span>updateWelcome</span> <span>=</span> <span>welcomeView</span><span>(</span><span>)</span><span>;</span>

  <span>/* DOM update functions */</span>
  <span>function</span> <span>setHostNode</span><span>(</span><span>welcomeFrag</span><span>)</span> <span>{</span>
    <span>hostNode</span><span>.</span><span>appendChild</span><span>(</span><span>welcomeFrag</span><span>(</span><span>)</span><span>)</span><span>;</span>
  <span>}</span>

  <span>/* Initialization */</span>
  <span>setHostNode</span><span>(</span><span>updateWelcome</span><span>(</span><span>)</span><span>)</span><span>;</span>

  <span>function</span> <span>update</span><span>(</span><span>data</span> <span>=</span> <span>{</span><span>}</span><span>)</span> <span>{</span>
    <span>// This is equivalent to render() being called.</span>
    <span>if</span><span>(</span><span>data</span><span>.</span><span>name</span><span>)</span> <span>updateWelcome</span><span>(</span><span>data</span><span>)</span><span>;</span>

    <span>return</span> <span>frag</span><span>;</span>
  <span>}</span>

  <span>return</span> <span>update</span><span>;</span>
<span>}</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Sections within init()</h3><a id="user-content-sections-within-init" aria-label="Permalink: Sections within init()" href="#sections-within-init"></a></p>
<p dir="auto">The <code>init</code> function acts as a closure for the view instance. It contains variables and functions that are used to change state, modify the DOM, listen to events, and receive updates from parent views.</p>
<p dir="auto">Conventional wisdom says this sort of imperative code causes chaos. <em>Writing JavaScript Views the Hard Way</em> prevents this by structuring each part of a view into sections. This <strong>convention</strong> gives you a place to put everything your view needs.</p>
<p dir="auto">After all, all code is imperative in the end. Abstractions are just conventions in hiding. A <strong>pattern</strong>, which is all <em>Writing JavaScript Views the Hard Way</em> is, are conventions in plain site.</p>
<p dir="auto">With that being said, here are the sections of <code>init</code>.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">DOM variables</h4><a id="user-content-dom-variables" aria-label="Permalink: DOM variables" href="#dom-variables"></a></p>
<p dir="auto">At the top of the <code>init</code> function is a comment <code>/* DOM variables */</code> and it looks something like this:</p>
<div dir="auto" data-snippet-clipboard-copy-content="function init() {
  /* DOM variables */
  let frag = clone();
  let nameNode = frag.querySelector('#name');

  // More stuff later...
}"><pre><span>function</span> <span>init</span><span>(</span><span>)</span> <span>{</span>
  <span>/* DOM variables */</span>
  <span>let</span> <span>frag</span> <span>=</span> <span>clone</span><span>(</span><span>)</span><span>;</span>
  <span>let</span> <span>nameNode</span> <span>=</span> <span>frag</span><span>.</span><span>querySelector</span><span>(</span><span>'#name'</span><span>)</span><span>;</span>

  <span>// More stuff later...</span>
<span>}</span></pre></div>
<p dir="auto">Let's break down what goes here:</p>
<ul dir="auto">
<li>The <strong>fragment</strong> or root element returned by <a href="#clone">clone()</a> is assigned to <code>frag</code>.</li>
<li><code>nameNode</code> is plucked from within the <code>frag</code> and held as a variable.</li>
</ul>
<p dir="auto">This pattern will be used for any nodes which might need to be modified during the course of the view's lifetime.</p>
<p dir="auto">By convention DOM nodes are named like <code>fooNode</code>. Where <code>foo</code> is contextual to the node's usage and <code>Node</code> denotes that it is a DOM node.</p>
<p dir="auto">As you'll see in below sections, there are many types of bindings in a view. Having conventional names makes it easier to tell what is what.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">DOM views</h4><a id="user-content-dom-views" aria-label="Permalink: DOM views" href="#dom-views"></a></p>
<p dir="auto">After <strong>DOM variables</strong> come <strong>DOM views</strong>. These are other views used within the current view. If you are used to component libraries, a view is very much like a component. In the same way that components use other components, so do views use other views.</p>
<div dir="auto" data-snippet-clipboard-copy-content="import conditionalView from './conditiona.js';

function init() {
  /* DOM variables */
  let frag = clone();

  /* DOM views */
  let updateCondition = conditionalView();

  // More stuff later...
}"><pre><span>import</span> <span>conditionalView</span> <span>from</span> <span>'./conditiona.js'</span><span>;</span>

<span>function</span> <span>init</span><span>(</span><span>)</span> <span>{</span>
  <span>/* DOM variables */</span>
  <span>let</span> <span>frag</span> <span>=</span> <span>clone</span><span>(</span><span>)</span><span>;</span>

  <span>/* DOM views */</span>
  <span>let</span> <span>updateCondition</span> <span>=</span> <span>conditionalView</span><span>(</span><span>)</span><span>;</span>

  <span>// More stuff later...</span>
<span>}</span></pre></div>
<p dir="auto">As a convention view instances are named <code>updateFoo</code>. This isn't strictly required, of course, but it helps to distinguish them vs. the other types of variables within a view.</p>
<p dir="auto">The view instances are themselves functions. You pass them an object of properties which the view will use to update itself. Later in this document <code>update</code> is described.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">State variables</h4><a id="user-content-state-variables" aria-label="Permalink: State variables" href="#state-variables"></a></p>
<p dir="auto">After <strong>DOM views</strong> comes <strong>State variables</strong>. State variables are simply variables that are not DOM nodes or DOM views. Anything else like strings or numbers fit here.</p>
<p dir="auto">State variables are useful because they give us a mechanism to prevent mutating the DOM unless the variable has changed. Later when we discuss <strong>State update functions</strong> you'll see how that works, and why it is useful.</p>
<div dir="auto" data-snippet-clipboard-copy-content="function init() {
  /* DOM variables */
  let frag = clone();
  let nameNode = frag.querySelector('[name]');

  /* State variables */
  let name = 'world';

  // More stuff later...
}"><pre><span>function</span> <span>init</span><span>(</span><span>)</span> <span>{</span>
  <span>/* DOM variables */</span>
  <span>let</span> <span>frag</span> <span>=</span> <span>clone</span><span>(</span><span>)</span><span>;</span>
  <span>let</span> <span>nameNode</span> <span>=</span> <span>frag</span><span>.</span><span>querySelector</span><span>(</span><span>'[name]'</span><span>)</span><span>;</span>

  <span>/* State variables */</span>
  <span>let</span> <span>name</span> <span>=</span> <span>'world'</span><span>;</span>

  <span>// More stuff later...</span>
<span>}</span></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">DOM update functions</h4><a id="user-content-dom-update-functions" aria-label="Permalink: DOM update functions" href="#dom-update-functions"></a></p>
<p dir="auto">There are essentially 2 uses for views: Mutating the DOM and listening to user input from the DOM.</p>
<p dir="auto"><strong>DOM update functions</strong> comes after <strong>State variables</strong> and provide the mechanism for updating DOM nodes.</p>
<div dir="auto" data-snippet-clipboard-copy-content="function init() {
  /* DOM variables */
  let frag = clone();
  let nameNode = frag.querySelector('[name]');

  /* DOM update functions */
  function setNodeName(value) {
    nameNode.value = value;
  }

  // More stuff later...
}"><pre><span>function</span> <span>init</span><span>(</span><span>)</span> <span>{</span>
  <span>/* DOM variables */</span>
  <span>let</span> <span>frag</span> <span>=</span> <span>clone</span><span>(</span><span>)</span><span>;</span>
  <span>let</span> <span>nameNode</span> <span>=</span> <span>frag</span><span>.</span><span>querySelector</span><span>(</span><span>'[name]'</span><span>)</span><span>;</span>

  <span>/* DOM update functions */</span>
  <span>function</span> <span>setNodeName</span><span>(</span><span>value</span><span>)</span> <span>{</span>
    <span>nameNode</span><span>.</span><span>value</span> <span>=</span> <span>value</span><span>;</span>
  <span>}</span>

  <span>// More stuff later...</span>
<span>}</span></pre></div>
<p dir="auto">In the <a href="#dom-variables">DOM variables</a> section we mention that DOM variables are named like <code>nameNode</code>. This helps to distinguish them from other types of variables in a view, like state variables.</p>
<p dir="auto">In the same way, DOM update functions are named by convention as <code>setNodeName</code>. Breaking this down:</p>
<ul dir="auto">
<li><code>set</code> is an action we are taking on the node. It doesn't have to be set, it could be <code>change</code> or <code>delete</code> depending on what you are doing and what language you prefer.</li>
<li><code>name</code> specifies that this node holds information about a <strong>name</strong>.</li>
<li><code>Node</code> specifies that it is a DOM node that is being updated.</li>
</ul>
<p dir="auto"><em><strong>Important</strong></em></p>
<p dir="auto">It is critical that DOM nodes only be modified by DOM update functions. One of the difficulties in writing low-level imperative views is keeping track of where DOM mutations can occur.</p>
<p dir="auto">By restricting mutations to only DOM update functions we can more easily figure out where a mutation occurs. Additionally you can easily stick a breakpoint inside of this function and see the stack trace to figure out how we got here.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/361671/52751232-ca8b6180-2fbc-11e9-96bc-393c68a019ef.png"><img src="https://user-images.githubusercontent.com/361671/52751232-ca8b6180-2fbc-11e9-96bc-393c68a019ef.png" alt="An example of shallow stack traces that you get from using views the hard way"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">State update functions</h4><a id="user-content-state-update-functions" aria-label="Permalink: State update functions" href="#state-update-functions"></a></p>
<p dir="auto">After the DOM update functions comes the <strong>State update functions</strong>. This is a lot like the DOM update functions, but instead it is where <strong>State variables</strong> are changed. An example of a state update function:</p>
<div dir="auto" data-snippet-clipboard-copy-content="function init() {
  /* DOM variables */
  let frag = clone();
  let nameNode = frag.querySelector('.name');

  /* State variables */
  let name;

  /* DOM update functions */
  function setNameNode(value) {
    nameNode.textContent = value;
  }

  /* State update functions */
  function setName(value) {
    if(name !== value) {
      name = value;
      setNameNode(value);
    }
  }

  // More stuff later...
}"><pre><span>function</span> <span>init</span><span>(</span><span>)</span> <span>{</span>
  <span>/* DOM variables */</span>
  <span>let</span> <span>frag</span> <span>=</span> <span>clone</span><span>(</span><span>)</span><span>;</span>
  <span>let</span> <span>nameNode</span> <span>=</span> <span>frag</span><span>.</span><span>querySelector</span><span>(</span><span>'.name'</span><span>)</span><span>;</span>

  <span>/* State variables */</span>
  <span>let</span> <span>name</span><span>;</span>

  <span>/* DOM update functions */</span>
  <span>function</span> <span>setNameNode</span><span>(</span><span>value</span><span>)</span> <span>{</span>
    <span>nameNode</span><span>.</span><span>textContent</span> <span>=</span> <span>value</span><span>;</span>
  <span>}</span>

  <span>/* State update functions */</span>
  <span>function</span> <span>setName</span><span>(</span><span>value</span><span>)</span> <span>{</span>
    <span>if</span><span>(</span><span>name</span> <span>!==</span> <span>value</span><span>)</span> <span>{</span>
      <span>name</span> <span>=</span> <span>value</span><span>;</span>
      <span>setNameNode</span><span>(</span><span>value</span><span>)</span><span>;</span>
    <span>}</span>
  <span>}</span>

  <span>// More stuff later...</span>
<span>}</span></pre></div>
<p dir="auto">The naming convention for State update functions is <code>setName</code>:</p>
<ul dir="auto">
<li><code>set</code> is the action we are taking on the state.</li>
<li><code>name</code> denotes the name of the state variable.</li>
</ul>
<p dir="auto">The other thing to notice about State update functions is the following logic (from the example):</p>
<div dir="auto" data-snippet-clipboard-copy-content="if(name !== value) {
  name = value;
  setNameNode(value);
}"><pre><span>if</span><span>(</span><span>name</span> <span>!==</span> <span>value</span><span>)</span> <span>{</span>
  <span>name</span> <span>=</span> <span>value</span><span>;</span>
  <span>setNameNode</span><span>(</span><span>value</span><span>)</span><span>;</span>
<span>}</span></pre></div>
<p dir="auto">The convention here is to check if the incoming value is different from the current value. If so, reassign the State variable to the new value. Secondary, you also often have a corresponding <strong>DOM update function</strong> that gets called when the state variable changes. This is important because it means that we are only updating DOM when necessary.</p>
<p dir="auto">Usually a State update function is only going to call <em>one</em> DOM update function. This isn't always the case, but if you find yourself modifying multiple DOM nodes in a single State update function, it might be the case that your State variable is responsibility for too much. Instead break up the state into smaller pieces, create more State update functions, and call those in the <strong>State logic</strong> section (discussed below).</p>
<p dir="auto"><em><strong>Important</strong></em></p>
<p dir="auto">Like with DOM update functions, it's critical that State variables are <em>only</em> updated within the State update functions. In particular to state, it's important so that:</p>
<ul dir="auto">
<li>You can easily track and debug where state is modified, as for each variable there's only one place where it can happen.</li>
<li>By only mutating state in the State update functions, you consolidate the logic in one place.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Compatibility</h2><a id="user-content-compatibility" aria-label="Permalink: Compatibility" href="#compatibility"></a></p>
<p dir="auto"><strong>TODO</strong></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Hands-On Large Language Models (135 pts)]]></title>
            <link>https://github.com/HandsOnLLM/Hands-On-Large-Language-Models</link>
            <guid>43733553</guid>
            <pubDate>Sat, 19 Apr 2025 01:52:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/HandsOnLLM/Hands-On-Large-Language-Models">https://github.com/HandsOnLLM/Hands-On-Large-Language-Models</a>, See on <a href="https://news.ycombinator.com/item?id=43733553">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Hands-On Large Language Models</h2><a id="user-content-hands-on-large-language-models" aria-label="Permalink: Hands-On Large Language Models" href="#hands-on-large-language-models"></a></p>
<p dir="auto"><a href="https://www.linkedin.com/in/jalammar/" rel="nofollow"><img src="https://camo.githubusercontent.com/6a0c6a9c7dbb027b88582bc4a733240f959c30c38a30ee0a0c44a789925f1e56/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f466f6c6c6f772532304a61792d626c75652e7376673f6c6f676f3d6c696e6b6564696e" data-canonical-src="https://img.shields.io/badge/Follow%20Jay-blue.svg?logo=linkedin"></a>
<a href="https://www.linkedin.com/in/mgrootendorst/" rel="nofollow"><img src="https://camo.githubusercontent.com/ebe48ac2cefd3aa7d6c9e6555d45271753ae640a7d5acf91d00e5ba1d90650d7/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f466f6c6c6f772532304d61617274656e2d626c75652e7376673f6c6f676f3d6c696e6b6564696e" data-canonical-src="https://img.shields.io/badge/Follow%20Maarten-blue.svg?logo=linkedin"></a>
<a href="https://www.deeplearning.ai/short-courses/how-transformer-llms-work/?utm_campaign=handsonllm-launch&amp;utm_medium=partner" rel="nofollow"><img src="https://camo.githubusercontent.com/baaa1e8f1e9ce719f6777328468b164c78c03f48588ed22ebfc7807f6f59a50e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f446565704c6561726e696e672e4149253230436f757273652d4e4557212d266c6162656c436f6c6f723d626c61636b26636f6c6f723d7265642e7376673f6c6f676f3d646174613a696d6167652f737667253262786d6c3b6261736536342c50484e325a79423462577875637a30696148523063446f764c336433647935334d793576636d63764d6a41774d43397a646d636949485a705a58644362336739496a41754d4441774d7a59314d6a6778494330774c6a41774d4445304d4445304d69417a4d7934794f53417a4d7934784e53492b43676b38634746306143426b50534a4e4d5459754e6a517a49444d7a4c6a45304e574d744d7934794f5449674d4330324c6a55784c5334354e7a49744f5334794e4459744d6934334f544e684d5459754e546734494445324c6a55344f434177494441784c5459754d544d744e7934304d7a68424d5459754e544133494445324c6a55774e794177494441784c6a4d794944457a4c6a4d30595445324c6a5531494445324c6a5531494441674d4445304c6a55314e5330344c6a51344e5545784e6934324e6a55674d5459754e6a5931494441674d4445784d79347a4f5459754d7a4534595445324c6a6378494445324c6a6378494441674d4445354c6a59784e6934354e4451674d5459754e6a4934494445324c6a59794f434177494441784e7934304e7941324c6a45774d7941784e6934314d6a49674d5459754e544979494441674d4445794c6a67774e4341354c6a49774e324d77494451754d7a6b324c5445754e7a557a494467754e6a45744e4334344e7a51674d5445754e7a4535595445324c6a5934494445324c6a5934494441674d4445744d5445754e7a5935494451754f445530656d30754d5449314c5459754e6a4934597a59754f544132494441674d5449754e5445334c5455754e6a6b34494445794c6a55784e7930784d6934334d7941774c5463754d444d744e5334324d5330784d6934334d6a55744d5449754e5445334c5445794c6a63794e5330324c6a6b774e6941774c5445794c6a55784e7941314c6a59354f4330784d6934314d5463674d5449754e7a4931494441674e7934774d6a63674e5334324d5445674d5449754e7a4d674d5449754e544533494445794c6a637a656d30744c6a45794e5330794c6a6b784f474d744e6934794f446b674d4330784d53347a4f4459744e4334354d6a55744d5445754d7a67324c5445784c6a41774d6b4d314c6a49314e7941324c6a5579494445774c6a4d32494445754e546b674d5459754e6a517a494445754e546c6a4e6934794f4451674d4341784d53347a4f4459674e4334354d7941784d53347a4f4459674d5445754d444133637930314c6a41354e7941784d5334774d4449744d5445754d7a6732494445784c6a41774d6e70744c5334794e4449744e4334314d44686a4e4334334e794177494467754e6a4d7a4c544d754e6a6335494467754e6a4d7a4c5467754d6a4534494441744e4334314d7a67744d7934344f4455744f4334794d6a45744f4334324d7a4d744f4334794d6a45744e4334334e4463674d4330344c6a597a4d69417a4c6a59334f5330344c6a597a4d6941344c6a49794d534177494451754e54517a49444d754f446731494467754d6a4534494467754e6a4d79494467754d6a4534656949675a6d6c736244306949305a454e4545324d53497650676f384c334e325a7a343d" data-canonical-src="https://img.shields.io/badge/DeepLearning.AI%20Course-NEW!-&amp;labelColor=black&amp;color=red.svg?logo=data:image/svg%2bxml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAuMDAwMzY1MjgxIC0wLjAwMDE0MDE0MiAzMy4yOSAzMy4xNSI+Cgk8cGF0aCBkPSJNMTYuNjQzIDMzLjE0NWMtMy4yOTIgMC02LjUxLS45NzItOS4yNDYtMi43OTNhMTYuNTg4IDE2LjU4OCAwIDAxLTYuMTMtNy40MzhBMTYuNTA3IDE2LjUwNyAwIDAxLjMyIDEzLjM0YTE2LjU1IDE2LjU1IDAgMDE0LjU1NS04LjQ4NUExNi42NjUgMTYuNjY1IDAgMDExMy4zOTYuMzE4YTE2LjcxIDE2LjcxIDAgMDE5LjYxNi45NDQgMTYuNjI4IDE2LjYyOCAwIDAxNy40NyA2LjEwMyAxNi41MjIgMTYuNTIyIDAgMDEyLjgwNCA5LjIwN2MwIDQuMzk2LTEuNzUzIDguNjEtNC44NzQgMTEuNzE5YTE2LjY4IDE2LjY4IDAgMDEtMTEuNzY5IDQuODU0em0uMTI1LTYuNjI4YzYuOTA2IDAgMTIuNTE3LTUuNjk4IDEyLjUxNy0xMi43MyAwLTcuMDMtNS42MS0xMi43MjUtMTIuNTE3LTEyLjcyNS02LjkwNiAwLTEyLjUxNyA1LjY5OC0xMi41MTcgMTIuNzI1IDAgNy4wMjcgNS42MTEgMTIuNzMgMTIuNTE3IDEyLjczem0tLjEyNS0yLjkxOGMtNi4yODkgMC0xMS4zODYtNC45MjUtMTEuMzg2LTExLjAwMkM1LjI1NyA2LjUyIDEwLjM2IDEuNTkgMTYuNjQzIDEuNTljNi4yODQgMCAxMS4zODYgNC45MyAxMS4zODYgMTEuMDA3cy01LjA5NyAxMS4wMDItMTEuMzg2IDExLjAwMnptLS4yNDItNC41MDhjNC43NyAwIDguNjMzLTMuNjc5IDguNjMzLTguMjE4IDAtNC41MzgtMy44ODUtOC4yMjEtOC42MzMtOC4yMjEtNC43NDcgMC04LjYzMiAzLjY3OS04LjYzMiA4LjIyMSAwIDQuNTQzIDMuODg1IDguMjE4IDguNjMyIDguMjE4eiIgZmlsbD0iI0ZENEE2MSIvPgo8L3N2Zz4="></a></p>
<p dir="auto">Welcome! In this repository you will find the code for all examples throughout the book <a href="https://www.amazon.com/Hands-Large-Language-Models-Understanding/dp/1098150961" rel="nofollow">Hands-On Large Language Models</a> written by <a href="https://www.linkedin.com/in/jalammar/" rel="nofollow">Jay Alammar</a> and <a href="https://www.linkedin.com/in/mgrootendorst/" rel="nofollow">Maarten Grootendorst</a> which we playfully dubbed: <br></p>
<p dir="auto"><b><i>"The Illustrated LLM Book"</i></b></p>
<p dir="auto">Through the visually educational nature of this book and with <strong>almost 300 custom made figures</strong>, learn the practical tools and concepts you need to use Large Language Models today!</p>
<p dir="auto"><a href="https://www.amazon.com/Hands-Large-Language-Models-Understanding/dp/1098150961" rel="nofollow"><img src="https://github.com/HandsOnLLM/Hands-On-Large-Language-Models/raw/main/images/book_cover.png" width="50%" height="50%"></a></p>

<p dir="auto">The book is available on:</p>
<ul dir="auto">
<li><a href="https://www.amazon.com/Hands-Large-Language-Models-Understanding/dp/1098150961" rel="nofollow">Amazon</a></li>
<li><a href="https://www.shroffpublishers.com/books/computer-science/large-language-models/9789355425522/" rel="nofollow">Shroff Publishers (India)</a></li>
<li><a href="https://www.oreilly.com/library/view/hands-on-large-language/9781098150952/" rel="nofollow">O'Reilly</a></li>
<li><a href="https://www.amazon.com/Hands-Large-Language-Models-Alammar-ebook/dp/B0DGZ46G88/ref=tmm_kin_swatch_0?_encoding=UTF8&amp;qid=&amp;sr=" rel="nofollow">Kindle</a></li>
<li><a href="https://www.barnesandnoble.com/w/hands-on-large-language-models-jay-alammar/1145185960" rel="nofollow">Barnes and Noble</a></li>
<li><a href="https://www.goodreads.com/book/show/210408850-hands-on-large-language-models" rel="nofollow">Goodreads</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Table of Contents</h2><a id="user-content-table-of-contents" aria-label="Permalink: Table of Contents" href="#table-of-contents"></a></p>
<p dir="auto">We advise to run all examples through Google Colab for the easiest setup. Google Colab allows you to use a T4 GPU with 16GB of VRAM for free. All examples were mainly built and tested using Google Colab, so it should be the most stable platform. However, any other cloud provider should work.</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Chapter</th>
<th>Notebook</th>
</tr>
</thead>
<tbody>
<tr>
<td>Chapter 1: Introduction to Language Models</td>
<td><a href="https://colab.research.google.com/github/HandsOnLLM/Hands-On-Large-Language-Models/blob/main/chapter01/Chapter%201%20-%20Introduction%20to%20Language%20Models.ipynb" rel="nofollow"><img src="https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" alt="Open In Colab" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg"></a></td>
</tr>
<tr>
<td>Chapter 2: Tokens and Embeddings</td>
<td><a href="https://colab.research.google.com/github/HandsOnLLM/Hands-On-Large-Language-Models/blob/main/chapter02/Chapter%202%20-%20Tokens%20and%20Token%20Embeddings.ipynb" rel="nofollow"><img src="https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" alt="Open In Colab" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg"></a></td>
</tr>
<tr>
<td>Chapter 3: Looking Inside Transformer LLMs</td>
<td><a href="https://colab.research.google.com/github/HandsOnLLM/Hands-On-Large-Language-Models/blob/main/chapter03/Chapter%203%20-%20Looking%20Inside%20LLMs.ipynb" rel="nofollow"><img src="https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" alt="Open In Colab" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg"></a></td>
</tr>
<tr>
<td>Chapter 4: Text Classification</td>
<td><a href="https://colab.research.google.com/github/HandsOnLLM/Hands-On-Large-Language-Models/blob/main/chapter04/Chapter%204%20-%20Text%20Classification.ipynb" rel="nofollow"><img src="https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" alt="Open In Colab" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg"></a></td>
</tr>
<tr>
<td>Chapter 5: Text Clustering and Topic Modeling</td>
<td><a href="https://colab.research.google.com/github/HandsOnLLM/Hands-On-Large-Language-Models/blob/main/chapter05/Chapter%205%20-%20Text%20Clustering%20and%20Topic%20Modeling.ipynb" rel="nofollow"><img src="https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" alt="Open In Colab" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg"></a></td>
</tr>
<tr>
<td>Chapter 6: Prompt Engineering</td>
<td><a href="https://colab.research.google.com/github/HandsOnLLM/Hands-On-Large-Language-Models/blob/main/chapter06/Chapter%206%20-%20Prompt%20Engineering.ipynb" rel="nofollow"><img src="https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" alt="Open In Colab" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg"></a></td>
</tr>
<tr>
<td>Chapter 7: Advanced Text Generation Techniques and Tools</td>
<td><a href="https://colab.research.google.com/github/HandsOnLLM/Hands-On-Large-Language-Models/blob/main/chapter07/Chapter%207%20-%20Advanced%20Text%20Generation%20Techniques%20and%20Tools.ipynb" rel="nofollow"><img src="https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" alt="Open In Colab" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg"></a></td>
</tr>
<tr>
<td>Chapter 8: Semantic Search and Retrieval-Augmented Generation</td>
<td><a href="https://colab.research.google.com/github/HandsOnLLM/Hands-On-Large-Language-Models/blob/main/chapter08/Chapter%208%20-%20Semantic%20Search.ipynb" rel="nofollow"><img src="https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" alt="Open In Colab" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg"></a></td>
</tr>
<tr>
<td>Chapter 9: Multimodal Large Language Models</td>
<td><a href="https://colab.research.google.com/github/HandsOnLLM/Hands-On-Large-Language-Models/blob/main/chapter09/Chapter%209%20-%20Multimodal%20Large%20Language%20Models.ipynb" rel="nofollow"><img src="https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" alt="Open In Colab" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg"></a></td>
</tr>
<tr>
<td>Chapter 10: Creating Text Embedding Models</td>
<td><a href="https://colab.research.google.com/github/HandsOnLLM/Hands-On-Large-Language-Models/blob/main/chapter10/Chapter%2010%20-%20Creating%20Text%20Embedding%20Models.ipynb" rel="nofollow"><img src="https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" alt="Open In Colab" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg"></a></td>
</tr>
<tr>
<td>Chapter 11: Fine-tuning Representation Models for Classification</td>
<td><a href="https://colab.research.google.com/github/HandsOnLLM/Hands-On-Large-Language-Models/blob/main/chapter11/Chapter%2011%20-%20Fine-Tuning%20BERT.ipynb" rel="nofollow"><img src="https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" alt="Open In Colab" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg"></a></td>
</tr>
<tr>
<td>Chapter 12: Fine-tuning Generation Models</td>
<td><a href="https://colab.research.google.com/github/HandsOnLLM/Hands-On-Large-Language-Models/blob/main/chapter12/Chapter%2012%20-%20Fine-tuning%20Generation%20Models.ipynb" rel="nofollow"><img src="https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" alt="Open In Colab" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg"></a></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<div dir="auto"><p dir="auto">Tip</p><p dir="auto">You can check the <a href="https://github.com/HandsOnLLM/Hands-On-Large-Language-Models/blob/main/.setup">setup</a> folder for a quick-start guide to install all packages locally and you can check the <a href="https://github.com/HandsOnLLM/Hands-On-Large-Language-Models/blob/main/.setup/conda">conda</a> folder for a complete guide on how to setup your environment, including conda and PyTorch installation.
Note that the depending on your OS, Python version, and dependencies your results might be slightly differ. However, they
should this be similar to the examples in the book.</p>
</div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Reviews</h2><a id="user-content-reviews" aria-label="Permalink: Reviews" href="#reviews"></a></p>
<blockquote>
<p dir="auto">"<em>Jay and Maarten have continued their tradition of providing beautifully illustrated and insightful descriptions of complex topics in their new book. Bolstered with working code, timelines, and references to key papers, their book is a valuable resource for anyone looking to understand the main techniques behind how Large Language Models are built.</em>"</p>
<p dir="auto"><strong>Andrew Ng</strong> - founder of <a href="https://www.deeplearning.ai/" rel="nofollow">DeepLearning.AI</a></p>
</blockquote>
<hr>
<blockquote>
<p dir="auto">"<em>This is an exceptional guide to the world of language models and their practical applications in industry. Its highly-visual coverage of generative, representational, and retrieval applications of language models empowers readers to quickly understand, use, and refine LLMs. Highly recommended!</em>"</p>
<p dir="auto"><strong>Nils Reimers</strong> - Director of Machine Learning at Cohere | creator of <a href="https://github.com/UKPLab/sentence-transformers">sentence-transformers</a></p>
</blockquote>
<hr>
<blockquote>
<p dir="auto">"<em>I can’t think of another book that is more important to read right now. On every single page, I learned something that is critical to success in this era of language models.</em>"</p>
<p dir="auto"><strong>Josh Starmer</strong> - <a href="https://www.youtube.com/channel/UCtYLUTtgS3k1Fg4y5tAhLbw" rel="nofollow">StatQuest</a></p>
</blockquote>
<hr>
<blockquote>
<p dir="auto">"<em>If you’re looking to get up to speed in everything regarding LLMs, look no further! In this wonderful book, Jay and Maarten will take you from zero to expert in the history and latest advances in large language models. With very intuitive explanations, great real-life examples, clear illustrations, and comprehensive code labs, this book lifts the curtain on the complexities of transformer models, tokenizers, semantic search, RAG, and many other cutting-edge technologies. A must read for anyone interested in the latest AI technology!</em>"</p>
<p dir="auto"><strong>Luis Serrano, PhD</strong> - Founder and CEO of <a href="https://www.youtube.com/@SerranoAcademy" rel="nofollow">Serrano Academy</a></p>
</blockquote>
<hr>
<blockquote>
<p dir="auto">"<em>Hands-On Large Language Models brings clarity and practical examples to cut through the hype of AI. It provides a wealth of great diagrams and visual aids to supplement the clear explanations. The worked examples and code make concrete what other books leave abstract. The book starts with simple introductory beginnings, and steadily builds in scope. By the final chapters, you will be fine-tuning and building your own large language models with confidence.</em>"</p>
<p dir="auto"><strong>Leland McInnes</strong> - Researcher at the Tutte Institute for Mathematics and Computing | creator of <a href="https://github.com/lmcinnes/umap">UMAP</a> and <a href="https://github.com/scikit-learn-contrib/hdbscan">HDBSCAN</a></p>
</blockquote>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Additional Resources</h2><a id="user-content-additional-resources" aria-label="Permalink: Additional Resources" href="#additional-resources"></a></p>
<p dir="auto">We attempted to put as much information into the book without it being overwhelming. However, even with a 400-page book there is still much to discover!</p>
<p dir="auto">We continue to create more guides that compliment the book and go more in-depth into new and exciting topics:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th><a href="https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-mamba-and-state" rel="nofollow">A Visual Guide to Mamba</a></th>
<th><a href="https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-quantization" rel="nofollow">A Visual Guide to Quantization</a></th>
<th><a href="https://jalammar.github.io/illustrated-stable-diffusion/" rel="nofollow">The Illustrated Stable Diffusion</a></th>
</tr>
</thead>
<tbody>
<tr>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/HandsOnLLM/Hands-On-Large-Language-Models/blob/main/images/mamba.png"><img src="https://github.com/HandsOnLLM/Hands-On-Large-Language-Models/raw/main/images/mamba.png" alt=""></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/HandsOnLLM/Hands-On-Large-Language-Models/blob/main/images/quant.png"><img src="https://github.com/HandsOnLLM/Hands-On-Large-Language-Models/raw/main/images/quant.png" alt=""></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/HandsOnLLM/Hands-On-Large-Language-Models/blob/main/images/diffusion.png"><img src="https://github.com/HandsOnLLM/Hands-On-Large-Language-Models/raw/main/images/diffusion.png" alt=""></a></td>
</tr>
<tr>
<td><strong><a href="https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-mixture-of-experts" rel="nofollow">A Visual Guide to Mixture of Experts</a></strong></td>
<td><strong><a href="https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-reasoning-llms" rel="nofollow">A Visual Guide to Reasoning LLMs</a></strong></td>
<td><strong><a href="https://newsletter.languagemodels.co/p/the-illustrated-deepseek-r1" rel="nofollow">The Illustrated DeepSeek-R1</a></strong></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/HandsOnLLM/Hands-On-Large-Language-Models/blob/main/images/moe.png"><img src="https://github.com/HandsOnLLM/Hands-On-Large-Language-Models/raw/main/images/moe.png" alt=""></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/HandsOnLLM/Hands-On-Large-Language-Models/blob/main/images/reasoning.png"><img src="https://github.com/HandsOnLLM/Hands-On-Large-Language-Models/raw/main/images/reasoning.png" alt=""></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/HandsOnLLM/Hands-On-Large-Language-Models/blob/main/images/deepseek.png"><img src="https://github.com/HandsOnLLM/Hands-On-Large-Language-Models/raw/main/images/deepseek.png" alt=""></a></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">For more information on these visual/illustrated guides, check out the <a href="https://github.com/HandsOnLLM/Hands-On-Large-Language-Models/blob/main/bonus">bonus</a> folder.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Citation</h2><a id="user-content-citation" aria-label="Permalink: Citation" href="#citation"></a></p>
<p dir="auto">Please consider citing the book if you consider it useful for your research:</p>
<div data-snippet-clipboard-copy-content="@book{hands-on-llms-book,
  author       = {Jay Alammar and Maarten Grootendorst},
  title        = {Hands-On Large Language Models},
  publisher    = {O'Reilly},
  year         = {2024},
  isbn         = {978-1098150969},
  url          = {https://www.oreilly.com/library/view/hands-on-large-language/9781098150952/},
  github       = {https://github.com/HandsOnLLM/Hands-On-Large-Language-Models}
}"><pre><code>@book{hands-on-llms-book,
  author       = {Jay Alammar and Maarten Grootendorst},
  title        = {Hands-On Large Language Models},
  publisher    = {O'Reilly},
  year         = {2024},
  isbn         = {978-1098150969},
  url          = {https://www.oreilly.com/library/view/hands-on-large-language/9781098150952/},
  github       = {https://github.com/HandsOnLLM/Hands-On-Large-Language-Models}
}
</code></pre></div>
</article></div></div>]]></description>
        </item>
    </channel>
</rss>