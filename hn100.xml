<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Mon, 04 Nov 2024 17:30:04 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[We're Leaving Kubernetes (125 pts)]]></title>
            <link>https://www.gitpod.io/blog/we-are-leaving-kubernetes</link>
            <guid>42041917</guid>
            <pubDate>Mon, 04 Nov 2024 14:41:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.gitpod.io/blog/we-are-leaving-kubernetes">https://www.gitpod.io/blog/we-are-leaving-kubernetes</a>, See on <a href="https://news.ycombinator.com/item?id=42041917">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				
				<header>
					</header>
				<p>Kubernetes seems like the obvious choice for building out remote, standardized and automated development environments. We thought so too and have spent six years invested in making the most popular cloud development environment platform at internet scale. That’s 1.5 million users, where we regularly see thousands of development environments per day. <strong>In that time we’ve found that Kubernetes is not the right choice for building development environments.</strong></p>
<p>This is our journey of experiments, failures and dead-ends building development environments on <a href="https://kubernetes.io/" rel="nofollow noopener noreferrer" target="_blank">Kubernetes</a>. Over the years, we experimented with many ideas involving SSDs, PVCs, <a href="https://ebpf.io/" rel="nofollow noopener noreferrer" target="_blank">eBPF</a>, <a href="https://brauner.github.io/2020/07/23/seccomp-notify.html" rel="nofollow noopener noreferrer" target="_blank">seccomp notify</a>, <a href="https://man7.org/linux/man-pages/man8/tc.8.html" rel="nofollow noopener noreferrer" target="_blank">TC</a> and <a href="https://kernel.dk/io_uring.pdf" rel="nofollow noopener noreferrer" target="_blank">io_uring</a>, <a href="https://lwn.net/Articles/718639/" rel="nofollow noopener noreferrer" target="_blank">shiftfs</a>, FUSE and <a href="https://docs.kernel.org/filesystems/idmappings.html" rel="nofollow noopener noreferrer" target="_blank">idmapped mounts</a>, ranging from <a href="https://firecracker-microvm.github.io/" rel="nofollow noopener noreferrer" target="_blank">microVMs</a>, <a href="https://kubevirt.io/" rel="nofollow noopener noreferrer" target="_blank">kubevirt</a> to <a href="https://www.vcluster.com/" rel="nofollow noopener noreferrer" target="_blank">vCluster</a>.</p>
<p>In pursuit of the most optimal infrastructure to balance security, performance and interoperability. All while wrestling with the unique challenges of building a system to scale up, remain secure as it’s handling arbitrary code execution, and be stable enough for developers to work in.</p>
<p><strong>This is not a story of whether or not to use Kubernetes for production workloads</strong> that’s a whole separate conversation. As is the topic of how to build a comprehensive soup-to-nuts developer experience for shipping applications on Kubernetes.</p>
<p><strong>This is the story of how (not) to build development environments in the cloud.</strong></p>
<h2 id="why-are-development-environments-unique">Why are development environments unique?<a href="#why-are-development-environments-unique"></a></h2>
<p>Before we dive in, it’s crucial to understand what makes development environments unique compared to production workloads:</p>
<ul><li><strong>They are extremely stateful and interactive</strong>: Which means they cannot be moved from one node to another. The many gigabytes of source code, build caches, Docker container and test data are subject to a high change rate and costly to migrate. Unlike many production services, there’s a 1-to-1 interaction between the developer and their environment.</li>
<li><strong>Developers are deeply invested in their source code and the changes they make</strong>: Developers don’t take kindly to losing any source code changes or to being blocked by any system. This makes development environments particularly intolerant to failure.</li>
<li><strong>They have unpredictable resource usage patterns</strong>: Development Environments have particular and unpredictable resource usage patterns. They won’t need much CPU bandwidth most of the time, but will require several cores within a few 100ms. Anything slower than that manifests as unacceptable latency and unresponsiveness.</li>
<li><strong>They require far-reaching permissions and capabilities</strong>: Unlike production workloads, development environments often need root access and the ability to download and install packages. What constitutes a security concern for production workloads, is expected behavior of development environments: getting root access, extended network capabilities and control over the system (e.g. mounting additional filesystems).</li></ul>
<p>These characteristics set development environments apart from typical application workloads and significantly influence the infrastructure decisions we’ve made along the way.</p>
<h2 id="the-system-today-obviously-its-kubernetes">The system today: obviously it’s Kubernetes<a href="#the-system-today-obviously-its-kubernetes"></a></h2>
<p>When we started Gitpod, Kubernetes seemed like the ideal choice for our infrastructure. Its promise of scalability, container orchestration, and rich ecosystem aligned perfectly with our vision for cloud development environments. However, as we scaled and our user base grew, we encountered several challenges around security and state management that pushed Kubernetes to its limits. <strong>Fundamentally, Kubernetes is built to run well controlled application workloads, not unruly development environments.</strong></p>
<p>Managing Kubernetes at scale is complex. While managed services like GKE and EKS alleviate some pain points, they come with their own set of restrictions and limitations. We found that many teams looking to operate a CDE underestimate the complexity of Kubernetes, which lead to a significant support load for our previous self-managed Gitpod offering.</p>
<h2 id="resource-management-struggles">Resource management struggles<a href="#resource-management-struggles"></a></h2>
<p>One of the most significant challenges we faced was resource management, particularly CPU and memory allocation per environment. At first glance, running multiple environments on a node seems attractive to share resources (such as CPU, memory, IO and network bandwidth) between those resources. In practice, this incurs significant noisy neighbor effects leading to a detrimental user experience.</p>
<h3 id="cpu-challenges">CPU challenges<a href="#cpu-challenges"></a></h3>
<p>CPU time seems like the simplest candidate to share between environments. Most of the time development environments don’t need much CPU, but when they do, they need it quickly. Latency becomes immediately apparent to users when their language server starts to lag or their terminal becomes choppy. This spiky nature of the CPU requirements of development environments (periods of inactivity followed by intensive builds) makes it difficult to predict when CPU time is needed.</p>
<p>For solutions, we experimented with various CFS (<a href="https://docs.kernel.org/scheduler/sched-design-CFS.html" rel="nofollow noopener noreferrer" target="_blank">Completely Fair Scheduler</a>) based schemes, implementing a custom controller using a DaemonSet. A core challenge is that we can not predict when CPU bandwidth is needed, but only understand when it would have been needed (by observing nr_throttled of the cgroup’s cpu_stats).</p>
<p>Even when using static CPU resource limits, challenges arise, because unlike application workloads a development environment will run many processes in the same container. These processes compete for the same CPU bandwidth, which can lead to e.g. VS Code disconnects because VS Code server is starved for CPU time.</p>
<p>We have attempted to solve this problem by adjusting the process priorities of the individual processes, e.g. increasing the priority of bash or vscode-server. However, these process priorities apply to the entire process group (depending on your Kernel’s autogroup scheduling configuration), hence also to the resource hungry compilers started in a VS Code terminal. Using process priorities to counter terminal lag requires a carefully written control loop to be effective.</p>
<p>We introduced custom CFS and process priority based control loops built on cgroupv1 and moved to cgroupsv2 once they became more readily available on managed Kubernetes platforms with 1.24. <a href="https://kubernetes.io/docs/concepts/scheduling-eviction/dynamic-resource-allocation/" rel="nofollow noopener noreferrer" target="_blank">Dynamic resource allocation</a> introduced with Kubernetes 1.26 means one no longer needs to deploy a DaemonSet and modify cgroups directly, possibly at the expense of the control loop speed and hence effectiveness. All the schemes outlined above rely on second-by-second readjustment of CFS limits and niceness values.</p>
<h3 id="memory-management">Memory management<a href="#memory-management"></a></h3>
<p>Memory management presented its own set of challenges. Assigning every environment a fixed amount of memory, so that under maximum occupation each environment gets their fixed share is straightforward, but very limiting. In the cloud, RAM is one of the more expensive resources, hence the desire to overbook memory.</p>
<p>Until <a href="https://kubernetes.io/blog/2021/08/09/run-nodes-with-swap-alpha/" rel="nofollow noopener noreferrer" target="_blank">swap-space became available in Kubernetes 1.22</a>, memory overbooking was near impossible to do, because reclaiming memory inevitably means killing processes. With the addition of swap space the need to overbook memory has somewhat gone away, since swap works well in practice for hosting development environments.</p>
<h2 id="storage-performance-optimization">Storage performance optimization<a href="#storage-performance-optimization"></a></h2>
<p>Storage performance is important for the startup performance and experience of development environments. We have found that specifically IOPS and latency affect experience within an environment. IO bandwidth however directly impacts your workspace startup performance, specifically when creating/restoring backups or extracting large workspace images.</p>
<p><strong>We experimented with various setups to find the right balance between speed and reliability, cost and performance.</strong></p>
<ul><li><strong>SSD RAID 0</strong>: This offered high IOPS and bandwidth but tied the data to a specific node. The failure of any single disk would result in complete data loss. This is how gitpod.io operates today and we have not seen such a disk failure happen yet. A simpler version of this setup is to use a single SSD attached to the node. This approach provides lower IOPS and bandwidth, and still binds the data to individual nodes.</li>
<li><strong>Block storage such as EBS volumes or Google persistent disks which are permanently attached to the nodes</strong> considerably broaden the different instances or availability zones that can be used. While still bound to a single node, and offering considerably lower throughput/bandwidth than local SSDs they are more widely available.</li>
<li><strong>Persistent Volume Claims (PVCs) seem like the obvious choice when using Kubernetes</strong>. As abstraction over different storage implementations they offer a lot of flexibility, but also introduce new challenges:<ul><li>Unpredictable attachment and detachment timing, leading to unpredictable workspace startup times. Combined with increased scheduling complexity they make implementing effective scheduling strategies harder.</li>
<li>Reliability issues leading to workspace failures, particularly during startup. This was especially noticeable on Google Cloud (in 2022) and rendered our attempts to use PVCs impractical.</li>
<li>Limited number of disks that could be attached to an instance, imposing additional constraints on the scheduler and number of workspaces per node.</li>
<li>AZ locality constraints which makes balancing workspaces across AZs even harder.</li></ul></li></ul>
<p>Backing up and restoring local disks proved to be an expensive operation. We implemented a solution using a daemonSet that uploads and downloads uncompressed tar archives to/from S3. This approach required careful balancing of I/O, network bandwidth, and CPU usage: for example, (de)compressing archives consumes most available CPU on a node, whereas the extra traffic produced by uncompressed backups usually doesn’t consume all available network bandwidth (if the number of concurrently starting/stopping workspaces is carefully controlled).</p>
<p>IO bandwidth on the node is shared across workspaces. We found that, unless we limited the IO bandwidth available to each workspace, other workspaces might starve for IO bandwidth and cease to function. Particularly the content backup/restore produced this problem. We implemented cgroup-based <a href="https://github.com/gitpod-io/gitpod/pull/9440" rel="nofollow noopener noreferrer" target="_blank">IO limiter</a> which imposed fixed IO bandwidth limits per environment to solve this problem.</p>
<h2 id="autoscaling-and-startup-time-optimization">Autoscaling and startup time optimization<a href="#autoscaling-and-startup-time-optimization"></a></h2>
<p>Our primary goal was to minimize startup time at all costs. Unpredictable wait times can significantly impact productivity and user satisfaction. However, this goal often conflicted with our desire to pack workspaces densely to maximize machine utilization.</p>
<p>We initially thought that running multiple workspaces on one node would help with startup times due to shared caches. However, this didn’t pan out as expected. The reality is that Kubernetes imposes a lower bound for startup time because of all the content operations that need to happen, content needs to be moved into place, which takes time.</p>
<p>Short of keeping workspaces in hot standby (which would be prohibitively expensive), we had to find other ways to optimize startup times.</p>
<h3 id="scaling-ahead-evolution-of-our-approach">Scaling ahead: evolution of our approach<a href="#scaling-ahead-evolution-of-our-approach"></a></h3>
<p><strong>To minimize startup time, we explored various approaches to scale up and ahead:</strong></p>
<ul><li><strong>Ghost workspaces</strong>: Before cluster autoscaler plugins were available, we experimented with “ghost workspaces”. These were preemptible pods that occupied space to scale ahead. We implemented this using a custom scheduler. However, this approach proved to be slow and unreliable to replace.</li>
<li><strong>Ballast pods</strong>: An evolution of the ghost workspace concept, ballast pods filled an entire node. This resulted in less replacement cost and faster replacement times compared to ghost workspaces.</li>
<li><strong>Autoscaler plugins</strong>: In June 2022, we switched to using cluster-autoscaler plugins when they were introduced. With these plugins we no longer needed to “trick” the autoscaler, but could directly affect how scale-up happens. This marked a significant improvement in our scaling strategy.</li></ul>
<h3 id="proportional-autoscaling-for-peak-loads">Proportional autoscaling for peak loads<a href="#proportional-autoscaling-for-peak-loads"></a></h3>
<p>To handle peak loads more effectively, we implemented a proportional autoscaling system. This approach controls the rate of scale-up as a function of the rate of starting development environments. It works by launching empty pods using the pause image, allowing us to quickly increase our capacity in response to demand spikes.</p>
<h3 id="image-pull-optimization-a-tale-of-many-attempts">Image pull optimization: a tale of many attempts<a href="#image-pull-optimization-a-tale-of-many-attempts"></a></h3>
<p>Another crucial aspect of startup time optimization was improving image pull times. Workspace container images (i.e. all the tools available to a developer) can grow to more than 10 gigabytes uncompressed. Downloading and extracting this amount of data for every workspace considerably taxes a node’s resources. We explored numerous strategies to speed up image pulls:</p>
<ul><li><strong>Daemonset pre-pull</strong>: We tried pre-pulling common images using a daemonSet. However, this proved ineffective during scale-up operations because when the node came online, and workspaces were starting, the images still wouldn’t be present on the node. Also, the pre-pulls would now compete for IO and CPU bandwidth with the starting workspaces.</li>
<li><strong>Layer reuse maximization</strong>: We built our own images using a custom builder called <a href="https://github.com/gitpod-io/dazzle" rel="nofollow noopener noreferrer" target="_blank">dazzle</a>, which can build layers independently. This approach aimed to maximize layer reuse. However, we found that layer reuse is very difficult to observe due to the high cardinality and amount of indirections in the <a href="https://github.com/opencontainers/image-spec/blob/main/spec.md" rel="nofollow noopener noreferrer" target="_blank">OCI manifests</a>.</li>
<li><strong>Pre-baked images</strong>: We experimented with baking images into the node disk image. While this improved startup times, it had significant drawbacks. The images quickly became outdated, and this approach didn’t work for self-hosted installations.</li>
<li><strong>Stargazer and lazy-pulling</strong>: This method required all images to be converted, which added complexity, cost, and time to our operations. Additionally, not all registries supported this approach when we tried it in 2022.</li>
<li><strong>Registry-facade + IPFS</strong>: This solution worked well in practice, providing good performance and distribution. We gave a <a href="https://www.youtube.com/watch?v=kS6aDScfVuw" rel="nofollow noopener noreferrer" target="_blank">KubeCon talk about this approach in 2022</a>. However, it introduced significant complexity to our system.</li></ul>
<p>There is no one-size-fits all solution for image caching, but a set of trade-offs with respect to complexity, cost and restrictions imposed on users (images they can use). We have found that homogeneity of workspace images is the most straightforward way to optimize startup times.</p>
<h2 id="networking-complexities">Networking complexities<a href="#networking-complexities"></a></h2>
<p>Networking in Kubernetes introduced its own set of challenges, specifically:</p>
<ul><li><p><strong>Development environment access control</strong>: by default the network of environments needs to be entirely isolated from one another, i.e. one environment cannot reach another. The same is true for the access of a user to the workspace. <a href="https://kubernetes.io/docs/concepts/services-networking/network-policies/" rel="nofollow noopener noreferrer" target="_blank">Network Policies</a> go a long way in ensuring environments are properly disconnected from each other.</p>
<p>Initially we controlled the access to individual environment ports (such as the IDE, or services running in the workspace) using Kubernetes services, together with an ingress proxy that would forward traffic to the service, resolving it using DNS. This quickly became unreliable at scale because of the sheer number of services. Name resolution would fail, and if not careful (e.g. setting enableServiceLinks: false) one can bring entire workspaces down.</p></li>
<li><p><strong>Network bandwidth sharing</strong> on the node is yet another resource that needs to be shared with multiple workspaces on a single node. Some CNIs offer network shaping support (e.g. Cilium’s <a href="https://docs.cilium.io/en/latest/network/kubernetes/bandwidth-manager/" rel="nofollow noopener noreferrer" target="_blank">Bandwidth Manager</a>). This now leaves you with yet another resource to control for, and potentially share between environments.</p></li></ul>
<h2 id="security-and-isolation-balancing-flexibility-and-protection">Security and isolation: balancing flexibility and protection<a href="#security-and-isolation-balancing-flexibility-and-protection"></a></h2>
<p>One of the most significant challenges we faced in our Kubernetes-based infrastructure was providing a secure environment while giving users the flexibility they need for development. Users want the ability to install additional tools (e.g., using apt-get install), run Docker, or even set up a Kubernetes cluster within their development environment. Balancing these requirements with robust security measures proved to be a complex undertaking.</p>
<h3 id="the-naive-approach-root-access">The naive approach: root access<a href="#the-naive-approach-root-access"></a></h3>
<p>The simplest solution would be to give users root access to their containers. However, this approach quickly reveals its flaws:</p>
<ul><li>Giving users root access essentially provides them with root privileges on the node itself, granting access to the development environment platform and other development environments that are running on that node .</li>
<li>This eliminates any meaningful security boundary between users and the host system meaning developers can accidentally, or intentionally interfere and break the development environment platform itself or even access others’ development environments.</li>
<li>It also exposes the infrastructure to potential abuse and security risks. It is then also not possible to implement a true access control model and the architecture falls short of zero-trust. You cannot ensure that a given actor in the system performing an action was verifiably themselves.</li></ul>
<p>Clearly, a more sophisticated approach was needed.</p>
<h3 id="user-namespaces-a-more-nuanced-solution">User namespaces: a more nuanced solution<a href="#user-namespaces-a-more-nuanced-solution"></a></h3>
<p>To address these challenges, we turned to user namespaces, a Linux kernel feature that provides fine-grained control over the mapping of user and group IDs inside containers. This approach allows us to give users “root-like” privileges within their container without compromising the security of the host system.</p>
<p>While Kubernetes introduced support for user namespaces in version 1.25, we had already implemented our own solution starting with Kubernetes 1.22. Our implementation involved several complex components:</p>
<ul><li><p><strong>Filesystem UID shift</strong>: This is necessary to ensure that files created inside the container map correctly to UIDs on the host system. We experimented with several approaches:</p>
<ul><li>We continue to use shiftfs as our primary method for filesystem UID shifting. Despite being deprecated in some contexts, shiftfs still provides the functionality we need with acceptable performance characteristics.</li>
<li>We’ve experimented with fuse-overlayfs, which provided the necessary functionality but had performance limitations.</li>
<li>While idmapped mounts offer potential benefits, we haven’t transitioned to them yet due to various compatibility and implementation considerations.</li></ul></li>
<li><p><strong>Mounting masked proc</strong>: When a container starts, it typically wants to mount /proc. However, in our security model, /proc is sensibly masked to prevent potential security bypasses. Working around this limitation required a tricky solution:</p>
<ul><li>We construct a masked proc filesystem.</li>
<li>This masked proc is then moved into the correct mount namespace.</li>
<li>We implement this using seccomp notify, which allows us to intercept and modify certain system calls.</li></ul></li>
<li><p><strong>FUSE support</strong>: Adding FUSE (Filesystem in Userspace) support, which is crucial for many development workflows, required implementing custom device policies. This involved modifying the container’s eBPF (extended Berkeley Packet Filter) device filter, a low-level programming capability that allows us to make fine-grained decisions about device access.</p></li>
<li><p><strong>Network capabilities</strong>: As true root one holds the CAP_NET_ADMIN and CAP_NET_RAW capabilities which provide far-reaching privileges to configure networking. Container runtimes (such as Docker/runc) make extensive use of these capabilities. Granting such capabilities to the development environment container would interfere with CNI and break the security isolation.</p>
<p>To provide such capabilities we ended up creating another network namespace inside the Kubernetes container, first connected to the outside world using slirp4netns and later using a veth pair and custom and nftables rules.</p></li>
<li><p><strong>Enabling docker</strong>: required some specific hacks for Docker itself. We register a custom <a href="https://github.com/gitpod-io/gitpod/blob/main/components/docker-up/runc-facade/main.go" rel="nofollow noopener noreferrer" target="_blank">runc-facade</a> which modifies the OCI runtime spec produced by Docker. This lets us remove e.g. OOMScoreAdj which still isn’t allowed because that would require CAP_SYS_ADMIN on the node.</p></li></ul>
<p>Implementing this security model came with its own set of challenges:</p>
<ul><li><strong>Performance impact</strong>: Some of our solutions, particularly earlier ones like fuse-overlayfs, had noticeable performance impacts. We’ve continually worked to optimize these.</li>
<li><strong>Compatibility</strong>: Not all tools and workflows are compatible with this restricted environment. We’ve had to carefully balance security with usability.</li>
<li><strong>Complexity</strong>: The resulting system is significantly more complex than a simple containerized environment, which impacts both development and operational overhead.</li>
<li><strong>Keeping up with Kubernetes</strong>: As Kubernetes has evolved, we’ve had to adapt our custom implementations to take advantage of new features while maintaining backwards compatibility.</li></ul>
<h2 id="the-micro-vm-experiment">The micro-VM experiment<a href="#the-micro-vm-experiment"></a></h2>
<p>As we grappled with the challenges of Kubernetes, we began exploring micro-VM (uVM) technologies like <a href="https://github.com/firecracker-microvm/firecracker" rel="nofollow noopener noreferrer" target="_blank">Firecracker</a>, <a href="https://www.cloudhypervisor.org/" rel="nofollow noopener noreferrer" target="_blank">Cloud Hypervisor</a>, and <a href="https://www.qemu.org/" rel="nofollow noopener noreferrer" target="_blank">QEMU</a> as a potential middle ground. This exploration was driven by the promise of improved resource isolation, compatibility with other workloads (e.g. Kubernetes) and security, while potentially maintaining some of the benefits of containerization.</p>
<h3 id="the-promise-of-micro-vms">The promise of micro-VMs<a href="#the-promise-of-micro-vms"></a></h3>
<p>Micro-VMs offered several enticing benefits that aligned well with our goals for cloud development environments:</p>
<ul><li><strong>Enhanced resource isolation</strong>: uVMs promised better resource isolation compared to containers, albeit at the expense of overbooking capabilities. With uVMs, we would no longer have to contend with shared kernel resources, potentially leading to more predictable performance for each development environment.</li>
<li><strong>Memory snapshots and fast resume</strong>: One of the most exciting features, particularly with Firecracker using userfaultfd, was the support for memory snapshots. This technology promised near-instant full machine resume, including running processes. For developers, this could mean significantly faster environment startup times and the ability to pick up exactly where they left off.</li>
<li><strong>Improved security boundaries</strong>: uVMs offered the potential to serve as a robust security boundary, potentially eliminating the need for the complex user namespace mechanisms we had implemented in our Kubernetes setup. This could provide full compatibility with a wider range of workloads, including nested containerization (running Docker or even Kubernetes within the development environment).</li></ul>
<h3 id="challenges-with-micro-vms">Challenges with micro-VMs<a href="#challenges-with-micro-vms"></a></h3>
<p>However, our experiments with micro-VMs revealed several significant challenges:</p>
<ul><li><strong>Overhead</strong>: Even as lightweight VMs, uVMs introduced more overhead than containers. This impacted both performance and resource utilization, key considerations for a cloud development environment platform.</li>
<li><strong>Image conversion</strong>: Converting OCI (Open Container Initiative) images into uVM-consumable filesystems required custom solutions. This added complexity to our image management pipeline and potentially impacted startup times.</li>
<li><strong>Technology-specific limitations</strong>:<ul><li>Firecracker:<ul><li>Lack of GPU support, which is increasingly important for certain development workflows.</li>
<li>No virtiofs support at the time of our experiments (mid 2023), limiting our options for efficient file system sharing.</li></ul></li>
<li>Cloud hypervisor:<ul><li>Slower snapshot and restore processes due to the lack of userfaultfd support, negating one of the key advantages we hoped to gain from uVMs.</li></ul></li></ul></li>
<li><strong>Data movement challenges</strong>: Moving data around became even more challenging with uVMs, as we now had to contend with large memory snapshots. This affected both scheduling and startup times, two critical factors for user experience in cloud development environments.</li>
<li><strong>Storage considerations</strong>: Our experiments with attaching EBS volumes to micro-VMs opened up new possibilities but also raised new questions:<ul><li>Persistent storage: Keeping workspace content on attached volumes reduced the need to pull data from S3 repeatedly, potentially improving startup times and reducing network usage.</li>
<li>Performance considerations: While sharing high-throughput volumes among workspaces showed promise for improving I/O performance, it also raised concerns about implementing effective quotas, managing latency, and ensuring scalability.</li></ul></li></ul>
<h3 id="lessons-from-the-uvm-experiment">Lessons from the uVM experiment<a href="#lessons-from-the-uvm-experiment"></a></h3>
<p>While micro-VMs didn’t ultimately become our primary infrastructure solution, the experiment provided valuable insights:</p>
<ul><li>We loved the experience of full workspace backup and runtime state suspend/resume provided for development environments.</li>
<li>We, for the first time, considered moving away from Kubernetes. The effort to integrate KVM and uVMs into pods had us explore options outside of Kubernetes.</li>
<li>We, once again, identified storage as the crucial element for providing all three: reliable startup performance, reliable workspaces (don’t lose my data) and optimal machine utilization.</li></ul>
<h2 id="kubernetes-is-immensely-challenging-as-a-development-environment-platform">Kubernetes is immensely challenging as a development environment platform<a href="#kubernetes-is-immensely-challenging-as-a-development-environment-platform"></a></h2>
<p>As I mentioned at the beginning, for development environments we need a system that respects the uniquely stateful nature of development environments. We need to give the necessary permissions for developers to be productive, whilst ensuring secure boundaries. And we need to do all of this whilst keeping operational overhead low and not compromising security.</p>
<p>Today, achieving all of the above with Kubernetes is possible—but comes at a significant cost. We learned the difference between application and system workloads the hard way.</p>
<p>Kubernetes is incredible. It’s supported by an engaged and passionate community, which builds a truly rich ecosystem. If you’re running application workloads, Kubernetes continues to be a fine choice. However <strong>for system workloads like development environments Kubernetes presents immense challenges in both security and operational overhead</strong>. Micro-VMs and clear resource budgets help, but make cost a more dominating factor.</p>
<p>So after many years of effectively reverse-engineering and forcing development environments onto the Kubernetes platform we took a step back to think about what we believe a future development architecture needs to look like. In January 2024 we set out to build it. In October, we shipped it: <a href="https://www.gitpod.io/blog/introducing-gitpod-flex" rel="nofollow noopener noreferrer" target="_blank">Gitpod Flex</a>.</p>
<p>More than six years of incredibly hard-won insights for running development environments securely at internet scale went into the architectural foundations.</p>
<h2 id="the-future-of-development-environments">The future of development environments<a href="#the-future-of-development-environments"></a></h2>
<p>In <a href="https://www.gitpod.io/blog/introducing-gitpod-flex" rel="nofollow noopener noreferrer" target="_blank">Gitpod Flex</a> we carried over the foundational aspects of Kubernetes such as the liberal application of control theory and the declarative APIs whilst simplifying the architecture and improving the security foundation.</p>
<p>We orchestrate development environments using a control plane heavily inspired by Kubernetes. We introduced some necessary abstraction layers that are specific to development environments and cast aside much of the infrastructure complexity that we didn’t need—all whilst <a href="https://www.gitpod.io/blog/how-we-built-it-zero-trust-architecture" rel="nofollow noopener noreferrer" target="_blank">putting zero-trust security first</a>.</p>
<p><img src="https://www.gitpod.io/images/blog/we-are-leaving-kubernetes/boundary-diagram.png" alt="Security boundaries of Gitpod Flex" width="1600" height="928" loading="lazy"></p>
<p><strong>Caption:</strong> Security boundaries of Gitpod Flex.</p>
<p>This new architecture allows us to <a href="https://www.gitpod.io/blog/gitpod-supports-development-container" rel="nofollow noopener noreferrer" target="_blank">integrate devcontainer seamlessly</a>. We also unlocked the ability to <a href="https://www.gitpod.io/blog/introducing-gitpod-desktop" rel="nofollow noopener noreferrer" target="_blank">run development environments on your desktop</a>. Now that we’re no longer carrying the heavy weight of the Kubernetes platform, <strong>Gitpod Flex can be deployed self-hosted in less than three minutes</strong> and in any number of regions, giving more fine-grained control on compliance and added flexibility when modeling organizational boundaries and domains.</p>
<p>We’ll be posting a lot more about Gitpod Flex architecture in the coming weeks or months. I’d love to invite you on November the 6th to a virtual event where I’ll be giving a demo of Gitpod Flex and I’ll deep-dive into the architecture and security model at length. You can <a href="https://www.gitpod.io/webinars/gitpod-flex-demo" rel="nofollow noopener noreferrer" target="_blank">sign-up here</a>.</p>
<p>When it comes to building a platform for standardized, automated and secure development environments choose a system because it improves your developer experience, eases your operational burden and improves your bottom line. <strong>You are not choosing Kubernetes vs something else, you are choosing a system because it improves the experience for the teams you support.</strong></p>
<blockquote><div><p><strong>Virtual Event: Gitpod Flex - Deploy your self-hosted CDE in 3 minutes</strong></p><p> &gt; <strong>What?</strong> Deep dive into Gitpod Flex architecture and security. <br> &gt; <strong>When?</strong> November 6th. </p></div>
<p><strong><a href="https://www.gitpod.io/webinars/gitpod-flex-demo" rel="nofollow noopener noreferrer" target="_blank">Register Now →</a></strong></p></blockquote>

	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[New York Times tech workers go on strike (256 pts)]]></title>
            <link>https://www.nytimes.com/2024/11/04/business/media/new-york-times-strike.html</link>
            <guid>42040795</guid>
            <pubDate>Mon, 04 Nov 2024 12:08:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2024/11/04/business/media/new-york-times-strike.html">https://www.nytimes.com/2024/11/04/business/media/new-york-times-strike.html</a>, See on <a href="https://news.ycombinator.com/item?id=42040795">Hacker News</a></p>
Couldn't get https://www.nytimes.com/2024/11/04/business/media/new-york-times-strike.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Cheap Thrills, an album cover by Robert Crumb (2020) (130 pts)]]></title>
            <link>https://musicaficionado.blog/2020/01/28/cheap-thrills-an-album-cover-by-robert-crumb/</link>
            <guid>42039935</guid>
            <pubDate>Mon, 04 Nov 2024 09:35:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://musicaficionado.blog/2020/01/28/cheap-thrills-an-album-cover-by-robert-crumb/">https://musicaficionado.blog/2020/01/28/cheap-thrills-an-album-cover-by-robert-crumb/</a>, See on <a href="https://news.ycombinator.com/item?id=42039935">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-7019">
	
	<section>

<p>A curious tale this, about an artist who draws an album cover for a band he does not care for, playing a music style he does not listen to, appealing to an audience he does not connect with. And to top it, the art selected for the front cover was the one he intended for the back cover. The result: one of the most iconic album covers to come out of the late 1960s. This is the story of Robert Crumb’s cover art for Janis Joplin and Big Brother and the Holding Company’s career-changing album Cheap Thrills.</p>



<figure><img data-recalc-dims="1" fetchpriority="high" decoding="async" width="720" height="724" data-attachment-id="7025" data-permalink="https://musicaficionado.blog/cheap-thrills/" data-orig-file="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Cheap-Thrills.jpg?fit=1990%2C2000&amp;ssl=1" data-orig-size="1990,2000" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Cheap Thrills" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Cheap-Thrills.jpg?fit=300%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Cheap-Thrills.jpg?fit=720%2C724&amp;ssl=1" src="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Cheap-Thrills.jpg?resize=720%2C724&amp;ssl=1" alt="" srcset="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Cheap-Thrills.jpg?resize=1019%2C1024&amp;ssl=1 1019w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Cheap-Thrills.jpg?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Cheap-Thrills.jpg?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Cheap-Thrills.jpg?resize=768%2C772&amp;ssl=1 768w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Cheap-Thrills.jpg?resize=1528%2C1536&amp;ssl=1 1528w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Cheap-Thrills.jpg?resize=120%2C120&amp;ssl=1 120w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Cheap-Thrills.jpg?resize=239%2C240&amp;ssl=1 239w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Cheap-Thrills.jpg?resize=50%2C50&amp;ssl=1 50w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Cheap-Thrills.jpg?w=1990&amp;ssl=1 1990w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Cheap-Thrills.jpg?w=1440&amp;ssl=1 1440w" sizes="(max-width: 720px) 100vw, 720px"></figure>



<span id="more-7019"></span>



<p>The story of this album cover starts in January of 1967,
when Crumb moved to San Francisco. The previous two years were spent soaking in
LSD and travelling between New York, Chicago, and Detroit. The drug was legal
then and an eye opener for many, as he remembers: “At that moment, 1965-1966,
it was very exciting. You got in a subway and you were a person that took LSD.
If there was another person on that subway who has also taken LSD, you
immediately knew who they were, you knew each other. You’d look in their eyes
and you knew and they knew you had. It was like an intimate brotherhood of
people who had seen through the whole thing in some way that most people didn’t
have a clue at all. There was that golden moment.”</p>



<p>During these two years he published the character of Fritz the Cat, the most outrageous feline in history, in various magazines including Help! and Cavalier. Other characters started their life during that period and bloomed after his move to the Hippie capital. They included the mystic guru Mr. Natural, the sex-crazed Mr. Snoid and last but not least, Snoid’s favorite companion Angelfood McSpade, the insatiable African black woman who took stereotyping to new levels.</p>



<figure><img data-recalc-dims="1" decoding="async" width="720" height="930" data-attachment-id="7026" data-permalink="https://musicaficionado.blog/crumb-moves-to-sf/" data-orig-file="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Crumb-moves-to-SF.jpg?fit=1394%2C1800&amp;ssl=1" data-orig-size="1394,1800" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Crumb moves to SF" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Crumb-moves-to-SF.jpg?fit=232%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Crumb-moves-to-SF.jpg?fit=720%2C930&amp;ssl=1" src="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Crumb-moves-to-SF.jpg?resize=720%2C930&amp;ssl=1" alt="" srcset="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Crumb-moves-to-SF.jpg?resize=793%2C1024&amp;ssl=1 793w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Crumb-moves-to-SF.jpg?resize=232%2C300&amp;ssl=1 232w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Crumb-moves-to-SF.jpg?resize=768%2C992&amp;ssl=1 768w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Crumb-moves-to-SF.jpg?resize=1190%2C1536&amp;ssl=1 1190w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Crumb-moves-to-SF.jpg?resize=186%2C240&amp;ssl=1 186w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Crumb-moves-to-SF.jpg?w=1394&amp;ssl=1 1394w" sizes="(max-width: 720px) 100vw, 720px"></figure>



<p>Upon his arrival in San Francisco, Crumb quickly found his way to Haight Ashbury and the Psychedelic Shop and immersed himself in the carefree culture of the town: “San Francisco was a great town at the time, a really beautiful city. After living in Cleveland, Chicago, New York, Philadelphia and Detroit, all these really depressing industrial cities, San Francisco seemed like a sweet little cupcake with Victorian houses and pretty parks.” The town offered him the best environment to indulge in the things that most interested him: drawing wild comics and taking acid. Oh, and of course, sex. </p>



<figure><img data-recalc-dims="1" decoding="async" width="720" height="566" data-attachment-id="7035" data-permalink="https://musicaficionado.blog/2020/01/28/cheap-thrills-an-album-cover-by-robert-crumb/psychedelic-shop/" data-orig-file="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Psychedelic-Shop.jpg?fit=1226%2C964&amp;ssl=1" data-orig-size="1226,964" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Psychedelic Shop" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Psychedelic-Shop.jpg?fit=300%2C236&amp;ssl=1" data-large-file="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Psychedelic-Shop.jpg?fit=720%2C566&amp;ssl=1" src="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Psychedelic-Shop.jpg?resize=720%2C566&amp;ssl=1" alt="" srcset="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Psychedelic-Shop.jpg?resize=1024%2C805&amp;ssl=1 1024w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Psychedelic-Shop.jpg?resize=300%2C236&amp;ssl=1 300w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Psychedelic-Shop.jpg?resize=768%2C604&amp;ssl=1 768w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Psychedelic-Shop.jpg?resize=305%2C240&amp;ssl=1 305w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Psychedelic-Shop.jpg?w=1226&amp;ssl=1 1226w" sizes="(max-width: 720px) 100vw, 720px"></figure>



<p>Talking about LSD and its impact on the counter-culture, Crumb said: “LSD was the road to Damascus for the hippies. It turned the left wing serious political anti-war movement into something religious and visionary. It was no longer political, folk music, help the Negros, fight the war and all that. It became mystical, saving the earth, the preciousness of nature, living close to nature. Much more radical and extreme.” He was drawing all that time, adapting old cartoon styles to the hippie hallucinogen vision, slowly picking up interest and recognition. After contributing his work to various underground magazines, he was invited to create a full comic magazine named Zap. The first issue featured his favorite Mr. Natural on the cover.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="720" height="1009" data-attachment-id="7038" data-permalink="https://musicaficionado.blog/2020/01/28/cheap-thrills-an-album-cover-by-robert-crumb/zap-vol-1/" data-orig-file="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Zap-Vol-1.jpg?fit=1000%2C1401&amp;ssl=1" data-orig-size="1000,1401" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Zap Vol 1" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Zap-Vol-1.jpg?fit=214%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Zap-Vol-1.jpg?fit=720%2C1009&amp;ssl=1" src="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Zap-Vol-1.jpg?resize=720%2C1009&amp;ssl=1" alt="" srcset="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Zap-Vol-1.jpg?resize=731%2C1024&amp;ssl=1 731w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Zap-Vol-1.jpg?resize=214%2C300&amp;ssl=1 214w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Zap-Vol-1.jpg?resize=768%2C1076&amp;ssl=1 768w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Zap-Vol-1.jpg?resize=171%2C240&amp;ssl=1 171w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Zap-Vol-1.jpg?w=1000&amp;ssl=1 1000w" sizes="(max-width: 720px) 100vw, 720px"></figure>



<p>The publication of Zap Magazine provided exposure but no income and Crumb was nearly penniless. Copies of the first issue were printed, folded and stapled by Crumb and sold on the street at Haight-Ashbury for 25 cents a copy. Proprietors of stores in that hip area did not get what’s with these comic books he was offering them. They stocked psychedelic art nouveau concert posters, incense, pipes, bongs, candles, not comic books that looked like Popeye on the cover. But within six months Zap comics caught on and Crumb became known for his talent as an underground comics artist. None describes the world of Crumb better than Crumb: “My comics appealed to the hard-drinking, hard-fucking end of the hippie spectrum as opposed to the spiritual, Eastern-religious, lighter-than-air type hippie.” Still, monetary rewards were not forthcoming from hippie stardom. He wrote in a letter in June 1968: “What good has fame done me? I’m broke and girls still act aloof. Time has come for a change! Bwah howdy!” In that same letter, addressed to his friend Mike Britt, he mentions an important meeting, contrasting it with the sad affair of his monogamous relationship: “I am going over to meet Janis Joplin tonight… CAN’T WAIT! Which brings me to another important point, which is my sex life has been sliding downhill lately so I’m trying to do something about that! The only girl I’m making it with is my wife, and getting’ tired of just her all the time.” Words that would send chills down conservative Americans’ spines, but we are at the center of the hippie galaxy in 1968, the time and place where anything goes. Was Janis his salvation from bedroom boredom? Lets stick with the topic of this article and assume that she was just asking him to draw the cover of her band’s second album, which is exactly what happened.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="677" height="1024" data-attachment-id="7030" data-permalink="https://musicaficionado.blog/2020/01/28/cheap-thrills-an-album-cover-by-robert-crumb/janis-joplin-1968/" data-orig-file="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Janis-Joplin-1968.jpg?fit=736%2C1114&amp;ssl=1" data-orig-size="736,1114" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Janis Joplin 1968" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Janis-Joplin-1968.jpg?fit=198%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Janis-Joplin-1968.jpg?fit=677%2C1024&amp;ssl=1" src="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Janis-Joplin-1968.jpg?resize=677%2C1024&amp;ssl=1" alt="" srcset="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Janis-Joplin-1968.jpg?resize=677%2C1024&amp;ssl=1 677w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Janis-Joplin-1968.jpg?resize=198%2C300&amp;ssl=1 198w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Janis-Joplin-1968.jpg?resize=159%2C240&amp;ssl=1 159w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Janis-Joplin-1968.jpg?w=736&amp;ssl=1 736w" sizes="(max-width: 677px) 100vw, 677px"><figcaption>Janis Joplin, 1968</figcaption></figure>



<p>Crumb had no patience for much of the music surrounding him in San Francisco or elsewhere in the late 1960s. This is blasphemy for anyone (myself included) who cares about all the great music created in those days, the golden age of rock and psychedelic music. But Crumb came from another era, mentally, and to him this music was commercialism personified compared to the roots music from the 1920s and 1930s that moved him: “I had no patience for any of that psychedelic pop music or crap that came in the 60s: The Grateful Dead, Jim Morrison, The Doors, The Beatles, Bob Dylan. I had little or no interest in any of that. I thought I had found some music that was much more real, that came from the heart of people’s culture but had been wiped out by mass media and commercialism.”</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="658" height="980" data-attachment-id="7037" data-permalink="https://musicaficionado.blog/2020/01/28/cheap-thrills-an-album-cover-by-robert-crumb/robert-crumb-1969/" data-orig-file="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Robert-Crumb-1969.jpg?fit=658%2C980&amp;ssl=1" data-orig-size="658,980" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Robert Crumb 1969" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Robert-Crumb-1969.jpg?fit=201%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Robert-Crumb-1969.jpg?fit=658%2C980&amp;ssl=1" src="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Robert-Crumb-1969.jpg?resize=658%2C980&amp;ssl=1" alt="" srcset="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Robert-Crumb-1969.jpg?w=658&amp;ssl=1 658w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Robert-Crumb-1969.jpg?resize=201%2C300&amp;ssl=1 201w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Robert-Crumb-1969.jpg?resize=161%2C240&amp;ssl=1 161w" sizes="(max-width: 658px) 100vw, 658px"><figcaption>Robert Crumb, 1969</figcaption></figure>



<p>But Crumb made an exception with Janis Joplin, connecting with her for their mutual love of old Blues music: “She wasn’t nationally known yet. I remember going to see her at the Avalon Ballroom and you could tell right away that she had an exceptional voice and she would go far. She started out singing old time blues like Bessie Smith. She was kind of a folknik originally.“ While he did not care for her current band and the psychedelic spin they took on blues, he recognized her ability to belt out the good ol’ blues: “Janis had played with earlier bands just playing country blues and it was much better. Way, way better. She’s singing well, not screaming, not playing to the audience that wanted to watch her sweat blood. In the beginning she was just an authentic, genuine Texas country-girl shouter.”</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="720" height="719" data-attachment-id="7032" data-permalink="https://musicaficionado.blog/2020/01/28/cheap-thrills-an-album-cover-by-robert-crumb/janis-joplin-san-francisco-1966/" data-orig-file="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Janis-Joplin-San-Francisco-1966.jpg?fit=960%2C959&amp;ssl=1" data-orig-size="960,959" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Janis Joplin, San Francisco 1966" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Janis-Joplin-San-Francisco-1966.jpg?fit=300%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Janis-Joplin-San-Francisco-1966.jpg?fit=720%2C719&amp;ssl=1" src="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Janis-Joplin-San-Francisco-1966.jpg?resize=720%2C719&amp;ssl=1" alt="" srcset="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Janis-Joplin-San-Francisco-1966.jpg?w=960&amp;ssl=1 960w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Janis-Joplin-San-Francisco-1966.jpg?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Janis-Joplin-San-Francisco-1966.jpg?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Janis-Joplin-San-Francisco-1966.jpg?resize=768%2C767&amp;ssl=1 768w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Janis-Joplin-San-Francisco-1966.jpg?resize=120%2C120&amp;ssl=1 120w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Janis-Joplin-San-Francisco-1966.jpg?resize=500%2C500&amp;ssl=1 500w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Janis-Joplin-San-Francisco-1966.jpg?resize=320%2C320&amp;ssl=1 320w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Janis-Joplin-San-Francisco-1966.jpg?resize=240%2C240&amp;ssl=1 240w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Janis-Joplin-San-Francisco-1966.jpg?resize=50%2C50&amp;ssl=1 50w" sizes="(max-width: 720px) 100vw, 720px"><figcaption>Janis Joplin, San Francisco 1966</figcaption></figure>



<p>Crumb was not the first choice for Big Brother and the Holding Company’s album cover. The band, which rose to meteoric success immediately after their milestone performance at the Monterey Pop Festival in the summer of 1967, was quickly signed to Columbia Records who wanted an album quick to cash in on the emerging flower power market. The original title for the band’s first album for Columbia was Sex, Dope and Cheap Thrills, a fair summary of the band’s credo. That, of course, did not fly with the suits at Columbia who nixed the blunt Sex and Dope and left only the vague Cheap Thrills. When it came time for the album cover, the band’s idea was to go with an expected band photo, with a minor twist of taking the photo in their birthday suits. The result proved unsatisfactory, and another no-no for the suits who make the decisions. </p>



<p>The idea of going with a standard band photograph was not
abandoned yet, as Drummer Dave Getz remembers: “Then Bob Cato, CBS’s art
director, thought we should do a photo session with Richard Avedon, perhaps the
most famous fashion photographer in the world. Avedon did his ‘Avedon thing’ on
us; the fan blowing our hair, the strobe lights flashing, white background,
random rearrangement of our faces. It was another huge and costly miss. The
photos were good but more about Avedon than us.”</p>



<figure data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/musicaficionado.blog\/2020\/01\/28\/cheap-thrills-an-album-cover-by-robert-crumb\/&quot;}"><ul><li><figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="225" height="224" data-attachment-id="7021" data-permalink="https://musicaficionado.blog/avedon-joplin2/" data-orig-file="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Avedon-Joplin2.jpg?fit=225%2C224&amp;ssl=1" data-orig-size="225,224" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Avedon Joplin2" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Avedon-Joplin2.jpg?fit=225%2C224&amp;ssl=1" data-large-file="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Avedon-Joplin2.jpg?fit=225%2C224&amp;ssl=1" src="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Avedon-Joplin2.jpg?resize=225%2C224&amp;ssl=1" data-id="7021" data-full-url="https://musicaficionado.blog/wp-content/uploads/2019/12/Avedon-Joplin2.jpg" srcset="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Avedon-Joplin2.jpg?w=225&amp;ssl=1 225w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Avedon-Joplin2.jpg?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Avedon-Joplin2.jpg?resize=120%2C120&amp;ssl=1 120w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Avedon-Joplin2.jpg?resize=50%2C50&amp;ssl=1 50w" sizes="(max-width: 225px) 100vw, 225px"></figure></li><li><figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="226" height="223" data-attachment-id="7020" data-permalink="https://musicaficionado.blog/avedon-joplin1/" data-orig-file="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Avedon-Joplin1.jpg?fit=226%2C223&amp;ssl=1" data-orig-size="226,223" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Avedon Joplin1" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Avedon-Joplin1.jpg?fit=226%2C223&amp;ssl=1" data-large-file="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Avedon-Joplin1.jpg?fit=226%2C223&amp;ssl=1" src="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Avedon-Joplin1.jpg?resize=226%2C223&amp;ssl=1" data-id="7020" data-full-url="https://musicaficionado.blog/wp-content/uploads/2019/12/Avedon-Joplin1.jpg" srcset="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Avedon-Joplin1.jpg?w=226&amp;ssl=1 226w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Avedon-Joplin1.jpg?resize=50%2C50&amp;ssl=1 50w" sizes="(max-width: 226px) 100vw, 226px"></figure></li></ul><figcaption>Big Brother and the Holding Company, by Richard Avedon</figcaption></figure>



<p>What’s a band to do now? Enter Crumb the Sex, Dope and Cheap Thrills universe. Drummer Dave Getz recalls the moment the idea of asking Crumb to do the cover came up: “We had a huge loft/warehouse in SF where we rehearsed and I lived. I remember us all sitting around and talking ideas for the cover and I said ‘How about asking R.Crumb?’&nbsp; Janis, James (Gurley, guitar player) and I were all big fans of his work, we loved his cartoons which were appearing in the SF underground newspapers and Zap Comics. But outside of SF not that many people knew of his genius.” Through a mutual friend they got Crumb’s number and Janis called him. Crumb continues the tale: “Janis asked me to do an album cover. I liked Janis OK and I did her cover. I took speed and did an all-nighter. The front cover I designed wasn’t used at all. They used the back cover for the front. I got paid $600. The album cover impressed the hell out of girls much more so than the comics. I got a lot of mileage out of that over the years!” Getz adds: “The next weekend Crumb came to our show at The Carousel Ballroom, sat on the floor in our backstage dressing room and observed. He really wasn’t into our music but it didn’t matter. It was maybe one or two days later Crumb called Janis to come and pick up what he’d done.”</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="720" height="719" data-attachment-id="7031" data-permalink="https://musicaficionado.blog/2020/01/28/cheap-thrills-an-album-cover-by-robert-crumb/janis-joplin-by-crumb/" data-orig-file="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Janis-Joplin-by-Crumb.jpg?fit=1024%2C1022&amp;ssl=1" data-orig-size="1024,1022" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Janis Joplin by Crumb" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Janis-Joplin-by-Crumb.jpg?fit=300%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Janis-Joplin-by-Crumb.jpg?fit=720%2C719&amp;ssl=1" src="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Janis-Joplin-by-Crumb.jpg?resize=720%2C719&amp;ssl=1" alt="" srcset="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Janis-Joplin-by-Crumb.jpg?w=1024&amp;ssl=1 1024w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Janis-Joplin-by-Crumb.jpg?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Janis-Joplin-by-Crumb.jpg?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Janis-Joplin-by-Crumb.jpg?resize=768%2C767&amp;ssl=1 768w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Janis-Joplin-by-Crumb.jpg?resize=120%2C120&amp;ssl=1 120w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Janis-Joplin-by-Crumb.jpg?resize=500%2C500&amp;ssl=1 500w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Janis-Joplin-by-Crumb.jpg?resize=320%2C320&amp;ssl=1 320w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Janis-Joplin-by-Crumb.jpg?resize=240%2C240&amp;ssl=1 240w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Janis-Joplin-by-Crumb.jpg?resize=50%2C50&amp;ssl=1 50w" sizes="(max-width: 720px) 100vw, 720px"><figcaption>Janis Joplin, by Richard Crumb</figcaption></figure>



<p>Getz is understandably mild in his description of Crumb’s opinion of Big Brother and the Holding Company. Here is Crumb’s version, unadulterated: “She was a swell gal and a very talented singer. Ever heard any of this pre-Big Brother stuff she recorded? She was great. Then she got together with those idiots. The main problem with Big Brother was they were amateur musicians trying to play psychedelic rock and be heavy and you listen to it now and it’s bad… just embarrassing.” Agree with him or not, this is Crumb. Gotta love his candid way of describing things in words and images.</p>



<p>Back to that cover. Crumb’s original idea for the front
cover was a cartoon of the band performing on stage with the band’s faces
pasted on them. The band was less than overwhelmed by this, but then they
looked at what Crumb delivered for the back cover and they saw the light. A
comic strip with a panel for each of the songs plus band members credits. They
immediately decided to make it the front cover and forever cemented the iconic
status of that comic strip among album covers.</p>



<figure><img data-recalc-dims="1" fetchpriority="high" decoding="async" width="720" height="724" data-attachment-id="7025" data-permalink="https://musicaficionado.blog/cheap-thrills/" data-orig-file="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Cheap-Thrills.jpg?fit=1990%2C2000&amp;ssl=1" data-orig-size="1990,2000" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Cheap Thrills" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Cheap-Thrills.jpg?fit=300%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Cheap-Thrills.jpg?fit=720%2C724&amp;ssl=1" src="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Cheap-Thrills.jpg?resize=720%2C724&amp;ssl=1" alt="" srcset="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Cheap-Thrills.jpg?resize=1019%2C1024&amp;ssl=1 1019w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Cheap-Thrills.jpg?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Cheap-Thrills.jpg?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Cheap-Thrills.jpg?resize=768%2C772&amp;ssl=1 768w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Cheap-Thrills.jpg?resize=1528%2C1536&amp;ssl=1 1528w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Cheap-Thrills.jpg?resize=120%2C120&amp;ssl=1 120w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Cheap-Thrills.jpg?resize=239%2C240&amp;ssl=1 239w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Cheap-Thrills.jpg?resize=50%2C50&amp;ssl=1 50w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Cheap-Thrills.jpg?w=1990&amp;ssl=1 1990w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Cheap-Thrills.jpg?w=1440&amp;ssl=1 1440w" sizes="(max-width: 720px) 100vw, 720px"></figure>



<p>Lets give the band some and listen to a few tunes from that album, while looking at the comic panels related to them. </p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="720" height="340" data-attachment-id="7024" data-permalink="https://musicaficionado.blog/cheap-thrills-close-up/" data-orig-file="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Cheap-Thrills-close-up.png?fit=1692%2C799&amp;ssl=1" data-orig-size="1692,799" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Cheap Thrills close up" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Cheap-Thrills-close-up.png?fit=300%2C142&amp;ssl=1" data-large-file="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Cheap-Thrills-close-up.png?fit=720%2C340&amp;ssl=1" src="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Cheap-Thrills-close-up.png?resize=720%2C340&amp;ssl=1" alt="" srcset="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Cheap-Thrills-close-up.png?resize=1024%2C484&amp;ssl=1 1024w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Cheap-Thrills-close-up.png?resize=300%2C142&amp;ssl=1 300w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Cheap-Thrills-close-up.png?resize=768%2C363&amp;ssl=1 768w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Cheap-Thrills-close-up.png?resize=1536%2C725&amp;ssl=1 1536w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Cheap-Thrills-close-up.png?resize=508%2C240&amp;ssl=1 508w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Cheap-Thrills-close-up.png?w=1692&amp;ssl=1 1692w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Cheap-Thrills-close-up.png?w=1440&amp;ssl=1 1440w" sizes="(max-width: 720px) 100vw, 720px"></figure>



<p>We begin with I Need A Man To Love, a blues-rock number that Crumb adorned with his idea of a well-endowed woman (Janis) stretched on a bed, looking in need, of a man.</p>



<figure><p>
<iframe loading="lazy" title="I Need a Man to Love" width="720" height="540" src="https://www.youtube.com/embed/rd3pCS4fkFA?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<p>Next is the band’s fantastic cover of Summertime, George Gershwin’s song from the 1935 opera Porgy and Bess. The song has been covered many times in operatic and jazz renditions, but here it takes a completely different spin with a wonderful arrangement and solo by the band’s guitarist Sam Andrew. As for Crumb’s depiction of that scene from the musical, lets not even go there. Suffice it to say that a cover like that will not see the light of day today.</p>



<figure><p>
<iframe loading="lazy" title="Big Brother &amp; The Holding Company, Janis Joplin - Summertime (Audio)" width="720" height="405" src="https://www.youtube.com/embed/A24JZkgvNv4?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<p>And one more, the song that put the band and Janis Joplin on the map at the Monterey Pop Festival, Big Mama Thornton’s Ball and Chain. The song closes the album with a bang with one of the dirtiest guitar sounds committed to vinyl and a vocal performance for the ages.</p>



<figure><p>
<iframe loading="lazy" title="Big Brother &amp; The Holding Company, Janis Joplin - Ball and Chain (Audio)" width="720" height="405" src="https://www.youtube.com/embed/mrF_nM9pknU?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="720" height="720" data-attachment-id="7022" data-permalink="https://musicaficionado.blog/ball-and-chain/" data-orig-file="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Ball-and-Chain.png?fit=738%2C738&amp;ssl=1" data-orig-size="738,738" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Ball and Chain" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Ball-and-Chain.png?fit=300%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Ball-and-Chain.png?fit=720%2C720&amp;ssl=1" src="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Ball-and-Chain.png?resize=720%2C720&amp;ssl=1" alt="" srcset="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Ball-and-Chain.png?w=738&amp;ssl=1 738w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Ball-and-Chain.png?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Ball-and-Chain.png?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Ball-and-Chain.png?resize=120%2C120&amp;ssl=1 120w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Ball-and-Chain.png?resize=500%2C500&amp;ssl=1 500w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Ball-and-Chain.png?resize=320%2C320&amp;ssl=1 320w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Ball-and-Chain.png?resize=240%2C240&amp;ssl=1 240w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Ball-and-Chain.png?resize=50%2C50&amp;ssl=1 50w" sizes="(max-width: 720px) 100vw, 720px"></figure>



<p>Cheap Thrills was released in August of 1968, steadily climbing the Billboard LPs chart until it reached the top and stayed there 8 consecutive weeks. When Janis Joplin announced during a show at the Fillmore East in the fall of 1968 that their album cover was the work of R.Crumb, they received the biggest standing ovation of the night. Crumb was a hero for the hippies, but by that point he was on a very different wavelength. He liked some aspects of the Hippie movement, what he termed as seeing through the hype of consumer culture. He valued how they strived to live simply and saw the ecology movement being sparked by that. But he quickly became disillusioned by the movement: “Since it was mostly children of the middle class, it was immediately something for them to be smug about. ’Oh, I have seen the light and you haven’t. I’m beautiful, I’m spiritual. I lost my ego and you haven’t.’ It became where in any social gathering everybody sat around trying to out-cool each other.” But as he admits, he never felt comfortable in that environment anyway, even when it was at its peak of innocence: “I couldn’t kick off my shows and go dance in the park. I didn’t have it in me.” </p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="677" height="610" data-attachment-id="7023" data-permalink="https://musicaficionado.blog/billboard-top-lps-november-1968/" data-orig-file="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Billboard-top-LPs-November-1968.png?fit=677%2C610&amp;ssl=1" data-orig-size="677,610" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Billboard top LPs November 1968" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Billboard-top-LPs-November-1968.png?fit=300%2C270&amp;ssl=1" data-large-file="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Billboard-top-LPs-November-1968.png?fit=677%2C610&amp;ssl=1" src="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Billboard-top-LPs-November-1968.png?resize=677%2C610&amp;ssl=1" alt="" srcset="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Billboard-top-LPs-November-1968.png?w=677&amp;ssl=1 677w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Billboard-top-LPs-November-1968.png?resize=300%2C270&amp;ssl=1 300w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Billboard-top-LPs-November-1968.png?resize=266%2C240&amp;ssl=1 266w" sizes="(max-width: 677px) 100vw, 677px"></figure>



<p>In November of 1968, when the album peaked at the top of the
LP charts, the top 10 albums also included Electric Ladyland and Are You Experienced
by the Jimi Hendrix Experience, The Time Has Come by The Chambers Brothers,
Crown of Creation by Jefferson Airplane, The Crazy World of Arthur Brown and
Wheels of Fire by Cream. This was the golden age of psychedelic music. Crumb
was inside the bubble physically, but not mentally.</p>



<p>I want to spend the last part of this article discussing the
music Crumb DID like, for which he produced many album covers and portraits of
musicians, all of them wonderful articles of art. None of them as remotely well
known as Cheap Thrills, however by all means worth looking at.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="720" height="720" data-attachment-id="7028" data-permalink="https://musicaficionado.blog/harmonica-blues/" data-orig-file="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Harmonica-Blues.jpg?fit=2522%2C2524&amp;ssl=1" data-orig-size="2522,2524" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;HA.com&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Harmonica Blues" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Harmonica-Blues.jpg?fit=300%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Harmonica-Blues.jpg?fit=720%2C720&amp;ssl=1" src="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Harmonica-Blues.jpg?resize=720%2C720&amp;ssl=1" alt="" srcset="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Harmonica-Blues.jpg?resize=1024%2C1024&amp;ssl=1 1024w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Harmonica-Blues.jpg?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Harmonica-Blues.jpg?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Harmonica-Blues.jpg?resize=768%2C769&amp;ssl=1 768w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Harmonica-Blues.jpg?resize=1536%2C1536&amp;ssl=1 1536w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Harmonica-Blues.jpg?resize=2046%2C2048&amp;ssl=1 2046w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Harmonica-Blues.jpg?resize=120%2C120&amp;ssl=1 120w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Harmonica-Blues.jpg?resize=500%2C500&amp;ssl=1 500w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Harmonica-Blues.jpg?resize=320%2C320&amp;ssl=1 320w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Harmonica-Blues.jpg?resize=240%2C240&amp;ssl=1 240w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Harmonica-Blues.jpg?resize=50%2C50&amp;ssl=1 50w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Harmonica-Blues.jpg?w=1440&amp;ssl=1 1440w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Harmonica-Blues.jpg?w=2160&amp;ssl=1 2160w" sizes="(max-width: 720px) 100vw, 720px"></figure>



<p>Crumb owns a large collection of old 78 albums. He talked elaborately about his passion for the music he loves, and the moment he started collecting music: “I always liked the kind of music you’d hear in the background of old movies from the early ‘30s, the early sound movies and cartoons. And then in my searching for old books and comic books, these junk stores had these old 78 records. One day, out of curiosity, I bought some of these records. They were very cheap. I put the records on and voila! ‘Oh my god, that’s the music, that’s the music from these old movies, that’s incredible.’ I was sixteen and I remember very clearly the day that I discovered that you could find those records. They were lying around everywhere in those days, in 1959.”</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="720" height="948" data-attachment-id="7027" data-permalink="https://musicaficionado.blog/crumb-robertjohnson/" data-orig-file="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/crumb-robertjohnson.jpg?fit=988%2C1300&amp;ssl=1" data-orig-size="988,1300" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="crumb-robertjohnson" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/crumb-robertjohnson.jpg?fit=228%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/crumb-robertjohnson.jpg?fit=720%2C948&amp;ssl=1" src="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/crumb-robertjohnson.jpg?resize=720%2C948&amp;ssl=1" alt="" srcset="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/crumb-robertjohnson.jpg?resize=778%2C1024&amp;ssl=1 778w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/crumb-robertjohnson.jpg?resize=228%2C300&amp;ssl=1 228w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/crumb-robertjohnson.jpg?resize=768%2C1011&amp;ssl=1 768w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/crumb-robertjohnson.jpg?resize=182%2C240&amp;ssl=1 182w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/crumb-robertjohnson.jpg?w=988&amp;ssl=1 988w" sizes="(max-width: 720px) 100vw, 720px"></figure>



<p>In his teens Crumb was exposed to 1950s pop music, which he describes as something he had to suffer through, singers like Frank Sinatra, Perry Como, Doris Day. He had a period of reprieve with the advent of rock n roll, Elvis Presley and Little Richard: “There was some feeling of blues and old time country in that early rock and roll, it was coming out of really low life in the South. Those people all came from the lowest rung of society.” That period did not last long for him, as it was quickly commercialized for middle class consumption, and he stack with old black blues and folk music ever since.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="720" height="720" data-attachment-id="7034" data-permalink="https://musicaficionado.blog/2020/01/28/cheap-thrills-an-album-cover-by-robert-crumb/louie-bluie/" data-orig-file="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Louie-Bluie.jpg?fit=1200%2C1200&amp;ssl=1" data-orig-size="1200,1200" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Louie Bluie" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Louie-Bluie.jpg?fit=300%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Louie-Bluie.jpg?fit=720%2C720&amp;ssl=1" src="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Louie-Bluie.jpg?resize=720%2C720&amp;ssl=1" alt="" srcset="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Louie-Bluie.jpg?resize=1024%2C1024&amp;ssl=1 1024w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Louie-Bluie.jpg?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Louie-Bluie.jpg?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Louie-Bluie.jpg?resize=768%2C768&amp;ssl=1 768w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Louie-Bluie.jpg?resize=120%2C120&amp;ssl=1 120w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Louie-Bluie.jpg?resize=500%2C500&amp;ssl=1 500w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Louie-Bluie.jpg?resize=320%2C320&amp;ssl=1 320w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Louie-Bluie.jpg?resize=240%2C240&amp;ssl=1 240w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Louie-Bluie.jpg?resize=50%2C50&amp;ssl=1 50w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Louie-Bluie.jpg?w=1200&amp;ssl=1 1200w" sizes="(max-width: 720px) 100vw, 720px"></figure>



<p>Asked about how a white guy connects so deeply with black music created in the 1930s, he answered: “I don’t know. There’s something so raw, kind of beauty that speaks to me in a deep and direct way. Personally I barely even know any black people and I can’t relate to lower class black culture very well at all. It’s very alien to me in a certain way, and people I’ve known from that black culture, I’ve never been able to get very close to, because their values are so different. So what is it about their music that speaks so directly? It has some universal appeal because it has had such a big influence on the music of the entire world.”</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="720" height="953" data-attachment-id="7033" data-permalink="https://musicaficionado.blog/2020/01/28/cheap-thrills-an-album-cover-by-robert-crumb/lightnin-hopkins/" data-orig-file="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Lightnin-Hopkins.jpg?fit=774%2C1024&amp;ssl=1" data-orig-size="774,1024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Lightnin Hopkins" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Lightnin-Hopkins.jpg?fit=227%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Lightnin-Hopkins.jpg?fit=720%2C953&amp;ssl=1" src="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Lightnin-Hopkins.jpg?resize=720%2C953&amp;ssl=1" alt="" srcset="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Lightnin-Hopkins.jpg?w=774&amp;ssl=1 774w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Lightnin-Hopkins.jpg?resize=227%2C300&amp;ssl=1 227w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Lightnin-Hopkins.jpg?resize=768%2C1016&amp;ssl=1 768w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/Lightnin-Hopkins.jpg?resize=181%2C240&amp;ssl=1 181w" sizes="(max-width: 720px) 100vw, 720px"></figure>



<p>What a better way to close this article about Crumb and his contributions as an artist to the music world, then mention the stint he had in the mid 1970s as a musician himself. After settling down in Madison, California, Crumb started playing banjo and mandolin in the Cheap Suit Serenaders Band: “They were my pals for years. We sat around playing music together and somebody said we could play a job for $100, so we agreed. It was interesting for a while, but I came to the point where I realized I had to quit. I asked myself ‘Do I want to get more deeply involved in this music business?’ and I really didn’t.”</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="720" height="720" data-attachment-id="7036" data-permalink="https://musicaficionado.blog/2020/01/28/cheap-thrills-an-album-cover-by-robert-crumb/r-crumb-and-his-cheap-suite-serenaders/" data-orig-file="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/R-Crumb-and-his-Cheap-Suite-Serenaders.jpg?fit=1080%2C1080&amp;ssl=1" data-orig-size="1080,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="R Crumb and his Cheap Suite Serenaders" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/R-Crumb-and-his-Cheap-Suite-Serenaders.jpg?fit=300%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/R-Crumb-and-his-Cheap-Suite-Serenaders.jpg?fit=720%2C720&amp;ssl=1" src="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/R-Crumb-and-his-Cheap-Suite-Serenaders.jpg?resize=720%2C720&amp;ssl=1" alt="" srcset="https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/R-Crumb-and-his-Cheap-Suite-Serenaders.jpg?resize=1024%2C1024&amp;ssl=1 1024w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/R-Crumb-and-his-Cheap-Suite-Serenaders.jpg?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/R-Crumb-and-his-Cheap-Suite-Serenaders.jpg?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/R-Crumb-and-his-Cheap-Suite-Serenaders.jpg?resize=768%2C768&amp;ssl=1 768w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/R-Crumb-and-his-Cheap-Suite-Serenaders.jpg?resize=120%2C120&amp;ssl=1 120w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/R-Crumb-and-his-Cheap-Suite-Serenaders.jpg?resize=500%2C500&amp;ssl=1 500w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/R-Crumb-and-his-Cheap-Suite-Serenaders.jpg?resize=320%2C320&amp;ssl=1 320w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/R-Crumb-and-his-Cheap-Suite-Serenaders.jpg?resize=240%2C240&amp;ssl=1 240w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/R-Crumb-and-his-Cheap-Suite-Serenaders.jpg?resize=50%2C50&amp;ssl=1 50w, https://i0.wp.com/musicaficionado.blog/wp-content/uploads/2019/12/R-Crumb-and-his-Cheap-Suite-Serenaders.jpg?w=1080&amp;ssl=1 1080w" sizes="(max-width: 720px) 100vw, 720px"></figure>



<hr>



<p>If you enjoyed reading this article, you may also like this one about another great album art coming out of San Francisco in the late 1960s:</p>



<figure></figure>


<div>
	
	<hr>
	

	
	<h3>Discover more from The Music Aficionado</h3>
	

	
	<p>Subscribe to get the latest posts sent to your email.</p>
	

	
	
	
</div>
			</section>
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Quincy Jones has died (150 pts)]]></title>
            <link>https://apnews.com/article/quincy-jones-dead-a9e31c7e39c448d8971519f47a22dd21</link>
            <guid>42039569</guid>
            <pubDate>Mon, 04 Nov 2024 08:13:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://apnews.com/article/quincy-jones-dead-a9e31c7e39c448d8971519f47a22dd21">https://apnews.com/article/quincy-jones-dead-a9e31c7e39c448d8971519f47a22dd21</a>, See on <a href="https://news.ycombinator.com/item?id=42039569">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                                        <p><span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/hub/quincy-jones">Quincy Jones</a></span>, the multitalented <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/quincy-jones-state-department-global-music-diplomacy-ad771f888c9b91c0991a583d09f77e24">music titan</a></span> whose vast legacy ranged from producing Michael Jackson’s historic “Thriller” album to writing prize-winning film and television scores and collaborating with Frank Sinatra, Ray Charles and hundreds of other recording artists, has died at 91. </p><p>Jones’ publicist, Arnold Robinson, says he died Sunday night at his home in the Bel Air section of Los Angeles, surrounded by his family. Jones was to have received an <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/oscars-governor-awards-quincy-jones-bc6906d90d975870b3405f149699d910">honorary Academy Award</a></span> later this month.</p><div data-align-center="">
                    <figure>
    
    <a id="image-290000"></a>


    
        <picture data-crop="imgEn-medium-nocrop">
    
        <source media="(min-width: 768px)" type="image/webp" width="800" height="618" srcset="https://dims.apnews.com/dims4/default/53d4889/2147483647/strip/true/crop/2590x2002+0+0/resize/800x618!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F57%2F83%2Fc38a42a2fe6203ad6d06edddb112%2Fe5a8eba0530a4ef48ec1ad592db0bf43 1x,https://dims.apnews.com/dims4/default/3bf49b8/2147483647/strip/true/crop/2590x2002+0+0/resize/1600x1236!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F57%2F83%2Fc38a42a2fe6203ad6d06edddb112%2Fe5a8eba0530a4ef48ec1ad592db0bf43 2x">

    

    
        <source media="(min-width: 768px)" width="800" height="618" srcset="https://dims.apnews.com/dims4/default/93ffa17/2147483647/strip/true/crop/2590x2002+0+0/resize/800x618!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F57%2F83%2Fc38a42a2fe6203ad6d06edddb112%2Fe5a8eba0530a4ef48ec1ad592db0bf43 1x,https://dims.apnews.com/dims4/default/6630c7c/2147483647/strip/true/crop/2590x2002+0+0/resize/1600x1236!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F57%2F83%2Fc38a42a2fe6203ad6d06edddb112%2Fe5a8eba0530a4ef48ec1ad592db0bf43 2x">

    

    
        <source media="(min-width: 600px)" type="image/webp" width="767" height="593" srcset="https://dims.apnews.com/dims4/default/acc5689/2147483647/strip/true/crop/2590x2002+0+0/resize/767x593!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F57%2F83%2Fc38a42a2fe6203ad6d06edddb112%2Fe5a8eba0530a4ef48ec1ad592db0bf43 1x,https://dims.apnews.com/dims4/default/eb9326e/2147483647/strip/true/crop/2590x2002+0+0/resize/1534x1186!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F57%2F83%2Fc38a42a2fe6203ad6d06edddb112%2Fe5a8eba0530a4ef48ec1ad592db0bf43 2x">

    

    
        <source media="(min-width: 600px)" width="767" height="593" srcset="https://dims.apnews.com/dims4/default/c95f026/2147483647/strip/true/crop/2590x2002+0+0/resize/767x593!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F57%2F83%2Fc38a42a2fe6203ad6d06edddb112%2Fe5a8eba0530a4ef48ec1ad592db0bf43 1x,https://dims.apnews.com/dims4/default/90a277d/2147483647/strip/true/crop/2590x2002+0+0/resize/1534x1186!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F57%2F83%2Fc38a42a2fe6203ad6d06edddb112%2Fe5a8eba0530a4ef48ec1ad592db0bf43 2x">

    

    
        <source type="image/webp" width="599" height="463" srcset="https://dims.apnews.com/dims4/default/08031d0/2147483647/strip/true/crop/2590x2002+0+0/resize/599x463!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F57%2F83%2Fc38a42a2fe6203ad6d06edddb112%2Fe5a8eba0530a4ef48ec1ad592db0bf43 1x,https://dims.apnews.com/dims4/default/f5d5882/2147483647/strip/true/crop/2590x2002+0+0/resize/1198x926!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F57%2F83%2Fc38a42a2fe6203ad6d06edddb112%2Fe5a8eba0530a4ef48ec1ad592db0bf43 2x">

    

    
        <source width="599" height="463" srcset="https://dims.apnews.com/dims4/default/c2a64c7/2147483647/strip/true/crop/2590x2002+0+0/resize/599x463!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F57%2F83%2Fc38a42a2fe6203ad6d06edddb112%2Fe5a8eba0530a4ef48ec1ad592db0bf43 1x,https://dims.apnews.com/dims4/default/e7ab218/2147483647/strip/true/crop/2590x2002+0+0/resize/1198x926!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F57%2F83%2Fc38a42a2fe6203ad6d06edddb112%2Fe5a8eba0530a4ef48ec1ad592db0bf43 2x">

    
<img alt="Image" srcset="https://dims.apnews.com/dims4/default/c2a64c7/2147483647/strip/true/crop/2590x2002+0+0/resize/599x463!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F57%2F83%2Fc38a42a2fe6203ad6d06edddb112%2Fe5a8eba0530a4ef48ec1ad592db0bf43 1x,https://dims.apnews.com/dims4/default/e7ab218/2147483647/strip/true/crop/2590x2002+0+0/resize/1198x926!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F57%2F83%2Fc38a42a2fe6203ad6d06edddb112%2Fe5a8eba0530a4ef48ec1ad592db0bf43 2x" width="599" height="463" src="https://dims.apnews.com/dims4/default/c2a64c7/2147483647/strip/true/crop/2590x2002+0+0/resize/599x463!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F57%2F83%2Fc38a42a2fe6203ad6d06edddb112%2Fe5a8eba0530a4ef48ec1ad592db0bf43" loading="lazy">
</picture>

    

    
        <div><bsp-read-more data-more-button-text="Read More" data-less-button-text="Read Less" data-expand="ReadMore-expand" data-limit="110" data-main-class="ReadMore">
                    <figcaption><p>FILE - Michael Jackson, left, holds eight awards as he poses with Quincy Jones at the Grammy Awards in Los Angeles, Feb. 28, 1984. Quincy Jones died at age 91. (AP Photo/Doug Pizac, File)</p></figcaption>
                </bsp-read-more></div>
    
</figure>

                </div><p>“Tonight, with full but broken hearts, we must share the news of our father and brother Quincy Jones’ passing,” the family said in a statement. “And although this is an incredible loss for our family, we celebrate the great life that he lived and know there will never be another like him.” </p><p>Jones rose from running with gangs on the South Side of Chicago to the very heights of show business, becoming one of the first Black executives to thrive in Hollywood and amassing an <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/we-are-world-greatest-night-netflix-c06beb0f15e3b1c95f355cf55843f93a">extraordinary musical catalog</a></span> that includes some of the richest moments of American rhythm and song. For years, it was unlikely to find a music lover who did not own at least one record with his name on it, or a leader in the entertainment industry and beyond who did not have some connection to him.</p><div data-separate-event="audioModule" data-separate-value="AP AUDIO: Quincy Jones, music titan who worked with everyone from Frank Sinatra to Michael Jackson, dies at 91" data-module="" data-gtm-region="AP AUDIO: Quincy Jones, music titan who worked with everyone from Frank Sinatra to Michael Jackson, dies at 91" data-align-center="">
    
    
    
    
    <h2 data-mb-5="">
        AP AUDIO: Quincy Jones, music titan who worked with everyone from Frank Sinatra to Michael Jackson, dies at 91
    </h2>
    
    
    <p>AP correspondent Donna Warder reports on the death of Quincy Jones.</p>
    
</div>
    

<p>Jones kept company with presidents and foreign leaders, movie stars and musicians, philanthropists and business leaders. He toured with Count Basie and Lionel Hampton, arranged records for Sinatra and Ella Fitzgerald, composed the soundtracks for “Roots” and “In the Heat of the Night,” organized President Bill Clinton’s first inaugural celebration and oversaw the all-star recording of “We Are the World,” the 1985 charity record for famine relief in Africa.</p>
    
    
    
<p>Lionel Richie, who co-wrote “We Are the World” and was among the featured singers, would call Jones “the master orchestrator.”</p>




    

<p>In a career which began when records were still played on platters turning at 78 rpm, top honors likely go to his productions with Jackson: “Off the Wall,” “Thriller” and “Bad” were albums near-universal in their style and appeal. Jones’ versatility and imagination helped set off the explosive talents of Jackson as he transformed from child star to the “King of Pop.” On such classic tracks as “Billie Jean” and “Don’t Stop ‘Til You Get Enough,” Jones and Jackson fashioned a global soundscape out of disco, funk, rock, pop, R&amp;B and jazz and African chants. For “Thriller,” some of the most memorable touches originated with Jones, who recruited Eddie Van Halen for a guitar solo on the genre-fusing “Beat It” and brought in Vincent Price for a ghoulish voiceover on the title track.</p><div data-align-fullwidth="">
                
                <figure>
    

    
        <picture data-crop="twoup-3x2">
    
        <source media="(max-width: 599px)" type="image/webp" width="599" height="399" srcset="https://dims.apnews.com/dims4/default/d1531a7/2147483647/strip/true/crop/3000x1998+0+46/resize/599x399!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F5f%2F2a%2Fe9aa4b514b1fb518ab24925f1ebe%2F5bc556a747224808bf9c6f3831898a95 1x,https://dims.apnews.com/dims4/default/8397cbb/2147483647/strip/true/crop/3000x1998+0+46/resize/1198x798!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F5f%2F2a%2Fe9aa4b514b1fb518ab24925f1ebe%2F5bc556a747224808bf9c6f3831898a95 2x">

    

    
        <source media="(max-width: 599px)" width="599" height="399" srcset="https://dims.apnews.com/dims4/default/74d9e54/2147483647/strip/true/crop/3000x1998+0+46/resize/599x399!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F5f%2F2a%2Fe9aa4b514b1fb518ab24925f1ebe%2F5bc556a747224808bf9c6f3831898a95 1x,https://dims.apnews.com/dims4/default/f2e858e/2147483647/strip/true/crop/3000x1998+0+46/resize/1198x798!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F5f%2F2a%2Fe9aa4b514b1fb518ab24925f1ebe%2F5bc556a747224808bf9c6f3831898a95 2x">

    

    
        <source type="image/webp" width="767" height="511" srcset="https://dims.apnews.com/dims4/default/0eb4bd7/2147483647/strip/true/crop/3000x1999+0+46/resize/767x511!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F5f%2F2a%2Fe9aa4b514b1fb518ab24925f1ebe%2F5bc556a747224808bf9c6f3831898a95 1x,https://dims.apnews.com/dims4/default/c867203/2147483647/strip/true/crop/3000x1999+0+46/resize/1534x1022!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F5f%2F2a%2Fe9aa4b514b1fb518ab24925f1ebe%2F5bc556a747224808bf9c6f3831898a95 2x">

    

    
        <source width="767" height="511" srcset="https://dims.apnews.com/dims4/default/995ce12/2147483647/strip/true/crop/3000x1999+0+46/resize/767x511!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F5f%2F2a%2Fe9aa4b514b1fb518ab24925f1ebe%2F5bc556a747224808bf9c6f3831898a95 1x,https://dims.apnews.com/dims4/default/a96a0a1/2147483647/strip/true/crop/3000x1999+0+46/resize/1534x1022!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F5f%2F2a%2Fe9aa4b514b1fb518ab24925f1ebe%2F5bc556a747224808bf9c6f3831898a95 2x">

    
<img alt="Image" srcset="https://dims.apnews.com/dims4/default/995ce12/2147483647/strip/true/crop/3000x1999+0+46/resize/767x511!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F5f%2F2a%2Fe9aa4b514b1fb518ab24925f1ebe%2F5bc556a747224808bf9c6f3831898a95 1x,https://dims.apnews.com/dims4/default/a96a0a1/2147483647/strip/true/crop/3000x1999+0+46/resize/1534x1022!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F5f%2F2a%2Fe9aa4b514b1fb518ab24925f1ebe%2F5bc556a747224808bf9c6f3831898a95 2x" width="767" height="511" src="https://dims.apnews.com/dims4/default/995ce12/2147483647/strip/true/crop/3000x1999+0+46/resize/767x511!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F5f%2F2a%2Fe9aa4b514b1fb518ab24925f1ebe%2F5bc556a747224808bf9c6f3831898a95" loading="lazy">
</picture>

    

    
        <div>
            <p><bsp-read-more data-more-button-text="Read More" data-less-button-text="Read Less" data-expand="ReadMore-expand" data-limit="110" data-main-class="ReadMore">
                    <figcaption>Jones and his wife, Peggy Lipton, hold Jones' star which was placed in the Hollywood Walk of Fame in Los Angeles on March 14, 1980. (AP Photo/Barfield, File)</figcaption>
                </bsp-read-more></p>
            
        </div>
    
</figure>
<figure>
    

    
        <picture data-crop="twoup-3x2">
    
        <source media="(max-width: 599px)" type="image/webp" width="599" height="399" srcset="https://dims.apnews.com/dims4/default/fbe1efb/2147483647/strip/true/crop/2000x1332+0+47/resize/599x399!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fe7%2Fa1%2F36ab0069a07b3078bc2259e2e5da%2Fcfd09aa286724957989c3f554c3c7c64 1x,https://dims.apnews.com/dims4/default/ed0180d/2147483647/strip/true/crop/2000x1332+0+47/resize/1198x798!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fe7%2Fa1%2F36ab0069a07b3078bc2259e2e5da%2Fcfd09aa286724957989c3f554c3c7c64 2x">

    

    
        <source media="(max-width: 599px)" width="599" height="399" srcset="https://dims.apnews.com/dims4/default/f9551e3/2147483647/strip/true/crop/2000x1332+0+47/resize/599x399!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fe7%2Fa1%2F36ab0069a07b3078bc2259e2e5da%2Fcfd09aa286724957989c3f554c3c7c64 1x,https://dims.apnews.com/dims4/default/5bacfe5/2147483647/strip/true/crop/2000x1332+0+47/resize/1198x798!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fe7%2Fa1%2F36ab0069a07b3078bc2259e2e5da%2Fcfd09aa286724957989c3f554c3c7c64 2x">

    

    
        <source type="image/webp" width="767" height="511" srcset="https://dims.apnews.com/dims4/default/40b1102/2147483647/strip/true/crop/2000x1332+0+47/resize/767x511!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fe7%2Fa1%2F36ab0069a07b3078bc2259e2e5da%2Fcfd09aa286724957989c3f554c3c7c64 1x,https://dims.apnews.com/dims4/default/391cfd3/2147483647/strip/true/crop/2000x1332+0+47/resize/1534x1022!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fe7%2Fa1%2F36ab0069a07b3078bc2259e2e5da%2Fcfd09aa286724957989c3f554c3c7c64 2x">

    

    
        <source width="767" height="511" srcset="https://dims.apnews.com/dims4/default/7df1eea/2147483647/strip/true/crop/2000x1332+0+47/resize/767x511!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fe7%2Fa1%2F36ab0069a07b3078bc2259e2e5da%2Fcfd09aa286724957989c3f554c3c7c64 1x,https://dims.apnews.com/dims4/default/b90a6f9/2147483647/strip/true/crop/2000x1332+0+47/resize/1534x1022!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fe7%2Fa1%2F36ab0069a07b3078bc2259e2e5da%2Fcfd09aa286724957989c3f554c3c7c64 2x">

    
<img alt="Image" srcset="https://dims.apnews.com/dims4/default/7df1eea/2147483647/strip/true/crop/2000x1332+0+47/resize/767x511!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fe7%2Fa1%2F36ab0069a07b3078bc2259e2e5da%2Fcfd09aa286724957989c3f554c3c7c64 1x,https://dims.apnews.com/dims4/default/b90a6f9/2147483647/strip/true/crop/2000x1332+0+47/resize/1534x1022!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fe7%2Fa1%2F36ab0069a07b3078bc2259e2e5da%2Fcfd09aa286724957989c3f554c3c7c64 2x" width="767" height="511" src="https://dims.apnews.com/dims4/default/7df1eea/2147483647/strip/true/crop/2000x1332+0+47/resize/767x511!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fe7%2Fa1%2F36ab0069a07b3078bc2259e2e5da%2Fcfd09aa286724957989c3f554c3c7c64" loading="lazy">
</picture>

    

    
        <div>
            <p><bsp-read-more data-more-button-text="Read More" data-less-button-text="Read Less" data-expand="ReadMore-expand" data-limit="110" data-main-class="ReadMore">
                    <figcaption>Jones poses amongst his many Grammy awards at his home in the Bel Air section of Los Angeles, Calif., April 9, 2004. (AP Photo/Chris Pizzello, File)</figcaption>
                </bsp-read-more></p>
            
        </div>
    
</figure>

                
            </div><p><span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/entertainment-taylor-swift-questlove-music-961a22151d0651e22dbfea49e6b11579">“Thriller” sold more</a></span> than 20 million copies in 1983 alone and has contended with the Eagles’ “Greatest Hits 1971-1975” among others as the best-selling album of all time.</p><p>“If an album doesn’t do well, everyone says ‘it was the producers fault’; so if it does well, it should be your ‘fault,’ too,” Jones said in an interview with the Library of Congress in 2016. “The tracks don’t just all of a sudden appear. The producer has to have the skill, experience and ability to guide the vision to completion.”</p><div data-align-center="">
                    <figure>
    
    <a id="image-d10000"></a>


    
        <picture data-crop="imgEn-medium-nocrop">
    
        <source media="(min-width: 768px)" type="image/webp" width="800" height="593" srcset="https://dims.apnews.com/dims4/default/ec4b2e6/2147483647/strip/true/crop/1992x1476+0+0/resize/800x593!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fcf%2F8a%2Ff5d6a3356af141b56a2e45a2bb0d%2Fb7b17fa677ba49b3af5883cd50eda8ab 1x,https://dims.apnews.com/dims4/default/9a90bdf/2147483647/strip/true/crop/1992x1476+0+0/resize/1600x1186!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fcf%2F8a%2Ff5d6a3356af141b56a2e45a2bb0d%2Fb7b17fa677ba49b3af5883cd50eda8ab 2x">

    

    
        <source media="(min-width: 768px)" width="800" height="593" srcset="https://dims.apnews.com/dims4/default/583a9da/2147483647/strip/true/crop/1992x1476+0+0/resize/800x593!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fcf%2F8a%2Ff5d6a3356af141b56a2e45a2bb0d%2Fb7b17fa677ba49b3af5883cd50eda8ab 1x,https://dims.apnews.com/dims4/default/c519acf/2147483647/strip/true/crop/1992x1476+0+0/resize/1600x1186!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fcf%2F8a%2Ff5d6a3356af141b56a2e45a2bb0d%2Fb7b17fa677ba49b3af5883cd50eda8ab 2x">

    

    
        <source media="(min-width: 600px)" type="image/webp" width="767" height="568" srcset="https://dims.apnews.com/dims4/default/8c850ff/2147483647/strip/true/crop/1992x1476+0+0/resize/767x568!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fcf%2F8a%2Ff5d6a3356af141b56a2e45a2bb0d%2Fb7b17fa677ba49b3af5883cd50eda8ab 1x,https://dims.apnews.com/dims4/default/22beaa1/2147483647/strip/true/crop/1992x1476+0+0/resize/1534x1136!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fcf%2F8a%2Ff5d6a3356af141b56a2e45a2bb0d%2Fb7b17fa677ba49b3af5883cd50eda8ab 2x">

    

    
        <source media="(min-width: 600px)" width="767" height="568" srcset="https://dims.apnews.com/dims4/default/c902ec5/2147483647/strip/true/crop/1992x1476+0+0/resize/767x568!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fcf%2F8a%2Ff5d6a3356af141b56a2e45a2bb0d%2Fb7b17fa677ba49b3af5883cd50eda8ab 1x,https://dims.apnews.com/dims4/default/c40f85d/2147483647/strip/true/crop/1992x1476+0+0/resize/1534x1136!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fcf%2F8a%2Ff5d6a3356af141b56a2e45a2bb0d%2Fb7b17fa677ba49b3af5883cd50eda8ab 2x">

    

    
        <source type="image/webp" width="599" height="444" srcset="https://dims.apnews.com/dims4/default/c3d1a53/2147483647/strip/true/crop/1992x1476+0+0/resize/599x444!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fcf%2F8a%2Ff5d6a3356af141b56a2e45a2bb0d%2Fb7b17fa677ba49b3af5883cd50eda8ab 1x,https://dims.apnews.com/dims4/default/32b9eed/2147483647/strip/true/crop/1992x1476+0+0/resize/1198x888!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fcf%2F8a%2Ff5d6a3356af141b56a2e45a2bb0d%2Fb7b17fa677ba49b3af5883cd50eda8ab 2x">

    

    
        <source width="599" height="444" srcset="https://dims.apnews.com/dims4/default/cd44c5c/2147483647/strip/true/crop/1992x1476+0+0/resize/599x444!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fcf%2F8a%2Ff5d6a3356af141b56a2e45a2bb0d%2Fb7b17fa677ba49b3af5883cd50eda8ab 1x,https://dims.apnews.com/dims4/default/6a818c8/2147483647/strip/true/crop/1992x1476+0+0/resize/1198x888!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fcf%2F8a%2Ff5d6a3356af141b56a2e45a2bb0d%2Fb7b17fa677ba49b3af5883cd50eda8ab 2x">

    
<img alt="Image" srcset="https://dims.apnews.com/dims4/default/cd44c5c/2147483647/strip/true/crop/1992x1476+0+0/resize/599x444!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fcf%2F8a%2Ff5d6a3356af141b56a2e45a2bb0d%2Fb7b17fa677ba49b3af5883cd50eda8ab 1x,https://dims.apnews.com/dims4/default/6a818c8/2147483647/strip/true/crop/1992x1476+0+0/resize/1198x888!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fcf%2F8a%2Ff5d6a3356af141b56a2e45a2bb0d%2Fb7b17fa677ba49b3af5883cd50eda8ab 2x" width="599" height="444" src="https://dims.apnews.com/dims4/default/cd44c5c/2147483647/strip/true/crop/1992x1476+0+0/resize/599x444!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Fcf%2F8a%2Ff5d6a3356af141b56a2e45a2bb0d%2Fb7b17fa677ba49b3af5883cd50eda8ab" loading="lazy">
</picture>

    

    
        <div><bsp-read-more data-more-button-text="Read More" data-less-button-text="Read Less" data-expand="ReadMore-expand" data-limit="110" data-main-class="ReadMore">
                    <figcaption><p>Quincy Jones cradles his Grammy awards including the album of the year award, for his eclectic album “Back on the Block” during the 33rd annual Grammy Awards, at New York’s Radio City Music Hall night of Feb.20,1991. (AP Photo/Susan Ragan, File)</p></figcaption>
                </bsp-read-more></div>
    
</figure>

                </div>
    

<p>The list of his honors and awards fills 18 pages in his 2001 autobiography “Q,” including 27 Grammys at the time (now 28), an honorary Academy Award (now two) and an Emmy for “Roots.” He also received France’s Legion d’Honneur, the Rudolph Valentino Award from the Republic of Italy and a Kennedy Center tribute for his contributions to American culture. He was the subject of a 1990 documentary, “Listen Up: The Lives of Quincy Jones,” and a 2018 film by daughter Rashida Jones. His memoir made him a best-selling author.</p><p>Born in Chicago in 1933, Jones would cite the hymns his mother sang around the house as the first music he could remember. But he looked back sadly on his childhood, once telling Oprah Winfrey that “There are two kinds of people: those who have nurturing parents or caretakers, and those who don’t. Nothing’s in between.” Jones’ mother suffered from emotional problems and was eventually institutionalized, a loss that made the world seem “senseless” for Quincy. He spent much of his time in Chicago on the streets, with gangs, stealing and fighting.</p>
    

<p>“They nailed my hand to a fence with a switchblade, man,” he told the AP in 2018, showing a scar from his childhood.</p><p>Music saved him. As a boy, he learned that a Chicago neighbor owned a piano and he soon played it constantly himself. His father moved to Washington state when Quincy was 10 and his world changed at a neighborhood recreation center. Jones and some friends had broken into the kitchen and helped themselves to lemon meringue pie when Jones noticed a small room nearby with a stage. On the stage was a piano.</p><p>“I went up there, paused, stared, and then tinkled on it for a moment,” he wrote in his autobiography. “That’s where I began to find peace. I was 11. I knew this was it for me. Forever.”</p>
    

<p>Within a few years he was playing trumpet and befriending a young blind musician named Ray Charles, who became a lifelong friend. He was gifted enough to win a scholarship at the Berklee College of Music in Boston, but dropped out when Hampton invited him to tour with his band. Jones went on to work as a freelance composer, conductor, arranger and producer. As a teen, he backed Billie Holiday. By his mid-20s, he was touring with his own band.</p><p>“We had the best jazz band on the planet, and yet we were literally starving,” Jones later told Musician magazine. “That’s when I discovered that there was music, and there was the music business. If I were to survive, I would have to learn the difference between the two.”</p><p>As a music executive, he overcame racial barriers by becoming a vice president at Mercury Records in the early ’60s. In 1971, he became the first Black musical director for the Academy Awards ceremony. The first movie he produced, “The Color Purple,” received 11 Oscar nominations in 1986. (But, to his great disappointment, no wins). In a partnership with Time Warner, he created Quincy Jones Entertainment, which included the pop-culture magazine Vibe and Qwest Broadcasting. The company was sold for $270 million in 1999.</p><p>“My philosophy as a businessman has always come from the same roots as my personal credo: take talented people on their own terms and treat them fairly and with respect, no matter who they are or where they come from,” Jones wrote in his autobiography.</p><div data-align-center="">
                    <figure>
    
    <a id="image-c80000"></a>


    
        <picture data-crop="imgEn-medium-nocrop">
    
        <source media="(min-width: 768px)" type="image/webp" width="800" height="554" srcset="https://dims.apnews.com/dims4/default/2d409e6/2147483647/strip/true/crop/1992x1380+0+0/resize/800x554!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F10%2Fc4%2Fd4fbb10d4327ba7edc3f67b5a099%2Fcbf959acd10e4c6fa6dd2acf0c5e2832 1x,https://dims.apnews.com/dims4/default/c540712/2147483647/strip/true/crop/1992x1380+0+0/resize/1600x1108!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F10%2Fc4%2Fd4fbb10d4327ba7edc3f67b5a099%2Fcbf959acd10e4c6fa6dd2acf0c5e2832 2x">

    

    
        <source media="(min-width: 768px)" width="800" height="554" srcset="https://dims.apnews.com/dims4/default/eb46908/2147483647/strip/true/crop/1992x1380+0+0/resize/800x554!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F10%2Fc4%2Fd4fbb10d4327ba7edc3f67b5a099%2Fcbf959acd10e4c6fa6dd2acf0c5e2832 1x,https://dims.apnews.com/dims4/default/877fc3c/2147483647/strip/true/crop/1992x1380+0+0/resize/1600x1108!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F10%2Fc4%2Fd4fbb10d4327ba7edc3f67b5a099%2Fcbf959acd10e4c6fa6dd2acf0c5e2832 2x">

    

    
        <source media="(min-width: 600px)" type="image/webp" width="767" height="531" srcset="https://dims.apnews.com/dims4/default/89bd6e4/2147483647/strip/true/crop/1992x1380+0+0/resize/767x531!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F10%2Fc4%2Fd4fbb10d4327ba7edc3f67b5a099%2Fcbf959acd10e4c6fa6dd2acf0c5e2832 1x,https://dims.apnews.com/dims4/default/13f91b8/2147483647/strip/true/crop/1992x1380+0+0/resize/1534x1062!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F10%2Fc4%2Fd4fbb10d4327ba7edc3f67b5a099%2Fcbf959acd10e4c6fa6dd2acf0c5e2832 2x">

    

    
        <source media="(min-width: 600px)" width="767" height="531" srcset="https://dims.apnews.com/dims4/default/8a27b4a/2147483647/strip/true/crop/1992x1380+0+0/resize/767x531!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F10%2Fc4%2Fd4fbb10d4327ba7edc3f67b5a099%2Fcbf959acd10e4c6fa6dd2acf0c5e2832 1x,https://dims.apnews.com/dims4/default/d633562/2147483647/strip/true/crop/1992x1380+0+0/resize/1534x1062!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F10%2Fc4%2Fd4fbb10d4327ba7edc3f67b5a099%2Fcbf959acd10e4c6fa6dd2acf0c5e2832 2x">

    

    
        <source type="image/webp" width="599" height="415" srcset="https://dims.apnews.com/dims4/default/c26ca84/2147483647/strip/true/crop/1992x1380+0+0/resize/599x415!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F10%2Fc4%2Fd4fbb10d4327ba7edc3f67b5a099%2Fcbf959acd10e4c6fa6dd2acf0c5e2832 1x,https://dims.apnews.com/dims4/default/0f09d6a/2147483647/strip/true/crop/1992x1380+0+0/resize/1198x830!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F10%2Fc4%2Fd4fbb10d4327ba7edc3f67b5a099%2Fcbf959acd10e4c6fa6dd2acf0c5e2832 2x">

    

    
        <source width="599" height="415" srcset="https://dims.apnews.com/dims4/default/4633d90/2147483647/strip/true/crop/1992x1380+0+0/resize/599x415!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F10%2Fc4%2Fd4fbb10d4327ba7edc3f67b5a099%2Fcbf959acd10e4c6fa6dd2acf0c5e2832 1x,https://dims.apnews.com/dims4/default/1ed7f68/2147483647/strip/true/crop/1992x1380+0+0/resize/1198x830!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F10%2Fc4%2Fd4fbb10d4327ba7edc3f67b5a099%2Fcbf959acd10e4c6fa6dd2acf0c5e2832 2x">

    
<img alt="Image" srcset="https://dims.apnews.com/dims4/default/4633d90/2147483647/strip/true/crop/1992x1380+0+0/resize/599x415!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F10%2Fc4%2Fd4fbb10d4327ba7edc3f67b5a099%2Fcbf959acd10e4c6fa6dd2acf0c5e2832 1x,https://dims.apnews.com/dims4/default/1ed7f68/2147483647/strip/true/crop/1992x1380+0+0/resize/1198x830!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F10%2Fc4%2Fd4fbb10d4327ba7edc3f67b5a099%2Fcbf959acd10e4c6fa6dd2acf0c5e2832 2x" width="599" height="415" src="https://dims.apnews.com/dims4/default/4633d90/2147483647/strip/true/crop/1992x1380+0+0/resize/599x415!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F10%2Fc4%2Fd4fbb10d4327ba7edc3f67b5a099%2Fcbf959acd10e4c6fa6dd2acf0c5e2832" loading="lazy">
</picture>

    

    
        <div><bsp-read-more data-more-button-text="Read More" data-less-button-text="Read Less" data-expand="ReadMore-expand" data-limit="110" data-main-class="ReadMore">
                    <figcaption><p>FILE - U.S. musician Quincy Jones directs the Orchestra National de France Tuesday, July 4, 2000, in Paris, during rehearsals prior the evening’s unique concert. Quincy Jones died at age 91. (AP Photo/Laurent Emmanuel, File)</p></figcaption>
                </bsp-read-more></div>
    
</figure>

                </div><p>He was at ease with virtually every form of American music, whether setting Sinatra’s “Fly Me to the Moon” to a punchy, swinging rhythm and wistful flute or opening his production of Charles’ soulful “In the Heat of the Night” with a lusty tenor sax solo. He worked with jazz giants (Dizzy Gillespie, Duke Ellington), rappers (Snoop Dogg, LL Cool J), crooners (Sinatra, Tony Bennett), pop singers (Lesley Gore) and rhythm and blues stars (Chaka Khan, Queen Latifah).</p><p>On “We are the World” alone, performers included Michael Jackson, Bob Dylan, Billy Joel, Stevie Wonder and Bruce Springsteen. He co-wrote hits for Jackson – “P.Y.T (Pretty Young Thing)” – and Donna Summer – “Love Is in Control (Finger on the Trigger) – and had songs sampled by Tupac Shakur, Kanye West and other rappers. He even composed the theme song for the sitcom “Sanford and Son.”</p><p>Jones was a facilitator and maker of the stars. He gave Will Smith a key break in the hit TV show “The Fresh Prince of Bel-Air,” which Jones produced, and through “The Color Purple” he introduced Winfrey and Whoopi Goldberg to filmgoers. Starting in the 1960s, he composed more than 35 film scores, including for “The Pawnbroker,” “In the Heat of the Night” and “In Cold Blood.”</p><p>He called scoring “a multifaceted process, an abstract combination of science and soul.”</p><p>Jones’ work on the soundtrack for “The Wiz” led to his partnership with Jackson, who starred in the 1978 movie. In an essay published in Time magazine after Jackson’s death, in 2009, Jones remembered that the singer kept slips of paper on him that contained thoughts by famous thinkers. When Jones asked about the origins of one passage, Jackson answered “Socrates,” but pronounced it “SO-crayts.” Jones corrected him, “Michael, it’s SOCK-ra-tees.”</p><p>“And the look he gave me then, it just prompted me to say, because I’d been impressed by all the things I saw in him during the rehearsal process, ‘I would love to take a shot at producing your album,’” Jones recalled. “And he went back and told the people at Epic Records, and they said, `No way — Quincy’s too jazzy.’ Michael was persistent, and he and his managers went back and said, `Quincy’s producing the album.’ And we proceeded to make ‘Off the Wall.’ Ironically, that was one of the biggest Black-selling albums at the time, and that album saved all the jobs of the people saying I was the wrong guy. That’s the way it works.”</p><p>Tensions emerged after Jackson’s death. In 2013, <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/7adb910007e4d705278bed1b7ecb5660">Jones sued Jackson’s estate</a></span>, claiming he was owed millions in royalties and production fees on some of the superstar’s greatest hits. In a 2018 interview with New York magazine, he called Jackson “as Machiavellian as they come” and alleged that he lifted material from others.</p><p>Jones was hooked on work and play, and at times suffered for it. He nearly died from a brain aneurysm in 1974 and became deeply depressed in the 1980s after “The Color Purple” was snubbed by Academy Awards voters; he never received a competitive Oscar. A father of seven children by five mothers, Jones described himself as a “dog” who had countless lovers around the world. He was married three times, his wives including the actor Peggy Lipton.</p><p>“To me, loving a woman is one of the most natural, blissful, life-enhancing — and dare I say, religious — acts in the world,” he wrote.</p><p>Along with Rashida, Jones is survived by daughters Jolie Jones Levine, Rachel Jones, Martina Jones, Kidada Jones and Kenya Kinski-Jones; son Quincy Jones III; brother Richard Jones and sisters Theresa Frank and Margie Jay.</p><p>He was not an activist in his early years, but changed after attending the 1968 funeral of the Rev. Martin Luther King Jr. and later befriending the Rev. Jesse Jackson. Jones was dedicated to philanthropy, saying “the best and only useful aspect of fame and celebrity is having a platform to help others.”</p><p>His causes included fighting HIV and AIDS, educating children and providing for the poor around the world. He founded the Quincy Jones Listen Up! Foundation to connect young people with music, culture and technology, and said he was driven throughout his life “by a spirit of adventure and a criminal level of optimism.”</p><p>“Life is like a dream, the Spanish poet and philosopher Federico Garcia Lorca said,” Jones wrote in his memoir. “Mine’s been in Technicolor, with full Dolby sound through THX amplification before they knew what these systems were.”</p><div data-align-center="">
                    <figure>
    
    <a id="image-ad0000"></a>


    
        <picture data-crop="imgEn-medium-nocrop">
    
        <source media="(min-width: 768px)" type="image/webp" width="800" height="610" srcset="https://dims.apnews.com/dims4/default/eb1575f/2147483647/strip/true/crop/3000x2286+0+0/resize/800x610!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Ff5%2F5a%2Fd98122ca972f0f884bb312b42422%2F58b151708e1947c99a0fe10a6434ba9f 1x,https://dims.apnews.com/dims4/default/29e7c83/2147483647/strip/true/crop/3000x2286+0+0/resize/1600x1220!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Ff5%2F5a%2Fd98122ca972f0f884bb312b42422%2F58b151708e1947c99a0fe10a6434ba9f 2x">

    

    
        <source media="(min-width: 768px)" width="800" height="610" srcset="https://dims.apnews.com/dims4/default/491a689/2147483647/strip/true/crop/3000x2286+0+0/resize/800x610!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Ff5%2F5a%2Fd98122ca972f0f884bb312b42422%2F58b151708e1947c99a0fe10a6434ba9f 1x,https://dims.apnews.com/dims4/default/7e8f63e/2147483647/strip/true/crop/3000x2286+0+0/resize/1600x1220!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Ff5%2F5a%2Fd98122ca972f0f884bb312b42422%2F58b151708e1947c99a0fe10a6434ba9f 2x">

    

    
        <source media="(min-width: 600px)" type="image/webp" width="767" height="584" srcset="https://dims.apnews.com/dims4/default/39b0891/2147483647/strip/true/crop/3000x2286+0+0/resize/767x584!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Ff5%2F5a%2Fd98122ca972f0f884bb312b42422%2F58b151708e1947c99a0fe10a6434ba9f 1x,https://dims.apnews.com/dims4/default/14aa54f/2147483647/strip/true/crop/3000x2286+0+0/resize/1534x1168!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Ff5%2F5a%2Fd98122ca972f0f884bb312b42422%2F58b151708e1947c99a0fe10a6434ba9f 2x">

    

    
        <source media="(min-width: 600px)" width="767" height="584" srcset="https://dims.apnews.com/dims4/default/7997768/2147483647/strip/true/crop/3000x2286+0+0/resize/767x584!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Ff5%2F5a%2Fd98122ca972f0f884bb312b42422%2F58b151708e1947c99a0fe10a6434ba9f 1x,https://dims.apnews.com/dims4/default/4985a3e/2147483647/strip/true/crop/3000x2286+0+0/resize/1534x1168!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Ff5%2F5a%2Fd98122ca972f0f884bb312b42422%2F58b151708e1947c99a0fe10a6434ba9f 2x">

    

    
        <source type="image/webp" width="599" height="456" srcset="https://dims.apnews.com/dims4/default/83bf94d/2147483647/strip/true/crop/3000x2286+0+0/resize/599x456!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Ff5%2F5a%2Fd98122ca972f0f884bb312b42422%2F58b151708e1947c99a0fe10a6434ba9f 1x,https://dims.apnews.com/dims4/default/3043114/2147483647/strip/true/crop/3000x2286+0+0/resize/1198x912!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Ff5%2F5a%2Fd98122ca972f0f884bb312b42422%2F58b151708e1947c99a0fe10a6434ba9f 2x">

    

    
        <source width="599" height="456" srcset="https://dims.apnews.com/dims4/default/8702264/2147483647/strip/true/crop/3000x2286+0+0/resize/599x456!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Ff5%2F5a%2Fd98122ca972f0f884bb312b42422%2F58b151708e1947c99a0fe10a6434ba9f 1x,https://dims.apnews.com/dims4/default/4f5852d/2147483647/strip/true/crop/3000x2286+0+0/resize/1198x912!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Ff5%2F5a%2Fd98122ca972f0f884bb312b42422%2F58b151708e1947c99a0fe10a6434ba9f 2x">

    
<img alt="Image" srcset="https://dims.apnews.com/dims4/default/8702264/2147483647/strip/true/crop/3000x2286+0+0/resize/599x456!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Ff5%2F5a%2Fd98122ca972f0f884bb312b42422%2F58b151708e1947c99a0fe10a6434ba9f 1x,https://dims.apnews.com/dims4/default/4f5852d/2147483647/strip/true/crop/3000x2286+0+0/resize/1198x912!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Ff5%2F5a%2Fd98122ca972f0f884bb312b42422%2F58b151708e1947c99a0fe10a6434ba9f 2x" width="599" height="456" src="https://dims.apnews.com/dims4/default/8702264/2147483647/strip/true/crop/3000x2286+0+0/resize/599x456!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2Ff5%2F5a%2Fd98122ca972f0f884bb312b42422%2F58b151708e1947c99a0fe10a6434ba9f" loading="lazy">
</picture>

    

    
        <div><bsp-read-more data-more-button-text="Read More" data-less-button-text="Read Less" data-expand="ReadMore-expand" data-limit="110" data-main-class="ReadMore">
                    <figcaption><p>Quincy Jones, famed composer recovering from recent brain-blood-vessel surgery, relaxes at his Los Angeles music studio on Oct. 16, 1974. (AP Photo/George Brich, File)</p></figcaption>
                </bsp-read-more></div>
    
</figure>

                </div><h2>____</h2><p>AP Entertainment writer Andrew Dalton and former AP Entertainment Writer Sandy Cohen contributed to this report from Los Angeles.</p>
                                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I've had a change of heart regarding employee metrics (455 pts)]]></title>
            <link>http://rachelbythebay.com/w/2024/11/03/metrics/</link>
            <guid>42038653</guid>
            <pubDate>Mon, 04 Nov 2024 05:06:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://rachelbythebay.com/w/2024/11/03/metrics/">http://rachelbythebay.com/w/2024/11/03/metrics/</a>, See on <a href="https://news.ycombinator.com/item?id=42038653">Hacker News</a></p>
Couldn't get http://rachelbythebay.com/w/2024/11/03/metrics/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Please just stop saying "just" (2019) (118 pts)]]></title>
            <link>https://sgringwe.com/2019/10/10/Please-just-stop-saying-just.html</link>
            <guid>42038139</guid>
            <pubDate>Mon, 04 Nov 2024 03:25:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sgringwe.com/2019/10/10/Please-just-stop-saying-just.html">https://sgringwe.com/2019/10/10/Please-just-stop-saying-just.html</a>, See on <a href="https://news.ycombinator.com/item?id=42038139">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
      <p>Do you work in Software Engineering, and have you seen messages or sentences like these before?</p>

<blockquote>
  <p>“Can’t we <em>just</em> set up a redirect to this other domain?”</p>
</blockquote>

<blockquote>
  <p>“Why don’t we <em>just</em> add some caching to speed that page up?”</p>
</blockquote>

<blockquote>
  <p>“I read their documentation, and we <em>just</em> need to inject some javascript, we should be all set!”</p>
</blockquote>

<p>Me too, and it drives me a little crazy.</p>

<p>Not because anyone is being rude, or because anything they are saying is necessarily wrong. Nobody is being intentionally malice, here. <strong>It’s that (in my opinion) the word “<em>just</em>” added as a qualifier to an idea carries with it a whole bunch of implied baggage.</strong></p>

<h2 id="the-baggage">The Baggage</h2>

<h2 id="implies-simplicity">Implies Simplicity</h2>

<p>First and foremost, the word “<em>just</em>” implies that an idea is simple. “Oh, we can <em>just</em> do this!”.</p>

<p>If there is one thing I’ve learned with Software Engineering, it’s that <em>Computers are Hard</em> and implementation details matter, especially when it comes to complexity. Very rarely can the complexity of an engineering solution be outlined in a single sentence. There is almost always more to it.</p>

<p>Let’s take one of the above examples of “<em>just</em>” injecting javascript into the page.</p>

<ul>
  <li>Do we trust this javascript to run on our page? What is the security posture of the javascript author?</li>
  <li>What dependencies does the script have, and are they trusted and up-to-date?</li>
  <li>What data is being sent from their javascript? Do we need to update our privacy policy?</li>
  <li>How will the javascript be minified?</li>
  <li>Does it work with our other libraris, such as React or Turbolinks?</li>
  <li>Do we need to load this Javascript from a third party? What if that server goes down? Can we trust the integrity of their server?</li>
  <li>Do we need to update our Content Security Policy for this script?</li>
  <li>What sort of performance impact will this have on our page load performance?</li>
  <li>Does the script need to run at any a particular point in the page load process?</li>
  <li>Does the styling of the DOM elements it produces match our brand? Is that important?</li>
  <li>What sort of impact will this have on the accessibility of our website?</li>
  <li>Who is going to maintain this javascript, and update it when it needs to be?</li>
  <li>How will we monitor if this javascript snippet is still working?</li>
  <li>If the business decides to stop using it, who will tell us and how will we know?</li>
</ul>

<h2 id="reinforces-imposter-syndrome">Reinforces Imposter Syndrome</h2>

<p>Many engineers report having Imposter Syndrome, with some data even suggesting over <a href="https://www.techrepublic.com/article/why-58-of-tech-employees-suffer-from-imposter-syndrome/">half of engineers</a> at most major Silicon Valley companies.</p>

<p>Let’s paint the picture of a very common, every-day scenario…</p>

<p>Imagine being an engineer with Imposter Syndrome, and you are working on solving a problem all day. You find yourself stuck on a few tricky details on the solutions you are considering, and so you ask for help from a Senior Engineer on your team. You sit down, start to talk through it, and your coworker says…</p>

<p><strong>“what if you <em>just</em> do this?”</strong></p>

<p>I ask you, reader:</p>

<ul>
  <li>Would you feel good or happy to hear that?</li>
  <li>If you disagreed, would you voice that disagreement with such a confident and simple answer from a Senior Engineer?</li>
  <li>If you don’t understand, do you ask “what do you mean?”</li>
</ul>

<p>My guess is probably not. How could you disagree with such a simple answer?! Or not understand it?!</p>

<h2 id="reduces-ideation">Reduces Ideation</h2>

<p>Because of the implications the word “<em>just</em>” comes with, I believe that engineers are less likely to ideate and brainstorm in that environment.</p>

<p>In the face of an idea that says to “<em>just</em> do this”, I believe engineers are less confident in voicing disagreement, and are less likely to ask “what do you mean?” to truly understand the problem and the solution.</p>

<p>A team where engineers aren’t asking for clarification, don’t understand their solutions, and aren’t voicing alternative approaches is <strong>not a team that I hope to be on</strong>. That team is missing out on so much, including great ideas.</p>

<h2 id="solution">Solution</h2>

<p>My solution is simple: stop qualifying your statements with the word “<em>just</em>”.</p>

<p>Of course, I’ll acknowledge right away that such as task is not easy. And I continue to use the word by mistake all the time! But I try hard not to, and I believe I am better for it.</p>

<p>When I catch myself typing a sentence that uses the word “just”, I pause and rephrase my sentence to avoid using it. I find that doing so helps for me to:</p>

<ul>
  <li>get better response and ideation back from others</li>
  <li>clarify my thinking with strong examples and evidence</li>
  <li>orient the discussion towards a more generative mindset</li>
  <li>produce a healthier debate with more learning and sharing from everyone</li>
</ul>

<p>So please… <em>just</em> stop saying “<em>just</em>”!</p>

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[An embarrassingly simple approach to recover unlearned knowledge for LLMs (212 pts)]]></title>
            <link>https://arxiv.org/abs/2410.16454</link>
            <guid>42037982</guid>
            <pubDate>Mon, 04 Nov 2024 02:52:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2410.16454">https://arxiv.org/abs/2410.16454</a>, See on <a href="https://news.ycombinator.com/item?id=42037982">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2410.16454">View PDF</a>
    <a href="https://arxiv.org/html/2410.16454v1">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>Large language models (LLMs) have shown remarkable proficiency in generating text, benefiting from extensive training on vast textual corpora. However, LLMs may also acquire unwanted behaviors from the diverse and sensitive nature of their training data, which can include copyrighted and private content. Machine unlearning has been introduced as a viable solution to remove the influence of such problematic content without the need for costly and time-consuming retraining. This process aims to erase specific knowledge from LLMs while preserving as much model utility as possible. Despite the effectiveness of current unlearning methods, little attention has been given to whether existing unlearning methods for LLMs truly achieve forgetting or merely hide the knowledge, which current unlearning benchmarks fail to detect. This paper reveals that applying quantization to models that have undergone unlearning can restore the "forgotten" information. To thoroughly evaluate this phenomenon, we conduct comprehensive experiments using various quantization techniques across multiple precision levels. We find that for unlearning methods with utility constraints, the unlearned model retains an average of 21\% of the intended forgotten knowledge in full precision, which significantly increases to 83\% after 4-bit quantization. Based on our empirical findings, we provide a theoretical explanation for the observed phenomenon and propose a quantization-robust unlearning strategy to mitigate this intricate issue...
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Fali Wang [<a href="https://arxiv.org/show-email/606b1885/2410.16454" rel="nofollow">view email</a>]      <br>    <strong>[v1]</strong>
        Mon, 21 Oct 2024 19:28:37 UTC (1,232 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Scientists glue two proteins together, driving cancer cells to self-destruct (547 pts)]]></title>
            <link>https://med.stanford.edu/news/all-news/2024/10/protein-cancer.html</link>
            <guid>42037386</guid>
            <pubDate>Mon, 04 Nov 2024 00:42:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://med.stanford.edu/news/all-news/2024/10/protein-cancer.html">https://med.stanford.edu/news/all-news/2024/10/protein-cancer.html</a>, See on <a href="https://news.ycombinator.com/item?id=42037386">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">

    
      
        <p itemprop="description">Stanford researchers hope new technique will flip lymphoma protein’s normal action — from preventing cell death to triggering it.</p>
      
    

   <p><span itemprop="datePublished">October 22, 2024</span> 
       - By Rachel Tompa</p>


    <div><div>























<wcmmode:edit>
    
</wcmmode:edit>


    
    
        
    



<div id="" data-fullscreen-modal="false">
                    <p>A new molecule developed by Stanford Medicine researchers (turquoise and yellow) tethers two proteins (purple and red) that together switch on self-destruction genes in cancer cells.<br>
<i>Ella Maru Studio</i></p>
                </div></div>
<div id="main_content">
    <p>Our bodies divest themselves of 60 billion cells every day through a natural process of cell culling and turnover called apoptosis.</p>
<p>These cells — mainly blood and gut cells — are all replaced with new ones, but the way our bodies rid themselves of material could have profound implications for cancer therapies in a new approach developed by Stanford Medicine researchers.</p>
<p>They aim to use this natural method of cell death to trick cancer cells into disposing of themselves. Their method accomplishes this by artificially bringing together two proteins in such a way that the new compound switches on a set of cell death genes, ultimately driving tumor cells to turn on themselves. The researchers describe their <a href="https://www.science.org/doi/10.1126/science.adl5361?url_ver=Z39.88-2003&amp;rfr_id=ori:rid:crossref.org&amp;rfr_dat=cr_pub%20%200pubmed">latest such compound</a> in a paper published Oct. 4 in <i>Science</i>.</p>
<p>The idea came to <a href="https://profiles.stanford.edu/gerald-crabtree">Gerald Crabtree</a>, MD, a professor of development biology, during a pandemic stroll through the forests of Kings Mountain, west of Palo Alto, California. As he walked, Crabtree, a longtime cancer biologist, was thinking about major milestones in biology.</p>
<p>One of the milestones he pondered was the 1970s-era discovery that cells trigger their own deaths for the greater good of the organism. Apoptosis turns out to be critical for many biological processes, including proper development of all organs and the fine-tuning of our immune systems. That system retains pathogen-recognizing cells but kills off self-recognizing ones, thus preventing autoimmune disease.</p>
<p>“It occurred to me, Well gee, this is the way we want to treat cancer,” said Crabtree, a co-senior author on the study who is the David Korn, MD, Professor in Pathology. “We essentially want to have the same kind of specificity that can eliminate 60 billion cells with no bystanders, so no cell is killed that is not the proper object of the killing mechanism.”</p>


</div>

<div id="main_text">
    <p>Traditional treatments for cancer — namely chemotherapy and radiation — often kill large numbers of healthy cells alongside the cancerous ones. To harness cells’ natural and highly specific self-destruction abilities, the team developed a kind of molecular glue that sticks together two proteins that normally would have nothing to do with one another.</p>
<h3>Flipping the cancer script</h3>
<p>One of these proteins, BCL6, when mutated, drives the blood cancer known as diffuse large cell B-cell lymphoma. This kind of cancer-driving protein is also referred to as an oncogene. In lymphoma, the mutated BCL6 sits on DNA near apoptosis-promoting genes and keeps them switched off, helping the cancer cells retain their signature immortality.</p>
<p>The researchers developed a molecule that tethers BCL6 to a protein known as CDK9, which acts as an enzyme that catalyzes gene activation, in this case, switching on the set of apoptosis genes that BCL6 normally keeps off.</p>
<p>“The idea is, Can you turn a cancer dependency into a cancer-killing signal?” asked <a href="https://profiles.stanford.edu/nathanael-gray">Nathanael Gray</a>, PhD, co-senior author with Crabtree, the Krishnan-Shah Family Professor and a chemical and systems biology professor. “You take something that the cancer is addicted to for its survival and you flip the script and make that be the very thing that kills it.”</p>
<p>This approach — switching something on that is off in cancer cells — stands in contrast to many other kinds of targeted cancer therapies that inhibit specific drivers of cancer, switching off something that is normally on.</p>
<p>“Since oncogenes were discovered, people have been trying to shut them down in cancer,” said Roman Sarott, PhD, a postdoctoral scholar at Stanford Medicine and co-first author on the study. “Instead, we’re trying to use them to turn signaling on that, we hope, will prove beneficial for treatment.”</p>

</div>

<div id="main_text_0">
    <p>When the team tested the molecule in diffuse large cell B-cell lymphoma cells in the lab, they found that it indeed killed the cancer cells with high potency. They also tested the molecule in healthy mice and found no obvious toxic side effects, even though the molecule killed off a specific category of of the animals’ healthy B cells, a kind of immune cell, which also depend on BCL6. They’re now testing the compound in mice with diffuse large B-cell lymphoma to gauge its ability to kill cancer in a living animal.</p>
<p>Because the technique relies on the cells’ natural supply of BCL6 and CDK9 proteins, it seems to be very specific for the lymphoma cells — the BCL6 protein is found only in this kind of lymphoma cell and in one specific kind of B cell. The researchers tested the molecule in 859 different kinds of cancer cells in the lab; the chimeric compound killed only diffuse large cell B-cell lymphoma cells.</p>
<p>And because BCL6 normally acts on 13 different apoptosis-promoting genes, the researchers hope their strategy will avoid the treatment resistance that seems so common in cancer. Cancer is often able to rapidly adapt to therapies that target only one of the disease’s weak spots, and some of these therapies may stop cancer from growing without killing the cells entirely. The research team hopes that by blasting the cells with multiple different cell death signals at once, the cancer will not be able to survive long enough to evolve resistance, although this idea remains to be tested.</p>
<p>“It’s sort of cell death by committee,” said Sai Gourisankar, PhD, a postdoctoral scholar and co-first author on the study. “And once a cancer cell is dead, that’s a terminal state.”</p>
<p>Crabtree and Gray, both members of the <a href="https://med.stanford.edu/cancer.html">Stanford Cancer Institute</a>, are co-founders of a biotech startup, Shenandoah Therapeutics, that aims to further test this molecule and a similar, <a href="https://www.nature.com/articles/s41586-023-06348-2">previously developed molecule</a> in hopes of gathering enough pre-clinical data to support launching clinical trials of the compounds. They also plan to build similar molecules that could target other cancer-driving proteins, including the oncogene Ras, which is a driver of several different kinds of cancer.</p>
<p>The study was funded by the Howard Hughes Medical Institute, the National Institutes of Health (grants CA276167, CA163915, MH126720-01 and 5F31HD103339-03), the Mary Kay Foundation, the Schweitzer Family Fund, the SPARK Translational Research Program at Stanford University and Bio-X at Stanford University.</p>

</div>

</div>


    <div>






<ul>











<li>
    
    <div>
        
            <p>
                Rachel Tompa is a freelance science writer.
            </p>
        
    </div>
</li></ul>
</div>


    
  	  

      
    
      <p>About Stanford Medicine</p>
      <p><a href="https://med.stanford.edu/">Stanford Medicine</a> is an integrated academic health system comprising the <a href="https://med.stanford.edu/school.html">Stanford School of Medicine</a> and adult and pediatric health care delivery systems. Together, they harness the full potential of biomedicine through collaborative research, education and clinical care for patients. For more information, please visit <a href="https://med.stanford.edu/">med.stanford.edu</a>.</p>
    

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Hertz-dev, the first open-source base model for conversational audio (239 pts)]]></title>
            <link>https://si.inc/hertz-dev/</link>
            <guid>42036995</guid>
            <pubDate>Sun, 03 Nov 2024 23:30:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://si.inc/hertz-dev/">https://si.inc/hertz-dev/</a>, See on <a href="https://news.ycombinator.com/item?id=42036995">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    

    <article>
      <p>For the last few months, we at Standard Intelligence have focused on fundamental research on the frontier of audio-only speech generation. We're excited to announce that we're open-sourcing current checkpoints of our full-duplex, audio-only transformer base model, hertz-dev, with a total of 8.5 billion parameters.</p>

      <ul>
        <li><strong>hertz-codec:</strong> a convolutional audio autoencoder that takes mono, 16kHz speech and transforms it into a 8 Hz latent representation at about 1kbps bitrate. The codec at 1kbps outperforms Soundstream and Encodec at 6kbps and is on par with DAC at 8kbps in subjective evaluations, while having lower tokens per second than any popular tokenizer, critical for language modeling. The codec has 5 million encoder parameters and 95 million decoder parameters.</li>
        <li><strong>hertz-vae:</strong> a 1.8 billion parameter transformer decoder which acts as a learned prior for the audio VAE. The model uses a context of 8192 sampled latent representations (17 minutes) and predicts the next encoded audio frame as a mixture of gaussians. 15 bits of quantized information from the next token act as semantic scaffolding to steer the generation in a streamable manner.</li>
        <li><strong>hertz-dev:</strong> a 6.6 billion parameter transformer stack. The primary checkpoint is partially initialized from the weights of a pre-trained language model and then trained for a single epoch on 500B tokens with a 2048-token (4 minute) context length. We're also publishing an ablation of the language model initialization which is similarly trained on 500B tokens.</li>
      </ul>

      <p>Hertz-dev is the first publicly released audio base model of its kind. Base models are uniquely valuable as a research product because they accurately model the distribution of the data that they were trained on, as opposed to models that have had substantial RL tuning done to collapse their generation distributions. This makes base models the best starting point to fine-tune for a large number of different tasks.</p>

      <p>Hertz-dev has a theoretical latency of 65ms and a real-world average latency of 120ms on a RTX 4090. This is about 2x lower latency than any public model in the world—a prerequisite for a model that can interact with you in human-like ways instead of what feels like a delayed, choppy phone call. We're currently training a larger, more advanced version of Hertz, which will use a scaled base model recipe and RL tuning to substantially improve the raw capabilities and final coherence of the model. Hertz-dev is a glimpse at the future of real-time voice interaction, and is the easiest conversational audio model in the world for researchers to fine-tune and build on top of.</p>

      <h2>Sample Generations</h2>
      <p>To demonstrate the audio modeling capabilities of hertz-dev, we sample both one-channel and two-channel generations as well as a live conversation between the model and a human.</p>

      <h3>One-channel generation</h3>
      <div>
          <p><audio controls="">
            <source src="https://publicr2.si.inc/hertz-dev/generations/as_an_assistant.wav" type="audio/wav">
            Your browser does not support the audio element.
          </audio></p><p>2 seconds prompt.</p>
        </div>

      <h3>Two-channel generation</h3>
      <div>
          <div>
            <p><audio controls="">
                <source src="https://publicr2.si.inc/hertz-dev/generations/counting.wav" type="audio/wav">
                Your browser does not support the audio element.
              </audio>
            </p>
          </div>
          <p>22 seconds prompt.</p>
        </div>

      <h3>Interactive generation</h3>
      <div>
          <p><audio controls="">
            <source src="https://publicr2.si.inc/hertz-dev/generations/ai_talk.wav" type="audio/wav">
            Your browser does not support the audio element.
          </audio></p><p>9 seconds prompt.</p>
        </div>

      
    </article>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why systemd is a problem for embedded Linux (198 pts)]]></title>
            <link>https://kevinboone.me/systemd_embedded.html</link>
            <guid>42036305</guid>
            <pubDate>Sun, 03 Nov 2024 21:42:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://kevinboone.me/systemd_embedded.html">https://kevinboone.me/systemd_embedded.html</a>, See on <a href="https://news.ycombinator.com/item?id=42036305">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">





<p><img src="https://kevinboone.me/img/tux_win.png"></p>
<p>The Internet is full of rants about systemd, and I don’t want this
post to be another one. Many of the complaints people make about it
don’t stand up to much scrutiny, even the technical ones; and many
complaints are not even technical. My particular interest in Linux is
primarily for embedded applications; and there, I suggest, systemd is
creating a potential (technical) problem. In this article I will try to
articulate what the problem is; but I have no solution to offer.</p>
<h2 id="recapping-the-last-ten-years">Recapping the last ten years</h2>
<p>systemd is a set of integrated applications concerned with system
management. It replaces not only the traditional <code>init</code>
process that brings up long-lived processes, but also much of the other
system infrastructure: user session management, device management,
logging, timing, and an increasing number of other functions.</p>
<p>The majority of Linux users are uninterested in the pros and cons of
systemd. A small number are violently opposed to it, and a small number
are violently opposed to those who are opposed to it. Nevertheless, most
mainstream Linux distributions have adopted it after a shorter (Fedora)
or longer (Debian) period of argument.</p>
<p>I think there’s little argument that the main target for systemd is a
general-purpose computer, with a modern, integrated graphical desktop
(Gnome, KDE). systemd does well in systems like this because it can
handle process initialization on demand and in parallel. This
potentially makes boot times faster, and keeps resource usage down,
because it isn’t necessary to start a lot of services that are used only
occasionally. I don’t think these advantages are the main reasons for
systemd’s widespread adoption (see below), but they’re certainly
important.</p>
<h2 id="embedded-linux-the-problem">Embedded Linux: the problem</h2>
<p>Unfortunately, what makes systemd good for general-purpose desktop
applications potentially makes it unsatisfactory for embedded Linux
systems. As an illustration, I’ll show some memory figures from the
Raspberry Pi 3B that’s currently on my workbench. The board is running
the DietPi Linux distribution – probably the best fully-maintained Pi
distribution, if you want a minimal system. Although DietPi uses systemd
(it has little alternative, as I’ll explain later) it doesn’t
necessarily use the full set of components. In fact, a minimal
installation of DietPi, for console operation, installs only the systemd
service manager (the ‘init’ process), the log daemon, and the
<code>udev</code> daemon.</p>
<p>This is the resource usage, as reported by <code>top</code>, for the
systemd init process (alone) on the Raspberry Pi 3B.</p>
<pre><code>    PID USER      PR  NI    VIRT    RES    SHR S  %CPU  %MEM
      1 root      20   0  168144  11404   8592 S   0.0   0.3</code></pre>
<p>systemd init is not a particularly greedy user of memory by
contemporary standards – its virtual address space is 168Mb, but only
~8Mb is currently mapped to RAM. That’s about 0.3% of the Pi 3’s 4Gb of
RAM. But here’s the same figures for SystemV <code>init</code>, on
exactly the same hardware:</p>
<pre><code>  PID USER      PR  NI    VIRT    RES    SHR S  %CPU  %MEM
    1 root      20   0    2744   1532   1436 S   0.0   0.2</code></pre>
<p>It’s <em>much</em> smaller. Just to be clear – I got the systemd
implementation and the SystemV init implementation from the same Debian
ARM binary repository. I haven’t used fiddly compiler optimizations or
anything like that, to bias the resource usage figures.</p>
<p>Now let’s look at the systemd logging daemon,
<code>systemd-journald</code>.</p>
<pre><code>  PID USER     PR  NI    VIRT    RES    SHR S  %CPU  %MEM     TIME+ COMMAND
    147 root   20   0   41508   7744   6652 S   0.0   0.2   0:12.05 systemd-jour+</code></pre>
<p>Again, it’s a small, but noticeable, user of the 4Gb RAM. And, for
comparison, these are the figures from my own <a href="https://github.com/kevinboone/syslogd-lite">syslogd-lite</a>,
which I wrote specifically for embedded applications.</p>
<pre><code> PID USER      PR  NI    VIRT    RES    SHR S  %CPU  %MEM     TIME+ COMMAND
  117 root     20   0    1976     72      0 S   0.0   0.0   0:00.00 syslogd</code></pre>
<p>Note that the memory and CPU usage of this logging daemon are both
essentially zero. This is an unfair comparison, in a way, because I
wrote syslogd-lite specifically to minimize resource usage, and it has
few features. But it shows that it’s plausible to write utilities
that<br>
target embedded systems specifically, and sometimes it’s necessary.
systemd does not do this, and was never intended to. Running a
general-purpose software set like systemd on minimal, embedded hardware
can’t be expected to be effective.</p>
<p>With care, though, a minimal installation of systemd <em>does</em>
run on a low-resource ARM board like the Pi 3. In fact, it will run on a
board with 1Gb RAM, perhaps even lower. But, as the RAM decreases, the
proportion of it occupied by systemd increases.</p>
<p>What’s less obvious is the effect on boot time of the use of systemd
init. Proponents of systemd argue – correctly, I think – that it
decreases boot time in the kinds of system for which it was designed.
But on my Pi 3 it increases boot time quite noticeably. That is, the
systemd ‘init’ process takes an extra half-second or so to start,
compared to SystemV init. Half a second isn’t much, but in an embedded
application I actually care about boot time. I couldn’t care less on my
desktop computers, because they spend most of their lives suspended. I
rarely actually reboot them.</p>
<p>The extra start-up time of the init process is the result, I guess,
of the additional size and complexity of the systemd executable. It’s
about 200kB in size itself, and dynamically links 26 other libraries.
SystemV init, on the same hardware, is 40kB, and links only the standard
C library. The additional complexity of systemd is not wasted: it’s
needed for the additional functionality that systemd offers, in its
intended environment. But this functionality is mostly not needed in an
embedded application, so the additional complexity of systemd is a cost
without a benefit.</p>
<p>I’ve found that most of the services that systemd replaces have an
alternative that is smaller, and faster to start, in an embedded
environment. Unfortunately, some of these services don’t <em>have</em>
an alternative any more.</p>
<h2 id="so-what">So what?</h2>
<p>I’m not obliged to run systemd on my Raspberry Pi systems and, in
fact, usually I do not. I build my own Linux installation, using
binaries that I cherry-pick from the Debian repositories, and code I
write myself. Most of the binaries work without systemd. Some complain
about not finding systemd, but work anyway. Some things don’t work
without systemd: the Gnome display manager, for example, as it is built
for the standard Raspberry Pi, won’t work. It can be made to work, but
you have to build it from source. How long it will continue to work,
even if built from source, is open to question. But I’m not going to be
running Gnome on an embedded Linux board, so I don’t see this as a
problem for my applications.</p>
<p>The more fundamental problem is that <em>the people who most like
systemd are distribution managers</em>. Sure, there are administrators
who like it, and defend it vigorously; but most end users and
administrators don’t really care. But for the maintainers of mainstream
Linux distributions, systemd is like Christmas. systemd works reasonably
well for a whole range of usage scenarios and, best of all, it all comes
in one bundle. So a distribution manager doesn’t have to maintain,
integrate, and support a whole bunch of system utilities from different
sources – systemd provides everything in one huge build.</p>
<p>There are just a few Linux distributions that don’t use systemd, and
they are not widely used. Maintaining them is difficult, with just a
handful of volunteers. All the large, commercial Linux providers have
moved to systemd.</p>
<p>Only Gentoo and its derivatives (so far as I know) make systemd
optional, with fully-supported alternatives. And even Gentoo can’t be
made 100% free of systemd – not in practice.</p>
<h2 id="is-it-even-practical-to-avoid-systemd-any-more">Is it even
practical to avoid systemd any more?</h2>
<p>Take, for example, the <code>udev</code> daemon. This service
monitors the kernel, and makes configuration changes when devices are
added and removed. It’s not an essential part of Linux, but it removes
the need for a whole heap of manual configuration.</p>
<p><em>At the time of writing there is no fully-featured
<code>udev</code> implementation outside of systemd</em>. The original
<code>udev</code> code was absorbed into the systemd project about ten
years ago. The Gentoo alternative <code>eudev</code> is no longer fully
maintained. At present, if your Linux distribution requires
<code>udev</code>, you’re forced to use the version from systemd. This
version can be used without the rest of systemd, but it nevertheless
does systemd operations. In particular, it tries to communicate with
systemd over DBus. This communication (so far) fails gracefully if
systemd is not present, but it’s not clear how long this will continue
to be the case.</p>
<p>systemd is a tightly-coupled set of services. I don’t think a design
goal of the systemd maintainers is to make its components modular.
<code>udev</code> doesn’t need to talk to systemd but, clearly, there’s
some benefit to its doing so in a systemd installation. I understand
that there was a kind of ‘gentlemen’s agreement’ between the systemd
maintainers and the Gentoo maintainers, to keep <code>udev</code>
independent of the rest of systemd. I think we can see that this
agreement has broken down a little already; I suspect it will break down
more, if the systemd folks think that tighter integration will make
systemd work better.</p>
<p>Many parts of systemd continue – for now – to have non-systemd
alternatives. For example, systemd has a clock synchronizer
<code>systemd_systemtimed</code>. The systemd maintainers are perfectly
honest that this software lacks features that exist in alternatives like
Chrony and OpenNTPD, and it’s less accurate. <code>systemd_timed</code>
is included because it’s fast to start, and satisfactory for
applications where exact time synchronization is not critical.</p>
<p>At present, Chrony remains widely used, even in some distributions
(like Fedora) that use systemd. But with systemd becoming ubiquitous,
what motivation will there be to maintain non-systemd alternatives?
These alternatives could fall into disrepair, even though some are
superior to the systemd utilities – and even the systemd maintainers
admit this.</p>
<p>Similarly, systemd has a DHCP client. It isn’t the only DHCP client
that is available, but my concern is that one day it might be. In my
tests, I’ve found that the systemd components are larger, and slower to
start, than the traditional alternatives (where they still exist).
Again, this isn’t a criticism of systemd itself – I’m testing them in an
environment they were not designed for.</p>
<h2 id="so-where-does-that-leave-embedded-linux">So where does that
leave embedded Linux?</h2>
<p>I’ve found that many systemd components are less effective in an
embedded environment than the traditional alternatives. I’ve shown some
illustrative examples in this article, but I really don’t think there’s
much controversy here: this simply isn’t the environment that systemd
was designed for. But it’s getting increasingly difficult to find a
mainstream Linux distribution that doesn’t use systemd – even Raspberry
Pi distributions use it. As systemd absorbs more functionality into
itself, there’s going to be little motivation to maintain alternatives.
After all, if everybody uses systemd, what motivation is there to
support anything else? My concern is that we’re moving towards a future
where Linux is inconceivable without systemd. That will be a problem for
those environments where systemd really doesn’t shine.</p>
<p>I wish I knew the solution to this problem. There’s no point
complaining about systemd, because distribution maintainers have grown
to like it too much. And, in any event, well-reasoned, technical
concerns are drowned out by all the ranting and conspiracy theories. All
we can do – if we care – is to continue to use and support Linux
distributions that don’t insist on systemd, and stand ready to develop
or maintain alternatives to those bits of Linux that it absorbs.</p>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Do you need Redis? PostgreSQL does queuing, locking, and pub/sub (190 pts)]]></title>
            <link>https://spin.atomicobject.com/redis-postgresql/</link>
            <guid>42036303</guid>
            <pubDate>Sun, 03 Nov 2024 21:42:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://spin.atomicobject.com/redis-postgresql/">https://spin.atomicobject.com/redis-postgresql/</a>, See on <a href="https://news.ycombinator.com/item?id=42036303">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

					<p>There’s a tried-and-true architecture that I’ve seen many times for supporting your web services and applications:</p>
<ul id="condensed">
<li>PostgreSQL for data storage</li>
<li>Redis for coordinating background job queues (and some limited atomic operations)</li>
</ul>
<p>Redis is fantastic, but what if I told you that its most common use cases for this stack could actually be achieved using only PostgreSQL?</p>
<h2 id="use-case-1-job-queuing">Use Case 1: Job Queuing</h2>
<p>Perhaps the most common use of Redis I’ve seen is to coordinate dispatching of jobs from your web service to a pool of background workers. The concept is that you’d like to record the desire for some background job to be performed (perhaps with some input data) and to ensure that only one of your many background workers will pick it up. Redis helps with this because it provides a rich set of atomic operations for its data structures.</p>
<p>But since the introduction of version 9.5, PostgreSQL has a&nbsp;<code>SKIP LOCKED</code>&nbsp;option for the&nbsp;<code>SELECT ... FOR ...</code>statement (<a href="https://www.postgresql.org/docs/9.5/sql-select.html#SQL-FOR-UPDATE-SHARE">here’s the documentation</a>). When this option is specified, PostgreSQL will just ignore any rows that would require waiting for a lock to be released.</p>
<p>Consider this example from the perspective of a background worker:</p>
<pre><code>
BEGIN;

WITH job AS (
  SELECT
    id
  FROM
    jobs
  WHERE
    status = 'pending'
  LIMIT 1
  FOR UPDATE SKIP LOCKED
)
UPDATE
  jobs
SET
  status = 'running'
WHERE
  jobs.id = job.id
RETURNING
  jobs.*;
  
COMMIT;
</code></pre>

<p>By specifying&nbsp;<code>FOR UPDATE SKIP LOCKED</code>, a row-level lock is implicitly acquired for any rows returned from the&nbsp;<code>SELECT</code>. Further, because you specified&nbsp;<code>SKIP LOCKED</code>, there’s no chance of this statement blocking on another transaction. If there’s another job ready to be processed, it will be returned. There’s no concern about multiple workers running this command receiving the same row because of the row-level lock.</p>
<p>The biggest caveat for this technique is that, if you have a large number of workers trying to pull off this queue and a large number of jobs feeding them, they may spend some time stepping through jobs and trying to acquire a lock. In practice, most of the apps I’ve worked on have fewer than a dozen background workers, and the cost is not likely to be significant.</p>
<h2 id="use-case-2-application-locks">Use Case 2: Application Locks</h2>
<p>Let’s imagine that you have a synchronization routine with a third-party service, and you only want one instance of it running for any given user across all server processes. This is another common application I’ve seen for Redis: distributed locking.</p>
<p>PostgreSQL can achieve this as well using its&nbsp;<a href="https://www.postgresql.org/docs/9.2/explicit-locking.html#ADVISORY-LOCKS">advisory locks</a>. Advisory locks allow you to leverage the same locking engine PostgreSQL uses internally for your own application-defined purposes.</p>
<h2 id="use-case-3-pub-sub">Use Case 3: Pub/Sub</h2>
<p>I saved the coolest example for last: pushing events to your active clients. For example, say you need to notify a user that they have a new message available to read. Or perhaps you’d like to stream data to the client as it becomes available. Typically, web sockets are the transport layer for these events while Redis serves as the Pub/Sub engine.</p>
<p>However, since version 9, PostgreSQL also provides this functionality via the&nbsp;<a href="https://www.postgresql.org/docs/9.0/sql-listen.html"><code>LISTEN</code></a>&nbsp;and&nbsp;<a href="https://www.postgresql.org/docs/9.0/sql-notify.html"><code>NOTIFY</code></a>&nbsp;statements. Any PostgreSQL client can subscribe (<code>LISTEN</code>) to a particular message channel, which is just an arbitrary string. When any other client sends a message (<code>NOTIFY</code>) on that channel, all other subscribed clients will be notified. Optionally, a small message can be attached.</p>
<p>If you happen to be using Rails and ActionCable, using PostgreSQL is even supported out of the box.</p>
<h2 id="taking-full-advantage-of-postgresql">Taking Full Advantage of PostgreSQL</h2>
<p>Redis fundamentally fills a different niche than PostgreSQL and excels at things PostgreSQL doesn’t aspire to. Examples include caching data with TTLs and storing and manipulating ephemeral data.</p>
<p>However, PostgreSQL has a lot more capabilities than you may expect when you approach it from the perspective of just another SQL database or some mysterious entity that lives behind your ORM.</p>
<p>There’s a good chance that the things you’re using Redis for may actually be good tasks for PostgreSQL as well. It may be a worthy tradeoff to skip Redis and save on the operational costs and development complexity of relying on multiple data services.</p>

					



				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Tinder, but to Decide What to Eat (211 pts)]]></title>
            <link>https://whatdinner.com/</link>
            <guid>42036041</guid>
            <pubDate>Sun, 03 Nov 2024 20:56:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://whatdinner.com/">https://whatdinner.com/</a>, See on <a href="https://news.ycombinator.com/item?id=42036041">Hacker News</a></p>
<div id="readability-page-1" class="page"><div> <div> <div> <h2>
Swipe together - dine together
</h2>  <div> <p>
WhatDinner makes it easy for couples to <b>decide</b> on a meal <b>together</b>.
</p> <p>
Our simple <b>meal planning</b> interface is designed for couples who enjoy cooking dinner as a team.
</p> <p><a href="https://apps.apple.com/us/app/meal-planner-dinner-ideas/id6451110287"> <img src="https://whatdinner.com/images/appstore.svg"> </a> </p> </div> </div> <p><img src="https://whatdinner.com/images/screenshot.webp" alt="Hero image"></p> </div> <div> <div> <p><img src="https://whatdinner.com/images/frequency_screenshot.webp"> </p> <div> <h3>Recipe Manager</h3> <p>Manage your recipes and see at a glance how often you want to prepare them.</p> </div> </div> <div> <div> <h3>Frequency</h3> <p>Decide how often you'd like to prepare your own recipe. We respect and integrate your preferences for each day.</p> </div> <p><img src="https://whatdinner.com/images/recipes_screenshot.webp"> </p> </div> </div> <!--<div class="py-24 shadow">--> <!--  <div class="max-w-4xl mx-auto gap-2">--> <!--    <div class="pb-8 text-center">--> <!--      <h2 class="text-3xl text-comfortaa ">Decide Together</h2>--> <!--    </div>--> <!--    <div class="grid grid-cols-2">--> <!--      <div class="grid grid-cols-2 gap-4">--> <!--        <video width="886" height="1920" class="max-h-[500px]" autoplay muted>--> <!--          <source src="/videos/new_video.mp4" type="video/mp4">--> <!--          Your browser does not support the video tag.--> <!--        </video>--> <!--        <div>--> <!--          This works--> <!--        </div>--> <!--      </div>--> <!--    </div>--> <!--  </div>--> <!--</div>--> <div> <h2>
Start Deciding <br> Together
</h2> <div> <p><a href="https://apps.apple.com/us/app/meal-planner-dinner-ideas/id6451110287"> <img src="https://whatdinner.com/images/appstore.svg"> </a> </p> </div> </div>  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Hacker News Data Map [180MB] (179 pts)]]></title>
            <link>https://lmcinnes.github.io/datamapplot_examples/hackernews/</link>
            <guid>42035981</guid>
            <pubDate>Sun, 03 Nov 2024 20:45:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lmcinnes.github.io/datamapplot_examples/hackernews/">https://lmcinnes.github.io/datamapplot_examples/hackernews/</a>, See on <a href="https://news.ycombinator.com/item?id=42035981">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="title-container">
      <p><span>
        Hackernews Data Map
      </span>
      <br>
      <span>
        A Map of stories on Hackernews using UMAP and nomic-embed
      </span></p>
      
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Project Sid: Many-agent simulations toward AI civilization (365 pts)]]></title>
            <link>https://github.com/altera-al/project-sid</link>
            <guid>42035319</guid>
            <pubDate>Sun, 03 Nov 2024 19:09:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/altera-al/project-sid">https://github.com/altera-al/project-sid</a>, See on <a href="https://news.ycombinator.com/item?id=42035319">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><details open="">
  <summary>
    
    <span aria-label="Video description projectSidVideo.mp4">projectSidVideo.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/111396834/382341315-a288265d-03ac-4d7d-b803-b74066267f26.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzA2Njk3MDMsIm5iZiI6MTczMDY2OTQwMywicGF0aCI6Ii8xMTEzOTY4MzQvMzgyMzQxMzE1LWEyODgyNjVkLTAzYWMtNGQ3ZC1iODAzLWI3NDA2NjI2N2YyNi5tcDQ_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQxMTAzJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MTEwM1QyMTMwMDNaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT02NGM2YzJiNmFkOTYwMDM0Mzg5YTAyNTE0ZjZiMWMzN2UyZjBmZjg4YmIxZmRmNGJjNDRjOTgwMWFmZjM3ODAwJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.hbGHlPwv3Z1lEvS_fBAVSiCpEuPu0ZfI9L5-vJyZ2Co" data-canonical-src="https://private-user-images.githubusercontent.com/111396834/382341315-a288265d-03ac-4d7d-b803-b74066267f26.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzA2Njk3MDMsIm5iZiI6MTczMDY2OTQwMywicGF0aCI6Ii8xMTEzOTY4MzQvMzgyMzQxMzE1LWEyODgyNjVkLTAzYWMtNGQ3ZC1iODAzLWI3NDA2NjI2N2YyNi5tcDQ_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQxMTAzJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MTEwM1QyMTMwMDNaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT02NGM2YzJiNmFkOTYwMDM0Mzg5YTAyNTE0ZjZiMWMzN2UyZjBmZjg4YmIxZmRmNGJjNDRjOTgwMWFmZjM3ODAwJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.hbGHlPwv3Z1lEvS_fBAVSiCpEuPu0ZfI9L5-vJyZ2Co" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto"><h2 tabindex="-1" dir="auto">Project Sid: Many-agent simulations toward AI civilization</h2><a id="user-content-project-sid-many-agent-simulations-toward-ai-civilization" aria-label="Permalink: Project Sid: Many-agent simulations toward AI civilization" href="#project-sid-many-agent-simulations-toward-ai-civilization"></a></p>
<p dir="auto">This repository contains our technical report: "Project Sid: Many-agent simulations toward AI civilization"</p>
<p dir="auto">To appear on arXiv.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Abstract</h2><a id="user-content-abstract" aria-label="Permalink: Abstract" href="#abstract"></a></p>
<p dir="auto">AI agents have been evaluated in isolation or within small groups, where interactions remain limited in scope and complexity. Large-scale simulations involving many autonomous agents—reflecting the full spectrum of civilizational processes—have yet to be explored. Here, we demonstrate how 10 – 1000+ AI agents behave and progress within agent societies. We first introduce the PIANO (Parallel Information Aggregation via Neu- ral Orchestration) architecture, which enables agents to interact with humans and other agents in real-time while maintaining coherence across multiple output streams. We then evaluate agent performance in large- scale simulations using civilizational benchmarks inspired by human history. These simulations, set within a Minecraft environment, reveal that agents are capable of meaningful progress—autonomously developing specialized roles, adhering to and changing collective rules, and engaging in cultural and religious transmis- sion. These preliminary results show that agents can achieve significant milestones towards AI civilizations, opening new avenues for large-scale societal simulations, agentic organizational intelligence, and integrating AI into human civilizations.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/altera-al/project-sid/blob/main/visual_abstract.png"><img src="https://github.com/altera-al/project-sid/raw/main/visual_abstract.png" width="1200"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Paper</h2><a id="user-content-paper" aria-label="Permalink: Paper" href="#paper"></a></p>
<p dir="auto">The paper is available in two locations:</p>
<ul dir="auto">
<li>arXiv: To appear</li>
<li>PDF: <a href="https://github.com/altera-al/project-sid/blob/main/2024-10-31.pdf">2024-10-31.pdf</a> (in this repository)</li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[gptel: a simple LLM client for Emacs (145 pts)]]></title>
            <link>https://github.com/karthink/gptel</link>
            <guid>42034675</guid>
            <pubDate>Sun, 03 Nov 2024 17:52:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/karthink/gptel">https://github.com/karthink/gptel</a>, See on <a href="https://news.ycombinator.com/item?id=42034675">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">gptel: A simple LLM client for Emacs</h2><a id="user-content-gptel-a-simple-llm-client-for-emacs" aria-label="Permalink: gptel: A simple LLM client for Emacs" href="#gptel-a-simple-llm-client-for-emacs"></a></p>
<p dir="auto"><a href="https://elpa.nongnu.org/nongnu/gptel.svg" rel="nofollow"><img src="https://camo.githubusercontent.com/4b6f2590c77fa98a45d56fbea0332e8d9844f89a8524ad078621a9c638e6b523/68747470733a2f2f656c70612e6e6f6e676e752e6f72672f6e6f6e676e752f677074656c2e737667" alt="https://elpa.nongnu.org/nongnu/gptel.svg" data-canonical-src="https://elpa.nongnu.org/nongnu/gptel.svg"></a> <a href="https://stable.melpa.org/packages/gptel-badge.svg" rel="nofollow"><img src="https://camo.githubusercontent.com/c595cbac5099d30bb5ce893a701f6bbcd5b99948bca3ce42201938b5ab501845/68747470733a2f2f737461626c652e6d656c70612e6f72672f7061636b616765732f677074656c2d62616467652e737667" alt="https://stable.melpa.org/packages/gptel-badge.svg" data-canonical-src="https://stable.melpa.org/packages/gptel-badge.svg"></a> <a href="https://melpa.org/#/gptel" rel="nofollow"><img src="https://camo.githubusercontent.com/c607e4545b94060506a5b0f88e06c62839e09a256a49e8ed68780706a411fa99/68747470733a2f2f6d656c70612e6f72672f7061636b616765732f677074656c2d62616467652e737667" alt="https://melpa.org/packages/gptel-badge.svg" data-canonical-src="https://melpa.org/packages/gptel-badge.svg"></a></p>
<p dir="auto">gptel is a simple Large Language Model chat client for Emacs, with support for multiple models and backends.  It works in the spirit of Emacs, available at any time and uniformly in any buffer.</p>

<p dir="auto"><b>General usage</b>: (<a href="https://www.youtube.com/watch?v=bsRnh_brggM" rel="nofollow">YouTube Demo</a>)</p>
<details open="">
  <summary>
    
    <span aria-label="Video description intro-demo.mp4">intro-demo.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/8607532/230516812-86510a09-a2fb-4cbd-b53f-cc2522d05a13.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzA3MDIxMDEsIm5iZiI6MTczMDcwMTgwMSwicGF0aCI6Ii84NjA3NTMyLzIzMDUxNjgxMi04NjUxMGEwOS1hMmZiLTRjYmQtYjUzZi1jYzI1MjJkMDVhMTMubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MTEwNCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDExMDRUMDYzMDAxWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9YzNiNzM3ZDA2OGMzZTRiZjI3MDE4NjEzOTEyNTA5ODg4NmUyMTU4MTU3MjgwNTc5MzljNGQ1Mjg1YmRkN2VlYSZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.YRahKfgJxYSMeDSRF-nr_fN3GF9L4TTLm5TpM70o8tE" data-canonical-src="https://private-user-images.githubusercontent.com/8607532/230516812-86510a09-a2fb-4cbd-b53f-cc2522d05a13.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzA3MDIxMDEsIm5iZiI6MTczMDcwMTgwMSwicGF0aCI6Ii84NjA3NTMyLzIzMDUxNjgxMi04NjUxMGEwOS1hMmZiLTRjYmQtYjUzZi1jYzI1MjJkMDVhMTMubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MTEwNCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDExMDRUMDYzMDAxWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9YzNiNzM3ZDA2OGMzZTRiZjI3MDE4NjEzOTEyNTA5ODg4NmUyMTU4MTU3MjgwNTc5MzljNGQ1Mjg1YmRkN2VlYSZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.YRahKfgJxYSMeDSRF-nr_fN3GF9L4TTLm5TpM70o8tE" controls="controls" muted="muted">

  </video>
</details>

<details open="">
  <summary>
    
    <span aria-label="Video description intro-demo-2.mp4">intro-demo-2.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/8607532/230516816-ae4a613a-4d01-4073-ad3f-b66fa73c6e45.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzA3MDIxMDEsIm5iZiI6MTczMDcwMTgwMSwicGF0aCI6Ii84NjA3NTMyLzIzMDUxNjgxNi1hZTRhNjEzYS00ZDAxLTQwNzMtYWQzZi1iNjZmYTczYzZlNDUubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MTEwNCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDExMDRUMDYzMDAxWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9NzQ4Yjg3OTQyN2ZhYTkwZGFhNjIyNTlkYjk5OWZhZDBlNWUyYjVmNjIyNGQzZWFiZGJmYWM2MTRjODQ5OTcyOSZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.wSkWb8mu7PCGMK8s0RJPCNh0A-1_8meHG2hByRGf2Dk" data-canonical-src="https://private-user-images.githubusercontent.com/8607532/230516816-ae4a613a-4d01-4073-ad3f-b66fa73c6e45.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzA3MDIxMDEsIm5iZiI6MTczMDcwMTgwMSwicGF0aCI6Ii84NjA3NTMyLzIzMDUxNjgxNi1hZTRhNjEzYS00ZDAxLTQwNzMtYWQzZi1iNjZmYTczYzZlNDUubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MTEwNCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDExMDRUMDYzMDAxWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9NzQ4Yjg3OTQyN2ZhYTkwZGFhNjIyNTlkYjk5OWZhZDBlNWUyYjVmNjIyNGQzZWFiZGJmYWM2MTRjODQ5OTcyOSZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.wSkWb8mu7PCGMK8s0RJPCNh0A-1_8meHG2hByRGf2Dk" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto"><b>Media support</b></p>
<details open="">
  <summary>
    
    <span aria-label="Video description gptel-image-demo-1.mp4">gptel-image-demo-1.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/8607532/375931228-1fd947e1-226b-4be2-bc68-7b22b2e3215f.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzA3MDIxMDEsIm5iZiI6MTczMDcwMTgwMSwicGF0aCI6Ii84NjA3NTMyLzM3NTkzMTIyOC0xZmQ5NDdlMS0yMjZiLTRiZTItYmM2OC03YjIyYjJlMzIxNWYubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MTEwNCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDExMDRUMDYzMDAxWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9MmUwNDAwZjkzNmM5ZTNmM2NhNjE0NDVlNTBiOTIwNWQ1MTNmMzcwOTVkMmIyMjY1Y2QxMDIxZjc3MjBhOWI0ZCZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.U57pAV_5dvq59O388Fk6DvdZO2dt4bjdxS3ZggIQzmo" data-canonical-src="https://private-user-images.githubusercontent.com/8607532/375931228-1fd947e1-226b-4be2-bc68-7b22b2e3215f.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzA3MDIxMDEsIm5iZiI6MTczMDcwMTgwMSwicGF0aCI6Ii84NjA3NTMyLzM3NTkzMTIyOC0xZmQ5NDdlMS0yMjZiLTRiZTItYmM2OC03YjIyYjJlMzIxNWYubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MTEwNCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDExMDRUMDYzMDAxWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9MmUwNDAwZjkzNmM5ZTNmM2NhNjE0NDVlNTBiOTIwNWQ1MTNmMzcwOTVkMmIyMjY1Y2QxMDIxZjc3MjBhOWI0ZCZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.U57pAV_5dvq59O388Fk6DvdZO2dt4bjdxS3ZggIQzmo" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto"><b>Multi-LLM support demo</b>:</p>
<details open="">
  <summary>
    
    <span aria-label="Video description gptel-multi.mp4">gptel-multi.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/8607532/278854024-ae1336c4-5b87-41f2-83e9-e415349d6a43.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzA3MDIxMDEsIm5iZiI6MTczMDcwMTgwMSwicGF0aCI6Ii84NjA3NTMyLzI3ODg1NDAyNC1hZTEzMzZjNC01Yjg3LTQxZjItODNlOS1lNDE1MzQ5ZDZhNDMubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MTEwNCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDExMDRUMDYzMDAxWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9NjQ3MjA1M2U2ZTQ4YTdhYzAzMDQwMGQxMjk0NmNlNGVkZTE0MDZkZjExNTMwZGNmNjdmMTViNTcwY2NlNTAxNCZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.lQt2mdFFAu_Dlblp9agyCKtSSZwLSfDrOOW7coqJBhg" data-canonical-src="https://private-user-images.githubusercontent.com/8607532/278854024-ae1336c4-5b87-41f2-83e9-e415349d6a43.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzA3MDIxMDEsIm5iZiI6MTczMDcwMTgwMSwicGF0aCI6Ii84NjA3NTMyLzI3ODg1NDAyNC1hZTEzMzZjNC01Yjg3LTQxZjItODNlOS1lNDE1MzQ5ZDZhNDMubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MTEwNCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDExMDRUMDYzMDAxWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9NjQ3MjA1M2U2ZTQ4YTdhYzAzMDQwMGQxMjk0NmNlNGVkZTE0MDZkZjExNTMwZGNmNjdmMTViNTcwY2NlNTAxNCZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.lQt2mdFFAu_Dlblp9agyCKtSSZwLSfDrOOW7coqJBhg" controls="controls" muted="muted">

  </video>
</details>

<ul dir="auto">
  <li>It’s async and fast, streams responses.</li>
  <li>Interact with LLMs from anywhere in Emacs (any buffer, shell, minibuffer, wherever)</li>
  <li>LLM responses are in Markdown or Org markup.</li>
  <li>Supports multiple independent conversations and one-off ad hoc interactions.</li>
  <li>Supports multi-modal models (include images, documents)</li>
  <li>Save chats as regular Markdown/Org/Text files and resume them later.</li>
  <li>You can go back and edit your previous prompts or LLM responses when continuing a conversation. These will be fed back to the model.</li>
  <li>Don’t like gptel’s workflow? Use it to create your own for any supported model/backend with a <a href="https://github.com/karthink/gptel/wiki/Defining-custom-gptel-commands">simple API</a>.</li>
</ul>
<p dir="auto">gptel uses Curl if available, but falls back to url-retrieve to work without external dependencies.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contents</h2><a id="user-content-contents" aria-label="Permalink: Contents" href="#contents"></a></p>
<ul dir="auto">
  <li><a href="#breaking-changes">Breaking changes!</a></li>
  <li><a href="#installation">Installation</a>
    <ul dir="auto">
      <li><a href="#straight">Straight</a></li>
      <li><a href="#manual">Manual</a></li>
      <li><a href="#doom-emacs">Doom Emacs</a></li>
      <li><a href="#spacemacs">Spacemacs</a></li>
    </ul>
  </li>
  <li><a href="#setup">Setup</a>
    <ul dir="auto">
      <li><a href="#chatgpt">ChatGPT</a></li>
      <li><a href="#other-llm-backends">Other LLM backends</a>
        <ul dir="auto">
          <li><a href="#azure">Azure</a></li>
          <li><a href="#gpt4all">GPT4All</a></li>
          <li><a href="#ollama">Ollama</a></li>
          <li><a href="#gemini">Gemini</a></li>
          <li><a href="#llamacpp-or-llamafile">Llama.cpp or Llamafile</a></li>
          <li><a href="#kagi-fastgpt--summarizer">Kagi (FastGPT &amp; Summarizer)</a></li>
          <li><a href="#togetherai">together.ai</a></li>
          <li><a href="#anyscale">Anyscale</a></li>
          <li><a href="#perplexity">Perplexity</a></li>
          <li><a href="#anthropic-claude">Anthropic (Claude)</a></li>
          <li><a href="#groq">Groq</a></li>
          <li><a href="#openrouter">OpenRouter</a></li>
          <li><a href="#privategpt">PrivateGPT</a></li>
          <li><a href="#deepseek">DeepSeek</a></li>
          <li><a href="#cerebras">Cerebras</a></li>
          <li><a href="#github-models">Github Models</a></li>
          <li><a href="#novita-ai">Novita AI</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#usage">Usage</a>
    <ul dir="auto">
      <li><a href="#in-any-buffer">In any buffer:</a></li>
      <li><a href="#in-a-dedicated-chat-buffer">In a dedicated chat buffer:</a>
        <ul dir="auto">
          <li><a href="#including-media-images-documents-with-requests">Including media (images, documents) with requests</a></li>
          <li><a href="#save-and-restore-your-chat-sessions">Save and restore your chat sessions</a></li>
        </ul>
      </li>
      <li><a href="#include-more-context-with-requests">Include more context with requests</a></li>
      <li><a href="#rewrite-refactor-or-fill-in-a-region">Rewrite, refactor or fill in a region</a></li>
      <li><a href="#extra-org-mode-conveniences">Extra Org mode conveniences</a></li>
    </ul>
  </li>
  <li><a href="#faq">FAQ</a>
    <ul dir="auto">
      <li><a href="#i-want-the-window-to-scroll-automatically-as-the-response-is-inserted">I want the window to scroll automatically as the response is inserted</a></li>
      <li><a href="#i-want-the-cursor-to-move-to-the-next-prompt-after-the-response-is-inserted">I want the cursor to move to the next prompt after the response is inserted</a></li>
      <li><a href="#i-want-to-change-the-formatting-of-the-prompt-and-llm-response">I want to change the formatting of the prompt and LLM response</a></li>
      <li><a href="#i-want-the-transient-menu-options-to-be-saved-so-i-only-need-to-set-them-once">I want the transient menu options to be saved so I only need to set them once</a></li>
      <li><a href="#i-want-to-use-gptel-in-a-way-thats-not-supported-by-gptel-send-or-the-options-menu">I want to use gptel in a way that’s not supported by <code>gptel-send</code> or the options menu</a></li>
      <li><a href="#doom-emacs-sending-a-query-from-the-gptel-menu-fails-because-of-a-key-conflict-with-org-mode">(Doom Emacs) Sending a query from the gptel menu fails because of a key conflict with Org mode</a></li>
      <li><a href="#chatgpt-i-get-the-error-http2-429-you-exceeded-your-current-quota">(ChatGPT) I get the error “(HTTP/2 429) You exceeded your current quota”</a></li>
      <li><a href="#why-another-llm-client">Why another LLM client?</a></li>
    </ul>
  </li>
  <li><a href="#additional-configuration">Additional Configuration</a></li>
  <li><a href="#alternatives">Alternatives</a>
    <ul dir="auto">
      <li><a href="#packages-using-gptel">Packages using gptel</a></li>
    </ul>
  </li>
  <li><a href="#acknowledgments">Acknowledgments</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Breaking changes!</h2><a id="user-content-breaking-changes" aria-label="Permalink: Breaking changes!" href="#breaking-changes"></a></p>
<ul dir="auto">
  <li><code>gptel-model</code> is now expected to be a symbol, not a string.  Please update your configuration.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto">gptel can be installed in Emacs out of the box with <code>M-x package-install</code> ⏎ <code>gptel</code>.  This installs the latest commit.</p>
<p dir="auto">If you want the stable version instead, add NonGNU-devel ELPA or MELPA-stable to your list of package sources (<code>package-archives</code>), then install gptel with <code>M-x package-install⏎</code> <code>gptel</code> from these sources.</p>
<p dir="auto">(Optional: Install <code>markdown-mode</code>.)</p>
<details><summary>
<p dir="auto"><h4 tabindex="-1" dir="auto">Straight</h4><a id="user-content-straight" aria-label="Permalink: Straight" href="#straight"></a></p>
</summary>
<div dir="auto" data-snippet-clipboard-copy-content="(straight-use-package 'gptel)"><pre>(<span>straight-use-package</span> <span>'gptel</span>)</pre></div>
<p dir="auto">Installing the <code>markdown-mode</code> package is optional.</p>
</details>
<details><summary>
<p dir="auto"><h4 tabindex="-1" dir="auto">Manual</h4><a id="user-content-manual" aria-label="Permalink: Manual" href="#manual"></a></p>
</summary>
<p dir="auto">Clone or download this repository and run <code>M-x package-install-file⏎</code> on the repository directory.</p>
<p dir="auto">Installing the <code>markdown-mode</code> package is optional.</p>
</details>
<details><summary>
<p dir="auto"><h4 tabindex="-1" dir="auto">Doom Emacs</h4><a id="user-content-doom-emacs" aria-label="Permalink: Doom Emacs" href="#doom-emacs"></a></p>
</summary>
<p dir="auto">In <code>packages.el</code></p>

<p dir="auto">In <code>config.el</code></p>
<div dir="auto" data-snippet-clipboard-copy-content="(use-package! gptel
 :config
 (setq! gptel-api-key &quot;your key&quot;))"><pre>(use-package! gptel
 <span>:config</span>
 (setq! gptel-api-key <span><span>"</span>your key<span>"</span></span>))</pre></div>
<p dir="auto">“your key” can be the API key itself, or (safer) a function that returns the key.  Setting <code>gptel-api-key</code> is optional, you will be asked for a key if it’s not found.</p>
</details>
<details><summary>
<p dir="auto"><h4 tabindex="-1" dir="auto">Spacemacs</h4><a id="user-content-spacemacs" aria-label="Permalink: Spacemacs" href="#spacemacs"></a></p>
</summary>
<p dir="auto">In your <code>.spacemacs</code> file, add <code>llm-client</code> to <code>dotspacemacs-configuration-layers</code>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="(llm-client :variables
            llm-client-enable-gptel t)"><pre>(llm-client <span>:variables</span>
            llm-client-enable-gptel <span>t</span>)</pre></div>
</details>
<p dir="auto"><h2 tabindex="-1" dir="auto">Setup</h2><a id="user-content-setup" aria-label="Permalink: Setup" href="#setup"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">ChatGPT</h3><a id="user-content-chatgpt" aria-label="Permalink: ChatGPT" href="#chatgpt"></a></p>
<p dir="auto">Procure an <a href="https://platform.openai.com/account/api-keys" rel="nofollow">OpenAI API key</a>.</p>
<p dir="auto">Optional: Set <code>gptel-api-key</code> to the key. Alternatively, you may choose a more secure method such as:</p>
<ul dir="auto">
  <li>Storing in <code>~/.authinfo</code>. By default, “api.openai.com” is used as HOST and “apikey” as USER.
    <pre lang="authinfo">machine api.openai.com login apikey password TOKEN
    </pre>
  </li>
  <li>Setting it to a function that returns the key.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Other LLM backends</h3><a id="user-content-other-llm-backends" aria-label="Permalink: Other LLM backends" href="#other-llm-backends"></a></p>
<details><summary>
<p dir="auto"><h4 tabindex="-1" dir="auto">Azure</h4><a id="user-content-azure" aria-label="Permalink: Azure" href="#azure"></a></p>
</summary>
<p dir="auto">Register a backend with</p>
<div dir="auto" data-snippet-clipboard-copy-content="(gptel-make-azure &quot;Azure-1&quot;             ;Name, whatever you'd like
  :protocol &quot;https&quot;                     ;Optional -- https is the default
  :host &quot;YOUR_RESOURCE_NAME.openai.azure.com&quot;
  :endpoint &quot;/openai/deployments/YOUR_DEPLOYMENT_NAME/chat/completions?api-version=2023-05-15&quot; ;or equivalent
  :stream t                             ;Enable streaming responses
  :key #'gptel-api-key
  :models '(gpt-3.5-turbo gpt-4))"><pre>(gptel-make-azure <span><span>"</span>Azure-1<span>"</span></span>             <span><span>;</span>Name, whatever you'd like</span>
  <span>:protocol</span> <span><span>"</span>https<span>"</span></span>                     <span><span>;</span>Optional -- https is the default</span>
  <span>:host</span> <span><span>"</span>YOUR_RESOURCE_NAME.openai.azure.com<span>"</span></span>
  <span>:endpoint</span> <span><span>"</span>/openai/deployments/YOUR_DEPLOYMENT_NAME/chat/completions?api-version=2023-05-15<span>"</span></span> <span><span>;</span>or equivalent</span>
  <span>:stream</span> <span>t</span>                             <span><span>;</span>Enable streaming responses</span>
  <span>:key</span> <span>#<span>'gptel-api-key</span></span>
  <span>:models</span> '(gpt-3.5-turbo gpt-4))</pre></div>
<p dir="auto">Refer to the documentation of <code>gptel-make-azure</code> to set more parameters.</p>
<p dir="auto">You can pick this backend from the menu when using gptel. (see <a href="#usage">Usage</a>).</p>
<p dir="auto"><h5 tabindex="-1" dir="auto">(Optional) Set as the default gptel backend</h5><a id="user-content-optional-set-as-the-default-gptel-backend" aria-label="Permalink: (Optional) Set as the default gptel backend" href="#optional-set-as-the-default-gptel-backend"></a></p>
<p dir="auto">The above code makes the backend available to select.  If you want it to be the default backend for gptel, you can set this as the value of <code>gptel-backend</code>.  Use this instead of the above.</p>
<div dir="auto" data-snippet-clipboard-copy-content=";; OPTIONAL configuration
(setq
 gptel-model 'gpt-3.5-turbo
 gptel-backend (gptel-make-azure &quot;Azure-1&quot;
                 :protocol &quot;https&quot;
                 :host &quot;YOUR_RESOURCE_NAME.openai.azure.com&quot;
                 :endpoint &quot;/openai/deployments/YOUR_DEPLOYMENT_NAME/chat/completions?api-version=2023-05-15&quot;
                 :stream t
                 :key #'gptel-api-key
                 :models '(gpt-3.5-turbo gpt-4)))"><pre><span><span>;</span>; OPTIONAL configuration</span>
(<span>setq</span>
 gptel-model <span>'gpt-3</span>.5-turbo
 gptel-backend (gptel-make-azure <span><span>"</span>Azure-1<span>"</span></span>
                 <span>:protocol</span> <span><span>"</span>https<span>"</span></span>
                 <span>:host</span> <span><span>"</span>YOUR_RESOURCE_NAME.openai.azure.com<span>"</span></span>
                 <span>:endpoint</span> <span><span>"</span>/openai/deployments/YOUR_DEPLOYMENT_NAME/chat/completions?api-version=2023-05-15<span>"</span></span>
                 <span>:stream</span> <span>t</span>
                 <span>:key</span> <span>#<span>'gptel-api-key</span></span>
                 <span>:models</span> '(gpt-3.5-turbo gpt-4)))</pre></div>
</details>
<details><summary>
<p dir="auto"><h4 tabindex="-1" dir="auto">GPT4All</h4><a id="user-content-gpt4all" aria-label="Permalink: GPT4All" href="#gpt4all"></a></p>
</summary>
<p dir="auto">Register a backend with</p>
<div dir="auto" data-snippet-clipboard-copy-content="(gptel-make-gpt4all &quot;GPT4All&quot;           ;Name of your choosing
 :protocol &quot;http&quot;
 :host &quot;localhost:4891&quot;                 ;Where it's running
 :models '(mistral-7b-openorca.Q4_0.gguf)) ;Available models"><pre>(gptel-make-gpt4all <span><span>"</span>GPT4All<span>"</span></span>           <span><span>;</span>Name of your choosing</span>
 <span>:protocol</span> <span><span>"</span>http<span>"</span></span>
 <span>:host</span> <span><span>"</span>localhost:4891<span>"</span></span>                 <span><span>;</span>Where it's running</span>
 <span>:models</span> '(mistral-7b-openorca.Q4_0.gguf)) <span><span>;</span>Available models</span></pre></div>
<p dir="auto">These are the required parameters, refer to the documentation of <code>gptel-make-gpt4all</code> for more.</p>
<p dir="auto">You can pick this backend from the menu when using gptel (see <a href="#usage">Usage</a>).</p>
<p dir="auto"><h5 tabindex="-1" dir="auto">(Optional) Set as the default gptel backend</h5><a id="user-content-optional-set-as-the-default-gptel-backend-1" aria-label="Permalink: (Optional) Set as the default gptel backend" href="#optional-set-as-the-default-gptel-backend-1"></a></p>
<p dir="auto">The above code makes the backend available to select.  If you want it to be the default backend for gptel, you can set this as the value of <code>gptel-backend</code>.  Use this instead of the above.  Additionally you may want to increase the response token size since GPT4All uses very short (often truncated) responses by default.</p>
<div dir="auto" data-snippet-clipboard-copy-content=";; OPTIONAL configuration
(setq
 gptel-max-tokens 500
 gptel-model 'mistral-7b-openorca.Q4_0.gguf
 gptel-backend (gptel-make-gpt4all &quot;GPT4All&quot;
                 :protocol &quot;http&quot;
                 :host &quot;localhost:4891&quot;
                 :models '(mistral-7b-openorca.Q4_0.gguf)))"><pre><span><span>;</span>; OPTIONAL configuration</span>
(<span>setq</span>
 gptel-max-tokens <span>500</span>
 gptel-model <span>'mistral-7b-openorca</span>.Q4_0.gguf
 gptel-backend (gptel-make-gpt4all <span><span>"</span>GPT4All<span>"</span></span>
                 <span>:protocol</span> <span><span>"</span>http<span>"</span></span>
                 <span>:host</span> <span><span>"</span>localhost:4891<span>"</span></span>
                 <span>:models</span> '(mistral-7b-openorca.Q4_0.gguf)))</pre></div>
</details>
<details><summary>
<p dir="auto"><h4 tabindex="-1" dir="auto">Ollama</h4><a id="user-content-ollama" aria-label="Permalink: Ollama" href="#ollama"></a></p>
</summary>
<p dir="auto">Register a backend with</p>
<div dir="auto" data-snippet-clipboard-copy-content="(gptel-make-ollama &quot;Ollama&quot;             ;Any name of your choosing
  :host &quot;localhost:11434&quot;               ;Where it's running
  :stream t                             ;Stream responses
  :models '(mistral:latest))          ;List of models"><pre>(gptel-make-ollama <span><span>"</span>Ollama<span>"</span></span>             <span><span>;</span>Any name of your choosing</span>
  <span>:host</span> <span><span>"</span>localhost:11434<span>"</span></span>               <span><span>;</span>Where it's running</span>
  <span>:stream</span> <span>t</span>                             <span><span>;</span>Stream responses</span>
  <span>:models</span> '(mistral:latest))          <span><span>;</span>List of models</span></pre></div>
<p dir="auto">These are the required parameters, refer to the documentation of <code>gptel-make-ollama</code> for more.</p>
<p dir="auto">You can pick this backend from the menu when using gptel (see <a href="#usage">Usage</a>)</p>
<p dir="auto"><h5 tabindex="-1" dir="auto">(Optional) Set as the default gptel backend</h5><a id="user-content-optional-set-as-the-default-gptel-backend-2" aria-label="Permalink: (Optional) Set as the default gptel backend" href="#optional-set-as-the-default-gptel-backend-2"></a></p>
<p dir="auto">The above code makes the backend available to select.  If you want it to be the default backend for gptel, you can set this as the value of <code>gptel-backend</code>.  Use this instead of the above.</p>
<div dir="auto" data-snippet-clipboard-copy-content=";; OPTIONAL configuration
(setq
 gptel-model 'mistral:latest
 gptel-backend (gptel-make-ollama &quot;Ollama&quot;
                 :host &quot;localhost:11434&quot;
                 :stream t
                 :models '(mistral:latest)))"><pre><span><span>;</span>; OPTIONAL configuration</span>
(<span>setq</span>
 gptel-model <span>'mistral:latest</span>
 gptel-backend (gptel-make-ollama <span><span>"</span>Ollama<span>"</span></span>
                 <span>:host</span> <span><span>"</span>localhost:11434<span>"</span></span>
                 <span>:stream</span> <span>t</span>
                 <span>:models</span> '(mistral:latest)))</pre></div>
</details>
<details><summary>
<p dir="auto"><h4 tabindex="-1" dir="auto">Gemini</h4><a id="user-content-gemini" aria-label="Permalink: Gemini" href="#gemini"></a></p>
</summary>
<p dir="auto">Register a backend with</p>
<div dir="auto" data-snippet-clipboard-copy-content=";; :key can be a function that returns the API key.
(gptel-make-gemini &quot;Gemini&quot; :key &quot;YOUR_GEMINI_API_KEY&quot; :stream t)"><pre><span><span>;</span>; :key can be a function that returns the API key.</span>
(gptel-make-gemini <span><span>"</span>Gemini<span>"</span></span> <span>:key</span> <span><span>"</span>YOUR_GEMINI_API_KEY<span>"</span></span> <span>:stream</span> <span>t</span>)</pre></div>
<p dir="auto">These are the required parameters, refer to the documentation of <code>gptel-make-gemini</code> for more.</p>
<p dir="auto">You can pick this backend from the menu when using gptel (see <a href="#usage">Usage</a>)</p>
<p dir="auto"><h5 tabindex="-1" dir="auto">(Optional) Set as the default gptel backend</h5><a id="user-content-optional-set-as-the-default-gptel-backend-3" aria-label="Permalink: (Optional) Set as the default gptel backend" href="#optional-set-as-the-default-gptel-backend-3"></a></p>
<p dir="auto">The above code makes the backend available to select.  If you want it to be the default backend for gptel, you can set this as the value of <code>gptel-backend</code>.  Use this instead of the above.</p>
<div dir="auto" data-snippet-clipboard-copy-content=";; OPTIONAL configuration
(setq
 gptel-model 'gemini-pro
 gptel-backend (gptel-make-gemini &quot;Gemini&quot;
                 :key &quot;YOUR_GEMINI_API_KEY&quot;
                 :stream t))"><pre><span><span>;</span>; OPTIONAL configuration</span>
(<span>setq</span>
 gptel-model <span>'gemini-pro</span>
 gptel-backend (gptel-make-gemini <span><span>"</span>Gemini<span>"</span></span>
                 <span>:key</span> <span><span>"</span>YOUR_GEMINI_API_KEY<span>"</span></span>
                 <span>:stream</span> <span>t</span>))</pre></div>
</details>
<details>
<summary>
<p dir="auto"><h4 tabindex="-1" dir="auto">Llama.cpp or Llamafile</h4><a id="user-content-llamacpp-or-llamafile" aria-label="Permalink: Llama.cpp or Llamafile" href="#llamacpp-or-llamafile"></a></p>
</summary>
<p dir="auto">(If using a llamafile, run a <a href="https://github.com/Mozilla-Ocho/llamafile#other-example-llamafiles">server llamafile</a> instead of a “command-line llamafile”, and a model that supports text generation.)</p>
<p dir="auto">Register a backend with</p>
<div dir="auto" data-snippet-clipboard-copy-content=";; Llama.cpp offers an OpenAI compatible API
(gptel-make-openai &quot;llama-cpp&quot;          ;Any name
  :stream t                             ;Stream responses
  :protocol &quot;http&quot;
  :host &quot;localhost:8000&quot;                ;Llama.cpp server location
  :models '(test))                    ;Any names, doesn't matter for Llama"><pre><span><span>;</span>; Llama.cpp offers an OpenAI compatible API</span>
(gptel-make-openai <span><span>"</span>llama-cpp<span>"</span></span>          <span><span>;</span>Any name</span>
  <span>:stream</span> <span>t</span>                             <span><span>;</span>Stream responses</span>
  <span>:protocol</span> <span><span>"</span>http<span>"</span></span>
  <span>:host</span> <span><span>"</span>localhost:8000<span>"</span></span>                <span><span>;</span>Llama.cpp server location</span>
  <span>:models</span> '(test))                    <span><span>;</span>Any names, doesn't matter for Llama</span></pre></div>
<p dir="auto">These are the required parameters, refer to the documentation of <code>gptel-make-openai</code> for more.</p>
<p dir="auto">You can pick this backend from the menu when using gptel (see <a href="#usage">Usage</a>)</p>
<p dir="auto"><h5 tabindex="-1" dir="auto">(Optional) Set as the default gptel backend</h5><a id="user-content-optional-set-as-the-default-gptel-backend-4" aria-label="Permalink: (Optional) Set as the default gptel backend" href="#optional-set-as-the-default-gptel-backend-4"></a></p>
<p dir="auto">The above code makes the backend available to select.  If you want it to be the default backend for gptel, you can set this as the value of <code>gptel-backend</code>.  Use this instead of the above.</p>
<div dir="auto" data-snippet-clipboard-copy-content=";; OPTIONAL configuration
(setq
 gptel-model   'test
 gptel-backend (gptel-make-openai &quot;llama-cpp&quot;
                 :stream t
                 :protocol &quot;http&quot;
                 :host &quot;localhost:8000&quot;
                 :models '(test)))"><pre><span><span>;</span>; OPTIONAL configuration</span>
(<span>setq</span>
 gptel-model   <span>'test</span>
 gptel-backend (gptel-make-openai <span><span>"</span>llama-cpp<span>"</span></span>
                 <span>:stream</span> <span>t</span>
                 <span>:protocol</span> <span><span>"</span>http<span>"</span></span>
                 <span>:host</span> <span><span>"</span>localhost:8000<span>"</span></span>
                 <span>:models</span> '(test)))</pre></div>
</details>
<details><summary>
<p dir="auto"><h4 tabindex="-1" dir="auto">Kagi (FastGPT &amp; Summarizer)</h4><a id="user-content-kagi-fastgpt--summarizer" aria-label="Permalink: Kagi (FastGPT &amp; Summarizer)" href="#kagi-fastgpt--summarizer"></a></p>
</summary>
<p dir="auto">Kagi’s FastGPT model and the Universal Summarizer are both supported.  A couple of notes:</p>
<ol dir="auto">
  <li>Universal Summarizer: If there is a URL at point, the summarizer will summarize the contents of the URL.  Otherwise the context sent to the model is the same as always: the buffer text upto point, or the contents of the region if the region is active.</li>
  <li>Kagi models do not support multi-turn conversations, interactions are “one-shot”.  They also do not support streaming responses.</li>
</ol>
<p dir="auto">Register a backend with</p>
<div dir="auto" data-snippet-clipboard-copy-content="(gptel-make-kagi &quot;Kagi&quot;                    ;any name
  :key &quot;YOUR_KAGI_API_KEY&quot;)                ;can be a function that returns the key"><pre>(gptel-make-kagi <span><span>"</span>Kagi<span>"</span></span>                    <span><span>;</span>any name</span>
  <span>:key</span> <span><span>"</span>YOUR_KAGI_API_KEY<span>"</span></span>)                <span><span>;</span>can be a function that returns the key</span></pre></div>
<p dir="auto">These are the required parameters, refer to the documentation of <code>gptel-make-kagi</code> for more.</p>
<p dir="auto">You can pick this backend and the model (fastgpt/summarizer) from the transient menu when using gptel.</p>
<p dir="auto"><h5 tabindex="-1" dir="auto">(Optional) Set as the default gptel backend</h5><a id="user-content-optional-set-as-the-default-gptel-backend-5" aria-label="Permalink: (Optional) Set as the default gptel backend" href="#optional-set-as-the-default-gptel-backend-5"></a></p>
<p dir="auto">The above code makes the backend available to select.  If you want it to be the default backend for gptel, you can set this as the value of <code>gptel-backend</code>.  Use this instead of the above.</p>
<div dir="auto" data-snippet-clipboard-copy-content=";; OPTIONAL configuration
(setq
 gptel-model 'fastgpt
 gptel-backend (gptel-make-kagi &quot;Kagi&quot;
                 :key &quot;YOUR_KAGI_API_KEY&quot;))"><pre><span><span>;</span>; OPTIONAL configuration</span>
(<span>setq</span>
 gptel-model <span>'fastgpt</span>
 gptel-backend (gptel-make-kagi <span><span>"</span>Kagi<span>"</span></span>
                 <span>:key</span> <span><span>"</span>YOUR_KAGI_API_KEY<span>"</span></span>))</pre></div>
<p dir="auto">The alternatives to <code>fastgpt</code> include <code>summarize:cecil</code>, <code>summarize:agnes</code>, <code>summarize:daphne</code> and <code>summarize:muriel</code>.  The difference between the summarizer engines is <a href="https://help.kagi.com/kagi/api/summarizer.html#summarization-engines" rel="nofollow">documented here</a>.</p>
</details>
<details><summary>
<p dir="auto"><h4 tabindex="-1" dir="auto">together.ai</h4><a id="user-content-togetherai" aria-label="Permalink: together.ai" href="#togetherai"></a></p>
</summary>
<p dir="auto">Register a backend with</p>
<div dir="auto" data-snippet-clipboard-copy-content=";; Together.ai offers an OpenAI compatible API
(gptel-make-openai &quot;TogetherAI&quot;         ;Any name you want
  :host &quot;api.together.xyz&quot;
  :key &quot;your-api-key&quot;                   ;can be a function that returns the key
  :stream t
  :models '(;; has many more, check together.ai
            mistralai/Mixtral-8x7B-Instruct-v0.1
            codellama/CodeLlama-13b-Instruct-hf
            codellama/CodeLlama-34b-Instruct-hf))"><pre><span><span>;</span>; Together.ai offers an OpenAI compatible API</span>
(gptel-make-openai <span><span>"</span>TogetherAI<span>"</span></span>         <span><span>;</span>Any name you want</span>
  <span>:host</span> <span><span>"</span>api.together.xyz<span>"</span></span>
  <span>:key</span> <span><span>"</span>your-api-key<span>"</span></span>                   <span><span>;</span>can be a function that returns the key</span>
  <span>:stream</span> <span>t</span>
  <span>:models</span> '(<span><span>;</span>; has many more, check together.ai</span>
            mistralai/Mixtral-8x7B-Instruct-v0.1
            codellama/CodeLlama-13b-Instruct-hf
            codellama/CodeLlama-34b-Instruct-hf))</pre></div>
<p dir="auto">You can pick this backend from the menu when using gptel (see <a href="#usage">Usage</a>)</p>
<p dir="auto"><h5 tabindex="-1" dir="auto">(Optional) Set as the default gptel backend</h5><a id="user-content-optional-set-as-the-default-gptel-backend-6" aria-label="Permalink: (Optional) Set as the default gptel backend" href="#optional-set-as-the-default-gptel-backend-6"></a></p>
<p dir="auto">The above code makes the backend available to select.  If you want it to be the default backend for gptel, you can set this as the value of <code>gptel-backend</code>.  Use this instead of the above.</p>
<div dir="auto" data-snippet-clipboard-copy-content=";; OPTIONAL configuration
(setq
 gptel-model   'mistralai/Mixtral-8x7B-Instruct-v0.1
 gptel-backend
 (gptel-make-openai &quot;TogetherAI&quot;         
   :host &quot;api.together.xyz&quot;
   :key &quot;your-api-key&quot;                   
   :stream t
   :models '(;; has many more, check together.ai
             mistralai/Mixtral-8x7B-Instruct-v0.1
             codellama/CodeLlama-13b-Instruct-hf
             codellama/CodeLlama-34b-Instruct-hf)))"><pre><span><span>;</span>; OPTIONAL configuration</span>
(<span>setq</span>
 gptel-model   <span>'mistralai/Mixtral-8x7B-Instruct-v0</span>.1
 gptel-backend
 (gptel-make-openai <span><span>"</span>TogetherAI<span>"</span></span>         
   <span>:host</span> <span><span>"</span>api.together.xyz<span>"</span></span>
   <span>:key</span> <span><span>"</span>your-api-key<span>"</span></span>                   
   <span>:stream</span> <span>t</span>
   <span>:models</span> '(<span><span>;</span>; has many more, check together.ai</span>
             mistralai/Mixtral-8x7B-Instruct-v0.1
             codellama/CodeLlama-13b-Instruct-hf
             codellama/CodeLlama-34b-Instruct-hf)))</pre></div>
</details>
<details><summary>
<p dir="auto"><h4 tabindex="-1" dir="auto">Anyscale</h4><a id="user-content-anyscale" aria-label="Permalink: Anyscale" href="#anyscale"></a></p>
</summary>
<p dir="auto">Register a backend with</p>
<div dir="auto" data-snippet-clipboard-copy-content=";; Anyscale offers an OpenAI compatible API
(gptel-make-openai &quot;Anyscale&quot;           ;Any name you want
  :host &quot;api.endpoints.anyscale.com&quot;
  :key &quot;your-api-key&quot;                   ;can be a function that returns the key
  :models '(;; has many more, check anyscale
            mistralai/Mixtral-8x7B-Instruct-v0.1))"><pre><span><span>;</span>; Anyscale offers an OpenAI compatible API</span>
(gptel-make-openai <span><span>"</span>Anyscale<span>"</span></span>           <span><span>;</span>Any name you want</span>
  <span>:host</span> <span><span>"</span>api.endpoints.anyscale.com<span>"</span></span>
  <span>:key</span> <span><span>"</span>your-api-key<span>"</span></span>                   <span><span>;</span>can be a function that returns the key</span>
  <span>:models</span> '(<span><span>;</span>; has many more, check anyscale</span>
            mistralai/Mixtral-8x7B-Instruct-v0.1))</pre></div>
<p dir="auto">You can pick this backend from the menu when using gptel (see <a href="#usage">Usage</a>)</p>
<p dir="auto"><h5 tabindex="-1" dir="auto">(Optional) Set as the default gptel backend</h5><a id="user-content-optional-set-as-the-default-gptel-backend-7" aria-label="Permalink: (Optional) Set as the default gptel backend" href="#optional-set-as-the-default-gptel-backend-7"></a></p>
<p dir="auto">The above code makes the backend available to select.  If you want it to be the default backend for gptel, you can set this as the value of <code>gptel-backend</code>.  Use this instead of the above.</p>
<div dir="auto" data-snippet-clipboard-copy-content=";; OPTIONAL configuration
(setq
 gptel-model   'mistralai/Mixtral-8x7B-Instruct-v0.1
 gptel-backend
 (gptel-make-openai &quot;Anyscale&quot;
                 :host &quot;api.endpoints.anyscale.com&quot;
                 :key &quot;your-api-key&quot;
                 :models '(;; has many more, check anyscale
                           mistralai/Mixtral-8x7B-Instruct-v0.1)))"><pre><span><span>;</span>; OPTIONAL configuration</span>
(<span>setq</span>
 gptel-model   <span>'mistralai/Mixtral-8x7B-Instruct-v0</span>.1
 gptel-backend
 (gptel-make-openai <span><span>"</span>Anyscale<span>"</span></span>
                 <span>:host</span> <span><span>"</span>api.endpoints.anyscale.com<span>"</span></span>
                 <span>:key</span> <span><span>"</span>your-api-key<span>"</span></span>
                 <span>:models</span> '(<span><span>;</span>; has many more, check anyscale</span>
                           mistralai/Mixtral-8x7B-Instruct-v0.1)))</pre></div>
</details>
<details><summary>
<p dir="auto"><h4 tabindex="-1" dir="auto">Perplexity</h4><a id="user-content-perplexity" aria-label="Permalink: Perplexity" href="#perplexity"></a></p>
</summary>
<p dir="auto">Register a backend with</p>
<div dir="auto" data-snippet-clipboard-copy-content=";; Perplexity offers an OpenAI compatible API
(gptel-make-openai &quot;Perplexity&quot;         ;Any name you want
  :host &quot;api.perplexity.ai&quot;
  :key &quot;your-api-key&quot;                   ;can be a function that returns the key
  :endpoint &quot;/chat/completions&quot;
  :stream t
  :models '(;; has many more, check perplexity.ai
            pplx-7b-chat
            pplx-70b-chat
            pplx-7b-online
            pplx-70b-online))"><pre><span><span>;</span>; Perplexity offers an OpenAI compatible API</span>
(gptel-make-openai <span><span>"</span>Perplexity<span>"</span></span>         <span><span>;</span>Any name you want</span>
  <span>:host</span> <span><span>"</span>api.perplexity.ai<span>"</span></span>
  <span>:key</span> <span><span>"</span>your-api-key<span>"</span></span>                   <span><span>;</span>can be a function that returns the key</span>
  <span>:endpoint</span> <span><span>"</span>/chat/completions<span>"</span></span>
  <span>:stream</span> <span>t</span>
  <span>:models</span> '(<span><span>;</span>; has many more, check perplexity.ai</span>
            pplx-7b-chat
            pplx-70b-chat
            pplx-7b-online
            pplx-70b-online))</pre></div>
<p dir="auto">You can pick this backend from the menu when using gptel (see <a href="#usage">Usage</a>)</p>
<p dir="auto"><h5 tabindex="-1" dir="auto">(Optional) Set as the default gptel backend</h5><a id="user-content-optional-set-as-the-default-gptel-backend-8" aria-label="Permalink: (Optional) Set as the default gptel backend" href="#optional-set-as-the-default-gptel-backend-8"></a></p>
<p dir="auto">The above code makes the backend available to select.  If you want it to be the default backend for gptel, you can set this as the value of <code>gptel-backend</code>.  Use this instead of the above.</p>
<div dir="auto" data-snippet-clipboard-copy-content=";; OPTIONAL configuration
(setq
 gptel-model   'pplx-7b-chat
 gptel-backend
 (gptel-make-openai &quot;Perplexity&quot;
   :host &quot;api.perplexity.ai&quot;
   :key &quot;your-api-key&quot;
   :endpoint &quot;/chat/completions&quot;
   :stream t
   :models '(;; has many more, check perplexity.ai
             pplx-7b-chat
             pplx-70b-chat
             pplx-7b-online
             pplx-70b-online)))"><pre><span><span>;</span>; OPTIONAL configuration</span>
(<span>setq</span>
 gptel-model   <span>'pplx-7b-chat</span>
 gptel-backend
 (gptel-make-openai <span><span>"</span>Perplexity<span>"</span></span>
   <span>:host</span> <span><span>"</span>api.perplexity.ai<span>"</span></span>
   <span>:key</span> <span><span>"</span>your-api-key<span>"</span></span>
   <span>:endpoint</span> <span><span>"</span>/chat/completions<span>"</span></span>
   <span>:stream</span> <span>t</span>
   <span>:models</span> '(<span><span>;</span>; has many more, check perplexity.ai</span>
             pplx-7b-chat
             pplx-70b-chat
             pplx-7b-online
             pplx-70b-online)))</pre></div>
</details>
<details><summary>
<p dir="auto"><h4 tabindex="-1" dir="auto">Anthropic (Claude)</h4><a id="user-content-anthropic-claude" aria-label="Permalink: Anthropic (Claude)" href="#anthropic-claude"></a></p>
</summary>
<p dir="auto">Register a backend with</p>
<div dir="auto" data-snippet-clipboard-copy-content="(gptel-make-anthropic &quot;Claude&quot;          ;Any name you want
  :stream t                             ;Streaming responses
  :key &quot;your-api-key&quot;)"><pre>(gptel-make-anthropic <span><span>"</span>Claude<span>"</span></span>          <span><span>;</span>Any name you want</span>
  <span>:stream</span> <span>t</span>                             <span><span>;</span>Streaming responses</span>
  <span>:key</span> <span><span>"</span>your-api-key<span>"</span></span>)</pre></div>
<p dir="auto">The <code>:key</code> can be a function that returns the key (more secure).</p>
<p dir="auto">You can pick this backend from the menu when using gptel (see <a href="#usage">Usage</a>).</p>
<p dir="auto"><h5 tabindex="-1" dir="auto">(Optional) Set as the default gptel backend</h5><a id="user-content-optional-set-as-the-default-gptel-backend-9" aria-label="Permalink: (Optional) Set as the default gptel backend" href="#optional-set-as-the-default-gptel-backend-9"></a></p>
<p dir="auto">The above code makes the backend available to select.  If you want it to be the default backend for gptel, you can set this as the value of <code>gptel-backend</code>.  Use this instead of the above.</p>
<div dir="auto" data-snippet-clipboard-copy-content=";; OPTIONAL configuration
(setq
 gptel-model 'claude-3-sonnet-20240229 ;  &quot;claude-3-opus-20240229&quot; also available
 gptel-backend (gptel-make-anthropic &quot;Claude&quot;
                 :stream t :key &quot;your-api-key&quot;))"><pre><span><span>;</span>; OPTIONAL configuration</span>
(<span>setq</span>
 gptel-model <span>'claude-3-sonnet-20240229</span> <span><span>;</span>  "claude-3-opus-20240229" also available</span>
 gptel-backend (gptel-make-anthropic <span><span>"</span>Claude<span>"</span></span>
                 <span>:stream</span> <span>t</span> <span>:key</span> <span><span>"</span>your-api-key<span>"</span></span>))</pre></div>
</details>
<details><summary>
<p dir="auto"><h4 tabindex="-1" dir="auto">Groq</h4><a id="user-content-groq" aria-label="Permalink: Groq" href="#groq"></a></p>
</summary>
<p dir="auto">Register a backend with</p>
<div dir="auto" data-snippet-clipboard-copy-content=";; Groq offers an OpenAI compatible API
(gptel-make-openai &quot;Groq&quot;               ;Any name you want
  :host &quot;api.groq.com&quot;
  :endpoint &quot;/openai/v1/chat/completions&quot;
  :stream t
  :key &quot;your-api-key&quot;                   ;can be a function that returns the key
  :models '(llama-3.1-70b-versatile
            llama-3.1-8b-instant
            llama3-70b-8192
            llama3-8b-8192
            mixtral-8x7b-32768
            gemma-7b-it))"><pre><span><span>;</span>; Groq offers an OpenAI compatible API</span>
(gptel-make-openai <span><span>"</span>Groq<span>"</span></span>               <span><span>;</span>Any name you want</span>
  <span>:host</span> <span><span>"</span>api.groq.com<span>"</span></span>
  <span>:endpoint</span> <span><span>"</span>/openai/v1/chat/completions<span>"</span></span>
  <span>:stream</span> <span>t</span>
  <span>:key</span> <span><span>"</span>your-api-key<span>"</span></span>                   <span><span>;</span>can be a function that returns the key</span>
  <span>:models</span> '(llama-3.1-70b-versatile
            llama-3.1-8b-instant
            llama3-70b-8192
            llama3-8b-8192
            mixtral-8x7b-32768
            gemma-7b-it))</pre></div>
<p dir="auto">You can pick this backend from the menu when using gptel (see <a href="#usage">Usage</a>).  Note that Groq is fast enough that you could easily set <code>:stream nil</code> and still get near-instant responses.</p>
<p dir="auto"><h5 tabindex="-1" dir="auto">(Optional) Set as the default gptel backend</h5><a id="user-content-optional-set-as-the-default-gptel-backend-10" aria-label="Permalink: (Optional) Set as the default gptel backend" href="#optional-set-as-the-default-gptel-backend-10"></a></p>
<p dir="auto">The above code makes the backend available to select.  If you want it to be the default backend for gptel, you can set this as the value of <code>gptel-backend</code>.  Use this instead of the above.</p>
<div dir="auto" data-snippet-clipboard-copy-content=";; OPTIONAL configuration
(setq gptel-model   'mixtral-8x7b-32768
      gptel-backend
      (gptel-make-openai &quot;Groq&quot;
        :host &quot;api.groq.com&quot;
        :endpoint &quot;/openai/v1/chat/completions&quot;
        :stream t
        :key &quot;your-api-key&quot;
        :models '(llama-3.1-70b-versatile
                  llama-3.1-8b-instant
                  llama3-70b-8192
                  llama3-8b-8192
                  mixtral-8x7b-32768
                  gemma-7b-it)))"><pre><span><span>;</span>; OPTIONAL configuration</span>
(<span>setq</span> gptel-model   <span>'mixtral-8x7b-32768</span>
      gptel-backend
      (gptel-make-openai <span><span>"</span>Groq<span>"</span></span>
        <span>:host</span> <span><span>"</span>api.groq.com<span>"</span></span>
        <span>:endpoint</span> <span><span>"</span>/openai/v1/chat/completions<span>"</span></span>
        <span>:stream</span> <span>t</span>
        <span>:key</span> <span><span>"</span>your-api-key<span>"</span></span>
        <span>:models</span> '(llama-3.1-70b-versatile
                  llama-3.1-8b-instant
                  llama3-70b-8192
                  llama3-8b-8192
                  mixtral-8x7b-32768
                  gemma-7b-it)))</pre></div>
</details>
<details><summary>
<p dir="auto"><h4 tabindex="-1" dir="auto">OpenRouter</h4><a id="user-content-openrouter" aria-label="Permalink: OpenRouter" href="#openrouter"></a></p>
</summary>
<p dir="auto">Register a backend with</p>
<div dir="auto" data-snippet-clipboard-copy-content=";; OpenRouter offers an OpenAI compatible API
(gptel-make-openai &quot;OpenRouter&quot;               ;Any name you want
  :host &quot;openrouter.ai&quot;
  :endpoint &quot;/api/v1/chat/completions&quot;
  :stream t
  :key &quot;your-api-key&quot;                   ;can be a function that returns the key
  :models '(openai/gpt-3.5-turbo
            mistralai/mixtral-8x7b-instruct
            meta-llama/codellama-34b-instruct
            codellama/codellama-70b-instruct
            google/palm-2-codechat-bison-32k
            google/gemini-pro))
"><pre><span><span>;</span>; OpenRouter offers an OpenAI compatible API</span>
(gptel-make-openai <span><span>"</span>OpenRouter<span>"</span></span>               <span><span>;</span>Any name you want</span>
  <span>:host</span> <span><span>"</span>openrouter.ai<span>"</span></span>
  <span>:endpoint</span> <span><span>"</span>/api/v1/chat/completions<span>"</span></span>
  <span>:stream</span> <span>t</span>
  <span>:key</span> <span><span>"</span>your-api-key<span>"</span></span>                   <span><span>;</span>can be a function that returns the key</span>
  <span>:models</span> '(openai/gpt-3.5-turbo
            mistralai/mixtral-8x7b-instruct
            meta-llama/codellama-34b-instruct
            codellama/codellama-70b-instruct
            google/palm-2-codechat-bison-32k
            google/gemini-pro))
</pre></div>
<p dir="auto">You can pick this backend from the menu when using gptel (see <a href="#usage">Usage</a>).</p>
<p dir="auto"><h5 tabindex="-1" dir="auto">(Optional) Set as the default gptel backend</h5><a id="user-content-optional-set-as-the-default-gptel-backend-11" aria-label="Permalink: (Optional) Set as the default gptel backend" href="#optional-set-as-the-default-gptel-backend-11"></a></p>
<p dir="auto">The above code makes the backend available to select.  If you want it to be the default backend for gptel, you can set this as the value of <code>gptel-backend</code>.  Use this instead of the above.</p>
<div dir="auto" data-snippet-clipboard-copy-content=";; OPTIONAL configuration
(setq gptel-model   'mixtral-8x7b-32768
      gptel-backend
      (gptel-make-openai &quot;OpenRouter&quot;               ;Any name you want
        :host &quot;openrouter.ai&quot;
        :endpoint &quot;/api/v1/chat/completions&quot;
        :stream t
        :key &quot;your-api-key&quot;                   ;can be a function that returns the key
        :models '(openai/gpt-3.5-turbo
                  mistralai/mixtral-8x7b-instruct
                  meta-llama/codellama-34b-instruct
                  codellama/codellama-70b-instruct
                  google/palm-2-codechat-bison-32k
                  google/gemini-pro)))
"><pre><span><span>;</span>; OPTIONAL configuration</span>
(<span>setq</span> gptel-model   <span>'mixtral-8x7b-32768</span>
      gptel-backend
      (gptel-make-openai <span><span>"</span>OpenRouter<span>"</span></span>               <span><span>;</span>Any name you want</span>
        <span>:host</span> <span><span>"</span>openrouter.ai<span>"</span></span>
        <span>:endpoint</span> <span><span>"</span>/api/v1/chat/completions<span>"</span></span>
        <span>:stream</span> <span>t</span>
        <span>:key</span> <span><span>"</span>your-api-key<span>"</span></span>                   <span><span>;</span>can be a function that returns the key</span>
        <span>:models</span> '(openai/gpt-3.5-turbo
                  mistralai/mixtral-8x7b-instruct
                  meta-llama/codellama-34b-instruct
                  codellama/codellama-70b-instruct
                  google/palm-2-codechat-bison-32k
                  google/gemini-pro)))
</pre></div>
</details>
<details><summary>
<p dir="auto"><h4 tabindex="-1" dir="auto">PrivateGPT</h4><a id="user-content-privategpt" aria-label="Permalink: PrivateGPT" href="#privategpt"></a></p>
</summary>
<p dir="auto">Register a backend with</p>
<div dir="auto" data-snippet-clipboard-copy-content="(gptel-make-privategpt &quot;privateGPT&quot;               ;Any name you want
  :protocol &quot;http&quot;
  :host &quot;localhost:8001&quot;
  :stream t
  :context t                            ;Use context provided by embeddings
  :sources t                            ;Return information about source documents
  :models '(private-gpt))
"><pre>(gptel-make-privategpt <span><span>"</span>privateGPT<span>"</span></span>               <span><span>;</span>Any name you want</span>
  <span>:protocol</span> <span><span>"</span>http<span>"</span></span>
  <span>:host</span> <span><span>"</span>localhost:8001<span>"</span></span>
  <span>:stream</span> <span>t</span>
  <span>:context</span> <span>t</span>                            <span><span>;</span>Use context provided by embeddings</span>
  <span>:sources</span> <span>t</span>                            <span><span>;</span>Return information about source documents</span>
  <span>:models</span> '(private-gpt))
</pre></div>
<p dir="auto">You can pick this backend from the menu when using gptel (see <a href="#usage">Usage</a>).</p>
<p dir="auto"><h5 tabindex="-1" dir="auto">(Optional) Set as the default gptel backend</h5><a id="user-content-optional-set-as-the-default-gptel-backend-12" aria-label="Permalink: (Optional) Set as the default gptel backend" href="#optional-set-as-the-default-gptel-backend-12"></a></p>
<p dir="auto">The above code makes the backend available to select.  If you want it to be the default backend for gptel, you can set this as the value of <code>gptel-backend</code>.  Use this instead of the above.</p>
<div dir="auto" data-snippet-clipboard-copy-content=";; OPTIONAL configuration
(setq gptel-model   'private-gpt
      gptel-backend
      (gptel-make-privategpt &quot;privateGPT&quot;               ;Any name you want
        :protocol &quot;http&quot;
        :host &quot;localhost:8001&quot;
        :stream t
        :context t                            ;Use context provided by embeddings
        :sources t                            ;Return information about source documents
        :models '(private-gpt)))
"><pre><span><span>;</span>; OPTIONAL configuration</span>
(<span>setq</span> gptel-model   <span>'private-gpt</span>
      gptel-backend
      (gptel-make-privategpt <span><span>"</span>privateGPT<span>"</span></span>               <span><span>;</span>Any name you want</span>
        <span>:protocol</span> <span><span>"</span>http<span>"</span></span>
        <span>:host</span> <span><span>"</span>localhost:8001<span>"</span></span>
        <span>:stream</span> <span>t</span>
        <span>:context</span> <span>t</span>                            <span><span>;</span>Use context provided by embeddings</span>
        <span>:sources</span> <span>t</span>                            <span><span>;</span>Return information about source documents</span>
        <span>:models</span> '(private-gpt)))
</pre></div>
</details>
<details><summary>
<p dir="auto"><h4 tabindex="-1" dir="auto">DeepSeek</h4><a id="user-content-deepseek" aria-label="Permalink: DeepSeek" href="#deepseek"></a></p>
</summary>
<p dir="auto">Register a backend with</p>
<div dir="auto" data-snippet-clipboard-copy-content=";; DeepSeek offers an OpenAI compatible API
(gptel-make-openai &quot;DeepSeek&quot;       ;Any name you want
  :host &quot;api.deepseek.com&quot;
  :endpoint &quot;/chat/completions&quot;
  :stream t
  :key &quot;your-api-key&quot;               ;can be a function that returns the key
  :models '(deepseek-chat deepseek-coder))
"><pre><span><span>;</span>; DeepSeek offers an OpenAI compatible API</span>
(gptel-make-openai <span><span>"</span>DeepSeek<span>"</span></span>       <span><span>;</span>Any name you want</span>
  <span>:host</span> <span><span>"</span>api.deepseek.com<span>"</span></span>
  <span>:endpoint</span> <span><span>"</span>/chat/completions<span>"</span></span>
  <span>:stream</span> <span>t</span>
  <span>:key</span> <span><span>"</span>your-api-key<span>"</span></span>               <span><span>;</span>can be a function that returns the key</span>
  <span>:models</span> '(deepseek-chat deepseek-coder))
</pre></div>
<p dir="auto">You can pick this backend from the menu when using gptel (see <a href="#usage">Usage</a>).</p>
<p dir="auto"><h5 tabindex="-1" dir="auto">(Optional) Set as the default gptel backend</h5><a id="user-content-optional-set-as-the-default-gptel-backend-13" aria-label="Permalink: (Optional) Set as the default gptel backend" href="#optional-set-as-the-default-gptel-backend-13"></a></p>
<p dir="auto">The above code makes the backend available to select.  If you want it to be the default backend for gptel, you can set this as the value of <code>gptel-backend</code>.  Use this instead of the above.</p>
<div dir="auto" data-snippet-clipboard-copy-content=";; OPTIONAL configuration
(setq gptel-model   'deepseek-chat
      gptel-backend
      (gptel-make-openai &quot;DeepSeek&quot;     ;Any name you want
        :host &quot;api.deepseek.com&quot;
        :endpoint &quot;/chat/completions&quot;
        :stream t
        :key &quot;your-api-key&quot;             ;can be a function that returns the key
        :models '(deepseek-chat deepseek-coder)))
"><pre><span><span>;</span>; OPTIONAL configuration</span>
(<span>setq</span> gptel-model   <span>'deepseek-chat</span>
      gptel-backend
      (gptel-make-openai <span><span>"</span>DeepSeek<span>"</span></span>     <span><span>;</span>Any name you want</span>
        <span>:host</span> <span><span>"</span>api.deepseek.com<span>"</span></span>
        <span>:endpoint</span> <span><span>"</span>/chat/completions<span>"</span></span>
        <span>:stream</span> <span>t</span>
        <span>:key</span> <span><span>"</span>your-api-key<span>"</span></span>             <span><span>;</span>can be a function that returns the key</span>
        <span>:models</span> '(deepseek-chat deepseek-coder)))
</pre></div>
</details>
<details><summary>
<p dir="auto"><h4 tabindex="-1" dir="auto">Cerebras</h4><a id="user-content-cerebras" aria-label="Permalink: Cerebras" href="#cerebras"></a></p>
</summary>
<p dir="auto">Register a backend with</p>
<div dir="auto" data-snippet-clipboard-copy-content=";; Cerebras offers an instant OpenAI compatible API
(gptel-make-openai &quot;Cerebras&quot;
  :host &quot;api.cerebras.ai&quot;
  :endpoint &quot;/v1/chat/completions&quot;
  :stream t                             ;optionally nil as Cerebras is instant AI
  :key &quot;your-api-key&quot;                   ;can be a function that returns the key
  :models '(llama3.1-70b
            llama3.1-8b))"><pre><span><span>;</span>; Cerebras offers an instant OpenAI compatible API</span>
(gptel-make-openai <span><span>"</span>Cerebras<span>"</span></span>
  <span>:host</span> <span><span>"</span>api.cerebras.ai<span>"</span></span>
  <span>:endpoint</span> <span><span>"</span>/v1/chat/completions<span>"</span></span>
  <span>:stream</span> <span>t</span>                             <span><span>;</span>optionally nil as Cerebras is instant AI</span>
  <span>:key</span> <span><span>"</span>your-api-key<span>"</span></span>                   <span><span>;</span>can be a function that returns the key</span>
  <span>:models</span> '(llama3.1-70b
            llama3.1-8b))</pre></div>
<p dir="auto">You can pick this backend from the menu when using gptel (see <a href="#usage">Usage</a>).</p>
<p dir="auto"><h5 tabindex="-1" dir="auto">(Optional) Set as the default gptel backend</h5><a id="user-content-optional-set-as-the-default-gptel-backend-14" aria-label="Permalink: (Optional) Set as the default gptel backend" href="#optional-set-as-the-default-gptel-backend-14"></a></p>
<p dir="auto">The above code makes the backend available to select.  If you want it to be the default backend for gptel, you can set this as the value of <code>gptel-backend</code>.  Use this instead of the above.</p>
<div dir="auto" data-snippet-clipboard-copy-content=";; OPTIONAL configuration
(setq gptel-model   'llama3.1-8b
      gptel-backend
      (gptel-make-openai &quot;Cerebras&quot;
        :host &quot;api.cerebras.ai&quot;
        :endpoint &quot;/v1/chat/completions&quot;
        :stream nil
        :key &quot;your-api-key&quot;
        :models '(llama3.1-70b
                  llama3.1-8b)))"><pre><span><span>;</span>; OPTIONAL configuration</span>
(<span>setq</span> gptel-model   <span>'llama3</span>.1-8b
      gptel-backend
      (gptel-make-openai <span><span>"</span>Cerebras<span>"</span></span>
        <span>:host</span> <span><span>"</span>api.cerebras.ai<span>"</span></span>
        <span>:endpoint</span> <span><span>"</span>/v1/chat/completions<span>"</span></span>
        <span>:stream</span> <span>nil</span>
        <span>:key</span> <span><span>"</span>your-api-key<span>"</span></span>
        <span>:models</span> '(llama3.1-70b
                  llama3.1-8b)))</pre></div>
</details>
<details><summary>
<p dir="auto"><h4 tabindex="-1" dir="auto">Github Models</h4><a id="user-content-github-models" aria-label="Permalink: Github Models" href="#github-models"></a></p>
</summary>
<p dir="auto">Register a backend with</p>
<div dir="auto" data-snippet-clipboard-copy-content=";; Github Models offers an OpenAI compatible API
(gptel-make-openai &quot;Github Models&quot; ;Any name you want
  :host &quot;models.inference.ai.azure.com&quot;
  :endpoint &quot;/chat/completions&quot;
  :stream t
  :key &quot;your-github-token&quot;
  :models '(gpt-4o))"><pre><span><span>;</span>; Github Models offers an OpenAI compatible API</span>
(gptel-make-openai <span><span>"</span>Github Models<span>"</span></span> <span><span>;</span>Any name you want</span>
  <span>:host</span> <span><span>"</span>models.inference.ai.azure.com<span>"</span></span>
  <span>:endpoint</span> <span><span>"</span>/chat/completions<span>"</span></span>
  <span>:stream</span> <span>t</span>
  <span>:key</span> <span><span>"</span>your-github-token<span>"</span></span>
  <span>:models</span> '(gpt-4o))</pre></div>
<p dir="auto">For all the available models, check the <a href="https://github.com/marketplace/models">marketplace</a>.</p>
<p dir="auto">You can pick this backend from the menu when using (see <a href="#usage">Usage</a>).</p>
<p dir="auto"><h5 tabindex="-1" dir="auto">(Optional) Set as the default gptel backend</h5><a id="user-content-optional-set-as-the-default-gptel-backend-15" aria-label="Permalink: (Optional) Set as the default gptel backend" href="#optional-set-as-the-default-gptel-backend-15"></a></p>
<p dir="auto">The above code makes the backend available to select.  If you want it to be the default backend for gptel, you can set this as the value of <code>gptel-backend</code>.  Use this instead of the above.</p>
<div dir="auto" data-snippet-clipboard-copy-content=";; OPTIONAL configuration
(setq gptel-model  'gpt-4o
      gptel-backend
      (gptel-make-openai &quot;Github Models&quot; ;Any name you want
        :host &quot;models.inference.ai.azure.com&quot;
        :endpoint &quot;/chat/completions&quot;
        :stream t
        :key &quot;your-github-token&quot;
        :models '(gpt-4o))"><pre><span><span>;</span>; OPTIONAL configuration</span>
(<span>setq</span> gptel-model  <span>'gpt-4o</span>
      gptel-backend
      (gptel-make-openai <span><span>"</span>Github Models<span>"</span></span> <span><span>;</span>Any name you want</span>
        <span>:host</span> <span><span>"</span>models.inference.ai.azure.com<span>"</span></span>
        <span>:endpoint</span> <span><span>"</span>/chat/completions<span>"</span></span>
        <span>:stream</span> <span>t</span>
        <span>:key</span> <span><span>"</span>your-github-token<span>"</span></span>
        <span>:models</span> '(gpt-4o))</pre></div>
</details>
<details><summary>
<p dir="auto"><h4 tabindex="-1" dir="auto">Novita AI</h4><a id="user-content-novita-ai" aria-label="Permalink: Novita AI" href="#novita-ai"></a></p>
</summary>
<p dir="auto">Register a backend with</p>
<div dir="auto" data-snippet-clipboard-copy-content=";; Novita AI offers an OpenAI compatible API
(gptel-make-openai &quot;NovitaAI&quot;         ;Any name you want
  :host &quot;api.novita.ai&quot;
  :endpoint &quot;/v3/openai&quot;
  :key &quot;your-api-key&quot;                   ;can be a function that returns the key
  :stream t
  :models '(;; has many more, check https://novita.ai/llm-api
            gryphe/mythomax-l2-13b
            meta-llama/llama-3-70b-instruct
            meta-llama/llama-3.1-70b-instruct))"><pre><span><span>;</span>; Novita AI offers an OpenAI compatible API</span>
(gptel-make-openai <span><span>"</span>NovitaAI<span>"</span></span>         <span><span>;</span>Any name you want</span>
  <span>:host</span> <span><span>"</span>api.novita.ai<span>"</span></span>
  <span>:endpoint</span> <span><span>"</span>/v3/openai<span>"</span></span>
  <span>:key</span> <span><span>"</span>your-api-key<span>"</span></span>                   <span><span>;</span>can be a function that returns the key</span>
  <span>:stream</span> <span>t</span>
  <span>:models</span> '(<span><span>;</span>; has many more, check https://novita.ai/llm-api</span>
            gryphe/mythomax-l2-13b
            meta-llama/llama-3-70b-instruct
            meta-llama/llama-3.1-70b-instruct))</pre></div>
<p dir="auto">You can pick this backend from the menu when using gptel (see <a href="#usage">Usage</a>)</p>
<p dir="auto"><h5 tabindex="-1" dir="auto">(Optional) Set as the default gptel backend</h5><a id="user-content-optional-set-as-the-default-gptel-backend-16" aria-label="Permalink: (Optional) Set as the default gptel backend" href="#optional-set-as-the-default-gptel-backend-16"></a></p>
<p dir="auto">The above code makes the backend available to select.  If you want it to be the default backend for gptel, you can set this as the value of <code>gptel-backend</code>.  Use this instead of the above.</p>
<div dir="auto" data-snippet-clipboard-copy-content=";; OPTIONAL configuration
(setq
 gptel-model   'gryphe/mythomax-l2-13b
 gptel-backend
 (gptel-make-openai &quot;NovitaAI&quot;         
   :host &quot;api.novita.ai&quot;
   :endpoint &quot;/v3/openai&quot;
   :key &quot;your-api-key&quot;                   
   :stream t
   :models '(;; has many more, check https://novita.ai/llm-api
             mistralai/Mixtral-8x7B-Instruct-v0.1
             meta-llama/llama-3-70b-instruct
             meta-llama/llama-3.1-70b-instruct)))"><pre><span><span>;</span>; OPTIONAL configuration</span>
(<span>setq</span>
 gptel-model   <span>'gryphe/mythomax-l2-13b</span>
 gptel-backend
 (gptel-make-openai <span><span>"</span>NovitaAI<span>"</span></span>         
   <span>:host</span> <span><span>"</span>api.novita.ai<span>"</span></span>
   <span>:endpoint</span> <span><span>"</span>/v3/openai<span>"</span></span>
   <span>:key</span> <span><span>"</span>your-api-key<span>"</span></span>                   
   <span>:stream</span> <span>t</span>
   <span>:models</span> '(<span><span>;</span>; has many more, check https://novita.ai/llm-api</span>
             mistralai/Mixtral-8x7B-Instruct-v0.1
             meta-llama/llama-3-70b-instruct
             meta-llama/llama-3.1-70b-instruct)))</pre></div>
</details>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto">(There is also a <a href="https://www.youtube.com/watch?v=bsRnh_brggM" rel="nofollow">video demo</a> showing various uses of gptel.)</p>
<markdown-accessiblity-table><table>
  <tbody><tr><th><b>To send queries</b></th><th>Description</th></tr>
  <tr><td><code>gptel-send</code></td><td>Send all text up to <code>(point)</code>, or the selection if region is active.  Works anywhere in Emacs.</td></tr>
  <tr><td><code>gptel</code></td><td>Create a new dedicated chat buffer.  Not required to use gptel.</td></tr>
  <tr><th><b>To Set options</b></th><th></th></tr>
  <tr><td><code>C-u</code> <code>gptel-send</code></td><td>Transient menu for preferences, input/output redirection etc.</td></tr>
  <tr><td><code>gptel-menu</code></td><td><i>(Same)</i></td></tr>
  <tr><th><b>To add context</b></th><th></th></tr>
  <tr><td><code>gptel-add</code></td><td>Add/remove a region or buffer to gptel’s context.  In Dired, add/remove marked files.</td></tr>
  <tr><td><code>gptel-add-file</code></td><td>Add a file (text or supported media type) to gptel’s context.  Also available from the transient menu.</td></tr>
  <tr><th><b>Org mode bonuses</b></th><th></th></tr>
  <tr><td><code>gptel-org-set-topic</code></td><td>Limit conversation context to an Org heading.  (For branching conversations see below.)</td></tr>
  <tr><td><code>gptel-org-set-properties</code></td><td>Write gptel configuration as Org properties, for per-heading chat configuration.</td></tr>
</tbody></table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">In any buffer:</h3><a id="user-content-in-any-buffer" aria-label="Permalink: In any buffer:" href="#in-any-buffer"></a></p>
<ol dir="auto">
  <li>Call <code>M-x gptel-send</code> to send the text up to the cursor. The response will be inserted below.  Continue the conversation by typing below the response.</li>
  <li>If a region is selected, the conversation will be limited to its contents.</li>
  <li>Call <code>M-x gptel-send</code> with a prefix argument (<code>C-u</code>)
    <ul dir="auto">
      <li>to set chat parameters (GPT model, system message etc) for this buffer,</li>
      <li>include quick instructions for the next request only,</li>
      <li>to add additional context – regions, buffers or files – to gptel,</li>
      <li>to read the prompt from or redirect the response elsewhere,</li>
      <li>or to replace the prompt with the response.</li>
    </ul>
  </li>
</ol>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/8607532/342004903-3562a6e2-7a5c-4f7e-8e57-bf3c11589c73.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzA3MDIxMDEsIm5iZiI6MTczMDcwMTgwMSwicGF0aCI6Ii84NjA3NTMyLzM0MjAwNDkwMy0zNTYyYTZlMi03YTVjLTRmN2UtOGU1Ny1iZjNjMTE1ODljNzMucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MTEwNCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDExMDRUMDYzMDAxWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9NTVkNWYzZjk3MTM1YzNlYTA4YzYwZWMwNmJkZDU1N2U5ZjRlYTA5ZTYwYmJmYmJkZTVmNjlkMDIxZjM4ZjFhNCZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.DkcoQKgXo3SQvkCa6nK5wL70J28NOYBpImDMycLLNwo"><img src="https://private-user-images.githubusercontent.com/8607532/342004903-3562a6e2-7a5c-4f7e-8e57-bf3c11589c73.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzA3MDIxMDEsIm5iZiI6MTczMDcwMTgwMSwicGF0aCI6Ii84NjA3NTMyLzM0MjAwNDkwMy0zNTYyYTZlMi03YTVjLTRmN2UtOGU1Ny1iZjNjMTE1ODljNzMucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MTEwNCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDExMDRUMDYzMDAxWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9NTVkNWYzZjk3MTM1YzNlYTA4YzYwZWMwNmJkZDU1N2U5ZjRlYTA5ZTYwYmJmYmJkZTVmNjlkMDIxZjM4ZjFhNCZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.DkcoQKgXo3SQvkCa6nK5wL70J28NOYBpImDMycLLNwo" alt="Image showing gptel's menu with some of the available query options."></a>
<p dir="auto"><h3 tabindex="-1" dir="auto">In a dedicated chat buffer:</h3><a id="user-content-in-a-dedicated-chat-buffer" aria-label="Permalink: In a dedicated chat buffer:" href="#in-a-dedicated-chat-buffer"></a></p>
<ol dir="auto">
  <li>Run <code>M-x gptel</code> to start or switch to the chat buffer. It will ask you for the key if you skipped the previous step. Run it with a prefix-arg (<code>C-u M-x gptel</code>) to start a new session.</li>
  <li>In the gptel buffer, send your prompt with <code>M-x gptel-send</code>, bound to <code>C-c RET</code>.</li>
  <li>Set chat parameters (LLM provider, model, directives etc) for the session by calling <code>gptel-send</code> with a prefix argument (<code>C-u C-c RET</code>):</li>
</ol>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/8607532/342005178-eb4867e5-30ac-455f-999f-e17123afb810.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzA3MDIxMDEsIm5iZiI6MTczMDcwMTgwMSwicGF0aCI6Ii84NjA3NTMyLzM0MjAwNTE3OC1lYjQ4NjdlNS0zMGFjLTQ1NWYtOTk5Zi1lMTcxMjNhZmI4MTAucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MTEwNCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDExMDRUMDYzMDAxWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9Zjk4Y2ZjMmQ3NWM1MmMyMDA4NTcyMzU0NTRiMGIzMWE3NWM2Y2E5MjU3NTZmMmM5ZGQ5ZmIyNjhmZjdjNzNkMiZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.WfGSV-bVk2NluLyE__PI402BY5iTVQvPlCaY8hGKiKU"><img src="https://private-user-images.githubusercontent.com/8607532/342005178-eb4867e5-30ac-455f-999f-e17123afb810.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzA3MDIxMDEsIm5iZiI6MTczMDcwMTgwMSwicGF0aCI6Ii84NjA3NTMyLzM0MjAwNTE3OC1lYjQ4NjdlNS0zMGFjLTQ1NWYtOTk5Zi1lMTcxMjNhZmI4MTAucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MTEwNCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDExMDRUMDYzMDAxWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9Zjk4Y2ZjMmQ3NWM1MmMyMDA4NTcyMzU0NTRiMGIzMWE3NWM2Y2E5MjU3NTZmMmM5ZGQ5ZmIyNjhmZjdjNzNkMiZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.WfGSV-bVk2NluLyE__PI402BY5iTVQvPlCaY8hGKiKU" alt="Image showing gptel's menu with some of the available query options."></a>
<p dir="auto">That’s it. You can go back and edit previous prompts and responses if you want.</p>
<p dir="auto">The default mode is <code>markdown-mode</code> if available, else <code>text-mode</code>.  You can set <code>gptel-default-mode</code> to <code>org-mode</code> if desired.</p>
<details><summary>
<p dir="auto"><h4 tabindex="-1" dir="auto">Including media (images, documents) with requests</h4><a id="user-content-including-media-images-documents-with-requests" aria-label="Permalink: Including media (images, documents) with requests" href="#including-media-images-documents-with-requests"></a></p>
</summary>
<p dir="auto">gptel supports sending media in Markdown and Org chat buffers, but this feature is disabled by default.</p>
<ul dir="auto">
  <li>You can enable it globally, for all models that support it, by setting <code>gptel-track-media</code>.</li>
  <li>Or you can set it locally, just for the chat buffer, via the header line:</li>
</ul>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/8607532/375929517-91f6aaab-2ea4-4806-9cc9-39b4b46a8e6c.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzA3MDIxMDEsIm5iZiI6MTczMDcwMTgwMSwicGF0aCI6Ii84NjA3NTMyLzM3NTkyOTUxNy05MWY2YWFhYi0yZWE0LTQ4MDYtOWNjOS0zOWI0YjQ2YThlNmMucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MTEwNCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDExMDRUMDYzMDAxWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9ZTEzZjU4OGFiN2RlZjgwMzg0MzNjYmYxM2NhM2M2NTI3OTRhOGRmYTkzY2JhNmU5N2ZkOTgyN2I4MmVmMmVkMyZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.gm0emXnTb-ycQYPMp1VAVCNDPaB156wnyuZdeRO2h5U"><img src="https://private-user-images.githubusercontent.com/8607532/375929517-91f6aaab-2ea4-4806-9cc9-39b4b46a8e6c.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzA3MDIxMDEsIm5iZiI6MTczMDcwMTgwMSwicGF0aCI6Ii84NjA3NTMyLzM3NTkyOTUxNy05MWY2YWFhYi0yZWE0LTQ4MDYtOWNjOS0zOWI0YjQ2YThlNmMucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MTEwNCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDExMDRUMDYzMDAxWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9ZTEzZjU4OGFiN2RlZjgwMzg0MzNjYmYxM2NhM2M2NTI3OTRhOGRmYTkzY2JhNmU5N2ZkOTgyN2I4MmVmMmVkMyZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.gm0emXnTb-ycQYPMp1VAVCNDPaB156wnyuZdeRO2h5U" alt="Image showing a gptel chat buffer's header line with the button to toggle media support"></a>
<hr>
<p dir="auto">There are two ways to include media with requests:</p>
<ol dir="auto">
  <li>Adding media files to the context with <code>gptel-add-file</code>, described further below.</li>
  <li>Including links to media in chat buffers, described here:</li>
</ol>
<p dir="auto">To send media – images or other supported file types – with requests in chat buffers, you can include links to them in the chat buffer.  Such a link must be “standalone”, i.e. on a line by itself surrounded by whitespace.</p>
<p dir="auto">In Org mode, for example, the following are all <b>valid</b> ways of including an image with the request:</p>
<ul dir="auto">
  <li>“Standalone” file link:</li>
</ul>
<pre>Describe this picture

[[file:/path/to/screenshot.png]]

Focus specifically on the text content.
</pre>
<ul dir="auto">
  <li>“Standalone” file link with description:</li>
</ul>
<pre>Describe this picture

[[file:/path/to/screenshot.png][some picture]]

Focus specifically on the text content.
</pre>
<ul dir="auto">
  <li>“Standalone”, angle file link:</li>
</ul>
<pre>Describe this picture

&lt;file:/path/to/screenshot.png&gt;

Focus specifically on the text content.
</pre>
<p dir="auto">The following links are <b>not valid</b>, and the text of the link will be sent instead of the file contents:</p>
<ul dir="auto">
  <li>Inline link:</li>
</ul>
<pre>Describe this [[file:/path/to/screenshot.png][picture]].

Focus specifically on the text content.
</pre>
<ul dir="auto">
  <li>Link not “standalone”:</li>
</ul>
<pre>Describe this picture: 
[[file:/path/to/screenshot.png]]
Focus specifically on the text content.
</pre>
<ul dir="auto">
  <li>Not a valid Org link:</li>
</ul>
<pre>Describe the picture

file:/path/to/screenshot.png
</pre>
<p dir="auto">Similar criteria apply to Markdown chat buffers.</p>
</details>
<details><summary>
<p dir="auto"><h4 tabindex="-1" dir="auto">Save and restore your chat sessions</h4><a id="user-content-save-and-restore-your-chat-sessions" aria-label="Permalink: Save and restore your chat sessions" href="#save-and-restore-your-chat-sessions"></a></p>
</summary>
<p dir="auto">Saving the file will save the state of the conversation as well.  To resume the chat, open the file and turn on <code>gptel-mode</code> before editing the buffer.</p>
</details>
<p dir="auto"><h3 tabindex="-1" dir="auto">Include more context with requests</h3><a id="user-content-include-more-context-with-requests" aria-label="Permalink: Include more context with requests" href="#include-more-context-with-requests"></a></p>
<p dir="auto">By default, gptel will query the LLM with the active region or the buffer contents up to the cursor.  Often it can be helpful to provide the LLM with additional context from outside the current buffer. For example, when you’re in a chat buffer but want to ask questions about a (possibly changing) code buffer and auxiliary project files.</p>
<p dir="auto">You can include additional text regions, buffers or files with gptel’s queries.  This additional context is “live” and not a snapshot.  Once added, the regions, buffers or files are scanned and included at the time of each query.  When using multi-modal models, added files can be of any supported type – typically images.</p>
<p dir="auto">You can add a selected region, buffer or file to gptel’s context from the menu, or call <code>gptel-add</code>.  (To add a file use <code>gptel-add</code> in Dired or use the dedicated <code>gptel-add-file</code> command.)</p>
<p dir="auto">You can examine the active context from the menu:</p>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/8607532/342006376-63cd7fc8-6b3e-42ae-b6ca-06ff935bae9c.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzA3MDIxMDEsIm5iZiI6MTczMDcwMTgwMSwicGF0aCI6Ii84NjA3NTMyLzM0MjAwNjM3Ni02M2NkN2ZjOC02YjNlLTQyYWUtYjZjYS0wNmZmOTM1YmFlOWMucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MTEwNCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDExMDRUMDYzMDAxWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9ZjdkMjEyNTM2NWZhZGYwOTlkZjYxMjc1MmJkYjZlNmQ2MTdhZjc3NmEyNjU3ZWZiZjk1MWRjMTRjZTQwN2JkZCZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.ZHy1S-7UHn0gJ0hGRQusjvyP9nWBlhNmOo4eRGjXRMk"><img src="https://private-user-images.githubusercontent.com/8607532/342006376-63cd7fc8-6b3e-42ae-b6ca-06ff935bae9c.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzA3MDIxMDEsIm5iZiI6MTczMDcwMTgwMSwicGF0aCI6Ii84NjA3NTMyLzM0MjAwNjM3Ni02M2NkN2ZjOC02YjNlLTQyYWUtYjZjYS0wNmZmOTM1YmFlOWMucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MTEwNCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDExMDRUMDYzMDAxWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9ZjdkMjEyNTM2NWZhZGYwOTlkZjYxMjc1MmJkYjZlNmQ2MTdhZjc3NmEyNjU3ZWZiZjk1MWRjMTRjZTQwN2JkZCZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.ZHy1S-7UHn0gJ0hGRQusjvyP9nWBlhNmOo4eRGjXRMk" alt="Image showing gptel's menu with the "></a>
<p dir="auto">And then browse through or remove context from the context buffer:</p>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/8607532/342006378-79a5ffe8-3d63-4bf7-9bf6-0457ab61bf2a.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzA3MDIxMDEsIm5iZiI6MTczMDcwMTgwMSwicGF0aCI6Ii84NjA3NTMyLzM0MjAwNjM3OC03OWE1ZmZlOC0zZDYzLTRiZjctOWJmNi0wNDU3YWI2MWJmMmEucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MTEwNCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDExMDRUMDYzMDAxWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9ZTAyYmQ4N2M5ODQ3YmI5MTA0NTMzYmEwYTQxMGRiMjk4MTVmNWZmMzBlYmIwZjlkNzNmMzRmY2NmNzJmMzNlOCZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.UvRFbVbq8t2ov3b_04ba4DRkuLMcYcgiE6obSKddoHM"><img src="https://private-user-images.githubusercontent.com/8607532/342006378-79a5ffe8-3d63-4bf7-9bf6-0457ab61bf2a.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzA3MDIxMDEsIm5iZiI6MTczMDcwMTgwMSwicGF0aCI6Ii84NjA3NTMyLzM0MjAwNjM3OC03OWE1ZmZlOC0zZDYzLTRiZjctOWJmNi0wNDU3YWI2MWJmMmEucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MTEwNCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDExMDRUMDYzMDAxWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9ZTAyYmQ4N2M5ODQ3YmI5MTA0NTMzYmEwYTQxMGRiMjk4MTVmNWZmMzBlYmIwZjlkNzNmMzRmY2NmNzJmMzNlOCZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.UvRFbVbq8t2ov3b_04ba4DRkuLMcYcgiE6obSKddoHM" alt="Image showing gptel's context buffer."></a>
<p dir="auto"><h3 tabindex="-1" dir="auto">Rewrite, refactor or fill in a region</h3><a id="user-content-rewrite-refactor-or-fill-in-a-region" aria-label="Permalink: Rewrite, refactor or fill in a region" href="#rewrite-refactor-or-fill-in-a-region"></a></p>
<p dir="auto">In any buffer: with a region selected, you can rewrite prose or refactor code from here:</p>
<p dir="auto"><b>Prose</b>:</p>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/8607532/365940610-172e75cd-11e9-4f3b-9ab9-b4edfb8f6695.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzA3MDIxMDEsIm5iZiI6MTczMDcwMTgwMSwicGF0aCI6Ii84NjA3NTMyLzM2NTk0MDYxMC0xNzJlNzVjZC0xMWU5LTRmM2ItOWFiOS1iNGVkZmI4ZjY2OTUucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MTEwNCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDExMDRUMDYzMDAxWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9NTE0M2YzNmIyOTg5NzUxM2Y2Mjg4MmM1MDcxMjRmMTc5ZmFkNzEwMGFhZTZkN2Q5OGFmMmJlMzI2ZDVjYmYzYSZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.yS0YIwBW1Obs97_OahUoFlsEyAc_K-GCcP0zRoTWUsE"><img src="https://private-user-images.githubusercontent.com/8607532/365940610-172e75cd-11e9-4f3b-9ab9-b4edfb8f6695.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzA3MDIxMDEsIm5iZiI6MTczMDcwMTgwMSwicGF0aCI6Ii84NjA3NTMyLzM2NTk0MDYxMC0xNzJlNzVjZC0xMWU5LTRmM2ItOWFiOS1iNGVkZmI4ZjY2OTUucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MTEwNCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDExMDRUMDYzMDAxWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9NTE0M2YzNmIyOTg5NzUxM2Y2Mjg4MmM1MDcxMjRmMTc5ZmFkNzEwMGFhZTZkN2Q5OGFmMmJlMzI2ZDVjYmYzYSZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.yS0YIwBW1Obs97_OahUoFlsEyAc_K-GCcP0zRoTWUsE"></a>
<p dir="auto"><b>Code</b>:</p>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/8607532/365940620-8670ddb3-8655-47f4-a70c-8994994e61e3.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzA3MDIxMDEsIm5iZiI6MTczMDcwMTgwMSwicGF0aCI6Ii84NjA3NTMyLzM2NTk0MDYyMC04NjcwZGRiMy04NjU1LTQ3ZjQtYTcwYy04OTk0OTk0ZTYxZTMucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MTEwNCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDExMDRUMDYzMDAxWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9ODQ3ZGM0MjU1ZTQzYTljMWRhNDJlYjVmNzhiMmJiNjUzYzEwYWJmYTEzNzJjY2NjZmM2YjY1YzA1YzhkMGRiNyZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.gCNnTf2JWon0JMMzJt6X0FOCnlI1Ed-thVOQvbD8fjs"><img src="https://private-user-images.githubusercontent.com/8607532/365940620-8670ddb3-8655-47f4-a70c-8994994e61e3.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzA3MDIxMDEsIm5iZiI6MTczMDcwMTgwMSwicGF0aCI6Ii84NjA3NTMyLzM2NTk0MDYyMC04NjcwZGRiMy04NjU1LTQ3ZjQtYTcwYy04OTk0OTk0ZTYxZTMucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MTEwNCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDExMDRUMDYzMDAxWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9ODQ3ZGM0MjU1ZTQzYTljMWRhNDJlYjVmNzhiMmJiNjUzYzEwYWJmYTEzNzJjY2NjZmM2YjY1YzA1YzhkMGRiNyZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.gCNnTf2JWon0JMMzJt6X0FOCnlI1Ed-thVOQvbD8fjs"></a>
<p dir="auto">When the refactor is ready, you can apply it or compare against the original:</p>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/8607532/365940614-a0cf33b2-3ad3-4f55-aa7b-4349e54d6771.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzA3MDIxMDEsIm5iZiI6MTczMDcwMTgwMSwicGF0aCI6Ii84NjA3NTMyLzM2NTk0MDYxNC1hMGNmMzNiMi0zYWQzLTRmNTUtYWE3Yi00MzQ5ZTU0ZDY3NzEucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MTEwNCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDExMDRUMDYzMDAxWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9YjFhNDUzZmExNjFkMmVjMTdlYWM0OGZhYzFhMmE1NDA2MzY0YzRkY2FmMzBjNTEzOTdmYWU3ODk3M2RmNTRmYyZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.1nvdV4vIiHVvjo1_6Iu6PewA1ZsCC4K29RwKeMIqoWk"><img src="https://private-user-images.githubusercontent.com/8607532/365940614-a0cf33b2-3ad3-4f55-aa7b-4349e54d6771.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzA3MDIxMDEsIm5iZiI6MTczMDcwMTgwMSwicGF0aCI6Ii84NjA3NTMyLzM2NTk0MDYxNC1hMGNmMzNiMi0zYWQzLTRmNTUtYWE3Yi00MzQ5ZTU0ZDY3NzEucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MTEwNCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDExMDRUMDYzMDAxWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9YjFhNDUzZmExNjFkMmVjMTdlYWM0OGZhYzFhMmE1NDA2MzY0YzRkY2FmMzBjNTEzOTdmYWU3ODk3M2RmNTRmYyZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.1nvdV4vIiHVvjo1_6Iu6PewA1ZsCC4K29RwKeMIqoWk"></a>
<p dir="auto">These actions are also available directly when the cursor is inside the pending rewrite region:</p>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/8607532/365940607-57e1fff7-f8e4-47f0-9bda-d0b698443559.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzA3MDIxMDEsIm5iZiI6MTczMDcwMTgwMSwicGF0aCI6Ii84NjA3NTMyLzM2NTk0MDYwNy01N2UxZmZmNy1mOGU0LTQ3ZjAtOWJkYS1kMGI2OTg0NDM1NTkucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MTEwNCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDExMDRUMDYzMDAxWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9ZTUzZTA4MDcyOTU0YmE2NzhiZGIwYjYzMzQyOTdmNTk5NjM3Y2JlOTEyMDM2MWU3ZTIyNWNhMzlhMDEzYjI2ZCZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.U4R5EUDylkoJiHUnOfo0hkTcgEbk1WPTt9JPpDL2ZTE"><img src="https://private-user-images.githubusercontent.com/8607532/365940607-57e1fff7-f8e4-47f0-9bda-d0b698443559.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzA3MDIxMDEsIm5iZiI6MTczMDcwMTgwMSwicGF0aCI6Ii84NjA3NTMyLzM2NTk0MDYwNy01N2UxZmZmNy1mOGU0LTQ3ZjAtOWJkYS1kMGI2OTg0NDM1NTkucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MTEwNCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDExMDRUMDYzMDAxWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9ZTUzZTA4MDcyOTU0YmE2NzhiZGIwYjYzMzQyOTdmNTk5NjM3Y2JlOTEyMDM2MWU3ZTIyNWNhMzlhMDEzYjI2ZCZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.U4R5EUDylkoJiHUnOfo0hkTcgEbk1WPTt9JPpDL2ZTE"></a>
<p dir="auto"><h3 tabindex="-1" dir="auto">Extra Org mode conveniences</h3><a id="user-content-extra-org-mode-conveniences" aria-label="Permalink: Extra Org mode conveniences" href="#extra-org-mode-conveniences"></a></p>
<p dir="auto">gptel offers a few extra conveniences in Org mode.</p>
<ul dir="auto">
  <li>You can limit the conversation context to an Org heading with the command <code>gptel-org-set-topic</code>.</li>
  <li>You can have branching conversations in Org mode, where each hierarchical outline path through the document is a separate conversation branch.  This is also useful for limiting the context size of each query.  See the variable <code>gptel-org-branching-context</code>.
    Note: using this option requires Org 9.6.7 or higher to be available.  The <a href="https://github.com/ultronozm/ai-org-chat.el">ai-org-chat</a> package uses gptel to provide this branching conversation behavior for older versions of Org.</li>
  <li>You can declare the gptel model, backend, temperature, system message and other parameters as Org properties with the command <code>gptel-org-set-properties</code>.  gptel queries under the corresponding heading will always use these settings, allowing you to create mostly reproducible LLM chat notebooks, and to have simultaneous chats with different models, model settings and directives under different Org headings.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">FAQ</h2><a id="user-content-faq" aria-label="Permalink: FAQ" href="#faq"></a></p>
<details><summary>
<p dir="auto"><h4 tabindex="-1" dir="auto">I want the window to scroll automatically as the response is inserted</h4><a id="user-content-i-want-the-window-to-scroll-automatically-as-the-response-is-inserted" aria-label="Permalink: I want the window to scroll automatically as the response is inserted" href="#i-want-the-window-to-scroll-automatically-as-the-response-is-inserted"></a></p>
</summary>
<p dir="auto">To be minimally annoying, gptel does not move the cursor by default.  Add the following to your configuration to enable auto-scrolling.</p>
<div dir="auto" data-snippet-clipboard-copy-content="(add-hook 'gptel-post-stream-hook 'gptel-auto-scroll)"><pre>(<span>add-hook</span> <span>'gptel-post-stream-hook</span> <span>'gptel-auto-scroll</span>)</pre></div>
</details>
<details><summary>
<p dir="auto"><h4 tabindex="-1" dir="auto">I want the cursor to move to the next prompt after the response is inserted</h4><a id="user-content-i-want-the-cursor-to-move-to-the-next-prompt-after-the-response-is-inserted" aria-label="Permalink: I want the cursor to move to the next prompt after the response is inserted" href="#i-want-the-cursor-to-move-to-the-next-prompt-after-the-response-is-inserted"></a></p>
</summary>
<p dir="auto">To be minimally annoying, gptel does not move the cursor by default.  Add the following to your configuration to move the cursor:</p>
<div dir="auto" data-snippet-clipboard-copy-content="(add-hook 'gptel-post-response-functions 'gptel-end-of-response)"><pre>(<span>add-hook</span> <span>'gptel-post-response-functions</span> <span>'gptel-end-of-response</span>)</pre></div>
<p dir="auto">You can also call <code>gptel-end-of-response</code> as a command at any time.</p>
</details>
<details><summary>
<p dir="auto"><h4 tabindex="-1" dir="auto">I want to change the formatting of the prompt and LLM response</h4><a id="user-content-i-want-to-change-the-formatting-of-the-prompt-and-llm-response" aria-label="Permalink: I want to change the formatting of the prompt and LLM response" href="#i-want-to-change-the-formatting-of-the-prompt-and-llm-response"></a></p>
</summary>
<p dir="auto">For dedicated chat buffers: customize <code>gptel-prompt-prefix-alist</code> and <code>gptel-response-prefix-alist</code>.  You can set a different pair for each major-mode.</p>
<p dir="auto">Anywhere in Emacs: Use <code>gptel-pre-response-hook</code> and <code>gptel-post-response-functions</code>, which see.</p>
</details>
<details><summary>
<p dir="auto"><h4 tabindex="-1" dir="auto">I want the transient menu options to be saved so I only need to set them once</h4><a id="user-content-i-want-the-transient-menu-options-to-be-saved-so-i-only-need-to-set-them-once" aria-label="Permalink: I want the transient menu options to be saved so I only need to set them once" href="#i-want-the-transient-menu-options-to-be-saved-so-i-only-need-to-set-them-once"></a></p>
</summary>
<p dir="auto">Any model options you set are saved for the current buffer.  But the redirection options in the menu are set for the next query only:</p>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/8607532/298437596-2ecc6be9-aa52-4287-a739-ba06e1369ec2.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzA3MDIxMDEsIm5iZiI6MTczMDcwMTgwMSwicGF0aCI6Ii84NjA3NTMyLzI5ODQzNzU5Ni0yZWNjNmJlOS1hYTUyLTQyODctYTczOS1iYTA2ZTEzNjllYzIucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MTEwNCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDExMDRUMDYzMDAxWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9ZTc5ODc1MzkyYTVhOGRhZTRhNjAyNjk5NjU2YjRiNTkyNWVhYzUxODRiOGQ4OTUzYWVjZjkwNTg4OGFjZjJlYyZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.NcvUe7-u4f_817v593QAqEgc11g_bJblOxJ7qAb0Ehk"><img src="https://private-user-images.githubusercontent.com/8607532/298437596-2ecc6be9-aa52-4287-a739-ba06e1369ec2.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzA3MDIxMDEsIm5iZiI6MTczMDcwMTgwMSwicGF0aCI6Ii84NjA3NTMyLzI5ODQzNzU5Ni0yZWNjNmJlOS1hYTUyLTQyODctYTczOS1iYTA2ZTEzNjllYzIucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MTEwNCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDExMDRUMDYzMDAxWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9ZTc5ODc1MzkyYTVhOGRhZTRhNjAyNjk5NjU2YjRiNTkyNWVhYzUxODRiOGQ4OTUzYWVjZjkwNTg4OGFjZjJlYyZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.NcvUe7-u4f_817v593QAqEgc11g_bJblOxJ7qAb0Ehk" alt="https://github.com/karthink/gptel/assets/8607532/2ecc6be9-aa52-4287-a739-ba06e1369ec2"></a>
<p dir="auto">You can make them persistent across this Emacs session by pressing <code>C-x C-s</code>:</p>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/8607532/298438187-b8bcb6ad-c974-41e1-9336-fdba0098a2fe.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzA3MDIxMDEsIm5iZiI6MTczMDcwMTgwMSwicGF0aCI6Ii84NjA3NTMyLzI5ODQzODE4Ny1iOGJjYjZhZC1jOTc0LTQxZTEtOTMzNi1mZGJhMDA5OGEyZmUucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MTEwNCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDExMDRUMDYzMDAxWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9NmNmNWE3MTMzYThkY2JmY2ZhYjdiNTA0ZWE0ZmM0ZjFjNmVkMWMxMDYxYmZhMjlhMmJlNjljYmJmYjUwZTFmZCZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.oA194Nj-NoQn_RDhsMOsh8XVbwNREeZ8QqVuHlwmj_8"><img src="https://private-user-images.githubusercontent.com/8607532/298438187-b8bcb6ad-c974-41e1-9336-fdba0098a2fe.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzA3MDIxMDEsIm5iZiI6MTczMDcwMTgwMSwicGF0aCI6Ii84NjA3NTMyLzI5ODQzODE4Ny1iOGJjYjZhZC1jOTc0LTQxZTEtOTMzNi1mZGJhMDA5OGEyZmUucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MTEwNCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDExMDRUMDYzMDAxWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9NmNmNWE3MTMzYThkY2JmY2ZhYjdiNTA0ZWE0ZmM0ZjFjNmVkMWMxMDYxYmZhMjlhMmJlNjljYmJmYjUwZTFmZCZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.oA194Nj-NoQn_RDhsMOsh8XVbwNREeZ8QqVuHlwmj_8" alt="https://github.com/karthink/gptel/assets/8607532/b8bcb6ad-c974-41e1-9336-fdba0098a2fe"></a>
<p dir="auto">(You can also cycle through presets you’ve saved with <code>C-x p</code> and <code>C-x n</code>.)</p>
<p dir="auto">Now these will be enabled whenever you send a query from the transient menu.  If you want to use these saved options without invoking the transient menu, you can use a keyboard macro:</p>
<div dir="auto" data-snippet-clipboard-copy-content=";; Replace with your key to invoke the transient menu:
(keymap-global-set &quot;<f6>&quot; &quot;C-u C-c <return> <return>&quot;)"><pre><span><span>;</span>; Replace with your key to invoke the transient menu:</span>
(keymap-global-set <span><span>"</span>&lt;f6&gt;<span>"</span></span> <span><span>"</span>C-u C-c &lt;return&gt; &lt;return&gt;<span>"</span></span>)</pre></div>
<p dir="auto">Or see this <a href="https://github.com/karthink/gptel/wiki/Commonly-requested-features#save-transient-flags">wiki entry</a>.</p>
</details>
<details><summary>
<p dir="auto"><h4 tabindex="-1" dir="auto">I want to use gptel in a way that’s not supported by <code>gptel-send</code> or the options menu</h4><a id="user-content-i-want-to-use-gptel-in-a-way-thats-not-supported-by-gptel-send-or-the-options-menu" aria-label="Permalink: I want to use gptel in a way that’s not supported by gptel-send or the options menu" href="#i-want-to-use-gptel-in-a-way-thats-not-supported-by-gptel-send-or-the-options-menu"></a></p>
</summary>
<p dir="auto">gptel’s default usage pattern is simple, and will stay this way: Read input in any buffer and insert the response below it.  Some custom behavior is possible with the transient menu (<code>C-u M-x gptel-send</code>).</p>
<p dir="auto">For more programmable usage, gptel provides a general <code>gptel-request</code> function that accepts a custom prompt and a callback to act on the response. You can use this to build custom workflows not supported by <code>gptel-send</code>.  See the documentation of <code>gptel-request</code>, and the <a href="https://github.com/karthink/gptel/wiki/Defining-custom-gptel-commands">wiki</a> for examples.</p>
</details>
<details><summary>
<p dir="auto"><h4 tabindex="-1" dir="auto">(Doom Emacs) Sending a query from the gptel menu fails because of a key conflict with Org mode</h4><a id="user-content-doom-emacs-sending-a-query-from-the-gptel-menu-fails-because-of-a-key-conflict-with-org-mode" aria-label="Permalink: (Doom Emacs) Sending a query from the gptel menu fails because of a key conflict with Org mode" href="#doom-emacs-sending-a-query-from-the-gptel-menu-fails-because-of-a-key-conflict-with-org-mode"></a></p>
</summary>
<p dir="auto">Doom binds <code>RET</code> in Org mode to <code>+org/dwim-at-point</code>, which appears to conflict with gptel’s transient menu bindings for some reason.</p>
<p dir="auto">Two solutions:</p>
<ul dir="auto">
  <li>Press <code>C-m</code> instead of the return key.</li>
  <li>Change the send key from return to a key of your choice:
    <div dir="auto" data-snippet-clipboard-copy-content="(transient-suffix-put 'gptel-menu (kbd &quot;RET&quot;) :key &quot;<f8>&quot;)
    "><pre>(transient-suffix-put <span>'gptel-menu</span> (<span>kbd</span> <span><span>"</span>RET<span>"</span></span>) <span>:key</span> <span><span>"</span>&lt;f8&gt;<span>"</span></span>)
    </pre></div>
  </li>
</ul>
</details>
<details><summary>
<p dir="auto"><h4 tabindex="-1" dir="auto">(ChatGPT) I get the error “(HTTP/2 429) You exceeded your current quota”</h4><a id="user-content-chatgpt-i-get-the-error-http2-429-you-exceeded-your-current-quota" aria-label="Permalink: (ChatGPT) I get the error “(HTTP/2 429) You exceeded your current quota”" href="#chatgpt-i-get-the-error-http2-429-you-exceeded-your-current-quota"></a></p>
</summary>
<blockquote>
  <p dir="auto">(HTTP/2 429) You exceeded your current quota, please check your plan and billing details.</p>
</blockquote>
<p dir="auto">Using the ChatGPT (or any OpenAI) API requires <a href="https://platform.openai.com/account/billing/overview" rel="nofollow">adding credit to your account</a>.</p>
</details>
<details><summary>
<p dir="auto"><h4 tabindex="-1" dir="auto">Why another LLM client?</h4><a id="user-content-why-another-llm-client" aria-label="Permalink: Why another LLM client?" href="#why-another-llm-client"></a></p>
</summary>
<p dir="auto">Other Emacs clients for LLMs prescribe the format of the interaction (a comint shell, org-babel blocks, etc).  I wanted:</p>
<ol dir="auto">
  <li>Something that is as free-form as possible: query the model using any text in any buffer, and redirect the response as required.  Using a dedicated <code>gptel</code> buffer just adds some visual flair to the interaction.</li>
  <li>Integration with org-mode, not using a walled-off org-babel block, but as regular text.  This way the model can generate code blocks that I can run.</li>
</ol>
</details>
<p dir="auto"><h2 tabindex="-1" dir="auto">Additional Configuration</h2><a id="user-content-additional-configuration" aria-label="Permalink: Additional Configuration" href="#additional-configuration"></a></p>
<markdown-accessiblity-table><table>
  <tbody><tr><th><b>Connection options</b></th><th></th></tr>
  <tr><td><code>gptel-use-curl</code></td><td>Use Curl (default), fallback to Emacs’ built-in <code>url</code>.</td></tr>
  <tr><td><code>gptel-proxy</code></td><td>Proxy server for requests, passed to curl via <code>--proxy</code>.</td></tr>
  <tr><td><code>gptel-api-key</code></td><td>Variable/function that returns the API key for the active backend.</td></tr>
  <tr><th><b>LLM request options</b></th><th><i>(Note: not supported uniformly across LLMs)</i></th></tr>
  <tr><td><code>gptel-backend</code></td><td>Default LLM Backend.</td></tr>
  <tr><td><code>gptel-model</code></td><td>Default model to use, depends on the backend.</td></tr>
  <tr><td><code>gptel-stream</code></td><td>Enable streaming responses, if the backend supports it.</td></tr>
  <tr><td><code>gptel-directives</code></td><td>Alist of system directives, can switch on the fly.</td></tr>
  <tr><td><code>gptel-max-tokens</code></td><td>Maximum token count (in query + response).</td></tr>
  <tr><td><code>gptel-temperature</code></td><td>Randomness in response text, 0 to 2.</td></tr>
  <tr><td><code>gptel-use-context</code></td><td>How/whether to include additional context</td></tr>
  <tr><th><b>Chat UI options</b></th><th></th></tr>
  <tr><td><code>gptel-default-mode</code></td><td>Major mode for dedicated chat buffers.</td></tr>
  <tr><td><code>gptel-track-response</code></td><td>Distinguish between user messages and LLM responses?</td></tr>
  <tr><td><code>gptel-track-media</code></td><td>Send images or other media from links?</td></tr>
  <tr><td><code>gptel-prompt-prefix-alist</code></td><td>Text inserted before queries.</td></tr>
  <tr><td><code>gptel-response-prefix-alist</code></td><td>Text inserted before responses.</td></tr>
  <tr><td><code>gptel-use-header-line</code></td><td>Display status messages in header-line (default) or minibuffer</td></tr>
  <tr><td><code>gptel-display-buffer-action</code></td><td>Placement of the gptel chat buffer.</td></tr>
  <tr><th><b>Org mode UI options</b></th><th></th></tr>
  <tr><td><code>gptel-org-branching-context</code></td><td>Make each outline path a separate conversation branch</td></tr>
  <tr><th><b>Hooks for customization</b></th><th></th></tr>
  <tr><td><code>gptel-save-state-hook</code></td><td>Runs before saving the chat state to a file on disk</td></tr>
  <tr><td><code>gptel-pre-response-hook</code></td><td>Runs before inserting the LLM response into the buffer</td></tr>
  <tr><td><code>gptel-post-response-functions</code></td><td>Runs after inserting the full LLM response into the buffer</td></tr>
  <tr><td><code>gptel-post-stream-hook</code></td><td>Runs after each streaming insertion</td></tr>
  <tr><td><code>gptel-context-wrap-function</code></td><td>To include additional context formatted your way</td></tr>
</tbody></table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Alternatives</h2><a id="user-content-alternatives" aria-label="Permalink: Alternatives" href="#alternatives"></a></p>
<p dir="auto">Other Emacs clients for LLMs include</p>
<ul dir="auto">
  <li><a href="https://github.com/ahyatt/llm">llm</a>: llm provides a uniform API across language model providers for building LLM clients in Emacs, and is intended as a library for use by package authors.  For similar scripting purposes, gptel provides the command <code>gptel-request</code>, which see.</li>
  <li><a href="https://github.com/s-kostyaev/ellama">Ellama</a>: A full-fledged LLM client built on llm, that supports many LLM providers (Ollama, Open AI, Vertex, GPT4All and more).  Its usage differs from gptel in that it provides separate commands for dozens of common tasks, like general chat, summarizing code/text, refactoring code, improving grammar, translation and so on.</li>
  <li><a href="https://github.com/xenodium/chatgpt-shell">chatgpt-shell</a>: comint-shell based interaction with ChatGPT.  Also supports DALL-E, executable code blocks in the responses, and more.</li>
  <li><a href="https://github.com/rksm/org-ai">org-ai</a>: Interaction through special <code>#+begin_ai ... #+end_ai</code> Org-mode blocks.  Also supports DALL-E, querying ChatGPT with the contents of project files, and more.</li>
</ul>
<p dir="auto">There are several more: <a href="https://github.com/MichaelBurge/leafy-mode">leafy-mode</a>, <a href="https://github.com/iwahbe/chat.el">chat.el</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Packages using gptel</h3><a id="user-content-packages-using-gptel" aria-label="Permalink: Packages using gptel" href="#packages-using-gptel"></a></p>
<p dir="auto">gptel is a general-purpose package for chat and ad-hoc LLM interaction.  The following packages use gptel to provide additional or specialized functionality:</p>
<ul dir="auto">
  <li><a href="https://github.com/karthink/gptel-quick">gptel-quick</a>: Quickly look up the region or text at point.</li>
  <li><a href="https://github.com/daedsidog/evedel">Evedel</a>: Instructed LLM Programmer/Assistant</li>
  <li><a href="https://github.com/lanceberge/elysium">Elysium</a>: Automatically apply AI-generated changes as you code</li>
  <li><a href="https://github.com/kamushadenes/gptel-extensions.el">gptel-extensions</a>: Extra utility functions for gptel</li>
  <li><a href="https://github.com/kamushadenes/ai-blog.el">ai-blog.el</a>: Streamline generation of blog posts in Hugo</li>
  <li><a href="https://github.com/douo/magit-gptcommit">magit-gptcommit</a>: Generate Commit Messages within magit-status Buffer using gptel</li>
  <li><a href="https://github.com/armindarvish/consult-omni">consult-omni</a>: Versatile multi-source search package.  It includes gptel as one of its many sources.</li>
  <li><a href="https://github.com/ultronozm/ai-org-chat.el">ai-org-chat</a>: Provides branching conversations in Org buffers using gptel.  (Note that gptel includes this feature as well (see <code>gptel-org-branching-context</code>), but requires a recent version of Org mode (9.67 or later) to be installed.)</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Acknowledgments</h2><a id="user-content-acknowledgments" aria-label="Permalink: Acknowledgments" href="#acknowledgments"></a></p>
<ul dir="auto">
  <li><a href="https://github.com/algal">Alexis Gallagher</a> and <a href="https://github.com/d1egoaz">Diego Alvarez</a> for fixing a nasty multi-byte bug with <code>url-retrieve</code>.</li>
  <li><a href="https://github.com/tarsius">Jonas Bernoulli</a> for the Transient library.</li>
  <li><a href="https://github.com/daedsidog">daedsidog</a> for adding context support to gptel.</li>
  <li><a href="https://github.com/Aquan1412">Aquan1412</a> for adding PrivateGPT support to gptel.</li>
  <li><a href="https://github.com/r0man">r0man</a> for improving gptel’s Curl integration.</li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ToolGit: A collection of scripts that extend Git with various sub-commands (110 pts)]]></title>
            <link>https://github.com/ahmetsait/toolgit</link>
            <guid>42034521</guid>
            <pubDate>Sun, 03 Nov 2024 17:32:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/ahmetsait/toolgit">https://github.com/ahmetsait/toolgit</a>, See on <a href="https://news.ycombinator.com/item?id=42034521">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto">ToolGit is a collection of scripts that extend Git with various sub-commands to make life easier.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Commands</h2><a id="user-content-commands" aria-label="Permalink: Commands" href="#commands"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Command</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>git-amend</code></td>
<td>Amend currently staged changes.</td>
</tr>
<tr>
<td><code>git-delete-gone-branches</code></td>
<td>Delete local branches that no longer exist on remote.</td>
</tr>
<tr>
<td><code>git-dir</code></td>
<td>Output <code>.git</code> directory path of this Git repository.</td>
</tr>
<tr>
<td><code>git-force-pull</code></td>
<td>Fetch and force pull remote tracking branch(es) by doing a hard reset.</td>
</tr>
<tr>
<td><code>git-forward</code></td>
<td>Fetch and fast forward all remote tracking branches.</td>
</tr>
<tr>
<td><code>git-gc-all</code></td>
<td>Expire the reflog and run a full garbage collection on the Git repository.</td>
</tr>
<tr>
<td><code>git-in-repo</code></td>
<td>Returns 0 if current working directory is a Git repository, non-zero otherwise.</td>
</tr>
<tr>
<td><code>git-is-branch-remote</code></td>
<td>Returns 0 if the branch(es) refer to a remote branch.</td>
</tr>
<tr>
<td><code>git-is-head-detached</code></td>
<td>Returns 0 if HEAD is in detached state, non-zero otherwise.</td>
</tr>
<tr>
<td><code>git-is-worktree-clean</code></td>
<td>Returns 0 if the working tree has no changes or untracked files, non-zero otherwise.</td>
</tr>
<tr>
<td><code>git-legacy</code></td>
<td>Rebase the whole history of current HEAD on top of .</td>
</tr>
<tr>
<td><code>git-main-branch</code></td>
<td>Get the name of the main (default) branch.</td>
</tr>
<tr>
<td><code>git-mode-restore</code></td>
<td>Restore file modes in index and/or worktree.</td>
</tr>
<tr>
<td><code>git-root</code></td>
<td>Output root path of this Git repository.</td>
</tr>
<tr>
<td><code>git-xlog</code></td>
<td>Search history for string only in added or removed lines.</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Downloads</h2><a id="user-content-downloads" aria-label="Permalink: Downloads" href="#downloads"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto"><a href="https://github.com/ahmetsait/toolgit/archive/refs/heads/main.tar.gz">Tarball (Posix)</a></h3><a id="user-content-tarball-posix" aria-label="Permalink: Tarball (Posix)" href="#tarball-posix"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto"><a href="https://github.com/ahmetsait/toolgit/archive/refs/heads/main.zip">Zip (Windows)</a></h3><a id="user-content-zip-windows" aria-label="Permalink: Zip (Windows)" href="#zip-windows"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installing</h2><a id="user-content-installing" aria-label="Permalink: Installing" href="#installing"></a></p>
<p dir="auto">Extract ToolGit to an appropriate folder of your choice and add the folder path to your <code>PATH</code> environment variable. Git will recognize executable <code>git-*</code> files in <code>PATH</code> and allow using them as sub-commands.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Getting Started</h2><a id="user-content-getting-started" aria-label="Permalink: Getting Started" href="#getting-started"></a></p>
<p dir="auto">Use <code>-?</code> switch to learn about commands and their options. Example:</p>
<div data-snippet-clipboard-copy-content="$ git mode-restore -?
usage: git-mode-restore [-s <tree-ish>] [-W] [-S] [-8] [-n] [-q] [-?] path [path ...]

Restore file modes in index and/or worktree.

positional arguments:
  path

options:
  -s <tree-ish>, --source <tree-ish>
                        Restore file modes from the given tree. If not specified, the modes are restored from HEAD if --staged is given, otherwise from the index.
  -W, --worktree        The working tree modes are restored. This is the default.
  -S, --staged          File modes in the index are restored. Specifying both --worktree and --staged restores both index and worktree.
  -8, --octal           Print permissions in octal based numeric format instead of using 'rwx' letters.
  -n, --dry-run         Don’t actually restore file modes, just show what would happen.
  -q, --quiet           Suppress printing file permission changes to standard output.
  -?, --help            Show this help text and exit."><pre><code>$ git mode-restore -?
usage: git-mode-restore [-s &lt;tree-ish&gt;] [-W] [-S] [-8] [-n] [-q] [-?] path [path ...]

Restore file modes in index and/or worktree.

positional arguments:
  path

options:
  -s &lt;tree-ish&gt;, --source &lt;tree-ish&gt;
                        Restore file modes from the given tree. If not specified, the modes are restored from HEAD if --staged is given, otherwise from the index.
  -W, --worktree        The working tree modes are restored. This is the default.
  -S, --staged          File modes in the index are restored. Specifying both --worktree and --staged restores both index and worktree.
  -8, --octal           Print permissions in octal based numeric format instead of using 'rwx' letters.
  -n, --dry-run         Don’t actually restore file modes, just show what would happen.
  -q, --quiet           Suppress printing file permission changes to standard output.
  -?, --help            Show this help text and exit.
</code></pre></div>
<p dir="auto">Example <code>mode-restore</code> usage:</p>
<div data-snippet-clipboard-copy-content="$ git status
On branch main
Your branch is up to date with 'origin/main'.

Changes not staged for commit:
  (use &quot;git add <file>...&quot; to update what will be committed)
  (use &quot;git restore <file>...&quot; to discard changes in working directory)
        modified:   .editorconfig
        modified:   .gitattributes
        modified:   .vscode/launch.json
        modified:   .vscode/tasks.json
        modified:   README.md
        modified:   UNLICENSE.txt

no changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;)"><pre><code>$ git status
On branch main
Your branch is up to date with 'origin/main'.

Changes not staged for commit:
  (use "git add &lt;file&gt;..." to update what will be committed)
  (use "git restore &lt;file&gt;..." to discard changes in working directory)
        modified:   .editorconfig
        modified:   .gitattributes
        modified:   .vscode/launch.json
        modified:   .vscode/tasks.json
        modified:   README.md
        modified:   UNLICENSE.txt

no changes added to commit (use "git add" and/or "git commit -a")
</code></pre></div>
<div data-snippet-clipboard-copy-content="$ git diff
diff --git a/.editorconfig b/.editorconfig
old mode 100644
new mode 100755
diff --git a/.gitattributes b/.gitattributes
old mode 100644
new mode 100755
diff --git a/.vscode/launch.json b/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/.vscode/tasks.json b/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/README.md b/README.md
old mode 100644
new mode 100755
diff --git a/UNLICENSE.txt b/UNLICENSE.txt
old mode 100644
new mode 100755"><pre><code>$ git diff
diff --git a/.editorconfig b/.editorconfig
old mode 100644
new mode 100755
diff --git a/.gitattributes b/.gitattributes
old mode 100644
new mode 100755
diff --git a/.vscode/launch.json b/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/.vscode/tasks.json b/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/README.md b/README.md
old mode 100644
new mode 100755
diff --git a/UNLICENSE.txt b/UNLICENSE.txt
old mode 100644
new mode 100755
</code></pre></div>
<div data-snippet-clipboard-copy-content="$ git mode-restore .
rwxrwxr-x -> rw-rw-r--: .editorconfig
rwxrwxr-x -> rw-rw-r--: .gitattributes
rwxrwxr-x -> rw-rw-r--: .vscode/launch.json
rwxrwxr-x -> rw-rw-r--: .vscode/tasks.json
rwxrwxr-x -> rw-rw-r--: README.md
rwxrwxr-x -> rw-rw-r--: UNLICENSE.txt"><pre><code>$ git mode-restore .
rwxrwxr-x -&gt; rw-rw-r--: .editorconfig
rwxrwxr-x -&gt; rw-rw-r--: .gitattributes
rwxrwxr-x -&gt; rw-rw-r--: .vscode/launch.json
rwxrwxr-x -&gt; rw-rw-r--: .vscode/tasks.json
rwxrwxr-x -&gt; rw-rw-r--: README.md
rwxrwxr-x -&gt; rw-rw-r--: UNLICENSE.txt
</code></pre></div>
<div data-snippet-clipboard-copy-content="$ git status
On branch main
Your branch is up to date with 'origin/main'.

nothing to commit, working tree clean"><pre><code>$ git status
On branch main
Your branch is up to date with 'origin/main'.

nothing to commit, working tree clean
</code></pre></div>
</article></div></div>]]></description>
        </item>
    </channel>
</rss>