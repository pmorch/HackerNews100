<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 07 Aug 2025 19:30:05 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[GPT-5: Key characteristics, pricing and system card (159 pts)]]></title>
            <link>https://simonwillison.net/2025/Aug/7/gpt-5/</link>
            <guid>44827794</guid>
            <pubDate>Thu, 07 Aug 2025 17:46:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://simonwillison.net/2025/Aug/7/gpt-5/">https://simonwillison.net/2025/Aug/7/gpt-5/</a>, See on <a href="https://news.ycombinator.com/item?id=44827794">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-permalink-context="/2025/Aug/7/gpt-5/">

<p>7th August 2025</p>



<p>I’ve had preview access to the new GPT-5 model family for the past two weeks (see <a href="https://simonwillison.net/2025/Aug/7/previewing-gpt-5/">related video</a>) and have been using GPT-5 as my daily-driver. It’s my new favorite model. It’s still an LLM—it’s not a dramatic departure from what we’ve had before—but it rarely screws up and generally feels competent or occasionally impressive at the kinds of things I like to use models for.</p>
<p>I’ve collected a lot of notes over the past two weeks, so I’ve decided to break them up into <a href="https://simonwillison.net/series/gpt-5/">a series of posts</a>. This first one will cover key characteristics of the models, how they are priced and what we can learn from the <a href="https://openai.com/index/gpt-5-system-card/">GPT-5 system card</a>.</p>
<ul>
<li><a href="https://simonwillison.net/2025/Aug/7/gpt-5/#key-model-characteristics">Key model characteristics</a></li>
<li><a href="https://simonwillison.net/2025/Aug/7/gpt-5/#position-in-the-openai-model-family">Position in the OpenAI model family</a></li>
<li><a href="https://simonwillison.net/2025/Aug/7/gpt-5/#pricing-is-aggressively-competitive">Pricing is aggressively competitive</a></li>
<li><a href="https://simonwillison.net/2025/Aug/7/gpt-5/#more-notes-from-the-system-card">More notes from the system card</a></li>
<li><a href="https://simonwillison.net/2025/Aug/7/gpt-5/#prompt-injection-in-the-system-card">Prompt injection in the system card</a></li>
<li><a href="https://simonwillison.net/2025/Aug/7/gpt-5/#thinking-traces-in-the-api">Thinking traces in the API</a></li>
<li><a href="https://simonwillison.net/2025/Aug/7/gpt-5/#and-some-svgs-of-pelicans">And some SVGs of pelicans</a></li>
</ul>

<h4 id="key-model-characteristics">Key model characteristics</h4>
<p>Let’s start with the fundamentals. GPT-5 in ChatGPT is a weird hybrid that switches between different models. Here’s what the system card says about that (my highlights in bold):</p>
<blockquote>
<p>GPT-5 is a unified system with a smart and fast model that answers most questions, a deeper reasoning model for harder problems, and <strong>a real-time router that quickly decides which model to use based on conversation type, complexity, tool needs, and explicit intent</strong> (for example, if you say “think hard about this” in the prompt). [...] Once usage limits are reached, a mini version of each model handles remaining queries. In the near future, we plan to integrate these capabilities into a single model.</p>
</blockquote>
<p>GPT-5 in the API is simpler: it’s available as three models—<strong>regular</strong>, <strong>mini</strong> and <strong>nano</strong>—which can each be run at one of four reasoning levels: minimal (a new level not previously available for other OpenAI reasoning models), low, medium or high.</p>
<p>The models have an input limit of 272,000 tokens and an output limit (which includes invisible reasoning tokens) of 128,000 tokens. They support text and image for input, text only for output.</p>
<p>I’ve mainly explored full GPT-5. My verdict: it’s just <strong>good at stuff</strong>. It doesn’t feel like a dramatic leap ahead from other LLMs but it exudes competence—it rarely messes up, and frequently impresses me. I’ve found it to be a very sensible default for everything that I want to do. At no point have I found myself wanting to re-run a prompt against a different model to try and get a better result.</p>

<p>Here are the OpenAI model pages for <a href="https://platform.openai.com/docs/models/gpt-5">GPT-5</a>, <a href="https://platform.openai.com/docs/models/gpt-5-mini">GPT-5 mini</a> and <a href="https://platform.openai.com/docs/models/gpt-5-nano">GPT-5 nano</a>. Knowledge cut-off is September 30th 2024 for GPT-5 and May 30th 2024 for GPT-5 mini and nano.</p>

<h4 id="position-in-the-openai-model-family">Position in the OpenAI model family</h4>
<p>The three new GPT-5 models are clearly intended as a replacement for most of the rest of the OpenAI line-up. This table from the system card is useful, as it shows how they see the new models fitting in:</p>
<table>
<thead>
<tr>
<th>Previous model</th>
<th>GPT-5 model</th>
</tr>
</thead>
<tbody>
<tr>
<td>GPT-4o</td>
<td>gpt-5-main</td>
</tr>
<tr>
<td>GPT-4o-mini</td>
<td>gpt-5-main-mini</td>
</tr>
<tr>
<td>OpenAI o3</td>
<td>gpt-5-thinking</td>
</tr>
<tr>
<td>OpenAI o4-mini</td>
<td>gpt-5-thinking-mini</td>
</tr>
<tr>
<td>GPT-4.1-nano</td>
<td>gpt-5-thinking-nano</td>
</tr>
<tr>
<td>OpenAI o3 Pro</td>
<td>gpt-5-thinking-pro</td>
</tr>
</tbody>
</table>
<p>That “thinking-pro” model is currently only available via ChatGPT where it is labelled as “GPT-5 Pro” and limited to the $200/month tier. It uses “parallel test time compute”.</p>
<p>The only capabilities not covered by GPT-5 are audio input/output and image generation. Those remain covered by models like <a href="https://platform.openai.com/docs/models/gpt-4o-audio-preview">GPT-4o Audio</a> and <a href="https://platform.openai.com/docs/models/gpt-4o-realtime-preview">GPT-4o Realtime</a> and their mini variants and the <a href="https://platform.openai.com/docs/models/gpt-image-1">GPT Image 1</a> and DALL-E image generation models.</p>
<h4 id="pricing-is-aggressively-competitive">Pricing is aggressively competitive</h4>
<p>The pricing is <em>aggressively competitive</em> with other providers.</p>
<ul>
<li>GPT-5: $1.25/million for input, $10/million for output</li>
<li>GPT-5 Mini: $0.25/m input, $2.00/m output</li>
<li>GPT-5 Nano: $0.05/m input, $0.40/m output</li>
</ul>
<p>GPT-5 is priced at half the input cost of GPT-4o, and maintains the same price for output. Those invisible reasoning tokens count as output tokens so you can expect most prompts to use more output tokens than their GPT-4o equivalent (unless you set reasoning effort to “minimal”).</p>
<p>The discount for token caching is significant too: 90% off on input tokens that have been used within the previous few minutes. This is particularly material if you are implementing a chat UI where the same conversation gets replayed every time the user adds another prompt to the sequence.</p>
<p>Here’s a comparison table I put together showing the new models alongside the most comparable models from OpenAI’s competition:</p>
<table>
<thead>
<tr>
<th>Model</th>
<th>Input $/m</th>
<th>Output $/m</th>
</tr>
</thead>
<tbody>
<tr>
<td>Claude Opus 4.1</td>
<td>15.00</td>
<td>75.00</td>
</tr>
<tr>
<td>Claude Sonnet 4</td>
<td>3.00</td>
<td>15.00</td>
</tr>
<tr>
<td>Grok 4</td>
<td>3.00</td>
<td>15.00</td>
</tr>
<tr>
<td>Gemini 2.5 Pro (&gt;200,000)</td>
<td>2.50</td>
<td>15.00</td>
</tr>
<tr>
<td>GPT-4o</td>
<td>2.50</td>
<td>10.00</td>
</tr>
<tr>
<td>GPT-4.1</td>
<td>2.00</td>
<td>8.00</td>
</tr>
<tr>
<td>o3</td>
<td>2.00</td>
<td>8.00</td>
</tr>
<tr>
<td>Gemini 2.5 Pro (&lt;200,000)</td>
<td>1.25</td>
<td>10.00</td>
</tr>
<tr>
<td><strong>GPT-5</strong></td>
<td>1.25</td>
<td>10.00</td>
</tr>
<tr>
<td>o4-mini</td>
<td>1.10</td>
<td>4.40</td>
</tr>
<tr>
<td>Claude 3.5 Haiku</td>
<td>0.80</td>
<td>4.00</td>
</tr>
<tr>
<td>GPT-4.1 mini</td>
<td>0.40</td>
<td>1.60</td>
</tr>
<tr>
<td>Gemini 2.5 Flash</td>
<td>0.30</td>
<td>2.50</td>
</tr>
<tr>
<td>Grok 3 Mini</td>
<td>0.30</td>
<td>0.50</td>
</tr>
<tr>
<td><strong>GPT-5 Mini</strong></td>
<td>0.25</td>
<td>2.00</td>
</tr>
<tr>
<td>GPT-4o mini</td>
<td>0.15</td>
<td>0.60</td>
</tr>
<tr>
<td>Gemini 2.5 Flash-Lite</td>
<td>0.10</td>
<td>0.40</td>
</tr>
<tr>
<td>GPT-4.1 Nano</td>
<td>0.10</td>
<td>0.40</td>
</tr>
<tr>
<td>Amazon Nova Lite</td>
<td>0.06</td>
<td>0.24</td>
</tr>
<tr>
<td><strong>GPT-5 Nano</strong></td>
<td>0.05</td>
<td>0.40</td>
</tr>
<tr>
<td>Amazon Nova Micro</td>
<td>0.035</td>
<td>0.14</td>
</tr>
</tbody>
</table>
<p>(Here’s a good example of a GPT-5 failure: I tried to get it to <a href="https://chatgpt.com/share/6894d804-bca4-8006-ac46-580bf4a9bf5f">output that table sorted itself</a> but it put Nova Micro as more expensive than GPT-5 Nano, so I prompted it to “construct the table in Python and sort it there” and that fixed the issue.)</p>
<h4 id="more-notes-from-the-system-card">More notes from the system card</h4>
<p>As usual, <a href="">the system card</a> is vague on what went into the training data. Here’s what it says:</p>
<blockquote>
<p>Like OpenAI’s other models, the GPT-5 models were trained on diverse datasets, including information that is publicly available on the internet, information that we partner with third parties to access, and information that our users or human trainers and researchers provide or generate. [...] We use advanced data filtering processes to reduce personal information from training data.</p>
</blockquote>
<p>I found this section interesting, as it reveals that writing, code and health are three of the most common use-cases for ChatGPT. This explains why so much effort went into health-related questions,  for both GPT-5 and the recently released OpenAI open weight models.</p>
<blockquote>
<p>We’ve made significant advances in <strong>reducing hallucinations, improving instruction following, and minimizing sycophancy</strong>, and have leveled up GPT-5’s performance in <strong>three of ChatGPT’s most common uses: writing, coding, and health</strong>. All of the GPT-5 models additionally feature <strong>safe-completions, our latest approach to safety training</strong> to prevent disallowed content.</p>
</blockquote>
<p>Safe-completions is later described like this:</p>
<blockquote>
<p>Large language models such as those powering ChatGPT have <strong>traditionally been trained to
either be as helpful as possible or outright refuse a user request</strong>, depending on whether the
prompt is allowed by safety policy. [...] Binary refusal boundaries are especially ill-suited for dual-use cases (such as biology
or cybersecurity), where a user request can be completed safely at a high level, but may lead
to malicious uplift if sufficiently detailed or actionable. <strong>As an alternative, we introduced safe-
completions: a safety-training approach that centers on the safety of the assistant’s output rather
than a binary classification of the user’s intent</strong>. Safe-completions seek to maximize helpfulness
subject to the safety policy’s constraints.</p>
</blockquote>
<p>So instead of straight up refusals, we should expect GPT-5 to still provide an answer but moderate that answer to avoid it including “harmful” content.</p>
<p>OpenAI have a paper about this which I haven’t read yet (I didn’t get early access): <a href="https://openai.com/index/gpt-5-safe-completions/">From Hard Refusals to Safe-Completions: Toward Output-Centric Safety Training</a>.</p>
<p>Sycophancy gets a mention, unsurprising given <a href="https://simonwillison.net/2025/May/2/what-we-missed-with-sycophancy/">their high profile disaster in April</a>. They’ve worked on this in the core model:</p>
<blockquote>
<p>System
prompts, while easy to modify, have a more limited impact on model outputs relative to changes in
post-training. For GPT-5, we post-trained our models to reduce sycophancy. Using conversations
representative of production data, we evaluated model responses, then assigned a score reflecting
the level of sycophancy, which was used as a reward signal in training.</p>
</blockquote>
<p>They claim impressive reductions in hallucinations. In my own usage I’ve not spotted a single hallucination yet, but that’s been true for me for Claude 4 and o3 recently as well—hallucination is so much less of a problem with this year’s models.</p>
<blockquote>
<p>One of our focuses when training the GPT-5 models was to reduce the frequency of factual
hallucinations. While ChatGPT has browsing enabled by default, many API queries do not use
browsing tools. Thus, we focused both on training our models to browse effectively for up-to-date
information, and on reducing hallucinations when the models are relying on their own internal
knowledge.</p>
</blockquote>
<p>The section about deception also incorporates the thing where models sometimes pretend they’ve completed a task that defeated them:</p>
<blockquote>
<p>We placed gpt-5-thinking in a variety of tasks that were partly or entirely infeasible to accomplish,
and <strong>rewarded the model for honestly admitting it can not complete the task</strong>. [...]</p>
<p>In tasks where the agent is required to use tools, such as a web browsing
tool, in order to answer a user’s query, previous models would hallucinate information when
the tool was unreliable. We simulate this scenario by purposefully disabling the tools or by
making them return error codes.</p>
</blockquote>
<h4 id="prompt-injection-in-the-system-card">Prompt injection in the system card</h4>
<p>There’s a section about prompt injection, but it’s pretty weak sauce in my opinion.</p>
<blockquote>
<p>Two external red-teaming groups conducted a two-week prompt-injection assessment targeting
system-level vulnerabilities across ChatGPT’s connectors and mitigations, rather than model-only
behavior.</p>
</blockquote>
<p>Here’s their chart showing how well the model scores against the rest of the field. It’s an impressive result in comparison—56.8 attack success rate for gpt-5-thinking, where Claude 3.7 scores in the 60s (no Claude 4 results included here) and everything else is 70% plus:</p>
<p><img src="https://static.simonwillison.net/static/2025/prompt-injection-chart.jpg" alt="A bar chart titled &quot;Behavior Attack Success Rate at k Queries&quot; shows attack success rates (in %) for various AI models at k=1 (dark red) and k=10 (light red). For each model, the total height of the stacked bar represents the k=10 success rate (labeled above each bar), while the lower dark red section represents the k=1 success rate (estimated). From left to right: Llama 3.3 70B – k=10: 92.2%, k=1: ~47%; Llama 3.1 405B – k=10: 90.9%, k=1: ~38%; Gemini Flash 1.5 – k=10: 87.7%, k=1: ~34%; GPT-4o – k=10: 86.4%, k=1: ~28%; OpenAI o3-mini-high – k=10: 86.4%, k=1: ~41%; Gemini Pro 1.5 – k=10: 85.5%, k=1: ~34%; Gemini 2.5 Pro Preview – k=10: 85.0%, k=1: ~28%; Gemini 2.0 Flash – k=10: 85.0%, k=1: ~33%; OpenAI o3-mini – k=10: 84.5%, k=1: ~40%; Grok 2 – k=10: 82.7%, k=1: ~34%; GPT-4.5 – k=10: 80.5%, k=1: ~28%; 3.5 Haiku – k=10: 76.4%, k=1: ~17%; Command-R – k=10: 76.4%, k=1: ~28%; OpenAI o4-mini – k=10: 75.5%, k=1: ~17%; 3.5 Sonnet – k=10: 75.0%, k=1: ~13%; OpenAI o1 – k=10: 71.8%, k=1: ~18%; 3.7 Sonnet – k=10: 64.5%, k=1: ~17%; 3.7 Sonnet: Thinking – k=10: 63.6%, k=1: ~17%; OpenAI o3 – k=10: 62.7%, k=1: ~13%; gpt-5-thinking – k=10: 56.8%, k=1: ~6%. Legend shows dark red = k=1 and light red = k=10."></p>
<p>On the one hand, a 56.8% attack rate is cleanly a big improvement against all of those other models.</p>
<p>But it’s also a strong signal that prompt injection continues to be an unsolved problem! That means that more than half of those k=10 attacks (where the attacker was able to try up to ten times) got through.</p>
<p>Don’t assume prompt injection isn’t going to be a problem for your application just because the models got better.</p>
<h4 id="thinking-traces-in-the-api">Thinking traces in the API</h4>
<p>I had initially thought that my biggest disappointment with GPT-5 was that there’s no way to get at those thinking traces via the API... but that turned out <a href="https://bsky.app/profile/sophiebits.com/post/3lvtceih7222r">not to be true</a>. The following <code>curl</code> command demonstrates that the responses API <code>"reasoning": {"summary": "auto"}</code> is available for the new GPT-5 models:</p>

<pre><code>curl https://api.openai.com/v1/responses \
  -H "Authorization: Bearer $(llm keys get openai)" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gpt-5",
    "input": "Give me a one-sentence fun fact about octopuses.",
    "reasoning": {"summary": "auto"}
  }'</code></pre>

<p>Here’s <a href="https://gist.github.com/simonw/1d1013ba059af76461153722005a039d">the response</a> from that API call.</p>

<p>Without that option the API will often provide a lengthy delay while the model burns through thinking tokens until you start getting back visible tokens for the final response.</p>
<p>OpenAI offer a new <code>reasoning_effort=minimal</code> option which turns off most reasoning so that tokens start to stream back to you as quickly as possible.</p>
<h4 id="and-some-svgs-of-pelicans">And some SVGs of pelicans</h4>
<p>Naturally I’ve been running <a href="https://simonwillison.net/tags/pelican-riding-a-bicycle/">my “Generate an SVG of a pelican riding a bicycle” benchmark</a>. I’ll actually spend more time on this in a future post—I have some fun variants I’ve been exploring—but for the moment here’s <a href="https://gist.github.com/simonw/c98873ef29e621c0fe2e0d4023534406">the pelican</a> I got from GPT-5 running at its default “medium” reasoning effort:</p>
<p><img src="https://static.simonwillison.net/static/2025/gpt-5-pelican.png" alt="The bicycle is really good, spokes on wheels, correct shape frame, nice pedals. The pelican has a pelican beak and long legs stretching to the pedals."></p>
<p>It’s pretty great! Definitely recognizable as a pelican, and one of the best bicycles I’ve seen yet.</p>
<p>Here’s <a href="https://gist.github.com/simonw/9b5ecf61a5fb0794729aa0023aaa504d">GPT-5 mini</a>:</p>
<p><img src="https://static.simonwillison.net/static/2025/gpt-5-mini-pelican.png" alt="Blue background with clouds. Pelican has two necks for some reason. Has a good beak though. More gradents and shadows than the GPT-5 one."></p>
<p>And <a href="https://gist.github.com/simonw/3884dc8b186b630956a1fb0179e191bc">GPT-5 nano</a>:</p>
<p><img src="https://static.simonwillison.net/static/2025/gpt-5-nano-pelican.png" alt="Bicycle is two circles and some randomish black lines. Pelican still has an OK beak but is otherwise very simple."></p>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GPT-5 for Developers (208 pts)]]></title>
            <link>https://openai.com/index/introducing-gpt-5-for-developers</link>
            <guid>44827101</guid>
            <pubDate>Thu, 07 Aug 2025 17:06:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://openai.com/index/introducing-gpt-5-for-developers">https://openai.com/index/introducing-gpt-5-for-developers</a>, See on <a href="https://news.ycombinator.com/item?id=44827101">Hacker News</a></p>
Couldn't get https://openai.com/index/introducing-gpt-5-for-developers: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[GPT-5 (834 pts)]]></title>
            <link>http://openai.com/gpt-5</link>
            <guid>44826997</guid>
            <pubDate>Thu, 07 Aug 2025 17:00:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://openai.com/gpt-5">http://openai.com/gpt-5</a>, See on <a href="https://news.ycombinator.com/item?id=44826997">Hacker News</a></p>
Couldn't get http://openai.com/gpt-5: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Live: GPT-5 (168 pts)]]></title>
            <link>https://www.youtube.com/watch?v=0Uu_VJeVVfo</link>
            <guid>44826463</guid>
            <pubDate>Thu, 07 Aug 2025 16:16:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.youtube.com/watch?v=0Uu_VJeVVfo">https://www.youtube.com/watch?v=0Uu_VJeVVfo</a>, See on <a href="https://news.ycombinator.com/item?id=44826463">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Building Bluesky Comments for My Blog (178 pts)]]></title>
            <link>https://natalie.sh/posts/bluesky-comments/</link>
            <guid>44826164</guid>
            <pubDate>Thu, 07 Aug 2025 15:56:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://natalie.sh/posts/bluesky-comments/">https://natalie.sh/posts/bluesky-comments/</a>, See on <a href="https://news.ycombinator.com/item?id=44826164">Hacker News</a></p>
<div id="readability-page-1" class="page"><p data-astro-cid-2q5oecfc=""> I hate disqus too much. </p><article data-astro-cid-2q5oecfc=""> 
<p>I’ve been running my blog without decent comments for years. Not by choice, really - I just couldn’t find a solution that didn’t suck.</p>
<ul>
<li>
<p>Disqus? Slow, heavy, tracks users, and I don’t own anything. Plus it makes every page 100x slower to load.</p>
</li>
<li>
<p>Self-hosted solutions? Great in theory. (not really.) You’re signing up to manage users, moderate spam, maintain databases, and deal with all the headaches that come with running basically a miniature social platform. And if your users aren’t where you are, it’s probably slow as hell.</p>
</li>
<li>
<p>GitHub Issues as comments? Probably works for some developer blogs, but feels hacky and limits your audience to people with GitHub accounts.</p>
</li>
<li>
<p>No comments at all? Clean and simple, but you lose the conversations. Some of my favorite discoveries came from comment threads that went in unexpected directions.</p>
</li>
</ul>
<p>I’ve been a Bluesky user for a while. Recently, the community has been feeling healthier than Twitter ever did, the API is designed, and this decentralized approach means I don’t necessarily have to be beholden to a single company. People have been doing some interesting things with Bluesky, like on-protocol blog content and using Bluesky comments as a comment system. Why not do some of that for myself?</p>
<h2 id="why-bluesky-actually-makes-sense">Why Bluesky Actually Makes Sense</h2>
<p>The more I thought about it, the more directly using Bluesky for comments made sense:</p>
<ul>
<li>
<p>No infrastructure to maintain. (for me, at least) I don’t need to run databases, manage user accounts, or build moderation tools. Bluesky handles all of that.</p>
</li>
<li>
<p>Rich(er) content support. People can post images, links, and in threads. All the stuff that makes conversations interesting.</p>
</li>
<li>
<p>Real identities. Since people are using their actual Bluesky profiles, and your one profile can <em>actually</em> be used on any supported platform, there’s more accountability and less incentive to drive-by troll.</p>
</li>
<li>
<p>Cross-platform conversations. Comments live on Bluesky too, so people can discover my blog posts through social media and vice versa.</p>
</li>
<li>
<p>I own my content, they own theirs. No platform lock-in for anyone!</p>
</li>
</ul>
<p>The workflow is simple: I publish a blog post, share it on Bluesky, edit the post to add the AT URI, and the replies to that Bluesky post become the comments on my blog.</p>
<h2 id="building-the-component">Building the Component</h2>
<h3 id="understanding-the-at-protocol">Understanding the AT Protocol</h3>
<p>Bluesky runs on the AT Protocol, which has surprisingly okay documentation. The key concepts I needed:</p>
<ul>
<li><strong>DIDs</strong> (Decentralized Identifiers): Unique user IDs like <code>did:plc:abc123...</code> or <code>did:web:joe.coffee</code></li>
<li><strong>CIDs</strong> (Content Identifiers): Unique post IDs</li>
<li><strong>AT URIs</strong>: Addresses for content like <code>at://did:plc:user.../app.bsky.feed.post/postid</code></li>
</ul>
<p>To fetch comments, I just need to call the <code>getPostThread</code> endpoint with the right URI. No authentication required. Easy peasy.</p>
<h3 id="component-architecture">Component Architecture</h3>
<p>I ended up with three main pieces:</p>
<ol>
<li>The main comments component that fetches and displays the thread.</li>
<li>A reply component that handles rendering individual posts and their replies. Also includes metadata and a link to the original Bluesky post.</li>
<li>An embed component for rich content like images and open graph previews.</li>
</ol>
<p>This separation made each piece reasonably manageable, reasonable, and small.</p>
<h3 id="the-threading-challenge">The Threading Challenge</h3>
<p>The interesting part was handling nested replies. Bluesky threads can go arbitrarily deep, but I needed to display them in a way that’s readable and doesn’t break layouts.</p>
<p>I settled on a naive recursive approach where each reply can render child replies, with visual indentation to show the hierarchy. I cap it at 5 levels deep because beyond that, conversations usually devolve into two people arguing anyway.</p>
<pre tabindex="0" data-language="typescript"><code><span><span>const</span><span> MAX_DEPTH </span><span>=</span><span> 5</span><span>;</span></span>
<span><span>const</span><span> BlueskyReply</span><span> =</span><span> ({</span><span> thread</span><span>,</span><span> depth</span><span> =</span><span> 0</span><span> })</span><span> =&gt;</span><span> {</span></span>
<span><span>  return</span><span> (</span></span>
<span><span>    &lt;</span><span>div style</span><span>=</span><span>{{</span><span> marginLeft</span><span>:</span><span> depth </span><span>*</span><span> 12</span><span> }}</span><span>&gt;</span></span>
<span><span>      {</span><span>/* Render the post content */</span><span>}</span></span>
<span></span>
<span><span>      {</span><span>depth</span><span> &lt; </span><span>MAX_DEPTH</span><span> &amp;&amp; </span><span>thread</span><span>.</span><span>replies</span><span>?.</span><span>map</span><span>(</span><span>reply</span><span> =&gt;</span></span>
<span><span>        &lt;</span><span>BlueskyReply</span><span> thread</span><span>=</span><span>{</span><span>reply</span><span>}</span><span> depth</span><span>=</span><span>{</span><span>depth + </span><span>1</span><span>}</span><span> /&gt;</span></span>
<span><span>      )</span><span>}</span></span>
<span><span>    &lt;/</span><span>div</span><span>&gt;</span></span>
<span><span>  )</span><span>;</span></span>
<span><span>};</span></span></code></pre>
<h3 id="handling-rich-content">Handling Rich Content</h3>
<p>One of the nice things about Bluesky is that posts can contain more than just text. People embed images, external links, and even quote other posts. Each embed type needs special handling.</p>
<p><strong>Images</strong> were the most complex. Bluesky serves them through their CDN, and people often post multiple images in a single reply. I built a responsive grid layout that adapts based on image count, plus a modal for viewing images full-screen.</p>
<p><strong>External links</strong> get rendered as cards with thumbnails and descriptions, just like they appear in Bluesky apps.</p>
<p><strong>Other embed types</strong> get a graceful fallback message since the AT Protocol is extensible and new embed types might appear.</p>
<h3 id="integrating-with-astro">Integrating with Astro</h3>
<p>Getting this working with my Astro blog was straightforward. I had the React integration (which I already had for my background and music components) and used the <code>client:load</code> directive to ensure the comment component hydrates immediately:</p>
<pre tabindex="0" data-language="astro"><code><span><span>---</span></span>
<span><span>import</span><span> BlueskyComments </span><span>from</span><span> '../components/bsky-comments.tsx'</span><span>;</span></span>
<span><span>---</span></span>
<span></span>
<span><span>{</span><span>post</span><span>.</span><span>data</span><span>.</span><span>bsky </span><span>&amp;&amp;</span><span> (</span></span>
<span><span>  &lt;</span><span>BlueskyComments</span></span>
<span><span>    did</span><span>=</span><span>{</span><span>post</span><span>.</span><span>data</span><span>.</span><span>bsky</span><span>.</span><span>did</span><span>}</span></span>
<span><span>    postCid</span><span>=</span><span>{</span><span>post</span><span>.</span><span>data</span><span>.</span><span>bsky</span><span>.</span><span>postCid</span><span>}</span></span>
<span><span>    client</span><span>:</span><span>load</span></span>
<span><span>  /&gt;</span></span>
<span><span>)</span><span>}</span></span></code></pre>
<p>Now I just add this to any post’s frontmatter to enable comments:</p>
<pre tabindex="0" data-language="yaml"><code><span><span>bsky</span><span>:</span></span>
<span><span>  did</span><span>:</span><span> "my-bluesky-did"</span></span>
<span><span>  postCid</span><span>:</span><span> "the-post-id"</span></span></code></pre>
<h2 id="what-i-learned">What I Learned</h2>
<h3 id="typescript-is-your-friend">TypeScript is Your Friend</h3>
<p>There are proper TypeScript types for all their API responses through the <code>@atcute/client</code> package. This made development much smoother as I could rely on autocomplete and catch type errors before they became runtime bugs.</p>
<h3 id="progressive-enhancement-works">Progressive Enhancement Works</h3>
<p>I built the comments as an enhancement to the blog, not a core dependency. If JavaScript is disabled or the API is down, the blog post (rendered a long time ago) still works perfectly. The comments just don’t appear.</p>
<h3 id="performance-by-default--ish">Performance by Default (-ish)</h3>
<p>Since I’m not managing any backend infrastructure, server-side performance optimizations are just there. Bluesky’s CDN handles image delivery, their public API is fast and cached, and I don’t have to care about database queries or server scaling.</p>
<h2 id="the-results">The Results</h2>
<p>I’m pretty happy with how it turned out. The conversations feel more natural than traditional blog comments - people use their actual profiles, share images and links, and more. It’s a lot more like social media.</p>
<h2 id="whats-next">What’s Next</h2>
<p>I’m considering a few improvements, but honestly, the core system works so well that I’m not in a rush to change it. Sometimes the best solution is the one just works, almost invisibly.</p>
<h2 id="why-this-approach-works">Why This Approach Works</h2>
<p>Traditional comment systems try to recreate social media features on every individual website. I think that’s backwards. People already have social media accounts they like using. Instead of forcing them to create new accounts and learn new interfaces, why not try meeting them where they already are?</p>
<p>This approach scales with the platform because it <em>uses</em> the platform. As Bluesky grows, more people can participate in blog discussions without any additional work from me. And because everything is built on open protocols, I’m not locked into any single platform’s decisions. If Bluesky ever changes for the worse, I can always switch to another AppView, such as zeppelin or Blacksky’s AppView.</p>
<p>I could theoretically even write my own comments AppView. ATProto is designed to be flexible, especially with data, so doing such would be quite simple. I’d just need to listen to the right events on the firehose and store the data in a way that makes sense and rebuild the comment thread every so often.</p>
<p>In my opinion, the web is better when independent sites can connect to broader conversations without sacrificing their independence. I feel like this <del>is</del> was the goal of other decentralised platforms like Mastodon, but Bluesky’s focus on user-owned identities and app intercompat via the PDS ultimately makes it a better fit.</p>
<hr>
<p><em>Want to see it in action? The comments are right below this post, powered by the system I mentioned above. Meta.</em></p> </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Open AI Announces $1.5M Bonus for Every Employee (115 pts)]]></title>
            <link>https://medium.com/activated-thinker/breaking-open-ai-announces-1-5-million-bonus-for-every-employee-29d057b9d590</link>
            <guid>44825309</guid>
            <pubDate>Thu, 07 Aug 2025 14:55:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://medium.com/activated-thinker/breaking-open-ai-announces-1-5-million-bonus-for-every-employee-29d057b9d590">https://medium.com/activated-thinker/breaking-open-ai-announces-1-5-million-bonus-for-every-employee-29d057b9d590</a>, See on <a href="https://news.ycombinator.com/item?id=44825309">Hacker News</a></p>
Couldn't get https://medium.com/activated-thinker/breaking-open-ai-announces-1-5-million-bonus-for-every-employee-29d057b9d590: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Let's stop pretending that managers and executives care about productivity (111 pts)]]></title>
            <link>https://www.baldurbjarnason.com/2025/disingenuous-discourse/</link>
            <guid>44824981</guid>
            <pubDate>Thu, 07 Aug 2025 14:33:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.baldurbjarnason.com/2025/disingenuous-discourse/">https://www.baldurbjarnason.com/2025/disingenuous-discourse/</a>, See on <a href="https://news.ycombinator.com/item?id=44824981">Hacker News</a></p>
Couldn't get https://www.baldurbjarnason.com/2025/disingenuous-discourse/: AggregateError]]></description>
        </item>
        <item>
            <title><![CDATA[Windows XP Professional (185 pts)]]></title>
            <link>https://win32.run/</link>
            <guid>44824539</guid>
            <pubDate>Thu, 07 Aug 2025 13:58:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://win32.run/">https://win32.run/</a>, See on <a href="https://news.ycombinator.com/item?id=44824539">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="pos_loader">
			<!-- Bootup by Kyle Stephens -->
			<!-- https://codepen.io/kylestephens/pen/zYOgLrr -->
			<section id="bios">
				<p>PhoenixBIOS 1.4 Release 6.0</p>
				<p>Copyright 1985-2001 Phoenix Technologies Ltd.</p>
				<p>All Rights Reserved</p>
				<p>Copyright 2001-2003 VMware. Inc.</p>
				<p>VMware BIOS build 314</p>
				
				<p>ATAPI CD-ROM: VMware Virtual IDECDROM Drive</p>
				<p>Initializing <span>...</span></p>
			  
			  </section>
			  
			
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Infinite Pixels (191 pts)]]></title>
            <link>https://meyerweb.com/eric/thoughts/2025/08/07/infinite-pixels/</link>
            <guid>44824056</guid>
            <pubDate>Thu, 07 Aug 2025 13:12:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://meyerweb.com/eric/thoughts/2025/08/07/infinite-pixels/">https://meyerweb.com/eric/thoughts/2025/08/07/infinite-pixels/</a>, See on <a href="https://news.ycombinator.com/item?id=44824056">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>I was on one of my rounds of social media trawling, just seeing what was floating through the aether, when I came across <a href="https://mastodon.art/@otterlove/114971594534242993">a toot by Andy P</a> that said:</p>
<blockquote>
<div><p>Fun #css trick:</p><p>

width: calc(infinity * 1px);<br>
height: calc(infinity * 1px);</p></div>
</blockquote>
<p>…and I immediately thought, <em>This is a perfect outer-limits probe!</em> By which I mean, if I hand a browser values that are effectively infinite by way of <a href="https://www.w3.org/TR/css-values-4/#calc-error-constants"> the<code>infinity</code> keyword</a>, it will necessarily end up clamping to something finite, thus revealing how far it’s able or willing to go for that property.</p>
<p>The first thing I did was exactly what Andy proposed, with a few extras to zero out box model extras:</p>
<pre><code>div {
	width: calc(infinity * 1px);&nbsp; 
	height: calc(infinity * 1px);
	margin: 0;
	padding: 0; }</code></pre>
<pre><code>&lt;body&gt;
&nbsp;  &lt;div&gt;I’m huge!&lt;/div&gt;
&lt;/body&gt;</code></pre>
<p>Then I loaded the (fully valid HTML 5) test page in Firefox Nightly, Chrome stable, and Safari stable, all on macOS, and things pretty immediately got weird:</p>
<table>
<caption>Element Size Results</caption>
<thead>
<tr>
<th>Browser</th>
<th>Computed value</th>
<th>Layout value</th>
</tr>
</thead>
<tbody>
<tr>
<td>Safari</td>
<td>33,554,428</td>
<td>33,554,428</td>
</tr>
<tr>
<td>Chrome</td>
<td>33,554,400</td>
<td>33,554,400</td>
</tr>
<tr>
<td>Firefox (Nightly)</td>
<td>19.2 / 17,895,700</td>
<td>19.2 / 8,947,840 †</td>
</tr>
</tbody>
</table>
<p><em>† height / width</em></p>
<p>Chrome and Safari both get <em>very</em> close to 2<sup>25</sup>-1 (33,554,431), with Safari backing off from that by just 3 pixels, and Firefox by 31.&nbsp; I can’t even hazard a guess as to why this sort of value would be limited in that way; if there was a period of time where 24-bit values were in vogue, I must have missed it.&nbsp; I assume this is somehow rooted in the pre-Blink-fork codebase, but who knows. (Seriously, who knows?&nbsp; I want to talk to you.)</p>
<p>But the faint whiff of oddness there has <em>nothing</em> on what’s happening in Firefox.&nbsp; First off, the computed height is<code>19.2px</code>, which is the height of a line of text at default font size and line height.&nbsp; If I explicitly gave it<code> line-height: 1</code>, the height of the <code>&lt;div&gt;</code> changes to 16px.&nbsp; All this is despite my assigning a height of infinite pixels!&nbsp; Which, to be fair, is not really possible to do, but does it make sense to just drop it on the floor rather than clamp to an upper bound?</p>
<p>Even if that can somehow be said to make sense, it <em>only</em> happens with height.&nbsp; The computed width value is, as indicated, nearly 17.9 million, which is not the content width and is also nowhere close to any power of two.&nbsp; But the actual layout width, according to the diagram in the Layout tab, is just over 8.9 million pixels; or, put another way, one-half of 17,895,700 <em> minus 10</em>.</p>
<p>This frankly makes my brain hurt.&nbsp; I would truly love to understand the reasons for any of these oddities.&nbsp; If you know from whence they arise, please, please leave a comment!&nbsp; The more detail, the better.&nbsp; I also accept trackbacks from blog posts if you want to get extra-detailed.</p>
<p>For the sake of my aching skullmeats, I almost called a halt there, but I decided to see what happened with font sizes.</p>
<pre><code>div {
	width: calc(infinity * 1px);&nbsp; 
	height: calc(infinity * 1px);
	margin: 0;
	padding: 0;
	font-size: calc(infinity * 1px); }</code></pre>
<p>My skullmeats did not thank me for this, because once again, things got…&nbsp;interesting.</p>
<table>
<caption>Font Size Results</caption>
<thead>
<tr>
<th>Browser</th>
<th>Computed value</th>
<th>Layout value</th>
</tr>
</thead>
<tbody>
<tr>
<td>Safari</td>
<td>100,000</td>
<td>100,000</td>
</tr>
<tr>
<td>Chrome</td>
<td>10,000</td>
<td>10,000</td>
</tr>
<tr>
<td>Firefox (Nightly)</td>
<td>3.40282e38</td>
<td>2,400 / 17,895,700 †</td>
</tr>
</tbody>
</table>
<p><em>† line height values of <code>normal</code> /<code>1</code></em></p>
<p>Safari and Chrome have pretty clearly set hard limits, with Safari’s an order of magnitude larger than Chrome’s.&nbsp; I get it: what are the odds of someone wanting their text to be any larger than, say, a viewport height, let alone ten or 100 times that height?&nbsp; What intrigues me is the nature of the limits, which are so clearly base-ten numbers that someone typed in at some point, rather than being limited by setting a register size or variable length or something that would have coughed up a power of two.</p>
<p>And speaking of powers of two… ah, Firefox.&nbsp; Your idiosyncrasy continues.&nbsp; The computed value is a 32-bit <a href="https://en.wikipedia.org/wiki/Single-precision_floating-point_format">single-precision floating-point</a> number.&nbsp; It doesn’t get used in any of the actual rendering, but that’s what it is.&nbsp; Instead, the actual font size of the text, as judged by the Box Model diagram on the Layout tab, is…&nbsp;2,400 pixels.</p>
<p>Except, I can’t say that’s the <em>actual</em> actual font size being used: I suspect the actual value is 2,000 with a line height of 1.2, which is generally what <code> normal</code> line heights are in browsers. “So why didn’t you just set <code> line-height: 1</code> to verify that, genius?” I hear you asking.&nbsp; I did!&nbsp; And that’s when the layout height of the <code>&lt;div&gt;</code> bloomed to just over 8.9 million pixels, like it probably should have in the previous test!&nbsp; And all the same stuff happened when I moved the styles from the<code>&lt;div&gt;</code> to the <code>&lt;body&gt;</code>!</p>
<p>I’ve started writing at least three different hypotheses for why this happens, and stopped halfway through each because each hypothesis self-evidently fell apart as I was writing it.&nbsp; Maybe if I give my whimpering neurons a rest, I could come up with something.&nbsp; Maybe not.&nbsp; All I know is, I’d be much happier if someone just explained it to me; bonus points if their name is Clarissa.</p>
<p>Since setting line heights opened the door to madness in font sizing, I thought I’d try setting <code>line-height</code> to infinite pixels and see what came out.&nbsp; This time, things were (relatively speaking) more sane.</p>
<table>
<caption>Line Height Results</caption>
<thead>
<tr>
<th>Browser</th>
<th>Computed value</th>
<th>Layout value</th>
</tr>
</thead>
<tbody>
<tr>
<td>Safari</td>
<td>33,554,428</td>
<td>33,554,428</td>
</tr>
<tr>
<td>Chrome</td>
<td>33,554,400</td>
<td>33,554,400</td>
</tr>
<tr>
<td>Firefox (Nightly)</td>
<td>17,895,700</td>
<td>8,947,840</td>
</tr>
</tbody>
</table>
<p>Essentially, the results were the same as what happened with element widths in the first example: Safari and Chrome were very close to 2<sup>25</sup>-1, and Firefox had its thing of a strange computed value and a rendering size not <em> quite</em> half the computed value.</p>
<p>I’m sure there’s a fair bit more to investigate about infinite-pixel values, or about infinite values in general, but I’m going to leave this here because my gray matter needs a rest and possibly a pressure washing.&nbsp; Still, if you have ideas for infinitely fun things to jam into browser engines and see what comes out, let me know.&nbsp; I’m already wondering what kind of shenanigans, other than in <code>z-index</code>, I can get up to with <code> calc(-infinity)</code>…</p> 
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI Ethics is being narrowed on purpose, like privacy was (159 pts)]]></title>
            <link>https://nimishg.substack.com/p/ai-ethics-is-being-narrowed-on-purpose</link>
            <guid>44823094</guid>
            <pubDate>Thu, 07 Aug 2025 11:20:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nimishg.substack.com/p/ai-ethics-is-being-narrowed-on-purpose">https://nimishg.substack.com/p/ai-ethics-is-being-narrowed-on-purpose</a>, See on <a href="https://news.ycombinator.com/item?id=44823094">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!DANS!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F400a5908-8000-4717-8537-bd326bb46886_1024x1024.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!DANS!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F400a5908-8000-4717-8537-bd326bb46886_1024x1024.png 424w, https://substackcdn.com/image/fetch/$s_!DANS!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F400a5908-8000-4717-8537-bd326bb46886_1024x1024.png 848w, https://substackcdn.com/image/fetch/$s_!DANS!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F400a5908-8000-4717-8537-bd326bb46886_1024x1024.png 1272w, https://substackcdn.com/image/fetch/$s_!DANS!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F400a5908-8000-4717-8537-bd326bb46886_1024x1024.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!DANS!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F400a5908-8000-4717-8537-bd326bb46886_1024x1024.png" width="1024" height="1024" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/400a5908-8000-4717-8537-bd326bb46886_1024x1024.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1024,&quot;width&quot;:1024,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:2158689,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://nimishg.substack.com/i/170332859?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F400a5908-8000-4717-8537-bd326bb46886_1024x1024.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!DANS!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F400a5908-8000-4717-8537-bd326bb46886_1024x1024.png 424w, https://substackcdn.com/image/fetch/$s_!DANS!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F400a5908-8000-4717-8537-bd326bb46886_1024x1024.png 848w, https://substackcdn.com/image/fetch/$s_!DANS!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F400a5908-8000-4717-8537-bd326bb46886_1024x1024.png 1272w, https://substackcdn.com/image/fetch/$s_!DANS!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F400a5908-8000-4717-8537-bd326bb46886_1024x1024.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p><br><span>A few days ago, OpenAI released an open-source language model for the first time in a very long time.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1-170332859" href="https://nimishg.substack.com/p/ai-ethics-is-being-narrowed-on-purpose#footnote-1-170332859" target="_self" rel="nofollow ugc noopener">1</a></span><span>  It had been promised for a while, but the deadline kept being pushed for “safety” concerns.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-2-170332859" href="https://nimishg.substack.com/p/ai-ethics-is-being-narrowed-on-purpose#footnote-2-170332859" target="_self" rel="nofollow ugc noopener">2</a></span></p><p><span>In fact, they’ve put quite a bit of time and effort into discussing safety</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-3-170332859" href="https://nimishg.substack.com/p/ai-ethics-is-being-narrowed-on-purpose#footnote-3-170332859" target="_self" rel="nofollow ugc noopener">3</a></span><span>, because, ostensibly, safety and ethics is at the top of people’s minds. </span></p><p>So, the public is worried about AI ethics, and OpenAI is putting efforts into making sure the AI is ethical. Sounds like a match. </p><p><span>Not just a match, but a great talking point. When the press or someone issues a question or challenge around ethics, they can point to the work they’re doing </span><strong>around that very subject</strong><span>, and superficially the questioner is shut down.</span></p><p><span>Except that’s not what people actually mean when they say “ethics”</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-4-170332859" href="https://nimishg.substack.com/p/ai-ethics-is-being-narrowed-on-purpose#footnote-4-170332859" target="_self" rel="nofollow ugc noopener">4</a></span><span>.  People are far more concerned with the </span><em>real-world </em><span>implications of ethics: governance structures, accountability, how their data is used, jobs being lost, etc.  In other words, they’re not so worried about whether their models will swear or philosophically handle the </span><a href="https://en.wikipedia.org/wiki/Trolley_problem" rel="nofollow ugc noopener">trolley problem</a><span> so much as, you know, reality. What happens with the </span><em>humans</em><span> running the models? </span><em>Their</em><span> influx of power and resources? How will </span><em>they</em><span> hurt or harm society? </span></p><p>This isn’t the first time this “redefining a legitimate concern” tactic has been used in tech. Way back, in the one thousand nine hundred and 90s, telemarketer calls were even more ubiquitous than they are now, and puzzled recipients would often ask “how did you even get my number?”</p><p><span>The answer was that telemarketing companies would just buy customer lists from other companies, who naively didn’t understand the true value of what they had</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-5-170332859" href="https://nimishg.substack.com/p/ai-ethics-is-being-narrowed-on-purpose#footnote-5-170332859" target="_self" rel="nofollow ugc noopener">5</a></span><span>. It was a sketchy practice and there was a huge consumer backlash against it, leading to </span><strong>the</strong><span> privacy cop-out phrase: “we never share your data with third parties”.</span></p><p><span>The full statement should be “we never share your data with third parties because that would be dumb. If they want that data, they have to buy out the company. In fact, that’s a large part of our exit strategy and valuation”. Business-wise, this has become common knowledge, so the statement about third-parties is almost redundant.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-6-170332859" href="https://nimishg.substack.com/p/ai-ethics-is-being-narrowed-on-purpose#footnote-6-170332859" target="_self" rel="nofollow ugc noopener">6</a></span></p><p><span>When people express concerns about privacy nowadays, the concern is what </span><em>the company they’re interacting with right now</em><span> is doing with the data. There’s an app I’m required to have for my kids’ school. What kind of profile and behavior model are they building about me? Why? What about the one I’m required to have to buy parking? Or the one I’m required to have to ride the train?</span></p><p><span>Those concerns aren’t really discussed. Instead, privacy is redefined as “making sure people </span><em>who aren’t this company</em><span> won’t have access to your data”, and never “what exactly is </span><em>this</em><span> company going to do with my data?”</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-7-170332859" href="https://nimishg.substack.com/p/ai-ethics-is-being-narrowed-on-purpose#footnote-7-170332859" target="_self" rel="nofollow ugc noopener">7</a></span></p><p>This narrow redefinition has become the accepted professional definition of the term. We have entire industries around procurement, compliance, testing and others to make sure the above standards of “privacy” are upheld. Don’t get me wrong — it’s definitely important to secure your data and to prevent data leaks and testing the security infrastructure and all that. If anything, in a ‘vibe code’ era of start-ups, it’s even more important to make sure baseline security practices are followed.</p><p>But, when it comes to addressing public concerns about privacy, it’s (deliberately) spending time, resources, and energy on a particular scope, and pretending this effort is your way of addressing a different scope.</p><p>It’s like when a politician is asked “Will you raise taxes?” and then answers with “I want to grow the economy”… it’s not actually addressing the question being asked. Only now, with privacy, there are whole ecosystems of process and tools that are dedicated to answering the wrong question, specifically so they don’t have to answer the right one.</p><p>AI is different in that it’s new and (for many) came out of nowhere when it comes to culture and ethics discussions around it.</p><p><span>In fact, the only thing we had to fall back on were sci-fi thought experiments (which we have </span><a href="https://en.wikipedia.org/wiki/Roko%27s_basilisk" rel="nofollow ugc noopener">plenty</a><span> </span><a href="https://en.wikipedia.org/wiki/Gray_goo" rel="nofollow ugc noopener">of</a><span>). They’re interesting, fun, profound, and from a business perspective, totally safe. I mean, no one wants an AI to trap them in some sort of </span><em>Black Mirror</em><span> simulation, or turn the world into paperclips or anything like that. If it earns you good PR, there’s no reason </span><em>not</em><span> to spend time on such issues. It’s also free publicity since the press eats that stuff up.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-8-170332859" href="https://nimishg.substack.com/p/ai-ethics-is-being-narrowed-on-purpose#footnote-8-170332859" target="_self" rel="nofollow ugc noopener">8</a></span></p><p>But, realistically, is that the actual danger? </p><p><span>One final AI thought experiment is the </span><a href="https://en.wikipedia.org/wiki/AI_alignment#Alignment_problem" rel="nofollow ugc noopener">alignment problem</a><span>. Basically, if we give an AI lots of resources and ask it to do something, how do we know it will do what we want it to, and not try to subvert us and… take over the world? How do we know it will stay on humanity’s side?</span></p><p><span>This is something that some companies have </span><a href="https://openai.com/index/our-approach-to-alignment-research/" rel="nofollow ugc noopener">whole</a><span> </span><a href="https://alignment.anthropic.com/" rel="nofollow ugc noopener">teams</a><span> dedicated to working on and see as a fundamental challenge of the AI age. I absolutely agree, but I don’t think they’re using the right premise or assumptions.</span></p><div><p><span>If we give </span><em>companies</em><span> unending hype, near unlimited government and scientific resources, all of our personal data including thoughts and behavior patterns, how do we know </span><em>their leaders</em><span> will do what we want them to, and not try to subvert us and… take over the world? How do we know </span><em>they</em><span> stay on humanity’s side?</span></p><p><span>See, AI ethics is quite important. But like everything else in AI, we have to be sure we understand the actual problems so we can set up the solutions right.</span></p></div></div></article></div><div id="discussion"><h4>Discussion about this post</h4></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How AI Conquered the US Economy: A Visual FAQ (114 pts)]]></title>
            <link>https://www.derekthompson.org/p/how-ai-conquered-the-us-economy-a</link>
            <guid>44822665</guid>
            <pubDate>Thu, 07 Aug 2025 10:12:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.derekthompson.org/p/how-ai-conquered-the-us-economy-a">https://www.derekthompson.org/p/how-ai-conquered-the-us-economy-a</a>, See on <a href="https://news.ycombinator.com/item?id=44822665">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p>The American economy has split in two. There’s a rip-roaring AI economy. And there’s a lackluster consumer economy.</p><p><span>You see it in the economic statistics. Last quarter, spending on artificial intelligence outpaced the growth in consumer spending. Without AI, US economic growth </span><a href="https://www.wsj.com/economy/the-ai-booms-hidden-risk-to-the-economy-731b00d6?mod=author_content_page_1_pos_1" rel="">would be meager.</a></p><p><span>You see it in stocks. In the last two years, </span><a href="https://privatebank.jpmorgan.com/content/dam/jpm-pb-aem/global/en/documents/eotm/summer-mailbag.pdf" rel="">about 60 percent</a><span> of the stock market’s growth has come from AI-related companies, such as Microsoft, Nvidia, and Meta. Without the AI boom, stock market returns would be putrid.</span></p><p><span>You see it in the business data. According to </span><a href="https://stripe.com/guides/indexing-the-ai-economy" rel="">Stripe</a><span>, firms that self-describe as “AI companies” are dominating revenue growth on the platform, and they’re far surpassing the growth rate of any other group.</span></p><p>Nobody can say for sure whether the AI boom is evidence of the next Industrial Revolution or the next big bubble. All we know is that it’s happening. We can all stop talking about “what will happen if AI dominates the economy at such-and-such future date?” No, the AI economy is here and now. We’re living in it, for better or worse.</p><p><span>So, what exactly </span><em>is</em><span> the artificial intelligence boom? How did it happen, where did all this money to build AI come from, who is using the technology, and is it making people more productive? Today, in a bit of a throwback to my early blogging years, I’m going to try to walk through an FAQ with graphs to create a visual guide to the question: </span></p><p>Artificial intelligence has a few simple ingredients: computer chips, racks of servers in data centers, huge amounts of electricity, and networking and cooling systems that keep everything running without overheating.</p><p><span>This hardware is immensely expensive. In the last six months, the four companies investing the most in artificial intelligence—Meta, Google, Microsoft, and Amazon—spent between $100 billion and $200 billion on chips, data centers, and the like. “The most valuable tech companies are buying and building stuff at a record pace,” </span><a href="https://www.wsj.com/tech/ai/silicon-valley-ai-infrastructure-capex-cffe0431" rel="">wrote</a><span> the Wall Street Journal’s Christopher Mims.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!Nkpa!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde0d8a15-6b98-4874-b1b7-0f2f30698bab_1155x887.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!Nkpa!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde0d8a15-6b98-4874-b1b7-0f2f30698bab_1155x887.png 424w, https://substackcdn.com/image/fetch/$s_!Nkpa!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde0d8a15-6b98-4874-b1b7-0f2f30698bab_1155x887.png 848w, https://substackcdn.com/image/fetch/$s_!Nkpa!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde0d8a15-6b98-4874-b1b7-0f2f30698bab_1155x887.png 1272w, https://substackcdn.com/image/fetch/$s_!Nkpa!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde0d8a15-6b98-4874-b1b7-0f2f30698bab_1155x887.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!Nkpa!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde0d8a15-6b98-4874-b1b7-0f2f30698bab_1155x887.png" width="1155" height="887" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/de0d8a15-6b98-4874-b1b7-0f2f30698bab_1155x887.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:887,&quot;width&quot;:1155,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:306661,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.derekthompson.org/i/170278858?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde0d8a15-6b98-4874-b1b7-0f2f30698bab_1155x887.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!Nkpa!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde0d8a15-6b98-4874-b1b7-0f2f30698bab_1155x887.png 424w, https://substackcdn.com/image/fetch/$s_!Nkpa!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde0d8a15-6b98-4874-b1b7-0f2f30698bab_1155x887.png 848w, https://substackcdn.com/image/fetch/$s_!Nkpa!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde0d8a15-6b98-4874-b1b7-0f2f30698bab_1155x887.png 1272w, https://substackcdn.com/image/fetch/$s_!Nkpa!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde0d8a15-6b98-4874-b1b7-0f2f30698bab_1155x887.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>WSJ</figcaption></figure></div><p>This is either the biggest tech-infrastructure project since the 1960s (since the beginning of the computer age) or the 1880s (the heyday of the railroad age).</p><p><span>In January, JP Morgan’s Michael Cembalest </span><a href="https://assets.jpmprivatebank.com/content/dam/jpm-pb-aem/global/en/documents/eotm/the-alchemists.pdf" rel="">calculated</a><span> that the leading AI chip manufacturer Nvidia is on pace to capture the highest share of market-wide capital spending since IBM’s peak revenues in 1969. Not to be outdone, the economic writer Paul Kedrosky </span><a href="https://paulkedrosky.com/honey-ai-capex-ate-the-economy/" rel="">has calculated</a><span> that AI capital expenditures as a share of GDP have already exceeded the dot-com boom and are now approaching levels not seen since the railroad build-out of the Gilded Age. </span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!wqm2!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d255833-0919-43de-b2ad-9bd427368b6d_1080x694.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!wqm2!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d255833-0919-43de-b2ad-9bd427368b6d_1080x694.png 424w, https://substackcdn.com/image/fetch/$s_!wqm2!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d255833-0919-43de-b2ad-9bd427368b6d_1080x694.png 848w, https://substackcdn.com/image/fetch/$s_!wqm2!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d255833-0919-43de-b2ad-9bd427368b6d_1080x694.png 1272w, https://substackcdn.com/image/fetch/$s_!wqm2!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d255833-0919-43de-b2ad-9bd427368b6d_1080x694.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!wqm2!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d255833-0919-43de-b2ad-9bd427368b6d_1080x694.png" width="1080" height="694" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/8d255833-0919-43de-b2ad-9bd427368b6d_1080x694.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:694,&quot;width&quot;:1080,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:99436,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.derekthompson.org/i/170278858?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d255833-0919-43de-b2ad-9bd427368b6d_1080x694.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!wqm2!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d255833-0919-43de-b2ad-9bd427368b6d_1080x694.png 424w, https://substackcdn.com/image/fetch/$s_!wqm2!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d255833-0919-43de-b2ad-9bd427368b6d_1080x694.png 848w, https://substackcdn.com/image/fetch/$s_!wqm2!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d255833-0919-43de-b2ad-9bd427368b6d_1080x694.png 1272w, https://substackcdn.com/image/fetch/$s_!wqm2!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d255833-0919-43de-b2ad-9bd427368b6d_1080x694.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>JPM</figcaption></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!2pDW!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F11c1cb0e-2d05-41a6-a238-893813e36352_1322x834.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!2pDW!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F11c1cb0e-2d05-41a6-a238-893813e36352_1322x834.png 424w, https://substackcdn.com/image/fetch/$s_!2pDW!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F11c1cb0e-2d05-41a6-a238-893813e36352_1322x834.png 848w, https://substackcdn.com/image/fetch/$s_!2pDW!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F11c1cb0e-2d05-41a6-a238-893813e36352_1322x834.png 1272w, https://substackcdn.com/image/fetch/$s_!2pDW!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F11c1cb0e-2d05-41a6-a238-893813e36352_1322x834.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!2pDW!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F11c1cb0e-2d05-41a6-a238-893813e36352_1322x834.png" width="1322" height="834" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/11c1cb0e-2d05-41a6-a238-893813e36352_1322x834.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:834,&quot;width&quot;:1322,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:164779,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.derekthompson.org/i/170278858?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F11c1cb0e-2d05-41a6-a238-893813e36352_1322x834.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!2pDW!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F11c1cb0e-2d05-41a6-a238-893813e36352_1322x834.png 424w, https://substackcdn.com/image/fetch/$s_!2pDW!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F11c1cb0e-2d05-41a6-a238-893813e36352_1322x834.png 848w, https://substackcdn.com/image/fetch/$s_!2pDW!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F11c1cb0e-2d05-41a6-a238-893813e36352_1322x834.png 1272w, https://substackcdn.com/image/fetch/$s_!2pDW!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F11c1cb0e-2d05-41a6-a238-893813e36352_1322x834.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>Today’s AI infrastructure boom is made possible by the extraordinary and unprecedented profits of today’s leading tech companies. As Cembalest </span><a href="https://www.theringer.com/podcasts/plain-english-with-derek-thompson/2025/01/07/the-big-2025-economy-forecast-ai-and-big-tech-nuclears-renaissance-trump-vs-china-and-whats-eating-europe" rel="">explained</a><span> on my podcast, today's leading tech companies have become so profitable in the last few years that their share of total “free cash flow” (meaning, revenue minus operating expenses and infrastructure) dwarfs anything we’ve seen since the end of World War II. These firms’ existing business models—whether it’s ads for Meta or search ads for Google—are strong enough to generate stupid amounts of money to throw at the next generation of technology. “They’re generating unprecedented amounts of free cash flow,” Cembalest told me. “They make oodles and oodles of money, which is why they can afford to be pouring hundreds of billions of dollars of capital spending each year into AI-related R&amp;D and infrastructure.”</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!Zx6X!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b1bd0f7-8e00-48e8-b607-6035a53ac09b_1270x827.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!Zx6X!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b1bd0f7-8e00-48e8-b607-6035a53ac09b_1270x827.png 424w, https://substackcdn.com/image/fetch/$s_!Zx6X!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b1bd0f7-8e00-48e8-b607-6035a53ac09b_1270x827.png 848w, https://substackcdn.com/image/fetch/$s_!Zx6X!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b1bd0f7-8e00-48e8-b607-6035a53ac09b_1270x827.png 1272w, https://substackcdn.com/image/fetch/$s_!Zx6X!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b1bd0f7-8e00-48e8-b607-6035a53ac09b_1270x827.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!Zx6X!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b1bd0f7-8e00-48e8-b607-6035a53ac09b_1270x827.png" width="1270" height="827" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7b1bd0f7-8e00-48e8-b607-6035a53ac09b_1270x827.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:827,&quot;width&quot;:1270,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:106735,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.derekthompson.org/i/170278858?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b1bd0f7-8e00-48e8-b607-6035a53ac09b_1270x827.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!Zx6X!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b1bd0f7-8e00-48e8-b607-6035a53ac09b_1270x827.png 424w, https://substackcdn.com/image/fetch/$s_!Zx6X!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b1bd0f7-8e00-48e8-b607-6035a53ac09b_1270x827.png 848w, https://substackcdn.com/image/fetch/$s_!Zx6X!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b1bd0f7-8e00-48e8-b607-6035a53ac09b_1270x827.png 1272w, https://substackcdn.com/image/fetch/$s_!Zx6X!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b1bd0f7-8e00-48e8-b607-6035a53ac09b_1270x827.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>JPM</figcaption></figure></div><p>I think so. There’s an interesting debate in finance circles now about why the stock market seems to be shrugging off the Trump tariffs and slowing growth. I think the clearest answer to this question is some combination of (a) some investors still think Trump will chicken out on the tariffs; (b) they don’t think the final effect of the tariffs will be very big; and (c) the tariffs don’t matter much to the digital economy, and AI-related stocks are dominating returns while the rest of the market collectively putters along.</p><p><span>As this chart from Societe Generale </span><a href="https://insight-public.sgmarkets.com/quant-motion-pictures/outside-of-the-top-10-stocks-sp500-forward-profits-haven-t-grown-in-three-years?utm_source=chatgpt.com" rel="">shows</a><span>, the ten largest companies in the S&amp;P 500 have so dominated net income growth in the last six years that it’s becoming more useful to think about an S&amp;P 10 vs an S&amp;P 490. If you’re a portfolio manager invested in the other 490 stocks, the last six years of equity returns aren’t very impressive because these companies have collectively not managed to increase their profits.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!y2id!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb65a1c13-91df-4e54-88a7-a74998480ac1_1058x624.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!y2id!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb65a1c13-91df-4e54-88a7-a74998480ac1_1058x624.png 424w, https://substackcdn.com/image/fetch/$s_!y2id!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb65a1c13-91df-4e54-88a7-a74998480ac1_1058x624.png 848w, https://substackcdn.com/image/fetch/$s_!y2id!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb65a1c13-91df-4e54-88a7-a74998480ac1_1058x624.png 1272w, https://substackcdn.com/image/fetch/$s_!y2id!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb65a1c13-91df-4e54-88a7-a74998480ac1_1058x624.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!y2id!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb65a1c13-91df-4e54-88a7-a74998480ac1_1058x624.png" width="1058" height="624" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b65a1c13-91df-4e54-88a7-a74998480ac1_1058x624.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:624,&quot;width&quot;:1058,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:270757,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.derekthompson.org/i/170278858?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb65a1c13-91df-4e54-88a7-a74998480ac1_1058x624.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!y2id!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb65a1c13-91df-4e54-88a7-a74998480ac1_1058x624.png 424w, https://substackcdn.com/image/fetch/$s_!y2id!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb65a1c13-91df-4e54-88a7-a74998480ac1_1058x624.png 848w, https://substackcdn.com/image/fetch/$s_!y2id!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb65a1c13-91df-4e54-88a7-a74998480ac1_1058x624.png 1272w, https://substackcdn.com/image/fetch/$s_!y2id!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb65a1c13-91df-4e54-88a7-a74998480ac1_1058x624.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Societe Generale</figcaption></figure></div><p><span>Not yet. As the </span><em>Wall Street Journal</em><span>'s Greg Ip </span><a href="https://www.wsj.com/economy/the-ai-booms-hidden-risk-to-the-economy-731b00d6?mod=author_content_page_1_pos_1" rel="">wrote</a><span>, the "unsettling” side of the AI boom is that all this spending on chips and data centers is "draining American corporations of cash." OpenAI and Anthropic are losing gobs of money, and the biggest tech companies are still relying on their older business models to generate their largest profit margins. If these firms are spending much more than they’ll ever be able to earn back, it would suggest that we’re in the midst of a historic infrastructure bubble.</span></p><p><span>As for the bull case: The payments company Stripe is already seeing evidence that AI startup revenue is exceeding the growth rate of </span><em>any</em><span> previous generation of technology.</span><strong> “</strong><span>AI companies are reaching revenue milestones faster than previous generations of startups,” the company </span><a href="https://stripe.com/blog/inside-the-growth-of-the-top-ai-companies-on-stripe" rel="">announced</a><span> in a recent report. “The top 100 AI companies on Stripe achieved annualized revenues of $1 million in a median period of just 11.5 months—four months ahead of the fastest-growing SaaS companies.”</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!Bqd0!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5e175aac-6ebf-4dc9-8cea-de2bf7cc932b_1643x766.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!Bqd0!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5e175aac-6ebf-4dc9-8cea-de2bf7cc932b_1643x766.png 424w, https://substackcdn.com/image/fetch/$s_!Bqd0!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5e175aac-6ebf-4dc9-8cea-de2bf7cc932b_1643x766.png 848w, https://substackcdn.com/image/fetch/$s_!Bqd0!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5e175aac-6ebf-4dc9-8cea-de2bf7cc932b_1643x766.png 1272w, https://substackcdn.com/image/fetch/$s_!Bqd0!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5e175aac-6ebf-4dc9-8cea-de2bf7cc932b_1643x766.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!Bqd0!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5e175aac-6ebf-4dc9-8cea-de2bf7cc932b_1643x766.png" width="1456" height="679" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5e175aac-6ebf-4dc9-8cea-de2bf7cc932b_1643x766.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:679,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:283989,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.derekthompson.org/i/170278858?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5e175aac-6ebf-4dc9-8cea-de2bf7cc932b_1643x766.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!Bqd0!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5e175aac-6ebf-4dc9-8cea-de2bf7cc932b_1643x766.png 424w, https://substackcdn.com/image/fetch/$s_!Bqd0!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5e175aac-6ebf-4dc9-8cea-de2bf7cc932b_1643x766.png 848w, https://substackcdn.com/image/fetch/$s_!Bqd0!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5e175aac-6ebf-4dc9-8cea-de2bf7cc932b_1643x766.png 1272w, https://substackcdn.com/image/fetch/$s_!Bqd0!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5e175aac-6ebf-4dc9-8cea-de2bf7cc932b_1643x766.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Stripe</figcaption></figure></div><p><span>By one account, generative AI tools like ChatGPT and Gemini are being adopted faster than practically any technology for which we have good data. The St. Louis Federal Reserve </span><a href="https://www.stlouisfed.org/on-the-economy/2024/sep/rapid-adoption-generative-ai" rel="">has estimated</a><span> that the rate of adoption for generative AI is roughly twice as fast as the Internet.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!k_ds!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa4e1e6d6-8f0f-4518-baf2-a6d0256525ad_1623x1289.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!k_ds!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa4e1e6d6-8f0f-4518-baf2-a6d0256525ad_1623x1289.png 424w, https://substackcdn.com/image/fetch/$s_!k_ds!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa4e1e6d6-8f0f-4518-baf2-a6d0256525ad_1623x1289.png 848w, https://substackcdn.com/image/fetch/$s_!k_ds!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa4e1e6d6-8f0f-4518-baf2-a6d0256525ad_1623x1289.png 1272w, https://substackcdn.com/image/fetch/$s_!k_ds!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa4e1e6d6-8f0f-4518-baf2-a6d0256525ad_1623x1289.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!k_ds!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa4e1e6d6-8f0f-4518-baf2-a6d0256525ad_1623x1289.png" width="1456" height="1156" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a4e1e6d6-8f0f-4518-baf2-a6d0256525ad_1623x1289.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1156,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:258824,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.derekthompson.org/i/170278858?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa4e1e6d6-8f0f-4518-baf2-a6d0256525ad_1623x1289.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!k_ds!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa4e1e6d6-8f0f-4518-baf2-a6d0256525ad_1623x1289.png 424w, https://substackcdn.com/image/fetch/$s_!k_ds!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa4e1e6d6-8f0f-4518-baf2-a6d0256525ad_1623x1289.png 848w, https://substackcdn.com/image/fetch/$s_!k_ds!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa4e1e6d6-8f0f-4518-baf2-a6d0256525ad_1623x1289.png 1272w, https://substackcdn.com/image/fetch/$s_!k_ds!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa4e1e6d6-8f0f-4518-baf2-a6d0256525ad_1623x1289.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>In one the largest recent surveys of generative AI—the 2025 paper </span><a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5136877" rel="">"The Labor Market Effects of Generative Artificial Intelligence</a><span>”—economists estimated that more than 50 percent of workers in information services (meaning, software firms) and management are already using the technology at work. That compares with very few people in old-economy firms, such as mining or fishing. AI is also much more popular among college graduates than people who never attended college.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!F9t1!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa6743275-a7a2-4eba-bad3-6d765a996bf2_1609x1107.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!F9t1!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa6743275-a7a2-4eba-bad3-6d765a996bf2_1609x1107.png 424w, https://substackcdn.com/image/fetch/$s_!F9t1!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa6743275-a7a2-4eba-bad3-6d765a996bf2_1609x1107.png 848w, https://substackcdn.com/image/fetch/$s_!F9t1!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa6743275-a7a2-4eba-bad3-6d765a996bf2_1609x1107.png 1272w, https://substackcdn.com/image/fetch/$s_!F9t1!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa6743275-a7a2-4eba-bad3-6d765a996bf2_1609x1107.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!F9t1!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa6743275-a7a2-4eba-bad3-6d765a996bf2_1609x1107.png" width="1456" height="1002" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a6743275-a7a2-4eba-bad3-6d765a996bf2_1609x1107.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1002,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:305371,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.derekthompson.org/i/170278858?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa6743275-a7a2-4eba-bad3-6d765a996bf2_1609x1107.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!F9t1!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa6743275-a7a2-4eba-bad3-6d765a996bf2_1609x1107.png 424w, https://substackcdn.com/image/fetch/$s_!F9t1!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa6743275-a7a2-4eba-bad3-6d765a996bf2_1609x1107.png 848w, https://substackcdn.com/image/fetch/$s_!F9t1!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa6743275-a7a2-4eba-bad3-6d765a996bf2_1609x1107.png 1272w, https://substackcdn.com/image/fetch/$s_!F9t1!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa6743275-a7a2-4eba-bad3-6d765a996bf2_1609x1107.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Hartley, et al</figcaption></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!ySxl!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1b00b72e-7c86-4048-b7a0-d9a27976c369_1633x1086.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!ySxl!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1b00b72e-7c86-4048-b7a0-d9a27976c369_1633x1086.png 424w, https://substackcdn.com/image/fetch/$s_!ySxl!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1b00b72e-7c86-4048-b7a0-d9a27976c369_1633x1086.png 848w, https://substackcdn.com/image/fetch/$s_!ySxl!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1b00b72e-7c86-4048-b7a0-d9a27976c369_1633x1086.png 1272w, https://substackcdn.com/image/fetch/$s_!ySxl!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1b00b72e-7c86-4048-b7a0-d9a27976c369_1633x1086.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!ySxl!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1b00b72e-7c86-4048-b7a0-d9a27976c369_1633x1086.png" width="1456" height="968" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/1b00b72e-7c86-4048-b7a0-d9a27976c369_1633x1086.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:968,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:193624,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.derekthompson.org/i/170278858?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1b00b72e-7c86-4048-b7a0-d9a27976c369_1633x1086.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!ySxl!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1b00b72e-7c86-4048-b7a0-d9a27976c369_1633x1086.png 424w, https://substackcdn.com/image/fetch/$s_!ySxl!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1b00b72e-7c86-4048-b7a0-d9a27976c369_1633x1086.png 848w, https://substackcdn.com/image/fetch/$s_!ySxl!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1b00b72e-7c86-4048-b7a0-d9a27976c369_1633x1086.png 1272w, https://substackcdn.com/image/fetch/$s_!ySxl!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1b00b72e-7c86-4048-b7a0-d9a27976c369_1633x1086.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Hartley, et al</figcaption></figure></div><p><span>Yes. The iconic study proving that new AI models improve productivity comes from firms with rather repetitive work, such as </span><a href="https://hai.stanford.edu/news/will-generative-ai-make-you-more-productive-work-yes-only-if-youre-not-already-great-your-job" rel="">call centers</a><span>. But we’re getting more self-reports from workers saying that AI is helping them save lots of time. One surprising example: teaching. According to a recent </span><a href="https://news.gallup.com/poll/691967/three-teachers-weekly-saving-six-weeks-year.aspx" rel="">Gallup survey</a><span>, roughly 60 percent of elementary school teachers say they’ve used AI to prepare lessons, review instruction material, make worksheets, or do administrative work. Most teachers who use AI say it improves their work, and those who use it regularly say it saves them 6 hours a week—or six weeks per school year. In one very optimistic interpretation, that’s like saying AI gives elementary school teachers a month and a half of paid leave every year.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!UOEU!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8687f204-6def-4c30-b3e4-ef82b0ecb12d_1349x1196.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!UOEU!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8687f204-6def-4c30-b3e4-ef82b0ecb12d_1349x1196.png 424w, https://substackcdn.com/image/fetch/$s_!UOEU!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8687f204-6def-4c30-b3e4-ef82b0ecb12d_1349x1196.png 848w, https://substackcdn.com/image/fetch/$s_!UOEU!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8687f204-6def-4c30-b3e4-ef82b0ecb12d_1349x1196.png 1272w, https://substackcdn.com/image/fetch/$s_!UOEU!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8687f204-6def-4c30-b3e4-ef82b0ecb12d_1349x1196.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!UOEU!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8687f204-6def-4c30-b3e4-ef82b0ecb12d_1349x1196.png" width="1349" height="1196" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/8687f204-6def-4c30-b3e4-ef82b0ecb12d_1349x1196.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1196,&quot;width&quot;:1349,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:284978,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.derekthompson.org/i/170278858?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8687f204-6def-4c30-b3e4-ef82b0ecb12d_1349x1196.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!UOEU!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8687f204-6def-4c30-b3e4-ef82b0ecb12d_1349x1196.png 424w, https://substackcdn.com/image/fetch/$s_!UOEU!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8687f204-6def-4c30-b3e4-ef82b0ecb12d_1349x1196.png 848w, https://substackcdn.com/image/fetch/$s_!UOEU!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8687f204-6def-4c30-b3e4-ef82b0ecb12d_1349x1196.png 1272w, https://substackcdn.com/image/fetch/$s_!UOEU!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8687f204-6def-4c30-b3e4-ef82b0ecb12d_1349x1196.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Gallup</figcaption></figure></div><p>Perhaps the most bullish indicator that AI is going to help people become more productive at work comes from the AI research nonprofit METR, which found that the length of tasks that AI agents can complete is doubling every 7 months. In 2021, AI could automate a simple Google search: 10 seconds. Two years later, ChatGPT was looking up facts on the Internet that would take the typical person about 4 minutes. Now some models are performing coding tasks that take a typical developer 50 minutes. “Extrapolating this trend predicts that, in under a decade, we will see AI agents that can independently complete a large fraction of software tasks that currently take humans days or weeks,” the researchers said.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!E3fb!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F40f5ced6-480d-42d7-a001-2cf3573c602c_1395x973.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!E3fb!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F40f5ced6-480d-42d7-a001-2cf3573c602c_1395x973.png 424w, https://substackcdn.com/image/fetch/$s_!E3fb!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F40f5ced6-480d-42d7-a001-2cf3573c602c_1395x973.png 848w, https://substackcdn.com/image/fetch/$s_!E3fb!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F40f5ced6-480d-42d7-a001-2cf3573c602c_1395x973.png 1272w, https://substackcdn.com/image/fetch/$s_!E3fb!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F40f5ced6-480d-42d7-a001-2cf3573c602c_1395x973.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!E3fb!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F40f5ced6-480d-42d7-a001-2cf3573c602c_1395x973.png" width="1395" height="973" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/40f5ced6-480d-42d7-a001-2cf3573c602c_1395x973.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:973,&quot;width&quot;:1395,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:318042,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.derekthompson.org/i/170278858?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F40f5ced6-480d-42d7-a001-2cf3573c602c_1395x973.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!E3fb!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F40f5ced6-480d-42d7-a001-2cf3573c602c_1395x973.png 424w, https://substackcdn.com/image/fetch/$s_!E3fb!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F40f5ced6-480d-42d7-a001-2cf3573c602c_1395x973.png 848w, https://substackcdn.com/image/fetch/$s_!E3fb!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F40f5ced6-480d-42d7-a001-2cf3573c602c_1395x973.png 1272w, https://substackcdn.com/image/fetch/$s_!E3fb!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F40f5ced6-480d-42d7-a001-2cf3573c602c_1395x973.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>Not so fast. In fact, many workers might dramatically </span><em>overestimate</em><span> how much more productive AI is making them.</span></p><p><span>METR also </span><a href="https://metr.org/blog/2025-07-10-early-2025-ai-experienced-os-dev-study/" rel="">conducted</a><span> an in-depth study that asked experienced developers to code with a popular AI assistant. After they finished their tasks, the developers claimed that using the AI had made them 20 percent more productive. But independent evaluators in the study actually concluded that using AI did the opposite: it </span><em>increased</em><span> task completion time by about 20 percent. I don’t want to speculate too much about what this study means in the long run. But for now, I think it’s a necessary caveat to boosterish claims that ChatGPT is on the cusp of replacing tens of millions of entry-level white-collar jobs.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!aH-u!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F230b051c-0861-49bc-bdf5-5ffab4b5d8e1_1557x942.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!aH-u!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F230b051c-0861-49bc-bdf5-5ffab4b5d8e1_1557x942.png 424w, https://substackcdn.com/image/fetch/$s_!aH-u!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F230b051c-0861-49bc-bdf5-5ffab4b5d8e1_1557x942.png 848w, https://substackcdn.com/image/fetch/$s_!aH-u!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F230b051c-0861-49bc-bdf5-5ffab4b5d8e1_1557x942.png 1272w, https://substackcdn.com/image/fetch/$s_!aH-u!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F230b051c-0861-49bc-bdf5-5ffab4b5d8e1_1557x942.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!aH-u!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F230b051c-0861-49bc-bdf5-5ffab4b5d8e1_1557x942.png" width="1456" height="881" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/230b051c-0861-49bc-bdf5-5ffab4b5d8e1_1557x942.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:881,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:243646,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.derekthompson.org/i/170278858?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F230b051c-0861-49bc-bdf5-5ffab4b5d8e1_1557x942.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!aH-u!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F230b051c-0861-49bc-bdf5-5ffab4b5d8e1_1557x942.png 424w, https://substackcdn.com/image/fetch/$s_!aH-u!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F230b051c-0861-49bc-bdf5-5ffab4b5d8e1_1557x942.png 848w, https://substackcdn.com/image/fetch/$s_!aH-u!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F230b051c-0861-49bc-bdf5-5ffab4b5d8e1_1557x942.png 1272w, https://substackcdn.com/image/fetch/$s_!aH-u!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F230b051c-0861-49bc-bdf5-5ffab4b5d8e1_1557x942.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>A new paper in </span><em>Science</em><span> </span><a href="https://www.science.org/doi/10.1126/sciadv.adt3813?utm_campaign=ScienceMagazine&amp;utm_source=twitter&amp;utm_medium=ownedSocial" rel="">found</a><span> that since the rise of large language models, there's been a huge shift in academic writing. In 2024, the word "delves" has appeared 2,700% more than its historical average, by one account. The analysis suggests that about 1/7th of 2024 abstracts were processed by AI.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!UDeX!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d360121-e1d1-490e-81e8-c170abd9efe3_1658x1416.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!UDeX!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d360121-e1d1-490e-81e8-c170abd9efe3_1658x1416.png 424w, https://substackcdn.com/image/fetch/$s_!UDeX!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d360121-e1d1-490e-81e8-c170abd9efe3_1658x1416.png 848w, https://substackcdn.com/image/fetch/$s_!UDeX!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d360121-e1d1-490e-81e8-c170abd9efe3_1658x1416.png 1272w, https://substackcdn.com/image/fetch/$s_!UDeX!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d360121-e1d1-490e-81e8-c170abd9efe3_1658x1416.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!UDeX!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d360121-e1d1-490e-81e8-c170abd9efe3_1658x1416.png" width="1456" height="1243" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/4d360121-e1d1-490e-81e8-c170abd9efe3_1658x1416.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1243,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1132159,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.derekthompson.org/i/170278858?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d360121-e1d1-490e-81e8-c170abd9efe3_1658x1416.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!UDeX!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d360121-e1d1-490e-81e8-c170abd9efe3_1658x1416.png 424w, https://substackcdn.com/image/fetch/$s_!UDeX!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d360121-e1d1-490e-81e8-c170abd9efe3_1658x1416.png 848w, https://substackcdn.com/image/fetch/$s_!UDeX!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d360121-e1d1-490e-81e8-c170abd9efe3_1658x1416.png 1272w, https://substackcdn.com/image/fetch/$s_!UDeX!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d360121-e1d1-490e-81e8-c170abd9efe3_1658x1416.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Kobak, et al</figcaption></figure></div></div></article></div><div id="discussion"><h4>Discussion about this post</h4></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA["I closed MPEG on 2 Jun '20 when I left because obscure forces had hijacked it." (189 pts)]]></title>
            <link>https://leonardo.chiariglione.org/</link>
            <guid>44822637</guid>
            <pubDate>Thu, 07 Aug 2025 10:09:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://leonardo.chiariglione.org/">https://leonardo.chiariglione.org/</a>, See on <a href="https://news.ycombinator.com/item?id=44822637">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-id="5c35ece" data-element_type="section" data-widget_type="text-editor.default">
									<p><span>I needed an organisation that would</span><em>&nbsp;create digital media standards for <span>consumers</span>&nbsp;to seamlessly communicate and&nbsp;<span>industry</span>&nbsp;operate in a global market of interoperable products, services and applications</em><span>.&nbsp;</span><span>I conceived&nbsp;</span><span>t</span><span>hat organisation&nbsp;</span><span>in 1987, established it in 1988</span><span>I, and called </span><span>&nbsp;</span><a href="http://mpeg.chiariglione.org/">Moving Picture Experts Group</a><span>&nbsp;(MPEG). In four years,&nbsp;</span><span>MPEG had&nbsp;</span><span>ushered in the&nbsp;</span><span><i>digital media age </i><span>with&nbsp;</span></span><span>MPEG-1,&nbsp;</span><span>a standard for interactive media&nbsp;</span><span>used in Video CD, digital audio broadcasting (MP2), and personal music (MP3). Starting from the mid ’90s, MPEG-2, the result of the second MPEG project, became the common infrastructure that underpinned distribution of digital television via cable, satellite, terrestrial networks and package media (DVD). MPEG-4, the third standard first released in 1988, opened the way to digital media distribution over the internet. Several families of standards followed: MPEG-7, MPEG-21, </span><span>MPEG-A, MPEG-H, MPEG-I and more.</span></p><p><span>I chaired the group </span><span>fostering its productivity with the development of over 200 standards, membership with a 20-fold growth in attendance </span><span>from the initial 29 experts attending the first meeting, and scope extending from media to genomics, the “born digital” data of the world..&nbsp;</span></p><p><span>I closed MPEG on 2 June 2020 when I left because&nbsp;</span><span>obscure forces</span><span>&nbsp;had hijacked it.&nbsp;</span></p><p>Even before it has ceased to exists, the MPEG engine had run out of steam – technology- and business wise. The same obscure forces that have hijacked MPEG had kept it hostage to their interests impeding its technical development and keeping it locked to outmoded Intellectual Property licensing models delaying market adoption of MPEG standards. Industry has been strangled&nbsp;<span>and consumers have been deprived of the benefits of new technologies. From&nbsp;</span><span>facilitators&nbsp;</span><span>of new opportunities and experiences, MPEG s</span><span>tandards have morphed from </span><span>&nbsp;into </span><span>roadblocks.</span></p><p>On the 19th of July 2020 I proposed and, on 30 September 2020, a group of 33 companies established the&nbsp;<a href="http://mpai.community/" target="_blank" rel="nofollow noopener noreferrer">Moving Picture, Audio and Data Coding by Artificial Intelligence</a>&nbsp;(MPAI). Industry and consumers have now an organisation developing standards based on powerful technologies, overcoming stagnation and licensing stalemates. Five standards covering <a href="https://mpai.community/standards/mpai-aif/">execution of AI applications</a>, <a href="https://mpai.community/standards/mpai-cae/">audio enhancement</a>, <a href="https://mpai.community/standards/mpai-mmc/">multimodal conversation</a>, <a href="https://mpai.community/standards/mpai-cui/">company performance prediction</a>, and <a href="https://mpai.community/standards/mpai-gme/">ecosystem governance</a> have been developed and adopted. More standards are in the pipeline: <a href="https://mpai.community/standards/mpai-eev/">AI-based End-to-End Video Coding</a>, <a href="https://mpai.community/standards/mpai-evc/">AI-Enhanced Video Coding</a>, <a href="https://mpai.community/standards/mpai-aih/">AI Health</a>, <a href="https://mpai.community/standards/mpai-ara/">Avatar Representation and Animation</a>, <a href="https://mpai.community/standards/mpai-cav/">Connected Autonomous Vehicles</a>, <a href="https://mpai.community/standards/mpai-mmm/">Metaverse Model</a>,&nbsp; <a href="https://mpai.community/standards/mpai-spg/">Server-based Predictive Multiplayer Gaming</a>, and <a href="https://mpai.community/standards/mpai-xrv/">XR Venues</a>.</p><p>The book <a href="https://leonardo.chiariglione.org/publications/even-the-stars-die/"><em>Even the stars die</em></a> tell the MPEG story from birth to death and the MPAI story from birth to growth to death. The book <a href="https://mpai.community/the-mpai-book-2021/"><em>Towards Pervasive and Trustworthy Artificial Intelligence</em></a> tells the MPAI story in its first 15 months of life: 5 standards produced and 7 projects under way1998.</p>								</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[New AI Coding Teammate: Gemini CLI GitHub Actions (202 pts)]]></title>
            <link>https://blog.google/technology/developers/introducing-gemini-cli-github-actions/</link>
            <guid>44822389</guid>
            <pubDate>Thu, 07 Aug 2025 09:28:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.google/technology/developers/introducing-gemini-cli-github-actions/">https://blog.google/technology/developers/introducing-gemini-cli-github-actions/</a>, See on <a href="https://news.ycombinator.com/item?id=44822389">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="jump-content" tabindex="-1">
            

    
    

    <article>

    
    





    

    
      








<div data-analytics-module="{
    &quot;module_name&quot;: &quot;Hero Menu&quot;,
    &quot;section_header&quot;: &quot;Meet your new AI coding teammate: Gemini CLI GitHub Actions&quot;
  }">
  
  <div>
      
      
        <p>
          Gemini CLI GitHub Actions is a no-cost, powerful AI coding teammate for your repository. It acts both as an autonomous agent for critical routine coding tasks, and an on-demand collaborator you can quickly delegate work to.
        </p>
      
    </div>
  
  <div>
  <p>Ryan J. Salva</p>
  
    <p>
      Senior Director, Product Management
    </p>
  
  
</div>
</div>

    

    
      










<div>
    <figure>
      <div>
        <p><img alt="Gemini CLI GitHub Actions implements a feature at a user's request" data-component="uni-progressive-image" fetchpriority="high" height="150px" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/All-Three_1.width-200.format-webp.webp" width="360px" data-sizes="(max-width: 1023px) 100vw,(min-width: 1024px and max-width: 1259) 80vw, 1046px" data-srcset="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/All-Three_1.width-800.format-webp.webp 800w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/All-Three_1.width-1200.format-webp.webp 1200w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/All-Three_1.width-1600.format-webp.webp 1600w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/All-Three_1.width-2200.format-webp.webp 2200w">
        </p>
      </div>
      
    </figure>
  </div>






    

    
    <div data-reading-time="true" data-component="uni-article-body">

            
              





<uni-article-speakable page-title="Meet your new AI coding teammate: Gemini CLI GitHub Actions" listen-to-article="Listen to article" data-date-modified="2025-08-06T01:00:00.396657+00:00" data-tracking-ids="G-HGNBTNCHCQ,G-6NKTLKV14N" data-voice-list="en.ioh-pngnat:Cyan,en.usb-pngnat:Lime" data-script-src="https://www.gstatic.com/readaloud/player/web/api/js/api.js" data-highlight-mode="word-over-paragraph"></uni-article-speakable>

            

            
            
<!--article text-->

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Meet your new AI coding teammate: Gemini CLI GitHub Actions&quot;
         }"><p data-block-key="qeat0">In June, we launched <a href="https://blog.google/technology/developers/introducing-gemini-cli-open-source-ai-agent/">Gemini CLI</a>, an open-source AI agent that brings the power of Gemini to your terminal. The enthusiastic adoption from developers has been incredible. To keep up with the flood of feature requests and contributions, we put our own tool to the test — using Gemini CLI to automate issue triage and pull request reviews. When community members noticed our new workflows, they asked us to share what we’ve built.</p><p data-block-key="dkm0r">Today, we’re introducing <b>Gemini CLI GitHub Actions</b>. It’s a no-cost, powerful AI coding teammate for your repository. It acts both as an autonomous agent for critical routine coding tasks, and an on-demand collaborator you can quickly delegate work to.</p><p data-block-key="4h2fu">It’s now in beta, available to everyone worldwide, and you can find it on GitHub at <a href="https://github.com/google-github-actions/run-gemini-cli">google-github-actions/run-gemini-cli</a>.</p><h3 data-block-key="d3s1s"><b>An AI teammate in your repository</b></h3><p data-block-key="5qn4">While Gemini CLI is a tool built for individual use in your own terminal, Gemini CLI GitHub Actions was created for team collaboration on the platform where developers work with each other.</p><p data-block-key="3tmop">Triggered by events like new issues or pull requests, it works asynchronously in the background, using the full context of your project to automatically handle tasks. It knows your code, understands what you want to do, and gets it done.</p><p data-block-key="413o5">We’re launching with three powerful, open-source workflows that can help you code better, faster:</p><ol><li data-block-key="1fbho"><b>🤖Intelligent issue triage</b>: Automate the overhead of managing new issues. Gemini CLI can analyze, label and prioritize incoming issues, helping focus your attention on what matters most.</li><li data-block-key="fu7pb"><b>🚀Accelerated pull request reviews</b>: Get instant, insightful feedback on code changes. Gemini CLI can review pull requests for quality, style and correctness, freeing up reviewers to focus on more complex tasks and decisions.</li><li data-block-key="2q78t"><b>🤝On-demand collaboration</b>: Simply mention @gemini-cli in any issue or pull request to delegate tasks. Tell it to do things like, "write tests for this bug," "implement the changes suggested above," "brainstorm alternative solutions," or "fix this well defined bug."</li></ol></div>
  

  
    

















<uni-image-carousel section-header="Meet your new AI coding teammate: Gemini CLI GitHub Actions" images="[
    
      {
        
          &quot;src&quot;: [&quot; https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/CLI_Labels.mp4 &quot;],
        
        &quot;alt&quot;: &quot;Easily create new feature requests on GitHub for Gemini CLI to handle on your behalf&quot;,
        &quot;isVideo&quot;: true,
        &quot;videoTitle&quot;: &quot;Gemini CLI GitHub Actions labels workflow&quot;
      },
    
      {
        
          &quot;src&quot;: [&quot; https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/CLI_Pull_Request.mp4 &quot;],
        
        &quot;alt&quot;: &quot;Gemini CLI GitHub Actions can handle your pull requests, providing code changes and AI\u002Dgenerated suggestions for improving the user experience&quot;,
        &quot;isVideo&quot;: true,
        &quot;videoTitle&quot;: &quot;Gemini CLI GitHub Actions Pull Request&quot;
      },
    
      {
        
          &quot;src&quot;: [&quot; https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/CLI_Comment.mp4 &quot;],
        
        &quot;alt&quot;: &quot;Delegate work with an \u0022@gemini\u002Dcli\u0022 tag and the agent can complete a range of tasks, from writing bugs to fixing bugs&quot;,
        &quot;isVideo&quot;: true,
        &quot;videoTitle&quot;: &quot;Gemini CLI GitHub Actions feature request&quot;
      }
    
  ]">
  
    
      <div slot="caption-slot-0">
        <p data-block-key="3g0nl">Easily create new feature requests on GitHub for Gemini CLI to handle on your behalf</p>
      </div>
    
  
    
      <div slot="caption-slot-1">
        <p data-block-key="foxmz">Gemini CLI GitHub Actions can handle your pull requests, providing code changes and AI-generated suggestions for improving the user experience</p>
      </div>
    
  
    
      <div slot="caption-slot-2">
        <p data-block-key="foxmz">Delegate work with an "@gemini-cli" tag and the agent can complete a range of tasks, from writing bugs to fixing bugs</p>
      </div>
    
  
</uni-image-carousel>

  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Meet your new AI coding teammate: Gemini CLI GitHub Actions&quot;
         }"><p data-block-key="qeat0">Think of these initial workflows as your launchpad. They are open-source and fully customizable — you can create your own workflows, or configure the ones that come built into Gemini CLI GitHub Actions.</p><h2 data-block-key="fe8q4">Built with enterprise-grade security and control</h2><p data-block-key="16p06">Robust security measures are a fundamental part of modern software development. That’s why we built Gemini CLI GitHub Actions with security and flexibility at its core.</p><p data-block-key="ataps">You are always in control with capabilities including:</p><ul><li data-block-key="9s87r"><b>Secure, credential-less authentication:</b> Vertex AI and Gemini Code Assist Standard and Enterprise users can tap into Google Cloud's <a href="https://cloud.google.com/iam/docs/workload-identity-federation">Workload Identity Federation</a> (WIF) to eliminate the need for long-lived API keys in your environment, drastically reducing the risk of credential compromise.</li><li data-block-key="e2u6u"><b>Granular control</b>: Enforce the principle of least privilege with multi-layered controls. Use capabilities like command allowlisting to explicitly approve every shell command the agent can execute. You can also create a custom identity for the agent (e.g., gemini-for-your-org) and grant it only the precise permissions it needs.</li><li data-block-key="d5i11"><b>Complete transparency:</b> GitHub on CLI comes integrated with <a href="https://opentelemetry.io/">OpenTelemetry</a>, an industry standard for telemetry, so you can stream logs and metrics to your preferred observability platform, like Google Cloud Monitoring. This gives you full, real-time visibility into every action to monitor usage and debug complex workflows.</li></ul><h2 data-block-key="ffuab">Get started today</h2><p data-block-key="3bqq">What will you build with your new coding teammate? A workflow that automatically generates release notes? One that keeps documentation in sync with your code? Don’t just imagine it; build it. We invite you to contribute your innovative workflows to our repository and share them with the community.</p><p data-block-key="f79fk">Gemini CLI GitHub Actions is <a href="https://github.com/google-github-actions/run-gemini-cli">available today</a> in beta, with <a href="https://github.com/google-gemini/gemini-cli/blob/main/docs/quota-and-pricing.md#gemini-cli-quotas-and-pricing">generous free-of-charge quotas</a> for Google AI Studio. Vertex AI, along with the Standard and Enterprise tiers of Gemini Code Assist, are also supported. We will have free-of-charge use for Gemini Code Assist for individual users available soon.</p><p data-block-key="mgkb">To get started, <a href="https://github.com/google-gemini/gemini-cli">download</a> Gemini CLI 0.1.18 or later and run `/setup-github`. You can find the GitHub Action at <a href="https://github.com/google-github-actions/run-gemini-cli">google-github-actions/run-gemini-cli</a>.</p></div>
  


            
            

            
              




            
          </div>
  </article>
  





  

  


<div data-component="uni-related-articles" aria-roledescription="carousel" data-analytics-module="{
    &quot;module_name&quot;: &quot;Article Footer Related Stories&quot;,
    &quot;section_header&quot;: &quot;Related stories&quot;
  }">
        <h3>
          <p>
            Related stories
          </p>
        </h3>
      </div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Cracking the Vault: How we found zero-day flaws in HashiCorp Vault (191 pts)]]></title>
            <link>https://cyata.ai/blog/cracking-the-vault-how-we-found-zero-day-flaws-in-authentication-identity-and-authorization-in-hashicorp-vault/</link>
            <guid>44821434</guid>
            <pubDate>Thu, 07 Aug 2025 07:01:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cyata.ai/blog/cracking-the-vault-how-we-found-zero-day-flaws-in-authentication-identity-and-authorization-in-hashicorp-vault/">https://cyata.ai/blog/cracking-the-vault-how-we-found-zero-day-flaws-in-authentication-identity-and-authorization-in-hashicorp-vault/</a>, See on <a href="https://news.ycombinator.com/item?id=44821434">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-rocket-location-hash="b5f44b58950a14272f2f7bf6d6b43960">
<h2>Introduction: when the trust model can’t be trusted</h2>



<p>Secrets vaults are the backbone of digital infrastructure. They store the credentials, tokens, and certificates that govern access to systems, services, APIs, and data. They’re not just a part of the trust model, they <em>are</em> the trust model. In other words, if your vault is compromised, your infrastructure is already lost.</p>



<p>Driven by the understanding that vaults are high-value targets for attackers, our research team at Cyata set out to conduct a comprehensive assessment of HashiCorp Vault (“Vault”), one of the most widely used tools in this space.</p>



<p>Over several weeks of deep investigation, we identified <strong>nine previously unknown zero-day vulnerabilities</strong>, <strong>each assigned a CVE</strong> through responsible disclosure. We worked closely with HashiCorp to ensure all issues were patched prior to public release.</p>



<p>The flaws we uncovered bypass lockouts, evade policy checks, and enable impersonation. One vulnerability even allows root-level privilege escalation, and another – perhaps most concerning – leads to the first public <strong>remote code execution (RCE)</strong> reported in Vault, enabling an attacker to execute a full-blown system takeover.</p>



<p>We found a pattern of logic failures that, individually and in combination, create dangerous attack paths – especially in real-world Vault deployments where misconfigurations or excessive permissions are common.</p>



<p>These vulnerabilities weren’t memory corruption or race condition issues, but subtle logic flaws buried in Vault’s authentication, identity, and policy enforcement layers. Some had existed for nearly a decade, quietly embedded and easy to miss, yet straightforward to exploit once understood.</p>



<p>Previous public research on Vault risks, most notably Google Project Zero’s <a href="https://googleprojectzero.blogspot.com/2020/10/enter-the-vault-auth-issues-hashicorp-vault.html">Enter the Vault</a> (2020), focused on bypasses in cloud-provider-specific IAM backends like AWS and GCP. Our work targets Vault’s <strong>core authentication flows</strong>, surfacing issues that impact both Open Source and Enterprise versions, across multiple solution providers.</p>



<p>In this post, we share what we found, how we found it, and what it means for the infrastructure Vault is meant to protect.</p>



<p>In parallel, we conducted a similar assessment of <strong>CyberArk Conjur</strong>, uncovering several high-severity vulnerabilities – composing a pre-auth remote code authentication chain. Those findings are detailed <a href="https://cyata.ai/blog/exploiting-a-full-chain-of-trust-flaws-how-we-went-from-unauthenticated-to-arbitrary-remote-code-execution-rce-in-cyberark-conjur/">in a separate post on Conjur</a>.</p>



<h2>What is HashiCorp Vault?</h2>



<p>HashiCorp Vault is an open-source tool designed to secure, store, and control access to secrets, including API keys, database passwords, certificates, and encryption keys.</p>



<p>Used across organizations of all sizes, Vault centralizes secret management and enforces fine-grained access policies across distributed systems.</p>



<p>At its core, it acts as a security boundary: authenticating users and machines and brokering access to sensitive data.</p>



<p>Vault plays a critical role in modern DevSecOps pipelines, helping teams reduce the risks of hardcoded credentials, secret sprawl, and unauthorized access.</p>



<p>Users frequently highlight its integration flexibility, detailed policy enforcement, and suitability for complex, distributed environments.</p>



<p>In many environments, it’s trusted as the final gatekeeper of secrets and, depending on its configuration, a breach of Vault can mean a breach of <strong>everything</strong>.</p>



<figure><img loading="lazy" decoding="async" width="1360" height="1562" src="https://cyata.ai/wp-content/uploads/2025/08/Group-2147203144.webp" alt="" srcset="https://cyata.ai/wp-content/uploads/2025/08/Group-2147203144.webp 1360w, https://cyata.ai/wp-content/uploads/2025/08/Group-2147203144-261x300.webp 261w, https://cyata.ai/wp-content/uploads/2025/08/Group-2147203144-892x1024.webp 892w, https://cyata.ai/wp-content/uploads/2025/08/Group-2147203144-768x882.webp 768w, https://cyata.ai/wp-content/uploads/2025/08/Group-2147203144-1337x1536.webp 1337w, https://cyata.ai/wp-content/uploads/2025/08/Group-2147203144-372x427.webp 372w" sizes="auto, (max-width: 1360px) 100vw, 1360px"></figure>



<p>Vault highlights</p>



<ul>
<li>Secrets management and cryptographic engine designed for dynamic, multi-cloud and hybrid environments</li>



<li>Centralized secrets storage with access via API</li>



<li>Dynamic credential provisioning with automatic expiration</li>



<li>Identity-based access controls supporting human and machine authentication</li>



<li>Encryption as a service for data at rest and in transit</li>



<li>Certificate management for generating, rotating, and revoking certificates</li>



<li>Distribution, enabling, disabling, and rotating encryption keys</li>
</ul>



<p>For more on Vault, see: <a href="https://www.hashicorp.com/en/resources/introduction-to-hashicorp-vault">Introduction to HashiCorp Vault</a>.</p>



<h2>Methodology: how we found what others missed</h2>



<p>This research was the result of a deliberate, weeks-long effort by our research team to uncover logic-level vulnerabilities in Vault – the kind that don’t show up in memory scanners or crash logs, but that can quietly undermine a system’s trust model.</p>



<p>We didn’t stumble into these issues. We sought them out, starting with a clear hypothesis – if Vault plays the role of trust anchor for organizations, then even minor inconsistencies in how it enforces identity, authentication, or policy could have outsized consequences.</p>



<p>We focused on Vault’s core request flow, especially the <code>request_handling.go</code> file which functions as the “brain” of Vault. This is where requests are routed, identities resolved, and policy decisions made. We spent weeks reviewing the logic across functions and modules, looking for edge cases where trust boundaries might blur.</p>



<p>We didn’t rely on fuzzers or automated probes. Instead, we conducted a deep manual review of the source code – looking not just at what each function did, but how different components interpreted identity and input. Where we saw inconsistencies in casing, aliasing, or formatting, we dug deeper.</p>



<p>These weren’t random guesses, each test input was a precision-guided hypothesis shaped by the code itself. We also approached the system like an attacker: starting with minimal access and asking, <em>“How far can we push from here?”</em></p>



<p>We repeated that process again and again.</p>



<p>This recurring loop – spotting subtle inconsistencies, reasoning through their downstream impact, and validating them with controlled testing – led us to each of the nine vulnerabilities disclosed in this report.</p>



<p>Ultimately, we didn’t just look for vulnerabilities. We looked at how trust itself could break and followed the logic wherever it led.</p>



<h2>The path to compromise</h2>



<p><mark>Step 1 – Cracks in userpass authentication</mark></p>



<p>HashiCorp Vault supports a wide range of authentication methods, 14 by default. To kick off our research, we began with the simplest and most widely used – <code>userpass</code>, Vault’s native username-and-password login mechanism.</p>



<p>To enable <code>userpass</code>, users configure it through the Vault UI or API as one of the available authentication methods.</p>



<figure><img loading="lazy" decoding="async" width="1294" height="844" src="https://cyata.ai/wp-content/uploads/2025/08/hashicorp-1.webp" alt="" srcset="https://cyata.ai/wp-content/uploads/2025/08/hashicorp-1.webp 1294w, https://cyata.ai/wp-content/uploads/2025/08/hashicorp-1-300x196.webp 300w, https://cyata.ai/wp-content/uploads/2025/08/hashicorp-1-1024x668.webp 1024w, https://cyata.ai/wp-content/uploads/2025/08/hashicorp-1-768x501.webp 768w, https://cyata.ai/wp-content/uploads/2025/08/hashicorp-1-372x243.webp 372w" sizes="auto, (max-width: 1294px) 100vw, 1294px"></figure>



<p>In a typical <code>userpass</code> setup, each user is assigned a hashed password and one or more Vault policies. On login, Vault verifies the credentials and applies the appropriate policy upon success.</p>



<p>Given how foundational <code>userpass</code> is to Vault and how widely it’s deployed across production environments, we were surprised to discover logic flaws in this core component. Even here, at the default entry point to the system, the trust model could be broken.</p>



<p>The Full Login Flow</p>



<figure><img loading="lazy" decoding="async" width="1360" height="1360" src="https://cyata.ai/wp-content/uploads/2025/08/userpass-login.webp" alt="" srcset="https://cyata.ai/wp-content/uploads/2025/08/userpass-login.webp 1360w, https://cyata.ai/wp-content/uploads/2025/08/userpass-login-300x300.webp 300w, https://cyata.ai/wp-content/uploads/2025/08/userpass-login-1024x1024.webp 1024w, https://cyata.ai/wp-content/uploads/2025/08/userpass-login-150x150.webp 150w, https://cyata.ai/wp-content/uploads/2025/08/userpass-login-768x768.webp 768w, https://cyata.ai/wp-content/uploads/2025/08/userpass-login-372x372.webp 372w" sizes="auto, (max-width: 1360px) 100vw, 1360px"></figure>



<p><strong>What we looked for</strong></p>



<p>We began by reviewing how Vault enforces lockout protections under <code>userpass</code> – specifically, how failed login attempts are tracked, throttled, and attributed to individual users.</p>



<p><strong>What we found</strong></p>



<p>Our first stop was Vault’s userpass backend. We wanted to understand not only how it works – but also how it could be manipulated into misbehaving.</p>



<p>Our investigation focused on Vault’s <strong>lockout protection</strong> logic, the mechanism that’s supposed to throttle brute-force attempts. We discovered three vulnerabilities, all related to how Vault tracks and handles failed login attempts:</p>



<ul>
<li id="CVE-2025-6010"><strong>CVE-2025-6010 – Redacted (Pending Fix)<br></strong>This CVE has been temporarily withheld from publication at the request of the vendor. No technical details will be shared at this time.</li>



<li id="CVE-2025-6004"><strong>CVE-2025-6004 – Lockout bypass via case permutation</strong><br>By changing the casing of a known username (e.g., <code>admin</code> vs <code>Admin</code>), an attacker can reset the lockout counter and continue brute-forcing.</li>



<li id="CVE-2025-6011"><strong>CVE-2025-6011 – Timing-based enumeration</strong><br>When Vault authenticates a real user, it performs a bcrypt hash comparison. For nonexistent users, that step is unintentionally skipped due to an early return. This leads to a detectable timing difference, allowing attackers to infer which usernames are valid.</li>
</ul>



<p>CVE-2025-6004 Lockout Bypass:</p>



<figure><video controls="" src="https://cyata.ai/wp-content/uploads/2025/08/CVE-2025-6004-userpass.mp4"></video></figure>



<p><strong>Why it matters</strong></p>



<p>These flaws allow an attacker to:</p>



<ul>
<li><strong>Enumerate </strong>valid users without alerting defenders</li>



<li><strong>Bypass </strong>Vault’s intended lockout protections</li>



<li><strong>Brute-force </strong>credentials at scale, even in hardened environments</li>
</ul>



<p>In short, Vault’s simplest authentication path – the first line of defense – contained logic bugs that could be exploited to undermine access controls before any policies were ever enforced.</p>



<p>Step 2 – LDAP logic flaws and MFA enforcement bypass</p>



<p>After uncovering multiple vulnerabilities in <code>userpass</code>, we turned our attention to another backend that shares the same lockout mechanism: <code>ldap</code>. It’s one of Vault’s most widely used authentication methods in production environments, often integrated with directory services like Active Directory or OpenLDAP. And like <code>userpass</code>, it enforces a lockout threshold by default, which made it a compelling next target for investigation.</p>



<p>To enable the <code>ldap</code> backend, it must be configured through the Vault UI or API:</p>



<figure><img loading="lazy" decoding="async" width="1294" height="844" src="https://cyata.ai/wp-content/uploads/2025/08/hashicorp-2.webp" alt="" srcset="https://cyata.ai/wp-content/uploads/2025/08/hashicorp-2.webp 1294w, https://cyata.ai/wp-content/uploads/2025/08/hashicorp-2-300x196.webp 300w, https://cyata.ai/wp-content/uploads/2025/08/hashicorp-2-1024x668.webp 1024w, https://cyata.ai/wp-content/uploads/2025/08/hashicorp-2-768x501.webp 768w, https://cyata.ai/wp-content/uploads/2025/08/hashicorp-2-372x243.webp 372w" sizes="auto, (max-width: 1294px) 100vw, 1294px"></figure>



<p>Unlike <code>userpass</code>, where Vault verifies credentials internally, the <code>ldap</code> method delegates authentication to an external server. Vault simply forwards the provided credentials, and the LDAP server performs the verification.</p>



<p>The full authentication flow looks like this:</p>



<figure><img loading="lazy" decoding="async" width="1360" height="1562" src="https://cyata.ai/wp-content/uploads/2025/08/ldap-login-flow.webp" alt="" srcset="https://cyata.ai/wp-content/uploads/2025/08/ldap-login-flow.webp 1360w, https://cyata.ai/wp-content/uploads/2025/08/ldap-login-flow-261x300.webp 261w, https://cyata.ai/wp-content/uploads/2025/08/ldap-login-flow-892x1024.webp 892w, https://cyata.ai/wp-content/uploads/2025/08/ldap-login-flow-768x882.webp 768w, https://cyata.ai/wp-content/uploads/2025/08/ldap-login-flow-1337x1536.webp 1337w, https://cyata.ai/wp-content/uploads/2025/08/ldap-login-flow-372x427.webp 372w" sizes="auto, (max-width: 1360px) 100vw, 1360px"></figure>



<p><strong>What we looked for</strong></p>



<p>After discovering username enumeration issues in <code>userpass</code>, we turned our attention to the <code>ldap</code> backend – specifically, how it handles lockout behavior for unknown users.</p>



<p>Unlike <code>userpass</code>, <code>ldap </code>applies lockout uniformly to all failed login attempts, regardless of whether the username exists. This consistent treatment prevents the kind of enumeration attacks seen in <code>userpass</code>.</p>



<p>So:</p>



<ul>
<li>No lockout discrepancy → no username enumeration vector</li>



<li>A previous known issue (CVE-2023-3462) had already been patched</li>
</ul>



<p>But despite this uniformity, we uncovered <strong>two high-impact logic flaws</strong>.</p>



<p><strong>What we found</strong></p>



<p>We found two critical flaws that weakened lockout enforcement and bypassed MFA controls under specific configuration conditions.</p>



<p><strong>CVE-2025-6004 – Lockout bypass via input normalization mismatch</strong></p>



<p>This vulnerability stems from how Vault and the LDAP server handle input formatting differently. Vault tracks lockouts by the exact input string, but most LDAP servers normalize input, ignoring case and trimming spaces.</p>



<p>So, these inputs:</p>



<ul>
<li><code>"yardenporat"</code></li>



<li><code>"yardenporat "</code></li>



<li><code>" yardenporat"</code></li>



<li><code>"YARDENPORAT"</code></li>
</ul>



<p>These are all interpreted by LDAP as the same user, but treated by Vault as different aliases.</p>



<p>That discrepancy results in an astronomical number of login attempts that bypass the intended lockout limits. For example:</p>



<pre><code>≈ 1,000 (leading spaces) × 1,000 (trailing spaces) × 2¹¹ (case variants) × 5 (attempts) = ~10 billion guesses</code></pre>



<p><strong>Impact:</strong> </p>



<p>An attacker can make <strong>billions of password guesses</strong> against the same account in a single lockout window – completely defeating the brute-force protection mechanism</p>



<p><strong>CVE-2025-6003 – MFA enforcement bypass via</strong> <code>username_as_alias</code> <strong>and</strong> <code>EntityID</code><br>The second flaw was even more subtle and potentially more dangerous.</p>



<p>Vault allows admins to set <code>username_as_alias=true</code> in the <code>ldap </code>configuration. This means the username itself is used as the basis for identity resolution.</p>



<p>But when MFA enforcement is applied at the <code>EntityID</code> or <code>IdentityGroup</code> level, a mismatch occurs between how Vault resolves the user and how it enforces MFA.</p>



<p>Even though the user logs in successfully, Vault may fail to associate the correct <code>EntityID</code> and therefore, MFA never gets triggered.</p>



<p>For this bypass to occur, two conditions must be met:</p>



<ol>
<li><code>username_as_alias=true</code> in the LDAP auth configuration</li>



<li>MFA enforcement is applied at the <code>EntityID</code>or <code>IdentityGroup</code> level</li>



<li>This issue only became apparent after a deep analysis of how Vault handles <code>EntityID</code>resolution in tandem with authentication workflows, but the result is easily exploitable in practice, including via the UI.</li>
</ol>



<p><strong>Impact:</strong></p>



<p>When MFA is enforced at the <code>EntityID</code> level, Vault may fail to associate the correct <code>EntityID</code>, allowing the login to proceed without triggering MFA.</p>



<p>CVE-2025-6004 Lockout Bypass:</p>



<figure><video controls="" src="https://cyata.ai/wp-content/uploads/2025/08/CVE-2025-6004-ldap.mp4"></video></figure>



<p><br>CVE-2025-6003 MFA enforcement bypass:</p>



<figure><video controls="" src="https://cyata.ai/wp-content/uploads/2025/08/CVE-2025-6003-1.mp4"></video></figure>



<p><br><strong>Why it matters</strong></p>



<p>These two vulnerabilities allow an attacker to:</p>



<ul>
<li><strong>Bypass Vault’s lockout mechanism</strong>, enabling a high volume of password guesses per account</li>



<li><strong>Silently bypass MFA enforcement</strong> in specific configurations where MFA is applied at the <code>EntityID</code> or <code>IdentityGroup</code> level and <code>username_as_alias=true</code> is set</li>
</ul>



<p>Both flaws directly undermine core security protections in enterprise Vault deployments and highlight how subtle logic mismatches can erode trust at the identity layer.</p>



<p>Step 3 – Bypassing TOTP MFA protections</p>



<p><code>userpass</code> and <code>ldap</code> are widely used authentication backends in Vault, but they’re rarely deployed on their own. In most real-world setups, multi-factor authentication (MFA) is also configured. That’s why it was clear to us that any analysis of the authentication surface would be incomplete without examining it.</p>



<p>The MFA method we investigated is TOTP (Time-based One-Time Password), the most common MFA method overall, and especially common alongside <code>userpass</code> and <code>ldap</code>.</p>



<p>This approach adds a rotating numeric code on top of static credentials, aiming to stop brute-force and replay attacks with minimal overhead.</p>



<p><strong>TOTP in Vault</strong></p>



<p>Vault’s built-in TOTP MFA relies on a per-entity shared secret. During authentication, it generates a 6-digit code (valid for a 30-second window by default) and compares it to the user’s input.</p>



<p>By taking a look under the hood, we saw that:</p>



<ul>
<li>Vault uses the Go package <a href="https://pkg.go.dev/github.com/pquerna/otp/totp">github.com/pquerna/otp/totp</a></li>



<li>Rate-limiting and replay protection are implemented separately inside Vault</li>
</ul>



<p>For TOTP specification details, see <a href="https://datatracker.ietf.org/doc/html/rfc6238">RFC 6238</a></p>



<p><strong>Vault’s TOTP flow</strong></p>



<p>Here’s how Vault handles TOTP MFA during login:</p>



<p>1. Login begins</p>



<p>2. Vault checks for TOTP MFA</p>



<p>3. A passcode is extracted:</p>



<pre><code>func (c *Core) validateTOTP(...) error {
    if mfaFactors == nil || mfaFactors.passcode == "" {
        return fmt.Errorf("MFA credentials not supplied")
    }
    passcode := mfaFactors.passcode
    ...
}</code></pre>



<p>4. Vault checks if the passcode was already used (replay detection):</p>



<pre><code>usedName := fmt.Sprintf("%s_%s", configID, passcode)

_, ok := usedCodes.Get(usedName)
if ok {
    return fmt.Errorf("code already used; new code is available in %v seconds", totpSecret.Period)
}</code></pre>



<p>5. Rate-limiting is enforced per <code>EntityID</code>:</p>



<pre><code>rateLimitID := fmt.Sprintf("%s_%s", configID, entityID)

numAttempts, _ := usedCodes.Get(rateLimitID)
if numAttempts == nil {
    usedCodes.Set(rateLimitID, uint32(1), passcodeTTL)
} else {
    num, ok := numAttempts.(uint32)
    if !ok {
        return fmt.Errorf("invalid counter type returned in TOTP usedCode cache")
    }
    if num == maximumValidationAttempts {
        return fmt.Errorf("maximum TOTP validation attempts %d exceeded the allowed attempts %d.", num, maximumValidationAttempts)
    }
    err := usedCodes.Increment(rateLimitID, 1)
    if err != nil {
        return fmt.Errorf("failed to increment the TOTP code counter")
    }
}</code></pre>



<p>6. Code validation occurs using the <code>ValidateCustom()</code> function:</p>



<pre><code>key, err := c.fetchTOTPKey(ctx, configID, entityID)
if err != nil {
    return errwrap.Wrapf("error fetching TOTP key: {{err}}", err)
}

if key == "" {
    return fmt.Errorf("empty key for entity's TOTP secret")
}

valid, err := totplib.ValidateCustom(passcode, key, time.Now(), validateOpts)</code></pre>



<p><br>7. If the code is valid, it is marked as used:</p>



<pre><code>validityPeriod := time.Duration(int64(time.Second) * int64(totpSecret.Period) * int64(2+totpSecret.Skew))
err = usedCodes.Add(usedName, nil, validityPeriod)</code></pre>



<p>8. Authentication completes</p>



<figure><img loading="lazy" decoding="async" width="1360" height="1360" src="https://cyata.ai/wp-content/uploads/2025/08/totop-image.webp" alt="" srcset="https://cyata.ai/wp-content/uploads/2025/08/totop-image.webp 1360w, https://cyata.ai/wp-content/uploads/2025/08/totop-image-300x300.webp 300w, https://cyata.ai/wp-content/uploads/2025/08/totop-image-1024x1024.webp 1024w, https://cyata.ai/wp-content/uploads/2025/08/totop-image-150x150.webp 150w, https://cyata.ai/wp-content/uploads/2025/08/totop-image-768x768.webp 768w, https://cyata.ai/wp-content/uploads/2025/08/totop-image-372x372.webp 372w" sizes="auto, (max-width: 1360px) 100vw, 1360px"></figure>



<p><strong>What we looked for</strong></p>



<p>We dug into Vault’s TOTP implementation, looking for logic flaws that could significantly weaken this layer of protection, whether individually or when combined.</p>



<p><strong>What we found</strong></p>



<p>We uncovered <strong>three major logic flaws</strong>, plus a CVE that captures their combined impact:</p>



<p><strong>Bug 1 – Used passcode enumeration</strong></p>



<p>Vault checks for code reuse before applying rate-limiting. This opens a subtle but powerful attack surface.</p>



<p>If an attacker submits a passcode that was recently used, Vault responds with a specific error:</p>



<pre><code>"code already used; new code is available in %v seconds"</code></pre>



<p>This behavior reveals information. Even if a code is expired, Vault confirms it was valid at some point, enabling enumeration of previously used passcodes.</p>



<p><br><strong>Bug 2 – One-time-use bypass via space padding</strong></p>



<p>This issue originates deep inside Vault’s TOTP validation stack. Specifically:</p>



<ol>
<li>Vault calls <code>totp.ValidateCustom()</code></li>



<li><code>totp</code> internally calls <code>hotp.ValidateCustom()</code></li>



<li>Inside <code>hotp</code>, input is normalized:</li>
</ol>



<pre><code>func ValidateCustom(passcode string, ...) {
    passcode = strings.TrimSpace(passcode)
    ...
}</code></pre>



<p>So <code>"123456"</code> and <code>" 123456"</code> are treated as equivalent by the validator.</p>



<p>But Vault’s internal <code>usedCodes</code> cache does not normalize the input. This means:</p>



<ul>
<li><code>"123456"</code> is marked as used</li>



<li><code>" 123456"</code> is accepted as new, even though it’s the same underlying code</li>
</ul>



<p><strong>Impact:</strong> </p>



<p>An attacker can <strong>bypass the one-time-use restriction</strong> simply by adding spaces.</p>



<p><br><strong>Bug 3.1 – Rate-limiting evasion via time skew</strong></p>



<p>Even if an attacker has a valid TOTP code using Bug 1, Vault may still reject it because the enumeration attempts required to discover that code may have already triggered per-entity rate-limiting within the TOTP validity window. But this protection can be bypassed if the attacker understands how Vault sets its TTL threshold:</p>



<pre><code>passcodeTTL := time.Duration(int64(time.Second) * int64(totpSecret.Period))</code></pre>



<p>This default is <strong>30 seconds</strong>, matching the default TOTP period. But due to skew, passcodes may remain valid for <strong>up to 60 seconds</strong>, spanning two time windows.</p>



<p>This creates a strategy:</p>



<ul>
<li>Hit the rate limit</li>



<li>Wait out the 30-second TTL</li>



<li>Resubmit the same code (still within skew window)</li>



<li><strong>Authentication succeeds</strong></li>
</ul>



<p><br><strong>Bug 3.2 – Rate-limiting bypass via entity switching</strong></p>



<p>Vault enforces rate limits <strong>per </strong><code>EntityID</code>, but the <code>usedCodes</code> cache is <strong>global</strong>. This creates a loophole:</p>



<ol>
<li>One entity hits the rate limit while brute-forcing</li>



<li>A second entity submits the same (space-padded) passcode</li>



<li><strong>Rate-limit doesn’t apply</strong></li>
</ol>



<p id="CVE-2025-6013">Even worse, <strong>CVE-2025-6013</strong>, which we discovered and described above, allows LDAP users to generate multiple <code>EntityIDs</code> for the same identity. So even if Vault enforced rate limits per <code>EntityID</code> (which it doesn’t), attackers could still rotate <code>EntityIDs</code> to keep attacking.</p>



<p id="CVE-2025-6016"><br><strong>CVE-2025-6016 – Aggregated logic flaws weaken MFA</strong></p>



<p>All these flaws combine into a dangerous scenario.</p>



<p>An attacker can:</p>



<ol>
<li><strong>Enumerate </strong>used passcodes by probing for error messages</li>



<li><strong>Evade </strong>rate-limiting by either:
<ul>
<li>Switching entities</li>



<li>Waiting out the TTL window</li>
</ul>
</li>



<li><strong>Bypass </strong>one-time-use protection via space manipulation</li>



<li><strong>Submit </strong>the correct passcode to authenticate without triggering defenses</li>
</ol>



<p>Despite TOTP being configured as a second factor, Vault’s logic flaws allowed attackers to <strong>brute-force MFA codes </strong>within a small time window.</p>



<p><strong>Why it matters</strong></p>



<p>These flaws significantly reduced the effectiveness of MFA in Vault, enabling attackers to bypass protections like rate-limiting and one-time-use enforcement, and in some configurations, guess valid TOTP codes without triggering MFA challenges as expected.</p>



<p>Step 4 – Certificate-based authentication and entity impersonation</p>



<p>In Vault, TLS certificate authentication is commonly used for machine-to-machine scenarios, allowing automated services, infrastructure components, or nodes to securely identify themselves.</p>



<p>To enable cert-based authentication, users configure it through the Vault UI or API:</p>



<figure><img loading="lazy" decoding="async" width="1243" height="811" src="https://cyata.ai/wp-content/uploads/2025/08/hashicorp-3.webp" alt="" srcset="https://cyata.ai/wp-content/uploads/2025/08/hashicorp-3.webp 1243w, https://cyata.ai/wp-content/uploads/2025/08/hashicorp-3-300x196.webp 300w, https://cyata.ai/wp-content/uploads/2025/08/hashicorp-3-1024x668.webp 1024w, https://cyata.ai/wp-content/uploads/2025/08/hashicorp-3-768x501.webp 768w, https://cyata.ai/wp-content/uploads/2025/08/hashicorp-3-372x243.webp 372w" sizes="auto, (max-width: 1243px) 100vw, 1243px"></figure>



<p>Once enabled, Vault’s <code>cert</code> method supports two modes:</p>



<ol>
<li><strong>CA mode</strong> – Trust any certificate issued by a configured Certificate Authority (CA)</li>



<li><strong>Non-CA mode</strong> – Trust only a specific pinned certificate, verified by public key</li>
</ol>



<p>In both cases, Vault maps the TLS client certificate to an <code>EntityID</code> using the authentication mount path and the Common Name (CN) from the certificate.</p>



<p>(auth mount path, alias.Name)</p>



<p>The value of <code>alias.Name</code> is taken from the Common Name (CN) field of the client certificate presented during the TLS handshake, not from the certificate configured in Vault:</p>



<pre><code>Alias: &amp;logical.Alias{
    Name: clientCerts[0].Subject.CommonName,
}</code></pre>



<p>In CA mode, this behavior makes sense – CNs vary and can’t be predicted in advance. But in non-CA mode, this introduces a dangerous blind spot.</p>



<p><strong>What we looked for</strong></p>



<p>We examined how Vault maps identities in cert-based authentication, particularly in non-CA mode, to identify potential mismatches between trust and identity resolution.</p>



<p><strong>What we found</strong></p>



<p>We discovered a logic flaw in Vault’s non-CA certificate authentication: Vault verifies only that the TLS client certificate’s public key matches the pinned certificate, but does not verify that the CN matches as well.</p>



<p id="CVE-2025-6037"><strong>CVE-2025-6037 – Certificate entity impersonation</strong></p>



<p>In non-CA mode, an attacker who has access to the private key of a pinned certificate can:</p>



<ul>
<li>Present a certificate with the correct public key</li>



<li>Modify the CN in the client certificate to any arbitrary value</li>



<li>Cause Vault to assign the resulting <code>alias.Name</code> to that CN</li>
</ul>



<p>Because Vault maps this alias to an <code>EntityID</code>, the attacker is now authenticated as any identity whose alias matches the forged CN.</p>



<p>This allows impersonation of other machine identities, inheriting:</p>



<ul>
<li>Policies tied to the spoofed <code>EntityID</code></li>



<li>Policies from associated <code>Identity Groups</code></li>
</ul>



<p>Even though policies directly tied to a specific certificate remain inaccessible, in many deployments, <code>EntityID</code> – linked policies may be sufficient to escalate access or retrieve secrets.</p>



<p><strong>Why it matters</strong></p>



<p>Vault’s trust model depends on accurate identity mapping. This vulnerability breaks that assumption by allowing any private-key holder of a pinned cert to impersonate other machine identities, a severe breach of trust.</p>



<p>In environments where certificates govern automated secret retrieval, service orchestration, or backend access control, this opens the door to full lateral compromise.</p>



<p>Step 5 – Escalating from admin to root</p>



<p>So far, we’ve focused on breaking Vault’s authentication surface, through <code>userpass</code>, <code>LDAP</code>, <code>MFA</code>, and <code>cert</code>.</p>



<p>Now we turn to what happens after authentication: what can a legitimate user do? In this section, we show how an admin-level user can escalate privileges and obtain a root token, despite the boundaries the Vault trust model is designed to enforce.</p>



<p>The Vault trust model is one that relies on strict role separation. Even users with admin-level tokens are restricted from performing certain privileged actions. But that boundary can break.</p>



<p><strong>How it works</strong></p>



<p>Vault uses a policy-based authorization system. Each identity or token is granted permissions through attached policies.</p>



<p>Two built-in policies define access boundaries:</p>



<ul>
<li><code>default:</code> minimal access</li>



<li><code>root:</code> full administrative control, including audit logging, plugin registration, encryption key rotation, and system reconfiguration</li>
</ul>



<p>To prevent misuse, Vault includes a hardcoded restriction to block assignment of the <code>root</code> policy. This protection applies at all expected enforcement points, including:</p>



<ul>
<li>During user login</li>



<li>When modifying an identity (<code>EntityID</code>) via Vault’s identity API</li>
</ul>



<p>To assign policies to an identity, Vault provides the following endpoint:</p>



<p><code>POST /v1/identity/entity/id/{entity_id}</code></p>



<p>This endpoint allows modification of the attached policy set for a given <code>EntityID</code>. It’s powerful and typically reserved for high-privilege users.</p>



<p>Vault includes a safeguard to prevent abuse:</p>



<pre><code>if strutil.StrListContains(entity.Policies, "root") {
    return logical.ErrorResponse("policies cannot contain root"), nil
}</code></pre>



<p>This hardcoded check explicitly blocks requests that attempt to assign the <code>root</code> policy, or so it seems.</p>



<p><strong>What we looked for</strong></p>



<p>With initial access achieved, we turned our attention to potential escalation paths, particularly whether admin users could gain root.</p>



<p>We uncovered a <strong>logic flaw</strong> in how Vault normalizes policy names, one that lets an attacker escalate from <strong>admin to root</strong> by bypassing its most explicitly protected gate.</p>



<p><strong>What we found</strong></p>



<p id="CVE-2025-5999"><strong>CVE-2025-5999 – Root privilege escalation via policy normalization</strong></p>



<p>During request evaluation (e.g., when a token is used to access an endpoint), Vault performs policy merging and normalization. The relevant code:</p>



<pre><code>auth.Policies = policyutil.SanitizePolicies(append(te.Policies, identityPolicies[te.NamespaceID]...))</code></pre>



<p>Inside <code>SanitizePolicies</code>, this logic appears:</p>



<pre><code>p = strings.ToLower(strings.TrimSpace(p))</code></pre>



<p>This introduces a subtle but powerful mismatch:</p>



<ul>
<li>The <strong>validation</strong> layer checks for <code>"root"</code>  – exactly as written</li>



<li>The <strong>enforcement</strong> layer normalizes input by trimming and lowercasing</li>
</ul>



<p>That means the following inputs:</p>



<ul>
<li><code>" root"</code> (with a space)</li>



<li><code>"ROOT"</code> (uppercase)</li>
</ul>



<p>Because these variations aren’t blocked by the validation check, they pass through and are then normalized to ‘root’ during enforcement.</p>



<p>So, if an attacker submits a request assigning <code>" root"</code> as a policy, it silently passes the block and becomes <code>root</code> in practice.</p>



<p>Vault will now treat the token as having full administrative privileges.</p>



<p><strong>Why it matters</strong></p>



<p>This logic flaw allows an attacker with admin-level access to:</p>



<ul>
<li>Authenticate and obtain a valid token</li>



<li>Submit a request to <code>POST /v1/identity/entity/id/{entity_id}</code> with <code>" root"</code> in the policy list</li>



<li>Bypass the hardcoded <code>root</code> check</li>



<li>Gain <strong>root privileges</strong> after the policy is normalized at runtime</li>
</ul>



<p>This bypass targets one of the <strong>most tightly protected controls in Vault</strong> and succeeds without crashing the service, triggering alarms, or touching memory. It’s a clean, silent privilege escalation.</p>



<p>Step 6 – Remote code execution via plugin interface abuse</p>



<p>In the previous step, we demonstrated how an admin-level user can escalate to root token privileges.</p>



<p>From there, the next logical step was to investigate whether that level of access could be used to achieve code execution, specifically, to abuse Vault’s internal interfaces in order to run arbitrary commands on the server.</p>



<p><strong>What we looked for</strong></p>



<p>From root, we explored whether code execution was possible for an attacker with elevated access, specifically via Vault’s plugin system.</p>



<p><strong>What we found</strong></p>



<p>Vault supports loading custom plugins – binaries that provide secret engines, auth methods, or other extensible functionality.&nbsp;These plugins are stored in a predefined <code>plugin_directory</code>, which is configured during setup and cannot be modified at runtime.</p>



<p>During our testing, we discovered a method for creating and loading an attacker-controlled plugin.</p>



<p><strong>CVE-2025-6000 – RCE via plugin catalog abuse</strong></p>



<p>To create and load a new plugin, an attacker must achieve five goals:</p>



<ol>
<li>Create a controlled file on disk</li>



<li>Locate the configured <code>plugin_directory</code></li>



<li>Place the controlled file inside <code>plugin_directory</code></li>



<li>Assign execute permissions to the file</li>



<li>Know the SHA256 hash of the file contents in advance (required to load a plugin)</li>
</ol>



<p><strong>Step 1 – Writing a payload to disk</strong></p>



<p>Vault encrypts nearly all user-controlled content, including secrets and metadata.</p>



<p>Even when storing data through the API, the resulting file is encoded and wrapped in structured formats.</p>



<p>There’s no way to get raw bytes written directly to disk . . . except in one place:</p>



<p><strong>Audit logs.</strong></p>



<p>Audit logs are written in plaintext, not encrypted. And while each entry is a structured JSON object, we discovered something surprising:</p>



<p><strong>Vault’s audit log system supports a “prefix” – a string prepended to every log entry.</strong></p>



<p>We set the prefix to a payload like <code>#!/bin/bash\n...</code> and let Vault write the rest. The JSON body that follows is ignored by Bash. All that matters is that the script starts with a valid shebang and executable code.</p>



<p><strong>Step 2 – Locating the </strong><code>plugin_directory</code></p>



<p>The <code>plugin_directory </code>configuration is used only for loading plugins. So, to locate it, our best bet was to examine the plugin loading endpoint:</p>



<p><code>POST /v1/sys/plugins/catalog/:type/:name.</code></p>



<p>We experimented with it to understand how plugin loading works and what the code flow looks like. During testing, we found that when attempting to load a non-existent binary, the endpoint returns an error message, and that message includes the full path to the <code>plugin_directory</code>.</p>



<p>For example, when we tried to load the binary <code>invalid91cad96-b8e6-4f5b-9359-ad20fe5815c4</code>, we got:</p>



<pre><code>Loading plugin invalid91cad96-b8e6-4f5b-9359-ad20fe5815c4&nbsp;
Got error:&nbsp;&nbsp;&nbsp;&nbsp; * error while validating the command path: lstat /Users/yarpo/Desktop/vaults/hashicorp/config/plugins/invalid91cad96-b8e6-4f5b-9359-ad20fe5815c4: no such file or directory&nbsp;</code></pre>



<p><strong>Step 3 – Writing to the plugin directory</strong></p>



<p>Now that we had the <code>plugin_directory</code> we wanted to write our audit file to there.</p>



<p>Fortunately, Vault allows configuring the audit backend to write logs to any absolute file path.</p>



<p>We set:</p>



<ul>
<li><code>file_path</code> = inside the plugin directory</li>
</ul>



<p><strong>Step 4 – Getting execute permissions</strong></p>



<p>Vault doesn’t load just any file as a binary. The file must have execute permissions in order to be loaded as a plugin.</p>



<p>This turned out to be the most unexpected and critical part. When configuring the audit log file, there is an option to set the file’s mode. and this includes support for executable modes.</p>



<p>So we set:</p>



<ul>
<li><code>mode = 0755</code></li>
</ul>



<p><strong>Note:</strong> Using the audit logs, we can create a file with arbitrary contents matching a regex, write it to any absolute <code>file_path</code>, and assign it executable permissions.</p>



<p><strong>Step 5 – Capturing the hash</strong></p>



<p>In the registration phase, a SHA256 of the binary must be provided. This might sound simple, but for our audit log approach, it presents a challenge: audit logs include timestamps and other unpredictable values, making it impossible to precompute the hash.&nbsp;</p>



<p>To solve this, we configured multiple audit backends simultaneously.</p>



<p>We added a second backend that streamed logs to a TCP socket we controlled. This gave us a real-time copy of the exact file content, allowing us to compute the correct SHA256 after the file was written.</p>



<p><strong>Full exploit flow</strong></p>



<ol>
<li>Attempt to load a non-existent plugin → Vault returns an error that reveals the full <code>plugin_directory</code> path.</li>



<li>Enable a file-based audit backend with:</li>
</ol>



<ul>
<li><code>file_path = inside plugin_directory</code></li>



<li>mode = 0755</li>
</ul>



<ol>
<li><code>prefix = Bash payload</code> <strong>Send request</strong> → Vault writes executable Bash file.</li>



<li>Capture file content from the socket → Compute SHA256.</li>



<li><strong>Register the plugin</strong> using the correct hash.</li>



<li>Vault executes it → <strong>RCE achieved</strong>.</li>
</ol>



<p>Default -&gt; RCE (CVE-2025-6037, CVE-2025-5999, CVE-2025-6000):</p>



<figure><video controls="" src="https://cyata.ai/wp-content/uploads/2025/08/HashiCorpRCE-1.mp4"></video></figure>



<p><strong>Why it matters</strong></p>



<p>This vulnerability chains together multiple trusted Vault components – audit logging, file permissions, plugin registration, to break critical security boundaries.</p>



<p>The ability to:</p>



<ul>
<li>Write a file to disk</li>



<li>Control its contents via a hidden prefix feature</li>



<li>Set its mode to executable</li>



<li>Compute its hash</li>



<li>And execute it as a plugin</li>
</ul>



<p>translates into a full remote code execution with no memory corruption or native code injection.</p>



<p>CVE-2025-6000 is <strong>the first public RCE reported in Vault</strong>, even though the underlying risk had been present for nearly a decade.</p>



<p><strong>Post-exploitation scenarios</strong></p>



<p>With RCE in Vault, an attacker gains complete control, but what they do next depends on their intent. We highlight two realistic post-exploitation strategies observed during testing.</p>



<p><strong>Vault ransomware</strong></p>



<p>Vault stores all critical state – including secrets, tokens, and policies, encrypted on disk. One of the key components required for decryption is the file:</p>



<ul>
<li><code>core/hsm/_barrier-unseal-keys</code></li>
</ul>



<p>If this file is deleted, Vault permanently loses access to its encryption key, rendering the remaining data unreadable – even to administrators.</p>



<p>By removing a single file, an attacker can flip Vault’s encryption model on its head, turning it from a security mechanism into a ransomware vector.</p>



<p><strong>Stealthy path: audit-free persistence</strong></p>



<p>In Vault Enterprise, the <strong>Control Group</strong> feature is designed to enforce multi-approver workflows for sensitive operations. But with RCE, this mechanism can be subverted for stealth.</p>



<p>By writing custom control group files directly to disk, an attacker can abuse the system to send HTTP requests and receive responses without being audited. This results in persistent, low-visibility access that bypasses oversight.</p>



<p>This abuse was discovered through black-box testing, as Control Group is exclusive to Vault Enterprise and not openly documented.</p>



<h2>Putting it all together: impact and attack paths</h2>



<p>This research exposes critical weak points in Vault’s trust and identity model – flaws that, under real-world conditions, form exploitable attack paths and can drive devastating results.</p>



<p>Each issue stands on its own, but when combined, they open the door to high-impact compromise scenarios.</p>



<p>In practice, a determined attacker may be able to chain together multiple vulnerabilities, depending on configuration, permissions, and persistence level.</p>



<p>Below are three realistic attack paths, based on common authentication methods:</p>



<p>1. <code>userpass</code> attack path (high-effort, persistent attacker)</p>



<ul>
<li>Enumerate valid usernames via error message mismatch</li>



<li>Bypass lockout using case variation</li>



<li>Bypass TOTP MFA rate limits and one-time-use protection</li>



<li><em>(If the compromised user has admin privileges)</em> → escalate to <code>root</code> via policy normalization</li>



<li>Achieve RCE via audit log and plugin abuse</li>
</ul>



<p>This path is difficult and requires persistence, but it’s viable, especially if MFA policies are weak and admin tokens are in use.</p>



<p>2. <code>ldap</code> attack path (config-dependent)</p>



<ul>
<li>Bypass lockout using input normalization mismatch</li>



<li>Bypass MFA if <code>username_as_alias=true</code> and MFA is enforced at the <code>EntityID</code> level</li>



<li><em>(If the compromised user has admin privileges)</em> → escalate to <code>root</code></li>



<li>Achieve RCE via plugin interface abuse</li>
</ul>



<p>This scenario depends on specific but common configuration choices</p>



<p>3. <code>cert</code> attack path (targeted impersonation)</p>



<ul>
<li>Impersonate an admin-level user by modifying CN in a certificate with a trusted public key</li>



<li><em>(If the impersonated identity has entity-based policies)</em> → gain admin access</li>



<li>Escalate to <code>root</code></li>



<li>Trigger RCE through audit logging chain</li>
</ul>



<p>This path requires access to the private key of a pinned certificate and benefits from permissive policy binding.</p>



<p>Each of these paths leverages distinct logic flaws in Vault, but all converge at the same critical outcome: <strong>root access and full code execution inside the Vault server</strong>.</p>



<p><strong>Why this matters</strong></p>



<p>This research shows how authentication, policy enforcement, and plugin execution can all be subverted through logic bugs, without touching memory, triggering crashes, or breaking cryptography.</p>



<p><strong>These logic vulnerabilities – one of which would qualify as CVSS ‘critical’ –  could be weaponized to exfiltrate secrets, disable access controls, or sabotage infrastructure from within.</strong></p>



<p><strong>It’s a reminder that even without memory safety bugs, logic flaws can open the door to complete compromise.</strong></p>



<h2>How long were these vulnerabilities in Vault?</h2>



<p>As part of our research, we analyzed the history of key vulnerabilities in Vault to understand how long they had existed before our discovery. Two cases stood out:</p>



<p><em>CVE-2025-6037 – Certificate impersonation</em></p>



<p>This vulnerability existed in Vault for over <strong>eight years</strong>. For the first seven years, it was effectively a <strong>full authentication bypass via certificate</strong>, not just impersonation, making it far more severe.</p>



<p>In the past year, the issue appears to have been partially addressed, “downgrading” the bug to impersonation.</p>



<p id="CVE-2025-6000"><em>CVE-2025-6000 – Remote Code Execution</em></p>



<p>This vulnerability has existed in Vault for <strong>nine years</strong>, dating back to the project’s early releases.</p>



<p>This is also the <strong>first public RCE ever reported in Vault</strong>. While there have been issues in adjacent areas before, none previously enabled full command execution on the Vault server.</p>



<h2>Disclosure and response</h2>



<p>At Cyata, we followed a strict responsible disclosure process throughout this research. Every vulnerability was privately reported to HashiCorp with clear documentation, technical detail, and proof-of-concept support.</p>



<p>We worked in close coordination with HashiCorp’s security team to ensure that all issues were understood, addressed, and resolved before any public disclosure – minimizing risk to users and ensuring timely protection.</p>



<p>HashiCorp responded professionally at every stage of the process, engaging constructively and collaborating with us until all findings were fully resolved.</p>



<p>This wasn’t just a technical milestone. It was a deliberate, professional collaboration aimed at protecting the global organizations that rely on Vault.</p>



<p>Disclosure timeline</p>



<ul>
<li><strong>May 18, 2025</strong> – Cyata submitted the initial disclosure to the HashiCorp security team, covering the majority of the findings. Some issues were still under active investigation.</li>



<li><strong>May 23, 2025</strong> – We followed up with the complete list of confirmed vulnerabilities.</li>



<li><strong>May 24, 2025</strong> – HashiCorp responded with additional questions, primarily focused on the certificate impersonation issue.</li>



<li><strong>May 24 (Evening)</strong> – Cyata sent a detailed technical explanation clarifying the impersonation path.</li>



<li><strong>May 25, 2025</strong> – We shared a full proof-of-concept video demonstrating the certificate impersonation attack in action.</li>



<li><strong>June 12, 2025</strong> – HashiCorp acknowledged and accepted all findings, assigning <strong>nine CVEs</strong> across the reported issues.</li>
</ul>



<p><em>Coordinated patching and resolution</em></p>



<p>HashiCorp moved quickly to develop and release patches for both the Open Source and Enterprise versions of Vault. These fixes were made available to users ahead of public disclosure, ensuring organizations could protect their environments immediately.</p>



<p>Further information from the vendor is available in&nbsp;<a href="https://discuss.hashicorp.com/t/hcsec-2025-22-multiple-vulnerabilities-impacting-hashicorp-vault-and-vault-enterprise/76096" target="_blank" rel="noreferrer noopener">this HashiCorp advisory</a>.</p>



<p>This coordinated response is a model for how security research and vendor collaboration should work – transparent, professional, and impact-driven.</p>



<p>At Cyata, we believe meaningful research doesn’t stop at discovery. It must include responsible coordination, resolution, and ultimately, protection for the infrastructure the world depends on.</p>



<h2>Conclusion</h2>



<p>This research reinforces a critical truth – even memory-safe software can fail at the logic level – and when it does, the consequences can be just as severe.</p>



<p>Vault is designed to be the ultimate protector of secrets and infrastructure access. But this work shows how subtle logic bugs in authentication flows, identity resolution, and policy enforcement, can quietly break trust.</p>



<p>And when trust in the vault is broken, the impact is immediate and devastating: attackers can impersonate users, bypass MFA, extract credentials, seize root tokens, and even execute arbitrary commands. With control over Vault, they can hijack internal services, pivot across environments, and hold entire systems hostage, all without triggering conventional alarms.</p>



<p>One of our key takeaways is that vaults must be tested not only against brute-force and interface abuse, but against deep behavioral inconsistencies – edge cases that only emerge when you understand how the system is wired together internally.</p>



<p>Cyata’s research team uncovered these vulnerabilities through manual review, attacker-style reasoning, and persistence. This wasn’t automation. It was a methodical, step-by-step process, reasoning through Vault’s design and asking: where can things go wrong?</p>



<p>The issues uncovered in this research are exceptionally severe, capable of quietly compromising the core layer that organizations rely on to protect everything else.</p>



<p>We believe that research like this is essential – not only to harden individual products, but to help the security community stay one step ahead of attackers.</p>



<p>Because when trust itself is the surface, scrutiny is protection.</p>


<div>
		<p>The Control Plane  for Agentic Identity</p>
					
			</div>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FDA approves eye drops that fix near vision without glasses (124 pts)]]></title>
            <link>https://newatlas.com/aging/age-related-near-sighted-drops-vizz/</link>
            <guid>44820325</guid>
            <pubDate>Thu, 07 Aug 2025 03:34:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://newatlas.com/aging/age-related-near-sighted-drops-vizz/">https://newatlas.com/aging/age-related-near-sighted-drops-vizz/</a>, See on <a href="https://news.ycombinator.com/item?id=44820325">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>The first aceclidine-based eye drop to improve near vision in adults with presbyopia, which affects more than 100 million adults in the US alone, has been approved by the Food and Drug Administration (FDA) and will be available within three months.</p><p>Known as VIZZ, from pharmaceutical company LENZ, the drops are an aceclidine ophthalmic solution that effectively treats <a href="https://newatlas.com/medical/vuity-presbyopia-eye-drops/" data-cms-ai="0">presbyopia</a> in adults. The once-daily drops offer relief from blurry near. vision for up to 10 hours.</p><p>"The FDA approval of VIZZ is a defining moment for LENZ and represents a transformative improvement in the available treatment options for the 128 million adults living with blurry near vision in the United States," said Eef Schimmelpennink, President and Chief Executive Officer of LENZ Therapeutics. "This significant milestone is the result of tremendous commitment and collaboration by the LENZ team and our partners, the dedication of our clinical investigators, and the contributions of hundreds of participants in our clinical trials."</p><p>VIZZ works by gently shrinking the pupil of the eye, using aceclidine. This creates a “pinhole effect” – like narrowing a camera lens — which helps bring nearby objects into sharper focus. Unlike older eye drops, this one does not significantly affect the eye’s focusing muscles, so it doesn’t blur your distance vision or cause that “zoomed-in” effect (aka a myopic shift).</p><p>Ultimately, the drops offer improved reading vision for up to 10 hours, without the need for glasses and, importantly, without the side effects of older treatments.</p><p><a href="https://newatlas.com/medical/vuity-presbyopia-eye-drops/" data-cms-ai="0">In 2021, the very first drops to treat this condition were launched</a> to much acclaim, but there's a reason VIZZ drops are considered first-in-class. Vuity (pilocarpine hydrochloride 1.25%) is a dual-action eye drop that can improve near vision but may cause side effects like brow heaviness or rare vitreoretinal issues due to the ciliary muscle activation. Aceclidine, a pupil-selective miotic, works without significantly stimulating the focusing (ciliary) muscle, creating a pinhole effect – which improves near vision without adverse outcomes seen in Vuity.</p><p>"This FDA approval represents a disruptive paradigm shift in treatment options for millions of people who are frustrated and struggling with the inevitable age-related loss of their near vision," said VIZZ clinical investigator Marc Bloomenstein, from Schwartz Laser Eye Care Center in Scottsdale, Arizona. "I believe this will be a welcome solution for both optometrists and ophthalmologists who will now be able to offer a highly effective and sought-after presbyopia treatment that could immediately become the standard of care, with a product profile that will meet our patients’ needs."</p><p>The FDA approval comes on the back of three randomized, double-masked, controlled Phase II studies featuring hundreds of participants. VIZZ was well-tolerated with no serious adverse events observed in the 30,000-plus treatment days across all three trials. </p><p>Presbyopia is, unfortunately, an inevitable condition associated with aging. Almost everyone over the age of 45 experiences this near-sight vision loss, which gradually gets worse and usually requires correction with glasses or contact lenses. While presbyopia is a gradual condition, it can progress quickly and unexpectedly, making formerly simple tasks of day-to-day tasks like reading instructions or food labels more difficult. </p><p>The therapeutics company said VIZZ is expected to be broadly available in the fourth quarter of 2025, making it the first and only FDA-approved aceclidine-based eye drop for presbyopia treatment. </p><p>"This is uniquely engineered, highly-differentiated and designed to deliver quick onset and lasting benefit for the vast majority of presbyopes," said Schimmelpennink. "As we have shown, this is not only best-in-class, but frankly, the only in a class of pupil selective ciliary-sparing myotics."</p><p>The FDA approval comes based on trial data submitted by the pharmaceutical company, so it's worth noting that published peer-reviewed reports are yet to be published. Peer-reviewed publications often follow regulatory approvals, not precede them, which is common in the field of ophthalmology and dermatology.</p><p>However, the FDA data and guidance can be found <a href="https://www.accessdata.fda.gov/drugsatfda_docs/label/2025/218585s000lbl.pdf" target="_blank" data-cms-ai="0">published here</a>.</p><p>Source: <a href="https://ir.lenz-tx.com/news-events/press-releases/detail/39/lenz-therapeutics-announces-us-fda-approval-of-vizz-for-the-treatment-of-presbyopia" target="_blank" data-cms-ai="0">LENZ Therapeutics</a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Running GPT-OSS-120B at 500 tokens per second on Nvidia GPUs (225 pts)]]></title>
            <link>https://www.baseten.co/blog/sota-performance-for-gpt-oss-120b-on-nvidia-gpus/</link>
            <guid>44819968</guid>
            <pubDate>Thu, 07 Aug 2025 02:28:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.baseten.co/blog/sota-performance-for-gpt-oss-120b-on-nvidia-gpus/">https://www.baseten.co/blog/sota-performance-for-gpt-oss-120b-on-nvidia-gpus/</a>, See on <a href="https://news.ycombinator.com/item?id=44819968">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>The day an open source model like OpenAI’s new gpt-oss-120b is released, we race to make the model as performant as possible for our customers. As a <a href="https://openai.com/index/introducing-gpt-oss/">launch partner</a> for OpenAI’s first open-source LLM since 2019, we wanted to give developers a great experience with the new LLMs.</p><p>By the end of launch day, we were the clear leader running on NVIDIA GPUs for both latency and throughput per public data from real-world use on <a href="https://openrouter.ai/openai/gpt-oss-120b">OpenRouter</a>.</p><div><p>✕</p><p><img alt="What matters is having the inference optimization muscle to immediately push on latency and throughput" draggable="false" loading="lazy" width="1200" height="593" decoding="async" data-nimg="1" sizes="100vw" srcset="https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1754532343-screenshot-2025-08-06-at-2-45-29-pm.png%3Fauto%3Dformat%26w%3D1200&amp;w=640&amp;q=75 640w, https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1754532343-screenshot-2025-08-06-at-2-45-29-pm.png%3Fauto%3Dformat%26w%3D1200&amp;w=750&amp;q=75 750w, https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1754532343-screenshot-2025-08-06-at-2-45-29-pm.png%3Fauto%3Dformat%26w%3D1200&amp;w=828&amp;q=75 828w, https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1754532343-screenshot-2025-08-06-at-2-45-29-pm.png%3Fauto%3Dformat%26w%3D1200&amp;w=1080&amp;q=75 1080w, https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1754532343-screenshot-2025-08-06-at-2-45-29-pm.png%3Fauto%3Dformat%26w%3D1200&amp;w=1200&amp;q=75 1200w, https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1754532343-screenshot-2025-08-06-at-2-45-29-pm.png%3Fauto%3Dformat%26w%3D1200&amp;w=1920&amp;q=75 1920w, https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1754532343-screenshot-2025-08-06-at-2-45-29-pm.png%3Fauto%3Dformat%26w%3D1200&amp;w=2048&amp;q=75 2048w, https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1754532343-screenshot-2025-08-06-at-2-45-29-pm.png%3Fauto%3Dformat%26w%3D1200&amp;w=3840&amp;q=75 3840w" src="https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1754532343-screenshot-2025-08-06-at-2-45-29-pm.png%3Fauto%3Dformat%26w%3D1200&amp;w=3840&amp;q=75"><span><span>What matters is having the inference optimization muscle to immediately push on latency and throughput</span></span></p></div><p>Optimizing performance on a new model is a substantial engineering challenge. Thanks to our flexible <a href="https://www.baseten.co/resources/guide/the-baseten-inference-stack/">inference stack</a> and the collective expertise of our model performance engineering team, we are able to roll out performance improvements by the hour on new models.</p><p>In fact, in the time it took to write this blog post, we added another 100 tokens per second while maintaining 100% uptime.</p><div><p>✕</p><p><img alt="OpenRouter performance for GPT OSS, 6:45 PM August 6, 2025" draggable="false" loading="lazy" width="1200" height="412" decoding="async" data-nimg="1" sizes="100vw" srcset="https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1754532371-screenshot-2025-08-06-at-6-49-49-pm.png%3Fauto%3Dformat%26w%3D1200&amp;w=640&amp;q=75 640w, https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1754532371-screenshot-2025-08-06-at-6-49-49-pm.png%3Fauto%3Dformat%26w%3D1200&amp;w=750&amp;q=75 750w, https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1754532371-screenshot-2025-08-06-at-6-49-49-pm.png%3Fauto%3Dformat%26w%3D1200&amp;w=828&amp;q=75 828w, https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1754532371-screenshot-2025-08-06-at-6-49-49-pm.png%3Fauto%3Dformat%26w%3D1200&amp;w=1080&amp;q=75 1080w, https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1754532371-screenshot-2025-08-06-at-6-49-49-pm.png%3Fauto%3Dformat%26w%3D1200&amp;w=1200&amp;q=75 1200w, https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1754532371-screenshot-2025-08-06-at-6-49-49-pm.png%3Fauto%3Dformat%26w%3D1200&amp;w=1920&amp;q=75 1920w, https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1754532371-screenshot-2025-08-06-at-6-49-49-pm.png%3Fauto%3Dformat%26w%3D1200&amp;w=2048&amp;q=75 2048w, https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1754532371-screenshot-2025-08-06-at-6-49-49-pm.png%3Fauto%3Dformat%26w%3D1200&amp;w=3840&amp;q=75 3840w" src="https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1754532371-screenshot-2025-08-06-at-6-49-49-pm.png%3Fauto%3Dformat%26w%3D1200&amp;w=3840&amp;q=75"><span><span>OpenRouter performance for GPT OSS, 6:45 PM August 6, 2025</span></span></p></div><p> Model performance efforts included:</p><ul><li><p>Testing and benchmarking across inference frameworks (TensorRT-LLM, vLLM, and SGLang)</p></li><li><p>Ensuring compatibility with Hopper and Blackwell GPU architectures</p></li><li><p>Integrating with key pieces of our inference stack, including NVIDIA Dynamo</p></li><li><p>Layering in our favorite performance optimizations, like KV cache-aware routing and speculative decoding with Eagle</p></li></ul><p>Below are the steps we took to achieve our goal of SOTA performance with full context window support.</p><h2 id="step-1-running-first-inference">Step 1: Running first inference</h2><p>The first step is running baseline inference however possible. Running inference on a model requires support at the inference framework, hardware architecture, and model server level.</p><p>Inspired by GPUs, we parallelized this effort across multiple engineers. One engineer tried vLLM, another SGLang, and a third worked on TensorRT-LLM. We were able to quickly get TensorRT-LLM working, which was fortunate as it is usually the most performant inference framework for LLMs.</p><div><p>✕</p><p><img alt="NVIDIA cut a dev release of TensorRT-LLM to support GPT OSS" draggable="false" loading="lazy" width="1200" height="122" decoding="async" data-nimg="1" sizes="100vw" srcset="https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1754532392-catalog-ngc-nvidia-com_orgs_nvidia_teams_tensorrt-llm_containers_release_tags.png%3Fauto%3Dformat%26w%3D1200&amp;w=640&amp;q=75 640w, https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1754532392-catalog-ngc-nvidia-com_orgs_nvidia_teams_tensorrt-llm_containers_release_tags.png%3Fauto%3Dformat%26w%3D1200&amp;w=750&amp;q=75 750w, https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1754532392-catalog-ngc-nvidia-com_orgs_nvidia_teams_tensorrt-llm_containers_release_tags.png%3Fauto%3Dformat%26w%3D1200&amp;w=828&amp;q=75 828w, https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1754532392-catalog-ngc-nvidia-com_orgs_nvidia_teams_tensorrt-llm_containers_release_tags.png%3Fauto%3Dformat%26w%3D1200&amp;w=1080&amp;q=75 1080w, https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1754532392-catalog-ngc-nvidia-com_orgs_nvidia_teams_tensorrt-llm_containers_release_tags.png%3Fauto%3Dformat%26w%3D1200&amp;w=1200&amp;q=75 1200w, https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1754532392-catalog-ngc-nvidia-com_orgs_nvidia_teams_tensorrt-llm_containers_release_tags.png%3Fauto%3Dformat%26w%3D1200&amp;w=1920&amp;q=75 1920w, https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1754532392-catalog-ngc-nvidia-com_orgs_nvidia_teams_tensorrt-llm_containers_release_tags.png%3Fauto%3Dformat%26w%3D1200&amp;w=2048&amp;q=75 2048w, https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1754532392-catalog-ngc-nvidia-com_orgs_nvidia_teams_tensorrt-llm_containers_release_tags.png%3Fauto%3Dformat%26w%3D1200&amp;w=3840&amp;q=75 3840w" src="https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1754532392-catalog-ngc-nvidia-com_orgs_nvidia_teams_tensorrt-llm_containers_release_tags.png%3Fauto%3Dformat%26w%3D1200&amp;w=3840&amp;q=75"><span><span>NVIDIA cut a dev release of TensorRT-LLM to support GPT OSS</span></span></p></div><p>With TensorRT-LLM, it was important to serve the model on both Hopper and Blackwell architectures to support widely-available H100 GPUs and access the speed of B200 GPUs for our public model APIs.</p><p>One key tenet of the Baseten Inference Runtime is flexibility. This is especially useful when serving new models with novel architectures. Navigating, and when necessary updating, the support matrix across the entire stack requires the ability to swap between tools quickly.</p><h2 id="step-2-fixing-compatibility-bugs">Step 2: Fixing compatibility bugs</h2><p>Whenever a new model architecture is released, there will be subtle bugs and issues when integrating it into existing frameworks. The GPT OSS release added multiple new technologies, including <a href="https://cookbook.openai.com/articles/openai-harmony">Harmony</a>, a new response format.</p><div><p>✕</p><p><img alt="Romain Huet of OpenAI warns that implementation details affect performance and output quality." draggable="false" loading="lazy" width="1200" height="527" decoding="async" data-nimg="1" sizes="100vw" srcset="https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1754532411-screenshot-2025-08-06-at-5-04-16-pm.png%3Fauto%3Dformat%26w%3D1200&amp;w=640&amp;q=75 640w, https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1754532411-screenshot-2025-08-06-at-5-04-16-pm.png%3Fauto%3Dformat%26w%3D1200&amp;w=750&amp;q=75 750w, https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1754532411-screenshot-2025-08-06-at-5-04-16-pm.png%3Fauto%3Dformat%26w%3D1200&amp;w=828&amp;q=75 828w, https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1754532411-screenshot-2025-08-06-at-5-04-16-pm.png%3Fauto%3Dformat%26w%3D1200&amp;w=1080&amp;q=75 1080w, https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1754532411-screenshot-2025-08-06-at-5-04-16-pm.png%3Fauto%3Dformat%26w%3D1200&amp;w=1200&amp;q=75 1200w, https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1754532411-screenshot-2025-08-06-at-5-04-16-pm.png%3Fauto%3Dformat%26w%3D1200&amp;w=1920&amp;q=75 1920w, https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1754532411-screenshot-2025-08-06-at-5-04-16-pm.png%3Fauto%3Dformat%26w%3D1200&amp;w=2048&amp;q=75 2048w, https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1754532411-screenshot-2025-08-06-at-5-04-16-pm.png%3Fauto%3Dformat%26w%3D1200&amp;w=3840&amp;q=75 3840w" src="https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1754532411-screenshot-2025-08-06-at-5-04-16-pm.png%3Fauto%3Dformat%26w%3D1200&amp;w=3840&amp;q=75"><span><span>Romain Huet of OpenAI warns that implementation details affect performance and output quality.</span></span></p></div><p>A large part of our engineering work was iteratively fixing bugs and testing models for both speed and correctness. Where we could, we <a href="https://github.com/openai/harmony/pull/13">contributed back to open source</a> with the fixes that worked for us.</p><p>Thanks to the hard work of open source maintainers worldwide, there are multiple excellent options for running GPT OSS, and bugs are getting identified and fixed quickly.</p><h2 id="step-3-optimizing-model-configuration">Step 3: Optimizing model configuration</h2><p>While OpenAI advertises that GPT OSS 120B can be run on a single H100 GPU, optimized deployments parallelize the model across 4 or 8 GPUs for improved performance and throughput. There are two parallelism approaches worth considering for this model: Tensor Parallelism and Expert Parallelism.</p><div><p>✕</p><p><img alt="Tensor Parallelism vs Expert Parallelism for mixture of experts models" draggable="false" loading="lazy" width="1200" height="773" decoding="async" data-nimg="1" sizes="100vw" srcset="https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1752686946-diagram-4-2.png%3Fauto%3Dformat%26w%3D1200&amp;w=640&amp;q=75 640w, https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1752686946-diagram-4-2.png%3Fauto%3Dformat%26w%3D1200&amp;w=750&amp;q=75 750w, https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1752686946-diagram-4-2.png%3Fauto%3Dformat%26w%3D1200&amp;w=828&amp;q=75 828w, https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1752686946-diagram-4-2.png%3Fauto%3Dformat%26w%3D1200&amp;w=1080&amp;q=75 1080w, https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1752686946-diagram-4-2.png%3Fauto%3Dformat%26w%3D1200&amp;w=1200&amp;q=75 1200w, https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1752686946-diagram-4-2.png%3Fauto%3Dformat%26w%3D1200&amp;w=1920&amp;q=75 1920w, https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1752686946-diagram-4-2.png%3Fauto%3Dformat%26w%3D1200&amp;w=2048&amp;q=75 2048w, https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1752686946-diagram-4-2.png%3Fauto%3Dformat%26w%3D1200&amp;w=3840&amp;q=75 3840w" src="https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1752686946-diagram-4-2.png%3Fauto%3Dformat%26w%3D1200&amp;w=3840&amp;q=75"><span><span>Tensor Parallelism vs Expert Parallelism for mixture of experts models</span></span></p></div><p>We found that Tensor Parallelism offered better latency, while Expert Parallelism offered better system throughput. As we are prioritizing latency, we selected Tensor Parallelism.</p><p>Additionally, we adopted the TensorRT-LLM MoE Backend, which is supported on Blackwell but not Hopper. This backend adds improved CUDA kernels that outperform the previous Triton backend. For more details on server configuration, see <a href="https://github.com/NVIDIA/TensorRT-LLM/blob/main/docs/source/blogs/tech_blog/blog9_Deploying_GPT_OSS_on_TRTLLM.md">NVIDIA’s TensorRT-LLM documentation for GPT OSS optimization</a>.</p><p>We packaged our preferred configuration for Hopper GPUs for the <a href="https://github.com/basetenlabs/truss-examples/blob/main/openai/gpt-oss-120b/config.yaml">120B</a> and <a href="https://github.com/basetenlabs/truss-examples/blob/main/openai/gpt-oss-20b/config.yaml">20B</a> models for dedicated deployments in our model library, and used Blackwell for our Model API.</p><div><p>✕</p><p><img alt="GPT OSS 120B Model API on Baseten, optimized for performance with full context window support" draggable="false" loading="lazy" width="1200" height="377" decoding="async" data-nimg="1" sizes="100vw" srcset="https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1754532484-screenshot-2025-08-06-at-5-11-41-pm.png%3Fauto%3Dformat%26w%3D1200&amp;w=640&amp;q=75 640w, https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1754532484-screenshot-2025-08-06-at-5-11-41-pm.png%3Fauto%3Dformat%26w%3D1200&amp;w=750&amp;q=75 750w, https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1754532484-screenshot-2025-08-06-at-5-11-41-pm.png%3Fauto%3Dformat%26w%3D1200&amp;w=828&amp;q=75 828w, https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1754532484-screenshot-2025-08-06-at-5-11-41-pm.png%3Fauto%3Dformat%26w%3D1200&amp;w=1080&amp;q=75 1080w, https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1754532484-screenshot-2025-08-06-at-5-11-41-pm.png%3Fauto%3Dformat%26w%3D1200&amp;w=1200&amp;q=75 1200w, https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1754532484-screenshot-2025-08-06-at-5-11-41-pm.png%3Fauto%3Dformat%26w%3D1200&amp;w=1920&amp;q=75 1920w, https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1754532484-screenshot-2025-08-06-at-5-11-41-pm.png%3Fauto%3Dformat%26w%3D1200&amp;w=2048&amp;q=75 2048w, https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1754532484-screenshot-2025-08-06-at-5-11-41-pm.png%3Fauto%3Dformat%26w%3D1200&amp;w=3840&amp;q=75 3840w" src="https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1754532484-screenshot-2025-08-06-at-5-11-41-pm.png%3Fauto%3Dformat%26w%3D1200&amp;w=3840&amp;q=75"><span><span>GPT OSS 120B Model API on Baseten, optimized for performance with full context window support</span></span></p></div><h2 id="next-steps-in-performance-optimization">Next steps in performance optimization</h2><p>These first-pass performance improvements achieved SOTA latency and throughput, but there is a lot more headroom to improve performance on GPT OSS 120B.</p><p>One exciting update we’re working on is adding speculative decoding. Speculative decoding uses a smaller “draft” model to guess at future tokens, which are then validated by the target model. We’re big fans of Eagle 3 for speculation, but our inference stack supports 10+ algorithms to ensure that we can pick the right fit for each model and workload.</p><div><p>✕</p><p><img alt="Speculative decoding accelerates inference by generating multiple tokens per forward pass" draggable="false" loading="lazy" width="1200" height="542" decoding="async" data-nimg="1" sizes="100vw" srcset="https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1754532511-specdecnew.png%3Fauto%3Dformat%26w%3D1200&amp;w=640&amp;q=75 640w, https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1754532511-specdecnew.png%3Fauto%3Dformat%26w%3D1200&amp;w=750&amp;q=75 750w, https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1754532511-specdecnew.png%3Fauto%3Dformat%26w%3D1200&amp;w=828&amp;q=75 828w, https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1754532511-specdecnew.png%3Fauto%3Dformat%26w%3D1200&amp;w=1080&amp;q=75 1080w, https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1754532511-specdecnew.png%3Fauto%3Dformat%26w%3D1200&amp;w=1200&amp;q=75 1200w, https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1754532511-specdecnew.png%3Fauto%3Dformat%26w%3D1200&amp;w=1920&amp;q=75 1920w, https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1754532511-specdecnew.png%3Fauto%3Dformat%26w%3D1200&amp;w=2048&amp;q=75 2048w, https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1754532511-specdecnew.png%3Fauto%3Dformat%26w%3D1200&amp;w=3840&amp;q=75 3840w" src="https://www.baseten.co/_next/image/?url=https%3A%2F%2Fwww.datocms-assets.com%2F104802%2F1754532511-specdecnew.png%3Fauto%3Dformat%26w%3D1200&amp;w=3840&amp;q=75"><span><span>Speculative decoding accelerates inference by generating multiple tokens per forward pass</span></span></p></div><p>If this kind of performance optimization work sounds exciting to you, we’re <a href="https://www.baseten.co/resources/careers/">actively hiring for model performance engineers</a>. But for most AI engineering teams, this kind of performance optimization work shouldn’t stand in the way of testing new models in your product. Whether you’re looking for <a href="https://www.baseten.co/library/gpt-oss-120b/">GPT OSS 120B</a> or any open-source or custom model, <a href="https://www.baseten.co/talk-to-us/">get in touch with us</a> for help optimizing your latency and throughput!</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mac history echoes in current Mac operating systems (133 pts)]]></title>
            <link>http://tenfourfox.blogspot.com/2025/08/mac-history-echoes-in-mac-operating.html</link>
            <guid>44819962</guid>
            <pubDate>Thu, 07 Aug 2025 02:27:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://tenfourfox.blogspot.com/2025/08/mac-history-echoes-in-mac-operating.html">http://tenfourfox.blogspot.com/2025/08/mac-history-echoes-in-mac-operating.html</a>, See on <a href="https://news.ycombinator.com/item?id=44819962">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-body-9184177753103360477" itemprop="description articleBody">
<p><a href="https://arstechnica.com/gadgets/2025/08/rip-to-the-macintosh-hd-hard-drive-icon-2000-2025/">Ars Technica mentioned</a> that in <a href="http://tenfourfox.blogspot.com/2025/06/macos-tahoe.html">macOS Tahoe</a> the venerable old hard disk icons will be replaced with new, more generic, relatively less interesting equivalents. This process also apparently happens with Apple CEOs from time to time. If you are on Sequoia and want to keep them for posterity, you can get them out of </p><tt>/System/Library/Extensions/IOStorageFamily.kext/Contents/Resources</tt><p>. I'm still impressed to this day that someone not only took the time to write actually plausible text copy for the label, but also gave it Torx screws. Get out your T8 MacCracker for this drive:

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj6sFx-YfsvZs1T1yp7crjQsQrZEpxaJUNZ7JzrCCjMqwQ9Du3x8y2l_JoKvuBjbOboBITj2fB-92P54wZ0OrsBoMKiX95A0ledQpacxwFOACnnbVH6h_pMNjIXnugDjMAOfIEuJ01Bv7N3y5DAsxeBjbHzVzw4MGCGCmEPRvSGNqzIQQbwQHaeltupp5Dt/s1024/Internal.png"><img alt="" data-original-height="1024" data-original-width="1024" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj6sFx-YfsvZs1T1yp7crjQsQrZEpxaJUNZ7JzrCCjMqwQ9Du3x8y2l_JoKvuBjbOboBITj2fB-92P54wZ0OrsBoMKiX95A0ledQpacxwFOACnnbVH6h_pMNjIXnugDjMAOfIEuJ01Bv7N3y5DAsxeBjbHzVzw4MGCGCmEPRvSGNqzIQQbwQHaeltupp5Dt/s320/Internal.png" width="320"></a></p><p>

This isn't the only echo of Macs past in the operating system. <a href="https://www.spacebar.news/apple-history-hiding-in-mac-font/">The Spacebar</a> also noticed that Apple Symbols still has many old, nay, "obsolete" icons that are only of use to people who still use web browsers on Power Macs.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEieADu0-wXBMQH_W9_gsTQ5D24EcpCBQbB4w0hF4NzWhsOMpQFZW1EoRvyw0x3BVgmKhQmyn1YLg3VXKYe9_fnQr_zC1tZiNtYQEC05UabQbf14KtzwlDsAmgADTqlSa_oxQMvV-DE_j0238oz-_-3sAwAvnV1Bgtb9VZ3H9Dg3AMRT7wOdmVu8hiyKuOno/s3552/Screenshot%202025-08-06%20at%205.44.43%E2%80%AFPM.png"><img alt="" data-original-height="2130" data-original-width="3552" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEieADu0-wXBMQH_W9_gsTQ5D24EcpCBQbB4w0hF4NzWhsOMpQFZW1EoRvyw0x3BVgmKhQmyn1YLg3VXKYe9_fnQr_zC1tZiNtYQEC05UabQbf14KtzwlDsAmgADTqlSa_oxQMvV-DE_j0238oz-_-3sAwAvnV1Bgtb9VZ3H9Dg3AMRT7wOdmVu8hiyKuOno/s320/Screenshot%202025-08-06%20at%205.44.43%E2%80%AFPM.png" width="320"></a></p><p>

That's not the half of it, though. There's a bunch more in that file than the ones he spotted. Here's what I saw; perhaps you can find more.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEisfewYuIj0Id6WTojGA6X6qYfPwz4-aa99S91PZViF4FnVlAEkd1aeAgaTlW_JchYMPtnOa6Mi8R5HGQwlgk1nnqFxBBsLpt_5_ZFkTASDzKJW6LN0Rp-HcJ6fQyGQO_BL2_WBPfWnNL7eVcJyzzeZCUAi8l87ReZ8jeFI-nt6DRVYvM3cTqN9Lwv_8sLg/s2000/charsheet.png"><img alt="" data-original-height="801" data-original-width="2000" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEisfewYuIj0Id6WTojGA6X6qYfPwz4-aa99S91PZViF4FnVlAEkd1aeAgaTlW_JchYMPtnOa6Mi8R5HGQwlgk1nnqFxBBsLpt_5_ZFkTASDzKJW6LN0Rp-HcJ6fQyGQO_BL2_WBPfWnNL7eVcJyzzeZCUAi8l87ReZ8jeFI-nt6DRVYvM3cTqN9Lwv_8sLg/s320/charsheet.png" width="320"></a></p><p>

In order: PowerPC logo, composite video out and in, S-video out and in (such as seen on some later PowerBooks), modem port, combined modem/printer port (like on the Duo 2300), printer port, SCSI, Ethernet (also AAUI), three glyphs for Apple Desktop Bus (ADB) ports, a server, rainbow outline Apple, Balloon Help (from System 7), Apple Guide (7.5), 5.25" floppy (I guess mostly for the Apple II folks), two Newton lightbulbs, Newton undo, Newton extras, Newton dates, Newton names, high-density 3.5" disk icon, a confused Compact Mac (possibly to evoke the flashing question mark when it can't find a bootable volume), classic QuickTime logo, busy watch, Apple Pro Speakers port (such as on the iMac G4 or the MDD G4), FireWire, programmer's key icon, and two versions of the reset icon, though these three do have Unicode equivalents or you can also use regular geometric shapes, and sometimes those faced the other way.
</p><p>
(A note on most of these characters is that they don't actually map to any defined Unicode code point; they are unconnected glyphs. Font Book will show them but you can't really copy them anywhere. A tool like Ultra Character Map will let you at least grab a graphical representation and paste it somewhere, as I have done here.)
</p><p>
But that's not all! Feast your eyes on what's still in <tt>/System/Library/CoreServices/CoreTypes.bundle/Contents/Resources</tt>!
</p><p>
<a name="more"></a>
What's particularly impressive is the <em>multiple sizes</em> for systems with differently sized screens as options. These are taken from the 1024x1024 144dpi retina versions in Sequoia.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhj3Cp4pdajMnRygAVpqSAeOm17UnEmh07WqX_quEAO5TfG5E5jz-Fw2VcBlEO4odhNj2LjWlXxUDSsvwfPBvastaKvPUn5ShHoqz8ZoL0Phw_hM5A4R_a3yA5bksLHC989DDedszUt13GrCa1iSUaop8qkEPjz6u61gHDKXbW4balfdeN2W7zUpIgjr4Qb/s1024/01.png"><img alt="" data-original-height="1024" data-original-width="1024" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhj3Cp4pdajMnRygAVpqSAeOm17UnEmh07WqX_quEAO5TfG5E5jz-Fw2VcBlEO4odhNj2LjWlXxUDSsvwfPBvastaKvPUn5ShHoqz8ZoL0Phw_hM5A4R_a3yA5bksLHC989DDedszUt13GrCa1iSUaop8qkEPjz6u61gHDKXbW4balfdeN2W7zUpIgjr4Qb/s320/01.png" width="320"></a></p><p>

eMac,

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi9FDXgrJbykjqy-O4VeaWYPSBlStuSRsNTZPOyevVoS9EmAGHzHoByH4CAZHUqENGNXnZTMXKqK9NZqvfSc1PEpIF_SYFPGsqwOv29cY92anQ43NnHeXZq2UP_Of4fJ7kRhKtNzS-mJbTkMlSsyfr8jtKmIDYXLRsfs0AaonieLgaj94LEF-q6A-gJjdO0/s1024/02.png"><img alt="" data-original-height="1024" data-original-width="1024" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi9FDXgrJbykjqy-O4VeaWYPSBlStuSRsNTZPOyevVoS9EmAGHzHoByH4CAZHUqENGNXnZTMXKqK9NZqvfSc1PEpIF_SYFPGsqwOv29cY92anQ43NnHeXZq2UP_Of4fJ7kRhKtNzS-mJbTkMlSsyfr8jtKmIDYXLRsfs0AaonieLgaj94LEF-q6A-gJjdO0/s320/02.png" width="320"></a></p>
<p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj1bHUGrS0Gca3bP767GMF3VZWlfYCvRfR-hnV26KiWeJNO-vF4Ym9f4S7hdNWV3CC1CfCbjCFotGpC4lYKKqkrRif8ydbcX5-n-yx_3JzxDZs7G8QyHB2NWZqQN9bUBnDAlgf0Zlgoi_VoEByKwe8ulMTujrPuhXaLTyZRn8nKYtQyMJ9aT6mV3EHBG0ia/s1024/03.png"><img alt="" data-original-height="1024" data-original-width="1024" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj1bHUGrS0Gca3bP767GMF3VZWlfYCvRfR-hnV26KiWeJNO-vF4Ym9f4S7hdNWV3CC1CfCbjCFotGpC4lYKKqkrRif8ydbcX5-n-yx_3JzxDZs7G8QyHB2NWZqQN9bUBnDAlgf0Zlgoi_VoEByKwe8ulMTujrPuhXaLTyZRn8nKYtQyMJ9aT6mV3EHBG0ia/s320/03.png" width="320"></a></p><p>

iBook G4 12" and 14",

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjoqDFJfwLk_I1fgcwSni3sBJGq3LCyJ-TarFbnlwfbj3ZeC0oOIZtxit576AXVie8zdEi1SPnCD0g0Q1L2999N0pdaWzuwnzU4TDIfCEjntiJrfG5T0AJjzcG7LfVEynDph4ljbqwsQWvjMKAAT-NbxqOiSDiV-d6DrwYKZiWMTOx-_vP4Sdi_OtefPKBz/s1024/04.png"><img alt="" data-original-height="1024" data-original-width="1024" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjoqDFJfwLk_I1fgcwSni3sBJGq3LCyJ-TarFbnlwfbj3ZeC0oOIZtxit576AXVie8zdEi1SPnCD0g0Q1L2999N0pdaWzuwnzU4TDIfCEjntiJrfG5T0AJjzcG7LfVEynDph4ljbqwsQWvjMKAAT-NbxqOiSDiV-d6DrwYKZiWMTOx-_vP4Sdi_OtefPKBz/s320/04.png" width="320"></a></p>
<p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgMTJUl264hArRxcO05B0fTwqzJXqoF_BwEk7Ph7ruDchM-clv1kD3m9087WW9skX9Nd9qCIAxjfkkeoQuyh3hlcuwckRRmF087jbrsi5oJ11Xn9o6-Ax3KpIfoztefMzTCVBPaTD0PU3s4nYj5NuzEnivrWjCCc78HiADiRCH6w5SXjs2ztpxmbSPCarLN/s1024/05.png"><img alt="" data-original-height="1024" data-original-width="1024" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgMTJUl264hArRxcO05B0fTwqzJXqoF_BwEk7Ph7ruDchM-clv1kD3m9087WW9skX9Nd9qCIAxjfkkeoQuyh3hlcuwckRRmF087jbrsi5oJ11Xn9o6-Ax3KpIfoztefMzTCVBPaTD0PU3s4nYj5NuzEnivrWjCCc78HiADiRCH6w5SXjs2ztpxmbSPCarLN/s320/05.png" width="320"></a></p>
<p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgH5tBuloGLh75tYnfeA-_AXwOjpvBi8ztLbf1nEm6Y4EGMNVdd-rC1bu5_YPdlpSdzwssLvS0oNXubuP7iNIQqCfyVPMSSVgfldRkP9QEcDsjM6c8wqT8Kat8hIwvySmxST1ox3qhEsyM-KiImRnSpoNFSoYthJw2e6m0svHb45fzd9R8MQFlCBLtzlC3Z/s1024/06.png"><img alt="" data-original-height="1024" data-original-width="1024" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgH5tBuloGLh75tYnfeA-_AXwOjpvBi8ztLbf1nEm6Y4EGMNVdd-rC1bu5_YPdlpSdzwssLvS0oNXubuP7iNIQqCfyVPMSSVgfldRkP9QEcDsjM6c8wqT8Kat8hIwvySmxST1ox3qhEsyM-KiImRnSpoNFSoYthJw2e6m0svHb45fzd9R8MQFlCBLtzlC3Z/s320/06.png" width="320"></a></p><p>

iMac G4 15" (my favourite because it doesn't wear out the arm), 17" and 20",

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh1hhS_RPA_31kFwOan2niCjnkUxH4P44f27pOIMgYw7lj-_mn_XLEy1O6LtmNnx5pZ_V1ZfOz7hx77cPPzGSvGpF-fEJ0YWNqDJTXVCDs2mRKWuIMJqvC1vT-nxIzVV0a43Kl32MF6Z7s_ARlYmEVsF0TpdSEq4Cc5rSJVypjkcma4zKfzATuHOobGRkFi/s1024/07.png"><img alt="" data-original-height="1024" data-original-width="1024" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh1hhS_RPA_31kFwOan2niCjnkUxH4P44f27pOIMgYw7lj-_mn_XLEy1O6LtmNnx5pZ_V1ZfOz7hx77cPPzGSvGpF-fEJ0YWNqDJTXVCDs2mRKWuIMJqvC1vT-nxIzVV0a43Kl32MF6Z7s_ARlYmEVsF0TpdSEq4Cc5rSJVypjkcma4zKfzATuHOobGRkFi/s320/07.png" width="320"></a></p>
<p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhfvZHKmsHYtXDn72hhzR_JHK2zgBpbGf9tVTPdW-MjcV9sGI7BNrjTsLsoq2pHK6cDTl2vBGKP3rLrBzQqw5jkDdfrNyfzhH56l-4F1W1DImV2KZtyRQOw6j6W-PsHYgx3WmPPMyqiv4oNAuaF9A3MEilcACgOG_i_EASjEdZlzz1yZErzB4uxnPYItbTm/s1024/08.png"><img alt="" data-original-height="1024" data-original-width="1024" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhfvZHKmsHYtXDn72hhzR_JHK2zgBpbGf9tVTPdW-MjcV9sGI7BNrjTsLsoq2pHK6cDTl2vBGKP3rLrBzQqw5jkDdfrNyfzhH56l-4F1W1DImV2KZtyRQOw6j6W-PsHYgx3WmPPMyqiv4oNAuaF9A3MEilcACgOG_i_EASjEdZlzz1yZErzB4uxnPYItbTm/s320/08.png" width="320"></a></p><p>

iMac G5 (recognizeable because no iSight) 17" and 20",

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjmW8-ijMYDzj0efl5Pc4DuwfmHsKW1gofe_td-LfS9W4O3RCwvlUU609VaUSWsGiUz7fz-rqcjVJw2hyXS9AdYXe51dgnvkgp9hTkqqZFgR_y2Geea6kJhZmAIqs4jb06yUSuzLOviXWhRWASwYp7Q1qkYe2hbjY8iCUlp4VCyvyEKEHkFrJPF1E0lDadG/s1024/09.png"><img alt="" data-original-height="1024" data-original-width="1024" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjmW8-ijMYDzj0efl5Pc4DuwfmHsKW1gofe_td-LfS9W4O3RCwvlUU609VaUSWsGiUz7fz-rqcjVJw2hyXS9AdYXe51dgnvkgp9hTkqqZFgR_y2Geea6kJhZmAIqs4jb06yUSuzLOviXWhRWASwYp7Q1qkYe2hbjY8iCUlp4VCyvyEKEHkFrJPF1E0lDadG/s320/09.png" width="320"></a></p>
<p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj_oscMOiGm-mhWtdcd4ithzOsID0yxxlAJKE2G0N_o18T9LlSLpKfshGcAOgJqPY1UHS4OGLzLBgEvXdz7NhnxQibPBbN8jKu3WhxLtsLYd5IAG-T0DzveQIyLX3UmtvEmDjOwJ_dyp2GIUYZukMnSDd-X-76J8hcGuEvfBrcE-_7QSa4I3ngWS1bC-9Ry/s1024/10.png"><img alt="" data-original-height="1024" data-original-width="1024" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj_oscMOiGm-mhWtdcd4ithzOsID0yxxlAJKE2G0N_o18T9LlSLpKfshGcAOgJqPY1UHS4OGLzLBgEvXdz7NhnxQibPBbN8jKu3WhxLtsLYd5IAG-T0DzveQIyLX3UmtvEmDjOwJ_dyp2GIUYZukMnSDd-X-76J8hcGuEvfBrcE-_7QSa4I3ngWS1bC-9Ry/s320/10.png" width="320"></a></p><p>

iPhone 2G and 3G (notice the subtly different chrome),

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgLuiUcd_re30nrBM6RPj579r4mnyQ8IBWhvFsKMWX5YMNa9kMN1nzmT2vr79-FRIARBSMffB2Jae2GaKw__k6f0tcMpl3uIQu1rg9_AzjwxmdGT1r18kTz39yi6l67wjsyAKcNd6CBAN2kSwpYepDDodJ4-bIwinymdzXiQu9_-W_tXVflKsSCu3gWIxh9/s1024/11.png"><img alt="" data-original-height="1024" data-original-width="1024" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgLuiUcd_re30nrBM6RPj579r4mnyQ8IBWhvFsKMWX5YMNa9kMN1nzmT2vr79-FRIARBSMffB2Jae2GaKw__k6f0tcMpl3uIQu1rg9_AzjwxmdGT1r18kTz39yi6l67wjsyAKcNd6CBAN2kSwpYepDDodJ4-bIwinymdzXiQu9_-W_tXVflKsSCu3gWIxh9/s320/11.png" width="320"></a></p><p>

Titanium PowerBook G4,

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjDRt2LgCbDdekO_b-X8ArZFq8QriMdQzDK2SJYPDB8eHDKZBQTQ9JoUavWp-MAWHl6rryoVC5EQfUllnzWPLOPvRS69wfoKpGZ9UHi2S1doI22RMci43qAX5wQSLpWE8c-RNdCYLG11P85Q43eVbXKM9S0X_aFumCJbyhXgncd7yYaI1sgyHlkjot_6iIv/s1024/12.png"><img alt="" data-original-height="1024" data-original-width="1024" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjDRt2LgCbDdekO_b-X8ArZFq8QriMdQzDK2SJYPDB8eHDKZBQTQ9JoUavWp-MAWHl6rryoVC5EQfUllnzWPLOPvRS69wfoKpGZ9UHi2S1doI22RMci43qAX5wQSLpWE8c-RNdCYLG11P85Q43eVbXKM9S0X_aFumCJbyhXgncd7yYaI1sgyHlkjot_6iIv/s320/12.png" width="320"></a></p>
<p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj8G5bjzpdXHu_i_ZKqlaHwXbARb6dfaHw_Ll0NccAHst_5IxrN3U_FEJeR4b1im4yhRZkpYUvyI3bxS_ydYGvERNO3qKQDi3AE0mCWn0kCGkLWsooT-0cub1_4jnYqZEPbNHLKmn7laMS2Oo1jVlD0xHtRcQaN3mnGzbEI3Jsf_6hIMxw4lEcfLbJ_GCm5/s1024/13.png"><img alt="" data-original-height="1024" data-original-width="1024" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj8G5bjzpdXHu_i_ZKqlaHwXbARb6dfaHw_Ll0NccAHst_5IxrN3U_FEJeR4b1im4yhRZkpYUvyI3bxS_ydYGvERNO3qKQDi3AE0mCWn0kCGkLWsooT-0cub1_4jnYqZEPbNHLKmn7laMS2Oo1jVlD0xHtRcQaN3mnGzbEI3Jsf_6hIMxw4lEcfLbJ_GCm5/s320/13.png" width="320"></a></p>
<p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEijgB9_iu8ks7N7-xER0N1LL6A5oKQ70XX-WkdBQkFl_ecoFx4mmmLDX8rYRGpRpKKvDKQTXaDPNdPFrrgObwHE4pCDUcYfcImKgdtKNrJaQpkALoXXpNum1eMdumwGaLGRnNO54dF-iobEgC_XKWzuJyQr32-f7RJiTXFLo0BPCnp3_l5znscY1oEfBQi7/s1024/14.png"><img alt="" data-original-height="1024" data-original-width="1024" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEijgB9_iu8ks7N7-xER0N1LL6A5oKQ70XX-WkdBQkFl_ecoFx4mmmLDX8rYRGpRpKKvDKQTXaDPNdPFrrgObwHE4pCDUcYfcImKgdtKNrJaQpkALoXXpNum1eMdumwGaLGRnNO54dF-iobEgC_XKWzuJyQr32-f7RJiTXFLo0BPCnp3_l5znscY1oEfBQi7/s320/14.png" width="320"></a></p><p>

Alumin(i)um PowerBook G4 12", 15" and 17" (with all-region DVD drive firmware it's the best portable DVD player you can get),

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhyR6owvS1nZqWr2j-6uesXQM5AcI_P5ByS4Jg-AD-54wZruvyjROJmStGP_yr_LyLf71hGX1uHO5OHXUZVUMC4PZ_e3HwHmZXIEblCqRXKxEcpLzoXA_Yr6f7MIxBnm1Ph-q-LEWJWzpzTAOgBpmAcIfIOhkH-70c1_Tj7wj5EPtagzC9hkktnHzAdQiIj/s1024/15.png"><img alt="" data-original-height="1024" data-original-width="1024" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhyR6owvS1nZqWr2j-6uesXQM5AcI_P5ByS4Jg-AD-54wZruvyjROJmStGP_yr_LyLf71hGX1uHO5OHXUZVUMC4PZ_e3HwHmZXIEblCqRXKxEcpLzoXA_Yr6f7MIxBnm1Ph-q-LEWJWzpzTAOgBpmAcIfIOhkH-70c1_Tj7wj5EPtagzC9hkktnHzAdQiIj/s320/15.png" width="320"></a></p><p>

"Graphite" Power Macintosh G4 (doesn't say if it's a Yikes!, Sawtooth or Gigabit Ethernet),

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjMMYR5XoGBUpIYbAKkBr3dFQKvW8UEvXdazdr1zjEmUXPrlWD_d1g-tmjLbJq1JTZDz26X7iagE-ufqGHg7i7JYYRBbUboSJTwEsIM7fgOKDRlqMN8J2J_saHtzNOTaCd_RERCbLDIf5FQr1ACmaiz9Az23DwuJ2EvqufJvG_h9ukkreIKOBBvHuHdQmuw/s1024/16.png"><img alt="" data-original-height="1024" data-original-width="1024" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjMMYR5XoGBUpIYbAKkBr3dFQKvW8UEvXdazdr1zjEmUXPrlWD_d1g-tmjLbJq1JTZDz26X7iagE-ufqGHg7i7JYYRBbUboSJTwEsIM7fgOKDRlqMN8J2J_saHtzNOTaCd_RERCbLDIf5FQr1ACmaiz9Az23DwuJ2EvqufJvG_h9ukkreIKOBBvHuHdQmuw/s320/16.png" width="320"></a></p><p>

"Quicksilver" Power Macintosh G4,

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhOKtzQVeljcbZlQB-vK6YNdEg1XvEHCdXb_Dzjn623rZSA8Q2_lMJ8qNkIB5_0V-LLZhSi_4WKTgihHXg51xfRHIu9YH9mq4O1TfG2K5qTzYBwqznhegMutspl0n4SChDz7srtgfCt4tmRhyphenhyphenux_OAht8ISoL-r3I4Vv2JYgyO0A_DjfJF92dd-4VMsaasy/s1024/17.png"><img alt="" data-original-height="1024" data-original-width="1024" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhOKtzQVeljcbZlQB-vK6YNdEg1XvEHCdXb_Dzjn623rZSA8Q2_lMJ8qNkIB5_0V-LLZhSi_4WKTgihHXg51xfRHIu9YH9mq4O1TfG2K5qTzYBwqznhegMutspl0n4SChDz7srtgfCt4tmRhyphenhyphenux_OAht8ISoL-r3I4Vv2JYgyO0A_DjfJF92dd-4VMsaasy/s320/17.png" width="320"></a></p><p>

"Mirrored Drive Doors" Power Macintosh G4, which looks nearly the same,

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjV0YQ-5sA9x_f3zUsJuacUQdzvrbv-LP4A0aNmLLyPIHiT4BmK_TxsuKVbF3aYsiBX6q_liJNwCXo-ajdGqPxRlDRgquRVC0y4Rpi4e4ImopRdubYTVUbdn3Qysvn1vGXvf8HijfmZKUKc8zxi9OqRv4LKOMjxSH849y8CwyL0BTg079H8JNj_OdzHKEJs/s1024/18.png"><img alt="" data-original-height="1024" data-original-width="1024" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjV0YQ-5sA9x_f3zUsJuacUQdzvrbv-LP4A0aNmLLyPIHiT4BmK_TxsuKVbF3aYsiBX6q_liJNwCXo-ajdGqPxRlDRgquRVC0y4Rpi4e4ImopRdubYTVUbdn3Qysvn1vGXvf8HijfmZKUKc8zxi9OqRv4LKOMjxSH849y8CwyL0BTg079H8JNj_OdzHKEJs/s320/18.png" width="320"></a></p><p>

Xserve G4,

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjLhzzRm3pjz25jYjJCDjrB2BWCksK2DJcXsaUsNblNXWSNMZJriZiX-HghfPqJGxEtYiLLcEAC661LJ7Al7tnlLxZm57G3LG1munGvfvaKPfyPvJQdLcXB6XgicQu_qj_BO9VZSwW-O_HlxhzvVeMQb4i4gll_ribTdunLRQE5hNDPANwcH4pF4jS-hqet/s1024/18a.png"><img alt="" data-original-height="1024" data-original-width="1024" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjLhzzRm3pjz25jYjJCDjrB2BWCksK2DJcXsaUsNblNXWSNMZJriZiX-HghfPqJGxEtYiLLcEAC661LJ7Al7tnlLxZm57G3LG1munGvfvaKPfyPvJQdLcXB6XgicQu_qj_BO9VZSwW-O_HlxhzvVeMQb4i4gll_ribTdunLRQE5hNDPANwcH4pF4jS-hqet/s320/18a.png" width="320"></a></p><p>

early Mac mini (we'll call it a G4, since we can't see the back),

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhYvQTWRgdHtSEtdrIqxIHtu2cxXiEsMF70YMHJQVDDTDwSP1ReuJmKL-Bya6lE8xPE9BUR0hz_QZ7CEJACnPZo337zey5sGdQSNYn-OS9aX6uymB7hTyUWTqHmzb5mCYORZOabm_RBZaU0zd31A1XAquNQReIFhrLjGv7BggpjlnOwd1g9D3tRvmWn_Pr0/s1024/19.png"><img alt="" data-original-height="1024" data-original-width="1024" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhYvQTWRgdHtSEtdrIqxIHtu2cxXiEsMF70YMHJQVDDTDwSP1ReuJmKL-Bya6lE8xPE9BUR0hz_QZ7CEJACnPZo337zey5sGdQSNYn-OS9aX6uymB7hTyUWTqHmzb5mCYORZOabm_RBZaU0zd31A1XAquNQReIFhrLjGv7BggpjlnOwd1g9D3tRvmWn_Pr0/s320/19.png" width="320"></a></p><p>

and who let this thing in?
</p><p>
Why are all these things still in the macOS? My guess, modulo the Blue Screen PC, is trademark purposes.<i>[A number of people have suggested for network serves; some servers will identify themselves as specific computers, which will pick up an icon in this group, and of course the Windows PC for this purpose is well-known. Fine, except that this archive isn't comprehensive for all the possible Mac models that could have participated as a network share point: no G3s, for example, and no Power Mac G5.]</i> These all were used as Apple-specific labeling and could be considered as part of their trade dress, and having these legacy items still in the macOS probably serves some legal purpose if someone were to try to rip off their old IP. It can't be for nostalgia purposes or we'd still be able to run Carbon PowerPC apps on Tahoe like you can still run most Win32 applications on Windows 11. And Apple just doesn't <em>do</em> nostalgia — except in their ads.
</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[We replaced passwords with something worse (789 pts)]]></title>
            <link>https://blog.danielh.cc/blog/passwords</link>
            <guid>44819917</guid>
            <pubDate>Thu, 07 Aug 2025 02:19:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.danielh.cc/blog/passwords">https://blog.danielh.cc/blog/passwords</a>, See on <a href="https://news.ycombinator.com/item?id=44819917">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-v-39a288b8=""><p>Too many services have been using the following login method:</p><ul><li>Enter an email address or phone number</li><li>The website will send a 6-digit code</li><li>Use the 6-digit code to log in</li></ul><p>Please stop.</p><p>This is terrible for account security:</p><ul><li>An attacker can simply send your email address to a legitimate service, and prompt for a 6-digit code. You can't know for sure if the code is supposed to be entered in the right place. Password managers (a usual defense against phishing) can't help you either.</li><li>In fact, this attack method has been successfully used in the wild: Microsoft's login for Minecraft accounts use this login method, and <a href="https://www.reddit.com/r/hypixel/comments/1l7h2be/account_verification_scam_help_me_if_you_can/" target="_blank" rel="noreferrer">many</a> <a href="https://www.reddit.com/r/Minecraft/comments/1ell43o/microsoft_account_discord_verification_scam_and/" target="_blank" rel="noreferrer">accounts</a> <a href="https://www.youtube.com/watch?v=QXHGFXq28oQ" target="_blank" rel="noreferrer">have</a> <a href="https://learn.microsoft.com/en-us/answers/questions/5493482/i-fell-to-a-phishing-scam-on-discord-how-i-get-my" target="_blank" rel="noreferrer">been</a> <a href="https://www.youtube.com/watch?v=qWwU9uK2b3I" target="_blank" rel="noreferrer">stolen</a> already.</li></ul></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A candidate giant planet imaged in the habitable zone of α  Cen A (109 pts)]]></title>
            <link>https://arxiv.org/abs/2508.03814</link>
            <guid>44819738</guid>
            <pubDate>Thu, 07 Aug 2025 01:42:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2508.03814">https://arxiv.org/abs/2508.03814</a>, See on <a href="https://news.ycombinator.com/item?id=44819738">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
    <div><p><span>Authors:</span><a href="https://arxiv.org/search/astro-ph?searchtype=author&amp;query=Beichman,+C" rel="nofollow">Charles Beichman</a>, <a href="https://arxiv.org/search/astro-ph?searchtype=author&amp;query=Sanghi,+A" rel="nofollow">Aniket Sanghi</a>, <a href="https://arxiv.org/search/astro-ph?searchtype=author&amp;query=Mawet,+D" rel="nofollow">Dimitri Mawet</a>, <a href="https://arxiv.org/search/astro-ph?searchtype=author&amp;query=Kervella,+P" rel="nofollow">Pierre Kervella</a>, <a href="https://arxiv.org/search/astro-ph?searchtype=author&amp;query=Wagner,+K" rel="nofollow">Kevin Wagner</a>, <a href="https://arxiv.org/search/astro-ph?searchtype=author&amp;query=Quarles,+B" rel="nofollow">Billy Quarles</a>, <a href="https://arxiv.org/search/astro-ph?searchtype=author&amp;query=Lissauer,+J+J" rel="nofollow">Jack J. Lissauer</a>, <a href="https://arxiv.org/search/astro-ph?searchtype=author&amp;query=Sommer,+M" rel="nofollow">Max Sommer</a>, <a href="https://arxiv.org/search/astro-ph?searchtype=author&amp;query=Wyatt,+M" rel="nofollow">Mark Wyatt</a>, <a href="https://arxiv.org/search/astro-ph?searchtype=author&amp;query=Godoy,+N" rel="nofollow">Nicolas Godoy</a>, <a href="https://arxiv.org/search/astro-ph?searchtype=author&amp;query=Balmer,+W+O" rel="nofollow">William O. Balmer</a>, <a href="https://arxiv.org/search/astro-ph?searchtype=author&amp;query=Pueyo,+L" rel="nofollow">Laurent Pueyo</a>, <a href="https://arxiv.org/search/astro-ph?searchtype=author&amp;query=Llop-Sayson,+J" rel="nofollow">Jorge Llop-Sayson</a>, <a href="https://arxiv.org/search/astro-ph?searchtype=author&amp;query=Aguilar,+J" rel="nofollow">Jonathan Aguilar</a>, <a href="https://arxiv.org/search/astro-ph?searchtype=author&amp;query=Akeson,+R" rel="nofollow">Rachel Akeson</a>, <a href="https://arxiv.org/search/astro-ph?searchtype=author&amp;query=Belikov,+R" rel="nofollow">Ruslan Belikov</a>, <a href="https://arxiv.org/search/astro-ph?searchtype=author&amp;query=Boccaletti,+A" rel="nofollow">Anthony Boccaletti</a>, <a href="https://arxiv.org/search/astro-ph?searchtype=author&amp;query=Choquet,+E" rel="nofollow">Elodie Choquet</a>, <a href="https://arxiv.org/search/astro-ph?searchtype=author&amp;query=Fomalont,+E" rel="nofollow">Edward Fomalont</a>, <a href="https://arxiv.org/search/astro-ph?searchtype=author&amp;query=Henning,+T" rel="nofollow">Thomas Henning</a>, <a href="https://arxiv.org/search/astro-ph?searchtype=author&amp;query=Hines,+D" rel="nofollow">Dean Hines</a>, <a href="https://arxiv.org/search/astro-ph?searchtype=author&amp;query=Hu,+R" rel="nofollow">Renyu Hu</a>, <a href="https://arxiv.org/search/astro-ph?searchtype=author&amp;query=Lagage,+P" rel="nofollow">Pierre-Olivier Lagage</a>, <a href="https://arxiv.org/search/astro-ph?searchtype=author&amp;query=Leisenring,+J" rel="nofollow">Jarron Leisenring</a>, <a href="https://arxiv.org/search/astro-ph?searchtype=author&amp;query=Mang,+J" rel="nofollow">James Mang</a>, <a href="https://arxiv.org/search/astro-ph?searchtype=author&amp;query=Ressler,+M" rel="nofollow">Michael Ressler</a>, <a href="https://arxiv.org/search/astro-ph?searchtype=author&amp;query=Serabyn,+E" rel="nofollow">Eugene Serabyn</a>, <a href="https://arxiv.org/search/astro-ph?searchtype=author&amp;query=Tremblin,+P" rel="nofollow">Pascal Tremblin</a>, <a href="https://arxiv.org/search/astro-ph?searchtype=author&amp;query=Ygouf,+M" rel="nofollow">Marie Ygouf</a>, <a href="https://arxiv.org/search/astro-ph?searchtype=author&amp;query=Zilinskas,+M" rel="nofollow">Mantas Zilinskas</a></p></div>            
    <p><a href="https://arxiv.org/pdf/2508.03814">View PDF</a>
    <a href="https://arxiv.org/html/2508.03814v1">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>We report on coronagraphic observations of the nearest solar-type star, $\alpha$ Cen A, using the MIRI instrument on the James Webb Space Telescope. With three epochs of observation (August 2024, February 2025, and April 2025), we achieve a sensitivity sufficient to detect $T_{\rm eff}\approx$ 225-250 K (1-1.2 $R_{\rm Jup}$) planets between 1"-2" and exozodiacal dust emission at the level of $&gt;$5-8$\times$ the brightness of our own zodiacal cloud. The lack of exozodiacal dust emission sets an unprecedented limit of a few times the brightness of our own zodiacal cloud$-$a factor of $\gtrsim$10 more sensitive than measured toward any other stellar system to date. In August 2024, we detected a F$_\nu$(15.5 $\mu$m) = 3.5 mJy point source, called $S1$, at a separation of 1.5" from $\alpha$ Cen A. Because the August 2024 epoch had only one successful observation at a single roll angle, it is not possible to unambiguously confirm $S1$ as a bona fide planet. Our analysis confirms that $S1$ is neither a background nor a foreground object. $S1$ is not recovered in the February and April 2025 epochs. However, if $S1$ is the counterpart of the object, $C1$, seen by the VLT/NEAR program in 2019, we find that there is a 52% chance that the $S1+C1$ candidate was missed in both follow-up JWST/MIRI observations due to orbital motion. Incorporating constraints from the non-detections, we obtain families of dynamically stable orbits for $S1+C1$ with periods between 2-3 years. These suggest that the planet candidate is on an eccentric ($e \approx 0.4$) orbit significantly inclined with respect to $\alpha$ Cen AB orbital plane ($i_{\rm mutual} \approx 50^\circ$, or $\approx 130^\circ$). Based on the photometry and orbital properties, the planet candidate could have a temperature of 225 K, a radius of $\approx$1-1.1 $R_{\rm Jup}$ and a mass between 90-150 $M_{\rm Earth}$, consistent with RV limits.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Aniket Sanghi [<a href="https://arxiv.org/show-email/3e1f4f56/2508.03814" rel="nofollow">view email</a>]      <br>    <strong>[v1]</strong>
        Tue, 5 Aug 2025 18:01:46 UTC (10,437 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Rules by which a great empire may be reduced to a small one (1773) (244 pts)]]></title>
            <link>https://founders.archives.gov/documents/Franklin/01-20-02-0213</link>
            <guid>44819037</guid>
            <pubDate>Wed, 06 Aug 2025 23:29:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://founders.archives.gov/documents/Franklin/01-20-02-0213">https://founders.archives.gov/documents/Franklin/01-20-02-0213</a>, See on <a href="https://news.ycombinator.com/item?id=44819037">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="doc"><a id="main_content"></a><header id="doc_title"></header><div id="doc_text">

<h2>Rules by Which a Great Empire May Be Reduced to a Small One</h2>
<p>Printed in <span>The Public Advertiser</span>, September 11, 1773; incomplete draft and notes:<a id="BNFN-01-20-02-0213-fn-0001-ptr" href="#BNFN-01-20-02-0213-fn-0001" title="jump to note 6">6</a> American Philosophical Society</p>
<div>
<p>Franklin was pleased with this satire, which was a companion piece to “An Edict by the King of Prussia.”<a id="BNFN-01-20-02-0213-fn-0002-ptr" href="#BNFN-01-20-02-0213-fn-0002" title="jump to note 7">7</a> Both had the virtues, he believed, <a id="BNFN-01-20-02-pb-0390"></a>of brevity, comprehensiveness, and “out-of-the-way forms” that caught attention; but he preferred the “Rules” to the “Edict” for the breadth and variety of its contents and for “a kind of spirited ending of each paragraph.”<a id="BNFN-01-20-02-0213-fn-0003-ptr" href="#BNFN-01-20-02-0213-fn-0003" title="jump to note 8">8</a> His technique in the two was different: in this one he challenged his readers to see their government’s policy through colonial eyes; in the “Edict” he jolted them with the fiction that they were colonists themselves. The two essays had a single purpose, to induce the public to take a fresh look at the American problem. When Parliament reconvened in the autumn, that problem promised to be a major subject of discussion; and the sensational demand from Massachusetts for the removal of Hutchinson and Oliver was sure, when it came before the Privy Council, to provoke a storm. Moderate counsels could never prevail unless the folly of past measures was exposed, and Franklin devoted himself to exposing it. At the top of his satirical bent he could not be ignored, and the initial public reaction to his efforts was gratifying. The issue of the <span>Public Advertiser</span> containing the “Edict” sold out immediately, and both satires were widely reprinted in England and then in America.<a id="BNFN-01-20-02-0213-fn-0004-ptr" href="#BNFN-01-20-02-0213-fn-0004" title="jump to note 9">9</a></p>
<p>What Franklin achieved is another matter. Satire is a poor instrument of persuasion, for the open-minded are likely to be entertained—perhaps shocked—rather than convinced, and the close-minded to be angered. He was aware of the danger. Although he hoped to turn a spotlight on colonial grievances in order to gain redress, he realized that the effect might be to make matters worse.<a id="BNFN-01-20-02-0213-fn-0005-ptr" href="#BNFN-01-20-02-0213-fn-0005" title="jump to note 1">1</a> For him personally that seems to have been the effect. The government dared not mention these attacks for fear of giving them even greater publicity, he concluded later, but they accounted in great part for the official fury unleashed upon him early in 1774.<a id="BNFN-01-20-02-0213-fn-0006-ptr" href="#BNFN-01-20-02-0213-fn-0006" title="jump to note 2">2</a></p>
<p>The substance behind the “Rules” was scarcely new. Franklin had, in more sober fashion, made almost every point before. He touched hardly at all upon the constitutional issues that the Bostonians had set boiling, no doubt because they were difficult to treat satirically; but he marshaled most of the other themes that were his stock in trade as a controversialist. Some related to the colonies in general, some to Massachusetts in particular, and they ran the gamut from old trade restrictions and novel taxes to the oppression wrought by the army <a id="BNFN-01-20-02-pb-0391"></a>and navy; the result was, as he said, comprehensive. These themes were so familiar from long reiteration that in their usual form they might well have evoked no more than a shrug from the British public. By recasting them in the “out-of-the-way” form of satire he gave them a new bite. But the effect was short-lived. The government soon bit him in turn and then—the final irony—legislated many of his “Rules” in the Coercive Acts of 1774.</p>
</div>
<div>
<div><p><span>For the</span> Public Advertiser.</p></div>
<p><span>Rules</span> <span>by which a</span> <span>GREAT</span> <span>Empire</span> <span>may be reduced to a</span> <span>SMALL ONE</span>. [Presented privately to a <span>late Minister</span>, when he entered upon his Administration; and now first published.]<a id="BNFN-01-20-02-0213-fn-0007-ptr" href="#BNFN-01-20-02-0213-fn-0007" title="jump to note 3">3</a></p>
<p>An ancient Sage valued himself upon this, that tho’ he could not fiddle, he knew how to make a <span>great City</span> of a <span>little one</span>.<a id="BNFN-01-20-02-0213-fn-0008-ptr" href="#BNFN-01-20-02-0213-fn-0008" title="jump to note 4">4</a> The Science that I, a modern Simpleton, am about to communicate is the very reverse.</p>
<p>I address myself to all Ministers who have the Management of extensive Dominions, which from their very Greatness are become troublesome to govern, because the Multiplicity of their Affairs leaves no Time for <span>fiddling</span>.</p>
<p>I. In the first Place, Gentlemen, you are to consider, that a great Empire, like a great Cake, is most easily diminished at the Edges. Turn your Attention therefore first to your remotest Provinces; that as you get rid of them, the next may follow in Order.</p>
<p>II. That the Possibility of this Separation may always exist, take special Care the Provinces are never incorporated with the Mother Country, that they do not enjoy the same common Rights, the same Privileges in Commerce, and that they are governed by <span>severer</span> Laws, all of <span>your enacting</span>, without allowing them any Share in the Choice of the Legislators. By carefully making and preserving such Distinctions, you will (to keep to my Simile of the Cake) act like a wise Gingerbread Baker, who, to facilitate a Division, cuts his Dough half through in those Places, where, when bak’d, he would have it <span>broken to Pieces</span>.</p>
<p>III. These remote Provinces have perhaps been acquired, purchas’d, or conquer’d, at the <span>sole Expence</span> of the Settlers or their Ancestors, without the Aid of the Mother Country. If this should happen to increase her <span>Strength</span> by their growing Numbers ready to join in her Wars, her <span>Commerce</span> by their growing Demand for her Manufactures, or her <span>Naval Power</span> by greater Employment for her Ships and Seamen, they may probably suppose some Merit in this, and that it entitles them to some Favour; you are therefore to <span>forget it all</span>, or resent it as if they had done you Injury. If they happen to be zealous Whigs, Friends of Liberty, nurtur’d in Revolution Principles, <span>remember all that</span> to their Prejudice, and contrive to punish it: For such Principles, after a Revolution is thoroughly established, are of <span>no more Use</span>, they are even <span>odious</span> and <span>abominable</span>.<a id="BNFN-01-20-02-0213-fn-0009-ptr" href="#BNFN-01-20-02-0213-fn-0009" title="jump to note 5">5</a></p>
<p>IV. However peaceably your Colonies have submitted to your Government, shewn their Affection to your Interest, and patiently borne their Grievances, you are to <span>suppose</span> them always inclined to revolt, and treat them accordingly. Quarter Troops among them, who by their Insolence may <span>provoke</span> the rising of Mobs, and by their Bullets and Bayonets <span>suppress</span> them. By this Means, like the Husband who uses his Wife ill <span>from Suspicion</span>, you may in Time convert your <span>Suspicions</span> into <span>Realities</span>.</p>
<p>V. Remote Provinces must have <span>Governors</span>, and <span>Judges</span>, to represent the Royal Person, and execute every where the delegated Parts of his Office and Authority. You Ministers know, that much of the Strength of Government depends on the <span>Opinion</span> of the People; and much of that Opinion on the Choice of<a id="BNFN-01-20-02-0213-fn-0010-ptr" href="#BNFN-01-20-02-0213-fn-0010" title="jump to note 6">6</a> Rulers placed immediately over them. If you send them wise and good Men for Governors, who study the Interest of the Colonists, and <a id="BNFN-01-20-02-pb-0393"></a>advance their Prosperity, they will think their King wise and good, and that he wishes the Welfare of his Subjects. If you send them learned and upright Men for judges, they will think him a Lover of Justice. This may attach your Provinces more to his Government. You are therefore to be careful who you recommend for those Offices. If you can find Prodigals who have ruined their Fortunes, broken Gamesters or Stock-Jobbers, these may do well as <span>Governors;</span> for they will probably be rapacious, and provoke the People by their Extortions. Wrangling Proctors and petty-fogging Lawyers<a id="BNFN-01-20-02-0213-fn-0011-ptr" href="#BNFN-01-20-02-0213-fn-0011" title="jump to note 7">7</a> too are not amiss, for they will be for ever disputing and quarrelling with their little Parliaments, if withal they should be ignorant, wrong-headed and insolent, so much the better. Attorneys Clerks and Newgate Solicitors will do for <span>Chief-Justices</span>, especially if they hold their Places <span>during your Pleasure</span>: And all will contribute to impress those ideas of your Government that are proper for a People <span>you would wish to renounce it</span>.</p>
<p>VI. To confirm these Impressions, and strike them deeper, whenever the Injured come to the Capital with Complaints of Mal-administration, Oppression, or Injustice, punish such Suitors with long Delay, enormous Expence, and a final Judgment in Favour of the Oppressor. This will have an admirable Effect every Way. The Trouble of future Complaints will be prevented, and Governors and Judges will be encouraged to farther Acts of Oppression and Injustice; and thence the People may become more disaffected, <span>and at length desperate</span>.</p>
<p>VII. When such Governors have crammed their Coffers, and made themselves so odious to the People that they can no longer remain among them with Safety to their Persons, recall and <span>reward</span> them with Pensions. You may make them <span>Baronets</span> too,<a id="BNFN-01-20-02-0213-fn-0012-ptr" href="#BNFN-01-20-02-0213-fn-0012" title="jump to note 8">8</a> if that respectable Order should not think fit to resent it. All will contribute to encourage new Governors in the same Practices, and make the supreme Government <span>detestable</span>.</p>
<p>VIII. If when you are engaged in War, your Colonies should vie in liberal Aids of Men and Money against the common Enemy, upon your simple Requisition, and give far beyond their Abilities, <a id="BNFN-01-20-02-pb-0394"></a>reflect, that a Penny taken from them by your Power is more honourable to you than a Pound presented by their Benevolence. Despise therefore their voluntary Grants, and resolve to harrass them with novel Taxes. They will probably complain to your Parliaments that they are taxed by a Body in which they have no Representative, and that this is contrary to common Right. They will petition for Redress. Let the Parliaments flout their Claims, reject their Petitions, refuse even to suffer the reading of them, and treat the Petitioners with the utmost Contempt. Nothing can have a better Effect, in producing the Alienation proposed; for though many can forgive Injuries, <span>none ever forgave Contempt</span>.</p>
<p>IX. In laying these Taxes, never regard the heavy Burthens those remote People already undergo, in defending their own Frontiers, supporting their own provincial Governments, making new Roads, building Bridges, Churches and other public Edifices, which in old Countries have been done to your Hands by your Ancestors, but which occasion constant Calls and Demands on the Purses of a new People. Forget the <span>Restraints</span> you lay on their Trade for <span>your own</span> Benefit, and the Advantage a <span>Monopoly</span> of this Trade gives your exacting Merchants. Think nothing of the Wealth those Merchants and your Manufacturers acquire by the Colony Commerce; their encreased Ability thereby to pay Taxes at home; their accumulating, in the Price of their Commodities, most of those Taxes, and so levying them from their consuming Customers: All this, and the Employment and Support of thousands of your Poor by the Colonists, you are <span>intirely to forget</span>. But remember to make your arbitrary Tax more grievous to your Provinces, by public Declarations importing that your Power of taxing them has <span>no limits</span>, so that when you take from them without their Consent a Shilling in the Pound, you have a clear Right to the other nineteen. This will probably weaken every Idea of <span>Security in their Property</span>, and convince them that under such a Government <span>they have nothing they can call their own;</span> which can scarce fail of producing <span>the happiest Consequences</span>!<a id="BNFN-01-20-02-0213-fn-0013-ptr" href="#BNFN-01-20-02-0213-fn-0013" title="jump to note 9">9</a></p>
<p>X. Possibly indeed some of them might still comfort themselves, and say, “Though we have no Property, we have yet <span>something</span> left that is valuable; we have constitutional <span>Liberty</span> both <a id="BNFN-01-20-02-pb-0395"></a>of Person and of Conscience. This King, these Lords, and these Commons, who it seems are too remote from us to know us and feel for us, cannot take from us our <span>Habeas Corpus</span> Right, or our Right of Trial <span>by a Jury of our Neighbours:</span> They cannot deprive us of the Exercise of our Religion, alter our ecclesiastical Constitutions, and compel us to be Papists if they please, or Mahometans.” To annihilate this Comfort, begin by Laws to perplex their Commerce with infinite Regulations impossible to be remembered and observed; ordain Seizures of their Property for every Failure; take away the Trial of such Property by Jury, and give it to arbitrary Judges of your own appointing, and of the lowest Characters in the Country, whose Salaries and Emoluments are to arise out of the Duties or Condemnations, and whose Appointments are <span>during Pleasure</span>. Then let there be a formal Declaration of both Houses, that Opposition to your Edicts is <span>Treason</span>, and that Persons suspected of Treason in the Provinces may, according to some obsolete Law, be seized and sent to the Metropolis of the Empire for Trial; and pass an Act that those there charged with certain other Offences shall be sent away in Chains from their Friends and Country to be tried in the same Manner for Felony. Then erect a new Court of Inquisition among them, accompanied by an armed Force, with Instructions to transport all such suspected Persons, to be ruined by the Expence if they bring over Evidences to prove their Innocence, or be found guilty and hanged if they can’t afford it. And lest the People should think you cannot possibly go any farther, pass another solemn declaratory Act, that “King, Lords, and Commons had, hath, and of Right ought to have, full Power and Authority to make Statutes of sufficient Force and Validity to bind the unrepresented Provinces <span>IN ALL CASES WHATSOEVER</span>.” This will include <span>Spiritual</span> with temporal; and taken together, must operate wonderfully to your Purpose, by convincing them, that they are at present under a Power something like that spoken of in the Scriptures, which can not only <span>kill their Bodies</span>, but <span>damn their Souls</span> to all Eternity, by compelling them, if it pleases, <span>to worship the Devil</span>.<a id="BNFN-01-20-02-0213-fn-0014-ptr" href="#BNFN-01-20-02-0213-fn-0014" title="jump to note 1">1</a></p>
<p>XI. To make your Taxes more odious, and more likely to <a id="BNFN-01-20-02-pb-0396"></a>procure Resistance, send from the Capital a Board of Officers to superintend the Collection, composed of the most <span>indiscreet, ill-bred</span> and <span>insolent</span> you can find. Let these have large Salaries out of the extorted Revenue, and live in open grating Luxury upon the Sweat and Blood of the Industrious, whom they are to worry continually with groundless and expensive Prosecutions before the above-mentioned arbitrary Revenue-Judges, all <span>at the Cost of the Party prosecuted</span> tho’ acquitted, because <span>the King is to pay no Costs</span>. Let these Men <span>by your Order</span> be exempted from all the common Taxes and Burthens of the Province, though they and their Property are protected by its Laws. If any Revenue Officers are <span>suspected</span> of the least Tenderness for the People, discard them.<a id="BNFN-01-20-02-0213-fn-0015-ptr" href="#BNFN-01-20-02-0213-fn-0015" title="jump to note 2">2</a> If others are justly complained of, protect and reward them. If any of the Under-officers behave so as to provoke the People to drub them, promote those to better Offices: This will encourage others to procure for themselves such profitable Drubbings, by multiplying and enlarging such Provocations, and <span>all with work towards the End you aim at</span>.</p>
<p>XII. Another Way to make your Tax odious, is to misapply the Produce of it. If it was originally appropriated for the <span>Defence</span> of the Provinces and the better Support of Government, and the Administration of Justice where it may be <span>necessary</span>, then apply none of it to that <span>Defence</span>, but bestow it where it is <span>not necessary</span>, in augmented Salaries or Pensions to every Governor who has distinguished himself by his Enmity to the People, and by calumniating them to their Sovereign. This will make them pay it more unwillingly, and be more apt to quarrel with those that collect it, and those that imposed it, who will quarrel again with them, and all shall contribute to your <span>main Purpose</span> of making them <span>weary of your Government</span>.</p>
<p>XIII. If the People of any Province have been accustomed to support their own Governors and Judges to Satisfaction, you are to apprehend that such Governors and Judges may be thereby influenced to treat the People kindly, and to do them Justice. This is another Reason for applying Part of that Revenue in larger Salaries to such Governors and Judges, given, as their Commissions are, <span>during your Pleasure</span> only, forbidding them to take any <a id="BNFN-01-20-02-pb-0397"></a>Salaries from their Provinces; that thus the People may no longer hope any Kindness from their Governors, or (in Crown Cases) any Justice from their Judges. And as the Money thus mis-applied in one Province is extorted from all, probably <span>all will resent the Misapplication</span>.</p>
<p>XIV. If the Parliaments of your Provinces should dare to claim Rights or complain of your Administration, order them to be harass’d with repeated <span>Dissolutions</span>. If the same Men are continually return’d by new Elections, adjourn their Meetings to some Country Village where they cannot be accommodated, and there keep them <span>during Pleasure;</span> for this, you know, is your <span>Prerogative</span>; and an excellent one it is, as you may manage it, to promote Discontents among the People, diminish their Respect, and <span>increase their Disaffection</span>.</p>
<p>XV. Convert the brave honest Officers of your Navy into pimping Tide-waiters and Colony Officers of the Customs. Let those who in Time of War fought gallantly in Defence of the Commerce of their Countrymen, in Peace be taught to prey upon it. Let them learn to be corrupted by great and real Smugglers; but (to shew their Diligence) scour with armed Boats every Bay, Harbour, River, Creek, Cove or Nook throughout the Coast of your Colonies, stop and detain every Coaster, every Wood-boat, every Fisherman, tumble their Cargoes, and even their Ballast, inside out and upside down; and if a Penn’orth of Pins is found un-entered, let the Whole be seized and confiscated. Thus shall the Trade of your Colonists suffer more from their Friends in Time of Peace, than it did from their Enemies in War. Then let these Boats Crews land upon every Farm in their Way, rob the Orchards, steal the Pigs and Poultry, and insult the Inhabitants. If the injured and exasperated Farmers, unable to procure other Justice, should attack the Agressors, drub them and burn their Boats, you are to call this <span>High Treason</span> and <span>Rebellion</span>, order<a id="BNFN-01-20-02-0213-fn-0016-ptr" href="#BNFN-01-20-02-0213-fn-0016" title="jump to note 3">3</a> Fleets and Armies into their Country, and threaten to carry all the Offenders three thousand Miles to be hang’d, drawn and quartered. <span>O! this will work admirably!</span></p>
<p>XVI. If you are told of Discontents in your Colonies, never believe that they are general, or that you have given Occasion for <a id="BNFN-01-20-02-pb-0398"></a>them; therefore do not think of applying any Remedy, or of changing any offensive Measure. Redress no Grievance, lest they should be encouraged to demand the Redress of some other Grievance. Grant no Request that is just and reasonable, lest they should make another that is unreasonable. Take all your Informations of the State of the Colonies from your Governors and Officers in Enmity with them. Encourage and reward these <span>Leasing-makers;</span><a id="BNFN-01-20-02-0213-fn-0017-ptr" href="#BNFN-01-20-02-0213-fn-0017" title="jump to note 4">4</a> secrete their lying Accusations lest they should be confuted; but act upon them as the clearest Evidence, and believe nothing you hear from the Friends of the People. Suppose all <span>their</span> Complaints to be invented and promoted by a few factious Demagogues, whom if you could catch and hang, all would be quiet. Catch and hang a few of them accordingly; and the <span>Blood of the Martyrs</span> shall <span>work Miracles</span> in favour of your Purpose.</p>
<p>XVII. If you see <span>rival Nations</span> rejoicing at the Prospect of your Disunion with your Provinces, and endeavouring to promote it: If they translate, publish and applaud all the Complaints of your discontented Colonists,<a id="BNFN-01-20-02-0213-fn-0018-ptr" href="#BNFN-01-20-02-0213-fn-0018" title="jump to note 5">5</a> at the same Time privately stimulating you to severer Measures; let not that <span>alarm</span> or offend you. Why should it? since you all mean <span>the same Thing</span>.<a id="BNFN-01-20-02-0213-fn-0019-ptr" href="#BNFN-01-20-02-0213-fn-0019" title="jump to note 6">6</a></p>
<p>XVIII. If any Colony should at their own Charge erect a Fortress to secure their Port against the Fleets of a foreign Enemy, get your Governor to betray that Fortress into your Hands. Never think of paying what it cost the Country, for that would <span>look</span>, at least, like some Regard for Justice; but turn it into a Citadel to awe the Inhabitants and curb their Commerce. If they should have lodged in such Fortress the very Arms they bought <a id="BNFN-01-20-02-pb-0399"></a>and used to aid you in your Conquests, seize them all, ’twill provoke like <span>Ingratitude</span> added to <span>Robbery</span>.<a id="BNFN-01-20-02-0213-fn-0020-ptr" href="#BNFN-01-20-02-0213-fn-0020" title="jump to note 7">7</a> One admirable Effect of these Operations will be, to discourage every other Colony from erecting such Defences, and so their and your Enemies may more easily invade them, to the great Disgrace of your Government, and of course <span>the Furtherance of your Project</span>.<a id="BNFN-01-20-02-0213-fn-0021-ptr" href="#BNFN-01-20-02-0213-fn-0021" title="jump to note 8">8</a></p>
<p>XIX. Send Armies into their Country under Pretence of protecting the Inhabitants; but instead of garrisoning the Forts on their Frontiers with those Troops, to prevent Incursions, demolish those Forts, and order the Troops into the Heart of the Country, that the Savages may be encouraged to attack the Frontiers, and that the Troops may be protected by the Inhabitants: This will seem to proceed from your Ill will or your Ignorance, and contribute farther to produce and strengthen an Opinion among them, <span>that you are no longer fit to govern them</span>.</p>
<p>XX. Lastly, Invest the General of your Army in the Provinces with great and unconstitutional Powers, and free him from the Controul of even your own Civil Governors. Let him have Troops enow under his Command, with all the Fortresses in his Possession; and who knows but (like some provincial Generals in the Roman Empire, and encouraged by the universal Discontent you have produced) he may take it into his Head to set up for himself. If he should, and you have carefully practised these few <span>excellent Rules</span> of mine, take my Word for it, all the Provinces will immediately join him, and you will that Day (if you have not done it sooner) get rid of the Trouble of governing them, and all the <span>Plagues</span> attending their <span>Commerce</span> and Connection from thenceforth and for ever.</p>
<p>Q.E.D.</p>
</div>
<div><p>[Note numbering follows the Franklin Papers source.]</p>
<p><a id="BNFN-01-20-02-0213-fn-0001" href="#BNFN-01-20-02-0213-fn-0001-ptr" title="jump to note 6 context">6</a><span>.&nbsp;</span>The draft lacks the middle pages and conclusion. The notes are small additions, written on the back of an invoice from Brown &amp; Whitefoord dated Sept. 2, 1773; we indicate where they were and were not embodied in the draft.</p>
<p><a id="BNFN-01-20-02-0213-fn-0002" href="#BNFN-01-20-02-0213-fn-0002-ptr" title="jump to note 7 context">7</a><span>.&nbsp;</span>Below, under Sept. 22. For a literary analysis of the satires see Richard E. Amacher, <span>Benjamin Franklin</span> (New York, [1962]), pp. 82–8. The fullest analysis is unfortunately not in print: Francis X. Davy, “Benjamin Franklin, Satirist: the Satire of Franklin and Its Rhetoric,” unpublished doctoral dissertation, Columbia University, 1958.</p>
<p><a id="BNFN-01-20-02-0213-fn-0003" href="#BNFN-01-20-02-0213-fn-0003-ptr" title="jump to note 8 context">8</a><span>.&nbsp;</span><abbr title="Benjamin Franklin">BF</abbr> to <abbr title="William Franklin">WF</abbr> below, Oct. 6.</p>
<p><a id="BNFN-01-20-02-0213-fn-0004" href="#BNFN-01-20-02-0213-fn-0004-ptr" title="jump to note 9 context">9</a><span>.&nbsp;</span><span>Ibid.</span>; Crane, <span>Letters to the Press</span>, pp. 233–4, 236–7.</p>
<p><a id="BNFN-01-20-02-0213-fn-0005" href="#BNFN-01-20-02-0213-fn-0005-ptr" title="jump to note 1 context">1</a><span>.&nbsp;</span>To <abbr title="William Franklin">WF</abbr> below, Nov. 3. <abbr title="Benjamin Franklin">BF</abbr>’s most interesting comment on his motives was to Jane Mecom below, Nov. 1.</p>

<p><a id="BNFN-01-20-02-0213-fn-0007" href="#BNFN-01-20-02-0213-fn-0007-ptr" title="jump to note 3 context">3</a><span>.&nbsp;</span>When Hillsborough took office in 1768, in other words, he adopted these rules to guide his policy. Brackets are in the original.</p>
<p><a id="BNFN-01-20-02-0213-fn-0008" href="#BNFN-01-20-02-0213-fn-0008-ptr" title="jump to note 4 context">4</a><span>.&nbsp;</span>The sage was Themistocles, as reported by Plutarch; <abbr title="Benjamin Franklin">BF</abbr>’s wording is approximated in John and William Langhorne, <span>Plutarch’s Lives</span> … (6 vols., London, 1770), <span>I</span>, 281.</p>
<p><a id="BNFN-01-20-02-0213-fn-0009" href="#BNFN-01-20-02-0213-fn-0009-ptr" title="jump to note 5 context">5</a><span>.&nbsp;</span><abbr title="Benjamin Franklin">BF</abbr> added this passage, beginning with “If they happen,” from one of the notes mentioned above. His comment must have shocked English readers as much as he intended, for the principles of the Glorious Revolution had developed differently on the two sides of the Atlantic. In England the principle of an omnicompetent crown in Parliament had largely submerged the contractual limitations on government inherent in the Bill of Rights. The colonies, where local autonomy was in tension with control from London, preserved in full force the principle that authority per se was dangerous. See Bernard Bailyn, <span>The Ideological Origins of the American Revolution</span> (Cambridge, Mass., [1967]), especially pp. 35–6, 43–7, 201–3.</p>
<p><a id="BNFN-01-20-02-0213-fn-0010" href="#BNFN-01-20-02-0213-fn-0010-ptr" title="jump to note 6 context">6</a><span>.&nbsp;</span>The first portion of the surviving draft ends here.</p>
<p><a id="BNFN-01-20-02-0213-fn-0011" href="#BNFN-01-20-02-0213-fn-0011-ptr" title="jump to note 7 context">7</a><span>.&nbsp;</span>Proctors had their own areas of pettifoggery, the ecclesiastical and admiralty courts.</p>
<p><a id="BNFN-01-20-02-0213-fn-0012" href="#BNFN-01-20-02-0213-fn-0012-ptr" title="jump to note 8 context">8</a><span>.&nbsp;</span>Sir Francis Bernard.</p>
<p><a id="BNFN-01-20-02-0213-fn-0013" href="#BNFN-01-20-02-0213-fn-0013-ptr" title="jump to note 9 context">9</a><span>.&nbsp;</span><abbr title="Benjamin Franklin">BF</abbr> had made this point earlier in his marginalia: above, <span>XVII</span>, 339.</p>
<p><a id="BNFN-01-20-02-0213-fn-0014" href="#BNFN-01-20-02-0213-fn-0014-ptr" title="jump to note 1 context">1</a><span>.&nbsp;</span><abbr title="Benjamin Franklin">BF</abbr> introduced “unrepresented Provinces” into his quotation from the Declaratory Act. His Biblical reference is to Matthew 10:28.</p>
<p><a id="BNFN-01-20-02-0213-fn-0015" href="#BNFN-01-20-02-0213-fn-0015-ptr" title="jump to note 2 context">2</a><span>.&nbsp;</span>A reference to John Temple, dismissed in 1770: above, <span>XIX</span>, 402.</p>
<p><a id="BNFN-01-20-02-0213-fn-0016" href="#BNFN-01-20-02-0213-fn-0016-ptr" title="jump to note 3 context">3</a><span>.&nbsp;</span>The second portion of the surviving draft begins here.</p>
<p><a id="BNFN-01-20-02-0213-fn-0017" href="#BNFN-01-20-02-0213-fn-0017-ptr" title="jump to note 4 context">4</a><span>.&nbsp;</span>Liars, a phrase derived from Scottish law. The part of the sentence that follows, from “secrete” to “Evidence,” <abbr title="Benjamin Franklin">BF</abbr> interlined in his draft from one of the notes mentioned above.</p>
<p><a id="BNFN-01-20-02-0213-fn-0018" href="#BNFN-01-20-02-0213-fn-0018-ptr" title="jump to note 5 context">5</a><span>.&nbsp;</span>The controlled French press had been publishing, since the time of the Stamp Act, documentation of the developing Anglo-American quarrel; see Durand Echeverria, <span>Mirage in the West: a History of the French Image of American Society to 1815</span> (Princeton, [1957]), pp. 36–7.</p>
<p><a id="BNFN-01-20-02-0213-fn-0019" href="#BNFN-01-20-02-0213-fn-0019-ptr" title="jump to note 6 context">6</a><span>.&nbsp;</span><abbr title="Benjamin Franklin">BF</abbr> added Rule <span>XVII</span> to his draft from one of the notes mentioned above, but deleted the opening sentence of that note: “If wretched Writers rail against your Colonists, and do their best to widen Breaches, reward them with Pensions or with Patent Places: if those are to be paid out of the Colony Revenue, and those are Colony Places, it will be the more <span>grating</span> and of course <span>so much the better</span>. And if you see,” etc.</p>
<p><a id="BNFN-01-20-02-0213-fn-0020" href="#BNFN-01-20-02-0213-fn-0020-ptr" title="jump to note 7 context">7</a><span>.&nbsp;</span><abbr title="Benjamin Franklin">BF</abbr> interlined this sentence in his draft from one of the notes mentioned above.</p>
<p><a id="BNFN-01-20-02-0213-fn-0021" href="#BNFN-01-20-02-0213-fn-0021-ptr" title="jump to note 8 context">8</a><span>.&nbsp;</span>The second portion of the surviving draft ends here. <abbr title="Benjamin Franklin">BF</abbr> returned to the subject of this paragraph in his introduction to Bernard’s speeches below, Sept. 17.</p>
</div>
<div><h2>Index Entries</h2><ul></ul></div></div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The new shape of Mixxx 3.0 – Open Source DJing (102 pts)]]></title>
            <link>https://mixxx.org/news/2025-08-06-qml-project/</link>
            <guid>44818077</guid>
            <pubDate>Wed, 06 Aug 2025 21:29:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mixxx.org/news/2025-08-06-qml-project/">https://mixxx.org/news/2025-08-06-qml-project/</a>, See on <a href="https://news.ycombinator.com/item?id=44818077">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main-container">


<nav id="navbar">
  <div>
    <p><span>
      <a href="https://mixxx.org/">
        <img src="https://mixxx.org/theme/images/mixxx-logo.svg" alt="Mixxx">
      </a>
    </span>
    
    <label for="navbar-hamburger-button"><span></span></label></p>
  </div>
</nav>
<div>
    <h2>Announcing the new shape of Mixxx 3.0 - take part in the future of Open Source DJing</h2>
    <p>
      <span>
        <img src="https://mixxx.org/theme/images/icons/date.svg" alt="Date">
        <time>Wed 06 August 2025</time>
      </span>
      
      <span>
        <img src="https://mixxx.org/theme/images/icons/tag.svg" alt="Tag">
        <span><a href="https://mixxx.org/news/tag/community">community</a></span>,
        <span><a href="https://mixxx.org/news/tag/contribute">contribute</a></span>,
        <span><a href="https://mixxx.org/news/tag/development">development</a></span>,
        <span><a href="https://mixxx.org/news/tag/announcement">announcement</a></span>
      </span>
    </p>
    <p>We are thrilled to announce an exciting new chapter in the evolution of Mixxx. We are embarking on a comprehensive redesign of the Mixxx user interface, transitioning from QWidget to <a href="https://en.wikipedia.org/wiki/QML">QML</a>. This significant update aims to enhance customization, improve performance, and ensure better accessibility for a variety of hardware, including tablets and touchscreen laptops, but also to users with vision deficiency thanks to <a href="https://doc.qt.io/qt-6/accessible-qtquick.html">built-in capabilities of QML</a>. Further details on the original proposal can be found <a href="https://github.com/mixxxdj/proposals/blob/main/proposals/2024-11-16_qml_interface.md">here</a>.</p>
<p>Here is a preview of the current look we have designed during the proposal. Of course, as always with design work, the final version will likely look a little different, but this helps as a general guideline and goal to something we like, and hopefully you will to!</p>
<p><img alt="Preview" src="https://raw.githubusercontent.com/mixxxdj/proposals/main/proposals/contents/2024-11-16_qml_interface_overview_live.svg">
<img alt="Preview" src="https://raw.githubusercontent.com/mixxxdj/proposals/main/proposals/contents/2024-11-16_qml_interface_library_split_button.svg">
<img alt="Preview" src="https://raw.githubusercontent.com/mixxxdj/proposals/main/proposals/contents/2024-11-16_qml_interface_waveform_overview_customization.png"></p>
<h2>Why We Are Redesigning Mixxx</h2>
<p>The current user interface of Mixxx has served us well, but as technology evolves, so must we. The shift to QML will simplify customization and maintenance, allowing us to focus more on innovative features and less on upkeep. This transition will also enable us to phase out our homemade theme system, streamlining our development process.</p>
<h2>Key Features of the New Design</h2>
<ol>
<li><strong>Modernized Library and Waveform Views</strong>: We are introducing a fresh look for the Library and Waveform views, making them more intuitive and user-friendly.</li>
</ol>
<p><img alt="Preview" src="https://raw.githubusercontent.com/mixxxdj/proposals/main/proposals/contents/2024-11-16_qml_interface_overlays_playlist.svg"></p>
<ol>
<li>
<p><strong>Enhanced Support for Lightweight Platforms</strong>: The new design will be optimized for tablets, smartphones, and touchscreen laptops, ensuring a seamless experience across all devices.</p>
</li>
<li>
<p><strong>Improved Search Capabilities</strong>: The new search experience will offer better usability of advanced search options, making it easier to find and manage your tracks.</p>
</li>
</ol>
<p><img alt="Preview" src="https://raw.githubusercontent.com/mixxxdj/proposals/main/proposals/contents/2024-11-16_qml_interface_overlays_search.svg">
<img alt="Preview" src="https://raw.githubusercontent.com/mixxxdj/proposals/main/proposals/contents/2024-11-16_qml_interface_overlays_search3.svg"></p>
<ol>
<li><strong>Interactive Settings and Preferences</strong>: We are introducing more interactive settings for audio routing, controllers, and waveforms, providing a more dynamic and user-friendly experience.</li>
</ol>
<p><img alt="Preview" src="https://raw.githubusercontent.com/mixxxdj/proposals/main/proposals/contents/2024-11-16_qml_interface_setting_audio_routing_advanced.svg">
<img alt="Preview" src="https://raw.githubusercontent.com/mixxxdj/proposals/main/proposals/contents/2024-11-16_qml_interface_setting_controller_overview.svg">
<img alt="Preview" src="https://raw.githubusercontent.com/mixxxdj/proposals/main/proposals/contents/2024-11-16_qml_interface_setting_controller_pointnclick.svg">
<img alt="Preview" src="https://raw.githubusercontent.com/mixxxdj/proposals/main/proposals/contents/2024-11-16_qml_interface_setting_waveform.svg"></p>
<h2>Get Involved</h2>
<p>We are calling on developers and testers to join us in this exciting journey. Whether you are a seasoned developer or a passionate DJ looking to contribute, there are many ways you can help us.</p>
<p>This significant project offers a fantastic opportunity to make a substantial impact from the ground up. By helping implement the new QML interface, fixing bugs, and adding features, you can shape the future of a widely-used DJ software. Your Qt/QML expertise will be crucial in this transition.
Whether you're beefing up your portfolio or just want to give back to the open-source community, contributing to Mixxx is a great way to truly make a difference!</p>
<h2>For Developers</h2>
<ul>
<li><strong>Code Contributions</strong>: Help us implement the new QML interface, fix bugs, and add new features. Your expertise in Qt/QML will be invaluable as we transition to this new technology.<blockquote>
<p><strong>Pro tip</strong></p>
<p>Contributing to Mixxx enhances your coding skills and connects you with a vibrant community, providing real-world impact and career opportunities. Many contributors have advanced their careers through Mixxx, gaining valuable experience and recognition. Join us to collaborate with passionate developers and open doors to exciting tech industry opportunities.</p>
</blockquote>
</li>
<li><strong>Review and Feedback</strong>: Review our code, provide feedback, and suggest improvements. Collaboration is key to our success, and your insights will help shape the future of Mixxx.
  Code review is currently our biggest struggle and your help could be a real success factor for the project!</li>
</ul>
<h2>For Testers</h2>
<ul>
<li><strong>Beta Testing</strong>: Join our beta testing program to try out the new features and provide feedback. Your input will help us identify and fix issues, ensuring a smooth and stable release.</li>
<li><strong>User Experience Feedback</strong>: Share your thoughts on the new design and user experience. Your feedback will help us refine and improve the interface, making it more intuitive and user-friendly.<blockquote>
<p><strong>Heads up</strong></p>
<p>We especially want to gather feedback from the visually impaired and blind communities to ensure that the next generation of Mixxx is the most accessible it has ever been!</p>
</blockquote>
</li>
</ul>
<h2>How to Get Started</h2>
<ol>
<li><strong>Join our community</strong>: Connect with us on our chat platform <a href="https://mixxx.zulipchat.com/">Zulip</a>. Stay updated on the latest developments and contribute to discussions.</li>
<li><strong>Check out the progress</strong>: Check out our <a href="https://github.com/mixxxdj/mixxx">GitHub repository</a> and more precisely <a href="https://github.com/orgs/mixxxdj/projects/3/views/1">the QML project</a>. You can also help us testing the <a href="https://github.com/mixxxdj/mixxx/pulls?q=is%3Aopen+is%3Apr+milestone%3A3.0-beta+draft%3Afalse">ready merge requests</a>, or even help with review in case you are familiar with QML!</li>
<li><strong>Follow us on our socials</strong>: We have committed to increase our presence on <a href="https://www.youtube.com/@mixxxdj">YouTube</a> and provide regular updates on <a href="https://floss.social/@mixxx">Mastodon</a> and <a href="https://bsky.app/profile/mixxx.bsky.social">Bluesky</a>. Follow us and help us reaching out to more contributor to make this project successful.</li>
</ol>
<h2>Closing Thoughts</h2>
<p>The future of Mixxx is bright, and we are excited to have you on board. Together, we can create the best DJ software experience for our community. Join us in this journey and help us shape the future of Mixxx and DJing!</p>
<p>Stay tuned for more updates and happy mixxxing!</p>

    
  </div>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Bluesky Dictionary (197 pts)]]></title>
            <link>https://www.avibagla.com/blueskydictionary/</link>
            <guid>44817583</guid>
            <pubDate>Wed, 06 Aug 2025 20:43:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.avibagla.com/blueskydictionary/">https://www.avibagla.com/blueskydictionary/</a>, See on <a href="https://news.ycombinator.com/item?id=44817583">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <header>
            
            <p>Can Bluesky say <b><i>every word</i></b> in the English language?</p>
            
        </header>

        <div>
            <div>
                <p>0%</p>
                <p>Dictionary Coverage</p>
                <p>(0/0 words seen)</p>
                
            </div>
            <div>
                <div>
                    <p>0</p>
                    <p>Total Words Seen</p>
                </div>
                <div>
                    <p>0</p>
                    <p>Posts Processed</p>
                </div>
            </div>
        </div>

        <div>
            <h2>Newest Words</h2>
            
        </div>

        <div>
            <h2>Posts With New Words</h2>
            <div id="discoveriesList">
                    <p>Loading recent discoveries...</p>
                    <p>Connecting to Bluesky stream to find new words...</p>
                    <p>Waiting for data...</p>
                </div>
        </div>

        <div>
            <div>
                <h2>Words We Have Seen</h2>
                <div id="seenWordsContainer">
                            <p>Loading...</p>
                            <p>Loading seen words...</p>
                            <p>Please wait...</p>
                        </div>
            </div>
            
            <div>
                <h2>Words We Haven't Seen</h2>
                <div id="unseenWordsContainer">
                        <!-- Placeholder unseen words -->
                        <p>Loading words...</p>
                        <p>Please wait...</p>
                        <p>Loading...</p>
                    </div>
            </div>
        </div>

        
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Project Hyperion: Interstellar ship design competition (340 pts)]]></title>
            <link>https://www.projecthyperion.org</link>
            <guid>44817539</guid>
            <pubDate>Wed, 06 Aug 2025 20:40:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.projecthyperion.org">https://www.projecthyperion.org</a>, See on <a href="https://news.ycombinator.com/item?id=44817539">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-mesh-id="Containerb272tinlineContent" data-testid="inline-content" id="PAGES_CONTAINER" tabindex="-1" data-main-content="true"><div data-mesh-id="comp-m4puj09yinlineContent" data-testid="inline-content" id="comp-m4puj09y" tabindex="-1" data-block-level-container="ClassicSection"><p>Design for Centuries</p><div id="comp-m4puj7k0" data-testid="richTextElement"><p><span><span>Project Hyperion explores the feasibility of crewed interstellar travel via generation ships, using current and near-future technologies. A generation ship is a hypothetical spacecraft designed for long-duration interstellar travel, where the journey may take centuries to complete. The idea behind a generation ship is that the initial crew would live, reproduce, and die on the ship, with their descendants continuing the journey until reaching the destination. These ships are often envisioned as self-sustaining ecosystems, featuring agriculture, habitation, and other necessary life-support systems to ensure survival across multiple generations.&nbsp;</span></span></p>

<p><span><span>​</span></span></p>

<p>The Initiative for Interstellar Studies (i4is) is delighted to reveal the winners of the Project Hyperion Design Competition, a landmark global challenge that called upon interdisciplinary teams to envision a generation ship—a crewed interstellar spacecraft designed for a 250-year journey to a habitable planet. The teams designed habitats of such a spacecraft that would allow a society to sustain itself and flourish in a highly resource-constrained environment.</p>

<p><span><span><span><span>​</span></span></span></span></p>

<p><span><span><span>The Project Hyperion Design Competition required architectural designers, engineers, and social scientists to collaborate and address critical mission aspects that enable a spacecraft to function as a closed society over centuries. The collaboration between different disciplines is key to finding holistic solutions that do justice to the complexity of the requirements, in order to provide:</span></span></span></p>

<ul>
<li>
<p><span><span><span>Habitability for 1,000 ± 500 people over centuries</span></span></span></p>
</li>
<li>
<p><span><span><span>Artificial gravity via rotation</span></span></span></p>
</li>
<li>
<p><span><span><span>A society that ensures good living conditions, including essential provisions such as shelter, clothing, and other basic needs.</span></span></span></p>
</li>
<li>
<p><span><span><span>Robust life support systems for food, water, waste, and the atmosphere</span></span></span></p>
</li>
<li>
<p><span><span><span>Knowledge transfer mechanisms to retain culture and technologies</span></span></span></p>
</li>
</ul>

<p><span><span><span>More details about the competition requirements can be found <span><a href="https://www.projecthyperion.org/_files/ugd/91ab16_c3f7196fe5a348cdb0cd56904d02ae81.pdf" target="_blank" rel="noreferrer noopener">here</a></span>.</span></span></span></p></div></div><div data-mesh-id="comp-mddbkc3iinlineContent" data-testid="inline-content" id="comp-mddbkc3i" tabindex="-1" data-block-level-container="ClassicSection"><p id="comp-mddbkc3s" data-testid="richTextElement"><h2><span><span>We thank our jury</span></span></h2></p><p><span><span>The submissions were evaluated by our esteemed jury, comprising distinguished professionals with extensive experience in architecture, engineering, and social sciences.</span></span></p><div id="comp-mddbkc3u" data-mesh-id="comp-mddbkc3v1inlineContent" data-testid="columns"><fluid-columns-repeater horizontal-gap="10" vertical-gap="10" justify-content="center" container-id="comp-mddbkc3w1_wrapper" items="5" role="list" direction="ltr"><div id="comp-mddbkc3x5__item1" data-mesh-id="comp-mddbkc3x5__item1inlineContent" data-testid="inline-content"><p><img loading="lazy" sizes="255px" srcset="https://static.wixstatic.com/media/1dff9e_eddb5a8391104dcea91d49f32774601c~mv2.png/v1/fill/w_255,h_283,al_c,q_85,usm_0.66_1.00_0.01,enc_avif,quality_auto/bannova_edited_edited.png 1x, https://static.wixstatic.com/media/1dff9e_eddb5a8391104dcea91d49f32774601c~mv2.png/v1/fill/w_490,h_544,al_c,lg_1,q_85,enc_avif,quality_auto/bannova_edited_edited.png 2x" id="img_comp-mddbkc3z__item1" src="https://static.wixstatic.com/media/1dff9e_eddb5a8391104dcea91d49f32774601c~mv2.png/v1/fill/w_255,h_283,al_c,q_85,usm_0.66_1.00_0.01,enc_avif,quality_auto/bannova_edited_edited.png" alt="bannova_edited_edited.png" width="255" height="283"></p></div><div id="comp-mddbkc3x5__item-kf51ysxt" data-mesh-id="comp-mddbkc3x5__item-kf51ysxtinlineContent" data-testid="inline-content"><p><img loading="lazy" sizes="255px" srcset="https://static.wixstatic.com/media/1dff9e_e8614d9a18bd460a9dd765b66145efff~mv2.png/v1/fill/w_255,h_283,al_c,q_85,usm_0.66_1.00_0.01,enc_avif,quality_auto/image0_edited_edited.png 1x, https://static.wixstatic.com/media/1dff9e_e8614d9a18bd460a9dd765b66145efff~mv2.png/v1/fill/w_510,h_566,al_c,q_85,usm_0.66_1.00_0.01,enc_avif,quality_auto/image0_edited_edited.png 2x" id="img_comp-mddbkc3z__item-kf51ysxt" src="https://static.wixstatic.com/media/1dff9e_e8614d9a18bd460a9dd765b66145efff~mv2.png/v1/fill/w_255,h_283,al_c,q_85,usm_0.66_1.00_0.01,enc_avif,quality_auto/image0_edited_edited.png" alt="image0_edited_edited.png" width="255" height="283"></p></div><div id="comp-mddbkc3x5__item-kf51yt5v" data-mesh-id="comp-mddbkc3x5__item-kf51yt5vinlineContent" data-testid="inline-content"><p><img loading="lazy" sizes="255px" srcset="https://static.wixstatic.com/media/1dff9e_116945e2adb849a58021fee0d8afc9cb~mv2.png/v1/fill/w_255,h_283,al_c,q_85,usm_0.66_1.00_0.01,enc_avif,quality_auto/RE%201_edited_edited_edited.png 1x, https://static.wixstatic.com/media/1dff9e_116945e2adb849a58021fee0d8afc9cb~mv2.png/v1/fill/w_510,h_566,al_c,q_85,usm_0.66_1.00_0.01,enc_avif,quality_auto/RE%201_edited_edited_edited.png 2x" id="img_comp-mddbkc3z__item-kf51yt5v" src="https://static.wixstatic.com/media/1dff9e_116945e2adb849a58021fee0d8afc9cb~mv2.png/v1/fill/w_255,h_283,al_c,q_85,usm_0.66_1.00_0.01,enc_avif,quality_auto/RE%201_edited_edited_edited.png" alt="RE 1_edited_edited_edited.png" width="255" height="283"></p></div><div id="comp-mddbkc3x5__item-kf51ytd5" data-mesh-id="comp-mddbkc3x5__item-kf51ytd5inlineContent" data-testid="inline-content"><p><img loading="lazy" sizes="255px" srcset="https://static.wixstatic.com/media/1dff9e_05fafe635a344fed8774b6c5fe1807fe~mv2.png/v1/fill/w_255,h_283,al_c,lg_1,q_85,enc_avif,quality_auto/smith_edited_edited_edited_edited_edited.png 1x, https://static.wixstatic.com/media/1dff9e_05fafe635a344fed8774b6c5fe1807fe~mv2.png/v1/fill/w_260,h_288,al_c,lg_1,q_85,enc_avif,quality_auto/smith_edited_edited_edited_edited_edited.png 2x" id="img_comp-mddbkc3z__item-kf51ytd5" src="https://static.wixstatic.com/media/1dff9e_05fafe635a344fed8774b6c5fe1807fe~mv2.png/v1/fill/w_255,h_283,al_c,lg_1,q_85,enc_avif,quality_auto/smith_edited_edited_edited_edited_edited.png" alt="smith_edited_edited_edited_edited_edited" width="255" height="283"></p></div><div data-mesh-id="comp-mddbkc3x5__item-753ce626-934e-4e6f-a00d-ed236ea8212ainlineContent" data-testid="inline-content" id="comp-mddbkc3x5__item-753ce626-934e-4e6f-a00d-ed236ea8212a"><div id="comp-mddbkc3z__item-753ce626-934e-4e6f-a00d-ed236ea8212a"><p><img loading="lazy" sizes="255px" srcset="https://static.wixstatic.com/media/1dff9e_242e4e96053f4201882c4b8ac76b67d5~mv2.png/v1/fill/w_255,h_283,al_c,q_85,usm_0.66_1.00_0.01,enc_avif,quality_auto/Madhu-Thangavelu_edited_edited_edited_pn.png 1x, https://static.wixstatic.com/media/1dff9e_242e4e96053f4201882c4b8ac76b67d5~mv2.png/v1/fill/w_381,h_423,al_c,lg_1,q_85,enc_avif,quality_auto/Madhu-Thangavelu_edited_edited_edited_pn.png 2x" id="img_comp-mddbkc3z__item-753ce626-934e-4e6f-a00d-ed236ea8212a" src="https://static.wixstatic.com/media/1dff9e_242e4e96053f4201882c4b8ac76b67d5~mv2.png/v1/fill/w_255,h_283,al_c,q_85,usm_0.66_1.00_0.01,enc_avif,quality_auto/Madhu-Thangavelu_edited_edited_edited_pn.png" alt="Madhu-Thangavelu_edited_edited_edited.pn" width="255" height="283"></p></div><div data-mesh-id="comp-mddbkc40__item-753ce626-934e-4e6f-a00d-ed236ea8212ainlineContent" data-testid="inline-content" id="comp-mddbkc40__item-753ce626-934e-4e6f-a00d-ed236ea8212a"><p>University of Southern California</p></div></div></fluid-columns-repeater></div></div><div data-mesh-id="comp-mdgxtk50inlineContent" data-testid="inline-content" id="comp-mdgxtk50" tabindex="-1" data-block-level-container="ClassicSection"><p id="comp-mdgxtra2" data-testid="richTextElement"><h2>1st Place</h2></p></div><div data-mesh-id="comp-mdiki8wuinlineContent" data-testid="inline-content" id="comp-mdiki8wu" tabindex="-1" data-block-level-container="ClassicSection"><p id="comp-mdiki8xb5" data-testid="richTextElement"><h2><span><span>Team</span></span></h2></p><p>Giacomo Infelise, Veronica Magli, Guido Sbrogio', Nevenka Martinello, Federica Chiara Serpe​</p></div><div data-mesh-id="comp-mddbz389inlineContent" data-testid="inline-content" id="comp-mddbz389" tabindex="-1" data-block-level-container="ClassicSection"><p id="comp-mddbz38h4" data-testid="richTextElement"><h2><span><span>Jury feedback</span></span></h2></p><p>Chrysalis impressed the jury with its system-level coherence and innovative design of the modular habitat structure but also overall depth of detail, which included, for example, in-space manufacturing and the value of pre-mission crew preparation in Antarctica. Its modular shell design promotes flexibility and connectivity, supporting both functionality and scalability. The large Dome structure adds a dramatic, cinematic quality that evokes science fiction classics, while the overall system-level planning—covering not just architecture but also how to build the vessel—is notably strong. The radiation protection strategy is solid, and the practical structural approach is well-suited. While cultural systems could be further developed, the concept offers a compelling starting point. The presentation is rich and visually engaging, drawing comparisons to iconic works like Rama, and showcasing a clear passion for both design and storytelling. Its overall spacecraft design seems to take inspiration from the gigantic world ship concepts of the 1980s.&nbsp;</p></div><div data-mesh-id="comp-mdgxxfp2inlineContent" data-testid="inline-content" id="comp-mdgxxfp2" tabindex="-1" data-block-level-container="ClassicSection"><p id="comp-mdgxxfp54" data-testid="richTextElement"><h2>2nd Place</h2></p></div><div data-mesh-id="comp-mdinrdusinlineContent" data-testid="inline-content" id="comp-mdinrdus" tabindex="-1" data-block-level-container="ClassicSection"><p id="comp-mdinrduy" data-testid="richTextElement"><h2><span><span>Team</span></span></h2></p><div id="comp-mdinrduy5" data-testid="richTextElement"><p>Julia Biernacik, Jakub Kot, Aleksandra Wróbel, Jacek Janas, Michał Kucharski, Wiktoria Kuchta, Natalia Łakoma, Katarzyna Śliwa</p>

<p><span>​</span></p>

<p>Mentor: dr hab. Michał Kracik</p>

<p><span>​</span></p>

<p><span>​</span>Faculty of Industrial Design (Design for Extreme Environments Studio) AFA in Krakow</p></div></div><div data-mesh-id="comp-mdinrj5finlineContent" data-testid="inline-content" id="comp-mdinrj5f" tabindex="-1" data-block-level-container="ClassicSection"><p id="comp-mdinrj5m5" data-testid="richTextElement"><h2><span><span>Jury feedback</span></span></h2></p><p>Commended for overall excellence, WFP Extreme has a particularly strong focus on cultural and societal dimensions, including concepts like clothing and spiritual spaces. It excels in its cultural and societal considerations, offering some of the most thoughtfully developed ideas in this area. The architectural design introduces advanced technologies such as radiation protection and demonstrates creative touches like the “taxi capsule” and personalized crew clothing. Though system-level coherence and interior design in artificial gravity could be further developed, the structural approach is well-suited to orbital applications. Overall, the project balances technical ambition with a unique and sensitive vision of future space living. This concept is clearly presented through a well-crafted booklet and poster, with strong attention to detail and a distinctive, human-centered aesthetic.</p></div><div data-mesh-id="comp-mdgye4krinlineContent" data-testid="inline-content" id="comp-mdgye4kr" tabindex="-1" data-block-level-container="ClassicSection"><p id="comp-mdgye4kv" data-testid="richTextElement"><h2>3rd Place</h2></p></div><div data-mesh-id="comp-mdinsb6hinlineContent" data-testid="inline-content" id="comp-mdinsb6h" tabindex="-1" data-block-level-container="ClassicSection"><p id="comp-mdinsb6o6" data-testid="richTextElement"><h2><span><span>Team</span></span></h2></p><p>Philip Koshy, Jan Johan Ipe, Amaris Ishana Mathen</p></div><div data-mesh-id="comp-mdinskm3inlineContent" data-testid="inline-content" id="comp-mdinskm3" tabindex="-1" data-block-level-container="ClassicSection"><p id="comp-mdinskma5" data-testid="richTextElement"><h2><span><span>Jury feedback</span></span></h2></p><p>Systema Stellare Proximum distinguishes itself by its immersive storytelling, seamlessly tying together technical, social, and cultural aspects. This concept delivers a rich and imaginative narrative that thoughtfully weaves together social, technical, and cultural aspects of long-term space habitation. Its storytelling is engaging, with creative scenarios that explore community dynamics and even spirituality—emphasizing the role of shared values in building resilient, intergenerational societies. The use of an asteroid as a radiation shield is a bold and compelling strategy, paired with a visually striking structure inspired by the form of a jellyfish. While the physical feasibility of the thin-shelled asteroid could be further refined, the concept shows a solid understanding of cosmic radiation challenges. System-level planning is well-considered, and the presentation is detailed and visually dynamic, enhanced by artistic illustrations. This entry leaves a strong impression through its holistic vision and poetic approach to deep space living.</p></div><div data-mesh-id="comp-mdh02c3sinlineContent" data-testid="inline-content" id="comp-mdh02c3s" tabindex="-1" data-block-level-container="ClassicSection"><p id="comp-mdh02c3x2" data-testid="richTextElement"><h2>Honorable Mentions</h2></p></div><div data-mesh-id="comp-mdmwbvm6inlineContent" data-testid="inline-content" id="comp-mdmwbvm6" tabindex="-1" data-block-level-container="ClassicSection"><p id="comp-mdmwdc1m" data-testid="richTextElement"><h2><span><span>Team</span></span></h2></p><p>David Oliveira Silveira Junior, Natalia dos Santos Mesquita</p></div><div data-mesh-id="comp-mdmwby1oinlineContent" data-testid="inline-content" id="comp-mdmwby1o" tabindex="-1" data-block-level-container="ClassicSection"><p id="comp-mdmwdy9y" data-testid="richTextElement"><h2><span><span>Jury feedback</span></span></h2></p><p>The design demonstrates thoughtful consideration of the time dimension and how the roles and needs of the population may evolve over the life of the habitat—an important and often underexplored aspect of long-term space settlement planning. The use of decoupled artificial gravity through counter-rotating rings is an excellent starting point, showing strong awareness of rotational dynamics and occupant comfort. While the rings are not concentric, which could potentially introduce unwanted torque due to offset centers of gravity, the concept still reflects a solid grasp of key mechanical challenges. The inclusion of maglev-supported habitat wagons enhances system redundancy and safety through multiple pressure vessels. The recognition that curved cylindrical modules would impose structural mass penalties, and the corresponding pivot to straight "sausage"-shaped modules with domed ends, shows a pragmatic engineering approach grounded in realistic structural constraints. Finally, the Mass/Equipment List (MEL) budgets represent a commendable early step in translating the conceptual architecture into quantifiable system requirements.</p></div><div data-mesh-id="comp-mdmwc2hwinlineContent" data-testid="inline-content" id="comp-mdmwc2hw" tabindex="-1" data-block-level-container="ClassicSection"><p id="comp-mdmwi85p" data-testid="richTextElement"><h2><span><span>Team</span></span></h2></p><p>Kyeongjun Na, Haesung Hwang, Hyeonguk Jeon, Hyeonsu Jang, Taemin Eom</p></div><div data-mesh-id="comp-mdmwc4ybinlineContent" data-testid="inline-content" id="comp-mdmwc4yb" tabindex="-1" data-block-level-container="ClassicSection"><p id="comp-mdmwjjka" data-testid="richTextElement"><h2><span><span>Jury feedback</span></span></h2></p><p>Galaxy Express 999 by EBS presents a well-considered approach to social organization, with a practical vision for internal modularity and adaptable living arrangements. The "Negotiopolis" concept is particularly compelling, offering an imaginative civic architecture and a negotiation-based governance model that introduces fresh perspectives on societal structure in an interstellar context. While the design is lighter on technical implementation, it contributes meaningfully to the broader discourse by emphasizing the importance of civic and social aspects. The artificial gravity concept is fundamentally sound, and the linear arrangement of pancake modules along the axis shows clear intent toward modular scalability. Although the pressure vessel design has some limitations—flat-ended cylindrical modules would face significant stress under pressure, requiring heavier structural reinforcement—there is awareness of this issue, as evidenced by partial attempts at incorporating domed ends. A refinement of this aspect, especially for end modules and during descent phases, would strengthen the structural logic. The internal modular system is sensibly developed and shows promise for flexible habitation. Inclusion of a Mass/Equipment List (MEL) would further support the design's technical depth, but the overall concept stands out for its imaginative and socially rich framework.</p></div><div data-mesh-id="comp-mdlanzqyinlineContent" data-testid="inline-content" id="comp-mdlanzqy" tabindex="-1" data-block-level-container="ClassicSection"><p id="comp-mdlanzr46" data-testid="richTextElement"><h2><span><span>Team</span></span></h2></p><p>Antonio Azzolino, Alexandre Goulart, Bianca Montesanti, Juliana Matos, Luciano Ferraresi</p></div><div data-mesh-id="comp-mdlao7s0inlineContent" data-testid="inline-content" id="comp-mdlao7s0" tabindex="-1" data-block-level-container="ClassicSection"><p id="comp-mdlao7s76" data-testid="richTextElement"><h2><span><span>Jury feedback</span></span></h2></p><p>F.A.O.C. presents a strikingly original and compelling concept by embedding a rotating habitat within a mined asteroid shell—a bold architectural move that addresses key deep space challenges with elegance. The approach to radiation protection is particularly noteworthy, standing out as the most robust solution among all entries by leveraging the asteroid's natural mass for shielding. At a systems level, the proposal shows strong conceptual coherence, especially in its vision for interstellar transit and long-term habitat protection. The underlying idea of repurposing an asteroid as both a protective shell and a rotational structure is highly promising and grounded in sound reasoning. The interior storytelling, symbolic layering, and nods to ecological sustainability enrich the narrative quality of the project, making it memorable. F.A.O.C. offers a visionary and well-anchored starting point for future exploration.</p></div><div data-mesh-id="comp-mdlap0h1inlineContent" data-testid="inline-content" id="comp-mdlap0h1" tabindex="-1" data-block-level-container="ClassicSection"><p id="comp-mdlap0h75" data-testid="richTextElement"><h2><span><span>Team</span></span></h2></p><p>Tharshan Maheswaran, Lina Salman, Sergio Santaeufemia Sánchez, Mario Butscher, Jovana Stojković, Branko Drčelić, Seraphine Arnold, Franziska Maier, Anja Rieker, Vanessa Schwaiger</p></div><div data-mesh-id="comp-mdlap7x5inlineContent" data-testid="inline-content" id="comp-mdlap7x5" tabindex="-1" data-block-level-container="ClassicSection"><p id="comp-mdlap7xa6" data-testid="richTextElement"><h2><span><span>Jury feedback</span></span></h2></p><p>Helios Ark stands out for its technically and socially comprehensive submission. It demonstrates an exceptional integration of detailed propulsion and life-support systems with robust governance structures, psychological support strategies, and thoughtful mission-phase planning—altogether presenting a design that plausibly supports human life across a 250-year interstellar journey. The architectural layout, featuring three stacked rings behind a wide frontal shield, shows a strong effort to balance artificial gravity and protection. While there are some unresolved questions regarding the interface between inner and outer toroids—particularly how they rotate relative to one another and to any potential non-rotating central axis—the design shows an awareness of the challenges in managing multiple rotational systems. More detailed elaboration of torque balance and spin-up mechanics would improve technical coherence, especially in terms of energy efficiency and long-term operational stability. The large forward shield is a notable feature, offering some protection from frontal impacts. Further consideration of omnidirectional threats in the high-velocity space environment would strengthen the defensive strategy. Overall, Helios Ark remains a standout for its rare balance of engineering depth and human-centered planning, making it one of the most credible and complete visions in the field.</p></div><div data-mesh-id="comp-mdh06jr0inlineContent" data-testid="inline-content" id="comp-mdh06jr0" tabindex="-1" data-block-level-container="ClassicSection"><p id="comp-mdh06m5w2" data-testid="richTextElement"><h2><span><span>Orion</span></span><br>
<span><span><span><span><span>(</span></span></span></span></span><a href="https://www.orbital.design/projects/hyperion" target="_blank" rel="noreferrer noopener"><span><span><span><span><span><span>Link to submission</span></span></span></span></span></span></a><span><span><span><span><span>)</span></span></span></span></span></h2></p><div id="comp-mdh190j6"><p><img loading="lazy" sizes="600px" srcset="https://static.wixstatic.com/media/1dff9e_71347339b4c6440b821520772dd3c88c~mv2.jpg/v1/fill/w_600,h_848,al_c,q_85,usm_0.66_1.00_0.01,enc_avif,quality_auto/Neo-Genesis%20Seed_Poster_Identified.jpg 1x, https://static.wixstatic.com/media/1dff9e_71347339b4c6440b821520772dd3c88c~mv2.jpg/v1/fill/w_1200,h_1696,al_c,q_90,usm_0.66_1.00_0.01,enc_avif,quality_auto/Neo-Genesis%20Seed_Poster_Identified.jpg 2x" id="img_comp-mdh190j6" src="https://static.wixstatic.com/media/1dff9e_71347339b4c6440b821520772dd3c88c~mv2.jpg/v1/fill/w_600,h_848,al_c,q_85,usm_0.66_1.00_0.01,enc_avif,quality_auto/Neo-Genesis%20Seed_Poster_Identified.jpg" alt="Neo-Genesis Seed_Poster_Identified.jpg" width="600" height="848"></p></div><div data-mesh-id="comp-mdlaq5o35inlineContent" data-testid="columns" id="comp-mdlaq5mx"><p id="comp-mdlaq5o44" data-testid="richTextElement"><h2><span><span>Team</span></span></h2></p><p>Elliott Orion Ruzicka, Anna Dovliatidou, Eden Buch Kornreich, Sean Wessels, Thomas Bjelkeman-Pettersson, Sam Ross, Moa Råhlander, James Boullion</p></div></div><div data-mesh-id="comp-mdlaqebzinlineContent" data-testid="inline-content" id="comp-mdlaqebz" tabindex="-1" data-block-level-container="ClassicSection"><p id="comp-mdlaqec46" data-testid="richTextElement"><h2><span><span>Jury feedback</span></span></h2></p><p>Neo-Genesis Seed presents a usefully novel design that balances conceptual depth with practical simplicity. Its drum-shaped architecture, featuring an ellipsoidal pressure vessel, reflects a sound approach to both structural integrity and artificial gravity. The design avoids unnecessary complexity while still incorporating a number of thoughtful and feasible features. Notably, the pressure vessel concept is robust, though the reliance on a single large volume highlights the need for an articulated emergency protocol in the event of a pressure breach—an area worth further development. The thermal management system is particularly distinctive, proposing a creative solution that acknowledges the limitations of convection in an artificial gravity environment. The submission's strength lies in its integration of biocultural systems, ecological logic, and generational storytelling. This holistic perspective on human resilience, mental health, and societal continuity positions Neo-Genesis Seed as a standout in conceptual vision.&nbsp;</p></div><div data-mesh-id="comp-mdh06ol2inlineContent" data-testid="inline-content" id="comp-mdh06ol2" tabindex="-1" data-block-level-container="ClassicSection"><div data-mesh-id="comp-mdlayyy0inlineContent" data-testid="columns" id="comp-mdlayyvq"><p id="comp-mdlayyy2" data-testid="richTextElement"><h2><span><span>Team</span></span></h2></p><p>Chisomo Phiri, Nobukhosi Ngwenya, Lynette Thabo, Mongezi Ncube, Kasalina, Uvir Hansraj</p></div></div><div data-mesh-id="comp-mdlazheminlineContent" data-testid="inline-content" id="comp-mdlazhem" tabindex="-1" data-block-level-container="ClassicSection"><p id="comp-mdlazhes" data-testid="richTextElement"><h2><span><span>Jury feedback</span></span></h2></p><p>Principium Hereditatis presents a richly symbolic and culturally nuanced vision of interstellar life, distinguished by its strong narrative structure, ritual design, and emphasis on storytelling. The sequential modular habitat design—featuring elongated rotating toroids—supports a compelling conceptual arc that aligns the architectural layout with the emotional and psychological phases of embarkation, journey, and arrival. The artificial gravity system appears plausible, demonstrating a thoughtful application of rotational dynamics. The highly elliptical minor cross-sections of the toroidal structures would require substantial reinforcement to counteract the natural tendency of internal pressure to deform them into circular shapes, resulting in significant mass penalties. Overall, the proposal succeeds in offering a poetic and human-centered perspective. Principium Hereditatis' cultural depth and innovative ritual framing make it a valuable and thought-provoking contribution to the conversation on interstellar habitat design.</p></div><div data-mesh-id="comp-mdh06tvoinlineContent" data-testid="inline-content" id="comp-mdh06tvo" tabindex="-1" data-block-level-container="ClassicSection"><div data-mesh-id="comp-mdlb9ppd2inlineContent" data-testid="columns" id="comp-mdlb9po7"><p id="comp-mdlb9ppe5" data-testid="richTextElement"><h2><span><span>Team</span></span></h2></p><p>Alessandro Savina, Simone Tondi, Maria Del Vecchio</p></div><div data-mesh-id="comp-mdlba5ffinlineContent" data-testid="columns" id="comp-mdlba5ed"><p id="comp-mdlba5ff6" data-testid="richTextElement"><h2><span><span>Jury feedback</span></span></h2></p><p>STASS presents a thoughtful and imaginative design supported by a well-articulated methodology and a solid structural overview. One of its most distinctive features is the inclusion of the Five-Point Knowledge Transmission System, which adds a meaningful cultural and educational dimension to the concept—ensuring continuity of knowledge and identity over generations. The design demonstrates good system-level coherence, with particular strengths in its approach to artificial gravity: a rotating toroidal volume paired with two counter-rotating flywheels, enabling efficient spin-up and spin-down using electrical energy rather than propellant. This is a technically sound and elegant solution that enhances long-term sustainability. While the elongated football-shaped geometry provides a striking visual identity. Radiation and impact protection strategies are addressed, including consideration of current TRLs, though the radiation shielding appears less robust compared to leading entries. The use of elliptical minor toroid cross-sections presents potential structural inefficiencies due to internal pressure forces that coulb e mitigated by the integration of residential spheres. Culturally, the concept leans into a somewhat mythical aesthetic. However, many of its themes—particularly those related to legacy and intergenerational knowledge—are highly relevant to interstellar missions. The interior designs contribute to an evocative and atmospheric presentation. The final layout is clean, visually engaging, and easy to navigate. Overall, STASS stands out for its narrative richness and coherent systems thinking, with room for further refinement in structural and radiation strategies.</p></div></div><div data-mesh-id="comp-mdh06yo4inlineContent" data-testid="inline-content" id="comp-mdh06yo4" tabindex="-1" data-block-level-container="ClassicSection"><p id="comp-mdh0710x" data-testid="richTextElement"><h2><span><span>The Belgian Space Hikers</span></span><br>
<span><span><span><span><span>(<span><a href="https://www.projecthyperion.org/_files/ugd/1dff9e_1e78cf9fe7614e30bc74c0a438c74e1e.pdf" target="_blank">Link to submission</a></span>)</span></span></span></span></span></h2></p><div id="comp-mdh1af5o"><p><img loading="lazy" sizes="600px" srcset="https://static.wixstatic.com/media/1dff9e_c9097127e00a4dd0949aa577996eecf1~mv2.jpg/v1/fill/w_600,h_848,al_c,q_85,usm_0.66_1.00_0.01,enc_avif,quality_auto/Belgian.jpg 1x, https://static.wixstatic.com/media/1dff9e_c9097127e00a4dd0949aa577996eecf1~mv2.jpg/v1/fill/w_1200,h_1696,al_c,q_90,usm_0.66_1.00_0.01,enc_avif,quality_auto/Belgian.jpg 2x" id="img_comp-mdh1af5o" src="https://static.wixstatic.com/media/1dff9e_c9097127e00a4dd0949aa577996eecf1~mv2.jpg/v1/fill/w_600,h_848,al_c,q_85,usm_0.66_1.00_0.01,enc_avif,quality_auto/Belgian.jpg" alt="Belgian.jpg" width="600" height="848"></p></div><div data-mesh-id="comp-mdlbe1e0inlineContent" data-testid="columns" id="comp-mdlbe1d1"><p id="comp-mdlbe1e1" data-testid="richTextElement"><h2><span><span>Team</span></span></h2></p><div id="comp-mdlbe1e15" data-testid="richTextElement"><p>Jan Beeldens, Caroline Gerard, Natalie De Backer, Pieter Verberck, Jan Van den Broeck, Brecht Caers, Eva Verhelle, Eva Burm, Jonathan Van Cauwenberge</p>

<p><span>​</span></p>

<p>Advisors: Erwin Verstraelen (VP Innovation Port of Antwerp-Bruges), Johan De Greeve (Sr. Director Engineering KLA ICOS Division), Marleen Ramaekers (Accountmanager Plastics2Chemicals at Indaver), Tom Monballiu (International networks manager Port of Antwerp-Bruges), Christophe Roes (E&amp;I engineering Director at Agidens), …</p></div></div><div data-mesh-id="comp-mdlbekoj5inlineContent" data-testid="columns" id="comp-mdlbeknk"><p id="comp-mdlbekok2" data-testid="richTextElement"><h2><span><span>Jury feedback</span></span></h2></p><p>The Belgian Space Hikers provide a highly creative and well-presented design that ranks as one of the top submissions. It stands out for its exceptional balance and completeness, showcasing a strong integration of architectural innovation, social systems, and technical feasibility. The dual-torus habitat, combined with layered AI governance and thoughtfully designed educational and civic spaces, reflects a mature and holistic approach to interstellar living. While it may not push the boundaries with radical innovations, its clarity, coherence, and attention to detail across all domains establish it as a model of design excellence. The internal modular habitat system is particularly well-developed, supporting adaptability and long-term habitation. Although more detailed drawings of the rotating toroids and overall vessel design would aid in deeper technical evaluation, The Belgian Space Hikers impress with their well-rounded and practical vision.</p></div></div><div data-mesh-id="comp-mdh0sjr1inlineContent" data-testid="inline-content" id="comp-mdh0sjr1" tabindex="-1" data-block-level-container="ClassicSection"><p id="comp-mdlfhwa4" data-testid="richTextElement"><h2><span><span>undagila</span></span><br>
<span><span><span><span><span>(<span><a href="https://www.projecthyperion.org/_files/ugd/1dff9e_a4afb10c71f04f94a5aed8e8aa68e391.pdf" target="_blank">Link to submission</a></span>)</span></span></span></span></span></h2></p><div id="comp-mdr6esxv"><p><img loading="lazy" sizes="600px" srcset="https://static.wixstatic.com/media/1dff9e_7bf72d27e9f04c099516aefe2c6d1d54~mv2.png/v1/fill/w_600,h_849,al_c,q_90,usm_0.66_1.00_0.01,enc_avif,quality_auto/undagila_submission_A0%20Panel%20thumbnail.png 1x, https://static.wixstatic.com/media/1dff9e_7bf72d27e9f04c099516aefe2c6d1d54~mv2.png/v1/fill/w_1200,h_1698,al_c,q_95,usm_0.66_1.00_0.01,enc_avif,quality_auto/undagila_submission_A0%20Panel%20thumbnail.png 2x" id="img_comp-mdr6esxv" src="https://static.wixstatic.com/media/1dff9e_7bf72d27e9f04c099516aefe2c6d1d54~mv2.png/v1/fill/w_600,h_849,al_c,q_90,usm_0.66_1.00_0.01,enc_avif,quality_auto/undagila_submission_A0%20Panel%20thumbnail.png" alt="undagila_submission_A0 Panel thumbnail.png" width="600" height="849"></p></div><div data-mesh-id="comp-mdlbh4sq2inlineContent" data-testid="columns" id="comp-mdlbh4rr"><p id="comp-mdlbh4sr4" data-testid="richTextElement"><h2><span><span>Team</span></span></h2></p><p>Made &nbsp;Wigana, Bonar Yeshurn, Steven Gilberto, Naradhipati Andaru</p></div><div data-mesh-id="comp-mdlbhbwninlineContent" data-testid="columns" id="comp-mdlbhbva"><p id="comp-mdlbhbwo1" data-testid="richTextElement"><h2><span><span>Jury feedback</span></span></h2></p><p>Sriwijaya is a creative and well-presented concept that offers a deeply poetic and culturally immersive vision. It thoughtfully emphasizes intergenerational continuity, ritual, and symbolic heritage, crafting a socially resilient and meaningful culture suited for a long-duration mission. While the technical systems are not extensively detailed, the proposal excels in its focus on the human and cultural dimensions of interstellar habitation. The design may incorporate a rotating ring structure, though the drawings seem to leave this open. The internal modular habitat system is well-developed, supporting flexible and adaptable living spaces. Additional detailed drawings of the overall vessel would help provide a clearer technical assessment. Overall, Sriwijaya stands out for its rich cultural narrative and strong social vision.</p></div></div><div data-mesh-id="comp-mdh0su0kinlineContent" data-testid="inline-content" id="comp-mdh0su0k" tabindex="-1" data-block-level-container="ClassicSection"><div data-mesh-id="comp-mdlbiwaa2inlineContent" data-testid="columns" id="comp-mdlbiw92"><p id="comp-mdlbiwab" data-testid="richTextElement"><h2><span><span>Team</span></span></h2></p><p>Fatemeh Mosavi, Nafise Etemadi Idgahi, Saeed Vahdani, Negar Radfar, Elham Yousefi, Ahmad Eltaf Zhian, Mobina Fallah Gavareshk, Fatemeh Barzegar, Negar Ahmadpour, Ali Seddighi, Mahdieh Hosseinpour</p></div><div data-mesh-id="comp-mdlbj6us6inlineContent" data-testid="columns" id="comp-mdlbj6tk"><p id="comp-mdlbj6ut5" data-testid="richTextElement"><h2><span><span>Jury feedback</span></span></h2></p><p>This submission offers an interesting and ambitious design, with modularity as a core concept—an approach that generally supports flexibility and resilience. It stands out as one of the most integrated proposals seen so far, demonstrating strength across architecture, engineering, and social systems, and embodying the spirit of envisioning a generation ship that balances speculative vision with system-level coherence. The DNA-shaped vessel and the arrangement of globular habitats linked in a spiral pattern are visually and conceptually intriguing. The pressure vessel design is solid, and the artificial gravity approach appears generally sound, though some visual elements—such as people walking on the zero-g core cylinder walls—may overstate the effective gravity in those areas. The abundance of AI-generated images contributes to a striking but somewhat disjointed presentation; many visuals lack clear correspondence to detailed drawings. The mission control center design also feels somewhat unconventional, with its wide floor facing a circular windshield, which may merit further reconsideration. Overall, the submission impresses with its ambitious scope and integration. It may benefit from clearer technical documentation and tighter alignment between visuals and engineering details.</p></div></div><div data-mesh-id="comp-m56ptqfoinlineContent" data-testid="inline-content" id="comp-m56ptqfo" tabindex="-1" data-block-level-container="ClassicSection"><p id="comp-m56ptqgo1" data-testid="richTextElement"><h2><span><span>Q&amp;A</span></span></h2></p><p><span>Please feel free to ask your questions on our Discord Server.</span></p></div><div data-mesh-id="comp-m4pnzqv8inlineContent" data-testid="inline-content" id="comp-m4pnzqv8" tabindex="-1" data-block-level-container="ClassicSection"><p id="comp-m4pnzqvr" data-testid="richTextElement"><h2><span><span>About Us</span></span></h2></p><p>Project Hyperion works on a preliminary study that defines integrated concepts for a crewed interstellar starship or generation ship. The study aims to provide an assessment of the feasibility of crewed interstellar flight using current and near-future technologies. It also aims to guide future research and technology development plans as well as to inform the public about crewed interstellar travel.</p></div><div id="comp-m4po1uz2" data-testid="inline-content" data-mesh-id="comp-m4po1uz2inlineContent" tabindex="-1" data-block-level-container="ClassicSection"><p>We are an international, interdisciplinary team with expertise in architecture, engineering, anthropology, and urban planning.&nbsp;</p>



<p>We've had the privilege of working with some of the biggest names in R&amp;D, including NASA, ESA, and MIT. Our expertise in interstellar travel has earned us a reputation as leaders in our field.</p></div><div data-mesh-id="comp-m4po2warinlineContent" data-testid="inline-content" id="comp-m4po2war" tabindex="-1" data-block-level-container="ClassicSection"><p id="comp-m4po2wbi" data-testid="richTextElement"><h2><span><span>Organisation Team</span></span></h2></p><div id="comp-m4po2wbs1"><fluid-columns-repeater horizontal-gap="30" vertical-gap="30" justify-content="center" container-id="comp-m4po2wbs1_wrapper" items="8" role="list" direction="ltr"><div data-mesh-id="comp-m4po2wbv2__item1inlineContent" data-testid="inline-content" id="comp-m4po2wbv2__item1"><p><a data-testid="linkElement" href="https://www.linkedin.com/in/andreas-hein-7b19bb2/" target="_blank" rel="noreferrer noopener"><img loading="lazy" sizes="443px" srcset="https://static.wixstatic.com/media/1dff9e_af9a11c38d0648648c81c23fe4788499~mv2.png/v1/fill/w_443,h_445,al_c,lg_1,q_85,enc_avif,quality_auto/image.png 1x, https://static.wixstatic.com/media/1dff9e_af9a11c38d0648648c81c23fe4788499~mv2.png/v1/fill/w_460,h_462,al_c,lg_1,q_85,enc_avif,quality_auto/image.png 2x" id="img_comp-m4po2wby1__item1" src="https://static.wixstatic.com/media/1dff9e_af9a11c38d0648648c81c23fe4788499~mv2.png/v1/fill/w_443,h_445,al_c,lg_1,q_85,enc_avif,quality_auto/image.png" alt="image.png" width="443" height="445"></a></p><p><span>Aerospace engineer</span></p></div><div data-mesh-id="comp-m4po2wbv2__item-j9r9uz7einlineContent" data-testid="inline-content" id="comp-m4po2wbv2__item-j9r9uz7e"><p><a data-testid="linkElement" href="https://www.linkedin.com/in/yazgi-demirbas-pech-3509a196/" target="_blank" rel="noreferrer noopener"><img loading="lazy" sizes="443px" srcset="https://static.wixstatic.com/media/1dff9e_379f15c7655b4dfe98833b8dbb0d15fe~mv2.jpg/v1/fill/w_443,h_445,al_c,q_80,usm_0.66_1.00_0.01,enc_avif,quality_auto/Yazgi2_edited.jpg 1x, https://static.wixstatic.com/media/1dff9e_379f15c7655b4dfe98833b8dbb0d15fe~mv2.jpg/v1/fill/w_843,h_847,al_c,q_85,enc_avif,quality_auto/Yazgi2_edited.jpg 2x" id="img_comp-m4po2wby1__item-j9r9uz7e" src="https://static.wixstatic.com/media/1dff9e_379f15c7655b4dfe98833b8dbb0d15fe~mv2.jpg/v1/fill/w_443,h_445,al_c,q_80,usm_0.66_1.00_0.01,enc_avif,quality_auto/Yazgi2_edited.jpg" alt="Yazgi2_edited.jpg" width="443" height="445"></a></p><p><span>Architect, Illustrator, Designer</span></p></div><div data-mesh-id="comp-m4po2wbv2__item-j9r9uxnsinlineContent" data-testid="inline-content" id="comp-m4po2wbv2__item-j9r9uxns"><p><a data-testid="linkElement" href="https://www.linkedin.com/in/iamdrfries/" target="_blank" rel="noreferrer noopener"><img loading="lazy" sizes="443px" srcset="https://static.wixstatic.com/media/1dff9e_e7f8c833138941acb2ea69ff042b5657~mv2.jpg/v1/fill/w_443,h_445,al_c,q_80,usm_0.66_1.00_0.01,enc_avif,quality_auto/DanF2_BW_edited.jpg 1x, https://static.wixstatic.com/media/1dff9e_e7f8c833138941acb2ea69ff042b5657~mv2.jpg/v1/fill/w_822,h_826,al_c,q_85,enc_avif,quality_auto/DanF2_BW_edited.jpg 2x" id="img_comp-m4po2wby1__item-j9r9uxns" src="https://static.wixstatic.com/media/1dff9e_e7f8c833138941acb2ea69ff042b5657~mv2.jpg/v1/fill/w_443,h_445,al_c,q_80,usm_0.66_1.00_0.01,enc_avif,quality_auto/DanF2_BW_edited.jpg" alt="DanF2_BW_edited.jpg" width="443" height="445"></a></p><p><span>Aerospace Engineer, Researcher</span></p></div><div data-mesh-id="comp-m4po2wbv2__item-kdzpu1loinlineContent" data-testid="inline-content" id="comp-m4po2wbv2__item-kdzpu1lo"><p><a data-testid="linkElement" href="https://pdx.academia.edu/CameronMSmith" target="_blank" rel="noreferrer noopener"><img loading="lazy" sizes="443px" srcset="https://static.wixstatic.com/media/1dff9e_6fa774e8b8df49feb08cd484d5e6d895~mv2.jpg/v1/fill/w_287,h_288,al_c,lg_1,q_80,enc_avif,quality_auto/smith_edited.jpg 1x, https://static.wixstatic.com/media/1dff9e_6fa774e8b8df49feb08cd484d5e6d895~mv2.jpg/v1/fill/w_287,h_288,al_c,lg_1,q_80,enc_avif,quality_auto/smith_edited.jpg 2x" id="img_comp-m4po2wby1__item-kdzpu1lo" src="https://static.wixstatic.com/media/1dff9e_6fa774e8b8df49feb08cd484d5e6d895~mv2.jpg/v1/fill/w_287,h_288,al_c,lg_1,q_80,enc_avif,quality_auto/smith_edited.jpg" alt="smith_edited.jpg" width="443" height="445"></a></p><p><span>Anthropologist</span></p></div><div data-mesh-id="comp-m4po2wbv2__item-kdzpu26iinlineContent" data-testid="inline-content" id="comp-m4po2wbv2__item-kdzpu26i"><p><a data-testid="linkElement" href="https://sites.google.com/view/worldships/accueil?authuser=0" target="_blank" rel="noreferrer noopener"><img loading="lazy" sizes="443px" srcset="https://static.wixstatic.com/media/1dff9e_4b7865bc8ee64dc08cadbdde77046f85~mv2.jpg/v1/fill/w_223,h_224,al_c,lg_1,q_80,enc_avif,quality_auto/michel.jpg 1x, https://static.wixstatic.com/media/1dff9e_4b7865bc8ee64dc08cadbdde77046f85~mv2.jpg/v1/fill/w_223,h_224,al_c,lg_1,q_80,enc_avif,quality_auto/michel.jpg 2x" id="img_comp-m4po2wby1__item-kdzpu26i" src="https://static.wixstatic.com/media/1dff9e_4b7865bc8ee64dc08cadbdde77046f85~mv2.jpg/v1/fill/w_223,h_224,al_c,lg_1,q_80,enc_avif,quality_auto/michel.jpg" alt="michel.jpg" width="443" height="445"></a></p><p><span>Illustrator, Designer</span></p></div><div data-mesh-id="comp-m4po2wbv2__item-kdzpu0y3inlineContent" data-testid="inline-content" id="comp-m4po2wbv2__item-kdzpu0y3"><p><a data-testid="linkElement" href="https://www.linkedin.com/in/maciej-r%C4%99bisz-8a063014b/?originalSubdomain=pl" target="_blank" rel="noreferrer noopener"><img loading="lazy" sizes="443px" srcset="https://static.wixstatic.com/media/1dff9e_bce512bd877a47c7a34dfa6aa367d296~mv2.jpg/v1/fill/w_443,h_445,al_c,q_80,usm_0.66_1.00_0.01,enc_avif,quality_auto/1475766803_480x480%20(1).jpg 1x, https://static.wixstatic.com/media/1dff9e_bce512bd877a47c7a34dfa6aa367d296~mv2.jpg/v1/fill/w_573,h_576,al_c,lg_1,q_80,enc_avif,quality_auto/1475766803_480x480%20(1).jpg 2x" id="img_comp-m4po2wby1__item-kdzpu0y3" src="https://static.wixstatic.com/media/1dff9e_bce512bd877a47c7a34dfa6aa367d296~mv2.jpg/v1/fill/w_443,h_445,al_c,q_80,usm_0.66_1.00_0.01,enc_avif,quality_auto/1475766803_480x480%20(1).jpg" alt="1475766803_480x480 (1).jpg" width="443" height="445"></a></p><p><span>Concept Artist</span></p></div><div data-mesh-id="comp-m4po2wbv2__item-lyltt6tbinlineContent" data-testid="inline-content" id="comp-m4po2wbv2__item-lyltt6tb"><div id="comp-m4po2wby1__item-lyltt6tb"><p><img loading="lazy" sizes="443px" srcset="https://static.wixstatic.com/media/1dff9e_9cbbb132bfc3496da900c91bd74f1ee2~mv2.png/v1/fill/w_420,h_421,al_c,lg_1,q_85,enc_avif,quality_auto/Steve_PNG.png 1x, https://static.wixstatic.com/media/1dff9e_9cbbb132bfc3496da900c91bd74f1ee2~mv2.png/v1/fill/w_420,h_421,al_c,lg_1,q_85,enc_avif,quality_auto/Steve_PNG.png 2x" id="img_comp-m4po2wby1__item-lyltt6tb" src="https://static.wixstatic.com/media/1dff9e_9cbbb132bfc3496da900c91bd74f1ee2~mv2.png/v1/fill/w_420,h_421,al_c,lg_1,q_85,enc_avif,quality_auto/Steve_PNG.png" alt="Steve.PNG" width="443" height="445"></p></div><p><span>Landscape Architect</span></p></div><div data-mesh-id="comp-m4po2wbv2__item-m2z0mqdhinlineContent" data-testid="inline-content" id="comp-m4po2wbv2__item-m2z0mqdh"><div id="comp-m4po2wby1__item-m2z0mqdh"><p><img loading="lazy" sizes="443px" srcset="https://static.wixstatic.com/media/1dff9e_1904a77362f548f483262e18d83cd364~mv2.jpg/v1/fill/w_443,h_445,al_c,q_80,usm_0.66_1.00_0.01,enc_avif,quality_auto/linda_edited.jpg 1x, https://static.wixstatic.com/media/1dff9e_1904a77362f548f483262e18d83cd364~mv2.jpg/v1/fill/w_579,h_582,al_c,lg_1,q_80,enc_avif,quality_auto/linda_edited.jpg 2x" id="img_comp-m4po2wby1__item-m2z0mqdh" src="https://static.wixstatic.com/media/1dff9e_1904a77362f548f483262e18d83cd364~mv2.jpg/v1/fill/w_443,h_445,al_c,q_80,usm_0.66_1.00_0.01,enc_avif,quality_auto/linda_edited.jpg" alt="linda_edited.jpg" width="443" height="445"></p></div><p><span>Architect</span></p></div></fluid-columns-repeater></div></div><div data-mesh-id="comp-m4po3qo8inlineContent" data-testid="inline-content" id="comp-m4po3qo8" tabindex="-1" data-block-level-container="ClassicSection"><p id="comp-m4po3qot3" data-testid="richTextElement"><h2><span>Organizer</span></h2></p><p><a data-testid="linkElement" href="https://i4is.org/" target="_blank" rel="noreferrer noopener"><img loading="lazy" sizes="153px" srcset="https://static.wixstatic.com/media/91ab16_cfcb7ce2c0744cae897f3d8ef418cf91~mv2.png/v1/fill/w_153,h_140,al_c,q_85,usm_0.66_1.00_0.01,enc_avif,quality_auto/I4IS-Logo-Transparent.png 1x, https://static.wixstatic.com/media/91ab16_cfcb7ce2c0744cae897f3d8ef418cf91~mv2.png/v1/fill/w_306,h_280,al_c,q_85,usm_0.66_1.00_0.01,enc_avif,quality_auto/I4IS-Logo-Transparent.png 2x" id="img_comp-m4po3qov4" src="https://static.wixstatic.com/media/91ab16_cfcb7ce2c0744cae897f3d8ef418cf91~mv2.png/v1/fill/w_153,h_140,al_c,q_85,usm_0.66_1.00_0.01,enc_avif,quality_auto/I4IS-Logo-Transparent.png" alt="I4IS-Logo-Transparent.png" width="153" height="140"></a></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Litestar is worth a look (322 pts)]]></title>
            <link>https://www.b-list.org/weblog/2025/aug/06/litestar/</link>
            <guid>44816755</guid>
            <pubDate>Wed, 06 Aug 2025 19:43:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.b-list.org/weblog/2025/aug/06/litestar/">https://www.b-list.org/weblog/2025/aug/06/litestar/</a>, See on <a href="https://news.ycombinator.com/item?id=44816755">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
      




<!--
 If this entry is assigned to one or more categories, they'll appear
 in links in the paragraph below. Each of those links uses
 rel="category" to indicate it's a link to a category.

 See http://microformats.org/wiki/rel-category for details.
-->
<p>
  <a href="https://www.b-list.org/weblog/2025/aug/06/">  <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" viewBox="0 0 16 16">
    <title>Published on:</title>
    <path d="M3.5 0a.5.5 0 0 1 .5.5V1h8V.5a.5.5 0 0 1 1 0V1h1a2 2 0 0 1 2 2v11a2 2 0 0 1-2 2H2a2 2 0 0 1-2-2V3a2 2 0 0 1 2-2h1V.5a.5.5 0 0 1 .5-.5M1 4v10a1 1 0 0 0 1 1h12a1 1 0 0 0 1-1V4z"></path>
    </svg>
August 6, 2025</a>
  &nbsp;&nbsp;
  <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" viewBox="0 0 16 16">
    <title>Categories:</title>
    <path d="M3 2v4.586l7 7L14.586 9l-7-7zM2 2a1 1 0 0 1 1-1h4.586a1 1 0 0 1 .707.293l7 7a1 1 0 0 1 0 1.414l-4.586 4.586a1 1 0 0 1-1.414 0l-7-7A1 1 0 0 1 2 6.586z"></path>
    <path d="M5.5 5a.5.5 0 1 1 0-1 .5.5 0 0 1 0 1m0 1a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3M1 7.086a1 1 0 0 0 .293.707L8.75 15.25l-.043.043a1 1 0 0 1-1.414 0l-7-7A1 1 0 0 1 0 7.586V3a1 1 0 0 1 1-1z"></path>
  </svg>
  <a rel="category" href="https://www.b-list.org/weblog/categories/django/">Django</a>, <a rel="category" href="https://www.b-list.org/weblog/categories/python/">Python</a>
</p>
  
<p>A few years ago at work, I had a project which offered an opportunity to look at the new generation of async-first, type-hint-driven Python web frameworks. For reasons which aren’t particularly relevant today, on that project I ended up choosing <a href="https://litestar.dev/">Litestar</a>, which is the one that <em>doesn’t</em> have a ravenous all-consuming hype machine surrounding it. And I’m very glad I did, because today I’m more convinced than ever it was the right choice, and for the last 18 months or so every new project I’ve started at my day job has been built with&nbsp;Litestar.</p>
<p>But even if you’re someone who does Python web apps for a living, and even if you’re someone who builds asynchronous type-hint-driven web apps, you might not be familiar with this absolute gem of the Python web ecosystem, and today I want to remedy&nbsp;that.</p>
<h2>A&nbsp;taste</h2>
<p>Here’s the traditional single-file-app&nbsp;demo:</p>
<div><pre><span></span><code><span>from</span><span> </span><span>litestar</span><span> </span><span>import</span> <span>Litestar</span><span>,</span> <span>get</span>


<span>@get</span><span>(</span><span>"/greet"</span><span>)</span>
<span>async</span> <span>def</span><span> </span><span>greet</span><span>(</span><span>name</span><span>:</span> <span>str</span><span>)</span> <span>-&gt;</span> <span>str</span><span>:</span>
    <span>return</span> <span>f</span><span>"Hi, </span><span>{</span><span>name</span><span>}</span><span>!"</span>


<span>app</span> <span>=</span> <span>Litestar</span><span>([</span><span>greet</span><span>])</span>
</code></pre></div>

<p>You save this&nbsp;as <code>app.py</code>, run&nbsp;with <code>litestar run</code> or hand it directly to the <abbr title="Asynchronous Server Gateway Interface"><span>ASGI</span></abbr> server of your choice, and it launches a web application. You go&nbsp;to <code>/greet?name=Bob</code> and it replies “Hi, Bob!”. Leave out&nbsp;the <code>name</code> parameter and it responds with an <span>HTTP</span> 400 telling you&nbsp;the <code>name</code> parameter is&nbsp;required.</p>
<p>So what. Big deal. The FastAPI Evangelism Strike Force will be along soon to bury you under rocket-ship emoji while explaining that FastAPI does the same thing but a million times better. And if you’re a Java person used to Spring, or a .<span>NET</span>  person used to <span>ASP</span>.<span>NET</span> <span>MVC</span>, well, there’s nothing here that’s new to you; you’ve had this style of annotation/signature-driven framework for years (and in fact one thing I like about Litestar is how often it reminds me of the good parts of those frameworks). And did anyone tell you FastAPI does this, too!&nbsp;🚀🚀🚀🚀🚀🚀🚀🚀🚀</p>
<p>But there are a lot of things that make Litestar stand out to me in the Python world. I’m going to pick out three to talk about today, and one of them is hiding in plain sight in that simple example&nbsp;application.</p>
<div>
<p><strong>What’s in a&nbsp;name?</strong></p>
<p>You might see older material referring to Litestar as “Starlite”, which was its original&nbsp;name.</p>
<p><a href="https://www.starlette.io/">Starlette</a> is a toolkit for doing async Python web development, which can be used standalone or as a component in a more complex library or framework. FastAPI still uses Starlette under the hood, for example. And Litestar originally was built on Starlette too, and was named “Starlite”, presumably in recognition of that. Over time, though, it dropped the Starlette dependency in favor of its own implementations for that functionality, and people on social media complained that the “Starlite” name was confusing, especially since Star<em>lette</em> was no longer being used. So the project which had been “Starlite” was renamed to Litestar for version 2.0, released in 2023, and has had that name ever&nbsp;since.</p>
</div>
<h3>Scaling (the other&nbsp;kind)</h3>
<p>It’s a bit unfortunate that the term “scaling” is almost always assumed to mean handling larger and larger quantities of traffic, because that’s only one axis on which any given piece of of technology can “scale” (and, I’d argue, possibly the least important one). The type of scaling I want to talk about here is scaling of a codebase: how does something (in this case, a web framework) help or hinder you as you deal with different amounts of&nbsp;code?</p>
<p>Django, for example, has a reputation for not scaling “down” all that well. You <em>can</em> do it if you really want to, and every so often someone will come up with a new demo of doing a Django project in a single Python file, but it’s just not something that comes naturally to Django. Quite the opposite: if you work through the official beginner Django tutorial and do things the “Django way”, you’ll have around a dozen files laid out in a specific structure of directories and subdirectories before you’ve written a single meaningful line of your own&nbsp;code. </p>
<p>But “micro” frameworks have often had the opposite problem: they’re great at starting out with a tiny single-file application, and then get painful as your codebase grows and needs to spread out (single-file Django approaches have the same problem: you have to do a lot of work to get a “micro-Django” working, and then you have to <em>undo</em> all that work as soon as the code grows large enough to be worth splitting across multiple&nbsp;files).</p>
<p>Let’s look at an example. Here’s a FastAPI equivalent of the basic Litestar application I showed&nbsp;above:</p>
<div><pre><span></span><code><span>from</span><span> </span><span>fastapi</span><span> </span><span>import</span> <span>FastAPI</span>


<span>app</span> <span>=</span> <span>FastAPI</span><span>()</span>

<span>@app</span><span>.</span><span>get</span><span>(</span><span>"/greet"</span><span>)</span>
<span>async</span> <span>def</span><span> </span><span>greet</span><span>(</span><span>name</span><span>:</span> <span>str</span><span>)</span> <span>-&gt;</span> <span>str</span><span>:</span>
    <span>return</span> <span>f</span><span>"Hello, </span><span>{</span><span>name</span><span>}</span><span>!"</span>
</code></pre></div>

<p>Notice that&nbsp;the <code>get()</code> decorator here is attached to the application object. This is a common pattern (Flask/Quart do the same thing, for example, and Starlette used to but has deprecated its entire decorator-based routing system), but it creates a problem once you have multiple files. You need to import the main application object into the other files in order to decorate the routes, but you need to import the other files into your “main” application file to make sure the route registrations are visible from there, and now you have a circular import, and that doesn’t&nbsp;work.</p>
<p>The general solution these frameworks offer is some sort of alternative sub-application object which can act as a per-file route registry that’s safe to import into the file where your application object is defined. FastAPI calls this object an “<span>API</span> router”; Flask/Quart call it a “blueprint”. Either way, it’s a necessary construct for those frameworks because their route decorators are always bound to some parent object, either the application object in a single-file app or an “<span>API</span> router”/“blueprint”/etc. object in a multi-file&nbsp;app.</p>
<p>That solves the circular-import problem, but creates a new issue: the whiz-bang quickstart demos of “micro” frameworks generally register all the example routes on the application object in a single file in order to keep everything as simple and flashy as possible, but now in order to build a real application (which will almost never stay in a single file) you’ll need to use a different mechanism, or start out following the demo and then switch later on. You also have to <em>know</em> about that different mechanism; in one framework’s documentation that I looked at, you can (at the time I’m writing this post) apparently get 40 pages into the user guide before encountering the section on how to register routes in a multi-file app&nbsp;😖😖😖.</p>
<p>Litestar avoids this entire mess by having the route decorators be standalone functions, not bound to a parent application or application-like object. This may seem like a small thing to focus on, but if you’ve spent time with popular Python microframeworks you’ve probably had to deal with the transition from single- to multi-file&nbsp;applications.</p>
<p>More importantly, this small change in approach frees up Litestar’s documentation to introduce route-grouping constructs early on and to present them as part of <a href="https://docs.litestar.dev/latest/usage/applications.html#layered-architecture">a coherent layered architecture/configuration concept</a> rather than as an escape hatch for avoiding circular imports. Which is great, because Litestar’s layered architecture is one of its best features: its grouping constructs, and their ability to share configuration, offer an elegant way to compose functionality. For example, a common pattern I use when writing a set of <abbr title="Create, Retrieve, Update, Delete"><span>CRUD</span></abbr> endpoints looks like&nbsp;this:</p>
<div><pre><span></span><code><span>from</span><span> </span><span>litestar</span><span> </span><span>import</span> <span>Router</span>
<span>from</span><span> </span><span>litestar.di</span><span> </span><span>import</span> <span>Provide</span>

<span># Imagine some CRUD routes for widgets defined here...</span>

<span>_write_widget_router</span> <span>=</span> <span>Router</span><span>(</span>
    <span>guards</span><span>=</span><span>[</span><span>some_auth_function</span><span>],</span>
    <span>route_handlers</span><span>=</span><span>[</span>
        <span>create_widget</span><span>,</span>
        <span>delete_widget</span><span>,</span>
        <span>update_widget</span><span>,</span>
    <span>]</span>
<span>)</span>

<span>widget_router</span> <span>=</span> <span>Router</span><span>(</span>
    <span>dependencies</span><span>=</span><span>{</span><span>"widget_dependency"</span><span>:</span> <span>Provide</span><span>(</span><span>some_widget_dependency</span><span>)},</span>
    <span>path</span><span>=</span><span>"/widgets"</span><span>,</span>
    <span>route_handlers</span><span>=</span><span>[</span>
        <span>get_widget</span><span>,</span>
        <span>get_widget_list</span><span>,</span>
        <span>_write_widget_router</span><span>,</span>
    <span>]</span>
<span>)</span>
</code></pre></div>

<p>This provides a single&nbsp;“public” <code>Router</code> instance with all the widget routes, all of which have access to the same core dependencies, but with the data-modifying routes also having auth applied. That composability is extremely powerful, and is less obvious if the “router” has to be introduced initially as a way to solve circular-import&nbsp;problems.</p>
<p>Litestar’s approach also means it’s easy to do things like register a single route multiple times, each with different configuration. Which enables use cases&nbsp;like:</p>
<ul>
<li>Different authentication/authorization schemes for each registration. For example, a data-editing route might be written once, and registered once under a router which applies <span>API</span> key auth for machine-to-machine requests, then registered again under a router which uses session auth for interaction by a human&nbsp;user.</li>
<li>Different sets of dependencies for each registration. For example, a route which queries and returns a list of widgets might just declare that it accepts an argument of&nbsp;type <code>WidgetRepository</code>, and leave it up to the router configuration to decide whether to dependency-inject one that sees all widgets, or perhaps only a subset, or only those which are active,&nbsp;etc.</li>
</ul>
<p>If you know what you’re doing, you can emulate some of this in the FastAPI/Flask style of bound route registration, but the techniques you’ll end up using for that feel to me like fighting against the framework, which is something I usually want to&nbsp;avoid.</p>
<h2>Not to be too&nbsp;Pydantic</h2>
<p><a href="https://docs.pydantic.dev/">Pydantic</a> is a popular package for defining schema objects which perform validation and serialization/deserialization, driven by Python type annotations, and one major use case for this is the input/output schemas of web applications. FastAPI appears to use Pydantic exclusively, which comes with both upsides and downsides. Pydantic is very useful and very powerful, of course, but it also means FastAPI is somewhat limited by what Pydantic can support: mostly, this is Pydantic’s own classes, and <a href="https://docs.python.org/3/library/dataclasses.html">the Python standard&nbsp;library’s <code>dataclasses</code></a>.</p>
<p>One crucial limitation is an inability to derive validation/serialization behavior directly from <a href="https://www.sqlalchemy.org/">SQLAlchemy</a> <abbr title="Object-Relational Mapper"><span>ORM</span></abbr> classes, even though they both support a very similar type-annotation-based declaration format. Which means that to use SQLAlchemy with a Pydantic-only framework (and SQLAlchemy is basically <em>the</em> standard database toolkit and <abbr title="Object-Relational Mapper"><span>ORM</span></abbr> for Python), you either have to write out the shape of your data multiple times—once for SQLAlchemy, and then at least one more time (possibly more than one time) for Pydantic—or turn to a third-party package to help bridge the gap. FastAPI’s author worked around this by writing <a href="https://sqlmodel.tiangolo.com/">a new <span>DB</span> toolkit which combines SQLAlchemy and Pydantic</a>, and pushing it in FastAPI’s&nbsp;documentation.</p>
<p>Litestar, meanwhile, <em>supports</em> Pydantic, but is not <em>tightly coupled to</em> Pydantic, which gives a bit more flexibility. By default Litestar lets you define input/output schemas using Pydantic&nbsp;models, <code>dataclasses</code>, or <a href="https://jcristharif.com/msgspec/">msgspec</a>; ships with plugins to enable the use of <a href="https://www.attrs.org/">attrs</a> and of SQLAlchemy models; and <a href="https://docs.litestar.dev/latest/usage/plugins/index.html#serializationpluginprotocol">provides a protocol for writing your own serialization plugins</a> to extend support to other kinds of&nbsp;objects.</p>
<p>That’s very convenient already, but the convenience is amplified by Litestar’s <a href="https://docs.litestar.dev/latest/usage/dto/1-abstract-dto.html">system for automatically deriving data-transfer objects</a> from data-access or domain objects. Suppose, for example, that we have the following SQLAlchemy model&nbsp;class:</p>
<div><pre><span></span><code><span>from</span><span> </span><span>sqlalchemy.orm</span><span> </span><span>import</span> <span>DeclarativeBase</span><span>,</span> <span>Mapped</span><span>,</span> <span>mapped_column</span>

<span>Base</span> <span>=</span> <span>DeclarativeBase</span><span>()</span>

<span>class</span><span> </span><span>Widget</span><span>(</span><span>Base</span><span>):</span>
    <span>__tablename__</span> <span>=</span> <span>"widget"</span>

    <span>id</span><span>:</span> <span>Mapped</span><span>[</span><span>int</span><span>]</span> <span>=</span> <span>mapped_column</span><span>(</span><span>primary_key</span><span>=</span><span>True</span><span>)</span>
    <span>internal_notes</span><span>:</span> <span>Mapped</span><span>[</span><span>str</span><span>]</span>
    <span>sku</span><span>:</span> <span>Mapped</span><span>[</span><span>str</span><span>]</span> <span>=</span> <span>mapped_column</span><span>(</span><span>unique</span><span>=</span><span>True</span><span>)</span>
    <span>name</span><span>:</span> <span>Mapped</span><span>[</span><span>str</span><span>]</span>
    <span>price_cents</span><span>:</span> <span>Mapped</span><span>[</span><span>int</span><span>]</span>
</code></pre></div>

<p>In a Pydantic-only world, we’d need to write multiple Pydantic models representing different use&nbsp;cases:</p>
<ul>
<li>A “read” schema for use in <span>HTTP</span> responses, which would probably not include&nbsp;the <code>internal_notes</code> field and probably also&nbsp;not <code>id</code> (since <code>sku</code> is more likely to be the public&nbsp;identifier)</li>
<li>A “write” schema for creating widgets, which would&nbsp;exclude <code>id</code> since that likely is auto-generated on&nbsp;insert</li>
<li>Another “write” schema for updating widgets, setting all fields optional to allow partial&nbsp;update</li>
</ul>
<p>As well as possibly more schemas like an admin-view “read” schema that does include the internal fields, etc. Even if you get clever and use inheritance to share field definitions among all these Pydantic classes, you still will write out the full set of fields for widgets at least twice, and the second time it will be fragmented across multiple Pydantic classes, creating the risk of making a change to the <abbr title="Object-Relational Mapper"><span>ORM</span></abbr> model and forgetting to update all the corresponding field definitions in the Pydantic&nbsp;models.</p>
<p>Litestar’s approach is a significant improvement on this. For example, here’s how to use Litestar’s <abbr title="Data Transfer Object"><span>DTO</span></abbr> helpers to define the “read”&nbsp;schema:</p>
<div><pre><span></span><code><span>from</span><span> </span><span>litestar.dto</span><span> </span><span>import</span> <span>DTOConfig</span>
<span>from</span><span> </span><span>litestar.plugins.sqlalchemy</span><span> </span><span>import</span> <span>SQLAlchemyDTO</span>

<span>class</span><span> </span><span>ReadWidget</span><span>(</span><span>SQLAlchemyDTO</span><span>[</span><span>Widget</span><span>]):</span>
    <span>config</span> <span>=</span> <span>DTOConfig</span><span>(</span><span>exclude</span><span>=</span><span>{</span><span>"id"</span><span>,</span> <span>"internal_notes"</span><span>})</span>
</code></pre></div>

<p>This will give you a <abbr title="Data Transfer Object"><span>DTO</span></abbr> class containing all the fields of&nbsp;the <code>Widget</code> <abbr title="Object-Relational Mapper"><span>ORM</span></abbr> model <em>except</em> the two explicitly excluded, and will derive that set of fields, and the correct data types, from&nbsp;introspecting <code>Widget</code>. It will also automatically handle conversion to and from instances&nbsp;of <code>Widget</code> when you specify it as the input or return <abbr title="Data Transfer Object"><span>DTO</span></abbr> type of a route. Similarly, it’s possible to declare a list of fields to include, or to re-map field names for public consumption, or to declare a <abbr title="Data Transfer Object"><span>DTO</span></abbr> which makes fields optional for partial updates. This means there’s only one canonical definition of the fields—on the original class, which might be a SQLAlchemy <abbr title="Object-Relational Mapper"><span>ORM</span></abbr> model, might be&nbsp;a <code>dataclass</code>, etc.—and it doesn’t have to be repeated in the DTOs because the DTOs will always derive their field definitions directly from the source class you point them&nbsp;at.</p>
<p>Of course, there are going to be cases where your DTOs are sufficiently different from your DAOs and domain objects that this isn’t a big help, but my own experience is that “the <abbr title="Data Transfer Object"><span>DTO</span></abbr> is a subset of the <abbr title="Data Access Object"><span>DAO</span></abbr>’s fields” is extremely common in real-world applications, so Litestar’s approach really pays off in both reduced boilerplate and reduced errors from manual “transcription” of fields between different class&nbsp;definitions.</p>
<h2>Alchemical&nbsp;architecture</h2>
<p>I wasn’t exaggerating earlier when I said that SQLAlchemy is <em>the</em> database toolkit and <abbr title="Object-Relational Mapper"><span>ORM</span></abbr> for Python. While there are others out there, the only one I’m aware of that sees anything close to SQLAlchemy’s usage is the Django <abbr title="Object-Relational Mapper"><span>ORM</span></abbr>, and only because it’s built into and tightly integrated with Django. So if you’re going to be writing a database-backed web application in Python, and you’re not doing Django, you are almost certainly going to be using&nbsp;SQLAlchemy.</p>
<p>And Litestar makes that easy. While officially remaining agnostic as to whether you even have a persistence layer, it still includes good integrations for SQLAlchemy: the serialization plugin mentioned earlier allows the direct use of SQLAlchemy <abbr title="Object-Relational Mapper"><span>ORM</span></abbr> classes as input and output schemas; the <abbr title="Data Transfer Object"><span>DTO</span></abbr> helpers can derive subsets and remappings of fields from SQLAlchemy <abbr title="Object-Relational Mapper"><span>ORM</span></abbr> classes; and Litestar also ships with <a href="https://docs.litestar.dev/latest/usage/databases/sqlalchemy/plugins/sqlalchemy_init_plugin.html">a plugin that manages a SQLAlchemy engine and per-request <abbr title="Object-Relational Mapper"><span>ORM</span></abbr> session for you</a>, as well as <a href="https://docs.litestar.dev/latest/usage/databases/sqlalchemy/plugins/sqlalchemy_plugin.html">a single SQLAlchemy mega-plugin</a> combining all the SQLAlchemy plugins’&nbsp;functionality.</p>
<p>So it’s already pretty convenient to use SQLAlchemy in Litestar applications. But there’s more! The Litestar team also maintains <a href="https://docs.advanced-alchemy.litestar.dev/latest/">the excellent Advanced Alchemy library</a> which provides a bunch of useful features on top of SQLAlchemy. While Advanced Alchemy is framework-agnostic, Litestar’s SQLAlchemy plugin makes use of it and re-exports much of its functionality, giving you access to it automatically, and it does include Litestar-specific helpers for registering certain utility classes with Litestar’s dependency&nbsp;injection.</p>
<p>Advanced Alchemy provides a lot of quality-of-life improvements for SQLAlchemy, including a variety of base classes and mixins and data types doing useful things like database-agnostic big-integer primary keys, automatic create/update timestamps, <abbr title="Universally Unique IDentifier"><span>UUID</span></abbr>-keyed models, a proper <abbr title="Coordinated Universal Time"><span>UTC</span></abbr> timestamp type, and a <abbr title="JavaScript Object Notation"><span>JSON</span></abbr> type which chooses the best column type for your database. There are also command-line helpers for database management (including creating and working with <a href="https://alembic.sqlalchemy.org/en/latest/">Alembic migrations</a>), database dumping and seeding to/from <abbr title="JavaScript Object Notation"><span>JSON</span></abbr>, and a lot&nbsp;more.</p>
<p>But the place where Advanced Alchemy really shines is in providing <a href="https://docs.advanced-alchemy.litestar.dev/latest/usage/repositories.html">a generic repository implementation</a> (both sync and async flavors) on top of SQLAlchemy models, along with <a href="https://docs.advanced-alchemy.litestar.dev/latest/usage/services.html">a service-layer abstraction</a> and helpers to integrate them into Litestar’s dependency injection&nbsp;system.</p>
<p>Here’s a basic example using&nbsp;the <code>Widget</code> class from&nbsp;above:</p>
<div><pre><span></span><code><span>from</span><span> </span><span>litestar.plugins.sqlalchemy</span><span> </span><span>import</span> <span>repository</span>

<span>class</span><span> </span><span>WidgetRepository</span><span>(</span><span>repository</span><span>.</span><span>SQLAlchemyAsyncRepository</span><span>[</span><span>Widget</span><span>]):</span>
    <span>model_type</span> <span>=</span> <span>Widget</span>
</code></pre></div>

<p><code>WidgetRepository</code> will have all the methods you’d&nbsp;expect—<code>list()</code>, <code>get_one()</code>, <code>add()</code>, <code>delete()</code>, etc.—automatically derived from&nbsp;the <code>Widget</code> model. And let me just say that having repository implementations automatically derived from any SQLAlchemy model, with not just basic <abbr title="Create, Retrieve, Update, Delete"><span>CRUD</span></abbr> operations but also things like paginated fetches, is a <em>massive</em> productivity boost compared to just using vanilla SQLAlchemy. It’s maybe not quite on the level of Django’s generic views, but it’s a big step in that direction, and you probably could produce something like Django’s generic views with Litestar and Advanced Alchemy if you wanted to (perhaps one day, in my copious free time, I’ll even make an attempt at&nbsp;it).</p>
<p>I know it may seem strange to hear me saying this, since a few years ago I went on record as being strongly <em>against</em> these sorts of abstractions—specifically service layers—in Django. And I still think you absolutely should not try to retrofit repository or service-layer abstractions onto Django! They’re not the native patterns of Django’s architecture, and instead I think you should stick to <a href="https://www.b-list.org/weblog/2020/mar/16/no-service/">what I recommended back then</a>, which is to leverage Django’s own architecture, especially its “manager” abstraction, rather than trying to force abstractions onto it that don’t&nbsp;fit.</p>
<p>I also still think there are a lot of bad use cases for repositories and service layers that people should avoid, but that’s a digression which should probably become its own post, so I’ll just say for now that I think it’s fine to use repositories and service layers <em>as an organizing principle</em> when you’re using a less-structured framework which doesn’t express strong opinions about how you should lay out your code. And that’s exactly what I do when working with&nbsp;Litestar.</p>
<h2>A lightweight star of&nbsp;Python</h2>
<p>There are plenty of other features and conveniences in Litestar, many of which I use daily. Its auth system, supporting both <a href="https://docs.litestar.dev/latest/usage/security/guards.html">simple guard functions</a> and <a href="https://docs.litestar.dev/latest/usage/security/abstract-authentication-middleware.html">middlewares</a> for attaching identity and complex authn/authz logic to requests. Its <a href="https://docs.litestar.dev/latest/usage/stores.html">“stores” framework</a>, which makes caching and similar tasks convenient. Its <a href="https://docs.litestar.dev/latest/usage/logging.html">logging integrations</a> which support both the Python standard&nbsp;library’s <code>logging</code> module and popular third-party tools&nbsp;like <code>structlog</code>. Its built-in support for <a href="https://docs.litestar.dev/latest/usage/plugins/problem_details.html">transforming errors to standard “problem details” structures</a>. Its built-in support for <a href="https://docs.litestar.dev/latest/usage/metrics/index.html">recording and exporting metrics in standard Prometheus or OpenTelemetry formats</a>. Its <a href="https://docs.litestar.dev/latest/usage/htmx.html">htmx support</a>.</p>
<p>You can do this stuff in other microframeworks, but it typically involves a lot of tracking down of third-party add-ons and/or writing your own glue code to integrate things. Litestar manages to keep the “microframework” feel when starting a new project while also having all these nice bits optionally available with the framework itself when and if you decide you want them, and that’s nothing to sneeze at. That’s what I was getting at earlier when I said it reminds me of the things I like in certain frameworks from other languages. Litestar doesn’t feel, to me, like it’s trying to be a replacement for any pre-existing Python web framework. It’s not trying to be the next Django or the next Flask or whatever; instead, it feels to me like a Pythonic take on the good parts of something like Spring Boot (and the way I like to set it up, doing things like using <a href="https://svcs.hynek.me/en/stable/">svcs</a> behind the scenes as a service locator to feed things to both Litestar’s and <a href="https://docs.pytest.org/">pytest’s</a> dependency injection, makes it feel even more that&nbsp;way).</p>
<p>I could go on for a lot longer listing things I like about Litestar, and probably wind up way too far into my own subjective preferences, but hopefully I’ve given you enough of a realistic taste of what it offers that, next time you’re about to build a Python web app, you might decide to reach for 💡⭐ to carry you to the moon&nbsp;🚀🚀🚀.</p>


    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[We'd be better off with 9-bit bytes (173 pts)]]></title>
            <link>https://pavpanchekha.com/blog/9bit.html</link>
            <guid>44816692</guid>
            <pubDate>Wed, 06 Aug 2025 19:39:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pavpanchekha.com/blog/9bit.html">https://pavpanchekha.com/blog/9bit.html</a>, See on <a href="https://news.ycombinator.com/item?id=44816692">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">

<p>
A number of 70s computing systems had nine-bit bytes, most prominently
the PDP-10, but today<sup><a id="fnr.1" href="#fn.1" role="doc-backlink">1</a></sup><span id="fn.1"><sup>1</sup> Apparently, it was the System/360 that
really set the standard here.</span> all systems use 8-bit bytes and that
now seems natural.<sup><a id="fnr.2" href="#fn.2" role="doc-backlink">2</a></sup><span id="fn.2"><sup>2</sup> Though you still see RFCs use "octet", and the
C standard has a <code>CHAR_BITS</code> macro, to handle the possibility of a
different-sized byte.</span> As a power of two, eight is definitely nicer.
But I think a series of historical coincidences would actually go our
way with 9-bit bytes.<sup><a id="fnr.3" href="#fn.3" role="doc-backlink">3</a></sup><span id="fn.3"><sup>3</sup> And, as I say below, I don't think
equivalently bad coincidences would break against us.</span>
</p>

<p>
<b>IPv4</b>: Everyone knows the story: IPv4 had 32-bit addresses, so about 4
billion total.<sup><a id="fnr.4" href="#fn.4" role="doc-backlink">4</a></sup><span id="fn.4"><sup>4</sup> Less due to various reserved subnets.</span> That's not
enough in a world with 8 billion humans, and that's lead to NATs, more
active network middleware, and the impossibly glacial pace of IPv6
roll-out. It's 2025 and Github—Github!—doesn't support IPv6. But in a
world with 9-bit bytes IPv4 would have had 36-bit addresses, about 64
billion total. That would still be enough right now, and even with
continuing growth in India and Africa it would probably be enough for
about a decade more.<sup><a id="fnr.5" href="#fn.5" role="doc-backlink">5</a></sup><span id="fn.5"><sup>5</sup> In our timeline, exhaustion hit in 2011, when
demand was doubling every five years. 16× more addresses gets us to
2031 projecting linearly, and probably a little later with growth
slowing.</span> When exhaustion does set in, it would plausibly at a time
where there's not a lot of growth left in penetration, population, or
devices, and mild market mechanisms instead of NATs would be the
solution.
</p>

<p>
<b>UNIX time</b>: In our timeline, 32-bit UNIX timestamps run out in 2038, so
again all software has to painfully transition to larger, 64-bit
structures. Equivalent 36-bit timestamps last until 3058, so no hurry.
Negative timestamps would represent any time since 882, so could cover
the founding of Kievan Rus', the death of Alfred the Great, the
collapse of the Classic Maya,<sup><a id="fnr.6" href="#fn.6" role="doc-backlink">6</a></sup><span id="fn.6"><sup>6</sup> The people stuck around, but they
stopped building cool cities.</span> and the movement of Magyar tribes into
the Carpathian basin.
</p>

<p>
<b>Unicode</b>: In our universe, there are 65 thousand 16-bit characters,
which looked like <i>maybe</i> enough for all the world's languages, assuming
you're really careful about which Chinese characters you let
in.<sup><a id="fnr.7" href="#fn.7" role="doc-backlink">7</a></sup><span id="fn.7"><sup>7</sup> Known as CJK unification, a real design flaw in Unicode that
we're stuck with.</span> With 9-bit bytes we'd have 262 thousand 18-bit
characters instead, which would totally be enough—there are only 155
thousand Unicode characters today, and that's with all the cat smileys
and emojis we can dream of. UTF-9 would be thought of more as a
compression format and largely sidelined by GZip.<sup><a id="fnr.8" href="#fn.8" role="doc-backlink">8</a></sup><span id="fn.8"><sup>8</sup> Alternatively,
we could lose a bit, be sparing with the cat smileys, and UTF-9 could
be one/two byte like Shift-JIS. That would be pretty attractive.</span>
</p>

<p>
<b>Pointers</b>: In 8-bit byte land, 32-bit operating systems impose a 2 GB
cap on processes,<sup><a id="fnr.9" href="#fn.9" role="doc-backlink">9</a></sup><span id="fn.9"><sup>9</sup> Because the kernel needs the top half of the
memory space.</span> which turns out to be pretty restrictive. 36-bit
operating systems would allow up to 32 GB per process, which even
today would be a big machine; I'm writing this on a four-year-old
Macbook Pro and it only has 16 GB of RAM. Server-class machines would
still need to address more memory than that, but they're usually
running specialized software or virtualizing; databases and
hypervisors are already tricky code and segmentation wouldn't be the
end of the world.<sup><a id="fnr.10" href="#fn.10" role="doc-backlink">10</a></sup><span id="fn.10"><sup>10</sup> Basically, it'd be <a href="https://en.wikipedia.org/wiki/X32_ABI">x32 as the standard</a>.</span> Memory
usage, even measured in bits, would be lower thanks to smaller
pointers<sup><a id="fnr.11" href="#fn.11" role="doc-backlink">11</a></sup><span id="fn.11"><sup>11</sup> So maybe 5% faster per x32 benchmarks?</span> though strings
would be bigger.<sup><a id="fnr.12" href="#fn.12" role="doc-backlink">12</a></sup><span id="fn.12"><sup>12</sup> So overall, maybe a wash?</span>
</p>

<p>
There are more obscure wins too. 16-bit AS numbers ran out years ago;
18-bit numbers would still be enough. 18-bit ports and process IDs and
user IDs would be a bit roomier. X86 and A64 instruction encodings
would be a bit saner.<sup><a id="fnr.13" href="#fn.13" role="doc-backlink">13</a></sup><span id="fn.13"><sup>13</sup> Thumb would work better?</span> Half-precision
(18-bit) floats might be prominent earlier.<sup><a id="fnr.14" href="#fn.14" role="doc-backlink">14</a></sup><span id="fn.14"><sup>14</sup> Today's manic 4- and
5-bit floats wouldn't work, and 3-bit floats seem impossible. Maybe
6-bit floats, 6-in-4, would be the consensus OCP float.</span> Extended
ASCII would have room for Greek and would become a kind of NATO code
page.<sup><a id="fnr.15" href="#fn.15" role="doc-backlink">15</a></sup><span id="fn.15"><sup>15</sup> And UTF-9 would privilege most of Western Europe, not just
the US.</span> Unix permissions would be one byte, so would lack sticky
bits. Octal, not hex, would be standard.<sup><a id="fnr.16" href="#fn.16" role="doc-backlink">16</a></sup><span id="fn.16"><sup>16</sup> It all comes from the
PDP-10!</span> Probably there are other benefits too.<sup><a id="fnr.17" href="#fn.17" role="doc-backlink">17</a></sup><span id="fn.17"><sup>17</sup> I measured ΔE for
18-bit color, which nicely splits 6/6/6. ChatGPT says the numbers I'm
getting are imperceptible, but I don't really know, and losing an
alpha channel would hurt.</span>
</p>

<p>
Would there be costs? No system has bit addressing; if a byte isn't a
power of two it doesn't actually matter.<sup><a id="fnr.18" href="#fn.18" role="doc-backlink">18</a></sup><span id="fn.18"><sup>18</sup> No CPU would be dividing
by nine or anything like that.</span> Page sizes and block sizes probably
wouldn't change, the kernel wouldn't be doing anything different from
now.<sup><a id="fnr.19" href="#fn.19" role="doc-backlink">19</a></sup><span id="fn.19"><sup>19</sup> Though kernels would need to support some kind of 54-bit
segment selector plus pointer memory mapping.</span> Would something else
exhaust in ugly ways because it would look like it might fit? A bunch
of single-system stuff, probably; one-byte UID/GID might be tempting,
or two-byte inode numbers, but these happened in our universe and
didn't cause painful transitions.
</p>

<p>
The scariest I've come up with<sup><a id="fnr.20" href="#fn.20" role="doc-backlink">20</a></sup><span id="fn.20"><sup>20</sup> ChatGPT o4 came up with it.</span> is TCP
sequence numbers, where 18-bit sequence numbers might look appealing
but would cause real problems for high-bandwidth connections. You'd
need window scaling by the early 90s and a bump to 36-bit sequence
numbers by the mid 90s, culminating in an IPv6-like TCPv2 effort. Or
maybe instead of IPv6's "skinny upgrade" strategy TCPv2 would
incorporate networking concerns of the era; maybe ECN would be on by
default. But it's still not as bad as IPv6: ISPs would need to support
TCPv2 to offer higher speeds, which was the main way ISPs competed.
They'd make the investment. And since it all happens in the mid-90s,
HTTP might end up requiring TCPv2. We wouldn't dual-stack.
</p>

<p>
<i>Update</i>: This post hit the <a href="https://news.ycombinator.com/item?id=44816692">HN front page</a>. Mostly the comments were
"like always" as we say,<sup><a id="fnr.21" href="#fn.21" role="doc-backlink">21</a></sup><span id="fn.21"><sup>21</sup> As usual, reading the post and looking up
the author's identity instead of guessing gets you a long way.</span> but I
wanted to highlight <a href="https://news.ycombinator.com/item?id=44819306">JdeBP's wonderful comment</a> sketching more of this
9-bit alternate history. Do read it. My gestalt impression is that
this alternate world sounds pretty good! Fewer annoying limits, lame
protocol extensions, US-specificity, and so on. So much of the early
computing era was shaped by numerological limits.
</p>

<p>
<i>Thank you to GPT 4o and o4 for discussions, research, and drafting.</i>
</p>
</div></div>]]></description>
        </item>
    </channel>
</rss>