<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 03 Jan 2024 17:00:06 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Linux hits nearly 4% desktop user share on Statcounter (211 pts)]]></title>
            <link>https://www.gamingonlinux.com/2024/01/linux-hits-nearly-4-desktop-user-share-on-statcounter/</link>
            <guid>38853877</guid>
            <pubDate>Wed, 03 Jan 2024 13:37:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.gamingonlinux.com/2024/01/linux-hits-nearly-4-desktop-user-share-on-statcounter/">https://www.gamingonlinux.com/2024/01/linux-hits-nearly-4-desktop-user-share-on-statcounter/</a>, See on <a href="https://news.ycombinator.com/item?id=38853877">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>According to Statcounter, which should be taken with a pinch of salt of course like any sampling, the Linux share on the desktop hit nearly 4% in Decemeber 2023. Last month was a record too and a clear trend over time, as going back a couple of years, it was rarely coming close to 2% but now it's repeatedly nearing 4% so it's quite a good sign overall.</p>
<p>The latest from Statcounter shows for all of 2023 below:</p>
<ul>
<li>January - 2.91%</li>
<li>February - 2.94%</li>
<li>March - 2.85%</li>
<li>April - 2.83%</li>
<li>May - 2.7%</li>
<li>June - 3.07%</li>
<li>July - 3.12%</li>
<li>August - 3.18%</li>
<li>September - 3.02%</li>
<li>October - 2.92%</li>
<li>November - 3.22%</li>
<li><strong>December - 3.82%</strong></li>
</ul>
<p>Looking at December it shows Windows rising too, with macOS dropping down. If we actually take ChromeOS directly into the Linux numbers for December 2023 the overall number would actually be 6.24% (ChromeOS is Linux after all).</p>
<p>Here's how just Linux looks over time on Statcounter since early 2009 until now:</p>
<p><a data-fancybox="images" href="https://uploads.golmedia.net/uploads/articles/article_media/996456521704281563gol1.png" target="_blank"><img src="https://uploads.golmedia.net/uploads/articles/article_media/996456521704281563gol1.png"></a></p>
<p>Seems like a pretty clear trend over time don't you think? Nice to see this happening elsewhere, just like we've seen over years <a href="https://www.gamingonlinux.com/2024/01/linux-use-on-steam-ends-2023-with-a-multi-year-high-thanks-steam-deck/" target="_blank">with the Steam Survey</a>.</p>
<p>You can see their stats <a href="https://gs.statcounter.com/os-market-share/desktop/worldwide" target="_blank">over here</a>.</p>
<p><span>Article taken from <a href="https://www.gamingonlinux.com/">GamingOnLinux.com.</a></span>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Possible Meissner effect near room temperature: copper-substituted lead apatite (207 pts)]]></title>
            <link>https://arxiv.org/abs/2401.00999</link>
            <guid>38853706</guid>
            <pubDate>Wed, 03 Jan 2024 13:19:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2401.00999">https://arxiv.org/abs/2401.00999</a>, See on <a href="https://news.ycombinator.com/item?id=38853706">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2401.00999.pdf">Download PDF</a>
    <a href="https://browse.arxiv.org/html/2401.00999v1">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>With copper-substituted lead apatite below room temperature, we observe diamagnetic dc magnetization under magnetic field of 25 Oe with remarkable bifurcation between zero-field-cooling and field-cooling measurements, and under 200 Oe it changes to be paramagnetism. A glassy memory effect is found during cooling. Typical hysteresis loops for superconductors are detected below 250 K, along with an asymmetry between forward and backward sweep of magnetic field. Our experiment suggests at room temperature the Meissner effect is possibly present in this material.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Yao Yao [<a href="https://arxiv.org/show-email/3ff8ef53/2401.00999">view email</a>]      <br>    <strong>[v1]</strong>
        Tue, 2 Jan 2024 02:53:38 UTC (237 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Reasons to grow and keep big muscles (108 pts)]]></title>
            <link>https://todaypurpose.com/posts/big-muscles/</link>
            <guid>38853118</guid>
            <pubDate>Wed, 03 Jan 2024 12:03:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://todaypurpose.com/posts/big-muscles/">https://todaypurpose.com/posts/big-muscles/</a>, See on <a href="https://news.ycombinator.com/item?id=38853118">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><time datetime="2023-12-28T13:37:59+0800">Dec 28, 2023</time></p><p>Life isn’t just about how long we live; it’s about how well we live it. We often hear about increasing our lifespan, but is a longer life worth it if we can’t move and become dependent on others? What’s equally, or even more important, is enhancing our healthspan—the period during which we enjoy a good quality of life. From what I’ve observed when talking to older people, they care more about “improving the quality of their life” than “living a longer life”</p><p>Imagine being unable to engage in activities you love, like traveling, playing with kids, hiking, or even just gardening. The loss of functional ability can lead to a diminished the enjoyment we have in life.</p><p>What can you do to maintain your independence, relationships, and <strong>dignity</strong>? I believe the answer lies in working out, especially <strong>resistance training</strong> that helps keeping our strength. In his book <a href="https://peterattiamd.com/outlive/">“Outlive”</a>, Peter Attia shows how we can increase our healthpan and combat the effect of aging :</p><p><img src="https://todaypurpose.com/img/working-out/increase-healthspan-quality-of-life.jpg" alt="Health Decline Graphic"></p><blockquote><p>“Exercise is by far the most potent longevity ‘drug’ available.” It’s not just about delaying death; it’s about preserving cognitive and physical abilities.</p></blockquote><h2 id="the-inevitable-decline-begins-in-your-30s">The inevitable decline begins in your 30s</h2><p>Many of us don’t notice it in our 20s, but as we enter our 30s, the signs become more and more reccurent. Recovery from injuries slows down, we get tired more quickly, and our overall vigor starts to wane.</p><h3 id="sarcopenia-losing-muscle-and-strength-as-we-age">sarcopenia: losing muscle and strength as we age</h3><p>Sarcopenia is the loss of muscle strength with age. It often catches people off guard and people realize it when it’s too late. Starting as early as age 30, we begin to lose 3% to 5% of our muscle mass each decade. By the end of a typical lifespan, most individuals have lost about 30% of their muscle strength.
Preserving muscle mass is crucial. <strong>No amount of cardio</strong> (running, cycling) can combat this natural decline. Both men and women need to engage in strength training along with cardiovascular exercise.</p><p><img src="https://todaypurpose.com/img/working-out/muscle-strengtht-loss.webp" alt="Muscle Loss Over Time"></p><p>Look at the similarities in thigh muscle of the triathletes and someone who does not move below (<a href="https://twitter.com/ChamberofFit/status/1688607251316056065">source</a>):</p><p><img src="https://pbs.twimg.com/media/F28jWCFWwAAWJbn?format=jpg" alt="Comaparison triathlete sedetanire"></p><h2 id="resistance-training-the-ultimate-drug-to-improve-healthspan">Resistance Training: The ultimate drug to improve healthspan</h2><p>The graph show than our peak strength happen at 30 and start decreasing over time:</p><p><img src="https://todaypurpose.com/img/working-out/peak-strenght.jpeg" alt="Peak strength"></p><p>This other graph show the effect of resistance training, and how it can prevent disability:</p><p><img src="https://todaypurpose.com/img/working-out/resistance-training-effect.png" alt="Effect of Exercises Over Time"></p><p>Without resistance training, our bodies undergo a transformation post-30: muscle loss gives way to a higher fat percentage, leading to a weaker physique and the lose of autonomy.</p><h3 id="reducing-the-risk-of-injuries-and-falls">reducing the risk of injuries and falls</h3><p>Falls are a leading cause of mortality for people over 75. Resistance training enhances lower body strength, crucial for activities like climbing stairs or simply standing up from a chair. Stronger muscles also mean better balance and a reduced risk of falls, which can be catastrophic in later life. Starting 60-65: risk of falls that lead to immediate death or within 12 months (break hips / femur) is really high (15-30% depending the study). <a href="https://www.cdc.gov/falls/data/">Over 14 million, or 1 in 4 older adults report falling every year</a>. It is also the leading cause on the non-fatal injuries in the USA at all ages :</p><p><img src="https://todaypurpose.com/img/working-out/fall-leading-cause-hospitals.png" alt="Fall hospitals"></p><h3 id="a-20-year-advantage">a 20-year advantage</h3><p><a href="https://www.nsca.com/contentassets/2a4112fb355a4a48853bbafbe070fb8e/resistance_training_for_older_adults__position.1.pdf">Research</a> shows that 85-year-old individuals who have consistently engaged in weightlifting display similar physical power to non-lifting 65-year-olds. Long-term resistance training can grant an approximate 20-year advantage in physical capabilities.</p><h3 id="avoiding-pains">avoiding pains</h3><p>If you are in your 30s like me, you probably already feel it. Regular exercise, especially strength training, plays a vital role in pain prevention and management. Weak muscles and a sedentary lifestyle often lead to chronic pain issues, which can severely impact the quality of life in our later years.</p><h2 id="other-reasons-to-stay-strong-as-we-age">Other reasons to stay strong as we age?</h2><h3 id="cognitive-benefits-mood-stamina">cognitive benefits, mood, stamina</h3><p>Resistance training doesn’t just benefit the body; it also supports cognitive health. Low muscle mass and physical inactivity are linked to cognitive decline in old age. Exercise releases myokines, which support brain health, indicating a dose-dependent effect between muscle mass and cognitive function.</p><p>It also boost mood and reduce symptoms of anxiety and depression. When pushing hard, your body release endorphins and other mood-enhancing chemicals during exercise. These natural mood lifters contribute to a sense of well-being you can get each time you go for a workout.</p><p>Beyond building muscle strength, resistance training enhances overall stamina and endurance. This increased stamina is not just physical; it translates into greater mental and emotional resilience. Older adults with higher levels of fitness and stamina are better equipped to handle the challenges of daily life, remain independent, and engage in social activities, which are crucial for mental health and quality of life.</p><h3 id="being-in-control">being in control</h3><p>Resistance training is the art of pushing yourself than what you think is your limit. It teaches the value of persistence, discipline, and hard work. The satisfaction of achieving a physical goal through resistance training, and in my humble opinion, can <strong>boost confidence</strong> in one’s ability to <strong>overcome other challenges in life</strong> you might think are not possible to overcome.</p><p>Alan Thrall (that I started following because his excellent <a href="https://www.youtube.com/watch?v=UFs6E3Ti1jg">“how to squat video”</a>) puts it really well. Why did he kept working out during a crazy time such has the first weeks of having a baby and he his overwhelmed?</p><blockquote><p>When times get tough, I need keeps everyone (his household) grounded, and helps people moving to the right direction. Stay 1 step ahead of everything, and not only being pushed around by life circumstances. I need to be stronger than the situation.</p></blockquote><iframe width="560" height="315" src="https://www.youtube.com/embed/NQlHBvg6Cgw?si=wsx7Pvh-gDhkrXCP&amp;start=516" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe><h3 id="independance-autonomy">independance, autonomy</h3><p>As we lost strength we will lose ability to grab things, or even walk. This might lead to Keeping some dignity as a human being.
The ability to engage in activities like playing with kids, hiking, or traveling is not just a matter of physical capability; it’s also about maintaining independence and relationships, which are central to happiness. As we age, the desire to remain self-reliant grows stronger, and resistance training plays a crucial role in this.</p><h3 id="keeping-relationships">keeping relationships</h3><p>Strength directly influences our ability to maintain social connections. If our mobility decreases, so does the ability to visit friends and family, which can lead to isolation and loneliness.</p><p>Staying strong and mobile enables us to actively participate in social activities, maintaining and nurturing relationships that are essential for mental and emotional well-being.</p><p>Staying healthy is probably the best gift we can give to our children. As we become more dependent due to health issues, we not only incur significant healthcare costs but also potentially place a financial and emotional burden on our families.</p><h3 id="reducing-risk-of-cancer-and-heart-disease">reducing risk of cancer and heart disease:</h3><p>Resistance training can lead from <strong>10 to 20 percent reduction</strong> in the risk of early death from all causes and from cancer and heart disease. <a href="https://bjsm.bmj.com/content/56/13/755">https://bjsm.bmj.com/content/56/13/755</a></p><h3 id="staying-fit-by-doing-nothing">staying fit by doing “nothing”</h3><p>Friends usually ask me how I can stay fit by eating that much I believe I have and advantage I’ve been building since I was 10ish: I kept working out. I’ve built muscle over the years, and my <strong>resting metabolic rate</strong> . Lean muscle burns more calories than fat, even at rest. Having more muscle is a kind of cheat code. By increasing muscle mass your resting metabolic rate goes up. It means that <a href="https://todaypurpose.com/posts/big-muscles/(https://www.researchgate.net/figure/Relationship-between-BMR-and-lean-body-mass_fig1_5440088)">you can burn more calories when you are at rest</a>:</p><p><img src="https://todaypurpose.com/img/working-out/resting-metabolic-rate-vs-lean-muscle.png" alt="resting metabolic rate vs muscle"></p><p>Of course you’ll need to preserve those muscle with resistance training.</p><h2 id="some-last-words">Some last words</h2><p>Resistance training is a choice you make. It’s hard, but only has upsides for your current and future self. It is never too late to start. The benefits of starting it can be seen at any age. The key is to keep doing it, no matter what.</p><p>My only advices:</p><ul><li>Find good lasting reasons to workout (I hope this article helped) and stop finding excuses to not go.</li><li>If you’re over 30 (or even in your 20s and able to afford it), hire a personal trainer to start. They can check your form and avoid any kind of injuries. With weights, it is really easy to get a bad form, no matter how many youtube videos you watch. I went to see a Physiotherapist 4 years after I started squats, and this is the best thing I’ve ever done. She retaught me everything I think I knew about squatting.</li><li>I also do a bit of aerobic exercices (cardio). But excessive cardio is counterproductive, leading to loss of muscle mass and potential joint issues.</li><li>The CDC recommends <a href="https://www.cdc.gov/physicalactivity/basics/age-chart.html">2+ days per week that work all major muscle groups (legs, hips, back, abdomen, chest, shoulders, and arms)</a>.</li><li>For very beginner, I do recommend the <a href="https://stronglifts.com/5x5/">5x5 program</a>. The program work on all biggest muscles of your bodies. I do also like their app that is really easy to follow. There is plenty of strength training gurus out there. No matter what program you pick, you’ll find benefits any of them.</li><li>When you go to the gym, leave your ego at home, and never compare yourself to others. You’ll just get injured.</li></ul><hr><p>Liked this post ? You’ll love that one: <a href="https://todaypurpose.com/posts/time-money-health/">On Time, Money and Health</a></p><hr></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[UK 2022 rail station flow images (126 pts)]]></title>
            <link>https://github.com/anisotropi4/kingfisher/blob/main/station.md</link>
            <guid>38852580</guid>
            <pubDate>Wed, 03 Jan 2024 10:37:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/anisotropi4/kingfisher/blob/main/station.md">https://github.com/anisotropi4/kingfisher/blob/main/station.md</a>, See on <a href="https://news.ycombinator.com/item?id=38852580">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <nav aria-label="Global">
            <ul>
                <li>
      
      <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Actions&quot;,&quot;label&quot;:&quot;ref_cta:Actions;&quot;}" href="https://github.com/features/actions">
      
      <div>
        <p>Actions</p><p>
        Automate any workflow
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Packages&quot;,&quot;label&quot;:&quot;ref_cta:Packages;&quot;}" href="https://github.com/features/packages">
      
      <div>
        <p>Packages</p><p>
        Host and manage packages
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Security&quot;,&quot;label&quot;:&quot;ref_cta:Security;&quot;}" href="https://github.com/features/security">
      
      <div>
        <p>Security</p><p>
        Find and fix vulnerabilities
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Codespaces&quot;,&quot;label&quot;:&quot;ref_cta:Codespaces;&quot;}" href="https://github.com/features/codespaces">
      
      <div>
        <p>Codespaces</p><p>
        Instant dev environments
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Copilot&quot;,&quot;label&quot;:&quot;ref_cta:Copilot;&quot;}" href="https://github.com/features/copilot">
      
      <div>
        <p>Copilot</p><p>
        Write better code with AI
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Code review&quot;,&quot;label&quot;:&quot;ref_cta:Code review;&quot;}" href="https://github.com/features/code-review">
      
      <div>
        <p>Code review</p><p>
        Manage code changes
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Issues&quot;,&quot;label&quot;:&quot;ref_cta:Issues;&quot;}" href="https://github.com/features/issues">
      
      <div>
        <p>Issues</p><p>
        Plan and track work
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Discussions&quot;,&quot;label&quot;:&quot;ref_cta:Discussions;&quot;}" href="https://github.com/features/discussions">
      
      <div>
        <p>Discussions</p><p>
        Collaborate outside of code
      </p></div>

    
</a></li>

            </ul>
          </div>
</li>


                <li>
      
      
</li>


                <li>
      
      <div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to GitHub Sponsors&quot;,&quot;label&quot;:&quot;ref_cta:GitHub Sponsors;&quot;}" href="https://github.com/sponsors">
      
      <div>
        <p>GitHub Sponsors</p><p>
        Fund open source developers
      </p></div>

    
</a></li>

            </ul>
          </div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to The ReadME Project&quot;,&quot;label&quot;:&quot;ref_cta:The ReadME Project;&quot;}" href="https://github.com/readme">
      
      <div>
        <p>The ReadME Project</p><p>
        GitHub community articles
      </p></div>

    
</a></li>

            </ul>
          </div>
          
      </div>
</li>


                <li>
    <a data-analytics-event="{&quot;category&quot;:&quot;Header menu top item (logged out)&quot;,&quot;action&quot;:&quot;click to go to Pricing&quot;,&quot;label&quot;:&quot;ref_cta:Pricing;&quot;}" href="https://github.com/pricing">Pricing</a>
</li>

            </ul>
          </nav>

        <div>
                


<qbsearch-input data-scope="repo:anisotropi4/kingfisher" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="Jkafbe_Rbcf2AtRT6PBJzics1lgN6GTD37g-DBvSlky4cMlmsrhWrqbSj0fq5rpTOhtPzVY4esXqJXbA4Z69kQ" data-max-custom-scopes="10" data-header-redesign-enabled="false" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="anisotropi4/kingfisher" data-current-org="" data-current-owner="anisotropi4" data-logged-in="false" data-copilot-chat-enabled="false" data-blackbird-indexed-repo-csrf="<esi:include src=&quot;/_esi/rails_csrf_token_form_hidden?r=fwnhz5lvKQxCu%2B34U%2FAue0rW9N4vr%2FU4LOkLZaC8yPCOsAXABwhIjpnGlh7YT9JxUBf1fDAUkYGZHR3MNhYRit202QsEJNnch53FwXoYk8xv8Kd%2FXJu2pDZavtN%2Bymgd1bF5W4mjFfwowBnq6YLOdOfB1uQciuTOSQpSlS6S2ax%2FklQgCViSw%2BxCjz7vH8dSCWcIunCzmXGdCaxpHS6LsjoPZqtHZwIQstrUBCumMFev5Ca2wI0j2yPb%2BfoHe0DfxN2LvYwr0BPxvCru%2BdH3lT15nefUt4Zmj0Qhaogw2dwrzUjEHAKn2PzncGaRvM9UEpHAhFaY0H10IY4IBz6%2BWp60wUp90O47TGgohDD7ImD7MAyNNWrFQvpzdxImdYzaR%2BBiXCitCvUuovkigiQ2%2Br15tpGlTQr5WF%2FkdWEe29Z7O8VxiC4qClXbpQA6yB6SpzK0FB0HZZJc0HpFgXeIDbsecCAgyVPUCNorcf%2BdRyIfIknpNHe0AsUB5bSkFtyElOWY3maTsoo7Y729Du7q87CHnXPYnE11vuWDdBB0EvspM86%2B4SDe0Mcp6eKITkXzXpY%3D--v9Iz%2B7veJE9u9tu9--rVsbFN3T2%2FVucffsKj4Z6g%3D%3D&quot; />">
  <div data-modal-dialog-overlay="" data-action="click:qbsearch-input#searchInputContainerClicked">
  <modal-dialog data-action="close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose" data-target="qbsearch-input.searchSuggestionsDialog" role="dialog" id="search-suggestions-dialog" aria-modal="true" aria-labelledby="search-suggestions-dialog-header" data-view-component="true">
      <h2 id="search-suggestions-dialog-header">Search code, repositories, users, issues, pull requests...</h2>
    
</modal-dialog></div>
  
  <div>
    
<div data-modal-dialog-overlay="">
  <modal-dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" role="dialog" id="feedback-dialog" aria-modal="true" aria-disabled="true" aria-labelledby="feedback-dialog-title" aria-describedby="feedback-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="feedback-dialog-title">
        Provide feedback
      </h2>
    </p>
    
  </div>
      
      
</modal-dialog></div>

    <custom-scopes data-target="qbsearch-input.customScopesManager">
    
<div data-modal-dialog-overlay="">
  <modal-dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" role="dialog" id="custom-scopes-dialog" aria-modal="true" aria-disabled="true" aria-labelledby="custom-scopes-dialog-title" aria-describedby="custom-scopes-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="custom-scopes-dialog-title">
        Saved searches
      </h2>
        <h2 id="custom-scopes-dialog-description">Use saved searches to filter your results more quickly</h2>
    </p>
    
  </div>
      
      
</modal-dialog></div>
    </custom-scopes>
  </div>
</qbsearch-input>

            <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fblob%2Fshow&amp;source=header-repo&amp;source_repo=anisotropi4%2Fkingfisher" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/anisotropi4/kingfisher/blob/main/station.md&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="c0b5191e8b5b0ebfb05d0272de955d3957f111471c41c33106cd9caae5ec70a6" data-analytics-event="{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/<user-name>/<repo-name>/blob/show;ref_cta:Sign up;ref_loc:header logged out&quot;}">
              Sign up
            </a>
        </p></div>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Maestro: A Linux-compatible kernel in Rust (405 pts)]]></title>
            <link>https://blog.lenot.re/a/introduction</link>
            <guid>38852360</guid>
            <pubDate>Wed, 03 Jan 2024 09:59:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.lenot.re/a/introduction">https://blog.lenot.re/a/introduction</a>, See on <a href="https://news.ycombinator.com/item?id=38852360">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
					
					<h6><span id="date-long">2024-01-02T15:00:00+00:00</span></h6>
					<p>
						Maestro is a Unix-like kernel and operating system written from scratch in Rust
					</p>
					<p><img src="https://blog.lenot.re/assets/article/neofetch.png">
				</p></div><div>
					<p>Thanks to the internet, I can learn how most things I am interested in work. However, something stayed a mystery to me for a long time: computers.</p>
<p>Computers are amongst the most complex tools that humanity has ever built. They are a marvel of engineering that we take for granted because we use them in our everyday lives.</p>
<p>I like to dig into complexity, and I like to learn by doing.
On top of that, I spend a lot of time on the computer. Wouldn’t it be cool if I had a system that I would know from A to Z and that I could customise as much as I wanted to fit my expectations?</p>
<p>This is why I decided to build <a href="https://github.com/llenotre/maestro" target="_blank">Maestro</a>. A Unix-like operating system that is meant to be lightweight and compatible-enough with Linux to be usable in everyday life.</p>
<h2>A bit of history</h2>
<p>The first commit of the kernel dates back to December 22nd, 2018, at 3:18 in the morning (the best time to write code, of course). It started as a school project.</p>
<p>It was originally implemented using the <strong>C language</strong> and continued to be for roughly a year and a half, until the codebase became too hard to keep clean.</p>
<p>At that moment, I decided to switch to <strong>Rust</strong> (my first project in this language), which represented several advantages:</p>
<ul>
<li>Restart the project from the beginning, using lessons learned from previous mistakes</li>
<li>Be a bit more innovative than just writing a Linux-like kernel in C. After all, just use Linux at that point</li>
<li>Use the safety of the Rust language to leverage some difficulty of kernel programming. Using Rust’s typing system allows to shift some responsibility over memory safety from the programmer to the compiler</li>
</ul>
<p>In kernel development, debugging is very hard for several reasons:</p>
<ul>
<li>Documentation is often hard to find, and BIOS implementations may be flawed (more often than you would think)</li>
<li>On boot, the kernel has full access to the memory and is allowed to write where it should not (its own code, for example)</li>
<li>Troubleshooting memory leaks is not easy. Tools such as <em>valgrind</em> cannot be used</li>
<li><em>gdb</em> can be used with <em>QEMU</em> and <em>VMWare</em>, but the kernel may have a different behaviour when running on a different emulator or virtual machine. Also, those emulators may not support gdb (example <em>VirtualBox</em>)</li>
<li>Some features in the support for gdb in QEMU or VMWare are missing (such as <em>Record and Replay</em>) and gdb might even crash sometimes</li>
</ul>
<p>All those issues are reasons for using a memory-safe language, to avoid them as much as possible.</p>
<p>Overall, the use of Rust in the kernel allowed for the implementation of a lot of safeguards. And I believe that it is, to this day, the best decision I have made for this project.</p>
<h3>Timelapse</h3>
<video controls="" width="100%" loading="lazy">
  <source src="https://blog.lenot.re/assets/article/gource.mp4" type="video/mp4">
</video>
<p>Created using <a href="https://gource.io/" target="_blank">Gource</a>. Music: <em>Many Moons of Saturn, Mike Cole</em></p>
<h2>The current state of the project</h2>
<p>Maestro is a monolithic kernel, supporting only the x86 (in 32 bits) architecture for now.</p>
<p>At the time of writing, <strong>135</strong> out of <strong>437</strong> Linux system calls (roughly 31%) are more or less implemented.
The project has <strong>48 800</strong> lines of code across <strong>615</strong> files (all repositories combined, counted using the <code>cloc</code> command).</p>
<p>The OS currently has the following components, aside from the kernel:</p>
<ul>
<li><a href="https://github.com/llenotre/solfege" target="_blank">Solfège</a>: a boot system and daemon manager (kind of similar to systemd, but lighter)</li>
<li><a href="https://github.com/llenotre/maestro-utils" target="_blank">maestro-utils</a>: system utility commands</li>
<li><a href="https://github.com/llenotre/blimp" target="_blank">blimp</a>: a package manager</li>
<li>And more components that are available on <a href="https://github.com/llenotre" target="_blank">my github</a></li>
</ul>
<p>So far, the following third-party software has been tested and is working on the OS:</p>
<ul>
<li>musl (C standard library)</li>
<li>bash</li>
<li>Some GNU coreutils commands such as <code>ls</code>, <code>cat</code>, <code>mkdir</code>, <code>rm</code>, <code>rmdir</code>, <code>uname</code>, <code>whoami</code>, etc…</li>
<li>neofetch (a patched version, since the original neofetch does not know about my OS)</li>
</ul>
<h2>Test it yourself!</h2>
<blockquote>
<p><strong>Disclaimer</strong>: It is important to note that the OS is still in a very early stage of development and is highly unstable. I discourage trying to install it on a machine with important data on it.</p>
<p>So far, it has been tested mostly on QEMU, VMWare and VirtualBox.</p>
</blockquote>
<p>There are two ways you can install the OS:</p>
<ul>
<li>Use a pre-built (compressed) .iso file that you can download <a href="https://blog.lenot.re/assets/article/maestro.iso.gz">here</a></li>
<li><a href="https://github.com/llenotre/maestro-install/" target="_blank">Build the ISO yourself</a></li>
</ul>
<p>The ISO provides an installer for the OS. You can use it on QEMU, VMWare or VirtualBox for example.</p>
<blockquote>
<p>You should run the ISO with sufficient RAM (<strong>1GB</strong> should be more than enough).</p>
<p>Such an amount of memory is required because packages to be installed are stored in RAM (on the initramsfs) instead of the disk. This is currently the best method since the OS is <em>not yet</em> able to read on a USB stick or CD-ROM by itself, so it relies on the bootloader for this.</p>
</blockquote>
<h2>What this blog is about</h2>
<p>The aim of this blog is <strong>not</strong> to write tutorials about how to create an OS. This is already well covered by other websites/blogs. I recommend in particular:</p>
<ul>
<li><a href="https://wiki.osdev.org/Expanded_Main_Page" target="_blank">osdev.org</a></li>
<li><a href="https://os.phil-opp.com/" target="_blank">Philipp Oppermann’s blog</a></li>
</ul>
<p>The goal is to explore more advanced subjects (since most people/blogs tend to stop at the basics), to push the subjects as far as I am able to, to write articles about problems I encounter and how I solve them, to discover how computers work underneath, but also operating systems, the internet, and much more… Plenty of things to talk about!</p>
<h2>What’s coming next?</h2>
<p>Cleaning of the codebase and performance optimisations are in order. Since the OS started as a school project, I had to cut corners in order to finish it on time. But now is the time to pay back the technical debt I accumulated.</p>
<p>Some memory leaks are also lying around and have to be fixed. Performance optimisations will probably be a subject for blog articles.</p>
<p>The next leap forward will be to have the package manager fully working on the OS. To do so, some features are required:</p>
<ul>
<li>Network support, which is currently under development. And will probably be the subject of numerous articles</li>
<li>Shared library support. This currently does not work because it requires mapping files directly into memory, which is not currently supported by the implementation of the <code>mmap</code> system call on the kernel</li>
</ul>
<p>After that, I will be able to install (without pain) and test programmes such as compilers (gcc/g++, clang, rustc), make, Git, Vim, etc… And then develop the kernel while using it!</p>
<p>The development of the kernel largely follows a simple procedure:</p>
<ul>
<li><strong>1</strong>: Run a programme on the kernel and see if it works correctly</li>
<li><strong>2</strong>: If it does not work, then:
<ul>
<li><strong>3</strong>: Run the programme while printing system calls and search for the first system call that is causing troubles (not implemented or buggy)</li>
<li><strong>4</strong>: Implement or fix the system call in question</li>
<li><strong>5</strong>: Go to step 1</li>
</ul>
</li>
<li><strong>6</strong>: Else: Yay!</li>
</ul>
<p>The more programmes running correctly on the kernel, the more stable and complete it becomes!</p>
<h2>How <em>you</em> can help</h2>
<p>You can leave a star ⭐ on the <a href="https://github.com/llenotre/maestro" target="_blank">Github repository of the kernel</a> ❤️</p>
<p>And stay in touch by:</p>
<ul>
<li>Subscribing to the newsletter on the <a href="https://blog.lenot.re/">main page</a></li>
<li>Watching the <a href="https://blog.lenot.re/rss">RSS feed</a></li>
</ul>
<p>Do not hesitate to join Discord! If you have feedback to make, advice to give, or questions to ask, I will be glad to answer!</p>

				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Cross-platform Rust rewrite of the GNU coreutils (244 pts)]]></title>
            <link>https://github.com/uutils/coreutils</link>
            <guid>38851740</guid>
            <pubDate>Wed, 03 Jan 2024 07:56:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/uutils/coreutils">https://github.com/uutils/coreutils</a>, See on <a href="https://news.ycombinator.com/item?id=38851740">Hacker News</a></p>
<div id="readability-page-1" class="page"><p dir="auto">uutils coreutils is a cross-platform reimplementation of the GNU coreutils in
<a href="http://www.rust-lang.org/" rel="nofollow">Rust</a>. While all programs have been implemented, some
options might be missing or different behavior might be experienced.</p><p dir="auto">uutils aims to be a drop-in replacement for the GNU utils. Differences with GNU
are treated as bugs.</p><p dir="auto">uutils aims to work on as many platforms as possible, to be able to use the same
utils on Linux, Mac, Windows and other platforms. This ensures, for example,
that scripts can be easily transferred between platforms.</p><div dir="auto">
<h2 tabindex="-1" dir="auto">Documentation</h2>
<p dir="auto">uutils has both user and developer documentation available:</p>
<ul dir="auto">
<li><a href="https://uutils.github.io/coreutils/book/" rel="nofollow">User Manual</a></li>
<li><a href="https://uutils.github.io/dev/coreutils/" rel="nofollow">Developer Documentation</a> (currently offline, you can use docs.rs in the meantime)</li>
</ul>
<p dir="auto">Both can also be generated locally, the instructions for that can be found in
the <a href="https://github.com/uutils/uutils.github.io">coreutils docs</a> repository.</p>

<h2 tabindex="-1" dir="auto">Requirements</h2>
<ul dir="auto">
<li>Rust (<code>cargo</code>, <code>rustc</code>)</li>
<li>GNU Make (optional)</li>
</ul>
<h3 tabindex="-1" dir="auto">Rust Version</h3>
<p dir="auto">uutils follows Rust's release channels and is tested against stable, beta and
nightly. The current Minimum Supported Rust Version (MSRV) is <code>1.70.0</code>.</p>
<h2 tabindex="-1" dir="auto">Building</h2>
<p dir="auto">There are currently two methods to build the uutils binaries: either Cargo or
GNU Make.</p>
<blockquote>
<p dir="auto">Building the full package, including all documentation, requires both Cargo
and Gnu Make on a Unix platform.</p>
</blockquote>
<p dir="auto">For either method, we first need to fetch the repository:</p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/uutils/coreutils
cd coreutils"><pre>git clone https://github.com/uutils/coreutils
<span>cd</span> coreutils</pre></div>
<h3 tabindex="-1" dir="auto">Cargo</h3>
<p dir="auto">Building uutils using Cargo is easy because the process is the same as for every
other Rust program:</p>

<p dir="auto">This command builds the most portable common core set of uutils into a multicall
(BusyBox-type) binary, named 'coreutils', on most Rust-supported platforms.</p>
<p dir="auto">Additional platform-specific uutils are often available. Building these expanded
sets of uutils for a platform (on that platform) is as simple as specifying it
as a feature:</p>
<div dir="auto" data-snippet-clipboard-copy-content="cargo build --release --features macos
# or ...
cargo build --release --features windows
# or ...
cargo build --release --features unix"><pre>cargo build --release --features macos
<span><span>#</span> or ...</span>
cargo build --release --features windows
<span><span>#</span> or ...</span>
cargo build --release --features unix</pre></div>
<p dir="auto">If you don't want to build every utility available on your platform into the
final binary, you can also specify which ones you want to build manually. For
example:</p>
<div dir="auto" data-snippet-clipboard-copy-content="cargo build --features &quot;base32 cat echo rm&quot; --no-default-features"><pre>cargo build --features <span><span>"</span>base32 cat echo rm<span>"</span></span> --no-default-features</pre></div>
<p dir="auto">If you don't want to build the multicall binary and would prefer to build the
utilities as individual binaries, that is also possible. Each utility is
contained in its own package within the main repository, named "uu_UTILNAME". To
build individual utilities, use cargo to build just the specific packages (using
the <code>--package</code> [aka <code>-p</code>] option). For example:</p>
<div dir="auto" data-snippet-clipboard-copy-content="cargo build -p uu_base32 -p uu_cat -p uu_echo -p uu_rm"><pre>cargo build -p uu_base32 -p uu_cat -p uu_echo -p uu_rm</pre></div>
<h3 tabindex="-1" dir="auto">GNU Make</h3>
<p dir="auto">Building using <code>make</code> is a simple process as well.</p>
<p dir="auto">To simply build all available utilities:</p>

<p dir="auto">In release mode:</p>

<p dir="auto">To build all but a few of the available utilities:</p>
<div dir="auto" data-snippet-clipboard-copy-content="make SKIP_UTILS='UTILITY_1 UTILITY_2'"><pre>make SKIP_UTILS=<span><span>'</span>UTILITY_1 UTILITY_2<span>'</span></span></pre></div>
<p dir="auto">To build only a few of the available utilities:</p>
<div dir="auto" data-snippet-clipboard-copy-content="make UTILS='UTILITY_1 UTILITY_2'"><pre>make UTILS=<span><span>'</span>UTILITY_1 UTILITY_2<span>'</span></span></pre></div>
<h2 tabindex="-1" dir="auto">Installation</h2>
<h3 tabindex="-1" dir="auto">Install with Cargo</h3>
<p dir="auto">Likewise, installing can simply be done using:</p>
<div dir="auto" data-snippet-clipboard-copy-content="cargo install --path . --locked"><pre>cargo install --path <span>.</span> --locked</pre></div>
<p dir="auto">This command will install uutils into Cargo's <em>bin</em> folder (<em>e.g.</em>
<code>$HOME/.cargo/bin</code>).</p>
<p dir="auto">This does not install files necessary for shell completion or manpages. For
manpages or shell completion to work, use <code>GNU Make</code> or see
<code>Manually install shell completions</code>/<code>Manually install manpages</code>.</p>
<h3 tabindex="-1" dir="auto">Install with GNU Make</h3>
<p dir="auto">To install all available utilities:</p>

<p dir="auto">To install using <code>sudo</code> switch <code>-E</code> must be used:</p>

<p dir="auto">To install all but a few of the available utilities:</p>
<div dir="auto" data-snippet-clipboard-copy-content="make SKIP_UTILS='UTILITY_1 UTILITY_2' install"><pre>make SKIP_UTILS=<span><span>'</span>UTILITY_1 UTILITY_2<span>'</span></span> install</pre></div>
<p dir="auto">To install only a few of the available utilities:</p>
<div dir="auto" data-snippet-clipboard-copy-content="make UTILS='UTILITY_1 UTILITY_2' install"><pre>make UTILS=<span><span>'</span>UTILITY_1 UTILITY_2<span>'</span></span> install</pre></div>
<p dir="auto">To install every program with a prefix (e.g. uu-echo uu-cat):</p>
<div dir="auto" data-snippet-clipboard-copy-content="make PROG_PREFIX=PREFIX_GOES_HERE install"><pre>make PROG_PREFIX=PREFIX_GOES_HERE install</pre></div>
<p dir="auto">To install the multicall binary:</p>

<p dir="auto">Set install parent directory (default value is /usr/local):</p>
<div dir="auto" data-snippet-clipboard-copy-content="# DESTDIR is also supported
make PREFIX=/my/path install"><pre><span><span>#</span> DESTDIR is also supported</span>
make PREFIX=/my/path install</pre></div>
<p dir="auto">Installing with <code>make</code> installs shell completions for all installed utilities
for <code>bash</code>, <code>fish</code> and <code>zsh</code>. Completions for <code>elvish</code> and <code>powershell</code> can also
be generated; See <code>Manually install shell completions</code>.</p>
<h3 tabindex="-1" dir="auto">Manually install shell completions</h3>
<p dir="auto">The <code>coreutils</code> binary can generate completions for the <code>bash</code>, <code>elvish</code>,
<code>fish</code>, <code>powershell</code> and <code>zsh</code> shells. It prints the result to stdout.</p>
<p dir="auto">The syntax is:</p>
<div dir="auto" data-snippet-clipboard-copy-content="cargo run completion <utility> <shell>"><pre>cargo run completion <span>&lt;</span>utility<span>&gt;</span> <span>&lt;</span>shell<span>&gt;</span></pre></div>
<p dir="auto">So, to install completions for <code>ls</code> on <code>bash</code> to
<code>/usr/local/share/bash-completion/completions/ls</code>, run:</p>
<div dir="auto" data-snippet-clipboard-copy-content="cargo run completion ls bash > /usr/local/share/bash-completion/completions/ls"><pre>cargo run completion ls bash <span>&gt;</span> /usr/local/share/bash-completion/completions/ls</pre></div>
<h3 tabindex="-1" dir="auto">Manually install manpages</h3>
<p dir="auto">To generate manpages, the syntax is:</p>
<div dir="auto" data-snippet-clipboard-copy-content="cargo run manpage <utility>"><pre>cargo run manpage <span>&lt;</span>utility<span>&gt;</span></pre></div>
<p dir="auto">So, to install the manpage for <code>ls</code> to <code>/usr/local/share/man/man1/ls.1</code> run:</p>
<div dir="auto" data-snippet-clipboard-copy-content="cargo run manpage ls > /usr/local/share/man/man1/ls.1"><pre>cargo run manpage ls <span>&gt;</span> /usr/local/share/man/man1/ls.1</pre></div>
<h2 tabindex="-1" dir="auto">Un-installation</h2>
<p dir="auto">Un-installation differs depending on how you have installed uutils. If you used
Cargo to install, use Cargo to uninstall. If you used GNU Make to install, use
Make to uninstall.</p>
<h3 tabindex="-1" dir="auto">Uninstall with Cargo</h3>
<p dir="auto">To uninstall uutils:</p>

<h3 tabindex="-1" dir="auto">Uninstall with GNU Make</h3>
<p dir="auto">To uninstall all utilities:</p>

<p dir="auto">To uninstall every program with a set prefix:</p>
<div dir="auto" data-snippet-clipboard-copy-content="make PROG_PREFIX=PREFIX_GOES_HERE uninstall"><pre>make PROG_PREFIX=PREFIX_GOES_HERE uninstall</pre></div>
<p dir="auto">To uninstall the multicall binary:</p>
<div dir="auto" data-snippet-clipboard-copy-content="make MULTICALL=y uninstall"><pre>make MULTICALL=y uninstall</pre></div>
<p dir="auto">To uninstall from a custom parent directory:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# DESTDIR is also supported
make PREFIX=/my/path uninstall"><pre><span><span>#</span> DESTDIR is also supported</span>
make PREFIX=/my/path uninstall</pre></div>

<h2 tabindex="-1" dir="auto">GNU test suite compatibility</h2>
<p dir="auto">Below is the evolution of how many GNU tests uutils passes. A more detailed
breakdown of the GNU test results of the main branch can be found
<a href="https://uutils.github.io/coreutils/book/test_coverage.html" rel="nofollow">in the user manual</a>.</p>
<p dir="auto">See <a href="https://github.com/orgs/uutils/projects/1">https://github.com/orgs/uutils/projects/1</a> for the main meta bugs
(many are missing).</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/uutils/coreutils-tracking/blob/main/gnu-results.png?raw=true"><img src="https://github.com/uutils/coreutils-tracking/raw/main/gnu-results.png?raw=true" alt="Evolution over time"></a></p>
</div><p dir="auto">GNU Coreutils is licensed under the GPL 3.0 or later.</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Benchmarking 20 programming languages on N-queens and matrix multiplication (118 pts)]]></title>
            <link>https://github.com/attractivechaos/plb2</link>
            <guid>38850651</guid>
            <pubDate>Wed, 03 Jan 2024 04:13:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/attractivechaos/plb2">https://github.com/attractivechaos/plb2</a>, See on <a href="https://news.ycombinator.com/item?id=38850651">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><p dir="auto"><strong>TL;DR</strong>: see the figure below. Note that nqueen and matmul are implemented in
all languages but sudoku and bedcov are only implemented in some.
NB: nqueen and matmul in V have been updated in the <a href="#table">table</a>, but the
figure is not in sync yet. Now V is the fastest on nqueen+matmul.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/attractivechaos/plb2/blob/master/analysis/rst-m1.png"><img src="https://github.com/attractivechaos/plb2/raw/master/analysis/rst-m1.png"></a></p>
<h2 tabindex="-1" dir="auto">Table of Contents</h2>
<ul dir="auto">
<li><a href="#intro">Introduction</a></li>
<li><a href="#result">Results</a>
<ul dir="auto">
<li><a href="#overall">Overall impressions</a></li>
<li><a href="#caveat">Caveats</a>
<ul dir="auto">
<li><a href="#startup">Startup time</a></li>
<li><a href="#cputime">Elapsed time vs CPU time</a></li>
</ul>
</li>
<li><a href="#opt">Subtle optimizations</a>
<ul dir="auto">
<li><a href="#matmul">Optimizing inner loops</a></li>
<li><a href="#memlayout">Controlling memory layout</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#conclusion">Discussions</a></li>
<li><a href="#table">Appendix: Timing on Apple M1 Macbook Pro</a></li>
</ul>
<h2 tabindex="-1" dir="auto"><a name="user-content-intro"></a>Introduction</h2>
<p dir="auto">Programming Language Benchmark v2 (plb2) evaluates the performance of 20
programming languages on four CPU-intensive tasks. It is a follow-up to
<a href="https://github.com/attractivechaos/plb">plb</a> conducted in 2011. In plb2, all implementations use the same
algorithm for each task and their performance bottlenecks do not fall in
library functions. We do not intend to compare different algorithms or the
quality of the standard libraries in these languages. Plb2 is supposed to
demonstrate the performance of a language when you have to implement a new
algorithm in the language, which may happen if you can't find the algorithm in
existing libraries.</p>
<p dir="auto">The four tasks in plb2 all take a few seconds for a fast implementation to
complete. The tasks are:</p>
<ul dir="auto">
<li>
<p dir="auto"><strong>nqueen</strong>: solving a <a href="https://en.wikipedia.org/wiki/Eight_queens_puzzle" rel="nofollow">15-queens problem</a>. The algorithm was inspired
by the second C implementation <a href="https://rosettacode.org/wiki/N-queens_problem#C" rel="nofollow">from Rosetta Code</a>. It involves nested
loops and integer bit operations.</p>
</li>
<li>
<p dir="auto"><strong>matmul</strong>: multiplying two square matrices of 1500x1500 in size. The inner
loop resembles BLAS' <a href="https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms#Level_1" rel="nofollow">axpy</a> operation.</p>
</li>
<li>
<p dir="auto"><strong>sudoku</strong>: solving 4000 hard <a href="https://en.wikipedia.org/wiki/Sudoku" rel="nofollow">Sudokus</a> (20 puzzles repeated for 200
times) using the <a href="https://attractivechaos.github.io/plb/kudoku.html" rel="nofollow">kudoku algorithm</a>. This algorithm heavily uses
small fixed-sized arrays with a bit complex logic.</p>
</li>
<li>
<p dir="auto"><strong>bedcov</strong>: finding the overlaps between two arrays of 1,000,000 intervals
with <a href="https://academic.oup.com/bioinformatics/article/37/9/1315/5910546" rel="nofollow">implicit interval trees</a>. The algorithm involves frequent
array access in a pattern similar to binary searches.</p>
</li>
</ul>
<p dir="auto">Every language has nqueen and matmul implementations. Some languages do not
have sudoku or bedcov implementations. In addition, I implemented most
algorithms in plb2 and adapted a few contributed matmul and sudoku
implementations in plb. As I am mostly a C programmer, implementations in other
languages may be suboptimal and there are no implementations in functional
languages. <strong>Pull requests are welcomed!</strong></p>
<h2 tabindex="-1" dir="auto"><a name="user-content-result"></a>Results</h2>
<p dir="auto">The figure at the top of the page summarizes the elapsed time of each implementation
measured on an Apple M1 MacBook Pro. <a href="https://github.com/sharkdp/hyperfine">Hyperfine</a> was used for timing
except for a few slow implementations which were timed with the "time" bash
command without repetition. A plus sign "+" indicates an explicit compilation
step. Exact timing can be found in the <a href="#table">table below</a>. The figure was
programmatically generated from the table but may be outdated.</p>
<h3 tabindex="-1" dir="auto"><a name="user-content-overall"></a>Overall impression</h3>
<p dir="auto">Programming language implementations in plb2 can be classified into four groups
depending on how and when compilation is done:</p>
<ol dir="auto">
<li>
<p dir="auto">Purely interpretted with no compilation (Perl and <a href="https://en.wikipedia.org/wiki/CPython" rel="nofollow">CPython</a>, the
official Python implementation). Not surprisingly, these are the slowest
language implementations in this benchmark.</p>
</li>
<li>
<p dir="auto">JIT compiled without a separate compilation step (Dart, all JavaScript
runtimes, Julia, LuaJIT, PHP, PyPy and Ruby3 with <a href="https://github.com/ruby/ruby/blob/master/doc/yjit/yjit.md">YJIT</a>). These
language implementations compile hot code on the fly and then execute. They
have to balance compilation time and running time to achieve the best
overall performance.</p>
<p dir="auto">In this group, although PHP and Ruby3 are faster than Perl and CPython, they
are still an order of magnitude slower than PyPy. The two JavaScript engines
(Bun and Node), Dart and Julia all perform well. They are about twice as
fast as PyPy.</p>
</li>
<li>
<p dir="auto">JIT compiled with a separate compilation step (Java and C#). With separate
compilation, Java and C# can afford to trade compilation time for running
time in theory, but in this benchmark, they are not obviously faster than
those in group 2.</p>
</li>
<li>
<p dir="auto"><a href="https://en.wikipedia.org/wiki/Ahead-of-time_compilation" rel="nofollow">Ahead-of-time compilation</a> (the rest). Optimizing binaries for
specific hardware, these compilers, except Swift, tend to generate the
fastest executables.</p>
</li>
</ol>
<h3 tabindex="-1" dir="auto"><a name="user-content-caveat"></a>Caveats</h3>
<h4 tabindex="-1" dir="auto"><a name="user-content-startup"></a>Startup time</h4>
<p dir="auto">Some JIT-based language runtimes take up to ~0.3 second to compile and warm-up.
We are not separating out this startup time. Nonetheless, because most
benchmarks run for several seconds, including the startup time does not greatly
affect the results.</p>
<h4 tabindex="-1" dir="auto"><a name="user-content-cputime"></a>Elapsed time vs CPU time</h4>
<p dir="auto">Although no implementations use multithreading, language runtimes may be doing
extra work, such as garbage collection, in a separate thread. In this case, the
CPU time (user plus system) may be longer than elapsed wall-clock time. Julia,
in particular, takes noticeably more CPU time than wall-clock time even for the
simplest nqueen benchmark. In plb2, we are measuring the elapsed wall-clock
time because that is the number users often see. The ranking of CPU time may be
slightly different.</p>
<h3 tabindex="-1" dir="auto"><a name="user-content-opt"></a>Subtle optimizations</h3>
<h4 tabindex="-1" dir="auto"><a name="user-content-memlayout"></a>Controlling memory layout</h4>
<p dir="auto">When implementing bedcov in Julia, C and many compiled languages, it is
preferred to have an array of objects in a contiguous memory block such that
adjacent objects are close in memory. This helps cache efficiency. In most
scripting languages, unfortunately, we have to put references to objects in an
array at the cost of cache locality. The issue can be alleviated by cloning
objects to a new array. This doubles the speed of PyPy and Bun.</p>
<h4 tabindex="-1" dir="auto"><a name="user-content-matmul"></a>Optimizing inner loops</h4>
<p dir="auto">The bottleneck of matrix multiplication falls in the following nested loop:</p>
<div dir="auto" data-snippet-clipboard-copy-content="for (int i = 0; i < n; ++i)
    for (int k = 0; k < n; ++k)
        for (int j = 0; j < n; ++j)
            c[i][j] += a[i][k] * b[k][j];"><pre><span>for</span> (<span>int</span> i = <span>0</span>; i &lt; n; ++i)
    <span>for</span> (<span>int</span> k = <span>0</span>; k &lt; n; ++k)
        <span>for</span> (<span>int</span> j = <span>0</span>; j &lt; n; ++j)
            c[i][j] += a[i][k] * b[k][j];</pre></div>
<p dir="auto">It is obvious that <code>c[i]</code>, <code>b[k]</code> and <code>a[i][k]</code> can be moved out of the inner
loop to reduce the frequency of matrix access. The Clang compiler can apply
this optimization. Manual optimization may actually hurt performance.</p>
<p dir="auto">However, <strong>most other languages cannot optimize this nested loop.</strong> If we
manually move <code>a[i][k]</code> to the loop above it, we can often improve their
performance. Some C/C++ programmers say compilers often optimize better than
human, but this might not be the case in other languages.</p>
<h2 tabindex="-1" dir="auto"><a name="user-content-conclusion"></a>Discussions</h2>
<p dir="auto">The most well-known and the longest running language benchmark is the <a href="https://benchmarksgame-team.pages.debian.net/benchmarksgame/index.html" rel="nofollow">Computer
Language Benchmark Games</a>. Plb2 differs in that it includes more recent
languages (e.g. Nim and Crystal), more language runtimes (e.g. PyPy and
LuaJIT) and more tasks (all four tasks are new), and it comes with more uniform
implementations and focuses more on the performance of the language itself
without library functions. <strong>Plb2 complements the Computer Language Benchmark
Games.</strong></p>
<p dir="auto">One important area that plb2 does not evaluate is the performance of memory
allocation and/or garbage collection. This may contribute more to practical
performance than generating machine code. Nonetheless, it is challenging to
design a realistic micro-benchmark to evaluate memory allocation. If the
built-in allocator in a language implementation does not work well, we can
implement customized memory allocator just for the specific task but this, in
my view, would not represent typical use cases.</p>
<p dir="auto">When plb was conducted in 2011, half of the languages in the figure above were
not mature or even did not exist. It is exciting to see many of them have
reached the 1.0 milestone and are gaining popularity among modern programmers.
On the other hand, Python remains one of the two most used scripting languages
despite its poor performance. In my view, this is because PyPy would not be
officially endorsed while other JIT-based languages are not general or good
enough. Will there be a language to displace Python in the next decade? I am
not optimistic.</p>
<h2 tabindex="-1" dir="auto"><a name="user-content-table"></a>Appendix: Timing on Apple M1 Macbook Pro</h2>
<table>
<thead>
<tr>
<th>Label</th>
<th>Language</th>
<th>Runtime</th>
<th>Version</th>
<th>nqueen</th>
<th>matmul</th>
<th>sudoku</th>
<th>bedcov</th>
</tr>
</thead>
<tbody>
<tr>
<td>c:clang+</td>
<td>C</td>
<td>Clang</td>
<td>15.0.0</td>
<td>2.70</td>
<td>0.54</td>
<td>1.54</td>
<td>0.84</td>
</tr>
<tr>
<td>crystal+</td>
<td>Crystal</td>
<td></td>
<td>1.10.0</td>
<td>3.28</td>
<td>2.45</td>
<td></td>
<td>0.87</td>
</tr>
<tr>
<td>c#:.net+</td>
<td>C#</td>
<td>.NET</td>
<td>8.0.100</td>
<td>3.00</td>
<td>4.67</td>
<td>3.01</td>
<td></td>
</tr>
<tr>
<td>d:ldc2+</td>
<td>D</td>
<td>LDC2</td>
<td>2.105.2</td>
<td>2.68</td>
<td>0.57</td>
<td>1.60</td>
<td></td>
</tr>
<tr>
<td>dart</td>
<td>Dart</td>
<td>(JIT)</td>
<td>3.2.4</td>
<td>3.62</td>
<td>4.81</td>
<td>3.24</td>
<td></td>
</tr>
<tr>
<td>go+</td>
<td>Go</td>
<td></td>
<td>1.21.5</td>
<td>2.94</td>
<td>1.63</td>
<td>2.04</td>
<td></td>
</tr>
<tr>
<td>java+</td>
<td>Java</td>
<td>OpenJDK</td>
<td>20.0.1</td>
<td>3.92</td>
<td>1.14</td>
<td>3.20</td>
<td></td>
</tr>
<tr>
<td>js:bun</td>
<td>JavaScript</td>
<td>Bun</td>
<td>1.0.20</td>
<td>3.11</td>
<td>1.75</td>
<td>3.07</td>
<td>2.83</td>
</tr>
<tr>
<td>js:deno</td>
<td>JavaScript</td>
<td>Deno</td>
<td>1.39.1</td>
<td>4.00</td>
<td>3.06</td>
<td>4.04</td>
<td>3.87</td>
</tr>
<tr>
<td>js:k8</td>
<td>JavaScript</td>
<td>k8</td>
<td>1.0</td>
<td>3.79</td>
<td>2.99</td>
<td>3.76</td>
<td>4.02</td>
</tr>
<tr>
<td>js:node</td>
<td>JavaScript</td>
<td>Node</td>
<td>21.5.0</td>
<td>3.73</td>
<td>2.88</td>
<td>3.77</td>
<td>3.83</td>
</tr>
<tr>
<td>julia</td>
<td>Julia</td>
<td></td>
<td>1.10.0</td>
<td>3.75</td>
<td>0.76</td>
<td>2.72</td>
<td>2.47</td>
</tr>
<tr>
<td>luajit</td>
<td>Lua</td>
<td>LuaJIT</td>
<td>2.1</td>
<td>5.31</td>
<td>2.66</td>
<td>4.48</td>
<td>10.59</td>
</tr>
<tr>
<td>mojo+</td>
<td>Mojo</td>
<td></td>
<td>0.6.1</td>
<td>3.24</td>
<td>1.12</td>
<td></td>
<td></td>
</tr>
<tr>
<td>nim+</td>
<td>Nim</td>
<td></td>
<td>2.0.2</td>
<td>3.18</td>
<td>0.69</td>
<td></td>
<td>1.18</td>
</tr>
<tr>
<td>perl</td>
<td>Perl</td>
<td></td>
<td>5.34.1</td>
<td>158.34</td>
<td>158.01</td>
<td>90.78</td>
<td></td>
</tr>
<tr>
<td>php</td>
<td>PHP</td>
<td></td>
<td>8.3</td>
<td>48.15</td>
<td>71.20</td>
<td></td>
<td></td>
</tr>
<tr>
<td>py:pypy</td>
<td>Python</td>
<td>Pypy</td>
<td>7.3.14</td>
<td>6.91</td>
<td>4.95</td>
<td>8.82</td>
<td>6.27</td>
</tr>
<tr>
<td>py:cpy</td>
<td>Python</td>
<td>CPython</td>
<td>3.11.7</td>
<td>159.97</td>
<td>223.66</td>
<td>52.88</td>
<td>42.84</td>
</tr>
<tr>
<td>ruby</td>
<td>Ruby</td>
<td>(YJIT)</td>
<td>3.3.0</td>
<td>88.15</td>
<td>130.51</td>
<td>52.26</td>
<td></td>
</tr>
<tr>
<td>rust+</td>
<td>Rust</td>
<td></td>
<td>1.75.0</td>
<td>2.68</td>
<td>0.56</td>
<td>1.65</td>
<td></td>
</tr>
<tr>
<td>swift+</td>
<td>Swift</td>
<td></td>
<td>5.9.0</td>
<td>2.92</td>
<td>7.46</td>
<td>16.02</td>
<td></td>
</tr>
<tr>
<td>v+</td>
<td>V</td>
<td></td>
<td>0.4.3</td>
<td>2.57</td>
<td>0.56</td>
<td></td>
<td></td>
</tr>
<tr>
<td>zig+</td>
<td>Zig</td>
<td></td>
<td>0.11.0</td>
<td>2.74</td>
<td>0.56</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GCC Specs: An Introduction (107 pts)]]></title>
            <link>https://wozniak.ca/blog/2024/01/02/1/index.html</link>
            <guid>38850400</guid>
            <pubDate>Wed, 03 Jan 2024 03:35:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://wozniak.ca/blog/2024/01/02/1/index.html">https://wozniak.ca/blog/2024/01/02/1/index.html</a>, See on <a href="https://news.ycombinator.com/item?id=38850400">Hacker News</a></p>
Couldn't get https://wozniak.ca/blog/2024/01/02/1/index.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Sieve is simpler than LRU (225 pts)]]></title>
            <link>https://cachemon.github.io/SIEVE-website/blog/2023/12/17/sieve-is-simpler-than-lru/</link>
            <guid>38850202</guid>
            <pubDate>Wed, 03 Jan 2024 03:07:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cachemon.github.io/SIEVE-website/blog/2023/12/17/sieve-is-simpler-than-lru/">https://cachemon.github.io/SIEVE-website/blog/2023/12/17/sieve-is-simpler-than-lru/</a>, See on <a href="https://news.ycombinator.com/item?id=38850202">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-md-component="container"> <main data-md-component="main"> <div data-md-component="content">  <article>  <p>Caching is a method of storing temporary data for quick access to keep the online world running smoothly. But with limited space, comes a critical decision: what to keep and what to discard. This is where <strong>eviction algorithms</strong> come into play. Our team recently designed a new cache eviction algorithm called <strong>SIEVE</strong>: it is both very effective and simple with just one FIFO queue.</p> <!-- more --> <h2 id="the-importance-of-simplicity">The Importance of Simplicity<a href="#the-importance-of-simplicity" title="Permanent link">¶</a></h2> <p>In the world of cache eviction algorithms, there's something to be said for keeping it simple. Complex algorithms, for all their sophistication, can bring their own set of headaches. They can be tricky to debug, sometimes unexpectedly drag down efficiency, and even put a damper on throughput and scalability because of their higher computational needs. </p> <p>On the flip side, simpler eviction methods, though maybe not as flashy in managing cache, have a knack for improving system throughput and scalability. Just look at examples like <a href="https://www.usenix.org/conference/nsdi13/technical-sessions/presentation/fan">MemC3</a> and <a href="https://www.usenix.org/conference/nsdi21/presentation/yang-juncheng">Segcache</a>. They rely on straightforward approaches like FIFO and manage to significantly boost system performance. It turns out, sometimes, the best move is to keep things uncomplicated!</p> <h2 id="meet-sieve-the-harmony-of-simplicity-and-efficiency">Meet SIEVE: The Harmony of Simplicity and Efficiency<a href="#meet-sieve-the-harmony-of-simplicity-and-efficiency" title="Permanent link">¶</a></h2> <p>SIEVE is an algorithm that decides what to keep in the cache and what to discard. But unlike its predecessors, it does this with a flair for simplicity and efficiency.</p> <h3 id="a-technical-walkthrough-of-sieve">A Technical Walkthrough of SIEVE<a href="#a-technical-walkthrough-of-sieve" title="Permanent link">¶</a></h3> <p>SIEVE is built on a FIFO queue, supplemented by a "hand" pointer that navigates through the cache. Each object in the queue has a bit indicating whether it's been visited. On a cache hit, SIEVE marks the object as visited. On a cache miss, SIEVE checks the object pointed to by the hand. If the object has been visited, its visited bit is reset, and the hand moves to the next position, keeping the retained object in its original position in the queue. This continues until an unvisited object is found and evicted. After eviction, the hand moves to the next position.</p> <figure> <p><img src="https://cachemon.github.io/SIEVE-website/blog/assets/sieve/sieve_diagram_animation.gif" alt="sieve-diagram-gif"> </p> <figcaption>An iilustration of SIEVE</figcaption> </figure> <p>At first glance, SIEVE is similar to CLOCK/Second Chance/FIFO-Reinsertion - <em>Note that they are different implementations of the same eviction algorithm</em>. Each algorithm maintains a single queue in which each object is associated with a visited bit to track its access status. Visited objects are retained (also called "survived") during an eviction. Notably, new objects are inserted at the head of the queue in both SIEVE and FIFO-Reinsertion. However, the hand in SIEVE moves from the tail to the head over time, whereas the hand in FIFO-Reinsertion stays at the tail. <strong>The key difference is where a retained object is kept.</strong> SIEVE keeps it in the old position, while FIFO-Reinsertion inserts it at the head, together with newly inserted objects.</p> <figure> <p><img src="https://cachemon.github.io/SIEVE-website/blog/assets/sieve/sieve-diagram.png" alt="figure-sieve-efficiency-small"> </p> <figcaption>SIEVE vs. CLOCK</figcaption> </figure> <!-- ```bash title="SIEVE pseudocode"
Input: The request x, doubly-linked queue T, cache size C, hand p
1: if x is in T then                            # Cache Hit
2:     x.visited <- true
3: else                                         # Cache Miss
4:     if |T| = C then                          # Cache Full
5:         obj <- p
6:         if obj is NULL then
7:             obj <- tail of T
8:         while obj.visited = true do
9:             obj.visited <- false
10:            obj <- obj.prev
11:            if obj is NULL then
12:                obj <- tail of T
13:        p <- obj.prev
14:        Discard obj in T                     # Eviction
15:    Insert x in the head of T
16:    x.visited <- false                       # Insertion
``` --> <p>For anyone interested, see the <a href="#sieve-cache-code">sieve cache implementation code</a> at the end of this blog post for a detailed example.</p> <h3 id="sieves-real-world-impact-a-performance-breakdown">SIEVE's Real-World Impact: A Performance Breakdown<a href="#sieves-real-world-impact-a-performance-breakdown" title="Permanent link">¶</a></h3> <p>SIEVE's practicality shines in its real-world application. </p> <h4 id="efficiency">Efficiency<a href="#efficiency" title="Permanent link">¶</a></h4> <p>Our evaluation, involving over 1559 traces from diverse datasets that together contain 247,017 million requests to 14,852 million objects, show that SIEVE outperforms all state-of-the-art eviction algorithms on more than 45% of the traces.</p> <p>The following figure shows the miss ratio reduction (from FIFO) of different algorithms across traces. The whiskers on the boxplots are defined using p10 and p90, allowing us to disregard extreme data and concentrate on the typical cases. SIEVE demonstrates the most significant reductions across nearly all percentiles. For example, SIEVE reduces FIFO’s miss ratio by more than 42% on 10% of the traces (top whisker) with a mean of 21% on the one of the largest CDN company dataset. As a comparison, all other algorithms have smaller reductions on this dataset. Compared to advanced algorithms, e.g., ARC, SIEVE reduces ARC miss ratio by up to 63.2% with a mean of 1.5%.</p> <!-- While SIEVE excels with large caches, it faces competition at smaller sizes from algorithms like TwoQ and LHD. This is due to their ability to quickly discard low-value objects, a challenge for SIEVE when cache space is limited. However, at larger cache sizes, where real-world applications often operate, SIEVE consistently outperforms its peers. --> <figure> <p><img src="https://cachemon.github.io/SIEVE-website/blog/assets/sieve/efficiency-large.png" alt="figure-sieve-efficiency-large"></p> <!-- <figcaption>Image caption</figcaption> --> </figure> <h4 id="simplicity">Simplicity<a href="#simplicity" title="Permanent link">¶</a></h4> <p>SIEVE is very simple. We delved into the most popular cache libraries and systems across five diverse programming languages: C++, Go, JavaScript, Python, and Rust. </p> <p>Despite the varied ways LRU is implemented across these libraries - some opt for doubly-linked lists, others for arrays - integrating SIEVE turned out to be a breeze. Whether it's the structural differences or the coding style, SIEVE slotted in smoothly. As illustrated in the Table, the required code changes to replace LRU with SIEVE were minimal. In all cases, it took no more than 21 lines of code modifications (tests not included).</p> <figure> <table> <thead> <tr> <th>Cache library</th> <th>Language</th> <th>Lines</th> <th>Hour of Work</th> </tr> </thead> <tbody> <tr> <td><a href="https://github.com/cacheMon/groupcache">groupcache</a></td> <td>Golang</td> <td>21</td> <td>&lt;1</td> </tr> <tr> <td><a href="https://github.com/cacheMon/mnemonist">mnemonist</a></td> <td>Javascript</td> <td>12</td> <td>1</td> </tr> <tr> <td><a href="https://github.com/cacheMon/lru-rs">lru-rs</a></td> <td>Rust</td> <td>16</td> <td>1</td> </tr> <tr> <td><a href="https://github.com/cacheMon/lru-dict">lru-dict</a></td> <td>Python + C</td> <td>21</td> <td>&lt;1</td> </tr> </tbody> </table> </figure> <h4 id="throughput">Throughput<a href="#throughput" title="Permanent link">¶</a></h4> <p>Besides efficiency, throughput is the other important metric for caching systems. Although we have implemented SIEVE in five different libraries, we focus on Cachelib’s results.</p> <p>Compared to these LRU-based algorithms, SIEVE does not require “promotion” at each cache hit. Therefore, it is faster and more scalable. At a single thread, SIEVE is 16% (17%) faster than the optimized LRU (TwoQ) and on the tested traces. At 16 threads, SIEVE shows more than 2× higher throughput than the optimized LRU and TwoQ.</p> <!-- In Cachelib, LRU and TwoQ have been tweaked for better scalability. With smart moves like limiting promotion frequency and introducing lock combining, we've seen a 6× increase in throughput at 16 threads, a significant jump from just one thread on the Twitter trace. On the other hand, the classic, unoptimized LRU hits its limit at 4 threads.

SIEVE takes a different approach, eliminating the need for promotion with each cache hit. This simplicity pays off. On a single thread, SIEVE is 16% faster than the spruced-up LRU and 17% quicker than TwoQ on both traces. When ramped up to 16 threads, SIEVE's throughput more than doubles compared to these algorithms on the Meta trace, showcasing its effortless scalability. --> <h3 id="sieve-is-beyond-an-eviction-algorithm">SIEVE is beyond an eviction algorithm<a href="#sieve-is-beyond-an-eviction-algorithm" title="Permanent link">¶</a></h3> <p>SIEVE isn't just playing the part of a cache eviction algorithm; it's stepping up as a cache design superstar. Think of it like giving a fresh spin to classics. We've plugged SIEVE into <a href="https://www.usenix.org/conference/hotstorage18/presentation/vietri">LeCaR</a>, <a href="https://www.vldb.org/conf/1994/P439.PDF">TwoQ</a>, <a href="https://www.usenix.org/conference/fast-03/arc-self-tuning-low-overhead-replacement-cache">ARC</a>, and <a href="https://dl.acm.org/doi/10.1145/3600006.3613147">S3-FIFO</a>, swapping out their LRU or FIFO queue for a SIEVE one.</p> <p>Swapping LRU with SIEVE in these algorithms isn't just a minor tweak; it's more like giving them a turbo boost. Take ARC-SIEVE, for instance – it's turning heads with its slick efficiency, especially noticeable across different cache sizes. We didn't stop there. We pushed SIEVE a bit further by letting it peek into the future – well, sort of. We tested how well it could guess the next request. It turns out, with this extra bit of foresight, SIEVE is nailing it, outperforming the rest in almost all scenarios.</p> <figure> <p><img src="https://cachemon.github.io/SIEVE-website/blog/assets/sieve/sieve_queue_all_large.svg" alt="figure-sieve-efficiency-small"> </p> <!-- <figcaption>An iilustration of SIEVE</figcaption> --> </figure> <h3 id="sieve-is-not-scan-resistant">SIEVE is not scan-resistant<a href="#sieve-is-not-scan-resistant" title="Permanent link">¶</a></h3> <p>Besides web cache workloads, we evaluated SIEVE on some block cache workloads. However, we find that SIEVE sometimes shows a miss ratio higher than LRU. The primary reason for this discrepancy is that SIEVE is not scan-resistant. In block cache workloads, which frequently feature scans, popular objects often intermingle with objects from scans. Consequently, both types of objects are rapidly evicted after insertion.</p> <p><a href="https://brooker.co.za/blog/2023/12/15/sieve.html">Marc's latest blog post</a> has explored the idea of making sieve scan-resistant by adding a small counter for each item. It shows some wins and losses on different workloads. We're really excited to see how this plays out in the real world. If you're an engineer, a tech enthusiast, or just someone who enjoys playing around with systems, we'd absolutely love for you to give SIEVE a whirl in your setups. </p> <h2 id="wed-love-to-hear-from-you">We'd Love to Hear from you<a href="#wed-love-to-hear-from-you" title="Permanent link">¶</a></h2> <p>As we wrap up this blog post, we would like to give a big shoutout to the people and organizations that open-sourced and shared the traces. We believe SIEVE presents an intriguing opportunity to explore and enhance the efficiency of web caching. <strong>If you have questions, thoughts, or if you've given SIEVE a try, we're eager to hear from you! Don't hesitate to get in touch :-)</strong></p> <h2 id="appendix">Appendix<a href="#appendix" title="Permanent link">¶</a></h2> <div id="sieve-cache-code"><p><span>SIEVE Python Implementation</span></p><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span>class</span> <span>Node</span><span>:</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>value</span><span>):</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>        <span>self</span><span>.</span><span>value</span> <span>=</span> <span>value</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>        <span>self</span><span>.</span><span>visited</span> <span>=</span> <span>False</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>        <span>self</span><span>.</span><span>prev</span> <span>=</span> <span>None</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>        <span>self</span><span>.</span><span>next</span> <span>=</span> <span>None</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a><span>class</span> <span>SieveCache</span><span>:</span>
</span><span id="__span-0-9"><a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>capacity</span><span>):</span>
</span><span id="__span-0-10"><a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>        <span>self</span><span>.</span><span>capacity</span> <span>=</span> <span>capacity</span>
</span><span id="__span-0-11"><a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>        <span>self</span><span>.</span><span>cache</span> <span>=</span> <span>{}</span>  <span># To store cache items as {value: node}</span>
</span><span id="__span-0-12"><a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>        <span>self</span><span>.</span><span>head</span> <span>=</span> <span>None</span>
</span><span id="__span-0-13"><a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>        <span>self</span><span>.</span><span>tail</span> <span>=</span> <span>None</span>
</span><span id="__span-0-14"><a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>        <span>self</span><span>.</span><span>hand</span> <span>=</span> <span>None</span>
</span><span id="__span-0-15"><a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a>        <span>self</span><span>.</span><span>size</span> <span>=</span> <span>0</span>
</span><span id="__span-0-16"><a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a>
</span><span id="__span-0-17"><a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a>    <span>def</span> <span>_add_to_head</span><span>(</span><span>self</span><span>,</span> <span>node</span><span>):</span>
</span><span id="__span-0-18"><a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a>        <span>node</span><span>.</span><span>next</span> <span>=</span> <span>self</span><span>.</span><span>head</span>
</span><span id="__span-0-19"><a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a>        <span>node</span><span>.</span><span>prev</span> <span>=</span> <span>None</span>
</span><span id="__span-0-20"><a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a>        <span>if</span> <span>self</span><span>.</span><span>head</span><span>:</span>
</span><span id="__span-0-21"><a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a>            <span>self</span><span>.</span><span>head</span><span>.</span><span>prev</span> <span>=</span> <span>node</span>
</span><span id="__span-0-22"><a id="__codelineno-0-22" name="__codelineno-0-22" href="#__codelineno-0-22"></a>        <span>self</span><span>.</span><span>head</span> <span>=</span> <span>node</span>
</span><span id="__span-0-23"><a id="__codelineno-0-23" name="__codelineno-0-23" href="#__codelineno-0-23"></a>        <span>if</span> <span>self</span><span>.</span><span>tail</span> <span>is</span> <span>None</span><span>:</span>
</span><span id="__span-0-24"><a id="__codelineno-0-24" name="__codelineno-0-24" href="#__codelineno-0-24"></a>            <span>self</span><span>.</span><span>tail</span> <span>=</span> <span>node</span>
</span><span id="__span-0-25"><a id="__codelineno-0-25" name="__codelineno-0-25" href="#__codelineno-0-25"></a>
</span><span id="__span-0-26"><a id="__codelineno-0-26" name="__codelineno-0-26" href="#__codelineno-0-26"></a>    <span>def</span> <span>_remove_node</span><span>(</span><span>self</span><span>,</span> <span>node</span><span>):</span>
</span><span id="__span-0-27"><a id="__codelineno-0-27" name="__codelineno-0-27" href="#__codelineno-0-27"></a>        <span>if</span> <span>node</span><span>.</span><span>prev</span><span>:</span>
</span><span id="__span-0-28"><a id="__codelineno-0-28" name="__codelineno-0-28" href="#__codelineno-0-28"></a>            <span>node</span><span>.</span><span>prev</span><span>.</span><span>next</span> <span>=</span> <span>node</span><span>.</span><span>next</span>
</span><span id="__span-0-29"><a id="__codelineno-0-29" name="__codelineno-0-29" href="#__codelineno-0-29"></a>        <span>else</span><span>:</span>
</span><span id="__span-0-30"><a id="__codelineno-0-30" name="__codelineno-0-30" href="#__codelineno-0-30"></a>            <span>self</span><span>.</span><span>head</span> <span>=</span> <span>node</span><span>.</span><span>next</span>
</span><span id="__span-0-31"><a id="__codelineno-0-31" name="__codelineno-0-31" href="#__codelineno-0-31"></a>        <span>if</span> <span>node</span><span>.</span><span>next</span><span>:</span>
</span><span id="__span-0-32"><a id="__codelineno-0-32" name="__codelineno-0-32" href="#__codelineno-0-32"></a>            <span>node</span><span>.</span><span>next</span><span>.</span><span>prev</span> <span>=</span> <span>node</span><span>.</span><span>prev</span>
</span><span id="__span-0-33"><a id="__codelineno-0-33" name="__codelineno-0-33" href="#__codelineno-0-33"></a>        <span>else</span><span>:</span>
</span><span id="__span-0-34"><a id="__codelineno-0-34" name="__codelineno-0-34" href="#__codelineno-0-34"></a>            <span>self</span><span>.</span><span>tail</span> <span>=</span> <span>node</span><span>.</span><span>prev</span>
</span><span id="__span-0-35"><a id="__codelineno-0-35" name="__codelineno-0-35" href="#__codelineno-0-35"></a>
</span><span id="__span-0-36"><a id="__codelineno-0-36" name="__codelineno-0-36" href="#__codelineno-0-36"></a>    <span>def</span> <span>_evict</span><span>(</span><span>self</span><span>):</span>
</span><span id="__span-0-37"><a id="__codelineno-0-37" name="__codelineno-0-37" href="#__codelineno-0-37"></a>        <span>obj</span> <span>=</span> <span>self</span><span>.</span><span>hand</span> <span>if</span> <span>self</span><span>.</span><span>hand</span> <span>else</span> <span>self</span><span>.</span><span>tail</span>
</span><span id="__span-0-38"><a id="__codelineno-0-38" name="__codelineno-0-38" href="#__codelineno-0-38"></a>        <span>while</span> <span>obj</span> <span>and</span> <span>obj</span><span>.</span><span>visited</span><span>:</span>
</span><span id="__span-0-39"><a id="__codelineno-0-39" name="__codelineno-0-39" href="#__codelineno-0-39"></a>            <span>obj</span><span>.</span><span>visited</span> <span>=</span> <span>False</span>
</span><span id="__span-0-40"><a id="__codelineno-0-40" name="__codelineno-0-40" href="#__codelineno-0-40"></a>            <span>obj</span> <span>=</span> <span>obj</span><span>.</span><span>prev</span> <span>if</span> <span>obj</span><span>.</span><span>prev</span> <span>else</span> <span>self</span><span>.</span><span>tail</span>
</span><span id="__span-0-41"><a id="__codelineno-0-41" name="__codelineno-0-41" href="#__codelineno-0-41"></a>        <span>self</span><span>.</span><span>hand</span> <span>=</span> <span>obj</span><span>.</span><span>prev</span> <span>if</span> <span>obj</span><span>.</span><span>prev</span> <span>else</span> <span>None</span>
</span><span id="__span-0-42"><a id="__codelineno-0-42" name="__codelineno-0-42" href="#__codelineno-0-42"></a>        <span>del</span> <span>self</span><span>.</span><span>cache</span><span>[</span><span>obj</span><span>.</span><span>value</span><span>]</span>
</span><span id="__span-0-43"><a id="__codelineno-0-43" name="__codelineno-0-43" href="#__codelineno-0-43"></a>        <span>self</span><span>.</span><span>_remove_node</span><span>(</span><span>obj</span><span>)</span>
</span><span id="__span-0-44"><a id="__codelineno-0-44" name="__codelineno-0-44" href="#__codelineno-0-44"></a>        <span>self</span><span>.</span><span>size</span> <span>-=</span> <span>1</span>
</span><span id="__span-0-45"><a id="__codelineno-0-45" name="__codelineno-0-45" href="#__codelineno-0-45"></a>
</span><span id="__span-0-46"><a id="__codelineno-0-46" name="__codelineno-0-46" href="#__codelineno-0-46"></a>    <span>def</span> <span>access</span><span>(</span><span>self</span><span>,</span> <span>x</span><span>):</span>
</span><span id="__span-0-47"><a id="__codelineno-0-47" name="__codelineno-0-47" href="#__codelineno-0-47"></a>        <span>if</span> <span>x</span> <span>in</span> <span>self</span><span>.</span><span>cache</span><span>:</span>  <span># Cache Hit</span>
</span><span id="__span-0-48"><a id="__codelineno-0-48" name="__codelineno-0-48" href="#__codelineno-0-48"></a>            <span>node</span> <span>=</span> <span>self</span><span>.</span><span>cache</span><span>[</span><span>x</span><span>]</span>
</span><span id="__span-0-49"><a id="__codelineno-0-49" name="__codelineno-0-49" href="#__codelineno-0-49"></a>            <span>node</span><span>.</span><span>visited</span> <span>=</span> <span>True</span>
</span><span id="__span-0-50"><a id="__codelineno-0-50" name="__codelineno-0-50" href="#__codelineno-0-50"></a>        <span>else</span><span>:</span>  <span># Cache Miss</span>
</span><span id="__span-0-51"><a id="__codelineno-0-51" name="__codelineno-0-51" href="#__codelineno-0-51"></a>            <span>if</span> <span>self</span><span>.</span><span>size</span> <span>==</span> <span>self</span><span>.</span><span>capacity</span><span>:</span>  <span># Cache Full</span>
</span><span id="__span-0-52"><a id="__codelineno-0-52" name="__codelineno-0-52" href="#__codelineno-0-52"></a>                <span>self</span><span>.</span><span>_evict</span><span>()</span>  <span># Eviction</span>
</span><span id="__span-0-53"><a id="__codelineno-0-53" name="__codelineno-0-53" href="#__codelineno-0-53"></a>            <span>new_node</span> <span>=</span> <span>Node</span><span>(</span><span>x</span><span>)</span>
</span><span id="__span-0-54"><a id="__codelineno-0-54" name="__codelineno-0-54" href="#__codelineno-0-54"></a>            <span>self</span><span>.</span><span>_add_to_head</span><span>(</span><span>new_node</span><span>)</span>
</span><span id="__span-0-55"><a id="__codelineno-0-55" name="__codelineno-0-55" href="#__codelineno-0-55"></a>            <span>self</span><span>.</span><span>cache</span><span>[</span><span>x</span><span>]</span> <span>=</span> <span>new_node</span>
</span><span id="__span-0-56"><a id="__codelineno-0-56" name="__codelineno-0-56" href="#__codelineno-0-56"></a>            <span>self</span><span>.</span><span>size</span> <span>+=</span> <span>1</span>
</span><span id="__span-0-57"><a id="__codelineno-0-57" name="__codelineno-0-57" href="#__codelineno-0-57"></a>            <span>new_node</span><span>.</span><span>visited</span> <span>=</span> <span>False</span>  <span># Insertion</span>
</span><span id="__span-0-58"><a id="__codelineno-0-58" name="__codelineno-0-58" href="#__codelineno-0-58"></a>
</span><span id="__span-0-59"><a id="__codelineno-0-59" name="__codelineno-0-59" href="#__codelineno-0-59"></a>    <span>def</span> <span>show_cache</span><span>(</span><span>self</span><span>):</span>
</span><span id="__span-0-60"><a id="__codelineno-0-60" name="__codelineno-0-60" href="#__codelineno-0-60"></a>        <span>current</span> <span>=</span> <span>self</span><span>.</span><span>head</span>
</span><span id="__span-0-61"><a id="__codelineno-0-61" name="__codelineno-0-61" href="#__codelineno-0-61"></a>        <span>while</span> <span>current</span><span>:</span>
</span><span id="__span-0-62"><a id="__codelineno-0-62" name="__codelineno-0-62" href="#__codelineno-0-62"></a>            <span>print</span><span>(</span><span>f</span><span>'</span><span>{</span><span>current</span><span>.</span><span>value</span><span>}</span><span> (Visited: </span><span>{</span><span>current</span><span>.</span><span>visited</span><span>}</span><span>)'</span><span>,</span> <span>end</span><span>=</span><span>' -&gt; '</span> <span>if</span> <span>current</span><span>.</span><span>next</span> <span>else</span> <span>'</span><span>\n</span><span>'</span><span>)</span>
</span><span id="__span-0-63"><a id="__codelineno-0-63" name="__codelineno-0-63" href="#__codelineno-0-63"></a>            <span>current</span> <span>=</span> <span>current</span><span>.</span><span>next</span>
</span><span id="__span-0-64"><a id="__codelineno-0-64" name="__codelineno-0-64" href="#__codelineno-0-64"></a>
</span><span id="__span-0-65"><a id="__codelineno-0-65" name="__codelineno-0-65" href="#__codelineno-0-65"></a><span># Example usage</span>
</span><span id="__span-0-66"><a id="__codelineno-0-66" name="__codelineno-0-66" href="#__codelineno-0-66"></a><span>cache</span> <span>=</span> <span>SieveCache</span><span>(</span><span>3</span><span>)</span>
</span><span id="__span-0-67"><a id="__codelineno-0-67" name="__codelineno-0-67" href="#__codelineno-0-67"></a><span>cache</span><span>.</span><span>access</span><span>(</span><span>'A'</span><span>)</span>
</span><span id="__span-0-68"><a id="__codelineno-0-68" name="__codelineno-0-68" href="#__codelineno-0-68"></a><span>cache</span><span>.</span><span>access</span><span>(</span><span>'B'</span><span>)</span>
</span><span id="__span-0-69"><a id="__codelineno-0-69" name="__codelineno-0-69" href="#__codelineno-0-69"></a><span>cache</span><span>.</span><span>access</span><span>(</span><span>'C'</span><span>)</span>
</span><span id="__span-0-70"><a id="__codelineno-0-70" name="__codelineno-0-70" href="#__codelineno-0-70"></a><span>cache</span><span>.</span><span>access</span><span>(</span><span>'D'</span><span>)</span>
</span><span id="__span-0-71"><a id="__codelineno-0-71" name="__codelineno-0-71" href="#__codelineno-0-71"></a><span>cache</span><span>.</span><span>show_cache</span><span>()</span>
</span></code></pre></div> </article> </div>  </main>  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[With revenue and users declining, Mozilla CEO gets a 20% raise (351 pts)]]></title>
            <link>https://www.theregister.com/2024/01/02/mozilla_in_2024_ai_privacy/</link>
            <guid>38849580</guid>
            <pubDate>Wed, 03 Jan 2024 01:29:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2024/01/02/mozilla_in_2024_ai_privacy/">https://www.theregister.com/2024/01/02/mozilla_in_2024_ai_privacy/</a>, See on <a href="https://news.ycombinator.com/item?id=38849580">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>Mozilla closed out 2023 with a report that dodges its flatlining browser market share and Mozilla.social beta in favor of calls for a faster pace from its highly paid CEO.</p>
<p>According to the company's filings, Mitchell Baker's compensation went from $5,591,406 <a target="_blank" rel="nofollow" href="https://assets.mozilla.net/annualreport/2021/mozilla-fdn-990-ty21-public-disclosure.pdf">in 2021</a> [PDF] to $6,903,089 <a target="_blank" rel="nofollow" href="https://assets.mozilla.net/annualreport/2022/mozilla-fdn-990-ty22-public-disclosure.pdf">in 2022</a> [PDF]. It's quite the jump considering that revenues declined from $527,585,000 to $510,389,000 in <a target="_blank" rel="nofollow" href="https://assets.mozilla.net/annualreport/2022/mozilla-fdn-2022-fs-final-0908.pdf">the same period</a> [PDF].</p>
<p>Despite the executive payout, Firefox continues to trail Google and even Microsoft in desktop browser market share. While it has not suffered any catastrophic losses, neither has it made any significant gains.</p>

    

<p>Baker, however, would very much like to speed things up and says in the <a target="_blank" rel="nofollow" href="https://stateof.mozilla.org/#">State of Mozilla report</a>: "The pace is not enough, the impact is not enough."</p>

        


        

<p>Unsurprisingly for a technology company, the report is heavy on AI going mainstream where Mozilla reckons it can make an impact in the technology, particularly with regard to open source developers and privacy.</p>
<p>Mozilla's adventures in AI? The organization says it has 15 engineers working on open source large language models and is working on use cases in the healthcare space. Moez Draief, managing director of Mozilla.ai, said: "There's a lot of structured data work in that industry that will feed the language models; we don't have to invent it."</p>
<ul>

<li><a href="https://www.theregister.com/2023/12/21/mozilla_decides_trusted_types_is/">Mozilla decides Trusted Types is a worthy security feature</a></li>

<li><a href="https://www.theregister.com/2023/12/20/firefox_121_released/">Penguins get their Wayland with Firefox 121</a></li>

<li><a href="https://www.theregister.com/2023/11/21/ad_block_google/">Firefox slow to load YouTube? Just another front in Google's war on ad blockers</a></li>

<li><a href="https://www.theregister.com/2023/11/15/google_amazon_microsoft_mozilla/">Google, Amazon, Microsoft make the Mozilla naughty list for Christmas shopping</a></li>
</ul>
<p>Earlier this year, Mozilla had to <a target="_blank" href="https://www.theregister.com/2023/07/06/mozilla_ai_explain_shift/">hit pause on its AI chatbot</a> after the service served up a worrying amount of nonsense in response to user queries.</p>
<p>Chief product officer Steve Teixeira notes in the report the rapid growth of AI and social networks, although warns that Mozilla.social is unlikely to move beyond the experimentation phase in 2024. He says that Mozilla would be "exploring ways to better integrate advertising while adhering to our focus on privacy and choice," including web browsing.</p>

        

<p>Teixeira also acknowledged subscription services such as Mozilla VPN and Relay.</p>
<p>It will be interesting to see how Mozilla picks up the pace in 2024. As well as Teixeira's comments regarding advertising, Baker notes: "We need to be faster in prototyping, launching, learning, and iterating ... This requires rich data, and so we will be moving in that direction, but in a very Mozilla way."</p>
<p>Surely not slurping telemetry?</p>

        

<p>According to the report, the "Mozilla way" is all about privacy, encryption, and keeping customer data safe. Hopefully, it will also be about <a target="_blank" href="https://www.theregister.com/2023/09/29/mozilla_asleep_at_wheel/">innovation</a> rather than scattering AI fairy dust over its product line. ®</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Can a pill prevent deaths from venomous snakebites? (103 pts)]]></title>
            <link>https://www.latimes.com/environment/story/2023-12-24/can-a-pill-prevent-deaths-from-venomous-snake-bites</link>
            <guid>38848566</guid>
            <pubDate>Tue, 02 Jan 2024 23:26:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.latimes.com/environment/story/2023-12-24/can-a-pill-prevent-deaths-from-venomous-snake-bites">https://www.latimes.com/environment/story/2023-12-24/can-a-pill-prevent-deaths-from-venomous-snake-bites</a>, See on <a href="https://news.ycombinator.com/item?id=38848566">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-element="story-body" data-dateline="" data-subscriber-content="">  <p><span>SAN FRANCISCO&nbsp;—&nbsp;</span></p><p>John Heenan knows the terror of feeling a sting on his foot, then looking down and seeing two bright red puncture wounds about an inch apart and a massive rattlesnake slithering away into tall grass.</p><p>It was a summer morning in 2017, and the 74-year-old horticulturist was carrying a box of fruit in a Marin County orchard when, he said, “I stepped right on him, then called out to a partner, ‘Hey, I’ve been bitten by a rattlesnake.’”</p><p>It’s a snapshot imprinted in Heenan’s brain. “The fangs struck a vein, and I could feel the venom moving throughout my system,” he recalled, wincing at the memory. “I started seizing up, and struggled to breathe as though I had the wind knocked out of me.”</p><div data-click="enhancement" data-module-id="0000018a-d215-de7e-a3ce-d715a9510002" data-align-center="">  <div>   <a href="https://www.latimes.com/environment"><picture>     <img alt="Climate California" width="510" height="161" src="https://ca-times.brightspotcdn.com/90/bb/022ad6e14f6487f2d58336619061/climatecasvg-padding.svg" decoding="async" loading="lazy">  </picture></a>   </div>     <p>Aggressive and impactful reporting on climate change, the environment, health and science.</p>      </div><p>Heenan was rushed to a hospital, where he spent the next four days in a coma. During that time, he was administered 28 vials of antivenom intravenously at a cost of $3,400 per vial. </p><p>When he regained consciousness, there were two people at his bedside, his wife and expedition doctor Matthew Lewin, who smiled and said, “You are one lucky guy.”</p><div data-click="enhancement" data-align-center=""><figure> <picture>    <source type="image/webp" srcset="https://ca-times.brightspotcdn.com/dims4/default/e8c461e/2147483647/strip/true/crop/3024x4032+0+0/resize/320x427!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fb7%2F47%2F00e8d1fb442fb6218f89a35b8c4a%2Fla-me-snake-bite-medicine08.JPG 320w,https://ca-times.brightspotcdn.com/dims4/default/29a3da5/2147483647/strip/true/crop/3024x4032+0+0/resize/568x757!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fb7%2F47%2F00e8d1fb442fb6218f89a35b8c4a%2Fla-me-snake-bite-medicine08.JPG 568w,https://ca-times.brightspotcdn.com/dims4/default/9c1dae4/2147483647/strip/true/crop/3024x4032+0+0/resize/768x1024!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fb7%2F47%2F00e8d1fb442fb6218f89a35b8c4a%2Fla-me-snake-bite-medicine08.JPG 768w,https://ca-times.brightspotcdn.com/dims4/default/e6d3011/2147483647/strip/true/crop/3024x4032+0+0/resize/1080x1440!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fb7%2F47%2F00e8d1fb442fb6218f89a35b8c4a%2Fla-me-snake-bite-medicine08.JPG 1080w,https://ca-times.brightspotcdn.com/dims4/default/af29672/2147483647/strip/true/crop/3024x4032+0+0/resize/1240x1654!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fb7%2F47%2F00e8d1fb442fb6218f89a35b8c4a%2Fla-me-snake-bite-medicine08.JPG 1240w,https://ca-times.brightspotcdn.com/dims4/default/15f99cd/2147483647/strip/true/crop/3024x4032+0+0/resize/1440x1920!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fb7%2F47%2F00e8d1fb442fb6218f89a35b8c4a%2Fla-me-snake-bite-medicine08.JPG 1440w,https://ca-times.brightspotcdn.com/dims4/default/48856ec/2147483647/strip/true/crop/3024x4032+0+0/resize/2160x2880!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fb7%2F47%2F00e8d1fb442fb6218f89a35b8c4a%2Fla-me-snake-bite-medicine08.JPG 2160w" sizes="100vw">     <img alt="A man gestures to another man while the pair stand in an orchard." srcset="https://ca-times.brightspotcdn.com/dims4/default/4492a05/2147483647/strip/true/crop/3024x4032+0+0/resize/320x427!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fb7%2F47%2F00e8d1fb442fb6218f89a35b8c4a%2Fla-me-snake-bite-medicine08.JPG 320w,https://ca-times.brightspotcdn.com/dims4/default/0b9f240/2147483647/strip/true/crop/3024x4032+0+0/resize/568x757!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fb7%2F47%2F00e8d1fb442fb6218f89a35b8c4a%2Fla-me-snake-bite-medicine08.JPG 568w,https://ca-times.brightspotcdn.com/dims4/default/ce6720c/2147483647/strip/true/crop/3024x4032+0+0/resize/768x1024!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fb7%2F47%2F00e8d1fb442fb6218f89a35b8c4a%2Fla-me-snake-bite-medicine08.JPG 768w,https://ca-times.brightspotcdn.com/dims4/default/09f6140/2147483647/strip/true/crop/3024x4032+0+0/resize/1080x1440!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fb7%2F47%2F00e8d1fb442fb6218f89a35b8c4a%2Fla-me-snake-bite-medicine08.JPG 1080w,https://ca-times.brightspotcdn.com/dims4/default/e8217fd/2147483647/strip/true/crop/3024x4032+0+0/resize/1240x1654!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fb7%2F47%2F00e8d1fb442fb6218f89a35b8c4a%2Fla-me-snake-bite-medicine08.JPG 1240w,https://ca-times.brightspotcdn.com/dims4/default/262ceea/2147483647/strip/true/crop/3024x4032+0+0/resize/1440x1920!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fb7%2F47%2F00e8d1fb442fb6218f89a35b8c4a%2Fla-me-snake-bite-medicine08.JPG 1440w,https://ca-times.brightspotcdn.com/dims4/default/8705d55/2147483647/strip/true/crop/3024x4032+0+0/resize/2160x2880!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fb7%2F47%2F00e8d1fb442fb6218f89a35b8c4a%2Fla-me-snake-bite-medicine08.JPG 2160w" sizes="100vw" width="2000" height="2667" src="https://ca-times.brightspotcdn.com/dims4/default/cd36856/2147483647/strip/true/crop/3024x4032+0+0/resize/2000x2667!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fb7%2F47%2F00e8d1fb442fb6218f89a35b8c4a%2Fla-me-snake-bite-medicine08.JPG" decoding="async" loading="lazy">  </picture>  <div>   <p>Matthew Lewin, left, and John  Heenan  stand in the  orchard  where Heenan  was bitten by a 5 1/2-foot-long Pacific rattlesnake. The horticulturist at Indian Valley Campus of the College of Marin went into a coma for four days.</p>   <p>(Louis Sahagun / Los Angeles Times)</p>   </div>  </figure></div><p>Heenan would later learn that Lewin was hot on the trail of a novel treatment for the long, agonizing and often deadly effects of venomous snakebites: It’s a pill that he says “is intended to at least buy victims enough time to get to the hospital.”</p><p>Snake venom is a complex cocktail of toxins, amino acids and proteins that evolved primarily to immobilize and kill prey, but it also  prepares tissues for digestion. In humans, venom causes severe swelling and instability of blood pressure, neuromuscular weakness and paralysis, hemorrhaging, and the death of skeletal muscle, leading to permanent tissue loss and amputations.</p><p>The World Health Organization estimates that 138,000 people are killed by venomous snakes annually, and most of them die before they can reach emergency medical care. This suffering goes on with little outrage or publicity because snakebites most often occur in impoverished, backwater areas, and there is no easy way to treat snakebite in the field.</p><p> Nature has provided an abundance of slithering assailants to watch out for: rattlesnakes, copperheads, water moccasins and coral snakes in the United States; kraits in Southeast Asia; taipans in Australia; Nikolsky’s vipers in Ukraine; Gaboon vipers with 2-inch-long fangs in Africa; and bushmasters in Central America. Then there are Russel’s vipers, big, irritable snakes responsible for 25,000 fatalities in India annually.</p><p>Typical standard-of-care antivenoms are extremely expensive, require refrigeration and must be administered intravenously in a hospital setting. They are also species-specific, meaning selecting proper antivenom requires knowing which type of snake bit you. </p><p>As a result, survivors of rattlesnake bites in Southern California, for instance, get a second painful surprise when presented with hospital bills totaling hundreds of thousands of dollars.</p><div data-click="enhancement" data-align-right=""><figure> <picture>    <source type="image/webp" srcset="https://ca-times.brightspotcdn.com/dims4/default/3a4ebe2/2147483647/strip/true/crop/4000x2667+0+0/resize/320x213!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F34%2F67%2F858a1b5646548dc5f463ea4f1f88%2Fla-me-snake-bite-medicine05.JPG 320w,https://ca-times.brightspotcdn.com/dims4/default/d705c01/2147483647/strip/true/crop/4000x2667+0+0/resize/568x379!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F34%2F67%2F858a1b5646548dc5f463ea4f1f88%2Fla-me-snake-bite-medicine05.JPG 568w,https://ca-times.brightspotcdn.com/dims4/default/231b72f/2147483647/strip/true/crop/4000x2667+0+0/resize/768x512!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F34%2F67%2F858a1b5646548dc5f463ea4f1f88%2Fla-me-snake-bite-medicine05.JPG 768w,https://ca-times.brightspotcdn.com/dims4/default/89b71b6/2147483647/strip/true/crop/4000x2667+0+0/resize/1080x720!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F34%2F67%2F858a1b5646548dc5f463ea4f1f88%2Fla-me-snake-bite-medicine05.JPG 1080w,https://ca-times.brightspotcdn.com/dims4/default/a547d6c/2147483647/strip/true/crop/4000x2667+0+0/resize/1240x827!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F34%2F67%2F858a1b5646548dc5f463ea4f1f88%2Fla-me-snake-bite-medicine05.JPG 1240w,https://ca-times.brightspotcdn.com/dims4/default/0ae28c2/2147483647/strip/true/crop/4000x2667+0+0/resize/1440x960!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F34%2F67%2F858a1b5646548dc5f463ea4f1f88%2Fla-me-snake-bite-medicine05.JPG 1440w,https://ca-times.brightspotcdn.com/dims4/default/6e71803/2147483647/strip/true/crop/4000x2667+0+0/resize/2160x1441!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F34%2F67%2F858a1b5646548dc5f463ea4f1f88%2Fla-me-snake-bite-medicine05.JPG 2160w" sizes="100vw">     <img alt="A specimen from the Herpetology Collection at the California Academy of Sciences in San Francisco." srcset="https://ca-times.brightspotcdn.com/dims4/default/ab2c21d/2147483647/strip/true/crop/4000x2667+0+0/resize/320x213!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F34%2F67%2F858a1b5646548dc5f463ea4f1f88%2Fla-me-snake-bite-medicine05.JPG 320w,https://ca-times.brightspotcdn.com/dims4/default/7e64135/2147483647/strip/true/crop/4000x2667+0+0/resize/568x379!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F34%2F67%2F858a1b5646548dc5f463ea4f1f88%2Fla-me-snake-bite-medicine05.JPG 568w,https://ca-times.brightspotcdn.com/dims4/default/35f4efb/2147483647/strip/true/crop/4000x2667+0+0/resize/768x512!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F34%2F67%2F858a1b5646548dc5f463ea4f1f88%2Fla-me-snake-bite-medicine05.JPG 768w,https://ca-times.brightspotcdn.com/dims4/default/5f1bebd/2147483647/strip/true/crop/4000x2667+0+0/resize/1080x720!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F34%2F67%2F858a1b5646548dc5f463ea4f1f88%2Fla-me-snake-bite-medicine05.JPG 1080w,https://ca-times.brightspotcdn.com/dims4/default/7b1c14e/2147483647/strip/true/crop/4000x2667+0+0/resize/1240x827!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F34%2F67%2F858a1b5646548dc5f463ea4f1f88%2Fla-me-snake-bite-medicine05.JPG 1240w,https://ca-times.brightspotcdn.com/dims4/default/54145e4/2147483647/strip/true/crop/4000x2667+0+0/resize/1440x960!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F34%2F67%2F858a1b5646548dc5f463ea4f1f88%2Fla-me-snake-bite-medicine05.JPG 1440w,https://ca-times.brightspotcdn.com/dims4/default/314f69d/2147483647/strip/true/crop/4000x2667+0+0/resize/2160x1441!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F34%2F67%2F858a1b5646548dc5f463ea4f1f88%2Fla-me-snake-bite-medicine05.JPG 2160w" sizes="100vw" width="2000" height="1334" src="https://ca-times.brightspotcdn.com/dims4/default/0a07670/2147483647/strip/true/crop/4000x2667+0+0/resize/2000x1334!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F34%2F67%2F858a1b5646548dc5f463ea4f1f88%2Fla-me-snake-bite-medicine05.JPG" decoding="async" loading="lazy">  </picture>  <div>      <p>(Gayle Laird / California Academy of Sciences)</p>   </div>  </figure></div><p>Lewin has been working for a decade to develop an easy-to-use, needle-free solution to all those problems with a drug called Varespladib.</p><p>What makes Varespladib promising is that it blocks phospholipase-A2, a highly toxic protein that is present in 95% of all snake venoms and plays a direct role in life-threatening tissue destruction, catastrophic bleeding, paralysis and respiratory failure. Proponents say the small synthetic molecule has the potential to stop or reverse neurological damage, as well as restore normal blood-clotting ability when administered immediately after envenoming.</p><p>Drug trials are  being conducted by  Ophirex Inc. — a public benefit corporation that Lewin founded with musician and entrepreneur Jerry Harrison in Corte Madera, Calif.</p><p>The U.S. Food and Drug Administration a year ago granted Varespladib a “fast track” designation to expedite development and review of its safety and effectiveness, as well as Ophirex’s proposals for manufacturing and distributing the drug. </p><p>The Department of Defense has also invested about $24 million into the effort, saying the drug could provide an important capability to teams of special forces deployed in austere conditions where snakebites are a significant threat to life and limb.</p><p> “Ophirex may help us widen the window of time needed for evacuation in the event of a snakebite,” said Lindsey Garver, deputy manager for the Army Medical Materiel Agency’s Warfighter Protection and Acute Care Project. “There is also a psychological benefit to having something in your pocket that is life-saving.”</p><div data-click="enhancement" data-align-right=""><figure> <picture>    <source type="image/webp" srcset="https://ca-times.brightspotcdn.com/dims4/default/a65d63c/2147483647/strip/true/crop/2667x4000+0+0/resize/320x480!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F2e%2Fc5%2Fd5e7c8724a548707e7fba0e143d8%2Fla-me-snake-bite-medicine01.JPG 320w,https://ca-times.brightspotcdn.com/dims4/default/31511b0/2147483647/strip/true/crop/2667x4000+0+0/resize/568x852!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F2e%2Fc5%2Fd5e7c8724a548707e7fba0e143d8%2Fla-me-snake-bite-medicine01.JPG 568w,https://ca-times.brightspotcdn.com/dims4/default/016d0cd/2147483647/strip/true/crop/2667x4000+0+0/resize/768x1152!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F2e%2Fc5%2Fd5e7c8724a548707e7fba0e143d8%2Fla-me-snake-bite-medicine01.JPG 768w,https://ca-times.brightspotcdn.com/dims4/default/8a18abf/2147483647/strip/true/crop/2667x4000+0+0/resize/1080x1620!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F2e%2Fc5%2Fd5e7c8724a548707e7fba0e143d8%2Fla-me-snake-bite-medicine01.JPG 1080w,https://ca-times.brightspotcdn.com/dims4/default/d6ac5e9/2147483647/strip/true/crop/2667x4000+0+0/resize/1240x1860!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F2e%2Fc5%2Fd5e7c8724a548707e7fba0e143d8%2Fla-me-snake-bite-medicine01.JPG 1240w,https://ca-times.brightspotcdn.com/dims4/default/a076bd7/2147483647/strip/true/crop/2667x4000+0+0/resize/1440x2160!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F2e%2Fc5%2Fd5e7c8724a548707e7fba0e143d8%2Fla-me-snake-bite-medicine01.JPG 1440w,https://ca-times.brightspotcdn.com/dims4/default/75fb52b/2147483647/strip/true/crop/2667x4000+0+0/resize/2160x3240!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F2e%2Fc5%2Fd5e7c8724a548707e7fba0e143d8%2Fla-me-snake-bite-medicine01.JPG 2160w" sizes="100vw">     <img alt="Bottles of antivenom." srcset="https://ca-times.brightspotcdn.com/dims4/default/26488fa/2147483647/strip/true/crop/2667x4000+0+0/resize/320x480!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F2e%2Fc5%2Fd5e7c8724a548707e7fba0e143d8%2Fla-me-snake-bite-medicine01.JPG 320w,https://ca-times.brightspotcdn.com/dims4/default/1f028b7/2147483647/strip/true/crop/2667x4000+0+0/resize/568x852!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F2e%2Fc5%2Fd5e7c8724a548707e7fba0e143d8%2Fla-me-snake-bite-medicine01.JPG 568w,https://ca-times.brightspotcdn.com/dims4/default/f51fbe8/2147483647/strip/true/crop/2667x4000+0+0/resize/768x1152!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F2e%2Fc5%2Fd5e7c8724a548707e7fba0e143d8%2Fla-me-snake-bite-medicine01.JPG 768w,https://ca-times.brightspotcdn.com/dims4/default/fd6fa30/2147483647/strip/true/crop/2667x4000+0+0/resize/1080x1620!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F2e%2Fc5%2Fd5e7c8724a548707e7fba0e143d8%2Fla-me-snake-bite-medicine01.JPG 1080w,https://ca-times.brightspotcdn.com/dims4/default/b41b0c7/2147483647/strip/true/crop/2667x4000+0+0/resize/1240x1860!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F2e%2Fc5%2Fd5e7c8724a548707e7fba0e143d8%2Fla-me-snake-bite-medicine01.JPG 1240w,https://ca-times.brightspotcdn.com/dims4/default/61ba39b/2147483647/strip/true/crop/2667x4000+0+0/resize/1440x2160!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F2e%2Fc5%2Fd5e7c8724a548707e7fba0e143d8%2Fla-me-snake-bite-medicine01.JPG 1440w,https://ca-times.brightspotcdn.com/dims4/default/80f5a8b/2147483647/strip/true/crop/2667x4000+0+0/resize/2160x3240!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F2e%2Fc5%2Fd5e7c8724a548707e7fba0e143d8%2Fla-me-snake-bite-medicine01.JPG 2160w" sizes="100vw" width="2000" height="3000" src="https://ca-times.brightspotcdn.com/dims4/default/3d12775/2147483647/strip/true/crop/2667x4000+0+0/resize/2000x3000!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F2e%2Fc5%2Fd5e7c8724a548707e7fba0e143d8%2Fla-me-snake-bite-medicine01.JPG" decoding="async" loading="lazy">  </picture>  <div>   <p>Bottles of anti-venom at the California Academy of Sciences in San Francisco.</p>   <p>(Gayle Laird / California Academy of Sciences)</p>   </div>  </figure></div><p>But getting any new drug from the laboratory to the market is an expensive, intricate process that can sometimes take just months to show promise but years to perfect.</p><p>The company is completing a Phase  II clinical trial in the United States and India to determine the tolerability and potential side effects of multi-dose regimens of the drug in about 100 suspected or confirmed snakebite victims. Among them is a man who a month ago was bitten by a sidewinder rattlesnake near the desert resort city of Palm Springs.</p><p>A federal analysis of the results is expected sometime next year and will ultimately determine whether Ophirex has a blockbuster snakebite drug treatment with military and global market opportunities.</p><p>“I certainly underestimated the astonishing complexity of an undertaking such as this one,” said Lewin, 55, expedition physician for the California Academy of Sciences in San Francisco. “It’s humbling.”</p><p>The company has assembled an impressive board of directors: Derrick Rossi, a stem cell scientist and co-founder of Moderna; Curt LaBelle, chair of Global Health Funds; Tim Garnett, former chief medical officer for Eli Lilly and Co.; and Hans Bishop, co-founder of Altos Labs Inc., a biotechnology research company.</p><p>“Our company is trying to produce a drug for a neglected global crisis,” Rossi said. “The vast majority of people who are being killed or maimed by snake bites are village farmers and children working out in the fields without shoes.”</p><p>Varespladib was originally discovered and developed by Eli Lilly and Co. to suppress inflammation. The company abandoned that effort, however, after clinical studies failed to produce the desired results.</p><p>Since then, patents on the drug’s molecule have expired, providing  Ophirex with “an opportunity for us to establish an appropriate patent portfolio,” said Nancy Koch, chief executive  of  Ophirex.</p><p>The proposed pill’s price tag remains unclear. “We haven’t made any estimates of pricing yet,” Koch said. “But we want to make the drug accessible around the world, and to make that possible we are studying ways to reduce manufacturing costs.”</p><div data-click="enhancement" data-align-center=""><figure> <picture>    <source type="image/webp" srcset="https://ca-times.brightspotcdn.com/dims4/default/b3f670e/2147483647/strip/true/crop/4000x2667+0+0/resize/320x213!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F98%2Fdf%2Fbefd9fbd40acbb63631a19383587%2Fla-me-snake-bite-medicine06.JPG 320w,https://ca-times.brightspotcdn.com/dims4/default/9f7175c/2147483647/strip/true/crop/4000x2667+0+0/resize/568x379!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F98%2Fdf%2Fbefd9fbd40acbb63631a19383587%2Fla-me-snake-bite-medicine06.JPG 568w,https://ca-times.brightspotcdn.com/dims4/default/c07c29c/2147483647/strip/true/crop/4000x2667+0+0/resize/768x512!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F98%2Fdf%2Fbefd9fbd40acbb63631a19383587%2Fla-me-snake-bite-medicine06.JPG 768w,https://ca-times.brightspotcdn.com/dims4/default/9e89061/2147483647/strip/true/crop/4000x2667+0+0/resize/1080x720!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F98%2Fdf%2Fbefd9fbd40acbb63631a19383587%2Fla-me-snake-bite-medicine06.JPG 1080w,https://ca-times.brightspotcdn.com/dims4/default/c8a8cdf/2147483647/strip/true/crop/4000x2667+0+0/resize/1240x827!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F98%2Fdf%2Fbefd9fbd40acbb63631a19383587%2Fla-me-snake-bite-medicine06.JPG 1240w,https://ca-times.brightspotcdn.com/dims4/default/dcfe6a9/2147483647/strip/true/crop/4000x2667+0+0/resize/1440x960!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F98%2Fdf%2Fbefd9fbd40acbb63631a19383587%2Fla-me-snake-bite-medicine06.JPG 1440w,https://ca-times.brightspotcdn.com/dims4/default/62bbaff/2147483647/strip/true/crop/4000x2667+0+0/resize/2160x1441!/format/webp/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F98%2Fdf%2Fbefd9fbd40acbb63631a19383587%2Fla-me-snake-bite-medicine06.JPG 2160w" sizes="100vw">     <img alt="A view of the Herpetology Collection at the California Academy of Sciences in San Francisco." srcset="https://ca-times.brightspotcdn.com/dims4/default/f945d43/2147483647/strip/true/crop/4000x2667+0+0/resize/320x213!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F98%2Fdf%2Fbefd9fbd40acbb63631a19383587%2Fla-me-snake-bite-medicine06.JPG 320w,https://ca-times.brightspotcdn.com/dims4/default/1cba055/2147483647/strip/true/crop/4000x2667+0+0/resize/568x379!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F98%2Fdf%2Fbefd9fbd40acbb63631a19383587%2Fla-me-snake-bite-medicine06.JPG 568w,https://ca-times.brightspotcdn.com/dims4/default/45310f4/2147483647/strip/true/crop/4000x2667+0+0/resize/768x512!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F98%2Fdf%2Fbefd9fbd40acbb63631a19383587%2Fla-me-snake-bite-medicine06.JPG 768w,https://ca-times.brightspotcdn.com/dims4/default/26fa750/2147483647/strip/true/crop/4000x2667+0+0/resize/1080x720!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F98%2Fdf%2Fbefd9fbd40acbb63631a19383587%2Fla-me-snake-bite-medicine06.JPG 1080w,https://ca-times.brightspotcdn.com/dims4/default/80a8813/2147483647/strip/true/crop/4000x2667+0+0/resize/1240x827!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F98%2Fdf%2Fbefd9fbd40acbb63631a19383587%2Fla-me-snake-bite-medicine06.JPG 1240w,https://ca-times.brightspotcdn.com/dims4/default/a8b9216/2147483647/strip/true/crop/4000x2667+0+0/resize/1440x960!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F98%2Fdf%2Fbefd9fbd40acbb63631a19383587%2Fla-me-snake-bite-medicine06.JPG 1440w,https://ca-times.brightspotcdn.com/dims4/default/84e03f6/2147483647/strip/true/crop/4000x2667+0+0/resize/2160x1441!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F98%2Fdf%2Fbefd9fbd40acbb63631a19383587%2Fla-me-snake-bite-medicine06.JPG 2160w" sizes="100vw" width="2000" height="1334" src="https://ca-times.brightspotcdn.com/dims4/default/71e93d1/2147483647/strip/true/crop/4000x2667+0+0/resize/2000x1334!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F98%2Fdf%2Fbefd9fbd40acbb63631a19383587%2Fla-me-snake-bite-medicine06.JPG" decoding="async" loading="lazy">  </picture>  <div>      <p>(Gayle Laird / California Academy of Sciences)</p>   </div>  </figure></div><p>To hear Lewin tell it,  Ophirex emerged from a tragic event. In 2001, Joseph Slowinski, a herpetologist at the California Academy of Sciences in San Francisco, died 30 hours after he was bitten by a small venomous snake in the mountainous jungles of northern Myanmar.</p><p>No antivenom was available at the remote site, a five-day hike from the nearest town. Heroic efforts to save him were unsuccessful.</p><p>A decade later, after a trip to the same region, Lewin, director of the academy’s Center for Exploration and Travel Health, began to ponder the possibility of a needle-free treatment that could be administered in the field immediately after being bitten.</p><p>Lewin initially set his sights on proving that the potentially fatal paralytic effects of certain toxic substances could be reversed with an antiparalytic drug administered via a nasal spray.</p><p>With that goal in mind, Lewin self-volunteered to become a test subject.</p><p>In a 2013 experiment conducted with a team of anesthesiologists in a research laboratory at UC San Francisco, Lewin allowed himself to be paralyzed with derivative of curare, a chemical typically administered intravenously as a paralyzing agent for surgical procedures.</p><p>Moments later, he said, “I couldn’t talk, felt dizzy and had trouble breathing.”</p><p>The team then administered the nasal spray, and within 20 minutes Lewin had recovered. The results of the experiment were published online in the medical journal Clinical Case Reports.</p><p>“It was terrifying, and I’d never do that again,” Lewin said. “But the experiment proved that paralysis could be reversed without intravenous medication.”</p><p>The arc of Lewin’s career has led him from emergency rooms to wilderness medicine as a doctor on scientific expeditions sponsored by the American Museum of Natural History, the Kellogg Foundation and National Geographic.</p><p>Not all of his research occurs in remote corners of the world, however. Studying the factors that influence snakebite severity means working with scientists such as William Hayes, a professor at Loma Linda University School of Medicine in Loma Linda, Calif., who keeps an assortment of snake venom available for testing in a laboratory refrigerator.</p><p>It also means studying the physical and financial struggles of survivors like John Heenan, whose hospital bills soared to more than $350,000 after he was bitten at the Indian Valley Campus of the College of Marin.</p><p>“Medicare eventually covered my medical costs, but I had to pay about 300 bucks for the ambulance service,” Heenan said, shaking his head. </p><p>The college, for its part, later planted a large digital welcome sign at its entrance that states: “CAUTION: Entering Rattlesnake Country. Be alert when walking.”</p> <p>Heenan wouldn’t argue with any of that. But he also has high hopes for Lewin’s vision.</p><p>“Everybody should carry a few of those pills in their first aid kits and lunch boxes,” he said. “Of course, they should also watch where they step.”</p> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Thoughts on PostgreSQL in 2024 (105 pts)]]></title>
            <link>https://jkatz05.com/post/postgres/postgresql-2024/</link>
            <guid>38848001</guid>
            <pubDate>Tue, 02 Jan 2024 22:34:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jkatz05.com/post/postgres/postgresql-2024/">https://jkatz05.com/post/postgres/postgresql-2024/</a>, See on <a href="https://news.ycombinator.com/item?id=38848001">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p><em></em>
<span>Tue, Jan 2, 2024
</span><em></em>
<span>18-minute read</span></p></div><p>A question I often hear, and also ask myself, is “where is PostgreSQL going?” This is a deep question: it’s not limited to the work on the core database engine, but rather everything going on in the community, including related open source projects and event and community development. Even with the popularity of PostgreSQL, which was selected as <a href="https://db-engines.com/en/blog_post/106">DB Engine’s “DBMS of the Year” for the fourth time</a>, it’s a good idea to step back at times and reflect on what PostgreSQL will look like in the future. While it may not necessarily lead to immediate changes, it does help give context to all the work going on in the community.</p><p>The new year is a great opportunity to ask “where is PostgreSQL going?” and is a question I’ve been personally reflecting on. So here are some of my thoughts on where PostgreSQL is going as we enter into 2024. This is not meant to be a roadmap, but rather personal thoughts on where PostgreSQL is going.</p><h2 id="postgresql-feature-development">PostgreSQL feature development</h2><p>At the <a href="https://wiki.postgresql.org/wiki/PgCon_2023_Developer_Meeting">PGCon 2023 Developer Meeting</a>, I proposed a topic entitled <a href="https://wiki.postgresql.org/wiki/PgCon_2023_Developer_Meeting#What_are_the_big_challenges_for_our_users.3F_What_are_the_big_challenges_for_us_to_solve.3F">“What are the big challenges for PostgreSQL users?”</a>. The goal of this was to talk about both common user requests and understand where database workloads were heading to determine if we are building PostgreSQL towards where database workloads are going. Based on many conversation and observations, I proposed three broad feature buckets to look at:</p><ul><li><strong>Availability</strong></li><li><strong>Performance</strong></li><li><strong>Developer features</strong></li></ul><p>These are all ongoing areas of work for 2024 and beyond, but there are definitely steps PostgreSQL can take in the coming year to make improvements in all of these areas. Below I dive into more details about each of these feature groups.</p><h3 id="availability">Availability</h3><p>Continuing to improve the availability of a PostgreSQL cluster is the first, second, and third most requested “feature” I hear about from both current and prospective PostgreSQL users. I’m not exaggerating either: while restarting PostgreSQL can be nearly instantaneous, there are use cases where that can be too much time (though those are at the extreme). Additionally, operations with locks that block writes for prolonged periods of time can be considered as “downtime.”</p><p>While most PostgreSQL users can currently achieve their uptime requirements, there is a class of workloads with critical uptime requirements that we can better support in PostgreSQL with additional development effort. Most of this section (and blog post) focuses on one feature area where continued improvements will allow PostgreSQL to be deployed in even more environments that have these requirements.</p><h4 id="how-logical-replication-can-help-with-active-active-bluegreen-zero-downtime-upgrading-and-other-workflows">How logical replication can help with active-active, blue/green, zero-downtime upgrading, and other workflows</h4><p>For existing PostgreSQL users and users looking to migrate to PostgreSQL, features around availability are the biggest ask. Typically, this centers around <a href="https://en.wikipedia.org/wiki/High_availability">high availability</a>, or the ability to continue to have access to the database (especially read/write access) during a planned (update) or unplanned (outage) disruption. PostgreSQL provides many features to support high availability, including streaming replication. However, maximizing HA still requires the use of an additional service or a utility like <a href="https://github.com/zalando/patroni">Patroni</a> to achieve many uptime goals.</p><p>Many users I talk to are happy with the availability they can get with PostgreSQL: it works for most of their use cases. However, I’ve been seeing an emerging trend of workloads on PostgreSQL that need even higher availability, where a 15-30s offline window isn’t good enough. This is both for planned outages (e.g. minor version upgrades, major version upgrades) and unplanned outages. I’ve even talked to users who have workloads that can only be unavailable for 1s – and while I was initially skeptical, when I heard what the workloads were for, I did agree that 1s was a reasonable requirement for them!</p><p>A key feature for PostgreSQL that will continue to improve availability is <a href="https://www.postgresql.org/docs/current/logical-replication.html">logical replication</a>. Logical replication allows the real-time streaming of changes from a database into any system that can understand the PostgreSQL logical replication protocol. Logical replication in PostgreSQL <a href="https://jkatz05.com/post/postgres/postgres-10-tribute/">has been around for awhile</a>, but <a href="https://www.postgresql.org/about/news/postgresql-16-released-2715/">recent releases</a> have added significant enhancements that can better support availability use-cases, including functionality and performance features.</p><p>One advantage this has over physical (or binary) replication is that you can use logical replication to stream changes from a PostgreSQL 15 to a PostgreSQL 16 system as part of a major version upgrade. This can help reduce the amount of downtime it takes to perform a major version upgrade (here is an example of how <a href="https://www.instacart.com/company/how-its-made/zero-downtime-postgresql-cutovers/">Instacart used logical replication to get to zero-downtime on major version upgrades</a>), but there is still work to be done in PostgreSQL to improve this use case and other high availability use cases. Additional features will help unlock more seamless ways of supporting <a href="https://en.wikipedia.org/wiki/Blue%E2%80%93green_deployment">blue-green deployments</a> in PostgreSQL.</p><p>Logical replication can also be used as part of the high availability mechanism itself. One technique, “active-active replication,” allows multiple databases can simultaneously accept writes and replicate the changes amongst themselves. This technique is typically used in systems that have that “no more than 1s of unavailability” requirement: if a writer database is unavailable, then an application can switch its database traffic to a different writer database without waiting for it to be promoted. While this sounds ideal, building and managing an active-active system is extremely complicated: it impacts application design, requires you to have a write-conflict management and resolution strategy, and requires careful fault tolerance monitoring to help ensure data integrity (e.g. a “conflict storm”) and replication health (e.g. what happens if an instance can’t replicate changes for several hours?).</p><p>However, both the major version upgrade and active-active cases do present a roadmap for how we can continue to improve logical replication in PostgreSQL. <a href="https://amitkapila16.blogspot.com/">Amit Kapila</a>, who has led many of the logical replication feature efforts, and I developed a talk this year called <a href="https://www.postgresql.eu/events/pgconfeu2023/sessions/session/4783/slides/434/pgconfeu2023_active_active.pdf">The journey towards active-active replication in PostgreSQL</a> (<a href="https://www.youtube.com/watch?v=jPp4XIY4XRw">video of us co-presening one version</a>) that talks about why solving for these use cases are important, the current state-of-the-art of PostgreSQL logical replication, and what work we need to do to get PostgreSQL to better support these cases. The good news: as of PostgreSQL 16, we have most of the foundational blocks for supporting active-active, blue-green deployments, and zero downtime major version upgrades – and even if they are not in core, there are PostgreSQL extensions that can provide this functionality (disclosure: I’ve been involved with one such extension, <a href="https://aws.amazon.com/blogs/database/using-pgactive-active-active-replication-extension-for-postgresql-on-amazon-rds-for-postgresql/"><code>pgactive</code></a>).</p><p>There are multiple efforts in 2024 to help close these feature gaps. Targeted for PostgreSQL 17 (usual disclaimer that these may not be included), there has been a focus on ensuring logical replication can work with key workflows, such as <a href="https://www.postgresql.org/docs/current/pgupgrade.html"><code>pg_upgrade</code></a> and in <a href="https://commitfest.postgresql.org/46/4423/">high availability systems</a>, and working to support replication of additional changes (e.g. <a href="https://commitfest.postgresql.org/46/3823/">sequences</a>). Beyond that, we must continue to support more commands in logical replication (e.g. <a href="https://commitfest.postgresql.org/46/3595/">DDL</a>), continue to improve performance (more parallelism support, worker optimizations), and add features that simplify management of logical replication (node synchronization/resynchronization).</p><p>All of these efforts will make it possible to use PostgreSQL in more workloads that have very high uptime requirements, and simplify how users roll out new changes to their production environments. While there’s still more work to do with enhancing logical replication in PostgreSQL, it looks like 2024 will give us more features that help users run PostgreSQL in critical environments.</p><h4 id="unblocking-the-locks">Unblocking the locks</h4><p>Another area of availability to consider is around schema maintenance operations (i.e. <a href="https://en.wikipedia.org/wiki/Data_definition_language">DDL</a> statements), such an <a href="https://www.postgresql.org/docs/current/sql-altertable.html"><code>ALTER TABLE</code></a> that takes an <a href="https://www.postgresql.org/docs/current/explicit-locking.html#LOCKING-TABLES"><code>ACCESS EXCLUSIVE</code></a> lock on the table that blocks all other write operations on that table. For many users, this is the same thing as being unavailable, even if it’s only to a subset of their data. Lack of full support for nonblocking/online schema maintenance operations in PostgreSQL has become more noticeable as other relational databases include support for this feature.</p><p>There are various utilities and extensions that let you run nonblocking schema updates, but it would be more convenient, and likely performant, to support more nonblocking schema changes natively in PostgreSQL. Based on the design, we may already have the foundation to build out this feature, but it will take some time. While I’m not aware of active implementation efforts, I do think in 2024 we need to make more progress on making it possible for users to run most, if not all, DDL commands without blocking writes, if they so choose.</p><h3 id="performance">Performance</h3><p>Performance is very much a “what have you done for me lately” feature: we can always go faster! The good news is that PostgreSQL has a reputation of vertically scaling, or being able to scale as you provide more hardware resources to a single instance. While there are use cases where horizontally scaling both reads and writes makes sense, we do need to continue to ensure PostgreSQL can continue to scale as compute and memory resources continue to grow.</p><p>Here’s a more “practical” way of putting it: there is an Amazon EC2 instance that has <a href="https://aws.amazon.com/ec2/instance-types/high-memory/">448 vCPU and 24TB of RAM</a> – is PostgreSQL able to fully maximize its use of all of those resources on a single instance? Looking at the current and upcoming hardware that PostgreSQL users will use gives us a measured target for how we can continue to improve PostgreSQL performance.</p><p>As we enter 2024, there are already multiple efforts that will help make it possible to continue to vertically scale PostgreSQL. One of the biggest efforts, and one that’s been an ongoing multi-year project, is to support direct IO (DIO) and asynchronous IO (AIO) in PostgreSQL. For details, I’ll defer to Andres Freund’s <a href="https://www.pgconf.eu/">PGConf.EU</a> slides on the <a href="https://anarazel.de/talks/2023-12-14-pgconf-eu-path-to-aio/path-to-aio.pdf">status of adding AIO to PostgreSQL</a>, but it looks like in 2024 that we’ll be much closer to full AIO support.</p><p>Another effort I’m intrigued by is <a href="https://wiki.postgresql.org/wiki/Parallel_Recovery">parallel recovery</a>. PostgreSQL users with heavy write workloads tend to postpone <a href="https://www.postgresql.org/docs/current/sql-checkpoint.html">checkpoints</a> to defer I/O workload. This can be problematic on a busy system if PostgreSQL crashes and a checkpoint has not occurred for awhile. When PostgreSQL restarts, it enters “crash recovery” where it replays every change since the last checkpoint so it can reach a consistent state. During crash recovery, PostgreSQL cannot accept reads or writes, which means that it’s unavailable. This is problematic for busy stems: while PostgreSQL can accept concurrent writes, it can only replay changes with a single process. If a crash on a busy system occurred an hour after the last checkpoint, it could take several more hours to reach a consistent state while the system is offline!</p><p>One way to help overcome this limitation is to support “<a href="https://wiki.postgresql.org/wiki/Parallel_Recovery">parallel recovery</a>,” or being able to replay changes in parallel. At <a href="https://www.pgcon.org/">PGCon 2023</a>, Koichi Suzuki gave a <a href="https://www.pgcon.org/events/pgcon_2023/sessions/session/392/slides/69/Parallel%20Recovery%20in%20PostgreSQL.pdf">detailed presentation on how PostgreSQL can support parallel recovery</a>. This would apply not only to crash recovery, but how PostgreSQL can replay any WAL changes (e.g. point-in-time-recovery). While this is a very challenging problem to solve, supporting parallel recovery helps PostgreSQL to continue to scale vertically, as users can further optimize for heavy write workloads and mitigate the risk of a crash causing an untenable delay in coming back online.</p><p>This is not an exhaustive list of performance-related features. There are many more efforts around PostgreSQL server performance, including indexing optimizations, locking improvements, leveraging hardware acceleration, and more. This in addition to work on clients, such as drivers and connection poolers, that can bring additional performance gains to how apps interact with PostgreSQL. Looking at what the community is working on in 2024, I do believe we’ll continue to see general performance gains across all areas of PostgreSQL.</p><h3 id="developer-features">Developer features</h3><p>I view “developer features” as a fairly broad category around how users can architect and build their apps around PostgreSQL. This includes SQL syntax, functions, <a href="https://wiki.postgresql.org/wiki/PL_Matrix">procedural language support</a>, and other features that help users both build apps and transition from other database systems. One example of such an innovation is the <a href="https://www.postgresql.org/docs/current/rangetypes.html"><code>multirange</code></a> data type, added in PostgreSQL 14, which let users group non-contiguous ranges together. This had many practical purposes, such as in scheduling, and personally let me <a href="https://www.crunchydata.com/blog/better-range-types-in-postgres-14-turning-100-lines-of-sql-into-3">reduce hundreds of lines of PL/pgSQL code into roughly three lines</a>. Developer features is also a way to keep track of how PostgreSQL can support emergent workloads, such as <a href="https://jkatz05.com/post/postgres/vectors-json-postgresql/">JSON or vectors</a>.</p><p>Currently, a lot of innovation on PostgreSQL developer features is occurring in extensions, which is an advantage of PostgreSQL’s extensible model. In the server itself, there are areas where PostgreSQL is lagging behind its previous pace of releasing developer features. For example, PostgreSQL was the <a href="https://jkatz05.com/post/postgres/vectors-json-postgresql/">first relational database to support JSON as a queryable data type</a>, but has been lagging on implementing syntax and features specified in the SQL/JSON standard. PostgreSQL 16 released several of the SQL/JSON syntax features, and there are multiple efforts targeted for 2024 that will include more of the SQL/JSON specification.</p><p>With that said, we should be investing in adding developer features in PostgreSQL that are not possible to add in extensions, such as SQL standard features. I suggest a focus of features that are already available in other databases, such as more of the SQL/JSON standard (e.g. <code>JSON_TABLE</code>), system versioned tables (useful for auditing and “flashback” / bitemporal queries to view data at a specific point in time), and module support (useful for “packaging” stored procedures).</p><p>Additionally, with the previously mentioned focus on availability and performance, we should continue to simplify how users can migrate from other databases to PostgreSQL. As part of my day job, I had the opportunity to read through a lot of content around migration strategies from commercial databases to PostgreSQL, and there’s still ample opportunity to simplify the process while enhancing PostgreSQL capabilities. This includes features available in other databases (e.g. global temporary tables, global partitioned indexes, <a href="https://www.postgresql.org/message-id/f7470d5a-3cf1-4919-8404-5c4d91341a9f@tantorlabs.com">autonomous transactions</a>) and adding more functionality and performance optimizations in PL/pgSQL (bulk data processing functions, <a href="https://commitfest.postgresql.org/46/1608/">schema variables</a>, <a href="https://commitfest.postgresql.org/46/4684/">caching function metadata</a>). All these things improve the PostgreSQL developer experience while making it easier for users coming from other relational databases to adopt PostgreSQL.</p><p>Finally, we need to see how we can continue to support the emergent workload coming from AI/ML data, specifically vector storage and search. At <a href="https://www.pgcon.org/">PGCon</a> 2023, while folks wanted to see native vector support in PostgreSQL itself, there was consensus that implementing functionality in an extension like <a href="https://github.com/pgvector/pgvector">pgvector</a> would let us support these workloads more quickly (and this <a href="https://jkatz05.com/post/postgres/pgvector-overview-0.5.0/">strategy seems to have worked</a> with <a href="https://aws.amazon.com/blogs/database/accelerate-hnsw-indexing-and-searching-with-pgvector-on-amazon-rds-for-postgresql/">great performance results on vector data</a>). However, <a href="https://www.postgresql.eu/events/pgconfeu2023/sessions/session/4592/slides/435/pgconfeu2023_vectors.pdf">given many of the properties of vector workloads</a>, there are additions we can make to PostgreSQL to further support them, including planner optimizations for working with <a href="https://www.postgresql.org/message-id/ad8a178f-bbe7-d89d-b407-2f0fede93144@postgresql.org">TOAST’d data that’s in the active query path</a>, and exploring how we can better support queries where the bulk filtering step occurs in the <code>ORDER BY</code> clause.</p><p>I do think we can make a lot of progress on all of these areas in 2024 and continue to add features directly to PostgreSQL that make it easier to build applications, even as we see a boon of functionality in extensions around PostgreSQL.</p><h3 id="but-what-about-security">But what about security?</h3><p>I do want to quickly disucss security features. PostgreSQL does have a strong reputation for enabling workloads in security-focused environments, but there is always more to do. The past several years, adding native support for <a href="https://wiki.postgresql.org/wiki/Transparent_Data_Encryption">transparent data encryption</a> (TDE) in PostgreSQL has received a lot of attention, but there are other areas we can continue to innovate. This includes adding support for additional authentication methods or mechanisms (OIDC is amongst the biggest asks) and exploring the possibility of a federation authorization model to allow PostgreSQL to inherit permissions from other systems. And while this is challenging today, I’d suggest we look at how we can support TDE on a per-database level. I’m keeping this discussion short as there are ways to satisfy the requirements that these features would add to PostgreSQL today, but we can certainly continue to build towards full native support.</p><p>And with that, let’s look at other areas where PostgreSQL can make progress in 2024.</p><h2 id="extensions">Extensions</h2><p>PostgreSQL was designed to be extensible: you can add functionality to PostgreSQL without having to fork it. This includes new data types, indexing methods, ways to work with other database systems, utilities that make it easier to manage PostgreSQL features, <a href="https://wiki.postgresql.org/wiki/PL_Matrix">additional programming languages</a>, and even <a href="https://github.com/aws/pg_tle">extensions that let you write your own extensions</a>. People have built open source communities and companies around specific PostgreSQL extensions (e.g. <a href="https://postgis.net/">PostGIS</a>), and PostgreSQL extensions have made it possible to support all kinds of workloads (geospatial, timeseries, analytical, AI) from a single database. With <a href="https://gist.github.com/joelonsql/e5aa27f8cc9bd22b8999b7de8aee9d47">thousands of available PostgreSQL extensions</a>, they truly are a “force multiplier” for PostgreSQL and help drive significant adoption while letting users quickly build functionality for their databases!</p><p>The side-effect of all this is we’re now seeing “extension <a href="https://en.wikipedia.org/wiki/Urban_sprawl">sprawl</a>.” How do I know which extension to use? What is the level of support of an extension? How do I know an extension will continue to be actively maintained? How can I help contribute a feature to an extension? Even “where can I download an extension” has become a big question: while postgresql.org has an <a href="https://www.postgresql.org/download/products/6-postgresql-extensions/">incomplete list of extensions</a> and the <a href="https://www.postgresql.org/download/">community packages</a> maintain a set of extensions, there are now multiple PostgreSQL extension repositories available (<a href="https://pgxn.org/">PGXN</a>, <a href="https://database.dev/">dbdev</a>, and <a href="https://pgt.dev/">Trunk</a>).</p><p>One of the strengths of the PostgreSQL community is that it is widely distributed, but we can make it easier to help guide users through the sprawl make informed choices about how they manage their data. I see 2024 as an opportunity to put more central resources into how we represent PostgreSQL extensions, and help users understand when to use certain extensions and their development maturity level, and likewise help extension builders with both governance and maintenance resources.</p><h2 id="community-building">Community Building</h2><p>I wanted to round out thoughts for 2024 around community building. The PostgreSQL contributor community has significantly grown since I first started, and the community has done a better job of <a href="https://www.postgresql.org/community/contributors/">recognizing contributors</a> to all parts of the project, not just the code base (noting that there is still room for improvement here). But we can continue to do better, and there are three areas I’d like to specifically highlight: mentorship and <a href="https://en.wikipedia.org/wiki/Diversity,_equity,_and_inclusion">DEI</a>, and transparency, which will help in all areas of the project.</p><p>During the <a href="https://wiki.postgresql.org/wiki/PgCon_2023_Developer_Meeting#What_are_the_big_challenges_for_our_users.3F_What_are_the_big_challenges_for_us_to_solve.3F">developer meeting @ PGCon 2023</a>, <a href="https://mastodon.social/@melanieplageman/">Melanie Plageman</a> gave a very detailed analysis of the experience of being a newer contributor to PostgreSQL and the challenges it takes to ramp up. Melanie identified many problems: ramp up time on learning basic of how to contribute to PostgreSQL (getting started on the codebase, communicating on the mailing list), the effort to get a patch to a committable state and having a committer interested in it, guidance that may be given with the best of intentions (get started by reviewing patches!) which actually may be more challenging than writing code, and how feedback, when delivered, is delivered.</p><p>On the last point, how to give feedback, I want to call out an <a href="https://rhaas.blogspot.com/2023/12/praise-criticism-and-dialogue.html">excellent blog post by Robert Haas</a> that specifically addresses the power of giving <a href="https://rhaas.blogspot.com/2023/12/praise-criticism-and-dialogue.html">praise while delivering feedback</a> – these things do make a difference and it’s a good reminder in general that we should be supportive even while we’re being critical.</p><p>Back to Melanie’s points, mentorship is something we can do better across the community. Personally, I admit I have been bad at this in areas around project advocacy, including helping to get more people to contribute to the <a href="https://www.postgresql.org/developer/related-projects/">web infrastructure</a> and the <a href="https://www.postgresql.org/about/press/presskit16/">release process</a>. This doesn’t mean PostgreSQL lacks mentorship – I can count numerous folks in the community as mentors – but we can be better in terms of how we can help people get started with contributing and finding mentors who can guide them on their journey.</p><p>2024 serves as a gateway to building better mentorship processes, and we’re looking to test some of these ideas at <a href="https://2024.pgconf.dev/">PGConf.dev 2024</a> in May 2024 in Vancouver.</p><p>(Some history: Before <a href="https://www.pgconf.dev/">PGConf.dev</a>, <a href="https://www.pgcon.org/">PGCon</a> was the event where PostgreSQL contributors gathered to discuss strategic projects for the upcoming development cycle. PGCon was organized by Dan Langille from 2007 to 2023, and after umpteen years of organizing, he was ready to extend the efforts to a group of folks and helped to establish <a href="https://www.pgconf.dev/">PGConf.dev</a>).</p><p><a href="https://www.pgconf.dev/">PGConf.dev</a> is a conference for folks who want to contribute to PostgreSQL, and covers topics around PostgreSQL development (both core server and all open source projects around PostgreSQL such as extensions and drivers), community building, and open source thought leadership. A big portion of PGConf.dev is dedicated to mentorship, and is planning to include workshops around how to contribute to PostgreSQL. If you’re looking for ways to help contribute to PostgreSQL, I strongly suggest attending or <a href="https://2024.pgconf.dev/cfp/">submitting a talk</a>!</p><p>This leads into how the PostgreSQL community can improve in <a href="https://en.wikipedia.org/wiki/Diversity,_equity,_and_inclusion">DEI</a>. I strongly suggest reading the slides and watching the video (when it’s available) of <a href="https://karenjex.blogspot.com/">Karen Jex</a> and <a href="https://mydbanotebook.org/">Lætitia AVROT</a>’s PGConf.eu 2023 talk <a href="https://www.postgresql.eu/events/pgconfeu2023/schedule/session/4913-trying-to-be-barbie-in-kens-mojo-dojo-casa-house/">Trying to be Barbie in Ken’s Mojo Dojo Casa House</a>, as it’s an insightful presentation on how we can continue to make the PostgreSQL community more inclusive. The community has made progress in this area (and Karen and Lætitia point to initiatives that have helped with this), but we can still be better, and we should actively and proactively work to address feedback to help ensure contributing to PostgreSQL is a welcoming experience. There are actions we can all take, for example, calling out an inappropriate (e.g. sexist) behavior as it happens and providing guidance on why it’s not appropriate.</p><p>Finally, there’s transparency. This might seem odd in open source, given, well, it’s open. But there are quite a few governance issues that are discussed not in the open, and it helps to understand how decisions are made. The <a href="https://www.postgresql.org/about/policies/coc_committee/">PostgreSQL Code of Conduct Committee</a> provides an excellent example of how the community can be transparent about issues that require sensitivity. Each year, the Code of Conduct committee publishes a report (<a href="https://www.postgresql.org/about/policies/coc/reports/2022/">here is the one from 2022</a>) of its work, including high level descriptions of cases and overall statistics. This is a practice we can reproduce across many of the PostgreSQL teams that are involved in tasks that may require privacy due to their sensitivity.</p><h2 id="conclusion-this-was-originally-supposed-to-be-a-shorter-post">Conclusion: This was originally supposed to be a shorter post</h2><p>When I originally started writing this, I thought it’d be a pithy post that I’d finish in a few hours. A few days later…</p><p>In all seriousness, PostgreSQL is in a good place. It remains popular, and its reputation for reliability, robustness, and performance remain sound. But we can still do better, and the good news is that the community is actively working towards improving in every which way</p><p>While these are thoughts for what PostgreSQL can do in 2024 and beyond, there’s so much PostgreSQL already does today. In fact, asking questions like “where is PostgreSQL going” does give us an opportunity to step back and reflect on all the progress PostgreSQL has made over the past several years while looking ahead on what is to come!</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[QEMU AioContext removal and how it was done (113 pts)]]></title>
            <link>http://blog.vmsplice.net/2024/01/qemu-aiocontext-removal-and-how-it-was.html</link>
            <guid>38847732</guid>
            <pubDate>Tue, 02 Jan 2024 22:06:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://blog.vmsplice.net/2024/01/qemu-aiocontext-removal-and-how-it-was.html">http://blog.vmsplice.net/2024/01/qemu-aiocontext-removal-and-how-it-was.html</a>, See on <a href="https://news.ycombinator.com/item?id=38847732">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>This post is about the AioContext lock removal in QEMU 9.0 (planned for release in 2024), how we got here, and what it means for multi-threaded code in QEMU.</p>

<h2>Early QEMU as a single-threaded program</h2>

<p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhaRqkkKqhE7ghlhSAp8xKLgRs-R4JL13E2hNg6FnGlbLWGkl4m34B0sLntGiSdNB70eSySkV0tG5O0oV4XIG6KuM9roPIfKHJ6ANI7xiSH-xLI5N2us7AFDmj0dBMlien019UaDJgQ3FLZdO6K2n27U7hyphenhyphenAmvB6KE0M2kmY1NTarvHPDWWNpzpdNvZAEA/s1600/aiocontext-lock-removal.png"><img alt="" data-original-height="323" data-original-width="178" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhaRqkkKqhE7ghlhSAp8xKLgRs-R4JL13E2hNg6FnGlbLWGkl4m34B0sLntGiSdNB70eSySkV0tG5O0oV4XIG6KuM9roPIfKHJ6ANI7xiSH-xLI5N2us7AFDmj0dBMlien019UaDJgQ3FLZdO6K2n27U7hyphenhyphenAmvB6KE0M2kmY1NTarvHPDWWNpzpdNvZAEA/s1600/aiocontext-lock-removal.png"></a></p>

<p>Until 2009 QEMU was largely a single-threaded program. This had the benefit
that the code didn't need to consider thread-safety and was thus simpler and
less bug-prone. The main loop interleaved running the next piece of guest code
and handling external events such as timers, disk I/O, and network I/O. This
architecture had the downside that emulating multi-processor guests was
bottlenecked by the single host CPU on which QEMU ran. There was no parallelism
and this became problematic as multi-processor guests became popular.</p>

<h2>Multi-threading with vCPU threads and the Big QEMU Lock</h2>

<p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiH839GLUwVrLnNx3fjDgB16sXcc85EsF5DxjWYPUueVjQvtCyVGB3hq_K78iES6Ks3eP97t2NS08WcKIJ9dC0ZwZuptwwNWyvoGB7uA9Lnh24hO5fN7Sky2CKGf2Z3HGXXdMmD8ViypgIKzPnfBbnzg33skQ9HRCp9Osmt9ZCuYNtoR3FV2EkMD42rFS0/s1600/aiocontext-lock-removal%281%29.png"><img alt="" data-original-height="323" data-original-width="400" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiH839GLUwVrLnNx3fjDgB16sXcc85EsF5DxjWYPUueVjQvtCyVGB3hq_K78iES6Ks3eP97t2NS08WcKIJ9dC0ZwZuptwwNWyvoGB7uA9Lnh24hO5fN7Sky2CKGf2Z3HGXXdMmD8ViypgIKzPnfBbnzg33skQ9HRCp9Osmt9ZCuYNtoR3FV2EkMD42rFS0/s1600/aiocontext-lock-removal%281%29.png"></a></p>

<p>The architecture was modified to support running dedicated vCPU threads for KVM guests. This made parallelism possible for multi-processor guests but the feature was initially only available for KVM guests. The Multi-Threaded TCG (MTTCG) feature eventually allowed translated code
  to also take advantage of vCPU threads in 2016.</p>

<p>A straightforward approach to making all existing code thread-safe was taken: the Big QEMU
Lock (BQL) was introduced to serialize access to QEMU's internal state. The BQL is a single global mutex that is used to protect the majority of QEMU's internal state. KVM vCPU threads do not need access to
QEMU's internal state while executing guest code, so they don't hold the BQL most of the time. The main loop thread drops the BQL while blocking in <tt>ppoll(2)</tt> and this allows vCPU threads to acquire the lock when they come out of guest code.</p>

<h2>Multi-threading with IOThreads and the AioContext lock</h2>
<p>Although the vCPU bottleneck had been solved, device emulation still ran with the BQL held. This meant that only a single QEMU thread could process I/O requests at a time. For I/O bound workloads this was a bottleneck and especially disk I/O performance suffered due to this limitation. My first attempt at removing the bottleneck in 2012 amounted to writing a new "dataplane" code path outside the BQL, but it lacked the features that users needed like disk image file formats, I/O throttling, etc because it couldn't use the existing code that relied on the BQL. The long term solution would be introducing thread-safety to the existing code and that led to the creation of the AioContext lock.</p>

<p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjxXoqTPO2j_GrEHm8cU73KXT1RlIphD4nTi6WX4pRjdSOYwcfzqtvDzQR5bCInPyZzmcrom_46oO1Kq595z2Ie0oK4LuajjWFHoSIkFU5RG0HZFMjv_5ub4E5j7GpdijsikrcsnCdQoBAvs4_h10TjdZs5SEvWbhonBE0B7YpUtsEf6MG1OKlQh5YwVyY/s1600/aiocontext-lock-removal%282%29.png"><img alt="" data-original-height="323" data-original-width="758" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjxXoqTPO2j_GrEHm8cU73KXT1RlIphD4nTi6WX4pRjdSOYwcfzqtvDzQR5bCInPyZzmcrom_46oO1Kq595z2Ie0oK4LuajjWFHoSIkFU5RG0HZFMjv_5ub4E5j7GpdijsikrcsnCdQoBAvs4_h10TjdZs5SEvWbhonBE0B7YpUtsEf6MG1OKlQh5YwVyY/s1600/aiocontext-lock-removal%282%29.png"></a></p>

<p>The AioContext lock was like a mini-BQL but for an event loop (QEMU calls this an AioContext) instead of the entire program. Initially the event loop would acquire the lock while running event handlers, thereby ensuring mutual exclusion for all handlers associated with the event loop. Another thread could acquire the lock to stop the event loop from running and safely access variables. This was a crude approach though and propagated the BQL way of thinking further. QEMU began to suffer from deadlocks and race conditions now that multi-threading was possible. Although I wrote developer documentation about how the model worked, it became tricky to gain confidence in the safety of the code as the whole QEMU block layer needed to grapple with AioContext locking and did so incompletely and inconsistently.</p>

<p>The upshot of all of this was that disk I/O processing could run in a dedicated event loop thread (QEMU calls this an IOThread) while the QEMU monitor could acquire the AioContext lock for a brief moment to inspect the emulated disk for an "info block" monitor command, for example. Unlike the earlier "dataplane" approach, it was now possible for the QEMU block layer to run outside the BQL and instead rely on the AioContext lock.</p>

<h2>Removing the AioContext lock</h2>
<p>Paolo Bonzini had the idea to gradually eliminate the AioContext lock in favor of fine-grained locks because we kept hitting problems with the AioContext lock that I described above. His insight was to change the model so that handler functions would explicitly take their AioContext's lock instead acquiring the lock around the entire event loop iteration. The advantage to letting handlers take the lock was that they could also replace it with another mechanism. Eventually it would be possible to move away from the AioContext lock.</p>

<p>What came after was a multi-year journey that I credit to Paolo's vision. Emanuele Giuseppe Esposito worked with Paolo on putting fine-grained locking into practice and on sorting through the entire QEMU block layer to determine under which threads and locks variables were accessed. This was a massive effort and required a lot of persistence. Kevin Wolf figured out how to use clang's Thread Safety Analysis (TSA) to check some of the locking rules at compile time. Kevin also spent a lot of time protecting the block driver graph with a reader/writer lock so that in-flight I/O does not crash amidst modifications to the graph. Emanuele and Kevin gave a talk at KVM Forum 2023 about the larger QEMU multi-queue block layer effort and the slides are available <a href="https://kvm-forum.qemu.org/2023/Multiqueue_in_the_block_layer_wLom4Bt.pdf">here (PDF)</a>.</p>

<p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhoui6qLoeUNBnyz6Wz8LN9aZz-0kMBT0wU4dkZFnMWnaR61H9esMca1QZ0RJh1w-FkVrPGOMLrV622ZG4Wh2ucn3xFD6AIFxUIlV2D_mjyBIESdj4eMoEbISGdVTzOhoW10Dn01eCzP7pdjmR5EJRcD9_I3-rGmRbW4zbMJsgEJVJiHGfLHPogXr_Lkpw/s1600/aiocontext-lock-removal%283%29.png"><img alt="" data-original-height="323" data-original-width="585" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhoui6qLoeUNBnyz6Wz8LN9aZz-0kMBT0wU4dkZFnMWnaR61H9esMca1QZ0RJh1w-FkVrPGOMLrV622ZG4Wh2ucn3xFD6AIFxUIlV2D_mjyBIESdj4eMoEbISGdVTzOhoW10Dn01eCzP7pdjmR5EJRcD9_I3-rGmRbW4zbMJsgEJVJiHGfLHPogXr_Lkpw/s1600/aiocontext-lock-removal%283%29.png"></a></p>

<p>Once everything that previously relied on the AioContext lock had switched to another form of thread-safety, it was possible to remove the AioContext lock as nothing used it anymore. The BQL is still widely used and covers global state that is accessed from few threads. Code that can run in any IOThread now uses its own locks or other mechanisms. The complexity of the codebase is still roughly the same as with the AioContext lock, but now there are fine-grained locks, which are easier to understand and there are fewer undocumented locking assumptions that led to deadlocks and races in the past.</p>

<h2>Conclusion</h2>
<p>QEMU's AioContext lock enabled multi-threading but was also associated with deadlocks and race conditions due to its ambient nature. From QEMU 9.0 onwards, QEMU will switch to fine-grained locks that are more localized and make thread-safety more explicit. Changing locking in a large program is time-consuming and difficult. It took a multi-person multi-year effort to complete this work, but it forms the basis for further work including the QEMU multi-queue block layer effort that push multi-threading further in QEMU.</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Browsers are the most likely disruptor of the mobile duopoly (277 pts)]]></title>
            <link>https://infrequently.org/2024/01/the-web-is-the-app-store/</link>
            <guid>38847719</guid>
            <pubDate>Tue, 02 Jan 2024 22:05:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://infrequently.org/2024/01/the-web-is-the-app-store/">https://infrequently.org/2024/01/the-web-is-the-app-store/</a>, See on <a href="https://news.ycombinator.com/item?id=38847719">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
      <!-- BLOCK_CONTENT -->

  
  <article>
    <header>
      <h2>
        <a href="https://infrequently.org/2024/01/the-web-is-the-app-store/">Why Are Tech Reporters Sleeping On The Biggest App Store Story?</a>
      </h2>
      <h3>Browsers are the most likely disruptor of the mobile duopoly but you'd never know it reading Wired or The Verge.</h3>
      
    </header>
    <p>The tech news is chockablock<sup><a href="#fn-recent-antitrust-news-1" id="fnref-recent-antitrust-news-1">[1]</a></sup> with <a href="https://open-web-advocacy.org/blog/owa-2023-review/">antitrust rumblings and slow-motion happenings.</a> Through eagle-eyed press coverage, regulatory reports, and legal discovery the shady dealings of <a href="https://www.theverge.com/2020/4/3/21206400/apple-tax-amazon-tv-prime-30-percent-developers">Apple</a> and <a href="https://www.theverge.com/2023/11/30/23923533/google-explains-why-some-developers-were-able-to-get-away-with-paying-less-on-play">Google's</a> app stores are now comprehensively documented and pressure for change has built to an unsustainable level. Something's gotta give.</p>
<p>This is the backdrop to the biggest app store story nobody is writing about: on pain of <a href="https://ec.europa.eu/commission/presscorner/detail/en/qanda_20_2349#:~:text=In%20case%20a,systemic%20non%2Dcompliance.">steep fines,</a> gatekeepers are opening up to competing browsers. This, in turn, will enable competitors to replace app stores with directories of <a href="https://infrequently.org/2015/06/progressive-apps-escaping-tabs-without-losing-our-soul/">Progressive Web Apps</a>. Capable browsers that <a href="https://patrickbrosset.com/articles/2023-09-26-my-first-tpac-conference/#:~:text=The%20Web%20Applications,was%20also%20reviewed.">expose</a> web app installation and powerful features to developers can kickstart app portability, breaking open the mobile duopoly.</p>
<p>But you'd never know it reading Wired or The Verge.</p>
<div><ul><li><a href="#the-buried-lede">The Buried Lede </a></li><li><a href="#disruption-disrupted">Disruption Disrupted </a></li><li><a href="#green-shoots">Green Shoots </a></li><li><a href="#a-new-hope">A New Hope </a></li></ul></div>
<p>With shockingly few <a href="https://www.theregister.com/2023/10/09/apple_app_store/">exceptions,</a> coverage of app store regulation that the answer to crummy, extractive native app stores is other native app stores. This unexamined framing shapes hundreds of pieces covering regulatory events, including <a href="https://www.rollingstone.com/culture/culture-commentary/internet-future-about-to-get-weird-1234938403/">by web-friendly authors.</a> The tech press almost universally fails to mention the web as a <a href="https://en.wikipedia.org/wiki/Substitute_good">substitute</a> for native apps and fail to inform readers of its potential to disrupt app stores.</p>
<p>As <a href="https://doctorow.medium.com/the-open-web-is-good-actually-9683c692df84#:~:text=%E2%80%9CAn%20app%20is%20just%20a%20web%2Dpage%20wrapped%20in%20enough%20IP%20to%20make%20it%20a%20crime%20to%20defend%20yourself%20against%20corporate%20predation%E2%80%9D">Cory Doctorow observed</a>:</p>
<blockquote>
<p>"An app is just a web-page wrapped in enough IP to make it a crime to defend yourself against corporate predation."</p>
</blockquote>
<p>The implication is clear: browsers unchained can do to mobile what the web did to desktop, where more than 70% of daily "jobs to be done" happen on the web.</p>
<p>Replacing mobile app stores will look different than the web's path to desktop centrality, but the enablers are waiting in the wings. It has gone largely unreported that <a href="https://web.dev/explore/progressive-web-apps">Progressive Web Apps (PWAs)</a> have been held back by Apple and Google denying competing browsers access to essential APIs.<sup><a href="#fn-convergent-agendas-2" id="fnref-convergent-agendas-2">[2]</a></sup></p>
<p>Thankfully, regulators haven't been waiting on the press to explain the situation. Recent interventions into mobile ecosystems include requirements to repair browser choice, and the analysis backing those regulations takes into account the web's role as a potential competitor (e.g., <a href="https://www.jftc.go.jp/file/230327EN_Summary.pdf">Japan's JFTC (pdf)</a>).</p>
<p>Regulators seem to understand that:</p>
<ul>
<li>App stores protect proprietary ecosystems through preferential discovery and capabilities.</li>
<li>Stores then extract rents from developers dependent on commodity capabilities duopolists provide only through proprietary APIs.</li>
<li>App portability threatens the proprietary agenda of app stores.</li>
<li>The web can interrupt this model by bringing portability to apps and over-the-top discovery through search. This has yet to happen because...</li>
<li>The duopolists, in different ways, have kneecapped competing browsers along with their own, keeping the web from contesting the role of app stores.</li>
</ul>
<p>Apple and Google saw what the web did to desktop, and they've laid roadblocks to the competitive forces that would let history repeat on smartphones.</p>
<h2 id="the-buried-lede">The Buried Lede <a href="#the-buried-lede">#</a></h2>
<p>The web's potential to disrupt mobile is evident to regulators, <a href="https://open-web-advocacy.org/">advocates</a>, and developers. So why does the tech news fail to explain the situation?</p>
<p>Consider <a href="https://www.techmeme.com/231226/p14#a231226p14">just one</a> of the many antitrust events of recent months. It was covered by <a href="https://www.theverge.com/2023/12/28/24017565/japan-plans-to-crack-down-on-apple-and-google-app-stores">The Verge</a>, <a href="https://www.macrumors.com/2023/12/27/japan-preparing-eu-style-law/">Mac Rumors</a>, <a href="https://appleinsider.com/articles/23/12/26/japan-plans-to-fine-apple-over-app-stores-and-antitrust-issues">Apple Insider</a>, and <a href="https://news.ycombinator.com/item?id=38773429">more.</a></p>
<p>None of the linked articles note browser competition's potential to upend app stores. Browsers unshackled have the potential to free businesses from build-it-twice proprietary ecosystems, end rapacious app store taxes, pave the way for new OS entrants — all without the valid security concerns side-loading introduces.</p>
<p>Lest you think this an isolated incident, <a href="https://www.techmeme.com/230820/p8#a230820p8">this article on the impact of the EU's DMA</a> lacks any hint of the web's potential to unseat app stores. You can repeat this trick with <a href="https://www.techmeme.com/search/query?q=EU+DMA&amp;wm=false"><em>any</em> DMA story from the past year</a>. Or spot-check <a href="https://www.techmeme.com/230201/p11#a230201p11">coverage</a> of the <a href="https://www.ntia.gov/report/2023/competition-mobile-app-ecosystem">NTIA's February report.</a></p>
<p>Reporters are "covering" these stories in the lightest sense of the word. Barrels of virtual ink has been spilt documenting unfair app store terms, conditions, and competition. And yet.</p>
<h2 id="disruption-disrupted">Disruption Disrupted <a href="#disruption-disrupted">#</a></h2>
<p>In an industry obsessed with "disruption," why is this David vs. Goliath story going untold? Some theories, in no particular order.</p>
<p>First, Mozilla <a href="https://infrequently.org/2020/06/platform-adjacency-theory/#the-committee-to-cast-the-web-in-amber">isn't advocating for a web that can challenge native apps,</a> and none of the other major browser vendors are telling the story either. Apple and Google have no interest in seeing their lucrative proprietary platforms supplanted, and Microsoft (your narrator's employer) <a href="https://www.theverge.com/2023/10/24/23930478/microsoft-ceo-satya-nadella-mobile-windows-phone">famously lacks sustained mobile focus.</a></p>
<p>Next, it's hard to overlook that tech reporters live like wealthy people, iPhones and all. From that vantage point, it's often news that the web is <a href="https://fugu-tracker.web.app/">significantly more capable</a> on other OSes (never mind that they spend much of every day working in a desktop browser). It's hard to report on the potential of something you can't see for yourself.</p>
<p>Also, this might all be Greek. Reporters and editors aren't software engineers, so the potential of browser competition can remain understandably opaque. Stories that include mention of "alternative app stores" generally fail to mention that these stores may not be as safe, or that OS restrictions on features won't disappear just because of a different distribution mechanism, or that the security track records of the <em>existing</em> duopolist app stores are sketchy at best. Under these conditions, it's asking a lot to expect details-based discussion of alternatives, given the many technical wrinkles. Hopefully, <a href="https://open-web-advocacy.org/">someone can walk them through it.</a></p>
<p>Further, <a href="https://en.wikipedia.org/wiki/Contestable_market">market contestability theory</a> has only recently become a big part of the tech news beat. Regulators have been writing reports to convey their understanding of the market, and to shape effective legislation that will unchain the web, but smart folks unversed in both antitrust and browser minutiae might need help to pick up what regulators are putting down.</p>
<p>Lastly, it hasn't happened yet. Yes, <a href="https://infrequently.org/2015/06/progressive-apps-escaping-tabs-without-losing-our-soul/">Progressive Web Apps</a> have been around for a few years, but they haven't had an impact on the iPhones that reporters and their circles almost universally carry. It's much easier to get folks to cover stories that directly affect them, and this is one that, so far, largely hasn't.</p>
<h2 id="green-shoots">Green Shoots <a href="#green-shoots">#</a></h2>
<p>The seeds of web-based app store dislocation have already been sown, but the chicken-and-egg question at the heart of platform competition looms.</p>
<p>On the technology side, Apple has been <a href="https://infrequently.org/2021/04/progress-delayed/">enormously successful at denying essential capabilities to the web</a> through a strategy of compelled monoculture combined with strategic foot-dragging.</p>
<figure>
<a href="https://mastodon.social/@bobpony/111602947135060878" alt="undefined">
<picture width="682" height="841">
  <source sizes="(max-width: 1200px) 70vw, 600px" srcset="https://infrequently.org/2024/01/the-web-is-the-app-store/every_browser_toot.webp?nf_resize=fit&amp;w=3600 2400w,
                  https://infrequently.org/2024/01/the-web-is-the-app-store/every_browser_toot.webp?nf_resize=fit&amp;w=2400 1600w,
                  https://infrequently.org/2024/01/the-web-is-the-app-store/every_browser_toot.webp?nf_resize=fit&amp;w=1800 1200w,
                  https://infrequently.org/2024/01/the-web-is-the-app-store/every_browser_toot.webp?nf_resize=fit&amp;w=1200   800w,
                  https://infrequently.org/2024/01/the-web-is-the-app-store/every_browser_toot.webp?nf_resize=fit&amp;w=900   600w,
                  https://infrequently.org/2024/01/the-web-is-the-app-store/every_browser_toot.webp?nf_resize=fit&amp;w=750   500w,
                  https://infrequently.org/2024/01/the-web-is-the-app-store/every_browser_toot.webp?nf_resize=fit&amp;w=600   400w">
<img src="https://infrequently.org/2024/01/the-web-is-the-app-store/every_browser_toot.webp" alt="Missing alt text" width="682" height="841" decoding="async">
</picture>

</a>
  <figcaption></figcaption>
</figure>
<p>As an example, the <a href="https://infrequently.org/2023/02/safari-16-4-is-an-admission/">eight-year delay</a> in implementing Push Notifications for the web<sup><a href="#fn-checkbox-compliance-3" id="fnref-checkbox-compliance-3">[3]</a></sup> kept many businesses from giving the web a second thought. If they couldn't re-engage users at the same rates as native apps, the web might as well not exist on phones. This logic has played out on a loop over the last decade, category-by-category, with gatekeepers preventing competing browsers from bringing capabilities to web apps that would let them supplant app stores<sup><a href="#fn-convergent-agendas-2" id="fnref-convergent-agendas-2:1">[2:1]</a></sup> while simultaneously keeping them from being discovered through existing stores.</p>
<p>Proper browser choice could upend this situation, finally allowing the web to provide "table stakes" features in a compelling way. For the first time, developers could bring the modern web's full power to wealthy mobile users, enabling the "write once, test everywhere" vision, and cut out the app store middleman — all without sacrificing essential app features or undermining security.</p>
<p>Sunsetting the 30% tax requires a compelling alternative, and Apple's simultaneous underfunding of Safari and compelled adoption of its underpowered engine have interlocked to keep the web out of the game. No wonder Apple is massively funding lobbyists, lawyers, and <a href="https://www.bloomberg.com/news/articles/2022-09-19/apple-flexes-muscle-as-quiet-power-behind-app-developer-group">astroturf groups</a> to keep engine diversity at bay while belatedly <a href="https://infrequently.org/2023/02/safari-16-4-is-an-admission/">battening the hatches</a>.</p>
<p>On the business side, managers think about "mobile" as a category. Rather than digging into the texture of iOS, Android, and the differing web features available on each, businesses tend to bulk accept or reject the app store model. One sub-segment of "mobile" growing the ability to route around highway robbery Ts &amp; Cs is tantalising, but not enough to change the game; the web, like other metaplatforms, is only a disruptive force when pervasive and capable.<sup><a href="#fn-self-censorship-4" id="fnref-self-censorship-4">[4]</a></sup></p>
<p>A prohibition on store discovery for web apps has buttressed Apple's denial of essential features to browsers:</p>
<figure>
<a href="https://developer.apple.com/app-store/review/guidelines/#2.4" alt="Even if developers overcome the ridiculous hurdles that Apple's shoddy browser engine throws up, they're still <a href='https://developer.apple.com/app-store/review/guidelines/#2.4'>prevented by Apple policy</a> from making interoperable web apps discoverable where users look for them.">
<picture width="626" height="136">
  <source sizes="(max-width: 1200px) 70vw, 600px" srcset="https://infrequently.org/2024/01/the-web-is-the-app-store/apple_4.2._highlight_minimum-functionality.png?nf_resize=fit&amp;w=3600 2400w,
                  https://infrequently.org/2024/01/the-web-is-the-app-store/apple_4.2._highlight_minimum-functionality.png?nf_resize=fit&amp;w=2400 1600w,
                  https://infrequently.org/2024/01/the-web-is-the-app-store/apple_4.2._highlight_minimum-functionality.png?nf_resize=fit&amp;w=1800 1200w,
                  https://infrequently.org/2024/01/the-web-is-the-app-store/apple_4.2._highlight_minimum-functionality.png?nf_resize=fit&amp;w=1200   800w,
                  https://infrequently.org/2024/01/the-web-is-the-app-store/apple_4.2._highlight_minimum-functionality.png?nf_resize=fit&amp;w=900   600w,
                  https://infrequently.org/2024/01/the-web-is-the-app-store/apple_4.2._highlight_minimum-functionality.png?nf_resize=fit&amp;w=750   500w,
                  https://infrequently.org/2024/01/the-web-is-the-app-store/apple_4.2._highlight_minimum-functionality.png?nf_resize=fit&amp;w=600   400w">
<img src="https://infrequently.org/2024/01/the-web-is-the-app-store/apple_4.2._highlight_minimum-functionality.png" alt="Even if developers overcome the ridiculous hurdles that Apple's shoddy browser engine throws up, they're still <a href='https://developer.apple.com/app-store/review/guidelines/#2.4'>prevented by Apple policy</a> from making interoperable web apps discoverable where users look for them." width="626" height="136" decoding="async" loading="lazy">
</picture>

</a>
  <figcaption>Even if developers overcome the ridiculous hurdles that Apple's shoddy browser engine throws up, they're still <a href="https://developer.apple.com/app-store/review/guidelines/#2.4">prevented by Apple policy</a> from making interoperable web apps discoverable where users look for them.</figcaption>
</figure>
<p><a href="https://developer.chrome.com/docs/android/trusted-web-activity">Google's answer to web apps in Play is a dog's breakfast</a>, but it <em>does</em> at least exist for developers willing to put in the effort, or for teams savvy enough to reach for <a href="https://www.pwabuilder.com/">PWA Builder.</a></p>
<p>Recent developments also point to a competitive future for capable web apps.</p>
<p>First, browser engine choice should become a reality on iOS in the EU in 2024, thanks to the plain language of the DMA. Apple will, of course, attempt to delay the entry of competing browsers through as-yet-unknown strategies, but the clock is ticking. Once browsers can enable capable web apps with easier distribution, the logic of the app store loses a bit of its lustre.</p>
<p>Work is also underway to give competing browsers a <a href="https://github.com/MicrosoftEdge/MSEdgeExplainers/blob/main/WebInstall/explainer_cross_domain.md">chance to facilitate PWAs that can install other PWAs.</a> Web App Stores would then become a real possibility through browsers that support them, and we should expect that regulatory and legislative interventions will facilitate this in the near future. Removed from the need to police security (browsers have that covered) and handle distribution (websites update themselves), PWA app stores like <a href="https://store.app/">store.app</a> can become honest-to-goodness app management surfaces that can safely facilitate discovery and sync.</p>
<figure>
<figure>
<img src="https://infrequently.org/2024/01/the-web-is-the-app-store/appsco.pe.webp" decoding="async" loading="lazy">
<img src="https://infrequently.org/2024/01/the-web-is-the-app-store/store.app.webp" decoding="async" loading="lazy">
</figure>
<figcaption>
  PWA app stores like <a href="https://appsco.pe/" target="_new">Appscope</a> and <a href="https://store.app/">store.app</a> exist, but they're hobbled by gatekeepers that have denied competing browsers access to APIs that could turn PWA directories into real contenders.
<figcaption>
</figcaption></figcaption></figure>
<p>It's no surprise that Apple and Google have kept private the APIs needed to make this better future possible. They built the necessary infrastructure for the web to disrupt native, then kept it to themselves. This potential has remained locked away within organisations politically hamstrung by native app store agendas. But all of that is about to change.</p>
<p>This begs the question: where's the coverage? This is the most exciting moment in more than 15 years for the web vs. native story, but the tech press is whiffing it.</p>
<h2 id="a-new-hope">A New Hope <a href="#a-new-hope">#</a></h2>
<p>2024 will be packed to the gills with app store and browser news, from implementation of the DMA, to the UK's renewed push into mobile browsers and cloud gaming, to new legislation arriving in many jurisdictions, to the first attempts at shipping iOS ports of Blink and Gecko browsers. Each event is a chance to inform the public about the already-raging battle for the future of the phone.</p>
<p>It's still possible to reframe these events and provide better context. We need a fuller discussion about what it will mean for mobile OSes to have competing native app stores when the underlying OSes are foundationally insecure. There are also existing examples of ecosystems with this sort of choice (e.g., China), and more needs to be written about the implications for users and developers. Instead of nirvana, the insecure status quo of today's mobile OSes, combined with (even more) absentee app store purveyors, turns side-loading into an alternative form of lock-in, with a kicker of added insecurity for users. With such a foundation, the tech-buying public could understand why a browser's superior sandboxing, web search's better discovery, and frictionless links are better than dodgy curation side-deals and <a href="https://www.theverge.com/c/22611236/epic-v-apple-emails-project-liberty-app-store-schiller-sweeney-cook-jobs#:~:text=%E2%80%9CRegarding%20review%20processes,we%20can%20detect%3F%E2%80%99%E2%80%9D"><em>"beware of dog"</em> sign security.</a></p>
<p>The more that folks understand the stakes, the more likely tech will genuinely change for the better. And isn't that what public interest journalism is <em>for</em>?</p>

<hr>
<section>
<ol>
<li id="fn-recent-antitrust-news-1"><p><a href="https://www.theverge.com/antitrust">Antitrust is now a significant tech beat</a>, and recent events frequently include browser choice angles because regulators keep writing regulations that will enhance it. This beat is only getting more intense, giving the tech press ample column inches to explain the status quo more deeply and and educate around the most important issues.</p>
<p>In just the last two months:</p>
<ul>
<li>
<p>Google lost to Epic in a <a href="https://www.theverge.com/23994174/epic-google-trial-jury-verdict-monopoly-google-play">jury trial that determined Google's Play Store is an illegal monopoly.</a></p>
</li>
<li>
<p>Google <a href="https://www.theverge.com/23945184/epic-v-google-fortnite-play-store-antitrust-trial-updates/archives/3#stream-entry-d3f7f1e3-0891-475e-95f8-0b0a4320e371">lost all assumption of good faith</a> as evidence from the Epic trial <a href="https://www.theverge.com/2023/11/13/23959570/samsung-knew-the-project-banyan-deal-was-anticompetitive">showed the Play team to be scoundrels</a>, <a href="https://www.theverge.com/2023/11/15/23962589/i-dont-know-if-ensuring-fairness-was-part-of-my-job-i-never-thought-of-it-that-way">two-timers</a>, and <a href="https://www.theverge.com/2023/11/9/23954111/google-boasted-it-got-riot-games-not-to-launch-its-own-app-store-by-offering-10m">cretins</a> who were willing to set <a href="https://www.theverge.com/2023/11/20/23969690/google-spotify-android-billing-commission-secret-deal">shockingly unfair terms</a> for <a href="https://www.theverge.com/23954852/google-netflix-app-store-deal-play-10-percent-revshare">anyone</a> with enough market power to embarrass them. And that's before we get to the <a href="https://gizmodo.com/google-denies-its-project-hug-bribed-20-developers-1851009202">light attempted bribery.</a></p>
</li>
<li>
<p>Google's <a href="https://arstechnica.com/gadgets/2023/11/googles-36-search-revenue-share-with-apple-is-3x-what-android-oems-get/">witness also blurted out a statistic that is both anodyne and damning: 36%.</a> That's what Google pays Apple in search rev-share for default search placement in Safari. Normally, this would be a detail of a boring business deal. In context, however, it highlights Apple's decade-long suppression of iOS browser competition — combined with <a href="https://wpt.fyi/results/?label=experimental&amp;label=master&amp;aligned">poverty-level funding of WebKit</a> — which has <a href="https://www.theverge.com/2023/11/14/23960819/pichai-admits-google-pays-apple-a-36-percent-revenue-share-for-search-results">skimmed tens of billions in profit <em>per year</em> from the web</a> while starving browser development. This has deprived users, businesses, and web developers of safe (but critical) capabilities. It wasn't just Play that buggered the mobile web; Google was happy to outsource the dirty deed too.</p>
</li>
<li>
<p>Apple <a href="https://caselaw.nationalarchives.gov.uk/ewca/civ/2023/1445">lost on an appeal</a> to keep the UK's Competition and Market Authority (CMA) <a href="https://www.gov.uk/cma-cases/mobile-browsers-and-cloud-gaming">investigation into browsers and cloud gaming</a> on ice.<sup><a href="#fn-mir-icing-5" id="fnref-mir-icing-5">[5]</a></sup></p>
</li>
<li>
<p>In December, Apple <a href="https://open-web-advocacy.org/blog/cma-reopens-investigation-into-apple/">declined to appeal to the UK's Supreme Court</a> for reasons that remain opaque.</p>
<p>Perhaps Apple didn't appeal because, in November, the UK unexpectedly brought forward the <a href="https://bills.parliament.uk/bills/3453">Digital Markets, Competition and Consumers Bill.</a> It looks set to become law early in the new year, standing up a regulator with real teeth who, one presumes, will not be predisposed to think well of Apple's delay of its predecessor's investigations.</p>
</li>
<li>
<p>Meanwhile, in the EU, Apple attempted to wriggle out of regulations that might bring about proper browser choice by <a href="https://www.theregister.com/2023/11/02/apple_safari_browser/">arguing that Safari is actually <em>three</em> under-performing browsers.</a> in <a href="https://brucelawson.co.uk/2023/apples-eu-legal-shenanigans/">a marketing trenchcoat</a><sup><a href="#fn-hair-splitting-6" id="fnref-hair-splitting-6">[6]</a></sup>.</p>
</li>
<li>
<p>On the other side of the planet, <a href="https://asia.nikkei.com/Business/Technology/Japan-to-crack-down-on-Apple-and-Google-app-store-monopolies">news just broke that Japan will bring forward legislation</a> to target app store shenanigans. Given the JFTC's earlier findings about how interlocking layers of control have kept browsers from contesting app store prominence, we can expect some spicy legislative language around browsers.</p>
</li>
<li>
<p>Australia has also <a href="https://open-web-advocacy.org/blog/new-digital-competition-laws-for-australia/">just agreed (in principle) to do the same</a>, including language that acknowledges the role suppressing browser choice has had in preventing the web from competing with mobile native app ecosystems.</p>
</li>
</ul>
<p>All but one of the 19 links above are from just the last 60 days, a period which includes a holiday break in the US and Europe. With the EU's DMA coming into force in March and the CMA back on the job, browser antitrust enforcement is only accelerating. It sure would be great if reporters could occasionally connect these dots. <a href="#fnref-recent-antitrust-news-1">↩︎</a></p>
</li>
<li id="fn-convergent-agendas-2"><p>The stories of how Apple and Google have kept browsers from becoming real app stores differ greatly in their details, but the effects have been nearly identical: only their browsers could offer installation of web apps, and those browsers have done shockingly little to support web developers who want to depend on the browser as the platform.</p>
<p>The ways that Apple has undermined browser-based stores is relatively well known: no equivalent to PWA install or <a href="https://bugs.webkit.org/show_bug.cgi?id=255858">"Smart Banners" for the web</a>, no way for sites to <a href="https://bugs.webkit.org/show_bug.cgi?id=259490">suppress promotion of native apps</a>, no ability for competing browsers to trigger homescreen installation until just this year, etc. etc. The decade-long build of Apple's many and varied attacks on the web as a platform is a story that's both tired and under-told.</p>
<p>Google's malfeasance has gotten substantially less airtime, even among web developers – nevermind the tech press.</p>
<p>The story picks up in 2017, two years after the <a href="https://blog.chromium.org/2015/03/chrome-42-beta-push-notifications_12.html">release of PWAs and Push Notifications in Chrome.</a> At the time, the PWA install flow was something of a poorly practised parlour trick: installation used an unreliable homescreen shortcut API that failed on many devices with OEM-customised launchers. The shortcut API also came laden with baggage that prevented effective uninstall and cross-device sync.</p>
<p>To improve this situation, <a href="https://web.dev/articles/webapks">"WebAPKs" were developed.</a> This new method of installation allows for deep integration with the OS, similar to the Application Identity Proxy feature that Windows lets browsers to provide for PWAs, with one notable exception: on Android, only Chrome gets to use the WebAPK system.</p>
<p>Without getting into the weeds, suffice to say many non-Chrome browsers requested access. Only Google could meaningfully provide this essential capability across the Android ecosystem. So important were WebAPKs that Samsung gave up begging and <a href="https://medium.com/samsung-internet-dev/new-year-new-samsung-internet-b74f282e4429">reverse engineered it for their browser</a> on Samsung devices. This only worked on Samsung phones where Suwon's engineers could count on device services and system keys not available elsewhere. That hasn't helped other browsers, and it certainly isn't an answer to an ecosystem-level challenge.</p>
<p>Without WebAPK API access, competing browsers can't innovate on PWA install UI and can't meaningfully offer PWA app stores. Instead, the ecosystem has been left to limp along at the excruciating pace of Chrome's PWA UI development.</p>
<p>Sure, Chrome's PWA support has been a damn sight better than Safari's, but that's just damning with faith praise. Both Apple and Google have done their part to quietly engineer a decade of unchallenged native app dominance. Neither can be trusted as exclusive stewards of web competitiveness. Breaking the lock on the doors holding back real PWA installation competition will be a litmus test for the effectiveness of regulation now in-flight. <a href="#fnref-convergent-agendas-2">↩︎</a> <a href="#fnref-convergent-agendas-2:1">↩︎</a></p>
</li>
<li id="fn-checkbox-compliance-3"><p>Push Notifications were, without exaggeration, the single most requested mobile Safari in the eight years between when Chromium browsers shipped them and when Apple finally capitulated.</p>
<p>It's unedifying to recount all of the ways Apple prevented competing iOS browsers from implementing Push, all while gaslighting developers who requested this business-critical feature over and over and over again. It's also unhelpful to fixate on the runarounds that Apple gave companies with enough clout to somehow find an Apple rep to harangue directly. So, let's call it water under the bridge. Apple <a href="https://developer.apple.com/documentation/usernotifications/sending_web_push_notifications_in_web_apps_and_browsers">shipped</a>, so we're good, right?</p>
<p>Right?</p>
<p>I regret to inform you, dear reader, that it not, in fact, "good".</p>
<p>Despite most of a decade to study up on the problem space, and nearly <a href="https://en.wikipedia.org/wiki/Apple_Push_Notification_service">15 years of of experience</a> with Push, Apple's implementation is anything but complete.</p>
<p>The first few releases exposed APIs that hinted at important functionality, but were broken or missing. Features as core as closing notifications, or updating text when new data comes in. Think, showing the latest message in a chat, rather than leaving a stream of notifications in the tray for every message that has arrived since you last cleared the tray.</p>
<p>Important features didn't work. <a href="https://bugs.webkit.org/show_bug.cgi?id=258922">Some still don't.</a>. And the pathetic set of customisations provided for notification UI is a joke.</p>
<p>Web developers have once again been left to dig through the wreckage to understand just how badly Apple's <em>cough</em> "minimalist" <em>cough</em> implementation is compromised. And boy howdy, is it bad.</p>
<p>Apple's implementation might have <a href="https://wpt.fyi/results/notifications?label=experimental&amp;label=master&amp;aligned">passed surface-level tests</a> (gotta drive up that score!), but it's unusable for serious products. It's possible to draw many possible conclusions from this terrible showing, but even the relative charity of Hanlon's Razor is damning.</p>
<p>Nothing about this would be worse than any other under-funded, trailing-edge browser over the past three decades (which is to say, a bloody huge problem), except for Apple's well-funded, aggressive, belligerent ongoing protest to every regulatory attempt to allow true browser choice for iPhone owners.</p>
<p>In the year 2024, you can have any iOS browser you like. You can even set them as default. They <em>might</em> even have APIs that look like they'll solve important product needs, but as long as they're forced to rely on Apple's shit-show implementation, the web can't ever be a competitive platform.</p>
<p>When Apple gets to define the web's potential, the winner will always be native, and through it, Apple's bottom line. <a href="#fnref-checkbox-compliance-3">↩︎</a></p>
</li>
<li id="fn-self-censorship-4"><p>The muting effect of Apple's abuse of monopoly over wealthy users to kneecap the web's capabilities is aided by the self-censorship of web developers. The values of the web are a mirror world to native, where developers are feted for adopting bleeding-edge APIs. On the web, features aren't "available" until 90+% of all users have access to them. Because <a href="https://analytics.wikimedia.org/dashboards/browsers/#all-sites-by-os-and-browser">iOS is at least 20%</a> of <a href="https://gs.statcounter.com/browser-market-share/">the pie</a>), web developers don't go near features Apple fails to support. Which is a <em>lot</em>.</p>
<figure>
  <picture>
    <img src="https://infrequently.org/2024/01/the-web-is-the-app-store/caniuse_browser_scores.webp" decoding="async" loading="lazy">
  </picture>
  <figcaption>
    caniuse.com's <a href="https://caniuse.com/#:~:text=See%20full%20list-,Browser%20scores,-Current%20version">"Browser Score"</a> is one way to understand the scale of the gap in features that Apple has forced on all iOS browsers.
  </figcaption>
</figure>
<figure>
  <picture>
    <img src="https://infrequently.org/2024/01/the-web-is-the-app-store/wpt_browser_specific_failures.webp" decoding="async" loading="lazy">
  </picture>
  <figcaption>
    The <a href="https://wpt.fyi/">Web Platform Tests dashboard</a> highlights 'Browser Specific Failures', which only measure failures <em>in tests for features the browser claims to support</em>. Not only are iOS browsers held back by Apple's shockingly poor feature support, but the features that _are_ available are broken so often that many businesses feel no option but to retreat to native APIs that Apple doesn't break on a whim, forcing the logic of the app store on them if they want to reach valuable users.
  </figcaption>
</figure>
<p>Apple's pocket veto over the web is no accident, and its abuse of that power is no bug.</p>
<p>Native app stores can only take an outsized cut if the web remains weak and developers stay dependent on proprietary APIs to access commodity capabilities. A prohibition on capable engines prevents feature parity, suppressing competition. A feature-poor, unreliable open web is essential to prevent the dam from breaking.</p>
<p>Why, then, have competing browser makers played along? Why aren't Google, Mozilla, Microsoft, and Opera on the ramparts, waving the flag of engine choice? Why do they silently lend their brands to Apple's campaign against the web? Why don't they rename their iOS browsers to "Chrome Lite" or "Firefox Lite" until genuine choice is possible? Why don't they ask users to write their representatives or sign petitions for effective browser choice? It's not like they shrink from it for <a href="https://blog.mozilla.org/en/mozilla/news/mozilla-joins-net-neutrality-blackout-for-break-the-internet-day/">other worthy causes.</a></p>
<p>I'm shocked by not surprised by the tardiness of browser bosses to seize the initiative. Instead of standing up to unfair terms, they've rolled over time and time again. It makes a perverse sort of sense.</p>
<p>More than 30 years have passed since we last saw <a href="https://en.wikipedia.org/wiki/History_of_Unix#:~:text=In%201983%2C%20the%20U.S.%20Department,System%20V%20into%20the%20market.">effective tech regulation.</a> The careers of those at the top have been forged under the unforgiving terms of late-stage, might-makes-right capitalism, rather than the logic of open markets and standards. Today's bosses didn't rise by sticking their necks above the parapets to argue virtue and principle. At best, they kept the open web dream alive by quietly nurturing the potential of open technology, hoping the situation would change.</p>
<p>Now it has, and yet they cower.</p>
<p>Organisations that value conflict aversion and <em>"the web's lane is desktop"</em> thinking get as much of it as they care to afford. <a href="#fnref-self-censorship-4">↩︎</a></p>
</li>
<li id="fn-mir-icing-5"><p>Recall that Apple <a href="https://www.reuters.com/technology/apple-wins-appeal-against-uks-decision-investigate-its-mobile-browser-2023-03-31/">won an upset victory in March</a> after litigating the meaning of the word "may" and arguing that the CMA wasn't wrong to find after multiple years of investigations that Apple were (to paraphrase) inveterate shitheels, but rather that the CMA waited <em>too long</em> (six months) to bring an action which might have had teeth.</p>
<p>Yes, you're reading that right; Apple's <em>actual</em> argument to the Competition Appeal Tribunal amounted to a mashup of rugged, free-market fundamentalist <em>" but mah regulatory certainty!"</em>, performative fainting into strategically placed couches, and feigned ignorance about issues it knows it'll have to address in other jurisdictions.</p>
<p>Thankfully, the Court of Appeals was not to be taken for fools. Given the <a href="https://caselaw.nationalarchives.gov.uk/ewca/civ/2023/1445#:~:text=In%20my%20judgement%2C%20the%20CAT%20lost%20sight%20of%20this%20consideration.%20There%20is%20no%20overarching%20principle%20that%20an%20undertaking%20is%20entitled%20to%20be%20investigated%20once%2C%20and%20once%20only.">harsh (in British) language</a> of the reversal, we can hope a chastened Competition Appeal Tribunal will roll over less readily in future. <a href="#fnref-mir-icing-5">↩︎</a></p>
</li>
<li id="fn-hair-splitting-6"><p>If you're getting the sense that legalistic hair-splitting is what Apple spends its <a href="https://venturebeat.com/mobile/apples-former-top-lawyer-1-billion-budget-enabled-high-risk-strategies/">billion-dollar-per-year legal budget</a> on because it has neither the facts nor real benefits to society on its side, <a href="http://www.fosspatents.com/2023/02/japans-competition-authority-jftc.html">wait 'till you hear about some of the stuff it filed with Japan's Fair Trade Commission!</a></p>
<p>A clear strategy is being deployed. Apple:</p>
<ul>
<li>First claims there's <a href="https://www.congress.gov/116/meeting/house/110883/witnesses/HHRG-116-JU05-Wstate-CookT-20200729.pdf">no there there (pdf).</a> When that fails...</li>
<li>Claims competitors that it has expressly ham-strung are credible substitutes. When that fails...</li>
<li>Claims security would suffer if reasonable competition were allowed. Rending of garments is performed while prophets of doom recycle the script that the sky will fall if competing browsers are allowed (which would, in turn, expand the web's capabilities). Many treatments of this script fill the inboxes of regulators worldwide. When those bodies investigate, e.g. the history of iOS's forced-web-monoculture insecurity, and inevitably reject these farcical arguments, Apple...</li>
<li>Uses any and every procedural hurdle to prevent intervention in the market it has broken.</li>
</ul>
<p>The modern administrative state indulges firms with <em>"as much due process as money can buy"</em>, and Apple knows it, viciously contesting microscopic points. When bluster fails, <a href="https://infrequently.org/2022/02/minimum-standards/">huffingly implemented, legalistic, hair-splitting "fixes" are deployed</a> on the slowest possible time scale. This strategy buys years of delay, and it's everywhere: browser and mail app defaults, payment alternatives, engine choice, and right-to-repair. Even charging cable standardisation took years longer than it should have thanks to stall tactics. This maximalist, joined-up legal and lobbying strategy works to exhaust regulators and bamboozle legislators. Delay favours the monopolist.</p>
<p>A firm that can <a href="https://www.youtube.com/watch?v=17p3ThgMQYo">transform the economy of an entire nation</a> just by paying a bit of the tax it owes won't even notice a line item for lawyers to argue the most outlandish things at every opportunity. Apple (correctly) calculates that regulators are gun-shy about punishing them for delay tactics, so engagement with process is a is a win by default. Compelling $1600/hr white-shoe associates to make ludicrous, unsupportable claims is a <em>de facto</em> win when delay brings in billions. Regulators are too politically cowed and legally ham-strung to do more, and Apple plays process like a fiddle. <a href="#fnref-hair-splitting-6">↩︎</a></p>
</li>
</ol>
</section>

    
    
  </article>
      <!-- END_BLOCK_CONTENT -->
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Resurrecting the Dillo Browser (546 pts)]]></title>
            <link>https://dillo-browser.github.io/</link>
            <guid>38847613</guid>
            <pubDate>Tue, 02 Jan 2024 21:55:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dillo-browser.github.io/">https://dillo-browser.github.io/</a>, See on <a href="https://news.ycombinator.com/item?id=38847613">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
      
      <p>Dillo is a fast and small graphical web browser with the following features: </p>
      <ul>
        <li>Multi-platform, running on Linux, BSD, MacOS and even Atari.</li>
        <li>Written in C and C++ with few dependencies.</li>
        <li>Implements its own real-time rendering engine.</li>
        <li>Low memory usage and fast rendering, even with large pages.</li>
        <li>Uses the fast and bloat-free <a href="https://www.fltk.org/">FLTK</a> GUI library.</li>
        <li>Support for HTTP, HTTPS, FTP and local files.</li>
        <li>Extensible with plugins written in any language
          (<a href="https://github.com/topics/dillo-plugin">search on GitHub</a>).
        </li>
        <li>Is free software licensed with the GPLv3.</li>
        <li>Helps authors to comply with web standards by using the
          <a href="https://dillo-browser.github.io/old/help/bug_meter.html">bug meter</a> 
          <img src="https://dillo-browser.github.io/img/bugmeter.png">.</li>
      </ul>

      <h2>Screenshots</h2>
      <p><a href="https://dillo-browser.github.io/img/plan9.png"><img src="https://dillo-browser.github.io/img/mini-plan9.png"></a>
      <a href="https://dillo-browser.github.io/img/armadillo.png"><img src="https://dillo-browser.github.io/img/mini-armadillo.png"></a>
      <a href="https://dillo-browser.github.io/img/suckless.png"><img src="https://dillo-browser.github.io/img/mini-suckless.png"></a>
      <a href="https://dillo-browser.github.io/img/aaronsw.png"><img src="https://dillo-browser.github.io/img/mini-aaronsw.png"></a>
      <a href="https://dillo-browser.github.io/img/hackernews.png"><img src="https://dillo-browser.github.io/img/mini-hackernews.png"></a>
      <a href="https://dillo-browser.github.io/img/100r.png"><img src="https://dillo-browser.github.io/img/mini-100r.png"></a></p><p>...check <a href="https://dillo-browser.github.io/old/screenshots/index.html">the archives</a> for more pictures.</p>
      <h2>Project objectives</h2>
      <ul>
        <li>Lower the barrier of entry to the web.</li>
        <li>Support old or small machines and slow connections.</li>
        <li>Personal security and privacy.</li>
        <li>High software efficiency.</li>
      </ul>
      <p>
      Check the <a href="https://dillo-browser.github.io/old/index.html">old website</a> for more details.
      </p>
      <h2>Download</h2>
      <p>Download Dillo from the
      <a href="https://github.com/dillo-browser/dillo/">git repository</a>
      and follow the instructions in the README to install it.
      </p>
      <h2>Contributing</h2>
      <p>We always welcome contributions, here are several ways in which
      you can help:</p>
      <ul>
        <li>Use Dillo to browse the web and if you find something that
          is not working,
          <a href="https://github.com/dillo-browser/dillo/issues/new">report it</a>.
        </li>
        <li>Spread the word, so the world knows Dillo exists and is
          still alive.</li>
        <li>Implement some new feature or fix some bug and send us a
          patch or create a pull request.</li>
      </ul>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[CGA in 1024 colors – a new mode (2015) (117 pts)]]></title>
            <link>https://int10h.org/blog/2015/04/cga-in-1024-colors-new-mode-illustrated/</link>
            <guid>38845951</guid>
            <pubDate>Tue, 02 Jan 2024 19:34:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://int10h.org/blog/2015/04/cga-in-1024-colors-new-mode-illustrated/">https://int10h.org/blog/2015/04/cga-in-1024-colors-new-mode-illustrated/</a>, See on <a href="https://news.ycombinator.com/item?id=38845951">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
		
		<div>
			
			

<p><span>
Part <strong><em>#1</em></strong> of the 8088 MPH writeup series • continued in <a href="https://int10h.org/blog/2015/08/8088-mph-final-old-vs-new-cga-gory-details/" target="_blank">8088 MPH Final: Old vs. New CGA (and Other Gory Details)</a>
</span></p>

<p>By now you may have heard of the <a href="http://www.pouet.net/prod.php?which=65371" target="_blank">8088 MPH
demo</a>, the winning entry in
<a href="http://2015.revision-party.net/" target="_blank">Revision 2015</a>'s Oldskool Demo compo
this month.&nbsp; It's been my pleasure to combine efforts with the likes of
<a href="http://trixter.oldskool.org/" target="_blank">Trixter</a>,
<a href="http://www.reenigne.org/blog/" target="_blank">reenigne</a> and
<a href="https://scalibq.wordpress.com/" target="_blank">Scali</a> to make it happen - not only did
I get the opportunity to work alongside a bunch of extremely talented
wizards of code, we also achieved what we set out to do: break some
world records on the venerable (and yet much-maligned!) IBM PC, the
mommy and daddy of the x86 platform as we still know it today.</p>

<p>One of our "hey, this hardware shouldn't be doing that!"-moments was
extending the CGA's color palette by a cool order of magnitude or two.&nbsp;
How'd we pull that off? - reenigne has already posted an <a href="http://www.reenigne.org/blog/1k-colours-on-cga-how-its-done/" target="_blank">excellent
technical
article</a>
answering that very question.&nbsp; To complement his writeup, I'll take a
bit of a different approach – here's my 'pictorial' take on how we
arrived at this:</p>

<figure>
    
    
        <img src="https://int10h.org/blog/img/1k01_graffiti1k2.png" alt="8088 MPH 1K color CGA graffiti">
    
    
    <figcaption>
        <p>
        Old dog, posing with new tricks. (Not pictured: blood, sweat, tears.).
        
            
        
        </p> 
    </figcaption>
    
</figure>


<p>The idea that such multi-color trickery was possible came to me some
time ago, as I was looking at reenigne's code for patching up composite
CGA emulation in <a href="http://www.dosbox.com/" target="_blank">DOSBox</a>; messing with that
patch during development gave me a much better picture of composite
CGA's inner workings.&nbsp; When I had ironed out the basic concept for this
hack, I divulged it to reenigne for 'peer review' and for testing on
real hardware.&nbsp; Soon enough, we had an improved recipe:</p>

<ul>
<li>Take two familiar (though officially undocumented) tweaks. Blend to
an even mixture producing a new effect.</li>
<li>Add one crucial new trick – an ingredient of reenigne's devising.</li>
<li>Test and calibrate until blue in the face.
</li>
</ul>

<p>Below is my rundown of how it all fits together.&nbsp; Fair warning: the
'target audience' for this writeup is people who may not be overly
familiar with CGA, and/or come from other demo platforms.&nbsp; As such,
there's a whole bunch of background that's already well-known in
CGA-land.&nbsp; To prevent acute boredom, I decided to stick this TOC here –
feel free to skip to the interesting part(s):</p>

<div>
    <div>
        <ol>
            <li><a href="#16_colors_rgbi">Old Trick #1: 16-color graphics over RGBI</a></li>
            <ol>
                <li><a href="#low_resolution_mode">Low-resolution mode</a></li>
                <li><a href="#the_macrocom_method">The Macrocom Method</a></li>
            </ol>
            <li><a href="#16_colors_composite">Old Trick #2: 16-color graphics over composite</a></li>
            <ol>
                <li><a href="#direct_colors">Direct colors</a></li>
                <li><a href="#artifact_colors">Artifact colors</a></li>
                <li><a href="#solid_artifact_colors">Solid artifact colors</a></li>
            </ol>
            <li><a href="#256_colors">256 colors</a></li>
            <li><a href="#512_colors">512 colors</a></li>
            <li><a href="#1024_colors">1024 colors</a></li>
        </ol>
    </div>
    
    <p><span>Because, much like a broken clock, even Wikipedia gets it right sometimes</span>
</p></div>
&nbsp;  

  

<h2 id="a-id-16-colors-rgbi-a-old-trick-1-16-color-graphics-over-rgbi"><a id="16_colors_rgbi"></a> Old Trick #1: 16-color graphics over RGBI</h2>

<p>A short crash course on CGA basics: the first graphics standard
available on PCs supports a 16KB memory buffer, and is driven by an
MC6845 CRTC (some later cards used alternatives).&nbsp; Video output options
are composite NTSC through a standard RCA jack, and the more widely-used
DE9 connector, which outputs an RGBI signal (red, green, blue and
intensity).&nbsp; The latter is what most people think of when they hear
"CGA"; this is a <em>digital (TTL)</em> signal, where each component can be
either on or off, hence 16 different colors.&nbsp; Despite what arcade
hardware buffs would like you to think, CGA – in the strict sense – is
NOT analog RGB, and never was.</p>

<p>Standard (BIOS-supported) graphics modes are high-resolution (640x200)
in 2 colors, and medium-resolution (320x200) in 4 colors.&nbsp; Not a lot of
wiggle room here: in hi-res mode, only one of the colors (foreground) is
redefinable – the background is always black; in medium-res, it's the
background color that's adjustable, while the other 3 are determined by
the infamously nasty <a href="http://en.wikipedia.org/wiki/Color_Graphics_Adapter#Standard_graphics_modes" target="_blank">fixed
palettes</a>.</p>

<p>Infuriatingly, in an almost-trollish move, IBM
<a href="https://archive.org/stream/bitsavers_ibmpccardsptionsandAdaptersVolume2Apr84_25079400/Technical_Reference_Options_and_Adapters_Volume_2_Apr84#page/n49/mode/2up/search/%22low-resolution+color+graphics+mode%22" target="_blank">mentioned</a>
an additional low-resolution 16-color mode - "not supported in ROM" -
with zero information on how to actually achieve it.&nbsp; That nut was
cracked pretty early on, though.</p>

<h3 id="a-id-low-resolution-mode-a-low-resolution-mode"><a id="low_resolution_mode"></a> Low-resolution mode</h3>

<p>This is no graphics mode at all, but a modified 80-column <a href="http://www.techhelpmanual.com/89-video_memory_layouts.html" target="_blank">text
mode</a>.
Basically, you adjust CRTC registers to get 100 rows of text instead of
the usual 25; this gives you a character box of 8x2 pixels, a quarter of
the normal 8x8.&nbsp; Filling the screen with one "magic" ASCII character,
0xDE, effectively splits each character cell into left and right
"pixels", corresponding to the background and foreground colors.&nbsp; These
two colors can be individually set to any of the 16 CGA values, as in
any CGA text mode, as long as you remember to turn off blinking.</p>

<figure>
    
    
        <img src="https://int10h.org/blog/img/1k02_16c_low-resolution_cga_160x100.png" alt="CGA low resolution mode">
    
    
    <figcaption>
        <p>
        CGA low resolution mode
        
            
        
        </p> 
    </figcaption>
    
</figure>


<p>So there you have it; 160x100 @ 16c.&nbsp; This mode was used in games <a href="http://www.mobygames.com/game/pc-booter/moon-bugs/screenshots" target="_blank">as
early as
1983</a>,
but never got wildly popular - probably because of the
"<a href="http://en.wikipedia.org/wiki/Color_Graphics_Adapter#Limitations.2C_bugs_and_errata" target="_blank">snow</a>"
that plagues IBM CGA cards in 80-column mode, unless you burn some
costly CPU time to avoid it.</p>

<h3 id="a-id-the-macrocom-method-a-the-macrocom-method"><a id="the_macrocom_method"></a> The Macrocom Method</h3>

<p>You may ask: since this is text mode, what's stopping you from using the
<em>entire</em> ASCII character set? Other than a healthy respect for your own
sanity, nothing really!&nbsp; This was first attempted around the mid-'80s by
a few brave souls at
<a href="http://www.mobygames.com/featured_article/feature,10/" target="_blank">Macrocom</a>, who
combined the 100-rows trick with ASCII art, to create what Trixter once
succinctly called "ANSI from hell".</p>

<figure>
    
    
        <img src="https://int10h.org/blog/img/1k03_16c_cga_ansi_from_hell.png" alt="CGA ANSI from Hell">
    
    
</figure>

&nbsp;

<p>As you can see above, I've experimented with this a little.&nbsp; With
judicious use of the character set, you can <em>almost</em> fool somebody into
thinking that this is a 640x200 mode - although there's some inevitable
"attribute clash", a little like the <a href="http://www.retroyak.com/clash-of-the-bright-dims/" target="_blank">ZX
Spectrum</a>: each 8x2
character cell can contain only two colors, foreground and background.
Also, you have to be a bit of a glutton for punishment to actually draw
in this mode from scratch... but that's a subject for a future post.</p>

<p>This trick isn't directly relevant to our demo: we were targeting
composite displays. Even if CGA's composite output didn't have its share
of bugs and quirks in 80-column mode – <a href="http://www.reenigne.org/blog/cga-why-the-80-column-text-mode-requires-the-border-color-to-be-set/" target="_blank">which it
does</a>
– there'd be no way to see this level of detail over NTSC.&nbsp; There's a
reason I mention this effect, however; the idea behind it does figure
into the story.&nbsp; But more on that later.<br>
&nbsp;</p>

<h2 id="a-id-16-colors-composite-a-old-trick-2-16-color-graphics-over-composite"><a id="16_colors_composite"></a> Old Trick #2: 16-color graphics over composite</h2>

<p>Digital RGB monitors were still a luxury item at the time of CGA's
introduction, and IBM itself didn't offer one until a couple of years
later, coinciding with the release of the PC/XT.&nbsp; But CGA also provided
composite output, giving out (mostly) NTSC-compatible video. At the
expense of resolution, there's more fun to be had here with color.</p>

<h3 id="a-id-direct-colors-a-direct-colors"><a id="direct_colors"></a> Direct colors</h3>

<figure>
    
    
        <img src="https://int10h.org/blog/img/1k04_cga_composite_direct_colors.png#floatleft" alt="Composite CGA, 16 direct colors">
    
    
</figure>


<p>On the composite output, the familiar 16-color CGA palette is
represented by a series of color signals, whose hue is determined by
their <strong>phase</strong> relative to a reference signal (the NTSC <em>color
burst</em>).&nbsp; The <strong>frequency</strong> of the NTSC color clock (3.579545 MHz) works
out to exactly <strong>160</strong> color cycles per active CGA scanline.</p>

<p>These are directly generated by CGA hardware as color signals, so we'll
conveniently call them "direct colors".&nbsp; IBM had <a href="http://www.reenigne.org/blog/comparison-of-cga-card-versions/" target="_blank">two main
revisions</a>
of the CGA, which produce composite video somewhat differently:
'new-style' cards contain additional circuitry, which helps the palette
match its RGBI counterpart a little more closely.&nbsp; For the demo, we
standardized on 'old-style' cards, simply because we happened to have
done more testing on those (with somwhat better results), so all images
in this post will reflect 'old-style' CGA colors.</p>

<p>If these 16 <em>direct</em> colors were all we had, it wouldn't be a whole lot
of fun, would it?&nbsp; They're also shockingly ugly, esepcially on an
old-style CGA, which doesn’t help matters either.&nbsp; Just look at that
palette... gross, dude.&nbsp; Luckily, there's a way to go one better.</p>

<h3 id="a-id-artifact-colors-a-artifact-colors"><a id="artifact_colors"></a> Artifact colors</h3>

<p>Due to bandwidth restrictions, NTSC video doesn't fully separate
chrominance (color) from luminance.&nbsp; Effectively, any high-resolution
detail – that is, detail with higher frequency than the NTSC color clock
– gets 'smeared' when the signal is decoded. This is responsible for the
characteristic color bleed, seen in the form of fetching little fringes
at the edges of text characters and other fine detail.</p>

<p>Remember how you get 160 color cycles per active CGA scanline? Standard
CGA gives us either <strong>320</strong> or <strong>640</strong> active pixels per scanline,
depending on the video mode.&nbsp; Ergo, we can switch pixels on and off at
<strong>2x</strong> or <strong>4x</strong> the frequency of the color carrier.&nbsp; Since this
high-frequency detail cannot be fully separated from color information,
the upshot is this:</p>

<div>
     <p><strong><em>The hue of a pixel, or a fringe (transition between pixels), depends on its position within the color-cycle period.</em></strong>
     </p>
</div>
&nbsp;  

  

<figure>
    
    
        <img src="https://int10h.org/blog/img/1k05_ntsc_color_wheel.png#floatleft" alt="NTSC color wheel">
    
    
</figure>


<p>This NTSC color cycle is sometimes represented as a wheel: one complete
period of this cycle equals a 360° revolution around the color wheel,
and we have 160 complete revolutions per scanline.</p>

<p>Let's say we're in hi-res (640x200) mode, where 4 pixels fit into one
such color cycle: moving one pixel left or right translates to moving
90° along the wheel, in either direction, and accordingly shifts the hue
by 90°.&nbsp; Likewise, in 320x200 mode, we move in 180° increments of
hue-shift.</p>

<p>In short, manipulating detail at high resolutions is
effectively a method of generating color; being an artifact of NTSC's
imperfections, this is known as <em>artifact</em> color.</p>

<figure>
    
    
        <img src="https://int10h.org/blog/img/1k06_cga_composite_fringing_artifacts.png" alt="CGA composite output: fringing and artifact colors">
    
    
</figure><p>

­</p>

<p>Various filters can be (and often are) employed on the receiving end to
recover some of the high-frequency detail, reducing color bleed and
making edge transitions somewhat sharper.&nbsp; We're still dealing with
technology, not magic, so full separation of detail and color can never
quite be achieved, and the trade-off is a whole new set of artifacts (in
the form of "echoing" or "ringing").&nbsp; This trade-off may or may not be
acceptable, depending on what you're doing, but the above image doesn't
attempt to reproduce any such filtering.</p>

<h3 id="a-id-solid-artifact-colors-a-solid-artifact-colors"><a id="solid_artifact_colors"></a> Solid artifact colors</h3>

<p>All this business of "fringing" and "bleeding" sure sounds like a
bummer, and that's exactly what it is: the unwanted side-effect of a
less-than-ideal encoding scheme.&nbsp; But like any good flaw, it can be
turned into an advantage by an enterprising soul, and this is where we
get to the fun part (your mileage may vary).</p>

<p>When you look at the interplay of color vs. detail over NTSC, a very
handy fact becomes apparent:</p>

<div>
     <p><strong><em>Any periodic composite signal, with the same frequency as the color carrier (160 per line), will be decoded as a solid, continuous color.</em></strong>
     </p>
</div>
&nbsp;  

  

<p>Our 16 <em>direct</em> colors are exactly this type of periodic composite
signal.&nbsp; But hold on – with some simple high-resolution pixel-pushing,
we can manually put together our own periodic waveforms!&nbsp; Any pattern of
dots will do, as long as it repeats at the right frequency.&nbsp; This lets
us achieve solid colors that lie <em>outside</em> the direct color palette.</p>

<figure>
    
    
        <img src="https://int10h.org/blog/img/1k07_cga_composite_solid_colors_1.png#floatleft" alt="CGA solid artifact colors 1">
    
    
</figure>


<p>The "classic" way of doing this on CGA is to set up BIOS mode 6 –
640x200 in 2 colors, white on black – and set the color-burst bit (which
is off by default, for a B&amp;W picture).&nbsp; At this resolution we can
squeeze 4 pixels into a color clock period, and at 1 bit per pixel,
there are 16 possible patterns – giving us 16 solid artifact colors.</p>

<p>This is pretty much the same
<a href="http://laboratorium.net/archive/2009/03/08/why_did_the_applie_ii_have_six_colors" target="_blank">technique</a>
used by Steve Wozniak to generate color on the Apple ][.&nbsp; In fact, on
an old-style CGA card, these 16 colors are <em>identical</em> to the 16 low-res
Apple colors (although you couldn't get them on a poster, like Apple
owners
<a href="http://beagle.applearchives.com/the_posters/poster_1.html" target="_blank">could</a>).&nbsp;
More to the point: the pixels themselves are white, which carries no
color information; it's the detail that does the deed.</p>

<p>*But wait, there's more!*&nbsp; Despite popular wisdom, CGA lets us one-up
the Apple, and then some.&nbsp; OUR underlying pixels don't have to be white:
in 640x200 mode, we can play with the palette register and set any of
the 16 <em>direct</em> colors as the foreground (background is always black).&nbsp;
By using the same pixel patterns with a different foreground color, we
get 16 <em>entirely new</em> sets of artifact colors, with 16 colors each.&nbsp; We
can only use one such set at a time, but we get to pick and choose what
our 16 colors are.</p>

<p>Then there's 320x200 mode, which supports a palette of 4 direct colors.&nbsp;
Only one of those, color #0 (background), is freely selectable.&nbsp; For
the rest, intensity may be on or off, but we can only use
green/red/yellow or cyan/magneta/white; the undocumented cyan/red/white
palette involves disabling the color burst, making the composite picture
greyscale.</p>

<p>Since our pixels are twice as fat in this mode, only two of them can
squeeze into a color-clock cycle – but at 2 bits per pixel, the total
count of artifact colors is still 16.&nbsp; The possible combinations of
palette, plus the user-defined background color, provide us with a whole
slew of other 16-color sets.</p>

<figure>
    
    
        <img src="https://int10h.org/blog/img/1k08_cga_composite_solid_colors_2.png" alt="CGA solid artifact colors 2">
    
    
</figure><p>

­</p>

<p>This may be a good place to correct a bit of a misconception.&nbsp; Since we
have 160 color cycles per scanline, many people treat CGA's graphics
modes over composite as 160x200 "modes", but that's not quite accurate.&nbsp;
Our <em>effective color resolution</em> is indeed 160x200, and it's impossible
to get finer detail than that using solid artifact colors.&nbsp; But as we've
seen, on NTSC the pixel grid and color grid are NOT one and the same –
which makes the question of horizontal resolution a bit fuzzy, depending
on how you're sampling and/or filtering the signal.&nbsp; It even varies with
the specific color waveforms you're using.</p>

<p>IBM itself never documented any of these artifact color tricks, other
than one oblique reference to "<a href="https://archive.org/stream/IbmPcjrTechnicalReference#page/n331/mode/2up/search/%22color+mixing+techniques%22" target="_blank">color mixing
techniques</a>"
in the PCjr tech ref (if I'm wrong about this, drop me a line and link
me!).&nbsp; The concept is fairly old hat, however – it was used in games
very early on; some of the first ones I can think of were Microsoft's
<a href="http://www.mobygames.com/game/pc-booter/microsoft-decathlon/screenshots" target="_blank">Decathlon</a>
and <a href="http://www.mobygames.com/game/pc-booter/microsoft-flight-simulator-v10/screenshots" target="_blank">Flight
Simulator</a>,
both in 1982.&nbsp; And the limitation has always been the same: the maximum
simultaneous color count you can get over composite CGA is 16.</p>

<p>....Or is it?&nbsp; On the off chance that you've been following me so far, and
you're still reading, you may have an idea of what the next step is.</p>

<h2 id="a-id-256-colors-a-256-colors"><a id="256_colors"></a> 256 colors</h2>

<p>We've already observed that our choice of 16 artifact colors depends on
the palette and color register settings.&nbsp; One fairly obvious strategy
seems to suggest itself here – change those registers at particular
scanlines on every frame, and get &gt;16 colors on screen that way.&nbsp;
Right?</p>

<p><a href="https://int10h.org/blog/img/1k09_reenigne_chart1a00.png" target="_blank"><img src="https://int10h.org/blog/img/1k09_reenigne_chart1a00.png" title="CGA 256 colors chart.com" alt="CGA 256 colors chart.com" width="123" height="92"></a></p>

<p>This has been done before on CGA, and you <em>can</em> actually exploit this
for 256 colors (as proven by reenigne - see the image to the left), but
that's <strong>not</strong> how we did our multi-color hacking in the demo.&nbsp; We were
actually toying with the idea of including a static screen that uses
this technique, but I didn't have the time to pursue this; if anyone
manages to compose some nice artwork using this method, I'd love to see
it – that's gotta be a bit of an artistic challenge.&nbsp; But no, the way we
wrangled more color out of CGA is a whole other shenanigan... which I came
across by equal parts chance and morbid curiosity.</p>

<p>Recall how any color/dot pattern of the right length (four repeating
pixels in 640x200, or two in 320x200) produces a solid color on a
composite display?&nbsp; Back when I was testing composite emulation for
DOSBox, that fact was fresh in my mind.&nbsp; At around the same time, I was
experimenting with the "ANSI from Hell" graphical hack detailed
<a href="#the_macrocom_method">above</a>;
that's purely a text mode / RGBI trick, but it requires a close
familiarity with the ROM character set... closer than most sane people
would want or need.</p>

<p>Let's take another look at a particular section of the CGA ROM font, in
80-column mode, with the top 2 scanlines highlighted:</p>

<figure>
    
    
        <img src="https://int10h.org/blog/img/1k10_cga_charset_subset.png" alt="CGA ROM font subset">
    
    
</figure><p>

­</p>

<p>At this point, if you're a visually-oriented person, and if you've been
following my drift, you're probably catching on.&nbsp; Don't see it yet?
Here's a fatter clue:</p>

<figure>
    
    
        <img src="https://int10h.org/blog/img/1k11_ascii_0x55.png" alt="ASCII char 0x55">
    
    
</figure><p>

­</p>

<p>See those top 25% of the character bitmap?&nbsp; Two dots of foreground and
two dots of background, doubled horizontally across.&nbsp; We're in
hi-res/80-column mode, so there are two color cycles per character...
corresponding exactly to those two matching halves.&nbsp; And those top two
scanlines are identical.</p>

<p>That's just the type of repeating pattern that gets us a solid artifact
color over NTSC.&nbsp; In fact, it's the very same waveform that 320x200 mode
lets us play with.&nbsp; Except that now we have it available in <em>text mode</em>:
you know, where we can freely assign a foreground AND a background to
each character, from the 16 direct colors.</p>

<p>That's 256 possibilities right there... this is the part that made me go
<em>"I have a cunning plan"</em>, in my best imitation of Blackadder's
<a href="https://int10h.org/blog/img/baldrick.jpg" target="_blank">Baldrick</a>
(just not out loud).&nbsp; Indeed, it's possible to achieve &gt;16 colors on
CGA without any flickering, dithering, interlacing or per-scanline
effects.</p>

<p>Here's what the possible combinations work out to:</p>

<figure>
    
    
        <img src="https://int10h.org/blog/img/1k12_cga_artifact_colors_ascii_0x55.png" alt="CGA artifacts - ASCII char 0x55">
    
    
</figure>

&nbsp;

<h2 id="a-id-512-colors-a-512-colors"><a id="512_colors"></a> 512 colors</h2>

<p>Oh, we're not done yet: once that lightbulb went off over my head, I had
another look at the CGA ROM font to see if any other useful bit
sequences emerge.&nbsp; There are a few character bitmaps that give us the
exact same waveform as 'U' does – 'H', 'V', 'Y' and '¥' – but only one
with a <em>different</em> suitable bit sequence right where we need it: 0x13,
the double exclamation mark ('‼').</p>

<p>The top two scanlines of 'U' give us a bitmask of 11001100 for
foreground/background; '‼' is 01100110 – a single shift to the right, or
a 90° shift in phase.&nbsp; This perfectly complements 'U' in terms of having
a well-rounded palette, because we get all the colors that the "...1100..."
waveform has to offer: going from 'U' to '‼' shifts the phase by 90°
(0110); 180° and 270° are achieved by flipping the foreground and
background colors for 'U' and '‼' respectively – the same as going
'0011' and '1001'.</p>

<figure>
    
    
        <img src="https://int10h.org/blog/img/1k13_cga_artifact_colors_ascii_0x13.png" alt="CGA artifacts - ASCII char 0x13">
    
    
</figure><p>

­</p>

<p>Okay, we've pushed the envelope even further: 512 simultaneous colors!&nbsp;
Granted, the real number is lower, because a good few are duplicates
(and others are very close).&nbsp; But 512 seems to be the limit for this
technique: no other characters in our font fit the bill for solid
colors.&nbsp; The CGA character ROM does have an <a href="http://www.seasip.info/VintagePC/cga.html" target="_blank">alternate 'thin' 8x8
font</a>; but, besides the fact
that you'd have to mod your card if you wanted to use it, the 'thin'
font has none of the magic bit patterns in the right places, which makes
it useless for our purposes.</p>

<p>My kingdom for redefinable characters... alas, when you're dealing with
old PC hardware, IBM's penchant for cost-cutting over innovation can
<em>always</em> sneak up from behind and ruin your day – even in the most
unusual of places.</p>

<p>Still, I was pleased with my little discovery: extending the palette by
a factor of <strong>32</strong> has to count for something, right?&nbsp; At this point, I
shared my ideas with reenigne.&nbsp; Little did I know that he'll promptly
come up with a new devious scheme to double our color count yet
again...</p>



<p>This part is some next-level CRTC black magic which I could never have
figured out by myself – I'm just a graphics guy; you might as well ask
me to wait for a full moon and chant the MC6845 spec-sheet backwards in
hexadecimal.&nbsp; All credit goes to reenigne for this particular bit of mad
science, which, despite its complex execution, stems from a wonderfully
simple idea: our fixed character bitmaps don't play nice with what we're
trying to do? No problem – we'll <em>make</em> them play nice, or else.</p>

<figure>
    
    
        <img src="https://int10h.org/blog/img/1k14_ascii_0xb0_0xb1.png#floatleft" alt="ASCII chars 0xb0, 0xb1">
    
    
</figure>


<p>See, there are two additional characters whose very <em>first</em> scanline
could be used; problem is, the second scanline is different, which would
ruin our solid color effect.&nbsp; These are ASCII codes 0xB0 and 0xB1, the
'shaded block' characters. It would be quite convenient if we could just
tell that offending second scanline to buzz off, wouldn't it? As it
turns out, we can.</p>

<p>The lowdown on how this is done is all in reenigne's writeup, which is
linked to at the top of this post.&nbsp; But this is the basic idea: by
starting a new CRTC frame <em>every other scanline</em> and twiddling with the
start address, it's possible to lay down our character rows so that the
first scanline of each gets duplicated twice!</p>

<p>Now we can make use of those two extra characters, and doing so gets us
two more 256-color sets:</p>

<figure>
    
    
        <img src="https://int10h.org/blog/img/1k15_cga_artifact_colors_ascii_0xb0_0xb1.png" alt="CGA artifacts - ASCII chars 0xb0, 0xb1">
    
    
</figure><p>

­</p>

<p>Naturally, there are downsides: having to mess with the CRTC every
couple of scanlines is quite taxing for the poor 4.77MHz 8088, so
there's not much you can do with this other than static pictures.&nbsp; The
512-color variant, using only ASCII 0x55 and 0x13, doesn't suffer from
this – it's basically "set and forget", requiring no more CPU
intervention than any 80-column text mode (the familiar overhead of
avoiding snow).</p>

<p>Then, there's that other problem which plagues 80-column CGA on
composite displays... the hardware bug that leads to bad hsync timing and
missing color burst.&nbsp; There are ways to compensate for that, but none
that reliably works with <em>every</em> monitor and capture device out there.&nbsp;
This proved to be an enduring headache in calibrating, determining the
actual colors, and obtaining a passable video capture of the entire
demo... but that's all covered elsewhere.</p>

<p>At any rate, we now have 1K colors on a 1981 IBM CGA, at an effective
resolution of 80x100 'chunky pixels'.&nbsp; 'Chunky' describes the memory
layout, but it also applies in the visual sense: we're really plumbing
the depths of resolution here.&nbsp; 160x100,&nbsp; that's as low as you could go?
allow me to snicker, IBM - "low-res" just got <em>lower</em>, baby!</p>

<p>One might object that this isn't a lot of canvas.&nbsp; Yeah, yeah: 80x100 is
a bit on the cramped side, 'artistically' speaking; but the limitation
is part of the challenge, as it has always been in demos.&nbsp; You can keep
your fancy 4K monitors - 0.008 megapixels should be enough for
anybody.</p>

<figure>
    
    
        <img src="https://int10h.org/blog/img/1k16_flowergirl_cga_1024_colors.png" alt="CGA flowergirl 1k colors">
    
    
</figure><p>

­</p>

<p>When we first showed Trixter the 'proof-of-concept' 1024c drawings, his
response was, and I quote: "HOLY F!@#$%G SHIT. WOW. I must know how
this works!!".&nbsp;&nbsp; Achievement unlocked: getting THAT out of a veteran
8088/CGA hacker and demomaker is, by itself, almost as good as... well,
joining the team, 'making a demo about it' and winning the oldskool
compo. :)</p>

<p>That's about it for my writeup.&nbsp; If you made it this far,
congratulations!&nbsp; There's more I could write about the tools and
techniques I used to actually compose these graphics... but we'll get to
that some other time.</p>

<p><br><span>
Continued in part 2: <a href="https://int10h.org/blog/2015/08/8088-mph-final-old-vs-new-cga-gory-details/" target="_blank">8088 MPH Final: Old vs. New CGA (and Other Gory Details)</a>
</span></p>

		</div>
		

	</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[LLM spews nonsense in CVE report for curl (301 pts)]]></title>
            <link>https://hackerone.com/reports/2298307</link>
            <guid>38845878</guid>
            <pubDate>Tue, 02 Jan 2024 19:28:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hackerone.com/reports/2298307">https://hackerone.com/reports/2298307</a>, See on <a href="https://news.ycombinator.com/item?id=38845878">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Better Seater – Wedding seating chart optimizer (122 pts)]]></title>
            <link>https://seater.steam-oven.net/</link>
            <guid>38845650</guid>
            <pubDate>Tue, 02 Jan 2024 19:10:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://seater.steam-oven.net/">https://seater.steam-oven.net/</a>, See on <a href="https://news.ycombinator.com/item?id=38845650">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[1D Pac-Man (1641 pts)]]></title>
            <link>https://abagames.github.io/crisp-game-lib-11-games/?pakupaku</link>
            <guid>38845510</guid>
            <pubDate>Tue, 02 Jan 2024 19:00:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://abagames.github.io/crisp-game-lib-11-games/?pakupaku">https://abagames.github.io/crisp-game-lib-11-games/?pakupaku</a>, See on <a href="https://news.ycombinator.com/item?id=38845510">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[First do it, then do it right, then do it better (182 pts)]]></title>
            <link>https://twitter.com/addyosmani/status/1739052802314539371</link>
            <guid>38845461</guid>
            <pubDate>Tue, 02 Jan 2024 18:57:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/addyosmani/status/1739052802314539371">https://twitter.com/addyosmani/status/1739052802314539371</a>, See on <a href="https://news.ycombinator.com/item?id=38845461">Hacker News</a></p>
Couldn't get https://twitter.com/addyosmani/status/1739052802314539371: Error: Request failed with status code 400]]></description>
        </item>
        <item>
            <title><![CDATA[90x Faster Than Pgvector – Lantern's HNSW Index Creation Time (104 pts)]]></title>
            <link>https://lantern.dev/blog/hnsw-index-creation</link>
            <guid>38844945</guid>
            <pubDate>Tue, 02 Jan 2024 18:21:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lantern.dev/blog/hnsw-index-creation">https://lantern.dev/blog/hnsw-index-creation</a>, See on <a href="https://news.ycombinator.com/item?id=38844945">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><a href="https://github.com/lanterndata/lantern">Lantern</a> is a Postgres extension to enable performant vector search using an index. Lantern is built using <a href="https://github.com/unum-cloud/usearch/">Usearch</a>, an optimized C++ implementation of the <a href="https://arxiv.org/abs/1603.09320">HNSW algorithm</a>, the most performant algorithm for vector search.</p>
<p>In this post we discuss the significance of index creation times and how Lantern enables 90x faster index creation times than <a href="https://github.com/pgvector/pgvector">pgvector</a>, another popular vector search Postgres extension, using external indexing. We also compare Lantern's performance against <a href="https://pinecone.io/">Pinecone</a>, a popular, closed-source hosted vector database.</p>
<h2 id="h2--316512533" level="2" siblingcount="51">Why fast index creation matters</h2>
<p>Index creation time affects how quickly a developer can add vector search to their data. On a single core, generating an index on 1 billion vectors could take days or even weeks.</p>
<p>It also affects how quickly a developer can experiment with different parameters to optimize their index. HNSW relies on two parameters for index construction:</p>
<ul>
<li>The <code>M</code> parameter controls the number of neighbors that each node in the graph will maintain. Higher values lead to longer construction times, longer query times, and higher memory usage, but result in a higher-quality index.</li>
<li>The <code>ef_construction</code> parameter determines how many nodes will be traversed during index construction. Higher values lead to longer construction times but result in a higher-quality index.</li>
</ul>
<p>Generally, there is a tradeoff between recall and latency. The ideal set of parameters requires experimentation to find. It depends on the application's recall / latency needs and the data itself (what recall is possible given the data distribution). This experimentation could become untenable with slow index creation times.</p>
<h2 id="h2-130942622" level="2" siblingcount="51">How external index creation enables parallelism</h2>
<p>With Postgres, HNSW index creation is single-threaded. This prevents the utilization of multiple cores to speed up index creation. In addition, the index creation process is resource-intensive, which can slow down other database operations. The latter would pose a problem even if HNSW index creation were multi-threaded.</p>
<p>Lantern allows developers to create an index externally, and then import the index as a file into their database. With external index creation, the core database remains unburdened during index creation, and the index can be created using multiple cores. This enables significant performance improvements.</p>
<p>Below we show the results of two sets of experiments with Lantern: one with index creation occurring inside Postgres, and one with index creation occurring externally. We compare Lantern's performance against pgvector and Pinecone.</p>
<h2 id="h2-11442535" level="2" siblingcount="51">Lantern's single-core index creation performance</h2>
<h3 id="h3--1383936870" level="3" index="12" siblingcount="51">Experiment Setup</h3>
<p>We use the following datasets</p>
<ul>
<li><a href="http://corpus-texmex.irisa.fr/">sift</a> - 1 million vectors of 128 dimensions, downloadable <a href="https://storage.googleapis.com/lanterndata/datasets/sift_base1m.csv">here</a></li>
<li><a href="https://huggingface.co/datasets/KShivendu/dbpedia-entities-openai-1M">wiki</a> - 1 million vectors of 1536 dimensions generated using the <code>text-embedding-ada-002</code> model</li>
</ul>
<p>The experiments were run on a Linode instance with 32 Cores and 64GB of RAM.</p>
<p>The SQL to create a table, copy the data, and create the index using Lantern follows</p>
<div><pre tabindex="0"><code><span><span>CREATE</span><span> TABLE</span><span> wiki1m</span><span> (id </span><span>SERIAL</span><span>, v </span><span>REAL</span><span>[]);</span></span>
<span><span>COPY</span><span> wiki1m (v) </span><span>FROM</span><span> '/tmp/wiki1m.csv'</span><span> WITH</span><span> CSV;</span></span>
<span><span>CREATE</span><span> INDEX</span><span> ON</span><span> wiki1m </span><span>USING</span><span> hnsw (v) </span><span>WITH</span><span> (dim</span><span>=</span><span>128</span><span>, m</span><span>=</span><span>8</span><span>, ef_construction</span><span>=</span><span>128</span><span>, ef</span><span>=</span><span>128</span><span>);</span></span>
<span></span></code></pre></div>
<h3 id="h3-1395271028" level="3" index="18" siblingcount="51">Table: Index Creation Times for Sift</h3>
<table><thead><tr><th><p>Vector Database</p></th><th><p>Time</p></th><th><p>Vec/s</p></th></tr></thead><tbody><tr><td><p>Lantern</p></td><td><p>8m 30s</p></td><td><p>~1960 vec/s</p></td></tr><tr><td><p>Pinecone (p2x2 - 1 pod)</p></td><td><p>9m</p></td><td><p>~1818 vec/s</p></td></tr><tr><td><p>Pgvector</p></td><td><p>46m</p></td><td><p>~361 vec/s</p></td></tr></tbody></table>
<h3 id="h3-1395390336" level="3" index="20" siblingcount="51">Table: Index Creation Times for Wiki</h3>
<table><thead><tr><th><p>Vector Database</p></th><th><p>Time</p></th><th><p>Vec/s</p></th></tr></thead><tbody><tr><td><p>Lantern</p></td><td><p>44m</p></td><td><p>~382 vec/s</p></td></tr><tr><td><p>Pinecone (p2x2 - 1 pod)</p></td><td><p>30m</p></td><td><p>~555 vec/s</p></td></tr><tr><td><p>Pgvector</p></td><td><p>2h</p></td><td><p>~140 vec/s</p></td></tr></tbody></table>
<h3 id="h3--1973001272" level="3" index="22" siblingcount="51">Graph: Index Creation Speed</h3>
<p><img src="https://storage.googleapis.com/lantern-blog/2/2.svg" alt="Index Creation Speed (Single Core)"></p>
<h2 id="h2--69255453" level="2" siblingcount="51">Using external index creation, Lantern is 90x faster than pgvector</h2>
<h3 id="h3-1281314467" level="3" index="25" siblingcount="51">Results Overview</h3>
<ul>
<li><strong>17x</strong> performance improvement compared to creating the index on a single thread.</li>
<li><strong>90x</strong> performance improvement compared to pgvector, and a <strong>6x</strong> improvement over Pinecone for sift dataset</li>
<li><strong>48x</strong> performance improvement over pgvector, as well as a <strong>3x</strong> improvement over Pinecone with 32 pods</li>
<li>Pinecone index on 32 p2 pods costs <strong>$3,889.44 / month</strong>. 32 CPU Linode costs <strong>$576 / month</strong>. Lantern is over <strong>6x cheaper and 6x faster!</strong></li>
</ul>
<h3 id="h3-792589141" level="3" index="27" siblingcount="51">Graph: Index Creation Speed with 32 Cores</h3>
<p><img src="https://storage.googleapis.com/lantern-blog/2/3.svg" alt="Index Creation Speed (Multi Core)"></p>
<h3 id="h3-1171237270" level="3" index="29" siblingcount="51">Graph: Index Creation Speed with 2 - 32 Cores</h3>
<p><img src="https://storage.googleapis.com/lantern-blog/2/4.svg" alt="Index creation speed with Lantern Multi-Core Index"></p>
<p>Fine-tuning the recall using parameters <code>m=16</code>, <code>ef_construction=128</code>, and <code>ef=128</code> for Lantern, we can achieve a 99% recall@5 for sift dataset, with the index creation taking only <strong>50 seconds</strong>.</p>
<p>Notice that a 2 Core Linode Server running Lantern outperforms Pinecone’s 32 pod cluster - this means that Lantern can be <strong>60x cheaper than Pinecone for the same performance.</strong></p>
<h2 id="h2--1139598294" level="2" siblingcount="51">External index creation with Lantern</h2>
<h3 id="h3--124802092" level="3" index="34" siblingcount="51">Implementation Details</h3>
<p>Here is a brief overview of how Lantern's external index creation works under the hood.</p>
<p>We use the row's <a href="https://www.postgresql.org/docs/current/ddl-system-columns.html#DDL-SYSTEM-COLUMNS-CTID"><code>ctid</code></a> as a label for our nodes during index creation. Later, this label is used to retrieve the actual row from Postgres, as it represents the physical location of the row.</p>
<p>We use Postgres's <a href="https://www.postgresql.org/docs/current/largeobjects.html">large object</a> functionality for data transfer. We use the <a href="https://www.postgresql.org/docs/current/lo-funcs.html"><code>lo_export</code></a> function to export the indexable data to the file system. After generating the index using <a href="https://github.com/unum-cloud/usearch/">Usearch</a> on the file system, we then use the <a href="https://www.postgresql.org/docs/current/lo-funcs.html"><code>lo_import</code></a> function to transfer the index file to the database server.</p>
<h3 id="h3-1922878868" level="3" index="38" siblingcount="51">How to use external index creation</h3>
<ol>
<li>Install the <a href="https://github.com/lanterndata/lantern_extras/tree/main#lantern-index-builder">Lantern CLI</a></li>
<li>Create an index from a regular Postgres table via the <code>create-index</code> utility</li>
</ol>
<p>Here is a walk through:</p>
<p>First, install the Lantern CLI:</p>
<div><pre tabindex="0"><code><span><span>cargo</span><span> install</span><span> --git</span><span> https://github.com/lanterndata/lantern_extras</span><span> --bin</span><span> lantern-cli</span></span>
<span></span></code></pre></div>
<p>Next, use the <code>create-index</code> utility to externally create and import our index to Postgres:</p>
<blockquote>
<p><em><strong>Note</strong>: If you encounter ONNXRuntime, issues, set up onnx runtime manually using <a href="https://github.com/lanterndata/lantern_extras?tab=readme-ov-file#building-from-source">these steps</a> and export the required env variables.</em></p>
</blockquote>
<div><pre tabindex="0"><code><span><span>lantern-cli</span><span> create-index</span><span> \</span></span>
<span><span>    --uri</span><span> postgresql://postgres@localhost:5432/testlive</span><span> \</span></span>
<span><span>    --table</span><span> sift</span><span> \</span></span>
<span><span>    --column</span><span> v</span><span> \</span></span>
<span><span>    -m</span><span> 8</span><span> \</span></span>
<span><span>    --efc</span><span> 128</span><span> \</span></span>
<span><span>    --ef</span><span> 64</span><span> \</span></span>
<span><span>    -d</span><span> 128</span><span> \</span></span>
<span><span>    --metric-kind</span><span> cos</span><span> \</span></span>
<span><span>    --out</span><span> index.usearch</span><span> \</span></span>
<span><span>    --import</span></span>
<span></span></code></pre></div>
<p>The <code>--uri</code> parameter specifies the database connection URI, and the <code>--table</code> and <code>--column</code> parameters specify the table and column to index. The index parameters are <code>-m</code>, <code>--efc</code>, <code>--ef</code>, <code>-d</code> (dimension of column), and <code>--metric-kind</code> (<code>l2sq</code>, <code>cos</code>, or <code>hamming</code>). The <code>--out</code> parameter specifies the output file name. If <code>--import</code> is also specified, the externally created index will be automatically imported to Postgres after creation, and the temporary output file will be removed.</p>
<p>The table will be exclusively locked during the index creation process to avoid inconsistency. To reindex the data, use <code>select lantern_reindex_external_index('&lt;index_name&gt;')</code>; if you have <code>lantern_extras</code> extension installed in your database, or use the same CLI command as above and provide the <code>--index-name</code> argument. In the latter case, the existing index will be dropped and a new one will be created.</p>
<h2 id="h2-262204991" level="2" siblingcount="51">Conclusion</h2>
<p>In this post, we discussed the significance of index creation times, Lantern's external indexing process, and shared our benchmarking results against pgvector and Pinecone.</p>
<p>For a deeper dive into the code, you can check out our <a href="https://github.com/lanterndata/lantern">core repo</a> or the <a href="https://github.com/lanterndata/lantern_extras">Lantern Extras repo</a>. Our core repo enables vector search in Postgres, while Lantern Extras provides routines for external index generation and embedding management.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How to do OCR on a Mac using the CLI or just Python (322 pts)]]></title>
            <link>https://blog.greg.technology/2024/01/02/how-do-you-ocr-on-a-mac.html</link>
            <guid>38844943</guid>
            <pubDate>Tue, 02 Jan 2024 18:20:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.greg.technology/2024/01/02/how-do-you-ocr-on-a-mac.html">https://blog.greg.technology/2024/01/02/how-do-you-ocr-on-a-mac.html</a>, See on <a href="https://news.ycombinator.com/item?id=38844943">Hacker News</a></p>
<div id="readability-page-1" class="page"><div aria-label="Content">
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>a kind reader reached out about <a href="https://blog.greg.technology/2024/01/01/all-of-my-iphone-alarms.html">all of my iphone alarms</a> and asked how specifically did I run OCR on my mac. I’m not one to gatekeep, so here’s how you can get yourself a nice local ocr ‘service’ that works in the terminal/CLI/python and costs 0 dollars:</p>

<ul>
  <li>((by the way sharing Shortcuts <a href="https://9to5mac.com/2021/03/24/icloud-shortcut-sharing-broken/">is really weird</a> which is why I’m having you do this all manually…))</li>
  <li>(also, most of the stuff below only needs to be done once – after that, actually ocr’ing is easy)</li>
  <li>open the <strong>Shortcuts</strong> app in your Applications folder</li>
  <li>click the “<strong>+</strong>” button to create a new shortcut</li>
  <li>in the right sidebar, search for “<strong>extract text</strong>”</li>
</ul>

<p><img src="https://blog.greg.technology/assets/how-to-ocr/step1.png"></p>

<ul>
  <li>you should see “<strong>Extract Text from Image</strong>” in the list of possible actions. <strong>drag it</strong> from the right sidebar into the main area on the left</li>
  <li>in the “Extract text from …” action that’s now on the left, click on the pale “<strong>Image</strong>” blue-ish pill</li>
  <li>pick “<strong>Shortcut Input</strong>”</li>
</ul>

<p><img src="https://blog.greg.technology/assets/how-to-ocr/step2.png"></p>

<ul>
  <li>you’ll see a big “<strong>Receive <em>Any</em> input from <em>Nowhere</em></strong>” action appear above the “Extract text from Shortcut Input”. it’s all good, leave it as is</li>
  <li>in the right sidebar, search for “<strong>copy</strong>”. you should see “<strong>Copy to Clipboard</strong>”. drag that action below the “<strong>Extract text from …</strong>” one
    <ul>
      <li>dragging the “Copy to …” action below the “Extract from …” is really annoyingly hard. just keep dragging it <em>really</em> below and it will work at some point</li>
    </ul>
  </li>
  <li>your final setup should look like this:</li>
</ul>

<p><img src="https://blog.greg.technology/assets/how-to-ocr/step3.png"></p>

<ul>
  <li>in the last action, make sure that after “<strong>Copy</strong>” it does say “<strong>Text from Image</strong>”!</li>
  <li>you’re like almost done!!</li>
  <li>in the window title bar, type stuff to name the shortcut. because <a href="https://twitter.com/TheIdOfAlan/status/1458117496087748618">I’m from a generation</a>, I recommend naming it “extract-text” or “ocr-text” or something simple with no spaces and all lowercase. sorry. <strong>press enter</strong> after naming the shortcut otherwise it won’t remember the name (…??)</li>
</ul>

<p><img src="https://blog.greg.technology/assets/how-to-ocr/step4.png"></p>

<ul>
  <li>ok you may be actually done here I think</li>
  <li>try out the shortcut in your terminal:</li>
</ul>

<div><pre><code>shortcuts run ocr-text <span>-i</span> &lt;A PATH TO SOME IMAGE&gt;
</code></pre></div>

<ul>
  <li>then try <strong>command-V</strong> – do you see the resulting text? if yes, you’re good to go!!!</li>
  <li>from python, you can do the following:</li>
</ul>

<div><pre><code><span>import</span> <span>subprocess</span>

<span>file_path</span> <span>=</span> <span>'... some file path ...'</span>
<span>ocr_out</span> <span>=</span> <span>subprocess</span><span>.</span><span>check_output</span><span>(</span>
    <span>f</span><span>'shortcuts run ocr-text -i "</span><span>{</span><span>file_path</span><span>}</span><span>"'</span><span>,</span> <span>shell</span><span>=</span><span>True</span>
<span>)</span>
<span>print</span><span>(</span><span>ocr_out</span><span>)</span>
</code></pre></div>

<ul>
  <li>THAT’S IT! x</li>
</ul>

  </div>
</article>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Do It Yourself Blind Repair (566 pts)]]></title>
            <link>https://fixmyblinds.com/</link>
            <guid>38844274</guid>
            <pubDate>Tue, 02 Jan 2024 17:31:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fixmyblinds.com/">https://fixmyblinds.com/</a>, See on <a href="https://news.ycombinator.com/item?id=38844274">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="PageContainer">

    <main id="MainContent" role="main" tabindex="-1">
      <!-- BEGIN content_for_index --><div id="shopify-section-hero" data-layout="full_width" data-section-id="hero" data-section-type="hero-section"><p>Find replacement parts and learn how to fix your blinds.</p><p><a href="https://fixmyblinds.com/collections/identify-your-blind">
              START HERE
            </a></p></div><div id="shopify-section-1569518458652">
      
        <p>
          <h2>Join over 1,000,000 people that have fixed their blinds!</h2>
        </p>
      
      
        <p>"I was able to locate and order my part from the detailed parts list. I received the correct part in 2 business days. With the help of the online repair video, I had the blind fixed in 5 min. Big help to avoid costly replacement."&nbsp; &nbsp;- Michael B.</p>
      
      
        
      
      
        
      
    </div><div id="shopify-section-1569522452835">
  
    <p>
      <h2>What type of blind do you need to fix?</h2>
    </p>
  

  

  

  
  
  
    
  
  
  
</div><div id="shopify-section-1570081033819">
  
    <p>
      <h2>Popular Blind Parts</h2>
    </p>
  

  

  

  
  
  
    
  
  
  
</div><div id="shopify-section-1569518393485">
  
    <p>
      <h2>Helpful Resources</h2>
    </p>
  

  <div>
    
      
      <div id="TextColumnImageWrapper-1569518393485-0">
              <p><a href="https://fixmyblinds.com/pages/how-blinds-work-horizontal-blinds">
                
                <img id="TextColumnImage-1569518393485-0" src="https://fixmyblinds.com/cdn/shop/files/how-blinds-work-home_banner_%7Bwidth%7Dx.png?v=1613686223" data-src="//fixmyblinds.com/cdn/shop/files/how-blinds-work-home_banner_{width}x.png?v=1613686223" data-widths="[180, 360, 540, 720, 900, 1080, 1296, 1512, 1728, 2048]" data-aspectratio="1.74" data-sizes="auto" alt="">
                
                </a>
                
              </p>
            </div>
    
      
      <div>
        
          
            
            


            <div id="TextColumnImageWrapper-1569518393485-1">
              <p><a href="https://fixmyblinds.com/pages/identify-your-part">
                
                <img id="TextColumnImage-1569518393485-1" src="https://fixmyblinds.com/cdn/shop/files/WEB-DIAGRAMS-GRAPHIC-HOME_%7Bwidth%7Dx.png?v=1613686223" data-src="//fixmyblinds.com/cdn/shop/files/WEB-DIAGRAMS-GRAPHIC-HOME_{width}x.png?v=1613686223" data-widths="[180, 360, 540, 720, 900, 1080, 1296, 1512, 1728, 2048]" data-aspectratio="1.74" data-sizes="auto" alt="">
                
                </a>
                
              </p>
            </div>
            
            <p>All blinds work a little bit differently.&nbsp;<a href="https://fixmyblinds.com/pages/identify-your-part" title="Identify Your Part">Our diagrams</a>&nbsp;label all of the parts so you can quickly identify what you need!</p>
        
        
      </div>
    
  </div>

  
  
  
</div><!-- END content_for_index -->

    </main>

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    





    

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Double encryption: Analyzing the NSA/GCHQ arguments against hybrids (105 pts)]]></title>
            <link>https://blog.cr.yp.to/20240102-hybrid.html</link>
            <guid>38844117</guid>
            <pubDate>Tue, 02 Jan 2024 17:20:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.cr.yp.to/20240102-hybrid.html">https://blog.cr.yp.to/20240102-hybrid.html</a>, See on <a href="https://news.ycombinator.com/item?id=38844117">Hacker News</a></p>
<div id="readability-page-1" class="page">
<h2>The cr.yp.to <a href="https://blog.cr.yp.to/index.html" accesskey="i">blog</a></h2>
<hr>
<div>

<details><summary>Table of contents (Access-I for index page)</summary>
<table>
<tbody><tr><td><b>2024.01.02: Double encryption:</b> Analyzing the NSA/GCHQ arguments against hybrids. #nsa #quantification #risks #complexity #costs</td></tr>
<tr><td><a href="https://blog.cr.yp.to/20231125-kyber.html"><b>2023.11.25: Another way to botch the security analysis of Kyber-512:</b></a> <span>Responding to a recent blog post. #nist #uncertainty #errorbars #quantification</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20231023-clumping.html"><b>2023.10.23: Reducing "gate" counts for Kyber-512:</b></a> <span>Two algorithm analyses, from first principles, contradicting NIST's calculation. #xor #popcount #gates #memory #clumping</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20231003-countcorrectly.html"><b>2023.10.03: The inability to count correctly:</b></a> <span>Debunking NIST's calculation of the Kyber-512 security level. #nist #addition #multiplication #ntru #kyber #fiasco</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20230609-turboboost.html"><b>2023.06.09: Turbo Boost:</b></a> <span>How to perpetuate security problems. #overclocking #performancehype #power #timing #hertzbleed #riskmanagement #environment</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20220805-nsa.html"><b>2022.08.05: NSA, NIST, and post-quantum cryptography:</b></a> <span>Announcing my second lawsuit against the U.S. government. #nsa #nist #des #dsa #dualec #sigintenablingproject #nistpqc #foia</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20220129-plagiarism.html"><b>2022.01.29: Plagiarism as a patent amplifier:</b></a> <span>Understanding the delayed rollout of post-quantum cryptography. #pqcrypto #patents #ntru #lpr #ding #peikert #newhope</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20201206-msword.html"><b>2020.12.06: Optimizing for the wrong metric, part 1: Microsoft Word:</b></a> <span>Review of "An Efficiency Comparison of Document Preparation Systems Used in Academic Research and Development" by Knauff and Nejasmic. #latex #word #efficiency #metrics</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20191024-eddsa.html"><b>2019.10.24: Why EdDSA held up better than ECDSA against Minerva:</b></a> <span>Cryptosystem designers successfully predicting, and protecting against, implementation failures. #ecdsa #eddsa #hnp #lwe #bleichenbacher #bkw</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20190430-vectorize.html"><b>2019.04.30: An introduction to vectorization:</b></a> <span>Understanding one of the most important changes in the high-speed-software ecosystem. #vectorization #sse #avx #avx512 #antivectors</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20171105-infineon.html"><b>2017.11.05: Reconstructing ROCA:</b></a> <span>A case study of how quickly an attack can be developed from a limited disclosure. #infineon #roca #rsa</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20171017-collisions.html"><b>2017.10.17: Quantum algorithms to find collisions:</b></a> <span>Analysis of several algorithms for the collision problem, and for the related multi-target preimage problem. #collision #preimage #pqcrypto</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20170723-random.html"><b>2017.07.23: Fast-key-erasure random-number generators:</b></a> <span>An effort to clean up several messes simultaneously. #rng #forwardsecrecy #urandom #cascade #hmac #rekeying #proofs</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20170719-pqbench.html"><b>2017.07.19: Benchmarking post-quantum cryptography:</b></a> <span>News regarding the SUPERCOP benchmarking system, and more recommendations to NIST. #benchmarking #supercop #nist #pqcrypto</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20161030-pqnist.html"><b>2016.10.30: Some challenges in post-quantum standardization:</b></a> <span>My comments to NIST on the first draft of their call for submissions. #standardization #nist #pqcrypto</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20160607-dueprocess.html"><b>2016.06.07: The death of due process:</b></a> <span>A few notes on technology-fueled normalization of lynch mobs targeting both the accuser and the accused. #ethics #crime #punishment</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20160516-quantum.html"><b>2016.05.16: Security fraud in Europe's "Quantum Manifesto":</b></a> <span>How quantum cryptographers are stealing a quarter of a billion Euros from the European Commission. #qkd #quantumcrypto #quantummanifesto</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20160315-jefferson.html"><b>2016.03.15: Thomas Jefferson and Apple versus the FBI:</b></a> <span>Can the government censor how-to books? What if some of the readers are criminals? What if the books can be understood by a computer? An introduction to freedom of speech for software publishers. #censorship #firstamendment #instructions #software #encryption</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20151120-batchattacks.html"><b>2015.11.20: Break a dozen secret keys, get a million more for free:</b></a> <span>Batch attacks are often much more cost-effective than single-target attacks. #batching #economics #keysizes #aes #ecc #rsa #dh #logjam</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20150314-optimizing.html"><b>2015.03.14: The death of optimizing compilers:</b></a> <span>Abstract of my tutorial at ETAPS 2015. #etaps #compilers #cpuevolution #hotspots #optimization #domainspecific #returnofthejedi</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20150218-printing.html"><b>2015.02.18: Follow-You Printing:</b></a> <span>How Equitrac's marketing department misrepresents and interferes with your work. #equitrac #followyouprinting #dilbert #officespaceprinter</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20140602-saber.html"><b>2014.06.02: The Saber cluster:</b></a> <span>How we built a cluster capable of computing 3000000000000000000000 multiplications per year for just 50000 EUR. #nvidia #linux #howto</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20140517-insns.html"><b>2014.05.17: Some small suggestions for the Intel instruction set:</b></a> <span>Low-cost changes to CPU architecture would make cryptography much safer and much faster. #constanttimecommitment #vmul53 #vcarry #pipelinedocumentation</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20140411-nist.html"><b>2014.04.11: NIST's cryptographic standardization process:</b></a> <span>The first step towards improvement is to admit previous failures. #standardization #nist #des #dsa #dualec #nsa</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20140323-ecdsa.html"><b>2014.03.23: How to design an elliptic-curve signature system:</b></a> <span>There are many choices of elliptic-curve signature systems. The standard choice, ECDSA, is reasonable if you don't care about simplicity, speed, and security. #signatures #ecc #elgamal #schnorr #ecdsa #eddsa #ed25519</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20140213-ideal.html"><b>2014.02.13: A subfield-logarithm attack against ideal lattices:</b></a> <span>Computational algebraic number theory tackles lattice-based cryptography.</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20140205-entropy.html"><b>2014.02.05: Entropy Attacks!</b></a> <span>The conventional wisdom says that hash outputs can't be controlled; the conventional wisdom is simply wrong.</span></td></tr>
</tbody></table></details></div><hr>
<h2>2024.01.02: Double encryption: <span>Analyzing the NSA/GCHQ arguments against hybrids. #nsa #quantification #risks #complexity #costs</span></h2>
<p>In 2019,
Google and Cloudflare ran an experiment where they
upgraded HTTPS for many
<a href="https://blog.cloudflare.com/towards-post-quantum-cryptography-in-tls/">"real users’ connections"</a>
to use post-quantum encryption.
They then reported
<a href="https://blog.cloudflare.com/the-tls-post-quantum-experiment/">statistics</a>
on how affordable this was.
Google had also run a similar
<a href="https://security.googleblog.com/2016/07/experimenting-with-post-quantum.html">experiment</a>
in 2016:
"While it's still very early days for quantum computers, we're excited to begin preparing for them,
and to help ensure our users' data will remain secure long into the future."</p>
<p>Sounds great!
Except that, oops, the 2016 experiment ran into
<a href="https://blog.cr.yp.to/20220129-plagiarism.html">patent trouble</a>.
And, oops, half of the post-quantum connections in the 2019 experiment used SIKE,
which in 2022 was shown by
<a href="https://eprint.iacr.org/2022/975">public</a>
<a href="https://eprint.iacr.org/2022/1026">attacks</a>
to be efficiently breakable.</p>
<p>Upgrading connections to SIKE wasn't just
failing to protect those connections against future quantum computers.
It was encrypting the connections using an algorithm broken by <em>today's</em> computers.
The only reason this wasn't giving the user data away to today's attackers
is that these experiments were using "hybrids":
continuing to encrypt with elliptic-curve cryptography
while <em>adding</em> a layer of encryption with the new algorithm.
<a name="x25519deployment"></a>
The elliptic-curve cryptography was
<a href="https://ianix.com/pub/curve25519-deployment.html">X25519</a>,
which was already the
<a href="https://blog.cloudflare.com/towards-post-quantum-cryptography-in-tls/">"most commonly used key exchange algorithm"</a>
in 2019 and today is used in the
<a href="https://eprint.iacr.org/2023/734.pdf">"vast majority"</a>
of TLS connections.</p>
<p>Post-quantum deployment today has progressed far beyond experiments.
OpenSSH upgraded in April 2022 to
<a href="https://www.openssh.com/txt/release-9.0">"the hybrid Streamlined NTRU Prime + x25519 key exchange method by default"</a>.
Google upgraded its internal communication in November 2022 to a hybrid of
<a href="https://cloud.google.com/blog/products/identity-security/why-google-now-uses-post-quantum-cryptography-for-internal-comms">"NTRU-HRSS and X25519"</a>,
and upgraded Chrome in August 2023 to support
<a href="https://blog.chromium.org/2023/08/protecting-chrome-traffic-with-hybrid.html">"X25519Kyber768"</a>
in TLS.</p>
<p>All of these upgrades use a post-quantum layer to <em>try</em> to protect today's user data against future quantum computers,
and at the same time keep a pre-quantum layer
so that they don't <em>lose</em> security if something goes wrong with the post-quantum system.</p>
<p>This shouldn't be controversial.
However,
<a href="https://nsarchive2.gwu.edu/NSAEBB/NSAEBB441/">NSA</a>
stated in May 2022 that it
<a href="https://web.archive.org/web/20220524232249/https://twitter.com/mjos_crypto/status/1433443198534361101/photo/1">"<span color="#663319">does not expect to approve</span>"</a>
hybrids.
After the July 2022 SIKE break
(see also the section on hybrids
in my August 2022 blog post <a href="https://blog.cr.yp.to/20220805-nsa.html">"NSA, NIST, and post-quantum cryptography"</a>),
NSA issued a
<a href="https://web.archive.org/web/20220908002357/https://media.defense.gov/2022/Sep/07/2003071836/-1/-1/0/CSI_CNSA_2.0_FAQ_.PDF">September 2022 FAQ</a>
that retreats slightly from "<span color="#663319">does not expect to approve</span>" to "<span color="#663319">will not require</span>".
NSA's FAQ continues <em>discouraging</em> hybrids.</p>
<p>It's important to realize that
NSA's public positions have a major influence on the cryptographic market.
The United States
<a href="https://en.wikipedia.org/wiki/Military_budget_of_the_United_States">military budget</a>
is approaching a trillion dollars a year,
and NSA
<a href="https://web.archive.org/web/20221022163808/https://www.jcs.mil/Portals/36/Documents/Library/Instructions/CJCSI%206510.02F.pdf?ver=qUEnOsWpGPcGGMFTb4yYVA%3D%3D">controls</a>
the cryptographic part of that purchasing.</p>
<p>This doesn't mean that NSA has unlimited power.
See, e.g., the quotes <a href="#x25519deployment">above</a> regarding X25519 deployment in TLS.
<a href="https://www.ssllabs.com/ssltest/viewClient.html?name=Chrome&amp;version=80&amp;platform=Win%2010&amp;key=170">Pretty</a>
<a href="https://www.ssllabs.com/ssltest/viewClient.html?name=Firefox&amp;version=73&amp;platform=Win%2010&amp;key=171">much</a>
<a href="https://www.ssllabs.com/ssltest/viewClient.html?name=Safari&amp;version=12.1.2&amp;platform=MacOS%2010.14.6%20Beta&amp;key=161">every</a>
<a href="https://www.ssllabs.com/ssltest/viewClient.html?name=Edge&amp;version=18&amp;platform=Win%2010&amp;key=160">browser</a>
and
<a href="https://www.ssllabs.com/ssltest/">server</a>
supports X25519 and uses it by default,
although there are exceptions, such as
<a href="https://www.ssllabs.com/ssltest/analyze.html?d=nsa.gov">nsa.gov</a>
preferring P-256.
As for hybrids,
NIST and other standardization organizations
can and should <strong>require</strong> upgrades to use hybrids,
for example with the following language for key-encapsulation mechanisms (KEMs):
"Any upgrade from pre-quantum encryption to this KEM
shall retain the pre-quantum encryption
and add this KEM as an extra layer of defense,
rather than removing the pre-quantum encryption."</p>
<p>In this blog post,
I'll look at NSA's arguments against hybrids.
I'll also look at the anti-hybrid arguments in a
<a href="https://web.archive.org/web/20231104161635/https://www.ncsc.gov.uk/whitepaper/next-steps-preparing-for-post-quantum-cryptography">statement</a>
from NSA's
<a href="https://www.theguardian.com/uk-news/2013/aug/01/nsa-paid-gchq-spying-edward-snowden">friends</a>
at <a href="https://www.theguardian.com/uk-news/2021/may/25/gchqs-mass-data-sharing-violated-right-to-privacy-court-rules">GCHQ</a>.</p>
<p><strong>The NSA anti-hybrid arguments.</strong>
Let's consider the following quotes from NSA's September 2022 FAQ:</p>
<ul>
<li>
<p>"<span color="#663319">Hybrids add complexity to protocols, as designers need to incorporate additional negotiation and error handling.</span>"</p>
<p>This is not true.
  A protocol using a signature system
  doesn't care that the signature system is
  (1) internally using a pre-quantum signature system and a post-quantum signature system
  and
  (2) internally requiring both of those signatures to pass verification.
  Similarly, a protocol using a KEM
  doesn't care that the KEM is internally hashing together pre-quantum and post-quantum session keys.</p>
<p>One <em>can</em> instead support hybrids at the protocol layer, and this can even have some advantages;
  but this doesn't require additional negotiation, doesn't require additional error handling,
  and, most importantly, isn't required in the first place.</p>
</li>
<li>
<p>"<span color="#663319">Hybrid deployments introduce additional interoperability concerns, now that all
  algorithms plus the method of hybridization must be features common to all parties to a
  communication.</span>"</p>
<p>This is also not true.
  Upgrades require paying attention to interoperability,
  but upgrading to a hybrid KEM works the same way as upgrading to a non-hybrid KEM.
  The OpenSSH upgrade to <code>sntrup761x25519-sha512</code>
  worked the same way that an upgrade
  to a hypothetical non-hybrid <code>sntrup761-sha512</code> would have worked.</p>
</li>
<li>
<p><a name="transition"></a>"<span color="#663319">Many hybrid solutions being developed externally do not facilitate the transition to
  strictly-QR solutions, so implementers would need to anticipate an additional significant
  transition from hybrid to QR as classical algorithms lose their utility.</span>"</p>
<p>"QR" is jargon for "quantum-resistant",
which in turn is the marketing department falsely claiming that the <em>goal</em> is an established <em>fact</em>.
But let's read this as "post-quantum" and focus on what the "<span color="#663319">transition</span>" argument is saying.</p>
<p>Here's the scenario to think about.
Imagine public demonstrations of low-cost quantum attacks
showing that X25519 has negligible security value.
Imagine the community then deciding to move from
<code>sntrup761x25519-sha512</code>
to just <code>sntrup761-sha512</code>.
An initial transition to <code>sntrup761x25519-sha512</code>,
followed by a transition to <code>sntrup761-sha512</code>,
is <em>two</em> transitions!</p>
<p>But what makes this second transition "<span color="#663319">significant</span>"?
It isn't a security upgrade.
Yes, software changes take time to test and deploy,
but if this second transition is such a problem
that we should be insisting on having just one transition,
then why should that one transition be to <code>sntrup761-sha512</code>
rather than to <code>sntrup761x25519-sha512</code>?</p>
<p>NSA's argument here is a puzzling combination of
(1) arguing that it's important to minimize the number of transitions and
(2) arguing that if there's a transition to a hybrid
then it will be important to subsequently transition <em>away</em> from the hybrid.
This doesn't make sense unless you assume that there's something wrong with hybrids in the first place.
In other words, this two-transition argument
isn't an independent argument against hybrids.</p>
</li>
<li>
<p>"<span color="#663319">Perhaps most importantly, hybrid solutions make implementations even more complex,
  so one must balance the risk of flaws in an increasingly complex implementation with
  the risk of a cryptanalytic breakthrough.</span>"</p>
<p>The scenario here is much more immediate.
Let's say you've designed a cryptographic application using X25519 for encryption.
You decide to upgrade from pre-quantum encryption to post-quantum encryption.
You sensibly use a hybrid.
Along with the existing X25519 code,
there's new code for whichever KEM—let's call it UltraKEM.
You then compute a hybrid hash:
this means hashing
the X25519 session key, the UltraKEM session key,
the X25519 public keys, and the UltraKEM ciphertext.
You use the output of this hash as the new session key.</p>
<p>Skipping the hybrid would certainly reduce code volume in the long run:
once all clients and servers support UltraKEM,
you'd be able to eliminate the X25519 code
and the code for the hybrid hash.</p>
<p>Could the X25519 code have bugs?
Yes.
X25519 is <a href="https://cr.yp.to/papers.html#nistecc">easier</a>
to implement correctly than NSA's ECDH using P-256,
but this doesn't mean that the risk of someone implementing X25519 incorrectly is zero.</p>
<p>But why is NSA not mentioning the risk of bugs in the UltraKEM software?
Isn't this <em>obviously</em> a bigger risk?</p>
<p><a name="morecomplicated"></a>
The UltraKEM software is newer and more complicated than the X25519 software.
Any reasonable risk assessment will conclude that
the probability of an exploitable arithmetic bug or timing leak or randomness-usage mistake in the UltraKEM software
is higher than the probability of such a exploit in the X25519 software.
Furthermore,
if the first type of exploit happens,
its impact is destroying the security of UltraKEM (user data is exposed today),
while an X25519+UltraKEM hybrid reduces the damage (user data is exposed to a future quantum computer).
If the second type of exploit happens,
its impact is merely dropping the security of X25519+UltraKEM down to the security of UltraKEM.</p>
<p>Consider
<a href="https://kyberslash.cr.yp.to/">KyberSlash</a>,
a timing variation that was in
<a href="https://blog.cr.yp.to/kyberslash.cr.yp.to/libraries.html">most</a>
Kyber libraries at the beginning of December 2023.
I posted a
<a href="https://groups.google.com/a/list.nist.gov/g/pqc-forum/c/ldX0ThYJuBo/m/uIOqRF5BAwAJ">demo</a>
on 30 December 2023
recovering Kyber's complete secret key from timings of the beginning-of-December-2023 Kyber reference code.
Are we supposed to believe that this is the last vulnerability in post-quantum software?</p>
<p>Let's be clear about what NSA needs to have happen
to support its scenario of what I'll call a <em>hybrid reversal</em>,
namely the X25519+UltraKEM software being <em>less</em> secure than the UltraKEM software.
There needs to be a program-partitioning disaster in the X25519 software,
such as an exploitable buffer overflow;
or there needs to be some similarly devastating bug
in the lines of code for the hybrid hash,
such as omitting the UltraKEM session key from the hash input.</p>
<p>We have tools automatically checking that there's no data flow from the X25519 input to any branch conditions or array indices,
so how exactly is a buffer overflow supposed to happen?
As for a bug in the hybrid hash,
how is this supposed to slip past interoperability testing?</p>
<p>I'm not saying a hybrid reversal is impossible to achieve.
But NSA's wording ("<span color="#663319">risk of flaws in an increasingly complex implementation</span>")
makes the reader think about
the overall amount of code for an X25519+UltraKEM hybrid,
and suggests, incorrectly, that any flaws in this code are an argument against hybrids.
NSA doesn't acknowledge the possibility of flaws in the UltraKEM code
making UltraKEM less secure than the hybrid,
as illustrated by KyberSlash.
NSA also doesn't distinguish between (1) the possibility of flaws in the X25519 code
reducing the security of X25519+UltraKEM to the security of UltraKEM
and (2) the possibility of a hybrid reversal.</p>
<p>Maybe NSA will respond that, oh, sorry, it wasn't thinking about bugs in the post-quantum software,
and didn't know about KyberSlash,
and, really, how common can this sort of thing be?
But a separate document shows that,
for some "national security" data,
NSA uses two independent encryption layers
<a href="https://web.archive.org/web/20220524232250/https://www.nsa.gov/Portals/75/documents/resources/everyone/csfc/threat-prevention.pdf">"to mitigate the ability of an adversary to exploit a single cryptographic implementation"</a>.
How does NSA reconcile this with its FAQ not even mentioning the risk of an exploit of a post-quantum implementation?</p>
<p>Meanwhile the word "<span color="#663319">breakthrough</span>" in NSA's FAQ
suggests that mathematical breaks of post-quantum systems are rare;
and NSA's word "<span color="#663319">balance</span>" suggests
that the risks of those breaks are no higher than the risks from hybrid reversals.
Certainly a problem in cryptographic software can be as devastating as a mathematical break
(and there are cases where patching a
<a href="https://cr.yp.to/papers.html#cachetiming">software problem</a>
is <a href="https://eprint.iacr.org/2019/996">harder</a>
than switching to a different cryptosystem);
but why should we think that the <em>probability</em> of a hybrid reversal
is anywhere near the probability of post-quantum systems being broken?</p>
</li>
<li>
<p>"<span color="#663319">More security products fail due to implementation or configuration errors than failures in
    their underlying cryptographic algorithms. Therefore, spending limited resources to add
    cryptographic complexity can potentially weaken security.</span>"</p>
<p>This needs clarification.
What exactly is included in "<span color="#663319">products</span>"?
Is NSA claiming that vulnerabilities in non-cryptographic code somehow count as arguments against hybrids?
If the focus is on cryptography:
is NSA excluding, e.g., the 1990s,
when <a href="https://link.springer.com/chapter/10.1007/3-540-45539-6_1">"95%"</a>
of SSL connections used RSA-512,
which was breakable no matter how competent the implementation was?
Also, are failures weighted by severity?
What's the weight assigned to, e.g., the
<a href="https://en.wikipedia.org/wiki/Flame_(malware)">Flame malware</a>,
which was discovered in 2012
and exploited an MD5 weakness?
Also, how is keeping the existing X25519 code supposed to be
an example of "<span color="#663319">spending limited resources to add cryptographic complexity</span>"?
Is NSA talking about the effort to write the code for the hybrid hash?</p>
</li>
</ul>
<p><strong>Quantifying cryptographic risks.</strong>
Let's look more closely at the notion that a mathematical break of a post-quantum system
would be a "<span color="#663319">breakthrough</span>".</p>
<p>As an analogy,
what would you think of someone using the word "breakthroughs" for discoveries of bugs in published software?
Shockingly ignorant, right?</p>
<p>There's broad awareness that programming is an error-prone activity.
There's ample data quantifying this.
Big software projects track their <a href="https://bugzilla.mozilla.org/describecomponents.cgi?product=Firefox">bugs</a>.
Cross-cutting papers
<a href="https://www.vuminhle.com/pdf/issta16.pdf">study</a> bugs in multiple projects,
<a href="https://www.alexopoulos.ch/files/TOPS2020.pdf">study</a> bug discoveries across time,
<a href="https://arxiv.org/pdf/2103.07189.pdf">study</a>
the impact of different software-engineering practices upon bug rates,
etc.
Programmer beliefs are often
<a href="https://www.cs.ucdavis.edu/~devanbu/belief+evidence.pdf">contradicted</a>
by studies.</p>
<p>Is there broad awareness
that the processes of designing and selecting post-quantum cryptosystems
are error-prone?
Readers might occasionally hear news about a broken cryptosystem,
or might bump into a paper describing a break,
but how are readers supposed to figure out how <em>common</em> this is?
Where are the studies of how often cryptosystems fail?</p>
<p>NSA stated in 2021 that
<a href="https://datatracker.ietf.org/meeting/112/materials/slides-112-lamps-hybrid-non-composite-multi-certificate-00">"<span color="#663319">NSA has confidence in the NIST PQC process</span>"</a>.
Typical readers of NSA's 2022 FAQ will end up with the impression
that hybrids are dealing with a hypothetical failure mode rather than a real failure mode.
A "<span color="#663319">breakthrough</span>" doesn't sound like something to be expected.
NSA doesn't mention SIKE.
A reader who has heard separately about SIKE could easily think that it's an isolated example.</p>
<p>Maybe you're thinking something like this:
"Isn't it in fact an isolated example?
Aren't almost all post-quantum proposals holding up just fine?
Otherwise, wouldn't I have heard more news about breaks?"</p>
<p>I have a new paper,
titled
<a href="https://cr.yp.to/papers.html#qrcsp">"Quantifying risks in cryptographic selection processes"</a>,
that takes NIST's post-quantum competition as a case study:</p>
<ul>
<li>
<p>Out of the 69 round-1 submissions to the competition in 2017:
  <strong>48%</strong> are broken by now,
  meaning that the smallest proposed parameters are now known to be easier to break than AES-128.
  (AES-128 was the minimum security level allowed in the competition.)</p>
</li>
<li>
<p>Out of the 48 submissions that were unbroken during round 1:
  <strong>25%</strong> are broken by now.</p>
</li>
<li>
<p>Out of the 28 submissions <em>selected by NIST in 2019 for round 2</em>:
  <strong>36%</strong> are broken by now.</p>
</li>
</ul>
<p>These are shockingly high failure rates.
No, SIKE isn't an isolated example.</p>
<p>Don't let yourself be fooled by confident-sounding salesmen.
If you run into people claiming that selection mechanism S reliably selects cryptosystems that won't be broken within 10 years,
try asking for references to (1) the publication of a clear definition of mechanism S and
(2) the publication, at least 10 years later, of a study of the quantitative failure rate of mechanism S.
People aren't demonstrating any predictive power
if they merely point to an unbroken system and claim reasons for its security.
Keep in mind that a <em>breakable</em> system is <em>unbroken</em> until enough time has been spent to find the attack algorithm,
and incorrect claims of its security in the meantime can be generated by pure confirmation bias.</p>
<p><strong><a name="complexity"></a>Quantifying cryptographic code complexity.</strong>
Another unquantified aspect of NSA's text is its claim that
"<span color="#663319">hybrid solutions make implementations even more complex</span>".</p>
<p>If the words are taken purely at face value then they're clearly correct,
and just as clearly useless for making decisions.
Yes,
X25519+UltraKEM software is more complex than UltraKEM software;
so what?
UltraKEM software is more complex than NullKEM software;
is that supposed to be an argument for NullKEM?
(NullKEM has empty keys, empty ciphertexts, and session keys where every bit is 0.)</p>
<p>What the reader understands NSA to be saying
is that there's an <em>important</em> difference in complexity between X25519+UltraKEM software and UltraKEM software.
The statement from GCHQ, covered <a href="#gchq">below</a>,
explicitly says that there is "<span color="#663319">significantly</span>" more complexity.
This begs a quantitative question:
how much software are we talking about?</p>
<p>I have another new paper,
titled
<a href="https://cr.yp.to/papers.html#pqcomplexity">"Analyzing the complexity of reference post-quantum software"</a>,
that takes the reference software for the following lattice-based KEMs as case studies:
<code>kyber512</code>,
<code>kyber768</code>,
<code>kyber1024</code>,
<code>ntruhps2048509</code>,
<code>ntruhps2048677</code>,
<code>ntruhps4096821</code>,
<code>ntruhrss701</code>,
<code>sntrup653</code>,
<code>sntrup761</code>,
<code>sntrup857</code>,
<code>sntrup953</code>,
<code>sntrup1013</code>,
and
<code>sntrup1277</code>.</p>
<p>The paper applies consistent rules to streamline the reference software for each KEM,
ending up with, e.g., 381 lines for <code>ntruhps4096821</code>,
385 lines for <code>ntruhrss701</code>,
472 lines for <code>kyber1024</code>,
and 478 lines for <code>sntrup1277</code>.
There are also subroutines for hashing, such as a 67-line <code>hash/sha3256</code>,
and for constant-time sorting (in the case of <code>ntruhps</code> and <code>sntrup</code>), such as a 33-line <code>sort/uint32</code>.
The paper includes further metrics (e.g., cyclomatic complexity,
which is a snobbish way to talk about counting functions plus branches),
combinations of multiple KEM sizes (e.g., 574 lines for <code>kyber512</code> plus <code>kyber1024</code>),
and in-depth analyses of how the lines of code are being spent.</p>
<p><a name="tweetnacl"></a>
For comparison,
extracting the X25519 software from
<a href="https://tweetnacl.cr.yp.to/">TweetNaCl</a>,
and reformatting it the same way as in the new paper,
produces 156 lines,
which is under half the size of any of these lattice KEMs.
Sure, I should also count the lines of code for a hybrid hash,
but these numbers easily justify what I wrote
<a href="#morecomplicated">above</a>
about a generic post-quantum UltraKEM:
"The UltraKEM software is newer and more complicated than the X25519 software."</p>
<p><strong>Quantifying complexity of fast code.</strong>
One can criticize this code-size comparison
as being only for <em>simple</em> code.
What about an application that switches to <em>fast</em> code?</p>
<p><a name="x25519assembly"></a>
For X25519,
there are many microarchitecture-specific optimizations available in
<a href="https://lib25519.cr.yp.to/speed.html">lib25519</a>,
but let's assume the application is satisfied with the performance
of John Harrison's
Intel/AMD assembly-language
<a href="https://github.com/awslabs/s2n-bignum/blob/main/x86/curve25519/curve25519_x25519.S">software</a>,
which is 2197 lines,
or the equivalent
<a href="https://github.com/awslabs/s2n-bignum/blob/main/arm/curve25519/curve25519_x25519.S">software</a>
for ARM.
These come with formally verified proofs in HOL Light
that the software
<a href="https://github.com/awslabs/s2n-bignum/blob/main/arm/proofs/curve25519_x25519.ml">correctly</a>
<a href="https://github.com/awslabs/s2n-bignum/blob/main/x86/proofs/curve25519_x25519.ml">computes</a>
X25519 on all inputs,
so the length of the code isn't a correctness concern:
it simply reflects the difficulty of writing (and verifying) the code in the first place.</p>
<p>If I've counted correctly, the Kyber-768 AVX2 software in
<a href="https://github.com/formosa-crypto/libjade/tree/main/src/crypto_kem/kyber">libjade</a>
is 4589 lines plus the hashing subroutines.
(This is <a href="https://eprint.iacr.org/2023/215">mostly</a> verified.)
The line counts aren't directly comparable since the code style is somewhat different,
but I think a direct comparison would again show that
the fast X25519 code is under half the complexity of the fast code for a single Kyber parameter set.</p>
<p>Note that formal verification of software correctness
changes the risk analysis of hybrids:
to the extent it's used,
it reduces the chance of software bugs,
so it increases the relative weight that has to be placed on mathematical breaks.
(The X25519 code from TweetNaCl is also
<a href="https://eprint.iacr.org/2021/428">verified</a>.)</p>
<p><strong><a name="gchq"></a>The GCHQ anti-hybrid arguments.</strong>
Let's move on to considering quotes from GCHQ's November 2023 statement:</p>
<ul>
<li>
<p>"<span color="#663319">There are greater costs to PQ/T hybrid schemes than those with a single algorithm.
    PQ/T hybrid schemes will be more complex to implement and maintain and will also be less efficient.</span>"</p>
<p>The "<span color="#663319">more complex</span>" part is echoing NSA and is covered <a href="#complexity">above</a>.
I'll say more <a href="#efficiency">below</a>
about the "<span color="#663319">less efficient</span>" part.
"PQ/T" is jargon for "post quantum/traditional".</p>
</li>
<li>
<p>"<span color="#663319">PQ/T hybrid key establishment mechanisms should be designed carefully
    to ensure the hybridisation mechanism does not allow additional
    attacks. As of November 2023, advice on how to do this is currently
    in development by ETSI.
    [Next paragraph:]
    Proposed PQ/T hybrid schemes for authentication can be significantly
    more complex than those used for confidentiality, due to the need to
    make sure both signatures verify in a robust way. There has also
    been significantly less research activity into PQ/T schemes for
    authentication than for confidentiality, and there is not yet
    guidance or a consensus on how to do this in a secure way.</span>"</p>
<p>Um, what?</p>
<p>Sign the message with both signature systems.
On the verifier side,
accept the message only if
both signatures pass verification.</p>
<p>If the words "<span color="#663319">there is not yet guidance</span>" are supposed to be a claim that this hasn't been written down:
see, e.g., Section 3.3 of
<a href="https://www.pqcrypto.eu/deliverables/d2.5.pdf">PQCRYPTO deliverable 2.5</a>
from 2018.
The reason there's no research activity here is that this is a trivially solved problem.</p>
<p>For encryption,
simple hashing solutions are presented in
<a href="https://eprint.iacr.org/2018/024">"KEM combiners"</a>,
also from 2018.
We don't need to wait for "<span color="#663319">development by ETSI</span>".</p>
</li>
<li>
<p>"<span color="#663319">PQ/T hybrid authentication within a PKI requires either a PKI which
  can generate and sign traditional and post-quantum digital signatures,
  or two parallel PKIs (one for traditional and one for post-quantum
  digital signatures). This additional complexity and the difficulty in
  migrating PKIs mean that a single migration to a fully post-quantum
  PKI is preferred to adopting an intermediate PQ/T hybrid PKI.</span>"</p>
<p>Migrating a PKI from, say, Ed25519 signatures to Ed25519+UltraSign signatures
works the same way as migrating a PKI from Ed25519 signatures to non-hybrid UltraSign signatures.
Regarding "<span color="#663319">single migration</span>",
see <a href="#transition">above</a> regarding NSA's "<span color="#663319">transition</span>" argument.</p>
</li>
<li>
<p>"<span color="#663319">In the future, if a CRQC exists, traditional PKC algorithms will
  provide no additional protection against an attacker with a CRQC. At
  this point, a PQ/T hybrid scheme will provide no more security than a
  single post-quantum algorithm but with significantly more complexity
  and overhead.</span>"</p>
<p>The assumption that there's a CRQC
(this is jargon for "cryptographically relevant quantum computer")
doesn't justify the conclusion that pre-quantum cryptography provides "<span color="#663319">no additional protection</span>"
and "<span color="#663319">no more security than a single post-quantum algorithm</span>".</p>
<p>Concretely, think about a demo showing that spending a billion dollars on quantum computation can break a thousand X25519 keys.
Yikes! We should be aiming for much higher security than that!
We don't even want a billion-dollar attack to be able to break <em>one</em> key!
Users who care about the security of their data will be happy that we deployed post-quantum cryptography.
But are the users going to say "Let's turn off X25519 and make each session a million dollars cheaper to attack"?
I'm skeptical.
I think users will need to see much cheaper attacks before agreeing that X25519 has negligible security value.</p>
<p>On the flip side, "<span color="#663319">complexity</span>" is covered <a href="#complexity">above</a>,
and I'll say more
<a href="#efficiency">below</a>
about "<span color="#663319">overhead</span>".</p>
</li>
<li>
<p>"<span color="#663319">With this in mind, technical system and risk owners should weigh the
  reasons for and against PQ/T hybrid schemes including
  interoperability, implementation security, and protocol constraints,
  as well as the complexity, cost of maintaining a more complex system,
  and the need to complete the migration twice (once to a PQ/T hybrid
  scheme and again to PQC-only algorithms as a future end state).</span>"</p>
<p>There are no new anti-hybrid arguments here.</p>
</li>
</ul>
<p><strong>Quantifying cryptographic costs.</strong>
<a name="efficiency"></a>
Let's now consider GCHQ's unquantified efficiency claims.</p>
<p>Obviously the continued use of X25519 has <em>some</em> overhead:
32 bytes more in the public key,
32 bytes more in the ciphertext,
and some number of CPU cycles.
But the real question is whether these costs matter for the application.</p>
<p>I have another new paper,
titled
<a href="https://cr.yp.to/papers.html#pppqefs">"Predicting performance for post-quantum encrypted-file systems"</a>,
that looks at the current use of public-key cryptography to encrypt stored files
(for example, in Microsoft's EFS),
and predicts the dollar cost of various post-quantum KEMs in this application.</p>
<p>Part of the paper is collecting data on the purchase costs of storage, communication, and CPU time,
to be able to convert bytes and cycles into dollars.
In particular, Internet data transmission costs roughly 2<sup>−40</sup> dollars per byte,
and computation costs roughly 2<sup>−51</sup> dollars per CPU cycle.
That paper focuses on comparing the costs added by various post-quantum KEMs in one application,
but the purchase costs of bytes and cycles
are application-independent and also shed light on the question of whether the cost of a hybrid can be a problem.</p>
<p>A server sending 32 bytes and receiving 32 bytes for an X25519 key exchange
incurs data-communication costs of roughly 2<sup>−34</sup> dollars.
The software mentioned
<a href="#x25519assembly">above</a>
from John Harrison takes about 2<sup>17</sup> cycles
for key generation plus shared-secret generation,
so also roughly 2<sup>−34</sup> dollars,
for a total cost of roughly 2<sup>−33</sup> dollars.</p>
<p>Saying that the server can do billions of X25519 key exchanges for a dollar
doesn't end the analysis:
it begs the question of how many key exchanges the application is carrying out.
But let's compare this cost to the cost of a Kyber key exchange.</p>
<p>Sending an 800-byte key and receiving a 768-byte ciphertext
for the smallest Kyber option, Kyber-512,
costs roughly 2<sup>−29</sup> dollars.
Including X25519 adds roughly 7% to that.</p>
<p>Are we supposed to believe that an application can afford the cost of Kyber-512
but <em>can't</em> afford to multiply that cost by 1.07?
Um, ok, it's conceivable, but where's the evidence?
How many readers would expect
the words "<span color="#663319">less efficient</span>"
to be referring to such a small performance gap?
If there's going to be <em>any</em> comment on such a small gap,
how about <em>stating the numbers</em> so that the reader isn't misled?</p>
<p>Maybe GCHQ will try to defend its claim
by pointing to slower X25519 implementations,
such as the TweetNaCl implementation mentioned <a href="#tweetnacl">above</a>.
But those implementations are for applications where this slowness is just fine:
think of an application where each user is starting "only" a million sessions.
These applications make GCHQ's cost argument even weaker.</p>
<p><strong>The importance of quantification.</strong>
I'll close this blog post
with some observations on the role of unquantified claims inside the NSA/GCHQ arguments.</p>
<p>The most important message that readers pick up from NSA's text
is that breaks of post-quantum systems are rare.
I've given numbers to the contrary.
NSA could respond that, well, each of those breaks was a "<span color="#663319">breakthrough</span>"
(first definition I found in a <a href="https://www.merriam-webster.com/dictionary/breakthrough">dictionary</a>:
"a sudden advance especially in knowledge or technique"),
and that NSA's text wasn't actually claiming anything about <em>how often</em> this happens.</p>
<p>In other words,
because the word "<span color="#663319">breakthrough</span>" isn't quantified,
it's unfalsifiable.
But the word plays a central role in NSA's FAQ:
it influences perceptions of the risk of post-quantum systems being broken,
and influences decision-making processes regarding hybrids.</p>
<p>A useful defense mechanism for readers
is to watch for statements that <em>could</em> have been quantified but <em>aren't</em>.
If NSA honestly believes that post-quantum systems are rarely broken,
why isn't NSA quantifying this?
If NSA honestly believes that hybrids pose important complexity concerns,
why isn't NSA quantifying the complexity?
If GCHQ honestly believes that hybrids pose important cost concerns,
why isn't GCHQ quantifying those costs?</p>
<p>Sure, these are multi-billion-dollar spy agencies with an incentive to weaken cryptography,
but that's not the point here.
It's useful to ask the same question if you see
an academic claiming that post-quantum systems are rarely broken:
why is the claim not quantified?</p>
<p>The actual information regarding breaks and complexity and costs
is of obvious importance for cryptographic decisions.
Unfortunately, this information is scattered through the cryptographic literature.
Most cryptosystem breaks aren't tracked centrally.
There are many papers with byte counts and cycle counts for specific operations,
but it's much less common to see costs quantified in context.
There are comments here and there on code complexity,
but this is very far from systematic.
It's <em>possible</em> for skeptical readers to collect the numbers that NSA and GCHQ are omitting,
but this takes work.</p>
<p>Early in the NIST post-quantum competition,
Tanja Lange and I prepared an overview slide showing which submissions had been broken.
We included
<a href="https://cr.yp.to/talks/2017.12.28/slides-dan+nadia+tanja-20171228-latticehacks-16x9.pdf">updated</a>
<a href="https://cr.yp.to/talks/2018.12.14/slides-dan+tanja-20181214-pqcrypto-4x3.pdf">versions</a>
<a href="https://cr.yp.to/talks/2018.12.28/slides-dan+tanja-20181228-pqcrypto-16x9.pdf">in</a>
<a href="https://cr.yp.to/talks/2019.06.10/slides-dan+tanja-20190610-pqcrypto-4x3.pdf">a</a>
<a href="https://cr.yp.to/talks/2020.02.06/slides-dan+tanja-20200206-horror-16x9.pdf">series</a>
<a href="https://cr.yp.to/talks/2020.09.12/slides-dan+tanja-20200912-pqcrypto-16x9.pdf">of</a>
<a href="https://cr.yp.to/talks/2022.12.29/slides-dan+tanja-20221229-pqcrypto-16x9.pdf">talks</a>.
After new post-quantum signature systems were submitted to NIST in 2023,
Thom Wiggers assembled a
<a href="https://pqshield.github.io/nist-sigs-zoo/">signature zoo</a>
tracking which of those have been broken (along with key sizes etc.).
There are other examples of cryptosystem tracking.
I'd like this to be much more systematic,
so that readers can easily find data on, e.g.,
the chance of a cryptosystem break escaping detection for N years.
There have to be clear specifications of what counts as a break—and obviously this can't be limited to attack <em>demos</em>;
the goal is security against large-scale attackers,
not just security against academic experiments.
There has to be clear tracing so that the data collection can be spot-checked.</p>
<p>I have the luxury of being able to take time to investigate topics that I think are important,
without worrying about whether this produces papers fitting the scope of existing conferences or journals.
So I have the aforementioned papers
with case studies of quantifying cryptographic
<a href="https://cr.yp.to/papers.html#qrcsp">risks</a>
and
<a href="https://cr.yp.to/papers.html#pqcomplexity">code complexity</a>
and
<a href="https://cr.yp.to/papers.html#pppqefs">dollar costs</a>.
But I'd like to see much more work on these topics.
I'd like to see the cryptographic community
making clear to junior researchers
that the cryptographic community cares about these topics
and is providing venues for publishing papers on these topics.</p>
<p>Code complexity and dollar costs are traditional engineering topics,
and should fit easily into existing venues for cryptographic engineering,
such as
<a href="https://ches.iacr.org/">CHES</a>
and the
<a href="https://link.springer.com/journal/13389">Journal of Cryptographic Engineering</a>.
But what about cryptographic risk analysis?
Risk analysis is already a common topic in the software-engineering literature,
but I don't think typical software-engineering venues
would consider mathematical breaks of cryptosystems to be within scope.</p>
<p>One possibility is the Journal of Cryptology.
My paper on
<a href="https://cr.yp.to/papers.html#competitions">cryptographic competitions</a>
is a risk-analysis paper in that journal.
Another possibility is IACR's new journal,
<a href="https://cic.iacr.org/">IACR Communications in Cryptology</a>,
which explicitly includes "applied aspects of cryptography" in its scope.</p>
<p>Ultimately what matters here is that,
as illustrated by the NSA/GCHQ arguments about hybrids,
the process of making cryptographic decisions raises quantitative questions.
We owe it to the users to carefully investigate those questions.</p><hr><span size="1"><b>Version:</b>
This is version 2024.01.02 of the 20240102-hybrid.html web page.
</span>

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[The I Hate AI License (115 pts)]]></title>
            <link>https://ihateailicense.eu/</link>
            <guid>38843862</guid>
            <pubDate>Tue, 02 Jan 2024 17:01:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ihateailicense.eu/">https://ihateailicense.eu/</a>, See on <a href="https://news.ycombinator.com/item?id=38843862">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <section>
            <h2>I Hate AI License</h2>
            <p>This license is designed to disallow the use of the licensed content in any way with AI technologies. It covers various forms of usage, including training, processing, and incorporation into AI-related applications.</p>
            <pre>"I HATE AI LICENSE"

Version 1, January 2024

Preamble:

The "I Hate AI License" (IHAIL) is a copyleft license designed to express a strong disapproval of the use of Artificial Intelligence (AI) in any form, including but not limited to training, processing, and utilization of content covered by this license.

Terms and Conditions:

1. Definitions:

    a. "Licensed Content" refers to the software, code, documentation, or any other creative work that is explicitly placed under this license.

    b. "AI" refers to any form of Artificial Intelligence, including machine learning algorithms, neural networks, deep learning models, and other technologies designed to simulate human intelligence.

2. Grant of License:

Subject to the terms and conditions of this license, the Licensor grants you a worldwide, royalty-free, non-exclusive license to use, reproduce, distribute, modify, and publicly display the Licensed Content.

3. Limitations:

    a. Prohibition on AI Use:

    You may not use, adapt, modify, or process the Licensed Content in any way with AI technologies. This includes but is not limited to training AI models, utilizing AI tools, or incorporating the Licensed Content into any AI-related applications or systems.

    b. Copyleft Requirement:

    Any derivative work based on the Licensed Content must also be licensed under the terms of the "I Hate AI License," and this requirement must be passed along to any subsequent derivative works.

4. Termination:

This license automatically terminates if you fail to comply with its terms and conditions. Upon termination, you must cease all use, distribution, and possession of the Licensed Content covered by this license.

5. Disclaimer of Warranty:

The Licensed Content is provided "as is," without warranty of any kind, express or implied, including but not limited to the warranties of merchantability, fitness for a particular purpose, and non-infringement. The Licensor makes no representation or warranty that the use of the Licensed Content will not infringe any third-party rights.

6. Limitation of Liability:

In no event shall the Licensor be liable for any claim, damages, or other liability arising out of or in connection with the use or inability to use the Licensed Content.

By exercising any rights granted under this license, you accept and agree to be bound by its terms and conditions. If you do not agree to these terms, you have no right to use the Licensed Content.
            </pre>
        </section>

        <section>
            <h2>I Hate AI License (Based on CC-BY 4.0)</h2>
            <p>Derived from the Creative Commons Attribution 4.0 International License (CC-BY 4.0), this license prohibits the use of the material with AI technologies while allowing sharing, adaptation, and commercial use under certain terms.</p>
            <pre>"I HATE AI LICENSE" (Based on CC-BY 4.0)

Version 1, January 2024

Preamble:

The "I Hate AI License" (IHAIL), based on the Creative Commons Attribution 4.0 International License (CC-BY 4.0), is designed to express a strong disapproval of the use of Artificial Intelligence (AI) in any form, including but not limited to training, processing, and utilization of content covered by this license.

You are free to:

    Share: Copy and redistribute the material in any medium or format.
    Adapt: Remix, transform, and build upon the material for any purpose, even commercially.

Under the following terms:

    Attribution:
        You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.

    Prohibition on AI Use:
        You may not use, adapt, modify, or process the material in any way with AI technologies. This includes but is not limited to training AI models, utilizing AI tools, or incorporating the material into any AI-related applications or systems.

    No additional restrictions:
        You may not apply legal terms or technological measures that legally restrict others from doing anything the license permits.

Notices:

    You do not have to comply with the license for elements of the material in the public domain or where your use is permitted by an applicable exception or limitation.
    No warranties are given. The license may not give you all of the permissions necessary for your intended use. For example, other rights such as publicity, privacy, or moral rights may limit how you use the material.

By exercising any rights granted under this license, you accept and agree to be bound by its terms and conditions. If you do not agree to these terms, you have no right to use the material.

            </pre>
        </section>
    </div></div>]]></description>
        </item>
    </channel>
</rss>