<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 29 May 2025 21:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Airlines are charging solo passengers higher fares than groups (166 pts)]]></title>
            <link>https://thriftytraveler.com/news/airlines/airlines-charging-solo-travelers-higher-fares/</link>
            <guid>44128901</guid>
            <pubDate>Thu, 29 May 2025 18:39:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thriftytraveler.com/news/airlines/airlines-charging-solo-travelers-higher-fares/">https://thriftytraveler.com/news/airlines/airlines-charging-solo-travelers-higher-fares/</a>, See on <a href="https://news.ycombinator.com/item?id=44128901">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <p>Yesterday, we discovered that <a href="https://thriftytraveler.com/news/airlines/delta-pricing-quirk/" target="_blank" rel="noopener">Delta was charging solo and business travelers higher fares</a> per ticket than when booking for two or more passengers. But it turns out that pricing quirk goes far beyond just Delta.&nbsp;</p>
<p>Since we published that story, we've searched through hundreds of fares and found plenty of examples that prove it: <strong>All three of the country's largest carriers (American Airlines, United Airlines, and Delta) are penalizing solo travelers with higher ticket prices than you can book when traveling with a group – sometimes, significantly higher.</strong></p>
<p>Our&nbsp;<strong><a href="https://thriftytraveler.com/premium/" target="_blank" rel="noopener noreferrer" data-stringify-link="https://thriftytraveler.com/premium/" data-sk="tooltip_parent">Thrifty Traveler Premium</a></strong> team of flight deal analysts search hundreds of routes each day and confirms it's not exactly widespread – you won't see it on each and every route – but it's undeniable. And while it's unclear how long this pricing tactic has been utilized, it doesn't really matter: Whether it's been just days, months, or even years, it's something that few everyday travelers may realize is happening … or how much it might be costing them.</p>
<p>For example, a search for one passenger flying United from its Chicago-O'Hare (ORD) hub to nearby Peoria (PIA) next month yields a $269 one-way fare.&nbsp;</p>

<p><img fetchpriority="high" decoding="async" src="https://thriftytraveler.com/wp-content/uploads/2025/05/ord-pia-1-pax.jpg" alt="united flight from chicago to peoria for $269" width="750" height="389" title="Exclusive: US Airlines Are Quietly Hitting Solo &amp; Biz Travelers with Higher Fares 1" srcset="https://thriftytraveler.com/wp-content/uploads/2025/05/ord-pia-1-pax.jpg 1872w, https://thriftytraveler.com/wp-content/uploads/2025/05/ord-pia-1-pax-300x156.jpg 300w, https://thriftytraveler.com/wp-content/uploads/2025/05/ord-pia-1-pax-1024x532.jpg 1024w, https://thriftytraveler.com/wp-content/uploads/2025/05/ord-pia-1-pax-768x399.jpg 768w, https://thriftytraveler.com/wp-content/uploads/2025/05/ord-pia-1-pax-1536x798.jpg 1536w" sizes="(max-width: 750px) 100vw, 750px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20750%20389'%3E%3C/svg%3E" data-lazy-srcset="https://thriftytraveler.com/wp-content/uploads/2025/05/ord-pia-1-pax.jpg 1872w, https://thriftytraveler.com/wp-content/uploads/2025/05/ord-pia-1-pax-300x156.jpg 300w, https://thriftytraveler.com/wp-content/uploads/2025/05/ord-pia-1-pax-1024x532.jpg 1024w, https://thriftytraveler.com/wp-content/uploads/2025/05/ord-pia-1-pax-768x399.jpg 768w, https://thriftytraveler.com/wp-content/uploads/2025/05/ord-pia-1-pax-1536x798.jpg 1536w" data-lazy-src="https://thriftytraveler.com/wp-content/uploads/2025/05/ord-pia-1-pax.jpg"></p>

<p>But bump that up to two (or three or even four) passengers, and the price drops by almost a third: <strong>Just $181 apiece for that exact same standard economy ticket.</strong> Plus, a <a href="https://thriftytraveler.com/guides/airlines/united-basic-economy/" target="_blank" rel="noopener">United basic economy</a> fare suddenly appears that's even cheaper – something that wasn't even an option when searching for just one passenger.&nbsp;</p>

<p><img decoding="async" src="https://thriftytraveler.com/wp-content/uploads/2025/05/united-ord-pia-2-pax.jpg" alt="united flights from chicago to peoria for $151" width="750" height="384" title="Exclusive: US Airlines Are Quietly Hitting Solo &amp; Biz Travelers with Higher Fares 2" srcset="https://thriftytraveler.com/wp-content/uploads/2025/05/united-ord-pia-2-pax.jpg 1886w, https://thriftytraveler.com/wp-content/uploads/2025/05/united-ord-pia-2-pax-300x154.jpg 300w, https://thriftytraveler.com/wp-content/uploads/2025/05/united-ord-pia-2-pax-1024x524.jpg 1024w, https://thriftytraveler.com/wp-content/uploads/2025/05/united-ord-pia-2-pax-768x393.jpg 768w, https://thriftytraveler.com/wp-content/uploads/2025/05/united-ord-pia-2-pax-1536x787.jpg 1536w" sizes="(max-width: 750px) 100vw, 750px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20750%20384'%3E%3C/svg%3E" data-lazy-srcset="https://thriftytraveler.com/wp-content/uploads/2025/05/united-ord-pia-2-pax.jpg 1886w, https://thriftytraveler.com/wp-content/uploads/2025/05/united-ord-pia-2-pax-300x154.jpg 300w, https://thriftytraveler.com/wp-content/uploads/2025/05/united-ord-pia-2-pax-1024x524.jpg 1024w, https://thriftytraveler.com/wp-content/uploads/2025/05/united-ord-pia-2-pax-768x393.jpg 768w, https://thriftytraveler.com/wp-content/uploads/2025/05/united-ord-pia-2-pax-1536x787.jpg 1536w" data-lazy-src="https://thriftytraveler.com/wp-content/uploads/2025/05/united-ord-pia-2-pax.jpg"></p>

<p>You can see in the fine print below each fare exactly how United is doing this: by opening up different fare buckets based upon how many passengers you're booking for. When searching for one passenger, the lowest economy price is a Q economy fare – United's “discount coach” fare. But by searching for multiple travelers, you can pull in (even cheaper) S class fares, which United considers a “deep discount coach” ticket.</p>
<p>And much like Delta, this isn't a glitch. United spells it all out in the fare rules for these cheaper tickets, which are publicly accessible using an advanced airfare search engine like <a href="https://oldmatrix.itasoftware.com/" target="_blank" rel="nofollow noopener">ITA Matrix</a>. It plainly states: “Must be accompanied on all sectors in same compartment by at least 1 adult 15 or older.”</p>

<p><img decoding="async" src="https://thriftytraveler.com/wp-content/uploads/2025/05/ord-pia-fare-rules.jpg" alt="fare rules for united flight from chicago to peoria" width="750" height="190" title="Exclusive: US Airlines Are Quietly Hitting Solo &amp; Biz Travelers with Higher Fares 3" srcset="https://thriftytraveler.com/wp-content/uploads/2025/05/ord-pia-fare-rules.jpg 1144w, https://thriftytraveler.com/wp-content/uploads/2025/05/ord-pia-fare-rules-300x76.jpg 300w, https://thriftytraveler.com/wp-content/uploads/2025/05/ord-pia-fare-rules-1024x260.jpg 1024w, https://thriftytraveler.com/wp-content/uploads/2025/05/ord-pia-fare-rules-768x195.jpg 768w" sizes="(max-width: 750px) 100vw, 750px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20750%20190'%3E%3C/svg%3E" data-lazy-srcset="https://thriftytraveler.com/wp-content/uploads/2025/05/ord-pia-fare-rules.jpg 1144w, https://thriftytraveler.com/wp-content/uploads/2025/05/ord-pia-fare-rules-300x76.jpg 300w, https://thriftytraveler.com/wp-content/uploads/2025/05/ord-pia-fare-rules-1024x260.jpg 1024w, https://thriftytraveler.com/wp-content/uploads/2025/05/ord-pia-fare-rules-768x195.jpg 768w" data-lazy-src="https://thriftytraveler.com/wp-content/uploads/2025/05/ord-pia-fare-rules.jpg"></p>

<p>There's no such “accompaniment restriction” on United's higher-priced single traveler fares.</p>
<p>Whether you'll run into pricier fares searching for one passenger instead of two is hit-or-miss, at least for now. So far, we've seen this pricing dynamic mainly on one-way domestic tickets – not roundtrip fares or long-haul international routes. And we haven't seen it on other major U.S. carriers like Alaska, JetBlue, or Southwest.</p>
<p>Airlines are notoriously secretive about the inner workings of how they price their fares and why. Case in point: <strong>No one from American, Delta, or United responded to requests for comment from Thrifty Traveler on this pricing strategy.&nbsp;</strong></p>
<p>In this case, the rationale for charging solo travelers more is fairly clear: It's just another way for airlines to continue “segmenting” their customers, charging business travelers paying with a corporate card more while offering a better deal to families on the exact same flight.</p>
<p>And it's even more egregious on this American Airlines flight from Charlotte (CLT) to Fort Myers (RSW) this fall. Traveling solo, you'll pay at least $422 fare for this one-way flight in economy on Oct. 13.&nbsp;</p>

<p><img decoding="async" src="https://thriftytraveler.com/wp-content/uploads/2025/05/aa-clt-rsw-1-pax.jpg" alt="american airlines flight from charlotte to fort myers for $422" width="750" height="560" title="Exclusive: US Airlines Are Quietly Hitting Solo &amp; Biz Travelers with Higher Fares 4" srcset="https://thriftytraveler.com/wp-content/uploads/2025/05/aa-clt-rsw-1-pax.jpg 1652w, https://thriftytraveler.com/wp-content/uploads/2025/05/aa-clt-rsw-1-pax-300x224.jpg 300w, https://thriftytraveler.com/wp-content/uploads/2025/05/aa-clt-rsw-1-pax-1024x765.jpg 1024w, https://thriftytraveler.com/wp-content/uploads/2025/05/aa-clt-rsw-1-pax-768x574.jpg 768w, https://thriftytraveler.com/wp-content/uploads/2025/05/aa-clt-rsw-1-pax-1536x1147.jpg 1536w" sizes="(max-width: 750px) 100vw, 750px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20750%20560'%3E%3C/svg%3E" data-lazy-srcset="https://thriftytraveler.com/wp-content/uploads/2025/05/aa-clt-rsw-1-pax.jpg 1652w, https://thriftytraveler.com/wp-content/uploads/2025/05/aa-clt-rsw-1-pax-300x224.jpg 300w, https://thriftytraveler.com/wp-content/uploads/2025/05/aa-clt-rsw-1-pax-1024x765.jpg 1024w, https://thriftytraveler.com/wp-content/uploads/2025/05/aa-clt-rsw-1-pax-768x574.jpg 768w, https://thriftytraveler.com/wp-content/uploads/2025/05/aa-clt-rsw-1-pax-1536x1147.jpg 1536w" data-lazy-src="https://thriftytraveler.com/wp-content/uploads/2025/05/aa-clt-rsw-1-pax.jpg"></p>

<p>But by searching for two passengers, <strong>the ticket cost drops to just $266 per person </strong>– and, again, even cheaper if you book an <a href="https://thriftytraveler.com/guides/airlines/american-airlines-basic-economy/" target="_blank" rel="noopener">American basic economy</a>&nbsp; fare.</p>

<p><img decoding="async" src="https://thriftytraveler.com/wp-content/uploads/2025/05/aa-clt-rsw-2-pax.jpg" alt="american airlines flights from charlotte to fort myers for two" width="750" height="558" title="Exclusive: US Airlines Are Quietly Hitting Solo &amp; Biz Travelers with Higher Fares 5" srcset="https://thriftytraveler.com/wp-content/uploads/2025/05/aa-clt-rsw-2-pax.jpg 1650w, https://thriftytraveler.com/wp-content/uploads/2025/05/aa-clt-rsw-2-pax-300x223.jpg 300w, https://thriftytraveler.com/wp-content/uploads/2025/05/aa-clt-rsw-2-pax-1024x762.jpg 1024w, https://thriftytraveler.com/wp-content/uploads/2025/05/aa-clt-rsw-2-pax-768x572.jpg 768w, https://thriftytraveler.com/wp-content/uploads/2025/05/aa-clt-rsw-2-pax-1536x1143.jpg 1536w" sizes="(max-width: 750px) 100vw, 750px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20750%20558'%3E%3C/svg%3E" data-lazy-srcset="https://thriftytraveler.com/wp-content/uploads/2025/05/aa-clt-rsw-2-pax.jpg 1650w, https://thriftytraveler.com/wp-content/uploads/2025/05/aa-clt-rsw-2-pax-300x223.jpg 300w, https://thriftytraveler.com/wp-content/uploads/2025/05/aa-clt-rsw-2-pax-1024x762.jpg 1024w, https://thriftytraveler.com/wp-content/uploads/2025/05/aa-clt-rsw-2-pax-768x572.jpg 768w, https://thriftytraveler.com/wp-content/uploads/2025/05/aa-clt-rsw-2-pax-1536x1143.jpg 1536w" data-lazy-src="https://thriftytraveler.com/wp-content/uploads/2025/05/aa-clt-rsw-2-pax.jpg"></p>

<p>One last example shows airlines know what their competitors are up to. Searching for one-way flights from Chicago-O'Hare (ORD) to Lexington (LEX) in Kentucky, <a href="https://thriftytraveler.com/guides/google-flights/" target="_blank" rel="noopener">Google Flights</a> shows you can book either American or United for $214.</p>

<p><img decoding="async" src="https://thriftytraveler.com/wp-content/uploads/2025/05/ord-to-lex-1-pax.jpg" alt="google flights screenshot of flights from chicago to lexington" width="750" height="489" title="Exclusive: US Airlines Are Quietly Hitting Solo &amp; Biz Travelers with Higher Fares 6" srcset="https://thriftytraveler.com/wp-content/uploads/2025/05/ord-to-lex-1-pax.jpg 1590w, https://thriftytraveler.com/wp-content/uploads/2025/05/ord-to-lex-1-pax-300x195.jpg 300w, https://thriftytraveler.com/wp-content/uploads/2025/05/ord-to-lex-1-pax-1024x667.jpg 1024w, https://thriftytraveler.com/wp-content/uploads/2025/05/ord-to-lex-1-pax-768x500.jpg 768w, https://thriftytraveler.com/wp-content/uploads/2025/05/ord-to-lex-1-pax-1536x1001.jpg 1536w" sizes="(max-width: 750px) 100vw, 750px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20750%20489'%3E%3C/svg%3E" data-lazy-srcset="https://thriftytraveler.com/wp-content/uploads/2025/05/ord-to-lex-1-pax.jpg 1590w, https://thriftytraveler.com/wp-content/uploads/2025/05/ord-to-lex-1-pax-300x195.jpg 300w, https://thriftytraveler.com/wp-content/uploads/2025/05/ord-to-lex-1-pax-1024x667.jpg 1024w, https://thriftytraveler.com/wp-content/uploads/2025/05/ord-to-lex-1-pax-768x500.jpg 768w, https://thriftytraveler.com/wp-content/uploads/2025/05/ord-to-lex-1-pax-1536x1001.jpg 1536w" data-lazy-src="https://thriftytraveler.com/wp-content/uploads/2025/05/ord-to-lex-1-pax.jpg"></p>

<p>Yet the <strong>total price</strong> for two passengers is $215, or just $108 per passenger. Importantly, Google Flights always displays the total price for all passengers – not the cost per ticket. And while that cheapest fare is a basic economy ticket on both carriers, standard economy fares are still considerably cheaper when booking for two instead of just one.</p>

<p><img decoding="async" src="https://thriftytraveler.com/wp-content/uploads/2025/05/ord-to-lex-2-pax.jpg" alt="chicago to lexington flights for two passengers" width="750" height="492" title="Exclusive: US Airlines Are Quietly Hitting Solo &amp; Biz Travelers with Higher Fares 7" srcset="https://thriftytraveler.com/wp-content/uploads/2025/05/ord-to-lex-2-pax.jpg 1590w, https://thriftytraveler.com/wp-content/uploads/2025/05/ord-to-lex-2-pax-300x197.jpg 300w, https://thriftytraveler.com/wp-content/uploads/2025/05/ord-to-lex-2-pax-1024x672.jpg 1024w, https://thriftytraveler.com/wp-content/uploads/2025/05/ord-to-lex-2-pax-768x504.jpg 768w, https://thriftytraveler.com/wp-content/uploads/2025/05/ord-to-lex-2-pax-1536x1009.jpg 1536w" sizes="(max-width: 750px) 100vw, 750px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20750%20492'%3E%3C/svg%3E" data-lazy-srcset="https://thriftytraveler.com/wp-content/uploads/2025/05/ord-to-lex-2-pax.jpg 1590w, https://thriftytraveler.com/wp-content/uploads/2025/05/ord-to-lex-2-pax-300x197.jpg 300w, https://thriftytraveler.com/wp-content/uploads/2025/05/ord-to-lex-2-pax-1024x672.jpg 1024w, https://thriftytraveler.com/wp-content/uploads/2025/05/ord-to-lex-2-pax-768x504.jpg 768w, https://thriftytraveler.com/wp-content/uploads/2025/05/ord-to-lex-2-pax-1536x1009.jpg 1536w" data-lazy-src="https://thriftytraveler.com/wp-content/uploads/2025/05/ord-to-lex-2-pax.jpg"></p>

<p>Whenever this pricing strategy began, this is a massive change in how airlines set prices – and one that will likely catch many travelers off guard.&nbsp;</p>
<p>Unlike shopping at retail stores or Costco, bulk discounts are unusual for airlines – at least not just for booking just two passengers instead of one. And these higher fares for one passenger are&nbsp;the opposite of what we typically see, where travelers booking for two passengers or more wind up getting charged more per person than a single passenger.</p>
<p>That comes down to the mechanics of how airlines actually sell tickets: Carriers aren't just selling economy, extra legroom, and first class tickets but an alphabet soup of different fare classes, each at a different price. If there's only one fare available at the cheapest $118, searching for two would only yield fares at a higher, $199 price point.</p>
<p>This is a complete reversal. And solo travelers will be the ones who pay the price.&nbsp;</p>

<p><em>This is a breaking news story, check back for updates</em></p>
  </div><div>
      <h2>Stop Overpaying for Travel!</h2>
      <p>Get our daily email for the latest in travel, flight deals, and how to save on your next trip.</p>
      
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FLUX.1 Kontext (149 pts)]]></title>
            <link>https://bfl.ai/models/flux-kontext</link>
            <guid>44128322</guid>
            <pubDate>Thu, 29 May 2025 17:40:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bfl.ai/models/flux-kontext">https://bfl.ai/models/flux-kontext</a>, See on <a href="https://news.ycombinator.com/item?id=44128322">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="abstract"><h2>Play. Create. Manipulate.</h2><p>FLUX.1 Kontext models go beyond text-to-image. Unlike previous flow models that only allow for pure text based generation, FLUX.1 Kontext models also understand and can create from existing images. With FLUX.1 Kontext you can modify an input image via simple text instructions, enabling flexible and instant image editing - no need for finetuning or complex editing workflows. The core capabilities of the the FLUX.1 Kontext suite are:</p><div><div><h3>Character consistency</h3><p>Preserve unique elements of an image, such as a reference character or object in a picture, across multiple scenes and environments.</p></div><div><h3>Local editing</h3><p>Make targeted modifications of specific elements in an image without affecting the rest.</p></div><div><h3>Style Reference</h3><p>Generate novel scenes while preserving unique styles from a reference image, directed by text prompts.</p></div><div><h3>Interactive Speed</h3><p>Iterate at minimal latency for both image generation and editing.</p></div></div><p>Flux.1 Kontext allows you to iteratively add more instructions and build on previous edits, refining your creation step-by-step with minimal latency, while preserving image quality and character consistency.</p></div><div id="get-started"><div><h2>Get started with FLUX.1 Kontext</h2><p>Redefine what's possible with consistent, context-aware image generation</p></div><div><div><h2>FLUX.1 Kontext [max]</h2><p>Maximum Performance at High Speed</p><p>Our new premium model brings maximum performance across all aspects – greatly improved prompt adherence and typography generation meet premium consistency for editing without compromise on speed.</p></div><div><h2>FLUX.1 Kontext [pro]</h2><p>A pioneer for fast, iterative image editing</p><p>A unified model delivering local editing, generative modifications, and text-to-image generation in FLUX.1 quality. Processes text and image inputs for precise regional edits or full scene transformations at breakthrough speeds, pioneering iterative workflows that maintain character consistency across multiple editing turns.</p></div><div><h2>FLUX.1 Kontext [dev]</h2><p>Open-weights, distilled variant of Kontext, our most advanced generative image editing model.</p></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Human coders are still better than LLMs (217 pts)]]></title>
            <link>https://antirez.com/news/153</link>
            <guid>44127739</guid>
            <pubDate>Thu, 29 May 2025 16:41:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://antirez.com/news/153">https://antirez.com/news/153</a>, See on <a href="https://news.ycombinator.com/item?id=44127739">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article data-comment-id="153-" id="153-"><span><span><a href="https://antirez.com/user/antirez">antirez</a></span> 1 hour ago. 17444 views.  </span><pre>This is a short story of how humans are still so much more capable of LLMs. Note that I'm not anti-AI or alike, you know it if you know me / follow me somewhere. I use LLMs routinely, like I did today, when I want to test my ideas, for code reviews, to understand if there are better approaches than what I had in mind, to explore stuff at the limit of my expertise, and so forth (I wrote a blog post about coding with LLMs almost two years, when it was not exactly cool: I was already using LLMs for coding and never stopped, I'll have to write an update, but that's not the topic of this post).

But, still: the current level of AI is useful, great too, but so incredibly behind human intelligence, and I want to remark this as lately it is impossible to have balanced conversations.

So, today I was working to Vector Sets for Redis, to fix a complicated bug: during the time I stopped working at Redis my colleagues introduced resistance against corruption RDB and RESTORE payloads, even when the checksum of the data passes. This feature is disabled by default, but provides an enhanced layer of safety for people wanting it.

But… there is a but as big as an elephant: In order to make HNSWs fast to save into Redis RDBs and to load back, I serialized the *graph* representation, and not the element-vector pairs, otherwise I would have to re-insert back data into HNSWs, and that would be, like, 100 times slower (!). So I store all the links the nodes have with other nodes, as integers, and then I resolve them into pointers, it’s a nice trick and works great. But if you mix this and random corruptions of the representation, and the fact that my own twist on HNSWs enforce reciprocal links between nodes (I wrote my own implementation of HNSWs with many useful features, but reciprocal links are needed to enable many of them) then this could happen:

1. We load corrupted data that says A links to B, but B no longer links to A (corrupted node IDs).
2. We delete node B: since the reciprocity is violated, we don’t clear the link from A to B.
3. Then we scan the graph and once we are at B we access A: use-after-free :-D :-) :-|

So after loading data, I need to check that every link is reciprocal, and in the vanilla case this is going to be O(N^2), for each node we need to scan all the levels, for each level all the neighbors of the node, and check that it also links to this node by scanning its links at that level. Not good.

# Human vs LLM

To start, I implemented the vanilla approach, to see if the fuzzer could no longer find the bug, and it worked indeed, but loading times for a big vector set with 20 million vectors went from 45 seconds to 90 or something. WTF. So I opened a Gemini 2.5 PRO chat and told the LLM, hey, what we can do here? Is there a super fast way to do so?

The best solution that Gemini could find was to say: order the pointers of the neighbors links, so you can use binary search. Oh, well, sure, I know this, I’m not really sure if in arrays of 16/32 pointers this is going to be faster or slower. So I asked, anything else? Nope, no better solution.

So I told it: look, what about when we see A linking B at level X we store in a hash table A:B:X (but we sort A and B always so that A&gt;B, and links are the same whatever the direction), and when we see the link again we clean it, this time we just scan the whole thing as we are already doing when resolving IDs to pointers in the links, and if at the end the hash table is not empty, we know there is some link that must be non-reciprocal?

Gemini told me it was a nice idea, but there was the snprintf() to create the key and the hashing time and so forth, but yep, it was better than what my original approach (even sorting pointers). I made it notice that snprintf() was not needed. We could just memcpy() pointers in a fixed sized key. It recognized that it was possible to do so, then I realized something…

Hey, I told Gemini, what about using a fixed accumulator for A:B:X? No hash table at all. Each time we see a link (A:B:X, so 8+8+4 bytes) we xor it in the current accumulator of 12 bytes. If we store it twice, it cancels out, so at the end if the register is non-zero, we know something is odd! However I anticipated Gemini that this system was potentially subject to collisions, and to evaluate them. Even if this feature is normally turned off in Redis, when users enable such extra checks they also often expect some more protection against an attacker deliberately crafting bad payloads.

Gemini was quite impressed about the idea, but still told that pointers are… you know, similar in structure, change of a few bits, so if there were three spurious links L1, L2, L3 it could happen that the xor between L1 and L2 was the same as the L3 bits, and we could have a false negative (zero register). I also noticed that allocators tend to be very predictable and externally guessable.

I asked Gemini for ways to improve upon this: it got no great ideas. Then I thought, wait, we can actually hash this with a good enough hash function that is still fast, murmur-128 or alike (we don’t need it to have cryptographic properties for this task), and proposed the following schema to Gemini:

1. Take the link A:B:X, but use a seed obtained via /dev/urandom to prefix all the keys with it, so we actually have S:A:B:X.
2. We just xor the output of murmur-128(S:A:B:X) into the 128 bit register.
3. At the end, we check if the register is 0 (all links reciprocal).

I asked Gemini to do an analysis of that, and it was finally happy, saying that this makes it a lot harder both to casually find orphaned links that happen to xor to 0 together, and even that an external attacker could ever use this in a useful way, since “S” is not known, there is to control the pointers too, and all that it is really hard to put together. Also, this feature is a best effort extra protection that you need to enable, it is normally off and to be practical it should not pose a too big performance penalty.

Well, all this to say: I just finished the analysis and stopped to write this blog post, I’m not sure if I’m going to use this system (but likely yes), but, the creativity of humans still have an edge, we are capable of really thinking out of the box, envisioning strange and imprecise solutions that can work better than others. This is something that is extremely hard for LLMs. Still, to verify all my ideas, Gemini was very useful, and maybe I started to think at the problem in such terms because I had a “smart duck” to talk with.</pre></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[WeatherStar 4000+: Weather Channel Simulator (361 pts)]]></title>
            <link>https://weatherstar.netbymatt.com/</link>
            <guid>44127109</guid>
            <pubDate>Thu, 29 May 2025 15:38:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://weatherstar.netbymatt.com/">https://weatherstar.netbymatt.com/</a>, See on <a href="https://news.ycombinator.com/item?id=44127109">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="loading" width="640" height="480"><p>WeatherStar 4000+</p><p>v5.21.2</p><p>Enter your location above to continue</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I wrote a modern Command Line Handbook (196 pts)]]></title>
            <link>https://commandline.stribny.name/</link>
            <guid>44126612</guid>
            <pubDate>Thu, 29 May 2025 14:44:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://commandline.stribny.name/">https://commandline.stribny.name/</a>, See on <a href="https://news.ycombinator.com/item?id=44126612">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <h2>The command line is for everyone</h2>
          <p>
            Software developers, sysadmins, tech workers, and regular Linux/macOS
            users all use the modern Unix/Linux command-line shells to get things
            done. What about you?
          </p>
          <h2>You don't have to read the entire shell manual</h2>
          <p>
            You don't have to read the entire shell manual or study bulky Linux
            bibles to get going. Understand the most common concepts and commands
            quickly instead with this short handbook.
          </p>
          <h2>It's not just about the shell</h2>
          <p>
            Terminals, shells, command-line applications, and shell scripting.
            Don't learn things separately when you can learn them together. Tips and tricks included.
          </p>
          <h2>Run commands with confidence</h2>
          <p>More than one hundred annotated shell sessions and code examples to explore and follow along. If this
            doesn't change your approach to the command line, nothing will.
          </p>
          <h2>Fresh out of press</h2>
          <p>This handbook is a culmination of 4 years of learning, writing, and rewriting. Updated in 2025 to
            be the best guidebook that you can get this year.
          </p>
          <h2>
            5700+ readers
          </h2>
          <p>
            You are in good company. Join more than five thousand others
            sharpening their command line skills with this handbook.
          </p> 
        </div><div>
          <h2>From the author</h2>
          <p>
            I have been a long-time Linux and command-line user, but I didn't always use the command line to its full potential.
            Partially because I didn't know what I was missing and partially because the world of shells and terminals has evolved so much over the years.
          </p>
          <p>
            I designed this book to showcase the most essential things in the shortest possible time. The book will introduce you to the efficient usage of the command line, shells like Bash and Zsh, scripting, and many classic and modern programs that are available for the terminal today.
          </p>
          <p>
            You will get a beautiful, carefully curated PDF with almost 100 syntax-highlighted and annotated shell sessions and other examples. My hope
            is that you will be able to get that satisfying feeling of using the command line to its full potential.
          </p>
          <p>– Petr Stribny</p>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nova: A JavaScript and WebAssembly engine written in Rust (108 pts)]]></title>
            <link>https://trynova.dev/</link>
            <guid>44126264</guid>
            <pubDate>Thu, 29 May 2025 14:05:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://trynova.dev/">https://trynova.dev/</a>, See on <a href="https://news.ycombinator.com/item?id=44126264">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2>Welcome!</h2><p>Nova is a JavaScript (<a href="https://tc39.es/ecma262/">ECMAScript</a>) and <a href="https://webassembly.org/">WebAssembly</a> engine written in Rust and following <a href="https://en.wikipedia.org/wiki/Data-oriented_design">data-oriented design principles</a>. It is currently nothing more than a fun experiment to learn and to prove the viability of such an engine, but may very well become something much more in the future.</p><p>The engine is still very limited in it's capabilities only passing about <a href="https://trynova.dev/test262">70% of the test262 test suite</a>. However development is ongoing and we are quickly improving the engine. If you are interested in the project, please check out the <a href="https://github.com/trynova/nova">GitHub repository</a> and or join our <a href="https://discord.gg/bwY4TRB8J7">Discord server</a> where the core team resides and where we discuss development.</p><section><h2>Latest Blog Posts</h2><ul><li><a href="https://trynova.dev/blog/working-for-the-internet">Working for the Internet</a><time datetime="2025-05-08">2025-05-08</time></li><li><a href="https://trynova.dev/blog/guide-to-nova-gc">Guide to Nova's garbage collector</a><time datetime="2025-03-14">2025-03-14</time></li><li><a href="https://trynova.dev/blog/memory-hell">Memory hell</a><time datetime="2025-02-23">2025-02-23</time></li><li><a href="https://trynova.dev/blog/fosdem-2025">FOSDEM 2025</a><time datetime="2025-02-16">2025-02-16</time></li><li><a href="https://trynova.dev/blog/year-end-2024">2024 - Looking backwards and forwards</a><time datetime="2024-12-30">2024-12-30</time></li><a href="https://trynova.dev/blog">View all posts</a></ul></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Learning C3 (175 pts)]]></title>
            <link>https://alloc.dev/2025/05/29/learning_c3</link>
            <guid>44125966</guid>
            <pubDate>Thu, 29 May 2025 13:33:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://alloc.dev/2025/05/29/learning_c3">https://alloc.dev/2025/05/29/learning_c3</a>, See on <a href="https://news.ycombinator.com/item?id=44125966">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <div id="introduction">
            <h2> 2025-05-29 # Learning C3 </h2>
            <p>
                In this article, I describe my experience learning the <a href="https://c3-lang.org/" target="_blank">C3</a> programming language.
            </p>
            <p>
                I've always been an avid computer programmer. I would say that I am most familiar with low level systems
                languages, though I have dipped into other programming languages from time to time. My journey here is
                motivated by curiosity. I am always curious to try new programming languages, which has resulted in
                learning a dozen or so within the past few years.
            </p>
            <p>
                With each new programming language I learn, I encounter a never-before-seen paradigm. Each language has
                it's own method of expressing ideas, and it's own status-quo for solving problems. I hope to learn what
                this means for C3, and what projects I would be likely to use it for.
            </p>
            <p>
                Here's the disclaimer: I'm writing this article in "real-time", which is to say I am typing it up as I
                am learning C3. This means that I may have added insights about pain points and neat features that get
                glossed over or forgotten in other articles, yet it may also mean that my explanations and conceptual
                grasp of the language is reduced or faulty compared to other sources.
            </p>
        </div>

        <div id="contents">
            <h2> Contents: </h2>
            <ol>
                <li> <a href="#what_is_c3"> What is C3? </a> </li>
                <li> <a href="#language_overview"> Language Overview </a> </li>
                <ol>
                    <li> <a href="#hello_world"> Hello World </a> </li>
                    <li> <a href="#foreach_loops"> <code> foreach </code> loops </a> </li>
                    <li> <a href="#while_loops"> <code> while </code> loops </a> </li>
                    <li> <a href="#enum_and_switch"> <code> enum </code> and <code> switch </code> </a> </li>
                    <li> <a href="#defer_keyword"> <code> defer </code> keyword </a> </li>
                    <li> <a href="#struct_type"> <code> struct </code> types </a> </li>
                    <li> <a href="#error_handling"> Error handling </a> </li>
                    <li> <a href="#contracts"> Contracts </a> </li>
                    <li> <a href="#struct_methods"> <code> struct </code> methods </a> </li>
                    <li> <a href="#macros"> <code>macro</code>s </a> </li>
                    <li> <a href="#type_properties"> Type Properties </a> </li>
                    <li> <a href="#base64_strings"> Base64 &amp; Hex Literals</a> </li>
                    <li> <a href="#primitives"> Primitives </a> </li>
                    <li> <a href="#much_more"> Much More </a> </li>
                </ol>
                <li> <a href="#first_steps"> First Steps </a> </li>
                <ol>
                    <li> <a href="#installing_c3"> Installing C3 </a> </li>
                    <li> <a href="#new_project"> Creating a new project </a> </li>
                </ol>
                <li> <a href="#making_calculator"> Making a calculator with C3 </a> </li>
                <ol>
                    <li> <a href="#what_for_calc"> What will this require? </a> </li>
                    <li> <a href="#getting_input"> Getting user input </a> </li>
                    <li> <a href="#tokenizer"> The tokenizer </a> </li>
                    <li> <a href="#parser"> The parser </a> </li>
                </ol>
                <li> <a href="#conclusion"> Conclusion </a> </li>
            </ol>
        </div>

        <div id="what_is_c3">
            <h2> What is C3? </h2>
            <p>
                According to the C3 website, C3 aims to build on and with C. It offers ergonomics, optimizations, and
                features. Some of these features may be difficult or impossible to express in standard C. These features
                include a module system, operator overloading, generics, compile time execution, semantic macros,
                an integrated build system, error handling, <code>defer</code>, value methods, associated enum data,
                distinct types &amp; subtypes, gradual contracts, built-in slices, <code>foreach</code>, dynamic calls &amp;
                types, <a href="https://c3-lang.org/getting-started/" target="_blank">and more</a>.
            </p>
            <p> Here are two other perspectives on what C3 is: </p>
            <p><img alt="C3 creator: 'C3 is an evolution on C'" src="https://alloc.dev/2025/05/29/c3_desc_1.webp" width="100%">
            <img alt="FoxKiana: 'awesome sauce' and 'epic'" src="https://alloc.dev/2025/05/29/c3_desc_0.webp" width="100%"></p><p> Thank you to FoxKiana and the C3 creator Christoffer Lernö for replying :) </p>
        </div>

        <div id="language_overview">
            <h2> Language Overview: </h2>
            <p>
                It's hard for me to picture what the language is like without clear examples. For this section I will
                review the language reference online and share my thoughts on the language features C3 offers. I will
                not cover each and every feature of C3, as this isn't meant to be an introduction to C3.
            </p>

            <h3 id="hello_world"> Hello World: </h3>
            <pre><code>import std::io;

fn void main()
{
    io::printn("Hello, World!");
}</code></pre>
            <p>
                Hello world seems pretty straightforward. I can immediately see this reminds me of C, although I
                personally prefer having the opening brackets on the same line as the function declaration. In any case,
                it's best to follow the status-quo here as it helps you understand other C3 code, and helps other C3
                developers understand your code.
            </p>
            <p>
                Something to note about importing modules - According to the <a href="https://c3-lang.org/language-fundamentals/modules/#importing-modules" target="_blank">modules
                    page</a>, imports will recursively import submodules. C of course would do the same, and you might
                end up needing to deal with name collisions by renaming things deep down the <code>#include</code>
                chain. C3 fixes the name collision issue by requiring you to use a more full case to resolve collisions.
                For example, you would use <code>abc::Context</code> instead of <code>Context</code> if both imported
                modules <code>abc</code> and <code>de</code> have a structure named <code>Context</code>.
            </p>
            <p>
                I find it curious that the language requires the <code>fn</code> keyword to define the function here. I
                would think that the language could get away with avoiding that keyword like C does. On further thought,
                perhaps it is better to be more explicit that this is a function. Some reasons this may be is that the
                function declaration syntax could be used elsewhere, or C3 could allow nested function declarations. The
                first possibility seems more likely than the second, given that C3 is an evolution of C.
            </p>
            <p>
                The <a href="https://c3-lang.org/standard-library/#void-printx-void-printnx-" target="_blank">standard
                    print function</a> will print most types that are passed to it. That seems pretty nice! Definitely a
                step-up from C here. I can imagine that <code>print</code> debugging works great in this language.
            </p>
            <p>
                Taking a look at <a href="https://c3-lang.org/standard-library/#usz-printfstring-format-args-maydiscard" target="_blank">formatted printing</a>, it seems that C3 resembles C quite a bit here. For the
                <code>printf</code> function, <code>%s</code> is still used for strings, <code>%d</code> is still used
                for decimals, <code>%f</code> is still used for floats. Truly C3 is easing the transition for C
                programmers. Something unique to note here - it seems that the string formatter (<code>%s</code>) can be
                used to format certain non-string types as well - so an enum of type <code>Heat</code> with a value of
                <code>REALLY_WARM</code> would format itself as <code>REALLY_WARM</code> when you use the
                <code>%s</code> formatter.
            </p>

            <h3 id="foreach_loops"> <code> foreach </code> loops: </h3>
            <pre><code>// Prints the values in the slice.
fn void example_foreach(float[] values)
{
    foreach (index, value : values)
    {
        io::printfn("%d: %f", index, value);
    }
}

// Updates each value in the slice by multiplying it by 2.
fn void example_foreach_by_ref(float[] values)
{
    foreach (&amp;value : values)
    {
        *value *= 2;
    }
}</code></pre>
            <p>
                Hold up, hold up. <a href="https://c3-lang.org/implementation-details/specification/#foreach-and-foreach_r-statements" target="_blank">C3 has foreach</a>? That is interesting. According to the docs, <code>break</code>
                and <code>continue</code> work as you would expect. Iteration by reference is accomplished by prepending
                a <code>&amp;</code> (ampersand) to the variable name, as shown in the second example above. To me, foreach
                feels higher level than normal <code>for</code>. Don't misunderstand me - I love using foreach in other
                languages; the added syntax better expresses your intent, reducing logic errors. It did jump out at me
                as "this isn't C" though.
            </p>

            <h3 id="while_loops"> <code> while </code> loops: </h3>
            <pre><code>// while loops are again the same as in C
int a = 10;
while (a &gt; 0)
{
    a--;
}

// while loops can declare variables
while (Point* p = getPoint())
{
    // ..
}</code></pre>
            <p>
                Before C99, you had to declare the <code>for</code> loop variable outside of the <code>for</code> loop.
                As far as I know, you cannot declare variables inside of the <code>while</code> loop condition in C. It
                is nice to see the change here.
            </p>

            <h3 id="enum_and_switch"> <code> enum </code> types and <code> switch </code> statements: </h3>
            <pre><code>enum Height : uint
{
    LOW,
    MEDIUM,
    HIGH,
}

fn void demo_enum(Height h)
{
    switch (h)
    {
        case LOW:
        case MEDIUM:
            io::printn("Not high");
            // Implicit break.
        case HIGH:
            io::printn("High");
    }

    // This also works
    switch (h)
    {
        case LOW:
        case MEDIUM:
            io::printn("Not high");
            // Implicit break.
        case Height.HIGH:
            io::printn("High");
    }

    // Completely empty cases are not allowed
    switch (h)
    {
        case LOW:
            break; // Explicit break required, since switches can't be empty
        case MEDIUM:
            io::printn("Medium");
        case HIGH:
            break;
    }

    // special checking of switching on enum types
    switch (h)
    {
        case LOW:
        case MEDIUM:
        case HIGH:
            break;
        default:    // The compiler warns that all values are already handled
            break;
    }

    // Using "nextcase" will fallthrough to the next case statement,
    // and each case statement starts its own scope.
    switch (h)
    {
        case LOW:
            int a = 1;
            io::printn("A");
            nextcase;
        case MEDIUM:
            int a = 2;
            io::printn("B");
            nextcase;
        case HIGH:
            // a is not defined here
            io::printn("C");
    }
}</code></pre>
            <p>
                C3 resembles C a lot here. I appreciate the implicit <code>break</code> that it offers. I'll have to see
                when I install the compiler, but I feel I would frequently confuse myself here with these implicit /
                explicit <code>break</code> rules. Perhaps C3 would benefit from polarizing itself a bit more. It would
                make more sense to me if all breaks were implicit (requiring <code>nextcase</code> for all multi-case
                scopes), or explicit. That being said, my initial view will surely adapt to fit the language when I
                start writing it for myself.
            </p>
            <p>
                After a short discussion in <a href="https://discord.gg/5WSNhWBxWq" target="_blank">the C3 discord
                    server</a>, (specifically <a href="https://discord.com/channels/650345951868747808/650345952468795425/1376676029258797077" target="_blank">this message</a>,) the power of <code>nextcase</code> was further emphasized:
            </p>
            <pre><code>int n = (count + 7) / 8;
switch (count % 8)
{
  case 0: *to++ = *from++; nextcase;
  case 7: *to++ = *from++; nextcase;
  case 6: *to++ = *from++; nextcase;
  case 5: *to++ = *from++; nextcase;
  case 4: *to++ = *from++; nextcase;
  case 3: *to++ = *from++; nextcase;
  case 2: *to++ = *from++; nextcase;
  case 1: *to++ = *from++; if (--n &gt; 0) nextcase 0;
}</code></pre>
            <p>
                Yes, that is <a href="https://en.wikipedia.org/wiki/Duff's_device" target="_blank">duff's device</a> in
                C3! No ugly hacks here, the <code>nextcase</code> keyword supports a (possibly runtime) case, as if
                <code>switch</code> were a jump table. Additionally, the <code>@jump</code> attribute will force the
                optimizing compiler to turn the switch into a jump table, if it did not already do that. I'm pleased to
                note that C3 had this capability *before* Zig. I wish that more languages had this "jump table" view of
                switch statements.
            </p>

            <h3 id="defer_keyword"> <code> defer </code> keyword: </h3>
            <pre><code>fn void test(int x)
{
    defer io::printn();
    defer io::print("A");
    if (x == 1) return;
    {
        defer io::print("B");
        if (x == 0) return;
    }
    io::print("!");
}

fn void main()
{
    test(1); // Prints "A"
    test(0); // Prints "BA"
    test(10); // Prints "B!A"
}</code></pre>
            <p>
                Ahh, the <a href="https://c3-lang.org/language-overview/examples/#defer" target="_blank">defer</a>
                keyword. I've enjoyed this feature immensely in <a href="https://ziglang.org/" target="_blank">other
                    languages</a>. If you have never worked with <code>defer</code> before, then you are missing out!
                The feature allows for some amazing control flow capabilities. Essentially, all defer statements are
                invoked in reverse order on scope exit. They are primarily used to clean up resources that you have. I
                find the keyword is much easier to remember, as you always put a <code>defer</code> after claiming a
                resource that is only used in the current scope. Without the keyword, you are stuck remembering to clean
                up your resources at every possible scope exit point. In C, this frequently meant that there was a block
                at the end of the function with a <code>goto</code> label for cleaning up function resources. 10x better
                than C here.
            </p>
            <p>
                On further investigation, it seems like the common constructs <code>errdefer</code> and
                <code>okdefer</code> can be represented with <code>defer catch</code> and <code>defer try</code>
                respectively. This will be pleasant to use.
            </p>

            <h3 id="struct_type"> <code> struct </code> types: </h3>
            <pre><code>alias Callback = fn int(char c);

enum Status : int
{
    IDLE,
    BUSY,
    DONE,
}

struct MyData
{
    char* name;
    Callback open;
    Callback close;
    Status status;

    // named sub-structs (x.other.value)
    struct other
    {
        int value;
        int status;   // ok, no name clash with other status
    }

    // anonymous sub-structs (x.value)
    struct
    {
        int value;
        int status;   // error, name clash with other status in MyData
    }

    // anonymous union (x.person)
    union
    {
        Person* person;
        Company* company;
    }

    // named sub-unions (x.either.this)
    union either
    {
        int this;
        bool  or;
        char* that;
    }
}</code></pre>
            <p>
                After a minute or two, it seems more obvious how this works. It appears that the "sub structs" aren't
                types, but an expression for how the data is stored / accessed with the structure. The anonymous
                <code>union</code> inside of the structure is of particular note; it seems to me that they offer a
                really clean way of implenting a <a href="https://en.wikipedia.org/wiki/Tagged_union" target="_blank">tagged union</a>. You would only need to have an <code>enum</code> and anonymous
                <code>union</code> in your struct do do so!
            </p>
            <p>
                C allows you to do essentially the same thing here, but I rarely used unions inside of my structures
                like this. Perhaps I need to <a href="https://www.acepace.net/integerQuiz/" target="_blank">brush up on
                    my C</a>.
            </p>

            <h3 id="error_handling"> Error handling: </h3>
            <p>
                The <a href="https://c3-lang.org/language-common/optionals-essential" target="_blank">error handling
                    page</a> of the C3 website is very thorough. Below I have summarized what I have learned in a
                collection of C3 code snippets:
            </p>
            <pre><code>// Optional types are suffxed with a ?
int? a = 1; // Set the Optional to a result</code></pre>
            <pre><code>// When an Optional is empty it has an Excuse explaining what happened.
int? b = io::FILE_NOT_FOUND?; // Set the Optional to an Excuse type of "fault"</code></pre>
            <pre><code>// Faults are defined using the faultdef keyword
faultdef OOPS, LOTS_OF_OOPS, USER_ERROR;</code></pre>
            <pre><code>// This function returns an Optional integer
fn int? get_value();</code></pre>
            <pre><code>// Return an Excuse by adding '?' after the fault.
return io::FILE_NOT_FOUND?;</code></pre>
            <pre><code>// Check if an Optional is empty with "catch"
if (catch excuse = get_value()) // ...</code></pre>
            <pre><code>// If the scope is escaped after checking an Optional, the variable is
// automatically unwrapped for the remainder of the scope.
int? foo = unreliable_function();
if (catch excuse = foo) return excuse?; // Return excuse with the '?' operator
io::printfn("foo: %s", foo); // foo is guaranteed to be of type "int" here</code></pre>
            <pre><code>int foo = maybe_function()!;
// The rethrow operator "!" above is equivalent to the following:
int? foo = maybe_function();
if (catch excuse = foo) return excuse?;</code></pre>
            <pre><code>// Optionals in expressions produce optionals
int? first_optional = 7;
// "int?" is required for the type below, unless unwrapped (maybe implicitly)
int? second_optional = first_optional + 1;</code></pre>
            <pre><code>// Optionals affect function return types
fn int test(int input) // ... omitted for brevity ...
int? optional_argument = 7;
int? returned_optional = test(optional_argument);
// The fuction is shortcut if any of it's non-Optional arguments can't be so</code></pre>
            <p>
                There's a lot to unpack here. It took me a while to understand how these optional types work. C3 seems
                to combine the roles of "error unions" and "optional types". In Zig this would be
                <code>error{SomeError}!i32</code> and <code>?i32</code>, while in Rust this would be
                <code>Result&lt;i32, SomeError&gt;</code> and <code>Option&lt;i32&gt;</code>.
            </p>
            <p>
                This language decision will impact the way I think about error handling. I typically imagine "optional
                types" in these scenarios:
            </p>
            <ol>
                <li> A function can sometimes return a value. (eg. polling for some data)</li>
                <li> A stateful iterator function needs to mark when it is empty / completed. </li>
                <li> A lookup function fails to find a match. (eg. <code>hashmap.get()</code>) </li>
            </ol>
            <p> I likewise imagine "error unions" in these scenarios: </p>
            <ol>
                <li> A function is expected to return, but can fail. (eg. memory allocation) </li>
                <li> A function requires certain specified input, and reports invalid inputs. </li>
                <li> A property that is assumed to be true is false. (eg. runtime assertions) </li>
            </ol>
            <p>
                With the roles combined, It seems harder to differentiate functions that are *expected* to return a
                value, versus functions that *can* return a value. While this is certainly a con, I would say that one
                pro of this approach is that you can avoid worrying about the distinction of the two split types when
                you are handling the return values of functions.
            </p>

            <h3 id="contracts"> Contracts: </h3>
            <pre><code>&lt;*
 @require foo != null
 @ensure return &gt; foo.x
*&gt;
fn uint check_foo(Foo* foo)
{
    uint y = abs(foo.x) + 1;
    // If we had row: foo.x = 0, then this would be a runtime contract error.
    return y * abs(foo.x);
}</code></pre>
            <p>
                <a href="https://c3-lang.org/language-common/contracts/" target="_blank">C3 has support</a> for <a href="https://en.wikipedia.org/wiki/Precondition" target="_blank">preconditions</a> and <a href="https://en.wikipedia.org/wiki/Postcondition" target="_blank">postconditions</a>. These
                contracts are kept inside of <code>&lt;*</code> and <code>*&gt;</code> symbols. According to the C3
                website, this is a type of comment which is parsed. I have mixed feelings here. I personally think that
                a language only needs some well-placed (possibly runtime) asserts to handle inputs &amp; outputs. As noted
                on the website, these contracts allow for more than just runtime assertions. C3 will propagate these
                conditions up the call chain, and analyze them during compile time folding. C3 does not currently
                perform static analysis *beyond* compile-time folding though.
            </p>
            <p>
                It feels a bit strange to me that the language has this third method of comments, given that many
                programming languages have only one or two comment types. This is trivial though, I expect that I will
                easily adapt.
            </p>

            <h3 id="struct_methods"> <code> struct </code> methods: </h3>
            <pre><code>struct Foo
{
    int i;
}

fn void Foo.next(Foo* this)
{
    if (this) this.i++;
}

fn void test()
{
    Foo foo = { 2 };
    foo.next();
    foo.next();
    // Prints 4
    io::printfn("%d", foo.i);
}</code></pre>
            <p>
                Namespaced &amp; dot-syntax functions are a thing, apparently. They work on unions, structs, and enums
                <code>[EDIT: They work on *any* type, including primitives!]</code>. This is another strict improvement
                over C, and
                I've enjoyed using them in other languages.
            </p>

            <h3 id="macros"> <code>macro</code>s: </h3>
            <p>
                Macros are a bag of worms. Sure, they can be a great source of protein, but will you really see me
                eating them? I might use worms when I'm fishing, but I don't see much use for them around the home. To
                express my opinion outside of a metaphor: macros have niche use cases, are good at what they do, but
                shouldn't be abused. One example of this abuse would be making a turing-complete domain-specific
                language inside of some macro-supporting programming language.
            </p>
            <p>
                I won't dive too far into <a href="https://c3-lang.org/generic-programming/macros/" target="_blank">the
                    complexities</a> of C3's macros, but here's a brief overview of what I learned:
            </p>
            <ul>
                <li> C3 macros act similar to C macros; they can be evaluated at compile-time. </li>
                <li> Macros can look like functions, but use <code>macro</code> instead of <code>fn</code>. </li>
                <li> Macros can't act in their caller's scope, so no declaring variables. </li>
                <li> Macros avoid the nasty <code>\</code> used for trailing macro lines in C. </li>
                <li> Macro parameters can be prefixed with <code>$</code>, meaning they are compile-time known. </li>
                <li>
                    Macro parameters can be prefixed with <code>#</code>, meaning the expression isn't yet evaluated.
                    When a variable is passed to a macro this way, it is evaluated once, then used directly where the
                    parameter is referenced. Pretty smart!
                </li>
                <li>
                    User-defined macros which use <code>$</code> or <code>#</code> parameters must be prefixed with
                    <code>@</code>. I like this - it means I can be confident whether a macro will screw up my AST.
                </li>
                <li>
                    C3 macros <a href="https://c3-lang.org/generic-programming/macros/#macro-vaargs" target="_blank">may
                        have</a> a <a href="https://en.wikipedia.org/wiki/Variadic_function" target="_blank">variable
                        number of parameters</a>.
                </li>
                <li>
                    Macros with only compile-time variables are completely evaluated at compile-time. This guarantee is
                    solid. As far as I know, C doesn't ensure this itself. Yes, it will expand all of your macros, but
                    the evaluation of the parts is up to the specific compiler you are using. As an extension to this,
                    type reflection and compile-time execution in the language is handled exclusively via macros.
                </li>
            </ul>
            <p>
                Ok, that actually wasn't too bad. I guess I still have some stress from handling cursed macros in other
                language, such as Rust. Too much power and someone is bound to misuse it. C3 macros don't have quite the
                AST manipulation power of C, but they do have some really nice features in terms of compile-time
                evaluation. In my opinion, the macros in C3 are a good fit.
            </p>

            <h3 id="type_properties"> Type Properties: </h3>
            <p>
                C3 <a href="https://c3-lang.org/language-overview/types/#compile-time-properties" target="_blank">has
                    built-in properties</a> for all types. These properties are avaliable through <code>.method</code>
                syntax. Some types have their own specific properties, yet there are a baker's dozen that all types
                share. Here they are:
            </p>
            <ol>
                <li> <code>alignof</code> - The standard alignment of the type in bytes. </li>
                <li>
                    <code>kindof</code> - The category of type, e.g. <code>TypeKind.POINTER</code> /
                    <code>TypeKind.STRUCT</code>.
                </li>
                <li> <code>extnameof</code> - Returns a string with the extern name of the type, rarely used. </li>
                <li> <code>nameof</code> - Returns a string with the unqualified name of the type. </li>
                <li> <code>qnameof</code> - Returns a string with the qualified name of the type. </li>
                <li> <code>sizeof</code> - Returns the storage size of the type in bytes. </li>
                <li> <code>typeid</code> - Returns a runtime typeid for the type. </li>
                <li> <code>methodsof</code> - Retuns the methods implemented for a type. </li>
                <li> <code>has_tagof(tagname)</code> - Returns true if the type has a particular tag. </li>
                <li> <code>tagof(tagname)</code> - Retrieves the tag defined on the type. </li>
                <li> <code>is_eq</code> - True if the type implements <code>==</code>. </li>
                <li> <code>is_ordered</code> - True if the type implements comparisons. </li>
                <li> <code>is_substruct</code> - True if the type has an inline member. </li>
            </ol>
            <p>
                These properties appear to be very helpful for metaprogramming. In the Zig language, one would need to
                use <code>@typeInfo</code> on the type to get this information. I imagine that it would be harder for me
                to realize that type reflection is occuring in the code, however alluring the ease of access.
            </p>

            <h3 id="base64_strings"> Base64 &amp; Hex Literals: </h3>
            <p>
                C3 supports <a href="https://c3-lang.org/language-overview/types/#base64-and-hex-data-literals" target="_blank">base64 and hex data literals</a>. Personally I don't see the appeal, as <a href="https://c3-lang.org/generic-programming/compiletime/#embed" target="_blank">the
                    <code>$embed</code> macro</a> would fulfill my common use-case for this. I imagine that a macro
                could accomplish the same thing as these types of literals. Honestly not too happy about this feature, I
                think it's trying to add language sugar for something that isn't often used.
            </p>
            <pre><code>char[*] hello_world_base64 = b64"SGVsbG8gV29ybGQh";
char[*] hello_world_hex = x"4865 6c6c 6f20 776f 726c 6421";</code></pre>
            <p>
                While not quite as bad as Rust, I do feel hesitant about the string situation overall in C3. I agree a
                lot with the C &amp; Zig approach that "all strings are just bytes", rather than different syntaxes and
                types for representing the encoding or capability of a string type.
            </p>

            <h3 id="primitives"> Primitives: </h3>
            <p>
                C3 has several primitive types. These include integers, booleans, and floats. The types are essentially
                equal to C, except <code>char</code> is defined to be unsigned. That's a big pro, considering C leaves
                char signedness up to the compiler. There are additionally 128 bit integers <code>int128</code> and
                <code>uint128</code>, which are also pleasant to see. It's not often that you reach for a 128 bit
                integer, but when you do, you appreciate it.
            </p>
            <p>
                C3 has the types <code>iptr</code>, <code>uptr</code>, <code>isz</code>, and <code>usz</code>. They are
                signed respectively according to the letter prefix, whether it be <code>i</code> or <code>u</code>. I
                feel these types are a bit shorter than they should be. The keystrokes that are saved by typing two or
                three fewer letters don't quite outweigh the cost of reading the code, at least for someone who is
                unfamiliar with the notation.
            </p>
            <p>
                I do appreciate that the bit size of the other primitive types are well defined - it offers another
                improvement over C, where your <code>int</code> could be as small as 16 bits.
            </p>

            <h3 id="much_more"> Much More: </h3>
            <p>
                The C3 language additionally has <a href="https://c3-lang.org/generic-programming/operator-overloading/" target="_blank">operator overloading</a> (pretty great imo), <a href="https://c3-lang.org/language-overview/types/#struct-subtyping" target="_blank">struct
                    subtyping</a> (a bit confusing), <a href="https://c3-lang.org/generic-programming/generics/" target="_blank">generics</a> (seems unclear, as the generic parameters are detatched from the type),
                <a href="https://c3-lang.org/generic-programming/anyinterfaces/" target="_blank">runtime dynamic
                    dispatch</a> (no opinion), <a href="https://c3-lang.org/language-overview/types/#the-any-type" target="_blank">the <code>any</code> type</a> (absolutely amazing idea, I love it!), <a href="https://c3-lang.org/language-overview/types/#typedef---distinct-type-definitions" target="_blank">distinct types</a> (nitpick: why not use <code>distinct</code> instead of
                <code>typedef</code>?), <a href="https://c3-lang.org/language-overview/types/#bitstructs" target="_blank">bitstructs</a> (awesome imo), and <a href="https://discord.com/channels/650345951868747808/650345952468795425/1376784774676615199" target="_blank">more (link about optionals)</a>.
            </p>
            <p> Feel free to dive more into C3. For now, I'll continue. </p>
        </div>

        <div id="first_steps">
            <h2> First Steps: </h2>

            <h3 id="installing_c3"> Installing C3: </h3>
            <p>
                The C3 website provides <a href="https://c3-lang.org/getting-started/prebuilt-binaries/" target="_blank">helpful installing instructions</a> for the compiler binary. Unfortunately for C3,
                not many people use it yet. I couldn't find any package for it on gentoo, so I'll probably build it from
                source.
            </p>
            <p>
                <a href="https://c3-lang.org/getting-started/compile/" target="_blank">Compiling the C3 compiler</a> is
                surprisingly simple:
            </p>
            <pre><code>git clone https://github.com/c3lang/c3c.git
cd c3c
mkdir build
cd build
cmake ..
make</code></pre>
            <p>
                As long as I have LLVM and LLD installed it should work, right?
            </p>
            <pre><code>CMake Error: The following variables are used in this project, but they are set to NOTFOUND.
Please set them or make sure they are set and tested correctly in the CMake files:
LLD_COFF
    linked by target "c3c" in directory /home/retrodev/repos/C3/c3c
    linked by target "c3c_wrappers" in directory /home/retrodev/repos/C3/c3c
LLD_COMMON
    linked by target "c3c" in directory /home/retrodev/repos/C3/c3c
    linked by target "c3c_wrappers" in directory /home/retrodev/repos/C3/c3c
LLD_ELF
    linked by target "c3c" in directory /home/retrodev/repos/C3/c3c
    linked by target "c3c_wrappers" in directory /home/retrodev/repos/C3/c3c
LLD_MACHO
    linked by target "c3c" in directory /home/retrodev/repos/C3/c3c
    linked by target "c3c_wrappers" in directory /home/retrodev/repos/C3/c3c
LLD_MINGW
    linked by target "c3c" in directory /home/retrodev/repos/C3/c3c
    linked by target "c3c_wrappers" in directory /home/retrodev/repos/C3/c3c
LLD_WASM
    linked by target "c3c" in directory /home/retrodev/repos/C3/c3c
    linked by target "c3c_wrappers" in directory /home/retrodev/repos/C3/c3c

-- Generating done (0.0s)
CMake Generate step failed.</code></pre>
            <p> Haha nope. Let's check to make sure I actually have LLD installed: </p>
            <pre><code>*  llvm-core/lld
      Latest version available: 20.1.5
      Latest version installed: 20.1.5
      Size of files: 143789 KiB
      Homepage:      https://llvm.org/
      Description:   The LLVM linker (link editor)
      License:       Apache-2.0-with-LLVM-exceptions UoI-NCSA</code></pre>
            <p>
                Well that's not great! The build script detected LLVM just fine, but couldn't find LLD for some reason.
                <a href="https://discord.com/channels/650345951868747808/927010276128202762/1377003877492068464" target="_blank">I can probably use</a> <code>-DLLVM_DIR=...</code> and <code>-DLLD_DIR=...</code>
                with cmake to ensure it knows where they are installed.
            </p>
            <p>
                For a while I couldn't understand why cmake wasn't working here. And yes, the solutions just mentioned
                did nothing. <a href="https://youtu.be/gakX1m9oJhQ" target="_blank">Some time later</a> I realized that
                my LLD installation did not include the LLD libraries which C3 relies on, so the problem is on my end.
                Instead of building LLD from source to get the required LLD libraries, I decided to just go the cheap
                route and download the C3 compiler build for my laptop:
            </p>
            <pre><code>retrodev@lime ~ $ c3c --version
c3c: /usr/lib64/libtinfo.so.6: no version information available (required by c3c)
C3 Compiler Version:       0.7.1
Installed directory:       /home/retrodev/repos/C3/c3/
Git Hash:                  c5494a23ce18ad16a382774a2f360c94b1515e3f
Backends:                  LLVM
LLVM version:              17.0.6
LLVM default target:       x86_64-pc-linux-gnu</code></pre>
            <p>
                Ahh, much better. Seems like the C3 compiler depends on libtinfo here; I'll probably install it at some
                point just to silence the error.
            </p>

            <h3 id="new_project"> Creating a new project: </h3>
            <p>
                C3's compiler reminds me a lot of Zig's compiler. Both allow initializing projects
                (<code>c3c init</code> / <code>zig init</code>), building their respective projects
                (<code>c3c build</code> / <code>zig build</code>), and of course, compiling source files that don't
                belong to a project (<code>c3c compile</code> / <code>zig build-exe</code>). I'll use a project here.
            </p>
            <pre><code>retrodev@lime ~/repos/C3 $ c3c init hello_world
Project 'hello_world' created.</code></pre>
            <p>
                From the <code>c3c init</code> command, we can see that a directory for the project is created,
                including a lot of files that would otherwise be boilerplate. Both <code>LICENSE</code> and
                <code>README.md</code> are empty. <code>project.json</code> contains the project configuration,
                including source files, targets to build, optimization and target settings, and more.
            </p>
            <pre><code>retrodev@lime ~/repos/C3 $ tree hello_world -a
hello_world
├── LICENSE
├── README.md
├── build
│&nbsp;&nbsp; └── .gitkeep
├── docs
│&nbsp;&nbsp; └── .gitkeep
├── lib
│&nbsp;&nbsp; └── .gitkeep
├── project.json
├── resources
│&nbsp;&nbsp; └── .gitkeep
├── scripts
│&nbsp;&nbsp; └── .gitkeep
├── src
│&nbsp;&nbsp; ├── .gitkeep
│&nbsp;&nbsp; └── main.c3
└── test
    └── .gitkeep</code></pre>
            <p>
                Yep. That's kinda what I was expecting. Overall I agree that the folder structure is helpful here - it
                establishes a status-quo for new users of C3. I do find it strange that C3 would create an empty
                <code>LICENSE</code> file though. I initially expected to find a general permissive licence, and was
                surprised when <code>ls</code> displayed the file as 0 bytes. That might have bitten me if I didn't
                notice.
            </p>
            <p>
                Let's look at the generated main.c3 file:
            </p>
            <pre><code>module hello_world;
import std::io;

fn int main(String[] args)
{
    io::printn("Hello, World!");
    return 0;
}</code></pre>
            <p>
                Oh! this is pleasant. The conciceness reminds me of the default <code>main.rs</code> file from
                <code>cargo new</code>. I'd consider this an improvement on Zig, which by default will create a template
                stuffed to the brim with comments and example code. Zig's template is useful for beginners, but
                painfully verbose. I also hadn't realized that C3's <code>String</code> is title case. I'm not sure how
                I feel about that - it makes <code>String</code> feel more abstract than an <code>int</code>, which I
                suppose it is.
            </p>
            <p>
                Let's compile and run this:
            </p>
            <pre><code>retrodev@lime ~/repos/C3/hello_world $ c3c run
Program linked to executable 'build/hello_world'.
Launching ./build/hello_world
Hello, World!
Program completed with exit code 0.</code></pre>
            <p>
                Fantastic. I think I'm ready to dive all-in.
            </p>
        </div>

        <div id="making_calculator">
            <h2> Making a calculator with C3: </h2>
            <p>
                To better document this learning experience, I'll attempt to make a basic calculator in C3. I expect it
                to handle addition <code>+</code>, subtraction <code>-</code>, multiplication <code>*</code>, division
                <code>/</code>, negation (also <code>-</code>), exponentiation <code>^</code>, and parenthesis
                <code>( )</code>.
            </p>

            <h3 id="what_for_calc"> What will this require? </h3>
            <p>
                Writing this form of calculator will test my knowlege of C3. I will need to know how to make and call
                functions (especially for the <a href="https://en.wikipedia.org/wiki/Recursive_descent_parser" target="_blank">recursive descent parser</a>), how to get user input, how to do basic math with
                floats, and how to print to the terminal. I have a rough idea of how I want the code to look like, but
                the point here is to find and document what I find amazing - and not so amazing - about my experience
                learning C3. The internet is too full of armchair experts. Only my hands-on experience will provide me
                with an opinion worth sharing.
            </p>

            <h3 id="getting_input"> Getting user input: </h3>
            <p>
                As with any language, you trip when you transition from *reading* the language to actually *using* the
                language. In this case, I had neglected to read much of the "memory management" documentation for C3, so
                I needed to learn how allocators are currently used in C3:
            </p>
            <pre><code>module calculator;
import std::io;

fn int main()
{
    @pool()
    {
        io::printf("Enter an equation: ");
        String? equation = io::treadline();
        if (catch equation) return 1;
        io::printfn("Your equation: %s", equation);
    };
    return 0;
}
</code></pre>
            <p>
                There are currently <a href="https://discord.com/channels/650345951868747808/927010276128202762/1377463685416616036" target="_blank">two default</a> allocators used in code. (This isn't a link to the language
                reference, because it is updated by hand and this section is currently out of date.) These allocators
                are <code>tmem</code> and <code>mem</code>. <code>tmem</code> is a "temporary" allocator, acting as an
                <a href="https://www.rfleury.com/p/untangling-lifetimes-the-arena-allocator" target="_blank">arena
                    allocator</a>. The context for the temporary allocations is marked by the macro <code>@pool</code>.
                This macro will free items allocated with <code>tmem</code> at the end of the defined scope. Several
                functions in the C3 standard library are prefixed with "t", representing that they use the temporary
                allocator under the hood. These functions are alternatives to non-prefixed functions, which take an
                allocator parameter.
            </p>
            <p>
                C3 feels like a balance of Zig and C in this instance. It is common practice in Zig to pass allocators
                to every function, so you can know what function may allocate memory, and pick the most effective
                allocator for the job. It is common in C to use only one allocator - namely the standard library
                allocator - through <code>malloc</code>, <code>calloc</code>, and <code>free</code>.
            </p>
            <p>
                One more thing to note here are the return values of functions. Many C compilers will allow you to
                create the standard <code>int main()</code> function, then allow you to omit returning a value from it.
                The compilers I am talking about will implicitly return <code>EXIT_SUCCESS</code> (0 on all systems I
                know of) for you. C3 mandates returning a value from this function. It will give me an error if I fail
                to return a value:
            </p>
            <pre><code> 1: module calculator;
 2: import std::io;
 3: 
 4: fn int main()
           ^^^^
(/home/retrodev/repos/C3/calculator/src/main.c3:4:8) Error: Missing return statement at the end of the function.</code></pre>
            <p>
                C3 will also allow me to mark the main function as <code>void</code>, so this isn't bothersome. While
                it's not standard according to ISO C, some C compilers also allow you to define the main function as
                <code>void</code>.
            </p>
            <p>
                Referencing the C3 code again, the <code>io::printf</code> and <code>io::printfn</code> functions return
                a value that the compiler does not require me to handle. C3 allows it's users to skip checking the
                return value here. This may introduce points of (admittedly very unlikely) failure into a program that
                are hard to identify, for the benefit of ease-of-programming. This is normal C behavior here. Also like
                in C, C3 will allow you to explicitly discard function return values by prefixing the function call with
                <code>(void)</code>. <code>EDIT: The functions here can be implicitly discarded because they have been annotated with @maydiscard. On the flip side, there is also @nodiscard.</code>
            </p>

            <h3 id="tokenizer"> The tokenizer: </h3>
            <p>
                So we are making a calculator? That's quite a bit to do. Let's take a bigger leap this time. Here's my
                code for tokenizing the input:
            </p>
            <pre><code>module calculator;
import std::io;
import std::collections::list;

enum TokenTag: char
{
    // Final Token
    DELIMITER,
    // Operators
    ADD,
    SUBTRACT,
    MULTIPLY,
    DIVIDE,
    POWER,
    // Operator precedence
    LEFT_PAREN,
    RIGHT_PAREN,
    // Number literal
    NUMBER,
}

struct Token
{
    TokenTag tag;
    float number;
}

faultdef INVALID_TOKEN; 

// Convert an input string into a list of tokens that define our equation
fn Token[]? tokenize(Allocator allocator, String equation)
{
    List {Token} token_list;
    token_list.tinit();
    defer token_list.free();
    
    // Scan through the string; most bytes should be one token.
    for (usz idx = 0; idx &lt; equation.len; idx += 1)
    {
        switch (equation[idx])
        {
            case ' ': continue; // Skip whitespace
            case '+': token_list.push({.tag = ADD});
            case '-': token_list.push({.tag = SUBTRACT});
            case '*': token_list.push({.tag = MULTIPLY});
            case '/': token_list.push({.tag = DIVIDE});
            case '^': token_list.push({.tag = POWER});
            case '(': token_list.push({.tag = LEFT_PAREN});
            case ')': token_list.push({.tag = RIGHT_PAREN});
                
            default:
                // We probably have a number - parse it:
                usz start = idx;
                usz end = idx;

                // Scan digits and radix points from this position
                for (; end &lt; equation.len; end += 1)
                {
                    char x = equation[end];
                    if (x != '.' &amp;&amp; (x &lt; '0' || x &gt; '9')) break;
                }

                // This is true if we didn't parse a number
                if (start == end) return INVALID_TOKEN?;

                // Slicing indexes are inclusive on both ends
                float? number = equation[start..end - 1].to_float();
                if (catch number) return INVALID_TOKEN?;
                token_list.push({NUMBER, number});

                // Update the index so we don't re-parse the number
                idx = end - 1;
        }
    }

    token_list.push({DELIMITER, {}});
    return token_list.to_array(allocator);
}

fn int main()
{
    @pool()
    {
        io::printf("Enter an equation: ");
        String? equation = io::treadline();
        if (catch equation) return 1;

        Token[]? tokens = tokenize(tmem, equation);
        if (catch tokens) return 1;

        io::printn("[");
        foreach (Token t : tokens)
        {
            io::printf("    %s", t.tag);
            if (t.tag == NUMBER) io::printf(": %f", t.number);
            io::printn(",");
        }
        io::printn("]");
    };
    return 0;
}</code></pre>
            <p>
                Ok bear with me - This was a lot of code all at once. This code essentially gets the equation from the
                user, splits that into a list of "tokens" (parts of the equation), then prints out those tokens. Here is
                an example program output:
            </p>
            <pre><code>Enter an equation: 2+3 * (-7/-4) ^ 3.14
[
    NUMBER: 2.000000,
    ADD,
    NUMBER: 3.000000,
    MULTIPLY,
    LEFT_PAREN,
    SUBTRACT,
    NUMBER: 7.000000,
    DIVIDE,
    SUBTRACT,
    NUMBER: 4.000000,
    RIGHT_PAREN,
    POWER,
    NUMBER: 3.140000,
    DELIMITER,
]</code></pre>
            <p> This representation of the math equation will be perfect for the parser. </p>
            <p>
                I'm sorry to say that I struggled quite a bit while writing this code. A lot of my struggles were not
                due to the language itself, but the lack of features that the language server offers. Code completion
                and jumping to definitions (in the standard library) just doesn't work. This should improve as the
                language matures.
            </p>
            <p>
                One more confusing aspect of C3 is it's slicing. The syntax is of the form
                <code>some_string[start..end]</code>, where both the start and end indexes are inclusive. This isn't
                consistent with most of the other programming languages I know, and it requires that I take the end
                index (exclusive) and subtract one for the slice. It also means I have to make sure I don't accidentally
                form a slice of negative length (the check above it). One other side effect of this language design
                choice is that I can't create a slice of length 0 this way. This confuses me.
                <code>EDIT: C3 has built-in slice-by-length syntax of the form some_string[start:length], which is status-quo here.</code>
            </p>
            <p>
                To list the positives though, it is nice how convenient the <code>List</code> type is, which is supplied
                by C3's standard library. In C I normally use a prebuilt library of mine for this purpose, or I need to
                manually track my allocations, which isn't fun.
            </p>
            <p>
                The familiar C <code>for</code> loops formed the meat of the tokenizer
                algorithm, and the <code>foreach</code> loop worked great for printing out the token types! In more
                complex tokenizers I may have been able to use the advanced <code>nextcase</code> statement (my
                tokenizers / parsers seem to turn into a FSM after a while). The control flow in this language is really
                nice to use.
            </p>
            <p>
                There was one more thing I really didn't expect to find - the temporary allocator (<code>tmem</code>)
                could be used at the same time as the passed allocator for the <code>tokenize</code> function. This is
                interesting because you can use it for code that you need allocator assurances for. If I were to make
                this in Zig, I would either have to request a single allocator that worked both for the tokenization and
                return value, or request two allocators, and hope that the user would supply an efficient allocator for
                the intermediate process.
            </p>
            <p>
                Side note: I really wouldn't use Rust for it's allocator flexibility - it wasn't designed to have any
                flexibility in this area, making it hard to use with custom allocators. C3 does very well here.
            </p>
            <p> Let's finish this. </p>

            <h3 id="parser"> The parser: </h3>
            <p>
                Compared with the tokenizer, the parser was much easier to write. This is likely because I overcame the
                initial hurdle of writing code in the language. I'm pretty pleased with how simple it is! Here's the
                complete program (minus the tokenizer):
            </p>
            <pre><code>module calculator;
import std::io;
import std::math;
import std::collections::list;

// TokenTag, Token, and tokenize() trimmed for conciseness

faultdef UNEXPECTED_TOKEN;

struct Parser
{
    Token[] source;
    usz index;
}

fn float? Parser.parse(Parser* p)
{
    float result = p.expression()!;
    TokenTag next_tag = p.source[p.index].tag;
    if (next_tag != DELIMITER) return UNEXPECTED_TOKEN?;
    return result;
}

// &lt;​expression&gt; ::= &lt;​term&gt; (("+" | "-") &lt;​term&gt;)*
fn float? Parser.expression(Parser* p)
{
    float result = p.term()!;

    switch (p.source[p.index].tag)
    {
        case ADD:
            p.index += 1;
            result += p.term()!;
            nextcase p.source[p.index].tag;
        case SUBTRACT:
            p.index += 1;
            result -= p.term()!;
            nextcase p.source[p.index].tag;
        default:
            return result;
    }
}

// &lt;​term&gt; ::= &lt;​factor&gt; (("*" | "/") &lt;​factor&gt;)* | &lt;​factor&gt; &lt;​term&gt;
fn float? Parser.term(Parser* p)
{
    float result = p.factor()!;

    switch (p.source[p.index].tag)
    {
        case MULTIPLY:
            p.index += 1;
            result *= p.factor()!;
            nextcase p.source[p.index].tag;
        case DIVIDE:
            p.index += 1;
            result /= p.factor()!;
            nextcase p.source[p.index].tag;
        default:
            return result;
    }
}

// &lt;​factor&gt; ::= &lt;​negation&gt; ('^' &lt;​factor&gt;)*
fn float? Parser.factor(Parser* p)
{
    float result = p.negation()!;
    if (p.source[p.index].tag == POWER)
    {
        p.index += 1;
        float power = p.factor()!;
        result = math::pow(result, power);
    }
    return result;
}

// &lt;​negation&gt; ::= "-" &lt;​negation&gt; | &lt;​number&gt;
fn float? Parser.negation(Parser* p)
{
    if (p.source[p.index].tag == SUBTRACT)
    {
        p.index += 1;
        return -p.negation()!;
    }
    return p.number();
}

// &lt;​number&gt; ::= '(' &lt;​expression&gt; ')' | &lt;​floating point number&gt;
fn float? Parser.number(Parser* p)
{
    switch (p.source[p.index].tag)
    {
        case LEFT_PAREN:
            p.index += 1;
            float result = p.expression()!;
            TokenTag next_tag = p.source[p.index].tag;
            if (next_tag != RIGHT_PAREN) return UNEXPECTED_TOKEN?;
            p.index += 1;
            return result;
        default:
            float number = p.source[p.index].number;
            p.index += 1;
            return number;
    }
}

fn int main()
{
    while (true) 
    {
        @pool()
        {
            io::printf("Enter an equation: ");
            String? equation = io::treadline();
            if (catch equation) return 1;

            Token[]? tokens = tokenize(tmem, equation);
            if (catch tokens) return 2;

            Parser p = {tokens, 0};
            float? result = p.parse();
            if (catch result) return 3;

            io::printfn("Result: %f", result);
        };
    }
}</code></pre>
            <p> Let's take it for a spin. </p>
            <pre><code>Enter an equation: 2+3 * (-7/-4) ^ 3.14
Result: 19.388445</code></pre>
            <p> It works! </p>
            <p>
                Earlier in this article, I expressed some concern about the error system. With this small example, I
                found that it worked out well. I was able to write the code nearly the same as if an error would never
                occur, trusting that it would get "bubbled-out" in the case that someone goofed up. 100% an improvement
                on C, yet again.
            </p>
            <p>
                I also found that the <code>nextcase</code> keyword worked very well in both the <code>expression</code>
                and <code>term</code> functions. The same can be accomplished with a normal while loop with the switch,
                but this way it seems cleaner to me :)
            </p>
        </div>

        <div id="conclusion">
            <h2> Conclusion: </h2>
            <p>
                C3 reminds me of C. The flavor lingers in my mouth, yet I don't sense the same aftertaste. It isn't
                perfect though, I cut myself a few times. It is fun to work with. This language is simpler than C++ and
                Rust. This language is faster to develop in than Rust, C++, and Zig. This language is safer and more
                expressive than C.
            </p>
            <p>
                Would I use this language daily? I don't think so. It is a good alternative to C, where projects that
                would otherwise be written in C could be written here. I think personally I prefer working with Zig, and
                that's alright. Zig holds a special place in my heart, and it won't give up easily.
            </p>
            <p>
                C3 has loads of potential. Already I've seen this in my very short time using it. Yes, I will continue
                to use it. I haven't even tried to (ab)use the macro system yet, nor have messed with some of the more
                complex features that C3 has, such as it's dynamic interfaces.
            </p>
            <p>
                The C3 source code is very readable. While in the making of this article, I was able to read the source
                code of many parts of the standard library with ease. Lots of languages with macros seem like
                navigating a non-euclidean labrynth, where the entrance and exit keep running away from you. The C3
                macro system is well built, kindof feeling like a hybrid of Zig's comptime system and C's macros. I
                prefer it to other macro systems, hands down.
            </p>
            <p>
                There are some things which I would rather not have in this language. These include inclusive slicing
                syntax, and the error system still doesn't quite sit right with me. Perhaps these will be fixed in the
                next update!
            </p>
            <p>
                Thank you to <code>is_human_ (1075947477913567294 on discord)</code> for all the wonderful answers you
                supplied to me while I was trying this language out. Thank you to Christoffer for making this language,
                you are certainly more talented than I am: the compiler source code shows it.
            </p>
            <p>
                If you are looking to try C3 out, go for it. <a href="https://xkcd.com/989/" target="_blank">Don't wait
                    for it to become better</a>. I've gained a lot out of this venture, and will continue to gain
                insight as I continue to learn it. Thanks for reading.
            </p>
        </div>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google is using AI to censor independent websites like mine (141 pts)]]></title>
            <link>https://travellemming.com/perspectives/ftc-letter-google-censors-indie-publishers-with-ai/</link>
            <guid>44124820</guid>
            <pubDate>Thu, 29 May 2025 11:05:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://travellemming.com/perspectives/ftc-letter-google-censors-indie-publishers-with-ai/">https://travellemming.com/perspectives/ftc-letter-google-censors-indie-publishers-with-ai/</a>, See on <a href="https://news.ycombinator.com/item?id=44124820">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
	<p><em>[Note: What follows is a blog-post formatted version of the 34 page letter I submitted to the FTC on May 21, 2025 in response to the agency’s <a href="https://www.ftc.gov/system/files/ftc_gov/pdf/P251203CensorshipRFI.pdf" target="_blank" rel="noopener">RFI entitled</a>: “Request for Public Comment Regarding Technology Platform Censorship.” I have also added a section at the end on <a href="#what-you-can-do">what you can do</a> to save the open web from Google’s AI takeover.]</em></p><p><strong>Introduction:</strong></p><p>I am an American citizen and founder of the Florida company Travel Lemming LLC. Travel Lemming runs a website, <a href="https://travellemming.com/">TravelLemming.com</a>, that provides online travel advice.&nbsp;</p><p>In this letter I will explain how Google censored my travel website – and thousands of small and independent web publishers like me – all so that it can use AI to control the flow of information online.&nbsp;</p><p>In late 2023 and early 2024, Google released an unprecedented series of algorithm updates that utterly decimated thousands of independent websites.&nbsp;</p><p>Travel Lemming lost more than 95% of our Google organic search referral traffic in these updates.&nbsp;</p><p>The shadowban algorithm that hit us was supposedly based on the content on our websites. But we later realized the shadowban really was about the <em>type </em>of website we are (i.e., small and independent).&nbsp;</p><p>While Google gives large publishers an appeal and recovery process, small and independent publishers have no path to appeal our shadowbans.&nbsp;</p><div><p>This is true even though Google <em>admitted </em>our shadowbans are its fault and not ours.</p><p><strong>In fact, last October, Google even flew me and 19 other publishers out to its headquarters for a tour, an admission of wrongdoing, and an apology.</strong></p></div><p>Though Google apologized, it also said that search has permanently changed with AI and thus our traffic may never return.&nbsp;</p><p>In this letter I will describe how I believe Google has been laying the groundwork for a grand plan to rethink search from the ground-up so as to profit from AI.&nbsp;</p><p><strong>Google isn’t satisfied with its monopoly on the questions we search.&nbsp;</strong></p><p><strong>Google wants to use AI to monopolize the very </strong><strong><em>answers </em></strong><strong>themselves.&nbsp;</strong></p><p>As one Google executive recently explained: “<em>Organizing information is clearly a trillion-dollar opportunity, but a trillion dollars is not cool anymore. What’s cool is a quadrillion dollars</em>.”</p><p>Google plans to use AI to consume and replace the open web.&nbsp;</p><p><strong>I believe demolishing independent sites like mine was Google’s first step in clearing ground so it has space to rebuild search from the ground up for an “AI-first” future.&nbsp;</strong></p><p>Google envisions a future where “<em>Google does the Googling for you</em>,” its AI and ads do the answering – and users never need to leave Google.&nbsp;</p><p>Google will just source information from a handful of sources and partner websites <em>that it controls and selects </em>– effectively creating an information cartel.&nbsp;</p><p>If Google can use AI to censor a travel website from the web arbitrarily and without opportunity for appeal – it can do the same to any source of information it wants.&nbsp;</p><p>And American citizens and Internet users everywhere will be worse off for it.&nbsp;</p><p>So while you may not really care about the plight of some random travel website getting censored, everyone should care about the way Google is deploying AI to build a censorship cartel that lets it control the flow of information online.&nbsp;</p><p>What follows is a lengthy summary of my experiences and my opinions as an independent publisher trying to survive in a monopolist’s information economy.&nbsp;</p><p>To start, let me explain how we got to this point where Google has the power to do this:&nbsp;</p><h2>Google Promised Publishers a “<em>fundamental fair exchange between Google and the web</em>”&nbsp;</h2><p>To lay the context for Google’s censorship, I need to briefly explain the social contract between Google and the open web – and how AI threatens to change it.&nbsp;</p><p><a href="https://www.google.com/intl/en_us/search/howsearchworks/our-approach/" target="_blank" rel="noopener">According to Google</a>, its “<em>mission is to organize the world’s information and make it universally accessible and useful</em>.”&nbsp;</p><p>In the early days of the Internet, Google gained popularity by promising to be a “<em>pure search engine</em>” that just provided links to websites with <em>“no distractions</em>”:&nbsp;&nbsp;</p><figure><img decoding="async" width="1024" height="768" src="https://travellemming.com/wp-content/uploads/Google-Ad-from-1999-1024x768.jpg" alt="A graphic showing the Google ad from 1999" srcset="https://travellemming.com/wp-content/uploads/Google-Ad-from-1999-1024x768.jpg 1024w, https://travellemming.com/wp-content/uploads/Google-Ad-from-1999-300x225.jpg 300w, https://travellemming.com/wp-content/uploads/Google-Ad-from-1999-768x576.jpg 768w, https://travellemming.com/wp-content/uploads/Google-Ad-from-1999-600x450.jpg 600w, https://travellemming.com/wp-content/uploads/Google-Ad-from-1999.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20width='1024'%20height='768'%20viewBox='0%200%201024%20768'%3E%3C/svg%3E" data-src="https://travellemming.com/wp-content/uploads/Google-Ad-from-1999-1024x768.jpg" data-srcset="https://travellemming.com/wp-content/uploads/Google-Ad-from-1999-1024x768.jpg 1024w, https://travellemming.com/wp-content/uploads/Google-Ad-from-1999-300x225.jpg 300w, https://travellemming.com/wp-content/uploads/Google-Ad-from-1999-768x576.jpg 768w, https://travellemming.com/wp-content/uploads/Google-Ad-from-1999-600x450.jpg 600w, https://travellemming.com/wp-content/uploads/Google-Ad-from-1999.jpg 1200w"><figcaption><em>A Google ad from 1999 (</em><a href="https://www.uniladtech.com/news/tech-news/google-ad-from-1999-588164-20240314" target="_blank" rel="noopener"><em>Source</em></a><em>)</em></figcaption></figure><p><strong><br></strong>To this day, Google’s official <a href="https://about.google/company-info/philosophy/" target="_blank" rel="noopener">corporate philosophy page</a> still states: “<em>We may be the only people in the world who can say our goal is to have people leave our website as quickly as possible</em>.”</p><div><p><strong>Google created a social contract with the online publishing industry: publishers provide content for Google to crawl and, in exchange, Google sends valuable clicks back to publishers.</strong></p><p>As recently as 2020, Google’s official blog recognized the existence of this social contract:&nbsp;</p></div><blockquote><p>“<em>Google Search has evolved since its early beginnings, but one thing that hasn’t changed is the </em><strong><em><mark>fundamental fair exchange between Google and the web</mark></em></strong><em>. Google crawls, indexes and links to websites in search results, and each search result includes a short preview of what to expect at the site. Websites gain free traffic from users interested in what they have to offer, and each user visit is an opportunity to build a long-term relationship and monetize through advertising or subscriptions</em>.”<br>–<a href="https://blog.google/outreach-initiatives/google-news-initiative/setting-record-straight-news/#:~:text=Google%20Search%20has%20evolved%20since,monetize%20through%20advertising%20or%20subscriptions" target="_blank" rel="noopener"><em>Google’s The Keyword Blog</em></a> (June 26, 2020, emphasis added)</p></blockquote><p>To this day, Google’s website <em>still </em>says the company believes search should “<strong><em>help creators succeed online</em></strong>” and that:&nbsp;</p><blockquote><p><em>“To support a healthy ecosystem of fresh and useful content in all the world’s languages, we help people, publishers, and businesses of all sizes succeed and be found by others. </em><strong><em><mark>We do this by sending visitors to websites small and large through our search results</mark></em></strong><em>, or by connections such as listing business addresses and phone numbers. We don’t charge to be in our search listings, and we also provide free tools and resources to help site owners be successful.” <br>–</em><a href="https://www.google.com/intl/en_us/search/howsearchworks/our-approach/" target="_blank" rel="noopener"><em>Google’s “Our approach to search” webpage</em></a> (accessed May 18, 2025, emphasis added)&nbsp;</p></blockquote><h2>Google Encouraged Americans to “Create Millions of Sustainable Content-First Businesses on the Web”</h2><p>Google didn’t just promise a fair exchange of content for clicks – Google <em>actively encouraged</em> Americans to start small online businesses creating content.&nbsp;</p><p>In 2018, shortly after I started Travel Lemming, <a href="https://blog.google/products/adsense/looking-back-looking-forward/" target="_blank" rel="noopener">Google told publishers</a>: “<em>the world has an insatiable appetite for great content and publishers like you remain the beating heart of the open web. Sharing in this mission with you, helping to create </em><strong><em><mark><span>millions of sustainable content-first businesses on the web</span></mark></em></strong><em>, keeps us going</em>.”</p><h2>Google Promised to Give Small &amp; Independent Publishers a Fair Shot on the Open Web</h2><div><p>Importantly, Google promised that its “<em>fundamental fair exchange</em>” of content for clicks would be a marketplace open not just to massive legacy news publications, but also to new, small, and independent websites.&nbsp;</p><p>In 2014, Google representative <a href="https://www.youtube.com/watch?v=7XHAhn8HCzs" target="_blank" rel="noopener">Matt Cuts told publishers in a video</a>: “<em>The small guys absolutely can outperform the larger guys as long as they do a really good job at it.</em>”&nbsp;</p></div><p>The way smaller publishers could compete? Quality content!&nbsp;</p><p>Cutts encouraged sites: “<em>don’t stop trying to produce superior content, because over time that’s one of the best ways to rank higher on the web</em>.”&nbsp;</p><p>But what makes content “superior” and worthy of receiving Google clicks?&nbsp;</p><p>Well, Google had things to say about that too …&nbsp;</p><h2>Google Promised to Reward Publishers Who Invest Resources Into Content Created “<em>By People, For People</em>”&nbsp;</h2><div><p>Google provides websites with <a href="https://developers.google.com/search/docs/fundamentals/seo-starter-guide" target="_blank" rel="noopener">extensive documentation</a> on what kind of content Google <em>says </em>it seeks to reward with search traffic.</p><p>Google says “<em>While there’s no guarantee that any particular site will be added to Google’s index, sites that follow the </em><a href="https://developers.google.com/search/docs/essentials" target="_blank" rel="noopener"><em>Search Essentials</em></a><em> are more likely to show up in Google’s search results</em>.”</p><p>At the top of Google’s list of “key best practices” for websites is an instruction to “<em>[c]reate helpful, reliable, people-first content</em>.”&nbsp;</p></div><p>Google <a href="https://developers.google.com/search/docs/fundamentals/creating-helpful-content" target="_blank" rel="noopener">has a whole page</a> that with questions webmasters can ask to self-assess whether they are creating the kind of content Google seeks to reward. Some examples are:&nbsp;</p><ul><li><em>“Does your content clearly demonstrate first-hand expertise and a depth of knowledge (for example, expertise that comes from having actually used a product or service, or visiting a place)?”</em></li>

<li><em>“Is this content written or reviewed by an expert or enthusiast who demonstrably knows the topic well?”</em></li>

<li><em>“Does the content provide original information, reporting, research, or analysis?</em>”</li></ul><p>In short, <strong>Google </strong><strong><em>claims </em></strong><strong>it rewards publishers who invest resources and effort into their content</strong> – as opposed to spammers, who often use automated or low-effort content production systems.&nbsp;</p><p>In August 2022, Google summed up this guidance in a now-infamous blog post announcing Google was “<em>rolling out a series of improvements to Search to make it easier for people to find helpful content made by, and for, people</em>.”&nbsp;</p><figure><img decoding="async" width="1024" height="535" src="https://travellemming.com/wp-content/uploads/Googles-Blog-Post-1024x535.jpg" alt="A Google's blog post, titled more content by people, for people in Search" srcset="https://travellemming.com/wp-content/uploads/Googles-Blog-Post-1024x535.jpg 1024w, https://travellemming.com/wp-content/uploads/Googles-Blog-Post-300x157.jpg 300w, https://travellemming.com/wp-content/uploads/Googles-Blog-Post-768x401.jpg 768w, https://travellemming.com/wp-content/uploads/Googles-Blog-Post-600x314.jpg 600w, https://travellemming.com/wp-content/uploads/Googles-Blog-Post.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20width='1024'%20height='535'%20viewBox='0%200%201024%20535'%3E%3C/svg%3E" data-src="https://travellemming.com/wp-content/uploads/Googles-Blog-Post-1024x535.jpg" data-srcset="https://travellemming.com/wp-content/uploads/Googles-Blog-Post-1024x535.jpg 1024w, https://travellemming.com/wp-content/uploads/Googles-Blog-Post-300x157.jpg 300w, https://travellemming.com/wp-content/uploads/Googles-Blog-Post-768x401.jpg 768w, https://travellemming.com/wp-content/uploads/Googles-Blog-Post-600x314.jpg 600w, https://travellemming.com/wp-content/uploads/Googles-Blog-Post.jpg 1200w"><figcaption><em>Google’s </em><a href="https://blog.google/products/search/more-content-by-people-for-people-in-search/?utm_source=newsletter&amp;utm_medium=referral&amp;utm_campaign=content-by-people-for-people-is-at-the-core-of-the-new-google-update" target="_blank" rel="noopener"><em>blog post</em></a><em> calling for “more content by people, for people in Search”</em></figcaption></figure><h2>Like Many Small &amp; Independent Publishers, My Website Invested Enormous Resources Into Creating Content “By People, For People”&nbsp;</h2><p>While Google’s Gemini AI will create you a blog post with just a click of a button, creating content by people, for people, is — by contrast – an enormously expensive and laborious proposition.&nbsp;</p><p>At Travel Lemming, we ban AI content flat out. Instead, we produce guides written by knowledgeable locals and destination experts. We hire employees and freelance creators in destinations around the United States and the world, and pay them fair wages.&nbsp;</p><p>Our creators actually visit the places we write about.&nbsp;</p><p>Our creators take and publish thousands of original photos.&nbsp;</p><p>Our creators create original videos, podcasts, and multimedia content to share on the site.&nbsp;</p><p>And, because the world is constantly changing, we also invest significant resources into updating our guides and keeping them fresh and accurate over time.&nbsp;</p><p>We also invest considerable resources engaging with our community. We respond to thousands of reader comments, emails, and messages with personalized travel advice.&nbsp;</p><p>We also host free community meetups in 8 cities in the US and Canada.&nbsp;</p><p>We are not a perfect travel guide. If you look hard enough at any website you’ll find imperfections, and we have many. But we really do <em>try </em>to create the kind of content Google claims it rewards.&nbsp;</p><p><strong><span>And here’s the thing – creating content by people, for people, is incredibly expensive.</span></strong></p><p>Travel Lemming invests tens of thousands of dollars every month on the costs of producing and maintaining our travel guides.&nbsp;</p><p>And that doesn’t even include the opportunity cost of my time as founder.&nbsp;</p><p>For me, founding Travel Lemming <a href="https://thepenngazette.com/vagabond-publisher/" target="_blank" rel="noopener">meant leaving behind</a> a much more stable and promising legal career.</p><p>The path of online content creation is one of enormous risk and uncertainty. There is no guarantee of a paycheck each month. No one gives you health insurance, benefits, or paid vacation. If you fail, you often fail hard.&nbsp;</p><div><p>At the time I started the blog, I still had nearly six figures in law school debt (debt I only finally paid off in 2023, just months before Google’s shadowban devastated Travel Lemming).</p><p>In 2020, pandemic-related restrictions on travel devastated Travel Lemming’s traffic and, with it, my personal finances.&nbsp;</p></div><p>I was faced with a choice: close the business, or take drastic action.&nbsp;</p><p>Against the advice of nearly everyone close to me, I doubled down on my passion and invested in myself. I sold my one remaining significant financial asset – my house in Denver – and invested the proceeds into Travel Lemming’s content.&nbsp;</p><div><p>I say none of this to elicit sympathy for me personally. I have done well in life and I am enormously grateful for all I have given. Travel Lemming, despite the challenges and the betrayal by Google, persists in our mission of helping our readers wherever they can still find us.</p><p>But I do want to show that <span><strong>creating content “by people, for people” has a very real human cost</strong>.</span></p></div><p><strong><span>And that cost is only worth it if there is an open web ecosystem that properly incentivizes talented entrepreneurs to create high quality content for the web.</span></strong></p><p>Google says it supports such an ecosystem, but let’s look at what it really does …&nbsp;</p><h2>Meanwhile, Google Monopolized Search, Subjugating Publishers of All Sizes Into a Dependent Relationship&nbsp;</h2><p>Google promised publishers a “fair exchange” of content for valuable traffic. But exchanges seldom remain fair when one party wields unfair leverage over the other.&nbsp;</p><p>Over the past decade, Google has come to dominate – and monopolize – the way that Americans search for and retrieve information.&nbsp;</p><p>A <a href="https://www.courtlistener.com/docket/18552824/1033/united-states-of-america-v-google-llc/" target="_blank" rel="noopener">federal court recently found</a> Google illegally built and maintained a monopoly over the search market, noting that Google has a 90+% search market share.&nbsp;</p><p>One consequence of Google’s illegal search monopoly is that web publishers have been forced into a dependent relationship with Google.&nbsp;</p><p>The reality is that search is the main driver of traffic to most content websites.&nbsp;&nbsp;</p><p>A <a href="https://sparktoro.com/blog/who-sends-traffic-on-the-web-and-how-much-new-research-from-datos-sparktoro/" target="_blank" rel="noopener">2024 report by SparkToro</a> found that more than <strong><span>74% of web traffic referrals come from search engines – and 64% come from Google</span></strong>.&nbsp;</p><p>Search referral traffic is an even more important revenue source for informational websites, such as travel guides like ours. Search is where users seek out the type of long-form guide content we create. Social media may be great for quick visual inspiration, but search is still where most travelers plan the specifics of their trips.&nbsp;&nbsp;</p><p>And, because Google has a monopoly on search, online publishers are fundamentally dependent on Google.&nbsp;</p><p><strong><span>It’s a monopolist’s web, and we’re just publishing in it.</span></strong></p><p>Which gives Google a lot of power, including the power to effectively hide entire businesses from being found.&nbsp;</p><h2>After ChatGPT, Google Executives Announced a Plan to “Reimagine” and “Reinvent” Search for an “AI-First” Future&nbsp;</h2><div><p>In late 2022, just a few months after Google’s call for “<em>more content by people, for people in Search</em>,” ChatGPT took the world by storm.</p><p>Though Google had been working on its own AI ambitions for years, the emergence of ChatGPT reportedly caused Google to <a href="https://www.nytimes.com/2022/12/21/technology/ai-chatgpt-google-search.html" target="_blank" rel="noopener">declare a “code red”</a> internally – dramatically restructuring the company, calling in its former founders, and reworking everything around AI.&nbsp;</p></div><p>In February 2023, then-Google SVP Prabhakar Raghavan <a href="https://edition.cnn.com/2023/02/08/tech/google-search-event/index.html" target="_blank" rel="noopener">announced</a> that Google was “<em>reinventing what it means to search</em>.”&nbsp;</p><p>At Google’s annual I/O event in May, 2023, CEO Sundar Picahi <a href="https://www.reuters.com/technology/google-expected-unveil-its-answer-microsofts-ai-search-challenge-2023-05-10/#:~:text=Sign%20up%20here" target="_blank" rel="noopener">reiterated</a> the scope of the change, saying: “<em>We are reimagining all of our core products, including search</em>.”&nbsp;</p><p>After the event, <a href="https://www.theverge.com/2023/5/10/23717120/google-search-ai-results-generated-experience-io" target="_blank" rel="noopener"><em>The Verge</em></a> declared in a headline: “<em>The AI takeover of Google Search starts now</em>.”&nbsp;</p><p>That article astutely observed: “<em>The future of Google Search is AI. But not in the way you think</em>.”&nbsp;</p><p>You see, Google wasn’t planning to compete head on in a chatbot war with OpenAI.&nbsp;</p><p>Instead, as <em>The Verge </em>explained, Google decided to leverage its search market share to put “<em>AI front and center in the most valuable real estate on the internet: its existing search results</em>.”&nbsp;</p><h2>“Reimagining Search” Means Reworking the Open Web’s Social Contract&nbsp;</h2><div><p>Reimagining search means reworking the social contract that had underpinned the open web ecosystem for decades, something Google CEO Sundar Pichai acknowledged in <a href="https://abc.xyz/2023-q2-earnings-call/" target="_blank" rel="noopener">Alphabet’s 2023 Q2 earnings call</a> in July, 2023.</p><p>In that call, Pichai told investors in that call that AI presented “<em>an opportunity to reimagine many of our products, including our most important product, Search</em>” and that Google was “<em>engaging with the broader ecosystem and </em><strong><em>will continue to prioritize approaches that send valuable traffic and support a healthy, open web</em></strong>.” (emphasis added)</p></div><p>That same month, Google <a href="https://blog.google/technology/ai/ai-web-publisher-controls-sign-up/" target="_blank" rel="noopener">published a blog post</a> for webmasters entitled “<em>A principled approach to evolving choice and control for web content</em>,” saying:</p><blockquote><p>“<em>We believe everyone benefits from a vibrant content ecosystem. Key to that is web publishers having choice and control over their content, and opportunities to derive value from participating in the web ecosystem. However, </em><strong><em><mark><span>we recognize that existing web publisher controls were developed before new AI and research use cases</span></mark></em></strong>.” (emphasis added)&nbsp;</p></blockquote><p>In short, Google was acknowledging that any fair approach to an AI-first web would require re-writing the web’s underlying social contract.</p><h2>So Google Promised Publishers a “Public Discussion” About the Future of the Web and AI (But Never Gave Us A Chance to Speak)</h2><p>In that 2023 <a href="https://blog.google/technology/ai/ai-web-publisher-controls-sign-up/" target="_blank" rel="noopener">blog post</a>, Google promised a “<em>public discussion</em>” to “<em>evolve standards and protocols that support the web’s future development</em>.”&nbsp;</p><p>Specifically Google was speaking about robots.txt – the <a href="https://en.wikipedia.org/wiki/Robots.txt" target="_blank" rel="noopener">voluntary protocol</a> that publishers use to control which crawlers crawl our sites for which purposes.&nbsp;</p><p>This protocol lets publishers block Google’s crawlers if we don’t want our content to appear in Google’s search results.&nbsp;</p><p>However, robots.txt was designed decades ago, well before the AI age.&nbsp;</p><p>The protocol provides a very “all or nothing” choice, and doesn’t give publishers the type of granular control we need to really be able to control how our content is used by AI systems (and <em>which </em>AI<em> </em>systems).&nbsp;</p><p>Why is granular control so important to publishers?&nbsp;</p><p>Well, because publishers want Google to pay us when it uses our content for its AI features.&nbsp;</p><p>But we have no real leverage to negotiate if Google <em>already </em>has access to our content for its search indexing.&nbsp;</p><p>As the US Department of Justice <a href="https://www.courtlistener.com/docket/18552824/1052/united-states-of-america-v-google-llc/" target="_blank" rel="noopener">recently explained its proposed remedies</a> in the search antitrust case, <strong><mark>web publishers “<em>have little-to-no bargaining power against Google’s monopoly</em>”</mark></strong> because Google can “<em>leverage its monopoly power to feed artificial intelligence features</em>” our content, which we have to provide if we want our websites to be visible in online search.</p><p>Google now opposes the DOJ’s proposed remedy to give publishers more granular control over how AI companies use our content.&nbsp;</p><p>But back in <a href="https://blog.google/technology/ai/ai-web-publisher-controls-sign-up/" target="_blank" rel="noopener">its July, 2023 blog post</a>, Google seemed to <em>agree </em>robots.txt isn’t enough:</p><blockquote><p>“<em>As new technologies emerge, they present opportunities for the web community to evolve standards and protocols that support the web’s future development. One such community-developed web standard, robots.txt, was created nearly 30 years ago and has proven to be a simple and transparent way for web publishers to control how search engines crawl their content. </em><strong><em><span>We believe it’s time for the web and AI communities to explore <mark>additional machine-readable means for web publisher choice and control</mark> for emerging AI and research use cases</span></em></strong>.” (emphasis added)</p></blockquote><p>After that blog post, Google’s promised “public discussion” about web publisher control never actually happened.&nbsp;</p><p>The blog post led to a <a href="https://services.google.com/fb/forms/ai-web-publisher-controls-external/" target="_blank" rel="noopener">now-closed form</a> that only asked for contact info and didn’t even give us a field to write comments.&nbsp;</p><p>I filled my contact info into the form, but there was never really a public discussion apart from a single one-off webinar.&nbsp;</p><p>Months later, in March 2024, I complained about this silent treatment <a href="https://x.com/natejhake/status/1772215355475185729" target="_blank">on X</a>.&nbsp;</p><p>Google representative John Mueller replied (in a post he has <a href="https://x.com/natejhake/status/1772371278998950029" target="_blank">since apparently <s>deleted </s>restricted</a>):&nbsp;</p><figure><img decoding="async" width="1024" height="511" src="https://travellemming.com/wp-content/uploads/John-Mueller-Tweet-1024x511.jpg" alt="A reply from Google representative John Mueller" srcset="https://travellemming.com/wp-content/uploads/John-Mueller-Tweet-1024x511.jpg 1024w, https://travellemming.com/wp-content/uploads/John-Mueller-Tweet-300x150.jpg 300w, https://travellemming.com/wp-content/uploads/John-Mueller-Tweet-768x383.jpg 768w, https://travellemming.com/wp-content/uploads/John-Mueller-Tweet-600x300.jpg 600w, https://travellemming.com/wp-content/uploads/John-Mueller-Tweet.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20width='1024'%20height='511'%20viewBox='0%200%201024%20511'%3E%3C/svg%3E" data-src="https://travellemming.com/wp-content/uploads/John-Mueller-Tweet-1024x511.jpg" data-srcset="https://travellemming.com/wp-content/uploads/John-Mueller-Tweet-1024x511.jpg 1024w, https://travellemming.com/wp-content/uploads/John-Mueller-Tweet-300x150.jpg 300w, https://travellemming.com/wp-content/uploads/John-Mueller-Tweet-768x383.jpg 768w, https://travellemming.com/wp-content/uploads/John-Mueller-Tweet-600x300.jpg 600w, https://travellemming.com/wp-content/uploads/John-Mueller-Tweet.jpg 1200w"><figcaption><em>A restricted X post by Google rep John Mueller from March 26, 2024</em></figcaption></figure><p>A single one-off “webinar” and a few unpublicized discussions at foreign conferences abroad do not, in my opinion, constitute a “public discussion” on an issue of such importance.&nbsp;</p><p>And what about the “Google-Extended” directive Mueller mentions?&nbsp;</p><p>Well, Google <a href="https://searchengineland.com/google-extended-crawler-432636" target="_blank" rel="noopener">announced</a> that in October 2023. But Google-Extended <em>is a robots.txt directive</em> – in other words, <em>precisely </em>what Google’s initial blog post admitted was an insufficient control mechanism for the AI age.&nbsp;</p><p><strong>So why did Google do a 180 on publisher controls in late 2023?&nbsp;</strong></p><p>Well, I can only speculate – but it might have had something to do with my question back to Mueller in the tweet above (which he never answered).&nbsp;</p><p>Because as it turns out …&nbsp;</p><h2>Behind Closed Doors, Google Was Secretly Negotiating a <em>Private </em>Contract with Reddit&nbsp;</h2><div><p>Publishers were not the only ones concerned about Google scraping our content to feed its AI systems.</p><p>The owners of the social media platform Reddit were very vocal that they didn’t think it was fair for AI companies to scrape and use Reddit’s content for free.&nbsp;</p></div><p>They even started making noises about Reddit blocking Google’s search crawlers.&nbsp;</p><p>In an April 2023 <a href="https://www.nytimes.com/2023/04/18/technology/reddit-ai-openai-google.html" target="_blank" rel="noopener"><em>New York Times</em> article</a>, Reddit CEO Steve Huffman said: “<em>Crawling Reddit, generating value and not returning any of that value to our users is something we have a problem with … It’s a good time for us to tighten things up</em>.”&nbsp;</p><p>Unlike independent publishers, though, Reddit actually had leverage over Google. Reddit was the owner of a trove of historical user generated content that Google wanted for its grand AI plans.&nbsp;</p><p>If Google could secure a deal for Reddit’s content, maybe that would spare Google the expense of negotiating licensing deals with the web’s many disparate publishers and rightsholders.&nbsp;</p><p>We didn’t know it at the time, but <strong>even as Google strung publishers along in 2023 with false promises of a public discussion, behind closed doors the search monopolist was negotiating a private contract with Reddit</strong>.&nbsp;</p><p>Although I and others had our suspicions at the time, the existence of the Reddit-Google negotiations remained a secret until their eventual deal <a href="https://www.reuters.com/technology/reddit-ai-content-licensing-deal-with-google-sources-say-2024-02-22/" target="_blank" rel="noopener">was announced</a> in February, 2024.&nbsp;</p><p>(more on that later)&nbsp;</p><p>Meanwhile, as summer 2023 drew to a close, Google was working on algorithm updates that would start laying the groundwork for its “reimagined” AI-first version of search – and for a new social contract for the web that it would unilaterally write.&nbsp;</p><p>A new social contract that, as it would turn out, excluded independent publishers …&nbsp;</p><h2>Google Begins Demolishing the Open Web So It Can “Reimagine Search” from the “Ground Up” for an AI-First Future</h2><p>In summer 2023, we and many other publishers were very apprehensive about AI. But some of us held out hope Google might responsibly guide the open web through the transition to the AI future.&nbsp;</p><p>At Travel Lemming, we continued to invest exclusively in content “written by people, for people” even as pressure grew in the industry to use new AI tools to create cheaper content at scale.&nbsp;</p><p>Importantly, <em>Google still claimed</em> in its webmaster documentation that it wanted to prioritize human-created content in its ranking algorithms.&nbsp;</p><p>Surely, I thought, Google would realize that publishers are the beating heart of the open web ecosystem – and that even an AI-first future requires publishers who create fresh material for AIs to use and learn from.&nbsp;</p><p>In my view, AI is a poor substitute for human publishers.&nbsp;</p><p>AI is inherently derivative.&nbsp;</p><p>AI cannot experience the world.&nbsp;</p><div><p>AI cannot visit a place.</p><p>AI cannot handle a product.&nbsp;</p></div><p>AI can only take, summarize, and regurgitate what <em>other </em>actual humans have created.&nbsp;</p><p>And, most importantly, Google had spent the prior years making <em>such </em>a big deal about wanting to elevate content “by people, for people.”&nbsp;</p><p><strong>After making such a big deal about the importance of human content, wouldn’t it be hypocritical for Google to suddenly put AI content at the center of search?&nbsp;</strong></p><p>Well, yes, it would be.&nbsp;</p><p>So …&nbsp;</p><h2>Google Quietly Erased “Written by People” From Its Guidance for Websites</h2><p>Google did what any good monopolist does when it gets caught breaking the rules. It just changed the rulebook.&nbsp;</p><p>On September 14, 2023, <a href="https://gizmodo.com/google-search-written-by-people-helpful-content-update-1850848956" target="_blank" rel="noopener">Google quietly updated its documentation</a> to remove “written by people” from its guidance for websites:</p><figure><img decoding="async" width="1024" height="427" src="https://travellemming.com/wp-content/uploads/Googles-Change-1024x427.jpg" alt="A graphic showing changes from Google" srcset="https://travellemming.com/wp-content/uploads/Googles-Change-1024x427.jpg 1024w, https://travellemming.com/wp-content/uploads/Googles-Change-300x125.jpg 300w, https://travellemming.com/wp-content/uploads/Googles-Change-768x320.jpg 768w, https://travellemming.com/wp-content/uploads/Googles-Change-600x250.jpg 600w, https://travellemming.com/wp-content/uploads/Googles-Change.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20width='1024'%20height='427'%20viewBox='0%200%201024%20427'%3E%3C/svg%3E" data-src="https://travellemming.com/wp-content/uploads/Googles-Change-1024x427.jpg" data-srcset="https://travellemming.com/wp-content/uploads/Googles-Change-1024x427.jpg 1024w, https://travellemming.com/wp-content/uploads/Googles-Change-300x125.jpg 300w, https://travellemming.com/wp-content/uploads/Googles-Change-768x320.jpg 768w, https://travellemming.com/wp-content/uploads/Googles-Change-600x250.jpg 600w, https://travellemming.com/wp-content/uploads/Googles-Change.jpg 1200w"><figcaption><em>A before and after screenshot showing Google’s change (Source: </em><a href="https://searchengineland.com/google-september-2023-helpful-content-system-update-rolling-out-431978" target="_blank" rel="noopener"><em>Search Engine Land</em></a><em>)</em></figcaption></figure><h2>The Same Day, Google Unleashed an Algorithmic Wrecking Ball on Independent Web Publishers</h2><p>To reimagine search from the ground up, Google had to begin by tearing down what was currently there.&nbsp;</p><p>By this summer 2023, Google knew it wanted to insert AI directly into search results.&nbsp;</p><p>But rolling out AI all at once would mean a massive drop in clicks for publishers – and a potential litigation threat for Google.&nbsp;</p><p><strong>So Google started its AI demolition project by razing the parts of the open web least capable of fighting back: independent publishers.&nbsp;</strong></p><p>Google implemented this demolition project under the pretext of search ranking algorithm updates.&nbsp;</p><p>Google frequently adjusts its rankings algorithms to change how its systems rank web content. Announced algorithm updates happen several times a year and are a recurring part of life for publishers on the open web.&nbsp;</p><p>As a publisher focused on human-first content, Travel Lemming had never really worried too much about Google’s updates.&nbsp;</p><p>Indeed, Google’s <a href="https://developers.google.com/search/updates/core-updates#:~:text=updates%20status" target="_blank" rel="noopener">guidance to webmasters</a> still states that “<em>most sites don’t need to worry about core updates and may not even realize one has happened</em>.”&nbsp;</p><p>And, indeed, Travel Lemming had never once seen a negative effect from a Google update.&nbsp;</p><p>Plus, even when I witnessed other sites getting hit by past updates, the effect typically was only partial (something on the order of a 10-25% drop in traffic). And those webmasters were usually given opportunities to improve their site and to recover ranking, which they often did.&nbsp;</p><p>But this time was different.&nbsp;</p><p><strong>On September 14, 2023 – the same day Google removed “written by people” from its guidance – a massive Google algo was announced.&nbsp;</strong></p><p><strong>Almost immediately, search referral traffic to Travel Lemming plummeted:&nbsp;</strong></p><figure><img decoding="async" width="1024" height="566" src="https://travellemming.com/wp-content/uploads/Travel-Lemmings-Google-Search-Console-1024x566.jpg" alt="A graphic showing the Travel Lemming's search traffic in Google Search Console" srcset="https://travellemming.com/wp-content/uploads/Travel-Lemmings-Google-Search-Console-1024x566.jpg 1024w, https://travellemming.com/wp-content/uploads/Travel-Lemmings-Google-Search-Console-300x166.jpg 300w, https://travellemming.com/wp-content/uploads/Travel-Lemmings-Google-Search-Console-768x424.jpg 768w, https://travellemming.com/wp-content/uploads/Travel-Lemmings-Google-Search-Console-600x332.jpg 600w, https://travellemming.com/wp-content/uploads/Travel-Lemmings-Google-Search-Console.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20width='1024'%20height='566'%20viewBox='0%200%201024%20566'%3E%3C/svg%3E" data-src="https://travellemming.com/wp-content/uploads/Travel-Lemmings-Google-Search-Console-1024x566.jpg" data-srcset="https://travellemming.com/wp-content/uploads/Travel-Lemmings-Google-Search-Console-1024x566.jpg 1024w, https://travellemming.com/wp-content/uploads/Travel-Lemmings-Google-Search-Console-300x166.jpg 300w, https://travellemming.com/wp-content/uploads/Travel-Lemmings-Google-Search-Console-768x424.jpg 768w, https://travellemming.com/wp-content/uploads/Travel-Lemmings-Google-Search-Console-600x332.jpg 600w, https://travellemming.com/wp-content/uploads/Travel-Lemmings-Google-Search-Console.jpg 1200w"><figcaption><em>A graphic of Travel Lemming’s search referral traffic report in Google Search Console, overlaid with contemporaneous headlines</em><sup data-fn="ce0a92e3-1027-45cd-a7ba-0c787e4a8635"><a id="ce0a92e3-1027-45cd-a7ba-0c787e4a8635-link" href="#ce0a92e3-1027-45cd-a7ba-0c787e4a8635">1</a></sup></figcaption></figure><p>The effect on Travel Lemming’s traffic and business was swift and devastating.&nbsp;</p><p>That September update that hit us was nicknamed “The Helpful Content Update.” It was an update to the content system Google had announced a year earlier.&nbsp;</p><p>And it was only the beginning of the carnage …&nbsp;</p><h2>Between Fall 2023 and Spring 2024, Google Updates Systematically Demolished Independent Publishers&nbsp;</h2><p>Between fall 2023 and spring 2024, <a href="https://www.bbc.com/future/article/20240524-how-googles-new-algorithm-will-shape-your-internet" target="_blank" rel="noopener">Google unleashed a flurry of updates</a> on a scale that hadn’t been seen in nearly a decade, both in terms of their frequency and their overall effect on the web ecosystem.&nbsp;</p><p><span><strong>By the time this wave of updates finished in May 2024, Travel Lemming’s organic search referrals from Google had been reduced by more than 97%.</strong></span></p><p>At least our site was not alone in our misery.&nbsp;</p><p>Google’s flurry of updates decimated independent sites across the board: <a href="https://housefresh.com/david-vs-digital-goliaths/" target="_blank" rel="noopener">product review sites</a>, <a href="https://retrododo.com/google-is-killing-retro-dodo/" target="_blank" rel="noopener">gaming sites</a>, <a href="https://www.giantfreakinrobot.com/ent/independent-ends.html" target="_blank" rel="noopener">entertainment websites</a>, <a href="https://www.youtube.com/watch?v=FozpcXclAtU" target="_blank" rel="noopener">fitness websites</a>, and more verticals felt the pain.<sup data-fn="e12e5083-12e3-4b59-89d8-3ea5f445a7db"><a id="e12e5083-12e3-4b59-89d8-3ea5f445a7db-link" href="#e12e5083-12e3-4b59-89d8-3ea5f445a7db">2</a></sup></p><p><strong>In short, the period from fall 2023 to spring 2024 was an absolute bloodbath for independent websites.</strong></p><p>As <a href="https://www.cnet.com/tech/services-and-software/google-search-changes-are-killing-websites-in-an-age-of-ai-spam/" target="_blank" rel="noopener"><em>CNET </em>described it in an article</a> I was interviewed for, “<em>Google’s major search algorithm updates this past year have left many smaller websites with no other choice than to lay off staff. The internet is worse for it.</em>”</p><p>The travel vertical in particular was hit particularly hard.&nbsp;</p><p>An <a href="https://digitaloft.co.uk/the-impact-of-googles-helpful-content-update-on-travel-publishers/" target="_blank" rel="noopener">analysis by Digitaloft</a> found that <strong>78% of travel publishers lost organic traffic during these updates – and 32% lost more than 90% of their organic traffic</strong>.&nbsp;</p><p>Furthermore, the handful of travel publishers who survived were almost all owned by large mainstream media corporations.</p><h2>Google Initially Claimed It Was Only Shadowbanning Websites of “Little Value”&nbsp;</h2><p>When the September, 2023 “HCU” update rolled out, Google provided written guidance to affected site owners.&nbsp;</p><div><p>Google has since deleted those statements but they are archived <a href="http://web.archive.org/web/20231101203407/https://developers.google.com/search/updates/helpful-content-update" target="_blank" rel="noopener">here</a>.</p><p>Google initially claimed the shadowbanning algorithm that hit my site “<em>automatically identifies content that seems to have little value, low-added value or is otherwise not particularly helpful to people</em>.”</p></div><p>It was hurtful to hear Google thought our site was of “little value” to the web.</p><p>As creators, we at Travel Lemming pride ourselves on sharing our personal travel experiences and pouring our soul into making original, helpful guides. Our readers agree, consistently rating our guides an average of 4.7 out of 5 stars.&nbsp;</p><p>But now Google’s algorithms were saying our entire site was of “little value.”&nbsp;</p><div><p>But Google Promised Siteowners Like Us That We Could Recover</p><p>But Google’s <a href="http://web.archive.org/web/20231101203407/https://developers.google.com/search/updates/helpful-content-update" target="_blank" rel="noopener">guidance</a> was also telling us that recovery was possible if we just “removed” our “unhelpful” on-page content:&nbsp;</p></div><blockquote><p><em>“If you’ve noticed a change in traffic you suspect may be related to this system (such as after a publicly-posted ranking update to the system), then </em><strong><em><span>you should self-assess your content and fix or remove any that seems unhelpful</span></em></strong><em>. Our help page on how to create helpful, reliable people-first content has questions that you can use to self-assess your content to be successful with the helpful content system.</em></p></blockquote><blockquote><p><em>A natural question some will have is how long will it take for a site to do better, if it removes unhelpful content? Sites identified by this system may find the signal applied to them over a period of months. </em><strong><em><span>Our classifier runs continuously</span></em></strong><em>, allowing it to monitor newly-launched sites and existing ones. </em><strong><em><span>As it determines that the unhelpful content hasn’t returned in the long-term, the classification will no longer apply</span></em></strong><em>.” </em></p></blockquote><blockquote><p><em>-Source: </em><a href="http://web.archive.org/web/20231101203407/https://developers.google.com/search/updates/helpful-content-update" target="_blank" rel="noopener"><em>archived version of Google’s since-deleted guidance</em></a><em> (emphasis added)</em></p></blockquote><p>Note Google represented that these were <em>content</em>-based updates, and said that making content more “helpful” – or deleting a site’s weakest content entirely – could lead to recovery.</p><p>Google’s <a href="https://developers.google.com/search/blog/2022/08/helpful-content-update" target="_blank" rel="noopener">documentation</a> further stated that the “classifier” that had shadowbanned our sites ran “<em>continuously</em>,” meaning it would be constantly re-calculated in “<em>real-time</em>.”&nbsp;</p><p>Further, Google said the classifier was “<em>weighted</em>.” Had that been true (it wasn’t), it would have meant that at least partial recovery was possible even with just partial content “improvement.”&nbsp;</p><p>In retrospect, the first sign of Google’s lies was that it replaced indie sites with content that clearly violated Google’s own guidelines (but more on that later).&nbsp;</p><h2>My Site, And Many Others, Invested Precious Time and Resources Chasing Google’s False Promises</h2><p>Despite being hurt by Google calling us of “little value” and brutally shadowbanning us from the web, many of us affected site owners actually took Google’s statements to heart.&nbsp;</p><p>Us independent site owners are also small business owners.&nbsp;</p><p>For many of us, our sites aren’t just our livelihoods – they are also our passion projects.&nbsp;</p><p>I consider Travel Lemming my life’s work. I’ve always wanted it to be the most helpful site it can be, and not just because Google tells me so.&nbsp;</p><p>And, while I thought Travel Lemming’s guides were high quality, every site can always improve further. So that’s what we set out to do.&nbsp;</p><p>The entire team at Travel Lemming invested nearly a year of time and more than six-figures of resources turning our content upside down in an effort to “improve it” and meet Google’s guidelines for content guidelines even more.&nbsp;</p><p>We even removed the majority of our content from Google’s index – leaving only the guides we were 100% confident were abundantly “helpful” beyond any doubt.&nbsp;</p><p>Many other <a href="https://medium.com/@lucwiesman/looking-to-recover-from-the-google-helpful-content-update-or-any-algorithm-update-45c25d0d2b62" target="_blank" rel="noopener">sites invested similar resources</a> trying to recover in vain.&nbsp;</p><p>This investment came at great cost to many of us – because <strong><span>we had to invest such significant resources precisely at the time that our websites were completely starved of search referral traffic</span></strong>.&nbsp;</p><p>But it turns out we were all just chasing Google’s shadows – shadows that kept us all busy while Google worked on its blueprint for reimagining search around AI.&nbsp;</p><h2>But, Despite Those Efforts, Recovery Proved Impossible&nbsp;</h2><div><p>Nearly a year went by and, despite massive efforts, we didn’t recover at all.</p><p>Neither did anyone else.</p><p>In fact, like almost all affected indie sites, we continued to <em>lose </em>rankings further – no matter how much we changed our content.&nbsp;</p></div><p>Something seemed …. wrong.&nbsp;</p><div><p>As it turns out, the algorithms that hit ours and other sites were not really based on content at all.</p><p>Instead, it eventually became clear that these were really “authority” based algorithms. Which is a fancy way of saying that Google decided to promote larger sites over small ones – and it actually had nothing to do with content all along.</p><p>That explained why all our investments in overhauling or deleting content didn’t move the needle.</p></div><p>But it didn’t explain <em>what </em>we indie publishers should do next – other than, as one site owner snarkingly put it to me, “becoming <em>Forbes</em>.”&nbsp;</p><h2>Google Does Not Let Small Independent Sites Appeal Their Shadowbans (But Large Media Companies Can)</h2><p>By mid-2024, we and other affected sites were in a truly terrible position: not only were shadowbanned, but there didn’t seem like there was anything we could even do about it.&nbsp;</p><p><span><strong>Google offers no way to appeal an algorithmic shadow ban like the classifier that hit our site</strong>.</span></p><p>This is why Google usually avoids deploying algorithmic shadowbans against big sites owned by media conglomerates, even when big sites knowingly break Google’s spam policies.&nbsp;</p><p>Instead, when large sites break Google’s rules, Google instead issues them “manual penalties.”&nbsp;</p><p><span><strong>The big publishers then get access to a structured appeal and reconsideration process</strong>.</span></p><p>Google representatives will even help guide these sites through what changes they need to make, until they eventually recover their rankings.&nbsp;</p><p>For example, in March 2024, <a href="https://developers.google.com/search/blog/2024/03/core-update-spam-policies" target="_blank" rel="noopener">Google announced it would supposedly crack down on “site reputation abuse”</a> – a practice where large big-brand websites are able to abuse their site’s authority score to pump out low-effort content en masse.&nbsp;</p><p>Some of these large publications are even known for <a href="https://larslofgren.com/parasite-seo/" target="_blank" rel="noopener">renting out urls on their webpages to third party spammers</a>, a practice known in the spamming community as “Parasite SEO.”&nbsp;</p><p>This spammy practice is only possible because of how heavily Google’s algorithm now favors a site’s “authority” signals (as opposed to actually measuring content helpfulness).&nbsp;</p><p>These large sites were abusing Google’s long-existing policies against low effort content. And they were doing it intentionally.&nbsp;</p><p>But, nonetheless, Google did something unprecedented: it gave these large sites several months advance notice to clean up their act.</p><p><a href="https://developers.google.com/search/blog/2024/03/core-update-spam-policies" target="_blank" rel="noopener">Google said</a>: “<em>To allow time for site owners to prepare for this change, this new policy will take effect starting May 5, 2024</em>.”</p><div><p>I initially expected this meant Google would unleash an algorithm to punish these large sites. But no algorithm update ever hit these sites.</p><p>Instead, in June 2024, <a href="https://x.com/searchliaison/status/1797682174407463280?s=46" target="_blank">Google explained</a> it would “<em>only [be] doing manual actions on scaled content abuse, not algorithmic</em>.”</p></div><p>Why only manual and not algorithmic?&nbsp;</p><p>Google Search Liaison Danny Sullivan answered this in an <a href="https://www.seroundtable.com/interview-google-august-core-update-38024.html" target="_blank" rel="noopener">August, 2024 interview</a>:&nbsp;</p><blockquote><p><em>“There’s no algorithmic action, I don’t expect there to be any algorithmic action anytime in the near future,” Sullivan told me. He said if and when it becomes algorithmic, Google will announce it. Until then, it is not.</em></p></blockquote><blockquote><p><strong><em><span>Why is it not algorithmic?</span></em></strong><em> “The reason we probably won’t have it any time in the near future is </em><strong><em><span>because we wouldn’t be exceedingly careful and, and thoughtful in how we do it</span>.</em></strong><em> So that’s just taking time and for the moment, the manual actions are the way for us to go,” Sullivan explained. </em>(emphasis added)</p></blockquote><p>Google was admitting that it uses manual actions for sites owned by large media conglomerates because it treats them differently than independent sites.&nbsp;</p><p>Large sites are allowed to <em>knowingly and intentionally</em> abuse Google – and the worst risk they face is a manual action that comes with an opportunity to appeal and work with Google to get the manual action lifted.&nbsp;</p><p>As an example of this, a few months later <a href="https://arstechnica.com/gadgets/2024/11/google-cracks-down-on-parasite-seo-punishing-established-publishers/" target="_blank" rel="noopener">Google hit the website <em>Forbes</em></a> for violating Google’s “site reputation abuse” policy.&nbsp;</p><p>This meant <em>Forbes </em>was given access to an appeals and recovery process – <a href="https://www.linkedin.com/posts/lily-ray-44755615_seo-activity-7302339364578066433-H_Vp/" target="_blank" rel="noopener">and was able to recover from the penalty</a> just a few months later.&nbsp;</p><p>Shortly thereafter, a <em>Forbes </em>representative <a href="https://www.wsj.com/business/media/google-search-change-product-recommendation-websites-02394b79" target="_blank" rel="noopener">told <em>The Wall Street Journal</em></a> that “<em>Forbes continues to partner closely with Google</em>” and that Google “<em>has a careful review and appeals process for site owners</em>” that <em>Forbes </em>was able to use to get the manual action lifted quickly.&nbsp;</p><p>Independent sites like us, however, get no such appeals procedure.&nbsp;</p><p>Our entire sites can be permanently shadowbanned from Google by an algorithm.&nbsp;</p><p>Independent site owners exist on Google’s web in a permanent state of anxiety and insecurity. We can be erased by an algorithm at any time – arbitrarily, brutally, and with zero opportunity for appeal.&nbsp;</p><div><p>The one thing we could do was use our voice on our blogs and on platforms like X.</p><p>So, even though many site owners were scared of retaliation by Google, some of us started speaking out publicly about what was happening (examples <a href="https://housefresh.com/how-google-decimated-housefresh/" target="_blank" rel="noopener">here</a>, <a href="https://retrododo.com/google-is-killing-retro-dodo/" target="_blank" rel="noopener">here</a>, <a href="https://healthyframework.com/an-open-letter-to-google-from-a-small-publisher/" target="_blank" rel="noopener">here</a>, <a href="https://worldtravelfamily.com/is-google-destroying-blogging/" target="_blank" rel="noopener">here</a>, and <a href="https://wanderingwheatleys.com/how-google-screwed-the-blogging-community/" target="_blank" rel="noopener">here</a>).&nbsp;</p></div><h2>Google Eventually Admitted Fault – And Invited 20 Creators (Including Me) Out to Google’s Headquarters to Apologize</h2><p>At a certain point the evidence was just too overwhelming to ignore. Too many quality independent sites had been hit too hard for too long.</p><p>Google’s algorithms obviously weren’t working the way Google said they should.</p><div><p>Google even admitted it.</p><p><strong>In October 2024, Google invited me and 19 other independent web creators out to Google’s headquarters in Mountain View, California.</strong></p></div><p>Google gave us a tour of its (mostly empty) campus.</p><figure><img decoding="async" width="1024" height="767" src="https://travellemming.com/wp-content/uploads/Googles-Headquarters-1024x767.jpg" alt="Travel Lemming founder Nate Hake outside the Google’s Headquarters" srcset="https://travellemming.com/wp-content/uploads/Googles-Headquarters-1024x767.jpg 1024w, https://travellemming.com/wp-content/uploads/Googles-Headquarters-300x225.jpg 300w, https://travellemming.com/wp-content/uploads/Googles-Headquarters-768x575.jpg 768w, https://travellemming.com/wp-content/uploads/Googles-Headquarters-600x450.jpg 600w, https://travellemming.com/wp-content/uploads/Googles-Headquarters.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20width='1024'%20height='767'%20viewBox='0%200%201024%20767'%3E%3C/svg%3E" data-src="https://travellemming.com/wp-content/uploads/Googles-Headquarters-1024x767.jpg" data-srcset="https://travellemming.com/wp-content/uploads/Googles-Headquarters-1024x767.jpg 1024w, https://travellemming.com/wp-content/uploads/Googles-Headquarters-300x225.jpg 300w, https://travellemming.com/wp-content/uploads/Googles-Headquarters-768x575.jpg 768w, https://travellemming.com/wp-content/uploads/Googles-Headquarters-600x450.jpg 600w, https://travellemming.com/wp-content/uploads/Googles-Headquarters.jpg 1200w"><figcaption><em>Me at Google’s Headquarters during the event</em></figcaption></figure><p><strong>And Google gave us a clear and unequivocal apology.</strong></p><p><strong>Google said our sites didn’t deserve our shadowbans, and that it wasn’t our fault.</strong></p><p>Personally, I at least felt validated by the apology. I had let the events of the past year shake my sense of self-worth, and it was nice to not be gaslit anymore.</p><p>But, as a fellow creator said at the event, “apologies don’t pay the bills.”</p><p>We all still had no idea of how we could get our sites un-shadowbanned.&nbsp;</p><p>Unfortunately, Google didn’t really have an idea either.</p><h2>Google Told Us There Was Nothing We Could Do to Recover, Because Search Had Permanently Changed With AI</h2><p>We all gave Google a mouthful of our opinions at the event.&nbsp;</p><p>The Commission can review some public accounts of the event from other creator attendees <a href="https://x.com/ichbinGisele/status/1851785266152739289" target="_blank">here</a>, <a href="https://x.com/CharlestonCraft/status/1851467133412393319" target="_blank">here</a>, <a href="https://www.giantfreakinrobot.com/tech/google-creators-event.html" target="_blank" rel="noopener">here</a>, <a href="https://techraptor.net/blog/google-web-creator-conversation-event-2024" target="_blank" rel="noopener">here</a>, <a href="https://betweenenglandandiowa.com/google-web-creator-conversation/" target="_blank" rel="noopener">here</a>, <a href="https://www.linkedin.com/pulse/yesterdays-google-creator-event-seos-take-steve-weber-1f2we/" target="_blank" rel="noopener">here</a>, <a href="https://x.com/TravelerAddicts/status/1851674228308988090" target="_blank">here</a>, <a href="https://goingawesomeplaces.com/google-web-creator-conversation-event-2024-retrospective/" target="_blank" rel="noopener">here</a>, and <a href="https://googhell.substack.com/p/i-was-invited-to-google-hq-to-talk" target="_blank" rel="noopener">here</a>.&nbsp;</p><p>You can read my own post-event reflections <a href="https://x.com/natejhake/status/1851776985724522789" target="_blank">here</a>.&nbsp;</p><p>And you can also read <a href="https://www.bloomberg.com/news/articles/2025-04-07/google-ai-search-shift-leaves-website-makers-feeling-betrayed" target="_blank" rel="noopener">this <em>Bloomberg </em>article</a> for more context.&nbsp;</p><p>At one point I aggressively pressured Google executive Pandu Nayak for specific guidance on how web creators are supposed to survive in Google’s AI-first future.&nbsp;</p><p>Nayak appeared visibly shaken by my questioning, but he ultimately gave no real answers. He made an offhand comment about how we could try using AI to create content (umm, no thank you!). But beyond that, he just blustered about how AI was changing search.</p><div><p>And, ultimately, that was really the main takeaway from the event:</p><p><strong><span>Googlers clearly told us that, even if our algorithmic shadowbans got lifted, our traffic might never return because search had been fundamentally changed by AI over the previous year.</span></strong></p></div><p>I’d note that Googlers used passive phrasing to make it seem like the changing search landscape was a result of forces of nature – and not of Google’s very deliberate decisions.</p><p>But, regardless, the message was clear – AI is fundamentally changing how Google works, and the old ecosystem of search isn’t ever coming back.</p><p>Google did promise to work on improving its algorithms so as to elevate more independent sites like ours.</p><p>While I initially held out some hope, most of my fellow creators left pessimistic that Google actually planned to change anything.</p><p>Unfortunately, time has proven them right.</p><p>As I write this 8 months after the event, Travel Lemming and most other affected sites remain shadowbanned by Google’s algorithms.</p><p>Meanwhile, Google continues to press full-steam ahead on its project of rebuilding search from the ground up with AI …</p><h2>“Rebuilding Search from the Ground Up” – What Did Google Build on the Ground It Demolished?&nbsp;</h2><p>Which brings me to the obvious question you may have:<em> if Google cleared out so many independent publishers, what took their place in search results</em>?&nbsp;</p><p>Well, let’s rewind to spring, 2024, when Google wrapped up its demolition job.&nbsp;</p><div><p>The last of Google’s ground-clearing updates was <a href="https://searchengineland.com/google-march-2024-core-update-rollout-is-now-complete-438713" target="_blank" rel="noopener">announced</a> as complete on April 26, 2024.</p><p>The foundation for Google’s “re-imagining” of search had been laid.&nbsp;</p></div><p>Now it was time for Google to start the process of rebuilding search from the ground up.&nbsp;</p><h2>Google Rolled Out AI Overviews – Two Weeks After Purging Indie Publishers</h2><p>Just two weeks after Google finished clearing out independent publishers <a href="https://www.theguardian.com/technology/article/2024/may/14/google-ai-search-results" target="_blank" rel="noopener">Google announced</a> the next phase in its plans at its annual “I/O’ event:&nbsp;</p><p>Google was putting AI content directly into search results with AI Overviews.&nbsp;</p><figure><img decoding="async" width="1024" height="483" src="https://travellemming.com/wp-content/uploads/AI-Overviews-1024x483.jpg" alt="Google's blog post about AI Overviews" srcset="https://travellemming.com/wp-content/uploads/AI-Overviews-1024x483.jpg 1024w, https://travellemming.com/wp-content/uploads/AI-Overviews-300x142.jpg 300w, https://travellemming.com/wp-content/uploads/AI-Overviews-768x362.jpg 768w, https://travellemming.com/wp-content/uploads/AI-Overviews-600x283.jpg 600w, https://travellemming.com/wp-content/uploads/AI-Overviews.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20width='1024'%20height='483'%20viewBox='0%200%201024%20483'%3E%3C/svg%3E" data-src="https://travellemming.com/wp-content/uploads/AI-Overviews-1024x483.jpg" data-srcset="https://travellemming.com/wp-content/uploads/AI-Overviews-1024x483.jpg 1024w, https://travellemming.com/wp-content/uploads/AI-Overviews-300x142.jpg 300w, https://travellemming.com/wp-content/uploads/AI-Overviews-768x362.jpg 768w, https://travellemming.com/wp-content/uploads/AI-Overviews-600x283.jpg 600w, https://travellemming.com/wp-content/uploads/AI-Overviews.jpg 1200w"><figcaption><em>Google’s </em><a href="https://blog.google/products/search/generative-ai-google-search-may-2024/" target="_blank" rel="noopener"><em>blog post</em></a><em> announcing the roll out of AI Overviews</em></figcaption></figure><p>Google’s AI Overviews work by scraping content from websites, summarizing it with an LLM, and presenting a summarized answer right on Google.&nbsp;</p><p>In its I/O presentation, Google demo’ed of an AI Overview for a question about a broken record player (<a href="https://www.youtube.com/live/XEzRZ35urlk?si=UYUbQroNcWLfZzqy&amp;t=3087" target="_blank" rel="noopener">video here</a>, starting around minute 51):&nbsp;</p><figure><img decoding="async" width="1024" height="556" src="https://travellemming.com/wp-content/uploads/Demo-of-an-AI-Overview-1024x556.jpg" alt="A woman during a Google’s 2024 demo of an AI Overview" srcset="https://travellemming.com/wp-content/uploads/Demo-of-an-AI-Overview-1024x556.jpg 1024w, https://travellemming.com/wp-content/uploads/Demo-of-an-AI-Overview-300x163.jpg 300w, https://travellemming.com/wp-content/uploads/Demo-of-an-AI-Overview-768x417.jpg 768w, https://travellemming.com/wp-content/uploads/Demo-of-an-AI-Overview-600x326.jpg 600w, https://travellemming.com/wp-content/uploads/Demo-of-an-AI-Overview.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20width='1024'%20height='556'%20viewBox='0%200%201024%20556'%3E%3C/svg%3E" data-src="https://travellemming.com/wp-content/uploads/Demo-of-an-AI-Overview-1024x556.jpg" data-srcset="https://travellemming.com/wp-content/uploads/Demo-of-an-AI-Overview-1024x556.jpg 1024w, https://travellemming.com/wp-content/uploads/Demo-of-an-AI-Overview-300x163.jpg 300w, https://travellemming.com/wp-content/uploads/Demo-of-an-AI-Overview-768x417.jpg 768w, https://travellemming.com/wp-content/uploads/Demo-of-an-AI-Overview-600x326.jpg 600w, https://travellemming.com/wp-content/uploads/Demo-of-an-AI-Overview.jpg 1200w"><figcaption><em>Google’s 2024 demo of an AI Overview at Google I/O</em></figcaption></figure><p><strong>Google’s on stage AI Overview demo showed the fabric of the web’s social contract fraying in real time:&nbsp;&nbsp;</strong></p><p>The AI Overview pulled, summarized, and slightly reworded content from the source website <em><a href="https://www.audio-technica.com/en-us/support/balance-tone-arm-set-tracking-force-lp120-usb-lp1240-usb-turntables" target="_blank" rel="noopener">Audio-Technica</a></em>.&nbsp;</p><figure><img decoding="async" width="1024" height="470" src="https://travellemming.com/wp-content/uploads/AI-Overview-Demo-1024x470.jpg" alt="A text similarity analysis showing the similarity of AI Overview demo’s text to a website's content" srcset="https://travellemming.com/wp-content/uploads/AI-Overview-Demo-1024x470.jpg 1024w, https://travellemming.com/wp-content/uploads/AI-Overview-Demo-300x138.jpg 300w, https://travellemming.com/wp-content/uploads/AI-Overview-Demo-768x353.jpg 768w, https://travellemming.com/wp-content/uploads/AI-Overview-Demo-600x276.jpg 600w, https://travellemming.com/wp-content/uploads/AI-Overview-Demo.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20width='1024'%20height='470'%20viewBox='0%200%201024%20470'%3E%3C/svg%3E" data-src="https://travellemming.com/wp-content/uploads/AI-Overview-Demo-1024x470.jpg" data-srcset="https://travellemming.com/wp-content/uploads/AI-Overview-Demo-1024x470.jpg 1024w, https://travellemming.com/wp-content/uploads/AI-Overview-Demo-300x138.jpg 300w, https://travellemming.com/wp-content/uploads/AI-Overview-Demo-768x353.jpg 768w, https://travellemming.com/wp-content/uploads/AI-Overview-Demo-600x276.jpg 600w, https://travellemming.com/wp-content/uploads/AI-Overview-Demo.jpg 1200w"><figcaption><em>A text similarity analysis showing the AI Overview demo’s text was lifted from the source website</em></figcaption></figure><div><p>Notably, the Googler performing the demo was able to “solve” her problem without actually clicking through to the website that created the content that helped her.</p><p>This presents an existential problem for publishers – if searchers can find the information we create without ever visiting our websites, how are we supposed to earn revenue to fund content creation?&nbsp;</p></div><p>Indeed, in the year since, <strong>multiple independent studies have found that the presence of AI Overviews in search results reduces click through rates to web publishers by anywhere from 15% to 55%</strong>. (<em>Sources: </em><a href="https://www.seerinteractive.com/insights/ctr-aio" target="_blank" rel="noopener"><em>Seer Interactive</em></a><em>, </em><a href="https://ahrefs.com/blog/ai-overviews-reduce-clicks/" target="_blank" rel="noopener"><em>Ahrefs</em></a><em>, </em><a href="https://www.amsive.com/insights/seo/google-ai-overviews-new-research-reveals-how-to-navigate-click-drop-off/" target="_blank" rel="noopener"><em>Amisive</em></a>)</p><p>Instead of clicking through to websites, AI Overviews keep searchers clicking around Google – letting Google generate more profit at the expense of the hard work of publishers.&nbsp;</p><h2>Google Plans to Use AI to Monetize Not Just Searchers’ Questions, But Also the Answers</h2><figure><img decoding="async" width="1024" height="768" src="https://travellemming.com/wp-content/uploads/Googles-AI-Overviews-1024x768.jpg" alt="A graphic showing Google's AI" srcset="https://travellemming.com/wp-content/uploads/Googles-AI-Overviews-1024x768.jpg 1024w, https://travellemming.com/wp-content/uploads/Googles-AI-Overviews-300x225.jpg 300w, https://travellemming.com/wp-content/uploads/Googles-AI-Overviews-768x576.jpg 768w, https://travellemming.com/wp-content/uploads/Googles-AI-Overviews-600x450.jpg 600w, https://travellemming.com/wp-content/uploads/Googles-AI-Overviews.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20width='1024'%20height='768'%20viewBox='0%200%201024%20768'%3E%3C/svg%3E" data-src="https://travellemming.com/wp-content/uploads/Googles-AI-Overviews-1024x768.jpg" data-srcset="https://travellemming.com/wp-content/uploads/Googles-AI-Overviews-1024x768.jpg 1024w, https://travellemming.com/wp-content/uploads/Googles-AI-Overviews-300x225.jpg 300w, https://travellemming.com/wp-content/uploads/Googles-AI-Overviews-768x576.jpg 768w, https://travellemming.com/wp-content/uploads/Googles-AI-Overviews-600x450.jpg 600w, https://travellemming.com/wp-content/uploads/Googles-AI-Overviews.jpg 1200w"></figure><p>As <a href="https://zyppy.com/list/ai-overviews-to-google-ads/" target="_blank" rel="noopener">one prominent search expert</a> put it, “<em>Google’s AI Overviews are seemingly designed to shift user clicks away from websites and nudge them towards Google ads</em>.”&nbsp;</p><div><p>At I/O 2024, Google announced its vision for an AI-first future where “<a href="https://www.youtube.com/live/XEzRZ35urlk?si=5wFkl-QLS0_7_9Uz&amp;t=2608" target="_blank" rel="noopener"><em>Google will do the Googling for You</em></a>.”</p><p>Just a week later, at Google’s Marketing Live Keynote, revealed plans for “<a href="https://www.youtube.com/live/feezAE_YAmc?si=ET85SIonmg0bWDfB&amp;t=2130" target="_blank" rel="noopener"><em>Ads that Answer</em></a>” – letting Google monetize not just questions but also the answers themselves.&nbsp;</p></div><div><p>Google’s plan is working.</p><p>Google’s search ad revenue has surged <a href="https://searchengineland.com/us-search-ad-revenues-2024-454410" target="_blank" rel="noopener">16% over the last year</a> – and that’s <em>despite </em>competition from ChatGPT, the maturity of the search market, and the fact that Google’s market share has not grown.&nbsp;</p></div><h2>Google Also Favors Its Own Properties in Search Results&nbsp;</h2><p>Google cut down independent publishers to create space for AI and ads – but also so it could promote its own web properties.&nbsp;</p><div><p>Remember how I said that Google’s algorithmic wrecking balls <a href="https://digitaloft.co.uk/the-impact-of-googles-helpful-content-update-on-travel-publishers/" target="_blank" rel="noopener">hit the travel sector</a> especially hard?</p><p>Well, <strong><span>consider this chart of Google Travel’s search visibility</span></strong> over the past few years:&nbsp;</p></div><figure><img decoding="async" width="1024" height="360" src="https://travellemming.com/wp-content/uploads/Google-Travels-Search-Visibility-1024x360.jpg" alt="A graphic showing the Google Travel search visibility" srcset="https://travellemming.com/wp-content/uploads/Google-Travels-Search-Visibility-1024x360.jpg 1024w, https://travellemming.com/wp-content/uploads/Google-Travels-Search-Visibility-300x106.jpg 300w, https://travellemming.com/wp-content/uploads/Google-Travels-Search-Visibility-768x270.jpg 768w, https://travellemming.com/wp-content/uploads/Google-Travels-Search-Visibility-600x211.jpg 600w, https://travellemming.com/wp-content/uploads/Google-Travels-Search-Visibility.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20width='1024'%20height='360'%20viewBox='0%200%201024%20360'%3E%3C/svg%3E" data-src="https://travellemming.com/wp-content/uploads/Google-Travels-Search-Visibility-1024x360.jpg" data-srcset="https://travellemming.com/wp-content/uploads/Google-Travels-Search-Visibility-1024x360.jpg 1024w, https://travellemming.com/wp-content/uploads/Google-Travels-Search-Visibility-300x106.jpg 300w, https://travellemming.com/wp-content/uploads/Google-Travels-Search-Visibility-768x270.jpg 768w, https://travellemming.com/wp-content/uploads/Google-Travels-Search-Visibility-600x211.jpg 600w, https://travellemming.com/wp-content/uploads/Google-Travels-Search-Visibility.jpg 1200w"><figcaption><em>(Source: </em><a href="https://x.com/lilyraynyc/status/1907130140280385741" target="_blank"><em>Lily Ray X post</em></a><em>)</em></figcaption></figure><p>You may notice that Google Travel’s graph looks like a near-perfect inverse of Travel Lemming’s search referral graph.&nbsp;</p><p>Google also favors its other properties like Youtube and Maps.&nbsp;</p><p>And Google aggressively injecting links back to its own search results within AI Overviews, to keep searchers from clicking out to third party websites.&nbsp;</p><p>One recent study found that “<a href="https://www.searchenginejournal.com/google-links-to-itself-43-of-ai-overviews-point-back-to-google/546574/" target="_blank" rel="noopener"><em>43% Of AI Overviews Point Back To Google</em></a>.”</p><p>Google consistently favors itself above all other websites.</p><p>Though Google does have another favorite recently …&nbsp;</p><h2>Reddit Got an AI Licensing Deal With Google – Plus an “Unprecedented” Boost in Search Visibility – Right Before Its IPO</h2><p>Apart from Google, there is one clear winner from Google’s project of reimagining search: Reddit.&nbsp;</p><p>The same algorithm updates that removed independent publishers from search results also elevated Reddit to a degree never before seen in Google search history:</p><figure><img decoding="async" width="1024" height="343" src="https://travellemming.com/wp-content/uploads/Reddits-Sistrix-Visibility-Graph-1024x343.jpg" alt="A graphic showing the search visibility of Reddit" srcset="https://travellemming.com/wp-content/uploads/Reddits-Sistrix-Visibility-Graph-1024x343.jpg 1024w, https://travellemming.com/wp-content/uploads/Reddits-Sistrix-Visibility-Graph-300x101.jpg 300w, https://travellemming.com/wp-content/uploads/Reddits-Sistrix-Visibility-Graph-768x257.jpg 768w, https://travellemming.com/wp-content/uploads/Reddits-Sistrix-Visibility-Graph-600x201.jpg 600w, https://travellemming.com/wp-content/uploads/Reddits-Sistrix-Visibility-Graph.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20width='1024'%20height='343'%20viewBox='0%200%201024%20343'%3E%3C/svg%3E" data-src="https://travellemming.com/wp-content/uploads/Reddits-Sistrix-Visibility-Graph-1024x343.jpg" data-srcset="https://travellemming.com/wp-content/uploads/Reddits-Sistrix-Visibility-Graph-1024x343.jpg 1024w, https://travellemming.com/wp-content/uploads/Reddits-Sistrix-Visibility-Graph-300x101.jpg 300w, https://travellemming.com/wp-content/uploads/Reddits-Sistrix-Visibility-Graph-768x257.jpg 768w, https://travellemming.com/wp-content/uploads/Reddits-Sistrix-Visibility-Graph-600x201.jpg 600w, https://travellemming.com/wp-content/uploads/Reddits-Sistrix-Visibility-Graph.jpg 1200w"><figcaption><em>Reddit’s Sistrix visibility graph (Source: </em><a href="https://x.com/lilyraynyc/status/1922377910951805244" target="_blank"><em>Lily Ray, X</em></a><em>)&nbsp;</em></figcaption></figure><p>In summer 2024, Steve Paine of the search visibility tool Sistrix told <a href="https://www.businessinsider.com/why-reddit-is-taking-over-google-right-now-2024-4" target="_blank" rel="noopener"><em>Business Insider</em></a> that Reddit’s growth was “<em>unprecedented</em>.”&nbsp;</p><p>He continued: “<em>There hasn’t been a website that’s grown so much search visibility so quickly in the US in at least the last five years</em>.”</p><p><strong>But search visibility was only part of what Google gave Reddit.&nbsp;</strong></p><div><p>Reddit also got cold hard cash.</p><p><strong>On February 22, 2024, </strong><a href="https://www.reuters.com/technology/reddit-ai-content-licensing-deal-with-google-sources-say-2024-02-22/" target="_blank" rel="noopener"><strong>Reddit and Google announced</strong></a><strong> a $60 million per year AI licensing deal.</strong></p><p>Reddit’s sabre-rattling in 2023 about blocking Google’s crawlers had apparently worked.&nbsp;</p></div><p>The deal, as well as the search visibility boost, came at an <em>incredibly </em>convenient time for Reddit and its executives. You see, almost exactly one month after the deal announcement, Reddit completed its IPO and went public on the NYSE.&nbsp;</p><p>Reddit priced its IPO at $34 per share, which was “the top of the target range set by Reddit’s investment bankers” according to <a href="https://www.theguardian.com/technology/2024/mar/20/reddit-stock-market-debut-new-york-exchange" target="_blank" rel="noopener"><em>The Guardian</em></a>. The shares <a href="https://www.theguardian.com/technology/2024/mar/20/reddit-stock-market-debut-new-york-exchange" target="_blank" rel="noopener">popped 48% higher</a> just in their first day of trading.&nbsp;</p><p><strong><span>As of mid-May, 2025, Reddit is </span></strong><a href="https://www.cnbc.com/quotes/RDDT" target="_blank" rel="noopener"><span><strong>trading</strong></span></a><strong><span> at over $100 per share – giving it a market cap of almost $20 billion.</span></strong></p><p>Now, to be fair, Google will say that the two things – Reddit’s boost in search, and its AI licensing deal – are completely unrelated and a total coincidence.&nbsp;</p><p>You can judge the facts for yourself.</p><p>Collusive or coincidence, one thing is clear: <strong>the whole incident shows just how much power Google wields to reshape the entire Internet to its whims all in the span of a few months</strong>.&nbsp;&nbsp;</p><p>And AI will give Google even more power to re-write the Internet:&nbsp;</p><h2>Google Plans to Use AI Licensing Fees to Let It Control Which Websites Survive In the AI-First Future</h2><p>How will websites survive when users don’t need to click through?&nbsp;</p><p>Well, many web experts believe that an AI licensing fee model is the logical replacement for the current “clicks for content” web social contract.&nbsp;</p><p>Google apparently agrees.&nbsp;</p><p><strong>Sundar Pichai </strong><a href="https://deadline.com/2024/12/creators-get-paid-training-ai-google-ceo-sundar-pichai-1236194395/" target="_blank" rel="noopener"><strong>recently said</strong></a><strong>: “</strong><strong><em>There will be a marketplace in the future, I think. There will be creators who create for AI models and get paid for it. I really think that’s part of the future and people will figure it out</em></strong><strong>.”</strong></p><p>But Pichai doesn’t seem to be in a rush to create that marketplace just yet.&nbsp;</p><p>Google paid Reddit $60 million a year for AI licensing fees, but so far refuses to seriously discuss licensing with most other publishers.&nbsp;</p><p>Why?&nbsp;</p><p>Well, Google explained its AI licensing position in a <a href="https://storage.googleapis.com/gweb-uniblog-publish-prod/documents/Google_response_to_UK_Copyright__AI_Consultation_February_2025_hLpZUuW.pdf" target="_blank" rel="noopener">recent letter to the UK government</a>.&nbsp;</p><p>Google said that publishers have a right to opt out of their content appearing in Google search but that “<em>this does not extend to a right to be paid</em>.”&nbsp;</p><p>Google’s letter goes on to explain that Google is open to “<em>negotiating agreements and partnership deals for a variety of situations, including programmatic access to custom APIs, access to data, digitisation, etc</em>.”</p><p>But, Google said: “<em>No single piece of content has value, and as such, pricing becomes </em><strong><em><mark><span>a pure bargaining issue</span></mark></em></strong>.”</p><p>In other words: Google is only willing to pay AI licensing fees to parties (like Reddit) with enough leverage to bargain against the monopolist.&nbsp;</p><p>And, conveniently for Google, the more Google rolls out AI, the less leverage publishers have.&nbsp;</p><p><strong>Like a reality TV game show, Google can slowly eliminate publishers from the web – winnowing Google’s final bargaining counterparties to a small handful of contestants Google gets to select.&nbsp;</strong></p><p>And there are indications Google has already chosen which sites will get a chance to survive in its AI-first future …&nbsp;</p><h2>Google Is Heavily Biased Towards A Few Large Media Conglomerates&nbsp;</h2><p>When Google needed to raze ground to build out its reimagined AI search, independent publishers were an obvious first target for Google.&nbsp;</p><p>After all, small websites typically don’t have the resources to sue, as some larger publications have threatened to do over the years (or, as some like <a href="https://www.courtlistener.com/docket/69668109/1/chegg-inc-v-google-llc/" target="_blank" rel="noopener"><em>Chegg, </em>have actually done recently</a>).</p><div><p>But Google has, at least so far, treated the mega media companies differently – sparing them from its AI wrecking ball (at least so far).</p><p>This, in turn, has led to incredible consolidation of the information ecosystem. In fact, “<strong><em><span>close to half of all of Google’s traffic is going to just a handful, a few hundred websites</span></em></strong>.” (<em>Source: </em><a href="https://sparktoro.com/blog/content-marketing-needs-to-evolve-beyond-seo/" target="_blank" rel="noopener"><em>SparkToro</em></a>)&nbsp;</p></div><div><p>Most of those websites are owned by just 16 VC-backed media conglomerates.</p><p>This consolidation of the information ecosystem hurts users in many invisible ways.&nbsp;</p></div><p>Gisele Navarro of the website <em>HouseFresh</em> has extensively documented how some big brands owned by some of these conglomerates often flood Google with questionable content.&nbsp;</p><p><strong><span>I strongly recommend Commission’s staff review these articles from Gisele:</span></strong></p><ul><li><em>“</em><a href="https://housefresh.com/how-google-decimated-housefresh/" target="_blank" rel="noopener"><em>HouseFresh has virtually disappeared from Google Search results. Now what?</em></a><em>”</em></li>

<li><em>“</em><a href="https://housefresh.com/david-vs-digital-goliaths/" target="_blank" rel="noopener"><em>How Google is killing independent sites like ours</em></a><em>”</em></li>

<li><em>“</em><a href="https://housefresh.com/finding-helpful-content-in-an-enshittified-google/" target="_blank" rel="noopener"><em>How to find helpful content in a sea of made-for-Google BS</em></a><em>”&nbsp;</em></li></ul><p>I personally think many of these large companies are living on borrowed time, and that Google is likely to come for their slots in search results in the next round of its game show.&nbsp;</p><p>I hold out hope some of them will see the light and join independent publishers in speaking out more forcefully against Google.&nbsp;</p><p>But, at least for now, many of these large media conglomerates seem content to be permitted by Google to exist within the monopolist’s walled garden (for now).&nbsp;</p><h2>Google Is Planning to Use AI to Consolidate the Flow of Information Online&nbsp;</h2><p>Google already has the power to control which sources of information users find and click on when they search.</p><p>And, as I’ve shown above, Google is not afraid of abusing its monopoly power to direct users to itself, its partners, or its preferred sources of media.</p><p><strong>But what happens when Google controls not just the </strong><strong><em>sources</em></strong><strong> of information – but also </strong><strong><em>the actual information itself</em></strong><strong>?</strong></p><p><strong>That is exactly what Google aims to do with AI: to become the singular source of all information, opinions, and advice on the web.</strong></p><p>Soon we may not have to worry at all about which websites get clicks from search – because Google won’t be sending clicks to anyone at all.</p><p>Unless, of course, you pay Google to show an “ad that answers” users’ questions.</p><p>And therein lies the rub …</p><h2>Google Isn’t Satisfied With Its Search Monopoly – It Wants a Monopoly on <em>Answers</em></h2><div><p>Google executive Noam Shazeer recently let slip Google’s real plans for AI <a href="https://www.youtube.com/watch?v=v0gjI__RyCY&amp;t=1801s" target="_blank" rel="noopener">in a podcast interview</a>:</p><p>“<strong><em><mark><span>Organizing information is clearly a trillion-dollar opportunity, but a trillion dollars is not cool anymore. What’s cool is a quadrillion dollars</span></mark></em></strong>.”</p></div><p>Indeed, Google is well on its way to realizing that quadrillion dollar opportunity – silently, and with less fanfare than OpenAI.</p><p>Already AI Overviews are used by 1.5 billion users.&nbsp;</p><p>Of course, those 1.5 billion didn’t choose to use AI Overviews – Google just leveraged its monopoly to force AI Overviews on users.</p><p>At <a href="https://www.youtube.com/live/o8NiE3XMPrM?si=QhU951K9WKDuEuqx" target="_blank" rel="noopener">Google’s 2025 I/O event</a>, Google CEO Sundar Pichai even bragged about how Google is leveraging its search monopoly to force AI Overviews on “<em>more people than any product in the world</em>”:</p><figure><img decoding="async" width="1024" height="567" src="https://travellemming.com/wp-content/uploads/Googles-2025-IO-event-1024x567.jpg" alt="The Google CEO during the Google’s 2025 I/O event" srcset="https://travellemming.com/wp-content/uploads/Googles-2025-IO-event-1024x567.jpg 1024w, https://travellemming.com/wp-content/uploads/Googles-2025-IO-event-300x166.jpg 300w, https://travellemming.com/wp-content/uploads/Googles-2025-IO-event-768x426.jpg 768w, https://travellemming.com/wp-content/uploads/Googles-2025-IO-event-600x333.jpg 600w, https://travellemming.com/wp-content/uploads/Googles-2025-IO-event.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20width='1024'%20height='567'%20viewBox='0%200%201024%20567'%3E%3C/svg%3E" data-src="https://travellemming.com/wp-content/uploads/Googles-2025-IO-event-1024x567.jpg" data-srcset="https://travellemming.com/wp-content/uploads/Googles-2025-IO-event-1024x567.jpg 1024w, https://travellemming.com/wp-content/uploads/Googles-2025-IO-event-300x166.jpg 300w, https://travellemming.com/wp-content/uploads/Googles-2025-IO-event-768x426.jpg 768w, https://travellemming.com/wp-content/uploads/Googles-2025-IO-event-600x333.jpg 600w, https://travellemming.com/wp-content/uploads/Googles-2025-IO-event.jpg 1200w"></figure><p>Because, for Google, taking away user choice is precisely the goal anyway …&nbsp;</p><h2>Because Once Google Controls the Answers, It Will Control the People Too</h2><p>Google envisions a future where “Google does the Googling for you” and its AI and ads supply the answers right there on Google – all sourced from a handful of large media conglomerates forced to license their content to Google via contracts of adhesion.&nbsp;</p><p>For Google, a monopoly on answers is the ultimate goal.&nbsp;</p><p>Answers are so powerful because answers dictate people’s decisions.</p><p><strong>So when you control the answers, you actually control the people themselves.</strong></p><p>Americans already use Google to find answers to so much more than relatively frivolous questions like where to travel.</p><p>Americans use Google to find answers on where to live.</p><p>Americans use Google to find answers on what careers to pursue.</p><p>Americans use Google to find answers on whether to have kids.</p><p>Americans use Google to find answers to what medical procedures to get.</p><p>Americans use Google to find answers to what faith to follow.</p><p>Americans use Google to find answers on who to trust.</p><p>And Americans use Google to find answers on how to vote.</p><p><strong><span>I believe that our sources for those answers should be diffuse, varied, and independent – not monopolized by a single tech company.</span></strong></p><p><strong><span>Because if one company can monopolize the people’s answers, it can also monopolize the people’s decisions.</span></strong></p><h2 id="what-you-can-do">What You (Yes, You!) Can Do to Save the Open Web from Google’s AI Takeover<sup data-fn="ddb3fe20-e1d8-4a4d-b2fc-8bd141d6f209"><a href="#ddb3fe20-e1d8-4a4d-b2fc-8bd141d6f209" id="ddb3fe20-e1d8-4a4d-b2fc-8bd141d6f209-link">3</a></sup></h2><p>The open web is under attack by Google and AI – but there is still time to save it, so long as we all act together swiftly. </p><p><strong>Here is what you can do right now to save the open web: </strong></p><ul><li><strong>Share what Google is doing to the open web</strong>. You could start by sharing this article. Alternatively, I’ve left other good articles to share in the <a href="#further-reading">further reading</a> section below.  </li>

<li><strong>Switch your default search engine</strong> to literally anything except Google. Here are <a href="https://www.wikihow.com/Change-Your-Browser's-Default-Search-Engine" target="_blank" rel="noopener">instructions</a>. I use <a href="https://kagi.com/" target="_blank" rel="noopener">Kagi</a> (paid) on desktop and <a href="https://duckduckgo.com/" target="_blank" rel="noopener">DuckDuckGo</a> on mobile. Both are 10x better than Google, and better citizens of the open web. But switching to literally any other search engine will help de-centralize the Internet. </li>

<li><strong>Visit independent publishers directly</strong>. You won’t find many of us on Google anymore, but many of us are still publishing helpful content written by humans — we just need you to find and support us directly. My friend Gisele has a <a href="https://housefresh.com/finding-helpful-content-in-an-enshittified-google/" target="_blank" rel="noopener">good guide on how to do this</a>. If you find an independent website you like, bookmark it. Subscribe to their newsletter. And go straight to that site for your next question. </li>

<li><strong>De-Googlefy your life as much as possible. </strong>From Gmail to to Workspace to Maps to Photos to Calendar to Android to Chrome to hundreds of other products, Google’s grip on our digital lives goes way beyond search. And though many of these products are free (and you may even love some of them), they also fuel Google’s monopolistic ways by providing data about you that Google uses to train its AI systems and entrench its control over the web. Switching away from as many Google products as possible will help starve the monopolist of the data it feeds on. <a href="https://proton.me/blog/how-to-de-google" target="_blank" rel="noopener">Here is a guide</a> with more details.</li>

<li><strong>Call Congress to express support the efforts of the DOJ and the FTC to hold Google to account. </strong>These agencies have been battling Google in court across multiple administrations. No matter your party, you should support these agencies in their fight to break Google’s hold on the open web. One way to do that is to <a href="https://www.house.gov/representatives/find-your-representative" target="_blank" rel="noopener">contact your representatives</a> and express your support for the breakup of Google.</li>

<li><strong>If you are a independent publisher, share your story. </strong>Talk to your audience wherever they can still find you. Tell them what Google is doing to the open web and how they can help. If you publish a post, send it to me so I can help amplify. </li>

<li><strong>If you are a large publisher, now is the time to stop your silence. </strong>I know many large publications are scared to speak up against Google. You may think you’ll get an AI licensing deal. You may think Google will spare you from the AI carnage. I doubt it. And, even if your publication is among the privileged few permitted to exist behind Google’s walled garden, Google will still squeeze you for every penny it can. If you work at one of these publications, please push your editors to stop being silent about what Google is doing to the open web with AI. If you need sources or material, reach out to me. </li></ul><p>There was a web before Google and there will be a web after Google, so long as we all decide to take back control of our online lives before it’s too late. </p><h2>Recommendations for the Commission</h2><ul><li>Investigate Google’s algorithm updates in 2023 and 2024 for evidence that they were pretextual efforts to wrongly censor specific categories of web publishers and/or to unfairly promote Google’s AI ambitions</li>

<li>Require Google to treat independent websites the same way as large publications, including by for example giving siteowners an explanation for shadowbans and an appeals process</li>

<li>Continue to support the Department of Justice’s effort to break Google’s monopoly on Search, so publishers have more leverage in the information economy of the future</li>

<li>Investigate Google’s potentially collusive actions with other information market participants like Reddit</li>

<li>Require Google to publicly report important statistics necessary for publishers to fairly compete in an AI-first online economy, such as click through rates for AI Overviews and AI Mode</li>

<li>Require AI companies like Google to disclose their AI training material</li>

<li>Require AI companies like Google to give rightsholders granular consent and control mechanisms</li>

<li>Take steps to force AI companies like Google to pay just compensation to rightsholders when they use our content to train their AI models&nbsp;</li></ul><h2>Conclusion</h2><p>If you’ve read this far, I thank you from the bottom of my heart for hearing me out. Believe it or not, this was the abbreviated version of my story. If the Commission wants further information or explanation, I’ve got a lot more to say and would be happy to be contacted.</p><p>I realize few people care about the plight of a struggling travel blogger.</p><p>But I truly believe that we independent publishers were the canaries in the coal mine.</p><p>What Google did to censor us with AI it can do to others – and America and the world will be worse off for it.</p><p>I pray that the Commission and the Department of Justice will stop this evil monopolist before it’s too late for us all.</p><p><strong><mark>I truly believe you are the last best hope for freedom online.</mark></strong></p><p id="further-reading"><strong><em>Further reading:&nbsp;</em></strong></p><ul><li>“<a href="https://www.bbc.com/future/article/20240524-how-googles-new-algorithm-will-shape-your-internet" target="_blank" rel="noopener">Google just updated its algorithm. The Internet will never be the same</a>” –<em>BBC </em>(May 25, 204)</li>

<li>“<a href="https://housefresh.com/david-vs-digital-goliaths/" target="_blank" rel="noopener">How Google is killing independent sites like ours</a>” –<em>HouseFresh</em> (February 19, 2024)</li>

<li>“<a href="https://www.cnet.com/tech/services-and-software/google-search-changes-are-killing-websites-in-an-age-of-ai-spam/" target="_blank" rel="noopener">Google Search Changes Are Killing Websites in an Age of AI Spam</a>” –<em>CNET</em> (December 23, 2024)</li>

<li>“<a href="https://www.bloomberg.com/news/articles/2025-04-07/google-ai-search-shift-leaves-website-makers-feeling-betrayed" target="_blank" rel="noopener">Google AI Search Shift Leaves Website Makers Feeling ‘Betrayed’</a>” – <em>Bloomberg </em>(April 7, 2025)</li>

<li>“<a href="https://podcasts.apple.com/us/podcast/the-open-web-is-under-attack/id1514456916?i=1000704428299" target="_blank" rel="noopener">The Open Web is Under Attack</a>” –<em>Next in Media Podcas</em>t (April 22, 2025)</li></ul><p><strong><em>Footnotes</em></strong>:</p><ol><li id="ce0a92e3-1027-45cd-a7ba-0c787e4a8635">&nbsp;“<a href="https://gizmodo.com/google-search-written-by-people-helpful-content-update-1850848956" target="_blank" rel="noopener">Google Quietly Removes ‘Written By People’ From Suggestions for Website Owners</a>” –<em>Gizmodo</em> (September 18, 2023)<br>“<a href="https://www.theverge.com/2024/5/2/24147152/google-search-seo-publishing-housefresh-product-reviews" target="_blank" rel="noopener">Google is getting even worse for independent sites</a>” –<em>The Verge</em> (May 2, 2024)<br>“<a href="https://www.theverge.com/2024/10/30/24283871/google-cant-guarantee-that-independent-sites-will-recover-from-search-changes" target="_blank" rel="noopener">Google “can’t guarantee” that independent sites will recover from Search changes</a>” –<em>The Verge</em> (October 31, 2024)<br> <a href="#ce0a92e3-1027-45cd-a7ba-0c787e4a8635-link" aria-label="Jump to footnote reference 1">↩︎</a></li><li id="e12e5083-12e3-4b59-89d8-3ea5f445a7db">Curiously, based on my own observations, one significant vertical <em>does </em>seem to have been at least partially spared from the carnage: recipes. I think it is relevant that recipes is the <em>only </em>vertical where <a href="https://www.androidcentral.com/apps-software/google-is-working-with-publishers-to-show-you-a-quick-view-for-recipes-in-a-limited-test" target="_blank" rel="noopener">Google has done direct content licensing deals</a> with (select) independent publishers. <a href="#e12e5083-12e3-4b59-89d8-3ea5f445a7db-link" aria-label="Jump to footnote reference 2">↩︎</a></li><li id="ddb3fe20-e1d8-4a4d-b2fc-8bd141d6f209"><em>Editor’s Note: this section with action items for readers was added to this blog post and did not appear in my original letter to the FTC. I also fixed a few typos from the original and added a link to the BBC article in the “further reading” section, and clarified that Mueller’s post was restricted, not entirely deleted. The original letter was directed to the FTC’s specific requests, but I didn’t want to leave readers without actionable steps.</em> <a href="#ddb3fe20-e1d8-4a4d-b2fc-8bd141d6f209-link" aria-label="Jump to footnote reference 3">↩︎</a></li></ol><!-- FeedbackWP Plugin --><!-- [element-154392] --><!-- [/element-154392] --></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Edamagit: Magit for VSCode (118 pts)]]></title>
            <link>https://github.com/kahole/edamagit</link>
            <guid>44123953</guid>
            <pubDate>Thu, 29 May 2025 07:58:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/kahole/edamagit">https://github.com/kahole/edamagit</a>, See on <a href="https://news.ycombinator.com/item?id=44123953">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><div dir="auto"><h2 tabindex="-1" dir="auto">
  <br>
  <a href="https://marketplace.visualstudio.com/items?itemName=kahole.magit" rel="nofollow">
    <img src="https://github.com/kahole/edamagit/raw/develop/images/edamagit_logo.png" alt="edamagit" width="120">
  </a>
  <br>
  edamagit
  <br>
</h2><a id="user-content---------------edamagit--" aria-label="Permalink: 
  edamagit
  " href="#--------------edamagit--"></a></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Magit for VSCode, inspired by the awesome original <a href="https://magit.vc/" rel="nofollow">Magit</a>.</h3><a id="user-content-magit-for-vscode-inspired-by-the-awesome-original-magit" aria-label="Permalink: Magit for VSCode, inspired by the awesome original Magit." href="#magit-for-vscode-inspired-by-the-awesome-original-magit"></a></p>
<p dir="auto">
  <a href="https://marketplace.visualstudio.com/items?itemName=kahole.magit" rel="nofollow">
      <img src="https://camo.githubusercontent.com/b7952d4bc4f5a179cad80c3d4448d14114c09a1ecc2a367624573f39d69be7bd/68747470733a2f2f696d672e736869656c64732e696f2f76697375616c2d73747564696f2d6d61726b6574706c6163652f762f6b61686f6c652e6d616769743f636f6c6f723d677265656e266c6162656c3d56532532304d61726b6574706c616365" data-canonical-src="https://img.shields.io/visual-studio-marketplace/v/kahole.magit?color=green&amp;label=VS%20Marketplace">
  </a>
  <a href="https://open-vsx.org/extension/kahole/magit" rel="nofollow">
    <img src="https://camo.githubusercontent.com/20994c7168ae72130ee7b88596911519bafcf0b9f4a249bdf07fbfc79255f84c/68747470733a2f2f696d672e736869656c64732e696f2f6f70656e2d7673782f762f6b61686f6c652f6d616769743f636f6c6f723d626c7565" data-canonical-src="https://img.shields.io/open-vsx/v/kahole/magit?color=blue">
  </a>
  <a href="https://www.buymeacoffee.com/kahole" rel="nofollow"><img src="https://camo.githubusercontent.com/67f1b859c85032255c81e5f861a5f572fa25813c2ea5e7623b7efa91c395e37f/68747470733a2f2f63646e2e6275796d6561636f666665652e636f6d2f627574746f6e732f64656661756c742d6f72616e67652e706e67" height="28" data-canonical-src="https://cdn.buymeacoffee.com/buttons/default-orange.png">
  </a>
  <a href="https://github.com/sponsors/kahole"><img src="https://camo.githubusercontent.com/9b229f65216c76fb730e4467eda4e312be36d1aa5aab3e9130346ddfd932cd60/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d53706f6e736f72266d6573736167653d254532253944254134266c6f676f3d47697448756226636f6c6f723d70696e6b" data-canonical-src="https://img.shields.io/static/v1?label=Sponsor&amp;message=%E2%9D%A4&amp;logo=GitHub&amp;color=pink"></a>
</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">
  <a href="#usage">Usage</a> •
  <a href="https://kahole.github.io/hole.dev/articles/edamagit-introduction/" rel="nofollow">Tutorial</a> •
  <a href="#settings">Settings</a> •
  <a href="#vim-support-vscodevim">Vim Bindings</a> •
  <a href="#roadmap">Roadmap</a>
</h3><a id="user-content---usage---tutorial---settings---vim-bindings---roadmap" aria-label="Permalink: Usage •
  Tutorial •
  Settings •
  Vim Bindings •
  Roadmap" href="#--usage---tutorial---settings---vim-bindings---roadmap"></a></p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Keyboard driven Git interface</h2><a id="user-content-keyboard-driven-git-interface" aria-label="Permalink: Keyboard driven Git interface" href="#keyboard-driven-git-interface"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/kahole/edamagit/raw/5ebf38107c6130cc16a23f18d84aeecc21f09fe8/magit_commit_demo.gif"><img src="https://github.com/kahole/edamagit/raw/5ebf38107c6130cc16a23f18d84aeecc21f09fe8/magit_commit_demo.gif" alt="Usage" data-animated-image=""></a>
(Theme: <a href="https://draculatheme.com/" rel="nofollow">Dracula</a>)</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>VSCode Command</th>
<th>Default shortcut</th>
</tr>
</thead>
<tbody>
<tr>
<td>Magit Status</td>
<td><code>alt+x g</code></td>
</tr>
<tr>
<td>Magit File Popup</td>
<td><code>alt+x alt+g</code></td>
</tr>
<tr>
<td>Magit Dispatch</td>
<td><code>alt+x ctrl+g</code></td>
</tr>
<tr>
<td>Magit Help (when in status view)</td>
<td><code>?</code></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><code>&gt; Magit </code> in VSCode Command palette will show you all available Magit actions from where you are.</p>
<p dir="auto">Keybindings inside edamagit</p>
<div data-snippet-clipboard-copy-content="Popup and dwim commands
  A Cherry-pick      b Branch           c Commit
  d Diff             f Fetch            F Pull
  I Ignore           l Log              m Merge
  M Remote           P Push             r Rebase
  t Tag              V Revert           X Reset
  y Show Refs        z Stash            shift+1 Run
  shift+5 Worktree   o Submodules       shift+4 Process Log

Applying changes
  a Apply          s Stage          u Unstage
  v Reverse        S Stage all      U Unstage all
  k Discard

Essential commands
  g        refresh current buffer
  TAB      toggle section at point
  RET      visit thing at point
  shift+4  show git process view
  q        exit / close magit view

  ctrl+j Move cursor to next entity
  ctrl+k Move cursor to previous entity"><pre><code>Popup and dwim commands
  A Cherry-pick      b Branch           c Commit
  d Diff             f Fetch            F Pull
  I Ignore           l Log              m Merge
  M Remote           P Push             r Rebase
  t Tag              V Revert           X Reset
  y Show Refs        z Stash            shift+1 Run
  shift+5 Worktree   o Submodules       shift+4 Process Log

Applying changes
  a Apply          s Stage          u Unstage
  v Reverse        S Stage all      U Unstage all
  k Discard

Essential commands
  g        refresh current buffer
  TAB      toggle section at point
  RET      visit thing at point
  shift+4  show git process view
  q        exit / close magit view

  ctrl+j Move cursor to next entity
  ctrl+k Move cursor to previous entity
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto"><a href="https://kahole.github.io/hole.dev/articles/edamagit-introduction/" rel="nofollow">[ See also the edamagit tutorial ]</a></h2><a id="user-content--see-also-the-edamagit-tutorial-" aria-label="Permalink: [ See also the edamagit tutorial ]" href="#-see-also-the-edamagit-tutorial-"></a></p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Settings</h2><a id="user-content-settings" aria-label="Permalink: Settings" href="#settings"></a></p>
<ul dir="auto">
<li><code>Forge-enabled</code>: Enable Forge functionality (show pull requests, issues, etc from e.g. Github)</li>
<li><code>Display-buffer-function</code>: Choose which side for magit windows to open on.</li>
<li><code>Hide-status-sections</code>: Hide listed sections from status view.</li>
<li><code>Quick-switch-enabled</code>: Automatically confirm switch menu after enabling a switch (e.g. --force)</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Monorepo support</h2><a id="user-content-monorepo-support" aria-label="Permalink: Monorepo support" href="#monorepo-support"></a></p>
<p dir="auto">When used in a monorepo, you need to make sure that the subdirectory can detect the parent's <code>.git</code>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="{
  &quot;git.openRepositoryInParentFolders&quot;: &quot;always&quot;,
}"><pre>{
  <span>"git.openRepositoryInParentFolders"</span>: <span><span>"</span>always<span>"</span></span>,
}</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Vim support (VSCodeVim)</h2><a id="user-content-vim-support-vscodevim" aria-label="Permalink: Vim support (VSCodeVim)" href="#vim-support-vscodevim"></a></p>
<p dir="auto">All edamagit keybindings are customizable using VSCode's built-in <code>keybindings.json</code>.</p>
<p dir="auto">Below are bindings providing evil-magit / spacemacs like keybindings.</p>
<p dir="auto">The negative bindings, e.g. <code>-magit.discard-at-point</code> for key <code>k</code>,
remove the default edamagit bindings and the collisions with the Vim extension.</p>
<p dir="auto"><a href="https://code.visualstudio.com/docs/getstarted/keybindings#_advanced-customization" rel="nofollow">Open your <code>keybindings.json</code></a> and paste the following JSON snippet.</p>
<details>
  <summary>Bindings - keybindings.json</summary>
<div dir="auto" data-snippet-clipboard-copy-content="  {
     &quot;key&quot;: &quot;g g&quot;,
     &quot;command&quot;: &quot;cursorTop&quot;,
     &quot;when&quot;: &quot;editorTextFocus &amp;&amp; editorLangId == 'magit' &amp;&amp; vim.mode =~ /^(?!SearchInProgressMode|CommandlineInProgress).*$/&quot; 
  },
  { &quot;key&quot;: &quot;g r&quot;,
     &quot;command&quot;: &quot;magit.refresh&quot;,
     &quot;when&quot;: &quot;editorTextFocus &amp;&amp; editorLangId == 'magit' &amp;&amp; vim.mode =~ /^(?!SearchInProgressMode|CommandlineInProgress).*$/&quot; 
  },
  {
    &quot;key&quot;: &quot;tab&quot;,
    &quot;command&quot;: &quot;extension.vim_tab&quot;,
    &quot;when&quot;: &quot;editorTextFocus &amp;&amp; vim.active &amp;&amp; !inDebugRepl &amp;&amp; vim.mode != 'Insert' &amp;&amp; editorLangId != 'magit'&quot;
  },
  {
    &quot;key&quot;: &quot;tab&quot;,
    &quot;command&quot;: &quot;-extension.vim_tab&quot;
  },
  {
    &quot;key&quot;: &quot;x&quot;,
    &quot;command&quot;: &quot;magit.discard-at-point&quot;,
    &quot;when&quot;: &quot;editorTextFocus &amp;&amp; editorLangId == 'magit' &amp;&amp; vim.mode =~ /^(?!SearchInProgressMode|CommandlineInProgress).*$/&quot;
  },
  {
    &quot;key&quot;: &quot;k&quot;,
    &quot;command&quot;: &quot;-magit.discard-at-point&quot;
  },
  {
    &quot;key&quot;: &quot;-&quot;,
    &quot;command&quot;: &quot;magit.reverse-at-point&quot;,
    &quot;when&quot;: &quot;editorTextFocus &amp;&amp; editorLangId == 'magit' &amp;&amp; vim.mode =~ /^(?!SearchInProgressMode|CommandlineInProgress).*$/&quot;
  },
  {
    &quot;key&quot;: &quot;v&quot;,
    &quot;command&quot;: &quot;-magit.reverse-at-point&quot;
  },
  {
    &quot;key&quot;: &quot;shift+-&quot;,
    &quot;command&quot;: &quot;magit.reverting&quot;,
    &quot;when&quot;: &quot;editorTextFocus &amp;&amp; editorLangId == 'magit' &amp;&amp; vim.mode =~ /^(?!SearchInProgressMode|CommandlineInProgress).*$/&quot;
  },
  {
    &quot;key&quot;: &quot;shift+v&quot;,
    &quot;command&quot;: &quot;-magit.reverting&quot;
  },
  {
    &quot;key&quot;: &quot;shift+o&quot;,
    &quot;command&quot;: &quot;magit.resetting&quot;,
    &quot;when&quot;: &quot;editorTextFocus &amp;&amp; editorLangId == 'magit' &amp;&amp; vim.mode =~ /^(?!SearchInProgressMode|CommandlineInProgress).*$/&quot;
  },
  {
    &quot;key&quot;: &quot;shift+x&quot;,
    &quot;command&quot;: &quot;-magit.resetting&quot;
  },
  {
    &quot;key&quot;: &quot;x&quot;,
    &quot;command&quot;: &quot;-magit.reset-mixed&quot;
  },
  {
    &quot;key&quot;: &quot;ctrl+u x&quot;,
    &quot;command&quot;: &quot;-magit.reset-hard&quot;
  }"><pre>  {
     <span>"key"</span>: <span><span>"</span>g g<span>"</span></span>,
     <span>"command"</span>: <span><span>"</span>cursorTop<span>"</span></span>,
     <span>"when"</span>: <span><span>"</span>editorTextFocus &amp;&amp; editorLangId == 'magit' &amp;&amp; vim.mode =~ /^(?!SearchInProgressMode|CommandlineInProgress).*$/<span>"</span></span> 
  },
  { <span>"key"</span>: <span><span>"</span>g r<span>"</span></span>,
     <span>"command"</span>: <span><span>"</span>magit.refresh<span>"</span></span>,
     <span>"when"</span>: <span><span>"</span>editorTextFocus &amp;&amp; editorLangId == 'magit' &amp;&amp; vim.mode =~ /^(?!SearchInProgressMode|CommandlineInProgress).*$/<span>"</span></span> 
  },
  {
    <span>"key"</span>: <span><span>"</span>tab<span>"</span></span>,
    <span>"command"</span>: <span><span>"</span>extension.vim_tab<span>"</span></span>,
    <span>"when"</span>: <span><span>"</span>editorTextFocus &amp;&amp; vim.active &amp;&amp; !inDebugRepl &amp;&amp; vim.mode != 'Insert' &amp;&amp; editorLangId != 'magit'<span>"</span></span>
  },
  {
    <span>"key"</span>: <span><span>"</span>tab<span>"</span></span>,
    <span>"command"</span>: <span><span>"</span>-extension.vim_tab<span>"</span></span>
  },
  {
    <span>"key"</span>: <span><span>"</span>x<span>"</span></span>,
    <span>"command"</span>: <span><span>"</span>magit.discard-at-point<span>"</span></span>,
    <span>"when"</span>: <span><span>"</span>editorTextFocus &amp;&amp; editorLangId == 'magit' &amp;&amp; vim.mode =~ /^(?!SearchInProgressMode|CommandlineInProgress).*$/<span>"</span></span>
  },
  {
    <span>"key"</span>: <span><span>"</span>k<span>"</span></span>,
    <span>"command"</span>: <span><span>"</span>-magit.discard-at-point<span>"</span></span>
  },
  {
    <span>"key"</span>: <span><span>"</span>-<span>"</span></span>,
    <span>"command"</span>: <span><span>"</span>magit.reverse-at-point<span>"</span></span>,
    <span>"when"</span>: <span><span>"</span>editorTextFocus &amp;&amp; editorLangId == 'magit' &amp;&amp; vim.mode =~ /^(?!SearchInProgressMode|CommandlineInProgress).*$/<span>"</span></span>
  },
  {
    <span>"key"</span>: <span><span>"</span>v<span>"</span></span>,
    <span>"command"</span>: <span><span>"</span>-magit.reverse-at-point<span>"</span></span>
  },
  {
    <span>"key"</span>: <span><span>"</span>shift+-<span>"</span></span>,
    <span>"command"</span>: <span><span>"</span>magit.reverting<span>"</span></span>,
    <span>"when"</span>: <span><span>"</span>editorTextFocus &amp;&amp; editorLangId == 'magit' &amp;&amp; vim.mode =~ /^(?!SearchInProgressMode|CommandlineInProgress).*$/<span>"</span></span>
  },
  {
    <span>"key"</span>: <span><span>"</span>shift+v<span>"</span></span>,
    <span>"command"</span>: <span><span>"</span>-magit.reverting<span>"</span></span>
  },
  {
    <span>"key"</span>: <span><span>"</span>shift+o<span>"</span></span>,
    <span>"command"</span>: <span><span>"</span>magit.resetting<span>"</span></span>,
    <span>"when"</span>: <span><span>"</span>editorTextFocus &amp;&amp; editorLangId == 'magit' &amp;&amp; vim.mode =~ /^(?!SearchInProgressMode|CommandlineInProgress).*$/<span>"</span></span>
  },
  {
    <span>"key"</span>: <span><span>"</span>shift+x<span>"</span></span>,
    <span>"command"</span>: <span><span>"</span>-magit.resetting<span>"</span></span>
  },
  {
    <span>"key"</span>: <span><span>"</span>x<span>"</span></span>,
    <span>"command"</span>: <span><span>"</span>-magit.reset-mixed<span>"</span></span>
  },
  {
    <span>"key"</span>: <span><span>"</span>ctrl+u x<span>"</span></span>,
    <span>"command"</span>: <span><span>"</span>-magit.reset-hard<span>"</span></span>
  }</pre></div>
</details>
<p dir="auto"><h2 tabindex="-1" dir="auto">Roadmap</h2><a id="user-content-roadmap" aria-label="Permalink: Roadmap" href="#roadmap"></a></p>
<p dir="auto"><em>Feature requests as well as issues are welcome</em></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Interface</h3><a id="user-content-interface" aria-label="Permalink: Interface" href="#interface"></a></p>
<ul dir="auto">
<li>More interactivity in second-tier views (commit view, stash view, etc)</li>
<li>Config menus</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Missing Git/Magit features</h3><a id="user-content-missing-gitmagit-features" aria-label="Permalink: Missing Git/Magit features" href="#missing-gitmagit-features"></a></p>
<ul dir="auto">
<li>More diffing features</li>
<li>More logging features (<a data-error-text="Failed to load title" data-id="633955067" data-permission-text="Title is private" data-url="https://github.com/kahole/edamagit/issues/40" data-hovercard-type="pull_request" data-hovercard-url="/kahole/edamagit/pull/40/hovercard" href="https://github.com/kahole/edamagit/pull/40">#40</a>)</li>
<li>Bisecting</li>
<li>Patches</li>
<li>Subtrees</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Missing Forge features</h3><a id="user-content-missing-forge-features" aria-label="Permalink: Missing Forge features" href="#missing-forge-features"></a></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Gurus of 90s Web Design: Zeldman, Siegel, Nielsen (335 pts)]]></title>
            <link>https://cybercultural.com/p/web-design-1997/</link>
            <guid>44123852</guid>
            <pubDate>Thu, 29 May 2025 07:33:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cybercultural.com/p/web-design-1997/">https://cybercultural.com/p/web-design-1997/</a>, See on <a href="https://news.ycombinator.com/item?id=44123852">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main">
<article data-pagefind-body="">
  <div>
        
    <p>With the rise of Flash and CSS in 1997, three web design philosophies emerged. David Siegel advocated for 'hacks', Jakob Nielsen kept it simple, while Jeffrey Zeldman combined flair with usability.</p>
    <p><picture><source type="image/webp" srcset="https://cybercultural.com/img/QzPzOzmZqg-1280.webp 1280w" sizes="(max-width: 768px) 100vw, 1280px"><img loading="eager" decoding="async" src="https://cybercultural.com/img/QzPzOzmZqg-1280.jpeg" alt="classic web design books" width="1280" height="720"></picture>
<em>My well-thumbed copies of three classic web design books: 'Creating Killer Web Sites' by David Siegel (1996-97), 'Taking your Talent to the Web' by Jeffrey Zeldman (2001), and 'Designing Web Usability' by Jakob Nielsen (1999).</em></p>
<p>Like many of the first wave of web designers, Jeffrey Zeldman — who turned 42 in early 1997 — had begun his career in a completely different profession. He’d started out as an aspiring fiction author, briefly worked as a journalist, tried his hand as a touring musician, and then spent ten years in the advertising business. “Writing billboards and coming up with quick visuals was good training for the web because you have to communicate something instantly,” he <a href="https://thegreatdiscontent.com/interview/jeffrey-zeldman/" target="_blank" rel="noopener">later said</a> in an interview.</p>
<p>It was the <a href="https://cybercultural.com/p/multimedia-gulch-1994/">rise of multimedia</a> that attracted creatives like Zeldman, who made his first website in 1995. “Hyperlinked text made the web, graphics made it a consumer playground,” <a href="https://web.archive.org/web/19961219052244fw_/http://www.zeldman.com/abtgraph.html" target="_blank" rel="noopener">he wrote</a> on his personal website at the end of 1996.</p>
<p><picture><source type="image/webp" srcset="https://cybercultural.com/img/S0uFcNRnMR-1200.webp 1200w" sizes="(max-width: 768px) 100vw, 1280px"><img loading="lazy" decoding="async" src="https://cybercultural.com/img/S0uFcNRnMR-1200.jpeg" alt="Zeldman website, 30 March 1997" width="1200" height="1240"></picture>
<em>Jeffrey Zeldman's homepage, March 1997. Note that the typical display size at the time was 800x600 pixels, so this and other websites would likely have been designed for those dimensions. <a href="https://web.archive.org/web/19970330110648/http://zeldman.com/toc.html" target="_blank" rel="noopener">Via Wayback Machine</a>.</em></p>
<p>But if the web was a “consumer playground” now, it was still one with many constraints. As Zeldman told budding web designers, “the accepted wisdom is to use as few images as possible, and make them as small as you can (small in file size, though not necessarily in height or width).”</p>
<p>To create his webpages, <a href="https://web.archive.org/web/19961219052231fw_/http://www.zeldman.com/faq.html" target="_blank" rel="noopener">Zeldman used</a> a plain text editor on a Macintosh computer to compose the HTML, along with Photoshop to create his graphics. He encouraged people to keep to HTML fundamentals, but he was also pragmatic — copy other designers to learn, he advised, and select “File: View Source” to see how different pages on the web were created.</p>
<p><picture><source type="image/webp" srcset="https://cybercultural.com/img/3U8yOAxhag-1000.webp 1000w" sizes="(max-width: 768px) 100vw, 1280px"><img loading="lazy" decoding="async" src="https://cybercultural.com/img/3U8yOAxhag-1000.jpeg" alt="Zeldman view source" width="1000" height="688"></picture>
<em>"Imitation is the sincerest form of theft, and most every web author starts by stealing." From an FAQ on Zeldman's site, March 1997; <a href="https://web.archive.org/web/19970330110530/http://zeldman.com/faq.html" target="_blank" rel="noopener">via Wayback Machine</a>.</em></p>
<h2>The 3 Musketeers</h2>
<p>Early in his new career as a web designer, Zeldman was heavily influenced by David Siegel, who had published a book in 1996 entitled <em>Creating Killer Web Sites: The Art of Third-Generation Site Design</em>. This was before <a href="https://cybercultural.com/p/1996-flash-css-web-design/">CSS (Cascading Style Sheets) or Flash</a>, so the book advocated for “hacks” to HTML in order to make websites more visually appealing. The primary hacks were using invisible tables and single-pixel GIFs to help control layout. The book had a chapter entitled “A PDF Primer,” but did not mention CSS (as the final spec hadn’t yet been released). The second edition, published in 1997, replaced the PDF primer with a new chapter: “A CSS Primer.” That’s how fast web design was changing at this time.</p>
<p><picture><source type="image/webp" srcset="https://cybercultural.com/img/ssdC2IvUCa-1000.webp 1000w" sizes="(max-width: 768px) 100vw, 1280px"><img loading="lazy" decoding="async" src="https://cybercultural.com/img/ssdC2IvUCa-1000.jpeg" alt="David Siegel's homepage, February 1997" width="1000" height="927"></picture>
<em>David Siegel's homepage, February 1997; <a href="https://web.archive.org/web/19970213054442/http://dsiegel.com/home.html" target="_blank" rel="noopener">via Wayback Machine</a>.</em></p>
<p>Siegel was around 37 years old at the start of 1997, but unlike Zeldman he had a background in digital design. He’d started his career in digital typography and so when he moved to the web, his goal was purely aesthetic. “I will use any means necessary to achieve quality typography and clear communication,” <a href="https://web.archive.org/web/19970213055012/http://dsiegel.com/tips/me.html" target="_blank" rel="noopener">he wrote</a> on his website. One of the ways he chose to do this was to focus his efforts on <a href="https://cybercultural.com/p/netscape-1994/">Netscape Navigator</a>. “I will not make pages that are optimized for ALL browsers,” he wrote.</p>
<p>This was the beginning of browser optimization on the web, which forced web users to view certain websites in a specific browser. Siegel styled himself as an “HTML terrorist,” so he was willing to take a contrary stance to achieve perfect typography on the web.</p>
<p><picture><source type="image/webp" srcset="https://cybercultural.com/img/USmS-2C-A2-1000.webp 1000w" sizes="(max-width: 768px) 100vw, 1280px"><img loading="lazy" decoding="async" src="https://cybercultural.com/img/USmS-2C-A2-1000.jpeg" alt="David Siegel tips, February 1997" width="1000" height="908"></picture>
<em>David Siegel's "Web Wonk" HTML tips site, February 1997; <a href="https://web.archive.org/web/19970213055004/http://www.dsiegel.com/tips/index.html" target="_blank" rel="noopener">via Wayback Machine</a>.</em></p>
<p>If Siegel was a self-described web design terrorist, then 39-year old Jakob Nielsen positioned himself as a web sheriff. <a href="https://www.nngroup.com/articles/trends-for-the-web-in-1997/" target="_blank" rel="noopener">He wrote</a> that his goal was to “get rid of superficial coolness and make websites into serious business tools.” He wasn’t a trained designer (instead, he <a href="https://web.archive.org/web/19980128103620/http://www.useit.com/jakob/" target="_blank" rel="noopener">called himself</a> a “usability guru”), but Nielsen strongly advocated for designs that were accessible on all the main browsers. For this reason he encouraged designers to use “semantic encoding” to keep content and presentation separate.</p>
<p>At first, Nielsen was talking about sticking to the structure defined in the HTML specification — such as using H1 and H2 for headers, rather than encoding something like "18 pixels tall bold Garamond.” Essentially, he was saying that each browser should define how headers would be displayed to their users. But he quickly got behind the emerging web standard, CSS. “Style sheets are a new development on the Web and currently not widely used,” <a href="https://www.nngroup.com/articles/trends-for-the-web-in-1997/" target="_blank" rel="noopener">wrote Nielsen</a> at the end of 1996, “but they are the only solution to getting nice presentation with ever-increasing numbers of browsers and display devices.”</p>
<p><picture><source type="image/webp" srcset="https://cybercultural.com/img/aYV_7OwrnD-1000.webp 1000w" sizes="(max-width: 768px) 100vw, 1280px"><img loading="lazy" decoding="async" src="https://cybercultural.com/img/aYV_7OwrnD-1000.jpeg" alt="Useit, February 1997" width="1000" height="858"></picture>
<em>Jakob Nielsen's Useit website, February 1997; <a href="https://web.archive.org/web/19970218113042/http://www.useit.com/" target="_blank" rel="noopener">via Wayback Machine</a>.</em></p>
<p>The problem was, CSS support from the two main browsers at the start of 1997 was <a href="https://www.quirksmode.org/css/quirksmode.html" target="_blank" rel="noopener">patchy at best</a>. Internet Explorer 3.0 was the closest to supporting the W3C standard for CSS, but it was <a href="https://cybercultural.com/p/1996-microsoft-activates-the-internet-with-activex-jscript/">buggy and inconsistent</a>. As for Netscape, its 3.0 browser had <a href="https://cybercultural.com/p/1996-netscape-lays-the-groundwork-for-web-applications/">poor CSS support</a>. In fact, the company even tried to create an alternative to CSS, with a JavaScript-powered styling mechanism called JavaScript-Based Style Sheets (JSSS). Thankfully JSSS went nowhere, but it did serve to delay Netscape getting behind the nascent web standard for style sheets.</p>
<p>As 1997 progressed, the schism between the aesthetic approach to web design (personified by Siegel) and the semantic approach (personified by Nielsen) widened. Jeffrey Zeldman found himself in the middle of this. He was a proponent of CSS, but he also wasn’t above using new tools that disregarded semantic coding — like Shockwave and Flash. Over the coming years, Zeldman continued to insist that web design could be both aesthetic and standards-compliant. “Images, table layouts, style sheets, JavaScript, server-side technologies like PHP, and embedded technologies like Flash and Quicktime are all compatible with the rigors of accessible site design,” <a href="https://zeldman.com/daily/0602b.html" target="_blank" rel="noopener">he wrote</a> as late as July 2002.</p>
<h2>Flash Point</h2>
<p>Zeldman would eventually turn his back on Flash, which of all the web design tools available in the 90s was probably the least semantic. But when it first became popular, over 1997, it was seen as an animation tool that could take multimedia on the web to the next level.</p>
<p><picture><source type="image/webp" srcset="https://cybercultural.com/img/_1A4unOU4z-800.webp 800w" sizes="(max-width: 768px) 100vw, 1280px"><img loading="lazy" decoding="async" src="https://cybercultural.com/img/_1A4unOU4z-800.jpeg" alt="Flash 1997" width="800" height="572"></picture>
<em>In May 1997, Macromedia <a href="https://web.archive.org/web/19980613005908/http://www.macromedia.com/macromedia/proom/pr/1997/flash2rel.html" target="_blank" rel="noopener">released Flash 2</a>, "the first tool for creating and animating vector-based resolution-independent graphics without programming"; <a href="https://www.webdesignmuseum.org/software/macromedia-flash-2-0-in-1997" target="_blank" rel="noopener">image via Web Design Museum</a>.</em></p>
<p>Flash had a few important things going for it. Firstly, the tool was easy to learn (unlike CSS). Secondly, it could do much more, visually, than CSS at that time. Almost anything was possible using Flash, with the only constraint being bandwidth limitations. Thirdly, and most crucially, Flash didn’t rely on the leading browser companies implementing it. The Flash player was a browser plug-in, so all it needed was for users to download that plug-in. Which they did, en masse.</p>
<p>Siegel quickly embraced Flash. In the second edition of <em>Creating Killer Websites</em>, published in September 1997, <a href="https://archive.org/details/creatingkiller1997sieg/page/266/mode/2up?view=theater&amp;q=flash" target="_blank" rel="noopener">he wrote</a> that “Flash is the best bet for bringing vector graphics into mainstream use on the Web.” To be fair, he also devoted an entire new chapter to CSS. However, he clearly wasn’t impressed by what CSS could actually deliver at the time. “To a certain extent, this chapter represents an exercise in futility — it demonstrates the appalling degree to which the browsers fail to deliver on the promise of style sheets in August 1997,” he wrote. In his summary, he expressed hope for CSS, but warned that “I will continue to commit HTML terrorism to accomplish my design objectives on today’s browsers.”</p>
<p><picture><source type="image/webp" srcset="https://cybercultural.com/img/iQfeqWCstG-1280.webp 1280w" sizes="(max-width: 768px) 100vw, 1280px"><img loading="lazy" decoding="async" src="https://cybercultural.com/img/iQfeqWCstG-1280.jpeg" alt="Killer Websites Flash" width="1280" height="802"></picture>
<em>The Flash section of the second edition of Killer Websites; via Internet Archive.</em></p>
<p>As quickly as Siegel and Zeldman embraced Flash, Nielsen just as quickly rejected it — primarily because presentation and content were mashed together into one file, so there was nothing at all semantic about the code it produced. A few years later, he <a href="https://www.nngroup.com/articles/flash-99-percent-bad/" target="_blank" rel="noopener">famously wrote</a> that Flash was “99% bad” and that it was almost always “a usability disease.”</p>
<p>Even Siegel was concerned that Flash was a proprietary tool, owned and controlled by Macromedia (which had <a href="https://cybercultural.com/p/internet-1996/">acquired the technology</a> from a company called FutureWave at the end of 1996). Flash couldn’t have been more different from CSS — the software was not open source, the file format (.fla) was proprietary, and the output did not conform to web standards.</p>
<p><picture><source type="image/webp" srcset="https://cybercultural.com/img/Mb7oi42AMI-1000.webp 1000w" sizes="(max-width: 768px) 100vw, 1280px"><img loading="lazy" decoding="async" src="https://cybercultural.com/img/Mb7oi42AMI-1000.jpeg" alt="W3C Style, June 1997" width="1000" height="728"></picture>
<em>The W3C Style page, June 1997; <a href="https://web.archive.org/web/19970605010635/https://www.w3.org/Style/" target="_blank" rel="noopener">via Wayback Machine</a>.</em></p>
<p>For all their differences, CSS and Flash did have similar goals: both aimed to expand the state of web design on the web. Yet only one of them led to an explosion of visual creativity on the web over the rest of the 1990s…and it wasn’t the open web standard. If you wanted to create a killer website in 1997, Flash was the tool many web designers of that time reached for.</p>
<h2>Whatever Happened To…</h2>
<p>As for Zeldman, Siegel and Nielsen, for all <em>their differences</em>, the three musketeers of web design all wanted to move their fledgling profession forward. Because the web platform was in flux in 1997 — epitomised by the emergence of Flash and CSS, two diametrically opposed technologies — web design was necessarily experimental that year.</p>
<p>It’s only by looking at the careers of all three men in the following decades that you get a sense of which web design philosophy eventually ‘won’.</p>
<p>Post-90s, Jakob Nielsen became ever more defined by his barebones website, Useit, which eschewed any design flourishes. Like Craigslist, another famously minimalist website, Useit didn't change its design over the years. By the Web 2.0 period, it was seen my most in the web design profession as being <a href="https://css-tricks.com/the-usability-problems-of-useitcom/" target="_blank" rel="noopener">hopelessly outdated</a>. The site lasted several more years, before Nielsen announced that Useit would be <a href="https://www.nngroup.com/news/item/useitcom-moves-to-nngroupcom/" target="_blank" rel="noopener">folded into</a> his main corporate website, NNGroup, at the end of 2012.</p>
<p>It may not surprise you to know that in 2025, Jakob Nielsen is writing <a href="https://jakobnielsenphd.substack.com/" target="_blank" rel="noopener">about AI on Substack</a>.</p>
<p><picture><source type="image/webp" srcset="https://cybercultural.com/img/Vez2PrOeV9-1280.webp 1280w" sizes="(max-width: 768px) 100vw, 1280px"><img loading="lazy" decoding="async" src="https://cybercultural.com/img/Vez2PrOeV9-1280.jpeg" alt="Useit, December 2012" width="1280" height="728"></picture>
<em>Useit website in December 2012, just before it was closed down. The design (purposefully) hadn't changed much since 1997. <a href="https://web.archive.org/web/20121223175349/http://www.useit.com/" target="_blank" rel="noopener">via Wayback Machine</a>.</em></p>
<p>David Siegel has had a surprisingly varied career. He was the most qualified design professional of the three, having earned a master's degree in digital typography from Stanford University in 1985 and then working at Pixar. But after two editions of his hugely influential “Killer Web Sites” book over 1996-97, he switched gears and moved from web design to web business in the late-90s. I had <a href="https://web.archive.org/web/20100404072141/http://www.readwriteweb.com/archives/david_siegel_pull_semantic_web.php" target="_blank" rel="noopener">some contact</a> with him in 2010, when he was promoting his fourth book, <a href="https://archive.org/details/isbn_9781591842774" target="_blank" rel="noopener">Pull: The Power of the Semantic Web to Transform Your Business</a>.</p>
<p>Later, Siegel got interested in the blockchain and pursued that for a few years. His current website, cuttingthroughthenoise.net, shows that he now has a variety of business and personal interests.</p>
<p><picture><source type="image/webp" srcset="https://cybercultural.com/img/ovJladicCl-1280.webp 1280w" sizes="(max-width: 768px) 100vw, 1280px"><img loading="lazy" decoding="async" src="https://cybercultural.com/img/ovJladicCl-1280.jpeg" alt="David Siegel 2025" width="1280" height="641"></picture>
<em><a href="https://www.cuttingthroughthenoise.net/" target="_blank" rel="noopener">David Siegel's website in 2025</a> reflects his eclectic interests.</em></p>
<p>Jeffrey Zeldman is still very much a web designer. Since 2019 he’s been Executive Creative Director at Automattic, the company behind the WordPress blogging system, Tumblr, and other web products. He still regularly blogs about web design topics on his website, <a href="https://zeldman.com/" target="_blank" rel="noopener">zeldman.com</a> — although the current site design is one of the default WordPress themes.</p>
<p>I was curious why he no longer has a custom design, so before I published this article I reached out to him via a Bluesky DM. He replied: "I'm working on a redesign of my site as we speak. It will go live soon." He added that the default WordPress theme, which he switched to in February 2019, "wasn't so different from one I might have designed myself at the time. That said, after living with the default theme for six years, I'm ready to move on."</p>
<p><picture><source type="image/webp" srcset="https://cybercultural.com/img/pS6DflLQU2-1280.webp 1280w" sizes="(max-width: 768px) 100vw, 1280px"><img loading="lazy" decoding="async" src="https://cybercultural.com/img/pS6DflLQU2-1280.jpeg" alt="Zeldman website May 2025" width="1280" height="738"></picture>
<em>Jeffrey Zeldman's website as at 28 May 2025...but stay tuned, a redesign is coming soon!</em></p>
<p>I must say, I'm thrilled to hear that Zeldman is working on a redesign. I'd argue that his pragmatic approach to web design — combining web standards with design flair — was what won out during the 90s and early 2000s. Certainly, of the three web design gurus in 1997, Zeldman’s website back then was by far the most interesting and exotic. So I look forward to seeing that design philosophy return to zeldman.com — and indeed, let's hope it proliferates again across the rest of the indie web.</p>
<p><picture><source type="image/webp" srcset="https://cybercultural.com/img/SuLShqpEyb-400.webp 400w" sizes="(max-width: 768px) 100vw, 1280px"><img loading="lazy" decoding="async" src="https://cybercultural.com/img/SuLShqpEyb-400.jpeg" alt="Bonus photo of ricmac in 2010" width="400" height="533"></picture>
<em>A sneaky pic of me <a href="https://www.flickr.com/photos/zeldman/4699929293/in/album-72157623550476154" target="_blank" rel="noopener">taken by Jeffrey Zeldman</a> in June 2010, during one of my trips to NYC.</em></p>


<hr>


 

<h2>Buy the Book</h2>
<p>My <a href="https://cybercultural.com/p/book-release-bubbleblog/">Web 2.0 memoir</a>, <em>Bubble Blog: From Outsider to Insider in Silicon Valley's Web 2.0 Revolution</em>, is now available to purchase:</p>
<ul>
<li>Paperback, US$19.99: <a href="https://www.amazon.com/Bubble-Blog-Outsider-Insider-Revolution/dp/B0DQKRB3P5?&amp;linkCode=ll1&amp;tag=richardmacman-20&amp;linkId=b38f92f2c0bd2c9f05cda3a07413fd40&amp;language=en_US&amp;ref_=as_li_ss_tl" target="_blank" rel="noopener">Amazon</a>; <a href="https://bookshop.org/p/books/bubble-blog-from-outsider-to-insider-in-silicon-valley-s-web-2-0-revolution-richard-macmanus/22135084" target="_blank" rel="noopener">Bookshop.org</a></li>
<li>eBook, US$9.99: <a href="https://www.amazon.com/Bubble-Blog-Outsider-Insider-Revolution-ebook/dp/B0DQJQ4LJ9?&amp;linkCode=ll1&amp;tag=richardmacman-20&amp;linkId=63e982f1c9d1ded8c83666d8b6917ff7&amp;language=en_US&amp;ref_=as_li_ss_tl" target="_blank" rel="noopener">Amazon Kindle Store</a>; <a href="http://books.apple.com/us/book/id6739734992" target="_blank" rel="noopener">Apple Books</a>; <a href="https://play.google.com/store/books/details?id=Sug5EQAAQBAJ" target="_blank" rel="noopener">Google Play</a></li>
</ul>

<p>Or search for "Bubble Blog MacManus" on your local online bookstore.</p>
  </div>
</article>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Typed-FFmpeg 3.0–Typed Interface to FFmpeg and Visual Filter Editor (297 pts)]]></title>
            <link>https://github.com/livingbio/typed-ffmpeg</link>
            <guid>44123098</guid>
            <pubDate>Thu, 29 May 2025 04:23:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/livingbio/typed-ffmpeg">https://github.com/livingbio/typed-ffmpeg</a>, See on <a href="https://news.ycombinator.com/item?id=44123098">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">typed-ffmpeg</h2><a id="user-content-typed-ffmpeg" aria-label="Permalink: typed-ffmpeg" href="#typed-ffmpeg"></a></p>
<p dir="auto"><a href="https://github.com/livingbio/typed-ffmpeg/actions?query=workflow%3Aci-package"><img src="https://github.com/livingbio/typed-ffmpeg/actions/workflows/ci-package.yml/badge.svg" alt="CI Package"></a>
<a href="https://livingbio.github.io/typed-ffmpeg/" rel="nofollow"><img src="https://camo.githubusercontent.com/5a4414aacd5db4051f8ae830d1eca85ffd60e261f2855e432d7e3b7f210bb0af/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6d6b646f63732532306d6174657269616c2d626c75652e7376673f7374796c653d666c6174" alt="Documentation" data-canonical-src="https://img.shields.io/badge/docs-mkdocs%20material-blue.svg?style=flat"></a>
<a href="https://pypi.org/project/typed-ffmpeg/" rel="nofollow"><img src="https://camo.githubusercontent.com/afd329fb15a52d6e6b60b2e1b302be4823ae665e5555e848075599f6af367443/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f74797065642d66666d7065672e737667" alt="PyPI Version" data-canonical-src="https://img.shields.io/pypi/v/typed-ffmpeg.svg"></a>
<a href="https://codecov.io/gh/livingbio/typed-ffmpeg" rel="nofollow"><img src="https://camo.githubusercontent.com/8fd3d468cf99ef7221b9000544bf1e7df476dcb551634338fd03525f0307839d/68747470733a2f2f636f6465636f762e696f2f67682f6c6976696e6762696f2f74797065642d66666d7065672f67726170682f62616467652e7376673f746f6b656e3d42393550523632394c50" alt="codecov" data-canonical-src="https://codecov.io/gh/livingbio/typed-ffmpeg/graph/badge.svg?token=B95PR629LP"></a></p>
<p dir="auto"><strong>typed-ffmpeg</strong> offers a modern, Pythonic interface to FFmpeg, providing extensive support for complex filters with detailed typing and documentation. Inspired by <code>ffmpeg-python</code>, this package enhances functionality by addressing common limitations, such as lack of IDE integration and comprehensive typing, while also introducing new features like JSON serialization of filter graphs and automatic FFmpeg validation.</p>
<hr>
<p dir="auto"><h3 tabindex="-1" dir="auto">Table of Contents</h3><a id="user-content-table-of-contents" aria-label="Permalink: Table of Contents" href="#table-of-contents"></a></p>
<ul dir="auto">
<li><a href="#features">Features</a></li>
<li><a href="#installation">Installation</a></li>
<li><a href="#quick-usage">Quick Usage</a></li>
<li><a href="https://livingbio.github.io/typed-ffmpeg/" rel="nofollow">Documentation</a></li>
<li><a href="#interactive-playground">Interactive Playground</a></li>
<li><a href="#acknowledgements">Acknowledgements</a></li>
</ul>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/livingbio/typed-ffmpeg/main/docs/media/autocomplete.png"><img src="https://raw.githubusercontent.com/livingbio/typed-ffmpeg/main/docs/media/autocomplete.png" alt="typed-ffmpeg"></a></p>
<ul dir="auto">
<li><strong>Zero Dependencies:</strong> Built purely with the Python standard library, ensuring maximum compatibility and security.</li>
<li><strong>User-Friendly:</strong> Simplifies the construction of filter graphs with an intuitive Pythonic interface.</li>
<li><strong>Comprehensive FFmpeg Filter Support:</strong> Out-of-the-box support for most FFmpeg filters, with IDE auto-completion.</li>
<li><strong>Integrated Documentation:</strong> In-line docstrings provide immediate reference for filter usage, reducing the need to consult external documentation.</li>
<li><strong>Robust Typing:</strong> Offers static and dynamic type checking, enhancing code reliability and development experience.</li>
<li><strong>Filter Graph Serialization:</strong> Enables saving and reloading of filter graphs in JSON format for ease of use and repeatability.</li>
<li><strong>Graph Visualization:</strong> Leverages <code>graphviz</code> for visual representation, aiding in understanding and debugging.</li>
<li><strong>Validation and Auto-correction:</strong> Assists in identifying and fixing errors within filter graphs.</li>
<li><strong>Input and Output Options Support:</strong> Provide a more comprehensive interface for input and output options, including support for additional codecs and formats.</li>
<li><strong>Partial Evaluation:</strong> Enhance the flexibility of filter graphs by enabling partial evaluation, allowing for modular construction and reuse.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Planned Features</h3><a id="user-content-planned-features" aria-label="Permalink: Planned Features" href="#planned-features"></a></p>
<p dir="auto">Please note that the following features are under consideration or development for future releases:</p>
<ul dir="auto">
<li><strong>Extended FFmpeg Version Support:</strong> While <code>typed-ffmpeg</code> is currently built with FFmpeg version 6.0 in mind, we are working to ensure compatibility across different FFmpeg versions. Feedback and issue reports are welcome to improve version support.</li>
<li><strong>Additional Filter Support:</strong> We aim to expand the range of FFmpeg filters supported by <code>typed-ffmpeg</code>. Continuous updates will be made to include more complex and varied filters.</li>
</ul>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto">To install <code>typed-ffmpeg</code>, simply use pip:</p>

<p dir="auto">Note: FFmpeg must be installed on your system.</p>
<p dir="auto">Note: If you need to install <code>ffmpeg-python</code> at the same time, use <code>pip install typed-ffmpeg-compatible</code> to prevent conflicts with the module name.​</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Visualization Support</h3><a id="user-content-visualization-support" aria-label="Permalink: Visualization Support" href="#visualization-support"></a></p>
<p dir="auto">To enable graph visualization features:</p>
<div dir="auto" data-snippet-clipboard-copy-content="pip install 'typed-ffmpeg[graph]'"><pre>pip install <span><span>'</span>typed-ffmpeg[graph]<span>'</span></span></pre></div>
<p dir="auto">Note: This requires Graphviz to be installed on your system.</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Quick Usage</h2><a id="user-content-quick-usage" aria-label="Permalink: Quick Usage" href="#quick-usage"></a></p>
<p dir="auto">Here's how to quickly start using <code>typed-ffmpeg</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="import ffmpeg

# Flip video horizontally and output
f = (
    ffmpeg
    .input(filename='input.mp4')
    .hflip()
    .output(filename='output.mp4')
)
f"><pre><span>import</span> <span>ffmpeg</span>

<span># Flip video horizontally and output</span>
<span>f</span> <span>=</span> (
    <span>ffmpeg</span>
    .<span>input</span>(<span>filename</span><span>=</span><span>'input.mp4'</span>)
    .<span>hflip</span>()
    .<span>output</span>(<span>filename</span><span>=</span><span>'output.mp4'</span>)
)
<span>f</span></pre></div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/livingbio/typed-ffmpeg/main/docs/media/README_files/README_1_0.svg"><img src="https://raw.githubusercontent.com/livingbio/typed-ffmpeg/main/docs/media/README_files/README_1_0.svg" alt="svg"></a></p>
<p dir="auto">For a more complex example:</p>
<div dir="auto" data-snippet-clipboard-copy-content="import ffmpeg.filters
import ffmpeg

# Complex filter graph example
in_file = ffmpeg.input(&quot;input.mp4&quot;)
overlay_file = ffmpeg.input(&quot;overlay.png&quot;)

f = (
    ffmpeg.filters
    .concat(
        in_file.trim(start_frame=10, end_frame=20),
        in_file.trim(start_frame=30, end_frame=40),
    )
    .video(0)
    .overlay(overlay_file.hflip())
    .drawbox(x=&quot;50&quot;, y=&quot;50&quot;, width=&quot;120&quot;, height=&quot;120&quot;, color=&quot;red&quot;, thickness=&quot;5&quot;)
    .output(filename=&quot;out.mp4&quot;)
)
f"><pre><span>import</span> <span>ffmpeg</span>.<span>filters</span>
<span>import</span> <span>ffmpeg</span>

<span># Complex filter graph example</span>
<span>in_file</span> <span>=</span> <span>ffmpeg</span>.<span>input</span>(<span>"input.mp4"</span>)
<span>overlay_file</span> <span>=</span> <span>ffmpeg</span>.<span>input</span>(<span>"overlay.png"</span>)

<span>f</span> <span>=</span> (
    <span>ffmpeg</span>.<span>filters</span>
    .<span>concat</span>(
        <span>in_file</span>.<span>trim</span>(<span>start_frame</span><span>=</span><span>10</span>, <span>end_frame</span><span>=</span><span>20</span>),
        <span>in_file</span>.<span>trim</span>(<span>start_frame</span><span>=</span><span>30</span>, <span>end_frame</span><span>=</span><span>40</span>),
    )
    .<span>video</span>(<span>0</span>)
    .<span>overlay</span>(<span>overlay_file</span>.<span>hflip</span>())
    .<span>drawbox</span>(<span>x</span><span>=</span><span>"50"</span>, <span>y</span><span>=</span><span>"50"</span>, <span>width</span><span>=</span><span>"120"</span>, <span>height</span><span>=</span><span>"120"</span>, <span>color</span><span>=</span><span>"red"</span>, <span>thickness</span><span>=</span><span>"5"</span>)
    .<span>output</span>(<span>filename</span><span>=</span><span>"out.mp4"</span>)
)
<span>f</span></pre></div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/livingbio/typed-ffmpeg/main/docs/media/README_files/README_3_0.svg"><img src="https://raw.githubusercontent.com/livingbio/typed-ffmpeg/main/docs/media/README_files/README_3_0.svg" alt="svg"></a></p>
<p dir="auto">See the <a href="https://livingbio.github.io/typed-ffmpeg/usage/typed/" rel="nofollow">Usage</a> section in our documentation for more examples and detailed guides.</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Interactive Playground</h2><a id="user-content-interactive-playground" aria-label="Permalink: Interactive Playground" href="#interactive-playground"></a></p>
<p dir="auto">Try out <code>typed-ffmpeg</code> directly in your browser with our <a href="https://livingbio.github.io/typed-ffmpeg-playground/" rel="nofollow">Interactive Playground</a>! The playground provides a live environment where you can:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/livingbio/typed-ffmpeg/main/docs/media/playground-screenshot.png"><img src="https://raw.githubusercontent.com/livingbio/typed-ffmpeg/main/docs/media/playground-screenshot.png" alt="Interactive Playground"></a></p>
<ul dir="auto">
<li>Experiment with FFmpeg filters and commands</li>
<li>Visualize filter graphs in real-time</li>
<li>Test different input/output configurations</li>
<li>Learn through interactive examples</li>
<li>Share your filter graphs with others</li>
</ul>
<p dir="auto">The playground is perfect for learning and prototyping FFmpeg filter chains without setting up a local environment.</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Acknowledgements</h2><a id="user-content-acknowledgements" aria-label="Permalink: Acknowledgements" href="#acknowledgements"></a></p>
<p dir="auto">This project was initially inspired by the capabilities of GPT-3, with the original concept focusing on using GPT-3 to generate an FFmpeg filter SDK directly from the FFmpeg documentation. However, during the development process, I encountered limitations with GPT-3's ability to fully automate this task.</p>
<p dir="auto">As a result, I shifted to traditional code generation methods to complete the SDK, ensuring a more robust and reliable tool. Despite this change in approach, both GitHub Copilot and GPT-3 were instrumental in accelerating the development process, providing valuable insights and saving significant time.</p>
<p dir="auto">I would also like to extend my gratitude to the <code>ffmpeg-python</code> project, which inspired this project significantly. The API style and design ideas from <code>ffmpeg-python</code> have been influential, and I have utilized these aspects to shape the development of our SDK.</p>
<p dir="auto">This project is dedicated to my son, Austin, on his seventh birthday (February 24, 2024), whose curiosity and zest for life continually inspire me.</p>
<hr>
<p dir="auto">Feel free to check the <a href="https://livingbio.github.io/typed-ffmpeg/" rel="nofollow">Documentation</a> for detailed information and more advanced features.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Run a C# file directly using dotnet run app.cs (306 pts)]]></title>
            <link>https://devblogs.microsoft.com/dotnet/announcing-dotnet-run-app/</link>
            <guid>44122582</guid>
            <pubDate>Thu, 29 May 2025 02:30:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://devblogs.microsoft.com/dotnet/announcing-dotnet-run-app/">https://devblogs.microsoft.com/dotnet/announcing-dotnet-run-app/</a>, See on <a href="https://news.ycombinator.com/item?id=44122582">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="single-wrapper">
    
    <article data-clarity-region="article" id="post-56905">
        <div data-bi-area="body_article" data-bi-id="post_page_body_article">
            <p>We are super excited to introduce a new feature that was released as part of .NET 10 Preview 4 that makes getting started with C# easier than ever. You can now run a C# file directly using <code>dotnet run app.cs</code>. This means you no longer need to create a project file or scaffold a whole application to run a quick script, test a snippet, or experiment with an idea. It’s simple, intuitive, and designed to streamline the C# development experience, especially for those just getting started.</p>
<h2>What is <code>dotnet run app.cs</code>?</h2>
<p>Until now, executing C# code using the <code>dotnet</code> CLI required a project structure that included a <code>.csproj</code> file. With this new capability, which we call <em>file-based apps</em>, you can run a standalone <code>.cs</code> file directly, much like you would with scripting languages such as Python or JavaScript.</p>
<p>This lowers the entry barrier to trying out C# and makes the language a much more attractive choice for learning, prototyping, or automation scenarios.</p>
<ul>
<li><strong>Quick Start, No Project File Required</strong> – Great for learning, experimentation, and small scripts.</li>
<li><strong>First-Class CLI Integration</strong> – No extra tools, no dependencies, just <code>dotnet</code> and your <code>.cs</code> file.</li>
<li><strong>Scales to Real Applications</strong> – This isn’t a separate dialect or runtime. When your script grows up, it can evolve into a full-fledged project using the same language, syntax, and tooling.</li>
</ul>
<h2>New file-level directives for file-based C# apps</h2>
<p>With .NET 10 Preview 4, file-based apps also support a set of powerful <strong>file-level directives</strong> that allow to declare a small number of important things that are stored in project files for project-based apps, all without leaving your single <code>.cs</code> file. These directives make file-based apps more flexible and expressive while maintaining compatibility with MSBuild concepts.</p>
<h3>Referencing NuGet packages with <code>#:package</code></h3>
<p>You can add NuGet package references directly in your <code>.cs</code> file using the <code>#:package</code> directive:</p>
<pre><code>#:package Humanizer@2.14.1

using Humanizer;

var dotNet9Released = DateTimeOffset.Parse("2024-12-03");
var since = DateTimeOffset.Now - dotNet9Released;

Console.WriteLine($"It has been {since.Humanize()} since .NET 9 was released.");</code></pre>
<h3>Specifying an SDK with <code>#:sdk</code></h3>
<p>By default, file-based apps use the <code>Microsoft.NET.Sdk</code> SDK. If you’re building something like a web API, you can change the SDK using the <code>#:sdk</code> directive:</p>
<pre><code>#:sdk Microsoft.NET.Sdk.Web</code></pre>
<p>This tells the tooling to treat the file as if it were part of a web project, enabling features of ASP.NET Core like Minimal APIs and MVC.</p>
<h3>Setting MSBuild properties with <code>#:property</code></h3>
<p>You can configure additional build properties using <code>#:property</code>. For example:</p>
<pre><code>#:property LangVersion preview</code></pre>
<p>This allows your file-based app to opt into advanced language features and platform targeting, without needing a full project file.</p>
<h3>Using shebang lines for shell scripts</h3>
<p>File-based apps also support <a href="https://en.wikipedia.org/wiki/Shebang_%28Unix%29">shebang</a> lines (<code>#!</code>), allowing you to write cross-platform C# shell scripts that are executable directly on Unix-like systems. For example:</p>
<pre><code>#!/usr/bin/dotnet run
Console.WriteLine("Hello from a C# script!");</code></pre>
<p>You can make the file executable and run it directly:</p>
<pre><code>chmod +x app.cs
./app.cs</code></pre>
<p>This makes C# a convenient option for CLI utilities, automation scripts, and tooling, no project setup required.</p>
<h2>Converting to a project-based app</h2>
<p>When your file-based app grows in complexity, or you simply want the extra capabilities afforded in project-based apps, you can convert it to a standard project with:</p>
<pre><code>dotnet project convert app.cs</code></pre>
<p>This command creates a new directory named for your file, scaffolds a <code>.csproj</code> file, moves your code into a <code>Program.cs</code> file, and translates any <code>#:</code> directives into MSBuild properties and references.</p>
<h3>Example</h3>
<p>Given this file:</p>
<pre><code>#:sdk Microsoft.NET.Sdk.Web
#:package Microsoft.AspNetCore.OpenApi@10.*-*

var builder = WebApplication.CreateBuilder();

builder.AddOpenApi();

var app = builder.Build();

app.MapGet("/", () =&gt; "Hello, world!");
app.Run();</code></pre>
<p>The generated <code>.csproj</code> would be:</p>
<pre><code>&lt;Project Sdk="Microsoft.NET.Sdk.Web"&gt;

  &lt;PropertyGroup&gt;
    &lt;TargetFramework&gt;net10.0&lt;/TargetFramework&gt;
    &lt;ImplicitUsings&gt;enable&lt;/ImplicitUsings&gt;
    &lt;Nullable&gt;enable&lt;/Nullable&gt;
  &lt;/PropertyGroup&gt;

  &lt;ItemGroup&gt;
    &lt;PackageReference Include="Microsoft.AspNetCore.OpenApi" Version="10.*-*" /&gt;
  &lt;/ItemGroup&gt;

&lt;/Project&gt;</code></pre>
<p>This makes the transition seamless, from a single file to a fully functional, buildable, and extensible project.</p>
<h2>Existing ways to run C# without projects</h2>
<p>This is far from the first time developers have wanted to run C# without a project. Community projects like <a href="https://github.com/oleg-shilo/cs-script">CS-Script</a>, <a href="https://github.com/dotnet-script/dotnet-script">dotnet-script</a>, <a href="https://cakebuild.net/">Cake</a>, and others have long filled this role, enabling scripting workflows, REPL experiences, and other experiences with C#. Here’s a <a href="https://www.hanselman.com/blog/c-and-net-core-scripting-with-the-dotnetscript-global-tool">blog post by Scott Hanselman from 2018 detailing the <code>dotnet-script</code> global tool</a>.</p>
<p>These tools remain valuable and are worth checking out, especially for more advanced scripting scenarios. However, with this new built-in support, developers can get started immediately: no additional installation, configuration, or discovery steps required.</p>
<p>Equally important: this isn’t a separate dialect or mode of C#. We’re being intentional about making this feature a natural earlier “click-stop” from a regular C# project-based app. You’re writing the same C#, using the same compiler, and when your code grows up, it transitions naturally into a project-based app, if and when you want.</p>
<h2>Getting Started</h2>
<ol>
<li><strong>Install .NET 10 Preview 4</strong>
Download and install it from <a href="https://dotnet.microsoft.com/download/dotnet/10.0">dotnet.microsoft.com</a>.</li>
<li><strong>Install Visual Studio Code (recommended)</strong>
If you’re using Visual Studio Code, install the <a href="https://marketplace.visualstudio.com/items?itemName=ms-dotnettools.csdevkit">C# Dev Kit</a> and then follow these instructions to update the C# extension for file-based apps support:
<blockquote><p>To enable support for file-based apps and directives, you’ll need the latest <strong>pre-release version</strong> of the C# extension:</p>
<ul>
<li>Open the Extensions sidebar (<code>Ctrl+Shift+X</code>)</li>
<li>Search for “C#”</li>
<li>In the extension page, click the <strong>Switch to Pre-Release Version</strong> button</li>
<li>Ensure the version installed is at least <code>2.79.8</code></li>
</ul>
</blockquote>
</li>
<li><strong>Write your code</strong>
Create a file called <code>hello.cs</code>:
<pre><code>Console.WriteLine("Hello, world!");</code></pre>
</li>
<li><strong>Run it!</strong>
Open a terminal in the same folder and run:
<pre><code>dotnet run hello.cs</code></pre>
</li>
<li><strong>Convert to a project</strong>
To convert the file to a project, run:
<pre><code>dotnet project convert hello.cs</code></pre>
</li>
</ol>
<h2>Learn more</h2>
<p>Watch this feature in action in this <a href="https://build.microsoft.com/sessions/DEM518?source=sessions">demo session from Microsoft Build</a>:
<a href="https://www.youtube.com/watch?v=98MizuB7i-w">No projects, just C# with <code>dotnet run app.cs</code></a></p>
<p>You’ll see how easy it is to get started, explore directives, and convert to a full project when ready.
<iframe width="800" height="450" src="https://www.youtube.com/embed/98MizuB7i-w?si=l_k3YRlViQR-rCpr" allowfullscreen=""></iframe></p>
<p>You’ll see how easy it is to get started, explore directives, and convert to a full project when ready.</p>
<h2>The road ahead</h2>
<p>With <code>dotnet run app.cs</code>, we’re making C# more approachable, while preserving the full power and depth of the .NET ecosystem. Whether you’re prototyping, teaching, or building production systems, this new capability helps you move faster from idea to execution.</p>
<p>In upcoming .NET 10 previews we’re aiming to improve the experience of working with file-based apps in VS Code, with enhnanced IntelliSense for the new file-based directives, improved performance, and support for debugging. At the command line we’re exploring support for file-based apps with <a href="https://github.com/dotnet/sdk/blob/main/documentation/general/dotnet-run-file.md#multiple-c-files">multiple files</a>, and ways to make running file-based apps faster.</p>
<p>Try it out today and send your <a href="https://github.com/dotnet/sdk/issues/new">feedback to GitHub</a> as we continue to shape this experience during .NET 10 and beyond.</p>
        </div><!-- .entry-content -->

        <!-- AI Disclaimer -->
            </article>
    
</div><div><!-- Author section -->
            <h2>Author</h2>
            <div><div><p><img src="https://devblogs.microsoft.com/dotnet/wp-content/uploads/sites/10/2023/06/Damian-Edwards-Profile-Pic-2020-square-96x96.jpg" alt="Damian Edwards"></p></div><p>Damian's a Principal Architect on the .NET product team at Microsoft.</p></div>        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[US Trade Court Finds Trump Tariffs Illegal (545 pts)]]></title>
            <link>https://www.bloomberg.com/news/articles/2025-05-28/trump-s-global-tariffs-blocked-by-us-trade-court</link>
            <guid>44121732</guid>
            <pubDate>Thu, 29 May 2025 00:06:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bloomberg.com/news/articles/2025-05-28/trump-s-global-tariffs-blocked-by-us-trade-court">https://www.bloomberg.com/news/articles/2025-05-28/trump-s-global-tariffs-blocked-by-us-trade-court</a>, See on <a href="https://news.ycombinator.com/item?id=44121732">Hacker News</a></p>
Couldn't get https://www.bloomberg.com/news/articles/2025-05-28/trump-s-global-tariffs-blocked-by-us-trade-court: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[HTAP is Dead (147 pts)]]></title>
            <link>https://www.mooncake.dev/blog/htap-is-dead</link>
            <guid>44121177</guid>
            <pubDate>Wed, 28 May 2025 22:22:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.mooncake.dev/blog/htap-is-dead">https://www.mooncake.dev/blog/htap-is-dead</a>, See on <a href="https://news.ycombinator.com/item?id=44121177">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div><p>This blog is inspired by Jordan Tigani’s blog titled <a href="https://motherduck.com/blog/big-data-is-dead/">“Big Data is Dead”</a>. Jordan and I actually spent some time building a HTAP database at SingleStore. 
</p><h2>The good old days ('70s)</h2><p>Back in the ’70s, one relational database did everything. Transactions (OLTP) during the day and reports after hours (OLAP). Databases like Oracle V2 and IBM DB2 ran OLTP and OLAP on the same system; largely because data sets still fit on a few disks and compute was costly.</p><p>Nobody called it Hybrid Transactional/Analytical Processing (HTAP); it was simply the <strong>database.</strong>
</p><h2>The great divide (‘80s)</h2><p>As businesses had more data and asked tougher questions, the database began to show its limits.</p><p>See, transactional and analytical workloads pull in opposite directions. OLTP requires microsecond inserts and single-row lookups, while OLAP demands full-table scans and large-scale aggregates. This created constant contention; analytics consuming I/O and cache needed for latency-sensitive transactions, and vice versa. </p><p>The solution? Isolate the workloads. By the early ’80s, the Great Divide had begun.
</p><h2>The storage split (‘90s)</h2><p>A key technical driver behind this divide was storage architecture. OLTP systems optimized for row-based storage (fast writes + point queries). While OLAP systems chose columnar storage for efficient scans and aggregations.</p><p>By the mid-2000s, this split had become industry standard. Database pioneer Michael Stonebraker marked this shift in his <a href="https://dl.acm.org/doi/abs/10.1145/3226595.3226636">paper</a>, “One Size Fits All”: An Idea Whose Time Has Come and Gone. The database started breaking up into specialized engines.
</p><h2>OLTP and OLAP both ditched the SQL (2000–2010s)</h2><p>Horizontal scaling pushed OLTP and OLAP even further apart.</p><p>Early distributed OLTP databases (NoSQL engines like MongoDB) dropped SQL and analytical capabilities entirely. On the analytics side, we saw the adoption of MapReduce and Data Lake architectures (Hadoop/HDFS): trading traditional RDBMS properties like strict consistency for massive throughput.
</p><h2>The unexpected reconciliation (2010s)</h2><p>In the 2010s, two distinct database movements gained momentum:</p><p>1. <strong>NewSQL</strong> (Spanner, CockroachDB, Vitess). OLTP should remain SQL-based. <br>2. <strong>Cloud Data Warehouses</strong> (Redshift, Snowflake). OLAP should be on SQL systems with stronger consistency guarantees.</p><p>On paper, these systems served very different workloads. But under the hood, they shared a lot: distributed, MPP-style execution, and SQL. OLTP and OLAP systems, in isolation, had converged on many of the same architectural principles. There was one big difference: storage engines.</p><p>We asked ourselves: what if you could combine both row and columnstore storage engines in a single database? </p><h2>Voilà, HTAP (2014)</h2><p>In 2014, Gartner <a href="https://www.gartner.com/en/documents/2657815#:~:text=Summary,memory%20computing%20technologies%20as%20enablers">introduced</a> the term HTAP (Hybrid Transactional and Analytical Processing): the next big DB architecture. </p><p>The goal was to close the gap between operational and analytical systems. This was a necessity for emerging workloads like pricing, fraud detection, and personalization. Even at the business level, decision makers wanted now’s data. Early HTAP systems showed it could be done. Well, mostly…</p><p><a href="https://dl.acm.org/doi/10.1145/3514221.3526055">SingleStoreDB</a> combined an in-memory rowstore, a disk-based columnstore, and a vectorized execution engine—supporting fast scans, seeks, filters, aggregations, and updates in a single system. Over time, we found that with modern hardware, the columnstore alone could handle a surprising number of OLTP-style queries, including point lookups and low-latency access patterns.</p><p><a href="https://docs.pingcap.com/tidb/stable/tidb-architecture">TiDB</a> took a different route, pairing its TiKV rowstore with a separate columnar engine based on ClickHouse—maintaining two copies of the data to serve both workloads.</p><p>So that should be it, right? ‘70s data nirvana, alas.
</p><h2>The Cloud Data Warehouse was the only winner (2020s)</h2><p>Cloud data warehouses have clearly won. The NewSQL movement stalled… And HTAP? It never got the attention it deserved. Despite real technical progress, it remained pre-product market fit. </p><p><strong>1. It’s really, really hard to replace someone’s OLTP system.</strong> Take <a href="https://db-engines.com/en/ranking">DBEngines’</a> word for this: Oracle and SQL Server still sit at #1 and #3. </p><p><strong>2. Most workloads don’t need distributed OLTP.</strong> Hardware got faster and cheaper. A single beefy machine can handle the majority of transactional workloads.
<a href="https://www.youtube.com/watch?v=4jDQi9P9UIw">Cursor</a> and <a href="https://www.pixelstech.net/article/1747708863-openai%3a-scaling-postgresql-to-the-next-level">OpenAI</a> are powered by a single-box Postgres instance. You’ll be just fine. </p><p><strong>3. Cloud-native architectures favored shared-disk, not shared-nothing.</strong> While NewSQL systems demanded fast local storage (and even in-memory durability), cloud platforms pushed toward object storage and elastic compute. </p><p><strong>4. OLTP and OLAP are owned by different teams.</strong> OLTP is owned by product engineering; OLAP belongs to the data team. The incentives rarely align. No one gets promoted for “consolidating the stack”. </p><h2>Your data-stack forms the HTAP database (Today)</h2><p>The cloud also started the move away from tightly coupled warehouses toward modular lakes built on object storage.<br>In trying to escape the traditional warehouse/database, data teams started assembling their own custom systems. Made of ‘best-in-class’ building blocks:</p><p>1. OLTP systems and stream processors as the WAL<br>2. Open table formats like Iceberg serve as the storage engine<br>3. Query engines like Spark and Trino for execution<br>4. Real-time systems like ClickHouse or Elastic function as indexes</p><p>Even in today’s disaggregated data stack, the need remains the same: fast OLAP queries on fresh transactional data. This now happens through a web of streaming pipelines, cloud data lakes, and real-time query layers.</p><p>It’s still HTAP; but through composition instead of consolidation of databases. It comes down to questions like:</p><p><strong>1. How do I apply the WAL to my storage engine?</strong>
AKA: How do I CDC from my OLTP system to the data lake efficiently?</p><p><strong>2. Can I build a lower-cost index on my data lake, and keep it in sync?</strong>
AKA: How do I ingest real-time data into the lake? Or how do I query Lake data with Postgres or Elastic functionality?</p><p>The HTAP challenge of our time comes down to making the lakehouse real-time ready.</p><p>After spending my best 10 years first starting and then rescuing it, HTAP as a database is dead. <br>But let the spirit live on.<br>🥮</p></div></article></div></div>]]></description>
        </item>
    </channel>
</rss>